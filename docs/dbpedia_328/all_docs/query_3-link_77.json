{
    "id": "dbpedia_328_3",
    "rank": 77,
    "data": {
        "url": "https://pytorch.org/hub/nvidia_deeplearningexamples_tacotron2/",
        "read_more_link": "",
        "language": "en",
        "title": "Tacotron 2",
        "top_image": "https://pytorch.org/assets/images/social-share.jpg",
        "meta_img": "https://pytorch.org/assets/images/social-share.jpg",
        "images": [
            "https://www.facebook.com/tr?id=243028289693773&ev=PageView  &noscript=1",
            "https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)",
            "https://t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)",
            "https://pytorch.org/assets/images/tacotron2_diagram.png",
            "https://pytorch.org/assets/images/no-image",
            "https://pytorch.org/assets/images/logo-icon.svg",
            "https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&guid=ON&script=0",
            "https://pytorch.org/assets/images/pytorch-x.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Model Description",
        "meta_lang": "en",
        "meta_favicon": "/favicon.ico?",
        "meta_site_name": "PyTorch",
        "canonical_link": null,
        "text": "Model Description\n\nThe Tacotron 2 and WaveGlow model form a text-to-speech system that enables user to synthesise a natural sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.\n\nThis implementation of Tacotron 2 model differs from the model described in the paper. Our implementation uses Dropout instead of Zoneout to regularize the LSTM layers.\n\nExample\n\nIn the example below:\n\npretrained Tacotron2 and Waveglow models are loaded from torch.hub\n\nGiven a tensor representation of the input text (“Hello world, I missed you so much”), Tacotron2 generates a Mel spectrogram as shown on the illustration\n\nWaveglow generates sound given the mel spectrogram\n\nthe output sound is saved in an ‘audio.wav’ file\n\nTo run the example you need some extra python packages installed. These are needed for preprocessing the text and audio, as well as for display and input / output.\n\nLoad the Tacotron2 model pre-trained on LJ Speech dataset and prepare it for inference:\n\nLoad pretrained WaveGlow model\n\nNow, let’s make the model say:\n\nFormat the input using utility methods\n\nRun the chained models:\n\nYou can write it to a file and listen to it\n\nAlternatively, play it right away in a notebook with IPython widgets\n\nDetails\n\nFor detailed information on model input and output, training recipies, inference and performance visit: github and/or NGC\n\nReferences\n\nNatural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions\n\nWaveGlow: A Flow-based Generative Network for Speech Synthesis\n\nTacotron2 and WaveGlow on NGC\n\nTacotron2 and Waveglow on github"
    }
}