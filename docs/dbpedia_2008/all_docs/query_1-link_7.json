{
    "id": "dbpedia_2008_1",
    "rank": 7,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9377685/",
        "read_more_link": "",
        "language": "en",
        "title": "Online Medical Misinformation in Cancer: Distinguishing Fact From Fiction",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-jcoop.gif",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9377685/bin/op-18-00584-g001.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Eleonora Teplinsky",
            "Sara Beltrán Ponce",
            "Emily K. Drake",
            "Ann Meredith Garcia",
            "Stacy Loeb",
            "G.J. van Londen",
            "Deanna Teoh",
            "Michael Thompson",
            "Lidia Schapira"
        ],
        "publish_date": "2022-08-11T00:00:00",
        "summary": "",
        "meta_description": "It is without question that the Internet has democratized access to medical information, with estimates that 70% of the American population use it as a resource, particularly for cancer-related information. Such unfettered access to information has led ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9377685/",
        "text": "JCO Oncol Pract. 2022 Aug; 18(8): 584–589.\n\nPMCID: PMC9377685\n\nPMID: 35357887\n\nOnline Medical Misinformation in Cancer: Distinguishing Fact From Fiction\n\n, MD, 1 , MD, 2 , BScH, MA, 3 , MD, 4 , MD, 5 , MD, MS, 6 , MD, 7 , MD, PhD, 8 and , MD 9 , for the Collaboration for Outcomes using Social Media in Oncology (COSMO)\n\nEleonora Teplinsky\n\n1Valley-Mount Sinai Comprehensive Cancer Care; Valley Health System, Paramus, NJ\n\nFind articles by Eleonora Teplinsky\n\nSara Beltrán Ponce\n\n2Department of Radiation Oncology, Medical College of Wisconsin, Milwaukee, WI\n\nFind articles by Sara Beltrán Ponce\n\nEmily K. Drake\n\n3Faculty of Health, Dalhousie University, Halifax, Nova Scotia, Canada\n\nFind articles by Emily K. Drake\n\nAnn Meredith Garcia\n\n4Section of Medical Oncology, Dagupan Doctors Villaflor Memorial Hospital, Dagupan City, Philippines\n\nFind articles by Ann Meredith Garcia\n\nStacy Loeb\n\n5Department of Urology and Population Health, New York University and Manhattan Veterans Affairs, New York, NY\n\nFind articles by Stacy Loeb\n\nG.J. van Londen\n\n6Department of Medicine, University of Pittsburgh, Pittsburgh, PA\n\nFind articles by G.J. van Londen\n\nDeanna Teoh\n\n7Division of Gynecologic Oncology, University of Minnesota, Minneapolis, MN\n\nFind articles by Deanna Teoh\n\nMichael Thompson\n\n8Aurora Cancer Care, Advocate Aurora Health, Milwaukee, WI\n\nFind articles by Michael Thompson\n\nLidia Schapira\n\n9Stanford Cancer Institute, Stanford University, Palo Alto, CA\n\nFind articles by Lidia Schapira\n\n1Valley-Mount Sinai Comprehensive Cancer Care; Valley Health System, Paramus, NJ\n\n2Department of Radiation Oncology, Medical College of Wisconsin, Milwaukee, WI\n\n3Faculty of Health, Dalhousie University, Halifax, Nova Scotia, Canada\n\n4Section of Medical Oncology, Dagupan Doctors Villaflor Memorial Hospital, Dagupan City, Philippines\n\n5Department of Urology and Population Health, New York University and Manhattan Veterans Affairs, New York, NY\n\n6Department of Medicine, University of Pittsburgh, Pittsburgh, PA\n\n7Division of Gynecologic Oncology, University of Minnesota, Minneapolis, MN\n\n8Aurora Cancer Care, Advocate Aurora Health, Milwaukee, WI\n\n9Stanford Cancer Institute, Stanford University, Palo Alto, CA\n\nCorresponding author.\n\nEleonora Teplinsky, MD, Valley-Mount Sinai Comprehensive Cancer Care, Valley Health System, Paramus, NJ; e-mail: moc.htlaehyellav@lelpet.\n\nCopyright © 2022 by American Society of Clinical Oncology\n\nAbstract\n\nIt is without question that the Internet has democratized access to medical information, with estimates that 70% of the American population use it as a resource, particularly for cancer-related information. Such unfettered access to information has led to an increase in health misinformation. Fortunately, the data indicate that health care professionals remain among the most trusted information resources. Therefore, understanding how the Internet has changed engagement with health information and facilitated the spread of misinformation is an important task and challenge for cancer clinicians. In this review, we perform a meta-synthesis of qualitative data and point toward empirical evidence that characterizes misinformation in medicine, specifically in oncology. We present this as a call to action for all clinicians to become more active in ongoing efforts to combat misinformation in oncology.\n\nINTRODUCTION\n\nApproximately 72% of the population of the United States engages in at least one type of social media.1 The 2018 Health Information National Trends Survey found that 70% of US adults have accessed health information online,2 with cancer being one of the most frequently searched health terms.3,4 However, what is reliable and what is not continues to be a significant issue.5 In this area of uncertainty, trust in health care professionals continues to be stable, with 94% of Americans trusting clinicians compared with 64% who trust what is found on the Internet.6\n\nThe Internet has democratized access to medical information, and consumers with varying degrees of health and scientific literacy flock to various sources, platforms, and social media. Unfortunately, this has led to the rise of health misinformation, defined as any health-related claim of fact that is false on the basis of current scientific consensus, which can have negative and detrimental consequences.7 Understanding how the Internet has changed engagement with health information and facilitated the spread of misinformation is an important task and challenge for cancer clinicians. This review presents a meta-synthesis of qualitative data that addresses the origin, spread, and scope of misinformation in oncology.\n\nHEALTH MISINFORMATION ON THE INTERNET: WHAT IS IT?\n\nIn addition to the above definition, the US Surgeon General's Advisory on Building a Healthy Information Environment defines misinformation as information that is false, inaccurate, or misleading according to the best available evidence at the time.8 Misinformation can include information that is no longer current or information derived from an unreliable or irrelevant source.9\n\nMisinformation is not the same as disinformation, which is defined as a coordinated or deliberate effort to circulate misinformation knowingly to gain power, money, or reputation.9 Simply put, disinformation is intentional misinformation for secondary gain. Although the notion that sugar causes hyperactivity in children constitutes an example of misinformation, the deliberate effort of a pharmaceutical company to hide the addictive nature of opiates constitutes an example of disinformation.10 These distinctions are not static concepts, especially given the evolving nature of medical knowledge as new data are reported. This remains especially true in the context of cancer, where knowledge and information are constantly changing.\n\nCHALLENGES WITH EVALUATION AND VALIDATION OF ONLINE INFORMATION\n\nSocial media users are more likely to believe that information is correct if it is posted by a credible source,9 and in the case of medical information, it will typically be someone with health care–related credentials. However, there is no online verification of credentials for social media accounts, and anyone can engage in social media without providing credentials or by reporting false ones. In addition, there is a lack of incentive for social media companies to limit its spread.\n\nAnother challenge is defining fake scientific news, here defined as providing false or misleading information that is presented as scientifically believable and valid. Because fake news often has some basis in reality, it can be challenging for a layperson to distinguish it from what is scientifically valid and informed by current evidence. The most frequently cited example is a study published in The Lancet in 1998 linking the measles, mumps, and rubella vaccines to autism.11 Although this study has been used to support the belief that preventive vaccines cause serious and chronic health conditions, this seminal article was ultimately retracted in 2010 and the lead author stripped of his medical license.12,13 The false association persists despite the retraction, promoted in part by celebrities and others with large social media followings that claim personal experiences as proof.\n\nOncology is not immune to this type of misinformation. Haber et al demonstrated that 58% of the media articles covering the 50 most shared academic articles in 2015 inaccurately reported the question, results, methodology, or population of the study. There is a large disparity between the strength of the language presented in the media to the consumer and the underlying strength of causal inference.14 For example, the media coverage of a study evaluating coffee consumption and melanoma risk used stronger language than the language used in the scientific article.14,15\n\nBoutron et al evaluated the impact of spin on abstract results from randomized controlled clinical trials in oncology. Clinicians who assessed an abstract with spin rated the experimental treatment as being more beneficial than those assessing an article without spin.16 Although this study was conducted in the scientific community, the results have implications for the way oncology research is presented and interpreted in the media and public opinion.\n\nThe burden and challenge of evaluating content falls on the user, yet there are no clear methods or guidelines to verify the validity of the information posted on social media. Those with limited health literacy and/or experience may not be able to distinguish legitimate sources from questionable ones. Trivedi et al conducted a study of 53 social media users looking at 16 target posts focusing on human papillomavirus (HPV) vaccination or sunscreen safety. Users with adequate health literacy were able to correctly rate evidence-based posts as more believable than non–evidence-based posts, whereas users with limited health literacy were not. Those with limited health literacy spent more time on the source of the message than users with adequate health literacy. These users may tend to be more likely to believe in false news if the message comes from what they consider to be trusted sources on social media.17\n\nWHAT ACCOUNTS FOR THE SPREAD OF MISINFORMATION\n\nThe psychology of why misinformation spreads goes beyond the scope of this paper and we point the reader toward excellent resources.18-20 For the purpose of this discussion, we focus on the role of cognitive bias that influence our thinking and lead to errors in processing information. Two examples prevalent on social media are confirmation bias and the echo chamber effect. Confirmation bias refers to seeking information that supports a person's own hypothesis while ignoring information that deviates from it.21-23 It is a phenomenon common on closed social networks, most notably on Facebook, and is associated with the amplification of misinformation.20,24,25 An echo chamber refers to a situation in which users interact with other users who share their own viewpoints and avoid those with whom they do not agree.26 For example, a study of breast cancer retweeting behavior on Twitter demonstrated that messages written by users who had a higher number of followers, higher levels of personal influence over the interaction, and closer relationships and similarities with other users tended to be retweeted.27 These influences can lead to potential confirmation bias if users are exposed to messages from similar others. Similarly, in a study examining online HPV vaccine content, users who were more often exposed to antivaccine messages were more likely to have a negative opinion about the HPV vaccine in subsequent tweets.28 The combination of being susceptible to being influenced by others and the ease of access to information that confirms a person's bias makes it less likely that users will question the credibility of sources.24\n\nThe role of confirmation bias and the echo chamber effect has been clearly demonstrated in discussions around vaccine hesitancy (in general), which predated the COVID-19 pandemic (and the issues surrounding COVID-19 vaccines specifically, which are outside the scope of this paper). Schmidt et al29 performed a quantitative analysis of more than 2.6 million Facebook users around vaccine hesitancy and discovered that users consumed information either in favor or against vaccination, but not both, which over time resulted in highly polarized communities. Another study demonstrated that the social media content of users characterized as vaccine-hesitant was rarely shared between those in the mainstream community.30\n\nIt is important to understand who is more susceptible to online misinformation. In one study that included 923 Facebook participants, the accuracy of true and false social media posts on statin medications, cancer treatment, and the (HPV) vaccine was evaluated.31 People who believed in misinformation about the HPV vaccine were also likely to believe in misinformation about statins and cancer treatment. Individuals with less education and health literacy, less trust in the health care system, and more positive attitudes toward alternative medicine were more likely to believe in health misinformation. By contrast, health-related conditions that made the information more personally relevant, such as cancer or high cholesterol or cancer, did not predict misinformation.\n\nHowever, when medical science does not have all the answers and the expectation of a clinical benefit from evidence-based therapies is low, it may be easier to see the appeal of an unproven treatment, even if it defies logical reasoning.32 Fear and doubt can further increase susceptibility to misinformation.33\n\nIn the case of people living with cancer, it may well be the existential threat of death and/or the occurrence or fear of severe side effects of standard treatment that drives people to search for any intervention that provides a source of hope and empowerment. Although data evaluating this possibility are lacking, the use of complementary and alternative medicines (CAM) in people with cancer has been noted. For example, in one survey of Polish patients with gynecologic cancer, CAM use was significantly associated with educational status and recurrent disease.34\n\nONLINE HEALTH MISINFORMATION IN ONCOLOGY\n\nOncology-related health misinformation on social media is a pressing concern. Loeb et al35 reported a significant negative correlation between scientific quality and viewer engagement among prostate cancer informational videos on YouTube. Users were more likely to view poor quality or biased videos rather than higher-quality information. Unfortunately, this suggests that medical misinformation can spread quite rapidly (or go viral), particularly because most social media platform algorithms push content with more views or engagement.36 In a separate study, Loeb et al37 reported that almost 70% of bladder cancer content on YouTube was judged to be of moderate to poor quality. Johnson et al reviewed 50 of the most popular social media articles on each of the four most common cancers (breast, prostate, colorectal, and lung) posted on Facebook, Reddit, Twitter, or Pinterest between January 2018 and December 2019. Nearly one third of these articles contained misinformation, and 76.9% contained harmful information that could lead to adverse consequences such as treatment delays, toxicity of recommended tests or procedures, and/or adverse interactions with the current standard of care. The role of misinformation and how it might relate to the standard of care was suggested in the study cited regarding people with gynecologic cancer: 26% received information about CAM from the Internet and 52% read other sources, whereas < 3% discussed its use with their doctors.4 Despite this, CAM use was 2.3-fold higher among those being treated with standard chemotherapy (v other therapies). Although not specifically addressing misinformation, this study informs people with cancer of role of alternative sources of information and suggests that they may still undergo standard treatment.\n\nIt is clear that online cancer information is inconsistent and sometimes at odds with published data and expert opinions. It is no wonder that patients may become confused and unsure where to turn and who to trust.16\n\nTHE ROLE OF HEALTH CARE PROFESSIONALS ON SOCIAL MEDIA AND A CALL TO ACTION\n\nWe are just beginning to understand how to respond to misinformation, especially in the field of oncology.9 However, steps to address this have been proposed by the National Academies of Sciences, Engineering, and Medicine in a 2020 roundtable on health literacy (Table ).38\n\nCalling out those who spread misinformation for secondary gain (eg, financial profit or Internet fame) is a means by which we can induce skepticism toward those who create or spread misinformation. A contemporary example was published in 2005 to expose the extent to which the tobacco industry was involved in the review of sudden infant death syndrome and secondhand smoke.39 The authors noted that the main author had financial conflicts of interest and that tobacco industry executives were directly involved in the preparation of the review.\n\nThere are many credible sources for cancer-related news and information, including multiple patient advocacy, nonprofit organizations, and university- and hospital-based websites. Social media users are in a unique position to counter misinformation by pointing followers in their direction so individuals searching for information can access more credible data.\n\nBecause scientific literacy is not only a contributor to the spread of misinformation but also a significant problem in the United States, health care providers should view the Internet as a collaborative tool that has the potential to assist patients and care partners in better managing their illness, especially when we use it to speak in plain language to our own constituents, thereby making complicated studies more accessible. In turn, health care organizations need to prioritize the dissemination of scientifically vetted and practical health information by providing resources and training of health care professionals in health communication and social media use.40-42\n\nOur ability to fight misinformation cannot be accomplished alone, especially given the rapid global flow of information. It will take collaboration with all affected by its spread. Stakeholder engagement is critical to doing this, both by presenting unified messages that are accessible to as wide an audience as possible and by disseminating accurate information across multiple platforms. We should not forget that the majority of the public believe in science and medicine. This is evident even during the COVID-19 pandemic, where despite the havoc caused by vaccine misinformation, the majority of the public have accepted vaccination.43\n\nOur role on social media is to collectively monitor and flag misinformation when we encounter it, regardless of the platform. Cancer professionals should proactively raise awareness of low-quality information (or egregiously false information) and educate and share high-quality information. Adding clinician engagement can aid in appropriate information provision and dissemination, as shown through the #BCSM (breast cancer social media) community, which was the first cancer support community established on Twitter and founded in 2011 by two breast cancer survivors.44,45 We must be careful not to devalue and judge patient experiences and beliefs, both in person and online.\n\nIn the current social media landscape, the responsibility is to identify what is accurate and what misinformation falls on the user consuming the information. On a larger scale, we encourage social media platforms to focus on vetting accounts, fact-checking, and supporting verification efforts for health information. This will help users who cannot distinguish accurate information from misleading information on the basis of the message or post content alone. Currently, a blue verified badge on Twitter denotes that a public interest account is active, authentic, and notable.46 Verified accounts tend to have greater credibility and tend to be shared and promoted more widely. Setting criteria for verification that focus specifically on health and science information accounts is imperative to begin to combat misinformation and help users better differentiate accurate information from misleading information.\n\nIn conclusion, misinformation has a pervasive impact on oncology. We anticipate that the rapid evolution of new communication technologies and social media will continue to raise new challenges and dilemmas, while at the same time, offer new opportunities for social connection and accessing information. Health care professionals need to be engaged in research to better understand misinformation, how to work to combat it, and reach the population most affected by online health misinformation. Interventional research in this area is in its infancy; however, some data suggest that it can be effective. Indeed, a 2021 meta-analysis concluded that social media interventions can produce a significant and positive impact, with effectiveness tied to the involvement of stakeholders and dissemination by news organizations and experts.47 These data suggest that our traditional methods for conducting scientific research require greater collaboration, from their design to implementation to analysis. Together, we can find new approaches to decrease the abundance of misinformation about cancer.\n\nNotes\n\nEleonora Teplinsky\n\nConsulting or Advisory Role: GlaxoSmithKline, Eisai, Tesaro\n\nEmily K. Drake\n\nOther Relationship: Emily Drake (EmilyDrake.ca)\n\nAnn Meredith Garcia\n\nHonoraria: Pfizer, MIMS\n\nConsulting or Advisory Role: Docquity, Lilly\n\nSpeakers' Bureau: AstraZeneca, Boehringer Ingelheim, MSD, Roche, Unilab\n\nTravel, Accommodations, Expenses: Sun Pharma, Fresenius Kabi, Goodfellow Pharma, orient EuroPharma\n\nStacy Loeb\n\nStock and Other Ownership Interests: Gilead Sciences\n\nG.J. van Londen\n\nEmployment: CancerSurvivorMD, LLC, GvanLondenMD, LLC\n\nLeadership: GvanLondenMD, LLC, CancerSurvivorMD, LLC\n\nStock and Other Ownership Interests: CancerSurvivorMD, LLC, GvanLondenMD, LLC\n\nConsulting or Advisory Role: bioTheranostics\n\nOpen Payments Link: https://openpaymentsdata.cms.gov/physician/1218078\n\nDeanna Teoh\n\nResearch Funding: Tesaro, Moderna Therapeutics (Inst)\n\nMichael Thompson\n\nStock and Other Ownership Interests: Doximity\n\nConsulting or Advisory Role: Celgene, VIA Oncology, Takeda, GlaxoSmithKline, Syapse, Adaptive Biotechnologies, AbbVie, GRAIL, Epizyme, Janssen Oncology, Sanofi\n\nResearch Funding: Takeda (Inst), Bristol Myers Squibb (Inst), TG Therapeutics (Inst), Cancer Research and Biostatistics (Inst), AbbVie (Inst), PrECOG (Inst), Strata Oncology (Inst), Lynx Biosciences (Inst), Denovo Biopharma (Inst), ARMO BioSciences (Inst), GlaxoSmithKline (Inst), Amgen (Inst)\n\nPatents, Royalties, Other Intellectual Property: UpToDate, Peer Review for Plasma Cell Dyscrasias (Editor: Robert Kyle)\n\nTravel, Accommodations, Expenses: Takeda, GlaxoSmithKline, Syapse\n\nOther Relationship: Doximity\n\nUncompensated Relationships: Strata Onoclogy\n\nOpen Payments Link: https://openpaymentsdata.cms.gov/physician/192826/summary\n\nLidia Schapira\n\nConsulting or Advisory Role: Rubedo Life Sciences, Blue Note Therapeutics\n\nNo other potential conflicts of interest were reported.\n\nSUPPORT\n\nThis paper represents themes presented at the Inaugural Collaboration for Outcomes Using Social Media in Oncology (COSMO) Conference, funded in part by the National Cancer Institute 1R13CA239613-01A1, the Rhode Island Department of Health, Stanford Cancer Institute, Lifespan Cancer Institute, and The Warren Alpert Medical School of Brown University.\n\nAUTHOR CONTRIBUTIONS\n\nConception and design: Eleonora Teplinsky, Emily K. Drake, G.J. van Londen, Deanna Teoh, Michael Thompson, Lidia Schapira\n\nCollection and assembly of data: Eleonora Teplinsky, Sara Beltrán Ponce, Ann Meredith Garcia, Michael Thompson, Lidia Schapira\n\nData analysis and interpretation: Eleonora Teplinsky, Sara Beltrán Ponce, Stacy Loeb, G.J. van Londen, Deanna Teoh, Michael Thompson, Lidia Schapira\n\nManuscript writing: All authors\n\nFinal approval of manuscript: All authors\n\nAccountable for all aspects of the work: All authors\n\nAUTHORS' DISCLOSURES OF POTENTIAL CONFLICTS OF INTEREST\n\nOnline Medical Misinformation in Cancer: Distinguishing Fact From Fiction\n\nThe following represents disclosure information provided by authors of this manuscript. All relationships are considered compensated unless otherwise noted. Relationships are self-held unless noted. I = Immediate Family Member, Inst = My Institution. Relationships may not relate to the subject matter of this manuscript. For more information about ASCO's conflict of interest policy, please refer to www.asco.org/rwc or ascopubs.org/op/authors/author-center.\n\nOpen Payments is a public database containing information reported by companies about payments made to US-licensed physicians (Open Payments).\n\nEleonora Teplinsky\n\nConsulting or Advisory Role: GlaxoSmithKline, Eisai, Tesaro\n\nEmily K. Drake\n\nOther Relationship: Emily Drake (EmilyDrake.ca)\n\nAnn Meredith Garcia\n\nHonoraria: Pfizer, MIMS\n\nConsulting or Advisory Role: Docquity, Lilly\n\nSpeakers' Bureau: AstraZeneca, Boehringer Ingelheim, MSD, Roche, Unilab\n\nTravel, Accommodations, Expenses: Sun Pharma, Fresenius Kabi, Goodfellow Pharma, orient EuroPharma\n\nStacy Loeb\n\nStock and Other Ownership Interests: Gilead Sciences\n\nG.J. van Londen\n\nEmployment: CancerSurvivorMD, LLC, GvanLondenMD, LLC\n\nLeadership: GvanLondenMD, LLC, CancerSurvivorMD, LLC\n\nStock and Other Ownership Interests: CancerSurvivorMD, LLC, GvanLondenMD, LLC\n\nConsulting or Advisory Role: bioTheranostics\n\nOpen Payments Link: https://openpaymentsdata.cms.gov/physician/1218078\n\nDeanna Teoh\n\nResearch Funding: Tesaro, Moderna Therapeutics (Inst)\n\nMichael Thompson\n\nStock and Other Ownership Interests: Doximity\n\nConsulting or Advisory Role: Celgene, VIA Oncology, Takeda, GlaxoSmithKline, Syapse, Adaptive Biotechnologies, AbbVie, GRAIL, Epizyme, Janssen Oncology, Sanofi\n\nResearch Funding: Takeda (Inst), Bristol Myers Squibb (Inst), TG Therapeutics (Inst), Cancer Research and Biostatistics (Inst), AbbVie (Inst), PrECOG (Inst), Strata Oncology (Inst), Lynx Biosciences (Inst), Denovo Biopharma (Inst), ARMO BioSciences (Inst), GlaxoSmithKline (Inst), Amgen (Inst)\n\nPatents, Royalties, Other Intellectual Property: UpToDate, Peer Review for Plasma Cell Dyscrasias (Editor: Robert Kyle)\n\nTravel, Accommodations, Expenses: Takeda, GlaxoSmithKline, Syapse\n\nOther Relationship: Doximity\n\nUncompensated Relationships: Strata Onoclogy\n\nOpen Payments Link: https://openpaymentsdata.cms.gov/physician/192826/summary\n\nLidia Schapira\n\nConsulting or Advisory Role: Rubedo Life Sciences, Blue Note Therapeutics\n\nNo other potential conflicts of interest were reported."
    }
}