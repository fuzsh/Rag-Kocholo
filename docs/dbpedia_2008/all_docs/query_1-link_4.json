{
    "id": "dbpedia_2008_1",
    "rank": 4,
    "data": {
        "url": "https://misinforeview.hks.harvard.edu/article/fact-opinion-differentiation/",
        "read_more_link": "",
        "language": "en",
        "title": "Fact-opinion differentiation",
        "top_image": "https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/03/company-3502288_1280.jpg",
        "meta_img": "https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/03/company-3502288_1280.jpg",
        "images": [
            "https://misinforeview.hks.harvard.edu/wp-content/themes/ristretto/img/misinfo-logo-white.svg",
            "https://misinforeview.hks.harvard.edu/wp-content/themes/ristretto/img/crossref-logo.png",
            "https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/03/company-3502288_1280-1024x633.jpg",
            "https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/03/fact-opinion-differentiation-figure1.jpeg",
            "https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/03/fact-opinion-differentiation-figure2.jpeg",
            "https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/06/paragraph-63977_1920-736x570.png",
            "https://misinforeview.hks.harvard.edu/wp-content/uploads/2024/06/decision-1697537_1920-736x570.png",
            "https://misinforeview.hks.harvard.edu/wp-content/themes/ristretto/img/hks.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "information bias",
            "partisan issues"
        ],
        "tags": null,
        "authors": [
            "Vicky Gabriel",
            "Matthew Mettler",
            "Jeffery J. Mondak"
        ],
        "publish_date": "2024-03-07T00:39:38-05:00",
        "summary": "",
        "meta_description": "Statements of fact can be proved or disproved with objective evidence, whereas statements of opinion depend on personal values and preferences. Distinguishing between these types of statements contributes to information competence. Conversely, failure at fact-opinion differentiation potentially brings resistance to corrections of misinformation and susceptibility to manipulation. Our analyses show that on fact-opinion differentiation tasks, unsystematic",
        "meta_lang": "en",
        "meta_favicon": "/apple-touch-icon.png",
        "meta_site_name": "Misinformation Review",
        "canonical_link": "https://misinforeview.hks.harvard.edu/article/fact-opinion-differentiation/",
        "text": "Implications\n\nDuring an episode of the sitcom Abbott Elementary, the whiteboard in second-grade teacher Janine Teagues’ classroom displayed the outline of a lesson on fact-opinion differentiation: “Fact vs. Opinion. Fact – A thing that is known or proved to be true. Opinion – A personal judgment, thought, or belief.” The skill taught in that lesson represents a key component of successful information processing. Statements of fact and statements of opinion differ in form, content, and significance. Absent a capacity to distinguish between statements of fact and statements of opinion, our concern is that individuals will struggle to make sense of the claims they encounter from sources such as politicians, newscasters, and salespersons.\n\nThe producers of Abbott Elementary were right to incorporate a lesson on fact-opinion differentiation in their fictional curriculum. Faulty fact-opinion differentiation leaves individuals misinformed not because they are wrong on the facts but because they are wrong on what facts are. Consequently, we posit that fact-opinion differentiation may play an underappreciated role in how individuals come to be misinformed and why misinformation can be difficult to correct. Research on the nature and significance of factual misinformation abounds, with much of this research exploring basic matters regarding how much misinformation exists, the conditions in which it flourishes, and the factors that lead individuals to be susceptible to it. Building on that research requires attention to the information-processing skills that can empower individuals to be more sophisticated information consumers. Fact-opinion differentiation is one such skill because understanding what is and is not a factual claim fosters more discerning categorization and evaluation of new information. Statements of fact are claims that can be “proved or disproved by objective evidence” (Mitchell et al., 2018, p. 3). Similar terminology is used in educational resources. As one example, a review sheet published by Palm Beach State College (n.d.) explains that “A fact is a statement that can be verified. It can be proven to be true or false through objective evidence.”\n\nObjective evidence is often quantifiable (e.g., the number of votes cast in an election and the change in the national unemployment rate from one month to another) and comes from verifiable sources and methods such as official government records. In some instances, objective evidence can be obtained from scientific testing. For example, if someone claimed, “the color green can be formed by mixing blue and yellow” or “the boiling point of water is 212° F,” others could conduct their own tests to corroborate those assertions.\n\nStatements of opinion are claims that cannot be proved true or false with objective evidence because their assessment depends on individual preferences and values. For Mitchell et al. (2018), a statement of opinion “reflects the beliefs and values of whoever expressed it” (p. 3). Examples are “the unemployment rate is too high” and “green is the most beautiful color.” Both these claims reflect personal values and preferences, and other people may feel differently.\n\nImportantly, statements of fact are not inherently true. Factual claims can get the facts wrong. For instance, “2 + 2 = 22” is a statement of fact, but it is factually incorrect. Making errors in statements of fact does not transform those statements of fact into statements of opinion. They are incorrect statements of fact. As an example, a news source might see a 4.4% unemployment rate in a Bureau of Labor Statistics document but inadvertently report it as 44%. That would be an incorrect statement of fact, and it would be a statement that could be proved false with review of objective evidence—the actual rate as reported by the BLS. Thus, statements of fact and statements of opinion both come in two forms. For statements of fact, some are correct, and others are incorrect. For statements of opinion, some are opinions we share, and others are opinions we reject.\n\nMost scholarly research on misinformation examines whether people get the facts right. The implicit assumption is that people agree that factual matters are under consideration but sometimes get the facts wrong. At any given moment, the U.S. unemployment rate is below 5% or it is greater than or equal to 5%. Therefore, if one person says unemployment is less than 5% while another person insists it is higher, one of them is right, and the other is wrong. When one person claims “the U.S. unemployment rate currently is 10.5%,” a second person might answer, “That’s wrong. Here is the Bureau of Labor Statistics website. The current unemployment rate is 3.7%.” In this scenario, an obvious path to correction of misinformation exists, and corrective efforts can be expected to yield at least some success.\n\nFaulty fact-opinion differentiation produces a different form of misinformation. Instead of disagreeing on the facts, there is disagreement about whether the matter under consideration even involves facts. In this circumstance, the hypothetical conversation would play out differently. When the first person asserts that the national unemployment rate is 10.5% and the second shows that the rate is actually 3.7%, the first person might react by saying, “we can agree to disagree. We’re each entitled to our own opinion.” This is meta-level misinformation. The first person has misconstrued the empirical world due to a misunderstanding about the very nature of statements of fact and statements of opinion.\n\nFlipping our example around, flawed fact-opinion differentiation can also lead people to see facts where they do not exist. When a candidate insists “unemployment is too high,” that is an opinion. It is an interpretation of current conditions. A voter who accepts that claim on its face as being a statement of fact would misconstrue the empirical world. Upon making that error, a risk exists that the voter would see no need to acquire factual information, such as what the unemployment rate is and how that rate compares with historical averages. Thinking we have the facts when we do not is a form of misinformation.\n\nOnly a handful of prior studies on the link between fact-opinion differentiation and mass opinion have been reported. Mitchell et al. (2018) produced an exploratory, descriptive analysis of Americans’ levels of success at fact-opinion differentiation. Subsequent research has contributed analyses with data from college students (Bak, 2022; Peterson, 2019), patterns in the presentation of factual and opinion content on cable news programs (Meacham, 2020), and the impact of linguistic structure on readers’ success in determining whether textual claims are statements of fact or opinion (Kaiser & Wang, 2021). Building on this literature, we introduce data from twelve fact-opinion items included on a 2019 survey and conduct multivariate analyses expanding on the findings in Mitchell et al. (2018).\n\nAcross ten items, Mitchell et al. (2018) found that respondents had an overall success rate of 69.3%. That percentage risks being interpreted unduly positively. The items are dichotomous—the only choice options are that the statement being evaluated is a statement of fact or a statement of opinion—meaning, on average, a respondent guessing randomly would have scored 50%. To acknowledge this 50% baseline, we describe success rates in terms of respondents’ levels of improvement over chance. Our reassessment of the prevalence of faulty fact-opinion differentiation suggests that judgmental failures are widespread. On our survey, nearly half of respondents (45.7%) exhibited no improvement over chance.\n\nTwo processes can generate errors in fact-opinion differentiation. One, labeled here as unbiased error, is largely unsystematic. Some individuals struggle with the task in a manner that leads them toward random guessing. Mitchell et al. (2018) show via crosstabs that fact-opinion differentiation success increases with political awareness and media savvy. Consistent with that, our multivariate analyses reveal that accuracy increases and unsystematic error decreases as a function of four components of political sophistication: civics knowledge, current events knowledge, cognitive ability, and education. In our conceptualization, unbiased error is a residual category that comprises incorrect responses that reflect neither accuracy nor error rooted in partisan bias. Although most such responses likely emanate from random guessing, some may not. For instance, a respondent who believes all politicians always lie would record systematic rather than random errors on our items, but those errors would not reflect partisan preference. Put differently, our terminology of unbiased error is shorthand for “incorrect responses resulting from any cause other than partisan bias.”\n\nThe second process, which we label as partisan bias, is systematic. Mitchell et al. (2018) provide preliminary evidence that partisans are more likely to see claims that align with their views as being statements of fact and claims inconsistent with their views as being statements of opinion. Expanding on this, we focus not on partisan identity but instead on affective partisan polarization. Iyengar and Westwood (2015) define affective polarization as “the tendency of people identifying as Republicans or Democrats to view opposing partisans negatively and co-partisans positively” (p. 691). Our analyses indicate that affective polarization increases the response tendency observed by Mitchell et al. (2018). As affective partisan polarization intensifies, respondents become more likely to answer that their party has the facts on its side while the other party has opinions. Hence, respondents do not merely misconstrue the empirical world. Instead, they systematically reconstruct it so that it aligns with their partisan orientations. Democrats and Republicans do not just disagree on the facts; they disagree on what facts are. This partisan bias is quite powerful. When success at fact-opinion differentiation increases as a function of civics knowledge, current events knowledge, cognitive ability, and education, it mostly does so by converting unbiased error to correct response; partisan error largely persists. Thus, faulty fact-opinion differentiation not only contributes to political misinformation but also does so in a manner that activates partisan biases, thereby amplifying polarization in perceptions of American politics and society.\n\nWe examined the phenomenon’s general contours through development and application of a novel multivariate analytical strategy. Specifically, we used a carefully constructed measure of fact-opinion differentiation success, one that enabled us to distinguish between correct responses, unbiased errors, and errors resulting from partisan bias. We then examined these outcomes using a multinomial estimation strategy. Analyses proceeded in three steps. First, we assessed the extent to which people have an easy or difficult time distinguishing between statements of fact and opinion. Second, with focus on four components of political sophistication, we considered what factors may contribute to successful fact-opinion differentiation. Third, where errors occurred, their properties were examined. Errors may emanate from nonpolitical processes such as blind guessing, but systematic processes rooted in partisan bias may also shape what people view as being included in or excluded from the empirical world.\n\nCollectively, our analyses call attention to faulty fact-opinion differentiation and show that errors rooted in partisan bias are especially persistent. For media organizations and public interest groups committed to combatting misinformation, our analyses suggest a second form of action may be needed. Fact checks strive to be curative, but they are not preventative. Lessons in fact-opinion differentiation, lessons such as those in the Abbott Elementary episode described above, strive to be preventative. Beyond being careful not to blur the line between fact and opinion themselves, media organizations can also explain and reiterate the difference between statements of fact and statements of opinion to their viewers and readers. They can help their audiences to appreciate the difference between statements of fact and statements of opinion and to become more adept at distinguishing between the two forms of claims. With more such efforts by journalists to highlight the fundamental distinction between statements of fact and statements of opinion, news consumers may be inoculated against reflexively concluding that favored claims are always fact-based and disfavored ones are only opinions.\n\nFindings\n\nFinding 1: Success rates at fact-opinion differentiation are low.\n\nRespondents on the 2019 survey rated twelve claims, including ten drawn from Mitchell et al. (2018), as statements of fact or statements of opinion. Results are shown in Table 1. Parallel results for the ten Pew items examined by Mitchell et al. (2018) are also reported. Across all items, accuracy ranges between 26% and 80% and averages 64%.\n\nTwo items warrant mention. First, as noted by Firey (2018), item 2 perhaps could be categorized as a statement of opinion because the phrase “a significant portion” is subjective. We repeated Pew’s coding on our survey, and solid majorities on both surveys rated the item as a statement of fact. In retrospect, we would categorize the statement as borderline (see note 4 above). By the end of 2017, ISIS had lost 95% of its territory (Wilson Center, 2019). Because such an overwhelming loss would be difficult to deem insignificant, we retain the item as a statement of fact for present purposes.\n\nItem 6 is a statement of fact that is factually incorrect. Only 26% of respondents answered this correctly. We suspect many of the errors may reflect thinking to the effect of “people who claim that are wrong, but they’re entitled to their opinion.” Such rationalizations potentially enable misinformation to survive by reclassifying factual error as opinion.\n\nBecause the fact-opinion items are dichotomous, 2019 data are recoded for multivariate analyses. Using 50% as the baseline success rate for random guessing, the mean level of improvement over chance is 26.9%. Error is decomposed into error reflecting partisan bias (28.5%) and unbiased residual error (44.6%). For multivariate analyses, the dependent variable is a proportion, and there are three categories or outcomes: accurate response, partisan error, and unbiased error. Models were estimated using grouped-data multinomial logistic regression.\n\nFinding 2: Success at fact-opinion differentiation increases with civics knowledge, current events knowledge, cognitive ability, and education.\n\nConsistent with Mitchell et al.’s (2018) finding that success at fact-opinion differentiation improves with political awareness, our multivariate analyses revealed that higher levels of civics knowledge, current events knowledge, cognitive ability, and education correspond with greater accuracy. This is seen in the green lines in Figure 1, which depict predicted levels of accurate response. These lines all slope modestly upward as the political sophistication variables increase in value. Figure 1 also shows that the variables operate mostly by reducing unbiased error (the blue lines, which provide predicted levels of unbiased error, have significant downward slopes). In contrast, effects on partisan error are minimal (the red lines that show estimates for partisan error slope slightly upward for civics knowledge and current events knowledge and very slightly downward for cognitive ability and education).\n\nFinding 3: Affective partisan polarization produces systematic partisan error in fact-opinion differentiation.\n\nAffective partisan polarization was operationalized as the difference in average feeling thermometer scores for Democrats (Obama, H. Clinton, Pelosi, Schumer) and Republicans (Trump, Pence, Cruz, McConnell), with separate 0 to 100 variables used to represent pro-Democratic and pro-Republican polarization. Figure 2 shows that partisan polarization leads individuals to assess political statements differently depending upon whether the statements align with partisan preferences. For biased partisans, the tendency is to perceive statements amenable to their political interests as statements of fact and claims inconsistent with their interests as statements of opinion (the red lines, denoting partisan error, slope significantly upward as affective partisan polarization increases). This effect is more pronounced for Republicans than for Democrats. Moreover, increasing levels of affective partisan polarization decrease accurate responses only for Republicans.\n\nMethods\n\nData are from a national online survey we designed. The survey was fielded by YouGov from March 9 to March 14, 2019. There are 2,500 respondents.\n\nThe dependent measure is a proportions variable with three outcomes: accurate response, partisan error, and unbiased error. Accurate response is operationalized as improvement over chance. With twelve dichotomous fact-opinion items, accuracy ranges from 0 (six or fewer items were answered correctly) to 1 (all items were answered correctly). Partisan bias exists when respondents answer that claims more aligned with their party are facts and claims more aligned with the opposing party are opinions. The items were structured such that partisan preferences coincided with three statements of fact and three statements of opinion for each party. Therefore, respondents exhibited partisan bias—and committed partisan error—if seven or more of their answers favored their own political party. Thus, partisan bias ranged from 0 (six or fewer answers favor the respondent’s party) to 1 (all 12 answers favor the respondent’s party). Unbiased error was a residual category that captured errors in fact-opinion differentiation that did not arise from favoritism toward one’s own party: 1 – (accurate response + partisan bias).\n\nMultivariate models include controls for age and partisanship. Political sophistication is represented with four variables: civics knowledge, current events knowledge, cognitive ability, and education. Pro-Democratic and pro-Republican affective partisan polarization is operationalized by differencing feeling thermometer scores for four Democrats (Obama, H. Clinton, Pelosi, Schumer) and four Republicans (Trump, Pence, Cruz, McConnell). Descriptive statistics for all variables are reported in the Appendix.\n\nBecause the dependent measure is a proportions variable, models are estimate using grouped-data multinomial logistic regression (see Greene, 2016). We used the nnet package in R. Full results are reported in the Appendix."
    }
}