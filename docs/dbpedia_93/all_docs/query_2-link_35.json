{
    "id": "dbpedia_93_2",
    "rank": 35,
    "data": {
        "url": "http://www.openthefuture.com/the_long_view/",
        "read_more_link": "",
        "language": "en",
        "title": "Open the Future: The Long View Archives",
        "top_image": "http://www.openthefuture.com/images/archetypes.png",
        "meta_img": "",
        "images": [
            "http://www.openthefuture.com/OTF_new_banner2.jpg",
            "http://www.openthefuture.com/images/cena_cxo_big.jpg",
            "http://www.assoc-amazon.com/e/ir?t=openthefuture-20&l=as2&o=1&a=0441014151",
            "http://www.openthefuture.com/images/future%20in%20reverse.png",
            "http://www.assoc-amazon.com/e/ir?t=openthefuture-20&l=as2&o=1&a=0316098124",
            "http://www.assoc-amazon.com/e/ir?t=openthefuture-20&l=as2&o=1&a=0441014151",
            "http://www.openthefuture.com/images/jet-pack.png",
            "http://www.openthefuture.com/images/Mechanical Staff.jpg",
            "http://www.openthefuture.com/images/CSIthefuture.jpg",
            "http://www.assoc-amazon.com/e/ir?t=openthefuture-20&l=as2&o=1&a=0061724602",
            "http://farm6.staticflickr.com/5291/5583056317_04aeccb704.jpg",
            "http://www.openthefuture.com/images/logo2.png",
            "http://www.openthefuture.com/images/ad025.jpg",
            "http://farm7.static.flickr.com/6113/6355637385_bdd41ae114.jpg",
            "http://www.openthefuture.com/images/tec1.jpg",
            "http://www.openthefuture.com/images/nothing_ever_ends.PNG",
            "http://farm6.static.flickr.com/5225/5602551907_3dd911dfc8_m.jpg",
            "http://www.openthefuture.com/images/tabletontablet.jpg",
            "http://upload.wikimedia.org/wikipedia/en/1/1f/Mosaic_Netscape_0.9_on_Windows_XP.png",
            "http://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Archaeopteryx_lithographica_%28Berlin_specimen%29.jpg/250px-Archaeopteryx_lithographica_%28Berlin_specimen%29.jpg",
            "http://upload.wikimedia.org/wikipedia/commons/c/c2/Velociraptor_BW.jpg",
            "http://www.openthefuture.com/images/archetypes.png",
            "http://www.openthefuture.com/images/SCCTmatrix.png",
            "http://www.openthefuture.com/images/Nothing_Ends.png",
            "http://farm5.static.flickr.com/4044/4303852557_016c5c72d2_o.png",
            "http://farm2.static.flickr.com/1386/4724805604_7b316bbf86_d.jpg",
            "http://www.openthefuture.com/images/Future of Money.png",
            "http://upload.wikimedia.org/wikipedia/commons/thumb/0/00/John_Henry-27527.jpg/720px-John_Henry-27527.jpg",
            "http://www.openthefuture.com/images/Were-Car.png",
            "http://upload.wikimedia.org/wikipedia/en/3/3f/Day_the_Earth_Stood_Still_1951.jpg",
            "http://www.openthefuture.com/images/Puccinia_graminis_teliospores.png",
            "http://farm3.static.flickr.com/2268/2186974234_eba0f34aaf_m.jpg",
            "http://www.openthefuture.com/images/second uncanny valley.jpg",
            "http://www.openthefuture.com/images/saturn-eclipse.jpg",
            "http://www.openthefuture.com/images/tinyearth.jpg",
            "http://www.openthefuture.com/images/seeds.jpg",
            "http://www.boingboing.net/images/parts.jpg",
            "http://www.openthefuture.com/images/88mpg_annotated_sm.jpg",
            "http://static.zooomr.com/images/850346_21f4f9d31e_t.jpg",
            "http://www.openthefuture.com/images/sb.jpg",
            "http://www.openthefuture.com/images/metropolis.jpg",
            "http://farm1.static.flickr.com/180/379448815_7719b6c58f_m.jpg",
            "http://farm1.static.flickr.com/159/380856484_2c1221c9d5_m.jpg",
            "http://www.openthefuture.com/images/apocoscale_sm.jpg",
            "http://www.openthefuture.com/images/crystal_ball.jpg",
            "http://www.openthefuture.com/images/stuffstation.jpg",
            "http://www.openthefuture.com/images/vivagel.jpg",
            "http://www.openthefuture.com/images/nanotube-yarn.gif",
            "http://www.openthefuture.com/images/200px-DendrimerOverview.png",
            "http://www.assoc-amazon.com/e/ir?t=openthefuture-20&l=ur2&o=1",
            "http://www.openthefuture.com/images/fruiticeutical.jpg",
            "http://www.openthefuture.com/images/hi2050sust.jpg",
            "http://veimages.gsfc.nasa.gov/1199/S1999164224031_md.jpg",
            "http://www.openthefuture.com/images/mchawking.jpg",
            "http://www.openthefuture.com/images/saturn_encedalus.jpg",
            "http://www.openthefuture.com/images/things_to_come.jpg",
            "http://www.openthefuture.com/80th/sgtwickline.jpg",
            "http://www.openthefuture.com/80th/paris1.jpg",
            "http://www.openthefuture.com/images/futurist_map_rev.jpg",
            "http://www.openthefuture.com/images/futurist_map.jpg",
            "http://www.openthefuture.com/images/spacer_tabi.jpg",
            "http://www.openthefuture.com/images/impact.jpg",
            "http://s28.sitemeter.com/meter.asp?site=s28openthefuture"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Thought experiment: imagine you've been taken, somehow, and dropped into a big city in another place, with comparable technological and economic development, somewhere you don't speak the language. Here's the twist: it's also time travel. How long would it take you to notice that you've been shifted in time as well as space?\n\nI've been thinking more lately about how it is we (as a collection of societies) respond to the world evolving around us. I've written before about the banality of the future -- the idea that changes that seem mind-boggling and transformative from the perspective of today would seem utterly boring to people who have lived through the development and slow deployment of those particular changes. There's also William Gibson's famous line, \"the future is here, it's just not evenly distributed.\" I'm fascinated by the idea that our perception of \"the future\" is contingent upon where and when we live.\n\nAt the Institute for the Future's 2013 Ten-Year Forecast event, I offered the concept of the \"fuzzy now\" -- the stretch of time before and after the present day in which there seems to be little if any significant change. The length of the fuzzy now period corresponds to how much disruptive, dislocative change is taking place. Which brings us back to the thought experiment: if you're within the \"fuzzy now,\" you may not realize that you've traveled in time for days.\n\nDropped into a new place, your first clues that you're in a different year would come from the gross physical environment: transportation types, building size/materials/designs, clothing design. You'd also be looking at what people are doing as they go about their business -- if they are fiddling with mobile phones, for example. Are there cues in terms of social behavior around ethnicity, gender, or sexual orientation? (Of course, if you spot an abundance of Zeppelins in the sky, you know immediately that you've moved to an alternate universe.)\n\nClues would come in two broad categories: things that should be there, but aren't; and things that shouldn't be there, but are.\n\nIf you were to be sent back ten years (2003), for example, you might not immediately recognize that you were in a different year. Clothing, building, and automobile designs would be familiar enough, and the lack of the most recent items wouldn't be instantly apparent (especially if you factor in being in a different country, where such differences would be masked by cultural/market variations). One possible clue you might notice soon is the fewer number of people using mobile devices, the complete lack of any kind of \"tablet,\" and that the mobile phones in use are essentially all the old \"feature phone\" with buttons and tiny screens. Nobody has an Android or the like -- the iPhone wouldn't be coming out for another five years. Depending upon where you were, you might also see more public telephones and newspaper boxes. And once you saw that, you'd likely start picking up all sorts of other clues, especially about technology and media.\n\nIn short, we can say that ten years back is probably just beyond what we'd consider the \"fuzzy now\" -- you wouldn't notice immediately (as you would if you were bounced back a hundred years, or probably even 25), but you'd very likely pick up on it within an hour or two. Five years, conversely, would almost certainly be well within the \"fuzzy now;\" you'd eventually pick up on the shift, but it might take a day or more.\n\nWhat about if you were shifted forward in time ten years, not back? I'd hazard a guess that you'd notice much more swiftly that something was very, very wrong. Why? Because while the physical objects, designs, and media of ten years ago might seem dated, they would also seem familiar; decade-old stuff is often still in active use. New stuff would be a surprise, especially if the overall appearance was distinctive from anything back in your home time. Some of it you might discount as being in another country, but seeing big signs for electric vehicle rapid-charging stations, or bunches of people walking along the street wearing the descendants of Google Glass, or just about everyone wearing hats for sun protection, these would quickly stand out, especially in combination.\n\nA five year forward jump probably wouldn't be detected as quickly, but -- depending upon what kinds of developments we see -- could start to feel weird and wrong within an hour or two. This parallels the depiction of ten years back: the changes may not immediately be noticeable, but would not remain hidden for very long. This could actually be more dizzying than a jump in time that's immediately visible -- your sense of safety, already compromised by the unexpected shift in place, gets steadily undermined by the gnawing sense of wrongness. A bigger shift in time, conversely, is like ripping a bandage off -- shocking, but all at once.\n\nThe observation that a five year forward jump might parallel the effects of a ten year backwards shift suggests that a \"fuzzy now\" might extend twice as far back as it does forward. The you from 2013 would likely feel at home anywhere from (say) 2008 to 2015/2016, perhaps going for days without realizing that you've moved in time as well as space.\n\nThere's a futurist adage that to get a sense of the changes we face, you need to look back twice as far as you look ahead. My suggestion of the structure of the fuzzy now seems to align with that, at least superficially. But what needs to be clear is that I'm not saying that we'll change twice as much over the next ten years as we did in the last. Rather, it's that we are more sensitive to the emergence of the new than to the persistence of the old.\n\nThis has a few implications for foresight work.\n\nIt's a useful way of explaining the \"banality of the future\" idea. It's all about perspective. We may think of developments happening eight or ten years from now as being wildly disruptive, but for people living eight or ten years from now, today (2013) seems only marginally different at best.\n\nIt also offers a language for thinking about how different parts of the world experience change. A stable part of the developing world may have a broader fuzzy now than a place going through conflict or environmental destruction. Similarly, it's a way of articulating the disruption arising from different kinds of changes or events -- do they (temporarily?) shrink the fuzzy now period? Does a global economic downturn make the fuzzy now period expand?\n\nUltimately, it's a way of articulating the shock that can accompany big disruptions. We rely on the comforting knowledge that tomorrow will be pretty much like today. That seeming stability -- the spread of the fuzzy now -- actually allows us to think about the future. We don't have to look at our feet when we walk, figuratively speaking. But if you're accustomed to the present feeling like the last five or six years, and the next few years likely to seem like more of the same, suddenly having that perception of the present reduced from years to weeks, even days, can be enormously debilitating. Suddenly, we have to watch our feet.\n\nA disruptive, cataclysmic future doesn't goad us into action, it eviscerates our ability to look ahead.\n\nIn every foresight or forecasting exercise, there are two overarching tensions:\n\nThe more certain and detailed the forecast, the more people will accept it and believe it to be useful.\n\nThe more certain and detailed the forecast, the less likely it is to happen.\n\nThis is the foresight paradox: you can be completely accurate, or you can be completely engaging, but you can't be both. As a result, every forecast (or scenario, or prediction) has to find the right balance between the two, trading off likelihood for believability.\n\nAs a simple example: a forecast that says \"the next decade will see continued economic disruption\" is very likely to be true, but of limited utility and almost no capacity to inspire innovative thought; conversely, a forecast that says \"the Eurozone will collapse in the Summer of 2013, leaving EU countries scrambling to find usable currencies, with many temporarily adopting the dollar\" is almost certainly not going to happen as described, but offers clear guidance for action, and can inspire novel business and political strategies. If the latter forecast is given by someone in a suit and tie, with a very serious sounding title from a very serious sounding institution, many people will accept it as being much more than informed conjecture -- and will reject the more general forecast as being useless.\n\nThis shouldn't come as a surprise. Precise and detailed forecasts offer structure for thinking, giving the listener a framework upon which to build strategies or make concrete rebuttals. Moreover, there appears to be a psychology of belief that makes people more likely to listen to detailed predictions, offered with certainty and clarity, than to listen to general forecasts, or those offered with plenty of hedges and caveats -- even though the detailed predictions are almost always wrong. (This isn't helped by a media culture that favors the spectacular over the thoughtful, and the adamant over the hesitant.)\n\nIt's not hard to find pundits and self-described futurists who will gladly accept the visibility and attention that comes from making detailed, spectacular predictions, no matter the eventual accuracy. If confronted, they'll mumble something about timing or unpredictable events; such confrontations are vanishingly rare, however, especially for high-profile pundits. It doesn't matter how wrong you are if you get good ratings.\n\nEthical futurists have a bit more of a dilemma here, however. A forecast needs to be vivid and engaging enough to trigger action, yet general and cautious enough to engender restraint. Or, as I put it in one interview, should be wrong in useful ways.\n\nThe simplest approach is to keep forecasts as general as possible, using detail only when well-supported by evidence. With this method, the emphasis is on the present-day and near-term drivers that lead towards the (more general) future. There is a temptation to over-emphasize the visible, and not leave enough space for wild cards and \"black swans,\" however. The core quandary remains knowing how general and cautious one can be while still offering useful insights, and how specific and detailed one can be while still not leading the audience astray.\n\nAnother fairly straightforward method is to use a more detailed forecast, but emphasize the uncertainty from the outset, being clear to the audience that the real outcomes will vary. The given forecast should be considered an example, not a certainty, a possible future that fits within a broader framework. Audiences don't always respond well to that approach, however; in some cases, they'll still take the example future to be the \"real prediction,\" and in others can interpret an emphasis on caution to mean that the futurist really doesn't know what she or he is talking about.\n\nMy preferred approach is to use scenarios, essentially giving multiple examples within the general framework. This illustrates the shape of the broader framework better, and makes clear that no one specific forecast is the \"real prediction.\" Yet the problems with this approach are manifold: coming up with three to five internally consistent forecasts is significantly harder than just coming up with one; audiences will gravitate towards preferred scenarios, sometimes ignoring those that don't turn out in ways they like; and it's difficult to encapsulate multiple scenarios into a short presentation or statement without rendering them meaningless.\n\nThis last problem is one that I've encountered quite a bit recently. There seems to be a trend in conferences right now (especially in Europe) to limit presentations to 15 minutes. Although there are definite benefits to this approach (most notably in maintaining audience interest), it means that any foresight-based presentation is crippled. A speaker simply doesn't have the time to offer multiple scenarios in anything other than a bullet point/headline format, surrounded by lots of big idea framing to give the scenario headlines some context (the talk I gave at the Guardian Activate Summit in London last year is probably my best effort at doing this).\n\nUnfortunately, audiences don't respond as well to multiple scenarios as they do to single, detailed forecasts, even when they know the detailed forecasts will inevitably be wrong. Moreover, appearances limited by time (such as, in particular, television) make even the headline scenario approach difficult. The best one can do -- in my experience, at least, and I'd love to hear better suggestions -- is to be sure to offer caveats and use cautious language such as \"appears to,\" \"likely,\" and especially \"one possibility\" (or similar statements underlining that different outcomes are possible).\n\nThe modern spectacle-driven media loathes uncertainty, and will almost always give more attention to aggressive certitude (no matter the accuracy) than caution. Many business audiences feel the same way. Sadly, the foresight paradox boils down to this:\n\nThe futurists who get the most attention are usually the least accurate.\n\nAbout ten years ago, I found myself sitting on the floor of my San Francisco Bay Area apartment, hoping that the call I was on wasn’t going to drop yet again. At the other end of the line was a Seattle public radio station, hosting a live debate/conversation between me and computer scientist Bill Joy on the question of whether our technologies were going to kill us; at that point, my main concern was whether our technologies would even work. Joy had recently published his infamous “Why the Future Doesn’t Need Us” essay in Wired, and was still charged with the fiery nihilism of his argument that we are less than a generation away from nano-, bio-, and information technologies that would fundamentally transform — in a bad way — human society and the human species. Joy was convinced that these emerging technologies would cause our extinction, and that the only hope for humanity was to give up entirely on these innovations.\n\nJoy was suffering from the same repeated disconnection problem I was wrestling with, but didn’t seem to appreciate the irony of the situation: here he was arguing that all-powerful technologies on the near horizon would inevitably destroy us, even while a ubiquitous and more-than-a-century-old technology remained stubbornly unreliable.\n\nIt’s a theme that would recur in countless arguments and debates I’d find myself in over the years. Usually, my sparring partner would claim (like Joy) that transformative technologies were about to sweep away human civilization, eliminating our humanity if they don’t destroy us completely. The only weak hope we might have would be to get rid of them — call this the Rejectionist perspective. Occasionally, however, the claim would be that transformative technologies were about to sweep away human civilization and replace it (and eventually us) with something better. This future was being driven by forces beyond our understanding, let alone control — call this one the Posthumanist argument. Each claim is a funhouse mirror of the other: We are on the verge of disaster or on the verge of transcendence, and the only way to hold on to our humanity in either case would be to disavow what we have made.\n\nAnd they’re both wrong. More importantly, they’re both dangerous.\n\nOur technologies are not going to rob us (or relieve us) of our humanity. Our technologies are part of what makes us human, and are the clear expression of our uniquely human minds. They both manifest and enable human culture; we co-evolve with them, and have done so for hundreds of thousands of years. The technologies of the future will make us neither inhuman nor posthuman, no matter how much they change our sense of place and identity.\n\nThe Rejectionist and Posthumanist arguments are dangerous because they aren’t just dueling abstractions. They have increasing cultural weight, and are becoming more pervasive than ever. And while they superficially take opposite views on technology and change, they both lead to the same result: they tell us to give up.\n\nBy positing these changes as massive forces beyond our control, these arguments tell us that we have no say in the future of the world, that we may not even have the right to a say in the future of the world. We have no agency; we are hapless victims of techno-destiny. We have no responsibility for outcomes, have no influence on the ethical choices embodied by these tools. The only choice we might be given is whether or not to slam on the brakes and put a halt to technological development — and there’s no guarantee that the brakes will work. There’s no possible future other than loss of control or stagnation.\n\nToday, Rejectionists like writer Nicholas Carr and MIT social scientist Sherry Turkle argue passionately that a new wave of digital technologies is crippling our minds and breaking our social ties. Their solution is to (paraphrasing the words of William F. Buckley) “stand athwart history yelling Stop!” While their visions are less apocalyptic than Joy’s tirade, they’re more directly relevant for many people, and ultimately have the same ends.\n\nThe Posthumanist side is no less active. The godfather of the concept, technologist Ray Kurzweil, continues to churn out books and interviews telling us that the Singularity is near, a claim that seems to have special attraction for many tech-savvy young men. But like the Rejectionist perspective, Posthumanist arguments have mutated into new forms linked to current debates. Venture capitalist Peter Thiel (co-founder of PayPal and currently on the board of directors at Facebook), for example, insists that his investments in Singularity technologies will allow him to create a future devoid of politics — and arguing, infamously, that true freedom is incompatible with democracy.\n\nTechnology is part of who we are. What both critics and cheerleaders of technological evolution miss is something both subtle and important: our technologies will, as they always have, make us who we are—make us human. The definition of Human is no more fixed by our ancestors’ first use of tools, than it is by using a mouse to control a computer. What it means to be Human is flexible, and we change it every day by changing our technology. And it is this, more than the demands for abandonment or the invocations of a secular nirvana, that will give us enormous challenges in the years to come.\n\nI'm looking forward to it.\n\nAt the Institute for the Future's 2011 Ten Year Forecast event in late March, I presented a long talk on ways in which evolutionary and ecological metaphors could inform our understanding of systemic change. The head of the Ten Year Forecast team, IFTF Distinguished Fellow Kathi Vian, thought that the ideas it contained should get a wider viewing, and asked me to put the talk on my blog. Here it is. It's lightly edited, and only contains a fraction of the slides I used; let me know what you think.\n\nWe’ve now reached the part of the day where I’ve been asked to make your brains hurt. Don’t worry, there will be alcohol afterwards.\n\nThe first thing I’m going to do, of course, is talk about dinosaurs.\n\nEverybody knows about dinosaurs, right? Giant, lumbering lizards that were killed off by an asteroid just when the smarter, more nimble mammals were starting to take over anyway. And everyone knows what dinosaur means as a metaphor: big, stupid, and about to be wiped out. Nobody wants to be a dinosaur.\n\nWhat if I told you that all of that – all of it – was wrong?\n\nHere’s another dinosaur:\n\nIt turns out that most dinosaurs were actually pretty small and fast, and far more closely related to today’s birds than to lizards.\n\nSome dinosaurs we might envision as scaly monsters from the movies were likely actually feathered. It’s widely accepted, in fact, that dinosaurs didn’t all die off when that asteroid struck 65.5 million years ago — they stuck around as birds.\n\nOh, and one other thing.\n\nThe “age of dinosaurs” lasted 185 million years, not counting the 65 million years of dino-birds. And mammals first emerged about halfway through the “age of dinosaurs,” and were stuck scurrying around between dinosaur legs, trying to avoid being eaten.\n\nDinosaurs have been around, including as birds, for 250 million years. Humans, conversely, have been around in a form recognizable as Homo sapiens for only about 250 thousand years. Dinosaurs have had a thousand times more history than has Homo sapiens.\n\nAnd they survived – arguably eventually thrived after – one of the biggest mass extinctions in Earth’s history. Maybe being a dinosaur wouldn’t be such a bad thing.\n\nThe story of dinosaurs is a particularly vivid example of what happens after complex systems face traumatic shocks. It’s a story of change and adaptation. And it’s one that we can learn from.\n\nThis will come as a surprise to precisely none of you, but one of the areas that I studied academically was evolutionary biology. Although I didn’t follow that path professionally, I’ve always kept my eyes open for ways in which bioscience can illuminate dilemmas we face in other areas.\n\nThere’s one concept from biology that I’ve been mulling for awhile, and I think it has quite a bit to say about our current global situation.\n\nIt’s an element of the concept of “ecological succession,” the term for how ecosystems respond to disruptive change. A fundamental part of that process is the “r/K selection model,” with a little r and a big K, which is a way of thinking about the reproductive strategy that living species employ within a changing environment.\n\nBiologist E.O. Wilson came up with this concept over 30 years ago, and it’s proven to be a useful lens through which to understand ecosystems.\n\nSpecies that use the “r” strategy tend to have lots of offspring, but devote little time or energy to their care. Even though most will die, the ones that survive will have a bunch of offspring of their own, hopefully carrying the same advantages that let their progenitors survive. Because these species are optimized to reproduce and spread quickly, we humans often think of them as weeds, “vermin,” and other pests.\n\nSpecies that use the “K” strategy tend to have very few offspring, and devote quite a bit of time and energy to their care. Survival rates for the progeny are much higher, but the loss of an offspring is correspondingly more devastating. K species are optimized to compete for established resources, and tend to be larger and longer-lived than r species. Humans are on the K side of the spectrum, which might be why we often tend to sympathize with other K species.\n\nAs I said, Ecological Succession is what happens when an ecosystem has been hit with a major disturbance. When various species come to re-inhabit the area, it follows a pretty standard pattern.\n\nWhile conditions are still unstable, r species dominate. Although they may not be ideally suited for the changing environment, they reproduce quickly. r strategies promote rapid iteration, diversification, and a willingness to sacrifice unsuccessful offspring.\n\nAs an ecosystem returns to stability, K species start to take over. Sometimes they’ll evolve from r species, sometimes they’ll come in from other locations. Species that employ K strategies evolve to fit their environmental niche as optimally as possible, seeking out the last bit of advantage over ecological competitors.\n\nThis is the typical pattern, then: disruption, r dominance, increased stability, K dominance.\n\nBut in periods when the volatility itself is sporadic, things get weird. Think of it as “unstable instability:” disruptions happen unpredictably, with long enough periods of stasis for the normal ecological succession pattern to start to take hold – then wham! A spike of instability. But this doesn’t eliminate the K strategists; they can reemerge once stability returns.\n\nIn this kind of environment, K approaches and r approaches trade off, neither gaining dominance. This is the kind of setting that accelerates change. Arguably, extended periods of unstable instability have been engines of radical evolution. They appear at numerous points in our planet’s history, and nearly always have a major impact.\n\nIn this kind of setting, imagine the impact of a species able to shift rapidly between r and K, optimizing when possible, rapidly iterating when necessary. Such as, to pick a random example, Homo sapiens, us. We’ve been able to adapt to changing environmental conditions through technological innovation, using rapid iteration of tools to enable biological stability\n\nThe appropriate question, now, is “so what?”\n\nThe language we employ when we do foresight work is often intensely metaphorical. We focus on events yet to fully unfold, new processes overshadowed by legacies, and weak signals amidst the noise of the now. And because of this, we often find ourselves reaching for familiar concepts that parallel the story we’re trying to tell.\n\nAs I suggested earlier, the r/K selection and ecological succession models offer us some insights into what’s happening the broader global political economy.\n\nHuman enterprises, whether business or government, civil or military, aren’t precisely biological species, but you can see numerous historical parallels to the ecological succession logic. The traumatic chaos of World War Two, with its vicious, rapidly-evolving competition between myriad nations, becomes the long stability of the Cold War era, dominated by two superpowers. Or, less bloody, think of the rapid churn of Silicon Valley startups trying to take advantage of a new innovation, and eventually settling into a small number of dominant players.\n\nTime and again, disruptive events lead to periods of experimentation and diversity, which over time crystallize into more stable institutions. But if that was the extent of the metaphor, it might be of passing interest, and not of much value.\n\nIt’s the periods of unstable instability, where r and K make strange bedfellows, that pulls us in.\n\nA useful example is the era of the late 1800s to early 1900s. There was instability, to be sure, but it was matched by periods of recovery and growth – but none of it proved able to last.\n\nAnd alongside these economic and political convulsions came an enormously fruitful era of technological and social innovation. Much of the technology that so dominates our day-to-day lives that we even sometimes stop thinking of it as technology – airplanes, automobiles, air conditioning, electricity to the home, the incandescent light bulb, and so on – emerged in the period between 1880 and 1920.\n\nSo, too, did social transformations like the labor movement, the progressive model of governance, and, in the US, women’s suffrage.\n\nI believe that there’s a good case to be made that we’re now in a similar era of unstable instability. Disruptions, when they hit, are intense, but there’s an equally powerful drive to stabilize. Innovations arise across a spectrum of technologies, but quickly become old news. There are major conflicts over social change. Both recoveries and chaos have strong regional and sectoral dimensions, and can flare up and die off seemingly without notice.\n\nIt would be dangerous to rely on strategies – reproductive or otherwise – that assume the continuation of either stability or instability. This period of unstable instability has been with us for at least the last decade, and will very likely continue for at least another decade more.\n\nAnd this suggests that neither relying upon scale and incumbency nor relying upon rapid-fire iteration will succeed as fully and as dependably as we might wish. We can’t depend on either the garage hacker or the global corporation to push us to a new phase of history. It’s going to have to be something that manages to combine elements of both flexible experimentation and long-term strategy. Something that puts r in service of K.\n\nThis doesn’t mean that r is less important than K; we could just as easily call it “K enabling r.” Either way, it comes down to strategies that take advantage of scale and diversity, that allow both long-shot experimentation and quick adoption of innovation. Decentralized, but collaborative.\n\nStrategies, in other words, that are resilient.\n\nResilience is a concept we think about quite a bit at IFTF, and if you’ve been involved in engagements with us over the past couple of years, you have probably heard us talk about it. It’s the ability of a system to withstand shocks and to rebuild and thrive afterwards. We believe that it will be a fundamental characteristic of success in the present decade, and Kathi will talk more about it tomorrow.\n\nBut from the ecological perspective, resilience interweaves r and K, containing elements that we might consider to be “r” in nature , as well as elements we’d consider to be “K.”\n\nResilience is the goal. r in service of K is the path.\n\nNow, I said a moment ago that this “unstable instability” is likely to last for at least another decade. I’m sure we could all spend the next hour coming up with reasons why that might be so, but one that I want to focus on for a bit is climate disruption. In many respects, climate disruption is the ultimate unstable instability system.\n\nClimate disruption is something that comes up in nearly all of our gatherings these days, and I don’t think I need to reiterate to this audience the challenges to health, prosperity, and peace that it creates.\n\nWe’ve spent quite a bit of time over the last few Ten Year Forecasts looking at different ways we might mitigate or stall global warming. Last year, we talked about carbon economies; the year before that, social innovation through “superstructures.” In 2008, geoengineering. This year, I want to take yet another approach. I want to talk about climate adaptation.\n\nI say that with some trepidation. Adaptation is a concept that many climate change specialists have been hesitant to talk about, because it seems to imply that we can or will do nothing to prevent worsening climate disruption, and instead should just get ready for it. But the fact of the matter is that our global efforts at mitigation have been far too slow and too hesitant to have a near-term impact, and we will see more substantial climate disruptions in the years to come no matter how hard we try to reduce carbon emissions. This doesn’t mean we should stop trying to cut carbon; what it does mean is that cutting carbon won’t be enough.\n\nBut adaptation won’t be easy. It’s going to require us to make both large and small changes to our economy and society in order to endure climate disruption more readily. That said, simply running down a checklist of possible adaptation methods wouldn’t really illuminate just how big of a deal adaptation would be. We decided instead that it would be more useful to think through a systematic framework for adaptation.\n\nOur first cut was to think about adaptations in terms of whether they simplify systems – reducing dependencies and thereby hopefully reducing system “brittleness” – or make systems more complex, introducing new dependencies but hopefully increasing system capacity.\n\nSimplified systems, on the whole, tend to be fairly local in scale. But reducing dependencies can also reduce influence. Simplification asks us to sacrifice some measure of capability in order to gain a greater degree of robustness. It’s a popular strategy for dealing with climate disruption and energy uncertainty; the environmental mantra of “reduce, reuse, recycle” is a celebration of adaptive simplification.\n\nAdaption through complexity creates or alters interconnected systems to better fit a changing environment. This usually requires operating at a regional or global scale, in order to take advantage of diverse material and intellectual resources. Complex systems may have increased dependencies, and therefore increased vulnerabilities, but they will be able to do things that simpler systems cannot.\n\nSo that’s the first pass: when we think about adaptation, are we thinking about changes that make our systems simpler, or more complex?\n\nBut here’s the twist: the effectiveness of these adaptive changes and the forms that they take will really depend upon the broader conditions under which they’re applied. We have to understand the context.\n\nAt last year’s Ten-Year Forecast, we introduced a tool for examining how choices vary under different conditions. It’s the “alternate scenario archetype” approach, and it offers us a framework here for teasing apart the implications of different adaptive strategies. If you were here last year, you’ll recall that the four archetypes are Growth, Constraint, Collapse, and Transformation. These four archetypes give us a basic framework to understand the different paths the future might take.\n\nBut let’s also apply the ecosystem thinking I was talking about earlier. With this in mind, we can see Growth and Collapse as aspects of the standard ecological succession model: Growth supports K strategy dominance, until we get a major disruption leading to Collapse, which supports r strategy dominance until we return to Growth. As it happens, while they may not use this exact language, many of the long-term cycle theories in economist-land map to this model.\n\nConstraint and Transformation, however, seem more like unstable instability scenarios.\n\nBoth Constraint and Transformation have quite a bit in common. Both can be seen as being on the precipice of either growth or collapse, and needing just the right push to head down one path or the other. At the same time, both will contain pockets of growth and collapse, side by side, emerging and disappearing quickly. In both, previously well-understood processes no longer seem to work as well, yet there’s enough that remains functional and understandable that the world doesn’t simply spin apart. For both, the underlying systems are in flux.\n\nWith Constraint, the result is a reduced set of options. The uncertainty and churn limit what you can do.\n\nWith Transformation, the result is the emergence of new models and new opportunities.\n\nSo we have two adaptive strategies – simplify and complexify – and two conditions of “unstable instability” – constraint and transformation. What do you do when you have two variables? You make a matrix!\n\nAh, the good old two-by-two matrix. So let’s put up the conditions, and the strategies. What happens when we combine them?\n\nIn many ways, Constraint and Simplification go hand-in-hand, giving us a world of doing more with less. Smaller scale, fewer resources, and a need for cheap experimentation: this is very much an “r” world.\n\nSimilarly, Transformation and Complexification are also common partners, resulting in a world focused on big ideas and long-term results. The potential is here for major changes, but failures can be catastrophic: it’s a classic “K” world.\n\nThe less-common combinations, however, prove pretty interesting.\n\nWhen you link Constraint and Complexification , you get a world of deep interconnection: lots of small components in dense networks. There’s quite a bit of interdependence, but no one element is a potential “single point of failure.” This is an “r in service of K” world.\n\nAnd when Transformation and Simplification come together , you get a world of fast iteration and slow strategy: numerous projects and experiments functioning independently, with loose connections but a long-range perspective. This, too, is an “r in service of K” world.\n\nOkay.\n\nRemember, I said earlier that foresight relies on intensely metaphorical language. You might not have expected the metaphors to be quite that intense, however. So here’s the takeaway:\n\nAdaptation can take multiple forms, but more importantly, the value of an adaptation depends upon the conditions in which it is tried. Just because an adaptive process worked in the past doesn’t mean that it will be just as effective next time. But there are larger patterns at work, too. If you can see them early enough, you can shape your adaptive strategies in ways that take advantage of conditions, rather than struggle against them.\n\nBut here’s the crucial element: it looks very likely that we’re in a period where the large patterns we’ve seen before aren’t working right.\n\nInstead, we’re in an environment that will force swift and sometimes frightening evolution. Businesses, communities, social institutions of all kinds, will find themselves facing a need to simultaneously experiment rapidly and keep hold of a longer-term perspective. You simply can’t expect that the world to which you’ve become adapted will look in any way the same – economically, environmentally, politically – in another decade.\n\nAs a result, you simply can’t expect that you will look in any way the same, either.\n\nThe asteroid strikes. The era of evolution is upon us. It’s now time to watch the dinosaurs take flight.\n\nWarren Ellis did me the great honor of asking me to write a piece for his website, on whatever topic was on my mind. This is what resulted. You can see the posting at Warren's place here; I've reproduced it below for my archives.\n\nTechnology will save us. Technology will destroy us.\n\nThe Future will save us. The Future will destroy us.\n\nThe tension between the myriad ways our tools — our technologies — affect us is often at the core of futurological discussions. Do they weaken us, destroying our memories (as Socrates argued) or our ability to think deeply (as Nicholas Carr argues), or do they enhance us? Do our technologies rob us of our humanity, or are they what make us human? While I tend to bias towards the latter view, it's not without recognition that our tools (and how we use them) can damage our planet and our civilization. But for a surprisingly large number of people, such discussions of technology aren't just part of futurism, they are futurism. From this perspective, the question of whether our technologies will destroy us is essentially the same as asking if our futures will destroy us.\n\nThis deep fear that what we have built will both give us heretofore unimagined power and ultimately lay us to waste has been with us for centuries, from the story of Icarus to the story of Frankenstein to the story of the Singularity. But because of its mythical roots, few foresight professionals give this fear sufficient credence. Not in the particulars of each story (I don't think we have much cause to worry about the risks associated with wax-and-feather personal flight), but in the recognition that for many people, a desire to embrace \"the future\" is entangled with a real, visceral fear of what the future holds for us.\n\nIn religious study, an explanation of how an all-powerful deity that claims to love us can allow evil is known as a \"theodicy.\" The term was coined in 1710 by Gottfried Liebniz -- a German natural philosopher who, among his many inventions and ideas, came up with calculus (independently of Newton, who is usually credited) and the binary number system. A theodicy is not merely a \"mysterious ways\" or \"free will\" defense, it's an attempt to craft a consistent plausible justification for evil in a universe created by an intrinsically good deity. Theodicies are inherently controversial; some philosophers claim that without full knowledge of good, no theodicy can be sufficient. Nonetheless, theodicies have allowed believers to think through and discuss in relatively sophisticated ways the existence of evil.\n\nThe practice of foresight needs within its philosophical underpinnings a similar discourse that treats the fear of dangerous outcomes as a real and meaningful concern, one that can neither be waved away as pessimism nor treated as the sole truth — a \"neodicy,\" if you will. Neodicies would grapple with the very real question of how we can justifiably believe in better futures while still acknowledging the risks that will inevitably arise as our futures unfold. Such a discourse may even allow the rehabilitation of the concept of progress, the idea that as a civilization we do learn from our mistakes, and have the capacity to make our futures better than our past.\n\nFor those outside the practice of futurism, neodicies could be sources of comfort, allowing a measure of grace and calm within a dynamic and turbulent environment; neodicies give future dangers meaningful context. For futurists, the construction of neodicies would demand that we base our forecasts in more than just passing trends and a desire to catch the Next Big Thing; neodicies require complexity. For all of us, neodicies would force an abandonment of both optimism- and (more often) pessimism-dominated filters. Neodicies would reveal the risks inherent to a Panglossian future, and the beauty and hope contained within an apocaphile's lament.\n\nWhat I'm seeking here is ultimately an articulation of futurology (futurism, foresight, etc.) as a philosophical approach, not simply a tool for business or political strategy. I want those of us in the discipline to think more about the \"why\" of the futures we anticipate than about the \"what.\" Arguing neodicies would allow us to construct sophisticated, complex paradigms of how futures emerge, and what they mean (I'd call them \"futurosophies,\" but I'm on a strict one-neologism-at-a-time diet). Different paradigms need not agree with each other; in fact, it's probably better if they don't, encouraging greater intellectual ferment, competition and evolution. And while these paradigms would be abstractions, they could still have practical value: when applied to particular time frames, technologies, or regions, these paradigms could offer distinct perspectives on issues such as why some outcomes are more likely than others, why risks and innovation coevolve, and how tomorrow can be simultaneously within our grasp and out of control.\n\nBut the real value of a neodicy is not in the utility it provides, but the understanding. For too many of us, \"the future\" is a bizarre and overwhelming concept, where danger looms large amidst a shimmering assortment of gadgets and temptations. We imagine that, at best, the shiny toys will give us solace while the dangers unfold, and thoughts of the enormous consequences about to fall upon us are themselves buried beneath the desire for immediate (personal, economic, political) gratification. Under such conditions, it's easy to lose both caution and hope.\n\nA world where futurology embraces the concept of neodicy won't make those conditions go away, but it would give us a means of pushing back. Neodicies could provide the necessary support for caution and hope, together. Theodicy is often defined simply as an explanation of why the existence of evil in the world doesn't rule out a just and omnipotent God; we can define neodicy, then, as an explanation of why a future that contains dangers and terrible risks can still be worth building — and worth fighting for.\n\nYou might remember the story of old John Henry. He built rail lines, and could work harder and faster than any man alive. When the company brought in a steam-driven rail driving machine, though, they announced that they were going to fire all of the human rail workers. John Henry stepped up and challenged that machine.\n\nChallenged it, and beat it.\n\nAnd then dropped over dead.\n\nKeep that in mind as you read this.\n\nRoy Blount, Jr., the president of the Authors' Guild, wrote an editorial in the New York Times on February 25th, arguing that the text-to-speech feature of Amazon's new Kindle 2 electronic book reading device actually violates the intellectual property rights of the authors he represents, as it provides the functional equivalent of an audiobook, without paying for audiobook rights.\n\nThe crux of Blount's argument is that it's critical to set a precedent now, because the text-to-speech is an audio performance of the book, and even if the digital vocalization is now lousy, it won't always be.\n\nNot surprisingly, authors who have more willingly entered the 21st century, such as Cory Doctorow, John Scalzi, Neil Gaiman, and Wil Wheaton, have attacked Blount's argument with gusto. Wil even provides an amusing side-by-side audio comparison (MP3) of himself and the Mac's \"Alex\" voice reading a section of his new book Sunken Treasure.\n\nFor Scalzi, Gaiman, and Wheaton, the crux of the argument is that Blount's concerns are worse than silly, because nobody would mistake the text-to-speech for real voice acting. (Doctorow, as is his practice, focuses on the legal aspect of Blount's argument, finding it more than wanting.)\n\nMy take on this? They're all wrong (well, probably not Cory)... and they're all right, too. That is, Blount is right about the technology, but wrong in his conclusions, while Scalzi/Gaiman/Wheaton/et al are wrong about the problem, but right about the proper response. The reason that Blount's wrong is that he's just trying to hold back the tide, fighting a battle that was lost long ago. The reason that the 21st century digital writers are wrong is that they've forgotten the Space Invaders rule: Aim at where your target will be, not at where it is.\n\nText-to-speech is laughably bad now for reading books aloud.\n\nText-to-speech could very well be the primary way people consume audiobooks within a decade.\n\nAt present, text-to-speech systems that go from ASCII to audio follow a few pronunciation conventions, but otherwise have no way of interpreting what is read for proper emphasis. For the kinds of uses that current text-to-speech systems typically see, that's good enough. For reading books, especially fiction, that's not.\n\nBut it's not hard to imagine what would be needed to make text-to-speech good enough for books, too. In order to give the right vocalization to the words it's reading, an \"AutoAudio Book\" would have to have one of three characteristics:\n\nIt could have been told in detail how to emphasize certain words and phrases, probably through some kind of XML-based markup standard. Call it DRML, or Dramatic Reading Markup Language. Given the existence of other kinds of voice control systems (such as speech synthesis markup language and pronunciation lexicon specification), such a standard isn't hard to imagine. It would take some pre-processing of the text files, though, to really make it work.\n\nAt the other end of the spectrum, it could actually understand what it's reading, and be able to provide emphasis based on what is going on in the story (basically, what you or I would do).\n\nSomewhere in the middle would be a system that had a number of standard emphasis heuristics, and is able to take a raw text file and, after a little just-in-time processing, offer an audio version that would by no means be as good as a real voice actor, but would, for most people, be good enough.\n\nThe DRML version is possible now -- hell, I had DOS apps back in the 1990s that would let me add markers to a text file to tell primitive text-to-speech software how to read it. The \"understand what it's reading\" version, conversely, remains some time off; frankly, that's pretty close to a real AI, and if those are available for something as prosaic as an ebook reader, we have bigger disruptions to worry about.\n\nBut the \"emphasis heuristics\" scenario strikes me as just on the edge of possible. There would have to be some level of demand -- such as would arguably be demonstrated by the success of the Kindle 2 and its offspring. More importantly, it would require a dedicated effort to create the necessary heuristics; amusingly, Blount's editorial has probably done more than anything else to make irritated geeks want to figure out how to do just that. It would probably also need a more powerful processor in the ebook reader; that's the kind of incentive that might make Intel want to underwrite the aforementioned irritated geeks.\n\nOne can easily imagine a scenario in which we see a kind of \"wiki-emphasis\" editing, allowing tech-attuned readers, upon encountering a poorly-read section of an AutoAudio Book, to update it and upload the bugfix, thereby improving the heuristics. (Of course, that would undoubtedly result in orthographic edit-wars and dialect forking. But I digress.)\n\nUltimately, Blount's fears that a super text-to-speech system could undermine the market for professional audiobooks really have more to do with economic choices than technical ones. The requisite technologies are either here but expensive or just on the horizon, and the combination of technological pathways and legal precedent (as Doctorow describes) make the scenario of good-enough book reading systems all but certain. But that doesn't guarantee that the market for audio books goes away. The history of online music is illustrative here, I think: when the music companies were ignorant or stubborn, music sharing proliferated; when music companies finally figured out that it was smart to sell the music online at a low price, music sharing dropped off considerably.\n\nThe more that the book industry tries to fight book-reading systems, the more likely it is that these systems (whether for Kindles, or iPhones, or Googlephones, or whatever) will start to crowd out commercial audiobooks. The more that the book industry sees this as an opportunity -- keeping audiobook prices low, for example, or maybe providing ebooks with DRML \"hinting\" for a dollar more than the plain ebook -- the more likely it is that book reading systems will be seen as a curiosity, not a competitor.\n\nNone of these scenarios may be very heartening for authors, unfortunately. Sorry about that.\n\nAt least you're not likely to keel over and die competing with an automated audiobook.\n\nAll distant problems are not created equally.\n\nBy definition, distant (long-term) problems are those that show their real impact at some point in the not-near future; arbitrarily, we can say five or more years, but many of them won't have significant effects for decades. Our habit, and the institutions we've built, tend to look at long-term problems as more-or-less identical: Something big will happen later. For the most part, we simply wait until the long-term becomes the near-term before we act.\n\nThis practice can be effective for some distant problems: Let's call them \"long-run problems.\" With a long-run problem, a solution can be applied any time between now and when the problem manifests; the \"solution window,\" if you will, is open up to the moment of the problem. While the costs will vary, it's possible for a solution applied at any time to work. It doesn't hurt to plan ahead, but taking action now instead of waiting until the problem looms closer isn't necessarily the best strategy. Sometimes, the environment changes enough that the problem is moot; sometimes, a new solution (costing much less) becomes available. By and large, long-run problems can be addressed with common-sense solutions.\n\nHere's a simple example of a long-run problem: You're driving a car in a straight line, and the map indicates a cliff in the distance. You can change direction now, or you can change direction as the cliff looms, and either way you avoid the cliff. If you know that there's a turn-off ahead, you may keep driving towards the cliff until you get to your preferred exit.\n\nThe practice of waiting until the long-term becomes the near-term is less effective, however, for the other kind of distant problem: Let's call them \"long-lag problems.\" With long-lag problems, there's a significant distance between cause and effect, for both the problem and any attempted solution. The available time to head-off the problem doesn't stretch from now until when the problem manifests; the \"solution window\" may be considerably briefer. Such problems can be harder to comprehend, since the connection between cause and effect may be subtle, or the lag time simply too enormous. Common-sense answers won't likely work.\n\nA simple, generic example of a long-lag problem is difficult to construct, since we don't tend to recognize them in our day-to-day lives. Events that may have been set in motion years ago can simply seem like accidents or coincidences, or even assigned a false proximate trigger in order for them to \"make sense.\"\n\nBut a real-world example of a long-lag problem should make the concept clear.\n\nGlobal warming is, for me, the canonical example of a long-lag problem, as geophysical systems don't operate on human cause-and-effect time frames. Because of atmospheric and ocean heat cycles (the \"thermal inertia\" I keep going on about), we're now facing the climate impacts of carbon pumped into the atmosphere decades ago. Similarly, if we were to stop emitting any greenhouse gases right this very second, we'd still see another two to three decades of warming, with all of the corresponding problems. If we're still three degrees below a climate disaster point, but have another two degrees of warming left because of thermal inertia regardless of what we do, we can't wait until we've increased to just below three degrees to act. If we do, we're hosed.\n\nWith long-lag problems, you simply can't wait until the problem is imminent before you act. You have to act long in advance in order to solve the problem. In other words, the solution window closes long before the problem hits.\n\nWe have a number of institutions, from government to religions to community organizations, with the potential to deal with long-run problems. We may not do well with them individually, but as a civilization, we've developed decent tools. However, we don't have many -- perhaps any -- institutions with the inherent potential to deal with long-lag problems. Moreover, too many people think all long-term problems are long-run problems.\n\n(This argument emerged from a mailing list discussion of the Copenhagen Consensus. Smart people, with lots of good ideas, but clearly convinced that we can address global warming as a long-run problem.)\n\nSadly, recognizing the difference between long-run and long-lag problems simply isn't a common (or common-sense) way of thinking about the world. We evolved to engage in near-term foresight (and I mean that literally; look at the work of University of Washington neuroscientist William Calvin for details), and (as noted) we have developed institutions to engage in long-run foresight. Long-lag is a hard problem because it combines the insight requirements of long-run foresight (e.g., being able to make a reasonable projection for long-range issues) with the limited-knowledge-action requirements of near-term foresight (e.g., being able to act decisively and effectively before all information about a problem has been settled). Both are already difficult tasks; in combination, they can seem overwhelming.\n\nA salient characteristic of long-lag problems is that they're often not amenable to brief, intense interactions as solutions. Dealing with such problems can take a long period, during which time it may be unclear whether the problem has been solved. Politically, this can be a dangerous time -- the investment of money, time and expertise has already happened, but nothing yet can be shown for it.\n\nAnother long-lag problem that shows this dilemma clearly is the risk of asteroid impact. It turns out that nuking the rock (as in Armageddon) doesn't work, but a small, steady force on the rock for a period of years, years ahead of the potential impact, does. Pushing the rock moves the point of impact slowly, and it may take a decade or more before we can be certain that the asteroid will now miss us. That's why the slim possibility of a 2036 impact of 99942 Apophis frightens many asteroid watchers: if we don't get a good read on the trajectory of the rock long before its near-approach in 2029, we simply won't have time to make a big enough change to its path to avoid disaster.\n\nBut tell people in power that we need to be worrying now about something that won't even potentially hurt us until 2036, and the best you'll get is a blank look.\n\nMy interest, at this point, is to try to identify other long-lag problems, and to see what kinds of general conditions separate long-run and long-lag problems. With both global warming and asteroid impacts, the lag comes from physics; with peak oil (and other resource collapse problems), conversely, the lag comes from the need for wholesale infrastructure replacement. What else is out there?\n\n(The Big Picture is my series on the major driving forces likely to shape the next 20 years. The first post, on Climate Change, went up in early February.)\n\nTruism #1: Human society's continued existence depends on the sustained flows of a variety of natural resources.\n\nTruism #2: What that set of natural resources comprises can change over time.\n\nWe (the human we) have pushed the limits of many of the resources our civilization has come to depend upon. Oil is the most talked-about example, but from topsoil to fisheries, water to wheat, many of the resources underpinning life and society as we know it face significant threat. In many cases, this threat comes from simple over-consumption; in others, it comes from ecosystem damage (often, but not always, made worse by over-consumption).\n\nThe most obvious cause of over-consumption is population. Long a contentious issue for environmentalists, the argument that \"we have too many people,\" logical in theory, faces serious ethical questions when turned to practice. One example: how do we decide who gets to continue living? Over-consumption is compounded by rising standards-of-living allowing more people to consume even more than before, and by a historically-rooted assumption that the Earth is big and can always provide.\n\nBut some resources simply have limits -- there's a maximum amount of oil to be extracted, or copper to be dug up. Some resources (topsoil, fisheries) can renew themselves, but at a rate far slower than our use. Unfortunately, what we've seen from other dwindling resources is that humans have a tendency to try to grab the last bits for themselves, even at the expense of others. This is the so-called \"tragedy of the commons,\" and its most visible present-day manifestation has to be ocean fisheries. Many seafood species are the on the verge of total collapse, perhaps even extinction; official efforts to limit or halt fishing of certain species face desperate communities dependent upon the industry.\n\nThe other driver for resource collapse, ecosystem damage, is somewhat more complex. In some cases, such as honeybees, we still have little certainty as to why the resource is in such danger. In the case of wheat, the risk comes from a combination of human and natural activity.\n\nIf you hadn't heard that wheat is threatened, you're not alone. It's a relatively recent problem: a fungus known as Ug99. Emerging in Uganda in 1999 (hence the name), this black stem rust fungus seemed to be slowly moving north into the Middle East, not yet hitting locations dependent upon wheat as a primary food crop; this slow movement seemed to offer biologists time to come up with effective counters and to breed resistant strains of wheat, a time-consuming process. But that luck didn't hold.\n\n...on 8 June 2007, Cyclone Gonu hit the Arabian peninsula, the worst storm there for 30 years.\n\n\"We know it changed the winds,\" says Wafa Khoury of the UN Food and Agriculture Organization in Rome, because desert locusts the FAO had been tracking in Yemen blew north towards Iran instead of north-west as expected [...]. \"We think it may have done that to the rust spores.\" This means, she says, that Ug99 has reached Iran a year or two earlier than predicted. The fear is that the same winds could have blown the spores into Pakistan, which is also north of Yemen, and where surveillance of the fungus is limited.\n\nIn Iran, the spore will encounter barberry bushes, which trigger explosive reproduction of Ug99 (and more potential for mutation). From Iran to Pakistan, and then to India (much more dependent upon wheat) and to China. From China, it can blow to North America (as dust and soot do already). The fungus ignores current strains of wheat with fungal resistance, because it initially faced monocultures of wheat with single markers for resistance, allowing for easy mutation and replication.\n\nI'm just glad the Norwegian seed vault is now up and operating. But as disturbing as the potential for collapse may be, the second truism listed above offers cause for hope.\n\nEcosystem services is the term to remember this time around. It's tempting to think of ourselves as dependent upon the resources we currently use, but that's not quite right. What we depend upon are the services the various resources provide -- the energy, for example, or the protein. In principle, if we can receive those service a different way, we may avoid the repercussions of the collapse of a particular resource. It's true that, in some cases (like water), the resources effectively are the services, but even here, we have to be careful not to think of a particular source (e.g., aquifers) as being the only possibility.\n\nBird poop provides an instructive example. In the 19th century, guano from birds native to Peru offered the world's best form of fertilizer -- so good that guano became the subject of imperial ambitions, national laws, and international tension. In \"When guano imperialists ruled the earth,\" Salon's Andrew Leonard quotes from President Millard Fillmore's 1850 state of the union address:\n\nPeruvian guano has become so desirable an article to the agricultural interest of the United States that it is the duty of the Government to employ all the means properly in its power for the purpose of causing that article to be imported into the country at a reasonable price.\n\nBut by the end of the century, the market for guano had collapsed, along with Peru's economy, because of the development of industrial \"superphosphate\" fertilizer. It's worth noting that, even if superphosphate hadn't been developed, Peru would have been in trouble -- the supplies of guano were just about depleted by the time the market collapsed. That's right: The world was facing \"Peak Guano,\" only to be saved by catalytic innovation.\n\nResource Collapse and... Climate Change\n\nI addressed this in The Big Picture: Climate Change, but as I noted a week or so ago, a recent article by NASA's James Hansen points to another point of intersection. In \"Implications of “peak oil” for atmospheric CO2 and climate\" (PDF), Hansen and colleague Pushker A. Kharecha argue that the effort to keep atmospheric carbon levels below 450ppm (widely considered the seriously bad news tipping point) may be greatly helped by limitations on the amount of available oil. With a reasonable phase-out of coal, active measures to reduce non-CO2 forcings (including methane and black soot), and draw-down of CO2 through reforestation, limiting CO2 to 450ppm can be readily accomplished due to limits on oil reserves. This doesn't require the most aggressive peak oil scenarios, either -- simply using the US Energy Information Administration's estimates of oil reserves is enough. Using more aggressive numbers, atmospheric CO2 peaks at 422ppm.\n\nWe may end up avoiding catastrophic climate disruption despite our own best efforts.\n\nResource Collapse and... Catalytic Innovation\n\nThe clearest connection between resource collapse and catalytic innovation is in the realm of substitution services. Nobody wants oil, for example, people want what can be done with oil. That can mean other forms of energy, such as electricity (for transportation), or it may mean other sources of hydrocarbons, such as thermal polymerization (for plastics), and so forth. The big concern: will the substitute technologies be ready by the time the resource is (effectively) gone?\n\nOften, the issue really isn't technology, but expense and willingness to change. Driving the cost of alternatives down to make them competitive with the depleting resource can be difficult; even more difficult can be getting people to accept a substitution service that isn't exactly like the old one (even if it's objectively \"better\"). Cultured meat would be far and away better than today's meat processing industry -- environmentally, ethically, health-wise -- but, even if the product looked, tasted and felt just like \"real\" meat, a substantial number of people would likely avoid it simply because it was weird.\n\nMore important may be questions of culture and \"ways of life.\" Substitutions rarely mean the same workforce providing one resource shifts seamlessly over to its replacement; more often, the substitute comes from an entirely different region, or may require different kinds or numbers of workers.\n\nIt also means a change in mindset or interpretations of the world around us. I've commented before about the imminent emergence of photovoltaic technologies allowing us to make nearly any surface a point of power generation. To an extent, this seems superficially obvious, but try taking a walk or drive with your mind's eye set on what would be different with a solar world. What rationale would we have, for example, for not giving any outside surface a photovoltaic layer? How would we design the material world differently? What would disappear -- and what would suddenly become ubiquitous?\n\nOr there may be larger issues of infrastructure delaying an otherwise \"easy\" transition. Take alternative power vehicles: in many ways, making the cars & trucks run on clean energy will be the easy part. Think of all of the gas stations that would have to change or go out of business; think of all of the jobs lost when old skills become less valuable; think of the thousands of car repair places needing to retrain and retool. If you take the scenario I posited in The Problem of Cars last year, imagine all of the elements of the present day that would have to change in order for it to become possible.\n\nResource Collapse and... Ubiquitous Transparency\n\nAs with the climate, the role of ubiquitous transparency is to keep a close eye on the flows of production and consumption that might otherwise be invisible (at least until it's too late).\n\nThe scientific benefits would likely be the proximate driver. Whether the ultimate users are regulatory officials or participating panopticoneers depends on the balance of top-down vs. bottom-up power. Ultimately, it won't just be the points of production being watched, it will be the points of consumption, as well.\n\nResource Collapse and... New Models of Development\n\nThis is both harsh and simple.\n\nIf the newly-developing nations persist in trying to follow a Western path of development, then the competition for dwindling resources will end up as a critical point of tension and, likely, warfare. The more powerful nations will scrape by, while the ones less-able to throw their weight around will suffer. The more that the newly developing nations emulate Western consumption, the more that they're likely to face famine, economic collapse, and millions of casualties.\n\nConversely, if the newly-developing nations take a leapfrog-alternatives path, with a strong emphasis on efficiency and experimentation, they could find themselves the eventual winners of the century. The leapfrog concept is straightforward -- the areas with less legacy infrastructure can adopt new systems and models faster -- and emerging catalytic technologies and economic models seem custom-made for new adopters. But this isn't without risk; the new systems and models are intrinsically unproven, and may not work as well as expected. Leapfrogging nations may find themselves facing famine, economic collapse, and mass deaths anyway, and probably compounded by the expenditure of resources needed by the leapfrog systems and the loss or weakening of the old systems.\n\nResource Collapse and... The Rise of the Post-Hegemonic World\n\nResource collapse isn't the cause of the rise of the post-hegemonic world, but it's an important driver. It weakens the powerful, and opens up new niches of influence. It triggers conflict, setting the mighty against the mighty. It reveals vulnerabilities.\n\nMost importantly, it sets up the conditions for the emergence of new models of power, as ultimately the most effective responses to resource collapse will come from revolutions in technology and socio-economic behavior. Those actors adopting the new successful models will find themselves disproportionately powerful.\n\nRight now, none of the leading great power nations seem well-suited to discover and adopt such new models. The same can be said of the leading global corporate powers. The climate and resource crises of the 2010s and 2020s will be compounded by a vacuum of global leadership.\n\nUltimately, I suspect that the identity of the pre-eminent global actors of the mid-21st century will surprise us all.\n\nI like Stewart Brand, and he and I seem to get along pretty well. I first met him at GBN a decade ago, and I run into him fairly often at a variety of SF-area futures-oriented events.\n\nBut I found myself grumpy and frustrated after reading \"An Early Environmentalist, Embracing New ‘Heresies’\" in Sunday's New York Times, a profile of Stewart and what he calls his \"environmental heresies.\"\n\nStewart Brand has become a heretic to environmentalism, a movement he helped found, but he doesn’t plan to be isolated for long. He expects that environmentalists will soon share his affection for nuclear power. They’ll lose their fear of population growth and start appreciating sprawling megacities. They’ll stop worrying about “frankenfoods” and embrace genetic engineering.\n\nBrand seems to retain an image of environmentalism that may have been appropriate in the 1970s, but has diminishing credibility today: the anti-technology, back-to-nature hippie. Today's environmental movement is urban, techie, and far less likely to refer to any assertion as \"heresy\" (although, in the case of the handful of people who still try to deny the existence of global warming, we're happy to use the term \"stupidity\"). Stewart Brand is nailing his environmental heresies on the door of a church that was long ago abandoned... or, at the very least, taken over by Unitarians.\n\nThis isn't to say that the Bright Green types have fully embraced Stewart's views. There's little support for aggressive nuclear power production among the new environmentalists, and the various positions concerning biotech are complex, to say the least. There's little disagreement with his love of cities, but in this case, Brand is almost a latecomer. Ultimately, the positions that Stewart stakes out appear more to be arguments against his own past beliefs than against the claims of modern eco-advocates.\n\nDavid Roberts, over at Gristmill, dissects the nuclear argument exceedingly well, and rather than reiterate what he wrote, I'll just point you to it. The short version, in my phrasing: the Bright Green reluctance about nuclear power has far more to do with it being centralized infrastructure and dated technology than with any fear or loathing of atoms. The environmental situation in which we find ourselves demands a fast-learning, fast-iterating, distributed and collaborative technological capacity, not a system that bleeds out investment dollars and leaves us stuck with technologies already on the verge of obsolescence.\n\nIf we're looking for resilience, flexibility and innovation, the nuclear industry is not a good place to start.\n\nWith regards to biotechnology, resilience, flexibility and innovation are definitely possible, at least in the years to come. Brand argues that genetic engineering has the potential to be a major tool for dealing with global warming's effects, and he's not the only one making claims of the sort. There's no consensus Bright Green position on environmental biotech, but there are plenty of voices calling for the responsible use of biotech (and nanotech) as a way of combatting climate and ecosystem disruption; moreover, most people arguing for holding off on bioengineering do so out of concern that we still have more to learn before we can undertake such solutions responsibly, not out of a flat opposition to the technology.\n\nStewart asks, \"where are the green biotech hackers?\" Rob Carlson -- one of the original open-source bio thinkers, now a leading expert in synthetic biology -- has an answer: they're here, but they're still working under the radar.\n\nWe're coming, Stewart. It's just that we're still on the slow part of the curves. [...] At the moment, synthesis of a long gene takes about four weeks at a commercial DNA foundry, with a bacterial genome still requiring many months at best, though the longest reported contiguous synthesis job to date is still less than 50 kilobases. And at a buck a base, hacking any kind of interesting new circuit is still expensive. [...] So, Mr. Brand, it will be a few years before green hackers, at least those who aren't support by Vinod Khosla or Kleiner Perkins, really start to have an impact.\n\nGreen biotech hacking is still in the punch-card era, and as Stewart himself could tell you, computer hacker culture really didn't take off until you got past punch-cards into time-sharing, where the cost in time and money was low enough that mistakes were something to learn from, not dread.\n\nAs for cities, I'm not sure I could find many modern enviros still clinging to the notion that, on the whole, rural life is intrinsically better than urban life. There are plenty of individual examples of terrific rural homes and awful urban homes, of course, but in the aggregate, there's no question that communities in dense, urban settings have a smaller footprint than communities of the same size in suburban and rural settings. And the notion that population size is still at the top of the environmental hit list is seriously out of date; all signs point to a global population peak of below 10 billion, and possibly no more than 8 billion -- of concern to the extent that more people means more consumption, but by no means a panic-inducing Malthusian threat.\n\nThe conventional meaning of \"heretic\" is one who goes against dogma, and the positions that Stewart takes here just don't meet that requirement. There's no doubt that it would be possible to find self-described environmentalists who fit the stereotype that Stewart is responding to, but one of the hallmarks of the modern environmental movement -- and the reason why the \"heresy\" model is arguably obsolete -- is that, when it comes to solutions, nothing is a priori off the table. All solution options can be considered, but they must be able to stand up to competing ideas. Even if some of us believe that some of the solutions he advocates don't stand up to the competition, we aren't going to try to claim that Stewart Brand somehow isn't an environmentalist. As long as he recognizes that the Earth's geophysical systems are under extraordinary duress, and that business-as-usual is driving us headlong into disaster, he's one of us -- even if the ways we want to avoid that disaster vary.\n\nThe \"Good Ancestor Principle\" is based on a challenge posed by Jonas Salk:\n\n...the most important question we must ask ourselves is, “Are we being good ancestors?” Given the rapidly changing discoveries and conditions of the times, this opens up a crucial conversation – just what will it take for our descendants to look back at our decisions today and judge us good ancestors?\n\nThe two-day Good Ancestor Principle workshop focused primarily upon teasing out just what it would mean to be a good ancestor, and a bit upon exploring various ways of making sure the Earth inherited by our descendants is better than the Earth we inherited. But a surprisingly large part of the conversation covered a question that is at once unexpected and entirely relevant: just who will our descendants be?\n\nThe baseline assumption, not unreasonably, was that our descendants will be people like us, individuals living deep within the \"human condition\" of pain, love, family, death, and so forth; as a result, the \"better ancestors\" question inevitably focuses upon the external world of politics, warfare, the global environment, poverty, and so forth (essentially, the WorldChanging arena). Some participants suggested a more radical vision, of populations with genetic enhancements including extreme longevity. Sadly, this part of the conversation never managed to get much past the tired \"how will the Enhanced abuse the Normals\" tropes, so we never really got to the \"...and how can we be good ancestors to them?\" question, other than to point out that we ourselves may be filling in the role of \"descendants\" if we end up living for centuries.\n\nInstead, we ran right past the \"human++\" scenario right into the Singularity -- and with Vernor Vinge in attendance, this is hardly surprising. (Not that Vinge is dead-certain that the Singularity is on its way; when he speaks next week at the Long Now seminar in San Francisco, he'll be covering what change looks like in a world where a Singularity doesn't happen.) This group of philosophers and writers really take the Singularity concept seriously, and not for Kurzweilian \"let's all get uploaded into Heaven 2.0\" reasons. Their recurring question had a strong evolutionary theme: what niche is left for humans if machines become ascendant?\n\nThe conversation about the Singularity touched on more than science fiction stories, because of the attendance of Ben Goertzel, a cognitive science/computer science specialist who runs a company called \"Novamente\" -- a company with the express goal of creating the first Artificial General Intelligence (AGI). He has a working theory of how to do it, some early prototypes (that for now exist solely in virtual environments), and a small number of employees in the US and Brazil. He says that with the right funding, his team would be able to produce a working AGI system within ten years. With his current funding, it might take a bit longer.\n\nAccording to Goertzel, the Singularity would happen fairly shortly after his AGI wakes up.\n\nIt was a surreal moment for me. I've been writing about the Singularity and related issues for years, and have spoken to a number of people who were working on related technologies or were major enthusiasts of the concept (the self-described \"Singularitarians\"). This was the first time I sat down with someone who was both. Goertzel is confident of his vision, and quite clear on the potential outcomes, many of which would be unpleasant for humankind. When I spoke to my wife mid-way through the first day, I semi-jokingly told her that I'd just met the man who was going to destroy the world.\n\nBen doesn't actually want that to happen, as far as I can tell, and has made a point of considering from the very beginning of his work the problem of giving super-intelligent machines a sense of ethics that would preclude them from wanting to make choices that would be harmful to humankind.\n\nIn 2002, he wrote:\n\n...I would like an AGI to consider human beings as having a great deal of value. I would prefer, for instance, if the Earth did not become densely populated with AGI’s that feel about humans as most humans feel about cows and sheep – let alone as most humans feel about ants or bacteria, or instances of Microsoft Word. To see the potential problem here, consider the possibility of a future AGI whose intelligence is as much greater than ours, as ours is greater than that of a sheep or an ant or even a bacterium. Why should it value us particularly? Perhaps it can create creatures of our measly intelligence and complexity level without hardly any effort at all. In that case, can we really expect it to value us significantly? This is not an easy question.\n\nBeyond my attachment to my own species, there are many general values that I hold, that I would like future AGI’s to hold. For example, I would like future AGI’s to place a significant value on:\n\nDiversity\n\nLife: relatively unintelligent life like trees and protozoa and bunnies, as well as intelligent life like humans and dolphins and other AGI’s.\n\nThe generation of new pattern (on “creation” and “creativity” broadly conceived)\n\nThe preservation of existing structures and systems\n\nThe happiness of other intelligent or living systems (“compassion”)\n\nThe happiness and continued existence of humans\n\n(From his essay \"Thoughts on AI Morality,\" in which he quotes both Ray Kurzweil and Jello Biafra.)\n\nThe issue of how to give AGIs a sense of empathy towards humans consumed a major part of the Good Ancestor Principle workshop discussion. The participants recognized quickly that what this technology meant was the creation of a parallel line of descendants of humankind. In essence, the answer to the question of \"how can we be better ancestors for our descendants\" is answered in part by \"making sure our other descendants are helpful, not harmful.\"\n\nUltimately, the notion of being good ancestors by reducing the chances that our descendants will be harmed appeared in nearly every attempt to answer Jonas Salk's challenge. It's a point that's both obvious and subtle. Of course we want to reduce the chances that our descendants will be harmed; the real challenge is figuring out just what we are doing today that runs counter to that desire. We don't always recognize the longer-term harm emerging from a short-term benefit. This goes back to an argument I've made time and again: the real problems we're facing in the 21st century are the long, slow threats. We need our solutions to have a long term consciousness, too.\n\nThat strikes me as an important value for any intelligent being to hold, organic or otherwise.\n\nThere's a story I've seen about a philosopher who bet an engineer that he could make a robot that the engineer couldn't destroy. What the philosopher produced was a tiny little thing, covered in fur, that would squeak when touched -- and when threatened, would roll onto its back and look at the attacker with its big, glistening eyes. When the engineer lifted his hammer to smash the robot, he found that he couldn't. He paid the wager *.\n\nEvolution has programmed us, for good reasons, to be responsive to \"cute\" creatures. Even the coldest heart melts at the sight of kittens playing or puppies sleeping, and while parents respond most quickly to their own children, we all have at least some positive response to sight of a child. Given all of this, it wouldn't be surprising if our biological imperatives could be hijacked by things that are decidedly not puppies and babies -- but approximated their look and behavior. Like, for example, a robot.\n\nSociologist Sherry Turkle has studied the effects of technology on society for years. Recently, she brought a collection of realistic robotic dolls called \"My Real Baby\" to nursing homes. Much to her surprise -- and dismay -- the seniors responded to these artificial dependents in ways that mirrored how they would interact with real living beings. They weren't fooled by the robots; they knew that these were devices. But the artificial beings' look and behavior elicited strong, generally positive, emotions for the elderly recipients. Turkle describes it thusly:\n\nIn bringing My Real Babies into nursing homes, it was not unusual for seniors to use the doll to re-enact scenes from their children’s youth or important moments in their relationships with spouses. Indeed, seniors were more comfortable playing out family scenes with robotic dolls than with traditional ones. Seniors felt social “permission” to be with the robots, presented as a highly valued and “grownup” activity. Additionally, the robots provided the elders something to talk about, a seed for a sense of community.\n\nTurkle is bothered by the emotions these dolls -- and similar \"therapeutic\" robots, such as the Japanese Paro seal -- trigger in the adults interacting with them. She argues:\n\nRelationships with computational creatures may be deeply compelling, perhaps educational, but they do not put us in touch with the complexity, contradiction, and limitations of the human life cycle. They do not teach us what we need to know about empathy, ambivalence, and life lived in shades of gray.\n\nTurkle is particularly concerned with the issue of the \"human life cycle.\" She worries about emotional bonds with beings that can't understand death, or themselves die. \"What can something that does not have a life cycle know about your death, or about your pain?\" she asks. She fears the disconnection with the reality of life when children and adults alike bond with machines that can't die. But this machine immortality may be a benefit, not a problem.\n\nMany, likely most, of the seniors who embraced the robotic children were seriously depressed. Aging is often painful, physically and emotionally, and life in a nursing home -- even a good one -- can seem like the demoralizing final stop on one's journey. Seniors aren't the only ones who are depressed, of course. According to a recent World Health Organization study published in the Public Library of Science (\"Projections of Global Mortality and Burden of Disease from 2002 to 2030\"), depressive disorders are currently the fourth most common \"burden of disease\" globally, ranking right behind HIV/AIDS; moreover, the research group projects that depressive disorders will become the second most common burden of disease by 2030, above even heart disease. Depression is debilitating, saps productivity and creativity, and is all too often fatal. Medical and social researchers are only now starting to see the immensity of the problem of depression.\n\nThe ability of the therapeutic robots to reduce the effects of depression, therefore, should not be ignored. The seniors themselves describe how interacting with the robots makes them feel less depressed, either because they can talk about problems with a completely trustable partner, or because the seniors see the robots as depressed as well, and seek to comfort and care for them. Concerns about whether or not the robots are really feeling depressed, or recognize (let alone care about) the human's feelings, appear to be secondary or non-existent. Of far greater importance are the benefits for helping someone in the depths of depression to recover a sense of purpose and self.\n\nIf you were to look for a My Real Baby doll today, you'd be hard-pressed to find one. They were a flop as commercial toys, with a common reaction (at least among adults) being that they were \"creepy.\" That kind of response -- \"it's creepy\" -- is a sign that the doll has fallen into the \"Uncanny Valley,\" the point along the realism curve where the object looks alive enough to trigger biologically-programmed responses, but not quite alive enough to pass for human -- and as a result, can be unsettling or even repulsive. First suggested by Japanese robotics researcher Masahiro Mori in 1970, the Uncanny Valley concept may help to explain why games, toys and animations with cartoony, exaggerated characters often are more successful than their \"realistic\" counterparts. Nobody would ever mistake a human character from World of Warcraft for a photograph, for example, but the human figures in EverQuest 2, conversely, look close enough to right to appear oddly wrong.\n\nAs work on robotics and interactive systems progresses, we'll find ourselves facing Creatures from the Uncanny Valley increasingly often. It's a subjective response, and the empathetic/creepy threshold seems to vary considerably from person to person. It's notable, and clearly worth more study, that the nursing home residents who received the My Real Baby dolls didn't have as strong of an \"Uncanny Valley\" response as the greater public seemed to have. Regardless, it's important to remember that the Uncanny Valley isn't a bottomless pit; eventually, as the realism is further improved, the sense of a robot being \"wrong\" fades, and what's left is a simulacrum that just seems like another person.\n\nThe notion of human-looking robots made for love has a long history, but -- perhaps unsurprisingly -- by far the dominant emphasis has been on erotic love. And while it's true that many emerging technologies get their first serious use in the world of sexual entertainment, it's by no means clear that there's a real market for realistic interactive sex dolls. The social norms around sex, and the biological and social need for bonding beyond physical play, may well relegate realistic sex dolls to the tasks of therapy and of assistance for those who, for whatever reason, are unable to ever find a partner.\n\nBut that doesn't mean we won't see love dolls. Instead of sex-bots driving the industry, emotional companions for the aged and depressed may end up being the leading edge of the field of personal robotics. These would not be care-givers in the robot nurse sense; instead, they'd serve as recipients of care provided by the human partner, as it is increasingly clear that the tasks of taking care of someone else can be a way out of the depths of depression. In this scenario, the robot's needs would be appropriate to the capabilities of the human, and the robot may in some cases serve as a health monitoring system, able to alert medical or emergency response personnel if needed. In an interesting counter-point to Turkle's fear of humans building bonds with objects that can not understand pain and death, these robots may well develop abundant, detailed knowledge of their partner's health conditions.\n\nTurkle is also concerned about the robot's inability to get sick and die, as she believes that it teaches inappropriate lessons to the young and removes any acknowledgment of either the cycle of life or the meaning of loss and death. Regardless of one's views on whether death gives life meaning, it's clear that the sick, the dying, and the deeply depressed are already well-acquainted with loss. The knowledge that this being isn't going to disappear from their lives forever is for them a benefit, not a flaw.\n\nWe're accustomed to thinking about computers and robots as forms of augmentation: technologies that allow us to do more than our un-augmented minds and bodies could otherwise accomplish. But in our wonder at enhanced mental feats and physical efforts, we may have missed out on another important form of augmentation these technologies might provide. Emotional support isn't as exciting or as awe-inspiring as the more commonplace tasks we assign to machines, but it's a role that could very well help people who are at the lowest point of their lives. Sherry Turkle is worried that emotional bonds with machines can diminish our sense of love and connection with other people; it may well be, however, that such bonds can help rebuild what has already been lost, making us more human, not less.\n\n-=-=-=-=-\n\n*(If anyone has the source of this story, I'd love a direct reference.)\n\nLots of nano-news over the past week or two -- and most of it good!\n\nClean Bill of Health: One of the big questions about nanomaterials arising in recent months concerns the toxicity of nanoparticles, particularly carbon nanotubes. Since carbon nanotubes have applications ranging from solar power to artificial muscles (see below), their almost-magical potential would be blunted by confirmation of nasty effects on living tissues. Rice University is one of the leading institutions studying the biological effects of nanomaterials, so it was welcome news that a Rice University group (working with the University of Texas) has found through in-vivo tests that single-wall carbon nanotubes have no immediate harmful effects, and that they are flushed from the bloodstream within 24 hours -- long enough to be useful for medical procedures, but not long enough to trigger potential longer-term effects.\n\nObviously these tests need to be replicated and built upon, but still -- good news!\n\nMuscles Made of Yarn: One potential application in the body of carbon nanotubes may be in artificial muscle fibers. University of Texas at Dallas researchers have come up with a way to use carbon nanotubes, would together like yarn, as electro-chemical actuators acting essentially like muscles. According to Technology Review:\n\nBy spinning carbon nanotubes into yarn a fraction of the width of a human hair, researchers have developed artificial muscles that exert 100 times the force, per area, of natural muscle. [...] The yarns are created by first growing densely packed nanotubes, each about 100 micrometers long. The carbon nanotubes are then gathered from a portion of this field and spun together into long, thin threads. The nanotube yarn can be just 2 percent of the width of a hair--not even visible--but upwards of a meter long.\n\nThere's still much work to do to make nanotube yarn a full replacement for muscles, but their potential is clear. Among the many issues surrounding powered prosthetic limbs and walking robots is the insufficiency of current artificial muscle/muscle replication technologies. At present, mechanical muscles are far weaker than biological muscles, gram-for-gram. If this line of research is successful, the situation may end up reversed.\n\nViva!: A biotech company with a comic-book name, StarPharma, has come up with a novel nano-material-based gel designed to block the activity of HIV and Herpes viruses. VivaGel™ is a \"vaginal microbicide,\" made to be self-applied by women. It contains dendrimers -- synthetic polymer molecules shaped like the branches of a tree -- structured to stick to the linking surfaces on the virus in question, effectively making it impossible for the viruses to attach to the binding points on their cellular targets. The viruses can't harm the cells (or the host) because their molecular latches are clogged.\n\nThis kind of physical attack on a pathogen is less apt to result in the kind of rapid evolutionary adaptation that is seen with traditional antibiotic and antiviral medicines. The virus has to be able to connect to the right spot on a cell to take it over, so there's a very limited assortment of molecular structures it can have on its binding sites -- evolving away from the dendrimer being able to clog the site means evolving away from the site being able to link to the target cell. Adaption remains possible, of course, but just much less likely.\n\nDendrimers are interesting molecules. Because of their branching structure, it's actually possible to design dendrimers that can target different viruses simultaneously. In principle, VivaGel™ could be an all-purpose viral STD blocker. StarPharma (not a wholly-owned operation of LexCorp) has begun safety trials with UC San Francisco.\n\nNano-War, Uh, What is it Nano-Good For? Moving away from nano-materials, fellow futurist Michael Anissimov spotted the publication of the academic work Military Nanotechnology, written by Dr. Jurgen Altmann. The book covers the application of nanomaterials as weapons, the use of nanoscale devices as sensors and the like, and the use of nanofabrication technologies to create novel systems. Altmann even looks at the policy implications of the use of human augmentation technologies for military purposes. The answers to how to respond to the development of these technologies won't come easily, but will be even harder to devise if we wait until the technologies are already available.\n\nUnfortunately, as Michael notes, the people who need to take these issues seriously are likely to dismiss this as way off in the future, if they even give it that much thought.\n\nUrgency Noted: That doesn't mean that nobody is paying attention. The National Materials Advisory Board has just released a congressionally-mandated review of US nanotechnology policy. Although it looks chiefly at policies around nano-materials and current research into nano-scale devices, it does take a few pages to consider some of the implications of nano-fabrication. My colleagues at the Center for Responsible Nanotechnology have studied the report in detail, and have offered their own take on its findings.\n\nThe Center for Responsible Nanotechnology (CRN) expects that the NMAB report will accelerate research toward the development of molecularly-precise manufacturing. However, without adequate understanding and preparation, exponential atom-by-atom construction of advanced products could have catastrophic results. Conclusions published in this report should create a new level of urgency in preparing for molecular manufacturing.\n\nMost of the risks arising from all forms of nanotechnology are familiar, at least on their face. What nano-scale engineering, particularly molecular manufacturing, does is to make those risks happen much more swiftly, more cheaply, more easily, and in greater abundance. It's not that we don't know how to deal with toxic particles or readily-obtained weapons; it's that we've never lived in a world in which the particles could result from such a wide variety of common products, and the weapons could be so hard to detect and yet so powerful. Some of the risks associated with molecular technologies are novel, to be sure, but the core lesson we need to learn has less to do with how to respond to individual threats than with how to grapple with an environment in which the threats arise orders of magnitude more quickly than ever before.\n\nIt's the classic dilemma of both foresight and environmental consulting: how do you get the people with the power to act to pay attention? Political leaders rarely pay sufficient attention to issues of systemic sustainability and planning for long-term processes, at least before events reach a crisis. There are numerous reasons why this might be, ranging from election cycles to crisis \"triage\" to politicians not wanting to institute programs for which they won't be around to take credit. It's nearly as difficult to get leaders to pay attention to complex systems, with superficially different but deeply-connected issue areas. If you were to try to bring together political, business and community leaders for a day-long discussion of, say, what life might be like at the midpoint of this century, with a focus on environmental sustainability coupled with economic, cultural and demographic demands, how much support do you think you'd get?\n\nIn Hawaii, over 500 leaders showed up on Saturday the 26th for just such an event, including numerous state legislators and former Hawaii governor George Ariyoshi. Legislative support for the Hawaii 2050 Sustainability project was so great, in fact, that funding for the project received a near-unanimous override of the current governor's veto. The meeting hall was filled to capacity, and the buzz of excitement from the participants grew throughout the day. They could tell: this was the start of something transformative.\n\nThe Hawaii 2050 Sustainability project is remarkably ambitious, seeking to create, over the course of the next 18 months, an entirely new planning strategy for the state's next half-century. This strategy will shape how the state handles a tourist economy, a swelling population, friction between cultures and, most importantly, an increasingly dangerous climate and environment.\n\nSaturday's event kicked off the process, mixing a variety of traditional presentations on Hawaii's major dilemmas with four immersive scenarios created by Dr. Jim Dator, Jake Dunagan and Stuart Candy at the University of Hawaii's Graduate Research Center for Future Studies. (Jake and Stuart, of course, invited me to Hawaii this last week to talk to some of the grad students and to attend the Hawaii 2050 event; I got a chance to meet and converse with Dr. Dator, as well.) The four scenarios represented a diverse array of possible futures for the state, and included a high-growth world, a limited-growth outcome, a collapse scenario, and a near-Singularity possibility. Participants"
    }
}