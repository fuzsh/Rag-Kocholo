{
    "id": "correct_subsidiary_00027_3",
    "rank": 61,
    "data": {
        "url": "https://thecuberesearch.com/231-breaking-analysis-how-nvidia-tsm-broadcom-and-qualcomm-will-lead-a-trillion-dollar-silicon-boom/",
        "read_more_link": "",
        "language": "en",
        "title": "How NVIDIA, TSM, Broadcom, and Qualcomm Will Lead a Trillion Dollar Silicon Boom - theCUBEResearch",
        "top_image": "https://thecuberesearch.com/wp-content/uploads/AI-Factory-DallE.webp",
        "meta_img": "https://thecuberesearch.com/wp-content/uploads/AI-Factory-DallE.webp",
        "images": [
            "https://thecuberesearch.com/wp-content/uploads/logo-theCUBEresearch-white2x.png",
            "https://thecuberesearch.com/wp-content/uploads/Breaking-Analysis_-How-NVIDIA-TSM-Broadcom-and-Qualcomm-Will-Lead-a-Trillion-Dollar-Silicon-Boom--1024x576.jpg",
            "https://thecuberesearch.com/wp-content/uploads/Breaking-Analysis_-How-NVIDIA-TSM-Broadcom-and-Qualcomm-Will-Lead-a-Trillion-Dollar-Silicon-Boom-1-1024x576.jpg",
            "https://thecuberesearch.com/wp-content/uploads/Breaking-Analysis_-How-NVIDIA-TSM-Broadcom-and-Qualcomm-Will-Lead-a-Trillion-Dollar-Silicon-Boom-3-1024x576.jpg",
            "https://thecuberesearch.com/wp-content/uploads/Breaking-Analysis_-How-NVIDIA-TSM-Broadcom-and-Qualcomm-Will-Lead-a-Trillion-Dollar-Silicon-Boom-4-1024x576.jpg",
            "https://thecuberesearch.com/wp-content/uploads/Breaking-Analysis_-How-NVIDIA-TSM-Broadcom-and-Qualcomm-Will-Lead-a-Trillion-Dollar-Silicon-Boom-5-1024x576.jpg",
            "https://thecuberesearch.com/wp-content/uploads/Breaking-Analysis_-How-NVIDIA-TSM-Broadcom-and-Qualcomm-Will-Lead-a-Trillion-Dollar-Silicon-Boom-6-1024x576.jpg",
            "https://thecuberesearch.com/wp-content/uploads/John-F.jpeg",
            "https://secure.gravatar.com/avatar/b709acbf7584a374ad6bf774a247d2c6?s=300&d=wp_user_avatar&r=g",
            "https://thecuberesearch.com/wp-content/uploads/CrowdStrike-Blue-Screen-of-Death-300x171.webp",
            "https://thecuberesearch.com/wp-content/uploads/pexels-googledeepmind-17485678-300x169.jpg",
            "https://thecuberesearch.com/wp-content/uploads/logo-theCUBEresearch-white2x.png"
        ],
        "movies": [
            "https://www.youtube.com/embed/zwBgaSsRB1g?start=99&feature=oembed"
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "David Vellante",
            "David Floyer",
            "www.facebook.com"
        ],
        "publish_date": "2024-05-25T20:08:21+00:00",
        "summary": "",
        "meta_description": "In this Breaking Analysis we analyze NVIDIA, TSMC, Broadcom, Qualcomm and other companies leading the Trillion Dollar Silicon Boom",
        "meta_lang": "en",
        "meta_favicon": "https://thecuberesearch.com/wp-content/uploads/mark-theCUBEresearch-32x32.png",
        "meta_site_name": "theCUBEResearch",
        "canonical_link": "https://thecuberesearch.com/231-breaking-analysis-how-nvidia-tsm-broadcom-and-qualcomm-will-lead-a-trillion-dollar-silicon-boom/",
        "text": "We believe the AI wave will bring profound changes, not only to the technology industry but to society as a whole. These changes will perhaps be as significant to the world as the agricultural and industrial revolutions, both of which had drastic economic consequences. While the exact progression and timing of these changes are unpredictable, one thing is clear, the AI wave will not be possible without advancements in – and a stable supply of – hardware and software generally; and silicon specifically. The complexity of semiconductor design and manufacturing combined with rapid innovation and the vulnerability of the supply chain, creates unique and challenging dynamics that in our view are reshaping leadership in the semiconductor industry. Our forecast shows that the combined revenues of: 1) Companies that supply manufacturing equipment, components and software to build fabrication facilities; 2) Chip manufacturers, and 3) Chip and AI software designers, will approach $1T this decade. Our research suggests that four companies, NVIDIA, TSM, Broadcom and Qualcomm will account for almost half of that trillion dollar opportunity.\n\nIn this Breaking Analysis, we bring in theCUBE Research analyst emeritus David Floyer to quantify and forecast the dynamic semiconductor ecosystem. We compare market shares from 2010 to those of 2023 and provide a five year outlook for more than a dozen of the top players in the industry. With a view of where we see the overall market headed, our assumptions for the market and the top players, which firms we see winning and losing and why; with a bit of survey data from ETR.\n\nWe’ll also address the following five items:\n\nHow sustainable is NVIDIA’s moat?\n\nWhat’s the impact of competition on NVIDIA, including form hyperscalers, Intel, AMD and others?\n\nThe challenges faced by two companies that both design and manufacture semiconductors – Intel and Samsung.\n\nWhat the opportunities at the edge mean for firms and competition.\n\nRisks to our scenarios including geopolitical, technological and energy risks.\n\nAI Capturing Budget Momentum\n\nLet’s start with the macro impact that the Gen AI awakening has had on IT spending in the last two years. The data below from ETR shows the 19 sectors the company tracks each quarter. The vertical axis is spending velocity or Net Score and the horizontal plane is the Pervasion, or penetration of the sector within the survey. We’ve shown this many times before but note where AI was one month prior to ChatGPT’s launch in the October 2022 survey. It dropped just below the 40% magic line that month and since then has been up and to the right. Consequently other sectors have been suppressed. As we’ve reported, 42% of customers indicate they’re funding AI by stealing from other budgets. And we know that generally enterprise AI ROI is coming in small productivity wins at this time and for most organizations is not yet self funding.\n\nThe point is that AI is consuming not only the conversation but also the spending momentum.\n\nWe believe there are three significant impacts for all organizations.\n\nThe first is across the board productivity gains. Our expectation is that significant adopters of AI will initially see initially 20% and eventually up to 50% improvements over the next few years.\n\nSecond quality of service. For example, a contact center representative should be able to answer any customer or prospects question correctly, accurately and immediately. Or the customer can self serve the answer on the company’s website by voice in the language of their choice.\n\nPerhaps the most important value of AI to organizations is the potential automation of business processes. Specifically, the elimination of people within a business processes that leads to a simplification of the business processes and the company as a whole.\n\nAs such, our guidance to clients is a combination of all three is ideal. If you are not planning for a tenfold productivity improvement over the next five to ten years, there are startups and competitors that will and risk taking your business.\n\nNVIDIA’s Moat is Wide and Deep\n\nOk let’s cut right to the chase. NVIDIA momentum is simply remarkable and has caught the attention of everyone in the industry. The pace of innovation coming out of the AI ecosystem generally and NVIDIA specifically is astounding. Here’s a diagram that underscores the new era in computing that we’re in catalyzed by large language models and the AI breakthroughs.\n\nThis chart shows the teraflop progression NVIDIA has made since 2016. We’ve overlaid a depiction of the Moore’s Law progression. The comparison is remarkable with NVIDIA demonstrating a 1000X improvement in parallel / matrix computing (what NVIDIA calls accelerated computing) in 8 years versus a 100X improvement from Moore’s Law in a decade.\n\nIt’s important to understand that in this episode where we’re forecasting the semiconductor industry ecosystem and we’re taking liberties with the scope. And by that we mean we’re modeling NVIDIA as a full platform solution and a company that is building end-to-end AI data centers – what they call the AI Factory. And they’re selling that capability through partners. One of the key aspects of NVIDIA’s moat is they build entire AI systems and then disaggregate and sell them in pieces. As such when they sell AI offerings, be they chips, networking, software, etc., they know where the bottlenecks are and can assist customers in fine tuning their architectures.\n\nNVIDIA’s moat is deep and wide in our view. They have an ecosystem and are driving innovation hard. Jensen has announced that there’s another big chip behind Blackwell – no surprise – and they are on a one year “cadence”rhythm” for systems and networking and the new systems will run CUDA. NVIDIA claims to be “all in” on Ethernet, the company will continue to extendi NVLink for homogenous AI Factories and Infiniband’s roadmap continues.\n\nJensen’s claim and bet is the more you spend with NVIDIA, the more you save and the more revenue you can drive.\n\nIn addition:\n\nWe think NVIDIAs performance gains will continue. I means we’ll see one million teraflops in five years time.\n\nBut the important thing is NVIDIA is not just a chip, it’s an entire AI platform. It has specialized GPUs, CPUs, networking, cooling and software – it’s a complete systems software. CUDA is by far the best software in the industry. It’s the key AI software platform.\n\nNVIDIA can deliver an entire AI data center. Nothing has been introduced that’s this revolutionary since IBM introduced the System 360 in 1964, which changed the computer industry.\n\nIn addition, the goal is to crank it up and introduce a new system every year. In our opinion, the value to the users, to hyperscalers and anyone using these technologies is so high that combined with the cost of creating alternatives means to us that for at least the next five years, NVIDIA will be the dominant supplier in the AI data center.\n\nA Trillion Dollar Semiconductor Ecosystem\n\nLet’s get to the meat of this research and our five year outlook for the ecosystem. The table below lays out how we see the semiconductor industry evolving. In the first column we show the players in the ecosystem comprising the chip designers like Qualcomm, the chip manufacturers like TSMC, three leading firms which do both, Intel, Samsung and Micron, equipment manufacturers like ASML and Applied Materials and software providers like Cadence, which is in the “other” category.\n\nOf course we’re also including NVIDIA, which we believe has become and will continue to be the most important player in the market. Again we’ve pushed the envelope a bit in terms of the forecast and are forecasting NVIDIA’s entire revenue stream beyond just chips.\n\nFor each company we’re showing their related revenue in 2010, 2023 and our forecast for each firm in 2028 with a CAGR for the relevant time period.\n\nMethodology\n\nWe ingested a series of relevant financial data for each firm and we combined this data with our fundamental assumptions to create a top down model of the industry as we describe here. We tested this data with a two external data points and added a third dimension, including: 1) Company strategic forecasts based on their long term financial frameworks; 2) Inputs from various financial analysts that have made long term projections for these companies and; 3) Applying our own assumptions about how we see the market playing out.\n\nWe’ll share that our assumptions and the resulting forecasts deviate quite widely from generally accepted market narratives. In particular, the broad consensus when you take into account the publicly available data essential says that everyone wins and the disruption to existing firms will be modest. We don’t see it this way. Rather we forecast a dramatic shift to matrix computing or so-called accelerated computing; and we see meaningful spending shifts causing market dislocation, particularly to traditional x86 markets.\n\nKey Findings\n\nThe high level findings in our market assessment are as follows:\n\nThe global semi ecosystem with our expanded scope, surpasses $900B by 2028 and will approximate $1T by 2030.\n\nWe forecast a 10% CAGR from ‘23 – ‘28\n\nThere is a massive market shift away from general purpose x86 toward parallel AI computing architectures or matrix computing to support AI.\n\nFour companies will account for approximately 40% of the revenue in this forecast by 2028 – NVIDIA, TSM, Broadcom and Qualcomm.\n\nSamsung and Intel are bucking the trend by vertically integrating design and manufacturing and are facing similar challenges.\n\nAI PCs will cause PC lifecycles to shorten. They will go mainstream and not only participate in a Windows refresh but will change the dynamics of the useful life of PCs.\n\nArm-based designs dominate the market volume and will confer significant cost advantages to those firms up the Arm curve\n\nHigh bandwidth memory (HBM) drives unprecedented demand for memory suppliers and creates a tailwind for those companies that can produce them.\n\nLet’s look at the data in more detail by company, sorted by our 2028 projections in descending order. We’ll show the company, our projected CAGR and our revenue forecast for 2028.\n\nNVIDIA – 25% CAGR, $160B\n\nIn our view, NVIDIA essentially has a monopoly somewhat similar to WinTel’s duopoly of the 90’s with the core GPU dominance and the AI operating system all within in the same company. We believe NVIDIA’s growth rate will actually accelerate as it penetrates new markets and will surpass $160B in revenue by 2028.\n\nImportantly, we’re including more than just chips in this forecast. Specifically, we’re assuming NVIDIA’s full platform and portfolio revenue; and the assumption is that NVIDIA continues to execute across its portfolio on a rapid cadence.\n\nNvidia has executed brilliantly. They have bet on very large chips and invested in GPUs, CPUs, networking and software offering a complete solution and a complete data center that can be disaggregated. Our assumption and belief is NVIDIA will sustain this cadence for at least the next five years.\n\nTaiwan Semiconductor Manufacturing Company (TSM or TSMC) – 14% CAGR, $135B\n\nTSM has become the go to manufacturer for advanced chips. We have TSM almost doubling in size over the next five years. Our core assumption is that volume economics will confer major strategic advantage to TSM and they will remain the world’s #1 foundry by far.\n\nIt’s important to note how TSMC is investing. The company just announced the A16, 1.6nm process targeted for 2026. We believe this will be a significant milestone in its manufacturing, with nanosheet transistors and the backside power delivery. TSM calls this Super Power Rail. These innovations in our view are industry leading and the company’s track record of execution and delivering volume at high yields will allow it to maintain leadership.\n\nBroadcom Semiconductor – 10% CAGR, $58B\n\nNext on the list is Broadcom and we’re only including its semiconductor revenue. As such we think while the company’s CAGR slows to 10%, it’s really because in 2010 it was very small. Much of Broadcom’s 2023 revenue was dispersed in our model under the other category.\n\nBroadcom has done a remarkable job through acquisitions and engineering. It doesn’t compete head on with NVIDIA in GPUs, although it is a major provider of silicon and AI chip IP for Google, Meta and we think ByteDance via its custom silicon group. We see Broadcom’s semiconductor business growing at a CAGR of 10% over the next five years, taking the division to 1.6 times its current size. Broadcom solves really difficult problems to connect all the GPUs, CPUs, NPUs, accelerators and high bandwidth memories together. They are uniquely positioned to continue to win in the market. Broadcom plays in virtually all sectors, consumer, enterprise, mobile, cloud, edge.\n\nBroadcom in our view is a very well-positioned and well-run company. Its focus particularly on networking is vital. High speed networking of all types is going to be absolutely essential for AI processing and they’re entrenched in this market. In particular they’re very well set up with major Internet players who will be AI leaders. As such Broadcom has early visibility on the most critical market trends.\n\nQualcomm – 9% CAGR, $55B\n\nQualcomm is very well-positioned both in mobile and now in AI PCs. We see them getting a huge tailwind from the recently introduced Windows AI PC stack from Microsoft. We have Qualcomm on a similar trajectory as Broadcom in terms of its growth. Essentially, Microsoft with its Windows Copilot in release 11, is following Apple’s moves from several years ago and that will be a big benefit for Qualcomm, which provides core silicon for AI PCs. This is more bad news for x86 based PCs.\n\nMicrosoft announced full support for Arm-based PCs based on Qualcomm. Now Dell, Lenovo and others have announced Arm-based PCs and suddenly you’ve got a whole plethora of these initiatives and they’re selling them on the basis of improved performance and a 24-hour battery life going directly after Intel’s PC installed base.\n\nSo you can see our forecast indicates that the four companies at the top, NVIDIA, TSM, Broadcom and Qualcomm, comprise around 45% of a $900B+ market by 2028.\n\nIntel – 2% CAGR, $54B\n\nWe’re forecasting Intel’s Foundry revenue to comprise about $22B of a $54B business in 2028. So unlike many, we’re forecasting no growth for Intel over the time period. We see the rise in foundry revenue unable to offset the decline in x86. Combined with our assumption that AMD continues to gain share in x86 markets. We have Intel data center and client revenue dropping from $45B in ’23 to $26B in ’28.\n\nIntel is late with support for AI PCs and we’re projecting a 12-18 monthly delay in its 14A process which is its big bet…combining gate all around technology – what they call RibbonFET and backside power delivery – which Intel refers to as Power Via. The company hopes to be the first to use High NA EUV technology, which combined with these other innovations is extremely bold, but also likely to be delayed. Hence our assumption that 14A gets pushed.\n\nIntel needs all three of these innovations to be successful and differentiate from the rest of the industry. We believe Intel has a very good chance of executing on two of the three simultaneously, but even that is risky. Our assumption is Intel’s 14A gets to volume production and high yeilds in 2028 (best case) or 2029 (likely case) but perhaps even 2030 (worst case). The key to understanding Intel in our view is they’ve lost the volume lead. Apple and TSMC have taken the lead and its ARM- based phones and PCs have given it a significant learning curve moat in our view, to Intel’s detriment.\n\nIf however, Intel is able to succeed and deliver 14A in volume production as it plans in 2026 and can follow with its 10A 1nm node in late 2027, then our forecasts will be incorrect and Intel will in a much better position than we project.\n\nASML – 7% CAGR, $41B\n\nASML has unique differentiation that is going to remain unmatched. Essentially we see ASML as a monopoly that’s going to continue and they’ll be able to command whatever pricing they want.\n\nSK Hynix – 10% CAGR, $40B\n\nHigh bandwidth memory has become a new enabler for AI. It’s in high demand and short supply and that is going to propel SK Hynix. We have SK Hynix growth actually accelerating with revenue growing from $25 billion today to $40 billion by 28128. High-speed memory is incredibly important and the company has multiple options in this space.\n\nSamsung Semiconductor – (-1%) CAGR, $38B\n\nWe think Samsung is going to struggle to get its advanced process working. We think it’s going to continue to face challenges and we think that constricts volumes and puts them in a cost dilemma. We’ve got Samsung basically flat from its $40 billion today.\n\nIntel has said that it intends to be the number two foundry by 2030. Given Samsung’s struggles, we think it is the right target for Intel. It’s just a matter as to whether or not Intel can get there. So, in that sense going after Samsung is the right move.\n\nAMD – 10% CAGR, $37B\n\nLisa Su has done an amazing job with this company. A key turning point was when AMD shed its fabs, which co-founder Jerry Sanders once famously remarked, “real men have fabs.” That didn’t really prove out for AMD in the long run. It took several years for the company to get back on track but their persistence has paid off.\n\nAMD is still very much tied still to x86. By 2028, the end of our forecast period, we still have 45% of AMD’s revenue coming from X86, which puts downward pressure on a big part of the company’s TAM. The good news is our assumptions call for AMD to continue to steal share from Intel and at the same time make progress in AI hardware.\n\nOf course, Intel’s going to fight like crazy for its x86 data center share, but we’re more sanguine on AMD’s outlook as a chip designer. They’re not saddled by foundry, and while that x86 pressure is a negative we believe AMD will continue to take share. They just are faster to market and have actually a quality product. For example, Oracle has just gone all AMD-based chips for their new Exadata systems which was a big win for AMD.\n\nApplied Materials – 6% CAGR, $35B\n\nWe think applied materials continues to execute. They’re in a really good position, but they have more competition than does ASML, but we’ve got them doing pretty well here growing from $27 billion in 2023 to $35 billion with a 6% CAGR. We’re basically forecasting ASML, SK Hynix, Samsung, AMD and AMAT all around that $35 to $40 billion range.\n\nApple Semiconductor Value – 12% CAGR, $33B\n\nEssentially what we’ve done here is modeled the value contribution within Apple’s hardware to the silicon and made some assumptions around its value contribution in the chain. We saw that Apple, based on our assumptions, grew at a 15% CAGR from 2010 to 2023 and we’ve got them at 12% from 2023 to 2028. We’re assuming a $33 billion contribution from silicon.\n\nThere have been ongoing rumors that Apple’s going to sell silicon as a merchant supplier. We do not make that assumption in our figures. Nonetheless, Apple getting into the business of manufacturing its own chips was profound. It started with its A series in smartphones and now of course the M series in its newest laptops and iPads. They were the first to ship NPUs both in the iPhone and in PCs. Now they’ve got to make major step up as the AI PC competition heats up.\n\nApple quietly led the AI PC wave. They introduced large chips many years ago on iPhones and integrated the CPUs, NPUs and GPUs on the same chip. They have a large shared SRAM which architecturally is a leading example and well-positined for AI. Apple has a proven track record in silicon, for example, evolving its M series, M1, M2, M3 and and now M4. We believe Apple is a leader in designing silicon architectures required to go into AI and we assume they will quickly respond to the Qualcomm AI PC trend. In our view, Apple is a main reason why Microsoft is pushing support for ARM-based designs, because they were under pressure from Apple.\n\n[Dave Vellante] >> And then designing their own chips confers real advantages-\n\nMicron – 14% CAGR, $31B\n\nWe believe Micron can accelerate its growth rate, propelled by high bandwidth memory. Similar to SK Hynix, demand is way outstripping supply for Micron’s HBM. Micron has executed very well. We see an acceleration in their CAGR to 14% and nearly doubling revenue by 2028 from $16 billion in 2023 to $31 billion. Micron not only design chips, they’ve been a successful manufacturer for years.\n\nHyperscaler Silicon – AWS, Google, Microsoft, Meta, Alibaba, ByteDance – 15% CAGR, $12B\n\nWe grouped hyperscalers into a single category. Hyperscalers design their own silicon and partner with merchant suppliers like Broadcom and others. Our forecast for hyperscalers excludes Broadcom’s contribution of custom chips, for example. We’re not double counting here.\n\nWe think hyperscaler general purpose, training and inference chips will be used for cost-sensitive applications such as inferencing at the edge. We assume they’re not going to keep pace with Nvidia at the high end, but they will get their fair share. We assume AWS Graviton accounted for about 20% of AWS workloads in 2023. Inferentia and Trainium were a smaller portion of AI workloads in 2023 as were the counterparts at Google and Microsoft. We assume a healthy contribution from hyperscalers, but they will not be a dominant factor in terms of disrupting Nvidia in our view.\n\nHyperscalers are introducing Nvidia IP. They really have to take Nvidia because they can’t make a comparable platform themselves. We assume it’s going to be cheaper for the next five years and as such they will continue to be large customers of Nvidia.\n\nOther Silicon Ecosystem Players – 4% CAGR, $175B\n\nOther includes a long tail of suppliers across the value chain. You have TI, GlobalFoundries, Chinese players like Yangtze, CXMT, startups like Cerebras and many more.\n\nWe assume in our forecastChina doesn’t invade Taiwan and that hot wars don’t completely disrupt the market. And it also assumes that the AI PC market generally follows Apple’s trends from x86 to Arm. We show x86 at about 13% of the market revenue in 2010 dropping to 11% in 2023. And it’s projected to be 5% in 2028.\n\nVisualizing the Leaders – 2010 to 2028\n\nHere’s a visual of what we just went through. In the interest of time, we’ll just say that the two companies bucking the trend among the leaders are Intel and Samsung. Micron is in a different business and has uniquely figured out the combined model. And AI is brining new investment to a market that was always considered risky by investors. News flash…it still is.\n\nAI PCs will Shorten Lifecycles\n\nHere’s our forecast for PC’s going back to 2009. When PC volumes peaked in 2011 that was the beginning of Intel’s descent from the mountaintop, even though most people didn’t see it. David Floyer made the call in 2013. And the key points here are:\n\nConsumer volumes from the iphone are what enabledinnovation in AI PC’s.\n\nSpecifically the first true inference came out in 2017 with Apple using neural processing units – NPUs – to do facial recognition and that innovation led to the first NPUs in laptops and the early example of AI PCs.\n\nWhile PC volumes picked up during COVID, they’ve been constricting. But we believe AI PCs are a game changer.\n\nMicrosoft just reset the windows stack for AI around Arm – WinArm – following Apple’s moves. PC makers like Dell and HP are adopting and Qualcomm is seizing the day. And you can see in the green below what we think it means for AI PCs powered by Arm and what happens to x86 PCs – they follow the Apple path. Not as severe but pretty much a managed decline market.\n\nWhile we forecast a surge in PC volumes, it is important to understand that this does not signal a return to the dominance once enjoyed by PC chip manufacturers like Intel. The landscape is now heavily influenced by Arm-based chips, whose wafer volumes are ten times that of x86. Companies like Nvidia, Apple, and Tesla recognized this shift early and have leveraged Wright’s Law to gain significant cost and time to market advantages in Arm-based chip design and manufacturing.\n\nThis shift underscores the increasing value of Arm technology in reducing design costs and highlights the challenges faced by x86. The market dynamics have fundamentally changed, and Arm’s advancements have made it a dominant force, fundamentally altering the competitive landscape.\n\nFinal Thoughts on Key Topics\n\nLet’s close on some of the key issues we haven’t hit.\n\nThe future of AI and its market dynamics are evolving rapidly, with significant implications for key players and emerging technologies. Our analysis highlights the pivotal trends and forecasts that will shape the AI landscape over the next decade, focusing on AI inference at the edge, energy needs, geopolitical risks, and the potential shifts in semiconductor manufacturing.\n\nKey Points\n\nAI Inference at the Edge:\n\nBy 2034, 80% of AI spending is projected to be on inference at the edge.\n\nThis workload is expected to dominate the AI market.\n\nWhile Nvidia currently holds a strong position in AI inference, driven largely by ChatGPT, the competitive landscape for high-volume, low-cost, low-power inference at the edge remains wide open and will challenge NVIDIA’s dominance.\n\nEnergy Needs:\n\nFuture energy requirements will drive the adoption of nuclear, solar, wind, and large local batteries.\n\nInnovative energy solutions will be critical to support the growing AI infrastructure.\n\nLocal power generation will be an emerging trend.\n\nGeopolitical Risks:\n\nPotential disruptions from geopolitical tensions, particularly involving China and Taiwan, pose significant risks.\n\nOur forecast assumes a frictionless environment, but there’s a 35-40% probability of supply chain disruptions affecting the market within our forecast period.\n\nIntel Foundry and Semiconductor Innovations:\n\nIntel’s future positioning depends on the successful implementation of gate-all-around, backside power, and NA EUV technologies by 2026-2027.\n\nAchieving high yields in these areas could significantly enhance Intel’s competitiveness by the 2030s and alter out scenario for the company.\n\nMarket Disruptors:\n\nWell-funded startups and major mergers and acquisitions by hyperscalers could introduce alternative approaches.\n\nDespite potential disruptions, Nvidia and the other three silicon giants with momentum – TSM, Broadcom and Qualcomm – are expected to maintain their velocity.\n\nBottom Line\n\nThe AI market is set for significant transformation, with AI inference at the edge poised to become the dominant workload. Energy innovations and geopolitical stability are crucial for sustaining this growth. While Nvidia currently leads, the competitive landscape remains fluid, with potential shifts driven by technological advancements and market disruptors. Our analysis underscores the need to monitor these developments closely as they will shape the future of AI.\n\nAs always, we’ll be watching.\n\nHow do you see the market playing out over the next five years? What do you think of our assumptions and forecasts? Let us know your thoughts and thanks for being part of the community.\n\nImage Dall-E 3"
    }
}