{
    "id": "correct_subsidiary_00027_1",
    "rank": 24,
    "data": {
        "url": "https://link.springer.com/article/10.1007/s11265-020-01558-7",
        "read_more_link": "",
        "language": "en",
        "title": "Verification and Design Methods for the BrainScaleS Neuromorphic Hardware System",
        "top_image": "https://static-content.springer.com/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig1_HTML.png",
        "meta_img": "https://static-content.springer.com/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig1_HTML.png",
        "images": [
            "https://link.springer.com/oscar-static/images/darwin/header/img/logo-springerlink-39ee2a28d8.svg",
            "https://media.springernature.com/w72/springer-static/cover-hires/journal/11265?as=webp",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-030-91741-8?as=webp",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-031-19568-6?as=webp",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-030-61616-8?as=webp",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig1_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig2_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig3_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Figa_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig4_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig5_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig6_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig7_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Figb_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig8_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig9_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig10_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11265-020-01558-7/MediaObjects/11265_2020_1558_Fig11_HTML.png",
            "https://link.springer.com/oscar-static/images/logo-springernature-white-19dd4ba190.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2020-07-09T00:00:00",
        "summary": "",
        "meta_description": "This paper presents verification and implementation methods that have been developed for the design of the BrainScaleS-2 65 nm ASICs. The 2nd generation Br",
        "meta_lang": "en",
        "meta_favicon": "/oscar-static/img/favicons/darwin/apple-touch-icon-92e819bf8a.png",
        "meta_site_name": "SpringerLink",
        "canonical_link": "https://link.springer.com/article/10.1007/s11265-020-01558-7",
        "text": "In the following paragraphs we present methods and tool flows developed for the verification of the BrainScaleS-2 mixed-signal ASIC.\n\n3.1 RTL Verification\n\nThe two important verification milestones are unit tests and integration tests. Any design of sufficient complexity must employ both methods, as without unit tests it is unfeasible to localize bugs, while integration tests make sure that all interfaces are implemented correctly and there are no throughput mismatches [4]. The testbench for integration testing needs to encompass as much of the system as possible, ideally also including the majority of the user software stack. Since the BrainScaleS System is controlled by an FPGA via playback programs which are generated by user software, it is convenient to use this interface for software-RTL co-simulation. In the physical system, compiled playback programs are transported to the FPGA via Ethernet into local memory, from where they can be fetched and passed to the FPGA executor (cf. Section 2.3). In the simulation setup, we instantiate the BrainScaleS design together with the FPGA executor and their connecting link (cf. Fig. 2). The instances of analog macros like the PLL or SRAM are replaced by behavioral models. We then pass the compiled playback program via the SystemVerilog direct programming interface (DPI) [45] into a blocking FIFO connecting to the FPGA executor which ensures the same execution pattern as in the physical system. Errors are detected via software unit tests, as well as RTL assertions monitored by the simulator. This setup is not only used for RTL verification, but also as a convenient reference for in-silico testing, since it is now possible to transparently execute a playback program in simulation or on the physical system and compare the results.\n\n3.2 Full-Custom Verification\n\nMixed-signal neuromorphic circuits as implemented in the BrainScaleS systems are designed to emulate complex biological mechanisms. To allow for a flexible and faithful replication of the underlying models, the circuits must be tunable, which sometimes requires a large number of analog and digital parameters. Both, the biological prototype as well as the neuromorphic replica can possess high-dimensional parameter spaces and a wide range of operating points. Analog circuits are prone to parameter deviations due to mismatch effects and thus require additional calibration to reach a target operating point. While individual components can often be unit-tested with conventional simulation strategies, assessability of a complete circuit‚Äôs functionality is limited due to error propagation and inter-dependencies of parameters. Verifying such complex circuits is hence a challenge.\n\nSoftware-driven simulation of such designs can aid the developer to increase pre-tape-out verification coverage, by allowing to programmatically generate stimuli and perform advanced analyses on recorded data. Although inherently scriptable, the Cadence Virtuoso Analog Design Environment does not feature an ecosystem as rich as of more widely used programming languages [10, 11].\n\n3.2.1 Interfacing Analog Simulations from Python\n\nWe implemented the Python module teststand to provide tight integration of analog simulations into the language‚Äôs ecosystem. Teststand does not implement a new simulator but rather represents a thin layer to interface with the Cadence Spectre simulator and other tools from the Cadence Design Suite (cf. Fig 3).\n\nNetlists are directly extracted from the target cell view as available in the design library. The data is accessed by querying the database via a script executed as a child process, using Cadence‚Äôs scripting language OCEAN [10]. Teststand then reads the netlist and modifies it according to the user‚Äôs specification. In addition to the schematic description, Spectre netlists also contain simulator instructions. Teststand generates these statements and hence potentially supports all features provided by the backend. Specifically, the user can define analyses to be performed by the simulator, such as DC, AC, and transient simulations. Monte Carlo (MC) analyses are supported as well and play an important role in the verification strategies presented below.\n\nThe user specifies the simulation including e.g. stimuli, parameters, and nodes to be recorded using an object-oriented interface that resembles Spectre simulation instructions.\n\nThe simulate()-call executes Spectre as a child process. Basic parallelization features are natively provided via the multiprocessing library. Scheduling can be trivially extended to support custom compute environments. The simulation log is parsed and potential error messages are presented to the user as Python exceptions.\n\nResults are read and provided to the user as structured NumPy arrays. This allows to resort to the vast amount of data processing libraries available in the Python ecosystem to process and evaluate recorded data. Most notably, this includes NumPy [37], SciPy [31], and Matplotlib [30]. As a side effect, the latter allows to directly generate rich publication-ready figures from analog circuit simulations.\n\n3.2.2 Monte Carlo Calibration\n\nTeststand‚Äôs benefits become most clearly visible in conjunction with MC simulations, which allow to asses the performance of a circuit under the influence of random variations in the production process. Traditionally, developers analyze a circuit‚Äôs performance under statistical parameter variations that mimic in-silicon imperfections to allow them to anticipate post-tape-out functionality and yield. Moreover, by fixing the MC seed a set of virtual instances can be obtained, which can be individually parameterized and analyzed, similar to an array of actual in-silicon instances of the design.\n\nSuch simulations can be iteratively and algorithmically modified. This concept can be used to optimize bias and reference parameters ùúÉhw of a design to reach a desired operating point determined by a set of model parameters ùúÉmodel. In the case of a neuromorphic circuit these can for example be given by a set of potentials, conductances, and time constants. Such a MC calibration can be performed on each sample individually to also equilibrate mismatch-induced effects.\n\nThe approach to find a suitable parameter set generally depends on both model and circuit. One possible strategy is based on iteratively reconfiguring and probing the design‚Äôs behavior. An effective implementation will likely be based on a binary search. This method is particularly useful for parameters that are intended to be kept constant during operation, e.g. to compensate for a fixed offset. In other scenarios it might be desirable to find and measure a transformation between the model‚Äôs and circuit‚Äôs parameter spaces ùúÉhw(ùúÉmodel) and make it persistent. These data can then later be reused to perform one or multiple benchmarks on the calibrated instance, incorporating potentially different operating points.\n\nThese calibration algorithms are ‚Äì when required ‚Äì often implemented only after tape-out. Already implementing them for simulated instances, however, brings several major advantages. It allows the designer to determine a suitable calibration range and resolution and estimate the post-calibration yield. The co-development of circuits and algorithms leads to better hardware but also improved software, and might reveal details in their interplay otherwise potentially overlooked. Especially for complex circuits with high-dimensional parameter spaces there might occur multidimensional dependencies which can be hard to resolve. Actually calibrating such a circuit as a whole might reveal insufficient parametrization that would not have been found in tests of individual sub-components. In order to uncover potential regressions due to modifications to a circuit, simulations based on teststand can easily be automated and allow continuous integration testing for full-custom designs.\n\nFor the BrainScaleS systems, the use of teststand has lead to large increase of in-silicon usability. It was used throughout the verification of various components of the BrainScaleS-2 ASICs, including the current neuron implementation [2, 35]. As a more compact example of teststand usage, we want to present a verification strategy for the BrainScaleS-2 synapse driver circuit, focussing on the analog implementation of short-term plasticity (STP). The testbench shown in Fig. 4 is centered around the synapse driver as the design under testing. The latter is accompanied by an instance of the synapse circuit. To mock parasitic effects due to the synapse array‚Äôs spatial extents, an RC wire model based on post-layout extractions is inserted in between the two instances. Finally, a simple neuron circuit based on ideal components is included in the testbench, integrating the post-synaptic currents to form the characteristic post-synaptic potentials.\n\nThe testbench is controlled from Python code using teststand. Both input interfaces, the SRAM controller as well as the event interface receiver, are mocked in Python, allowing for the verification of the entire design in a realistic scenario, beginning with accessing the configuration memory and then moving to processing of synaptic events. The synapse driver is exposed to predefined input spike trains consisting of a series of equidistant events. The design‚Äôs response is recorded and then processed using tools from the Python ecosystem in order to extract parameters from the biological model [49]. Thus, quantities as the circuit‚Äôs synaptic utilization and the recovery time constant, describing the decay and re-uptake of synaptic resources, can be benchmarked against specification and constraints. More importantly, a mismatch-induced offset in synaptic efficacy can be extracted and compared across multiple virtual synapse drivers. Following a binary search based on their deviation from a target value, a 4 bit offset calibration parameter in the DUT‚Äôs configuration memory is iteratively reprogrammed, minimizing the offset. Implementing this calibration routine before tape-out allowed to fully judge the circuits usability. Fig. 4 includes histograms of the extracted offsets for 128 synapse driver instances, prior to and after calibration. Applying the same calibration methodology to the taped-out circuits resulted in very similar distributions. While certainly relying on the quality of the models provided with the process design kit, these results show that the advanced verification methods facilitated by teststand allow to successfully pre-asses the behavior of even complex full-custom circuit designs that require calibration.\n\nPhysical implementation describes the process of generating an ASIC layout from a netlist description. It is part of a usually customized design flow which is applied during the overall design process. For BrainScaleS-2 we apply separate flows for analog and digital design as illustrated in Fig. 5. Analog layout is carried out using Cadence Virtuoso and shall not be covered in this paper.\n\nWe are using a digital top-level description for all BrainScaleS chips (cf. Section 2.3), thus top-level chip assembly is carried out in the digital design flow, using Cadence Innovus. Depending on the complexity of the specific design, we follow a hierarchical implementation approach using separate design partitions which might be instantiated multiple times in the design. Besides this re-usability, partitioning the design has the main advantage of a dedicated implementation approach per partition, for example optimized for a purely digital partition, or a partition having or containing a mixed-signal interface.\n\nOur digital logic is written in SystemVerilog, and partially in VHDL. The gate-level netlist which is the basis for physical implementation is generated during logic synthesis, where the RTL description of the logic is mapped to a standard cell library [47]. Blocks with more complex functionality (such as large SRAM blocks, PLLs) need to be provided as pin-level macros and are directly instantiated already in the RTL description. Both, logic synthesis and physical implementation require a pin-level characterization of the signal timing of the blocks in order to correctly analyze static timing of the whole design. Characterization is also required for our analog neuromorphic circuits, which are directly instantiated in the SystemVerilog source. The following section covers methods that we have developed for this purpose.\n\n4.1 Timing Analysis at Mixed-Signal Interfaces\n\nThe PPU has local memory for program data and vector operations, but also accesses the memory that has been implemented into the synapse array for digital synaptic weight storage. Thus, the synapse array can be accessed row-wise by the PPU, with every column of the array being directly connected to the synapse memory access controller. The resulting data bus has a width of8bit times number of synapses per row.\n\nIt is desirable to minimize the access time to the synapse weight storage in order to maximize the weight update rate during plasticity operation [19]. To facilitate this and reduce access latencies, a full-custom SRAM controller has been implemented in the synapse array [27]. It has a fully synchronous digital interface towards the PPU that is designed to operate at the maximum targeted PPU operating frequency of 500MHz. All circuits behind the registers of this interface are covered by the verification steps in the analog design flow and do not have to be taken into account for timing analysis at the interface. As a consequence, only the communication with the interface registers needs to be verified in order to ensure correct functionality at this mixed-signal interface.\n\n4.1.1 Timing Characterization of Anncore\n\nSynchronous digital circuits are commonly implemented using a set of standard cells that implement logic gates and memory elements (e.g. flip-flops). In contrast to analog circuits, performance of digital circuits is not evaluated by transistor-level simulations, but by STA [8] which verifies whether setup and hold timing constraints are met for all flip-flops in the design, thus, whether the design is able to operate at a given clock period. STA requires information about setup, hold, and clock-to-output time of flip-flops, delays through logic gates, as well es external capacitive load on cells and the propagation delay on signal wires. Among those, all cell-related delays are dependent on the actual wiring of the cell, operating conditions and process corner. Therefore, not a single value can be given for e.g. a gate propagation delay, but the cells rather have to be characterized for several sets of conditions, usually covering typical values that arise during operation. Results are stored in a timing library file containing either look-up table data or a current source model [8]. For each combination of process corner and operating conditions that should be analyzed one such library is provided by the standard cell vendor. When calculating STA, the tools are allowed to extrapolate from and interpolate in between the given values.\n\nCommercial tools exist for characterizing custom designed standard cell libraries, as for example Cadence Liberate. These tools can automatically determine the relevant signal paths through circuits representing logic gates or flip-flops and then carry out a series of analog simulations in order to determine the aforementioned delay values under a certain set of conditions. However, these tools are scarcely configurable for automatically analyzing complex VLSI circuits, like the described synapse memory interface of the anncore. For this reason, a Python-based characterization framework has been developed in [26].\n\nSequential input pins with a timing relation to a clock input are characterized for capacitance, setup and hold time. Output pins associated to a clock input are characterized for clock-to-output delay and load-dependent output transition time. For example all data pins of the synapse memory interface belong to this category. Non-sequential input pins are solely characterized for their capacitance and output pins for their transition time. Potential timing requirements on these pins need to be defined externally. This includes for example pins of custom SRAM arrays, static control pins, and the event interface.\n\nThe clock signal of the synapse array memory interface‚Äôs registers is distributed in a fly-by manner (see Fig. 9), along the edge of the synapse array. This edge has a length of 1.5mm in the current BrainScaleS-2 chip. Since no balanced clock tree exists for these registers, a correct characterization of the resulting spread in timing constraints is one of the most crucial results of this characterization.\n\nThe digital timing of the anncore is characterized after completion of the analog design process and the resulting data is stored in a timing library file [8]. It can then directly be instantiated in the RTL code and is treated as a macro block throughout the digital design flow. For the layout of the current anncore (see Section 4.2), a spread in setup and hold times of approximately 150ps has been determined. Most notably, the setup-and-hold window of the data pins which usually lies around the clock edge of a flip-flop lies up to 600ps after the related edge at the clock pin, due to the internal delay on the clock signal.\n\nFor the digital design implementation of the current BrainScaleS-2 ASIC, we have used a standard bottom-up hierarchical synthesis flow with Synopsys DesignCompiler to obtain a single shared implementation for the two PPU instances. As a first step during subsequent physical implementation the floorplan needs to be laid out. The illustrated floorplan of the current BrainScaleS-2 full-size ASIC is depicted in Fig. 7. Non-standard floorplanning and further physical implementation steps will be described in the following subsections.\n\n4.2 Anncore Abstract View\n\nAll analog circuits of the BrainScaleS architecture are arranged such that they are combined into one large analog macro block (anncore). When implementing full-sized ASICs with up to 512 neurons and 256 synapse circuits per neuron, we split the resulting VLSI synapse array into several subunits because resistance and capacitance of the long wires would lead to undesirably high energy consumption and internal signal delay. The drawback is an increased number of pins that result at the split edges and require additional routing when connecting with the digital logic. In case of the current BrainScaleS-2 chip we considered a 4 quadrant layout as a good compromise between energy consumption and routability. It is illustrated in Fig. 7, where the top right quadrant is illustrated. Two halves of the array are arranged such that the neuron circuits are located at the horizontal symmetry axis in order to minimize vertical wire capacitances. To balance horizontal wire capacitances and routability we choose to introduce a vertical split which adds additional row drivers and according pins at the split edges. The quadrants have been arranged in a way that all control pins are facing towards a cut-out in the center of anncore (see zoom-out in Fig. 6). The strategies we developed to connect to the pins in this center cut-out will be described in the following.\n\nDuring physical implementation, abstracted layout data are required to floorplan the design and connect the block using the auto-router. We generate these using Cadence Abstract Generator, with a few non-standard tweaks to obtain a routable block, since physical size, shape, and number of pins pose several challenges to the standard abstract generation.\n\nThe anncore abstract is illustrated in Fig. 6. Approximately 85% of the pins are made up by the interfaces for synapse memory access and column ADC readout. These pins are placed at the top and bottom edges of the anncore to facilitate direct access by the adjacent PPUs. The other 15% of the pins consist of SRAM and auxiliary control pins for the neuron configuration, the capacitive memory and the event communication. They are placed at the row-ends of their connected circuits for neurons and capacitive memory, and at the bottom edge of the event interface columns, all facing towards the cut-out in the center (zoom-out in Fig. 6).\n\nAll control logic, including power supply, the according clock tree and the interface to the top-level control need to be placed in this cut-out area. It has a size of approximately 1440 √ó 225Œºm2 with an area of approximately 2 √ó 105Œºm2 being available for standard cell placement due to the dumbbell-shaped outline. This would allow for roughly 30 k flip-flops of minimum size at 100 % placement density. All but the two topmost metal layers are available for routing; the two topmost layers are exclusively used for power distribution. Pins to the analog circuits are spread over the complete boundary, while care has been taken to optimize accessibility by the auto-router: they have been placed on layers with horizontal/vertical preferred routing direction depending on the edge, and blockage generation around the pins has been optimized for routability, per layer.\n\nAccess to this area has been enabled by means of two routing channels that have been left open during analog layout. Three horizontal routing layers are available inside these channels and they have been sized in a way to accommodate routing of all required interface signals. The generation of placement blockage in the generated abstract view has carefully been tuned to represent the actual outline of only the layout of metal layers defining the cut-out and channels, and not the covering power distribution layers (cf. Fig. 6).\n\nStandard cells can therefore be placed inside the cut-out and the channels but the tool is restricted to only place buffers within the channels that are required to meet the timing constraints. This allows keeping the routing channels as small as possible while still being able to achieve timing closure. Bus guides have been used to guide the auto-router and use one channel for inbound and one channel for outbound signals, only. All corresponding interface logic has been constrained to be placed in the proximity of the channel entry areas.\n\n4.3 Mixed-Signal Event Input\n\nNeural events are injected into the synapse drivers using four event interface buses in each half of anncore. Each bus consists of four signals address[5:0], select[4:0], pulse, and stable. These signals are generated by flip-flops in the event handling logic and are required to keep below a maximum skew of 200ps at the according anncore pins (see undefined regions in Fig. 8 a). Since the inputs to the anncore have no synchronous relation to a clock signal, the timing to these pins cannot be constrained by a sequential relation, like the standard setup and hold conditions between two flip-flops. The signals rather have to be treated like a source-synchronous bus with a strobe signal as a reference signal and all bus signals must be constrained to stay within a maximum skew compared to the strobe signal. From a functional point of view, the pulse signal acts as this strobe signal (cf. Section 2.1 and Fig. 8 a). While allowing for a clock skew of 50ps to the registers generating these signals, they have been constrained for a maximum skew of 150ps w.r.t. the pulse signal using the following constraints:\n\nThe mutual definition of a negative setup time between the signals results in a temporal window within which the signals must arrive at the anncore pins. The above statements are part of the timing constraints which are used as an input already for synthesis. They are interpreted equally to a regular setup constraint and the tool fixes violations during setup-time optimization steps. The resulting delay distribution of all affected signals is shown in Fig. 8 b. In the typical and fast corner the delay values cover a range of 125ps and 75ps, respectively. In the slow corner, the spread is about 190ps which is perfectly within specification.\n\n4.4 Partition Interface Timing\n\nIn Fig. 7 the floorplan of the most recent version Brain-ScaleS-2 chip is shown. The two PPUs are placed at the top and bottom edges as a copy of one implemented design partition. Each PPU has a purely digital interface to the digital control logic at its left edge and an interface to the anncore which is connected to anncore pins (see also Fig. 9). Registers inside the PPU partition are connected to registers in the anncore while both receive the same clock. This clock can be switched off towards the synapse array by a clock gate, controlled by the PPU, to save dynamic power. The main problem that comes with this configuration is the fact that this gated clock is yet to be implemented inside the PPU partition, thus has an initially unknown clock tree propagation delay. Therefore the standard methods to derive the interface timing for the partition implementation are not applicable here. We use the following approach to solve this, which could be considered a generic solution to such configurations:\n\nIn general, timing budgeting using virtual in-place optimization (IPO) provided by the Innovus tool is used to derive the partition interface timing before splitting off the PPU design for separate implementation. A preliminary place-and-route step and a provisional timing optimization is automatically run in this step to estimate the signal timing at partition boundaries. During budgeting, a certain amount of available time on signal paths between two flip-flops before and after a partition boundary (slack) is distributed between both sides, depending on provisional optimization results. The changes made during optimization are then reverted and actual timing optimization has to be carried out during partition and top-level implementation, using the slack values that have been distributed to the respective signal pins. However, since the involved algorithms assume that during later implementation steps the optimization engine will operate on both sides of the partition boundary, this cannot be applied to the signals directly connecting to the anncore since no buffers can be added outside the partition. This affects all grey interconnect lines and routing inside the anncore (cf. Fig. 9).\n\nTo solve this problem the following method is applied for budgeting of the partitions‚Äô timing constraints before partitioning the design: Pin locations at the partition boundary are fixed, adjacent to their anncore counterparts, in order to have predictable routing lengths between PPU partition and anncore. Sufficiently sized buffers are constrained to be placed close to those pins inside the PPU partition, in order to fix the capacitive load on input pins and the drive strength at output pins, respectively (solidly drawn buffers in Fig. 9). These buffer cells are already instantiated in the RTL description; they are merely up- or downsized in this step, according to their actual load. After completion of these steps, a preliminary routing and STA is run in order to determine the signal delays between partition boundary and anncore (grey interconnect lines and in-anncore routing are fixed at this step). The result is then used as a fixed slack outside the partition, while the remaining slack is available for the timing paths inside the partition.\n\nThe delay between partition and anncore pins is determined in a similar fashion for the according clock signals. In order to get the delay reported correctly, a clock buffer is placed and fixed close to the partition boundary, serving as a start point for the path segment between PPU partition and anncore. The determined delay is then given to the clock tree synthesizer and is accounted as an external additional delay during clock tree synthesis. Toghether with the strategy for fixing external signal delay, the setup condition for the anncore registers can be written as\n\n$$ (t_{\\text{cp}} + {\\Delta} t_{\\text{cp}}) + t_{\\text{dp}} + \\underbrace{t_{\\text{dt}} + t_{\\text{co}} + t_{\\text{sut}}}_{\\text{delay~fixed}} \\leq t_{\\text{cp}} + \\underbrace{t_{\\text{ct}} + t_{\\text{per}}}_{\\text{delay~fixed}} , $$\n\n(1)\n\nwith tcp being the clock tree delay inside the PPU and Œîtcp the skew after clock tree synthesis, tdp the signal path delay inside the PPU (logic and wires), tdt the external signal delay between PPU and anncore, tco the clock-to-output time of the flip-flops inside the PPU, tsut the setup time of the anncore register, tct the portion of the clock tree delay between PPU and anncore, and tper the clock period. This condition must be met by the tool during optimizations in the PPU partition. To achieve this, the clock port to the synapse array and the related registers inside the PPU partition are constrained into a separate skew group which can subsequently be optimized separately by the clock tree synthesizer. The maximum allowed skew within this group is set to 0ps to force the clock tree synthesizer to achieve as identical as possible tcp at all those endpoints. It is allowed to skew all other registers, if useful for timing optimization.\n\nIdeally, the described setup condition could then be met by timing optimization steps during partition implementation. However, zero skew cannot be realized by the clock tree synthesizer, especially over large spatial distances, as is the case along the anncore edges. As a consequence, the resulting clock skew Œîtcp at the constrained registers has to be checked after clock tree synthesis is finished. This maximum skew value is a timing uncertainty that could not be taken into account during calculation of the partition timing budgets. Therefore, it has to be accounted for in the signal paths between PPU partition and anncore by adding the skew value as a slack adjustment to these paths in the scripts that are used for partition implementation. This way, setup timing gets slightly overconstrained for most paths, yet we found no other way to safely account for the inevitable clock skew. At least one iteration of the partition implementation design flow is necessary to obtain the skew values and add them to the scripts, ideally already before initial placement, to have consistent constraints throughout the design flow.\n\n4.5 Partition and Top-Level Implementation\n\nIn the PPU partition, each slice of the vector unit is connected to 32 synapse columns each and operates only on data local to the slice. This spatial correlation results in a predictable implementation quality of the vector units themselves in terms of area and timing. However, the vector control unit requires access to all synapse data, and the state values of the vector units. Therefore, the critical path inside the PPU partition runs between registers in the outermost vector units through the vector control unit which is located in the partition‚Äôs geometrical center to the outermost synapse array data pins. Since the responsible RTL designer left the group prior to tapeout we could not improve this path by e.g. adding pipeline registers, for this chip revision. PPU partition implementation is carried out using a standard physical design flow, including pre- and post-route in-place timing optimizations and the previously discussed modifications to clock tree synthesis and the slack adjustment. Maximum expected clock frequency of the PPU in the worst process corner is 245MHz, due to the aforementioned critical path. Initial measurements, running a memory test on the full synapse array which was executed on the PPU using the access path through the vector units yielded a maximum clock frequency of 400MHz.\n\nThe top-level implementation essentially follows a standard physical design flow as well, with two exceptions: First, drivers to full-custom SRAM bitlines of the various configuration memories in the anncore center are placed close to their corresponding pins, to obtain equal parasitic load on those lines. This is done automatically by means of a script that determines pin location and the connected cell, and places the cell at the closest legal location to the pin. Second, the clock tree generation to the center cut-out in the anncore is constrained in a way to optimize balancing between flip-flops that are located outside and inside the cut-out area. This is beneficial in terms of overall clock tree depth, thus power consumption on the clock tree, because balancing the tree globally would require an adaption of all clock sinks to the additional delay introduced by the routing channels into the anncore center. A similar approach to the technique described in Section 4.4 is taken to achieve good balancing: all registers that are to be placed inside the anncore center are constrained into a dedicated skew group which is disjunct from the remainder logic, with no skew constraint set. This way, the clock tree synthesizer can optimally balance inside and outside skew with respect to the anncore center.\n\nAs an implementation result, a total of 33003 standard cells have been placed in the anncore center, at an average placement density of roughly 75 % in the 2 √ó 105Œºm2 area and no issues in routability (see Section 4.2 for an area calculation). All control and event handling logic that connects to the mixed-signal interfaces of the analog neuromorphic circuits is thus either contained inside the square area of the anncore, or in the PPUs which are connected by abutment. Timing could be closed in all process corners, the target clock frequencies of 250MHz and 125MHz for link/event handling clock and on-chip bus clock, respectively have been met and proven in silicon (cf. Section 3.2)."
    }
}