{
    "id": "dbpedia_6494_3",
    "rank": 70,
    "data": {
        "url": "https://beginningwithml.wordpress.com/author/yrahul97/",
        "read_more_link": "",
        "language": "en",
        "title": "Rahul Yedida",
        "top_image": "https://secure.gravatar.com/avatar/927b80f86f0620c816413fcdc6446437?s=200&d=identicon&r=g",
        "meta_img": "https://secure.gravatar.com/avatar/927b80f86f0620c816413fcdc6446437?s=200&d=identicon&r=g",
        "images": [
            "https://s0.wp.com/latex.php?latex=p&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=p&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/07/screenshot-from-2019-07-09-18-51-46.png?w=525&h=376",
            "https://s0.wp.com/latex.php?latex=%5Cbeta&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=n%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=l&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bn%5E%7B%5Bl%5D%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=l&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/07/panthera_tigris_tigris_tidoba_20150306.jpg?w=1100",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/07/17121124_tiger.jpg?w=1100",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/07/screenshot-from-2019-07-17-22-49-39.png?w=1100",
            "https://s0.wp.com/latex.php?latex=g%28x%29+%3D+%5Cmax+%280%2C+x%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/06/screenshot-from-2019-06-15-11-44-28.png?w=1100",
            "https://s0.wp.com/latex.php?latex=g%28x%29+%3D+x&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+z%5E%7B%5B1%5D%7D+%26%3D+W%5E%7B%5B1%5D%7Dx+%2B+b%5E%7B%5B1%5D%7D+%5C%5C+a%5E%7B%5B1%5D%7D+%26%3D+W%5E%7B%5B1%5D%7Dx+%2B+b%5E%7B%5B1%5D%7D+%5C%5C+z%5E%7B%5B2%5D%7D+%26%3D+W%5E%7B%5B2%5D%7Da%5E%7B%5B1%5D%7D+%2B+b%5E%7B%5B2%5D%7D+%5C%5C+a%5E%7B%5B2%5D%7D+%26%3D+W%5E%7B%5B2%5D%7Da%5E%7B%5B1%5D%7D+%2B+b%5E%7B%5B2%5D%7D+%5C%5C+%26%3D+W%5E%7B%5B2%5D%7D+%5Cleft%28+W%5E%7B%5B1%5D%7Dx%2Bb%5E%7B%5B1%5D%7D+%5Cright+%29+%2B+b%5E%7B%5B2%5D%7D+%5C%5C+%26%3D+W%5E%7B%5B2%5D%7DW%5E%7B%5B1%5D%7Dx+%2B+W%5E%7B%5B2%5D%7Db%5E%7B%5B1%5D%7D+%2B+b%5E%7B%5B2%5D%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=W&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5B2%5D%7D%2C+1%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b%5E%7B%5B2%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%28x%29+%3D+%5Ctanh+%28x%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/06/screenshot-from-2019-06-15-12-04-29.png?w=477&h=279",
            "https://s0.wp.com/latex.php?latex=g%28x%3B+k%2C+%5Calpha%29+%3D+%5Cfrac%7B1%7D%7B1+%2B+kx%5E%5Calpha+%281-x%29%5E%7B1-%5Calpha%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%28x%3B+k%2C+n%29+%3D+kx%5En&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%28x%3B+%5Calpha%29+%3D+%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D+x%3B+%26+x+%5Cgeq+0+%5C%5C+%5Calpha%28e%5Ex-1%29%3B+%26+x+%3C+0+%5Cend%7Bmatrix%7D%5Cright.&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%5E%7B%5Cprime%7D%28x%29+%3D+g%28x%29%281-g%28x%29%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%28x%29+%5Cto+1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=1-g%28x%29+%5Cto+0&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%5E%7B%5Cprime%7D%28x%29+%5Cto+0&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%28x%29+%5Cto+0+%5CRightarrow+g%5E%7B%5Cprime%7D%28x%29+%5Cto+0&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29+%26%3D+g%28x%29%281-g%28x%29%29+%5C%5C+%26%3D+g%28x%29+-+g%5E2%28x%29+%5C%5C+f%5E%7B%5Cprime%7D%28x%29+%26%3D+g%5E%7B%5Cprime%7D%28x%29-2g%28x%29+g%5E%7B%5Cprime%7D%28x%29+%3D+0+%5C%5C+%5CRightarrow+g%5E%7B%5Cprime%7D%28x%29+%26%3D+2g%28x%29g%5E%7B%5Cprime%7D%28x%29+%5C%5C+%5CRightarrow+g%28x%29+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=f%28x%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B4%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x+%3C+0&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%28x%29+%3D+0.01x&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/06/screenshot-from-2019-06-14-18-48-38.png?w=1100",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/06/screenshot-from-2019-06-14-19-06-33.png?w=597&h=337",
            "https://s0.wp.com/latex.php?latex=f%28x_1%2C+x_2%2C%5Cldots%2C+x_n%29+%3D+g%28w_1+x_1+%2B+w_2+x_2+%2B+%5Cldots+%2B+w_n+x_n%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=w&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%28%5Ccdot%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=g%5E%7B%5Bl%5D%7D%28%5Ccdot%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=l&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=z%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=a%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=a%5E%7B%5B0%5D%7D+%3D+x&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=W%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=l&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=n%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=l&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+z%5E%7B%5Bl%5D%7D+%26%3D+W%5E%7B%5Bl%5D%7Da%5E%7B%5Bl-1%5D%7D+%2B+b%5E%7B%5Bl%5D%7D+%5C%5C+a%5E%7B%5Bl%5D%7D+%26%3D+g%28z%5E%7B%5Bl%5D%7D%29+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=W%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5Bl%5D%7D%2C+n%5E%7B%5Bl-1%5D%7D%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=a%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=z%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5Bl%5D%7D%2C+1%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x_0%3D1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Chat%7By%7D+%3D+w%5ET+x&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b%5E%7B%5Bl%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=W%5E%7B%5Bl%5D%7Da%5E%7B%5Bl-1%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+W%5E%7B%5BL%5D%7D%7D+%3D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+a%5E%7B%5BL%5D%7D%7D%5Cfrac%7B%5Cpartial+a%5E%7B%5BL%5D%7D%7D%7B%5Cpartial+z%5E%7B%5BL%5D%7D%7D%5Cfrac%7B%5Cpartial+z%5E%7B%5BL%5D%7D%7D%7B%5Cpartial+W%5E%7B%5BL%5D%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+W%5E%7B%5BL-1%5D%7D%7D+%3D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+a%5E%7B%5BL%5D%7D%7D%5Cfrac%7B%5Cpartial+a%5E%7B%5BL%5D%7D%7D%7B%5Cpartial+z%5E%7B%5BL%5D%7D%7D%5Cfrac%7B%5Cpartial+z%5E%7B%5BL%5D%7D%7D%7B%5Cpartial+a%5E%7B%5BL-1%5D%7D%7D%5Cfrac%7B%5Cpartial+a%5E%7B%5BL-1%5D%7D%7D%7B%5Cpartial+z%5E%7B%5BL-1%5D%7D%7D%5Cfrac%7B%5Cpartial+z%5E%7B%5BL-1%5D%7D%7D%7B%5Cpartial+W%5E%7B%5BL-1%5D%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+a%5E%7B%5BL%5D%7D%7D+%26%3D+%5Cfrac%7B%5Cpartial+%7D%7B%5Cpartial+a%5E%7B%5BL%5D%7D%7D+%5Cleft%28-y+%5Clog+a%5E%7B%5BL%5D%7D-%281-y%29%5Clog+%281-a%5E%7B%5BL%5D%7D%29+%5Cright+%29+%5C%5C+%26%3D+-%5Cfrac%7By%7D%7Ba%5E%7B%5BL%5D%7D%7D%2B%5Cfrac%7B1-y%7D%7B1-a%5E%7B%5BL%5D%7D%7D+%5C%5C+%26%3D+%5Cfrac%7B-y+%2B+ya%5E%7B%5BL%5D%7D%2Ba%5E%7B%5BL%5D%7D-ya%5E%7B%5BL%5D%7D%7D%7Ba%5E%7B%5BL%5D%7D%281-a%5E%7B%5BL%5D%7D%29%7D+%5C%5C+%26%3D+%5Cfrac%7Ba%5E%7B%5BL%5D%7D-y%7D%7Ba%5E%7B%5BL%5D%7D%281-a%5E%7B%5BL%5D%7D%29%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+a%5E%7B%5BL%5D%7D%7D%7B%5Cpartial+z%5E%7B%5BL%5D%7D%7D+%26%3D+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+z%5E%7B%5BL%5D%7D%7D%5Cfrac%7B1%7D%7B1%2B%5Cexp%28-z%5E%7B%5BL%5D%7D%29%7D+%5C%5C+%26%3D+a%5E%7B%5BL%5D%7D%281-a%5E%7B%5BL%5D%7D%29+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+z%5E%7B%5BL%5D%7D%7D%7B%5Cpartial+a%5E%7B%5BL-1%5D%7D%7D+%26%3D+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+a%5E%7B%5BL-1%5D%7D%7D+%5Cleft%28+W%5E%7B%5BL%5D%7Da%5E%7B%5BL-1%5D%7D%2Bb%5E%7B%5BL%5D%7D+%5Cright+%29+%5C%5C+%26%3D+W%5E%7B%5BL%5D%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+z%5E%7B%5BL-1%5D%7D%7D%7B%5Cpartial+W%5E%7B%5BL-1%5D%7D%7D+%26%3D+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+W%5E%7B%5BL-1%5D%7D%7D+%5Cleft%28+W%5E%7B%5BL-1%5D%7Da%5E%7B%5BL-2%5D%7D%2Bb%5E%7B%5BL-1%5D%7D+%5Cright+%29+%5C%5C+%26%3D+a%5E%7B%5BL-2%5DT%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+W%5E%7B%5BL%5D%7D%7D+%3D+%28a%5E%7B%5BL%5D%7D-y%29a%5E%7B%5BL-1%5DT%7D+&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+z%5E%7B%5BL%5D%7D%7D%7B%5Cpartial+W%5E%7B%5BL%5D%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+b%5E%7B%5BL%5D%7D%7D+%3D+%28a%5E%7B%5BL%5D%7D-y%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+W%5E%7B%5BL-1%5D%7D%7D+%3D+%28a%5E%7B%5BL%5D%7D-y%29W%5E%7B%5BL%5D%7Da%5E%7B%5BL-1%5D%7D%281-a%5E%7B%5BL-1%5D%7D%29a%5E%7B%5BL-2%5DT%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5BL%5D%7D%2C+1%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=a%5E%7B%5BL%5D%7D+-+y&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=W%5E%7B%5BL%5D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5BL%5D%7D%2C+n%5E%7B%5BL-1%5D%7D%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+W%5E%7B%5BL-1%5D%7D%7D+%3D+%5Cleft%28+W%5E%7B%5BL%5DT%7D%C2%A0+%28a%5E%7B%5BL%5D%7D-y%29+%5Cright%29+%5Ctimes+%5Cleft%28+a%5E%7B%5BL-1%5D%7D%281-a%5E%7B%5BL-1%5D%7D%29+%5Cright%29%C2%A0+a%5E%7B%5BL-2%5DT%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=W%5E%7B%5BL%5DT%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5BL-1%5D%7D%2C+n%5E%7B%5BL%5D%7D%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28a%5E%7B%5BL%5D%7D-y%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5BL%5D%7D%2C+1%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Ctimes&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5BL-1%5D%7D%2C+1%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=a%5E%7B%5BL-1%5D%7D%281-a%5E%7B%5BL-1%5D%7D%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%28n%5E%7B%5BL-1%7D%2C+1%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Ctimes&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%5E%7B%5Bl%5D%7D%7D+%26%3D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+a%5E%7B%5Bl%5D%7D%7D%5Ctimes+g%5E%7B%5Bl%5D%5Cprime%7D%28z%5E%7B%5Bl%5D%7D%29+%5C%5C+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+W%5E%7B%5Bl%5D%7D%7D+%26%3D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%5E%7B%5Bl%5D%7D%7Da%5E%7B%5Bl-1%5DT%7D+%5C%5C+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+a%5E%7B%5Bl-1%5D%7D%7D+%26%3D+W%5E%7B%5Bl%5DT%7D%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%5E%7B%5Bl%5D%7D%7D+%5C%5C+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+b%5E%7B%5Bl%5D%7D%7D+%26%3D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%5E%7B%5Bl%5D%7D%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+W%5E%7B%5Bl%5D%7D%7D+%26%3D+%5Cfrac%7B1%7D%7Bm%7D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%5E%7B%5Bl%5D%7D%7Da%5E%7B%5Bl-1%5DT%7D+%5C%5C+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+b%5E%7B%5Bl%5D%7D%7D+%26%3D+%5Cfrac%7B1%7D%7Bm%7D+%5Csum%5Climits_i%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%5E%7B%5Bl%5D%7D_i%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=S+%3D+%5C%7B+s_1%2C+s_2%2C+%5Cldots%2C+s_%7B%7CS%7C%7D%5C%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5C%7Bz_1%2Cz_2%2C%5Cldots%2Cz_T%5C%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=3+%5Ctimes+3&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cpi&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=1%2F3&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=z_0&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+p%28z%29+%26%3D+p%28z_t%2C+z_%7Bt-1%7D%2C+%5Cldots%2C+z_1%2C+z_0%3B+A%29+%5C%5C+%26%3D+p%28z_t%7Cz_%7Bt-1%7D%3B+A%29p%28z_%7Bt-1%7D%7Cz_%7Bt-2%7D%3B+A%29%5Cldots+p%28z_1%7Cz_0%3B+A%29+%5C%5C+%26%3D+%5Cprod%5Climits_%7Bt%3D1%7D%5ET+p%28z_t%7Cz_%7Bt-1%7D%3B+A%29+%5C%5C+%26%3D+%5Cprod%5Climits_%7Bt%3D1%7D%5ET+A_%7Bz_%7Bt-1%7Dz_t%7D%C2%A0+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+l%28A%29+%26%3D+%5Clog+p%28z%3B+A%29+%5C%5C+%26%3D+%5Clog+%5Cprod_%7Bt%3D1%7D%5ET+A_%7Bz_%7Bt-1%7Dz_t%7D+%5C%5C+%26%3D+%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Clog+A_%7Bz_%7Bt-1%7Dz_t%7D+%5C%5C+%26%3D+%5Csum%5Climits_%7Bi%3D1%7D%5E%7B%7CS%7C%7D+%5Csum%5Climits_%7Bj%3D1%7D%5E%7B%7CS%7C%7D+%5Csum%5Climits_%7Bt%3D2%7D%5ET+%5Bz_%7Bt-1%7D+%3D+s_i%2C+z_t+%3D+s_j%5D+%5Clog+A_%7Bij%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmax%5Climits_%7BA%7D+%5Ctext%7B%C2%A0+%7D+%26l%28A%29+%5C%5C+%5Ctext%7Bs.t.%7D+%26+%5Csum%5Climits_%7Bj%3D1%7D%5E%7B%7CS%7C%7D+A_%7Bij%7D%3D1%2C+i+%3D+1%2C+%5Cldots%2C+%7CS%7C+%5C%5C+%26+A_%7Bij%7D+%5Cgeq+0%2C+i%2C+j+%3D+1%2C+%5Cldots%2C+%7CS%7C+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathcal%7BL%7D%28A%2C+%5Calpha%29+%3D+%26%5Csum%5Climits_%7Bi%3D1%7D%5E%7B%7CS%7C%7D+%5Csum%5Climits_%7Bj%3D1%7D%5E%7B%7CS%7C%7D+%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Bz_%7Bt-1%7D+%3D+s_i%2C+z_t+%3D+s_j%5D+%5Clog+A_%7Bij%7D+%2B+%5Csum%5Climits_%7Bi%3D1%7D%5E%7B%7CS%7C%7D+%5Calpha_i+%5Cleft%28+1+-+%5Csum%5Climits_%7Bj%3D1%7D%5E%7B%7CS%7C%7D+A_%7Bij%7D+%5Cright%29+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+A_%7Bij%7D%7D+%26%3D+%5Cfrac%7B1%7D%7BA_%7Bij%7D%7D%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Bz_%7Bt-1%7D%3Ds_i%2C+z_t+%3D+s_j%5D+-+%5Calpha_i+%5Cequiv+0+%5C%5C+%26%5CRightarrow+%5Cboxed%7BA_%7Bij%7D+%3D+%5Cfrac%7B1%7D%7B%5Calpha_i%7D%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Bz_%7Bt-1%7D%3Ds_i%2C+z_t+%3D+s_j%5D%7D+%5C%5C+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+%5Calpha_i%7D+%26%3D+1+-+%5Csum%5Climits_%7Bj%3D1%7D%5E%7B%7CS%7C%7D+A_%7Bij%7D+%5C%5C+%26%3D+1+-+%5Csum%5Climits_%7Bj%3D1%7D%5E%7B%7CS%7C%7D%5Cfrac%7B1%7D%7B%5Calpha_i%7D%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Bz_%7Bt-1%7D%3Ds_i%2C+z_t+%3D+s_j%5D+%5Cequiv+0+%5C%5C+%26%5CRightarrow+%5Calpha_i+%3D+%5Csum%5Climits_%7Bj%3D1%7D%5E%7B%7CS%7C%7D%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Bz_%7Bt-1%7D%3Ds_i%2C+z_t+%3Ds_j%5D+%5C%5C+%26%5CRightarrow+%5Cboxed%7B+%5Calpha_i+%3D+%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Bz_%7Bt-1%7D%3Ds_i%5D+%7D+%5Cend%7Baligned%7D+&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=i%2C+j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=A_%7Bij%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=z_t&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=s_j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=A_%7Bij%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Calpha_i&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=A_%7Bij%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cboxed%7B+A_%7Bij%7D+%3D+%5Cfrac%7B%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Bz_%7Bt-1%7D%3Ds_i%2C+z_t+%3D+s_j%5D%7D%7B+%5Csum%5Climits_%7Bt%3D1%7D%5ET+%5Bz_%7Bt-1%7D%3Ds_i%5D%7D%7D&bg=ffffff&fg=000000&s=2&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=n&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/05/index.png?w=1100",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/05/index2.png?w=1100",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/05/sphx_glr_plot_kmeans_silhouette_analysis_003.png?w=1100",
            "https://s0.wp.com/latex.php?latex=X&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=n+%5Ctimes+p&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=X%3DUDV%5ET&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=X%5E%5Cprime%3DXV&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=Z%5E%5Cprime&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=X%5E%5Cprime&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=Z+%3D+Z%5E%5Cprime+V%5ET&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=Z&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=C_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=D_k+%3D+%5Csum%5Climits_%7Bx%5E%7B%28i%29%7D%2C+x%5E%7B%28j%29%7D+%5Cin+C_k%7D+d%28x%5E%7B%28i%29%7D%2C+x%5E%7B%28j%29%7D%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=W_k+%3D+%5Cfrac%7B1%7D%7B2n_k%7DD_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=n_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=C_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Ctext%7BGap%7D%28k%29+%3D+%5Cmathbb%7BE%7D%5E%2A_n%5Cleft%5B%5Clog+W_k%5Cright%5D+-+%5Clog+W_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k+%3D+%5Ctext%7Bargmax+Gap%7D%28k%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Clog+W_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Clog+W_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Ctext%7Bsd%7D%28k%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=s_k+%3D+%5Csqrt%7B1%2B1%2FB%7D%5Ctext%7Bsd%7D%28k%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Ctext%7BGap%7D%28k%29+%5Cgeq+%5Ctext%7BGap%7D%28k%2B1%29-s_%7Bk%2B1%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=D_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=D_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=W_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/05/index-1.png?w=1100",
            "https://s0.wp.com/latex.php?latex=%5Clog+W_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5Cleft%5B%5Clog+W_k+%5Cright%5D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Ctext%7Bsd%7D%28k%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Clog+W_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Clog+W_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Clog+W_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5Cleft%5B+%5Clog+W_k+%5Cright%5D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=s_k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/05/index-2.png?w=1100",
            "https://s0.wp.com/latex.php?latex=%5CDelta_i&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=i&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cdelta%28C_i%2C+C_j%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=i%2C+j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=m&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=DI_M+%3D+%5Cfrac%7B%5Cmin%5Climits_%7B1+%5Cleq+i+%5Cleq+j+%5Cleq+m%7D+%5Cdelta%28C_i%2C+C_j%29%7D%7B%5Cmax%5Climits_k+%5CDelta_k%7D&bg=ffffff&fg=000000&s=2&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cdelta&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5CDelta&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=A+%3D+%5C%7Ba_1%2C+a_2%2C+%5Cldots%2C+a_n%5C%7D%2C+B+%3D+%5C%7Bb_1%2C+b_2%2C+%5Cldots%2C+b_n%5C%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=i%2C+j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=a_i+%3C+a_j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b_i+%3C+b_j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=s%5E%2B&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=s%5E-&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5CGamma+%3D+%5Cfrac%7Bs%5E%2B-s%5E-%7D%7Bs%5E%2B%2Bs%5E-%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=s%5E%2B&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b_i+%3C+b_j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=i&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b_i+%3D+0&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b_j+%3D+1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b_i+%3D+0+%3C+1+%3D+b_j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=s%5E-&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28i%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=C_i&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=a%28i%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=a%28i%29+%3D+%5Cfrac%7B1%7D%7B%7CC_i%7C-1%7D%5Csum%5Climits_%7Bx%5E%7B%28j%29%7D%5Cin+C_i%2C+i+%5Cneq+j%7Dd%28x%5E%7B%28i%29%7D%2C+x%5E%7B%28j%29%7D%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7CC_i%7C-1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28i%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28i%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=b%28i%29+%3D+%5Cmin%5Climits_%7Bi+%5Cneq+j%7D+%5Cfrac%7B1%7D%7B%7CC_j%7C%7D%5Csum%5Climits_%7Bx%5E%7B%28j%29%7D+%5Cin+C_j%7Dd%28x%5E%7B%28i%29%7D%2C+x%5E%7B%28j%29%7D%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=s%28i%29+%3D+%5Cbegin%7Bcases%7D+1-a%28i%29%2Fb%28i%29%2C+%26+%5Cmbox%7Bif+%7D+a%28i%29+%5Cleq+b%28i%29+%5C%5C+b%28i%29%2Fa%28i%29-1%2C+%26+%5Cmbox%7Bif+%7D+a%28i%29+%3E+b%28i%29+%5C%5C+%5Cend%7Bcases%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=m&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=F+%3D+%5Cfrac%7BGSS+%2F+%28k-1%29%7D%7BWSS+%2F+%28m-k%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=GSS&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=WSS&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=d_%7Bij%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28i%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28j%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=t_%7Bij%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28i%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28j%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbar%7Bd%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=d_%7Bij%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbar%7Bt%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=t_%7Bij%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=c+%3D+%5Cfrac+%7B%5Csum%5Climits_%7Bi%3Cj%7D+%28d_%7Bij%7D+-+%5Cbar%7Bx%7D%29%28t_%7Bij%7D+-+%5Cbar%7Bt%7D%29%7D%7B%5Csqrt%7B%5B%5Csum%5Climits_%7Bi%3Cj%7D%28d_%7Bij%7D-%5Cbar%7Bx%7D%29%5E2%5D+%5B%5Csum%5Climits_%7Bi%3Cj%7D%28t_%7Bij%7D-%5Cbar%7Bt%7D%29%5E2%5D%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=X+%3D+%5C%7B+x%5E%7B%281%29%7D%2C+x%5E%7B%282%29%7D%2C+%5Cldots%2C+x%5E%7B%28m%29%7D%5C%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=P_1+%3D+%5C%7B+X_1%2C+X_2%2C+%5Cldots%2C+X_r%5C%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=P_2+%3D+%5C%7B+Y_1%2C+Y_2%2C+%5Cldots%2C+Y_s%5C%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=yy&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=yn&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=P_1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=P_2&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=ny&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=P_1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=P_1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=nn&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=R+%3D+%5Cfrac%7Byy%2Bnn%7D%7Byy%2Byn%2Bny%2Bnn%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cdisplaystyle+%7B%5Cbegin%7Barray%7D%7Bc%7Ccccc%7Cc%7D%7B%7B%7D+%5Catop+X%7D%5C%21%5Cdiagdown+%5C%21%5E%7BY%7D%26Y_%7B1%7D%26Y_%7B2%7D%26%5Cldots+%26Y_%7Bs%7D%26%7B%5Ctext%7BSums%7D%7D%5C%5C%5Chline+X_%7B1%7D%26n_%7B11%7D%26n_%7B12%7D%26%5Cldots+%26n_%7B1s%7D%26a_%7B1%7D%5C%5CX_%7B2%7D%26n_%7B21%7D%26n_%7B22%7D%26%5Cldots+%26n_%7B2s%7D%26a_%7B2%7D%5C%5C%5Cvdots+%26%5Cvdots+%26%5Cvdots+%26%5Cddots+%26%5Cvdots+%26%5Cvdots+%5C%5CX_%7Br%7D%26n_%7Br1%7D%26n_%7Br2%7D%26%5Cldots+%26n_%7Brs%7D%26a_%7Br%7D%5C%5C%5Chline+%7B%5Ctext%7BSums%7D%7D%26b_%7B1%7D%26b_%7B2%7D%26%5Cldots+%26b_%7Bs%7D%26%5Cend%7Barray%7D%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=X_i&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=Y_j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cdisplaystyle+%5Coverbrace+%7BARI%7D+%5E%7B%5Ctext%7BAdjusted+Index%7D%7D%3D%7B%5Cfrac+%7B%5Coverbrace+%7B%5Csum+_%7Bij%7D%7B%5Cbinom+%7Bn_%7Bij%7D%7D%7B2%7D%7D%7D+%5E%7B%5Ctext%7BIndex%7D%7D-%5Coverbrace+%7B%5Cleft%5B%5Csum+_%7Bi%7D%7B%5Cbinom+%7Ba_%7Bi%7D%7D%7B2%7D%7D%5Csum+_%7Bj%7D%7B%5Cbinom+%7Bb_%7Bj%7D%7D%7B2%7D%7D%5Cright%5D%2F%7B%5Cbinom+%7Bn%7D%7B2%7D%7D%7D+%5E%7B%5Ctext%7BExpected+Index%7D%7D%7D%7B%5Cunderbrace+%7B%7B%5Cfrac+%7B1%7D%7B2%7D%7D%5Cleft%5B%5Csum+_%7Bi%7D%7B%5Cbinom+%7Ba_%7Bi%7D%7D%7B2%7D%7D%2B%5Csum+_%7Bj%7D%7B%5Cbinom+%7Bb_%7Bj%7D%7D%7B2%7D%7D%5Cright%5D%7D+_%7B%5Ctext%7BMax+Index%7D%7D-%5Cunderbrace+%7B%5Cleft%5B%5Csum+_%7Bi%7D%7B%5Cbinom+%7Ba_%7Bi%7D%7D%7B2%7D%7D%5Csum+_%7Bj%7D%7B%5Cbinom+%7Bb_%7Bj%7D%7D%7B2%7D%7D%5Cright%5D%2F%7B%5Cbinom+%7Bn%7D%7B2%7D%7D%7D+_%7B%5Ctext%7BExpected+Index%7D%7D%7D%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=FM+%3D+%5Csqrt%7B%5Cfrac%7Byy%7D%7Byy%2Byn%7D%5Ccdot+%5Cfrac%7Byy%7D%7Byy%2Bny%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=R%28x%29&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=i&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=i+%3C+j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28i%29%7D%2C+x%5E%7B%28j%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=X&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=Y&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=R_1%2C+R_2&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5CGamma+%26%3D+%5Cfrac%7B%5Csum%5Climits_%7Bi%3Cj%7D+%28R_1%28i%2C+j%29+-+%5Cmu_%7BR_1%7D%29%28R_2%28i%2C+j%29-%5Cmu_%7BR_2%7D%29%7D%7Bn%5Csigma_%7BR_1%7D%5Csigma_%7BR_2%7D%7D+%5C%5C+%26%3D+%5Cfrac%7Bn%5Ccdot+yy+-%28yy%2Byn%29%28yy%2Bny%29%7D%7B%5Csqrt%7B%28yy%2Byn%29%28yy%2Bny%29%28nn%2Byn%29%28nn%2Bny%29%7D%7D+%5Cend%7Baligned%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=n+%3D+yy%2Byn%2Bny%2Bnn&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=A_%7Bij%7D+%3D+%5Cexp%5Cleft%28-%5Cfrac%7B%5Cleft%5CVert+x%5E%7B%28i%29%7D+-x%5E%7B%28j%29%7D+%5Cright%5CVert%5E2%7D%7B2%5Csigma%5E2%7D+%5Cright%29&bg=ffffff&fg=000000&s=2&c=20201002",
            "https://s0.wp.com/latex.php?latex=D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=D_%7Bi%2C+i%7D+%3D+%5Csum%5Climits_%7Bj%3D1%7D%5En+A_%7Bij%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=L+%3D+D+-+A&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=L_N+%3D+D%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7DLD%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=L_N+%3D+D%5E%7B-1%7DL&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=L_N+%3D+D%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7DAD%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=k&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=X&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=Y_%7Bij%7D+%3D+%5Cfrac%7BX_%7Bij%7D%7D%7B%5Cleft%28+%5Csum%5Climits_%7Bj%3D1%7D%5En+X_%7Bij%7D%5E2+%5Cright%29%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%7D&bg=ffffff&fg=000000&s=2&c=20201002",
            "https://s0.wp.com/latex.php?latex=Y&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=x%5E%7B%28i%29%7D&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=i&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=Y&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://s0.wp.com/latex.php?latex=j&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/04/photo_2019-04-20_23-34-08.jpg?w=1100",
            "https://s0.wp.com/latex.php?latex=%5Csigma%5E2%3D1&bg=ffffff&fg=000000&s=1&c=20201002",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/04/index.png?w=1100",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/04/index2.png?w=1100",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/04/index3.png?w=1100",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2019/04/photo_2019-04-20_23-34-08.jpg?w=1100",
            "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2024/01/logo_appcair.jpg",
            "https://beginningwithml.wordpress.com/wp-content/uploads/2024/01/logo_bits.jpeg?w=150",
            "https://s2.wp.com/i/logo/wpcom-gray-white.png",
            "https://s2.wp.com/i/logo/wpcom-gray-white.png",
            "https://pixel.wp.com/b.gif?v=noscript"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Rahul Yedida"
        ],
        "publish_date": "2019-07-23T06:26:53+00:00",
        "summary": "",
        "meta_description": "Read all of the posts by Rahul Yedida on Beginning with ML",
        "meta_lang": "en",
        "meta_favicon": "https://s1.wp.com/i/favicon.ico",
        "meta_site_name": "Beginning with ML",
        "canonical_link": "http://theproductivityapp.wordpress.com",
        "text": "What we’ve discussed so far is really only the basics of neural networks (okay, maybe not just the basics, but there’s still a long way to go). At this point, you’re ready to learn different network architectures that are commonly used, after which you might go on and try designing your own! Again, we won’t go in depth here, but we will link to resources where you can learn more.\n\nConvolutional neural networks\n\nConvolutional neural networks (CNNs) are used for image processing–tasks like classification (“what is this an image of?”), segmentation (“which pixels in this image are of what object?”), and even captioning (“give a relevant caption to this image”). So far, we’ve seen dense layers (a regular layer with some nodes, fully connected to the previous and next layers), dropout, and batch normalization layers. CNNs use some additional layers–convolutional and pooling layers. Convolutional layers use a number of filters (matrices, usually about 3 x 3 or 5 x 5) at each layer. To perform a convolution, you start by overlaying the filter on the image, multiplying each overlapping square, and summing them up. This gives you one number, the first element of the first row of the result. Then, you move the filter across the image and repeat, giving you the rest of the result. This blog shows a nice animated visualization of the process. Pooling layers are used to reduce the size of the image. In such a layer, you take the top 2 x 2 square (for example) of your image, and pool it–you can take the max (called max-pooling) or average (called average pooling). Very frequently, you’ll see conv layers followed by pooling layers, and then batch norm and dropout layers.\n\nRecurrent neural networks\n\nThe basic idea in recurrent neural networks is to use loops in the architecture (making it recurrent). There are several different ways you can arrange such cells, creating either regular recurrent neural networks, long short-term memory (LSTMs), or gated recurrent units (GRUs). LSTMs are the most popular among these, though they are a little complex.\n\nGenerative adversarial networks\n\nGenerative adversarial nets (GANs) are used to generate realistic images, say of faces, sceneries, or pretty much anything. The idea is to use two different neural networks–a generator that generates images, and a discriminator that is essentially a classifier, and reports either “true image” or “fake image”. These two are trained together, and are the adversaries of each other–the generator wants to “fool” the discriminator into thinking a fake generated image is a real one, and the discriminator wants to get better at spotting the fake ones. GANs typically take a long time to train, and one of the reasons is that initially, the generator starts off random, so the discriminator’s job is pretty easy–so they both kind of suck–and now you have a case of the blind leading the blind. This blog does a good job of detailing the different kinds of GANs that are in use. Dr. Saha’s notes detail the math behind GANs.\n\nCourses\n\nI’d recommend you start with the Deep Learning Specialization on Coursera, a series of five courses to get you up to speed on the subject. Don’t worry if it seems like a lot of work–we’ve covered a lot of material from the first two, so you can probably watch those two courses at 1.5x or maybe even 2x. The third course gives some practical advice about using neural networks. It’s not required, but it’s handy to learn the information that’s presented there. Course 4 discusses convolutional neural networks in detail, along with some common architectures, and course 5 discusses recurrent neural networks, GRUs, and LSTMs. Along the way you’ll also learn to use two popular frameworks, TensorFlow and Keras.\n\nNext, you can watch the two courses by fast.ai, where the emphasis is on getting you started using neural network, while also showing you the inner workings and other neat tricks. Here, you’ll learn to use another framework called PyTorch (which, in my personal opinion, is the best, along with Keras, but I don’t want to bias you).\n\nSo you have a neural network, and it’s doing okay. How do you improve its performance? Here, we’ll briefly go over some techniques commonly used to improve the performance of neural networks. I’ll only give a high-level overview here, and then link to the original papers that proposed these that provide more details.\n\nDropout\n\nPaper: Srivastava, Nitish, et al. “Dropout: a simple way to prevent neural networks from overfitting.” The journal of machine learning research 15.1 (2014): 1929-1958.\n\nDropout is a regularization method used to reduce overfitting in deep learning models. The core idea is to temporarily remove some nodes randomly during training (along with all of its incoming and outgoing weights). During test time, none of the nodes are removed, but the weights are scaled appropriately. In dropout, each node in the network is dropped out with probability .\n\nThe idea behind dropout is to make the network robust to noise. In practice, between 0.2 and 0.5 work well. During training, both during forward prop and backprop, the dropped out units are not considered.\n\nBatch normalization\n\nPapers:\n\n[1] Ioffe, Sergey, and Christian Szegedy. “Batch normalization: Accelerating deep network training by reducing internal covariate shift.” arXiv preprint arXiv:1502.03167 (2015).\n\n[2] Santurkar, Shibani, et al. “How does batch normalization help optimization?.” Advances in Neural Information Processing Systems. 2018.\n\n[3] Salimans, Tim, and Durk P. Kingma. “Weight normalization: A simple reparameterization to accelerate training of deep neural networks.” Advances in Neural Information Processing Systems. 2016.\n\nBatch normalization, as the name suggests, is a method that normalizes the inputs to a hidden layer. You add batch normalization layers in between layers of a network, and it normalizes the outputs of the preceding layer. This normalization is done by subtracting the mean and dividing by the standard deviation. After normalizing, the result is scaled and shifted. From the paper, the algorithm is below:\n\nNote that when we scale and shift, the parameters there are learned–they aren’t fixed. You can use gradient descent to learn these parameters for each batch norm layer. These parameters ensure that it is possible to represent the identity transformation across layers.\n\nNow a concept we haven’t discussed–what’s a mini-batch? Typically, deep neural networks require a lot of data. More than might fit in your RAM. In such a case, you can’t simply run gradient descent with all the data at once. Instead, you split your data into mini-batches, typically of size 64 or 128. You run forward prop on each batch, compute the cost for that batch, and run backprop. You do this for all the batches, and when you’re done, you’ve completed one epoch, or pass over the entire training set. In general, the smaller your batch size, the slower your training will be, but sometimes, with large datasets, you need small sizes.\n\nSo why does batch normalization work? In their paper, Sergey and Christian explained that as the weights of the network change, the distributions of the inputs at each layer change: a phenomenon they called internal covariate shift. This phenomenon, they stated, “slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities”. However, this was later proven to be wrong. In 2018, a NIPS paper revealed that this was incorrect, showing instead that batch norm makes the loss landscape more smooth, making training easier. For those of you more mathematically fluent, by “smooth”, we mean it improves both the Lipschitzness of the loss and the -smoothness.\n\nA related work to batch normalization is weight normalization [3], which reparameterizes the weights in neural networks and is more applicable to recurrent neural networks.\n\nInitialization methods\n\nPaper: He, Kaiming, et al. “Delving deep into rectifiers: Surpassing human-level performance on imagenet classification.” Proceedings of the IEEE international conference on computer vision. 2015.\n\nIt turns out that the way you initialize the weights randomly in the beginning can also have an effect on how fast you can train your network. The seminal 2015 paper by Kaiming He et al. introduced a new activation function, called PReLU (parameterized ReLU), as well as a new initialization method. Typically, initialization schemes followed the “Xavier” initialization method. If is the number of units in layer , Xavier initialization uses a uniform random initialization with variance for the weights in layer . He et al. proved that for ReLU networks, the mathematically sound way to initialize the weights is to use a variance twice of that–a fact they prove in their paper.\n\nData augmentation\n\nLike we said earlier, more data is better. Data augmentation does exactly that–uses your existing data and creates more. This discussion is more pertinent with image data, which is where this is most widely used. With images, in a lot of cases, you can flip, shift, or slightly rotate the image to get something that looks similar. For example, suppose you have a picture of a tiger:\n\nNow suppose we vertically flip this image:\n\nIt still looks like a tiger, so we expect the network to recognize both of these images as tiger. We could also rotate the image clockwise and counterclockwise by say 5 or 10 degrees. Further, we could perform random cropping (in a way that ensures the tiger is present in all the crops). This way, we get a much bigger dataset.\n\nEarly stopping\n\nPaper: Smith, Leslie N. “A disciplined approach to neural network hyper-parameters: Part 1–learning rate, batch size, momentum, and weight decay.” arXiv preprint arXiv:1803.09820 (2018).\n\nThere’s a common misconception in deep learning that if your training error is less than your validation error, then you’re overfitting–this is wrong! If your training error is more than your validation error, something is probably going wrong–you might want to train longer, for example. A good sign of overfitting is to look at the plot of the loss over epochs.\n\nHere’s an example from the paper above. Both curves plot the validation loss over epochs (here, two learning rate scheduling mechanisms are compared: read the full paper for more information). Notice how the blue line consistently has a downward slope to it–this means it’s still underfitting. When the line becomes horizontal, you’re done training. When, as with the red line, it starts going up again, you’re now overfitting. So the idea place to stop is when the validation loss stops decreasing for a few epochs, and instead starts increasing. This is called early stopping. The takeaway here is this: more epochs is not necessarily better.\n\nLearning rate scheduling\n\nPapers:\n\n[1] Smith, Leslie N. “Cyclical learning rates for training neural networks.” 2017 IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE, 2017.\n\n[2] Seong, Sihyeon, et al. “Towards Flatter Loss Surface via Nonmonotonic Learning Rate Scheduling.” UAI. 2018.\n\n[3] Yedida, Rahul, and Snehanshu Saha. “A novel adaptive learning rate scheduler for deep neural networks.” arXiv preprint arXiv:1902.07399 (2019).\n\nI’m particularly excited to talk about this, partly because I’ve recently been working on this. There have been several new learning rate scheduling methods proposed, so that rather than use a fixed learning rate, you change it over time. A common method is to use some kind of decaying learning rate. In 2017, Leslie Smith proposed cyclical learning rates, where the learning rate varies periodically between two bounds. Additionally, he also proposed a 1cycle learning rate policy, where the learning rate is varied between the lower and upper bounds in one cycle over all the epochs. In 2018, Sihyeon Seong et al. took this further, detailing how any non-monotonic learning rate scheduling mechanism works well.\n\nFinally, a few months ago, Dr. Saha and I proposed the LipschitzLR policy (though in the paper above, we hadn’t come up with a name yet). The LipschitzLR policy is different in that you don’t use an equation to determine the learning rate at some epoch–well, okay, you do, but the equation isn’t a function of which epoch you’re on, like the other policies discussed here–it’s a function of the activations and the data–which means that for different datasets, you get (slightly) different curves. More importantly, you get higher learning rates while still converging to a good solution. Our paper shows the math behind this, but given what we’ve covered so far, it shouldn’t be hard to understand.\n\nSummary\n\nWe’ve discussed different ways to improve model performance: dropout, batch normalization and (briefly) weight normalization, early stopping, and some learning rate scheduling schemes. You don’t need to use all of these–a lot of papers don’t, in fact. Deep learning is a very empirical process, so you’ll need to figure out what works best for your application.\n\nSo we’ve discussed what neural networks are, how forward prop and backprop work. The only thing left now is the choice of activation function. We’ve already discussed the sigmoid activation. In practice, modern neural networks don’t use sigmoid in all the layers–typically, only the last layer uses sigmoid activations, and only when the problem is a binary classification one. Similarly, when our problem is multi-class classification, we use the softmax activation function, and the gradients are similar to what we derived when discussing softmax regression.\n\nSo what about the middle layers? Remember how in the beginning, we said that one of the reasons that deep neural networks (deep simply means that there are many layers) are popular is the ReLU activation function? Let’s look at it. The ReLU is defined as\n\nSo it’s essentially a linear layer, except that the negative side has been “rectified”–forced to zero. That one change makes this function non-linear, and make neural networks much better. And if you’re wondering why, so is everyone else. At this point, we’re still understanding how and why neural networks work as well as they do, and it’s an active research area. In my opinion, this recent paper does a good job at explaining the success of ReLU. Essentially, it says that as you build deeper networks using the ReLU activations, you can get many more piece-wise linear regions. So suppose you had a complex function. This could be a decision boundary in classification problems, or the function you want to regress over (for regression problems). Now any function can be approximated arbitrarily well using many piece-wise linear functions. So the deeper you build your network, the more piece-wise linear regions you get, and the better you can approximate your function.\n\nSo why couldn’t we have just used a simple linear activation function, ? Let’s see what happens after two layers with this activation:\n\nThe first term is simply some new matrix, say , times . And the second term is a vector whose dimensions equal , the same as . So even with two layers, we’ve ended up with the equivalent of what you’d do with just one layer.\n\nNow you might notice that the ReLU activation isn’t differentiable at 0, which is a problem since we need to compute its gradient. During implementation, we arbitrarily set it to either 0 or 1, and it doesn’t really matter what you choose.\n\nThere are other activation functions as well:\n\nis sometimes used instead of sigmoid\n\nA recently proposed activation by Dr. Snehanshu Saha is the Saha-Bora activation function (SBAF): . This function is flexible because you can change its shape with its two parameters, and under certain conditions, it can approximate the sigmoid and the ReLU activations rather well.\n\nAnother proposed activation is the A-ReLU (approximate ReLU), . The parameters of this function can be tweaked to approximate ReLU, while making sure that the function is everywhere differentiable.\n\nAnother activation function sometimes used is the Exponential Linear Unit (ELU). It is defined as\n\nVanishing gradient problem\n\nLet’s look at the sigmoid activation function now. Specifically, let’s look at its derivative.\n\nWhat happens when gets large? Then , and therefore , and we have . Similarly, when is very small (that is, high in magnitude, but negative), then . This is a problem. But there’s another problem. What’s the maximum value of the gradient? A little calculus helps here:\n\nYou should compute the second derivative of to convince yourself that this is a maximum. Therefore, the maximum value of the gradient is . So as we perform backprop, layer by layer, these gradients will get multiplied and thus get smaller and smaller. The deeper the network, the smaller the gradients, and the bigger this problem. This problem is called the vanishing gradients problem. This is precisely why networks using only the sigmoid activation have trouble learning well.\n\nReLU doesn’t suffer from this problem technically, since its gradients are either 0 or 1. But it has its own curious problem, called the dying ReLU problem. In this situation, all the inputs to a particular neuron are such that the output is 0, and so the gradient is also 0 and this neuron never really learns (since during weight update, the gradient is 0). This is rare, but happens rarely and can render a network less effective.\n\nTo make sure this never happens, an activation function called the leaky ReLU was proposed. Rather than force the output to 0 on the negative side, we allow a small amount to “leak”. So when , , and we could use any constant instead of 0.01. Now how do we choose that constant? We could certainly try some values and see what seems to work best. Alternatively, we could learn that constant using gradient descent! That’s exactly what Kaiming He et al. proposed in 2015, in their stunning paper, “Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification”. Beyond mentioning that this is how PReLU (Parametric ReLU) works, however, we won’t discuss it further. Like we said before, we can’t go down every rabbit hole.\n\nWrapping up\n\nNow we’ve seen a couple of other activation functions and when they’re used. Next, we’ll look at some other aspects of training and working with neural networks.\n\nNeural networks are quickly becoming omnipresent for many tasks, including image recognition, text summarizing and synthesis, and speech recognition. There are a couple of reasons why they’ve become so popular in recent years: first, we have a lot more data these days than earlier, and this means learning algorithms have more to learn from; second, computers are more powerful now, and hardware support in the form of GPUs makes neural networks significantly quicker to train; finally, a new “activation function” called ReLU (rectified linear unit) made neural networks significantly better at a lot of tasks.\n\nBecause of the depth of the field and the pace at which research in “deep learning”, as it is called, is progressing, it is practically impossible to concisely discuss all of neural networks in anything less than a (rather fat) book. We will certainly not go down every rabbit hole we see; rather, we will look at the foundations of neural networks–what are the building blocks, how does learning take place, and a few other questions that might arise. We will link to external content to help you learn so that you’re not left dangling not knowing where to go next. Unfortunately, even with just an overview, this will be a long post. Let’s start by talking about neural networks.\n\nIntroduction\n\nAt a very high level, neural networks are a black box. They take in some inputs, do some magic, and then give you outputs that are extraordinarily accurate.\n\nThis is a high-level, don’t-care-about-any-details, diagram of neural networks. You chuck some data at it to train it. Later, you can give it inputs and expect highly accurate outputs. Those circles that you see are typically called nodes or neurons. The idea is to simulate what goes on in the human brain. Arrows in diagrams like this represent weighted connections. Let’s now open that box in the middle.\n\nInside, you simply have more neurons! These neurons are organized in layers, with the connections connecting neurons in one layer to neurons in the next. Images like the one above give the impression that every neuron is necessarily connected to every other. This certainly need not be the case. In fact, you could also have connections jump over layers–we call these skip-connections. However, beyond simply mentioning that, we will not discuss it further.\n\nOnwards, then. We have a layer that collects inputs. These input layer nodes do something, and pass the results on to so-called hidden layers. Those hidden layers in turn do something, and pass the results forward, until you get outputs. In theory, you could customize what every neuron in every layer does; in practice, that becomes cumbersome, and we only do such customizations layer-wise, meaning that all neurons in one layer will perform the same operation.\n\nWhat does each neuron do, then? If you see the figure above, each neuron receives several inputs from weighted connections. We specifically used the term weighted connections, because the inputs are not treated equally. So a neuron will first add up all the inputs that it gets, but it will perform a weighted sum. After performing a weighted summation, the neuron ends up with a single number. It then computes a function of that number, and the result of that is the neuron’s final output–the one that it broadcasts to whatever it happens to be connected to at future layers. So loosely, a neuron does this:\n\nThose terms are called the weights. Shortly, we will see that it is those weights that we learn using gradient descent. The function is called the activation function. This name is partly historical: in the earlier days of neural networks, this function gave an output of 1 if the weighted sum was higher than a set threshold, and gave output 0 otherwise, and the neuron was “activated” if the weighted sum was above that threshold.\n\nSo given inputs, the input layer neurons will forward the inputs to the first hidden layer, which compute a weighted sum, compute the activations (the results of the activation function), and pass these to the second hidden layer. The neurons in this layer will in turn do the same thing, and so on until you get outputs. So far so good. This process is called forward propagation, and is the first step used in gradient descent while training a neural network. Recall how in algorithms like linear regression, you had to compute the output of the model, then compute the gradients, then update the weights. We do exactly the same thing here, except that computing the model outputs is a more elaborate process.\n\nWe will not use the notation above, though, because it gets very confusing very quickly what weights and what inputs we’re talking about. Here’s the notation we will use instead. will still represent the activation function; but since the activation used can be different at each layer, we will be explicit about that, and write to denote the activation at layer . We won’t actually care about the outputs of individual neurons; rather, we will look at the outputs of an entire layer (which will of course, be a vector). We will represent the weighted sums computed by the neurons at a layer by , and the outputs (the activations) by . The inputs will simply be denoted by the vector , and to simplify things, we let . At each layer, the weights form a matrix, where the first row corresponds to the weights of the outputs from the first neuron, the second row corresponds to the weights of the outputs from the second neuron, and so on. We will represent this by . We will denote the number of layers by , and the number of neurons at layer by . What do we mean by “number of layers”? In the diagram above, how many distinct layers of neurons do you see? Four, right? But of course it wouldn’t be that easy! The number of layers there are three, because the layer of inputs aren’t counted as an actual layer (since those neurons aren’t really doing anything).\n\nAlright, so let’s put that notation to use. At a given layer , the computations performed are:\n\nThis is because has dimensions , and , , and have the dimensions .\n\nBack to forward propagation now. We first compute weighted sums, now represented as a matrix multiplication, and then compute the activations from those weighted sums. But what are those terms? Recall that in linear regression, we would add a term so that we could add a constant and that would allow us to write ? In neural networks, we don’t add that extra input, and explicitly represent that constant term–we call this constant term the bias. Typically, all the neurons in a layer use the same value of the bias, so is technically a real number, but because the result of the multiplication is a vector, we simply create a vector of the same dimensions, where every value is that same bias. Now, given all this information, let’s recap what happens at each layer once again, so it really sticks in your head:\n\nEach neuron computes a weighted sum of its inputs.\n\nTo this weighted sum, it adds a bias.\n\nIt finally computes an activation function of the sum computed above.\n\nThe above summarizes what forward propagation in a neural network does. You do this for all layers until you get the outputs.\n\nNow that we have the outputs, we need to perform the next step in gradient descent: compute the gradients. We do this via backpropagation. Let’s cover this now.\n\nBackpropagation\n\nLet’s start off by being clear what we want to achieve here. What are we computing the gradients of, exactly? Well, we can’t change the inputs. We certainly cannot change the activation function that is used. All that’s left then, are the weights and the biases. Note how these are key to the output produced by the network (these, and the activation, of course, but more on that later). These are what we compute the gradients with respect to, and then update in gradient descent. Therefore, the parameters of a neural network are the weights and the biases.\n\nWe can’t directly compute the gradients with respect to the weights in the first few layers. Because of the way that we computed the outputs, left to right, we have to compute the gradients in the reverse order–from right to left–and that’s what gives this step its name. Let’s now discuss how we compute the gradients. Essentially, we simply use the chain rule. Here’s how we compute the gradients with respect to the weights in the last layer:\n\nSimilarly, we can continue and compute the gradients with respect to the penultimate layer:\n\nWe simply continue this way till we hit the first layer. Now, at a first glance, this seems very complicated. As you’ll soon see, all of these derivatives are very simple terms, and it becomes quite easy to calculate the gradients that we need for gradient descent. To see that these are indeed simple, let’s consider the problem of binary classification. We will use the binary cross-entropy loss as before. For now, we’ll assume that every activation function is the sigmoid function–a function that we’ve encountered before while discussing logistic regression. We’ll compute all the terms in the equation above, and you should be able to carry on the calculations for more layers if you want to.\n\nThat was the first term. Let’s compute the second term.\n\nThe second step shouldn’t be new to you: we did this already when discussing logistic regression. Notice how this cancels out the denominator from the previous term. Our next term is also easy to compute:\n\nThe next term is the same as for the last layer, so we won’t repeat that calculation: all you need to do is change the layer numbers in the superscripts. And now the final piece:\n\nThat transpose is a matrix calculus rule. Obviously, the derivatives with respect to the biases end up being 1, so we haven’t done those calculations. To really let the concept sink in, let’s multiply the terms that we derived above and actually write out the gradients of the loss with respect to our parameters.\n\nThe first part here is a combination of the first two terms. For the last part, we needed . We did calculate this, but we calculated it for the previous layer. So our result is the same, but we simply change the superscript to reflect the correct layer. If you’re not convinced fully, write the chain rule expression for the gradient with respect to the weights, and compute each term.\n\nMoving on, we have\n\nand\n\nOkay. That was the last of it. Let’s quickly do a sanity check to make sure that this does make sense. By sanity check, we simply mean ensuring that all the dimensions agree so that the matrix multiplications work. Both the outputs and the targets have dimensions , which is thus also the dimension of . The dimension of is . So this doesn’t work quite so well. It turns out that the right form for this is:\n\nLet’s work out the dimensions here. has dimensions . has dimensions , and thus the first part (before the symbol) has dimensions . Now, has dimensions , and the multiplication proceeds smoothly. Note that the symbol denotes element-wise multiplication, not a matrix multiplication.\n\nMore generally, we have\n\nIf we had multiple training examples and we vectorized this code, the equations would be pretty much the same, with two changes:\n\nA much more detailed discussion of backprop is done by Andrew Ng in his Coursera course.\n\nFurther reading\n\nDr. Saha’s notes on neural networks discuss forward and backward propagation in more detail. You can download Part 1 and Part 2 from our OneDrive.\n\nConclusion\n\nWe could go on and on forever, but we do need to stop at some point, and this is where we’ll break. In this post, we discussed what neural networks are, and how gradients are computed for gradient descent. We will discuss some more aspects about neural networks in the next few posts.\n\nLet’s now look at a popular model for time-series data. Time-series data means data in a sequence, where the order of the elements has some meaningful interpretation. For example, the weather across the days of a week is time-series data; weather across random days of a year is not. Time-series data presents interesting challenges, because the value of some element typically relies on elements preceding it.\n\nIn this post, we’ll talk about Markov models. Let’s discuss notation. Let represent the possible states that you can observe. In our weather example, we might have sunny, rainy, and cloudy states. Suppose we are given a sequence with elements: . We’ll make the assumption that the time-series data came from a Markov chain.\n\nIn a Markov chain, the assumption is that the value of the current element depends only on the preceding one, and not the others. A Markov chain has a transition matrix, which holds the probability values for each transition. Continuing our weather example, the transition matrix would have probabilities that today will be sunny, cloudy, or rainy, given that yesterday was any of these. So this transition matrix will be . Another assumption of Markov chains is that this transition matrix remains constant over time.\n\nWe can also have a parameter representing the initial state distribution, denoted by . For our weather example, we might choose to simply leave it as for all 3 weather states. Now given a state sequence, we can compute its probability.\n\nProbability of a state sequence\n\nIf is the start state, then\n\nThis shouldn’t be too hard to follow. The first step comes from the assumption that the data comes from a Markov chain, so only the preceding element is required in the conditional probability.\n\nSo finding the probability of a state sequence given the parameter isn’t very hard, but it raises the question: how do you find it in the first place? We’ve already covered this concept:\n\nMaximum likelihood parameter assignment\n\nLet’s define the log-likelihood of the Markov chain:\n\nWe need to carefully note that each row of the transition matrix must add up to 1. Further, all these probability values must be non-negative. Our optimization problem is\n\nOur Lagrangian looks like this:\n\nIt’s quite easy to solve for the parameters analytically. Let’s take the partial derivatives and set them to 0 to get them:\n\nLet’s briefly review. For the first equation, we could collapse the first two summations because for all the sum indices except the specific that we’re interested in, becomes a constant. It can be a little confusing in the beginning, but you’ll get used to it. We essentially use the same collapsing trick with the next equation, noting that can only equal one particular , removing the need for both that term in the Iverson notation and the corresponding summation. For the last derivation, we also used the previously obtained value of .\n\nNow we substitute the values of in the equation for :\n\nThis is very intuitive. It says that to find the probability of a transition from one state to another, look at the sequence you have for times when you made this transition (the numerator), and to get a probability, divide this by the number of times you were in the first state (the denominator).\n\nWe’ll very briefly mention here that this is pretty much exactly what n-gram models in Natural Language Processing do (if you don’t know what n-grams are, skip this paragraph). Recall that in an n-gram model, to find the probability of say, a bigram, you essentially compute conditional probabilities, which evaluate to what we derived above. Even in NLP, you could use MLE to compute the n-grams, and you’d arrive at the same formula above, though you might use different notations.\n\nAn observant reader would notice that we haven’t talked much about our initial state distribution. This is something that you have to set up, maybe by looking at historical data. So you might look at the weather over the last 5 years, and say, “Okay, it’s been sunny about 70% of the days, cloudy about 10%, and rainy about 20% of the days, so let’s assign the initial state distribution as 0.7 for sunny, 0.1 for cloudy, and 0.2 for rainy.”\n\nConclusion\n\nWe’ve talked about an interesting time-series model, Markov Models. These model Markov chains, which have many other uses as well, most notably, Markov Chain Monte Carlo (MCMC). Next, we’ll discuss another variant of Markov models: Hidden Markov Models (HMMs).\n\nNow that we know how to cluster data, let’s look at how many clusters is a good idea. Clustering is typically used as an exploratory device to see if there’s any structure in the data. In some cases, though, it may be useful to know a priori how many clusters may be there. Several methods exist to find out the number of clusters, and we will discuss them here.\n\nElbow method\n\nThe elbow method is a rather simple method of computing an ideal number of clusters. The idea is simple–for k=1 to 10 clusters (say), compute some metric, like the pseudo-F (popular for hierarchical clusters) or the sum of within-cluster sum of squares (for k-means, the within cluster sum of squares (WSS) may be taken as the sum of squares of distances from each point to the center).\n\nYou plot these values against the number of clusters. Typically, you will see a bend, or an “elbow”. The elbow is the point at which adding more clusters doesn’t help explain more. You can also plot the percentage of variance explained, which is derived from the WSS. Note that if you do not see a noticeable elbow, there probably aren’t any distinct clusters in the data. This is a visual test for that. Let’s implement this. We’ll build on our k-means clustering code from before. Let’s write a WSS function:\n\ndef WSS(): \"\"\" Finds the sum of all within-cluster sum of squares \"\"\" sum_ = 0 for i in range(len(C)): center = C[i] for j in clusters[i]: point = x[j] sum_ += distance(point, center) return sum_\n\nWhere all the other variables and functions are as defined previously. Now, we can write some code to generate random initial centers, cluster the data, and compute the error for 1 to say 5 clusters. You might get a slightly wonky curve, but that’s alright. The code sometimes gives nan values in the centers–this happens when there’s an empty cluster, so there’s a division by 0–we will not fix that here, but the fix is to simply add a condition to check for empty clusters, and ignore them. It’s not usually an issue, and for our case, you can simply re-run the code to make sure this doesn’t happen.\n\nerrors = [] for i in range(1, 6): # up to 5 clusters n_clusters = i lower_limits = [min(x.T[i]) for i in range(x.shape[1])] upper_limits = [max(x.T[i]) for i in range(x.shape[1])] C = [[np.random.uniform(lower_limits[i], upper_limits[i]) for i in range(x.shape[1])] for _ in range(n_clusters)] for _ in range(5): # number of steps step() errors.append(WSS())\n\nWe find the lower and upper limits of each dimension (our points were 2-dimensional, if you recall). We then make random centers, and run our clustering algorithm for 5 steps. You can run it longer if you wish. We gather all the error values to plot later. Let’s plot the elbow curve:\n\nplt.plot(range(1, len(errors)+1), errors, 'ro--');\n\nOne would think both 2 and 4 are elbows, but we choose 4 clusters here because there still is a pretty big dip from 3 to 4. Let’s now plot the clusters and their centers for 4 clusters. To do this, let’s run the above code again, removing the loop:\n\nn_clusters = 4 lower_limits = [min(x.T[i]) for i in range(x.shape[1])] upper_limits = [max(x.T[i]) for i in range(x.shape[1])] C = [[np.random.uniform(lower_limits[i], upper_limits[i]) for i in range(x.shape[1])] for _ in range(n_clusters)] for _ in range(5): # number of steps step()\n\nAnd now we can plot the clusters:\n\nplt.scatter(x.T[0], x.T[1], c=assign_clusters(x)); plt.plot(np.array(C).T[0], np.array(C).T[1], 'rx');\n\nThis seems like a reasonable clustering. You might get slightly different clusters as well.\n\nSilhouette method\n\nIn this method, you could do one of two things. You could use the silhouette index as a metric and use the elbow method described above. Alternatively, you could create a silhouette plot. A silhouette plot can be thought of as a specially organized horizontal bar graph. Points in the same cluster are grouped together, and within each cluster, the silhouette values are arranged in descending order. Here’s what it looks like (image taken from sklearn documentation).\n\nThe red vertical line is optional–it is the silhouette index (recall that this is the average of all the silhouette values). If all the blobs end to the right of the red line, then this is a good clustering. The linked documentation also has code to generate this plot.\n\nGap statistics\n\nThe Gap statistic was proposed by Tibshirani et al. in their 2001 paper at Stanford University. It’s based on comparing the error with that of a null reference distribution–a set of data points generated by a distribution so that there is no obvious clustering. The paper suggests two ways of getting a null reference distribution:\n\nGenerate uniform data for each of the features of the data. This is easy to implement and straightforward.\n\nGenerate uniform data from a uniform distribution, along the principal components of the data. Quoting the paper (page 4):\n\nIn detail, if is our data matrix, assume that the columns have mean 0 and compute the singular value decomposition . We transform via and then draw uniform features over the ranges of the columns of , as in method a) above. Finally we back-transform via to give reference data .\n\nThe second is slightly more complex, but as the paper notes, “takes into account the shape of the data distribution and makes the procedure rotationally invariant, as long as the clustering method itself is invariant.” First, for every cluster , we compute the sum of all pairwise distances:\n\nWe then find the normalized distance:\n\nwhere is the number of points in cluster and we divide by two because each pair is considered twice in the summation. Formally, the Gap statistic is defined as:\n\nEssentially, the first term is the one for the null reference distribution, and the second one is for the real data. We choose . More specifically, we generate null reference datasets, and compute the average of for each of them. These values of will also have a standard deviation, . Accounting for the simulation error, we compute:\n\nWe choose the smallest such that . Let’s now implement this. We’ll first implement .\n\ndef Dk(i): return np.sum([distance(x[pair[0]], x[pair[1]]) for pair in list(itertools.combinations(clusters[i], 2)) ]) / len(clusters[i])\n\nWe use the itertools package to get all pairs of points within a cluster, and use the formula for . Note that we use the combinations function, which treats the pairs (a, b) and (b, a) as the same, so we don’t get all pairs twice. For this reason, we remove the 2 in the denominator. We can now implement :\n\ndef Wk(): return np.sum([Dk(i) for i in range(len(C))])\n\nWe’ll make a dataset using sklearn here:\n\nX = make_blobs(500, cluster_std=1.3)[0]\n\nAnd plot it:\n\nplt.scatter(X.T[0], X.T[1])\n\nLet’s create a variable for the number of features:\n\ndimensions = X.shape[1]\n\nAnd some variables required to compute the Gap statistic:\n\nWks = [] Ewks = [] sds = [] B = 10\n\nThe first stores all the values for each . The second stores all the values. The third stores all the values. The rest of the code isn’t too hard:\n\nfor i in range(1, 5): # up to 4 clusters n_clusters = i # First, run the clustering on actual data x = X lower_limits = [min(x.T[i]) for i in range(x.shape[1])] upper_limits = [max(x.T[i]) for i in range(x.shape[1])] C = [[np.random.uniform(lower_limits[i], upper_limits[i]) for i in range(dimensions)] for _ in range(n_clusters)] for _ in range(5): # number of steps step() Wks.append(np.log(Wk())) Bwks = [] # Now, on the null reference data for j in range(B): # Generate a dataset of 30 samples x = np.array([[np.random.uniform(lower_limits[i], upper_limits[i]) for i in range(dimensions)] for _ in range(30)]) # Generate initial centers C = [[np.random.uniform(lower_limits[i], upper_limits[i]) for i in range(dimensions)] for _ in range(n_clusters)] # Cluster for _ in range(5): step() Bwks.append(np.log(Wk())) Ewks.append(np.average(Bwks)) sds.append(np.sqrt(np.var(Bwks)))\n\nWe know there are supposed to be 3 clusters. We check for up to 4. Since all the functions we used for k-means clustering assume that the x (lowercase) variable stores the data, we set it to our data, X. We compute the lower and upper limits for each dimension. We set up some random centers and cluster by running 5 steps. Finally, we compute and add it to the list.\n\nNext, we do this exact same thing for the null reference data. We create a variable called Bwks that stores the for each of the reference datasets. Each time in the loop running times, we create a uniform null reference set (method (a)), set the lowercase x variable to that, and then create random centers. We then cluster and find the value for this null reference dataset. We append the average of these to the list that stores . We also compute the standard deviation, which is the square root of the variance.\n\nNow, let’s compute :\n\nsks = [np.sqrt(1 + 1./B) * i for i in sds]\n\nNow, we can compute the Gap statistics:\n\nGaps = [Ewks[i] - Wks[i] for i in range(len(Wks))]\n\nAnd plot this:\n\nplt.plot(range(1, len(Gaps)+1), Gaps, 'ro--');\n\nIt seems like 3 might be a good number of clusters. Let’s check if it fulfills our other criterion as well:\n\nfor i in range(len(sks)-1): print('for k =', i+1, ', Gap(k) >= Gap(k+1) - s(k+1) is', Gaps[i] >= Gaps[i+1] - sks[i+1])\n\nThis for me shows:\n\nfor k = 1 , Gap(k) >= Gap(k+1) - s(k+1) is False for k = 2 , Gap(k) >= Gap(k+1) - s(k+1) is False for k = 3 , Gap(k) >= Gap(k+1) - s(k+1) is True\n\nTherefore, we pick the number of clusters as 3.\n\nNote: I’m not sure why the Gap statistic values here (on the y-axis) are negative. I’m pretty sure it has something to do with the way we’ve computed it, but it’s possible there’s an error in what we’re doing. If so, please tell me about it. You can find another implementation for the Gap statistic in this blog.\n\nClosing thoughts\n\nWe’ve covered a lot of ground in clustering, ranging from several popular clustering algorithms to clustering metrics and even finding an optimal number of clusters. But how do we know if the data is “clustered enough”, or “strongly clustered”? This Stack Exchange answer gives an overview. Essentially, the idea is to use statistical methods to “resample” from your dataset. Alternatively, the answer claims you could add small amounts of noise to your data, and re-run the clustering algorithm. Then, you use a metric called the Jaccard similarity index to check how many points remain in the same cluster despite this.\n\nWith this, we stop our discussion of cluster analysis, and move on to other topics.\n\nHow do you check the “goodness” of clusters? Can we use these metrics to identify an ideal number of clusters? We discuss the answers to these questions in this post. First, what makes a set of clusters “good”? Ideally, we want within-cluster variance to be low, and the between-cluster variance to be high. In other words, the within-cluster distance should be low, and the distance between clusters should be high.\n\nWe’ll discuss several metrics here. The metrics listed here are not at all exhaustive, but are the most commonly reported and used.\n\nClustering metrics\n\nHow do we define the distance between or within clusters? Is it the maximum distance between any two points? The minimum? Or perhaps the mean or median? We can use any of these, and what you choose depends on what your goal is. Let’s now look at some clustering metrics.\n\nGeneralized Dunn index\n\nWikipedia has an excellent article on this [1], so we’ll follow the notations used there. Suppose we use a within-cluster distance metric for cluster . This can be the maximum, minimum, or mean/median of all this distances between two (distinct) points in the cluster. You could also compute the average distance between all points and the cluster mean. Now, let denote the distance (with any definition) between clusters . Then, for clusters, the Generalized Dunn index (GDI) is defined as\n\nHow we choose these distances depends on our goal. When we use something like k-means, which aim for globular clusters, the mean or maximum distance between any two points within a cluster seems like a reasonable within-cluster distance, and the minimum distance between any two points seems like a reasonable between-cluster distance. For density-based and spectral clustering, the reverse seems like a reasonable choice.\n\nThe Generalized Dunn index is computationally expensive to compute, especially as the number of clusters increases. This is its main drawback. You should note that because the denominator uses max, that the Dunn index is a worst-case (lower bound) score. This is because if every cluster except one is compact and clearly separated from the others, but the remaining one is not compact (that is, the within-cluster distance is high), then the Dunn index reduces. You should use other metrics along with the Dunn index to get a better idea of the clustering validity.\n\nWhen we choose to be the minimum distance between points in the two clusters, and to be the maximum distance between two points in the same cluster, we get the Dunn index.\n\nBaker-Hubert Gamma index\n\nThe Baker-Hubert gamma index is an adaptation of the Gamma index of correlation between two vectors of data [2].\n\nSuppose we have two vectors . Then, two given indices are said to be concordant if whenever , we have . Otherwise, the two indices are said to be discordant. We now compute the number of concordant pairs, , and the number of discordant pairs . The gamma index is then defined as\n\nIn the context of clustering, we define the first vector to be the set of distances between two points in the data (regardless of whether or not they’re in the same cluster). The corresponding element of the second vector is binary–it is 0 if the two points are in the same cluster, and 1 otherwise. The Gamma index is then computed.\n\nFrom Bernard Desgraupes’ document [2], the number is the number of times that a distance between two points in the same cluster is less than than a distance between two points in different clusters. Why? Because for a concordant pair, in our case, means that the th pair was in the same cluster (i.e., ), and the th pair in the vector had two points in different clusters (i.e., and thus ). The number is the number of times the opposite situation occurs.\n\nSilhouette index\n\nThe silhouette index is one of the most commonly reported metric, especially with k-means clustering. The silhouette index is the average of the silhouette values of each point, where the silhouette value is a measure of how similar an object is to its own cluster as compared to other clusters [8]. To compute the silhouette value for a point that belongs to cluster , we first compute :\n\nWe divide by , since we don’t include the distance of the point to itself. This may be interpreted as how good of an assignment the point to its current cluster is. Next, we find for each cluster that does not belong to, we find the average distance of to all points in that cluster:\n\nFinally, we compute the silhouette value:\n\nThe silhouette index (the average of all silhouette values) lies between -1 and +1, and can be interpreted as follows [9]:\n\nValue Interpretation 0.71-1.0 A strong structure has been found 0.51-0.70 A reasonable structure has been found 0.26-0.50 The structure is weak and could be artificial. Try additional methods of data analysis. <0.25 No substantial structure has been found\n\nCalinski-Harabasz index\n\nThe Calinski-Harabasz index, also called the pseudo-F statistic, yields the ratio of between-cluster variance to within cluster variance [5]. This metric is used with hierarchical clustering methods. If at a given step in the algorithm, there are clusters, is the number of data points, the pseudo-F statistic is defined as\n\nwhere is the between-cluster sum of squares, and is the within-cluster sum of squares. Larger values of the pseudo-F statistic are preferred, since this implies compact and well-separated clusters.\n\nCophenetic correlation\n\nBecause hierarchical clustering does not maintain the distance between points when we form the dendogram, one might wonder how well the distances between the original data points are preserved in the dendogram. The cophenetic correlation is a measure of this, and is defined as follows [6]: let represent the distance of and . Let be the height of the dendogram at which and first get merged into one cluster. Finally, we let represent the mean of all the s, and be the mean of all the s. The cophenetic correlation is defined as:\n\nA value of c close to 1 is ideal.\n\nComparing different partitions\n\nWe can also compare the partitions created using two algorithms. This can be used to test the effectiveness of the clusters produced. The measures we discuss here fall under external indices or evaluations [3], since we’re comparing two partitions. Therefore, to test the efficacy of your clustering algorithm, you could hold back some data, say 20%, when you give it to the clustering algorithm. You cluster this held-out data independently, say using human experts. Once the algorithm has identified clusters (using the 80% that you gave it), you give it this previously left-out (20%) data, and see how well it performs compared to the “gold standard” human clustering. Essentially, we’re labeling the held-out data. Let’s look at some metrics. First, we’ll briefly define some notation, from Wikipedia [4].\n\nSuppose we have a dataset, . Suppose we want to compare two partitions, and . Let’s define the following:\n\n: The number of data points that are in the same cluster in both the partitions.\n\n: The number of data points that are in the same cluster in partition , but in different clusters in partition .\n\n: The number of data points that are in different clusters in partition , but in the same cluster in partition .\n\n: The number of data points that are in different clusters in both the partitions.\n\nRand index\n\nThe Rand index is defined as\n\nIntuitively, the Rand index acts as an accuracy measure for clusters, and is between 0 and 1. There’s also an adjusted Rand index (ARI), which is actually used in practice. The ARI is corrected for chance. To compute the adjusted Rand index, we first compute a contingency table:\n\nEssentially, each entry is the number of common elements in and . Now, the Adjusted Rand index (ARI), also called the corrected Rand index, is defined as [4]:\n\nFowlkes-Mallows index\n\nIf the Rand index acts like an accuracy measure, we can similarly define precision and recall measures. The Fowlkes-Mallows index, also called the G-measure, is the geometric mean of the precision and recall. In the equation below, the first term corresponds to the precision, and the second corresponds to the recall.\n\nHubert Gamma index\n\nFor each of the two partitions, we can associate a random variable. Think of a random variable as a function, say that maps to real numbers. For each partition, we define a random variable that takes in two indices, and , such that , and returns if are in the same cluster in that partition. Using the notation above, let’s call these two partitions and . Then, the Hubert Gamma index is the correlation coefficient of the random variables associated with these two partitions [2]:\n\nwhere .\n\nSources\n\n[1] Dunn index – Wikipedia\n\n[2] Clustering Indices by Bernard Desgraupes\n\n[3] Cluster analysis – Wikipedia\n\n[4] Rand index – Wikipedia\n\n[5] Lela Wilkinson et al., Cluster analysis\n\n[6] Cophenetic correlation – Wikipedia\n\n[7] Where to cut a dendogram? by chl on Cross Validated\n\n[8] Silhouette (clustering) – Wikipedia\n\n[9] L. Kaufman and P. J. Rousseeuw, Finding groups in data: an introduction to cluster analysis, vol. 344. John Wiley & Sons, 2009\n\nSpectral clustering will be the last clustering technique that we will discuss. Hopefully, all the five (including this one) algorithms that we discussed were different enough to give you an idea of how many possible solutions there are to the clustering problem. Spectral clustering considers all the data points to be nodes in a graph, and the clustering problem to be a graph partitioning problem. A background on graph theory will help you understand at a deeper level, but is not at all necessary. Let’s dig into the algorithm.\n\nAlgorithm\n\nSpectral clustering starts by defining an affinity matrix. This is simply a similarity matrix, where the value is close to 1 when points are nearby, and close to 0 when they’re not. There are many ways to define an affinity matrix. In fact, for those of you familiar with the adjacency matrix representation of a graph, this can also be used as the affinity matrix. We’ll use a Gaussian kernel to define our affinity matrix:\n\nIn fact, there have also been approaches that learn the affinity matrix, (see Section 4 of [2]). The next step is to construct the Graph Laplacian. This is another matrix representation of a graph, but it has some advantages. In particular, it can be used to construct low-dimensional embeddings (which is what we will use it for) [3]. There are many Laplacians we could construct [4]. In constructing all of these, you inevitably construct a diagonal matrix (a matrix where only the principal diagonal elements are nonzero) :\n\nTherefore, each diagonal element is simply the sum of the corresponding row of the affinity matrix. Here are some Laplacians you could construct using this matrix:\n\nSimple Laplacian:\n\nNormalized Laplacian:\n\nGeneralized Laplacian:\n\nNg, Jordan, and Weiss Laplacian:\n\nWe’ll use the last of these. Note that the second and third modify the simple Laplacian, while the last one uses the affinity matrix directly. Next, assuming that we need clusters, we select the largest eigenvectors of the Laplacian matrix. We stack these up side-by-side, to get a matrix , where each column is an eigenvector. Next, we normalize each row of this matrix to get a new matrix:\n\nAs a final step, we treat each row of as a data point, and use k-means clustering. In our original data set, belongs to cluster if the th row of belongs to the cluster according to k-means.\n\nImplementation\n\nLet’s now proceed to implement our algorithm! One classic example that this algorithm is shown with is the moons dataset. Let’s first import the libraries we need.\n\nimport numpy as np from sklearn.datasets import make_moons import matplotlib.pyplot as plt plt.style.use('ggplot')\n\nWe can now generate the data and plot it:\n\nX, y = make_moons(n_samples=1000, noise=.05) plt.scatter(X.T[0], X.T[1], c=y);\n\nThis gives us the following:\n\nClearly, k-means won’t work on this data. So we’ll use spectral clustering (although DBSCAN or hierarchical clustering should work well too), since it relies on connectivity. We first need to compute the affinity matrix.\n\nfrom sklearn.metrics import pairwise_distances A = np.exp(- 1./(2 * 1) * pairwise_distances(X, metric='sqeuclidean'))\n\nWe didn’t bother implementing the squared distance, but you can achieve it using nested loops (which is how the scipy library does it). Note that here, we’ve taken . Next, let’s compute the Laplacian matrix:\n\nL = np.power(D, -0.5) * A * np.power(D, -0.5)\n\nWe now need the eigenvectors. We don’t really need the eigenvalues, so we’ll assign them to a dummy variable.\n\n_, V = np.linalg.eig(L)\n\nSince we want two clusters, we need the first two columns of V. Print them out:\n\nprint(V[:, :2])\n\nYou’ll see something strange here. There are values, but each value is something like\n\n-0.03385498+0.j\n\nThe js means that we have complex values. We don’t really want the imaginary parts of these numbers, so let’s discard them:\n\nV = np.real(V) Y = V[:, :2]\n\nThe first line discards the imaginary parts; the second one extracts the first two columns, since we want two clusters. Next, we normalize the rows:\n\nY /= np.linalg.norm(Y, axis=1).reshape(-1, 1)\n\nLet’s plot this:\n\nplt.scatter(Y.T[0], Y.T[1]);\n\nYou should get something like this:\n\nThere’s a reason we’re plotting this. We’ll get to it shortly. Let’s use k-means to cluster:\n\nfrom sklearn.cluster import KMeans kmeans = KMeans(n_clusters=2) clusters = kmeans.fit_predict(Y)\n\nWe’ll plot the original data, using these clusters:\n\nplt.scatter(X.T[0], X.T[1], c=clusters)\n\nIt didn’t work! Let’s figure out why. We used a Gaussian kernel for our affinity matrix. We know that part is right. But our variance was 1. Which means that points that were 1 unit apart would also be considered “nearby”. But if you look at the data, we have points in two clusters, that are only about 0.7 away from each other. Which means that our definition of nearby was too loose. We can fix this by simply replacing the 1 in the denominator with something smaller. I chose to use 0.2. After applying this fix, let’s plot Y again:\n\nThere’s a gap! This is a good thing. It means our data is separable. Remember how we mentioned the Laplacian can be used to obtain an embedding? We wanted an embedding where the two clusters are separable–this is that embedding. This is why we plotted this–if there was no visual way to see two disjoint clusters, the final clusters wouldn’t be right. Now, we can confidently apply k-means:\n\nPerfect! However, it seems that our choice of variance was pretty crucial, though. There are ways to avoid this. In particular, there are other ways of computing an affinity matrix. Most popular among these is to build a neighbor graph, and one way of doing this is to build a k-Nearest Neighbor graph matrix. We will not discuss this approach here. But with these approaches, once you’ve gotten an affinity matrix, the rest of the steps are exactly the same, which is why we will avoid going down this rabbit hole.\n\nSources\n\n[1] Ng, A.Y., Jordan, M.I. and Weiss, Y., 2002. On spectral clustering: Analysis and an algorithm. In Advances in neural information processing systems (pp. 849-856).\n\n[2] Bach, F.R. and Jordan, M.I., 2004. Learning spectral clustering. In Advances in neural information processing systems (pp. 305-312).\n\n[3] Laplacian matrix – Wikipedia\n\n[4] Spectral Clustering"
    }
}