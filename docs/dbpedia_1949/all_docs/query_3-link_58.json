{
    "id": "dbpedia_1949_3",
    "rank": 58,
    "data": {
        "url": "https://www.irif.fr/en/seminaires/pps/index",
        "read_more_link": "",
        "language": "en",
        "title": "Proofs, programs and systems",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.irif.fr/_media/logo.png",
            "https://www.irif.fr/lib/plugins/translation/flags/fr.gif",
            "https://www.irif.fr/lib/plugins/translation/flags/en.gif",
            "https://www.irif.fr/_media/logo_footer.png",
            "https://www.irif.fr/lib/exe/taskrunner.php?id=en%3Aseminaires%3Apps%3Aindex&1723401287"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "en",
            "seminaires",
            "pps",
            "index"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "https://www.irif.fr/_media/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://www.irif.fr/en/seminaires/pps/index",
        "text": "Seminar\n\nPole Proofs, programs and systems\n\nInria project-team $\\pi r^2$ (Inria)\n\nThematic team Algebra and computation\n\nThematic team Analysis and conception of systems\n\nThematic team Proofs and programs\n\nManage talks\n\nProofs, programs and systems\n\nDay, hour and place\n\nThursday at 10:30am, room 3052\n\nThe calendar of events (iCal format).\n\nIn order to add the event calendar to your favorite agenda, subscribe to the calendar by using this link.\n\nNicolas Behr\n\nGiovanni Bernardi\n\nAdrien Guatto\n\nTo receive talk announcements for the PPS seminar, please send an email to sympa@listes.irif.fr with “subscribe seminaire-pps YourFirstname YourLastname” as a title and an empty body.\n\nPrevious talks\n\nYear 2024\n\nProofs, programs and systems\n\nThursday June 27, 2024, 10:30AM, ENS Lyon\n\nTba Séminaire CHOCOLA\n\nProofs, programs and systems\n\nTuesday June 25, 2024, 9:15AM, Amphi Turing @ Sophie Germain\n\nPps Members, All Hands On Deck ! (PPS) Journée PPS\n\nhttps://www.irif.fr/rencontres/pps2024/index\n\nTo be debated: same philosophical questions as the preceding day.\n\nProofs, programs and systems\n\nMonday June 24, 2024, 9:15AM, Amphi Turing @ Sophie Germain\n\nPps Members, All Hands On Deck ! (PPS) Journée PPS\n\nhttps://www.irif.fr/rencontres/pps2024/index\n\nWe will address two typical philosophical questions: What are we doing ? Where are we going ?\n\nProofs, programs and systems\n\nThursday June 20, 2024, 11AM, Salle 3052 & online (Zoom link)\n\nJan Vitek (Northeastern University) Reusing Just-in-Time Compiled Code\n\nMost code is executed more than once. If not entire programs then libraries remain unchanged from one run to the next. Just-in-time compilers expend considerable effort gathering insights about code they compiled many times, and often end up generating the same binary over and over again. We explore how to reuse compiled code across runs of different programs to reduce warm-up costs of dynamic languages. We propose to use speculative contextual dispatch to select versions of functions from an off-line curated code repository. That repository is a persistent database of previously compiled functions indexed by the context under which they were compiled. The repository is curated to remove redundant code and to optimize dispatch. We assess practicality by extending Ř, a compiler for the R language, and evaluating its performance. Our results suggest that the approach improves warmup times while preserving peak performance.\n\nProofs, programs and systems\n\nThursday May 23, 2024, 10:30AM, ENS Lyon\n\nTba Séminaire CHOCOLA\n\nProofs, programs and systems\n\nThursday April 25, 2024, 11AM, Salle 3052\n\nVikraman Choudhury (Università di Bologna) The Duality of Abstraction\n\nThere are well-known dualities of computation in both functional and concurrent programming: input/output, expression/context, strict/lazy, sender/receiver, forward/backwards, and several others. When viewed through an algebraic lens, these can be understood as metaphysical interpretations of rigorous mathematical dualities.\n\nIn this talk, I will explore the duality of values and continuations (Filinski'89) through the lens of cartesian closure/co-cartesian co-closure. The main observation is that, just as higher-order functions give exponentials, higher-order continuations give co-exponentials. Using this semantic duality, I will present a λλ~ (lambda-lambda-bar or tilde) calculus, which exhibits a duality of abstraction/co-abstraction. I will develop the syntax and semantics of this language, which gives a computational interpretation in terms of speculative execution and backtracking.\n\nUsing this language, I will show how to recover classical control operators, the computational interpretation of classical logic, and a complete axiomatisation of control effects. Finally, I will show how this dualises Lambek's functional completeness, thereby dualising Hasegawa's decomposition of λ-calculus into first-order κ/ζ-calculi.\n\nProofs, programs and systems\n\nThursday March 28, 2024, 11AM, Salle 3052\n\nFabio Gadducci (University of Pisa) On Petri nets and monoidal categories (with a bit of linear logic)\n\nA classical result in concurrency theory shows that an algebraic interpretation of Petri nets in terms of commutative monoids can be used to provide a characterisation of the deterministic computations of a net via monoidal categories, accounting for their sequential and parallel composition. In turn, this characterisation leads to the interpretation of such computations as sequents of the multiplicative fragment of linear logic. The talk presents a survey of the topic, including recent results concerning non-deterministic computations and their characterisation in terms of dioidal categories, the categorical equivalent of tropical semirings, as well as suggesting a possible connection with the multiplicative additive fragment of linear logic.\n\nProofs, programs and systems\n\nThursday March 21, 2024, 11AM, Salle 3052\n\nUli Fahrenberg Directed topology and concurrency: a personal view\n\nI will give an introduction to directed algebraic topology and its application in concurrency theory, covering directed spaces, directed paths, and directed homotopies. Then I will touch upon the combinatorial side of things, precubical sets and higher-dimensional automata (HDAs), which will bring us to the second part of the talk: the language theory of HDAs. This makes the connection back to the initial motivation, concurrency theory, and also gives new inspiration and tools to directed topology.\n\nProofs, programs and systems\n\nThursday March 7, 2024, 11AM, Salle 3052 & online (Zoom link)\n\nJérôme Feret (École normale supérieure) Static analysis and model reduction for a site-graph rewriting language\n\nSoftware sciences have a role to play in the description, the organization, the execution, and the analysis of the molecular interaction systems such as biological signaling pathways. These systems involve a huge diversity of bio-molecular entities whereas their dynamics may be driven by races for shared resources, interactions at different time- and concentration-scales, and non-linear feedback loops. Understanding how the behavior of the populations of proteins orchestrates itself from their individual interactions, which is the holy grail on systems biology, requires dedicated languages offering adapted levels of abstraction and efficient analysis tools.\n\nIn this talk we describe the design of formal tools for Kappa, a site-graph rewriting language inspired by bio-chemistry. In particular, we introduce a static analysis to compute some properties on the biological entities that may arise in models, so as to increase our confidence in them. We also present a model reduction approach based on a study of the flow of information between the different regions of the biological entities and the potential symmetries. This approach is applied both in the differential and in the stochastic semantics.\n\nProofs, programs and systems\n\nThursday February 22, 2024, 11AM, Salle 3052 & online (Zoom link)\n\nAdrienne Lancelot (IRIF, Université Paris Cité & INRIA, LIX, Ecole Polytechnique) Light Genericity\n\nTo better understand Barendregt's genericity for the untyped call-by-value lambda-calculus, we start by first revisiting it in call-by-name, adopting a lighter statement and establishing a connection with contextual equivalence. Then, we use it to give a new, lighter proof of maximality of head contextual equivalence, i.e. that H* is a maximal consistent equational theory. We move on to call-by-value, where we adapt these results and also introduce a new notion dual to light genericity, that we dub co-genericity. We present light (co-)genericity as robust properties rather than just lemmas and provide different proofs based on applicative bisimilarity, semantic models and direct rewriting techniques.\n\nProofs, programs and systems\n\nThursday February 15, 2024, 10:30AM, Salle 3052 & online (Zoom link)\n\nDavid Monniaux (VERIMAG, CNRS) Chamois: agile development of CompCert extensions for optimization and security\n\nCompCert is the only formally-verified C compiler, and one of the very few formally verified compilers altogether. It is intended for use for safety-critical applications. I will discuss some improvements we implemented over CompCert: new VLIW target, new optimizations, and security features. A lot of our development uses untrusted oracles implemented in OCaml plus a formally verified checker. I will discuss typing issues regarding this interface and some questions we have about them.\n\nProofs, programs and systems\n\nThursday February 8, 2024, 11AM, Salle 3052\n\nNathanaël Fijalkow (CNRS, LaBRI, Bordeaux) Machine learning meets program synthesis\n\nOver the past 5 to 10 years, machine learning has revolutionised program synthesis. In this talk we'll present ProgSynth, a general purpose program synthesis tool based on neurosymbolic methods. We'll discuss some challenges: combinatorial search, semantic program synthesis, and reinforcement learning.\n\nProofs, programs and systems\n\nThursday January 25, 2024, 11AM, Salle 3052 & online (Zoom link)\n\nCameron Calk (Laboratoire d'Informatique et Systèmes, Université d'Aix-Marseille) From coherence to quantales, and on to directed topology\n\nA first such link appeared in the context of previous work, in which we provided an algebraic formalisation of categorical coherence theorems in higher dimensional analogs of Kleene algebras. I will briefly recall our definition of the latter and the associated coherence theorems. However, this link between categorical and algebraic structures has since led us to a Jónsson-Tarski correspondance between (higher) catoids, generalizations of (higher) categories, and (higher) quantales. The latter were introduced as a non-commutative extension of locales, and have since also been studied in the context of categorical logic. The first part of this talk will focus on this correspondance and its extension to the associated convolution algebras. These results, as well as the coherence theorem described above, have been formalized in the proof assistant Isabelle.\n\nIn the second part of this talk, I will describe ongoing work relating rewriting, quantales, and (directed) topological methods. The goal of this work is to describe the congruences of multinomial lattices and their continuous analogs, in particular the quantale Qv(I) of sup-continuous endomorphisms of the ordered unit interval. The former, generalizing the permutohedra, provide a description of the rewriting system associated to commutativity on finite words, while the latter are studied in the context of categorical linear logic. These structures all have an interpretation as directed spaces, the homotopy types of which are closely related to their congruences. I will describe this correspondance, and briefly discuss the use of topological duality in our ongoing study of these structures.\n\nProofs, programs and systems\n\nThursday January 11, 2024, 11AM, Salle 3052\n\nHugo Paquet (LIPN, Université Sorbonne Paris Nord) Element-free probability distributions and Bayesian clustering\n\nAn “element-free” probability distribution is what remains of a probability distribution after we forget the elements to which the probabilities were assigned. These objects naturally arise in Bayesian statistics, in situations where the specific identity of elements is not important. This talk is about the theory of element-free distributions in the category of measurable spaces. I will explain the basic concepts, and then present two new results which demonstrate that element-free distributions are a canonical notion. The first result is a categorical version of a representation theorem for random partitions, originally due to Kingman, which characterises the space of element-free distributions as a limit in the Kleisli category for the Giry monad G. The second result establishes a correspondence between random element-free distributions and natural transformations of type G → GG. I will sketch the relevance of this theory to nonparametric Bayesian clustering.\n\nThis is joint work with Victor Blanchi.\n\nYear 2023\n\nProofs, programs and systems\n\nThursday December 14, 2023, 10:30AM, ENS Lyon\n\nMarianna Girlando & Sonia Marin, Paige Randall North, Lionel Vaux Auclair Séminaire CHOCOLA\n\nProofs, programs and systems\n\nThursday December 7, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nMeven Lennon-Bertrand (Université de Cambridge) Towards a certified proof assistant kernel – What it takes and what we have\n\nProof assistant kernels are a natural target for program certification: they are small, critical, and well-specified. Still, despite the maturity of the field of software certification, we are yet to see a certified Agda, Coq or Lean. In this talk, I will try and explain why this is not such an easy task, and present two complementary projects going in that direction. The first, MetaCoq, is a large scale project, broadly aiming at giving tools to manipulate Coq terms and derivations inside of Coq, in particular developing an important body of formalized proofs around Coq's typing. The second is a more recent endeavour, aimed at tackling the mother of all properties: normalisation.\n\nProofs, programs and systems\n\nThursday November 23, 2023, 10:30AM, Salle 3052\n\nLuca Reggio (University College London) Games, comonads, and categorical homotopy\n\nThe game comonads research programme, started by Samson Abramsky and Anuj Dawar in 2017, provides categorical accounts of key constructions in finite model theory, and has led to an axiomatic approach to various notions of logical resources central to this field.\n\nI will outline some preliminary ideas on how to bring the tools of homotopy theory to the research area of game comonads, with the aim of tackling open questions concerning e.g. expressive completeness and preservation results.\n\nProofs, programs and systems\n\nThursday November 16, 2023, 10:30AM, ENS Lyon\n\nMorgan Rogers, Cyril Cohen, Simon Forest (Various institutions) Séminaire CHOCOLA\n\nJoint session with the CHOCOLA seminar. See details at:\n\nhttps://chocola.ens-lyon.fr/events/meeting-2023-11-16/\n\nProofs, programs and systems\n\nThursday November 9, 2023, 10:30AM, Salle 3052\n\nAndreas Nuyts (KU Leuven) Multimodal Type Theory and Applications\n\nCertain properties of (type) dependencies in typed programming languages can be established syntactically by observing non-violation, shortcutting the need of a manual proof. Examples of such properties are variance, irrelevance, parametricity, or causality as in guarded type theory. A type system where function types are annotated with a *modality* expressing the function's behaviour, can account for this syntactic check as part of type-checking. From the need to type basic function operations, we find that these modalities should have the structure of an ordered monoid, or more generally they can be the morphisms of a 2-category whose objects are called *modes*. The purpose of multi[mode/modal] type theory (MTT) is to provide a type system, parametrized by a 2-category called the *mode theory* which abstractly achieves this result.\n\nAfter introducing MTT and its models, depending on the timing and the interests and background of the audience, we can either look at questions arising during the implementation of MTT, or at applications. Some applications that I have worked on, or am working on, are Degrees of Relatedness (for parametricity & irrelevance), naturality type theory (naturality & variance), and the modal transpension system (for internalizing aspects of presheaf models). J. Ceulemans' Sikkel library for Agda explores how MTT can help to use the many extensions of type theory found in the literature *locally and modularly*.\n\nProofs, programs and systems\n\nThursday October 19, 2023, 10:30AM, Salle 3052\n\nTba Séminaire CHOCOLA\n\nProofs, programs and systems\n\nThursday October 12, 2023, 10:30AM, Salle 3052\n\nJuliusz Chroboczek (Université Paris Cité) Le routage next-hop : une introduction illustrée sur le protocole Babel\n\nL'Internet est un réseau consistant de plusieurs dizaines de milliards de nœuds. Le *routage* est le problème d'acheminer un paquet à travers un réseau. Le paradigme de routage utilisé dans l'Internet s'appelle le *routage next-hop*.\n\nDans cet exposé, je ferai une introduction au routage next-hop, puis je décrirai comment il est traditionnellement réalisé dans l'Internet. Je décrirai les faiblesses des techniques traditionnelles de routage, et je montrerai comment le protocole de routage Babel vise à les contourner.\n\nProofs, programs and systems\n\nThursday September 28, 2023, 10:30AM, Lyon\n\nAntoine Allioux, Liseau Blondeau-Patissier, William Simmons Séminaire CHOCOLA\n\nTitles and abstracts available at: https://chocola.ens-lyon.fr/events/meeting-2023-09-28/\n\nProofs, programs and systems\n\nThursday September 21, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nBrigitte Pientka (McGill University) A Layered Modal Type Theory For Meta-Programming – Where Meta-Programming Meets Intensional Code Analysis\n\nMetaprogramming is the art of writing programs that produce or manipulate other programs. This opens the possibility to eliminate boilerplate code and exploit domain-specific knowledge to build high-performance programs. While this widely used concept is almost as old as programming itself, it has been surprisingly challenging to extend to logical frameworks and type-theory in general.\n\nIn this talk, I present a layered modal type theory that provides a logical foundation to meta-programming with intensional code analysis. At its core (layer 0), has a pure (simply-typed) calculus with no modality. Layer 1 is obtained by extending the core with one layer of contextual box types which describes open code at layer 0 and supports pattern matching on open code from layer 0. Although both layers fundamentally share the same language and the same typing judgment, we only allow computation at layer 1. As a consequence, layer 0 accurately captures the syntactic representation of code in contrast to the computational behaviors at layer 1. The system is justified by normalization by evaluation (NbE) using a presheaf model. The normalization algorithm extracted from the model is sound and complete and is implemented in Agda.\n\nWe see this work as a stepping stone towards developing a dependent type theory that supports intensional code analysis in meta-programming.\n\nThis is joint work with Jason Z. Hu.\n\nProofs, programs and systems\n\nThursday June 22, 2023, 10:30AM, Room: TBA\n\nHall Hands On Deck AG\n\nProofs, programs and systems\n\nFriday May 26, 2023, 9:30AM, Amphi 9e Halle aux Farines\n\nAll Hands On Deck (PPS pole) Journées PPS 2023\n\nProofs, programs and systems\n\nThursday May 25, 2023, 9:30AM, Amphi 9e Halle aux Farines\n\nAll Hands On Deck (pole PPS) Journées PPS 2023\n\nProofs, programs and systems\n\nThursday April 13, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nGiulio Manzonetto (Université Sorbonne Paris Nord) The Lambda Calculus - 40 Years Later\n\nBarendregt's book “The Lambda Calculus, its syntax and semantics” (1981/84) has become a `classic' in Theoretical Computer Science because it presents the state of the art in lambda calculus in a comprehensive way, and proposes a number of open problems and conjectures. In 2022, Barendregt and Manzonetto published a `sequel' of this book, presenting the solutions of several of these problems, and more. In this talk, we will present a selection of these problems and the key ingredients that were employed to solve them.\n\nProofs, programs and systems\n\nThursday March 30, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nRomain Pascual (Université Paris-Saclay) Graph transformation for reasoning about geometric modeling operations\n\nTopology-based geometric modeling deals with the representation of nD objects, which splits the topological description, i.e., the representation of the objects' topological cells (vertices, edges, faces, volumes, …), and the geometric information, i.e., the addition of data to the topological cells. We study the combinatorial models of generalized and oriented maps represented as attributed typed graphs subject to consistency conditions. This representation allows the study of modeling operations as graph rewriting rules. The motivation is twofold. First, we study the preservation of the model consistency through syntactic conditions statically checked on the rules. Second, we extend rules into rule schemes to abstract over the underlying topology. This formalization of modeling operations also offers guidelines for inferring operations from a representative example consisting of an initial and a target object. The inference mechanism is implemented in Jerboa, a platform for designing geometric modelers exploiting graph transformation rules.\n\nProofs, programs and systems\n\nThursday March 23, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nGiulio Manzonetto Postponed to Apil 13th.\n\nProofs, programs and systems\n\nThursday March 16, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nAdrien Durier (Université Paris-Saclay) Open call-by-value and concurrency\n\nMilner's work on functions as processes shows how the evaluation strategies of the lambda-calculus can be faithfully mimicked in the pi-calculus, allowing a dynamic representation of functional programs. Milner namely studies the call-by-name and call-by-value evaluation strategies, and raises the problem of full abstraction for these encodings, i.e., what are the equivalences induced by these encodings. The theory of call-by-name is well-studied and understood, and the problem of full abstraction for call-by-name was solved shortly after. On the other hand, the theory of call-by-value on open terms is complex, and we present the solution of the full abstraction problem for call-by-value, which was left open until quite recently.\n\nProofs, programs and systems\n\nThursday March 9, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nGhyselen Alexis (Università di Bologna) Choices via algebraic operations and stateful computations\n\nAlgebraic operations, as defined by Plotkin and Power, are well-studied and powerful tools to provide denotational semantics for computational lambda-calculus and it is especially useful in design for abstraction of effectful computations, allowing a high degree of modularity by separating effect signatures from their interpretations. The practical counterpart of this is obtained by the use of handlers, a popular tool in functional programming that can actually provide concrete implementations of effect signatures while preserving modularity.\n\nIn this talk, I will present a joint work with Ugo Dal Lago and Francesco Gavazzo on how algebraic operations, and handlers, can support decision-making abstractions in functional programs: a user can invoke an operation to resolve choices without implementing the underlying selection mechanism, and can give feedback by way of rewards. We differ from some recently proposed approach to the problem based on the selection monad, by Abadi and Plotkin, as we express the underlying selection mechanism with efficient algorithms implemented by a set of handlers. I will first introduce algebraic effects and handlers, then present the selection monad approach for choices, and our approach, based on stateful computations (or equivalently comodels). Both the theoretical and practical aspects will be examined, and I will show the practical efficiency of our approach compared to the selection monad. Finally, I will focus on how our work can actually be implemented in a modular way on a concrete language with handlers and how we can use expressive type systems to obtain safety properties, especially ensuring a high-degree of modularity and a sound usage of algebraic operations.\n\nProofs, programs and systems\n\nThursday February 23, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nFrancesco Gavazzo (University of Pisa) Computational Effects From a Relational Angle\n\nProgram execution rarely happens in isolation. Indeed, during its evaluation a program may modify the memory of the machine, interact with external processes, change the flow of the computation, etc. All these phenomena are known as computational effects, and they can be informally described as those side effects happening during the evaluation process of the program. Computational effects are of paramount importance to understand program behaviour, and indeed they are one of the main research topics in programming language semantics since the very birth of the discipline. Starting with the seminal work by Eugenio Moggi, computational effects have been successfully understood relying on the language of algebra and category theory, with notions such as monad, algebraic (and Lawvere) theory, and distributive law being nowadays well-accepted idioms in the programming language community. Although the categorical perspective on computational effects has been particularly effective to model the denotational semantics of effectful programs it does not work so well when it comes to accounting for their operational behaviour. In this talk, I will introduce the theory of computational effects by first reviewing the categorical approach to effectful programs, focusing in particular on Plotkin and Power's theory of algebraic effects, and then moving to computational effects in (some subfields of) operational reasoning. In particular, I will give evidence that by extending the aforementioned categorical notions from a categorical (functional) to an allegorical (relational) setting, it is possible to obtain an elegant operational theory of computational effects having the same level of generality as its denotational counterpart. To maintain the talk as accessible as possible, I will give a first introductory part on computational effects and then move to the more technical relational development. The latter will consist of a general high-level outline of the results achieved in the context of operational reasoning and of a more in-depth case study.\n\nProofs, programs and systems\n\nTuesday February 14, 2023, 11AM, Salle 3052 & online (Zoom link)\n\nBenoît Valiron (CentraleSupélec) Complete Equational Theories for Linear Optical and Quantum Circuits\n\nIn this talk, we introduce two complete equational theories: one for linear optical circuits and one for quantum circuits. More precisely, in both cases we introduce a set of circuit equations that we prove to be sound and complete: two circuits represent the same quantum evolution if and only if they can be transformed one into the other using the equations.\n\nWe shall first present our proposed equational theory for linear optical circuits. We shall then discuss how the semantics of both kind of circuits differ, and how to relate them using controlled-gates. The discussion will drive is to the completeness result for quantum circuits, based on the one for linear optical circuits.\n\nJoint session with the Algorithmes et complexité seminar series.\n\nProofs, programs and systems\n\nThursday February 9, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nClément Blaudeau (INRIA Paris, CAMBIUM Project-Team) Retrofitting OCaml modules\n\nML modules are offer large-scale notions of composition and modularity. Provided as an additional layer on top of the core language, they have proven both vital to the working OCaml and SML programmers, and inspiring to other use-cases and languages. Unfortunately, their meta-theory remains difficult to comprehend, and more recent extensions (abstract signatures, module aliases) lack a complete formalization. Building on a previous translation from ML modules to Fω, we propose a new comprehensive description of a significant subset of OCaml modules, including both applicative and generative functors and the proposed feature of transparent ascription. By exploring the translations both to and from Fω, we provide a complete description of the signature avoidance issue, as well as insights on the limitations and benefits of the path-based approach of OCaml type-sharing.\n\nProofs, programs and systems\n\nThursday January 26, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nGeorge Metcalfe (University of Bern) Deciding equations in ordered groups and ordered monoids\n\n(Joint work with Almudena Colacito, Nikolaos Galatos, and Simon Santschi)\n\nThis talk will be about deciding equations in various classes of ordered groups and ordered monoids, and how this relates to deciding if there exist orders on free groups and monoids satisfying finitely many inequalities.\n\nRemoving the inverse operation from any lattice-ordered group (l-group) yields a distributive lattice-ordered monoid (l-monoid), but not every distributive l-monoid admits a group structure. Indeed, every distributive l-monoid is a (possibly finite) pointwise-ordered monoid of order-preserving maps on a chain, whereas every l-group is a pointwise-ordered group of order-preserving permutations on a chain and must be either trivial or infinite.\n\nWe will see that the equational theory of distributive l-monoids is decidable and coincides with the equational theory of l-groups without inverses, and hence, by eliminating inverses, that the equational theory of l-groups is also decidable. This contrasts with the fact that there are inverse-free equations that are satisfied by all totally ordered abelian groups but not all totally ordered commutative monoids, and the decidability of the equational theory of the latter is open.\n\nProofs, programs and systems\n\nThursday January 12, 2023, 10:30AM, Salle 3052 & online (Zoom link)\n\nRémy Cerda (Université d'Aix-Marseille) Taylor expansion for the infinitary λ-calculus\n\nEhrhard and Regnier’s Taylor expansion of λ-terms has been broadly used as an approximation theory for several variants of the λ-calculus. Many results arise from a Commutation theorem relating the normal form of the Taylor expansion of a term to its Böhm tree. We extend this framework to the (001-)infinitary λ-calculus, where terms and reductions may be infinite, and where the normal forms are precisely the Böhm trees. This enables us to give a unified presentation of the Commutation theorem, thanks to the simulation of the infinitary reduction by the (finitary, confluent and terminating) reduction of the Taylor expansion. Finally we deduce new, simple proofs of confluence and genericity for the infinitary λ-calculus, as well as approximation-based characterisations of head- and β-reductions.\n\nCorresponding paper (submitted to LMCS): https://arxiv.org/abs/2211.05608. This is joint work with my supervisor Lionel Vaux Auclair (I2M, AMU).\n\nYear 2022\n\nProofs, programs and systems\n\nThursday December 15, 2022, 10:30AM, Salle 3052 & online (Zoom link)\n\nDavide Barbarossa (Università di Bologna) Lambda-calculus goes to the tropics\n\nIn the last years, there has been a growing interest in the notion of “distances/errors” between programs. A natural question is that of the relation between this point of view and the one provided by Ehrhrard and Regnier's Taylor expansion of lambda-terms, in which the role played by polynomials in analysis is played by so-called resource terms. One of the main motivations of this still very in progress work – joint with Paolo Pistone – is precisely to explore how can we relate these two worlds. For instance, a notable notion from the “metric perspective” is that of a program being K-Lipschitz; from the “differential perspective”, one may want resource terms to be Lipschitz, but then there is a mismatch with respect to analysis, because polynomials are not. Now, the well known “tropicalisation”, precisely transforms polynomials into Lipschitz functions. Tropical mathematics is a well-established field, in tight relation with algebraic geometry and optimisation; we explore some of its relations with lambda-calculus. In particular, we consider the category of sets and matrices with coefficients in the so-called tropical semifield. Endowed with certain bang and differential operators, it gives rise to a model of the differential lambda-calculus in which morphisms can be Taylor expanded and, seen as “infinite” tropical polynomials, satisfy certain continuity and Lipschitz properties. I will mention some possible applications in relation with probabilities and extracting quantitative information from programs. If time allows, I will mention how we are recognising that, actually, all this relates to some general research in quantales-enriched categories, and probably has an interesting relation with Ehrhard's finiteness spaces.\n\nProofs, programs and systems\n\nThursday December 8, 2022, 10:30AM, Salle 3052 & online (Zoom link)\n\nBeniamino Accattoli (INRIA Saclay, PARTOUT Project-Team) Exponentials as Substitutions and the Cost of Cut Elimination in Linear Logic.\n\nIn this talk, I will start by discussing the lack of a reasonable time cost model for linear logic. Then, inspired by recent advances in the sister field of lambda calculus, I will introduce a new term-based presentation of cut elimination for IMELL admitting a reasonable strategy (that is, a strategy of which the number of step is a reasonable time cost model). The focus will be on the principles behind the new presentation of cut elimination.\n\nProofs, programs and systems\n\nThursday December 1, 2022, 10:30AM, Salle 3052 & online (Zoom link)\n\nDavid Baelde (ENS Rennes) Logical foundations of the Squirrel prover\n\nThe computationally complete symbolic attacker (CCSA) is a logically-based approach proposed by Bana and Comon to verify cryptographic protocols in the computational model, i.e. in the model of cryptographers where messages are probabilistic bitstrings and attackers are arbitrary probabilistic PTIME machines. The original formulation of CCSA was based on first-order logic and only supported the verification of protocols with bounded traces. With several co-authors, we have proposed in 2020 to build a meta-logic on top of this “base” first-order logic, to obtain a methodology that supports verifying unbounded protocols. This meta-logic forms the basis of the Squirrel proof assistant.\n\nProofs, programs and systems\n\nThursday November 10, 2022, 10:30AM, Salle 3052\n\nGabriele Vanoni (Inria Sophia Antipolis) Reasonable Space and the Lambda-Calculus\n\nThe study of computational complexity is based on computational models, traditionally Turing machines. Space complexity is defined as the maximum number of cells used during a computation. How could we measure the space complexity of functional programs? The notion of space is not clear as there is not a fixed evaluation schema. However, the cost model should be reasonable, i.e. linearly related with the one of Turing machines. In this talk, I will go through the journey that led to the definition of the first reasonable space cost model for the lambda-calculus, accounting for logarithmic space complexity.\n\nProofs, programs and systems\n\nThursday October 13, 2022, 10:30AM, Salle 3052 & online (Zoom link)\n\nWillem Heijltjes (University of Bath) The Functional Machine Calculus\n\nThis talks presents the Functional Machine Calculus (FMC) as a simple model of higher-order computation with effects, including higher-order mutable store, input and output, and probabilistic and non-deterministic computation as special cases of input. It consists of two independent generalizations of the lambda-calculus, derived from the standard opera- tional perspective of a call–by–name stack machine and supported by domain-theoretic considerations. One generalization, “locations”, enables effect operators to be encoded into the constructs of the calculus. The second, “sequencing”, is known from kappa-calculus and concate- native languages, and introduces the imperative notions of “skip” and “sequence”. This enables the encoding of reduction strategies, including call–by–value lambda-calculus and monadic constructs. Reduction in the FMC is confluent, which is possible be- cause encoded effect operations reduce algebraically, rather than operationally. It can be simply typed to confer strong normalization, and semantically forms a Cartesian closed category.\n\nProofs, programs and systems\n\nThursday October 6, 2022, 10AM, Salle 3052\n\nAll Hands On Deck (IRIF) Matinée de rentrée de PPS\n\nProofs, programs and systems\n\nThursday September 22, 2022, 10:30AM, ENS Lyon\n\nRomain Couillet, Claudia Faggian, Guillaume Geoffroy Séminaire CHOCOLA\n\nhttp://chocola.ens-lyon.fr/events/\n\nProofs, programs and systems\n\nMonday September 19, 2022, 11AM, 3052 and Zoom link\n\nShachar Itzhaky (Technion, Haifa) TheSy: Theory Exploration Powered by Deductive Synthesis and E-graphs\n\nRecent years have seen tremendous growth in the amount of verified software. Proofs for complex properties can now be achieved using higher-order theories and calculi. Complex properties lead to an ever-growing number of definitions and associated lemmas, which constitute an integral part of proof construction. Following this – whether automatic or semi-automatic – methods for computer-aided lemma discovery have emerged. In this work, we introduce a new symbolic technique for bottom-up lemma discovery, that is, the generation of a library of lemmas from a base set of inductive data types and recursive definitions. This is known as the theory exploration problem, and so far, solutions have been proposed based either on counter-example generation or the more prevalent random testing combined with first-order solvers. Our new approach, being purely deductive, eliminates the need for random testing as a filtering phase and for SMT solvers. Therefore it is amenable compositional reasoning and for the treatment of user-defined higher-order functions. Our implementation, TheSy, has shown to find more lemmas than prior art, while avoiding redundancy and without having to run the programs once.\n\nIn this talk, I will present results published in CAV 2021, and ongoing work on extending TheSy to richer theories. In the first work, we used e-graphs on top of egg (Willsey et al). In the follow-up, we extend egg to be able to handle conditional equalities, which are pervasive in many theories; notably, Separation Logic with inductive definitions. We hope that this will allow synthesizing a richer set of lemmas.\n\nJoint session with the Verification seminar.\n\nProofs, programs and systems\n\nWednesday July 13, 2022, 2:30PM, Salle 3052\n\nDaniela Petrisan, Alexandre Goy, Nicolas Munnich, Chris Barrett, Willem Heijltjes And Other Mfps Speakers MFPS local event - day 3\n\nThe Mathematical Foundations of Programming Semantics takes place in Ithaca, New York, with a local event hosted at IRIF. The talks of Daniela Petrisan, Alexandre Goy, Nicolas Munnich, Chris Barrett, and Willem Heijltjes will take place in room 3052. The talks from speakers in Ithaca will be broadcast in the same room.\n\nSee https://www.cs.cornell.edu/mfps-2022/paris.md.html for additional information.\n\nProofs, programs and systems\n\nTuesday July 12, 2022, 2:30PM, Salle 3052\n\nNicolas Wu And Other Mfps Speakers MFPS local event - day 2\n\nThe Mathematical Foundations of Programming Semantics takes place in Ithaca, New York, with a local event hosted at IRIF. The talk of Nicolas Wu will take place in room 3052 at 18:20. The talks from speakers in Ithaca will be broadcast in the same room.\n\nSee https://www.cs.cornell.edu/mfps-2022/paris.md.html for additional information.\n\nProofs, programs and systems\n\nMonday July 11, 2022, 2:30PM, Salle 3052\n\nBarbara König, Ayberk Tosun, Frank Pfenning And Other Mfps Speakers MFPS local event - day 1\n\nThe Mathematical Foundations of Programming Semantics takes place in Ithaca, New York, with a local event hosted at IRIF. The talks of Barbara König, Ayberk Tosun, and Frank Pfenning will take place in room 3052. The talks from speakers in Ithaca will be broadcast in the same room.\n\nSee https://www.cs.cornell.edu/mfps-2022/paris.md.html for additional information.\n\nProofs, programs and systems\n\nThursday June 23, 2022, 10:30AM, Salle 3052 & online\n\nLison Blondeau-Patissier (Aix-Marseille Université) Positional Injectivity for Innocent Strategies\n\nIn asynchronous games, Melliès proved that innocent strategies are positional: their behaviour only depends on the position, not the temporal order used to reach it. This insightful result shaped our understanding of the link between dynamic (i.e. game) and static (i.e. relational) semantics. Here, we investigate the positionality of innocent strategies in the traditional setting of Hyland-Ong-Nickau-Coquand pointer games. Although innocent strategies are not positional, total finite innocent strategies still enjoy a key consequence of positionality, namely positional injectivity: they are entirely determined by their positions.\n\nThis talk is based on a article written with Pierre Clairambault (https://drops.dagstuhl.de/opus/volltexte/2021/14255).\n\nProofs, programs and systems\n\nThursday June 16, 2022, 10:30AM, Salle 3052 & online (Zoom link)\n\nNicola Gambino (University of Leeds) Kripke-Joyal semantics for type theory\n\nOne of the key aspects of mathematical logic and semantical techniques in theoretical computer science is to test the validity of a formula in structure. This can be a complex task, e.g. if the formula or the structure is complicated. In this talk, I will present a method for testing the validity of a statement of dependent type theory in categories of variable sets (presheaves). This involves a generalisation of the well-known Kripke semantics for intuitionistic logic and of the Kripke-Joyal semantics for higher-order intuitionistic logic. As an application, I will outline how this method can be used to relate type-theoretic and category-theoretic characterisations of so-called uniform fibrations, which have been used in Homotopy Type Theory. I will not assume prior knowledge of type theory or category theory. This is joint work with Steve Awodey (Carnegie Mellon University) and Sina Hazratpour (Johns Hopkins University), see https://arxiv.org/abs/2110.14576.\n\nProofs, programs and systems\n\nThursday June 9, 2022, 10:30AM, Salle 3052\n\nJonathan Sterling (University of Aarhus) Naïve logical relations in synthetic Tait computability\n\nLogical relations are the main tool for proving positive properties of logics, type theories, and programming languages: canonicity, normalization, decidability, conservativity, computational adequacy, and more. Logical relations combine pure syntax with non-syntactic objects that are parameterized in syntax in a somewhat complex way; the sophistication of possible parameterizations makes logical relations a tool that is primarily accessible to specialists. In the spirit of Halmos' book Naïve Set Theory, I advocate for a new viewpoint on logical relations based on synthetic Tait computability, the internal language of categories of logical relations. In synthetic Tait computability, logical relations are manipulated as if they were sets, making the essence of many complex logical relations arguments accessible to non-specialists.\n\nProofs, programs and systems\n\nThursday June 2, 2022, 10:30AM, Online (Zoom link)\n\nCezary Kaliszyk (University of Innsbruck) Property Invariant Machine Learning for Theorem Proving\n\nIn this talk I will discuss the recent progress in learning methods for theorem proving. In many domains, representations that are able to abstract over unimportant transformations, such as abstraction over translations and rotations in vision are becoming more common. Standard methods of interpreting formulas for learning theorem proving are however yet unable to handle many important transformations. In particular, embedding previously unseen labels, that often arise in definitional encodings and in Skolemization, has been very weak so far. Similar problems appear when transferring knowledge between known symbols. I will discuss encoding of formulas based on graph models, that represents symbols only by nodes in the graph, without any knowledge of the original labels. I will discuss this in multiple theorem proving tasks, including lemma selection, reasoning, and interaction with an ITP.\n\nProofs, programs and systems\n\nThursday May 19, 2022, 10:30AM, On-line.\n\nGlynn Winskel (Huawei Edinburgh Research Centre) Making Concurrency Functional\n\nThe talk bridges between two major paradigms in computation, the functional, at basis computation from input to output, and the interactive, where computation reacts to its environment while underway. Central to any compositional theory of interaction is the dichotomy between a system and its environment. Concurrent games and strategies address the dichotomy in fine detail, very locally, in a distributed fashion, through distinctions between Player moves (events of the system) and Opponent moves (those of the environment). A functional approach has to handle the dichotomy much more ingeniously, through its blunter distinction between input and output. This has led to a variety of functional approaches, specialised to particular interactive demands. Through concurrent games we can more clearly see what separates and connects the differing paradigms, and show how:\n\n- several paradigms of functional programming and logic arise naturally as subcategories of concurrent games, including stable domain theory; nondeterministic dataflow; geometry of interaction; the dialectica interpretation; lenses and optics; and their extensions to containers in dependent lenses and optics.\n\n- to transfer enrichments of strategies (such as to probabilistic, quantum or real-number computation) to functional settings.\n\nProofs, programs and systems\n\nThursday May 12, 2022, 10:30AM, Salle 3052\n\nPatrick Baillot (CNRS, CRIStAL Lille) Bunched Fuzz: Sensitivity for Vector Metrics\n\n“Program sensitivity” measures the distance between the outputs of a program when it is run on two related inputs. This notion, which plays an important role in areas such as differential privacy and optimization, has been the focus of several program analysis techniques introduced in recent years. One approach that has proved particularly fruitful for this domain is the use of type systems inspired by linear logic, as pioneered by Reed and Pierce in the Fuzz programming language. In Fuzz, each type is equipped with its own notion of distance, and the typing rules explain how those distances can be treated soundly when analyzing the sensitivity of a program. In particular, Fuzz features two products types, corresponding to two different sensitivity analyses: the “tensor product” combines the distances of each component by adding them, while the “with product” takes their maximum. In this talk we will show how products in Fuzz can be generalized to arbitrary Lp distances, metrics that are often used in privacy and optimization. The original Fuzz products, tensor and with, correspond to the special cases L1 and L∞. To handle the generalized products, we extend the Fuzz type system with bunches – as in the logic of bunched implications – where the distances of different groups of variables can be combined using different Lp distances. We show that our extension, Bunched Fuzz, can be used to reason about important examples of metrics between probability distributions in a natural way.\n\nThis is joint work with june wunder, Arthur Azevedo de Amorim, and Marco Gaboardi.\n\nProofs, programs and systems\n\nThursday May 5, 2022, 10:30AM, Salle 3052\n\nMarcelo Fiore (University of Cambridge) The Mathematical Foundations of a Formal Computational Metatheory of Second-Order Algebraic Theories\n\nI will present a further step in my ongoing research programme on Algebraic Type Theory, the overall aim of which is to develop a mathematical theory understanding type theories algebraically while supporting practical foundations. The talk will centre on Second-Order Algebraic Theories, which are equational presentations in languages with (first-order) algebraic type structure and (second-order) term structure with variable-binding operators and parametrised metavariables. Examples include: first-order logic, simply-typed computational calculi, and the calculus of partial differentiation.\n\nSpecifically, I will present a new categorical model for Second-Order Algebraic Theories: it is based on indexed families and founded upon the initial-algebra approach. A main motivation for and crucial aspect of the mathematical theory is that it is directly programmable in languages supporting inductive families; and, indeed, was developed in unison with building a formally-verified computer implementation for second-order semantics, computation, and deduction. As such, the work resulted in a framework within the Agda proof assistant for the automatic generation of generic second-order abstract syntax and provably-correct metaoperations for manipulating it; to wit, algebraic models together with compositional interpretations, capture-avoiding and metavariable substitution operations, and equational and/or rewriting reasoning. This is joint work with Dmitrij Szamozvancev; a paper, source code, documentation, and case studies are available at the project page <tinyurl.com/agda-soas>.\n\nProofs, programs and systems\n\nThursday April 28, 2022, 10:30AM, Salle 3052\n\nAntonino Salibra (IRIF & Università Ca'Foscari) Universal clone algebra\n\nClones are sets of finitary operations on a fixed carrier set that contain all projection operations and are closed under composition. They play an important role in universal algebra (the term clone of an algebra), in the study of first-order structures (the polymorphism clone of a structure), and in theoretical computer science (the polymorphism clone of a constraint satisfaction problem). In this talk we introduce a new general framework for algebras and clones, called universal clone algebra. Algebras and clones of finitary operations are to universal algebra what t-algebras and clone algebras are to universal clone algebra. Clone algebras found a one-sorted, purely algebraic theory of clones, while t-algebras are a slight generalisation of algebras to cope with infinite arities. We present a method to codify algebras and clones into t-algebras and clone algebras, respectively. We provide concrete examples showing that general results in universal clone algebra, when translated in terms of algebras and clones, give new versions of known theorems in universal algebra. We apply this methodology to Birkhoff's HSP theorem and to the recent topological versions of Birkhoff's theorem.\n\nProofs, programs and systems\n\nThursday April 21, 2022, 10:30AM, Salle 3052\n\nLaura Fontanella (Université Paris-Est Créteil) Representing ordinals in classical realizability\n\nRealizability aims at extracting the computational content of mathematical proofs. Introduced in 1945 by Kleene as part of a broader program in constructive mathematics, realizability has later evolved to include classical logic and even set theory. Krivine's work led to define realizability models for the theory ZF following a technique that generalizes the method of Forcing. After a brief presentation of this technique, we will discuss the problem of representing ordinals in realizability models for set theory, thus we will present the solution proposed in a joint work with Guillaume Geoffroy that led to realize uncountable versions of the Axiom of Dependent Choice.\n\nProofs, programs and systems\n\nThursday April 7, 2022, 10:30AM, Salle 3052 & online\n\nPierre Clairambault (CNRS, Aix-Marseille Université) The Geometry of Causality : Multi-Token Geometry of Interaction and its Causal Unfolding\n\nIn this talk, I will introduce a multi-token machine for Idealized Parallel Algol (IPA), a higher-order concurrent programming language with shared state and semaphores. For the purely functional fragment, the machine is conceptually close to Geometry of Interaction token machines, originating from Linear Logic and presenting higher-order computation as the low-level process of a token walking through a graph (a proof net) representing the term. However, our methodology is somewhat different: instead of representing terms as proof nets, the machine takes the shape of a compositional interpretation of terms as “Petri structures”, certain coloured Petri nets. Formalizing the token machine as a Petri net allows us to pair GoI with folklore ideas on the representation of first-order imperative concurrent programs as coloured Petri nets.\n\nTo prove our machine correct, we follow game semantics and represent types as certain games specifying dependencies and conflict between computational events. We define Petri strategies as those Petri structures obeying the rules of the game. In turn, we show how Petri strategies unfold to concurrent strategies in the sense of concurrent games on event structures. This not only entails correctness and adequacy of our machine, but also lets us generate operationally a causal description of the behaviour of programs at higher-order types.\n\nThis is joint work with Simon Castellan. The Geometry of Causality machine is implemented, and available at: https://ipatopetrinets.github.io/\n\nProofs, programs and systems\n\nThursday March 31, 2022, 10:30AM, Online\n\nCristina Matache, Abhishek De, Federico Olimpieri Séminaire CHOCOLA\n\nProofs, programs and systems\n\nThursday March 24, 2022, 10:30AM, Online\n\nMatteo Acclavio (Université du Luxembourg) Designing graphical proof systems\n\nIn this talk we define logical systems where graphs play the role of formulas. We recall the well-known correspondence between propositional formulas and cographs, a specific family of graphs satisfying simple topological conditions, and we introduce a proof system for a logic generalising this correspondence to general undirected graphs. We show that the proof system satisfies some basic requirements, most notably analyticity. We conclude by outlining the novelty in this approach and the research directions which it opens.\n\nOnline at link (any password works)\n\nProofs, programs and systems\n\nThursday March 17, 2022, 10:30AM, Salle 3052 & online\n\nGabriel Scherer (Inria Saclay) A right-to-left type system for recursive value definitions\n\nIn call-by-value languages, some mutually-recursive value definitions can be safely evaluated to build recursive functions or cyclic data structures, but some definitions (`let rec x = x + 1`) contain vicious circles and their evaluation fails at runtime. We propose a new static analysis to check the absence of such runtime failures.\n\nOur analysis is described by a set of declarative inference rules that can be “directed” into an algorithmic check. Our implementation of this check replaced the existing check used by the OCaml programming language, a fragile syntactic/grammatical criterion which let several subtle bugs slip through as the language kept evolving.\n\nhttps://galene.org:8443/group/seminaire-pps (any password works)\n\nProofs, programs and systems\n\nThursday March 10, 2022, 10:15AM, On-line.\n\nTba Séminaire CHOCOLA\n\nProofs, programs and systems\n\nThursday March 3, 2022, 10:30AM, Salle 3052 and virtual room at link (any password works)\n\nMirna Džamonja (IRIF) Soundness after Gödel\n\nThis talk is about an exploration of a mathematical logician into a taboo in modern mathematics : the veracity of our proofs. It is not a formal proof talk and not even a foundations of mathematics one, but it rather gives a perspective of where we stand in mathematics with respect to how much we can trust our own doing, and how we could perhaps improve it. Or if it is really possible to improve. The talk is an adaptation of an invited address I gave at the conference « 90 years after Gödel’s Incompleteness Theorem » (July 202, Tübingen, Germany).\n\nOn suivra la tradition où les transparents sont en anglais et la langue de présentation le français si tout le monde est francophone, l’anglais autrement.\n\nProofs, programs and systems\n\nThursday February 17, 2022, 10:30AM, Room 3052 and virtual room at link (any password works)\n\nXavier Denis (LMF, Paris-Saclay) Creusot: A prophetic verifier for Rust\n\nRust is a fairly recent programming language for system programming, bringing static guarantees of memory safety through a strong ownership policy. This feature opens promising advances for deductive verification, which aims at proving the conformity of Rust code with respect to a specification of its intended behavior.\n\nWe present Creusot, a tool for the formal specification and deductive verification of Rust. Creusot's specification language features a notion of prophecies to reason about memory mutation. Rust provides advanced abstraction features based on a notion of traits, extensively used in the standard library and in user code. The support for traits is at the heart of Creusot's approach of verification and specification of programs.\n\nProofs, programs and systems\n\nThursday January 27, 2022, 10:30AM, Room 3052 and virtual room at link (any password works)\n\nTitouan Carette (LORIA / Université de Lorraine) Diagrammatic semantics of quantum streams\n\nIn the same way we have streams of bits and stream transformer, we can define streams of qubits and qubit stream transformers. I will present an extension of quantum circuits with quantum memories to represent stream tranfsormers. We provide a set of rewriting rule and a coinduction principle that can extend any complete set of rules for cirucits to a complete set of rule for stream transformer. Thus, any two observationaly equivalent stream transformers can be proven equivalent using our rewriting rules. I will also expose ongoing works on the denotational semantics of stream transformers and extension to the post selectioned case.\n\nProofs, programs and systems\n\nThursday January 20, 2022, 10:15AM, Virtual room at link\n\nBruno Dinis (Universidade de Lisboa) Functional interpretations and applications\n\nFunctional interpretations are maps of formulas from the language of one theory into the language of another theory, in such a way that provability is preserved. These interpretations typically replace logical relations by functional relations. Functional interpretations have many uses, such as relative consistency results, conservation results, and extraction of computational content from proofs as is the case in the so-called proof mining program.\n\nI will present several recent functional interpretations and some results that come from these interpretations. I will also give examples of application of functional interpretations, in the spirit of the proof mining program.\n\nSéminaire CHOCOLAT.\n\nProofs, programs and systems\n\nThursday January 13, 2022, 10:30AM, Virtual room at link (any password works)\n\nXavier Rival (École normale supérieure) Towards Verified Stochastic Variational Inference for Probabilistic Programs\n\nProbabilistic programming is the idea of writing models from statistics and machine learning using program notations and reasoning about these models using generic inference engines. Recently its combination with deep learning has been explored intensely, which led to the development of so called deep probabilistic programming languages, such as Pyro, Edward and ProbTorch. At the core of this development lie inference engines based on stochastic variational inference algorithms. When asked to find information about the posterior distribution of a model written in such a language, these algorithms convert this posterior-inference query into an optimisation problem and solve it approximately by a form of gradient ascent or descent.\n\nIn this talk, we analyse one of the most fundamental and versatile variational inference algorithms, called score estimator or REINFORCE, using tools from denotational semantics and program analysis. We formally express what this algorithm does on models denoted by programs, and expose implicit assumptions made by the algorithm on the models. The violation of these assumptions may lead to an undefined optimisation objective or the loss of convergence guarantee of the optimisation process. We then describe rules for proving these assumptions, which can be automated by static program analyses. Some of our rules use nontrivial facts from continuous mathematics, and let us replace requirements about integrals in the assumptions, such as integrability of functions defined in terms of programs' denotations, by conditions involving differentiation or boundedness, which are much easier to prove automatically (and manually). Following our general methodology, we have developed a static program analysis for the Pyro programming language that aims at discharging the assumption about what we call model-guide support match. Our analysis is applied to eight representative model-guide pairs from the Pyro webpage, which include sophisticated neural network models such as AIR. It finds a bug in one of these cases, reveals a non-standard use of an inference engine in another, and shows that the assumptions are met in the remaining six cases.\n\n(Joint work with Wonyeol Lee, Hangyeol Yu, and Hongseok Yang, KAIST)\n\nYear 2021\n\nProofs, programs and systems\n\nThursday December 16, 2021, 10:30AM, Virtual room at link (any password works)\n\nVasileios Koutavas (Trinity College Dublin) From Bounded Checking to Verification of Equivalence via Symbolic Up-to Techniques\n\nContextual equivalence is a relation over program expressions which guarantees that related expressions are interchangeable in any program context. It encompasses verification properties like safety and termination, has attracted considerable attention from the semantics community, and has found its main applications in the verification of cryptographic protocols, compiler correctness and regression verification.\n\nIn this talk we present a bounded equivalence verification technique for higher-order programs with local state. This technique combines fully abstract symbolic environmental bisimulations similar to symbolic game semantics, up-to techniques, and lightweight state invariant annotations. This yields an equivalence verification technique with no false positives or negatives. The technique is bounded-complete, in that all inequivalences are automatically detected given large enough bounds. Moreover, several hard equivalences are proved automatically or after being annotated with state invariants. We have realised the technique in a tool prototype called Hobbit and benchmarked it with an extensive set of new and existing examples. Hobbit can prove many classical equivalences including all Meyer and Sieber examples.\n\nProofs, programs and systems\n\nFriday December 10, 2021, 10:30AM, Virtual room at link (any password works)\n\nJérémy Ledent (University of Strathclyde) Simplicial Models for Multi-Agent Epistemic Logic\n\nEpistemic Logic is the modal logic of knowledge. It allows to reason about a finite set of agents who can know facts about the world, and about what the other agents know. The traditional Kripke-style semantics for epistemic logic is based on graphs whose vertices represent the possible worlds, and whose edges indicate the agents that cannot distinguish between two worlds. In this talk, I will present an alternative semantics for epistemic logic, based on combinatorial topology. The idea is to replace the Kripke graph by a simplicial complex, allowing for higher-dimensional connectivity between the possible worlds. In fact, every Kripke model can be turned into an equivalent simplicial model, thus uncovering its underlying topological information.\n\nThis is joint work with Éric Goubault and Sergio Rajsbaum\n\nProofs, programs and systems\n\nThursday December 2, 2021, 10:30AM, Virtual room at link (any password works)\n\nSylvain Boulmé (Verimag) Formally Verified Assembly Optimizations by Symbolic Execution.\n\nNecula (PLDI'2000) and Tristan, Gouvereau, Morrisett (PLDI'2011) established that symbolic execution combined with rewriting is effective in validating the code produced by state-of-the-art compilers applying various optimizations. In the meantime, Tristan and Leroy (POPL'2008) used formally-verified symbolic execution to certify the schedules produced by untrusted oracles – optimizing pipeline usage – within the CompCert compiler. Alas, their formally-verified checker had exponential complexity and was thus never integrated into mainline CompCert.\n\nWith Cyril Six and David Monniaux, we solved this performance issue with formally verified hash-consing within the symbolic execution. And we successfully applied this technique to implement within CompCert effective optimizations targeting superscalar (or VLIW) in-order processors.\n\nThe talk will actually start by briefly introducing a sound Foreign Function Interface for embedding OCaml oracles within Coq. Hence, it will explain how we used it in this application.\n\nThis talk will be in French.\n\nProofs, programs and systems\n\nThursday November 25, 2021, 10:30AM, Room 3052 and virtual room at link (any password works)\n\nDenis Merigoux (INRIA) Catala: A Programming Language for the Law\n\nLaw at large underpins modern society, codifying and governing many aspects of citizens' daily lives. Oftentimes, law is subject to interpretation, debate and challenges throughout various courts and jurisdictions. But in some other areas, law leaves little room for interpretation, and essentially aims to rigorously describe a computation, a decision procedure or, simply said, an algorithm. Unfortunately, prose remains a woefully inadequate tool for the job. The lack of formalism leaves room for ambiguities; the structure of legal statutes, with many paragraphs and sub-sections spread across multiple pages, makes it hard to compute the intended outcome of the algorithm underlying a given text; and, as with any other piece of poorly-specified critical software, the use of informal language leaves corner cases unaddressed. We introduce Catala, a new programming language that we specifically designed to allow a straightforward and systematic translation of statutory law into an executable implementation. Catala aims to bring together lawyers and programmers through a shared medium, which together they can understand, edit and evolve, bridging a gap that often results in dramatically incorrect implementations of the law. We have implemented a compiler for Catala, and have proven the correctness of its core compilation steps using the F* proof assistant. We evaluate Catala on several legal texts that are algorithms in disguise, notably section 121 of the US federal income tax and the byzantine French family benefits; in doing so, we uncover a bug in the official implementation. We observe as a consequence of the formalization process that using Catala enables rich interactions between lawyers and programmers, leading to a greater understanding of the original legislative intent, while producing a correct-by-construction executable specification reusable by the greater software ecosystem.\n\nProofs, programs and systems\n\nThursday November 18, 2021, 10:30AM, Room 3052 and virtual room at link (any password works)\n\nAymeric Fromherz (INRIA) Steel: Proof-Oriented Programming in a Dependently Typed Concurrent Separation Logic\n\nModern software increasingly exploits parallelism to reach new heights of performance. Unfortunately, concurrent programming is error-prone, and developers often make incorrect assumptions about how their programs will behave, raising concerns about its use in critical systems. Using formal methods to provide strong correctness guarantees is appealing, but challenging; verification frameworks either lack the expressivity required to model every advanced low-level pattern found in real-world implementations, or they do not retain the level of automation needed to ensure the scalability of verification. To address this issue, we present Steel, a new verification framework to develop and prove concurrent programs embedded in F*, a dependently typed programming language and proof assistant.\n\nIn this talk, we give an overview of Steel from the ground up. To reason about programs, Steel provides a higher-order, impredicative concurrent separation logic with support for dynamically-allocated invariants and partial commutative monoids (PCMs). To automate verification, Steel separates verification conditions between separation logic predicates and first-order logic encodeable predicates; we develop a (partial) decision procedure using efficient, reflective tactics that focuses on the former, while the latter can be encoded efficiently to SMT by F*. We will conclude by presenting several verified Steel libraries, including mutable, self-balancing trees as well as a novel PCM-based encoding of 2-party dependently typed sessions, that illustrate the expressiveness and programmability of Steel.\n\nThis talk will be in English.\n\nProofs, programs and systems\n\nThursday October 21, 2021, 10:15AM, On-line.\n\nArmaël Guéneau (Aarhus) Program verification on a capability machine in the presence of untrusted code\n\nThis talk is joint with the CHOCOLA seminar. See https://chocola.ens-lyon.fr/events/online-2021-10-22/ for details.\n\nProofs, programs and systems\n\nThursday July 1, 2021, 10AM, Online\n\nDaniele Varacca Milner and Alur walk into a bar\n\nThe chef kicks them out: “I'm sorry, in my kitchen we only use induction”\n\nThis talk will start from Morris' PhD thesis in 1968 and present 50 years of theoretical computer science, through PCF, CCS, Alternating transition systems, contexts and strategies, ending up at the footsteps of the monumental Palace of Justice in Créteil.\n\nThis talk is joint with the CHOCOLA seminar. See https://chocola.ens-lyon.fr/events/online-2021-07-01/talks/varacca/ for details.\n\nProofs, programs and systems\n\nThursday June 24, 2021, 5PM, Online at link (any password works)\n\nMichael Shulman (University of San Diego) Affine logic for constructive mathematics\n\nInformally, “constructivism” is a programme of mathematics aiming to ensure that anything asserted to exist must be explicitly constructed. It is generally practiced using intuitionistic logic, which achieves this by rejecting the law of excluded middle. However, the same result is also achieved by Girard's linear logic, which instead restricts the number of times each hypothesis can be used in a proof; but essentially no practicing constructivists today use linear logic.\n\nI will show that intuitionistic and linear approaches to constructive mathematics are intimately connected, through an interpretation of linear logic (or more precisely, affine logic) into intuitionistic logic based on a categorical Chu/Dialectica construction called the “antithesis translation”. In particular, many odd features of intuitionistic mathematics, such as inequality relations, anti-subgroups, and apartness spaces, arise automatically and unavoidably by translating natural definitions from affine logic across this interpretation. Thus, affine logic can be used as a “high-level tool” for intuitionistic mathematics, helping to find the right definitions and manage the bookkeeping of formally dual properties in proofs.\n\nProofs, programs and systems\n\nThursday June 17, 2021, 10AM, Online\n\nSonia Marin Focused nested calculi applied to the logic of bunched implications\n\nFocusing is a general technique for syntactically compartmentalising the non-deterministic choices in a proof system, which not only improves proof search but also has the representational benefit of distilling sequent proofs into synthetic normal forms. However, since focusing was traditionally specified as a restriction of the sequent calculus, the technique had not been transferred to logics that lack a (shallow) sequent presentation, as is the case for some modal or substructural logics.\n\nWith K. Chaudhuri and L. Straßburger, we extended the focusing technique to nested sequents, a generalisation of ordinary sequents which allows us to capture all the logics of the classical and intuitionistic S5 cube in a modular fashion. This relied, following the method introduced by O. Laurent, on an adequate polarisation of the syntax and an internal cut-elimination procedure for the focused system which in turn is used to show its completeness.\n\nRecently, with A. Gheorghiu, we applied a similar method to the logic of Bunched Implications (BI), a logic that freely combines intuitionistic logic and multiplicative linear logic. For this we had first to reformulate the traditional bunched calculus for BI using nested sequents, followed by a polarised and focused variant that (again) we show is sound and complete via a cut-elimination argument.\n\nThis talk is joint with the CHOCOLA seminar. See https://chocola.ens-lyon.fr/events/online-2021-06-17/talks/marin/ for details.\n\nProofs, programs and systems\n\nThursday June 10, 2021, 10:30AM, Online at link (any password works)\n\nPaul-André Melliès (IRIF) A gentle introduction to template games\n\nGame semantics is the art of interpreting formulas (or types) as games and proofs (or programs) as strategies. In order to reflect the interactive behaviour of programs, strategies are required to follow specific scheduling policies. Typically, in the case of a sequential programming language, the program (Player) and its environment (Opponent) play one after the other, in a strictly alternating way. On the other hand, in the case of a concurrent language, Player and Opponent are allowed to play several moves in a row, in a non alternating way. In the two cases, the scheduling policy is designed very carefully in order to ensure that the strategies synchronise properly and compose well when plugged together. A longstanding conceptual problem has been to understand when and why a given scheduling policy works and is compositional in that sense. In this talk, I will introduce the notion of template game and exhibit a number of simple and fundamental combinatorial properties which ensure that a given scheduling policy defines (indeed) a monoidal closed bicategory of games, strategies and simulations. The notion of template game will be illustrated by constructing two game models of linear logic with different flavours (alternating and asynchronous) using the same categorical combinatorics, performed in the category of small 2-categories.\n\nThe interested reader will find more material here https://www.irif.fr/~mellies/template-games.html https://www.youtube.com/watch?v=ZC2jtq2R3cw and in the companion papers [1,2,3].\n\n[1] PAM. Categorical combinatorics of scheduling and synchronization in game semantics. Proceedings of POPL 2019. https://www.irif.fr/~mellies/papers/Mellies19popl.pdf https://www.irif.fr/~mellies/slides/popl-slides-january-2019.pdf\n\n[2] PAM. Template games and differential linear logic. Proceedings of LICS 2019. https://www.irif.fr/~mellies/template-games/2-template-games-and-differential-linear-logic.pdf\n\n[3] PAM. Asynchronous template games and the Gray tensor product of 2-categories. Proceedings of LICS 2021. https://www.irif.fr/~mellies/papers/asynchronous-template-games.pdf\n\n[4] PAM. Une étude micrologique de la négation https://www.irif.fr/~mellies/hdr-mellies.pdf\n\nProofs, programs and systems\n\nThursday June 3, 2021, 3PM, Online\n\nCarlo Angiuli (Carnegie Mellon University) Internalizing Representation Independence with Univalence\n\nIn their usual form, representation independence metatheorems provide an external guarantee that two implementations of an abstract interface are interchangeable when they are related by an operation-preserving correspondence. In the dependently-typed setting, however, we would like to appeal to such invariance results within a language itself, in order to transfer theorems from simple to complex implementations. Homotopy type theorists have noted that Voevodsky's univalence principle equates isomorphic structures, but unfortunately many instances of representation independence are not isomorphisms.\n\nIn this talk, we describe a technique for establishing internal relational representation independence results in Cubical Agda by using higher inductive types to simultaneously quotient two related implementation types by a heterogeneous correspondence between them. The correspondence becomes an isomorphism between the quotiented types, thereby allowing us to obtain an equality of implementations by univalence. Joint work with Evan Cavallo, Anders Mörtberg, and Max Zeuner. Available at https://dl.acm.org/doi/10.1145/3434293.\n\nThis talk is joint with the CHOCOLA seminar. See https://chocola.ens-lyon.fr/events/online-2021-06-03/talks/angiuli/ for details.\n\nProofs, programs and systems\n\nThursday May 27, 2021, 10:30AM, Online at link (any password works)\n\nXavier Rival (École normale supérieure) To be announced.\n\nStatic analysis aims at discovering semantic properties of software prior to execution. Examples of emantic properties of interest include the absence of some classes of errors, the invariance of certain classes of numerical properties, or the preservation of the shape of unbounded data-structures. While many static analyses proceed by computing an over-approximation of the set of reachable states of a program, it is also possible to seek for an abstraction of the input/output relation of programs. The former is often sufficient to answer questions such as “may my program crash ?”, but the former opens up several interesting roads. First it allows to prove certain classes of functional correctness properties. Second, it makes it possible to reuse the analysis for a given program fragment (typically a function), and to speed up the overall analysis process. We call such analyses relational. However, relational analyses need to manipulate abstractions of state relations. Tables of pairs or abstract pre- and post-conditions are often used. In this talk, we present an abstraction that is based on logical connectors that are designed specifically to capture relations. We present the abstrction, analysis algorithms and examples.\n\n(Joint work with Hugo Illous and Matthieu Lemerre.)\n\nProofs, programs and systems\n\nThursday May 20, 2021, 10AM, Online\n\nValeria Vignudelli (École normale supérieure de Lyon) Monads, equational theories, and metrics for nondeterministic and probabilistic systems\n\nMonads and their presentations via equational theories provide a tool for reasoning about programs with computational effects. In recent works, we have studied monads resulting from the combination of nondeterminism, probabilities, and termination, as well as their extensions to the category of metric spaces. In this talk, we'll introduce this framework and show applications to proving equivalences and distances of nondeterministic and probabilistic systems.\n\nBibliography:\n\nBonchi, Sokolova, Vignudelli. The theory of traces for systems with nondeterminism and probabilities. LICS 2019. Available at: https://arxiv.org/abs/1808.00923\n\nMio, Vignudelli. Monads and quantitative equational theories for nondeterminism and probabilities. CONCUR 2020. Available at: https://arxiv.org/abs/2005.07509\n\nMio, Sarkis, Vignudelli. Combining nondeterminism, probability, and termination: equational and metric reasoning. LICS 2021. Available at: https://arxiv.org/abs/2012.00382\n\nThis talk is joint with the CHOCOLA seminar. See https://chocola.ens-lyon.fr/events/online-2021-05-20/talks/vignudelli/ for details.\n\nProofs, programs and systems\n\nThursday May 6, 2021, 10AM, Online\n\nBarbara König Fixpoint Theory - Upside Down\n\nKnaster-Tarski's theorem, characterising the greatest fixpoint of a monotone function over a complete lattice as the largest post-fixpoint, naturally leads to the so-called coinduction proof principle for showing that some element is below the greatest fixpoint (e.g., for providing bisimilarity witnesses). The dual principle, used for showing that an element is above the least fixpoint, is related to inductive invariants. This talks considers proof rules which are similar in spirit but for showing that an element is above the greatest fixpoint or, dually, below the least fixpoint.\n\nThe theory is developed for non-expansive monotone functions on suitable lattices of the form M^Y, where Y is a finite set and M an MV-algebra, and it is based on the construction of (finitary) approximations of the original functions. We show that our theory applies to a wide range of examples, including termination probabilities, behavioural distances for probabilistic automata and bisimilarity. Moreover it allows us to determine original algorithms for solving simple stochastic games.\n\nThis talk is joint with the CHOCOLA seminar. See https://chocola.ens-lyon.fr/events/online-2021-05-06/talks/konig/ for details.\n\nProofs, programs and systems\n\nThursday April 29, 2021, 10:30AM, Online at link (any password works)\n\nGabriel Scherer (Inria Saclay) Normalization by realizability: a dependently typed pearl\n\nThe work to be presented is in collaboration with Pierre-Évariste Dagand and Lionel Rieg. It studies the computational content of the Fundamental Lemma of classical realizability for the simply-typed lambda-calculus with sums.\n\n(If you are unfamiliar with classical realizability, it might help to think of it as a unary logical relation with an elegant symmetric setup – it originates in studies of classical logic. The talk will gently introduce classical realizability.)\n\nTwo salient points of our presentation correspond to folklore ideas that we present as opinionated recommandations, to ourselves and others, of how to give a “modern” presentation of these questions (classical realizability, and in general studying the computational content of a proof device):\n\n1. We present classical realizablity as compilation to Curien-Herbelin style symmetric abstract machine calculi, instead of the Krivine Abstract Machine, to represent realizers. Experts will recognize the polarized reduction rules of Munch-Maccagnoni.\n\n2. To present computation content, we are *not* using extraction of a program from a mathematical-style proof in a proof assistant. That beautiful approach rarely works and it generates ugly code. Instead we *write* the logical argument directly as a program in a dependently-typed (meta)language, and we think about the code we are writing.\n\nProofs, programs and systems\n\nThursday April 22, 2021, 10AM, Online\n\nGabriele Vanoni (Università di Bologna) The Time and Space of Interaction\n\nGirard's Geometry of Interaction (GOI) can be made concrete by considering it as an implementation technique for functional programs, in particular the lambda calculus. Our work is about the complexity analysis of the abstract machine based on the GOI, the interaction abstract machine (IAM). We have adapted in a non trivial way de Carvalho's non idempotent intersection types so that type derivations completely characterize the time and space complexity of the IAM, thus providing a logical account of the IAM resource usage. Moreover, by the way of the type systems we have introduced, we are able to state some negative results about time and space cost models for the lambda calculus based on the IAM. This is joint work with Beniamino Accattoli and Ugo Dal Lago.\n\nThis talk is joint with the CHOCOLA seminar. See https://chocola.ens-lyon.fr/events/online-2021-04-22/ for details.\n\nProofs, programs and systems\n\nThursday April 1, 2021, 10:30AM, https://galene.org:8443/group/seminaire-pps\n\nPierre-Evariste Dagand (LIP6) A Programming Model for Transiently-Powered Systems\n\nTransiently-powered systems featuring non-volatile memory as well as external peripherals enable the development of new low-power sensor applications. However, as programmers, we are ill-equipped to reason about systems where power failures are the norm rather than the exception. A first challenge consists in being able to capture all the volatile state of the application –external peripherals included– to ensure progress. A second, more fundamental, challenge consists in specifying how power failures may interact with peripheral operations. In a joint work with Rémi Oudin, Delphine Demange, Gautier Berthou and Tanguy Risset, we have proposed a formal specification of intermittent computing with peripherals, an axiomatic model of interrupt-based checkpointing as well as its proof of correctness, machine-checked in the Coq proof assistant. However, this result assumes that the system is able to maintain a shadow copy of the external devices it interacts with. Perhaps surprisingly, this could be an opportunity to adopt an algebraic treatment of external peripherals.\n\nProofs, programs and systems\n\nThursday April 1, 2021, 2PM, https://bbb-front.math.univ-paris-diderot.fr/recherche/hug-tje-nwj-dtk\n\nPps Members (IRIF) Journée PPS\n\nProofs, programs and systems\n\nMonday March 29, 2021, 2PM, https://bbb-front.math.univ-paris-diderot.fr/recherche/hug-tje-nwj-dtk\n\nPps Members (IRIF) Journée PPS\n\nProofs, programs and systems\n\nTuesday March 23, 2021, 10:30AM, https://galene.org:8443/group/seminaire-pps\n\nC. Keller (Université Paris-Saclay) SMTCoq: safe and efficient automation in Coq\n\nThe subject of the SMTCoq project is to significantly enhance automation in the Coq proof assistant. At the heart of SMTCoq is a Coq plugin that offers a way to use automatic provers with the same degree of trust as Coq itself. On top of it, we define a framework to progressively encode Coq's logic into first-order logic, through modular and fine-grained logical transformations that can be composed. Our objective is to obtain automatic while expressive tactics for Coq.\n\nIn this talk, I will concisely introduce the communication between Coq and external provers, before presenting the new framework of logical transformations. I will report on work in progress of examples of transformations in this framework.\n\nThis is joint work with Valentin Blot, Louise Dubois de Prisque and Pierre Vial.\n\nProofs, programs and systems\n\nTuesday March 23, 2021, 2PM, https://bbb-front.math.univ-paris-diderot.fr/recherche/hug-tje-nwj-dtk\n\nPps Members (IRIF) Journée PPS\n\nProofs, programs and systems\n\nMonday March 22, 2021, 2PM, https://galene.org:8443/group/seminaire-pps\n\nPps Members (IRIF) Journée PPS\n\nProofs, programs and systems\n\nThursday March 4, 2021, 10:30AM, Online\n\nMicaela Mayero (Université Sorbonne Paris Nord) Formalisation en Coq de problèmes numériques: un exemple avec l'intégrale de Lebesgue\n\nCe travail est un travail commun avec Sylvie Boldo, François Clément Florian Faissole et Vincent Martin dans le cadre du projet DIM-RFSI MILC. La résolution des équations aux dérivées partielles (EDP) est au cœur de nombreux programmes de simulation dans l'industrie et la méthode des éléments finis (MEF) est un outil très utilisé pour leur résolution numérique.\n\nJe présenterai le but à long terme dans lequel s'inscrit ce travail, domaine de la sécurité, de la fiabilité et de la sûreté. Il s'agit de poser les fondements qui nous permettront de prouver la correction d'une bibliothèque implantant la MEF en C++, telle que FELiScE (Finite Elements for Life Sciences and Engineering). Sa vérification formelle augmentera la confiance dans tous les codes qui l'utilisent. Ces travaux sont interdisciplinaires (logique/preuve de programmes/analyse numérique). Ces preuves reposent entre autres sur les bases mathématiques telles que la théorie de la mesure, l'intégrale de Lebesgue, les distributions, les espaces de Sobolev jusqu'à la construction de l'espace fonctionnel L2. Dans cet exposé je m'attarderai sur la formalisation de l'intégrale de Lebesgue pour les fonctions positives.\n\nVirtual room at link (any password works)\n\nProofs, programs and systems\n\nThursday February 25, 2021, 10:30AM, Online\n\nAdrian Francalanza (University of Malta) An Operational Guide to Monitorability\n\nMonitorability underpins the technique of Runtime Verification because it delineates what properties can be verified at runtime. Although many monitorability definitions exist, few are defined explicitly in terms of the operational guarantees provided by monitors, i.e., the computational entities carrying out the verification. This work views monitorability as a spectrum, where the fewer guarantees that are required of monitors, the more properties become monitorable. Accordingly, I present a monitorability hierarchy based on this trade-off. For regular specifications, I give syntactic characterisations in Hennessy–Milner logic with recursion for its levels. Finally, I map existing monitorability definitions into our hierarchy. This gives a unified framework that makes the operational assumptions and guarantees of each definition explicit and provides a rigorous foundation that can inform design choices and correctness claims for runtime verification tools.\n\nThis is joint work with Luca Aceto, Antonis Achilleos, Anna Ingolfsdottir and Karoliina Lehtinen\n\nVirtual room at link (any password works)\n\nProofs, programs and systems\n\nWednesday February 24, 2021, 2PM, https://bbb-front.math.univ-paris-diderot.fr/recherche/hug-a7x-lga-hy7\n\nElaine Pimentel (UFRN - Brazil) On linear logic, modalities and frameworks\n\nWe start by presenting a local system for linear logic (LL) based on linear nested sequents. Relying on that system, we propose a general framework for modularly describing systems combining, coherently, substructural behaviors inherited from LL with simply dependent multimodalities. This class of systems includes linear, elementary, affine, bounded and subexponential linear logics and extensions of multiplicative additive linear logic (MALL) with normal modalities, as well as general combinations of them.\n\nWe then move to the question of giving an interpretation to subexponentials. We will show a game interpretation of affine linear logic with subexponentials, viewing the game as a playground for illuminating semantic intuitions underlying resource conscious reasoning. Interestingly enough, this led to the proposal of new sequent systems for capturing the notions of costs and budget in a fragment of linear logic with subexponentials, thus opening new possibilities for analysing the problem of comparing proofs.\n\nWe finish the talk by showing a computational interpretation of subexponentials in the process-as-formula fashion, where process constructors are mapped to logical connectives and computational steps are related to proof steps. In particular, we will show in detail the role of pre-orders in subexponentials for the adequate specification of different modalities in concurrent systems, such as time, space, epistemic and preferences. We end with a discussion about which new models of computation should arise from the extension of the concept of modality in linear logic.\n\nProofs, programs and systems\n\nThursday February 18, 2021, 10:30AM, Online\n\nSamuele Giraudo (Université Gustave Eiffel) Rewrite systems on free clones and realizations of algebraic structures\n\nSome interactions between combinatorics and universal algebra through rewrite systems and clone theory are presented. Given a variety $V$ of algebras (presented by generating operations and relations between some of their compositions), a natural question consists in building a combinatorial realization of $V$. This consists in encoding the operations of $V$ in such a way that two equivalent ones have the same representation, and in providing an algorithm to compute the representation of the functional composition of several operations. In particular, we present a class of clones obtained from monoids. This gives rise among other to realizations of varieties of various classes of semigroups (commutative, left/right-regular bands, semilattices, etc.).\n\nJoint session with the Combinatoire seminar.\n\nVirtual room at link (any password works)\n\nProofs, programs and systems\n\nFriday February 12, 2021, 2PM, On-line\n\nThibaut Benjamin (LIX) CaTT : Une theorie des types qui decrit les omega-categories faibles\n\nLes omega-catégories faibles, comme toutes les structures supérieures, sont délicates a définir et a manipuler. La raison est qu'elles ont de la structure dans toutes les dimensions, et que cette structure est cohérente: pour chaque dimension, les bonnes propriétés vérifiées par la structure dans cette dimension sont encodées par des éléments de dimension supérieure. La conséquence est qu'au fur et à mesure que l'on monte en dimension, les éléments présents deviennent de plus en plus riches et complexes a décrire. Ainsi, les définitions possibles de ces structures s'appuient sur des schémas d'axiomes, permettant de générer l'infinité d'opérations et de cohérences en toute dimensions, et ces schémas d'axiomes sont eux-mêmes encodés dans des structures algébriques adéquates, comme une opérade globulaire (définition due a Batanin et Leinster) ou une catégorie avec certaines colimites (définition due a Grothendieck et Maltsiniotis). Plus récemment, Finster et Mimram ont proposé une définition des omega-catégories faibles en encodant ces schémas d'axiomes dans une théorie des types, CaTT. Dans cet exposé, je vais présenter la theorie CaTT et m'appuyer sur cette formulation pour présenter formellement les omega-categories faibles. Je vais ensuite faire une démonstration d'un assistant de preuve pour les oméga-categories faibles que j'ai implementé en m'appuyant sur cette théorie des types et discuter des possibilités de cet outil, ainsi que des améliorations que j'y ai apportées. Je vais finalement esquisser une comparaison entre CaTT et la définition de Grothendieck-Maltsiniotis des omega-catégories faibles.\n\nVirtual room at link Joint seminar with the GT “Catégories supérieures, polygraphes et homotopie”.\n\nProofs, programs and systems\n\nThursday February 11, 2021, 10:30AM, Online\n\nAntoine Genitrini (LIP6) The Combinatorics of Barrier Synchronization in Concurrency\n\nWe introduce probabilistic analysis techniques for the testing of programs based on concurrent models. During this talk we study the notion of process synchronization from the point of view of combinatorics. As a first step, we address the quantitative problem of counting the number of executions of simple processes interacting with synchronization barriers. We elaborate a systematic decomposition of processes that produces a symbolic integral formula to solve the problem. Based on this procedure, we develop a generic algorithm to generate process executions uniformly at random. For some interesting sub-classes of processes we propose very efficient counting and random sampling algorithms. All these algorithms have one important characteristic in common: they work on the control graph of processes and thus do not require the explicit construction of the state-space. By consequence, we thus completely avoid the classical combinatorial explosion induced by such processes.\n\nVirtual room at link (any password works)\n\nProofs, programs and systems\n\nThursday February 4, 2021, 10:30AM, Online\n\nRomain Péchoux (Université de Lorraine) Implicit Complexity: to infinity… and beyond!\n\nWe provide an overview of the techniques developed and results obtained in the field of Implicit Computational Complexity, which aims at providing machine-independent or PL-based characterizations of complexity classes. After discussing some related results on “infinite data” (streams, real numbers, functions, …), we present a new tractable characterization of the class of Basic Feasible Functionals (BFF), known to be the class of second order functions computable in polynomial time. The corresponding programs consist of simply-typed terms that can call strongly normalizing imperative procedures following a tier-based type discipline.\n\nVirtual room at link (any password works)\n\nProofs, programs and systems\n\nThursday January 28, 2021, 10:30AM, Online\n\nJérôme Feret (INRIA) Conservative approximation of systems of polymers\n\nWe propose a systematic approach to approximate the behavior of models of polymers with synthesis and degradation. Our technique consists in discovering time-dependent lower and upper bounds for the concentration of some quantities of interest. These bounds are obtained by approximating the state of the system by a hyper-box,. The evolution of the position of each hyper-face is defined by the means of differential equations which are obtained by pessimistically bounding the derivative with respect to the corresponding coordinate on this hyper-face.\n\nThe over-approximation of each derivative relies on symbolic reasoning. We use Kappa to describe our models. Kappa is a site-graph rewriting languages which is popular to describe protein-protein interaction networks. The main ingredients of Kappa, graph patterns, can be interpreted in two ways. Intensionally by the means of embeddings between graphs, or extensionally as the (potentially infinite) multi-sets of the complete graphs they occur in. This second interpretation leads to the definition of positive series of concentration of species. Interestingly, it can be proven that some universal constructions between graphs induce generic methods to prove the well-posedness of some numerical series, and some equality and inequality among them, hence providing a convenient tool-kit for symbolic reasoning\n\nVirtual room at link (any password works)\n\nYear 2020\n\nProofs, programs and systems\n\nThursday December 17, 2020, 10:30AM, Online\n\nVincent Rahli (University of Birmingham) Open Bar - a Brouwerian Intuitionistic Logic with a Pinch of Excluded Middle\n\nOne of the differences between Brouwerian intuitionistic logic and classical logic is their treatment of time. In classical logic truth is atemporal, whereas in intuitionistic logic it is time-relative. Thus, in intuitionistic logic it is possible to acquire new knowledge as time progresses, whereas the classical Law of Excluded Middle (LEM) is essentially flattening the notion of time stating that it is possible to decide whether or not some knowledge will ever be acquired. This paper demonstrates that, nonetheless, the two approaches are not necessarily incompatible by introducing an intuitionistic type theory along with a Beth-like model for it that provide some middle ground. On one hand they incorporate a notion of progressing time and include evolving mathematical entities in the form of choice sequences, and on the other hand they are consistent with a variant of the classical LEM. Accordingly, this new type theory provides the basis for a more classically inclined Brouwerian intuitionistic type theory.\n\nVirtual room at link (any password works)\n\nProofs, programs and systems\n\nThursday December 3, 2020, 10:30AM, Online\n\nLaure Gonnord (Université Lyon Claude Bernard) Contributions in static analyses for memory: the example of arrays\n\nProving the absence of bugs in a given piece of software (a problem which has been known to be intrinsically hard since Turing and Cook) is not the only challenge in software development. Indeed, the ever growing complexity of software increases the need for more trustable optimisations. Solving these two problems (reliability, optimisation) implies the development of safe (without false negative answers) and efficient (wrt memory and time) analyses, yet precise enough (with few false positive answers).\n\nIn this talk I will present two experiences in the design of static analyses dedicated to array properties and explore the intrinsic difficulties we, together with my coauthors, faced while developing them. I will also show some experimental evidence of the impact of this work on real-world compilers, as well as future perspective for this area of research.\n\nVirtual room at link (any password works)\n\nProofs, programs and systems\n\nThursday November 26, 2020, 10:30AM, Online\n\nAmbroise Lafont (CSIRO) Mathematical specifications of programming languages via modules over monads\n\nResearch in the field of programming languages traditionally relies on a definition of syntax modulo renaming of bound variables, with its associated operational semantics. We are interested in mathematical tools allowing us to automatically generate syntax and semantics from bas"
    }
}