{
    "id": "dbpedia_6066_2",
    "rank": 38,
    "data": {
        "url": "https://www.jmir.org/2024/1/e49431",
        "read_more_link": "",
        "language": "en",
        "title": "Design of Digital Mental Health Platforms for Family Member Cocompletion: Scoping Review",
        "top_image": "https://asset.jmir.pub/assets/09d8f1e13cf75a9b223ae346b328ba43.png",
        "meta_img": "https://asset.jmir.pub/assets/09d8f1e13cf75a9b223ae346b328ba43.png",
        "images": [
            "https://asset.jmir.pub/resources/images/logos/JMIR-25-year-logo-less-white.png",
            "https://asset.jmir.pub/assets/09d8f1e13cf75a9b223ae346b328ba43.png 480w,https://asset.jmir.pub/assets/09d8f1e13cf75a9b223ae346b328ba43.png 960w,https://asset.jmir.pub/assets/09d8f1e13cf75a9b223ae346b328ba43.png 1920w,https://asset.jmir.pub/assets/09d8f1e13cf75a9b223ae346b328ba43.png 2500w",
            "https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png",
            "https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png",
            "https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png",
            "https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png",
            "https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png",
            "https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png",
            "https://asset.jmir.pub/assets/977735c302ea2c13c7a3ccf5e61624e4.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "mental health; internet interventions; ehealth; digital health; digital health; development; design; accessibility; user engagement; user experience; caregiver; family; family caregiver; platform; mobile phone; family therapy; engagement; psychosocial; child; couples; psychosocial interventions; families; access; parent; platforms; utility; dyadic; synthesis; scoping; review methodology; dyad; review methods; e–mental health; cocompletion"
        ],
        "tags": null,
        "authors": [
            "Ellen T"
        ],
        "publish_date": "2024-07-03T00:00:00",
        "summary": "",
        "meta_description": "Background: The COVID-19 pandemic placed an additional mental health burden on individuals and families, resulting in widespread service access problems. Digital mental health interventions suggest promise for improved accessibility. Recent reviews have shown emerging evidence for individual use and early evidence for multiusers. However, attrition rates remain high for digital mental health interventions, and additional complexities exist when engaging multiple family members together.\nObjective: As such, this scoping review aims to detail the reported evidence for digital mental health interventions designed for family use with a focus on the build and design characteristics that promote accessibility and engagement and enable cocompletion by families.\nMethods: A systematic literature search of MEDLINE, Embase, PsycINFO, Web of Science, and CINAHL databases was conducted for articles published in the English language from January 2002 to March 2024. Eligible records included empirical studies of digital platforms containing some elements designed for cocompletion by related people as well as some components intended to be completed without therapist engagement. Platforms were included in cases in which clinical evidence had been documented.\nResults: Of the 9527 papers reviewed, 85 (0.89%) met the eligibility criteria. A total of 24 unique platforms designed for co-use by related parties were identified. Relationships between participants included couples, parent-child dyads, family caregiver–care recipient dyads, and families. Common platform features included the delivery of content via structured interventions with no to minimal tailoring or personalization offered. Some interventions provided live contact with therapists. User engagement indicators and findings varied and included user experience, satisfaction, completion rates, and feasibility. Our findings are more remarkable for what was absent in the literature than what was present. Contrary to expectations, few studies reported any design and build characteristics that enabled coparticipation. No studies reported on platform features for enabling cocompletion or considerations for ensuring individual privacy and safety. None examined platform build or design characteristics as moderators of intervention effect, and none offered a formative evaluation of the platform itself.\nConclusions: In this early era of digital mental health platform design, this novel review demonstrates a striking absence of information about design elements associated with the successful engagement of multiple related users in any aspect of a therapeutic process. There remains a large gap in the literature detailing and evaluating platform design, highlighting a significant opportunity for future cross-disciplinary research. This review details the incentive for undertaking such research; suggests design considerations when building digital mental health platforms for use by families; and offers recommendations for future development, including platform co-design and formative evaluation.",
        "meta_lang": "en",
        "meta_favicon": "https://asset.jmir.pub/assets/static/images/apple-touch-icon-57x57.png",
        "meta_site_name": "Journal of Medical Internet Research",
        "canonical_link": "https://www.jmir.org/2024/1/e49431",
        "text": "Introduction\n\nFamily Mental Health\n\nNormatively, mental health disorders impacted >1 billion people worldwide in 2016 [ ]. The COVID-19 pandemic brought further substantial impact on mental health, placing increased demand on mental health services [ ]. Mental health is inherently relational [ , ], and family members and partners are inevitably impacted by an individual’s mental health challenges [ ]. During the COVID-19 pandemic, markers of heightened family stress included rising rates of family violence [ ]; increased parenting stress [ ]; and observed rates of maladaptive parenting practices, including neglectful, harsh, and coercive parenting [ - ].\n\nThere is a strong evidence base for family and systemic interventions for child- and adult-focused mental health challenges. Family participation supports members of the family to safely contribute to individual recovery and improved relationships [ - ] and can be more beneficial than individual work [ - ] and family educational interventions [ ]. In addition, parent involvement in interventions for childhood behavioral [ ] and adolescent anxiety disorders [ ] has been shown to be beneficial and contributes to positive long-term outcomes.\n\nDigital Mental Health\n\nThe World Health Organization has emphasized the significant potential of digital mental health interventions (DMHIs) in expanding reach and access to services [ ]. Such DMHIs have shown promise in reaching underserved populations [ ], leading to improved management of symptoms in individuals [ ], particularly youth aged <25 years [ , ]. There is growing meta-analytic evidence for positive mental health outcomes of digitally delivered versus in-person individual treatment, for example, in the field of cognitive behavioral interventions [ ]. With rapid developments in technology, research interest is expanding, with most of the literature so far focused on DMHIs for individuals. For example, a review of systematic reviews of digital interventions for mental health and well-being (with no limitations placed on population) conducted in 2021 identified 246 systematic reviews published between 2016 and 2021, all of which reviewed digitally delivered mental health interventions for individuals [ ].\n\nBeyond DMHIs designed for individuals, 2 first-generation reviews of dyadic (caregiver and care recipient) [ ] and couple-targeted DMHIs [ ] suggest that DMHIs can decrease barriers and improve timely access and outcomes for distressed relationships. However, research into DMHIs for families to access together is as yet undeveloped.\n\nDespite growing evidence, and regardless of the population targeted, retention rates for DMHIs remain low, limiting their ultimate impact [ - ]. Among other factors, interface ease of use has been identified as a barrier to DMHI retention and engagement by individuals [ , ]. It is likely that similar (or possibly even greater) barriers for family engagement in the digital mental health space exist. Given the fundamental differences in the approach and focus for family and relational interventions when compared to interventions designed for individuals [ , ], it is likely that there are unique factors to consider when designing DMHIs for use by families. This might include considerations for individual user privacy and ways in which the platform allows multiple people to contribute to and especially cocomplete activities, such as shared goal setting. Thus, it would be ill-founded to extrapolate results from studies on DMHIs designed for use by individuals and assume similar platform interaction values for families. The need for further research specific to the design of DMHIs for family use is clear.\n\nDesign of DMHIs for Families\n\nTherefore, the question arises about what an effective DMHI for family use might look like. Given that computers and tablets are designed for use by individuals, DMHIs intended for cocompletion by family members may use different platform and interface features to support and sustain family engagement. No review to date has examined evidence for design and build characteristics that promote cocompletion usability, including improved engagement and accessibility.\n\nIn that light, this review aimed to synthesize the available evidence regarding the build and design characteristics that enable cocompletion and discuss reported indicators of user engagement with platforms designed for such use, namely, usability, satisfaction, acceptability, and feasibility. In the digital mental health literature, these user engagement indicators measure the ability of a platform to engage and sustain users. However, there is a notable lack of agreement on both the definition and measurement of the construct of engagement, which can lead to inappropriate selection, presentation, and interpretation of user engagement indicators across studies [ ]. As such, a scoping review was conducted, and we adopted the definition of user engagement as outlined by Perski et al [ ]: “Engagement with [Digital Behaviour Change Interventions] is (1) the extent (e.g. amount, frequency, duration, depth) of usage and (2) a subjective experience characterised by attention, interest and affect.”\n\nIn this scoping review, we differentiate the term “platform” from the term “intervention.” We define “platform” as the tools, infrastructure, and technical foundation behind the delivery of an intervention, including interface characteristics such as the design, layout, and delivery mode. We define “intervention” as the mental health–related content that is delivered via the platform. This review sought to understand (1) the design and functionality characteristics that enable the effective engagement with and cocompletion of a family-oriented DMHI and (2) whether these elements moderate the effect of the intervention on mental health or relational outcomes. To distinguish effective platform contributors to engagement from elements pertaining to intervention content, we selected only those platforms housing interventions of established clinical efficacy (which we defined as any intervention that had at least one study reporting a significant improvement in a mental health or relational outcome). In addition, it is expected that build characteristics may vary by population, and given that there is no uniform family composition, this review scoped platforms designed for cocompletion by any family relationship type, including couples, family subsystems, and whole families.\n\nMethods\n\nSearch Strategy\n\nTo identify studies reviewing platforms delivering clinical interventions designed for cocompletion by families, a systematic search was conducted following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines [ ]. A comprehensive electronic literature search for articles published in English was conducted in the following databases: MEDLINE, Embase, and PsycINFO via the Ovid platform; CINAHL via the EBSCOhost platform, and Web of Science. In line with developments in digital technology, studies were included if they were published in or since 2002. The search was first conducted on June 24, 2022, and additional searches were conducted on November 24, 2022; April 21, 2023; and March 15, 2024.\n\nEligibility Criteria\n\nAs advised by the Joanna Briggs Institute’s guidelines for conducting scoping reviews [ ], the population, concept, and context framework was used to define eligibility. shows the inclusion and exclusion criteria in line with the population, concept, and context framework and contains additional study elements relevant to the eligibility criteria.\n\nStudies were not excluded when platforms contained additional components involving practitioner (sometimes referred to in the studies as a coach, professional, therapist, or staff member) engagement. Further to the inclusion and exclusion criteria outlined in , platforms offering interventions that had no evidence of clinical efficacy (ie, no identified studies that reported any significant improvements in mental health or relational outcomes) were excluded. Provided that at least 1 identified study established clinical efficacy for that platform, all studies on that intervention were then included regardless of whether they reported on clinical outcomes. Platforms that met all the other inclusion criteria but without established clinical efficacy are presented in .\n\nSearch and Data Extraction Methodology\n\nA total of 3 key search constructs addressed the different elements of the research question: digital intervention, mental or relational health, and population. Results were combined using Boolean operators. The search strategies for each database can be found in . The reference lists of relevant reviews were also screened for potentially relevant studies. Data extraction was completed by 2 researchers trained in systematic search methodology using a standardized template, and discrepancies were resolved through discussion between the 2 researchers. In cases in which it appeared that there could be cocompletion but it was not directly specified, the study authors were contacted, and websites were searched.\n\nScreening and Selection Process\n\nSearch results were downloaded into EndNote (Clarivate Analytics) [ ] and imported into Covidence (Veritas Health Innovation) [ ]. Duplicates were first removed in EndNote and again following import into Covidence. In total, 2 researchers screened the identified studies at the title and abstract level, with 20% being double screened. Disagreements were resolved through discussion. A total of 2 researchers screened the articles at the full-text level with 20% double screening to determine eligibility against the inclusion criteria outlined previously. Reasons for exclusion at the full-text level were recorded.\n\nData Synthesis\n\nData were synthesized using a narrative approach. Due to high variability in the reporting of outcomes and measurements across studies, a systematic or meta-analytic approach was not possible.\n\nThe included articles were grouped by the digital platform used. Information regarding the authors, the year of publication, the country where the study took place, the population, and associated user engagement indicators was extracted. Significant differences in mental health or relational outcomes following the DMHI were indicated. Details about the platforms were extracted into a separate table. Also detailed were the intervention target; the relationship between the participants; components designed to be completed in a self-paced manner, together, individually, or with a professional; tailored components; and any additional key features. Results were categorized and synthesized based on the targeted relationship for the intervention (eg, couples or families).\n\nResults\n\nOverview\n\nThe combined searches yielded 17,765 results. Following removal of 46.37% (8238/17,765) of duplicates in EndNote and Covidence, 9527 papers were screened at the title and abstract level, resulting in 9184 (96.4%) exclusions. A total of 343 full-text articles were reviewed for inclusion, with 263 (76.7%) exclusions. Reasons for exclusion included the platform being designed for use by individuals (154/263, 58.6%), nonempirical studies (55/263, 20.9%), the platform not containing any self-guided components (36/263, 13.7%), or wrong indication (eg, weight loss intervention; 18/263, 6.8%). A total of 80 studies were included for data extraction. An additional 5 studies were identified through reference scanning and included in data extraction, resulting in a total of 85 studies included in this review. shows the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) diagram [ ].\n\nThe following sections first summarize the studies identified and then report on characteristics of and findings related to the included platforms.\n\nIncluded Studies\n\ndetails the characteristics of the 85 studies, including study type, their population and sample size, usability measures and findings, and an indication of clinical efficacy based on significant improvement in mental health or relational outcomes following completion of the intervention. Among the 85 included studies, data were collected during randomized controlled trials (n=63, 74%), pilot feasibility studies (n=14, 16%), single-arm studies (n=7, 8%), and nonrandomized quasi-experimental studies (n=1, 1%).\n\nA total of 74% (63/85) of the studies were conducted in the United States; 12% (10/85) were conducted in Canada; 5% (4/85) were conducted in Australia; 2% (2/85) were conducted in the United Kingdom; 2% (2/85) were conducted in China; and 1% (1/85) were conducted each in the Netherlands, Sweden, Japan, and Korea. In total, 52% (44/85) of the included studies were published between January 2019 and March 2024, whereas 5% (4/85) of the studies were published in the first 5 years of the search period (2002-2006 inclusive) and the remainder (37/85, 43%) were published in between these periods.\n\nThe Platforms\n\nOverview\n\nA total of 24 unique platforms were identified from the 85 studies. shows the characteristics of the 24 platforms, including the intervention target; relationship targeted; duration of intervention participation; components designed for cocompletion, individual completion, and therapist engagement; any tailoring offered; and additional reported features.\n\nMost interventions (14/24, 58%) were designed for cocompletion by couples, with some identified interventions for parent-child dyads (6/24, 25%), families (2/24, 8%), and caregiver–care recipient dyads (2/24, 8%). Given that it was expected that build characteristics might differ according to the population (eg, number of participating family members and their ages), platform results are grouped and reported by the relationship structure targeted by the platform (ie, couples, parent-child dyads, families, and caregiver–care recipient dyads).\n\nData from are synthesized based on the features of the platforms and detail reported user engagement indicators. As platforms were included only in cases in which at least one study had demonstrated clinical efficacy of the intervention, mental health and relational outcomes are not reported in this table (and are, instead, indicated in ).\n\nCouples\n\nFeatures of Platforms for Couples\n\nOverview\n\nOf the platforms requiring cocompletion, platforms designed for couples were the most common. A total of 58% (14/24) of the identified platforms were for couples. The intervention targets included relationship distress when a member has a cancer diagnosis (2/14, 14%); relationship functioning when a member has a cancer diagnosis (2/14, 14%), has posttraumatic stress disorder (1/14, 7%), or is a veteran (1/14, 7%); parenting-focused interventions, including a father-inclusive parenting intervention (1/14, 7%), education for foster and adoptive parents (1/14, 7%), and an intervention for military couples transitioning to parenthood (1/14, 7%); partnership support interventions for cases in which the male partner is undergoing treatment for infertility (1/14, 7%) or a member is pregnant (1/14, 7%); general relational distress (1/14, 7%); and preventative interventions to enhance relationship satisfaction and mental health (1/14, 7%) and reduce vulnerability to middle adulthood depression (1/14, 7%).\n\nStructure and Duration of Engagement\n\nDuration of participation varied from 1 to 16 weeks, with the most common duration being 8 weeks (5/14, 36%) followed by 6 weeks (4/14, 29%), including 1 intervention described as taking 5 to 7 weeks. The intended duration of 7% (1/14) of the interventions was not specified. One intervention offered a brief version that was completed by couples in 2 weeks as opposed to the 6-week full version. As per the inclusion criteria for this review, all interventions involved some web-based self-paced component completed on the platform. Most appeared to require at least weekly engagement, although it was not always specified or prescribed. One platform was designed such that participants could complete the intervention modules in any order but advised participants to access 1 module per week and complete all modules. For all the remaining interventions, it appeared that intervention content or modules were designed to be completed in a defined order and over a specified period.\n\nCoparticipation and Contact With Practitioners\n\nA total of 43% (6/14) of the interventions contained elements that were intended for individual completion (ranging from completing assessments to completion of entire sections of content), 50% (7/14) of the interventions required couples to cocomplete the whole intervention, and 7% (1/14) of the interventions gave participants the choice to complete some or all of the intervention together. In total, 57% (8/14) of the interventions included an element of practitioner engagement, including asynchronous platform-based messaging or scheduled synchronous counseling sessions.\n\nTailoring and Additional Features\n\nBeyond personalization through contact with practitioners, 29% (4/14) of the platforms provided tailored content or options for personalization. A total of 14% (2/14) of the platforms provided supplementary content that could be accessed based on need, and 14% (2/14) of the platforms provided personalized feedback and reporting based on responses to questionnaires. In total, 29% (4/14) of the platforms specified that they were formatted for both web and mobile or tablet use, and 7% (1/14) of the platforms allowed participants to select either audio-enhanced or text-based presentation of content. Finally, 7% (1/14) of the platforms included an automated graph depicting reported symptom change over time and a progress bar to incentivize participation.\n\nReported User Engagement Indicators of Platforms for Couples\n\nA total of 56% (48/85) of the studies examined the 14 couple-focused platforms. Of those 48 studies, 30 (62%) reported on user engagement indicators, including 23 (77%) studies that reported on satisfaction, feedback, usability, participant evaluation, feasibility, and acceptability and 18 (60%) that reported on completion rates and website use. The remaining 38% (18/48) of the studies did not report on any user engagement data or findings.\n\nMeasures used to collect participant satisfaction, feedback, usability, and evaluation varied. A total of 10% (5/48) of the studies administered the Client Evaluation of Services Questionnaire [ ], and 15% (7/48) used the Client Satisfaction Questionnaire [ ]. The remaining studies reported on satisfaction, feedback, and participant evaluation through nonvalidated measures. Satisfaction ratings were generally high across all studies.\n\nThe impact of video content on user engagement appeared mixed. Participants in 8% (4/48) of the studies provided feedback that the content and examples presented in the videos were helpful; however, in another 4% (2/48) of the studies, participants reported that the videos were unhelpful or that they negatively impacted engagement as they were not relatable, overly dramatized, or appeared outdated. In addition, participant qualitative feedback reported in another study suggested that outdated imagery and low-technology visualizations also negatively impacted engagement. Other factors that were reported to be important based on qualitative feedback included one study that reported on the structured nature of the intervention and reminder calls and another where participants reported that they were more likely to access audio-enhanced slides than text-based content. Feedback provided by participants in one study also noted that the flexibility of the web-based format facilitated engagement. However, in general, satisfaction, feedback, usability, and evaluation data were reported as average values on rating scales.\n\nReporting of completion rates and website use rates varied. They were reported as combinations of the following: the average number of participants who completed the entire intervention, the average number of modules or sessions completed by individuals or couples, the average time to completion, the number of discrete log-ins or page views, and the amount of time spent accessing the platform. Feasibility and acceptability data were reported similarly, with completion statistics often used as an indication of an intervention’s feasibility or acceptability. In addition, 5 studies reported on predictors of noncompletion, including 3 (60%) studies that reported higher levels of support from a practitioner as predictors of completion. The remaining 40% (2/5) of the studies reported on participant baseline characteristics as predictors of noncompletion.\n\nFinally, 4% (2/48) of the studies on the same platform identified different couple “types” with regard to their enthusiasm and engagement (eg, “keen completers” or “stragglers”) and therapists’ role in engagement promotion. One study reported that higher levels of engagement (measured using participants’ correct responses to quiz questions) led to greater intervention effect on a number of clinical outcomes, and another found that those with the shortest time frame between commencement and completion (ie, completed the intervention faster) were more likely to be classified as “treatment responders” (identified by significant improvement on outcomes) at the postintervention assessment.\n\nNo studies of couple-based platforms identified build or design characteristics as moderators of intervention effect. No studies performed a formative evaluation of the platforms, and no studies reported design and build characteristics that enabled coparticipation beyond participant qualitative feedback.\n\nParent-Child Dyads\n\nFeatures of Platforms for Parent-Child Dyads\n\nOverview\n\nPlatforms designed for co-use by parent-child dyads were the second most common, accounting for 25% (6/24) of the platforms identified in this review. The intervention targets included behavioral problems and conflict in young minority adolescents and their families (1/6, 17%), emotional development and parental responses to child behavior (1/6, 17%), mother-daughter relationship quality and risk of underage drinking (1/6, 17%), adolescent male domestic violence prevention (1/6, 17%), emotional availability and parent-child adjustment when a child has cerebral palsy (1/6, 17%), and anxiety management skills and psychoeducation for parents and children (1/6, 17%). A total of 67% (4/6) of the platforms were developed for adolescents and a parent, 17% (1/6) were for young children aged 2 to 7 years and a parent, and 17% (1/6) were for children aged 7 to 12 years and their parents. In all cases, only 1 parent was asked to participate. In the following sections, we summarize the reported features of the platforms as detailed in the included studies.\n\nStructure and Duration of Engagement\n\nDuration of intervention use varied from 4 to 12 weeks, with the most common duration being 10 weeks (3/6, 50%). One intervention of a 10-week duration in total enforced an extended break in the middle of intervention engagement, and another offered a brief version of only 4 weeks (compared with the 10-week full version). Participation varied from once a fortnight to 2 web-based sessions or modules a week. A total of 83% (5/6) of the interventions appeared to involve completion in a structured manner following a predetermined order. One platform presented intervention content in a modular format that allowed participants to select the content that was relevant to their needs and cultural preferences in any order. However, the intended duration and number of modules accessed appeared to be prescribed.\n\nCoparticipation and Contact With Practitioners\n\nThe amount and method of coparticipation varied greatly. A total of 33% (2/6) of the platforms required parents to watch the intervention content or preparatory materials before engaging with their adolescent child. In total, 33% (2/6) of the platforms required the parent to complete explanation videos or additional content following cocompletion with their young child. A total of 17% (1/6) of the platforms involved cocompletion of all intervention modules and independent completion of questions about content, with both the parent and adolescent required to complete these questions before the dyad could progress to the next module. Finally, studies on 17% (1/6) of the platforms reported that “some exercises” were designed for cocompletion but did not specify the extent of cocompletion.\n\nA total of 67% (4/6) of the interventions included contact with a practitioner, whereas 33% (2/6) were entirely self-guided. One of those offering contact with a practitioner only offered this to parents and not the participating child. A total of 33% (2/6) of the interventions included scheduled sessions with a practitioner to discuss content, with 17% (1/6) also supporting asynchronous communication with a practitioner via the platform. Finally, in 17% (1/6) of the interventions, participants could contact practitioners via the platform for technical troubleshooting as required.\n\nTailoring and Additional Features\n\nIn total, 17% (1/6) of the platforms allowed participants to select content based on their clinical and cultural needs. Content was selected from a list of available modules, although the process through which the dyads selected this content was not described. This same platform offered dyads links to external sources of information based on their responses to questionnaires.\n\nReported User Engagement Indicators of Platforms for Parent-Child Dyads\n\nA total of 14% (12/85) of the studies evaluated 6 different interventions designed for use by parent-child dyads. Of those 12 studies, 5 (42%) reported on user engagement indicators, including completion or fidelity (4/5, 80%) and satisfaction or acceptability (3/5, 60%). The remaining 58% (7/12) of the studies reported on mental health or relational outcomes and did not report on user engagement indicators.\n\nThe 33% (4/12) of the studies reporting on completion or fidelity documented the number of participants who completed the entire intervention as prescribed. One study also reported on the average time it took participants to complete the intervention, and another reported on the number of dyads who accessed all sessions and received calls from a practitioner. No studies reported on participants’ interaction with the platform or any predictors of noncompletion.\n\nAll studies reporting on satisfaction and acceptability did so using nonvalidated measures. Mean satisfaction ratings were high. One study asked participants to indicate how easily they found time to complete the activities together, with a mean rating of 3.04/5 (SD 0.37) for daughters and a mean rating of 3.24/5 (SD 0.33) for mothers. In no study did the satisfaction and acceptability data distinguish between platform and intervention satisfaction.\n\nNo studies on parent-child interventions identified platform build or design characteristics as moderators of intervention effect. No studies performed formative evaluations of the platforms, and no studies reported on design and build characteristics that enabled coparticipation.\n\nFamilies\n\nFeatures of Platforms for Families\n\nOverview\n\nAmong the 24 platforms, 2 (8%) designed for cocompletion by families were identified. The intervention targets included family functioning when a child has an anxiety diagnosis (1/2, 50%) and family functioning when a child, adolescent, or teenager has a traumatic brain injury (1/2, 50%). Both platforms were intended for use by a child, adolescent, or teenager with a presenting clinical concern and any family members, including parents and siblings. Though siblings and other family members were invited to participate, the studies detailed outcomes and engagement for a single parent and child only.\n\nStructure and Duration of Engagement\n\nIntervention participation on one platform extended for 10 weeks over 11 web-based chapters, and the other delivered 7 to 11 sessions over 6 months. Both were designed for sequential completion of module content.\n\nCoparticipation and Contact With Practitioners\n\nOne platform asked family members to complete the entire intervention together. The other asked parents to complete sections themselves before working with their children on a small number of modules intended for cocompletion. Both included scheduled telehealth sessions with a practitioner during intervention participation. In addition, one platform also included a platform-based message system for contacting practitioners asynchronously. In this same platform, practitioners also provided reports to participants following exercise completion.\n\nTailoring and Additional Features\n\nOne platform provided no tailoring beyond engagement with and feedback provided by practitioners. The other platform included supplementary sessions that could be completed by families should they wish to. In addition, this platform supported cocompletion by asking family members to select their picture when they were present. The platform would then either prompt individual family members to respond or ask all family members to respond together.\n\nReported User Engagement Indicators of Platforms for Families\n\nA total of 27% (23/85) of the studies examined the 2 family-based interventions. Of these 23 studies, 16 (70%) reported user engagement indicators including satisfaction and ease of use (n=9, 56%); completion rates, compliance, adherence, and website use (n=13, 81%); and feasibility (n=2, 12%). The remaining 30% (7/23) of the studies did not report on satisfaction, completion, or feasibility data or findings.\n\nOf the 9 studies reporting satisfaction and ease of use, 6 (67%) used an adaptation of the Website Evaluation Questionnaire [ ] to measure participant satisfaction with the intervention. The remaining 33% (3/9) of the studies administered nonvalidated measures developed for the studies. Satisfaction ratings were high across all studies. In 33% (2/6) of the studies in which the Website Evaluation Questionnaire was administered, participants were asked to rate the website’s ease of use, generally reporting that the website was “moderately easy” to “easy” to use. Participants in one study reported a preference for meeting in person. Other than this, satisfaction ratings either were relevant to content or did not distinguish between platform and intervention satisfaction.\n\nCompletion rates, compliance, adherence, and website use were all reported as combinations of the following: the number of participants who completed the entire intervention, the average number of modules completed, time spent on the platform, and the number of families who completed supplemental sessions. Feasibility was reported similarly, with one study also reporting that families were able to complete all sessions without practitioner assistance. In addition, one study reported on number of sessions completed as a predictor of symptom change (with inconsistent effect), and another reported on participant characteristics at baseline as predictors of completion.\n\nA total of 13% (3/23) of the studies also measured participants’ technology use and comfort with technology before the commencement of the intervention and examined this as a predictor of intervention effect. Results were inconsistent. In addition, one study identified whether participants’ preference for treatment modality before the intervention, that is, face-to-face, web self-paced, or therapist-guided modality, impacted treatment outcomes. It was found that adolescent treatment preference was significantly related to attrition, but there were no other links with treatment effect or satisfaction.\n\nNo studies on family-based platforms identified build or design characteristics as moderators of the intervention effect. No studies performed a formative evaluation of the platforms, and aside from one study describing how participants identified that they were present, no studies reported design and build characteristics that enabled coparticipation.\n\nCaregiver–Care Recipient (Family) Dyads\n\nFeatures of Platforms for Caregiver–Care Recipient Dyads\n\nAmong the 24 platforms, 2 (8%) were identified for family caregiver–care recipient dyads. The targets of the interventions on the platforms included dyadic resilience for patients with stroke or brain tumor and their family caregivers (1/2, 50%) and the psychosocial health of patients with cancer and their family caregivers (1/2, 50%).\n\nStructure and Duration of Engagement\n\nOne of the 2 platforms involved intervention participation over 6 weeks, with 3 sessions delivered sequentially. The other platform contained 4 web-based modules and a participant journal completed over 8 weeks. While not explicitly reported, it appeared that this platform also required sequential completion of intervention content.\n\nCoparticipation and Contact With Practitioners\n\nBoth platforms were designed to be completed by members of the dyad together; however, one had the option of completing the entire intervention independently if desired. One platform contained an asynchronous help function that generated an email to the project director. The other included a telehealth session before commencement of the web-based component.\n\nTailoring and Additional Features\n\nOne platform contained several tailored elements, whereas the other did not offer any personalization. Tailoring included platform-generated messages that provided web links addressing the dyad’s concerns and supplementary activities offered between web sessions. Both were generated from self-reported baseline information.\n\nReported User Engagement Indicators of Platforms for Caregiver–Care Recipient Dyads\n\nThe 2 interventions were each evaluated in 1% (1/85) of the studies. Both studies reported on satisfaction, and one reported on feasibility, with both reporting high satisfaction ratings. One study reported that there were no adverse effects of participants completing the intervention on the web-based platform together, and the other identified the length of the modules and the ability to complete the intervention in the users’ own time as facilitators to use. In one study, participants noted that finding time to complete the intervention as a dyad was sometimes challenging. Where feasibility was reported, the study found lower enrollment rates than those for previous in-person randomized controlled trials but higher retention rates.\n\nNeither study identified build or design characteristics as moderators of intervention effect. No study performed a formative evaluation of the platforms, and neither reported on design nor build characteristics that enabled coparticipation.\n\nDiscussion\n\nPrincipal Findings\n\nThis review details build, design, and user engagement characteristics of platforms that enable cocompletion of clinical interventions by related people. To distinguish effective platform contributors to engagement from elements pertaining to intervention content, we selected only those platforms housing interventions of established clinical efficacy (ie, previously reported significant improvement of at least one mental health or relational outcome). Some common design features were identified; however, in contrast to expected findings, specific design characteristics enabling cocompletion were rarely reported, and evidence for engaging families was underexplored.\n\nCommon Platform Features\n\nThis review identified platform design features that were common across the included studies. Regardless of the relationship targeted, most platforms delivered a structured intervention that required engagement over a prescribed duration with content completed sequentially. A total of 8% (2/24) of the platforms allowed participants to access content in a nonsequential manner, and a handful (4/24, 17%) offered supplementary content based on identified need. Retention rates remain low for DMHIs [ ], and there are further complexities when family members participate together [ ]. As such, consideration might be given to ways in which families’ time on the platform can be optimized.\n\nSingle Session Thinking is one process through which therapists treat each encounter as if it were the sole session, encouraging the participants to make the most of the time [ ]. Adaptation to web delivery of family therapy sessions already holds promise [ ], and digital single-session interventions have been trialed in college student settings with positive preliminary findings [ - ]. Therefore, there is emerging evidence suggesting that Single Session Thinking principles could be readily applied to DMHIs, mimicking single, stand-alone sessions that address the family’s present needs as they identify them. Check-in prompts and invitations to return as needed could be automated from the platform to encourage return visits as required or desired by the family. A platform designed to deliver content in this way would likely reduce the burden on families and provide greater flexibility in how they access content.\n\nMinimal tailoring was offered in 29% (7/24) of the DMHIs identified in this review, providing more or less the same intervention to all participants. A total of 67% (16/24) of the interventions included interaction (either synchronous or asynchronous) with a practitioner. Evidence for personalized mental health care is growing rapidly, acknowledging the complexity and diversity of individuals and families [ , ]. Higher levels of engagement are reported for guided interventions (ie, those where participants have some contact with a practitioner) than for self-guided interventions; however, incorporating human contact can be costly and can limit the flexibility and accessibility associated with DMHIs [ ]. Research suggests that, compared with targeted or generic feedback, personalization can be used to improve engagement and subsidize personal contact and contributes to positive attitudes toward a DMHI [ , ]. Beyond this, several studies included in this review (9/85, 11%) identified baseline characteristics that moderated participants’ responses to the intervention. These included characteristics such as age, relationship status, and previous comfort with technology. Understanding how baseline measures might impact participants’ ability or desire to engage with platforms and providing options for personalization accordingly would likely result in greater engagement. A family-based platform might include tailored design options such as color and font choices, preferences for video- or text-based content, and preferences for receipt of prompts and reminders. In addition, if children are present, families could have the option to access content that has been adapted for younger readers. In a world where artificial intelligence is supporting personalization across the internet, it would be remiss not to consider personalization in family- and relational-based DMHIs.\n\nPlatform Features for Enabling Cocompletion\n\nBy their nature, computers and mobile devices are designed for use by individuals. Given obvious complexities involved in having multiple people participate in a web-based intervention together, it was expected that platforms designed for such use may contain features for enabling cocompletion across the life span. It was also expected that the way in which participants engage may differ from that in platforms designed for individual use. This could include considerations about privacy of individual participants’ data, methods for encouraging participants to work together, and design choices to allow all participants to contribute to activities. One platform requested participants to select their image when they were in attendance, and this was then used to prompt individuals to respond and participate in activities. Other than this, no study identified platform characteristics that were included to specifically enable cocompletion. In general, studies detailed participants’ engagement with the intervention but not with the platform. Reporting on platform engagement might include details on how participants navigated the interface, how they identified and accessed content, or the modes through which content was delivered. On the other hand, intervention reporting was found to delve into factors such as attrition rate and measurement completion. Crucially, it is important to distinguish between intervention trial attrition (ie, dropout or loss to follow-up) and platform disengagement (ie, nonuse attrition), as recommended in a previous review [ ]. These 2 forms of attrition are influenced by distinct factors [ , ], and failure to differentiate between them could potentially lead to misinterpretation of platform engagement dynamics.\n\nIt was also expected that studies would provide insights into the build and design considerations related to individual user privacy and safety within a shared web-based space. This encompasses considerations such as determining when an individual’s information can or should be shared with other members of the family and effectively identifying and responding to safety risks. From our perspective, these design aspects are essential considerations when developing a family-based DMHI. However, none of the studies identified in this review reported or discussed how they tackled or addressed these privacy and safety considerations. To further ensure the adequate addressing of not only these concerns and anticipate other potential considerations, rigorous co-design processes are essential. This co-design strategy would significantly contribute to the refinement of family-based DMHIs, ensuring that they meet the nuanced needs of users.\n\nEngagement With Practitioners\n\nThe varied nature of engagement with guided tools (ie, involving interaction with practitioners, structured sessions, and feedback loops) stands in stark contrast to the self-guided use and consistent participation characterizing engagement with tools lacking contact with practitioners. Recognizing challenges intrinsic to self-guided tools, such as user motivation and adherence, becomes paramount, particularly given that the absence of practitioner involvement is likely to make the sustainability of user interest more demanding. The role of technology in promoting engagement with practitioners is multifaceted, encompassing communication facilitation through asynchronous methods and data-driven insights that enhance personalized interactions. Moreover, exploring hybrid models and incorporating periodic check-ins or teletherapy sessions within self-guided platforms presents a promising balance between autonomy and professional support.\n\nAddressing challenges in technology engagement involves prioritizing user-centered design; integrating behavioral science principles; and leveraging feedback mechanisms, either automated or through clinician input, to ensure continuous support and guidance. Looking forward, suggested avenues for future research are many, including the long-term effectiveness of guided and self-guided tools, understanding the impact of different engagement strategies, and developing sophisticated technology-assisted therapeutic approaches.\n\nEvidence for Enabling Cocompletion\n\nWe faced constraints in reporting evidence on platform features that engaged and enabled cocompletion by families because no study conducted a direct evaluation of the platform design. This limitation hindered our ability to provide comprehensive insights into the effectiveness of features promoting cocompletion among participating family members. In addition, while several studies (13/85, 15%) evaluated practitioner support, family member coparticipation, population characteristics, and baseline scores on mental health or relational measures as moderators of intervention outcomes, no study evaluated design features as potential moderators of intervention outcomes.\n\nOf the 85 included studies, 66 (78%) reported on user engagement indicators. Of those, most (48/66, 73%) used custom, nonvalidated measures, and the remaining studies used validated measures that were intervention specific and gave no information about platform engagement. Given this measurement heterogeneity, little is possible by way of cross-study comparison. In addition, without evaluation of platform design strategies, no conclusions can be drawn about enabling or disabling features. The capacity for real-world translation and understanding of how to overcome known barriers is constrained.\n\nA Need for Cohesive Platform Evaluation and Reporting\n\nPlatform user experience design, including ease of use, navigation, screen layout, readability, gamification, feedback, and attractiveness, plays a large role in a participant’s perception of and engagement with a website and, ultimately, a site’s usability [ , , ]. In addition, individual participant characteristics such as age, literacy level, level of disability, and mental health conditions may impact their engagement with and ability to use a platform as designed. When a family presents on a web-based platform, more than one person’s needs must be catered to.\n\nThere is a lack of consensus and shared understanding of how to usefully conceptualize and measure engagement with and accessibility of digital mental health platforms [ , ]. This variability is not unique to the context of family-based mental health platforms, with reviews of engagement in digital mental health reporting similar heterogeneity [ , , ]. Studies tend to report on measures such as completion or attrition rates, usability, user satisfaction, acceptability, and feasibility as indicators of how well the application engaged users. Often, these data are self-reported. Given the high attrition rates for self-guided platforms [ ] and additional complexities involved in requiring family members to cocomplete activities [ ], understanding platform characteristics that enable co-use and promote engagement is vital to informing the future development of such platforms. There is limited direct evidence to support practitioners, developers, and designers in understanding why engagement levels remain low, and there remains a limited understanding of how to design a DMHI to optimize engagement for families.\n\nAssessment of user engagement indicators such as completion data alone is likely insufficient to measure how well a platform engaged its users. For example, reporting on duration of participation and sessions completed neglects factors impacting how families navigate the website, such as interface design and organization, and user characteristics. Analysis of platform use patterns and baseline characteristics in addition to these completion statistics would provide greater insights into how families engage with a platform. Formative as opposed to summative evaluations of usability are conducted to inform the redesign and improvement of a web interface. Formative evaluations consider multiple factors and involve building a deep understanding of user perceptions and use patterns of platforms. In addition to self-reported measures and completion rates, formative evaluations often also consider website analytics such as bounce rate, pages per session, top exit pages, and the pathways that users take to get to pages where they ultimately spend most of their time. It is a recommendation of this review that formative evaluations of web-based mental health platforms become common practice for DMHIs, particularly for novel and complex applications such as family-based platforms.\n\nFinally, a systematic review of evaluations of usability of mobile mental health technologies [ ] recommended closer collaboration between health care and computer science experts when evaluating DMHIs, suggesting that this would increase the quality of interpretation of the evaluation. A summary of learnings from the ParentWorks trial identified an expected benefit of having involved a web agency during the early stages of content translation to optimize user experience [ ]. An interdisciplinary approach might enhance knowledge sharing, too, through detailed reporting of DMHI design decisions and their interactions with platform elements and clinical outcomes.\n\nClearly, there remains a need for coherent reporting and evaluation practices in the field to inform guidelines and policy on effective strategies for engaging families on the web in mental health–related interventions. Until rigorous co-design with families and an interdisciplinary approach between content experts and user experience designers is taken to formative evaluations, the growth and expansion of efficacious mental health platforms for family use will lag.\n\nStudy Strengths, Limitations, and Future Research Directions\n\nThis study represents the first of its kind. Using a replicable search strategy over 4 periods, we synthesized in this study the state of the published evidence regarding platform design and build characteristics enabling successful engagement of related parties with digitally delivered mental health interventions. Given that gray literature was not searched for this review, it is possible that emerging evidence for new multiuser digital platforms was missed. Our findings are limited by the technical reporting of the studies. Principally, many studies did not provide details about their platform build or the way in which participants engaged with the platform, including whether coparticipation was expected. Where this information was not provided, the study authors were contacted, and websites were searched to retrieve the relevant information. It is likely that examination of some relevant functionality was precluded when this information was not provided or was insufficient.\n\nMany studies (24/85, 28%) explicitly excluded participants when those other than the identified person had a mental illness. Whether through caregiving burden, stigma, or familial shared conditions, it is rare for a family presenting for therapy to have only 1 member experiencing mental health stress or significant challenges [ , ]. Given the potential of these platforms to aid family therapy, further research with families in which multiple members experience stress or mental health challenges is needed. Until then, it is difficult to generalize the evidence reported in this review to the real-world experience of families who may present for family therapy.\n\nIn addition, diversity in populations was limited, with most studies including White, heterosexual, and middle-class participants. There was a lack of evidence from low- and middle-income countries (LMICs), with all studies conducted in more high-income countries. The technological experiences and needs of families in LMICs will likely vary significantly from those in more high-income countries given, among other factors, the varying degree of ease of access to technology. Digital interventions have the potential to expand reach and access to services; however, until participants from LMICs are included in studies of digital platforms for families, findings cannot be generalized to these populations and ultimate reach will be limited.\n\nAs this is a new and novel field, language and terminology are still being defined, and means of measuring and defining engagement and feasibility are not well established [ ]. Of the included studies, 52% (44/85) were published in the last 5 years, reflecting rapid developments in technology and associated applications.\n\nConclusions\n\nWhile there is emerging evidence suggesting that DMHIs are clinically effective, there remains a large evidence gap in the literature on the extent to which platform-specific design and build elements may also contribute to timely access, user experience, safe cocompletion by family members, and clinical outcomes. In the service of improved mental and relational health outcomes, our findings point to a significant opportunity for meaningful cross-disciplinary research, development, and evaluation of family-based mental health platforms. Findings from the next era of research will be central to enabling policy and practice advancements in equitable access to effective mental health care support for families."
    }
}