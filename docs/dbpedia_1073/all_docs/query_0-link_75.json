{
    "id": "dbpedia_1073_0",
    "rank": 75,
    "data": {
        "url": "https://worldwidescience.org/topicpages/c/compositions%2Bmusic%2Bvisualization.html",
        "read_more_link": "",
        "language": "en",
        "title": "compositions music visualization: Topics by WorldWideScience.org",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/WWSlogo_wTag650px-min.png",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/OSTIlogo.svg",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/ICSTIlogo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Visual Representation in GENESIS as a tool for Physical Modeling, Sound Synthesis and Musical Composition\n\nOpenAIRE\n\nVilleneuve, JÃ©rÃ´me; Cadoz, Claude; CastagnÃ©, Nicolas\n\n2015-01-01\n\nThe motivation of this paper is to highlight the importance of visual representations for artists when modeling and simulating mass-interaction physical networks in the context of sound synthesis and musical composition. GENESIS is a musician-oriented software environment for sound synthesis and musical composition. However, despite this orientation, a substantial amount of effort has been put into building a rich variety of tools based on static or dynamic visual representations of models an...\n\nVisualizing the semantic structure in classical music works.\n\nScience.gov (United States)\n\nChan, Wing-Yi; Qu, Huamin; Mak, Wai-Ho\n\n2010-01-01\n\nA major obstacle in the appreciation of classical music is that extensive training is required to understand musical structure and compositional techniques toward comprehending the thoughts behind the musical work. In this paper, we propose an innovative visualization solution to reveal the semantic structure in classical orchestral works such that users can gain insights into musical structure and appreciate the beauty of music. We formulate the semantic structure into macrolevel layer interactions, microlevel theme variations, and macro-micro relationships between themes and layers to abstract the complicated construction of a musical composition. The visualization has been applied with success in understanding some classical music works as supported by highly promising user study results with the general audience and very positive feedback from music students and experts, demonstrating its effectiveness in conveying the sophistication and beauty of classical music to novice users with informative and intuitive displays.\n\nManifold compositions, music visualization, and scientific sonification in an immersive virtual-reality environment.\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nKaper, H. G.\n\n1998-01-05\n\nAn interdisciplinary project encompassing sound synthesis, music composition, sonification, and visualization of music is facilitated by the high-performance computing capabilities and the virtual-reality environments available at Argonne National Laboratory. The paper describes the main features of the project's centerpiece, DIASS (Digital Instrument for Additive Sound Synthesis); ''A.N.L.-folds'', an equivalence class of compositions produced with DIASS; and application of DIASS in two experiments in the sonification of complex scientific data. Some of the larger issues connected with this project, such as the changing ways in which both scientists and composers perform their tasks, are briefly discussed.\n\nVisualizing Music: The Archaeology of Music-Video.\n\nScience.gov (United States)\n\nBerg, Charles M.\n\nMusic videos, with their characteristic visual energy and frenetic music-and-dance numbers, have caught on rapidly since their introduction in 1981, bringing prosperity to a slumping record industry. Creating images to accompany existing music is, however, hardly a new idea. The concept can be traced back to 1877 and Thomas Edison's invention ofâ¦\n\nMusic and words in the visual cortex: The impact of musical expertise.\n\nScience.gov (United States)\n\nMongelli, Valeria; Dehaene, Stanislas; Vinckier, Fabien; Peretz, Isabelle; Bartolomeo, Paolo; Cohen, Laurent\n\n2017-01-01\n\nHow does the human visual system accommodate expertise for two simultaneously acquired symbolic systems? We used fMRI to compare activations induced in the visual cortex by musical notation, written words and other classes of objects, in professional musicians and in musically naÃ¯ve controls. First, irrespective of expertise, selective activations for music were posterior and lateral to activations for words in the left occipitotemporal cortex. This indicates that symbols characterized by different visual features engage distinct cortical areas. Second, musical expertise increased the volume of activations for music and led to an anterolateral displacement of word-related activations. In musicians, there was also a dramatic increase of the brain-scale networks connected to the music-selective visual areas. Those findings reveal that acquiring a double visual expertise involves an expansion of category-selective areas, the development of novel long-distance functional connectivity, and possibly some competition between categories for the colonization of cortical space. Copyright Â© 2016 Elsevier Ltd. All rights reserved.\n\nEyeMusic: Making Music with the Eyes\n\nOpenAIRE\n\nHornof, Anthony J.; Sato, Linda\n\n2004-01-01\n\nThough musical performers routinely use eye movements to communicate with each other during musical performances, very few performers or composers have used eye tracking devices to direct musical compositions and performances. EyeMusic is a system that uses eye movements as an input to electronic music compositions. The eye movements can directly control the music, or the music can respond to the eyes moving around a visual scene. EyeMusic is implemented so that any composer using established...\n\nMusician Map: visualizing music collaborations over time\n\nScience.gov (United States)\n\nYim, Ji-Dong; Shaw, Chris D.; Bartram, Lyn\n\n2009-01-01\n\nIn this paper we introduce Musician Map, a web-based interactive tool for visualizing relationships among popular musicians who have released recordings since 1950. Musician Map accepts search terms from the user, and in turn uses these terms to retrieve data from MusicBrainz.org and AudioScrobbler.net, and visualizes the results. Musician Map visualizes relationships of various kinds between music groups and individual musicians, such as band membership, musical collaborations, and linkage to other artists that are generally regarded as being similar in musical style. These relationships are plotted between artists using a new timeline-based visualization where a node in a traditional node-link diagram has been transformed into a Timeline-Node, which allows the visualization of an evolving entity over time, such as the membership in a band. This allows the user to pursue social trend queries such as \"Do Hip-Hop artists collaborate differently than Rock artists\".\n\nMusic and Visual Research\n\nDEFF Research Database (Denmark)\n\nJensen, Julie Borup\n\n2017-01-01\n\n, ethnographic video observation was chosen as a way of handling complex data and analysing complex interaction. Preliminary analyses of the findings indicates the ability of music to both contain and express experiential, sensory, emotional and cognitive complexity in ways that allow for differences......The paper explores the potential of video ethnography concerning educational research on music as contributing to an inclusive learning environment in elementary school (research objective). In music education research, the use of visual data provided by video seems to be a relevant choice...... of method, because music as a school subject encompasses multiple ways for the pupils to participate and interact in the learning environment, and music itself provides a whole set of complex linguistic rules that will escape traditional observation and interview methods in ethnographic research. Therefore...\n\nVisual analysis of music in function of music video\n\nDirectory of Open Access Journals (Sweden)\n\nAntal Silard\n\n2015-01-01\n\nFull Text Available Wide-spread all over the planet, incorporating all music genres, the music video, the subject matter of this analysis, has become irreplaceable in promotions, song presentations, an artist's image, visual aesthetics of subculture; today, most of the countries in the world have a channel devoted to music only, i.e. to music video. The form started to develop rapidly in the 50s of the twentieth century, alongside television. As it developed, its purpose has changed: from a simple presentation of musicians to an independent video form.\n\nContent and user-based music visual analysis\n\nScience.gov (United States)\n\nGuo, Xiaochun; Tang, Lei\n\n2015-12-01\n\nIn recent years, people's ability to collect music got enhanced greatly. Many people who prefer listening music offline even stored thousands of music on their local storage or portable device. However, their ability to deal with music information has not been improved accordingly, which results in two problems. One is how to find out the favourite songs from large music dataset and satisfy different individuals. The other one is how to compose a play list quickly. To solve these problems, the authors proposed a content and user-based music visual analysis approach. We first developed a new recommendation algorithm based on the content of music and user's behaviour, which satisfy individual's preference. Then, we make use of visualization and interaction tools to illustrate the relationship between songs and help people compose a suitable play list. At the end of this paper, a survey is mentioned to show that our system is available and effective.\n\nMental imagery boosts music compositional creativity\n\nScience.gov (United States)\n\nLim, Stephen Wee Hun\n\n2017-01-01\n\nWe empirically investigated the effect of mental imagery on young childrenâs music compositional creativity. Children aged 5 to 8 years participated in two music composition sessions. In the control session, participants based their composition on a motif that they had created using a sequence of letter names. In the mental imagery session, participants were given a picture of an animal and instructed to imagine the animalâs sounds and movements, before incorporating what they had imagined into their composition. Six expert judges independently rated all music compositions on creativity based on subjective criteria (consensual assessment). Reliability analyses indicated that the expert judges demonstrated a high level of agreement in their ratings. The mental imagery compositions received significantly higher creativity ratings by the expert judges than did the control compositions. These results provide evidence for the effectiveness of mental imagery in enhancing young childrenâs music compositional creativity. PMID:28296965\n\nMental imagery boosts music compositional creativity.\n\nScience.gov (United States)\n\nWong, Sarah Shi Hui; Lim, Stephen Wee Hun\n\n2017-01-01\n\nWe empirically investigated the effect of mental imagery on young children's music compositional creativity. Children aged 5 to 8 years participated in two music composition sessions. In the control session, participants based their composition on a motif that they had created using a sequence of letter names. In the mental imagery session, participants were given a picture of an animal and instructed to imagine the animal's sounds and movements, before incorporating what they had imagined into their composition. Six expert judges independently rated all music compositions on creativity based on subjective criteria (consensual assessment). Reliability analyses indicated that the expert judges demonstrated a high level of agreement in their ratings. The mental imagery compositions received significantly higher creativity ratings by the expert judges than did the control compositions. These results provide evidence for the effectiveness of mental imagery in enhancing young children's music compositional creativity.\n\nComplex network structure of musical compositions: Algorithmic generation of appealing music\n\nScience.gov (United States)\n\nLiu, Xiao Fan; Tse, Chi K.; Small, Michael\n\n2010-01-01\n\nIn this paper we construct networks for music and attempt to compose music artificially. Networks are constructed with nodes and edges corresponding to musical notes and their co-occurring connections. We analyze classical music from Bach, Mozart, Chopin, as well as other types of music such as Chinese pop music. We observe remarkably similar properties in all networks constructed from the selected compositions. We conjecture that preserving the universal network properties is a necessary step in artificial composition of music. Power-law exponents of node degree, node strength and/or edge weight distributions, mean degrees, clustering coefficients, mean geodesic distances, etc. are reported. With the network constructed, music can be composed artificially using a controlled random walk algorithm, which begins with a randomly chosen note and selects the subsequent notes according to a simple set of rules that compares the weights of the edges, weights of the nodes, and/or the degrees of nodes. By generating a large number of compositions, we find that this algorithm generates music which has the necessary qualities to be subjectively judged as appealing.\n\nComputer Music Synthesis and Composition\n\nScience.gov (United States)\n\nAyers, Lydia\n\nWhat is computer music composition? Composers are using the computer for everything from MIDI instruments communicating with computer sequencers, pitch trackers analyzing the sounds of acoustic instruments and converting them to pitch information, live performers with recorded music, performers with interactive computer programs, computer music produced by dancers using sensors, automatic music composition with the computer programs composing the music, composing with sounds or parts of sounds rather than notes, how to structure the use of time, composing with timbres, or the colors of sounds, and timbre morphing, such as a gong morphing to a voice, composing with textures and texture morphing, such as fluttertonguing morphing to pitch, granular synthesis, trills and convolution.\n\nAffective evolutionary music composition with MetaCompose\n\nDEFF Research Database (Denmark)\n\nScirea, Marco; Togelius, Julian; Eklund, Peter\n\n2017-01-01\n\nThis paper describes the MetaCompose music generator, a compositional, extensible framework for affective music composition. In this context âaffectiveâ refers to the music generatorâs ability to express emotional information. The main purpose of MetaCompose is to create music in real-time that can...\n\nA Reggio-Inspired Music Atelier: Opening the Door between Visual Arts and Music\n\nScience.gov (United States)\n\nHanna, Wendell\n\n2014-01-01\n\nThe Reggio Emilia approach is based on the idea that every child has at least, \"one hundred languages\" available for expressing perspectives of the world, and one of those languages is music. While all of the arts (visual, music, dance, drama) are considered equally important in Reggio schools, the visual arts have been particularlyâ¦\n\nArchitecture in motion: A model for music composition\n\nScience.gov (United States)\n\nVariego, Jorge Elias\n\n2011-12-01\n\nSpeculations regarding the relationship between music and architecture go back to the very origins of these disciplines. Throughout history, these links have always reaffirmed that music and architecture are analogous art forms that only diverge in their object of study. In the 1 st c. BCE Vitruvius conceived Architecture as \"one of the most inclusive and universal human activities\" where the architect should be educated in all the arts, having a vast knowledge in history, music and philosophy. In the 18th c., the German thinker Johann Wolfgang von Goethe, described Architecture as \"frozen music\". More recently, in the 20th c., Iannis Xenakis studied the similar structuring principles between Music and Architecture creating his own \"models\" of musical composition based on mathematical principles and geometric constructions. The goal of this document is to propose a compositional method that will function as a translator between the acoustical properties of a room and music, to facilitate the creation of musical works that will not only happen within an enclosed space but will also intentionally interact with the space. Acoustical measurements of rooms such as reverberation time, frequency response and volume will be measured and systematically organized in correspondence with orchestrational parameters. The musical compositions created after the proposed model are evocative of the spaces on which they are based. They are meant to be performed in any space, not exclusively in the one where the acoustical measurements were obtained. The visual component of architectural design is disregarded; the room is considered a musical instrument, with its particular sound qualities and resonances. Compositions using the proposed model will not result as sonified shapes, they will be musical works literally \"tuned\" to a specific space. This Architecture in motion is an attempt to adopt scientific research to the service of a creative activity and to let the aural properties of\n\nMusic Therapy for the Visually Impaired.\n\nScience.gov (United States)\n\nSteele, Anita Louise; Crawford, Celeste\n\n1982-01-01\n\nThe development and implementation of a music therapy program to achieve behavioral change in visually impaired children and adolescents are described. Goals targeted by the music therapist at the Cleveland Society for the Blind include altering unusual body movements, poor posture, and other mannerisms often associated with blindness. (SEW)\n\nInteractive music composition driven by feature evolution.\n\nScience.gov (United States)\n\nKaliakatsos-Papakostas, Maximos A; Floros, Andreas; Vrahatis, Michael N\n\n2016-01-01\n\nEvolutionary music composition is a prominent technique for automatic music generation. The immense adaptation potential of evolutionary algorithms has allowed the realisation of systems that automatically produce music through feature and interactive-based composition approaches. Feature-based composition employs qualitatively descriptive music features as fitness landmarks. Interactive composition systems on the other hand, derive fitness directly from human ratings and/or selection. The paper at hand introduces a methodological framework that combines the merits of both evolutionary composition methodologies. To this end, a system is presented that is organised in two levels: the higher level of interaction and the lower level of composition. The higher level incorporates the particle swarm optimisation algorithm, along with a proposed variant and evolves musical features according to user ratings. The lower level realizes feature-based music composition with a genetic algorithm, according to the top level features. The aim of this work is not to validate the efficiency of the currently utilised setup in each level, but to examine the convergence behaviour of such a two-level technique in an objective manner. Therefore, an additional novelty in this work concerns the utilisation of artificial raters that guide the system through the space of musical features, allowing the exploration of its convergence characteristics: does the system converge to optimal melodies, is this convergence fast enough for potential human listeners and is the trajectory to convergence \"interesting' and \"creative\" enough? The experimental results reveal that the proposed methodological framework represents a fruitful and robust, novel approach to interactive music composition.\n\nMusic alters visual perception.\n\nDirectory of Open Access Journals (Sweden)\n\nJacob Jolij\n\nFull Text Available BACKGROUND: Visual perception is not a passive process: in order to efficiently process visual input, the brain actively uses previous knowledge (e.g., memory and expectations about what the world should look like. However, perception is not only influenced by previous knowledge. Especially the perception of emotional stimuli is influenced by the emotional state of the observer. In other words, how we perceive the world does not only depend on what we know of the world, but also by how we feel. In this study, we further investigated the relation between mood and perception. METHODS AND FINDINGS: We let observers do a difficult stimulus detection task, in which they had to detect schematic happy and sad faces embedded in noise. Mood was manipulated by means of music. We found that observers were more accurate in detecting faces congruent with their mood, corroborating earlier research. However, in trials in which no actual face was presented, observers made a significant number of false alarms. The content of these false alarms, or illusory percepts, was strongly influenced by the observers' mood. CONCLUSIONS: As illusory percepts are believed to reflect the content of internal representations that are employed by the brain during top-down processing of visual input, we conclude that top-down modulation of visual processing is not purely predictive in nature: mood, in this case manipulated by music, may also directly alter the way we perceive the world.\n\nPleasant music improves visual attention in patients with unilateral neglect after stroke.\n\nScience.gov (United States)\n\nChen, Mei-Ching; Tsai, Pei-Luen; Huang, Yu-Ting; Lin, Keh-Chung\n\n2013-01-01\n\nTo investigate whether listening to pleasant music improves visual attention to and awareness of contralesional stimuli in patients with unilateral neglect after stroke. A within-subject design was used with 19 participants with unilateral neglect following a right hemisphere stroke. Participants were tested in three conditions (pleasant music, unpleasant music and white noise) within 1 week. All musical pieces were chosen by the participants. In each condition, participants were asked to complete three sub-tests of the Behavioural Inattention Test (the Star Cancellation Test, the Line Bisection Test and the Picture Scanning test) and a visual exploration task with everyday scenes. Eye movements in the visual exploration task were recorded simultaneously. Mood and arousal induced by different auditory stimuli were assessed using visual analogue scales, heart rate and galvanic skin response. Compared with unpleasant music and white noise, participants rated their moods as more positive and arousal as higher with pleasant music, but also showed significant improvement on all tasks and eye movement data, except the Line Bisection Test. The findings suggest that pleasant music can improve visual attention in patients with unilateral neglect after stroke. Additional research using randomized controlled trials is required to validate these findings.\n\nHow do musical tonality and experience affect visual working memory?\n\nScience.gov (United States)\n\nYang, Hua; Lu, Jing; Gong, Diankun; Yao, Dezhong\n\n2016-01-20\n\nThe influence of music on the human brain has continued to attract increasing attention from neuroscientists and musicologists. Currently, tonal music is widely present in people's daily lives; however, atonal music has gradually become an important part of modern music. In this study, we conducted two experiments: the first one tested for differences in perception of distractibility between tonal music and atonal music. The second experiment tested how tonal music and atonal music affect visual working memory by comparing musicians and nonmusicians who were placed in contexts with background tonal music, atonal music, and silence. They were instructed to complete a delay matching memory task. The results show that musicians and nonmusicians have different evaluations of the distractibility of tonal music and atonal music, possibly indicating that long-term training may lead to a higher auditory perception threshold among musicians. For the working memory task, musicians reacted faster than nonmusicians in all background music cases, and musicians took more time to respond in the tonal background music condition than in the other conditions. Therefore, our results suggest that for a visual memory task, background tonal music may occupy more cognitive resources than atonal music or silence for musicians, leaving few resources left for the memory task. Moreover, the musicians outperformed the nonmusicians because of the higher sensitivity to background music, which also needs a further longitudinal study to be confirmed.\n\nMusic in film and animation: experimental semiotics applied to visual, sound and musical structures\n\nScience.gov (United States)\n\nKendall, Roger A.\n\n2010-02-01\n\nThe relationship of music to film has only recently received the attention of experimental psychologists and quantificational musicologists. This paper outlines theory, semiotical analysis, and experimental results using relations among variables of temporally organized visuals and music. 1. A comparison and contrast is developed among the ideas in semiotics and experimental research, including historical and recent developments. 2. Musicological Exploration: The resulting multidimensional structures of associative meanings, iconic meanings, and embodied meanings are applied to the analysis and interpretation of a range of film with music. 3. Experimental Verification: A series of experiments testing the perceptual fit of musical and visual patterns layered together in animations determined goodness of fit between all pattern combinations, results of which confirmed aspects of the theory. However, exceptions were found when the complexity of the stratified stimuli resulted in cognitive overload.\n\nAudio-Visual Integration Modifies Emotional Judgment in Music\n\nDirectory of Open Access Journals (Sweden)\n\nShen-Yuan Su\n\n2011-10-01\n\nFull Text Available The conventional view that perceived emotion in music is derived mainly from auditory signals has led to neglect of the contribution of visual image. In this study, we manipulated mode (major vs. minor and examined the influence of a video image on emotional judgment in music. Melodies in either major or minor mode were controlled for tempo and rhythm and played to the participants. We found that Taiwanese participants, like Westerners, judged major melodies as expressing positive, and minor melodies negative, emotions. The major or minor melodies were then paired with video images of the singers, which were either emotionally congruent or incongruent with their modes. Results showed that participants perceived stronger positive or negative emotions with congruent audio-visual stimuli. Compared to listening to music alone, stronger emotions were perceived when an emotionally congruent video image was added and weaker emotions were perceived when an incongruent image was added. We therefore demonstrate that mode is important to perceive the emotional valence in music and that treating musical art as a purely auditory event might lose the enhanced emotional strength perceived in music, since going to a concert may lead to stronger perceived emotion than listening to the CD at home.\n\nThe role of ocean phenomenon in music compositions\n\nScience.gov (United States)\n\nLiu, Chi-Min\n\n2016-04-01\n\nThis is a preliminarily interdisciplinary study for exploring the elements of ocean phenomenon appearing in some compositions of classical music. The so-called ocean phenomenon contain wave conditions, climate change, coastal landform, and other natural events around or over the sea. In some music compositions, it is apparent that natural phenomenon over the sea influence the composers' moods and the music pieces they composed. In this poster, some music compositions in the 19th and the early 20th centuries will be introduced to demonstrate the relation between ocean and music works. These works include Meeresstille by Schubert, Ãtude Op.25 No.12 by Chopin, Fingal's Cave Overture by Mendelssohn, Der Fliegende HollÃ¤nder by Wagner and La Mer by Debussy. In addition, present idea may give a novel way for music teachers to elucidate the knowledge of ocean science in classes.\n\nMusical, visual and cognitive deficits after middle cerebral artery infarction\n\nDirectory of Open Access Journals (Sweden)\n\nStephanie Rosemann\n\n2017-03-01\n\nFull Text Available The perception of music can be impaired after a stroke. This dysfunction is called amusia and amusia patients often also show deficits in visual abilities, language, memory, learning, and attention. The current study investigated whether deficits in music perception are selective for musical input or generalize to other perceptual abilities. Additionally, we tested the hypothesis that deficits in working memory or attention account for impairments in music perception. Twenty stroke patients with small infarctions in the supply area of the middle cerebral artery were investigated with tests for music and visual perception, categorization, neglect, working memory and attention. Two amusia patients with selective deficits in music perception and pronounced lesions were identified. Working memory and attention deficits were highly correlated across the patient group but no correlation with musical abilities was obtained. Lesion analysis revealed that lesions in small areas of the putamen and globus pallidus were connected to a rhythm perception deficit. We conclude that neither a general perceptual deficit nor a minor domain general deficit can account for impairments in the music perception task. But we find support for the modular organization of the music perception network with brain areas specialized for musical functions as musical deficits were not correlated to any other impairment.\n\nMusical, visual and cognitive deficits after middle cerebral artery infarction.\n\nScience.gov (United States)\n\nRosemann, Stephanie; Brunner, Freimuth; Kastrup, Andreas; Fahle, Manfred\n\n2017-03-01\n\nThe perception of music can be impaired after a stroke. This dysfunction is called amusia and amusia patients often also show deficits in visual abilities, language, memory, learning, and attention. The current study investigated whether deficits in music perception are selective for musical input or generalize to other perceptual abilities. Additionally, we tested the hypothesis that deficits in working memory or attention account for impairments in music perception. Twenty stroke patients with small infarctions in the supply area of the middle cerebral artery were investigated with tests for music and visual perception, categorization, neglect, working memory and attention. Two amusia patients with selective deficits in music perception and pronounced lesions were identified. Working memory and attention deficits were highly correlated across the patient group but no correlation with musical abilities was obtained. Lesion analysis revealed that lesions in small areas of the putamen and globus pallidus were connected to a rhythm perception deficit. We conclude that neither a general perceptual deficit nor a minor domain general deficit can account for impairments in the music perception task. But we find support for the modular organization of the music perception network with brain areas specialized for musical functions as musical deficits were not correlated to any other impairment.\n\nMelodic sound enhances visual awareness of congruent musical notes, but only if you can read music.\n\nScience.gov (United States)\n\nLee, Minyoung; Blake, Randolph; Kim, Sujin; Kim, Chai-Youn\n\n2015-07-07\n\nPredictive influences of auditory information on resolution of visual competition were investigated using music, whose visual symbolic notation is familiar only to those with musical training. Results from two experiments using different experimental paradigms revealed that melodic congruence between what is seen and what is heard impacts perceptual dynamics during binocular rivalry. This bisensory interaction was observed only when the musical score was perceptually dominant, not when it was suppressed from awareness, and it was observed only in people who could read music. Results from two ancillary experiments showed that this effect of congruence cannot be explained by differential patterns of eye movements or by differential response sluggishness associated with congruent score/melody combinations. Taken together, these results demonstrate robust audiovisual interaction based on high-level, symbolic representations and its predictive influence on perceptual dynamics during binocular rivalry.\n\nThe effects of music composition as a classroom activity on engagement in music education and academic and music achievement: A quasi-experimental study\n\nNARCIS (Netherlands)\n\nHogenes, M.; van Oers, B.; Diekstra, R.; Sklad, M.\n\n2015-01-01\n\nThe present study aims to contribute to the understanding of the effects of music education, in particular music composition as a classroom activity for fifth- and sixth-graders. The intervention (experimental condition) focused on a three-step-model for music composition, based on the Cultural\n\nStudentsâ Musical Creativity and the Role of Teachers - a Study of Compositions Written for the Music Olympiad\n\nDirectory of Open Access Journals (Sweden)\n\nBranka Rotar Pance\n\n2017-06-01\n\nFull Text Available Creativity is the focus of research in various areas. The present paper focuses on creativity in music and the role of the teacher in stimulating and developing it in an individualâs musical development. It highlights the importance of evaluating musical ideas, the creative process and final products. The Music Olympiad involves a presentation of competitorâs own compositions. In the research, we analysed the characteristics of the compositions written for and performed at the first three Slovene Music Olympiads.\n\nTALENT DEVELOPMENT IN THE WORLD OF CLASSICAL MUSIC AND VISUAL ARTS\n\nDirectory of Open Access Journals (Sweden)\n\nLinda Jarvin\n\n2017-12-01\n\nFull Text Available In this article, we propose to explore the developmental trajectories of children displaying gifts and abilities in the domains of (classical music and in visual arts. A developmental model for talent development that was developed in the domain of classical music will be briefly presented and its applicability in the field of visual arts will be discussed.\n\nA framework to evaluate the functionality of mobile applications for music composition\n\nDirectory of Open Access Journals (Sweden)\n\nSonja Visagie\n\n2014-07-01\n\nFull Text Available The functionality of a diverse range of mobile applications for music composition is discussed in this paper. The focus is on generic functionality requirements, the needs of novice and expert users to compose music and some of the mobile applications for music composition available from the iTunes App Store. The paper further addresses the gap that exists in current literature about the functionalities required of mobile applications for music composition. In order to assist composers of music (from novices to experts to identify and choose the most appropriate application for composing music on a mobile device, a framework is developed against which the functionality of ten mobile applications for music composition is evaluated.\n\nThe music of your emotions: neural substrates involved in detection of emotional correspondence between auditory and visual music actions.\n\nDirectory of Open Access Journals (Sweden)\n\nKarin Petrini\n\nFull Text Available In humans, emotions from music serve important communicative roles. Despite a growing interest in the neural basis of music perception, action and emotion, the majority of previous studies in this area have focused on the auditory aspects of music performances. Here we investigate how the brain processes the emotions elicited by audiovisual music performances. We used event-related functional magnetic resonance imaging, and in Experiment 1 we defined the areas responding to audiovisual (musician's movements with music, visual (musician's movements only, and auditory emotional (music only displays. Subsequently a region of interest analysis was performed to examine if any of the areas detected in Experiment 1 showed greater activation for emotionally mismatching performances (combining the musician's movements with mismatching emotional sound than for emotionally matching music performances (combining the musician's movements with matching emotional sound as presented in Experiment 2 to the same participants. The insula and the left thalamus were found to respond consistently to visual, auditory and audiovisual emotional information and to have increased activation for emotionally mismatching displays in comparison with emotionally matching displays. In contrast, the right thalamus was found to respond to audiovisual emotional displays and to have similar activation for emotionally matching and mismatching displays. These results suggest that the insula and left thalamus have an active role in detecting emotional correspondence between auditory and visual information during music performances, whereas the right thalamus has a different role.\n\nNarrating the origin of the universe through music: A case study\n\nDirectory of Open Access Journals (Sweden)\n\nMannone Maria\n\n2017-01-01\n\nFull Text Available Our project is about the synthesis of a musical piece, based on the timeline of the Universe. We can understand music through visual and gestural analogies. In a similar way, popular descriptions of scientific concepts also use external metaphors and visual support to help comprehension. We will use music to describe a topic from astrophysics, the birth and evolution of the Universe. We describe the compositional technique used to create the composition 'Origin,' referring to recent techniques to derive music from tridimensional images and from gestures, under the light of the mathematical theory of music in the context of a narrative.\n\nNocturne aquatique (musical composition)\n\nOpenAIRE\n\nAtkinson, Simon\n\n2015-01-01\n\n19 minutes duration; original performance version two stereo stems. Performance materials available from the composer. A musical composition, commissioned by Radio France/INA-GRM, world premiere given at Auditorium Saint-Germain, Paris, 24th January 2015 as part of the Akousma Festival programme.\n\nThe Effects of Music Composition as a Classroom Activity on Engagement in Music Education and Academic and Music Achievement: A Quasi-Experimental Study\n\nScience.gov (United States)\n\nHogenes, Michel; van Oers, Bert; Diekstra, RenÃ© F. W.; Sklad, Marcin\n\n2016-01-01\n\nThe present study aims to contribute to the understanding of the effects of music education, in particular music composition as a classroom activity for fifth- and sixth-graders. The intervention (experimental condition) focused on a three-step-model for music composition, based on the Cultural Historical Activity Theory of education, and has beenâ¦\n\nLong-term musical training may improve different forms of visual attention ability.\n\nScience.gov (United States)\n\nRodrigues, Ana Carolina; Loureiro, MaurÃ­cio Alves; Caramelli, Paulo\n\n2013-08-01\n\nMany studies have suggested that structural and functional cerebral neuroplastic processes result from long-term musical training, which in turn may produce cognitive differences between musicians and non-musicians. We aimed to investigate whether intensive, long-term musical practice is associated with improvements in three different forms of visual attention ability: selective, divided and sustained attention. Musicians from symphony orchestras (n=38) and non-musicians (n=38), who were comparable in age, gender and education, were submitted to three neuropsychological tests, measuring reaction time and accuracy. Musicians showed better performance relative to non-musicians on four variables of the three visual attention tests, and such an advantage could not solely be explained by better sensorimotor integration. Moreover, in the group of musicians, significant correlations were observed between the age at the commencement of musical studies and reaction time in all visual attention tests. The results suggest that musicians present augmented ability in different forms of visual attention, thus illustrating the possible cognitive benefits of long-term musical training. Copyright Â© 2013 Elsevier Inc. All rights reserved.\n\nConstituents of Music and Visual-Art Related Pleasure - A Critical Integrative Literature Review.\n\nScience.gov (United States)\n\nTiihonen, Marianne; Brattico, Elvira; Maksimainen, Johanna; Wikgren, Jan; Saarikallio, Suvi\n\n2017-01-01\n\nThe present literature review investigated how pleasure induced by music and visual-art has been conceptually understood in empirical research over the past 20 years. After an initial selection of abstracts from seven databases (keywords: pleasure, reward, enjoyment, and hedonic), twenty music and eleven visual-art papers were systematically compared. The following questions were addressed: (1) What is the role of the keyword in the research question? (2) Is pleasure considered a result of variation in the perceiver's internal or external attributes? (3) What are the most commonly employed methods and main variables in empirical settings? Based on these questions, our critical integrative analysis aimed to identify which themes and processes emerged as key features for conceptualizing art-induced pleasure. The results demonstrated great variance in how pleasure has been approached: In the music studies pleasure was often a clear object of investigation, whereas in the visual-art studies the term was often embedded into the context of an aesthetic experience, or used otherwise in a descriptive, indirect sense. Music studies often targeted different emotions, their intensity or anhedonia. Biographical and background variables and personality traits of the perceiver were often measured. Next to behavioral methods, a common method was brain imaging which often targeted the reward circuitry of the brain in response to music. Visual-art pleasure was also frequently addressed using brain imaging methods, but the research focused on sensory cortices rather than the reward circuit alone. Compared with music research, visual-art research investigated more frequently pleasure in relation to conscious, cognitive processing, where the variations of stimulus features and the changing of viewing modes were regarded as explanatory factors of the derived experience. Despite valence being frequently applied in both domains, we conclude, that in empirical music research pleasure\n\nComparing the effect of visual and non-visual music on functional factors in a progressive aerobic exercise program\n\nDirectory of Open Access Journals (Sweden)\n\nFaezeh Alizadeh\n\n2017-10-01\n\nFull Text Available Â Objective: Aerobic exercises have a significant effect on losing weight and increasing the energy levels. This research aimed to increase the fatigue time in this type of exercises, making it more enjoyable. Â Method: In this study, eight physical education female students with the same preparedness level were selected by random sampling. The subjects participated ina periodic aerobic exercise during three stages with an interval of 48 hours. The test was based on the Bruce Protocol, which measured the burnout, the maximum oxygen consumption, the perceived exercise pressure, and the heart rate in each stage. Â Findings: the results revealed that there was a significant difference in the subjectsâ burnout time (p = 0.039 while the impact of the visual music compared to the non-visual music in perceiving the exercise pressure was significantly different (p = 0.034. Nonetheless, while measuring the heart rate (p = 0.443, the maximum oxygen consumption (p <0.05 had no significant effect. Â Conclusion: In was found in the current research that the visual music can be a stronger factor than the non-visual music in making the exercise more enjoyable and increasing the fatigue time.\n\n\"LITTLE TRAGEDIES\": THE POLYPHONY OF MUSIC, WORDS AND VISUAL IMAGERY\n\nDirectory of Open Access Journals (Sweden)\n\nNikolaeva Julia E.\n\n2015-01-01\n\nFull Text Available The music for three-part television movie Little Tragedies (1979 on Pushkinâs literature works (directed by M.Schweitzer, music composed by A.Schnittke has been investigated. The trinity of music, poetic words and visual imagery, and their amazing consistency and reciprocal functioning has been considered in aspect of polyphony as the universal logical principle of building an art form. All the music of the TV movie grows out of two leitmotifs. And theirs varied implementation in the film is exemplified on examples of polyphonic analysis (music/words/images of fragments from the four main film sections, such as \"Scene from Faust\", \"Mozart and Salieri\", \"The Covetous Knight\", and \"A Feast in Time of Plague\".\n\nPleasant music as a countermeasure against visually induced motion sickness.\n\nScience.gov (United States)\n\nKeshavarz, Behrang; Hecht, Heiko\n\n2014-05-01\n\nVisually induced motion sickness (VIMS) is a well-known side-effect in virtual environments or simulators. However, effective behavioral countermeasures against VIMS are still sparse. In this study, we tested whether music can reduce the severity of VIMS. Ninety-three volunteers were immersed in an approximately 14-minute-long video taken during a bicycle ride. Participants were randomly assigned to one of four experimental groups, either including relaxing music, neutral music, stressful music, or no music. Sickness scores were collected using the Fast Motion Sickness Scale and the Simulator Sickness Questionnaire. Results showed an overall trend for relaxing music to reduce the severity of VIMS. When factoring in the subjective pleasantness of the music, a significant reduction of VIMS occurred only when the presented music was perceived as pleasant, regardless of the music type. In addition, we found a gender effect with women reporting more sickness than men. We assume that the presentation of pleasant music can be an effective, low-cost, and easy-to-administer method to reduce VIMS. Copyright Â© 2013 Elsevier Ltd and The Ergonomics Society. All rights reserved.\n\nBach in 2014: Music Composition with Recurrent Neural Network\n\nOpenAIRE\n\nLiu, I-Ting; Ramakrishnan, Bhiksha\n\n2014-01-01\n\nWe propose a framework for computer music composition that uses resilient propagation (RProp) and long short term memory (LSTM) recurrent neural network. In this paper, we show that LSTM network learns the structure and characteristics of music pieces properly by demonstrating its ability to recreate music. We also show that predicting existing music using RProp outperforms Back propagation through time (BPTT).\n\nComparison of L-system applications towards plant modelling, music rendering and score generation using visual language programming\n\nScience.gov (United States)\n\nLim, Chen Kim; Tan, Kian Lam; Yusran, Hazwanni; Suppramaniam, Vicknesh\n\n2017-10-01\n\nVisual language or visual representation has been used in the past few years in order to express the knowledge in graphic. One of the important graphical elements is fractal and L-Systems is a mathematic-based grammatical model for modelling cell development and plant topology. From the plant model, L-Systems can be interpreted as music sound and score. In this paper, LSound which is a Visual Language Programming (VLP) framework has been developed to model plant to music sound and generate music score and vice versa. The objectives of this research has three folds: (i) To expand the grammar dictionary of L-Systems music based on visual programming, (ii) To design and produce a user-friendly and icon based visual language framework typically for L-Systems musical score generation which helps the basic learners in musical field and (iii) To generate music score from plant models and vice versa using L-Systems method. This research undergoes a four phases methodology where the plant is first modelled, then the music is interpreted, followed by the output of music sound through MIDI and finally score is generated. LSound is technically compared to other existing applications in the aspects of the capability of modelling the plant, rendering the music and generating the sound. It has been found that LSound is a flexible framework in which the plant can be easily altered through arrow-based programming and the music score can be altered through the music symbols and notes. This work encourages non-experts to understand L-Systems and music hand-in-hand.\n\nThe Integration of Visual Expression in Music Education for Children\n\nScience.gov (United States)\n\nRoels, Johanna Maria; Van Petegem, Peter\n\n2014-01-01\n\nThis study is the result of a two-year experimental collaboration with children from my piano class. Together, the children and I designed a method that uses visual expression as a starting point for composing and visualising music-theoretical concepts. In this method various dimensions of musicality such as listening, creating, noting down andâ¦\n\nConstituents of Music and Visual-Art Related Pleasure â A Critical Integrative Literature Review\n\nDirectory of Open Access Journals (Sweden)\n\nMarianne Tiihonen\n\n2017-07-01\n\nFull Text Available The present literature review investigated how pleasure induced by music and visual-art has been conceptually understood in empirical research over the past 20 years. After an initial selection of abstracts from seven databases (keywords: pleasure, reward, enjoyment, and hedonic, twenty music and eleven visual-art papers were systematically compared. The following questions were addressed: (1 What is the role of the keyword in the research question? (2 Is pleasure considered a result of variation in the perceiverâs internal or external attributes? (3 What are the most commonly employed methods and main variables in empirical settings? Based on these questions, our critical integrative analysis aimed to identify which themes and processes emerged as key features for conceptualizing art-induced pleasure. The results demonstrated great variance in how pleasure has been approached: In the music studies pleasure was often a clear object of investigation, whereas in the visual-art studies the term was often embedded into the context of an aesthetic experience, or used otherwise in a descriptive, indirect sense. Music studies often targeted different emotions, their intensity or anhedonia. Biographical and background variables and personality traits of the perceiver were often measured. Next to behavioral methods, a common method was brain imaging which often targeted the reward circuitry of the brain in response to music. Visual-art pleasure was also frequently addressed using brain imaging methods, but the research focused on sensory cortices rather than the reward circuit alone. Compared with music research, visual-art research investigated more frequently pleasure in relation to conscious, cognitive processing, where the variations of stimulus features and the changing of viewing modes were regarded as explanatory factors of the derived experience. Despite valence being frequently applied in both domains, we conclude, that in empirical music\n\nConstituents of Music and Visual-Art Related Pleasure â A Critical Integrative Literature Review\n\nScience.gov (United States)\n\nTiihonen, Marianne; Brattico, Elvira; Maksimainen, Johanna; Wikgren, Jan; Saarikallio, Suvi\n\n2017-01-01\n\nThe present literature review investigated how pleasure induced by music and visual-art has been conceptually understood in empirical research over the past 20 years. After an initial selection of abstracts from seven databases (keywords: pleasure, reward, enjoyment, and hedonic), twenty music and eleven visual-art papers were systematically compared. The following questions were addressed: (1) What is the role of the keyword in the research question? (2) Is pleasure considered a result of variation in the perceiverâs internal or external attributes? (3) What are the most commonly employed methods and main variables in empirical settings? Based on these questions, our critical integrative analysis aimed to identify which themes and processes emerged as key features for conceptualizing art-induced pleasure. The results demonstrated great variance in how pleasure has been approached: In the music studies pleasure was often a clear object of investigation, whereas in the visual-art studies the term was often embedded into the context of an aesthetic experience, or used otherwise in a descriptive, indirect sense. Music studies often targeted different emotions, their intensity or anhedonia. Biographical and background variables and personality traits of the perceiver were often measured. Next to behavioral methods, a common method was brain imaging which often targeted the reward circuitry of the brain in response to music. Visual-art pleasure was also frequently addressed using brain imaging methods, but the research focused on sensory cortices rather than the reward circuit alone. Compared with music research, visual-art research investigated more frequently pleasure in relation to conscious, cognitive processing, where the variations of stimulus features and the changing of viewing modes were regarded as explanatory factors of the derived experience. Despite valence being frequently applied in both domains, we conclude, that in empirical music research pleasure\n\nEffect of skill level on recall of visually presented patterns of musical notes.\n\nScience.gov (United States)\n\nKalakoski, Virpi\n\n2007-04-01\n\nExpertise effects in music were studied in a new task: the construction of mental representations from separate fragments. Groups of expert musicians and non-musicians were asked to recall note patterns presented visually note by note. Skill-level, musical well-formedness of the note patterns and presentation mode were varied. The musicians recalled note patterns better than the non-musicians, even though the presentation was visual and successive. Furthermore, only musicians' performance was affected by musical well-formedness of the note patterns when visual gestalt properties, verbal rehearsability, and familiarity of the stimuli were controlled. Musicians were also able to use letter names referring to notes as efficiently as visual notes, which indicates that the better recall of musicians cannot be explained by perceptual visual chunking. These results and the effect of skill level on the distribution of recall errors indicate that the ability to chunk incoming information into meaningful units does not require that complete familiar patterns are accessible to encoding processes, yet previous knowledge stored in long-term memory affects representation construction in working memory. The present method offers a new reliable tool, and its implications to the research on construction of representations and musical imagery are discussed.\n\nDISCO: An object-oriented system for music composition and sound design\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nKaper, H. G.; Tipei, S.; Wright, J. M.\n\n2000-09-05\n\nThis paper describes an object-oriented approach to music composition and sound design. The approach unifies the processes of music making and instrument building by using similar logic, objects, and procedures. The composition modules use an abstract representation of musical data, which can be easily mapped onto different synthesis languages or a traditionally notated score. An abstract base class is used to derive classes on different time scales. Objects can be related to act across time scales, as well as across an entire piece, and relationships between similar objects can replicate traditional music operations or introduce new ones. The DISCO (Digital Instrument for Sonification and Composition) system is an open-ended work in progress.\n\nMetaCompose: A Compositional Evolutionary Music Composer\n\nDEFF Research Database (Denmark)\n\nScirea, Marco; Togelius, Julian; Eklund, Peter\n\n2016-01-01\n\nThis paper describes a compositional, extensible framework for music composition and a user study to systematically evaluate its core components. These components include a graph traversal-based chord sequence generator, a search-based melody generator and a pattern-based accompaniment generator...\n\nReimagining the Role of Composition in Music Teacher Education\n\nScience.gov (United States)\n\nDeemer, Rob\n\n2016-01-01\n\nThe disconnect between the need for music composition instruction at the precollege levels and the content of music education curricula across North America has been a concern for over two decades. To be able to effectively teach their students how to compose, music educators need to have both experience and comfort in the creative process ofâ¦\n\nA Case Study of Diverse Multimodal Influences on Music Improvisation Using Visual Methodology\n\nScience.gov (United States)\n\nTomlinson, Michelle M.\n\n2016-01-01\n\nThis case study employed multimodal methods and visual analysis to explore how a young multilingual student used music improvisation to form a speech rap. This student, recently arrived in Australia from Ethiopia, created piano music that was central to his music identity and that simultaneously, through dialogue with his mother, enhanced hisâ¦\n\nMusic Therapy in the Treatment of Social Isolation in Visually Impaired Children.\n\nScience.gov (United States)\n\nGourgey, Charles\n\n1998-01-01\n\nReviews the literature on the use of music therapy with visually impaired and socially isolated children. Describes ways that music therapy can help the child explore his environment, modify blindisms (stereotypic, autistic-like behaviors), and encourage social awareness and interaction with other children. (DB)\n\nThe Use of Music to Promote Purposeful Movement in Children with Visual Impairments\n\nScience.gov (United States)\n\nColeman, Jeremy\n\n2017-01-01\n\nMusic plays a major role in the education and development of all children. Although the use of music in the education process may seem obvious to most professionals, there are only a few studies that discuss the effect of music on the purposeful movement of students with visual impairments (DePountis, Cady, & Hallak, 2013; Desrochers, Oshlag,â¦\n\nConnecting Music and Place: Exploring Library Collection Data Using Geo-visualizations\n\nDirectory of Open Access Journals (Sweden)\n\nCarolyn Doi\n\n2017-06-01\n\nFull Text Available Abstract Objectives â This project had two stated objectives: 1 to compare the location and concentration of Saskatchewan-based large ensembles (bands, orchestras, choirs within the province, with the intention to draw conclusions about the history of community-based musical activity within the province; and 2 to enable location-based browsing of Saskatchewan music materials through an interactive search interface. Methods â Data was harvested from MARC metadata found in the library catalogue for a special collection of Saskatchewan music at the University of Saskatchewan. Microsoft Excel and OpenRefine were used to screen, clean, and enhance the dataset. Data was imported into ArcGIS software, where it was plotted using a geo-visualization showing location and concentrations of musical activity by large ensembles within the province. The geo-visualization also allows users to filter results based on the ensemble type (band, orchestra, or choir. Results â The geo-visualization shows that albums from large community ensembles appear across the province, in cities and towns of all sizes. The ensembles are concentrated in the southern portion of the province and there is a correlation between population density and ensemble location. Choral ensembles are more prevalent than bands and orchestras, and appear more widely across the province, whereas bands and orchestras are concentrated around larger centres. Conclusions â Library catalogue data contains unique information for research based on special collections, though additional cleaning is needed. Using geospatial visualizations to navigate collections allows for more intuitive searching by location, and allow users to compare facets. While not appropriate for all kinds of searching, maps are useful for browsing and for location-based searches. Information is displayed in a visual way that allows users to explore and connect with other platforms for more information.\n\nVisualizing Music\n\nScience.gov (United States)\n\nOverby, Alexandra\n\n2009-01-01\n\nMusic has always been an important aspect of teenage life, but with the portability of the newest technological devices, it is harder and harder to separate students from their musical influences. In this article, the author describes a lesson wherein she incorporated their love of song into an engaging art project. In this lesson, she hadâ¦\n\n[Social behavior, musicality and visual perception in monogloid children (author's transl)].\n\nScience.gov (United States)\n\nRabensteiner, B\n\n1975-01-01\n\nForty-nine mongoloid and 48 non-mongol test persons of equivalent age and intelligence were selected and studied with respect to social behavior, speech disorders (observation of behavior), musicality and visual perception. There were significant differences in favor of the mongols with respect to social adaption. Speech disorders of all kinds occurred significantly more frequently in mongol children; stuttering was significantly more frequent in the boys. The mongol group did significantly better in the musicality test; the difference in the rhythmical part was highly significant. The average differences in the capacity for visual discrimination of colors, geometrical forms and the spatial relationship of geometrical forms were not significant.\n\nImagined Voices : a poetics of Music-Text-Film\n\nNARCIS (Netherlands)\n\nKyriakides, Y.\n\n2017-01-01\n\nImagined Voices deals with a form of composition, music with on-screen text, in which the dynamic between sound, words and visuals is explored. The research explores the ideas around these 'music-text-films', and attempts to explain how meaning is constructed in the interplay between the different\n\nDifferential Effects of Music and Video Gaming During Breaks on Auditory and Visual Learning.\n\nScience.gov (United States)\n\nLiu, Shuyan; Kuschpel, Maxim S; Schad, Daniel J; Heinz, Andreas; Rapp, Michael A\n\n2015-11-01\n\nThe interruption of learning processes by breaks filled with diverse activities is common in everyday life. This study investigated the effects of active computer gaming and passive relaxation (rest and music) breaks on auditory versus visual memory performance. Young adults were exposed to breaks involving (a) open eyes resting, (b) listening to music, and (c) playing a video game, immediately after memorizing auditory versus visual stimuli. To assess learning performance, words were recalled directly after the break (an 8:30 minute delay) and were recalled and recognized again after 7 days. Based on linear mixed-effects modeling, it was found that playing the Angry Birds video game during a short learning break impaired long-term retrieval in auditory learning but enhanced long-term retrieval in visual learning compared with the music and rest conditions. These differential effects of video games on visual versus auditory learning suggest specific interference of common break activities on learning.\n\nArtful terms: A study on aesthetic word usage for visual art versus film and music\n\nScience.gov (United States)\n\nAugustin, M Dorothee; Carbon, Claus-Christian; Wagemans, Johan\n\n2012-01-01\n\nDespite the importance of the arts in human life, psychologists still know relatively little about what characterises their experience for the recipient. The current research approaches this problem by studying people's word usage in aesthetics, with a focus on three important art forms: visual art, film, and music. The starting point was a list of 77 words known to be useful to describe aesthetic impressions of visual art (Augustin et al 2012, Acta Psychologica 139 187â201). Focusing on ratings of likelihood of use, we examined to what extent word usage in aesthetic descriptions of visual art can be generalised to film and music. The results support the claim of an interplay of generality and specificity in aesthetic word usage. Terms with equal likelihood of use for all art forms included beautiful, wonderful, and terms denoting originality. Importantly, emotion-related words received higher ratings for film and music than for visual art. To our knowledge this is direct evidence that aesthetic experiences of visual art may be less affectively loaded than, for example, experiences of music. The results render important information about aesthetic word usage in the realm of the arts and may serve as a starting point to develop tailored measurement instruments for different art forms. PMID:23145287\n\nArtful terms: A study on aesthetic word usage for visual art versus film and music.\n\nScience.gov (United States)\n\nAugustin, M Dorothee; Carbon, Claus-Christian; Wagemans, Johan\n\n2012-01-01\n\nDespite the importance of the arts in human life, psychologists still know relatively little about what characterises their experience for the recipient. The current research approaches this problem by studying people's word usage in aesthetics, with a focus on three important art forms: visual art, film, and music. The starting point was a list of 77 words known to be useful to describe aesthetic impressions of visual art (Augustin et al 2012, Acta Psychologica139 187-201). Focusing on ratings of likelihood of use, we examined to what extent word usage in aesthetic descriptions of visual art can be generalised to film and music. The results support the claim of an interplay of generality and specificity in aesthetic word usage. Terms with equal likelihood of use for all art forms included beautiful, wonderful, and terms denoting originality. Importantly, emotion-related words received higher ratings for film and music than for visual art. To our knowledge this is direct evidence that aesthetic experiences of visual art may be less affectively loaded than, for example, experiences of music. The results render important information about aesthetic word usage in the realm of the arts and may serve as a starting point to develop tailored measurement instruments for different art forms.\n\nArtful Terms: A Study on Aesthetic Word Usage for Visual Art versus Film and Music\n\nDirectory of Open Access Journals (Sweden)\n\nM Dorothee Augustin\n\n2012-06-01\n\nFull Text Available Despite the importance of the arts in human life, psychologists still know relatively little about what characterises their experience for the recipient. The current research approaches this problem by studying people's word usage in aesthetics, with a focus on three important art forms: visual art, film, and music. The starting point was a list of 77 words known to be useful to describe aesthetic impressions of visual art (Augustin et al 2012, Acta Psychologica 139 187â201. Focusing on ratings of likelihood of use, we examined to what extent word usage in aesthetic descriptions of visual art can be generalised to film and music. The results support the claim of an interplay of generality and specificity in aesthetic word usage. Terms with equal likelihood of use for all art forms included beautiful, wonderful, and terms denoting originality. Importantly, emotion-related words received higher ratings for film and music than for visual art. To our knowledge this is direct evidence that aesthetic experiences of visual art may be less affectively loaded than, for example, experiences of music. The results render important information about aesthetic word usage in the realm of the arts and may serve as a starting point to develop tailored measurement instruments for different art forms.\n\nCharacterizing chaotic melodies in automatic music composition\n\nScience.gov (United States)\n\nCoca, AndrÃ©s E.; Tost, Gerard O.; Zhao, Liang\n\n2010-09-01\n\nIn this paper, we initially present an algorithm for automatic composition of melodies using chaotic dynamical systems. Afterward, we characterize chaotic music in a comprehensive way as comprising three perspectives: musical discrimination, dynamical influence on musical features, and musical perception. With respect to the first perspective, the coherence between generated chaotic melodies (continuous as well as discrete chaotic melodies) and a set of classical reference melodies is characterized by statistical descriptors and melodic measures. The significant differences among the three types of melodies are determined by discriminant analysis. Regarding the second perspective, the influence of dynamical features of chaotic attractors, e.g., Lyapunov exponent, Hurst coefficient, and correlation dimension, on melodic features is determined by canonical correlation analysis. The last perspective is related to perception of originality, complexity, and degree of melodiousness (Euler's gradus suavitatis) of chaotic and classical melodies by nonparametric statistical tests.\n\nAudiovisual correspondence between musical timbre and visual shapes.\n\nDirectory of Open Access Journals (Sweden)\n\nMohammad eAdeli\n\n2014-05-01\n\nFull Text Available This article investigates the cross-modal correspondences between musical timbre and shapes. Previously, such features as pitch, loudness, light intensity, visual size, and color characteristics have mostly been used in studies of audio-visual correspondences. Moreover, in most studies, simple stimuli e.g. simple tones have been utilized. In this experiment, 23 musical sounds varying in fundamental frequency and timbre but fixed in loudness were used. Each sound was presented once against colored shapes and once against grayscale shapes. Subjects had to select the visual equivalent of a given sound i.e. its shape, color (or grayscale and vertical position. This scenario permitted studying the associations between normalized timbre and visual shapes as well as some of the previous findings for more complex stimuli. 119 subjects (31 females and 88 males participated in the online experiment. Subjects included 36 claimed professional musicians, 47 claimed amateur musicians and 36 claimed non-musicians. 31 subjects have also claimed to have synesthesia-like experiences. A strong association between timbre of envelope normalized sounds and visual shapes was observed. Subjects have strongly associated soft timbres with blue, green or light gray rounded shapes, harsh timbres with red, yellow or dark gray sharp angular shapes and timbres having elements of softness and harshness together with a mixture of the two previous shapes. Color or grayscale had no effect on timbre-shape associations. Fundamental frequency was not associated with height, grayscale or color. The significant correspondence between timbre and shape revealed by the present work allows designing substitution systems which might help the blind to perceive shapes through timbre.\n\nImproving Students' Memory for Musical Compositions and Their Composers: Mneme that Tune!\n\nScience.gov (United States)\n\nCarney, Russell N.; Levin, Joel R.\n\n2007-01-01\n\nStudents enrolled in music appreciation and music history courses may find it difficult to remember composers' names and the titles of their compositions--particularly when retrieval is prompted by corresponding classical music themes. We sought to develop and validate a mnemonic approach in which musical themes were first recoded as more concreteâ¦\n\nMusic training improves verbal but not visual memory: cross-sectional and longitudinal explorations in children.\n\nScience.gov (United States)\n\nHo, Yim-Chi; Cheung, Mei-Chun; Chan, Agnes S\n\n2003-07-01\n\nThe hypothesis that music training can improve verbal memory was tested in children. The results showed that children with music training demonstrated better verbal but not visual memory than did their counterparts without such training. When these children were followed up after a year, those who had begun or continued music training demonstrated significant verbal memory improvement. Students who discontinued the training did not show any improvement. Contrary to the differences in verbal memory between the groups, their changes in visual memory were not significantly different. Consistent with previous findings for adults (A. S. Chan, Y. Ho, & M. Cheung, 1998), the results suggest that music training systematically affects memory processing in accordance with possible neuroanatomical modifications in the left temporal lobe.\n\nA Knowledge-Based Tutor for Music Composition. CITE Report No. 16.\n\nScience.gov (United States)\n\nHolland, Simon\n\nThe work described here forms part of a project using models of musical ideas within an artificial intelligence and education framework whose goal is to encourage and facilitate music composition by novices. Formal knowledge of the domain (popular music) is too incomplete and fragmented to support a traditional expert-based tutor for preciselyâ¦\n\nOcean images in music compositions and folksongs\n\nScience.gov (United States)\n\nLiu, C. M.\n\n2017-12-01\n\nIn general, ocean study usually ranges from physical oceanography, chemical oceanography, marine biology, marine geology, and other related fields. In addition to pure scientific fields, ocean phenomenon influence not only human mood but also the shaping of local cultures. In this paper, we present some ocean images and concepts appeared in music compositions and folksongs to show the mixing, influence and interaction between them. This may give a novel way not for science teachers but also music teachers to deliver the knowledge of ocean science in classes.\n\nRobust Real-Time Music Transcription with a Compositional Hierarchical Model.\n\nScience.gov (United States)\n\nPesek, MatevÅ¾; Leonardis, AleÅ¡; Marolt, Matija\n\n2017-01-01\n\nThe paper presents a new compositional hierarchical model for robust music transcription. Its main features are unsupervised learning of a hierarchical representation of input data, transparency, which enables insights into the learned representation, as well as robustness and speed which make it suitable for real-world and real-time use. The model consists of multiple layers, each composed of a number of parts. The hierarchical nature of the model corresponds well to hierarchical structures in music. The parts in lower layers correspond to low-level concepts (e.g. tone partials), while the parts in higher layers combine lower-level representations into more complex concepts (tones, chords). The layers are learned in an unsupervised manner from music signals. Parts in each layer are compositions of parts from previous layers based on statistical co-occurrences as the driving force of the learning process. In the paper, we present the model's structure and compare it to other hierarchical approaches in the field of music information retrieval. We evaluate the model's performance for the multiple fundamental frequency estimation. Finally, we elaborate on extensions of the model towards other music information retrieval tasks.\n\nMusical agents\n\nDEFF Research Database (Denmark)\n\nDahlstedt, Palle; McBurney, Peter\n\n2006-01-01\n\nThe authors, a composer and a computer scientist, discuss their collaborative research on the use of multiagent systems and their applicability to music and musical composition. They describe the development of software and techniques for the composition of generative music.......The authors, a composer and a computer scientist, discuss their collaborative research on the use of multiagent systems and their applicability to music and musical composition. They describe the development of software and techniques for the composition of generative music....\n\nThe Apperception of Musical Creativity: Performance as Ritual, Composition as Self-Realization\n\nScience.gov (United States)\n\nNagy, Zvonimir\n\n2015-01-01\n\nMusical invention is defined in this article as a form of inward creativity. The creative acts of musical performance are understood in terms of ritual-like symbolic and stylized actions, and those of musical composition as the mind's enactment of meditation and reflection. This article draws on the relationship between two psychologicalâ¦\n\nImmersion and togetherness: How live visualization of audience engagement can enhance music events\n\nNARCIS (Netherlands)\n\nN. Shirzadian (Najereh); J.A. Redi (Judith); T. RÃ¶ggla (Tom); A. Panza (Alice); F.-M. Nack (Frank); P.S. Cesar Garcia (Pablo Santiago)\n\n2017-01-01\n\ntextabstractThis paper evaluates the influence of an additional visual aesthetic layer on the experience of concert goers during a live event. The additional visual layer incorporates musical features as well as bio-sensing data collected during the concert, which is coordinated by our audience\n\nA composition algorithm based on crossmodal taste-music correspondences\n\nDirectory of Open Access Journals (Sweden)\n\nBruno eMesz\n\n2012-04-01\n\nFull Text Available While there is broad consensus about the structural similarities between language and music, comparably less attention has been devoted to semantic correspondences between these two ubiquitous manifestations of human culture. We have investigated the relations between music and a narrow and bounded domain of semantics: the words and concepts referring to taste sensations. In a recent work, we found that taste words were consistently mapped to musical parameters. Bitter is associated with low-pitched and continuous music (legato, salty is characterized by silences between notes (staccato, sour is high pitched, dissonant and fast and sweet is consonant, slow and soft (Mesz2011. Here we extended these ideas, in a synergistic dialog between music and science, investigating whether music can be algorithmically generated from taste-words. We developed and implemented an algorithm that exploits a large corpus of classic and popular songs. New musical pieces were produced by choosing fragments from the corpus and modifying them to minimize their distance to the region in musical space that characterizes each taste. In order to test the capability of the produced music to elicit significant associations with the different tastes, musical pieces were produced and judged by a group of non musicians. Results showed that participants could decode well above chance the taste-word of the composition. We also discuss how our findings can be expressed in a performance bridging music and cognitive science.\n\nColorado Multicultural Resources for Arts Education: Dance, Music, Theatre, and Visual Art.\n\nScience.gov (United States)\n\nCassio, Charles J., Ed.\n\nThis Colorado resource guide is based on the premise that the arts (dance, music, theatre, and visual art) provide a natural arena for teaching multiculturalism to students of all ages. The guide provides information to Colorado schools about printed, disc, video, and audio tape visual prints, as well as about individuals and organizations thatâ¦\n\nVisual processing of music notation: a study of event-related potentials.\n\nScience.gov (United States)\n\nLee, Horng-Yih; Wang, Yu-Sin\n\n2011-04-01\n\nIn reading music, the acquisition of pitch information depends mostly on the spatial position of notes, hence more spatial processing, whereas the acquisition of temporal information depends mostly on the visual features of notes and object recognition. This study used both electrophysiological and behavioral methods to compare the processing of pitch and duration in reading single musical notes. It was observed that in the early stage of note reading, identification of pitch could elicit greater N1 and N2 amplitude than identification of duration at the parietal lobe electrodes. In the later stages of note reading, identifying pitch elicited a greater negative slow wave at parietal electrodes than did identifying note duration. The sustained contribution of parietal processes for pitch suggests that the dorsal pathway is essential for pitch processing. However, the duration task did not elicit greater amplitude of any early ERP components than the pitch task at temporal electrodes. Accordingly, a double dissociation, suggesting involvement of the dorsal visual stream, was not observed in spatial pitch processing and ventral visual stream in processing of note durations.\n\nCross-National Comparisons of Background and Confidence in Visual Arts and Music Education of Pre-Service Primary Teachers\n\nScience.gov (United States)\n\nRussell-Bowie, Deirdre\n\n2010-01-01\n\nThis paper reports the findings of a study on pre-service teachers' background and confidence in music and visual arts education. The study involved 939 non-specialist pre-service primary teachers from five countries. Initially the paper identifies the students' perceptions of their background and confidence in relation to music and visual artsâ¦\n\nLayers Of Visual Imagination And Degrees Of Subjectivity In Listening Experiences Exploring Visual Imagination In Acousmatic Composition And Listening\n\nDirectory of Open Access Journals (Sweden)\n\nStefano Poillucci\n\n2015-08-01\n\nFull Text Available Abstract Electroacoustic music especially Acousmatic is often perceived differently between listeners and a wide variety of visual images is evoked. This because of the spectromorphological qualities and the abstract reality in which this kind of music carries the listener into. In everyday life it seems that we have a natural tendency to assess and understand reality around us and to quantise how and if the perceived circumstances could affect our wellbeing. Some studies also affirm that brain and the biological function of the sensory and perceptual processes are commonly identical in each listener. This gives evidence that arises the interest to investigate which variations the subjectivity of visual imagery depends on and if it is possible to unfold it in various layers. This experimental research has taken in consideration questionnaire-based listening tests to gather details from each listening experience and to get a better understanding of the visual imagery evoked by electroacoustic compositions into the listeners mind and its degrees of objectivity and subjectivity. The compositions used in the experiment were both composed by the author with the intention of guiding listeners into their personal perceptual-imaginative journey by delivering encoded perhaps objective sonic cues. This paper is a theoretical inter-disciplinary analysis backed by research on the foundations of senses perception cognition emotions etc. An artistic approach based on scientific evidences led to the theorization of layers of imagination and their bias to produce visual images with a degree of subjectivity that lies into micro aspects of sounds and in the perceptual and innate knowledge of each individual. Glossary The terms listed here have been invented or readapted for the purpose of the study in order to make concepts easier to assimilate and understand. Aural World sonic world with intrinsic features Smalley 1997. The purely auditory realm which an\n\nSegmentation of dance movement: Effects of expertise, visual familiarity, motor experience and music\n\nDirectory of Open Access Journals (Sweden)\n\nBettina E. BlÃ¤sing\n\n2015-01-01\n\nFull Text Available According to event segmentation theory, action perception depends on sensory cues and prior knowledge, and the segmentation of observed actions is crucial for understanding and memorizing these actions. While most activities in everyday life are characterized by external goals and interaction with objects or persons, this does not necessarily apply to dance-like actions. We investigated to what extent visual familiarity of the observed movement and accompanying music influence the segmentation of a dance phrase in dancers of different skill level and non-dancers. In Experiment 1, dancers and non-dancers repeatedly watched a video clip showing a dancer performing a choreographed dance phrase and indicated segment boundaries by key press. Dancers generally defined less segment boundaries than non-dancers, specifically in the first trials in which visual familiarity with the phrase was low. Music increased the number of segment boundaries in the non-dancers and decreased it in the dancers. The results suggest that dance expertise reduces the number of perceived segment boundaries in an observed dance phrase, and that the ways visual familiarity and music affect movement segmentation are modulated by dance expertise. In a second experiment, motor experience was added as factor, based on empirical evidence suggesting that action perception is modified by visual and motor expertise in different ways. In Experiment 2, the same task as in Experiment 1 was performed by dance amateurs, and was repeated by the same participants after they had learned to dance the presented dance phrase. Less segment boundaries were defined in the middle trials after participants had learned to dance the phrase, and music reduced the number of segment boundaries before learning. The results suggest that specific motor experience of the observed movement influences its perception and anticipation and makes segmentation broader, but not to the same degree as dance expertise\n\nThe effects of age and experience on memory for visually presented music.\n\nScience.gov (United States)\n\nMeinz, E J; Salthouse, T A\n\n1998-01-01\n\nIncreased age is often associated with lower levels of performance in tests of memory for spatial information. The primary question in the current study was whether this relationship could be moderated as a function of one's relevant experience and/or knowledge. Stimulus materials consisted of short (7-11 note), visually presented musical melodies and structurally equivalent nonmusical stimuli. Participants (N = 128) were recruited from a wide range of age and experience levels. Although there were strong main effects of age and experience on memory for music, there was no evidence that the age-related differences in memory for these stimuli were smaller for individuals with moderate to large amounts of experience with music.\n\nComparing the Effects of Elementary Music and Visual Arts Lessons on Standardized Mathematics Test Scores\n\nScience.gov (United States)\n\nKing, Molly Elizabeth\n\n2016-01-01\n\nThe purpose of this quantitative, causal-comparative study was to compare the effect elementary music and visual arts lessons had on third through sixth grade standardized mathematics test scores. Inferential statistics were used to compare the differences between test scores of students who took in-school, elementary, music instruction during theâ¦\n\nThe effect of composition (art or music) on the self-concept of hospitalized children.\n\nScience.gov (United States)\n\nColwell, Cynthia M; Davis, Kathy; Schroeder, Linda K\n\n2005-01-01\n\nThe purpose of the present study was to determine the effect of composition (art or music) on the self-concept of hospitalized children. The music composition was created using the program Making More Music. The art composition was a drawing using standard medium. The Piers-Harris Children's Self-Concept Scale was used to measure self-concept. When examining subjects as one group, a significant difference from pre- to posttest for the Total score indicated an improved self-concept. Further analyses on each of the 6 categories indicated no significant differences. The art composition group had a significant difference from pre- to posttest for the Total score and for Popularity (POP). Although not significant, scores increased from pre- to posttest for Behavioral Adjustment (BEH), Physical Appearance (PHY), Freedom from Anxiety (FRE), and Happiness and Satisfaction (HAP). The music composition group had no significant difference from pre- to posttest for the Total score but a significant difference from pre- to posttest on Intellectual and School Status (INT) and Physical Appearance (PRY). Although not significant, scores increased from pre- to posttest for TOT, BEH, and HAP. There was a significant difference between the groups on 2 categories that indicated an improved self-concept for the music group under Intellectual and School Status and for the art group under Popularity.\n\nMusic interventions and group participation skills of preschoolers with visual impairments: raising questions about music, arousal, and attention.\n\nScience.gov (United States)\n\nRobb, Sheri L\n\n2003-01-01\n\nThe purposes of this pilot study were two-fold: First, to document and compare attentive behavior during music and play-based group instructional sessions and second, to document and compare 4 group participation behaviors during music and play-based sessions. The 4 group participation behaviors included facing a central speaker, following onestep directions, manipulating objects according to their function, and remaining seated. Six of the 12 children enrolled completed the study, with all participants enrolled in an early intervention program due to visual impairments. Study participants were between the ages of 4 and 6 years inclusively. Children participated in 4, 30-minute instructional sessions. Two instructional sessions were music-based and two were play-based with the 4 sessions equally distributed across a 2-week period. An ABBA design was used to control for possible order effects. Each session was videotaped to facilitate collection of behavioral data. Statistical analysis of these data revealed that attentive behavior was significantly higher during music based-sessions (t(5) = 5.81; p =.002). Mean scores for the remaining group participation behaviors were higher in the music condition, but these differences were not statistically significant. Discussion regarding differential outcomes among participants, as well as an exploration of theories related to music, arousal, and attention are discussed in an effort to guide future research.\n\nQuantifying Shapes: Mathematical Techniques for Analysing Visual Representations of Sound and Music\n\nDirectory of Open Access Journals (Sweden)\n\nGenevieve L. Noyce\n\n2013-12-01\n\nFull Text Available Research on auditory-visual correspondences has a long tradition but innovative experimental paradigms and analytic tools are sparse. In this study, we explore different ways of analysing real-time visual representations of sound and music drawn by both musically-trained and untrained individuals. To that end, participants' drawing responses captured by an electronic graphics tablet were analysed using various regression, clustering, and classification techniques. Results revealed that a Gaussian process (GP regression model with a linear plus squared-exponential covariance function was able to model the data sufficiently, whereas a simpler GP was not a good fit. Spectral clustering analysis was the best of a variety of clustering techniques, though no strong groupings are apparent in these data. This was confirmed by variational Bayes analysis, which only fitted one Gaussian over the dataset. Slight trends in the optimised hyperparameters between musically-trained and untrained individuals allowed for the building of a successful GP classifier that differentiated between these two groups. In conclusion, this set of techniques provides useful mathematical tools for analysing real-time visualisations of sound and can be applied to similar datasets as well.\n\nWhen music flows. State and Trait Flow in musical performance, composition and listening: A systematic review\n\nDirectory of Open Access Journals (Sweden)\n\nAlice eChirico\n\n2015-06-01\n\nFull Text Available It is not unusual to experience a sense of total absorption, concentration, action-awareness, distortion of time and intrinsic enjoyment during an activity that involves music. Indeed, it is noted that there is a special relationship between these two aspects (i.e., music and flow experience. In order to deeply explore flow in the musical domain, it is crucial to consider the complexity of the flow experienceâboth as a state and as a trait. Secondly, since music is a multifaceted domain, it is necessary to concentrate on specific music settings, such as (i musical composition; (ii listening; and (iii musical performance. To address these issues, the current review aims to outline flow experience as a trait and as a state in the three above-mentioned musical domains. Clear and useful guidelines to distinguish between flow as a state and as a trait are provided by literature concerning flow assessment. For this purpose, three aspects of the selected studies are discussed and analyzed: (i the characteristics of the flow assessments used; (ii the experimental design; (iii the results; and (iv the interrelations between the three domains. Results showed that the dispositional approach is predominant in the above-mentioned settings, mainly regarding music performance. Several aspects concerning musical contexts still need to be deeply analyzed.Future challenges could include the role of a group level of analysis, overcoming a frequency approach towards dispositional flow, and integrating both state and dispositional flow perspectives in order to deepen comprehension of how flow takes place in musical contexts.Finally, to explain the complex relationship between these two phenomena, we suggest that music and flow could be seen as an emergent embodied system.\n\nWhen music âflowsâ. State and trait in musical performance, composition and listening: a systematic review\n\nScience.gov (United States)\n\nChirico, Alice; Serino, Silvia; Cipresso, Pietro; Gaggioli, Andrea; Riva, Giuseppe\n\n2015-01-01\n\nIt is not unusual to experience a sense of total absorption, concentration, action-awareness, distortion of time and intrinsic enjoyment during an activity that involves music. Indeed, it is noted that there is a special relationship between these two aspects (i.e., music and flow experience). In order to deeply explore flow in the musical domain, it is crucial to consider the complexity of the flow experienceâboth as a âstateâ and as a âtrait.â Secondly, since music is a multifaceted domain, it is necessary to concentrate on specific music settings, such as (i) musical composition; (ii) listening; and (iii) musical performance. To address these issues, the current review aims to outline flow experience as a âtraitâ and as a âstateâ in the three above-mentioned musical domains. Clear and useful guidelines to distinguish between flow as a âstateâ and as a âtraitâ are provided by literature concerning flow assessment. For this purpose, three aspects of the selected studies are discussed and analyzed: (i) the characteristics of the flow assessments used; (ii) the experimental design; (iii) the results; and (iv) the interrelations between the three domains. Results showed that the dispositional approach is predominant in the above-mentioned settings, mainly regarding music performance. Several aspects concerning musical contexts still need to be deeply analyzed. Future challenges could include the role of a group level of analysis, overcoming a frequency approach toward dispositional flow, and integrating both state and dispositional flow perspectives in order to deepen comprehension of how flow takes place in musical contexts. Finally, to explain the complex relationship between these two phenomena, we suggest that music and flow could be seen as an emergent embodied system. PMID:26175709\n\nExploring the association between visual perception abilities and reading of musical notation.\n\nScience.gov (United States)\n\nLee, Horng-Yih\n\n2012-06-01\n\nIn the reading of music, the acquisition of pitch information depends primarily upon the spatial position of notes as well as upon an individual's spatial processing ability. This study investigated the relationship between the ability to read single notes and visual-spatial ability. Participants with high and low single-note reading abilities were differentiated based upon differences in musical notation-reading abilities and their spatial processing; object recognition abilities were then assessed. It was found that the group with lower note-reading abilities made more errors than did the group with a higher note-reading abilities in the mental rotation task. In contrast, there was no apparent significant difference between the two groups in the object recognition task. These results suggest that note-reading may be related to visual spatial processing abilities, and not to an individual's ability with object recognition.\n\nA single frequency component-based re-estimated MUSIC algorithm for impact localization on complex composite structures\n\nInternational Nuclear Information System (INIS)\n\nYuan, Shenfang; Bao, Qiao; Qiu, Lei; Zhong, Yongteng\n\n2015-01-01\n\nThe growing use of composite materials on aircraft structures has attracted much attention for impact monitoring as a kind of structural health monitoring (SHM) method. Multiple signal classification (MUSIC)-based monitoring technology is a promising method because of its directional scanning ability and easy arrangement of the sensor array. However, for applications on real complex structures, some challenges still exist. The impact-induced elastic waves usually exhibit a wide-band performance, giving rise to the difficulty in obtaining the phase velocity directly. In addition, composite structures usually have obvious anisotropy, and the complex structural style of real aircrafts further enhances this performance, which greatly reduces the localization precision of the MUSIC-based method. To improve the MUSIC-based impact monitoring method, this paper first analyzes and demonstrates the influence of measurement precision of the phase velocity on the localization results of the MUSIC impact localization method. In order to improve the accuracy of the phase velocity measurement, a single frequency component extraction method is presented. Additionally, a single frequency component-based re-estimated MUSIC (SFCBR-MUSIC) algorithm is proposed to reduce the localization error caused by the anisotropy of the complex composite structure. The proposed method is verified on a real composite aircraft wing box, which has T-stiffeners and screw holes. Three typical categories of 41 impacts are monitored. Experimental results show that the SFCBR-MUSIC algorithm can localize impact on complex composite structures with an obviously improved accuracy. (paper)\n\nArt as behaviour--an ethological approach to visual and verbal art, music and architecture.\n\nScience.gov (United States)\n\nSÃ¼tterlin, Christa; SchiefenhÃ¶vel, Wulf; Lehmann, Christian; Forster, Johanna; Apfelauer, Gerhard\n\n2014-01-01\n\nIn recent years, the fine arts, architecture, music and literature have increasingly been examined from the vantage point of human ethology and evolutionary psychology. In 2011 the authors formed the research group 'Ethology of the Arts' concentrating on the evolution and biology of perception and behaviour. These novel approaches aim at a better understanding of the various facets represented by the arts by taking into focus possible phylogenetic adaptations, which have shaped the artistic capacities of our ancestors. Rather than culture specificity, which is stressed e.g. by cultural anthropology and numerous other disciplines, universal human tendencies to perceive, feel, think and behave are postulated. Artistic expressive behaviour is understood as an integral part of the human condition, whether expressed in ritual, visual, verbal or musical art. The Ethology of the Arts-group's research focuses on visual and verbal art, music and built environment/architecture and is designed to contribute to the incipient interdisciplinarity in the field of evolutionary art research.\n\nAn Interdisciplinary Approach for Understanding Artworks: The Role of Music in Visual Arts Education\n\nScience.gov (United States)\n\nPavlou, Victoria; Athansiou, Georgina\n\n2014-01-01\n\nIn a world that is becoming increasingly more visual, there is a greater need to educate children to better understand images. A school subject that deals directly with image understanding is visual arts. This article discusses an interdisciplinary approach to promote art understanding, within a multimodal environment that combines art and music.â¦\n\nLocus of control and styles of coping with stress in students educated a"
    }
}