{
    "id": "dbpedia_1734_3",
    "rank": 12,
    "data": {
        "url": "https://projectreactor.io/docs/kafka/snapshot/reference/",
        "read_more_link": "",
        "language": "en",
        "title": "Reactor Kafka Reference Guide",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "5.2. Reactive Kafka Sender\n\nOutbound messages are sent to Kafka using reactor.kafka.sender.KafkaSender. Senders are thread-safe and can be shared across multiple threads to improve throughput. A KafkaSender is associated with one KafkaProducer that is used to transport messages to Kafka.\n\nA KafkaSender is created with an instance of sender configuration options reactor.kafka.sender.SenderOptions. Changes made to SenderOptions after the creation of KafkaSender will not be used by the KafkaSender. The properties of SenderOptions such as a list of bootstrap Kafka brokers and serializers are passed down to the underlying KafkaProducer. The properties may be configured on the SenderOptions instance at creation time or by using the setter SenderOptions#producerProperty. Other configuration options for the reactive KafkaSender like the maximum number of in-flight messages can also be configured before the KafkaSender instance is created.\n\nThe generic types of SenderOptions<K, V> and KafkaSender<K, V> are the key and value types of producer records published using the KafkaSender and corresponding serializers must be set on the SenderOptions instance before the KafkaSender is created.\n\nMap<String, Object> producerProps = new HashMap<>(); producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); SenderOptions<Integer, String> senderOptions = SenderOptions.<Integer, String>create(producerProps) (1) .maxInFlight(1024); (2)\n\n1 Specify properties for underlying KafkaProducer 2 Configure options for reactive KafkaSender\n\nOnce the required options have been configured on the options instance, a new KafkaSender instance can be created with the options already configured in senderOptions.\n\nKafkaSender<Integer, String> sender = KafkaSender.create(senderOptions);\n\nThe KafkaSender is now ready to send messages to Kafka. The underlying KafkaProducer instance is created lazily when the first message is ready to be sent. At this point, a KafkaSender instance has been created, but no connections to Kafka have been made yet.\n\nLetâ€™s now create a sequence of messages to send to Kafka. Each outbound message to be sent to Kafka is represented as a SenderRecord. A SenderRecord is a Kafka ProducerRecord with additional correlation metadata for matching send results to records. ProducerRecord consists of a key/value pair to send to Kafka and the name of the Kafka topic to send the message to. Producer records may also optionally specify a partition to send the message to or use the configured partitioner to choose a partition. Timestamp may also be optionally specified in the record and if not specified, the current timestamp will be assigned by the Producer. The additional correlation metadata included in SenderRecord is not sent to Kafka, but is included in the SendResult generated for the record when the send operation completes or fails. Since results of sends to different partitions may be interleaved, the correlation metadata enables results to be matched to their corresponding record.\n\nA Flux<SenderRecord> of records is created for sending to Kafka. For beginners, Lite Rx API Hands-on provides a hands-on tutorial on using the Reactor classes Flux and Mono.\n\nFlux<SenderRecord<Integer, String, Integer>> outboundFlux = Flux.range(1, 10) .map(i -> SenderRecord.create(topic, partition, timestamp, i, \"Message_\" + i, i));\n\nThe code segment above creates a sequence of messages to send to Kafka, using the message index as correlation metadata in each SenderRecord. The outbound Flux can now be sent to Kafka using the KafkaSender created earlier.\n\nThe code segment below sends the records to Kafka and prints out the response metadata received from Kafka and the correlation metadata for each record. The final subscribe() in the code block requests upstream to send the records to Kafka and the response metadata received from Kafka flow downstream. As each result is received, the record metadata from Kafka along with the correlation metadata identifying the record is printed out to console by the onNext handler. The response from Kafka includes the partition to which the record was sent as well as the offset at the which the record was appended, if available. When records are sent to multiple partitions, responses arrive in order for each partition, but responses from different partitions may be interleaved.\n\nsender.send(outboundFlux) (1) .doOnError(e-> log.error(\"Send failed\", e)) (2) .doOnNext(r -> System.out.printf(\"Message #%d send response: %s\\n\", r.correlationMetadata(), r.recordMetadata())) (3) .subscribe(); (4)\n\n1 Reactive send operation for the outbound Flux 2 If Kafka send fails, log an error 3 Print metadata returned by Kafka and the message index in correlationMetadata() 4 Subscribe to trigger the actual flow of records from outboundFlux to Kafka.\n\nSee github.com/reactor/reactor-kafka/blob/main/reactor-kafka-samples/src/main/java/reactor/kafka/samples/SampleProducer.java for the full code listing of a sample producer.\n\n5.2.1. Error handling\n\npublic SenderOptions<K, V> stopOnError(boolean stopOnError);\n\nSenderOptions#stopOnError() specifies whether each send sequence should fail immediately if one record could not be delivered to Kafka after the configured number of retries or wait until all records have been processed. This can be used along with ProducerConfig#ACKS_CONFIG and ProducerConfig#RETRIES_CONFIG to configure the required quality of service.\n\n<T> Flux<SenderResult<T>> send(Publisher<SenderRecord<K, V, T>> outboundRecords);\n\nIf stopOnError is false, a success or error response is returned for each outgoing record. For error responses, the exception from Kafka indicating the reason for send failure is set on SenderResult and can be retrieved using SenderResult#exception(). The Flux fails with an error after attempting to send all records published on outboundRecords. If outboundRecords is a non-terminating Flux, send continues to send records published on this Flux until the result Flux is explicitly cancelled by the user.\n\nIf stopOnError is true, a response is returned for the first failed send and the result Flux is terminated immediately with an error. Since multiple outbound messages may be in-flight at any time, it is possible that some messages are delivered successfully to Kafka after the first failure is detected. SenderOptions#maxInFlight() option may be configured to limit the number of messages in-flight at any time.\n\n5.2.2. Send without result metadata\n\nIf individual results are not required for each send request, ProducerRecord can be sent to Kafka without providing correlation metadata using the KafkaOutbound interface. KafkaOutbound is a fluent interface that enables sends to be chained together.\n\nKafkaOutbound<K, V> send(Publisher<? extends ProducerRecord<K, V>> outboundRecords);\n\nThe send sequence is initiated by subscribing to the Mono obtained from KafkaOutbound#then(). The returned Mono completes successfully if all the outbound records are delivered successfully. The Mono terminates on the first send failure. If outboundRecords is a non-terminating Flux, records continue to be sent to Kafka unless a send fails or the returned Mono is cancelled.\n\nsender.createOutbound() .send(Flux.range(1, 10) .map(i -> new ProducerRecord<Integer, String>(topic, i, \"Message_\" + i))) (1) .then() (2) .doOnError(e -> e.printStackTrace()) (3) .doOnSuccess(s -> System.out.println(\"Sends succeeded\")) (4) .subscribe(); (5)\n\n1 Create ProducerRecord Flux. Records are not wrapped in SenderRecord 2 Get the Mono to subscribe to for starting the message flow 3 Error indicates failure to send one or more records 4 Success indicates all records were published, individual partitions or offsets not returned 5 Subscribe to request the actual sends\n\nMultiple sends can be chained together using a sequence of sends on KafkaOutbound. When the Mono returned from KafkaOutbound#then() is subscribed to, the sends are invoked in sequence in the declaration order. The sequence is cancelled if any of the sends fail after the configured number of retries.\n\nsender.createOutbound() .send(flux1) (1) .send(flux2) .send(flux3) .then() (2) .doOnError(e -> e.printStackTrace()) (3) .doOnSuccess(s -> System.out.println(\"Sends succeeded\")) (4) .subscribe(); (5)\n\n1 Sends flux1, flux2 and flux3 in order 2 Get the Mono to subscribe to for starting the message flow sequence 3 Error indicates failure to send one or more records from any of the sends in the chain 4 Success indicates successful send of all records from the whole chain 5 Subscribe to initiate the sequence of sends in the chain\n\nNote that in all cases the retries configured for the KafkaProducer are attempted and failures returned by the reactive KafkaSender indicate a failure to send after the configured number of retry attempts. Retries can result in messages being delivered out of order. The producer property ProducerConfig#MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION may be set to one to avoid re-ordering.\n\n5.2.3. Threading model\n\nKafkaProducer uses a separate network thread for sending requests and processing responses. To ensure that the producer network thread is never blocked by applications while processing results, KafkaSender delivers responses to applications on a separate scheduler. By default, this is a single threaded pooled scheduler that is freed when no longer required. The scheduler can be overridden if required, for instance, to use a parallel scheduler when the Kafka sends are part of a larger pipeline. This is done on the SenderOptions instance before the KafkaSender instance is created using:\n\npublic SenderOptions<K, V> scheduler(Scheduler scheduler);\n\n5.2.4. Non-blocking back-pressure\n\nThe number of in-flight sends can be controlled using the maxInFlight option. Requests for more elements from upstream are limited by the configured maxInFlight to ensure that the total number of requests at any time for which responses are pending are limited. Along with buffer.memory and max.block.ms options on KafkaProducer, maxInFlight enables control of memory and thread usage when KafkaSender is used in a reactive pipeline. This option can be configured on SenderOptions before the KafkaSender is created. Default value is 256. For small messages, a higher value will improve throughput.\n\npublic SenderOptions<K, V> maxInFlight(int maxInFlight);\n\n5.2.5. Closing the KafkaSender\n\nWhen the KafkaSender is no longer required, the KafkaSender instance can be closed. The underlying KafkaProducer is closed, closing all client connections and freeing all memory used by the producer.\n\nsender.close();\n\n5.2.6. Access to the underlying KafkaProducer\n\nReactive applications may sometimes require access to the underlying producer instance to perform actions that are not exposed by the KafkaSender interface. For example, an application might need to know the number of partitions in a topic in order to choose the partition to send a record to. Operations that are not provided directly by KafkaSender like send can be run on the underlying KafkaProducer using KafkaSender#doOnProducer.\n\nsender.doOnProducer(producer -> producer.partitionsFor(topic)) .doOnSuccess(partitions -> System.out.println(\"Partitions \" + partitions)) .subscribe();\n\nUser provided methods are executed asynchronously. A Mono is returned by doOnProducer which completes with the value returned by the user-provided function.\n\n5.3. Reactive Kafka Receiver\n\nMessages stored in Kafka topics are consumed using the reactive receiver reactor.kafka.receiver.KafkaReceiver. Each instance of KafkaReceiver is associated with a single instance of KafkaConsumer. KafkaReceiver is not thread-safe since the underlying KafkaConsumer cannot be accessed concurrently by multiple threads.\n\nA receiver is created with an instance of receiver configuration options reactor.kafka.receiver.ReceiverOptions. Changes made to ReceiverOptions after the creation of the receiver instance will not be used by the KafkaReceiver. The properties of ReceiverOptions such as a list of bootstrap Kafka brokers and de-serializers are passed down to the underlying KafkaConsumer. These properties may be configured on the ReceiverOptions instance at creation time or by using the setter ReceiverOptions#consumerProperty. Other configuration options for the reactive KafkaReceiver including subscription topics must be added to options before the KafkaReceiver instance is created.\n\nThe generic types of ReceiverOptions<K, V> and KafkaReceiver<K, V> are the key and value types of consumer records consumed using the receiver and corresponding de-serializers must be set on the ReceiverOptions instance before the KafkaReceiver is created.\n\nMap<String, Object> consumerProps = new HashMap<>(); consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, \"sample-group\"); consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); ReceiverOptions<Integer, String> receiverOptions = ReceiverOptions.<Integer, String>create(consumerProps) (1) .subscription(Collections.singleton(topic)); (2)\n\n1 Specify properties to be provided to KafkaConsumer 2 Topics to subscribe to\n\nOnce the required configuration options have been configured on the options instance, a new KafkaReceiver instance can be created with these options to consume inbound messages. The code block below creates a receiver instance and creates an inbound Flux for the receiver. The underlying KafkaConsumer instance is created lazily later when the inbound Flux is subscribed to.\n\nFlux<ReceiverRecord<Integer, String>> inboundFlux = KafkaReceiver.create(receiverOptions) .receive();\n\nThe inbound Kafka Flux is ready to be consumed. Each inbound message delivered by the Flux is represented as a ReceiverRecord. Each receiver record is a ConsumerRecord returned by KafkaConsumer along with a committable ReceiverOffset instance. The offset must be acknowledged after the message is processed since unacknowledged offsets will not be committed. If commit interval or commit batch size are configured, acknowledged offsets will be committed periodically. Offsets may also be committed manually using ReceiverOffset#commit() if finer grained control of commit operations is required.\n\ninboundFlux.subscribe(r -> { System.out.printf(\"Received message: %s\\n\", r); (1) r.receiverOffset().acknowledge(); (2) });\n\n1 Prints each consumer record from Kafka 2 Acknowledges that the record has been processed so that the offset may be committed\n\n5.3.1. Error handling\n\nSince in reactive streams an error represents a terminal signal, any error signal emitted in the inbound Flux will cause the subscription to be cancelled and effectively cause the consumer to shut down. This can be mitigated by using the retry() operator (or retryWhen for finer grained control), which will ensure that a new consumer is created:\n\nFlux<ReceiverRecord<Integer, String>> inboundFlux = KafkaReceiver.create(receiverOptions) .receive() .retryWhen(Retry.backoff(3, Duration.of(10L, ChronoUnit.SECONDS)));\n\nAny errors related to the event processing rather than the KafkaConsumer itself should be handled as close to the source as possible and should ideally be prevented from propagating up to the inbound Flux. This is to ensure that the KafkaConsumer doesnâ€™t get restarted unnecessarily due to unrelated application errors.\n\n5.3.2. Subscribing to wildcard patterns\n\nThe example above subscribed to a single Kafka topic. The same API can be used to subscribe to more than one topic by specifying multiple topics in the collection provided to ReceiverOptions#subscription(). Subscription can also be made to a wildcard pattern by specifying a pattern to subscribe to. Group management in KafkaConsumer dynamically updates topic assignment when topics matching the pattern are created or deleted and assigns partitions of matching topics to available consumer instances.\n\nreceiverOptions = receiverOptions.subscription(Pattern.compile(\"demo.*\")); (1)\n\n1 Consume records from all topics starting with \"demo\"\n\nChanges to ReceiverOptions must be made before the receiver instance is created. Altering the subscription deletes any existing subscriptions on the options instance.\n\n5.3.3. Manual assignment of topic partitions\n\nPartitions may be manually assigned to the receiver without using Kafka consumer group management.\n\nreceiverOptions = receiverOptions.assignment(Collections.singleton(new TopicPartition(topic, 0))); (1)\n\n1 Consume from partition 0 of specified topic\n\nExisting subscriptions and assignments on the options instance are deleted when a new assignment is specified. Every receiver created from this options instance with manual assignment consumes messages from all the specified partitions.\n\n5.3.4. Controlling commit frequency\n\nCommit frequency can be controlled using a combination of commit interval and commit batch size. Commits are performed when either the interval or batch size is reached. One or both of these options may be set on ReceiverOptions before the receiver instance is created. If commit interval is configured, at least one commit is scheduled within that interval if any records were consumed. If commit batch size is configured, a commit is scheduled when the configured number of records are consumed and acknowledged.\n\nManual acknowledgement of consumed records after processing along with automatic commits based on the configured commit frequency provides at-least-once delivery semantics. Messages are re-delivered if the consuming application crashes after message was dispatched but before it was processed and acknowledged. Only offsets explicitly acknowledged using ReceiverOffset#acknowledge() are committed. Note that acknowledging an offset acknowledges all previous offsets on the same partition. All acknowledged offsets are committed when partitions are revoked during rebalance and when the receive Flux is terminated.\n\nApplications which require fine-grained control over the timing of commit operations can disable periodic commits and explicitly invoke ReceiverOffset#commit() when required to trigger a commit. This commit is asynchronous by default, but the application many invoke Mono#block() on the returned Mono to implement synchronous commits. Applications may batch commits by acknowledging messages as they are consumed and invoking commit() periodically to commit acknowledged offsets.\n\nreceiver.receive() .doOnNext(r -> { process(r); r.receiverOffset().commit().block(); });\n\nNote that committing an offset acknowledges and commits all previous offsets on that partition. All acknowledged offsets are committed when partitions are revoked during rebalance and when the receive Flux is terminated.\n\nStarting with version 1.3.12, when a rebalance occurs due to group member changes, the rebalance is delayed until records received from the previous poll have been processed. This is controlled by two ReceiverOptions - maxDelayRebalance (default 60s) and commitIntervalDuringDelay (default 100ms). While the delay is in process, any offsets available for committal will be committed every commitIntervalDuringDelay milliseconds. This allows orderly completion of processing the records that have already been received. maxDelayRebalance should be less than max.poll.interval.ms to avoid a forced rebalance due to a non-responsive consumer.\n\n5.3.5. Out of Order Commits\n\nStarting with version 1.3.8, commits can be performed out of order and the framework will defer the commits as needed, until any \"gaps\" are filled. This removes the need for applications to keep track of offsets and commit them in the right order. Deferring commits increases the likelihood of duplicate deliveries if the application crashes while deferred commits are present.\n\nTo enable this feature, set the maxDeferredCommits property of ReceiverOptions. If the number of deferred offset commits exceeds this value, the consumer is pause() d until the number of deferred commits is reduced by the application acknowledging or commiting some of the \"missing\" offsets.\n\nReceiverOptions<Object, Object> options = ReceiverOptions.create() .maxDeferredCommits(100) .subscription(Collections.singletonList(\"someTopic\"));\n\nThe number is an aggregate of deferred commits across all the assigned topics/partitions.\n\nLeaving the property at its default 0 disables the feature and commits are performed whenever called.\n\n5.3.6. Auto-acknowledgement of batches of records\n\nKafkaReceiver#receiveAutoAck returns a Flux of batches of records returned by each KafkaConsumer#poll(). The records in each batch are automatically acknowledged when the Flux corresponding to the batch terminates.\n\nKafkaReceiver.create(receiverOptions) .receiveAutoAck() .concatMap(r -> r) (1) .subscribe(r -> System.out.println(\"Received: \" + r)); (2)\n\n1 Concatenate in order 2 Print out each consumer record received, no explicit ack required\n\nThe maximum number of records in each batch can be controlled using the KafkaConsumer property MAX_POLL_RECORDS. This is used together with the fetch size and wait times configured on the KafkaConsumer to control the amount of data fetched from Kafka brokers in each poll. Each batch is returned as a Flux that is acknowledged after the Flux terminates. Acknowledged records are committed periodically based on the configured commit interval and batch size. This mode is simple to use since applications do not need to perform any acknowledge or commit actions. It is efficient as well but can not be used for at-least-once delivery of messages.\n\n5.3.7. Manual acknowledgement of batches of records\n\nKafkaReceiver#receiveBatch returns a Flux of batches of records returned by each KafkaConsumer#poll(). The records in each batch should be manually acknowledged or committed.\n\nKafkaReceiver.create(receiverOptions) .receiveBatch() .concatMap(b -> b) (1) .subscribe(r -> { System.out.println(\"Received message: \" + r); (2) r.receiverOffset().acknowledge(); (3) });\n\n1 Concatenate in order 2 Print out each consumer record received 3 Explicit ack for each message\n\nSame as the KafkaReceiver#receiveAutoAck method, the maximum number of records in each batch can be controlled using the KafkaConsumer property MAX_POLL_RECORDS. This is used together with the fetch size and wait times configured on the KafkaConsumer to control the amount of data fetched from Kafka brokers in each poll. But unlike the KafkaReceiver#receiveAutoAck, each batch is returned as a Flux that should be acknowledged or committed using ReceiverOffset.\n\nAs the KafkaReceiver#receive method messages, each message in the batch is represented as a ReceiverRecord which has a committable ReceiverOffset instance.\n\nKafkaReceiver#receiveBatch combines the batch consumption mode of KafkaReceiver#receiveAutoAck with the manual acknowledgement/commit mode of KafkaReceiver#receive. This batching mode is efficient and is easy to use for at-least-once delivery of messages.\n\n5.3.8. Disabling automatic commits\n\nApplications which donâ€™t require offset commits to Kafka may disable automatic commits by not acknowledging any records consumed using KafkaReceiver#receive().\n\nreceiverOptions = ReceiverOptions.<Integer, String>create() .commitInterval(Duration.ZERO) (1) .commitBatchSize(0); (2) KafkaReceiver.create(receiverOptions) .receive() .subscribe(r -> process(r)); (3)\n\n1 Disable periodic commits 2 Disable commits based on batch size 3 Process records, but donâ€™t acknowledge\n\n5.3.9. At-most-once delivery\n\nApplications may disable automatic commits to avoid re-delivery of records. ConsumerConfig#AUTO_OFFSET_RESET_CONFIG can be configured to \"latest\" to consume only new records. But this could mean that an unpredictable number of records are not consumed if an application fails and restarts.\n\nKafkaReceiver#receiveAtmostOnce can be used to consume records with at-most-once semantics with a configurable number of records-per-partition that may be lost if the application fails or crashes. Offsets are committed synchronously before the corresponding record is dispatched. Records are guaranteed not to be re-delivered even if the consuming application fails, but some records may not be processed if an application fails after the commit before the records could be processed.\n\nThis mode is expensive since each record is committed individually and records are not delivered until the commit operation succeeds. ReceiverOptions#atmostOnceCommitCommitAheadSize may be configured to reduce the cost of commits and avoid blocking before dispatch if the offset of the record has already been committed. By default, commit-ahead is disabled and at-most one record is lost per-partition if an application crashes. If commit-ahead is configured, the maximum number of records that may be lost per-partition is ReceiverOptions#atmostOnceCommitCommitAheadSize + 1.\n\nKafkaReceiver.create(receiverOptions) .receiveAtmostOnce() .subscribe(r -> System.out.println(\"Received: \" + r)); (1)\n\n1 Process each consumer record, this record is not re-delivered if the processing fails\n\n5.3.10. Partition assignment and revocation listeners\n\nApplications can enable assignment and revocation listeners to perform any actions when partitions are assigned or revoked from a consumer.\n\nWhen group management is used, assignment listeners are invoked whenever partitions are assigned to the consumer after a rebalance operation. When manual assignment is used, assignment listeners are invoked when the consumer is started. Assignment listeners can be used to seek to particular offsets in the assigned partitions so that messages are consumed from the specified offset. When a user pauses topics/partitions before rebalancing, the behavior depends on the value of pauseAllAfterRebalance. If it is set to false, the paused topics/partitions will remain paused after the rebalance. However, if it is set to true, all assigned topics/partitions will be paused after the rebalance.\n\nWhen group management is used, revocation listeners are invoked whenever partitions are revoked from a consumer after a rebalance operation. When manual assignment is used, revocation listeners are invoked before the consumer is closed. Revocation listeners can be used to commit processed offsets when manual commits are used. Acknowledged offsets are automatically committed on revocation if automatic commits are enabled.\n\n5.3.11. Controlling start offsets for consuming records\n\nBy default, receivers start consuming records from the last committed offset of each assigned partition. If a committed offset is not available, the offset reset strategy ConsumerConfig#AUTO_OFFSET_RESET_CONFIG configured for the KafkaConsumer is used to set the start offset to the earliest or latest offset on the partition. Applications can override offsets by seeking to new offsets in an assignment listener. Methods are provided on ReceiverPartition to seek to the earliest, latest, a specific offset in the partition, or to a record with a timestamp later than a point in time.\n\nvoid seekToBeginning(); void seekToEnd(); void seek(long offset); void seekToTimestamp(long timestamp);\n\nFor example, the following code block starts consuming messages from the latest offset.\n\nreceiverOptions = receiverOptions .addAssignListener(partitions -> partitions.forEach(p -> p.seekToEnd())) (1) .subscription(Collections.singleton(topic)); KafkaReceiver.create(receiverOptions).receive().subscribe();\n\n1 Seek to the last offset in each assigned partition\n\nOther methods are available on ReceiverPartition to determine the current position, the beginning offset, and ending offset, at the time the partition is assigned.\n\nlong position(); Long beginningOffset(); Long endOffset();\n\n5.3.12. Consumer lifecycle\n\nEach KafkaReceiver instance is associated with a KafkaConsumer that is created when the inbound Flux returned by one of the receive methods in KafkaReceiver is subscribed to. The consumer is kept alive until the Flux completes. When the Flux completes, all acknowledged offsets are committed and the underlying consumer is closed.\n\nOnly one receive operation may be active in a KafkaReceiver at any one time. Any of the receive methods can be invoked after the receive Flux corresponding to the last receive is terminated."
    }
}