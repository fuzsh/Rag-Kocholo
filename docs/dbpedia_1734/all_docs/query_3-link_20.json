{
    "id": "dbpedia_1734_3",
    "rank": 20,
    "data": {
        "url": "https://aws.amazon.com/msk/faqs/",
        "read_more_link": "",
        "language": "en",
        "title": "Fully Managed Apache Kafka – Amazon MSK FAQs – Amazon Web Services",
        "top_image": "https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png",
        "meta_img": "https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png",
        "images": [
            "https://d1.awsstatic.com/webteam/product-pages/Product-Page_Standard-Icons_01_Product-Features_SqInk.a8d5666758afc5121b4eb818ae18126031c4b61e.png",
            "https://d1.awsstatic.com/webteam/product-pages/Next-Steps-Icon_User-guide.24c016304c2e2b01024d8f0a103ba4f61c1e6fc9.png",
            "https://d1.awsstatic.com/webteam/product-pages/Product-Page_Standard-Icons_03_Start-Building_SqInk.6a1ef4429a6604cda9b0857084aa13e2ee4eebca.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Find answers to frequently asked questions for Amazon MSK, a fully managed service that makes it easy to build and run Apache Kafka to ingest and process streaming data in real time.",
        "meta_lang": "en",
        "meta_favicon": "https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico",
        "meta_site_name": "Amazon Web Services, Inc.",
        "canonical_link": "https://aws.amazon.com/msk/faqs/",
        "text": "Q: What is MSK Serverless?\n\nMSK Serverless is a cluster type for Amazon MSK that makes it easy for you to run Apache Kafka clusters without having to manage compute and storage capacity. With MSK Serverless, you can run your applications without having to provision, configure, or optimize clusters, and you pay for the data volume you stream and retain.\n\nQ: Does MSK Serverless automatically balance partitions within a cluster?\n\nYes. MSK Serverless fully manages partitions, including monitoring and moving them to even load across a cluster.\n\nQ: How much data throughput capacity does MSK Serverless support?\n\nMSK Serverless provides up to 200 MBps of write capacity and 400 MBps of read capacity per cluster. Additionally, to ensure sufficient throughput availability for all partitions in a cluster, MSK Serverless allocates up to 5 MBps of instant write capacity and 10 MBps of instant read capacity per partition.\n\nQ: What security features does MSK Serverless offer?\n\nMSK Serverless encrypts all traffic in transit and all data at rest using service-managed keys issued through AWS Key Management Service (KMS). Clients connect to MSK Serverless over a private connection using AWS PrivateLink without exposing your traffic to the public internet. Additionally, MSK Serverless offers IAM Access Control, which you can use to manage client authentication and client authorization to Apache Kafka resources such as topics.\n\nQ: How can producers and consumers access my MSK Serverless clusters?\n\nWhen you create a MSK Serverless cluster, you provide subnets of one or more Amazon Virtual Private Clouds (VPCs) that host the clients of the cluster. Clients hosted in any of these VPCs will be able to connect to the MSK Serverless cluster using its broker bootstrap string.\n\nQ: Which regions is MSK Serverless available in?\n\nPlease refer to the MSK pricing page for up-to-date regional availability.\n\nQ: Which authentication types does MSK Serverless support?\n\nMSK Serverless currently supports AWS IAM for client authentication and authorization. Your clients can assume an AWS IAM role for authentication, and you can enforce access control using an associated IAM policy.\n\nQ: How do I process data in my MSK Serverless cluster?\n\nYou can use any Apache Kafka compatible tools to process data in your MSK Serverless cluster topics. MSK Serverless integrates with Amazon Managed Service for Apache Flink for stateful stream processing and AWS Lambda for event processing. You can also use Kafka Connect sink connectors to send data to any desired destination.\n\nQ: How does MSK Serverless ensure high availability?\n\nWhen you create a partition, MSK Serverless creates 2 replicas of it and places them in different availability zones. Additionally, MSK serverless automatically detects and recovers failed backend resources to maintain high availability.\n\nQ: Does Amazon MSK run in an Amazon VPC?\n\nYes, Amazon MSK always runs within an Amazon VPC managed by the Amazon MSK service. Amazon MSK resources will be available to your own Amazon VPC, subnet, and security group you select when the cluster is setup. IP addresses from your VPC are attached to your Amazon MSK resources through elastic network interfaces (ENIs), and all network traffic stays within the AWS network and is not accessible to the internet by default.\n\nQ: How will the brokers in my Amazon MSK cluster be made accessible to clients within my VPC?\n\nThe brokers in your cluster will be made accessible to clients in your VPC through ENIs appearing in your account. The Security Groups on the ENIs will dictate the source and type of ingress and egress traffic allowed on your brokers.\n\nQ: Is it possible to connect to my cluster over the public Internet?\n\nYes, Amazon MSK offers an option to securely connect to the brokers of Amazon MSK clusters running Apache Kafka 2.6.0 or later versions over the internet. By enabling public access, authorized clients external to a private Amazon Virtual Private Cloud (VPC) can stream encrypted data in and out of specific Amazon MSK clusters. You can enable public access for MSK clusters after a cluster has been created at no additional cost, but standard AWS data transfer costs for cluster ingress and egress apply. To learn more about turning on public access, see the public access documentation.\n\nQ: Is the connection between my clients and an Amazon MSK cluster private?\n\nBy default, the only way data can be produced and consumed from an Amazon MSK cluster is over a private connection between your clients in your VPC and the Amazon MSK cluster. However, if you turn on public access for your Amazon MSK cluster and connect to your MSK cluster using the public bootstrap-brokers string, the connection, though authenticated, authorized and encrypted, is no longer considered private. We recommend that you configure the cluster's security groups to have inbound TCP rules that allow public access from your trusted IP address and make these rules as restrictive as possible if you turn on public access.\n\nQ: How do I control cluster authentication and Apache Kafka API authorization?\n\nFor serverless clusters, you can use IAM Access Control for both authentication and authorization. For provisioned clusters, you have three options: 1) AWS Identity and Access Management (IAM) Access Control for both AuthN/Z (recommended), 2) TLS certificate authentication (CA) for AuthN and access control lists for AuthZ, and 3) SASL/SCRAM for AuthN and access control lists for AuthZ. Amazon MSK recommends using IAM Access Control. It is the easiest to use and, because it defaults to least privilege access, the most secure option.\n\nQ: How does authorization work in Amazon MSK?\n\nIf you are using IAM Access Control, Amazon MSK uses the policies you write and its own authorizer to authorize actions. If you are using TLS certificate authentication or SASL/SCRAM, Apache Kafka uses access control lists (ACLs) for authorization. To enable ACLs you must enable client authentication using either TLS certificates or SASL/SCRAM.\n\nQ: How can I authenticate and authorize a client at the same time?\n\nIf you are using IAM Access Control, Amazon MSK will authenticate and authorize for you without any additional set up. If you are using TLS authentication, you can use the Dname of clients TLS certificates as the principal of the ACL to authorize client requests. If you are using SASL/SCRAM, you can use the username as the principal of the ACL to authorize client requests.\n\nQ: How do I control service API actions?\n\nYou can control service API actions using AWS Identity and Access Management (IAM).\n\nQ: Can I enable IAM Access Control for an existing cluster?\n\nYes, you can enable IAM Access Control for an existing cluster from the AWS console or by using the UpdateSecurity API.\n\nQ: Can I use IAM Access Control outside of Amazon MSK?\n\nNo, IAM Access Control is only available for Amazon MSK clusters.\n\nQ: How do I provide cross-account access permissions to a Kafka client in an AWS account different from Amazon MSK’s to connect privately to my Amazon MSK cluster?\n\nYou can attach a cluster policy to your Amazon MSK cluster to provide your cross-account Kafka client permissions to set up private connectivity to your Amazon MSK cluster. When using IAM client authentication, you can also use the cluster policy to granularly define the Kafka data plane permissions for the connecting client. To learn more about cluster policies, see the cluster policy documentation.\n\nQ: What is Amazon MSK Replicator?\n\nAmazon MSK Replicator is a feature of Amazon MSK that enables customers to reliably replicate data across Amazon MSK clusters in different AWS regions (cross-region replication) or within the same AWS region (same-region replication), without writing code or managing infrastructure. You can use cross-region replication (CRR) to build highly available and fault-tolerant multi-region streaming applications for increased resiliency. You can also CRR to provide lower latency access to consumers in different geographic regions. You can use SRR to distribute data from one cluster to many clusters for sharing data with your partners and teams. You can also use SRR to aggregate data from multiple clusters into one for analytics.\n\nQ: How do I use MSK Replicator?\n\nTo setup replication between a pair of source and target MSK clusters, you need to create a Replicator in the destination AWS region. To create a Replicator, you specify details that include the Amazon Resource Name (ARN) of the source and target MSK clusters and an AWS Identity and Access Management (IAM) role that MSK Replicator can use to access the clusters. You will need to create the target MSK cluster if it does not already exist.\n\nQ: Which type of Kafka clusters are supported by MSK Replicator?\n\nMSK Replicator supports replication across MSK clusters only. Both Provisioned and Serverless type of MSK clusters are supported. You can also use MSK Replicator to move from Provisioned to Serverless or vice-versa. Other Kafka clusters are not supported.\n\nQ: Can I specify which topics I want to replicate?\n\nYes, you can specify which topics you want to replicate using allow and deny lists while creating the Replicator.\n\nQ: Does MSK Replicator replicate topic settings and consumer group offsets?\n\nYes. MSK Replicator automatically replicates the necessary Kafka metadata like topic configuration, Access Control Lists (ACLs), and consumer group offsets so that consuming applications can resume processing seamlessly after failover. You can choose to turn off one or more of these settings if you only want to replicate the data. You can also specify which consumer groups you want to replicate using allow or deny lists while creating the Replicator.\n\nQ: Do I need to scale the replication when my ingress throughput changes?\n\nNo, MSK Replicator automatically deploys, provisions and scales the underlying replication infrastructure to support changes in your ingress throughput.\n\nQ: Can I replicate data across MSK clusters in different AWS accountS?\n\nNo, MSK Replicator only supports replication across MSK clusters in the same AWS account.\n\nQ: How can I monitor the replication?\n\nYou can use Amazon CloudWatch in the destination region to view metrics for “ReplicationLatency,\n\nMessageLag, and ReplicatorThroughput” at a topic and aggregate level for each Replicator at no additional charge. Metrics would be visible under ReplicatorName in “AWS/Kafka” namespace. You can also see the “ReplicatorFailure, AuthError and ThrottleTime” metrics to check if your Replicator is running into any issues.\n\nQ: How can I use replication to increase the resiliency of my streaming application across regions?\n\nYou can use MSK Replicator to setup active-active or active-passive cluster topologies to increase resiliency of your Kafka application across regions. In an active-active setup, both MSK clusters are actively serving reads and writes. Comparatively, in an active-passive setup only one MSK cluster at a time is actively serving streaming data, while the other cluster is on standby.\n\nQ: Can I use MSK Replicator to replicate data from one cluster to multiple clusters or replicate data from many clusters to one?\n\nYes. You simply need to create a different Replicator for each source and target cluster pair.\n\nQ: How does MSK Replicator connect to the source and target MSK clusters?\n\nMSK Replicator uses IAM Access Control to connect to your source and target clusters. You need to turn on your source and target MSK clusters for IAM Access Control for creating a Replicator. You can continue to use other authentication methods including SASL/SCRAM and mTLS at the same time for your clients since Amazon MSK supports multiple authentication methods simultaneously.\n\nQ: How much replication latency should I expect with MSK Replicator?\n\nMSK Replicator replicates data asynchronously. Replication latency varies based on many factors including the network distance between the AWS regions of your MSK clusters, your source and target clusters’ throughput capacity and the number of partitions on your source and target clusters\n\nQ: Can I keep topic names same with MSK Replicator?\n\nNo, MSK Replicator creates new topics in the target cluster with an auto-generated prefix added to the topic name. For instance, MSK Replicator will replicate data in “topic” from the source cluster to a new topic in target cluster called “<sourceKafkaClusterAlias>.topic”. MSK Replicator does this to distinguish topics that contain data replicated from source cluster from other topics in the target cluster and avoid data being circularly replicated between the clusters. You can find the prefix that will be added to the topic names in the target cluster under “sourceKafkaClusterAlias“ field using DescribeReplicator API or the Replicator details page on the MSK Console.\n\nQ: Can I replicate existing data on the source cluster?\n\nYes. By default, when you create a new Replicator, it starts replicating data from the tip of the stream (latest offset) on the source cluster. Alternatively, if you want to replicate existing data, you can configure a new Replicator to start replicating data from the earliest offset in the source cluster topic partitions.\n\nQ: Can replication result in throttling consumers on the source cluster?\n\nSince MSK Replicator acts as a consumer for your source cluster, it is possible that replication causes other consumers to be throttled on your source cluster. This depends on how much read capacity you have on your source cluster and throughput of the data you are replicating. We recommend that your provision identical capacity for your source and target clusters and account for the replication throughput while calculating how much capacity you need. You can also set Kafka quotas for the Replicator on your source and target clusters to control how much capacity the Replicator can use.\n\nQ: Can I compress data before writing to the target cluster?\n\nYes, you can specify your choice of compression codec while creating the Replicator amongst None, GZIP, Snappy, LZ4 and ZSTD."
    }
}