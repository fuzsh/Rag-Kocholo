{
    "id": "dbpedia_7392_3",
    "rank": 8,
    "data": {
        "url": "https://stanfordmag.org/contents/keeping-secrets",
        "read_more_link": "",
        "language": "en",
        "title": "Keeping Secrets",
        "top_image": "https://project-orion-production.s3.amazonaws.com/uploads/content/14114/feature_ND14_Cryptography_Opr_Medium4.jpg",
        "meta_img": "https://project-orion-production.s3.amazonaws.com/uploads/content/14114/feature_ND14_Cryptography_Opr_Medium4.jpg",
        "images": [
            "https://stanfordmag.org/packs/media/images/tailwind/alumni-logo-ccd2876ccb76125286bf75d59645d5d7.png",
            "https://stanfordmag.org/packs/media/images/StanfordMagazineDigitalLogo-Blk-Red-RGB-b9343de6ab2800ab825b5907a1c3dfe4.svg",
            "https://stanfordmag.org/packs/media/images/tailwind/mag_glass-337b36ab9737e1c1408a3219be7ce2ca.png",
            "https://stanfordmag.org/packs/media/images/tailwind/alumni-logo-ccd2876ccb76125286bf75d59645d5d7.png",
            "https://stanfordmag.org/packs/media/images/StanfordMagazineDigitalLogo-Blk-Red-RGB-b9343de6ab2800ab825b5907a1c3dfe4.svg",
            "https://stanfordmag.org/packs/media/images/tailwind/ham-menu-c6af6ca8ae4e3c596628b8b5c5abbfae.png",
            "https://stanfordmag.org/packs/media/images/tailwind/logo-white-4fb124b10603c3fab79c77ce201fd4d7.png",
            "https://stanfordmag.org/packs/media/images/tailwind/close-icon-white-f8fc8a1028d6ec984018b4b459889f2f.png",
            "https://stanfordmag.org/packs/media/images/tailwind/search-icon-2-d9dbc9fd2d7598ffa66528e0713cbbd8.png",
            "https://stanfordmag.org/packs/media/images/tailwind/down-arrow-18db0208cf9fc45d0df08fe228678f17.png",
            "https://stanfordmag.org/packs/media/images/tailwind/up-arrow-86b7c666149c1113ea1256a7adfc54a3.png",
            "https://stanfordmag.org/packs/media/images/tailwind/down-arrow-18db0208cf9fc45d0df08fe228678f17.png",
            "https://stanfordmag.org/packs/media/images/tailwind/up-arrow-86b7c666149c1113ea1256a7adfc54a3.png",
            "https://project-orion-production.s3.amazonaws.com/uploads/content/14114/ND14_Cryptography_Opr_Medium4.jpg",
            "https://d28fxxt57nf3uz.cloudfront.net/uploads/content_picture/2557/ND14_Cryptography_photo_QG_225px.jpg",
            "https://d28fxxt57nf3uz.cloudfront.net/uploads/content_picture/581/ND14_Crypto_Spot-Final_700px.jpg",
            "https://stanfordmag.org/packs/media/images/tailwind/logo-white-4fb124b10603c3fab79c77ce201fd4d7.png",
            "https://stanfordmag.org/packs/media/images/tailwind/alumni-logo-ccd2876ccb76125286bf75d59645d5d7.png",
            "https://stanfordmag.org/packs/media/images/tailwind/right-icon-16f40b9ed8d129585c17c2d8aceef0ed.png",
            "https://stanfordmag.org/packs/media/images/tailwind/right-icon-16f40b9ed8d129585c17c2d8aceef0ed.png",
            "https://stanfordmag.org/packs/media/images/tailwind/right-icon-16f40b9ed8d129585c17c2d8aceef0ed.png",
            "https://stanfordmag.org/packs/media/images/tailwind/right-icon-16f40b9ed8d129585c17c2d8aceef0ed.png",
            "https://stanfordmag.org/packs/media/images/tailwind/right-icon-16f40b9ed8d129585c17c2d8aceef0ed.png",
            "https://stanfordmag.org/packs/media/images/tailwind/right-icon-16f40b9ed8d129585c17c2d8aceef0ed.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "STANFORD magazine"
        ],
        "publish_date": "2014-11-01T00:00:00",
        "summary": "",
        "meta_description": "Four decades ago, university researchers figured out the key to computer privacy, sparking a battle with the National Security Agency that continues today.",
        "meta_lang": "en",
        "meta_favicon": "/packs/media/images/favicon-893e94720235aa87bb04006d499f4bc7.png",
        "meta_site_name": "",
        "canonical_link": "https://stanfordmag.org/contents/keeping-secrets",
        "text": "The International Symposium on Information Theory is not known for its racy content or politically charged presentations, but the session at Cornell University on October 10, 1977, was a special case. In addition to talks with titles like \"Distribution-Free Inequalities for the Deleted and Holdout Error Estimates,\" the conference featured the work of a group from Stanford that had drawn the ire of the National Security Agency and the attention of the national press. The researchers in question were Martin Hellman, then an associate professor of electrical engineering, and his students Steve Pohlig, MS '75, PhD '78, and Ralph Merkle, PhD '79.\n\nA year earlier, Hellman had published \"New Directions in Cryptography\" with his student Whitfield Diffie, Gr. '78. The paper introduced the principles that now form the basis for all modern cryptography, and its publication rightfully caused a stir among electrical engineers and computer scientists. As Hellman recalled in a 2004 oral history, the nonmilitary community's reaction to the paper was \"ecstatic.\" In contrast, the \"NSA was apoplectic.\"\n\nThe fact that Hellman and his students were challenging the U.S. government's longstanding domestic monopoly on cryptography deeply annoyed many in the intelligence community. The NSA acknowledged that Diffie and Hellman had come up with their ideas without access to classified materials. Even so, in the words of an internal NSA history declassified in 2009 and now held in the Stanford Archives, \"NSA regarded the [Diffie-Hellman] technique as classified. Now it was out in the open.\"\n\nThe tension between Hellman and the NSA only worsened in the months leading up to the 1977 symposium. In July, someone named J. A. Meyer sent a shrill letter to the Institute of Electrical and Electronics Engineers, which had published Hellman's papers and was holding the conference. It began:\n\n\"I have noticed in the past months that various IEEE Groups have been publishing and exporting technical articles on encryption and cryptology—a technical field which is covered by Federal Regulations, viz: ITAR (International Traffic in Arms Regulations, 22 CFR 121-128).\"\n\nMeyer's letter asserted that the IEEE and the authors of the relevant papers might be subject to prosecution under federal laws prohibiting arms trafficking, communication of atomic secrets and disclosure of classified information.\n\nWithout naming Hellman or his co-authors, Meyer specified the issues of IEEE's Transactions on Information Theory journal and Computer magazine in which Hellman's articles appeared. Meyer concluded ominously that \"these modern weapons technologies, uncontrollably disseminated, could have more than academic effect.\"\n\nMeyer's letter alarmed many in the academic community and drew coverage by Science and the New York Times for two main reasons. First, the letter suggested that merely publishing a scientific paper on cryptography would be the legal equivalent of exporting nuclear weapons to a foreign country. If Meyer's interpretation of the law was correct, it seemed to place severe restrictions on researchers' freedom to publish. Second, Deborah Shapley and Gina Kolata of Science magazine discovered that Meyer was an NSA employee.\n\nAs soon as Hellman received a copy of the letter, he recognized that continuing to publish might put him and his students in legal jeopardy, so he sought advice from Stanford University counsel John Schwartz.\n\nIn his memo to Schwartz, Hellman made a lucid case for the value of public-domain cryptography research. Astutely, Hellman first acknowledged that the U.S. government's tight control over cryptographic techniques proved enormously useful in World War II: Allied forces used confidential cryptographic discoveries to improve their own encryption systems while denying those same cryptographic benefits to Axis powers. Even so, Hellman argued that circumstances had changed.\n\n\"[T]here is a commercial need today that did not exist in the 1940's. The growing use of automated information processing equipment poses a real economic and privacy threat. Although it is a remote possibility, the danger of initially inadvertent police state type surveillance through computerization must be considered. From that point of view, inadequate commercial cryptography (which our publications are trying to avoid) poses an internal national security threat.\"\n\nIn the memo, Hellman described how his earlier attempts to prevent \"stepping on [the] toes\" of the NSA failed when the agency's staffers would not even disclose which areas of cryptography research Hellman should avoid.\n\nResponding to Hellman a few days later, Schwartz opined that publishing cryptography research would not in itself violate federal law. His findings had a strong legal basis: Two regulations governed classified information in the United States at the time—an executive order and the Atomic Energy Act of 1954—and neither seemed to prevent the publication of unclassified research on cryptography.\n\nThere was only one other likely legal tool that the federal government could use to prevent the Stanford group from disseminating their work: the Arms Export Control Act of 1976, which regulated the export of military equipment. Under a generous interpretation of the law, giving a public presentation on cryptographic algorithms could constitute \"export\" of arms. It was not clear, however, that a prosecution under this act would stand up to a legal challenge on First Amendment grounds.\n\nEvaluating these laws together, Schwartz concluded that Hellman and his students could legally continue to publish. At the same time, Schwartz noted wryly, \"at least one contrary view [of the law] exists\"—that of Joseph A. Meyer. Hellman later recalled Schwartz's less-than-comforting informal advice: \"If you are prosecuted, Stanford will defend you. But if you're found guilty, we can't pay your fine and we can't go to jail for you.\"\n\nThe Cornell symposium was to begin three days after Schwartz offered his legal opinion; Hellman, Merkle and Pohlig had to quickly decide whether to proceed with their presentations in spite of the threat of prosecution, fines and jail time. Graduate students typically present their own research at academic conferences, but according to Hellman, Schwartz recommended against it in this case. Since the students were not employees of Stanford, it might be more difficult for the university to justify paying their legal bills. Schwartz also reasoned that dealing with a lengthy court case would be harder for a young PhD student than for a tenured faculty member. Hellman left the decision up to the students.\n\nAccording to Hellman, Merkle and Pohlig at first said, \"We need to give the papers, the hell with this.\" After speaking with their families, though, the students agreed to let Hellman present on their behalf.\n\nIn the end, the symposium took place without incident. Merkle and Pohlig stood on stage while Hellman gave the presentation. The fact that the conference went ahead as planned, Science observed, \"left little doubt that the work [in cryptography] has been widely circulated.\" That a group of nongovernmental researchers could publicly discuss cutting-edge cryptographic algorithms signaled the end of the U.S. government's domestic control of information on cryptography.\n\nThe View from Fort Meade\n\nVice Adm. Bobby Ray Inman took over as director of the NSA in the summer of 1977. Inman was an experienced naval intelligence officer with allies in both political parties. If his qualifications for the job were good, his timing was not. He had barely warmed his desk chair when he was thrust into the center of what he recently described as \"a huge media uproar\" over the J. A. Meyer letter—written the very first day of Inman's tenure.\n\nIn the tradition of intelligence professionals, Inman set out to gather some information for himself. He went to California to meet with faculty members and industry leaders at Berkeley, Stanford and elsewhere. Inman quickly discovered that the researchers at Stanford were designing cryptographic systems to solve an emerging problem that was not yet on the NSA's radar: securing the growing number of commercial computer systems, which were subject to attack or compromise. The researchers' position, Inman said, was that \"there's a whole new world emerging out there where there's going to need to be cryptography, and it's not going to be provided by the government.\"\n\nMartin Hellman recently recounted their conversation in similar terms: \"I was working on cryptography from an unclassified point of view because I could see—even in the mid-'70s—the growing marriage of computers and communication and the need therefore for unclassified knowledge of cryptography.\" Inman realized that the California academics saw strong public cryptographic systems as a crucial piece of a functioning technological environment.\n\nStill, Inman was not excited about the prospect of high-grade encryption systems being available for purchase, especially abroad. \"We were worried that foreign countries would pick up and use cryptography that would make it exceedingly hard to decrypt and read their traffic.\"\n\nThe level of public excitement surrounding the recent cryptography work made growth in the field of unclassified cryptography almost inevitable. In August 1977, Scientific American had published a description of the new RSA cryptosystem devised by Ron Rivest, Adi Shamir and Leonard Adleman of MIT. According to Steven Levy's 2001 book Crypto, the researchers offered a copy of a technical report describing the scheme to anyone who would send a self-addressed stamped envelope to MIT. The authors received 7,000 requests.\n\nTo reckon with the growing threat of unclassified cryptography, Inman convened an internal NSA panel for advice. As recounted in the declassified NSA history, the panel gave Inman three stark choices for how to control the publication of cryptography research:\n\n(a) Do nothing\n\n(b) Seek new legislation to impose additional government controls\n\n(c) Try non-legislative means such as voluntary commercial and academic compliance.\n\nThe panel concluded that the damage was already so serious that something needed to be done.\n\nNSA documents and Hellman's recollection both suggest that Inman first tried to get a law drafted to restrict cryptographic research, along the lines of the Atomic Energy Act. For political reasons, the NSA history says, Inman's proposed bill was \"dead on arrival.\"\n\n\"Congress [wanted to] unshackle U.S. commerce from any sort of Pentagon-imposed restriction on trade,\" the history ruefully recounts, and the Carter administration \"wanted to loosen Pentagon control of anything, especially anything that might affect individual rights and academic freedom.\"\n\nEven if Inman could get a bill through Congress, Hellman said, the First Amendment would make it difficult to prevent researchers from speaking publicly about their work. If they didn't publish their papers, \"they'll give 100 talks before they submit it for publication.\"\n\nAs a sort of last-ditch effort at compromise, Inman organized a voluntary system of prepublication review for cryptography research papers. A number of other scientific journals have attempted a similar system in recent years. \"That's really the best anyone has been able to come up with,\" said Steven Aftergood of the Federation of American Scientists, an expert on government secrecy.\n\nThe review process was used for a decade, but Inman recalled that it eventually \"fell apart\" because of \"the explosion of . . . uses\" for cryptography. As the world underwent a digital revolution, there was an accompanying \"revolution in cryptography,\" just as Diffie and Hellman had predicted in 1976.\n\nAftermath\n\nIt is tempting to view the outcome of the conflict between the Stanford researchers and the NSA as an unequivocal victory for freedom of speech and the beginning of the democratization of the tools of cryptography. There is a grain of truth in this characterization, but it misses the larger effect the run-in had on the academic cryptography community and on the NSA.\n\nHellman and other academic researchers realized they could win the debate, as long as it took place in public. Newspapers and scientific journals found it much easier to sympathize with a group of quirky and passionate academics than with a shadowy and stern-faced intelligence agency. The issue of First Amendment rights, Hellman recalled in 2004, also gave the press and the researchers a common cause. \"With the freedom of publication issue, the press was all on our side. There were editorials in the New York Times and a number of other publications. Science, I remember, had covered our work and was very helpful.\"\n\nFrom the other side, NSA officials realized they would have a difficult time getting public support to suppress publication of what they considered dangerous research results. They turned instead to two aspects of nongovernmental cryptography over which they had near-total control: research funding and national standards.\n\nAs of 2012, the federal government provided 60 percent of U.S. academic research and development funding. By choosing which projects to fund, grant-giving government agencies influence what research takes place.\n\nEven before the 1977 Symposium on Information Theory, the NSA reviewed National Science Foundation grant applications that might be relevant to signals intelligence or communications security. The purported reason for these reviews was for the NSA to advise the NSF on the proposals' \"technical merits,\" but the agency appeared to use this process to exercise control over nongovernmental cryptography research.\n\nFor instance, the NSA reviewed and approved an NSF grant application from Ron Rivest. Later, Rivest used the funds to develop the enormously influential RSA cryptosystem, which secures most encrypted Internet traffic today. An internal NSA history suggests that the agency would have tried to derail Rivest's grant application if the reviewers had understood what Rivest would do with the money. The NSA missed this opportunity, the history complains, because the wording of Rivest's proposal \"was so general that the Agency did not spot the threat\" posed by the project.\n\nIn 1979, Leonard Adleman (another member of the RSA triumvirate) applied to the NSF for funding and had his application forwarded to the NSA. According to Whitfield Diffie and Susan Landau's 2007 book, Privacy on the Line, the NSA offered to fund the research in lieu of the NSF. Fearing that his work would end up classified, Adleman protested and eventually received an NSF grant.\n\nEven though the NSF appears to have maintained some level of independence from NSA influence, the agency likely has had greater control over other federal funding sources. In particular, the Department of Defense funds research through the Defense Advanced Research Projects Agency (DARPA), the Office of Naval Research, the Army Research Office and other offices. After the run-in with the academic community in the late 1970s, the NSA history asserts that Vice Adm. Inman \"secure[d] a commitment\" that the Office of Naval Research would coordinate its grants with the NSA. Since funding agencies often need not explain why they have rejected a particular grant proposal, it is hard to judge the NSA's effect on the grant-making process."
    }
}