{
    "id": "dbpedia_6208_1",
    "rank": 21,
    "data": {
        "url": "https://dl.acm.org/doi/10.1145/3491102.3517719",
        "read_more_link": "",
        "language": "en",
        "title": "Augmented Reality and Robotics: A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces",
        "top_image": "https://dl.acm.org/cms/asset/728eef81-0b50-41af-8d77-f471fe338928/3491102.cover.jpg",
        "meta_img": "https://dl.acm.org/cms/asset/728eef81-0b50-41af-8d77-f471fe338928/3491102.cover.jpg",
        "images": [
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-dl-logo-white-1ecfb82271e5612e8ca12aa1b1737479.png",
            "https://dl.acm.org/doi/10.1145/specs/products/acm/releasedAssets/images/acm-logo-1-ad466e729c8e2a97780337b76715e5cf.png",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-99659155646&format=rel-imgonly&assetId=profile.jpg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81324491951&format=rel-imgonly&assetId=nic_2022-2.jpeg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/footer-logo1-45ae33115db81394d8bd25be65853b77.png",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/Default_image_lazy-0687af31f0f1c8d4b7a22b686995ab9b.svg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81100505114&format=rel-imgonly&assetId=81100505114.jpg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81311484266&format=rel-imgonly&assetId=id-appert.jpg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81100288295&format=rel-imgonly&assetId=me.jpg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81442606751&format=rel-imgonly&assetId=julie_pic.jpg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81100158260&format=rel-imgonly&assetId=me_202010.jpg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/loader-7e60691fbe777356dc81ff6d223a82a6.gif",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-99659155646&format=rel-imgonly&assetId=profile.jpg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81324491951&format=rel-imgonly&assetId=nic_2022-2.jpeg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-logo-dl-8437178134fce530bc785276fc316cbf.png",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-logo-3-10aed79f3a6c95ddb67053b599f029af.png"
        ],
        "movies": [
            "https://iframe.videodelivery.net/eyJraWQiOiI3YjgzNTg3NDZlNWJmNDM0MjY5YzEwZTYwMDg0ZjViYiIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiI2YTMxMTJjODVlNjYxYTg2Nzk2Y2UwODQ5YzdkMjRlOSIsImV4cCI6MTcyMzgyODcxOCwia2lkIjoiN2I4MzU4NzQ2ZTViZjQzNDI2OWMxMGU2MDA4NGY1YmIifQ.A4qbkD7Q79wSxUI7b333aiXs3B4TBsRXvRjicg93J4LgY4BDAUaYwLCEsm4Ipg5ZTsTZlaR1He9Uws1cgv7jfDhePmo585LX4KmrNN3s8-LYog6kuDZCfxMLa0ALPje2Z9jDwyDq0lvcuPMqvoq63zby_9IiScRgycC-_YM2q5LCvi7trr-TCkpp1qqsr9zV9avgXvCA5hTsIeIeMSIOfqrSYkGTq0jnz5mvrbraCPlXPIz8421Fj3VmC1bjT0nmuRPBVeWJZn-BUbJk_gvJQTie462XgZPZcN8MY75ZiTU7k0ghJ_eXBJx_W2XlszvTD8HBDJ012Gflsfux02p-IQ?poster=https%3A%2F%2Fvideodelivery.net%2FeyJraWQiOiI3YjgzNTg3NDZlNWJmNDM0MjY5YzEwZTYwMDg0ZjViYiIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiI2YTMxMTJjODVlNjYxYTg2Nzk2Y2UwODQ5YzdkMjRlOSIsImV4cCI6MTcyMzgyODcxOCwia2lkIjoiN2I4MzU4NzQ2ZTViZjQzNDI2OWMxMGU2MDA4NGY1YmIifQ.A4qbkD7Q79wSxUI7b333aiXs3B4TBsRXvRjicg93J4LgY4BDAUaYwLCEsm4Ipg5ZTsTZlaR1He9Uws1cgv7jfDhePmo585LX4KmrNN3s8-LYog6kuDZCfxMLa0ALPje2Z9jDwyDq0lvcuPMqvoq63zby_9IiScRgycC-_YM2q5LCvi7trr-TCkpp1qqsr9zV9avgXvCA5hTsIeIeMSIOfqrSYkGTq0jnz5mvrbraCPlXPIz8421Fj3VmC1bjT0nmuRPBVeWJZn-BUbJk_gvJQTie462XgZPZcN8MY75ZiTU7k0ghJ_eXBJx_W2XlszvTD8HBDJ012Gflsfux02p-IQ%2Fthumbnails%2Fthumbnail.jpg%3Ftime%3D10.0s"
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Canada View Profile",
            "Adnan Karim Computer Science",
            "University of Calgary",
            "United States",
            "University of Colorado Boulder",
            "USA View Profile",
            "University College London",
            "United Kingdom",
            "Microsoft Research",
            "United States View Profile"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/pb-assets/head-metadata/apple-touch-icon-1574252172393.png",
        "meta_site_name": "ACM Conferences",
        "canonical_link": "https://dl.acm.org/doi/10.1145/3491102.3517719",
        "text": "Abstract\n\nThis paper contributes to a taxonomy of augmented reality and robotics based on a survey of 460 research papers. Augmented and mixed reality (AR/MR) have emerged as a new way to enhance human-robot interaction (HRI) and robotic interfaces (e.g., actuated and shape-changing interfaces). Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically. In this paper, we synthesize and categorize this research field in the following dimensions: 1) approaches to augmenting reality; 2) characteristics of robots; 3) purposes and benefits; 4) classification of presented information; 5) design components and strategies for visual augmentation; 6) interaction techniques and modalities; 7) application domains; and 8) evaluation strategies. We formulate key challenges and opportunities to guide and inform future research in AR and robotics.\n\nSupplementary Material\n\nMP4 File (3491102.3517719-talk-video.mp4)\n\nTalk Video\n\nDownload\n\n92.87 MB\n\nReferences\n\n[1]\n\n2014. List of Physical Visualizations and Related Artifacts. Retrieved on January 5, 2022 from http://dataphys.org/list/\n\n[2]\n\n2015. The Mercedes-Benz F 015 luxury in motion. Retrieved on January 5, 2022 from https://www.mercedes-benz.com/en/innovation/autonomous/research-vehicle-f-015-luxury-in-motion/\n\n[3]\n\n2015. Microsoft Hololens Robot Demo at Build 2015. Retrieved on January 5, 2022 from https://www.youtube.com/watch?v=mSCrviBGTeQ\n\n[4]\n\n2016. Boeing: UAVs. Holograms. Wildfire. Retrieved on January 5, 2022 from https://www.youtube.com/watch?v=omGoz66xHU8\n\n[5]\n\n2017. Personal Fabrication Research in HCI and Graphics: An Overview of Related Work. Retrieved on January 5, 2022 from https://hcie.csail.mit.edu/fabpub/\n\n[6]\n\n2018. MorphUI. Retrieved on January 5, 2022 from http://morphui.com/\n\n[7]\n\n2019. Jaguar land rover lights up the road ahead for self-driving vehicles of the future. Retrieved on January 5, 2022 from https://media.jaguarlandrover.com/news/2019/01/jaguar-land-rover-lights-road-ahead-self-driving-vehicles-future\n\n[8]\n\n2020. Nintendo Mario Kart Live: Home Circuit. Retrieved on January 5, 2022 from https://mklive.nintendo.com/\n\n[9]\n\nSyed Mohsin Abbas, Syed Hassan, and Jongwon Yun. 2012. Augmented reality based teaching pendant for industrial robot. In 2012 12th International Conference on Control, Automation and Systems. IEEE, 2210–2213.\n\n[10]\n\nJong-gil Ahn, Gerard J Kim, Hyemin Yeon, Eunja Hyun, and Kyoung Choi. 2013. Supporting augmented reality based children’s play with pro-cam robot: three user perspectives. In Proceedings of the 12th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. 17–24. https://doi.org/10.1145/2534329.2534342\n\n[11]\n\nYuya Aikawa, Masayoshi Kanoh, Felix Jimenez, Mitsuhiro Hayase, Takahiro Tanaka, and Hitoshi Kanamori. 2018. Comparison of gesture inputs for robot system using mixed reality to encourage driving review. In 2018 Joint 10th International Conference on Soft Computing and Intelligent Systems (SCIS) and 19th International Symposium on Advanced Intelligent Systems (ISIS). IEEE, 62–66. https://doi.org/10.1109/scis-isis.2018.00020\n\n[12]\n\nBatu Akan, Afshin Ameri, Baran Cürüklü, and Lars Asplund. 2011. Intuitive industrial robot programming through incremental multimodal language and augmented reality. In 2011 IEEE International Conference on Robotics and Automation. IEEE, 3934–3939. https://doi.org/10.1109/icra.2011.5979887\n\n[13]\n\nTakintope Akinbiyi, Carol E Reiley, Sunipa Saha, Darius Burschka, Christopher J Hasser, David D Yuh, and Allison M Okamura. 2006. Dynamic augmented reality for sensory substitution in robot-assisted surgical systems. In 2006 International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE, 567–570. https://doi.org/10.1109/iembs.2006.259707\n\n[14]\n\nSamer Al Moubayed, Jonas Beskow, Gabriel Skantze, and Björn Granström. 2012. Furhat: a back-projected human-like robot head for multiparty human-machine interaction. In Cognitive behavioural systems. Springer, 114–130. https://doi.org/10.1007/978-3-642-34584-5_9\n\n[15]\n\nJacopo Aleotti, Giorgio Micconi, Stefano Caselli, Giacomo Benassi, Nicola Zambelli, Manuele Bettelli, and Andrea Zappettini. 2017. Detection of nuclear sources by UAV teleoperation using a visuo-haptic augmented reality interface. Sensors 17, 10 (2017), 2234. https://doi.org/10.3390/s17102234\n\n[16]\n\nJason Alexander, Anne Roudaut, Jürgen Steimle, Kasper Hornbæk, Miguel Bruns Alonso, Sean Follmer, and Timothy Merritt. 2018. Grand challenges in shape-changing interface research. In Proceedings of the 2018 CHI conference on human factors in computing systems. 1–14. https://doi.org/10.1145/3173574.3173873\n\n[17]\n\nOmri Alon, Sharon Rabinovich, Chana Fyodorov, and Jessica R Cauchard. 2021. Drones in Firefighting: A User-Centered Design Perspective. In Proceedings of the 23rd International Conference on Mobile Human-Computer Interaction. 1–11. https://doi.org/10.1145/3447526.3472030\n\n[18]\n\nMalek Alrashidi, Ahmed Alzahrani, Michael Gardner, and Vic Callaghan. 2016. A pedagogical virtual machine for assembling mobile robot using augmented reality. In Proceedings of the 7th Augmented Human International Conference 2016. 1–2. https://doi.org/10.1145/2875194.2875229\n\n[19]\n\nMalek Alrashidi, Michael Gardner, and Vic Callaghan. 2017. Evaluating the use of pedagogical virtual machine with augmented reality to support learning embedded computing activity. In Proceedings of the 9th International Conference on Computer and Automation Engineering. 44–50. https://doi.org/10.1145/3057039.3057088\n\n[20]\n\nAlborz Amir-Khalili, Masoud S Nosrati, Jean-Marc Peyrat, Ghassan Hamarneh, and Rafeef Abugharbieh. 2013. Uncertainty-encoded augmented reality for robot-assisted partial nephrectomy: A phantom study. In Augmented Reality Environments for Medical Imaging and Computer-Assisted Interventions. Springer, 182–191. https://doi.org/10.1007/978-3-642-40843-4_20\n\n[21]\n\nRasmus S Andersen, Ole Madsen, Thomas B Moeslund, and Heni Ben Amor. 2016. Projecting robot intentions into human environments. In 2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, 294–301. https://doi.org/10.1109/ROMAN.2016.7745145\n\n[22]\n\nSean Andrist, Tomislav Pejsa, Bilge Mutlu, and Michael Gleicher. 2012. Designing effective gaze mechanisms for virtual agents. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 705–714. https://doi.org/10.1145/2207676.2207777\n\n[23]\n\nTakafumi Aoki, Takashi Matsushita, Yuichiro Iio, Hironori Mitake, Takashi Toyama, Shoichi Hasegawa, Rikiya Ayukawa, Hiroshi Ichikawa, Makoto Sato, Takatsugu Kuriyama, 2005. Kobito: virtual brownies. In ACM SIGGRAPH 2005 emerging technologies. 11–es. https://doi.org/10.1145/1187297.1187309\n\n[24]\n\nDejanira Araiza-Illan, Alberto De San Bernabe, Fang Hongchao, and Leong Yong Shin. 2019. Augmented reality for quick and intuitive robotic packing re-programming. In 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 664–664. https://doi.org/10.1109/hri.2019.8673327\n\n[25]\n\nStephanie Arévalo Arboleda, Tim Dierks, Franziska Rücker, and Jens Gerken. 2020. There’s More than Meets the Eye: Enhancing Robot Control through Augmented Visual Cues. In Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction. 104–106. https://doi.org/10.1145/3371382.3378240\n\n[26]\n\nStephanie Arévalo Arboleda, Tim Dierks, Franziska Rücker, and Jens Gerken. 2021. Exploring the Visual Space to Improve Depth Perception in Robot Teleoperation Using Augmented Reality: The Role of Distance and Target’s Pose in Time, Success, and Certainty. In IFIP Conference on Human-Computer Interaction. Springer, 522–543. https://doi.org/10.1007/978-3-030-85623-6_31\n\n[27]\n\nStephanie Arevalo Arboleda, Franziska Rücker, Tim Dierks, and Jens Gerken. 2021. Assisting Manipulation and Grasping in Robot Teleoperation with Augmented Reality Visual Cues. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1–14. https://doi.org/10.1145/3411764.3445398\n\n[28]\n\nMichael Argyle and Mark Cook. 1976. Gaze and mutual gaze.(1976). https://doi.org/10.1017/S0007125000073980\n\n[29]\n\nPasquale Arpaia, Carmela Bravaccio, Giuseppina Corrado, Luigi Duraccio, Nicola Moccaldi, and Silvia Rossi. 2020. Robotic Autism Rehabilitation by Wearable Brain-Computer Interface and Augmented Reality. In 2020 IEEE International Symposium on Medical Measurements and Applications (MeMeA). IEEE, 1–6. https://doi.org/10.1109/MeMeA49120.2020.9137144\n\n[30]\n\nDoris Aschenbrenner, Jonas SI Rieder, Daniëlle Van Tol, Joris Van Dam, Zoltan Rusak, Jan Olaf Blech, Mohammad Azangoo, Salo Panu, Karl Kruusamäe, Houman Masnavi, 2020. Mirrorlabs-creating accessible Digital Twins of robotic production environment with Mixed Reality. In 2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR). IEEE, 43–48. https://doi.org/10.1109/aivr50618.2020.00017\n\n[31]\n\nDoris Aschenbrenner, Michael Rojkov, Florian Leutert, Jouke Verlinden, Stephan Lukosch, Marc Erich Latoschik, and Klaus Schilling. 2018. Comparing different augmented reality support applications for cooperative repair of an industrial robot. In 2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). IEEE, 69–74. https://doi.org/10.1109/ismar-adjunct.2018.00036\n\n[32]\n\nRonald T Azuma. 1997. A survey of augmented reality. Presence: teleoperators & virtual environments 6, 4(1997), 355–385. https://doi.org/10.1162/pres.1997.6.4.355\n\n[33]\n\nDaniel Bambuŝek, Zdeněk Materna, Michal Kapinus, Vítězslav Beran, and Pavel Smrž. 2019. Combining interactive spatial augmented reality with head-mounted display for end-user collaborative robot programming. In 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). IEEE, 1–8. https://doi.org/10.1109/RO-MAN46459.2019.8956315\n\n[34]\n\nKim Baraka, Ana Paiva, and Manuela Veloso. 2016. Expressive lights for revealing mobile service robot state. In Robot 2015: Second Iberian Robotics Conference. Springer, 107–119. https://doi.org/10.1007/978-3-319-27146-0_9\n\n[35]\n\nZoltán Bárdosi, Christian Plattner, Yusuf Özbek, Thomas Hofmann, Srdjan Milosavljevic, Volker Schartinger, and Wolfgang Freysinger. 2020. CIGuide: in situ augmented reality laser guidance. International journal of computer assisted radiology and surgery 15, 1(2020), 49–57. https://doi.org/10.1007/s11548-019-02066-1\n\n[36]\n\nPatrick Baudisch, Stefanie Mueller, 2017. Personal fabrication. Foundations and Trends® in Human–Computer Interaction 10, 3–4(2017), 165–293. https://doi.org/10.1561/1100000055\n\n[37]\n\nPhilipp Beckerle, Claudio Castellini, and Bigna Lenggenhager. 2019. Robotic interfaces for cognitive psychology and embodiment research: a research roadmap. Wiley Interdisciplinary Reviews: Cognitive Science 10, 2 (2019), e1486. https://doi.org/10.1002/wcs.1486\n\n[38]\n\nWilliam Bentz, Sahib Dhanjal, and Dimitra Panagou. 2019. Unsupervised learning of assistive camera views by an aerial co-robot in augmented reality multitasking environments. In 2019 International Conference on Robotics and Automation (ICRA). IEEE, 3003–3009. https://doi.org/10.1109/icra.2019.8793587\n\n[39]\n\nLorenzo Bianchi, Francesco Chessa, Andrea Angiolini, Laura Cercenelli, Simone Lodi, Barbara Bortolani, Enrico Molinaroli, Carlo Casablanca, Matteo Droghetti, Caterina Gaudiano, 2021. The use of augmented reality to guide the intraoperative frozen section during robot-assisted radical prostatectomy. European Urology 80, 4 (2021), 480–488. https://doi.org/10.1016/j.eururo.2021.06.020\n\n[40]\n\nMark Billinghurst and Michael Nebeling. 2021. Rapid prototyping for XR. In SIGGRAPH Asia 2021 Courses. 1–178. https://doi.org/10.1145/3476117.3483444\n\n[41]\n\nOliver Bimber and Ramesh Raskar. 2006. Modern approaches to augmented reality. In ACM SIGGRAPH 2006 Courses. 1–es. https://doi.org/10.1145/1185657.1185796\n\n[42]\n\nSebastian Blankemeyer, Rolf Wiemann, Lukas Posniak, Christoph Pregizer, and Annika Raatz. 2018. Intuitive robot programming using augmented reality. Procedia CIRP 76(2018), 155–160. https://doi.org/10.1016/J.PROCIR.2018.02.028\n\n[43]\n\nAndrew Boateng and Yu Zhang. 2021. Virtual Shadow Rendering for Maintaining Situation Awareness in Proximal Human-Robot Teaming. In Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction. 494–498. https://doi.org/10.1145/3434074.3447221\n\n[44]\n\nGabriele Bolano, Christian Juelg, Arne Roennau, and Ruediger Dillmann. 2019. Transparent robot behavior using augmented reality in close human-robot interaction. In 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). IEEE, 1–7. https://doi.org/10.1109/ro-man46459.2019.8956296\n\n[45]\n\nGabriele Bolano, Arne Roennau, and Ruediger Dillmann. 2020. Planning and Evaluation of Robotic Solutions in a Logistic Line Through Augmented Reality. In 2020 Fourth IEEE International Conference on Robotic Computing (IRC). IEEE, 422–423. https://doi.org/10.1109/irc.2020.00075\n\n[46]\n\nJean Botev and Francisco J Rodríguez Lera. 2021. Immersive Robotic Telepresence for Remote Educational Scenarios. Sustainability 13, 9 (2021), 4717. https://doi.org/10.3390/SU13094717\n\n[47]\n\nGustavo Caiza, Pablo Bonilla-Vasconez, Carlos A Garcia, and Marcelo V Garcia. 2020. Augmented Reality for Robot Control in Low-cost Automation Context and IoT. In 2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA), Vol. 1. IEEE, 1461–1464. https://doi.org/10.1109/etfa46521.2020.9212056\n\n[48]\n\nDavide Calandra, Alberto Cannavò, and Fabrizio Lamberti. 2021. Evaluating an Augmented Reality-Based Partially Assisted Approach to Remote Assistance in Heterogeneous Robotic Applications. In 2021 IEEE 7th International Conference on Virtual Reality (ICVR). IEEE, 380–387. https://doi.org/10.1109/icvr51878.2021.9483849\n\n[49]\n\nDaniel Calife, João Luiz Bernardes Jr, and Romero Tori. 2009. Robot Arena: An augmented reality platform for game development. Computers in Entertainment (CIE) 7, 1 (2009), 1–26. https://doi.org/10.1145/1486508.1486519\n\n[50]\n\nLaura Cancedda, Alberto Cannavò, Giuseppe Garofalo, Fabrizio Lamberti, Paolo Montuschi, and Gianluca Paravati. 2017. Mixed reality-based user interaction feedback for a hand-controlled interface targeted to robot teleoperation. In International Conference on Augmented Reality, Virtual Reality and Computer Graphics. Springer, 447–463. https://doi.org/10.1007/978-3-319-60928-7_38\n\n[51]\n\nYuanzhi Cao, Tianyi Wang, Xun Qian, Pawan S Rao, Manav Wadhawan, Ke Huo, and Karthik Ramani. 2019. GhostAR: A time-space editor for embodied authoring of human-robot collaborative task with augmented reality. In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology. 521–534. https://doi.org/10.1145/3332165.3347902\n\n[52]\n\nYuanzhi Cao, Zhuangying Xu, Terrell Glenn, Ke Huo, and Karthik Ramani. 2018. Ani-Bot: A Modular Robotics System Supporting Creation, Tweaking, and Usage with Mixed-Reality Interactions. In Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction. 419–428. https://doi.org/10.1145/3173225.3173226\n\n[53]\n\nYuanzhi Cao, Zhuangying Xu, Fan Li, Wentao Zhong, Ke Huo, and Karthik Ramani. 2019. V. Ra: An in-situ visual authoring system for robot-IoT task planning with augmented reality. In Proceedings of the 2019 on Designing Interactive Systems Conference. 1059–1070. https://doi.org/10.1145/3322276.3322278\n\n[54]\n\nIrvin Steve Cardenas, Kaleb Powlison, and Jong-Hoon Kim. 2021. Reducing Cognitive Workload in Telepresence Lunar-Martian Environments Through Audiovisual Feedback in Augmented Reality. In Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction. 463–466. https://doi.org/10.1145/3434074.3447214\n\n[55]\n\nJon Carroll and Fabrizio Polo. 2013. Augmented reality gaming with sphero. In ACM Siggraph 2013 Mobile. 1–1. https://doi.org/10.1145/2503512.2503535\n\n[56]\n\nGiandomenico Caruso and Paolo Belluco. 2010. Robotic arm for car dashboard layout assessment in mixed reality environment. In 19th International Symposium in Robot and Human Interactive Communication. IEEE, 62–68. https://doi.org/10.1109/ROMAN.2010.5598685\n\n[57]\n\nJessica Cauchard, Woody Gover, William Chen, Stephen Cartwright, and Ehud Sharlin. 2021. Drones in Wonderland–Disentangling Collocated Interaction Using Radical Form. IEEE Robotics and Automation Letters(2021). https://doi.org/10.1109/lra.2021.3103653\n\n[58]\n\nJessica R Cauchard, Alex Tamkin, Cheng Yao Wang, Luke Vink, Michelle Park, Tommy Fang, and James A Landay. 2019. Drone. io: A gestural and visual interface for human-drone interaction. In 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 153–162. https://doi.org/10.1109/HRI.2019.8673011\n\n[59]\n\nElizabeth Cha, Naomi T Fitter, Yunkyung Kim, Terrence Fong, and Maja J Matarić. 2018. Effects of Robot Sound on Auditory Localization in Human-Robot Collaboration. In Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction. ACM, 434–442. https://doi.org/10.1145/3171221.3171285\n\n[60]\n\nElizabeth Cha and Maja Matarić. 2016. Using nonverbal signals to request help during human-robot collaboration. In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 5070–5076. https://doi.org/10.1109/IROS.2016.7759744\n\n[61]\n\nSonia Mary Chacko, Armando Granado, and Vikram Kapila. 2020. An augmented reality framework for robotic tool-path teaching. Procedia CIRP 93(2020), 1218–1223. https://doi.org/10.1016/j.procir.2020.03.143\n\n[62]\n\nSonia Mary Chacko, Armando Granado, Ashwin RajKumar, and Vikram Kapila. 2020. An Augmented Reality Spatial Referencing System for Mobile Robots. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 4446–4452. https://doi.org/10.1109/iros45743.2020.9340742\n\n[63]\n\nSonia Mary Chacko and Vikram Kapila. 2019. An augmented reality interface for human-robot interaction in unconstrained environments. In 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 3222–3228. https://doi.org/10.1109/iros40897.2019.8967973\n\n[64]\n\nRavi Teja Chadalavada, Henrik Andreasson, Maike Schindler, Rainer Palm, and Achim J Lilienthal. 2020. Bi-directional navigation intent communication using spatial augmented reality and eye-tracking glasses for improved safety in human–robot interaction. Robotics and Computer-Integrated Manufacturing 61 (2020), 101830. https://doi.org/10.1016/j.rcim.2019.101830\n\n[65]\n\nSeungho Chae, Hyocheol Ro, Yoonsik Yang, and Tack-Don Han. 2018. A Pervasive Assistive Robot System Including Projection-Camera Technology for Older Adults. In Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction. 83–84. https://doi.org/10.1145/3173386.3177007\n\n[66]\n\nTathagata Chakraborti, Sarath Sreedharan, Anagha Kulkarni, and Subbarao Kambhampati. 2018. Projection-aware task planning and execution for human-in-the-loop operation of robots in a mixed-reality workspace. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 4476–4482. https://doi.org/10.1109/IROS.2018.8593830\n\n[67]\n\nWesley P Chan, Geoffrey Hanks, Maram Sakr, Tiger Zuo, HF Machiel Van der Loos, and Elizabeth Croft. 2020. An augmented reality human-robot physical collaboration interface design for shared, large-scale, labour-intensive manufacturing tasks. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 11308–11313. https://doi.org/10.1109/IROS45743.2020.9341119\n\n[68]\n\nWesley P Chan, Adnan Karim, Camilo P Quintero, HF Machiel Van der Loos, and Elizabeth Croft. 2018. Virtual barriers in augmented reality for safe human-robot collaboration in manufacturing. In Robotic Co-Workers 4.0 2018: Human Safety and Comfort in Human-Robot Interactive Social Environments.\n\n[69]\n\nWesley P Chan, Maram Sakr, Camilo Perez Quintero, Elizabeth Croft, and HF Machiel Van der Loos. 2020. Towards a Multimodal System combining Augmented Reality and Electromyography for Robot Trajectory Programming and Execution. In 2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). IEEE, 419–424. https://doi.org/10.1109/RO-MAN47096.2020.9223526\n\n[70]\n\nTom Chandler, Maxime Cordeil, Tobias Czauderna, Tim Dwyer, Jaroslaw Glowacki, Cagatay Goncu, Matthias Klapperstueck, Karsten Klein, Kim Marriott, Falk Schreiber, 2015. Immersive analytics. In 2015 Big Data Visual Analytics (BDVA). IEEE, 1–8. https://doi.org/10.1109/TVCG.2019.2929033\n\n[71]\n\nChih-Wei Chang, Jih-Hsien Lee, Chin-Yeh Wang, and Gwo-Dong Chen. 2010. Improving the authentic learning experience by integrating robots into the mixed-reality environment. Computers & Education 55, 4 (2010), 1572–1578. https://doi.org/10.1016/j.compedu.2010.06.023\n\n[72]\n\nSiam Charoenseang and Tarinee Tonggoed. 2011. Human–robot collaboration with augmented reality. In International Conference on Human-Computer Interaction. Springer, 93–97. https://doi.org/10.1007/978-3-642-22095-1_19\n\n[73]\n\nHua Chen, Oliver Wulf, and Bernardo Wagner. 2006. Object detection for a mobile robot using mixed reality. In International Conference on Virtual Systems and Multimedia. Springer, 466–475. https://doi.org/10.1007/11890881_51\n\n[74]\n\nIan Yen-Hung Chen, Bruce MacDonald, Burkhard Wünsche, Geoffrey Biggs, and Tetsuo Kotoku. 2010. Analysing mixed reality simulation for industrial applications: A case study in the development of a robotic screw remover system. In International Conference on Simulation, Modeling, and Programming for Autonomous Robots. Springer, 350–361. https://doi.org/10.1007/978-3-642-17319-6_33\n\n[75]\n\nLinfeng Chen, Akiyuki Ebi, Kazuki Takashima, Kazuyuki Fujita, and Yoshifumi Kitamura. 2019. PinpointFly: An egocentric position-pointing drone interface using mobile AR. In SIGGRAPH Asia 2019 Emerging Technologies. 34–35. https://doi.org/10.1145/3355049.3360534\n\n[76]\n\nLinfeng Chen, Kazuki Takashima, Kazuyuki Fujita, and Yoshifumi Kitamura. 2021. PinpointFly: An Egocentric Position-control Drone Interface using Mobile AR. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1–13. https://doi.org/10.1145/3411764.3445110\n\n[77]\n\nLong Chen, Fengfeng Zhang, Wei Zhan, Minfeng Gan, and Lining Sun. 2020. Optimization of virtual and real registration technology based on augmented reality in a surgical navigation system. Biomedical engineering online 19, 1 (2020), 1–28. https://doi.org/10.1186/s12938-019-0745-z\n\n[78]\n\nMingxuan Chen, Ping Zhang, Zebo Wu, and Xiaodan Chen. 2020. A multichannel human-swarm robot interaction system in augmented reality. Virtual Reality & Intelligent Hardware 2, 6 (2020), 518–533. https://doi.org/10.1016/j.vrih.2020.05.006\n\n[79]\n\nXiaogang Chen, Xiaoshan Huang, Yijun Wang, and Xiaorong Gao. 2020. Combination of augmented reality based brain-computer interface and computer vision for high-level control of a robotic arm. IEEE Transactions on Neural Systems and Rehabilitation Engineering 28, 12(2020), 3140–3147. https://doi.org/10.1109/tnsre.2020.3038209\n\n[80]\n\nZhe Chen, Zhuohang Cao, Peili Ma, and Lijun Xu. 2020. Industrial Robot Training Platform Based on Virtual Reality and Mixed Reality Technology. In International Conference on Man-Machine-Environment System Engineering. Springer, 891–898. https://doi.org/10.1007/978-981-15-6978-4_102\n\n[81]\n\nVijay Chidambaram, Yueh-Hsuan Chiang, and Bilge Mutlu. 2012. Designing persuasive robots: how robots might persuade people using vocal and nonverbal cues. In Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Interaction. 293–300. https://doi.org/10.1145/2157689.2157798\n\n[82]\n\nSeung Wook Choi, Hee Chan Kim, Heung Sik Kang, Seongjun Kim, and Jaesoon Choi. 2013. A haptic augmented reality surgeon console for a laparoscopic surgery robot system. In 2013 13th International Conference on Control, Automation and Systems (ICCAS 2013). IEEE, 355–357. https://doi.org/10.1109/iccas.2013.6703923\n\n[83]\n\nJonathan Wun Shiung Chong, SKc Ong, Andrew YC Nee, and KB Youcef-Youmi. 2009. Robot programming using augmented reality: An interactive method for planning collision-free paths. Robotics and Computer-Integrated Manufacturing 25, 3(2009), 689–701. https://doi.org/10.1016/J.RCIM.2008.05.002\n\n[84]\n\nWusheng Chou, Tianmiao Wang, and Yuru Zhang. 2004. Augmented reality based preoperative planning for robot assisted tele-neurosurgery. In 2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No. 04CH37583), Vol. 3. IEEE, 2901–2906. https://doi.org/10.1109/icsmc.2004.1400773\n\n[85]\n\nNicklas H Christensen, Oliver G Hjermitslev, Frederik Falk, Marco B Madsen, Frederik H Østergaard, Martin Kibsgaard, Martin Kraus, Johan Poulsen, and Jane Petersson. 2017. Depth cues in augmented reality for training of robot-assisted minimally invasive surgery. In Proceedings of the 21st International Academic Mindtrek Conference. 120–126. https://doi.org/10.1145/3131085.3131123\n\n[86]\n\nFrancesco Clemente, Strahinja Dosen, Luca Lonini, Marko Markovic, Dario Farina, and Christian Cipriani. 2016. Humans can integrate augmented reality feedback in their sensorimotor control of a robotic hand. IEEE Transactions on Human-Machine Systems 47, 4 (2016), 583–589. https://doi.org/10.1109/thms.2016.2611998\n\n[87]\n\nMarcelo Coelho and Jamie Zigelbaum. 2011. Shape-changing interfaces. Personal and Ubiquitous Computing 15, 2 (2011), 161–173. https://doi.org/10.1007/s00779-010-0311-y\n\n[88]\n\nMichael D Coovert, Tiffany Lee, Ivan Shindev, and Yu Sun. 2014. Spatial augmented reality as a method for a mobile robot to communicate intended movement. Computers in Human Behavior 34 (2014), 241–248. https://doi.org/10.1016/j.chb.2014.02.001\n\n[89]\n\nAustin Corotan and Jianna Jian Zhang Irgen-Gioro. 2019. An Indoor Navigation Robot Using Augmented Reality. In 2019 5th International Conference on Control, Automation and Robotics (ICCAR). IEEE, 111–116. https://doi.org/10.1109/iccar.2019.8813348\n\n[90]\n\nHugo Costa, Peter Cebola, Tiago Cunha, and Armando Sousa. 2015. A mixed reality game using 3Pi robots—“PiTanks”. In 2015 10th Iberian Conference on Information Systems and Technologies (CISTI). IEEE, 1–6. https://doi.org/10.1109/CISTI.2015.7170600\n\n[91]\n\nNuno Costa and Artur Arsenio. 2015. Augmented reality behind the wheel-human interactive assistance by mobile robots. In 2015 6th International Conference on Automation, Robotics and Applications (ICARA). IEEE, 63–69. https://doi.org/10.1109/ICARA.2015.7081126\n\n[92]\n\nÈve Coste-Manière, Louaï Adhami, Fabien Mourgues, and Alain Carpentier. 2003. Planning, simulation, and augmented reality for robotic cardiac procedures: the STARS system of the ChIR team. In Seminars in thoracic and cardiovascular surgery, Vol. 15. Elsevier, 141–156. https://doi.org/10.1016/S1043-0679(03)70022-7\n\n[93]\n\nMatthew Cousins, Chenguang Yang, Junshen Chen, Wei He, and Zhaojie Ju. 2017. Development of a mixed reality based interface for human robot interaciotn. In 2017 International Conference on Machine Learning and Cybernetics (ICMLC), Vol. 1. IEEE, 27–34. https://doi.org/10.1109/icmlc.2017.8107738\n\n[94]\n\nOscar Danielsson, Anna Syberfeldt, Rodney Brewster, and Lihui Wang. 2017. Assessing instructions in augmented reality for human-robot collaborative assembly by using demonstrators. Procedia CIRP 63(2017), 89–94. https://doi.org/10.1016/J.PROCIR.2017.02.038\n\n[95]\n\nKurtis Danyluk, Barrett Ens, Bernhard Jenny, and Wesley Willett. 2021. A Design Space Exploration of Worlds in Miniature. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems(CHI ’21). Association for Computing Machinery, 1–15. https://doi.org/10.1145/3411764.3445098\n\n[96]\n\nRajkumar Darbar, Joan Sol Roo, Thibault Lainé, and Martin Hachet. 2019. DroneSAR: extending physical spaces in spatial augmented reality using projection on a drone. In Proceedings of the 18th International Conference on Mobile and Ubiquitous Multimedia. 1–7. https://doi.org/10.1145/3365610.3365631\n\n[97]\n\nDevleena Das, Siddhartha Banerjee, and Sonia Chernova. 2021. Explainable ai for robot failures: Generating explanations that improve user assistance in fault recovery. In Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction. 351–360. https://doi.org/10.1145/3434073.3444657\n\n[98]\n\nAlessandro De Franco, Edoardo Lamon, Pietro Balatti, Elena De Momi, and Arash Ajoudani. 2019. An Intuitive augmented reality interface for task scheduling, monitoring, and work performance improvement in human-robot collaboration. In 2019 IEEE International Work Conference on Bioinspired Intelligence (IWOBI). IEEE, 75–80. https://doi.org/10.1109/iwobi47054.2019.9114472\n\n[99]\n\nArtem Dementyev, Hsin-Liu Kao, Inrak Choi, Deborah Ajilo, Maggie Xu, Joseph A Paradiso, Chris Schmandt, and Sean Follmer. 2016. Rovables: Miniature on-body robots as mobile wearables. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology. 111–120. https://doi.org/10.1145/2984511.2984531\n\n[100]\n\nMorteza Dianatfar, Jyrki Latokartano, and Minna Lanz. 2021. Review on existing VR/AR solutions in human–robot collaboration. Procedia CIRP 97(2021), 407–411. https://doi.org/10.1016/j.procir.2020.05.259\n\n[101]\n\nAdhitha Dias, Hasitha Wellaboda, Yasod Rasanka, Menusha Munasinghe, Ranga Rodrigo, and Peshala Jayasekara. 2020. Deep Learning of Augmented Reality based Human Interactions for Automating a Robot Team. In 2020 6th International Conference on Control, Automation and Robotics (ICCAR). IEEE, 175–182. https://doi.org/10.1109/iccar49639.2020.9108004\n\n[102]\n\nTiago Dias, Pedro Miraldo, Nuno Gonçalves, and Pedro U Lima. 2015. Augmented reality on robot navigation using non-central catadioptric cameras. In 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 4999–5004. https://doi.org/10.1109/iros.2015.7354080\n\n[103]\n\nMaximilian Diehl, Alexander Plopski, Hirokazu Kato, and Karinne Ramirez-Amaro. 2020. Augmented Reality interface to verify Robot Learning. In 2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). IEEE, 378–383. https://doi.org/10.1109/ro-man47096.2020.9223502\n\n[104]\n\nAndré Dietrich, Michael Schulze, Sebastian Zug, and Jörg Kaiser. 2010. Visualization of robot’s awareness and perception. In Proceedings of the First International Workshop on Digital Engineering. 38–44. https://doi.org/10.1145/1837154.1837160\n\n[105]\n\nHuy Dinh, Quilong Yuan, Iastrebov Vietcheslav, and Gerald Seet. 2017. Augmented reality interface for taping robot. In 2017 18th International Conference on Advanced Robotics (ICAR). IEEE, 275–280. https://doi.org/10.1109/ICAR.2017.8023530\n\n[106]\n\nAnca D Dragan, Kenton CT Lee, and Siddhartha S Srinivasa. 2013. Legibility and predictability of robot motion. In 2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 301–308. https://doi.org/10.1109/HRI.2013.6483603\n\n[107]\n\nMauro Dragone, Thomas Holz, and Gregory MP O’Hare. 2006. Mixing robotic realities. In Proceedings of the 11th international conference on Intelligent user interfaces. 261–263. https://doi.org/10.1145/1111449.1111504\n\n[108]\n\nMauro Dragone, Thomas Holz, and Gregory MP O’Hare. 2007. Using mixed reality agents as social interfaces for robots. In RO-MAN 2007-The 16th IEEE International Symposium on Robot and Human Interactive Communication. IEEE, 1161–1166. https://doi.org/10.1109/roman.2007.4415255\n\n[109]\n\nMauro Dragone, Thomas Holz, GMP O’Hare, and Michael J O’Grady. 2009. Mixed Reality Agent (MiRA) Chameleons. In Agent-Based Ubiquitous Computing. Springer, 13–33. https://doi.org/10.2991/978-94-91216-31-2_2\n\n[110]\n\nPhilip Edgcumbe, Rohit Singla, Philip Pratt, Caitlin Schneider, Christopher Nguan, and Robert Rohling. 2016. Augmented reality imaging for robot-assisted partial nephrectomy surgery. In International Conference on Medical Imaging and Augmented Reality. Springer, 139–150. https://doi.org/10.1007/978-3-319-43775-0_13\n\n[111]\n\nLotfi El Hafi, Hitoshi Nakamura, Akira Taniguchi, Yoshinobu Hagiwara, and Tadahiro Taniguchi. 2021. Teaching system for multimodal object categorization by human-robot interaction in mixed reality. In 2021 IEEE/SICE International Symposium on System Integration (SII). IEEE, 320–324. https://doi.org/10.1109/IEEECONF49454.2021.9382607\n\n[112]\n\nAhmed Elsharkawy, Khawar Naheem, Dongwoo Koo, and Mun Sang Kim. 2021. A UWB-Driven Self-Actuated Projector Platform for Interactive Augmented Reality Applications. Applied Sciences 11, 6 (2021), 2871. https://doi.org/10.3390/app11062871\n\n[113]\n\nBarrett Ens, Benjamin Bach, Maxime Cordeil, Ulrich Engelke, Marcos Serrano, Wesley Willett, Arnaud Prouzeau, Christoph Anthes, Wolfgang Büschel, Cody Dunne, 2021. Grand challenges in immersive analytics. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems(CHI ’21). Association for Computing Machinery, 1–17. https://doi.org/10.1145/3411764.3446866\n\n[114]\n\nOkan Erat, Werner Alexander Isop, Denis Kalkofen, and Dieter Schmalstieg. 2018. Drone-augmented human vision: Exocentric control for drones exploring hidden areas. IEEE transactions on visualization and computer graphics 24, 4(2018), 1437–1446. https://doi.org/10.1109/TVCG.2018.2794058\n\n[115]\n\nDavid Estevez, Juan G Victores, Santiago Morante, and Carlos Balaguer. 2015. Robot devastation: Using DIY low-cost platforms for multiplayer interaction in an augmented reality game. In 2015 7th International Conference on Intelligent Technologies for Interactive Entertainment (INTETAIN). IEEE, 32–36. https://doi.org/10.4108/icst.intetain.2015.259753\n\n[116]\n\nAluna Everitt and Jason Alexander. 2017. PolySurface: a design approach for rapid prototyping of shape-changing displays using semi-solid surfaces. In Proceedings of the 2017 Conference on Designing Interactive Systems. 1283–1294. https://doi.org/10.1145/3064663.3064677\n\n[117]\n\nAluna Everitt and Jason Alexander. 2019. 3D Printed Deformable Surfaces for Shape-Changing Displays. Frontiers in Robotics and AI 6 (2019), 80. https://doi.org/10.3389/frobt.2019.00080\n\n[118]\n\nA Evlampev and M Ostanin. 2019. Obstacle avoidance for robotic manipulator using Mixed reality glasses. In 2019 3rd School on Dynamics of Complex Networks and their Application in Intellectual Robotics (DCNAIR). IEEE, 46–48. https://doi.org/10.1109/dcnair.2019.8875555\n\n[119]\n\nVolkmar Falk, Fabien Mourgues, Louaï Adhami, Stefan Jacobs, Holger Thiele, Stefan Nitzsche, Friedrich W Mohr, and Ève Coste-Manière. 2005. Cardio navigation: planning, simulation, and augmented reality in robotic assisted endoscopic bypass grafting. The Annals of thoracic surgery 79, 6 (2005), 2040–2047. https://doi.org/10.1016/J.ATHORACSUR.2004.11.060\n\n[120]\n\nHC Fang, SK Ong, and AYC Nee. 2012. Interactive robot trajectory planning and simulation using augmented reality. Robotics and Computer-Integrated Manufacturing 28, 2(2012), 227–237. https://doi.org/10.1016/J.RCIM.2011.09.003\n\n[121]\n\nHC Fang, SK Ong, and AYC Nee. 2012. Robot path and end-effector orientation planning using augmented reality. Procedia CIRP 3(2012), 191–196. https://doi.org/10.1016/J.PROCIR.2012.07.034\n\n[122]\n\nHC Fang, SK Ong, and AYC Nee. 2013. Orientation planning of robot end-effector using augmented reality. The International Journal of Advanced Manufacturing Technology 67, 9-12(2013), 2033–2049. https://doi.org/10.1007/S00170-012-4629-7\n\n[123]\n\nHC Fang, SK Ong, and AYC Nee. 2014. A novel augmented reality-based interface for robot path planning. International Journal on Interactive Design and Manufacturing (IJIDeM) 8, 1(2014), 33–42. https://doi.org/10.1007/S12008-013-0191-2\n\n[124]\n\nHongchao Fang, Soh Khim Ong, and Andrew Yeh-Ching Nee. 2009. Robot programming using augmented reality. In 2009 International Conference on CyberWorlds. IEEE, 13–20. https://doi.org/10.1109/CW.2009.14\n\n[125]\n\nFederica Ferraguti, Marco Minelli, Saverio Farsoni, Stefano Bazzani, Marcello Bonfè, Alexandre Vandanjon, Stefano Puliatti, Giampaolo Bianchi, and Cristian Secchi. 2020. Augmented reality and robotic-assistance for percutaneous nephrolithotomy. IEEE robotics and automation letters 5, 3 (2020), 4556–4563. https://doi.org/10.1109/lra.2020.3002216\n\n[126]\n\nMichael Filipenko, Alexander Poeppel, Alwin Hoffmann, Wolfgang Reif, Andreas Monden, and Markus Sause. 2020. Virtual commissioning with mixed reality for next-generation robot-based mechanical component testing. In ISR 2020; 52th International Symposium on Robotics. VDE, 1–6. https://doi.org/10.14236/EWIC/EVA2008.3\n\n[127]\n\nSean Follmer, Daniel Leithinger, Alex Olwal, Akimitsu Hogge, and Hiroshi Ishii. 2013. inFORM: dynamic physical affordances and constraints through shape and object actuation. In Uist, Vol. 13. 2501988–2502032. https://doi.org/10.1145/2501988.2502032\n\n[128]\n\nJason Fong, Renz Ocampo, Douglas P Gross, and Mahdi Tavakoli. 2019. A robot with an augmented-reality display for functional capacity evaluation and rehabilitation of injured workers. In 2019 IEEE 16th International Conference on Rehabilitation Robotics (ICORR). IEEE, 181–186. https://doi.org/10.1109/icorr.2019.8779417\n\n[129]\n\nJutta Fortmann, Tim Claudius Stratmann, Susanne Boll, Benjamin Poppinga, and Wilko Heuten. 2013. Make me move at work! An ambient light display to increase physical activity. In 2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops. IEEE, 274–277. https://doi.org/10.4108/icst.pervasivehealth.2013.252089\n\n[130]\n\nJared A Frank and Vikram Kapila. 2016. Towards teleoperation-based interactive learning of robot kinematics using a mobile augmented reality interface on a tablet. In 2016 Indian Control Conference (ICC). IEEE, 385–392. https://doi.org/10.1109/indiancc.2016.7441163\n\n[131]\n\nJared Alan Frank, Sai Prasanth Krishnamoorthy, and Vikram Kapila. 2017. Toward mobile mixed-reality interaction with multi-robot systems. IEEE Robotics and Automation Letters 2, 4 (2017), 1901–1908. https://doi.org/10.1109/LRA.2017.2714128\n\n[132]\n\nJared A Frank, Matthew Moorhead, and Vikram Kapila. 2016. Realizing mixed-reality environments with tablets for intuitive human-robot collaboration for object manipulation tasks. In 2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, 302–307. https://doi.org/10.1109/ROMAN.2016.7745146\n\n[133]\n\nJared A Frank, Matthew Moorhead, and Vikram Kapila. 2017. Mobile mixed-reality interfaces that enhance human–robot interaction in shared spaces. Frontiers in Robotics and AI 4 (2017), 20. https://doi.org/10.3389/frobt.2017.00020\n\n[134]\n\nAyaka Fujii, Kanae Kochigami, Shingo Kitagawa, Kei Okada, and Masayuki Inaba. 2020. Development and Evaluation of Mixed Reality Co-eating System: Sharing the Behavior of Eating Food with a Robot Could Improve Our Dining Experience. In 2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). IEEE, 357–362. https://doi.org/10.1109/ro-man47096.2020.9223518\n\n[135]\n\nRichard Fung, Sunao Hashimoto, Masahiko Inami, and Takeo Igarashi. 2011. An augmented reality system for teaching sequential tasks to a household robot. In 2011 RO-MAN. IEEE, 282–287. https://doi.org/10.1109/roman.2011.6005235\n\n[136]\n\nAnna Fuste, Ben Reynolds, James Hobin, and Valentin Heun. 2020. Kinetic AR: A Framework for Robotic Motion Systems in Spatial Computing. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. 1–8. https://doi.org/10.1145/3334480.3382814\n\n[137]\n\nSamir Yitzhak Gadre, Eric Rosen, Gary Chien, Elizabeth Phillips, Stefanie Tellex, and George Konidaris. 2019. End-user robot programming using mixed reality. In 2019 International conference on robotics and automation (ICRA). IEEE, 2707–2713. https://doi.org/10.1109/icra.2019.8793988\n\n[138]\n\nRamsundar Kalpagam Ganesan, Yash K Rathore, Heather M Ross, and Heni Ben Amor. 2018. Better teaming through visual cues: how projecting imagery in a workspace can improve human-robot collaboration. IEEE Robotics & Automation Magazine 25, 2 (2018), 59–71. https://doi.org/10.1109/mra.2018.2815655\n\n[139]\n\nPeng Gao, Brian Reily, Savannah Paul, and Hao Zhang. 2020. Visual reference of ambiguous objects for augmented reality-powered human-robot communication in a shared workspace. In International Conference on Human-Computer Interaction. Springer, 550–561. https://doi.org/10.1007/978-3-030-49695-1_37\n\n[140]\n\nYuxiang Gao and Chien-Ming Huang. 2019. PATI: a projection-based augmented table-top interface for robot programming. In Proceedings of the 24th international conference on intelligent user interfaces. 345–355. https://doi.org/10.1145/3301275.3302326\n\n[141]\n\nYuan Gao, Elena Sibirtseva, Ginevra Castellano, and Danica Kragic. 2019. Fast adaptation with meta-reinforcement learning for trust modelling in human-robot interaction. In 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 305–312. https://doi.org/10.1109/IROS40897.2019.8967924\n\n[142]\n\nAbraham Prieto García, Gervasio Varela Fernández, Blanca María Priego Torres, and Fernando López-Peña. 2011. Educational autonomous robotics setup using mixed reality. In 2011 7th International Conference on Next Generation Web Services Practices. IEEE, 452–457. https://doi.org/10.1109/nwesp.2011.6088222\n\n[143]\n\nAndre Gaschler, Maximilian Springer, Markus Rickert, and Alois Knoll. 2014. Intuitive robot tasks with augmented reality and virtual obstacles. In 2014 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 6026–6031. https://doi.org/10.1109/icra.2014.6907747\n\n[144]\n\nHakan GENÇTÜRK and Uğur YAYAN. 2019. Development of Augmented Reality Based Mobile Robot Maintenance Software. In 2019 Innovations in Intelligent Systems and Applications Conference (ASYU). IEEE, 1–5. https://doi.org/10.1109/asyu48272.2019.8946359\n\n[145]\n\nFabrizio Ghiringhelli, Jérôme Guzzi, Gianni A Di Caro, Vincenzo Caglioti, Luca M Gambardella, and Alessandro Giusti. 2014. Interactive augmented reality for understanding and analyzing multi-robot systems. In 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 1195–1201. https://doi.org/10.1109/iros.2014.6942709\n\n[146]\n\nMario Gianni, Federico Ferri, and Fiora Pirri. 2013. ARE: Augmented reality environment for mobile robots. In Conference Towards Autonomous Robotic Systems. Springer, 470–483. https://doi.org/10.1007/978-3-662-43645-5_48\n\n[147]\n\nFabio Giannone, Emanuele Felli, Zineb Cherkaoui, Pietro Mascagni, and Patrick Pessaux. 2021. Augmented Reality and Image-Guided Robotic Liver Surgery. Cancers 13, 24 (2021), 6268. https://doi.org/10.3390/cancers13246268\n\n[148]\n\nAntonio Gomes, Calvin Rubens, Sean Braley, and Roel Vertegaal. 2016. Bitdrones: Towards using 3d nanocopter displays as interactive self-levitating programmable matter. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. 770–780. https://doi.org/10.1145/2858036.2858519\n\n[149]\n\nLiang Gong, Changyang Gong, Zhao Ma, Lujie Zhao, Zhenyu Wang, Xudong Li, Xiaolong Jing, Haozhe Yang, and Chengliang Liu. 2017. Real-time human-in-the-loop remote control for a life-size traffic police robot with multiple augmented reality aided display terminals. In 2017 2nd International Conference on Advanced Robotics and Mechatronics (ICARM). IEEE, 420–425. https://doi.org/10.1109/icarm.2017.8273199\n\n[150]\n\nLL Gong, SK Ong, and AYC Nee. 2019. Projection-based augmented reality interface for robot grasping tasks. In Proceedings of the 2019 4th International Conference on Robotics, Control and Automation. 100–104. https://doi.org/10.1145/3351180.3351204\n\n[151]\n\nMichael A Goodrich and Alan C Schultz. 2008. Human-robot interaction: a survey. Now Publishers Inc. https://doi.org/10.1561/1100000005\n\n[152]\n\nGregory R Gossweiler, Cameron L Brown, Gihan B Hewage, Eitan Sapiro-Gheiler, William J Trautman, Garrett W Welshofer, and Stephen L Craig. 2015. Mechanochemically active soft robots. ACS applied materials & interfaces 7, 40 (2015), 22431–22435. https://doi.org/10.1021/acsami.5b06440\n\n[153]\n\nMichael Gradmann, Eric M Orendt, Edgar Schmidt, Stephan Schweizer, and Dominik Henrich. 2018. Augmented reality robot operation interface with Google Tango. In ISR 2018; 50th International Symposium on Robotics. VDE, 1–8.\n\n[154]\n\nKeith Evan Green. 2016. Architectural robotics: ecosystems of bits, bytes, and biology. MIT Press.\n\n[155]\n\nScott A Green, Mark Billinghurst, XiaoQi Chen, and J Geoffrey Chase. 2008. Human-robot collaboration: A literature review and augmented reality approach in design. International journal of advanced robotic systems 5, 1 (2008), 1. https://doi.org/10.5772/5664\n\n[156]\n\nScott A Green, Xioa Qi Chen, Mark Billinghurst, and J Geoffrey Chase. 2008. Collaborating with a mobile robot: An augmented reality multimodal interface. IFAC Proceedings Volumes 41, 2 (2008), 15595–15600. https://doi.org/10.3182/20080706-5-KR-1001.02637\n\n[157]\n\nSantiago Grijalva and Wilbert G Aguilar. 2019. Landmark-Based Virtual Path Estimation for Assisted UAV FPV Tele-Operation with Augmented Reality. In International Conference on Intelligent Robotics and Applications. Springer, 688–700. https://doi.org/10.1007/978-3-030-27529-7_58\n\n[158]\n\nThomas Groechel, Zhonghao Shi, Roxanna Pakkar, and Maja J Matarić. 2019. Using socially expressive mixed reality arms for enhancing low-expressivity robots. In 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). IEEE, 1–8. https://doi.org/10.1109/ro-man46459.2019.8956458\n\n[159]\n\nJens Emil Grønbæk, Majken Kirkegaard Rasmussen, Kim Halskov, and Marianne Graves Petersen. 2020. KirigamiTable: Designing for proxemic transitions with a shape-changing tabletop. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1–15. https://doi.org/10.1145/3313831.3376834\n\n[160]\n\nUwe Gruenefeld, Lars Prädel, Jannike Illing, Tim Stratmann, Sandra Drolshagen, and Max Pfingsthorn. 2020. Mind the ARm: realtime visualization of robot motion intent in head-mounted augmented reality. In Proceedings of the Conference on Mensch und Computer. 259–266. https://doi.org/10.1145/3404983.3405509\n\n[161]\n\nJan Guhl, Johannes Hügle, and Jörg Krüger. 2018. Enabling human-robot-interaction via virtual and augmented reality in distributed control systems. Procedia CIRP 76(2018), 167–170. https://doi.org/10.1016/J.PROCIR.2018.01.029\n\n[162]\n\nJan Guhl, Son Tung, and Jörg Kruger. 2017. Concept and architecture for programming industrial robots using augmented reality with mobile devices like microsoft HoloLens. In 2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA). IEEE, 1–4. https://doi.org/10.1109/etfa.2017.8247749\n\n[163]\n\nCheng Guo, James Everett Young, and Ehud Sharlin. 2009. Touch and toys: new techniques for interaction with a remote group of robots. In Proceedings of the SIGCHI conference on human factors in computing systems. 491–500. https://doi.org/10.1145/1518701.1518780\n\n[164]\n\nAkihiro Hamada, Atsuro Sawada, Jin Kono, Masanao Koeda, Katsuhiko Onishi, Takashi Kobayashi, Toshinari Yamasaki, Takahiro Inoue, Hiroshi Noborio, and Osamu Ogawa. 2020. The current status and challenges in augmented-reality navigation system for robot-assisted laparoscopic partial nephrectomy. In International Conference on Human-Computer Interaction. Springer, 620–629. https://doi.org/10.1007/978-3-030-49062-1_42\n\n[165]\n\nJared Hamilton, Thao Phung, Nhan Tran, and Tom Williams. 2021. What’s The Point? Tradeoffs Between Effectiveness and Social Perception When Using Mixed Reality to Enhance Gesturally Limited Robots. In Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction. 177–186. https://doi.org/10.1145/3434073.3444676\n\n[166]\n\nJeonghye Han, Miheon Jo, Eunja Hyun, and Hyo-Jeong So. 2015. Examining young children’s perception toward augmented reality-infused dramatic play. Educational Technology Research and Development 63, 3(2015), 455–474. https://doi.org/10.1007/S11423-015-9374-9\n\n[167]\n\nJohn Hardy, Christian Weichel, Faisal Taher, John Vidler, and Jason Alexander. 2015. Shapeclip: towards rapid prototyping with shape-changing displays for designers. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 19–28. https://doi.org/10.1145/2702123.2702599\n\n[168]\n\nJeremy Hartmann, Yen-Ting Yeh, and Daniel Vogel. 2020. AAR: Augmenting a wearable augmented reality display with an actuated head-mounted projector. In Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology. 445–458. https://doi.org/10.1145/3379337.3415849\n\n[169]\n\nSunao Hashimoto, Akihiko Ishida, Masahiko Inami, and Takeo Igarashi. 2011. Touchme: An augmented reality based remote robot manipulation. In The 21st International Conference on Artificial Reality and Telexistence, Proceedings of ICAT2011, Vol. 2.\n\n[170]\n\nHooman Hedayati, Ryo Suzuki, Daniel Leithinger, and Daniel Szafir. 2020. Pufferbot: Actuated expandable structures for aerial robots. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 1338–1343. https://doi.org/10.1109/iros45743.2020.9341088\n\n[171]\n\nHooman Hedayati, Michael Walker, and Daniel Szafir. 2018. Improving collocated robot teleoperation with augmented reality. In Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction. 78–86. https://doi.org/10.1145/3171221.3171251\n\n[172]\n\nMary Hegarty, Matt S Canham, and Sara I Fabrikant. 2010. Thinking about the weather: How display salience and knowledge affect performance in a graphic inference task.Journal of Experimental Psychology: Learning, Memory, and Cognition 36, 1(2010), 37. https://doi.org/10.1037/a0017683\n\n[173]\n\nViviane Herdel, Anastasia Kuzminykh, Andrea Hildebrandt, and Jessica R Cauchard. 2021. Drone in Love: Emotional Perception of Facial Expressions on Flying Robots. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1–20. https://doi.org/10.1145/3411764.3445495\n\n[174]\n\nJuan David Hernández, Shlok Sobti, Anthony Sciola, Mark Moll, and Lydia E Kavraki. 2020. Increasing robot autonomy via motion planning and an augmented reality interface. IEEE Robotics and Automation Letters 5, 2 (2020), 1017–1023. https://doi.org/10.1109/lra.2020.2967280\n\n[175]\n\nTakayuki Hirai, Satoshi Nakamaru, Yoshihiro Kawahara, and Yasuaki Kakehi. 2018. xslate: A stiffness-controlled surface for shape-changing interfaces. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems. 1–4. https://doi.org/10.1145/3170427.3186496\n\n[176]\n\nTakefumi Hiraki, Shogo Fukushima, Yoshihiro Kawahara, and Takeshi Naemura. 2018. Phygital field: An integrated field with physical robots and digital images using projection-based localization and control method. SICE Journal of Control, Measurement, and System Integration 11, 4(2018), 302–311. https://doi.org/10.9746/jcmsi.11.302\n\n[177]\n\nTakefumi Hiraki, Shogo Fukushima, Yoshihiro Kawahara, and Takeshi Naemura. 2019. NavigaTorch: Projection-based Robot Control Interface using High-speed Handheld Projector. In SIGGRAPH Asia 2019 Emerging Technologies. 31–33. https://doi.org/10.1145/3355049.3360538\n\n[178]\n\nTakefumi Hiraki, Shogo Fukushima, and Takeshi Naemura. 2016. Phygital field: an integrated field with a swarm of physical robots and digital images. In SIGGRAPH ASIA 2016 Emerging Technologies. 1–2. https://doi.org/10.1145/2988240.2988242\n\n[179]\n\nTakefumi Hiraki, Issei Takahashi, Shotaro Goto, Shogo Fukushima, and Takeshi Naemura. 2015. Phygital field: integrated field with visible images and robot swarm controlled by invisible images. In ACM SIGGRAPH 2015 Posters. 1–1. https://doi.org/10.1145/2787626.2792604\n\n[180]\n\nYutaka Hiroi, Shuhei Hisano, and Akinori Ito. 2010. Evaluation of head size of an interactive robot using an augmented reality. In 2010 World Automation Congress. IEEE, 1–6. https://doi.org/10.1109/ro-man46459.2019.8956315\n\n[181]\n\nTzu-Hsuan Ho and Kai-Tai Song. 2020. Supervised control for robot-assisted surgery using augmented reality. In 2020 20th International Conference on Control, Automation and Systems (ICCAS). IEEE, 329–334. https://doi.org/10.23919/ICCAS50221.2020.9268278\n\n[182]\n\nKhoa Cong Hoang, Wesley P Chan, Steven Lay, Akansel Cosgun, and Elizabeth Croft. 2021. Virtual Barriers in Augmented Reality for Safe and Effective Human-Robot Cooperation in Manufacturing. arXiv preprint arXiv:2104.05211(2021).\n\n[183]\n\nAyanna M Howard, Luke Roberts, Sergio Garcia, and Rakale Quarells. 2012. Using mixed reality to map human exercise demonstrations to a robot exercise coach. In 2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEE, 291–292. https://doi.org/10.1109/ismar.2012.6402579\n\n[184]\n\nBaichuan Huang, Deniz Bayazit, Daniel Ullman, Nakul Gopalan, and Stefanie Tellex. 2019. Flight, camera, action! using natural language and mixed reality to control a drone. In 2019 International Conference on Robotics and Automation (ICRA). IEEE, 6949–6956. https://doi.org/10.1109/ICRA.2019.8794200\n\n[185]\n\nBidan Huang, Nicholas Gerard Timmons, and Qiang Li. 2020. Augmented reality with multi-view merging for robot teleoperation. In Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction. 260–262. https://doi.org/10.1145/3371382.3378336\n\n[186]\n\nChien-Ming Huang and Bilge Mutlu. 2013. Modeling and Evaluating Narrative Gestures for Humanlike Robots. In Robotics: Science and Systems. 57–64. https://doi.org/10.15607/RSS.2013.IX.026\n\n[187]\n\nTianqi Huang, Ruiyang Li, Yangxi Li, Xinran Zhang, and Hongen Liao. 2021. Augmented reality-based autostereoscopic surgical visualization system for telesurgery. International Journal of Computer Assisted Radiology and Surgery 16, 11(2021), 1985–1997. https://doi.org/10.1007/s11548-021-02463-5\n\n[188]\n\nDinh Quang Huy, I Vietcheslav, and Gerald Seet Gim Lee. 2017. See-through and spatial augmented reality-a novel framework for human-robot interaction. In 2017 3rd International Conference on Control, Automation and Robotics (ICCAR). IEEE, 719–726. https://doi.org/10.1109/ICCAR.2017.7942791\n\n[189]\n\nJane Hwang, Sangyup Lee, Sang Chul Ahn, and Hyoung-gon Kim. 2008. Augmented robot agent: Enhancing co-presence of the remote participant. In 2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality. IEEE, 161–162. https://doi.org/10.1109/ismar.2008.4637346\n\n[190]\n\nHisham Iqbal, Fabio Tatti, and Ferdinando Rodriguez y Baena. 2021. Augmented reality in robotic assisted orthopaedic surgery: A pilot study. Journal of Biomedical Informatics 120 (2021), 103841. https://doi.org/10.1016/j.jbi.2021.103841\n\n[191]\n\nKentaro Ishii, Shengdong Zhao, Masahiko Inami, Takeo Igarashi, and Michita Imai. 2009. Designing laser gesture interface for robot control. In IFIP Conference on Human-Computer Interaction. Springer, 479–492. https://doi.org/10.1007/978-3-642-03658-3_52\n\n[192]\n\nYvonne Jansen, Pierre Dragicevic, Petra Isenberg, Jason Alexander, Abhijit Karnik, Johan Kildal, Sriram Subramanian, and Kasper Hornbæk. 2015. Opportunities and challenges for data physicalization. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 3227–3236. https://doi.org/10.1145/2702123.2702180\n\n[193]\n\nYunwoo Jeong, Han-Jong Kim, and Tek-Jin Nam. 2018. Mechanism perfboard: An augmented reality environment for linkage mechanism design and fabrication. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. 1–11. https://doi.org/10.1145/3173574.3173985\n\n[194]\n\nZhenrui Ji, Quan Liu, Wenjun Xu, Bitao Yao, Jiayi Liu, and Zude Zhou. 2021. A Closed-Loop Brain-Computer Interface with Augmented Reality Feedback for Industrial Human-Robot Collaboration. (2021). https://doi.org/10.21203/RS.3.RS-283263/V1\n\n[195]\n\nChun Jia and Zhenzhong Liu. 2020. Collision Detection Based on Augmented Reality for Construction Robot. In 2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM). IEEE, 194–197. https://doi.org/10.1109/icarm49381.2020.9195301\n\n[196]\n\nJingang Jiang, Yafeng Guo, Zhiyuan Huang, Yongde Zhang, Dianhao Wu, and Yi Liu. 2021. Adjacent surface trajectory planning of robot-assisted tooth preparation based on augmented reality. Engineering Science and Technology, an International Journal (2021). https://doi.org/10.1016/J.JESTCH.2021.05.005\n\n[197]\n\nBrennan Jones, Yaying Zhang, Priscilla NY Wong, and Sean Rintel. 2020. VROOM: Virtual Robot Overlay for Online Meetings. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. 1–10. https://doi.org/10.1145/3334480.3382820\n\n[198]\n\nBrennan Jones, Yaying Zhang, Priscilla NY Wong, and Sean Rintel. 2021. Belonging There: VROOM-ing into the Uncanny Valley of XR Telepresence. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1–31. https://doi.org/10.1145/3449133\n\n[199]\n\nColin Jones, Michael Novitzky, and Christopher Korpela. 2021. AR/VR Tutorial System for Human-Robot Teaming. In 2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC). IEEE, 0878–0882. https://doi.org/10.1109/ccwc51732.2021.9375845\n\n[200]\n\nJana Jost, Thomas Kirks, Preity Gupta, Dennis Lünsch, and Jonas Stenzel. 2018. Safe human-robot-interaction in highly flexible warehouses using augmented reality and heterogenous fleet management system. In 2018 IEEE International Conference on Intelligence and Safety for Robotics (ISR). IEEE, 256–260. https://doi.org/10.1109/IISR.2018.8535808\n\n[201]\n\nKevin Sebastian Kain, Susanne Stadler, Manuel Giuliani, Nicole Mirnig, Gerald Stollnberger, and Manfred Tscheligi. 2017. Tablet-based augmented reality in the factory: Influence of knowledge in computer programming on robot teaching tasks. In Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction. 151–152. https://doi.org/10.1145/3029798.3038347\n\n[202]\n\nAlisa Kalegina, Grace Schroeder, Aidan Allchin, Keara Berlin, and Maya Cakmak. 2018. Characterizing the design space of rendered robot faces. In Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction. ACM, 96–104. https://doi.org/10.1145/3171221.3171286\n\n[203]\n\nMegha Kalia, Apeksha Avinash, Nassir Navab, and Septimiu Salcudean. 2021. Preclinical evaluation of a markerless, real-time, augmented reality guidance system for robot-assisted radical prostatectomy. International Journal of Computer Assisted Radiology and Surgery (2021), 1–8. https://doi.org/10.1007/s11548-021-02419-9\n\n[204]\n\nMegha Kalia, Prateek Mathur, Keith Tsang, Peter Black, Nassir Navab, and Septimiu Salcudean. 2020. Evaluation of a marker-less, intra-operative, augmented reality guidance system for robot-assisted laparoscopic radical prostatectomy. International Journal of Computer Assisted Radiology and Surgery 15 (2020), 1225–1233. https://doi.org/10.1007/s11548-020-02181-4\n\n[205]\n\nKenji Kansaku, Naoki Hata, and Kouji Takano. 2010. My thoughts through a robot’s eyes: An augmented reality-brain–machine interface. Neuroscience research 66, 2 (2010), 219–222. https://doi.org/10.1016/j.neures.2009.10.006\n\n[206]\n\nMichal Kapinus, Vítězslav Beran, Zdeněk Materna, and Daniel Bambušek. 2019. Spatially Situated End-User Robot Programming in Augmented Reality. In 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). IEEE, 1–8. https://doi.org/10.1109/RO-MAN46459.2019.8956336\n\n[207]\n\nMichal Kapinus, Zdeněk Materna, Daniel Bambušek, and Vitězslav Beran. 2020. End-User Robot Programming Case Study: Augmented Reality vs. Teach Pendant. In Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction. 281–283. https://doi.org/10.1145/3371382.3378266\n\n[208]\n\nMohamed Kari, Tobias Grosse-Puppendahl, Luis Falconeri Coelho, Andreas Rene Fender, David Bethge, Reinhard Schütte, and Christian Holz. 2021. TransforMR: Pose-Aware Object Substitution for Composing Alternate Mixed Realities. In 2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEE, 69–79. https://doi.org/10.1109/ismar52148.2021.00021\n\n[209]\n\nShunichi Kasahara, Ryuma Niiyama, Valentin Heun, and Hiroshi Ishii. 2013. exTouch: spatially-aware embodied manipulation of actuated objects mediated by augmented reality. In Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction. 223–228. https://doi.org/10.1145/2460625.2460661\n\n[210]\n\nMisaki Kasetani, Tomonobu Noguchi, Hirotake Yamazoe, and Joo-Ho Lee. 2015. Projection mapping by mobile projector robot. In 2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI). IEEE, 13–17. https://doi.org/10.1109/URAI.2015.7358918\n\n[211]\n\nLinh Kästner and Jens Lambrecht. 2019. Augmented-reality-based visualization of navigation data of mobile robots on the microsoft hololens-possibilities and limitations. In 2019 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM). IEEE, 344–349. https://doi.org/10.1109/cis-ram47153.2019.9095836\n\n[212]\n\nJun Kato, Daisuke Sakamoto, Masahiko Inami, and Takeo Igarashi. 2009. Multi-touch interface for controlling multiple mobile robots. In CHI’09 Extended Abstracts on Human Factors in Computing Systems. 3443–3448. https://doi.org/10.1145/1520340.1520500\n\n[213]\n\nYuta Kato, Yuya Aikawa, Masayoshi Kanoh, Felix Jimenez, Mitsuhiro Hayase, Takahiro Tanaka, and Hitoshi Kanamori. 2019. A Robot System Using Mixed Reality to Encourage Driving Review. In International Conference on Human-Computer Interaction. Springer, 112–117. https://doi.org/10.1007/978-3-030-23528-4_16\n\n[214]\n\nRubaiat Habib Kazi, Tovi Grossman, Nobuyuki Umetani, and George Fitzmaurice. 2016. Motion amplifiers: sketching dynamic illustrations using the principles of 2D animation. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems(CHI ’16). Association for Computing Machinery, 4599–4609. https://doi.org/10.1145/2858036.2858386\n\n[215]\n\nMaram Khatib, Khaled Al Khudir, and Alessandro De Luca. 2021. Human-robot contactless collaboration with mixed reality interface. Robotics and Computer-Integrated Manufacturing 67 (2021), 102030. https://doi.org/10.1016/j.rcim.2020.102030\n\n[216]\n\nHyoungnyoun Kim, Jun-Sik Kim, Kwanghyun Ryu, Seyoung Cheon, Yonghwan Oh, and Ji-Hyung Park. 2014. Task-oriented teleoperation through natural 3D user interaction. In 2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI). IEEE, 335–338. https://doi.org/10.1109/urai.2014.7057536\n\n[217]\n\nLawrence H Kim, Daniel S Drew, Veronika Domova, and Sean Follmer. 2020. User-defined swarm robot control. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems(CHI ’20). Association for Computing Machinery, 1–13. https://doi.org/10.1145/3313831.3376814\n\n[218]\n\nLawrence H Kim and Sean Follmer. 2017. Ubiswarm: Ubiquitous robotic interfaces and investigation of abstract motion as a display. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 1, 3 (2017), 1–20. https://doi.org/10.1145/3130931\n\n[219]\n\nWon S Kim. 1996. Virtual reality calibration and preview/predictive displays for telerobotics. Presence: Teleoperators & Virtual Environments 5, 2(1996), 173–190.\n\n[220]\n\nKazuhiko Kobayashi, Koichi Nishiwaki, Shinji Uchiyama, Hiroyuki Yamamoto, Satoshi Kagami, and Takeo Kanade. 2007. Overlay what humanoid robot perceives and thinks to the real-world by mixed reality system. In 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality. IEEE, 275–276. https://doi.org/ismar.2007.4538864\n\n[221]\n\nMinoru Kojima, Maki Sugimoto, Akihiro Nakamura, Masahiro Tomita, Hideaki Nii, and Masahiko Inami. 2006. Augmented coliseum: An augmented game environment with small vehicles. In First IEEE International Workshop on Horizontal Interactive Human-Computer Systems (TABLETOP’06). IEEE, 6–pp. https://doi.org/10.1109/TABLETOP.2006.3\n\n[222]\n\nAbhishek Kolagunda, Scott Sorensen, Sherif Mehralivand, Philip Saponaro, Wayne Treible, Baris Turkbey, Peter Pinto, Peter Choyke, and Chandra Kambhamettu. 2018. A mixed reality guidance system for robot assisted laparoscopic radical prostatectomy. In OR 2.0 Context-Aware Operating Theaters, Computer Assisted Robotic Endoscopy, Clinical Image-Based Procedures, and Skin Image Analysis. Springer, 164–174. https://doi.org/10.1007/978-3-030-01201-4_18\n\n[223]\n\nAndreas Korthauer, Clemens Guenther, Andreas Hinrichs, Wen Ren, and Yiwen Yang. 2020. Watch Your Vehicle Driving at the City: Interior HMI with Augmented Reality for Automated Driving. In 22nd International Conference on Human-Computer Interaction with Mobile Devices and Services. 1–5. https://doi.org/10.1145/3406324.3425895\n\n[224]\n\nTomáš Kot, Petr Novák, and Ján Babjak. 2017. Application of augmented reality in mobile robot teleoperation. In International Workshop on Modelling and Simulation for Autonomous Systems. Springer, 223–236. https://doi.org/10.1007/978-3-319-76072-8_16\n\n[225]\n\nNiki Kousi, Christos Stoubos, Christos Gkournelos, George Michalos, and Sotiris Makris. 2019. Enabling human robot interaction in flexible robotic assembly lines: An augmented reality based software suite. Procedia CIRP 81(2019), 1429–1434. https://doi.org/10.1016/J.PROCIR.2019.04.328\n\n[226]\n\nDennis Krupke, Frank Steinicke, Paul Lubos, Yannick Jonetzko, Michael Görner, and Jianwei Zhang. 2018. Comparison of multimodal heading and pointing gestures for co-located mixed reality human-robot interaction. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 1–9. https://doi.org/10.1109/iros.2018.8594043\n\n[227]\n\nAleksander Krzywinski, Haipeng Mi, Weiqin Chen, and Masanori Sugimoto. 2009. RoboTable: a tabletop framework for tangible interaction with robots in a mixed reality. In proceedings of the international conference on advances in computer Enterntainment technology. 107–114. https://doi.org/10.1145/1690388.1690407\n\n[228]\n\nEranda Lakshantha and Simon Egerton. 2014. Human Robot Interaction and Control: Translating Diagrams into an Intuitive Augmented Reality Approach. In 2014 International Conference on Intelligent Environments. IEEE, 111–116. https://doi.org/10.1109/ie.2014.24\n\n[229]\n\nFabrizio Lamberti, Davide Calandra, Federica Bazzano, Filippo G Prattico, and Davide M Destefanis. 2018. Robotquest: A robotic game based on projected mixed reality and proximity interaction. In 2018 IEEE Games, Entertainment, Media Conference (GEM). IEEE, 1–9. https://doi.org/10.1109/GEM.2018.8516501\n\n[230]\n\nFabrizio Lamberti, Alberto Cannavò, and Paolo Pirone. 2019. Designing interactive robotic games based on mixed reality technology. In 2019 IEEE International Conference on Consumer Electronics (ICCE). IEEE, 1–4. https://doi.org/10.1109/icce.2019.8661911\n\n[231]\n\nJens Lambrecht, Linh Kästner, Jan Guhl, and Jörg Krüger. 2021. Towards commissioning, resilience and added value of Augmented Reality in robotics: Overcoming technical obstacles to industrial applicability. Robotics and Computer-Integrated Manufacturing 71 (2021), 102178. https://doi.org/10.1016/J.RCIM.2021.102178\n\n[232]\n\nJens Lambrecht and Jörg Krüger. 2012. Spatial programming for industrial robots based on gestures and augmented reality. In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 466–472. https://doi.org/10.1109/IROS.2012.6385900\n\n[233]\n\nMatheus Laranjeira, Aurélien Arnaubec, Lorenzo Brignone, Claire Dune, and Jan Opderbecke. 2020. 3D Perception and Augmented Reality Developments in Underwater Robotics for Ocean Sciences. Current Robotics Reports(2020), 1–8. https://doi.org/10.1007/s43154-020-00014-5\n\n[234]\n\nTomas Lazna. 2018. The visualization of threats using the augmented reality and a remotely controlled robot. IFAC-PapersOnLine 51, 6 (2018), 444–449. https://doi.org/10.1016/J.IFACOL.2018.07.113\n\n[235]\n\nMathieu Le Goc, Lawrence H Kim, Ali Parsaei, Jean-Daniel Fekete, Pierre Dragicevic, and Sean Follmer. 2016. Zooids: Building blocks for swarm user interfaces. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology. 97–109. https://doi.org/10.1145/2984511.2984547\n\n[236]\n\nDavid Ledo, Steven Houben, Jo Vermeulen, Nicolai Marquardt, Lora Oehlberg, and Saul Greenberg. 2018. Evaluation strategies for HCI toolkit research. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. 1–17. https://doi.org/10.1145/3173574.3173610\n\n[237]\n\nHo-Dong Lee, Dongwon Kim, Min-Chul Park, and Gwi-Tae Park. 2008. Augmented reality based vision system for network based mobile robot. In Asia-Pacific Conference on Computer Human Interaction. Springer, 123–130. https://doi.org/10.1007/978-3-540-70585-7_14\n\n[238]\n\nHo-Dong Lee, Hyun-Gu Lee, Joo-Hyung Kim, Min-Chul Park, and Gwi-Tae Park. 2007. Human machine interface with augmented reality for the network based mobile robot. In International Conference on Knowledge-Based and Intelligent Information and Engineering Systems. Springer, 57–64. https://doi.org/10.1007/978-3-540-74829-8_8\n\n[239]\n\nJoo-Haeng Lee, Junho Kim, and Hyun Kim. 2011. A note on hybrid control of robotic spatial augmented reality. In 2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI). IEEE, 621–626. https://doi.org/10.1109/URAI.2011.6145895\n\n[240]\n\nJae Young Lee, Jong-Wook Lee, Teressa Talluri, Amarnathvarma Angani, and Jeong Bea Lee. 2020. Realization of Robot Fish with 3D Hologram Fish using Augmented Reality. In 2020 IEEE 2nd International Conference on Architecture, Construction, Environment and Hydraulics (ICACEH). IEEE, 102–104. https://doi.org/10.1109/icaceh51803.2020.9366226\n\n[241]\n\nKevin Lee, Christopher Reardon, and Jonathan Fink. 2018. Augmented Reality in Human-Robot Cooperative Search. In 2018 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR). IEEE, 1–1. https://doi.org/10.1109/ssrr.2018.8468659\n\n[242]\n\nMyungho Lee, Nahal Norouzi, Gerd Bruder, Pamela J Wisniewski, and Gregory F Welch. 2018. The physical-virtual table: exploring the effects of a virtual human’s physical influence on social interaction. In Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology. 1–11. https://doi.org/10.1145/3281505.3281533\n\n[243]\n\nDaniel Leithinger, Sean Follmer, Alex Olwal, Samuel Luescher, Akimitsu Hogge, Jinha Lee, and Hiroshi Ishii. 2013. Sublimate: state-changing virtual and physical rendering to augment interaction with shape displays. In Proceedings of the SIGCHI conference on human factors in computing systems. 1441–1450. https://doi.org/10.1145/2470654.2466191\n\n[244]\n\nDaniel Leithinger and Hiroshi Ishii. 2010. Relief: a scalable actuated shape display. In Proceedings of the fourth international conference on Tangible, embedded, and embodied interaction. 221–222. https://doi.org/10.1145/1709886.1709928\n\n[245]\n\nDaniel Leithinger, David Lakatos, Anthony DeVincenzi, Matthew Blackshaw, and Hiroshi Ishii. 2011. Direct and gestural interaction with relief: a 2.5 D shape display. In Proceedings of the 24th annual ACM symposium on User interface software and technology. 541–548. https://doi.org/10.1145/2047196.2047268\n\n[246]\n\nJakob Leitner, Michael Haller, Kyungdahm Yun, Woontack Woo, Maki Sugimoto, Masahiko Inami, Adrian David Cheok, and HD Been-Lirn. 2010. Physical interfaces for tabletop games. Computers in Entertainment (CIE) 7, 4 (2010), 1–21. https://doi.org/10.1145/1658866.1658880\n\n[247]\n\nGermán Leiva, Cuong Nguyen, Rubaiat Habib Kazi, and Paul Asente. 2020. Pronto: Rapid augmented reality video prototyping using sketches and enaction. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems(CHI ’20). Association for Computing Machinery, 1–13. https://doi.org/10.1145/3313831.3376160\n\n[248]\n\nAlexander Lenhardt and Helge Ritter. 2010. An augmented-reality based brain-computer interface for robot control. In International Conference on Neural Information Processing. Springer, 58–65. https://doi.org/10.1007/978-3-642-17534-3_8\n\n[249]\n\nFrancisco J Lera, Víctor Rodríguez, Carlos Rodríguez, and Vicente Matellán. 2014. Augmented reality in robotic assistance for the elderly. In International technology robotics applications. Springer, 3–11. https://doi.org/10.1007/978-3-319-02332-8_1\n\n[250]\n\nMirna Lerotic, Adrian J Chung, George Mylonas, and Guang-Zhong Yang. 2007. Pq-space based non-photorealistic rendering for augmented reality. In International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 102–109. https://doi.org/10.1007/978-3-540-75759-7_13\n\n[251]\n\nFlorian Leutert, Christian Herrmann, and Klaus Schilling. 2013. A spatial augmented reality system for intuitive display of robotic data. In 2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 179–180. https://doi.org/10.1109/hri.2013.6483560\n\n[252]\n\nFlorian Leutert and Klaus Schilling. 2012. Support of power plant telemaintenance with robots by augmented reality methods. In 2012 2nd International Conference on Applied Robotics for the Power Industry (CARPI). IEEE, 45–49. https://doi.org/10.1109/carpi.2012.6473362\n\n[253]\n\nFlorian Leutert and Klaus Schilling. 2015. Augmented reality for telemaintenance and-inspection in force-sensitive industrial robot applications. IFAC-PapersOnLine 48, 10 (2015), 153–158. https://doi.org/10.1016/J.IFACOL.2015.08.124\n\n[254]\n\nChunxu Li, Ashraf Fahmy, and Johann Sienz. 2019. An augmented reality based human-robot interaction interface using Kalman filter sensor fusion. Sensors 19, 20 (2019), 4586. https://doi.org/10.3390/s19204586\n\n[255]\n\nCongyuan Liang, Chao Liu, Xiaofeng Liu, Long Cheng, and Chenguang Yang. 2019. Robot teleoperation system based on mixed reality. In 2019 IEEE 4Th international conference on advanced robotics and mechatronics (ICARM). IEEE, 384–389. https://doi.org/10.1109/icarm.2019.8834302\n\n[256]\n\nLi Lin, Yunyong Shi, Andy Tan, Melia Bogari, Ming Zhu, Yu Xin, Haisong Xu, Yan Zhang, Le Xie, and Gang Chai. 2016. Mandibular angle split osteotomy based on a novel augmented reality navigation using specialized robot-assisted arms—A feasibility study. Journal of Cranio-Maxillofacial Surgery 44, 2 (2016), 215–223. https://doi.org/10.1016/j.jcms.2015.10.024\n\n[257]\n\nNatan Linder and Pattie Maes. 2010. LuminAR: portable robotic augmented reality interface design and prototype. In Adjunct proceedings of the 23nd annual ACM symposium on User interface software and technology. 395–396. https://doi.org/10.1145/1866218.1866237\n\n[258]\n\nDavid Lindlbauer, Jens Emil Grønbæk, Morten Birk, Kim Halskov, Marc Alexa, and Jörg Müller. 2016. Combining shape-changing interfaces and spatial augmented reality enables extended object appearance. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. 791–802. https://doi.org/10.1145/2858036.2858457\n\n[259]\n\nDavid Lindlbauer, Jörg Mueller, and Marc Alexa. 2017. Changing the appearance of real-world objects by modifying their surroundings. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems(CHI ’17). Association for Computing Machinery, 3954–3965. https://doi.org/10.1145/3025453.3025795\n\n[260]\n\nDavid Lindlbauer and Andy D. Wilson. 2018. Remixed Reality: Manipulating Space and Time in Augmented Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3173574.3173703\n\n[261]\n\nRagavendra Lingamaneni, Thomas Kubitza, and Jürgen Scheible. 2017. DroneCAST: towards a programming toolkit for airborne multimedia display applications. In Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services. 1–8. https://doi.org/10.1145/3098279.3122128\n\n[262]\n\nHangxin Liu, Yaofang Zhang, Wenwen Si, Xu Xie, Yixin Zhu, and Song-Chun Zhu. 2018. Interactive robot knowledge patching using augmented reality. In 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 1947–1954. https://doi.org/10.1109/ICRA.2018.8462837\n\n[263]\n\nKexi Liu, Daisuke Sakamoto, Masahiko Inami, and Takeo Igarashi. 2011. Roboshop: multi-layered sketching interface for robot housework assignment and management. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 647–656. https://doi.org/10.1145/1978942.1979035\n\n[264]\n\nWen P Liu, Jeremy D Richmon, Jonathan M Sorger, Mahdi Azizian, and Russell H Taylor. 2015. Augmented reality and cone beam CT guidance for transoral robotic surgery. Journal of robotic surgery 9, 3 (2015), 223–233. https://doi.org/10.1007/s11701-015-0520-5\n\n[265]\n\nYuzhou Liu, Georg Novotny, Nikita Smirnov, Walter Morales-Alvarez, and Cristina Olaverri-Monreal. 2020. Mobile Delivery Robots: Mixed Reality-Based Simulation Relying on ROS and Unity 3D. In 2020 IEEE Intelligent Vehicles Symposium (IV). IEEE, 15–20. https://doi.org/10.1109/IV47402.2020.9304701\n\n[266]\n\nSalvatore Livatino, Filippo Banno, and Giovanni Muscato. 2011. 3-D integration of robot vision and laser data with semiautomatic calibration in augmented reality stereoscopic visual interface. IEEE Transactions on Industrial Informatics 8, 1 (2011), 69–77. https://doi.org/10.1109/tii.2011.2174062\n\n[267]\n\nSalvatore Livatino, Dario C Guastella, Giovanni Muscato, Vincenzo Rinaldi, Luciano Cantelli, Carmelo D Melita, Alessandro Caniglia, Riccardo Mazza, and Gianluca Padula. 2021. Intuitive robot teleoperation through multi-sensor informed mixed reality visual aids. IEEE Access 9(2021), 25795–25808. https://doi.org/10.1109/access.2021.3057808\n\n[268]\n\nSalvatore Livatino, Giovanni Muscato, Filippo Banno, Davide De Tommaso, and Marco Macaluso. 2010. Video and laser based augmented reality stereoscopic viewing for mobile robot teleoperation. IFAC Proceedings Volumes 43, 23 (2010), 161–168. https://doi.org/10.3182/20101005-4-RO-2018.00049\n\n[269]\n\nSalvatore Livatino, Giovanni Muscato, Davide De Tommaso, and Marco Macaluso. 2010. Augmented reality stereoscopic visualization for intuitive robot teleguide. In 2010 IEEE International Symposium on Industrial Electronics. IEEE, 2828–2833. https://doi.org/10.1109/ISIE.2010.5636955\n\n[270]\n\nMatthew B Luebbers, Connor Brooks, Minjae John Kim, Daniel Szafir, and Bradley Hayes. 2019. Augmented reality interface for constrained learning from demonstration. In Proceedings of the 2nd International Workshop on Virtual, Augmented, and Mixed Reality for HRI (VAM-HRI).\n\n[271]\n\nDario Luipers and Anja Richert. 2021. Concept of an Intuitive Human-Robot-Collaboration via Motion Tracking and Augmented Reality. In 2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA). IEEE, 423–427. https://doi.org/10.1109/icaica52286.2021.9498091\n\n[272]\n\nMaria Luce Lupetti. 2016. Designing playful HRI: Acceptability of robots in everyday life through play. In 2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 631–632. https://doi.org/10.1109/hri.2016.7451891\n\n[273]\n\nMaria Luce Lupetti, Giovanni Piumatti, Claudio Germak, and Fabrizio Lamberti. 2018. Design and Evaluation of a Mixed-Reality Playground for Child-Robot Games. Multimodal Technologies and Interaction 2, 4 (2018), 69. https://doi.org/10.3390/mti2040069\n\n[274]\n\nAndreas Luxenburger, Jonas Mohr, Torsten Spieldenner, Dieter Merkel, Fabio Espinosa, Tim Schwartz, Florian Reinicke, Julian Ahlers, and Markus Stoyke. 2019. Augmented reality for human-robot cooperation in aircraft assembly. In 2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR). IEEE, 263–2633. https://doi.org/10.1109/AIVR46125.2019.00061\n\n[275]\n\nStéphane Magnenat, Morderchai Ben-Ari, Severin Klinger, and Robert W Sumner. 2015. Enhancing robot programming with visual feedback and augmented reality. In Proceedings of the 2015 ACM conference on innovation and technology in computer science education. 153–158. https://doi.org/10.1145/2729094.2742585\n\n[276]\n\nKarthik Mahadevan, Elaheh Sanoubari, Sowmya Somanath, James E Young, and Ehud Sharlin. 2019. AV-Pedestrian interaction design using a pedestrian mixed traffic simulator. In Proceedings of the 2019 on designing interactive systems conference. 475–486. https://doi.org/10.1145/3322276.3322328\n\n[277]\n\nKarthik Mahadevan, Maurício Sousa, Anthony Tang, and Tovi Grossman. 2021. “Grip-that-there”: An Investigation of Explicit and Implicit Task Allocation Techniques for Human-Robot Collaboration. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1–14. https://doi.org/10.1145/3411764.3445355\n\n[278]\n\nKartik Mahajan, Thomas Groechel, Roxanna Pakkar, Julia Cordero, Haemin Lee, and Maja J Matarić. 2020. Adapting Usability Metrics for a Socially Assistive, Kinesthetic, Mixed Reality Robot Tutoring Environment. In International Conference on Social Robotics. Springer, 381–391. https://doi.org/10.1007/978-3-030-62056-1_32\n\n[279]\n\nMadjid Maidi, Malik Mallem, Laredj Benchikh, and Samir Otmane. 2013. An evaluation of camera pose methods for an augmented reality system: Application to teaching industrial robots. In Transactions on Computational Science XVII. Springer, 3–30. https://doi.org/10.1007/978-3-642-35840-1_1\n\n[280]\n\nJim Mainprice, Emrah Akin Sisbot, Thierry Siméon, and Rachid Alami. 2010. Planning Safe and Legible Hand-over Motions for Human-Robot Interaction. In IARP/IEEE-RAS/EURON workshop on technical challenges for dependable robots in human environments. HAL. https://hal.laas.fr/hal-01976223\n\n[281]\n\nZhanat Makhataeva and Huseyin Atakan Varol. 2020. Augmented reality for robotics: a review. Robotics 9, 2 (2020), 21. https://doi.org/10.3390/robotics9020021\n\n[282]\n\nZhanat Makhataeva, Altay Zhakatayev, and Huseyin Atakan Varol. 2019. Safety Aura Visualization for Variable Impedance Actuated Robots. In 2019 IEEE/SICE International Symposium on System Integration (SII). IEEE, 805–810. https://doi.org/10.1109/SII.2019.8700332\n\n[283]\n\nSotiris Makris, Panagiotis Karagiannis, Spyridon Koukas, and Aleksandros-Stereos Matthaiakis. 2016. Augmented reality system for operator support in human–robot collaborative assembly. CIRP Annals 65, 1 (2016), 61–64. https://doi.org/10.1016/J.CIRP.2016.04.038\n\n[284]\n\nEhsan Malayjerdi, Mahdi Yaghoobi, and Mohammad Kardan. 2017. Mobile robot navigation based on fuzzy cognitive map optimized with grey wolf optimization algorithm used in augmented reality. In 2017 5th RSI International Conference on Robotics and Mechatronics (ICRoM). IEEE, 211–218. https://doi.org/10.1109/icrom.2017.8466169\n\n[285]\n\nIvo Malỳ, David Sedláček, and Paulo Leitao. 2016. Augmented reality experiments with industrial robot in industry 4.0 environment. In 2016 IEEE 14th international conference on industrial informatics (INDIN). IEEE, 176–181. https://doi.org/10.1109/INDIN.2016.7819154\n\n[286]\n\nRaúl Marín and Pedro J Sanz. 2002. Augmented reality to teleoperate a robot through the Web. IFAC Proceedings Volumes 35, 1 (2002), 161–165. https://doi.org/10.3182/20020721-6-ES-1901.00933\n\n[287]\n\nAndrés Martín-Barrio, Juan Jesús Roldán-Gómez, Iván Rodríguez, Jaime Del Cerro, and Antonio Barrientos. 2020. Design of a Hyper-Redundant Robot and Teleoperation Using Mixed Reality for Inspection Tasks. Sensors 20, 8 (2020), 2181. https://doi.org/10.3390/s20082181\n\n[288]\n\nZdeněk Materna, Michal Kapinus, Vítězslav Beran, Pavel SmrĚ, Manuel Giuliani, Nicole Mirnig, Susanne Stadler, Gerald Stollnberger, and Manfred Tscheligi. 2017. Using persona, scenario, and use case to develop a human-robot augmented reality collaborative workspace. In Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction. 201–202. https://doi.org/10.1145/3029798.3038366\n\n[289]\n\nZdeněk Materna, Michal Kapinus, Vítězslav Beran, Pavel Smrž, and Pavel Zemčík. 2018. Interactive spatial augmented reality in collaborative robot programming: User experience evaluation. In 2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, 80–87. https://doi.org/10.1109/roman.2018.8525662\n\n[290]\n\nFlorin Octavian Matu, Mikkel Thøgersen, Bo Galsgaard, Martin Møller Jensen, and Martin Kraus. 2014. Stereoscopic augmented reality system for supervised training on minimal invasive surgery robots. In Proceedings of the 2014 Virtual Reality International Conference. 1–4. https://doi.org/10.1145/2617841.2620722\n\n[291]\n\nWilliam A McNeely. 1993. Robotic graphics: a new approach to force feedback for virtual reality. In Proceedings of IEEE Virtual Reality Annual International Symposium. IEEE, 336–341. https://doi.org/10.1109/VRAIS.1993.380761\n\n[292]\n\nGeorge Michalos, Panagiotis Karagiannis, Sotiris Makris, Önder Tokçalar, and George Chryssolouris. 2016. Augmented reality (AR) applications for supporting human-robot interactive cooperation. Procedia CIRP 41(2016), 370–375. https://doi.org/10.1016/J.PROCIR.2015.12.005\n\n[293]\n\nPaul Milgram and Fumio Kishino. 1994. A taxonomy of mixed reality visual displays. IEICE TRANSACTIONS on Information and Systems 77, 12 (1994), 1321–1329.\n\n[294]\n\nPaul Milgram, Shumin Zhai, David Drascic, and Julius Grodski. 1993. Applications of augmented reality for human-robot communication. In Proceedings of 1993 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS’93), Vol. 3. IEEE, 1467–1472. https://doi.org/10.1109/IROS.1993.583833\n\n[295]\n\nOmid Mohareri and Ahmad B Rad. 2011. Autonomous humanoid robot navigation using augmented reality technique. In 2011 IEEE International Conference on Mechatronics. IEEE, 463–468. https://doi.org/10.1109/icmech.2011.5971330\n\n[296]\n\nNicolas Mollet, Ryad Chellali, and Luca Brayda. 2009. Virtual and augmented reality tools for teleoperation: improving distant immersion and perception. In Transactions on edutainment II. Springer, 135–159. https://doi.org/10.1007/978-3-642-03270-7_10\n\n[297]\n\nWilliam Montalvo, Pablo Bonilla-Vasconez, Santiago Altamirano, Carlos A Garcia, and Marcelo V Garcia. 2020. Industrial Control Robot Based on Augmented Reality and IoT Protocol. In International Conference on Augmented Reality, Virtual Reality and Computer Graphics. Springer, 345–363. https://doi.org/10.1007/978-3-030-58468-9_25\n\n[298]\n\nRafael Morales, Asier Marzo, Sriram Subramanian, and Diego Martínez. 2019. LeviProps: Animating levitated optimized fabric structures using holographic acoustic tweezers. In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology. 651–661. https://doi.org/10.1145/3332165.3347882\n\n[299]\n\nStephen A Morin, Robert F Shepherd, Sen Wai Kwok, Adam A Stokes, Alex Nemiroski, and George M Whitesides. 2012. Camouflage and display for soft machines. Science 337, 6096 (2012), 828–832. https://doi.org/10.1126/science.1222149\n\n[300]\n\nKohei Morita, Takefumi Hiraki, Haruka Matsukura, Daisuke Iwai, and Kosuke Sato. 2020. Extension of Projection Area using Head Orientation in Projected Virtual Hand Interface for Wheelchair Users. In 2020 59th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE). IEEE, 421–426. https://doi.org/10.23919/SICE48898.2020.9240271\n\n[301]\n\nD Mourtzis, G Synodinos, J Angelopoulos, and N Panopoulos. 2020. An augmented reality application for robotic cell customization. Procedia CIRP 90(2020), 654–659. https://doi.org/10.1016/j.procir.2020.02.135\n\n[302]\n\nDimitris Mourtzis, Vasilios Zogopoulos, and E Vlachou. 2017. Augmented reality application to support remote maintenance as a service in the robotics industry. Procedia Cirp 63(2017), 46–51. https://doi.org/10.1016/j.procir.2017.03.154\n\n[303]\n\nFabian Mueller, Christian Deuerlein, and Michael Koch. 2019. Intuitive welding robot programming via motion capture and augmented reality. IFAC-PapersOnLine 52, 10 (2019), 294–299. https://doi.org/10.1016/j.ifacol.2019.10.045\n\n[304]\n\nStefanie Mueller, Pedro Lopes, and Patrick Baudisch. 2012. Interactive construction: interactive fabrication of functional mechanical devices. In Proceedings of the 25th annual ACM symposium on User interface software and technology. 599–606. https://doi.org/10.1145/2380116.2380191\n\n[305]\n\nFaizan Muhammad, Amel Hassan, Andre Cleaver, and Jivko Sinapov. 2019. Creating a shared reality with robots. In 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 614–615. https://doi.org/10.1109/HRI.2019.8673191\n\n[306]\n\nAlex Murphy and Alan G Millard. 2020. Prototyping Sensors and Actuators for Robot Swarms in Mixed Reality. In Annual Conference Towards Autonomous Robotic Systems. Springer, 377–386. https://doi.org/10.1007/978-3-030-63486-5_39\n\n[307]\n\nBilge Mutlu, Jodi Forlizzi, and Jessica Hodgins. 2006. Modeling and evaluation of human-like gaze behavior. (2006), 518–523. https://doi.org/10.1109/ICHR.2006.321322\n\n[308]\n\nKen Nakagaki, Luke Vink, Jared Counts, Daniel Windham, Daniel Leithinger, Sean Follmer, and Hiroshi Ishii. 2016. Materiable: Rendering dynamic material properties in response to direct physical touch with shape changing interfaces. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. 2764–2772. https://doi.org/10.1145/2858036.2858104\n\n[309]\n\nNassir Navab, Christoph Hennersperger, Benjamin Frisch, and Bernhard Fürst. 2016. Personalized, relevance-based multimodal robotic imaging and augmented reality for computer assisted interventions., 64–71 pages. https://doi.org/10.1016/j.media.2016.06.021\n\n[310]\n\nAditya Nawab, Keshav Chintamani, Darin Ellis, Gregory Auner, and Abhilash Pandya. 2007. Joystick mapped augmented reality cues for end-effector controlled tele-operated robots. In 2007 IEEE Virtual Reality Conference. IEEE, 263–266. https://doi.org/10.1109/vr.2007.352496\n\n[311]\n\nMichael Nebeling, Janet Nebeling, Ao Yu, and Rob Rumble. 2018. Protoar: Rapid physical-digital prototyping of mobile augmented reality applications. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). Association for Computing Machinery, 1–12. https://doi.org/10.1145/3173574.3173927\n\n[312]\n\nChuen Leong Ng, Teck Chew Ng, Thi Anh Ngoc Nguyen, Guilin Yang, and Wenjie Chen. 2010. Intuitive robot tool path teaching using laser and camera in augmented reality environment. In 2010 11th International Conference on Control Automation Robotics & Vision. IEEE, 114–119. https://doi.org/10.1109/icarcv.2010.5707399\n\n[313]\n\nD Ni, AWW Yew, SK Ong, and AYC Nee. 2017. Haptic and visual augmented reality interface for programming welding robots. Advances in Manufacturing 5, 3 (2017), 191–198. https://doi.org/10.1007/s40436-017-0184-7\n\n[314]\n\nSivapong Nilwong and Genci Capi. 2020. Outdoor Robot Navigation System using Game-Based DQN and Augmented Reality. In 2020 17th International Conference on Ubiquitous Robots (UR). IEEE, 74–80. https://doi.org/10.1109/ur49135.2020.9144838\n\n[315]\n\nKoichi Nishiwaki, Kazuhiko Kobayashi, Shinji Uchiyama, Hiroyuki Yamamoto, and Satoshi Kagami. 2008. Mixed reality environment for autonomous robot development. In 2008 IEEE International Conference on Robotics and Automation. IEEE, 2211–2212. https://doi.org/10.1109/ROBOT.2008.4543538\n\n[316]\n\nDiana Nowacka, Karim Ladha, Nils Y Hammerla, Daniel Jackson, Cassim Ladha, Enrico Rukzio, and Patrick Olivier. 2013. Touchbugs: Actuated tangibles on multi-touch tables. In Proceedings of the SIGCHI conference on human factors in computing systems. 759–762. https://doi.org/10.1145/2470654.2470761\n\n[317]\n\nHiroki Nozaki. 2014. Flying display: a movable display pairing projector and screen in the air. In CHI’14 Extended Abstracts on Human Factors in Computing Systems. 909–914. https://doi.org/10.1145/2559206.2579410\n\n[318]\n\nR Nunez, JR Bandera, JM Perez-Lorenzo, and Francisco Sandoval. 2006. A human-robot interaction system for navigation supervision based on augmented reality. In MELECON 2006-2006 IEEE Mediterranean Electrotechnical Conference. IEEE, 441–444. https://doi.org/10.1109/melcon.2006.1653133\n\n[319]\n\nCristina Nuzzi, Stefano Ghidini, Roberto Pagani, Simone Pasinetti, Gabriele Coffetti, and Giovanna Sansoni. 2020. Hands-Free: a robot augmented reality teleoperation system. In 2020 17th International Conference on Ubiquitous Robots (UR). IEEE, 617–624. https://doi.org/10.1109/ur49135.2020.9144841\n\n[320]\n\nYoichi Ochiai and Keisuke Toyoshima. 2011. Homunculus: the vehicle as augmented clothes. In Proceedings of the 2nd Augmented Human International Conference. 1–4. https://doi.org/10.1145/1959826.1959829\n\n[321]\n\nYusuke Okuno, Takayuki Kanda, Michita Imai, Hiroshi Ishiguro, and Norihiro Hagita. 2009. Providing route directions: design of robot’s utterance, gesture, and timing. In 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 53–60. https://doi.org/10.1145/1514095.1514108\n\n[322]\n\nShayegan Omidshafiei, Ali-Akbar Agha-Mohammadi, Yu Fan Chen, Nazim Kemal Ure, Shih-Yuan Liu, Brett T Lopez, Rajeev Surati, Jonathan P How, and John Vian. 2016. Measurable augmented reality for prototyping cyberphysical systems: A robotics platform to aid the hardware prototyping and performance testing of algorithms. IEEE Control Systems Magazine 36, 6 (2016), 65–87. https://doi.org/10.1109/mcs.2016.2602090\n\n[323]\n\nSK Ong, AWW Yew, NK Thanigaivel, and AYC Nee. 2020. Augmented reality-assisted robot programming system for industrial applications. Robotics and Computer-Integrated Manufacturing 61 (2020), 101820. https://doi.org/10.1016/J.RCIM.2019.101820\n\n[324]\n\nSoh-Khim Ong, JWS Chong, and Andrew YC Nee. 2006. Methodologies for immersive robot programming in an augmented reality environment. In Proceedings of the 4th international conference on computer graphics and interactive techniques in Australasia and Southeast Asia. 237–244. https://doi.org/10.1145/1174429.1174470\n\n[325]\n\nMikhail Ostanin and Alexandr Klimchik. 2018. Interactive robot programing using mixed reality. IFAC-PapersOnLine 51, 22 (2018), 50–55. https://doi.org/10.1016/j.ifacol.2018.11.517\n\n[326]\n\nMikhail Ostanin, Stanislav Mikhel, Alexey Evlampiev, Valeria Skvortsova, and Alexandr Klimchik. 2020. Human-robot interaction for robotic manipulator programming in Mixed Reality. In 2020 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2805–2811. https://doi.org/10.1109/ICRA40945.2020.9196965\n\n[327]\n\nM Ostanin, R Yagfarov, and A Klimchik. 2019. Interactive Robots Control Using Mixed Reality. IFAC-PapersOnLine 52, 13 (2019), 695–700. https://doi.org/10.1016/j.ifacol.2019.11.307\n\n[328]\n\nAyberk Özgür, Séverin Lemaignan, Wafa Johal, Maria Beltran, Manon Briod, Léa Pereyre, Francesco Mondada, and Pierre Dillenbourg. 2017. Cellulo: Versatile handheld robots for education. In 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI. IEEE, 119–127. https://doi.org/10.1145/2909824.3020247\n\n[329]\n\nYun Suen Pai, Hwa Jen Yap, Siti Zawiah Md Dawal, S Ramesh, and Sin Ye Phoon. 2016. Virtual planning, control, and machining for a modular-based automated factory operation in an augmented reality environment. Scientific reports 6, 1 (2016), 1–19. https://doi.org/10.1038/srep27380\n\n[330]\n\nYong Pan, Chengjun Chen, Dongnian Li, Zhengxu Zhao, and Jun Hong. 2021. Augmented reality-based robot teleoperation system using RGB-D imaging and attitude teaching device. Robotics and Computer-Integrated Manufacturing 71 (2021), 102167. https://doi.org/10.1016/J.RCIM.2021.102167\n\n[331]\n\nGian Pangaro, Dan Maynes-Aminzade, and Hiroshi Ishii. 2002. The actuated workbench: computer-controlled actuation in tabletop tangible interfaces. In Proceedings of the 15th annual ACM symposium on User interface software and technology. 181–190. https://doi.org/10.1145/571985.572011\n\n[332]\n\nChristos Papachristos and Kostas Alexis. 2016. Augmented reality-enhanced structural inspection using aerial robots. In 2016 IEEE international symposium on intelligent control (ISIC). IEEE, 1–6. https://doi.org/10.1109/ISIC.2016.7579983\n\n[333]\n\nPeter Papcun, Jan Cabadaj, Erik Kajati, David Romero, Lenka Landryova, Jan Vascak, and Iveta Zolotova. 2019. Augmented Reality for Humans-Robots Interaction in Dynamic Slotting “Chaotic Storage” Smart Warehouses. In IFIP International Conference on Advances in Production Management Systems. Springer, 633–641. https://doi.org/10.1007/978-3-030-30000-5_77\n\n[334]\n\nHyeshin Park, Yo-An Lim, Aslam Pervez, Beom-Chan Lee, Sang-Goog Lee, and Jeha Ryu. 2007. Teleoperation of a multi-purpose robot over the internet using augmented reality. In 2007 International Conference on Control, Automation and Systems. IEEE, 2456–2461. https://doi.org/10.1109/iccas.2007.4406776\n\n[335]\n\nJung Pil Park, Min Woo Park, and Soon Ki Jung. 2014. Qr-code based online robot augmented reality system for education. In Proceedings of the 29th Annual ACM Symposium on Applied Computing. 180–185. https://doi.org/10.1145/2554850.2555038\n\n[336]\n\nKyeong-Beom Park, Sung Ho Choi, Jae Yeol Lee, Yalda Ghasemi, Mustafa Mohammed, and Heejin Jeong. 2021. Hands-Free Human–Robot Interaction Using Multimodal Gestures and Deep Learning in Wearable Mixed Reality. IEEE Access 9(2021), 55448–55464. https://doi.org/10.1109/access.2021.3071364\n\n[337]\n\nYoon Jung Park, Hyocheol Ro, and Tack-Don Han. 2019. Deep-ChildAR bot: educational activities and safety care augmented reality system with deep-learning for preschool. In ACM SIGGRAPH 2019 Posters. 1–2. https://doi.org/10.1145/3306214.3338589\n\n[338]\n\nYoon Jung Park, Yoonsik Yang, Hyocheol Ro, JungHyun Byun, Seougho Chae, and Tack Don Han. 2018. Meet AR-bot: Meeting Anywhere, Anytime with Movable Spatial AR Robot. In Proceedings of the 26th ACM international conference on Multimedia. 1242–1243. https://doi.org/10.1145/3240508.3241390\n\n[339]\n\nJames Patten and Hiroshi Ishii. 2007. Mechanical constraints as computational constraints in tabletop tangible interfaces. In Proceedings of the SIGCHI conference on Human factors in computing systems. 809–818. https://doi.org/10.1145/1240624.1240746\n\n[340]\n\nEsben Warming Pedersen and Kasper Hornbæk. 2011. Tangible bots: interaction with active tangibles in tabletop interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 2975–2984. https://doi.org/10.1145/1978942.1979384\n\n[341]\n\nHuaishu Peng, Jimmy Briggs, Cheng-Yao Wang, Kevin Guo, Joseph Kider, Stefanie Mueller, Patrick Baudisch, and François Guimbretière. 2018. RoMA: Interactive fabrication with augmented reality and a robotic 3D printer. In Proceedings of the 2018 CHI conference on human factors in computing systems. 1–12. https://doi.org/10.1145/3173574.3174153\n\n[342]\n\nLorenzo Peppoloni, Filippo Brizzi, Emanuele Ruffaldi, and Carlo Alberto Avizzano. 2015. Augmented reality-aided tele-presence system for robot manipulation in industrial manufacturing. In Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology. 237–240. https://doi.org/10.1145/2821592.2821620\n\n[343]\n\nNate Phillips, Brady Kruse, Farzana Alam Khan, J Edward Swan II, and Cindy L Bethel. 2020. A Robotic Augmented Reality Virtual Window for Law Enforcement Operations. In International Conference on Human-Computer Interaction. Springer, 591–610. https://doi.org/10.1007/978-3-030-49695-1_40\n\n[344]\n\nLuis Piardi, Vivian Cremer Kalempa, Marcelo Limeira, André Schneider de Oliveira, and Paulo Leitão. 2019. ARENA—augmented reality to enhanced experimentation in smart warehouses. Sensors 19, 19 (2019), 4308. https://doi.org/10.3390/s19194308\n\n[345]\n\nCarlo Pinciroli, Mohamed S Talamal"
    }
}