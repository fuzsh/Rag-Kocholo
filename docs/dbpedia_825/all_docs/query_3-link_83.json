{
    "id": "dbpedia_825_3",
    "rank": 83,
    "data": {
        "url": "https://www.mongodb.com/docs/manual/changeStreams/",
        "read_more_link": "",
        "language": "en",
        "title": "MongoDB Manual v7.0",
        "top_image": "http://www.mongodb.com/docs/assets/meta_generic.png",
        "meta_img": "http://www.mongodb.com/docs/assets/meta_generic.png",
        "images": [
            "https://webimages.mongodb.com/_com_assets/cms/kuyjf3vea2hg34taa-horizontal_default_slate_blue.svg?auto=format%252Ccompress",
            "https://webimages.mongodb.com/_com_assets/cms/krc3hljsdwdfd2w5d-web-actions-search.svg?auto=format%252Ccompress",
            "https://webimages.mongodb.com/_com_assets/icons/atlas_product_family.svg",
            "https://webimages.mongodb.com/_com_assets/icons/atlas_database.svg",
            "https://webimages.mongodb.com/_com_assets/icons/atlas_search.svg",
            "https://webimages.mongodb.com/_com_assets/icons/mdb_vector_search.svg",
            "https://webimages.mongodb.com/_com_assets/icons/atlas_stream_processing.svg",
            "https://webimages.mongodb.com/_com_assets/icons/enterprise_advanced_product family.svg",
            "https://webimages.mongodb.com/_com_assets/icons/community_edition_product_family.svg",
            "https://webimages.mongodb.com/_com_assets/icons/mdb_compass.svg",
            "https://webimages.mongodb.com/_com_assets/icons/atlas_integration.svg",
            "https://webimages.mongodb.com/_com_assets/icons/mdb_migrator.svg",
            "https://webimages.mongodb.com/_com_assets/icons/atlas_product_family.svg",
            "https://webimages.mongodb.com/_com_assets/icons/general_events_ask_the_experts.svg",
            "https://webimages.mongodb.com/_com_assets/icons/general_content_tutorial.svg",
            "https://webimages.mongodb.com/_com_assets/icons/general_events_session.svg",
            "https://webimages.mongodb.com/_com_assets/cms/lmqnddlajolelmbus-SearchIcon.svg?auto=format%252Ccompress",
            "https://webimages.mongodb.com/_com_assets/cms/lvz91dv3bugodsyau-language-selector-globe.svg?auto=format%252Ccompress",
            "https://webimages.mongodb.com/_com_assets/cms/kuyjf3vea2hg34taa-horizontal_default_slate_blue.svg?auto=format%252Ccompress",
            "https://webimages.mongodb.com/_com_assets/cms/lmqnddlajolelmbus-SearchIcon.svg?auto=format%252Ccompress"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "database triggers",
            "code example",
            "node.js",
            "motor",
            "coroutine",
            "java sync",
            "swift sync",
            "swift async"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Change streams code examples for how to access real-time data changes in MongoDB",
        "meta_lang": "en",
        "meta_favicon": "https://www.mongodb.com/docs/assets/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://www.mongodb.com/docs/manual/changeStreams/",
        "text": "Change Streams\n\nChange streams allow applications to access real-time data changes without the prior complexity and risk of manually tailing the oplog. Applications can use change streams to subscribe to all data changes on a single collection, a database, or an entire deployment, and immediately react to them. Because change streams use the aggregation framework, applications can also filter for specific changes or transform the notifications at will.\n\nStarting in MongoDB 5.1, change streams are optimized, providing more efficient resource utilization and faster execution of some aggregation pipeline stages.\n\nAvailability\n\nChange streams are available for replica sets and sharded clusters :\n\nStorage Engine.\n\nThe replica sets and sharded clusters must use the WiredTiger storage engine. Change streams can also be used on deployments that employ MongoDB's encryption-at-rest feature.\n\nReplica Set Protocol Version.\n\nThe replica sets and sharded clusters must use replica set protocol version 1 (pv1).\n\nRead Concern \"majority\" Enablement.\n\nStarting in MongoDB 4.2, change streams are available regardless of the \"majority\" read concern support; that is, read concern majority support can be either enabled (default) or disabled to use change streams.\n\nIn MongoDB 4.0 and earlier, change streams are available only if \"majority\" read concern support is enabled (default).\n\nStable API Support\n\nChange streams are included in Stable API V1. However, the showExpandedEvents option is not included in Stable API V1.\n\nConnect\n\nConnections for a change stream can either use DNS seed lists with the +srv connection option or by listing the servers individually in the connection string.\n\nIf the driver loses the connection to a change stream or the connection goes down, it attempts to reestablish a connection to the change stream through another node in the cluster that has a matching read preference. If the driver cannot find a node with the correct read preference, it throws an exception.\n\nFor more information, see Connection String URI Format .\n\nWatch a Collection, Database, or Deployment\n\nYou can open change streams against:\n\nTarget\n\nDescription\n\nNote\n\nChange Stream Examples\n\nThe examples on this page use the MongoDB drivers to illustrate how to open a change stream cursor for a collection and work with the change stream cursor.\n\nChange Stream Performance Considerations\n\nIf the amount of active change streams opened against a database exceeds the connection pool size, you may experience notification latency. Each change stream uses a connection and a getMore operation on the change stream for the period of time that it waits for the next event. To avoid any latency issues, you should ensure that the pool size is greater than the number of opened change streams. For details see the maxPoolSize setting.\n\nSharded Cluster Considerations\n\nWhen a change stream is opened on a sharded cluster:\n\nThe mongos creates individual change streams on each shard. This behavior occurs regardless of whether the change stream targets a particular shard key range.\n\nWhen the mongos receives change stream results, it sorts and filters those results. If needed, the mongos also performs a fullDocument lookup.\n\nFor best performance, limit the use of $lookup queries in change streams.\n\nOpen A Change Stream\n\nTo open a change stream:\n\nFor a replica set, you can issue the open change stream operation from any of the data-bearing members.\n\nFor a sharded cluster, you must issue the open change stream operation from the mongos.\n\nThe following example opens a change stream for a collection and iterates over the cursor to retrieve the change stream documents.\n\nâ¤ Use the Select your language drop-down menu in the upper-right to set the language of the examples on this page.\n\nThe C examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\nThe C# examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\nThe Go examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\nThe Java examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\nMongoCursor<ChangeStreamDocument<Document>> cursor = inventory.watch().iterator();ChangeStreamDocument<Document> next = cursor.next();\n\nThe examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\ncursor = db.inventory.watch()document = await cursor.next()\n\nThe Node.js examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\nThe following example uses stream to process the change events.\n\nAlternatively, you can also use iterator to process the change events:\n\nconst collection = db.collection('inventory') ;const changeStream = collection.watch( ) ;const next = await changeStream.next( ) ;\n\nChangeStream extends EventEmitter .\n\nThe examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\n$changeStream = $db->inventory->watch() ;$changeStream->rewind() ;$firstChange = $changeStream->current() ;$changeStream->next() ;$secondChange = $changeStream->current() ;\n\nThe Python examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\ncursor = db.inventory.watch()next(cursor)\n\nThe examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\ncursor = inventory.watch.to_enumnext_change = cursor.next\n\nThe Swift (Async) examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\nThe Swift (Sync) examples below assume that you have connected to a MongoDB replica set and have accessed a database that contains an inventory collection.\n\nTo retrieve the data change event from the cursor, iterate the change stream cursor. For information on the change stream event, see Change Events .\n\nThe change stream cursor remains open until one of the following occurs:\n\nThe cursor is explicitly closed.\n\nAn invalidate event occurs; for example, a collection drop or rename.\n\nThe connection to the MongoDB deployment closes or times out. See Cursor Behaviors for more information.\n\nIf the deployment is a sharded cluster, a shard removal may cause an open change stream cursor to close, and the closed change stream cursor may not be fully resumable.\n\nModify Change Stream Output\n\nâ¤ Use the Select your language drop-down menu in the upper-right to set the language of the examples on this page.\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nThe pipeline list includes a single $match stage that filters any operations where the username is alice, or operations where the operationType is delete.\n\nPassing the pipeline to the watch() method directs the change stream to return notifications after passing them through the specified pipeline.\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nThe following example uses stream to process the change events.\n\nAlternatively, you can also use iterator to process the change events:\n\nconst changeStreamIterator = collection.watch( pipeline) ;const next = await changeStreamIterator.next( ) ;\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nYou can control change stream output by providing an array of one or more of the following pipeline stages when configuring the change stream:\n\n$addFields\n\n$match\n\n$project\n\n$replaceRoot\n\n$replaceWith\n\n$redact\n\n$set\n\n$unset\n\nLookup Full Document for Update Operations\n\nBy default, change streams only return the delta of fields during the update operation. However, you can configure the change stream to return the most current majority-committed version of the updated document.\n\nâ¤ Use the Select your language drop-down menu in the upper-right to set the language of the examples on this page.\n\nTo return the most current majority-committed version of the updated document, pass the \"fullDocument\" option with the \"updateLookup\" value to the mongoc_collection_watch method.\n\nIn the example below, all update operations notifications include a fullDocument field that represents the current version of the document affected by the update operation.\n\nBSON_APPEND_UTF8 (&opts, \"fullDocument\", \"updateLookup\") ;stream = mongoc_collection_watch (collection, pipeline, &opts) ;mongoc_change_stream_next (stream, &change) ;if (mongoc_change_stream_error_document (stream, &error, NULL) ) { MONGOC_ERROR (\"%s\\n\", error.message) ;}mongoc_change_stream_destroy (stream) ;\n\nTo return the most current majority-committed version of the updated document, pass \"FullDocument = ChangeStreamFullDocumentOption.UpdateLookup\" to the db.collection.watch() method.\n\nIn the example below, all update operations notifications include a FullDocument field that represents the current version of the document affected by the update operation.\n\nTo return the most current majority-committed version of the updated document, SetFullDocument(options.UpdateLookup) change stream option.\n\nTo return the most current majority-committed version of the updated document, pass FullDocument.UPDATE_LOOKUP to the db.collection.watch.fullDocument() method.\n\nIn the example below, all update operations notifications include a FullDocument field that represents the current version of the document affected by the update operation.\n\ncursor = inventory.watch().fullDocument(FullDocument.UPDATE_LOOKUP).iterator();next = cursor.next();\n\nTo return the most current majority-committed version of the updated document, pass full_document='updateLookup' to the db.collection.watch() method.\n\nIn the example below, all update operations notifications include a `full_document field that represents the current version of the document affected by the update operation.\n\ncursor = db.inventory.watch(full_document=\"updateLookup\")document = await cursor.next()\n\nTo return the most current majority-committed version of the updated document, pass { fullDocument: 'updateLookup' } to the db.collection.watch() method.\n\nIn the example below, all update operations notifications include a fullDocument field that represents the current version of the document affected by the update operation.\n\nThe following example uses stream to process the change events.\n\nAlternatively, you can also use iterator to process the change events:\n\nconst changeStreamIterator = collection.watch( [ ] , { fullDocument: 'updateLookup' }) ;const next = await changeStreamIterator.next( ) ;\n\nTo return the most current majority-committed version of the updated document, pass \"fullDocument' => \\MongoDB\\Operation\\ChangeStreamCommand::FULL_DOCUMENT_UPDATE_LOOKUP\" to the db.watch() method.\n\nIn the example below, all update operations notifications include a fullDocument field that represents the current version of the document affected by the update operation.\n\n$changeStream = $db->inventory->watch([], ['fullDocument' => \\MongoDB\\Operation\\Watch::FULL_DOCUMENT_UPDATE_LOOKUP]) ;$changeStream->rewind() ;$firstChange = $changeStream->current() ;$changeStream->next() ;$secondChange = $changeStream->current() ;\n\nTo return the most current majority-committed version of the updated document, pass full_document='updateLookup' to the db.collection.watch() method.\n\nIn the example below, all update operations notifications include a full_document field that represents the current version of the document affected by the update operation.\n\ncursor = db.inventory.watch(full_document=\"updateLookup\")next(cursor)\n\nTo return the most current majority-committed version of the updated document, pass full_document: 'updateLookup' to the db.watch() method.\n\nIn the example below, all update operations notifications include a full_document field that represents the current version of the document affected by the update operation.\n\nTo return the most current majority-committed version of the updated document, pass options: ChangeStreamOptions(fullDocument: .updateLookup) to the watch() method.\n\nTo return the most current majority-committed version of the updated document, pass options: ChangeStreamOptions(fullDocument: .updateLookup) to the watch() method.\n\nResume a Change Stream\n\nChange streams are resumable by specifying a resume token to either resumeAfter or startAfter when opening the cursor.\n\nresumeAfter for Change Streams\n\nYou can resume a change stream after a specific event by passing a resume token to resumeAfter when opening the cursor.\n\nSee Resume Tokens for more information on the resume token.\n\nImportant\n\nThe oplog must have enough history to locate the operation associated with the token or the timestamp, if the timestamp is in the past.\n\nYou cannot use resumeAfter to resume a change stream after an invalidate event (for example, a collection drop or rename) closes the stream. Instead, you can use startAfter to start a new change stream after an invalidate event .\n\nIn the example below, the resumeAfter option is appended to the stream options to recreate the stream after it has been destroyed. Passing the _id to the change stream attempts to resume notifications starting after the operation specified.\n\nIn the example below, the resumeToken is retrieved from the last change stream document and passed to the Watch() method as an option. Passing the resumeToken to the Watch() method directs the change stream to attempt to resume notifications starting after the operation specified in the resume token.\n\nYou can use ChangeStreamOptions.SetResumeAfter to specify the resume token for the change stream. If the resumeAfter option is set, the change stream resumes notifications after the operation specified in the resume token. The SetResumeAfter takes a value that must resolve to a resume token, e.g. resumeToken in the example below.\n\nYou can use the resumeAfter() method to resume notifications after the operation specified in the resume token. The resumeAfter() method takes a value that must resolve to a resume token, e.g. resumeToken in the example below.\n\nYou can use the resume_after modifier to resume notifications after the operation specified in the resume token. The resume_after modifier takes a value that must resolve to a resume token, e.g. resume_token in the example below.\n\nresume_token = cursor.resume_tokencursor = db.inventory.watch(resume_after=resume_token)document = await cursor.next()\n\nYou can use the resumeAfter option to resume notifications after the operation specified in the resume token. The resumeAfter option takes a value that must resolve to a resume token, e.g. resumeToken in the example below.\n\nYou can use the resumeAfter option to resume notifications after the operation specified in the resume token. The resumeAfter option takes a value that must resolve to a resume token, e.g. $resumeToken in the example below.\n\nYou can use the resume_after modifier to resume notifications after the operation specified in the resume token. The resume_after modifier takes a value that must resolve to a resume token, e.g. resume_token in the example below.\n\nresume_token = cursor.resume_tokencursor = db.inventory.watch(resume_after=resume_token)next(cursor)\n\nYou can use the resume_after modifier to resume notifications after the operation specified in the resume token. The resume_after modifier takes a value that must resolve to a resume token, e.g. resume_token in the example below.\n\nYou can use the resumeAfter option to resume notifications after the operation specified in the resume token. The resumeAfter option takes a value that must resolve to a resume token, e.g. resumeToken in the example below.\n\nYou can use the resumeAfter option to resume notifications after the operation specified in the resume token. The resumeAfter option takes a value that must resolve to a resume token, e.g. resumeToken in the example below.\n\nstartAfter for Change Streams\n\nYou can start a new change stream after a specific event by passing a resume token to startAfter when opening the cursor. Unlike resumeAfter, startAfter can resume notifications after an invalidate event by creating a new change stream.\n\nSee Resume Tokens for more information on the resume token.\n\nImportant\n\nThe oplog must have enough history to locate the operation associated with the token or the timestamp, if the timestamp is in the past.\n\nResume Tokens\n\nThe resume token is available from multiple sources:\n\nSource\n\nDescription\n\nEach change event notification includes a resume token on the _id field.\n\nThe getMore command includes a resume token on the cursor.postBatchResumeToken field.\n\nStarting in MongoDB 4.2, change streams will throw an exception if the change stream aggregation pipeline modifies an event's _id field.\n\nTip\n\nMongoDB provides a \"snippet\", an extension to mongosh, that decodes hex-encoded resume tokens.\n\nYou can install and run the resumetoken snippet from mongosh:\n\nsnippet install resumetokendecodeResumeToken('<RESUME TOKEN>')\n\nYou can also run resumetoken from the command line (without using mongosh) if npm is installed on your system:\n\nnpx mongodb - resumetoken - decoder <RESUME TOKEN>\n\nSee the following for more details on:\n\nresumetoken\n\nusing snippets in mongosh.\n\nResume Tokens from Change Events\n\nChange event notifications include a resume token on the _id field:\n\nResume Tokens from aggregate\n\nWhen using the aggregate command, the $changeStream aggregation stage includes a resume token on the cursor.postBatchResumeToken field:\n\nResume Tokens from getMore\n\nThe getMore command also includes a resume token on the cursor.postBatchResumeToken field:\n\nUse Cases\n\nChange streams can benefit architectures with reliant business systems, informing downstream systems once data changes are durable. For example, change streams can save time for developers when implementing Extract, Transform, and Load (ETL) services, cross-platform synchronization, collaboration functionality, and notification services.\n\nAccess Control\n\nFor deployments enforcing Authentication and authorization :\n\nTo open a change stream against specific collection, applications must have privileges that grant changeStream and find actions on the corresponding collection.\n\n{ resource: { db: < dbname > , collection: < collection > } , actions: [ \"find\", \"changeStream\" ] }\n\nTo open a change stream on a single database, applications must have privileges that grant changeStream and find actions on all non-system collections in the database.\n\n{ resource: { db: < dbname > , collection: \"\" } , actions: [ \"find\", \"changeStream\" ] }\n\nTo open a change stream on an entire deployment, applications must have privileges that grant changeStream and find actions on all non-system collections for all databases in the deployment.\n\n{ resource: { db: \"\", collection: \"\" } , actions: [ \"find\", \"changeStream\" ] }\n\nEvent Notification\n\nChange streams only notify on data changes that have persisted to a majority of data-bearing members in the replica set. This ensures that notifications are triggered only by majority-committed changes that are durable in failure scenarios.\n\nFor example, consider a 3-member replica set with a change stream cursor opened against the primary. If a client issues an insert operation, the change stream only notifies the application of the data change once that insert has persisted to a majority of data-bearing members.\n\nIf an operation is associated with a transaction, the change event document includes the txnNumber and the lsid.\n\nCollation\n\nChange streams use simple binary comparisons unless an explicit collation is provided.\n\nChange Streams and Orphan Documents\n\nStarting in MongoDB 5.3, during range migration, change stream events are not generated for updates to orphaned documents .\n\nChange Streams with Document Pre- and Post-Images\n\nStarting in MongoDB 6.0, you can use change stream events to output the version of a document before and after changes (the document pre- and post-images):\n\nThe pre-image is the document before it was replaced, updated, or deleted. There is no pre-image for an inserted document.\n\nThe post-image is the document after it was inserted, replaced, or updated. There is no post-image for a deleted document.\n\nEnable changeStreamPreAndPostImages for a collection using db.createCollection(), create, or collMod.\n\nPre- and post-images are not available for a change stream event if the images were:\n\nNot enabled on the collection at the time of a document update or delete operation.\n\nRemoved after the pre- and post-image retention time set in expireAfterSeconds.\n\nThe following example sets expireAfterSeconds to 100 seconds on an entire cluster:\n\nuse admindb.runCommand( { setClusterParameter: { changeStreamOptions: { preAndPostImages: { expireAfterSeconds: 100 } } }} )\n\nThe following example returns the current changeStreamOptions settings, including expireAfterSeconds:\n\ndb.adminCommand( { getClusterParameter: \"changeStreamOptions\" } )\n\nSetting expireAfterSeconds to off uses the default retention policy: pre- and post-images are retained until the corresponding change stream events are removed from the oplog .\n\nIf a change stream event is removed from the oplog, then the corresponding pre- and post-images are also deleted regardless of the expireAfterSeconds pre- and post-image retention time.\n\nAdditional considerations:\n\nEnabling pre- and post-images consumes storage space and adds processing time. Only enable pre- and post-images if you need them.\n\nLimit the change stream event size to less than 16 megabytes. To limit the event size, you can:\n\nLimit the document size to 8 megabytes. You can request pre- and post-images simultaneously in the change stream output if other change stream event fields like updateDescription are not large.\n\nRequest only post-images in the change stream output for documents up to 16 megabytes if other change stream event fields like updateDescription are not large.\n\nRequest only pre-images in the change stream output for documents up to 16 megabytes if:\n\ndocument updates affect only a small fraction of the document structure or content, and\n\ndo not cause a replace change event. A replace event always includes the post-image.\n\nTo request a pre-image, you set fullDocumentBeforeChange to required or whenAvailable in db.collection.watch(). To request a post-image, you set fullDocument using the same method.\n\nPre-images are written to the config.system.preimages collection.\n\nThe config.system.preimages collection may become large. To limit the collection size, you can set expireAfterSeconds time for the pre-images as shown earlier.\n\nPre-images are removed asynchronously by a background process.\n\nImportant\n\nBackward-Incompatible Feature\n\nStarting in MongoDB 6.0, if you are using document pre- and post-images for change streams, you must disable changeStreamPreAndPostImages for each collection using the collMod command before you can downgrade to an earlier MongoDB version.\n\nTip\n\nSee also:\n\nFor change stream events and output, see Change Events .\n\nTo watch a collection for changes, see db.collection.watch().\n\nFor complete examples with the change stream output, see Change Streams with Document Pre- and Post-Images .\n\nFor complete examples with the change stream output, see Change Streams with Document Pre- and Post-Images ."
    }
}