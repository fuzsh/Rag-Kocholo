{
    "id": "yago_19693_3",
    "rank": 19,
    "data": {
        "url": "https://qasim-khawaja.medium.com/my-top-3-takeaways-from-donald-knuths-the-art-of-computer-programming-vol-1-68dab918122f",
        "read_more_link": "",
        "language": "en",
        "title": "My Top 3 Takeaways from Donald Knuth’s The Art of Computer Programming Vol. 1",
        "top_image": "https://miro.medium.com/v2/resize:fit:960/1*aJfoGBP35aAlN9xDsTyu5Q.jpeg",
        "meta_img": "https://miro.medium.com/v2/resize:fit:960/1*aJfoGBP35aAlN9xDsTyu5Q.jpeg",
        "images": [
            "https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:88:88/1*lWRrAT0VcKDnOleTaPepxw.jpeg",
            "https://miro.medium.com/v2/resize:fill:144:144/1*lWRrAT0VcKDnOleTaPepxw.jpeg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Qasim Khawaja",
            "qasim-khawaja.medium.com"
        ],
        "publish_date": "2020-07-24T23:34:26.428000+00:00",
        "summary": "",
        "meta_description": "A couple of months ago, I came across a lecture on the Analysis of Algorithms taught by Stanford Professor Donald Knuth. The topics covered in that 1-hour lecture genuinely piqued my interest and…",
        "meta_lang": "en",
        "meta_favicon": "https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19",
        "meta_site_name": "Medium",
        "canonical_link": "https://qasim-khawaja.medium.com/my-top-3-takeaways-from-donald-knuths-the-art-of-computer-programming-vol-1-68dab918122f",
        "text": "The Art of Computer Programming Vol. 1 | Fundamental Algorithms\n\nThis book series is overwhelmingly impressive; it has now been over 50 years since it was initially published, and this text is still considered the “magnum opus” of computer science. Renowned scientists have called it the bible of all the fundamental algorithms. Although Knuth published the first edition in the 60s, the underlying concepts remain timeless.\n\nI should note that the programming examples in this book all use the MIX assembly language for the hypothetical MIX computer, which I will cover briefly later on, and also include many types of algorithms along with their comprehensive analysis. I found the challenge of learning an assembly language very rewarding, and an excellent reason on its own to read through this book, the in-depth study of algorithms was fascinating as well.\n\nThe exercises in this book also take you throughout multiple levels of expertise; the problems start easy with warm-ups and progress in difficulty as they go into research problems that are still unsolved.\n\nFun fact: At the end of volume 1, there is a very popular blurb by Bill Gates:\n\n“You should definitely send me a résumé if you can read the whole thing.”\n\nIf a co-sign from Bill Gates himself doesn’t justify reading this, I don’t know what else will.\n\nNow I’ll discuss the three major takeaways that I had from reading so far:\n\nTopic 1: Analysis of an Algorithm and Asymptotic notation\n\nMathematical Induction\n\nBefore getting into details, let’s first talk about mathematical induction, which is a potent technique of mathematical proof that demonstrates the validity of a statement for all the natural numbers.\n\nProof by mathematical induction consists of two main steps:\n\nThe (base case): prove that the statement holds for the first natural number n. This is usually, n = 0 or n = 1.\n\nThe induction step: prove that, if the statement is true for some natural number n, then the statement is true for n + 1.\n\nA simple example to illustrate this is to imagine a line of dominos:\n\nIf the first domino falls, and\n\nif any domino (n) in the chain that falls, causes the next domino in line (n+1) to fall,\n\nproves that all dominos will fall.\n\nIn computing science, mathematical induction is used in an analysis of an algorithm to prove that the concerned algorithm correctly performs as expected (correction) by taking a certain amount of time (complexity).\n\nIt’s one of the most critical and vital concepts in computer programming because each program should work correctly in the least possible time.\n\nIt’s also exciting to notice that one program performs better than the other while solving the same problem. To analyze the efficiency of a program, computer scientists use different techniques. Moreover, advanced programs are developed based on different, well-proven algorithms. The process of analyzing the problem-solving capabilities of a specific algorithm is known as the analysis of the algorithm.\n\nAnalysis of an Algorithm\n\nThere are different ways to approach an analysis of an algorithm, including quantitative mathematical analysis\n\nSome essential steps for analyzing an algorithm include:\n\nComplete implementation of the algorithm\n\nIdentifying all the possible quantities to describe the execution frequency of all the necessary operations\n\nCreating a realistic input model to program\n\nCalculation of space and time complexities\n\nAn example of a straightforward algorithm that Knuth analyzes in the book is the algorithm for finding the max integer in a list of integers. Here is a flowchart for this algorithm.\n\nTo analyze, let’s break down the number of times each step is executed with an input of size n.\n\n+======+========================+\n\n| Step | Frequency of Execution |\n\n+======+========================+\n\n| 1 | 1 |\n\n+------+------------------------+\n\n| 2 | n |\n\n+------+------------------------+\n\n| 3 | n-1 |\n\n+------+------------------------+\n\n| 4 | A |\n\n+------+------------------------+\n\n| 5 | n-1 |\n\n+------+------------------------+\n\nThe only quantity that remains to be analyzed is ‘A,’ which is determined by the input.\n\nWe must determine the maximum, minimum, average, and the standard deviation of this value.\n\nThe maximum and minimum values for A are easy to determine for this algorithm; the max value for A is n-1, in the case that the list is in descending order, where every iteration will reassign the m value, and the minimum is zero when X[n] is the maximum value.\n\nTo determine the average value, we first need to determine the characteristics of the input. In this example, we assume that all the values of X are distinct and each of the n! permutations of these values are equally likely to occur.\n\nSo in the case that n = 3. There are six possible arrangements of the values in X.\n\n+================+========+===============+\n\n| Situation | Step 4 | “A” value |\n\n+================+========+===============+\n\n| X[1]<X[2]<X[3] | N/A | 0(Minimum) |\n\n+----------------+--------+---------------+\n\n| X[1]<X[3]<X[2] | m<-X[2]| 1 |\n\n+----------------+--------+---------------+\n\n| X[2]<X[1]<X[3] | N/A | 0(Minimum) |\n\n+----------------+--------+---------------+\n\n| X[2]<X[3]<X[1] | m<-X[1]| 1 |\n\n+----------------+--------+---------------+\n\n| X[3]<X[2]<X[1] | m<-X[2]| |\n\n| | m<-X[1]| 2(Max) |\n\n+----------------+--------+---------------+\n\n| X[3]<X[1]<X[2] | m<-X[3]| 1 |\n\n+----------------+--------+---------------+**THIS TABLE MAY NOT SHOW UP CORRECTLY ON A PHONE SCREEN**\n\nSo when n=3, the average A count is ( 0+1+0+1+2+1)/6 = 5/6\n\nGeneralizing this for n, we must realize that the probability of A being k is\n\npₙₖ = (the number of times A=k for n! objects) divided by n!\n\nFor example:\n\np₃₁= (2)/3! = ⅓\n\np₃₀ = (3)/3! = ½\n\np₃₂ = (1)/3! = ⅙\n\nThe formula for the average of A is found to be\n\nAₙ =∑ₖkpₙₖ\n\nTo verify\n\nA₃ =∑ₖkpₙₖ= 0*⅓+ 1*½+2*⅙ = 5/6\n\nThat’s as far as I will go into the analysis; however, Dr. Knuth’s review is a lot more comprehensive and thorough. To see the complete study, check out the book or his lecture, and I hope like me, you also appreciate how algorithms are quantifiably analyzed and studied.\n\nAsymptotic analysis is a type of algorithm analysis that approximates the solution for large values of n for input sizes. Often it’s more helpful to know that the complexity of an algorithm is O(n²) rather than 4n²+2n.\n\nAsymptotic notations are expressions that denote the complexity of algorithms.\n\nThe O-notation and the Big-O notation are asymptotic notations, which, as mentioned earlier, are used to find the complexity of an algorithm. These expressions indicate the relationship between the necessary operations (steps) needed to execute an algorithm and the size of the input provided to the algorithm. As the name suggests, O(n) denotes the expression, where n represents the input’s size.\n\nAlthough not covered in this volume, sorting algorithms are important for understanding this notation and easily comparing their different types.\n\nSome of the most common sorting algorithms with their complexities are as followed:\n\nMerge Sort: The efficiency of the merge sort is way better with more massive data sets, and programmers generally use it when they have to deal with large amounts of data. The complexities of Merge Sort are listed below.\n\nWorst Case O(n log n)\n\nBest Case O(n) natural variant, O(n log n) typical\n\nAverage Case O(n log n)\n\nQuick Sort: It is by far the most efficient and most used sorting algorithm, and it works best with smaller data sets. The complexities of Quick Sort are as followed:\n\nWorst Case O(n²)\n\nBest Case O(n log n)\n\nAverage Case O(n log n)\n\nBubble Sort: It is one of the less used sorting algorithms, and its complexities are as followed:\n\nWorst Case O(n²)\n\nBest Case O(n)\n\nAverage Case O(n²)\n\nInsertion Sort: It is yet another stable and faster sorting algorithm for small data sets, and its complexities are listed below:\n\nWorst Case О(n)\n\nBest Case O(n)\n\nAverage Case О(n²)\n\nTopic 2: Information Structures (Linear Lists and Trees)\n\nInformation Structures are my second key takeaway from The Art of Computer Programming Vol 1. because of their usefulness and countless applications in computer sciences. The two main information structures discussed in the book are linear lists and trees.\n\nLinear Lists\n\nLinear lists are a data structure(information structure) that stores a sequence of nodes. The elements of a linear list are ordered in a linear sequential way.\n\nThere are three important types of linear lists:\n\nStack\n\nA stack is one type of linear list, and it works on LIFO (Last in First out) functionality. This means that it has a common inserting (push) and exiting (pop) point. If we push the data into the stack one by one, the first item that we pushed will be the last one to pop. The item that accessible from the stack at any point is the youngest item inserted also referred to as the top of the stack. And the last item is the oldest item inserted into the stack, this is referred to as the bottom. In the book, a railway analogy is used to visualize a stack, but I prefer to stick with the visual of this toy.\n\nStacks are fairly common in computer programming in conjunction with recursive algorithms, an example being the Javascript Call Stack.\n\nQueues\n\nThis is another type of linear list. As the name would imply, Queues work on FIFO (First in First out) approach and items can only be inserted (Enqueued) from one end(rear) and deleted (Dequeued) from the other (front).\n\nQueues are also fairly common in computer programming, an example would be the Javascript Callback Queue.\n\nDeque\n\nThis type of linear list is a bit more general because it behaves like a “double-ended” queue. It has two open ends, where items can be inserted and deleted. The two ends are referred to as the left and right of a deque. Deques are also distinguished by being defined as output restricted or input restricted, this assertion limits the insertion and deletion to occur at one end.\n\nSequential Allocation\n\nThis is the most obvious way to store a linear list. It is a type of allocation where we store the nodes in sequence in memory, starting at some base address.\n\nLinked Allocation\n\nIn this type of allocation, the linear list does not have to be stored sequentially in memory, but instead, it is possible to store the nodes in the list in arbitrary locations in memory and retain access to the list by managing at least two pieces of information in one node (data and reference to the next node). This allocation takes up more memory but evidently it allows for easier insertion and deletion into the list.\n\nHere is an application of Linked Allocation:\n\nTrees\n\nTrees are nonlinear ways to save data in a hierarchical data structure, and they are especially useful for complex problems.\n\nThe most common properties of trees are:\n\nNodes\n\nPointer (one or more)\n\nBinary Tree\n\nBinary Trees are the most common hierarchical data structure, and in the binary tree, each node has two children (left and right). Each node of the binary tree contains the following component.\n\nPointer to the right child\n\nPointer to left child\n\nData\n\nTraversing a Binary Tree\n\nTraversing the tree means that you have visited all the nodes systematically in a tree at least once. There are three basic types of tree traversal.\n\nPreorder\n\nInorder\n\nPostorder\n\nSome types of tree structures are as followed:\n\nGeneral Tree\n\nBinary Tree (covered)\n\nAVL Tree\n\nRed-Black Tree\n\nN-ary Tree\n\nTopic 3: The Basics of How a Computer Works\n\n(This Section is Under Construction. You may skip this)\n\nTo put it simply, a computer receives data via the input device with the instructions to act, and it displays the results on the output device.\n\nRegister\n\nThese are the storage locations in an internal memory of the computers which are dedicated to speed up the operations of the processors.\n\nThere are always a limited number of registers stores the data elements, and they do not need to access the memory for processing.\n\nWord\n\nThe basic unit of data in MIX is a byte. A word is a piece of data with a fixed number of bytes, which is managed by the processor hardware instruction set as a unit. The most important properties of the word for particular computer architecture or processor are as followed:\n\nSize\n\nWidth\n\nLength\n\nMIX Computer\n\nIt is a hypothetical computer, envisioned by Donald Knuth in The Art of Computer Programming Vol 1, its model number is 1009 (sum of the model numbers of 16 other similar computers.) It is neither a fully decimal nor a binary machine, this peculiar property allows algorithms written on the MIX computer to be simulated in any type of machine with slight modification.\n\nDifferent Parts of the MIX Computer\n\n9 main registers: rA, rX, rI1, rI2, rI3, rI4, rI5, rI6, rJ\n\nrA accumulator register\n\nrX extension register\n\nrI1 — rI6 are index registers\n\nrJ holds the jump address\n\nMemory and input/output devices, including Tape units, Disk or drum units, Card reader, Typewriter terminal.\n\nInstructions which occupy the word\n\nHow Computer Executes a Program\n\nWe all use computers, but have you ever wondered how the programs in it are executed? Here’s how.\n\nThere is an instruction sequence stored in the memory with all the functionalities to perform.\n\nFrom that instruction sequence that memory address is copied which points to the first instruction\n\nThat address is sent to the memory in the program counter by the CPU through an address bus.\n\nThe memory sends a copy of the bits’ state on the data bus at the location.\n\nThe CPU takes a copy of that information into the instruction register\n\nThe pointer, which represents the instruction, is incremented to the next address for the next memory instruction.\n\nThe instruction is executed in the instruction register by the CPU\n\nBottom Line\n\nThe theories that back up Computing Science are numerous. This book does an impressive job of introducing the reader to essential concepts to build a foundational understanding of this field.\n\nIf you are a programming enthusiast, then I hope this discussion attracted you. If I missed something important or if you have any questions, please feel free to reach out to me in the comments below.\n\nFor more discussion, you can also join my other social media pages through the following links.\n\nLinkedin: https://www.linkedin.com/in/qkhawaja"
    }
}