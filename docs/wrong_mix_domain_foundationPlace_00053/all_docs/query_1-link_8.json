{
    "id": "wrong_mix_domain_foundationPlace_00053_1",
    "rank": 8,
    "data": {
        "url": "https://research.cs.aalto.fi/theory/seminar/seminar.html",
        "read_more_link": "",
        "language": "en",
        "title": "Helsinki CS Theory Seminar",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "29 May 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Teemu Hankala:\n\nComplexity of Neural Network Training and ETR: Extensions with Effectively Continuous Functions The training problem of neural networks (NNs) is known to be existsR-complete with respect to ReLU and linear activation functions. We show that the training problem for NNs equipped with arbitrary activation functions is polynomial-time bireducible to the existential theory of the reals extended with the corresponding activation functions. For effectively continuous activation functions (e.g., the sigmoid function), we obtain an inclusion to low levels of the arithmetical hierarchy. Consequently, the sigmoid activation function leads to the existential theory of the reals with the exponential function, and hence the decidability of training NNs using the sigmoid activation function is equivalent to the decidability of the existential theory of the reals with the exponential function, a long-standing open problem. In contrast, we obtain that the training problem is undecidable if sinusoidal activation functions are considered. 22 May 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Rishikesh Gajjala:\n\nA combinatorial approach to weighted model counting Weighted model counting consists of computing the weighted sum of all satisfying assignments of a propositional formula. It is a very well-studied area with applications in probabilistic reasoning, network reliability estimation, statistical physics, program synthesis, and system verification. One of the state-of-the-art approaches to solving weighted model counting is to reduce it to unweighted model counting. The following question arises from such reductions: âCan one construct a monotone DNF with few terms which has exactly n solutions?â. This problem is equivalent to a natural combinatorial question of finding the smallest antichain, which generates an ideal (also known as downsets or monotone decreasing families or abstract simplicial complexes) of size $n$. In this work, we prove that we can always construct such monotone DNFs using at most $O(\\sqrt{\\log{n}}\\log\\log{n})$ terms. We also prove that there exists infinitely many $n\\in \\mathbb{N}$ for which to construct any monotone DNF, we require at least $\\Omega(\\log\\log{n})$ terms.\n\nJoint work with L. Sunil Chandran and Kuldeep S. Meel.\n\n15 May 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Petteri Kaski:\n\nA universal sequence of tensors for the asymptotic rank conjecture The exponent $\\sigma(T)$ of a tensor $T\\in\\mathbb{F}^d\\otimes\\mathbb{F}^d\\otimes\\mathbb{F}^d$ over a field $\\mathbb{F}$ captures the base of the exponential growth rate of the tensor rank of $T$ under Kronecker powers. Tensor exponents are fundamental from the standpoint of algorithms and computational complexity theory; for example, the exponent $\\omega$ of matrix multiplication can be characterized as $\\omega=2\\sigma(\\mathrm{MM}_2)$, where $\\mathrm{MM}_2\\in\\mathbb{F}^4\\otimes\\mathbb{F}^4\\otimes\\mathbb{F}^4$ is the tensor that represents $2\\times 2$ matrix multiplication.\n\nOur main result is an explicit construction of a sequence $\\mathcal{U}_d$ of zero-one-valued tensors that is universal for the worst-case tensor exponent; more precisely, we show that $\\sigma(\\mathcal{U}_d)=\\sigma(d)$ where $\\sigma(d)=\\sup_{T\\in\\mathbb{F}^d\\otimes\\mathbb{F}^d\\otimes\\mathbb{F}^d}\\sigma(T)$. We also supply an explicit universal sequence $\\mathcal{U}_\\Delta$ localised to capture the worst-case exponent $\\sigma(\\Delta)$ of tensors with support contained in $\\Delta\\subseteq [d]\\times[d]\\times [d]$; by combining such sequences, we obtain a universal sequence $\\mathcal{T}_d$ such that $\\sigma(\\mathcal{T}_d)=1$ holds if and only if Strassen's asymptotic rank conjecture [Progr. Math. 120 (1994)] holds for $d$. Finally, we show that the limit $\\lim_{d\\rightarrow\\infty}\\sigma(d)$ exists and can be captured as $\\lim_{d\\rightarrow\\infty} \\sigma(D_d)$ for an explicit sequence $(D_d)_{d=1}^\\infty$ of tensors obtained by diagonalisation of the sequences $\\mathcal{U}_d$. As our second result we relate the absence of polynomials of fixed degree vanishing on tensors of low rank, or more generally asymptotic rank, with upper bounds on the exponent $\\sigma(d)$. Using this technique, one may bound asymptotic rank for all tensors of a given format, knowing enough specific tensors of low asymptotic rank.\n\nJoint work with Mateusz Michałek.\n\narXiv 8 May 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Okko Makkonen:\n\nAlgebraic methods in homomorphic secret sharing Secret sharing is a way of distributing a secret value to a group of users such that the secret is not revealed to any sufficiently small subset of users. The privacy guarantee in applications such as private information retrieval and secure distributed computation is based on linear secret sharing schemes that allow for computation on the data. Homomorphic secret sharing is a method of doing secret sharing that allows for computations on the secret value to be performed locally by the users. In this talk, we look at some algebraic methods of constructing homomorphic secret sharing schemes with applications in private information retrieval. In particular, we aim to reduce the field size requirements of such schemes by utilizing codes over algebraic curves.\n\nThis is joint work with David Karpuk and Camilla Hollanti.\n\n2 May 2024\n\n14:00 (Helsinki time)\n\nLocation: TU4, Maarintie 8 Zhuan Khye Koh:\n\nA strongly polynomial algorithm for the minimum cost generalized flow problem We give a strongly polynomial algorithm for minimum cost generalized flow, and as a consequence, for all linear programs with at most two variables per inequality. Previously, strongly polynomial algorithms were only known for the primal and dual feasibility problems. Our approach is to show that the path-following interior point method of Allamigeon et al. â22 terminates in a strongly polynomial number of iterations for minimum cost generalized flow. We achieve this by bounding the âstraight line complexityâ of the central path, which is the minimum number of pieces required by a piecewise affine curve to multiplicatively approximate the central path.\n\nBased on joint work with Daniel Dadush, Bento Natura, Neil Olver and LÃ¡szlÃ³ VÃ©gh.\n\n24 April 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Nicola Cotumaccio:\n\nSorting Automata and Regular Languages We present a new paradigm in graph compression and formal language theory. We show that the ideas behind some of the most important data structures for compressing and indexing strings --- such as the suffix array, the Burrows-Wheeler Transform and the FM-index --- are much more general and provide a new approach to studying automata and regular languages, which retrospectively explains the impact of these data structures. We classify all automata and all regular languages by their propensity to be sorted. Our classification represents a useful parameterization simultaneously for diverse automata-related measures: (i) the encoding bit-complexity of automata/labeled graphs, (ii) the complexity of operations on regular languages (e.g. membership) and on labeled graphs (e.g. pattern matching), (iii) the complexity of NFA determinization by the powerset-construction algorithm. To the best of our knowledge, ours is the only parameterization of automata/labeled graphs capturing simultaneously all these aspects. We show that our parameterization has deep and unexpected consequences both in data compression (encoding, pattern matching) and in automata theory (nondeterminism, entanglement, minimization). 17 April 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 SÃ¡ndor Kisfaludi-Bak:\n\nSeparator Theorem and Algorithms for Planar Hyperbolic Graph The hyperbolicity of a graph, informally, measures how close a graph is (metrically) to a tree. Hence, it is intuitively similar to treewidth, but the measures are formally incomparable. The main topic of the talk is a novel balanced separator theorem for planar delta-hyperbolic graphs that is substantially stronger than the classic planar separator theorem. For any fixed delta>=0, we can find a small balanced separator that induces either a single geodesic (shortest) path or a single geodesic cycle in the graph, which guarantees that each separated part plus the separator induces a (planar) delta-hyperbolic graph.\n\nAs an application of our separator theorem, we will see that both Independent Set and TSP have near-linear time FPTASes in planar delta-hyperbolic graphs for any constant delta, running in Ã(n)* 2^{O(delta^2)} / eps^{O(delta)} time. For Independent Set this running time is essentially tight under the Exponential Time Hypothesis (ETH).\n\narXiv 10 April 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Jara Uitto:\n\nDeterministic (1 + epsilon)-Approximation Algorithm for Maximum Matching with polynomial (in epsilon) Passes in the Semi-Streaming Model We consider the classic maximum cardinality matching problem in the semi-streaming model. In the streaming model, the input graph G = (V, E) is considered to be significantly larger than the available random access memory. The input is presented to the algorithm as a stream of edges and, at any given time, the algorithm is only able to store O(|V| log |V|) bits of information. A semi-streaming algorithm is allowed to make several passes over the edge-stream but, ideally, should commit to a solution after a constant number of passes.\n\nIn his seminal work in 2005, McGregor presented a randomized (1 + epsilon)-approximation algorithm for matching that requires an exponential (in epsilon) number of passes. After McGregor's result, Eggert et al. presented a deterministic algorithm with polynomial number of passes for bipartite graphs. Later, Tirodkar gave an exponential deterministic algorithm for general graphs. However, McGregor's algorithm remained the fastest for general graphs. In our work, we discovered an algorithm that reaches a polynomial number of passes for general graphs yielding an exponential improvement over the previous work. Satisfyingly, our algorithm is also deterministic.\n\n3 April 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Juha Harviainen:\n\nBayesian Network Learning with Narrow Precedence Constraint Graph Bayesian networks are probabilistic graphical models whose structure is represented as a directed acyclic graph (DAG). Finding the optimal network structure is a computationally hard task, but it can be made easier with constraints obtained from expert knowledge. These constraints can come in the form of precedence constraints which define a partial order that the structure must obey. When the constraints are compiled into a DAG, the complexity of learning with precedence constraints is connected to the number of ideals of the constraint graph. Taking the path cover number of the constraint graph as a parameter, we extend earlier results to the problems of sampling and weighted counting of network structures. We also consider the problems with a stronger type of precedence constraints, positive ancestral constraints, which state that a node must be an ancestor of another. With these constraints, we give efficient algorithms for the problems under the additional assumption that the constraint graph has only a small number of incomparable edges.\n\nJoint work with Pekka Parviainen.\n\n27 March 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Sorrachai Yingchareonthawornchai:\n\nFaster Deterministic Vertex Connectivity Algorithms An $n$-vertex $m$-edge graph is $k$-vertex connected if it cannot be disconnected by deleting less than $k$ vertices. After more than half a century of intensive research, the result by [Li et al. STOC'21] finally gave a randomized algorithm for checking $k$-connectivity in near-optimal $\\widehat{O}(m)$ time where $\\widehat{O}(\\cdot)$ to hide an $n^{o(1)}$ factor. Deterministic algorithms, unfortunately, have remained much slower even if we assume a linear-time max-flow algorithm: they either require at least $\\Omega(mn)$ time [Even'75; Henzinger Rao and Gabow, FOCS'96; Gabow, FOCS'00] or assume that $k=o(\\sqrt{\\log n})$ [Saranurak and Yingchareonthawornchai, FOCS'22].\n\nIn this talk, I will describe a deterministic algorithm for checking $k$-vertex connectivity in time proportional to making $\\min\\{k^2, n\\}$ max-flow calls, and, hence, in $\\widehat{O}(m\\min\\{k^{2},n\\})$ time using the deterministic max-flow algorithm by [Brand et al. FOCS'23]. Our algorithm gives the first almost-linear-time bound for all $k$ where $\\sqrt{\\log n}\\le k\\le n^{o(1)}$ and subsumes up to a sub-polynomial factor the long-standing state-of-the-art algorithm by [Even'75] which requires $O(n+k^{2})$ max-flow calls. For large $k$, the algorithm runs in $\\widehat O(mn)$ time, which improves over the state-of-the-art deterministic $\\widehat{O}(mn^{1.5})$-time algorithm [Gabow, FOCS'00]. Our key technique is based on Ramanujan expanders and derandomization of the kernelization technique of [Li et al. STOC'21] for which their kernel construction was randomized.\n\nJoint work with Yonggang Jiang, Chaitanya Nalam, and Thatchaphol Saranurak.\n\n6 March 2024\n\n14:00 (Helsinki time)\n\nLocation: T5, Konemiehentie 2 Lasse LeskelÃ¤:\n\nCommunity recovery from temporal and higher-order network interactions Community recovery is the task of learning a latent community structure from interactions in a population of N nodes. Efficient algorithms for sparse binary pairwise interaction data are well known, and so are their consistency properties with respect to data sampled from the stochastic block model (SBM), the canonical model for random graphs with a community structure. Instead of a binary variable indicating whether or not an interaction occurs, we often also observe a category, value, or shape of an interaction. This motivates the definition of a generalised SBM in which interactions can be of arbitrary type, including categorical, numeric, and vector-valued, and not excluding even more general objects such as Markov chains or Poisson processes. For this model, I will discuss information-theoretic bounds which characterise the existence of consistent estimators in terms of data sparsity, statistical similarity between intra- and inter-block interaction distributions, and the shape and size of the interaction space. Temporal networks with time-correlated interaction patterns of length T provide an important model instance, for which consistency can be analysed with respect to either N or T, or both, approaching infinity. Time permitting, I will also highlight recent findings and open problems related to data sets involving higher-order interactions which can be modelled using hypergraph stochastic block models.\n\nJoint work with Konstantin Avrachenkov and Maximilien Dreveton.\n\n7 February 2024\n\n14:00 (Helsinki time)\n\nLocation: AS6, Maarintie 8 Shreyas Pai:\n\nTime and Space Optimal Massively Parallel Algorithm for the 2-Ruling Set Problem In this talk, we present a constant-round algorithm for the 2-ruling set problem in the MPC model with linear space-per-machine and optimal total space. Our results improve on the O(log log log n)-round algorithm by [HPS, DISC'14] and the O(log log Î)-round algorithm by [GGKMR, PODC'18]. Our techniques can be applied to the Congested Clique model to obtain a constant round algorithm, and to the semi-streaming model to obtain a constant pass algorithm.\n\nThe main technical contribution is a novel sampling procedure that returns a small subgraph such that almost all nodes in the input graph are adjacent to the sampled subgraph. An MIS on the sampled subgraph provides a 2-ruling set for a large fraction of the input graph. As a technical challenge, we must handle the remaining part of the graph, which might still be relatively large. We overcome this challenge by showing useful structural properties of the remaining graph and show that running our process twice yields a 2-ruling set of the original input graph with high probability.\n\nThe talk is based on a paper that appeared in DISC 2023 and is joint work with MÃ©lanie Cambus, Fabian Kuhn, and Jara Uitto.\n\narXiv 24 January 2024\n\n14:00 (Helsinki time)\n\nLocation: TU6, Maarintie 8 Geert van Wordragen:\n\nA Quadtree, a Steiner Spanner, and Approximate Nearest Neighbours in Hyperbolic Space We propose a data structure in d-dimensional hyperbolic space that can be considered a natural counterpart to quadtrees in Euclidean spaces.\n\nUsing these quadtrees we build geometric spanners. Near-linear size (1+Ïµ)-spanners do not exist in hyperbolic spaces, but we are able to create a Steiner spanner that achieves a spanning ratio of 1+Ïµ with O(n) edges for constant d and Ïµ, using a simple construction that can be maintained dynamically. As a corollary we also get a (2+Ïµ)-spanner (in the classical sense) of the same size, where the spanning ratio 2+Ïµ is almost optimal among spanners of subquadratic size.\n\nFinally, we show that our Steiner spanner directly provides a solution to the approximate nearest neighbour problem: given a point set P in d-dimensional hyperbolic space we build the data structure in O(n log n) time, using O(n) space. Then for any query point q we can find a point pâP that is at most 1+Ïµ times farther from q than its nearest neighbour in P in O(log n) time. Moreover, the data structure is dynamic and can handle point insertions and deletions with update time O(log n).\n\nThis is joint work with SÃ¡ndor Kisfaludi-Bak.\n\narXiv 17 January 2024\n\n14:00 (Helsinki time)\n\nLocation: AS6, Maarintie 8 Augusto Modanese:\n\nTesting Spreading Behavior in Networks with Arbitrary Topologies Inspired by the works of Goldreich and Ron (J. ACM, 2017) and Nakar and Ron (ICALP, 2021), we initiate the study of property testing in dynamic environments with arbitrary topologies. Our focus is on the simplest non-trivial rule that can be tested, which corresponds to the 1-BP rule of bootstrap percolation and models a simple spreading behavior: Every \"infected\" node stays infected forever, and each \"healthy\" node becomes infected if and only if it has at least one infected neighbor. We show various results for both the case where we test a single time step of evolution and where the evolution spans several time steps. In the first, we show that the worst-case query complexity is O(Î/Îµ) or OÌ(nâ¾â/Îµ) (whichever is smaller), where Î and n are the maximum degree of a node and number of vertices, respectively, in the underlying graph, and we also show lower bounds for both one- and two-sided error testers that match our upper bounds up to Î=o(nâ¾â) and Î=O(n1/3), respectively. In the second setting of testing the environment over T time steps, we show upper bounds of O(ÎTâ1/ÎµT) and OÌ(|E|/ÎµT), where E is the set of edges of the underlying graph. All of our algorithms are one-sided error, and all of them are also time-conforming and non-adaptive, with the single exception of the more complex OÌ(nâ¾â/Îµ)-query tester for the case T=2.\n\nThis is joint work with Yuichi Yoshida (NII).\n\narXiv 10 January 2024\n\n14:00 (Helsinki time)\n\nLocation: TU3, Maarintie 8 Tuomas Hakoniemi:\n\nProof complexity meets algebraic circuit complexity - lower bounds for constant-depth refutations Ideal Proof System (IPS), introduced by Grochow and Pitassi, is a strong algebraic proof system that can be used to refute the solvability of systems of polynomial equations. IPS refutations are algebraic circuits, and lower bounds for IPS have an intimate connection with lower bounds in algebraic circuit complexity. In this talk we discuss lower bounds for constant-depth IPS refutations. Our work builds on the breakthrough lower bounds for constant-depth algebraic circuits by Limaye, Srinivasan and Tavenas, and the recent follow-up work by Amireddy, Garg, Kayal, Saha and Thankey that forgoes the hardness escalation step of Limaye, Srinivasan and Tavenas.\n\nThis talk is based on joint works with Nashlen Govindasamy, Nutan Limaye and Iddo Tzameret.\n\n13 December 2023\n\n16:15 (Helsinki time)\n\nLocation: AS3, Maarintie 8 Massimo Equi:\n\nFrom Bit-Parallelism to Quantum String Matching for Labelled Graphs Many problems that can be solved in quadratic time have bit-parallel speed-ups with factor w, where w is the computer word size. A classic example is computing the edit distance of two strings of length n, which can be solved in O(nÂ²/w) time. In a reasonable classical model of computation, one can assume w = Î(log n), and obtaining significantly better speed-ups is unlikely in the light of conditional lower bounds obtained for such problems. In this paper, we study the connection of bit-parallelism to quantum computation, aiming to see if a bit-parallel algorithm could be converted to a quantum algorithm with better than logarithmic speed-up. We focus on string matching in labeled graphs, the problem of finding an exact occurrence of a string as the label of a path in a graph. This problem admits a quadratic conditional lower bound under a very restricted class of graphs (Equi et al. ICALP 2019), stating that no algorithm in the classical model of computation can solve the problem in time O(|P||E|^(1-Îµ)) or O(|P|^(1-Îµ)|E|). We show that a simple bit-parallel algorithm on such restricted family of graphs (level DAGs) can indeed be converted into a realistic quantum algorithm that attains subquadratic time complexity O(|E|â|P|). 29 November 2023\n\n16:15 (Helsinki time)\n\nLocation: AS3, Maarintie 8 Petteri Kaski :\n\nThe Asymptotic Rank Conjecture and the Set Cover Conjecture are not Both True Strassen's asymptotic rank conjecture [Progr. Math. 120 (1994)] claims a strong submultiplicative upper bound on the rank of a three-tensor obtained as an iterated Kronecker product of a constant-size base tensor. The conjecture, if true, most notably would put square matrix multiplication in quadratic time. We note here that some more-or-less unexpected algorithmic results in the area of exponential-time algorithms would also follow. Specifically, we study the so-called set cover conjecture, which states that for any Îµ>0 there exists a positive integer constant k such that no algorithm solves the k-Set Cover problem in worst-case time O((2-Îµ)^n|F|poly(n)). The k-Set Cover problem asks, given as input an n-element universe U, a family F of size-at-most-k subsets of U, and a positive integer t, whether there is a subfamily of at most t sets in F whose union is U. The conjecture was formulated by Cygan, Fomin, Kowalik, Lokshtanov, Marx, Pilipczuk, Pilipczuk, and Saurabh in the monograph Parameterized Algorithms [Springer, 2015], but was implicit as a hypothesis already in Cygan, Dell, Lokshtanov, Marx, Nederlof, Okamoto, Paturi, Saurabh, and WahlstrÃ¶m [CCC 2012, TALG 2016], there conjectured to follow from the Strong Exponential Time Hypothesis. We prove that if the asymptotic rank conjecture is true, then the set cover conjecture is false. Using a reduction by Krauthgamer and Trabelsi [STACS 2019], in this scenario we would also get an O((2-Î´)^n)-time randomized algorithm for some constant Î´>0 for another well-studied problem for which no such algorithm is known, namely that of deciding whether a given $n$-vertex directed graph has a Hamiltonian cycle.\n\nThis is joint work with Andreas BjÃ¶rklund (ITU Copenhagen). arXiv 15 November 2023\n\n16:15 (Helsinki time)\n\nLocation: AS3, Maarintie 8 Francesco dâAmore :\n\nThe Strong Lottery Ticket Hypothesis and the Random Subset Sum Problem The Strong Lottery Ticket Hypothesis (SLTH) posits that randomly-initialized neural networks contain subnetworks (strong lottery tickets) that achieve competitive accuracy when compared to sufficiently small target networks, even those that have been trained. Empirical evidence for this phenomenon was first observed by Ramanujan et al. in 2020, spurring a line of theoretical research: Malach et al. (2020), Pensia et al. (2020), da Cunha et al. (2022), and Burkholz (2022) have analytically proved formulations of the SLTH in various neural network classes and under different hypotheses.\n\nIn this presentation, we provide an overview of the state-of-the-art theoretical research on the SLTH and its connection with the Random Subset Sum (RSS) problem in theoretical computer science. While previous works on the SLTH ensure that the strong lottery ticket can be obtained via unstructured pruning, we demonstrate how recent advances in the multidimensional generalization of the RSS problem can be leveraged to obtain forms of structured pruning. Additionally, we highlight how refining the RSS results would yield tighter formulations of the SLTH. This presentation is based on a joint work with Arthur da Cunha and Emanuele Natale that will be presented at NeurIPS 2023. Paper 26 April 2023\n\n14:15 (Helsinki time)\n\nOnline Goran Zuzic :\n\nUniversal optimality in distributed computing and its connections to diverse areas of theoretical computer science The modern computation and information processing systems shaping our world have become massively distributed, and a fundamental understanding of distributed algorithmics has never been more important. At the same time, despite 40 years of intense study, we often do not have an adequate understanding of the fundamental barriers that rule out the existence of ultra-fast distributed algorithms. This is true even for the most well-studied problems in computer science---including the shortest path, minimum spanning tree, minimum cut, and many other well-known tasks.\n\nIn this talk, I will present a high-level overview of a sequence of papers that give a near-complete answer to the above question. Its culmination is the following pie-in-the-sky result called universal optimality: for all of the tasks mentioned, there exists a single distributed algorithm that, when run on any communication network G, is provably competitive with the fastest algorithm on G.\n\nThe pursuit of universal optimality has led to the development of many new connections between distributed computing and other seemingly unrelated areas of theoretical computer science. Curiously, these connections have been mutually-beneficial and have already led to many breakthroughs not only in distributed computing, but also in the theory of metric embedding, information theory, and oblivious packet routing. I will briefly explore these connections.\n\nLocation: Virtual ( Zoom link ). Join us in A140 (T4) to watch it together. Arxiv 19 April 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Rustam Latypov :\n\nOptimal Deterministic Massively Parallel Connectivity on Forests We show fast deterministic algorithms for fundamental problems on forests in the challenging low-space regime of the well-known Massive Parallel Computation (MPC) model. A recent breakthrough result by Coy and Czumaj [STOC'22] shows that, in this setting, it is possible to deterministically identify connected components on graphs in O(log D + log log n) rounds, where D is the diameter of the graph and n the number of nodes. The authors left open a major question: is it possible to get rid of the additive log log n factor and deterministically identify connected components in a runtime that is completely independent of n?\n\nWe answer the above question in the affirmative in the case of forests. We give an algorithm that identifies connected components in O(log D) deterministic rounds. The total memory required is O(n + m) words, where m is the number of edges in the input graph, which is optimal as it is only enough to store the input graph. We complement our upper bound results by showing that Î©(log D) time is necessary even for component-unstable algorithms, conditioned on the widely believed 1 vs. 2 cycles conjecture. Our techniques also yield a deterministic forest-rooting algorithm with the same runtime and memory bounds.\n\nLocation: A140 (T4)\n\n12 April 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Parinya Chalermsook :\n\nAlgorithms, Extremal Combinatorics, and Rectangles In this talk, I will give an overview of the interplay between extremal combinatorics and algorithms in the context of computing maximum independent set in a graph. At some point, we will shift the attention to specific things like rectangle graphs.\n\nLocation: A140 (T4)\n\n5 April 2023\n\n14:15 (Helsinki time)\n\nOnline Ming Ding:\n\nA Hardness Result for 1-Laplacians and Fast 1-Laplacian Solvers 1-Laplacians or higher-dimensional Laplacians generalize graph Laplacians to higher-dimensional simplicial complexes and are crucial in computational topology and topological data analysis. It is known that nearly-linear time solvers exist for graph Laplacians. However, nearly-linear time solvers for 1-Laplacians are only known for restricted classes of complexes.\n\nIn this talk, I will present 1-Laplacians in two aspects. In the aspect of the lower bound, a hardness result for 1-Laplacians shows that linear equations in 1-Laplacians are as hard to solve as general linear equations. More precisely, for any constant c â¥ 1, if we can solve linear equations in 1-Laplacians up to high accuracy in time OË((# of nonzero coefficients)^c), then we can solve general linear equations with polynomially bounded integer coefficients and condition numbers up to high accuracy in time OË((# of nonzero coefficients)^c).\n\nIn the aspect of the upper bound, we generalize existing collapsing-based 1-Laplacian solvers to less restricted classes of complexes. Specifically, we can approximately solve 1-Laplacian systems of a well-shaped simplicial complex with $n$ simplexes up to high precision in time $\\tilde{O}(n^{3/2})$. Our solvers are inspired by the Incomplete Nested Dissection designed by Kyng et al. [STOCâ2018] for stiffness matrices of well-shaped trusses.\n\nBased on joint work with Peng Zhang, Rasmus Kyng, Maximilian Probst Gutenberg.\n\nLocation: Virtual (Zoom). Join us at A140 (T4) to watch together\n\nArxiv 29 March 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) MÃ©lanie Cambus :\n\nA Parallel Algorithm for (3 + Îµ)-Approximate Correlation Clustering Grouping together similar elements in datasets is a common task in data mining and machine learning. In this talk, we present parallel algorithms for correlation clustering, where each pair of items is labeled either similar or dissimilar. The task is to partition the elements and the objective is to minimize disagreements, that is, the number of dissimilar elements grouped together and similar elements grouped separately. Our main contribution is a parallel algorithm that achieves a (3 + Îµ)-approximation to the minimum number of disagreements. Our algorithm builds on the analysis of the PIVOT algorithm by Ailon, Charikar, and Newman that obtains a 3-approximation in the centralized setting. Our design allows us to sparsify the input graph by ignoring a large portion of the nodes and edges without a large extra cost as compared to the analysis of PIVOT. This sparsification makes our technique applicable on several models of massive graph processing, such as Massively Parallel Computing (MPC) and graph streaming, where sparse graphs can typically be handled much more efficiently. We focus on the linear memory MPC model, where our approach yields an O(1) time algorithm where the runtime is independent of Îµ, which only appears in the memory demand.\n\nLocation: A140 (T4)\n\nZoom\n\nArxiv 22 March 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Russell W. F. Lai :\n\nEfficient Laconic Cryptography from Learning With Errors Laconic cryptography is an emerging paradigm that enables cryptographic primitives with sublinear communication complexity in just two messages. In particular, a two-message protocol between Alice and Bob is called laconic if its communication and computation complexity are essentially independent of the size of Alice's input. This can be thought of as a dual notion of fully-homomorphic encryption, as it enables ``Bob-optimized'' protocols. This paradigm has led to tremendous progress in recent years. However, all existing constructions of laconic primitives are considered only of theoretical interest: They all rely on non-black-box cryptographic techniques, which are highly impractical. This work shows that non-black-box techniques are not necessary for basic laconic cryptography primitives. We propose a completely algebraic construction of laconic encryption, a notion that we introduce in this work, which serves as the cornerstone of our framework. We prove that the scheme is secure under the standard Learning With Errors assumption (with polynomial modulus-to-noise ratio). We provide proof-of-concept implementations for the first time for laconic primitives, demonstrating the construction is indeed practical: For a database size of 2^50, encryption and decryption are in the order of single digit milliseconds. Laconic encryption can be used as a black box to construct other laconic primitives. Specifically, we show how to construct: - Laconic oblivious transfer - Registration-based encryption scheme - Laconic private-set intersection protocol All of the above have essentially optimal parameters and similar practical efficiency. Furthermore, our laconic encryption can be preprocessed such that the online encryption step is entirely combinatorial and therefore much more efficient. Using similar techniques, we also obtain identity-based encryption with an unbounded identity space and tight security proof (in the standard model).\n\nLocation: A140 (T4)\n\n15 March 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Augusto Modanese :\n\nEmbedding arbitrary Boolean circuits into fungal automata Fungal automata are a variation of the two-dimensional sandpile automaton of Bak, Tang and Wiesenfeld (Phys.~Rev.~Lett., 1987). In each step toppling cells emit grains only to \\emph{some} of their neighbors chosen according to a specific update sequence. We show how to embed any Boolean circuit into the initial configuration of a fungal automaton with update sequence $HV$. In particular we give a constructor that, given the description $B$ of a circuit, computes the states of all cells in the finite support of the embedding configuration in $O(\\log |B|)$ space. As a consequence the prediction problem for fungal automata with update sequence $HV$ is $P$-complete. This solves an open problem of Goles et al.~(Phys.~Lett.~A, 2020).\n\nThis is joint work with Thomas Worsch.\n\nLocation: A140 (T4)\n\nZoom link Arxiv 8 March 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Shreyas Pai :\n\nMessage Complexity of Distributed Algorithms In this talk we will look at the communication cost (or message complexity) of fundamental problems in the distributed CONGEST model. We will address the following question in this talk: can we solve problems using sublinear, i.e., $o(m)$ communication, and if so under what conditions?\n\nIn a classical result, Awerbuch, Goldreich, Peleg, and Vainish [JACM 1990] showed that fundamental global problems such as broadcast and spanning tree construction require at least $\\Omega(m)$ messages in the KT-1 CONGEST model (i.e., CONGEST model in which nodes have initial knowledge of the neighbors' IDs) when algorithms are restricted to be comparison-based (i.e., algorithms in which node IDs can only be compared). Thirty five years after this result, King, Kutten, and Thorup [PODC 2015] showed that one can solve the above problems using $\\tilde{O}(n)$ messages ($n$ is the number of nodes in the graph) in $\\tilde{O}(n)$ rounds in the KT-1 CONGEST model if non-comparison-based algorithms are permitted. An important implication of this result is that one can use the synchronous nature of the KT-1 CONGEST model, using silence to convey information, and solve any graph problem using non-comparison-based algorithms with $\\tilde{O}(n)$ messages, but this takes an exponential number of rounds.\n\nIn contrast, much less is known about the message complexity of local symmetry breaking problems such as coloring and MIS. We will look at the following results in this talk: Lower bound: In the KT-1 CONGEST model, any comparison-based algorithm, even a randomized Monte-Carlo algorithm with constant success probability, requires $\\Omega(n^2)$ messages in the worst case to solve either $(\\Delta+1)$-coloring, regardless of the number of rounds. Upper bound: In the KT-1 CONGEST model, we present the following randomized non-comparison-based $(\\Delta+1)$-coloring algorithm that uses $\\tilde{O}(n^{1.5})$ messages, while running in $\\tilde{O}(D+\\sqrt{n})$ rounds, where $D$ is the graph diameter.\n\nIf time permits, we can also look at some more recent work on message complexity of optimization problems.\n\nBased on joint work with Fabien Douflon, Gopal Pandurangan, Sriram V. Pemmaraju, and Peter Robinson.\n\nLocation: A140 (T4)\n\n1st of March 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Andreas Grigorjew :\n\nWidth Helps and Hinders Splitting Flows Minimum flow decomposition (MFD) is the NP-hard problem of finding a smallest decomposition of a network flow $X$ on directed graph $G$ into weighted source-to-sink paths whose superposition equals $X$. We focus on a common formulation of the problem where the path weights must be non-negative integers and also on a new variant where these weights can be negative. We show that, for acyclic graphs, considering the \\emph{width} of the graph (the minimum number of $s$-$t$ paths needed to cover all of its edges) yields advances in our understanding of its approximability. For the non-negative version, we show that a popular heuristic is a $O( \\log |X|)$-approximation ($|X|$ being the total flow of $X$) on graphs satisfying two properties related to the width (satisfied by e.g., series-parallel graphs), and strengthen its worst-case approximation ratio from $\\Omega(\\sqrt{m})$ to $\\Omega(m / \\log m)$ for sparse graphs, where $m$ is the number of edges in the graph. For the negative version, we give a $(\\lceil \\log \\Vert X \\Vert \\rceil +1)$-approximation ($\\Vert X \\Vert$ being the maximum absolute value of $X$ on any edge) using a power-of-two approach, combined with parity fixing arguments and a decomposition of unitary flows ($\\Vert X \\Vert \\leq 1$) into at most width paths. We also disprove a conjecture about the linear independence of minimum (non-negative) flow decompositions posed by Kloster et al. [ALENEX 2018], but show that its useful implication (polynomial-time assignments of weights to a given set of paths to decompose a flow) holds for the negative version.\n\nJoint work with Manuel CÃ¡ceres, Massimo Cairo, Shahbaz Khan, Brendan Mumey, Romeo Rizzi, Alexandru I. Tomescu, Lucia Williams\n\nLocation: A140 (T4)\n\nZoom link Arxiv 22nd of February 2023\n\n14:15 (Helsinki time)\n\nLocation: A133 (T5) Schiewe Philine:\n\nAlgorithms and Hardness for Non-Pool-Based Line Planning Line planning, i.e., choosing paths which are operated by one vehicle end-to-end, is an important aspect of public transport planning and can be considered as a discrete optimization problem. The goal is to determine a multiset of paths such that each edge of a given graph is covered according to predefined bounds and the costs are minimzed. While there exist heuristic procedures for generating lines from scratch, most theoretical observations consider the problem of choosing lines from a predefined line pool, i.e., restricting the solution space by defining a superset of paths to choose from. In this talk, we consider the complexity of the line planning problem when all simple paths can be used as lines. Depending on the cost structure, we show that the problem can be NP-hard even for paths and stars, and that no polynomial time approximation of sub-linear performance is possible. Additionally, we identify polynomially solvable cases and present a pseudo-polynomial solution approach for trees.\n\nJoint work with Irene Heinrich (TU Darmstadt) and Constantin Seebach (RPTU Kaiserslautern Landau).\n\nLocation: A133 (T5) (Note: a different room from the usual room)\n\nPaper 15th of February 2023\n\n14:15 (Helsinki time)\n\nOnline Karol WÄgrzycki:\n\nParameterized Approximation for Maximum Weight Independent Set of Rectangles and Segments In the Maximum Weight Independent Set of Rectangles problem (MWISR) we are given a weighted set of $n$ axis-parallel rectangles in the plane. The task is to find a subset of pairwise non-overlapping rectangles with the maximum possible total weight. This problem is NP-hard and the best-known polynomial-time approximation algorithm, due to by Chalermsook and Walczak (SODA 2021), achieves approximation factor $\\mathcal{O}(\\log\\log(n))$. While in the unweighted setting, constant factor approximation algorithms are known, due to Mitchell (FOCS 2021) and to GÃ¡lvez et al. (SODA 2022), it remains open to extend these techniques to the weighted setting.\n\nIn this paper, we consider MWISR through the lens of parameterized approximation. Grandoni et~al. (ESA 2019) gave $(1-\\eps)$-approximation algorithm with running time $k^{\\mathcal{O}(k/\\eps^8)} n^{\\mathcal{O}(1/\\eps^8)}$ time, where $k$ is the number of rectangles in optimum solution. Unfortunately, their algorithm only works in the unweighted setting and they left it as an open problem to give a parameterized approximation scheme in the weighted setting.\n\nOur contribution is a partial answer to the open question of Grandoni et al. (ESA 2019). We give a parameterized approximation algorithm for MWISR that given a parameter $k$, finds a set of non-overlapping rectangles of weight at least $(1-\\eps) \\omega(\\mathrm{opt}_k)$ in $2^{\\mathcal{O}(k \\log(k/\\eps))} n^{\\mathcal{O}(1/\\eps)}$ time, where $\\omega(\\mathrm{opt}_k)$ is the maximum weight of solution of cardinality at most $k$. Note that thus, our algorithm may return a solution consisting of more than $k$ rectangles. To complement this apparent weakness, we also propose a parameterized approximation scheme that outputs a solution with cardinality at most $k$ and total weight at least $(1-\\eps)\\omega(\\mathrm{opt}_k)$ for the special case of axis-parallel segments.\n\nJoint work with Jana Cslovjecsek and MichaÅ Pilipczuk\n\nLocation: Virtual (Zoom). Join us in A140 (T4) to watch it together.\n\nZoom link Arxiv 8th of February 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Nidia Obscura Acosta:\n\nImproved Pattern-Avoidance Bounds for Greedy BSTs via Matrix Decomposition Greedy BST (or simply Greedy) is an online self-adjusting binary search tree defined in the geometric view ([Lucas, 1988; Munro, 2000; Demaine, Harmon, Iacono, Kane, Patrascu, SODA 2009). Along with Splay trees (Sleator, Tarjan 1985), Greedy is considered the most promising candidate for being dynamically optimal, i.e., starting with any initial tree, their access costs on any sequence is conjectured to be within $O(1)$ factor of the offline optimal. However, in the past four decades, the question has remained elusive even for highly restricted input.\n\nIn this paper, we prove new bounds on the cost of Greedy in the ''pattern avoidance'' regime. Our new results include: The (preorder) traversal conjecture for Greedy holds up to a factor of $O(2^{\\alpha(n)})$, improving upon the bound of $2^{\\alpha(n)^{O(1)}}$ in (Chalermsook et al., FOCS 2015). This is the best known bound obtained by any online BSTs. We settle the postorder traversal conjecture for Greedy. The deque conjecture for Greedy holds up to a factor of $O(\\alpha(n))$, improving upon the bound $O(2^{\\alpha(n)})$ in (Chalermsook, et al., WADS 2015). The split conjecture holds for Greedy up to a factor of $O(2^{\\alpha(n)})$.\n\nKey to all these results is to partition (based on the input structures) the execution log of Greedy into several simpler-to-analyze subsets for which classical forbidden submatrix bounds can be leveraged.\n\nThis is joint work with Parinya Chalermsook, Manoj Gupta, Wanchote Jiamjitrak, Akash Pareek, and Sorrachai Yingchareonthawornchai.\n\nLocation: A140 (T4)\n\nArxiv 1st of February 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Oumarou Oumarou:\n\nAccelerating Quantum Computations of Chemistry Through Regularized Compressed Double Factorization We propose the regularized compressed double factorization (RC-DF) method to classically compute compressed representations of molecular Hamiltonians that enable efficient simulation with noisy intermediate scale (NISQ) and error corrected quantum algorithms. We find that already for small systems with 12 to 20 qubits, the resulting NISQ measurement scheme reduces the number of measurement bases by roughly a factor of three and the shot count to reach chemical accuracy by a factor of three to six compared to truncated double factorization (DF) and we see order of magnitude improvements over Pauli grouping schemes. We demonstrate the scalability of our approach by performing RC-DF on the Cpd I species of cytochrome P450 with 58 orbitals and find that using the resulting compressed Hamiltonian cuts the run time of qubitization and truncated DF based error corrected algorithms almost in half and even outperforms the lambda parameters achievable with tensor hypercontraction (THC) while at the same time reducing the CCSD(T) energy error heuristic by an order of magnitude.\n\nJoint work with Maximilian Scheurer, Robert M. Parrish, Edward G. Hohenstein and Christian Gogolin.\n\nLocation: A140 (T4)\n\nArxiv 18th of January 2023\n\n14:15 (Helsinki time)\n\nLocation: A140 (T4) Manuel CÃ¡ceres:\n\nMinimum Path Cover in Parameterized Linear Time A minimum path cover (MPC) of a directed acyclic graph (DAG) $G = (V,E)$ is a minimum-size set of paths that together cover all the vertices of the DAG. Computing an MPC is a basic polynomial problem, dating back to Dilworth's and Fulkerson's results in the 1950s. Since the size $k$ of an MPC (also known as the \\emph{width}) can be small in practical applications, research has also studied algorithms whose running time is parameterized on $k$.\n\nWe obtain a new MPC parameterized algorithm for DAGs running in time $O(k^2|V| + |E|)$. Our algorithm is the first solving the problem in parameterized linear time. Additionally, we obtain an edge sparsification algorithm preserving the width of a DAG but reducing $|E|$ to less than $2|V|$. This algorithm runs in time $O(k^2|V|)$ and requires an MPC of a DAG as input, thus its total running time is the same as the running time of our MPC algorithm.\n\nLocation: A140 (T4)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link Arxiv 25th of January 2023\n\nBreak SODA 2023 11th of January 2023\n\n14:15 (Helsinki time) Michael KlooÃ:\n\nShort relaxed range proofs We give a brief overview of the relaxed range proofs by Couteau et al. [CKLR21](https://eprint.iacr.org/2021/540) and [CGKR22](https://eprint.iacr.org/2022/1153), which are based on square decomposition. Our focus is on the (batch) proof of shortness and its relaxed soundness notion (\"short rationals\") in the latter. The abstract of [CGKR22] is cited below.\n\nWe provide optimized range proofs, called Sharp, in discrete logarithm and hidden order groups, based on square decomposition. In the former setting, we build on the paradigm of Couteau et al. (Eurocrypt â21) and optimize their range proof (from now on, CKLR) in several ways: (1) We introduce batching via vector commitments and an adapted Î£-protocol. (2) We introduce a new group switching strategy to reduce communication. (3) As repetitions are necessary to instantiate CKLR in standard groups, we provide a novel batch shortness test that allows for cheaper repetitions. The analysis of our test is nontrivial and forms a core technical contribution of our work. For example, for Î» = 128 bit security and B = 64 bit ranges for N = 1 (resp. N = 8) proof(s), we reduce the proof size by 34% (resp. 75%) in arbitrary groups, and by 66% (resp. 88%) in groups of order 256-bit, compared to CKLR. As Sharp and CKLR proofs satisfy a ârelaxedâ notion of security, we show how to enhance their security with one additional hidden order group element. In RSA groups, this reduces the size of state of the art range proofs (Couteau et al., Eurocrypt â17) by 77% (Î» = 128, B = 64, N = 1). Finally, we implement our most optimized range proof. Compared to the state of the art Bulletproofs (BÃ¼nz et al., S&P 2018), our benchmarks show a very significant runtime improvement. Eventually, we sketch some applications of our new range proofs.\n\nLocation: A140 (T4)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link Paper 14th of December\n\n14:15 (Helsinki time) Tuukka Korhonen:\n\nAn Improved Parameterized Algorithm for Treewidth Treewidth is a graph parameter that, informally, characterizes how tree-like a graph is. Treewidth plays an important role in many areas of computer science and graph theory, in particular generalizing results on trees to graphs of small treewidth. We give a $2^{O(k^2)} n^{O(1)}$ time algorithm for determining if the treewidth of a given $n$-vertex graph is at most $k$ and outputting the corresponding tree decomposition. This resolves the long-standing open problem of whether there is a $2^{o(k^3)} n^{O(1)}$ time algorithm for treewidth. In particular, this is the first improvement on the dependency on $k$ in fixed-parameter algorithms for treewidth since the $2^{O(k^3)} n^{O(1)}$ time algorithm given in 1991 by Bodlaender and Kloks, and independently, by Lagergren and Arnborg. We also give a $k^{O(k/\\varepsilon)} n^{O(1)}$ time ($1+\\varepsilon$)-approximation algorithm for treewidth. Prior to our work, no approximation algorithms with approximation ratio less than 2 other than the exact algorithms were known.\n\nThis is joint work with Daniel Lokshtanov.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link ArXiv 7th of December\n\n14:15 (Helsinki time) Vikas Garg:\n\nProvably powerful temporal graph networks Temporal graph networks (TGNs) have gained prominence as models for embedding dynamic interactions, but little is known about their theoretical underpinnings. Iâll give an overview of our recent work on the representational power and limits of the two main categories of TGNs: those that aggregate temporal walks (WA-TGNs), and those that augment local message passing with recurrent memory modules (MP-TGNs). Specifically, novel constructions reveal the inadequacy of MP-TGNs and WA-TGNs, proving that neither category subsumes the other. The most powerful MP-TGNs must use injective memory modules and message passing updates, in which case they become as powerful as a natural temporal extension of 1-WL. Interestingly, it turns out that sufficiently deep MP-TGNs cannot benefit from memory. Our investigations lead to PINT, which provably more expressive than both MP-TGNs and WA-TGNs.\n\nBased on joint work with Amauri Souza, Diego Mesquita, and Samuel Kaski.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link Paper 30th of November\n\n14:15 (Helsinki time) Madhav Krishnan Vijayan:\n\nCompilation of algorithm-specific graph states for quantum circuits We present a quantum circuit compiler that prepares an algorithm-specific graph state from quantum circuits described in high level languages, such as Cirq and Q#. The computation can then be implemented using a series of non-Pauli measurements on this graph state. By compiling the graph state directly instead of starting with a standard lattice cluster state and preparing it over the course of the computation, we are able to better understand the resource costs involved and eliminate wasteful Pauli measurements on the actual quantum device. Access to this algorithm-specific graph state also allows for optimisation over locally equivalent graph states to implement the same quantum circuit. The compiler presented here finds ready application in measurement based quantum computing, NISQ devices and logical level compilation for fault tolereant implementations.\n\nLocation: Virtual (Zoom). Join us in A133 (T5) to view it together.\n\nZoom link ArXiv 23rd of November\n\n14:15 (Helsinki time) Hung Le:\n\nLow Treewidth Embeddings of Planar Graphs Traditional metric embedding focuses on finding an embedding with small multiplicative distortion. However, the search for this kind of embedding for planar graphs has not been very fruitful. Indeed, most known results for multiplicative embeddings of planar graphs are negative. In this talk, I will describe an embedding with additive distortion into low treewidth graphs, a new type of embedding for planar graphs. I will also discuss several algorithmic applications of this embedding and conclude the talk with several open problems.\n\nLocation: Virtual (Zoom). Join us in A133 (T5) to view it together.\n\nZoom link ArXiv 16th of November\n\n14:15 (Helsinki time) Akira Takahashi:\n\nTwo-round Multi-party Signing from Lattices Multi-party signatures comprise a class of protocols that allow a group of signers to jointly produce a single signature on the same message. In recent years, a number of such protocols following the Fiat-Shamir paradigm have been proposed in the discrete-log setting, e.g., MuSig2, DWMS, and FROST.\n\nIn this talk, I will first go over existing techniques realizing round-efficient Fiat-Shamir multi-party signing. I will then discuss new approaches to constructing lattice-based instantiations, by highlighting the main technical challenges as well as new proof techniques enabled by lattice trapdoors. Our protocols are provably secure in the (classical) random oracle model under the standard lattice-based hardness assumptions, such as SIS and LWE, while retaining only two rounds of interaction during the signing protocol as in the state-of-the-art Schnorr-based constructions.\n\nThis talk is based on joint work with Cecilia Boschini, Ivan DamgÃ¥rd, Claudio Orlandi, and Mehdi Tibouchi.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link Paper 1,\n\nPaper 2 9th of November\n\n14:15 (Helsinki time) Tillmann Miltzow:\n\nTraining Neural Networks is $\\exists\\mathbb{R}$-complete Given a neural network, training data, and a threshold, it was known that it is NP-hard to find weights for the neural network such that the total error is below the threshold. We determine the algorithmic complexity of this fundamental problem precisely, by showing that it is $\\exists\\mathbb{R}$-complete. This means that the problem is equivalent, up to polynomial-time reductions, to deciding whether a system of polynomial equations and inequalities with integer coefficients and real unknowns has a solution. If, as widely expected, $\\exists\\mathbb{R}$ is strictly larger than NP, our work implies that the problem of training neural networks is not even in NP. Neural networks are usually trained using some variation of backpropagation. The result of this paper offers an explanation of why techniques commonly used to solve big instances of NP-complete problems seem not to be of use for this task. Examples of such techniques are SAT solvers, IP solvers, local search, and dynamic programming, to name a few general ones.\n\nLocation: Virtual (Zoom). Join us in A133 (T5) to view it together.\n\nZoom link ArXiv 2nd of November\n\n14:15 (Helsinki time) Mikkel Abrahamsen:\n\nOnline Sorting and Translational Packing of Convex Polygons We investigate various online packing problems in which convex polygons arrive one by one and have to be placed irrevocably into a container before the next piece is revealed; the pieces must not be rotated, but only translated. The aim is to minimize the used space depending on the specific problem at hand, e.g., the strip length in strip packing, the number of bins in bin packing, etc.\n\nWe draw interesting connections to the following online sorting problem OnlineSorting$[\\gamma,n]$: We receive a stream of real numbers $s_1,â¦,s_n,\\; s_i \\in [0,1]$, one by one. Each real must be placed in an array $A$ with $\\gamma n$ initially empty cells without knowing the subsequent reals. The goal is to minimize the sum of differences of consecutive reals in $A$. The offline optimum is to place the reals in sorted order so the cost is at most 1. We show that for any $\\Delta$-competitive online algorithm of OnlineSorting$[\\gamma,n]$, it holds that $\\gamma\\Delta \\in \\Omega(\\log n/\\log\\log n)$. We use this lower bound to prove the non-existence of competitive algorithms for various online translational packing problems of convex polygons, among them strip packing, bin packing and perimeter packing. This also implies that there exists no online algorithm that can pack all streams of pieces of diameter and total area at most $\\delta$ into the unit square. These results are in contrast to the case when the pieces are restricted to rectangles, for which competitive algorithms are known. Likewise, the offline versions of packing convex polygons have constant factor approximation algorithms.\n\nOn the positive side, we present an algorithm with competitive ratio $O(n^{0.59})$ for online translational strip packing of convex polygons. In the case of OnlineSorting$[C,n]$ for any constant $C>1$, we present an $2^{O(\\sqrt{\\log n \\log\\log n})})$-competitive algorithm.\n\nLocation: Virtual (Zoom). Join us in A133 (T5) to view it together.\n\nZoom link ArXiv 26th of October\n\n14:15 (Helsinki time) Kirthivaasan Puniamurthy:\n\nPebbling for proving adaptive security: Yao's garbling scheme Secure multi-party computation (MPC) allows several parties to compute a function $f$ on their secret data $x_1,...,x_n$ without any party learning anything except for the output $y = f(x_1,...,x_n)$. Yao's garbling scheme is one of the key techniques in MPC. Informally, garbling enables one to transform a circuit/input pair $(C, x)$ into a \"garbled\" circuit/input pair $\\tilde{C}, \\tilde{x}$ while preserving the output, i.e. $C(x) = \\tilde{C}(\\tilde{x})$. Roughly speaking, a garbling scheme is secure if there exists an efficient simulator which is only given $y = C(x)$ (and the topology of $C$) and can generate $\\tilde{C}, \\tilde{x}$ that are indistinguishable from the real garbled pair $\\tilde{C}, \\tilde{x}$. We refer to this notion of security as selective simulation security. It is selective because $(C, x)$ are garbled simultaneously. One may instead consider an adaptive setting, where an adversary first obtains the garbled circuit, and only then selects an input to be garbled. Since the input may now depend on the garbled circuit, a proof for selective simulation does not carry over to the adaptive setting. To fix this, we require new proof techniques (and/or new constructions) for proving adaptive security. In this talk we look at a proof technique that involves guessing, which can then be formulated within the language of so called pebbling, a combinatorial game played on graphs.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link 19th of October\n\n14:15 (Helsinki time) Pekka Orponen:\n\nAlgorithmic Design of 3D Wireframe RNA Polyhedra We address the problem of de novo design and synthesis of nucleic acid nanostructures, a challenge that has been considered in the area of DNA nanotechnology since the 1980s and more recently in the area of RNA nanotechnology. Toward this goal, we introduce a general algorithmic design process and software pipeline for rendering 3D wireframe polyhedral nanostructures in single-stranded RNA. To initiate the pipeline, the user creates a model of the desired polyhedron using standard 3D graphic design software. As its output, the pipeline produces an RNA nucleotide sequence whose corresponding RNA primary structure can be transcribed from a DNA template and folded in the laboratory. As case examples, we have designed and characterised experimentally three 3D RNA nanostructures: a tetrahedron, a triangular bipyramid, and a triangular prism.\n\nJoint work with Antti Elonen, Ashwin Natarajan, Ibuki Kawamata, Lukas Oesinghaus, Abdulmelik Mohammed, Jani Seitsonen, Yuki Suzuki, Friedrich Simmel and Anton Kuzyk.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link Paper 12th of October\n\n14:15 (Helsinki time) Valerio Cini:\n\nLattice-Based SNARKs: Publicly Verifiable, Preprocessing, and Recursively Composable In this talk, we present the first publicly verifiable lattice-based succinct non-interactive argument of knowledge (SNARK). The construction stems from a general technical toolkit that we develop to translate pairing-based schemes to lattice-based ones, and that allows us to construct the primitive which is at the heart of our SNARK construction: a new lattice-based vector commitment (VC) scheme supporting openings to constant-degree multivariate polynomial maps. The security is based on a new family of lattice-based computational assumptions, that we call $k$-Ring-Inhomogenous Short Integer Solution (or $k$-R-ISIS for short), which naturally generalizes the standard Short Integer Solution (SIS) assumption.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link Paper 5th of October\n\n14:15 (Helsinki time) Sorrachai Yingchareonthawornchai:\n\nDeterministic Small Vertex Connectivity in Almost Linear Time In the vertex connectivity problem, given an undirected n-vertex m-edge graph, we need to compute the minimum number of vertices that can disconnect the graph after removing them. This problem is one of the most well-studied graph problems. From 2019, a new line of work [Nanongkai et al. STOC'19;SODA'20;STOC'21] has used randomized techniques to break the quadratic-time barrier and, very recently, culminated in an almost-linear time algorithm via the recently announced maxflow algorithm by Chen et al. In contrast, all known deterministic algorithms are much slower. The fastest algorithm [Gabow FOCS'00] takes $O(m(n+\\min\\{c^{5/2},cn^{3/4}\\}))$ time where $c$ is the vertex connectivity. It remains open whether there exists a subquadratic-time deterministic algorithm for any constant $c>3$.\n\nIn this talk, we present the first deterministic almost-linear time vertex connectivity algorithm for all constants c. Our running time is $m^{1+o(1)}2^{O(c^{2})}$ time, which is almost-linear for all $c=o(\\sqrt{\\log n})$. This is the first deterministic algorithm that breaks the $O(n^{2})$-time bound on sparse graphs where $m=O(n)$, which is known for more than 50 years ago [Kleitman'69].\n\nTowards our result, we give a new reduction framework to vertex expanders which in turn exploits our new almost-linear time construction of mimicking network for vertex connectivity. The previous construction by Kratsch and WahlstrÃ¶m [FOCS'12] requires large polynomial time and is randomized. An interesting aspect that allows our overall algorithm to be efficient is to ``lift'' several graph problems to hypergraphs and work directly on hypergraphs.\n\nThis is joint work with Thatchaphol Saranurak.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link 28th of September\n\n14:15 (Helsinki time) Juha Harviainen:\n\nTrustworthy Monte Carlo Monte Carlo integration is a key technique for designing randomized approximation schemes for counting problems, with applications, e.g., in machine learning and statistical physics. The technique typically enables massively parallel computation, however, with the risk that some of the delegated computations contain spontaneous or adversarial errors. We present an orchestration of the computations such that the outcome is accompanied with a proof of correctness. Specifically, we adopt an algebraic proof system developed in computational complexity theory, in which the proof is represented by a polynomial; evaluating the polynomial at a random point amounts to a verification of the proof with probabilistic guarantees. We give examples of known Monte Carlo estimators that admit verifiable extensions with moderate computational overhead: for the permanent of zero--one matrices, for the model count of disjunctive normal form formulas, and for the gradient of logistic regression models. We also discuss the prospects and challenges of engineering efficient verifiable approximation schemes more generally.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link 21st of September\n\n14:15 (Helsinki time) Francesco d'Amore:\n\nOn the multidimensional random subset sum problem In the Random Subset Sum Problem, given $n$ i.i.d. random variables $X_1,\\dots,X_n$, we wish to approximate any point $z\\in [â1,1]$ as the sum of a suitable subset $X_{i_1}(z),\\dots,X_{i_s}(z)$ of them, up to error $\\varepsilon$. Despite its simple statement, this problem is of fundamental interest to both theoretical computer science and statistical mechanics. More recently, it gained renewed attention for its implications in the theory of Artificial Neural Networks. An obvious multidimensional generalisation of the problem is to consider $n$ i.i.d. $d$-dimensional random vectors, with the objective of approximating every point $z\\in [â1,1]^d$. Rather surprisingly, after Lueker's 1998 proof that, in the one-dimensional setting, $n=O(\\log 1/\\varepsilon)$ samples guarantee the approximation property with high probability, little progress has been made on achieving the above generalisation. In this work, we prove that, in $d$ dimensions, $n=O(d^3 \\log 1/\\varepsilon \\cdot (\\log 1/\\varepsilon+\\log d))$ samples suffice for the approximation property to hold with high probability.\n\nLocation: A133 (T5)\n\nYou can also join via Zoom, but there are no guarantees regarding the audio/video quality. Zoom link Paper 24th of August\n\n14:15 (Helsinki time) MikÃ¤el Rabie:\n\nDistributed Recoloring In Graph Theory, a recoloring problem is as follows: given two colorings of a graph, can we go from the first one to the second by changing the color of a node one after another, while keeping the coloring proper? In 2018, we introduced the Distributed Recoloring question: what happens if we allow an independent set of nodes to be recolored at each step? Can we find a recoloring schedule in an efficient way in the Distributed LOCAL model? This question appears to be hard in the general settings. However, different results were found in some specific cases. In this presentation, I will show results from different papers on that topic: Recoloring on Trees, Interval Graphs and Chordal Graphs, with the use of some extra colors. I will also show how to produce a constant length schedule in bounded degree graphs with Delta+1 colors, without using any extra color, when the colorings follow some nice properties. This last result allows improving the recoloring schedule in the centralized settings (from quadratic to linear).\n\nThose works are the result of collaborations with Marthe Bonamy, Nicolas Bousquet, Laurent Feuilloley, March Heinrich, Paul Ouvrard, Jara Uitto and Jukka Suomela ArXiv 10th of August\n\n14:15 (Helsinki time) Tuukka Korhonen:\n\nFixed-Parameter Tractability of Maximum Colored Path and Beyond We introduce a general method for obtaining fixed-parameter algorithms for problems about finding paths in undirected graphs, where the length of the path could be unbounded in the parameter. The first application of our method is as follows. We give a randomized algorithm, that given a colored $n$-vertex undirected graph, vertices $s$ and $t$, and an integer $k$, finds an $(s,t)$-path containing at least $k$ different colors in time $2^k n^{O(1)}$. This is the first FPT algorithm for this problem, and it generalizes the algorithm of BjÃ¶rklund, Husfeldt, and Taslaman [SODA 2012] on finding a path through $k$ specified vertices. It also implies the first $2^k n^{O(1)}$ time algorithm for finding an $(s,t)$-path of length at least $k$. Our method yields FPT algorithms for even more general problems. For example, we consider the problem where the input consists of an $n$-vertex undirected graph $G$, a matroid $M$ whose elements correspond to the vertices of $G$ and which is represented over a finite field of order $q$, a positive integer weight function on the vertices of $G$, two sets of vertices $S,T \\subseteq V(G)$, and integers $p,k,w$, and the task is to find $p$ vertex-disjoint paths from $S$ to $T$ so that the union of the vertices of these paths contains an independent set of $M$ of cardinality $k$ and weight $w$, while minimizing the sum of the lengths of the paths. We give a $2^{p+O(k^2 \\log (q+k))} n^{O(1)} w$ time randomized algorithm for this problem. ArXiv 15th of June\n\n14:15 (Helsinki time) Yan Xia:\n\nInferring Multilayer Diffusion Networks in Online Social Media Information on social media spreads through an underlying diffusion network that connects people of common interests and opinions. This diffusion network often comprises multiple layers, each capturing the spreading dynamics of a certain type of information characterized by, for example, topic, language, or attitude. Researchers have previously proposed method for inferring these underlying multilayer diffusion networks from observed spreading patterns, but little is known about how well it performs across the range of realistic spreading data. We introduce an implementation of the multilayer diffusion network inference method that outperforms previous implementations in accuracy, and conduct an extensive series of synthetic data experiments to systematically analyze the performance of the inference method, under varied network structure (e.g. density, number of layers) and information diffusion settings (e.g. cascade size, layer mixing) that are designed to mimic real-world spreading on social media. Our results show extreme performance variation of the inference method: notably, it fails to decompose the diffusion network correctly when most cascades in the data reach a limited audience, or when the ground-truth diffusion network is sparse. Based on the analysis of the current method, we pose challenges toward further understanding and improving multilayer diffusion network inference from both theoretical and applicational perspectives. Paper 1st of June\n\n14:15 (Helsinki time) SÃ¡ndor Kisfaludi-Bak:\n\nApproximations for the Euclidean traveling salesman In the Euclidean traveling salesman problem (Euclidean TSP) we are given a set of n points in d-dimensional Euclidean space, and the goal is to find the shortest round trip containing all of these points. In this talk we will get on overview of the algorithmic techniques for Euclidean TSP, starting with Arora's approximation scheme. We will then briefly discuss geometric (light) spanners that brought the first round of improvements to the problem, and in the end we will look at the newest approximation scheme that achieves an optimal trade-off between running time and accuracy under reasonable complexity-theoretic assumptions. ArXiv 25th of May\n\n14:15 (Helsinki time) Darya Melnyk:\n\nOnline Algorithms with Lookaround In this talk, I will introduce a new model of computing model that was presented in âOnline Algorithms with Lookaroundâ, called the online-LOCAL. In this model, the adversary reveals the nodes of the input graph one by one, in the same way as in classical online algorithms, but for each new node the algorithm can also inspect its radius-T neighborhood before choosing the output. Instead of looking ahead in time, we have the power of looking around in space. This model gives a unifying view of locality in four settings: LOCAL model of distributed computing, its sequential counterpart SLOCAL, dynamic algorithms, and online algorithms.\n\nWe show that for LCL problems in paths, cycles, and rooted trees, all four models are roughly equivalent: the locality of any LCL problem falls in the same broad class - $O(\\log^* n)$, $\\Theta(\\log n)$, or $n^{\\Theta(1)}$ - in all four models. In particular, prior work on the LOCAL model directly generalizes to all four models.\n\nSecond, we show that this equivalence does not hold in two-dimensional grids. We show that the locality of the 3-coloring problem is $O(\\log n)$ in the online-LOCAL model, while it is known to be $\\Omega(\\sqrt{n})$ in the LOCAL model. ArXiv 11th of May\n\n14:15 (Helsinki time) Andrei Voicu Tomut:\n\nEnhanced Quantum Autoencoders for Anomaly Detection We present an extensive study of Quantum Auto Encoders (QAE) from the theoretical and application perspectives. This is a novel approach to building a quantum autoencoder that makes use of quantum entanglement as a resource to add an extra source of correlation between the compression and decompression process. We develop various conceptually different ideas: we let the encoder and decoder share Bell pairs, we entangle encoder and decoder qubits directly and we test what happens if we allow for both the encoder and decoder training contrary to the standard approach. So far, we have encountered an architecture that would provide a statistically significant advantage.\n\nWe investigate how QAE can be used in the task of anomaly detection for two datasets: breast cancer and credit card transactions. We train QAEs architectures solely on the non-anomalous data. Then, given an anomaly datapoint coming from a different than learnt distribution, QAE provides non-faithful reconstruction, hence indicating an anomaly appearance. We judge the reconstruction quality using either the fidelity test (suitable for simulations) and SWAP test (suitable for both simulations and QPU hardware). We extend previous work on anomaly detection using QAEs by employing for this task for the first time the enhanced autoencoder and the patch autoencoder. Results show in some cases up to 91% accuracy in identifying breast cancer and 88% in fraudulent transaction identification.\n\nThe present method won at Qhack2022 [2] in the following categories: Hybrid Algorithms Challenge, Amazon Braket Challenge (Best Open Hackathon experiment on Bracket Simulators), Quantum Finance Challenge (third place).\n\n[1] https://github.com/XanaduAI/QHack/issues/129\n\n[2] https://medium.com/xanaduai/qhack-2022-cb5ad92573e2 27th of April\n\n14:15 (Helsinki time) Stepháne Deny:\n\nAddressing the Topological Defects of Disentanglement via Distributed Operators A core challenge in Machine Learning is to learn to disentangle natural factors of variation in data (e.g. object shape vs. pose). A popular approach to disentanglement consists in learning to map each of these factors to distinct subspaces of a model's latent representation. However, this approach has shown limited empirical success to date. Here, we show that, for a broad family of transformations acting on images--encompassing simple affine transformations such as rotations and translations--this approach to disentanglement introduces topological defects (i.e. discontinuities in the encoder). Motivated by classical results from group representation theory, we study an alternative, more flexible approach to disentanglement which relies on distributed latent operators, potentially acting on the entire latent space. We theoretically and empirically demonstrate the effectiveness of this approach to disentangle affine transformations. Our work lays a theoretical foundation for the recent success of a new generation of models using distributed operators for disentanglement. Joint work with Diane Bouchacourt and Mark Ibrahim. 20th of April\n\n14:15 (Helsinki time) Janne Korhonen:\n\nDistributed matrix multiplication - an overview In this review talk, we give an overview of distributed matrix multiplication algorithms in fully connected communication models, from 60's classics to more contemporary work on sparse matrix multiplication. We will then briefly touch on some remaining challenges in the field, and discuss our recent work on uniformly sparse matrix multiplication. 6th of April\n\n14:15 (Helsinki time) Mika GÃ¶Ã¶s:\n\nCollapses, separations, and characterisations We discuss a range of results for total NP search problem classes (TFNP) that includes new collapses of classes, black-box separations, and characterisations using propositional proof systems. We will focus on a surprising collapse result, EoPL = PLS â© PPAD, and see its full proof. Joint work with Alexandros Hollender, Siddhartha Jain, Gilbert Maystre, William Pires, Robert Robere, and Ran Tao. 30th of March\n\n14:15 (Helsinki time) Petteri Kaski:\n\nThe Shortest Even Cycle Problem is Tractable Given a directed graph, we show how to efficiently find a shortest (directed, simple) cycle on an even number of vertices. As far as we know, no polynomial-time algorithm was previously known for this problem. In fact, finding any even cycle in a directed graph in polynomial time was open for more than two decades until Robertson, Seymour, and Thomas (Ann. of Math. (2) 1999) and, independently, McCuaig (Electron. J. Combin. 2004; announced jointly at STOC 1997) gave an efficiently testable structural characterisation of even-cycle-free directed graphs. Methodologically, our algorithm relies on algebraic fingerprinting and randomized polynomial identity testing over a finite field, and uses a generating polynomial implicit in Vazirani and Yannakakis ( Discrete Appl. Math. 1989) that enumerates weighted cycle covers as a difference of a permanent and a determinant polynomial. The need to work with the permanent is where our main technical contribution occurs. We design a family of finite commutative rings of characteristic 4 that simultaneously\n\n(i) give a nondegenerate representation for the generating polynomial identity via the permanent and the determinant,\n\n(ii) support efficient permanent computations, and\n\n(iii) enable emulation of finite-field arithmetic in characteristic 2. Here our work is foreshadowed by that of BjÃ¶rklund and Husfeldt (SIAM J. Comput. 2019), who used a considerably less efficient ring design to obtain a polynomial-time algorithm for the shortest two disjoint paths problem. Building on work of Gilbert and Tarjan (Numer. Math. 1978) as well as Alon and Yuster (J. ACM 2013), we also show how ideas from the nested dissection technique for solving linear equation systems leads to faster algorithm designs when we have control on the separator structure of the input graph; for example, this happens when the input has bounded genus.\n\nJoint work with Andreas BjÃ¶rklund (Lund, Sweden) and Thore Husfeldt (Lund University and Basic Algorithms Research Copenhagen, ITU Copenhagen). ArXiv 23rd of March\n\n14:15 (Helsinki time) Fabricio Oliveira:\n\nDecision programming: multi-stage optimization under uncertainty Multi-stage decision problems under uncertainty can be represented as influence diagrams that are converted into decision trees. These trees can then be solved using dynamic programming, if the optimal strategy within a given branch do not depend on the decisions in other non-overlapping branches. To address these shortfalls, we propose the Decision Programming approach, which can efficiently address this âno forgettingâ assumption and retain outcome distribution information. In this, we convert problems into equivalent mixed-integer linear programs that can be efficiently solved, including in the presence of multiple objectives, endogenous uncertainty, and other dependency conditions. ArXiv\n\nPaper\n\nCode Repository 16th of March\n\n14:15 (Helsinki time) Silvio Lattanzi:\n\nEfficient Online and Parallel Correlation Clustering Correlation clustering is a central topic in unsupervised learning, with many applications in ML and data mining. In correlation clustering, one receives as input a signed graph and the goal is to partition it to minimize the number of disagreements. In this talk we analyze the correlation clustering problem in the online and the massively parallel computation (MPC) settings. In the online setting we show that the celebrated Pivot algorithm performs well when given access to a small number of random samples from the input. For the MPC setting, we propose a new algorithm that uses machines with memory sublinear in the number of nodes in the graph and returns a constant approximation while running only for a constant number of rounds. To the best of our knowledge, our algorithm is the first that can provably approximate a clustering problem on graphs using only a constant number of MPC rounds in the sublinear memory regime. We complement our analysis with an experimental analysis of our techniques. ArXiv Two Talks\n\n2nd of March\n\n14:15 (Helsinki time) Evan E. Dobbs:\n\nConstructing Quantum Circuits by Tiling in 3D and LDPC Decoding for Quantum Error Correction using Stochastic Circuit Elements We take advantage of the regular layout common in quantum circuits to express them as 3D objects composed of tiles, where each tile is a 3D nearest-neighbor implementation of the Toffoli gate. Using this scheme, we implement the quantum multiplier proposed by Munoz-Coreas and Thapliyal and demonstrate improvements in the number and depth of SWAP gates necessary for nearest-neighbor implementations of this multiplier when compared with automatic routing methods. This scheme is applied prior to compilation and can be used as an intermediate step for both NISQ and error corrected circuits which use the surface code. We also discuss ongoing work on the implementation of a belief propagation decoder for LDPC codes with stochastic circuit elements, using the surface code as an example.\n\nGeorge Watkins:\n\nLattice Surgery Quantum Error Correction Compiler\n\nWe developed a state of the art, high performance compiler for surface code quantum error correction. Our compiler translates any quantum circuit to a fault-tolerant one error corrected one that follows Lattice Surgery (LS) instructions. We offer our compiler publicly through a web interface, a web service, and as an open sourced Python package. In this talk, we will demonstrate the operation of our compiler and the web visualizer for the conversion of a sample quantum circuit. We will also discuss our results on compiling thousands of qubits, and on verifying the correctness of the compiler output. Generally, verifying the correctness is an intractable problem. An example of this will be showcased during our talk. With respect to future work, we will present our preliminary results on implementing massively parallel compilation of very large scale circuits.\n\n23rd of February\n\n14:15 (Helsinki time) Thaha Mohammed:\n\nSparse Matrix Vector Multiplication (SpMVM) on Graphical processing units Sparse linear algebra is vital to many fields of science and engineering. The matrix sparsity structures vary widely based on the application domains and this poses major challenges in obtaining consistent high performance from sparse iterative solvers on GPUs. These challenges include coalesced memory access and load balancing. Due to the sparsity of the matrices there is no single storage/algorithmic technique that is suitable for all sparse matrix structures. In this talk we survey basic techniques and recent developments in SpMV computations on GPUs. Paper 2nd of February\n\n14:15 (Helsinki time) Michal Dory:\n\nFault-Tolerant Labeling and Compact Routing Schemes Assume that you have a huge graph, where edges and vertices may fail, and you want to answer questions about this graph quickly, without inspecting the whole graph. A fault-tolerant labeling scheme allows us to do just that. It is a distributed data structure, in which each vertex and edge is assigned a short label, such that given the labels of a pair of vertices $s,t$, and a set of failures $F$, you can answer questions about $s$ and $t$ in $G \\setminus F$. For example, determine if $s$ and $t$ are connected in $G \\setminus F$, just by looking at their labels.\n\nI will discuss a recent work where we show the first fault-tolerant connectivity labeling schemes for general graphs. I will also show applications for fault-tolerant routing. Here the goal is to provide each vertex a small routing table, such that given these tables we can efficiently route messages in the network, even in the presence of failures.\n\nBased on a joint work with Merav Parter. ArXiv 19th of January\n\n14:15 (Helsinki time) Michael Kapralov:\n\nStreaming (Lower Bounds) Given a large dataset as a stream of updates, how can we approximate its properties using a very small memory footprint? And what are the limitations imposed by the memory constraints? In this talk we will survey basic techniques and recent developments in graph streaming, with a focus on lower bounds. 1st of December\n\nNon-standard time\n\n17:15 (Helsinki time) Nathan Klein:\n\nA (Slightly) Improved Approximation Algorithm for Metric TSP I will describe work in which we obtain a randomized $3/2-\\epsilon$ approximation algorithm for metric TSP, for some $\\epsilon>10^{-36}$. This slightly improves over the classical 3/2 approximation algorithm due to Christofides [1976] and Serdyukov [1978]. Following the approach of Oveis Gharan, Saberi, and Singh [2010], we analyze an algorithm which is a small modification of Christofides-Serdyukov: we obtain a TSP tour by adding a matching to a random spanning tree instead of one of minimum cost. The talk will focus on giving an overview of the key ideas involved to analyze the approximation factor of this algorithm, such as properties of random spanning trees and the structure of near minimum cuts.\n\nI will also discuss a recent extension in which we show a $3/2-\\epsilon$ bound on the integrality gap of the subtour elimination polytope. This is joint work with Anna Karlin and Shayan Oveis Gharan. ArXiv 24th of November\n\n14:15 (Helsinki time) Roie Levin:\n\nRandom Order Set Cover is as Easy as Offline We give a polynomial time algorithm for Online Set Cover with a competitive ratio of $O(\\log mn)$ when the elements are revealed in random order, essentially matching the best possible offline bound of $O(\\log n)$ and circumventing the $O(\\log m \\log n)$ lower bound known in adversarial order. We also extend the result to solving pure covering IPs when constraints arrive in random order. The algorithm is a multiplicative-weights-based round-and-solve approach we call Learn-Or-Cover. We maintain a coarse fractional solution that is neither feasible nor monotone increasing, but can nevertheless be rounded online to achieve the claimed guarantee (in the random order model). This gives a new offline algorithm for Set Cover that performs a single pass through the elements, which may be of independent interest.\n\nThis is joint work with Anupam Gupta and Gregory Kehne. 17th of November\n\n14:15 (Helsinki time) Kamyar Khodamoradi:\n\nLocal Search for (Stable) $k$-Means In the classic (discrete) $k$-Median/Means problem, we are given a set of $n$ points in a metric alongside the parameter $k$, and our task is to choose $k$ of these points as centres such that the cost of connecting all the points to them is minimized. For $k$-Median, the cost of connecting a point to a set of centres is just the distance of the point to the closest centre in the set, and for $k$-Means, this cost is the square of the distance. In this talk, I will focus on a \"promise'' variation of $k$-Median/Means where, 1) the metric is a Euclidean plane of constant dimensions, and 2) the instances of the problem are guaranteed to satisfy some stability constraint.\n\nStable optimization is a relatively young sub-field of optimization and approximation theory (introduced by Bilu and Linial in 2010), and can be seen as a \"beyond the worst-case'' type of analysis. In the context of $k$-Means, an important notion of stability is that of perturbation resilience. An instance is called $\\alpha$-perturbation resilient if there is a promise of a unique optimum solution which remains optimum even if the distances are (potentially non-uniformly) stretched by a factor of at most $\\alpha$. Stable clustering instances have been studied to explain why heuristics such as Lloydâs algorithm perform well in practice.\n\nIn this talk, I will show how $(1 + \\varepsilon)$-stable instances of $k$-Means in bounded-dimension Euclidean metrics can be solved in polynomial time, using a simple local search algorithm. To give some background about the work, I will first roughly sketch how local search was applied to the (not necessarily stable) Euclidean instances of the problem (Friggstad et al., FOCS 2016) to obtain a $(1 + \\varepsilon)$-approximation. 10th of November\n\n14:15 (Helsinki time) Oren Louidor:\n\nA Scaling limit for the Cover Time of the Binary Tree We consider a continuous time random walk on the rooted binary tree of depth $n$ with all transition rates equal to one and study its cover time, namely the time until all vertices of the tree have been visited. We prove that, normalized by $2^{n+1} n$ and then centered by $(\\log 2) n - \\log n$, the cover time admits a weak limit as the depth of the tree tends to infinity. The limiting distribution is identified as that of a Gumbel random variable with rate one, shifted randomly by the logarithm of the sum of the limits of the derivative martingales associated with two negatively correlated discrete Gaussian free fields on the infinite version of the tree. The existence of the limit and its overall form were conjectured in the literature. Our approach is quite different from those taken in earlier works on this subject and relies in great part on a comparison with the extremal landscape of the discrete Gaussian free field on the tree.\n\nJoint work with Aser Cortines and Santiago Saglietti. ArXiv 27th of October\n\n14:15 (Helsinki time) Rustam Latypov:\n\nMemory Efficient Massively Parallel Algorithms for LCL Problems on Trees We pioneer the low-space Massively Parallel Computation (MPC) complexity landscape for a family of fundamental graph problems on trees. We give a general method that solves most locally checkable labeling (LCL) problems exponentially faster in the low-space MPC model than in the LOCAL message passing model. In particular, we show that all solvable LCL problems on trees can be solved in $O(\\log n)$ time (high-complexity regime) and that all LCL problems on trees with deterministic complexity $n^{o(1)}$ in the LOCAL model can be solved in $O(\\log \\log n)$ time (mid-complexity regime). We emphasize that we solve LCL problems on constant degree trees, our algorithms are deterministic, and they work in the low-space MPC model, where local memory is $O(n^\\delta)$ for $\\delta \\in (0,1)$ and global memory is $O(m)$.\n\nFor the high-complexity regime, their are two key ingredients. One is a novel $O(\\log n)$ time tree rooting algorithm, which may be of independent interest. The other ingredient is a novel pointer-chain technique and analysis that allows us to solve any solvable LCL problem on trees in $O(\\log n)$ time. For the mid-complexity regime, we adapt the approach by Chang and Pettie [FOCS'17], who gave a canonical LOCAL algorithm for solving LCL problems on trees. For the special case of 3-coloring trees, which is a natural LCL problem with LOCAL time complexity $n^{o(1)}$, we show that our analysis is tight, as it matches the conditional $\\Omega(\\log \\log n)$ lower bound for component-stable algorithms. 13th of October\n\n14:15 (Helsinki time) SÃ¡ndor Kisfaludi-Bak:\n\nThe traveling salesman and the Steiner tree with flat neighborhoods In the classic Euclidean traveling salesman problem, we are given n points in the Euclidean plane, and the goal is to find the shortest round trip that visits all the points. The Steiner tree asks for the shortest tree that can connect these points. An interesting variant of these problems is when instead of visiting points, we are asked to visit n \"neighborhoods\". A neighborhood could be any sort of geometric object; the goal is then to visit at least one point in each object. For example, we could be given a set of affine subspaces (often called flats) in $d$-dimensional Euclidean space, and the goal is to find the shortest round trip or tree that intersects each subspace. We will see how the 2-dimensional problems with line neighborhoods can be tackled, and see how the optimum tour for hyperplane neighborhoods ($(d-1)$-dimensional flats) can be efficiently approximated in higher dimensions. It turns out that these neighborhood problems have a different computational complexity than the classic problems with points: they require a novel approach for the hyperplane case, while the case of lower-dimensional flats remain largely mysterious. 6th of October\n\nNon-standard time\n\n17:15 (Helsinki time) Yakov Nekrich:\n\nDynamic Point Location in Optimal Time. In the dynamic point location problem we maintain a planar subdivision under insertions and deletions of segments so that for any query point $q$ the polygon containing $q$ can be found efficiently. In the dynamic vertical ray shooting problem we maintain a set of non-intersecting segments on a plane, so that for an arbitrary query point $q$ the highest segment immediately below $q$ can be found efficiently, where the segment immediately below $q$ is the first segment hit by a downward vertical ray from $q$. Vertical ray shooting and point location are closely connected problems: a data structure for vertical ray shooting can be transformed into a data structure for planar point location. In this talk we present a fully-dynamic data structure that supports point location queries in a connected planar subdivision with $n$ edges. Our data structure uses $O(n)$ space, answers queries in $O(\\log n)$ time, and supports updates in $O(\\log n)$ time. Our solution is based on a data structure for vertical ray shooting queries that supports queries and updates in $O(\\log n)$ time. Paper 29th of September\n\n14:15 (Helsinki time) Noam Touitou:\n\nFlow Time Scheduling with Uncertain Processing Time We consider the problem of online scheduling on a single machine in order to minimize weighted flow time. The existing algorithms for this problem (STOC '01, SODA '03, FOCS '18) all require exact knowledge of the processing time of each job. This assumption is crucial, as even a slight perturbation of the processing time would lead to polynomial competitive ratio. However, this assumption very rarely holds in real-life scenarios.\n\nIn this paper, we present the first algorithm for weighted flow time which do not require exact knowledge of the processing times of jobs. Specifically, we introduce the Scheduling with Predicted Processing Time (SPPT) problem, where the algorithm is given a prediction for the processing time of each job, instead of its real processing time. For the case of a constant factor distortion between the predictions and the real processing time, our algorithms match all the best known competitiveness bounds for weighted flow time -- namely $O(\\log P)$, $O(\\log D)$ and $O(\\log W)$, where $P, D, W$ are the maximum ratios of processing times, densities, and weights, respectively. For larger errors, the competitiveness of our algorithms degrades gracefully. ArXiv 22nd of September\n\n14:15 (Helsinki time) Chetan Gupta:\n\nDerandomizing Isolation Lemma for Special Classes of Graphs Isolation lemma states that if we randomly assign polynomially large weights to the elements of a set $S$ then for any family $F$ of subsets of $S$, the minimum weight subset in F will be unique with high probability. Isolation lemma has found numerous applications in complexity theory since its introduction. In this talk, I will talk about its application in the two fundamental problems in complexity theory, perfect matching and directed graph reachability.\n\nIn the perfect matching problem, we want to find out whether a given graph has a perfect matching or not. Perfect matching problem is known to have a polynomial-time sequential algorithm. In complexity theory, most often, for every problem that has a polynomial-time sequential algorithm, people try to find an efficient parallel algorithm (NC algorithm) for the same in order to make progress towards P vs NC question. But the question whether there exists an efficient parallel algorithm for perfect matching or not has been elusive so far. Efforts to find an efficient parallel algorithm for perfect matching spurred powerful tools like isolation lemma. It was shown that if we can derandomize the isolation lemma for perfect matchings, that is, if we can efficiently construct polynomial-size weights for the edges of a graph such that minimum weight perfect matching in the graph is unique then the perfect matching problem can be solved in SPL, which is a small subclass of NC.\n\nIn the graph reachability problem, given a directed graph and two vertices, we are asked whether there exists a path from one vertex to another or not. Reachability is a complete problem for complexity class NL, which is a class of problems that can be solved by nondeterministic Turing machines in logspace. The question whether reachability can be solved by an unambiguous logspace Turing machine (UL) or not is still open. It was shown that if we can derandomize the isolation lemma for paths, then reachability can be solved by a UL machine. This talk will explain how we can derandomize the isolation lemma for $O(\\log n)$ genus graphs and single-crossing minor free graphs to obtain an SPL bound for bipartite perfect matching and UL bound for reachabilty, in these two classes. Slides\n\nArXiv\n\nMFCS 15th of September\n\n14:15 (Helsinki time) Laurent Feuilloley:\n\nThe Secretary Problem with Independent Sampling The secretary problem is a classic online decision problem. In this problem, an adversary first chooses some n numbers, then these numbers are shuffled at random and presented to the player one by one. For each number, the player has two options: discard the number and continue, or keep the number and stop the game. The player wins if she kept the highest number of the whole set. It is clearly not possible to win all the time: when one decides to stop there might be a higher number in the rest of the sequence, and when one discards a number, it might actually be the highest of the sequence. But surprisingly one can win with probability $1/e$.\n\nAn issue with the secretary problem is that it assumes that the player has absolutely no information about the numbers, which reduces its applicability. A recent research direction is to understand what happens when one knows a distribution or samples etc. We study a simple such setting for which we prove tight results. Interestingly, some of the lower bound techniques we use are inspired by ideas from distributed graph algorithms. ArXiv 8th of September\n\nNon-standard time\n\n17:00 (Helsinki time) Jan van den Brand:\n\nUnifying Matrix Data Structures - Simplifying and Speeding up Iterative Algorithms Many algorithms use data structures that maintain properties of matrices undergoing some changes. The applications are wide-ranging and include for example matchings, shortest paths, linear programming, semi-definite programming, convex hull and volume computation. Given the wide range of applications, the exact property these data structures must maintain varies from one application to another, forcing algorithm designers to invent them from scratch or modify existing ones. Thus it is not surprising that these data structures and their proofs are usually tailor-made for their specific application and that maintaining more complicated properties results in more complicated proofs. In this talk, I present a unifying framework that captures a wide range of these data structures. The simplicity of this framework allows us to give short proofs for many existing data structures regardless of how complicated the to be maintained property is. We also show how the f"
    }
}