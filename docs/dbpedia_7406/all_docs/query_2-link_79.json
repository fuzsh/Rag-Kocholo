{
    "id": "dbpedia_7406_2",
    "rank": 79,
    "data": {
        "url": "https://kafka.apache.org/documentation/",
        "read_more_link": "",
        "language": "en",
        "title": "Apache Kafka",
        "top_image": "http://apache-kafka.org/images/apache-kafka.png",
        "meta_img": "http://apache-kafka.org/images/apache-kafka.png",
        "images": [
            "https://kafka.apache.org/images/feather-small.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "apache kafka messaging queuing distributed stream processing"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Apache Kafka: A Distributed Streaming Platform.",
        "meta_lang": "",
        "meta_favicon": "/images/apache_feather.gif",
        "meta_site_name": "Apache Kafka",
        "canonical_link": null,
        "text": "Documentation\n\nKafka 3.8 Documentation\n\nPrior releases: 0.7.x, 0.8.0, 0.8.1.X, 0.8.2.X, 0.9.0.X, 0.10.0.X, 0.10.1.X, 0.10.2.X, 0.11.0.X, 1.0.X, 1.1.X, 2.0.X, 2.1.X, 2.2.X, 2.3.X, 2.4.X, 2.5.X, 2.6.X, 2.7.X, 2.8.X, 3.0.X. 3.1.X. 3.2.X. 3.3.X. 3.4.X. 3.5.X. 3.6.X. 3.7.X.\n\n1. Getting Started\n\n1.1 Introduction\n\n1.2 Use Cases\n\nHere is a description of a few of the popular use cases for Apache KafkaÂ®. For an overview of a number of these areas in action, see this blog post.\n\nMessaging\n\nKafka works well as a replacement for a more traditional message broker. Message brokers are used for a variety of reasons (to decouple processing from data producers, to buffer unprocessed messages, etc). In comparison to most messaging systems Kafka has better throughput, built-in partitioning, replication, and fault-tolerance which makes it a good solution for large scale message processing applications.\n\nIn our experience messaging uses are often comparatively low-throughput, but may require low end-to-end latency and often depend on the strong durability guarantees Kafka provides.\n\nIn this domain Kafka is comparable to traditional messaging systems such as ActiveMQ or RabbitMQ.\n\nWebsite Activity Tracking\n\nThe original use case for Kafka was to be able to rebuild a user activity tracking pipeline as a set of real-time publish-subscribe feeds. This means site activity (page views, searches, or other actions users may take) is published to central topics with one topic per activity type. These feeds are available for subscription for a range of use cases including real-time processing, real-time monitoring, and loading into Hadoop or offline data warehousing systems for offline processing and reporting.\n\nActivity tracking is often very high volume as many activity messages are generated for each user page view.\n\nMetrics\n\nKafka is often used for operational monitoring data. This involves aggregating statistics from distributed applications to produce centralized feeds of operational data.\n\nLog Aggregation\n\nMany people use Kafka as a replacement for a log aggregation solution. Log aggregation typically collects physical log files off servers and puts them in a central place (a file server or HDFS perhaps) for processing. Kafka abstracts away the details of files and gives a cleaner abstraction of log or event data as a stream of messages. This allows for lower-latency processing and easier support for multiple data sources and distributed data consumption. In comparison to log-centric systems like Scribe or Flume, Kafka offers equally good performance, stronger durability guarantees due to replication, and much lower end-to-end latency.\n\nStream Processing\n\nMany users of Kafka process data in processing pipelines consisting of multiple stages, where raw input data is consumed from Kafka topics and then aggregated, enriched, or otherwise transformed into new topics for further consumption or follow-up processing. For example, a processing pipeline for recommending news articles might crawl article content from RSS feeds and publish it to an \"articles\" topic; further processing might normalize or deduplicate this content and publish the cleansed article content to a new topic; a final processing stage might attempt to recommend this content to users. Such processing pipelines create graphs of real-time data flows based on the individual topics. Starting in 0.10.0.0, a light-weight but powerful stream processing library called Kafka Streams is available in Apache Kafka to perform such data processing as described above. Apart from Kafka Streams, alternative open source stream processing tools include Apache Storm and Apache Samza.\n\nEvent Sourcing\n\nEvent sourcing is a style of application design where state changes are logged as a time-ordered sequence of records. Kafka's support for very large stored log data makes it an excellent backend for an application built in this style.\n\nCommit Log\n\nKafka can serve as a kind of external commit-log for a distributed system. The log helps replicate data between nodes and acts as a re-syncing mechanism for failed nodes to restore their data. The log compaction feature in Kafka helps support this usage. In this usage Kafka is similar to Apache BookKeeper project.\n\n1.3 Quick Start\n\n1.4 Ecosystem\n\nThere are a plethora of tools that integrate with Kafka outside the main distribution. The ecosystem page lists many of these, including stream processing systems, Hadoop integration, monitoring, and deployment tools.\n\n1.5 Upgrading From Previous Versions\n\n1.6 Docker\n\n2. APIs\n\n3. Configuration\n\n4. Design\n\n5. Implementation\n\n6. Operations\n\n7. Security\n\n8. Kafka Connect\n\n9. Kafka Streams\n\nKafka Streams is a client library for processing and analyzing data stored in Kafka. It builds upon important stream processing concepts such as properly distinguishing between event time and processing time, windowing support, exactly-once processing semantics and simple yet efficient management of application state.\n\nKafka Streams has a low barrier to entry: You can quickly write and run a small-scale proof-of-concept on a single machine; and you only need to run additional instances of your application on multiple machines to scale up to high-volume production workloads. Kafka Streams transparently handles the load balancing of multiple instances of the same application by leveraging Kafka's parallelism model."
    }
}