{
    "id": "dbpedia_7406_1",
    "rank": 67,
    "data": {
        "url": "https://pulsar.apache.org/docs/3.3.x/concepts-messaging/",
        "read_more_link": "",
        "language": "en",
        "title": "Apache Pulsar",
        "top_image": "https://pulsar.apache.org/img/pulsar-social-media-card.png",
        "meta_img": "https://pulsar.apache.org/img/pulsar-social-media-card.png",
        "images": [
            "https://pulsar.apache.org/img/logo-black.svg",
            "https://pulsar.apache.org/img/logo-black.svg",
            "https://pulsar.apache.org/assets/images/pub-sub-border-f20912d3eb1385f083ce0406685ceab7.svg",
            "https://pulsar.apache.org/assets/images/retry-letter-topic-5304f63457e6c17da20d0de7b6897a5b.svg",
            "https://pulsar.apache.org/assets/images/batching-a9d3dbabf97b2b6c504c6f353ccfda98.svg",
            "https://pulsar.apache.org/assets/images/chunking-01-194c42c53633b89cb7f4653c537d4264.png",
            "https://pulsar.apache.org/assets/images/chunking-02-50ca285dd380b4bbecc01774655ead49.png",
            "https://pulsar.apache.org/assets/images/pulsar-subscription-types-664733b68c7124129ca7d0e04dedcb96.png",
            "https://pulsar.apache.org/assets/images/pulsar-exclusive-subscriptions-b3304e5b293d0a6da17637735fcb1650.svg",
            "https://pulsar.apache.org/assets/images/pulsar-failover-subscriptions-5-9d3e27825c143823bb47244dfc33154e.png",
            "https://pulsar.apache.org/assets/images/pulsar-failover-subscriptions-1-bb15a6e2f6373dc1f20eecf1779ee0c7.svg",
            "https://pulsar.apache.org/assets/images/pulsar-failover-subscriptions-2-1f72791597afa07fa987ae1f7bc5cd42.svg",
            "https://pulsar.apache.org/assets/images/pulsar-failover-subscriptions-3-2b2e00ef5ee525ca7c1fd21dcd67e328.svg",
            "https://pulsar.apache.org/assets/images/pulsar-shared-subscriptions-c368030415b85eb3ef96448f79e87a58.svg",
            "https://pulsar.apache.org/assets/images/pulsar-key-shared-subscriptions-17bf12baab858b4ac0e66b9207bf4503.svg",
            "https://pulsar.apache.org/assets/images/partitioning-622ea170dd771fd212d6b7378f2bd928.png",
            "https://pulsar.apache.org/assets/images/retention-expiry-e45fc08fa68c18a8f1d4868ec2c022d7.svg",
            "https://pulsar.apache.org/assets/images/message-deduplication-854309d2abf6e9ba16d2a3f090e59ace.svg",
            "https://pulsar.apache.org/assets/images/message-delay-bcb21c8762efb886a192ae9557096f5d.svg",
            "https://pulsar.apache.org/img/slack-white.svg",
            "https://pulsar.apache.org/img/github-white.svg",
            "https://pulsar.apache.org/img/pulsar-white.svg",
            "https://pulsar.apache.org/img/pulsar-white.svg",
            "https://pulsar.apache.org/img/feather-logo-white.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Get a comprehensive understanding of essential messaging concepts within Pulsar, including topics, namespaces, subscriptions, and more.",
        "meta_lang": "en",
        "meta_favicon": "/img/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://pulsar.apache.org/docs/concepts-messaging/",
        "text": "Messaging\n\nPulsar is built on the publish-subscribe pattern (often abbreviated to pub-sub). In this pattern, producers publish messages to topics; consumers subscribe to those topics, process incoming messages, and send acknowledgments to the broker when processing is finished.\n\nWhen a subscription is created, Pulsar retains all messages, even if the consumer is disconnected. The retained messages are discarded only when a consumer acknowledges that all these messages are processed successfully.\n\nIf the consumption of a message fails and you want this message to be consumed again, you can enable the message redelivery mechanism to request the broker to resend this message.\n\nMessages are the basic \"unit\" of Pulsar. They're what producers publish to topics and what consumers then consume from topics. The following table lists the components of messages.\n\nComponentDescriptionValue / data payloadThe data carried by the message. All Pulsar messages contain raw bytes, although message data can also conform to data schemas.KeyThe key (string type) of the message. It is a short name of message key or partition key. Messages are optionally tagged with keys, which is useful for features like topic compaction.PropertiesAn optional key/value map of user-defined properties.Producer nameThe name of the producer who produces the message. If you do not specify a producer name, the default name is used.Topic nameThe name of the topic that the message is published to.Schema versionThe version number of the schema that the message is produced with.Sequence IDEach Pulsar message belongs to an ordered sequence on its topic. The sequence ID of a message is initially assigned by its producer, indicating its order in that sequence, and can also be customized.\n\nSequence ID can be used for message deduplication. If brokerDeduplicationEnabled is set to true, the sequence ID of each message is unique within a producer of a topic (non-partitioned) or a partition.Message IDThe message ID of a message is assigned by bookies as soon as the message is persistently stored. Message ID indicates a message's specific position in a ledger and is unique within a Pulsar cluster.Publish timeThe timestamp of when the message is published. The timestamp is automatically applied by the producer.Event timeAn optional timestamp attached to a message by applications. For example, applications attach a timestamp on when the message is processed. If nothing is set to event time, the value is 0.\n\nThe default max size of a message is 5 MB. You can configure the max size of a message with the following configuration options.\n\nIn the broker.conf file.\n\nmaxMessageSize=5242880\n\nIn the bookkeeper.conf file.\n\nnettyMaxFrameSizeBytes=5253120\n\nFor more information on Pulsar messages, see Pulsar binary protocol.\n\nA message acknowledgment is sent by a consumer to a broker after the consumer consumes a message successfully. Then, this consumed message will be permanently stored and deleted only after all the subscriptions have acknowledged it. An acknowledgment (ack) is Pulsar's way of knowing that the message can be deleted from the system. If you want to store the messages that have been acknowledged by a consumer, you need to configure the message retention policy.\n\nFor batch messages, you can enable batch index acknowledgment to avoid dispatching acknowledged messages to the consumer. For details about batch index acknowledgment, see batching.\n\nMessages can be acknowledged in one of the following two ways:\n\nBeing acknowledged individually\n\nWith individual acknowledgment, the consumer acknowledges each message and sends an acknowledgment request to the broker.\n\nBeing acknowledged cumulatively\n\nWith cumulative acknowledgment, the consumer only acknowledges the last message it received. All messages in the stream up to (and including) the provided message are not redelivered to that consumer.\n\nIf you want to acknowledge messages individually, you can use the following API.\n\nIf you want to acknowledge messages cumulatively, you can use the following API.\n\nThe negative acknowledgment mechanism allows you to send a notification to the broker indicating the consumer did not process a message. When a consumer fails to consume a message and needs to re-consume it, the consumer sends a negative acknowledgment (nack) to the broker, triggering the broker to redeliver this message to the consumer.\n\nMessages are negatively acknowledged individually or cumulatively, depending on the consumption subscription type.\n\nIn Exclusive and Failover subscription types, consumers only negatively acknowledge the last message they receive.\n\nIn Shared and Key_Shared subscription types, consumers can negatively acknowledge messages individually.\n\nBe aware that negative acknowledgments on ordered subscription types, such as Exclusive, Failover and Key_Shared, might cause failed messages being sent to consumers out of the original order.\n\nIf you are going to use negative acknowledgment on a message, make sure it is negatively acknowledged before the acknowledgment timeout.\n\nUse the following API to negatively acknowledge message consumption.\n\nTo redeliver messages with different delays, you can use the redelivery backoff mechanism by setting the number of retries to deliver the messages. Use the following API to enable Negative Redelivery Backoff.\n\nThe message redelivery behavior should be as follows.\n\nRedelivery countRedelivery delay11 seconds22 seconds34 seconds48 seconds516 seconds632 seconds760 seconds860 seconds\n\nThe acknowledgment timeout mechanism allows you to set a time range during which the client tracks the unacknowledged messages. After this acknowledgment timeout (ackTimeout) period, the client sends redeliver unacknowledged messages request to the broker, thus the broker resends the unacknowledged messages to the consumer.\n\nYou can configure the acknowledgment timeout mechanism to redeliver the message if it is not acknowledged after ackTimeout or to execute a timer task to check the acknowledgment timeout messages during every ackTimeoutTickTime period.\n\nYou can also use the redelivery backoff mechanism to redeliver messages with different delays by setting the number of times the messages are retried.\n\nIf you want to use redelivery backoff, you can use the following API.\n\nThe message redelivery behavior should be as follows.\n\nRedelivery countRedelivery delay110 + 1 seconds210 + 2 seconds310 + 4 seconds410 + 8 seconds510 + 16 seconds610 + 32 seconds710 + 60 seconds810 + 60 seconds\n\nUse the following API to enable acknowledgment timeout.\n\nRetry letter topic allows you to store the messages that failed to be consumed and retry consuming them later. With this method, you can customize the interval at which the messages are redelivered. Consumers on the original topic are automatically subscribed to the retry letter topic as well. Once the maximum number of retries has been reached, the unconsumed messages are moved to a dead letter topic for manual processing. The functionality of a retry letter topic is implemented by consumers.\n\nThe diagram below illustrates the concept of the retry letter topic.\n\nThe intention of using retry letter topic is different from using delayed message delivery, even though both are aiming to consume a message later. Retry letter topic serves failure handling through message redelivery to ensure critical data is not lost, while delayed message delivery is intended to deliver a message with a specified time delay.\n\nBy default, automatic retry is disabled. You can set enableRetry to true to enable automatic retry on the consumer.\n\nUse the following API to consume messages from a retry letter topic. When the value of maxRedeliverCount is reached, the unconsumed messages are moved to a dead letter topic.\n\nThe default retry letter topic uses this format:\n\nUse the Java client to specify the name of the retry letter topic.\n\nThe messages in the retry letter topic contain some special properties that are automatically created by the client.\n\nSpecial propertyDescriptionREAL_TOPICThe real topic name.ORIGIN_MESSAGE_IDThe origin message ID. It is crucial for message tracking.RECONSUMETIMESThe number of retries to consume messages.DELAY_TIMEMessage retry interval in milliseconds.\n\nExample\n\nUse the following API to store the messages in a retrial queue.\n\nUse the following API to add custom properties for the reconsumeLater function. In the next attempt to consume, custom properties can be get from message#getProperty.\n\nDead letter topic allows you to continue message consumption even when some messages are not consumed successfully. The messages that have failed to be consumed are stored in a specific topic, which is called the dead letter topic. The functionality of a dead letter topic is implemented by consumers. You can decide how to handle the messages in the dead letter topic.\n\nEnable dead letter topic in a Java client using the default dead letter topic.\n\nThe default dead letter topic uses this format:\n\nThe dead letter producerName uses this format:\n\nUse the Java client to specify the name of the dead letter topic.\n\nBy default, there is no subscription during DLQ topic creation. Without a just-in-time subscription to the DLQ topic, you may lose messages. To automatically create an initial subscription for the DLQ, you can specify the initialSubscriptionName parameter. If this parameter is set but the broker's allowAutoSubscriptionCreation is disabled, the DLQ producer will fail to be created.\n\nDead letter topic serves message redelivery, which is triggered by acknowledgment timeout or negative acknowledgment or retry letter topic.\n\nMessage compression can reduce message size by paying some CPU overhead. The Pulsar client supports the following compression types:\n\nLZ4\n\nZLIB\n\nZSTD\n\nSNAPPY\n\nCompression types are stored in the message metadata, so consumers can adopt different compression types automatically, as needed.\n\nThe sample code below shows how to enable compression type for a producer:\n\nWhen batching is enabled, the producer accumulates and sends a batch of messages in a single request. The batch size is defined by the maximum number of messages and the maximum publish latency. Therefore, the backlog size represents the total number of batches instead of the total number of messages.\n\nIn Pulsar, batches are tracked and stored as single units rather than as individual messages. Consumers unbundle a batch into individual messages. However, scheduled messages (configured through the deliverAt or the deliverAfter parameter) are always sent as individual messages even when batching is enabled.\n\nIn general, a batch is acknowledged when all of its messages are acknowledged by a consumer. It means that when not all batch messages are acknowledged, then unexpected failures, negative acknowledgments, or acknowledgment timeouts can result in a redelivery of all messages in this batch.\n\nTo avoid redelivering acknowledged messages in a batch to the consumer, Pulsar introduces batch index acknowledgment since Pulsar 2.6.0. When batch index acknowledgment is enabled, the consumer filters out the batch index that has been acknowledged and sends the batch index acknowledgment request to the broker. The broker maintains the batch index acknowledgment status and tracks the acknowledgment status of each batch index to avoid dispatching acknowledged messages to the consumer. The batch is deleted when all indices of the messages in it are acknowledged.\n\nBy default, batch index acknowledgment is disabled (acknowledgmentAtBatchIndexLevelEnabled=false). You can enable batch index acknowledgment by setting the acknowledgmentAtBatchIndexLevelEnabled parameter to true at the broker side. Enabling batch index acknowledgment results in more memory overheads.\n\nBatch index acknowledgment must also be enabled in the consumer by calling .enableBatchIndexAcknowledgment(true);\n\nFor example:\n\nMessage chunking enables Pulsar to process large payload messages by splitting the message into chunks at the producer side and aggregating chunked messages at the consumer side.\n\nWith message chunking enabled, when the size of a message exceeds the allowed maximum payload size (the maxMessageSize parameter of broker), the workflow of messaging is as follows:\n\nThe producer splits the original message into chunked messages and publishes them with chunked metadata to the broker separately and in order.\n\nThe broker stores the chunked messages in one managed ledger in the same way as that of ordinary messages, and it uses the chunkedMessageRate parameter to record chunked message rate on the topic.\n\nThe consumer buffers the chunked messages and aggregates them into the receiver queue when it receives all the chunks of a message.\n\nThe client consumes the aggregated message from the receiver queue.\n\nThe following figure shows a topic with one producer that publishes a large message payload in chunked messages along with regular non-chunked messages. The producer publishes message M1 in three chunks labeled M1-C1, M1-C2 and M1-C3. The broker stores all the three chunked messages in the managed ledger and dispatches them to the ordered (exclusive/failover) consumer in the same order. The consumer buffers all the chunked messages in memory until it receives all the chunked messages, aggregates them into one message and then hands over the original message M1 to the client.\n\nWhen multiple producers publish chunked messages into a single topic, the broker stores all the chunked messages coming from different producers in the same managed ledger. The chunked messages in the managed ledger can be interwoven with each other. As shown below, Producer 1 publishes message M1 in three chunks M1-C1, M1-C2 and M1-C3. Producer 2 publishes message M2 in three chunks M2-C1, M2-C2 and M2-C3. All chunked messages of the specific message are still in order but might not be consecutive in the managed ledger.\n\nPrerequisite: Disable batching by setting the enableBatching parameter to false.\n\nThe message chunking feature is OFF by default. To enable message chunking, set the chunkingEnabled parameter to true when creating a producer.\n\nA Pulsar topic is a unit of storage that organizes messages into a stream. As in other pub-sub systems, topics in Pulsar are named channels for transmitting messages from producers to consumers. Topic names are URLs that have a well-defined structure:\n\nTopic name componentDescriptionpersistent / non-persistentThis identifies the type of topic. Pulsar supports two kind of topics: persistent and non-persistent. The default is persistent, so if you do not specify a type, the topic is persistent. With persistent topics, all messages are durably persisted on disks (if the broker is not standalone, messages are durably persisted on multiple disks), whereas data for non-persistent topics is not persisted to storage disks.tenantThe topic tenant within the instance. Tenants are essential to multi-tenancy in Pulsar, and spread across clusters.namespaceThe administrative unit of the topic, which acts as a grouping mechanism for related topics. Most topic configuration is performed at the namespace level. Each tenant has one or more namespaces.topicThe final part of the name. Topic names have no special meaning in a Pulsar instance.\n\nA Pulsar namespace is a logical grouping of topics as well as a logical nomenclature within a tenant. A tenant creates namespaces via the admin API. For instance, a tenant with different applications can create a separate namespace for each application. A namespace allows the application to create and manage a hierarchy of topics. The topic my-tenant/app1 is a namespace for the application app1 for my-tenant. You can create any number of topics under the namespace.\n\nA Pulsar subscription is a named configuration rule that determines how messages are delivered to consumers. It is a lease on a topic established by a group of consumers. There are four subscription types in Pulsar:\n\nexclusive\n\nshared\n\nfailover\n\nkey_shared\n\nThese types are illustrated in the figure below.\n\nWhen a subscription has no consumers, its subscription type is undefined. The type of a subscription is defined when a consumer connects to it, and the type can be changed by restarting all consumers with a different configuration.\n\nThe exclusive type is a subscription type that only allows a single consumer to attach to the subscription. If multiple consumers subscribe to a topic using the same subscription, an error occurs. Note that if the topic is partitioned, all partitions will be consumed by the single consumer allowed to be connected to the subscription.\n\nIn the diagram below, only Consumer A is allowed to consume messages.\n\nThe failover type is a subscription type that multiple consumers can attach to the same subscription.\n\nA master consumer is picked for a non-partitioned topic or each partition of a partitioned topic and receives messages.\n\nWhen the master consumer disconnects, all (non-acknowledged and subsequent) messages are delivered to the next consumer in line.\n\nFor partitioned topics, the broker sorts consumers by priority and lexicographical order of consumer name.\n\nThe broker tries to evenly assign partitions to consumers with the highest priority.\n\nA consumer is selected by running a module operation mod (partition index, consumer index).\n\nIf the number of partitions in a partitioned topic is less than the number of consumers:\n\nFor example, in the diagram below, this partitioned topic has 2 partitions and there are 4 consumers.\n\nEach partition has 1 active consumer and 3 stand-by consumers.\n\nFor P0, Consumer A is the master consumer, while Consumer B, Consumer C, and Consumer D would be the next consumer in line to receive messages if consumer A is disconnected.\n\nFor P1, Consumer B is the master consumer, while Consumer A, Consumer C, and Consumer D would be the next consumer in line to receive messages if consumer B is disconnected.\n\nMoreover, if Consumer A and consumer B are disconnected, then\n\nfor P0: Consumer C is the active consumer and Consumer D is the stand-by consumer.\n\nfor P1: Consumer D is the active consumer and Consumer C is the stand-by consumer.\n\nIf the number of partitions in a partitioned topic is greater than the number of consumers:\n\nFor example, in the diagram below, this partitioned topic has 9 partitions and 3 consumers.\n\nP0, P3, and P6 are assigned to Consumer A. Consumer A is their active consumer. Consumer B and Consumer C are their stand-by consumers.\n\nP1, P4, and P7 are assigned to Consumer B. Consumer B is their active consumer. Consumer A and Consumer C are their stand-by consumers.\n\nP2, P5, and P8 are assigned to Consumer C. Consumer C is their active consumer. Consumer A and Consumer B are their stand-by consumers.\n\nIf there is one non-partitioned topic. The broker picks consumers in the order they subscribe to non-partitioned topics.\n\nFor example, in the diagram below, this non-partitioned topic has 1 topic and there are 2 consumers.\n\nThe topic has 1 active consumer and 1 stand-by consumer.\n\nConsumer A is the master consumer, while consumer B would be the next consumer in line to receive messages if consumer A is disconnected.\n\nIf there are multiple non-partitioned topics, a consumer is selected based on consumer name hash and topic name hash. The client uses the same consumer name to subscribe to all the topics.\n\nFor example, in the diagram below, there are 4 non-partitioned topics and 2 consumers.\n\nThe non-partitioned topic 1 and non-partitioned topic 4 are assigned to consumer A. Consumer B is their stand-by consumer.\n\nThe non-partitioned topic 2 and non-partitioned topic 3 are assigned to consumer B. Consumer A is their stand-by consumer.\n\nThe shared subscription type in Pulsar allows multiple consumers to attach to the same subscription. Messages are delivered in a round-robin distribution across consumers, and any given message is delivered to only one consumer. When a consumer disconnects, all the messages that were sent to it and not acknowledged will be rescheduled for sending to the remaining consumers.\n\nIn the diagram below, Consumer A, Consumer B and Consumer C are all able to subscribe to the topic.\n\nThe Key_Shared subscription type in Pulsar allows multiple consumers to attach to the same subscription. But different with the Shared type, messages in the Key_Shared type are delivered in distribution across consumers and messages with the same key or same ordering key are delivered to only one consumer. No matter how many times the message is re-delivered, it is delivered to the same consumer.\n\nThere are three types of mapping algorithms dictating how to select a consumer for a given message key (or ordering key):\n\nAuto-split Hash Range\n\nAuto-split Consistent Hashing\n\nSticky\n\nThe steps for all mapping algorithms are:\n\nThe message key (or ordering key) is passed to a hash function (e.g., Murmur3 32-bit), yielding a 32-bit integer hash.\n\nThat hash number is fed to the algorithm to select a consumer from the existing connected consumers.\n\nWhen a new consumer is connected and thus added to the list of connected consumers, the algorithm re-adjusts the mapping such that some keys currently mapped to existing consumers will be mapped to the newly added consumer. When a consumer is disconnected, thus removed from the list of connected consumers, keys mapped to it will be mapped to other consumers. The sections below will explain how a consumer is selected given the message hash and how the mapping is adjusted given a new consumer is connected or an existing consumer disconnects for each algorithm.\n\nAuto-split Hash Range assumes each consumer is mapped into a single region in a range of numbers between 0 to 2^16 (65,536). So all mapped regions cover the entire range, and no regions overlap. A consumer is selected for a given key by running a modulo operation on the message hash by the range size (65,536). The number received ( 0 <= i < 65,536) is contained within a single region. The consumer mapped to that region is the one selected.\n\nExample:\n\nSuppose we have 4 consumers (C1, C2, C3 and C4), then:\n\nGiven a message key Order-3459134, its hash would be murmur32(\"Order-3459134\") = 3112179635, and its index in the range would be 3112179635 mod 65536 = 6067. That index is contained within region [0, 16384) thus consumer C3 will be mapped to this message key.\n\nWhen a new consumer is connected, the largest region is chosen and is then split in half - the lower half will be mapped to the newly added consumer and upper half will be mapped to the consumer owning that region. Here is how it looks like from 1 to 4 consumers:\n\nWhen a consumer is disconnected its region will be merged into the region on its right. Examples:\n\nC4 is disconnected:\n\nC1 is disconnected:\n\nThe advantages of this algorithm is that it affects only a single existing consumer upon add/delete consumer, at the expense of regions not evenly sized. This means some consumers gets more keys that others. The next algorithm does the other way around.\n\nAuto-split Consistent Hashing assumes each consumer is mapped into a Hash Ring. It's a range of number from 0 to MAX_INT (32-bit) in which if you traverse the range, when reaching MAX_INT, the next number would be zero. It is as if you took a line starting from 0 ending at MAX_INT and bent into a circle such that the end glues to the start:\n\nWhen adding a consumer, we mark 100 points on that circle and associate them to the newly added consumer. For each number between 1 and 100, we concatenate the consumer name to that number and run the hash function on it to get the location of the point on the circle that will be marked. For Example, if the consumer name is \"orders-aggregator-pod-2345-consumer\" then we would mark 100 points on that circle:\n\nSince the hash function has the uniform distribution attribute, those points would be uniformly distributed across the circle.\n\nA consumer is selected for a given message key by putting its hash on the circle then continue clock-wise on the circle until you reach a marking point. The point might have more than one consumer on it (hash function might have collisions) there for, we run the following operation to get a position within the list of consumers for that point, then we take the consumer in that position: hash % consumer_list_size = index.\n\nWhen a consumer is added, we add 100 marking points to the circle as explained before. Due to the uniform distribution of the hash function, those 100 points act as if the new consumer takes a small slice of keys out of each existing consumer. It maintains the even distribution, on the trade-off that it impacts all existing consumers. This video explains the concept of Consistent Hashing quite well (the only difference is that in Pulsar's case we used K points instead of K hash functions as noted in the comments)\n\nSticky assumes each consumer is mapped to a multiple regions in a range of numbers between 0 to 2^16 (65,536) and there is no overlap between regions. The consumer is selected by running a modulo operation on the message hash by the range size (65,536), the number received (0 <= i < 65,536), is contained within a single region. The consumer mapped to the region is the one selected.\n\nIn this algorithm you have full control. Every newly added consumer specifies the ranges it wishes to be mapped to by using Consumer API. When the consumer object is constructed, you can specify the list of ranges. It's your responsibility to make sure there are no overlaps and all the range is covered by regions.\n\nExample:\n\nSuppose we have 2 consumers (C1 and C2) each specified their ranges, then:\n\nGiven a message key Order-3459134, it's hash would be murmur32(\"Order-3459134\") = 3112179635, and it's index in the range would be 3112179635 mod 65536 = 6067. That index is contained within [0, 16384) thus consumer C1 will map to this message key.\n\nIf the newly connected consumer didn't supply their ranges, or they overlap with existing consumer ranges, it's disconnected, removed from the consumers list and reverted as if it never tried to connect.\n\nTo use a mapping algorithm mentioned above, you can specify the Key Shared Mode when building the consumer:\n\nAUTO_SPLIT - Auto-split Hash Range\n\nSTICKY - Sticky\n\nConsistent Hashing will be used instead of Hash Range for Auto-split if the broker configuration subscriptionKeySharedUseConsistentHashing is enabled.\n\nKey Shared Subscription type guarantees a key will be processed by a single consumer at any given time. When a new consumer is connected, some keys will change their mapping from existing consumers to the new consumer. Once the connection has been established, the broker will record the current read position and associate it with the new consumer. The read position is a marker indicating that messages have been dispatched to the consumers up to this point, and after it, no messages have been dispatched yet. The broker will start delivering messages to the new consumer only when all messages up to the read position have been acknowledged. This will guarantee that a certain key is processed by a single consumer at any given time. The trade-off is that if one of the existing consumers is stuck and no time-out was defined (acknowledging for you), the new consumer won't receive any messages until the stuck consumer resumes or gets disconnected.\n\nThat requirement can be relaxed by enabling allowOutOfOrderDelivery via the Consumer API. If set on the new consumer, then when it is connected, the broker will allow it to receive messages knowing some messages of that key may be still be processing in other consumers at the time, thus order may be affected for that short period of adding a new consumer.\n\nThere are two reasons why the key-based batching is necessary for the Key_Shared subscription type:\n\nThe broker dispatches messages according to the keys of the messages, but the default batching approach might fail to pack the messages with the same key to the same batch.\n\nSince it is the consumers instead of the broker who dispatch the messages from the batches, the key of the first message in one batch is considered as the key to all messages in this batch, thereby leading to context errors.\n\nThe key-based batching aims at resolving the above-mentioned issues. This batching method ensures that the producers pack the messages with the same key to the same batch. The messages without a key are packed into one batch and this batch has no key. When the broker dispatches messages from this batch, it uses NON_KEY as the key. In addition, each consumer is associated with only one key and should receive only one message batch for the connected key. By default, you can limit batching by configuring the number of messages that producers are allowed to send.\n\nBelow are examples of enabling the key-based batching under the Key_Shared subscription type, with client being the Pulsar client that you created.\n\nThe subscription mode indicates the cursor belongs to durable type or non-durable type.\n\nWhen a subscription is created, an associated cursor is created to record the last consumed position.\n\nWhen a consumer of the subscription restarts, it can continue consuming from the last message it consumes.\n\nSubscription modeDescriptionNoteDurableThe cursor is durable, which retains messages and persists the current position.\n\nIf a broker restarts from a failure, it can recover the cursor from the persistent storage (BookKeeper), so that messages can continue to be consumed from the last consumed position.Durable is the default subscription mode.NonDurableThe cursor is non-durable.\n\nOnce a broker stops, the cursor is lost and can never be recovered, so that messages can not continue to be consumed from the last consumed position.Reader's subscription mode is NonDurable in nature and it does not prevent data in a topic from being deleted. Reader's subscription mode can not be changed.\n\nA subscription can have one or more consumers. When a consumer subscribes to a topic, it must specify the subscription name. A durable subscription and a non-durable subscription can have the same name, they are independent of each other. If a consumer specifies a subscription that does not exist before, the subscription is automatically created.\n\nBy default, messages of a topic without any durable subscriptions are marked as deleted. If you want to prevent the messages from being marked as deleted, you can create a durable subscription for this topic. In this case, only acknowledged messages are marked as deleted. For more information, see message retention and expiry.\n\nAfter a consumer is created, the default subscription mode of the consumer is Durable. You can change the subscription mode to NonDurable by making changes to the consumer's configuration.\n\nFor how to create, check, or delete a durable subscription, see manage subscriptions.\n\nWhen a consumer subscribes to a Pulsar topic, by default it subscribes to one specific topic, such as persistent://public/default/my-topic. As of Pulsar version 1.23.0-incubating, however, Pulsar consumers can simultaneously subscribe to multiple topics. You can define a list of topics in two ways:\n\nOn the basis of a regular expression (regex), for example, persistent://public/default/finance-.*\n\nBy explicitly defining a list of topics\n\nWhen subscribing to multiple topics, the Pulsar client automatically makes a call to the Pulsar API to discover the topics that match the regex pattern/list, and then subscribe to all of them. If any of the topics do not exist, the consumer auto-subscribes to them once the topics are created.\n\nThe following are multi-topic subscription examples for Java.\n\nFor code examples, see Java.\n\nNormal topics are served only by a single broker, which limits the maximum throughput of the topic. Partitioned topic is a special type of topic handled by multiple brokers, thus allowing for higher throughput.\n\nA partitioned topic is implemented as N internal topics, where N is the number of partitions. When publishing messages to a partitioned topic, each message is routed to one of several brokers. The distribution of partitions across brokers is handled automatically by Pulsar.\n\nThe diagram below illustrates this:\n\nThe Topic1 topic has five partitions (P0 through P4) split across three brokers. Because there are more partitions than brokers, two brokers handle two partitions a piece, while the third handles only one (again, Pulsar handles this distribution of partitions automatically).\n\nMessages for this topic are broadcast to two consumers. The routing mode determines each message should be published to which partition, while the subscription type determines which messages go to which consumers.\n\nDecisions about routing and subscription modes can be made separately in most cases. In general, throughput concerns should guide partitioning/routing decisions while subscription decisions should be guided by application semantics.\n\nThere is no difference between partitioned topics and normal topics in terms of how subscription types work, as partitioning only determines what happens between when a message is published by a producer and processed and acknowledged by a consumer.\n\nPartitioned topics need to be explicitly created via the admin API. The number of partitions can be specified when creating the topic.\n\nWhen publishing to partitioned topics, you must specify a routing mode. The routing mode determines each message should be published to which partition or which internal topic.\n\nThere are three MessageRoutingMode available:\n\nModeDescriptionRoundRobinPartitionIf no key is provided, the producer will publish messages across all partitions in round-robin fashion to achieve maximum throughput. Please note that round-robin is not done per individual message but rather it's set to the same boundary of batching delay, to ensure batching is effective. While if a key is specified on the message, the partitioned producer will hash the key and assign message to a particular partition. This is the default mode.SinglePartitionIf no key is provided, the producer will randomly pick one single partition and publish all the messages into that partition. While if a key is specified on the message, the partitioned producer will hash the key and assign message to a particular partition.CustomPartitionUse custom message router implementation that will be called to determine the partition for a particular message. User can create a custom routing mode by using the Java client and implementing the MessageRouter interface.\n\nThe ordering of messages is related to MessageRoutingMode and Message Key. Usually, user would want an ordering of Per-key-partition guarantee.\n\nIf there is a key attached to message, the messages will be routed to corresponding partitions based on the hashing scheme specified by HashingScheme in ProducerBuilder, when using either SinglePartition or RoundRobinPartition mode.\n\nOrdering guaranteeDescriptionRouting Mode and KeyPer-key-partitionAll the messages with the same key will be in order and be placed in same partition.Use either SinglePartition or RoundRobinPartition mode, and Key is provided by each message.Per-producerAll the messages from the same producer will be in order.Use SinglePartition mode, and no Key is provided for each message.\n\nHashing Scheme is an enum that represents sets of standard hashing functions available when choosing the partition to use for a particular message.\n\nThere are 2 types of standard hashing functions available:\n\nJavaStringHash\n\nMurmur3_32Hash\n\nThe default hashing function for producers is JavaStringHash. Please pay attention that JavaStringHash is not useful when producers can be from different multiple language clients, under this use case, it is recommended to use Murmur3_32Hash.\n\nBy default, Pulsar persistently stores all unacknowledged messages on multiple BookKeeper bookies (storage nodes). Data for messages on persistent topics can thus survive broker restarts and subscriber failover.\n\nPulsar also, however, supports non-persistent topics. Non-persistent topics are Pulsar topics in which message data is never persistently stored to disk and kept only in memory. When using non-persistent delivery, killing a Pulsar broker or disconnecting a subscriber to a topic means that all in-transit messages are lost on that (non-persistent) topic, meaning that clients may see message loss.\n\nNon-persistent topics have names of this form (note the non-persistent in the name):\n\nFor more info on using non-persistent topics, see the Non-persistent messaging cookbook.\n\nIn non-persistent topics, brokers immediately deliver messages to all connected subscribers without persisting them in BookKeeper. If a subscriber is disconnected, the broker will not be able to deliver those in-transit messages, and subscribers will never be able to receive those messages again. Eliminating the persistent storage step makes messaging on non-persistent topics slightly faster than on persistent topics in some cases, but with the caveat that some core benefits of Pulsar are lost.\n\nWith non-persistent topics, message data lives only in memory, without a specific buffer - which means data is not buffered in memory. The received messages are immediately transmitted to all connected consumers. If a message broker fails or message data can otherwise not be retrieved from memory, your message data may be lost. Use non-persistent topics only if you're certain that your use case requires it and can sustain it.\n\nBy default, non-persistent topics are enabled on Pulsar brokers. You can disable them in the broker's configuration. You can manage non-persistent topics using the pulsar-admin topics command. For more information, see pulsar-admin.\n\nCurrently, non-persistent topics which are not partitioned are not persisted to ZooKeeper, which means if the broker owning them crashes, they do not get re-assigned to another broker because they only exist in the owner broker memory. The current workaround is to set the value of allowAutoTopicCreation to true and allowAutoTopicCreationType to non-partitioned (they are default values) in broker configuration.\n\nWith persistent topics, all messages are durably persisted on disks, whereas with non-persistent topics, brokers don't persist messages and immediately send acks back to the producer as soon as that message is delivered to connected brokers, so non-persistent messaging is usually faster than persistent messaging. Producers thus see comparatively low publish latency with non-persistent topics.\n\nProducers and consumers can connect to non-persistent topics in the same way as persistent topics, with the crucial difference that the topic name must start with non-persistent. All the subscription types---exclusive, shared, key_shared and failover---are supported for non-persistent topics.\n\nHere's an example Java consumer for a non-persistent topic:\n\nHere's an example Java producer for the same non-persistent topic:\n\nSystem topic is a predefined topic for internal use within Pulsar. It can be either a persistent or non-persistent topic.\n\nSystem topics serve to implement certain features and eliminate dependencies on third-party components, such as transactions, heartbeat detections, topic-level policies, and resource group services. System topics empower the implementation of these features to be simplified, dependent, and flexible. Take heartbeat detections for example, you can leverage the system topic for health check to internally enable producer/reader to produce/consume messages under the heartbeat namespace, which can detect whether the current service is still alive.\n\nThe following table outlines the available system topics for each specific namespace.\n\nNamespaceTopicNameDomainCountUsagepulsar/systemtransaction_coordinator_assign_${id}PersistentDefault 16Transaction coordinatorpulsar/system__transaction_log_${tc_id}PersistentDefault 16Transaction logpulsar/systemresource-usageNon-persistentDefault 4Resource group servicehost/portheartbeatPersistent1Heartbeat detectionUser-defined-ns__change_eventsPersistentDefault 4Topic eventsUser-defined-ns__transaction_buffer_snapshotPersistentOne per namespaceTransaction buffer snapshotsUser-defined-ns${topicName}__transaction_pending_ackPersistentOne per every topic subscription acknowledged with transactionsAcknowledgments with transactions\n\nApache Pulsar supports graceful failure handling and ensures critical data is not lost. Software will always have unexpected conditions and at times messages may not be delivered successfully. Therefore, it is important to have a built-in mechanism that handles failure, particularly in asynchronous messaging as highlighted in the following examples.\n\nConsumers get disconnected from the database or the HTTP server. When this happens, the database is temporarily offline while the consumer is writing the data to it and the external HTTP server that the consumer calls are momentarily unavailable.\n\nConsumers get disconnected from a broker due to consumer crashes, broken connections, etc. As a consequence, unacknowledged messages are delivered to other available consumers.\n\nMessage redelivery in Apache Pulsar avoids failure in asynchronous messaging and other message delivery failures using at-least-once delivery semantics that ensure Pulsar processes a message more than once.\n\nTo utilize message redelivery, you need to enable this mechanism before the broker can resend the unacknowledged messages in Apache Pulsar client. You can activate the message redelivery mechanism in Apache Pulsar using three methods.\n\nNegative Acknowledgment\n\nAcknowledgment Timeout\n\nRetry letter topic\n\nBy default, Pulsar message brokers:\n\nimmediately delete all messages that have been acknowledged by a consumer, and\n\npersistently store all unacknowledged messages in a message backlog.\n\nPulsar has two features, however, that enable you to override this default behavior:\n\nMessage retention enables you to store messages that have been acknowledged by a consumer\n\nMessage expiry enables you to set a time to live (TTL) for messages that have not yet been acknowledged\n\nWith message retention, shown at the top, a retention policy applied to all topics in a namespace dictates that some messages are durably stored in Pulsar even though they've already been acknowledged. Acknowledged messages that are not covered by the retention policy are deleted. Without a retention policy, all of the acknowledged messages would be deleted.\n\nWith message expiry, shown at the bottom, some messages are deleted, even though they haven't been acknowledged, because they've expired according to the TTL applied to the namespace (for example because a TTL of 5 minutes has been applied and the messages haven't been acknowledged but are 10 minutes old).\n\nMessage duplication occurs when a message is persisted by Pulsar more than once. Message deduplication ensures that each message produced on Pulsar topics is persisted to disk only once, even if the message is produced more than once. Message deduplication is handled automatically on the server side.\n\nThe following diagram illustrates what happens when message deduplication is disabled vs. enabled:\n\nMessage deduplication is disabled in the scenario shown at the top. Here, a producer publishes message 1 on a topic; the message reaches a Pulsar broker and is persisted to BookKeeper. The producer then sends message 1 again (in this case due to some retry logic), and the message is received by the broker and stored in BookKeeper again, which means that duplication has occurred.\n\nIn the second scenario at the bottom, the producer publishes message 1, which is received by the broker and persisted, as in the first scenario. When the producer attempts to publish the message again, however, the broker knows that it has already seen message 1 and thus does not persist the message.\n\nThe other available approach to message deduplication is producer idempotency, which means each message is only produced once without data loss and duplication. The drawback of this approach is that it defers the work of message deduplication to the application. In Pulsar, this is handled at the broker level, so you do not need to modify your Pulsar client code. Instead, you only need to make administrative changes. For details, see Managing message deduplication.\n\nMessage deduplication makes Pulsar an ideal messaging system to be used in conjunction with stream processing engines (SPEs) and other systems seeking to provide effectively-once processing semantics. Messaging systems that do not offer automatic message deduplication require the SPE or other system to guarantee deduplication, which means that strict message ordering comes at the cost of burdening the application with the responsibility of deduplication. With Pulsar, strict ordering guarantees come at no application-level cost.\n\nDelayed message delivery enables you to consume a message later. In this mechanism, a message is stored in BookKeeper. The DelayedDeliveryTracker maintains the time index (time -> messageId) in memory after the message is published to a broker. This message will be delivered to a consumer once the specified delay is over.\n\nThe diagram below illustrates the concept of delayed message delivery:\n\nA broker saves a message without any check. When a consumer consumes a message, if the message is set to delay, then the message is added to DelayedDeliveryTracker. A subscription checks and gets timeout messages from DelayedDeliveryTracker.\n\nDelayed message delivery is enabled by default. You can change it in the broker configuration file as below:\n\nThe following is an example of delayed message delivery for a producer in Java:"
    }
}