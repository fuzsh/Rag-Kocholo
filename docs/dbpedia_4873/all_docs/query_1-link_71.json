{
    "id": "dbpedia_4873_1",
    "rank": 71,
    "data": {
        "url": "https://skepticalinquirer.org/2024/04/looking-for-the-bright-side-of-the-ai-apocalypse/",
        "read_more_link": "",
        "language": "en",
        "title": "Looking for the Bright Side of the AI Apocalypse",
        "top_image": "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2024/04/23170243/Harrison-feat-image-scaled.jpg",
        "meta_img": "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2024/04/23170243/Harrison-feat-image-scaled.jpg",
        "images": [
            "https://centerforinquiry.org/wp-content/uploads/2020/07/cfi-login-2.png",
            "https://centerforinquiry.org/wp-content/uploads/2020/07/cfi-login-2.png",
            "https://centerforinquiry.org/richard-dawkins/wp-content/uploads/sites/41/2019/05/RDF-logo-with-division-1.png",
            "https://centerforinquiry.org/richard-dawkins/wp-content/uploads/sites/41/2019/05/RDF-logo-with-division-1.png",
            "https://centerforinquiry.org/wp-content/uploads/2020/07/SI-login-2.png",
            "https://centerforinquiry.org/wp-content/uploads/2020/07/SI-login-2.png",
            "https://centerforinquiry.org/wp-content/uploads/2020/07/FI-login-2.png",
            "https://centerforinquiry.org/wp-content/uploads/2020/07/FI-login-2.png",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2019/03/22170100/SI-logo-tag-line-w.png",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2019/03/22170029/si-logo-stacked.png",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2019/03/22170029/si-logo-stacked.png",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2024/04/23165854/Harrison-Sheep-book-cover-186x300.jpg",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2024/04/23165854/Harrison-Sheep-book-cover-186x300.jpg",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2024/04/23165712/Harrison-donut-earth-1024x574.jpg",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2024/04/23165712/Harrison-donut-earth-1024x574.jpg",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2019/03/22170100/SI-logo-tag-line-w.png",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2019/03/22170100/SI-logo-tag-line-w.png",
            "https://cdn.centerforinquiry.org/img/social/cfi-facebook.png",
            "https://cdn.centerforinquiry.org/img/social/cfi-facebook.png",
            "https://cdn.centerforinquiry.org/img/social/cfi-twitter.png",
            "https://cdn.centerforinquiry.org/img/social/cfi-twitter.png",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2019/03/22170100/SI-logo-tag-line-w.png",
            "https://centerforinquiry.s3.amazonaws.com/wp-content/uploads/sites/29/2019/03/22170100/SI-logo-tag-line-w.png"
        ],
        "movies": [
            "data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Guy P. Harrison"
        ],
        "publish_date": "2024-04-24T00:00:00",
        "summary": "",
        "meta_description": "Rumors of impending artificial intelligence (AI) doom got you down? Take heart, there may be light at the end of this tunnel—and not all of it from the head ...",
        "meta_lang": "en",
        "meta_favicon": "https://skepticalinquirer.org/wp-content/uploads/sites/29/favicons/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://skepticalinquirer.org/2024/04/looking-for-the-bright-side-of-the-ai-apocalypse/",
        "text": "Rumors of impending artificial intelligence (AI) doom got you down? Take heart, there may be light at the end of this tunnel—and not all of it from the headlight of a self-driving locomotive. No, sorry, you can’t be sure that a precocious bundle of algorithms won’t take your job (Cao 2023; Georgieva 2024). There is no guarantee that a rogue or faulty AI system won’t trick someone into launching a nuclear missile (Johns 2023; Andersen 2023). We can’t even be sure that some enterprising task-obsessed AI won’t repurpose our atoms to maximize paperclip production (Bostrom 2014, 123–124). Scariest of all, perhaps, AI might deliver world domination into the hands of a Wall Street firm (Tegmark 2017, 3–21). Or, maybe T.S. Elliot got it right, and there will be more whimper than bang as we end up in Matrix-style pods simmering in the stale juices of desperate escape. Whatever ultimately happens, however, there is the possibility of a profoundly positive outcome emerging along the way. But first, there will be pain.\n\nA new world is dawning, and it’s going to hurt. First, we taught computers to play chess, then we taught them to lie. AIs with remarkable language-, audio-, and image-generating abilities are here and improving fast. This makes everyone vulnerable to fraud and irrational states of mind more than ever, because these powerful and fast-improving tools offer countless ways to manipulate, exploit, and do harm. Based on world history, the daily news, and the videoclip of a Joe Rogan podcast episode I just watched, it is clear to me that our present neural machinery is not up to the challenge.\n\nWe will fail to stay ahead of the coming tsunami of digital deceptions, because we are living contradictions, the intelligent/stupid/rational/emotional species. We follow. We believe before we think. We confuse knowledge for wisdom and confidence for competence. To some degree, all of us bend the knee to the misperceptions, fears, fantasies, and irrational whims of our own ghostly subconscious. Though able to reach the Moon and explore the internal worlds of atoms, we remain unprepared as thinkers with minds too often outmatched by the pace and complexities of the modern world we made.\n\nThe adult population is teeming with sleepwalkers and victims-in-waiting because humankind, generation after generation, neglects to teach its children how to think critically (Harrison 2021). Our default setting is to accept or trust nearly anything that feels good, comes wrapped in shiny packaging, or is endorsed by an authority figure. Our most absurd beliefs travel halfway around the world before critical thinking can put on its shoes. And now AI enables bad actors to sharpen, amplify, and accelerate the usual plague of cons, social discord, and madness while also introducing countless novel variations and additions.\n\nRespect the bias blind spot (Pronin et al. 2002). None of us should assume we are too smart to be conned by what is coming. The current quality of AI-generated deceptions, hoaxes, scams, and frauds is formidable, but what is looming on a very short horizon is alarming. Moreover, we must place all this in the context of a misinformation and disinformation crisis that is well underway. Infinite scrolls of half-minute videos hypnotize millions of people now. Social media newsfeeds have been fraying societies and corroding democracies for years (Harrison 2017, 73–129). Researchers have clocked fake news spreading online six times faster than real news (Vosoughi et al. 2018). Soon we may long for the bygone days of charming emails from Nigerian princes bearing gifts and quaint QAnon lunacy.\n\nWe cannot know if artificial general intelligence (AGI) will be created or evolve this century, the next, or ever (Russell 2019, 4–11). AGI, a true superintelligence, would resemble the godlike entity popularized by many science fiction writers. It would be capable of independent learning, problem solving, and creativity vaguely comparable to that of a human brain but with immensely more speed and power. Whether AGI happens or not, however, recent advances may be enough to bury us in a paradigm-flipping avalanche of deepfakes (hyper-realistic photos, voice simulations, and videos). AI tools now available, for example, are being used increasingly for sophisticated phishing scams, password hacking, voice-cloning phone scams, fake websites, CEO scams, fake pornographic videos of real people, and more (Henry 2023; Associated Press 2023; 2024).\n\nAnyone doubting our vulnerability need only consider the ominous preview provided by social media. Over the past two decades, various social media companies have had remarkable success identifying, cultivating, and monetizing their users’ fear, prejudice, lust, love, anger, and hate. And they accomplished it with relatively dumb algorithms and limited AI systems (Harrison 2017). Unfortunately, there are strong indications that these companies are getting worse rather than better at reining in the misinformation and disinformation that thrive on their platforms (Nix and Ellison 2023). Add to this the upward trend of governments and politicians using AI to manipulate public opinion and censor online information (Funk et al. 2023). Finally, a survey of nearly 1,500 global experts cited AI-generated misinformation and disinformation as “the most severe global risk anticipated over the next two years” (World Economic Forum 2024, 8).\n\nOur reality is about to become as slippery and surreal as a Philip K. Dick novel.\n\nMuch of the coming AI impact will be helpful and entertaining, no doubt, but will there be running and screaming later? When greater AI powers are in the hands of irresponsible, incompetent, unethical, and criminal users the following scenarios are likely:\n\nMore people believe more absurdities with more confidence than ever before.\n\nIncreasing numbers of corrupt and/or incompetent politicians are elected to high office in democracies.\n\nTrust in science and expertise in general plummet. Demagogues and charlatans fill the void.\n\nDictators and totalitarian governments enjoy unprecedented surveillance and control over their populations.\n\nMedical quackery flourishes causing global suffering to rise and life expectancy to decline.\n\nTheocratic leaders in religious fundamentalist societies use AI to identify LGBTQ people, blasphemers, and heretics in hiding for persecution and worse.\n\nPeople will suffer. People will die. Nevertheless, let’s try to find something positive in all this. An unprecedented global catastrophe of fraud and delusion could possibly provide the catalyst that helps us lift ourselves to a better place.\n\nAI trickery and turmoil could force our species into a long-overdue cognitive upgrade. We typically imagine future scenarios in which hard tech enhances human brains, a top-down process involving physical implants and interfaces. But it could be a bottom-up organic phenomenon, a grassroots transformation in the form of collective rejection of blind trust and baseless belief. An optimistic vision of the future for sure but not impossible. Keep in mind that the tools of critical thinking are always there, available for anyone to pick up and use. They don’t require extraordinary intelligence, extensive formal education, or great private or public financial investment. More than anything, thinking well is a matter of awareness and motivation (Harrison 2015, 15–34). Critical thinking could become a new cultural universal for humanity, a core code taught to every child and expected of every adult. Perhaps all we need is a dramatic shove in the right direction to achieve critical mass and come to a point where enough people realize that it is stupid to be stupid. Should an AI-fueled wildfire of psychological chaos lead us to intellectually bottom-out as a species, we would have nowhere to go but up. Positive adaptation might be seen as a no-brainer, even by the brainless. Second guessing could become second nature. Everyone would question everything, and the proud, aggressive, stubborn silliness so common and disheartening today might lose all appeal overnight. For the first time in history, the practical application of skepticism, an appreciation for science, and the preference for evidence-based decision making could be in vogue with a majority.\n\nLike a painful but lifesaving medical treatment, maybe our world needs some AI disruption and destruction to spark change. Nothing else has worked, and we can’t afford to wait on evolution. With perfectly calibrated lies and irresistible hoaxes everywhere all the time, it will become more difficult than ever to “just believe.” Who can continue to toe the flat-Earth line when a million different Oscar-worthy YouTube videos—each one narrated by the enthusiastic AI-generated voice of Neil deGrasse Tyson—make the case that our planet is definitely shaped like a doughnut? What will dedicated QAnon troopers do when cognitive dissonance rips through their minds in the wake of role-reversing deepfake videos depicting a pack of cannibal babies chasing Tom Hanks and Oprah Winfrey? Even the last-standing UFO enthusiast, exhausted by an infinite stream of pitch-perfect AI-shenanigans, will break: “You know, I’m just not sure about this new flying-saucer video. Sorry, but I’m gonna need confirmation from several credible sources and a convergence of scientifically vetted evidence.”\n\nImagine flawless images of the Dealey Plaza grassy knoll hitting Facebook, Instagram, and TikTok feeds, each one revealing a platoon of time-traveling deep-state assassins taking aim at JFK. What fun is a conspiracy theory without any mystery? When Bigfoot photos are in sharp focus and full color, the big guy won’t be so compelling. Alex Jones, Russell Brand, Graham Hancock, Jeremy Corbell, Tucker Carlson, and all other professional credulity vortexes will be rendered redundant. Who needs their schtick when a billion amateurs can enlist AI to create alternate realities as good or better than anything they can come up with?\n\nThere is no way to know if we will get the heaven or hell scenario from AI. Maybe it really will cure cancer, solve poverty, and invent a longer-lasting lightbulb. Or it might determine that Homo sapiens is pointless bio-fodder and show us the exit. Perhaps the most likely outcome, however, will be a murky mix of good and bad. That seems to be our fate with most things. Assuming the landing is soft enough to be survivable, let’s hope our problems with AI at least provide the motivation we need to finally wake up, grow up, and become a more rational species.\n\nReferences\n\nAndersen, Ross. 2023. Never give artificial intelligence the nuclear codes. The Atlantic (May 2). Online at https://www.theatlantic.com/magazine/archive/2023/06/ai-warfare-nuclear-weapons-strike/673780/.\n\nAssociated Press. 2023. AI-generated child sexual abuse images could flood the internet (October 25). Online at https://apnews.com/article/ai-artificial-intelligence-child-sexual-abuse-c8f17de56d41f05f55286eb6177138d2.\n\n———. 2024. Deepfake explicit images of Taylor Swift spread on social media (January 26). Online at https://apnews.com/article/taylor-swift-ai-images-protecttaylorswift-nonconsensual-d5eb3f98084bcbb670a185f7aeec78b1.\n\nBostrom, Nick. 2014. Superintelligence: Paths, Dangers, Strategies. Oxford, UK: Oxford University Press.\n\nCao, Sissi. 2023. Two-thirds of jobs are at risk. Observer (March 30). Online at https://observer.com/2023/03/generative-a-i-may-replace-300-million-jobs-goldman-sachs-study/.\n\nFunk, Allie, Adrian Shahbaz, and Kian Vesteinsson. 2023. Freedom on the Net 2023: The Repressive Power of Artificial Intelligence. Washington, DC: Freedom House. Online at https://freedomhouse.org/sites/default/files/2023-11/FOTN2023Final.pdf.\n\nGeorgieva, Kristalina. 2024. AI will transform the global economy. Let’s make sure it benefits humanity. International Monetary Fund (January 14). Online at https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity.\n\nHarrison, Guy P. 2015. Good Thinking: What You Need to Know to Be Smarter, Safer, Wealthier, and Wiser. Amherst, NY: Prometheus Books.\n\n———. 2017. Think Before You Like: Social Media’s Effect on the Brain and the Tools You Need to Navigate Your Newsfeed. Amherst, NY: Prometheus Books.\n\n———. 2021. How to repair the American mind. Skeptical Inquirer 45(3) (May/June). Online at https://skepticalinquirer.org/2021/04/how-to-repair-the-american-mind-solving-americas-cognitive-crisis/.\n\nHenry, William. 2023. AI and the rise of synthetic scams. Journal of Trading Standards (July). Online at https://www.journaloftradingstandards.co.uk/crime/ai-and-the-rise-of-synthetic-scams/.\n\nJohns, Eliana. 2023. AI may not launch a nuke, but it may convince you to. Outrider (December 4). Online at https://outrider.org/nuclear-weapons/articles/ai-may-not-launch-nuke-it-may-convince-you.\n\nNix, Naomi, and Sarah Ellison. 2023. Following Elon Musk’s lead, Big Tech is surrendering to disinformation. Washington Post (August 25). Online at https://www.washingtonpost.com/technology/2023/08/25/political-conspiracies-facebook-youtube-elon-musk/.\n\nPronin, E., D.Y. Lin, and L. Ross. 2002. The bias blind spot: Perceptions of bias in self versus others. Personality and Social Psychology Bulletin 28(3): 369–381. Online at https://doi.org/10.1177/0146167202286008.\n\nRussell, Stuart. 2019. Human Compatible: Artificial Intelligence and the Problem of Control. New York, NY: Viking.\n\nTegmark, Max. 2017. Life 3.0: Being Human in the Age of Artificial Intelligence. New York, NY: Alfred A. Knopf.\n\nVosoughi, Soroush, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science 359(6380): 1146–1151. Online at https://www.science.org/doi/10.1126/science.aap9559.\n\nWorld Economic Forum. 2024. The Global Risks Report 2024 (January). Online at https://www3.weforum.org/docs/WEF_The_Global_Risks_Report_2024.pdf."
    }
}