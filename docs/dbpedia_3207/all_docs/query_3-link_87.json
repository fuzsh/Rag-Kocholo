{
    "id": "dbpedia_3207_3",
    "rank": 87,
    "data": {
        "url": "https://github.com/chroma-core/chroma",
        "read_more_link": "",
        "language": "en",
        "title": "source embedding database",
        "top_image": "https://opengraph.githubassets.com/faf5aa880382532e79e735e221f614f2b3f46505f7b78d999867dc220a87ff7b/chroma-core/chroma",
        "meta_img": "https://opengraph.githubassets.com/faf5aa880382532e79e735e221f614f2b3f46505f7b78d999867dc220a87ff7b/chroma-core/chroma",
        "images": [
            "https://user-images.githubusercontent.com/891664/227103090-6624bf7d-9524-4e05-9d2c-c28d5d451481.png",
            "https://camo.githubusercontent.com/09967cf1f6582bd2755d4b00a2beeb51d8b5b09a53a75cfb82b9ba87540364a5/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313037333239333634353330333739353734323f63616368655365636f6e64733d33363030",
            "https://camo.githubusercontent.com/7509eb9ecbcff610a1adfd2e6de2816caa1a1dad25ab6df90017683378fe9150/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d6c6963656e7365266d6573736167653d41706163686520322e3026636f6c6f723d7768697465",
            "https://avatars.githubusercontent.com/u/35911053?s=64&v=4",
            "https://avatars.githubusercontent.com/u/81333644?s=64&v=4",
            "https://avatars.githubusercontent.com/u/16241978?s=64&v=4",
            "https://avatars.githubusercontent.com/u/115153839?s=64&v=4",
            "https://avatars.githubusercontent.com/u/135222639?s=64&v=4",
            "https://avatars.githubusercontent.com/u/59957741?s=64&v=4",
            "https://avatars.githubusercontent.com/u/175369269?s=64&v=4",
            "https://avatars.githubusercontent.com/u/175843847?s=64&v=4",
            "https://avatars.githubusercontent.com/u/891664?s=64&v=4",
            "https://avatars.githubusercontent.com/u/5598697?s=64&v=4",
            "https://avatars.githubusercontent.com/u/70788?s=64&v=4",
            "https://avatars.githubusercontent.com/u/64657842?s=64&v=4",
            "https://avatars.githubusercontent.com/u/1157440?s=64&v=4",
            "https://avatars.githubusercontent.com/u/7410405?s=64&v=4",
            "https://avatars.githubusercontent.com/u/1189848?s=64&v=4",
            "https://avatars.githubusercontent.com/u/1302641?s=64&v=4",
            "https://avatars.githubusercontent.com/u/14816236?s=64&v=4",
            "https://avatars.githubusercontent.com/u/2502591?s=64&v=4",
            "https://avatars.githubusercontent.com/u/3451471?s=64&v=4",
            "https://avatars.githubusercontent.com/u/6764957?s=64&v=4",
            "https://avatars.githubusercontent.com/u/1403638?s=64&v=4",
            "https://avatars.githubusercontent.com/u/127474210?s=64&v=4"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "chroma-core"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "the AI-native open-source embedding database. Contribute to chroma-core/chroma development by creating an account on GitHub.",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/chroma-core/chroma",
        "text": "Chroma - the open-source embedding database.\n\nThe fastest way to build Python or JavaScript LLM apps with memory!\n\n| | Docs | Homepage\n\npip install chromadb # python client # for javascript, npm install chromadb! # for client-server mode, chroma run --path /chroma_db_path\n\nThe core API is only 4 functions (run our üí° Google Colab or Replit template):\n\nimport chromadb # setup Chroma in-memory, for easy prototyping. Can add persistence easily! client = chromadb.Client() # Create collection. get_collection, get_or_create_collection, delete_collection also available! collection = client.create_collection(\"all-my-documents\") # Add docs to the collection. Can also update and delete. Row-based API coming soon! collection.add( documents=[\"This is document1\", \"This is document2\"], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # filter on these! ids=[\"doc1\", \"doc2\"], # unique for each doc ) # Query/search 2 most similar results. You can also .get by id results = collection.query( query_texts=[\"This is a query document\"], n_results=2, # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter # where_document={\"$contains\":\"search_string\"} # optional filter )\n\nSimple: Fully-typed, fully-tested, fully-documented == happiness\n\nIntegrations: ü¶úÔ∏èüîó LangChain (python and js), ü¶ô LlamaIndex and more soon\n\nDev, Test, Prod: the same API that runs in your python notebook, scales to your cluster\n\nFeature-rich: Queries, filtering, density estimation and more\n\nFree & Open Source: Apache 2.0 Licensed\n\nUse case: ChatGPT for ______\n\nFor example, the \"Chat your data\" use case:\n\nAdd documents to your database. You can pass in your own embeddings, embedding function, or let Chroma embed them for you.\n\nQuery relevant documents with natural language.\n\nCompose documents into the context window of an LLM like GPT3 for additional summarization or analysis.\n\nWhat are embeddings?\n\nRead the guide from OpenAI\n\nLiteral: Embedding something turns it from image/text/audio into a list of numbers. üñºÔ∏è or üìÑ => [1.2, 2.1, ....]. This process makes documents \"understandable\" to a machine learning model.\n\nBy analogy: An embedding represents the essence of a document. This enables documents and queries with the same essence to be \"near\" each other and therefore easy to find.\n\nTechnical: An embedding is the latent-space position of a document at a layer of a deep neural network. For models trained specifically to embed data, this is the last layer.\n\nA small example: If you search your photos for \"famous bridge in San Francisco\". By embedding this query and comparing it to the embeddings of your photos and their metadata - it should return photos of the Golden Gate Bridge.\n\nEmbeddings databases (also known as vector databases) store embeddings and allow you to search by nearest neighbors rather than by substrings like a traditional database. By default, Chroma uses Sentence Transformers to embed for you but you can also use OpenAI embeddings, Cohere (multilingual) embeddings, or your own.\n\nGet involved\n\nChroma is a rapidly developing project. We welcome PR contributors and ideas for how to improve the project.\n\nJoin the conversation on Discord - #contributing channel\n\nReview the üõ£Ô∏è Roadmap and contribute your ideas\n\nGrab an issue and open a PR - Good first issue tag\n\nRead our contributing guide\n\nRelease Cadence We currently release new tagged versions of the pypi and npm packages on Mondays. Hotfixes go out at any time during the week.\n\nApache 2.0"
    }
}