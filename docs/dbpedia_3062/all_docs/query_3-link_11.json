{
    "id": "dbpedia_3062_3",
    "rank": 11,
    "data": {
        "url": "https://canonicalized.com/tableau-dashboard-performance-optimization-case-study/",
        "read_more_link": "",
        "language": "en",
        "title": "Tableau Dashboard Performance Optimization [Case Study • 99% Boost]",
        "top_image": "https://canonicalized.com/wp-content/uploads/2018/08/tableau-performance-1.png",
        "meta_img": "https://canonicalized.com/wp-content/uploads/2018/08/tableau-performance-1.png",
        "images": [
            "https://www.facebook.com/tr?id=1751764948425017&ev=PageView&noscript=1",
            "https://secure.gravatar.com/avatar/9971fceb1a5fd68ef3d69be2ae329dd7?s=128&d=mm&r=g 2x",
            "https://secure.gravatar.com/avatar/9971fceb1a5fd68ef3d69be2ae329dd7?s=64&d=mm&r=g",
            "https://canonicalized.com/wp-content/uploads/2018/08/tableau-performance.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/tableau-performance.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/DashboardTransactions.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/DashboardTransactions.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/initial-perf-recording.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/initial-perf-recording.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/with-without-parallel-queries.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/with-without-parallel-queries.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/indexes.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/indexes.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/without-indexes.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/without-indexes.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/with-indexes.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/with-indexes.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/wildcard-union.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/wildcard-union.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/extract-partitioned-vs-full.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/extract-partitioned-vs-full.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/db-optimization-summary.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/db-optimization-summary.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/query-batching.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/query-batching.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/batching-lod.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/batching-lod.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/query-performance-recorder.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/query-performance-recorder.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/slow-computing-layout.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/slow-computing-layout.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/slow-layout-sheet.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/slow-layout-sheet.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/color-calculation.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/color-calculation.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/optimize-bad-calculation.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/optimize-bad-calculation.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/after-optimizing-calculation.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/after-optimizing-calculation.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/broken-query-batching.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/broken-query-batching.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/date-filter-context.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/date-filter-context.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/context-filter-query.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/context-filter-query.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/4months-context.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/4months-context.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/lod-filter-formula.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/lod-filter-formula.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/table-calculation-filter-full-month.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/table-calculation-filter-full-month.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/table-calc-filter.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/table-calc-filter.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/better-query-table-calc-filter.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/better-query-table-calc-filter.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/before-after-lod-tc.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/before-after-lod-tc.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/lod-filter-tc-filter-yoy.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/lod-filter-tc-filter-yoy.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/data-source-filter-join.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/data-source-filter-join.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/tableau-logic-optimization-summary.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/tableau-logic-optimization-summary.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/perf-recording-extract.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/perf-recording-extract.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/extract-refresh-schedule.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/extract-refresh-schedule.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/extract-filter.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/extract-filter.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/date-filter-extract.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/date-filter-extract.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/hide-unused-fields.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/hide-unused-fields.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/aggregate-to-visible-dimensions.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/aggregate-to-visible-dimensions.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/summary-extract.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/summary-extract.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/empty-performance-recorder.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/empty-performance-recorder.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/DashboardNew.png",
            "https://canonicalized.com/wp-content/uploads/2018/08/DashboardNew.png",
            "https://secure.gravatar.com/avatar/9971fceb1a5fd68ef3d69be2ae329dd7?s=200&d=mm&r=g 2x",
            "https://secure.gravatar.com/avatar/9971fceb1a5fd68ef3d69be2ae329dd7?s=100&d=mm&r=g",
            "https://canonicalized.com/wp-content/themes/canonicalized/images/tableau-partner.png",
            "https://canonicalized.com/wp-content/themes/canonicalized/images/tableau-partner.png",
            "https://canonicalized.com/wp-content/uploads/2016/01/canonicalized.png",
            "https://canonicalized.com/wp-content/uploads/2016/01/canonicalized.png",
            "https://px.ads.linkedin.com/collect/?pid=1585770&fmt=gif"
        ],
        "movies": [
            "about:blank",
            "https://www.youtube-nocookie.com/embed/mJbAsxVK004?rel=0"
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Dorian Banutoiu",
            "www.facebook.com"
        ],
        "publish_date": "2018-08-04T01:02:37+00:00",
        "summary": "",
        "meta_description": "We're sharing a marvelous case study on how we take a crappy Tableau Dashboard, and we turn it around! • Speed performance • Improved design • Better story",
        "meta_lang": "en",
        "meta_favicon": "https://canonicalized.com/wp-content/uploads/2015/12/canonicalized.png",
        "meta_site_name": "Canonicalized",
        "canonical_link": "https://canonicalized.com/tableau-dashboard-performance-optimization-case-study/",
        "text": "We want to share with you a sleek case study where we take a crappy Tableau dashboard, and we turn it around for the better.\n\nIn the first part of the article, we are going to focus on the technical details of improving the loading and interacting speed.\n\nTowards the end, we will include a sneak peek of the new improved version we’re working on.\n\nBefore anything else, how do we define performance? For us, it’s how fast we can get from question to answer.\n\nThere are two sides to this story: the actual speed of the dashboard and the time it takes for the user to understand it.\n\nThe quality of the question has a direct influence on the quality of the answer. We see it as a part of the performance optimization process.\n\nLet’s have a look of what we had to deal with!\n\nStarting point\n\nMarketing company with multiple clients sending out a monthly update.\n\nThe dashboard tries to answer the question of how well the client performed in the previous month from an SEO standpoint.\n\nAll the data is kept in a PostgreSQL database. Tableau is plugged-in using a live connection.\n\nThe viz in question:\n\nWe are going to base our analysis on the “Project” filter. Mainly because we want to be able to switch between different clients as fast as possible.\n\nThe initial loading time when switching to a new project is about 3 minutes (185 seconds).\n\nSubjective thought: if you have to wait 3 mins for a dashboard to load, it better be worth it!\n\nWell, it’s not. The dash is not the worst of all, but it’s not great either.\n\nNo worries, we can only go but up from here. Where others might see an unusable dashboard, we see the potential.\n\nAfter all, we can only go up from here. Think of all that opportunity!\n\nWe’re following the “Do your thing first, optimize after” credo. There’s no problem with a poor performing dashboard as long as we plan to iterate on it.\n\nDefining KPIs based on speed goals\n\nFirst, we need to clearly define who is viewing the dashboard.\n\nThere is the analyst who interacts with the dashboard on the Tableau Desktop and Online environments and the client who is receiving the report by email.\n\nFor the analyst, it’s essential that the dashboard loads fast and it’s easy to interact with.\n\nFor the clients on the other side, these factors are irrelevant. They receive a static report by email.\n\nGet them their answer as soon as possible!\n\nBut for now, let’s see how we can optimize our dashboard’s speed.\n\nWe are going to use the Tableau Desktop built-in performance recorder as our primary tool for analysis.\n\nWhat I love most about it is that you get the speed data in a new Tableau Workbook. We can play around with the reports to find whatever is causing loading issues.\n\nHere is our initial report:\n\nThe green bars are slow queries, and the blue ones are computing layout processes.\n\nWe have a timeline that shows the events by starting time and below they are sorted by duration.\n\nNotice the filter at the top that reduces the view to events that last over 0.1 seconds.\n\nWe will keep this filter throughout our analysis so we can focus on the central part of the problem.\n\nNow for the KPIs:\n\ninteracting with the dashboard (looking at events longer than 0.1s)\n\nstart to finish time\n\nnumber of queries\n\nlayout indicators\n\nnumber of slow computing layout events\n\nnumber of sheets in the dashboard\n\ndata volume\n\nextract duration\n\nnumber of records\n\ndatasource size (Mb)\n\nBased on these, we are going to start the step-by-step speed optimization process. We will measure the progress at the end of each section with a visualization built in nothing else but Tableau.\n\nOptimizing at the database level\n\nIt’s not recommended to work with a live DB connection.\n\nSo obviously we had to do it!\n\nWe will eventually move on to an extract, but we feel there is value in optimizing at the database level:\n\nthere are cases where people are compelled to use live connections\n\nfinding ways to speed up the extract durations\n\nTableau translates our actions into SQL queries that we get to see inside the performance reports (for a lot of us an SQL query is a lot easier to understand as opposed to XML ones used on Tableau extracts)\n\nBefore doing anything, make sure queries are running in parallel.\n\nThis feature should be enabled by default since Tableau 9.0. If you haven’t manually altered the connection-configs.xml file on your machine, you should be good to go.\n\nVisual difference:\n\nIn our case, the version with the paralleled queries was about 20% faster.\n\nFirst step: adding indexes\n\nThis is one of the easiest and effective adjustments you can make at the database level.\n\nOn our setup, we added indexes for the “date” and “project” fields (the ones that are often used for filtering).\n\nWhen comparing the difference visually, we get this:\n\nA 46% gain just by indexing two columns. Nice!\n\nThe indexes don’t seem to have an impact on the extract duration so we can use them without dwelling too much.\n\nStep 2: move the database to an optimized server\n\nBoth 185 seconds and 100 seconds translate to the same thing in our case: slow.\n\nBy moving the database from our crappy single-CPU/1GB RAM server to a 4-core/8GB RAM, we get a nice improvement.\n\nDown to a 15 seconds loading time to be more specific. There’s still a long way down, but we’re getting closer.\n\nTo partition or not to partition\n\nIf you are going to keep the live connection, we recommend splitting the database into multiple parts.\n\nIn our case, we tried to move every project’s data into its own table. We then brought the data back into Tableau using a wildcard union.\n\nBy using the partitioned database, we got the loading time down to 13 seconds.\n\nSince the performance recorder can show how much time it takes to generate the extract, we took the time to compare the two as well.\n\nExtracting from multiple tables seems to take 20 seconds longer.\n\nWe already mentioned that we will eventually use an extract, so we’ll keep all the data in one table.\n\nThere are more details about extracts in the data volume section below.\n\ntl;dr\n\nLet’s move on to the actual optimization!\n\nThe Tableau logic of things\n\nTo sum up our dashboard, we have 20 sheets to work with:\n\na 3-month traffic trend\n\na Year-over-Year comparison for the last 12 months\n\nindicators for the previous month: session duration, bounce rate, pageviews/session, transactions, conversion rate and revenue; for each of these we have 3 sheets:\n\none for the last month’s total\n\none for the difference vs. the previous year\n\none for the box-plot comparison vs. the previous year\n\nStep 1: Query batching\n\nIn the initial performance recording, I noticed something a tad peculiar. Even though we have 20 sheets, there are only 7 slow queries.\n\nThis happens because Tableau recognizes worksheets that are on the same level of detail and groups their queries into a single one.\n\nSmart huh? We just have to be careful enough not to break it!\n\nLooks like the “Transactions” box-plot is not being batched. Let’s investigate why!\n\nJust by looking at a sheet for which the query batching is working and comparing it to our troubled one we can see a subtle difference.\n\nThe “Transactions” sheet has a continuous date field on the detail marks card while all the other ones are using discrete fields:\n\nChange it to discrete, bada bing bada bum, we’re down to 6 queries!\n\nIf you were to have compulsive tendencies like I seem to have, you could start thinking about what you should use between discrete and continuous.\n\nLuckily the Tableau performance recorder shows the actual query that is being sent to the database:\n\nSo discrete or continuous?\n\nThe exact same query is being sent to the database in both cases. Personal debate ended!\n\nStep 2: Computing layout\n\nThe second thing that pops into my view is the blue bar from the top right side:\n\nFrom looking at the worksheet, I got suspicious about the calculated field used for color.\n\nHere’s the calculation:\n\nWe need a color for the latest 12 months and a different one for all the previous ones.\n\nWe can safely remove the MAX() function applied to the date and return booleans instead of integers.\n\nOur calculated field becomes something like this:\n\nLet’s do a performance recording to see if anything happened:\n\nWould you look at that! No more slow layout computation. More than that, we’re down to 5 queries.\n\nI’m not sure if you noticed in the previous performance reports, but the lousy color calculation was forcing Tableau to send two queries for the Year-over-Year worksheet.\n\nNot anymore!\n\nStep 3: Context filters\n\nAdding a filter to context is recommended if it reduces the size of the dataset by at least 10%.\n\nHere’s how the Tableau peeps describe them:\n\nYou can think of a context filter as being an independent filter. Any other filters that you set are defined as dependent filters because they process only the data that passes through the context filter.\n\nTrial and error\n\nOur sheets have filters in place to show data for 25 months at the most.\n\nBy adding the date filter to context for a handful of sheets, we ended up with this:\n\nIt broke our query batching!\n\nThis is precisely the kind of moment that shows the value of testing stuff out.\n\nBest practice is a good starting point, but every dashboard is different, and it has special needs.\n\nSmaller steps\n\nSince the Year-over-Year comparison and the 3-month trend are not being batched, I wanted to test context filters for each of them individually.\n\nBy adding the 25-month date filter to the context for the YoY worksheet, I notice a tiny improvement.\n\nTo make sure it’s valid, I grabbed the exact queries to compare them side-by-side:\n\nBy testing the queries directly on the database, we see a 10% improvement in speed:\n\nregular filter query takes 2.9s to execute\n\ncontext filter query takes 2.6s to execute\n\nNot only that, but Tableau brings in only the data it needs for the analysis. The other filters and calculations are performed on a smaller input.\n\nSecondly, for our 3-month trend, we only need about 3-4 months of data. Adding this filter to context shows a more noticeable gain in speed. You’ll see it in the summary chart at the end of this section.\n\nStep 4: replacing slow filters with table calculations\n\nTable calculations are performed on the view without filtering the underlying data.\n\nWe definitely have to try them out in our worksheets!\n\nAside from the project and date filters, there’s one more that uses a LOD (level of detail) expression – “Last month full?”.\n\nLet’s have a look at the formula:\n\nIt tries to filter out data points for the latest month if it hasn’t ended yet. For example, we have data up to July 4th, but we only want to look at data before June 30th (the latest complete month).\n\nAnyway, what we need to keep in mind is that it’s slow.\n\nThis is what I came up with to do the same thing:\n\nAnd it seems to work like a charm:\n\nThe query duration inside Tableau went down from 4s to a whopping 2s!\n\nWow! We should do this every time we get the chance.\n\nThe new computing table calculation event showed up inside the performance recorder, but absolutely nothing to worry about speed-wise (less than 0.001s).\n\nWith this new information in mind, let’s try the technique for the other worksheets as well!\n\nHow one of the slowest queries became the fastest one\n\nWe changed the LOD filter for all of the sheets in this batch to use a table calculation.\n\nTake a glance below to see how we achieved it:\n\nTwo more failed experiments\n\nFirst attempt: trying table calculation filters for the YoY comparison\n\nIt does the job regarding the speed, but it messes up our sorting. This happens because the sort is computed before the table calculation runs.\n\nHave a look at the actual difference:\n\nWe could find another way to sort by a table calculation, but it would be hackish at best.\n\nIn this case, we decided to do a temporary tradeoff: ease of implementation instead of performance.\n\nWe’re not giving up, we’ll just keep in mind to find a workaround for this problem. anchor link\n\nSecond attempt: add the LOD filter at data source level\n\nLong story short: it’s terrible!\n\nWhen comparing the query before and after adding the data source filter we get this:\n\nIt seems like Tableau adds a JOIN statement. When testing the speed on the database, we noticed that a 115 ms query becomes a 3-second query.\n\nNot good!\n\nOur suggestion would be to create a table in the database that contains only the data needed for the analysis. This way we can get rid of all the LOD and table calc filters.\n\nBut that should happen outside of Tableau.\n\nWe are planning to use a data extract, so no worries for now. We’ll deal with this problem later on.\n\nLet’s move forward for now!\n\nStep 5: Bring the difference in the same sheet with the total\n\nIt’s always recommended to reduce the number of sheets used in a dashboard.\n\nWe found a way to keep the total and the year over year difference within the same worksheet.\n\nAnd it worked very well for us:\n\nshaved off one second of the total loading time\n\ngot rid of a query\n\nreduced the number of sheets from 20 to 14\n\nCheck out the video below to see how we did it:\n\nWhile working on the totals, we realized we’re using data for the last 25 months. When we actually need no more than 14-15 months on these sheets.\n\nUpdated the filters and got a ~5% increase in performance.\n\nEvery bit counts!\n\ntl;dr\n\nExtract your data\n\nIt’s probably the most common recommendation you’ll get from performance specialists.\n\nExtracts are definitely something you can’t live without in 90% of cases.\n\nBut doing it at the start of the optimization process could cover up some underlying issues. And these might bite you in the ass later on.\n\nSince we’ve done everything we could think of on our live connection, it’s time to chop up the data extracts.\n\nWe have their duration in the performance recording. It would be easy to compare how much time it takes to generate the extract.\n\nHere’s an example recording of the extract process:\n\nThe bad news is that the extracts take some time to complete. The good news is that you can have them update automatically in the cloud so you won’t need to do it manually.\n\nIt’s easy to make it happen by publishing the extract (right-click on the data source and hit Publish to server)\n\nAt the server level (Tableau Server/Online) you can set up a refresh schedule:\n\nTip: don’t publish packaged workbooks on the server! It’s smarter to publish an extract that multiple users can connect to rather than having each person uploading large size packaged workbooks.\n\nNow let’s see how much we can reduce the volume of data present in the extract!\n\nStep 1: filter incomplete months\n\nRemember our LOD filter headache earlier in the article? Time to say goodbye to it!\n\nI’m very excited to add filters at the extract level!\n\nBe careful to confuse them with data source filters. We’ve seen before how one of these messed up our speed.\n\nSo we just pop our LOD expression filter (the slow one) into the extract “Edit” window:\n\nThis optimization isn’t meant to significantly reduce the volume of the data, but to help us get rid of complicated filters that slow down our dashboard.\n\nIt will actually increase the extract duration to about 80s, but don’t worry because we’ll deal with this as well.\n\nStep 2: keep the latest 25 months of data\n\nThe database could contain data from dark ages, but we’re only interested in the last two years.\n\nSo let’s add another filter to make it happen! This time it’s a relative date one:\n\nWe’ve decreased the data volume a bit, but it barely makes a dent.\n\nLet’s keep working!\n\nStep 3: hide unused fields\n\nI don’t know how it is for other people, but when I’m done with a dashboard, I usually find myself with a bunch of useless fields and sheets.\n\nLuckily Tableau has a quick fix for this as well!\n\nFirst I would start by cleaning up any sheet I’m not using:\n\nright-click on every dashboard and hide their sheets\n\ndelete any sheet that remained visible\n\ndepending on your preference, you can un-hide the ones used in your dashboards\n\nSecondly, I hit the “Hide All Unused Fields” button either on the extract window or right in the data pane.\n\nThe reason I’m cleaning up the sheets first is because Tableau will only hide fields that are not present in any worksheet.\n\nThe best time to do this step would be at the end of the process when you feel you’re done working on your dashboard(s).\n\nThis step brought quite the shrinkage in terms of data source size! Down to 4.4Mb from 23Mb.\n\nFor the second breakthrough, let’s move over to the final step!\n\nStep 4: Aggregating the extract\n\nThis is even easier than the previous one.\n\nWe just have to check the “Aggregate to visible dimensions” option from the same Extract window:\n\nOur data source size is now 172kb. Now that’s performance!\n\ntl;dr\n\nThe final speed of our dashboard is now under one second for local extracts (almost invisible to the naked eye).\n\nThe performance recorder doesn’t pick up anything over 0.1s:\n\nAlso, we get a loading time and around 1.5s when connecting live to remotely hosted extracts (it varies a lot depending on the network speed, server load, and so on).\n\nImproved design\n\nIterating on the model based on customer feedback is essential. After all, they are the main character in this story.\n\nHere’s how we reworked the viz (the data shown is entirely fictitious):\n\nAs you can see, it’s a lot easier on the eyes.\n\nHere are some thoughts on it:\n\nwe moved the primary performance indicators at the top\n\nwe’re now using bullet charts and sparklines to show the Year-over-Year difference (seem a bit more adequate)\n\nwe got rid of the box-plots because most clients found them difficult to understand\n\nbounce rate, session duration, and pageviews/session play a more secondary role (we’re using dot plots for them)\n\ninstead of the Year-over-Year monthly comparison and the 3-month trend, we’re now using a single chart (inspired from the historical work of William Playfair)\n\nwe’ve colored the declines with red and the growths with blue throughout the visualization\n\nwe’ve separated more clearly the two main sections\n\nwe’ve added dynamic titles that update each month\n\nFor me personally, it seems that it’s saying a way better story with fewer words.\n\nConclusion\n\nDon’t take anything we talked about here as a rule of thumb! This is just what worked in our case.\n\nWe’ve tested everything thoroughly to see what works best for our particular dashboard.\n\nAlso, the process of making it easier to understand for a group of people is not a walk in the park. We feel that we need to continuously iterate on our visualizations to make them better.\n\nThey should require a minimum amount of brain power and effort from the end user.\n\nI hope you get some value out of our experience! If you have any feedback, don’t hesitate to share it with us!\n\nRecommendations to dive in deeper into Tableau performance"
    }
}