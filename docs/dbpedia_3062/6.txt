@@ -10,6 +10,7 @@ from fastapi.responses import StreamingResponse, JSONResponse

56

def predict(input_image, prompt, guidance_scale=8.0, strength=0.5, seed=2159232):

58

# Can be set to 1~50 steps. LCM support fast inference even <= 4 steps. Recommend: 1~8 steps.

58

def predict(input_image, prompt, guidance_scale=8.0, strength=0.5, seed=2159232):

61

# Can be set to 1~50 steps. LCM support fast inference even <= 4 steps. Recommend: 1~8 steps.

177

- target="_blank" class="text-blue-500 hover:underline">Diffusers</a> with a MJPEG

181

There are <span id="queue_size" class="font-bold">0</span> user(s) sharing the same GPU, affecting

182

real-time performance. Maximum queue size is 4. <a

184

- target="_blank" class="text-blue-500 hover:underline">Duplicate</a> and run it on your own GPU.

190

- Change the prompt to generate different images.

174

+ class="text-blue-500 underline hover:no-underline">LCM</a> Image to Image pipeline

177

+ target="_blank" class="text-blue-500 underline hover:no-underline">Diffusers</a> with a MJPEG