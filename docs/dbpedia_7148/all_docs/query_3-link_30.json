{
    "id": "dbpedia_7148_3",
    "rank": 30,
    "data": {
        "url": "https://www.science.gov/topicpages/t/trend%2Banalysis%2Bmethods.html",
        "read_more_link": "",
        "language": "en",
        "title": "trend analysis methods: Topics by Science.gov",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.science.gov/scigov/desktop/en/images/SciGov_logo.png",
            "https://www.science.gov/topicpages/t/images/arrow-up.gif",
            "https://www.science.gov/topicpages/t/images/arrow-down.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "The method of trend analysis of parameters time series of gas-turbine engine state\n\nNASA Astrophysics Data System (ADS)\n\nHvozdeva, I.; Myrhorod, V.; Derenh, Y.\n\n2017-10-01\n\nThis research substantiates an approach to interval estimation of time series trend component. The well-known methods of spectral and trend analysis are used for multidimensional data arrays. The interval estimation of trend component is proposed for the time series whose autocorrelation matrix possesses a prevailing eigenvalue. The properties of time series autocorrelation matrix are identified.\n\n[Comparison of application of Cochran-Armitage trend test and linear regression analysis for rate trend analysis in epidemiology study].\n\nPubMed\n\nWang, D Z; Wang, C; Shen, C F; Zhang, Y; Zhang, H; Song, G D; Xue, X D; Xu, Z L; Zhang, S; Jiang, G H\n\n2017-05-10\n\nWe described the time trend of acute myocardial infarction (AMI) from 1999 to 2013 in Tianjin incidence rate with Cochran-Armitage trend (CAT) test and linear regression analysis, and the results were compared. Based on actual population, CAT test had much stronger statistical power than linear regression analysis for both overall incidence trend and age specific incidence trend (Cochran-Armitage trend P valueanalysis remained the same when population size was reduced by 100 times and AMI incidence rate remained unchanged. The two statistical methods have their advantages and disadvantages. It is necessary to choose statistical method according the fitting degree of data, or comprehensively analyze the results of two methods.\n\nMethods for trend analysis: Examples with problem/failure data\n\nNASA Technical Reports Server (NTRS)\n\nChurch, Curtis K.\n\n1989-01-01\n\nStatistics are emphasized as an important role in quality control and reliability. Consequently, Trend Analysis Techniques recommended a variety of statistical methodologies that could be applied to time series data. The major goal of the working handbook, using data from the MSFC Problem Assessment System, is to illustrate some of the techniques in the NASA standard, some different techniques, and to notice patterns of data. Techniques for trend estimation used are: regression (exponential, power, reciprocal, straight line) and Kendall's rank correlation coefficient. The important details of a statistical strategy for estimating a trend component are covered in the examples. However, careful analysis and interpretation is necessary because of small samples and frequent zero problem reports in a given time period. Further investigations to deal with these issues are being conducted.\n\nNASA trend analysis procedures\n\nNASA Technical Reports Server (NTRS)\n\n1993-01-01\n\nThis publication is primarily intended for use by NASA personnel engaged in managing or implementing trend analysis programs. 'Trend analysis' refers to the observation of current activity in the context of the past in order to infer the expected level of future activity. NASA trend analysis was divided into 5 categories: problem, performance, supportability, programmatic, and reliability. Problem trend analysis uncovers multiple occurrences of historical hardware or software problems or failures in order to focus future corrective action. Performance trend analysis observes changing levels of real-time or historical flight vehicle performance parameters such as temperatures, pressures, and flow rates as compared to specification or 'safe' limits. Supportability trend analysis assesses the adequacy of the spaceflight logistics system; example indicators are repair-turn-around time and parts stockage levels. Programmatic trend analysis uses quantitative indicators to evaluate the 'health' of NASA programs of all types. Finally, reliability trend analysis attempts to evaluate the growth of system reliability based on a decreasing rate of occurrence of hardware problems over time. Procedures for conducting all five types of trend analysis are provided in this publication, prepared through the joint efforts of the NASA Trend Analysis Working Group.\n\nBreast Cancer Trend in Iran from 2000 to 2009 and Prediction till 2020 using a Trend Analysis Method.\n\nPubMed\n\nZahmatkesh, Bibihajar; Keramat, Afsaneh; Alavi, Nasrinossadat; Khosravi, Ahmad; Kousha, Ahmad; Motlagh, Ali Ghanbari; Darman, Mahboobeh; Partovipour, Elham; Chaman, Reza\n\n2016-01-01\n\nBreast cancer is the most common cancer in women worldwide with a rising incidence rate in most countries. Considering the increase in life expectancy and change in lifestyle of Iranian women, this study investigated the age-adjusted trend of breast cancer incidence during 2000-2009 and predicted its incidence to 2020. The 1997 and 2006 census results were used for the projection of female population by age through the cohort-component method over the studied years. Data from the Iranian cancer registration system were used to calculate the annual incidence rate of breast cancer. The age-adjusted incidence rate was then calculated using the WHO standard population distribution. The five-year-age-specific incidence rates were also obtained for each year and future incidence was determined using the trend analysis method. Annual percentage change (APC) was calculated through the joinpoint regression method. The bias adjusted incidence rate of breast cancer increased from 16.7 per 100,000 women in 2000 to 33.6 per 100,000 women in 2009. The incidence of breast cancer had a growing trend in almost all age groups above 30 years over the studied years. In this period, the age groups of 45-65 years had the highest incidence. Investigation into the joinpoint curve showed that the curve had a steep slope with an APC of 23.4% before the first joinpoint, but became milder after this. From 2005 to 2009, the APC was calculated as 2.7%, through which the incidence of breast cancer in 2020 was predicted as 63.0 per 100,000 women. The age-adjusted incidence rate of breast cancer continues to increas in Iranian women. It is predicted that this trend will continue until 2020. Therefore, it seems necessary to prioritize the prevention, control and care for breast cancer in Iran.\n\nGlaucoma progression detection: agreement, sensitivity, and specificity of expert visual field evaluation, event analysis, and trend analysis.\n\nPubMed\n\nAntÃ³n, Alfonso; Pazos, Marta; MartÃ­n, BelÃ©n; Navero, JosÃ© Manuel; Ayala, Miriam Eleonora; Castany, Marta; MartÃ­nez, Patricia; BardavÃ­o, Javier\n\n2013-01-01\n\nTo assess sensitivity, specificity, and agreement among automated event analysis, automated trend analysis, and expert evaluation to detect glaucoma progression. This was a prospective study that included 37 eyes with a follow-up of 36 months. All had glaucomatous disks and fields and performed reliable visual fields every 6 months. Each series of fields was assessed with 3 different methods: subjective assessment by 2 independent teams of glaucoma experts, glaucoma/guided progression analysis (GPA) event analysis, and GPA (visual field index-based) trend analysis. Kappa agreement coefficient between methods and sensitivity and specificity for each method using expert opinion as gold standard were calculated. The incidence of glaucoma progression was 16% to 18% in 3 years but only 3 cases showed progression with all 3 methods. Kappa agreement coefficient was high (k=0.82) between subjective expert assessment and GPA event analysis, and only moderate between these two and GPA trend analysis (k=0.57). Sensitivity and specificity for GPA event and GPA trend analysis were 71% and 96%, and 57% and 93%, respectively. The 3 methods detected similar numbers of progressing cases. The GPA event analysis and expert subjective assessment showed high agreement between them and moderate agreement with GPA trend analysis. In a period of 3 years, both methods of GPA analysis offered high specificity, event analysis showed 83% sensitivity, and trend analysis had a 66% sensitivity.\n\nAn analysis of secular trends in method-specific suicides in Japan, 1950-1975.\n\nPubMed\n\nYoshioka, Eiji; Saijo, Yasuaki; Kawachi, Ichiro\n\n2017-04-05\n\nIn Japan, a dramatic rise in suicide rates was observed in the 1950s, especially among the younger population, and then the rate decreased rapidly again in the 1960s. The aim of this study was to assess secular trends in method-specific suicides by gender and age in Japan between 1950 and 1975. We paid special attention to suicides by poisoning (solid and liquid substances), and their contribution to dramatic swings in the overall suicide rate in Japan during the 1950s and 1960s. Mortality and population data were obtained from the Vital Statistics of Japan and Statistics Bureau, Ministry of Internal Affairs and Communications in Japan, respectively. We calculated method-specific age-standardized suicide rates by gender and age group (15-29, 30-49, or 50+ years). The change in the suicide rate during the research period was larger in males than females in all age groups, and was more marked among people aged 15-29 years compared to those aged 30-49 years and 50Â years or over. Poisoning by solid and liquid substances overwhelmingly contributed to the dramatic change in the overall suicide rates in males and females aged 15-49 years in the 1950s and 1960s. For the peak years of the rise in poisoning suicides, bromide was the most frequently used substance. Our results for the 1950s and 1960s in Japan illustrated how assessing secular trends in method-specific suicides by gender and age could provide a deeper understanding of the dramatic swings in overall suicide rate. Although rapid increases or decreases in suicide rates have been also observed in some countries or regions recently, trends in method-specific suicides have not been analyzed because of a lack of data on method-specific suicide in many countries. Our study illustrates how the collection and analysis of method-specific data can contribute to an understanding of dramatic shifts in national suicide rates.\n\nA Simple Method to Control Positive Baseline Trend within Data Nonoverlap\n\nERIC Educational Resources Information Center\n\nParker, Richard I.; Vannest, Kimberly J.; Davis, John L.\n\n2014-01-01\n\nNonoverlap is widely used as a statistical summary of data; however, these analyses rarely correct unwanted positive baseline trend. This article presents and validates the graph rotation for overlap and trend (GROT) technique, a hand calculation method for controlling positive baseline trend within an analysis of data nonoverlap. GROT isâ¦\n\nAnalysis options for estimating status and trends in long-term monitoring\n\nUSGS Publications Warehouse\n\nBart, Jonathan; Beyer, Hawthorne L.\n\n2012-01-01\n\nThis chapter describes methods for estimating long-term trends in ecological parameters. Other chapters in this volume discuss more advanced methods for analyzing monitoring data, but these methods may be relatively inaccessible to some readers. Therefore, this chapter provides an introduction to trend analysis for managers and biologists while also discussing general issues relevant to trend assessment in any long-term monitoring program. For simplicity, we focus on temporal trends in population size across years. We refer to the survey results for each year as the âannual meansâ (e.g. mean per transect, per plot, per time period). The methods apply with little or no modification, however, to formal estimates of population size, other temporal units (e.g. a month), to spatial or other dimensions such as elevation or a northâsouth gradient, and to other quantities such as chemical or geological parameters. The chapter primarily discusses methods for estimating population-wide parameters rather than studying variation in trend within the population, which can be examined using methods presented in other chapters (e.g. Chapters 7, 12, 20). We begin by reviewing key concepts related to trend analysis. We then describe how to evaluate potential bias in trend estimates. An overview of the statistical models used to quantify trends is then presented. We conclude by showing ways to estimate trends using simple methods that can be implemented with spreadsheets.\n\nDetecting long-term growth trends using tree rings: a critical evaluation of methods.\n\nPubMed\n\nPeters, Richard L; Groenendijk, Peter; Vlam, Mart; Zuidema, Pieter A\n\n2015-05-01\n\nTree-ring analysis is often used to assess long-term trends in tree growth. A variety of growth-trend detection methods (GDMs) exist to disentangle age/size trends in growth from long-term growth changes. However, these detrending methods strongly differ in approach, with possible implications for their output. Here, we critically evaluate the consistency, sensitivity, reliability and accuracy of four most widely used GDMs: conservative detrending (CD) applies mathematical functions to correct for decreasing ring widths with age; basal area correction (BAC) transforms diameter into basal area growth; regional curve standardization (RCS) detrends individual tree-ring series using average age/size trends; and size class isolation (SCI) calculates growth trends within separate size classes. First, we evaluated whether these GDMs produce consistent results applied to an empirical tree-ring data set of Melia azedarach, a tropical tree species from Thailand. Three GDMs yielded similar results - a growth decline over time - but the widely used CD method did not detect any change. Second, we assessed the sensitivity (probability of correct growth-trend detection), reliability (100% minus probability of detecting false trends) and accuracy (whether the strength of imposed trends is correctly detected) of these GDMs, by applying them to simulated growth trajectories with different imposed trends: no trend, strong trends (-6% and +6% change per decade) and weak trends (-2%, +2%). All methods except CD, showed high sensitivity, reliability and accuracy to detect strong imposed trends. However, these were considerably lower in the weak or no-trend scenarios. BAC showed good sensitivity and accuracy, but low reliability, indicating uncertainty of trend detection using this method. Our study reveals that the choice of GDM influences results of growth-trend studies. We recommend applying multiple methods when analysing trends and encourage performing sensitivity and reliability\n\nA bootstrap method for estimating uncertainty of water quality trends\n\nUSGS Publications Warehouse\n\nHirsch, Robert M.; Archfield, Stacey A.; DeCicco, Laura\n\n2015-01-01\n\nEstimation of the direction and magnitude of trends in surface water quality remains a problem of great scientific and practical interest. The Weighted Regressions on Time, Discharge, and Season (WRTDS) method was recently introduced as an exploratory data analysis tool to provide flexible and robust estimates of water quality trends. This paper enhances the WRTDS method through the introduction of the WRTDS Bootstrap Test (WBT), an extension of WRTDS that quantifies the uncertainty in WRTDS-estimates of water quality trends and offers various ways to visualize and communicate these uncertainties. Monte Carlo experiments are applied to estimate the Type I error probabilities for this method. WBT is compared to other water-quality trend-testing methods appropriate for data sets of one to three decades in length with sampling frequencies of 6â24 observations per year. The software to conduct the test is in the EGRETci R-package.\n\nNASA standard: Trend analysis techniques\n\nNASA Technical Reports Server (NTRS)\n\n1990-01-01\n\nDescriptive and analytical techniques for NASA trend analysis applications are presented in this standard. Trend analysis is applicable in all organizational elements of NASA connected with, or supporting, developmental/operational programs. This document should be consulted for any data analysis activity requiring the identification or interpretation of trends. Trend analysis is neither a precise term nor a circumscribed methodology: it generally connotes quantitative analysis of time-series data. For NASA activities, the appropriate and applicable techniques include descriptive and graphical statistics, and the fitting or modeling of data by linear, quadratic, and exponential models. Usually, but not always, the data is time-series in nature. Concepts such as autocorrelation and techniques such as Box-Jenkins time-series analysis would only rarely apply and are not included in this document. The basic ideas needed for qualitative and quantitative assessment of trends along with relevant examples are presented.\n\nNASA standard: Trend analysis techniques\n\nNASA Technical Reports Server (NTRS)\n\n1988-01-01\n\nThis Standard presents descriptive and analytical techniques for NASA trend analysis applications. Trend analysis is applicable in all organizational elements of NASA connected with, or supporting, developmental/operational programs. Use of this Standard is not mandatory; however, it should be consulted for any data analysis activity requiring the identification or interpretation of trends. Trend Analysis is neither a precise term nor a circumscribed methodology, but rather connotes, generally, quantitative analysis of time-series data. For NASA activities, the appropriate and applicable techniques include descriptive and graphical statistics, and the fitting or modeling of data by linear, quadratic, and exponential models. Usually, but not always, the data is time-series in nature. Concepts such as autocorrelation and techniques such as Box-Jenkins time-series analysis would only rarely apply and are not included in this Standard. The document presents the basic ideas needed for qualitative and quantitative assessment of trends, together with relevant examples. A list of references provides additional sources of information.\n\nIntegrated mixed methods policy analysis for sustainable food systems: trends, challenges and future research.\n\nPubMed\n\nCuevas, Soledad\n\nAgriculture is a major contributor to greenhouse gas emissions, an important part of which is associated to deforestation and indirect land use change. Appropriate and coherent food policies can play an important role in aligning health, economic and environmental goals. From the point of view of policy analysis, however, this requires multi-sectoral, interdisciplinary approaches which can be highly complex. Important methodological advances in the area are not exempted from limitations and criticism. We argue that there is scope for further developments in integrated quantitative and qualitative policy analysis combining existing methods, including mathematical modelling and stakeholder analysis. We outline methodological trends in the field, briefly characterise integrated mixed methods policy analysis and identify contributions, challenges and opportunities for future research. In particular, this type of approach can help address issues of uncertainty and context-specific validity, incorporate multiple perspectives and help advance meaningful interdisciplinary collaboration in the field. Substantial challenges remain, however, such as the integration of key issues related to non-communicable disease, or the incorporation of a broader range of qualitative approaches that can address important cultural and ethical dimensions of food.\n\nNew trends in beer flavour compound analysis.\n\nPubMed\n\nAndrÃ©s-Iglesias, Cristina; Montero, Olimpio; Sancho, Daniel; Blanco, Carlos A\n\n2015-06-01\n\nAs the beer market is steadily expanding, it is important for the brewing industry to offer consumers a product with the best organoleptic characteristics, flavour being one of the key characteristics of beer. New trends in instrumental methods of beer flavour analysis are described. In addition to successfully applied methods in beer analysis such as chromatography, spectroscopy, nuclear magnetic resonance, mass spectrometry or electronic nose and tongue techniques, among others, sample extraction and preparation such as derivatization or microextraction methods are also reviewed. Â© 2014 Society of Chemical Industry.\n\nTrends in HFE Methods and Tools and Their Applicability to Safety Reviews\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nO'Hara, J.M.; Plott, C.; Milanski, J.\n\n2009-09-30\n\nThe U.S. Nuclear Regulatory Commission's (NRC) conducts human factors engineering (HFE) safety reviews of applicant submittals for new plants and for changes to existing plants. The reviews include the evaluation of the methods and tools (M&T) used by applicants as part of their HFE program. The technology used to perform HFE activities has been rapidly evolving, resulting in a whole new generation of HFE M&Ts. The objectives of this research were to identify the current trends in HFE methods and tools, determine their applicability to NRC safety reviews, and identify topics for which the NRC may need additional guidance tomoreÂ Â» support the NRC's safety reviews. We conducted a survey that identified over 100 new HFE M&Ts. The M&Ts were assessed to identify general trends. Seven trends were identified: Computer Applications for Performing Traditional Analyses, Computer-Aided Design, Integration of HFE Methods and Tools, Rapid Development Engineering, Analysis of Cognitive Tasks, Use of Virtual Environments and Visualizations, and Application of Human Performance Models. We assessed each trend to determine its applicability to the NRC's review by considering (1) whether the nuclear industry is making use of M&Ts for each trend, and (2) whether M&Ts reflecting the trend can be reviewed using the current design review guidance. We concluded that M&T trends that are applicable to the commercial nuclear industry and are expected to impact safety reviews may be considered for review guidance development. Three trends fell into this category: Analysis of Cognitive Tasks, Use of Virtual Environments and Visualizations, and Application of Human Performance Models. The other trends do not need to be addressed at this time.Â«Â less\n\nInterrupted time-series analysis: studying trends in neurosurgery.\n\nPubMed\n\nWong, Ricky H; Smieliauskas, Fabrice; Pan, I-Wen; Lam, Sandi K\n\n2015-12-01\n\nOBJECT Neurosurgery studies traditionally have evaluated the effects of interventions on health care outcomes by studying overall changes in measured outcomes over time. Yet, this type of linear analysis is limited due to lack of consideration of the trend's effects both pre- and postintervention and the potential for confounding influences. The aim of this study was to illustrate interrupted time-series analysis (ITSA) as applied to an example in the neurosurgical literature and highlight ITSA's potential for future applications. METHODS The methods used in previous neurosurgical studies were analyzed and then compared with the methodology of ITSA. RESULTS The ITSA method was identified in the neurosurgical literature as an important technique for isolating the effect of an intervention (such as a policy change or a quality and safety initiative) on a health outcome independent of other factors driving trends in the outcome. The authors determined that ITSA allows for analysis of the intervention's immediate impact on outcome level and on subsequent trends and enables a more careful measure of the causal effects of interventions on health care outcomes. CONCLUSIONS ITSA represents a significant improvement over traditional observational study designs in quantifying the impact of an intervention. ITSA is a useful statistical procedure to understand, consider, and implement as the field of neurosurgery evolves in sophistication in big-data analytics, economics, and health services research.\n\nWater-quality trends in the nationâs rivers and streams, 1972â2012âData preparation, statistical methods, and trend results\n\nUSGS Publications Warehouse\n\nOelsner, Gretchen P.; Sprague, Lori A.; Murphy, Jennifer C.; Zuellig, Robert E.; Johnson, Henry M.; Ryberg, Karen R.; Falcone, James A.; Stets, Edward G.; Vecchia, Aldo V.; Riskin, Melissa L.; De Cicco, Laura A.; Mills, Taylor J.; Farmer, William H.\n\n2017-04-04\n\nSince passage of the Clean Water Act in 1972, Federal, State, and local governments have invested billions of dollars to reduce pollution entering rivers and streams. To understand the return on these investments and to effectively manage and protect the Nationâs water resources in the future, we need to know how and why water quality has been changing over time. As part of the National Water-Quality Assessment Project, of the U.S. Geological Surveyâs National Water-Quality Program, data from the U.S. Geological Survey, along with multiple other Federal, State, Tribal, regional, and local agencies, have been used to support the most comprehensive assessment conducted to date of surface-water-quality trends in the United States. This report documents the methods used to determine trends in water quality and ecology because these methods are vital to ensuring the quality of the results. Specific objectives are to document (1) the data compilation and processing steps used to identify river and stream sites throughout the Nation suitable for water-quality, pesticide, and ecology trend analysis, (2) the statistical methods used to determine trends in target parameters, (3) considerations for water-quality, pesticide, and ecology data and streamflow data when modeling trends, (4) sensitivity analyses for selecting data and interpreting trend results with the Weighted Regressions on Time, Discharge, and Season method, and (5) the final trend results at each site. The scope of this study includes trends in water-quality concentrations and loads (nutrient, sediment, major ion, salinity, and carbon), pesticide concentrations and loads, and metrics for aquatic ecology (fish, invertebrates, and algae) for four time periods: (1) 1972â2012, (2) 1982â2012, (3) 1992â2012, and (4) 2002â12. In total, nearly 12,000 trends in concentration, load, and ecology metrics were evaluated in this study; there were 11,893 combinations of sites, parameters, and trend periods. The\n\nExploring stability of entropy analysis for signal with different trends\n\nNASA Astrophysics Data System (ADS)\n\nZhang, Yin; Li, Jin; Wang, Jun\n\n2017-03-01\n\nConsidering the effects of environment disturbances and instrument systems, the actual detecting signals always are carrying different trends, which result in that it is difficult to accurately catch signals complexity. So choosing steady and effective analysis methods is very important. In this paper, we applied entropy measures-the base-scale entropy and approximate entropy to analyze signal complexity, and studied the effect of trends on the ideal signal and the heart rate variability (HRV) signals, that is, linear, periodic, and power-law trends which are likely to occur in actual signals. The results show that approximate entropy is unsteady when we embed different trends into the signals, so it is not suitable to analyze signal with trends. However, the base-scale entropy has preferable stability and accuracy for signal with different trends. So the base-scale entropy is an effective method to analyze the actual signals.\n\nUrban and peri-urban precipitation and air temperature trends in mega cities of the world using multiple trend analysis methods\n\nNASA Astrophysics Data System (ADS)\n\nAjaaj, Aws A.; Mishra, Ashok K.; Khan, Abdul A.\n\n2018-04-01\n\nUrbanization plays an important role in altering local to regional climate. In this study, the trends in precipitation and the air temperature were investigated for urban and peri-urban areas of 18 mega cities selected from six continents (representing a wide range of climatic patterns). Multiple statistical tests were used to examine long-term trends in annual and seasonal precipitation and air temperature for the selected cities. The urban and peri-urban areas were classified based on the percentage of land imperviousness. Through this study, it was evident that removal of the lag-k serial correlation caused a reduction of approximately 20 to 30% in significant trend observability for temperature and precipitation data. This observation suggests that appropriate trend analysis methodology for climate studies is necessary. Additionally, about 70% of the urban areas showed higher positive air temperature trends, compared with peri-urban areas. There were not clear trend signatures (i.e., mix of increase or decrease) when comparing urban vs peri-urban precipitation in each selected city. Overall, cities located in dry areas, for example, in Africa, southern parts of North America, and Eastern Asia, showed a decrease in annual and seasonal precipitation, while wetter conditions were favorable for cities located in wet regions such as, southeastern South America, eastern North America, and northern Europe. A positive relationship was observed between decadal trends of annual/seasonal air temperature and precipitation for all urban and peri-urban areas, with a higher rate being observed for urban areas.\n\nLong-term trends of suicide by choice of method in Norway: a joinpoint regression analysis of data from 1969 to 2012.\n\nPubMed\n\nPuzo, Quirino; Qin, Ping; Mehlum, Lars\n\n2016-03-11\n\nSuicide mortality and the rates by specific methods in a population may change over time in response to concurrent changes in relevant factors in society. This study aimed to identify significant changing points in method-specific suicide mortality from 1969 to 2012 in Norway. Data on suicide mortality by specific methods and by sex and age were retrieved from the Norwegian Cause-of-Death Register. Long-term trends in age-standardized rates of suicide mortality were analyzed by using joinpoint regression analysis. The most frequently used suicide method in the total population was hanging, followed by poisoning and firearms. Men chose suicide by firearms more often than women, whereas poisoning and drowning were more frequently used by women. The joinpoint analysis revealed that the overall trend of suicide mortality significantly changed twice along the period of 1969 to 2012 for both sexes. The male age-standardized suicide rate increased by 3.1% per year until 1989, and decreased by 1.2% per year between 1994 and 2012. Among females the long-term suicide rate increased by 4.0% per year until 1988, decreased by 5.5% through 1995, and then stabilized. Both sexes experienced an upward trend for suicide by hanging during the 44-year observation period, with a particularly significant increase in 15-24 year old males. The most distinct change among men was seen for firearms after 1988 with a significant decrease through 2012 of around 5% per year. For women, significant reductions since 1985-88 were observed for suicide by drowning and poisoning. The present study demonstrates different time trends for different suicide methods with significant reductions in suicide by firearms, drowning and poisoning after the peak in the suicide rate in the late 1980s. Suicide by means of hanging continuously increased, but did not fully compensate for the reduced use of other methods. This lends some support for the effectiveness of method-specific suicide preventive measures\n\nTrend Analysis Using Microcomputers.\n\nERIC Educational Resources Information Center\n\nBerger, Carl F.\n\nA trend analysis statistical package and additional programs for the Apple microcomputer are presented. They illustrate strategies of data analysis suitable to the graphics and processing capabilities of the microcomputer. The programs analyze data sets using examples of: (1) analysis of variance with multiple linear regression; (2) exponentialâ¦\n\nAutomating Trend Analysis for Spacecraft Constellations\n\nNASA Technical Reports Server (NTRS)\n\nDavis, George; Cooter, Miranda; Updike, Clark; Carey, Everett; Mackey, Jennifer; Rykowski, Timothy; Powers, Edward I. (Technical Monitor)\n\n2001-01-01\n\nSpacecraft trend analysis is a vital mission operations function performed by satellite controllers and engineers, who perform detailed analyses of engineering telemetry data to diagnose subsystem faults and to detect trends that may potentially lead to degraded subsystem performance or failure in the future. It is this latter function that is of greatest importance, for careful trending can often predict or detect events that may lead to a spacecraft's entry into safe-hold. Early prediction and detection of such events could result in the avoidance of, or rapid return to service from, spacecraft safing, which not only results in reduced recovery costs but also in a higher overall level of service for the satellite system. Contemporary spacecraft trending activities are manually intensive and are primarily performed diagnostically after a fault occurs, rather than proactively to predict its occurrence. They also tend to rely on information systems and software that are oudated when compared to current technologies. When coupled with the fact that flight operations teams often have limited resources, proactive trending opportunities are limited, and detailed trend analysis is often reserved for critical responses to safe holds or other on-orbit events such as maneuvers. While the contemporary trend analysis approach has sufficed for current single-spacecraft operations, it will be unfeasible for NASA's planned and proposed space science constellations. Missions such as the Dynamics, Reconnection and Configuration Observatory (DRACO), for example, are planning to launch as many as 100 'nanospacecraft' to form a homogenous constellation. A simple extrapolation of resources and manpower based on single-spacecraft operations suggests that trending for such a large spacecraft fleet will be unmanageable, unwieldy, and cost-prohibitive. It is therefore imperative that an approach to automating the spacecraft trend analysis function be studied, developed, and applied to\n\nNZ Government's trend analysis of hospitalised self-harm is misleading.\n\nPubMed\n\nLangley, John; Cryer, Colin; Davie, Gabrielle\n\n2008-04-01\n\nThe aim of this paper is to demonstrate that the trends published in the New Zealand (NZ) Government's 2006 Suicide Trends document for hospitalised self-harm are misleading. Analysis of incident self-harm events resulting in hospitalisation and reference to published material on injury outcome indicators for the NZ Injury Prevention Strategy (NZIPS). The significant increase in rates of self-harm hospitalisation presented in Suicide Trends from 1989 to a large extent reflect changes in recording practice rather than any change in self-harm in the community. Indicators with significantly fewer threats to validity suggest there has been little, if any, increase in the incidence of self-harm. The authors of Suicide Trends did not adequately specify how they defined a case and, moreover, their methods were not consistent with those used for the NZIPS indicators. The methodological challenges to producing valid indicators for the purposes of measuring trends in important non-fatal injury are substantial. Unless we accept that the usual methods of measuring trends in non-fatal injury are misleading and commit to taking up the challenge to produce and use better indicators, we will continue to run the risk of misleading ourselves and the public.\n\nNoninvasive methods for monitoring bear population trends\n\nUSGS Publications Warehouse\n\nKendall, Katherine\n\n2010-01-01\n\nThe U.S. Geological Survey began a grizzly bear research project in 2009 in the Northern Continental Divide Ecosystem (NCDE) of northwestern Montana. This work uses hair collection and DNA analysis methods similar to those used in the 2004 Northern Divide Grizzly Bear Project. However, instead of producing a snapshot of population size, the objectives of this new work are to estimate population growth rates by collecting hair at natural bear rubs along trails, roads, and fence and power lines. This approach holds promise of providing reliable estimates of population trends in an efficient, cost-effective, and unobtrusive way.\n\nBeyond trend analysis: How a modified breakpoint analysis enhances knowledge of agricultural production after Zimbabwe's fast track land reform\n\nNASA Astrophysics Data System (ADS)\n\nHentze, Konrad; Thonfeld, Frank; Menz, Gunter\n\n2017-10-01\n\nIn the discourse on land reform assessments, a significant lack of spatial and time-series data has been identified, especially with respect to Zimbabwe's ;Fast-Track Land Reform Programme; (FTLRP). At the same time, interest persists among land use change scientists to evaluate causes of land use change and therefore to increase the explanatory power of remote sensing products. This study recognizes these demands and aims to provide input on both levels: Evaluating the potential of satellite remote sensing time-series to answer questions which evolved after intensive land redistribution efforts in Zimbabwe; and investigating how time-series analysis of Normalized Difference Vegetation Index (NDVI) can be enhanced to provide information on land reform induced land use change. To achieve this, two time-series methods are applied to MODIS NDVI data: Seasonal Trend Analysis (STA) and Breakpoint Analysis for Additive Season and Trend (BFAST). In our first analysis, a link of agricultural productivity trends to different land tenure regimes shows that regional clustering of trends is more dominant than a relationship between tenure and trend with a slightly negative slope for all regimes. We demonstrate that clusters of strong negative and positive productivity trends are results of changing irrigation patterns. To locate emerging and fallow irrigation schemes in semi-arid Zimbabwe, a new multi-method approach is developed which allows to map changes from bimodal seasonal phenological patterns to unimodal and vice versa. With an enhanced breakpoint analysis through the combination of STA and BFAST, we are able to provide a technique that can be applied on large scale to map status and development of highly productive cropping systems, which are key for food production, national export and local employment. We therefore conclude that the combination of existing and accessible time-series analysis methods: is able to achieve both: overcoming demonstrated limitations of\n\nA Brief Analysis of Suicide Methods and Trends in Virginia from 2003 to 2012\n\nPubMed Central\n\nKeyser-Marcus, Lori; Crouse Breden, Ericka; Hobron, Kathrin; Bhattachan, Atit; Pandurangi, Ananda\n\n2015-01-01\n\nBackground. The objective is to analyze and compare Virginia suicide data from 2003 to 2012 to US suicide data. Methods. Suicide trends by method, age, gender, and race were obtained from Virginia's Office of the Chief Medical Examiner's annual reports. Results. Similar to US suicide rates, suicide rates in Virginia increased between 2003 and 2012 from 10.9/100,000 people to 12.9/100,000 people. The most common methods were firearm, asphyxia, and intentional drug overdose, respectively. The increase in asphyxia (r = 0.77, P â¤ 0.01) and decrease in CO poisoning (r = â0.89, P â¤ 0.01) were significant. Unlike national trends, intentional drug overdoses decreased (r = â0.55, P = 0.10). Handgun suicides increased (r = 0.61, P = 0.06) and are the most common method of firearm suicide. Hanging was the most common method of asphyxia. Helium suicides also increased (r = 0.75, P = 0.05). Middle age females and males comprise the largest percentage of suicide. Unlike national data, the increase in middle age male suicides occurred only in the 55â64-year-old age group (r = 0.79, P â¤ 0.01) and decreased in the 35â44-year-old age group (r = â0.60, P = 0.07) and 10â14-year-old age group (r = â0.73, P = 0.02). Suicide in all female age ranges remained stable. Caucasians represent the highest percentage of suicide. Conclusion. There has been a rise in suicide in Virginia and suicide rates and trends have closely resembled the national average albeit some differences. Suicide prevention needs to be enhanced. PMID:25705647\n\nTESOL Methods: Changing Tracks, Challenging Trends\n\nERIC Educational Resources Information Center\n\nKumaravadivelu, B.\n\n2006-01-01\n\nThis article traces the major trends in TESOL methods in the past 15 years. It focuses on the TESOL profession's evolving perspectives on language teaching methods in terms of three perceptible shifts: (a) from communicative language teaching to task-based language teaching, (b) from method-based pedagogy to postmethod pedagogy, and (c) fromâ¦\n\nComparison of detrending methods for fluctuation analysis in hydrology\n\nNASA Astrophysics Data System (ADS)\n\nZhang, Qiang; Zhou, Yu; Singh, Vijay P.; Chen, Yongqin David\n\n2011-03-01\n\nSummaryTrends within a hydrologic time series can significantly influence the scaling results of fluctuation analysis, such as rescaled range (RS) analysis and (multifractal) detrended fluctuation analysis (MF-DFA). Therefore, removal of trends is important in the study of scaling properties of the time series. In this study, three detrending methods, including adaptive detrending algorithm (ADA), Fourier-based method, and average removing technique, were evaluated by analyzing numerically generated series and observed streamflow series with obvious relative regular periodic trend. Results indicated that: (1) the Fourier-based detrending method and ADA were similar in detrending practices, and given proper parameters, these two methods can produce similarly satisfactory results; (2) detrended series by Fourier-based detrending method and ADA lose the fluctuation information at larger time scales, and the location of crossover points is heavily impacted by the chosen parameters of these two methods; and (3) the average removing method has an advantage over the other two methods, i.e., the fluctuation information at larger time scales is kept well-an indication of relatively reliable performance in detrending. In addition, the average removing method performed reasonably well in detrending a time series with regular periods or trends. In this sense, the average removing method should be preferred in the study of scaling properties of the hydrometeorolgical series with relative regular periodic trend using MF-DFA.\n\nAnalysis of soybean production and import trends and its import factors in Indonesia\n\nNASA Astrophysics Data System (ADS)\n\nNingrum, I. H.; Irianto, H.; Riptanti, E. W.\n\n2018-03-01\n\nThis study aims to analyze the factors affecting soybean imports in Indonesia and to know the trend and projection of Indonesian soybean production as well as the import in 2016-2020. The basic method used in this research is the description analysis method. The data used are secondary data in the form of time series data from 1979-2015. Methods of data analysis using simultaneous equations model with 2SLS (Two Stage Least Square) method and Trend analysis. The results showed that the factors affecting soybean imports in Indonesia are consumption and production. Consumption has positive effect while production is negatively affected. The percentage changed in soybean imports is greater than the percentage change in consumption and production of soybeans. Consumption is positively influenced by imports and production, while production is influenced positively by consumption and negative by imports. The production trend of soybean in 2016-2020 has a tendency to increase with a percentage of 11.18% per year. Production in 2016 is projected at 1.110.537 tons while in 2020 it will increase to 1,721,350 tons. The import trend in 2016-2020 has a tendency to increase with an average percentage of 4.13% per year. Import in 2016 is projected at 2.224.188 tons while in 2020 it will increase to 2.611.270 tons.\n\nA power analysis for multivariate tests of temporal trend in species composition.\n\nPubMed\n\nIrvine, Kathryn M; Dinger, Eric C; Sarr, Daniel\n\n2011-10-01\n\nLong-term monitoring programs emphasize power analysis as a tool to determine the sampling effort necessary to effectively document ecologically significant changes in ecosystems. Programs that monitor entire multispecies assemblages require a method for determining the power of multivariate statistical models to detect trend. We provide a method to simulate presence-absence species assemblage data that are consistent with increasing or decreasing directional change in species composition within multiple sites. This step is the foundation for using Monte Carlo methods to approximate the power of any multivariate method for detecting temporal trends. We focus on comparing the power of the Mantel test, permutational multivariate analysis of variance, and constrained analysis of principal coordinates. We find that the power of the various methods we investigate is sensitive to the number of species in the community, univariate species patterns, and the number of sites sampled over time. For increasing directional change scenarios, constrained analysis of principal coordinates was as or more powerful than permutational multivariate analysis of variance, the Mantel test was the least powerful. However, in our investigation of decreasing directional change, the Mantel test was typically as or more powerful than the other models.\n\nA spatiotemporal analysis of U.S. station temperature trends over the last century\n\nNASA Astrophysics Data System (ADS)\n\nCapparelli, V.; Franzke, C.; Vecchio, A.; Freeman, M. P.; Watkins, N. W.; Carbone, V.\n\n2013-07-01\n\nThis study presents a nonlinear spatiotemporal analysis of 1167 station temperature records from the United States Historical Climatology Network covering the period from 1898 through 2008. We use the empirical mode decomposition method to extract the generally nonlinear trends of each station. The statistical significance of each trend is assessed against three null models of the background climate variability, represented by stochastic processes of increasing temporal correlation length. We find strong evidence that more than 50% of all stations experienced a significant trend over the last century with respect to all three null models. A spatiotemporal analysis reveals a significant cooling trend in the South-East and significant warming trends in the rest of the contiguous U.S. It also shows that the warming trend appears to have migrated equatorward. This shows the complex spatiotemporal evolution of climate change at local scales.\n\nTrends of Science Education Research: An Automatic Content Analysis\n\nERIC Educational Resources Information Center\n\nChang, Yueh-Hsia; Chang, Chun-Yen; Tseng, Yuen-Hsien\n\n2010-01-01\n\nThis study used scientometric methods to conduct an automatic content analysis on the development trends of science education research from the published articles in the four journals of \"International Journal of Science Education, Journal of Research in Science Teaching, Research in Science Education, and Science Education\" from 1990 to 2007. Theâ¦\n\nJoint principal trend analysis for longitudinal high-dimensional data.\n\nPubMed\n\nZhang, Yuping; Ouyang, Zhengqing\n\n2018-06-01\n\nWe consider a research scenario motivated by integrating multiple sources of information for better knowledge discovery in diverse dynamic biological processes. Given two longitudinal high-dimensional datasets for a group of subjects, we want to extract shared latent trends and identify relevant features. To solve this problem, we present a new statistical method named as joint principal trend analysis (JPTA). We demonstrate the utility of JPTA through simulations and applications to gene expression data of the mammalian cell cycle and longitudinal transcriptional profiling data in response to influenza viral infections. Â© 2017, The International Biometric Society.\n\n[Improved euler algorithm for trend forecast model and its application to oil spectrum analysis].\n\nPubMed\n\nZheng, Chang-song; Ma, Biao\n\n2009-04-01\n\nThe oil atomic spectrometric analysis technology is one of the most important methods for fault diagnosis and state monitoring of large machine equipment. The gray method is preponderant in the trend forecast at the same time. With the use of oil atomic spectrometric analysis result and combining the gray forecast theory, the present paper established a gray forecast model of the Fe/Cu concentration trend in the power-shift steering transmission. Aiming at the shortage of the gray method used in the trend forecast, the improved Euler algorithm was put forward for the first time to resolve the problem of the gray model and avoid the non-precision that the old gray model's forecast value depends on the first test value. This new method can make the forecast value more precision as shown in the example. Combined with the threshold value of the oil atomic spectrometric analysis, the new method was applied on the Fe/Cu concentration forecast and the premonition of fault information was obtained. So we can take steps to prevent the fault and this algorithm can be popularized to the state monitoring in the industry.\n\nProblems with the Fraser report Chapter 1: Pitfalls in BMI time trend analysis.\n\nPubMed\n\nLo, Ernest\n\n2014-11-05\n\nThe first chapter of the Fraser report \"Obesity in Canada: Overstated Problems, Misguided Policy Solutions\" presents a flawed and misleading analysis of BMI time trends. The objective of this commentary is to provide a tutorial on BMI time trend analysis through the examination of these flaws. Three issues are discussed: 1. Spotting regions of confidence interval overlap is a statistically flawed method of assessing trend; regression methods which measure the behaviour of the data as a whole are preferred. 2. Temporal stability in overweight (25â¤BMI<30) prevalence must be interpreted in the context of the underlying population BMI distribution. 3. BMI is considered reliable for tracking population-level weight trends due to its high correlation with body fat percentage. BMI-defined obesity prevalence represents a conservative underestimate of the population at risk. The findings of the Fraser report Chapter 1 are either refuted or substantially mitigated once the above issues are accounted for, and we do not find that the 'Canadian situation largely lacks a disconcerting or negative trend', as claimed. It is hoped that this commentary will help guide public health professionals who need to interpret, or wish to perform their own, time trend analyses of BMI.\n\nTrend analysis of hydro-climatic variables in the north of Iran\n\nNASA Astrophysics Data System (ADS)\n\nNikzad Tehrani, E.; Sahour, H.; Booij, M. J.\n\n2018-04-01\n\nTrend analysis of climate variables such as streamflow, precipitation, and temperature provides useful information for understanding the hydrological changes associated with climate change. In this study, a nonparametric Mann-Kendall test was employed to evaluate annual, seasonal, and monthly trends of precipitation and streamflow for the Neka basin in the north of Iran over a 44-year period (1972 to 2015). In addition, the Inverse Distance Weight (IDW) method was used for annual seasonal, monthly, and daily precipitation trends in order to investigate the spatial correlation between precipitation and streamflow trends in the study area. Results showed a downward trend in annual and winter precipitation (Z < -1.96) and an upward trend in annual maximum daily precipitation. Annual and monthly mean flows for most of the months in the Neka basin decreased by 14% significantly, but the annual maximum daily flow increased by 118%. Results for the trend analysis of streamflow and climatic variables showed that there are statistically significant relationships between precipitation and streamflow (p value < 0.05). Correlation coefficients for Kendall, Spearman's rank and linear regression are 0.43, 0.61, and 0.67, respectively. The spatial presentation of the detected precipitation and streamflow trends showed a downward trend for the mean annual precipitation observed in the upstream part of the study area which is consistent with the streamflow trend. Also, there is a good correlation between monthly and seasonal precipitation and streamflow for all sub-basins (Sefidchah, Gelvard, Abelu). In general, from a hydro-climatic point of view, the results showed that the study area is moving towards a situation with more severe drought events.\n\nOn summary measure analysis of linear trend repeated measures data: performance comparison with two competing methods.\n\nPubMed\n\nVossoughi, Mehrdad; Ayatollahi, S M T; Towhidi, Mina; Ketabchi, Farzaneh\n\n2012-03-22\n\nThe summary measure approach (SMA) is sometimes the only applicable tool for the analysis of repeated measurements in medical research, especially when the number of measurements is relatively large. This study aimed to describe techniques based on summary measures for the analysis of linear trend repeated measures data and then to compare performances of SMA, linear mixed model (LMM), and unstructured multivariate approach (UMA). Practical guidelines based on the least squares regression slope and mean of response over time for each subject were provided to test time, group, and interaction effects. Through Monte Carlo simulation studies, the efficacy of SMA vs. LMM and traditional UMA, under different types of covariance structures, was illustrated. All the methods were also employed to analyze two real data examples. Based on the simulation and example results, it was found that the SMA completely dominated the traditional UMA and performed convincingly close to the best-fitting LMM in testing all the effects. However, the LMM was not often robust and led to non-sensible results when the covariance structure for errors was misspecified. The results emphasized discarding the UMA which often yielded extremely conservative inferences as to such data. It was shown that summary measure is a simple, safe and powerful approach in which the loss of efficiency compared to the best-fitting LMM was generally negligible. The SMA is recommended as the first choice to reliably analyze the linear trend data with a moderate to large number of measurements and/or small to moderate sample sizes.\n\nGeneric trending and analysis system\n\nNASA Technical Reports Server (NTRS)\n\nKeehan, Lori; Reese, Jay\n\n1994-01-01\n\nThe Generic Trending and Analysis System (GTAS) is a generic spacecraft performance monitoring tool developed by NASA Code 511 and Loral Aerosys. It is designed to facilitate quick anomaly resolution and trend analysis. Traditionally, the job of off-line analysis has been performed using hardware and software systems developed for real-time spacecraft contacts; then, the systems were supplemented with a collection of tools developed by Flight Operations Team (FOT) members. Since the number of upcoming missions is increasing, NASA can no longer afford to operate in this manner. GTAS improves control center productivity and effectiveness because it provides a generic solution across multiple missions. Thus, GTAS eliminates the need for each individual mission to develop duplicate capabilities. It also allows for more sophisticated tools to be developed because it draws resources from several projects. In addition, the GTAS software system incorporates commercial off-the-shelf tools software (COTS) packages and reuses components of other NASA-developed systems wherever possible. GTAS has incorporated lessons learned from previous missions by involving the users early in the development process. GTAS users took a proactive role in requirements analysis, design, development, and testing. Because of user involvement, several special tools were designed and are now being developed. GTAS users expressed considerable interest in facilitating data collection for long term trending and analysis. As a result, GTAS provides easy access to large volumes of processed telemetry data directly in the control center. The GTAS archival and retrieval capabilities are supported by the integration of optical disk technology and a COTS relational database management system.\n\nCrossing trend analysis methodology and application for Turkish rainfall records\n\nNASA Astrophysics Data System (ADS)\n\nÅen, ZekÃ¢i\n\n2018-01-01\n\nTrend analyses are the necessary tools for depicting possible general increase or decrease in a given time series. There are many versions of trend identification methodologies such as the Mann-Kendall trend test, Spearman's tau, Sen's slope, regression line, and Åen's innovative trend analysis. The literature has many papers about the use, cons and pros, and comparisons of these methodologies. In this paper, a completely new approach is proposed based on the crossing properties of a time series. It is suggested that the suitable trend from the centroid of the given time series should have the maximum number of crossings (total number of up-crossings or down-crossings). This approach is applicable whether the time series has dependent or independent structure and also without any dependence on the type of the probability distribution function. The validity of this method is presented through extensive Monte Carlo simulation technique and its comparison with other existing trend identification methodologies. The application of the methodology is presented for a set of annual daily extreme rainfall time series from different parts of Turkey and they have physically independent structure.\n\nTrends in biomedical informatics: automated topic analysis of JAMIA articles\n\nPubMed Central\n\nWang, Shuang; Jiang, Chao; Jiang, Xiaoqian; Kim, Hyeon-Eui; Sun, Jimeng; Ohno-Machado, Lucila\n\n2015-01-01\n\nBiomedical Informatics is a growing interdisciplinary field in which research topics and citation trends have been evolving rapidly in recent years. To analyze these data in a fast, reproducible manner, automation of certain processes is needed. JAMIA is a âgeneralistâ journal for biomedical informatics. Its articles reflect the wide range of topics in informatics. In this study, we retrieved Medical Subject Headings (MeSH) terms and citations of JAMIA articles published between 2009 and 2014. We use tensors (i.e., multidimensional arrays) to represent the interaction among topics, time and citations, and applied tensor decomposition to automate the analysis. The trends represented by tensors were then carefully interpreted and the results were compared with previous findings based on manual topic analysis. A list of most cited JAMIA articles, their topics, and publication trends over recent years is presented. The analyses confirmed previous studies and showed that, from 2012 to 2014, the number of articles related to MeSH terms Methods, Organization & Administration, and Algorithms increased significantly both in number of publications and citations. Citation trends varied widely by topic, with Natural Language Processing having a large number of citations in particular years, and Medical Record Systems, Computerized remaining a very popular topic in all years. PMID:26555018\n\nModified visual field trend analysis.\n\nPubMed\n\nDe Moraes, Carlos Gustavo V; Ritch, Robert; Tello, Celso; Liebmann, Jeffrey M\n\n2011-01-01\n\nVisual field trend analysis can be influenced by outlying values that may disproportionately affect estimation of the rate of change. We tested a modified approach to visual field trend analysis to minimize this problem. Automated pointwise linear regression (PLR) was used in glaucoma patients with â¥13 SITA-Standard 24-2 VF tests in either eye. In the control group (Group A), conventional PLR using the entire set of VF tests was carried out. In the other 3 groups (study groups), a truncated analysis was done using only the first and last 3 (Group B), first and last 4 (Group C), or first and last 5 (Group D) VF tests. We compared the global slopes (dB/y), number of eyes experiencing significant progression, and significant improvement between groups. Ninety eyes of 90 patients were evaluated. The mean numberÂ±SD of VF tests was 15.7Â±2.6, spanning 7.8Â±1.7 years. The study groups showed similar global rates of VF change as the control group (Group A=-0.48Â±0.5, Group B=-0.48Â±0.6, Group C=-0.48Â±0.6, Group D=-0.48Â±0.5 dB/y, P>0.05), and a similar number of eyes reaching a progression endpoint (Group A=53, Group B=52, Group C=49, Group D=53, P>0.05). However, Group B showed fewer eyes presenting VF improvement (false-positives). The modified VF trend-analysis showed greater specificity than conventional PLR in a population with glaucoma.\n\nTrend analysis of weekly acid rain data, 1978-83\n\nUSGS Publications Warehouse\n\nSchertz, Terry L.; Hirsch, Robert M.\n\n1985-01-01\n\nThere are 19 stations in the National Atmospheric Deposition Program which operated over the period 1978-83 and were subsequently incorporated into the National Trends Network in 1983. The precipitation chemistry data for these stations for this period were analyzed for trend, spatial correlation, seasonality, and relationship to precipitation volume. The intent of the analysis was to provide insights on the sources of variation in precipitation chemistry and to attempt to ascertain what statistical procedures may be most useful for ongoing analysis of the National Trends Network data. The Seasonal Kendall test was used for detection of trends in raw concentrations of dissolved constituents, pH and specific conductance, and residuals of these parameters from regression analysis. Forty-one percent of the trends detected in the raw concentrations were downtrends, 4 percent were uptrends, and 55 percent showed no trends at a = 0.2. At a more restrictive significance level of a = 0.05, 24 percent of the trends detected were downtrends, 2 percent were uptrends, and 74 percent showed no trends. The two constituents of greatest interest in terms of human generated emissions and environmental effects, sulfate and nitrate, showed only downtrends, and sulfate showed the largest decreases in concentration per year of all the ions tested.\n\nTrend analysis of Arctic sea ice extent\n\nNASA Astrophysics Data System (ADS)\n\nSilva, M. E.; Barbosa, S. M.; Antunes, LuÃ­s; Rocha, ConceiÃ§Ã£o\n\n2009-04-01\n\nThe extent of Arctic sea ice is a fundamental parameter of Arctic climate variability. In the context of climate change, the area covered by ice in the Arctic is a particularly useful indicator of recent changes in the Arctic environment. Climate models are in near universal agreement that Arctic sea ice extent will decline through the 21st century as a consequence of global warming and many studies predict a ice free Arctic as soon as 2012. Time series of satellite passive microwave observations allow to assess the temporal changes in the extent of Arctic sea ice. Much of the analysis of the ice extent time series, as in most climate studies from observational data, have been focussed on the computation of deterministic linear trends by ordinary least squares. However, many different processes, including deterministic, unit root and long-range dependent processes can engender trend like features in a time series. Several parametric tests have been developed, mainly in econometrics, to discriminate between stationarity (no trend), deterministic trend and stochastic trends. Here, these tests are applied in the trend analysis of the sea ice extent time series available at National Snow and Ice Data Center. The parametric stationary tests, Augmented Dickey-Fuller (ADF), Phillips-Perron (PP) and the KPSS, do not support an overall deterministic trend in the time series of Arctic sea ice extent. Therefore, alternative parametrizations such as long-range dependence should be considered for characterising long-term Arctic sea ice variability.\n\nTechTrends 2010-2015: A Content Analysis\n\nERIC Educational Resources Information Center\n\nStauffer, Eric\n\n2017-01-01\n\nThis study is a content analysis of articles published within the journal \"TechTrends\" from 2000 to 2015. The study reveals that the publication \"TechTrends\" has increased the overall number of peer reviewed original papers over the last 6Â years. The author describes the proportion of these original papers per volume andâ¦\n\nAnalysis of temperature trends in Northern Serbia\n\nNASA Astrophysics Data System (ADS)\n\nTosic, Ivana; Gavrilov, Milivoj; UnkaÅ¡eviÄ, Miroslava; MarkoviÄ, Slobodan; PetroviÄ, Predrag\n\n2017-04-01\n\nAn analysis of air temperature trends in Northern Serbia for the annual and seasonal time series is performed for two periods: 1949-2013 and 1979-2013. Three data sets of surface air temperatures: monthly mean temperatures, monthly maximum temperatures, and monthly minimum temperatures are analyzed at 9 stations that have altitudes varying between 75 m and 102 m. Monthly mean temperatures are obtained as the average of the daily mean temperatures, while monthly maximum (minimum) temperatures are the maximum (minimum) values of daily temperatures in corresponding month. Positive trends were found in 29 out of 30 time series, and the negative trend was found only in winter during the period 1979-2013. Applying the Mann-Kendall test, significant positive trends were found in 15 series; 7 in the period 1949-2013 and 8 in the period 1979-2013; and no significant trend was found in 15 series. Significant positive trends are dominated during the year, spring, and summer, where it was found in 14 out of 18 cases. Significant positive trends were found 7, 5, and 3 times in mean, maximum and minimum temperatures, respectively. It was found that the positive temperature trends are dominant in Northern Serbia.\n\nComparison of Mann-Kendall and innovative trend method for water quality parameters of the Kizilirmak River, Turkey\n\nNASA Astrophysics Data System (ADS)\n\nKisi, Ozgur; Ay, Murat\n\n2014-05-01\n\nLow, medium and high values of a parameter are very important issues in climatological, meteorological and hydrological events. Moreover these values are used to decide various design parameters based on scientific aspects and real applications everywhere in the world. With this concept, a new trend method recently proposed by Åen was used for water parameters, pH, T, EC, Na+, K+, CO3-2, HCO3-, Cl-, SO4-2, B+3 and Q recorded at five different stations (station numbers and locations: 1535-Sogutluhan (Sivas), 1501-Yamula (Kayseri), 1546-Tuzkoy (Kayseri), 1503-Yahsihan (Kirsehir), and 1533-Inozu (Samsun)) selected from the Kizilirmak River in Turkey. Low, medium and high values of the parameters were graphically evaluated with this method. For comparison purposes, the Mann-Kendall trend test was also applied to the same data. Differences of the two trend tests were also emphasised. It was found that the Åen trend test compared with the MK trend test had several advantages. The results also revealed that the Åen trend test could be successfully used for trend analysis of water parameters especially in terms of evaluation of low, medium and high values of data.\n\nA case study in nonconformance and performance trend analysis\n\nNASA Technical Reports Server (NTRS)\n\nMaloy, Joseph E.; Newton, Coy P.\n\n1990-01-01\n\nAs part of NASA's effort to develop an agency-wide approach to trend analysis, a pilot nonconformance and performance trending analysis study was conducted on the Space Shuttle auxiliary power unit (APU). The purpose of the study was to (1) demonstrate that nonconformance analysis can be used to identify repeating failures of a specific item (and the associated failure modes and causes) and (2) determine whether performance parameters could be analyzed and monitored to provide an indication of component or system degradation prior to failure. The nonconformance analysis of the APU did identify repeating component failures, which possibly could be reduced if key performance parameters were monitored and analyzed. The performance-trending analysis verified that the characteristics of hardware parameters can be effective in detecting degradation of hardware performance prior to failure.\n\nCumulative meta-analysis: a new tool for detection of temporal trends and publication bias in ecology.\n\nPubMed Central\n\nLeimu, Roosa; Koricheva, Julia\n\n2004-01-01\n\nTemporal changes in the magnitude of research findings have recently been recognized as a general phenomenon in ecology, and have been attributed to the delayed publication of non-significant results and disconfirming evidence. Here we introduce a method of cumulative meta-analysis which allows detection of both temporal trends and publication bias in the ecological literature. To illustrate the application of the method, we used two datasets from recently conducted meta-analyses of studies testing two plant defence theories. Our results revealed three phases in the evolution of the treatment effects. Early studies strongly supported the hypothesis tested, but the magnitude of the effect decreased considerably in later studies. In the latest studies, a trend towards an increase in effect size was observed. In one of the datasets, a cumulative meta-analysis revealed publication bias against studies reporting disconfirming evidence; such studies were published in journals with a lower impact factor compared to studies with results supporting the hypothesis tested. Correlation analysis revealed neither temporal trends nor evidence of publication bias in the datasets analysed. We thus suggest that cumulative meta-analysis should be used as a visual aid to detect temporal trends and publication bias in research findings in ecology in addition to the correlative approach. PMID:15347521\n\nTrends in biomedical informatics: automated topic analysis of JAMIA articles.\n\nPubMed\n\nHan, Dong; Wang, Shuang; Jiang, Chao; Jiang, Xiaoqian; Kim, Hyeon-Eui; Sun, Jimeng; Ohno-Machado, Lucila\n\n2015-11-01\n\nBiomedical Informatics is a growing interdisciplinary field in which research topics and citation trends have been evolving rapidly in recent years. To analyze these data in a fast, reproducible manner, automation of certain processes is needed. JAMIA is a \"generalist\" journal for biomedical informatics. Its articles reflect the wide range of topics in informatics. In this study, we retrieved Medical Subject Headings (MeSH) terms and citations of JAMIA articles published between 2009 and 2014. We use tensors (i.e., multidimensional arrays) to represent the interaction among topics, time and citations, and applied tensor decomposition to automate the analysis. The trends represented by tensors were then carefully interpreted and the results were compared with previous findings based on manual topic analysis. A list of most cited JAMIA articles, their topics, and publication trends over recent years is presented. The analyses confirmed previous studies and showed that, from 2012 to 2014, the number of articles related to MeSH terms Methods, Organization & Administration, and Algorithms increased significantly both in number of publications and citations. Citation trends varied widely by topic, with Natural Language Processing having a large number of citations in particular years, and Medical Record Systems, Computerized remaining a very popular topic in all years. Â© The Author 2015. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved. For Permissions, please email: journals.permissions@oup.com.\n\nAir Pollution Instrumentation: A Trend toward Physical Methods\n\nERIC Educational Resources Information Center\n\nMaugh, Thomas H., II\n\n1972-01-01\n\nReviews reasons for the trend from wet chemical'' analytic techniques for measuring air pollutants toward physical methods based upon chemiluminescence, electrochemical transduction, flame ionization coupled with gas chromotography, and spectroscopy. (AL)\n\nInterfractional trend analysis of dose differences based on 2D transit portal dosimetry\n\nNASA Astrophysics Data System (ADS)\n\nPersoon, L. C. G. G.; Nijsten, S. M. J. J. G.; Wilbrink, F. J.; Podesta, M.; Snaith, J. A. D.; Lustberg, T.; van Elmpt, W. J. C.; van Gils, F.; Verhaegen, F.\n\n2012-10-01\n\nDose delivery of a radiotherapy treatment can be influenced by a number of factors. It has been demonstrated that the electronic portal imaging device (EPID) is valuable for transit portal dosimetry verification. Patient related dose differences can emerge at any time during treatment and can be categorized in two types: (1) systematicâappearing repeatedly, (2) randomâappearing sporadically during treatment. The aim of this study is to investigate how systematic and random information appears in 2D transit dose distributions measured in the EPID plane over the entire course of a treatment and how this information can be used to examine interfractional trends, building toward a methodology to support adaptive radiotherapy. To create a trend overview of the interfractional changes in transit dose, the predicted portal dose for the different beams is compared to a measured portal dose using a Î³ evaluation. For each beam of the delivered fraction, information is extracted from the Î³ images to differentiate systematic from random dose delivery errors. From the systematic differences of a fraction for a projected anatomical structures, several metrics are extracted like percentage pixels with |Î³| > 1. We demonstrate for four example cases the trends and dose difference causes which can be detected with this method. Two sample prostate cases show the occurrence of a random and systematic difference and identify the organ that causes the difference. In a lung cancer case a trend is shown of a rapidly diminishing atelectasis (lung fluid) during the course of treatment, which was detected with this trend analysis method. The final example is a breast cancer case where we show the influence of set-up differences on the 2D transit dose. A method is presented based on 2D portal transit dosimetry to record dose changes throughout the course of treatment, and to allow trend analysis of dose discrepancies. We show in example cases that this method can identify the causes of\n\nA Study on Environmental Research Trends Using Text-Mining Method - Focus on Spatial information and ICT -\n\nNASA Astrophysics Data System (ADS)\n\nLee, M. J.; Oh, K. Y.; Joung-ho, L.\n\n2016-12-01\n\nRecently there are many research about analysing the interaction between entities by text-mining analysis in various fields. In this paper, we aimed to quantitatively analyse research-trends in the area of environmental research relating either spatial information or ICT (Information and Communications Technology) by Text-mining analysis. To do this, we applied low-dimensional embedding method, clustering analysis, and association rule to find meaningful associative patterns of key words frequently appeared in the articles. As the authors suppose that KCI (Korea Citation Index) articles reflect academic demands, total 1228 KCI articles that have been published from 1996 to 2015 were reviewed and analysed by Text-mining method. First, we derived KCI articles from NDSL(National Discovery for Science Leaders) site. And then we pre-processed their key-words elected from abstract and then classified those in separable sectors. We investigated the appearance rates and association rule of key-words for articles in the two fields: spatial-information and ICT. In order to detect historic trends, analysis was conducted separately for the four periods: 1996-2000, 2001-2005, 2006-2010, 2011-2015. These analysis were conducted with the usage of R-software. As a result, we conformed that environmental research relating spatial information mainly focused upon such fields as `GIS(35%)', `Remote-Sensing(25%)', `environmental theme map(15.7%)'. Next, `ICT technology(23.6%)', `ICT service(5.4%)', `mobile(24%)', `big data(10%)', `AI(7%)' are primarily emerging from environmental research relating ICT. Thus, from the analysis results, this paper asserts that research trends and academic progresses are well-structured to review recent spatial information and ICT technology and the outcomes of the analysis can be an adequate guidelines to establish environment policies and strategies. KEY WORDS: Big data, Test-mining, Environmental research, Spatial-information, ICT Acknowledgements: The\n\nTrend analysis of the wave storminess: the wave direction\n\nNASA Astrophysics Data System (ADS)\n\nCasas Prat, M.; Sierra, J. P.; MÃ¶sso, C.; SÃ¡nchez-Arcilla, A.\n\n2009-09-01\n\ndirectionality. It is based on 44 year hindcast model data (1958-2001) of the HIPOCAS project, enabling to work with a longer time series compared to the existing measured ones. 41 nodes of this database are used, containing 3 hourly simulated data of significant wave height and wave direction, among other parameters. For storm definition, the Peak Over Threshold (POT) method is used with some additional duration requirements in order to analyse statistically independent events (Mendoza & JimÃ©nez, 2006). Including both wave height and storm duration, the wave storminess is characterised by the energy content (Mendoza & JimÃ©nez, 2004), being in turn log-transformed because of its positive scale. Separately, the wave directionality itself is analysed in terms of different sectors and approaching their probability of occurrence by counting events and using Bayesian inference (Agresti, 2002). Therefore, the original data is transformed into compositional data and, before performing the trend analysis, the isometric logratio (ilr) transformation (Egozcue et al., 2003) is done. In general, the trend analysis methodology consists in two steps: 1) trend detection and 2) trend quantification. For 1) the Mann Kendall test is used in order to identify the nodes with significant trend. For these selected nodes, the trend quantification is done, comparing two methods: 1) a simple linear regression analysis complemented with the bootstrap technique and 2) a Bayesian analysis, assuming normally distributed data with linearly increasing mean. Preliminary results show no significant trend for both annual mean and maximum energy content except for some nodes located to the Northern Catalan coast. Regarding the wave direction (but not only considering stormy conditions) there is a tendency of North direction to decrease whereas South and Southeast direction seems to increase.\n\nThe Fusion of Financial Analysis and Seismology: Statistical Methods from Financial Market Analysis Applied to Earthquake Data\n\nNASA Astrophysics Data System (ADS)\n\nOhyanagi, S.; Dileonardo, C.\n\n2013-12-01\n\nAs a natural phenomenon earthquake occurrence is difficult to predict. Statistical analysis of earthquake data was performed using candlestick chart and Bollinger Band methods. These statistical methods, commonly used in the financial world to analyze market trends were tested against earthquake data. Earthquakes above Mw 4.0 located on shore of Sanriku (37.75Â°N ~ 41.00Â°N, 143.00Â°E ~ 144.50Â°E) from February 1973 to May 2013 were selected for analysis. Two specific patterns in earthquake occurrence were recognized through the analysis. One is a spread of candlestick prior to the occurrence of events greater than Mw 6.0. A second pattern shows convergence in the Bollinger Band, which implies a positive or negative change in the trend of earthquakes. Both patterns match general models for the buildup and release of strain through the earthquake cycle, and agree with both the characteristics of the candlestick chart and Bollinger Band analysis. These results show there is a high correlation between patterns in earthquake occurrence and trend analysis by these two statistical methods. The results of this study agree with the appropriateness of the application of these financial analysis methods to the analysis of earthquake occurrence.\n\nRegional assessment of trends in vegetation change dynamics using principal component analysis\n\nNASA Astrophysics Data System (ADS)\n\nOsunmadewa, B. A.; Csaplovics, E.; R. A., Majdaldin; Adeofun, C. O.; Aralova, D.\n\n2016-10-01\n\nVegetation forms the basis for the existence of animal and human. Due to changes in climate and human perturbation, most of the natural vegetation of the world has undergone some form of transformation both in composition and structure. Increased anthropogenic activities over the last decades had pose serious threat on the natural vegetation in Nigeria, many vegetated areas are either transformed to other land use such as deforestation for agricultural purpose or completely lost due to indiscriminate removal of trees for charcoal, fuelwood and timber production. This study therefore aims at examining the rate of change in vegetation cover, the degree of change and the application of Principal Component Analysis (PCA) in the dry sub-humid region of Nigeria using Normalized Difference Vegetation Index (NDVI) data spanning from 1983-2011. The method used for the analysis is the T-mode orientation approach also known as standardized PCA, while trends are examined using ordinary least square, median trend (Theil-Sen) and monotonic trend. The result of the trend analysis shows both positive and negative trend in vegetation change dynamics over the 29 years period examined. Five components were used for the Principal Component Analysis. The results of the first component explains about 98 % of the total variance of the vegetation (NDVI) while components 2-5 have lower variance percentage (< 1%). Two ancillary land use land cover data of 2000 and 2009 from European Space Agency (ESA) were used to further explain changes observed in the Normalized Difference Vegetation Index. The result of the land use data shows changes in land use pattern which can be attributed to anthropogenic activities such as cutting of trees for charcoal production, fuelwood and agricultural practices. The result of this study shows the ability of remote sensing data for monitoring vegetation change in the dry-sub humid region of Nigeria.\n\nBeyond linear methods of data analysis: time series analysis and its applications in renal research.\n\nPubMed\n\nGupta, Ashwani K; Udrea, Andreea\n\n2013-01-01\n\nAnalysis of temporal trends in medicine is needed to understand normal physiology and to study the evolution of disease processes. It is also useful for monitoring response to drugs and interventions, and for accountability and tracking of health care resources. In this review, we discuss what makes time series analysis unique for the purposes of renal research and its limitations. We also introduce nonlinear time series analysis methods and provide examples where these have advantages over linear methods. We review areas where these computational methods have found applications in nephrology ranging from basic physiology to health services research. Some examples include noninvasive assessment of autonomic function in patients with chronic kidney disease, dialysis-dependent renal failure and renal transplantation. Time series models and analysis methods have been utilized in the characterization of mechanisms of renal autoregulation and to identify the interaction between different rhythms of nephron pressure flow regulation. They have also been used in the study of trends in health care delivery. Time series are everywhere in nephrology and analyzing them can lead to valuable knowledge discovery. The study of time trends of vital signs, laboratory parameters and the health status of patients is inherent to our everyday clinical practice, yet formal models and methods for time series analysis are not fully utilized. With this review, we hope to familiarize the reader with these techniques in order to assist in their proper use where appropriate.\n\n0.1 Trend analysis of Î´18O composition of precipitation in Germany: Combining Mann-Kendall trend test and ARIMA models to correct for higher order serial correlation\n\nNASA Astrophysics Data System (ADS)\n\nKlaus, Julian; Pan Chun, Kwok; Stumpp, Christine\n\n2015-04-01\n\n.s.l.). Higher order autoregressive processes are important in the isotope time series analysis. Our results show that the widely used trend analysis with only the first order autocorrelation adjustment may not adequately take account of the high order autocorrelated processes in the stable isotope series. The investigated time series analysis method including higher autocorrelation and external climate variable adjustments is shown to be a better alternative.\n\nUsing principal component analysis and annual seasonal trend analysis to assess karst rocky desertification in southwestern China.\n\nPubMed\n\nZhang, Zhiming; Ouyang, Zhiyun; Xiao, Yi; Xiao, Yang; Xu, Weihua\n\n2017-06-01\n\nIncreasing exploitation of karst resources is causing severe environmental degradation because of the fragility and vulnerability of karst areas. By integrating principal component analysis (PCA) with annual seasonal trend analysis (ASTA), this study assessed karst rocky desertification (KRD) within a spatial context. We first produced fractional vegetation cover (FVC) data from a moderate-resolution imaging spectroradiometer normalized difference vegetation index using a dimidiate pixel model. Then, we generated three main components of the annual FVC data using PCA. Subsequently, we generated the slope image of the annual seasonal trends of FVC using median trend analysis. Finally, we combined the three PCA components and annual seasonal trends of FVC with the incidence of KRD for each type of carbonate rock to classify KRD into one of four categories based on K-means cluster analysis: high, moderate, low, and none. The results of accuracy assessments indicated that this combination approach produced greater accuracy and more reasonable KRD mapping than the average FVC based on the vegetation coverage standard. The KRD map for 2010 indicated that the total area of KRD was 78.76Â ÃÂ 10 3 Â km 2 , which constitutes about 4.06% of the eight southwest provinces of China. The largest KRD areas were found in Yunnan province. The combined PCA and ASTA approach was demonstrated to be an easily implemented, robust, and flexible method for the mapping and assessment of KRD, which can be used to enhance regional KRD management schemes or to address assessment of other environmental issues.\n\nTrend analysis of selected water-quality constituents in the Verde River Basin, central Arizona\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nBaldys, S.\n\n1990-01-01\n\nTemporal trends of eight water quality constituents at six data collection sites in the Verde River basin in central Arizona were investigated using seasonal Kendall tau and ordinary least-squares regression methods of analysis. The constituents are dissolved solids, dissolved sulfate, dissolved arsenic, total phosphorus, pH, total nitrite plus nitrate-nitrogen, dissolved iron, and fecal coliform bacteria. Increasing trends with time in dissolved-solids concentrations of 7 to 8 mg/L/yr at Verde River near Camp Verde were found at significant level. An increasing trend in dissolved-sulfate concentrations of 3.59 mg/L/yr was also found at Verde River near Camp Verde, although at nonsignificant levels.moreÂ Â» Statistically significant decreasing trends with time in dissolved-solids and dissolved-sulfate concentrations were found at Verde River above Horseshoe Reservoir, which is downstream from Verde River near Camp Verde. Observed trends in the other constituents do not indicate the emergence of water quality problems in the Verde River basin. Analysis of the eight water quality constituents generally indicate nonvarying concentration levels after adjustment for seasonality and streamflow were made.Â«Â less\n\nAnalysis on the hot spot and trend of the foreign assembly building research\n\nNASA Astrophysics Data System (ADS)\n\nBi, Xiaoqing; Luo, Yanbing\n\n2017-03-01\n\nFirst of all, the paper analyzes the research on the front of the assembly building in the past 15 years. This article mainly adopts the method of CO word analysis, construct the co word matrix, correlation matrix, and then into a dissimilarity matrix, and on this basis, using factor analysis, cluster analysis and multi scale analysis method to study the structure of prefabricated construction field display. Finally, the results of the analysis are discussed, and summarized the current research focus of foreign prefabricated construction mainly concentrated in 7 aspects: embankment construction, wood construction, bridge construction, crane layout, PCM wall and glass system, based on neural network test, energy saving and recycling, and forecast the future trend of development study.\n\nStatistical analysis of stratospheric temperature and ozone profile data for trends and model comparison\n\nNASA Technical Reports Server (NTRS)\n\nTiao, G. C.\n\n1992-01-01\n\nWork performed during the project period July 1, 1990 to June 30, 1992 on the statistical analysis of stratospheric temperature data, rawinsonde temperature data, and ozone profile data for the detection of trends is described. Our principal topics of research are trend analysis of NOAA stratospheric temperature data over the period 1978-1989; trend analysis of rawinsonde temperature data for the period 1964-1988; trend analysis of Umkehr ozone profile data for the period 1977-1991; and comparison of observed ozone and temperature trends in the lower stratosphere. Analysis of NOAA stratospheric temperature data indicates the existence of large negative trends at 0.4 mb level, with magnitudes increasing with latitudes away from the equator. Trend analysis of rawinsonde temperature data over 184 stations shows significant positive trends about 0.2 C per decade at surface to 500 mb range, decreasing to negative trends about -0.3 C at 100 to 50 mb range, and increasing slightly at 30 mb level. There is little evidence of seasonal variation in trends. Analysis of Umkehr ozone data for 12 northern hemispheric stations shows significant negative trends about -.5 percent per year in Umkehr layers 7-9 and layer 3, but somewhat less negative trends in layers 4-6. There is no pronounced seasonal variation in trends, especially in layers 4-9. A comparison was made of empirical temperature trends from rawinsonde data in the lower stratosphere with temperature changes determined from a one-dimensional radiative transfer calculation that prescribed a given ozone change over the altitude region, surface to 50 km, obtained from trend analysis of ozonsonde and Umkehr profile data. The empirical and calculated temperature trends are found in substantive agreement in profile shape and magnitude.\n\nInternal displacement and the Syrian crisis: an analysis of trends from 2011-2014.\n\nPubMed\n\nDoocy, Shannon; Lyles, Emily; Delbiso, Tefera D; Robinson, Courtland W\n\n2015-01-01\n\nSince the start of the Syrian crisis in 2011, civil unrest and armed conflict in the country have resulted in a rapidly increasing number of people displaced both within and outside of Syria. Those displaced face immense challenges in meeting their basic needs. This study sought to characterize internal displacement in Syria, including trends in both time and place, and to provide insights on the association between displacement and selected measures of household well-being and humanitarian needs. This study presents findings from two complementary methods: a desk review of displaced population estimates and movements and a needs assessment of 3930 Syrian households affected by the crisis. The first method, a desk review of displaced population estimates and movements, provides a retrospective analysis of national trends in displacement from March 2011 through June 2014. The second method, analysis of findings from a 2014 needs assessment by displacement status, provides insight into the displaced population and the association between displacement and humanitarian needs. Findings indicate that while displacement often corresponds to conflict levels, such trends were not uniformly observed in governorate-level analysis. Governorate level IDP estimates do not provide information on a scale detailed enough to adequately plan humanitarian assistance. Furthermore, such estimates are often influenced by obstructed access to certain areas, unsubstantiated reports, and substantial discrepancies in reporting. Secondary displacement is not consistently reported across sources nor are additional details about displacement, including whether displaced individuals originated within the current governorate or outside of the governorate. More than half (56.4Â %) of households reported being displaced more than once, with a majority displaced for more than one year (73.3Â %). Some differences between displaced and non-displaced population were observed in residence crowding, food\n\nAssessment of the relative merits of a few methods to detect evolutionary trends.\n\nPubMed\n\nLaurin, Michel\n\n2010-12-01\n\non slope of all FIC methods is slightly higher than that of phylogenetic generalized least squares (PGLS), SR, and PVR. PGLS performs well, with low Type I error rate, low error on regression coefficient, and power comparable with some FIC methods. Four variants of skewness analysis are examined, and a new method to assess significance of results is presented. However, all have consistently low power, except in rare combinations of trees, trend strength, and distance between final means and bounds. Globally, the results clearly show that FIC-based methods and PGLS are globally better than nonphylogenetic methods and variance partitioning with PVR. FIC methods and PGLS are sensitive to the model of evolution (and, hence, to branch length errors). Our results suggest that regressing raw character contrasts against raw geological age contrasts yields a good combination of power and Type I error rate. New software to facilitate batch analysis is presented.\n\nOSPAR standard method and software for statistical analysis of beach litter data.\n\nPubMed\n\nSchulz, Marcus; van Loon, Willem; Fleet, David M; Baggelaar, Paul; van der Meulen, Eit\n\n2017-09-15\n\nThe aim of this study is to develop standard statistical methods and software for the analysis of beach litter data. The optimal ensemble of statistical methods comprises the Mann-Kendall trend test, the Theil-Sen slope estimation, the Wilcoxon step trend test and basic descriptive statistics. The application of Litter Analyst, a tailor-made software for analysing the results of beach litter surveys, to OSPAR beach litter data from seven beaches bordering on the south-eastern North Sea, revealed 23 significant trends in the abundances of beach litter types for the period 2009-2014. Litter Analyst revealed a large variation in the abundance of litter types between beaches. To reduce the effects of spatial variation, trend analysis of beach litter data can most effectively be performed at the beach or national level. Spatial aggregation of beach litter data within a region is possible, but resulted in a considerable reduction in the number of significant trends. Copyright Â© 2017 Elsevier Ltd. All rights reserved.\n\nReevaluation of Stratospheric Ozone Trends From SAGE II Data Using a Simultaneous Temporal and Spatial Analysis\n\nNASA Technical Reports Server (NTRS)\n\nDamadeo, R. P.; Zawodny, J. M.; Thomason, L. W.\n\n2014-01-01\n\nThis paper details a new method of regression for sparsely sampled data sets for use with time-series analysis, in particular the Stratospheric Aerosol and Gas Experiment (SAGE) II ozone data set. Non-uniform spatial, temporal, and diurnal sampling present in the data set result in biased values for the long-term trend if not accounted for. This new method is performed close to the native resolution of measurements and is a simultaneous temporal and spatial analysis that accounts for potential diurnal ozone variation. Results show biases, introduced by the way data is prepared for use with traditional methods, can be as high as 10%. Derived long-term changes show declines in ozone similar to other studies but very different trends in the presumed recovery period, with differences up to 2% per decade. The regression model allows for a variable turnaround time and reveals a hemispheric asymmetry in derived trends in the middle to upper stratosphere. Similar methodology is also applied to SAGE II aerosol optical depth data to create a new volcanic proxy that covers the SAGE II mission period. Ultimately this technique may be extensible towards the inclusion of multiple data sets without the need for homogenization.\n\nTrend Analysis of Betel Nut-associated Oral Cancer â¨and Health Burden in China.\n\nPubMed\n\nHu, Yan Jia; Chen, Jie; Zhong, Wai Sheng; Ling, Tian You; Jian, Xin Chun; Lu, Ruo Huang; Tang, Zhan Gui; Tao, Lin\n\nTo forecast the future trend of betel nut-associated oral cancer and the resulting burden on health based on historical oral cancer patient data in Hunan province, China. Oral cancer patient data in five hospitals in Changsha (the capital city of Hunan province) were collected for the past 12 years. Three methods were used to analyse the data; Microsoft Excel Forecast Sheet, Excel Trendline, and the Logistic growth model. A combination of these three methods was used to forecast the future trend of betel nut-associated oral cancer and the resulting burden on health. Betel nut-associated oral cancer cases have been increasing rapidly in the past 12ââyears in Changsha. As of 2016, betel nuts had caused 8,222 cases of oral cancer in Changsha and close to 25,000 cases in Hunan, resulting in about Â¥5 billion in accumulated financial loss. The combined trend analysis predicts that by 2030, betel nuts will cause more than 100,000 cases of oral cancer in Changsha and more than 300,000 cases in Hunan, and more than Â¥64 billion in accumulated financial loss in medical expenses. The trend analysis of oral cancer patient data predicts that the growing betel nut industry in Hunan province will cause a humanitarian catastrophe with massive loss of human life and national resources. To prevent this catastrophe, China should ban betel nuts and provide early oral cancer screening for betel nut consumers as soon as possible.\n\nPrediction of protein post-translational modifications: main trends and methods\n\nNASA Astrophysics Data System (ADS)\n\nSobolev, B. N.; Veselovsky, A. V.; Poroikov, V. V.\n\n2014-02-01\n\nThe review summarizes main trends in the development of methods for the prediction of protein post-translational modifications (PTMs) by considering the three most common types of PTMs â phosphorylation, acetylation and glycosylation. Considerable attention is given to general characteristics of regulatory interactions associated with PTMs. Different approaches to the prediction of PTMs are analyzed. Most of the methods are based only on the analysis of the neighbouring environment of modification sites. The related software is characterized by relatively low accuracy of PTM predictions, which may be due both to the incompleteness of training data and the features of PTM regulation. Advantages and limitations of the phylogenetic approach are considered. The prediction of PTMs using data on regulatory interactions, including the modular organization of interacting proteins, is a promising field, provided that a more carefully selected training data will be used. The bibliography includes 145 references.\n\nTrend analysis of salt load and evaluation of the frequency of water-quality measurements for the Gunnison, the Colorado, and the Dolores rivers in Colorado and Utah\n\nUSGS Publications Warehouse\n\nKircher, J.E.; Dinicola, Richard S.; Middelburg, R.F.\n\n1984-01-01\n\nMonthly values were computed for water-quality constituents at four streamflow gaging stations in the Upper Colorado River basin for the determination of trends. Seasonal regression and seasonal Kendall trend analysis techniques were applied to two monthly data sets at each station site for four different time periods. A recently develo"
    }
}