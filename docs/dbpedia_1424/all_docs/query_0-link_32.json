{
    "id": "dbpedia_1424_0",
    "rank": 32,
    "data": {
        "url": "https://docs.gitlab.com/ee/development/testing_guide/best_practices.html",
        "read_more_link": "",
        "language": "en",
        "title": "Testing best practices",
        "top_image": "https://docs.gitlab.com/favicon.ico?v=2",
        "meta_img": "https://docs.gitlab.com/favicon.ico?v=2",
        "images": [
            "https://docs.gitlab.com/assets/images/gitlab-logo-header.svg",
            "https://docs.gitlab.com/assets/images/gitlab-logo.svg",
            "https://docs.gitlab.com/assets/images/by-sa.svg",
            "https://dc.ads.linkedin.com/collect/?pid=30694&fmt=gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "GitLab development guidelines - testing best practices.",
        "meta_lang": "en",
        "meta_favicon": "/favicon.ico?v=2",
        "meta_site_name": "",
        "canonical_link": "https://docs.gitlab.com/ee/development/testing_guide/best_practices.html",
        "text": "Test Design\n\nRSpec\n\nGeneral guidelines\n\nEager loading the application code\n\nRuby warnings\n\nTest order\n\nTest flakiness\n\nTest slowness\n\nDon’t request capabilities you don’t need\n\nProfiling: see where your test spend its time\n\nInstallation\n\nGenerate the JSON report\n\nHow to interpret the flamegraph\n\nOptimize factory usage\n\nLet’s talk about let\n\nStubbing methods within factories\n\nStubbing member access level\n\nAdditional profiling metrics\n\nTroubleshoot slow feature test\n\nSee what the feature test is doing in the UI\n\nSearch for Capybara::DSL# when using profiling\n\nIdentify slow tests\n\nAvoid repeating expensive actions\n\nIn case you’re stuck\n\nFeature category metadata\n\nTests depending on EE license\n\nTests depending on SaaS\n\nCoverage\n\nSystem / Feature tests\n\nUI testing\n\nExternalized contents\n\nActions\n\nFinders\n\nMatchers\n\nInteracting with modals\n\nOther useful methods\n\nLive debug\n\nRun :js spec in a visible browser\n\nScreenshots\n\nFast unit tests\n\nMaintaining fast_spec_helper specs\n\nsubject and let variables\n\nCommon test setup\n\nTime-sensitive tests\n\nRSpec helpers\n\nFeature flags in tests\n\nPristine test environments\n\nSQL database\n\nTestProf in migration specs\n\nRedis\n\nBackground jobs / Sidekiq\n\nDNS\n\nRate Limiting\n\nStubbing File methods\n\nFile system\n\nPersistent in-memory application state\n\nElasticsearch specs\n\nTest Snowplow events\n\nTest Snowplow context against the schema\n\nTable-based / Parameterized tests\n\nPrometheus tests\n\nMatchers\n\nbe_like_time\n\nhave_gitlab_http_status\n\nmatch_schema and match_response_schema\n\nbe_valid_json\n\nbe_one_of(collection)\n\nTesting query performance\n\nQueryRecorder\n\nGitalyClient\n\nShared contexts\n\nShared examples\n\nHelpers\n\nTesting Ruby constants\n\nFactories\n\nFixtures\n\nRepositories\n\nConfiguration\n\nTest environment logging\n\nTesting best practices\n\nTest Design\n\nTesting at GitLab is a first class citizen, not an afterthought. It’s important we consider the design of our tests as we do the design of our features.\n\nWhen implementing a feature, we think about developing the right capabilities the right way. This helps us narrow our scope to a manageable level. When implementing tests for a feature, we must think about developing the right tests, but then cover all the important ways the test may fail. This can quickly widen our scope to a level that is difficult to manage.\n\nTest heuristics can help solve this problem. They concisely address many of the common ways bugs manifest themselves in our code. When designing our tests, take time to review known test heuristics to inform our test design. We can find some helpful heuristics documented in the Handbook in the Test Engineering section.\n\nRSpec\n\nTo run RSpec tests:\n\nUse Guard to continuously monitor for changes and only run matching tests:\n\nWhen using spring and guard together, use SPRING=1 bundle exec guard instead to make use of spring.\n\nGeneral guidelines\n\nUse a single, top-level RSpec.describe ClassName block.\n\nUse .method to describe class methods and #method to describe instance methods.\n\nUse context to test branching logic (RSpec/AvoidConditionalStatements RuboCop Cop - MR).\n\nTry to match the ordering of tests to the ordering in the class.\n\nTry to follow the Four-Phase Test pattern, using newlines to separate phases.\n\nUse Gitlab.config.gitlab.host rather than hard coding 'localhost'.\n\nFor literal URLs in tests, use example.com, gitlab.example.com. This will ensure that we do not utilize any real URLs.\n\nDon’t assert against the absolute value of a sequence-generated attribute (see Gotchas).\n\nAvoid using expect_any_instance_of or allow_any_instance_of (see Gotchas).\n\nDon’t supply the :each argument to hooks because it’s the default.\n\nOn before and after hooks, prefer it scoped to :context over :all.\n\nWhen using evaluate_script(\"$('.js-foo').testSomething()\") (or execute_script) which acts on a given element, use a Capybara matcher beforehand (such as find('.js-foo')) to ensure the element actually exists.\n\nUse focus: true to isolate parts of the specs you want to run.\n\nUse :aggregate_failures when there is more than one expectation in a test.\n\nFor empty test description blocks, use specify rather than it do if the test is self-explanatory.\n\nUse non_existing_record_id/non_existing_record_iid/non_existing_record_access_level when you need an ID/IID/access level that doesn’t actually exist. Using 123, 1234, or even 999 is brittle as these IDs could actually exist in the database in the context of a CI run.\n\nEager loading the application code\n\nBy default, the application code:\n\nIsn’t eagerly loaded in the test environment.\n\nIs eagerly loaded in CI/CD (when ENV['CI'].present?) to surface any potential loading issues.\n\nIf you need to enable eager loading when executing tests, use the GITLAB_TEST_EAGER_LOAD environment variable:\n\nIf your test depends on all the application code that is being loaded, add the :eager_load tag. This ensures that the application code is eagerly loaded before the test execution.\n\nRuby warnings\n\nWe’ve enabled deprecation warnings by default when running specs. Making these warnings more visible to developers helps upgrading to newer Ruby versions.\n\nYou can silence deprecation warnings by setting the environment variable SILENCE_DEPRECATIONS, for example:\n\nTest order\n\nAll new spec files are run in random order to surface flaky tests that are dependent on test order.\n\nWhen randomized:\n\nThe string # order random is added below the example group description.\n\nThe used seed is shown in the spec output below the test suite summary. For example, Randomized with seed 27443.\n\nFor a list of spec files which are still run in defined order, see rspec_order_todo.yml.\n\nTo make spec files run in random order, check their order dependency with:\n\nIf the specs pass the check the script removes them from rspec_order_todo.yml automatically.\n\nIf the specs fail the check they must be fixed before than can run in random order.\n\nTest flakiness\n\nConsult the Unhealthy tests page for more information about processes that are in place to avoid flaky tests.\n\nTest slowness\n\nGitLab has a massive test suite that, without parallelization, can take hours to run. It’s important that we make an effort to write tests that are accurate and effective as well as fast.\n\nTest performance is important to maintaining quality and velocity, and has a direct impact on CI build times and thus fixed costs. We want thorough, correct, and fast tests. Here you can find some information about tools and techniques available to you to achieve that.\n\nConsult the Unhealthy tests page for more information about processes that are in place to avoid slow tests.\n\nDon’t request capabilities you don’t need\n\nWe make it easy to add capabilities to our examples by annotating the example or a parent context. Examples of these are:\n\n:js in feature specs, which runs a full JavaScript capable headless browser.\n\n:clean_gitlab_redis_cache which provides a clean Redis cache to the examples.\n\n:request_store which provides a request store to the examples.\n\nWe should reduce test dependencies, and avoiding capabilities also reduces the amount of set-up needed.\n\n:js is particularly important to avoid. This must only be used if the feature test requires JavaScript reactivity in the browser (for example, clicking a Vue.js component). Using a headless browser is much slower than parsing the HTML response from the app.\n\nProfiling: see where your test spend its time\n\nrspec-stackprof can be used to generate a flame graph that shows you where you test spend its time.\n\nThe gem generates a JSON report that we can upload to https://www.speedscope.app for an interactive visualization.\n\nInstallation\n\nstackprof gem is already installed with GitLab, and we also have a script available that generates the JSON report (bin/rspec-stackprof).\n\nGenerate the JSON report\n\nHow to interpret the flamegraph\n\nBelow are some useful tips to interpret and navigate the flamegraph:\n\nThere are several views available for the flamegraph. Left Heavy is particularly useful when there are a lot of function calls (for example, feature specs).\n\nYou can zoom in or out! See the navigation documentation\n\nIf you are working on a slow feature test, search for Capybara::DSL# in the search to see the capybara actions that are made, and how long they take!\n\nSee #414929 or #375004 for some analysis examples.\n\nOptimize factory usage\n\nA common cause of slow tests is excessive creation of objects, and thus computation and DB time. Factories are essential to development, but they can make inserting data into the DB so easy that we may be able to optimize.\n\nThe two basic techniques to bear in mind here are:\n\nReduce: avoid creating objects, and avoid persisting them.\n\nReuse: shared objects, especially nested ones we do not examine, can generally be shared.\n\nTo avoid creation, it is worth bearing in mind that:\n\ninstance_double and spy are faster than FactoryBot.build(...).\n\nFactoryBot.build(...) and .build_stubbed are faster than .create.\n\nDon’t create an object when you can use build, build_stubbed, attributes_for, spy, or instance_double. Database persistence is slow!\n\nUse Factory Doctor to find cases where database persistence is not needed in a given test.\n\nExamples of factories optimization 1, 2.\n\nA common change is to use build or build_stubbed instead of create:\n\nFactory Profiler can help to identify repetitive database persistence via factories.\n\nA common cause of a large number of created factories is factory cascades, which result when factories create and recreate associations. They can be identified by a noticeable difference between total time and top-level time numbers:\n\nThe table above shows us that we never create any namespace objects explicitly (top-level == 0) - they are all created implicitly for us. But we still end up with 208 of them (one for each project) and this takes 9.5 seconds.\n\nIn order to reuse a single object for all calls to a named factory in implicit parent associations, FactoryDefault can be used:\n\nThen every project we create uses this namespace, without us having to pass it as namespace: namespace. In order to make it work along with let_it_be, factory_default: :keep must be explicitly specified. That keeps the default factory for every example in a suite instead of recreating it for each example.\n\nTo prevent accidental reliance between test examples, objects created with create_default are frozen.\n\nMaybe we don’t need to create 208 different projects - we can create one and reuse it. In addition, we can see that only about 1/3 of the projects we create are ones we ask for (76/208). There is benefit in setting a default value for projects as well:\n\nIn this case, the total time and top-level time numbers match more closely:\n\nLet’s talk about let\n\nThere are various ways to create objects and store them in variables in your tests. They are, from least efficient to most efficient:\n\nlet! creates the object before each example runs. It also creates a new object for every example. You should only use this option if you need to create a clean object before each example without explicitly referring to it.\n\nlet lazily creates the object. It isn’t created until the object is called. let is generally inefficient as it creates a new object for every example. let is fine for simple values. However, more efficient variants of let are best when dealing with database models such as factories.\n\nlet_it_be_with_refind works similar to let_it_be_with_reload, but the former calls ActiveRecord::Base#find instead of ActiveRecord::Base#reload. reload is usually faster than refind.\n\nlet_it_be_with_reload creates an object one time for all examples in the same context, but after each example, the database changes are rolled back, and object.reload will be called to restore the object to its original state. This means you can make changes to the object before or during an example. However, there are cases where state leaks across other models can occur. In these cases, let may be an easier option, especially if only a few examples exist.\n\nlet_it_be creates an object one time for all of the examples in the same context. This is a great alternative to let and let! for objects that do not need to change from one example to another. Using let_it_be can dramatically speed up tests that create database models. See https://github.com/test-prof/test-prof/blob/master/docs/recipes/let_it_be.md#let-it-be for more details and examples.\n\nPro-tip: When writing tests, it is best to consider the objects inside a let_it_be as immutable, as there are some important caveats when modifying objects inside a let_it_be declaration (1, 2). To make your let_it_be objects immutable, consider using freeze: true:\n\nSee https://github.com/test-prof/test-prof/blob/master/docs/recipes/let_it_be.md#state-leakage-detection for more information on let_it_be freezing.\n\nlet_it_be is the most optimized option since it instantiates an object once and shares its instance across examples. If you find yourself needing let instead of let_it_be, try let_it_be_with_reload.\n\nHere is an example of when let_it_be cannot be used, but let_it_be_with_reload allows for more efficiency than let:\n\nStubbing methods within factories\n\nYou should avoid using allow(object).to receive(:method) in factories, as this makes the factory unable to be used with let_it_be, as described in common test setup.\n\nInstead, you can use stub_method to stub the method:\n\nstub_method does not support method existence and method arity checks.\n\nStubbing member access level\n\nTo stub member access level for factory stubs like Project or Group use stub_member_access_level:\n\nAdditional profiling metrics\n\nWe can use the rspec_profiling gem to diagnose, for instance, the number of SQL queries we’re making when running a test.\n\nThis could be caused by some application side SQL queries triggered by a test that could mock parts that are not under test (for example, !123810).\n\nSee the instructions in the performance docs.\n\nTroubleshoot slow feature test\n\nA slow feature test can generally be optimized the same way as any other test. However, there are some specific techniques that can make the troubleshooting session more fruitful.\n\nSee what the feature test is doing in the UI\n\nSee Run :js spec in a visible browser for more info.\n\nSearch for Capybara::DSL# when using profiling\n\nWhen using stackprof flamegraphs, search for Capybara::DSL# in the search to see the capybara actions that are made, and how long they take!\n\nIdentify slow tests\n\nRunning a spec with profiling is a good way to start optimizing a spec. This can be done with:\n\nWhich includes information like the following:\n\nFrom this result, we can see the most expensive examples in our spec, giving us a place to start. The most expensive examples here are in shared examples; any reductions generally have a larger impact as they are called in multiple places.\n\nAvoid repeating expensive actions\n\nWhile isolated examples are very clear, and help serve the purpose of specs as specification, the following example shows how we can combine expensive actions:\n\nIf the call to subject.execute is expensive, then we are repeating the same action just to make different assertions. We can reduce this repetition by combining the examples:\n\nBe careful doing this, as this sacrifices clarity and test independence for performance gains.\n\nWhen combining tests, consider using :aggregate_failures, so that the full results are available, and not just the first failure.\n\nIn case you’re stuck\n\nWe have a backend_testing_performance domain expertise to list people that could help refactor slow backend specs.\n\nTo find people that could help, search for backend testing performance on the Engineering Projects page, or look directly in the www-gitlab-org project.\n\nFeature category metadata\n\nYou must set feature category metadata for each RSpec example.\n\nTests depending on EE license\n\nYou can use if: Gitlab.ee? or unless: Gitlab.ee? on context/spec blocks to execute tests depending on whether running with FOSS_ONLY=1.\n\nExample: SchemaValidator reads a different path depending on the license\n\nTests depending on SaaS\n\nYou can use the :saas RSpec metadata tag helper on context/spec blocks to test code that only runs on GitLab.com. This helper sets Gitlab.config.gitlab['url'] to Gitlab::Saas.com_url.\n\nCoverage\n\nsimplecov is used to generate code test coverage reports. These are generated automatically on the CI, but not when running tests locally. To generate partial reports when you run a spec file on your machine, set the SIMPLECOV environment variable:\n\nCoverage reports are generated into the coverage folder in the app root, and you can open these in your browser, for example:\n\nUse the coverage reports to ensure your tests cover 100% of your code.\n\nSystem / Feature tests\n\nFeature specs should be named ROLE_ACTION_spec.rb, such as user_changes_password_spec.rb.\n\nUse scenario titles that describe the success and failure paths.\n\nAvoid scenario titles that add no information, such as “successfully”.\n\nAvoid scenario titles that repeat the feature title.\n\nCreate only the necessary records in the database\n\nTest a happy path and a less happy path but that’s it\n\nEvery other possible path should be tested with Unit or Integration tests\n\nTest what’s displayed on the page, not the internals of ActiveRecord models. For instance, if you want to verify that a record was created, add expectations that its attributes are displayed on the page, not that Model.count increased by one.\n\nIt’s ok to look for DOM elements, but don’t abuse it, because it makes the tests more brittle\n\nUI testing\n\nWhen testing the UI, write tests that simulate what a user sees and how they interact with the UI. This means preferring Capybara’s semantic methods and avoiding querying by IDs, classes, or attributes.\n\nThe benefits of testing in this way are that:\n\nIt ensures all interactive elements have an accessible name.\n\nIt is more readable, as it uses more natural language.\n\nIt is less brittle, as it avoids querying by IDs, classes, and attributes, which are not visible to the user.\n\nWe strongly recommend that you query by the element’s text label instead of by ID, class name, or data-testid.\n\nIf needed, you can scope interactions within a specific area of the page by using within. As you will likely be scoping to an element such as a div, which typically does not have a label, you may use a data-testid selector in this case.\n\nYou can use the be_axe_clean matcher to run axe automated accessibility testing in feature tests.\n\nExternalized contents\n\nFor RSpec tests, expectations against externalized contents should call the same externalizing method to match the translation. For example, you should use the _ method in Ruby.\n\nSee Internationalization for GitLab - Test files (RSpec) for details.\n\nActions\n\nWhere possible, use more specific actions, such as the ones below.\n\nFinders\n\nWhere possible, use more specific finders, such as the ones below.\n\nMatchers\n\nWhere possible, use more specific matchers, such as the ones below.\n\nInteracting with modals\n\nUse the within_modal helper to interact with GitLab UI modals.\n\nFurthermore, you can use accept_gl_confirm for confirmation modals that only need to be accepted. This is helpful when migrating window.confirm() to confirmAction.\n\nYou can also pass the expected confirmation message and button text to accept_gl_confirm.\n\nOther useful methods\n\nAfter you retrieve an element using a finder method, you can invoke a number of element methods on it, such as hover.\n\nCapybara tests also have a number of session methods available, such as accept_confirm.\n\nSome other useful methods are shown below:\n\nYou can also find a number of GitLab custom helpers in the spec/support/helpers/ directory.\n\nLive debug\n\nSometimes you may need to debug Capybara tests by observing browser behavior.\n\nYou can pause Capybara and view the website on the browser by using the live_debug method in your spec. The current page is automatically opened in your default browser. You may need to sign in first (the current user’s credentials are displayed in the terminal).\n\nTo resume the test run, press any key.\n\nFor example:\n\nlive_debug only works on JavaScript enabled specs.\n\nRun :js spec in a visible browser\n\nRun the spec with WEBDRIVER_HEADLESS=0, like this:\n\nThe test completes quickly, but this gives you an idea of what’s happening. Using live_debug with WEBDRIVER_HEADLESS=0 pauses the open browser, and does not open the page again. This can be used to debug and inspect elements.\n\nYou can also add byebug or binding.pry to pause execution and step through the test.\n\nScreenshots\n\nWe use the capybara-screenshot gem to automatically take a screenshot on failure. In CI you can download these files as job artifacts.\n\nAlso, you can manually take screenshots at any point in a test by adding the methods below. Be sure to remove them when they are no longer needed! See https://github.com/mattheworiordan/capybara-screenshot#manual-screenshots for more.\n\nAdd screenshot_and_save_page in a :js spec to screenshot what Capybara “sees”, and save the page source.\n\nAdd screenshot_and_open_image in a :js spec to screenshot what Capybara “sees”, and automatically open the image.\n\nThe HTML dumps created by this are missing CSS. This results in them looking very different from the actual application. There is a small hack to add CSS which makes debugging easier.\n\nFast unit tests\n\nSome classes are well-isolated from Rails. You should be able to test them without the overhead added by the Rails environment and Bundler’s :default group’s gem loading. In these cases, you can require 'fast_spec_helper' instead of require 'spec_helper' in your test file, and your test should run really fast because:\n\nGem loading is skipped\n\nRails app boot is skipped\n\nGitLab Shell and Gitaly setup are skipped\n\nTest repositories setup are skipped\n\nIt takes around one second to load tests that are using fast_spec_helper instead of 30+ seconds in case of a regular spec_helper.\n\nfast_spec_helper also support autoloading classes that are located inside the lib/ directory. If your class or module is using only code from the lib/ directory, you don’t need to explicitly load any dependencies. fast_spec_helper also loads all ActiveSupport extensions, including core extensions that are commonly used in the Rails environment.\n\nNote that in some cases, you might still have to load some dependencies using require_dependency when a code is using gems or a dependency is not located in lib/.\n\nFor example, if you want to test your code that is calling the Gitlab::UntrustedRegexp class, which under the hood uses re2 library, you should either:\n\nAdd require_dependency 're2' to files in your library that need re2 gem, to make this requirement explicit. This approach is preferred.\n\nAdd it to the spec itself.\n\nAlternately, if it is a dependency which is required by many different fast_spec_helper specs in your domain, and you don’t want to have to manually add the dependency many times, you can add it to be called directly from fast_spec_helper itself. To do this, you can create a spec/support/fast_spec/YOUR_DOMAIN/fast_spec_helper_support.rb file, and require it from fast_spec_helper. There are existing examples of this you can follow.\n\nUse rubocop_spec_helper for RuboCop related specs.\n\nMaintaining fast_spec_helper specs\n\nThere is a utility script scripts/run-fast-specs.sh which can be used to run all specs which use fast_spec_helper, in various ways. This script is useful to help identify fast_spec_helper specs which have problems, such as not running successfully in isolation. See the script for more details.\n\nsubject and let variables\n\nThe GitLab RSpec suite has made extensive use of let(along with its strict, non-lazy version let!) variables to reduce duplication. However, this sometimes comes at the cost of clarity, so we need to set some guidelines for their use going forward:\n\nlet! variables are preferable to instance variables. let variables are preferable to let! variables. Local variables are preferable to let variables.\n\nUse let to reduce duplication throughout an entire spec file.\n\nDon’t use let to define variables used by a single test; define them as local variables inside the test’s it block.\n\nDon’t define a let variable inside the top-level describe block that’s only used in a more deeply-nested context or describe block. Keep the definition as close as possible to where it’s used.\n\nTry to avoid overriding the definition of one let variable with another.\n\nDon’t define a let variable that’s only used by the definition of another. Use a helper method instead.\n\nlet! variables should be used only in case if strict evaluation with defined order is required, otherwise let suffices. Remember that let is lazy and won’t be evaluated until it is referenced.\n\nAvoid referencing subject in examples. Use a named subject subject(:name), or a let variable instead, so the variable has a contextual name.\n\nIf the subject is never referenced inside examples, then it’s acceptable to define the subject without a name.\n\nCommon test setup\n\nIn some cases, there is no need to recreate the same object for tests again for each example. For example, a project and a guest of that project are needed to test issues on the same project, so one project and user are enough for the entire file.\n\nAs much as possible, do not implement this using before(:all) or before(:context). If you do, you would need to manually clean up the data as those hooks run outside a database transaction.\n\nInstead, this can be achieved by using let_it_be variables and the before_all hook from the test-prof gem.\n\nThis results in only one Project, User, and ProjectMember created for this context.\n\nlet_it_be and before_all are also available in nested contexts. Cleanup after the context is handled automatically using a transaction rollback.\n\nNote that if you modify an object defined inside a let_it_be block, then you must do one of the following:\n\nReload the object as needed.\n\nUse the let_it_be_with_reload alias.\n\nSpecify the reload option to reload for every example.\n\nYou can also use the let_it_be_with_refind alias, or specify the refind option as well to completely load a new object.\n\nNote that let_it_be cannot be used with factories that has stubs, such as allow. The reason is that let_it_be happens in a before(:all) block, and RSpec does not allow stubs in before(:all). See this issue for more details. To resolve, use let, or change the factory to not use stubs.\n\nTime-sensitive tests\n\nActiveSupport::Testing::TimeHelpers can be used to verify things that are time-sensitive. Any test that exercises or verifies something time-sensitive should make use of these helpers to prevent transient test failures.\n\nExample:\n\nRSpec helpers\n\nYou can use the :freeze_time and :time_travel_to RSpec metadata tag helpers to help reduce the amount of boilerplate code needed to wrap entire specs with the ActiveSupport::Testing::TimeHelpers methods.\n\nUnder the hood, these helpers use the around(:each) hook and the block syntax of the ActiveSupport::Testing::TimeHelpers methods:\n\nRemember that any objects created before the examples run (such as objects created via let_it_be) will be outside spec scope. If the time for everything needs to be frozen, before :all can be used to encapsulate the setup as well.\n\nActive Record timestamps are set by the Rails’ ActiveRecord::Timestamp module using Time.now. Time precision is OS-dependent, and as the docs state, may include fractional seconds.\n\nWhen Rails models are saved to the database, any timestamps they have are stored using a type in PostgreSQL called timestamp without time zone, which has microsecond resolution—i.e., six digits after the decimal. So if 1577987974.6472975 is sent to PostgreSQL, it truncates the last digit of the fractional part and instead saves 1577987974.647297.\n\nThe results of this can be a simple test like:\n\nFailing with an error along the lines of:\n\nThe fix is to ensure we .reload the object from the database to get the timestamp with correct precision:\n\nThis explanation was taken from a blog post by Maciek Rząsa.\n\nYou can see a merge request where this problem arose and the backend pairing session where it was discussed.\n\nFeature flags in tests\n\nThis section was moved to developing with feature flags.\n\nPristine test environments\n\nThe code exercised by a single GitLab test may access and modify many items of data. Without careful preparation before a test runs, and cleanup afterward, a test can change data in a way that affects the behavior of following tests. This should be avoided at all costs! Fortunately, the existing test framework handles most cases already.\n\nWhen the test environment does get polluted, a common outcome is flaky tests. Pollution often manifests as an order dependency: running spec A followed by spec B reliably fails, but running spec B followed by spec A reliably succeeds. In these cases, you can use rspec --bisect (or a manual pairwise bisect of spec files) to determine which spec is at fault. Fixing the problem requires some understanding of how the test suite ensures the environment is pristine. Read on to discover more about each data store!\n\nSQL database\n\nThis is managed for us by the database_cleaner gem. Each spec is surrounded in a transaction, which is rolled back after the test completes. Certain specs instead issue DELETE FROM queries against every table after completion. This allows the created rows to be viewed from multiple database connections, which is important for specs that run in a browser, or migration specs, among others.\n\nOne consequence of using these strategies, instead of the well-known TRUNCATE TABLES approach, is that primary keys and other sequences are not reset across specs. So if you create a project in spec A, then create a project in spec B, the first has id=1, while the second has id=2.\n\nThis means that specs should never rely on the value of an ID, or any other sequence-generated column. To avoid accidental conflicts, specs should also avoid manually specifying any values in these kinds of columns. Instead, leave them unspecified, and look up the value after the row is created.\n\nTestProf in migration specs\n\nBecause of what is described above, migration specs can’t be run inside a database transaction. Our test suite uses TestProf to improve the runtime of the test suite, but TestProf uses database transactions to perform these optimizations. For this reason, we can’t use TestProf methods in our migration specs. These are the methods that should not be used and should be replaced with default RSpec methods instead:\n\nlet_it_be: use let or let! instead.\n\nlet_it_be_with_reload: use let or let! instead.\n\nlet_it_be_with_refind: use let or let! instead.\n\nbefore_all: use before or before(:all) instead.\n\nRedis\n\nGitLab stores two main categories of data in Redis: cached items, and Sidekiq jobs. View the full list of Gitlab::Redis::Wrapper descendants that are backed by a separate Redis instance.\n\nIn most specs, the Rails cache is actually an in-memory store. This is replaced between specs, so calls to Rails.cache.read and Rails.cache.write are safe. However, if a spec makes direct Redis calls, it should mark itself with the :clean_gitlab_redis_cache, :clean_gitlab_redis_shared_state or :clean_gitlab_redis_queues traits as appropriate.\n\nBackground jobs / Sidekiq\n\nBy default, Sidekiq jobs are enqueued into a jobs array and aren’t processed. If a test queues Sidekiq jobs and need them to be processed, the :sidekiq_inline trait can be used.\n\nThe :sidekiq_might_not_need_inline trait was added when Sidekiq inline mode was changed to fake mode to all the tests that needed Sidekiq to actually process jobs. Tests with this trait should be either fixed to not rely on Sidekiq processing jobs, or their :sidekiq_might_not_need_inline trait should be updated to :sidekiq_inline if the processing of background jobs is needed/expected.\n\nThe usage of perform_enqueued_jobs is useful only for testing delayed mail deliveries, because our Sidekiq workers aren’t inheriting from ApplicationJob / ActiveJob::Base.\n\nDNS\n\nDNS requests are stubbed universally in the test suite (as of !22368), as DNS can cause issues depending on the developer’s local network. There are RSpec labels available in spec/support/dns.rb which you can apply to tests if you need to bypass the DNS stubbing, like this:\n\nAnd if you need more specific control, the DNS blocking is implemented in spec/support/helpers/dns_helpers.rb and these methods can be called elsewhere.\n\nRate Limiting\n\nRate limiting is enabled in the test suite. Rate limits may be triggered in feature specs that use the :js trait. In most cases, triggering rate limiting can be avoided by marking the spec with the :clean_gitlab_redis_rate_limiting trait. This trait clears the rate limiting data stored in Redis cache between specs. If a single test triggers the rate limit, the :disable_rate_limit can be used instead.\n\nStubbing File methods\n\nIn the situations where you need to stub the contents of a file use the stub_file_read, and expect_file_read helper methods which handle the stubbing for File.read correctly. These methods stub File.read for the given filename, and also stub File.exist? to return true.\n\nIf you need to manually stub File.read for any reason be sure to:\n\nStub and call the original implementation for other file paths.\n\nThen stub File.read for only the file path you are interested in.\n\nOtherwise File.read calls from other parts of the codebase get stubbed incorrectly.\n\nFile system\n\nFile system data can be roughly split into “repositories”, and “everything else”. Repositories are stored in tmp/tests/repositories. This directory is emptied before a test run starts, and after the test run ends. It is not emptied between specs, so created repositories accumulate in this directory over the lifetime of the process. Deleting them is expensive, but this could lead to pollution unless carefully managed.\n\nTo avoid this, hashed storage is enabled in the test suite. This means that repositories are given a unique path that depends on their project’s ID. Because the project IDs are not reset between specs, each spec gets its own repository on disk, and prevents changes from being visible between specs.\n\nIf a spec manually specifies a project ID, or inspects the state of the tmp/tests/repositories/ directory directly, then it should clean up the directory both before and after it runs. In general, these patterns should be completely avoided.\n\nOther classes of file linked to database objects, such as uploads, are generally managed in the same way. With hashed storage enabled in the specs, they are written to disk in locations determined by ID, so conflicts should not occur.\n\nSome specs disable hashed storage by passing the :legacy_storage trait to the projects factory. Specs that do this must never override the path of the project, or any of its groups. The default path includes the project ID, so it does not conflict. If two specs create a :legacy_storage project with the same path, they use the same repository on disk and lead to test environment pollution.\n\nOther files must be managed manually by the spec. If you run code that creates a tmp/test-file.csv file, for instance, the spec must ensure that the file is removed as part of cleanup.\n\nPersistent in-memory application state\n\nAll the specs in a given rspec run share the same Ruby process, which means they can affect each other by modifying Ruby objects that are accessible between specs. In practice, this means global variables, and constants (which includes Ruby classes, modules, etc).\n\nGlobal variables should generally not be modified. If absolutely necessary, a block like this can be used to ensure the change is rolled back afterwards:\n\nIf a spec needs to modify a constant, it should use the stub_const helper to ensure the change is rolled back.\n\nIf you need to modify the contents of the ENV constant, you can use the stub_env helper method instead.\n\nWhile most Ruby instances are not shared between specs, classes and modules generally are. Class and module instance variables, accessors, class variables, and other stateful idioms, should be treated in the same way as global variables. Don’t modify them unless you have to! In particular, prefer using expectations, or dependency injection along with stubs, to avoid the need for modifications. If you have no other choice, an around block like the global variables example can be used, but avoid this if at all possible.\n\nElasticsearch specs\n\nSpecs that require Elasticsearch must be marked with the :elastic trait. This creates and deletes indices before and after all examples.\n\nThe :elastic_delete_by_query trait was added to reduce runtime for pipelines by creating and deleting indices at the start and end of each context only. The Elasticsearch delete by query API is used to delete data in all indices (except the migrations index) between examples to ensure a clean index.\n\nThe :elastic_clean trait creates and deletes indices between examples to ensure a clean index. This way, tests are not polluted with non-essential data. If using the :elastic or :elastic_delete_by_query trait is causing issues, use :elastic_clean instead. :elastic_clean is significantly slower than the other traits and should be used sparingly.\n\nMost tests for Elasticsearch logic relate to:\n\nCreating data in PostgreSQL and waiting for it to be indexed in Elasticsearch.\n\nSearching for that data.\n\nEnsuring that the test gives the expected result.\n\nThere are some exceptions, such as checking for structural changes rather than individual records in an index.\n\nSpecs using Elasticsearch require that you:\n\nCreate data in PostgreSQL and then index it into Elasticsearch.\n\nEnable Application Settings for Elasticsearch (which is disabled by default).\n\nTo do so, use:\n\nAdditionally, you can use the ensure_elasticsearch_index! method to overcome the asynchronous nature of Elasticsearch. It uses the Elasticsearch Refresh API to make sure all operations performed on an index since the last refresh are available for search. This method is typically called after loading data into PostgreSQL to ensure the data is indexed and searchable.\n\nYou can use the SEARCH_SPEC_BENCHMARK environment variable to benchmark test setup steps:\n\nTest Snowplow events\n\nTo catch runtime errors due to type checks you can use expect_snowplow_event, which checks for calls to Gitlab::Tracking#event.\n\nWhen you want to ensure that no event got called, you can use expect_no_snowplow_event.\n\nEven though category and action can be omitted, you should at least specify a category to avoid flaky tests. For example, Users::ActivityService may track a Snowplow event after an API request, and expect_no_snowplow_event will fail if that happens to run when no arguments are specified.\n\nTest Snowplow context against the schema\n\nThe Snowplow schema matcher helps to reduce validation errors by testing Snowplow context against the JSON schema. The schema matcher accepts the following parameters:\n\nschema path\n\ncontext\n\nTo add a schema matcher spec:\n\nAdd a new schema to the Iglu repository, then copy the same schema to the spec/fixtures/product_intelligence/ directory.\n\nIn the copied schema, remove the \"$schema\" key and value. We do not need it for specs and the spec fails if we keep the key, as it tries to look for the schema in the URL.\n\nUse the following snippet to call the schema matcher:\n\nmatch_snowplow_context_schema(schema_path: '<filename from step 1>', context: <Context Hash> )\n\nTable-based / Parameterized tests\n\nThis style of testing is used to exercise one piece of code with a comprehensive range of inputs. By specifying the test case once, alongside a table of inputs and the expected output for each, your tests can be made easier to read and more compact.\n\nWe use the RSpec::Parameterized gem. A short example, using the table syntax and checking Ruby equality for a range of inputs, might look like this:\n\nIf, after creating a table-based test, you see an error that looks like this:\n\nThat indicates that you need to include the line using RSpec::Parameterized::TableSyntax in the spec file.\n\nPrometheus tests\n\nPrometheus metrics may be preserved from one test run to another. To ensure that metrics are reset before each example, add the :prometheus tag to the RSpec test.\n\nMatchers\n\nCustom matchers should be created to clarify the intent and/or hide the complexity of RSpec expectations. They should be placed under spec/support/matchers/. Matchers can be placed in subfolder if they apply to a certain type of specs only (such as features or requests) but shouldn’t be if they apply to multiple type of specs.\n\nbe_like_time\n\nTime returned from a database can differ in precision from time objects in Ruby, so we need flexible tolerances when comparing in specs.\n\nThe PostgreSQL time and timestamp types have the resolution of 1 microsecond. However, the precision of Ruby Time can vary depending on the OS.\n\nConsider the following snippet:\n\nOn Linux, Time can have the maximum precision of 9 and project.created_at has a value (like 2023-04-28 05:53:30.808033064) with the same precision. However, the actual value created_at (like 2023-04-28 05:53:30.808033) stored to and loaded from the database doesn’t have the same precision, and the match would fail. On macOS X, the precision of Time matches that of the PostgreSQL timestamp type and the match could succeed.\n\nTo avoid the issue, we can use be_like_time or be_within to compare that times are within one second of each other.\n\nExample:\n\nExample for be_within:\n\nhave_gitlab_http_status\n\nPrefer have_gitlab_http_status over have_http_status and expect(response.status).to because the former could also show the response body whenever the status mismatched. This would be very useful whenever some tests start breaking and we would love to know why without editing the source and rerun the tests.\n\nThis is especially useful whenever it’s showing 500 internal server error.\n\nPrefer named HTTP status like :no_content over its numeric representation 206. See a list of supported status codes.\n\nExample:\n\nmatch_schema and match_response_schema\n\nThe match_schema matcher allows validating that the subject matches a JSON schema. The item inside expect can be a JSON string or a JSON-compatible data structure.\n\nmatch_response_schema is a convenience matcher for using with a response object. from a request spec.\n\nExamples:\n\nbe_valid_json\n\nbe_valid_json allows validating that a string parses as JSON and gives a non-empty result. To combine it with the schema matching above, use and:\n\nbe_one_of(collection)\n\nThe inverse of include, tests that the collection includes the expected value:\n\nTesting query performance\n\nTesting query performance allows us to:\n\nAssert that N+1 problems do not exist in a block of code.\n\nEnsure that the number of queries in a block of code does not increase unnoticed.\n\nQueryRecorder\n\nQueryRecorder allows profiling and testing of the number of database queries performed in a given block of code.\n\nSee the QueryRecorder section for more details.\n\nGitalyClient\n\nGitlab::GitalyClient.get_request_count allows tests of the number of Gitaly queries made by a given block of code:\n\nSee the Gitaly Request Counts section for more details.\n\nShared contexts\n\nShared contexts only used in one spec file can be declared inline. Any shared contexts used by more than one spec file:\n\nShould be placed under spec/support/shared_contexts/.\n\nCan be placed in subfolder if they apply to a certain type of specs only (such as features or requests) but shouldn’t be if they apply to multiple type of specs.\n\nEach file should include only one context and have a descriptive name, such as spec/support/shared_contexts/controllers/githubish_import_controller_shared_context.rb.\n\nShared examples\n\nShared examples only used in one spec file can be declared inline. Any shared examples used by more than one spec file:\n\nShould be placed under spec/support/shared_examples/.\n\nCan be placed in subfolder if they apply to a certain type of specs only (such as features or requests) but shouldn’t be if they apply to multiple type of specs.\n\nEach file should include only one context and have a descriptive name, such as spec/support/shared_examples/controllers/githubish_import_controller_shared_example.rb.\n\nHelpers\n\nHelpers are usually modules that provide some methods to hide the complexity of specific RSpec examples. You can define helpers in RSpec files if they’re not intended to be shared with other specs. Otherwise, they should be placed under spec/support/helpers/. Helpers can be placed in a subfolder if they apply to a certain type of specs only (such as features or requests) but shouldn’t be if they apply to multiple type of specs.\n\nHelpers should follow the Rails naming / namespacing convention, where spec/support/helpers/ is the root. For instance spec/support/helpers/features/iteration_helpers.rb should define:\n\nHelpers should not change the RSpec configuration. For instance, the helpers module described above should not include:\n\nTesting Ruby constants\n\nWhen testing code that uses Ruby constants, focus the test on the behavior that depends on the constant, rather than testing the values of the constant.\n\nFor example, the following is preferred because it tests the behavior of the class method .categories.\n\nOn the other hand, testing the value of the constant itself, often only repeats the values in the code and the test, which provides little value.\n\nIn critical cases where an error on a constant could have a catastrophic impact, testing the constant values might be useful as an added safeguard. For example, if it could bring down the entire GitLab service, cause a customer to be billed more than they should be, or cause the universe to implode.\n\nFactories\n\nGitLab uses factory_bot as a test fixture replacement.\n\nFactory definitions live in spec/factories/, named using the pluralization of their corresponding model (User factories are defined in users.rb).\n\nThere should be only one top-level factory definition per file.\n\nFactoryBot methods are mixed in to all RSpec groups. This means you can (and should) call create(...) instead of FactoryBot.create(...).\n\nMake use of traits to clean up definitions and usages.\n\nWhen defining a factory, don’t define attributes that are not required for the resulting record to pass validation.\n\nWhen instantiating from a factory, don’t supply attributes that aren’t required by the test.\n\nUse implicit, explicit, or inline associations instead of create / build for association setup in callbacks. See issue #262624 for further context.\n\nWhen creating factories with a has_many and belongs_to association, use the instance method to refer to the object being built. This prevents creation of unnecessary records by using interconnected associations.\n\nFor example, if we have the following classes:\n\nclass Car < ApplicationRecord has_many :wheels, inverse_of: :car, foreign_key: :car_id end class Wheel < ApplicationRecord belongs_to :car, foreign_key: :car_id, inverse_of: :wheel, optional: false end\n\nWe can create the following factories:\n\nFactoryBot.define do factory :car do transient do wheels_count { 2 } end wheels do Array.new(wheels_count) do association(:wheel, car: instance) end end end end FactoryBot.define do factory :wheel do car { association :car } end end\n\nFactories don’t have to be limited to ActiveRecord objects. See example.\n\nFactories and their traits should produce valid objects that are verified by shared specs run in every model spec.\n\nAvoid the use of skip_callback in factories. See issue #247865 for details.\n\nFixtures\n\nAll fixtures should be placed under spec/fixtures/.\n\nRepositories\n\nTesting some functionality, such as merging a merge request, requires a Git repository with a certain state to be present in the test environment. GitLab maintains the gitlab-test repository for certain common cases - you can ensure a copy of the repository is used with the :repository trait for project factories:\n\nWhere you can, consider using the :custom_repo trait instead of :repository. This allows you to specify exactly what files appear in the main branch of the project’s repository. For example:\n\nThis creates a repository containing two files, with default permissions and the specified content.\n\nConfiguration\n\nRSpec configuration files are files that change the RSpec configuration (like RSpec.configure do |config| blocks). They should be placed under spec/support/.\n\nEach file should be related to a specific domain, such as spec/support/capybara.rb or spec/support/carrierwave.rb.\n\nIf a helpers module applies only to a certain kind of specs, it should add modifiers to the config.include call. For instance if spec/support/helpers/cycle_analytics_helpers.rb applies to :lib and type: :model specs only, you would write the following:\n\nIf a configuration file only consists of config.include, you can add these config.include directly in spec/spec_helper.rb.\n\nFor very generic helpers, consider including them in the spec/support/rspec.rb file which is used by the spec/fast_spec_helper.rb file. See Fast unit tests for more details about the spec/fast_spec_helper.rb file.\n\nTest environment logging\n\nServices for the test environment are automatically configured and started when tests are run, including Gitaly, Workhorse, Elasticsearch, and Capybara. When run in CI, or if the service needs to be installed, the test environment logs information about set-up time, producing log messages like the following:\n\nThis information is omitted when running locally and when no action needs to be performed. If you would always like to see these messages, set the following environment variable:"
    }
}