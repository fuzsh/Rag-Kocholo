{
    "id": "dbpedia_1582_3",
    "rank": 95,
    "data": {
        "url": "https://www.atlassian.com/incident-management/kpis/common-metrics",
        "read_more_link": "",
        "language": "en",
        "title": "MTBF, MTTR, MTTF, MTTA: Understanding incident metrics",
        "top_image": "https://www.atlassian.com/favicon-32x32.png",
        "meta_img": "https://www.atlassian.com/favicon-32x32.png",
        "images": [
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/AtlassianHeaderLogo.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Confluence.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira-Service-Management.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Trello.svg",
            "https://wac-cdn-bfldr.atlassian.com/K3MHR9G8/at/k5xhw8hpqxghzb55nfktt4/logo-light_Rovo_mark_brand_RGB.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira-Product-Discovery.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Compass.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Guard.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Loom.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Bitbucket.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Compass.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Confluence.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira-Product-Discovery.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira-Service-Management.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Guard.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Confluence.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Trello.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Loom.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira-Align.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Jira.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Confluence.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/prod-icon-Loom.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/nav-software.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/nav-software-hover.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/nav-marketing.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/nav-marketing-hover.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/nav-it.svg",
            "https://wac-cdn.atlassian.com/misc-assets/adg4-nav/nav-it-hover.svg",
            "https://wac-cdn.atlassian.com/dam/jcr:8b30a82b-4ede-499d-9927-34fdf9436dc9/im-handbook.png?cdnVersion=2117",
            "https://wac-cdn.atlassian.com/dam/jcr:f79d6dc8-c6d1-4fec-8673-e0f1850f7987/MTBF-oil-change-example.png?cdnVersion=2117",
            "https://wac-cdn.atlassian.com/dam/jcr:d49617bb-cb4e-46b3-9441-4a86f9d0abe6/MTTF-light-bulb-example.png?cdnVersion=2117",
            "https://wac-cdn.atlassian.com/dam/jcr:52a746c6-4924-43e3-8343-54b1c2f2f28e/tracking-incident-managment.png?cdnVersion=2117",
            "https://wac-cdn.atlassian.com/dam/jcr:84e77dc5-58da-48d6-94ab-c2eb068de8f2/jira%20service%20management-logo-gradient-blue.svg?cdnVersion=2117",
            "https://wac-cdn.atlassian.com/dam/jcr:9c4bf443-5045-4ff9-a48d-36ae466f3ced/logos-atlassian-mini-icon-onecolor-blue.svg?cdnVersion=2117"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "What do MTBF, MTTR, MTTF, and MTTA mean? How are they different? And what do you need to know about them to keep up at work? Find out here.",
        "meta_lang": "en",
        "meta_favicon": "/favicon-16x16.png",
        "meta_site_name": "Atlassian",
        "canonical_link": "https://www.atlassian.com/incident-management/kpis/common-metrics",
        "text": "MTBF, MTTR, MTTA, and MTTF\n\nUnderstanding a few of the most common incident metrics\n\nIn today’s always-on world, outages and technical incidents matter more than ever before. Glitches and downtime come with real consequences. Missed deadlines. Late payments. Project delays.\n\nWhich is why it’s important for companies to quantify and track metrics around uptime, downtime, and how quickly and effectively teams are resolving issues.\n\nSome of the industry’s most commonly tracked metrics are MTBF (mean time before failure), MTTR (mean time to recovery, repair, respond, or resolve), MTTF (mean time to failure), and MTTA (mean time to acknowledge)—a series of metrics designed to help tech teams understand how often incidents occur and how quickly the team bounces back from those incidents.\n\nA lot of experts argue that these metrics aren’t actually that useful on their own because they don’t ask the messier questions of how incidents are resolved, what works and what doesn’t, and how, when, and why issues escalate or deescalate.\n\nOn the other hand, MTTR, MTBF, and MTTF can be a good baseline or benchmark that starts conversations that lead into those deeper, important questions.\n\nHow the pros respond to major incidents\n\nGet our free incident management handbook. Learn all the tools and techniques Atlassian uses to manage major incidents.\n\nA disclaimer about MTTR\n\nWhen we talk about MTTR, it’s easy to assume it’s a single metric with a single meaning. But the truth is it potentially represents four different measurements. The R can stand for repair, recovery, respond, or resolve, and while the four metrics do overlap, they each have their own meaning and nuance.\n\nSo if your team is talking about tracking MTTR, it’s a good idea to clarify which MTTR they mean and how they’re defining it. Before you start tracking successes and failures, your team needs to be on the same page about exactly what you’re tracking and be sure everyone knows they’re talking about the same thing.\n\nMTBF: Mean time between failures\n\nWhat is mean time between failures?\n\nMTBF (mean time between failures) is the average time between repairable failures of a technology product. The metric is used to track both the availability and reliability of a product. The higher the time between failure, the more reliable the system.\n\nThe goal for most companies to keep MTBF as high as possible—putting hundreds of thousands of hours (or even millions) between issues.\n\nHow to calculate mean time between failures\n\nMTBF is calculated using an arithmetic mean. Basically, this means taking the data from the period you want to calculate (perhaps six months, perhaps a year, perhaps five years) and dividing that period’s total operational time by the number of failures.\n\nSo, let’s say we’re assessing a 24-hour period and there were two hours of downtime in two separate incidents. Our total uptime is 22 hours. Divided by two, that’s 11 hours. So our MTBF is 11 hours.\n\nBecause the metric is used to track reliability, MTBF does not factor in expected down time during scheduled maintenance. Instead, it focuses on unexpected outages and issues.\n\nThe origins of mean time between failures\n\nMTBF comes to us from the aviation industry, where system failures mean particularly major consequences not only in terms of cost, but human life as well. The initialism has since made its way across a variety of technical and mechanical industries and is used particularly often in manufacturing.\n\nHow and when to use mean time between failures\n\nMTBF is helpful for buyers who want to make sure they get the most reliable product, fly the most reliable airplane, or choose the safest manufacturing equipment for their plant.\n\nFor internal teams, it’s a metric that helps identify issues and track successes and failures. It can also help companies develop informed recommendations about when customers should replace a part, upgrade a system, or bring a product in for maintenance.\n\nMTBF is a metric for failures in repairable systems. For failures that require system replacement, typically people use the term MTTF (mean time to failure).\n\nFor example, think of a car engine. When calculating the time between unscheduled engine maintenance, you’d use MTBF—mean time between failures. When calculating the time between replacing the full engine, you’d use MTTF (mean time to failure).\n\nMTTR: Mean time to repair\n\nWhat is mean time to repair?\n\nMTTR (mean time to repair) is the average time it takes to repair a system (usually technical or mechanical). It includes both the repair time and any testing time. The clock doesn’t stop on this metric until the system is fully functional again.\n\nHow to calculate mean time to repair\n\nYou can calculate MTTR by adding up the total time spent on repairs during any given period and then dividing that time by the number of repairs.\n\nSo, let’s say we’re looking at repairs over the course of a week. In that time, there were 10 outages and systems were actively being repaired for four hours. Four hours is 240 minutes. 240 divided by 10 is 24. Which means the mean time to repair in this case would be 24 minutes.\n\nThe limitations of mean time to repair\n\nMean time to repair is not always the same amount of time as the system outage itself. In some cases, repairs start within minutes of a product failure or system outage. In other cases, there’s a lag time between the issue, when the issue is detected, and when the repairs begin.\n\nThis metric is most useful when tracking how quickly maintenance staff is able to repair an issue. It’s not meant to identify problems with your system alerts or pre-repair delays—both of which are also important factors when assessing the successes and failures of your incident management programs.\n\nHow and when to use mean time to repair\n\nMTTR is a metric support and maintenance teams use to keep repairs on track. The goal is to get this number as low as possible by increasing the efficiency of repair processes and teams.\n\nMTTR: Mean time to recovery\n\nWhat is mean time to recovery?\n\nMTTR (mean time to recovery or mean time to restore) is the average time it takes to recover from a product or system failure. This includes the full time of the outage—from the time the system or product fails to the time that it becomes fully operational again.\n\nIt's a key DevOps metric that can be used to measure the stability of a DevOps team, as noted by DevOps Research and Assessment (DORA).\n\nHow to calculate mean time to recovery\n\nMean time to recovery is calculated by adding up all the downtime in a specific period and dividing it by the number of incidents. So, let’s say our systems were down for 30 minutes in two separate incidents in a 24-hour period. 30 divided by two is 15, so our MTTR is 15 minutes.\n\nThe limitations of mean time to recovery\n\nThis MTTR is a measure of the speed of your full recovery process. Is it as quick as you want it to be? How does it compare to your competitors?\n\nThis is a high-level metric that helps you identify if you have a problem. However, if you want to diagnose where the problem lies within your process (is it an issue with your alerts system? Is the team taking too long on fixes? Does it take too long for someone to respond to a fix request?), you’ll need more data. Because there’s more than one thing happening between failure and recovery.\n\nThe problem could be with your alert system. Is there a delay between a failure and an alert? Are alerts taking longer than they should to get to the right person?\n\nThe problem could be with diagnostics. Are you able to figure out what the problem is quickly? Are there processes that could be improved?\n\nOr the problem could be with repairs. Are your maintenance teams as effective as they could be? If they’re taking the bulk of the time, what’s tripping them up?\n\nYou’ll need to look deeper than MTTR to answer those questions, but mean time to recovery can provide a starting point for diagnosing whether there’s a problem with your recovery process that requires you to dig deeper.\n\nHow and when to use mean time to recovery\n\nMTTR is a good metric for assessing the speed of your overall recovery process.\n\nMTTR: Mean time to resolve\n\nWhat is mean time to resolve?\n\nMTTR (mean time to resolve) is the average time it takes to fully resolve a failure. This includes not only the time spent detecting the failure, diagnosing the problem, and repairing the issue, but also the time spent ensuring that the failure won’t happen again.\n\nThis metric extends the responsibility of the team handling the fix to improving performance long-term. It’s the difference between putting out a fire and putting out a fire and then fireproofing your house.\n\nThere is a strong correlation between this MTTR and customer satisfaction, so it’s something to sit up and pay attention to.\n\nHow to calculate mean time to resolve\n\nTo calculate this MTTR, add up the full resolution time during the period you want to track and divide by the number of incidents.\n\nSo, if your systems were down for a total of two hours in a 24-hour period in a single incident and teams spent an additional two hours putting fixes in place to ensure the system outage doesn’t happen again, that’s four hours total spent resolving the issue. Which means your MTTR is four hours.\n\nA note about tracking mean time to resolve\n\nKeep in mind that MTTR is most frequently calculated using business hours (so, if you recover from an issue at closing time one day and spend time fixing the underlying issue first thing the next morning, your MTTR wouldn’t include the 16 hours you spent away from the office). If you have teams in multiple locations working around the clock or if you have on-call employees working after hours, it’s important to define how you will track time for this metric.\n\nHow and when to use mean time to resolve\n\nMTTR is typically used when talking about unplanned incidents, not service requests (which are typically planned).\n\nMTTR: Mean time to respond\n\nWhat is mean time to respond?\n\nMTTR (mean time to respond) is the average time it takes to recover from a product or system failure from the time when you are first alerted to that failure. This does not include any lag time in your alert system.\n\nHow to calculate mean time to respond\n\nTo calculate this MTTR, add up the full response time from alert to when the product or service is fully functional again. Then divide by the number of incidents.\n\nFor example: If you had four incidents in a 40-hour workweek and spent one total hour on them (from alert to fix), your MTTR for that week would be 15 minutes.\n\nHow and when to use mean time to respond\n\nThis MTTR is often used in cybersecurity when measuring a team’s success in neutralizing system attacks.\n\nMTTA: Mean time to acknowledge\n\nWhat is mean time between to acknowledge?\n\nMTTA (mean time to acknowledge) is the average time it takes from when an alert is triggered to when work begins on the issue. This metric is useful for tracking your team’s responsiveness and your alert system’s effectiveness.\n\nHow to calculate mean time to acknowledge\n\nTo calculate your MTTA, add up the time between alert and acknowledgement, then divide by the number of incidents.\n\nFor example: If you had 10 incidents and there was a total of 40 minutes of time between alert and acknowledgement for all 10, you divide 40 by 10 and come up with an average of four minutes.\n\nHow and when to use mean time to acknowledge\n\nMTTA is useful in tracking responsiveness. Is your team suffering from alert fatigue and taking too long to respond? This metric will help you flag the issue.\n\nMTTF: Mean time to failure\n\nWhat is mean time to failure?\n\nMTTF (mean time to failure) is the average time between non-repairable failures of a technology product. For example, if Brand X’s car engines average 500,000 hours before they fail completely and have to be replaced, 500,000 would be the engines’ MTTF.\n\nThe calculation is used to understand how long a system will typically last, determine whether a new version of a system is outperforming the old, and give customers information about expected lifetimes and when to schedule check-ups on their system.\n\nHow to calculate mean time to failure\n\nMean time to failure is an arithmetic average, so you calculate it by adding up the total operating time of the products you’re assessing and dividing that total by the number of devices.\n\nFor example: Let’s say you’re figuring out the MTTF of light bulbs. How long do Brand Y’s light bulbs last on average before they burn out? Let’s further say you have a sample of four light bulbs to test (if you want statistically significant data, you’ll need much more than that, but for the purposes of simple math, let’s keep this small).\n\nLight bulb A lasts 20 hours. Light bulb B lasts 18. Bulb C lasts 21. And bulb D lasts 21 hours. That’s a total of 80 bulb hours. Divided by four, the MTTF is 20 hours.\n\nThe problem of mean time to failure\n\nWith an example like light bulbs, MTTF is a metric that makes a lot of sense. We can run the light bulbs until the last one fails and use that information to draw conclusions about the resiliency of our light bulbs.\n\nBut what happens when we’re measuring things that don’t fail quite as quickly? Things meant to last years and years? For those cases, though MTTF is often used, it’s not as good of a metric. Because instead of running a product until it fails, most of the time we’re running a product for a defined length of time and measuring how many fail.\n\nFor example: Let’s say we’re trying to get MTTF stats on Brand Z’s tablets. Tablets, hopefully, are meant to last for many years. But Brand Z might only have six months to gather data. And so they test 100 tablets for six months. Let’s say one tablet fails exactly at the six-month mark.\n\nSo, we multiply the total operating time (six months multiplied by 100 tablets) and come up with 600 months. Only one tablet failed, so we’d divide that by one and our MTTR would be 600 months, which is 50 years.\n\nAre Brand Z’s tablets going to last an average of 50 years each? It’s pretty unlikely. And so the metric breaks down in cases like these.\n\nHow and when to use mean time to failure\n\nMTTF works well when you’re trying to assess the average lifetime of products and systems with a short lifespan (such as light bulbs). It’s also only meant for cases when you’re assessing full product failure. If you’re calculating time in between incidents that require repair, the initialism of choice is MTBF (mean time between failures).\n\nMTBF vs. MTTR vs. MTTF vs. MTTA\n\nSo, which measurement is better when it comes to tracking and improving incident management?\n\nThe answer is all of them.\n\nThough they are sometimes used interchangeably, each metric provides a different insight. When used together, they can tell a more complete story about how successful your team is with incident management and where the team can improve.\n\nMean time to recovery tells you how quickly you can get your systems back up and running.\n\nLayer in mean time to respond and you get a sense for how much of the recovery time belongs to the team and how much is your alert system.\n\nFurther layer in mean time to repair and you start to see how much time the team is spending on repairs vs. diagnostics.\n\nAdd mean time to resolve to the mix and you start to understand the full scope of fixing and resolving issues beyond the actual downtime they cause.\n\nFold in mean time between failures and the picture gets even bigger, showing you how successful your team is at preventing or reducing future issues.\n\nAnd then add mean time to failure to understand the full lifecycle of a product or system."
    }
}