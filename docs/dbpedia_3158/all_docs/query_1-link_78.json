{
    "id": "dbpedia_3158_1",
    "rank": 78,
    "data": {
        "url": "https://apnews.com/article/us-military-ai-projects-0773b4937801e7a0573f44b57a9a5942",
        "read_more_link": "",
        "language": "en",
        "title": "Pentagon’s AI initiatives accelerate hard decisions on lethal autonomous weapons",
        "top_image": "https://dims.apnews.com/dims4/default/af8e62f/2147483647/strip/true/crop/5063x2848+0+264/resize/1440x810!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F65%2Fbf%2F05eefe339b9b2b767f6a77200c0e%2F01a19ae6ec0b451a85cf81f10fc5ff34",
        "meta_img": "https://dims.apnews.com/dims4/default/af8e62f/2147483647/strip/true/crop/5063x2848+0+264/resize/1440x810!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F65%2Fbf%2F05eefe339b9b2b767f6a77200c0e%2F01a19ae6ec0b451a85cf81f10fc5ff34",
        "images": [
            "https://assets.apnews.com/fa/ba/9258a7114f5ba5c7202aaa1bdd66/aplogo.svg",
            "https://dims.apnews.com/dims4/default/94c503b/2147483647/strip/true/crop/640x236+0+0/resize/320x118!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fc3%2F4c%2F65482a7b452db66043542c093eaf%2Fpromo-2x.png 1x,https://dims.apnews.com/dims4/default/6e4b276/2147483647/strip/true/crop/640x236+0+0/resize/640x236!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fc3%2F4c%2F65482a7b452db66043542c093eaf%2Fpromo-2x.png 2x",
            "https://dims.apnews.com/dims4/default/ae6dee1/2147483647/strip/true/crop/5063x3375+0+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F65%2Fbf%2F05eefe339b9b2b767f6a77200c0e%2F01a19ae6ec0b451a85cf81f10fc5ff34 1x,https://dims.apnews.com/dims4/default/049dd88/2147483647/strip/true/crop/5063x3375+0+0/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F65%2Fbf%2F05eefe339b9b2b767f6a77200c0e%2F01a19ae6ec0b451a85cf81f10fc5ff34 2x",
            "https://dims.apnews.com/dims4/default/56ec597/2147483647/strip/true/crop/3575x2384+0+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fd9%2Fbb%2F2221c56971d43cb925c98ae63aef%2Febb13aba87b94710a3d1ee4c11e8e45e 1x,https://dims.apnews.com/dims4/default/95e64a5/2147483647/strip/true/crop/3575x2384+0+0/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fd9%2Fbb%2F2221c56971d43cb925c98ae63aef%2Febb13aba87b94710a3d1ee4c11e8e45e 2x",
            "https://dims.apnews.com/dims4/default/dae6d0e/2147483647/strip/true/crop/4029x2686+0+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F59%2Ffc%2F9c433fa6396cf479a8d5360cf623%2F9bae71175e1f48c6b2e3cdd46dfd3b62 1x,https://dims.apnews.com/dims4/default/dc7e96d/2147483647/strip/true/crop/4029x2686+0+0/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F59%2Ffc%2F9c433fa6396cf479a8d5360cf623%2F9bae71175e1f48c6b2e3cdd46dfd3b62 2x",
            "https://dims.apnews.com/dims4/default/f381fdb/2147483647/strip/true/crop/4365x2910+0+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fc4%2F9ef52f0c2dd72ca7f10e5833ccd6%2Ffc957310ab1d4473bdbed6a8a8e1d1a0 1x,https://dims.apnews.com/dims4/default/c50ed78/2147483647/strip/true/crop/4365x2910+0+0/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fc4%2F9ef52f0c2dd72ca7f10e5833ccd6%2Ffc957310ab1d4473bdbed6a8a8e1d1a0 2x",
            "https://dims.apnews.com/dims4/default/1cdf0c4/2147483647/strip/true/crop/258x258+0+14/resize/60x60!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F43%2Fbf%2F2b4628e64a839c3e0e500955c232%2Ffrank-bajak-portrait-small.jpg 1x,https://dims.apnews.com/dims4/default/fefaee4/2147483647/strip/true/crop/258x258+0+14/resize/120x120!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F43%2Fbf%2F2b4628e64a839c3e0e500955c232%2Ffrank-bajak-portrait-small.jpg 2x",
            "https://dims.apnews.com/dims4/default/c880f09/2147483647/strip/true/crop/1919x1278+1+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F9c%2Ff7%2F7bcbb801b4a1d48dc2fe47f57390%2F1ed503bf4dbd4635a07d7ef4d24e5a2f 1x,https://dims.apnews.com/dims4/default/63d63dd/2147483647/strip/true/crop/1919x1278+1+0/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F9c%2Ff7%2F7bcbb801b4a1d48dc2fe47f57390%2F1ed503bf4dbd4635a07d7ef4d24e5a2f 2x",
            "https://dims.apnews.com/dims4/default/6170197/2147483647/strip/true/crop/2083x1388+0+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F15%2F9e%2Fada729da8de0afcd18bd74cb4f6c%2F7e8dd0d103d44029b1573e873fc1f1a3 1x,https://dims.apnews.com/dims4/default/39866c5/2147483647/strip/true/crop/2083x1388+0+0/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F15%2F9e%2Fada729da8de0afcd18bd74cb4f6c%2F7e8dd0d103d44029b1573e873fc1f1a3 2x",
            "https://dims.apnews.com/dims4/default/ae6dee1/2147483647/strip/true/crop/5063x3375+0+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F65%2Fbf%2F05eefe339b9b2b767f6a77200c0e%2F01a19ae6ec0b451a85cf81f10fc5ff34 1x,https://dims.apnews.com/dims4/default/049dd88/2147483647/strip/true/crop/5063x3375+0+0/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F65%2Fbf%2F05eefe339b9b2b767f6a77200c0e%2F01a19ae6ec0b451a85cf81f10fc5ff34 2x",
            "https://dims.apnews.com/dims4/default/d7d2e36/2147483647/strip/true/crop/258x258+0+14/resize/100x100!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F43%2Fbf%2F2b4628e64a839c3e0e500955c232%2Ffrank-bajak-portrait-small.jpg",
            "https://dims.apnews.com/dims4/default/8650001/2147483647/strip/true/crop/992x617+0+0/resize/225x140!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ffc%2F24%2F7ff11448446fb8500bc984551325%2Faplogo-with-tagline.png 1x,https://dims.apnews.com/dims4/default/6669a9d/2147483647/strip/true/crop/992x617+0+0/resize/450x280!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ffc%2F24%2F7ff11448446fb8500bc984551325%2Faplogo-with-tagline.png 2x",
            "https://sb.scorecardresearch.com/p?c1=2&c2=3005041&cv=4.4.0&cj=1"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Artificial intelligence",
            "Military and defense",
            "Government surveillance",
            "U.S. Department of Defense",
            "General news",
            "AP Top News",
            "Technology",
            "Kathleen Hicks",
            "Business",
            "f",
            "Washington news",
            "Ukraine",
            "a",
            "China",
            "Washington News"
        ],
        "tags": null,
        "authors": [
            "FRANK BAJAK",
            "military AI. twitter",
            "apnews.com",
            "frank-bajak"
        ],
        "publish_date": "2023-11-25T15:49:50+00:00",
        "summary": "",
        "meta_description": "Artificial intelligence employed by the U.S. military has piloted pint-sized surveillance drones in special operations forces’ missions.",
        "meta_lang": "en",
        "meta_favicon": "/apple-touch-icon.png",
        "meta_site_name": "AP News",
        "canonical_link": "https://apnews.com/article/us-military-ai-projects-0773b4937801e7a0573f44b57a9a5942",
        "text": "NATIONAL HARBOR, Md. (AP) — Artificial intelligence employed by the U.S. military has piloted pint-sized surveillance drones in special operations forces’ missions and helped Ukraine in its war against Russia. It tracks soldiers’ fitness, predicts when Air Force planes need maintenance and helps keep tabs on rivals in space.\n\nNow, the Pentagon is intent on fielding multiple thousands of relatively inexpensive, expendable AI-enabled autonomous vehicles by 2026 to keep pace with China. The ambitious initiative — dubbed Replicator — seeks to “galvanize progress in the too-slow shift of U.S. military innovation to leverage platforms that are small, smart, cheap, and many,” Deputy Secretary of Defense Kathleen Hicks said in August.\n\nWhile its funding is uncertain and details vague, Replicator is expected to accelerate hard decisions on what AI tech is mature and trustworthy enough to deploy - including on weaponized systems.\n\nThere is little dispute among scientists, industry experts and Pentagon officials that the U.S. will within the next few years have fully autonomous lethal weapons. And though officials insist humans will always be in control, experts say advances in data-processing speed and machine-to-machine communications will inevitably relegate people to supervisory roles.\n\nThat’s especially true if, as expected, lethal weapons are deployed en masse in drone swarms. Many countries are working on them — and neither China, Russia, Iran, India or Pakistan have signed a U.S.-initiated pledge to use military AI responsibly.\n\nIt’s unclear if the Pentagon is currently formally assessing any fully autonomous lethal weapons system for deployment, as required by a 2012 directive. A Pentagon spokeswoman would not say.\n\nParadigm shifts\n\nReplicator highlights immense technological and personnel challenges for Pentagon procurement and development as the AI revolution promises to transform how wars are fought.\n\n“The Department of Defense is struggling to adopt the AI developments from the last machine-learning breakthrough,” said Gregory Allen, a former top Pentagon AI official now at the Center for Strategic and International Studies think tank.\n\nThe Pentagon’s portfolio boasts more than 800 AI-related unclassified projects, much still in testing. Typically, machine-learning and neural networks are helping humans gain insights and create efficiencies.\n\n“The AI that we’ve got in the Department of Defense right now is heavily leveraged and augments people,” said Missy Cummings, director of George Mason University’s robotics center and a former Navy fighter pilot.” “There’s no AI running around on its own. People are using it to try to understand the fog of war better.”\n\nSpace, war’s new frontier\n\nOne domain where AI-assisted tools are tracking potential threats is space, the latest frontier in military competition.\n\nChina envisions using AI, including on satellites, to “make decisions on who is and isn’t an adversary,” U.S. Space Force chief technology and innovation officer Lisa Costa, told an online conference this month.\n\nThe U.S. aims to keep pace.\n\nAn operational prototype called Machina used by Space Force keeps tabs autonomously on more than 40,000 objects in space, orchestrating thousands of data collections nightly with a global telescope network.\n\nMachina’s algorithms marshal telescope sensors. Computer vision and large language models tell them what objects to track. And AI choreographs drawing instantly on astrodynamics and physics datasets, Col. Wallace ‘Rhet’ Turnbull of Space Systems Command told a conference in August.\n\nAnother AI project at Space Force analyzes radar data to detect imminent adversary missile launches, he said.\n\nMaintaining planes and soldiers\n\nElsewhere, AI’s predictive powers help the Air Force keep its fleet aloft, anticipating the maintenance needs of more than 2,600 aircraft including B-1 bombers and Blackhawk helicopters.\n\nMachine-learning models identify possible failures dozens of hours before they happen, said Tom Siebel, CEO of Silicon Valley-based C3 AI, which has the contract. C3’s tech also models the trajectories of missiles for the the U.S. Missile Defense Agency and identifies insider threats in the federal workforce for the Defense Counterintelligence and Security Agency.\n\nAmong health-related efforts is a pilot project tracking the fitness of the Army’s entire Third Infantry Division — more than 13,000 soldiers. Predictive modeling and AI help reduce injuries and increase performance, said Maj. Matt Visser.\n\nAiding Ukraine\n\nIn Ukraine, AI provided by the Pentagon and its NATO allies helps thwart Russian aggression.\n\nNATO allies share intelligence from data gathered by satellites, drones and humans, some aggregated with software from U.S. contractor Palantir. Some data comes from Maven, the Pentagon’s pathfinding AI project now mostly managed by the National Geospatial-Intelligence Agency, say officials including retired Air Force Gen. Jack Shanahan, the inaugural Pentagon AI director,\n\nMaven began in 2017 as an effort to process video from drones in the Middle East – spurred by U.S. Special Operations forces fighting ISIS and al-Qaeda — and now aggregates and analyzes a wide array of sensor- and human-derived data.\n\nAI has also helped the U.S.-created Security Assistance Group-Ukraine help organize logistics for military assistance from a coalition of 40 countries, Pentagon officials say.\n\nAll-Domain Command and Control\n\nTo survive on the battlefield these days, military units must be small, mostly invisible and move quickly because exponentially growing networks of sensors let anyone “see anywhere on the globe at any moment,” then-Joint Chiefs chairman Gen. Mark Milley observed in a June speech. “And what you can see, you can shoot.”\n\nTo more quickly connect combatants, the Pentagon has prioritized the development of intertwined battle networks — called Joint All-Domain Command and Control — to automate the processing of optical, infrared, radar and other data across the armed services. But the challenge is huge and fraught with bureaucracy.\n\nChristian Brose, a former Senate Armed Services Committee staff director now at the defense tech firm Anduril, is among military reform advocates who nevertheless believe they “may be winning here to a certain extent.”\n\n“The argument may be less about whether this is the right thing to do, and increasingly more about how do we actually do it -- and on the rapid timelines required,” he said. Brose’s 2020 book, “The Kill Chain,” argues for urgent retooling to match China in the race to develop smarter and cheaper networked weapons systems.\n\nTo that end, the U.S. military is hard at work on “human-machine teaming.” Dozens of uncrewed air and sea vehicles currently keep tabs on Iranian activity. U.S. Marines and Special Forces also use Anduril’s autonomous Ghost mini-copter, sensor towers and counter-drone tech to protect American forces.\n\nIndustry advances in computer vision have been essential. Shield AI lets drones operate without GPS, communications or even remote pilots. It’s the key to its Nova, a quadcopter, which U.S. special operations units have used in conflict areas to scout buildings.\n\nOn the horizon: The Air Force’s “loyal wingman” program intends to pair piloted aircraft with autonomous ones. An F-16 pilot might, for instance, send out drones to scout, draw enemy fire or attack targets. Air Force leaders are aiming for a debut later this decade.\n\nThe race to full autonomy\n\nThe “loyal wingman” timeline doesn’t quite mesh with Replicator’s, which many consider overly ambitious. The Pentagon’s vagueness on Replicator, meantime, may partly intend to keep rivals guessing, though planners may also still be feeling their way on feature and mission goals, said Paul Scharre, a military AI expert and author of “Four Battlegrounds.”\n\nAnduril and Shield AI, each backed by hundreds of millions in venture capital funding, are among companies vying for contracts.\n\nNathan Michael, chief technology officer at Shield AI, estimates they will have an autonomous swarm of at least three uncrewed aircraft ready in a year using its V-BAT aerial drone. The U.S. military currently uses the V-BAT -- without an AI mind -- on Navy ships, on counter-drug missions and in support of Marine Expeditionary Units, the company says.\n\nIt will take some time before larger swarms can be reliably fielded, Michael said. “Everything is crawl, walk, run -- unless you’re setting yourself up for failure.”\n\nThe only weapons systems that Shanahan, the inaugural Pentagon AI chief, currently trusts to operate autonomously are wholly defensive, like Phalanx anti-missile systems on ships. He worries less about autonomous weapons making decisions on their own than about systems that don’t work as advertised or kill noncombatants or friendly forces.\n\nThe department’s current chief digital and AI officer Craig Martell is determined not to let that happen.\n\n“Regardless of the autonomy of the system, there will always be a responsible agent that understands the limitations of the system, has trained well with the system, has justified confidence of when and where it’s deployable -- and will always take the responsibility,” said Martell, who previously headed machine-learning at LinkedIn and Lyft. “That will never not be the case.”\n\nAs to when AI will be reliable enough for lethal autonomy, Martell said it makes no sense to generalize. For example, Martell trusts his car’s adaptive cruise control but not the tech that’s supposed to keep it from changing lanes. “As the responsible agent, I would not deploy that except in very constrained situations,” he said. “Now extrapolate that to the military.”\n\nMartell’s office is evaluating potential generative AI use cases – it has a special task force for that – but focuses more on testing and evaluating AI in development.\n\nOne urgent challenge, says Jane Pinelis, chief AI engineer at Johns Hopkins University’s Applied Physics Lab and former chief of AI assurance in Martell’s office, is recruiting and retaining the talent needed to test AI tech. The Pentagon can’t compete on salaries. Computer science PhDs with AI-related skills can earn more than the military’s top-ranking generals and admirals.\n\nTesting and evaluation standards are also immature, a recent National Academy of Sciences report on Air Force AI highlighted.\n\nMight that mean the U.S. one day fielding under duress autonomous weapons that don’t fully pass muster?\n\n“We are still operating under the assumption that we have time to do this as rigorously and as diligently as possible,” said Pinelis. “I think if we’re less than ready and it’s time to take action, somebody is going to be forced to make a decision.”"
    }
}