{
    "id": "dbpedia_3158_2",
    "rank": 13,
    "data": {
        "url": "https://www.mdpi.com/2079-9292/12/7/1509",
        "read_more_link": "",
        "language": "en",
        "title": "Machine Learning and AI Technologies for Smart Wearables",
        "top_image": "https://pub.mdpi-res.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g001-550.jpg?1679544710",
        "meta_img": "https://pub.mdpi-res.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g001-550.jpg?1679544710",
        "images": [
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-black-small1.svg?da3a8dcae975a41c?1723472589",
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-black-small1.svg?da3a8dcae975a41c?1723472589",
            "https://pub.mdpi-res.com/img/journals/electronics-logo.png?8600e93ff98dbf14",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1723472589",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g001-550.jpg",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g001.png",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g002-550.jpg",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g002.png",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g003-550.jpg",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g003.png",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g004-550.jpg",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g004.png",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g005-550.jpg",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g005.png",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g006-550.jpg",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g006.png",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g007-550.jpg",
            "https://www.mdpi.com/electronics/electronics-12-01509/article_deploy/html/images/electronics-12-01509-g007.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-white-small.png?71d18e5f805839ab?1723472589"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Kah Phooi Seng",
            "Li-Minn Ang",
            "Eno Peter",
            "Anthony Mmonyi",
            "Kah Phooi",
            "Li-Minn"
        ],
        "publish_date": "2023-03-23T00:00:00",
        "summary": "",
        "meta_description": "The recent progress in computational, communications, and artificial intelligence (AI) technologies, and the widespread availability of smartphones together with the growing trends in multimedia data and edge computation devices have led to new models and paradigms for wearable devices. This paper presents a comprehensive survey and classification of smart wearables and research prototypes using machine learning and AI technologies. The paper aims to survey these new paradigms for machine learning and AI for wearables from various technological perspectives which have emerged, including: (1) smart wearables empowered by machine learning and AI; (2) data collection architectures and information processing models for AI smart wearables; and (3) applications for AI smart wearables. The review covers a wide range of enabling technologies for AI and machine learning for wearables and research prototypes. The main findings of the review are that there are significant technical challenges for AI smart wearables in networking and communication aspects such as issues for routing and communication overheads, information processing and computational aspects such as issues for computational complexity and storage, and algorithmic and application-dependent aspects such as training and inference. The paper concludes with some future directions in the smart wearable market and potential research.",
        "meta_lang": "en",
        "meta_favicon": "https://pub.mdpi-res.com/img/mask-icon-128.svg?c1c7eca266cd7013?1723472589",
        "meta_site_name": "MDPI",
        "canonical_link": "https://www.mdpi.com/2079-9292/12/7/1509",
        "text": "1\n\nSchool of AI & Advanced Computing, Xi’an Jiaotong Liverpool University, Suzhou 215123, China\n\n2\n\nSchool of Computer Science, Queensland University of Technology, Brisbane, QLD 4000, Australia\n\n3\n\nSchool of Science, Technology and Engineering, University of the Sunshine Coast, Petrie, QLD 4502, Australia\n\n4\n\nDepartment of Computer Science, Federal University, Oye 370112, Ekiti, Nigeria\n\n5\n\nDepartment of Electrical and Computer, Engineering, Afe Babalola University, Ado 360102, Ekiti, Nigeria\n\n*\n\nAuthor to whom correspondence should be addressed.\n\nElectronics 2023, 12(7), 1509; https://doi.org/10.3390/electronics12071509\n\nSubmission received: 1 February 2023 / Revised: 20 February 2023 / Accepted: 23 February 2023 / Published: 23 March 2023\n\n(This article belongs to the Special Issue The Future of Artificial Intelligence (AI): Emerging Topics for AI and Its Applications)\n\nAbstract\n\n:\n\nThe recent progress in computational, communications, and artificial intelligence (AI) technologies, and the widespread availability of smartphones together with the growing trends in multimedia data and edge computation devices have led to new models and paradigms for wearable devices. This paper presents a comprehensive survey and classification of smart wearables and research prototypes using machine learning and AI technologies. The paper aims to survey these new paradigms for machine learning and AI for wearables from various technological perspectives which have emerged, including: (1) smart wearables empowered by machine learning and AI; (2) data collection architectures and information processing models for AI smart wearables; and (3) applications for AI smart wearables. The review covers a wide range of enabling technologies for AI and machine learning for wearables and research prototypes. The main findings of the review are that there are significant technical challenges for AI smart wearables in networking and communication aspects such as issues for routing and communication overheads, information processing and computational aspects such as issues for computational complexity and storage, and algorithmic and application-dependent aspects such as training and inference. The paper concludes with some future directions in the smart wearable market and potential research.\n\n1. Introduction\n\nRecent years have seen rapid progress in computational, communication, and artificial intelligence (AI) technologies and trends. Another trend is the widespread availabilities of smartphones, multimedia computing, and edge computation devices. Other trends are the availability of new data collection architectures and information processing technologies such as cloud computing. These converging trends have led to new models and paradigms for smart wearables and technologies. This section will briefly discuss the progress of AI in wearable devices beginning from the need for wearables, how AI can be used to benefit wearables, and the main challenges. The further sections in the paper will give more detailed discussions on the various aspects.\n\nThere is a growing market and perception for the benefits on constant monitoring technologies for clinical, health, and well-being. The trends on utilizing wearables for health monitoring and activity recognition are increasing rapidly. The advances in sensing technologies and integrated electronic circuits have enabled the development of small and compact sophisticated devices which can integrate different sensors such as temperature sensing, accelerometers, gyroscopes, and sensors for heart rate and blood oxygen levels. The availability of these wearable sensors and sensing devices have enabled new applications to be developed for sensing various human activities in consumer and workplace environments. Some examples include using wearables for sleep monitoring and circadian rhythms (Bianchi, 2018 [1]), fatigue detection (Moshawrab et al., 2022 [2]), fall detection for elderly people (Pierleoni et al., 2015 [3]), and human emotion and stress recognition (Zamkah et al., 2020 [4]). The usage of smart wearables can also be extended to the monitoring of animal and wildlife behaviours and activities. The authors in (Nagl et al., 2003 [5]) developed an early approach for using sensing and wearable technologies for the monitoring and health management of cattle and livestock. A review for using wearable technologies with a focus on animal monitoring can be found in (Neethirajan 2017, [6]).\n\nMachine learning and artificial intelligence technologies play a crucial role in smart wearables because its architecture is embedded in the wearables. Artificial intelligence and smart wearables are mostly used in medical healthcare sector, sports, rehabilitation centres, entertainment, and surveillance in smart homes. These wearables help in monitoring patients’ heart failure, diabetes, and cardiovascular activity. Additionally, it is useful in detecting and classifying the emotional states, human posture, and sleep stage. There are many AI and machine learning technologies which have been developed over the years. These AI and machine learning technologies can be classified into classical machine learning techniques (Michalski et al., 2013, [7]) and recent deep learning techniques (Goodfellow 2016, [8]). Some examples for classical machine learning techniques include multilayer perceptron (MLP), support vector machines (SVM), decision trees, linear discriminant analysis (Seng et al., 2017 [9]), random forest algorithms (Biau et al., 2016 [10]), Bayesian approaches, and hidden Markov models. Some examples for deep learning techniques include convolutional neural networks (CNNs), recurrent neural networks (RNNs), long short-term memory (LSTM) networks, deep reinforcement learning, and stacked autoencoder architectures. Our paper will focus on discussions for both classical machine learning approaches and recent deep learning approaches for smart wearable technologies and applications.\n\nAlthough machine (and deep) learning and AI-based technologies have enjoyed some considerable success for smart wearables and technologies, particularly for applications in human activity recognition and health monitoring, some challenges remain to be satisfactorily resolved in order to enable widespread adoption and application in the marketplace. For example, the authors in (Ramanujam et al., 2021 [11]) identified several issues or challenges which need to be addressed for the deployment of smart wearables for activity recognition. The first challenge is the need for a significant amount of training data to train the classifiers for activity recognition. The large amount of training data is particularly required for training deep learning classifiers. Classical machine learning classifiers can be adequately trained with a lower amount of data. The second challenge is to select the required features for recognition. In classical machine learning approaches, the process of feature selection is often performed manually using the expertise of the designer. In deep learning approaches, the process of feature selection can be performed in an end-to-end manner and incorporated as part of the training process. The third challenge is to distinguish between activities which may have similar inputs (e.g., distinguishing between a fall activity event and an event of searching for an item on the floor). A further challenge for real-time deployments is the need for computationally efficient algorithms and hardware implementations to realize the tasks to be performed by the smart wearables. These hardware architectures for smart wearables would need to take into account the challenging issues and hardware constraints such as the electronics chip and board area, power consumption, and costs for production.\n\nAlthough these challenges were targeted towards smart wearables for activity recognition, the issues the authors have identified have general applications towards the deployment of AI and machine learning technologies for smart wearables in general. Our paper will further survey and expound on these and other issues for smart wearables. The paper has been organized using the following structure: Section 2 gives an overview on wearables and smart device technologies to introduce the reader to the related concepts and technologies. Section 3–Section 5 discusses various technological perspectives for smart wearables. Section 3 gives discussions on smart wearables empowered by machine learning and AI. Deep learning architectures for smart wearables are also discussed in this section. Section 4 gives discussions on data collection architectures and information processing models for AI smart wearables. Section 5 provides discussions on various applications which have been proposed for AI smart wearables. Some future directions in the smart wearable market and potential research are discussed in Section 6. Section 7 provides a summary of the paper and some concluding remarks. Table 1 shows a summary of the classification descriptors covered in the main technology sections which also serves as a summary and roadmap to aid readers to navigate the contents of the paper. This survey paper aims to bring discussions on smart wearable technologies with recent AI innovations. Although there are some surveys on wearables in the literature, these works were not focused on the integration of wearables with AI technologies. The literature review and papers were retrieved using selected keywords such as “wearables and AI”, “wearables and machine learning”, etc., from standard publishers and databases such as IEEE Xplore, Elsevier, MDPI, etc.\n\n2. Smart Wearable Technologies\n\nThis section provides some background information on wearables and smart device technologies to introduce the reader to the related concepts and technologies. Table 2 shows a summary of some representative research works for wearable and smart device technologies. We have provided some representative examples for three categories which will be frequently encountered by the reader and further discussed in the paper: (1) research works for smart wearable wristbands and bracelet technologies; (2) research works for smart wearable waist and belt device technologies; (3) research works for smart wearable bowel recorder technologies; and (4) research works for smart wearable neural interface technologies.\n\n2.1. Research Works for Smart Wearable Wristbands and Bracelet Technologies\n\nThe wrist is a comfortable location to house a wearable smart AI device. Several authors have proposed the use of smart wearable wristbands and bracelets for wearable technologies. The authors in (Quadros et al., 2018 [12]) proposed a wrist wearable device for detecting falls in elders. The device is made up of different sensors, signals, and direction components. Their proposed wrist wearable device consisted of three sensor types (accelerometer, gyroscope, and magnetometer), three signal types (acceleration, velocity and displacement), and two direction components (vertical and non-vertical). These data captured from the different sensors were then combined and analysed using machine learning approaches to identify the best approach for fall detection. To validate their approach, the authors acquired data for fall events and non-fall events from 22 people. The authors showed that their proposed wearable device could provide an accuracy of approximately 91% to detect fall events.\n\nThe authors in (Shashikumar et al., 2017 [13]) proposed a wrist-worn wearable device for the classification of atrial fibrillation (AF). Shashikumar et al., (2017) introduced a method, applying deep neural network for the classification of atrial fibrillation (AF). The classification of AF was carried out from wrist-worn pulsatile photoplethysmography (PPG) signals. The distinctive traits from the PPG were extracted through the wavelet investigation, and the convolution neural network was utilized to forecast the 2D feature vector. The authors conducted a study on adult patients whose ages ranged from 18 to 89 years old. A watch-based wearable device was utilized to record the ambulatory pulsatile data.\n\nThe authors in (Sarivan et al., 2020 [14]) proposed an approach that utilized wearable smart devices with convolution neural network for real-time quality inspection in a smart manufacturing industry. This approach classifies a worker’s actions based on the acoustic and accelerometer data collected from the wrist device (Huawei watch 2). The data from the wrist device are sent to a computer, where the computer uses artificial intelligence techniques to process and classify the data and send them back to the wrist device over the local wireless network. The wrist device displays the results of their action, which is either successful or unsuccessful, and the feedback is given to the workers. The result from the wearable device is in different modes—namely, audio, visual, and haptic. The WearOS application, termed as QCApp, runs on the wrist device and gives a GUI for commencing and ending the inspection operation. An experiment was carried out using an artificial intelligence-based device during the manufacturing of Mercedes-Benz AG. Their experimental results indicated that acoustic and accelerometer data are very important in training a classifier for a proper assessment during the manufacturing operation.\n\nThe authors in (Costa et al., 2019, [15]) proposed an approach that combines a smart wristband with iGenda to recognize the emotional states of humans, especially elderly people. An overview of the architecture structure of the smart wristband with iGenda is shown in Figure 1. The wristband detects the emotional states of humans and sends the information to the iGenda, and the iGenda displays the information to the caregivers. This display of information allows for the scheduling of new tasks with respect to the emotional states of humans. This approach utilizes neural networks and the Pleasure, Arousal, Dominance (PAD) method to interpret bio-signals into emotion.\n\n2.2. Research Works for Smart Wearable Waist and Belt Device Technologies\n\nThe authors in (Desai et al., 2020 [16]) proposed a wearable belt device that can detect falls using machine learning and the signal processing algorithm. The wearable device sends information to the family through a mobile phone whenever a fall is detected. Their wearable belt device (termed as Hip-grip) contains an IMU sensor unit with an inbuilt combination of an accelerometer and gyroscope. The authors defined some activity events for walking, jogging, running, bending, squatting, and falls and trained a classifier using logistic regression to perform the fall detection task. The authors further categorized fall events into front, side, and back falls. The aim of their proposed wearable system was to detect potential fall events before the person completely falls. Their experimental results showed that the belt-based wearable device was able to detect a fall within 0.25 s with high accuracy.\n\nThe study in (Zurbuchen et al., 2020 [17]) provides another example of a fall detection system using a wearable waist wearable device. The authors approach used an accelerometer in combination with a waist-mounted gyroscope. The data were taken from SisFall, a public dataset that contains information about daily living activities and falls. Five machine learning algorithms were compared. Before applying and comparing the five machine learning techniques, we started with the steps of pre-processing and feature extraction. Ensemble learning algorithms with near 99% sensitivity and specificity, such as random forest and gradient boosting, provided the best results.\n\n2.3. Research Works for Smart Wearable Bowel Recorder Technologies\n\nThe authors in (Zhao et al., 2020 [18]) proposed an edge bowel sound (BS) wearable system aimed at selecting idle BS events while effectively eliminating audio segments that contain only background information noise, such as voice and white Gaussian noise. The system consists of a wearable BS recorder which captures the data for analysis by a remote computer. According to the experimental data, the proposed algorithm achieves a classification accuracy of 99.92% with a very low false alarm rate. The work in (Zhao et al., 2022 [19]) describes a lightweight BS recognizer for use with a convolutional neural network (CNN) portable system. The proposed recognizer first calculates the mel frequency-cepstrum to convert each one-dimensional segment into a two-dimensional spectrogram coefficient (MFCC) frame by frame, followed by the spectrogram via the CNN. To validate the CNN-based BS detector, a 28 min BS dataset of 955 BS present and 725 BS absent segments was constructed. According to the experimental outcome of the dataset, the recognizer achieves an average accuracy of 91.25% and 90.83% in “not across disciplines” and “cross validation of subjects” categories, respectively. Figure 2 shows an overview of the wearable bowel sound system of surveillance.\n\n2.4. Research Works for Smart Wearable Neural Interface Technologies\n\nThe authors in (AlZubi et al., 2020 [20]) introduced HTSMNN (heuristic tubu optimized sequence modular neural network), which is a smart wearable approach using neural interfaces to identify Parkinson’s disease. The authors introduced a wearable device called deep brain simulation (DBS), which is placed on the patient’s brain to simulate the patient’s brain and to receive event information about the brain.\n\n3. Machine Learning Approaches for AI and Smart Wearables\n\nMachine learning plays a crucial role in artificial intelligence and smart wearables be-cause its architecture is embedded in the wearables. Artificial intelligence and smart wearables find application in many sectors of society such as medical healthcare sector, sports, rehabilitation centres, entertainment, and surveillance in smart homes. This section discusses different AI and machine learning approaches for artificial intelligence technologies and smart wearables. The section will focus on more recent approaches which have been proposed using deep learning technologies.\n\n3.1. Machine Learning Approaches for Smart Wearable Technologies\n\nThere are different machine learning approaches which can be used in AI and smart wearables, such as deep learning, which is used for feature extraction in human behaviour, activity recognition and pattern recognition. The recent machine learning approaches require the utilization of feature engineering and classification to attain precision. The authors in (Lu et al., 2020 [21]) proposed a method which utilizes deep learning to address the challenges encountered in the application of recent machine learning approaches for detecting movement. The authors introduced an approach that utilizes confidence index and tunes confidence index thresholds to obtained stability intent recognition.\n\nMachine learning approaches can be utilized to overcome limitations in existing systems. For example, many fall detection sensors have some limitations, including false alarms and the cost of maintenance due to irregular usage. The machine learning approach integrated with Internet of Things (IoT) has a significant impact on addressing these challenges with fall detection wearable sensors. The authors in (Chaudhuri et al., 2020 [22]) proposed a machine learning-based wearable device that predicts pulse rates and skin temperature. The authors introduced an approach called enhanced predicted thermal state (ePTS), which predicts the thermal state index. Another machine learning approach for wearable technology by authors (Rubio-Solis et al., 2020 [23]) proposed an extreme learning machine with multilayer interval type-2 fuzzy for the effective identification of walking actions and patterns using wearable device.\n\n3.2. Deep Learning Approaches for Smart Wearable Technologies\n\nDeep learning is one of the most important methods of analysing data for smart wearable technologies. The authors in (Saeedi et al., 2017 [24]) proposed novel deep learning architecture using wearables sensors which support human activity recognition systems working in a robust environment. This deep architecture combines the innovative deep neural network and the active learning technique in the development of broad models for data classification. The former utilized the convolutional neural network (CNN) with layered long-short term memory (LSTM) to learn the tiered depiction of features and capture the long-term dependency in activity data, while the latter selects the best opportunity for the adjustment of the deep neural network to a new configuration that allows for the system to function. The deep network model is made up of eight layers which are further grouped into two recurrent LSTM layers, five convolutional layers, and a soft-max layer. The authors discussed that the deep network architecture works by allowing for the activity of the individual information segment to pass through the convolution neural network layers to create a static vector representation of length for the following layer, and the LSTM layers capture the time dependence of the activity data.\n\nThe authors in (Young et al., 2020 [25]) proposed an approach which utilized a deep learning-based wearable healthcare Internet of Things system to help people who have a hearing disability to communicate with others. The approach contains a server application that converts the output of the Google’s Online speech recognition system into text. The deployment of micro-display was used to display the content of the information to the people with a hearing disability. This approach helps in assisting the deaf people to communicate with others with a non-hearing disability. The authors also introduced an urban-emergency system which utilizes a deep learning approach, Inception-v4, with transfer learning for sound recognition and classification. In this system, an alarm is raised which creates an awareness of traffic congestion, fire, and road accidents. The text generated from this system is displayed to the road users.\n\nThe authors in (Jacobson et al., 2021 [26]) proposed a deep learning-paired technique with a wearable sensor-based device to forecast the decline in anxiety and panic disorder symptoms during the day’s movement and night’s sleep. Another work by authors in (Bauer et al., 2020 [27]) also proposed a deep learning approach with a wearable sensor device for promoting movement for people with a vision impairment. The deep learning method provides a 3D presentation of the surrounding area with certain names for the obstacle from the wearable camera. The smart watch gives information about the obstacles in the environment to the person with a visibility challenge. The depth estimator helps the obstacles to seem closer than they are. The authors in (Janarthanan et al., 2020 [28]) proposed an unsupervised deep learning approach that helps in the reconstruction of the on-nodule wearable sensor’s coder for the better recognition of human activities. The authors integrated the coder architecture with the Z-layer approach to eliminate the reconstruction error and promote precision in the system. The deep learning approach utilizes data collected from wearable sensors in the Lab of Wireless Sensor Data Mining. The data include six different action such as standing, walking, sitting, jogging, ascending stairs, and descending stairs. The subsequent sub-sections will discuss various deep learning network architectures for application in AI and smart wearable technologies.\n\n3.2.1. Deep Learning Approaches Using Convolutional Neural Networks (CNNs)\n\nConvolutional neural networks combine convolutional layers for feature extraction. Due to many challenges faced in research regarding falls in older people, (Alarifi & Alwadain, 2021 [29]) introduced a heuristic-optimized convolution neural network technique to detect falls in elders. The fall features were recognized using eight layers of a convolution neural network. This approach provides an accurate result regarding the detection of falls in elders. The authors utilized a wearable sensor-based system that is made up of a magnetometer, gyroscope, and accelerometer tri-axial device. Data were collected from different activities of human daily routines and falls. The authors in (Hernandez et al., 2021 [30]) proposed a wearable device which is based on deep learning to estimate the lower limb kinematic during gait analysis. Convolutional and long-short term memory recurrent layers were used in the deep learning process (DeepConvLSTM). The deep convolutional recurrent neural network is combined with the long-short term memory network. The former aids the extraction of the feature and the latter provides the time domain.\n\nThe authors in (Rad et al., 2018 [31]) proposed a wearable device that detects motion in patients with autism spectrum disorder using a convolutional neural network. To learn the characteristics from raw data that were obtained from different wearable sensors, three convolution neural network layers were employed. Figure 3 shows the architectural view of the stereotypical motor movement (SMM) detection proposed by the authors. The authors also introduced a concept which combines the convolution neural network with long short-term memory (LSTM) for the improvement of stereotypical motor movement (SMM) detection. The work in (Mai et al., 2021 [32]) proposed a 1D-Convolutonal Neural Network approach; this approach utilizes the EEG-based BCI method for the recognition of emotional states. A cordless and wearable 8-channel custom-designed electroencephalogram (EEG) device was utilized for signal classification. This wireless EEG device is made of dry active sensors, an active circuit, a communication unit, a micro controller, and an analogue-to-digital converter.\n\n3.2.2. Deep Learning Approaches Using Recurrent Neural Networks (RNN)\n\nThe authors in (Zhang et al., 2018 [33]) presented an approach for classifying and monitoring sleep using wearables medical devices. This approach utilized recurrent neural networks based on bidirectional long short-term memory (BLSTM) and tiered feature learning. Their experiments and analysis were carried out with a group of people with resting and non-resting sleep. The approach grouped sleep into the following groups: namely, wakes, regular eye shift, and irregular eye shift. The authors in (Torti et al., 2019 [34]) integrated recurrent neural networks into wearable devices with a micro controller unit (MCU) for monitoring and detecting falls in a real-time scenario. This device is linked to a wireless network and monitoring device to enable the caregiver to provide the necessary care for the patient. The authors emphasized that the wearable device must achieve the basic requirements for the effective detection of fall. The basic requirements are as follows: First, the wearables need to be constantly connected to the wireless network to alert the caregiver of the fall. Second, the device must be portable so that it will be convenient for the patients. Third, the device constantly needs to be on for a lengthy period of time to ensure the effective monitoring of activities.\n\nAnother study (Martindale et al., 2021 [35]) introduced an approach that utilizes the multi-task gait and activity segmentation approach. This approach uses recurrent neural network-based wearable devices. The authors in (Coutts et al., 2020 [36]) introduced a wearable device with deep recurrent neural network (LSTM) to predict the patient’s health. The wrist wearable device utilizes heart rate variability data to provide accurate information of the patient’s general and mental health.\n\n3.2.3. Deep Learning Approaches Using Long Short-Term Networks (LSTM)\n\nSome authors have also proposed to use the long short-term network (LSTM) architecture for application towards AI and smart wearables. Compared to deep learning models such as the CNN model, which has the capability of utilizing spatial correlations and performing the classification role, the LSTM model has the capability of utilizing feedback connections to process sequences of time-series data. The authors in (Chung et al., 2019 [37]) proposed an LSTM deep learning model for the fusion of multimodal data towards the application of human activity recognition. Their work developed a testbed for an on-body positioning system using IMU (inertial measurement unit) sensors. Their analytics model utilized the LSTM model to perform the classification of activity events in controlled and real-world scenarios. The authors also developed an ensemble approach for the computation of event probabilities from the multimodal sensors. Their experimental work used data from 15 people; their results showed challenges for developing a wearable-based system and scaling the work towards large-scale applications.\n\nThe authors in (Zhang et al., 2018 [33]) proposed an approach for classifying and monitoring sleep using wearable medical devices. This approach utilized recurrent neural networks based on bidirectional long short-term memory (BLSTM) and tiered feature learning. The analysis was carried out with a group of people with resting and non-resting sleep. The approach grouped sleep into the following groups, namely, wakes, regular eye shift, and irregular eye shift.\n\n3.2.4. Hybrid Deep Learning Approaches Using a Combination of Deep Learning Techniques\n\nSome authors have proposed combining a variety of deep learning techniques and developed hybrid deep learning approaches for AI and smart wearables. The authors in (Xia et al., 2020 [38]) proposed a hybrid deep learning approach for smart wearables by utilizing LSTM models which were connected to convolutional layers and Global Pooling layers (GAP). Their approach using the GAP and batch normalization process could speed up the convergence of the system. Their LSTM-CNN architecture approach was applied and validated towards the classification of human activity. The authors in (Rueda et al., 2019 [39]) combined deep neural network approaches with symbolic models to address the issues of subject and location dependency for activity recognition. Their work was validated using contextual information in realistic scenarios.\n\nAnother hybrid deep learning approach was proposed by authors in (Mukherjee et al., 2020 [40]) for human activity recognition. Their approach used a combination of deep learning techniques, conventional machine learning techniques, and statistical techniques. The authors termed their approach as EnsemConvNet, of which utilizes an ensemble of CNN-Net, Encoded-Net, and CNN-LSTM models. Their experimental work was validated on the WISDM, UniMB SHAR, and MobiAct activity prediction datasets. The authors in (Ascioglu and Senol 2020, [41]) proposed a hybrid deep learning approach for human activity recognition by utilizing a convolutional neural network with LSTM (ConvLSTM). The authors carried out experiments to classify human activities in outdoor-based environments and developed a novel sensor-based wireless activity monitoring system.\n\n4. Data Collection Architectures and Processing Models for AI and Smart Wearables\n\nThis section discusses various data collection architectures and processing models for AI and smart wearables which have been proposed. The section is structured into the following discussions: (1) standalone architectures for AI smart wearables; (2) smartphone architectures for AI smart wearables; (3) cloud architectures for AI smart wearables; and (4) edge architectures for AI smart wearables.\n\n4.1. Standalone Architectures for AI Smart Wearables\n\nThis sub-section will provide some discussions on standalone architectures for AI smart wearables. The authors in (Orfanidis et al., 2021 [42]) proposed a standalone architecture and low-cost wearable device which combines three components to detect foot movements and relay messages over long distances in an emergency, based on standard shoes and off-the-shelf electronic devices. The rating takes into account an application scenario in which the user executes accurate foot movements during other activities (such as walking) to trigger the sending of an urgent message. The proposed portable device is at risk and is useful for users who want to carefully alert their emergency contacts. The proposed system can identify the intended foot movement with 98 times the accuracy, according to the results.\n\nThe authors in (Ravi et al., 2017 [43]) proposed a standalone wearable architecture utilizing deep learning for an accurate, real-time activity classification by combining the extracted features using inertial sensor data and supplemental data from a collection of flat features. This combined method’s design aims to overcome some of the limitations found in standard deep learning frameworks that require on-node computing. Before the input is passed to the deep learning framework, it uses spectral domain pre-processing to improve the proposed approach for on-node real-time computation. Their work used datasets on both laboratory and real-world activity to compare the classification accuracy of the proposed deep learning strategy with the classification state-of-the-art precision methods. Their findings demonstrated the efficacy of the strategy across various human activity datasets and are superior to other techniques, including the two employed in the study.\n\nAnother example of a standalone architecture for smart wearables can be found in the work by (Mai et al., 2021 [32]). In this work, the authors developed a standalone smart wearable architecture for emotion detection using EEG signals. The authors utilized a one-dimensional CNN model to create a BCI system based on EEG for emotion detection. The EEG signals were captured non-invasively using eight drywall electrodes attached to the scalp and a cordless handheld custom EEG device.\n\n4.2. Smartphone and Smartwatch Architectures\n\nThere have been many smartphone and smartwatch architectures which have been proposed for smart AI and wearable technologies. The authors in (Rakhman et al., 2014 [44]) proposed, using an accelerometer and gyroscope based on a developed smartphone, a fall detection system that detects falls and daily activities using tilt angle and the acceleration threshold. The authors in (Zhang et al., 2018 [33]) proposed a two-stage method: multi-level learning features and classification using neural networks with recurrent connections (RNNs). The feature learning phase extracts low- and mid-level features. The raw signals are processed to extract low-level properties that capture temporal and frequency domain characteristics. Figure 4 shows the proposed sleep stage wearable method.\n\nThe authors of (Yin et al., 2017 [45]) proposed a hierarchical health decision support system which has been developed for disease detection by integrating health data from WMSs into CDSSs. The proposed system is multitiered, beginning with a WMS tier supported by robust machine learning and allowing for a disease diagnosis module that will track each disease individually. Six disease diagnosis modules targeting four ICD10CM disease categories are used to demonstrate the system’s feasibility. Using five examples, they demonstrated that the system is scalable for additional disease categories.\n\nThe authors of (Kalantarian et al., 2015 [46]) used data from a gyroscope and an accelerometer smart watch collected at 16 Hz to distinguish between the “Opening a pill bottle” and “pouring pills into hand” actions. Predictions were made for both actions, and if “pouring pills into hand” occurred within six seconds, a subject was considered to have successfully taken a pill from “opening a pill bottle”. The authors of (Fozoonmayeh et al., 2020 [47]) created a smart watch-based medication intake detection system that classified pill-taking behaviour using gyroscope and accelerometer sensors.\n\n4.3. IoT and Cloud-Based Architectures\n\nPositive computing makes use of mobile communications, wearables, and Internet of Things technologies. Smartphones, activity trackers, voice assistants, and smart sensors are examples of Internet of Things (IoT) devices. Positive computing research is frequently conducted interdisciplinary, making it challenging to obtain a holistic view of intelligent positive computing system designs, implementation, and evaluation using IoT, wearables and mobile technologies. To address this issue, the authors in (Lee et al., 2019 [48]) proposed a conceptual framework and reviewed key components to provide guidelines for studying intelligent positive computing systems. The author also presents some practical service scenarios and provides valuable insights into opportunities and challenges. By critically considering the literature and scenarios, the author suggested some research directions in intelligent positive computing’s core topic system research. In addition, the authors discussed issues such as technology dependence, abandonment, side effects, privacy, and ethical concerns.\n\nThe authors in (Gao et al., 2020 [49]) proposed a cellular network-based control system for intelligent wearable rehabilitation robots. In their research, they investigated how to stimulate the signal and process the signal feedback during the course of electromyographic stimulation of the rehabilitation robot in order to improve the robot’s rehabilitation effect after stimulation. In addition, the authors investigated problems of controlling patients for rehabilitation training, making use of biofeedback and fuzzy control rules. This encourages the patient to actively participate in the rehabilitation treatment and effectively restores the patient’s self-confidence. Then, for rehabilitation training, the system uses biofeedback and fuzzy control rules to investigate the problem of controlling the patient. This effectively guides the patient’s recovery of self-awareness.\n\nCurrently, pose detection algorithms rely on visual image analysis that detects motion and signal analysis based on wearable sensors. However, these systems have drawbacks such as a high misjudgement rate, high cost, and low efficiency. To address these concerns, the authors of (Hong et al., 2022 [50]) proposed a collaborative AI IoT-based solution that includes advanced AI-assisted technologies. The authors proposed a technique termed as Multiposture Recognition (MPR) algorithm. This is an offline technique that can be implemented on wearable hardware to recognize poses based on multidimensional data. The authors in (Tao et al., 2011 [51]) proposed a smart shoe system that uses sensors to detect the occurrence and direction of a fall; the MLP uses this as an input function. Several automated computer detection systems are used to detect this disease, but they cannot predict it at an earlier stage. In addition, traditional methods do not predict disease with the highest accuracy, which increases the accuracy of misclassification. As a result of this problem, wearable IoT mental health sensor devices such as deep brain stimulation (DBS) are used to capture the patient’s brain activity and cellular status and can predict changes in brain function. The information collected is processed by a heuristic tube-optimized sequence modular neural network (HTSMNN). This method examines the information collected continuously and independently to better predict the changes present in the brain.\n\n5. Applications for AI Smart Wearables\n\nThis section discusses applications for AI smart wearables in several areas and marketplaces: (1) healthcare and medical applications for AI smart wearables; (2) augmented and virtual reality applications for AI smart wearables; (3) sports and entertainment applications for AI smart wearables; and (4) environment applications for AI smart wearables.\n\n5.1. Healthcare and Medical Applications for AI Smart Wearables\n\nThe authors in (Ali et al., 2021 [52]) proposed a healthcare monitoring system utilizing smart wearables and AI that improved the efficiency of data handling and classification of healthcare data for monitoring the health of patients. The healthcare data were collected from different sources such as mobile phones, wearable devices, medical records, and social networks contents. The data collected were kept in the cloud network and analysed on the big data system. The analysis of data was carried out with different approaches which involved the mining of data, ontologies, and the utilization of bidirectional long short-term memory (Bi-LSTM). The mined data support the pre-processing and compressing of data size, ontologies provide a perspective on the features, while the Bi-LSTM carries out the classification of data on healthcare to determine the negative consequences of drug and unusual functionality in patients.\n\nFigure 5 shows the architectural view of the healthcare monitoring system. There are five layers in the architectural view of the system: (1) data source layer, where the data are generated from different types of sources; (2) data collection layer, which collects and gathers the data generated; (3) data storage layer, which has the role of storing the data for analysis; (4) analytics engine layer, which performs the compression and classification of the data; and (5) data presentation layer, which provides the user interface for healthcare monitoring and recommendation. The proposed system by the authors alerts the patients, especially those with diabetes and blood pressure, of the stage of their health and the danger of it and assists the doctors with the right treatment for their patients.\n\nThe authors in (Ramkumar et al., 2019 [53]) introduced a method based on wearable and machine learning that remotely monitors the total knee replacements of patients. This approach also provides evaluation for mobility, knee movement, opioid consumption, and home exercise consent. The authors in (Vos et al., 2020 [54]) integrated a wearable device with machine learning algorithms for the accurate differentiation of PSP (progressive supranuclear palsy) from PD (Parkinson’s disease). Logistic regression (LR) and random forest (RF) are two machine learning algorithms used for data analysis. The authors in (Meyer et al., 2021 [55]) proposed a wearable device that utilizes a deep neural network with bidirectional long short-term memory to recognize a person with multiple sclerosis. The authors in (Orfanidis et al., 2021 [42]) proposed an inexpensive wearable device that can identify human foot gestures and then sends emergency information, especially about someone who is in danger, to an emergency contact.\n\n5.2. Augmented and Virtual Reality Applications for AI Smart Wearables\n\nThe authors in (Park et al., 2020 [56]) introduced a smart task aid approach that combines wearable augmented reality (AR) with deep learning and instance segmentation in a real-world setting. This approach helps in providing visual guidance. The approach utilizes the Mask R-convolution neural network as instance segmentation. The authors also conducted a study comparison and evaluation of two users with respect to object matching, inspection, and maintenance of 3D in a manufacturing environment. The result from the study shows that the deep learning-based smart task assistance approach with wearable AR performs better in quantitative and qualitative measures than the previous method used by many researchers with a more effective performance. Figure 6 shows an architectural view of the deep learning-based wearable AR approach proposed by the authors.\n\n5.3. Sports and Entertainment Applications for AI Smart Wearables\n\nThe sport sector is faced with challenges due to the huge size of monitoring equipment. The monitoring equipment is not movable, making it difficult to monitor the health of an athlete during sport. The performance analysis of the sport activities is also a major challenge. The utilization of wearables by athletes helps to provide a record of sport activities to the computer for the detection and analysis of sport motion. The authors in (Xia et al., 2020 [57]) proposed a wearable-based Internet of Things device that can monitor and identify changes in an athlete’s heart rate during sport. The information, such as heart rate, body temperature, and blood oxygen, were collected and analysed.\n\nThe authors in (Hsu et al., 2019 [58]) presented a deep convolution neural network-based wearable device for classifying sport activities. The approach comprises two wearable sensor units that athletes wear on their wrists and ankles to enable the collection of data during sport activities. The information collected from the sensing unit is sent to the personal computer through the wireless RF transmission for sport analysis. The sensing unit in the wearable device consists of the microcontroller, triaxial accelerometer, RF wireless transmission module, triaxial gyroscope, and the power supply circuit. The convolution neural network used in the wearable helps to collect the features from the sport activities. The authors also introduced a deep learning-based algorithm for identifying the various types of sport activities. The proposed algorithm is made up of the following components: (1) first, the data from sport activities; (2) second, the data pre-processing; (3) third, the sport activity segmentation; (4) fourth, the signal normalization; (5) fifth, the spectrogram generation; (6) sixth, the image resizing; and (7) seventh, the convolution neural network classifier.\n\nThe authors in (Chiang et al., 2020 [59]) presented a low-cost wearable device that utilizes a machine learning approach to monitor an athlete’s body conditioning. The authors in (Seethi & Bharti, 2020 [60]) proposed a wrist-worn wearable device that recognizes the healthy lifestyle of humans. A convolution neural network algorithm was used to measure the physical activities required to achieve a good fitness level. The experiment was conducted using 15 people carrying out physical activities such as walking and running with various speeds on a treadmill. The authors in (Mahmud et al., 2021 [61]) proposed a multi-stage training method that utilizes a deep neural network for detecting human activities.\n\n5.4. Environmental and Smart City Applications for AI Smart Wearables\n\nAI and smart wearable technologies can also be utilized for environmental and smart city applications. The authors in (Balsamo et al., 2017 [62]) discussed the open challenges of wearable devices and autonomous computing systems for smart city scenarios. The authors in (Kyriazis et al., 2013 [63]) provided some discussions on using AI smart wearables for controlling and optimizing the heat and electricity resource management systems in smart buildings. On an individual scale, smart wearable technologies can be deployed to give authorization and access to shared appliances and living areas such as hostels, student accommodation, and dormitories.\n\n6. Challenges for AI Smart Wearables and Future Research Directions\n\nThe previous sections have discussed the benefits and potential of AI and smart wearable technologies. This section will provide discussions on some of the challenges and future research directions for AI smart wearables. The challenges will be discussed from two perspectives: (1) technical challenges; and (2) social challenges.\n\n6.1. Technical Challenges for AI Smart Wearables\n\nThe authors in (Schnell et al., 2022 [64]) identified several technical challenges for wearable devices in medical Internet-of-Things applications, of which are also applicable to wearable devices and for smart AI devices in general, such as battery consumption, high energy efficiency, and the need for data privacy and security. Other technology-related aspects and challenges for smart wearables and AI can be categorized into three main aspects: (1) networking and communication aspects, such as issues for routing and communication overheads; (2) information processing and computational aspects, such as issues for computational complexity and storage; and (3) algorithmic and application-dependent aspects, such as training and inference.\n\nThe first two aspects for networking and communication aspects, and algorithmic and application-dependent aspects share similar challenges with the challenges for application-specific Internet of Things (ASIoTs). The authors in (Ang et al., 2019 [65]) identified several challenges for the ASIoTs, including interoperability challenges, energy efficiency challenges, computational challenges using edge and fog machine learning models and security and privacy challenges. The reader is referred to the above two references for further details on challenges for networking and communication aspects, and algorithmic and application-dependent aspects for AI and smart wearable technologies.\n\nThe third challenge on algorithmic and application-dependent aspects applies directly to smart wearables with AI technologies and machine learning. First, as with machine learning and deep learning algorithms, there is a requirement for training the AI algorithms in the wearable technologies. The issues involved here are the need for a large amount of data, particularly for training deep learning algorithms. This would in turn require a significant investment in recruiting people to perform the required tasks or actions while using the wearable devices in order to obtain the authentic training data. The subjects or people may also need to be immersed in the actual operational environment (in contrast to a controlled or laboratory environment) during the training sessions. A further challenge at the algorithmic level is to optimize the usage of multimodal data to obtain higher performance and accuracy for the smart AI wearables. As an example, a smart wearable system for activity recognition could integrate sensing data from multiple devices such as a smart watch, smart clothes, and smart helmets.\n\n6.2. Social Challenges for AI Smart Wearables\n\nAI smart wearables would also face social challenges for the successful adoption to human society. The authors in (Xing et al., 2021 [66]) identified several socio-technical challenges or barriers which affect the large-scale deployment of AI-enabled wearable medical devices among the elderly population in China. The authors provided six categories for barriers or challenges to be addressed: (1) technological barriers or challenges, (2) managerial barriers or challenges, (3) clinical barriers or challenges, (4) financial barriers or challenges, (5) legal barriers or challenges, and (6) personal barriers or challenges.\n\nThe technological barriers for the design and development of the wearables include the trade-offs among designing the wearable device to be small and compact in order to be worn comfortably, designing the device to provide accurate readings, designing the device to have a long battery life, and designing the device to be cost-effective and affordable. The solution proposed by the authors is to design and develop the wearable devices to meet the specific requirements and needs. The managerial barriers include the need for the support from top management and for wearable device providers to establish the necessary links and official collaborations with public health organizations in order to promote the wearable devices in the marketplace. The clinical barriers include establishing the efficacy and collecting evidence to show the clinical value of the wearable devices. The authors also identified another clinical barrier or challenge due to the fear of undesirable changes in workload by doctors and physicians in public health organizations.\n\nThe financial barriers and challenges include the cost of producing the wearable devices and the development of a sustainable business model. For national and public health organizations, there may be insufficient public funding to support the large volume and demand from the society. The authors identified two legal barriers for the adoption of wearable devices which were the lack of an efficient legislative framework and the lack of instruments for data privacy. This challenge is particularly applicable for elderly users who have concerns regarding the potential legal risks for wearable medical devices. The second legal challenge is the issue for data privacy where elderly users have concerns that the wearable medical devices may have the capability to track personal information such as their movements, locations, and living styles. The personal barriers and challenges include a lack of user trustworthiness, a lack of personalized analytical services, and psychological resistance. Figure 7 shows a summary of the barriers or challenges for AI smart wearables.\n\n6.3. Future Directions for AI Smart Wearables\n\nThe research area of AI and smart wearables is constantly evolving. In this sub-section, we provide some recent innovations in the area and potential future directions for AI smart wearables. New sensing technologies are being invented which can be used to augment AI smart wearables and open up directions for future research. A recent innovation in sensing technologies is the development of e-skin (Li et al., 2022 [67]; Choi, 2022 [68]; Sapra et al., 2023 [69]). The authors in (Choi, 2022 [68]) discuss an electronic skin (e-skin) technology which can transmit health data such as heart and pulse rates without requiring further chips/electronics or batteries. The e-skin is flexible and can be worn on the human body like an electronic version of tape for long periods of time. New applications for AI smart wearables are being proposed. These innovations are applicable to different sectors of society and raises new challenges to be addressed.\n\nAn emerging application and future research direction is aimed at utilizing soft robotics and smart wearable technologies for paediatric assistive devices, thus targeting the market needs for infants (two years old and below). These wearable devices for infants need to address challenges such as fitting smaller body proportions and supporting greater activity levels (Mucchiani et al., 2022 [70]). The authors in (Hijazi et al., 2021 [71]) identified another important future research direction for AI smart wearables—the importance of developing interpretable or explainable AI (XAI) and being able to explain the AI-generated results to human practitioners, of which is particularly critical for health-based applications.\n\n7. Conclusions\n\nThis paper has provided a comprehensive survey of paradigms for AI and smart wearable technologies. The paper aims to serve as a useful reference work on how these new paradigms can be applied to solve new problems and applications in intelligent and sensor-based environments. The review has covered the various deployment types and interfaces for smart wearable and AI technologies. The paper has also provided insights into the various techniques and approaches which have been utilized, such as conventional machine learning and deep learning approaches. The review has also uncovered open challenges which remain to be resolved and provided recommendations for future work. A final note is on the constraints and limitations of the studies covered in this paper. While the authors have endeavoured to cover the published studies in major databases, there may be studies in other archives (e.g., arXiv) which have not been covered in this paper.\n\nAuthor Contributions\n\nConceptualization, K.P.S. and L.-M.A.; resources, K.P.S. and L.-M.A.; writing—original draft preparation, K.P.S., L.-M.A., E.P. and A.M.; writing—review and editing, K.P.S., L.-M.A., E.P. and A.M. All authors have read and agreed to the published version of the manuscript.\n\nFunding\n\nThis research received no external funding.\n\nData Availability Statement\n\nData sharing not applicable.\n\nConflicts of Interest\n\nThe authors declare no conflict of interest.\n\nReferences\n\nBianchi, M.T. Sleep devices: Wearables and nearables, informational and interventional, consumer and clinical. Metabolism 2018, 84, 99–108. [Google Scholar] [CrossRef] [PubMed]\n\nMoshawrab, M.; Adda, M.; Bouzouane, A.; Ibrahim, H.; Raad, A. Smart Wearables for the Detection of Occupational Physical Fatigue: A Literature Review. Sensors 2022, 22, 7472. [Google Scholar] [CrossRef]\n\nPierleoni, P.; Belli, A.; Palma, L.; Pellegrini, M.; Pernini, L.; Valenti, S. A high reliability wearable device for elderly fall detection. IEEE Sens. J. 2015, 15, 4544–4553. [Google Scholar] [CrossRef]\n\nZamkah, A.; Hui, T.; Andrews, S.; Dey, N.; Shi, F.; Sherratt, R.S. Identification of suitable biomarkers for stress and emotion detection for future personal affective wearable sensors. Biosensors 2020, 10, 40. [Google Scholar] [CrossRef] [Green Version]\n\nNagl, L.; Schmitz, R.; Warren, S.; Hildreth, T.S.; Erickson, H.; Andresen, D. Wearable sensor system for wireless state-of-health determination in cattle. In Proceedings of the 25th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (IEEE Cat. No. 03CH37439), Cancun, Mexico, 17–21 September 2003; Volume 4, pp. 3012–3015. [Google Scholar]\n\nNeethirajan, S. Recent advances in wearable sensors for animal health management. Sens. Bio-Sens. Res. 2017, 12, 15–29. [Google Scholar] [CrossRef] [Green Version]\n\nMichalski, R.S.; Carbonell, J.G.; Mitchell, T.M. (Eds.) Machine Learning: An Artificial Intelligence Approach; Springer Science & Business Media: Berlin/Heidelberg, Germany, 2013. [Google Scholar]\n\nGoodfellow, I.; Bengio, Y.; Courville, A. Deep Learning; MIT Press: Cambridge, MA, USA, 2016. [Google Scholar]\n\nSeng, J.K.P.; Ang, K.L.M. Big feature data analytics: Split and combine linear discriminant analysis (SC-LDA) for integration towards decision making analytics. IEEE Access 2017, 5, 14056–14065. [Google Scholar] [CrossRef]\n\nBiau, G.; Scornet, E. A random forest guided tour. Test 2016, 25, 197–227. [Google Scholar] [CrossRef] [Green Version]\n\nRamanujam, E.; Perumal, T.; Padmavathi, S. Human activity recognition with smartphone and wearable sensors using deep learning techniques: A review. IEEE Sens. J. 2021, 21, 13029–13040. [Google Scholar] [CrossRef]\n\nde Quadros, T.; Lazzaretti, A.E.; Schneider, F.K. A movement decomposition and machine learning-based fall detection system using wrist wearable device. IEEE Sens. J. 2018, 18, 5082–5089. [Google Scholar] [CrossRef]\n\nShashikumar, S.P.; Shah, A.J.; Li, Q.; Clifford, G.D.; Nemati, S. A deep learning approach to monitoring and detecting atrial fibrillation using wearable technology. In Proceedings of the 2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), Orlando, FL, USA, 16–19 February 2017; pp. 141–144. [Google Scholar]\n\nSarivan, I.-M.; Greiner, J.N.; Alvarez, D.D.; Euteneuer, F.; Reichenbach, M.; Madsen, O.; Bøgh, S. Enabling Real-Time Quality Inspection in Smart Manufacturing through Wearable Smart Devices and Deep Learning. Procedia Manuf. 2020, 51, 373–380. [Google Scholar] [CrossRef]\n\nCosta, A.; Rincon, J.A.; Carrascosa, C.; Julian, V.; Novais, P. Emotions detection on an ambient intelligent system using wearable devices. Future Gener. Comput. Syst. 2019, 92, 479–489. [Google Scholar] [CrossRef] [Green Version]\n\nDesai, K.; Mane, P.; Dsilva, M.; Zare, A.; Shingala, P.; Ambawade, D. A novel machine learning based wearable belt for fall detection. In Proceedings of the 2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON), Greater Noida, India, 2–4 October 2020; pp. 502–505. [Google Scholar]\n\nZurbuchen, N.; Bruegger, P.; Wilde, A. A Comparison of Machine Learning Algorithms for Fall Detection using Wearable Sensors. In Proceedings of the 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), Fukuoka, Japan, 19–21 February 2020; pp. 427–431. [Google Scholar]\n\nZhao, K.; Jiang, H.; Yuan, T.; Zhang, C.; Jia, W.; Wang, Z. A CNN Based Human Bowel Sound Segment Recognition Algorithm with Reduced Computation Complexity for Wearable Healthcare System. In Proceedings of the 2020 IEEE International Symposium on Circuits and Systems (ISCAS), Seville, Spain, 12–14 October 2020; pp. 1–5. [Google Scholar] [CrossRef]\n\nZhao, K.; Feng, S.; Jiang, H.; Wang, Z.; Chen, P.; Zhu, B.; Duan, X. A Binarized CNN-Based Bowel Sound Recognition Algorithm With Time-Domain Histogram Features for Wearable Healthcare Systems. IEEE Trans. Circuits Syst. II Express Briefs 2022, 69, 629–633. [Google Scholar] [CrossRef]\n\nAlZubi, A.A.; Alarifi, A.; Al-Maitah, M. Deep Brain Simulation Wearable IoT Sensor Device Based Parkinson Brain Disorder Detection Using Heuristic Tubu Optimized Sequence Modular Neural Network. Measurement 2020, 161, 107887. [Google Scholar] [CrossRef]\n\nLu, Z.; Narayan, A.; Yu, H. A Deep Learning Based End-to-End Locomotion Mode Detection Method for Lower Limb Wearable Robot Control. In Proceedings of the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems, Las Vegas, NV, USA, 24 October 2020–24 January 2021; p. 4091. [Google Scholar]\n\nChaudhuri, T.; Soh, Y.C.; Li, H.; Xie, L. Machine Learning Driven Personal Comfort Prediction by Wearable Sensing of Pulse Rate and Skin Temperature. Build. Environ. 2020, 170, 106615. [Google Scholar] [CrossRef]\n\nRubio-Solis, A.; Panoutsos, G.; Beltran-Perez, C.; Martinez-Hernandez, U. A Multilayer Interval Type-2 Fuzzy Extreme Learning Machine for the Recognition of Walking Activities and Gait Events Using Wearable Sensors. Neurocomputing 2020, 389, 42–54. [Google Scholar] [CrossRef]\n\nSaeedi, R.; Norgaard, S.; Gebremedhin, A.H. A Closed-loop Deep Learning Architecture for Robust Activity Recognition using Wearable Sensors. In Proceedings of the 2017 IEEE International Conference on Big Data (Big Data), Boston, MA, USA, 11–14 December 2017; p. 473. [Google Scholar]\n\nYoung, F.; Zhang, L.; Jiang, R.; Liu, H.; Wall, C. A Deep learning based wearable healthcare iot device for ai-enabled hearing assistance automation. In Proceedings of the 2020 International Conference on Machine Learning and Cybernetics (ICMLC), Adelaide, Australia, 2 December 2020; pp. 235–240. [Google Scholar]\n\nJacobson, N.C.; Lekkas, D.; Huang, R.; Thomas, N. Deep Learning Paired with Wearable Passive Sensing Data Predicts Deterioration in Anxiety Disorder Symptoms across 17–18 Years. J. Affect. Disord. 2021, 282, 104–111. [Google Scholar] [CrossRef] [PubMed]\n\nBauer, Z.; Dominguez, A.; Cruz, E.; Gomez-Donoso, F.; Orts-Escolano, S.; Cazorla, M. Enhancing Perception for the Visually Impaired with Deep Learning Techniques and Low-Cost Wearable Sensors. Pattern Recognit. Lett. 2020, 137, 27–36. [Google Scholar] [CrossRef]\n\nJanarthanan, R.; Doss, S.; Baskar, S. Optimized Unsupervised Deep Learning Assisted Reconstructed Coder in the On-Nodule Wearable Sensor for Human Activity Recognition. Measurement 2020, 164, 108050. [Google Scholar] [CrossRef]\n\nAlarifi, A.; Alwadain, A. Killer Heuristic Optimized Convolution Neural Network-Based Fall Detection with Wearable IoT Sensor Devices. Measurement 2021, 167, 108258–108266. [Google Scholar] [CrossRef]\n\nHernandez, V.; Dadkhah, D.; Babakeshizadeh, V.; Kulić, D. Lower Body Kinematics Estimation from Wearable Sensors for Walking and Running: A Deep Learning Approach. Gait Posture 2021, 83, 185–193. [Google Scholar] [CrossRef]\n\nRad, N.M.; Kia, S.M.; Zarbo, C.; Laarhoven, T.V.; Jurman, G.; Venuti, P.; Furlanello, C. Deep Learning for Automatic Stereotypical Motor Movement Detection Using Wearable Sensors in Autism Spectrum Disorders. arXiv 2017, arXiv:1709.05956. [Google Scholar]\n\nMai, N.-D.; Long, N.M.; Chung, W.-Y. 1D-CNN-based BCI system for detecting Emotional states using a Wireless and Wearable 8-channel Custom-designed EEG Headset. In Proceedings of the 2021 IEEE International Conference on Flexible and Printable Sensors and Systems (FLEPS), Manchester, UK, 20–23 June 2021; pp. 1–4. [Google Scholar]\n\nZhang, X.; Kou, W.; Chang, E.I.-C.; Gao, H.; Fan, Y.; Xu, Y. Sleep Stage Classification Based on Multi-Level Feature Learning and Recurrent Neural Networks via Wearable Device. arXiv 2017, arXiv:1711.00629. [Google Scholar] [CrossRef] [PubMed] [Green Version]\n\nTorti, E.; Fontanella, A.; Musci, M.; Blago, N.; Pau, D.; Leporati, F.; Piastra, M. Embedding Recurrent Neural Networks in Wearable Systems for Real-Time Fall Detection. Microprocess. Microsyst. 2019, 71, 102895. [Google Scholar] [CrossRef]\n\nMartindale, C.F.; Christlein, V.; Klumpp, P.; Eskofier, B.M. Wearables-Based Multi-Task Gait and Activity Segmentation Using Recurrent Neural Networks. Neurocomputing 2021, 432, 250–259. [Google Scholar] [CrossRef]\n\nCoutts, L.V.; Plans, D.; Brown, A.W.; Collomosse, J. Deep Learning with Wearable Based Heart Rate Variability for Prediction of Mental and General Health. J. Biomed. Inform. 2020, 112, 103610. [Google Scholar] [CrossRef]\n\nChung, S.; Lim, J.; Noh, K.J.; Kim, G.; Jeong, H. Sensor data acquisition and multimodal sensor fusion for human activity recognition using deep learning. Sensors 2019, 19, 1716. [Google Scholar] [CrossRef] [Green Version]\n\nXia, K.; Huang, J.; Wang, H. LSTM-CNN architecture for human activity recognition. IEEE Access 2020, 8, 56855–56866. [Google Scholar] [CrossRef]\n\nRueda, F.M.; Ludtke, S.; Schroder, M.; Yordanova, K.; Kirste, T.; Fink, G.A. Combining symbolic reasoning and deep learning for human activity recognition. In Proceedings of the 2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), Kyoto, Japan, 11–15 March 2019; pp. 22–27. [Google Scholar]\n\nMukherjee, D.; Mondal, R.; Singh, P.K.; Sarkar, R.; Bhattacharjee, D. EnsemConvNet: A deep learning approach for human activity recognition using smartphone sensors for healthcare applications. Multimed. Tools Appl. 2020, 79, 31663–31690. [Google Scholar] [CrossRef]\n\nAscioglu, G.; Senol, Y. Design of a wearable wireless multi-sensor monitoring system and application for activity recognition using deep learning. IEEE Access 2020, 8, 169183–169195. [Google Scholar] [CrossRef]\n\nOrfanidis, C.; Hassen, R.B.H.; Kwiek, A.; Fafoutis, X.; Jacobsson, M. A Discreet Wearable Long-Range Emergency System Based on Embedded Machine Learning. In Proceedings of the 2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops), Kassel, Germany, 22–26 March 2021; pp. 182–187. [Google Scholar]\n\nRavì, D.; Wong, C.; Lo, B.; Yang, G.Z. A Deep Learning Approach to on-Node Sensor Data Analytics for Mobile or Wearable Devices. IEEE J. Biomed. Health Inform. 2017, 21, 56–64. [Google Scholar] [CrossRef] [Green Version]\n\nRakhman, A.Z.; Nugroho, L.E. Fall detection system using accelerometer and gyro-scope based on smartphone. In Proceedings of the 1st International Conference on Information Technology, Computer, and Electrical Engineering, Semarang, Indonesia, 8 November 2014; pp. 99–104. [Google Scholar]\n\nYin, H.; Jha, N.K. A Health Decision Support System for Disease Diagnosis Based on Wearable Medical Sensors and Machine Learning Ensembles. IEEE Trans. Multi-Scale Comput. Syst. 2017, 3, 228–241. [Google Scholar] [CrossRef]\n\nKalantarian, H.; Alshurafa, N.; Nemati, E.; Le, T.; Sarrafzadeh, M. A smartwatch-based medication adher-ence system. In Proceedings of the 2015 IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks (BSN), Cambridge, MA, USA, 9–12 June 2015; pp. 1–6. [Google Scholar]\n\nFozoonmayeh, D.; Le, H.V.; Wittfoth, E.; Geng, C.; Ha, N.; Wang, J.; Vasilenko, M.; Ahn, Y.; Wood-bridge, D.M.-K. A scalable smartwatch-based medication intake detection system using distributed machine learning. J. Med. Syst. 2020, 44, 76. [Google Scholar] [CrossRef] [PubMed]\n\nLee, U.; Han, K.; Cho, H.; Chung, K.-M.; Hong, H.; Lee, S.-J.; Carroll, J.M. Intelligent positive computing with mobile, wearable, and IoT devices: Literature review and research directions. Ad Hoc Netw. 2019, 83, 8–24. [Google Scholar] [CrossRef]\n\nGao, F.; Wang, L.; Lin, T. Intelligent wearable rehabilitation robot control system based on mobile communication network. Comput. Commun. 2020, 153, 286–293. [Google Scholar] [CrossRef]\n\nHong, Z.; Hong, M.; Wang, N.; Ma, Y.; Zhou, X.; Wang, W. A wearable-based posture recognition system with AI-assisted approach for healthcare IoT. Future Gener. Comput. Syst. 2022, 127, 286–296. [Google Scholar] [CrossRef]\n\nTao, Y.; Qian, H.; Chen, M.; Shi, X.; Xu, Y. A real-time intelligent shoe system for fall detection. In Proceedings of the 2011 IEEE iIternational Conference on Robotics and Biomimetics (ROBIO 2011), Karon Beach, Thailand, 7–11 December 2011; pp. 2253–2258. [Google Scholar]\n\nAli, F.; El-Sappagh, S.; Islam, S.R.; Ali, A.; Attique, M.; Imran, M.; Kwak, K.S. An intelligent healthcare monitoring framework using wearable sensors and social networking data. Future Gener. Comput. Syst. 2021, 114, 23–43. [Google Scholar] [CrossRef]\n\nRamkumar, P.N.; Haeberle, H.S.; Ramanathan, D.; Cantrell, W.A.; Navarro, S.M.; Mont, M.A.; Bloomfield, M.; Patterson, B.M. Remote Patient Monitoring Using Mobile Health for Total Knee Arthroplasty: Validation of a Wearable and Machine Learning Based Surveillance Platform. J. Arthroplast. 2019, 34, 2253–2259. [Google Scholar] [CrossRef]\n\nVos, M.D.; Prince, J.; Buchanan, T.; FitzGerald, J.J.; Antoniades, C.A. Discriminating Progressive Supranuclear Palsy from Parkinson’s Disease Using Wearable Technology and Machine Learning. Gait Posture 2020, 77, 257–263. [Google Scholar] [CrossRef]\n\nMeyer, B.M.; Tulipani, L.J.; Gurchiek, R.D.; Allen, D.A.; Adamowicz, L.; Larie, D.; Solomon, A.J.; Cheney, N.; McGinnis, R.S. Wearables and Deep Learning Classify Fall Risk From Gait in Multiple Sclerosis. IEEE J. Biomed. Health Inform. 2021, 15, 1824–2831. [Google Scholar] [CrossRef]\n\nPark, K.-B.; Kim, M.; Choi, S.H.; Lee, J.Y. Deep Learning-Based Smart Task Assistance in Wearable Augmented Reality. Robot. Comput. -Integr. Manuf. 2020, 63, 101887. [Google Scholar] [CrossRef]\n\nXia, N.; Yu, W.; Han, X. Wearable Heart Rate Monitoring Intelligent Sports Bracelet Based on Internet of Things. Measurement 2020, 164, 108102. [Google Scholar] [CrossRef]\n\nHsu, Y.-L.; Chang, H.-C.; Chiu, Y.-J. Wearable Sport Activity Classification Based on Deep Convolutional Neural Network. IEEE 2019, 7, 170199–170210. [Google Scholar] [CrossRef]\n\nChiang, Y.-Y.; Shih, W.-Y.; Chen, W.-H.; Huang, J.-L.; Shiang, T.-Y. A Machine Learning-Based Countermovement Performance Measurement Method Using a Wearable IMU. In Proceedings of the 2020 International Conference on Pervasive Artificial Intelligence (ICPAI), Taipei, Taiwan, 3–5 December 2020; pp. 1–7. [Google Scholar]\n\nSeethi, V.D.; Bharti, P. CNN-based Speed Detection Algorithm for Walking and Running using Wrist-worn Wearable Sensors. In Proceedings of the 2020 IEEE International Conference on Smart Computing (SMARTCOMP), Bologna, Italy, 14–17 September 2020; pp. 1–6. [Google Scholar]\n\nMahmud, T.; Sayyed, A.Q.; Fattah, S.A.; Kung, S.-Y. A Novel Multi-Stage Training Approach for Human Activity Recognition from Multimodal Wearable Sensor Data Using Deep Neural Network. IEEE Sens. J. 2021, 21, 1715–1726. [Google Scholar] [CrossRef]\n\nBalsamo, D.; Merrett, G.V.; Zaghari, B.; Wei, Y.; Ramchurn, S.; Stein, S.; Weddell, A.S.; Beeby, S. Wearable and autonomous computing for future smart cities: Open challenges. In Proceedings of the 2017 25th International Conference on Software, Telecommunications and Computer Networks (SoftCOM), Split, Croatia, 21–26 September 2017; p. 15. [Google Scholar]\n\nKyriazis, D.; Varvarigou, T.; White, D.; Rossi, A.; Cooper, J. Sustainable smart city IoT applications: Heat and electricity management & eco-conscious cruise control for public transportation. In Proceedings of the 2013 IEEE 14th International Symposium on “A World of Wireless, Mobile and Multimedia Networks (WoWMoM), Madrid, Spain, 4–7 June 2013; p. 15. [Google Scholar]\n\nSchnell, B.; Moder, P.; Ehm, H.; Konstantinov, M.; Ismail, M. Challenges in smart health applications using wearable medical Internet-of-Things—A review. In Proceedings of the Sixth International Congress on Information and Communication Technology: ICICT 2021, London, UK, 25–26 February 2021; Springer: Singapore, 2022; Volume 3, pp. 283–296. [Google Scholar]\n\nAng, K.L.M.; Seng, J.K.P. Application specific internet of things (ASIoTs): Taxonomy, applications, use case and future directions. IEEE Access 2019, 7, 56577–56590. [Google Scholar] [CrossRef]\n\nXing, F.; Peng, G.; Zhang, B.; Li, S.; Liang, X. Socio-technical barriers affecting large-scale deployment of AI-enabled wearable medical devices among the ageing population in China. Technol. Forecast. Soc. Chang. 2021, 166, 120609. [Google Scholar] [CrossRef]\n\nLi, W.D.; Ke, K.; Jia, J.; Pu, J.H.; Zhao, X.; Bao, R.Y.; Yang, W. Recent Advances in Multiresponsive Flexible Sensors towards E-skin: A Delicate Design for Versatile Sensing. Small 2022, 18, 2103734. [Google Scholar] [CrossRef]\n\nChoi, C.Q. E-Skin Sensors Go Chipless and Batteryless-Flexible, Wearable Devices Promise VR and Medical-Monitoring Applications. IEEE Spectrum (Online). 2022. Available online: https://spectrum.ieee.org/electronic-skin-chipless-batteryless (accessed on 18 February 2023).\n\nSapra, S.; Chakraborthy, A.; Nuthalapati, S.; Nag, A.; Inglis, D.W.; Mukhopadhyay, S.C.; Altinsoy, M.E. Printed, wearable e-skin force sensor array. Measurement 2023, 206, 112348. [Google Scholar] [CrossRef]\n\nMucchiani, C.; Liu, Z.; Sahin, I.; Dube, J.; Vu, L.; Kokkoni, E.; Karydis, K. Closed-loop position control of a pediatric soft robotic wearable device for upper extremity assistance. In Proceedings of the 2022 31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), Napoli, Italy, 29 August–2 September 2022; pp. 1514–1519. [Google Scholar]\n\nHijazi, H.; Abu Talib, M.; Hasasneh, A.; Bou Nassif, A.; Ahmed, N.; Nasir, Q. Wearable devices, smartphones, and interpretable artificial intelligence in combating COVID-19. Sensors 2021, 21, 8424. [Google Scholar] [CrossRef]\n\nFigure 1. Overview of the smart wristband with iGenda (Costa et al., 2019 [15]).\n\nFigure 2. The wearable bowel sound system of surveillance (Zhao et al., 2022 [19]).\n\nFigure 3. The architectural view of the stereotypical motor movement (SMM) detection (Rad et al., 2018 [31]).\n\nFigure 4. Proposed sleep stage wearable method (Zhang et al., 2018 [33]).\n\nFigure 5. Architectural overview of the healthcare monitoring system (Ali et al., 2021 [52]).\n\nFigure 6. Architectural view of deep learning-based wearable AR (Park et al., 2020 [56]).\n\nFigure 7. Barriers or challenges for AI smart wearables (Xing et al., 2021 [66]).\n\nTable 1. Classification descriptors for machine learning and AI technologies for smart wearables.\n\nClassification DescriptorReferencesSmart Wearable TechnologiesSmart wearable wristbands and bracelets for AI smart wearables[12,13,14,15]Smart wearable waist devices and belts for AI smart wearables[16,17]Smart wearable bowel recorder devices for AI smart wearables[18,19]Smart wearable neural interfaces for AI smart wearables[20]Smart Wearables Empowered by Machine Learning and AIMachine learning for AI smart wearable technologies[21,22,23]Deep learning for AI smart wearable technologies[24,25,26,27,28] Convolutional neural networks (CNNs) for AI smart wearables[29,30,31,32] Recurrent neural network (RNN) for AI smart wearables[33,34,35,36] Long short-term networks (LSTMs) for AI smart wearables[37,38] Hybrid deep learning approaches for AI smart wearables[39,40,41,42]Data Collection Architectures and Information Processing for AI Smart WearablesStandalone architectures for AI smart wearables[43,44,45]Smartphone and smartwatch architectures for AI smart wearables[46,47,48,49,50]IoT and cloud architectures for AI smart wearables[51,52,53,54]Applications for AI Smart WearablesHealthcare and medical applications for AI smart wearables[55,56,57,58,59]Virtual/augmented reality applications for AI smart wearables[60]Sports and entertainment applications for AI smart wearables[61,62,63,64,65]Environment and smart city applications for AI smart wearables[66,67]Challenges and Future Research for AI Smart WearablesTechnical challenges for AI smart wearables[68,69]Social challenges for AI smart wearables[70]Future research directions for AI smart wearables[71]\n\nTable 2. Some representative works on wearable and smart device technologies.\n\nCategory/Domain AreaYearMain ContributionsReferenceResearch works for smart wearable wristbands and bracelet technologies2018Wrist wearable device for elderly fall detection—three sensor types (accelerometer, gyroscope and magnetometer), three signal types (acceleration, velocity and displacement), and two direction components (vertical and non-vertical).Quadros et al., 2018 [12]2017Wrist-worn wearable device for classification of atrial fibrillation (AF)—deep neural network classification from pulsatile photoplethysmography (PPG) signals, wavelet, and convolution neural network.Shashikumar et al., 2017 [13]2020Wearable smart device with the convolution neural network for real-time quality inspections in the smart manufacturing industry; classifies a worker’s actions based on acoustic and accelerometer data. Sarivan et al., 2020 [14]2019Smart wristband with iGenda to recognize the emotional states of human beings, especially elderly people; neural networks and the PAD method to interpret bio-signals into emotion.Costa et al., 2019, [15]Research works for smart wearable waist device and belt technologies2020Wearable belt device for fall detection using machine learning and signal processing; IMU sensor unit with an inbuilt combination of an accelerometer and gyroscope.Desai et al., 2020 [16]2020Waist wearable device—combined an accelerometer with a waist-mounted gyroscope; the machine learning algorithms utilized were ensemble learning, random forest, and gradient boosting.Zurbuchen et al., 2020 [17]Research works for smart wearable bowel recorder technologies 2020The edge bowel sound (BS) wearable system aimed at selecting idle BS events while effectively eliminating audio segments that contain only background information noise such as voice and white Gaussian noise.Zhao et al., 2020 [18]2022Lightweight BS recognizer for use with a convolutional neural network (CNN) portable system.Zhao et al., 2022 [19]Research works for smart wearable neural interface technologies2020HTSMNN (heuristic tubu optimized sequence modular neural network) smart wearable neural interfaces to identify Parkinson’s disease.AlZubi et al., 2020 [20]\n\nDisclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.\n\n© 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).\n\nShare and Cite\n\nMDPI and ACS Style\n\nSeng, K.P.; Ang, L.-M.; Peter, E.; Mmonyi, A. Machine Learning and AI Technologies for Smart Wearables. Electronics 2023, 12, 1509. https://doi.org/10.3390/electronics12071509\n\nAMA Style\n\nSeng KP, Ang L-M, Peter E, Mmonyi A. Machine Learning and AI Technologies for Smart Wearables. Electronics. 2023; 12(7):1509. https://doi.org/10.3390/electronics12071509\n\nChicago/Turabian Style\n\nSeng, Kah Phooi, Li-Minn Ang, Eno Peter, and Anthony Mmonyi. 2023. \"Machine Learning and AI Technologies for Smart Wearables\" Electronics 12, no. 7: 1509. https://doi.org/10.3390/electronics12071509\n\nNote that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here.\n\nArticle Metrics\n\nNo\n\nNo\n\nArticle Access Statistics\n\nFor more information on the journal statistics, click here.\n\nMultiple requests from the same IP address are counted as one view."
    }
}