{
    "id": "dbpedia_8307_1",
    "rank": 59,
    "data": {
        "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform",
        "read_more_link": "",
        "language": "en",
        "title": "Introduction to Vertex AI",
        "top_image": "https://cloud.google.com/_static/cloud/images/social-icon-google-cloud-1200-630.png",
        "meta_img": "https://cloud.google.com/_static/cloud/images/social-icon-google-cloud-1200-630.png",
        "images": [
            "https://www.gstatic.com/devrel-devsite/prod/v20ab951cf37b43fc7a428ae75ce91d8269f391204ca16525bc8a5ececea0ab56/cloud/images/cloud-logo.svg",
            "https://www.gstatic.com/devrel-devsite/prod/v20ab951cf37b43fc7a428ae75ce91d8269f391204ca16525bc8a5ececea0ab56/cloud/images/cloud-logo.svg",
            "https://cloud.google.com/static/vertex-ai/docs/start/images/ml-workflow.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "https://www.gstatic.com/devrel-devsite/prod/v20ab951cf37b43fc7a428ae75ce91d8269f391204ca16525bc8a5ececea0ab56/cloud/images/favicons/onecloud/favicon.ico",
        "meta_site_name": "Google Cloud",
        "canonical_link": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform",
        "text": "Vertex AI is a machine learning (ML) platform that lets you train and deploy ML models and AI applications, and customize large language models (LLMs) for use in your AI-powered applications. Vertex AI combines data engineering, data science, and ML engineering workflows, enabling your teams to collaborate using a common toolset and scale your applications using the benefits of Google Cloud.\n\nVertex AI provides several options for model training and deployment:\n\nAutoML lets you train tabular, image, text, or video data without writing code or preparing data splits.\n\nCustom training gives you complete control over the training process, including using your preferred ML framework, writing your own training code, and choosing hyperparameter tuning options.\n\nModel Garden lets you discover, test, customize, and deploy Vertex AI and select open-source (OSS) models and assets.\n\nGenerative AI gives you access to Google's large generative AI models for multiple modalities (text, code, images, speech). You can tune Google's LLMs to meet your needs, and then deploy them for use in your AI-powered applications.\n\nAfter you deploy your models, use Vertex AI's end-to-end MLOps tools to automate and scale projects throughout the ML lifecycle. These MLOps tools are run on fully-managed infrastructure that you can customize based on your performance and budget needs.\n\nYou can use the Vertex AI SDK for Python to run the entire machine learning workflow in Vertex AI Workbench, a Jupyter notebook-based development environment. You can collaborate with a team to develop your model in Colab Enterprise, a version of Colaboratory that is integrated with Vertex AI. Other available interfaces include the Google Cloud console, the Google Cloud CLI command line tool, client libraries, and Terraform (limited support).\n\nVertex AI and the machine learning (ML) workflow\n\nThis section provides an overview of the machine learning workflow and how you can use Vertex AI to build and deploy your models.\n\nData preparation: After extracting and cleaning your dataset, perform exploratory data analysis (EDA) to understand the data schema and characteristics that are expected by the ML model. Apply data transformations and feature engineering to the model, and split the data into training, validation, and test sets.\n\nExplore and visualize data using Vertex AI Workbench notebooks. Vertex AI Workbench integrates with Cloud Storage and BigQuery to help you access and process your data faster.\n\nFor large datasets, use Dataproc Serverless Spark from a Vertex AI Workbench notebook to run Spark workloads without having to manage your own Dataproc clusters.\n\nModel training: Choose a training method to train a model and tune it for performance.\n\nTo train a model without writing code, see the AutoML overview. AutoML supports tabular, image, text, and video data.\n\nTo write your own training code and train custom models using your preferred ML framework, see the Custom training overview.\n\nOptimize hyperparameters for custom-trained models using custom tuning jobs.\n\nVertex AI Vizier tunes hyperparameters for you in complex machine learning (ML) models.\n\nUse Vertex AI Experiments to train your model using different ML techniques and compare the results.\n\nRegister your trained models in the Vertex AI Model Registry for versioning and hand-off to production. Vertex AI Model Registry integrates with validation and deployment features such as model evaluation and endpoints.\n\nModel evaluation and iteration: Evaluate your trained model, make adjustments to your data based on evaluation metrics, and iterate on your model.\n\nUse model evaluation metrics, such as precision and recall, to evaluate and compare the performance of your models. Create evaluations through Vertex AI Model Registry, or include evaluations in your Vertex AI Pipelines workflow.\n\nModel serving: Deploy your model to production and get predictions.\n\nDeploy your custom-trained model using prebuilt or custom containers to get real-time online predictions (sometimes called HTTP prediction).\n\nGet asynchronous batch predictions, which don't require deployment to endpoints.\n\nOptimized TensorFlow runtime lets you serve TensorFlow models at a lower cost and with lower latency than open source based prebuilt TTensorFlow serving containers.\n\nFor online serving cases with tabular models, use Vertex AI Feature Store to serve features from a central repository and monitor feature health.\n\nVertex Explainable AI helps you understand how each feature contributes to model prediction (feature attribution) and find mislabeled data from the training dataset (example-based explanation).\n\nDeploy and get online predictions for models trained with BigQuery ML.\n\nModel monitoring: Monitor the performance of your deployed model. Use incoming prediction data to retrain your model for improved performance.\n\nVertex AI Model Monitoring monitors models for training-serving skew and prediction drift and sends you alerts when the incoming prediction data skews too far from the training baseline.\n\nWhat's next"
    }
}