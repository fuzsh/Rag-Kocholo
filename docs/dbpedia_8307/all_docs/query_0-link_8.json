{
    "id": "dbpedia_8307_0",
    "rank": 8,
    "data": {
        "url": "https://www.geeksforgeeks.org/hierarchical-clustering-with-scikit-learn/",
        "read_more_link": "",
        "language": "en",
        "title": "Hierarchical Clustering with Scikit",
        "top_image": "https://media.geeksforgeeks.org/wp-content/cdn-uploads/gfg_200x200-min.png",
        "meta_img": "https://media.geeksforgeeks.org/wp-content/cdn-uploads/gfg_200x200-min.png",
        "images": [
            "https://media.geeksforgeeks.org/gfg-gg-logo.svg",
            "https://media.geeksforgeeks.org/auth-dashboard-uploads/Google-news.svg",
            "https://media.geeksforgeeks.org/wp-content/uploads/20240612230602/download-(57).png",
            "https://media.geeksforgeeks.org/wp-content/uploads/20240612230636/download-(58).png",
            "https://media.geeksforgeeks.org/auth/profile/ofiztyugqsmdavh7vjci",
            "https://media.geeksforgeeks.org/auth-dashboard-uploads/Google-news.svg",
            "https://media.geeksforgeeks.org/auth-dashboard-uploads/new-premium-rbanner-us.png",
            "https://media.geeksforgeeks.org/auth-dashboard-uploads/gfgFooterLogo.png",
            "https://media.geeksforgeeks.org/auth-dashboard-uploads/googleplay.png",
            "https://media.geeksforgeeks.org/auth-dashboard-uploads/appstore.png",
            "https://media.geeksforgeeks.org/auth-dashboard-uploads/suggestChangeIcon.png",
            "https://media.geeksforgeeks.org/auth-dashboard-uploads/createImprovementIcon.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Data Structures",
            "Algorithms",
            "Python",
            "Java",
            "C",
            "C++",
            "JavaScript",
            "Android Development",
            "SQL",
            "Data Science",
            "Machine Learning",
            "PHP",
            "Web Development",
            "System Design",
            "Tutorial",
            "Technical Blogs",
            "Interview Experience",
            "Interview Preparation",
            "Programming",
            "Competitive Programming",
            "Jobs",
            "Coding Contests",
            "GATE CSE",
            "HTML",
            "CSS",
            "React",
            "NodeJS",
            "Placement",
            "Aptitude",
            "Quiz",
            "Computer Science",
            "Programming Examples",
            "GeeksforGeeks Courses",
            "Puzzles",
            "SSC",
            "Banking",
            "UPSC",
            "Commerce",
            "Finance",
            "CBSE",
            "School",
            "k12",
            "General Knowledge",
            "News",
            "Mathematics",
            "Exams"
        ],
        "tags": null,
        "authors": [
            "GeeksforGeeks"
        ],
        "publish_date": "2024-06-12T11:11:48",
        "summary": "",
        "meta_description": "A Computer Science portal for geeks. It contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview Questions.",
        "meta_lang": "en",
        "meta_favicon": "https://media.geeksforgeeks.org/wp-content/cdn-uploads/gfg_favicon.png",
        "meta_site_name": "GeeksforGeeks",
        "canonical_link": "https://www.geeksforgeeks.org/hierarchical-clustering-with-scikit-learn/",
        "text": "Hierarchical clustering is a popular method in data science for grouping similar data points into clusters. Unlike other clustering techniques like K-means, hierarchical clustering does not require the number of clusters to be specified in advance. Instead, it builds a hierarchy of clusters that can be visualized as a dendrogram. In this article, we will explore hierarchical clustering using Scikit-Learn, a powerful Python library for machine learning.\n\nIntroduction to Hierarchical Clustering\n\nHierarchical clustering is a method of cluster analysis that seeks to build a hierarchy of clusters. It is particularly useful when the number of clusters is not known beforehand. The main idea is to create a tree-like structure (dendrogram) that represents the nested grouping of data points.\n\nTypes of Hierarchical Clustering\n\nThere are two main types of hierarchical clustering:\n\nAgglomerative Clustering: Agglomerative clustering is a “bottom-up” approach. It starts with each data point as a single cluster and merges the closest pairs of clusters iteratively until all points are in a single cluster or a stopping criterion is met.\n\nDivisive Clustering: Divisive clustering is a “top-down” approach. It starts with all data points in a single cluster and recursively splits the clusters into smaller ones until each data point is in its own cluster or a stopping criterion is met.\n\nIn this article, we will focus on agglomerative clustering, as it is more commonly used and is well-supported by Scikit-Learn.\n\nHow Hierarchical Clustering Works?\n\nHierarchical clustering involves the following steps:\n\nCalculate the Distance Matrix: Compute the distance between every pair of data points using a distance metric (e.g., Euclidean distance).\n\nMerge Closest Clusters: Identify the two closest clusters and merge them into a single cluster.\n\nUpdate the Distance Matrix: Recalculate the distances between the new cluster and all other clusters.\n\nRepeat: Repeat steps 2 and 3 until all data points are merged into a single cluster or a stopping criterion is met.\n\nDendrograms: Visualizing Hierarchical Clustering\n\nA dendrogram is a tree-like diagram that shows the arrangement of clusters produced by hierarchical clustering. It provides a visual representation of the merging process and helps in determining the optimal number of clusters.\n\nHow to Read a Dendrogram?\n\nLeaves: Represent individual data points.\n\nBranches: Represent clusters formed by merging data points or other clusters.\n\nHeight: Represents the distance or dissimilarity between clusters. The higher the branch, the more dissimilar the clusters.\n\nImplementing Hierarchical Clustering with Scikit-Learn\n\nScikit-Learn provides a straightforward implementation of hierarchical clustering through the AgglomerativeClustering class. Let’s walk through the steps to implement hierarchical clustering using Scikit-Learn.\n\nStep 1: Import Libraries\n\nPython\n\nimport numpy as np import matplotlib.pyplot as plt from sklearn.datasets import make_blobs from sklearn.cluster import AgglomerativeClustering from scipy.cluster.hierarchy import dendrogram, linkage\n\nStep 2: Generate Sample Data\n\nFor demonstration purposes, we will generate synthetic data using the make_blobs function.\n\nPython\n\n# Generate sample data X, y = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n\nStep 3: Perform Agglomerative Clustering\n\nPython\n\n# Perform agglomerative clustering agg_clustering = AgglomerativeClustering(n_clusters=4) y_pred = agg_clustering.fit_predict(X)\n\nStep 4: Plot the Clusters\n\nPython\n\n# Plot the clusters plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='rainbow') plt.title('Agglomerative Clustering') plt.xlabel('Feature 1') plt.ylabel('Feature 2') plt.show()\n\nOutput:\n\nStep 5: Plot the Dendrogram\n\nTo plot the dendrogram, we need to use the linkage function from the scipy.cluster.hierarchy module.\n\nPython\n\n# Generate the linkage matrix Z = linkage(X, method='ward') # Plot the dendrogram plt.figure(figsize=(10, 7)) dendrogram(Z) plt.title('Dendrogram') plt.xlabel('Sample Index') plt.ylabel('Distance') plt.show()\n\nOutput:\n\nAdvantages and Disadvantages of Hierarchical Clustering\n\nAdvantages:\n\nNo Need to Specify Number of Clusters: Unlike K-means, hierarchical clustering does not require the number of clusters to be specified in advance.\n\nDendrogram: Provides a visual representation of the clustering process and helps in determining the optimal number of clusters.\n\nVersatility: Can be used for various types of data and distance metrics.\n\nDisadvantages:\n\nComputational Complexity: Hierarchical clustering can be computationally expensive, especially for large datasets.\n\nSensitivity to Noise: Can be sensitive to noise and outliers, which may affect the clustering results.\n\nLack of Scalability: Not suitable for very large datasets due to its high time complexity.\n\nConclusion\n\nHierarchical clustering is a powerful and versatile clustering technique that builds a hierarchy of clusters without requiring the number of clusters to be specified in advance. Scikit-Learn provides an easy-to-use implementation of hierarchical clustering through the AgglomerativeClustering class. By following the steps outlined in this article, you can perform hierarchical clustering on your own datasets and visualize the results using dendrograms."
    }
}