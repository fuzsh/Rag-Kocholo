{
    "id": "dbpedia_8307_1",
    "rank": 91,
    "data": {
        "url": "https://knowledge.dataiku.com/latest/code/python/tutorial-basics.html",
        "read_more_link": "",
        "language": "en",
        "title": "Tutorial | Code notebooks and recipes #",
        "top_image": "https://knowledge.dataiku.com/latest/_static/img/social-card.png",
        "meta_img": "https://knowledge.dataiku.com/latest/_static/img/social-card.png",
        "images": [
            "https://knowledge.dataiku.com/_static/img/DKU-logo-KNOWLEDGE-WHITE.png",
            "https://knowledge.dataiku.com/_static/img/home-links.png",
            "https://knowledge.dataiku.com/_images/create-notebook-from-dataset.png",
            "https://knowledge.dataiku.com/_images/notebook-starter-code.png",
            "https://knowledge.dataiku.com/_images/edit-starter-code.png",
            "https://knowledge.dataiku.com/_images/edit-notebook-in-dashboard.png",
            "https://knowledge.dataiku.com/_images/create-recipe-from-notebook.png",
            "https://knowledge.dataiku.com/_images/python-recipe-run.png",
            "https://knowledge.dataiku.com/_images/python-notebook-df-head.png",
            "https://knowledge.dataiku.com/_images/python-recipe-final-output.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Learn how to create Jupyter code notebooks and recipes, iterate between them, and deploy notebooks as recipes to a Dataiku Flow.",
        "meta_lang": "en",
        "meta_favicon": "https://www.dataiku.com/static/img/favicon.png",
        "meta_site_name": "Dataiku Knowledge Base",
        "canonical_link": "https://knowledge.dataiku.com/code/getting-started/notebooks-recipes/tutorial-index.html",
        "text": "Get started#\n\nDataiku not only has natively-integrated Jupyter notebooks for experimentation, but also has a way to deploy them as recipes into production workflows.\n\nObjectives#\n\nIn this tutorial, you will:\n\nCreate, edit, publish, and unload Jupyter notebooks.\n\nCreate a code recipe from a notebook.\n\nSync code back and forth between a notebook and a recipe.\n\nRun a code recipe in the Flow.\n\nSee also\n\nThis tutorial only covers the use of Python notebooks and recipes in Dataiku, but the workflow is similar for other languages. See the following for resources on R and SQL.\n\nPrerequisites#\n\nAccess to an instance of Dataiku.\n\nSome familiarity with coding in Python and using Jupyter notebooks.\n\nThe requested permissions for code execution.\n\nYou may also want to review Concept | Code notebooks and Concept | Code recipes.\n\nCreate the project#\n\nThe first step is to create a new Dataiku Project. We will work with a sample project containing data from the fictional Haiku T-Shirt company.\n\nFrom the Dataiku Design homepage, click + New Project > DSS tutorials > Developer > Code Notebooks & Recipes.\n\nFrom the project homepage, click Go to Flow (or g + f).\n\nNote\n\nYou can also download the starter project from this website and import it as a zip file.\n\nUse a code notebook#\n\nGiven their usefulness for data science, Jupyter notebooks are natively embedded in Dataiku and tightly integrated with other components, which makes them easy to use in various ways.\n\nCreate a Jupyter notebook#\n\nDepending on your objectives, you can create a Jupyter notebook in Dataiku in a number of different ways. In this exercise, we will create a notebook from a dataset, which simplifies reading in the dataset of interest using the Dataiku API.\n\nFrom the Flow, select the orders dataset.\n\nIn the right panel, select the Lab menu (with the microscope icon).\n\nIn the Code Notebooks section, click New.\n\nFrom the notebook options, select Python.\n\nName the notebook orders analysis.\n\nClick Create, leaving the default option to read the dataset in memory using Pandas.\n\nInspect a notebook’s starter code#\n\nThe newly created notebook contains some useful starter code:\n\nThe first cell uses the built-in magic commands to import the numpy and matplotlib packages.\n\nThe second cell imports other useful packages, including dataiku.\n\nThe third cell reads in the orders dataset and converts it to a Pandas dataframe.\n\nThe fourth cell contains a function that performs some basic analysis on the columns of the dataset.\n\nImportant\n\nThe starter code of a notebook created from a dataset will have already read in the chosen dataset to a df variable, whether it may be a Pandas, R, or Scala dataframe.\n\nEdit code in a notebook#\n\nYou can edit the starter code as well as write your own code in the same way you would outside of Dataiku.\n\nIn this very simple exercise, we will slightly modify the existing starter code:\n\nDelete limit=100000 from the second line of code in the third cell to remove the default dataset sampling. After removing it, the line of code should look like this:\n\ndf = dataset_orders.get_dataframe()\n\nType df.head() right under the one above. The code in the third cell should now look like this:\n\n# Read the dataset as a Pandas dataframe in memory # Note: here, we only read the first 100K rows. Other sampling options are available dataset_orders = dataiku.Dataset(\"orders\") df = dataset_orders.get_dataframe() df.head()\n\nRun the first three cells to read in the orders dataset and display the first five rows of the dataset.\n\nRun the fourth and last cell (pdu.audit(df)), which is part of the starter code, to display some basic information about the columns of the orders dataset.\n\nClick the Save button (or use the shortcut Ctrl + S / Cmd + S for Mac) to save your progress.\n\nNote\n\nIn addition to datasets, it’s also possible to create Jupyter notebooks from machine learning models. For more information, consult the reference documentation.\n\nPublish a notebook to a dashboard#\n\nFor a collaborative platform like Dataiku, the ability to share work and analyses is of high importance. Dataiku allows you to save static exports (non-interactive snapshots) of Jupyter notebooks in an HTML format, which can be shared on dashboards.\n\nTo share the notebook on a dashboard:\n\nOpen the Actions tab of the notebook.\n\nClick Publish > Dashboard.\n\nClick Create to create the notebook as an insight and publish that insight to the first page of the project’s default dashboard.\n\nIn the dashboard, expand the notebook tile by dragging the corners of the insight.\n\nIn the Tile settings, click Show code to include the code and not just the printed output.\n\nClick Save and then View to see how the notebook insight appears on the dashboard.\n\nNote\n\nPublishing a static snapshot of a notebook to a dashboard also adds it to the list of saved insights. To learn more about sharing Jupyter notebooks as insights, see the reference documentation.\n\nUnload a notebook#\n\nFinally, once you’re done working in a Jupyter notebook for the time being, you can optimize its computational efficiency by killing the kernel. To do this:\n\nNavigate to the Notebooks page (g + n).\n\nCheck the box to select the orders analysis notebook.\n\nIn the right panel, in the Actions tab, click Unload to kill the kernel.\n\nUse a code recipe#\n\nCode notebooks allow for free experimentation, but you’ll need code recipes to build outputs in your Flow.\n\nEdit code in a recipe#\n\nIn the resulting recipe, all the code from the Jupyter notebook has been transferred to the recipe code editor. Notice that Dataiku has added a number of commented out lines, each of which shows the beginning of a notebook cell. This way, if we need to edit the recipe in a notebook again, our existing cells are maintained.\n\nThe editor has also added two lines for the recipe output based on the name of the output dataset we created in the recipe dialog. We’ll discuss this below.\n\nNow let’s group the orders data by unique customers. Although we could accomplish this with a visual Group recipe, it can also be done with code.\n\nComment out the following lines of code:\n\ndf.head()\n\npdu.audit(df)\n\nIn a new line below df = dataset_orders.get_dataframe(), copy-paste the following code:\n\norders_by_customer_df = df.assign(total=df.tshirt_price*df.tshirt_quantity ).groupby(by=\"customer_id\" ).agg({\"pages_visited\":\"mean\", \"total\":\"sum\"})\n\nTip\n\nThis code block creates a new dataframe with rows grouped by customer_id. For each customer, we’ve computed the average number of pages on the Haiku T-shirt website visited by the customer during orders, and the sum total of the value of orders made by the customer, where the value of each order is the price of each t-shirt multiplied by the number of t-shirts purchased.\n\nFinally, Dataiku has added lines for the recipe output. However, it cannot know which dataframe (df or orders_by_customer_df) we want to output as the orders_by_customer dataset. Accordingly:\n\nIn the last line of code, change pandas_dataframe to orders_by_customer_df.\n\nClick Validate to check the validity of the code. It should display Validation successful.\n\nClick Run (or type @ + r + u + n) to execute the recipe, and then explore the output dataset.\n\nIterate between a recipe and a notebook#\n\nNotice that the output dataset orders_by_customer does not contain the customer_id column, even though this was the key we grouped by. We’d like to have it for reference.\n\nLet’s prototype the revised code in the notebook attached to the recipe.\n\nReopen the Python recipe (clicking Parent Recipe is one option).\n\nIn the header, click Edit in Notebook.\n\nClick Override Notebook Content.\n\nImportant\n\nPreviously we edited the recipe without saving the changes back to the recipe, creating this mismatch. Overriding the notebook content re-syncs the recipe and notebook.\n\nNow we can interactively test the recipe code in a notebook.\n\nUncomment the df.head() line and change df to orders_by_customer_df, so that the new line is as follows:\n\norders_by_customer_df.head()\n\nRun the first three cells. The output shows that the orders_by_customer_df dataframe has the customer_id information; however, the dataframe has a hierarchical index.\n\nIn order to flatten the index, add .reset_index() to the code that defines the dataframe so that it looks like the following:\n\norders_by_customer_df = df.assign(total=df.tshirt_price*df.tshirt_quantity ).groupby(by=\"customer_id\" ).agg({\"pages_visited\":\"mean\", \"total\":\"sum\"}).reset_index()\n\nRe-run the third cell to see how the dataframe has changed.\n\nIn the header, click Save Back to Recipe.\n\nComment out orders_by_customer_df.head(), Validate, and Run the recipe again.\n\nNow the output dataset contains a customer_id column.\n\nWhat’s next?#\n\nThis tutorial used the built-in code environment, but often you’ll want to use your own. Learn about code environments in How-to | Create a code environment!\n\nSee also\n\nTo learn more, see the reference documentation on Code notebooks and Recipes based on code."
    }
}