{
    "id": "dbpedia_8307_1",
    "rank": 97,
    "data": {
        "url": "https://docs.mpcdf.mpg.de/faq/hpc_software.html",
        "read_more_link": "",
        "language": "en",
        "title": "HPC Software and Applications — Technical Documentation",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://docs.mpcdf.mpg.de/_static/mpcdflogo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-07-10T11:07:52+02:00",
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "../_static/favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Environment modules\n\nThe MPCDF uses modules to adapt the user environment for working with software installed at various locations in the file system or for switching between different software versions. The user is no longer required to explicitly specify paths for different executable versions, or keep track of PATH, MANPATH and related environment variables. With the modules approach, users simply ‘load’ and ‘unload’ modules to control their environment. Note that since 2018, HPC systems as well as the increasing number of dedicated clusters all use hierarchical environment modules.\n\nHow can I use environment modules interactively?\n\nHere is a list of the most important commands (see https://modules.readthedocs.io/en/latest/module.html for a complete reference):\n\nmodule help: lists module subcommands and switches\n\nmodule avail: lists available software packages and versions which can be enabled (“loaded”) with the module command\n\nmodule help <package>/<version>: provides brief documentation for the specified module.\n\nmodule load <package>/<version>: “loads” the module, i.e. modifies the user’s environment ($PATH, $MANPATH, etc.)\n\nmodule unload <package>/<version>: “unloads” the module\n\nmodule list: lists all modules which are currently loaded in the user’s environment\n\nHow can I use environment modules in scripts?\n\nEnvironment modules are provided by default only in interactive login shells. For non-interactive shells (e.g. in shell scripts or batch scripts) the following system profiles must be explicitly sourced (for Linux, specifically SLES):\n\n/etc/profile.d/modules.sh for sh-derivative shells: sh, bash\n\n/etc/profile.d/modules.csh for csh-derivative shells: csh, tcsh\n\nHow can I use environment modules to avoid absolute paths in my scripts?\n\nInstead of absolute paths to libraries, binaries etc. the environment variables set by the modulefile should be used in scripts, makefiles etc. By convention, an MPCDF modulefile sets an environment variable named <PKG>_HOME (where PKG is the name of the package, for example: MKL_HOME) which points to the root directory of the installation path (see below for example usage). Information about additional, package-specific environment variables can be obtained with the commands module help <package>/<version> and module show <package>/<version>.\n\nExamples\n\nInteractive session on the command line\n\n$ module load intel mkl $ ifort -I$MKL_HOME/include example.F -L$MKL_HOME/lib/intel64 -lmkl_intel_lp64 -lmkl_sequential -lmkl_core\n\nMakefile (fragment)\n\nFC=ifort example:example.F $(FC) -I$(MKL_HOME)/include test.F -L$(MKL_HOME)/lib/intel64 -lmkl_intel_lp64 -lmkl_sequential -lmkl_core\n\nHow can I read the long output from module avail page by page?\n\n# sh/bash shell ( module avail)2>&1| less\n\n# c/tcsh shell ( module avail ) | & less\n\nHow do the hierarchical environment modules work?\n\nTo manage the plethora of software packages resulting from all the relevant combinations of compilers and MPI libraries, we have decided to organize the environment module system for accessing these packages in a natural hierarchical manner. Compilers (gcc, intel) are located on the uppermost level, depending libraries (e.g., MPI) on the second level, more depending libraries on a third level. This means that not all the modules are visible initially: only after loading a compiler module, will the modules depending on this become available. Similarly, loading an MPI module in addition will make the modules depending on the MPI library available.\n\nTo start at the root of the environment modules hierarchy, issue module purge.\n\nFor example, the FFTW library compiled with the default Intel compiler and the default Intel MPI library can be loaded as follows: First, load the default Intel compiler module using the command\n\nmodule load intel\n\nsecond, the default Intel MPI module with\n\nmodule load impi\n\nand, finally, the FFTW module fitting exactly to the compiler and MPI library via\n\nmodule load fftw-mpi\n\nYou may check using the command\n\nmodule available\n\nthat after the first and second steps the depending environment modules become visible, in the present example impi and fftw-mpi. Moreover, note that the environment modules can be loaded via a single ‘module load’ statement as long as the order given by the hierarchy is correct, e.g., ‘module load intel impi fftw-mpi’.\n\nHow do I quickly find a module?\n\nIn case you know the name of the module you wish to load, but you are not sure about the available versions or what dependencies need to be loaded first, you can try to use the ‘find-module’ command. This tool searches for the MODULENAME string through a list of all installed modules\n\nfind-module MODULENAME\n\nYou can then choose the desired module version, use the output of the command to determine the correct order to load dependencies, and finally load the module itself, e.g.\n\n$ find-module horovod horovod/cpu/0.13.11(after loading anaconda/3/2019.03 tensorflow/cpu/1.14.0) $ module load anaconda/3/2019.03 tensorflow/cpu/1.14.0 horovod/cpu/0.13.11\n\nIt is important to point out that a large fraction of the available software is not affected by the hierarchy, e.g., certain HPC applications, tools such as git or cmake, mathematical software (maple, matlab, mathematica), visualization software (visit, paraview, idl) are visible at the uppermost hierarchy. Note that a hierarchy exists for Python modules with the ‘anaconda’ module files on the top level.\n\nHow can I disable the “MPCDF specific note” for module avail?\n\nOn recent installations, the module avail command prints a “MPCDF specific note” that describes how to find nested environment modules in the hierarchy. To disable that note, set the environment variable ‘MPCDF_DISABLE_MODULE_AVAIL_HINT’ to ‘1’, e.g., by adding the line export MPCDF_DISABLE_MODULE_AVAIL_HINT=1 to your ‘.bashrc’ file.\n\nWhy there are no BLAS/LAPACK modules available on the clusters?\n\nIntel’s Math Kernel Library (MKL) library provides highly optimized replacements for the BLAS, Sparse BLAS, LAPACK, ScaLAPACK, PBLAS, and BLACS libraries as well as other math routines. For more information please refer to our MKL guide.\n\nMessage Passing Interface (MPI) Libraries and Runtimes\n\nWhich MPI implementations are supported?\n\nThe MPI library from Intel Parallel Studio XE is supported. In addition, OpenMPI is also provided.\n\nHow can I compile and link my MPI application?\n\nFirst, make sure to have a compiler and an MPI environment module loaded. In case an Intel compiler is used, the commands necessary to compile and link applications read mpiicc, mpiicpc, and mpiifort (for C, C++, and Fortran, respectively). In case a GNU compiler is used, the commands read mpigcc, mpigxx, and mpigfortran, respectively. These commands are in fact wrapper scripts that call the underlying compilers with the correct sets of arguments. The wrappers can be called with option -show in order to double check, e.g. about the underlying compiler.\n\nCMake cannot find MPI, what can I do?\n\nThis sometimes happens when using Intel MPI. To avoid the problem, CMake should be told explicitly which compiler wrappers to use:\n\nFor Intel compilers:\n\n# load compiler and Intel MPI module load intel/... module load impi/2021.x # other preparation steps ... # call CMake specifying MPI wrappers cmake ... -DMPI_C_COMPILER=mpiicx -DMPI_CXX_COMPILER=mpiicpx -DMPI_Fortran_COMPILER=mpiifx ...\n\nPlease note the use of ifx above. If needed, you may still use ifort with intel/2024.0. Separately, if your code uses C/C++ please also ensure to use the correct headers and version of GLIBC.\n\nAlternatively, for GCC:\n\n# load compiler and Intel MPI module load gcc/... module load impi/2021.x # other preparation steps ... # call CMake specifying MPI wrappers cmake ... -DMPI_C_COMPILER=mpigcc -DMPI_CXX_COMPILER=mpig++ -DMPI_Fortran_COMPILER=mpigfortran ...\n\nI cannot launch my MPI code using mpirun, what am I doing wrong?\n\nOn SLURM-based HPC clusters the launcher srun must be used for MPI codes. Production runs and large tests must be run via batch scripts. From a login node, small test runs can be started interactively, e.g. as follows:\n\nsrun --time=00:05:00 --mem=1G --ntasks=2 ./mpi_application\n\nGUI applications\n\nVisual Studio Code (in combination with the Remote-SSH extension) does not work any more on certain HPC clusters\n\nStarting with version 1.86 VSCode requires more recent versions of fundamental libraries that are not provided on older OS such as SLES12 and CentOS7. As a result, users of recent versions of VSCode are not able to connect to systems running one of these OS any more, notably Cobra and some older Linux clusters. Note that this does also affect the Remote-SSH extension even if the GUI is run locally on a Laptop.\n\nAs a workaround, please use the latest VSCode version 1.85.2 with automatic updates disabled, for the time being.\n\nWhy do certain GUI applications not work (any more) on the login nodes of HPC clusters? What are the alternatives?\n\nSome desktop applications are built on top of frameworks that use web technologies to render their graphical user interface (GUI). Examples include web browsers such as Firefox and Chromium, but also text editors and IDEs such as Spyder (using the Qt web framework), VSCode (using the Electron framework based on the Chromium engine), and potentially others.\n\nThese frameworks typically use sandboxing techniques based on Linux user namespaces to potentially increase application security at runtime. Unfortunately, some of these user namespace features are and have been suffering from security issues repeatedly such that they got disabled in mid May 2023 on MPCDF clusters.\n\nTo continue using these applications via X forwarding or via VNC, users can try to disable sandboxing:\n\nQT-based applications, for example certain Spyder versions, can be launched as follows:\n\n$exportQTWEBENGINE_DISABLE_SANDBOX=1 $ spyder&\n\nUsers of Electron-based apps might want to try the --no-sandbox flag when launching the application.\n\nFirefox users can set\n\nexportMOZ_DISABLE_CONTENT_SANDBOX=1MOZ_DISABLE_GMP_SANDBOX=1MOZ_DISABLE_NPAPI_SANDBOX=1MOZ_DISABLE_GPU_SANDBOX=1MOZ_DISABLE_RDD_SANDBOX=1MOZ_DISABLE_SOCKET_PROCESS_SANDBOX=1\n\nbefore launching firefox.\n\nAn environment module nosandbox/1.0 is provided which sets the aforementioned environment variables, so load that before launching Firefox or Spyder.\n\nHowever, a more efficient option would be to avoid running such heavyweight GUI applications remotely and rather launch them locally, and access remote files via sshfs or via builtin features such as the “Remote - SSH” extension for VSCode. Similarly, web browsers can be launched locally and configured to access remote services (such as manually launched Jupyter sessions) via SSH tunnels or the SOCKS5 feature of SSH."
    }
}