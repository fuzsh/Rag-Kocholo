{
    "id": "dbpedia_2670_2",
    "rank": 67,
    "data": {
        "url": "https://www.coastalwiki.org/wiki/Marine_data_portals_and_tools",
        "read_more_link": "",
        "language": "en",
        "title": "Marine data portals and tools",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.coastalwiki.org/w/resources/assets/poweredby_mediawiki_88x31.png",
            "https://www.vliz.be/sites/vliz.be/themes/vliz/img/logo.png",
            "https://piwik.vliz.be/piwik.php?idsite=40&rec=1&action_name=Marine_data_portals_and_tools"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "This article provides an overview of marine data portals, update 2021.\n\nData portals\n\nInternational oceanographic data portals\n\nCopernicus\n\nThe Copernicus Marine Service (or Copernicus Marine Environment Monitoring Service) is the marine component of the Copernicus Programme of the European Union that provides free, regular and systematic information on the state of the ocean, on a global and regional scale. Copernicus offers ocean hindcast (historical) and forecast data. Data comes from satellites, in-situ (direct ocean sampling), and numerical models that cover the global ocean.\n\nIODE\n\nThe IODE system forms a worldwide service oriented network consisting of DNAs (Designated National Agencies), NODCs (National Oceanographic Data Centres), RNODCs (Responsible National Oceanographic Data Centres) and WDCs (World Data Centres – Oceanography). During the past 50 years, IOC Member States have established over 80 oceanographic data centres in as many countries. This network has been able to collect, control the quality of, and archive millions of ocean observations, and makes these available to Member States. A list of marine data repositories is provided.\n\nNCEI\n\nNOAA's National Centers for Environmental Information (NCEI), including the US National Oceanographic Data Center, manages one of the largest archives of atmospheric, coastal, geophysical, and oceanic research in the world. NCEI offers users access to over 26,000 datasets and products. NCEI also hosts the Global Argo Data Repository containing data of the Argo Ocean Profiling Network assembled by the U.S. GODAE (Global Ocean Data Assimilation Experiment) Argo server and the French IFREMER (Institute for Research and Exploitation of the Sea) Argo server, who provide near real-time Argo data.\n\nSEANOE\n\nSEA scieNtific Open data Edition is a publisher of scientific data in the field of marine sciences providing global oceanographic datasets. It is operated by Sismer within the framework of the Odatis. They can be used in accordance with the terms of the Creative Commons license selected by the author of data.\n\nPANGAEA\n\nPANGAEA services are generally open for archiving, publishing, and re-usage of data in the field of earth sciences, mainly dedicated to data of oceanographic ecological surveys. PANGAEA is member of the World Data System and hosted by the Alfred Wegener Institute, Helmholtz Center for Polar and Marine Research (AWI) and the Center for Marine Environmental Sciences, University of Bremen (MARUM).\n\nSHOM\n\nSHOM provides tide forecasts and data of tide gauges worldwide. The SHOM (Service Hydrographique et Océanographique de la Marine) is the public operator for maritime and littoral geographical information in France. SHOM also hosts SONEL, the GNSS data assembly centre for the Global Sea Level Observing System (GLOSS). SONEL provides high-quality continuous measurements of sea- and land levels at the coast from tide gauges (relative sea levels) and from modern geodetic techniques (vertical land motion and absolute sea levels) for studies on long-term sea level trends including the calibration of satellite altimeters. For this, SHOM works together with the UHSLC, the University of Hawaii Sea Level Center, that routinely processes, analyzes, and distributes tide gauge sea level data at varying levels of temporal resolution and quality control.\n\nGEBCO\n\nThe General Bathymetric Chart of the Oceans (GEBCO) is an international group of experts in ocean mapping that creates and makes available a range of bathymetric data sets and data products, including maps showing the shape of the ocean seafloor.\n\nESDD\n\nEarth System Science Data (ESSD) is an international, interdisciplinary journal for the publication of articles on original research data (sets), furthering the reuse of high-quality data of benefit to Earth system sciences.\n\nEnvironmental data repositories\n\nOBIS\n\nThe Ocean Biodiversity Information System provides a comprehensive gateway to the world’s ocean biodiversity and biogeographic data and information. More than 20 OBIS nodes around the world connect 500 institutions from 56 countries. Collectively, they have provided over 45 million observations of nearly 120 000 marine species, from Bacteria to Whales, from the surface to 10 900 meters depth, and from the Tropics to the Poles. The datasets are integrated so you can search and map them all seamlessly by species name, higher taxonomic level, geographic area, depth, time and environmental parameters. OBIS emanates from the Census of Marine Life (2000-2010) and was adopted as a project under IOC-UNESCO’s International Oceanographic Data and Information (IODE) programme in 2009.\n\nEDI\n\nThe Environmental Data Initiative promotes and enables curation and re-use of environmental data. EDI assists researchers from field stations, individual laboratories, and research projects of all sizes to archive and publish their environmental data. EDI is committed to provide general environmental data that is Findable, Accessible, Interoperable, and Reusable (FAIR).\n\nGBIF\n\nThe Global Biodiversity Information Facility is an international network and data infrastructure funded by the world's governments and aimed at providing anyone, anywhere, open access to data about all types of life on Earth. Coordinated through its Secretariat in Copenhagen, the GBIF network of participating countries and organizations, working through participant nodes, provides data-holding institutions around the world with common standards and open-source tools that enable them to share information about where and when species have been recorded.\n\nEuropean marine data portals\n\nEMODNET\n\nThe European Marine Observation and Data Network (EMODnet) is the most important source for European marine environmental data. EMODNET is a network of organisations supported by the EU’s integrated maritime policy that work together to observe the sea, process the data according to international standards and make that information freely available as interoperable data layers and data products. EMODnet provides access to European marine data across seven discipline-based themes: Bathymetry, Geology, Seabed habitats, Chemistry, Biology, Physics and Human activities. For each of these themes, EMODnet has created a gateway to a range of data archives managed by local, national, regional and international organisations. Through these gateways, users have access to standardized observations, data quality indicators and processed data products, such as basin-scale maps. These data products are free to access and use. Available data are being used to create multi-resolution maps of all Europe’s seas and oceans, spanning all seven disciplinary themes.\n\nSeaDataNet\n\nSeaDataNet is a standardized distributed system for managing the large and diverse data sets collected by the European oceanographic fleets and new automatic observation systems. It is a network of major institutes and marine data centres active in data collection from 35 countries bordering the North-East Atlantic, and its adjacent seas: the Mediterranean, the Black Sea, the Baltic, the North Sea and the Arctic. SeaDataNet has developed an efficient distributed Pan-European Marine Data Management Infrastructure for managing these large and diverse data sets and provides integrated databases of standardized quality on-line. National Oceanographic Data Centres, Designated National Agencies for international data exchange and Satellite Data Centres represent the backbone of the marine data and information infrastructure.\n\nCOSYNA\n\nThe Coastal Observing System for Northern and Arctic Seas develops and operates an integrated observing and modelling system suitable for investigating the environmental state and variability of coastal areas, with a focus on the North Sea and Arctic coastal waters. COSYNA aims to provide data and knowledge tools to help evaluate the role of coastal systems for local and regional scientific questions and to provide authorities, industry, and the public with tools to plan and manage routine tasks, respond to emergency situations and to evaluate trends. COSYNA specifically develops scientific products and instruments, and provides its infrastructure to the scientific community.\n\nVLIZ\n\nThe Flanders Marine Institute is host of many international data and information systems: Aphia (Online Worldregister of marine species ), EurOBIS (Integrated management of marine species distribution data, the European node of OBIS), IRMNG (Interim Register of Marine and Nonmarine Genera), EMODnet (Disclosure and visualisation of physical, chemical and biological data) and Coastal Wiki. The Marine Data Archive (MDA) operated by VLIZ is an online repository specifically developed to archive marine data files in a fully documented manner. The MDA can serve individuals, consortia, working groups and institutes for: (i) to manage data files and file versions for a specific context (project, report, analysis, monitoring campaign), (ii) as a personal or institutional archive or back-up system, and (iii) as an open repository for data publication. VLIZ also hosts the Sea Level Station Monitoring Facility, global station monitoring service for real time sea level measuring stations that are part of IOC programmes i.e. (i) the Global Sea Level Observing System Core Network; and (ii) the networks under the regional tsunami warning systems in the Indian Ocean (IOTWS), North East Atlantic & Mediterranean (NEAMTWS), Pacific (PTWS) and the Caribbean (CARIBE-EWS).\n\nNational marine data portals\n\nBritish Oceanographic Data Centre\n\nThe British Oceanographic Data Centre (BODC) is a national facility for looking after and distributing data concerning the marine environment. The BODCs deal with biological, chemical, physical and geophysical data, and their databases contain measurements of nearly 10,000 different variables. BODC maintains and develops the National Oceanographic Database and manages the data for the UK Tide Gauge Network. BODC hosts the Marine Environmental Data and Information Network (MEDIN) core team. MEDIN is a partnership of public and private sector organisations working to provide harmonised stewardship and access to marine data and information, and so facilitate improved management of the seas around the UK. MEDIN hosts a discovery metadata portal for UK marine environmental data.\n\nCEFAS\n\nThe Centre for Environment Fisheries and Aquaculture Science provides datasets (including many legacy datasets) from fish, shellfish and plankton surveys from the 1980's to the present day. Other international datasets made available include species migration data from tagging activities and data on habitat and sediment, ecosystem change, human activities including marine litter, otolith sampling and fish stomach contents, oceanography, acoustics, health and water quality. CEFAS also provides access to datasets of WaveNet, the Defra strategic wave monitoring network for England and Wales, that consists of wave buoys located in areas at risk from flooding.\n\nDASSH\n\nDASHH (Data Archive for Seabed Species and Habitats) is the UK Marine Data Archive Centre for benthic survey data of both species and habitats. DASSH provides digital archive facilities for benthic datasets and a digital repository for benthic images and video.\n\nNNRCMP\n\nThe Brittish National Network of Regional Coastal Monitoring Programmes consists of six Regional Monitoring Programmes. The Programmes collect and distribute the necessary data to underpin evidence-based decisions regarding strategic and local level Flood and Coastal Erosion Risk Management (FCERM).\n\nSISMER\n\nSISMER (Systèmes d’informations scientifiques pour la Mer) is the national marine data portal in France operated by Ifremer. The information systems managed by Sismer range from CATDS (SMOS satellite data) to geoscience data (bathymetry, seismic, geological samples) to water column data (physics and chemistry, data for operational oceanography - Coriolis - Copernicus CMEMS), fishery data (Harmony), coastal environment data (Quadrige 2) and deep environment data (Archimedes).\n\nMDI-DE portal\n\nIn Germany an integrated national marine and coastal information system was set up in 2014 within the co-operative project \"Marine Data Infrastructure (MDI-DE)\". Coastal and marine data collected by 11 Federal and State agencies are made available by OGC (Open Geospatial Consortium) compliant Web services and documented with metadata according to the ISO standard. The new MDI-DE portal serves as central entry point for data and information from the German coastal zone and the adjacent marine waters. This facilitates intersectoral views of resources by providing technological solutions of networking and distributed data management. The benefit of hosting the data locally is that the data from different sources can be merged in almost any way, custom-made compositions of thematic data layers can be compiled without touching the data itself. Each participating agency or institute operates a node which consists of a few basic components: services to provide the data, metadata and a database. For the provision of spatial data, the OGC has developed a number of open and international standards: the Web Map Service (WMS) to generate and visualize digital maps in the Web and the Web Feature Service (WFS) to download the data in an interoperable format such as GML (Geography Markup Language). Corresponding metadata are harvested from the different local nodes and are provided through a standardized Catalogue Service for the Web (CSW) interface. Beyond the basic services such as WMS and WFS, a Web Processing Service (WPS) for data analysis was implemented.\n\nInformatiehuis Marien\n\nThe portal Informatiehuis Marien gives access to all monitoring data collected in the Netherlands by the Ministry of Infrastructure and Watermanagement and the Ministry of Agriculture, Nature and Food Quality.\n\nNODC Italy\n\nThe Italian National Oceanographic Data Centre (NODC) is hosted by the Istituto Nazionale di Oceanografica e di Geofisica Sperimentale. It is part of the IOC's network of National Oceanographic Data Centres and responsible for the coordination of data and information management at national level. The oceanographic database covers the fields of marine physics, chemical, biological, underway geophysics and general information on Italian oceanographic cruises and data sets.\n\nCDIP\n\nThe Coastal Data Information Program (CDIP) is an extensive network for monitoring waves and beaches along the coastlines of the United States. Since its inception in 1975, the program has produced a vast database of publicly-accessible environmental data for use by coastal engineers and planners, scientists, mariners, and marine enthusiasts. The program has also remained at the forefront of coastal monitoring, developing numerous innovations in instrumentation, system control and management, computer hardware and software, field equipment, and installation techniques. CDIP is operated by the Ocean Engineering Research Group (OERG), part of the Integrative Oceanography Division (IOD) at Scripps Institution of Oceanography (SIO).\n\nIOOS\n\nThe US Integrated Ocean Observing System (IOOS) is a national-regional partnership working to provide new tools and forecasts to improve safety, enhance the economy, and protect the environment. Integrated ocean information is available in near real time, as well as retrospectively. Primary focus of IOOS is integration of, and expedited access to, ocean observation data for improved decision making. The Data Management and Communication (DMAC) subsystem of U.S. IOOS serves as a central mechanism for integrating all existing and projected data sources.\n\nCoastWatch\n\nNOAA CoastWatch/OceanWatch provides easy access for everyone to global and regional satellite data products for use in understanding, managing and protecting ocean and coastal resources and for assessing impacts of environmental change in ecosystems, weather, and climate. Sea surface temperature, winds, and current products support meteorological weather predictions and also support commercial and recreational activities (e.g., fishing). Biologists utilize ocean color radiometry data and derived chlorophyll-a and total suspended matter/turbidity products to identify runoff plumes and blooms and also predict HABs; and sailors and commercial shipping pilots use ocean surface vector winds and current products for safe navigation. NOAA makes use of ERDDAP (Environmental Research Division Data Access Program), a data server that gives a simple, consistent way to download subsets of gridded and tabular scientific datasets in common file formats and make graphs and maps.\n\nINCOIS\n\nThe Indian National Centre for Ocean Information Services INCOIS, being the central repository for marine data in the country, receives voluminous oceanographic data in real time, from a variety of in-situ and remote sensing observing systems. The Ocean Information Bank provides information on physical, chemical, biological and geological parameters of ocean and coasts on spatial and temporal domains that is vital for both research and operational oceanography. The Ocean Information Bank is supported by the data received from Ocean Observing Systems in the Indian Ocean (both the in-situ platforms and satellites) as well as by a chain of Marine Data Centres. Data products are accessible through various portals on the site and are largely available by data type (in situ or remote sensing) and then by parameter.\n\nGeneral data repositories\n\nre3data\n\nThe REgistry of REsearch data REpositories offers detailed descriptions of more than 2600 repositories. These descriptions are based on the searchable re3data Metadata Schema and can be accessed via the re3data Application Programming Interface (API).\n\nfigshare\n\nFigshare is a generalist repository where academic institutions and researchers can make all of their research outputs available in a citable, shareable and discoverable manner.\n\nZenodo\n\nZenodo is a general-purpose open-access repository developed under the European OpenAIRE program and operated by CERN. It allows researchers to deposit research papers, data sets, research software, reports, and any other research related digital artefacts. For each submission, a persistent digital object identifier (DOI) is minted, which makes the stored items easily citeable.\n\nDryad\n\nDryad is an international open-access repository of research data, especially data underlying scientific and medical publications (mainly of evolutionary, genetic, and ecology biology). Dryad is a curated general-purpose repository that makes data discoverable, freely reusable, and citable. The scientific, educational, and charitable mission of Dryad is to provide the infrastructure for and promote the re-use of scholarly research data.\n\nEarth viewers\n\nUSGS satellite image viewer\n\nBrowser of LANDSAT satellite images covering coastal zones worldwide. Images available since the 1990ies with resolution of the order of 30m.\n\nSentinel image viewer\n\nBrowser of SENTINEL satellite images covering coastal zones worldwide. Images available since the 2015 with resolution of the order of 10m.\n\nOpen Earth\n\nOpenEarth is a free and open source initiative to deal with Data, Models and Tools in earth science & engineering projects, currently mainly marine & coastal. In current practice, research, consultancy and construction projects commonly spend a significant part of their budget to setup some basic infrastructure for data and knowledge management. Most of these efforts disappear again once the project is finished. As an alternative to these ad-hoc approaches, OpenEarth aims for a more continuous approach to data & knowledge management. It provides a platform to archive, host and disseminate high quality data, state-of-the-art model systems and well-tested tools for practical analysis. Through this project-superseding approach, marine & coastal engineers and scientists can learn from experiences in previous projects and each other. This may lead to considerable efficiency gains, both in terms of budget and time.\n\nOpenEarth community and workflow\n\nMatlab is one of the most commonly used programming languages for data analysis by marine and coastal scientist and engineers. In 2003, a number of scientists from Deltares and the TUDelft merged their Matlab toolboxes for marine and coastal science and engineering into one toolbox, culminating in open source release as OpenEarthTools (OET) in 2008. OpenEarth adopts the wikipedia approach to growth: web 2.0 crowd sourcing. All users are given full write access to help improve the collection. Quality is assured by version control tracking all changes in [SubVersion], the same tool used by professional software engineers worldwide. OpenEarth started as social experiment to investigate whether crowd sourcing was possible in our community. The answer is yes: just a few years after its launch over 1000 users registered, enjoying over 5000 contributions from over 100 contributors.\n\nGooglePlot toolbox\n\nOne of the most powerful toolboxes of OpenEarth is the GooglePlot toolbox. GooglePlot was developed in 307 revisions by 20 developers. They devised a set of Matlab functions that can plot any atomic data type with one coherent toolbox. The GooglePlot toolbox is designed to be the primary example of the OpenEarth quality control guidelines. For each GooglePlot plot function the settings were made customizable. Proper default values for all settings were chosen, which can be requested by calling the function without arguments. Common code fragments were detected in the toolbox and put into a separate subtoolbox. For each function in the GooglePlot toolbox a dedicated unit test was conceived. These test were coded into a unit test function that is run periodically to test ongoing performance of the entire toolbox. The rigorous test approach was included to deal with the typical shortcoming found in computer code made by scientists and engineers [Merali, 2010]. [1].\n\nSee also\n\nGeographical Information System\n\nReduction of uncertainties through Data Model Integration (DMI)\n\nMetadata and metadata catalogues\n\nDeltares website with an inventory of marine dataportals\n\nReferences"
    }
}