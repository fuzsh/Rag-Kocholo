{
    "id": "dbpedia_2233_0",
    "rank": 89,
    "data": {
        "url": "https://link.springer.com/article/10.1007/s13721-024-00455-4",
        "read_more_link": "",
        "language": "en",
        "title": "Technologies for design-build-test-learn automation and computational modelling across the synthetic biology workflow: a review",
        "top_image": "https://static-content.springer.com/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig1_HTML.png",
        "meta_img": "https://static-content.springer.com/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig1_HTML.png",
        "images": [
            "https://pubads.g.doubleclick.net/gampad/ad?iu=/270604982/springerlink/13721/article&sz=728x90&pos=top&articleid=s13721-024-00455-4",
            "https://link.springer.com/oscar-static/images/darwin/header/img/logo-springerlink-39ee2a28d8.svg",
            "https://media.springernature.com/w72/springer-static/cover-hires/journal/13721?as=webp",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-1-0716-2617-7?as=webp",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-1-0716-3718-0?as=webp",
            "https://media.springernature.com/w215h120/springer-static/image/art%3Aplaceholder%2Fimages/placeholder-figure-springernature.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig1_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig2_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig3_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig4_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig5_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig6_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig7_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig8_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13721-024-00455-4/MediaObjects/13721_2024_455_Fig9_HTML.png",
            "https://link.springer.com/oscar-static/images/logo-springernature-white-19dd4ba190.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-05-03T00:00:00",
        "summary": "",
        "meta_description": "Motivated by the need to parameterize and functionalize dynamic, multiscale simulations, as well as bridge the gap between advancing in silico and laborato",
        "meta_lang": "en",
        "meta_favicon": "/oscar-static/img/favicons/darwin/apple-touch-icon-92e819bf8a.png",
        "meta_site_name": "SpringerLink",
        "canonical_link": "https://link.springer.com/article/10.1007/s13721-024-00455-4",
        "text": "3.1 Data standards\n\nTo sustain reproducibility, engineering fields utilize worksheets and biology uses minimal information standards, e.g. MIAME for microarrays and MIFlowCyt for flow cytometry (Myers et al. 2017). SB standards were recommended for describing parts, genetic construct designs, sequences, assembly methods, vectors, integration points for transformation, CRISPR-based integration and host/chassis organism identity. A lack of quantitative parts datasheets was proposed to be a limiting factor in SB CAD design (Lux et al. 2011).\n\nMany exchange standards are built upon the Extensible Markup Language (Swat, et al. 2009). The Systems Biology Markup Language (SBML) (SBML 2022) represents biological/biochemical networks, including mathematically, and has been harnessed in automated methods (Keating et al. 2020). Tools and APIs can validate, analyse and simulate SBML models, which are commonly simulated via ordinary differential equations (ODE) and stochastic Gillespie algorithms. SBML can harness ontologies or semantic web technologies allowing software to explore network metadata. SBML can be translated to and from domain specific languages (DSLs) such as Antimony (Smith et al. 2009) and IBL (Konur et al. 2021), but typically lacks genetic details (Baig, et al. 2020). By contrast, the Synthetic Biology Open Language (SBOL) allows hierarchical, modular, annotated and extensible genetic design representations (Appleton et al. 2017). The FASTA format primarily contains nucleotide or amino acid (AA) sequence information, whilst GenBank and Swiss-Prot offered annotation capabilities. SBOL can also represent experimental details, unique identifiers, ontologies and uniform resource identifiers, including for external models, and was put forward to address GenBank format limitations regarding representing experimental data and genetic construction documenting (Ham et al. 2012).\n\nOther formats might be encountered whilst investigating SB modelling/data. In the multicellular domain, NUFEB (Li et al. 2019) used VTK, POVray and HDF5 (.h5) output formats. Meanwhile, the COMBINE standard can be used to archive various standards for sharing (Myers et al. 2017). Pretrained ML model formats can depend on the framework or format of choice, e.g..h5,.pb,.safetensors,.pt,.pth,.onnx.\n\n3.2 Databases\n\nComputational modelling for SB requires experimental data, ML tends to require large amounts (Rampasek and Goldenberg 2016; Perrakis and Sixma 2021). Data in literature and within online databases includes chemical reaction pathways, kinetics data, protein data, genomic data and expression data. To fulfil its potential both in de novo design and specific applications, e.g. medical, SB must fully explore applicable data and not confine itself to parts repositories.\n\nThe NCBI archive (Oberortner et al. 2017) provided access to genomes, with AA and nucleotide sequence data available in FASTA and GenBank formats. Design repositories for SB, such as SynBioHub (McLaughlin et al. 2018), and the iGEM Registry of Standard Biological Parts were available. JBEI-ICE (Joint BioEnergy Institute's Inventory of Composable Elements) was a registry for access to biological parts (Ham et al. 2012) with a collection of connected tools. Computational model repositories included BioModels (Biomodels Repository 2022), BiGG Models (Systems_Biology_Research_Group. BiGG Models 2023) and the CellML repository (The_CellML_Project. CellML Model Repository 2022; Büchel et al. 2013). An annotated SBOL parts registry was SBOLme for metabolic engineering (Myers et al. 2017). MetaCyc, KEGG, the Nature Pathway Interaction Database (PID), Reactome and WikiPathways contained curated biochemical pathways (Büchel et al. 2013). With the Human Metabolome Database, human metabolite data was searchable including 3D structures, diseases, proteins, pathways and reactions (Wishart, et al. 2018). The Protein Data Bank (PDB) and UniProt were available as protein-related resources. Specialized databases like the Transporter Classification Database also existed. The ChEBI database provided chemical data of biological interest (Keating et al. 2020). A detailed exploration of EMBL-EBI and NCBI can be encouraged. The Pan-Cancer Atlas (Miles and Lee 2018) aimed to assist precision medicine. gnomAD database has been referenced in phenotyping studies (Rosenhahn et al. 2022) and provides allele population scale frequencies, also classified for pathogenicity.\n\nThe Reactome pathway browser (Reactome. Reactome Pathway Browser. 2022) provided a map separated according to cellular functions, allowing the identification of annotated genetic mutations associated with disease phenotypes. Reactome was arguably more ergonomic than Recon3D’s (Brunk et al. 2018) extensive interactive browser (Recon 2022) (Fig. 1). The Reactome Knowledgebase is manually curated (Gillespie et al. 2022) and concerns molecular data emphasizing human disease and physiology; detailing gene expression and mutations. Reactome possessed information on 52.5% of the predicted protein-coding human genome (10,726 genes). Reactome utilized Gene and Disease Ontology annotations and Gene Set Analysis was supported, with datasets available from ExpressionAtlas and Single Cell ExpressionAtlas. Reactome used Systems Biology Graphical Notation (SBGN) for its pathway diagrams, visualized using Cytoscape.js. The druggable genome could be visualized with annotations provided by Reactome IDG. In a March 2024 email from QIAGEN, a company operating with hundreds of millions of dollars, they stated the connectivity of Reactome pathways to their commercial QIAGEN Ingenuity Pathway Analysis (QIAGEN IPA) service (QIAGEN. QIAGEN Ingenuity Pathway Analysis (QIAGEN IPA). 2024).\n\nExpression Atlas (EBML_EBI. Expression Atlas. 2022) and the Human Protein Atlas (HPA) (Human_Protein_Atlas. The Human Protein Atlas 2022) were resources for phenotypic expression profiles. The HPA contained histological section graphics with marker expression levels, protein function details, survival rates, and used external resources such as the Cancer Genome Atlas. RNA-seq data was available, which uses Next Generation Sequencing to sequence the transcriptomic profile of cells. Transcriptomics data acquisition can also arise from DNA microarray technology (Gurdo et al. 2023), however the use of probes compared to RNA-seq restricts detection to known sequences. Protein localization/compartmentalization can be associated with specific functions, which cells achieve via trafficking (Watson et al. 2022). Localization data was available at the Gene Ontology Cellular Component and Jensen COMPARTMENTS databases. The HPA was considered the gold-standard in protein localization.\n\nThe SABIO-RK online database offered scientist-curated biochemical kinetics data (Rojas et al. 2007), with reaction information obtained via databases including KEGG. Parameters included rate/equilibrium/dissociation/inhibition constants and maximal velocities (Golebiewski et al. 2007). Export could be in the SBML format (Rojas et al. 2007) and SABIO-RK has been used for kinetic model generation (Büchel et al. 2013; Dräger et al. 2015). Integration of SABIO-RK queries was reported for CellDesigner and SYCAMORE (Golebiewski et al. 2007).\n\nThis subsection noted many useful resources, however with countless bioinformatics resources undoubtedly many were excluded from this compilation. Our research implicated the importance of experimentally derived pathway networks coupled with omics resources, with different types of omics potentially presenting with different layers of regulatory control, and hence different perspectives on the true state of a biological system. In fact, the current biological state is the result of the physical molecular configuration resultant of the temporally past upstream interactome. It is the task of the biological modeller or researcher to understand the implications of experimental assays and interpret bioinformatics resources at different regulatory levels to infer a complete picture of the present state. For example, RNA-seq data is evidently highly popular, but restricted to the transcriptome, with uncertainty to the true downstream state of the system, discernible from the metabolome or proteome. Neither does RNA-seq represent the true capacity of a given genome, only that which is transcriptionally active in the present or past. Indeed, a range of techniques are available for data collection across the omics (Gurdo et al. 2023).\n\n3.3 Data mining\n\nBiological text mining tools are capable of “named entity recognition” (NER) and functional enrichment analysis (Baltoumas, et al. 2021). Functional enrichment analysis aims to identify genes that might be over or under expressed in particular phenotypes, e.g. via g:Profiler2 and aGOtool. NER can use ontologies and “concept-normalization” to map a word or phrase to a term (Pattisapu, et al. 2020). OnTheFly utilized the EXTRACT tagging service for this purpose (Baltoumas, et al. 2021), and also possessed Optical Character Recognition. aGOtool could locate documents related to identified genes and proteins, achieved through a text corpus from PubMed. The STRING and STITCH APIs could be used to assess protein interactions with resulting node-based graphs such as of interaction evidence and binding affinities.\n\n2023 was a breakout year for machine learned large language models (LLMs) (Else 2023) trained on large volumes of “human-generated text”, an eminent example being ChatGPT by OpenAI. Such technology was proposed to serve fields as diverse as stem cell research (Cahan and Treutlein 2023). Biomedical language models included BioBERT, PubMedBERT and BioGPT (Luo, et al. 2022), trained on vast corpora of biomedical literature. BioGPT is a domain-specific generative Transformer language model trained on 15 million PubMed abstracts. BERT utilized “masked language modelling” with probabilistic sentence predictions. Instead, the Generative Pre-Trained Transformer (GPT) would predict word tokens, including via Byte-Pair encoding (Vaswani, et al. 2017). LLMs can also assist with programmatic tasks. We have considered the possibility of extending our ongoing research (Matzko 2023) through the use of LLMs. Graph neural networks are another domain that could be considered (Gurdo et al. 2023).\n\nIn order to perform simulations, which have hypothesis generation and predictive potential, models must be established. This section details simulation and chemical reaction network (CRN) resources and principles, as well as introducing Synthetic Biology CAD software for genetic circuit design.\n\n4.1 Network analysis and modelling methodologies\n\nSimulators solve biochemical reactions and transitions by operating on syntactically compatible models. An example is libRoadRunner (Choi et al. 2018) with stochastic and ODE support (Available from 2022). NGSS (Next Generation Stochastic Simulator) (Sanassy et al. 2015) for Gillespie algorithms was discussed in our previous work (Matzko et al. 2023; Konur et al. 2021), alongside SSAPredict for algorithm selection based on model topology. Reaction-based models can be interrogated by parameter estimation, sensitivity analysis and parameter sweep analysis (Riva et al. 2022) at considerable computational expense. Thus, the move to GPU from CPU architecture was encouraged. Model analysis can be performed via numerical analysis, e.g. on matrix representations of state, or statistical analysis on stochastic runs (Appleton et al. 2017). Kinetic parameter estimation is possible via genetic algorithms, particle swarm and hill-climbing methods. BioPSy and COPASI software provided parameter estimation capabilities. Sensitivity analysis assesses the dynamics of a system relative to its parameters.\n\nGene regulatory networks involve the manipulation of “cis-regulatory module” DNA sequences for the activation or inhibition of transcription (Delile et al. 2017), and have been described as bipartite directed graphs (Yaman et al. 2012) modellable in Boolean fashion or through probabilistic differential equations (Delile et al. 2017). Contrasted with kinetics models, Boolean models can provide a convenient simplification (Karagöz et al. 2021) with utility in modelling domains such as signalling cascades (Letort et al. 2019) or phenotypic states (Rubinacci et al. 2015).\n\nStochastic simulation algorithms (SSAs), whilst computationally intensive by contrast to deterministic ODEs, are said to produce accurate simulations retaining the inherent stochasticity of biological metabolic networks (Sanassy et al. 2015). This arises from their discrete modelling contrasted to the continuous nature of deterministic ODEs. Classical kinetics was considered unsuitable for genetic regulatory systems, which involve large fluctuations in species counts (Appleton et al. 2017). Stochastic simulations assess propensities of reactions over successive infinitesimal time intervals, rendering them computationally expensive under conditions of high propensity. Hence the existence of hybrid-algorithms using both stochastic and ODE methods in COPASI (Hoops et al. 2006). The argument was made for the use of bond graphs in dynamic biological modelling (Pan et al. 2021) to correct for thermodynamic inconsistencies, e.g. via BondGraphTools for Python. A major challenge to kinetics modelling besides computational expense is the limited availability of experimentally determined kinetics data. Kinetics modelling was thus deemed “cost-prohibitive” (Gurdo et al. 2023). However, a lack of kinetics data was considered a limitation in translatable, cost effective modelling for certain expression systems. The possibility of using machine learning to enhance kinetics parameterization is noted in Sect. 5.1.\n\nFlux balance analysis (FBA) can guide metabolic engineering of interacting pathways (Sekiguchi et al. 2021). FBA is a kinetic rate free, constraint-based approach utilizing an objective function (Motamedian et al. 2017) that mathematically analyses the flow (e.g. mmol/gDW/hr) through a metabolic network (Orth et al. 2010), associated with the field of fluxomics (Gurdo et al. 2023). For growth, the objective function may be the maximization of biomass (Motamedian et al. 2017; Dukovski et al. 2021). FBA has been used to predict missing reactions and gene knockouts for optimized end-product formation, e.g. knockouts by modulating upper and lower flux bounds (Rowe et al. 2018). However, without kinetic parameters, chemical concentrations are undefined and FBA is confined to steady state evaluations (Orth et al. 2010). FBA tools included Escher-FBA, OptFlux, COBRA Toolbox, COBRApy, PSAMM and FAME (Rowe et al. 2018). COBRA stands for constraint-based reconstruction and analysis (Gurdo et al. 2023). FBA optimization of flux values via objective function at the genome-scale was considered to be extremely rapid even on conventional hardware (Dukovski et al. 2021). FBA uses a stoichiometric matrix with rows of metabolites and columns of reactions to simulate under a steady state assumption. However, a limitation of FBA was described as a lack of “explicit gene regulation”. Also FBA presents with flux inaccuracies (Gurdo et al. 2023). Amongst FBA variants, thermodynamic flux analysis is an alternative that considers the Gibb’s free energy to drive reactions, such as via the pyTFA package (Lent et al. 2023). Due to the Michaelis Menten proportionality between Vmax and enzyme concentration [E], in this method perturbations of Vmax would be used to simulate variable [E] under factors such as assumed promoter strength for the enzyme.\n\nCOPASI (COPASI. COPASI 2022) is an open-source biochemical simulator (Hoops et al. 2006), with GUI (Graphical User Interface) version, capable of model editing and analysis. Operating on CRNs, COPASI has deterministic ODE capabilities, stochastic algorithms, ODE/stochastic hybrid methods, steady state computations, stoichiometric network analysis, sensitivity analysis, metabolic control analysis, optimization, parameter estimation and flux analysis. Kinetic functions could be defined and chosen from an integrated library. Optimization used objective functions, steepest descent, genetic algorithms and evolutionary strategies for maximizing or minimizing model variables.\n\n4.2 Whole cell models\n\nRecon3D may be the most extensive public human metabolic network model, containing 3,288 open reading frames, 13,543 reactions, 4140 metabolites (Brunk et al. 2018) and 12,890 protein structures. Contrast this scale to EcoCyc-18.0-GEM (Weaver et al. 2014) for E. coli and Path2Models (Büchel et al. 2013) in Fig. 2. Other genome scale metabolic reconstruction models for E. coli and other organisms are available on BiGG Models (Systems_Biology_Research_Group. BiGG Models 2023). Recon3D could be explored on the Virtual Metabolic Human website (VMH. Virtual Metabolic Human. 2022), including via Recon Map 3 (Recon 2022). Pathway enzymes could be cross-referenced with databases such as KEGG, PDB, CHEBI, PharmGKB and UniProt via external links.\n\nRecon3D utilized a subset (17%) of human proteins from UniProt to generate a 10,600 reaction computational model made available at BiGG models (UCSD_SBRG. BiGG Models. 2019). Recon3D possessed 3D protein structural information from the PDB and included atom-scale models produced through homology modelling via protein sequence alignment. Metabolite structures were included from various sources. Structural data was hence achieved for 85% of the human metabolome, including the aforementioned 12,890 protein structures. Drug metabolic perturbation effects were assessed, assisted by resources such as the Connectivity Map (Broad_Institute 2022).\n\n4.3 Minimal genomes\n\nMinimal genomes can present as a starting point for developing synthetic biological systems. Mycoplasma genitalium contains only 525 genes (Sleator 2016). Comparisons with other bacteria provided rationale for estimating 256 essential genes, whilst other methods suggested 375 genes via transposon mutagenesis data. JCVI-syn3.0 was a physiologically stable synthetic cell developed with an approximately minimal genome, based on Mycoplasma mycoides (Rees-Garbutt et al. 2020). 240 essential genes were identified, along with quasi-essential genes numbering 229 with minor or major cell abnormalities. The method utilized the Tn5 transposase.\n\nThe JCVI-Syn3.0 researchers computationally assessed tens of thousands of gene knockouts for implementation with Mycoplasma genitalium ATCC 33530/NCTC 10195. The model was parameterized from 900 publications and 1900 experimental observations and such models of Mycoplasma genitalium are perhaps the most complete of any cell. Minesweeper and GAMA algorithms performed deletions with subsequent simulation ensuring that division still occurred in silico. These algorithms produced tens of thousands of genomes having used 3000 CPUs operating over months. GAMA primarily knocked out genes less likely to disrupt division, followed by random knockouts and recombination, predicting a 360 gene minimal genome. The in silico cell could grow/divide in a simulated SP4 growth medium. Reduced Gene Ontology category terms from UniProt permitting continuity included DNA repair/replication/topology, transcription, regulation, the cell cycle/division, protein transport/folding, lipid production and RNA processing. BLAST (sequence alignment) was used to compare JCVI-Syn3.0 to the GAMA_237 and Minesweeper_256 models. The whole cell model of Mycoplasma genitalium (Karr and Brandon;. 2015) could be run through SimulationRunner.m or MGGRunner.m via MatLab.\n\n4.4 Biochemical pathway/network model generation and optimization\n\nChemical Reaction Networks (CRNs) were considered critical for modelling in both Synthetic and Systems Biology (Poole et al. 2022), with ongoing efforts to automate the process, with tools created for synthetic network generation (Riva et al. 2022). Despite the successes of constraint-based (flux balance) approaches, explicit concentration-based modelling requires kinetics data (Rosmalen et al. 2021). For kinetic networks, rate laws must be defined (Dräger et al. 2015). A model might be outlined and subsequently parameterized (Poole et al. 2022), perhaps with estimates. Tools capable of defining rate laws included COPASI, CellDesigner and SABIO-RK (Dräger et al. 2015). Specialist tools existed, such as Odefy, which could generate differential Hill-type equations from Boolean networks. Various methods for “model reduction” existed (Rosmalen et al. 2021). Model reduction software included FastCore, NetworkReducer and minNW. Other approaches included MOMA for reduction, which was proposed in relation to next generation constraint-based modelling using GECKO, REMI, MOMENT or RBA. SMGen, with GUI, generated reaction networks with CPU parallelization (Riva et al. 2022). SMGen had SBML and BioSimWare export; where BioSimWare was used by some GPU simulators. There was no evidence that SMGen pursued biological reality beyond arbitrary constraint-generated CRNs. Models for SMGen were defined through stoichiometry and kinetic rate constants and utilized the law of mass-action.\n\nBioCRNpyler, written in Python and programmatically scripted (Poole et al. 2022), was designed to generate SBML format CRNs with combinatorial capacity. The simulator of choice was Bioscrape. BioCRNpyler could combine modular components (essentially SB parts and devices) into large models. Alternatives to BioCRNpyler include BioNetGen, PySB, Tellurium, Virtual Parts Repository (VPR), iBioSim, COPASI and MATLAB Simbiology. Models could be constructed from species and reactions, and could take on a variety of “propensity functions” such as mass-action, Hill and user specified functions. Mechanisms included binding, cooperative binding, catalysis, Michaelis Menten, transcription, translation, dilution, degradation (nuclease/protease), activation (Hill function) and repression (negative Hill function).\n\nSBMLsqueezer 2, also a CellDesigner plugin, made use of the SABIO-RK database via RESTful API to generate large-scale biochemical kinetics models (Dräger et al. 2015), with selectable gene-regulatory rate law alternatives including Hill-Hinze, Hill-Radde, Weaver’s equation, S-systems, H-systems etc. Hill function kinetics can provide switch-like behaviour, suitable for transcription factor dynamics, and transcription is a non-linear reaction with power-law approximations connected to Taylor’s theorem (Chakraborty et al. 2022). SBMLsqueezer 2 would manipulate SBML via JSBML with libSBML support (Dräger et al. 2015). Reaction type was determined by Systems Biology Ontology and MIRIAM annotations. A pipeline was suggested using a BiGG database model, or generated by KEGGtranslator, with SBMLsqueezer 2 providing kinetic law generation, and SBMLsimulator was suggested for fitting models to experimental data. For the Path2Models project, a pipeline was developed for the generation of computational biochemical pathway models in SBML from KEGG, MetaCyc and BioPAX (Büchel et al. 2013). Upon conversion to SBML, the models would have kinetic rate equations (via SBMLsqueezer) and flux bounds added. KEGG metabolic pathways are described via “processes”, downloadable as KEGG Markup Language (KGML), allowing for “process-based” reconstructions, translatable to SBML via KEGGtranslator. Only 0.22% of reactions could utilize SABIO-RK, although as much as 12.2% for Homo sapiens. Path2Models only considered the simplest form of rate law for reversible reactions. Genome-scale metabolic models were generated from KEGG, primarily, and MetaCyc via libAnnotationSBML and SuBliMinal Toolbox software (RAVEN Toolbox and KEGGtranslator are alternatives). Models were specified minimal growth media. Errors were generated in terms of AA essentiality in Path2Models and it incorrectly generalized biochemical constituents for certain lifeforms. The SKiMpy Python package was recently noted for “semi-automated” kinetic model generation (Lent et al. 2023).\n\nThe conversion of SBOL to SBML has potential for automating the generation of behavioural simulations from genetic designs; an unrealized aspiration of GenoCAD (Czar et al. 2009). It was suggested that the automation of model construction on the basis of design repositories had not been achieved (Misirli, G.k,, et al. 2019), perhaps the most promising options being the VPR and SB suites such as iBioSim. The VPR was said to contain SBOL designs with corresponding SBML models (Poole et al. 2022), with sufficient metadata for automation (Misirli, G.k,, et al. 2019). An example workflow generated SBOL using Cello, with import into iBiosim for conversion to SBML (Appleton et al. 2017) and simulation via COPASI. The reverse is SBOL generation from CRNs, as performed by MoSec, a sequence generation program (Misirli et al. 2011). MoSec generated EMBL/GenBank and SBOL formatted DNA sequences from SBML or CellML models. The SBML and CellML files would require Standard Virtual Parts and MIRIAM-compliance.\n\nRetrosynthesis can optimize and complete gaps in biochemical pathways, a tool of interest being SciFinder-N (American_Chemical_Society. 2023). Brute-force chemical pathway optimization is computationally demanding, and multithreaded RetSynth was developed to address this (Whitmore et al. 2019). RetSynth could perform FBA for product yield optimization via CobraPy and visualize the pathways. RetSynth could compile information from metabolic databases including PATRIC, KBase, MetaCyc, KEGG, MINE, the ATLAS of Biochemistry and SPRESI.\n\n4.5 Synthetic biology suites\n\nA “Synthetic Biology Suite” is a platform designed to house Synthetic Biology CAD requirements under a single roof. Usually the emphasis is bioregulatory genetic construct design and simulation. Figure 3 presents an overview of such technologies.\n\nInfobiotics Workbench (IBW) is an open source SB suite. IBW integrated various binaries, such as model checkers and Gillespie algorithms, and was designed to be an effective modelling, simulation, verification and sequence generation (via ATGC) tool, with its own ontology-inspired programming language (IBL) for biological circuit design (Konur et al. 2021). IBW ran Gillespie simulations through NGSS and integrated SSA Predictor, an ML solution for identifying the optimal Gillespie algorithm for a model network topology. In practice SSA Predictor presented with inaccuracies (Matzko et al. 2023). A GPU parallelized CUDA Gillespie stochastic simulation algorithm was under development for IBW (Konur et al. 2021), although its status remained uncertain. Formal verification could check models for time course simulation conditions such as molecular quantity thresholds. IBW could automatically add terminators, RBSs via Salis’ RBS calculator and spacers. Synthetic Biology genetic part sequences could be determined from the iGem repository or a local database created from Biofab and Rebase. User defined directives could guide ATGC to manage restriction sites. Case studies have used genetic regulatory networks (circuits) with molecular switches to dynamically regulate expression levels; e.g. GFP expression regulation via XOR gate constructed from genetic parts (Konur, et al. 2014). In previous iterations, IBW was intended for the design, analysis and optimization of multicellular systems (Blakes et al. 2014). Decomposition/decoupling of reaction networks could have allowed for tractable and modular optimization. Our ongoing research continued to investigate the spatiotemporal extension of the NGSS component of IBW (Matzko et al. 2023).\n\niBioSim modelled biochemical systems through in silico genetic circuit design, with optional multicellular grid representations. Operons could be designed in vSBOL (Visual SBOL) and an online registry could be communicated with to select parts. SBOL designs use an embedded part sequencer, SBOLDesigner (Watanabe et al. 2019). iBioSim could import and export in SBML, SBOL, Labelled Petri Net models (LPN) and SED-ML (Myers 2015). Analysis of models used deterministic ODEs, Monte Carlo, Markov Chain and FBA. A similar software, Tinkercell (TinkerCell_Website. TinkerCell. 2022), was created for the product design and analysis cycle. Plug-ins could allow for stochastic simulations, directed evolution, DNA optimization, online searches and experimental data import. Tinkercell used deterministic and tau-leaping stochastic simulations and possessed automated or manual rate equation assignments for designed constructs (Chandran et al. 2010). C, Python and Octave languages could be used for scripting. Tinkercell had text-based modelling via the Antimony language (Smith et al. 2009) and allowed for the drag and drop design of operons, including into plasmid representations. Another suite of tools, Clotho, was developed for iGEM (Internationally Genetically Engineered Machine) competitions (Xia, et al. 2011). Various Clotho apps could be used to operate on metadata objects. An interesting feature was provisional risk assessments based on NIH Guidelines, flagging Parts, Vectors and features using BLAST against virulence factors.\n\nTellurium, applied through Jupyter Notebook or Spyder IDE, was created for Systems Biology and SB modelling, simulation and analysis (Choi et al. 2018). It used phraSED-ML and SimpleSBML for model design and the Antimony language for translation to and from SBML. Tellurium utilized libRoadRunner for deterministic and stochastic simulations, assessing parameter changes by metabolic control analysis. Network structural analysis used libStructural and Tellurium utilized AUTO2000 for bifurcation analysis, allowing for the assessment of parametric changes, bi-stability and oscillations. Tellurium could parameter estimate by model fitting to experimental data and used a “differential evolution optimizer” from SciPy for parameterization via global optimization. Known data was contrasted to predicted via normalized root mean squared error.\n\nPreviously, we mentioned combinatorial possibilities in CRN generation (Poole et al. 2022). Rational, semi-rational and combinatorial approaches to pathway design are possible (Appleton et al. 2017), with the potential to utilize genetic parts in combinatorial experiments, even with population level consequences. The power of combinatorial approaches to solve otherwise intractable problems likely overrepresented them in industry compared to rational approaches overrepresented within academia. Rational designs (Stephanopoulos 2012) can be given a combinatorial treatment to select for mutants with best performance by high-throughput, and high-throughput has been suggested for part characterization (Buecherl and Myers 2022). Genetic design automation (GDA) was described as involving part selection, combinatorial methods, assembly and analysis; with emphasis on standards and design portability of well-established parts.\n\nFigure 4 depicts an approximated schematic for the DBTL loop for SB. In this case ML is proposed as a modality through which learning can be automatically administered to combinatorial design, however ML feedback might alternatively interact with other stages of the cycle, calibrating the automated system towards an idealized state. The test metrics would depend on the specific requirements of the product, and can be generalized as assays or micrographics. Assays may include sequencing (e.g. RNA-seq, ribo-seq (Foo et al. 2023)), flow cytometry, mass spectrometry, transcriptomics, metabolomics and proteomics to extract characterizations of the generated cells or cell populations. Metabolite concentration data can be considered for modelling (Gurdo et al. 2023). Microarrays might be used, as well as various forms of chromatography and DNA assays (e.g. agarose gel electrophoresis). Automated liquid handling with photometric screening was reported (Helleckes et al. 2023). Micrographic analysis is an alternative, although a variety of other testing options might be available, including the use of magnetic resonance (NMR, even MRI) and X-ray crystallography to characterize the synthetic system being generated. Imaging, such as micrographs, might take various forms, for example including whole organism behavioural studies/phenomics (Rosenhahn et al. 2022) or microbial phenomics such as growth rate and sporulation in yeast (Foo et al. 2023). Often behavioural characteristics such as growth are used as objectives functions in modelling (Motamedian et al. 2017; Dukovski et al. 2021). Electron microscopy and serial sectioning can be combined (Larsen et al. 2021) to produce digital reconstructions for analysis (Liimatainen et al. 2021), with implications in 3D culture engineering, such as tissue engineering. For instance, AutoCUTS-LM (Automatic Collector of Ultrathin Sections for Light Microscopy) possessed an ultramicrotome with collection of sections by tape at a rate of 800 per hour, coupled with scanning electron microscopy (Larsen et al. 2021). Electron microscopy was reportedly capable of resolving biological neural networks, and neuron centroid detection utilized the machine learned solution UNetDense.\n\nSemiconductors have been designed through Electronic Design Automation (EDA) for decades (Densmore and Bhatia 2013). Biological Design Automation (BDA) was proposed to involve protocols relayed to microfluidics, liquid handling robots and bioprinters. This could be coupled with ML and an iterative design process. Microfluidic systems could provide for regulated environments for experimentation, with a parallel drawn with EDA “frequency response analysis” (Lux et al. 2011). In terms of the automated genetic design phase of a DBTL cycle (Fig. 4), Cello, GEC, BioCompiler and GenoCAD were singled out, however a manually curated library of devices is a large part of Cello’s success (Beal and Rogers 2020). In assessing the capacity of available resources, design and test were ascribed to the successes of Autoprotocol, Aquarium, Antha and OpenTrons API. Automated analytics was attributed to automated flow cytometry analysis (TASBE), other assays (Galaxy) and microscopy (SuperSegger and Fogbank).\n\nIt is worth noting that while mechanistic models have design implications, another perspective is that the modelling phase resides in the learn stage of the DBTL loop (Gurdo et al. 2023). Whilst modelling is the modality through which design is achieved, this perspective defines the learn phase as the interpretation of collected test phase data into modelling modalities.\n\n5.1 Machine learning for synthetic biology CAD\n\nML (Fig. 5) can find solutions beyond human intuition (Fawzi et al. 2022). Artificial neural networks are layers of interconnected nodes operating through weighted functions (Rampasek and Goldenberg 2016). Such technology has been applied to biological research including protein folding, molecular biology, neuroimaging-based diagnosis, impact of point mutations and nucleic acid interactions. However, many biological problems have low sample sizes, which is not conducive to deep learning, although data may be manipulable to increase trainability. Thus, pre-existing data is essential, for example AlphaFold exploited motifs and evolutionary information for protein structure inference (Callaway 2022) using the data rich PDB (Varadi et al. 2022). For the design of riboswitches, the Rfam database was used (Palaniappan 2022). Perhaps kinetics data (SABIO-RK) presents as a potential target (Dräger et al. 2015). Other repositories, including metadata from the VPR (Misirli, G.k,, et al. 2019), may present with potential. Our research trajectory would lead us towards considering multi-omics (Matzko 2023). Regarding available ML frameworks, TensorFlow is an open-source example from Google (Rampasek and Goldenberg 2016) and provisioned free access to remote CPU, TPU and GPU computing via Google Colab. TensorFlow’s technical complexity was simplified by high level wrappers like Keras and Pretty Tensor. Alternative deep learning frameworks include Torch7, Theano, Caffe, Neon by Nervana, Deeplearning4J and H2O-3. pyTorch Python library has proven to be convenient to use through an IDE (integrated development environment) such as Visual Studio Code on Windows. Although as noted, Google Colab provisions for remote computing, useful particularly if one is operating on limited local hardware.\n\nProtein structure has significance to pathological states, e.g. leukodystrophy (Akdel, et al. 2022), and the structure–function relationship is a well known principle in biological study. Structural and functional predictions can be made from AA sequence motifs (Torres and Fuente-Nunez 2019), which is beneficial to protein design and docking (e.g. via Rosetta 3 (Huang et al. 2016)) and useful for in silico drug design. Docking software can evaluate the ligand potential of billions of small molecules for drug development (Callaway 2022). However, small structural differences between experiment and prediction can have a significant impact on drug matches. Protein folding predictions had been made via structural homologs or physics/energetics (Brunk et al. 2018; David et al. 2022). Such predictions involved the rearrangement of an AA sequence into a favourable “low-energy state”, considered to be an intractable problem (Perrakis and Sixma 2021). However, AlphaFold made no consideration for energy minima, rather applying ML to homolog templates and multiple sequence alignment (David et al. 2022) via neural networks (Callaway 2022) upon half a century of experimental data (Perrakis and Sixma 2021). AlphaFold could predict dynamic domain behaviours, although interactions were not available in its database. RoseTTAfold and AlphaFold-Multimer were able to achieve limited multimeric predictions. ColabFold allowed the submission of an AA sequence for structure prediction (Callaway 2022). AlphaFold data could be accessed via API, which was used by archives such as UniProt to display protein structures, which also contains X-Ray determined structures from the PDB (Varadi et al. 2022), including Nobel Prize winning structural elucidations upon which AlphaFold was trained. AlphaFold can have serious structural flaws when compared to X-Ray results (Varadi et al. 2022; David et al. 2022; Thornton et al. 2021). Since the Therapeutic Target Database had only a few thousand targets compared to the tens of thousands of human proteins, new virtual screening tools for therapeutic targets might arise from AlphaFold (Tong et al. 2021). AlphaFold reportedly led to drastic improvements in identifying disorders (Callaway 2022). It can be speculated that hybrid ML and classical physical algorithms might be developed, where computationally expensive physical predictions could be used sparingly where necessary if proven to enhance model performance.\n\nElsewhere, Deep Learning via Python was applied to Riboswitches (Palaniappan 2022) for their classification in a project called RiboFlow, including the use of convolutional neural networks (CNNs) and bidirectional recurrent neural networks with “Long Short-Term memory” (RNNs) derived from TensorFlow (Premkumar et al. 2020). Each of the 32 to 39 riboswitch classes was regulated by a particular ligand, for example glutamine, fluoride, cobalamin etc. The Rfam database for non-coding RNAs was used to obtain FASTA sequences via File Transfer Protocol. “Feature vectors”, essentially an array of encoded data points, were obtained and normalized for ML, including mononucleotide and dinucleotide frequencies. The research presented the potential for riboswitch discovery, with class membership probabilities implying aptamer strength. Such work could be applied to riboswitch targeting drugs, such as antibiotics.\n\nElsewhere still, the CAD design of purpose-built living multicellular organoids was pursued (Kriegman et al. 2020), with implementations via microsurgical approximations. Evolutionary models were deemed favourable over learning methods due to the flexibility conferred to desired behaviour, however artificial neural networks were suggested for narrowing the design space. Simulations were re-constrained according to observed physical behaviours, thus tying together multiple ML methods, Synthetic Biology, surgical methods and spatiotemporal physical simulations. Physics informed neural networks might be considered for dynamic simulations of such a nature (Gurdo et al. 2023).\n\nWhilst it is prudent to target and validate against big biological data as in above examples, computational scenarios featuring somewhat abstract kinetic enzyme pathways have been probed with ML strategies with optimization towards maximizing fluxes through specific reactions (Lent et al. 2023). The ML models would hence be able to probe the entire design space to select for the desired criteria. However, that work presented with abstractions with author acknowledged assumptions. Hence, laboratory automation, discussed next, could accelerate the process of data collection whilst generating inferable real world data for supervised learning where it is not already available. Real world biological models must be considered the gold standard, however, with high-throughput data acquisition a scenario of diminishing returns might be envisaged between the benefits of biological combinatorial experiments versus computational prediction models.\n\n5.2 Automated laboratories and enabling organizations\n\nDNA Assembly methods have been automated using the OT-2 (Fig. 6) liquid handling robot by OpenTrons, along with external thermocycler (Storch et al. 2020) for DNA amplification via PCR. The OT-2 system came with a python-based API for the manipulation of protocols. The combination of the OpenTrons system and BASIC assembly method was termed DNA-BOT. OpenTrons was a laboratory automation provider, and there was potential to use foundries and automated laboratories such as Strateos (Buecherl and Myers 2022) (Fig. 7). Another company, Synthace (Synthace. Synthace website. 2022), promoted DOE (design of experiments) visual scripting, translated into machine instructions using liquid handlers, dispensers and analytical devices with high-throughput. DOE can be highly parametric, which Synthace referred to as “High Dimensional Experimentation” (Miles and Lee 2018).\n\nStandardized methods with automated laboratories run on software-prepared protocols can address experimental reproducibility issues (Miles and Lee 2018). Sensors were used for precise experimental parameterization with programmatic robotic cloud laboratories with remote access. The “Transcriptic Common Lab Environment” (TCLE) featured web-interface trackable assays controlled by a scheduler running experiments via robotics that operated via Intel Nus, miniature PCs, operating with precision liquid handling, plate management, centrifugal evacuation of plates, media switching, self-decontamination, absorbance and fluorescence validation, reagent injection, temperature control and PCR. “Autoprotocol” was developed for preparing human and computer reproducible protocols. Having already mentioned microsurgical techniques (Kriegman et al. 2020), it can be speculated that it might even be possible to include microsurgical automation protocols in certain cases. Fog or edge computing for decentralized, heterogenous systems could be considered to localize processing where appropriate, with benefits for distributed computing and latency/bandwidth reduction (Torabi et al. 2022). Strategies in this domain consider data replica placement throughout the distributed system. Given that the above automation relates to the “Internet Of Things” (IoT), such architectures may take into consideration intelligent resource scaling of such distributed systems (Etemadi et al. 2021).\n\nWhile liquid-handling robotics can hasten research via high-throughput, they occupy a large amount of space, and can be expensive and wasteful (Linshiz et al. 2016). Small volume laboratory experimentation was considered the future of biotechnology. A microfluidics platform utilizing electronically controlled pneumatically actuated microvalves allowed precision fluidic control at 150nL, including mixing, routing and automatic rinsing. PR-PR was software, with GUI, for instruction generation in robotic and microfluidic devices (Oberortner et al. 2017), providing high level programming processed by LabView for solenoid microvalve control (Linshiz et al. 2016).\n\nBiofoundries were reported as high-tech organizations for genetic reprogramming (Hillson et al. 2019). Biofoundries provided and promoted high-throughput, automated systems, CAD, ML, training, logistics, infrastructure, expertise, sustainability and standardization. The Regenerative Medicine Manufacturing Society promoted cell manufacturing for cell therapies, 3D bioprinting, bioreactors, cell counting/sorting, biofabrication of tissues/organs, AI (artificial intelligence) automation, cell harvesting, materials transport, training and supplying laboratories (Hunsberger et al. 2020). ASTM International worked towards standardizing bioinks for bioprinting, such as for drug delivery systems, tissue scaffolds, prosthetics, organoids and tissue/organ products. Biofoundries are reported to utilize the DBTL cycle to generate thousands of microbial strain variants through parallelized strategies, with screening in microbioreactors (Helleckes et al. 2023). Investigations aimed to resolve the automation of cryopreserved samples from an automatic deep-freezer for use with downstream BioLector microbioreactors and a Tecan Freedom EVO robotics platform. The robotic setup would include a robotic manipulator arm, microplate reader, centrifuge and microtiter plate handling. The process would include disinfection, preculture thawing and optical density triggered genetic expression induction of cultures via IPTG (Isopropyl β-D-1-thiogalactopyranoside). As a result of the phenotyping assays (in this case spectrophotometric), the generation of larger datasets was deemed to have shifted the “bottleneck” of the DBTL cycle towards the learn phase.\n\nThe following involves a non-exhaustive detailing of cutting edge technologies, hardware and services encountered at The Festival of Genomics & Biodata in London 2024. Hardware included a Tecan single cell dispenser (Tecan_Trading_AG. Uno 2024), DNA fragmentation via Megaruptor 3 allowing for subsequent long-read sequencing via technologies by PacBio and Oxford Nanopore sequencers (Diagenode. 2024), as well as chromatin and DNA shearing via Diagenode’s Bioruptor (Diagenode. Shearing technologies Bioruptor. 2024). Such companies offered a range of services, for example Diagenode offered ATAC-seq (Assay for Transposase-Accessible Chromatin) to analyse chromatin accessibility and ChIP-seq (Chromatin Immunoprecipitation Sequencing) to assess protein-DNA interactions. They also offered a DNA-methylation profiling range, as well as total RNA-seq and mRNA-seq. Also on display was the Promega Maxwell® Benchtop Automated DNA/RNA extractor (Promega_UK. 2024) for simplifying the purification of nucleic acids for downstream Next Generation Sequencing (NGS) and qPCR. NGS hardware included Illumina platforms (Illumina_Inc. 2024) and PromethION platform from Oxford Nanopore. The PromethION 24/48 (Oxford_Nanopore_Technologies_plc. 2024) offered a staggering 4 NVIDIA onboard GPUs, 512 GB RAM and 60 TB of storage. The single cell gene expression kit by Scale Biosciences (SCALEBIO. SINGLE CELL RNA SEQUENCING KIT. 2024) offered multiplexing, i.e. multiple cell high throughput, involving cell barcoding. Unchained Labs provisioned services for viral vector and lipid nanoparticle delivery, including hardware for lipid nanoparticle quality (Unchained_Labs 2024). Vendors also offered reagents for cell disassociation from tissue samples. Not noted at the festival, although possibly represented, would be cell sorting devices, such as via Flow Cytometry and Fluorescence-Activated Cell Sorting. Digital PCR, a more quantitative alternative to standard polymerase chain reaction, was also represented. It is easy to envision how such technologies can be linked together, including phenotypic profiling, for modern Synthetic Biology research and development, and the festival saw research representing leading organizations. For instance, sequenced data can be compared to one or more reference genomes or expression profiles.\n\n5.3 Combinatorial construct design languages\n\nWhile “forward-engineering” was considered viable for the future, combinatorial optimization (Fig. 8) was said to have great utility in SB (Naseri and Koffas 2020). For example, Proto Biocompiler could select parts and optimize circuit design based on specifications (Myers et al. 2017) as a language for genetic regulatory network generation (Beal et al. 2011). Such technologies can be coupled to other automation categories, notably assembly design. For example, JBEI developed Device Editor for combinatorial part-based DNA constructs with visualization through VectorEditor, while using J5 for automated DNA assembly design (Myers et al. 2017). As GDA was being pursued, design rules and standardization were being promoted, with cloning the focus of software development rather than function design (Lux et al. 2011), which would need to be addressed. BDA and GDA could utilize DSLs not dissimilar to the “Hardware Description Languages” of EDA (Bilitchenko et al. 2011; Konur et al. 2021; Smith et al. 2009; Pedersen and Phillips 2009).\n\nGEC was a formal language, with interface implementations, designed for simulation and modelling cycles to select for idealized SB genetic constructs (Pedersen and Phillips 2009) for combinatorial part automation (Pedersen and Andrew;. GEC Manual. 2016) using constraint-based programmatic syntaxes at the part level. Multiple compilations could result, allowing for rapid generation of operon variants (Pedersen and Phillips 2009). Selection capabilities were limited by the lack of well described parts registries containing detailed molecular properties. With Visual GEC discontinued by Microsoft, Lattice Automation and Asimov were approaching the industry with custom tailored software designs (Buecherl and Myers 2022). Similarly, Eugene was a human-readable “ecosystem” of languages for SB, inspired by EDA netlists of connected components (Bilitchenko et al. 2011).\n\nA laboratory combinatorial implementation involved the iBioFAB automated robotics platform integrated with ML and Spearmint source code (HamediRad et al. 2019), with the resulting platform named BioAutomata. Golden Gate assembly was performed by iBioFAB with the iScheduler software. Lycopene production (HamediRad et al. 2019; Exley et al. 2019) would be the output variable, whilst inputs would be via part selection. A T7 promoter region was mutated for strength, generating 12 promoters, and an RBS calculator was used to generate two RBSs of different strengths. The combination of promoters and RBSs yielded 24 unique expression levels, judged via eGFP fluorescence bound to the three expressed genes in the pathway. This project hence demonstrated the potential for ML to predict expression levels, i.e. phenotypic behaviour, from parts selection. Ultimately such design processes benefit from quantifiable dependent outputs relative to input independent variables, where the input variables of the experimental system can be given combinatorial treatment, and outputs can be of varying dimensionality, although in the above case would represent a univariate expression output.\n\n5.4 Circuit design\n\nCircuit design was encountered in relation to Synthetic Biology Suites (Sect. 4.5), and refers primarily to relatively small networks of interactions brought about by small synthetic genetic constructs, unlike genome scale reconstructions. Circuit design is also closely related to the aforementioned “Combinatorial Construct Design Languages”, as genetic constructs possess regulatory characteristics that control the behaviour of bioregulatory circuits. This discipline is expanded upon here (Fig. 9).\n\nSB first considered simple genetic circuits before their modular usage (Naseri and Koffas 2020), which would naturally increase the complexity of models. Genetic circuits can include disease marker detection designs, e.g. in lung cancer, and drug delivery (Buecherl and Myers 2022). However, wet-lab testing was still considered necessary since prediction tools had limited accuracy (Naseri and Koffas 2020) and required significant data input from high-throughput experimental transcriptomics, proteomics and metabolomics. For example, Tn-Core could use Tn-seq (transposon insertion sequencing) and RNA-seq data to generate models. Note that Tn-seq can be used to study functional disruptions of genes by transposon introduction.\n\nLogic gates with switching capabilities allow for decision making circuits (Yeoh et al. 2019). Gates can be perceived as nodes in the interactome of a genetic circuit, and potentially controllable in Boolean fashion (Nielsen, et al. 2016). NOT gates can operate via repressors (Cui et al. 2021). AND gates require the presence of multiple signals to allow for expression. OR gates require only the activation of one of multiple pathways. Complex (composite) logic gates include NAND, NOR and XOR. A deoxyribozyme-based circuit of 23 logic gates was reportedly able to play noughts and crosses (Miyamoto et al. 2013). Circuits include logic gates, toggle switches, oscillators (e.g. circadian), repressilators, clocks, French flag, pulse width modulators, memory, counters, decoders, encoders, multiplexers, perceptrons and biosensors (Chakraborty et al. 2022). One model used oscillator-driven DNA tweezers operating alongside an RNA aptamer. An automated biomodel selection platform (BMSS) was created in Python 3 and tested with models containing NOT, AND and OR gates along with inducible and constitutive expression, providing SBOL circuit design and SBML output of the best matched models contrasted to experiment (Yeoh et al. 2019). The BMSS system utilized fluorescence data from microplate readers, along with system perturbation evaluations.\n\nVerilog “Hardware Description Language” was repurposed for genetic circuit design (Nielsen, et al. 2016) and was parsed by Cello into a DNA sequence (Taketani et al. 2020). Genetic circuit generation from Verilog involved the formation of a netlist Boolean gate network description (Jones, et al. 2022). The user constraints file provided restrictions for the selection of part alternatives (Chakraborty et al. 2022), arranged into a DNA sequence according to Eugene language rules (Jones, et al. 2022). Combinatorial construct design algorithms were used for part alternatives or part order (Nielsen, et al. 2016) with subsequent simulation and possible identification of regulatory defects with comparisons made to experimental flow cytometry. The Cello workflow was applied to smart therapeutics (Taketani et al. 2020).\n\nSYNBADm was a Matlab implementation for automated optimization of genetic circuit design (Otero-Muras et al. 2016) utilizing multi-objective optimization for pareto optimality, an approach also mentioned in relation to TopoFilter for 3 enzyme networks (Chakraborty et al. 2022). TopoFilter was considered to have limited scalability due to its brute force approach. SYNBADm supported mass action and Hill kinetics upon construction of biological components/parts, as well as providing time-course simulations (Otero-Muras et al. 2016). This would require libraries of “components” and objective functions based around features such as production costs and circuit behaviours. SYNBADm was scalable to 9 nodes (Chakraborty et al. 2022). It was put forward that bioregulatory networks resemble neural networks, and hence ML has a suitable role to play in relation to them.\n\n5.5 Genetic optimization\n\nOnce a genetic construct has been initially designed, it is prudent to consider genetic optimization, not least due to the redundancy of the triplet code for encoding amino acids in codons. Subsequently, the required sequences may be synthesized de novo and/or stitched together through restriction and ligation. Genetic optimization alters the features of a genetic sequence, such as codon optimization and RBS translation initiation rates (Swainston et al. 2018), as well as exotic exercises such as optimizing riboswitches (Wu et al. 2019). Codon optimization may prevent ribosome stalling, ensure correct translation termination, modulate gene expression, prevent growth impairment, prevent frameshifts and prevent the misincorporation of AAs. It allows genes to be recycled between organisms (heterologous expression) (Villalobos et al. 2006; Gaspar et al. 2016).\n\nEuGene (not Eugene language) was a DNA optimization program that exploited online databases for codon usage, context tables and orthologs for sequence alignment (Gaspar et al. 2016). EuGene used data extraction from FASTA and GenBank, combined with homolog searches using BLAST. The PDB and KEGG databases provided EuGene more information on homologs, as well as protein structure and genomic expression levels. EuGene performed alignment using the MUSCLE algorithm. CAI (Codon Adaptation Index) was calculated through highly expressed genes. However, CAI use was advised against (Villalobos et al. 2006). The heterologous gene redesign algorithm used genetic algorithms (slow) or simulated annealing (fast) (Gaspar et al. 2016).\n\nGene Designer could edit and annotate in silico DNA constructs with functions including the addition of polyhistidine-tags or sequencing primers into a DNA sequence, the identification of restriction sites, and flagging for methylation sensitive restriction enzymes (Villalobos et al. 2006). Gene Designer could search for Open Reading Frames by their start and stop codons; as well as a search capability for RBSs and sequence motifs. It allowed manual codon triplet code manipulations, and could simulate cloning in silico via restriction sites, with cut plasmids selected for ligation considering overhangs. An alternative to CAI involved Codon Usage Tables. Gene Designer’s Codon Optimizer used a probabilistic Monte Carlo based algorithm able to find different, but essentially equivalent, outcomes. In-built vector types (Dixon 2023) included an E. coli plasmid (pT7-SNAP), and a mammalian plasmid (pMCPm™).\n\nAvailable via web application (Berkeley_Lab. BOOST Build 2022), JAR format and REST API, BOOST was a suite of software tools intended for the SB design-build transition (Oberortner et al. 2017), emphasizing automated DNA construct design for vendor synthesis. Consideration could be made regarding GC (strongly hydrogen bonding) content, repeats, secondary structures and restriction sites. BOOST commenced with codon usage optimization via Codon Tables. Violations could undergo “codon juggling” by translation to a polypeptide with codon modification via reverse-translation. “Relaxed Weight” or complete randomization could even out codon usages and reduce excessively used codons. With DNA length a factor for genetic construct assembly success, excessively short sequences were flagged and long sequences partitioned according to success probability. BOOST, for its three tools (Juggler, Polisher, Partitioner), accepted DNA sequences in various formats.\n\nRiboLogic was developed in Python to design Riboswitch sequences (Wu et al. 2019). Input involved ligand-binding aptamer sequences along with estimated dissociation constants and perhaps secondary structures of the activated state. RiboLogic optimized surrounding sequences for ligand binding simulations and utilized simulated annealing optimization with temperature reduction for possible sequences, along with random mutations and scoring mechanisms.\n\n5.6 Automating genetic construct assembly protocols\n\nDNA assembly generates constructs from DNA components/parts, and assembly standardization has been pursued by the SB community (Walsh et al. 2019), despite continued variability. DNA assembly involves vector design, assembly planning and liquid handling (Appleton et al. 2017). Traditionally, such techniques were manual, with restriction and ligation in separate steps. However, high-throughput DNA assembly was sought using assembly planning tools such as DNALD and Raven. Algorithms for joining two DNA fragments per assembly step were developed (Densmore et al. 2010). As DNA assembly evolved, one-pot restriction ligation toolkits were released (Exley et al. 2019). To generate variations of genetic constructs, the assembly of a “goal part” could be sought algorithmically, with each step represented on an “assembly graph” (Densmore et al. 2010), with time and financial costs estimated from resulting graph steps and levels. Algorithms for these purposes were implemented through the Clotho framework.\n\nA liquid-handling platform (Freedom EVO 150) was compared to manual DNA assembly using the MoClo methodology (Walsh et al. 2019) using variations of 5 part constructs. Transformation efficiency was measured in colony forming units (CFU) per volume, as observed by coloration. GenBank files were read by software called Puppeteer to create combinatorial variants with a fixed sequence of part types, and subsequent generation of a DNA assembly plan and protocols for humans and robots. Pipetting commands for a Tecan system were generated more rapidly with Puppeteer than if programmed with EvoWare. Manual versus automated CFU percentage outcomes demonstrated no difference. Thus a single assembly may be more suitable for a human, whilst larger numbers would suit robotics.\n\nJ5 was a web-based tool for design automation in scarless DNA assembly (Hillson et al. 2012) across multiple assembly methods. In a case study, GFP was tagged for localization and degradation, with combinatorial design potential. In such experiments, variants could number in the thousands and J5’s combinatorial assembly planning could save time. Constraints were applied to parts for combinatorial selection via Eugene-based rules, similarly to tools like Cello (Jones, et al. 2022). J5 could perform BLAST to check for flanking sequence similarity and potential incompatibilities (Hillson et al. 2012). Endonuclease generated overhangs must not combine with the wrong targets, which J5 could manage. As many as 2.4 billion overhang combinations were assessed. J5 performed simulated annealing, and could generate a PCR setup control file for the eXeTek liquid-handling robot, with future intent to apply such methods to the Tecan EvoLab.\n\nDNA Constructor software was used to design DNA combinatorial library construction protocols for a microfluidics platform (Linshiz et al. 2016). J5 and Device Editor were used to construct a combinatorial library. Assembly protocol outputs from DNA Constructor took the form of an”interactive assembly tree” via the DOT language of Graphviz (used for Figs. 3, 4, 5, 8, 9 in this review). Isothermal Hierarchical DNA Construction was automated on a 16 input and output well microfluidic chip. One pot Gibson assembly was used with the pETBlue-1 plasmid expression vector. Automated transformation of the plasmid into E. coli utilized the microfluidic chip, with subsequent plating of the cells. On-chip assays assessed cell growth, protein expression and colorimetry. Hence, combinatorial genetic sequence methods and library construction were combined with assembly protocols for microfluidics assays of transformed cells."
    }
}