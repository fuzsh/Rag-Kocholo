{
    "id": "dbpedia_1604_3",
    "rank": 60,
    "data": {
        "url": "https://www.mdpi.com/1424-8220/21/15/4961",
        "read_more_link": "",
        "language": "en",
        "title": "Railway Overhead Contact System Point Cloud Classification",
        "top_image": "https://pub.mdpi-res.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g001-550.jpg?1626942725",
        "meta_img": "https://pub.mdpi-res.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g001-550.jpg?1626942725",
        "images": [
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-black-small1.svg?da3a8dcae975a41c?1723031622",
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-black-small1.svg?da3a8dcae975a41c?1723031622",
            "https://pub.mdpi-res.com/img/journals/sensors-logo.png?8600e93ff98dbf14",
            "https://pub.mdpi-res.com/bundles/mdpisciprofileslink/img/unknown-user.png?1723031622",
            "https://pub.mdpi-res.com/bundles/mdpisciprofileslink/img/unknown-user.png?1723031622",
            "https://pub.mdpi-res.com/bundles/mdpisciprofileslink/img/unknown-user.png?1723031622",
            "https://pub.mdpi-res.com/bundles/mdpisciprofileslink/img/unknown-user.png?1723031622",
            "https://pub.mdpi-res.com/bundles/mdpisciprofileslink/img/unknown-user.png?1723031622",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1723031622",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/profiles/1372957/thumb/Wei_Xiang.png",
            "https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1723031622",
            "https://www.mdpi.com/profiles/89534/thumb/Rui_Zhang.jpg",
            "https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1723031622",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g001-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g001.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g002-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g002.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g003-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g003.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g004-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g004.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g005-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g005.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g006-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g006.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g007-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g007.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g008-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g008.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g009-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g009.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g010-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g010.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g011-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g011.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g012-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g012.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g013-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g013.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g014-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g014.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g015-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g015.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g016-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g016.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g017-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g017.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g018-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g018.png",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g019-550.jpg",
            "https://www.mdpi.com/sensors/sensors-21-04961/article_deploy/html/images/sensors-21-04961-g019.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-white-small.png?71d18e5f805839ab?1723031622"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Xiao Chen",
            "Zhuang Chen",
            "Guoxiang Liu",
            "Kun Chen",
            "Lu Wang",
            "Wei Xiang",
            "Rui Zhang"
        ],
        "publish_date": "2021-07-21T00:00:00",
        "summary": "",
        "meta_description": "As the railway overhead contact system (OCS) is the key component along the high-speed railway, it is crucial to detect the quality of the OCS. Compared with conventional manual OCS detection, the vehicle-mounted Light Detection and Ranging (LiDAR) technology has advantages such as high efficiency and precision, which can solve the problems of OCS detection difficulty, low efficiency, and high risk. Aiming at the contact cables, return current cables, and catenary cables in the railway vehicle-mounted LiDAR OCS point cloud, this paper used a scale adaptive feature classification algorithm and the DBSCAN (density-based spatial clustering of applications with noise) algorithm considering OCS characteristics to classify the OCS point cloud. Finally, the return current cables, catenary cables, and contact cables in the OCS were accurately classified and extracted. To verify the accuracy of the method presented in this paper, we compared the experimental results of this article with the classification results of TerraSolid, and the classification results were evaluated in terms of four accuracy indicators. According to statistics, the average accuracy of using this method to extract two sets of OCS point clouds is 99.83% and 99.89%, respectively; the average precision is 100% and 99.97%, respectively; the average recall is 99.16% and 99.42%, respectively; and the average overall accuracy is 99.58% and 99.69% respectively, which is overall better than TerraSolid. The experimental results showed that this approach could accurately and quickly extract the complete OCS from the point cloud. It provides a new method for processing railway OCS point clouds and has high engineering application value in railway component detection.",
        "meta_lang": "en",
        "meta_favicon": "https://pub.mdpi-res.com/img/mask-icon-128.svg?c1c7eca266cd7013?1723031622",
        "meta_site_name": "MDPI",
        "canonical_link": "https://www.mdpi.com/1424-8220/21/15/4961",
        "text": "Open AccessArticle\n\nRailway Overhead Contact System Point Cloud Classification †\n\nby\n\nXiao Chen\n\n1 ,\n\nZhuang Chen\n\n1 ,\n\nGuoxiang Liu\n\n1,2 ,\n\nKun Chen\n\n1 ,\n\nLu Wang\n\n3 ,\n\nWei Xiang\n\n1 and\n\nRui Zhang\n\n1,2,*\n\n1\n\nFaculty of Geoscience and Environmental Engineering, Southwest Jiaotong University, Chengdu 611756, China\n\n2\n\nNational and Local Joint Engineering Laboratory of Safe Space Information Technology for High-Speed Railway Operation, Southwest Jiaotong University, Chengdu 611756, China\n\n3\n\nDepartment of Road and Bridge Engineering, Sichuan Vocational and Technical College of Communications, Chengdu 611130, China\n\n*\n\nAuthor to whom correspondence should be addressed.\n\n†\n\nThis paper is an extended version of Xiao Chen, Guoxiang Liu, Zhen Chen, Zhuang Chen, Rui Zhang, Zhanguang Wu, Xianzhang Zhou, Railway contact point cloud classification extraction. In Proceedings of the Sixth National LiDAR Conference, International Conference Center of China University of Geosciences, Beijing, China, 20–22 November 2020.\n\nSensors 2021, 21(15), 4961; https://doi.org/10.3390/s21154961\n\nSubmission received: 15 June 2021 / Revised: 12 July 2021 / Accepted: 16 July 2021 / Published: 21 July 2021\n\n(This article belongs to the Special Issue Selected Papers from The Sixth National LiDAR Conference)\n\nAbstract\n\n:\n\nAs the railway overhead contact system (OCS) is the key component along the high-speed railway, it is crucial to detect the quality of the OCS. Compared with conventional manual OCS detection, the vehicle-mounted Light Detection and Ranging (LiDAR) technology has advantages such as high efficiency and precision, which can solve the problems of OCS detection difficulty, low efficiency, and high risk. Aiming at the contact cables, return current cables, and catenary cables in the railway vehicle-mounted LiDAR OCS point cloud, this paper used a scale adaptive feature classification algorithm and the DBSCAN (density-based spatial clustering of applications with noise) algorithm considering OCS characteristics to classify the OCS point cloud. Finally, the return current cables, catenary cables, and contact cables in the OCS were accurately classified and extracted. To verify the accuracy of the method presented in this paper, we compared the experimental results of this article with the classification results of TerraSolid, and the classification results were evaluated in terms of four accuracy indicators. According to statistics, the average accuracy of using this method to extract two sets of OCS point clouds is 99.83% and 99.89%, respectively; the average precision is 100% and 99.97%, respectively; the average recall is 99.16% and 99.42%, respectively; and the average overall accuracy is 99.58% and 99.69% respectively, which is overall better than TerraSolid. The experimental results showed that this approach could accurately and quickly extract the complete OCS from the point cloud. It provides a new method for processing railway OCS point clouds and has high engineering application value in railway component detection.\n\n1. Introduction\n\nWith the rapid development of railway electrification, the reliability and safety of railway traction power equipment is a key research issue [1,2,3]. Among them, the detection of railway overhead contact systems (OCS) is the key link to ensure the normal operation of railway traction electric power. The overhead contact system shown in Figure 1a is the infrastructure of the power supply for trains. Under the influence of pantograph and environmental factors, the components of OCS, such as contact cables, return current cables, and catenary cables, are prone to deformation. These deformations may cause instability of the power supply, affect the durability of components, and even cause accidents [4]. Therefore, the regular detection of OCS to ensure its stability is of great significance for the normal operation and safety of the railway system. Although the conventional manual monitoring method shown in Figure 1b is more flexible, there are many shortcomings in artificial detection such as low efficiency, high risk, and human factors such as personnel experience, which can affect detection results. Therefore, it has been unable to meet the existing detection needs [5,6,7,8]. At present, determining the detection method with high efficiency, high precision, and low risk has become a research hotspot.\n\nThe research on the high-efficiency detection work of the OCS started relatively early. Kusumi et al. [9] developed an OCS inspection system that can be installed on rail vehicles. Liu et al. [10] described a wireless system for monitoring a railway’s signaling, control, or infrastructure condition. In 2012, the Ministry of Railways of China proposed a ‘High-speed Railway Power Supply Security Detection and Monitoring System,’ named the ‘6C’ system [4]. However, due to the limitations of the accuracy of sensors, equipment size, and corresponding algorithms, it is difficult to achieve the desired effect in railways.\n\nWith the rapid development of detection technology, the Light Detection, and Ranging (LiDAR) measurement system has become an effective method for solving these problems. Manual inspection requires operators to carry measuring instruments for measurement in a limited skylight period; generally, the efficiency is low and influenced by subjective factors and environmental factors, and there are many hidden dangers on site, which brings many problems to prevention and control. Compared with the conventional methods, LiDAR technology has the advantages of high detection efficiency, good accuracy, non-contact, and being less affected by environmental factors [11,12]. LiDAR systems can quickly and accurately obtain a large number of 3D point clouds and extract valuable spatial data with details that cannot be achieved by previous patrol detection techniques [13]. It has a unique advantage in the acquisition of 3D information of railways in complex and even dangerous areas and has a great application prospect in the detection of OCS [14,15]. Therefore, the classification of OCS from the point cloud is an effective method for OCS detection [16,17]. Due to the cost and special environmental conditions of the railway, it is not suitable to obtain point clouds using airborne LiDAR and drones, which are widely used to obtain OCS point clouds. Therefore, vehicle-mounted LiDAR is the best choice to obtain OCS point clouds. Scholars have done some research on the theory and algorithm of extracting OCS and other facilities from point clouds containing environmental factors. Mostafa [18] developed an automated method to recognize railroad infrastructure from 3D LiDAR data. The proposed methodology recognizes key components of the railroad corridor based on their physical shape, geometrical properties, and the topological relationships among them. Zhang et al. [19] used principal component analysis combined with information entropy theory to achieve the extraction of power lines, and the method is based on vehicle-mounted LiDAR data and the parallel characteristics of power lines and rails. Jung et al. [20] designed a classifier based on the MrCRF (multi-range Conditional Random Field) and SVM (support vector machine) to identify ten key components introducing neighbor information for the misclassification caused by similar features. The MrCRF only takes spatial information within limited ranges and does not consider the shape and size variance. Arastounia [21] identified contact cables by applying a region growing algorithm and then classified catenary cables according to the positional relationship between the contact cables and catenary cables. Sánchez-Rodríguez et al. [14] presented a method for automatically inspecting the clearance gauge and the deflection of the aerial contact line in railway tunnels. Ariyachandra and Brilakis [22] detected lines using RANSAC and classified cables based on the heights of the lines relative to the track structure. Gutiérrez-Fernández et al. [23] presented a new method for the automatic extraction of power cable locations in railways using surface LiDAR systems. Lin et al. and [7] presented a method based on deep learning to recognize point clouds of OCS components. In general, the mean extraction accuracy of these methods can reach 92–98%. At present, the extraction of OCS from point clouds mainly relies on the structural characteristics of the OCS and their positional relationship with the track; the clustering method is mainly used. This process will bring more errors, and it is necessary to set thresholds when extracting the trackbed and the OCS, which is more subjective. For catenary cables with large curvatures, the effect is often poor. Recently, deep convolutional neural networks for point cloud segmentation [24,25] have been brought into being, but this method is less used in the extraction of OCS. The point clouds of the catenary are large-scale, and a few hundred meters of railway scene can contain more than 100,000 points. Therefore, it is quite hard to train a good segmentation model with whole scene data, which requires high memory and training time costs. There are also researchers using voxel-based, patch context analysis, improved PCA (principal component analysis), improved region growing method, and other methods to achieve effective large-scale point cloud classification [26,27,28,29,30,31]. However, for such a long and narrow point cloud set, to achieve precise extraction and classification, these methods may require further research. Increasing the amount of LiDAR can effectively increase the perception range of visual systems and the density of point clouds [32,33] while bringing problems of point cloud splicing, camera calibration, data volume, and cost.\n\nThis paper aims to develop algorithms to reduce the subjective selection process of parameters, extract and make full use of the spatial distribution characteristics of the target points and improve the accuracy of classification extraction. We adopted a scale adaptive feature classification algorithm and the DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm considering OCS characteristics to classify the target point cloud in this paper. The scale adaptive feature classification algorithm and entropy eigenvalue were adopted to judge the distribution of geometric structure features of the point cloud in 3D space realized rough classification of OCS point cloud to maximize the retention of the target point cloud and reduce the calculation time and complexity of fine classification. We introduced the entropy eigenvalue to reduce the difficulty of parameter selection in the rough classification process. Then, the DBSCAN algorithm was utilized to classify OCS precisely.\n\n2. Methodology\n\nTo complete the classification task of OCS, this section adopted a coarse to fine classification method. Firstly, the non-ground point cloud is roughly classified to maximize the retention of the target point cloud, reduce the calculation time and complexity of fine classification, and improve the accuracy of fine classification. Furthermore, the target point cloud is classified more accurately based on the rough classification. This section focuses on the scales adaptive feature classification algorithm and uses the algorithm for the fine classification of non-ground point clouds.\n\n2.1. Removing Ground Points\n\nBefore the OCS classification, the ground points in the point cloud need to be removed, and we use the Euclidean distance clustering segmentation algorithm [34,35] to achieve this goal. The method refers to the actual distance between points in m-dimensional space. The calculation formula is as follows:\n\nd L = ∑ n p − q 2\n\n(1)\n\nQ = p , q | d L < r , p , q ∈ P\n\n(2)\n\nwhere dL is the distance between two points, Q represents the processed points, and P is the 3D point cloud set.\n\nThe basic principle of the Euclidean distance clustering segmentation algorithm is to traverse all points in the point cloud as a point clustering center. We then judge the similarity between the remaining points and clustering centers according to the Euclidean distance between the cluster centers and the remaining points. We assign each point to the cluster that is most similar to that point. Lastly, the center of each new cluster is recalculated, and the above process is repeated until the loop center converges and the segmentation of the point cloud can be completed.\n\n2.2. Rough Classification\n\nTo classify most OCS points in the non-ground point cloud, this paper takes the scale geometric structure features (dimensional features) of the point as the basis of classification. We combine the scale feature classification algorithm [36,37] with the entropy eigenvalue to form a new algorithm called the scale adaptive feature classification algorithm. We use the algorithm to realize the rough classification of the OCS point cloud. Before analyzing the distribution of geometric structure features, the points in the neighborhood of each target point (i.e., target point set) are searched; the selection of the best neighborhood radius is elaborated in Section 2.2.3. Furthermore, the covariance matrix and eigenvalues corresponding to the target point sets are calculated. Secondly, the relationship between the eigenvalues is analyzed, and then the geometric structure distribution characteristics of the target points in 3D are obtained. The contact cable, return current cable, and catenary cable in OCS are linear structure characteristics, so all the data with linear distribution characteristics in the point cloud are retained.\n\nThe scale adaptive feature classification algorithm aims at finding the best neighborhood radius of each point and working directly in 3D space to calculate the geometric structure distribution characteristics of the target point in 3D space. The algorithm mainly includes two steps:\n\nTraverse the predefined minimum and maximum neighborhood scales in a certain step. The 3D features of points in the different neighborhood radii of the target point are calculated to represent the geometric structure distribution of the point in 3D space, which can be divided into linear features (1D), planar features (2D), and discrete features (3D);\n\nSelection of the best neighborhood-scale r: when searching for the neighborhood radius, select a neighborhood radius to make one of the dimensional features of the point in the neighborhood more obvious than the other two. By comparing the dimension results of these three features in the range of minimum radius and maximum radius, the best radius is determined.\n\nIn the process of obtaining geometric structure features, the research focuses on calculating the dimension features contained in the neighborhood of the target point. The neighborhood points v P r are all the points surrounded by the sphere, with the target point P as the center and the scale r as the radius. P k is a set of points that need to be verified, the mathematical expression is as follows:\n\nP k ∈ v P r ⇔ P − P k ≤ r\n\n(3)\n\nTherefore, the 3D sphere is used to define the neighborhood shape. The definition method is isotropic and rotation invariant so that the geometric features are not affected by the shape deviation of the neighborhood, and r is the only parameter to be optimized.\n\n2.2.1. Calculation of Eigenvalue\n\nTo obtain the three-dimensional feature distribution of the target points in the three-dimensional space, it is necessary to find the X, Y, and Z coordinate values in the point cloud set and calculate the covariance matrix and eigenvalues corresponding to the point cloud set.\n\nFirst, let x = x 1 , y 2 , z 3 T , X ¯ = 1 n ∑ i = 1 n X i is the center of gravity of n points, M = ( X 1 − X ¯ , X 2 − X ¯ , … , X n − X ¯ ) T , and the corresponding covariance matrix C is as follows:\n\nC = 1 n M T M\n\n(4)\n\nC is the covariance matrix of 3 × 3 and is a symmetric positive definite matrix.\n\nThe eigenvalue decomposition of C is expressed as:\n\nC = R Λ R T\n\n(5)\n\nAccording to the eigenvalue decomposition of the covariance matrix, the eigenvalues λ 1 , λ 2 , and λ 3 ( λ 1 ≥ λ 2 ≥ λ 3 > 0 ) can be obtained. Let δ j = λ j , ∀ j ∈ [ 1 , 3 ] , denote the standard deviation in the direction of the corresponding feature vector. The PCA algorithm can be used to obtain the three main directions of v P r , and the size of the eigenvalues obtained indicates their importance.\n\n2.2.2. Geometric Feature Analysis\n\nGeometric structure features can be judged according to the size of the feature value. The discriminant index [38,39] can be divided into linear features ∂ 1 D , planar features ∂ 2 D , and discrete features ∂ 3 D ; the formula is as follows:\n\n∂ 1 D = δ 1 − δ 2 u\n\n(6)\n\n∂ 2 D = δ 2 − δ 3 u\n\n(7)\n\n∂ 3 D = δ 3 u\n\n(8)\n\nwhere u is the normalization coefficient, when u = δ 1 or u = ∑ d = 1 , 3 δ d , we get ∂ 1 D , ∂ 2 D , ∂ 3 D ∈ [ 0 , 1 ] . To simplify the calculation and expression, we take u to be δ 1 , then ∂ 1 D + ∂ 2 D + ∂ 3 D = 1 .\n\nWhen δ 1 ≫ δ 2 , δ 3 ≃ 0 and the value of α 1 D is greater than the value of α 2 D and α 3 D , the point cloud set represents a linear feature distribution. If δ 1 , δ 2 ≫ δ 3 ≃ 0 and the value of α 2 D is greater than the value of α 1 D and α 3 D , the point cloud set represents a planar feature distribution. When δ 1 ≃ δ 2 ≃ δ 3 and the value of α 3 D is greater than the value of α 1 D and α 2 D , the point cloud set represents a discrete feature distribution.\n\n2.2.3. Selection of Scale\n\nBefore analyzing the geometric structure of the point, it is necessary to determine the r. We set multiple radii r so that the target point shows different geometric structure distribution characteristics under different r [40,41]. By changing the value of r, we construct a spherical space neighborhood of different sizes with the target point as the center, thus forming a scale space. The neighborhood distributions of point clouds in different scale spaces are shown in Figure 2, in which the blue triangular points represent the points in the neighborhood.\n\nIn the first scale, the sample data represent linear features, namely one-dimensional features; in the second scale, the sample data represent planar features, namely two-dimensional (2D) features, and in the third scale, the sample data represent discrete features, namely three-dimensional (3D) features.\n\nTo determine the best neighborhood scale, the upper and lower bounds r min and r max of scale r are determined. The setting r min depends on the noise of the point cloud, the specifications of the sensor, and the constraints of the calculation. The r max can be directly selected according to the scale of the largest object in the scene.\n\nTo choose the best scale, the entropy eigenvalue Ef is introduced. This unpredictable measure is given by the information entropy of the discrete probability distribution α 1 D , α 2 D , α 3 D ; the entropy of the point cloud set v P r is defined as follows:\n\nE f ( v P r ) = − α 1 D ln ( α 1 D ) − α 2 D ln ( α 2 D ) − α 3 D ln ( α 3 D )\n\n(9)\n\nWhen the entropy E f ( v P r ) is smaller, it means that all the features of the point cloud set are more concentrated in one of the dimensions. Then we can get the definition of the best scale r E f * :\n\nr E f * = arg min E f v p r , r ∈ [ r min , r max ]\n\n(10)\n\nEach point in the point cloud can be calculated to obtain different entropy feature values under different neighborhood scales. In order to select the best neighborhood-scale r value, we need to traverse all points in the point cloud at different neighborhood scales, calculate the entropy eigenvalues of all points, and obtain an average value of entropy eigenvalues. When the average value of entropy eigenvalues reaches the minimum, the corresponding neighborhood scale r is the best scale.\n\nThen we can get the radius of the most concentrated feature between rmin and rmax.\n\n2.3. Fine Classification\n\nMost non-target points are removed after the rough classification, and then this paper used the DBSCAN algorithm, which takes into account the characteristics of OCS to realize the fine classification of the OCS point cloud. The algorithm combines the traditional DBSCAN algorithm with the spatial feature information of OCS to achieve the final goal of accurate classification.\n\nDBSCAN is a density-based clustering algorithm, which has been widely used in the classification of point clouds. The clustering recognition of this algorithm is not affected by noise points, and the time complexity is low [42,43]. The algorithm includes two steps:\n\nSet the values of the neighborhood radius Eps and density MinPts, select the point P that meets the requirements of the two parameters through the distance metric and find all the density-reachable object points from P to form a cluster;\n\nRepeat step 1 until all the points are processed. The algorithm will be described in detail below.\n\n2.3.1. Determination of Clustering Parameters\n\nBefore implementing the DBSCAN algorithm, we need to set reasonable parameters of density MinPts and neighborhood radius Eps [44] to filter the point cloud.\n\nThe value of Eps can be obtained by the k-dist distance curve [42], and the critical inflection point of the k-dist distance curve is the corresponding better Eps value. If the value is too small, most of the data can not be clustered; if the value is too large, multiple clusters and most of the objects will be merged into the same cluster. The choice of the value of k depends on the user’s experience. Finally, take k to be MinPts. This method of determining Eps based on statistical characteristics of the k-dist curve analysis data is called the heuristic method, which is suitable for 2D and 3D data.\n\nFor the selection of parameter MinPts [45], it is the minimum expected cluster size; that is, a cluster is composed of at least MinPts points. As a guiding principle:\n\nM i n P t s ≥ d i m + 1\n\n(11)\n\nAmong them d i m represents the dimension of the data to be clustered.\n\nIt is unreasonable to take MinPts equal to 1 because when it is set to 1, each independent point is a cluster, and the result is the same as the nearest neighbor of the hierarchy distance. Therefore, MinPts must be greater than 3. If the value is too small, the result in the sparse cluster will not be used for further expansion of the class because the density is less than MinPts; if the value is too large, two neighboring clusters with higher density may merge into the same cluster.\n\nAfter setting the two parameters values of MinPts and Eps, we take the Euclidean distance as a measure [46,47] to select the data point P that meets the requirements of the two parameters.\n\n2.3.2. Principle of DBSCAN Algorithm Considering Railway OCS Characteristics\n\nAccording to the characteristics of the number of overhead conductors and the constant structure distribution, the contact cable and return current cable are almost in the same plane. The height of the catenary cable is the highest, and it is directly above the contact cable. According to the above characteristics, we use the DBSCAN algorithm that combines the spatial position relationship between cables of OCS to realize the fine classification of OCS cloud data. The principle of the algorithm is as follows:\n\nSelect the Eps value and MinPts value according to the method in Section 2.3.1, and perform DBSCAN clustering on OCS point cloud after rough classification.\n\nAfter clustering, the number of points of each cluster is compared and sorted. Because the data volume of contact cable, catenary cable, and return current cable in the point cloud after rough classification is in the top three of the whole data set, the top three point clouds are saved and the remaining data set is deleted.\n\nCompare the values in the Z direction in the three saved point clouds. Compare the calculated Z-means of each group of clusters, and the group of clusters with the largest Z-mean value is judged as the catenary cable point cloud.\n\nTaking the catenary cable point cloud as the reference object, the Euclidean distance between the remaining two groups of cluster point cloud and catenary cable point cloud on the XOY plane is calculated, respectively. The cluster with a smaller Euclidean distance is the contact cable point cloud, and the cluster with a larger Euclidean distance is the return current cable point cloud.\n\nThe algorithm flow is shown in Figure 3.\n\n3. Data Acquisition and Experiment\n\n3.1. Experimental Data\n\nThe experimental data used in this paper are the point clouds with lengths 100 m and 50 m that are intercepted from the vehicle-borne LiDAR of a domestic railway trunk line. The point cloud was collected by the German Z + F three-dimensional laser scanner profiler 9012; Table 1 shows the technical parameters of the scanner. Figure 4 shows the point cloud collection equipment and its installation location. Euclidean distance clustering was performed on the collected point cloud to obtain a non-ground point cloud, which is the experimental data in this article. Figure 5 shows the original point cloud. Figure 6 and Figure 7 show the experimental data with a length of 50 m and 100 m, respectively. Next, we conducted experiments on these two sets of data separately.\n\nThe LiDAR system was installed on the locomotive, roughly located on the vertical plane of the track centerline. The installation of the equipment does not cost too much time. Railway OCS is set above the track; only the ground points need to be removed to get the OCS point cloud with noise points. Ground points can be removed by Euclidean distance clustering. The removal of ground points is relatively simple. Overall, the data used in this article will not require a great amount of upstream work.\n\n3.2. Rough Classification\n\nAccording to the algorithm in Section 2, the feature distribution of the point cloud can be obtained. Firstly, select the scale according to the factors of boundary selection, adjustment accuracy, and calculation time. We sample r values between [0.1, 3.0] as multiple spatial scales (i.e., multiple neighborhood radii r) for experiments. We choose 0.02 as the iteration step because the scan line spacing of LiDAR is between 0.02 and 0.03. The minimum value of r is selected based on experience; usually, five times the distance between scanning lines, and the maximum value of r is select based on the largest object. Secondly, we use PCA to calculate the three main directions of v P r in the candidate spatial scale and analyze whether the points are set in the linear distribution (one-dimensional feature). Finally, we retain and output the linear distribution feature point cloud. In order to select the best scale, we calculate the entropy eigenvalue Ef of each point in the point cloud and find the average value of the entropy eigenvalues of all points. When the mean value of the entropy eigenvalue is the smallest, the corresponding scale is the best scale r E f * . According to the calculation results, Figure 8 and Figure 9 show the mean entropy eigenvalue of 50 m of OCS data and 100 m of data changes with the radius of the neighborhood, respectively. For the 50 m OCS point cloud, when the neighborhood radius r is equal to 0.90, the mean value of entropy eigenvalue reaches the minimum. Therefore, we select 0.90 as the best neighborhood scale. Likewise, we select 0.88 as the best neighborhood scale for the 100 m OCS point cloud.\n\n3.3. Fine Classification\n\nBefore the classification using the DBSCAN algorithm considering the characteristics of the OCS, the SOR (Statistical Outlier Removal) filter was used to denoise the point cloud after the rough classification, which is essential to further remove part of the non-OCS point cloud.\n\nFirstly, determine the values of MinPts and Eps according to the clustering parameter determination method in Section 2.2.1, and then the overhead contact system fine classification experiment is carried out. We count the neighborhood density of the point cloud after rough classification. The graph of the number of points changing with the neighborhood density is shown in Figure 10 and Figure 11. As the figures show, most points are concentrated in a certain density range, and we treat the density as valid density ranges. The density ranges of 50 m data and 100 m data are 38–145 and 50–325, respectively.\n\nTake the smaller point cloud density of the data set as the minimum expected cluster. Take MinPts of 50 m point cloud equal to k, k equal to 38, and then draw the ascending k-dist graph through the heuristic method to determine the value of Eps according to the information in the graph. Figure 12 shows the k-dist graph of the 50 m OCS point cloud. Similarly, for the 100 m data, take MinPts equal to 50, and Figure 13 shows the k-dist graph of the 100 m OCS point cloud.\n\nIn Figure 12 and Figure 13, the abscissa represents the number of points, and the ordinate represents the k-dist corresponding to the number of points. Then, by sorting the k-dist map, the recessed area, which is the threshold dividing point (critical value), is obtained. Therefore, the MinPts of the 50 m OCS point cloud and 100 m OCS point cloud are equal to 38 and 50, respectively. The required Eps value is the k-dist value corresponding to the threshold point; at this time, Eps = 0.8 in the two datasets. After determining the parameter values of MinPts and Eps, the final OCS fine classification is performed on the experimental data using the DBSCAN algorithm that takes into account the characteristics of the OCS.\n\n4. Results and Discussion\n\n4.1. Results of Classification\n\n4.1.1. Results of Rough Classification\n\nDue to a large number of points in the large scene, to obtain a more accurate linearly distributed feature point cloud (OCS point cloud), this paper iterated the methods in Section 2.1. The final results of the two sets of point clouds are shown in Figure 14 and Figure 15.\n\nMultiple calculations have significantly reduced the point cloud of the OCS mast and cantilever. Therefore, after many iterations of the experiment, as many OCS points as possible are retained to lay a good data foundation for the subsequent fine classification. As shown in Figure 14 and Figure 15, a large number of points of OCS poles and masts have been eliminated, and a small number of OCS poles and masts with linear distribution characteristics are left. The point cloud of the overhead contact system is almost completely retained.\n\n4.1.2. Results of Fine Classification\n\nAfter determining the parameter values of MinPts and Eps, the DBSCAN algorithm considering the characteristics of OCS is used to classify the OCS. The red point cloud is classified as a contact cable, the green point cloud is a catenary cable, and the pink point cloud is a return current cable. The previously deleted and unclassified point clouds are merged into a point set as the imprecise and incomplete OCS mast point cloud, which includes some noise points and OCS clouds that had been wrongly deleted. The classification results of the two point clouds are shown in Figure 16 and Figure 17.\n\n4.2. Performance Evaluation\n\nIn order to evaluate the accuracy of the extraction algorithm of OCS, we use four accuracy evaluation indexes in pattern recognition, namely precision, recall, accuracy, and overall accuracy [47]. To compare and analyze the number of points of the contact cable, return current cable, and catenary cable extracted by the algorithm and the actual points of the three.\n\n(1) Precision: refers to the percentage of the extracted OCS points in the real OCS points. (Real railway OCS points refer to manually classified OCS points, the same below)\n\nPrecision = T P T P + F P × 100 %\n\n(12)\n\n(2) Recall: refers to the percentage of the real OCS points judged as railway OCS points in the extracted railway OCS points.\n\nRecall = T P T P + F N × 100 %\n\n(13)\n\n(3) Accuracy: refers to the percentage of the total point cloud judged as the OCS point in the total point cloud.\n\nAccuracy = T P + T N T P + T N + F P + F N × 100 %\n\n(14)\n\n(4) Overall accuracy: as a measure of overall accuracy, it refers to the harmonic mean value of accuracy and recall α = 1 .\n\nOverall accuracy = ( α 2 + 1 ) × Precision × Recall α 2 ( Precision + Recall ) × 100 %\n\n(15)\n\nwhere TP, TN, FP, and FN denote true positive, true negative, false positive, and false negative, respectively. A more detailed explanation is as follows, TP is the number of real OCS points in OCS extraction; TN is the number of real non-OCS points in non-OCS extraction; FP is the number of non-OCS points wrongly classified as OCS points in OCS extraction; FN is the number of OCS points wrongly classified as non-OCS in OCS extraction.\n\n4.2.1. Classification Accuracy Evaluation\n\nThrough manual classification, the correct number of points of the contact cable, return current cable, and catenary cable is counted and compared with the number of points obtained by the experimental classification algorithm in this paper. The values of TP, TN, FP, and FN of the point clouds with a length of 50 m and 100 m are calculated, and then the corresponding precision indexes are calculated through the above four precision evaluation parameter formulas, as shown in Table 2, Table 3 and Table 4.\n\nIt can be seen from Table 3 that the average accuracy of classification of the 50 m OCS point cloud with the proposed classification algorithm is 99.83%, the average precision is 100.00%, the average recalls is 99.16%, and the average overall accuracy is 99.58%.\n\nAs shown in Table 4, the average accuracy of classification of the 100 m OCS point cloud with the proposed classification algorithm is 99.89%, the average precision is 99.97%, the average recall is 99.42%, and the average overall accuracy is 99.69%. The classification effect of the 100-m-long OCS point cloud is similar to that of the 50-m-long OCS point cloud data.\n\nThis paper used a scale adaptive feature classification algorithm combined with the DBSCAN classification algorithm considering characteristics of the OCS to classify the test point clouds of OCS, and all indicators show that it obtains good experimental results.\n\n4.2.2. TerraSolid Software Processing Results\n\nIn order to verify the accuracy and reliability of the algorithm proposed in this article, we use TerraSolid point cloud processing software to classify the two sets of OCS point clouds in this paper and compare the results of the two methods. The result of TerraSolid processing is shown in Figure 18 and Figure 19, respectively.\n\nAfter statistics, the values of TP, TN, FP, and FN are calculated, and then the corresponding accuracy indicators are calculated by the above four accuracy evaluation parameter formulas. The indicators are shown in Table 5 and Table 6.\n\nCompare the accuracy indexes of OCS cables extracted by the methods in this paper with the accuracy indexes of OCS cables extracted by Terrasolid. The results are shown in Table 7.\n\nFor the 50-m-long OCS point cloud, the average accuracy of Terrasolid and the algorithm proposed in this paper to extract OCS is 99.80% and 99.83%, respectively; the average precision is 99.99% and 100.00%, respectively; the average recalls are 99.03% and 99.16% respectively; and the average overall accuracy is 99.51% and 99.58% respectively. Obviously, for this set of data, the accuracy of these two methods is very good, and the difference is low.\n\nFor the 100-m-long OCS point cloud, the average accuracy of Terrasolid and the algorithm proposed in this paper to extract OCS is 99.81% and 99.89%, respectively; the average precision is 99.99% and 99.97%, respectively; the average recalls are 98.92% and 99.42% respectively; the average overall accuracy is 99.45% and 99.69% respectively. The results show that the algorithm proposed in this paper and Terrasolid used to extract OCS have achieved good classification results and high accuracy. In the average of the four accuracy indicators, except for the precision, the algorithm proposed in this paper is better than the Terrasolid. The extraction accuracy of the catenary cable and the return line is equivalent, but as shown in Table 7, the overall accuracy of the Terrasolid for extracting the OCS is 98.98%, which is significantly lower than that of the contact cable and the return current cable. In conclusion, the method proposed in this paper is more effective in extracting the OCS.\n\n4.3. Discussion\n\nIn the process of rough classification, the result of OCS by the scale adaptive classification algorithm is not very satisfactory because a few of the points of the mast and cantilever are also considered to be in a linear distribution. Therefore, in order to achieve better classification effects and remove most non-target points, the point cloud is processed multiple times. When the difference between the number of points of the last two iterations is less than 10, we stop the iteration.\n\nDue to the point density or the data quality, the cluster of the same linear object will be discontinuous. The clustering method based on normal is used to merge the discontinuous sub-clusters. The specific process is to traverse all clusters, find the position of two endpoints of each cluster and obtain its direction vector, then classify the two sub-clusters with a similar distance between endpoints and smaller angle of direction vector into one cluster.\n\nThe algorithm proposed in this article needs to use the geometric structure characteristics of the OCS, and the automatic classification of OCS can be realized after inputting the prior structure information of OCS. Terrasolid is a semi-automatic extraction software. As far as the experimental data in this article is concerned, each OCS cable extracted by Terrasolid software requires a manual drawing of the centerline of masts, which may be because the contact mast is not the symmetrical center of the cables, and this process will significantly increase the time.\n\nThis paper focuses on the point cloud of the overhead contact system, which has a single structure and no complex background and is only affected by data noise. Therefore, the effectiveness of the algorithm proposed in this article can be guaranteed. This article does not consider OCS extraction in the tunnel and multi-track railways. The situation in the tunnel and multi-track railways is relatively more complicated.\n\n5. Conclusions\n\nThe vehicle-mounted LiDAR technology has the advantages of high efficiency and high precision, which can solve the problems of difficulty, low efficiency, and high risk of railway OCS detection. In this paper, experiments were carried out for the classification of OCS from vehicle-mounted LiDAR data. The algorithm proposed in this paper extracted contact cables, catenary cables and return current cables from the OCS point cloud accurately. The average overall accuracy of the method in this paper to extract OCS point clouds of 50 m and 100 m is 99.58% and 99.69%, respectively, which is better than Terrasolid (99.51% and 99.45%, respectively).\n\nThe comparison experiment verifies the accuracy and effectiveness of the method. This article focuses on in-depth research on the segmentation and classification algorithm of the OCS point cloud. The main research results and conclusions obtained were as follows:\n\nUnder the current research background, the research on overhead contact system detection was analyzed. At present, the extraction of OCS from point clouds mainly relies on the structural characteristics of the power line and its positional relationship with the track, and the clustering method is mainly used. This process will bring more errors, and it is necessary to set thresholds when extracting the trackbed and the OCS, which is more subjective. For catenary cables with large curvatures, the effect is often poor. This article analyzed the characteristics of the OCS, and on this basis, put forward the main research content of this article to make full use of and extract the spatial distribution characteristics of target points and improve the accuracy of classification extraction.\n\nTo classify most of the OCS point cloud in the non-ground point cloud, this paper used the geometric structure feature (dimensional feature) of the point cloud with different scales as the basis for classification. We adopted a scale adaptive feature classification algorithm and introduced the concept of entropy feature values to better select the best scale. We then completed the rough classification of the point cloud; this laid a good foundation for the subsequent classification.\n\nBased on the rough classification, this paper adopted a DBSCAN algorithm that takes into account the characteristics of the OCS to realize the fine classification of the OCS point cloud. This algorithm combined the traditional DBSCAN algorithm with the spatial characteristic information of the OCS to achieve the purpose of accurate classification. This method has strong pertinence to the classification of the overhead contact system and provided a new method for the classification of railway OCS from the railway point cloud.\n\nHowever, the proposed method still has defects and can be improved. The accuracy of the method is affected by the data quality, and the poor data quality may cause more clusters of the same target object. When the environment is more complex, the algorithm may not be able to detect the target object like crossed lines effectively.\n\nIn general, this provides a new method for processing railway overhead contact system point clouds, and it has done the basic work for the detection of the railway overhead contact system and also provided the basis for the modeling of the OCS. The method in this paper has high engineering application value in railway component detection. With our further research, we will study the extraction and classification of railway OCS in the relatively complex environment of the tunnel and multi-track railway.\n\nAuthor Contributions\n\nConceptualization, X.C., G.L. and Z.C.; methodology, X.C., Z.C. and G.L.; software, X.C., K.C., L.W. and W.X.; validation, R.Z., K.C. and L.W.; formal analysis, W.X., K.C. and Z.C.; investigation, R.Z., L.W. and W.X.; writing, X.C. and Z.C. All authors have read and agreed to the published version of the manuscript.\n\nFunding\n\nThis research was jointly funded by the National Natural Science Foundation of China (Grant Nos. 41771402, 41804009, 42071410); the National Key R&D Program of China (Grant No. 2017YFB0502700); and the Sichuan Science and Technology Program (Nos. 2018JY0664, 2019ZDZX0042, 2020JDTD0003).\n\nInstitutional Review Board Statement\n\nNot applicable.\n\nInformed Consent Statement\n\nNot applicable.\n\nData Availability Statement\n\nNot applicable.\n\nAcknowledgments\n\nWe would like to thank the General Scientific Research Projects of the Beijing Municipal Commission of Education for its support.\n\nConflicts of Interest\n\nThe authors declare no conflict of interest.\n\nReferences\n\nLiu, Z.; Song, Y.; Han, Y.; Wang, H.; Zhang, J.; Han, Z. Advances of research on high-speed railway catenary. J. Mod. Transport. 2018, 26, 1–23. [Google Scholar] [CrossRef] [Green Version]\n\nChen, C.; Yang, B.; Song, S.; Peng, X.; Huang, R. Automatic Clearance Anomaly Detection for Transmission Line Corridors Utilizing UAV-Borne LIDAR Data. Remote Sens. 2018, 10, 613. [Google Scholar] [CrossRef] [Green Version]\n\nWu, G.; Gao, G.; Wei, W.; Yang, Z. Diagnosis and Detection of Service Performance of Pantograph and Catenary. In The Electrical Contact of the Pantograph-Catenary System; Springer: Singapore, 2019. [Google Scholar] [CrossRef]\n\nChen, L.; Xu, C.; Lin, S.; Li, S.; Tu, X. A Deep Learning-Based Method for Overhead Contact System Component Recognition Using Mobile 2D LiDAR. Sensors 2020, 20, 2224. [Google Scholar] [CrossRef] [Green Version]\n\nGao, S.B.; Liu, Z.G.; Yu, L. Detection and monitoring system of the pantograph-catenary in high-speed railway (6C). In Proceedings of the 7th International Conference on Power Electronics Systems and Applications—Smart Mobility, Power Transfer & Security (PESA), Hong Kong, China, 12–14 December 2017; pp. 1–7. [Google Scholar] [CrossRef]\n\nHan, Y.; Liu, Z.G.; Lyu, Y.; Liu, K.; Li, C.J.; Zhang, W.X. Deep Learning-based Visual Ensemble Method for High-Speed Railway Catenary Clevis Fracture Detection. Neurocomputing 2019, 396, 556–568. [Google Scholar] [CrossRef]\n\nLin, S.; Xu, C.; Chen, L.; Li, S.; Tu, X. LiDAR Point Cloud Recognition of Overhead Catenary System with Deep Learning. Sensors 2020, 20, 2212. [Google Scholar] [CrossRef] [Green Version]\n\nLiu, Z. Detection and Estimation Research of High-speed Railway Catenary; Springer: Singapore, 2017. [Google Scholar] [CrossRef]\n\nKusumi, S.; Nezu, K.; Nagasawa, H. Overhead Contact Line Inspection System by Rail-and-Road Car. RTRI 2000, 41, 169–172. [Google Scholar] [CrossRef] [Green Version]\n\nLiu, K.; Siew, W.H.; Stewart, R.W.; Wang, Y. Smart wireless railway monitoring system. In Proceedings of the 4th IET International Conference on Railway Condition Monitoring, Derby, UK, 18–20 June 2008; pp. 1–3. [Google Scholar] [CrossRef] [Green Version]\n\nChen, X.; Qin, F.; Xia, C.; Bao, J.; Huang, Y.; Zhang, X. An Innovative Detection Method of High-Speed Railway Track Slab Supporting Block Plane Based on Point Cloud Data from 3D Scanning Technology. Appl. Sci. 2019, 9, 3345. [Google Scholar] [CrossRef] [Green Version]\n\nZou, R.; Fan, X.; Qian, C.; Ye, W.; Zhao, P.; Tang, J.; Liu, H. An Efficient and Accurate Method for Different Configurations Railway Extraction Based on Mobile Laser Scanning. Remote Sens. 2019, 11, 2929. [Google Scholar] [CrossRef] [Green Version]\n\nSoilán, M.; Sánchez-Rodríguez, A.; del Río-Barral, P.; Perez-Collazo, C.; Arias, P.; Riveiro, B. Review of Laser Scanning Technologies and Their Applications for Road and Railway Infrastructure Monitoring. Infrastructures 2019, 4, 58. [Google Scholar] [CrossRef] [Green Version]\n\nSánchez-Rodríguez, A.; Soilán, M.; Cabaleiro, M.; Arias, P. Automated Inspection of Railway Tunnels’ Power Line Using LiDAR Point Clouds. Remote Sens. 2019, 11, 2567. [Google Scholar] [CrossRef] [Green Version]\n\nTu, X.; Xu, C.; Liu, S.; Lin, S.; Chen, L.; Xie, G.; Li, R. LiDAR Point Cloud Recognition and Visualization with Deep Learning for Overhead Contact Inspection. Sensors 2020, 20, 6387. [Google Scholar] [CrossRef] [PubMed]\n\nAzevedo, F.; Dias, A.; Almeida, J.; Oliveira, A.; Ferreira, A.; Santos, T.; Martins, A.; Silva, E. LiDAR-Based Real-Time Detection and Modeling of Power Lines for Unmanned Aerial Vehicles. Sensors 2019, 19, 1812. [Google Scholar] [CrossRef] [Green Version]\n\nChasco-Hernández, D.; Sanz-Delgado, J.A.; García-Morales, V.; Álvarez-Mozos, J. Automatic Detection of High-Voltage Power Lines in LiDAR Surveys Using Data Mining Techniques. In Advances in Design Engineering, Proceedings of the XXIX International Congress INGEGRAF, Logroño, Spain, 20–21 June 2019; Springer International Publishing: Cham, Switzerland, 2020. [Google Scholar] [CrossRef]\n\nArastounia, M. Automated Recognition of Railroad Infrastructure in Rural Areas from LIDAR Data. Remote Sens. 2015, 7, 14916–14938. [Google Scholar] [CrossRef] [Green Version]\n\nZhang, S.; Wang, C.; Yang, Z.; Chen, Y.; Li, J. Automatic Railway Power Line Extraction Using Mobile Laser Scanning Data. In Proceedings of the International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XXIII ISPRS Congress, Prague, Czech Republic, 12–19 July 2016; pp. 615–619. [Google Scholar] [CrossRef]\n\nJun, J.; Chen, L.H.; Sohn, G.; Luo, C.; Won, J. Multi-Range Conditional Random Field for Classifying Railway Electrification System Objects Using Mobile Laser Scanning Data. Remote Sens. 2016, 8, 1008. [Google Scholar] [CrossRef] [Green Version]\n\nArastounia, M. An Enhanced Algorithm for Concurrent Recognition of Rail Tracks and Power Cables from Terrestrial and Airborne LiDAR Point Clouds. Infrastructures 2017, 2, 8. [Google Scholar] [CrossRef] [Green Version]\n\nAriyachandra, M.; Brilakis, I. Digital Twinning of Railway Overhead Line Equipment from Airborne LiDAR Data. In Proceedings of the 37th International Symposium on Automation and Robotics in Construction (ISARC), Kitakyushu, Japan, 27–28 October 2020. [Google Scholar] [CrossRef]\n\nGutiérrez-Fernández, A.; Fernández-Llamas, C.; Matellán-Olivera, V.; Suárez-González, A. Automatic Extraction of Power Cables Location in Railways Using Surface LiDAR Systems. Sensors 2020, 20, 6222. [Google Scholar] [CrossRef]\n\nQi, C.R.; Su, H.; Mo, K.C.; Guibas, L.J. PointNet: Deep learning on point sets for 3D classification and segmentation. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21–26 July 2017. [Google Scholar] [CrossRef] [Green Version]\n\nQi, C.R.; Su, H.; Guibas, L.J. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Proceedings of the Conference on Neural Information Processing Systems (NIPS), Long Beach, CA, USA, 4–9 December 2017. [Google Scholar]\n\nPoux, F.; Billen, R. Voxel-based 3D point cloud semantic segmentation: Unsupervised geometric and relationship featuring vs deep learning methods. ISPRS Int. J. Geo Inf. 2019, 8, 213. [Google Scholar] [CrossRef] [Green Version]\n\nHu, S.M.; Cai, J.X.; Lai, Y.K. Semantic Labeling and Instance Segmentation of 3D Point Clouds using Patch Context Analysis and Multiscale Processing. IEEE Trans. Vis. Comput. Graph. 2018, 26, 2485–2498. [Google Scholar] [CrossRef] [PubMed] [Green Version]\n\nNurunnabi, A.; Belton, D.; West, G. Robust Segmentation for Large Volumes of Laser Scanning Three-Dimensional Point Cloud Data. IEEE Trans. Geosci. Remote Sens. 2016, 54, 4790–4805. [Google Scholar] [CrossRef]\n\nAijazi, A.K.; Checchin, P.; Trassoudaine, L. Segmentation Based Classification of 3D Urban Point Clouds: A Super-Voxel Based Approach with Evaluation. Remote Sens. 2013, 5, 1624–1650. [Google Scholar] [CrossRef] [Green Version]\n\nDimitrov, A.; Golparvar-Fard, M. Segmentation of building point cloud models including detailed architectural/structural features and MEP systems. Autom. Constr. 2015, 51, 32–45. [Google Scholar] [CrossRef]\n\nVo, A.V.; Truong-Hong, L.; Laefer, D.F.; Bertolotto, M. Octree-based region growing for point cloud segmentation. ISPRS J. Photogramm. Remote Sens. 2015, 104, 88–100. [Google Scholar] [CrossRef]\n\nTang, Y.C.; Chen, M.Y.; Lin, Y.F.; Huang, X.Y.; Huang, K.Y.; He, Y.X.; Li, L.J. Vision-Based Three-Dimensional Reconstruction and Monitoring of Large-Scale Steel Tubular Structures. Adv. Civ. Eng. 2020, 2020, 1236021. [Google Scholar] [CrossRef]\n\nChen, M.Y.; Tang, Y.C.; Zou, X.J.; Huang, K.Y.; Li, L.J.; He, Y.X. High-accuracy multi-camera reconstruction enhanced by adaptive point cloud correction algorithm. Opt. Lasers Eng. 2019, 122, 170–183. [Google Scholar] [CrossRef]\n\nRusu, R.B. Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments. KI Künstliche Intell. 2010, 24, 345–348. [Google Scholar] [CrossRef] [Green Version]\n\nLiberti, L.; Lavor, C. Euclidean Distance Geometry; Springer: Cham, Switzerland, 2017. [Google Scholar] [CrossRef]\n\nDemantké, J.; Mallet, C.; David, N.; Vallet, B. Dimensionality based scale selection in 3d lidar point clouds. In Proceedings of the ISPRS—International Archives of the Photogrammetry Remote Sensing and Spatial Information Sciences, Calgary, AB, Canada, 29–31 August 2011; pp. 97–102. [Google Scholar] [CrossRef] [Green Version]\n\nBrodu, N.; Lague, D. 3D terrestrial LiDAR data classification of complex natural scenes using a multi-scale dimensionality criterion: Applications in geomorphology. ISPRS J. Photogr. Remote Sens. 2012, 68, 121–134. [Google Scholar] [CrossRef] [Green Version]\n\nLi, T.; Zhan, Q.M.; Yu, L. A classification method for mobile laser scanning data based on object feature extraction. Remote Sens. Land Resour. 2012, 1, 17–21. [Google Scholar] [CrossRef]\n\nKim, H.B.; Sohn, G. 3D classification of power-line scene from airborne laser scanning data using random forests. Int. Arch. Photogramm. Remote Sens. 2010, 38, 126–132. [Google Scholar] [CrossRef]\n\nWang, Y.J.; Li, K.; Lu, L.J. Power line classification from airborne LiDAR data via multi-scale neighborhood features. Bull. Surv. Mapp. 2019, 4, 21–25. [Google Scholar] [CrossRef]\n\nEster, M.; Kriegel, H.P.; Xu, X.W. A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise. In Proceedings of the KDD’96: Second International Conference on Knowledge Discovery and Data Mining, Portland, OR, USA, 2–4 August 1996; pp. 226–231. Available online: https://dblp.org/rec/conf/kdd/EsterKSX96 (accessed on 28 May 2021).\n\nFu, J.Y.; Jing, C.F.; Du, M.Y. Review and progress of DBSCAN research on spatial density clustering pattern mining method. Sci. Surv. Mapp. 2018, 43, 50–57. [Google Scholar] [CrossRef]\n\nZhu, L. Improvement of DBSCAN Algorithm Based on Adaptive Estimation of Eps Parameters and Its Application in Outlier Detection; Yunnan University: Kunming, China, 2019. [Google Scholar]\n\nXiao, J.; Wang, P.J.; Li, W.T.; Li, B.Q.; Yang, J. Application of density clustering and pca point cloud processing in high-speed rail track detection. Railw. Stand. Des. 2020, 64, 37–42. [Google Scholar] [CrossRef]\n\nGuo, B.Q.; Yu, Z.J.; Zhang, N.; Zhu, L.; Gao, C. 3D point cloud segmentation, classification and recognition algorithm of railway scene. Chin. J. Sci. Instrum. 2017, 38, 2103–2111. [Google Scholar]\n\nBa, J.J. Research on Anomaly Detection Method Based on Dbscan Algorithm; Civil Aviation University of China: Tianjin, China, 2019. [Google Scholar]\n\nGoutte, C.; Gaussier, E. A Probabilistic Interpretation of Precision, Recall and F-score, with Implication for Evaluation. In Proceedings of the 27th European Conference on IR Research, ECIR 2005, Santiago de Compostela, Spain, 21–23 March 2005; Volume 3408, pp. 345–359. [Google Scholar] [CrossRef]\n\nFigure 1. The struct of OCS and manual monitoring method: (a) overhead contact system; (b) manual monitoring method.\n\nFigure 2. Neighborhood of point cloud at different scales.\n\nFigure 3. Flow chart of DBSCAN classification algorithm considering OCS characteristics.\n\nFigure 4. Vehicle-mounted LiDAR and its installation location.\n\nFigure 5. Original point cloud.\n\nFigure 6. Railway OCS point cloud with a length of 50 m.\n\nFigure 7. Railway OCS point cloud with a length of 100 m.\n\nFigure 8. The mean entropy eigenvalue of 50 m OCS point cloud changes with the radius of the neighborhood.\n\nFigure 9. The mean entropy eigenvalue of 100 m OCS point cloud changes with the radius of the neighborhood.\n\nFigure 10. Density histogram of 50 m OCS point cloud.\n\nFigure 11. Density histogram of 100 m OCS point cloud.\n\nFigure 12. k-dist graph of 50 m OCS point cloud.\n\nFigure 13. k-dist graph of 100 m OCS point cloud.\n\nFigure 14. Experimental results of OCS with a length of 50 m.\n\nFigure 15. Experimental results of OCS with a length of 100 m.\n\nFigure 16. Fine classification results of the OCS point cloud with a length of 50 m.\n\nFigure 17. Fine classification results of the OCS point cloud with a length of 100 m.\n\nFigure 18. The result of 50 m OCS point cloud classification by TerraSolid.\n\nFigure 19. The result of 100 m OCS point cloud classification by TerraSolid.\n\nTable 1. Technical parameters of German Z + F 3D laser scanner PROFILER 9012.\n\nParameter CategoryParameterScanning systemZ + F PROFILER 9012Scanning modePhase-scanningRange measure119 mLaser grade1 levelRotation speed200 R/sAngular resolution0.0088°(40,960 pixel/360°)Point scan rate1,016,000 points/s\n\nTable 2. TP, TN, FP, and FN values in classification results with the algorithm proposed in this article.\n\nCategoryPoint Cloud with a Length of 50 mTPTNFPFN50 m OCS Point Cloud Contact cable21,32698,1169234Catenary cable19,027100,601848Return current cable21,52098,066090100 m OCS Point CloudContact cable725425,082075Catenary cable598826,347076Return current cable717025,224017\n\nTable 3. Accuracy evaluation index of classification results of the 50 m OCS point cloud.\n\nCategoryAccuracy (%)Precision (%)Recall (%)Overall Accuracy (%)Contact cable99.77%100.00%98.98%99.49%Catenary cable99.77%100.00%98.75%99.37%Return current cable99.95%100.00%99.76%99.88%Average99.83%100.00%99.16%99.58%\n\nTable 4. Accuracy evaluation index of classification results of the 100 m OCS point cloud.\n\nCategoryAccuracy (%)Precision (%)Recall (%)Overall Accuracy (%)Contact cable99.80%99.96%98.91%99.43%Catenary cable99.95%99.96%99.75%99.85%Return current cable99.92%100.00%99.58%99.79%Average99.89%99.97%99.42%99.69%\n\nTable 5. Accuracy evaluation index for the 50 m OCS point cloud classification results by Terrasolid.\n\nCategoryAccuracy (%)Precision (%)Recall (%)Overall Accuracy (%)Contact cable99.78%100.00%99.04%99.52%Catenary cable99.74%100.00%98.61%99.30%Return current cable99.87%99.97%99.44%99.71%Average99.80%99.99%99.03%99.51%\n\nTable 6. Accuracy evaluation index for the 100 m OCS point cloud classification results by Terrasolid.\n\nCategoryAccuracy (%)Precision (%)Recall (%)Overall Accuracy (%)Contact cable99.87%100.00%99.26%99.63%Catenary cable99.92%99.99%99.51%99.75%Return current cable99.63%99.97%98.01%98.98%Average99.81%99.99%98.92%99.45%\n\nTable 7. Accuracy comparison of the two methods.\n\nCategoryThe Algorithm in This PaperTerrasolid50 m Data100 m Data50 m Data100 m DataAverageAccuracy (%)99.83%99.89%99.80%99.81%Precision (%)100.00%99.97%99.99%99.99%Recall (%)99.16%99.42%99.03%98.92%Overall accuracy (%)99.58%99.69%99.51%99.45%Overall accuracyContact cable99.49%99.43%99.52%99.63%Catenary cable99.37%99.85%99.30%99.75%Return current cable99.88%99.79%99.71%98.98%\n\nPublisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\n© 2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).\n\nShare and Cite\n\nMDPI and ACS Style\n\nChen, X.; Chen, Z.; Liu, G.; Chen, K.; Wang, L.; Xiang, W.; Zhang, R. Railway Overhead Contact System Point Cloud Classification. Sensors 2021, 21, 4961. https://doi.org/10.3390/s21154961\n\nAMA Style\n\nChen X, Chen Z, Liu G, Chen K, Wang L, Xiang W, Zhang R. Railway Overhead Contact System Point Cloud Classification. Sensors. 2021; 21(15):4961. https://doi.org/10.3390/s21154961\n\nChicago/Turabian Style\n\nChen, Xiao, Zhuang Chen, Guoxiang Liu, Kun Chen, Lu Wang, Wei Xiang, and Rui Zhang. 2021. \"Railway Overhead Contact System Point Cloud Classification\" Sensors 21, no. 15: 4961. https://doi.org/10.3390/s21154961\n\nNote that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here.\n\nArticle Metrics\n\nNo\n\nNo\n\nArticle Access Statistics\n\nFor more information on the journal statistics, click here.\n\nMultiple requests from the same IP address are counted as one view."
    }
}