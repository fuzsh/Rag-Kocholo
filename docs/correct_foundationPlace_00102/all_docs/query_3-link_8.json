{
    "id": "correct_foundationPlace_00102_3",
    "rank": 8,
    "data": {
        "url": "https://blog.audiokinetic.com/en/wwise-2017-2-is-now-live/",
        "read_more_link": "",
        "language": "en",
        "title": "Wwise 2017.2 is now live!",
        "top_image": "https://info.audiokinetic.com/hubfs/SoundPropagation%20-%20What%27s%20new%202017.2-2.png",
        "meta_img": "https://info.audiokinetic.com/hubfs/SoundPropagation%20-%20What%27s%20new%202017.2-2.png",
        "images": [
            "https://blog.audiokinetic.com/images/branding/2022/ak_blog_white.png",
            "https://blog.audiokinetic.com/images/icon_facebook_blue.png",
            "https://blog.audiokinetic.com/images/icon_facebook_hover.png",
            "https://blog.audiokinetic.com/images/icon_x_blue.png",
            "https://blog.audiokinetic.com/images/icon_x_hover.png",
            "https://blog.audiokinetic.com/images/icon_linkedin_blue.png",
            "https://blog.audiokinetic.com/images/icon_linkedin_hover.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/2.NewStateProps.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/3.image2017-12-5_22-29-57.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/SoundPropagation%20-%20What's%20new%202017.2%20-%20White.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/4.image2017-11-8_11-26-50.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/5.UnityWindowRoomsAndPortalsTutorialScene.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/AkEmitterObstructionOcclusion.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/6.Timeline_RTPCKeyframeContextMenu.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/7.Timeline_RTPCKeyframeEdit.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/8.sequencer_example_retrigger_enablement.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/9.image2017-12-4_11-33-39.png",
            "https://info.audiokinetic.com/hubfs/Blog_Images/2017.2/10.waapi_picker.png",
            "https://no-cache.hubspot.com/cta/default/1940263/f652daf0-ef4e-4428-9e87-79b5d2020496.png",
            "https://info.audiokinetic.com/hubfs/Headshots/AUDIOKINETIC_FAVICON_RGB_Socials.png",
            "https://blog.audiokinetic.com/images/icon_facebook_blue.png",
            "https://blog.audiokinetic.com/images/icon_facebook_hover.png",
            "https://blog.audiokinetic.com/images/icon_linkedin_blue.png",
            "https://blog.audiokinetic.com/images/icon_linkedin_hover.png",
            "https://blog.audiokinetic.com/images/icon_x_blue.png",
            "https://blog.audiokinetic.com/images/icon_x_hover.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Audiokinetic Inc"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "We’re excited to announce that Wwise 2017.2 is now live!Below, a short-list of what’s new in Wwise 2017.",
        "meta_lang": "",
        "meta_favicon": "/favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "We’re excited to announce that Wwise 2017.2 is now live!\n\nBelow, a short-list of what’s new in Wwise 2017.2.\n\nWorkflow and Feature Improvements\n\nImprovements with States\n\nMost RTPC properties now available to States\n\nAll audio properties that support multiple RTPC curves and most properties from the Wwise plug-ins can now be controlled by States. To add new State properties to an audio object or plug-in, simply open the State Properties view and select the properties as seen below. This selection is done on a per object or plug-in basis, so you don’t waste space with all possible properties used by your project.\n\nA new State icon has been added next to the link/unlink and RTPC icons to help you identify which properties can be modified by States.\n\nMixing Desk Workflow Enhancements\n\nIt’s now possible to quickly change which State Group is listening to State changes. This makes faders move when States are changing on motorized controllers. It’s also possible to expand and collapse State Groups (and other main categories, such as Monitoring, Positioning, and Effects), which is convenient when Mixing Desk sessions contain multiple State Groups.\n\nWwise Spatial Audio improvements\n\nSpatial Audio: Sound Propagation, Rooms, and Portals\n\nDevelopment in Spatial Audio continued during 2017.2 with a focus on expanding the existing features by enhancing usability, runtime efficiency, and flexibility. Here’s an overview of the main elements:\n\nSound Propagation\n\nThe path of sound from an emitter to reach a listener can now traverse one or multiple Portals.\n\nVirtual positions are attributed to sounds as if they are coming from the Portal closest to the listener.\n\nSmooth Transitions Between Rooms\n\nPortals are now volumes instead of being point sources, which allows for smoother and more accurate panning and spread when going through Portals.\n\nRoom reverbs now smoothly and automatically crossfade over distance.\n\nSpatialized Portal Game Objects can also send to listener’s room.\n\nDiffraction Modeling\n\nDiffraction is represented as an angle ranging from 0° (no diffraction) to 180°. It can be driven using obstruction and/or the new Diffraction built-in parameters.\n\nThe emitter dry path(s) and a Room's wet path have different angles. The dry diffraction angle is the deviation from the straight-line path, and the wet diffraction angle is the angle from the normal of the Portal.\n\nBasic Transmission Modeling\n\nWhen no paths through Portals are found from the emitter to the listener, the ‘sound transmission’ path goes through the walls.\n\nRooms are tagged with ‘wall occlusion’ values, which are used to set the Wwise occlusion value on the emitter.\n\nPortal Obstruction\n\nThe Spatial Audio API provides means to set game-driven obstruction values on the Portal objects.\n\nProfiler Improvements\n\nLPF and HPF values are now complementing the volume values in the Voices Graph tab of the Advanced Profiler view.\n\nEfficient Game Object Usage\n\nMultiple positions are leveraged at the Portals when the listener is not in the Room, which results in an important performance improvement over 2017.1 as only one game object is now instantiated per Room.\n\nSingle position (not using orientation) following the listener is used when the listener is located inside a Room.\n\nIntegrations in UE4, Unity, and an SDK Example Exposed in the Integration Demo Are Provided.\n\nFilters in (and on) Busses\n\nBuilt-in Low-pass and High-pass filters have been reworked in the sound engine's audio graph to better model filter values coming from different features such as Wwise user parameters Attenuation, Occlusion and Obstruction. Previously, Wwisehad a singlefilter on thevoice output, and competingparametervalues for this filter would have to be logically combined into a single value; only the minimum value was used. Wwise 2017.2 features individual filters on each unique output,including outputs from busses,so that values pertaining to different rays or output busses no longer have to be combined.\n\nAn example of how this is useful can be seen when using multiple listener scenarios. A game object that has multiple listeners will have different Attenuation curve evaluations for each listener, since they may be at different distances. The curve defines a Low-pass filter value; however, in previous versions of Wwise, only one Low-pass filter value could be used per voice. Now, upon mixing the single voice into each listener's output bus instance, the correct filter value (as determined by the curve evaluation) will be applied for each output bus.\n\nBusses have three new controls: Output Bus Volume, Output Bus LPF, and Output Bus HPF, allowing one to filter the output of mix busses. Also, low-pass and high-pass filtering of user-defined sends is now possible via RTPC.\n\nNew Built-In Parameters: Listener Cone & Diffraction\n\nListener cone represents the angle between the listener's front vector (gaze) and the emitter position. It can be used to implement the listener cone via RTPC. This can be useful to, for example, reduce focus on emitters outside the front cone of the listener or simulate microphone polar patterns.\n\nDiffractionangle between emitter and listener operates in tandem with Portals. The diffraction built-in parameter ranges from 0° (no diffraction) to 180° and can be used to, for example, shape different Attenuation curves for Rooms' dry and wet paths.\n\nAmbisonics IR Now Packaged with Wwise Convolution Reverb\n\nPackaged with the plug-in, all ShareSets and stereo impulse responses included with the original Wwise Convolution Reverb now come with their ambisonics equivalents. Projects that already licensed the Convolution Reverb can simply get access to the ambisonics versions of the impulse responses from the \" ...\" menu in Wwise (you may need to first download them from the Wwise Launcher).\n\nAudio Output Management and Motion Refactor\n\nAudio output management and motion have been refactored to offer greater flexibility, and represent the foundation for future improvements for output management and support of haptic devices.\n\nAudio Output Management\n\nThe management of audio output is now mostly done in Wwise Authoring by assigning Audio Device ShareSets to master busses.\n\nIt is now possible to create any number of master busses in the Master-Mixer Hierarchy and assign specific audio devices to them.\n\nIndependent audio device ShareSets are created to output specific audio content, like voice chat or user music, to specific audio devices such as game controllers or alternative physical outputs.\n\nOn master busses, different output devices can be assigned for authoring and runtime, which, among other things, greatly simplifies auditioning during the development of complex sound installations.\n\nWwise Motion Refactor\n\nThe motion system used by Wwise Motion to support rumble on game controllers has been refactored. Instead of using a specific code path, it now uses the same feature set and API as the audio. This simplified model allows support for third-party haptic plug-ins for devices such as VR kits or mobile platforms.\n\nWwise Authoring API improvements\n\nWwise Authoring API New Features\n\nA series of feature requests from early adopters of WAAPI have been added to 2017.2. Here are a few examples!\n\nTo ease transfer across computers, it’s now possible to import audio files from base64 without the need to write files on disk.\n\nSwitch Container associations with audio objects can now be gathered or edited from WAAPI.\n\nThe WAAPI API can be queried to get all available functions. For each function, the information is returned with its JSON schema.\n\nWAAPI can bring Wwise to the foreground and expose its Process ID.\n\nThe Wwise search can be used from the Command Line Interface.\n\nApplications using WAAPI can subscribe to transport activity notifications.\n\nGame Engine Integrations - Unity\n\nWwise Spatial Audio\n\nThe Spatial Audio suite is now fully integrated in the Unity integration. There’s also a step-by-step tutorial to help you discover its functionality!\n\nSimple Obstruction and Occlusion\n\nThe Ak Emitter Obstruction Occlusion component is applied to emitters and offers a basic ray-casting system to occlude or obstruct sounds. The presence or lack of the Ak Room component within the scene determines whether occlusion or obstruction should be used:\n\nWhen an Ak Room component is added to a scene, the Ak Emitter Obstruction Occlusion component uses obstruction.\n\nWhen there is no Ak Room component present in the scene, the Ak Emitter Obstruction Occlusion component uses occlusion instead.\n\nWhile its system might be too elementary for certain games, it should be useful to many other projects needing a simple and straightforward mechanism to manage occlusion and obstruction.\n\nTimeline & Audio Scrubbing\n\nIt’s now possible to play back from anywhere in the timeline to allow, for example, more control when editing in-game cinematics. Audio scrubbing is also supported, which can be helpful when syncing audio to video.\n\nAutomatic SoundBank Management\n\nA manual copy of SoundBanks in the StreamingAssets folder is no longer required. There is a pre-build processing step now that generates and copies SoundBanks to their appropriate location for the Unity build pipeline.\n\nNew C# Scripts\n\nMIDI Events can now be posted to Wwise via C# scripts. Further, the Wwise Audio Input source plug-in is now accessible via C# scripts.\n\nPreview in Editor\n\nIt is now possible to preview sounds from the Inspector view without entering Play Mode.\n\nGame Engine Integrations - Unreal\n\nDAW-Like Workflow in Sequencer\n\nThere are significant improvements in the Unreal Sequencer to support audio scrubbing, seeking inside tracks, and waveform display. These improvements should be particularly useful when editing in-game cinematics and linear or interactive VR experiences.\n\nWAAPI Integration in UE4\n\nUMG Widget Library: Using WAAPI, you can control Wwise directly from Unreal. With this new widget library, you can build your own custom UI in Unreal to optimize your team's workflow.\n\nBlueprint:WAAPI is now accessible from Blueprint, allowing you to use built-in UMG widgets to control Wwise.\n\nWwise Picker:A new WAAPI-enabled Wwise Picker has been added to the UE4 integration, which allows to complete a number of operations (such as selecting audio objects, modifying volume, and playing/stopping) directly in the Unreal Editor.\n\nImprovements with Listeners\n\nAkComponents can now support more than one listener. Further, a listener, which follows the focused viewport's camera position, has been added to the Unreal Editor (when not in Play in Editor mode). It can be used to, for example, preview sounds and distance attenuation directly from the Animation Editor."
    }
}