{
    "id": "dbpedia_4770_2",
    "rank": 86,
    "data": {
        "url": "http://l.web.umkc.edu/lz74d/CS441/Homework3.htm",
        "read_more_link": "",
        "language": "en",
        "title": "Year of",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Major Contribution\n\nMotivation\n\nImpact on Language Implementation\n\nto Development\n\nfor Development Readability Writability Reliability Source FORTRAN 1954 One of the features of FORTRAN I, and all of its successors except 90, that allow highly optimized compilers are that the types and storage for all variables are fixed before run time modules). The environment in which FORTRAN was developed was as follows: (1) Computers were still small, slow, and relatively unreliable. (2) The primary use of computers was for scientific computations. (3) There were no existing efficient ways to program computers. (4) Because of the high cost of computers compared to the cost of programmers, speed of the generated object code was the primary goal of the first FORTRAN compilers. So I think FORTRAN did increase the readability of the major programming language from the late 1940s to the mid-1950s for it was evolved more with the features of simplicity and orthogonality, getting more new control statement, data structures (Ext ending names to six characters, independent compilation, type names that could be parameter, character string handling, declarations and allow subprogram Increase writability too. The same reason as readability. However, I dont think its syntax considerations and expressivity is very good. Its reliability is high since it got parameter type checking (FORTRAN 90), aliasing (FORTRAN 0 and I had user-defined programs) and its comparatively high readability and writability. Sebesta, Robert W, Concepts of Programming Languages (5th ed.2003) Algol 58 1958 Formalized concept of data type, compound statements Good used for scientific programming, syntax be close to math notation Hard to read programs, Following code difficult Hard to write parameters, hard to write structure of programs Read and write hard then reliability hard, hard modify programs Sebesta, Robert W, Concepts of Programming Languages (5th ed.2003) LISP 1958 LISP was the first functional programming language. It greatly influenced artificial intelligence (AI) from its inception. LISP was designed in 1958 by John McCarthy and Marvin Minsky, while working on the MIT AI Project. One of the first goals of the project was to produce a list processing system. The Fortran List Processing Language already existed; however, it did not support recursion, conditional expressions, dynamic storage allocation or implicit deallocation. Dynamically allocated linked lists and implicit deallocation were requirements for symbolic differentiation. McCarthys and Minskys list processing system was to be used to implement a program named the Advice Taker, but the application provided the incentive to develop the new list processing language LISP. Since LISP is a functional language, assignment statements and variables are not necessary. Functions are applied to arguments. LISP also uses recursive function calls, rather than loops. The simplicity of the LISP language does make is less readable and harder to understand for someone not familiar with the language. However, the simplicity and orthogonality are impressive to some language researchers. The profuse use of parentheses can also decrease the readability of this language. The simplicity and orthogonality of LISP have a huge impact on writability. They make it easier to write programs in LISP. The lack of assignments and variables also increases the writability of the language. LISP is a fairly reliable functional programming language. It is the most widely used language for artificial intelligence. Most of the past inefficiencies of LISP code have been eliminated. The code is ran faster because it is compiled and not ran on an interpreter. LISP is a reliable functional programming language. Sebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nhttp://users.erols.com/ziring/dopl.html\n\nCOBOL 1959 Business Application Programming Language\n\nHierarchial Data Structures\n\nEnglish like nonmathematical syntax.\n\nCOBOL was developed in 1959 to fulfill the needs of a growing base of business computer users. COBOL was not built in an attempt to create a universal programming language, but rather to create a practical language for business applications. COBOL succeded in that goal, resulting in the fact that there currently exist more lines of COBOL code than any other programming language. COBOL was the first language to implement English style commands rather than a more mathematics syntax. This decision fell in line with the goal of making COBOL usable for a broader base of programmers by making it more readable, and thus accessible to business professions with less mathematical and computer science background.\n\nCOBOL defines every variable is a special data division of the code, thus implementing a data dictionary which makes reading and understanding the code easier.\n\nCOBOL is the first language to implement heirarchial data structures, providing the first step toward data abstraction which makes programs more readable by managing complexity.\n\nThe use of English style in COBOL commands allows the programmer to think more in terms of the problem being solved and less in terms of the idiosyncrasies of the programming language and machine implementation. The abstraction provided by hierarchical data structures makes code less complex, thus easier to write. Finally, because of its business application focus, COBOL often trades power for usability. Therefore, while a programmer may have a difficult time writing scientific applications in COBOL because of the lack of powerful features, the usability gained in the area of business application allows the programmer to again focus on the problem not the language, improving writability. Reliability, as a function of how well a program is understood and can be modified correctly, is increased by COBOLs gains in readability and writeability. Clearly, based on its widespread use in business critical applications, COBOL has proven itself a reliable programming tool. Sebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nhttp://www.legacyj.com/cobol/cobol_history.html\n\nAlgol 60 1960 Public algortihms, Machine independent Make modifications to Algol 58 Understanding difficult, BNF make hard to read Input and output statements Implementation inefficient, BNF hard to modify Sebesta, Robert W, Concepts of Programming Languages (5th ed. 2003) BASIC 1963 The Basic design came from Fortran and Algol 60. Algol 60 had a minor influence, but with the help of these two languages Basic was born. In 1963 Kemeny began the work on the complier for the first version of Basic. Basic was designed in the spring of 1963 especially for the liberal art students. John Kemeny and Thomas Kurtz felt that the language was needed for those students who didnt have the computer science background. Since, Basic was based off of Fortran and Agol 60 the readability of Basic already had a solid ground. Basic has been criticized for the poor structure of programs written in it, among other things. By Sebesta evaluation criteria, the language does indeed fare very poorly. (Sebasta, 67) Basic received its reliability on the success and the ease in which it can be learned, and implemented on any computer. Sebesta, Robert W, Concepts of Programming Languages (6th ed. 2004) PL\\I 1965 PL/I represents the first large -scale attempt to design a language that could be used for a broad spectrum of application areas. First Concurrency. First exception handling. Switch-selectable recursion. First pointers. First array cross sections. In the 1970s, it enjoyed significant use in both business and scientific applications. By the early 1960s, the users of computers in industry had settled into two separate and quite different camps. Scientific programmers used the floating-point data type and arrays extensively. For business applications, people needed the decimal and character string data types. Until early 1963, IBM planners perceived the beginnings of a change in this situation. These perceptions quite naturally led to the concept of designing a single universal computer that would be capable of doing both floating-point and decimal arithmetic, and therefore both scientific and business applications. Along with this came the idea of a programming language that could be used for both business and scientific applications. Since Many of the new features of PL/I were poorly designed and too large and too much redundancy, it's readability is poor for me. Even though PL/I is not simple and orthogonal enough, but it was (and still is) actually used for both scientific and business applications. And from my point of view, its writability is good. Even PL/I was first one had exception handling, and ok writability, but its readability is so poor and not widely used as FORTRAN and COBOL, so I think its reliability is not so good. Sebesta, Robert W, Concepts of Programming Languages (5th ed. 2003) SIMULA 67 1967 SIMULA introduced important object-oriented programming concepts like classes and objects, inheritance, and dynamic binding. It was originally designed and implemented as a language for discrete event simulation. The basic concept of speaking in general and more specific terms had been adopted as a way of expressing reality in the context of a programming language SIMULA began with the idea of classes and objects to encapsulate procedures. This made the writability of languages to vastly improve, since all the procedures were in one location and removed the superfluous information. Classes increase reliability due to the object-oriented concepts, which were later developed in Java. Sebesta, Robert W, Concepts of Programming Languages (6th ed. 2004)\n\nhttp://java.sun.com/people/jag/SimulaHistory.html\n\nPascal 1971 The major contributions of Pascal were the value-result method of passing parameters and the case statement for multiple selections.\n\nThe largest contribution that Pascal had on the programming world was the teaching of the language. In the early 1970s FORTRAN, PL/I, and ALGOL-W were common languages taught to computer science students. By the mid 1970s Pascal had become the most widely used language to teach students. Pascal was the standard language to teach for almost two decades until the early 1990s. Pascal has affected almost every block-structured language designed since its creation and still does today\n\nNiklaus Wirth a member of the International Federation of Information Processing (IFIP) Working Group 2.1, which was created to continue the development of ALGOL in the mid 1960s. In August of 1965, Wirth and Tony Hoare contributed to that effort by presenting a proposal for additions and modifications to ALGOL 60. Their, proposal was rejected because it was considered to be too small to advance ALGOL 60. Later on, ALGOL 68 was released but Wirth and Hoare believed that it should not have been released because of its complexity. So they set out to develop and better version of ALGOL called ALGOL-W. From ALGOL-W the programming language known as Pascal was born. Pascal was created to be a simple language that would be widely used and easily teachable. Pascals impact on readability was huge because its simplicity and expressivity. Programs were easy to read through and it became the standard for readability for teaching young programmers how to write simple programs. Not only has Pascals impact on readability been enormous to programming, it also had a large impact on writability. It was easy for students to write small programs to learn the language quickly through in their classes. However, Pascal lacked many complex programming issues such as the impossibility of writing subprograms that take a parameter an array of variable length. Another problem with Pascal was the lack of any separate compilation capability. Although Pascal lacked the ability to do many things it was still considered to be a more stable than FORTRAN and C. It provided a safety net for young programmers to not allow them to make errors that they could have easily made in other languages. It did this because it was such and small language compared to it predecessors. Sebesta, Robert W, Concepts of Programming Languages (6th ed. 2004)\n\nhttp://cgibin.erols.com/ziring/cgi-bin/cep/cep.pl?_key=Pascal\n\nSNOBOL 1971 SNOBOL provided a language which could be used as if it were an object-oriented language, a logical programming language, a functional language, or a standard imperative language. This was made possible by changing the set of features used to write a program. SNOBOL was the fourth and final incarnation of a series of special purpose programming languages intended to make character string manipulation easier.\n\nSebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nhttp://www.wikipedia.org/wiki/SNOBOL\n\nC 1978 Ken Thompson wanted to create a comfortable computing environment constructed according to his own design using whatever means necessary. By early 1973 the language and compiler were strong enough to rewrite the Unix kernel for the PDP-11. C was developed because in the late 1960s 3 companies by the names of Bell Telephone Laboratories, MIT, and GE were in a project development with Multics. Multics development could not be fulfilled in time and was becoming very expensive. The language shows considerable power to describe important concepts. Its easy to read and there are different types of libraries set up within the language to help the user. The relationship between arrays and pointer, and the way in which declaration syntax mimics expression syntax. They are also among its most frequently criticized features and often secure as stumbling blocks to the beginner. C is quirky, flawed, and an enormous success. While accidents of history surely helped, it evidently satisfied a need for a system implementation language efficient enough to displace assembly language, yet sufficiently abstract and fluent to describe algorithms and interactions in a wide variety of environments. Dennis Ritchie, http://cm.bell-labs.com/cm/cs/who/dmr/chist.html, 1993 PROLOG 1979 Prolog is a dynamic high level language with untyped variables, encouraging a natural level of abstraction, and discouraging you from hard-wiring early assumptions into your code. Its major contribution has been that it allows Prolog programmers to be closer to the problem to be solved, more adaptable to changes in that problem, and easier to maintain and support. Alain Colmerauer and Phillippe Roussel at the University of Aix-Marseille, with the help of Robert Kowalski at University of Edinburgh, developed the fundamental design for Prolog.\n\nColmerauer and Roussel were interested in natural language processing, and Kowalski was interested in automated theorem proving. The collaboration between them and the two universities on this new language continued until the mid 1970s. In 1972, their efforts led to the use of formal logic as the basis for a programming language. Kowalski's research provided the theoretical framework, while Colmerauer's resulted in the programming language. After that time both universities received little attention on their research and conducted independent studies on the prolog language until 1981. At that time the Japanese government was launching a large research project called the Fifth Generation Computing Systems (FGCS). The primary objective of this project was to develop intelligent machines, and Prolog was chosen as the basis for their study. This caused other researchers and governments to soon take notice of the Prolog language which started a 10 year long interest around the world in artificial intelligence and logic programming. Readability is difficult because of many unresolved problems with the language. The main problem with it is that it is hard to follow the order of the program and much of the programming is without any set basis of rules. This makes it very difficult for another programmer to figure out what he or she is reading without detailed notes to accompany the program. However, Prolog does offer unification which provides the ability for variables to instantiated values to provide matches. To sum up the impact on readability has been that it has lead to many user-defined programming languages.\n\nProlog has good writability and it is considered the standard in logic programming and AI programming. It is a fairly simple language to program with because it is based on facts, rules, or goals with a mainly structures composed of atomic propositions and logic operators.\n\nFinally, the impact that prolog has had on writability has been the advantage and disadvantages that unification introduced to the word of programming, causing many future languages to copy its platform.\n\nReliability of Prolog is simply not good. There are many ways it is inefficient including infinite loops, the programmer MUST sometimes state control flow information in their programs. It is very easy for programmer to write statements that cause infinite loops resulting in total program failures. Also, there are problems of the closed-world assumption and negation. To sum up the impact of Prologs reliability it has basically been a model of what not to do in order to create a reliable program language. Sebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nRoth, Allison, YOU CAN'T IGNORE PROLOG\n\nhttp://web.archive.org/web/20010708010543/www.practical-applications.co.uk/Prolog/alli.html\n\nSmallTalk 1980 First widely used implementation of object oriented programming.\n\nImplemented first example of an graphical windowing human interface system both for program user interfaces and integrated development tools.\n\nSmalltalk was originally developed by Dr. Alan Kay to extend the ideas of object oriented programming which were first developed in a limited form in Simula-67. Everything in Smalltalk is an object and information is passed between objects by way of messages. The object oriented programming framework of Smalltalk was developed concurrently with a plan to create a dynamic windowing human interface system which would bring computing to a less technical class of user. This windowing system is also integral to Smalltalks first implementation of an integrated software development environment. Therefore, Smalltalk is not only a programming language but also a software development tool which created a model for all modern graphical software development environments. Reading Smalltalk code is more like reading a text representation of semantic chart than it is reading computer code due to the complete implementation of object oriented concepts in Smalltalk. Therefore, Smalltalk is very readable to a programmer with knowledge of object oriented programming, but will make little sense otherwise. The simple expressive syntax of Smalltalk uses human nouns and verbs, leading to easy readability based on knowledge of English semantics. In terms of Writability, it must be considered that Smalltalk is both a programming language and an integrated graphical software development environment. As the first language to implement such a development environment, Smalltalk makes large gains in writeability across the overall programming process. Such a development environment is key to dealing with the many discrete segments of code which interact in the form of objects in Smalltalk. Individual segments of Smalltalk code text will have good writeability so long as the programmer subscribes to the concepts of object orientation. The use of English nouns and verbs also enhances writability by making use of existing semantic knowledge. The powerful abstraction tool of object oriented design will itself help to manage complexity, which make Smalltalk programs easy to understand, write, and modify. As an interpreted system originally designed to have some of the simulating capabilities as its predecessor Simula, Smalltalk is an excellent tool for prototyping and small systems but may not be robust enough to be reliable in very large projects. Sebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nhttp://www.smalltalk.org/\n\nAda 1983 Ada was designed specifically for the use of the Department of Defense (DoD). It included many object-oriented programming features. It was designed to promote reliability. The requirement phase of Ada began in 1975 with the official version of the language being finalized in 1983. Ada included a numerous amount of features. Ada used to be the only widely used language that included exception handling. It was also one of the first languages to offer full support for abstract data types. Ada was developed for use by the Department of Defense as a high-level language used for embedded systems. The Ada language was based on the programming language Pascal. The impact on readability by Ada was in part due to the use of data types, control statements and structures. Additionally, the use of special words greatly increase the readability of this language. The Ada language is so large and complex that it decreases the writability of the language. However, there are also many factors that are beneficial to the writability of Ada. These include abstraction, expressivity and generic procedures. A compiler can generate a version of the generic procedure using a specific data type, reducing the amount of code to be written. Exception handling increased the reliability of Ada. The benefits of exception handling in the languages PL/I and CLU were also included in the design of Ada. In 1995, Ada began to support object-oriented programming. The complexity of the language may reduce the reliability; however, the readability and writability of the language has a positive impact on the reliability. Sebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nhttp://users.erols.com/ziring/dopl.html\n\nC++ 1984 Parameter type checking, derived classes, public/private access of components Evolved from C because modifications to improve its imperative features, object oriented programming Good Compilers, large & complex language C can be compiled as C++ programs, large and complex language C can be compiled as C++ programs, good compilers Sebesta, Robert W, Concepts of Programming Languages (5th ed. 2003) JAVA 1993 Java provides a secure, cross-platform way for code to be executed. Java also added several features to existing websites, such as arbitrary graphics, arbitrary data types, less load on the server, and more user interaction. Java was designed mainly to enable people to develop programs that use the Internet and the World-Wide Web. Java prevents casting between arbitrary variables. Only casts between numeric variables and between sub and superclasses of the same object are allowed. All conditional tests must return boolean values. Java supports both the \"/* ... */\" and \"//\" commenting conventions, but comments that begin with a \"/**\" are special. These comments should only be used before a method or class declaration. They indicate that the comment should be included in automatically generated documentation for that declaration. Java provided a new and higher level of reliability by eliminating most of the assignment coercions that are done in C++, and by using an \"index range\" method of accessing arrays. Sebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nhttp://www.shu.ac.uk/java/aboutthisbook/pref2.htm\n\nhttp://www.ibiblio.org/javafaq/javafaq.html\n\nJavaScript 1995 Brought full interactivity and sophisticated user interface and typography concepts to the formerly static Web. Tasked with making Navigator's newly added Java support more accessible to non-Java programmers, Brendan Eich eventually decided that a loosely-typed scripting language suited the environment and audience, namely the few thousand web designers and developers who needed to be able to tie into page elements (such as forms, or frames, or images) without a bytecode compiler or knowledge of object-oriented software design. The language he created was christened \"LiveScript,\" to reflect its dynamic nature, but was quickly (before the end of the Navigator 2.0 beta cycle) renamed JavaScript JavaScript's capabilities can't be extended or overridden by developers. A language that apparently required no skill to use, lacked an IDE and a reliable cross-platform debugger, and could only be tested in the context of the actual browser in which the page will be viewed, combined with a few highly publicized security flaws and several books aimed at non-programmers, caused many to write off JavaScript as a \"simple\" language for beginners and overshadowed its amazing potential. Sebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nhttp://www.oreillynet.com/pub/a/javascript/2001/04/06/js_history.html\n\nPHP 1995 One of the biggest strengths of PHP 3.0 was its strong extensibility features PHP was initially as a simple set of Perl scripts for tracking accesses to his online resume. He named this set of scripts 'Personal Home Page Tools'. As more functionality was required, Rasmus wrote a much larger C implementation, which was able to communicate with databases, and enabled users to develop simple dynamic Web applications Because PHP is based on Perl, it has many of the problems associated with Perl. As in Perl, an instruction can be written in a variety of ways, this reduces the readability of the language Because one can write an instruction in a variety of ways, this increases the writability of the language As the language's strongest attribute is its extensibility feature, this has forced PHP to be rather reliable Sebesta, Robert W, Concepts of Programming Languages, (6th ed., 2004)\n\nhttp://us2.php.net/history"
    }
}