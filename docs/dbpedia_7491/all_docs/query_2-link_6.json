{
    "id": "dbpedia_7491_2",
    "rank": 6,
    "data": {
        "url": "https://blog.min.io/warp-speed-ai-data-storage/",
        "read_more_link": "",
        "language": "en",
        "title": "WARP speed your AI data storage Infrastructure",
        "top_image": "https://blog.min.io/content/images/size/w1200/2024/06/blog-warp-speed.jpeg",
        "meta_img": "https://blog.min.io/content/images/size/w1200/2024/06/blog-warp-speed.jpeg",
        "images": [
            "https://blog.min.io/assets/img/logo.svg?v=2b104e5512",
            "https://blog.min.io/assets/img/erasure-code-calculator.svg?v=2b104e5512",
            "https://blog.min.io/assets/img/ref-hardware.svg?v=2b104e5512",
            "https://blog.min.io/assets/img/ec-icon.svg?v=2b104e5512",
            "https://blog.min.io/content/images/size/w300/2024/06/blog-warp-speed.jpeg 300w,                                        /content/images/size/w600/2024/06/blog-warp-speed.jpeg 600w,                                        /content/images/size/w1000/2024/06/blog-warp-speed.jpeg 1000w,                                        /content/images/size/w2000/2024/06/blog-warp-speed.jpeg 2000w",
            "https://lh7-us.googleusercontent.com/docsz/AD_4nXfvbtqsgM-2Mm6p-Uue5PLXbdyEYDtx1yu9I9pb_3rq-FBfhMAStNLptyt0_z_XEJMF27pMwT7zHAnA4NjQA0I0e95yI6JC6ehNnZ3IEJVSFVqcxktIyzvCGwe9xQC_2aeP5Pypnh8Nd2bHRjQloETKSsDi?key=OQtqEEIHyt269szbah2sgg",
            "https://lh7-us.googleusercontent.com/docsz/AD_4nXde_UFt_tYtwpPoUEdgKu5eSHooUf9ZqwFcbVIvO8j_7UC0Ar78rZiqQhtaufLzFRf1K47uRO3O5YlLTD0-8cmubbcKl5KNH3fjc1YoSdPW891uID0_Q6eIz8KK_0vTQs1hrZPdCesKFNrTONuV4kmRmoY?key=OQtqEEIHyt269szbah2sgg",
            "https://lh7-us.googleusercontent.com/docsz/AD_4nXegnbHjwyY2uBNmOMUbpFsy2mo8CZn_5yaTaV9zn6EbrgeML6uP-ToRgyLsd7aZ7W-6sZRQXVhP9zeuRc_acW0BTow1HR8d_w5qqMEzSVt-kwUEnV3MziyjwHjBgBXh6tL3bNmam20Yxsd7HVwrNQGvl11j?key=OQtqEEIHyt269szbah2sgg",
            "https://blog.min.io/content/images/size/w300/2024/08/blog-splunk-minio.jpg 300w,                        /content/images/size/w600/2024/08/blog-splunk-minio.jpg 600w,                        /content/images/size/w1000/2024/08/blog-splunk-minio.jpg 1000w,                        /content/images/size/w2000/2024/08/blog-splunk-minio.jpg 2000w",
            "https://blog.min.io/content/images/size/w300/2024/07/MinIO-DataPOD--1-.jpg 300w,                        /content/images/size/w600/2024/07/MinIO-DataPOD--1-.jpg 600w,                        /content/images/size/w1000/2024/07/MinIO-DataPOD--1-.jpg 1000w,                        /content/images/size/w2000/2024/07/MinIO-DataPOD--1-.jpg 2000w",
            "https://blog.min.io/content/images/size/w300/2024/08/Screenshot-2024-08-01-at-8.26.04-AM.png 300w,                        /content/images/size/w600/2024/08/Screenshot-2024-08-01-at-8.26.04-AM.png 600w,                        /content/images/size/w1000/2024/08/Screenshot-2024-08-01-at-8.26.04-AM.png 1000w,                        /content/images/size/w2000/2024/08/Screenshot-2024-08-01-at-8.26.04-AM.png 2000w",
            "https://blog.min.io/assets/img/footer-logo.svg?v=2b104e5512",
            "https://blog.min.io/assets/img/soc.png?v=2b104e5512",
            "https://blog.min.io/assets/img/slack.svg?v=2b104e5512"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "AJ"
        ],
        "publish_date": "2024-06-19T14:45:02+00:00",
        "summary": "",
        "meta_description": "Do you know the secret to some of the best AI models out there? It's the amount of data they had access to on which they could be trained on. For AI/ML models Fast accessible Data is King. Let me emphasize, it's not just Data, but fast accessible Data.",
        "meta_lang": "en",
        "meta_favicon": "https://blog.min.io/content/images/size/w256h256/2019/05/minio-publication-icon-7.png",
        "meta_site_name": "MinIO Blog",
        "canonical_link": "https://blog.min.io/warp-speed-ai-data-storage/",
        "text": "Do you know the secret to some of the best AI models out there? It's the amount of data they had access to on which they could be trained on. For AI/ML models Fast accessible Data is King. Let me emphasize, it’s not just Data, but fast accessible Data. If someone can build a faster and stronger model then you’ve already lost the AI race.\n\nWhen designing AI Infrastructure components, specially data storage components, it's crucial to ensure the overall experience of ML Engineers and Data scientists is taken into account when they need to store their machine learning algorithms and manage the resource available in the MinIO cluster effectively. This ensures that reliable models are built quickly and effectively without storage infrastructure being the bottleneck.\n\nThere are several components in the AI Infrastructure layer that are needed to not only build AI models, but train and store the resulting models in a fast accessible data store such as MinIO. The world of ML Ops is at the juncture of DevOps and integrating ML models that are being produced at a breakneck speed. In this post we’ll show you how to measure the performance of your MinIO AI data storage infrastructure using WARP.\n\nWARP is an open-source full-featured S3 performance assessment software built to conduct tests between WARP clients and object storage hosts. WARP measures GET and PUT performance from multiple clients against a MinIO cluster. WARP has many options, configured by command line or environmental variables, allowing you to create tests that align with your workloads. We’ll quickly show you how you can run it so you can start analyzing your AI data storage infrastructure.\n\nRun and Analyze WARP\n\nCreate warp client listeners to run distributed warp benchmarks, here we will run them as stateful sets across client nodes.\n\nkubectl apply -f https://raw.githubusercontent.com/minio/warp/master/k8s/warp.yaml\n\nIn warp-job.yaml update the --warp-clients and --host flags, to match your cluster specifics. Once set, deploy as follows\n\nkubectl apply -f https://raw.githubusercontent.com/minio/warp/master/k8s/warp-job.yaml\n\nOnce the WARP job completes the status can be found in the logs\n\nYou can also set WARP to do distributed benchmarking. This allows you to perform the test in a more realistic manner with multiple WARP clients, as it is usually the case in the real world.\n\nWhen Running WARP make sure the nodes where you install the clients are on a private server as there is a potential of getting DDoS if the client is exposed. Also avoid running WARP against during peak production periods and you could end up in a situation where the resources are being competed for.\n\nIt's possible to randomize object sizes and files will have a \"random\" size up to the object size refined.\n\nExample of objects (horizontally) and their sizes, 100MB max:\n\nYou can also auto terminate WARP when results are considered stable. To detect a stable setup, warp continuously downsample the current data to 25 data points stretched over the current timeframe. For a benchmark to be considered \"stable\", the last 7 of 25 data points must be within a specified percentage.\n\nLooking at the throughput over time, it could look like this\n\nThe red frame shows the window used to evaluate stability. The height of the box is determined by the threshold percentage of the current speed.\n\nWarp Speed Ahead!\n\nWe encourage you to refer to the documentation to learn about executing more test scenarios. For example, you can enable TLS and server-side encryption to measure their impact in your environment. You can stress infrastructure more by increasing the number of concurrent tests. You can use a random mix of object sizes, or specify an object size that matches your current environment and workload. You can configure tests to run for a defined period of time or to auto-terminate as we did above."
    }
}