{
    "id": "correct_foundationPlace_00109_3",
    "rank": 96,
    "data": {
        "url": "https://builtin.com/articles/exascale-computing",
        "read_more_link": "",
        "language": "en",
        "title": "What Is Exascale Computing?",
        "top_image": "https://cdn.builtin.com/cdn-cgi/image/f=auto,fit=cover,w=1200,h=635,q=80/https://builtin.com/sites/www.builtin.com/files/2024-03/Exascale%20Computing.jpg",
        "meta_img": "https://cdn.builtin.com/cdn-cgi/image/f=auto,fit=cover,w=1200,h=635,q=80/https://builtin.com/sites/www.builtin.com/files/2024-03/Exascale%20Computing.jpg",
        "images": [
            "https://static.builtin.com/dist/images/9.svg",
            "https://static.builtin.com/dist/images/skinny_9.svg",
            "https://builtin.com/articles/job.logo",
            "https://cdn.builtin.com/cdn-cgi/image/f=auto,w=96,h=96,q=100/https://builtin.com/sites/www.builtin.com/files/2022-09/BecherBrooke_SquareHeadshot_AuthorArchive%20%281%29.jpeg",
            "https://cdn.builtin.com/cdn-cgi/image/f=auto,fit=cover,w=320,h=200,q=80/https://builtin.com/sites/www.builtin.com/files/2024-03/Exascale%20Computing.jpg",
            "https://cdn.builtin.com/cdn-cgi/image/f=auto,fit=contain,w=120,h=70,q=80/https://builtin.com/sites/www.builtin.com/files/2022-08/3d-printing-companies.png",
            "https://cdn.builtin.com/cdn-cgi/image/f=auto,fit=contain,w=120,h=70,q=80/https://builtin.com/sites/www.builtin.com/files/2024-04/Space%20Plane%201600x900.jpg",
            "https://cdn.builtin.com/cdn-cgi/image/f=auto,fit=contain,w=120,h=70,q=80/https://builtin.com/sites/www.builtin.com/files/2024-06/robot-maid_0.jpg",
            "https://cdn.builtin.com/cdn-cgi/image/f=auto,w=250,h=105,q=80/https://builtin.com/sites/www.builtin.com/files/2022-10/Image from iOS (16) (2)_0.jpg",
            "https://cdn.builtin.com/cdn-cgi/image/f=auto,w=64,h=64,q=80/https://builtin.com/sites/www.builtin.com/files/2023-03/2023_Arrive Logistics-Symbol-BLK (2).png",
            "https://static.builtin.com/dist/images/midnight_9.svg",
            "https://static.builtin.com/dist/images/builtin-logo.svg",
            "https://static.builtin.com/dist/images/united-we-tech.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Brooke Becher"
        ],
        "publish_date": "2024-03-26T15:53:09+00:00",
        "summary": "",
        "meta_description": "These warehouse-sized supercomputers may lead the way to more personalized medicine and sustainable climate action.",
        "meta_lang": "en",
        "meta_favicon": "https://static.builtin.com/dist/images/favicon.png",
        "meta_site_name": "Built In",
        "canonical_link": "https://builtin.com/articles/exascale-computing",
        "text": "Exascale computing is a type of high-performance supercomputing that can solve one exaflop — or one quintillion operations — per second. In terms of processing power, exascale computers are the most powerful machines in the world.\n\nUsing advanced modeling and simulations, these hefty hardware systems crunch vast data volumes to provide predictive analysis about national security, precision medicine and climate research. This unlocks “new competition in the realms of science and computer engineering,” Lucas Ochoa, an ex-Google artificial intelligence engineer and former Microsoft product designer, told Built In.\n\nWhat Is Exascale Computing?\n\nExascale computing refers to computing systems capable of performing one quintillion calculations per second, known as an exaflop. That’s 18 zeros, or a billion billion calculations. These systems run on highly parallel software algorithms and require robust hardware architecture — made up of thousands of CPUs, GPUs and nodes — that’s so massive it must be stored in warehouse-sized buildings.\n\nTake for example Frontier, the first supercomputer to break the exascale and that beat out Fujitsu’s Fugaku supercomputer as the fastest in the world. Operating out of Tennessee’s Oak Ridge National Laboratory, the 7,300-square-foot system debuted in 2022, and is made up of 74 cabinets with more than 9,400 nodes, 10,000 CPUs and 38,000 GPUs. It runs a peak performance of 1.6 exaflops.\n\nThis extraordinary processing power allows exascale computers to analyze massive amounts of data at rapid speeds to simulate real-world phenomena and essentially figure out how everything works. One exascale machine could outperform the combined effort of today’s top one hundred petascale supercomputers.\n\nRelated Reading17 High-Performance Computing Applications and Examples\n\nWhat Is Exascale Computing Used For?\n\nExascale computers are multi-million-dollar machines owned by government entities or large conglomerates, so scientists typically must submit grants to access these systems. Once they do, researchers can use exascale computing for a range of applications:\n\nCybersecurity: With exascale computing’s ability to rapidly execute billions of calculations, researchers can anticipate, detect and handle many types of cyber attacks and malicious actors.\n\nGreentech: Researchers can use exascale computing-powered analyses to create sustainable materials that can handle challenging conditions and produce crops that can adapt to different stressors.\n\nEnergy: Exascale computing makes it possible to model nuclear weapons’ performance and gather data on whether they’re safe — all without having to conduct an actual nuclear explosion.\n\nManufacturing: The massive computational capacity of exascale computers allows researchers to more accurately model and simulate manufacturing materials, resulting in faster additive manufacturing processes.\n\nHealthcare: Exascale computing can work on the nanoscale to help researchers understand how various drug molecules interact with the human body and design more effective cancer treatments.\n\nAerospace: Scientists can use exascale computing to develop detailed simulations of the universe, making it possible to unlock some of the universe’s biggest mysteries (like how stars explode).\n\nExascale computing delivers a gateway to previously unattainable knowledge with better, faster science at scale. George Amvrosiadis, an associate research professor of electrical and computer engineering at Carnegie Mellon University and a member of the Parallel Data Lab, told Built In that exascale computing “allows us to execute complex simulations and analyses that would be too costly, dangerous or even impossible to conduct in real life.”\n\nHow Does Exascale Computing Work?\n\nThink of exascale computers as a bunch of smaller networked computers working as one. Each of these smaller computers, known as nodes, share access to rapid data storage and come equipped with their own set of processors that solve complex problems by breaking them down into smaller parts. So when a task is inputted into an exascale system, it’s broken up into smaller pieces that are then distributed among thousands — or even millions — of processors working concurrently in a process known as parallel computing.\n\nFor exascale computing to work, each processor, either a CPU or GPU, is assigned a specific job to complete. They then communicate with each other through a high-speed, interconnected network, ensuring that they’re all working toward the same goal. To prevent disruptions, exascale computers have built-in fail-safe systems to handle errors and keep running smoothly even if some parts fail.\n\nParallel processing enables intricate, large-scale systems to balance their computational power for efficient performance and optimal energy usage.\n\nRelated ReadingIs the Human Brain a Computer?\n\nBenefits of Exascale Computing\n\nExpanded Computational Power\n\nBy definition, exascale computers are built with unprecedented power. Frontier, the machine that first broke the exascale, is more powerful than the top seven supercomputers combined, with a peak performance of 1.6 exaflops that could theoretically surpass 2 exaflops. These machines will reign supreme until the next generation of zettascale technology takes over — potentially within a decade.\n\nEnhanced Performance\n\nExascale computing systems are built with size in mind, not just efficiency. Using parallelism, exascale computers split one task across thousands or millions of processing units that concurrently work on different parts of a problem. This method optimizes the use of computational resources for faster task execution.\n\nOchoa, who is also the CEO and founder at AI-startup Automat, said that exascale performance capacities enable the construction of AI models that are about four-and-a-half times faster and eight times larger. This capacity “allows for training on more extensive data sets, enhancing predictability and accelerating the time-to-discovery process,” he added.\n\nImproved Speed\n\nExascale computers outperform the human brain one quintillion to one. Since Frontier’s debut in 2022, exascale computers have set a new pace for computational speed at one exaflop per second, which is one thousand times faster than the top petascale computers.\n\n“If every person on the planet performed one calculation per second, it would still take over four years to accomplish what an exascale computer can do in a single second,” Ochoa said.\n\nIncreased Scientific Discovery\n\nWith the ability to create better simulations and predictive analysis at unimaginable speeds and scale, exascale computers facilitate groundbreaking discoveries by providing valuable insights that are otherwise impossible to achieve. By modeling natural processes and unobservable phenomena, scientists and researchers get one step closer to cracking the codes of fundamental principles that shape the world around us.\n\nAbility to Handle Complex Challenges\n\nExascale computing empowers researchers to address some of society’s biggest challenges, such as climate change, disease prevention, renewable energy optimization and urban planning. It provides the computational resources needed to model, simulate and optimize complex systems.\n\nRelated ReadingWhat Is Grid Computing?\n\nChallenges of Exascale Computing\n\nDemanding Power Consumption\n\nDue to their grand scale and high-performance parts, exascale systems require an enormous amount of power to operate. The world’s fastest supercomputer produces 20 megawatts per exaflop, at 22.7 megawatts total. That’s enough to power an American small town or a jet engine.\n\nGreater Chances for Errors to Occur\n\nExascale systems consist of many moving parts working independently in parallel, but as one. In the interest of peak performance, minimizing data movement and streamlining communication between networked nodes and processors is crucial. Given their sheer size, these larger-than-life systems won’t work without efficient data transfer rates, latency and bandwidth.\n\n“Exascale systems will deploy so many components that it’s improbable for the entire system to operate without issues at any given time,” Ochoa said. “The hardware, system software and applications must be capable of handling both minor malfunctions and major failures.”\n\nHigher Costs\n\nBuilding and operating exascale computing facilities comes with a hefty price tag, which is why they are largely owned by government entities or conglomerates. In addition to ongoing operational costs, they require specialized hardware, infrastructure and energy requirements. The initial investment alone disqualifies most organizations from exascale computing. So while it took $600 million to physically build Frontier, there’s an additional cost of $100 million per year to run the machine. This is just one of three exascale projects announced by the Department of Energy, collectively budgeted at $1.8 billion.\n\nHeightened Security Risks\n\nTo a cybercriminal, each node of a networked network system is a window inside. So while the thousands of interconnected nodes that make up an exascale computer may increase its computational performance, they also contribute to a sizable attack surface that increases their vulnerability to security threats, including cyberattacks, data breaches and unauthorized access.\n\nExascale Computing vs. Quantum Computing\n\nExascale computers are essentially classical computers with extremely powerful hardware, while quantum computers are entirely different computers that rely on quantum mechanics to function.\n\nExascale Computing\n\nYou can think of exascale computing as classical computing at scale. It uses the same coding that runs our smartphones, laptops and PCs, then builds it out using a maximal amount of hardware.\n\n“Our everyday computers cannot solve large-scale scientific problems that involve immense amounts of data or must be solved before a tight deadline,” Omer Subasi, a computer scientist at Pacific Northwest National Laboratory, told Built In. “This is why we need exascale supercomputers.”\n\nClassical computations use binary logic, where units of information are represented in “bits” and can be of two states: 1 (True) and 0 (False).\n\nQuantum Computing\n\nQuantum computing is a fundamentally different style of computation that leverages quantum mechanics and is capable of simulating atomic and subatomic phenomena. Quantum computing uses “qubits,” which may represent an infinite number of superimposed states. So while traditional methods have to carry out a single path per result, quantum computers use a larger workspace to explore multiple paths simultaneously.\n\nQuantum computers are expected to surpass any conventional binary-code machine in terms of complexity and speed. They also differ from traditional supercomputers in that they solve different types of questions specific to fields like chemistry, material science and physics, Subasi explained.\n\nFrequently Asked Questions"
    }
}