{
    "id": "dbpedia_8912_0",
    "rank": 87,
    "data": {
        "url": "https://www.amnesty.org/en/latest/news/2022/02/usa-facial-recognition-technology-reinforcing-racist-stop-and-frisk-policing-in-new-york-new-research/",
        "read_more_link": "",
        "language": "en",
        "title": "USA: Facial recognition technology reinforcing racist stop-and-frisk policing in New York – new research",
        "top_image": "https://www.amnesty.org/en/wp-content/uploads/2022/02/Inside-the-NYPD-surveillance-machine-1-1024x683.png",
        "meta_img": "https://www.amnesty.org/en/wp-content/uploads/2022/02/Inside-the-NYPD-surveillance-machine-1-1024x683.png",
        "images": [
            "https://www.amnesty.org/en/wp-content/uploads/2021/08/129327069-45f0fe5f-7fa9-4b09-acbb-3272541534ab-170x72.png",
            "https://www.amnesty.org/en/wp-content/uploads/2018/08/amnesty-international-logomark.jpg",
            "https://www.amnesty.org/en/wp-content/uploads/2022/02/Inside-the-NYPD-surveillance-machine-1-1444x710.png",
            "https://www.amnesty.org/en/wp-content/themes/humanity-theme/assets/images/icon-facebook.svg",
            "https://www.amnesty.org/en/wp-content/themes/humanity-theme/assets/images/icon-twitter.svg",
            "https://www.amnesty.org/en/wp-content/themes/humanity-theme/assets/images/icon-facebook.svg",
            "https://www.amnesty.org/en/wp-content/themes/humanity-theme/assets/images/icon-twitter.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2022-02-15T00:01:00+00:00",
        "summary": "",
        "meta_description": "Non-white neighbourhoods in the Bronx, Brooklyn and Queens live with more CCTV surveillance New interactive website details exposure to invasive technology New Yorkers living in areas at greater risk of stop-and-frisk by police are also more exposed to invasive facial recognition technology, new research by Amnesty International and partners has revealed. New analysis as part of […]",
        "meta_lang": "en",
        "meta_favicon": "https://www.amnesty.org/en/wp-content/plugins/wp-plugin-amnesty-branding/assets/favicons/apple-touch-icon.png",
        "meta_site_name": "Amnesty International",
        "canonical_link": "https://www.amnesty.org/en/latest/news/2022/02/usa-facial-recognition-technology-reinforcing-racist-stop-and-frisk-policing-in-new-york-new-research/",
        "text": "Non-white neighbourhoods in the Bronx, Brooklyn and Queens live with more CCTV surveillance\n\nNew interactive website details exposure to invasive technology\n\nNew Yorkers living in areas at greater risk of stop-and-frisk by police are also more exposed to invasive facial recognition technology, new research by Amnesty International and partners has revealed.\n\nNew analysis as part of the global Ban The Scan campaign has proven how the New York Police Department’s vast surveillance operation particularly affects people already targeted for stop-and-frisk across all five boroughs of New York City.\n\nIn the Bronx, Brooklyn and Queens, the research also showed that the higher the proportion of non-white residents, the higher the concentration of facial recognition compatible CCTV cameras.\n\nBanning facial recognition for mass surveillance is a much-needed first step towards dismantling racist policing\n\nMatt Mahmoudi, Artificial Intelligence and Human Rights Researcher\n\n“Our analysis shows that the NYPD’s use of facial recognition technology helps to reinforce discriminatory policing against minority communities in New York City,” said Matt Mahmoudi, Artificial Intelligence and Human Rights Researcher at Amnesty International.\n\n“We have long known that stop-and-frisk in New York is a racist policing tactic. We now know that the communities most targeted with stop-and-frisk are also at greater risk of discriminatory policing through invasive surveillance.\n\n“The shocking reach of facial recognition technology in the city leaves entire neighbourhoods exposed to mass surveillance. The NYPD must now disclose exactly how this invasive technology is used.\n\n“Banning facial recognition for mass surveillance is a much-needed first step towards dismantling racist policing, and the New York City Council must now immediately move towards a comprehensive ban.”\n\nThe findings are based on crowdsourced data obtained by thousands of digital volunteers as part of the Decode Surveillance NYC project, who mapped more than 25,500 CCTV cameras across New York City. Amnesty International worked with data scientists to compare this data with statistics on stop-and-frisk and demographic data.\n\nFacial recognition technologies (FRT) for identification are systems of mass surveillance that violate the right to privacy, and threaten the rights to freedom of assembly, equality and non-discrimination.\n\nThe NYPD used FRT in at least 22,000 cases between 2016 and 2019. Data on incidents of stop-and-frisk by the NYPD since 2002 shows Black and Latinx communities have been the overwhelming target of such tactics.\n\nLast year, Amnesty International sued the NYPD after it refused to disclose public records regarding its acquisition of FRT and other surveillance tools. The case is ongoing.\n\nNew interactive website detailing FRT exposure\n\nAmnesty International is today also launching a new website that allows users to discover how much of any potential walking route between two locations in New York City might be exposed to FRT surveillance.\n\nDuring the Black Lives Matter movement of mid-2020, New Yorkers attending protests experienced higher levels of exposure to FRT. For example, a protester walking from the nearest subway station to Washington Square Park would be under surveillance by NYPD Argus cameras for the entirety of their route.\n\n“When we looked at routes that people would have walked to get to and from protests from nearby subway stations, we found nearly total surveillance coverage by publicly-owned CCTV cameras, mostly NYPD Argus cameras,” said Matt Mahmoudi.\n\n“The pervasive use of facial recognition technology is effectively a digital stop-and-frisk. The use of mass surveillance technology at protest sites is being used to identify, track and harass people who are simply exercising their human rights.\n\n“This is a deliberate scare tactic by the NYPD that has no place in a free society, and must be stopped immediately.”\n\nThe website also allows users to track how much FRT is used between any of the major tourist attractions in the city by plotting the distance and possible route taken.\n\nThe pervasive use of facial recognition technology is effectively a digital stop-and-frisk\n\nMatt Mahmoudi\n\nAmnesty International encourages New Yorkers to take action by sending a letter of protest to their council member demanding the introduction of a bill that prohibits FRT to help protect their communities. Global users can sign Amnesty International’s petition calling for regulation of when and where public FRT systems are used.\n\nResearch partners that Amnesty International worked with include: Julien Cornebise of the Computer Science Department, University College London; BetaNYC, a civic organisation using data and technology to hold government to account; and Dr Damon Wischik, an independent data scientist."
    }
}