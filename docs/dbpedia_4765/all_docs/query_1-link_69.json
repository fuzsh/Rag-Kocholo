{
    "id": "dbpedia_4765_1",
    "rank": 69,
    "data": {
        "url": "https://arxiv.org/html/2310.03841v2",
        "read_more_link": "",
        "language": "en",
        "title": "ALBERTA: ALgorithm-Based Error Resilience in Transformer Architectures",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/extracted/5391272/figures/Self_Attention.png",
            "https://arxiv.org/html/extracted/5391272/figures/Pipeline_Overview.png",
            "https://arxiv.org/html/extracted/5391272/figures/ALBERTA_Pipeline.png",
            "https://arxiv.org/html/extracted/5391272/figures/Checksum_Diagram.png",
            "https://arxiv.org/html/extracted/5391272/figures/V_Orig/V_orig_ViT.png",
            "https://arxiv.org/html/extracted/5391272/figures/V_Orig/V_orig_DeiT.png",
            "https://arxiv.org/html/extracted/5391272/figures/V_Prop_Mismatch/V_Prop_DeiT_b.png",
            "https://arxiv.org/html/extracted/5391272/figures/V_Prop_Mismatch/V_Prop_DeiT_t.png",
            "https://arxiv.org/html/extracted/5391272/figures/V_Prop_Mismatch/V_Prop_ViT.png",
            "https://arxiv.org/html/extracted/5391272/figures/V_layer/DeiT-base.jpg",
            "https://arxiv.org/html/x1.png",
            "https://arxiv.org/html/x2.png",
            "https://arxiv.org/html/x3.png",
            "https://arxiv.org/html/x4.png",
            "https://arxiv.org/html/x5.png",
            "https://arxiv.org/html/x6.png",
            "https://arxiv.org/html/x7.png",
            "https://arxiv.org/html/x8.png",
            "https://arxiv.org/html/x9.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "resilience",
            "transformers",
            "safety",
            "robustness",
            "detection",
            "protection",
            "correction"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "License: arXiv.org perpetual non-exclusive license\n\narXiv:2310.03841v2 [cs.CR] 05 Feb 2024\n\nALBERTA: ALgorithm-Based Error Resilience in Transformer Architectures\n\nHaoxuan Liu, Vasu Singh, MichaÅ‚ Filipiuk, and Siva Kumar Sastry Hari\n\nNVIDIA\n\n{steveliu,vasus,mfilipiuk,shari}@nvidia.com\n\nAbstract\n\nVision Transformers are being increasingly deployed in safety-critical applications that demand high reliability. It is crucial to ensure the correctness of their execution in spite of potential errors such as transient hardware errors. We propose a novel algorithm-based resilience framework called ALBERTA that allows us to perform end-to-end resilience analysis and protection of transformer-based architectures. First, our work develops an efficient process of computing and ranking the resilience of transformers layers. We find that due to the large size of transformer models, applying traditional network redundancy to a subset of the most vulnerable layers provides high error coverage albeit with impractically high overhead. We address this shortcoming by providing a software-directed, checksum-based error detection technique aimed at protecting the most vulnerable general matrix multiply (GEMM) layers in the transformer models that use either floating-point or integer arithmetic. Results show that our approach achieves over 99% coverage for errors that result in a mismatch with less than 0.2% and 0.01% computation and memory overheads, respectively. Lastly, we present the applicability of our framework in various modern GPU architectures under different numerical precisions. We introduce an efficient self-correction mechanism for resolving erroneous detection with an average of less than 2% overhead per error.\n\nIndex Terms:\n\nresilience, transformers, safety, robustness, detection, protection, correction\n\nI Introduction\n\nDeep learning has become the key technology in several safety-critical fields like autonomous vehicles (AVs) [13], medical image analysis [27], and drug design [3]. While convolutional neural networks (CNNs) were the predominant architecture of choice for deep learning in the last decade in computer vision tasks, the focus is rapidly shifting to transformer-based networks. Following recent breakthroughs in self-attention and model training optimizations, vision transformers (ViTs) have demonstrated their effectiveness in adapting to a wide variety of vision problems ranging from image classification [8], object detection [19], image generation [31], and semantic segmentation [16].\n\nIt is important to understand the effect of transient hardware errors on various components of the transformer architecture. Such understanding can provide insights to develop resilient transformers without high computational overhead for safety-critical applications.\n\nPrior work on resilience in deep neural networks utilize different techniques like range-based bounds checking [4], redundant layer computation [21], and algorithm-based fault tolerance (ABFT) techniques [12]. These methods are either not sufficient or pose significant overhead for vision transformers. We investigate the vulnerability of individual layers of transformers and whether we can provide high resilience in vision transformer models with minimal overhead.\n\nIn this paper, we present a framework called ALBERTA (ALgorithm-Based Error Resilience in Transformer Architectures) for end-to-end resilience analysis and enhancement framework for vision transformers. While ALBERTA can be employed using any deep learning framework, we prototype it using PyTorch [23]. To the best of our knowledge, this is the first paper to perform a detailed resilience analysis of vision transformer models (an important class of perception models) using floating-point and integer data types, provide novel insights into the vulnerable components, and propose a low-cost protection technique to significantly increase its resilience with ultra-low overheads. The following are the main contributions of this paper:\n\nâ€¢\n\nWe implement the vulnerability analysis in ALBERTA using an error injector module in PyTorch that allows the user to import custom datasets and select desired injection modes for transformer model analysis. The set of injection locations supported by the injector module include layer input, output, and weights, while the set of enabled injection types include single bit flip for integers, single bit in the exponent or mantissa for floating-point values, and replacement with random or user-specified value.\n\nâ€¢\n\nWe investigate the vulnerability of different layers in a transformer model and gather interesting insights: (1) Our chosen transformer architecture exhibits a significant jump in resilience from the third to eighth multi-head attention blocks (out of twelve blocks), which is a counter-intuitive pattern compared to the findings on CNNs that earlier layers are resilient [17, 21]. (2) Injections in the prediction head of the transformer result in the highest probability of mismatch in the network output. (3) Selective layer duplication provides coverage of about 90% at an overhead of more than 30%.\n\nâ€¢\n\nThe error-resilience algorithm in ALBERTA is also implemented as a Pytorch module. We implement optimized checksum computation for floating-point (FP) based models. It is well-known that such checksums cannot be bitwise precise due to FP non-associativity. So, the solutions have to rely on conservative thresholds for error checking, which can compromise error coverage. We present a methodology that derives the thresholds such that high error coverage is maintained.\n\nâ€¢\n\nOur proposed error-resilience algorithm achieves over 99% coverage of all injected errors that result in network misclassification at <0.2% computation overhead and <0.01% memory overhead. While false detections are rare, we introduce an efficient self-correction mechanism with an average overhead of <2% to resolve each erroneous detection.\n\nThe paper is organized as follows. Section II formalizes our problem statement and related work. Section III describes the ALBERTA framework and Section IV presents the results we obtain on different vision transformers using ALBERTA. Section VI concludes the paper and discusses further directions for future work.\n\nII Problem Statement\n\nII-A Background\n\nVision Transformers. Transformer-based models [29] first gathered attention in the context of natural language processing. After their huge success, they started to gain traction in different areas [10, 32], computer vision including. The Vision Transformer (ViT) was one of the first transformer models for vision: it is pretrained (supervised) on the ImageNet-21k dataset at a resolution of 224x224 pixels, and later finetuned on ImageNet [5] at the same resolution [8]. Images are presented to the model as a sequence of 16x16 fixed-size patches that are linearly and positionally embedded. For image classification tasks, the model also contains an extra classification token that will eventually be passed through a final linear layer in order to produce the network result. Studies have demonstrated that transformers do not generalize well when trained on insufficient amounts of data, and the training of these models involved extensive computing resources [28]. As a result, DeiT was created as a more efficiently trained transformer that utilizes a novel distillation procedure. Specifically, the process involves a distillation token aimed at reproducing the label estimated by a teacher model (often a pretrained ConvNet).\n\nIn our work, we included both the original ViT and DeiT models, alongside the DeiT-Tiny to determine the effect of the networkâ€™s size and complexity on its error resilience. For all transformers included in our studies, the architecture follows a pattern of stacked self-attention functions and fully connected layers. The self-attention functions can be thought of as mapping a query vector and a set of key-value pairs to a vector output, while the fully connected layers serve to project and modify the output vector to be used as input tokens to the next layer. Similar to the concept used in database retrieval, the vector output of self-attention is computed as a weighted sum of the input values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key [29]. As shown in Figure 1, the self-attention function first computes the corresponding query, key, and value matrices for the input tokens, and subsequently performs scaled dot-products between the generated matrices to arrive at the output vector. Since these GEMM operations make up the majority of the computation in vision transformers, our studies focus primarily on analyzing and protecting these operations.\n\nFormulation to Quantify Resilience. We focus on understanding the resilience of different transformers used in vision in the context of transient hardware errors at inference time. Specifically, we employ a single-bit flip error model that is commonly used as an abstraction for modeling hardware faults [2]. Within this error model, we focus on transient errors that successfully alter the originally correctly chosen classification class of an inference. We refer to this as a classification mismatch and it can be used as the baseline vulnerability metric for selective protection.\n\nCNN error resilience is a well-studied topic [11, 14, 24, 25, 26, 18]. Similar to a prior work [21], we also formulated a transformer layerâ€™s vulnerability metric based on the size of the layer and the likelihood of an error in the layer propagating to the output. Specifically, we define a layerâ€™s vulnerability as Vlâ¢aâ¢yâ¢eâ¢râ¢[i]=Voâ¢râ¢iâ¢gâ¢[i]Ã—Ppâ¢râ¢oâ¢pâ¢[i]subscriptð‘‰ð‘™ð‘Žð‘¦ð‘’ð‘Ÿdelimited-[]ð‘–subscriptð‘‰ð‘œð‘Ÿð‘–ð‘”delimited-[]ð‘–subscriptð‘ƒð‘ð‘Ÿð‘œð‘delimited-[]ð‘–V_{layer}[i]=V_{orig}[i]\\times P_{prop}[i]italic_V start_POSTSUBSCRIPT italic_l italic_a italic_y italic_e italic_r end_POSTSUBSCRIPT [ italic_i ] = italic_V start_POSTSUBSCRIPT italic_o italic_r italic_i italic_g end_POSTSUBSCRIPT [ italic_i ] Ã— italic_P start_POSTSUBSCRIPT italic_p italic_r italic_o italic_p end_POSTSUBSCRIPT [ italic_i ], where Voâ¢râ¢iâ¢gâ¢[i]subscriptð‘‰ð‘œð‘Ÿð‘–ð‘”delimited-[]ð‘–V_{orig}[i]italic_V start_POSTSUBSCRIPT italic_o italic_r italic_i italic_g end_POSTSUBSCRIPT [ italic_i ] represents the probability that a transient hardware fault corrupts the output of the ið‘–iitalic_i-th layer and Ppâ¢râ¢oâ¢psubscriptð‘ƒð‘ð‘Ÿð‘œð‘P_{prop}italic_P start_POSTSUBSCRIPT italic_p italic_r italic_o italic_p end_POSTSUBSCRIPT represent the likelihood that the corrupted output will propagate to and modify the final model output. Voâ¢râ¢iâ¢gâ¢[i]subscriptð‘‰ð‘œð‘Ÿð‘–ð‘”delimited-[]ð‘–V_{orig}[i]italic_V start_POSTSUBSCRIPT italic_o italic_r italic_i italic_g end_POSTSUBSCRIPT [ italic_i ] depends heavily on the hardware details such as raw failure rates, numerical precision, size of the layer (e.g., number of MACs and buffers used to execute the work in the layer). It can effectively be approximated as proportional to the number of MAC operations used to compute the output of the ið‘–iitalic_i-th layer, assuming that all MAC operations within the system have an equal likelihood of faulting and the large storage structures (e.g., FIFOs, buffers) are protected with ECC/parity. Without loss of generality, we compute and use the relative vulnerability for Voâ¢râ¢iâ¢gâ¢[i]subscriptð‘‰ð‘œð‘Ÿð‘–ð‘”delimited-[]ð‘–V_{orig}[i]italic_V start_POSTSUBSCRIPT italic_o italic_r italic_i italic_g end_POSTSUBSCRIPT [ italic_i ] in this paper. It is computed as the number of MACs used in one forward pass of the ið‘–iitalic_i-th layer divided by the total number of MACs used in one forward pass of the entire model. By definition, 0.0<Voâ¢râ¢iâ¢gâ¢[i]<1.00.0subscriptð‘‰ð‘œð‘Ÿð‘–ð‘”delimited-[]ð‘–1.00.0<V_{orig}[i]<1.00.0 < italic_V start_POSTSUBSCRIPT italic_o italic_r italic_i italic_g end_POSTSUBSCRIPT [ italic_i ] < 1.0.\n\nA layerâ€™s propagation vulnerability, on the other hand, can be computed using either the number of mismatches that occur during our injection campaign of said layer, or a continuous metric we refer to as Delta Loss:\n\nÎ”â¢Lâ¢oâ¢sâ¢slâ¢aâ¢yâ¢eâ¢r=âˆ‘i=1N[â„“gâ¢oâ¢lâ¢dâ¢eâ¢nâˆ’â„“i]/NÎ”ð¿ð‘œð‘ subscriptð‘ ð‘™ð‘Žð‘¦ð‘’ð‘Ÿsuperscriptsubscriptð‘–1ð‘delimited-[]subscriptâ„“ð‘”ð‘œð‘™ð‘‘ð‘’ð‘›subscriptâ„“ð‘–ð‘\\Delta Loss_{layer}=\\sum_{i=1}^{N}[\\ell_{golden}-\\ell_{i}]/Nroman_Î” italic_L italic_o italic_s italic_s start_POSTSUBSCRIPT italic_l italic_a italic_y italic_e italic_r end_POSTSUBSCRIPT = âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT [ roman_â„“ start_POSTSUBSCRIPT italic_g italic_o italic_l italic_d italic_e italic_n end_POSTSUBSCRIPT - roman_â„“ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ] / italic_N\n\nwhere â„“gâ¢oâ¢lâ¢dâ¢eâ¢nsubscriptâ„“ð‘”ð‘œð‘™ð‘‘ð‘’ð‘›\\ell_{golden}roman_â„“ start_POSTSUBSCRIPT italic_g italic_o italic_l italic_d italic_e italic_n end_POSTSUBSCRIPT is the cross-entropy loss for an error-free inference and â„“isubscriptâ„“ð‘–\\ell_{i}roman_â„“ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT stands for the cross-entropy loss for the corresponding ið‘–iitalic_i-th error-injected inference across Nð‘Nitalic_N total error injections. Similar to the case for Voâ¢râ¢iâ¢gâ¢[i]subscriptð‘‰ð‘œð‘Ÿð‘–ð‘”delimited-[]ð‘–V_{orig}[i]italic_V start_POSTSUBSCRIPT italic_o italic_r italic_i italic_g end_POSTSUBSCRIPT [ italic_i ], the larger the value of Î”â¢Lâ¢oâ¢sâ¢slâ¢aâ¢yâ¢eâ¢rÎ”ð¿ð‘œð‘ subscriptð‘ ð‘™ð‘Žð‘¦ð‘’ð‘Ÿ\\Delta Loss_{layer}roman_Î” italic_L italic_o italic_s italic_s start_POSTSUBSCRIPT italic_l italic_a italic_y italic_e italic_r end_POSTSUBSCRIPT, the more vulnerable the layer is to transient errors. The main advantage of Î”â¢Lâ¢oâ¢sâ¢slâ¢aâ¢yâ¢eâ¢rÎ”ð¿ð‘œð‘ subscriptð‘ ð‘™ð‘Žð‘¦ð‘’ð‘Ÿ\\Delta Loss_{layer}roman_Î” italic_L italic_o italic_s italic_s start_POSTSUBSCRIPT italic_l italic_a italic_y italic_e italic_r end_POSTSUBSCRIPT is that it converts the binary metric of classification mismatch into a continuous metric, which has been shown to significantly boost the speed of model analysis, especially when mismatches occur sparsely.\n\nII-B Related Work\n\nFor CNNs, different techniques have been explored to make inferences resilient. Exploding neuron values were identified as one of the primary reasons for inference output corruptions [17, 4]. A prior work profiled the value ranges in each layer during fault-free executions and derived a range-based bounds checker to detect significant deviations [17]. Ranger extended the concept and proposed an automated transformation to selectively restrict the value ranges in DNNs, which reduces the large deviations caused by critical faults and transforms them to benign faults that can be tolerated by the inherent resilience of the DNNs [4]. This work builds on top of these methods and only considers residual errors. We assume that such detectors or range restrictors are in place or the quantized data types used during deployment will inherently restrict the value ranges. We only consider errors that will perturb the value of the neuron within the profiled value ranges as computed using the training set.\n\nMahmoud et al.[21] introduced FILR, an overarching procedure that can be broken down into two separate resilience methods â€“ feature-map level resilience (FLR) and inference level resilience (ILR) â€“ as each method targets a different dimension when providing selective resilience for CNNs. During FLR, the network layers are ranked using a given vulnerability metric, and the layers are selectively protected such that it will simultaneously maximize the vulnerability coverage and minimize the overhead of redundancy. ILR, on the other hand, is used to determine the thresholds on network confidence to determine which inferences are vulnerable and need a rerun. Metrics to determine vulnerability for non-classification models (e.g., segmentation or detection) are not studied, which makes it difficult to apply ILR to such applications. While FLR is attractive (and has similarities to our solution), the duplication of layers as a protection method is too expensive and often results in a high-overhead solution. We overcome that challenge by leveraging a significantly lower-cost algorithm-based protection method.\n\nSince most of the compute-intensive (convolution and fully connected) layers are linear operations and are executed as GEMMs (general matrix multiplications) on GPUs, algorithm-based fault tolerance (ABFT) techniques that verify and correct computation using checksums are applicable [12]. These techniques compute checksums for input data, store them with the original data, perform the original and redundant computation, verify outputs, and correct errors inline. While the extra compute operations ABFT introduces are a small fraction of the number of the original computations, prior ABFT implementations have achieved about 20 percent runtime overheads for square matrices [6]. A recent study reported that the overheads can be much higher (>50absent50{>}50> 50%) for the non-square matrices that are typically used in CNNs [11]. Recent studies applied the approach to detect errors in convolutions [9, 11] and reported much lower overheads (6âˆ’236236{-}236 - 23%) without the inline error correction capabilities (referred as Algorithm-Based Error Detection or ABED). In complex safety-critical systems such as AVs, preventing silent data corruption (SDC) is more important than the ability to correct the error inline. Some of the prior solutions focus on fixed-point computations (e.g., int8 convolutions in [11]) where a precise checksum computation is viable and sufficient. In most practical applications, the use of floating-point data types (e.g., FP16/E5M10 or Bfloat16/E8M7) remains prevalent. Floating-point computations are known to introduce numerical error that makes checksum-based checking challenging.\n\nThere is parallel work to ALBERTA that employs similar methodologies of providing transformer error resilience through checksum-based algorithms [20]. In our assessments, ALBERTA provides several advantages when compared to the alternative study. In terms of performance, ALBERTA achieves a substantial improvement in error recovery from 96% to 99%. When evaluating the experiment setup and results, ALBERTA evidently provides better versatility in handling production level architectures and dataset configurations. As opposed to analyzing CIFAR-10 with less relevant images in [20], ALBERTA utilizes the full ImageNet dataset and allows for error injection campaigns of arbitrary sizes. Moreover, ALBERTA provides detailed studies of numerical discrepancies encountered during checksum computation, which is crucial to providing error resilience for floating pointing models. Combined with an easy extension proposed to address broader SDCs from hardware and systemic faults, the findings and error correction capabilities provided by ALBERTA translates directly to production settings characterized by substantial variations in inference data.\n\nII-C Research Questions\n\nGiven the challenges mentioned above, the primary objective of this paper is to answer the following four key research questions.\n\nâ€¢\n\nRQ1: How resilient are vision transformers to transient errors when performing image classification?\n\nâ€¢\n\nRQ2: What per-layer resilience patterns and variations exist, if any, for vision transformers?\n\nâ€¢\n\nRQ3: Can we protect vision transformer models in a way to achieve high resilience with minimal computation and memory overhead?\n\nâ€¢\n\nRQ4: How do we design a reliable checksum-based error detection mechanism that maintains high error coverage for floating-point models?\n\nIII The ALBERTA Framework\n\nWe present ALBERTA, algorithm-based error resilience in transformer architectures, a framework that allows us to analyze and improve the resilience of (vision) transformer models. We focus on vision transformers owing to their increasing use in safety-critical applications. We first present the vulnerability analysis of vision transformers in ALBERTA followed by our resilience technique.\n\nIII-A Vulnerability Analysis\n\nWe quantify the vulnerability of individual layers with a pipeline that is divided into the following four stages. Figure 2 summarizes the pipeline.\n\n(1) The preprocess step records the numerical lower and upper bounds for every layer in the network during inference to define the expected values ranges of neuron outputs. This information is later used in the error injection to rule out errors that can be protected by techniques like clamping and range restriction [4, 17]. (2) The profiling step records the network architecture details (layer sizes, parameter count, etc.) in addition to collecting the set of images that the error-free pre-trained model correctly classifies. We refer to this subset as golden data and will use it as the sample space for error injection and resilience. (3) The error injection step performs data type dependent random error injections for every layer within the network. Specifically, for every injection experiment, we flip a random bit at a randomly chosen neuron for a random image â€“ as constrained by the numerical range determined during the preprocess step â€“ and record the location of the error injection with the corrupted output. (4) The postprocess step compiles the results from injection and profiling steps into pandas dataframes for selective layer level duplication.\n\nIn the error injection step, we perform 102400 injections for very low error in the measurement at high confidence. With the above sample size, the error bar is <0.24absent0.24{<}0.24< 0.24% at 99999999% confidence level (using 90909090% as population proportion). Depending on the desired error tolerance in the results, fewer injections may be sufficient. During each individual error injection, we sample from the set of Golden Data containing 5017600 images that the model correctly classifies and select batches of size 128 or user specified number of images for analysis. For each selected image, the output activation of the injected layer is modified using the target injection type and the corrupted classification loss â€“ alongside other injection metadata â€“ is recorded during inference for downstream analysis.\n\nWith the objective of protecting the model with the lowest possible overhead, we focus on using the vulnerability data collected from the pipeline to rank the network layers, such that employing a chosen protection algorithm, such as selective layer duplication or checksum style error detection, will simultaneously maximize the resilience and minimize the overhead of redundancy. In the case for selective layer duplication, the coverage provided by protecting a target layer is computed using the equation for Vlâ¢aâ¢yâ¢eâ¢rsubscriptð‘‰ð‘™ð‘Žð‘¦ð‘’ð‘ŸV_{layer}italic_V start_POSTSUBSCRIPT italic_l italic_a italic_y italic_e italic_r end_POSTSUBSCRIPT, while the overhead of duplicating a target layer depends on the amount of work in the layer (e.g., number of MACs, which is proportional to Voâ¢râ¢iâ¢gsubscriptð‘‰ð‘œð‘Ÿð‘–ð‘”V_{orig}italic_V start_POSTSUBSCRIPT italic_o italic_r italic_i italic_g end_POSTSUBSCRIPT according to the formulation described in Section II-A).\n\nThe majority of the computation in transformer architectures is performed in linear (fully connected) layers that are a part of each transformer block. To provide comprehensive error protection, we select four layers to be included in our analysis pipeline for every transformer block. This consists of the linear layer used to compute key query value matrices (Q, K, V) as shown in Figure 1, the linear projection layer that outputs the result of multi-head attention, and two accompanying linear layers used by the feed-forward MLP. The matrix multiplication that occurs within the self-attention computation (dot product between query and key matrix and subsequently the product between the softmax output and the value matrix) are not considered in this approach and will be addressed in future work due to user-end implementation complexity. As of Pytorch version v2.0.0, all efficient error injection methods are done through Pytorch hooks, whose applications are limited to well defined Pytorch modules as opposed to general operations such as matrix multiplication. Although it is possible to use a user-defined self-attention module with custom matrix multiplication layers, doing so would render the framework not generalizable where each target model must be individually modified.\n\nIII-B Resilience Analysis\n\nThis section presents our resilience improvement technique in the layers identified as vulnerable based on the above analysis. We start with the description of the Pytorch wrapper class that integrates ALBERTA into different transformer models. Next, we describe the execution and evaluation process which includes layer selection, parameter tuning, and generating the false positive and negative rates for error detection. Lastly, we provide the details of the correction mechanism that can be deployed alongside ALBERTA for forward error correction to complete the end-to-end protection solution.\n\nIII-B1 Resilience Implementation\n\nALBERTAâ€™s resilience implementation is defined as a Pytorch module. It provides a set of functionalities that enables an in-depth resilience analysis of transformer based architectures. Apart from the basic utility functions such as custom loading of models and datasets, the resilience implementation contains several key functionalities that sets it apart from previous works as listed below.\n\nChecksums. The core function of ALBERTA is to enable checksum style protection for the subset of layers that are deemed most vulnerable according to prior layer level analysis. In the case for most transformer models, such subsets consists solely of GEMM layers whose output activations are obtained by performing batched matrix multiplication between the input features and the transposed hidden weight matrix, while also adjusting the result by the layer bias. As part of ALBERTAâ€™s core functionality, we perform checksum style verification on this general matrix multiply (GEMM) operation and successfully avoid the overhead of traditional ABFT checksum matrices. To accomplish this, we forfeit the capabilities of inline error correction and instead compute row and column checksum vectors for the input and layer activation, respectively. Specifically, as depicted in Figure 4, the batched row checksum vector is computed by summing along the column dimension of the input batch, while the column checksum vector is computed by reducing the row dimension of the transposed hidden weight matrix. To perform error detection, we compare the dot product of the row and column checksums against the sum of layer activations for numerical discrepancy. It is worth noting that (1) this process offers a significant overhead reduction when compared to traditional techniques such as fmap duplication and modular redundancy â€“ as shown later in the results section and (2) it can be optimized such that the column checksum of the transposed hidden weight matrix can be computed offline and stored by ALBERTAâ€™s resilience implementation prior to deployment.\n\nWhile the checksum itself can be naively implemented using torch tensor operations, some challenges must be addressed for this detection mechanism to be generalizable.\n\n(1) As introduced in the findings of [11], the increasing use of reduced-precision data types (e.g., 8- and 4-bit integers) during inference accelerators introduces new challenges for checksum-based error detection techniques, as successive sums across large layer activations have a high likelihood for overflow. Although floating-point data types do not exhibit the extreme overflow behaviors observed in integers, significant numerical imprecision still occurs in the case where depending on the rounding mode â€“ overly large results will be represented as max float (RTZ) or Inf (RNE), while underflown results are often rounded to zero. In situations where such rounding errors necessitate significant increases in the discrepancy tolerance levels used during error detection, ALBERTAâ€™s resilience implementation includes additional functionalities for automatically selecting the appropriate numerical precision used for checksum computations based on the numerical range of network weights and the input dataset.\n\n(2) An equality check is sufficient when dealing with models that use fixed point data types. However, a more nuanced checksum verification is needed for floating-point models, as discrepancies in the checksum can arise due to the nondeterministic behavior of floating-point arithmetic, as opposed to transient errors. ALBERTAâ€™s resilience implementation addresses this issue by providing an intuitive, confidence based mechanism for identifying whether a discrepancy is caused by transient error or numerical imprecision. We now describe this epsilon generation process.\n\nEps Generation. One significant limitation of prior works in algorithm based fault tolerance (ABFT) is the restricted application to fixed datatypes where the checksum computations are deterministic. Our work provides a solution to this issue by introducing a confidence based error detection framework capable of achieving close to 100% coverage of transient errors that result in model misclassification. In order to accomplish this, ALBERTAâ€™s resilience implementation includes a numerical analysis function that empirically models â€“ for each layer â€“ a unique distribution describing the probability that a discrepancy in the layerâ€™s online checksum is due to numerical imprecision rather than transient error. More specifically, this process involves first iterating through the subset of data that the error free network correctly classifies, while collecting during every inference a set of differences between the computed checksum and the true layer activation sum. Using this set of discrepancies which are unique to each layerâ€™s trained parameters and dimensions, a layer specific distribution can then be generated through regression and used for error detection during deployment, where if the observed checksum discrepancy is above a user set confidence threshold, an error would be raised and the correction mechanism would be triggered.\n\nIII-B2 Execution and Evaluation\n\nAside from allowing the users to select their desired numerical precision for the checksum independently from the model itself, ALBERTA offers two additional tuning mechanisms that the user can use prior to the evaluation step:\n\n1.\n\nThe option to either select custom layers for resilience or provide a desired theoretical error coverage and have ALBERTAâ€™s resilience implementation dynamically select the layers necessary for achieving it.\n\n2.\n\nSelecting the target distribution (defaults to standard normal) and confidence threshold of checksum discrepancies based on which error detection will be performed.\n\nAs we show in the vulnerability analysis, it is not uncommon for transformer architectures to have layers that are extremely resilient to transient errors. As a result, we can reduce overhead by omitting these layers. By simply providing a desired coverage level, ALBERTAâ€™s resilience implementation will automatically perform this optimization through a knapsack inspired mechanism. It is important to note that since ALBERTA behaves independently for each layer of the network, selecting a subset of layers for protection means error occurring in any unprotected layers cannot be detected; making it important to select layers with the highest error propagation rate and overall vulnerability for protection. In other words, when we decide to not include a layer for checksum protection, we are choosing to forefeit all error coverage for that layer in exchange for a reduction in network overhead. Furthermore, the optimal subset of layers returned by ALBERTA is based on estimated layer vulnerabilities that are dataset dependent. As a result, the resilience bounds we provide in the results section are not strictly true when fine-tuning models on new target datasets, but can always serve as a statistically accurate approximation.\n\nIII-B3 Correction\n\nIn addition to providing the necessary tools to integrate and evaluate the effectiveness of checksums as a protection mechanism for arbitrary transformer models, the wrapper also offers the choice of two correction mechanisms to be performed after error detection â€“ replay and skip forward.\n\nTo perform a replay upon error detection, we first save the activation values of every layer during inference, and if the subsequent layer raises an error, we simply read the error-free activations from the previous layer and rerun the inference step. This mechanism incurs constant space overhead â€“ since only one activation needs to be saved at a time during evaluation â€“ while also resulting in minimal runtime overhead as shown later in the results section.\n\nTo perform a skip forward upon error detection, we have the following three options â€“ jump ahead to the next layer with the same input size, skip to the next transformer block, or simply jump to the inference step while passing forward the saved, error free activation as input. This mechanism can be used for any layer inside the transformer blocks with zero overhead but will likely have a negative impact on the model accuracy. For this reason, we believe it is applicable only for special use cases and have designed ALBERTAâ€™s resilience implementation to default to replay.\n\nIV Results\n\nIV-A Evaluation Methodology\n\nWe perform our evaluation with a focus on DeiT-base and DeiT-tiny models, which are both pretrained and fine-tuned with distillation on ImageNet-1k (1 million images, 1,000 classes). We use the Pytorch Framework and obtained pretrained models from the Facebook research repository with patch 16 and 224x224 pre-training resolution. All experiments are run on a standard Linux server with NVIDIA A6000 GPUs and Intel i9-10980XE CPU. We obtained the results for vulnerability analysis using an adapted version of the GoldenEye injection module [22] and perform all other testing using custom Pytorch hooks. During vulnerability analysis, all inferences are performed using full fp32 precision, while inferences during resilience analysis are executed with half-precision at fp16. We evaluate checksum operations comprehensively at fp16, fp32, and fp64. However, due to limitations mentioned regarding checksums, the best accuracy during error detection are obtained using fp64 and are included here in both overhead and coverage related plots.\n\nIV-B Vulnerability Analysis\n\nWe first present the results from ALBERTAâ€™s vulnerability analysis on DEiT models. We excluded the original ViT results as they are similar to base DeiT. We note that the original ViT performs significantly worse than its DeiT counterpart â€“ its error propagation rate and (as a result) vulnerability exceeds that of DeiT across all layers in the network. The cause for this behavior can be attributed to the network parameters learned during distillation versus regular training.\n\nOrigination Probability Comparison. During the profiling step of our pipeline, we compute Voâ¢râ¢iâ¢gsubscriptð‘‰ð‘œð‘Ÿð‘–ð‘”V_{orig}italic_V start_POSTSUBSCRIPT italic_o italic_r italic_i italic_g end_POSTSUBSCRIPT as the fraction of MAC operations used in the forward pass of each layer (shown in Figure 5). We observe that the largest value corresponds to the positional embedding layer (convolution), which is about 100Ã—\\timesÃ— bigger than the intermediate layers inside the transformer block. Furthermore, the layer sizes are proportionally identical among both models included in our study.\n\nPropagation Probability Comparison. Using mismatch as the ground truth vulnerability metric for computing Vpâ¢râ¢oâ¢psubscriptð‘‰ð‘ð‘Ÿð‘œð‘V_{prop}italic_V start_POSTSUBSCRIPT italic_p italic_r italic_o italic_p end_POSTSUBSCRIPT, we note that both the DeiT models exhibit a similar behavior where error injections performed at the final linear prediction head resulted in the highest probability of mismatch in the output. This is illustrated in Figure 6.\n\nMore importantly, it can be observed that a significant number of layers within the DeiT-base model are incredibly resistant to transient errors. Moreover, DeiT-base has significantly better built-in resilience to transient error propagation when compared to DeiT-tiny. Out of 102400 error injections, zero random bit flip resulted in mis-classification of the network output for 22 out of the 50 layers. Comparisons between the results of DeiT-base and DeiT-tiny support the conclusion that a larger network size contributes to a lower error propagation probability. In practice, this behavior can be intuitively understood as the result of larger transformer networks containing higher number of normalization and activation layers that can likely suppress errors during inference.\n\nDelta Loss. Î”â¢Lâ¢oâ¢sâ¢sÎ”ð¿ð‘œð‘ ð‘ \\Delta Lossroman_Î” italic_L italic_o italic_s italic_s converts binary classification mismatch into a continuous metric. We observe that the error propagation graph of DeiT-base exhibits a considerable dip in Vlâ¢aâ¢yâ¢eâ¢rsubscriptð‘‰ð‘™ð‘Žð‘¦ð‘’ð‘ŸV_{layer}italic_V start_POSTSUBSCRIPT italic_l italic_a italic_y italic_e italic_r end_POSTSUBSCRIPT value starting from the 3rd to the middle of the 8th transformer block as shown in Figure 7. Although this is consistent with the claim that DeiT-base has significantly better resilience than its DeiT-tiny counterpart, we do not fully understand how the random sparsity difference in the Mismatch graph is transformed into a contiguous block of minimal vulnerability in the DeiT-base architecture. Keeping in mind that both delta loss and mismatch measure the same latent layer vulnerability, we propose alternate error models based on finer-grained error injections as part of future investigation into this statistical divergence.\n\nSelective Layer Duplication The coverage versus overhead results from selective layer duplication for DeiT-Tiny are shown in Figure 8, where x and y axes represent the total coverage and cumulative overhead, respectively. The dotted line represents the result of using the Î”â¢Lâ¢oâ¢sâ¢sÎ”ð¿ð‘œð‘ ð‘ \\Delta Lossroman_Î” italic_L italic_o italic_s italic_s derived layer vulnerability, while the solid oracle line is the result of using mismatch. Due to the prediction head of transformer architectures being consistently the most vulnerable layer (as measured using mismatch), we assume it is always protected by the algorithm and instead plot the coverage vs. overhead from protecting the remaining layers.\n\nWe present here two main takeaways from this study using Mismatch as the ground truth vulnerability. First, using the intersection between x = 90% and the coverage graphs, it can be observed that DeiT-Tiny is able to achieve 90% of the remaining vulnerability coverage at approximately 49% overhead. Second, a significantly steeper overhead can be seen when trying to obtain the remaining 10% coverage. To reach 99% coverage for instance, select layer duplication would incur approximately 45% additional overhead, which is prohibitively high in most high performance systems. While 90% may be sufficient for architectures that have high fault tolerance, safety critical applications often demand higher reliability that are closer to full 100% coverage. As a solution to this shortcoming, we introduce the alternative checksum-based protection for vision transformers.\n\nIV-C Protecting Vision Transformers.\n\nWe now present the main results from our experiments on error resilience, as divided into the following points of focus. (1) The empirical statistics of numerical discrepancies observed during floating-point checksums. (2) The coverage and overhead from selecting optimal subsets of layers for checksum protection. (3) The overall effectiveness of ALBERTAâ€™s confidence-based error detection and correction.\n\nEmpirical statistics of numerical discrepancies. At its core, the basis for using confidence-based error detection is the observation that the empirical discrepancies encountered during checksum form a normal-like distribution for all Imagenet samples at inference. As shown in Figure 9, the same linear layer in DeiT-base and DeiT-tiny â€“ sizes (768,3072) and (192, 768) â€“ both exhibit a normal-like behavior, with the overall size decrease of 16x (3072 / 192) translating to a similar magnitude drop in observed discrepancies.\n\nAt the network level, similar trends can be seen in figures 10, where we observe a positive correlation between layer size and observed discrepancy during checksum. Across all layers in the network, the observed discrepancy for DeiT-base is approximately 10x higher than that of DeiT-tiny â€“ going from a range of (10âˆ’5,10âˆ’2)superscript105superscript102(10^{-5},10^{-2})( 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT , 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT ) to (10âˆ’6,10âˆ’3)superscript106superscript103(10^{-6},10^{-3})( 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT , 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT )\n\nALBERTA Coverage versus Overhead. As observed earlier from the layer analysis results of DeiT-base and similar models in Figure 6, the last layer of most transformer models is by far the most vulnerable to transient errors â€“ contributing to close to 50% of all mismatches and 88% of the total vulnerability score â€“ and as a result, we have designed ALBERTA such that the last layer will always be included during layer selection for protection.\n\nSimilar to the setup in Figure 8, the coverage & overhead offered by protecting the last linear layer is omitted in Figure 11. Although it cannot be directly observed in Figure 11, the plots for ALBERTA â€“ lying flat along the x-axis â€“ exhibit a similar pattern to that of selective layer duplication, but is consistently over 100Ã—\\timesÃ— more efficient. While this value depends on the dimensions of the protected layers, for most transformer models, this value is well above 100 even without considering the boosts from offline checksum generation.\n\nIn previous works such as selective duplication, serious concerns were raised due to non-negligible model performance drops that resulted from high computational and/or memory overhead. As illustrated in Figure 12, ALBERTA marks a significant improvement from existing works where the computation overhead is less than 0.2% across all of our target models, while the memory overhead reaches a negligible maximum of 0.01% during checksum computation. The memory overheads are so low because only the protected layers need additional memory and that the additional memory incurred is a order of magnitude lower than the layerâ€™s original memory footprint. Specifically, the network memory overhead is computed as the sum of two components â€“ offline and online checksums. The offline checksum term is computed as the total memory allocated to storing the column checksum of weight matrices that are computed prior to inference 4. The online checksum term, on the other hand, is computed as the per-layer maximum of memory allocated to input checksum vector + memory allocated to computing the output checksum during verification. In cases where kernel fusion is possible, the overhead can be significantly lower because the output checksum computation will be fused with the epilogue.\n\nALBERTA Performance Analysis. Furthermore, assessments using torch.cuda.max_memory_allocated() indicate that our target modelsâ€™ maximum memory usage during inference is >30% less than that of training. Given the efficient and accelerated training support on modern GPUs, models running ALBERTA for error resilience would see little to no performance impact even in resource constrained systems.\n\nEffectiveness of confidence based error detection and correction. In related works that focus on models with fixed data types, layers protected by checksum-based algorithms easily achieves 100% coverage of single-bit flip errors. In floating-point models, a range-based equality check at the 99.9% confidence level does not catch all injected errors but consistently achieves over 99% coverage of errors that result in mismatches. Figure 13 shows that out of 3890 error injections that resulted in mismatches, our detection algorithm achieves a false negative rate of less than 1%, with 31 missed errors. Please note that error detection with ALBERTA has near zero false positives thanks to the earlier analysis of per-layer numerical discrepancies in 9. By setting the per layer threshold at 99.99% confidence level or greater, we completely eliminate false positives in our detection, as any discrepancies recorded above our threshold have less than 0.01% chance of occurring due to numerical imprecision. In our studies, errors injections that do not cause a significant change in layer activation â€“ magnitude of less than 1e-5 â€“ are not detected by our proposed framework in layers with high error-free discrepancies, but have also rarely been detected to cause a mismatch. As a general rule, there exists a correlation between how much an error offsets the original activation value and the probability of it affecting the network output. In our case with eps of less than 1e-3, such situation becomes even more unlikely to occur.\n\nIV-D Answering the Research Questions\n\nBased on the above results, we directly answer the research questions listed in Section II-C here.\n\nRQ1: Vision transformers are extremely resilient to transient errors when performing image classification, with injections in several layers resulting in zero mismatches. Using the origination probability and per-layer mismatches as shown in Figures 5 and 6, we compute the probability that a transient error results in an SDC for DeiT-base and DeiT-tiny to be 0.98% and 2.49%, respectively. While a fault in a DeiT-tinyâ€™s operation is more likely to cause an SDC, it has 13.9Ã—\\timesÃ— fewer operations than DeiT-base.\n\nRQ2: Using mismatch as the ground truth vulnerability metric, we find that the prediction head of vision transformers is most vulnerable to transient errors, while many layers across the middle of the network are highly resilient. We observe a positive correlation between network size and layer level resilience (deit-base vs. deit-tiny), and that training techniques such as distillation can have a significant impact in network resilience (deit-base vs. vit-base).\n\nRQ3: Existing modular redundancy techniques provides good protection but at the cost of prohibitively high overheads. Despite the challenges, ALBERTA achieves over 99% coverage for transient errors that result in a mismatch at less than 0.2% computation overhead and on average <0.01% memory overhead for vision transformer. We introduce several optimizations in the future work section that can further reduce the memory overhead.\n\nV Discussion\n\nDuplication vs. ALBERTA: Using mismatch as the ground truth vulnerability metric, performing selective layer duplication for DeiT-base provides 90% coverage at around 40% computation overhead and 92% memory overhead. ALBERTA reduces the computation overhead to approximately 0.2% and the memory overhead to less than 0.01%, while also increasing the overall coverage to 99%. By using replay as the self-correction mechanism for transient hardware faults, we are able to resolve all erroneous detection with an overhead of less than 2% â€“ making the framework itself resilient to future architecture and library changes that may affect the false positive rate for error detection.\n\nOptimizations: While the compute and data transfer overheads are small, the checksum computations can be memory intensive. Several optimizations can be employed to reduce (and eliminate) this overhead. (1) L2 cache eviction policy hints (e.g., evict-last hint) available in the latest GPUs starting Ampere [1] can be provided to keep the inputs (and outputs) persistent in L2 to minimize DRAM traffic for checksum generation. (2) Merge the checksum generation with the layer that produces the tensor. This way the tensor need not be fetched twice, eliminating extra memory traffic originating from checksum generation. (3) Lastly, hardware support to perform near L2 cache (or memory) reduction will eliminate data fetching from L2 (or memory) to streaming multiprocessors and pollute local caches with read-once data, and speed up checksum generation.\n\nOther fault types: Methods proposed in ALBERTA can be used to guard against SDCs from other fault sources, e.g., permanent and intermittent hardware faults, and potentially software bugs. There is increased interest in the industry to address SDCs caused by faults in processors deployed in datacenters, where the source is largely attributed to manufacturing defects and aging related faults [30, 7]. While the checksum-based error detection approach will be effective in detecting such faults, the following need to change â€“ selection strategy to identify what to protect, a diagnosis procedure to root cause the fault type (between permanent and transient), and the recovery mechanism needs to relaunch the work on a different node to maintain forward progress.\n\nVI Conclusion\n\nWe investigate the error resilience of the transformer architecture, specifically for the DeiT-base and DeiT-tiny implementations. Our investigations show that the embedding layer is most susceptible to error origination due to its large size, while the final prediction head is most vulnerable to error propagation due to its proximity to network output. Moreover, comparisons between the results for DeiT-base and DeiT-tiny serve as evidence that a larger network size contributes to lower average error propagation probability in transformers, while also highlighting the significant jump in layer resilience inside DeiT-base.\n\nReferences\n\n[1] CUDA C programming guide â€“ device memory l2 access management. https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-l2-access-management.\n\n[2] Rizwan A Ashraf, Roberto Gioiosa, Gokcen Kestor, Ronald F DeMara, Chen-Yong Cher, and Pradip Bose. Understanding the propagation of transient errors in HPC applications. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, pages 1â€“12, 2015.\n\n[3] Heba Askr, Enas Elgeldawi, Heba Aboul Ella, Yaseen A M M Elshaier, Mamdouh M Gomaa, and Aboul Ella Hassanien. Deep learning in drug discovery: an integrative review and future challenges. Artif Intell Rev, pages 1â€“63, November 2022.\n\n[4] Zitao Chen, Guanpeng Li, and Karthik Pattabiraman. A low-cost fault corrector for deep neural networks through range restriction. In IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pages 1â€“13, 2021.\n\n[5] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 248â€“255, 2009.\n\n[6] Chong Ding, Christer Karlsson, Hui Liu, Teresa Davies, and Zizhong Chen. Matrix multiplication on gpus with on-line fault tolerance. In 2011 IEEE Ninth International Symposium on Parallel and Distributed Processing with Applications, pages 311â€“317, 2011.\n\n[7] Harish Dattatraya Dixit, Sneha Pendharkar, Matt Beadon, Chris Mason, Tejasvi Chakravarthy, Bharath Muthiah, and Sriram Sankar. Silent data corruptions at scale, 2021.\n\n[8] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.\n\n[9] Dionysios Filippas, Nikolaos Margomenos, Nikolaos Mitianoudis, Chrysostomos Nicopoulos, and Giorgos Dimitrakopoulos. Low-cost online convolution checksum checker. IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 30(2):201â€“212, 2022.\n\n[10] Yuan Gong, Yu-An Chung, and James R. Glass. AST: audio spectrogram transformer. CoRR, abs/2104.01778, 2021.\n\n[11] Siva Kumar Sastry Hari, Michael B Sullivan, Timothy Tsai, and Stephen W Keckler. Making convolutions resilient via algorithm-based error detection techniques. IEEE Transactions on Dependable and Secure Computing, 19(4):2546â€“2558, 2021.\n\n[12] Kuang-Hua Huang and Jacob A Abraham. Algorithm-based fault tolerance for matrix operations. IEEE transactions on computers, 100(6):518â€“528, 1984.\n\n[13] Yu Huang and Yue Chen. Autonomous driving with deep learning: A survey of state-of-art technologies. CoRR, abs/2006.06091, 2020.\n\n[14] Younis Ibrahim, Haibin Wang, Man Bai, Zhi Liu, Jianan Wang, Zhiming Yang, and Zhengming Chen. Soft error resilience of deep residual networks for object recognition. IEEE Access, 8:19490â€“19503, 2020.\n\n[15] Justin Johnson. Deep learning for computer vision, lecture 17: Attention. https://web.eecs.umich.edu/~justincj/slides/eecs498/WI2022/598_WI2022_lecture17.pdf. p. 62, Accessed: 2023-05-31.\n\n[16] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):1â€“41, 2022.\n\n[17] Guanpeng Li, Siva Kumar Sastry Hari, Michael Sullivan, Timothy Tsai, Karthik Pattabiraman, Joel Emer, and Stephen W. Keckler. Understanding error propagation in deep learning neural network (dnn) accelerators and applications. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC), 2017.\n\n[18] F. Libano, B. Wilson, J. Anderson, M. J. Wirthlin, C. Cazzaniga, C. Frost, and P. Rech. Selective hardening for neural networks in fpgas. IEEE Transactions on Nuclear Science, 66(1):216â€“222, 2019.\n\n[19] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. CoRR, abs/2103.14030, 2021.\n\n[20] Kwondo Ma, Chandramouli Amarnath, and Abhijit Chatterjee. Error resilient transformers: A novel soft error vulnerability guided approach to error checking and suppression. In 2023 IEEE European Test Symposium (ETS), pages 1â€“6, 2023.\n\n[21] Abdulrahman Mahmoud, Siva Kumar Sastry Hari, Christopher W Fletcher, Sarita V Adve, Charbel Sakr, Naresh R Shanbhag, Pavlo Molchanov, Michael B Sullivan, Timothy Tsai, and Stephen W Keckler. Optimizing selective protection for CNN resilience. In ISSRE, pages 127â€“138, 2021.\n\n[22] Abdulrahman Mahmoud, Thierry Tambe, Tarek Aloui, David Brooks, and Gu-Yeon Wei. Goldeneye: A platform for evaluating emerging numerical data formats in dnn accelerators. In 2022 52nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pages 206â€“214. IEEE, 2022.\n\n[23] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas KÃ¶pf, Edward Z. Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style, high-performance deep learning library. CoRR, abs/1912.01703, 2019.\n\n[24] Marco Rios, Flavio Ponzina, Giovanni Ansaloni, Alexandre Levisse, and David Atienza. Error resilient in-memory computing architecture for cnn inference on the edge. In Proceedings of the Great Lakes Symposium on VLSI 2022, GLSVLSI â€™22, page 249â€“254, New York, NY, USA, 2022. Association for Computing Machinery.\n\n[25] Christoph Schorn, Thomas Elsken, Sebastian Vogel, Armin Runge, Andre Guntoro, and Gerd Ascheid. Automated design of error-resilient and hardware-efficient deep neural networks. CoRR, abs/1909.13844, 2019.\n\n[26] Christoph Schorn, Andre Guntoro, and Gerd Ascheid. An efficient bit-flip resilience optimization method for deep neural networks. In 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE), pages 1507â€“1512, 2019.\n\n[27] Dinggang Shen, Guorong Wu, and Heung-Il Suk. Deep learning in medical image analysis. Annu Rev Biomed Eng, 19:221â€“248, March 2017.\n\n[28] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and HervÃ© JÃ©gou. Training data-efficient image transformers & distillation through attention. In International conference on machine learning, pages 10347â€“10357. PMLR, 2021.\n\n[29] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. Attention is all you need. 2017.\n\n[30] Shaobu Wang, Guangyan Zhang, Junyu Wei, Yang Wang, Jiesheng Wu, and Qingchao Luo. Understanding silent data corruptions in a large production cpu population. In Proceedings of the 29th Symposium on Operating Systems Principles, SOSP â€™23, page 216â€“230, New York, NY, USA, 2023. Association for Computing Machinery.\n\n[31] Bowen Zhang, Shuyang Gu, Bo Zhang, Jianmin Bao, Dong Chen, Fang Wen, Yong Wang, and Baining Guo. Styleswin: Transformer-based GAN for high-resolution image generation. CoRR, abs/2112.10762, 2021.\n\n[32] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. Informer: Beyond efficient transformer for long sequence time-series forecasting. CoRR, abs/2012.07436, 2020."
    }
}