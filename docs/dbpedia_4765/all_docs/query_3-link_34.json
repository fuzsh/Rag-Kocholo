{
    "id": "dbpedia_4765_3",
    "rank": 34,
    "data": {
        "url": "https://dl.acm.org/doi/fullHtml/10.1145/3410154",
        "read_more_link": "",
        "language": "en",
        "title": "A Study on the Use of Checksums for Integrity Verification of Web Downloads",
        "top_image": "https://dl.acm.org/cms/attachment/5a7aeb01-2971-4b28-b8dd-6ef1d98c91e7/tops2401-04-f14.jpg",
        "meta_img": "",
        "images": [
            "https://dl.acm.org/cms/attachment/fcdf852d-ed7c-45f5-8565-ebc4cc798780/tops2401-04-f01.jpg",
            "https://dl.acm.org/cms/attachment/5dbfb260-edb3-4822-9346-a714474018c8/tops2401-04-f02.jpg",
            "https://dl.acm.org/cms/attachment/96e42d89-bf34-40c5-9896-9793b1c515b2/tops2401-04-f03.jpg",
            "https://dl.acm.org/cms/attachment/cbf83411-7290-449b-a517-93299cdf0a95/tops2401-04-f04.jpg",
            "https://dl.acm.org/cms/attachment/87920314-8c77-410b-a9a3-a637b178d9a5/tops2401-04-f05.jpg",
            "https://dl.acm.org/cms/attachment/fe201517-75fb-40c3-b156-69f48bf0ee4f/tops2401-04-f06.jpg",
            "https://dl.acm.org/cms/attachment/0ff07150-c6f1-48b3-9816-4b83d38c84f5/tops2401-04-f07.jpg",
            "https://dl.acm.org/cms/attachment/6a940b78-6a52-454f-9c00-81a68126c283/tops2401-04-f08.jpg",
            "https://dl.acm.org/cms/attachment/60e6ea1b-021d-40c3-a44b-cad0f7a753c6/tops2401-04-f09.jpg",
            "https://dl.acm.org/cms/attachment/e96d7a92-a711-4df5-9b5b-a05e6f705dbc/tops2401-04-f10.jpg",
            "https://dl.acm.org/cms/attachment/47b5aa3c-459c-4c9e-8164-91277aa5ebdd/tops2401-04-f11.jpg",
            "https://dl.acm.org/cms/attachment/724c022a-2c59-4562-aa75-f19a835dc897/tops2401-04-f12.jpg",
            "https://dl.acm.org/cms/attachment/68b837e1-ccb5-4251-b945-12bc3330a755/tops2401-04-f13.jpg",
            "https://dl.acm.org/cms/attachment/5a7aeb01-2971-4b28-b8dd-6ef1d98c91e7/tops2401-04-f14.jpg",
            "https://dl.acm.org/cms/attachment/b9df5cbd-b3d0-4111-92eb-f2d4a0ca9c92/tops2401-04-f15.jpg",
            "https://dl.acm.org/cms/attachment/4cacd54f-3264-434c-8350-b1510af885a2/cc-by-nc-sa.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "ALEXANDRE MEYLAN",
            "MAURO CHERUBINI",
            "BERTIL CHAPUIS",
            "MATHIAS HUMBERT",
            "IGOR BILOGREVIC",
            "KÉVIN HUGUENIN"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "2.3 File Integrity Verification\n\nSeveral works have studied, by means of online surveys, the security and usability of different fingerprint representations for authentication and integrity verification. Hsiao et al. have compared the speed and accuracy of hash verification with various textual and visual representations [5]. Their between-subjects study with 436 participants is the first to show that users struggle with comparing long fingerprints. More recently, Dechand et al. have studied the performance and usability of six textual fingerprint representations [6]. Their experiment with 1,047 participants demonstrates that the state-of-the-art hexadecimal representation is prone to partial pre-image attacks more than others, with more than 10% of attacks being missed by the users. Similarly, Tan et al. evaluate the usability and security of eight textual and visual fingerprint representations [28]. The results of their 661-participant experiments suggest that, when security is paramount, the best strategy is to remove the human from the loop and automate the verification process, which the authors did not test.\n\nResearch on secure messaging also provides us with relevant findings on the usability and security of fingerprints for authenticating the communicating entities. In their systematization of knowledge on secure messaging, Unger et al. emphasize the usability and adoption limitations of manual fingerprint verification [29]. Moreover, they mention short authentication strings, which rely on truncated cryptographic hashes, as a more usable alternative to fingerprints. In a 60-participant study on secure communication tools, Abu-Salma et al. show that fingerprints are not understood by participants, thus indirectly hindering the adoption of such tools [30]. Vaziripour et al. evaluate the usability of the authentication processes in three popular messaging applications (WhatsApp, Viber, Facebook Messenger) through a two-phase study involving 36 pairs of participants [31]. These participants notably report that fingerprint strings are too long, and some WhatsApp users appreciate being able to scan QR codes instead of having to compare long digit strings. Note that in these contexts, unlike for web downloads, automating fingerprint comparison is not possible because fingerprints usually come from a different channel. On the practical side, a number of programs (including browser extensions [32, 33]) to compute and verify checksums with graphical user interface are available. Yet, they only enable users to compute checksums, not to automatically verify them against those extracted from webpages.\n\nIn addition to checksums, digital certificates can be used to certify the authenticity and integrity of programs. However, some shortcomings of digital certificates include their cost, certificate validation issues, and private key (of developers and certification authorities) compromise [34, 35]. In fact, digital certificates (used for code-signing) do not provide the same guarantees that checksums do: Certificates guarantee that the downloaded files have been produced by certain developers, whereas checksums guarantee that the downloaded files are those the website administrators intended to point to. Therefore, checksums do not provide protection in the case where a malicious website administrator includes a link to a corrupted version of a program (e.g., Transmission). And certificates do not provide protection in the case where a hacker replaces a program file with a corrupted version of the program signed with the (valid) account of a malicious developer (or with a stolen account).\n\nIn our work, we focus on one aspect that was neglected by prior research: What is the behavior of the users when they (are asked to) verify file integrity by using checksums? Instead of testing different design of the checksum, we focus on the process by which participants compare an hexadecimal checksum with the output of the hash functions. In summary, we go beyond the sole investigation of manual fingerprint comparison, and we consider the overlooked context of web download integrity. We also employ eye-tracking techniques to gain a deeper understanding of how users perform fingerprint/checksum comparisons.\n\n4.2 Checksum Verification: Browser Extension\n\nAs browsers do not currently handle SRI for links, we developed a Chrome extension to automatically check the integrity of downloaded files. This extension should be considered as a proof of concept and not as a final product.\n\nDesign and Implementation. Our extension supports three popular algorithms used to generate checksums: the MD5, SHA-1, and SHA-2 hash functions. It is implemented in JS and it relies on the md5.js library for computing MD5 digests and the asmcrypto.js library for computing SHA digests. In total, the extension consists of $\\sim$400 lines of JavaScript code (excluding the libraries); it requires permission to access the browser's download manager in order to initiate and monitor downloads, as well as read-only access to the file system in order to compute the digest of the downloaded file.\n\nBecause SRI for links is currently not supported, the extension automatically extracts checksums directly from the text of HTML pages, thus requiring no changes to existing websites (such as VLC). It operates as follows:\n\nFor each visited webpage, it navigates the HTML DOM tree and extracts, by using regular expressions, hexadecimal strings that have the same format as checksums and the corresponding hash function names (e.g., MD5).\n\nIf checksums are detected (on the webpage or in the integrity attribute of the a element), it intercepts click events triggered by hyperlinks. If a link points to a file with a sensitive extension (e.g., dmg, exe) and/or multipurpose internet mail extension (MIME) type (e.g., application/x-apple-diskimage, application/x-msdownload), the download is followed by the verification of the checksum, essentially a comparison between the checksum that is detected and the one computed from the downloaded file.\n\nIf multiple checksums are extracted from the webpage, the verification is considered successful as long as the computed checksum matches any one of them. The webpage is greyed out and a pop-up message is displayed to the user, as illustrated in Figure 2. Additionally, if the checksum originates from the text of the webpage, the matching text with the checksum is revealed (if originally hidden) and highlighted.\n\nThe extension displays a general message to the user and a status indicator (e.g., “downloading”, “computing checksum”) with an animation. Additionally, it can show four different messages according to the result of the verification (Figure 3), depending on the origin of the checksum (webpage text or integrity attribute) and on the outcome of the verification (success or failure). In the case of failure, users are offered the option to delete the possibly corrupted downloaded file (through a link). Clearly, there are multiple ways to communicate the result of the verification to the user, and the UI elements have a significant effect on the usability of our extension [16]. For the initial proof of concept, we experimented with the four messages shown in Figure 3. A careful consideration of alternatives that incorporate user feedback should be conducted before a public release of such an extension. We leave the careful design of the extension UI for future work.\n\nAn archive containing the source code of the extension used in the experiment can be downloaded at the following address: https://checksum-lab.github.io/chrome_extension.zip (SHA-256: 237ac0154e5d951d22f54c97300d3de81a88333c29ec66334c061edb44f2d368). A test webpage can also be found at the following address: https://checksum-lab.github.io/. It contains test download links with and without (correct/incorrect) integrity attributes and links to the download pages (that include checksums) of popular software (e.g., Android Studio, Plex, VLC) on which the extension can be successfully tested. Alternatively, a demo video can be downloaded or watched at the following address: https://checksum-lab.github.io/demo.mp4.\n\nPerformance Evaluation. In order to assess the delays induced by the verification of the checksums, we measured the computation times for different hash functions (namely, MD5, SHA-1, and SHA-2 with 256 bits), based on the implementation of the libraries used in the Chrome extension, and for different file sizes ranging from 45 MB (corresponding to VLC's app file) to 1.6 GB (corresponding to Ubuntu's ISO image file). For each hash function and file size, we performed 20 independent runs and we measured the mean and the standard deviation of the computation time. The results were obtained in a standard setting (MacBook Pro 2014, SSD, 16 GB of RAM, Core i7@2.2GHz, macOS 10.12.6, Chrome v.65 64-bit). They are shown in Figure 4. It can be observed that the computation time is reasonable. It takes less than one second to verify the checksum for small files ($\\lt$50 MB), and only about ten seconds for large files ($\\sim$1 GB). Note that we also compared the computation times for the extension against those for native programs (e.g., shasum) and find them to be comparable. Unsurprisingly, we find that the computation time grows linearly with the file size. The corresponding rates, obtained through a linear regression, are 121 MB/s (MD5), 120 MB/s (SHA-1), and 115 MB/s (SHA-2 with 256 bits). The verification throughput is much higher than those of most broadband connections; the verification time is therefore negligible compared to the download time for most users. To improve the performance, one can combine any of the following techniques: optimizing the library, optimizing the browser's JavaScript engine, using native libraries (e.g., SubtleCrypto), computing the checksum as the file is downloaded (i.e., pipelining).\n\nShortcomings and Perspectives. There are several limitations and missing features that we intend to address in the future. First, the UI and the textual messages of the browser extension should be carefully designed by taking into account user feedback (see Section 5.4) and best practices for the design of security warnings (see, for instance, [14], [15], [16], [17], [18], [21], [23], [40], [41], and [42]). Second, the extension does not handle the case of concurrent downloads from the same tab (e.g., multiple downloads from the same webpage). Third, the extension works only when the checksum and the direct link to the file are on the same page; for instance, the case where a download link redirects to a page with an automatic download based on a meta or iframe element is not supported. Similarly, it does not support the case where the checksums are in a separate file (e.g., .md5, .shasum, .sig) linked on the download page.\n\n5.4 Results\n\nWe describe and analyze the results related to the manual checksum verification (first phase) and report on the usability and effectiveness of the browser extension (second phase).\n\nIn order to study the gaze behavior, in our analysis, we surrounded the parts of the UI that displayed the checksums, and we labeled each area of interest (AOI). Unfortunately, we had to remove eye-tracking recording for one participant due to corrupted data.\n\n5.4.1 RQ1. From a qualitative analysis of the fixation heatmaps of the participants looking at the AOIs that contained the checksums, we could observe three distinct behaviors: (a) some participants produced extensive fixations throughout the sequence of characters (i.e., the checksum) covering most/all of the sequence; (b) other participants produced fewer fixations but still “sampled” the sequence at several points from beginning to end; (c) finally some other participants produced fewer fixations in the AOIs, typically pointing to the beginning and the end of the sequence. Examples of these three behaviors can be seen in Figure 6. While the first two behaviors typically led to identifying the incorrect checksum, the third was typically associated with not identifying the incorrect checksums. This was confirmed by our quantitative analysis presented below.\n\nTo understand whether all the digits of the checksum were treated equally by the participants, we further subdivided the area where the checksum is displayed in four sub-AOIs, both in the terminal and in the webpage (see Figure 7), and measured differences of the total number of fixations falling in each of these areas. As the assumptions for parametric inferential statistics were violated, we used nonparametric statistics for the subsequent quantitative analysis.\n\nWe conducted a Friedman test of differences among repeated measures to compare the total number of fixations that fell in each of the four sub-AOIs of the checksum displayed in the terminal. There was a significant difference in the scores: Term 1 - M = 25.15, SD = 13.11; Term 2 - M = 21.92, SD = 13.96; Term 3 - M = 13.92, SD = 9.55; and Term 4 - M = 10.58, SD = 6.99; $ \\chi$ $^2$(3) = 77.32, $p \\lt 0.001$. Six Wilcoxon signed rank tests with continuity correction were conducted to make post-hoc comparisons between AOIs. All the tests indicated that there was a significant difference between the number of fixations falling in each terminal AOI. We include the detailed results of the tests and the boxplot of the distribution of fixations for each terminal AOI, in Figure 8 and Table 1. These results suggest that the attention given to the digits of the checksum is highest at the beginning and decreases as we progress in the sequence. This means that a partial pre-image attack should focus on keeping the first digits of the checksum unchanged.\n\nAOIs (Term.) 1 2 3 4 1 $-$ $445^{**}$ $756^{***}$ $773^{***}$ 2 $-$ $-$ $709^{***}$ $688^{***}$ 3 $-$ $-$ $-$ $518^{***}$ 4 $-$ $-$ $-$ $-$\n\n5.4.2 RQ2. We observed that 15 (38%) of the participants did not detect the mismatch (for Transmission) between the checksum displayed on the download webpage and the checksum computed from the downloaded file (displayed in the terminal). This constitutes a substantial proportion of our subject pool. This number could be higher in real life as the subjects are likely to be more careful in a controlled environment compared to a situation where they are eager to run the program they just downloaded. Furthermore, we explicitly asked the subjects (in the instructions) to verify if the checksums on the webpage and in the terminal were identical. We did not find a significant difference in the detection rate for participants who had prior checksum knowledge ($p=1$, Fisher's exact test). We hypothesize that participants with prior knowledge understand better the importance and functioning of checksums but, at the same time, they might be more sloppy in their verification as they know that an accidental modification would very likely change the first digits of the checksum. The same result was observed for the previous results on RQ1.\n\nTo study more quantitatively if some behavioral differences existed between those who detected the mismatch and those who did not, we operated a post-hoc split of the participants. We focused our analysis on the terminal window. Figure 8 shows the distribution of the number of fixations and dwell time, for each of the four sub-AOIs in the terminal, across the participants who detected the mismatch and those who did not. A Wilcoxon rank sum test was conducted to compare the total number of fixations in the AOIs for the two groups of participants. The values of the task with the incorrect checksum were not considered in order to compare the usual behavior. There was a significant difference in the number of fixations for participants who detected the corrupted checksum (M = 12.47 fixations, SD = 5.01) and those who did not (M = 3.88 fixations, SD = 2.09); W = 338.5, $p\\lt 0.001$. Furthermore, the same test was conducted to compare total dwell time in the AOIs for the two groups. There was a significant difference in the amount of time spent in the checksum AOIs for participants who detected the corrupted checksum (M = 15.63 seconds, SD = 9.50) and those who did not (M = 3.97 seconds, SD = 2.60); W = 333, $p\\lt 0.001$.\n\nThese results suggest that participants who detected the corrupted checksum fixated the checksums significantly more frequently and spent significantly more time than those who did not. The observed ratios between the two behaviors were approximately 4:1. This analysis was also extended to tasks 1, 2, and 4 for the two groups of participants. We observed the same difference as for Task 3; this reveals that those who were thorough were consistently so, during the entire experiment.\n\nTo better understand how users conduct the checksum verification process, we extracted and analyzed the gaze movements between the sub-AOIs of both the checksum displayed in the terminal and the checksum displayed in the webpage; as the verification process consists in making sure that these two alphanumeric strings are identical, the participant had to look alternatively at the checksum in the terminal and at the checksum in the webpage. This is due to the fact that people can only hold so much information in their working memory. To perform this analysis, we relied on the same sub-AOIs as before (see Figure 7) and computed the number of transitions, with respect to participants fixations. We define as a transition one or multiple fixations in one of the AOIs followed by one or multiple fixations in a different AOI. All fixations outside of the AOIs were ignored: If a participant fixates in Term 1, then somewhere else on the screen, and finally in Web 1, this counts as a transition from Term 1 to Web 1.\n\nWe look at the transitions between the different AOIs. Figure 9 depicts the matrices of transition between AOIs for the tasks with a correct/incorrect checksums (top/bottom) and for the participants who detected/did not detect (left/right) the mismatch for Transmission. A first general finding is that participants start by looking at a chunk of the checksum in one window (terminal or webpage) and then check by looking at the corresponding chunk in the other window (diagonal in the top-right and bottom-left quadrants of the transition matrices, e.g., “Term $i$ $\\leftrightarrow$ Web $i$” transitions). Note, however, that some participants look at multiple chunks of the checksum successively in the same window (sub-diagonal in the top-left and bottom-right quadrants, e.g., “Term $i$ $\\rightarrow$ Term $i+1$” transitions). It can also be observed that the participants who did not detect the mismatch stopped the verification process in the first parts of the checksums; this confirms our previous analysis. In the case where the checksum is incorrect (right sub-figures, i.e., Transmission), the behavior of the participants who did not detect the mismatch does not change substantially; there is no substantial difference between Figure 9(b) and Figure 9(d). For the participants who did detect the mismatch, however, the difference is substantial: Indeed the participants’ fixations gravitate around the first two AOIs (the mismatch started at the end of AOI 1) with many transitions between these two.\n\nWe further look at the distribution of the number of back-and-forth transitions (i.e., transitions from one window to another and back to the original window) between the AOIs in the terminal and those in the webpage across participants, as depicted in Figure 10 (cumulative distribution function). This metric reflects the cognitive load of the participants. It can be observed that the number of back-and-forth transitions is substantial, with a median number of around 10 and a maximum of 26 for the participants who thoroughly checked the checksums (i.e., those who detected the mismatch for Transmission); this number is substantially lower for those who did not. Therefore, we can observe that identifying the mistake required more effort (and time). While participants who successfully identified the mismatch were thorough in checking the entire sequence of characters and numbers, those who did not identify the mismatch stopped right after the first few characters, perhaps thinking that if the beginning of the sequence matched so must the rest of it.\n\n5.4.3 RQ3. We now report the results of our user experiment related to the browser extension carried out in the second phase. As explained in Section 5, in order to study user reaction to the messages displayed by the extension and to collect user feedback, in the second phase of our user experiment, we asked the subjects to activate the extension and to download two programs (RealVNC and Audacity) from the corresponding official websites. The checksum of the second download (Audacity) was incorrect.\n\nDuring the experiment, 40% of the participants stopped when shown the warning message for the (corrupted) Audacity download. For those who did not, the reason they reported most frequently (in the exit survey) was that they tend to ignore popups shown on webpage systematically because they are too frequent and often irrelevant or even scams. Among the participants who did stop, 50% removed the download file: 37.5% of them clicked on the dedicated “delete” link embedded in the warning message and the remaining 62.5% manually removed the file.\n\nIn order to further analyze the participants’ interaction with the popup window of the browser extension, we measured the participants’ total dwell time on the popup; the cumulative distribution function across the participants is depicted in Figure 11. As expected, the median dwell time is higher for the incorrect checksum than for the correct ones. This could be explained by the fact that the participants tend to devote more time/attention to warnings (identified in many system-conventions with the orange warning icon). Surprisingly, in some cases the dwell time is lower for the warning (i.e., for the incorrect checksum); this could be explained by an habituation effect, as the incorrect checksum was always shown after the correct one in our experiment (as described in Section 5.3).\n\nWe further defined sub-AOIs in the extension popup window (see Figure 12) and we measured the breakdown of the dwell time across them. The boxplot representations of the distributions of dwell time are depicted in Figure 13. It is interesting to notice that participants did spend more time on the status text, particularly when the error message was displayed. This indicates that the design was effective in capturing the participants’ attention on the component that offered informative content to understand the status and behavior of the plugin.\n\nIn the exit survey, the participants reported an average satisfaction score of 5.2 $\\pm$1.4 (on a scale from 1 to 7). Furthermore, the participants reported an average desirability score of 4.6 $\\pm$1.9 (“Should the extension be available for download, how likely would you be to use it?”), with 55% of the participants answering positively, and an average net promoter score of 4.5 $\\pm$1.9 (“How likely would you be to recommend it to a friend or relative?”), with 55% of the participants answering positively. In these questions, the comparison was implicit to the status-quo offered by the command-line interface that the participants tested in the first phase.\n\nAnother observation from the user experiment was that 26/40 participants (65%) could not explain the goal of integrity verification in the exit questionnaire (before the debriefing). This reveals the inability of non-technical users to grasp the concept behind checksum-based integrity verification. This was confirmed by the following remark made by one participant: “Sur mon ordinateur personnel, j'aurai quand meme téléchargé le fichier car l'antivirus de l'ordinateur ne m'a prévenu d'aucune menace et le site web à partir du quel j'ai téléchargé le fichier me semblait fiable (On my personal computer, I would have downloaded the file anyway as the antivirus on the computer did not notify me about any threat and the website from which I downloaded the file seemed trustworthy).” This remark also highlights a clear misunderstanding regarding the location of a website's subresources.\n\nFinally, the participants gave us feedback on the messages displayed by the browser extension. The main comments were the following: The terminology used in the message was too technical or unclear (7 participants): “Plutôt sobre je trouve bien mais pour un neophyte, il n'est pas très clair par rapport à son rôle. (It is rather sober I think but for a newbie it is not clear enough in relation to its role)”; the popup did not sufficiently catch their attention (4 participants)–they suggested using larger icons and using colors for the text messages themselves or even to remove the icons–: “Sans le petit logo vert, qui fait penser à celui d'un antivirus, c'est personnellement le genre de message auquel je fais très rarement attention. (The little green logo, which makes me think about an antivirus, should be removed as it is the kind of message that I would rarely pay attention to.)”; the design of the skip button allowed participants to easily skip it (2 participants): “Pour éviter que le message ne soit fermé tout de suite, il faudrait peut-être bloquer le reste de la navigation tant que le message n'est pas fermé. Ou le laisser ouvert obligatoirement pendant quelques secondes. (To prevent the user from immediately dismissing the message the message, it would be necessary to block the user from pursuing navigation until the message is closed. Or to force the message to remain open for a few seconds).”. Interestingly, during the informal feedback with the experimenter, several participants reported that they are, in general, annoyed by popups displayed within webpages and tend to ignore them. Also, they mentioned that a warning originating directly from the browser in a standalone window would have been more effective. Finally, one participant reported that “[L'avertissement] est clair et bien expliqué, peut-être qu'un message plus ‘effrayant’ inciterait plus l'utilisateur à supprimer le fichier ([The warning] is clear and well explained, maybe a more ‘frightening’ message would push the user more to delete the file)”.\n\nDuring the experiment, we also received positive feedback on the extension. Several participants commented positively that the design of the message and the terms used were clear: “Le message est assez clair et explique bien pourquoi le fichier devrait être supprimé (The message is rather clear and it explains well why the file has to be deleted)”, “Ce message apparaît de manière assez claire dans la page, donc cela permet à l'utilisateur d’être au courant sur ce qu'il télécharge. (This message appears in a clear way on the page. This allows the user to be aware of what she is downloading.)”. Interestingly, one participant stated: “[L'avertissement] est également assez clair, j'y aurais fait attention hors du cadre de l'expérience. ([The warning] is rather clear, I would have paid attention to it outside of the context of the experiment)”. This suggests that the browser extension would be useful in practice. The study helped identify several areas for improvement of the design, namely around the behavior of the extension and the messages displayed to encourage the users to delete the downloaded file in case of mismatch. We took some the aforementioned comments into account and refined the browser extension for the follow-up experiment described in Section 6.\n\n5.4.4 Limitations. Like any lab study, the experiment suffered from low ecological validity. Also, the prescriptiveness of the sequence of tasks that we gave to participants reduced the ability to observe participants’ spontaneous behavior when downloading files. Furthermore, we might have introduced a learning bias by choosing not to randomize the presentation of the first and the second part of the study, and the correct vs. incorrect checksums within each part. Finally, the participants of the lab study were all university students and many were technically literate as reported in Section 5.1. Hence, we might expect a smaller share of users to understand and use checksums in the general population than the share identified in the presented results.\n\n5.4.5 Data Availability. The eye-tracking data is available online. The dataset is a 40 GB Tobii Pro Studio (version 3.4.8) archive in the .nas format. The archive includes all the screen recordings; the sound and the webcam streams are not included for privacy reasons. The archive is shipped with a spreadsheet that contains the anonymized responses to the screener and exit questionnaires and the notes taken by the experimenter. The IDs in the spreadsheet corresponds to the participant number and recording number in the Tobii dataset.\n\n6.1 Methodology\n\nIn order to capture data on how users behaved when facing a download with checksum information and how they reacted to the extension warnings, we followed a refined Experience Sampling Method (rESM) [46]. Experience Sampling involves asking participants to report on their experiences at specific points throughout the day. The method is regularly applied in studies of Human-Computer Interaction [47, 48, 49]. A typical drawback of the method is that it could be considered invasive by participants if they are sampled at random times. This is why, in recent years, researchers have proposed to refine the method by modeling the participants’ context [46, 50]. The goal of these questionnaires was to: (a) collect data on whether people noticed checksums on webpages; (b) whether they understood how to use the checksums (i.e., how checksums work); (c) whether they were going to compute and verify the checksums or take other security precautions such as scanning the file for viruses; (d) record self-reported measure of security of their system. The questions of the rESM are available (in French) in Figure 14.\n\nThese questionnaires were presented to the participants of the study only if any one of the following criteria were met: (a) the participant triggered a download from a webpage that does not contain a checksum; (b) the automated verification of a checksum succeeded; (c) the automated verification of a checksum failed; or (d) the participant encountered a checksum but did not download any file from the webpage. In the situation (a), (b), or (c), the rESM questionnaire was displayed immediately after the completion of either the download or the verification. A fixed delay of 2 seconds was added after the page was loaded (i.e., JavaScript load event), before presenting the questionnaire following trigger (d). This means that the checksum was visible on the page for a few seconds before the questionnaire was shown. In order not to overload the participants, we also established that the mini-questionnaires should not be triggered more than once per day on the same participant, per type of event.\n\nGiven that the extension was designed to alter the natural online browsing behavior by making users more careful with regard to downloads, we included in the experimental design a control group. In the control condition, the extension would be collecting data but not intervening during downloads. Each participant was randomly assigned (with probability 1/2) to one of two groups. The control group did not have the checksum verification result in the user interface (see Figure 15). The experimental group had, based on the user feedback collected in the in-situ experiment, a revised messages and layout of the verification result popup (see Figure 15). Adapted questionnaire messages were displayed when a verification was made. For both groups, the data collection of the browsing and download history was activated. Both groups received the rESM questionnaires when the specific browsing conditions were met.\n\nFinally, as we foresaw a small occurrences of downloads for which participants might incur into a checksum, we designed an exit activity that participants had to complete before collecting their financial incentive for the experiment. We designed a webpage with links to two apps they had to install on their computers. The webpage contained checksum so that it triggered our browser extension. For one app, the checksum was correct, while for the other app, it was incorrect; the ordering of the apps (correct/incorrect) was randomized to avoid presentation biases. This was intentionally designed to trigger downloads with valid checksums and downloads which could have been potentially tampered, and analyze reactions.\n\n6.1.1 Apparatus. In order to capture the browsing and download behavior of the users and the answers of the rESM questionnaires, we developed a system consisting of two parts: a browser extension—to be installed in the participants’ browsers—and a web server that communicated with the extension.\n\nChrome Extension. For this experiment, we adapted the browser extension that we initially used in the lab experiment (see Section 4.2). We added the following new functionalities:\n\nIt captured and stored all browsing and download activities of the user. This consisted of the visited/downloaded URL, the timestamp, and the unique ID assigned to each participant during the installation process. This data was stored on the local machine and regularly uploaded to our servers.\n\nIt presented participants with the short aforementioned questionnaire. From a UI perspective, the questions were also displayed in popup windows with the question at the top and the answer options (or text field) right below.\n\nIn addition to these two functionalities, we updated the text of the popup messages according to the feedback we received during the lab study. Particularly, we changed the mechanism by which users were informed about non-matching checksums: while in the lab study we only displayed a warning message, for this experiment, the extension was deleting the potentially dangerous downloaded file and displaying a warning message. Basically, while for the lab experiment the participant could easily ignore the popup, in the field deployment we took a safer approach for which the user was actually required to read the warning and to explicitly click on a link if they wanted to bypass the verification.\n\nThe code of the revised browser extension was structured and implemented using the Google developers guidelines and the Chrome extension APIs. The extension had three main functions. Checksum verification are usually proposed for files that can be executed on the computer. However, according to our adversary model, any file hosted on a different server can benefit from an integrity verification (i.e., Microsoft Office or PDF documents [CVE-2017-0199], [51]). To collect relevant information, the extension monitored the Chrome download manager and sent back all information available in the downloadItem object (Object available through the Chrome Extension API).\n\nServer. We set-up a Django web server with which the browser extension synchronizes. Additionally, the server contained a page with a step-by-step setup guide to install the extension and a dashboard for the researchers to monitor the progress of the study. Finally, the same server hosted the page we used for the exit task, where we asked participants to download two apps, one for which the checksum was correct and the other for which the checksum was (purposely made) incorrect.\n\n6.2 Participants\n\nTo take part in the 4-month long study, a total of 349 potential participants enrolled online for the experiment and were assessed for eligibility. These individuals volunteered to be part of a subject pool (consisting of approximately 8,000 subjects, most of whom were students) for behavioral experiments at the University of Lausanne (UNIL). A specialized unit at our institution, called Labex , managed the subject pool, took care of the randomization and enrollment processes, automated the transfers of financial incentives, and kept secure the contact information of the participants of the study. We collected demographic data through a short survey that also served to check eligibility for the study (i.e., a screener). The questionnaire verified the browser type used and only allowed Chrome users on desktop or laptop computer to continue. We also required the user to be at least once a week on their computer to join the experiment. If they corresponded to this profile, they were asked additional demographic questions and invited to participate. The main reason why potential participants were refused is that they only attempted to fill the screener from a mobile device and did not start the questionnaire again from Chrome on their computers. At the end of the screening process, a total of 152 people were selected to participate in the experiment. However, during the study, 18 participants dropped out (11.8% attrition rate), thus leaving us with a total of 134 that left the browser extension active for the 4 months of the study. Out of the 134 participants who completed the study, 57% (or 76) were female. The age distribution was as follows: 84% (113) were aged between 18 and 23, 15% (20) were between 24 and 30, and 1% (1) were over 30. We extracted the OS used from the user-agent string of the participant. About half of the participants were macOS users (45% or 60) and the other half Windows users (55%, or 74). A majority of users were from the Université de Lausanne (UNIL) (57%, or 77), the second group was from Ecole Polytechnique Fédérale de Lausanne (EPFL) (33%, or 44) and the last 10% (13) came from different schools in the French-speaking regions of Switzerland. A total of 134 participants remained active throughout the whole 4 months of the study. Concerning the two groups of the study, 44% of the participants (59) were assigned to the experimental group and 56% (75) to the control group. The results in the remainder of this section refer to the participants who remained active. However, concerning the last part of the study, only 117 participants completed the exit task. Therefore, when we will describe this part of the experiment, the statistics refer to only the participants who completed this last activity.\n\n6.2.1 Procedure. The screening process and the experiment were conducted in French. Registered subjects on the Labex panel received an e-mail invitation to fill out the online screener. The first page of the screener contained a description of the study and a checkbox where participants could provide their informed consent. The consent form also described the goal of the study (i.e., an observation of the browsing and download behavior), the condition of participation, the data being collected (and the associated data management plan), the procedure to withdraw from the study, and information about the financial incentive. In addition to selecting the right participants, the screener questionnaire was used to set up participants for the study. At the end of the survey —and only for qualifying respondents—a request was made to our server to be assigned a participant ID. The server created a new ID in the users table and returned that to the survey platform that stored the ID together with the other responses of the screener. This process was used to separate the personal identifiable information of the participants (or PII) from the collected dataset. Also, this process would assign each new participant at random to the experimental or the control group.\n\nOnce the survey platform received the ID, the participant was automatically redirected to the extension installation instruction page. The page contained a link to the extension on the Chrome webstore and step-by-step guide on how to complete the setup. Participants also received the same information via email. The page also provided information on how to pause the data collection of the extension, if the user wished to do so (e.g., for a browsing session that they might have wanted to exclude from the data collection). Participants were also instructed to contact us via email if they wished to delete a browsing session that had been already captured. On startup, the extension verified two conditions. The first one was checking that the user ID existed in the database. This variable was saved using synchronized storage from the Chrome API. In the event that the participant would start using Chrome on another computer and would log in his Google account, the extension would be installed on the new computer and the participant ID would be automatically added. This user ID also determines if users would see the download verification messages. If no ID was registered in the storage, the extension would use a JavaScript prompt to ask the user to enter their ID (communicated by email and available on their installation page). We chose to use a JavaScript prompt because it is an intrusive way of communication and we did not want a participant to start a browsing session without being identified. The second check was to ensure that the extension would be able to access the downloaded files in order to verify checksums. We used a less intrusive way than the prompt to communicate this setup process to the user. If the URL file access was not allowed, the extension would open a page where it explains how to grant this permission to the extension.\n\nOnce the extension was correctly installed on the participant's computer, the only situation in which a user would interact with the extension would be either during a verified download (for the experimental group) or when an rESM questionnaire was triggered (for both groups) (see Section 6.1).\n\nThe participants were required to keep the extension installed on their main computer for a duration of 4 months. During this time, we monitored the server health. A secondary server was tasked to contact our server every minute to ensure availability. Also, every day at 12 pm, the main server sent an email to our team containing the last 24h graphs about CPU, memory, and disk usage. The mail also included the IDs of participants who did not sent any data to the server for the last 5 days. When faced with such inactive participants, we contacted them by mail to ensure that they were still using the plugin on their personal computer. During the 4 months of the study, we contacted a total of 77 participants. Of these, 59 reactivated their extension and continued the study while 18 participants dropped out of the study (11.8% attrition rate). The feedback we received from the inactive participants to explain their inactivity—when we contacted them —was very diverse. The most common reason was that they were taking a few days off their computer, using only their smartphone/tablet instead for browsing the Web. The other reasons included not having Chrome set as their default browser, the use of a secondary computer (e.g., a desktop for gaming), or even the purchase of a new computer.\n\nAt the end of the 4-month-long experiment, we asked participants to complete a final task. They received instructions to visit one page located on our server. The page contained instructions to download and install two apps on their computers. Once installed, they had to enter their participant ID. This allowed us to collect feedback on the extension UI and see if they proceeded to install the app with the incorrect checksum. Participants received CHF 20 ($\\sim$USD 20) for their participation in the experiment. In addition, all participants took part in a raffle of four prizes of CHF 100 at the end of the study.\n\n6.2.2 Measures. In order to answer our research questions, we relied on a combination of objective observations (logged by the browser extension) and self-reported data (collected through the rESM surveys). To address RQ4 and RQ5, for every webpage visited by a participant, the extension sent back a summary of the webpage to our server (i.e., a sanitized URL). On our server, we collected metadata about the subject (IP address of the participant, user-agent string, time of visit, and participant ID) and also, the fully qualified domain name (FQDN) of the page visited. It was the extension which took care of transforming the full URL into FQDN; for example, it transformed “https://www.google.com/search?q=cat” into “www.google.com”. We did this transformation to avoid the collection of password or security token encoded in the URL. However, if a webpage visited would contain a checksum or a hashing algorithm name, the full URL and the related checksums information were saved on our server. We chose to keep the full URL so we could inspect the webpages that are false positive and refine our checksum selection criteria. The data was accessible only to the researchers of this study and will be deleted after the publication of the results, at the latest, one year after the end of the experiment. We mentioned these points when collecting consent from the participants at the beginning of the experiment (the participants had to sign a consent form).\n\nIn terms of self-reported data for RQ6, as the extension detected a checksum, the digest on the page was highlighted and the following two questions presented to the participant (see top questions of Figure 14):\n\n“Avez-vous remarqué cette séquence de lettres et de chiffres [checksum] sur la page ?” (Did you notice this sequence of letters and numbers on the page: [checksum string]? [Yes/No/Not sure]);\n\n“A votre avis, à quoi sert cette séquence de lettres et de chiffres ?” (What do you think this sequence of letters and numbers is used for? [free text]).\n\nAs explained in Section 6.1, in order not to overload the participants, we triggered these mini-questionnaires at most once per day, per type of event, per participant.\n\nIn terms of the objective data we stored concerning the downloaded files, the three main pieces of data that were relevant for RQ6 were (1) the MIME type (e.g., application/pdf for PDF documents) of the downloaded file, (2) the address that initiated the download (i.e., the page on which the user clicked to trigger the download), and (3) the address that the download was being made from after all redirects (i.e., the address from where the data was downloaded). The MIME type is a data format identifier that allows us to know if the downloaded file is potentially able to make modifications on the computer, thus of interest for an attacker. The association of the address that initiated the download and of the address that served the download allows us to determine whether the downloaded file is stored on an external server or not. Note that this is a simple heuristic: we compare the domain name of the server that served the webpage from where the download was triggered with the domain name of the server that served the downloaded file. If they are different, then we consider the download as happening on an external server. The extension was unable to monitor what would happen to the file once the download was complete. Therefore, we had to rely on the rESM survey to capture whether the participant was going to process the downloaded file before executing it (see bottom-left question of Figure 14).\n\nLastly for RQ7, we were interested in comparing the self-reported security of the computer between the control and the experimental group. For this reason, after each download (with or without checksum), we asked all participants to rate on a 7-level scale from “Not secure” to “Very secure” the level of security of their computer (see bottom-right question of Figure 14).\n\n6.2.3 Statistical Analysis. Nonparametric analysis was applied to the data considering the ordinal nature of some of the observed variables. Hence, differences between security valuation across experimental conditions were tested suing the Kruskal-Wallis test (see RQ7 below). The level of significance was taken as $p\\lt .05$.\n\n6.3 Results and Analysis\n\n(RQ4) How often do users download files from the Web and what types of files do they download? During the 4 months of observation, the participants of the study visited a total of 657,608 webpages. On average, each participant visited around 50.6 webpages every day. During the study, participants downloaded a total of 17,400 files from the Web. On average, each participant downloaded about 130 files, that is around 33 downloads each month. Table 2 presents the breakdown of the different MIME types of the files downloaded by the participants of the study during the experiment. We noticed that 7.7% of these files are executable (i.e., octet-stream, binary), and 3.7% are compressed archives, hence files that could potentially carry malicious code. Additionally, the large majority (55.6%) of the downloads are PDFs and office documents that could also be injected with corrupted macros or other harmful code. During the study, a total of 17 executable downloads contained a checksum on the page that was verified by the browser extension. For 6 of the 17 downloads, the participants that originated the download was in the experiment group; hence, the browser extension presented popup messages about the verification to the users. A large proportion of the downloaded files came from email attachments accessed via a webmail. The modest number of executable files downloaded can be explained by the fact that users download the bulk of the programs they need when they set up their computers and only a few, sporadically, after that.\n\nMIME type num. prop. [%] application/pdf 9,677 55.61 image/jpeg 1,988 11.43 application/octet-stream 1,151 6.61 application/vnd.openxmlformats-officedocument.wordprocessingml... 883 5.07 application/zip 648 3.72 audio/mpeg 284 1.63 application/vnd.openxmlformats-officedocument.presentationml... 221 1.27 image/png 210 1.21 text/plain 194 1.11 application/vnd.openxmlformats-officedocument.spreadsheetml... 182 1.05 application/msword 174 1.00 text/html 136 0.78 binary/octet-stream 106 0.61 video/mp4 100 0.57 image/gif 99 0.57 application/x-msdownload 93 0.53 application/x-bittorrent 92 0.53 application/binary 88 0.51 application/vnd.ms-powerpoint 88 0.51 application/force-download 57 0.33\n\n(RQ5) What is the prevalence and the current practices of checksums included in download webpages? Of the 17,400 downloads recorded in the final dataset, 4,853 files (or 27.9%) were hosted on a server that had a distinct domain name from the server that served the webpage of the site. This shows that about a third of the downloaded files we recorded in this study could potentially be compromised following the threat model described in this article. Similarly, we found that 923 downloads (or 5.3%) originated from a server that was not configured with HTTPS, hence allowing potential attackers to modify the files while being transferred to the machine requesting the download. Out of the 657,608 webpages visited by the participants during the study, only 153 pages (or 0.02%) contained a checksum string, and of the 17,400 downloads events in the final dataset, 37 originated from one of these webpages. We manually inspected these webpages and classified them into four categories: (i) 70 (or 45.7%) webpages linked executable files and references the name of the algorithm used to generate the checksum (i.e., SHA-256, MD5); (ii) 43 (or 28.1%) were false positives (i.e., webpages that contained alphanumeric strings that matched our regular expression but that were not checksums); (iii) 29 (or 19%) webpages linked torrent files (we will discuss this case below); and (iv) 11 (or 7.2%) webpages contained true checksums but the connected file was not an executable, hence the extension did not verify the integrity. For instance, Zenodo provides checksums for PDFs, and Digicert for security certificates. Concerning the webpages with checksum that linked torrent files, in these cases the participants visited a webpage that contained checksum information about one or multiple files seeded through the peer-to-peer network. In addition, these webpages also contained a .torrent file that could be downloaded from the webpage that contains metadata about files and folders to be distributed, and usually also a list of trackers, which are computers that help users of the system find each other. When participants of our experiment downloaded torrent files from these webpages, the extension was triggered, however it could not possibly verify the checksum as the file being downloaded from the browser (i.e., the .torrent file) was not the one the checksum information on the webpage referred to.\n\nOf the 7.7% of downloads involving executable files (plus the 3.7% of downloads involving archives), 17 downloads were downloaded from a webpage containing both the checksum and the name of the algorithm used. These were all executable files (i.e., .exe, .dmg, or .pkg) or archives (i.e., .zip). Finally, it is worth reporting that all of the checksums reported on the webpages we identified in the study matched the linked resources. Table 3 reports the details of the resources with a valid checksum that our participants downloaded during the study.\n\n(RQ6) What do Internet users most frequently do when they encounter a visible checksum? Out of the 153 events in which participants opened a webpage that contained a checksum and were prompted with a rESM questionnaire, we collected 35 valid responses. These 153 events were created by only 45 distinct participants. The participant would typically look at multiple pages with checksum under the same FQDN during the same day and thus receive only one questionnaire. To the first question, namely whether they noticed the checksum on the webpage, 28 (or 80%) participants replied that they did not see the checksum, while 3 (or 8.6%) replied that they were not sure, and 4 (or 11.4%) that they had seen the checksum. In sum, 88.6% of respondents did not see or were not sure about whether the checksum was on the webpage. In the follow-up question, we asked the 35 respondents to explain, in their own words, what is the purpose of the sequence of letters and numbers (i.e., the checksum or digest). Unfortunately, only one respondent provided an almost-correct explanation of the purpose of checksums: Elle sert a verifier que mon téléchargement est bien téléchargé car il s'agit de logiciel et le fichier doit être intact (It is used to check that my download is correctly downloaded because it is a software and the file has to be intact) [Business School student]. The rest of the respondents provided answers that were incorrect: e.g., Peut-être un numéro de série ou d'identification pour le programme (Maybe it is a serial number or identification number for the program) [Basic Sciences student].\n\nAfter a download event, we also prompted participants of the study with an rESM questionnaire to understand whether they would do anything with the downloaded file before executing it. A total of 155 responses from 97 distinct participants provided answers to this question during the course of the study. The large majority of the responses (i.e., 124 or 80% of the responses) stated they would directly execute the file. The remaining declared to either scan the file with an antivirus software (i.e., 4 or 2.6% responses) or provided unclear answers (i.e., 26 or 16.8% responses). Only one respondent reported performing a checksum verification on the file: Non, je fais confiance à l’éditeur en l'occurrence. Sinon, je fais un check MD5 (No, I trust the developer. Otherwise, I do a MD5 check) [Criminal Sciences student]. This shows a misconception regarding the trust assumption: Checksums are used in the case where a third-party host is compromised, not the software developer. It is interesting to notice that scanning a corrupted file with an antivirus might not protect entirely from potential threats (e.g., malware with zero-day exploit).\n\nAt the end of the study we asked participants to complete a final task (see Section 6.2.1 above). A total of 117 participants completed this step (while 17 participants dropped out at the very end). Of the remaining participants, 48 (or 41%) were in the experimental condition (i.e., with extension warnings active) and 69 (or 59%) participants were in the control group. During the final tasks, these participants were presented with the download of an app for which an incorrect checksum was provided on the webpage. While almost all participants in the control group installed the “malicious” app (except 4 or 3.4% participants who did not understand the instructions), 12 (or 10.3%) participants of the experimental condition did not complete the install process even if they were instructed to do so. Most of the other people in the experimental condition who forced the download by using the “Download again (dangerous)” button, did so because they trusted our institution: Si j'en crois ce qui a été affiché, ‘il a été corrompu’. Je présume qu'il s'agit cependant du déroulement habituel de l'expérience (If I believe what is displayed, the file is corrupted. I presume this is however the usual course of experience) [Criminal Sciences student]. This difference between the two groups has to be ascribed to the warnings of the browser extension, which made participants more wary of the potential threat.\n\n(RQ7) Would users feel more secure if they could use a system that automates parts of the verification process? On the last screen of the rESM questionnaire, we asked participants to rate the perceived security of their computer using a Likert scale with 7 levels (this goes from 1 = Extremely insecure to 7 = Extremely secure). In the exit task of the study, a total of 117 participants were asked to download and install two applications on their computer, one with a valid and one with an invalid checksum. These participants experienced installing an application that could have been potentially corrupted. To answer our RQ, we compared the security ratings provided by these participants to the rESM question. A Kruskal-Wallis test showed that participants in the experimental group reported higher security ratings (M = 5.0 points, SD = 1.4) for their computer than participants in the control group (M = 4.3 points, SD = 1.7); H(1) = 8.83, p < .05."
    }
}