Philanthropic foundations are interested in tackling the fake news problem — but where do they put their money? When the Hewlett Foundation — the philanthropy founded by the Hewlett family of Hewlett-Packard fame — started looking at how it could get involved after the 2016 presidential election, it found most money was either going “upstream” or “downstream” rather than midstream.

What does that mean? “The vast majority of funders were looking at what I framed as ‘upstream’ efforts to improve the quality of journalism,” Kelly Born, program officer for the foundation’s Madison Initiative, told me — audience engagement efforts, subscription-based revenue models, things like that. “While that is really important work, it won’t solve the specific problem around misinformation, because even when there is great-quality information out there — say, about climate change or vaccines — it either falls on deaf ears because we’ve become so polarized as a society, or it gets lost in a stream of noise.”

Other funders were focused “downstream,” on audience-facing efforts like media literacy and fact-checking. Again, important, but “there’s a long lag time to assess some of those efforts,” Born pointed out. “And they can be hard to scale because you’re trying to change the practices of millions of news consumers.”

The answer for Hewlett: Go for the middle. Hewlett, which has an endowment of $9 billion and paid out $400 million in grants in 2016 (making it more than three times as large as the Knight Foundation), announced Wednesday that it will give $10 million, over two years, to help fund research into the spread of disinformation on social media platforms. The announcement follows Hewlett’s year-long exploration of how philanthropy can mitigate disinformation and propaganda.

“There is much more leverage to intervene here because you’re not trying to change the practices of hundreds of newsrooms or millions of consumers,” Born said. “You’re looking at half a dozen social media platforms.” (And there’s a certain symmetry in a foundation funded by the success of Silicon Valley’s first great company engaging with this generation’s tech giants.)

Hewlett wants to fund research into the firehose of content that’s coming at people, microtargeting, bots, inauthentic conversations — the “wild west of voices.” It plans to fund research in three areas:

— Explanatory research that increases understanding of the current problem, including examining the supply of disinformation, how it spreads across different technology platforms and its effect on people’s political knowledge, beliefs and actions.

— Experimental research that helps examine potential solutions, by testing what actions can reduce disinformation’s negative impact on individuals or how high-quality content can be elevated.

— Ethical, legal, and technical research that examines the practical and philosophical considerations in addressing digital disinformation, including how well norms around privacy and free speech are bearing up in the digital age, the incentives for voluntary regulation, and the role of government including agencies such as the FEC, FTC, FCC, and others.

Conveniently, Hewlett recently released a report summing up all the current research into fake news and the many questions that remain; it also, at the end of 2017, released a report examining the potential role of philanthropy in the fake news space.

Hewlett plans to provide a smaller number of large grants, rather than lots of little grants; some of these are already in process, such as one to NYU’s Social Media and Political Participation initiative; The foundation has also invited more proposals and expects to disburse about $5 million this year and $5 million in 2019 and 2020. Born has immersed herself in academic research, looking out for academics whose work can apply to the real world.

Born said that Hewlett is also broadly interested in making it easier for research to be done in this area by building up research infrastructure that might allow different teams to share some data; the foundation will soon release a report about who’s doing what in the field. Born is also more broadly interested in hosting some sort of secure data repository, held by a consortium, that “white-listed academics” could access but that would not be vulnerable to misuse by bad players (like Cambridge Analytica). Basically, she wants to know: What might induce Facebook to share some of its data?