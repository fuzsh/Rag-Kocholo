{
    "id": "dbpedia_1570_2",
    "rank": 36,
    "data": {
        "url": "https://arxiv.org/html/2403.15857v2",
        "read_more_link": "",
        "language": "en",
        "title": "Automated System-level Testing of Unmanned Aerial Systems",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/extracted/5770304/images/rl.png",
            "https://arxiv.org/html/extracted/5770304/images/ate-app7.png",
            "https://arxiv.org/html/extracted/5770304/images/uav-profile.jpeg",
            "https://arxiv.org/html/extracted/5770304/images/uav-beh-profile-1.png",
            "https://arxiv.org/html/extracted/5770304/images/uav-beh-profile-2.png",
            "https://arxiv.org/html/extracted/5770304/images/uav-dm.png",
            "https://arxiv.org/html/extracted/5770304/images/uav-fsm.jpeg",
            "https://arxiv.org/html/extracted/5770304/images/uav-tsm.png",
            "https://arxiv.org/html/extracted/5770304/images/uav-states5.png",
            "https://arxiv.org/html/extracted/5770304/images/lstm2.png",
            "https://arxiv.org/html/extracted/5770304/images/asi.png",
            "https://arxiv.org/html/extracted/5770304/images/altimeter.png",
            "https://arxiv.org/html/extracted/5770304/images/tc.png",
            "https://arxiv.org/html/extracted/5770304/images/reward.png",
            "https://arxiv.org/html/x1.png",
            "https://arxiv.org/html/x2.png",
            "https://arxiv.org/html/x3.png",
            "https://arxiv.org/html/x4.png",
            "https://arxiv.org/html/x5.png",
            "https://arxiv.org/html/x6.png",
            "https://arxiv.org/html/x7.png",
            "https://arxiv.org/html/x8.png",
            "https://arxiv.org/html/extracted/5770304/images/testpath.png",
            "https://arxiv.org/html/extracted/5770304/images/tp-script.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "[1]\\fnmHassan \\surSartaj\n\n1]\\orgdivDepartment of Computer Science, \\orgnameNational University of Computer and Emerging Sciences, \\orgaddress\\streetA.K. Brohi Rd., \\cityIslamabad, \\countryPakistan 2]\\orgnameQuest Lab, \\orgaddress\\streetI8-Markaz, \\cityIslamabad, \\countryPakistan\n\nAutomated System-level Testing of Unmanned Aerial Systems\n\n\\fnmAsmar \\surMuqeet \\fnmMuhammad Zohaib \\surIqbal \\fnmMuhammad Uzair \\surKhan\n\nAbstract\n\nUnmanned aerial systems (UAS) rely on various avionics systems that are safety-critical and mission-critical. A major requirement of international safety standards is to perform rigorous system-level testing of avionics software systems. The current industrial practice is to manually create test scenarios, manually/automatically execute these scenarios using simulators, and manually evaluate outcomes. The test scenarios typically consist of setting certain flight or environment conditions and testing the system under test in these settings. The state-of-the-art approaches for this purpose also require manual test scenario development and evaluation. In this paper, we propose a novel approach to automate the system-level testing of the UAS. The proposed approach (namely AITester) utilizes model-based testing and artificial intelligence (AI) techniques to automatically generate, execute, and evaluate various test scenarios. The test scenarios are generated on the fly, i.e., during test execution based on the environmental context at runtime. The approach is supported by a toolset. We empirically evaluated the proposed approach on two core components of UAS, an autopilot system of an unmanned aerial vehicle (UAV) and cockpit display systems (CDS) of the ground control station (GCS). The results show that the AITester effectively generates test scenarios causing deviations from the expected behavior of the UAV autopilot and reveals potential flaws in the GCS-CDS.\n\nkeywords:\n\nArtificial Intelligence, Deep Reinforcement Learning, Unmanned Aerial Systems, UAV, Drones, GCS, Testing Automation\n\n1 Introduction\n\nUnmanned aerial systems (UAS) mainly consist of an unmanned aerial vehicle (UAV) and a ground control station (GCS). A UAV is an aircraft that does not have a human pilot on-board. It is either operated remotely from the ground control station or autonomously using the autopilot system. UAS are becoming progressively important due to their large number of applications in a variety of domains. For example, UAS are used for rescue operations, disaster management, geological surveys, agriculture and farming, weather forecasting, wildlife monitoring, entertainment, surveillance, airstrikes, military combat, and explosive material detection. UAS rely on several avionics software systems (e.g., an autopilot, navigation system, communication system, etc.) that are critical for completing the mission or are critical to safety. Malfunctioning of the UAS avionics software can lead to mission failure that can result in human life and financial loss. To ensure the dependability of such systems, international safety standards such as DO-178C [1] and others [2] define several guidelines. The automated testing of avionics systems is essentially due to the huge amount of cost and effort required to follow these guidelines.\n\nUAS are a special type of cyber-physical systems (CPS) and are also considered context-aware systems. The system-level testing of UAS requires the simulation of the UAV flight behavior with the help of flight simulators. It is typically performed at three levels, (i) software-in-the-loop (SIL) testing, (ii) hardware-in-the-loop (HIL) testing, and (iii) pilot-in-the-loop (PIL) testing also known as field testing. In SIL testing, the actual avionics software runs while simulating the flight hardware and environment. In HIL testing, the original avionics hardware parts are used and the environment is simulated. In PIL testing, the UAS is tested in a real environment. Testing at each level highly depends on the environmental context, i.e., test scenarios created for SIL testing may not be useful for HIL/PIL testing. The main challenge in automating system-level testing of the UAS is the generation and evaluation of environmental context-aware test scenarios.\n\nA traditional method of testing UAS at the system level includes a human tester (pilot) who knows UAV flight behavior and has expertise with UAV flight simulators. The tester is provided with the system under test (SUT) and the specifications of the SUT. Using this information, the tester manually designs test scenarios. For each test scenario, the tester simulates the behavior of a UAV in a particular environment with the help of a flight simulator, and at each flight operation, observes the behavior of the SUT by comparing the expected behavior mentioned in the specifications. Testing this way usually requires several days and only a limited set of potential scenarios can be tested. The existing approaches available in the literature also require manual test scenario development and manual test evaluation (e.g., [3, 4, 5, 6]). The activity of manual testing is tedious and error-prone due to numerous potential scenarios that need to be tested in the extremely dynamic environment of the UAV.\n\nIn this paper, we propose a novel approach to automate the system-level testing of UAS. To automate the manual testing of UAS, a human-level control on a flight simulator and a mechanism to model the SUT specifications are required. Therefore, our approach (namely AITester) utilizes artificial intelligence (AI) and model-based testing (MBT) techniques to automatically generate, execute, and evaluate various test scenarios. We use deep reinforcement learning (an AI technique) to get human-level control on a flight simulator and MBT to model the specifications of SUT. The test scenarios are generated on the fly, i.e., during test execution based on the environmental context at runtime. For this purpose, we propose a UML profile for modeling the structural aspects of UAS SUT and a UML profile for modeling the flight behavior of the UAV. The structural profile is used to model the domain concepts of the UAS SUT and the flight behavior profile is used to model the abstract flight behavior of the UAV. Our approach requires the constraints (written in Object Constraint Language (OCL) [7]) specified on the UAS SUT domain model and state invariants on the flight behavior model. The UAS SUT domain model, the UAV flight behavior model in the form of a UML state machine, and the expected behavior of the SUT in the form of OCL constraints are used as input to our approach. Using the UAV flight behavior information, a deep reinforcement learning algorithm is trained to explore different flight test scenarios while interacting with the environment at runtime. The flight information received from the environment is used to determine the current state of the UAV. This information is also used to populate an instance model of the UAS SUT domain model. The instance model representing the current flight information of the UAS SUT is used to evaluate OCL constraints. The AITester gets rewards based on the correct selection of action and the number of OCL constraints violated based on that action. During the testing process, the AITester continues to explore different flight states, learns to violate OCL constraints (expected behavior of the SUT) based on actions, and compiles the results for further analysis by avionics testers.\n\nWe developed a toolset that implements our proposed approach to support testing automation. We performed two experiments to evaluate AITester using two different subsystems of the UAS. For the first experiment, we used an autopilot of the UAV as a SUT, specifically employing the ArduCopter, a widely-used open-source autopilot system. For the second experiment, we used the cockpit display systems (CDS) of the GCS as the SUT, particularly utilizing an industrial case study of GCS-CDS. For UAV autopilot, the results indicated that AITester effectively generates test scenarios provoking deviations from the expected behavior of the UAV autopilot. For GCS-CDS, the results showed that AITester is effective in finding four different types of faults and in exploring diverse test scenarios. Overall, the results of both experiments demonstrated that AITester effectively generates test scenarios causing deviations from the expected behavior of the SUT that lead to potential faults.\n\nThis paper is an extended version of the research abstract published in the Doctoral Symposium of the 36th IEEE/ACM International Conference on Automated Software Engineering (ASE) [8]. In the conference paper, an initial idea of the proposed approach targeting UAVs and a pilot experiment on UAV autopilot was presented. The primary contributions of this paper relative to the conference paper are summarized below.\n\n•\n\nWe present a comprehensive modeling methodology targeting the whole UAS. This includes UML profiles for modeling the structural and behavioral aspects of a UAS SUT and modeling guidelines for avionics testers. The modeling methodology presented in this paper covers all UAS subsystems, e.g., GCS.\n\n•\n\nWe propose a novel approach (AITester) that utilizes MBT and AI to automatically generate, execute, and evaluate various test scenarios based on the environmental context at runtime.\n\n•\n\nWe developed a toolset that implements our proposed approach to support testing automation and to enable further research and development. The toolset is publicly available at an online repository .\n\n•\n\nWe performed two experiments to evaluate AITester using two different subsystems of the UAS. The first experiment was performed using a UAV autopilot as a SUT, extending the pilot experiment with a new research question. The second experiment was performed using the CDS of GCS as a SUT to evaluate the applicability of the proposed approach to another UAS subsystem.\n\nThe remaining portion of the paper is organized as follows. Section 2 presents the background of unmanned aerial vehicles, model-based testing, reinforcement learning, and deep learning. Section 3 describes our proposed approach in detail. Section 4 provides a discussion on the toolset that implements the proposed approach. Section 5 provides the empirical evaluation of the proposed approach. Section 6 discusses the works related to this paper. Section 7 outlines the limitations of the proposed approach. Finally, Section 8 concludes the paper.\n\n2 Background\n\nThis section presents a concise background discussion on unmanned aerial systems, model-based testing, reinforcement learning, and deep learning.\n\n2.1 Unmanned Aerial Systems (UAS)\n\nUnmanned aerial systems (UAS) primarily consist of an unmanned aerial vehicle (UAV) and ground control station (GCS). A UAV is an aircraft without a human pilot onboard. It is either operated by a remote pilot in the GCS or using an onboard autopilot system. To perform communication between UAV and GCS, a data link layer is used in which the uplink is used to send the command to the UAV, and the downlink is used to receive the flight information from the UAV. UAVs are classified into nine different categories based on their weight, size, operating altitude, range, and endurance [9]. UAV designs include fixed-wing (e.g., plane), single-copter (e.g., helicopter), multi-copter (e.g., quad-copter), and hybrid (e.g., quad-plane). UAVs can carry two types of payloads, (i) dispensable payloads such as medical supplies, food items, or ammunition, and (ii) indispensable payloads such as cameras, sensors, or radars of different kinds. UAVs have a large number of applications in different civil and military domains. In the civil sector, UAVs are used for rescue operations, disaster management, geological surveys, agriculture and farming, weather forecasting, wildlife monitoring, entertainment, etc. UAVs are also used for different military operations such as intelligence, surveillance and reconnaissance (ISR), airstrikes, military combat, and explosive material detection.\n\nA GCS is a ground-based cockpit for monitoring and controlling a UAV. The GCS consists of the cockpit display systems (CDS), a flight control system, a mission planner, a communication channel, a navigation system, 2D/3D maps, and a payload monitoring and control system. The CDS of the GCS provides various types of interfaces with different flight instruments to show the UAV flight information [10]. These user interfaces display different types of information received from the different avionics systems of a UAV during the flight. For example, the navigation system generates information such as latitude, longitude, and altitude using sensors such as gyros, accelerometers, and GPS. This information is necessary for a UAV to accurately determine its current position, next waypoint to follow, and navigate on the planned route. The flight control system is used to generate control and navigational commands for the UAV. The mission planner supports UAV profile management, route planning, path optimization, payload setup, and planning unforeseen situations. The communication channel is responsible for supporting all types of communications between a UAV and a GCS. The navigation system is used to monitor the navigational information (such as latitude, longitude, and altitude) of the UAV. The 2D/3D maps support interactive mission planning, mission execution, and observing the state of the UAV during flight. The payload monitoring and control system helps an operator in observing the status of the payload and in controlling the payload.\n\n2.2 Model-based Testing\n\nModel-based testing (MBT) is a testing technique that uses models of the system under test (SUT) to support automation in various testing activities such as test case generation and test execution. For conventional system testing, where it is possible to construct complete models of expected behavior, MBT provides a comprehensive solution for automated test generation, test execution, and test evaluation [11]. The MBT process generally comprises five steps [12]. In the first step, the abstract models of the SUT are developed based on the requirements or specifications using any modeling language such as Unified Modeling Langauge (UML) [13]. The SUT models capture the system’s functionality in the form of various UML models (diagrams) such as a class diagram, a state machine, and a sequence diagram. Different UML models support the automation of several testing activities. For example, UML state machines support the generation of test sequences [10]. The constraints specified in the requirements are modeled using a constraint specification language, i.e., Object Constraint Language (OCL) [7, 14]. The SUT models developed in UML are augmented with the constraints written in OCL. The second step is to determine the criteria for test case selection. The criteria for selecting test cases can be defined based on requirements (e.g., requirement coverage) or using the models of SUT (e.g., state/transition/transition-pair coverage of the state machine). In the third step, the specifications of test cases are defined based on the criteria for test selection. In the fourth step, the models of SUT (created in the first step) and test case specifications (defined in the third step) are used for generating test cases. In the fifth step, the generated test cases are executed using the test execution platform that is suitable for the SUT. In the end, the test verdict is determined by comparing the test execution output with the SUT expected output. If the expected output matches the test execution output, the verdict is pass and fail otherwise.\n\n2.3 Reinforcement Learning (RL)\n\nReinforcement learning (RL) is an artificial intelligence technique in which an agent learns based on its interaction with the environment. The RL agent, in a particular state, performs some action in the environment. Based on the action, the environment returns the next state and the reward. Therefore, the RL problem can be formulated as a Markov Decision Process (MDP). Fig. 1 shows an MDP in which an agent in a state Stsubscript𝑆𝑡S_{t}italic_S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT with reward Rtsubscript𝑅𝑡R_{t}italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT performs an action Atsubscript𝐴𝑡A_{t}italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT on the environment at time t. Based on the action, the environment returns the next state St+1subscript𝑆𝑡1S_{t+1}italic_S start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT and the reward Rt+1subscript𝑅𝑡1R_{t+1}italic_R start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT. According to the reward received from the environment, the agent learns whether the action was right or wrong. The learning process continues until the agent learns an optimal policy that can maximize the expected reward to explore the environment. RL is used for multiple applications in a variety of different domains [16] such as robotics, transportation, and games. In the context of UAVs, it has been used for various purposes such as for the UAV attitude control [17] and the robust control of the autonomous helicopter [18].\n\n2.4 Deep Learning\n\nIt is an AI technique that simulates a part of the human brain. For this purpose, it uses artificial neural networks (ANNs) inspired by the biological neural networks of the human brain [19]. The ANN can be a single-layer network with only input and output layers. It can be a multi-layer network with an input layer, an output layer, and several hidden layers in the middle. Multi-layer neural networks are also called deep neural networks. There are three commonly used types of ANNs, (i) feed-forward neural network, (ii) convolutional neural network (CNN), and (iii) recurrent neural network (RNN). In a feed-forward neural network, the information from the input layer flows toward the output layer after performing the function approximations in the intermediate levels. The feed-forward neural networks are also known as deep feed-forward networks or multi-layer perceptrons. In RNN, the information from the input layer flows toward the output layer and can be fed back to the neurons in the previous layer. In CNN, the information from the input layer flows toward the output layer by performing different convolution operations in the middle.\n\nLong Short-Term Memory (LSTM). An LSTM network is a variant of RNNs, specifically designed to handle temporal data and capture the state context. It comprises one or more units, each containing input gates, output gates, forget gates, and memory cells. The core purpose of the memory cell is to capture the correlation between the current data at time t with preceding data points, i.e., (t-1)!. This mechanism allows LSTM networks to learn longer sequences, making them especially useful for tasks involving sequential data such as time-series analysis.\n\n3 Approach\n\nIn this section, we discuss the proposed approach for the automated system-level testing of the UAS. The proposed approach is developed based on the idea presented in previous work [8]. First, we give a brief overview of the proposed approach. Second, we describe the modeling methodology including a discussion of the proposed profiles. In the end, we discuss the deep reinforcement learning technique employed in our approach for testing a UAS SUT based on environmental context at runtime.\n\n3.1 Overview of the Approach\n\nFig. 2 shows the overall workflow of the proposed approach. To model the system under test, we propose two UML profiles, the UAS structural profile and the UAV behavioral profile. The avionics tester is required to model the domain of the UAS SUT using the structural profile and the flight behavior of the UAV using the behavioral profile. The approach also requires the expected behavior of UAS SUT in the form of OCL constraints and state invariants. The proposed profiles play an important role in supporting the testing automation of the UAS SUT. The UAS structural profile represents an observation space of the environment. Similarly, the UAV behavioral profile represents the state and action space of the deep reinforcement learning (DRL) algorithm. The UAS SUT domain model serves two purposes, (i) initializing the observation space of the environment, and (ii) generating an instance model that will be used to evaluate the OCL constraints during execution. The flight behavior model of the UAV is used to initialize the DRL algorithm for UAS SUT.\n\nUsing the UAV flight states and actions, the DRL algorithm starts exploring various flight states using different actions (e.g., takeoff or land). The DRL algorithm selects an action and executes it on the environment using DroneKit API. The function of DroneKit is to receive the action command for the UAV, send the command to the UAV using a communication link (using Mavlink), and receive the state of the UAV. The continuous change in the flight state of the UAV is monitored by a state observer. This helps the DRL to keep track of the current state, action, and the next state of the UAV. Moreover, the flight data observed during execution is used to populate an instance model of the UAS SUT domain model. The instance model is evaluated on the OCL constraints and state invariants. The primary objective of our approach is to violate a maximal number of OCL constraints. The reward is calculated based on the correct selection of action and the number of OCL constraints violated based on that action. In this way, the DRL algorithm continues to explore different flight states, learns to violate OCL constraints (expected behavior of the SUT) based on actions, and compiles the results for further analysis by avionics testers. The compiled results include information related to UAV flight states, actions, and the number of failed OCL constraints for each execution.\n\n3.2 Modeling Methodology for UAS\n\nA fundamental step in our approach is the modeling of the UAS SUT. This includes modeling the UAS SUT domain concepts, the flight behavior of a UAV, and constraints on these models. For this purpose, we propose a UAS structural profile for modeling the UAS SUT domain concepts and a UAV behavioral profile for modeling the flight behavior of the UAV. The goal of the proposed profiles is to facilitate avionics testers with the modeling of different aspects of UAS SUT using domain-specific terminologies. The domains-specific modeling languages available in the literature are either generic for all CPS (e.g., [20]) or context-specific [21] (e.g., targeting UAV Swarm [22]). Our proposed profiles are based on UML which is widely adopted by the avionics industry [21]. Moreover, the proposed profiles consist of UAS domain concepts that avionics testers are familiar with. We provide modeling guidelines for avionics testers in the process of modeling a UAV using the proposed profiles and specifying constraints.\n\n3.2.1 UAS Structural Profile\n\nFig. 3 shows the profile to model the structural aspects of the UAS SUT. A key concept of the profile is UAV with properties such as thrust, heading, airspeed, groundspeed, and type. The type of UAV can be a helicopter, multi-copter, fixed-wing, or hybrid UAV. The enumeration UAVType is used to model various types of UAVs. Another important concept is the Attitude that represents pitch, roll, yaw, pitch_speed, roll_speed, yaw_speed, and yaw_rate of the UAV. The location of a UAV can be broadly categorized into LocationLocal and LocationGlobal. The LocationLocal can be represented in degrees using north/south, east/west, and up/down values. Whereas the LocationGlobal can be represented using latitude, longitude, and altitude values. The altitude can be measured above mean sea level (i.e., altitude_MSL) and it can be relative to ground level (i.e., altitude_AGL). The UAV can have a RangeFinder that is used to calculate the distance. The UAV can have Velocity along three axes i.e., vx, vy, and vz. To model different power systems, the profile provides two concepts, Engine and Battery. The Engine has properties such as speed, level, and flow_rate. The Battery has properties such as voltage, current, and level. Besides the above-mentioned concepts, the UAV can also have concepts for modeling different measurement units such as Accelerometer, Gyroscope, Barometer, and Magnetometer.\n\n3.2.2 UAV Behavioral Profile\n\nTo model the flight behavior of the UAV, the behavioral profile has two parts. One for modeling the abstract flight states as shown in Fig. 4. The second part is used for modeling the events that can lead the UAV into various flight states. An excerpt of the behavioral profile for modeling events is shown in Fig. 5.\n\nThe abstract flight states represent various flight stages of the UAV. Initially, the UAV is in a Disarmed state. After arming the motors, the UAV goes to the Armed state. From the Armed state, the UAV can go to the Taxiing or TakeOff state. If the UAV is fixed-wing, it has to start taxi on the ground before it can take off. Whereas the single or multi-copter type of UAV can directly take off from the ground without taxiing. In the case of hybrid UAVs, both states can be used alternatively. After taking off from the ground, the UAV can go through different flight phases such as Climb, Cruise, Descent, PositionHold, and AltitudeHold. The UAV can perform special types of flights such as Flipping, Drifting, Loiter, and Circle. The UAV can fly straight when in FlyingStraight state, it can take a left turn when in TurningLeft state, and it can take a right turn when in TurningRight state. At the end of the flight, first, the UAV goes to the Approach state, and then it goes to the Landing state.\n\nEach abstract flight state is achieved using different events. To arm the motors, the Arm event is used. Similarly, the Disarm is used to disarm the motors. The event Takeoff is used to take off the UAV from the ground and the event Land is used to land the UAV on the ground. The event ReturnToLaunch is used to make the UAV go to the home position (from where it took off) and land at that position. During the flight, UAV can move forward or backward (not in the case of fixed-wing) using the events MoveForward and MoveBackward respectively. Similarly, it can make a left or right turn using the events TurnLeft and TurnRight respectively. In the case of multi-copter or hybrid UAV, the event HoldPosition makes it maintain the current position. The event HoldAltitude is used to maintain a stable altitude. Whereas the events IncreaseAltitude and DecreaseAltitude are used to increase or decrease the altitude respectively. Note that the profile shown in Fig. 5 has only a subset of all the events modeled in the complete profile. The complete profile is available at an online repository .\n\n3.2.3 Modeling Guidelines\n\nTo model the domain of the UAS SUT, all avionics components (e.g., sensors) need to be modeled as a UML stereotyped class with the stereotype from the UAS structural profile. The profile stereotypes contain some common properties of various avionics components. The matching properties need to be used as it is and the additional properties can be added to the domain class. The avionics tester can freely model the associations among the domain classes.\n\nThe flight behavior model of the UAV needs to be modeled using the UML state machine. For this purpose, all flight states and events need to be modeled using the states and events stereotypes from the UAV behavioral profile. The avionics tester is required to model the end-to-end flight behavior of the UAV, i.e., to take off from the ground, perform different flight operations, and land on the ground. For example, a UAV cannot fly in the air without initial ground operations, therefore, the UAV flight state machine without ground states/events will not be useful. All the state machine events are required to be modeled as UML CallEvents. Other types of events such as SignalEvent, TimeEvent, and ChangeEvent are simulator-specific events that can not be controlled using the DRL algorithm. In the case of guard conditions, our approach requires modeling the guards in the form of OCL constraints or invariants. While modeling transitions, the avionics tester needs to model all possible transitions and events for a flight state.\n\n3.3 Modeling of UAS SUT\n\nOur approach requires three inputs. First, the domain model of the UAS SUT needs to be modeled using the structural profile. Second, the flight behavior is in the form of a UML state machine that is modeled using the behavioral profile. The third input is the expected behavior of UAS SUT in the form of OCL constraints that include expected ranges of values on various properties of the UAS SUT and w.r.t. the flight states. In the following, we discuss the modeling of the UAS SUT domain, flight behavior, and OCL constraints.\n\n3.3.1 UAS SUT Domain Modeling\n\nTo model the domain of UAS SUT, an instance of the structural profile is created for the target UAS component. Fig. 6 shows a domain model for the autopilot of a multi-copter named ArduCopter. The ArduCopter is modeled as an instance of UAV meta-class. The location of the ArduCopter is measured according to the global relative point, so CopterLocation is modeled as an instance of the LocationGlobalRelative meta-class. The attitude (roll, pitch, and yaw) of the ArduCopter is modeled using the Attitude stereotype. The ArduCopter has a range finder to calculate the distance which is modeled using the RangeFinder stereotype. Similarly, the speed of the ArduCopter along the three axes is modeled using the Velocity stereotype. Finally, the power system used in the ArduCopter is modeled using the Battery stereotype.\n\nThe domain model of the UAS SUT serves two purposes. First, it is used to provide the UAS SUT domain classes and properties to the environment utilized for the reinforcement learning algorithm (Section 3.4). This information becomes the observation space of the environment that is observed during the UAV flight. The second use of the domain model is to evaluate OCL constraints. For this purpose, an instance of the UAS SUT domain model is created and the slots are filled using the UAV flight data. The OCL constraints modeled for the corresponding flight state are evaluated on the instance model. The evaluation results are used later for the reward calculation (Section 3.4.2).\n\n3.3.2 Flight Behavior Modeling\n\nThe flight behavior of the UAV needs to be represented using abstract flight states and events. Fig. 7 and Fig. 8 show the flight behavior modeled as a UML state machine for the ArduCopter. The flight state machine contains various abstract flight states modeled as instances of meta-states from the UAV behavioral profile. Similarly, all the events are modeled as instances of various flight events from the UAV behavioral profile.\n\nInitially, the ArduCopter is in Idle state which is modeled using the Disarmed profile stereotype. To start the motors (arm the UAV) in the Idle state, the event armUAV() is used to take the ArduCopter to the Armed state. When the ArduCopter is in the Armed state, it can either turn off the motor to go back to the Idle state or it can go to Takeoff state using the takeoff() event. After taking off from the ground, the ArduCopter has six options. It can go to the Ascend state using the event increaseAlt(), or it can go to the Descend state using the event decreaseAlt(), or it can go to the Loiter state using the event startLoiter(), or it can go to the PositionHold state using the event holdPosition(), or it can go to the AltitudeHold state using the event holdAlt(), or it can go to the Landing state using the event landUAV(). If its next state is Ascend, it can remain in that state, or it can go to the Loiter or PositionHold or AltitudeHold or Descend. Moreover, the Ascend state has a sub-state machine for different types of turns, Straight, TurningRight, and TurningLeft as shown in Fig. 8. That means, the ArduCopter can Ascend while moving straight or it can take a left turn or right turn.\n\nAscend is the state in which the ArduCopter is making a climb i.e., increasing the altitude. Descend is the state in which the ArduCopter is making a descending i.e., decreasing the altitude. The Descend state also has a sub-state machine for turns because the ArduCopter can move straight or it can take a left turn or right turn. The Loiter state represents a flight phase in which the ArduCopter is flying in a small circle. During the Loiter state, the ArduCopter can loiter in a clockwise or counterclockwise direction. Thus, it has a sub-state machine for right and left turns for loitering in a clockwise or counterclockwise direction. The state PositionHold corresponds to the flight phase in which the ArduCopter is holding its position while keeping the attitude constant. Therefore, PositionHold state does not have a sub-state machine for different types of turns. Similarly, the AltitudeHold state represents a flight phase in which the ArduCopter is flying at the same level while keeping the altitude constant. For the ArduCopter types of UAV, it is possible to maintain constant altitude and move forward or backward or turn left or right.\n\nThe UAV flight behavior modeled in the form of a UML state machine is used by the reinforcement learning algorithm (Section 3.4). Each abstract flight state becomes a part of the state tuple. Each event modeled in the state machine becomes the action space. Similarly, all the transitions of the state machine represent the transitions model that will be used to keep track of the current and the next states. The UAV state machine plays an integral part in executing UAV flight behavior (i.e., transitioning the UAV through various flight states), which is performed by AITester during the testing process (Section 3.4.5).\n\n3.3.3 Specifying Expected Behavior of the SUT\n\nAfter modeling the domain UAS SUT and the flight behavior of the UAV, the expected behavior of UAS SUT in the form of OCL constraints is required to be specified. The OCL constraints should contain the expected ranges of value on various properties of the UAS SUT and w.r.t. the flight states. The purpose of the constraints is to check the invalid property values during the UAV flight. When formulating OCL constraints corresponding to UAV flight states, the specified ranges for a particular state must be consistent and non-overlapping with the subsequent state. For example, if the maximum altitude limit for Takeoff state is 50 feet, the altitude range for the subsequent state (Ascend) should consider 50 feet as the lower bound. Furthermore, the ranges defined in OCL constraints associated with UAV flight states should align with those specified in the general constraints.\n\nOCL constraints can be derived from two key sources: (i) the UAV configuration manual, and (ii) domain experts or testers who define constraints based on specific testing contexts. UAV configuration manuals usually specify parameter ranges for general scenarios and specific flight modes, such as Takeoff and Landing. While the parameter ranges provided by UAV configuration manuals are useful, they typically represent general or broader scenarios. Testers often focus on evaluating UAV application-specific or context-dependent conditions. For example, a tester might need to assess parameters like the UAV’s flight range, position, and navigation in a crop monitoring context. Similarly, in a package delivery scenario, a tester could be interested in evaluating parameters such as maximum weight, speed, and battery life along the intended flight path. For testing such conditions, testers must define OCL constraints considering each testing scenario. In our approach, these constraints are utilized to analyze deviations from the expected behavior of the SUT without imposing any restrictions on UAV flight operations. Therefore, OCL constraints must be carefully modeled to capture the testable range of values for the various properties during different flight states. It is important to note that each UAV has its unique set of constraints. The constraints defined for one specific UAV may not necessarily apply to other models of UAVs.\n\nLABEL:lst:constraints presents a set of example constraints designed to demonstrate the process of constraint specification, without being specific to any UAV type. Constraints C1 and C2 define general value ranges for altitude_AGL and distance properties of a UAV. These constraints include ranges that could be obtained from a UAV’s configuration manual. Constraint C1 specifies that a UAV can reach up to a maximum altitude of 300m above ground level (AGL). Exceeding this limit indicates a deviation from the expected behavior, suggesting a potential malfunction in the SUT. Similarly, constraint C2 defines a range for distance measurement by the UAV’s rangefinder, which is particularly beneficial for avoiding potential obstacles. Constraints C3 and C4 specify the valid ranges for the thrust and altitude_AGL during the Takeoff state. In the same way, constraints C5 and C6 define the valid range of values for the airspeed and speed along the z-axis during the Landing state. The constraints for the Takeoff and Landing states can be derived from the UAV’s configuration manual, as it defines the normal ranges for critical flight modes. The takeoff state is crucial for initiating a stable flight for the UAV, while the landing state is essential for the UAV’s safe return to the ground. For instance, a UAV surpassing the takeoff altitude limit could lose control, and violating landing speeds may risk a crash. Constraints C7 and C8 define ranges for airspeed (i.e., between 10 and 100 knots) and groundspeed (i.e., between 0 and 10 knots) during the Ascend state. With these constraints, a tester would be interested in examining the safety scenarios related to the UAV’s airspeed and groundspeed during the ascend/climb phase. For example, maintaining a low airspeed might risk stalling by compromising the UAV’s lift and a high groundspeed could destabilize the UAV. Constraints C9 and C10 specify valid ranges for airspeed (specifically between 5 and 100 knots) and altitude_AGL (specifically between 10 and 100 meter) during the Descend state. These constraints are necessary for UAV’s descending phase and a tester might be interested in testing scenarios related to this phase. For instance, a high airspeed or a low altitude could potentially result in a UAV crash.\n\n3.4 System-level Testing of UAS\n\nA typical practice of the avionics tester is to simulate the flight behavior of the UAV using the SIL/HIL simulator. During the simulation, the tester performs a certain action, observes the next state of the UAV in an environment, and analyzes the flight data to see if each avionics component is behaving according to the specification. This process of testing requires control of the UAV, continuously deciding various actions, and observing state change in the UAV and environment. To automate this process, human-level decision-making and control of the UAV are required at runtime. Such a problem can be devised in the form of a Markov Decision Process (MDP) [23]. In this case, an AI technique, deep reinforcement learning (DRL) is an appropriate choice compared to meta-heuristics search algorithms. Moreover, DRL provides a mechanism for on-the-fly testing of UAS in a dynamic environment which cannot be achieved by traditional model-based testing approaches (e.g., [24]). Using DRL, our approach introduces an AITester in place of a human tester to perform the system-level testing of the UAV. We formulate this problem as an MDP which consists of a set of states, a set of possible actions that can be performed in a state, a transition model, and a reward function [23]. For this purpose, the proposed profiles, UAS structural profile, and UAV behavioral profile play an important role. More discussion on the adaptation of DRL to automate the system-level testing of the UAV is given in the following subsections.\n\n3.4.1 Definitions\n\nDefinition 1 (State Space). A state space is defined as an ordered set of states S={S0,S1,S2,…,Sg}𝑆subscript𝑆0subscript𝑆1subscript𝑆2…subscript𝑆𝑔S=\\{S_{0},S_{1},S_{2},\\dots,S_{g}\\}italic_S = { italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_S start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT } in which each state is represented by a tuple Sx=⟨s0,s1,…,s9⟩subscript𝑆𝑥subscript𝑠0subscript𝑠1…subscript𝑠9S_{x}={\\left\\langle s_{0},s_{1},\\dots,s_{9}\\right\\rangle}italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = ⟨ italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPT ⟩. Where Sgsubscript𝑆𝑔S_{g}italic_S start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT represents the goal (final) state and s0subscript𝑠0s_{0}italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT represents one of the flight state stereotypes modeled in the UAV flight state machine. The remaining state elements are denoted as s1:=a⁢l⁢t⁢i⁢t⁢u⁢d⁢eassignsubscript𝑠1𝑎𝑙𝑡𝑖𝑡𝑢𝑑𝑒s_{1}:=altitudeitalic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := italic_a italic_l italic_t italic_i italic_t italic_u italic_d italic_e, s2:=a⁢i⁢r⁢s⁢p⁢e⁢e⁢dassignsubscript𝑠2𝑎𝑖𝑟𝑠𝑝𝑒𝑒𝑑s_{2}:=airspeeditalic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := italic_a italic_i italic_r italic_s italic_p italic_e italic_e italic_d, s3:=g⁢r⁢o⁢u⁢n⁢d⁢s⁢p⁢e⁢e⁢dassignsubscript𝑠3𝑔𝑟𝑜𝑢𝑛𝑑𝑠𝑝𝑒𝑒𝑑s_{3}:=groundspeeditalic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := italic_g italic_r italic_o italic_u italic_n italic_d italic_s italic_p italic_e italic_e italic_d, s4:=r⁢o⁢l⁢lassignsubscript𝑠4𝑟𝑜𝑙𝑙s_{4}:=rollitalic_s start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT := italic_r italic_o italic_l italic_l, s5:=p⁢i⁢t⁢c⁢hassignsubscript𝑠5𝑝𝑖𝑡𝑐ℎs_{5}:=pitchitalic_s start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT := italic_p italic_i italic_t italic_c italic_h, s6:=y⁢a⁢wassignsubscript𝑠6𝑦𝑎𝑤s_{6}:=yawitalic_s start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT := italic_y italic_a italic_w, s7:=h⁢e⁢a⁢d⁢i⁢n⁢gassignsubscript𝑠7ℎ𝑒𝑎𝑑𝑖𝑛𝑔s_{7}:=headingitalic_s start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT := italic_h italic_e italic_a italic_d italic_i italic_n italic_g, s8:=b⁢a⁢t⁢t⁢e⁢r⁢yassignsubscript𝑠8𝑏𝑎𝑡𝑡𝑒𝑟𝑦s_{8}:=batteryitalic_s start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT := italic_b italic_a italic_t italic_t italic_e italic_r italic_y, and s9:=d⁢i⁢s⁢t⁢a⁢n⁢c⁢eassignsubscript𝑠9𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒s_{9}:=distanceitalic_s start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPT := italic_d italic_i italic_s italic_t italic_a italic_n italic_c italic_e. Given the partially observable environment of UAVs [25], we consider the state space as a subset of the observation space. Hence, our definition of the state space incorporates a selection of properties from the UAS profile (Fig. 3), which constitutes the observation space (as per Definition 5). This state space design is based on key properties identified through various experimental trials. We keep the state space size small to avoid the “curse of dimensionality”—a phenomenon where the amount of data required to learn grows exponentially with the state space size, potentially hindering the agent’s learning capability [26]. The main objective is to streamline learning and decision-making processes within high-dimensional environments like UAVs [27].\n\nFig. 9 shows an example of the different states in the state space considering the UAV flight state machine shown in Fig. 7. For the given example, the initial state is represented as S0=⟨Disarmed,0.0,0.0,0,0,0.0,0.0,0.0,1,100,0.0⟩subscript𝑆0Disarmed0.00.0000.00.00.011000.0S_{0}={\\left\\langle\\mbox{\\em Disarmed},0.0,0.0,0,0,0.0,0.0,0.0,1,100,0.0\\right\\rangle}italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = ⟨ Disarmed , 0.0 , 0.0 , 0 , 0 , 0.0 , 0.0 , 0.0 , 1 , 100 , 0.0 ⟩, where Disarmed corresponds to s0subscript𝑠0s_{0}italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT in the tuple Sxsubscript𝑆𝑥S_{x}italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT. In this state, all the values are zero except the battery level which is 100. The next state is S1=⟨Armed,0.0,0.05,0.2,0.0081,0.0084,0.0235,357,99,0.0⟩subscript𝑆1Armed0.00.050.20.00810.00840.0235357990.0S_{1}={\\left\\langle\\mbox{\\em Armed},0.0,0.05,0.2,0.0081,0.0084,0.0235,357,99,0% .0\\right\\rangle}italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = ⟨ Armed , 0.0 , 0.05 , 0.2 , 0.0081 , 0.0084 , 0.0235 , 357 , 99 , 0.0 ⟩ where the airspeed, groundspeed, roll, pitch, yaw, heading, and battery values are little changed. After the UAV is armed, the next flight state is Takeoff. Therefore, the next state is S2=⟨Takeoff,20.0,0.22,2.5,−0.004,−0.004,−0.0501,357,98,0.0⟩subscript𝑆2Takeoff20.00.222.50.0040.0040.0501357980.0S_{2}={\\left\\langle\\mbox{\\em Takeoff},20.0,0.22,2.5,-0.004,-0.004,-0.0501,357,% 98,0.0\\right\\rangle}italic_S start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = ⟨ Takeoff , 20.0 , 0.22 , 2.5 , - 0.004 , - 0.004 , - 0.0501 , 357 , 98 , 0.0 ⟩ in which the altitude is increased to 20.0m, the airspeed is increased to 0.22, the groundspeed is increased to 2.5, and there is a small change in roll, pitch, yaw, and battery values. Similarly, the UAV state continues to change i.e., from S2subscript𝑆2S_{2}italic_S start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT to S3subscript𝑆3S_{3}italic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT to S4subscript𝑆4S_{4}italic_S start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT to S5subscript𝑆5S_{5}italic_S start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT to S6subscript𝑆6S_{6}italic_S start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT to S7subscript𝑆7S_{7}italic_S start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT state which is the goal (final) state. The goal state Sgsubscript𝑆𝑔S_{g}italic_S start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT is represented as S7=⟨Disarmed,0.0,0.0,0.0,0.0031,0.00039,0.0504,357,90,20.0⟩subscript𝑆7Disarmed0.00.00.00.00310.000390.05043579020.0S_{7}={\\left\\langle\\mbox{\\em Disarmed},0.0,0.0,0.0,0.0031,0.00039,0.0504,357,9% 0,20.0\\right\\rangle}italic_S start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT = ⟨ Disarmed , 0.0 , 0.0 , 0.0 , 0.0031 , 0.00039 , 0.0504 , 357 , 90 , 20.0 ⟩.\n\nDefinition 2 (Action Space). The action space is represented as a set A={A0,A1,A2,…,An}𝐴subscript𝐴0subscript𝐴1subscript𝐴2…subscript𝐴𝑛A=\\{A_{0},A_{1},A_{2},\\dots,A_{n}\\}italic_A = { italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }, where n is the total number of events in the UAV flight behavior model. Each action in the action space A𝐴Aitalic_A corresponds to an event modeled in the flight behavior model of the UAV corresponding to abstract flight events of the UAV behavioral profile. For the example state transitions shown in Fig. 9, the action A0subscript𝐴0A_{0}italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT corresponds to the event armUAV(), the action A1subscript𝐴1A_{1}italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT corresponds to the event takeoff(), the action A2subscript𝐴2A_{2}italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT corresponds to the event increaseAlt(), the action A3subscript𝐴3A_{3}italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT corresponds to the event decreaseAlt(), the action A4subscript𝐴4A_{4}italic_A start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT corresponds to the event landUAV(), the action A5subscript𝐴5A_{5}italic_A start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT corresponds to the event armUAV(), and the action A6subscript𝐴6A_{6}italic_A start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT corresponds to the event disarmUAV().\n\nDefinition 3 (Correct/Incorrect Action). An action is termed as correct if it is one of the possible actions (modeled in the flight state machine) for a given current state, otherwise, it is termed as an incorrect action. Our approach uses the UAV flight state machine to distinguish between correct and incorrect actions. The UAV flight state machine provides the possible set of corrective actions in a particular flight state. The distinction between correct and incorrect action is important in our case because if the selected action is incorrect it will either create zero or a negative effect on the UAV. For example, if the UAV is on the ground in the Armed state and the selected action is Loiter(), it is not possible for the UAV to start loitering.\n\nDefinition 4 (Transition Model). A transition model is defined as a probability of transition from a current flight state to the next flight state (in states space S𝑆Sitalic_S) using an action from the actions space A𝐴Aitalic_A. Equation 1 shows a transition model in which Sx+1subscript𝑆𝑥1S_{x+1}italic_S start_POSTSUBSCRIPT italic_x + 1 end_POSTSUBSCRIPT represents the next state in S𝑆Sitalic_S, Sxsubscript𝑆𝑥S_{x}italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT represents the current state in S𝑆Sitalic_S, and Axsubscript𝐴𝑥A_{x}italic_A start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT represents the current action in A𝐴Aitalic_A. According to the equation, there is a probability of the transition from the current state Sxsubscript𝑆𝑥S_{x}italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT to the next state Sx+1subscript𝑆𝑥1S_{x+1}italic_S start_POSTSUBSCRIPT italic_x + 1 end_POSTSUBSCRIPT using the action Axsubscript𝐴𝑥A_{x}italic_A start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT.\n\nT=P⁢(Sx+1|Sx,Ax)𝑇𝑃conditionalsubscript𝑆𝑥1subscript𝑆𝑥subscript𝐴𝑥T=P(S_{x+1}|S_{x},A_{x})italic_T = italic_P ( italic_S start_POSTSUBSCRIPT italic_x + 1 end_POSTSUBSCRIPT | italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ) (1)\n\nFor the example state transitions diagram shown in Fig. 9, using the action A0subscript𝐴0A_{0}italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT in state S0subscript𝑆0S_{0}italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, the next state is S1subscript𝑆1S_{1}italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Similarly, the action A1subscript𝐴1A_{1}italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT in state S1subscript𝑆1S_{1}italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT leads to the next state S3subscript𝑆3S_{3}italic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT.\n\nDefinition 5 (Observation Space). An observation space is defined as a vector of UAV properties, i.e., O=[o0,o1,o2,…,on]𝑂subscript𝑜0subscript𝑜1subscript𝑜2…subscript𝑜𝑛O=[o_{0},o_{1},o_{2},\\dots,o_{n}]italic_O = [ italic_o start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_o start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ] from the UAS SUT domain model, created using the UAS structural profile. Where oxsubscript𝑜𝑥o_{x}italic_o start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT corresponds to the UAV properties such as thrust, airspeed, vx, vy, and vz.\n\n3.4.2 Reward Function\n\nThe objective of AITester is to take control of the UAV flight during simulation, perform various actions on the UAV, and maximize the number of violations of the expected behavior. The reward function is designed based on two parameters, (i) correct/incorrect actions, and (ii) violations of the expected behavior specified as OCL constraints. These two parameters are important because a series of correct/incorrect actions may lead a UAV to crash. For example, if AITester continues to execute a correct action decreaseAlt() multiple times in Descent state, the UAV can hit the ground leading it to crash. This can happen frequently during training because the inherent behavior of the DRL algorithm involves exploring various possibilities of actions and observing their outcomes. Therefore, a correct action leading the UAV to crash is not considered a fault in the UAV. To handle such a situation, our approach utilizes the deviations from a UAV’s expected behavior based on violations of OCL constraints. The trace of OCL violations (i.e., deviations from the expected behavior) can support diagnosing faults in the SUT. Since OCL constraints are specified corresponding to each flight state of the UAV, it is possible to have multiple violations of OCL constraints at different states during the whole flight.\n\nThe reward for a single action performed in a particular state is calculated using Equation 2. For a correct action, the AITester gets a reward of (1+m)1𝑚(1+m)( 1 + italic_m ), where 1111 represents the reward for the correct selection of action and m𝑚mitalic_m represents the number of violations in the expected behavior (failed OCL constraints) based on that action. To calculate the number of failed OCL constraints, the UAV flight data (e.g., altitude, airspeed, roll, pitch, and yaw) sent by the state observer is used to populate an instance model which is generated using the input UAS SUT domain model (as shown in Fig. 2). The instance model populated in this way represents the current flight context of the UAV during execution. The constraints evaluator uses the input OCL constraints and state invariants for the current flight state and evaluates these constraints on the UAV instance model. The constraints evaluator returns the number of failed OCL constraints (m) for the given flight data. Since different OCL constraints are specified on a particular state, multiple violations of one constraint are considered as one violation. In this way, the AITester learns the flight behavior of the UAV, and at the same time, utilizes the flight behavior to explore the scenarios that violate the expected behavior of the SUT. For an incorrect action, the AITester gets the reward of −11-1- 1.\n\nr={1+mc⁢o⁢r⁢r⁢e⁢c⁢ta⁢c⁢t⁢i⁢o⁢n−1i⁢n⁢c⁢o⁢r⁢r⁢e⁢c⁢ta⁢c⁢t⁢i⁢o⁢n𝑟cases1𝑚𝑐𝑜𝑟𝑟𝑒𝑐𝑡𝑎𝑐𝑡𝑖𝑜𝑛1𝑖𝑛𝑐𝑜𝑟𝑟𝑒𝑐𝑡𝑎𝑐𝑡𝑖𝑜𝑛r=\\left\\{\\begin{array}[]{ l l }1+m&\\quad correct\\ \\ action\\\\ -1&\\quad incorrect\\ \\ action\\end{array}\\right.italic_r = { start_ARRAY start_ROW start_CELL 1 + italic_m end_CELL start_CELL italic_c italic_o italic_r italic_r italic_e italic_c italic_t italic_a italic_c italic_t italic_i italic_o italic_n end_CELL end_ROW start_ROW start_CELL - 1 end_CELL start_CELL italic_i italic_n italic_c italic_o italic_r italic_r italic_e italic_c italic_t italic_a italic_c italic_t italic_i italic_o italic_n end_CELL end_ROW end_ARRAY (2)\n\nR=∑t=0nγt∗rt𝑅superscriptsubscript𝑡0𝑛superscript𝛾𝑡subscript𝑟𝑡R=\\sum_{t=0}^{n}\\gamma^{t}*r_{t}italic_R = ∑ start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_γ start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ∗ italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT (3)\n\nThe cumulative reward for a single episode is calculated using Equation 3. According to this Equation, the cumulative reward is the added sum of the reward for individual action performed at time t (calculated using Equation 2) multiplied with discount factor γtsuperscript𝛾𝑡{\\gamma}^{t}italic_γ start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT at time step t. The discount factor γ𝛾\\gammaitalic_γ is between 0 and 1, i.e., γ∈[0,1]𝛾01\\gamma\\in[0,1]italic_γ ∈ [ 0 , 1 ]. This factor is essential in determining the extent to which the AITester prefers future rewards over immediate ones. If the discount factor is closer to 1, the AITester gives more preference to future rewards. This means the AITester will explore more of the state space, even if immediate rewards are not apparent. This can lead to broader state space coverage as the AITester is incentivized to explore and comprehend as much of the environment as possible. On the other hand, if the discount factor is closer to 0, the AITester is more inclined towards immediate rewards. This can limit the exploration of the state space. As a result, the AITester may not thoroughly explore the environment, possibly missing out on regions of the state space that could provide higher long-term rewards. Therefore, to enable broader state space coverage and thorough environment exploration, the discount factor should ideally be adjusted closer to 1, aligning with similar practices in the domain [28]. This value will progressively decrease after each time step t, thereby systematically shifting AITester’s focus toward immediate rewards. Consequently, the AITester initially prefers future rewards and gradually transitions its focus towards immediate rewards as time progresses.\n\n3.4.3 Determining LSTM Architecture for AITester\n\nThe UAV flight data at a particular time is correlated to the flight data at the previous instance of time. Due to this, UAV flight data holds a temporal relationship based on environmental context which is highly dynamic. Retaining information among these data points in subsequent time steps is important to comprehend the flight context. Moreover, our approach utilizes Deep Q-Network (DQN) [28] which works on the experience replay method by taking random samples from the replay memory of past experiences. This is an inherent feature of DQN to make learning efficient, however, it breaks correlation among different data points which makes it difficult to acquire the flight context. In such a scenario, an LSTM network is a suitable choice due to its ability to handle sequential data and long-term dependencies.\n\nFig. 10 shows a single-layer representation of LSTM architecture used in our approach. The LSTM network architecture used in our approach consists of an input layer, three LSTM layers with a hidden dimension of 10, and an output layer. The inputs of the neural network represent a state in states space S𝑆Sitalic_S. The first input is the abstract flight state that corresponds to one of the states in the flight behavior model. The remaining inputs such as altitude, airspeed, groundspeed, roll, pitch, yaw, battery, heading, and distance represent the information displayed on the cockpit of the ground control station which is received from the UAV during flight. This information is necessary for the remote pilot to control the UAV during flight [10]. That is, based on this information, the remote pilot decides a sequence of actions to successfully fly the UAV. The activation function used for the hidden layers of our LSTM network is the default hyperbolic tangent (tanh) [29]. The output of the neural network is the possible actions (from the action space A𝐴Aitalic_A) that can be performed given the input state. From the possible actions, the action with the highest probability is selected using the softmax function.\n\n3.4.4 UAV Environment\n\nThe agent has to interact with the UAV to perform an action, observe the state of the UAV, and get the reward for the selected action. To facilitate these operations, we build a goal-based environment with the goal of successfully landing the UAV on the ground. Under normal conditions, after performing different flight operations, if the UAV should land on the ground, the goal is achieved. Another possibility is that the UAV crashes due to a correct/incorrect sequence of actions (Section 3.4.2). In such a case, the goal is not achieved. UAV crashes during test execution can be observed in a simulation environment without requiring an actual UAV.\n\nThe environment takes state space and action space from the flight behavioral model (Section 3.3.2) and the observation properties from the domain model (Section 3.3.1). For each action in the action space, the environment implements the UAV-specific action commands. Similarly, for each action in a particular state, the environment keeps track of the next state. If the next state is the final (goal) state, the environment notifies the agent that the goal has been achieved. Based on the action (correct/incorrect), the environment produces observations for the next state. During the execution, it receives the action from the agent, determines the current state, performs the action on the UAV in simulation, observes the next state, and checks if the goal state is achieved or not.\n\n3.4.5 Testing Process of AITester\n\nTo begin, AITester requires three inputs from avionics testers (as shown in Fig. 2); (i) the domain model of the UAS SUT developed using the UAS structural profile, (ii) the flight behavior in the form of a UML state machine developed using the UAV behavioral profile, and (iii) the expected behavior of UAS SUT in the form of OCL constraints. The UAS SUT domain model is used to initialize the observation space and to generate an instance model that supports the evaluation of OCL constraints during execution. The flight behavior model of the UAV is used to initialize the state and action space of the DRL algorithm.\n\nAITester incorporates Deep Q-Network (DQN) as a DRL algorithm [28]. DQN has been widely used to train different game-playing bots and to get human-level control [30, 31]. The testing process starts by initializing the LSTM network called the policy network, the environment, and by getting the initial state of the UAV. For the selected state, the AITester selects an action randomly (explore) or by using the policy network (exploit). For this purpose, the AITester uses Epsilon ϵitalic-ϵ\\epsilonitalic_ϵ-greedy strategy to balance exploration and exploitation. Before executing the selected action, it is analyzed whether this action can be performed on a UAV or not. This is done using the flight state machine. If the selected action can not be performed, it is omitted and the negative reward is returned. In this case, the state of the UAV is not changed. If the selected action is fine, it is performed on a UAV operating in an environment.\n\nUsing the UAV flight states and actions, the AITester starts exploring various flight states using different actions (e.g., takeoff or land). The AITester selects an action and executes it using Action Executor. The Action Executor receives an action, establishes a connection with the UAV through DroneKit API, and sends the action command to the UAV. The function of DroneKit is to receive the action command for the UAV, send the command to the UAV using a communication link (using Mavlink), and receive the state of the UAV. The continuous change in the flight state of the UAV is monitored by a State Observer. This helps the AITester to keep track of the current state, action, and the next state of the UAV. Moreover, the flight data observed during execution is used to populate an instance model of the UAS SUT domain model. The instance model is evaluated on the OCL constraints and state invariants using a Constraints Evaluator. The Constraints Evaluator provides the number of violations of OCL constraints. Based on the selected action and the number of violations of OCL constraints, the AITester gets the reward.\n\nDuring training, this process continues for a specified number of episodes, and the AITester continues to explore different flight states based on different actions and learns to violate OCL constraints (expected behavior of the SUT). The training is performed using a flight simulator. At the end of the training process, the trained model is saved. In the evaluation phase, the trained model is loaded and AITester selects various actions using the trained model, performs the selected actions on the UAV operating in an environment, observes the outcomes, and compiles testing results for further analysis by avionics testers. The compiled results include information related to UAV flight states, actions, and the number of failed OCL constraints for each execution. This information helps an avionics tester to analyze the sources of faults in the SUT. At the end of the process, the policy network is saved so that it can be reused in later stages of testing.\n\n4 Implementation\n\nWe implemented the proposed approach in a toolset to support the automated system-level testing of the UAV. All main modules of the toolset are packed into two separate packages. The toolset is available at the GitHub repository1. In the following subsections, we discuss every module of the toolset w.r.t. each package.\n\n4.1 Model Handler\n\nThis component takes input UAS SUT domain model, flight behavior model, and OCL constraints. Using this input, it loads the models, generates a model instance, prepares the instance model for evaluation during execution, and evaluates the OCL constraints on the instance model. Each module of this component is developed using the Java programming language.\n\n4.1.1 Model Loader\n\nFirst, this module takes the UAS SUT domain model in the form of UML and loads this model in a data structure along with the meta-class elements (i.e., profile stereotypes). Second, it takes the flight behavior model in the form of a UML state machine and traverses the model to extract flight states, events, and transitions. In case the state machine has composite and orthogonal states, these states are flattened using the algorithm presented by Binder [24]. For the modeling manipulation, it uses an external API named Eclipse Modeling Framework (EMF ) that allows it to load and read the model information conveniently. The third function of this module is to load the OCL constraints and state invariants.\n\n4.1.2 Instance Generator\n\nThis module uses the domain model provided by Model Loader and the UAS profile to generate an instance model. For this purpose, EMF is used to create instances of the domain classes and the associations among these classes. The properties for each class are created using the domain class and profile stereotype attributes. A slot is created for each property in the instance model. The generated instance model is saved in the form of a UML model.\n\n4.1.3 Instance Populator\n\nThe responsibility of this module is to receive the UAV flight data and populate the instance model generated using Instance Generator. First, the classes and properties are mapped between the UAV flight data and the instance model. After that, the flight data corresponding to each UAV class and properties are used to fill the corresponding slots in the instance model.\n\n4.1.4 Constraints Evaluator\n\nThe core functionality of this module is to evaluate the OCL constraints and state invariants on the instance model containing the UAV flight information. For this purpose, the Eclipse OCL evaluator is used. Before starting the evaluation process, the OCL constraints and state invariants are extracted (using Model Loader) corresponding to each state of the UAV flight. During execution, the flight data received from the environment is sent to Instance Populator. The instance model is used to prepare an OCL evaluator environment for the evaluation of OCL constraints [32, 33]. Before starting the evaluation process, OCL constraints are loaded from a single file corresponding to each state of the UAV flight. This file contains general constraints and state-specific constraints, resembling the format depicted in LABEL:lst:constraints. All OCL constraints and state invariants are evaluated on the populated instance model. If an OCL constraint or state invariant fails on the instance model, the Eclipse OCL evaluator returns false. If the OCL constraint or state invariant is passed on the instance model, the Eclipse OCL evaluator returns true. At the end of the constraints evaluation, the evaluator returns the total number of failed OCL constraints (violations in the expected behavior of the SUT) for the given flight data.\n\n4.2 AITester\n\nThis constitutes the primary component of the toolset. The key functions of this component are UAV environment preparation, interaction with Constraints Evaluator for the reward calculation, and training and evaluation modes for system-level testing of UAVs. Since AITester is aimed to be used at different levels of testing, the tool contains a training module as well as an evaluation module. All modules of the AITester are developed using Python programming language. The deep learning framework used for this purpose is PyTorch [34].\n\n4.2.1 Training Module\n\nThe main function of this module is to train the AITester for the automated system-level testing of the UAV. This module implements a deep reinforcement learning algorithm named Deep Q-Network (DQN) along with the LSTM network. For the DQN, it takes various hyperparameters such as the number of episodes, batch size, gamma, replay memory size, target update, ϵitalic-ϵ\\epsilonitalic_ϵ-start, ϵitalic-ϵ\\epsilonitalic_ϵ-end, and ϵitalic-ϵ\\epsilonitalic_ϵ-decay. Before the start of the training process, it determines the current state of training i.e., whether the training needs to start from scratch or load the previous checkpoint and start from that point. To reload from the previous checkpoint, the LSTM networks (both policy and target network) are loaded using PyTorch model loading API. Each episode of the training process starts with an initial state, selects an action using the LSTM network, gets a reward from the Environment, and observes the next state. During each episode, the explored states, correct/incorrect actions, and resultant failed OCL constraints are compiled and stored in a file. To balance exploration and exploitation, the Epsilon ϵitalic-ϵ\\epsilonitalic_ϵ-greedy strategy is implemented. For the training, Adam optimizer [35] and SmoothL1Loss functions are used. After a specified interval, the state of the training process (including LSTM networks) is stored. When the training process finishes, the trained LSTM network is stored in the specified directory so that it can be used for evaluation.\n\n4.2.2 Evaluation Module\n\nThe role of this module is to perform the system-level testing of UAVs when the AITester is trained in the SIL simulator. This module takes a trained LSTM network and loads it using PyTorch. The process of this module is identical to the main procedure of the DQN algorithm during training except for the learning parameters such as the use of replay memory, calculation of Q-values, loss calculation, and gradient optimization. The main use of this module is the facilitation of testing at HIL and PIL levels. This module also supports the compilation of testing results at the end of each test execution.\n\n4.2.3 Environment\n\nThe core feature of this module is to create an environment in which the AITester can perform actions, observe the UAV flight state, and calculate rewards. For this purpose, this module provides an environment manager to facilitate these operations. To perform an action on the UAV, this module uses the DroneKit API . The DroneKit uses Mavlink as a communication link to communicate with the UAV. The main benefit of the DroneKit is that it is independent of a particular simulator environment. This makes our toolset capable of performing system-level testing of the UAVs at SIL, HIL, and PIL levels.\n\n4.2.4 Py2Java Communicator\n\nIn this module, py4j API is used to create a communication channel between the python component (AITester) and the Java component (Model Handler). The core feature is to send the UAV flight information to Model Handler for the constraints evaluation, receive the results, and pass them on to the AITester during the execution. Initially, this module gets the UAS SUT domain model details and flight behavior model information from the Model Handler. This information is used to create and initialize the state, action, and observation space of the environment.\n\n4.2.5 UAV Commands API\n\nWe provide an API for the execution of UAV flight events on the simulator environment. This API contains the concrete implementation of DroneKit-specific commands for ArduCoper and ArduPlane corresponding to the abstract flight events modeled in the flight behavior profile. Since the API contains the implementation of abstract flight events, it can easily be extended and modified for any other simulator that supports DroneKit.\n\n5 Empirical Evaluation\n\nThis section presents the empirical evaluation of AITester including two experiments. The first experiment was performed using the ArduCopter autopilot system and the second experiment was conducted using an industrial case study of ground control station (GCS) cockpit display systems (CDS), i.e., GCS-CDS. In the following subsections, we discuss research questions, case studies, both experiments’ setups, the design and execution of the experiments, the results of both experiments, and the possible threats to the validity of experimental results.\n\n5.1 Research Questions\n\nAITester utilizes a UAV flight state machine for the system-level testing of the UAS system under test (SUT) with the goal of violating the expected behavior of the SUT. There are two key aspects for analyzing the performance of the AITester. The first is the effectiveness of AITester in generating test scenarios that can lead to deviations from the expected behavior of the UAS SUT. During the testing process, the second aspect is the ability of the AITester to explore diverse paths from the UAV flight state machine. We formulate the following research questions for the experimental evaluation based on these two aspects.\n\n•\n\nRQ1: Is AITester effective in violating the expected behavior of a UAS SUT?\n\n•\n\nRQ2: Is AITester capable of exploring diverse flight paths during testing?\n\nBoth RQs are important from the testing perspective of a UAS SUT. The goal of the AITester is to perform system-level testing of a UAS SUT using a state machine representing the flight behavior of a UAV. RQ1 assesses AITester in terms of violations of the expected behavior of a UAS SUT that can lead to potential faults. This is a primary concern of testing a UAS. Since a flight state machine is utilized in the testing process, it is quite possible that AITester learns to explore a specific set of flight states and actions leading to maximum violations using the same set of OCL constraints. This results in testing the same behavior multiple times which is not a desired feature. Therefore, the analysis of diversity in exploring flight paths is an important consideration.\n\n5.2 Case Studies Description\n\nFor the first experiment, we used ArduCopter which is a part of the widely used open-source ArduPilot project. The ArduCopter supports operating a variety of multi-copter UAVs including helicopter, tri-copter, quad-copter, hexacopter, etc. It supports many flight modes including manual, semi-autonomous, and fully autonomous. Its software is compatible with a wide range of hardware e.g., Pixhawk, CUAV v5 Plus, OpenPilot Revolution, etc. It has also been used for research purposes in various experimental settings [36, 17].\n\nFor the second experiment, we used an industrial case study representing the CDS of GCS (i.e., GCS-CDS). The GCS-CDS contains three important flight instruments as shown in Fig. 11. The first flight instrument represents an airspeed indicator (ASI). Fig. 11(a) shows an ASI displaying the airspeed value of ≈\\approx≈0 knots. The second flight instrument represents an altimeter. Fig. 11(b) shows an altimeter indicating the altitude value of ≈\\approx≈1660 feet above sea level (ASL). The third flight instrument represents a turn coordinator that is used to display the current turning direction and the bank angle of the UAV. Fig. 11(c) shows a turn coordinator displaying the turning direction towards the right and the bank angle of ≈\\approx≈3 degrees.\n\n5.3 Experiments Setup\n\nThe modeling statistics of both case studies are shown in Table 1. For the first experiment using ArduCopter, we used the proposed UAS profile to model the domain and behavior of the ArduCopter. The ArduCopter domain model consists of six domain classes and 23 properties. The ArduCopter behavioral model comprises 12 flight states, 23 events, and 43 transitions. The domain model is shown in Fig. 6 and the flight behavioral model is shown in Fig. 7 and Fig. 8. The total number of applied stereotypes is 66. The expected behavior of the quadcopter is specified in the form of OCL constraints that are 48 in number (including general and state invariants). We used the ArduPilot software-in-the-loop simulator which was built using the binaries of the same version of the ArduCopter source code.\n\nFor the second experiment using GCS-CDS, we used the UAS profile and CDS testing profile proposed in previous work [10]. The UAS profile was used to model the flight behavior of a UAV and the CDS testing profile was used to model the domain of the GCS-CDS. The GCS-CDS domain model consists of 41 classes and 216 properties. The ArduCopter behavioral model comprises 14 flight states, 25 events, and 45 transitions. The total number of applied stereotypes is 40. The expected behavior of GCS-CDS is specified in the form of OCL constraints that are 30 in number.\n\nThe constraints for our experiments were identified through a careful analysis of the Ardupilot documentation, as well as consultations with avionics testers to consider important testing scenarios. LABEL:lst:expconstraints presents a selection of OCL constraints utilized in our experiments. Constraint C1 defines the minimum battery level for ArduCopter in Armed state, aiming to ensure the UAV has sufficient battery to take off. If ArduCopter initiates takeoff with a low battery level and further depletes its battery during flight without sufficient power for a failsafe landing action, it could potentially result in a crash. Constraint C2 specifies roll angle range during PositionHold state to maintain the stability of the ArduCopter. If the roll angle surpasses the defined limit, it could destabilize the ArduCopter, potentially leading to collisions with obstacles. Constraints C3 and C4 define ranges for yaw angle and yaw rate during Circle state. Both yaw angle and rate are crucial in this state because violating these limits could potentially result in uncontrollable rotations, flipping over, loss of control, and possible collisions with obstacles. Constraint C5 specifies airspeed values range during Approach state. Exceeding the airspeed limit during this state may lead to a rapid and uncontrolled landing, or hit the ground with extreme force, potentially causing damage to both the copter and its surroundings. It is important to note that in our approach, these constraints do not force a UAV into unsafe scenarios. They mainly define the expected ranges for a specific flight state, and exceeding these ranges could signify deviations from the expected behaviors.\n\n5.4 Experiments Execution\n\nFor the training phase, we used hyperparameters presented in Table 2. Since there are no standard guidelines for selecting hyperparameters for training, we selected these hyperparameters based on the various experimental trials with different values of parameters and their combinations. We executed AITester and Random to analyze the training progress considering the randomness factor. Both AITester and Random approaches were executed on two machines with the same specifications, i.e., core i7 3.6 GHz processor, 64 GB RAM, 1 TB hard drive, NVIDIA GeForce®RTX 2080 Ti graphics card, and Windows 10 64-bit operating system. We set the number of episodes to 1000 for AITester and the same number of iterations for Random. At the end of the training session, a trained model for AITester was stored.\n\nFor the first experiment with ArduCopter, we used the trained AITester and ran it 100 times (Table 2). We also ran Random 100 times for the comparison. We used random as a baseline because the available approaches in literature either require manual test scenario creation, focus on testing a specific subsystem of UAV autopilot, or do not provide public tool support. Moreover, avionics testers commonly execute UAV flight scenarios with random actions and data using a flight simulator, a practice similar to random testing aimed at identifying system faults. Alternatively, if the testing focus is on uncovering security vulnerabilities, fuzz testing could serve as a comparative approach. While fuzz testing is security-focused [37], aiming to identify vulnerabilities through invalid or unexpected inputs, our evaluation does not aim for security testing of the UAS.\n\nFor the second experiment using GCS-CDS, we compared AITester with the baseline model-based CDS testing approach [10]. For the CDS testing approach, we repeated the previous experiment procedure [10]. This experiment was executed on two machines with the same specifications used in the first experiment. We set the number of episodes to 100 (Table 2) for AITester and the same number of paths are used for the CDS testing approach. The overall execution time for each case study, across 100 episodes, was approximately 300 minutes. It is important to note that the execution time varies based on the machine specifications and the flight simulator being used. While we experimented with ArduPilot – a widely used open-source simulator – AITester is not tied to any specific simulator. It is adaptable and can seamlessly integrate with a faster simulator.\n\nTo make our experimental results reproducible, we provide the toolset with the experiment setup and execution information at an online repository1.\n\n5.5 Experiments Results and Analysis\n\nTo analyze the training progress, we calculated the moving average reward for all episodes. The moving average reward (MAR) for N episodes (M⁢A⁢RN𝑀𝐴subscript𝑅𝑁MAR_{N}italic_M italic_A italic_R start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT) is calculated using Equation 4, where n is the number of reward values to consider in one window of the moving average. The overall MAR values over total episodes can be calculated using Equation 5 for each new average window of n reward points. In this equation, rn+1subscript𝑟𝑛1r_{n+1}italic_r start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT is the new reward value and the rn−N+1subscript𝑟𝑛𝑁1r_{n-N+1}italic_r start_POSTSUBSCRIPT italic_n - italic_N + 1 end_POSTSUBSCRIPT is the oldest value in the previous episode window.\n\nM⁢A⁢RN=1N⁢∑i=N−n+1Nri𝑀𝐴subscript𝑅𝑁1𝑁superscriptsubscript𝑖𝑁𝑛1𝑁subscript𝑟𝑖MAR_{N}=\\frac{1}{N}\\sum_{i=N-n+1}^{N}r_{i}italic_M italic_A italic_R start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = italic_N - italic_n + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (4)\n\nM⁢A⁢R=M⁢A⁢RN,p⁢r⁢e⁢v+1N⁢(rn+1−rn−N+1)𝑀𝐴𝑅𝑀𝐴subscript𝑅𝑁𝑝𝑟𝑒𝑣1𝑁subscript𝑟𝑛1subscript𝑟𝑛𝑁1MAR=MAR_{N,prev}+\\frac{1}{N}\\left(r_{n+1}-r_{n-N+1}\\right)italic_M italic_A italic_R = italic_M italic_A italic_R start_POSTSUBSCRIPT italic_N , italic_p italic_r italic_e italic_v end_POSTSUBSCRIPT + divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ( italic_r start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT - italic_r start_POSTSUBSCRIPT italic_n - italic_N + 1 end_POSTSUBSCRIPT ) (5)\n\nFig. 12 presents a comparison between AITester and Random based on the MAR for 1000 training episodes. The figure demonstrates MAR values (up to ≈\\approx≈650) that are computed over 1000 episodes using a larger window size [38], i.e., n=350𝑛350n=350italic_n = 350. It can be observed that the MAR of AITester is high in most of the cases compared to Random. MAR of AITester is greater than 50 in a majority of the episodes and in some cases, it is higher than 100, whereas Random maintains MAR ≈\\approx≈ 45 in most of the episodes. The MAR of AITester and Random is close in some cases. This happens when the AITester tries to explore (select random actions) the environment to create a balance between exploration and exploitation. From the training outcomes, it can be seen that AITester learns to perform the correct sequence of actions while violating the expected behavior of the SUT.\n\nTo answer RQ1, we performed a comparison based on the deviations from the expected behavior, considering violations of OCL constraints. As AITester utilizes UAV flight state machines to explore different paths in a state machine, an important consideration is the exploration of diverse state machine paths during testing. To analyze the diverse exploration of UAV flight states, we used path diversity as a metric that was employed in a similar context and different domains, e.g., for Web [39]. For RQ2, we analyzed the statistically significant difference between the two approaches based on path diversity. We calculated path diversity using the method defined for state graphs [39]).\n\nTo analyze the results for RQ2 and perform a statistical comparison, we followed the guidelines defined by Arcuri and Briand [40]. We used the Wilcoxon signed-rank test with a significance level (α𝛼\\alphaitalic_α) set at 0.05. The Wilcoxon signed-rank test is a non-parametric statistical test utilized for comparing two different sample sets. This test produces a p-value, which is used to determine if the difference between two samples holds statistical significance. A smaller p-value (normally <=αabsent𝛼<=\\alpha< = italic_α) suggests that there is a statistically significant difference between the two samples. A larger p-value (normally >αabsent𝛼>\\alpha> italic_α) indicates that there is no statistically significant difference between the two samples. To measure the magnitude of the difference, particularly to determine which sample is better, we utilized Cliff’s Delta [41]. Cliff’s Delta is a non-parametric effect size measure that quantifies the degree of difference between two samples. A value of 0 signifies that the two samples are identical. A positive value (up to +1) suggests that the first sample is better than the second sample. Conversely, a negative value (down to -1) indicates that the second sample is better than the first sample. The discussion on experiment results corresponding to each research question is given below.\n\n5.5.1 Results of Experiment on ArduCopter\n\nTo answer RQ1, the results of the comparison between AITester and Random testing based on violations of the expected behavior of the SUT (OCL violations) are presented in Table 3. The table shows the total and the unique number of OCL violations corresponding to different UAV flight states. One constraint may be violated multiple times when the UAV is in one state for a particular time. For example, if a UAV takes five seconds to reach the altitude specified for the Climb state and the environment changes are being observed after 500 milliseconds, one constraint for Climb state can violate 10 times. Therefore, repeated violation of the same OCL constraint is considered as one unique violation. To isolate unique OCL violations, we first grouped recurring violations by flight state, followed by a manual analysis to ascertain the uniqueness of each OCL violation. We keep track of all violations as well as the unique number of violations. From the table, it can be observed that the number of OCL violations done by the AITester in each flight state is greater than that of Random. It can be seen that the total number of OCL violations of AITester is approximately thrice compared to Random. For some states such as Descent, Loiter, and Landing the AITester violates OCL constraints more than 50% compared to Random. Moreover, for some states like Climb and AltitudeHold, the difference in the number of violations done by AITester is higher than that of Random. The difference between AITester and Random is noteworthy in the unique number of OCL violations. In some states (e.g., Climb and AltitudeHold,), the AITester violates slightly more OCL constraints compared to Random. For the important flight states such as Descent, Loiter, and Landing, AITester violates all state invariants specified for these states, whereas Random can only violate a few. The total number of unique OCL violations done by AITester is more than 60% compared to Random. The results suggest that AITester effectively violated several OCL constraints representing the expected behavior of ArduCopter. These violations of OCL constraints may lead to faults in ArduCopter. However, identifying the root causes of faults in such a system requires faults reproduction and faults localization [42] which is not in the scope of our approach.\n\nRQ1 Result AITester is effective in generating diverse test scenarios that lead to deviations from the expected behavior of ArduCopter.\n\nTo answer RQ2, the results of the comparison between AITester and Random based on diversity are given in Table 4. The results of the Wilcoxon test suggest a statistically significant difference (i.e., p-value <αabsent𝛼<\\alpha< italic_α) between AITester and Random. To analyze which one is better, the results of the Cliff’s Delta effect size measure show a large effect size. This implies that the proposed approach (AITester) is better in comparison to Random. Therefore, we can conclude that AITester outperforms Random in exploring diverse flight paths.\n\nRQ2 Result AITester is able to explore the diverse nature of flight paths from the behavioral model of UAV during testing.\n\n5.5.2 Results of Experiment on GCS-CDS\n\nTable 5 shows the results of the comparison between the AITester approach and CDS testing baseline approach [10]. Fig. 13 presents diagrams created from the results generated by AITester. These diagrams depict the faults identified in three different flight instruments of GCS-CDS.\n\nTo answer RQ1, the results show that the total number of OCL violations performed by the AITester is greater than that of the CDST approach. In most of the flight states, the AITester performed a higher number of OCL violations compared to the CDST approach. The total number of unique OCL violations done by the AITester is 30 whereas the CDST approach can perform 24 total unique OCL violations. The analysis of flight state-wise unique OCL violations shows that the number of violations by AITester is greater than the CDST approach in some states, i.e., Armed, Approach, Circle, Loiter, and Takeoff.\n\nThe unique OCL violations performed by AITester lead to four different types of faults (Fig. 13) in GCS-CDS under test. These four types of faults are identified due to the violations of four OCL constraints shown in LABEL:gcscds-violated. Due to the violation of OCL constraint C1, the first type of fault is found in ASI during Cruise flight state. According to the constraint C1, the airspeed value must be between 50 and 100. Fig. 13(a) shows that the airspeed value pointed by the ASI needle is 240 knots whereas the ASI tape shows a value of ≈\\approx≈44 knots. This indicates an inconsistency between the ASI needle and tape. Therefore, this type of fault is considered a CDS elements integration fault.\n\nDue to the violation of OCL constraint C2, the second type of fault is found in the Altimeter during Approach flight state. The constraint C2 states that the altitude value must be between 584 and 604 feet during the Approach state. At the same flight state and in different executions, the Altimeter has shown incorrect values. The Altimeter shows the altitude value of ≈\\approx≈ 709 feet in Fig. 13(b), ≈\\approx≈ 956 feet in Fig. 13(c), ≈\\approx≈ 1718 feet in Fig. 13(d), and ≈\\approx≈ 2850 feet in Fig. 13(e).\n\nThe third and fourth types of faults are identified in Turn Coordinator during Circle and Loiter states due to the violation of OCL constraints C3 and C4 respectively. In the third type of fault, Turn Coordinator shows a bank angle out of the range specified by OCL constraint C3. Due to the out-of-range angle, the Turn Coordinator shows a high angle in Circle state as shown in Fig. 13(f). The fourth type of fault is identified due to the violation of OCL constraint C4. In this fault, while turning left during Descent (Fig. 13(g)) and Loiter (Fig. 13(h)) states, the Turn Coordinator shows values higher than -46. It was analyzed that the UAV was not flipped upside down during both states. This happened as the angle exceeded the maximum limit during Descent and Loiter states.\n\nAll four types of faults identified by AITester conform to the four types of faults found by the CDST approach [10] in GCS-CDS. Therefore, the proposed approach (AITester) is effective in finding potential faults in the GCS-CDS under test.\n\nRQ1 Result AITester is effective in finding four potential faults in three different flight instruments of GCS-CDS.\n\nFor the RQ2, the results of the comparison between the AITester and CDST approach based on diversity are given in Table 4. The results of the Wilcoxon test suggest that p-value <αabsent𝛼<\\alpha< italic_α, i.e., there is a statistically significant difference between the AITester and CDST approach. To identify which one is better, the results of the Cliff’s Delta effect size measure show a large effect size. The results of statistical tests suggest that the proposed approach (AITester) is better compared to the CDST approach. That is, AITester outperforms the CDST approach in exploring the diverse nature of flight paths of UAV flight state machines.\n\nRQ2 Result AITester is capable of exploring diverse flight paths from the UAV flight behavioral model during the testing of GCS-CDS.\n\n5.5.3 Test Paths in Experiments\n\nDuring the experiments, AITester generated multiple test paths, with violations of OCL constraints occurring in various flight states. Fig. 14 illustrates one of the test paths selected from the experimental results. This test path corresponds to a fault observed in the Turn Coordinator of the GCS-CDS, as shown in Fig. 13(h). The fault occurred during the Loiter state due to the violation of an OCL constraint C4 (LABEL:gcscds-violated). While traversing this test path, AITester executed the Arm action when the UAV was in the Disarmed state, resulting in a transition to the Armed state. After the state change, AITester evaluated the constraints specific to the Armed state. Next, AITester performed Takeoff action which led to the TakeOff state, and proceeded with the evaluation of constraints associated with this state. In a similar manner, AITester selected the actions IncreaseAltitude, HoldAltitude, DecreaseAltitude, HoldAltitude, and Loiter. These actions guided the UAV through the Climb, AltitudeHold, Descent, AltitudeHold, and Loiter states, respectively. Simultaneously, AITester evaluated the constraints applicable to each state. One of the constraints for Loiter state was violated, indicating a deviation from the expected behavior. AITester continued the testing process and performed further actions to take the UAV into AltitudeHold, Descent, Descent, Landing, and finally to Disarmed states. Upon completing this process, the deviation reported by AITester was utilized to locate the fault.\n\nReproducing Test Paths. Each AITester-generated test path consists of a series of actions executed by AITester during the testing process. To reproduce the test paths generated by AITester, each action must be transformed into corresponding UAV flight operations. Fig. 15 shows the transformation of a test path, as depicted in Fig. 14, into an executable test script. Initially, for each action in the test path, a corresponding UAV flight operation call must be defined within the test script. For instance, Arm action would be transformed into arm() operation. Subsequently, for each UAV operation call, a script specific to the flight simulator must be defined. As illustrated in Fig. 15, the scripts for arm() and takeoff() operations correspond to the Ardupilot flight simulator. If a different flight simulator is used, scripts for each operation need to be specifically defined for that particular simulator. Ultimately, this procedure results in test scripts corresponding to the test paths. These scripts can be utilized to re-execute the test path. Note that the process of transforming test paths into test scripts can be automated using the CDST tookit [43].\n\n5.6 Threats to Validity\n\nThe possible threats to the validity of our experiment are discussed individually in the following subsections.\n\n5.6.1 External Validity Threat\n\nThe possible threats to the validity of our experiment are discussed individually in the following subsections. The external threat to validity is related to the generalization of the experiment results. To reduce the chance of external validity threat, the experiment was performed using two primary subsystems of UAS, an autopilot (ArduCopter) and the CDS of GCS (GCS-CDS). ArduCopter is a good representative open-source autopilot system that is widely used in research and development [36, 17]. The ArduCopter supports a wide variety of multi-copter UAVs including a helicopter, tri-copter, quad-copter, hexacopter, etc. Moreover, this is also compatible with a wide range of hardware e.g., Pixhawk, CUAV v5 Plus, OpenPilot Revolution, etc. The GCS-CDS is an industrial case study containing widely used CDS elements. The results of our experiment may not be generalizable for all subsystems of UAS, however, this threat typically exists in every experiment [33].\n\n5.6.2 Internal Validity Threat\n\nThe parameter tuning of the training algorithm presents an internal threat to the validity of our experiment. There are no well-defined standard guidelines for selecting the hyperparameters of the DRL algorithm. We followed the common practice of selecting hyperparameters to minimize the internal validity threat. We performed several experimental trials with different values of parameters and their combinations. At the end of these trials, we selected the best-suited hyperparameters for our experiment. To reduce the chances of construct validity threat, we used the same stopping criterion for our approach (AITester) and Random algorithm. We execute AITester for 1000 episodes and Random for 1000 iterations during training. For the evaluation phase of both experiments, we repeated each approach 100 times which is a higher number compared to traditional DRL evaluation procedure [28]. In the experiment with GCS-CDS, we configured and executed test paths according to the method defined in previous work [10].\n\n5.6.3 Construct Validity Threat\n\nConstruct validity threat occurs when the relationship between cause and effect cannot be determined. To mitigate the possibility of this threat, we analyzed the experimental results according to the guidelines provided by Arcuri and Briand [40]. We examined the experimental results based on their statistical significance and also analyzed the effect size. Specifically, we used the Wilcoxon signed-rank test for statistical significance and the Cliff’s Delta effect size measure [41] to analyze the effect size.\n\n5.6.4 Conclusion Validity Threat\n\nThe threat to conclusion validity is associated with the effect of treatments on the outcomes. To reduce the chances of this threat, we used the moving average reward (MAR) metric to analyze the reward during the training session. Our approach utilizes UAV flight state machines to explore different flight behaviors. To analyze the diverse exploration of UAV flight states, we used path diversity as a metric that was employed in a similar context and different domains, e.g., for Web [39]. We also used the unique number of OCL constraint violations as a metric to compare AITester with the CDST approach. For a fair comparison, this metric is common between this work and the previous work [10].\n\n6 Related Works\n\nThis section presents a discussion of the works related to our approach including the works targeting UAV testing, autopilot system testing, the application of reinforcement learning to fly the UAV, and the studies related to the reinforcement learning-based testing of the UAV.\n\n6.1 UAV Testing\n\nIn the literature related to the testing of unmanned aerial vehicles (UAV), Johnson and Fontaine [44] developed a hardware and software-in-the-loop platform to carry out flight testing of small UAVs. For this purpose, test scenarios are required to be created m"
    }
}