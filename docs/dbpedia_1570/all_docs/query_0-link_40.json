{
    "id": "dbpedia_1570_0",
    "rank": 40,
    "data": {
        "url": "https://controls.papercept.net/conferences/conferences/ICUAS24/program/ICUAS24_ContentListWeb_4.html",
        "read_more_link": "",
        "language": "en",
        "title": "Friday June 7, 2024",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://controls.papercept.net/images/icuas/icuas24.webp",
            "https://controls.papercept.net/images/icuas/icuas_white.png",
            "https://controls.papercept.net/images/pc_logo_small.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "FrA1 Regular Session, MIKIS 1 Add to My Program Swarms II Chair: Leong, Wai LunNational University of Singapore Co-Chair: Mejias Alvarez, LuisQueensland University of Technology 10:30-10:50, Paper FrA1.1 Add to My Program Decentralized Control of UAV Swarms for Bandwidth-Aware Video Surveillance Using NMPC Rezaei Naghadehi, MohammadaminPolitecnico Di Bari Manfredi, GioacchinoPolitecnico Di Bari Racanelli, Vito AndreaPolitecnico Di Bari De Cicco, LucaPolitecnico Di Bari Mascolo, SaverioPolitecnico Di Bari\n\nKeywords: Networked Swarms, Autonomy, Swarms\n\nAbstract: This paper proposes a framework for controlling a drone swarm to achieve two goals: i) covering a desired region of interest through onboard cameras that capture videos to be sent in real-time to a Ground Control Station (GCS), and ii) ensuring the highest video quality possible given the available Internet network bandwidth. Notice that the quality of received videos depends on both the available bandwidth, which directly influences video encoding bitrate, and the altitude of drones, which influences pixel density. Thus, contrary to the conventional assumption of uniform drone altitudes, we let drones to track a reference altitude that is function of the time-varying available bandwidth to improve visual quality. To achieve the aforementioned goals, we propose a leader-follower multi-agent system formation control problem. In this setup, the leader tracks a desired path using Nonlinear Model Predictive Control (NMPC) to cover the area of interest. Follower agents track the leader using NMPC, aiming at maximizing both the total coverage area and the quality of the videos sent to the GCS, considering the constraints imposed by the network available bandwidth. At the same time, we formulate the NMPC problem to ensure that the swarm maintains a formation characterized by a given overlap percentage between the videos captured by the drones while avoiding collisions. This allows dynamical stitching of the received videos at the GCS, enabling the execution of computer vision algorithms for tasks such as object detection and surveillance.\n\n10:50-11:10, Paper FrA1.2 Add to My Program Decentralized Connectivity Maintenance for Multi-Agent Systems Using Control Barrier Functions Bhatia, PranjalIIIT Delhi Basu Roy, SayanIndraprastha Institute of InformationTechnology, Delhi (IIITD) Baliyarasimhuni, Sujit, PIISER Bhopal Mejias Alvarez, LuisQueensland University of Technology Mcfadyen, AaronQueensland University of Technology\n\nKeywords: Networked Swarms, Control Architectures, Fail-Safe Systems\n\nAbstract: This paper proposes a decentralized control barrier function (CBF) as a solution for distributed global connectivity maintenance for a multi-agent system (MAS). Using a combination of Fiedler value estimation (the second smallest eigenvalue of the Laplacian) and control barrier functions, the proposed method can ensure that agents will remain globally connected in a distributed fashion. The major advantage of using CBF is that it allows us to consider multiple objectives and constraints at the same time. Moreover, it enables the agent connectivity to be increased to a desired level. Mathematical analysis and simulation results demonstrate the efficacy of the approach.\n\n11:10-11:30, Paper FrA1.3 Add to My Program Multi-UAV Distributed Control for Reconfigurable Formations Skantzikas, KostasGrenoble INP Briñón Arranz, LaraGIPSA-Lab Susbielle, PierreGrenoble-INP UGA GIPSA-Lab Marchand, NicolasGIPSA-Lab CNRS\n\nKeywords: Networked Swarms, Swarms\n\nAbstract: This paper deals with cooperative formation control design for multi-UAVs. A new control strategy is developed to steer a group of robots to three kind of evenly spaced formations: circular, linear and circular sector. Our distributed approach enables real-time formation reconfiguration when the parameters of the formations change or when a robot leaves the formation. Communication among robots is used to maintain the robots equally spaced in the desired formation and to avoid collisions during the reconfigurations. Real world experiments with four mini aerial vehicles demonstrate the efficacy of the proposed formation control strategy.\n\n11:30-11:50, Paper FrA1.4 Add to My Program A Highly Scalable, Robust and Decentralized Approach for Multi-UAV Persistent Surveillance Cao, JiaweiNational University of Singapore Leong, Wai LunNational University of Singapore Teo, RodneyNational University of Singapore\n\nKeywords: Networked Swarms, Swarms, UAS Applications\n\nAbstract: Multi-robot patrolling is known to be challenging, especially in a decentralized manner. The state-of-the-art decentralized approaches are either suboptimal or usually require exchange of information that would potentially limit their scalability. This paper presents a novel decentralized approach of high scalability and robustness to multi-UAV persistent surveillance. Our solution decentralizes a cyclic strategy while considering communication constraints. We give a theoretical derivation of the decentralized algorithm with convergence analysis. In addition, we consider practical issues such as motion constraints and potential livelocks in our implementation. The proposed approach is extensively tested and analyzed in a medium-fidelity swarm simulator to minimize the gap between simulation and real experiments.\n\n11:50-12:10, Paper FrA1.5 Add to My Program Multi-Agent Reinforcement Learning Based Drone Guidance for N-View Triangulation Gavin, TimothéeThales LAS Lacroix, SimonLAAS/CNRS Bronz, MuratENAC\n\nKeywords: Swarms, Autonomy, UAS Applications\n\nAbstract: This article presents a novel approach for controlling a swarm of drones that can track the location of a flying target using onboard omnidirectional cameras. The drones use Multi-Agent Reinforcement Learning (MARL) to learn decentralized policies that optimize their formation and motion around the target, minimizing the uncertainty in the triangulated position. We design a reward function that encourages the trackers to minimize the trace of the covariance matrix of the triangulated position, which is derived from an analytical model of uncertainty propagation. We use Multi-Agent PPO (MAPPO), an extension of Proximal Policy Optimization (PPO) to the multi-agent setting, to train the policies using this common reward function that encourages good formation and avoids collisions. We validate our approach in simulation and real-flight experiments, demonstrating its effectiveness and potential in enhancing autonomous multi-drone coordination for precise tracking.\n\n12:10-12:30, Paper FrA1.6 Add to My Program Trajectory Tracking with Obstacle Avoidance for Autonomous UAV Swarms Based on Distributed Model Predictive Control Vavelidou, DespoinaUniversity of West Attica Protoulis, TeoUniversity of West Attica Alexandridis, AlexUniversity of West Attica\n\nKeywords: Swarms, Control Architectures, Navigation\n\nAbstract: Multi-agent quadcopter systems, a specialized class of unmanned aerial vehicles (UAVs), have become key players in various industries, showing potential for further growth. However, the inherently nonlinear and complex behavior of quadcopters, coupled with the need for collision and obstacle avoidance within the swarm, while simultaneously achieving collective goals, poses significant challenges for efficient control. Trajectory tracking - a particularly demanding task for swarms - requires a delicate balance between precise tracking and safe navigation. In this work, we address the challenge of trajectory tracking for multi-agent quadcopter configurations through a novel distributed model predictive control (DMPC) framework, with individual local controllers for each agent. For a balanced control scheme, we employ both PID controllers for angle regulation and linear adaptive MPC (LAMPC) controllers for three-dimensional position control. The local MPC schemes ensure safe trajectory tracking, without the need to use predetermined reference trajectories for each agent and predefined formation strategies. Simulation results of the proposed framework demonstrate advanced robustness and dynamic adaptation to unpredicted situations.\n\nFrA2 Regular Session, MIKIS 2 Add to My Program UAS Communications Chair: Ellinas, GeorgiosUniversity of Cyprus Co-Chair: Coopmans, CalvinUtah State University 10:30-10:50, Paper FrA2.1 Add to My Program SUAS Command-And-Redundant-Control Communications System with ROS 2 Data Bridge for Aerial Remote Sensing Rapid Development Coopmans, CalvinUtah State University Snider, Richard M.Utah State University Slack, StocktonUtah State University Beckwith, A. J.Utah State University\n\nKeywords: Payloads, Integration, Air Vehicle Operations\n\nAbstract: As small, uncrewed systems (sUAS) grow in popularity and in number, larger and larger drone aircraft will become more common--up to the FAA limit of 55 pound gross take-off weight (GTOW) and beyond. Due to their larger payload capabilities, longer flight time, and better safety systems, autonomous systems that maximize CFR 14 Part 107 flight drone operations regulations will become more common, especially for operations such as imagery or other data collection which scale well with longer flight times and larger flight areas. In this new paper, a unique all-electric 55-pound VTOL transition fixed-wing sUAS specifically engineered for scientific data collection named ``GreatBlue'' is presented, along with systems, communications, scientific payload, data collection and processing, package delivery payload, ground control station, and mission simulation system. Able to fly for up to 2.5 hours while collecting multispectral remotely-sensed imagery, the unique GreatBlue system is shown, along with a package delivery flight example, flight data from two scientific data collection flights over California almond fields and a Utah Reservoir are shown including flight plan vs. as-flown.\n\n10:50-11:10, Paper FrA2.2 Add to My Program Real-Time Mapping for Teleoperation Systems in VR of Unmanned Aerial Vehicles Ramírez, GermánCentro De Investigaciones En Óptica Verdìn, Rodolfo IsaacCentro De Investigaciones En òptica Flores, GerardoCenter for Research in Optics\n\nKeywords: Simulation, Perception and Cognition, UAS Communications\n\nAbstract: This study presents the development of virtual environments as control centers for remote teleoperation tasks of unmanned aerial vehicles (UAVs). Initially, our focus lies on reconstructing outdoor environments using a ZED mini stereo camera and reconstructing them through point cloud techniques. The virtual environment is hosted in UNITY, a widely recognized platform for designing virtual reality (VR) video games. Within this environment, a digital twin UAV is embedded, tasked with replicating the real positions and orientations of the vehicle. To achieve this, we propose using PID and PD control for the positions and rotations of the virtual vehicle, allowing it to follow the desired position, in this case, the real position of the vehicle. A series of experiments were conducted in outdoor and indoor environments to validate the functionality of this approach.\n\n11:10-11:30, Paper FrA2.3 Add to My Program Human Factors Issues of Limited Connectivity in Advanced UAS Operations: Insights and Prospects Karvonen, HannuVTT Technical Research Centre of Finland Kramar, VadimVTT Technical Research Centre of Finland Anttonen, AnttiVTT Höyhtyä, MarkoVTT Technical Research Centre of Finland Ltd Järvenpää, MikaNokia Solutions and Networks Oy\n\nKeywords: UAS Communications, Air Vehicle Operations, Airworthiness\n\nAbstract: This paper presents an assessment of relevant human factors issues of advanced unmanned aircraft systems (UAS), which are affected by limited data connectivity. Based on an earlier literature review, we categorize these issues under three aspects, namely system design, human factors evaluation, and operation process. Under each aspect, we examine in detail the pertinent human factors engineering insights regarding unmanned aircraft systems and their connectivity. We also present prospects for future research by listing relevant human factors-related research questions for each aspect regarding limited connectivity in UAS operations. A key conclusion of the paper is that similar human factors issues, such as automation awareness and trust, apply for advanced UAS operations as they do to other well-studied automated safety-critical environments.\n\n11:30-11:50, Paper FrA2.4 Add to My Program Dynamic Deployment and Control of an NDN Network for Military Multi-UAVs Based Surveillance Applications A. R. da Cruz, OtávioFederal University of Rio Grande Do Sul Pereira, Carlos EduardoFederal University of Rio Grande Do Sul Silva, Antonio Arlis Santos daFederal University of Rio Grande Do Sul Javidi da Costa, João PauloHochschule Hamm-Lippstadt - HSHL Milheiro Mendes, Paulo JorgeAirbus Pignaton de Freitas, EdisonFederal University of Rio Grande Do Sul\n\nKeywords: UAS Communications, Networked Swarms, Swarms\n\nAbstract: The military usage of Unmanned Aerial Vehicles (UAVs) has garnered attention, especially after their employment in the Ukrainian war. Despite the most commented lethal usage, they have many other applications from which surveillance for imagery acquisition is one of primal importance. Using a stand-alone UAV for this purpose is well-known, but to cope with the scale of battlefield operations, using multi-UAV systems is an asset of great value. However, these systems rely on ad hoc networks that require solutions beyond conventional ones based on the Internet Protocol (IP). This paper addresses this concern by proposing a communication support mechanism for multi-UAV military surveillance systems based on the Information-Centric Networks (ICN) paradigm. The proposed approach consists of the dynamic deployment of an ICN network based on microservices architecture, where the communication services of each UAV are deployed according to their resources. The solution is validated in a simulated battlefield scenario where a surveillance UAV provides data demanded by other nodes. The results demonstrate that the proposed solution minimizes the data delivery delays by successfully deploying the customized set of microservices to support the transmission, even when a UAV with a low battery level is replaced at runtime.\n\n11:50-12:10, Paper FrA2.5 Add to My Program Coordinating Cooperative Perception in Urban Air Mobility for Enhanced Environmental Awareness Häckel, TimoHamburg University of Applied Sciences von Roenn, LucaHelmut Schmidt University Hamburg Juchmann, NemoHamburg University of Applied Sciences Fay, AlexanderHelmut-Schmidt-Universität Akkermans, RinieHamburg University of Applied Sciences Tiedemann, TimHamburg University of Applied Sciences Schmidt, Thomas C.Hamburg University of Applied Sciences\n\nKeywords: UAS Communications, Perception and Cognition, Simulation\n\nAbstract: The trend for Urban Air Mobility (UAM) is growing with prospective air taxis, parcel deliverers, and medical and industrial services. Safe and efficient UAM operation relies on timely communication and reliable data exchange. In this paper, we explore Cooperative Perception (CP) for Unmanned Aircraft Systems (UAS), considering the unique communication needs involving high dynamics and a large number of UAS. We propose a hybrid approach combining local broadcast with a central CP service, inspired by centrally managed U-space and broadcast mechanisms from automotive and aviation domains. In a simulation study, we show that our approach significantly enhances the environmental awareness for UAS compared to fully distributed approaches, with an increased communication channel load, which we also evaluate. These findings prompt a discussion on communication strategies for CP in UAM and the potential of a centralized CP service in future research.\n\n12:10-12:30, Paper FrA2.6 Add to My Program Performance Evaluation of a Prototype UAV-Based Secure Communication System Employing ROS and Chaotic Communications Souli, N.University of Cyprus Stavrinides, StavrosInternational Hellenic University Kardaras, PanagiotisUniversity of Cyprus Picos, RodrigoDepartment of Industrial Engineering and Construction, Universit Karatzia, MariaKIOS Research and Innovation Center of Excellence and the Depart Kolios, PanayiotisUniversity of Cyprus Ellinas, GeorgiosUniversity of Cyprus\n\nKeywords: UAS Communications, Security, UAS Applications\n\nAbstract: Providing secure communications has become imperative in single- and multi-agent systems that need to ensure the integrity, confidentiality, and availability of the transmitted data, especially when these systems are employed in critical infrastructure applications. This work presents a novel approach for secure communications between a group of unmanned aerial vehicles (UAVs) to safeguard the confidentiality of the data exchanged in such a multi-agent system, employing the robot operating system (ROS), a virtual private network (VPN), and a chaotic based communication architecture. Specifically, a custom ROS-based framework is developed to collect and distribute the UAV sensor data, while a VPN network is deployed as the first layer of security for the system. Subsequently, a lightweight chaotic-based module is incorporated as the second layer of security to enable secure communications between the UAVs in real time. To evaluate the proposed system, a prototype multi-UAV system is designed, implemented, and extensively tested in a real-world environment. The proposed system achieves secure real-time communications, with low power consumption and minimal processing resources (CPU and RAM usage), demonstrating its applicability for the energy-constrained UAV-based system under consideration.\n\nFrA3 Regular Session, KAM Add to My Program Perception and Cognition Chair: Alkendi, YusraTechnology Innovation Institute Co-Chair: Karampinis, VasileiosNational Technical University of Athens(NTUA) 10:30-10:50, Paper FrA3.1 Add to My Program LiDAR Stereo Visual Inertial Pose Estimation Based on Feedforward and Feedbacks Yang, WenyuThe Hong Kong Polytechnic University Hu, HaochenThe Hong Kong Polytechnic University Tse, Kwai-WaThe Hong Kong Polytechnic University Chen, ShengyangThe Hong Kong Polytechnic University Wen, WeisongThe Department of Aeronautical and Aviation Engineering, the Hon Wen, Chih-YungThe Hong Kong Polytechnic University\n\nKeywords: Perception and Cognition, Autonomy, Sensor Fusion\n\nAbstract: In this paper, we present a LiDAR-visual-inertial Odometry (LVIO) based on feedforward and feedbacks. Compared to traditional Kalman filter-based methods or optimization-based methods for sensor fusion, the proposed system achieves sensor fusion through feedforward and feedbacks. This system, named Feedforward-feedback LiDAR Visual Inertial System (FLiVIS) consists of a Visual-Inertial Odometry (VIO) subsystem and a LiDAR-Inertial Odometry (LIO) subsystem, these two subsystems are coupled through complementary filters. Instead of directly integrating gyroscope data and accelerometer data, our framework leverages the complementary nature of gyroscope and accelerometer measurements. FLiVIS is evaluated on public datasets, it achieves a relative translation error of 0.68% on the KITTI dataset and 0.138 m absolute translation error on the NTU-Viral dataset, respectively. The experiment results demonstrate the accuracy and robustness of FLiVIS with respect to other state-of-the-art counterparts. FLiVIS is capable of accommodating both multi-line spinning LiDARs and emerging solid-state LiDARs, which employ distinct scanning patterns. Additionally, it can perform real-time operations on a range of platforms, from laptops to upboard processors.\n\n10:50-11:10, Paper FrA3.2 Add to My Program FlyNeRF: NeRF-Based Aerial Mapping for High-Quality 3D Scene Reconstruction Dronova, MariaSkolkovo Institute of Science and Technology Cheremnykh, VladislavSkolkovo Institute of Science and Technology Kotcov, AlexeySkolkovo Institute of Science and Technology Fedoseev, AlekseySkolkovo Institute of Science and Technology Tsetserukou, DzmitrySkolkovo Institute of Science and Technology\n\nKeywords: Perception and Cognition, Micro- and Mini- UAS, Path Planning\n\nAbstract: Current methods for 3D reconstruction and environmental mapping frequently face challenges in achieving high precision, highlighting the need for practical and effective solutions. In response to this issue, our study introduces FlyNeRF, a system integrating Neural Radiance Fields (NeRF) with drone-based data acquisition for high-quality 3D reconstruction. Utilizing unmanned aerial vehicles (UAV) for capturing images and corresponding spatial coordinates, the obtained data is subsequently used for the initial NeRF-based 3D reconstruction of the environment. Further evaluation of the reconstruction render quality is accomplished by the image evaluation neural network developed within the scope of our system. Depending on the results of the image evaluation module, our algorithm determines the position for additional image capture, thereby improving the reconstruction quality.\n\nThe neural network introduced for render quality assessment demonstrates an accuracy of 97%. Furthermore, our adaptive methodology enhances the overall reconstruction quality, resulting in an average improvement of 2.5 dB in Peak Signal-to-Noise Ratio (PSNR) for the 10{%} quantile. The FlyNeRF demonstrates promising results, offering advancements in such fields as environmental monitoring, surveillance, and reconstruction of digital twins, where high-fidelity 3D reconstructions are crucial.\n\n11:10-11:30, Paper FrA3.3 Add to My Program Dynamic-Obstacle Relative Localization Using Motion Segmentation with Event Cameras Alkendi, YusraTechnology Innovation Institute Abdulhay, OussamaKhalifa University of Science and Technology Ahmed Humais, MuhammadKhalifa University of Science and Technology Azzam, RanaKhalifa University of Science and Technology Seneviratne, LakmalKhalifa University of Science and Technology Zweiri, YahyaKhalifa University\n\nKeywords: Perception and Cognition, Navigation, UAS Applications\n\nAbstract: The ability to detect and localize dynamic obstacles within a robot's surroundings while navigating low-light environments is crucial for ensuring robot safety and the continuity of its mission. Event cameras excel in capturing motion within scenes clearly without motion blur, due to their asynchronous nature. These sensors are distinguished by their ability to trigger events with microsecond temporal resolution, possess a high dynamic range, and achieve low latency. In this work, we introduce a framework for a drone equipped with an event camera, named E-DoRL. This framework is specifically designed to address the challenge of detecting and localizing dynamic obstacles that are not previously known, ensuring safe navigation. E-DoRL processes raw event streams to estimate the relative position between a moving robot and dynamic obstacles. It employs a Graph Transformer Neural Network (GTNN) to extract spatiotemporal correlations from event streams, identifying active event pixels of moving objects without prior knowledge of scene topology or camera motion. Based on these identifications, E-DoRL is designed to determine the relative position of moving obstacles with respect to a dynamic unmanned aerial vehicle (UAV). E-DoRL outperformed state-of-the-art frame-based object tracking algorithms in good light scenarios (100 lux), by achieving 59.7% and 25.9% reduction in the mean absolute error (MAE) associated with the X and Y estimates, respectively. Additionally, when tested under much lower light illuminance (0.8 lux), E-DoRL consistently maintained its performance without any degradation, as opposed to image-based techniques that are highly sensitive to lighting conditions.\n\n11:30-11:50, Paper FrA3.4 Add to My Program Autonomous UAV Volcanic Plume Sampling Based on Machine Vision and Path Planning Rolland, Edouard George AlainUniversity of Southern Denmark Grøntved, Kasper Andreas RømerUniversity of Southern Denmark Christensen, Anders LyhneUniversity of Southern Denmark Watson, Iain MatthewUniversity of Bristol Richardson, ThomasUniversity of Bristol\n\nKeywords: Perception and Cognition, Path Planning, UAS Applications\n\nAbstract: Drones currently serve as a valuable tool for in-situ sampling of volcanic plumes, but they still involve manual piloting. In this paper, we enable autonomous dual plume sampling by using a machine vision model to detect eruptions. When an eruption is detected, a sampling trajectory is automatically generated to intercept the plume twice to collect comparative samples. The machine vision model is developed by training a YOLOv8 object detection model thanks to a database of 1505 images that feature labelled plumes. The obtained average precision value of the model's plume class, at 90.7%, is comparable to that of state-of-the-art models for wildfire smoke monitoring. The performance of this method is assessed using a software-in-the-loop simulation of the drone and a simulated plume model. Although the results confirm the efficacy of using a machine vision model for triggering an onboard path-planning algorithm, it also suggests the potential for a hybrid strategy that integrates visual servoing with our proposed path-planning approach.\n\n11:50-12:10, Paper FrA3.5 Add to My Program Ensuring UAV Safety: A Vision-Only and Real-Time Framework for Collision Avoidance through Object Detection, Tracking, and Distance Estimation Karampinis, VasileiosNational Technical University of Athens(NTUA) Arsenos, AnastasiosNational Technical University of Athens Filippopoulos, OrfeasHellenic Drones S.A Petrongonas, EvangelosNational Technical University of Athens Skliros, ChristosHellenic Drones S.A Kollias, DimitriosQueen Mary University of London Kollias, StefanosNational Technical University of Athens Voulodimos, AthanasiosNational Technical University of Athens\n\nKeywords: Perception and Cognition, See-and-avoid Systems, Autonomy\n\nAbstract: In the last twenty years, unmanned aerial vehicles (UAVs) have garnered growing interest due to their expanding applications in both military and civilian domains. Detecting non-cooperative aerial vehicles with efficiency and estimating collisions accurately are pivotal for achieving fully autonomous aircraft and facilitating Advanced Air Mobility (AAM). This paper presents a deep-learning framework that utilizes optical sensors for the detection, tracking, and distance estimation of non-cooperative aerial vehicles. In implementing this comprehensive sensing framework, the availability of depth information is essential for enabling autonomous aerial vehicles to perceive and navigate around obstacles. In this work, we propose a method for estimating the distance information of a detected aerial object in real- time using only the input of a monocular camera. In order to train our deep learning components for the object detection, tracking and depth estimation tasks we utilize the Amazon Airborne Object Tracking (AOT) Dataset. In contrast to previous approaches that integrate the depth estimation module into the object detector, our method formulates the problem as image-to-image translation. We employ a separate lightweight encoder-decoder network for efficient and robust depth estimation. In a nutshell, the object detection module identifies and localizes obstacles, conveying this information to both the tracking module for monitoring obstacle movement and the depth estimation module for calculating distances. Our approach is evaluated on the Airborne Object Tracking (AOT) dataset which is the largest (to the best of our knowledge) air-to-air airborne object dataset.\n\n12:10-12:30, Paper FrA3.6 Add to My Program Vision-Only Pose and Relative Distance Estimation for Leading Quadrotor UAV from Following UAV Xu, XiangpengSun Yat-Sen University Chujun, LiSun Yat-Sen University Zhuge, ShengSun Yat-Sen University Yang, XiaSun Yat-Sen University Khoo, Boo CheongNational University of Singapore Srigrarom, SutthiphongNational University of Singapore Chan, Wee KiatNational University of Singapore Leong, Wai LunNational University of Singapore Lin, BinFujian Normal University Zhang, XiaohuSun Yat-Sen University\n\nKeywords: See-and-avoid Systems, Perception and Cognition, Swarms\n\nAbstract: Multi-rotor unmanned aerial vehicle (UAV) systems have been applied in many scenarios to improve the flexibility and effectiveness of specific tasks. Common tasks include pursuing, intercepting and training. To increase efficiency and independent operation, particularly by reducing reliance on wireless communication and enhancing stability during cooperative control of systems, this paper introduces a vision-only and universal method for pose estimation and relative distance calculation. Firstly, key components of a UAV are detected through a two-step method. A novel feature encoding method is presented to establish the 2D-3D correspondence with the known 3D structure of UAVs and solve the Perspective-n-Point (PnP) problem. To mitigate misdetections in air-to-air scenarios, a robust auto-weighting Levenberg-Marquardt (AWLM) algorithm was integrated into pose estimation process. Secondly, with the detection of UAVs keypoints, the UAV pose and relative distance from the observer can be estimated through geometry. Flight experiments of a two-UAV leader-follower system in GPS-denied environments have been conducted to verify the efficacy of the proposed approach. The results show that the calculation error is less than 5%, i.e. less than a meter at relative distances of up to 20 meters, achieved at a processing speed of 30 milliseconds per frame. This signifies the highest precision and fastest processing speed among several similar methods. Keywords: Leader-follower UAV Systems, Multi-rotors UAVs, Motion Perception, Robotics Machine Vision, 6D Pose Estimation.\n\nFrA4 Regular Session, DILOVO Add to My Program Navigation Chair: Sarcinelli-Filho, MárioFederal University of Espirito Santo Co-Chair: Lee, KyumanKyungpook National University 10:30-10:50, Paper FrA4.1 Add to My Program Active Heading Planning for Improving Visual-Inertial Odometry Lee, JoohyukKyungpook National University Lee, KyumanKyungpook National University\n\nKeywords: Navigation\n\nAbstract: Visual-inertial odometry (VIO) is a technique to estimate the motion of a vehicle platform by fusing camera and inertial sensor data. It operates effectively in GPS-denied environments such as indoors and is widely utilized in applications like autonomous navigation of unmanned aerial vehicles (UAVs) due to its real-time performance and high localization accuracy. However, since VIO relies on textures in the environment or features extracted from image frames, localization may easily fail if the number of feature points in the image is insufficient or the UAV faces a low-texture environment. To address these issues, we propose an active VIO algorithm by planning heading angles autonomously. This algorithm improves VIO accuracy and maintains robust localization even in an unknown environment by employing heading planning to acquire more feature points in the subsequent image frames. To achieve this, we first divide an image frame into several sections and count the number of feature points in each section. Next, we determine the desired heading angle based on the feature-occupied ratio of each section. The proposed approach is validated in various cases in a simulation environment that mimics an indoor warehouse.\n\n10:50-11:10, Paper FrA4.2 Add to My Program Riding the Rollercoaster: Improving UAV Piloting Skills with Augmented Visualization and Collaborative Planning Franceschini, RiccardoEurecat, Centre Tecnològic De Catalunya, 08290 Cerdanyola Del Va Javier, RodriguezEurecat Fumagalli, MatteoDanish Technical University Cayero, Julian CayeroEurecat\n\nKeywords: Navigation, Autonomy, Integration\n\nAbstract: Operating unmanned aerial vehicles (UAVs) in complex environments can be challenging, particularly for inexperienced operators. This paper introduces a method aimed at enhancing the piloting experience by incorporating an intermediary processing layer between the remote controller and the drone. The presented approach empowers operators to control both the speed and direction of the UAV along a secure path, which is continuously computed and overlaid onto the operator's camera stream. The UAV autonomously plans and executes this path, adapting to the operator's commands and environmental changes. The primary aim of this proposed solution is to enhance the operator's situational awareness, perception, as well as the safety and efficiency of UAV navigation. The paper outlines the system and methodology employed, showing its ability to operate at a high enough frequency to enable seamless user interactions. Furthermore, to validate the effectiveness of this approach, a real-world test and a user-based experimental study conducted in a simulation environment with an audience comprising varying levels of pilot expertise have been carried out.\n\n11:10-11:30, Paper FrA4.3 Add to My Program Local Gaussian Modifiers (LGMs): UAV Dynamic Trajectory Generation for Onboard Computation Fernandez-Cortizas, MiguelUniversidad Politecnica De Madrid Perez-Saura, DavidUPM Perez-Segui, RafaelUniversidad Politécnica De Madrid Rodriguez-Vazquez, JavierUniveersidad Politéccnica De Madrid Cely, Juan S.Rey Juan Carlos University Campoy, PascualUniversidad Politecnica Madrid\n\nKeywords: Navigation, Autonomy, Reliability of UAS\n\nAbstract: Agile autonomous drones are becoming increasingly popular in research due to the challenges they represent in fields like control, state estimation, or perception at high speeds. When all algorithms are computed onboard the UAV, computational limitations make the task of agile flight even more difficult.\n\nOne of the most computationally expensive tasks in agile flight is the generation of optimal trajectories. When these trajectories must be updated online due to changes in the environment or uncertainties, this high computational cost may result in insufficient time to reach the desired waypoints, which could cause a drone crash in cluttered environments.\n\nIn this paper, we present Local Gaussian Modifiers (LGMs), a fast and lightweight way of modifying computationally heavy trajectories when recalculating them in time is not possible due to computational limitations. Moreover, we propose a strategy for deciding when is convenient to use these modifiers or recalculate the whole trajectory based on an estimation of the computational time of this trajectory generation. A trajectory blending procedure is also proposed to ensure smoothness in UAV control when a new trajectory is computed.\n\nOur approach was validated in simulation, being able to pass through a race circuit with moving gates, achieving speeds up to 16.0 m/s. Real flight validation was also performed achieving speeds up to 4.0 m/s in a fully autonomous pipeline using onboard computing.\n\n11:30-11:50, Paper FrA4.4 Add to My Program UAV-Assisted Visual SLAM Generating Reconstructed 3D Scene Graphs in GPS-Denied Environments Radwan, AhmedUniversity of Luxembourg Tourani, AliUniversity of Luxembourg Bavle, HridayPhD Student at Universidad Politecnica De Madrid Voos, HolgerUniversity of Luxembourg Sanchez-Lopez, Jose-LuisSnT, University of Luxembourg\n\nKeywords: Navigation, Perception and Cognition, Sensor Fusion\n\nAbstract: Aerial robots play a vital role in various applications where the situational awareness of the robots concerning the environment is a fundamental demand. As one such use case, drones in GPS-denied environments require equipping with different sensors (e.g., vision sensors) that provide reliable sensing results while performing pose estimation and localization. In this paper, reconstructing the maps of indoor environments alongside generating 3D scene graphs for a high-level representation using a camera mounted on a drone is targeted. Accordingly, an aerial robot equipped with a companion computer and an RGB-D camera was built and employed to be appropriately integrated with a Visual Simultaneous Localization and Mapping (VSLAM) framework proposed by the authors. To enhance the situational awareness of the robot while reconstructing maps, various structural elements, including doors and walls, were labeled with printed fiducial markers, and a dictionary of the topological relations among them was fed to the system. The VSLAM system detects markers and reconstructs the map of the indoor areas, enriched with higher-level semantic entities, including corridors and rooms. Another achievement is generating multi-layered vision-based situational graphs containing enhanced hierarchical representations of the indoor environment. In this regard, integrating VSLAM into the employed drone is the primary target of this paper to provide an end-to-end robot application for GPS-denied environments. To show the practicality of the system, various real-world condition experiments have been conducted in indoor scenarios with dissimilar structural layouts. Evaluations show the proposed drone application can perform adequately w.r.t. the ground-truth data and its baseline.\n\n11:50-12:10, Paper FrA4.5 Add to My Program Elevation Angle Redundancy from Barometric Altitude in Multipath-Affected Phased Array Radio Navigation of UAVs Okuhara, MikaNorwegian University of Science and Technology Bryne, Torleiv HålandNorwegian Univ. of Science and Technology Gryte, KristofferNorwegian University of Science and Technology Johansen, Tor ArneNorweigian Univ. of Sci. & Tech\n\nKeywords: Navigation, Sensor Fusion\n\nAbstract: Phased Array Radio Systems (PARS) are a promising alternative or backup to Global Navigation Satellite Systems (GNSS) based positioning, offering higher signal-to-noise ratio (SNR), narrow beam communication and robust encryption to mitigate these risks. However, PARS systems face multipath challenges, particularly when radio signals are reflected off horizontal surfaces such as flat fields, lakes and oceans, affecting the accuracy of elevation angle measurements.\n\nThe proposed solution introduces the concept of a recalculated elevation angle, inspired by grazing angle determination, as an alternative to the potentially uncertain elevation angle provided by PARS. Derived from PARS range measurements, barometric altitude, and the effective Earth radius, the recalculated elevation angle aims to overcome the limitations of previous methods that failed to fully consider the Earth's curvature, leading to inaccuracies in elevation angle estimates. Our approach uniquely incorporates the recalculated elevation angle into the PARS-aided inertial navigation system (INS), enhancing positioning accuracy, especially when the UAV is operating in close proximity to the ground antenna.\n\nThe paper evaluates the performance of the navigation system using the recalculated elevation angle using field test data. The root mean square vertical position error was improved by a factor of 7.5 with the proposed method compared to using multipath affected elevation measurement. The results show that the recalculated elevation angle is a viable alternative to the multipath affected measured elevation angle in PARS-based navigation.\n\n12:10-12:30, Paper FrA4.6 Add to My Program Localization of Unmanned Aircraft Systems Using Bio-Inspired Algorithms: An Experimental Study Araujo-Neto, WolmarUniversidade Federal Do Espírito Santo Villa, Daniel Khede DouradoFederal University of Espírito Santo Sarcinelli-Filho, MárioFederal University of Espirito Santo\n\nKeywords: Navigation, UAS Applications\n\nAbstract: This article describes the integrated application of the bio-inspired optimization algorithm LBBA and Digital Compass to enhance the localization of drones in autonomous missions. The work presents a approach covering Airworthiness, Localization and Sensor Fusion.\n\nThe LBBA algorithm, using data from a LIDAR sensor and information from a Digital Compass, shows significant advances in the safety and effectiveness of autonomous operations on mobile bases. Now, the proposal is to use this advantage to assist in locating drones on a known map.\n\nThis study contributes to the continuous evolution of autonomous drone technology, promoting a more effective and secure integration of these systems in laboratory testing environments. The results suggest that the combination of 2D localization from a ground robot with interaction with an aerial one offers a robust and reliable solution for the precise localization of drones, paving the way for future innovations in the field of unmanned aerial vehicles.\n\nFrB1 Invited Session, MIKIS 1 Add to My Program Aerial Robotics in Inspection and Maintenance Operations I Chair: Ruggiero, FabioUniversità Degli Studi Di Napoli \"Federico II\" Co-Chair: Zoric, FilipUniversity of Zagreb, Faculty of Electrical Engineering and Computing Organizer: Gabellieri, ChiaraUniversity of Twente Organizer: Silano, GiuseppeCzech Technical University in Prague Organizer: Selvaggio, MarioUniversity of Naples Federico II 14:00-14:20, Paper FrB1.1 Add to My Program Shared-Control Teleoperation Methods for a Cable-Suspended Dual-Arm Unmanned Aerial Manipulator (I) Selvaggio, MarioUniversity of Naples Federico II Esposito, FedericoUniversity of Naples Federico II Lippiello, VincenzoUniversita' Di Napoli Federico II Ruggiero, FabioUniversità Degli Studi Di Napoli \"Federico II\"\n\nKeywords: Aerial Robotic Manipulation, Control Architectures, Simulation\n\nAbstract: This paper introduces two shared-control teleoperation methods for remotely executing long-reach tasks with a cable-suspended dual-arm unmanned aerial manipulator. The proposed techniques aim to improve task performance and user experience during remote tasks involving interaction with the environment. Two application scenarios are envisioned: pushing against a flat surface to emulate in-contact inspection tasks of infrastructures, and object grasping to simulate debris removal in cluttered environments. The effectiveness of the two shared-control teleoperation methods is evaluated through a human-subjects study involving 10 participants commanding the simulated robot via a joystick interface. Statistical analysis demonstrates significant enhancements in task performance and system usability when using the proposed methods compared to standard teleoperation.\n\n14:20-14:40, Paper FrB1.2 Add to My Program A Model-Based Oscillation Suppression Approach for a Cable-Suspended Dual-Arm Aerial Manipulator (I) D'Ago, GiancarloEuropean Organization for Nuclear Research (CERN), University Of Selvaggio, MarioUniversity of Naples Federico II Marzio, ChiaraUniversity of Naples Federico II Buonocore, Luca RosarioCERN Suarez, AlejandroUniversity of Seville Gonzalez-Morgado, AntonioUniversidad De Sevilla Villanueva, JoseEscuela Técnica Superior De Ingeniería, Universidad De Sevilla Ollero, AnibalUniversidad De Sevilla - Q-4118001-I Ruggiero, FabioUniversità Degli Studi Di Napoli \"Federico II\"\n\nKeywords: UAS Applications, Aerial Robotic Manipulation\n\nAbstract: In aerial manipulators, the presence of cables between the aerial platform and the articulated system is beneficial to increase the distance between rotors blades and the obstacles in the workspace and absorb unavoidable impacts arising during the interaction with the environment. However, cables also produce pendulum-like oscillatory behaviour due to dynamic coupling and to the effect of external forces when the robot navigates in free space through the environment. This paper presents a model-based control approach for the suppression of oscillations in cable-suspended dual-arm aerial manipulators. Contrary to many oscillation suppression techniques that act on the suspension platform, we exploit the dynamics of the articulated system to achieve the same scope. A linear controller is devised applying a partial feedback linearization technique for the unactuated variables of our system, i.e. the cables. Simulation and experimental tests are carried out using a quadrotor equipped with a cable-suspended dual-arm system to validate our proposed framework. With our control technique drone-induced oscillations were reduced by up to 89%, with a settling time of 2.5 seconds.\n\n14:40-15:00, Paper FrB1.3 Add to My Program Autonomous Visual Inspection of Industrial Plants Using Unmanned Aerial Vehicles (I) Scognamiglio, VincenzoUniversity of Naples \"Federico II\" Caccavale, RiccardoUniversità Degli Studi Di Napoli Federico II Merone, PasqualeUniversity of Naples Federico II De Crescenzo, AlessandroNeabotics Srl Ruggiero, FabioUniversità Degli Studi Di Napoli \"Federico II\" Lippiello, VincenzoUniversita' Di Napoli Federico II\n\nKeywords: Autonomy, Navigation, UAS Applications\n\nAbstract: The development of autonomous systems has spurred numerous innovative inspection strategies. Some operations, such as monitoring the condition of industrial structures, typically entail significant deployment of human resources and pose risks to human safety. In this context, this paper presents a visual inspection framework that leverages unmanned aerial vehicles to explore designated facilities, identifying structural damages such as cracks or fissures for inspection. The proposed approach integrates autonomous navigation and high-level decision-making capabilities to effectively explore predefined points of interest within partially known environments and to select and inspect candidate spots for further analysis. The framework is validated through both simulated and real-world experiments conducted in GPS-denied environments, utilizing only onboard UAV capabilities.\n\n15:00-15:20, Paper FrB1.4 Add to My Program Efficient Development of Model-Based Controllers in PX4 Firmware: A Template-Based Customization Approach (I) D'Angelo, SimoneUniversità Degli Studi Di Napoli Federico II Pagano, FrancescaUniversità Degli Studi Di Napoli Federico II Longobardi, FrancescoUniversità Federico II Di Napoli Ruggiero, FabioUniversità Degli Studi Di Napoli \"Federico II\" Lippiello, VincenzoUniversita' Di Napoli Federico II\n\nKeywords: Control Architectures, Integration, UAS Applications\n\nAbstract: This paper introduces a refined iteration of the PX4 autopilot firmware tailored to support developers in integrating bespoke control algorithms alongside the existing control framework. The proposed methodology employs a template-driven approach and introduces two novel control modules, thereby enabling users to harness all firmware functionalities within their custom modalities, including the QGroundControl interface, while retaining all the standard modules and compatibility with the QGroundControl interface. With its transparent and adaptable structure, the software framework presented herein lays a robust groundwork for implementing tailored and specialized solutions across diverse aerospace domains. As a practical demonstration, we apply the developed firmware to the domain of inspection and maintenance, wherein it incorporates an admittance controller and a model-based control algorithm for a tiltable drone equipped with a sensorized tool. The efficacy and versatility of the proposed approach are validated through simulations and empirical trials conducted across multiple aerial platforms. The produced code is released to the community.\n\n15:20-15:40, Paper FrB1.5 Add to My Program An Experimentally Validated Model of the Propeller Force Accounting for Cross Influences on Multi-Rotor Aerial Systems (I) Bazzana, BarbaraUniversity of Twente Brantjes, RalphUniversity of Twente Gabellieri, ChiaraUniversity of Twente Franchi, AntonioUniversity of Twente\n\nKeywords: Multirotor Design and Control, Aerial Robotic Manipulation, Air Vehicle Operations\n\nAbstract: In this paper, we propose a model for the thrust coefficient of propellers that can take into account cross-influence between adjacent propellers. The aerodynamic interaction between propellers in multirotor aerial vehicles reduces the thrust they can produce. The influence between propellers depends on their relative positioning and orientation, which are taken into account by the proposed model. It is validated on measurements collected by a force sensor mounted on a propeller for different configurations of the adjacent propellers in a support structure. In this work, we focus on configurations with small relative orientations. Results show that the proposed model outperforms the traditional constant model in terms of thrust prediction on the data we collected, and it performs better than other models with fewer parameters, being the only one with less than 10% maximum percentage error.\n\n15:40-16:00, Paper FrB1.6 Add to My Program AI Enhanced Structural Health Monitoring with a Multi-Rotor Aerial Vehicle (I) Zoric, FilipUniversity of Zagreb, Faculty of Electrical Engineering and Comp Milas, AnaUniversity of Zagreb, Faculty of Electrical Engineering and Comp Petrovic, TamaraFER Kovacic, ZdenkoUniv. of Zagreb Orsag, MatkoUniversity of Zagreb, Faculty of Electrical Engineering and Comp\n\nKeywords: Perception and Cognition, UAS Applications, Technology Challenges\n\nAbstract: Roads, bridges, tunnels, railways and canals are crucial for the transportation of goods and people in modern society. Modern infrastructure is subject to damage and re- quires therefore regular inspection and maintenance to remain safe and functional. While this can be done manually, large parts of the mentioned infrastructure are hardly accessible, which is a main motivational factor for the use of multi- rotor aerial vehicles (MAVs) for inspection and maintenance tasks. MAVs, paired with novel deep learning computer vision techniques, such as instance segmentation, are emerging as an obvious choice for automating certain parts of structural health monitoring (SHM). In this manuscript, we provide an overview of available SHM datasets and how they can be utilized for the task of autonomous crack detection. We use available datasets to train and compare two neural network architectures for instance segmentation. The segmented crack instances are then localized in a global coordinate frame to perform autonomous mapping of the potentially dangerous infrastructure defects. Experimental studies demonstrate the effectiveness of the proposed SHM approach, which results in precisely localized infrastructure defects marked on the global map\n\nFrB2 Regular Session, MIKIS 2 Add to My Program Sensor Fusion Chair: Primatesta, StefanoPolitecnico Di Torino Co-Chair: Souli, N.University of Cyprus 14:00-14:20, Paper FrB2.1 Add to My Program Enhanced Altitude Estimation for Unmanned Aerial Vehicles in a GNSS-Denied Environment Minervini, AlessandroPolitecnico Di Torino Primatesta, StefanoPolitecnico Di Torino Guglieri, GiorgioPolitecnico Di Torino\n\nKeywords: Autonomy, Navigation, Sensor Fusion\n\nAbstract: GNSS-denied environments represent challenging environments for autonomous drones. Ensuring an accurate altitude estimate plays a crucial role in guaranteeing mission efficiency in such scenarios. The literature on autonomous drone localization in GNSS-denied environments relies on visual inertial odometry-based algorithms. However, the reliability of this technology cannot be guaranteed in poor features environments (omogeneous floor, white walls) or in high and low brightness conditions. Even applications adopting loop closure algorithms in combination with visual inertial odometry localization suffer from considerable position estimation drift in challenging environments. This paper aims to propose a methodology to address the altitude estimation problem for drones operating in GNSS-denied environments by combining a V-SLAM algorithm with the altitude measurements from a range finder. To account for ground inconsistencies due to varying terrain or obstacles, we have developed an Adaptive Kalman Filter. The Mahalanobis distance evaluation accomplishes the task of detecting these inconsistencies, enabling the filter to adapt and update states properly even in the presence of inconsistent range finder measurements. Experimental results demonstrate the effectiveness of the proposed solution in mitigating the drift accumulated by a purely V-SLAM algorithm.\n\n14:20-14:40, Paper FrB2.2 Add to My Program Vision-Aided Navigation for UAM Approach to Vertiports with Multiple Landing Pads Miccio, EnricoUniversity of Naples \"Federico II\" Veneruso, PaoloUniversity of Naples \"Federico II\" Opromolla, RobertoUniversity of Naples Federico II Fasano, GiancarmineUniversity of Naples \"Federico II\" Gentile, GiacomoCollins Aerospace Tiana, CarloCollins Aerospace\n\nKeywords: Autonomy, Navigation, Sensor Fusion\n\nAbstract: Abstract The vertiport concept has spread widely as the future aerodrome that will allow Vertical Take-Off and Landing vehicles to operate in complex and congested scenarios, such as those foreseen within the Urban Air Mobility framework. Possible vertiport configurations have been proposed by many government agencies such as European Union Aviation Safety Agency and the Federal Aviation Administration providing general design and development guidelines. This paper introduces an autonomous visual-aided navigation architecture able to estimate the aircraft state during approaches to vertiports exploiting visual observables gathered by multiple landing patterns. The implemented architecture exploits a Convolutional Neural Network for landing patterns detection; it then performs their discrimination and, for each of them, keypoints detection and identification to feed a perspective-n-point solver. The resulting pose measurements are input to an Extended Kalman Filter, which also processes data from an Inertial Measurement Unit and a Global Navigation Satellite System receiver. The implemented architecture is tested on synthetic and real data, showing the validity of the pattern discrimination techniques and the performance of the visual-aided filter varying the number of detected patterns along different approach trajectories.\n\n14:40-15:00, Paper FrB2.3 Add to My Program Creating a Robust and Expandable Framework for Cooperative Aerial Robots Georgiades, ChristosKIOS Research and Innovation Center of Excellence Souli, N.University of Cyprus Kolios, PanayiotisUniversity of Cyprus Ellinas, GeorgiosUniversity of Cyprus\n\nKeywords: Autonomy, Swarms, Sensor Fusion\n\nAbstract: This work focuses on the design and development of a microservice-based software framework for multi-drone autonomous systems, that is fault-tolerant, expandable, and easily monitored. The custom framework utilizes the Robot Operating System (ROS) and is applied on onboard embedded devices to command and control multiple unmanned aerial vehicles (UAV) in various scenarios, including autonomous flight missions, inter-process communication, as well as measurement fusion for mapping and localization purposes. Further, the proposed framework is implemented and tested in both hardware-in-the-loop simulations and real-world field tests to demonstrate and evaluate its performance. Specifically, the developed prototype is evaluated in scenarios where a swarm of UAVs is tasked to map a predefined area for search-and-rescue purposes and a scenario incorporating faults where one UAV loses its GPS signal and obtains relative positioning with the help of the rest of the UAVs in the swarm.\n\n15:00-15:20, Paper FrB2.4 Add to My Program A Joint Rogue Drone Detection and Tracking Fusing DOA and Passive Radar Measurements Souli, N.University of Cyprus Kardaras, PanagiotisUniversity of Cyprus Kolios, PanayiotisUniversity of Cyprus Ellinas, GeorgiosUniversity of Cyprus\n\nKeywords: Sensor Fusion, Security, Perception and Cognition\n\nAbstract: Advancements in unmanned aircraft systems (UASs) have led to a considerable increase in unlawful operations of these systems over critical infrastructures and public spaces. In this work, a system that is implemented utilizing software-defined radio and signals of opportunity (SOPs) and is based on the fusion of direction of arrival and passive radar sensor measurements is proposed to counter unlawful UAs/drone activities. Specifically, passive radar methodology applied on SOPs (data collection, disturbance cancellation, cross-ambiguity, and constant-false alarm rate detection functions), along with DOA measurements obtained via the multiple signal classification algorithm, are combined to detect and track the rogue UAS/target in an area under observation. A prototype implementation of the detection-and-tracking system, with the use of small embedded processing units and the robot operating system is developed and examined in numerous outdoor experiments to thoroughly evaluate its performance.\n\n15:20-15:40, Paper FrB2.5 Add to My Program Deep Learning for Radar Classification Holt, DannyCranfield University Guo, WeisiCranfield University Sun, MengweiCranfield University Panagiotakopoulos, DimitriCranfield University Warston, HåkanSaab\n\nKeywords: Smart Sensors, Technology Challenges, Airspace Management\n\nAbstract: Airfield surveillance radars (ASR) face increased challenge of both detecting and classifying non-cooperative airborne targets. Drones are smaller, more diverse, and often operate amongst clutter near the horizon. Traditional radar signal processing is aimed at detecting larger cooperative aircraft that announce their identity and fit within distinctive categories. This is achieved using banks of linear time-invariant processing, thus neglecting any non-linear relationships that may exist between the reflected signal and detected objects properties. Here, we leverage on Recurrent neural networks (RNNs), such as long-short-term memory (LSTM), to learn from sequences of radar data and generate a nonlinear output features to learn target classes. To date, deep learning has not yet been fully investigated with ASR for object classification. Here, we show that a novel RNN architecture combined with a normalised representation of the analytic radar signal can perform classification tasks. We found that an LSTM layer can discover features from the short running time span of each scan of a target. By concatenating these found features into a new sequence depicting the track over multiple scans, an additional LSTM layer can learn to classify objects. Training of the network was improved by fitting the network to multiple output labels that describe the object. This shows that neural networks can approximate radar linear processing, while also performing nonlinear processing to derive the overall classification. Responses from this architecture demonstrate the ability of deep learning to perform object classification using airfield surveillance radar data. This proposed method can be used as a starting point to explore how explainable the responses and trained model are.\n\n15:40-16:00, Paper FrB2.6 Add to My Program Vision-Based Parameter Estimation of a Slung Load Naundrup, JacobAalborg University Bendtsen, Jan DimonAalborg Univ la Cour-Harbo, AndersAalborg University\n\nKeywords: Smart Sensors, UAS Applications, Payloads\n\nAbstract: This research paper introduces an innovative vision-based technique designed to locate and estimate the position of a tethered slung load relative to an Unmanned Aerial System (UAS). The approach relies on fundamental image processing methodologies, primarily emphasizing accurately determining the pitch of the slung load. This is achieved through a combination of Gaussian filtering, HSV filtering, and Fitzgibbon ellipse detection. An independent measuring device is employed to validate the calculated pitch, adding an extra layer of reliability to the vision software's output. The effectiveness of the proposed method is confirmed through rigorous indoor testing, utilizing measuring devices in controlled conditions. Additionally, outdoor scenarios showcase the reliability and feasibility of the vision-based approach. This approach holds significant promise for enhancing UAS operational capabilities, presenting a cost-effective vision solution for load positioning applications. The outcomes contribute substantially to the advancement of UAS technologies, particularly in missions where precise load positioning is a critical determinant of success, extending the potential applications of vision-based systems in diverse operational environments.\n\nFrB3 Regular Session, KAM Add to My Program UAS Applications IV Chair: Zhang, YouminConcordia University Co-Chair: Shan, JinjunYork University 14:00-14:20, Paper FrB3.1 Add to My Program Reinforcement Learning Based PID Parameter Tuning and Estimation for Multirotor UAVs Sonmez, SerhatUniversity of Denver Martini, SimoneUniversity of Denver Rutherford, MatthewUniversity of Denver Valavanis, Kimon P.University of Denver\n\nKeywords: Training, Control Architectures, UAS Applications\n\nAbstract: A reinforcement learning (RL) based approach is proposed for PID controller fine-tuning and parameter estimation for effective and accurate tracking of a helix trajectory considering realistic flight controller sampling times. RL exploits a Deep Deterministic Policy Gradient (DDPG) algorithm, which is an off-policy actor-critic method. The quadrotor model follows the Newton-Euler formulation and accounts for complete gyroscopic and drag effects. Training and simulation studies are performed using Matlab/Simulink. Performance evaluation and comparison studies are detailed between the hand-tuned, RL-based tuned, and RL-based full estimation of parameters approaches. Results show that full estimation of controller parameters achieves the smallest attitude and position errors, and that both RL-based strategies significantly improve tracking performance compared to the hand-tuned approach.\n\n14:20-14:40, Paper FrB3.2 Add to My Program ROS2-Gazebo Simulator for Drone Applications Haridevan, Amal DevYork University Kang, JunjieYork University Yuan, MingfengYork University Shan, JinjunYork University\n\nKeywords: UAS Applications, Aerial Robotic Manipulation, Simulation\n\nAbstract: This paper introduces ROS2GazeboDrone, a modular C++ and Python-based toolbox based on ROS2 and Gazebo. ROS2GazeboDrone consists of a core module written as a Gazebo System Plugin, that orchestrates the interfaces between Gazebo and Quadrotor. The modular design of the toolbox can be used to test perception, path planning, and control algorithms efficiently. The toolbox can be integrated as a ROS2 node as well as a standalone quadrotor simulator. The decoupled and modular architecture enables the extension of this toolbox to any quadrotor model with minimal modifications. We demonstrate the flexibility of our toolbox through demonstrations.\n\n14:40-15:00, Paper FrB3.3 Add to My Program A Robust UAV-UGV Collaborative Framework for Persistent Surveillance in Disaster Management Applications Mondal, Mohammad SafwanUniversity of Illinois at Chicago Ramasamy, SubramanianUniversity of Illinois at Chicago D. Humann, JamesArmy Research Laboratory Dotterweich, JamesArmy Research Lab Reddinger, Jean-PaulArmy Research Lab Childers, MarshalArmy Research Lab Bhounsule, PranavUniversity of Illinois at Chicago\n\nKeywords: UAS Applications, Energy Efficient UAS, Path Planning\n\nAbstract: Unmanned Aerial Vehicles (UAVs) are fast, agile, and capable of covering large areas quickly but are constrained by their limited fuel capacities. In contrast, Unmanned Ground Vehicles (UGVs) have longer battery lives but move at slower speeds. By combining UAVs with UGVs, which serve as mobile recharging stations, we can harness the strengths of both: UAVs can achieve rapid task execution over extended periods by refueling from UGVs. This synergy makes the collaborative routing of UAVs and UGVs well-suited for modern disaster management applications. However, their varied operational constraints require a sophisticated planning framework to ensure optimized coordination and task execution. In this paper, we introduce a robust multi-agent framework leveraging asynchronous planning to optimize the routes of UAVs and UGVs in a persistent surveillance task, considering their individual limitations like fuel, speed, and charging constraints. The framework is designed to scale effectively with the number of vehicles and accommodates diverse team configurations. The effectiveness of this framework is demonstrated through a simulation of a 4-hour mission covering 30 task points across five different team compositions, showing significant improvements in route efficiency. Additionally, a detailed cost analysis identifies the optimal UAV-UGV team composition by effectively balancing mission performance and cost, thus serving as a valuable tool for optimizing disaster response strategies.\n\n15:00-15:20, Paper FrB3.4 Add to My Program A Fault Detection Method for Power Transmission Lines Using Aerial Images Zhang, YulongXi'an University of Technology Cao, ShaoweiXian University of Technology Mu, LingxiaXi'an University of Technology Xue, XianghongXi'an University of Technology Xin, JingXi'an University of Technology Zhang, YouminConcordia University\n\nKeywords: UAS Applications, Perception and Cognition, Risk Analysis\n\nAbstract: It is necessary to regularly detect faults to maintain the safety and stability of power lines. Insulators are one of the important electrical components in high-voltage transmission lines. It is extremely necessary to check the working status of insulators regularly. Traditional manual inspection is inefficient because it requires a significant amount of labor costs. In this paper, a method for detecting insulators' missing defect based on aerial images is proposed to address the issue by unmanned aerial vehicle (UAV). Firstly, the improved Faster R-CNN (region-based convolutional neural network) is used to identify and locate insulators in aerial images. Secondly, the U-Net image segmentation network segments insulators from the images. The adaptive threshold segmentation method completely separates the insulator from the background. Then the binary image of the insulator is obtained. Finally, the binary image is converted into a fault curve which is used for determining the missing insulators based on the distribution of the fault curve. By using collected insulator datasets on a 330kV overhead transmission line using a DJI M300 UAV platform and an onboard H20T camera/sensor, the detection accuracy of glass insulators is as high as 0.98 with the proposed algorithm. The positioning accuracy of the proposed algorithm is also higher than other algorithms. This method has high detection accuracy for missing defects in insulators. The experimental results show that compared with similar algorithms, this method has higher accuracy and efficiency.\n\n15:20-15:40, Paper FrB3.5 Add to My Program Fostering UAS Innovations in Sustainable Agriculture and Rural Development in Europe: Assessing the Role of Diversified Stakeholders in the Network Bojkova, ViaraNOOSWARE BV Doornbos, JurrianWageningen University Valente, JoãoSpanish National Research Council (CSIC) Kasimati, AikateriniAgricultural University of Athens Arampatzis, StratosNOOSWARE BV\n\nKeywords: UAS Applications, Technology Challenges\n\nAbstract: This research explores an interdisciplinary methodology for evaluating the role of diverse stakeholders: including policymakers, technology developers, and agricultural practitioners  in the development and deployment of multi-purpose drone applications within the European Union. The methodological framework, tested on five use cases across Europe, aims to enhance the Uncrewed Aerial Systems (UAS) ecosystem and strengthen local networks within EU member states. Addressing initiatives in livestock & crop monitoring, drone spraying, forest biodiversity, and rural logistics, the study identifies unique network structures, and the varied roles stakeholders play. As part of the ICAERUS Project, this work seeks to unlock the substantial potential and transformative impact of drones in EU agriculture, forestry, and rural areas. Initial findings underscore the critical need to understand the complexity of stakeholder interactions and the socio-technical factors at play. For instance, the analysis revealed that integrating real-time data sharing between drones and farm management systems significantly enhances decision-making processes, exemplifying a socio-technical factor that could accelerate drone innovation. This paves the way for targeted actions such as developing standardised protocols for data exchange and security, aiming to significantly advance drone innovation across a broader context.\n\n15:40-16:00, Paper FrB3.6 Add to My Program Adaptive Quaternion Control for a Quadcopter Vehicle: Real-Time Validation in Presence of Wind Gusts Arizaga, JorgeITESM Cariño Escobar, JossuéONERA Castaneda, HermanTecnologico De Monterrey Mercado Ravell, Diego AlbertoCenter for Research in Mathematics CIMAT Castillo, PedroUnviersité De Technologie De Compiègne\n\nKeywords: UAS Testbeds, Micro- and Mini- UAS, UAS Applications\n\nAbstract: An adaptive control for a quadcopter aerial vehicle exposed to aggressive wind gusts is presented in this paper. The control scheme is composed by two parts; firstly, the attitude dynamics is robustly stabilized using a controller based on the quaternion formulation. Then, a translational flight control law with adaptive properties is designed using the sliding mode approach. The stability analysis of the whole system is proved using the Lyapunov theory. The performance of the closed-loop system is validated in real-time experiments and for validating the adaptive and robust properties of the controller, strong wind gusts are applied during flight tests. A video and some graphs, obtained from these experiments, illustrate the effectiveness and robustness of the proposed control strategy.\n\nFrB4 Regular Session, DILOVO Add to My Program Technology Challenges Chair: McLain, TimBrigham Young University Co-Chair: Herfray, BenjaminMcGill University 14:00-14:20, Paper FrB4.1 Add to My Program Compact Docking Station for Sub-150g UAV Indoor Precise Landing Martin, ThomasINRIA Roman Blanco, JeffersonLCFC/University of Lorraine Mouret, Jean-BaptisteINRIA Raharijaona, ThibautUniversity of Lorraine\n\nKeywords: Integration, Micro- and Mini- UAS, UAS Applications\n\nAbstract: To be used at their full potential, sub-150g drones need to to be integrated in a \"foolproof\" deployment system, from take-off to landing. In this paper, we introduce a compact (less than 15x15 cm) docking station that could fit in a suitcase. To achieve accurate drone localization, we evaluated various systems (Optitrack Duo/Trio, Bitcraze's radio-based system) and found that a vertically mounted Lighthouse sensor from the HTC Vive system offers a few centimeters of accuracy while being significantly smaller than multi-camera systems. Our final docking station design incorporates this sensor, along with an actuated landing pad that retracts from the sensor's field of view during landing. This novel landing system paves the way for the use of small indoor drones by professionals without the need for extensive drone training.\n\n14:20-14:40, Paper FrB4.2 Add to My Program Comparative Analysis of Linear and Nonlinear Kalman Filters for Airflow Estimation in UAVs Clough, JustinThe University of Kansas Carlson, MeganThe University of Kansas Keshmiri, ShawnUniversity of Kansas\n\nKeywords: Integration, Simulation, Technology Challenges\n\nAbstract: In the past three decades, numerous works have been done on the applications of linear and nonlinear Kalman filters in estimating crewed and uncrewed aircraft airflow angles. In uncrewed autonomous aircraft, the flight envelope protection (FEP) algorithms play a vital role in ensuring the safety of the aircraft during flight. The FEP heavily relies on accurate estimations of angle of attack and sideslip angles. In addition to safety, autonomous controller performance can significantly degrade due to poor airflow estimations. Compared to large transport or general aviation aircraft, autonomous aircraft are much lighter, fly lower, and fly slower, which makes them more vulnerable to external disturbances. This work presents the theoretical framework of both linear and nonlinear Kalman filters. It showcases the design process of five different Kalman filters using the 6DoF simulation environment in the presence of sensor noise and external disturbances in the form of the Dryden wind disturbance model. Different Kalman filter designs are assessed using actual flight test data for a realistic evaluation process. Among the five different designs, the Ensemble Kalman filter demonstrated the lowest mean normal of the covariance matrix, indicating superior estimation accuracy. Given the stringent computation power onboard uncrewed aircraft, special attention is given to the computational overhead of each design.\n\n14:40-15:00, Paper FrB4.3 Add to My Program Velocity Planning with Multi-Objectives in Displacement-Time Graphs Using Deep Reinforcement Learning Wang, LiyangCOMAC Bronz, MuratENAC\n\nKeywords: Navigation, Path Planning, Simulation\n\nAbstract: This paper presents a novel velocity planning method in displacement-time graphs with multiple constraints and optimization goals using deep reinforcement learning. The method formulates the velocity planning problem as a reinforcement learning task with state representation including time, position, velocity, acceleration, and distances to each obstacle triangle representative. The action space is discretized within allowable accelerations, and the kinematics ensure velocity constraints during state transitions. The advantage of this method lies in its independence from scene-specific tuning, and exhibiting robustness in various complex scenarios. Comparative analysis demonstrates a 100% success rate, along with superior computational efficiency when contrasted with the baseline approach, while also exhibiting better comfort performance. It offers a valuable alternative for velocity planning in robotics and autonomous vehicles, showcasing deep reinforcement learning's potential in practical robotics applications.\n\n15:00-15:20, Paper FrB4.4 Add to My Program Robust IR-Based Pose Estimation for Precision VTOL Aircraft Landing in Urban Environments Akagi, DavidBrigham Young University McLain, TimBrigham Young University Mangelson, JoshBrigham Young University\n\nKeywords: Reliability of UAS, Navigation, Autonomy\n\nAbstract: This paper presents a novel pose estimation framework that provides high-accuracy localization for vertical take-off and landing aircraft in settings where GPS is unreliable or unavailable. The proposed framework utilizes a sparse constellation of infrared lights that can be robustly identified and associated in the presence of outliers and occlusions, making it suitable for use in realistic urban environments. This is enabled by constellation designs that exploit properties of invariance under projective transformations. Flight test results demonstrate that the framework is capable of running in real-time at speeds of over 30 Hz while providing pose information at decimeter-level accuracy at ranges of over 100 m from the landing site.\n\n15:20-15:40, Paper FrB4.5 Add to My Program Smart Self-Diagnosis Method for GPS Attacks and Safety Faults in UAVs Ferrão, IsadoraUniversity of São Paulo Luiz de Oliveira, AndréUniversidade Federal De Juiz De Fora Espes, DavidUniversité De Bretagne Occidentale Dezan, CatherineUniversité De Bretagne Occidentale Branco, Kalinka Regina Lucas Jaquie CasteloUniversity of São Paulo\n\nKeywords: Security, Levels of Safety\n\nAbstract: Unmanned aerial vehicles (UAVs) have been used in a variety of applications in safety-critical domains such as logistics, transportation, and defense. However, safety assurance is needed for the widespread development and operation of UAVs in urban areas where a failure may lead to physical harm to people, environment, or property. Since UAVs are highly interconnected, security is an important concern for the acceptance of safety-critical UAV applications. Thus, it is needed to ensure that UAVs are protected from attacks, e.g., Global Position System (GPS) signal spoofing, and unauthorized manipulation of flight controls, caused by malicious external agents aiming to compromise system/data confidentiality, integrity, or availability. Artificial Intelligence techniques such as Machine Learning classifiers can be used to support the identification of UAVs attacks. This study presents the development of safety and security diagnostic methods for UAVs. Two multiclass approaches are proposed, focusing on identifying safety-related failures and security threats such as GPS spoofing and jamming attacks. Various machine learning algorithms are employed, and evaluation metrics demonstrate high accuracy rates across models. The study underscores the importance of addressing both safety and security aspects in UAVs operations and provides pre-processing code for reproducibility. The developed methods contribute to enhancing UAV resilience and understanding safety and security measures in unmanned aerial operations.\n\n15:40-16:00, Paper FrB4.6 Add to My Program Development of a CFD Model of Propeller Slipstream Herfray, BenjaminMcGill University Nahon, MeyerMcGill University\n\nKeywords: Simulation\n\nAbstract: The growing interest in electric powertrains for aircraft has led to new aircraft designs for air taxis and Unmanned Aerial Vehicles (UAVs). Electric powertrains allow aircraft designers to consider novel propulsion layouts such ones in which many motors/propellers are distributed along the wing's leading edge, known as Distributed Electric Propulsion (DEP). This configuration confers a number of advantages, including the mitigation of airflow separation. Understanding the wake of a propeller can allow us to develop a better understanding of the dynamical behaviour of DEP aircraft, where large parts of the wings are immersed in the propeller slipstream, which can have a large influence on the forces generated by the wing. In the present work, we describe a method for simulating the wake of a given propeller in the OpenFOAM Computational Fluid Dynamics (CFD) package. The propeller model uses body forces within a finite propeller region, acting as a momentum source for fluid passing through it. Simulations using this method were performed for various propeller geometries, rotation rates, and freestream velocities, and results were compared with experimental measurements from the literature, yielding good agreement.\n\nFrC1 Invited Session, MIKIS 1 Add to My Program Aerial Robotics in Inspection and Maintenance Operations II Chair: Chaikalis, DimitrisNew York University Co-Chair: Castillo, PedroUnviersité De Technologie De Compiègne Organizer: Gabellieri, ChiaraUniversity of Twente Organizer: Silano, GiuseppeCzech Technical University in Prague Organizer: Selvaggio, MarioUniversity of Naples Federico II 16:30-16:50, Paper FrC1.1 Add to My Program Design and Experimental Validation of a Marsupial Long-Endurance UAV-UGV System (I) Martinez-Rozas, SimonUniversidad De Antofagasta Alejo, DavidUniversity Pablo De Olavide Carpio Jiménez, José JavierUniversidad Pablo De Olavide Merino, LuisUniversidad Pablo De Olavide Caballero, FernandoUniversity of Seville\n\nKeywords: UAS Applications, Technology Challenges, Autonomy\n\nAbstract: Over the last decades, we have experienced an exponential growth in the use of Unmanned Aerial Vehicles (UAVs) for inspection operations. However, the reduced flight autonomy of electric powered UAVs can limit their applicability in long duration operations. In this paper, we propose a marsupial system composed of a UAV and a Unmanned Ground Vehicle (UGV). The system is made with off-the-shelf components that can greatly extend the flight duration of the UAV by powering it from the UGV using a tether, and reducing the mobility limitations by the coordinated motion of the system. We present the hardware design, making emphasis in the decisions made and presenting different alternatives depending on the application. Moreover, the software architecture for operating the device, based on the Robotic Operating System (ROS) is presented. Finally, the system is validated in experiments lasting more than one hour.\n\n16:50-17:10, Paper FrC1.2 Add to My Program Optimization-Based Compliant Controller for Physical Human-Aerial Manipulator Interaction Chaikalis, DimitrisNew York University Tzes, AnthonyNew York University Abu Dhabi\n\nKeywords: Aerial Robotic Manipulation, Control Architectures, Navigation\n\nAbstract: The use of aerial manipulators in mixed human-robot environments, necessitates the capacity for safe interactions between them. This work is concerned with enabling human-aided navigation of unmanned aerial manipulators, allowing human operators to effectively take over the path planning task of an aerial manipulator platform, by exerting appropriate forces on its end-effector. A guaranteed-compliance model-based optimization controller is developed for the systems articulated arm, ensuring that the arm can comply with forces and moments on its end-effector, while using control barrier functions (CBFs) to maintain non-singular configurations at all times. Another optimization-based controller is designed for the aerial vehicle, appropriately interpreting the robot arm end-effector motions in order to comply with human-induced intended poses, with CBFs included to ensure measured forces remain bounded, for additional safety. Experimental studies are included, showcasing the capacity of the presented control framework in enabling human-guided navigation for autonomous aerial manipulators.\n\n17:10-17:30, Paper FrC1.3 Add to My Program Sarax: An Open-Source Software/Hardware Framework for Aerial Manipulators (I) Alharbat, AyhamSaxion University of Applied Sciences Dion, ZwakenbergSaxion University of Applied Sciences Esmaeeli, HaniehSaxion University of Applied Sciences Mersha, Abeje YenehunSaxion University of Applied Sciences\n\nKeywords: Aerial Robotic Manipulation, Multirotor Design and Control, Standardization\n\nAbstract: The use of Multi-Rotor Aerial Vehicles (MRAVs) in tasks that require physical interaction has been an active research field in the last decade which resulted in an increasing interest in Aerial Manipulators (AMs). This raises many challenges in the modeling, control, perception, and planning of these robots. However, designing and realizing an AM testbed is a complicated multi-disciplinary task, and there is a lack of standardization in the relatively new field of AMs. For this purpose, we introduce Sarax, an open-source hardware and software framework tailored for AMs research and innovation. The software of Sarax is built on top of open-source projects such as the Robot Operating System (ROS) and PX4 Autopilot, while the hardware is designed to be customizable, modular, and easily scalable through parameterized models. We verified and validated the proposed framework through indoor and outdoor experiments. We aim to open the door to accelerate AMs research and innovation, allow researchers and developers to focus on their core contributions, and take AMs technology to a higher readiness level.\n\n17:30-17:50, Paper FrC1.4 Add to My Program Streamlined Indoor UAVs Localization Using a Dense and Size-Heterogeneous Tags Map (I) Bertoni, MassimilianoUniversity of Padova Montecchio, SimoneUniversity of Padova Michieletto, GiuliaUniversity of Padova Oboe, RobertoUniversity of Padova Cenedese, AngeloUniversity of Padova\n\nKeywords: UAS Applications, Navigation, Technology Challenges\n\nAbstract: A significant challenge in the employment of UAV platforms for indoor inspection and maintenance operations lies in the problem of finding a portable and cost-effective way to accurately localize aerial vehicles in GNSS-denied environments. Focusing on the visual-based positioning paradigm, we outline a pose estimation procedure whose accuracy is achieved by leveraging the potential offered by a dense and size-heterogeneous map of tags. The proposed indoor UAVs localization rests on i) hierarchical tag selection, ii) outlier removal, and iii) multi-tag estimation averaging, to facilitate visual-inertial reconciliation. We assess the performance of the outlined positioning system through ad-hoc experimental tests that highlight the localization accuracy improvement as compared with other existing state-of-the-art solutions.\n\n17:50-18:10, Paper FrC1.5 Add to My Program Quaternion-Based Observer Control for Multirotor UAVs, an Application to Unactuated Grasping Gandulfo Cipres, Diego JoseTecnologico De Monterrey Varela, AlbertoTecnologico De Monterrey Castillo, PedroUnviersité De Technologie De Compiègne Abaunza, HernanTecnologico De Monterrey\n\nKeywords: Aerial Robotic Manipulation, Control Architectures, Micro- and Mini- UAS\n\nAbstract: A novel approach for aerial drone control in object pickup tasks is presented. The methodology integrates quaternion-observer control to address the challenge of variable mass during object interaction. A specialized non-actuated gripper designed explicitly for aerial drones enhances their ability to grasp objects efficiently. Real-time tests validated the effectiveness and feasibility of the proposed solution. The experiments demonstrated the robustness and adaptability of quaternion-observer control in compensating for variable mass during object pickup tasks. Additionally, the practical utility of the non-conventional gripper design under real-world conditions emphasized its relevance in aerial manipulation scenarios.\n\nFrC2 Invited Session, MIKIS 2 Add to My Program Industrial Inspection and Maintenance with Aerial Manipulators Chair: Ollero, AnibalUniversidad De Sevilla - Q-4118001-I Co-Chair: Rafee Nekoo, SaeedEscuela Técnica Superior De Ingeniería, Universidad De Sevilla Organizer: Gonzalez-Morgado, AntonioUniversidad De Sevilla Organizer: Fumagalli, MatteoDanish Technical University Organizer: Trujillo, Miguel ÁngelCenter for Advanced Aerospace Technologies (CATEC) Organizer: Rodriguez Rivero, JacobCompany 16:30-16:50, Paper FrC2.1 Add to My Program Assisted Physical Interaction: Autonomous Aerial Robots with Neural Network Detection, Navigation, and Safety Layers (I) Berra, Andrea(fada Catec) Fundacion Andaluza Para El Desarrollo Aeroespacial Sankaranarayanan, Viswa NarayananLuleå University of Technology, Sweden Seisa, Achilleas SantiLulea University of Technology Mellet, JulienUniversity of Naples Federico II Udayanga, Kashita Niranjan Gangoda Withana GamageDTU, Denmark Satpute, SumeetLulea University of Technology Ruggiero, FabioUniversità Degli Studi Di Napoli \"Federico II\" Lippiello, VincenzoUniversita' Di Napoli Federico II Tolu, SilviaTechnical University of Denmark Fumagalli, MatteoDanish Technical University Nikolakopoulos, GeorgeLuleå University of Technology, Sweden Trujillo, Miguel ÁngelCenter for Advanced Aerospace Technologies (CATEC) Heredia, GuillermoUniversity of Seville\n\nKeywords: Aerial Robotic Manipulation, UAS Applications\n\nAbstract: The paper introduces a novel framework for safe and autonomous aerial physical interaction in industrial settings. It comprises two main components: a neural network-based target detection system enhanced with edge computing for reduced onboard computational load, and a control barrier function (CBF)-based controller for safe and precise maneuvering. The target detection system is trained on a dataset under challenging visual conditions and evaluated for accuracy across various unseen data with changing lighting conditions. Depth features are utilized for target pose estimation, with the entire detection framework offloaded into low-latency edge computing. The CBF-based controller enables the UAV to converge safely to the target for precise contact. Simulated evaluations of both the controller and target detection are presented, alongside an analysis of real-world detection performance.\n\n16:50-17:10, Paper FrC2.2 Add to My Program Integration of Customized Commercial UAVs with Open-Source Tools in a Heterogeneous Multi-UAV System for Power-Lines Inspection (I) Gil Castilla, MiguelUniversity of Seville Caballero, AlvaroUniversity of Seville Maza, IvanUniversidad De Sevilla Ollero, AnibalUniversidad De Sevilla - Q-4118001-I\n\nKeywords: Autonomy, UAS Applications, Integration\n\nAbstract: This paper presents our approach to the power-lines inspection application with a team of multiple heterogeneous UAVs that provides the required flexibility to tackle with different use cases such as fault detection or periodic inspection. Our solution required proper integration of several commercial UAVs customizing their hardware and building a software architecture based on open-source tools under the ROS (Robotic Operating System) framework to enhance adaptability, specialization, and overall mission effectiveness. The team, comprising fixed-wing VTOLs and multicopters, collaboratively executes fully autonomous mission for monitoring the aerial power-lines, the transmission towers and their components in real-time. Heterogeinity is crucial to tackle different use cases, since for instance the fixed-wing VTOL can provide fast response for the detection of faults, while the agility and precision of multicopters facilitate detailed periodic inspections. The paper presents validation results of our approach both in simulation and in real power-lines inspection campaigns.\n\n17:10-17:30, Paper FrC2.3 Add to My Program Finite-Time and Infinite-Time Horizon State-Dependent Riccati Equation for Swinging-Up and Control of a Rotary Drone Pendulum (I) Rafee Nekoo, SaeedEscuela Técnica Superior De Ingeniería, Universidad De Sevilla Yao, JieUniversity of Minnesota at Twin Cities Ollero, AnibalUniversidad De Sevilla - Q-4118001-I\n\nKeywords: Control Architectures, Multirotor Design and Control, UAS Applications\n\nAbstract: The control, prototyping, and experimentation of rotor-based systems (aerial robotic platforms) were highlighted recently for rotation around pipes for inspection, measurement, and maintenance. The application of the rotary inspection comes from chemical plants and, the oil and gas industry where in some cases, access to all perimeters of the pipes is difficult. Rotary aerial systems then are good candidates. Here in this work, a novel system is proposed for rotary inspection based on a two-link rotary drone pendulum. The modeling of the system released highly nonlinear dynamics. Finite-time and infinite-time horizon state-dependent Riccati equation (SDRE) are chosen to control the system, both in the domain of nonlinear optimal control. These nonlinear controllers are suitable for handling the dynamics and the finite horizon design offers a rapid response for swinging up and stabilization around the pipe. Solving this challenge in control enables us to move forward with the design and implementation of the system on a real setup and prototype. The Simulation and comparison of finite-time (state-dependent differential Riccati equation (SDDRE)) and infinite-time SDRE were done; it showed successful regulation with faster response and less error for the finite-time method.\n\n17:30-17:50, Paper FrC2.4 Add to My Program Petrochemical Industry Aerial Robotic Inspection: A Novel Concept for Landing and Deploying Robots on Pipes (I) Montes-Grova, Marco AntonioCenter for Advanced Aerospace Technologies (CATEC) Ortuno Conde, JaimeCATEC Tejero-Ruiz, DavidAdvance Center for Aerospace Technologies (CATEC) Olmedo, JesúsCATEC Perez-Grau, Francisco Javier(fada Catec) Fundacion Andaluza Para El Desarrollo Aeroespacial Trujillo, Miguel ÁngelCenter for Advanced Aerospace Technologies (CATEC) Viguria, AntidioFADA-CATEC\n\nKeywords: UAS Applications\n\nAbstract: This paper introduces a hybrid aerial robot for Non-Destructive Testing (NDT) thickness petrochemical pipes inspection and a novel method for recognizing and landing on pipes in areas where Global Navigation Satellite System (GNSS) signals are degraded. In these environments, the inspection of pipes at height presents a high risk for the workers. We have addressed the issue of landing safely on pipes by implementing tilted rotors and a force control technique. Due to the type of environment, a LiDAR-Inertial Odometry has been implemented for the aircraft localization. In addition, pipes are detected and tracked using a fusion of some of the onboard sensors: a depth camera and a 2D LiDAR. The outcome is an unmanned aerial vehicle with the capability of deploying a robotic crawler on pipes at height while performing safe landing and takeoff. A demonstration of autonomous landing in an outdoor controlled environment can be found in https://youtu.be/yYRzDUkc_Bk.\n\n17:50-18:10, Paper FrC2.5 Add to My Program Open-Source Web-Based Ground Control Station for Long-Range Inspection with Multiple UAVs (I) Poma, Aguilar, Alvaro RamiroUniversity of Seville Caballero, AlvaroUniversity of Seville Maza, IvanUniversidad De Sevilla Ollero, AnibalUniversidad De Sevilla - Q-4118001-I\n\nKeywords: UAS Applications, Integration, Interoperability\n\nAbstract: This paper presents a web-based ground control station (GCS) designed to manage a fleet of heterogeneous Unmanned Aerial Vehicles (UAVs) based on a client-server architecture. The primary focus of the developed software is to efficiently oversee and monitor multiple UAVs engaged in long-range missions. The GCS emerges as a scalable solution compatible with various autopilots through the use of the Robotic Operating System (ROS) framework, featuring a user-friendly interface crafted to handle numerous UAVs seamlessly without overwhelming the operator. It allows multiple operators to assign different tasks to the UAV, monitor telemetry, view images from onboard cameras, and control the flight through the GCS. The implemented interface boasts a minimalist design, allowing users to effortlessly navigate and control multiple UAVs. This design philosophy aims to enhance user experience while ensuring effective mission management. The GCS enables connection with external programs, facilitating seamless integration with third-party applications.\n\nFrC3 Regular Session, KAM Add to My Program Energy/Environment/Reliability Chair: Bertolani, GiuliaUniversità Di Bologna Co-Chair: Cooper, TheloniousMIT 16:30-16:50, Paper FrC3.1 Add to My Program Airspace Situational Awareness: Proposed Airspace Safety Concepts & State-Of-The-Art Review of UAS Aircraft Detection Technologies Maalouf, GuyUniversity of Southern Denmark Jepsen, Jes HundevadtUniversity of Southern Denmark Jensen, KjeldUniversity of Southern Denmark\n\nKeywords: See-and-avoid Systems, Airspace Management, Regulations\n\nAbstract: The integration of UAS into lower airspace requires trustworthy Detect and Avoid (DAA) capabilities, which hinge on robust Airspace Situational Awareness (ASA) technologies. This paper introduces a structured approach to effectively address and simplify the challenges of ASA for UAS. It introduces Operational Classes (OCs) for categorising airspace risks, System Configurations (SysCons) for grouping distinct system structures, and DAA Strategies, based on ACAS-Xu, for improving UAS safety and operational efficiency through proactive and reactive measures. Furthermore, it explores diverse detection technologies for both cooperative and non-cooperative aircraft, analysing their strengths and limitations, and recommends which technologies to use for various SysCons.\n\n16:50-17:10, Paper FrC3.2 Add to My Program Enhancing Battery Efficiency through Semi-Markov Decision Processes in Task Allocation for UAVs De Alba Franco, AbrahamTecnologico De Monterrey Flores Madriz, AlejandroTecnologico De Monterrey Abaunza, HernanTecnologico De Monterrey\n\nKeywords: Energy Efficient UAS, Autonomy, Micro- and Mini- UAS\n\nAbstract: This research introduces a Semi-Markov Decision Process (SMDP) approach to task allocation for Unmanned Aerial Vehicles (UAVs) by considering the stochastic behavior of battery levels. The SMDP allows the UAV to dynamically allocate tasks based on its current battery state and the time spent in each state. We compare the SMDP method with a manually assigned task sequence and demonstrate a significant reduction in completion time for a set of predefined tasks. The SMDP optimally assigns tasks, considering the stochastic nature of battery levels, resulting in improved efficiency and eliminating uncertainties associated with human allocation. The findings underscore the benefits of incorporating SMDP in UAV task management, especially in scenarios dependent on real-time battery levels.\n\n17:10-17:30, Paper FrC3.3 Add to My Program Unveiling the Impact of Drone Noise on Wildlife: A Crucial Research Imperative Afridi, SaadiaAvy B.V Hlebowicz, KasperWildlife Ecology and Conservation, Wageningen University and Res Cawthorne, DylanUniversity of Southern Denmark Schultz, Ulrik PaghUniversity of Southern Denmark\n\nKeywords: Environmental Issues\n\nAbstract: Unmanned Aerial Vehicles, commonly known as drones, have become integral across various industries, ranging from photography and surveillance to scientific research. While their applications offer numerous benefits, the noise generated by drones poses a potential threat to the well-being of wildlife. Using a systematic literature review, we examine a wide range of sources to gain insights into the current state of knowledge on the impacts of drones on wildlife, with a particular focus on noise. The literature review reveals a significant research gap and highlights the need for a more comprehensive understanding of the impact of drone-induced noise on animal and ecosystem behavior. This paper advocates for concerted efforts to address the issue of drone noise on animals. It raises a fundamental question: Can we design drones to minimize noise and responsibly incorporate them into wildlife research?\n\n17:50-18:10, Paper FrC3.5 Add to My Program A Stochastic Compound Failure Model for Testing Resilience of Autonomous Fixed-Wing Aircraft I: Formulation and Simulation Cooper, TheloniousMIT Ravela, SaiMassachusetts Institute of Technology\n\nKeywords: Reliability of UAS, Risk Analysis, UAS Testbeds\n\nAbstract: This paper presents a Markov chain model to dynamically emulate the effects of adverse (failure) flight conditions on fixed-wing, autonomous aircraft system actuators. It implements a PX4 Autopilot flight stack module that perturbs the attitude control inputs to the plane's actuator mixer. We apply this approach in simulation on a fixed-wing autonomous aircraft to test the controller response to stochastic compound failures on a range of turning radii. Statistical measures of the differences between target and simulated flight paths demonstrate that a well-tuned PID controller remains competitive with adaptive control in a cascading, compound, transient failure regime.\n\n17:50-18:10, Paper FrC3.5 Add to My Program Hierarchical Control Design for a Helicopter-Payload System for Water Monitoring Bertolani, GiuliaUniversità Di Bologna Giulietti, FabrizioUniversità Di Bologna de Angelis, Emanuele LuigiUniversity of Bologna\n\nKeywords: Environmental Issues, Multirotor Design and Control, UAS Applications\n\nAbstract: The integration of helicopters with payloads for environmental monitoring applications presents a unique set of challenges. This paper proposes a hierarchical control scheme designed to address the complexities inherent in controlling a system composed of a helicopter and a payload dragged into water through a ca"
    }
}