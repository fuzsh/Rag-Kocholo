{
    "id": "dbpedia_1752_3",
    "rank": 96,
    "data": {
        "url": "https://www.globallegalpost.com/lawoverborders/artificial-intelligence-1272919708/ireland-636671881",
        "read_more_link": "",
        "language": "en",
        "title": "Artificial Intelligence",
        "top_image": "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/437656852bc041b7f4ebc63421f60bfeai_coverpng",
        "meta_img": "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/437656852bc041b7f4ebc63421f60bfeai_coverpng",
        "images": [
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2021MayThuglp_transparent_v2.png",
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2024JulFrithumbnail_ACWLS_24_EB_Leaderboard_728x90px.jpg",
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2021DecThuIreland.jpg",
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2022OctWedIRELAND-DavidCullen.jpg",
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2022OctWedIRELAND-Moore_Leo.jpg",
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2022OctTueIRELAND-William_Fry_Logo-WEB.jpg",
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2024JulWedthumbnail_LFMS_EB_EB_MPU_300x250px_300x250px.jpg",
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2021JunMon2021AprThuglp_transparent.png",
            "https://www-globallegalpost-static.s3.eu-west-2.amazonaws.com/images/2021JunMon2021AprThuglp_transparent.png",
            "https://px.ads.linkedin.com/collect/?pid=5009220&fmt=gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "IRELAND ARTIFICIAL INTELLIGENCE LAW"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Artificial Intelligence in Ireland, part of a global comparative guide on how to legally integrate Artificial Intelligence into business operations",
        "meta_lang": "en",
        "meta_favicon": "/favicon.png",
        "meta_site_name": "",
        "canonical_link": "https://www.globallegalpost.com/lawoverborders/artificial-intelligence-1272919708",
        "text": "Although currently untested, existing constitutional protections can be expected to apply to issues connected with the use of AI. Indeed, as with other emerging technologies, constitutionally protected rights such as privacy and other fundamental rights will impact on AI.\n\nRight to Privacy\n\nAlthough the Constitution does not explicitly specify a right to privacy, there exists an unenumerated right to privacy pursuant to Article 40.3.1 of the Constitution. In McGee v. Attorney General [1974] IR 284, the court recognised a right to privacy as being inherent to every person due to their human personality. Kennedy & Ors v. Ireland [1984] 1 IR 587 confirmed that the right to damages for breaches of the right to privacy may not be limited to claims against the State alone, allowing for claims against others.\n\nThe right to privacy is not absolute. Irish case law has established that the right is subject to the constitutional rights of others, to the requirements of public order, public morality and the common good (for example Ryan v. The Attorney General [1965] 1 IR 294 and Norris v. The Attorney General [1984] 1 IR 36).\n\nFreedom of Expression, Assembly, and Association\n\nThe rights to freedom of expression, assembly, and association are protected by Article 40.6.1 of the Constitution. People have the right to express their convictions and opinions, to assemble peaceably and without arms, and to form associations and unions. These freedoms are subject to limitation on the basis of public order and public morality.\n\nThe Irish courts, in The Irish Times v. Ireland [1998]1 IR 359, held that this extends to the dissemination of information, as well as the expression of convictions and opinions, and is primarily concerned with public activities. The courts have been reluctant to limit freedom of expression in Ireland (Ryan v. The Attorney General and Norris v. The Attorney General are examples of this).\n\nArticle 40.1 contains explicit constitutional protection that all citizens, as human persons, are equal before the law, including a ban on discriminatory behaviour.\n\nThese rights should be considered in the use of AI which could (inadvertently) have the effect of creating forms of bias and discrimination.\n\nIreland’s copyright regime is contained in the Copyright and Related Rights Act 2000 (CRRA), which protects copyright in a “computer program” where “a program which is original in that it is the author’s own intellectual creation and includes any design materials used for the preparation of the program”.\n\nUnder Section 2 of the CRRA, a “computer-generated” work is a work that is generated by computer in circumstances where the author of the work is not an individual. The author of this type of work is the person by whom the arrangements necessary for the creation of the work are undertaken. Section 21(f) states: “In this Act, “author” means the person who creates a work and includes:… (f) in the case of a work which is computer-generated, the person by whom the arrangements necessary for the creation of the work are undertaken”.\n\nThe legislation appears to derive from the idea of a legal entity model, i.e., one that implies the existence of natural persons behind a legal entity instructing it; although it could have been trying to capture the concept of a machine authoring a work as opposed to a human. As AI becomes more advanced, issues may arise where robots, acting autonomously, are not acting on the instructions of humans. This could make section 21(f) difficult to reconcile with the concept of machine learning. An absence of case law means that the legislation has yet to be tested. It is notable that this Irish provision is seen as lying outside the EU's copyright acquis, which requires human authorship for copyright to vest in a work.\n\nText and data mining\n\nText and data mining (TDM) is an AI technology which is an automated process by which large amounts of data are selected and analysed for purposes such as extraction, pattern recognition, semantic analysis, etc. Article 4 of Directive (EU) 2019/790 of the European Parliament and of the Council of 17 April 2019 on copyright and related rights in the Digital Single Market (CDSM Directive), which was transposed into Irish law by Regulation 4 of S.I. No. 567/2021 - European Union (Copyright and Related Rights in the Digital Single Market) Regulations 2021 (Irish CDSMD Regulations); provides for an exception to the reproduction copyright in works for the purposes of TDM, even if for commercial purposes, if the rights in such works have not been expressly reserved \"in an appropriate manner\" with regard to TDM. This \"appropriate manner\" includes, for online works, metadata and terms and conditions for a website or a service, and if not available online, it must be communicated to everyone who has lawful access to the work.\n\nSeveral provisions of the GDPR are applicable to the governance of AI in Ireland. Article 35 requires those processing personal data “using new technologies” to carry out an assessment of the impact of the processing where that processing is “likely to result in a high risk to the rights and freedoms of natural persons”. Those developing AI to process personal data are likely to need to conduct data protection impact assessments.\n\nWhile the CDSM Directive and the Irish CDSMD Regulations allow for exceptions for reproduction for the purposes of TDM, the legislation specifically disallows the processing of personal data unless it complies with the GDPR.\n\nThere is a prohibition on individuals being subject to a decision based solely on automated processing (Article 22), which is relevant to ‘profiling’. Similarly, the overarching principle of transparency (Article 5), obliges controllers to be clear about the processing of personal data undertaken. Also, controllers must build privacy by default into new technologies (Article 25).\n\nIrish Context\n\nThe GDPR allows for derogations to be made by EU Member States. Irish law may restrict the scope of data subjects’ rights and controllers’ related obligations in Articles 12 to 22, 34, and 5 (as it relates to the rights and obligations in Articles 12 to 22) of GDPR in certain circumstances. The DPA 2018 provides that this can be done when processing personal data for archiving in the public interest, scientific or historical research, or statistical purposes (Section 61) or where processing for purely journalistic purposes or academic, artistic, or literary expression (Section 43).\n\nFurther, Article 8 of the GDPR provides that countries must set a minimum age at which online service providers can rely on a child’s own consent to process their personal data. The DPA 2018 sets the age of this digital consent at 16. This means that companies deploying AI algorithms may need to obtain the consent of a child’s parent or guardian in order to rely on consent as the legal basis for processing a child’s personal data where that child is under the age of 16.\n\n1. Is AI a “product” and, based on this assessment, does the European Product Liability Directive apply to my business?\n\nThe Product Liability Directive 85/374/EEC was transposed into Irish law by the Liability for Defective Products Act 1991 (the Act). This Directive is a key component of both European and national frameworks governing product liability. Under the Act, the definition of a ‘product’ includes all movables including movables incorporated into another product or into an immovable. It is generally accepted that products incorporating AI are captured under this definition of a “product” and are therefore covered by the legislation. The type of damage that is captured under the Act is quite specific and comprises of “death or personal injury” or damage to any item of property, other than the defective product itself, provided that the property is a type intended to be used for private consumption or was used by the injured person for private use or consumption. However, given the passage of time since the drafting of the legislation, while the Act can be applied to products incorporating AI, it is not fit for purpose to adequately deal with the intricacies of such products due to advancements in digital technologies and how AI effects the operation of products.\n\nWhile the current framework does apply to products that incorporate AI, future (updated) legislation will aim to specifically address the issue of damage caused by AI systems.\n\n2. Is there anything from an ethical perspective that we should be aware of in our use of AI?\n\nIt remains to be seen whether Ireland’s legal and regulatory approach to AI will mirror the ethical proposals set out in the EU Commission’s AI Strategy, which, by placing people at the core of AI, enunciates that Europe can “safeguard the respect for our core societal values” and become “a leader in cutting-edge AI that can be trusted throughout the world”. In Ireland, an ethical structure is needed not just from a commercial perspective, but also as a cornerstone of positive public engagement by which consumers can trust AI systems. More than half (54%) of Ireland’s public sector bodies have implemented AI solutions in their organisations, while more than 30% view AI as highly important for qualifying decisions and assuring quality. Subsequently, questions have been raised about the ethical implications of deploying and/or using new technologies. William Fry’s recent Trends in Technology Report explored this issue. When C-suite industry leaders from over 300 firms were asked if they shared concerns when it came to ethical issues that arise in relation to the deployment of AI, 78% agreed that they did, while 83% believed that regulation would help businesses adjust to AI’s future impact. The EU AI Regulation’s categorised system of unacceptable-risk AI systems, high-risk AI systems and minimal-risk AI systems, may give standing to the ethical considerations raised in the current debate in Ireland. An ex-ante impact assessment carried out by the European Commission in relation to the proposed AI Act found that up to 35% of AI systems in place in Europe could fall under the remit of the AI Act.\n\n3. In the context of commercial contracts, how should legal liability relating to AI be allocated between parties?\n\nLegal liability is frequently identified as a sticking point between customers and AI vendors and this needs to be looked at in its many guises in a contract. Many AI vendors are start-up companies which may not have sufficient capital to adhere to indemnity and liability clauses. While dependant on the circumstances, legal advice should be taken before entering into an agreement with an AI vendor. The customers should seek certain indemnities and warranties from the vendor, especially relating to intellectual property and data protection laws.\n\nAI vendors commonly represent that they own the software involved, or at least that they have the licence to use it, and this should be contained as a warranty within the agreement. Furthermore customers should seek a warranty that the use of the software does not infringe the intellectual property rights of any third parties. However, where the end product created by the AI system infringes the intellectual property of a third party, this is unlikely to be covered by warranties. If the customer is the owner of this end product, should liability rest on the customer, or is it the fault of the AI system itself? Apportioning this liability cannot be addressed easily and requires extensive consideration and negotiation.\n\nThe most significant issue in relation to AI regarding warranties and liability, is the black box nature of AI systems, whereby the weightings etc. used in convolutional neural networks utilised in machine learning are dynamic and subject to constant change and flux. It may be difficult to settle upon warranties and liabilities when both parties accept that there may be a lack of explainability in the use of AI systems.\n\nA way in which AI liability will be dealt with is in the technical documents and instructions accompanying AI systems, and disputes will likely centre around whether users of AI strayed outside the intended parameters of the system's intended use. Contracts incorporating AI systems will increasingly concentrate on this element of AI as a product.\n\nWith the increased scrutiny on data protection, and with the volume of data used by AI systems, due diligence on adherence to data protection laws is crucial not least given the extensive fines possible under GDPR. A warranty/indemnity should be provided by the vendor that it will comply with all applicable data protection laws. This is increasingly an issue with the retention and return of data, especially where that data is personal data, as retention of data sets is a necessary part of the evolution of AI systems. If the data is to be retained, this increased risk may need to be reflected in a decreased purchase price.\n\nWhere legal liability could be at issue, then applicable insurance cover comes to the fore. While many vendors will have cyber insurance, this may only cover instances of a hack or a deliberate data breach, rather than damage caused by the AI system itself. It is important to look at the specificities of the cover and ensure it is adequate for the agreement involved, which would require legal advice."
    }
}