{
    "id": "dbpedia_6685_3",
    "rank": 54,
    "data": {
        "url": "https://arxiv.org/html/2401.13782v2",
        "read_more_link": "",
        "language": "en",
        "title": "Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/extracted/5445308/content/figures/conference-trends.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/review-scores.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akhf-hist.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akgt-hist.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akhf-violin.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akgt-violin.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akhf-qq.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akgt-qq.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/atet-forest.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akhf-heatmap.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akgt-heatmap.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/hai-country-year.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akhf-country-year.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akgt-country-year.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akhf_score_hist.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akgt_score_hist.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akhf-cdf.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akgt-cdf.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akhf-box.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/akgt-box.png",
            "https://arxiv.org/html/extracted/5445308/content/figures/score-differences.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "License: arXiv.org perpetual non-exclusive license\n\narXiv:2401.13782v2 [cs.DL] 03 Mar 2024\n\nTweets to Citations: Unveiling the Impact\n\nof Social Media Influencers on AI Research Visibility\n\nIain Xie Weissburg\n\nDepartment of Electrical and Computer Engineering\n\nUniversity of California, Santa Barbara\n\nSanta Barbara, CA, 93106\n\nixw@ucsb.edu\n\n&Mehir Arora*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT\n\nDepartment of Computer Science\n\nUniversity of California, Santa Barbara\n\nSanta Barbara, CA, 93106\n\nXinyi Wang\n\nDepartment of Computer Science\n\nUniversity of California, Santa Barbara\n\nSanta Barbara, CA, 93106\n\nLiangming Pan\n\nDepartment of Computer Science\n\nUniversity of California, Santa Barbara\n\nSanta Barbara, CA, 93106\n\n&William Yang Wang\n\nDepartment of Computer Science\n\nUniversity of California, Santa Barbara\n\nSanta Barbara, CA, 93106\n\nEqual ContributionCorresponding Author\n\nAbstract\n\nAs the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside controls precisely matched by 9 key covariates. Our statistical and causal inference analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. Given these findings, we advocate for a responsible approach to curation, encouraging influencers to uphold the journalistic standard that includes showcasing diverse research topics, authors, and institutions.\n\n1 Introduction\n\nIn the evolving landscape of artificial intelligence and machine learning (AI/ML), the exponential increase in conference papers, as depicted in Figure 1, alongside rapid technological advancements, has significantly transformed the dissemination of scholarly knowledge. A notable aspect of this transformation is the practice of online preprint sharing, with platforms like ArXiv becoming particularly prominent within the AI/ML community. This phenomenon allows for early access to research, often months before official publication, raising questions about the evolving relevance and reception of these papers in traditional academic forums. Most notably, how do people select papers to read in the online age?\n\nThis paper aims to explore the changing dynamics of academic discourse within the AI/ML community, emphasizing the constructive role of social media in addressing the challenges posed by the sheer volume of literature. We specifically focus on the case study of two influential ğ•ğ•\\mathbb{X}blackboard_X (formerly Twitter) users, AK (@_akhaliq) and Aran Komatsuzaki (@arankomatsuzaki), to understand how their social media activities aid in the curation and visibility of research. These influencers have emerged as pivotal figures in navigating the flood of information, akin to journalists in civic society, highlighting and contextualizing significant works for the community.\n\nAcknowledging the vital function of these influencers as curators, we examine the impact of their endorsements on the citation counts of shared papers. However, we also underscore the importance of maintaining a balanced research ecosystem. An over-reliance on a select group of curators may inadvertently skew the research landscape, emphasizing certain topics or perspectives over others. Therefore, we advocate for a responsible approach to curation, encouraging influencers to maintain the journalistic standard that includes showcasing diverse research topics, authors, and institutions.\n\nContributions.\n\nTo this end, we provide the following three main contributions to the discussion about the increasing impact of academic social media figures in the AI/ML domain:\n\nâˆ™âˆ™\\bulletâˆ™ Comprehensive Dataset with Control Samples. We collect a dataset of shared papers from AK and Komatsuzaki containing key paper information. We select control samples through precise matching, using several paper and author covariates.\n\nâˆ™âˆ™\\bulletâˆ™ Thorough Analysis of Citations and Demographics. Our comprehensive analysis aims to determine if papers shared by these influencers receive higher citation counts compared to non-shared papers. We conduct statistical and causal inference analysis and find significant evidence for a direct effect. We then explore the geographic and gender distributions of influencer-shared papers and compare them to reference points from the community at large.\n\nâˆ™âˆ™\\bulletâˆ™ Proposals for Future AI/ML Information Sharing. Finally, we propose that the academic community, particularly conference organizers, engage in a future discussion on evolving the conference system. This evolution is necessary to address the core challenge of managing an overwhelming number of submissions, ensuring that quality research is recognized and disseminated effectively. This approach will help ensure a more balanced and comprehensive understanding of research quality and relevance in these changing times.\n\n2 Related Work\n\nFor over a decade now, social media platformsâ€“namely ğ•ğ•\\mathbb{X}blackboard_Xâ€“have been studied as an influential means of scholarly communication. Darling et al. (2013) discusses the potential role of Twitter in many stages of the â€™life-cycleâ€™ of academic authorship and publication. Eysenbach (2011) provides early evidence to support social media sharing as a predictor of higher citation count in medical publications. More recently, studies have shown a statistically significant relationship between Twitter presence and citation counts across fields, especially after the first tweet Peoples et al. (2016); Vaghjiani et al. (2021). Others suggest that the correlation between tweets and citations is insignificant through randomized trials Tonia et al. (2016); Branch et al. (2023).\n\nWe note that the AI/ML community is much more active on platforms like ğ•ğ•\\mathbb{X}blackboard_X. While many previous works examine fields with a much lower volume of repository publications, the short research cycle and the need for quick dissemination of results, coupled with the rise of arXiv, motivates us to study the problem from the perspectives of modern AI/ML research lens. Additionally, the literature thus far has focused on social media as a forum for multi-user online discussion. In our work, we examine top-down dissemination from singular influencers, with many more followers than previously studied. We also contribute a geographic and gender analysis of influencer-sharing patterns and provide recommendations to conferences, influencers, and the wider community on managing the evolving field of Artificial Intelligence research.\n\n3 Data Collection\n\nWe model our analysis on retrospective cohort studies, in which a treatment and control group with identical underlying covariates are compared to determine the average treatment effect. In our case, we assume that a paperâ€™s citation count is most strongly influenced by elapsed time, quality, topic, and author prominence. While elapsed time is simple to measure, paper quality, topic are difficult to quantify. We use the publication venue and year as a proxy for quality and use a text embedding of the paperâ€™s title and abstract to approximate the topic. We use first author total citation counts and h-index, and the maximum of all authorsâ€™ citation counts and h-indexes to adjust for their prominence.\n\nAs such, our data collection process consists of three parts: (1) collecting the Target Set, the papers tweeted by @_akhaliq and @arankomatsuzaki, (2) collecting a large dataset of potential papers to match against, and (3) forming the Control Set by matching papers from (1) to papers from (2) with respect to the year of publication, the publication venue, and a text embedding of title and abstract. We detail each step below.\n\nTarget Set. The Target Set is collected by searching for document identifiers in the ğ•ğ•\\mathbb{X}blackboard_X feeds of both influencers (identifiers are found in links to arXiv.org or huggingface.co/papers). We use the Semantic Scholar (S2) API to query every document for desired attributes (Table 4). Notably, some papers are either not available on S2 or are not freely accessible. Hence, we remove any paper that lacks any required attribute. The number of unique papers and papers with all attributes for each influencer is shown in Table 2.\n\nWe find that roughly 90% of papers tweeted by either influencer have all attributes available. We express moderate caution about the minority of papers not included in our analysis, as they may be systematically different from papers we do include. However, we believe the large number of papers remaining in our analysis is sufficient to draw meaningful conclusions.\n\nControl Set. To build our Control Set, we first collect a large dataset of papers presented at the same venues and in the same years as those in the Target Set. Specifically, for every instance of a paper published in year yğ‘¦yitalic_y at venue vğ‘£vitalic_v, we query S2 for all papers published in year yğ‘¦yitalic_y at venue vğ‘£vitalic_v.\n\nWe follow the recommendations in King and Nielsen (2019) by performing exact matching on our categorical (year, venue, open_access ) and binned variables (n_authors, h-index, author cites), and Euclidean distance matching on our continuous variables (topic_embedding). Optimal matching can be reduced to the linear sum assignment problem, for which many efficient algorithms exist Crouse (2016). We use the implementation available in SciPy Virtanen et al. (2020).\n\nUsing this methodology, we match each paper in the Target Set to a paper in the Control Set with respect to the gathered covariates (Table 4). We exclude any paper for which we cannot find an exact match on categorical variables. For matching on topic embeddings, we use SPECTER2 Singh et al. (2022). Matches between papers were strong, and the distribution of cosine similarities as well as example matched pairs are detailed in Appendix A.\n\nReview Scores. To determine if we have successfully controlled for quality through our matching, we will look at the review scores of experimental and control pairs from some selected conferences. We extract the review data using OpenReview (2023). Across both paired datasets, we found 939 out of 7222 unique pairs with available scores.\n\nWe plot the mean review score of each treatment paper against the mean score of its paired control (Figure 2). For conferences that do not use numbered review scores, we assign numbers based on those of other conferences (7: Accept, 5: Borderline Accept, 3: Borderline Reject, 2: Reject).\n\nUsing the same three significance tests from Table 5, we do not find sufficient evidence to reject the null hypothesis that the control and experimental scores are from the same distribution (pğ‘pitalic_p-value >0.2absent0.2>0.2> 0.2). Assuming that mean review scores are an accurate measure of paper quality, we conclude that we have effectively controlled for paper quality in our matching.\n\n4 Analysis\n\nTo answer the central question of our work, we compare the impacts of papers shared by AK and Komatsuzaki against our control set. Then, we conduct multivariate analyses by geographic distributions and author attributes in their selected papers.\n\nContrasting Analysis. For the contrasting analysis, we will test the following hypotheses for correlation:\n\nâ€¢\n\nNull: Influencer-shared papers have the same citation count as others in the same field.\n\nâ€¢\n\nAlternative: Influencer-shared papers have a higher citation count than others in the same field.\n\nWe compare our paired target and control sets, as described in Section 3. We find that papers tweeted by AK have a median citation count of 24 (95% CI: 23, 25) versus 14 (95% CI: 13, 15) in the control group, and papers tweeted by Komatsuzaki have a median citation count of 31 (95% CI: 27, 34) versus 12 (95 % CI: 10.5, 13.5). Visually, we can see that both experimental set distributions are skewed toward higher citation counts when compared to their corresponding control sets (Figure 3). In the violin plots (Figures 2(c) and 2(d)), the three quartiles and max values are all higher in both of the shared paper distributions compared to the controls. In the 2-Sample Q-Q plots (Figure 4), we can see that the normalized quantiles are consistently higher for the test distributions.\n\nFinally, we establish statistical significance with three tests comparing the distributions of the experimental data with that of the control sets, Epps-Singleton (ES), Kolmogorov-Smirnov (KS), and Mann-Whitney U (MWU), none of which assume normal distribution, which is essential for our data. Table 5 shows the results, all with pğ‘pitalic_p-values well below even a stringent Î±=0.001ğ›¼0.001\\alpha=0.001italic_Î± = 0.001. From this, we can strongly reject the null hypothesis that the citation distributions for the influencer-shared papers and the control papers are the same.\n\nOverall, the correlation between influencer tweets and citation countâ€“and not review scoresâ€“points to a shift in how the community finds and reads papers. While traditionally, top conference acceptance (i.e. review score) has been a primary indicator of future citation count Lee (2018), we have shown that the sharing practices of far-reaching influencers are now a significant indicator of future research impact through citations.\n\nCausal Inference: Setup. Although we have shown a significant correlation between influencer sharing and citations, we have not investigated a causal link. For this, we turn to the model, techniques, and assumptions presented in Elazar et al. (2023). For additional background and details, see Appendix C\n\nWe aim to estimate the causal effect of the treatment Ağ´Aitalic_A, indicating that the paper was shared by influencers , on the outcome Yğ‘ŒYitalic_Y, if the paper is \"highly-cited\" or \"less-cited.\" Besides Ağ´Aitalic_A, there are a number of other factors, known as confounders, that can affect Yğ‘ŒYitalic_Y. We divide these confounders into two sets: observed Cğ¶Citalic_Câ€“which are the same used in our matching (Section 3)â€“and unobserved Uğ‘ˆUitalic_Uâ€“which are difficult to quantify or measure (e.g. novelty, contribution, hype).\n\nTo debias the effects of unobserved confounders Uğ‘ˆUitalic_U, we employ the negative outcome control (NOC) framework Card and Krueger (1993); Lipsitch et al. (2010). By finding a negative control outcome Nğ‘Nitalic_N that shares the same confounders as Yğ‘ŒYitalic_Y, but is not causally affected by Ağ´Aitalic_A, we can attempt to correct for the bias introduced by Uğ‘ˆUitalic_U. To this end, we select a paperâ€™s average review score for Nğ‘Nitalic_N, which we have already shown is not significantly correlated to Ağ´Aitalic_A (Figure 2) and which we believe share many of the same confounders (e.g., quality, contribution, author experience). However, another NCO can be substituted if deemed more suitable.\n\nTo account for fine-grained citation counts and review scores in comparison to the binary nature of Yğ‘ŒYitalic_Y and Nğ‘Nitalic_N, we define Ypsubscriptğ‘Œğ‘Y_{p}italic_Y start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT and Nqsubscriptğ‘ğ‘N_{q}italic_N start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT. For both, their value is 1 if the corresponding real-valued quality (citation count or average review score) is above the pthsuperscriptğ‘thp^{\\text{th}}italic_p start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT (or qthsuperscriptğ‘thq^{\\text{th}}italic_q start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT) quantile of the relevant sample distribution. We will use values of {50,75,90}507590\\{50,75,90\\}{ 50 , 75 , 90 } for both pğ‘pitalic_p and qğ‘qitalic_q in our analysis.\n\nFinally, we estimate the causal effect of influencer sharing on paper citations with the average treatment effect of the treated. Using the difference-in-difference assumption with NOC, we can write our estimate Elazar et al. (2023):\n\nATET=ğ”¼â¢[YA=1âˆ’NA=1]âˆ’ğ”¼â¢[YA=0âˆ’NA=0]ATETğ”¼delimited-[]subscriptğ‘Œğ´1subscriptğ‘ğ´1ğ”¼delimited-[]subscriptğ‘Œğ´0subscriptğ‘ğ´0\\text{ATET}=\\mathbb{E}[Y_{A=1}-N_{A=1}]-\\mathbb{E}[Y_{A=0}-N_{A=0}]ATET = blackboard_E [ italic_Y start_POSTSUBSCRIPT italic_A = 1 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT italic_A = 1 end_POSTSUBSCRIPT ] - blackboard_E [ italic_Y start_POSTSUBSCRIPT italic_A = 0 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT italic_A = 0 end_POSTSUBSCRIPT ]\n\nwhere ATET âˆˆ[âˆ’100%,100%]absentpercent100percent100\\in[-100\\%,100\\%]âˆˆ [ - 100 % , 100 % ] values closer to 0%percent00\\%0 % indicate weak to no effect of the treatment, and large absolute values indicate a stronger effect.\n\nCausal Inference: Results. First, we estimate the effect of Ağ´Aitalic_A on Yğ‘ŒYitalic_Y without accounting for the effects of Uğ‘ˆUitalic_U. We estimate ATET (95%-bootstrapping CI) to be 19% (15-24), 16% (13-20), 9% (6-12) for p={50,75,90}ğ‘507590p=\\{50,75,90\\}italic_p = { 50 , 75 , 90 }, respectively. This confirms the significant association between influencer sharing and citations we investigated during the contrasting analysis. However, this does not preclude the existence of strong confounders.\n\nFor that, we will use NOC to attempt to debias the effects of unobserved confounders, including quality. We record our results in Figure 5 and observe the following: (1) debiased effects are smaller than the unadjusted estimates, indicating our NCO has succeeded in accounting for some unobserved confounders; (2) all of our estimated effects are significant to the 95% level, because none contain 0 in their confidence interval; (3) influencer sharing is most successful at increasing the citations in lower percentilesâ€“papers with very high citation counts experience a smaller (yet still significant) effect compared to those with fewer citations.\n\nGeographic Distributions. In exploring the evolving landscape of machine learning (ML) paper dissemination, it is essential to consider the implications of a more centralized curation model, particularly as it relates to geographic and gender diversity in scholarly works. Our approach is to present data and observations that highlight trends and do not attribute intentional bias to the influencers involved.\n\nOur analysis begins by examining the geographic distribution in the dissemination of ML papers. Given the American affiliations of AK and Aran Komatsuzaki, we explore whether this translates into a geographic skew in the papers they share. To contextualize our findings, we refer to the geographic distribution of AI repository publications from the Stanford HAI 2023 AI Index Report (Figure 7). We choose to view this data in particular, as our selected influencers share papers from repositories (i.e. ArXiV).\n\nTo test this, we first collect the geographic data of the shared papers. First, we use S2 and dblp (2023) to collect the affiliation data of all listed authors from each test set. We then utilize the Nominatim geocoding API to find the approximate latitude and longitude of each affiliation, manually adjusting visibly inaccurate coordinates. From this information, we find the country of each affiliation and then use majority voting to assign each publication a geographic area. At this point, we can see that both influencers share papers from around the world in Figure 6. Finally, we aggregate these countries into the same geographic areas used in the HAI Report and plot using a similar format (Figure 8).\n\nTo account for the discrepancy between date ranges in the HAI Report and our influencersâ€™ activity, we will limit our analysis to the overlap between them. Additionally, we will focus on the range from 2018 to 2021, because of the low sample size of shared papers pre-2018â€“only 5 in total.\n\nWe must note, though, that using solely self-reported affiliations can have an inherent bias toward the United States. For example, many researchers affiliated with U.S.-based organizations are assigned to the United States despite working out of another area. Additionally, we must note the prominence of the \"Unknown\" category in the data of both influencers, where affiliations were not found.\n\nNevertheless, our results highlight the potential for centralized individuals to shape the perceived narrative of AI research prominence.\n\nGender Distributions. Beyond geographic diversity, gender diversity is crucial in Computer Science and Engineering, fields historically dominated by men. We extract author names and affiliations as described above. In this section, we filter only the first authors of each paper. For gender classification, we used the AMiner Scholar Gender Prediction API, which categorizes authors as \"male,\" \"female,\" or \"UNKNOWN\" based on name and affiliationâ€“if available. The API uses a majority vote of the results from three sources: google image search and facial recognition, the Facebook Generated Names List Tang et al. (2011), and WebGP Gu et al. (2016).\n\nTo ground our view of the overall gender distribution in the field, we reference the Taulbee surveyâ€™s reported gender distribution of US Ph.D. awardees and faculty in CS and related fields from 2021-2022 Zweben and Bizot (2023). To match the classifications we have available, we will consider the binary reported genders from the survey.\n\nOur analysis revealed an 80:20 male-to-female ratio among authors with identifiable genders in the @_akhaliq dataset and an 81:19 ratio in the @arankomatsuzaki dataset. These ratios align somewhat with the Taulbee surveyâ€™s reported 77:23 ratio in computing Ph.D. awardees and deviated slightly more from the 76:24 ratio in faculty. These deviations may stem from a trend toward increasing female representation in the ML space; the survey is recent data, while our influencer data spans several years into the past.\n\n5 Discussion\n\nOur analysis suggests that ML influencers strongly affect paper visibility, indicating a change in how ideas are propagated through the community. We discuss the downstream implications of influencers on the community and make recommendations on how to help improve the paper curation problem and enhance equity in publication visibility.\n\nInfluencers and the ML Community. Influencers serve as pivotal curators in the ML landscape. With the explosive growth of machine learning research, the community increasingly relies on social media to keep up-to-date with new developments. Their role in streamlining the dissemination process is akin to that of journalists in news media, making novel ideas and breakthroughs more accessible.\n\nHowever, we advise caution against excessive dependence on a limited set of information sources. Research inherently involves bottom-up exploration of a wide array of topics. Focusing on a handful of individualsâ€™ highlighted papers necessarily offers a narrow view of the research landscape. We encourage the community to keep the online academic space competitive, allowing for a diversity of highly visible ideas. This goal can be achieved through active participation in an open, community-driven curation process, enhancing the variety of prominent ideas. Additionally, we urge influencers to share a diverse array of ideas. This includes showcasing various techniques and subtopics within their areas of focus, thereby exposing community members to new approaches and concepts.\n\nEnhancing Equity. Unquestionably, we would rather have more voices than fewer in the machine learning community. The trend towards influencer-led dissemination in the ML community offers new avenues to enhance equity. Our geographic analysis indicates a bias towards U.S.-centered research in influencer-shared papers. Despite reflecting the current U.S. prominence in AI/ML repository publications, it also reveals the potential to include research from a broader range of regions, including Europe, Asia, Africa, and Latin America. Similarly, Machine Learning sees a dramatic disparity in male versus female authors. Additionally, our gender distribution analysis, though not indicating a bias in influencer-shared content, highlights the general gender disparity within ML. This disparity presents an opportunity to foster gender diversity in the field.\n\nWhile we specifically examine geography and gender, these principles apply broadly: proactive efforts in the online domain can significantly enhance equity. We encourage influencers to actively promote visibility for diverse groups globally. We emphasize that this does not necessarily indicate bias among current influencers but serves as a call for vigilance against potential biases as the AI/ML domain expands. This connects back to our recommendation for fostering a diverse online space where everyone can contribute to broadening the spectrum of shared ideas.\n\n6 Conclusion\n\nThis study delves into the influence of social media influencers on the dissemination and recognition of academic work in AI/ML, specifically examining the impact of AK and Aran Komatsuzaki on platforms like ğ•ğ•\\mathbb{X}blackboard_X and Hugging Face. Our analysis demonstrates that papers endorsed by these influencers receive significantly more citations than those that are not, underscoring the role of influencers in not only amplifying the reach of specific research but also in shaping its visibility in the field. This influence extends beyond merely sharing higher-quality papers, highlighting their ability to effectively contextualize and promote substantial findings within the community.\n\nThe study further discusses the dual role of influencers as both catalysts for visibility and curators of content, emphasizing the need for a balance in their influence to ensure a diversity of perspectives in the AI/ML research landscape. The implications of this influence are profound, suggesting a need for the academic community to reassess traditional methods of paper selection and review. Our findings encourage a dialogue among conference organizers and academic institutions to evolve the peer-review process and adapt to these changing norms. Additionally, the study opens avenues for future research into the generalizability of these trends in other scientific fields and the mechanisms behind the influence of social media on academic recognition.\n\nImpact Statement\n\nRecognizing the influential role of social media influencers in the academic community, particularly in the fields of AI/ML, itâ€™s important to gently encourage them to be aware of their impact. Influencers play a key role in shaping discussions and trends, and there is a growing need for them to consider the diversity and inclusivity of the research they share. This is not to undermine their contributions but to enhance the richness of academic discourse. Similarly, the academic community might benefit from reevaluating traditional metrics of research impact, embracing both peer-reviewed channels and digital platforms for a more holistic approach to recognizing scholarly work.\n\nIn doing so, we hope to spark future research into understanding any unintentional biases influencers might have, such as favoring research from prestigious institutions or specific regions. This is a subtle yet crucial aspect of ensuring a balanced representation in the academic landscape, preventing the overshadowing of significant but less publicized work. While influencers may have personal or commercial interests, we trust in their capacity to acknowledge and manage these to avoid conflicts of interest. This approach would help in preventing echo chambers and promoting a diverse range of perspectives in AI/ML research. Overall, we advocate for a collaborative and mindful effort among influencers and the academic community to foster an equitable and inclusive environment for scholarly discussions.\n\nReferences\n\nBranch et al. [2023] Trevor A. Branch, Isabelle M. CÃ´tÃ©, Solomon R. David, Josh Drew, Michelle LaRue, Melissa C. MÃ¡rquez, E. Chris M. Parsons, D. Rabaiotti, David Shiffman, David A. Steen, and Alexander L. Wild. Controlled experiment finds no detectable citation bump from Twitter promotion. bioRxiv, 2023. URL https://api.semanticscholar.org/CorpusID:262087567.\n\nCard and Krueger [1993] David Card and Alan B. Krueger. Minimum wages and employment: A case study of the fast food industry in new jersey and pennsylvania. NBER Working Paper Series, 1993. URL https://api.semanticscholar.org/CorpusID:1140202.\n\nCrouse [2016] David F. Crouse. On implementing 2D rectangular assignment algorithms. IEEE Transactions on Aerospace and Electronic Systems, 52(4):1679â€“1696, 2016. doi: 10.1109/TAES.2016.140952.\n\nDarling et al. [2013] Emily S. Darling, David Samuel Shiffman, Isabelle M. CÃ´tÃ©, and Joshua A. Drew. The role of twitter in the life cycle of a scientific publication. ArXiv, abs/1305.0435, 2013. URL https://api.semanticscholar.org/CorpusID:7583994.\n\ndblp [2023] dblp. dblp Computer Science Bibliography: Monthly Snapshot Release of October 2023. https://dblp.org/xml/release/dblp-2023-10-01.xml.gz, 2023. Accessed: 2023-10-01.\n\nElazar et al. [2023] Yanai Elazar, Jiayao Zhang, David Wadden, Boshen Zhang, and Noah A. Smith. Estimating the causal effect of early arxiving on paper acceptance. ArXiv, abs/2306.13891, 2023. URL https://api.semanticscholar.org/CorpusID:259251893.\n\nEysenbach [2011] Gunther Eysenbach. Can Tweets Predict Citations? Metrics of Social Impact Based on Twitter and Correlation with Traditional Metrics of Scientific Impact. Journal of Medical Internet Research, 13, 2011. URL https://api.semanticscholar.org/CorpusID:2157129.\n\nFeder et al. [2021] Amir Feder, Katherine A. Keith, Emaad A. Manzoor, Reid Pryzant, Dhanya Sridhar, Zach Wood-Doughty, Jacob Eisenstein, Justin Grimmer, Roi Reichart, Margaret E. Roberts, Brandon M Stewart, Victor Veitch, and Diyi Yang. Causal inference in natural language processing: Estimation, prediction, interpretation and beyond. Transactions of the Association for Computational Linguistics, 10:1138â€“1158, 2021. URL https://api.semanticscholar.org/CorpusID:237386009.\n\nGu et al. [2016] Xiaotao Gu, Hong Yang, Jie Tang, and Jing Zhang. Web User Profiling Using Data Redundancy. In Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM â€™16, page 358â€“365. IEEE Press, 2016. ISBN 9781509028467.\n\nImbens and Rubin [2015] Guido Imbens and Donald B. Rubin. Causal inference for statistics, social, and biomedical sciences: An introduction. 2015. URL https://api.semanticscholar.org/CorpusID:123646167.\n\nKing and Nielsen [2019] Gary King and Richard Nielsen. Why Propensity Scores Should Not Be Used for Matching. Political Analysis, 27(4):435â€“454, 2019 2019. URL https://doi.org/10.1017/pan.2019.11.\n\nLee [2018] Danielle H. Lee. Predictive power of conference-related factors on citation rates of conference papers. Scientometrics, 118:281â€“304, 2018. URL https://api.semanticscholar.org/CorpusID:53247921.\n\nLi [2023] Xin Li. Conference-Acceptance-Rate, 2023. URL https://github.com/lixin4ever/Conference-Acceptance-Rate. GitHub repository. Accessed: 2023-12-18.\n\nLipsitch et al. [2010] Marc Lipsitch, Eric J. Tchetgen Tchetgen, and Ted Cohen. Negative controls: A tool for detecting confounding and bias in observational studies. Epidemiology, 21:383â€“388, 2010. URL https://api.semanticscholar.org/CorpusID:13292337.\n\nMaslej et al. [2023] Nestor Maslej, Loredana Fattorini, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, Helen Ngo, Juan Carlos Niebles, Vanessa Parli, Yoav Shoham, Russell Wald, Jack Clark, and Raymond Perrault. Artificial Intelligence Index Report 2023, 2023.\n\nOpenReview [2023] OpenReview. OpenReview API. https://api.openreview.net, 2023. Accessed: 2024-01-29.\n\nPeoples et al. [2016] Brandon K. Peoples, Stephen R. Midway, Dana K. Sackett, Abigail J. Lynch, and Patrick B. Cooney. Twitter Predicts Citation Rates of Ecological Research. PLoS ONE, 11, 2016. URL https://api.semanticscholar.org/CorpusID:13689703.\n\nSheppard et al. [1999] Lianne Sheppard, Drew Levy, Gary A. Norris, Timothy V. Larson, and Jane Q. Koenig. Effects of ambient air pollution on nonelderly asthma hospital admissions in seattle, washington, 1987-1994. Epidemiology, 10 1:23â€“30, 1999. URL https://api.semanticscholar.org/CorpusID:36893348.\n\nSingh et al. [2022] Amanpreet Singh, Mike Dâ€™Arcy, Arman Cohan, Doug Downey, and Sergey Feldman. Scirepeval: A multi-format benchmark for scientific document representations. In Conference on Empirical Methods in Natural Language Processing, 2022. URL https://api.semanticscholar.org/CorpusID:254018137.\n\nSofer et al. [2016] Tamar Sofer, David B. Richardson, Elena Colicino, Joel Schwartz, and Eric J. Tchetgen Tchetgen. On negative outcome control of unobserved confounding as a generalization of difference-in-differences. Statistical science : a review journal of the Institute of Mathematical Statistics, 31 3:348â€“361, 2016. URL https://api.semanticscholar.org/CorpusID:207137332.\n\nTang et al. [2011] C. Tang, K. Ross, N. Saxena, and R. Chen. Whatâ€™s in a Name: A Study of Names, Gender Inference, and Gender Behavior in Facebook. In J. Xu, G. Yu, S. Zhou, and R. Unland, editors, Database Systems for Advanced Applications, volume 6637 of Lecture Notes in Computer Science, Berlin, Heidelberg, 2011. Springer. doi: 10.1007/978-3-642-20244-5_33.\n\nTonia et al. [2016] Thomy Tonia, Herman Van Oyen, Anke Berger, Christian Schindler, and Nino KÃ¼nzli. If I tweet will you cite? The effect of social media exposure of articles on downloads and citations. International Journal of Public Health, 61:513â€“520, 2016. URL https://api.semanticscholar.org/CorpusID:27919192.\n\nVaghjiani et al. [2021] Nilan G Vaghjiani, Vatsal Lal, Nima Vahidi, Ali Ebadi, Matthew Carli, Adam P. Sima, and Daniel H Coelho. Social Media and Academic Impact: Do Early Tweets Correlate With Future Citations? Ear, nose, & throat journal, page 1455613211042113, 2021. URL https://api.semanticscholar.org/CorpusID:237292881.\n\nVirtanen et al. [2020] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, StÃ©fan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J Carey, Ä°lhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R. Harris, Anne M. Archibald, AntÃ´nio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17:261â€“272, 2020. doi: 10.1038/s41592-019-0686-2.\n\nZhang et al. [2021] B. Zhang, Dylan S. Small, Karen B. Lasater, M. McHugh, Jeffrey H. Silber, and Paul R. Rosenbaum. Matching one sample according to two criteria in observational studies. Journal of the American Statistical Association, 118:1140 â€“ 1151, 2021. URL https://api.semanticscholar.org/CorpusID:240560096.\n\nZweben and Bizot [2023] Stuart Zweben and Betsy Bizot. CRA 2022 Taulbee Survey: Record Doctoral Degree Production; More Increases in Undergrad Enrollment Despite Increased Degree Production. Computing Research News, May 2023.\n\nAppendix A Target-Control Matching\n\nQualitatively, the matched pairs are very similar in topic, almost always covering the same sub-field of research (for example, language model hallucinations). We supply a random sample of matched pairs in table 6. The distribution of scores is shown in table 9, and shows that the matched pairs have high cosine similarity scores. Our results are consistent across many choices of matching schemes, such as when we use more than three quantiles for binned variables, or exclude author characteristics altogether.\n\nAppendix B Additional Analysis Plots\n\nAppendix C Causal Inference\n\nFor our causal inference analysis, we draw primarily from the model, techniques, and assumptions presented in Elazar et al. [2023]. In turn, they point interested readers to Imbens and Rubin [2015] and Feder et al. [2021].\n\nBackground.\n\nIn our work, we study the outcome as a binary variable Yğ‘ŒYitalic_Y, indicating if a paper is \"highly-cited\" (Y=1ğ‘Œ1Y=1italic_Y = 1) or \"less-cited\" (Y=0ğ‘Œ0Y=0italic_Y = 0). By introducing our treatment Ağ´Aitalic_A, we can define two cases for any given paper: Y1subscriptğ‘Œ1Y_{1}italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, the outcome if the paper were shared by influencers (when A=1ğ´1A=1italic_A = 1), or Y0subscriptğ‘Œ0Y_{0}italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, the outcome if the paper were not shared by influencers (when A=0ğ´0A=0italic_A = 0). In actuality, we can only observe exactly one of these for each paper. Rather, the goal of causal inference is to estimate the change in outcome if the treatment were flipped (Figure 12). Specifially, we hope to answer the question, does influencer sharing increase the likelihood of a paper being highly-cited?\n\nTo accomplish this, we use the average treatment effect on treated:\n\nATET=ğ”¼â¢[Y1âˆ’Y0|A=1]ATETğ”¼delimited-[]subscriptğ‘Œ1conditionalsubscriptğ‘Œ0ğ´1\\text{ATET}=\\mathbb{E}[Y_{1}-Y_{0}|A=1]ATET = blackboard_E [ italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_A = 1 ]\n\nwhich is the expected increase in highly-cited papers when shared by influencers, for those already shared.\n\nNegative Outcome Control and Difference-in-Difference.\n\nTo debias the effects of our unobserved confounders, we will utilize the Negative Outcome Control (NOC) framework Card and Krueger [1993], Lipsitch et al. [2010]. Specifically, we will use Difference-in-Difference (DiD) to estimate ATET over two time periods tâˆˆ{0,1}ğ‘¡01t\\in\\{0,1\\}italic_t âˆˆ { 0 , 1 } Sheppard et al. [1999]:\n\nATET=ğ”¼â¢[Y1â¢(1)âˆ’Y0â¢(1)]âˆ’ğ”¼â¢[Y1â¢(0)âˆ’Y0â¢(0)]ATETğ”¼delimited-[]subscriptğ‘Œ11subscriptğ‘Œ01ğ”¼delimited-[]subscriptğ‘Œ10subscriptğ‘Œ00\\text{ATET}=\\mathbb{E}[Y_{1}(1)-Y_{0}(1)]-\\mathbb{E}[Y_{1}(0)-Y_{0}(0)]ATET = blackboard_E [ italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1 ) - italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( 1 ) ] - blackboard_E [ italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 0 ) - italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( 0 ) ]\n\nwhich can be estimated by a fitting a logistic model and bootstrapping for confidence intervals Elazar et al. [2023].\n\nSofer et al. [2016] establishes that NCO and DiD-based estimators are equivalent, meaning ATET can be rewritten as:\n\nATET=ğ”¼â¢[Y1âˆ’N1]âˆ’ğ”¼â¢[Y0âˆ’N0]ATETğ”¼delimited-[]subscriptğ‘Œ1subscriptğ‘1ğ”¼delimited-[]subscriptğ‘Œ0subscriptğ‘0\\text{ATET}=\\mathbb{E}[Y_{1}-N_{1}]-\\mathbb{E}[Y_{0}-N_{0}]ATET = blackboard_E [ italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ] - blackboard_E [ italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ]\n\nand solved by taking the difference across treatment groups of the difference between Yğ‘ŒYitalic_Y and Nğ‘Nitalic_N.\n\nAssumptions.\n\nTo perform our causal estimate, we assume the following conditions hold:\n\n1.\n\nIgnorability: {Y0,Y1}âŸ‚âŸ‚A|(C,U)\\{Y_{0},Y_{1}\\}\\perp\\!\\!\\!\\perp A|(C,U){ italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } âŸ‚ âŸ‚ italic_A | ( italic_C , italic_U )\n\n2.\n\nPositivity: 0<â„™(A=1|C=c,U=u)<10<\\mathbb{P}(A=1|C=c,U=u)<10 < blackboard_P ( italic_A = 1 | italic_C = italic_c , italic_U = italic_u ) < 1\n\n3.\n\nConsistency: Ya=Yoâ¢bâ¢sâ¢ if â¢Aoâ¢bâ¢s=asubscriptğ‘Œğ‘superscriptğ‘Œğ‘œğ‘ğ‘  if superscriptğ´ğ‘œğ‘ğ‘ ğ‘Y_{a}=Y^{obs}\\textit{ if }A^{obs}=aitalic_Y start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT = italic_Y start_POSTSUPERSCRIPT italic_o italic_b italic_s end_POSTSUPERSCRIPT if italic_A start_POSTSUPERSCRIPT italic_o italic_b italic_s end_POSTSUPERSCRIPT = italic_a\n\n4.\n\nNegative control: Na=Nâ¢ for â¢a=0,1formulae-sequencesubscriptğ‘ğ‘ğ‘ for ğ‘01N_{a}=N\\textit{ for }a=0,1italic_N start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT = italic_N for italic_a = 0 , 1\n\n5.\n\nAdditive Equi-confounding:\n\nğ”¼â¢[Yaâ¢(1)âˆ’Yaâ¢(0)|U,A=a,C]=ğ”¼â¢[Yaâ¢(1)âˆ’Yaâ¢(0)|A=a,C]â¢ for â¢A=0,1formulae-sequenceğ”¼delimited-[]subscriptğ‘Œğ‘1conditionalsubscriptğ‘Œğ‘0ğ‘ˆğ´ğ‘ğ¶ğ”¼delimited-[]subscriptğ‘Œğ‘1conditionalsubscriptğ‘Œğ‘0ğ´ğ‘ğ¶ for ğ´01\\mathbb{E}[Y_{a}(1)-Y_{a}(0)|U,A=a,C]\\\\ =\\mathbb{E}[Y_{a}(1)-Y_{a}(0)|A=a,C]\\textit{ for }A=0,1blackboard_E [ italic_Y start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 ) - italic_Y start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 0 ) | italic_U , italic_A = italic_a , italic_C ] = blackboard_E [ italic_Y start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 ) - italic_Y start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 0 ) | italic_A = italic_a , italic_C ] for italic_A = 0 , 1\n\nIn other words, ignorability assumes (C,U)ğ¶ğ‘ˆ(C,U)( italic_C , italic_U ) are the only confounders with an effect on the outcome; positivity means each paper has a non-zero chance of being and not being influencer-shared; consistency establishes that the potential outcomes Yasubscriptğ‘Œğ‘Y_{a}italic_Y start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT and observed outcomes Yoâ¢bâ¢ssuperscriptğ‘Œğ‘œğ‘ğ‘ Y^{obs}italic_Y start_POSTSUPERSCRIPT italic_o italic_b italic_s end_POSTSUPERSCRIPT agree for a given treatment level Aoâ¢bâ¢ssuperscriptğ´ğ‘œğ‘ğ‘ A^{obs}italic_A start_POSTSUPERSCRIPT italic_o italic_b italic_s end_POSTSUPERSCRIPT; negative control assumes that the NCO is not causally affected by the treatment Ağ´Aitalic_A; additive equi-confounding relies on a linear (or logistic) outcome model for Uğ‘ˆUitalic_U.\n\nReview Scores as a Negative Control Outcome.\n\nThe goal of the Negative Outcome Control (NOC) framework Card and Krueger [1993], Lipsitch et al. [2010] is to find a Negative Control Outcome (NCO) variable that is affected by the same confounders (C,U)ğ¶ğ‘ˆ(C,U)( italic_C , italic_U ) as the outcome Yğ‘ŒYitalic_Y, but not the treatment. This way, we can de-bias the effects of confounders not captured by the metadata and text embeddings collected from S2. For this, we choose the average conference review score for each paper, collected as described in Section 3. We believe that this sub-sample is representative for the following reasons: (1) influencers often share preprint works before conference acceptance or proceedings are released; (2) our matching accounts for publication venue as a confounder; (3) using bootstrapping on the three tests from Table 5, we find there is not significant evidence to reject that the sub-sample and full dataset citations come from different distributions (pğ‘pitalic_p-value >0.05absent0.05>0.05> 0.05).\n\nMatching and Causal Inference.\n\nElazar et al. [2023] use tripartite matching on a number of covariates Zhang et al. [2021], and only sampled from one venue. To control the topic covariate, they use SPECTER embeddings to build 20 topic clusters and minimize distance for numerical variables (author citations, institution rank, etc.)\n\nInstead, we group the treated and control samples based on a mix of exact matching (venue, year, open access) and quantile binning (number of authors, h-index, and author cites). From these groups, we match samples by minimizing the L2subscriptğ¿2L_{2}italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT difference of text embeddings. This way, we can most accurately capture increased nuance between \"viral\" topics, techniques, and models.\n\nAdditionally, we use first-author information, rather than both minimum and average, to increase our group sizes and improve the quality of topic matches while maintaining descriptive author details.\n\nAppendix D Limitations\n\nWhile our study provides valuable insights into the role of influencers in the machine learning (ML) community, there are several limitations that must be acknowledged:\n\nBinary Gender Analysis: Our study utilized a gender prediction API that only outputs binary genders (male and female), limiting our ability to capture the full spectrum of gender identities. Consequently, our findings may not accurately represent the diversity of gender identities within the ML community.\n\nAccuracy with Non-Western Names: The gender prediction API may exhibit lower accuracy when analyzing non-Western names. As a result, the studyâ€™s conclusions regarding gender disparity might not fully capture the global diversity of our samples.\n\nSelf-Reported Affiliations: The affiliations in our dataset are self-reported, which can lead to inconsistencies such as misspellings or missing location information. This limitation affects the accuracy of our geographical analysis, as the data may not accurately reflect the true affiliations or locations of the authors. Consequently, our observations regarding geographical concentration and diversity must be interpreted with caution. Additionally, this limitation posed as a barrier to investigating institutions as an observed confounder for causal inference. We invite future studies with more complete affiliation data to investigate this.\n\nLack of Randomized Control Trial: The study did not include a randomized control trial, often considered the gold standard for establishing causality. Without this, we cannot conclusively determine whether the patterns observed are directly attributable to the influencersâ€™ activities or are coincidental. Though we attempt to remedy this through causal inference, such techniques are contingent upon the validity of our assumptions."
    }
}