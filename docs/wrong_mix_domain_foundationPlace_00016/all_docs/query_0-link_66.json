{
    "id": "wrong_mix_domain_foundationPlace_00016_0",
    "rank": 66,
    "data": {
        "url": "http://iris-hep.org/projects/skyhookdm.html",
        "read_more_link": "",
        "language": "en",
        "title": "SkyhookDM",
        "top_image": "http://iris-hep.org/logos/skyhookdmLogoJeff.png",
        "meta_img": "http://iris-hep.org/logos/skyhookdmLogoJeff.png",
        "images": [
            "http://iris-hep.org/assets/logos/Iris-hep-4-no-long-name.png",
            "http://iris-hep.org/assets/logos/skyhookdmLogoJeff.png",
            "http://iris-hep.org/assets/images/skyhook-arch-blog.png",
            "http://iris-hep.org/assets/images/skyhook-lat.png",
            "http://iris-hep.org/assets/images/skyhook-cpu.png",
            "http://iris-hep.org/assets/logos/Iris-hep-5-just-graphic.png",
            "http://iris-hep.org/assets/images/nsf-logo-128.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "The Institute for Research and Innovation in Software for High Energy Physics (IRIS-HEP) has been established to meet the software and computing challenges of the planned upgrades to the Large Hadron Collider, the world’s most powerful particle accelerator. IRIS-HEP pursues R&D for the software needed to acquire, manage, process and analyze the torrent of data that will be produced by the upgrade accelerator and its detectors as part of the search for discoveries beyond the Standard Model of Particle Physics.",
        "meta_lang": "en",
        "meta_favicon": "/apple-touch-icon.png",
        "meta_site_name": "Institute for Research and Innovation in Software for High Energy Physics",
        "canonical_link": "http://iris-hep.org/projects/skyhookdm.html",
        "text": "Skyhook Data Management\n\nOverview\n\nHL-LHC will challenge existing storage systems with regards to both data volumes and velocity: analysis datasets will grow significantly and users will demand higher event rates to improve the time-to-insight. The SkyHook DM project is an investment into computational storage, relying on the insight that the data organization of HEP files is highly structured. The service is able to recognize the layout of files and “push down” structured queries from client to server, taking advantage of the computational capacity in the storage hardware and reducing data movement significantly.\n\nCombining data management with storage also creates the opportunity for new services that can help avoid dataset copies and thereby can significantly save storage space. Data management-enabled storage systems can provide views by combining parts of multiple datasets. For HEP this means that columns from one table can be combined with columns from a different table without creating copies. For this to work, these storage systems need to store sufficient metadata and naming conventions about datasets. This makes them a natural place for maintaining this metadata and servicing it to other tools in convenient formats.\n\nSkyhook Data Management is an extension of the Ceph open source distributed storage system for the scalable storage of tables and for offloading common data management operations on them, including selection, projection, aggregation, and indexing, as well as user-defined functions. The goal of SkyhookDM is to transparently scale out data management operations across many storage servers leveraging the scale-out and availability properties of Ceph while significantly reducing the use of CPU cycles and interconnect bandwidth for unnecessary data transfers. The SkyhookDM architecture is also designed to transparently optimize for future storage devices of increasing heterogeneity and specialization. All the data movements from the Ceph OSDs to the client happen in Apache Arrow format.\n\nSkyhookDM is currently an incubator project at the Center for Research on Open Source Software at the University of California Santa Cruz.\n\nSalient Features\n\nEnables pushing down filters, projections, compute operations to the Storage backend for minimal data transfer over the network and linear scalability.\n\nAllows storing data in Parquet files for minimizing Disk I/O though predicate and projection pushdown.\n\nAllows writing files to a POSIX filesystem interface.\n\nMinimal deployment overhead either via Rook or Ceph-Deploy.\n\nPlugs-in seamlessly into the Arrow Dataset API and leverages all its functionality like dataset discovering, partition pruning, etc.\n\nWorks with latest Apache Arrow and latest Ceph versions.\n\nArchitecture\n\nIn the storage layer, we extend the Ceph Object Store with plugins built using the Object Class SDK to allow scanning objects containing Parquet data inside the Ceph OSDs. We utilize the Apache Arrow framework for building the data processing logic in the plugins. On the client side, we extend CephFS with a SkyhookDirectObjectAccess API that allows invoking Object Class methods on RADOS objects to perform query operations. We export our implementation by creating a new FileFormat in Apache Arrow called SkyhookFileFormat that uses the SkyhookDirectObjectAcess API to offload Parquet file scanning to the storage layer.\n\nPerformance Evaluation\n\nWe compare the query latencies of filtering a 1.2 billion row dataset via Parquet and Skyhook file formats with 1%, 10%, and 100% row selectivities. As shown in the above plot, Parquet performance doesn’t improve on scaling out from 4 to 16 nodes as it stays bottlenecked on the client’s CPUs. On the other hand, performance of Skyhook improves as it can distribute CPU consumption amongst the storage nodes and can scale out almost linearly.\n\nThe above two plots shows how Parquet (top) stays bottlenecked on the client CPU while Skyhook (bottom) distributes CPU usage between the storage nodes and allows scale out.\n\nOngoing Work\n\nWorking on deploying Skyhook in the UNL and SSL clusters.\n\nWorking on making the Coffea-Skyhook integration more user-friendly.\n\nWorking on joining HEP datasets using DuckDB/Arrow/Fugue.\n\nA middleware to allow writing Parquet files containing Nanoevents from ServiceX to SkyhookDM via CephFS.\n\nGithub repository.\n\nGetting started instructions and notebook.\n\nCode walkthrough video.\n\nAnnouncements\n\nApril, 2022 - Skyhook is deployed at UNL and at the SSL at the University of Chicago.\n\nMarch, 2022 - Skyhook: Toward an Arrow-Native Storage System, to appear in CCGrid 2022.\n\nJanuary, 2022 - Skyhook: Bringing Computation to Storage with Apache Arrow\n\nOctober, 2021 - Skyhook is now a part of Apache Arrow !\n\nDecember, 2021 - SkyhookDM v0.4.0 Released !\n\nJuly, 2021 - SkyhookDM v0.3.0\n\nMarch, 2021 - SkyhookDM v0.1.1 Released !\n\nFebruary, 2021 - SkyhookDM v0.1.0 Released !\n\nFebruary, 2021 - Guide for getting started with SkyhookDM.\n\nFellows\n\nJayjeet Chakraborty (current)\n\nXiongfeng Song (former)\n\nTeam\n\nJeff LeFevre\n\nIvo Jimenez\n\nEsmaeil Mirvakili\n\nJayjeet Chakraborty\n\nXiaowei (Aaron) Chu\n\nCarlos Maltzahn\n\nPresentations\n\n2 Dec 2022 - \"Open Source Program Offices in Research Universities\", Carlos Maltzahn, CHPC National Conference 2022\n\n28 Sep 2022 - \"Birds of a Feather: Pathways to Enable an Open Source Ecosystem for the Skyhook Project\", Carlos Maltzahn, 2022 UC Santa Cruz Open Source Symposium\n\n27 Sep 2022 - \"Welcome & Introductions\", Carlos Maltzahn, 2022 UC Santa Cruz Open Source Symposium\n\n23 Jun 2022 - \"HPC Panel at the Data Thread\", Carlos Maltzahn, The Data Thread Conference\n\n13 Jun 2022 - \"Skyhook Blueprint for Computational Storage, a Case for Amplifying Research Impact via Open Source\", Carlos Maltzahn, Research and Practice Colloquium at Friedrich-Alexander-Universität, Erlangen-Nürnberg, Germany\n\n23 May 2022 - \"Analysis user experience with the Python HEP ecosystem\", Jim Pivarski, Analysis Ecosystems Workshop II\n\n17 May 2022 - \"Skyhook: Towards an Arrow-Native Storage System\", Jayjeet Chakraborty, CCGrid22\n\n6 Apr 2022 - \"Creating an OSPO at the University of California\", Carlos Maltzahn, OSPOlogy: How Academic OSPOs are Amplifying Research Impact\n\n25 Mar 2022 - \"Faculty and Student Session: Open Source Research Experience (OSRE)\", Carlos Maltzahn, The Association of Computer Science Departments at Minority Institutions (ADMI) High Performance Computing and Gateways 2022 Symposium (ADMI 2022)\n\n2 Feb 2022 - \"Creating an OSPO at the University of California\", Carlos Maltzahn, OSPO++ Academic Track: UC Santa Cruz and UVM on setting up an OSPO\n\n4 Nov 2021 - \"Skyhook Data Management\", Carlos Maltzahn, Analysis Grand Challenge Tools 2021 Workshop\n\n2 Nov 2021 - \"Towards an OSPO at the University of California\", Carlos Maltzahn, Linux Foundation Membership Summit\n\n26 Oct 2021 - \"Ceph\", Carlos Maltzahn, DPS Guest Lecture at LIACS, Leiden University\n\n29 Sep 2021 - \"SkyhookDM: An Arrow-Native Storage System\", Jayjeet Chakraborty, SNIA 2021 Presentation\n\n30 Jun 2021 - \"SkyhookDM: Towards an Arrow-Native Storage System\", Jayjeet Chakraborty, IRIS-HEP Winter 2021 Fellowship Presentation\n\n9 Mar 2021 - \"Open Source Research Experience -- Summer 2021\", Carlos Maltzahn, Launch of 2021 OSRE Program\n\n30 Nov 2020 - \"Managing Bufferbloat in Storage Systems\", Carlos Maltzahn, Centre for High Performance Computing 2020 National Conference, online, South Africa\n\n2 Aug 2020 - \"The value of open source to universities: UC Santa Cruz tests the water\", Carlos Maltzahn, Interview for a Linux Professional Institute Blog Post by Andy Oram\n\n30 Jun 2020 - \"The Ceph Project\", Carlos Maltzahn, UC Berkeley Cloud Meetup 015\n\n11 Jun 2020 - \"Some lessons learned from creating and using the Ceph open source storage system\", Carlos Maltzahn, BCS Open Source Specialist Group: Open source softgware for scientific and parallel computing\n\n5 Jun 2020 - \"How $2 Million Dollars Helped Build CROSS with Dr. Carlos Maltzahn\", Carlos Maltzahn, Sustain Podcast\n\n26 May 2020 - \"Skyhook Data Management: programmable object storage for databases\", Jeff LeFevre, Fujitsu Labs\n\n15 May 2020 - \"Industry-supported seeding of developer communities around university research prototypes\", Carlos Maltzahn, OpenDP Community Meeting\n\n27 Feb 2020 - \"SkyhookDM: Programmable Storage for Datasets\", Carlos Maltzahn, IRIS-HEP Poster Session\n\n24 Feb 2020 - \"Scaling databases and file apis with programmable ceph object storage\", Carlos Maltzahn, 2020 Linux Storage and Filesystems Conference (Vault’20, co-located with FAST’20 and NSDI’20)\n\n19 Nov 2019 - \"Panel presentation on Enabling Data Services for HPC\", Carlos Maltzahn, Enabling Data Services for HPC (BoF at SC19)\n\n5 Nov 2019 - \"Mapping datasets to object storage\", Jeff LeFevre, CHEP 2019\n\n24 Oct 2019 - \"Education, research, and technology transfer in open source software: new possibilities for universities\", Carlos Maltzahn, École Polytechnique Fédérale de Lausanne (EPFL)\n\n21 Oct 2019 - \"Education, research, and technology transfer in open source software: new possibilities for universities\", Carlos Maltzahn, Friedrich-Alexander Universität, Erlangen-Nürnberg\n\n19 Oct 2019 - \"Center for Research in Open Source Software\", Carlos Maltzahn, Google Summer of Code Mentor Summit\n\n3 Oct 2019 - \"Skyhook Data Management: Scaling Databases and Applications with Open Source Extensible Storage\", Jeff LeFevre, CROSS Research Symposium 2019\n\n15 Aug 2019 - \"Update on the Center for Research in Open Source Software\", Carlos Maltzahn, Seminar at New Mexico Consortium, Los Alamos\n\n20 Jun 2019 - \"MBWU: Benefit Quantification for Data Access Function Offloading\", Carlos Maltzahn, HPC I/O in the Data Center Workshop (HPC-IODC 2019)\n\n24 Apr 2019 - \"Skyhook for query systems\", Jim Pivarski, IRIS-HEP Topical Meetings\n\n24 Apr 2019 - \"Skyhook: Programmable Object Storage for Analysis\", Jeff LeFevre, IRIS-HEP Topical Meetings\n\n13 Mar 2019 - \"How to Leverage Research Universities\", Carlos Maltzahn, Linux Foundation Open Source Leadership Summit (OSLS 2019)\n\n26 Feb 2019 - \"Skyhook: programmable storage for databases\", Jeff LeFevre, Vault'19\n\n26 Feb 2019 - \"Skyhook: programmable storage for databases\", Carlos Maltzahn, Vault'19\n\n25 Jan 2019 - \"Programmable Storage Systems: For I/O that doesn’t fit under the rug\", Carlos Maltzahn, Seminar at Amazon AWS\n\n14 Dec 2018 - \"IN53A-04: Reproducible, Automated and Portable Computational and Data Science Experimentation Pipelines with Popper (with Ivo Jimenez)\", Carlos Maltzahn, IN53A: Enabling Transparency and Reproducibility in Geoscience Through Practical Provenance and Cloud-Based Workflows I (AGU Fall Meeting)\n\n11 Dec 2018 - \"Programmable Storage Systems: For I/O that doesn’t fit under the rug\", Carlos Maltzahn, Seminar at VMware\n\n16 Nov 2017 - \"SkyhookDB - Leveraging object storage toward database elasticity in the cloud\", Jeff LeFevre, DOMA Workshop 2017 (Flatiron Institute)\n\nPublications"
    }
}