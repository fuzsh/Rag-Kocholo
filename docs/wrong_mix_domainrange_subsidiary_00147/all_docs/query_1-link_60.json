{
    "id": "wrong_mix_domainrange_subsidiary_00147_1",
    "rank": 60,
    "data": {
        "url": "https://docs.nvidia.com/ai-enterprise/latest/user-guide/index.html",
        "read_more_link": "",
        "language": "en",
        "title": "User Guide",
        "top_image": "https://docs.nvidia.com/favicon-32x32.png",
        "meta_img": "https://docs.nvidia.com/favicon-32x32.png",
        "images": [
            "https://docscontent.nvidia.com/bf/6f/f2d5da4743aebb3dff0e6a6129ec/nvidia-docshub-logo-2.svg",
            "https://docscontent.nvidia.com/dims4/default/b6af9b2/2147483647/strip/true/crop/624x405+0+0/resize/624x405!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fuser-guide%2Fgraphics%2Fnvaie-stack.jpg 1x,https://docscontent.nvidia.com/dims4/default/823df76/2147483647/strip/true/crop/624x405+0+0/resize/1248x810!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fuser-guide%2Fgraphics%2Fnvaie-stack.jpg 2x",
            "https://docscontent.nvidia.com/dims4/default/8f195fb/2147483647/strip/true/crop/566x300+0+0/resize/566x300!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Farchitecture-grid-vgpu-overview.png 1x,https://docscontent.nvidia.com/dims4/default/37225e0/2147483647/strip/true/crop/566x300+0+0/resize/1132x600!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Farchitecture-grid-vgpu-overview.png 2x",
            "https://docscontent.nvidia.com/dims4/default/241cf6e/2147483647/strip/true/crop/559x447+0+0/resize/559x447!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Farchitecture-grid-vgpu-internal.png 1x,https://docscontent.nvidia.com/dims4/default/0f09828/2147483647/strip/true/crop/559x447+0+0/resize/1118x894!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Farchitecture-grid-vgpu-internal.png 2x",
            "https://docscontent.nvidia.com/dims4/default/8d07753/2147483647/strip/true/crop/559x473+0+0/resize/559x473!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Farchitecture-grid-vgpu-mig-backed-internal.png 1x,https://docscontent.nvidia.com/dims4/default/328f505/2147483647/strip/true/crop/559x473+0+0/resize/1118x946!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Farchitecture-grid-vgpu-mig-backed-internal.png 2x",
            "https://docscontent.nvidia.com/dims4/default/9760f6d/2147483647/strip/true/crop/634x271+0+0/resize/634x271!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fmixed-vgpu-configurations.png 1x,https://docscontent.nvidia.com/dims4/default/b0efba8/2147483647/strip/true/crop/634x271+0+0/resize/1268x542!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fmixed-vgpu-configurations.png 2x",
            "https://docscontent.nvidia.com/dims4/default/708710c/2147483647/strip/true/crop/1288x868+0+0/resize/1288x868!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fnvidia-licensing-dashboard-expanded.png 1x,https://docscontent.nvidia.com/dims4/default/8da326d/2147483647/strip/true/crop/1288x868+0+0/resize/2576x1736!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fnvidia-licensing-dashboard-expanded.png 2x",
            "https://docscontent.nvidia.com/dims4/default/7849ccd/2147483647/strip/true/crop/1500x1138+0+0/resize/1440x1092!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvmware-vcenter-edit-advanced-server-settings-window.png 1x,https://docscontent.nvidia.com/dims4/default/028f1b7/2147483647/strip/true/crop/1500x1138+0+0/resize/2880x2184!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvmware-vcenter-edit-advanced-server-settings-window.png 2x",
            "https://docscontent.nvidia.com/dims4/default/9aebfd9/2147483647/strip/true/crop/1890x1494+0+0/resize/1440x1138!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fconfigure-host-graphics-tab-shared-mode-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/c7023db/2147483647/strip/true/crop/1890x1494+0+0/resize/2880x2276!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fconfigure-host-graphics-tab-shared-mode-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/a2ff697/2147483647/strip/true/crop/958x688+0+0/resize/958x688!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fshared-to-shared-direct-mode-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/35acf72/2147483647/strip/true/crop/958x688+0+0/resize/1916x1376!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fshared-to-shared-direct-mode-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/cd86587/2147483647/strip/true/crop/1443x385+0+0/resize/1440x384!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fgraphics-devices-shared-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/045dc49/2147483647/strip/true/crop/1443x385+0+0/resize/2880x768!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fgraphics-devices-shared-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/2710985/2147483647/strip/true/crop/1258x556+0+0/resize/1258x556!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fshared-to-shared-direct-mode-pgpu-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/d67f099/2147483647/strip/true/crop/1258x556+0+0/resize/2516x1112!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fshared-to-shared-direct-mode-pgpu-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/5852bb2/2147483647/strip/true/crop/1443x385+0+0/resize/1440x384!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fgraphics-devices-shared-direct-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/263f4b9/2147483647/strip/true/crop/1443x385+0+0/resize/2880x768!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fgraphics-devices-shared-direct-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/a3c94e5/2147483647/strip/true/crop/856x745+0+0/resize/856x745!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fedit-settings-vmware-8.png 1x,https://docscontent.nvidia.com/dims4/default/6102855/2147483647/strip/true/crop/856x745+0+0/resize/1712x1490!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fedit-settings-vmware-8.png 2x",
            "https://docscontent.nvidia.com/dims4/default/5bcc2b9/2147483647/strip/true/crop/857x695+0+0/resize/857x695!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvgpu-device-selection-vmware-8.png 1x,https://docscontent.nvidia.com/dims4/default/113b5ff/2147483647/strip/true/crop/857x695+0+0/resize/1714x1390!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvgpu-device-selection-vmware-8.png 2x",
            "https://docscontent.nvidia.com/dims4/default/05446e7/2147483647/strip/true/crop/752x776+0+0/resize/752x776!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvgpu-settings-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/ee9cd22/2147483647/strip/true/crop/752x776+0+0/resize/1504x1552!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvgpu-settings-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/9730247/2147483647/strip/true/crop/471x420+0+0/resize/471x420!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Finstall-nvidia-windows-guest-driver.png 1x,https://docscontent.nvidia.com/dims4/default/e91f0ee/2147483647/strip/true/crop/471x420+0+0/resize/942x840!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Finstall-nvidia-windows-guest-driver.png 2x",
            "https://docscontent.nvidia.com/dims4/default/8dc526d/2147483647/strip/true/crop/1039x594+0+0/resize/1039x594!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fverify-nvidia-driver-nvcp.png 1x,https://docscontent.nvidia.com/dims4/default/4fc0c7c/2147483647/strip/true/crop/1039x594+0+0/resize/2078x1188!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fverify-nvidia-driver-nvcp.png 2x",
            "https://docscontent.nvidia.com/dims4/default/353aab8/2147483647/strip/true/crop/942x591+0+0/resize/942x591!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fnvidia-license-system-user-guide%2Fselect-generated-credentials-file-windows-pop-up.png 1x,https://docscontent.nvidia.com/dims4/default/526e025/2147483647/strip/true/crop/942x591+0+0/resize/1884x1182!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fnvidia-license-system-user-guide%2Fselect-generated-credentials-file-windows-pop-up.png 2x",
            "https://docscontent.nvidia.com/dims4/default/9a177fd/2147483647/strip/true/crop/522x369+0+0/resize/522x369!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fdocker-container-architecture.png 1x,https://docscontent.nvidia.com/dims4/default/abbfeb2/2147483647/strip/true/crop/522x369+0+0/resize/1044x738!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fdocker-container-architecture.png 2x",
            "https://docscontent.nvidia.com/dims4/default/009ae77/2147483647/strip/true/crop/401x367+0+0/resize/401x367!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fnv-enterprise-catalog-ngc-private-registry%2Faccess-nvaie-user-menu.png 1x,https://docscontent.nvidia.com/dims4/default/96fbcf0/2147483647/strip/true/crop/401x367+0+0/resize/802x734!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fnv-enterprise-catalog-ngc-private-registry%2Faccess-nvaie-user-menu.png 2x",
            "https://docscontent.nvidia.com/dims4/default/3ad080d/2147483647/strip/true/crop/948x632+0+0/resize/948x632!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fnv-enterprise-catalog-ngc-private-registry%2Faccess-nvaie-private-registry.png 1x,https://docscontent.nvidia.com/dims4/default/0860b1f/2147483647/strip/true/crop/948x632+0+0/resize/1896x1264!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fnv-enterprise-catalog-ngc-private-registry%2Faccess-nvaie-private-registry.png 2x",
            "https://docscontent.nvidia.com/dims4/default/b35b678/2147483647/strip/true/crop/247x287+0+0/resize/247x287!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fmultinode-scaling%2Fdual-socket-server.png 1x,https://docscontent.nvidia.com/dims4/default/0e729ca/2147483647/strip/true/crop/247x287+0+0/resize/494x574!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fmultinode-scaling%2Fdual-socket-server.png 2x",
            "https://docscontent.nvidia.com/dims4/default/d06e9e0/2147483647/strip/true/crop/272x348+0+0/resize/272x348!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fmultinode-scaling%2Fwhole-server-vm.png 1x,https://docscontent.nvidia.com/dims4/default/e5d5586/2147483647/strip/true/crop/272x348+0+0/resize/544x696!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fmultinode-scaling%2Fwhole-server-vm.png 2x",
            "https://docscontent.nvidia.com/dims4/default/147ad9e/2147483647/strip/true/crop/536x129+0+0/resize/536x129!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fmultinode-scaling%2Fvcpus-per-socket.png 1x,https://docscontent.nvidia.com/dims4/default/46909be/2147483647/strip/true/crop/536x129+0+0/resize/1072x258!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fmultinode-scaling%2Fvcpus-per-socket.png 2x",
            "https://docscontent.nvidia.com/dims4/default/cb0f114/2147483647/strip/true/crop/271x348+0+0/resize/271x348!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fmultinode-scaling%2Fvm-per-socket.png 1x,https://docscontent.nvidia.com/dims4/default/71dee76/2147483647/strip/true/crop/271x348+0+0/resize/542x696!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fcommon%2Fgraphics%2Fmultinode-scaling%2Fvm-per-socket.png 2x",
            "https://docscontent.nvidia.com/dims4/default/9aebfd9/2147483647/strip/true/crop/1890x1494+0+0/resize/1440x1138!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fconfigure-host-graphics-tab-shared-mode-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/c7023db/2147483647/strip/true/crop/1890x1494+0+0/resize/2880x2276!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fconfigure-host-graphics-tab-shared-mode-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/f98de58/2147483647/strip/true/crop/958x688+0+0/resize/958x688!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fshared-to-shared-direct-mode-depth-first-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/4bc9b2b/2147483647/strip/true/crop/958x688+0+0/resize/1916x1376!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fshared-to-shared-direct-mode-depth-first-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/d3ffb13/2147483647/strip/true/crop/1892x1496+0+0/resize/1440x1139!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fconfigure-host-graphics-tab-shared-direct-mode-depth-first-vmware-vsphere.png 1x,https://docscontent.nvidia.com/dims4/default/e43bc7d/2147483647/strip/true/crop/1892x1496+0+0/resize/2880x2278!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fconfigure-host-graphics-tab-shared-direct-mode-depth-first-vmware-vsphere.png 2x",
            "https://docscontent.nvidia.com/dims4/default/3e50fbc/2147483647/strip/true/crop/1030x260+0+0/resize/1030x260!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvgpu-hot-migration-not-enabled.jpg 1x,https://docscontent.nvidia.com/dims4/default/b80e967/2147483647/strip/true/crop/1030x260+0+0/resize/2060x520!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvgpu-hot-migration-not-enabled.jpg 2x",
            "https://docscontent.nvidia.com/dims4/default/b5b1b83/2147483647/strip/true/crop/493x245+0+0/resize/493x245!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvgpu-migration-compatibility-issues.png 1x,https://docscontent.nvidia.com/dims4/default/9d27b94/2147483647/strip/true/crop/493x245+0+0/resize/986x490!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fvgpu-migration-compatibility-issues.png 2x",
            "https://docscontent.nvidia.com/dims4/default/4322874/2147483647/strip/true/crop/1106x108+0+0/resize/1106x108!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-94-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/f7648a5/2147483647/strip/true/crop/1106x108+0+0/resize/2212x216!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-94-gb-gpus.png 2x",
            "https://docscontent.nvidia.com/dims4/default/93a1e23/2147483647/strip/true/crop/1106x146+0+0/resize/1106x146!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-80-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/182d18f/2147483647/strip/true/crop/1106x146+0+0/resize/2212x292!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-80-gb-gpus.png 2x",
            "https://docscontent.nvidia.com/dims4/default/13a513f/2147483647/strip/true/crop/1106x94+0+0/resize/1106x94!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-64-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/98dac7a/2147483647/strip/true/crop/1106x94+0+0/resize/2212x188!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-64-gb-gpus.png 2x",
            "https://docscontent.nvidia.com/dims4/default/fa2b99a/2147483647/strip/true/crop/1106x182+0+0/resize/1106x182!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-48-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/422cfe5/2147483647/strip/true/crop/1106x182+0+0/resize/2212x364!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-48-gb-gpus.png 2x",
            "https://docscontent.nvidia.com/dims4/default/95c5207/2147483647/strip/true/crop/1106x182+0+0/resize/1106x182!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-48-gb-gpus-ada.png 1x,https://docscontent.nvidia.com/dims4/default/2afb039/2147483647/strip/true/crop/1106x182+0+0/resize/2212x364!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-48-gb-gpus-ada.png 2x",
            "https://docscontent.nvidia.com/dims4/default/54a6105/2147483647/strip/true/crop/1106x118+0+0/resize/1106x118!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-40-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/1fd7e3d/2147483647/strip/true/crop/1106x118+0+0/resize/2212x236!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-40-gb-gpus.png 2x",
            "https://docscontent.nvidia.com/dims4/default/4db7605/2147483647/strip/true/crop/1106x123+0+0/resize/1106x123!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-32-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/f89fea2/2147483647/strip/true/crop/1106x123+0+0/resize/2212x246!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-32-gb-gpus.png 2x",
            "https://docscontent.nvidia.com/dims4/default/3d22a1c/2147483647/strip/true/crop/738x182+0+0/resize/738x182!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-24-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/d23b204/2147483647/strip/true/crop/738x182+0+0/resize/1476x364!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-24-gb-gpus.png 2x",
            "https://docscontent.nvidia.com/dims4/default/d92da53/2147483647/strip/true/crop/802x141+0+0/resize/802x141!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-20-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/875e2f0/2147483647/strip/true/crop/802x141+0+0/resize/1604x282!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-20-gb-gpus.png 2x",
            "https://docscontent.nvidia.com/dims4/default/333a9cd/2147483647/strip/true/crop/642x122+0+0/resize/642x122!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-16-gb-gpus.png 1x,https://docscontent.nvidia.com/dims4/default/d5285d8/2147483647/strip/true/crop/642x122+0+0/resize/1284x244!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000190-a28d-d6e5-a5ba-bb9fa2d80000%2Fai-enterprise%2Flatest%2Fimports%2Fgraphics%2Fvgpu-software%2Fplacement-map-for-16-gb-gpus.png 2x"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Documentation for administrators that explains how to install and configure NVIDIA AI Enterprise.",
        "meta_lang": "en",
        "meta_favicon": "/apple-touch-icon.png",
        "meta_site_name": "NVIDIA Docs",
        "canonical_link": "https://docs.nvidia.com/ai-enterprise/latest/user-guide/index.html",
        "text": "NVIDIA AI Enterprise User Guide\n\nDocumentation for administrators that explains how to install and configure NVIDIA AI Enterprise.\n\nNVIDIA® AI Enterprise is an end-to-end, cloud-native suite of AI and data analytics software, optimized so every organization can succeed with AI. It's certified to deploy anywhere—from the enterprise data center to the public cloud—and includes global enterprise support and training.\n\nNVIDIA AI Enterprise includes key enabling technologies and software from NVIDIA for rapid deployment, management, and scaling of AI workloads in the modern hybrid cloud.\n\nNVIDIA AI Enterprise enables the following:\n\nLeverage fully integrated, optimized, certified, and supported software from NVIDIA for AI workloads.\n\nRun NVIDIA AI frameworks and tools optimized for GPU acceleration, reducing deployment time and ensuring reliable performance.\n\nDeploy anywhere – including on popular data center platforms from VMware and Red Hat, mainstream NVIDIA-Certified Systems configured with or without GPUs, and on GPU-accelerated instances in the public cloud.\n\nLeverage the jointly certified NVIDIA and Red Hat solution to deploy and manage AI workloads in containers or VMs with optimized software.\n\nScale out to multiple nodes, enabling even the largest deep learning training models to run on the VMware vSphere. Previously, scaling with bare metal performance in a fully virtualized environment was limited to a single node, limiting the complexity and size of AI workloads that could be supported.\n\nRun AI workloads at near bare-metal performance with new optimizations for GPU acceleration on vSphere, including support for the latest Ampere architecture including the NVIDIA A100. Additionally, technologies like GPUDirect Communications can now be supported on vSphere. This provides communication between GPU memory and storage across a cluster for improved performance.\n\n1.1. NVIDIA AI Enterprise Software Architecture\n\nThe software in the NVIDIA AI Enterprise suite is organized into separate layers for infrastructure optimization software, cloud native deployment software, and AI and data science frameworks.\n\nThe content of these layers is as follows:\n\nInfrastructure optimization software:\n\nNVIDIA virtual GPU (vGPU) software\n\nNVIDIA CUDA Toolkit\n\nNVIDIA Magnum IO™ software stack for accelerated data centers\n\nCloud native deployment software:\n\nNVIDIA GPU Operator\n\nNVIDIA Network Operator\n\nAI and data science frameworks:\n\nTensorFlow\n\nPyTorch\n\nNVIDIA Triton Inference Server\n\nNVIDIA TensorRT\n\nRAPIDS\n\nThe AI and data science frameworks are delivered as container images. Containerized software can be run directly with a tool such as Docker.\n\nWhat Is Included?\n\nThe NVIDIA AI Enterprise suite includes frameworks that are broadly applicable and used across vertical industries such as manufacturing, logistics, financial services, retail, and healthcare.\n\nNVIDIA AI Enterprise includes:\n\nTensorFlow and PyTorch for maching learning.\n\nNVIDIA TAO Toolkit for a faster, easier way to accelerate training and quickly create highly accurate and performant, domain-specific vision, and conversational AI models.\n\nNVIDIA Tensor RT, for GPU optimized deep learning inference and Triton Inference Server to deploy trained AI models at scale.\n\nTriton Inference Server supports all major frameworks, such as TensorFlow, TensorRT, PyTorch, MXNet, Python and more. Triton Inference Server also includes the RAPIDS FIL backend for the best inference performance for tree-based models on GPUs.\n\nNVIDIA RAPIDS, for end-to-end data science, machine learning and analytics pipeline.\n\nNVIDIA GPU and Network Operators, to deploy and manage NVIDIA GPU and Networking resources in Kubernetes.\n\nNVIDIA vGPU Software, to deploy vGPU on common data center platforms, including VMware and Red Hat.\n\n1.2. Prerequisites for Using NVIDIA AI Enterprise\n\nBefore proceeding, ensure that these prerequisites are met:\n\nYou have a system that meets the requirements in NVIDIA AI Enterprise Release Notes.\n\nOne or more supported NVIDIA GPUs are installed in your system.\n\nIf you are using an NVIDIA A100 GPU, the following BIOS settings are enabled on your system:\n\nSingle Root I/O Virtualization (SR-IOV)\n\nVT-d/IOMMU - Enabled\n\nThe following software is installed according to the instructions in the VMware documentation:\n\nVMware vSphere Hypervisor ESXi\n\nVMware vCenter Server\n\nA VM to be enabled with NVIDIA vGPU is created with the virtual hardware resources in the following table.\n\nResource Requirements vCPUs 16 RAM 64 GB Storage 500 GB thin provisioned virtual disk NIC VMXNet3 NIC connected to network\n\nA supported guest OS is installed in the VM.\n\nFor optimum performance, set options in your server configuration as follows:\n\nEnable the following options:\n\nHyperthreading\n\nMemory Mapped I/O above 4 GB (if applicable)\n\nSet the Power Setting or System Profile option to High Performance.\n\nIf applicable, set CPU Performance to Enterprise or High Throughput.\n\nNote:\n\nIf NVIDIA card detection does not include all the installed GPUs, set this option to Enabled.\n\nThe process for installing and configuring NVIDIA Virtual GPU Manager depends on the hypervisor that you are using. After you complete this process, you can install the display drivers for your guest OS and license any NVIDIA AI Enterprise licensed products that you are using.\n\n2.1. About NVIDIA Virtual GPUs\n\n2.1.1. NVIDIA vGPU Architecture\n\nThe high-level architecture of NVIDIA vGPU is illustrated in Figure 1. Under the control of the NVIDIA Virtual GPU Manager running under the hypervisor, NVIDIA physical GPUs are capable of supporting multiple virtual GPU devices (vGPUs) that can be assigned directly to guest VMs.\n\nGuest VMs use NVIDIA vGPUs in the same manner as a physical GPU that has been passed through by the hypervisor: an NVIDIA driver loaded in the guest VM provides direct access to the GPU for performance-critical fast paths, and a paravirtualized interface to the NVIDIA Virtual GPU Manager is used for non-performant management operations.\n\nFigure 1. NVIDIA vGPU System Architecture\n\nEach NVIDIA vGPU is analogous to a conventional GPU, having a fixed amount of GPU framebuffer, and one or more virtual display outputs or \"heads\". The vGPU’s framebuffer is allocated out of the physical GPU’s framebuffer at the time the vGPU is created, and the vGPU retains exclusive use of that framebuffer until it is destroyed. Depending on the physical GPU and the GPU virtualization software, NVIDIA Virtual GPU Manager supports different types of vGPU on a physical GPU:\n\nOn all GPUs that support NVIDIA AI Enterprise, time-sliced vGPUs can be created.\n\nAdditionally, on GPUs that support the Multi-Instance GPU (MIG) feature and NVIDIA AI Enterprise, MIG-backed vGPUs are supported. The MIG feature is introduced on GPUs that are based on the NVIDIA Ampere GPU architecture.\n\nNote:\n\nAlthough earlier releases of NVIDIA AI Enterprise supported GPUs that support the MIG feature, such GPUs are not supported on this release of NVIDIA AI Enterprise. GPUs that support the MIG feature are supported only on NVIDIA AI Enterprise.\n\n2.1.1.1. Time-Sliced NVIDIA vGPU Internal Architecture\n\nA time-sliced vGPU is a vGPU that resides on a physical GPU that is not partitioned into multiple GPU instances. All time-sliced vGPUs resident on a GPU share access to the GPU’s engines including the graphics (3D), video decode, and video encode engines.\n\nIn a time-sliced vGPU, processes that run on the vGPU are scheduled to run in series. Each vGPU waits while other processes run on other vGPUs. While processes are running on a vGPU, the vGPU has exclusive use of the GPU's engines. You can change the default scheduling behavior as explained in Changing Scheduling Behavior for Time-Sliced vGPUs.\n\nFigure 2. Time-Sliced NVIDIA vGPU Internal Architecture\n\n2.1.1.2. MIG-Backed NVIDIA vGPU Internal Architecture\n\nA MIG-backed vGPU is a vGPU that resides on a GPU instance in a MIG-capable physical GPU. Each MIG-backed vGPU resident on a GPU has exclusive access to the GPU instance’s engines, including the compute and video decode engines.\n\nIn a MIG-backed vGPU, processes that run on the vGPU run in parallel with processes running on other vGPUs on the GPU. Process run on all vGPUs resident on a physical GPU simultaneously.\n\nFigure 3. MIG-Backed NVIDIA vGPU Internal Architecture\n\n2.1.2. About Virtual GPU Types\n\nThe number of physical GPUs that a board has depends on the board. Each physical GPU can support several different types of virtual GPU (vGPU). vGPU types have a fixed amount of frame buffer, number of supported display heads, and maximum resolutions . They are grouped into different series according to the different classes of workload for which they are optimized. Each series is identified by the last letter of the vGPU type name.\n\nSeries Optimal Workload C-series Compute-intensive server workloads, such as artificial intelligence (AI), deep learning, or high-performance computing (HPC)1, 2\n\nThe number after the board type in the vGPU type name denotes the amount of frame buffer that is allocated to a vGPU of that type. For example, a vGPU of type A16-4C is allocated 4096 Mbytes of frame buffer on an NVIDIA A16 board.\n\nDue to their differing resource requirements, the maximum number of vGPUs that can be created simultaneously on a physical GPU varies according to the vGPU type. For example, an NVDIA A16 board can support up to 4 A16-4C vGPUs on each of its two physical GPUs, for a total of 16 vGPUs, but only 2 A16-8C vGPUs, for a total of 8 vGPUs.\n\nWhen enabled, the frame-rate limiter (FRL) limits the maximum frame rate in frames per second (FPS) for C-series vGPUs to 60 FPS.\n\nBy default, the FRL is enabled for all GPUs. The FRL is disabled when the vGPU scheduling behavior is changed from the default best-effort scheduler on GPUs that support alternative vGPU schedulers. For details, see Changing Scheduling Behavior for Time-Sliced vGPUs. On vGPUs that use the best-effort scheduler, the FRL can be disabled as explained in the release notes for your chosen hypervisor at NVIDIA AI Enterprise Documentation.\n\nNote:\n\nNVIDIA vGPU is a licensed product on all supported GPU boards. An NVIDIA AI Enterprise software license is required to enable all vGPU features within the guest VM.\n\nFor details of the virtual GPU types available from each supported GPU, see Virtual GPU Types for Supported GPUs.\n\n2.1.3. Valid Virtual GPU Configurations on a Single GPU\n\nValid vGPU configurations on a single GPU depend on whether the vGPUs are time sliced or, on GPUs that support MIG, are MIG-backed.\n\n2.1.3.1. Valid Time-Sliced Virtual GPU Configurations on a Single GPU\n\nNVIDIA AI Enterprise supports a mixture of different types of time-sliced vGPUs on the same physical GPU. Any combination of A-series, B-series, and Q-series vGPUs with any amount of frame buffer can reside on the same physical GPU simultaneously. The total amount of frame buffer allocated to the vGPUs on a physical GPU must not exceed the amount of frame buffer that the physical GPU has.\n\nFor example, the following combinations of vGPUs can reside on the same physical GPU simultaneously:\n\nA40-2B and A40-2Q\n\nA40-2Q and A40-4Q\n\nA40-2B and A40-4Q\n\nBy default, a GPU supports only vGPUs with the same amount of frame buffer and, therefore, is in equal-size mode. To support vGPUs with different amounts of frame buffer, the GPU must be put into mixed-size mode. When a GPU is in mixed-size mode, the maximum number of some types of vGPU allowed on a GPU is less than when the GPU is in equal-size mode. For more information, refer to the following topics:\n\nPutting a GPU Into Mixed-Size Mode\n\nVirtual GPU Types for Supported GPUs\n\nNot all hypervisors and GPUs support a mixture of different types of time-sliced vGPUs on the same physical GPU. To determine if your chosen hypervisor supports this feature with your chosen GPU, consult the release notes for your hypervisor at NVIDIA AI Enterprise Documentation.\n\n2.1.3.2. Valid MIG-Backed Virtual GPU Configurations on a Single GPU\n\nThis release of NVIDIA vGPU supports both homogeneous and mixed MIG-backed virtual GPUs based on the underlying GPU instance configuration.\n\nFor example, an NVIDIA A100 PCIe 40GB card has one physical GPU, and can support several types of virtual GPU. Figure 4 shows the following examples of valid homogeneous and mixed MIG-backed virtual GPU configurations on NVIDIA A100 PCIe 40GB.\n\nA valid homogeneous configuration with 3 A100-2-10C vGPUs on 3 MIG.2g.10b GPU instances\n\nA valid homogeneous configuration with 2 A100-3-20C vGPUs on 3 MIG.3g.20b GPU instances\n\nA valid mixed configuration with 1 A100-4-20C vGPU on a MIG.4g.20b GPU instance, 1 A100-2-10C vGPU on a MIG.2.10b GPU instance, and 1 A100-1-5C vGPU on a MIG.1g.5b instance\n\nFigure 4. Example MIG-Backed vGPU Configurations on NVIDIA A100 PCIe 40GB\n\n2.2. Switching the Mode of a GPU that Supports Multiple Display Modes\n\nSome GPUs support display-off and display-enabled modes but must be used in NVIDIA AI Enterprise deployments in display-off mode.\n\nThe GPUs listed in the following table support multiple display modes. As shown in the table, some GPUs are supplied from the factory in display-off mode, but other GPUs are supplied in a display-enabled mode.\n\nGPU Mode as Supplied from the Factory NVIDIA A40 Display-off NVIDIA L40 Display-off NVIDIA L40S Display-off NVIDIA L20 Display-off NVIDIA L20 liquid cooled Display-off NVIDIA RTX 5000 Ada Display enabled NVIDIA RTX 6000 Ada Display enabled NVIDIA RTX A5000 Display enabled NVIDIA RTX A5500 Display enabled NVIDIA RTX A6000 Display enabled\n\nA GPU that is supplied from the factory in display-off mode, such as the NVIDIA A40 GPU, might be in a display-enabled mode if its mode has previously been changed.\n\nTo change the mode of a GPU that supports multiple display modes, use the displaymodeselector tool, which you can request from the NVIDIA Display Mode Selector Tool page on the NVIDIA Developer website.\n\nNote:\n\nOnly the GPUs listed in the table support the displaymodeselector tool. Other GPUs that support NVIDIA AI Enterprise do not support the displaymodeselector tool and, unless otherwise stated, do not require display mode switching.\n\n2.3. Downloading NVIDIA AI Enterprise\n\nBefore you begin, ensure that you have your order confirmation message and have created an NVIDIA Enterprise Account.\n\nVisit the NVIDIA Application Hub by following the Login link in the instructions for using your NVIDIA Entitlement Certificate or when prompted after setting the password for your NVIDIA Enterprise Account.\n\nWhen prompted, provide your e-mail address and password, and click LOGIN.\n\nOn the NVIDIA APPLICATION HUB page that opens, click NVIDIA LICENSING PORTAL.\n\nThe NVIDIA Licensing Portal dashboard page opens.\n\nNote:\n\nYour entitlement might not appear on the NVIDIA Licensing Portal dashboard page until 24 business hours after you set your password during the initial registration process.\n\nIn the left navigation pane of the NVIDIA Licensing Portal dashboard page, click ENTITLEMENTS to view details of the NVIDIA AI Enterprise entitlements that you purchased.\n\nIn the left navigation pane of the NVIDIA Licensing Portal dashboard page, click SOFTWARE DOWNLOADS.\n\nOn the Software Downloads page that opens, download the NVIDIA AI Enterprise drivers that you require.\n\nEnsure that the Driver downloads tab is selected.\n\nSet the PRODUCT FAMILY option to NVAIE.\n\nFollow the Download link for the brand and version of your chosen hypervisor for the release of NVIDIA AI Enterprise that you are using. For example: NVIDIA AI Enterprise for vSphere 7.0.3 for NVIDIA AI Enterprise release 17.3. If the brand and version of your chosen hypervisor for the release of NVIDIA AI Enterprise that you are using aren't displayed, click ALL AVAILABLE to display a list of all available NVIDIA AI Enterprise downloads. Set filters on columns in the table to filter the software listed.\n\nWhen prompted to accept the license for the software that you are downloading, click AGREE & DOWNLOAD.\n\nIf necessary, download the standalone NVIDIA Control Panel installer.\n\nEnsure that the Driver downloads tab is selected.\n\nSet the filter on the DESCRIPTION column to control.\n\nFollow the Download link for the standalone NVIDIA Control Panel installer.\n\nWhen prompted to accept the license for the software that you are downloading, click AGREE & DOWNLOAD.\n\nDownload any additional, non-driver software that you need for your NVIDIA AI Enterprise deployment.\n\nClick the Non-Driver downloads tab.\n\nOptional: Use the CATEGORY filter to list only the category of software that you are interested in, for example, DLS.\n\nFollow the Download link for the software that you want to download.\n\nIf you are using Delegated License Service (DLS) instances to serve licenses, follow the link to the DLS release for your chosen platform, for example, NLS License Server (DLS) 3.2 for VMware vSphere.\n\nFor information about installing and configuring DLS instances, refer to NVIDIA License System User Guide.\n\nIf you are using NVIDIA GPU Operator, follow the vGPU Driver Catalog link.\n\nWhen prompted to accept the license for the software that you are downloading, click AGREE & DOWNLOAD.\n\n2.4. Installing the Virtual GPU Manager Package for Linux KVM\n\nBefore installing the Virtual GPU Manager package for Linux KVM, ensure that the following prerequisites are met:\n\nThe following packages are installed on the Linux KVM server:\n\nThe x86_64 build of the GNU Compiler Collection (GCC)\n\nLinux kernel headers\n\nThe package file is copied to a directory in the file system of the Linux KVM server.\n\nIf the Nouveau driver for NVIDIA graphics cards is present, disable it before installing the package.\n\nChange to the directory on the Linux KVM server that contains the package file.\n\nCopy\n\nCopied!\n\n# cd package-file-directory\n\npackage-file-directory\n\nThe path to the directory that contains the package file.\n\nMake the package file executable.\n\nCopy\n\nCopied!\n\n# chmod +x package-file-name\n\npackage-file-name\n\nThe name of the file that contains the Virtual GPU Manager package for Linux KVM, for example NVIDIA-Linux-x86_64-390.42-vgpu-kvm.run.\n\nRun the package file as the root user.\n\nCopy\n\nCopied!\n\n# sudo sh./package-file-name\n\nThe package file should launch and display the license agreement.\n\nAccept the license agreement to continue with the installation.\n\nWhen installation has completed, select OK to exit the installer.\n\nReboot the Linux KVM server.\n\nCopy\n\nCopied!\n\n# systemctl reboot\n\n2.5. Installing and Configuring the NVIDIA Virtual GPU Manager for Red Hat Enterprise Linux KVM\n\nThe following topics step you through the process of setting up a single Red Hat Enterprise Linux Kernel-based Virtual Machine (KVM) VM to use NVIDIA vGPU.\n\nCAUTION:\n\nOutput from the VM console is not available for VMs that are running vGPU. Make sure that you have installed an alternate means of accessing the VM (such as a VNC server) before you configure vGPU.\n\nFollow this sequence of instructions:\n\nInstalling the Virtual GPU Manager Package for Red Hat Enterprise Linux KVM\n\nVerifying the Installation of the NVIDIA AI Enterprise for Red Hat Enterprise Linux KVM\n\nMIG-backed vGPUs only: Configuring a GPU for MIG-Backed vGPUs\n\nvGPUs that support SR-IOV only: Preparing the Virtual Function for an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor\n\nOptional: Putting a GPU Into Mixed-Size Mode\n\nGetting the BDF and Domain of a GPU on a Linux with KVM Hypervisor\n\nCreating an NVIDIA vGPU on a Linux with KVM Hypervisor\n\nAdding One or More vGPUs to a Linux with KVM Hypervisor VM\n\nOptional: Placing a vGPU on a Physical GPU in Mixed-Size Mode\n\nSetting vGPU Plugin Parameters on a Linux with KVM Hypervisor\n\nAfter the process is complete, you can install the graphics driver for your guest OS and license any NVIDIA AI Enterprise licensed products that you are using.\n\n2.5.1. Installing the Virtual GPU Manager Package for Red Hat Enterprise Linux KVM\n\nThe NVIDIA Virtual GPU Manager for Red Hat Enterprise Linux KVM is provided as a .rpm file.\n\nCAUTION:\n\nNVIDIA Virtual GPU Manager and guest VM drivers must be compatible. If you update vGPU Manager to a release that is incompatible with the guest VM drivers, guest VMs will boot with vGPU disabled until their guest vGPU driver is updated to a compatible version.\n\nBefore installing the RPM package for Red Hat Enterprise Linux KVM, ensure that the sshd service on the Red Hat Enterprise Linux KVM server is configured to permit root login. If the Nouveau driver for NVIDIA graphics cards is present, disable it before installing the package. For instructions, see How to disable the Nouveau driver and install the Nvidia driver in RHEL 7 (Red Hat subscription required).\n\nSome versions of Red Hat Enterprise Linux KVM have z-stream updates that break Kernel Application Binary Interface (kABI) compatibility with the previous kernel or the GA kernel. For these versions of Red Hat Enterprise Linux KVM, the following Virtual GPU Manager RPM packages are supplied:\n\nA package for the GA Linux KVM kernel\n\nA package for the updated z-stream kernel\n\nTo differentiate these packages, the name of each RPM package includes the kernel version. Ensure that you install the RPM package that is compatible with your Linux KVM kernel version.\n\nSecurely copy the RPM file from the system where you downloaded the file to the Red Hat Enterprise Linux KVM server.\n\nFrom a Windows system, use a secure copy client such as WinSCP.\n\nFrom a Linux system, use the scp command.\n\nUse secure shell (SSH) to log in as root to the Red Hat Enterprise Linux KVM server.\n\nCopy\n\nCopied!\n\n# ssh root@kvm-server\n\nkvm-server\n\nThe host name or IP address of the Red Hat Enterprise Linux KVM server.\n\nChange to the directory on the Red Hat Enterprise Linux KVM server to which you copied the RPM file.\n\nCopy\n\nCopied!\n\n# cd rpm-file-directory\n\nrpm-file-directory\n\nThe path to the directory to which you copied the RPM file.\n\nUse the rpm command to install the package.\n\nCopy\n\nCopied!\n\n# rpm -iv NVIDIA-vGPU-rhel-8.9-550.90.05.x86_64.rpm Preparing packages for installation... NVIDIA-vGPU-rhel-8.9-550.90.05 #\n\nReboot the Red Hat Enterprise Linux KVM server.\n\nCopy\n\nCopied!\n\n# systemctl reboot\n\nAfter the Red Hat Enterprise Linux KVM server has rebooted, verify the installation of the NVIDIA AI Enterprise package for Red Hat Enterprise Linux KVM.\n\nVerify that the NVIDIA AI Enterprise package is installed and loaded correctly by checking for the VFIO drivers in the list of kernel loaded modules.\n\nVerify that the libvirtd service is active and running.\n\nCopy\n\nCopied!\n\n# service libvirtd status\n\nVerify that the NVIDIA kernel driver can successfully communicate with the NVIDIA physical GPUs in your system by running the nvidia-smi command. The nvidia-smi command is described in more detail in NVIDIA System Management Interface nvidia-smi.\n\nRunning the nvidia-smi command should produce a listing of the GPUs in your platform.\n\nIf nvidia-smi fails to run or doesn’t produce the expected output for all the NVIDIA GPUs in your system, see Troubleshooting for troubleshooting steps.\n\n2.6. Installing and Configuring the NVIDIA Virtual GPU Manager for Ubuntu\n\nFollow this sequence of instructions to set up a single Ubuntu VM to use NVIDIA vGPU.\n\nInstalling the NVIDIA Virtual GPU Manager for Ubuntu\n\nMIG-backed vGPUs only: Configuring a GPU for MIG-Backed vGPUs\n\nGetting the BDF and Domain of a GPU on a Linux with KVM Hypervisor\n\nvGPUs that support SR-IOV only: Preparing the Virtual Function for an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor\n\nOptional: Putting a GPU Into Mixed-Size Mode\n\nCreating an NVIDIA vGPU on a Linux with KVM Hypervisor\n\nAdding One or More vGPUs to a Linux with KVM Hypervisor VM\n\nOptional: Placing a vGPU on a Physical GPU in Mixed-Size Mode\n\nSetting vGPU Plugin Parameters on a Linux with KVM Hypervisor\n\nCAUTION:\n\nOutput from the VM console is not available for VMs that are running vGPU. Make sure that you have installed an alternate means of accessing the VM (such as a VNC server) before you configure vGPU.\n\nAfter the process is complete, you can install the graphics driver for your guest OS and license any NVIDIA AI Enterprise licensed products that you are using.\n\nThe NVIDIA Virtual GPU Manager for Ubuntu is provided as a Debian package (.deb) file.\n\nCAUTION:\n\nNVIDIA Virtual GPU Manager and guest VM drivers must be compatible. If you update vGPU Manager to a release that is incompatible with the guest VM drivers, guest VMs will boot with vGPU disabled until their guest vGPU driver is updated to a compatible version. Consult for further details.\n\n2.6.1.1. Installing the Virtual GPU Manager Package for Ubuntu\n\nBefore installing the Debian package for Ubuntu, ensure that the sshd service on the Ubuntu server is configured to permit root login. If the Nouveau driver for NVIDIA graphics cards is present, disable it before installing the package.\n\nSecurely copy the Debian package file from the system where you downloaded the file to the Ubuntu server.\n\nFrom a Windows system, use a secure copy client such as WinSCP.\n\nFrom a Linux system, use the scp command.\n\nUse secure shell (SSH) to log in as root to the Ubuntu server.\n\nCopy\n\nCopied!\n\n# ssh root@ubuntu-server\n\nubuntu-server\n\nThe host name or IP address of the Ubuntu server.\n\nChange to the directory on the Ubuntu server to which you copied the Debian package file.\n\nCopy\n\nCopied!\n\n# cd deb-file-directory\n\ndeb-file-directory\n\nThe path to the directory to which you copied the Debian package file.\n\nUse the apt command to install the package.\n\nCopy\n\nCopied!\n\n# apt install ./.deb\n\nReboot the Ubuntu server.\n\nCopy\n\nCopied!\n\n# systemctl reboot\n\nAfter the Ubuntu server has rebooted, verify the installation of the NVIDIA AI Enterprise package for Ubuntu.\n\nVerify that the NVIDIA AI Enterprise package is installed and loaded correctly by checking for the VFIO drivers in the list of kernel loaded modules.\n\nVerify that the libvirtd service is active and running.\n\nCopy\n\nCopied!\n\n# service libvirtd status\n\nVerify that the NVIDIA kernel driver can successfully communicate with the NVIDIA physical GPUs in your system by running the nvidia-smi command. The nvidia-smi command is described in more detail in NVIDIA System Management Interface nvidia-smi.\n\nRunning the nvidia-smi command should produce a listing of the GPUs in your platform.\n\nIf nvidia-smi fails to run or doesn’t produce the expected output for all the NVIDIA GPUs in your system, see Troubleshooting for troubleshooting steps.\n\n2.7. Installing and Configuring the NVIDIA Virtual GPU Manager for VMware vSphere\n\nYou can use the NVIDIA Virtual GPU Manager for VMware vSphere to set up a VMware vSphere VM to use NVIDIA vGPU.\n\nNote:\n\nSome servers, for example, the Dell R740, do not configure SR-IOV capability if the SR-IOV SBIOS setting is disabled on the server. If you are using the Tesla T4 GPU with VMware vSphere on such a server, you must ensure that the SR-IOV SBIOS setting is enabled on the server.\n\nHowever, with any server hardware, do not enable SR-IOV in VMware vCenter Server for the Tesla T4 GPU. If SR-IOV is enabled in VMware vCenter Server for T4, VMware vCenter Server lists the status of the GPU as needing a reboot. You can ignore this status message.\n\nRequirements for Configuring NVIDIA vGPU in a DRS Cluster\n\nYou can configure a VM with NVIDIA vGPU on an ESXi host in a VMware Distributed Resource Scheduler (DRS) cluster. However, to ensure that the automation level of the cluster supports VMs configured with NVIDIA vGPU, you must set the automation level to Partially Automated or Manual.\n\nFor more information about these settings, see Edit Cluster Settings in the VMware documentation.\n\n2.7.1. Installing the NVIDIA Virtual GPU Manager on VMware vSphere\n\nTo install the NVIDIA Virtual GPU Manager you need to access the ESXi host via the ESXi Shell or SSH. Refer to VMware’s documentation on how to enable ESXi Shell or SSH for an ESXi host.\n\nBefore you begin, ensure that the following prerequisites are met:\n\nThe ZIP archive that contains NVIDIA AI Enterprise has been downloaded from the NVIDIA Licensing Portal.\n\nThe software components for the NVIDIA Virtual GPU Manager have been extracted from the downloaded ZIP archive.\n\nCopy the NVIDIA Virtual GPU Manager component files to the ESXi host.\n\nPut the ESXi host into maintenance mode.\n\nCopy\n\nCopied!\n\n$ esxcli system maintenanceMode set –-enable true\n\nInstall the NVIDIA vGPU hypervisor host driver and the NVIDIA GPU Management daemon from their software component files.\n\nRun the esxcli command to install the NVIDIA vGPU hypervisor host driver from its software component file.\n\nCopy\n\nCopied!\n\n$ esxcli software vib install -d /vmfs/volumes/datastore/host-driver-component.zip\n\nRun the esxcli command to install the NVIDIA GPU Management daemon from its software component file.\n\nCopy\n\nCopied!\n\n$ esxcli software vib install -d /vmfs/volumes/datastore/gpu-management-daemon-component.zip\n\ndatastore\n\nThe name of the VMFS datastore to which you copied the software components.\n\nhost-driver-component\n\nThe name of the file that contains the NVIDIA vGPU hypervisor host driver in the form of a software component. Ensure that you specify the file that was extracted from the downloaded ZIP archive. For example, for VMware vSphere 7.0.3, host-driver-component is NVD-VMware-x86_64-525.125.03-1OEM.703.0.0.17630552-bundle-build-number.\n\ngpu-management-daemon-component\n\nThe name of the file that contains the NVIDIA GPU Management daemon in the form of a software component. Ensure that you specify the file that was extracted from the downloaded ZIP archive. For example, for VMware vSphere 7.0.3, gpu-management-daemon-component is VMW-esx-7.0.2-nvd-gpu-mgmt-daemon-1.0-0.0.0001.\n\nExit maintenance mode.\n\nCopy\n\nCopied!\n\n$ esxcli system maintenanceMode set –-enable false\n\nReboot the ESXi host.\n\nCopy\n\nCopied!\n\n$ reboot\n\nUpdate the NVIDIA Virtual GPU Manager if you want to install a new version of NVIDIA Virtual GPU Manager on a system where an existing version is already installed.\n\nTo update the vGPU Manager VIB you need to access the ESXi host via the ESXi Shell or SSH. Refer to VMware’s documentation on how to enable ESXi Shell or SSH for an ESXi host.\n\nNote:\n\nBefore proceeding with the vGPU Manager update, make sure that all VMs are powered off and the ESXi host is placed in maintenance mode. Refer to VMware’s documentation on how to place an ESXi host in maintenance mode\n\nStop the NVIDIA GPU Management Daemon.\n\nCopy\n\nCopied!\n\n$ /etc/init.d/nvdGpuMgmtDaemon stop\n\nUpdate the NVIDIA vGPU hypervisor host driver and the NVIDIA GPU Management daemon.\n\nRun the esxcli command to update the NVIDIA vGPU hypervisor host driver from its software component file.\n\nCopy\n\nCopied!\n\n$ esxcli software vib update -d /vmfs/volumes/datastore/host-driver-component.zip\n\nRun the esxcli command to update the NVIDIA GPU Management daemon from its software component file.\n\nCopy\n\nCopied!\n\n$ esxcli software vib update -d /vmfs/volumes/datastore/gpu-management-daemon-component.zip\n\ndatastore\n\nThe name of the VMFS datastore to which you copied the software components.\n\nhost-driver-component\n\nThe name of the file that contains the NVIDIA vGPU hypervisor host driver in the form of a software component. Ensure that you specify the file that was extracted from the downloaded ZIP archive. For example, for VMware vSphere 7.0.3, host-driver-component is NVD-VMware-x86_64-525.125.03-1OEM.703.0.0.17630552-bundle-build-number.\n\ngpu-management-daemon-component\n\nThe name of the file that contains the NVIDIA GPU Management daemon in the form of a software component. Ensure that you specify the file that was extracted from the downloaded ZIP archive. For example, for VMware vSphere 7.0.3, gpu-management-daemon-component is VMW-esx-7.0.2-nvd-gpu-mgmt-daemon-1.0-0.0.0001.\n\nReboot the ESXi host and remove it from maintenance mode.\n\nAfter the ESXi host has rebooted, verify the installation of the NVIDIA AI Enterprise package for vSphere.\n\nVerify that the NVIDIA AI Enterprise package installed and loaded correctly by checking for the NVIDIA kernel driver in the list of kernel loaded modules.\n\nCopy\n\nCopied!\n\n[root@esxi:~] vmkload_mod -l | grep nvidia nvidia 5 8420\n\nIf the NVIDIA driver is not listed in the output, check dmesg for any load-time errors reported by the driver.\n\nVerify that the NVIDIA GPU Management daemon has started.\n\nCopy\n\nCopied!\n\n$ /etc/init.d/nvdGpuMgmtDaemon status\n\nVerify that the NVIDIA kernel driver can successfully communicate with the NVIDIA physical GPUs in your system by running the nvidia-smi command. The nvidia-smi command is described in more detail in NVIDIA System Management Interface nvidia-smi.\n\nRunning the nvidia-smi command should produce a listing of the GPUs in your platform.\n\nIf nvidia-smi fails to report the expected output for all the NVIDIA GPUs in your system, see Troubleshooting for troubleshooting steps.\n\n2.7.4. Managing the NVIDIA GPU Management Daemon for VMware vSphere\n\nThe NVIDIA GPU Management Daemon for VMware vSphere is a service that is controlled through scripts in the /etc/init.d directory. You can use these scripts to start the daemon, stop the daemon, and get its status.\n\nTo start the NVIDIA GPU Management Daemon, enter the following command:\n\nCopy\n\nCopied!\n\n$ /etc/init.d/nvdGpuMgmtDaemon start\n\nTo stop the NVIDIA GPU Management Daemon, enter the following command:\n\nCopy\n\nCopied!\n\n$ /etc/init.d/nvdGpuMgmtDaemon stop\n\nTo get the status of the NVIDIA GPU Management Daemon, enter the following command:\n\nCopy\n\nCopied!\n\n$ /etc/init.d/nvdGpuMgmtDaemon status\n\n2.7.5. Configuring VMware vMotion with vGPU for VMware vSphere\n\nNVIDIA AI Enterprise supports vGPU migration, which includes VMware vMotion and suspend-resume, for VMs that are configured with vGPU. To enable VMware vMotion with vGPU, an advanced vCenter Server setting must be enabled. However, suspend-resume for VMs that are configured with vGPU is enabled by default.\n\nBefore configuring VMware vMotion with vGPU for an ESXi host, ensure that the current NVIDIA Virtual GPU Manager for VMware vSphere package is installed on the host.\n\nLog in to vCenter Server by using the vSphere Web Client.\n\nIn the Hosts and Clusters view, select the vCenter Server instance.\n\nNote:\n\nEnsure that you select the vCenter Server instance, not the vCenter Server VM.\n\nClick the Configure tab.\n\nIn the Settings section, select Advanced Settings and click Edit.\n\nIn the Edit Advanced vCenter Server Settings window that opens, type vGPU in the search field.\n\nWhen the vgpu.hotmigrate.enabled setting appears, set the Enabled option and click OK.\n\n2.7.6. Changing the Default Graphics Type in VMware vSphere\n\nAfter the vGPU Manager VIB for VMware vSphere VIB is installed, the default graphics type is Shared. To enable vGPU support for VMs in VMware vSphere, you must change the default graphics type to Shared Direct.\n\nIf you do not change the default graphics type, VMs to which a vGPU is assigned fail to start and the following error message is displayed:\n\nNote:\n\nChange the default graphics type before configuring vGPU. Output from the VM console in the VMware vSphere Web Client is not available for VMs that are running vGPU.\n\nBefore changing the default graphics type, ensure that the ESXi host is running and that all VMs on the host are powered off.\n\nLog in to vCenter Server by using the vSphere Web Client.\n\nIn the navigation tree, select your ESXi host and click the Configure tab.\n\nFrom the menu, choose Graphics and then click the Host Graphics tab.\n\nOn the Host Graphics tab, click Edit.\n\nFigure 5. Shared default graphics type\n\nIn the Edit Host Graphics Settings dialog box that opens, select Shared Direct and click OK.\n\nFigure 6. Host graphics settings for vGPU\n\nNote:\n\nIn this dialog box, you can also change the allocation scheme for vGPU-enabled VMs. For more information, see Modifying GPU Allocation Policy on VMware vSphere.\n\nAfter you click OK, the default graphics type changes to Shared Direct.\n\nClick the Graphics Devices tab to verify the configured type of each physical GPU on which you want to configure vGPU. The configured type of each physical GPU must be Shared Direct. For any physical GPU for which the configured type is Shared, change the configured type as follows:\n\nOn the Graphics Devices tab, select the physical GPU and click the Edit icon.\n\nFigure 7. Shared graphics type\n\nIn the Edit Graphics Device Settings dialog box that opens, select Shared Direct and click OK.\n\nFigure 8. Graphics device settings for a physical GPU\n\nRestart the ESXi host or stop and restart nv-hostengine on the ESXi host.\n\nTo stop and restart nv-hostengine, perform these steps:\n\nStop nv-hostengine.\n\nCopy\n\nCopied!\n\n[root@esxi:~] nv-hostengine -t\n\nWait for 1 second to allow nv-hostengine to stop.\n\nStart nv-hostengine.\n\nCopy\n\nCopied!\n\n[root@esxi:~] nv-hostengine -d\n\nIn the Graphics Devices tab of the VMware vCenter Web UI, confirm that the active type and the configured type of each physical GPU are Shared Direct.\n\nFigure 9. Shared direct graphics type\n\nAfter changing the default graphics type, configure vGPU as explained in Configuring a vSphere VM with NVIDIA vGPU.\n\nSee also the following topics in the VMware vSphere documentation:\n\nLog in to vCenter Server by Using the vSphere Web Client\n\nConfiguring Host Graphics\n\n2.7.7. Configuring a vSphere VM with NVIDIA vGPU\n\nTo support applications and workloads that are compute or graphics intensive, you can add multiple vGPUs to a single VM.\n\nCAUTION:\n\nOutput from the VM console in the VMware vSphere Web Client is not available for VMs that are running vGPU. Make sure that you have installed an alternate means of accessing the VM (such as VMware Horizon or a VNC server) before you configure vGPU.\n\nVM console in vSphere Web Client will become active again once the vGPU parameters are removed from the VM’s configuration.\n\nHow to configure a vSphere VM with a vGPU depends on your VMware vSphere version as explained in the following topics:\n\nConfiguring a vSphere 8 VM with NVIDIA vGPU\n\nConfiguring a vSphere 7 VM with NVIDIA vGPU\n\nAfter you have configured a vSphere VM with a vGPU, start the VM. VM console in vSphere Web Client is not supported in this vGPU release. Therefore, use VMware Horizon or VNC to access the VM’s desktop.\n\nAfter the VM has booted, install the NVIDIA AI Enterprise graphics driver as explained in Installing and Licensing NVIDIA AI Enterprise Software Components.\n\n2.7.7.1. Configuring a vSphere 8 VM with NVIDIA vGPU\n\nOpen the vCenter Web UI.\n\nIn the vCenter Web UI, right-click the VM and choose Edit Settings.\n\nIn the Edit Settings window that opens, configure the vGPUs that you want to add to the VM. Add each vGPU that you want to add to the VM as follows:\n\nFrom the ADD NEW DEVICE menu, choose PCI Device.\n\nFigure 10. Command for Adding a PCI Device\n\nIn the Device Selection window that opens, select the type of vGPU you want to configure and click SELECT.\n\nFigure 11. VM Device Selections for vGPU\n\nBack in the Edit Settings window, click OK.\n\n2.7.7.2. Configuring a vSphere 7 VM with NVIDIA vGPU\n\nIf you are adding multiple vGPUs to a single VM, perform this task for each vGPU that you want to add to the VM.\n\nOpen the vCenter Web UI.\n\nIn the vCenter Web UI, right-click the VM and choose Edit Settings.\n\nClick the Virtual Hardware tab.\n\nIn the New device list, select Shared PCI Device and click Add. The PCI device field should be auto-populated with NVIDIA GRID vGPU.\n\nFigure 12. VM settings for vGPU\n\nFrom the GPU Profile drop-down menu, choose the type of vGPU you want to configure and click OK.\n\nEnsure that VMs running vGPU have all their memory reserved:\n\nSelect Edit virtual machine settings from the vCenter Web UI.\n\nExpand the Memory section and click Reserve all guest memory (All locked).\n\n2.7.8. Setting vGPU Plugin Parameters on VMware vSphere\n\nPlugin parameters for a vGPU control the behavior of the vGPU, such as the frame rate limiter (FRL) configuration in frames per second or whether console virtual network computing (VNC) for the vGPU is enabled. The VM to which the vGPU is assigned is started with these parameters. If parameters are set for multiple vGPUs assigned to the same VM, the VM is started with the parameters assigned to each vGPU.\n\nEnsure that the VM to which the vGPU is assigned is powered off.\n\nFor each vGPU for which you want to set plugin parameters, perform this task in the vSphere Client. vGPU plugin parameters are PCI pass through configuration parameters in advanced VM attributes.\n\nIn the vSphere Client, browse to the VM to which the vGPU is assigned.\n\nContext-click the VM and choose Edit Settings.\n\nIn the Edit Settings window, click the VM Options tab.\n\nFrom the Advanced drop-down list, select Edit Configuration.\n\nIn the Configuration Parameters dialog box, click Add Row.\n\nIn the Name field, type the parameter name pciPassthruvgpu-id.cfg.parameter, in the Value field type the parameter value, and click OK.\n\nvgpu-id\n\nA positive integer that identifies the vGPU assigned to a VM. For the first vGPU assigned to a VM, vgpu-id is 0. For example, if two vGPUs are assigned to a VM and you are setting a plugin parameter for both vGPUs, set the following parameters:\n\npciPassthru0.cfg.parameter\n\npciPassthru1.cfg.parameter\n\nparameter\n\nThe name of the vGPU plugin parameter that you want to set. For example, the name of the vGPU plugin parameter for enabling unified memory is enable_uvm.\n\nTo enable unified memory for two vGPUs that are assigned to a VM, set pciPassthru0.cfg.enable_uvm and pciPassthru1.cfg.enable_uvm to 1.\n\n2.8. Configuring the vGPU Manager for a Linux with KVM Hypervisor\n\nNVIDIA AI Enterprise supports the following Linux with KVM hypervisors: Red Hat Enterprise Linux with KVM and Ubuntu.\n\n2.8.1. Getting the BDF and Domain of a GPU on a Linux with KVM Hypervisor\n\nSometimes when configuring a physical GPU for use with NVIDIA AI Enterprise, you must find out which directory in the sysfs file system represents the GPU. This directory is identified by the domain, bus, slot, and function of the GPU.\n\nFor more information about the directory in the sysfs file system that represents a physical GPU, see NVIDIA vGPU Information in the sysfs File System.\n\nObtain the PCI device bus/device/function (BDF) of the physical GPU.\n\nCopy\n\nCopied!\n\n# lspci | grep NVIDIA\n\nThe NVIDIA GPUs listed in this example have the PCI device BDFs 06:00.0 and 07:00.0.\n\nCopy\n\nCopied!\n\n# lspci | grep NVIDIA 06:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M10] (rev a1) 07:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M10] (rev a1)\n\nObtain the full identifier of the GPU from its PCI device BDF.\n\nCopy\n\nCopied!\n\n# virsh nodedev-list --cap pci| grep transformed-bdf\n\ntransformed-bdf\n\nThe PCI device BDF of the GPU with the colon and the period replaced with underscores, for example, 06_00_0.\n\nThis example obtains the full identifier of the GPU with the PCI device BDF 06:00.0.\n\nCopy\n\nCopied!\n\n# virsh nodedev-list --cap pci| grep 06_00_0 pci_0000_06_00_0\n\nObtain the domain, bus, slot, and function of the GPU from the full identifier of the GPU.\n\nCopy\n\nCopied!\n\nvirsh nodedev-dumpxml full-identifier| egrep 'domain|bus|slot|function'\n\nfull-identifier\n\nThe full identifier of the GPU that you obtained in the previous step, for example, pci_0000_06_00_0.\n\nThis example obtains the domain, bus, slot, and function of the GPU with the PCI device BDF 06:00.0.\n\nCopy\n\nCopied!\n\n# virsh nodedev-dumpxml pci_0000_06_00_0| egrep 'domain|bus|slot|function' <domain>0x0000</domain> <bus>0x06</bus> <slot>0x00</slot> <function>0x0</function> <address domain='0x0000' bus='0x06' slot='0x00' function='0x0'/>\n\n2.8.2. Preparing the Virtual Function for an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor\n\nAn NVIDIA vGPU that supports SR-IOV resides on a physical GPU that supports SR-IOV, such as a GPU based on the NVIDIA Ampere architecture. Before creating an NVIDIA vGPU on a GPUthat supports SR-IOV, you must enable the virtual functions of the GPU and obtain the domain, bus, slot, and function of the specific virtual function on which you want to create the vGPU.\n\nBefore performing this task, ensure that the GPU is not being used by any other processes, such as CUDA applications, monitoring applications, or the nvidia-smi command.\n\nEnable the virtual functions for the physical GPU in the sysfs file system.\n\nNote:\n\nThe virtual functions for the physical GPU in the sysfs file system are disabled after the hypervisor host is rebooted or if the driver is reloaded or upgraded.\n\nUse only the custom script sriov-manage provided by NVIDIA AI Enterprise for this purpose. Do not try to enable the virtual function for the GPU by any other means.\n\nCopy\n\nCopied!\n\n# /usr/lib/nvidia/sriov-manage -e domain:bus:slot.function\n\ndomain\n\nbus\n\nslot\n\nfunction\n\nThe domain, bus, slot, and function of the GPU, without the 0x prefix.\n\nNote:\n\nOnly one mdev device file can be created on a virtual function.\n\nThis example enables the virtual functions for the GPU with the domain 00, bus 41, slot 0000, and function 0.\n\nCopy\n\nCopied!\n\n# /usr/lib/nvidia/sriov-manage -e 00:41:0000.0\n\nObtain the domain, bus, slot, and function of the available virtual functions on the GPU.\n\nCopy\n\nCopied!\n\n# ls -l /sys/bus/pci/devices/domain\\:bus\\:slot.function/ | grep virtfn\n\ndomain\n\nbus\n\nslot\n\nfunction\n\nThe domain, bus, slot, and function of the GPU, without the 0x prefix.\n\nThis example shows the output of this command for a physical GPU with slot 00, bus 41, domain 0000, and function 0.\n\nChoose the available virtual function on which you want to create the vGPU and note its domain, bus, slot, and function.\n\nCreating an NVIDIA vGPU on a Linux with KVM Hypervisor\n\nFor each vGPU that you want to create, perform this task in a Linux command shell on the a Linux with KVM hypervisor host.\n\nBefore you begin, ensure that you have the domain, bus, slot, and function of the GPU on which you are creating the vGPU. For instructions, see Getting the BDF and Domain of a GPU on a Linux with KVM Hypervisor.\n\nHow to create an NVIDIA vGPU on a Linux with KVM hypervisor depends on whether the NVIDIA vGPU supports single root I/O virtualization (SR-IOV). For details, refer to:\n\nCreating a Legacy NVIDIA vGPU on a Linux with KVM Hypervisor\n\nCreating an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor\n\n2.8.3.1. Creating a Legacy NVIDIA vGPU on a Linux with KVM Hypervisor\n\nA legacy NVIDIA vGPU does not support SR-IOV.\n\nChange to the mdev_supported_types directory for the physical GPU.\n\nCopy\n\nCopied!\n\n# cd /sys/class/mdev_bus/domain\\:bus\\:slot.function/mdev_supported_types/\n\ndomain\n\nbus\n\nslot\n\nfunction\n\nThe domain, bus, slot, and function of the GPU, without the 0x prefix.\n\nThis example changes to the mdev_supported_types directory for the GPU with the domain 0000 and PCI device BDF 06:00.0.\n\nCopy\n\nCopied!\n\n# cd /sys/bus/pci/devices/0000\\:06\\:00.0/mdev_supported_types/\n\nFind out which subdirectory of mdev_supported_types contains registration information for the vGPU type that you want to create.\n\nCopy\n\nCopied!\n\n# grep -l \"vgpu-type\" nvidia-*/name\n\nvgpu-type\n\nThe vGPU type, for example, M10-2Q.\n\nThis example shows that the registration information for the M10-2Q vGPU type is contained in the nvidia-41 subdirectory of mdev_supported_types.\n\nCopy\n\nCopied!\n\n# grep -l \"M10-2Q\" nvidia-*/name nvidia-41/name\n\nConfirm that you can create an instance of the vGPU type on the physical GPU.\n\nCopy\n\nCopied!\n\n# cat subdirectory/available_instances\n\nsubdirectory\n\nThe subdirectory that you found in the previous step, for example, nvidia-41.\n\nThe number of available instances must be at least 1. If the number is 0, either an instance of another vGPU type already exists on the physical GPU, or the maximum number of allowed instances has already been created.\n\nThis example shows that four more instances of the M10-2Q vGPU type can be created on the physical GPU.\n\nCopy\n\nCopied!\n\n# cat nvidia-41/available_instances 4\n\nGenerate a correctly formatted universally unique identifier (UUID) for the vGPU.\n\nCopy\n\nCopied!\n\n# uuidgen aa618089-8b16-4d01-a136-25a0f3c73123\n\nWrite the UUID that you obtained in the previous step to the create file in the registration information directory for the vGPU type that you want to create.\n\nCopy\n\nCopied!\n\n# echo \"uuid\"> subdirectory/create\n\nuuid\n\nThe UUID that you generated in the previous step, which will become the UUID of the vGPU that you want to create.\n\nsubdirectory\n\nThe registration information directory for the vGPU type that you want to create, for example, nvidia-41.\n\nThis example creates an instance of the M10-2Q vGPU type with the UUID aa618089-8b16-4d01-a136-25a0f3c73123.\n\nCopy\n\nCopied!\n\n# echo \"aa618089-8b16-4d01-a136-25a0f3c73123\" > nvidia-41/create\n\nAn mdev device file for the vGPU is added to the parent physical device directory of the vGPU. The vGPU is identified by its UUID.\n\nThe /sys/bus/mdev/devices/ directory contains a symbolic link to the mdev device file.\n\nMake the mdev device file that you created to represent the vGPU persistent.\n\nCopy\n\nCopied!\n\n# mdevctl define --auto --uuid uuid\n\nuuid\n\nThe UUID that you specified in the previous step for the vGPU that you are creating.\n\nNote:\n\nNot all Linux with KVM hypervisor releases include the mdevctl command. If your release does not include the mdevctl command, you can use standard features of the operating system to automate the re-creation of this device file when the host is booted. For example, you can write a custom script that is executed when the host is rebooted.\n\nConfirm that the vGPU was created.\n\nConfirm that the /sys/bus/mdev/devices/ directory contains the mdev device file for the vGPU.\n\nIf your release includes the mdevctl command, list the active mediated devices on the hypervisor host.\n\nCopy\n\nCopied!\n\n# mdevctl list aa618089-8b16-4d01-a136-25a0f3c73123 0000:06:00.0 nvidia-41\n\n2.8.3.2. Creating an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor\n\nAn NVIDIA vGPU that supports SR-IOV resides on a physical GPU that supports SR-IOV, such as a GPU based on the NVIDIA Ampere architecture.\n\nBefore performing this task, ensure that the virtual function on which you want to create the vGPU has been prepared as explained in Preparing the Virtual Function for an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor.\n\nIf you want to support vGPUs with different amounts of frame buffer, also ensure that the GPU has been put into mixed-size mode as explained in Preparing the Virtual Function for an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor.\n\nChange to the mdev_supported_types directory for the virtual function on which you want to create the vGPU.\n\nCopy\n\nCopied!\n\n# cd /sys/class/mdev_bus/domain\\:bus\\:vf-slot.v-function/mdev_supported_types/\n\ndomain\n\nbus\n\nThe domain and bus of the GPU, without the 0x prefix.\n\nvf-slot\n\nv-function\n\nThe slot and function of the virtual function that you noted in Preparing the Virtual Function for an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor.\n\nThis example changes to the mdev_supported_types directory for the first virtual function (virtfn0) for the GPU with the domain 0000 and bus 41. The first virtual function (virtfn0) has slot 00 and function 4.\n\nCopy\n\nCopied!\n\n# cd /sys/class/mdev_bus/0000\\:41\\:00.4/mdev_supported_types\n\nFind out which subdirectory of mdev_supported_types contains registration information for the vGPU type that you want to create.\n\nCopy\n\nCopied!\n\n# grep -l \"vgpu-type\" nvidia-*/name\n\nvgpu-type\n\nThe vGPU type, for example, A40-2Q.\n\nThis example shows that the registration information for the A40-2Q vGPU type is contained in the nvidia-558 subdirectory of mdev_supported_types.\n\nCopy\n\nCopied!\n\n# grep -l \"A40-2Q\" nvidia-*/name nvidia-558/name\n\nConfirm that you can create an instance of the vGPU type on the virtual function.\n\nCopy\n\nCopied!\n\n# cat subdirectory/available_instances\n\nsubdirectory\n\nThe subdirectory that you found in the previous step, for example, nvidia-558.\n\nThe number of available instances must be 1. If the number is 0, a vGPU has already been created on the virtual function. Only one instance of any vGPU type can be created on a virtual function.\n\nThis example shows that an instance of the A40-2Q vGPU type can be created on the virtual function.\n\nCopy\n\nCopied!\n\n# cat nvidia-558/available_instances 1\n\nGenerate a correctly formatted universally unique identifier (UUID) for the vGPU.\n\nCopy\n\nCopied!\n\n# uuidgen aa618089-8b16-4d01-a136-25a0f3c73123\n\nWrite the UUID that you obtained in the previous step to the create file in the registration information directory for the vGPU type that you want to create.\n\nCopy\n\nCopied!\n\n# echo \"uuid\"> subdirectory/create\n\nuuid\n\nThe UUID that you generated in the previous step, which will become the UUID of the vGPU that you want to create.\n\nsubdirectory\n\nThe registration information directory for the vGPU type that you want to create, for example, nvidia-558.\n\nThis example creates an instance of the A40-2Q vGPU type with the UUID aa618089-8b16-4d01-a136-25a0f3c73123.\n\nCopy\n\nCopied!\n\n# echo \"aa618089-8b16-4d01-a136-25a0f3c73123\" > nvidia-558/create\n\nAn mdev device file for the vGPU is added to the parent virtual function directory of the vGPU. The vGPU is identified by its UUID.\n\nTime-sliced vGPUs only: Make the mdev device file that you created to represent the vGPU persistent.\n\nCopy\n\nCopied!\n\n# mdevctl define --auto --uuid uuid\n\nuuid\n\nThe UUID that you specified in the previous step for the vGPU that you are creating.\n\nNote:\n\nIf you are using a GPU that supports SR-IOV, the mdev device file persists after a host reboot only if you enable the virtual functions for the GPU as explained in Preparing the Virtual Function for an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor before rebooting any VM that is configured with a vGPU on the GPU.\n\nYou cannot use the mdevctl command to make the mdev device file for a MIG-backed vGPU persistent. The mdev device file for a MIG-backed vGPU is not retained after the host is rebooted because MIG instances are no longer available.\n\nNot all Linux with KVM hypervisor releases include the mdevctl command. If your release does not include the mdevctl command, you can use standard features of the operating system to automate the re-creation of this device file when the host is booted. For example, you can write a custom script that is executed when the host is rebooted.\n\nConfirm that the vGPU was created.\n\nConfirm that the /sys/bus/mdev/devices/ directory contains a symbolic link to the mdev device file.\n\nIf your release includes the mdevctl command, list the active mediated devices on the hypervisor host.\n\nCopy\n\nCopied!\n\n# mdevctl list aa618089-8b16-4d01-a136-25a0f3c73123 0000:06:00.0 nvidia-558\n\n2.8.4. Adding One or More vGPUs to a Linux with KVM Hypervisor VM\n\nTo support applications and workloads that are compute or graphics intensive, you can add multiple vGPUs to a single VM.\n\nEnsure that the following prerequisites are met:\n\nThe VM to which you want to add the vGPUs is shut down.\n\nThe vGPUs that you want to add have been created as explained in Creating an NVIDIA vGPU on a Linux with KVM Hypervisor.\n\nYou can add vGPUs to a Linux with KVM hypervisor VM by using any of the following tools:\n\nThe virsh command\n\nThe QEMU command line\n\nAfter adding vGPUs to a Linux with KVM hypervisor VM, start the VM.\n\nCopy\n\nCopied!\n\n# virsh start vm-name\n\nvm-name\n\nThe name of the VM that you added the vGPUs to.\n\nAfter the VM has booted, install the NVIDIA AI Enterprise graphics driver as explained in Installing and Licensing NVIDIA AI Enterprise Components Natively.\n\nAdding One or More vGPUs to a Linux with KVM Hypervisor VM by Using virsh\n\nIn virsh, open for editing the XML file of the VM that you want to add the vGPU to.\n\nCopy\n\nCopied!\n\n# virsh edit vm-name\n\nvm-name\n\nThe name of the VM to that you want to add the vGPUs to.\n\nFor each vGPU that you want to add to the VM, add a device entry in the form of an address element inside the source element to add the vGPU to the guest VM.\n\nCopy\n\nCopied!\n\n<device> ... <hostdev mode='subsystem' type='mdev' model='vfio-pci'> <source> <address uuid='uuid'/> </source> </hostdev> </device>\n\nuuid\n\nThe UUID that was assigned to the vGPU when the vGPU was created.\n\nThis example adds a device entry for the vGPU with the UUID a618089-8b16-4d01-a136-25a0f3c73123.\n\nCopy\n\nCopied!\n\n<device> ... <hostdev mode='subsystem' type='mdev' model='vfio-pci'> <source> <address uuid='a618089-8b16-4d01-a136-25a0f3c73123'/> </source> </hostdev> </device>\n\nThis example adds device entries for two vGPUs with the following UUIDs:\n\nc73f1fa6-489e-4834-9476-d70dabd98c40\n\n3b356d38-854e-48be-b376-00c72c7d119c\n\nCopy\n\nCopied!\n\n<device> ... <hostdev mode='subsystem' type='mdev' model='vfio-pci'> <source> <address uuid='c73f1fa6-489e-4834-9476-d70dabd98c40'/> </source> </hostdev> <hostdev mode='subsystem' type='mdev' model='vfio-pci'> <source> <address uuid='3b356d38-854e-48be-b376-00c72c7d119c'/> </source> </hostdev> </device>\n\nOptional: Add a video element that contains a model element in which the type attribute is set to none.\n\nCopy\n\nCopied!\n\n<video> <model type='none'/> </video>\n\nAdding this video element prevents the default video device that libvirt adds from being loaded into the VM. If you don't add this video element, you must configure the Xorg server or your remoting solution to load only the vGPU devices you added and not the default video device.\n\nAdding One or More vGPUs to a Linux with KVM Hypervisor VM by Using the QEMU Command Line\n\nAdd the following options to the QEMU command line:\n\nFor each vGPU that you want to add to the VM, add one -device option in the following format:\n\nCopy\n\nCopied!\n\n-device vfio-pci,sysfsdev=/sys/bus/mdev/devices/vgpu-uuid\n\nvgpu-uuid\n\nThe UUID that was assigned to the vGPU when the vGPU was created.\n\nAdd a -uuid option to specify the VM as follows:\n\nCopy\n\nCopied!\n\n-uuid vm-uuid\n\nvm-uuid\n\nThe UUID that was assigned to the VM when the VM was created.\n\nThis example adds the vGPU with the UUID aa618089-8b16-4d01-a136-25a0f3c73123 to the VM with the UUID ebb10a6e-7ac9-49aa-af92-f56bb8c65893.\n\nCopy\n\nCopied!\n\n-device vfio-pci,sysfsdev=/sys/bus/mdev/devices/aa618089-8b16-4d01-a136-25a0f3c73123 \\ -uuid ebb10a6e-7ac9-49aa-af92-f56bb8c65893\n\nThis example adds device entries for two vGPUs with the following UUIDs:\n\n676428a0-2445-499f-9bfd-65cd4a9bd18f\n\n6c5954b8-5bc1-4769-b820-8099fe50aaba\n\nThe entries are added to the VM with the UUID ec5e8ee0-657c-4db6-8775-da70e332c67e.\n\nCopy\n\nCopied!\n\n-device vfio-pci,sysfsdev=/sys/bus/mdev/devices/676428a0-2445-499f-9bfd-65cd4a9bd18f \\ -device vfio-pci,sysfsdev=/sys/bus/mdev/devices/6c5954b8-5bc1-4769-b820-8099fe50aaba \\ -uuid ec5e8ee0-657c-4db6-8775-da70e332c67e\n\nSetting vGPU Plugin Parameters on a Linux with KVM Hypervisor\n\nPlugin parameters for a vGPU control the behavior of the vGPU, such as the frame rate limiter (FRL) configuration in frames per second or whether console virtual network computing (VNC) for the vGPU is enabled. The VM to which the vGPU is assigned is started with these parameters. If parameters are set for multiple vGPUs assigned to the same VM, the VM is started with the parameters assigned to each vGPU.\n\nFor each vGPU for which you want to set plugin parameters, perform this task in a Linux command shell on the Linux with KVM hypervisor host.\n\nChange to the nvidia subdirectory of the mdev device directory that represents the vGPU.\n\nCopy\n\nCopied!\n\n# cd /sys/bus/mdev/devices/uuid/nvidia\n\nuuid\n\nThe UUID of the vGPU, for example, aa618089-8b16-4d01-a136-25a0f3c73123.\n\nWrite the plugin parameters that you want to set to the vgpu_params file in the directory that you changed to in the previous step.\n\nCopy\n\nCopied!\n\n# echo \"plugin-config-params\" > vgpu_params\n\nplugin-config-params\n\nA comma-separated list of parameter-value pairs, where each pair is of the form parameter-name=value.\n\nThis example disables frame rate limiting and console VNC for a vGPU.\n\nCopy\n\nCopied!\n\n# echo \"frame_rate_limiter=0, disable_vnc=1\" > vgpu_params\n\nThis example enables unified memory for a vGPU.\n\nCopy\n\nCopied!\n\n# echo \"enable_uvm=1\" > vgpu_params\n\nThis example enables NVIDIA CUDA Toolkit debuggers for a vGPU.\n\nCopy\n\nCopied!\n\n# echo \"enable_debugging=1\" > vgpu_params\n\nThis example enables NVIDIA CUDA Toolkit profilers for a vGPU.\n\nCopy\n\nCopied!\n\n# echo \"enable_profiling=1\" > vgpu_params\n\nTo clear any vGPU plugin parameters that were set previously, write a space to the vgpu_params file for the vGPU.\n\nCopy\n\nCopied!\n\n# echo \" \" > vgpu_params\n\nDeleting a vGPU on a Linux with KVM Hypervisor\n\nFor each vGPU that you want to delete, perform this task in a Linux command shell on the Linux with KVM hypervisor host.\n\nBefore you begin, ensure that the following prerequisites are met:\n\nYou have the domain, bus, slot, and function of the GPU where the vGPU that you want to delete resides. For instructions, see Getting the BDF and Domain of a GPU on a Linux with KVM Hypervisor.\n\nThe VM to which the vGPU is assigned is shut down.\n\nChange to the mdev_supported_types directory for the physical GPU.\n\nCopy\n\nCopied!\n\n# cd /sys/class/mdev_bus/domain\\:bus\\:slot.function/mdev_supported_types/\n\ndomain\n\nbus\n\nslot\n\nfunction\n\nThe domain, bus, slot, and function of the GPU, without the 0x prefix.\n\nThis example changes to the mdev_supported_types directory for the GPU with the PCI device BDF 06:00.0.\n\nCopy\n\nCopied!\n\n# cd /sys/bus/pci/devices/0000\\:06\\:00.0/mdev_supported_types/\n\nChange to the subdirectory of mdev_supported_types that contains registration information for the vGPU.\n\nCopy\n\nCopied!\n\n# cd `find . -type d -name uuid`\n\nuuid\n\nThe UUID of the vGPU, for example, aa618089-8b16-4d01-a136-25a0f3c73123.\n\nWrite the value 1 to the remove file in the registration information directory for the vGPU that you want to delete.\n\nCopy\n\nCopied!\n\n# echo \"1\" > remove\n\nNVIDIA vGPU Information in the sysfs File System\n\nInformation about the NVIDIA vGPU types supported by each physical GPU in a Linux with KVM hypervisor host is stored in the sysfs file system.\n\nAll physical GPUs on the host are registered with the mdev kernel module. Information about the physical GPUs and the vGPU types that can be created on each physical GPU is stored in directories and files under the /sys/class/mdev_bus/ directory.\n\nThe sysfs directory for each physical GPU is at the following locations:\n\n/sys/bus/pci/devices/\n\n/sys/class/mdev_bus/\n\nBoth directories are a symbolic link to the real directory for PCI devices in the sysfs file system.\n\nThe organization the sysfs directory for each physical GPU is as follows:\n\nCopy\n\nCopied!\n\n/sys/class/mdev_bus/ |-parent-physical-device |-mdev_supported_types |-nvidia-vgputype-id |-available_instances |-create |-description |-device_api |-devices |-name\n\nparent-physical-device\n\nEach physical GPU on the host is represented by a subdirectory of the /sys/class/mdev_bus/ directory.\n\nThe name of each subdirectory is as follows:\n\ndomain\\:bus\\:slot.function\n\ndomain, bus, slot, function are the domain, bus, slot, and function of the GPU, for example, 0000\\:06\\:00.0.\n\nEach directory is a symbolic link to the real directory for PCI devices in the sysfs file system. For example:\n\nmdev_supported_types\n\nA directory named mdev_supported_types is required under the sysfs directory for each physical GPU that will be configured with NVIDIA vGPU. How this directory is created for a GPU depends on whether the GPU supports SR-IOV.\n\nFor a GPU that does not support SR-IOV, this directory is created automatically after the Virtual GPU Manager is installed on the host and the host has been rebooted.\n\nFor a GPU that supports SR-IOV, such as a GPU based on the NVIDIA Ampere architecture, you must create this directory by enabling the virtual function for the GPU as explained in Creating an NVIDIA vGPU on a Linux with KVM Hypervisor. The mdev_supported_types directory itself is never visible on the physical function.\n\nThe mdev_supported_types directory contains a subdirectory for each vGPU type that the physical GPU supports. The name of each subdirectory is nvidia-vgputype-id, where vgputype-id is an unsigned integer serial number. For example:\n\nnvidia-vgputype-id\n\nEach directory represents an individual vGPU type and contains the following files and directories:\n\navailable_instances\n\nThis file contains the number of instances of this vGPU type that can still be created. This file is updated any time a vGPU of this type is created on or removed from the physical GPU.\n\nNote:\n\nWhen a time-sliced vGPU is created, the content of the available_instances for all other time-sliced vGPU types on the physical GPU is set to 0. This behavior enforces the requirement that all time-sliced vGPUs on a physical GPU must be of the same type. However, this requirement does not apply to MIG-backed vGPUs. Therefore, when a MIG-backed vGPU is created, available_instances for all other MIG-backed vGPU types on the physical GPU is not set to 0\n\ncreate\n\nThis file is used for creating a vGPU instance. A vGPU instance is created by writing the UUID of the vGPU to this file. The file is write only.\n\ndescription\n\nThis file contains the following details of the vGPU type:\n\nThe maximum number of virtual display heads that the vGPU type supports\n\nThe frame rate limiter (FRL) configuration in frames per second\n\nThe frame buffer size in Mbytes\n\nThe maximum resolution per display head\n\nThe maximum number of vGPU instances per physical GPU\n\nFor example:\n\nCopy\n\nCopied!\n\n# cat description num_heads=4, frl_config=60, framebuffer=2048M, max_resolution=4096x2160, max_instance=4\n\ndevice_api\n\nThis file contains the string vfio_pci to indicate that a vGPU is a PCI device.\n\ndevices\n\nThis directory contains all the mdev devices that are created for the vGPU type. For example:\n\nname\n\nThis file contains the name of the vGPU type. For example:\n\nCopy\n\nCopied!\n\n# cat name GRID M10-2Q\n\n2.9. Putting a GPU Into Mixed-Size Mode\n\nBy default, a GPU supports only vGPUs with the same amount of frame buffer and, therefore, is in equal-size mode. To support vGPUs with different amounts of frame buffer, the GPU must be put into mixed-size mode. When a GPU is in mixed-size mode, the maximum number of some types of vGPU allowed on a GPU is less than when the GPU is in equal-size mode.\n\nNote:\n\nA GPU in mixed-size mode reverts to its default mode if the hypervisor host is rebooted, the NVIDIA Virtual GPU Manager is reloaded, or the GPU is reset.\n\nWhen a GPU is in mixed-size mode, only the best effort and equal share schedulers are supported. The fixed share scheduler is not supported.\n\nBefore performing this task, ensure that no vGPUs are running on the GPU and that the GPU is not being used by any other processes, such as CUDA applications, monitoring applications, or the nvidia-smi command.\n\nIf you are using a GPU that supports SR-IOV on a Linux with KVM hypervisor, also ensure that the virtual functions for the physical GPU in the sysfs file system are enabled as explained in Preparing the Virtual Function for an NVIDIA vGPU that Supports SR-IOV on a Linux with KVM Hypervisor.\n\nUse nvidia-smi to list the status of all physical GPUs, and check that heterogeneous time-sliced vGPU sizes are noted as supported.\n\nCopy\n\nCopied!\n\n# nvidia-smi -q ... Attached GPUs : 1 GPU 00000000:41:00.0 ... Heterogeneous Time-Slice Sizes : Supported ...\n\nPut each GPU that you want to support vGPUs with different amounts of frame buffer into mixed-size mode.\n\nCopy\n\nCopied!\n\n# nvidia-smi vgpu -i id -shm 1\n\nid\n\nThe index of the GPU as reported by nvidia-smi.\n\nThis example puts the GPU with index 00000000:41:00.0 into mixed-size mode.\n\nConfirm that the GPU is now in mixed-size mode by using nvidia-smi to check that vGPU heterogeneous mode is enabled.\n\nCopy\n\nCopied!\n\n# nvidia-smi -q ... vGPU Heterogeneous Mode : Enabled ...\n\n2.10. Placing a vGPU on a Physical GPU in Mixed-Size Mode\n\nBy default, the Virtual GPU Manager determines where a vGPU is placed on a GPU. To fit as many vGPUs as possible on the GPU, you can control the placement of vGPUs on a GPU in mixed-size mode. By controlling the placement of vGPUs on the GPU, you can ensure that no gaps that cannot be occupied by a vGPU are left in the placement region on the GPU.\n\nThe vGPU placements that a GPU in mixed-size mode supports depend on the total amount of frame buffer that the GPU has. For details, refer to vGPU Placements for GPUs in Mixed-Size Mode.\n\nNote:\n\nThis task is optional. If you want the Virtual GPU Manager to determine where a vGPU is placed on a GPU, omit this task.\n\nBefore performing this task, ensure that following prerequisites are met:\n\nThe GPU has been put into mixed-size mode as explained in Putting a GPU Into Mixed-Size Mode.\n\nThe vGPU that you want to place on the physical GPU has been created as explained in Creating an NVIDIA vGPU on a Linux with KVM Hypervisor.\n\nPerform this task in a command shell on the hypervisor host.\n\nUse nvidia-smi to list the placement size and available placement IDs for the type of the vGPU.\n\nNote:\n\nSome supported placement IDs for the vGPU type might be unavailable because they are already in use by another vGPU. To list the placement size and all supported placement IDs for the type of the vGPU, run the following command:\n\nThe number of supported placement IDs is the maximum number of vGPUs of the type that are allowed on the GPU in mixed-size mode.\n\nSet the vgpu-placement-id vGPU plugin parameter for the vGPU to the placement ID that you want.\n\nFor a Linux with KVM hypervisor, write the parameter to the vgpu_params file in the nvidia subdirectory of the mdev device directory that represents the vGPU.\n\nCopy\n\nCopied!\n\n# echo \"vgpu-placement-id=placement-id\" > /sys/bus/mdev/devices/uuid/nvidia/vgpu_params\n\nplacement-id\n\nThe placement ID that you want to set for the vGPU.\n\nuuid\n\nThe UUID of the vGPU, for example, aa618089-8b16-4d01-a136-25a0f3c73123.\n\nThis example sets the placement ID for the vGPU that has the UUID aa618089-8b16-4d01-a136-25a0f3c73123 to 6.\n\nCopy\n\nCopied!\n\n# echo \"vgpu-placement-id=6\" > \\ /sys/bus/mdev/devices/aa618089-8b16-4d01-a136-25a0f3c73123/nvidia/vgpu_params\n\nWhen the VM to which the vGPU is assigned is rebooted, the Virtual GPU Manager validates the placement ID that you assigned to the vGPU. If the placement ID is invalid or unavailable, the VM fails to boot.\n\nAfter the VM to which the vGPU is assigned has been rebooted, you can confirm that the vGPU has been assigned the correct placement ID.\n\n2.11. Configuring a GPU for MIG-Backed vGPUs\n\nTo support GPU instances with NVIDIA vGPU, a GPU must be configured with MIG mode enabled and GPU instances must be created and configured on the physical GPU. Optionally, you can create compute instances within the GPU instances. If you don't create compute instances within the GPU instances, they can be added later for individual vGPUs from within the guest VMs.\n\nEnsure that the following prerequisites are met:\n\nThe NVIDIA Virtual GPU Manager is installed on the hypervisor host.\n\nYou have root user privileges on your hypervisor host machine.\n\nYou have determined which GPU instances correspond to the vGPU types of the MIG-backed vGPUs that you will create.\n\nTo get this information, consult the table of MIG-backed vGPUs for your GPU in Virtual GPU Types for Supported GPUs.\n\nThe GPU is not being used by any other processes, such as CUDA applications, monitoring applications, or the nvidia-smi command.\n\nTo configure a GPU for MIG-backed vGPUs, follow these instructions:\n\nEnabling MIG Mode for a GPU\n\nNote:\n\nFor VMware vSphere, only enabling MIG mode is required because VMware vSphere creates the GPU instances and, after the VM is booted and guest driver is installed, one compute instance is automatically created in the VM.\n\nCreating GPU Instances on a MIG-Enabled GPU\n\nOptional: Creating Compute Instances in a GPU instance\n\nAfter configuring a GPU for MIG-backed vGPUs, create the vGPUs that you need and add them to their VMs.\n\n2.11.1. Enabling MIG Mode for a GPU\n\nPerform this task in your hypervisor command shell.\n\nOpen a command shell as the root user on your hypervisor host machine. On all supported hypervisors, you can use secure shell (SSH) for this purpose. Individual hypervisors may provide additional means for logging in. For details, refer to the documentation for your hypervisor.\n\nDetermine whether MIG mode is enabled. Use the nvidia-smi command for this purpose. By default, MIG mode is disabled.\n\nThis example shows that MIG mode is disabled on GPU 0.\n\nNote:\n\nIn the output from nvidia-smi, the NVIDIA A100 HGX 40GB GPU is referred to as A100-SXM4-40GB.\n\nIf MIG mode is disabled, enable it.\n\nCopy\n\nCopied!\n\n$ nvidia-smi -i [gpu-ids] -mig 1\n\ngpu-ids\n\nA comma-separated list of GPU indexes, PCI bus IDs or UUIDs that specifies the GPUs on which you want to enable MIG mode. If gpu-ids is omitted, MIG mode is enabled on all GPUs on the system.\n\nThis example enables MIG mode on GPU 0.\n\nNote:\n\nIf the GPU is being used by another process, this command fails and displays a warning message that MIG mode for the GPU is in the pending enable state. In this situation, stop all processes that are using the GPU and retry the command.\n\nVMware vSphere ESXi with GPUs based on the NVIDIA Ampere architecture only: Reboot the hypervisor host. If you are using any other hypervisor or GPUs that are based on the NVIDIA Hopper™ GPU architecture or a later architecture, omit this step.\n\nQuery the GPUs on which you enabled MIG mode to confirm that MIG mode is enabled.\n\nThis example queries GPU 0 for the PCI bus ID and MIG mode in comma-separated values (CSV) format.\n\n2.11.2. Creating GPU Instances on a MIG-Enabled GPU\n\nNote:\n\nIf you are using VMware vSphere, omit this task. VMware vSphere creates the GPU instances automatically.\n\nPerform this task in your hypervisor command shell.\n\nIf necessary, open a command shell as the root user on your hypervisor host machine.\n\nList the GPU instance profiles that are available on your GPU.\n\nYou will need to specify the profiles by their IDs, not their names, when you create them.\n\nCreate the GPU instances that correspond to the vGPU types of the MIG-backed vGPUs that you will create.\n\nCopy\n\nCopied!\n\n$ nvidia-smi mig -cgi gpu-instance-profile-ids\n\ngpu-instance-profile-ids\n\nA comma-separated list of GPU instance profile IDs that specifies the GPU instances that you want to create.\n\nThis example creates two GPU instances of type 2g.10gb, which has profile ID 14.\n\n2.11.3. Optional: Creating Compute Instances in a GPU instance\n\nCreating compute instances within GPU instances is optional. If you don't create compute instances within the GPU instances, they can be added later for individual vGPUs from within the guest VMs.\n\nNote:\n\nIf you are using VMware vSphere, omit this task. After the VM is booted and guest driver is installed, one compute instance is automatically created in the VM.\n\nPerform this task in your hypervisor command shell.\n\nIf necessary, open a command shell as the root user on your hypervisor host machine.\n\nList the available GPU instances.\n\nCreate the compute instances that you need within each GPU instance.\n\nCopy\n\nCopied!\n\n$ nvidia-smi mig -cci -gi gpu-instance-ids\n\ngpu-instance-ids\n\nA comma-separated list of GPU instance IDs that specifies the GPU instances within which you want to create the compute instances.\n\nCAUTION:\n\nTo avoid an inconsistent state between a guest VM and the hypervisor host, do not create compute instances from the hypervisor on a GPU instance on which an active guest VM is running. Instead, create the compute instances from within the guest VM as explained in Modifying a MIG-Backed vGPU's Configuration.\n\nThis example creates a compute instance on each of GPU instances 3 and 5.\n\nVerify that the compute instances were created within each GPU instance.\n\nNote:\n\nAdditional compute instances that have been created in a VM are destroyed when the VM is shut down or rebooted. After the shutdown or reboot, only one compute instance remains in the VM. This compute instance is created automatically after the NVIDIA AI Enterprise graphics driver is installed.\n\n2.12. Disabling MIG Mode for One or More GPUs\n\nIf a GPU that you want to use for time-sliced vGPUs or GPU pass through has previously been configured for MIG-backed vGPUs, disable MIG mode on the GPU.\n\nEnsure that the following prerequisites are met:\n\nThe NVIDIA Virtual GPU Manager is installed on the hypervisor host.\n\nYou have root user privileges on your hypervisor host machine.\n\nThe GPU is not being used by any other processes, such as CUDA applications, monitoring applications, or the nvidia-smi command.\n\nPerform this task in your hypervisor command shell.\n\nOpen a command shell as the root user on your hypervisor host machine. On all supported hypervisors, you can use secure shell (SSH) for this purpose. Individual hypervisors may provide additional means for logging in. For details, refer to the documentation for your hypervisor.\n\nDetermine whether MIG mode is disabled. Use the nvidia-smi command for this purpose. By default, MIG mode is disabled, but might have previously been enabled.\n\nThis example shows that MIG mode is enabled on GPU 0.\n\nNote:\n\nIn the output from output from nvidia-smi, the NVIDIA A100 HGX 40GB GPU is referred to as A100-SXM4-40GB.\n\nIf MIG mode is enabled, disable it.\n\nCopy\n\nCopied!\n\n$ nvidia-smi -i [gpu-ids] -mig 0\n\ngpu-ids\n\nA comma-separated list of GPU indexes, PCI bus IDs or UUIDs that specifies the GPUs on which you want to disable MIG mode. If gpu-ids is omitted, MIG mode is disabled on all GPUs on the system.\n\nThis example disables MIG mode on GPU 0.\n\nConfirm that MIG mode was disabled. Use the nvidia-smi command for this purpose.\n\nThis example shows that MIG mode is disabled on GPU 0.\n\n2.13. Disabling and Enabling ECC Memory\n\nSome GPUs that support NVIDIA AI Enterprise support error correcting code (ECC) memory with NVIDIA vGPU. ECC memory improves data integrity by detecting and handling double-bit errors. However, not all GPUs, vGPU types, and hypervisor software versions support ECC memory with NVIDIA vGPU.\n\nOn GPUs that support ECC memory with NVIDIA vGPU, ECC memory is supported with C-series and Q-series vGPUs, but not with A-series and B-series vGPUs. Although A-series and B-series vGPUs start on physical GPUs on which ECC memory is enabled, enabling ECC with vGPUs that do not support it might incur some costs.\n\nOn physical GPUs that do not have HBM2 memory, the amount of frame buffer that is usable by vGPUs is reduced. All types of vGPU are affected, not just vGPUs that support ECC memory.\n\nThe effects of enabling ECC memory on a physical GPU are as follows:\n\nECC memory is exposed as a feature on all supported vGPUs on the physical GPU.\n\nIn VMs that support ECC memory, ECC memory is enabled, with the option to disable ECC in the VM.\n\nECC memory can be enabled or disabled for individual VMs. Enabling or disabling ECC memory in a VM does not affect the amount of frame buffer that is usable by vGPUs.\n\nGPUs based on the Pascal GPU architecture and later GPU architectures support ECC memory with NVIDIA vGPU. To determine whether ECC memory is enabled for a GPU, run nvidia-smi -q for the GPU.\n\nTesla M60 and M6 GPUs support ECC memory when used without GPU virtualization, but NVIDIA vGPU does not support ECC memory with these GPUs. In graphics mode, these GPUs are supplied with ECC memory disabled by default.\n\nSome hypervisor software versions do not support ECC memory with NVIDIA vGPU.\n\nIf you are using a hypervisor software version or GPU that does not support ECC memory with NVIDIA vGPU and ECC memory is enabled, NVIDIA vGPU fails to start. In this situation, you must ensure that ECC memory is disabled on all GPUs if you are using NVIDIA vGPU.\n\n2.13.1. Disabling ECC Memory\n\nIf ECC memory is unsuitable for your workloads but is enabled on your GPUs, disable it. You must also ensure that ECC memory is disabled on all GPUs if you are using NVIDIA vGPU with a hypervisor software version or a GPU that does not support ECC memory with NVIDIA vGPU. If your hypervisor software version or GPU does not support ECC memory and ECC memory is enabled, NVIDIA vGPU fails to start.\n\nWhere to perform this task depends on whether you are changing ECC memory settings for a physical GPU or a vGPU.\n\nFor a physical GPU, perform this task from the hypervisor host.\n\nFor a vGPU, perform this task from the VM to which the vGPU is assigned.\n\nNote:\n\nECC memory must be enabled on the physical GPU on which the vGPUs reside.\n\nBefore you begin, ensure that NVIDIA Virtual GPU Manager is installed on your hypervisor. If you are changing ECC memory settings for a vGPU, also ensure that the NVIDIA AI Enterprise graphics driver is installed in the VM to which the vGPU is assigned.\n\nUse nvidia-smi to list the status of all physical GPUs or vGPUs, and check for ECC noted as enabled.\n\nChange the ECC status to off for each GPU for which ECC is enabled.\n\nIf you want to change the ECC status to off for all GPUs on your host machine or vGPUs assigned to the VM, run this command:\n\nCopy\n\nCopied!\n\n# nvidia-smi -e 0\n\nIf you want to change the ECC status to off for a specific GPU or vGPU, run this command:\n\nid is the index of the GPU or vGPU as reported by nvidia-smi.\n\nThis example disables ECC for the GPU with index 0000:02:00.0.\n\nReboot the host or restart the VM.\n\nConfirm that ECC is now disabled for the GPU or vGPU.\n\nIf you later need to enable ECC on your GPUs or vGPUs, follow the instructions in Enabling ECC Memory.\n\n2.13.2. Enabling ECC Memory\n\nIf ECC memory is suitable for your workloads and is supported by your hypervisor software and GPUs, but is disabled on your GPUs or vGPUs, enable it.\n\nWhere to perform this task depends on whether you are changing ECC memory settings for a physical GPU or a vGPU.\n\nFor a physical GPU, perform this task from the hypervisor host.\n\nFor a vGPU, perform this task from the VM to which the vGPU is assigned.\n\nNote:\n\nECC memory must be enabled on the physical GPU on which the vGPUs reside.\n\nBefore you begin, ensure that NVIDIA Virtual GPU Manager is installed on your hypervisor. If you are changing ECC memory settings for a vGPU, also ensure that the NVIDIA AI Enterprise graphics driver is installed in the VM to which the vGPU is assigned.\n\nUse nvidia-smi to list the status of all physical GPUs or vGPUs, and check for ECC noted as disabled.\n\nChange the ECC status to on for each GPU or vGPU for which ECC is enabled.\n\nIf you want to change the ECC status to on for all GPUs on your host machine or vGPUs assigned to the VM, run this command:\n\nCopy\n\nCopied!\n\n# nvidia-smi -e 1\n\nIf you want to change the ECC status to on for a specific GPU or vGPU, run this command:\n\nid is the index of the GPU or vGPU as reported by nvidia-smi.\n\nThis example enables ECC for the GPU with index 0000:02:00.0.\n\nReboot the host or restart the VM.\n\nConfirm that ECC is now enabled for the GPU or vGPU.\n\nIf you later need to disable ECC on your GPUs or vGPUs, follow the instructions in Disabling ECC Memory.\n\n2.14. Configuring a vGPU VM for Use with NVIDIA GPUDirect Storage Technology\n\nTo use NVIDIA® GPUDirect Storage® technology with NVIDIA vGPU, you must install all the required software in the VM that is configured with NVIDIA vGPU.\n\nEnsure that the prerequisites in Prerequisites for Using NVIDIA AI Enterprise are met.\n\nInstall and configure the NVIDIA Virtual GPU Manager as explained in Installing and Configuring the NVIDIA Virtual GPU Manager for Red Hat Enterprise Linux KVM.\n\nAs root, log in to the VM that you configured with NVIDIA vGPU in the previous step.\n\nInstall the Mellanox OpenFabrics Enterprise Distribution for Linux (MLNX_OFED) in the VM as explained in Installation Procedure in Installing Mellanox OFED.\n\nIn the command to run the installation script, specify the following options:\n\n--with-nvmf\n\n--with-nfsrdma\n\n--enable-gds\n\n--add-kernel-support\n\nInstall the NVIDIA AI Enterprise graphics driver for Linux in the VM from a distribution-specific package.\n\nNote:\n\nGPUDirect Storage technology does not support installation of the NVIDIA AI Enterprise graphics driver for Linux from a .run file.\n\nFollow the instructions for the Linux distribution that is installed in the VM:\n\nInstalling the NVIDIA AI Enterprise Graphics Driver on Ubuntu from a Debian Package\n\nInstalling the NVIDIA AI Enterprise Graphics Driver on Red Hat Distributions from an RPM Package\n\nInstall NVIDIA CUDA Toolkit from a .run file, deselecting the CUDA driver when selecting the CUDA components to install.\n\nNote:\n\nTo avoid overwriting the NVIDIA AI Enterprise graphics driver that you installed in the previous step, do not install NVIDIA CUDA Toolkit from a distribution-specific package.\n\nFor instructions, refer to Runfile Installation in NVIDIA CUDA Installation Guide for Linux.\n\nUse the package manager of the Linux distribution that is installed in the VM to install the GPUDirect Storage technology packages, omitting the installation of the NVIDIA CUDA Toolkit packages.\n\nFollow the instructions in NVIDIA CUDA Installation Guide for Linux for the Linux distribution that is installed in the VM:\n\nRHEL 8/Rocky 8\n\nIn the step to install CUDA, execute only the command to include all GPUDirect Storage technology packages:\n\nCopy\n\nCopied!\n\nsudo dnf install nvidia-gds\n\nUbuntu In the step to install CUDA, execute only the command to include all GPUDirect Storage technology packages:\n\nCopy\n\nCopied!\n\nsudo apt-get install nvidia-gds\n\nAfter you configure a vGPU VM for use with NVIDIA GPUDirect Storage technology, you can license the NVIDIA AI Enterprise licensed products that you are using. For instructions, refer to NVIDIA AI Enterprise Client Licensing User Guide.\n\n3.1. Installing NVIDIA AI Enterprise Software Components by Using Kubernetes\n\nPerform this task if you are using one of the following combinations of guest operating system and container platform:\n\nUbuntu with Kubernetes\n\nEnsure that the following prerequisites are met:\n\nIf you are using Kubernetes, ensure that:\n\nKubernetes is installed in the VM.\n\nNVIDIA vGPU Manager is installed.\n\nNVIDIA vGPU License Server with licenses is installed.\n\nHelm is installed.\n\nYou have generated your NGC API key for accessing the NVIDIA Enterprise Collection at the URL provided to you by NVIDIA.\n\n3.1.1. Installing and Licensing the NVIDIA vGPU Software Graphics Driver by Using NVIDIA GPU Operator\n\nInstallation of the NVIDIA AI Enterprise GPU Operator is documented at:\n\nhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html#nvidia-ai-enterprise\n\n3.1.2. Transforming Container Images for AI and Data Science Applications and Frameworks into Kubernetes Pods\n\nThe AI and data science applications and frameworks are distributed as NGC container images through the NGC private registry. If you are using Kubernetes or Red Hat OpenShift, you must transform each image that you want to use into a Kubernetes pod. Each container image contains the entire user-space software stack that is required to run the application or framework, namely, the CUDA libraries, cuDNN, any required Magnum IO components, TensorRT, and the framework.\n\n3.2. Install NVIDIA AI Enterprise Software Components by Using Docker\n\nPerform this task if you are using Ubuntu with Docker.\n\n3.2.1. Installing and Licensing the NVIDIA AI Enterprise Graphics Driver Natively\n\nPerform this task in the guest VM by following this sequence of instructions:\n\nInstalling the NVIDIA AI Enterprise Graphics Driver on Linux\n\nConfiguring a Licensed Client of NVIDIA License System\n\nInstalling NVIDIA Container Toolkit\n\n3.2.2. Installing NVIDIA AI Enterprise Software, Applications, and Deep Learning Framework Components by Using Docker\n\nNVIDIA AI Enterprise software components in the infrastructure optimization and cloud native deployment layers are distributed through the NVIDIA AI Enterprise Infra Release 5 collection on NVIDIA NGC. Applications and deep learning framework components for NVIDIA AI Enterprise are distributed exclusively through the NGC Public Catalog.\n\nThe container image for each application or framework contains the entire user-space software stack that is required to run the application or framework, namely, the CUDA libraries, cuDNN, any required Magnum IO components, TensorRT, and the framework.\n\nEnsure that you have completed the following tasks in NGC Private Registry User Guide:\n\nGenerating Your NGC API Key\n\nAccessing the NGC Container Registry\n\nPerform this task from the VM.\n\nObtain the Docker pull command for downloading each of the following applications and deep learning framework components from the listing for the application or component in the NGC Public Catalog.\n\nApplications:\n\nNVIDIA Clara Parabricks\n\nNVIDIA DeepStream\n\nNVIDIA Riva\n\nMONAI - Medical Open Network for Artificial Intelligence\n\nRAPIDS\n\nRAPIDS Accelerator for Apache Spark\n\nTAO\n\nDeep learning framework components:\n\nNVIDIA TensorRT\n\nNVIDIA Triton Inference Server\n\nPyTorch\n\nTensorFlow 2\n\nObtain the command for downloading each of the following NVIDIA AI Enterprise software components from the listing for the component in the NVIDIA AI Enterprise Infra Release 5 collection on NVIDIA NGC.\n\nGPU Operator\n\nNetwork Operator\n\nNVIDIA Base Command Manager Essentials\n\nvGPU Guest Driver, Ubuntu 22.04\n\n3.3. Installing NVIDIA GPU Operator by Using a Bash Shell Script\n\nA bash shell script for installing NVIDIA GPU Operator with the NVIDIA vGPU guest driver is available for download from NVIDIA NGC.\n\nBefore performing this task, ensure that the following prerequisites are met:\n\nA client configuration token has been generated for the client on which the script will install the vGPU guest driver.\n\nThe API key of the NVIDIA NGC user to be used for creating the image pull secret has been generated.\n\nThe following environment variables are set:\n\nNGC_API_KEY\n\nThe API key of the NVIDIA NGC user to be used for creating the image pull secret For example:\n\nCopy\n\nCopied!\n\nexport NGC_API_KEY=\"RLh1zerCiG4wPGWWt4Tyj2VMyd7T8MnDyCT95pygP5VJFv8en4eLvdXVZzjm\"\n\nNGC_USER_EMAIL\n\nThe email address of the NVIDIA NGC user to be used for creating the image pull secret For example:\n\nCopy\n\nCopied!\n\nexport NGC_USER_EMAIL=\"ada.lovelace@example.com\"\n\nDownload the NVIDIA GPU Operator - Deploy Installer Script from NVIDIA NGC.\n\nEnsure that the file access modes of the script allow the owner to execute the script.\n\nChange to the directory that contains the script.\n\nCopy\n\nCopied!\n\n# cd script-directory\n\nscript-directory\n\nThe directory to which you downloaded the script in the previous step.\n\nDetermine the current file access modes of the script.\n\nCopy\n\nCopied!\n\n# ls -l gpu-operator-nvaie.sh\n\nIf necessary, grant execute permission to the owner of the script.\n\nCopy\n\nCopied!\n\n# chmod u+x gpu-operator-nvaie.sh\n\nCopy the client configuration token to the directory that contains the script.\n\nRename the client configuration token to client_configuration_token.tok. The client configuration token is generated with a file name that includes a time stamp, namely: client_configuration_token_mm-dd-yyyy-hh-mm-ss.tok.\n\nFrom the directory that contains the script, start the script, specifying the option to install the NVIDIA vGPU guest driver.\n\nCopy\n\nCopied!\n\n# bash gpu-operator-nvaie.sh install\n\n3.4. Installing and Licensing NVIDIA AI Enterprise Components Natively\n\n3.4.1. Installing the NVIDIA AI Enterprise Graphics Driver on Windows\n\nAfter you create a Windows VM on the hypervisor and boot the VM, the VM should boot to a standard Windows desktop in VGA mode at 800×600 resolution. You can use the Windows screen resolution control panel to increase the resolution to other standard resolutions, but to fully enable GPU operation, the NVIDIA AI Enterprise graphics driver must be installed. Windows guest VMs are supported on all NVIDIA vGPU types, namely: Q-series, C-series, B-series, and A-series NVIDIA vGPU types.\n\nCopy the NVIDIA Windows driver package to the guest VM where you are installing the driver.\n\nExecute the package to unpack and run the driver installer.\n\nFigure 13. NVIDIA driver installation\n\nClick through the license agreement.\n\nSelect Express Installation and click NEXT. After the driver installation is complete, the installer may prompt you to restart the platform.\n\nIf prompted to restart the platform, do one of the following:\n\nSelect Restart Now to reboot the VM.\n\nExit the installer and reboot the VM when you are ready.\n\nAfter the VM restarts, it boots to a Windows desktop.\n\nVerify that the NVIDIA driver is running.\n\nRight-click on the desktop.\n\nFrom the menu that opens, choose NVIDIA Control Panel.\n\nIn the NVIDIA Control Panel, from the Help menu, choose System Information.\n\nNVIDIA Control Panel reports the vGPU or physical GPU that is being used, its capabilities, and the NVIDIA driver version that is loaded.\n\nFigure 14. Verifying NVIDIA driver operation using NVIDIA Control Panel\n\nAfter you install the NVIDIA AI Enterprise graphics driver, you can license any NVIDIA AI Enterprise licensed products that you are using. For instructions, refer to NVIDIA AI Enterprise Client Licensing User Guide.\n\nNote:\n\nThe graphics driver for Windows in this release of NVIDIA AI Enterprise is distributed in a DCH-compliant package. A DCH-compliant package differs from a driver package that is not DCH compliant in the following ways:\n\nThe Windows registry key for license settings for a DCH-compliant package is different than the key for a driver package that is not DCH compliant. If you are upgrading from a driver package that is not DCH compliant in a VM that was previously licensed, you must reconfigure the license settings for the VM. Existing license settings are not propagated to the new Windows registry key for a DCH-compliant package.\n\nNVIDIA System Management Interface, nvidia-smi, is installed in a folder that is in the default executable path.\n\nThe NVWMI binary files are installed in the Windows Driver Store under %SystemDrive%:\\Windows\\System32\\DriverStore\\FileRepository\\.\n\nNVWMI help information in Windows Help format is not installed with graphics driver for Windows guest OSes.\n\n3.4.2. Installing the NVIDIA AI Enterprise Graphics Driver on Linux\n\nThe NVIDIA AI Enterprise graphics driver for Linux is distributed as a Debian package for Ubuntu distributions and as an RPM package for Red Hat distributions. The procedure for installing the driver is the same in a VM and on bare metal.\n\nIf you are using a Linux OS for which the Wayland display server protocol is enabled by default, disable it as explained in Disabling the Wayland Display Server Protocol for Red Hat Enterprise Linux.\n\nHow to install the NVIDIA AI Enterprisegraphics driver on Linux depends on the distribution format from which you are installing the driver. For detailed instructions, refer to:\n\nInstalling the NVIDIA AI Enterprise Graphics Driver on Ubuntu from a Debian Package\n\nInstalling the NVIDIA AI Enterprise Graphics Driver on Red Hat Distributions from an RPM Package\n\n3.4.2.1. Installing the NVIDIA AI Enterprise Graphics Driver on Ubuntu from a Debian Package\n\nThe NVIDIA AI Enterprise graphics driver for Ubuntu is distributed as a Debian package file.\n\nThis task requires sudo privileges.\n\nCopy the NVIDIA AI Enterprise Linux driver package, for example nvidia-linux-grid-550_550.90.07_amd64.deb, to the guest VM where you are installing the driver.\n\nLog in to the guest VM as a user with sudo privileges.\n\nOpen a command shell and change to the directory that contains the NVIDIA AI Enterprise Linux driver package.\n\nFrom the command shell, run the command to install the package.\n\nCopy\n\nCopied!\n\n$ sudo apt-get install ./nvidia-linux-grid-550_550.90.07_amd64.deb\n\nVerify that the NVIDIA driver is operational.\n\nReboot the system and log in.\n\nAfter the system has rebooted, confirm that you can see your NVIDIA vGPU device in the output from the nvidia-smi command.\n\nCopy\n\nCopied!\n\n$ nvidia-smi\n\n3.4.2.2. Installing the NVIDIA AI Enterprise Graphics Driver on Red Hat Distributions from an RPM Package\n\nThe NVIDIA AI Enterprise graphics driver for Red Hat Distributions is distributed as an RPM package file.\n\nThis task requires root user privileges.\n\nCopy the NVIDIA AI Enterprise Linux driver package, for example nvidia-linux-grid-550.90.07_amd64.rpm, to the guest VM where you are installing the driver.\n\nLog in to the guest VM as a user with root user privileges.\n\nOpen a command shell and change to the directory that contains the NVIDIA AI Enterprise Linux driver package.\n\nFrom the command shell, run the command to install the package.\n\nCopy\n\nCopied!\n\n$ rpm -iv ./nvidia-linux-grid-550.90.07_amd64.rpm\n\nVerify that the NVIDIA driver is operational.\n\nReboot the system and log in.\n\nAfter the system has rebooted, confirm that you can see your NVIDIA vGPU device in the output from the nvidia-smi command.\n\nCopy\n\nCopied!\n\n$ nvidia-smi\n\n3.4.2.3. Disabling the Nouveau Driver for NVIDIA Graphics Cards\n\nIf the Nouveau driver for NVIDIA graphics cards is present, disable it before installing the NVIDIA AI Enterprise graphics driver.\n\nNote:\n\nIf you are using SUSE Linux Enterprise Server, you can skip this task because the Nouveau driver is not present in SUSE Linux Enterprise Server.\n\nRun the following command and if the command prints any output, the Nouveau driver is present and must be disabled.\n\nCopy\n\nCopied!\n\n$ lsmod | grep nouveau\n\nCreate the file /etc/modprobe.d/blacklist-nouveau.conf with the following contents:\n\nCopy\n\nCopied!\n\nblacklist nouveau options nouveau modeset=0\n\nRegenerate the kernel initial RAM file system (initramfs). The command to run to regenerate the kernel initramfs depends on the Linux distribution that you are using.\n\nLinux Distribution Command CentOS\n\nCopy\n\nCopied!\n\n$ sudo dracut --force\n\nDebian\n\nCopy\n\nCopied!\n\n$ sudo update-initramfs -u\n\nRed Hat Enterprise Linux\n\nCopy\n\nCopied!\n\n$ sudo dracut --force\n\nUbuntu\n\nCopy\n\nCopied!\n\n$ sudo update-initramfs -u\n\nReboot the host or guest VM.\n\n3.4.2.4. Disabling the Wayland Display Server Protocol for Red Hat Enterprise Linux\n\nStarting with Red Hat Enterprise Linux Desktop 8.0, the Wayland display server protocol is used by default on supported GPU and graphics driver configurations. However, the NVIDIA AI Enterprise graphics driver for Linux requires the X Window System. Before installing the driver, you must disable the Wayland display server protocol to revert to the X Window System.\n\nPerform this task from the host or guest VM that is running Red Hat Enterprise Linux Desktop.\n\nThis task requires administrative access.\n\nIn a plain text editor, edit the file /etc/gdm/custom.conf and remove the comment from the option WaylandEnable=false.\n\nSave your changes to /etc/gdm/custom.conf.\n\nReboot the host or guest VM.\n\n3.4.3. Configuring a Licensed Client of NVIDIA License System\n\nA client with a network connection obtains a license by leasing it from a NVIDIA License System service instance. The service instance serves the license to the client over the network from a pool of floating licenses obtained from the NVIDIA Licensing Portal. The license is returned to the service instance when the licensed client no longer requires the license.\n\nBefore configuring a licensed client, ensure that the following prerequisites are met:\n\nThe NVIDIA AI Enterprise graphics driver is installed on the client.\n\nThe client configuration token that you want to deploy on the client has been created from the NVIDIA Licensing Portal or the DLS as explained in NVIDIA License System User Guide.\n\nPorts 443 and 80 in your firewall or proxy must be open to allow HTTPS traffic between a service instance and its the licensed clients. These ports must be open for both CLS instances and DLS instances.\n\nNote:\n\nFor DLS releases before DL"
    }
}