{
    "id": "dbpedia_4516_3",
    "rank": 74,
    "data": {
        "url": "https://cvpr.thecvf.com/virtual/2024/poster/30563",
        "read_more_link": "",
        "language": "en",
        "title": "CVPR Poster The Devil is in the Details: StyleFeatureEditor for Detail",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://cvpr.thecvf.com/static/core/img/cvpr-navbar-logo.svg",
            "https://cvpr.thecvf.com/static/core/img/CVPR-logo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Denis Bobkov",
            "Vadim Titov",
            "Aibek Alanov",
            "Dmitry Vetrov"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": "https://cvpr.thecvf.com/virtual/2024/poster/30563",
        "text": "Abstract:\n\nThe task of manipulating real image attributes through StyleGAN inversion has been extensively researched. This process involves searching latent variables from a well-trained StyleGAN generator that can synthesize a real image, modifying these latent variables, and then synthesizing an image with the desired edits. A balance must be struck between the quality of the reconstruction and the ability to edit. Earlier studies utilized the low-dimensional W-space for latent search, which facilitated effective editing but struggled with reconstructing intricate details. More recent research has turned to the high-dimensional feature space F, which successfully inverses the input image but loses much of the detail during editing. In this paper, we introduce StyleFeatureEditor -- a novel method that enables editing in both w-latents and F-latents. This technique not only allows for the reconstruction of finer image details but also ensures their preservation during editing. We also present a new training pipeline specifically designed to train our model to accurately edit F-latents. Our method is compared with state-of-the-art encoding approaches, demonstrating that our model excels in terms of reconstruction quality and is capable of editing even challenging out-of-domain examples."
    }
}