{
    "id": "dbpedia_3264_0",
    "rank": 81,
    "data": {
        "url": "https://marcel-jan.eu/datablog/page/3/",
        "read_more_link": "",
        "language": "en",
        "title": "My journey to learn all things data engineering (and that's a lot)",
        "top_image": "https://marcel-jan.eu/datablog/wp-content/uploads/2022/01/IMG_2688-1024x769.jpg",
        "meta_img": "",
        "images": [
            "https://marcel-jan.eu/datablog/wp-content/uploads/2022/08/cropped-IMG_4759a2.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2022/01/IMG_2688-1024x769.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/12/MJK33535-1024x683.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/12/MJK33828-1024x683.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/12/IMG_3619-1024x768.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/12/IMG_3498-1024x768.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2022/01/IMG_3300-1024x768.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/11/bikrash_screenshot-1024x704.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/10/docker_superset_app_browser.png",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/10/examples_db_edit-1024x128.png",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/10/superset_more_dataset_options.png",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/10/superset_date_column_text-1024x331.png",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/10/superset_date_column_datetime-1024x334.png",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/10/Superset-My-Workout-Insights-Dashboard-1-1024x480.png",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/10/rickrolling-iptv.jpg",
            "https://marcel-jan.eu/datablog/wp-content/uploads/2021/10/image_10164-Gallium-CO2-Conversion.jpg",
            "https://live.staticflickr.com/65535/51483403123_93d9a5eb37_z.jpg"
        ],
        "movies": [
            "https://www.youtube.com/embed/faPvsOF3Efo?feature=oembed"
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "So at the end of 2021 I found myself in the waiting room of an emergency dentist. An infection above my front teeth became unbearable. Fortunately antibiotics makes my live much better now. Let that event not colour my view on 2021.\n\nFor me 2021 was a great year, despite the pandemic, lockdowns and those damned curfews. Luckily 2021 eventually also had vaccinations.\n\nAnd what a difference a year makes. Last year I was frantically working on the last modules of the Certified Data Engineering Professional course. This year I have time for whimsical things like watching a movie (on tv) or playing a computer game.\n\nWork\n\nI’ve learned so much by writing and teaching modules for this course. You want to learn stuff really, really fast? Teaching it is probably the best way to go. Also creating a course you can repeat is a great investment in the future. For every day I teach I have to spend time to prepare of course, but the greatest investment is happily behind me.\n\nI also managed to get an assignment at a Dutch financial company as a data engineer working with Hadoop, NiFi and other stuff. This is the first kind of data engineering assignment as I envisioned it back when I started changing from Oracle database expert to data engineering. The latest development is that I’m getting more and more into the practical aspects of data management.\n\nAlso got my Azure Fundamentals certification, but that will be just the start of my Azure certifications.\n\nGithub\n\nI never saw myself as a contributor of open source software. I wanted it to be, but I thought most of these are written by people who fluently write Java or Python. But then I created a docker-compose for a Hadoop environment for our data engineering course. And I decided to put it on GitHub. And to my surprise this repo has 38 stars now. Turns out there are other people who would like to run Hadoop with Spark and Hive on their own laptop.\n\nSo now I’m suddenly a maintainer of a repo. Halfway through the year Docker decided to harden their software (which is good). And whoops: suddenly some of the containers couldn’t communicate propery with each other. It took me a while before I found out what happened. What changed was that Docker Desktop no longer exposes the daemon without TLS. When you do expose it, everything works again. I need to find a better solution for that BTW.\n\nVacations\n\nIn August I went cycling in France in the Vercors and Drome and that was very nice. This area of France has some beautiful rides, hewn out of rock, like the Col de la Machine. The climbs are usually less steep than the onces I’ve encountered in other years in the Alpes. Except the Col de Noyer BTW.\n\nThen in October I decided to go to Paris for a week. I’ve been in Paris before, about 30 years ago. On sort of a 24 hour race through the city to see all the sights. As you do when you’re a student. I remember running through the Louvre with my brother just to see the Mona Lisa and then run out to see the next thing (didn’t matter, because the ticket was free).\n\nThis time I took my time to see all the sights. I went in all the famous museums: Musee d’ Orsay, the Louvre, Centre Pompidou and really took time to soak it all in. I went through the Louvre bottom to top. Amazing. I didn’t know the Venus de Milo is also there. The Nike of Samothrace was also stunning. A different museum I visited was the Musee des Arts et Metiers, which has a particle collider from the 1930s and a steampunk diving suit from the 1880s.\n\nThe modern art in the Centre Pompidou is just fantastic. I’m not exactly a modern art connaisseur. I didn’t expect the joy of seeing this collection. I learned to love artists I never knew, like Frantisek Kupka and Suzanne Valadon. (Surprised there are hardly any books on Kupka, except in French).\n\nI had the most fun in years. The food was great. And I got to see the Arc de Triomphe, Wrapped by Cristo (only for 3 weeks). It was a stunning sight.\n\nIf I have any resolutions for 2022, it’s to do another city trip like this. Preferably by train. Maybe Barcelona.\n\nCycling\n\nI set myself a goal to ride 10,000 kms this year. I knew I could do it. In 2020 I reached 8754 kms. And already halfway in October I managed to pass 10,000 kms. And just on the last day of the year I reached the stretch goal of 12,000 km.\n\nBTW I have no plans for even larger goals in 2022. There’s no need to overdo it. Cycling takes time. Riding 12,000 kms took 436 hours. I need to leave time to do other things.\n\nBut I do keep looking out for new rides. This year my favorite discoveries were the Kromme Mijdrecht, a river south of Amsterdam. You can follow it along a road next to the river in both ways.\n\nI also found my ride along the coast between Noordwijk and Katwijk is wonderful. This is a ride with a view on the North Sea for several kms. I need to ride about 110 kms in total to experience it, but in summer, when the days are long this is quite achievable. Also a ride I did with my brother in Noord-Brabant was a good one.\n\nThis year I rode the Gran Fondo Rosa and the Vael Ouwe. Both beautiful but long rides (although the Gran Fondo Rosa was very, very wet), both about 160 kms long. Which was a new record for me for kms on one day. Actually the Gran Fondo Rosa ended up being 170 kms because I couldn’t find the car park.\n\n(Oh and almost forgot: in Februari it froze long enough that I was able to go ice skating. Which was the first time in many years. Even went round on one of the lakes near Reeuwijk. Great experience.)\n\nAstronomy and space\n\nThis is my hobby that gets less and less time. Observing already suffered for several years. It’s especially hard to combine with the amount of cycling I did. After several hours of training your natural tendency is to go to bed early. And not stay up late to watch the skies.\n\nBut I was happy to observe the noctilucent clouds in June. And the passage of ISS and the new Nauka module (and its 3rd rocket stage).\n\nI used to do a lot more writing about the solar system (in Dutch), but the work on the course and the hours of cycling pushed that to the side. I did enjoy the landing of the Perseverance rover and the recent launch of the James Webb Space Telescope. Not to mention the bellyflops of the several Starship tests. Those were amazing. We’ll have to wait a couple of months for the first images of JWST, but that’s going to be game changing.\n\nWriting\n\nI’ve not done as much writing as I would like to, but my blogpost about critical thinking is one that was kind of influential in my personal life. It is about how I got advise from a homeopath to stop taking one of my prescribed medicine with bad results. I never wrote about something so personal, but in the end it worked out well.\n\nStage acting\n\nThis is the only thing that never got of the ground after the earlier lockdowns. I got together with my stage acting group only once in the pub. We made plans and then the new peak of COVID-19 happened.\n\nCooking\n\nI never order meals at home. I just keep cooking myself. And the freezer is usually well stocked with extra portions for other days. One of my favorite new recipes was bibimbap, a Korean dish.\n\nRecently I invited two friends of mine who I hadn’t seen in a while, for a meal at my house. But again COVID-19 infections peaked, so we saw another lockdown. And my friends understandably were rather safe than sorry. So I changed the plan. They live nearby, so I decided to cook Thai curry (there’s a recipe I’ve grown to like) and delivered it to their home with rice, beer and krupuk (sort of Indonesian deep fried crackers you get at a lot of Indonesian and Chinese meals in the Netherlands). We ate it both at our home and then discussed via Zoom. Despite the limitations these Zoom calls gives us, it all it turned out to be a very fun evening. I hope to do this more often.\n\n2022\n\nI don’t do new years resolutions. I have some ideas. They might pan out or not. I kept my Strava year goal on 10,000 km cycling. That is more than enough to stay healthy. Azure certifications will be a thing and I’m thinking of short new courses for DIKW. We’ll see.\n\nBest of whishes for 2022. Let’s make it a good one.\n\nOh, and of course you will be able to buy the NFT of this blogpost as soon as I know how to do that.\n\nFor a few years I’ve been gathering data on my workouts. In Excel. It’s not exactly state of the art data architecture, but it was fine for a while. But data alone doesn’t do much. I wanted some questions answered.\n\nLately I’ve been hearing a lot about Apache Superset. (Well, I’ve been hearing lately about lots of products actually. It’s hard to choose one product to spend a lot of time on.) Apache Superset is open source data visualization software. I decided to give it a try for this particular problem.\n\nThe video\n\nApart from the installation I demo most things in this video:\n\nStarting on your laptop\n\nIf there’s anything I’ve learned recently working with Docker Desktop, it’s that it is often very easy to get a working environment of most open source data products in one or more Docker containers. Usually they have an image or docker-compose on their site somewhere to get you started. Same for Superset.\n\nAll you need to get started is Git and Docker Desktop (available for Windows, Mac and Linux). I use Git for Windows. To build your Dockerized Superset environment, just follow the instructions on the Superset documentation site:\n\nhttps://superset.apache.org/docs/installation/installing-superset-using-docker-compose\n\nThis will start 6 Docker containers. One of them (named superset_db) runs a PostgreSQL 10 database, which contains the sample data, but also can be used to upload your CSV data. Another, superset_init, will only be used for installation and won’t run anymore after that. That is fine.\n\nAfter the installation is done, go to http://localhost:8088/login/ or, in Docker Desktop, click here:\n\nYou can log in here with username admin, password admin. Now the Superset welcome screen will show. You can have a look at the example charts and dashboards.\n\nUploading my own dataset\n\nSuperset allows you to upload a CSV file. It will do this in the example (PostgreSQL) database. But first you need to edit the settings of the example database to allow uploads. Go to Data, Databases and click on edit:\n\nGo to Advanced, Security and check Allow data upload. All this is explained in above video.\n\nHow to get a proper datetime column\n\nI also explain also all the settings you can do to upload the CSV file. But there was a problem. PostgreSQL didn’t recognise the date and time format. Despite the “Infer Datetime Format” setting I had enabled.\n\nAn example of my date and time data was this: 2021-10-21 17:52:00\n\nBecause PostgreSQL didn’t recognise this as a datetime, Superset didn’t allow more advanced time-related features. For example, when I used a Time-series Bar Chart v2 or Time-series Area Chart v2, and I chose a Time Grain: week or year, it would come up with an “Unexpected error”:\n\nError: function date_trunc(unknown, text) does not exist LINE 1: SELECT DATE_TRUNC('year', \"Datum\") AS __timestamp, ^ HINT: No function matches the given name and argument types. You might need to add explicit type casts.\n\nTo see the problem, go to your dataset, More dataset options and Edit dataset:\n\nIn my case my Datum column was of the type “TEXT”, not “DATETIME”. It doesn’t matter that I chose this to be temporal data. You will run into this Unexpected error.\n\nThis is more of a PostgreSQL problem. To solve it, let’s go into the superset_db container and change this datatype.\n\nYou need to solve this on the command prompt. In Windows I’ve used Powershell for this.\n\nLog in in the superset_db container with this command:\n\ndocker exec -it superset_db bash\n\nConnect to the PostgreSQL database:\n\npsql -h 127.0.0.1 -p 5432 -U superset\n\nCheck if you can access your table from here. In my case the table was called Workouts2. Because the name is case sensitive, I had to use double quotes around the name.\n\nselect * from \"Workouts2\";\n\nThis is how you change the data type of your date column. In my case it was called “Datum”. Here I create a temporary column called temp_date with the DATETIME data type. I then load the data from the “Datum” column:\n\nALTER TABLE \"Workouts2\" ADD COLUMN temp_date TIMESTAMP without time zone NULL; UPDATE \"Workouts2\" SET temp_date = \"Datum\"::TIMESTAMP; ALTER TABLE \"Workouts2\" ALTER COLUMN \"Datum\" TYPE TIMESTAMP without time zone USING temp_date; ALTER TABLE \"Workouts2\" DROP COLUMN temp_date;\n\nAfter this small operation, you will have the same old “Datum” column, but now with the DATETIME data type. And Superset will notice this too:\n\nNow you can really start using the fun time related features in Superset, which I demoed in the video.\n\nMy Superset experience\n\nOnce I had my datetime column set up, things really took off. Superset became really fun to use. I really was able to gain insights quickly. Superset is indeed very powerful. If possible I certainly will use it in the future.\n\nFurure work\n\nMy Superset dashboard looks awesome, but for every update to my Excel sheet, I need to upload it in Superset. That is not something I’m looking forward doing in the future.\n\nIn fact, I don’t like to enter my health data in Excel at all. Here is how I would like my data architecture to look like:\n\nI want an app on my iPad or iPhone to enter my weight data. (Now I use Evernote and copy that to Excel). The app uploads this data directly in a central database in my home. Possibly on a Raspberry Pi.\n\nI have a pipeline that retrieves new workout data from Strava and Polar and enters this data in my central database.\n\nOn this central database I run Superset, where my dashboard is always up to date.\n\nThis will require quite some work and time. I have no idea how to create an app that works on my iPad or iPhone. I hope it can be done in Python, but even creating an app in Python is new ground for me.\n\nIf I can create this, I will share it on this blog. But don’t hold your breath just now."
    }
}