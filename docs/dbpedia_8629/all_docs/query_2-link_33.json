{
    "id": "dbpedia_8629_2",
    "rank": 33,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809699/",
        "read_more_link": "",
        "language": "en",
        "title": "An acoustic analysis of laughter produced by congenitally deaf and normally hearing college students",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-jas.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809699/bin/JASMAN-000124-000472_1-g001.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809699/bin/JASMAN-000124-000472_1-g002.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809699/bin/JASMAN-000124-000472_1-g003.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809699/bin/JASMAN-000124-000472_1-g004.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Maja M. Makagon",
            "E. Sumie Funayama",
            "Michael J. Owren"
        ],
        "publish_date": "2008-07-19T00:00:00",
        "summary": "",
        "meta_description": "Relatively few empirical data are available concerning the role of auditory experience in nonverbal human vocal behavior, such as laughter production. This study compared the acoustic properties of laughter in 19 congenitally, bilaterally, and profoundly ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809699/",
        "text": "Laugh selection and acoustic analysis\n\nFollowing Bachorowski et al. (2001), laughter was defined relatively inclusively as being any perceptible vocal event that an ordinary person would characterize as a laugh sound. Two research assistants extracted laughter from the recordings, in each case comparing recording quality on the left and right channels and selecting the better of the two. Analysis was subsequently restricted to sounds that both assistants identified as laughter. Segments containing vocalizations that directly preceded, directly followed, or overlapped a laughter bout were excluded, as speech has been shown to alter the acoustic properties of laughter (Nwokah et al., 1999).\n\nAgain following Bachorowski et al. (2001), each laughter file was labeled at the bout and burst levels based on spectrographic representations (illustrated in Fig. ). A bout was defined as one entire laughter episode, and a burst as a discrete sound (note, syllable, or call) occurring within that episode. Onset and offset times for bouts and bursts were marked with cursor-based labels by one of the two research assistants. Each burst was then labeled as being produced with an “open,” “closed,” or “mixed” mouth position, with either egressive or ingressive air flow. These determinations were made acoustically, for example, based on the presence or absence of the audible characteristics of nostril air flow for closed-mouth unvoiced sounds and the muffled quality associated with closed-mouth voiced sounds (also following Bachorowski et al., 2001). The mixed-mouth designation was used for bursts in which the laugher alternated between open and closed mouth positions. Sounds that could be produced through either open or closed mouth positions were considered ambiguous and were not assigned labels for this analysis.\n\nAll duration and classification labels were reviewed before conducting further analyses. We performed further reliability checks approximately 24 months after the first classification based on blind relabeling of a randomly selected sample of 10% of the analyzed bouts (as in Bachorowski et al., 2001). Correlating outcomes for duration (reflecting placement of onset and offset labels) showed this measure to be highly reliable (Pearson’s r=0.999). Percent agreement (88%) and high reliability (Cohen’s kappa, calculated in SAS) was also found for mouth position (κ=0.69). Agreement in labeling air flow direction was lower (64.6%), and reliability was requisitely more modest (κ=0.42).\n\nAudio files were downsampled to 11.025 kHz prior to making acoustic measurements. Custom-written scripts operating based on onset and offset labels were used to automatically or semiautomatically extract bout durations, interburst durations, “raw” amplitudes, as well as F0- and formant-related measures at the burst level. All acoustic measures are listed and defined in Table . Relative burst amplitudes were then calculated as a ratio of absolute amplitude over the duration of the burst to the amplitude of the 700 Hz calibration tone recorded on the corresponding channel at the beginning of the session. Percentage-voicing outcomes were based on an automatic F0 extraction routine native in the XWAVES program and were used to classify each bout and burst as unvoiced, mixed, or voiced [see Fig. ]. An unvoiced sound was one containing 25% or less voicing, mixed sounds contained between 25% and 75% voicing, and voiced sounds had 75% or more voicing. Percentage-voicing values of bursts within each bout were used to compute mean percentage voicing at the bout level. Formant frequencies were extracted for all bursts produced by deaf laughers with sufficient voicing to allow this analysis and from a representative sample of bursts produced by hearing laughers. Formant measurement procedures followed those outlined in Bachorowski et al. (2001) and were based on formant-peak locations in linear predictive coding spectra (ten coefficients, 40 ms Hamming analysis window, autocorrelation method) overlaid on fast Fourier transform (FFT) spectra (40 ms, Hanning analysis window) that were computed over the same waveform segment (see also Owren and Bernacki, 1998).\n\nTable 2\n\nAnalysis levelMeasureDefinitionBout (a laughter episode or series)DurationTime between bout onset and offset (s)Burst (a continuous, discrete sound within a bout)DurationTime between burst onset and offset (s)Fundamental frequency (F0)Lowest-frequency harmonic in a quasiperiodic waveform (Hz)Formant frequency (F1,F2)Center frequency of the two lowest formants, where a formant is a resonance of the vocal tract (Hz)Percentage voicing (% voicing)Percentage of analysis frames in a burst from which an F0 value could be extracted using the xwaves software pitch-extraction algorithm (%)Raw amplitudeMean root-mean-square (rms) value computed over the entire burst (dB)Relative amplitudeA normalized amplitude value derived by subtracting a burst’s raw rms (dB) amplitude from the rms (dB) value of a constant amplitude, 700 Hz calibration tone recorded on the same channel of the audio recorder using identical input settings\n\nStatistical comparisons relied primarily on repeated-measure ANOVAs using participant identity as the subjects factor, gender as a within-group factor, and hearing status as a between-group factor. Variance distribution analyses were also conducted for all measures, in order to ensure that group differences were not traceable to any one individual. Statistical comparisons at the bout level focused on voicing classification, percentage-voicing, duration, and burst-type composition. At the burst level, comparisons included mouth position, air-flow direction, and voicing classifications, as well as duration, interburst interval, and relative amplitude.\n\nSimilarities\n\nAcoustic variability. Previous acoustic analyses have indicated that laughter is highly variable at both bout and burst levels, including degree of voicing (Bachorowski et al., 2001), mouth position (Bachorowski et al., 2001), air-flow direction (Bachorowski et al., 2001; Nwokah et al., 1999), and both temporal and F0 characteristics (Bachorowski et al., 2001; Mowrer et al., 1987). The laugh sounds recorded here were similarly variable, both replicating the earlier findings and extending those results to deaf laughers.\n\nFor example, both deaf and hearing participants produced bursts that could range from fully unvoiced to fully voiced. Some individuals in both groups produced bursts that were primarily of one type or another, while others produced sounds from all three categories. However, there was no reason to conclude that participants were limited in the degree of voicing they could potentially produce in their bursts. Most bouts and bursts produced by both deaf and hearing participants were unvoiced, a smaller number were mixed, and relatively few were purely voiced. This is the same order observed by Bachorowski et al. in their larger sample of normally hearing laughers, although higher proportions of voiced bouts and bursts were found in that study.\n\nSimilarly, bursts in both the deaf and hearing groups could be produced with open, closed, or mixed mouth positions and with either egressive or ingressive airflow. Mouth-position findings were similar to those reported by Bachorowski et al. (2001), although reliability was not quite as high in the current work as in this previous report. However, both studies have found most of the laughs being produced with the mouth closed, a significant number being produced with the mouth open, and only a few showing a mixed mouth position. Both deaf and hearing laughers scored here were found to not only produce a majority of egressive sounds, but also showed a nontrivial rate of ingressive sounds. This finding contrasts with some earlier studies arguing that ingressive laugh sounds are extremely rare (e.g., Provine and Yong, 1991) and may also be the first case in which air-flow direction has actually been coded and quantified. This outcome should also be interpreted cautiously, however, as reliability was lower than desired for this measure, and the validity of the judgments made could not be assessed. The outcomes are included mainly as an additional point of comparison for the hearing and deaf participants, as well as to highlight the need to specifically investigate this dimension of laughter production in the future work.\n\nLaughter in both groups was also characterized by significant temporal variability at each level of analysis. At the bout level, laughter in deaf participants lasted a minimum of 0.08 s and a maximum of 24.6 s. Laughter bouts in hearing participants were as short as 0.04 s and as long as 12.4 s. At the burst level, laughs ranged from 0.004 to 3.06 s for deaf laughers and from 0.002 to 4.02 s for hearing laughers. Considerable variation was also present in temporal factors such as bout and burst durations, with interburst intervals being greater in both laugh samples than in previous reports (cf. Bachorowski et al., 2001; Mowrer et al., 1987). These discrepancies may at least partly reflect inter- and intraindividual differences in intensity of response to the particular stimuli used in the various studies (Mowrer, 1994).\n\nIn the current work, mean laugh-production rates for hearing participants (3.82 bursts∕s) were somewhat lower than those reported by Bachorowski et al. (2001) (4.37 bursts∕s), but nonetheless higher than reported rates of speech (3.26 syllables∕s) (Venkatagiri, 1999). Mean rates were lower among deaf laughers (2.82 bursts∕s), perhaps reflecting that vocal production rates are generally slower among deaf than among hearing vocalizers (Leder and Spitzer, 1993; Okalidou and Harris, 1999; Osberger and Levitt, 1979; Osberger and McGarr, 1983). Possible reasons for these findings are discussed below.\n\nF0measures. Several previous studies (e.g., Bachorowski et al., 2001; Provine and Yong, 1991; Vettin and Todt, 2004) have found the mean F0 of laughter in hearing individuals to be much higher than the reported mean F0 of normative speech. In fact, large F0 range has been described as a defining characteristic of laughter (Mowrer et al., 1987). Laughter from deaf vocalizers was also characterized by large F0 ranges. At the burst level, mean F0 values for laughter produced by deaf females spanned 456.7 Hz. Similarly, mean F0 values for laugh bouts produced by deaf males spanned 460.9 Hz. However, ranges of mean F0 values were even greater among hearing laughers, being 742.4 Hz for female bursts and 550.0 Hz for male bursts.\n\nIn line with these characteristically large F0 ranges, mean F0’s in laughter have been reported to be more than a doubling of comparable values in speech (Mowrer et al., 1987). In the current study, mean F0’s were elevated in both deaf and hearing groups (see Fig. ), although they were not twice as high as prototypical values from normative speech (e.g., 120 and 220 Hz for males and females, respectively; Baken and Orlikoff, 1999). Mean F0 values in the speech of deaf individuals are thought to be similar to that of hearing talkers, but also vary significantly by individual talker (e.g., Lane et al., 1997). Finding more or less comparable F0 values in the laughter of deaf and hearing males, but lower F0’s in the laughter of deaf versus hearing females is therefore somewhat difficult to interpret. Taken at face value, the outcomes could indicate that laughter in deaf females does not show the same degree of F0 increase as found in hearing females or in males overall. On the other hand, the observed difference could reflect chance effects of a high degree of individual variation, that deaf females were less engaged by the stimulus material used for laugh induction, or were showing a greater degree of damping or inhibition of their vocal responses to that material (see below).\n\nLack of articulation. Although the evidence is indirect, acoustic results for laughter from both deaf and hearing groups indicate an overall lack of supralaryngeal articulatory effects. For example, plotting the formants extracted from voiced laughs in F1-F2 vowel space (see Fig. ) reveals close clustering of F2 values for both open- and closed-mouth versions. However, while F1 frequencies from closed-mouth laughter are similarly clustered, there is a greater variation in open-mouth F1 values. In vowel production, which has been extensively studied by using both direct and indirect methods, F2 frequency primarily reflects the front-to-back location of a vocal-tract constriction created by the tongue, whereas F1 frequency is largely determined by mouth-opening size and overall tongue height (e.g., Rosner and Pickering, 1994). Extending those principles to laughter, the overall location and the relative homogeneity in F2 values within the vowel space are consistent with an unconstricted vocal tract and concomitant schwalike auditory quality for both open- and closed-mouth versions.\n\nThese vowel-production principles can also make sense of finding that mouth position is critical for F1. On the one hand, keeping the mouth closed implies a raised jaw and little or no variation in tongue height or mouth opening [Fig. ]. F1 values should thus be relatively invariant for each individual laugher, and to a lesser degree, across individuals. On the other hand, lowering the jaw and parting the lips creates the possibility of significant variation in both tongue height and mouth-opening size. Given that each of these parameters can be expected to vary both within and among individual laughers, the heterogeneity observed for F1 values in open-mouth laughter [Fig. ] is also understandable. Overall, these outcomes are consistent with Bachorowski et al.’s (2001) formant-related findings for laughter from normally hearing vocalizers (see Fig. 6 in that article), and inconsistent with attributing a range of vowel qualities to these sounds (e.g., Provine, 2000; Provine and Yong, 1991).\n\nDifferences\n\nDespite the overall similarity in acoustic properties of laughter shown by deaf and hearing participants, some differences were also found. These particularly included aspects of duration, amplitude, percentage voicing, and F0. In several cases, those differences may be traceable to deficiencies in laryngeal and oral muscle control resulting from the relatively low rates of vocalization occurring in profoundly deaf individuals. Although our deaf participants’ use of speech was not specifically investigated, all lived in a deaf community in which ASL is the primary form of language communication, and all reported ASL rather than spoken English to be their primary, native language.\n\nResearchers investigating vocal production in deaf talkers have suggested that laryngeal and oral deficiencies can affect the temporal characteristics of their speech (LaPointe et al., 1990; Okalidou and Harris, 1999). Since speech and laughter utilize the same physical apparatus (Nwokah et al., 1999), vocal anatomy in the deaf participants tested here may have been affected by similar constraints. One possible example emerging in the results was the longer interburst intervals found in deaf laughers, which could conceivably be analogous to interphonemic and intersyllabic temporal distortions found in deaf talkers (Rothman, 1976). However, this phenomenon only occurred following unvoiced bursts, suggesting that the two phenomena are not directly related.\n\nA more likely parallel was revealed in finding that deaf laughers produced longer-duration voiced bursts than did hearing laughers. Figure shows two potentially relevant examples, the first being a sustained, creaky vowel sound occurring before the laugh begins (which was not scored as a laugh). This event is a likely analog to an unvoiced exhalation or inhalation that hearing vocalizers can routinely produce just before laughter onset, but with this deaf female’s vocal folds becoming engaged and vibrating somewhat irregularly. Later in the same bout, voiced bursts that would likely be separated in a hearing person’s laughter are connected by ongoing, and arguably artifactual, phonation. Here again, it appears that voicing is occurring at points where the vocal folds would have become disengaged in a hearing person. These phenomena may thus be mechanistically related to the slower, elongated vowels reported for deaf speech (Bakkum et al., 1995; Okalidou and Harris, 1999).\n\nWhile a number of studies have reported that the mean speaking F0 of deaf individuals does not differ from that of hearing talkers (e.g., Waldstein, 1990), others have found F0 values to be higher in the former (e.g., Leder and Spitzer, 1993). These conflicting results may reflect the higher individual variability noted earlier for deaf talkers, who, for instance, show greater variability in their experience with speech (Lane et al., 1997). Current results showed the converse, namely, that the range of mean F0 values was smaller among deaf than among hearing laughers, differences of almost 200 and 100 Hz for females and males, respectively. The next section considers a likely cause, namely, that more purely social factors may have influenced the vocal behavior of deaf participants during testing.\n\nAnother possibility to consider is that laughter has been shown to occur in the context of language communication in both deaf signers and hearing talkers (e.g., Provine and Emmorey, 2006; Provine and Yong, 1991). While any signing that may have been produced by deaf participants in the current work would not have affected recovery of laugh sounds, that was not the case for the talking that sometimes occurred in hearing participants. For the latter, laugh sounds occurring in the context of speech were specifically excluded from analysis, which may have served to inflate the differences observed between deaf and hearing laughers on measures such as proportion of unvoiced versus voiced laughter, and F0 values. However, the proportions of voiced laughter documented for normally hearing listeners at both bout and burst levels remained below those reported by Bachorowski et al. (2001), which argues against the possibility that any such effects had a major influence on current outcomes. Nonetheless, the safest conclusion may be that the results reflect a conservative estimate of the degree of similarity documented between laughs from deaf and hearing participants."
    }
}