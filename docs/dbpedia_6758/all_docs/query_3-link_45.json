{
    "id": "dbpedia_6758_3",
    "rank": 45,
    "data": {
        "url": "https://arxiv.org/html/2404.17652v1",
        "read_more_link": "",
        "language": "en",
        "title": "Validating Deep-Learning Weather Forecast Models on Recent High-Impact Extreme Events",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/extracted/5561922/overview.png",
            "https://arxiv.org/html/extracted/5561922/2021_PNW_heatwave_predictability_barrier_plots_rmse_all.png",
            "https://arxiv.org/html/x1.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_forecast_from_different_starts_bias_wrt_surface_India-Bangladesh.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_area_statistics_forecasts_India-Bangladesh.png",
            "https://arxiv.org/html/extracted/5561922/2021_NA_winterstorm_predictability_barrier_wind_chill.png",
            "https://arxiv.org/html/extracted/5561922/2021_NA_winterstorm_prediction_error_at_minimum_windchill.png",
            "https://arxiv.org/html/extracted/5561922/2021_PNW_heatwave_combined_contour_timeseries.png",
            "https://arxiv.org/html/extracted/5561922/2021_PNW_heatwave_anomalies_temporally_accumulated_start_dates.png",
            "https://arxiv.org/html/extracted/5561922/2021_PNW_heatwave_best_worst_model.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_area_statistics_forecasts_Laos-Thailand.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_forecast_from_different_starts_bias_wrt_surface_Laos-Thailand.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_forecast_from_different_starts_bias_wrt_level_Laos-Thailand.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_forecast_from_different_starts_bias_wrt_surface_temperature_India-Bangladesh.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_forecast_from_different_starts_bias_wrt_level_India-Bangladesh.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_forecast_from_different_starts_bias_wrt_same_level_humidity_India-Bangladesh.png",
            "https://arxiv.org/html/extracted/5561922/2023_humid_heatwave_heat_index_map_India-Bangladesh.png",
            "https://arxiv.org/html/extracted/5561922/2021_NA_winterstorm_college_station_timeseries.png",
            "https://arxiv.org/html/extracted/5561922/2021_NA_winterstorm_predictability_barrier_2m_temperature.png",
            "https://arxiv.org/html/extracted/5561922/2021_NA_winterstorm_predictability_barrier_surface_windspeed.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Olivier C. Pascheâˆ—\n\nResearch Center for Statistics,\n\nUniversity of Geneva, Switzerland,\n\nolivier.pasche@unige.ch\n\n&Jonathan Widerâˆ—\n\nDepartment of Compound Environmental Risks,\n\nHelmholtz Centre for Environmental Research â€“ UFZ, Leipzig, Germany\n\nScaDS.AI, Dresden/Leipzig, Germany,\n\njonathan.wider@ufz.de\n\n&Zhongwei Zhangâˆ—\n\nResearch Center for Statistics,\n\nUniversity of Geneva, Switzerland\n\n&Jakob Zscheischler\n\nDepartment of Compound Environmental Risks,\n\nHelmholtz Centre for Environmental Research â€“ UFZ, Leipzig, Germany\n\nScaDS.AI, Dresden/Leipzig, Germany\n\nTUD Dresden University of Technology, Dresden, Germany\n\n&Sebastian Engelke\n\nResearch Center for Statistics,\n\nUniversity of Geneva, Switzerland\n\nAbstract\n\nThe forecast accuracy of deep-learning-based weather prediction models is improving rapidly, leading many to speak of a â€œsecond revolution in weather forecastingâ€. With numerous methods being developed, and limited physical guarantees offered by deep-learning models, there is a critical need for comprehensive evaluation of these emerging techniques. While this need has been partly fulfilled by benchmark datasets, they provide little information on rare and impactful extreme events, or on compound impact metrics, for which model accuracy might degrade due to misrepresented dependencies between variables. To address these issues, we compare deep-learning weather prediction models (GraphCast, PanguWeather, FourCastNet) and ECMWFâ€™s high-resolution forecast (HRES) system in three case studies: the 2021 Pacific Northwest heatwave, the 2023 South Asian humid heatwave, and the North American winter storm in 2021. We find evidence that machine learning (ML) weather prediction models can locally achieve similar accuracy to HRES on record-shattering events such as the 2021 Pacific Northwest heatwave and even forecast the compound 2021 North American winter storm substantially better. However, extrapolating to extreme conditions may impact machine learning models more severely than HRES, as evidenced by the comparable or superior spatially- and temporally-aggregated forecast accuracy of HRES for the two heatwaves studied. The ML forecasts also lack variables required to assess the health risks of events such as the 2023 South Asian humid heatwave. Generally, case-study-driven, impact-centric evaluation can complement existing research, increase public trust, and aid in developing reliable ML weather prediction models.\n\nSignificance Statement\n\nWith the performance of machine-learning-based weather forecasting models improving rapidly, thorough analyses are needed to ensure that their forecasts are accurate and reliable before deploying them in operational settings. Existing evaluations often reduce forecast performance to a few metrics, potentially obscuring rare but systematic errors. This is especially problematic for high-impact extreme events, which, by definition, are rare in the data but often substantially affect society. In a detailed analysis of three extreme events, we observe that although machine learning (ML) models generally outperform the best physics-based numerical weather prediction (NWP) model on benchmark datasets, they do not consistently do so for extreme events or compound impact metrics, and lack some impact-relevant variables.\n\n1 Introduction\n\nIn recent years, the performance of machine learning (ML) weather forecast models has improved drastically (Rasp et al., 2024), leading some authors to speak of a â€œriseâ€ of ML methods in weather forecasting (Ben-Bouallegue et al., 2023), or even a second revolution of the field. While some studies focused on short-term predictions (â€œnowcastingâ€, Espeholt et al., 2022; Leinonen et al., 2023; Andrychowicz et al., 2023), and long-term subseasonal-to-seasonal forecasting (two weeks to two months ahead, Weyn et al., 2021; Lopez-Gomez et al., 2023), much work concentrated on the medium range (Rasp and Thuerey, 2021; Pathak et al., 2022; Nguyen et al., 2023a; Chen et al., 2023a; Bi et al., 2023; Kochkov et al., 2023; Lam et al., 2023; Chen et al., 2023b; Nguyen et al., 2023b; Price et al., 2023), i.e., forecasting days to weeks into the future.\n\nThe established technique for weather forecasting in the medium range is numerical weather prediction (NWP), which is based on evolving an estimate of the current weather state constructed from observations through time under differential equations. Therefore, the point of comparison for ML approaches is ECMWFâ€™s Integrated Forecasting System, including its high-resolution forecast system (HRES) (Owens and Hewson, 2018), which is generally considered to be the most reliable global NWP model. The latest ML weather models match or even outperform HRES in terms of overall summary scores across many variables, pressure levels, and prediction lead times (Rasp et al., 2024). In addition to performance, other reasons to consider ML-based weather forecasting include energy efficiency during operations and improved inference speed. Some see the possibility of a â€œnew paradigmâ€ emerging in medium-range weather forecasting: using numerical models primarily to assimilate observations, while applying ML models for operational forecasting (Ben-Bouallegue et al., 2023).\n\nGiven these recent advances and the immense importance of accurate and robust weather forecasting to many aspects of human life, thorough analyses are necessary before operationalizing ML weather prediction models. As extreme weather events often have severe impacts (Zscheischler et al., 2020; Seneviratne et al., 2021), such as crop loss, wildfires, and flooding, effective mitigation measures require accurate predictions in the tails of the distribution.\n\nWhile ML-based weather forecasts can achieve high overall accuracy, their performance for extreme events is not well understood. ML models generally face fundamental difficulties during extrapolation and generalization to unseen domains, and good test accuracy estimates do not guarantee good performance outside the range of previous observations, or in regions of the input space where observations were scarce (Hastie et al., 2009; Watson, 2022).\n\nSummary scores, like the root mean squared error (RMSE), play a central role in the evaluation of ML weather prediction models. Typically, one score is computed for each lead time, predicted variable, and (pressure) level to quantify the modelâ€™s performance over the entire test set (see, e.g., scorecards in Rasp et al., 2024). Several other aspects of ML forecasts have also been studied in the literature. For instance, Bonavita (2023), Lam et al. (2023) and Rasp et al. (2024) examined the smoothness of the predictions and found that most ML models tend to blur predictions for long lead times as a consequence of the way these models are conceptualized and trained. Bonavita (2023) studied PanguWeather, one of the best-performing ML models, and found it to be worse at maintaining physical balances than ECMWFâ€™s HRES.\n\nOlivetti and Messori (2024a) summarized some of the extreme-event evaluations performed for the latest generation of ML weather forecast models. In previous work, extreme temperatures (both hot and cold) were studied by comparing threshold exceedances of predictions and ground truth data (Ben-Bouallegue et al., 2023; Lam et al., 2023; Olivetti and Messori, 2024b). Other types of investigated extreme events include tropical cyclones, atmospheric rivers, and storm systems (Magnusson, 2023; Ben-Bouallegue et al., 2023; Lam et al., 2023; Charlton-Perez et al., 2024). While some studies have looked into individual events, many types of extremes are still under-explored, especially on a case-study level.\n\nIn addition, little attention has been paid to impact metrics that combine multiple predicted variables, or to events where accurate assessment of their spatial or temporal extent is important. The compounding effect of multiple variables in space and time can lead to particularly large impacts (Zscheischler et al., 2020). Examining prediction performance for these events in case studies is necessary to increase public trust in ML models, and also has the potential to uncover rare systematic errors in the ML model predictions that might be hidden by summary scores.\n\nThis study evaluates the ability of three popular ML weather prediction models to accurately forecast relevant impact metrics of extreme weather events through three case studies. The ML models GraphCast (Lam et al., 2023), PanguWeather (Bi et al., 2023), and FourCastNet (Pathak et al., 2022) are compared to IFS HRES (Owens and Hewson, 2018) for the 2021 Pacific Northwest heatwave, the 2023 South Asian humid heatwave, and the 2021 North American winter storm.\n\n2 Data and Models\n\n2.1 Data\n\nIn this paper, we use two kinds of data: ERA5 reanalysis data (Hersbach et al., 2020) and ECMWF HRES analysis data. All ML models considered in this study were trained on ERA5, which is produced using data assimilation, i.e., by combining observations with short-range forecasts to obtain a â€œbest guessâ€ of the actual weather state. ERA5 has a horizontal resolution of \\qtyâ¢0.25Ã—\\qtyâ¢0.25\\qty0.25\\qty0.25\\qty{0.25}{}\\times\\qty{0.25}{}0.25 Ã— 0.25, an hourly temporal resolution, and provides estimates of many atmospheric, land, and oceanic climate variables over the globe from 1940 to present. The ML models GraphCast and FourCastNet have an internal time step of \\qty6 and were trained on a subset of ERA5 at 00:00, 06:00, 12:00, and 18:00 UTC. Therefore, we also restrict our analyses to these times of day.\n\nWe use HRES forecasts of versions 47r1, 47r2, and 47r3 from ECMWFâ€™s Integrated Forecasting System. They have a horizontal resolution of \\qtyâ¢0.1Ã—\\qtyâ¢0.1\\qty0.1\\qty0.1\\qty{0.1}{}\\times\\qty{0.1}{}0.1 Ã— 0.1, and we downsample them to the \\qtyâ¢0.25Ã—\\qtyâ¢0.25\\qty0.25\\qty0.25\\qty{0.25}{}\\times\\qty{0.25}{}0.25 Ã— 0.25 grid using the default Meteorological Interpolation and Regridding (MIR) library in the ECMWF Meteorological Archival and Retrieval System (MARS). ERA5 and HRES data can be retrieved from online archives. HRES forecasts initialized at 00:00 UTC or 12:00 UTC are archived for lead times up to \\qty10, while forecasts initialized at 06:00 UTC and 18:00 UTC are only available for lead times up to \\qty3.75. To ensure a fair comparison, we use â€œHRES forecast at step 0â€ (HRES-fc0) as the ground truth for HRES forecasts. If ERA5 was used instead, HRES would have a non-zero error at lead time \\qty0h. We use HRES forecast data with lead times ranging from \\qty0 to the maximum available length in steps of \\qty6, so that the lead times match those of the ML forecasts.\n\nA key difference between our comparison study and Ben-Bouallegue et al. (2023) is the data used for initializing and evaluating ML models. In both cases, they used HRES data to ensure fairness in an operational context, but noted that this change of input data may bring disadvantages to ML models since they are trained on ERA5 data. Therefore, we choose the conventional approach in ML studies (Pathak et al., 2022; Bi et al., 2023; Lam et al., 2023; Chen et al., 2023b) and use ERA5 data to initialize and evaluate ML models.\n\n2.2 Machine Learning Models for Weather Forecasting\n\nWe focus on three recent ML models in this work: FourCastNet, PanguWeather, and GraphCast. Table 1 summarizes the main characteristics of these models. More details on the variables predicted by these models are presented in Section D.\n\nBi et al. (2023) trained four models with different lead times (1, 3, 6, and 24 \\unit). These models are combined during inference to achieve the minimum number of model executions for a given forecast lead time (â€œhierarchical temporal aggregation strategyâ€), thereby minimizing error accumulation (Bi et al., 2023). For instance, to forecast the weather state in 36 hours, using the 24h-model once plus two iterations of the 6h-model gives a more accurate forecast than simply using the 1h-model iteratively for 36 times. Because we only consider lead times that are multiples of \\qty6h in our study, we use sequences of \\qty6h- and \\qty24h-model calls to achieve the smallest possible forecast error for PanguWeather.\n\nWe also highlight that GraphCast requires the weather states at two consecutive time points as inputs to each forecast, while the other two models only need one. Furthermore, as shown in Table 1, for each time step the dimensionality of the input data (especially the number of pressure levels) of GraphCast is substantially higher than that of PanguWeather and FourCastNet. These two distinctions might advantage GraphCast in comparison to the other two ML models, since using additional covariate information in principle tends to increase the potential predictive accuracy.\n\nContrary to Olivetti and Messori (2024b), who used the forecast data of ML models from WeatherBench 2 (Rasp et al., 2024) and thus have strictly limited temporal study domains (e.g., GraphCast forecasts are only available for 2018 and 2020), we produce additional forecast data for more recent events by running the ML models ourselves.\n\n2.3 Initialization Times\n\nERA5 and HRES-fc0 differ in their assimilation windows (Lam et al., 2023). While observations up to three hours into the future are included in the assimilation for HRES-fc0, the lookahead for ERA5 varies between initialization times: three hours for forecasts initialized at 06:00/18:00 UTC and nine hours for forecasts initialized at 00:00/12:00 UTC. To ensure an equal lookahead, Lam et al. (2023) compared ML-based and HRES forecasts initialized at 06:00/18:00 UTC for lead times up to the availability of HRES (\\qty3.75). Beyond this time limit, ML forecasts initialized at 06:00/18:00 UTC are compared with HRES forecasts initialized at the preceding 00:00/12:00 UTC. We follow this mixed initialization methodology in one of our analyses in Section 3.1.\n\nAs shown in Section 5.2 in the Supplementary materials of Lam et al. (2023), the effect of unequal lookahead is small, particularly for long lead times. Therefore, for all analyses except the RMSE comparison in the first case study, we include all forecasts (00:00, 06:00, 12:00, and 18:00 UTC initialization times) in our analysis. Additionally, we extend the short HRES forecasts initialized at 06:00/18:00 UTC beyond lead times of \\qty4; these forecasts are augmented with data from the forecasts initialized \\qty6 prior to the 06:00/18:00 UTC initialization time, while increasing the lead time by \\qty6, so that the validity time of the forecast remains the same. This filling might disadvantage HRES, but it enables the analysis of a denser set of initialization and lead times.\n\n3 Case Studies\n\n3.1 2021 Pacific Northwest Heatwave\n\nWhile the impacts caused by very extreme events can be disproportionately large, there are few guarantees on the performance of ML-based forecasts in these cases. Therefore, in the first case study, we investigate a record-shattering extreme event. In late June 2021, a heatwave of unprecedented magnitude hit the Pacific Northwest with temperatures reaching up to \\qty49.6, beating the all-time record for Canada by \\qty4.6 (Figure 1A).\n\nEven in hindsight, quantifying the return period of the event is challenging (Bartusek et al., 2022; Philip et al., 2022; Zeder et al., 2023).\n\nThe heatwave impacted ecosystems, infrastructure, and human health considerably (with more than 1400 deaths), and attracted massive public attention and scientific interest (Neal et al., 2022; Schumacher et al., 2022; White et al., 2023; RÃ¶thlisberger and Papritz, 2023). In the analyzed region, temperatures peaked between June 27 and June 29. We analyze the heatwave in terms of the temperature at 2mtimes2meter2\\text{\\,}\\mathrm{m}start_ARG 2 end_ARG start_ARG times end_ARG start_ARG roman_m end_ARG above the surface (T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT), which is a standard variable for studying temperature extremes.\n\nIn the grid cells closest to three major population centers affected by the heatwave (Vancouver, Seattle, Portland), the prediction error of HRES and all tested ML models reaches at least twice the size of a typical HRES 10-day prediction error and exceeds the typical HRES 10-day error in Portland by a factor of four. This is consistent with the results of Lin et al. (2022), who examined the predictions of subseasonal-to-seasonal NWP models for the Pacific Northwest heatwave and found that all models failed to predict the magnitude of the heatwave for forecasts initialized on June 17, i.e., ten days before temperatures began to peak. We visualize our prediction errors in predictability barrier plots in Figure 2, using HRES-fc0 as ground truth for the HRES forecasts and ERA5 as ground truth for the ML-based predictions. Maps of the temperature anomaly patterns predicted for the peak of the heatwave for forecasts with different initialization times are shown in Figure A2.\n\nFourCastNet has the largest error among all models, while the errors of PanguWeather, GraphCast, and HRES are of a similar magnitude visually (Figure 2). For all models, the prediction errors are largest during the peak of the heatwave. The predictability barrier plots exhibit prominent vertical structures (i.e., forecasts for the same validity day), suggesting that the dominant factor is the predictability of the weather situation rather than the forecast initialization.\n\nFor HRES, the prediction errors in the first days of July 2021, when temperatures started to fall again, are larger than for PanguWeather and GraphCast. The predictability barrier plots for PanguWeather appear very patchy, likely due to the â€œhierarchical temporal aggregation strategyâ€ of PanguWeather (described in Section 2.2).\n\nThe best and worst performing models across various lead and validity times are visualized in Figure A3. Conclusions match those from Figure 2; FourCastNet has the largest errors during the heatwave, and HRES has comparatively high errors after the peak of the heatwave. During many of the time steps, especially for short lead times, GraphCast and HRES yield the smallest error. However, there is no clear best-performing model overall.\n\nTo assess the modelsâ€™ performance in predicting the extreme event, we compute the forecast RMSEs of all models during the peak of the heatwave and compare them to the RMSEs during the summer of 2022, a baseline year without extreme heatwaves in the region. We vary the lead time and study the event in the region defined by Philip et al. (2022). The RMSE computation follows Lam et al. (2023): it includes latitude-based weights, and only forecasts initialized at 06:00/18:00 UTC and lead times in multiples of \\qty12 are considered to ensure equal assimilation windows between ERA5 and HRES-fc0.\n\nThe results again highlight the difficulty of predicting the extreme temperatures during the event: for lead times beyond one week, all models perform substantially worse than for the summer 2022 baseline. More precisely, all ML models perform up to at least three times worse and HRES up to two times worse. The difference in accuracy thus seems relatively greater for ML approaches compared to HRES, especially for those large lead times, as they are all more accurate than HRES for 2022 but less accurate for the heatwave. This might be a consequence of extrapolation, as discussed in the introduction. As the evaluated baseline period is rather short, mainly for computational reasons, the baseline might not precisely represent the typical performance. However, the baseline results are in line with other studies (Bonavita, 2023; Lam et al., 2023).\n\nA further analysis focusing on the spatial aspect of the event is presented in Section A.2. A main conclusion is that FourCastNet under-predicts the area in which temperature anomalies exceed a given threshold, while in some PanguWeather forecasts, the area predicted to exceed the thresholds is too large.\n\n3.2 2023 South Asian Humid Heatwave\n\nIn April 2023, high temperature and humidity levels were reached simultaneously in South Asia (Zachariah et al., 2023) (Figure 1B). The human tolerance to high temperatures decreases with increasing humidity, mainly due to the inability of the body to self-regulate its temperature through transpiration. Heat stress associated with this type of event can therefore be particularly harmful to human health (Buzan and Huber, 2020; Lo et al., 2023).\n\nThe heat index (Hâ¢Iğ»ğ¼HIitalic_H italic_I) is an impact metric quantifying this hazard to human health. It estimates the apparent temperature (i.e., how hot the temperature feels) for given values of temperature (T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT) and relative humidity (Râ¢Hğ‘…ğ»RHitalic_R italic_H). While many metrics have been proposed to combine the influence of these two variables (Lo et al., 2023), we follow Zachariah et al. (2023) in using the modified version of the heat index (Rothfusz and Headquarters, 1990) used by the NOAA Weather Prediction Center. The detailed computations, including information on how we convert specific humidity produced by the ML models to relative humidity, are given in Appendix BB.3.\n\nFollowing Zachariah et al. (2023), we focus on two study regions in South Asia: Laos-Thailand (for which results are presented in Section B.4), and India-Bangladesh. For the latter, a sub-region with dry and semi-arid climate is excluded from the analysis (see Appendix BB.1 for details). We select a temporal range of April 17â€“20, 2023 (UTC time, inclusive range) for the India-Bangladesh region, corresponding to the period in which the heat stress peaked.\n\nWith existing ML weather prediction models, Hâ¢Iğ»ğ¼{HI}italic_H italic_I at the surface cannot be calculated correctly because humidity is only modeled at higher pressure levels, and none of the models predict a variable that could enable the calculation of relative humidity at the surface level. This presents a strong limitation on the utility of ML models in forecasting humid heat waves. While GraphCast and PanguWeather forecast variables at the \\qty1000\\hecto level, FourCastNet only includes variables at pressure levels starting from \\qty850\\hecto. In the following, we exclude FourCastNet from the analysis and use relative humidity at the \\qty1000\\hecto level as an approximation for humidity at the surface for the other ML models.\n\nThe Hâ¢Iğ»ğ¼{HI}italic_H italic_I prediction error during the peak of the heatwave in the India-Bangladesh region is shown in Figure 4. For each day, we select the time when the ground truth Hâ¢Iğ»ğ¼HIitalic_H italic_I is maximal, and then average the errors over April 18â€“20. For ML models, the predicted Hâ¢Iğ»ğ¼{HI}italic_H italic_I is computed using T2â¢msubscriptğ‘‡2ğ‘š{T}_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT and Râ¢H\\qtyâ¢1000â¢\\hectoğ‘…subscriptğ»\\qty1000\\hecto{RH}_{\\qty{1000}{\\hecto}}italic_R italic_H start_POSTSUBSCRIPT 1000 end_POSTSUBSCRIPT, while for HRES and for the ground truth data, Hâ¢Iğ»ğ¼HIitalic_H italic_I is computed using T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT and Râ¢Hsurfaceğ‘…subscriptğ»surfaceRH_{\\text{surface}}italic_R italic_H start_POSTSUBSCRIPT surface end_POSTSUBSCRIPT. This comparison is unfair in the sense that even if a model predicts Râ¢H\\qtyâ¢1000â¢\\hectoğ‘…subscriptğ»\\qty1000\\hectoRH_{\\qty{1000}{\\hecto}}italic_R italic_H start_POSTSUBSCRIPT 1000 end_POSTSUBSCRIPT and T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT perfectly well, it would not necessarily yield a zero forecast error. However, this setup is a possible â€œbest guessâ€ that forecasters could do with the ML models available at the time of writing.\n\nThe ML pseudo-predictions strongly underestimate the Hâ¢Iğ»ğ¼HIitalic_H italic_I, mainly because of the underprediction of humidity, but also because the predicted T2â¢msubscriptğ‘‡2ğ‘š{T}_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT values are too low (Figure B4). If we instead compute the ground truth Hâ¢Iğ»ğ¼HIitalic_H italic_I using the ERA5 relative humidity at \\qty1000\\hecto as well, the forecast errors are smaller, but there are still large deviations, especially over Bangladesh (Figure B5). These are mainly caused by an underprediction of Râ¢H\\qtyâ¢1000â¢\\hectoğ‘…subscriptğ»\\qty1000\\hectoRH_{\\qty{1000}{\\hecto}}italic_R italic_H start_POSTSUBSCRIPT 1000 end_POSTSUBSCRIPT (Figure B6).\n\nLarge fractions of the India-Bangladesh region experienced a mean daily maximum Hâ¢Iğ»ğ¼HIitalic_H italic_I during April 17â€“20 2021 that falls in the â€œextreme cautionâ€ or â€œdangerâ€ category (Figure 5, see Table B.1 for the definition of the categories). Notably, the Hâ¢Iğ»ğ¼HIitalic_H italic_I distributions computed from HRES-fc0 and ERA5 data using the same input variables T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT and Râ¢H\\qtyâ¢1000â¢\\hectoğ‘…subscriptğ»\\qty1000\\hectoRH_{\\qty{1000}{\\hecto}}italic_R italic_H start_POSTSUBSCRIPT 1000 end_POSTSUBSCRIPT differ from each other, mainly due to ERA5 humidity values being higher than HRES-fc0 during daily maximum Hâ¢Iğ»ğ¼HIitalic_H italic_I. This may be a consequence of differences in the assimilation procedure used to produce the ground truth data. The Hâ¢Iğ»ğ¼{HI}italic_H italic_I forecast by HRES matches its ground truth much better than the ML forecasts. The ML Hâ¢Iğ»ğ¼{HI}italic_H italic_I forecasts (computed using Râ¢H\\qtyâ¢1000â¢\\hectoğ‘…subscriptğ»\\qty1000\\hecto{RH}_{\\qty{1000}{\\hecto}}italic_R italic_H start_POSTSUBSCRIPT 1000 end_POSTSUBSCRIPT) underestimate the true Hâ¢Iğ»ğ¼HIitalic_H italic_I values computed from ERA5, as well as the pseudo Hâ¢Iğ»ğ¼HIitalic_H italic_I values, where ERA5 Râ¢H\\qtyâ¢1000â¢\\hectoğ‘…subscriptğ»\\qty1000\\hectoRH_{\\qty{1000}{\\hecto}}italic_R italic_H start_POSTSUBSCRIPT 1000 end_POSTSUBSCRIPT is used. This is especially the case for high values of Hâ¢Iğ»ğ¼HIitalic_H italic_I. Results for the Laos-Thailand region are also in line with these findings (see Section B.4).\n\nFigure B7 visualizes the heat index forecast for the peak of the heatwave by forecasts with different initialization times (in terms of threat categories, see Table B.1). Results match the other analyses in this section.\n\n3.3 2021 North American Winter Storm\n\nWhile heatwaves often receive a lot of media attention, especially in light of anthropogenic climate change, cold spells are also hazardous. Under the current climate, cold extremes lead to more human deaths overall than hot extremes (Gasparrini et al., 2015). In mid-February 2021, a winter storm hit large parts of the United States, Northern Mexico, and Canada (Figure 1C). Rapidly falling temperatures were accompanied by snow, sleet, freezing rain, and strong winds, causing damages to human livelihood and infrastructure (National Weather Service, 2021). In Texas, which was strongly affected by the event, pipes burst, interrupting the water distribution, and energy infrastructure failed, resulting in power outages and ordered rolling blackouts. Impacts were amplified by inadequate wintering of energy infrastructure (Gruber et al., 2022).\n\nWhile it would be interesting to look at a metric that directly relates to vulnerabilities of the Texas power grid, defining such a metric is not straightforward. Therefore, we restrict our analyses to T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT and the wind chill index Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT as defined in Osczevski and Bluestein (2005). The wind chill index is a metric that describes the apparent temperature in the presence of wind. It is defined as\n\nTwâ¢c=13.12+0.6215â¢T2â¢mâˆ’11.37â¢v0.16+0.3965â¢T2â¢mâ¢v0.16,subscriptğ‘‡ğ‘¤ğ‘13.120.6215subscriptğ‘‡2ğ‘š11.37superscriptğ‘£0.160.3965subscriptğ‘‡2ğ‘šsuperscriptğ‘£0.16T_{wc}=13.12+0.6215T_{2m}-11.37v^{0.16}+0.3965T_{2m}v^{0.16},italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT = 13.12 + 0.6215 italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT - 11.37 italic_v start_POSTSUPERSCRIPT 0.16 end_POSTSUPERSCRIPT + 0.3965 italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT italic_v start_POSTSUPERSCRIPT 0.16 end_POSTSUPERSCRIPT , (1)\n\nwhere Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT and T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT are given in \\unit, and the wind-speed at \\qty10 height vğ‘£vitalic_v in kilometers per hour (computed from the horizontal wind components). The formula was obtained by modeling heat transfer from the human body to the atmosphere (Osczevski and Bluestein, 2005). Note that Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT is only defined for temperatures below \\qty10 and wind speeds above \\qty4.8\\per. In a particularly affected Texas city, College Station, HRES-fc0 and ERA5 closely follow observational records for both Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT and T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT (see Figure C1), demonstrating the suitability of those datasets for this index.\n\nLooking at predictions of Twâ¢csubscriptğ‘‡ğ‘¤ğ‘{T}_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT for the grid cell closest to College Station in Figure 6, one can see that all models struggle to predict the minimum wind chill index, with forecast errors being largest for FourCastNet (sometimes exceeding \\qty40K at minimum Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT for large lead times). In general, errors are larger for the winter storm than for the Pacific Northwest heatwave, as expected from the seasonality in prediction errors (Figure 2 in Ben-Bouallegue et al. (2023)). Errors for PanguWeather and GraphCast are substantially lower than for HRES, especially between February 9 and February 17, after the peak of the winter storm.\n\nThe vertical structures in the plot (which are particularly prominent for GraphCast and PanguWeather on February 15â€“17) hint at the difficulty of predicting weather situations, while the diagonal structures (strong for FourCastNet and HRES) suggest variation between individual forecasts caused by their initial conditions. In general, HRES seems to produce stronger diagonal error structures, while the ML models tend to exhibit vertical error patterns. While the data filling we use to extend HRES forecasts might affect this finding, it could also be a result of fundamental differences between ML-based and NWP forecasts; assuming a very extreme event that is easily predictable following physical laws, the predictions of HRES would steadily improve when approaching the event. ML methods, however, might not be able to extrapolate to such extreme conditions, even at very short lead-times, resulting in vertical error patterns. On the other hand, if an extreme event that is difficult to predict with (first-order) physical laws is somewhat hidden in the current atmospheric conditions, then HRES would have trouble forecasting this on a given day (leading to a diagonal pattern), but when the event then becomes more apparent in the conditions, then the prediction will improve. The ML methods might be able to model such â€˜hiddenâ€™ (second-order) conditions better because of their flexibility, leading to less strong diagonal patterns.\n\nWhen the predicted temperatures are too high, or the predicted wind speeds too low, the thresholds in the definition of Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT are not exceeded, and Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT is thus not defined. This is the case during the wind chill minimum between February 15 and February 17, even though these were the most hazardous days. In Figures 6 and 7 we ignore the thresholds in the definition and still compute the Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT expression for visual clarity.\n\nPatterns in the prediction of T2â¢msubscriptğ‘‡2ğ‘š{T}_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT look similar to those of Twâ¢csubscriptğ‘‡ğ‘¤ğ‘{T}_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT (Figure C2), with FourCastNet errors being largest, and HRES errors during the event larger than PanguWeather and GraphCast errors. For the surface windspeed, which also enters Equation (1), the patterns are not as clear (Figure C3). Therefore, the Twâ¢csubscriptğ‘‡ğ‘¤ğ‘{T}_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT errors seem to be dominated by T2â¢msubscriptğ‘‡2ğ‘š{T}_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT.\n\nFigure 7 depicts the forecast errors in a bounding box around Texas (\\qtyrange10793W, \\qtyrange2537N) for 12:00 UTC on February 15, 2021 (6:00 am, Houston time), when the average wind chill index in the box reached a minimum in the ground truth data. For long lead times, forecast errors of GraphCast and PanguWeather seem smaller than those of FourCastNet and HRES, although all forecasts appear to be too warm. One can also notice a slightly â€œpatchyâ€ structure in the FourCastNet predictions, which is likely due to the Adaptive Fourier Neural Operator architecture used in this method.\n\n4 Discussion and Conclusions\n\nThe three case studies conducted highlight different aspects of comparison between the ML models GraphCast, PanguWeather, FourCastNet, and the NWP system HRES. For the 2021 Pacific Northwest heatwave, predictions of PanguWeather and GraphCast maintained comparable quality to HRES in terms of the evaluated metrics. However, our results suggest that HRES could better handle the extremeness of the event and that ML models might be more severely impacted by the extrapolation to extreme conditions. More systematic analyses would need to be conducted to reach definite conclusions.\n\nNone of the ML models predict a variable that enables the computation of surface-level humidity. This would have allowed us to better study the effects of the 2023 humid heatwave in South Asia, as surface humidity alters the effect of temperature on the human body. Looking at substitute variables, ML models seem to perform worse for this event overall, potentially due to extrapolation. Whether this effect persists for ML models that do predict surface humidity remains to be answered in future research.\n\nDuring the 2021 North American Winter Storm, PanguWeather and GraphCast show strong predictive performance, outperforming HRES (and FourCastNet) in terms of temperature and of the wind chill index, a metric that combines the effects of wind speed and temperature.\n\nOur study only uses single forecasts and disregards probabilistic forecasting. In NWP, forecast uncertainty is accounted for by running ensemble forecasts. While including NWP ensemble forecasts is possible, this would have caused further complications in the analyses, e.g. due to differing model resolutions. Furthermore, producing ensemble forecasts with the given ML models is non-trivial. Attempts have been made, e.g., by perturbing initial conditions or model parameters (Weyn et al., 2021; Bi et al., 2023; BÃ¼lte et al., 2024), but problems capturing the right scaling of uncertainties have been found in the literature. Selz and Craig (2023) investigated PanguWeather and found that the error growth for small perturbations is too small (â€œno butterfly effectâ€). Recently, Price et al. (2023) explored generative modeling to obtain better ensembles. Because of the generative training objective, these models can better capture the spectrum of the weather at long lead times, avoiding the over-smoothing that occurs for autoregressive models like GraphCast, PanguWeather, and FourCastNet. The comparison of ML models with HRES is also limited by differences between the ground truth data sets ERA5 and HRES-fc0 (differing assimilation times, short forecasts for 06:00/18:00 UTC initializations). However, this does not affect the comparison between the three ML models. ML weather prediction models are typically trained using ERA5 data, which does not correspond to an â€œoperational settingâ€ and complicates the comparison with HRES. While ML models could be trained or fine-tuned with HRES-fc0 data directly, the IFS version used to produce the forecasts varies over time, therefore characteristics and biases of the â€œground truthâ€ HRES-fc0 would also vary.\n\nMost ML models employ a large autoregressive time step (6h for GraphCast and FourCastNet). This coarse temporal resolution might affect the forecast of impacts for which the daily maximum or minimum is relevant, such as short-term heat stress peaks or severe wind gusts. The most extreme values might be missed due to an unfortunate combination of forecast time step and daily cycle or event time. Some important variables for impact assessments are forecast by few or no ML models. These include humidity at the surface, solar radiation reaching the surface (potentially relevant for solar energy production forecasts), and precipitation. While some ML models (including GraphCast and FourCastNet) do predict precipitation, authors have advised caution in the interpretation of this variable, citing issues with the ERA5 precipitation ground truth (Lavers et al., 2022; Bremnes et al., 2023).\n\nWhile case studies can only provide anecdotal evidence, testing ML models under individual extreme events can reveal unexpected deficiencies (or advantages) of these models in comparison to well-established techniques. The rather small number of meteorological variables predicted by ML models, as well as the available forecast lead time, limits the types of impactful extreme events that can be studied for these models. While longer forecasts would be interesting and would allow the study of more complex types of extreme events (Zscheischler et al., 2020), one would likely need to include new processes and variables into the models, such as feedback from soil moisture and the influence of sea-surface temperatures.\n\nNon-linear combinations of predicted output variables (e.g., wind chill, see Equation 1) have the potential to reveal weaknesses of ML models; Price et al. (2023) investigated horizontal surface wind speed (a non-linear function of the horizontal wind components) and found that GraphCast tends to perform worse in terms of this combined metric than for the individual components. They hypothesized that this might be due to the tendency of a certain type of ML architecture to predict close to the mean under forecast uncertainty and the non-commutativity of non-linear function applications and averaging. However, in our case studies (Twâ¢csubscriptğ‘‡ğ‘¤ğ‘T_{wc}italic_T start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT during the 2021 North American winter storm and Hâ¢Iğ»ğ¼HIitalic_H italic_I during the 2023 South Asia humid heatwave), the large differences in prediction errors for individual input variables (T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT during winter storm, relative humidity during humid heatwave) and the necessity of having to substitute relative humidity at the surface level seem to outweigh this effect. Nevertheless, the described problem is an interesting target for future work, as impacts often are not simply determined by linear combinations of the variables predicted by the ML models. Price et al. (2023) suggest using generative modeling to overcome this systematic problem.\n\nFor theoretically-justified extrapolation to extremes and when interested in risk assessment, a natural approach is the use of extreme value statistics (Coles, 2001). Recently, various approaches have combined machine learning and extreme value statistics to improve predictive extrapolation of extreme risk for the predicted variable (Pasche and Engelke, 2022; Richards and Huser, 2022; Velthoen et al., 2023; Cisneros et al., 2023; Allouche et al., 2024; Gnecco et al., 2024). Methods for extrapolation in the predictor space also exist but require stronger dependence assumptions (Chen and Meinshausen, 2023; Pfister and BÃ¼hlmann, 2024). Including physical domain knowledge in ML-based models, for example through architectural restrictions of explicit equations, could be another approach to improving generalization (Kochkov et al., 2023).\n\nReleasing raw predictions instead of aggregates or summaries, or even pre-trained models, is valuable (Burnell et al., 2023). As considering all metrics that stakeholders deem important during model development and testing is challenging or impossible, releasing the full predicted data or trained models allows assessing domain-specific model skill even after the development of the model. WeatherBench 2 (Rasp et al., 2024) already partially addressed this point. Building a continuously-updated database of extreme event case study set-ups (similar to ECMWFâ€™s Severe Event Catalogue), including domains and impact metrics, might be a valuable contribution to existing literature. A focus on re-usability for new models would be important, potentially through the integration of a framework like WeatherBench 2. One could hypothesize that the selection of extreme events based on their real-world impacts leads to a â€œselection biasâ€, as the larger impacts might have been caused by poor forecasts by operational models, potentially resulting in a biased estimate of the relative performance of HRES.\n\nThe evaluation of ML models typically focuses on meteorological variables. Putting a stronger focus directly on impacts has the potential to improve the practical value of ML models. To find suitable impact metrics, researchers could, for instance, look at warnings issued by weather services and analyse how warnings based on NWP compare to forecasts using ML models. Coupling ML weather forecasts to impact models, such as models for floods (Nearing et al., 2024), crop loss, or fires, might also be valuable, although the analysis would then also depend on the impact modelâ€™s fidelity. While ML models have shown impressive skill in forecasting key meteorological variables, it is worthwhile investigating whether their predictions can lead to similarly impressive results when assessing impacts.\n\nAcknowledgements.\n\nWe thank Gloria BuriticÃ¡ and Guohao Li for the discussions in early stages of the project, and Lily-Belle Sweet for her feedback on this manuscript. We are grateful to the developers of FourCastNet, PanguWeather, and GraphCast for sharing their code, and thank ECMWF for making their data sets publicly available, which has allowed us to conduct this study.\n\nSE, OP, and ZZ acknowledge funding from the Swiss National Science Foundation Eccellenza grant â€œGraph structures, sparsity and high-dimensional inference for extremesâ€ (grant no. 186858). JW acknowledges financial support by the Federal Ministry of Education and Research of Germany and by SÃ¤chsische Staatsministerium fÃ¼r Wissenschaft, Kultur und Tourismus in the program Center of Excellence for AI-research â€œCenter for Scalable Data Analytics and Artificial Intelligence Dresden/Leipzigâ€, project identification number: ScaDS.AI. JW and JZ acknowledge the Helmholtz Initiative and Networking Fund (Young Investigator Group COMPOUNDX, Grant Agreement VH-NG-1537).\n\nAuthor roles.\n\nConceptualization: SE, OP, JW, ZZ, JZ; Data curation: OP, JW, ZZ; Formal analysis: OP, JW, ZZ; Funding acquisition: SE, JZ; Investigation: OP, JW, ZZ; Methodology: SE, OP, JW, ZZ, JZ; Project administration: SE, JZ; Resources: SE, JZ; Software: OP, JW, ZZ; Supervision: SE, JZ; Validation: OP, JW, ZZ; Visualization: OP, JW, ZZ; Writing - original draft: OP, JW, ZZ; Writing - review and editing: SE, OP, JW, ZZ, JZ. OP led the analysis and implementation of PanguWeather and FourCastNet, ZZ led the analysis and implementation of GraphCast, and JW led the case study data analysis.\n\nData and Code Availability.\n\nWe use data from the ECMWF products ERA5, HRES, and TIGGE, which are published under a Creative Commons Attribution 4.0 International (CC BY 4.0) license. ERA5 is available on the Copernicus Climate Data Store. HRES forecasts initialized at 00:00/12:00 UTC can be accessed through ECMWFâ€™s TIGGE Data Retrieval portal. HRES forecasts initialized at 06:00/18:00 UTC are accessible through ECMWFâ€™s MARS, which requires access to be granted. Recently, Rasp et al. (2024) published cloud-optimized versions of the ERA5 and HRES data. We used these data sets for the case studies in 2021, and accessed their versions of ERA5, ERA5 climatology, and HRES forecasts initialized at 00:00/12:00 UTC.\n\nPreprocessed data (ground truth and forecasts) and code to reproduce our results will be made available upon publication.\n\nAppendix A Further Details and Analysis of the 2021 Pacific Northwest Heatwave\n\nA.1 Computation of the Root Mean Squared Error\n\nWhen computing the root mean squared error (RMSERMSE\\mathrm{RMSE}roman_RMSE), we follow Lam et al. (2023) and Rasp et al. (2024), who choose not to include the average over initialization time steps inside the square root of the RMSERMSE\\mathrm{RMSE}roman_RMSE formula. For a given variable xğ‘¥xitalic_x (say 2m temperature T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT), its prediction x^^ğ‘¥\\hat{x}over^ start_ARG italic_x end_ARG, and a fixed prediction lead time Ï„ğœ\\tauitalic_Ï„, we compute its RMSEâ¢(Ï„)RMSEğœ\\mathrm{RMSE}(\\tau)roman_RMSE ( italic_Ï„ ) as\n\nRMSEğ’¯,ğ’«â¢(Ï„)=1|ğ’¯|â¢âˆ‘t0âˆˆğ’¯1|ğ’«|â¢âˆ‘iâˆˆğ’«aiâ¢(x^it0+Ï„âˆ’xit0+Ï„)2,subscriptRMSEğ’¯ğ’«ğœ1ğ’¯subscriptsubscriptğ‘¡0ğ’¯1ğ’«subscriptğ‘–ğ’«subscriptğ‘ğ‘–superscriptsuperscriptsubscript^ğ‘¥ğ‘–subscriptğ‘¡0ğœsuperscriptsubscriptğ‘¥ğ‘–subscriptğ‘¡0ğœ2\\mathrm{RMSE}_{\\mathcal{T},\\mathcal{P}}(\\tau)=\\frac{1}{|\\mathcal{T}|}\\sum% \\limits_{t_{0}\\in\\mathcal{T}}\\sqrt{\\frac{1}{|\\mathcal{P}|}\\sum\\limits_{i\\in% \\mathcal{P}}a_{i}\\left(\\hat{x}_{i}^{t_{0}+\\tau}-x_{i}^{t_{0}+\\tau}\\right)^{2}},roman_RMSE start_POSTSUBSCRIPT caligraphic_T , caligraphic_P end_POSTSUBSCRIPT ( italic_Ï„ ) = divide start_ARG 1 end_ARG start_ARG | caligraphic_T | end_ARG âˆ‘ start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT âˆˆ caligraphic_T end_POSTSUBSCRIPT square-root start_ARG divide start_ARG 1 end_ARG start_ARG | caligraphic_P | end_ARG âˆ‘ start_POSTSUBSCRIPT italic_i âˆˆ caligraphic_P end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_Ï„ end_POSTSUPERSCRIPT - italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_Ï„ end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG , (2)\n\nwhere ğ’¯ğ’¯\\mathcal{T}caligraphic_T and ğ’«ğ’«\\mathcal{P}caligraphic_P are the sets of initialization times and grid points of interest, |ğ’¯|ğ’¯|\\mathcal{T}|| caligraphic_T | and |ğ’«|ğ’«|\\mathcal{P}|| caligraphic_P | are their cardinalities, x^it0+Ï„superscriptsubscript^ğ‘¥ğ‘–subscriptğ‘¡0ğœ\\hat{x}_{i}^{t_{0}+\\tau}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_Ï„ end_POSTSUPERSCRIPT is the forecast of the variable xğ‘¥xitalic_x at grid cell iğ‘–iitalic_i and time t0+Ï„subscriptğ‘¡0ğœt_{0}+\\tauitalic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_Ï„, with forecast initialized at time t0subscriptğ‘¡0t_{0}italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and xit0+Ï„superscriptsubscriptğ‘¥ğ‘–subscriptğ‘¡0ğœx_{i}^{t_{0}+\\tau}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_Ï„ end_POSTSUPERSCRIPT is the ground truth for the same grid cell and time step t0+Ï„subscriptğ‘¡0ğœt_{0}+\\tauitalic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_Ï„. The weight ai=cosâ¡(latiâˆ—Ï€/180)subscriptğ‘ğ‘–subscriptlatğ‘–ğœ‹180a_{i}=\\cos(\\text{lat}_{i}*\\pi/180)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = roman_cos ( lat start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆ— italic_Ï€ / 180 ) is proportional to the area of the latitude-longitude grid cell iğ‘–iitalic_i and varies with the latitude of iğ‘–iitalic_i, latisubscriptlatğ‘–\\text{lat}_{i}lat start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and {ai,iâˆˆğ’«}subscriptğ‘ğ‘–ğ‘–ğ’«\\{a_{i},i\\in\\mathcal{P}\\}{ italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_i âˆˆ caligraphic_P } are normalized to have unit mean across the included grid cells.\n\nNote that Equation 2 reduces to the mean absolute error if only a single grid cell is included in ğ’«ğ’«\\mathcal{P}caligraphic_P. To compute the average RMSE for a given day and lead time Ï„ğœ\\tauitalic_Ï„, we include only initialization times ğ’¯~âŠ†ğ’¯~ğ’¯ğ’¯\\tilde{\\mathcal{T}}\\subseteq\\mathcal{T}over~ start_ARG caligraphic_T end_ARG âŠ† caligraphic_T such that t0+Ï„subscriptğ‘¡0ğœt_{0}+\\tauitalic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_Ï„ falls on the day of interest for t0âˆˆğ’¯~subscriptğ‘¡0~ğ’¯t_{0}\\in\\tilde{\\mathcal{T}}italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT âˆˆ over~ start_ARG caligraphic_T end_ARG.\n\nIn Figure 2, we also include two contours that indicate the long-term average HRES performance for \\qty120 (D5subscriptğ·5D_{5}italic_D start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT) and \\qty240 (D10subscriptğ·10D_{10}italic_D start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT) forecasts. To estimate these values, we use all HRES forecasts provided by WeatherBench 2 (Rasp et al., 2024), which at the time of the writing contain only initializations at 00/12 UTC between January 1, 2016, and January 10, 2023. We use HRES-fc0 as the ground truth and only consider predictions for days within a window size of 45 days around the day-of-year of June 28, 2021. Numerical values for the grid boxes closest to the three investigated cities are provided in Table A.1.\n\nA.2 Further Analysis on the Spatial Extent of Forecasts\n\nTo further analyze the spatial aspect of the predictions, we first compute T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT anomalies. We use the climatology provided by WeatherBench 2 (Rasp et al., 2024), which is computed from ERA5 data between \\qty1990 and \\qty2019 (inclusive) and uses a sliding window of \\qty61 around the day of interest. For simplicity we also use the ERA5 climatology in the computation of the HRES and HRES-fc0 anomalies, acknowledging that there are differences in the climatologies of ERA5 and HRES-fc0. In panels A0 to A4 of Figure A1, we show in black the contour of the area in which the calculated true temperature anomaly, averaged between June 27 to 29 (inclusive), exceeds \\qty12.\n\nWe then look at forecasts initialized from \\qty7 to \\qty6 (with a time step of \\qty6) before June 27, 00 UTC. For each grid cell, we determine the percentage of the forecasts that predict the average temperature anomaly to exceed \\qty12 and plot this in panels A0 to A3) of Figure A1. An ideal prediction system would always predict an anomaly of â‰¥\\qtyâ¢12absent\\qty12\\geq\\qty{12}{}â‰¥ 12 everywhere within the black contour, and an anomaly <\\qtyâ¢12absent\\qty12<\\qty{12}{}< 12 everywhere outside the contour.\n\nOverall, the shapes of the predicted anomalies follow the shape of the true event well, i.e. heat was predicted in areas where it later actually occurred, and no large anomalies were predicted in regions where no large anomalies occurred. For FourCastNet, the anomaly as <\\qtyâ¢12absent\\qty12<\\qty{12}{}< 12 everywhere for a large fraction of the forecasts - the yellow colors within the contour are faint. For GraphCast and HRES, the predicted area matches the contour well, meaning that a large fraction of the forecasts captured the right spatial distribution. For PanguWeather, more forecasts reach large positive anomalies than for GraphCast and HRES, this is reflected by brighter yellow colors. At the same time, PanguWeather is the only model whose forecasts â€œspill outâ€ of the true \\qty12 contour notably, i.e. for PanguWeather some of the forecasts predicted anomalies â‰¥\\qtyâ¢12absent\\qty12\\geq\\qty{12}{}â‰¥ 12 in regions where they didnâ€™t occur in the ground truth data sets.\n\nNext, we compute the prediction error of the June 27 to 29 temperature anomaly for each grid cell and then take the (area-weighted) average over all pixels within the area in which the true anomaly exceeded \\qty12 over these days. The results for the different models are shown in Figure A1. FourCastNet strongly under-predicts the temperature anomaly within the contour for initialization times before June 24, while the other models have better predictions of the magnitude of the heatwave sooner. PanguWeatherâ€™s forecasts initialized on June 20 and June 21 predict notably warmer temperatures than HRES and GraphCast. PanguWeather and GraphCast slightly under-predict the size of the anomaly until the start of the event, while for HRES the under-prediction is smaller. One needs to keep in mind that the ERA5 ground truth and the HRES-fc0 ground truth donâ€™t coincide exactly, and thus it is not clear whether one can attribute this slight under-predictions of GraphCast and PanguWeather to model deficiencies.\n\nA.3 Additional Figures\n\nIn this subsection, we show additional figures on our analysis of the 2021 Pacific Northwest Heatwave.\n\nAppendix B Further Details and Analysis of the 2023 South Asian Humid Heatwave\n\nB.1 Shape Files\n\nIn Section 3.2, we use shape files to subset the study regions of the South Asian humid heatwave. We use country boundaries from the â€œWorld Administrative Boundaries - Countries and Territoriesâ€ (Open Government License 3.0, https://public.opendatasoft.com/explore/dataset/world-administrative-boundaries/information/) data set by the World Food Programme and for the India-Bangladesh region we additionally use the (1976-2000) map of â€œWorld Maps of the KÃ¶ppen-Geiger Climate Classificationâ€ (Creative Commons Attribution 4.0, https://datacatalog.worldbank.org/search/dataset/0042325). We only include grid cells with KÃ¶ppen-Geiger Class A (â€œtropicalâ€) in the India-Bangladesh region.\n\nB.2 Relative Humidity\n\nRelative humidity is required to compute the heat index, but PanguWeather (Bi et al., 2023) and GraphCast (Lam et al., 2023) only produce specific humidity, and only on atmospheric pressure levels, not at the surface. Therefore we first need to compute relative humidity from specific humidity. We exclude FourCastNet (Pathak et al., 2022) from the case study in Section 3.2 because here humidity is only available at pressure levels higher than \\qty850\\hecto.\n\nTo convert specific humidity to relative humidity from the machine learning models, we first compute the saturation vapor pressure at the respective pressure level using the Augustâ€“Rocheâ€“Magnus formula:\n\nesâ¢(T)=\\qtyâ¢6.1094â¢\\hectoâ¢expâ¡(17.625â¢TT+243.04)subscriptğ‘’ğ‘ ğ‘‡\\qty6.1094\\hecto17.625ğ‘‡ğ‘‡243.04e_{s}(T)=\\qty{6.1094}{\\hecto}\\exp\\left(\\frac{$17.625$T}{T+$243.04$}\\right)italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_T ) = 6.1094 roman_exp ( divide start_ARG 17.625 italic_T end_ARG start_ARG italic_T + 243.04 end_ARG ) (3)\n\nwhere Tğ‘‡Titalic_T is the temperature at the respective pressure level in \\unit. We compute the mixing ratio at saturation rssubscriptğ‘Ÿğ‘ r_{s}italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT (dimensionless) from pressure and saturation vapor pressure:\n\nrs=0.622â¢espâˆ’essubscriptğ‘Ÿğ‘ 0.622subscriptğ‘’ğ‘ ğ‘subscriptğ‘’ğ‘ r_{s}=0.622\\frac{e_{s}}{p-e_{s}}italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 0.622 divide start_ARG italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG start_ARG italic_p - italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG (4)\n\nwhere pğ‘pitalic_p is the pressure defining the pressure level. We then compute relative humidity Râ¢Hğ‘…ğ»RHitalic_R italic_H from the mixing ratio at saturation and the specific humidity qğ‘qitalic_q:\n\nRâ¢H=q(1âˆ’q)â¢rs,ğ‘…ğ»ğ‘1ğ‘subscriptğ‘Ÿğ‘ RH=\\frac{q}{(1-q)r_{s}},italic_R italic_H = divide start_ARG italic_q end_ARG start_ARG ( 1 - italic_q ) italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG , (5)\n\nwhere specific humidity is given in \\unit\\per\\kilo, and relative humidity is given in percent throughout the rest of the study. We emphasize again that Râ¢Hğ‘…ğ»RHitalic_R italic_H is not the relative humidity at the surface, which is not available for the ML models, but rather the humidity at pressure levels.\n\nFor HRES and ERA5, we compute relative humidity from 2â¢m2ğ‘š2m2 italic_m temperature T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT and 2â¢m2ğ‘š2m2 italic_m dewpoint temperature Tdsubscriptğ‘‡ğ‘‘T_{d}italic_T start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT:\n\nRâ¢H=esâ¢(Td)esâ¢(T2â¢m),ğ‘…ğ»subscriptğ‘’ğ‘ subscriptğ‘‡ğ‘‘subscriptğ‘’ğ‘ subscriptğ‘‡2ğ‘šRH=\\frac{e_{s}(T_{d})}{e_{s}(T_{2m})},italic_R italic_H = divide start_ARG italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_T start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) end_ARG start_ARG italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT ) end_ARG , (6)\n\nwhere essubscriptğ‘’ğ‘ e_{s}italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT was computed using formula 3 with T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT and Tdsubscriptğ‘‡ğ‘‘T_{d}italic_T start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT given in degrees Celsius.\n\nB.3 Heat Index\n\nAs described in Section 3.2, we follow Zachariah et al. (2023) during the computation of the heat index in using a modified version of the heat index (Rothfusz and Headquarters, 1990) used by NOAA Weather Prediction Center (WPC). The NOAA WPC formulation is accessible at https://www.wpc.ncep.noaa.gov/html/heatindex_equation.shtml (last accessed April 5 2024, page last modified May 12 2022 19:37:55 UTC).\n\nIn the following, the heat index formula is given for temperature in \\unitF. We transform the temperature input to \\unitF and the heat index output to \\unit in the study.\n\nTo obtain the heat index Hâ¢Iğ»ğ¼HIitalic_H italic_I, a simplified version Hâ¢Isğ»subscriptğ¼ğ‘ HI_{s}italic_H italic_I start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT is computed first:\n\nHâ¢Is=0.5â¢(T2â¢m+61+1.2â¢(T2â¢mâˆ’68)+0.094â¢Râ¢H)ğ»subscriptğ¼ğ‘ 0.5subscriptğ‘‡2ğ‘š611.2subscriptğ‘‡2ğ‘š680.094ğ‘…ğ»HI_{s}=0.5(T_{2m}+61+1.2(T_{2m}-68)+0.094RH)italic_H italic_I start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 0.5 ( italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT + 61 + 1.2 ( italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT - 68 ) + 0.094 italic_R italic_H ) (7)\n\nwhere T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT is the 2â¢m2ğ‘š2m2 italic_m temperature in \\unitF, and Râ¢Hğ‘…ğ»RHitalic_R italic_H is the relative humidity given as a percent value between 00 and 100100100100. If (Hâ¢Is+T2â¢m)/2ğ»subscriptğ¼ğ‘ subscriptğ‘‡2ğ‘š2(HI_{s}+T_{2m})/2( italic_H italic_I start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT + italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT ) / 2 is smaller than or equal to \\qty80F, the computation is complete, and the heat index is used as computed in equation 7. Otherwise, the heat index is recomputed using a more elaborate formula:\n\nHâ¢I=âˆ’42.379+2.04901523â¢T2â¢m+10.14333127â¢Râ¢Hâˆ’0.22475541â¢T2â¢mâ¢Râ¢Hâˆ’0.00683783â¢T2â¢m2âˆ’0.05481717â¢Râ¢H2+0.00122874â¢T2â¢m2â¢Râ¢H+0.00085282â¢T2â¢mâ¢Râ¢H2âˆ’0.00000199â¢T2â¢m2â¢Râ¢H2ğ»ğ¼42.3792.04901523subscriptğ‘‡2ğ‘š10.14333127ğ‘…ğ»0.22475541subscriptğ‘‡2ğ‘šğ‘…ğ»0.00683783superscriptsubscriptğ‘‡2ğ‘š20.05481717ğ‘…superscriptğ»20.00122874superscriptsubscriptğ‘‡2ğ‘š2ğ‘…ğ»0.00085282subscriptğ‘‡2ğ‘šğ‘…superscriptğ»20.00000199superscriptsubscriptğ‘‡2ğ‘š2ğ‘…superscriptğ»2\\begin{split}HI=&-42.379+2.04901523T_{2m}+10.14333127RH-0.22475541T_{2m}RH\\\\ &-0.00683783T_{2m}^{2}-0.05481717RH^{2}+0.00122874T_{2m}^{2}RH\\\\ &+0.00085282T_{2m}RH^{2}-0.00000199T_{2m}^{2}RH^{2}\\end{split}start_ROW start_CELL italic_H italic_I = end_CELL start_CELL - 42.379 + 2.04901523 italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT + 10.14333127 italic_R italic_H - 0.22475541 italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT italic_R italic_H end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL - 0.00683783 italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 0.05481717 italic_R italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 0.00122874 italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_R italic_H end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL + 0.00085282 italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT italic_R italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 0.00000199 italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_R italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_CELL end_ROW (8)\n\nIf Râ¢H<\\qtyâ¢13ğ‘…ğ»\\qty13RH<\\qty{13}{}italic_R italic_H < 13 and \\qtyâ¢80â¢F<T2â¢m<\\qtyâ¢112â¢F\\qty80ğ¹subscriptğ‘‡2ğ‘š\\qty112ğ¹\\qty{80}{F}<T_{2m}<\\qty{112}{F}80 italic_F < italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT < 112 italic_F, the heat index computed according to equation 8 is corrected:\n\nHâ¢I=Hâ¢Iâˆ’13âˆ’Râ¢H4â¢(17âˆ’|T2â¢mâˆ’95|)/17ğ»ğ¼ğ»ğ¼13ğ‘…ğ»417subscriptğ‘‡2ğ‘š9517HI=HI-\\frac{13-RH}{4}\\sqrt{(17-|T_{2m}-95|)/17}italic_H italic_I = italic_H italic_I - divide start_ARG 13 - italic_R italic_H end_ARG start_ARG 4 end_ARG square-root start_ARG ( 17 - | italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT - 95 | ) / 17 end_ARG (9)\n\nA different correction is applied if Râ¢H>\\qtyâ¢85ğ‘…ğ»\\qty85RH>\\qty{85}{}italic_R italic_H > 85 and \\qtyâ¢80â¢F<T2â¢m<\\qtyâ¢87â¢F\\qty80ğ¹subscriptğ‘‡2ğ‘š\\qty87ğ¹\\qty{80}{F}<T_{2m}<\\qty{87}{F}80 italic_F < italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT < 87 italic_F:\n\nHâ¢I=Hâ¢I+(Râ¢Hâˆ’85)10â¢87âˆ’T2â¢m5ğ»ğ¼ğ»ğ¼ğ‘…ğ»851087subscriptğ‘‡2ğ‘š5HI=HI+\\frac{(RH-85)}{10}\\frac{87-T_{2m}}{5}italic_H italic_I = italic_H italic_I + divide start_ARG ( italic_R italic_H - 85 ) end_ARG start_ARG 10 end_ARG divide start_ARG 87 - italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT end_ARG start_ARG 5 end_ARG (10)\n\nWe always use the \\qty2 temperature T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT in the computation of the heat index. If the relative humidity is not available at the surface level, we specify in the text, how we substitute the value at the surface.\n\nB.4 Humid Heatwave in the Laos-Thailand region\n\nIn Figure B1, again the ground truth ERA5 and HRES-fc0 data sets donâ€™t yield the same Hâ¢Iğ»ğ¼HIitalic_H italic_I values. HRES follows its ground truth well, while the ML prediction models under-predict the high Hâ¢Iğ»ğ¼HIitalic_H italic_I values when compared to their ERA5 ground truth computed using Râ¢H\\qtyâ¢1000â¢\\hectoğ‘…subscriptğ»\\qty1000\\hectoRH_{\\qty{1000}{\\hecto}}italic_R italic_H start_POSTSUBSCRIPT 1000 end_POSTSUBSCRIPT and the version computed with Râ¢Hsâ¢fâ¢cğ‘…subscriptğ»ğ‘ ğ‘“ğ‘RH_{sfc}italic_R italic_H start_POSTSUBSCRIPT italic_s italic_f italic_c end_POSTSUBSCRIPT.\n\nThe under-prediction of Hâ¢Iğ»ğ¼HIitalic_H italic_I can also be seen in Figure B2, where the forecast error is compared to the â€œtrueâ€ heat index computed from values at the surface. Again, if compared with the ERA5 Hâ¢Iğ»ğ¼HIitalic_H italic_I version computed from Râ¢H\\qtyâ¢1000â¢\\hectoğ‘…subscriptğ»\\qty1000\\hectoRH_{\\qty{1000}{\\hecto}}italic_R italic_H start_POSTSUBSCRIPT 1000 end_POSTSUBSCRIPT, the predicions are overall too low (See Figure B3). In this case, the bias seems to be driven by too low T2â¢msubscriptğ‘‡2ğ‘šT_{2m}italic_T start_POSTSUBSCRIPT 2 italic_m end_POSTSUBSCRIPT.\n\nB.5 Additional Figures\n\nIn this subsection, we show additional figures on our analysis of the 2023 South Asian Humid Heatwave.\n\nAppendix C Further Analysis of the 2021 North American Winter Storm\n\nAdditional Figures\n\nIn this subsection, we show additional figures on our analysis of the 2021 North American Winter Storm.\n\nAppendix D Details on ML Models\n\nFurther Details on ML Models\n\nIn Table D.1 we list the surface and pressure-level variables predicted by the ML models.\n\nReferences\n\nAllouche et al. (2024) Allouche, M., Girard, S., and Gobet, E. Estimation of extreme quantiles from heavy-tailed distributions with neural networks. Stat. and Comput., 34(12), 2024.\n\nAndrychowicz et al. (2023) Andrychowicz, M., Espeholt, L., Li, D., Merchant, S., Merose, A., Zyda, F., Agrawal, S., and Kalchbrenner, N. Deep learning for day forecasts from sparse observations, 2023. arXiv:2306.06079.\n\nBartusek et al. (2022) Bartusek, S., Kornhuber, K., and Ting, M. 2021 North American heatwave amplified by climate change-driven nonlinear interactions. Nature Climate Change, page 1143â€“1150, 2022. ISSN 1758-678X. doi:10.1038/s41558-022-01520-4. URL https://www.nature.com/articles/s41558-022-01520-4.\n\nBen-Bouallegue et al. (2023) Ben-Bouallegue, Z., Clare, M. C. A., Magnusson, L., Gascon, E., Maier-Gerber, M., Janousek, M., Rodwell, M., Pinault, F., Dramsch, J. S., Lang, S. T. K., Raoult, B., Rabier, F., Chevallier, M., Sandu, I., Dueben, P., Chantry, M., and Pappenberger, F. The rise of data-driven weather forecasting, 2023. arXiv:2307.10128.\n\nBi et al. (2023) Bi, K., Xie, L., Zhang, H., Chen, X., Gu, X., and Tian, Q. Accurate medium-range global weather forecasting with 3D neural networks. Nature, 619(7970):533â€“538, July 2023. ISSN 1476-4687. doi:10.1038/s41586-023-06185-3.\n\nBlazejczyk et al. (2012) Blazejczyk, K., Epstein, Y., Jendritzky, G., Staiger, H., and Tinz, B. Comparison of utci to selected thermal indices. International journal of biometeorology, 56:515â€“535, 2012. doi:10.1007/s00484-011-0453-2.\n\nBonavita (2023) Bonavita, M. On the limitations of data-driven weather forecasting models, Sept. 2023. arXiv:2309.08473.\n\nBremnes et al. (2023) Bremnes, J. B., Nipen, T. N., and Seierstad, I. A. Evaluation of forecasts by a global data-driven weather model with and without probabilistic post-processing at norwegian stations, 2023. arXiv:2309.01247.\n\nBurnell et al. (2023) Burnell, R., Schellaert, W., Burden, J., Ullman, T. D., Martinez-Plumed, F., Tenenbaum, J. B., Rutar, D., Cheke, L. G., Sohl-Dickstein, J., Mitchell, M., Kiela, D., Shanahan, M., Voorhees, E. M., Cohn, A. G., Leibo, J. Z., and Hernandez-Orallo, J. Rethink reporting of evaluation results in AI. Science, 380(6641):136â€“138, Apr. 2023. ISSN 0036-8075, 1095-9203. doi:10.1126/science.adf6369.\n\nBuzan and Huber (2020) Buzan, J. R. and Huber, M. Moist Heat Stress on a Hotter Earth. Annual Review of Earth and Planetary Sciences, 48(1):623â€“655, May 2020. ISSN 0084-6597, 1545-4495. doi:10.1146/annurev-earth-053018-060100.\n\nBÃ¼lte et al. (2024) BÃ¼lte, C., Horat, N., Quinting, J., and Lerch, S. Uncertainty quantification for data-driven weather models, 2024. arXiv:2403.13458.\n\nCharlton-Perez et al. (2024) Charlton-Perez, A. J., Dacre, H. F., Driscoll, S., Gray, S. L., Harvey, B., Harvey, N. J., Hunt, K. M. R., Lee, R. W., Swaminathan, R., Vandaele, R., and VolontÃ©, A. Do AI models produce better weather forecasts than physics-based models? A quantitative evaluation case study of Storm CiarÃ¡n. npj Climate and Atmospheric Science, 7(1):93, Apr. 2024. ISSN 2397-3722. doi:10.1038/s41612-024-00638-w.\n\nChen et al. (2023a) Chen, K., Han, T., Gong, J., Bai, L., Ling, F., Luo, J.-J., Chen, X., Ma, L., Zhang, T., Su, R., Ci, Y., Li, B., Yang, X., and Ouyang, W. FengWu: Pushing the skillful global medium-range weather forecast beyond 10 days lead, 2023a. arXiv:2304.02948.\n\nChen et al. (2023b) Chen, L., Zhong, X., Zhang, F., Cheng, Y., Xu, Y., Qi, Y., and Li, H. FuXi: A cascade machine learning forecasting system for 15-day global weather forecast. npj Climate and Atmospheric Science, 6(1):190, Nov. 2023b. ISSN 2397-3722. doi:10.1038/s41612-023-00512-1.\n\nChen and Meinshausen (2023) Chen, X. and Meinshausen, N. Engression: Extrapolation for nonlinear regression?, 2023. arXiv:2307.00835.\n\nCisneros et al. (2023) Cisneros, D., Richards, J., Dahal, A., Lombardo, L., and Huser, R. Deep graphical regression for jointly moderate and extreme Australian wildfires. ArXiv:2308.14547, 2023.\n\nColes (2001) Coles, S. An Introduction to Statistical Modeling of Extreme Values. Springer London, 2001.\n\nEspeholt et al. (2022) Espeholt, L., Agrawal, S., SÃ¸nderby, C., Kumar, M., Heek, J., Bromberg, C., Gazen, C., Carver, R., Andrychowicz, M., Hickey, J., Bell, A., and Kalchbrenner, N. Deep learning for twelve hour precipitation forecasts. Nature Communications, 13(1):5145, Sept. 2022. ISSN 2041-1723. doi:10.1038/s41467-022-32483-x.\n\nGasparrini et al. (2015) Gasparrini, A., Guo, Y., Hashizume, M., Lavigne, E., Zanobetti, A., Schwartz, J., Tobias, A., Tong, S., RocklÃ¶v, J., Forsberg, B., Leone, M., De Sario, M., Bell, M. L., Guo, Y.-L. L., Wu, C.-f., Kan, H., Yi, S.-M., de Sousa Zanotti Stagliorio Coelho, M., Saldiva, P. H. N., Honda, Y., Kim, H., and Armstrong, B. Mortality risk attributable to high and low ambient temperature: A multicountry observational study. The Lancet, 386(9991):369â€“375, July 2015. ISSN 01406736. doi:10.1016/S0140-6736(14)62114-0.\n\nGnecco et al. (2024) Gnecco, N., Terefe, E. M., and Engelke, S. Extremal Random Forests. to appear in J. Am. Stat. Assoc., 2024. ArXiv:2201.12865.\n\nGruber et al. (2022) Gruber, K., Gauster, T., Laaha, G., Regner, P., and Schmidt, J. Profitability and investment risk of Texan power system winterization. Nature Energy, 7(5):409â€“416, Apr. 2022. ISSN 2058-7546. doi:10.1038/s41560-022-00994-y.\n\nHastie et al. (2009) Hastie, T., Tibshirani, R., and Friedman, J. The Elements of Statistical Learning. Springer New York, 2009.\n\nHersbach et al. (2020) Hersbach, H., Bell, B., Berrisford, P., Hirahara, S., HorÃ¡nyi, A., MuÃ±oz-Sabater, J., Nicolas, J., Peubey, C., Radu, R., Schepers, D., Simmons, A., Soci, C., Abdalla, S., Abellan, X., Balsamo, G., Bechtold, P., Biavati, G., Bidlot, J., Bonavita, M., De Chiara, G., Dahlgren, P., Dee, D., Diamantakis, M., Dragani, R., Flemming, J., Forbes, R., Fuentes, M., Geer, A., Haimberger, L., Healy, S., Hogan, R. J., HÃ³lm, E., JaniskovÃ¡, M., Keeley, S., Laloyaux, P., Lopez, P., Lupu, C., Radnoti, G., de Rosnay, P., Rozum, I., Vamborg, F., Villaume, S., and ThÃ©paut, J.-N. The ERA5 global reanalysis. Quarterly Journal of the Royal Meteorological Society, 146(730):1999â€“2049, July 2020. ISSN 0035-9009, 1477-870X. doi:10.1002/qj.3803.\n\nKochkov et al. (2023) Kochkov, D., Yuval, J., Langmore, I., Norgaard, P., Smith, J., Mooers, G., Lottes, J., Rasp, S., DÃ¼ben, P., KlÃ¶wer, M., Hatfield, S., Battaglia, P., Sanchez-Gonzalez, A., Willson, M., Brenner, M. P., and Hoyer, S. Neural General Circulation Models, Nov. 2023. arXiv:2311.07222.\n\nLam et al. (2023) Lam, R., Sanchez-Gonzalez, A., Willson, M., Wirnsberger, P., Fortunato, M., Alet, F., Ravuri, S., Ewalds, T., Eaton-Rosen, Z., Hu, W., Merose, A., Hoyer, S., Holland, G., Vinyals, O., Stott, J., Pritzel, A., Mohamed, S., and Battaglia, P. Learning skillful medium-range global weather forecasting. Science, page eadi2336, Nov. 2023. ISSN 0036-8075, 1095-9203. doi:10.1126/science.adi2336.\n\nLavers et al. (2022) Lavers, D. A., Simmons, A., Vamborg, F., and Rodwell, M. J. An evaluation of ERA5 precipitation for climate monitoring. Quarterly Journal of the Royal Meteorological Society, 148(748):3152â€“3165, Oct. 2022. ISSN 0035-9009, 1477-870X. doi:10.1002/qj.4351.\n\nLeinonen et al. (2023) Leinonen, J., Hamann, U., Nerini, D., Germann, U., and Franch, G. Latent diffusion models for generative precipitation nowcasting with accurate uncertainty quantification, 2023. arXiv:2304.12891.\n\nLin et al. (2022) Lin, H., Mo, R., and Vitart, F. The 2021 Western North American Heatwave and Its Subseasonal Predictions. Geophysical Research Letters, 49(6):e2021GL097036, Mar. 2022. ISSN 0094-8276, 1944-8007. doi:10.1029/2021GL097036.\n\nLo et al. (2023) Lo, Y. T. E., Mitchell, D. M., Buzan, J. R., Zscheischler, J., Schneider, R., Mistry, M. N., KyselÃ½, J., Lavigne, Ã‰., da Silva, S. P., RoyÃ©, D., Urban, A., Armstrong, B., Multi-Country Multi-City (MCC) Collaborative Research Network, Gasparrini, A., and Vicedo-Cabrera, A. M. Optimal heat stress metric for modelling heat-related mortality varies from country to country. International Journal of Climatology, page joc.8160, July 2023. ISSN 0899-8418, 1097-0088. doi:10.1002/joc.8160.\n\nLopez-Gomez et al. (2023) Lopez-Gomez, I., McGovern, A., Agrawal, S., and Hickey, J. Global Extreme Heat Forecasting Using Neural Weather Models. Artificial Intelligence for the Earth Systems, 2(1):e220035, Jan. 2023. ISSN 2769-7525. doi:10.1175/AIES-D-22-0035.1.\n\nMagnusson (2023) Magnusson, L. Exploring machine-learning forecasts of extreme weather. https://www.ecmwf.int/en/newsletter/176/news/exploring-machine-learning-forecasts-extreme-weather, July 2023.\n\nNational Weather Service (2021) National Weather Service. Valentineâ€™s Week Winter Outbreak 2021: Snow, Ice, & Record Cold. https://www.weather.gov/hgx/2021ValentineStorm, 2021.\n\nNeal et al. (2022) Neal, E., Huang, C. S. Y., and Nakamura, N. The 2021 Pacific Northwest Heat Wave and Associated Blocking: Meteorology and the Role of an Upstream Cyclone as a Diabatic Source of Wave Activity. Geophysical Research Letters, 49(8):e2021GL097699, Apr. 2022. ISSN 0094-8276, 1944-8007. doi:10.1029/2021GL097699.\n\nNearing et al. (2024) Nearing, G., Cohen, D., Dube, V., Gauch, M., Gilon, O., Harrigan, S., Hassidim, A., Klotz, D., Kratzert, F., Metzger, A., Nevo, S., Pappenberger, F., Prudhomme, C., Shalev, G., Shenzis, S., Tekalign, T. Y., Weitzner, D., and Matias, Y. Global prediction of extreme floods in ungauged watersheds. Nature, 627(8004):559â€“563, Mar. 2024. ISSN 0028-0836, 1476-4687. doi:10.1038/s41586-024-07145-1.\n\nNguyen et al. (2023a) Nguyen, T., Brandstetter, J., Kapoor, A., Gupta, J. K., and Grover, A. Climax: A foundation model for weather and climate, 2023a. arXiv:2301.10343.\n\nNguyen et al. (2023b) Nguyen, T., Shah, R., Bansal, H., Arcomano, T., Madireddy, S., Maulik, R., Kotamarthi, V., Foster, I., and Grover, A. Scaling transformer neural networks for skillful and reliable medium-range weather forecasting, 2023b. arXiv:2301.03876.\n\nOlivetti and Messori (2024a) Olivetti, L. and Messori, G. Advances and prospects of deep learning for medium-range extreme weather forecasting. Geoscientific Model Development, 17(6):2347â€“2358, 2024a. doi:10.5194/gmd-17-2347-2024. URL https://gmd.copernicus.org/articles/17/2347/2024/.\n\nOlivetti and Messori (2024b) Olivetti, L. and Messori, G. Do data-driven models beat numerical models in forecasting weather extremes? A comparison of IFS HRES, Pangu-Weather and GraphCast, Apr. 2024b. URL https://egusphere.copernicus.org/preprints/2024/egusphere-2024-1042.\n\nOsczevski and Bluestein (2005) Osczevski, R. and Bluestein, M. THE NEW WIND CHILL EQUIVALENT TEMPERATURE CHART. Bulletin of the American Meteorological Society, 86(10):1453â€“1458, Oct. 2005. ISSN 0003-0007, 1520-0477. doi:10.1175/BAMS-86-10-1453.\n\nOwens and Hewson (2018) Owens, R. and Hewson, T. ECMWF Forecast User Guide, 2018.\n\nPasche and Engelke (2022) Pasche, O. C. and Engelke, S. Neural networks for extreme quantile regression with an application to forecasting of flood risk, 2022. ArXiv:2208.07590.\n\nPathak et al. (2022) Pathak, J., Subramanian, S., Harrington, P., Raja, S., Chattopadhyay, A., Mardani, M., Kurth, T., Hall, D., Li, Z., Azizzadenesheli, K., Hassanzadeh, P., Kashinath, K., and Anandkumar, A. FourCastNet: A global data-driven high-resolution weather model using adaptive fourier neural operators, 2022. arXiv:2202.11214.\n\nPfister and BÃ¼hlmann (2024) Pfister, N. and BÃ¼hlmann, P. Extrapolation-aware nonparametric statistical inference, 2024. arXiv:2402.09758.\n\nPhilip et al. (2022) Philip, S. Y., Kew, S., van Oldenborgh, G. J., Anslow, F. S., Seneviratne, S. I., Vautard, R., Coumou, D., Ebi, K. L., Arrighi, J., Singh, R., van Aalst, M., Pereira Marghidan, C., Wehner, M., Yang, W., Li, S., Schumacher, D. L., Hauser, M., Bonnet, R., Luu, L. N., Lehner, F., Gillett, N., Tradowsky, J. S., Vecchi, G. A., Rodell, C., Stull, R. B., Howard, R., and Otto, F. E. L. Rapid attribution analysis of the extraordinary heat wave on the Pacific coast of the US and Canada in June 2021. Earth System Dynamics, 13(4):1689â€“1713, 12 2022. ISSN 2190-4987. doi:10.5194/esd-13-1689-2022.\n\nPrice et al. (2023) Price, I., Sanchez-Gonzalez, A., Alet, F., Ewalds, T., El-Kadi, A., Stott, J., Mohamed, S., Battaglia, P., Lam, R., and Willson, M. GenCast: Diffusion-based ensemble forecasting for medium-range weather, Dec. 2023. arXiv:2312.15796.\n\nRasp and Thuerey (2021) Rasp, S. and Thuerey, N. Data-Driven Medium-Range Weather Prediction With a Resnet Pretrained on Climate Simulations: A New Model for WeatherBench. Journal of Advances in Modeling Earth Systems, 13(2), Feb. 2021. ISSN 1942-2466, 1942-2466. doi:10.1029/2020MS002405.\n\nRasp et al. (2024) Rasp, S., Hoyer, S., Merose, A., Langmore, I., Battaglia, P., Russel, T., Sanchez-Gonzalez, A., Yang, V., Carver, R., Agrawal, S., Chantry, M., Bouallegue, Z. B., Dueben, P., Bromberg, C., Sisk, J., Barrington, L., Bell, A., and Sha, F. WeatherBench 2: A benchmark for the next generation of data-driven global weather models, Jan. 2024. arXiv:2308.15560.\n\nRichards and Huser (2022) Richards, J. and Huser, R. Regression modelling of spatiotemporal extreme u.s. wildfires via partially-interpretable neural networks, 2022. arXiv:2208.07581.\n\nRothfusz and Headquarters (1990) Rothfusz, L. P. and Headquarters, N. S. R. The heat index equation (or, more than you ever wanted to know about heat index). Fort Worth, Texas: National Oceanic and Atmospheric Administration, National Weather Service, Office of Meteorology, 9023:640, 1990.\n\nRÃ¶thlisberger and Papritz (2023) RÃ¶thlisberger, M. and Papritz, L. Quantifying the physical processes leading to atmospheric hot extremes at a global scale. Nature Geoscience, 16(3):210â€“216, Mar. 2023. ISSN 1752-0908. doi:10.1038/s41561-023-01126-1.\n\nSchumacher et al. (2022) Schumacher, D. L., Hauser, M., and Seneviratne, S. I. Drivers and Mechanisms of the 2021 Pacific Northwest Heatwave. Earthâ€™s Future, 10(12):e2022EF002967, Dec. 2022. ISSN 2328-4277, 2328-4277. doi:10.1029/2022EF002967.\n\nSelz and Craig (2023) Selz, T. and Craig, G. C. Can Artificial Intelligence-Based Weather Prediction Models Simulate the Butterfly Effect? Geophysical Research Letters, 50(20):e2023GL105747, Oct. 2023. ISSN 0094-8276, 1944-8007. doi:10.1029/2023GL105747.\n\nSeneviratne et al. (2021) Seneviratne, S. I., Zhang, X., Adnan, M., Badi, W., Dereczynski, C., Di Luca, A., Ghosh, S., Iskander, I., Kossin, J., Lewis, S., Otto, F., Pinto, I., Satoh, M., Vicente-Serrano, S. M., Wehner, M., and Zhou, B. Weather and Climate Extreme Events in a Changing Climate (Chapter 11). In Masson-Delmotte, V., Zhai, P., Pirani, A., Connors, S. L., PÃ©an, C., Berger, S., Caud, N., Chen, Y., Goldfarb, L., Gomis, M. I., Huang, M., Leitzell, K., Lonnoy, E., Matthews, J. B. R., Maycock, T. K., Waterfield, T., YelekÃ§i, K., Yu, R., and Zhu, B., editors, Climate Change 2021: The Physical Science Basis. Contribution of Working Group I to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change, pages 1513â€“1766. Cambridge University Press, Cambridge, United Kingdom and New York, NY, USA, 2021. ISBN 978-1-00-915789-6. doi:10.1017/9781009157896.013.\n\nSmith et al. (2011) Smith, A., Lott, N., and Vose, R. The integrated surface database: Recent developments and partnerships. Bulletin of the American Meteorological Society, 92(6):704â€“708, 2011. doi:10.1175/2011BAMS3015.1.\n\nVelthoen et al. (2023) Velthoen, J., Dombry, C., Cai, J.-J., and Engelke, S. Gradient boosting for extreme quantile regression. Extremes, 26:639â€“667, 2023. ArXiv:2103.00808.\n\nWatson (2022) Watson, P. A. G. Machine learning applications for weather and climate need greater focus on extremes. Environmental Research Letters, 17(11):111004, Nov. 2022. ISSN 1748-9326. doi:10.1088/1748-9326/ac9d4e.\n\nWeyn et al. (2021) Weyn, J. A., Durran, D. R., Caruana, R., and Cresswell-Clay, N. Sub-Seasonal Forecasting With a Large Ensemble of Deep-Learning Weather Prediction Models. Journal of Advances in Modeling Earth Systems, 13(7), July 2021. ISSN 1942-2466, 1942-2466. doi:10.1029/2021MS002502.\n\nWhite et al. (2023) White, R. H., Anderson, S., Booth, J. F., Braich, G., Draeger, C., Fei, C., Harley, C. D. G., Henderson, S. B., Jakob, M., Lau, C.-A., Mareshet Admasu, L., Narinesingh, V., Rodell, C., Roocroft, E., Weinberger, K. R., and West, G. The unprecedented Pacific Northwest heatwave of June 2021. Nature Communications, 14(1):727, Feb. 2023. ISSN 2041-1723. doi:10.1038/s41467-023-36289-3.\n\nZachariah et al. (2023) Zachariah, M., Vautard, R., Chandrasekaran, R., Chaithra, ST., Kimutai, J., Arulalan, T., AchutaRao, K., Barnes, C., Singh, R., Vahlberg, M., Arrgihi, J., Raju, E., Sharma, U., Ogra, A., Vaddhanaphuti, C., Bahinipati, CS., Tschakert, P., Pereira Marghidan, C., Mondal, A., Schwingshackl, C., Philip, S., and Otto, F. Extreme humid heat in South Asia in April 2023, largely driven by climate change, detrimental to vulnerable and disadvantaged communities. Technical report, Imperial College London, May 2023.\n\nZeder et al. (2023) Zeder, J., Sippel, S., Pasche, O. C., Engelke, S., and Fischer, E. M. The Effect of a Short Observational Record on the Statistics of Temperature Extremes. Geophys. Res. Lett., 50(16), 2023. doi:10.1029/2023GL104090.\n\nZscheischler et al. (2020) Zscheischler, J., Martius, O., Westra, S., Bevacqua, E., Raymond, C., Horton, R. M., van den Hurk, B., AghaKouchak, A., JÃ©zÃ©quel, A., Mahecha, M. D., Maraun, D., Ramos, A. M., Ridder, N. N., Thiery, W., and Vignotto, E. A typology of compound weather and climate events. Nature Reviews Earth & Environment, 1(7):333â€“347, July 2020. ISSN 2662-138X. doi:10.1038/s43017-020-0060-z."
    }
}