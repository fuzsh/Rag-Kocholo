{
    "id": "dbpedia_721_1",
    "rank": 24,
    "data": {
        "url": "https://blog.pengjunjie.com/python.html",
        "read_more_link": "",
        "language": "en",
        "title": "ITBox Blog",
        "top_image": "https://pic1.zhimg.com/80/v2-79fd9ab21450015aa4b669bc0ac678f0_hd.jpg",
        "meta_img": "",
        "images": [
            "https://blog.pengjunjie.com/media/15668187060689/15668188229344.jpg",
            "https://blog.pengjunjie.com/media/15668187060689/15668190074864.jpg",
            "https://blog.pengjunjie.com/media/15667097163627/4929513d-d9ca-4733-8f16-4406ab9839b7.png",
            "http://blog.codecp.org/uploads/boot-fenye.jpg",
            "http://blog.codecp.org/uploads/showfenye.jpg",
            "https://blog.pengjunjie.com/media/15640692160050/15640692256413.jpg",
            "https://blog.pengjunjie.com/media/15641640533936/15641642546352.jpg",
            "https://blog.pengjunjie.com/media/15641640533936/15641643041071.jpg",
            "https://blog.pengjunjie.com/media/15641640533936/15641643757693.jpg",
            "https://blog.pengjunjie.com/media/15637119233711/15637126991025.jpg",
            "https://blog.pengjunjie.com/media/15637119233711/15637128739916.jpg",
            "https://blog.pengjunjie.com/media/15637119233711/15637143988572.jpg",
            "https://pic1.zhimg.com/80/v2-79fd9ab21450015aa4b669bc0ac678f0_hd.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "è¿ç¯æç« ççåçéå¸¸å¥½ï¼è®²è§£å°äºdjangoæ¯å¦ä½ä¸æ­¥ä¸æ­¥åæ§è½ä¼åçï¼å¯ä»¥ä¼åçç¹è¿æ¯å¾å¤çã\n\nFebruary 25, 2020\n\nOver the course of developing several Django apps, Iâve learned quite a bit about speed optimizations. Some parts of this process, whether on the backend or frontend, are not well-documented. Iâve decided to collect most of what I know in this article.\n\nIf you havenât taken a close look at the performance of your web-app yet, youâre bound to find something good here.\n\nÂ Whatâs in this article?\n\nWhy speed is important\n\nOn the web, 100 milliseconds can make a significant difference and 1 second is a lifetime. Countless studies indicate that faster loading times are associated with better conversion-rates, user-retention, and organic traffic from search engines. Most importantly, they provide a better user experience.\n\nDifferent apps, different bottlenecks\n\nThere areÂ manyÂ techniques and practices to optimize your web-appâs performance. Itâs easy to get carried away.Â Look for the highest return-to-effort ratio. Different web-apps have different bottlenecks and therefore will gain the most when those bottlenecks are taken care of. Depending on your app, some tips will be more useful than others.\n\nWhile this article is catered to Django developers, the speed optimization tips here can be adjusted to pretty much any stack. On the frontend side, itâs especially useful for people hosting with Heroku and who do not have access to aÂ CDNÂ service.\n\nAnalyzing and debugging performance issues\n\nOn the backend, I recommend the tried-and-trueÂ django-debug-toolbar. It will help you analyze your request/response cycles and see where most of the time is spent. Especially useful because it provides database query execution times and provides a niceÂ SQLÂ EXPLAINÂ in a separate pane that appears in the browser.\n\nGoogle PageSpeedÂ will display mainly frontend related advice, but some can apply to the backend as well (like server response times). PageSpeed scores do not directly correlate with loading times but should give you a good picture of where the low-hanging fruits for your app are. In development environments, you can useÂ Google Chromeâs LighthouseÂ which provides the same metrics but can work with local network URIs.Â GTmetrixÂ is another detail-rich analysis tool.\n\nDisclaimer\n\nSome people will tell you that some of the advice here is wrong or lacking. Thatâs okay; this is not meant to be a bible or the ultimate go-to-guide. Treat these techniques and tips as ones you may use, not should or must use. Different needs call for different setups.\n\nBackend: the database layer\n\nStarting with the backend is a good idea since itâs usually the layer thatâs supposed to do most of the heavy lifting behind the scenes.\n\nThereâs little doubt in my mind which twoÂ ORMÂ functionalities I want to mention first: these areÂ select_relatedÂ andÂ prefetch_related. They both deal specifically with retrieving related objects and will usually improve speed by minimizing the number of database queries.\n\nselect_related\n\nLetâs take a music web-app for example, which might have these models:\n\n# music/models.py, some fields & code omitted for brevity class RecordLabel(models.Model): name = models.CharField(max_length=560) class MusicRelease(models.Model): title = models.CharField(max_length=560) release_date = models.DateField() class Artist(models.Model): name = models.CharField(max_length=560) label = models.ForeignKey( RecordLabel, related_name=\"artists\", on_delete=models.SET_NULL ) music_releases = models.ManyToManyField( MusicRelease, related_name=\"artists\" )\n\nSo each artist is related to one and only one record company and each record company can sign multiple artists: a classic one-to-many relationship. Artists have many music-releases, and each release can belong to one artist or more.\n\nIâve created some dummy data:\n\n20 record labels\n\neach record label has 25 artists\n\neach artist has 100 music releases\n\nOverall, we have ~50,500 of these objects in our tiny database.\n\nNow letâs wire-up a fairly standard function that pulls our artists and their label.Â django_query_analyzeÂ is a decorator I wrote to count the number of database queries and time to run the function. Its implementation can be found in the appendix.\n\n# music/selectors.py @django_query_analyze def get_artists_and_labels(): result = [] artists = Artist.objects.all() for artist in artists: result.append({\"name\": artist.name, \"label\": artist.label.name}) return result\n\nget_artists_and_labelsÂ is a regular function which you may use in a Django view. It returns a list of dictionaries, each contains the artistâs name and their label. Iâm accessingÂ artist.label.nameÂ to force-evaluate the Django QuerySet; you can equate this to trying to access these objects in a Jinja template:\n\n{% for artist in artists_and_labels %} <p>Name: {{ artist.name }}, Label: {{ artist.label.name }}</p> {% endfor %}\n\nNow letâs run this function:\n\nran function get_artists_and_labels -------------------- number of queries: 501 Time of execution: 0.3585s\n\nSo weâve pulled 500 artists and their labels in 0.36 seconds, but more interestingly â weâve hit the database 501 times. Once for all the artists, and 500 more times:Â once for eachÂ of the artistsâ labels. This is calledÂ âThe N+1 problemâ. Letâs tell Django to retrieve each artistâsÂ labelÂ in the same query withÂ select_related:\n\n@django_query_analyze def get_artists_and_labels_select_related(): result = [] artists = Artist.objects.select_related(\"label\") # select_related for artist in artists: result.append( {\"name\": artist.name, \"label\": artist.label.name if artist.label else \"N/A\"} ) return result\n\nNow letâs run this:\n\nran function get_artists_and_labels_select_related -------------------- number of queries: 1 Time of execution: 0.01481s\n\n500 queries less and a 96% speed improvement.\n\nprefetch_related\n\nLetâs look at another function, for getting each artistâs first 100 music releases:\n\n@django_query_analyze def get_artists_and_releases(): result = [] artists = Artist.objects.all()[:100] for artist in artists: result.append( { \"name\": artist.name, \"releases\": [release.title for release in artist.music_releases.all()], } ) return result\n\nHow long does it take to fetch 100 artists and 100 releases for each one of them?\n\nran function get_artists_and_releases -------------------- number of queries: 101 Time of execution: 0.18245s\n\nLetâs change theÂ artistsÂ variable in this function and addÂ select_relatedÂ so we can bring the number of queries down and hopefully get a speed boost:\n\nartists = Artist.objects.select_related(\"music_releases\")\n\nIf you actually do that, youâll get an error:\n\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'music_releases'. Choices are: label\n\nThatâs becauseÂ select_relatedÂ can only be used to cache ForeignKey or OneToOneField attributes. The relationship betweenÂ ArtistÂ andÂ MusicReleaseÂ is many-to-many though, and thatâs whereÂ prefetch_ relatedÂ comes in:\n\n@django_query_analyze def get_artists_and_releases_prefetch_related(): result = [] artists = Artist.objects.all()[:100].prefetch_related(\"music_releases\") # prefetch_related for artist in artists: result.append( { \"name\": artist.name, \"releases\": [rel.title for rel in artist.music_releases.all()], } ) return result\n\nselect_relatedÂ can only cache theÂ âoneâ side of theÂ âone-to-manyâ relationship, or either side of aÂ âone-to-oneâ relationship. You can useÂ prefetch_relatedÂ for all other caching, including the many side in one-to-many relationships, and many-to-many relationships. Hereâs the improvement in our example:\n\nran function get_artists_and_releases_prefetch_related -------------------- number of queries: 2 Time of execution: 0.13239s\n\nNice.\n\nThings to keep in mind aboutÂ select_relatedÂ andÂ prefetch_related:\n\nIf you arenât pooling your database connections, the gains will be even bigger because of fewer roundtrips to the database.\n\nFor very large result-sets, runningÂ prefetch_relatedÂ can actually make things slower.\n\nOne database query isnâtÂ necessarilyÂ faster than two or more.\n\nIndexing\n\nIndexing your database columns can have a big impact on query performance. Why then, is it not the first clause of this section? Because indexing is more complicated than simply scatteringÂ db_index=TrueÂ on your model fields.\n\nCreating an index on frequently accessed columns can improve the speed of look-ups pertaining to them. Indexing comes at the cost of additional writes and storage space though, so you should always measure your benefit:cost ratio. In general, creating indices on a table will slow down inserts/updates.\n\nTake only what you need\n\nWhen possible, useÂ values()Â and especiallyÂ values_list()Â to only pull the needed properties of your database objects. Continuing our example, if we only want to display a list of artist names and donât need the fullÂ ORMÂ objects, itâs usually better to write the query like so:\n\nartist_names = Artist.objects.values('name') # <QuerySet [{'name': 'Chet Faker'}, {'name': 'Billie Eilish'}]> artist_names = Artist.objects.values_list('name') # <QuerySet [('Chet Faker',), ('Billie Eilish',)]> artist_names = Artist.objects.values_list('name', flat=True) # <QuerySet ['Chet Faker', 'Billie Eilish']>\n\nHaki Benita, a true database expert (unlike me), reviewed some parts of this section. You should readÂ Hakiâs blog.\n\nBackend: the request layer\n\nThe next layer weâre going to look at is the request layer. These are your Django views, context processors, and middleware. Good decisions here will also lead to better performance.\n\nPagination\n\nIn the section aboutÂ select_relatedÂ we were using the function to return 500 artists and their labels. In many situations returning this many objects is either unrealistic or undesirable. The section aboutÂ pagination in the Django docsÂ is crystal clear on how to work with theÂ PaginatorÂ object. Use it when you donât want to return more thanÂ NÂ objects to the user, or when doing so makes your web-app too slow.\n\nAsynchronous execution/background tasks\n\nThere are times when a certain action inevitably takes a lot of time. For example, a user requests to export a big number of objects from the database to anÂ XMLÂ file. If weâre doing everything in the same process, the flow looks like this:\n\nweb: user requests file -> process file -> return response\n\nSay it takes 45 seconds to process this file. Youâre not really going to let the user wait all this time for a response. First, because itâs a horrible experience from aÂ UXÂ standpoint, and second, because some hosts will actually cut the process short if your app doesnât respond with a properÂ HTTPÂ response after N seconds.\n\nIn most cases, the sensible thing to do here is to remove this functionality from the request-response loop and relay it to a different process:\n\nweb: user requests file -> delegate to another process -> return response | v background process: receive job -> process file -> notify user\n\nBackground tasks are beyond the scope of this article but if youâve ever needed to do something like the above Iâm sure youâve heard of libraries likeÂ Celery.\n\nCompressing DjangoâsÂ HTTPÂ responses\n\nThis is not to be confused with static-file compression, which is mentioned later in the article.\n\nCompressing Djangoâs HTTP/JSON responses also stands to save your users some latency. How much exactly? Letâs check the number of bytes in our responseâs body without any compression:\n\nContent-Length: 66980 Content-Type: text/html; charset=utf-8\n\nSo ourÂ HTTPÂ response is aroundÂ 67KB. Can we do better? Many use Djangoâs built-inÂ GZipMiddlewareÂ forÂ gzipÂ compression, but today the newer and more effectiveÂ brotliÂ enjoys the same support across browsers (exceptÂ IE11, of course).\n\nImportant:Â Compression canÂ potentiallyÂ open your website to security breaches, as mentioned in theÂ GZipMiddleware sectionÂ of the Django docs.\n\nLetâs install the excellentÂ django-compression-middlewareÂ library. It will choose the fastest compression mechanism supported by the browser by checking the requestâsÂ Accept-EncodingÂ headers:\n\npip install django-compression-middleware\n\nInclude it in our Django appâs middleware:\n\nMIDDLEWARE = [ \"django.middleware.security.SecurityMiddleware\", \"django.contrib.sessions.middleware.SessionMiddleware\", \"django.contrib.auth.middleware.AuthenticationMiddleware\", \"compression_middleware.middleware.CompressionMiddleware\", # ... ]\n\nAnd inspect the bodyâsÂ Content-LengthÂ again:\n\nContent-Encoding: br Content-Length: 7239 Content-Type: text/html; charset=utf-8\n\nThe body size is now 7.24KB, 89% smaller. You can certainly argue this kind of operation should be delegated to a dedicated server like Ngnix or Apache. Iâd argue that everything is a balance between simplicity and resources.\n\nCaching\n\nCaching is the process of storing the result of a certain calculation for faster future retrieval. Django has an excellentÂ caching frameworkÂ that lets you do this on a variety of levels and using different storage backends.\n\nCaching can be tricky in data-driven apps: youâd never want to cache a page thatâs supposed to display up-to-date, realtime information at all times. So, the big challenge isnât so much setting up caching as it is figuring out what should be cached, for how long, and understanding when or how the cache is invalidated.\n\nBefore resorting to caching, make sure youâve made proper optimizations at the database-level and/or on the frontend. If designed and queried properly, databases are ridiculously fast at pulling out relevant information at scale.\n\nFrontend: where it gets hairier\n\nReducing static files/assets sizes can significantly speed up your web application. Even if youâve done everything right on the backend, serving your images,Â CSS, and JavaScript files inefficiently will degrade your applicationâs speed.\n\nBetween compiling, minifying, compressing, and purging, itâs easy to get lost. Letâs try not to.\n\nServing static-files\n\nYou have several options on where and how to serve static files.Â Djangoâs docsÂ mention a dedicated server running Ngnix and Apache, Cloud/CDN, or the same-server approach.\n\nIâve gone with a bit of a hybrid attitude: images are served from aÂ CDN, large file-uploads go toÂ S3, but all serving and handling of other static assets (CSS, JavaScript, etcâ¦) is done using WhiteNoise (covered in-detail later).\n\nVocabulary\n\nJust to make sure weâre on the same page, hereâs what I mean when I say:\n\nCompiling: If youâre usingÂ SCSSÂ for your stylesheets, youâll first have to compile those toÂ CSSÂ because browsers donât understandÂ SCSS.\n\nMinifying: reducing whitespace and removing comments fromÂ CSSÂ andÂ JSÂ files can have a significant impact on their size. Sometimes this process involves uglifying: the renaming of long variable names to shorter ones, etcâ¦\n\nCompressing/Combining: forÂ CSSÂ andÂ JS, combining multiple files to one. For images, usually means removing some data from images to make their files size smaller.\n\nPurging: remove unneeded/unused code. InÂ CSSÂ for example: removing selectors that arenât used.\n\nServing static files from Django with WhiteNoise\n\nWhiteNoise allows your Python web-application to serve static assets on its own.Â As its author states, it comes in when other options like Nginx/Apache are unavailable or undesired.\n\nLetâs install it:\n\npip install whitenoise[brotli]\n\nBefore enabling WhiteNoise, make sure yourÂ STATIC_ROOTÂ is defined inÂ settings.py:\n\nSTATIC_ROOT = os.path.join(BASE_DIR, \"staticfiles\")\n\nTo enable WhiteNoise, add its WhiteNoise middleware right belowÂ SecurityMiddlewareÂ inÂ settings.py:\n\nMIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'whitenoise.middleware.WhiteNoiseMiddleware', # ... ]\n\nIn production, youâll have to runÂ manage.py collectstaticÂ for WhiteNoise to work.\n\nWhile this step is not mandatory, itâs strongly advised to add caching and compression:\n\nSTATICFILES_STORAGE = 'whitenoise.storage.CompressedManifestStaticFilesStorage'\n\nNow whenever it encounters aÂ {% static %}Â tag in templates, WhiteNoise will take care of compressing and caching the file for you. It also takes care of cache-invalidation.\n\nOne more important step: To ensure that we get a consistent experience between development and production environments, we addÂ runserver_nostatic:\n\nINSTALLED_APPS = [ 'whitenoise.runserver_nostatic', 'django.contrib.staticfiles', # ... ]\n\nThis can be added regardless of whetherÂ DEBUGÂ isÂ TrueÂ or not, because you donât usually run Django viaÂ runserverÂ in production.\n\nI found it useful to also increase the caching time:\n\n# Whitenoise cache policy WHITENOISE_MAX_AGE = 31536000 if not DEBUG else 0 # 1 year\n\nWouldnât this cause problems with cache-invalidation? No, because WhiteNoise createsÂ versionedÂ files when you runÂ collectstatic:\n\n<link rel=\"stylesheet\" href=\"/static/CACHE/css/4abd0e4b71df.css\" type=\"text/css\" media=\"all\">\n\nSo when you deploy your application again, your static files are overwritten and will have a different name, thus the previous cache becomes irrelevant.\n\nCompressing and combining with django-compressor\n\nWhiteNoise already compresses static files, soÂ django-compressorÂ is optional. But the latter offers an additional enhancement: combining the files. To use compressor with WhiteNoise we have to take a few extra steps.\n\nLetâs say the user loads anÂ HTMLÂ document that links threeÂ .cssÂ files:\n\n<head> <link rel=\"stylesheet\" href=\"base.css\" type=\"text/css\" media=\"all\"> <link rel=\"stylesheet\" href=\"additions.css\" type=\"text/css\" media=\"all\"> <link rel=\"stylesheet\" href=\"new_components.css\" type=\"text/css\" media=\"all\"> </head>\n\nYour browser will make three different requests to these locations. In many scenarios itâs more effective to combine these different files when deploying, andÂ django-compressorÂ does that with itsÂ {% compress css %}Â template tag:\n\nThis:\n\n{% load compress %} <head> {% compress css %} <link rel=\"stylesheet\" href=\"base.css\" type=\"text/css\" media=\"all\"> <link rel=\"stylesheet\" href=\"additions.css\" type=\"text/css\" media=\"all\"> <link rel=\"stylesheet\" href=\"new_components.css\" type=\"text/css\" media=\"all\"> {% compress css %} </head>\n\nBecomes:\n\n<head> <link rel=\"stylesheet\" href=\"combined.css\" type=\"text/css\" media=\"all\"> </head>\n\nLetâs go over the steps to makeÂ django-compressorÂ and WhiteNoise play well. Install:\n\npip install django_compressor\n\nTell compressor where to look for static files:\n\nCOMPRESS_STORAGE = \"compressor.storage.GzipCompressorFileStorage\" COMPRESS_ROOT = os.path.abspath(STATIC_ROOT)\n\nBecause of the way these two libraries intercept the request-response cycle, theyâre incompatible with their default configurations. We can overcome this by modifying some settings.\n\nI prefer to use environment variables inÂ .envÂ files and have one DjangoÂ settings.py, but if you haveÂ settings/dev.pyÂ andÂ settings/prod.py, youâll know how to convert these values:\n\nmain_project/settings.py:\n\nfrom decouple import config #... COMPRESS_ENABLED = config(\"COMPRESS_ENABLED\", cast=bool) COMPRESS_OFFLINE = config(\"COMPRESS_OFFLINE\", cast=bool)\n\nCOMPRESS_OFFLINEÂ isÂ TrueÂ in production andÂ FalseÂ in development.Â COMPRESS_ENABLEDÂ isÂ TrueÂ in both\n\n.\n\nWith offline compression, one must runÂ manage.py compressÂ on every deployment. On Heroku, youâll want to disable the platform from automatically runningÂ collectstaticÂ for you (on by default) and instead opt to do that in theÂ post_compileÂ hook, which Heroku will run when you deploy. If you donât already have one, create a folder calledÂ binÂ at the root of your project and inside of it a file calledÂ post_compileÂ with the following:\n\npython manage.py collectstatic --noinput python manage.py compress --force python manage.py collectstatic --noinput\n\nAnother nice thing about compressor is that it can compress SCSS/SASS files:\n\nCOMPRESS_PRECOMPILERS = ( (\"text/x-sass\", \"django_libsass.SassCompiler\"), (\"text/x-scss\", \"django_libsass.SassCompiler\"), )\n\nMinifyingÂ CSSÂ &Â JS\n\nAnother important thing to apply when talking about load-times and bandwidth usage is minifying: the process of (automatically) decreasing your codeâs file-size by eliminating whitespace and removing comments.\n\nThere are several approaches to take here, but if youâre usingÂ django-compressorÂ specifically, you get that for free as well. You just need to add the following (or any other filters compressor supports) to yourÂ settings.pyÂ file:\n\nCOMPRESS_FILTERS = { \"css\": [ \"compressor.filters.css_default.CssAbsoluteFilter\", \"compressor.filters.cssmin.rCSSMinFilter\", ], \"js\": [\"compressor.filters.jsmin.JSMinFilter\"], }\n\nDefer-loading JavaScript\n\nAnother thing that contributes to slower performance is loading external scripts. The gist of it is that browsers will try to fetch and execute JavaScript files in theÂ <head>Â tag as they are encounteredÂ and beforeÂ parsing the rest of the page:\n\n<html> <head> <script src=\"https://will-block.js\"></script> <script src=\"https://will-also-block.js\"></script> </head> </html>\n\nWe can use theÂ asyncÂ andÂ deferÂ keywords to mitigate this:\n\n<html> <head> <script async src=\"somelib.somecdn.js\"></script> </head> </html>\n\nasyncÂ andÂ deferÂ both allow the script to be fetched asynchronously without blocking. One of the key differences between them isÂ whenÂ the script is allowed to execute: WithÂ async, once the script has been downloaded, all parsing is paused until the script has finished executing, while withÂ deferÂ the script is executed only after allÂ HTMLÂ has been parsed.\n\nI suggest referring toÂ Flavio Copesâ articleÂ on theÂ deferÂ andÂ aysncÂ keywords. Its general conclusion is:\n\nThe best thing to do to speed up your page loading when using scripts is to put them in theÂ head, and add aÂ deferÂ attribute to yourÂ scriptÂ tag.\n\nLazy-loading images\n\nLazily loading images means that we only request them when or a little before they enter the clientâs (userâs) viewport. It saves time and bandwidth ($ on cellular networks) for your users. With excellent, dependency-free JavaScript libraries likeÂ LazyLoad, there really isnât an excuse to not lazy-load images. Moreover, Google Chrome natively supports theÂ lazyÂ attribute since version 76.\n\nUsing the aforementioned LazyLoad is fairly simple and the library is very customizable. In my own app, I want it to apply on images only if they have aÂ lazyÂ class, and start loading an image 300 pixels before it enters the viewport:\n\n$(document).ready(function (e) { new LazyLoad({ elements_selector: \".lazy\", // classes to apply to threshold: 300 // pixel threshold }) })\n\nNow letâs try it with an existing image:\n\n<img class=\"album-artwork\" alt=\"{{ album.title }}\" src=\"{{ album.image_url }}\">\n\nWe replace theÂ srcÂ attribute withÂ data-srcÂ and addÂ lazyÂ to the class attribute:\n\n<img class=\"album-artwork lazy\" alt=\"{{ album.title }}\" data-src=\"{{ album.image_url }}\">\n\nNow the client will request this image when the latter is 300 pixels under the viewport.\n\nIf you have many images on certain pages, using lazy-loading will dramatically improve your load times.\n\nOptimize & dynamically scale images\n\nAnother thing to consider is image-optimization. Beyond compression, there are two more techniques to consider here.\n\nFirst, file-format optimization. There are newer formats likeÂ WebPÂ that are presumably 25-30% smaller than your averageÂ JPEGÂ image at the same quality. As of 02/2020 WebP hasÂ decent but incompleteÂ browser support, so youâll have to provide a standard format fallback if you want to use it.\n\nSecond, serving different image-sizes to different screen sizes: if some mobile device has a maximum viewport width of 650px, then why serve it the same 1050px image youâre displaying to 13â³ 2560px retina display?\n\nHere, too, you can choose the level of granularity and customization that suits your app. For simpler cases, You can use theÂ srcsetÂ attribute to control sizing and be done at that, but if for example youâre also servingÂ WebPÂ withÂ JPEGÂ fallbacks for the same image, you may use theÂ <picture>Â element with multiple sources and source-sets.\n\nIf the above sounds complicated for you as it does for me,Â this guideÂ should help explain the terminology and use-cases.\n\nUnusedÂ CSS: Removing imports\n\nIf youâre using aÂ CSSÂ framework like Bootstrap, donât just include all of its components blindly. In fact, I would start with commenting out all of the non-essential components and only add those gradually as the need arises. Hereâs a snippet of myÂ bootstrap.scss, where all of its different parts are imported:\n\n// ... // Components // ... @import \"bootstrap/dropdowns\"; @import \"bootstrap/button-groups\"; @import \"bootstrap/input-groups\"; @import \"bootstrap/navbar\"; // @import \"bootstrap/breadcrumbs\"; // @import \"bootstrap/badges\"; // @import \"bootstrap/jumbotron\"; // Components w/ JavaScript @import \"bootstrap/modals\"; @import \"bootstrap/tooltip\"; @import \"bootstrap/popovers\"; // @import \"bootstrap/carousel\";\n\nI donât use things likeÂ badgesÂ orÂ jumbotronÂ so I can safely comment those out.\n\nUnusedÂ CSS: PurgingÂ CSSÂ with PurgeCSS\n\nA more aggressive and more complicated approach is using a library likeÂ PurgeCSS, which analyzes your files, detectsÂ CSSÂ content thatâs not in use, and removes it. PurgeCSS is anÂ NPMÂ package, so if youâre hosting Django on Heroku, youâll need to install the Node.js buildpack side-by-side with your Python one.\n\nConclusion\n\nI hope youâve found at least one area where you can make your Django app faster. If you have any questions, suggestions, or feedback donât hesitate toÂ drop me a line on Twitter.\n\nAppendices\n\nDecorator used for QuerySet performance analysis\n\nBelow is the code for theÂ django_query_analyzeÂ decorator:"
    }
}