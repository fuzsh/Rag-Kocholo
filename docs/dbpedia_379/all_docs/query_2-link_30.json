{
    "id": "dbpedia_379_2",
    "rank": 30,
    "data": {
        "url": "https://pages.ucsd.edu/~dkjordan/scriptorium/TaiwaneseLeftBehind.html",
        "read_more_link": "",
        "language": "en",
        "title": "Jordan: Languages Left Behind",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://pages.ucsd.edu/~dkjordan/scriptorium/igdmuublue.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "File last modified:\n\nLanguages Left Behind\n\nLanguages Left Behind\n\nKeeping Taiwanese off the World Wide Web\n\nDavid K. Jordan\n\nUniversity of California, San Diego\n\nReprinted from: Language Problems &\n\nLanguage Planning 26(2): 111-127. (2002)\n\nSections\n\nOrthographic Standardization\n\nUnicode: Letters and Computer Codes\n\nDouble-Byte Codes\n\nChinese Characters and Computers\n\nNon-Mandarin Chinese: The Politics of Being Left Out\n\nThe Nature of Non-Mandarin\n\nThe Case in Favor of Person-Reason-YÄ«n\n\nThe Case Against Person-Reason-YÄ«n\n\nConclusion\n\nAbstract: The Unicode standard is an enormous step toward realizing the goal of a single computer encoding scheme for virtually all of the worldâs scripts. Although not all computers will necessarily have the type fonts to display all characters, at least all computers will be able to recognize what characters are required for proper display of text in almost any language.\n\nHowever the Unicode standard presupposes that each language has a script consisting of a finite number of agreed-upon characters. Some languages still lack such agreement.\n\nAs planning has gone forward for Unicode, more and more code points are being assigned, leaving ever fewer conveniently accessed code points for future expansion.\n\nThis article describes the Unicode project. Then it describes the special challenge of encoding Chinese characters. Finally it uses the example of Hokkien, a âdialectâ of Chinese spoken by most people in Taiwan, to explore the problem of unorthodox, unstable, or unofficial scripts.\n\nPolitical forces and technical considerations make it difficult to include such scripts in Unicode. As Unicode becomes the de facto standard for writing human languages, script innovations will presumably become less and less likely to receive wide use.\n\n1. Orthographic Standardization\n\nStandardization is very much a part of the world as we know it today, and the benefits of common standards are obvious, despite occasional nostalgia for cranky localisms. There is a brief period when selected decision makers collaborate to generate and then legitimize the new standard. After that, changes are difficult. It is too late to change the length of a centimeter: the alternatives are no longer viable proposals.\n\nWe live today during the period when the worldâs orthographies are being standardized, and in particular are being integrated into a single set of numerical codes designed to allow all future computers around the globe to recognize, manipulate, and display all included languages with equal ease and with no variation beyond the artistic flourishes of particular type fonts. The coding system is usually referred to as Unicode, and its basic features are already in widespread, if not yet universal, use. If one uses a web browser, one uses Unicode, or anyway one can. If one uses the popular Microsoft business applications, one uses Unicode, even if one is unaware of it.\n\nMost of the decisions involved with the creation of Unicode are extremely technical and have been, appropriately, undertaken by computer specialists building on the work of other computer specialists. [Note 1] In this paper I will briefly describe the Unicode system. Then I will turn to how different orthographies are included in it. Some orthographies, by reason of political and historical accident, are also excluded from it and probably always will be. And that will be the principal point I wish to make.\n\nNote 1. Unicode is a cooperative project involving such major computer companies as IBM, Microsoft, Apple, Novell, Lotus, Xerox, and Hewlett-Packard; such research groups as the Research Libraries Group, the Getty Art History Information Project, and Knight-Ridder Information; and individuals from organizations like the Tibetan Languages Institute, the Asian Classics Input Project, and the Korea Industrial Advancement Administration. The Java computer programming language already uses Unicode as the basis of its text representations, and others seem likely to follow. The Unicode Consortium cooperates with the International Organization for Standardization and other standards bodies. The earlier ISO/lEG 10646 standard has been merged with the Unicode project.\n\nUnicode supposes that each language has a standard orthography (or orthographies) that must be accommodated. However there is in the end a finite number of code points in the system, and they are in fact rapidly coming to be claimed. There will soon come a time when there is no room for new characters in the system, and orthographic creativity will be severely curtailed (alternatively, Unicode will need to be expanded, a point I will return to later). Who defines the standard form of an orthography, the characters which Unicode must accommodate? For most modern languages, governments do. For dead languages, scholars do. Hokkien, a Chinese âdialectâ (also known as Minnan, Amoy, and Taiwanese), is a language that, for political reasons, has no standard orthography and is excluded from Unicode, despite being the native tongue of perhaps fifty million people. In describing the case of Hokkien, my more general point is to call attention to the disconcerting fact that international computer standardization locks insiders in and outsiders out, including, of course, the determination of which languages can easily be represented on the increasingly important World Wide Web.\n\nOpen bibliography.\n\nReturn to top.\n\n2. Unicode: Letters and Computer Codes\n\nComputers represent data as a series of binary numbers, that is, the numbers 0 and 1. Each binary digit is referred to as a âbitâ of information. By convention these bits are blocked in groups of eight; eight bits taken together are called a byte. A byte may vary in value from 00000000 to 11111111. Expressed as decimal values, this is the range from 0 to 256(=2^8). For programming purposes it is convenient to express each byte as a two-digit hexadecimal number from 00 to FF, with FF also of course equal to 256. The computer reads the eight bits making up the code, looks up the number in a character table, and sends the appropriate graphic representation to the screen or printer. Different type fonts can be swapped in the computerâs memory, and the exact form of a character may vary without limit, but the standard system defines a letter J, for example, as occupying position 74 (hexadecimal 4A). Although some type fonts may prefer to place an unrelated graphic at that position, compatibility with the worldâs computer systems is maximized by using fonts that use 74 for J.\n\nAt present, computers represent text by mapping the upper and lower case Latin alphabets, the Arabic numerals, and a variety of control codes and punctuation marks onto the values 00 to 128 (hex. 00-80), a code range referred to as âBasic Latin.â (Historically this derives from older American teletype codes, or so the story goes. Position 7, for example, does not print a letter: it rings the bell on the teletype machine.) Standards initially varied about what was mapped onto the values 129-256 (hex. 81ä¸FF), but these codes (known as âLatin-1â) today include additional characters used in Western European languages other than English, especially Latin letters with diacritical marks. (The letter Ã±, for example, is in position 241 [hex. F1].) Clearly, however, 256 positions is too few to allow the representation even of all the variants of the Latin alphabet, let alone the many other orthographies that the world uses.\n\nOpen bibliography.\n\nReturn to top.\n\n3. Double-Byte Codes\n\nUnicode uses double-byte codes, in which each character, rather than being coded between 00 and FF, has a code between 0000 and FFFF. This produces 65,536 (= 2^16) possible unique codes, which, it is proposed, can be used to accommodate all or nearly all of the worldâs scripts, depending in part upon how much space is allocated to Chinese. The letter J is then no longer represented by the code 4A, but 004A; Ã± is not Fl but 00F1. And there is now space for Ä at 0108, which is 264 in decimal figuring, just beyond the reach of the 256 positions of single- byte encoding. There is even room foré¾ (kÄn, a Chinese character meaning a niche in the wall serving as a shrine) at position 9F95 (decimal 40,853). Theoretically the last position available is of course position number 65,535 (hex. FFFF), although in fact many spaces are reserved or still unused. [Note 2]\n\nNote 2. The procedures for inputting these codes using a standard computer keyboard are an entirely separate issue not addressed by the Unicode Consortium. Character input systems have a less compelling need for standardization, since they can vary according to the convenience of the user with no effect on the finished result. Character 40,853 can be read as é¾ regardless of how the typist got the number into the file.\n\nNumbered character codes refer to the computerâs internal representation of characters as numbers and thus only indirectly to the graphic forms it places on the screen based on its look-up tables, which are referred to by computer specialists as glyphs. Unicode does not concern itself with the graphic form of a code, defining U+OOFF (Ã¿) [Note 3], for example, as âLatin small letter y with dieresisâ or U+0636 (Ø¶) as âArabic letter dad,â and leaving it to the type-font designer to worry about the graphic details. (Font designers are of course free to assign any graphic to any code position, but this is impractical if standardization is desired.)\n\nNote 3. It is conventional to precede a Unicode hexadecimal code with the prefix âU+â to distinguish it from other numbers or letters.\n\nVersion 2.0 of the Unicode Standard was released in printed form in February of 1997 by the Unicode Consortium (http://www.unicode.org), making the system easily available to the Anglophone public. It was and is a work in progress. When Version 3.0 was published in 2000, it included Sinhala, Ethiopic, Cherokee, âCanadian Aboriginal Syllabics,â and other new entries, as well as Braille patterns and over twelve hundred codes for the Yi (Lobo) syllabary.\n\nIn various states of consideration, approval, or proposal (and therefore not yet in the standard) were alternative scripts proposed but no longer used for English (Deseret, Shavian), as well as ancient scripts such as Etruscan, Gothic, Linear B, and Cypriot syllabary. âProposed scriptsâ included: Pollard, Phaistos disk, Ugaritic Cuneiform, Old Persian Cuneiform, Meroitic, and basic Egyptian hieroglyphics. [Note 4]\n\nNote 4. Updated details maybe found at http://www.unicode.org/unicode/alloc/PiPelifle.html.\n\nIn the case of Ethiopic, Unicode represents the first actual standard for its computer representation. âPrior to the Unicode 3.0 standard,â writes one commentator, âno fewer than 60 disparate encoding systems have appearedâ for Ethiopic (Yacob 2000: 30). [Note 5]\n\nNote 5. Inclusion in the Unicode standard can require a certain amount of housekeeping in unstandardized or no longer used scripts. Inclusion of Deseret, a script for English developed by early Mormon settlers in Utah, has required the establishment of sorting rules (alphabetical order) for these characters. Sorting rules are required by Unicode, but never established for Descret because, so far as is known, nothing was ever alphabetized in that script (Jenkins 2000: 36).\n\nOpen bibliography.\n\nReturn to top.\n\n4. Chinese Characters and Computers\n\nChinese characters have traditional forms as well as some standardized variants in Korean and Japanese, and recent simplifications officialized in mainland China. Computer specialists use the expression âCJKâ (Chinese-Japanese- Korean) to refer to the collectivity of Chinese and Chinese-derived characters, and âCJKVâ when they include pre-reform Vietnamese as well. National computer coding standards for CJK characters vary from one country to another, and from Taiwan to the mainland within the Chinese-speaking world. None of these standards actually incorporates all of the characters in occasional use in these countries. (For details see Vine 1999.)\n\nMany characters are used in more than one of these CJK languages. The character äºº for âperson,â for example, occurs in Korean and Japanese as well as both Chinese character sets, with a different double-byte code in each of the four different national standards. In Unicode a shared character is assigned a single code for use in all languages. [Note 6]\n\nNote 6. Because of this, the ordering of the characters in Unicode is not the same as in any of these CJK national standards, and the original codes are preserved for none of them. Because the Korean standard in particular includes some duplicate representations of the same character depending upon its pronunciation, Unicode has in fact duplicated some characters in order to retain maximum two-way translatability with each of the CJK national standards. There are minor differences in conventional type design (similar to serifs and ligatures in Roman typography) that make the conventional representation of a character slightly different from one language to another and between simplified and traditional Chinese characters. Font designers and specialists in globalization find that they must take this into account in producing text that is comfortable to read rather than merely intelligible, but it does not affect the representation of these characters in Unicode. See Lunde 1999, Meyer 1999, Hudson 2000.\n\nIn Version 2.0 of the Unicode Standard, the âCJK Unified Ideographsâ occupied 20,901 codes (U+4E00 through U+9FA5). [Note 7] Ominously, perhaps, by Version 3.0 it had been found desirable to allocate an additional 6,655 spaces for CJK characters (U+3400 through U+4DFF).\n\nNote 7. Technical considerations require some duplicate characters stored as F900 through FA2D, and the difficulties of composing the Korean Hangul alphabet into its traditional character-shaped entities stimulated the allocation of codes U+ACOO through U-D7A3 (11,172 spaces) for pre-composed versions of them. In addition spaces U+3000 through U+3400 are allocated to East Asian punctuation signs, individual phonetic and syllabary symbols, diacritics, currency symbols, alternate number symbols, etc. commonly used in the CJK scripts.\n\nIs this enough space? In actual practice, Chinese characters have always been an open set, and folk characters thrive today as they always have, some becoming the de facto standard despite efforts at centralized control. The largest general Chinese dictionary (ZhÄng QÃ­yÃºn 1973) contains 49,905 characters, not including shorthand forms, dialect forms, or Japanese, Korean, or mainland simplified variants.\n\nNearly twice that number has proved necessary for use by the international consortium engaged in computerizing the Chinese Buddhist canon.\n\nNon-standard characters and non-standard simplifications are constantly being invented and used, especially in shorthand, private letters, informal signs, and occasionally in specialized ways. [Note 8] (See Bokset 1988 for several hundred of these collected across China.)\n\nNote 8. The standard Chinese term for restaurant is cāntÄ«ng, traditionally written é¤å»³ The famous Chinese character simplification scheme officializes a simplification for one of these and not the other: é¤å . It is a rare restaurant in contemporary China that does not utilize a rogue simplification of the first, usually consisting only of its upper left-hand corner. The rogue simplification is unlikely to turn up in the Unicode scheme, since it has no official support, and hence no legitimate advocates.\n\nSome variants are matters of more than merely shorthand. A specialized form The character of the character æ¯ï¼ âmother,â is . It is used exclusively by the Unity Sect (YÄ«guÃ n DÃ o ä¸è²«é) of Taiwan. Since the sect has several million initiates, and produces books in which âmotherâ is always printed in this way, it is not obvious that the character should not be regarded as part of normal Chinese in Taiwan, except that it has no official status and can, as a practical matter, easily enough be written æ¯ï¼ An opposite argument would be that it is actually more comparable to a religious symbol such as the yÄ«n-yÃ¡ng (U+262F â¯) or the overlaid chi-ro of the Christian world (U+2627 â§), or to a linguistically irrelevant graphic flourish, like the stylized C in the Coca-Cola emblem. The inclusion of a small number of religious symbols in the Unicode set probably invites future claims of religious discrimination. Arguing that that the Unity Sect mother emblem belongs there if chi-ro belongs there would be an example.\n\nAnd finally several âdialectsâ of Chinese have rich but unstandardized traditions for writing terms that do not occur in standard Mandarin. Thus the 27,556 spaces now assigned to CJK characters in Unicode cannot be expected to represent everything writable in Chinese. Chinese would be capable of filling all sixty-five thousand spaces and would still have characters unrepresented. [Note 9]\n\nNote 9. I write from the perspective of Chinese. CJKV obviously includes some characters used only in Japanese, Korean, or Vietnamese and some variants or simplifications not used in China. (One character, U+5F41å½ï¼ seems not to occur in any of these languages.) The character simplification in Japan after World War II did not produce the same simplifications as the more radical reform in China, for example. However modern Japanese severely restricts its use of characters, and modern Korean and Vietnamese omit them. Thus the problems discussed in this paper are of most significance in Chinese.\n\nSo what is to be left out? Essentially only characters that are incorporated into the national standards used as source documents are included. Omitted are local and âsubstandardâ simplified characters (shorthand), characters no longer in active use and not occurring in the standard literary corpora, and â most interesting for present purposes â characters used only to represent Chinese languages other than modern Mandarin or standard literary Chinese. In particular, there has been no attempt to incorporate the characters used to write Shanghainese, Xiang, Hakka, Hokkien, or other âregional dialectsâ of Chinese that are in fact separate, though closely related, languages, each with millions of speakers. To understand this we need to review some facts about these kinds of Chinese.\n\nOpen bibliography.\n\nReturn to top.\n\n5. Non-Mandarin Chinese: The Politics of Being Left Out\n\nMandarin is but one of the regional Chinese languages (euphemistically but traditionally referred to as âdialectsâ), and indeed Mandarin itself contains broad enough regional variation that some Mandarin dialects could reasonably be called independent languages. Since the syntax of literary Chinese was peculiar to itself, all speakers of Chinese languages formerly shared it as a common writing system with little expectation that it would precisely correspond with spoken usage anywhere. The demise of literary Chinese early in the twentieth century brought this situation to an end, and elevated Mandarin, the majority dialect, to the position of a national standard. (In theory Beijing Mandarin is the standard. There is of course some slippage, but the details are not relevant here.) Modern written language is expected to follow spoken Mandarin usage.\n\nEach of these dialects has, over the last centuries, produced various attempts to represent colloquial speech in Chinese characters. When colloquial words seemed to have no equivalent, new characters were invented on the analogy of others, [Note 10] or existing homonyms were used exclusively for their sound value (a usage dubbed âwhite charactersâ in Chinese).\n\nNote 10. From the earliest times for which we have evidence, all variants of Chinese were written with graphic characters. Most characters in historic periods have been composed, consisting of a âradicalâ or âmeaning elementâ plus a âphonetic element.â For example fÃ n é£¯âriceâ is made of é£, a radical relating to food (and occurring as the separate character shI âto eat, foodâ) and fÇn åï¼âto turn back,â borrowed for its approximate sound value. Using these principles, new characters are easily created and readily understood, in context, by other speakers of the same dialect. In principle, the 214 radicals of the QÄ«ng æ¸ period KÄngxÄ« åº·ç dictionary combined with the 890 or so combining phonetics could produce about 190,000 compound characters of this kind. In view of the constant invention of shorthand forms, special radicals, and nonce and alternative writings, the total number of graphically distinct characters ever used in CJK languages is almost certainly well in excess of 100,000, possibly in excess of 200,000.\n\nNone of the non-Mandarin dialects has ever had its own standardized and widely used colloquial writing system, and none is routinely used for continuous written text today. [Note 11] An exception is Cantonese, which developed local conventions (if not exactly standards) in part because the long British occupation of Hong Kong did not include ideological efforts to manage how Chinese was written. (It did establish a semi-official Hong Kong Government Chinese Character Set, although other standards compete with it. See Meyer 1998.)\n\nNote 11. Missionary efforts to introduce alphabetical writing systems won little acceptance in China. A modified Latin script for Hokkien once taught in Christian churches was prohibited for use in running text during Taiwanâs long post-war period of martial law and is effectively extinct except to show pronunciation in a few Hokkien dictionaries. Efforts to create and use non-Mandarin Pinyin have also been stillborn.\n\nIn contrast, the language reforms of the twentieth century were associated with nationalist sentiment suspicious of the use of anything other than the ânational languageâ (guÃ³yÇï¼a Nationalist phrase) or the âcommon languageâ (pÇtÅnghuÃ , a Communist phrase) as vaguely treasonous. The force of the campaign against non-Mandarin Chinese varied, but the issue was never ignored. Non-Mandarin radio and television broadcasts were (and are) prohibited or limited, depending on the place and period, and a constant barrage of slogans and propaganda mark much of the twentieth century. (A colleague brought me a poster from a theoretically multilingual Singapore public office that reads: âSpeak more in Mandarin, speak less in regional dialectsâ (å¤è¯´åè¯­,å°è¯´æ¹è¨!)\n\nThese attitudes and policies inhibited the development of vernacular writing systems in non-Mandarin regions, where today one reads and writes in Mandarin, translating orally if there are still non-Mandarin speakers who need to be informed. The situation is roughly comparable to what would ensue if South Americans, both Spanish and Portuguese speakers, were required to conduct all written communication in French. At stake politically is linguistic uniformity as a symbol of nationhood.\n\nOpen bibliography.\n\nReturn to top.\n\n6. The Nature of Non-Mandarin\n\nIf a different dialect had been chosen as standard, written language would have been different, in some cases quite different. By way of example, here are written forms of three non-Mandarin languages compared with the same sentence as written in colloquial Mandarin. [Note 12] (Plus signs have been inserted to show sentence structure. The dummy character ☹ (U+2639) is used where no Unicode character is available.) [Note 13]\n\nNote 12. These examples are based in part on Gunn 1993. For the sake of simplicity, the non-Mandarin examples are here printed in traditional (non-simplified) characters. The use of simplified characters would create minor variants, as can be seen here for Mandarin. These writings may alternate with more Mandarin-like usages for some writers.\n\nEnglish: They didnât speak Mandarin with you.\n\nLiteral gloss: They+lack+with you+speak Mandarin.\n\nMandarinï¼ ä»ååæ²¡æåè·ä½ ï¼èªªåèªã\n\n(Simplified: ä»ä»¬åæ²¡æåè·ä½ ï¼è¯´å½è¯­ã)\n\nShanghainese: ä¼æï¼å¸æ²¡ï¼è±åï¼è¬åèªã\n\nHokkien: ☹ ï¼ç¡ åç²æ±ï¼è¬åèªã\n\nCantonese: ä½¢åï¼åï¼åä½ ï¼è¬åèªã\n\nNote 13. Shanghainese and a number of related âWu dialectsâ are spoken in the lower Yangzi region. Hokkien is spoken in southern Fujian and is the home language of most people in Taiwan. Cantonese is the language of Guangdong province, including Hong Kong. In Taiwan the status of Hokkien, locally often called Taiwanese, is a politically charged issue.\n\nThe non-Mandarin sentences as written here make use of quite a lot of characters that are not part of the Mandarin version. In most cases, these characters have Mandarin readings and occur in classical Chinese, but are not colloquial in Mandarin in this sentence. The non-Mandarin sentences here might not be written identically by all speakers, since these are not standardized orthographies.\n\nFour characters (Shanghaineseå¸ï¼Hokkien ☹ï¼and Cantonese å and åï¼ are not to be found in the basic standard B5 (Taiwan) or GB (Mainland) non-Unicode computer code sets. [Note 14]\n\nNote 14. Of these, number 4 (å) is quite usual in Cantonese, although some authors write ç¡ or å instead (e.g. Chiang Ker Chiu nd-b). Number 3 å is rare enough in Cantonese not to occur in some desk Cantonese dictionaries (Huang Gangsheng 1994, QiÃ¡o YÃ nnÃ³ng 1965). I am unfamiliar with Shanghainese and cannot comment on the first character å¸.\n\nBecause three of them are rare but extant characters in Mandarin or literary Chinese, they have made their way into Unicode. [Note 15] However, character 2 (Hokkien: in), here written with the place- holder ☹ï¼is not in the Unicode scheme (unlike the place-holder), and therefore is of particular interest to us here. As most usually written, it is composed of a âpersonâ element äºº ï¼Mandarin: rÃ©n) on the left plus a phonetic å Mandarin: yÄ«n) which, as an independent character, means âreason.â Chinese describing the combined character represented by ☹ would call this character the âperson-reason-yÄ«n,â meaning that it has the radical âperson,â the phonetic âreason,â and the sound âyÄ«n.â It is a third-person plural pronoun, pronounced in in Hokkien. (The Hokkien third-person singular pronoun is i.)\n\nNote 15. In an acknowledgment of the normalization achieved in Hong Kong, and perhaps as a political statement about Hong Kongâs successful autonomy within the larger PRC polity, many of the additional characters introduced in Unicode Version 3.0 are Hong Kong usages introduced with the apparent blessing of the Beijing government, although this example does not include any of those additions. My impression is that many occur only in place names.\n\nAlthough far more standardized among Hokkien speakers than many other vernacular characters, person-reason-yÄ«n is very clearly not Mandarin. Neither are many other characters, although how many depends on who is doing the writing, and what level of tolerance is allowed for using homophones as stand-in characters. Literate Hokkien speakers have apparently always produced a considerable number of distinctive characters not found in other forms of Chinese. Campbellâs Dictionary of Amoy [Hokkien] Vernacular, published in Tainan in 1913, circulates in a Taiwan martial-law-period reprint with Mandarin pronunciations written into its character index, apparently a fig leaf to avoid its being censored. The reprinters were able to provide Mandarin readings for only about 60 percent of the characters in Campbellâs index. Similarly an edition of Douglasâ 1873 Hokkien dictionary reprinted in the same period with characters written into the margins eschews non-Mandarin characters, with the result that no characters at all are written in for the many words that have no obvious Mandarin form. Since the martial-law period, Taiwanese lexicographers (e.g., ChÃ©n XiÅ« 1991, YÃ¡ng QÄ«ngchÃ¹ 1992) and promoters (e.g., FÄng NÃ¡nqiÃ¡ng 1994, 1996) have continued and expanded experiments in promoting the Hokkien language, using characters many of which do not occur in other kinds of Chinese. In some cases the desire to differentiate a Taiwanese from a Mandarin text has stimulated the selection or invention of maximally different characters even when a Mandarin-congruent choice has been available.\n\nShould person-reason-yÄ«n be in Unicode? Not necessarily, although a successful negotiation of Taiwan independence could very well make it politically necessary for a Taiwan government to argue in favor of it rather than against it. First of all, not all Hokkien writers use it. In competition with person-reason-yÄ«n as the character of choice for the third person plural pronoun are several other, less common but less âoffensiveâ forms, as follows (sources for each are noted):\n\n☹ built of person radical äºº plus phonetic å ï¼Mandarin: yÄ«n, âreasonâ).\n\nChÃ©n XiÅ« 1991:743 (a post-martial-law dictionary that records both this usage and following one)\n\nYÃ¡ng QÄ«ngchÃ¹ 1992 (a self-consciously language-engineering dictionary)\n\nFÄng NÃ¡nqiÃ¡ng 1994 (a textbook aimed at Taiwanese learning to read and write their own language)\n\nPTHM 1982:930 (a Mandarin-Hokkien dictionary prepared for the use of linguists in Fujian).\n\nä¼ use of the same graph for both singular (i) and plural (in).\n\nCampbell 1913:260.\n\nChiang nd-c (a Hokkien textbook for English speakers)\n\nXÃº HuÄ«hÃ o 1966:20, 1970: 15 (conversational manuals for Taiwan learners).\n\n☹ built of the singular third-person pronoun ä¼ ï¼Mandarin: yÄ«) plus a âheartâ radicalï¼å¿ï¼underneath. [Note 16] Like person-reason-yÄ«n, this character is also not in the Unicode scheme.\n\nTJTS 1931:93 (a Hokkien-Japanese dictionary for the use of the Japanese colonial administration)\n\nLÃ­n ShÃ oxiÃ¡n 1950:59 (a conversation manual)\n\nCÃ i PÃ©ihuÇ 1969 (a dictionary) and 1976 (a conversation manual), both intended to teach Hokkien to Mandarin speakers.\n\nUse of an etymologically unrelated character of similar sense arbitrarily read as in:\n\nä» ï¼Mandarin: tÄ) Macgowan 1883:533\n\nå½¼ï¼Mandarin: bÇ) Chiang nd-a: 86.\n\nUse of an etymologically unrelated but homonymous character, such as å ï¼Mandarin: yÄ«n, reason).\n\nCampbell 1913:260.\n\nUse of the bi-syllabic Mandarin third-person plural formï¼ ä»å tÄmen, translated into Hokkien when read aloud.\n\nAll Hokkien-English dictionaries (Kok and Tan 1956, Embree 1973, Sprinkle et al. 1977, Tan 1978). [Note17]\n\nNote 16. A Mandarin analogy and possible inspiration for this is the Mandarin second-person pronoun nÇ ä½ ï¼ which has a formal variant n/in æ¨ï¼ written by adding the heart below nÇ. Since in Hokkien plural pronouns add -n to singular ones, the use of the âheartâ radical to represent the sound of a final -n can become a productive device for converting characters for singular Hokkien pronouns into characters for plural ones.\n\nNote 17. Sources published under martial law were ill advised to propose separate writing systems for Taiwanese Hokkien, since Taiwanese âseparatismâ was considered a significant threat to the cause of national unification. Accordingly, few all-Chinese Hokkien dictionaries (e.g., ShÄn FÃ¹jÃ¬n 1954, LÇ MÃ¹qÃ­ 1963, CÃ i WÃ©nhuÄ« 1972) were produced, nearly always simply providing both Hokkien and Mandarin readings for characters shared by both languages, and nearly always in the name of linguistic research or with the avowed purpose of helping to teach Mandarin to Hokkien speakers, and never with the overt goal of rendering Hokkien a viable written idiom. Occasional dictionaries (e.g., GÄo ShÃ¹fÄn 1985) included a few characters used only in Taiwan place names, but treated them as Mandarin characters and gave them only Mandarin readings. The few dictionaries intended for foreigners normally represented Hokkien only in Romanization and provided only orthodox Mandarin Chinese characters.\n\nOpen bibliography.\n\nReturn to top.\n\n7. The Case in Favor of Person-Reason-YÄ«n\n\nThe case in favor of including person-reason-yÄ«n in Unicode is simple:\n\nTaiwanese Hokkien is the language of a people for whom nationalistic sentiments appear to be rising, and person-reason-yÄ«n appears today to be the traditional and preferred character for at least some of the most recent and most serious script reformers who would like to see Taiwanese people write at least sometimes in their native Hokkien rather than in Mandarin.\n\nThe Unicode Consortium has tried to provide codes for as many scripts as possible, including some (like ancient Greek) used by no living speakers and some (like Shavian and Deseret) with no significant history of use. A modern language with millions of speakers should not be excluded. Indeed the inclusion of a considerable amount of valuable code space for the Yi (Lobo) syllabary suggests that exactly this logic has been convincing in the case of a non-Han minority population in China.\n\nThe particular sin of the Hokikien speakers appears to be that they are of Han ethnicity, and Han has been defined as necessarily Mandarin- (or, grudgingly, Cantonese-) speaking.\n\nOpen bibliography.\n\nReturn to top.\n\n8. The Case Against Person-Reason-YÄ«n\n\nThe case against including person-reason-yÄ«n is also simple, but has more parts:\n\nFirst, it is not part of the Taiwan (or mainland) computer standard, so it is not part of an existing, bounded writing system already defined as one of the Chinese sources. It is therefore not included in the corpus of texts on the basis of which the Unicode standard establishes what Chinese characters to include. It is not obvious what expansion of the corpus would successfully capture the characters most appropriate for Hokkien in the absence of its prior standardization.\n\nPerson-reason-yÄ«n is not in (much) active use in Taiwan (or elsewhere in the CJK world) except as a proposal by a tiny handful of people, since Hokkien speakers normally write in Mandarin. Thus it is by definition a low-frequency character.\n\nBoth the PRC and the ROC governments oppose recognition of written colloquial Hokkien as a legitimate written standard, so as a practical matter there would be overwhelming political objection to introducing Hokkien-only characters from two countries whose participation is essential if Unicode is to work. âWho is entitled to define what Chinese is if not âthe Chineseâ?â it could reasonably be asked. Unlike ancient Egyptian, where a few responsible scholars can reasonably dictate what will and will not be enshrined in the Unicode Standard (http://anubis.dkuug.dk/jtcl/sc2/wg2/docs/n1637/n 1637.htm), Chinese carries with it considerable political baggage. The Consortium must tread delicately.\n\nThe acknowledgment of person-reason-yÄ«n (and other non-Mandarin Chinese characters) raises the issue of including hundreds or even thousands of other Chinese characters now excluded from the standard. For example:\n\nPolitical considerations aside, how much space should be allocated only to CJK when most African languages do not yet appear in Unicode?\n\nIf space is available, should Unicode include more of the rare characters created in the Tang dynasty for the transcription of Sanskrit and Pali words into Chinese?\n\nWhat about characters used in the remote past as Korean and Japanese localisms?\n\nWhat about characters used only as place names of places since renamed?\n\nChinese, as we have seen, is an open character set that could potentially gobble up the entire double-byte capacity if no limits are set. It is easy to incorporate the unused Shavian alternative alphabet for English, since it comes at relatively little cost because it is a small and closed set of symbols. Chinese, on the other hand, is an endless ocean. Arguably Unicode has already been overly generous to Chinese. Modern simplified Chinese merges some characters as essentially merely insignificant graphic variations. For example, çº and ç»ï¼both simplified to lÃ²u ç in Mainland China, are treated by Chinese dictionaries as interchangeable. Is it really necessary for Unicode to observe a distinction? Why?\n\nOpen bibliography.\n\nReturn to top.\n\n9. Conclusion\n\nThe exclusion of unofficial Chinese characters underlines the fact that script standardization is a process entwined with politics and national self-image. That is hardly a surprise.\n\nBut it also suggests a larger issue: When the new global standard is finally fully in place, when our operating systems are finally Unicode-based and our browsers and word processors routinely provided with full Unicode type fonts that offer Burmese and Russian and Arabic and Mongol on the same page (a moment that has already arrived for some of us), will it be too late to stabilize a new writing system for Hokkien? Will the age of innovative Chinese (and other) orthographies have drawn to a close? Will we have standardized at least some orthographies, perhaps some languages, into corners as curiosities that cannot be seriously used in a world in which literacy has become intimately bound to electronic information flow?\n\nOr, viewing the matter in the opposite direction, to the extent that local language activists in the Hokkien-speaking regions insist on the use of non-standard graphs like person-reason-yÄ«n, will they contribute to the defeat of their own goals by rendering colloquial Hokkien unusable in normal printing or computerized communication?\n\nI like standardization. It is an important basis of modernity. On the other hand there is a democratic, populist, localist voice in me that worries about person-reason-yÄ«n and similar vernacular innovations, whether for Hokkien or for any other language, being defined forever as outside the world of civilized discourse. [Note 18]\n\nNote 18. Foreseeing the problem of running out of space, the Unicode scheme provides a portal to a larger, 32-bit world (the so-called âUCS-4 character setâ) with room to encode vastly more characters than human ingenuity has yet imagined: 4,294,967,298 (=2^32), to be exact, and, ideally, computer input and interpretation systems could make the cumbersome addressing in these outer circles invisible to the user (Graham 2000:81-82). However the wide range of computer applications that still make it harder to deal with Czech than with English today does not give one confidence that any of us will live to see easy use of 32-bit character sets, especially if most major languages are adequately supported within the 16-bit world of mainstream Unicode. The imposition of additional technical requirements on an orthography can force unpopular compromises â the grudging use of cx, gx etc. in the absence of convenient access to Ä, Ä, etc. in computerized Esperanto is a ready example. This will probably always constitute a degree of discrimination, though less than the stigma of outright exclusion.\n\nOpen bibliography.\n\nReturn to top."
    }
}