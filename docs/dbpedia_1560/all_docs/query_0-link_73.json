{
    "id": "dbpedia_1560_0",
    "rank": 73,
    "data": {
        "url": "https://beam.apache.org/blog/beam-2.43.0/",
        "read_more_link": "",
        "language": "en",
        "title": "Apache Beam 2.43.0",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://beam.apache.org/images/beam_logo_navbar_mobile.png",
            "https://www.apache.org/foundation/press/kit/feather_small.png",
            "https://beam.apache.org/images/beam_logo_navbar.png",
            "https://www.apache.org/foundation/press/kit/feather_small.png",
            "https://beam.apache.org/images/banners/tour-of-beam/tour-of-beam-desktop.png",
            "https://beam.apache.org/images/banners/tour-of-beam/tour-of-beam-mobile.png",
            "https://beam.apache.org/images/banners/machine-learning/machine-learning-desktop.jpg",
            "https://beam.apache.org/images/banners/machine-learning/machine-learning-mobile.jpg",
            "https://beam.apache.org/images/beam_logo_circle.svg",
            "https://beam.apache.org/images/apache_logo_circle.svg",
            "https://beam.apache.org/images/external-link-icon.png",
            "https://beam.apache.org/images/logos/social-icons/github-logo-150.png",
            "https://beam.apache.org/images/logos/social-icons/linkedin-logo-150.png",
            "https://beam.apache.org/images/logos/social-icons/twitter-logo-150.png",
            "https://beam.apache.org/images/logos/social-icons/youtube-logo-150.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes.",
        "meta_lang": "en",
        "meta_favicon": "/images/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://beam.apache.org/blog/beam-2.43.0/",
        "text": "We are happy to present the new 2.43.0 release of Beam. This release includes both improvements and new functionality. See the download page for this release.\n\nFor more information on changes in 2.43.0, check out the detailed release notes.\n\nHighlights\n\nPython 3.10 support in Apache Beam (#21458).\n\nAn initial implementation of a runner that allows us to run Beam pipelines on Dask. Try it out and give us feedback! (Python) (#18962).\n\nI/Os\n\nDecreased TextSource CPU utilization by 2.3x (Java) (#23193).\n\nFixed bug when using SpannerIO with RuntimeValueProvider options (Java) (#22146).\n\nFixed issue for unicode rendering on WriteToBigQuery (#22312)\n\nRemove obsolete variants of BigQuery Read and Write, always using Beam-native variant (#23564 and #23559).\n\nBumped google-cloud-spanner dependency version to 3.x for Python SDK (#21198).\n\nNew Features / Improvements\n\nDataframe wrapper added in Go SDK via Cross-Language (with automatic expansion service). (Go) (#23384).\n\nName all Java threads to aid in debugging (#23049).\n\nAn initial implementation of a runner that allows us to run Beam pipelines on Dask. (Python) (#18962).\n\nAllow configuring GCP OAuth scopes via pipeline options. This unblocks usages of Beam IOs that require additional scopes. For example, this feature makes it possible to access Google Drive backed tables in BigQuery (#23290).\n\nAn example for using Python RunInference from Java (#23290).\n\nBreaking Changes\n\nCoGroupByKey transform in Python SDK has changed the output typehint. The typehint component representing grouped values changed from List to Iterable, which more accurately reflects the nature of the arbitrarily large output collection. #21556 Beam users may see an error on transforms downstream from CoGroupByKey. Users must change methods expecting a List to expect an Iterable going forward. See document for information and fixes.\n\nThe PortableRunner for Spark assumes Spark 3 as default Spark major version unless configured otherwise using --spark_version. Spark 2 support is deprecated and will be removed soon (#23728).\n\nBugfixes\n\nFixed Python cross-language JDBC IO Connector cannot read or write rows containing Numeric/Decimal type values (#19817).\n\nList of Contributors\n\nAccording to git shortlog, the following people contributed to the 2.43.0 release. Thank you to all contributors!\n\nAhmed Abualsaud AlexZMLyu Alexey Romanenko Anand Inguva Andrew Pilloud Andy Ye Arnout Engelen Benjamin Gonzalez Bharath Kumarasubramanian BjornPrime Brian Hulette Bruno Volpato Chamikara Jayalath Colin Versteeg Damon Daniel Smilkov Daniela MartÃ­n Danny McCormick Darkhan Nausharipov David Huntsperger Denis Pyshev Dmitry Repin Evan Galpin Evgeny Antyshev Fernando Morales Geddy05 Harshit Mehrotra IÃ±igo San Jose Visiers IsmaÃ«l MejÃ­a Israel Herraiz Jan LukavskÃ½ Juta Staes Kanishk Karanawat Kenneth Knowles KevinGG Kiley Sok Liam Miller-Cushon Luke Cwik Mc Melissa Pashniak Moritz Mack Ning Kang Pablo Estrada Philippe Moussalli Pranav Bhandari Rebecca Szper Reuven Lax Ritesh Ghorse Robert Bradshaw Robert Burke Ryan Thompson Ryohei Nagao Sam Rohde Sam Whittle Sanil Jain Seunghwan Hong Shane Hansen Shubham Krishna Shunsuke Otani Steve Niemitz Steven van Rossum Svetak Sundhar Thiago Nunes Toran Sahu Veronica Wasson Vitaly Terentyev Vladislav Chunikhin Xinyu Liu Yi Hu Yixiao Shen alexeyinkin arne-alex azhurkevich bulat safiullin bullet03 coldWater dpcollins-google egalpin johnjcasey liferoad rvballada shaojwu tvalentyn"
    }
}