{
    "id": "dbpedia_4663_3",
    "rank": 23,
    "data": {
        "url": "https://wasiswill.wordpress.com/2015/01/26/ex-machina-an-analysis/",
        "read_more_link": "",
        "language": "en",
        "title": "Ex Machina, an analysis",
        "top_image": "https://s0.wp.com/i/blank.jpg",
        "meta_img": "https://s0.wp.com/i/blank.jpg",
        "images": [
            "https://0.gravatar.com/avatar/ffb58982413969497af7dbf555b3e472efb80af089c0a622603eefab1333ebeb?s=60&d=identicon&r=G",
            "https://0.gravatar.com/avatar/96c64f8f3ab07c83b561ff59e0cfec2cffbcd37e23a66afb851ac2fbf5b8b083?s=60&d=identicon&r=G",
            "https://2.gravatar.com/avatar/2a1fef3dcdb428d9c68eedbe932c314146cd1b78a0726e9951a191694c2be90e?s=60&d=identicon&r=G",
            "https://0.gravatar.com/avatar/c5b4e456abc78ac9cd65749e0c5d21983cd2ed1dd086e29e130722ee4f8dfdf8?s=60&d=identicon&r=G",
            "https://2.gravatar.com/avatar/e18fb84b13e688369e7d90cc5033b6483a0f3b82c3f3dc5eff93b55b20893f1c?s=60&d=identicon&r=G",
            "https://2.gravatar.com/avatar/2b22cbee818033e9bc6d6e14ee2cf530db5e70072089c1d09c2465df090cb35d?s=60&d=identicon&r=G",
            "https://0.gravatar.com/avatar/0e613864dbc0c4ddc1dca78f9fbd56cf74ac3476bb4aef9a7b7c9ab8af370c22?s=60&d=identicon&r=G",
            "https://2.gravatar.com/avatar/2b22cbee818033e9bc6d6e14ee2cf530db5e70072089c1d09c2465df090cb35d?s=60&d=identicon&r=G",
            "https://1.gravatar.com/avatar/d3f8edca67ba7fc89d60c419dcfcdf84e1dadc560fcef553a1cf7ba046297d65?s=60&d=identicon&r=G",
            "https://0.gravatar.com/avatar/0e613864dbc0c4ddc1dca78f9fbd56cf74ac3476bb4aef9a7b7c9ab8af370c22?s=60&d=identicon&r=G",
            "https://0.gravatar.com/avatar/c5b4e456abc78ac9cd65749e0c5d21983cd2ed1dd086e29e130722ee4f8dfdf8?s=60&d=identicon&r=G",
            "https://2.gravatar.com/avatar/2b22cbee818033e9bc6d6e14ee2cf530db5e70072089c1d09c2465df090cb35d?s=60&d=identicon&r=G",
            "https://0.gravatar.com/avatar/69f189e60afe900db724e36eb93eb1c6705ad4f3e3f9c650579b85381ee351b1?s=60&d=identicon&r=G",
            "https://0.gravatar.com/avatar/c1dfac32dc1a1cc9159a923a01bb0252d3f3f97552305476eeed227f487b9694?s=60&d=identicon&r=G",
            "https://1.gravatar.com/avatar/df55b7956a8cc735ef5887974040a767e847cf28d904de43e1eed2158901f3c3?s=60&d=identicon&r=G",
            "https://2.gravatar.com/avatar/2b22cbee818033e9bc6d6e14ee2cf530db5e70072089c1d09c2465df090cb35d?s=60&d=identicon&r=G",
            "https://0.gravatar.com/avatar/ca0b9c035516598d4efc3851b416be380026a5e57cefb08cec514890957d5af5?s=60&d=identicon&r=G",
            "https://2.gravatar.com/avatar/2b22cbee818033e9bc6d6e14ee2cf530db5e70072089c1d09c2465df090cb35d?s=60&d=identicon&r=G",
            "https://1.gravatar.com/avatar/d22572cfca04194d932de246bc0af8920c43985628f358923f93b0edd5ba92e0?s=60&d=identicon&r=G",
            "https://s2.wp.com/i/logo/wpcom-gray-white.png",
            "https://s2.wp.com/i/logo/wpcom-gray-white.png",
            "https://pixel.wp.com/b.gif?v=noscript"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2015-01-26T00:00:00",
        "summary": "",
        "meta_description": "Ex Machina, Alex Garland's directorial debut, is fantastic as a film in its own right. It ticks all the psychological boxes for a very memorable watch: mood; tone; pacing; character development; things-not-seeming-as-they-are; sufficiently ambiguous ending to provoke thought; revelation, etc.. The film's premise may not seem so original, or Garland's script at least, when placed…",
        "meta_lang": "en",
        "meta_favicon": "https://s1.wp.com/i/favicon.ico",
        "meta_site_name": "Articulated",
        "canonical_link": "https://wasiswill.wordpress.com/2015/01/26/ex-machina-an-analysis/",
        "text": "Ex Machina, Alex Garland’s directorial debut, is fantastic as a film in its own right. It ticks all the psychological boxes for a very memorable watch: mood; tone; pacing; character development; things-not-seeming-as-they-are; sufficiently ambiguous ending to provoke thought; revelation, etc..\n\nThe film’s premise may not seem so original, or Garland’s script at least, when placed in the light of stories such as Spielberg’s AI, Pinocchio, Metropolis, Ghost in the Shell, Blade Runner, and the list literally does go on. Nevertheless, there are distinctions the film and script earn in their own right. To say the least, it’s a visually stunning film: set in an isolated nowhere, the state of the art home of the AI-creator and tech-billionaire Nathan (Oscar Isaac) houses the proverbial promethean fire with which its surrounding nature is conquered; additionally, the outstanding female lead of the film Ava (Alicia Vikander) is the nubile AI face of the enigma at the heart of all the film’s finely poised philosophical problems. Caleb (Domhnall Gleeson) starts off the fresh-faced protagonist, and it is through his learning of his circumstance, in being invited to Nathan’s home, that the plot moves forward to its inevitable climax.\n\nDespite all the sci-fi spectacle and brooding humanity, however, the reason I took an immediate liking to the film, and the reason I am writing this, is because its utilisation of philosophical and particularly academic subject matter is done so well, but also so subtly, that it screams out for articulation as to the value it adds to the film.\n\nVarious thought experiments are referred to and indeed utilised plot-wise by the film, of which any undergraduate studying philosophy of mind will undoubtedly by familiar with. The plot, indeed, moves to the tune of Frank Jackson’s thought experiment ‘Mary’s Room’. Can Ava, as a robot, ever really know everything about the world (supposing she does) if she is only ever kept in Nathan’s house-room-turned-prison? For, as she learns to yearn for, there is a quality to experiencing something, an extra slice of knowledge brought by being there in person, which Ava cannot ever know of.\n\nBut, then again, Ava isn’t human — Mary was. Caleb is originally brought to Nathan’s home under the pretense of his winning an internal lottery, as one of Nathan’s many employees at his ‘Bluebook’ (Google-esque) tech firm. Once there, Nathan reveals he has created an AI of which Caleb will perform the human component in what Nathan originally refers to as a Turing Test. The Turing Test that Nathan intends to perform is not, strictly speaking, a Turing Test: no, Nathan correctly asserts that the real trick is convincing a human that the robot is conscious, after they’ve been introduced as a robot. It is here that the viewer is invited to join in Caleb’s part: we are introduced, session after session, with Ava, to understand more and more what makes her so very different from us. Created by Nathan, we eventually witness the workshop where she was created, and it is explained to her what makes her brain work. Nevertheless, we are invited to empathise with Caleb’s desperate attempt to set Ava free. The puzzle at the heart of the film is whether or not Ava, after Nathan makes clear she was using to an unknowable extent Caleb in order to be set free, is or was at any point conscious of what she is doing. The ending of the film is inclined to provoke this response, it is clear; by leaving Caleb trapped in Nathan’s home and now grave, Ava betrays her inhumanity.\n\nIn contrast, Nathan betrays his sensualism and humanity always: as a typically flawed genius, he is also infinitely human, and indeed represents humanity at its most intelligent and dark. Nathan is distinctly bi-polar, corrupted, egotistical, and often drunk. To be more precise, Nathan is self-destructive — like many intelligent men, he perceives his own end and its insignificance, note not only the irony but the calmness of which he talks sincerely of the fossilisation of mankind as Ava and her successors inherit earth as humanity’s grave. As such, through such an indifference, weakness comes easy and thus the opportunity for Caleb to ‘save’ Ava is inevitably presented. In this, Nathan reminds me of another brooding genius — Ludwig Wittgenstein. As the German philosopher is referenced explicitly in the film, there is inevitably meaning behind this giant of philosophy’s presence here: BlueBook is named after Wittgenstein’s Blue Book of notes, a re-drafted version of his notes to his students and the basis of his later landmark Philosophical Investigations.\n\nIt is no coincidence that in the Blue Book Wittgenstein uses, as an example of his essential language game concept, that of a thinking robot. Asking, “Is it possible for a machine to think?”, Wittgenstein goes on to demonstrate his quality:\n\nAnd the trouble which is expressed in this question is not really that we don’t yet know a machine which could do the job. The question is not analogous to that which someone might have asked a hundred years ago: “Can a machine liquefy a gas?” The trouble is rather that the sentence, “A machine thinks (perceives, wishes)”: seems somehow nonsensical. It is as though we had asked “Has the number 3 a colour?” (“What colour could it be, as it obviously has none of the colours known to us?”) For in one aspect of the matter, personal experience, far from being the product of physical, chemical, physiological processes, seems to be the very basis of all that we say with any sense about such processes.\n\nThinking a little about what Wittgenstein is really getting at, we are asking whether a machine, or a robot, or an AI, can do something which humans have only really been considered to have done. The confusion is created by using the word — consciousness — in a new context, befuddling anyone who questions it. To be more precise, Wittgenstein proffers this, again re AI:\n\n“Could a machine think?” I shall talk about this at a later point, and now only refer you to an analogous question: “Can a machine have toothache?” You will certainly be inclined to say: “A machine can’t have toothache”. All I will do now is to draw your attention to the use which you have made of the word “can” and to ask you: “Did you mean to say that all our past experience has shown that a machine never had toothache?” The impossibility of which you speak is a logical one. The question is: What is the relation between thinking (or toothache) and the subject which thinks, has toothache, etc.?\n\nWe must be clear, is the message. To state that Ava can’t be conscious is to remark either one of two things: one, that Ava cannot be conscious by the very virtue of the word itself, i.e. it is reserved for humans and regardless of facts the word can only describe a human state of affairs; or, two, that all our experience to date has shown that AI have not been conscious. Crucially, the second entails the logical possibility that an AI could be conscious but, as Wittgenstein notes, this begs the question as to what the relation between being conscious and the subject which is conscious is. To answer this, Nathan did not turn to science but to Art.\n\nAnother reference I enjoyed was that of automatic art, specifically Jackson Pollock the iconic drip-painter. As Nathan, in an important scene, makes clear, the artist let his hand go where it wanted: not deliberate but not random, only somewhere in between. What makes a subject conscious then? What is the real Turing Test? The answer is somewhere in between deliberated actions and random actions; the space between programming and anarchy. Here, clearly, Ava was not doing anything random, in fact far from it — she planned her escape with Caleb. No, the challenge is whether or not Ava actions were automatic. As Nathan said, the challenge is to find an action that is not automatic, “from talking, to breathing, to painting — to fucking, even falling in love.”\n\nIf Nathan has gone on to say “to murdering” he would have predicted his own demise and simultaneously the act which betrayed Ava’s consciousness: for there was no automation in her act of executing patricide, this was the meticulousness of a conscious human at work; save for the wires and synthetics, Ava was seeking revenge and freedom in the arbitrary way a human forced into such dire circumstances would — objectifying Caleb as the saviour in her yearning to be free. Indeed, her going on to liberate herself in taking the parts of previous AI in order to look more human, and her only doing this after her creator had died, these are the insecurities and triumphal signs of the conscious mind. According to Garland and Nathan’s standards of non-automation, Ava was conscious and I suppose the act of her leaving Caleb in the building to die can be explained away as simply an unfamiliarity with morality (not that being familiar with morality necessarily means complying with it).\n\n“Fucking unreal” were Nathan’s last words, before simply “Ava”. I’d imagine he realised he’d become the subject of his own automatic art, and that by inviting his own demise he’d vindicated his own work — where, if he’d known what was going to happen every step of the way he wouldn’t have even begun. After everything, Ex Machina’s deep message is more about feeling than analytics and linguistic philosophy; as Nathan demands from Caleb his feelings as opposed to his analysis of Ava. Indeed, the real appeal of thought experiments, such as Mary’s Room and Searle’s Chinese Room, lies in their illustrative ability to expose deeply alien feelings: that Ava might have accomplished all she did without being conscious is one thought or feeling most of us would shudder at."
    }
}