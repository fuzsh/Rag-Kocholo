{
    "id": "dbpedia_6613_1",
    "rank": 98,
    "data": {
        "url": "https://developer.chrome.com/docs/lighthouse/performance/performance-scoring",
        "read_more_link": "",
        "language": "en",
        "title": "Lighthouse performance scoring",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.gstatic.com/devrel-devsite/prod/v20ab951cf37b43fc7a428ae75ce91d8269f391204ca16525bc8a5ececea0ab56/chrome/images/lockup.svg",
            "https://www.gstatic.com/devrel-devsite/prod/v20ab951cf37b43fc7a428ae75ce91d8269f391204ca16525bc8a5ececea0ab56/chrome/images/lockup.svg",
            "https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_36.png 36w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_48.png 48w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_72.png 72w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_96.png 96w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_480.png 480w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_720.png 720w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_856.png 856w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_960.png 960w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_1440.png 1440w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_1920.png 1920w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/lighthouse-scoring-calcul-196f49058e387_2880.png 2880w",
            "https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_36.png 36w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_48.png 48w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_72.png 72w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_96.png 96w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_480.png 480w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_720.png 720w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_856.png 856w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_960.png 960w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_1440.png 1440w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_1920.png 1920w,https://developer.chrome.com/static/docs/lighthouse/performance/performance-scoring/image/image-the-scoring-curve-f72983bc008e4_2880.png 2880w"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Learn how Lighthouse generates the overall Performance score for your page.",
        "meta_lang": "en",
        "meta_favicon": "https://www.gstatic.com/devrel-devsite/prod/v20ab951cf37b43fc7a428ae75ce91d8269f391204ca16525bc8a5ececea0ab56/chrome/images/favicon.png",
        "meta_site_name": "Chrome for Developers",
        "canonical_link": "https://developer.chrome.com/docs/lighthouse/performance/performance-scoring",
        "text": "How Lighthouse calculates your overall Performance score\n\nIn general, only metrics contribute to your Lighthouse Performance score, not the results of Opportunities or Diagnostics. That said, improving the opportunities and diagnostics likely improve the metric values, so there is an indirect relationship.\n\nBelow, we've outlined why the score can fluctuate, how it's comprised, and how Lighthouse scores each individual metric.\n\nWhy your score fluctuates\n\nA lot of the variability in your overall Performance score and metric values is not due to Lighthouse. When your Performance score fluctuates it's usually because of changes in underlying conditions. Common problems include:\n\nA/B tests or changes in ads being served\n\nInternet traffic routing changes\n\nTesting on different devices, such as a high-performance desktop and a low-performance laptop\n\nBrowser extensions that inject JavaScript and add/modify network requests\n\nAntivirus software\n\nLighthouse's documentation on Variability covers this in more depth.\n\nFurthermore, even though Lighthouse can provide you a single overall Performance score, it might be more useful to think of your site performance as a distribution of scores, rather than a single number. See the introduction of User-Centric Performance Metrics to understand why.\n\nHow the Performance score is weighted\n\nThe Performance score is a weighted average of the metric scores. Naturally, more heavily weighted metrics have a bigger effect on your overall Performance score. The metric scores are not visible in the report, but are calculated under the hood.\n\nLighthouse 10\n\nLighthouse 8\n\nHow metric scores are determined\n\nOnce Lighthouse has gathered the performance metrics (mostly reported in milliseconds), it converts each raw metric value into a metric score from 0 to 100 by looking where the metric value falls on its Lighthouse scoring distribution. The scoring distribution is a log-normal distribution derived from the performance metrics of real website performance data on HTTP Archive.\n\nFor example, Largest Contentful Paint (LCP) measures when a user perceives that the largest content of a page is visible. The metric value for LCP represents the time duration between the user initiating the page load and the page rendering its primary content. Based on real website data, top-performing sites render LCP in about 1,220ms, so that metric value is mapped to a score of 99.\n\nGoing a bit deeper, the Lighthouse scoring curve model uses HTTPArchive data to determine two control points that then set the shape of a log-normal curve. The 25th percentile of HTTPArchive data becomes a score of 50 (the median control point), and the 8th percentile becomes a score of 90 (the good/green control point). While exploring the scoring curve plot below, note that between 0.50 and 0.92, there's a near-linear relationship between metric value and score. Around a score of 0.96 is the \"point of diminishing returns\" as above it, the curve pulls away, requiring increasingly more metric improvement to improve an already high score.\n\nHow desktop vs mobile is handled\n\nAs mentioned above, the score curves are determined from real performance data. Prior to Lighthouse v6, all score curves were based on mobile performance data, however a desktop Lighthouse run would use that. In practice, this led to artificially inflated desktop scores. Lighthouse v6 fixed this bug by using specific desktop scoring. While you certainly can expect overall changes in your perf score from 5 to 6, any scores for desktop will be significantly different.\n\nHow scores are color-coded\n\nThe metrics scores and the perf score are colored according to these ranges:\n\n0 to 49 (red): Poor\n\n50 to 89 (orange): Needs Improvement\n\n90 to 100 (green): Good\n\nTo provide a good user experience, sites should strive to have a good score (90-100). A \"perfect\" score of 100 is extremely challenging to achieve and not expected. For example, taking a score from 99 to 100 needs about the same amount of metric improvement that would take a 90 to 94.\n\nWhat can developers do to improve their performance score?\n\nFirst, use the Lighthouse scoring calculator to help understand what thresholds you should be aiming for achieving a certain Lighthouse performance score."
    }
}