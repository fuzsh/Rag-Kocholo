{
    "id": "dbpedia_8306_3",
    "rank": 61,
    "data": {
        "url": "https://encord.com/blog/data-clustering-intro-methods-applications/",
        "read_more_link": "",
        "language": "en",
        "title": "Data Clustering: Methods & Applications",
        "top_image": "https://images.prismic.io/encord/7e86484a-786a-4927-955c-4659e20e3182_Data+Clustering.png?auto=compress%2Cformat&fit=max",
        "meta_img": "https://images.prismic.io/encord/7e86484a-786a-4927-955c-4659e20e3182_Data+Clustering.png?auto=compress%2Cformat&fit=max",
        "images": [
            "https://images.prismic.io/encord/7e86484a-786a-4927-955c-4659e20e3182_Data+Clustering.png?auto=compress%2Cformat&fit=max&w=906&h=638",
            "https://images.prismic.io/encord/7e86484a-786a-4927-955c-4659e20e3182_Data+Clustering.png?auto=compress%2Cformat&fit=max&w=906&h=638",
            "https://encord.com/static/VectorDesktop-d6a994f2c668a0332ba39898992e598f.png",
            "https://encord.com/static/VectorTablet-5246b4eeb12ce3a011a59f9a65313af7.png",
            "https://encord.com/static/VectorDesktop-d6a994f2c668a0332ba39898992e598f.png",
            "https://encord.cdn.prismic.io/encord/ZmrVVZm069VX1tfd_Union.svg",
            "https://images.prismic.io/encord/90631c4c-69e8-47bd-90b0-262dc97e2c8f_1626646958804.jpg?auto=compress%2Cformat&fit=max&w=80&h=80",
            "https://images.prismic.io/encord/90631c4c-69e8-47bd-90b0-262dc97e2c8f_1626646958804.jpg?auto=compress%2Cformat&fit=max&w=80&h=80",
            "https://images.prismic.io/encord/Zky98iol0Zci9U3b_tryEncordCTADark.png?auto=format,compress",
            "https://images.prismic.io/encord/15b25051-9a3d-48bb-93a9-ee0320272ae0_K-Means+%60Clustering+%7C+Encord.png?auto=compress,format",
            "https://images.prismic.io/encord/79b831a9-4a56-4515-81d8-60c51287de84_Hierarchial+Clustering+-+Dendrogram+-+Encord.png?auto=compress,format",
            "https://images.prismic.io/encord/0b06645f-2766-495a-aa8a-bbc196a8be18_K-Means+Clustering+-+Emcord.png?auto=compress,format",
            "https://images.prismic.io/encord/a477726c-3e43-4784-8c72-d63301ee8369_Agglomerative+Clustering+and+Divisive+Clustering.png?auto=compress,format",
            "https://images.prismic.io/encord/b0840977-4115-4c63-bf6d-ffdf4e81486d_DBSCAN+Clustering.png?auto=compress,format",
            "https://images.prismic.io/encord/e35a12a6-02f0-4b79-bb9a-d89e28ee4577_medical-cta-image.png?auto=compress,format",
            "https://images.prismic.io/encord/Zky98iol0Zci9U3b_tryEncordCTADark.png?auto=format,compress",
            "https://encord.com/static/VectorDesktop-d6a994f2c668a0332ba39898992e598f.png",
            "https://encord.com/static/VectorTablet-5246b4eeb12ce3a011a59f9a65313af7.png",
            "https://encord.com/static/VectorDesktop-d6a994f2c668a0332ba39898992e598f.png",
            "https://encord.cdn.prismic.io/encord/ZmrVVZm069VX1tfd_Union.svg",
            "https://images.prismic.io/encord/90631c4c-69e8-47bd-90b0-262dc97e2c8f_1626646958804.jpg?auto=compress%2Cformat&fit=max&w=80&h=80",
            "https://images.prismic.io/encord/90631c4c-69e8-47bd-90b0-262dc97e2c8f_1626646958804.jpg?auto=compress%2Cformat&fit=max&w=80&h=80",
            "https://images.prismic.io/encord/6eced55d-aef1-4b54-a205-75401ba5a717_Supervised+Learning.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6eced55d-aef1-4b54-a205-75401ba5a717_Supervised+Learning.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/4a859630-d119-4092-b679-fac382b4c72e_Complex+ML+tasks+blog+image.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/4a859630-d119-4092-b679-fac382b4c72e_Complex+ML+tasks+blog+image.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6155fefd-96d8-476c-8b9b-f579671f51b5_Fine-tuning+vs+training.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6155fefd-96d8-476c-8b9b-f579671f51b5_Fine-tuning+vs+training.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/424f6050-6d3f-49ab-b807-8465b455622c_Cross+Entropy+Loss+Functions.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/424f6050-6d3f-49ab-b807-8465b455622c_Cross+Entropy+Loss+Functions.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zr-Le0aF0TcGJAdk_image-122-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zr-Le0aF0TcGJAdk_image-122-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zr5Uy0aF0TcGI-M5_image-120-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zr5Uy0aF0TcGI-M5_image-120-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zr5Ud0aF0TcGI-Mz_image-119-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zr5Ud0aF0TcGI-Mz_image-119-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZqJZjx5LeNNTxfqa_image-66-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZqJZjx5LeNNTxfqa_image-66-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZpaXvR5LeNNTxNT1_image-65-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZpaXvR5LeNNTxNT1_image-65-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZnxKr5bWFbowe4m7_image-60-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZnxKr5bWFbowe4m7_image-60-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Znn0F5bWFbowe0cI_image7.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Znn0F5bWFbowe0cI_image7.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zma2yZm069VX1las_image-38-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zma2yZm069VX1las_image-38-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZlmUwaWtHYXtT9iJ_image-32-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZlmUwaWtHYXtT9iJ_image-32-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZkYKYCol0Zci9NOg_image-30-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZkYKYCol0Zci9NOg_image-30-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZkFuAkFLKBtrWzPe_MetaImageAI.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZkFuAkFLKBtrWzPe_MetaImageAI.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zj3aQkFLKBtrWxYT_KnowledgeDistillation.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zj3aQkFLKBtrWxYT_KnowledgeDistillation.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZjV2QUMTzAJOCh49_WhatisContinuousValidation%3F.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZjV2QUMTzAJOCh49_WhatisContinuousValidation%3F.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZjTuAkMTzAJOChUc_image-28-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZjTuAkMTzAJOChUc_image-28-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZivOnd3JpQ5PTNcs_MetaAIRay-BansSmartGlasses.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZivOnd3JpQ5PTNcs_MetaAIRay-BansSmartGlasses.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiqFu_Pdc1huK0dK_image-22-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiqFu_Pdc1huK0dK_image-22-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiLcJPPdc1huKpkr_DataOps-vs-MLOps-updated.jpg?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiLcJPPdc1huKpkr_DataOps-vs-MLOps-updated.jpg?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiKkbfPdc1huKpYI_image1.jpg?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiKkbfPdc1huKpYI_image1.jpg?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiJ8bfPdc1huKpGI_OpenAICLIPAlternatives.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiJ8bfPdc1huKpGI_OpenAICLIPAlternatives.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiIxCfPdc1huKoXq_Meta_Ilama3.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZiIxCfPdc1huKoXq_Meta_Ilama3.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZgL4CMcYqOFdyGEI_image1.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZgL4CMcYqOFdyGEI_image1.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZfwTkc68zyqdRoFM_DiffusionTransformer-DiT-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZfwTkc68zyqdRoFM_DiffusionTransformer-DiT-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZfTztnYkiKrtlKK5_image5.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZfTztnYkiKrtlKK5_image5.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZfSXsXYkiKrtlJ6p_image-8-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/ZfSXsXYkiKrtlJ6p_image-8-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Ze8JO0mNsf2sHf5B_image-52-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Ze8JO0mNsf2sHf5B_image-52-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zeg9Zf_jD4D4xSpU_ModelValidationTool-Banner.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/Zeg9Zf_jD4D4xSpU_ModelValidationTool-Banner.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/65df355d9c42d04f7d969005_image-43-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/65df355d9c42d04f7d969005_image-43-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/65dd08b73a605798c18c4dcd_MLLifecycle-Encord.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/65dd08b73a605798c18c4dcd_MLLifecycle-Encord.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/65d8cd593a605798c18c2e2b_image-41-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/65d8cd593a605798c18c2e2b_image-41-.png?auto=format%2Ccompress&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/bbd4982b-4999-489e-a2fe-789e2e630b5c_Introduction+to+Krippendorff%E2%80%99s+Alpha.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/bbd4982b-4999-489e-a2fe-789e2e630b5c_Introduction+to+Krippendorff%E2%80%99s+Alpha.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/80febfb8-b7da-4c8c-b7d8-3583214d7298_Model+Drift+-+Encord.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/80febfb8-b7da-4c8c-b7d8-3583214d7298_Model+Drift+-+Encord.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/2e37d9bb-2085-4824-bde0-540d27de401b_image+%2830%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/2e37d9bb-2085-4824-bde0-540d27de401b_image+%2830%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/904bd86a-514a-428b-b64b-0f6c3e7aabe3_image+%2826%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/904bd86a-514a-428b-b64b-0f6c3e7aabe3_image+%2826%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/434cb8dd-bf4d-4b00-95b6-12fda6d97dc7_Logistic+Regression.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/434cb8dd-bf4d-4b00-95b6-12fda6d97dc7_Logistic+Regression.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/4fda620b-ac6c-45dc-ba17-f0d68bc7888f_What+is+Ensemble+Learning_.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/4fda620b-ac6c-45dc-ba17-f0d68bc7888f_What+is+Ensemble+Learning_.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/cf3780cd-e699-45fe-acf7-afd32260e819_Accuracy+vs.+precision+vs.+recall+in+Machine+Learning+-+Encord.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/cf3780cd-e699-45fe-acf7-afd32260e819_Accuracy+vs.+precision+vs.+recall+in+Machine+Learning+-+Encord.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6eced55d-aef1-4b54-a205-75401ba5a717_Supervised+Learning.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6eced55d-aef1-4b54-a205-75401ba5a717_Supervised+Learning.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6f443587-6ec4-4d94-8305-26a1105f6aae_encord_minigptv2-explained.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6f443587-6ec4-4d94-8305-26a1105f6aae_encord_minigptv2-explained.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/554711cf-3104-4928-b544-98bd71fe33df_image8.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/554711cf-3104-4928-b544-98bd71fe33df_image8.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/563c021e-b9e7-429e-8f7d-d2d2f8a6f447_image+%2822%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/563c021e-b9e7-429e-8f7d-d2d2f8a6f447_image+%2822%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/9916d1b4-0301-445a-9ddf-0ce7d49b7e58_Zero+Shot+learning.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/9916d1b4-0301-445a-9ddf-0ce7d49b7e58_Zero+Shot+learning.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/f7b668b0-5eba-44a2-a94c-0235e17bd23b_image+%2851%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/f7b668b0-5eba-44a2-a94c-0235e17bd23b_image+%2851%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/36f1c0c4-3a58-43f8-be1b-c47015e3c53b_image+%2828%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/36f1c0c4-3a58-43f8-be1b-c47015e3c53b_image+%2828%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/bcda5a6a-c5ef-4a12-941f-55e68ac2e654_image11.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/bcda5a6a-c5ef-4a12-941f-55e68ac2e654_image11.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/1d87906c-9b2b-4f11-a870-0643de9622cb_image+%289%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/1d87906c-9b2b-4f11-a870-0643de9622cb_image+%289%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/a5804c5c-7b06-4885-9ba5-6ef200128f0c_image12.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/a5804c5c-7b06-4885-9ba5-6ef200128f0c_image12.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/e0fc86ea-0e65-4fc0-84b0-6a9b7a997b61_Embeddings.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/e0fc86ea-0e65-4fc0-84b0-6a9b7a997b61_Embeddings.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/f1785eed-f171-4505-9a23-695d99e4c115_HITL+Machine+Learning.jpg?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/f1785eed-f171-4505-9a23-695d99e4c115_HITL+Machine+Learning.jpg?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/098c8d25-b894-466f-b509-d2a019340b73_Algorithms+through+FDA+Approval.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/098c8d25-b894-466f-b509-d2a019340b73_Algorithms+through+FDA+Approval.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/fcea7f90-a40b-401d-82a6-5c55b8df61a1_Fireside+chat+banner+%281%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/fcea7f90-a40b-401d-82a6-5c55b8df61a1_Fireside+chat+banner+%281%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/8785958f-a555-4179-b52d-909775c15282_YOLOv8+for+Object+detection.webp?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/8785958f-a555-4179-b52d-909775c15282_YOLOv8+for+Object+detection.webp?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/581f3915-124b-4880-b1b8-3e41353f1967_First+ML+Model.webp?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/581f3915-124b-4880-b1b8-3e41353f1967_First+ML+Model.webp?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6a5f3933-d206-4ec9-a5d6-a4ef96251664_2500.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/6a5f3933-d206-4ec9-a5d6-a4ef96251664_2500.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/a268d8fd-6606-4cfd-9d96-90b1c9fc4823_2100.jpg?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/a268d8fd-6606-4cfd-9d96-90b1c9fc4823_2100.jpg?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/0660fd76-04e1-4e1d-8640-d5dea7d6b754_image+%2826%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/0660fd76-04e1-4e1d-8640-d5dea7d6b754_image+%2826%29.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/4eb41801-1c85-41c6-a038-c853c620b1bf_Image+Annotation.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://images.prismic.io/encord/4eb41801-1c85-41c6-a038-c853c620b1bf_Image+Annotation.png?auto=compress%2Cformat&fit=max&w=368&h=270",
            "https://cdn.drata.com/badge/soc2-dark.png",
            "https://images.prismic.io/encord/d5a5f02e-d8df-49c2-9413-5633a8e75e7d_soc2-certificate.png?auto=compress,format",
            "https://encord.cdn.prismic.io/encord/ZoZ1tR5LeNNTwyYw_g22024.svg",
            "https://dc.ads.linkedin.com/collect/?pid=4241362&fmt=gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Jonathon Byrd"
        ],
        "publish_date": "2023-11-08T13:57:25+00:00",
        "summary": "",
        "meta_description": "Data clustering involves grouping data based on inherent similarities without predefined categories. The main benefits of data clustering include simplifying complex data, revealing hidden structures, and aiding in decision-making. Let’s understand more with the help of an example. Data analysis using data clustering is a particularly interesting approach where you look at the entities or items by their general notion and not by their value.",
        "meta_lang": "en",
        "meta_favicon": "/apple-touch-icon.png",
        "meta_site_name": "",
        "canonical_link": "https://encord.com/blog/data-clustering-intro-methods-applications/",
        "text": "Mastering Supervised Learning: A Comprehensive Guide\n\nArtificial Intelligence (AI) has witnessed remarkable advancements in recent years, revolutionizing industries and reshaping how we interact with technology. At the core of these developments lies supervised learning, a fundamental concept in machine learning. In this comprehensive guide, we will delve deep into the world of supervised learning, exploring its significance, processes, and various facets like its significance, training a model on labeled data, the relationship between input features and output labels, generalizing knowledge, and making accurate predictions. By the end of this article, you'll have a firm grasp of what supervised learning is and how it can be applied to solve real-world problems. Definition and Brief Explanation of Supervised Learning Supervised Learning is a type of machine learning where algorithms learn from labeled data to make predictions. In simpler terms, it's like teaching a machine to recognize patterns or relationships in data based on the examples you provide. These examples, also known as training data, consist of input features and their corresponding target labels. The objective is to build a model to learn from this training data to make accurate predictions or classifications on new, unseen data. Supervised Learning In machine learning, four main learning paradigms are commonly recognized: supervised, self-supervised, unsupervised, and reinforcement learning. As opposed to supervised learning, unsupervised learning deals with unlabeled data within a dataset; self-supervised learning is where the model learns from the data without explicit supervision or labeling; and in reinforcement learning, an agent learns to make decisions by interacting with an environment and receiving feedback in the form of rewards or punishments. Interested in learning more about self-supervised learning (SSL) and how it compares to supervised and unsupervised learning? Read our explainer article, “Self-supervised Learning Explained.” Importance and Relevance of Supervised Learning in AI Supervised learning is the foundation of many AI applications that impact our daily lives, from spam email detection to recommendation systems on streaming platforms. From medical diagnosis to autonomous driving, supervised learning plays a pivotal role. Its ability to learn from historical data and make predictions makes it versatile for progress in AI. As AI continues to evolve, supervised learning remains an indispensable part. It powers applications in natural language processing, computer vision, and speech recognition, making it vital for developing intelligent systems. Understanding how supervised learning works is essential for anyone interested in AI and machine learning. Overview This article can prove to be a beginner’s guide to supervised learning, and here we will take a structured approach to understanding supervised learning: What is Supervised Learning: We'll start by breaking down the basic concept of supervised learning and examining the critical components involved. Types of Supervised Learning Algorithms: We will explore the different supervised learning algorithms and their characteristics, including classification and regression. You’ll learn examples of popular algorithms within each category. Data Preparation for Supervised Learning: Labeled data is the lifeblood of supervised learning, and we'll discuss the essential steps involved in preparing and cleaning data. We will also explain feature engineering, a crucial aspect of data preparation. Model Evaluation and Validation: Once a model is trained, it must be evaluated and validated to ensure its accuracy and reliability. We'll delve into various evaluation metrics and techniques used in this phase. Challenges and Future Directions: We'll discuss some of the difficulties in supervised learning and glimpse into the future, considering emerging trends and areas of research. Key Takeaways: Finally, we’ll quickly go through the main ingredients of the whole recipe for supervised learning. Now, let's embark on our journey to understand supervised learning. What is Supervised Learning? Supervised learning is a type of machine learning where an algorithm learns from labeled datasets to make predictions or decisions. It involves training a model on a dataset that contains input features and corresponding output labels, allowing the model to learn the relationship between the inputs and outputs. Basic Concept Supervised Learning operates under the assumption that there is a relationship or pattern hidden within the data that the model can learn and then apply to new, unseen data. In this context, \"supervised\" refers to providing guidance or supervision to the algorithm. Think of it as a teacher guiding a student through a textbook. The teacher knows the correct answers (the target labels), and the student learns by comparing their answers (predictions) to the teacher's. Main Components: Input Features and Target Labels To understand supervised learning fully, it's crucial to grasp the main components and processes involved. In supervised learning, labeled data is used to train a model, where each data point is associated with a corresponding target or output value. The model learns from this labeled data to make predictions or classify new, unseen data accurately. Additionally, supervised learning requires the selection of an appropriate algorithm and the evaluation of the model's performance using metrics such as accuracy or precision. It's crucial to grasp the two main components: input features target labels. Input Features: These are the variables or attributes that describe the data. For instance, in a spam email detection system, the input features might include the sender's email address, subject line, and the content of the email. The algorithm uses these features to make predictions. Target Labels: Target labels are the values we want the algorithm to predict or classify. In the case of spam email detection, the target labels would be binary: “spam” (1) or “not spam” (0). These labels are provided as part of the training data. ⚡Learn more: The Full Guide to Training Datasets for Machine Learning. Training a Supervised Learning Model Training a supervised learning model involves iteratively adjusting its parameters to minimize the difference between its predictions and the target values in the labeled data. This process is commonly known as optimization. During training, the model learns the underlying patterns and relationships in the data, allowing it to generalize and make accurate predictions on unseen data. However, it is important to note that the performance of a supervised learning model depends on the quality and representativeness of the labeled data used for training. Supervised Learning Flowchart Training a supervised learning model involves several key steps: Data Collection: The first step is to gather labeled data, which typically consists of input features and their corresponding target labels. This data should be representative of the problem you want to solve. Data curation: The process of cleaning and organizing the collected data to ensure its quality and reliability. This step involves removing any outliers or inconsistencies, handling missing values, and transforming the data into a suitable format for training the model. Data Splitting: The collected data is usually divided into two subsets: the training dataset and the test data. Train the model with the training dataset, while the test data is reserved for evaluating its performance. Model Selection: Depending on the problem at hand, you choose an appropriate supervised learning algorithm. For example, if you're working on a classification task, you might opt for algorithms like logistic regression, support vector machines, or decision trees. Training the Model: This step involves feeding the training data into the chosen algorithm, allowing the model to learn the patterns and relationships in the data. The training iteratively adjusts its parameters to minimize prediction errors with its learning techniques. Model Evaluation: After training, you evaluate the model's performance using the test set. Standard evaluation metrics include accuracy, precision, recall, and F1-score. Fine-tuning: If the model's performance is unsatisfactory, you may need to fine-tune its hyperparameters or consider more advanced algorithms. This step is crucial for improving the model's accuracy. Deployment: Once you're satisfied with the model's performance, you can deploy it to make predictions on new, unseen data in real-world applications. Now that we've covered the fundamentals of supervised learning, let's explore the different types of supervised learning algorithms. Types of Supervised Learning Algorithms Types of supervised learning Algorithms include linear regression, logistic regression, decision trees, random forests, support vector machines, and neural networks. Each algorithm has its strengths and weaknesses, and the choice of algorithm depends on the specific problem and data at hand. It is also important to consider factors such as interpretability, computational efficiency, and scalability when selecting a supervised learning algorithm. Additionally, ensemble methods such as bagging and boosting can combine multiple models to improve prediction accuracy. Supervised learning can be categorized into two main types: Classification Regression Each type has its own characteristics and is suited to specific use cases. Supervised Learning Algorithms Classification Classification is a type of supervised learning where the goal is to assign data points to predefined categories or classes. In classification tasks, the target labels are discrete and represent different classes or groups. Naive Bayes is a classification algorithm commonly used in supervised learning. It is particularly useful for solving classification problems, spam email detection, and sentiment analysis, where it learns the probability of different classes based on the input features. Here are some key points about classification: Binary Classification: In binary classification, there are only two possible classes, such as spam or not spam, fraud or not fraud, and so on. Multiclass Classification: Multiclass classification involves more than two classes. For example, classifying emails as spam, promotional, social, and primary. Examples of Classification Algorithms: Popular classification algorithms include logistic regression, support vector machines, decision trees, random forests, and neural networks. Use Cases: Classification is used in various applications, including sentiment analysis, image recognition, fraud detection, document categorization, and disease diagnosis. Regression Regression, on the other hand, is a type of supervised learning where the goal is to predict continuous values or numerical quantities. In regression tasks, the target labels are real numbers, and the model learns to map input features to a continuous output. Here are some key points about regression: Examples of Regression Algorithms: Common regression algorithms include linear regression, polynomial regression, ridge regression, and support vector regression. Use Cases: Regression is applied in scenarios like stock price prediction, real estate price estimation, and weather forecasting, where the goal is to make numerical predictions. Examples of Popular Algorithms Within Each Category Logistic Regression (Classification): Despite its name, logistic regression is used for binary classification. It models the probability of a data point belonging to one of the two classes, making it a fundamental algorithm in classification tasks. Decision Trees (Classification and Regression): Decision trees can be used for both classification and regression tasks. They break down a data set into smaller subsets based on input features and create a tree-like structure to make predictions. Linear Regression (Regression): Linear regression model is a simple yet powerful algorithm for regression tasks. It assumes a linear relationship between the input features and the target variable and tries to fit a straight line to the data. Random Forests (Classification and Regression): Random forests are an ensemble method that combines multiple decision trees to improve accuracy. They can be used for classification and regression problems and are known for their robustness. Some data scientists use the K-Nearest Neighbors (KNN) and K-Means algorithms for data classification and regression. These algorithms enable applications like spam email detection and sales forecasting. KNN is typically associated with unsupervised learning but can also be used in supervised learning. Another algorithm that is used for both regression and classification problems is Support Vector Machines (SVM). SVM aims to create the best line or decision boundary to segregate n-dimensional space into classes. Now that we've explored the types of supervised learning algorithms, let's move on to another stage of the workflow—data preparation. Data Preprocessing for Supervised Learning Data preprocessing is an essential step in supervised learning. It involves cleaning and transforming raw data into a format suitable for training a model. Common techniques used in data preprocessing include handling missing values, encoding categorical variables, and scaling numerical features. Additionally, you can perform feature selection or extraction to reduce the dimensionality of the dataset and likely improve model performance. Data Preprocessing in Machine Learning Data Cleaning Data cleaning is a crucial part of data preprocessing. It involves removing or correcting any errors, inconsistencies, or outliers in the dataset. Data cleaning techniques include removing duplicate entries, correcting typos or spelling errors, and handling noisy or irrelevant data. Missing Data in datasets is a common issue that can be addressed through techniques like deleting missing rows, imputing values, or using advanced imputation methods, but the most appropriate method depends on the dataset and research objectives. Noisy Data containing errors or inconsistencies from measurement, data entry, or transmission can be addressed through techniques like smoothing, filtering, outlier detection, and removal methods. Data cleaning is also known as data cleansing or data preprocessing. Learn more about data cleaning and preprocessing through our detailed guide. Data Transformation Data transformation is another technique commonly used to address noisy data. This involves converting the data into a different form or scale, such as logarithmic or exponential transformations, to make it more suitable for analysis. Another approach is to impute missing values using statistical methods, which can help fill in gaps in the data and reduce the impact of missing information on the analysis. Normalization standardizes the data range, allowing fair comparisons (considering the different units of variables) and reducing outliers, making it more robust and reliable for analysis when dealing with variables with different units or scales. Attribute Selection is a crucial step in selecting the most relevant and informative attributes from a dataset, reducing dimensionality, improving efficiency, avoiding overfitting, and enhancing interpretability. Discretization converts continuous variables into discrete categories or intervals, simplifying the analysis process and making results easier to interpret. Concept Hierarchy Generation sorts data into hierarchical structures based on connections and similarities. This helps us understand both discrete and continuous variables better. They also make it easier to interpret data and make decisions. Data Reduction Data reduction is a crucial technique in data analysis, reducing dataset complexity by transforming variables, simplifying the analysis process, improving computational efficiency, and removing redundant or irrelevant variables. Data Cube Aggregation summarizes data across multiple dimensions, providing a higher-level view for analysis. This technique aids in quick and efficient decision-making by analyzing large volumes of data. Attribute Subset Selection reduces data size, allowing you to focus on key factors contributing to patterns and insights, resulting in more accurate and efficient analysis results. Four methods are used to determine the most relevant attributes for analysis by evaluating their significance and contribution to the overall pattern. They are: undefinedundefinedundefinedundefined Numerosity Reduction reduces the data size without losing essential information, improving computational efficiency and speeding up analysis processes, particularly for large datasets. Dimensionality Reduction reduces variables while retaining relevant information. It's especially useful for high-dimensional data, eliminating noise and redundancy for better analysis. Introduction to the Concept of Feature Engineering and Its Impact on Model Performance Feature engineering is both an art and a science in machine learning. It involves creating new features from the existing ones or transforming features to better represent the underlying patterns in the data. Effective feature engineering can significantly boost a model's performance, while poor feature engineering can hinder it. Feature Engineering for Machine Learning Here are some examples of feature engineering: Feature Scaling: As mentioned earlier, feature scaling can be considered a form of feature engineering. It ensures that all features have a similar scale and can contribute equally to the model's predictions. Feature Extraction: In some cases, you may want to reduce the dimensionality of your data. Feature extraction techniques like Principal Component Analysis (PCA) can help identify the most critical features while reducing noise (irrelevant features). Text Data Transformation: When working with text data, techniques like TF-IDF (Term Frequency-Inverse Document Frequency) and word embeddings (e.g., Word2Vec) can convert text into numerical representations that machine learning models can process. Feature engineering is a creative process that requires a deep understanding of the data and the problem. It involves experimentation and iteration to find the most informative features for your model. With our data prepared and our model trained, the next critical step is evaluating and validating the supervised learning model. Model Evaluation and Validation Model evaluation and validation help you assess the performance of your model and ensure that it generalizes well to unseen data. Proper evaluation and validation help you identify any issues with your model, such as underfitting or overfitting, and make the necessary adjustments to improve its performance. Model Validation and Evaluation The Importance of Evaluating and Validating Supervised Learning Models Evaluating and validating supervised learning models is crucial to ensure they perform as expected in real-world scenarios. Without proper evaluation, a model might not generalize effectively to unseen data, leading to inaccurate predictions and potentially costly errors. Here's why model evaluation and validation are essential: Generalization Assessment: The goal of supervised learning is to create models that can make accurate predictions on new, unseen data. Model evaluation helps assess how well a model generalizes beyond the training data. Comparison of Models: In many cases, you might experiment with multiple algorithms or variations of a model. Model evaluation provides a basis for comparing these models and selecting the best-performing one. Tuning Hyperparameters: Model evaluation guides the fine-tuning of hyperparameters. By analyzing a model's performance on validation data, you can adjust hyperparameters to improve performance. Overview of Common Evaluation Metrics There are several evaluation metrics used in supervised learning, each suited to different types of problems. Here are some of the most common evaluation metrics: Accuracy: Accuracy measures the proportion of correctly classified instances out of all instances in the test set. It's a suitable metric for balanced datasets but can be misleading when dealing with imbalanced data. Precision: Precision measures the ratio of true positive predictions to the total positive predictions. It is particularly useful when the cost of false positives is high. Recall: Recall (or sensitivity) measures the ratio of true positives to all actual positives. It is essential when it's crucial to identify all positive instances, even if it means having some false positives. F1-Score: The F1-score is the harmonic mean of precision and recall. It provides a balanced measure of a model's performance, especially when dealing with imbalanced datasets. Confusion Matrix: A confusion matrix is a table that summarizes the model's predictions and actual class labels. It provides a more detailed view of a model's performance, showing true positives, true negatives, false positives, and false negatives. Model Evaluation Techniques To evaluate and validate supervised learning models effectively, you can employ various techniques: Cross-Validation: Cross-validation involves splitting the data into multiple subsets and training and testing the model on different subsets. This helps assess how well the model generalizes to other data partitions. Learning Curves: Learning curves visualize how a model's performance changes as the size of the training data increases. They can reveal whether the model is underfitting or overfitting. ROC Curves and AUC: Receiver Operating Characteristic (ROC) curves show the trade-off between true positive rate and false positive rate at different classification thresholds. The Area Under the Curve (AUC) quantifies the overall performance of a binary classification model. Validation Sets: Besides the training and test sets, a validation set is often used to fine-tune models and avoid overfitting. The validation set helps make decisions about hyperparameters and model selection. By diligently applying these evaluation techniques and metrics, you can ensure that your supervised learning model is robust, accurate, and ready for deployment in real-world scenarios. Through predictive analytics and predictive modeling, supervised learning empowers teams to make data-driven decisions by learning from historical data. Challenges and Future Directions While supervised learning has achieved remarkable success in various domains, it has its challenges. Some of the key challenges in supervised learning include: Data Quality: The quality of the training data heavily influences model performance. Noisy, biased, or incomplete data can lead to inaccurate predictions. Overfitting: Overfitting occurs when a model learns to memorize the training data rather than generalize from it. Techniques like regularization and cross-validation can mitigate this issue. Imbalanced Data: Imbalanced datasets can lead to biased models that perform poorly for underrepresented classes. Resampling techniques and specialized algorithms can address this challenge. Curse of Dimensionality: As the dimensionality of the feature space increases, the amount of data required for effective modeling also increases. Dimensionality reduction techniques can help manage this issue. Interpretability: Deep learning models, such as neural networks, are often considered \"black boxes\" due to their complexity. Ensuring model interpretability is an ongoing challenge. Looking ahead, the field of supervised learning continues to evolve. Some promising directions include: Transfer Learning: Transfer learning allows models trained on one task to be adapted for use on another, reducing the need for massive amounts of labeled data. Pre-Trained Models: These allow practitioners to leverage the knowledge and feature representations learned from vast, general datasets, making it easier and more efficient to develop specialized models for specific tasks. AutoML: Automated Machine Learning (AutoML) tools are becoming more accessible, allowing individuals and organizations to build and deploy models with minimal manual intervention. Responsible AI: Responsible AI ensures ethical, fair, and accountable AI systems, considering societal impacts, mitigating harm, and promoting transparency and explainability for clear decision-making. undefinedundefinedundefinedundefined Bias in Machine Learning refers to systematic errors introduced by algorithms or training data that lead to unfair or disproportionate predictions for specific groups or individuals. Learn how to mitigate model bias in Machine Learning. Supervised Learning: Key Takeaways Supervised learning is a foundational concept in data science, where data scientists leverage various techniques, including Naive Bayes, to build predictive models. It plays a pivotal role in various AI applications, including spam email detection, recommendation systems, medical diagnosis, and autonomous driving, making it essential to develop intelligent systems. The structured approach to understanding supervised learning includes input features, target labels, data preparation, model training, evaluation, and deployment. There are two main types of supervised learning algorithms: classification (for assigning data points to predefined categories) and regression (for predicting continuous values). Data scientists select appropriate algorithms, such as K-Nearest Neighbors (KNN), to classify or regress data points, enabling applications like spam email detection or sales forecasting. Common techniques for data preparation include data cleaning, feature scaling, feature engineering, one-hot encoding, and handling imbalanced data. Model evaluation and validation are crucial for assessing performance, generalization, and fine-tuning hyperparameters in supervised learning, despite challenges like data quality and interpretability.\n\nNov 08 2023\n\n8 M\n\nTraining vs. Fine-tuning: What is the Difference?\n\nTraining and fine-tuning are crucial stages in the machine learning model development lifecycle, serving distinct purposes. This article explains the intricacies of both methodologies, highlighting their differences and importance in ensuring optimal model performance. Training in the context of deep learning and neural networks refers to the phase where a new model learns from a dataset. During this phase, the model adjusts its model weights based on the input data and the corresponding output, often using embeddings and activation functions. While embeddings and activation functions play significant roles in certain model architectures and tasks, they are not universally employed during the training phase of all deep learning models. It's crucial to understand the specific context and model architecture to determine their relevance. The objective is to diminish the discrepancy between the anticipated and factual output, frequently termed error or loss. This is predominantly achieved using algorithms like backpropagation and optimization techniques like gradient descent. Fine-tuning, conversely, follows the initial training, where a pre-trained model (previously trained on a vast dataset like ImageNet) is trained on a smaller, task-specific dataset. The rationale is to leverage the knowledge the model has acquired from the initial training process and tailor it to a more specific task. This becomes invaluable, especially when the new dataset for the new task is limited, as training from scratch might lead to overfitting. As training stars, the neural network's weights are randomly initialized or set using methods like He or Xavier initialization. These weights are fundamental in determining the model's predictions. As the training progresses, these weights adjust to minimize the error, guided by a specific learning rate. Conversely, during fine-tuning, the model starts with pre-trained weights from the initial training, which are then fine-tuned to suit the new task better, often involving techniques like unfreezing certain layers or adjusting the batch size. The training aims to discern patterns and features from the data, creating a base model that excels on unseen data and is often validated using validation sets. Fine-tuning, however, zeroes in on adapting a generalized model for a specific task, often leveraging transfer learning to achieve this. While training focuses on generalizing models, fine-tuning refines this knowledge to cater to specific tasks, making it a crucial topic in NLP with models like BERT, computer vision tasks like image classification, and, more recently, the proliferation of foundation models. Learn more: Visual Foundation Models (VFMs) by Lead ML Engineer at Encord, Frederik Hvilshøj. The Training Process Initialization of Weights Random Initialization In deep learning, initializing the weights of neural networks is crucial for the training process. Random initialization is a common method where weights are assigned random values. This method ensures a break in symmetry among neurons, preventing them from updating similarly during backpropagation. However, random initialization can sometimes lead to slow convergence or the vanishing gradient problem. He or Xavier Initialization Specific strategies, like He or Xavier initialization, have been proposed to address the challenges of random initialization. He initialization, designed for ReLU activation functions, initializes weights based on the size of the previous layer, ensuring that the variance remains consistent across layers. On the other hand, Xavier initialization, suitable for tanh activation functions, considers the sizes of the current and previous layers. These methods help with faster and more stable convergence. Backpropagation and Weight Updates Gradient Descent Variants Backpropagation computes the gradient of the loss function concerning each weight by applying the chain rule. Various gradient descent algorithms update the weights and minimize the loss. The most basic form is the Batch Gradient Descent. However, other variants like Stochastic Gradient Descent (SGD) and Mini-Batch Gradient Descent have been introduced to improve efficiency and convergence. Role of Learning Rate The learning rate is a hyperparameter that dictates the step size during weight updates. A high learning rate might overshoot the optimal point, while a low learning rate might result in slow convergence. Adaptive learning rate methods like Adam, RMSprop, and Adagrad adjust the learning rate during training, facilitating faster convergence without manual tuning. Regularization Techniques Dropout Overfitting is a common pitfall in deep learning, where the model performs exceptionally well on the training data but needs to improve on unseen data. Dropout is a regularization technique that mitigates overfitting. During training, random neurons are \"dropped out\" or deactivated at each iteration, ensuring the model does not rely heavily on any specific neuron. Dropout Neural Networks L1 and L2 Regularization L1 and L2 are other regularization techniques that add a penalty to the loss function. L1 regularization adds a penalty equivalent to the absolute value of the weights' magnitude, which aids feature selection. L2 regularization adds a penalty based on the squared magnitude of weights, preventing weights from reaching extremely high values. Both methods help in preventing overfitting, penalizing complex models, and producing a more generalized model. L1 and L2 Regualization The Fine-tuning Process Transfer Learning: The Backbone of Fine-tuning Transfer learning is a technique where a model developed for a task is adapted for a second related task. It is a popular approach in deep learning where pre-trained models are used as the starting point for computer vision and natural language processing tasks due to the extensive computational resources and time required to train models from scratch. Pre-trained models save the time and resources needed to train a model from scratch. They have already learned features from large datasets, which can be leveraged for a new task with a smaller dataset. This is especially useful when acquiring labeled data is challenging or costly. When fine-tuning, it's common to adjust the deeper layers of the model while keeping the initial layers fixed. The rationale is that the initial layers capture generic features (like edges or textures), while the deeper layers capture more task-specific patterns. However, the extent to which layers are fine-tuned can vary based on the similarity between the new task and the original task. Strategies for Fine-tuning One of the key strategies in fine-tuning is adjusting the learning rates. A lower learning rate is often preferred because it makes the fine-tuning process more stable. This ensures the model retains the previously learned features without drastic alterations. Another common strategy is freezing the initial layers of the model during the fine-tuning process. This means that these layers won't be updated during training. As mentioned, the initial layers capture more generic features, so fixing them is often beneficial. Applications and Use Cases Domain Adaptation Domain adaptation refers to the scenario where the source and target tasks are the same, but the data distributions differ. Fine-tuning can be used to adapt a model trained on source data to perform well on target data. Domain Adaptation Data Augmentation Data augmentation involves creating new training samples by applying transformations (like rotations, scaling, and cropping) to the existing data. Combined with fine-tuning, it can improve the model's performance, especially when the available labeled data is limited. Data Augmentation Comparative Analysis Benefits of Training from Scratch Customization: Training a model from scratch allows complete control over its architecture, making it tailored specifically for the task. No Prior Biases: Starting from scratch ensures the model doesn't inherit any biases or unwanted features from pre-existing datasets. Deep Understanding: Training a model from the ground up can provide deeper insights into the data's features and patterns, leading to a more robust model for specific datasets. Optimal for Unique Datasets: For datasets significantly different from existing ones, training from scratch might yield better results as the model learns features unique to that dataset. Limitations of Training from Scratch This approach requires more time as the model learns features from the ground up and requires a large, diverse dataset for optimal performance. With the right data and regularization, models can easily fit. Extended Training Time: Starting from the basics means the model has to learn every feature, leading to prolonged training durations. Data Dependency: Achieving optimal performance mandates access to a vast and varied dataset, which might only sometimes be feasible. Risk of Overfitting: Without adequate data and proper regularization techniques, models can overfit, limiting their generalization capabilities on unseen data. Advantages of Fine-Tuning Efficiency in Training: Utilizing pre-trained models can expedite the training process, as they have already grasped foundational features from extensive datasets. Data Economy: Since the model has undergone training on vast datasets, fine-tuning typically demands a smaller amount of data, making it ideal for tasks with limited datasets. Limitations of Fine-Tuning Compatibility Issues: Ensuring that the input and output formats, as well as the architectures and frameworks of the pre-trained model, align with the new task can be challenging. Overfitting: Fine-tuning on a small dataset can lead to overfitting, which reduces the model's ability to generalize to new, unseen data. Knowledge Degradation: There's a risk that the model might forget some of the features and knowledge acquired during its initial training, a phenomenon often referred to as \"catastrophic forgetting.\" Bias Propagation: Pre-trained models might carry inherent biases. When fine-tuned, these biases can be exacerbated, especially in applications that require high sensitivity, such as facial recognition. Optimizing your hyperparameters is a key process for getting your pre-trained models to learn the dataset during fine-tuning. Interested in learning more about hyperparameter optimization while fine-tuning models? Check out our article. Research Breakthroughs Achieved Through Fine-tuning Fine-tuning in NLP BERT (Bidirectional Encoder Representations from Transformers) has been a cornerstone in the NLP community. Its architecture allows for capturing context from both directions (left-to-right and right-to-left) in a text, making it highly effective for various NLP tasks. In 2023, we have seen advancements in BERT and its variants. One such development is \"Ferret: Refer and Ground Anything Anywhere at Any Granularity.\" This Multimodal Large Language Model (MLLM) can understand the spatial reference of any shape or granularity within an image and accurately ground open-vocabulary descriptions. Such advancements highlight the potential of fine-tuning pre-trained models like BERT to achieve specific tasks with high precision. Fine-tuning in Computer Vision Models like ResNet and VGG have been foundational in computer vision. These architectures, with their deep layers, have been pivotal in achieving state-of-the-art results on various image classification tasks. In 2023, a significant breakthrough, \"Improved Baselines with Visual Instruction Tuning,\" was introduced. This research emphasized the progress of large multimodal models (LMM) with visual instruction tuning. Such advancements underscore the importance of fine-tuning in adapting pre-trained models to specific tasks or datasets, enhancing their performance and utility. Training vs Fine-tuning: Key Takeaways Training and fine-tuning are pivotal processes in deep learning and machine learning. While training involves initializing model weights and building a new model from scratch using a dataset, fine-tuning leverages pre-trained models and tailors them to a specific task. Opting for training from scratch is ideal when you have a large dataset vastly different from available pre-trained models like those on Imagenet. It's also the preferred strategy when there's an absence of pre-existing models on platforms like TensorFlow Hub, PyTorch Zoo, or Keras that align with the task. On the flip side, fine-tuning is advantageous when the dataset at hand is smaller or when the new task mirrors the objectives of the pre-trained model. This approach, backed by optimization techniques like adjusting the learning rate, allows for swifter convergence and frequently culminates in superior performance, especially in scenarios with limited training data. Future Trends and Predictions: The deep learning community, including platforms like OpenAI, is progressively gravitating towards fine-tuning, especially with the advent of large language models and transformers. This inclination is anticipated to persist, especially with the ascent of transfer learning and the triumph of models like BERT in NLP and ResNet in computer vision. As neural networks evolve and datasets expand, hybrid methodologies that amalgamate the strengths of both training and fine-tuning paradigms may emerge, potentially blurring the demarcation between the two.\n\nNov 07 2023\n\n5 M\n\nAn Introduction to Cross-Entropy Loss Functions\n\nLoss functions are widely used in machine learning tasks for optimizing models. The cross-entropy loss stands out among the many loss functions available, especially in classification tasks. But why is it so significant? Cross-entropy loss is invaluable in certain scenarios, particularly when interpreting the outputs of neural networks that utilize the softmax function, a common practice in deep learning models. This loss function measures the difference between two probability distributions, reflecting how well the model predicts the actual outcomes. The term \"surrogate loss\" refers to an alternative loss function used instead of the actual loss function, which might be difficult to compute or optimize. In this context, cross-entropy can be considered a surrogate for other more complex loss functions, providing a practical approach for model optimization. In the broader theoretical landscape of machine learning, there's an extensive analysis of a category of loss functions, often referred to in research as \"composite loss\" or \"sum of losses.\" This category includes cross-entropy (also known as logistic loss), generalized cross-entropy, mean absolute error, and others. These loss functions are integral to providing non-asymptotic guarantees and placing an upper boundary on the estimation error of the actual loss based on the error values derived from the surrogate loss. Such guarantees are crucial as they influence the selection of models or hypotheses during the learning process. Researchers have been delving into novel loss functions designed for more complex, often adversarial, machine learning environments. For instance, certain innovative loss functions have been crafted by incorporating smoothing terms into traditional forms. These \"smoothed\" functions enhance model robustness, especially in adversarial settings where data alterations can mislead learning processes. These advancements are paving the way for new algorithms that can withstand adversarial attacks, fortifying their predictive accuracy. Foundations of Loss Functions Loss functions are the backbone of machine learning optimization, serving as critical navigational tools that guide the improvement of models during the training process. These functions present a measure that models strive to minimize, representing the difference or 'loss' between predicted and actual known values. While the concept of maximizing a function, often referred to as a \"reward function,\" exists, particularly in reinforcement learning scenarios, the predominant focus in most machine learning contexts is minimizing the loss function. Role in Model Optimization Central to model optimization is the gradient descent process, which adjusts model parameters iteratively to minimize the loss function. This iterative optimization is further powered by backpropagation, an algorithm that calculates the gradient of the loss function concerning the model parameters. However, the optimization landscape is fraught with challenges. One of the primary concerns is the convergence to local minima instead of the global minimum. In simple terms, while the model might think it has found the optimal solution (local minimum), there might be a better overall solution (global minimum) that remains unexplored. Explanation of minima/maxima The choice and design of loss functions are crucial for optimal training of ML tasks. For instance, cross-entropy loss, commonly used in classification tasks, has properties such as being convex and providing a clear signal for model updates, making it particularly suitable for such problems. Understanding the nuances of different loss functions, including cross-entropy loss, and their impact on model optimization is essential for developing effective machine learning models. Common Loss Functions in Machine Learning Several loss functions have been developed and refined, each tailored to specific use cases. Mean Squared Error (MSE): The mean squared error (or MSE) is a quadratic loss function that measures the average squared difference between the estimated values (predictions) and the actual value. For n samples, it is mathematically represented as MSE Loss MSE Loss is widely used in regression problems. For instance, predicting house prices based on various features like area, number of rooms, and location. A model with a lower MSE indicates a better fit of the model to the data. Hinge Loss Hinge loss, or max-margin loss, is used for binary classification tasks. It is defined as Hinge Loss Function Here, 0 is for correct classifications, and 1 is for wrong classifications. The hinge loss is near zero if the prediction is correct and with a substantial margin from the decision boundary (high confidence). However, the loss increases as the prediction is either wrong or correct, but with a slim margin from the decision boundary. Hinge loss is commonly associated with Support Vector Machines (SVM). It's used in scenarios where a clear margin of separation between classes is desired, such as in image classification or text categorization. Log Loss (Logistic Loss) Log loss quantifies the performance of a classification model where the prediction input is a probability value between 0 and 1. It is defined as: Log Loss function The log loss penalizes both errors (false positives and false negatives), whereas the confidently wrong predictions are more severely penalized. Log loss is used in logistic regression and neural networks for binary classification problems. It's suitable for scenarios like email spam detection, where you want to assign a probability of an email being spam. Each loss function has unique characteristics and is chosen based on the problem's nature and the desired output type. How to select a loss function Regression: In regression tasks, where the goal is to predict a continuous value, the difference between the predicted and actual values is of primary concern. Common loss functions for regression include: Mean Squared Error (MSE): Suitable for problems where large errors are particularly undesirable since they are squared and thus have a disproportionately large impact. The squaring operation amplifies larger errors. Mean Absolute Error (MAE): Useful when all errors, regardless of magnitude, are treated uniformly. Classification: In classification tasks, where the goal is to categorize inputs into classes, the focus is on the discrepancy between the predicted class probabilities and the actual class labels. Common loss functions for classification include: Log Loss (Logistic Loss): Used when the model outputs a probability for each class, especially in binary classification. Hinge Loss: Used for binary classification tasks, especially with Support Vector Machines, focusing on maximizing the margin. Cross-Entropy Loss: An extension of log loss to multi-class classification problems. The selection of a loss function is not one-size-fits-all. It requires a deep understanding of the problem, the nature of the data, the distribution of the target variable, and the specific goals of the analysis. Entropy in Information Theory Entropy in information theory measures the amount of uncertainty or disorder in a set of probabilities. It quantifies the expected value of the information contained in a message and is foundational for data compression and encryption. Shannon's Entropy Shannon's entropy, attributed to Claude Shannon, quantifies the uncertainty in predicting a random variable's value. It is defined as: Shannon Entropy Shannon's entropy is closely related to data compression. It represents the minimum number of bits needed to encode the information contained in a message, which is crucial for lossless data compression algorithms. When the entropy is low (i.e., less uncertainty), fewer bits are required to encode the information, leading to more efficient compression. Shannon's entropy is foundational for designing efficient telecommunications coding schemes and developing compression algorithms like Huffman coding. Kullback-Leibler Divergence Kullback-Leibler (KL) Divergence measures how one probability distribution diverges from a second, expected probability distribution. It is defined as KL Divergence Equation Here are the parameters and their meanings: P: The true probability distribution, which serves as the reference. Q: The approximate probability distribution is being compared to P. x: The event or outcome for which the probabilities are defined. P(x): The probability of event x according to the true distribution P. Q(x): The probability of event x according to the distribution Q. DKL ( p || q ): The KL Divergence quantifies the difference between the two distributions. KL Divergence is used in model evaluation to measure the difference between predicted probability and true distributions. It is especially useful in scenarios like neural network training, where the goal is to minimize the divergence between the predicted and true distributions. KL Divergence is often used for model comparison, anomaly detection, and variational inference methods to approximate complex probability distributions. Cross-Entropy: From Theory to Application Mathematical Derivation Cross-entropy is a fundamental concept in information theory that quantifies the difference between two probability distributions. It builds upon the foundational idea of entropy, which measures the uncertainty or randomness of a distribution. The cross-entropy between two distributions, P and Q, is defined as: Cross Entropy between P & Q P(x) is the probability of event x in distribution P, and Q(x) is the probability of event x in distribution Q. 1. Log-likelihood function and maximization: The log-likelihood measures how well a statistical model predicts a sample. In machine learning, maximizing the log-likelihood is equivalent to minimizing the cross-entropy between the true data distribution and the model's predictions. 2. Relationship with Kullback-Leibler divergence: The Kullback-Leibler (KL) divergence is another measure of how one probability distribution differs from a second reference distribution. Cross-entropy can be expressed in terms of KL divergence and the entropy of the true distribution: Where H(p) is the entropy of distribution p, and DKL(p || q) is the KL divergence between distributions p and q. Binary vs. Multi-Class Cross-Entropy Cross-entropy is a pivotal loss function in classification tasks, measuring the difference between two probability distributions. Cross-entropy formulation varies depending on the nature of the classification task: binary or multi-class. Binary Cross-Entropy: This is tailored for binary classification tasks with only two possible outcomes. Given \\( y \\) as the actual label (either 0 or 1) and \\( \\hat{y} \\) as the predicted probability of the label being 1, the binary cross-entropy loss is articulated as: This formulation captures the divergence of the predicted probability from the actual label. Categorical Cross-Entropy: Suited for multi-class classification tasks, this formulation is slightly more intricate. If \\( P \\) represents the true distribution over classes and \\( Q \\) is the predicted distribution, the categorical cross-entropy is given by: Categorical Cross-Entropy Loss Here, the loss is computed over all classes, emphasizing the divergence of the predicted class probabilities from the true class distribution. Challenges in Multi-Class Scenarios: The complexity of multi-class cross-entropy escalates with an increase in the number of classes. A fundamental challenge is ensuring that the predicted probabilities across all classes aggregate to one. This normalization is typically achieved using the softmax function, which exponentiates each class score and then normalizes these values to yield a valid probability distribution. While binary and multi-class cross-entropy aim to measure the divergence between true and predicted distributions, their mathematical underpinnings and associated challenges differ based on the nature of the classification task. Practical Implications of Cross-Entropy Loss Cross-entropy loss is pivotal in optimizing models, especially in classification tasks. The implications of cross-entropy loss are vast and varied, impacting the speed of model convergence and regularization (to mitigate overfitting). Impact on Model Convergence Speed of Convergence: Cross-entropy loss is preferred in many deep learning tasks because it often leads to faster convergence than other loss functions. It amplifies the gradient when the predicted probability diverges significantly from the actual label, providing a stronger signal for the model to update its weights and thus encouraging faster learning. Avoiding Local Minima: The nature of the cross-entropy loss function helps models avoid getting stuck in local minima.. Cross-entropy loss penalizes incorrect predictions more heavily than other loss functions, which encourages the model to continue adjusting its parameters significantly until it finds a solution that generalizes well rather than settling for a suboptimal fit. Local Minima Regularization and Overfitting L1 and L2 Regularization: You can combine regularization techniques like L1 (Lasso) and L2 (Ridge) with cross-entropy loss to prevent overfitting. L1 regularization tends to drive some feature weights to zero, promoting sparsity, while L2 shrinks weights, preventing any single feature from overshadowing others. These techniques add penalty terms to the loss function, discouraging the model from assigning too much importance to any feature. Dropout and its effect on cross-entropy: Dropout is a regularization technique where random subsets of neurons are turned off during training. This prevents the model from becoming overly reliant on any single neuron. When combined with cross-entropy loss, dropout can help the model generalize better to unseen data. Implementing Cross-Entropy in Modern Frameworks PyTorch In PyTorch, the `nn.CrossEntropyLoss()` function is used to compute the cross-entropy loss. It's important to note that the input to this loss function should be raw scores (logits) and not the output of a softmax function because it combines the softmax activation function and the negative log-likelihood loss in one class. import tensorflow as tf loss_fn = tf.keras.losses.CategoricalCrossentropy() For binary classification tasks, `tf.keras.losses.BinaryCrossentropy()` is more appropriate: loss_fn_binary = tf.keras.losses.BinaryCrossentropy() Custom Loss Functions: TensorFlow and Keras provide flexibility in defining custom loss functions. This can be useful when the standard cross-entropy loss needs to be modified or combined with another loss function for specific applications. Advanced Topics in Cross-Entropy Label Smoothing Label smoothing is a regularization technique that prevents the model from becoming too confident about its predictions. Instead of using hard labels (e.g., [0, 1]), it uses soft labels (e.g., [0.1, 0.9]) to encourage the model to be less certain, distributing certainty between classes. Improving model generalization: Label smoothing can improve the generalization capability of models by preventing overfitting. Overfitting occurs when a model becomes too confident about its predictions based on the training data, leading to poor performance on unseen data. By using soft labels, label smoothing encourages the model to be less certain, which can lead to better generalization. Implementation and results: Most deep learning frameworks have label smoothing built-in implementations. For instance, in TensorFlow, it can be achieved by adding a small constant to the true labels and subtracting the same constant from the false labels. The results of using label smoothing can vary depending on the dataset and model architecture. Still, it can generally lead to improved performance, especially in cases where the training data is noisy or imbalanced. Cross Entropy Loss fn with Label Smoothing Focal Loss and Class Imbalance Focal loss is a modification of the standard cross-entropy loss designed to address the class imbalance problem. In datasets with imbalanced classes, the majority class can dominate the loss, leading to poor performance for the minority class. Focal Loss and Cross-Entropy Equation Origins and Context: The paper \"Focal Loss for Dense Object Detection\" delves into the challenges faced by one-stage object detectors, which have historically lagged behind the accuracy of two-stage detectors despite their potential for speed and simplicity. The authors identify the extreme foreground-background class imbalance during the training of dense detectors as the primary culprit. The core idea behind Focal Loss is to reshape the standard cross-entropy loss in a way that down-weights the loss assigned to well-classified examples. This ensures that the training focuses more on a sparse set of hard-to-classify examples, preventing the overwhelming influence of easy negatives. Addressing the class imbalance problem: Focal loss adds a modulating factor to the cross-entropy loss, which down-weights the loss contribution from easy examples (i.e., examples from the majority class) and up-weights the loss contribution from hard examples (i.e., examples from the minority class). This helps the model focus more on the minority class, leading to better performance on imbalanced datasets. Performance Implications: By focusing more on the minority class, focal loss can lead to improved performance on minority classes without sacrificing performance on the majority class. This makes it a valuable tool for tasks where the minority class is particularly important, such as medical diagnosis or fraud detection. Focal Loss Formula The parameters are: p_t is the model's estimated probability for the class with the true label t. alpha: A balancing factor, typically between 0 and 1, which can be set differently for each class. gamma: A focusing parameter, typically greater than 0, reduces the relative loss for well-classified examples, focusing more on hard, misclassified examples. Cross Entropy: Key Takeaways Cross-Entropy Loss as a Performance Measure: Cross-entropy loss is crucial in classification tasks because it quantifies the difference between the predicted probability distribution of the model and the actual distribution of the labels. It is particularly effective when combined with the softmax function in neural networks, providing a clear gradient signal that aids in faster and more efficient model training. Role of Loss Functions in Optimization: Loss functions like cross-entropy guide the training of machine learning models by providing a metric to minimize. The design of these functions, such as the convexity of cross-entropy, is essential to avoid local minima and ensure that the model finds the best possible parameters for accurate predictions. Handling Class Imbalance with Focal Loss: Focal loss is an adaptation of cross-entropy that addresses class imbalance by focusing training on hard-to-classify examples. It modifies the standard cross-entropy loss by adding a factor that reduces the contribution of easy-to-classify examples, thus preventing the majority class from overwhelming the learning process. Regularization Techniques to Prevent Overfitting: Combining cross-entropy loss with regularization techniques like L1 and L2 regularization, or dropout, can prevent overfitting. These methods add penalty terms to the loss function or randomly deactivate neurons during training, encouraging the model to generalize to new, unseen data. Label Smoothing for Improved Generalization: Label smoothing is a technique that uses soft labels instead of hard labels during training, which prevents the model from becoming overly confident about its predictions. This can lead to better generalization to unseen data by encouraging the model to distribute its certainty among the possible classes rather than focusing too narrowly on the classes observed in the training set.\n\nNov 07 2023\n\n10 M\n\nMachine Learning Trends & Stats for 2024\n\nThe world is witnessing exponential advancements in artificial intelligence and machine learning technologies. These developments are introducing advanced tools and frameworks that are revolutionizing human-machine interactions like never before. Businesses are quickly integrating AI to boost productivity and reduce costs. In fact, 83% of companies consider AI a top strategic priority. In this article, we will explore key trends and statistics to help you learn more about recent developments in AI. AI & ML Market Statistics The global AI market was worth $196.63 billion as of 2024 and is projected to grow at a CAGR of 28.46% between 2024 and 2030. Estimates suggest that by 2030, AI will contribute around $15.7 trillion to the global economy - more than India and China’s current GDP. The computer vision market was worth $20.31 billion in 2023, with a projected CAGR of 27.3% between 2023 and 2032. The estimated size of the natural language processing (NLP) market is projected to reach $31.76 billion by the end of 2024, with a CAGR of 23.97% between 2024 and 2029. The large language model (LLM) market is currently valued at $6.4 billion and is expected to reach $36.1 billion by 2030, growing at a CAGR of 33.2% between 2023 and 2030. AI & ML Adoption Over 50% of companies in the U.S. with more than 5,000 employees use AI. Chinese and Indian companies report the highest use of AI compared to other developed countries, with 60% of IT professionals saying they already use AI applications. Over 20% of American content creators used AI to generate videos and images in 2023. Due to labor shortages, around 25% of companies are adopting AI to enhance business operations globally. According to the latest online survey by Gartner that covered CIOs from multiple geographies and industries, 34% say they already adopted AI, while 22% say they will do so by the end of 2024. AI and Gen AI Adoption Around three in four CIOs across multiple industries globally intend to boost investment in IT services and AI-powered and AI-augmented applications. Insurance companies have the highest AI adoption rate of 49%, followed by U.S. healthcare companies, which have an adoption rate of 48%. U.S. healthcare companies also have the most aggressive spending budget for AI. 48% of businesses use deep learning, NLP, and ML models to manage large datasets. Organizations surveyed worked in software, consulting, finance, healthcare, government, higher education, telecommunications verticals among others. AI & ML Benefits According to a global survey by McKinsey, generative AI increased revenue by 5% in 2023 in supply chain and inventory management. 38% of businesses achieved cost reduction through machine learning technologies. According to research by Gartner, quick product development, enhanced customer experience, and greater workforce productivity are the most significant benefits of Gen AI. Netflix’s AI-based recommendation algorithm saves the company $1 billion annually. Companies that lead in AI functionalities produce total shareholder returns (TSR) four to six times higher than organizations that lag in AI investments. This trend is consistent across various industries, such as insurance, banking, and retail. TSR Returns - Leaders versus Laggards Amazon’s revenue from AWS increased by 17% to $25 billion in 2024. The company chief executive believes the performance is a result of continued focus on AI. AI & ML Sentiments 44% of business owners feel AI helps them with better decision-making. 64% of business owners believe AI will improve customer relationships. Globally, only 54% of consumers think that AI-based products have more benefits than drawbacks. Only 49% of consumers surveyed across 31 countries say AI changed their lives in the past 3 to 5 years. 57% of workers believe AI will change how they do their jobs and 36% feel AI will replace them. AI & ML Impact on the Workforce AI automation is projected toreplace around 400 million workers by 2030, resulting in a 15% job loss globally. On the other hand, AI will create around 97 million new jobs. These jobs include developers and engineers who work on LLMs, UX designers, and content creators. Demand for LLM developers will increase as more technologies become dependent on tools such as ChatGPT. Demand for UX designers will increase to create intuitive interfaces to help users interact with AI. Demand for content creators will increase due to the need for relevant prompt engineering to generate the desired content. AI models will increase labor productivity by 40% across sixteen industries by 2035. A recent survey shows that 39% of chief data officers implemented AI literacy programs to fill these crucial roles. Must-have AI roles include prompt, data, and machine learning engineers, data scientists, AI ethicists, heads of AI, and data and analytics translators. Must-have AI Roles According to Gartner, Gen AI will augment the human workforce in 90% of companies globally by 2025. Significant workforce reskilling is necessary to increase AI adoption. A recent report by Statista suggests that around20% or more enterprise employees will need reskilling. AI & ML Tools End-user spending on Robotics Process Automation (RPA) tools reached $3.35 million in 2023, up 17.5% from the previous year. Gartner Magic Quadrant According to the 2024 Gartner Magic Quadrant, Microsoft, Google, and Oracle are the leaders in analytics and business intelligence (BI) platforms. 48% of businesses in software and professional services use ML, data analysis, and other AI tools to ensure accurate and error-free data. Listings of AI software providers on Gartner Digital Markets doubled in 2023, with AI product reviews increasing by 2.5 times. 92% of organizations plan to invest in AI tools such as chatbots in 2024, believing such solutions offer significant productivity and time-saving benefits. Read more about the best image annotation tools Top AI Trends Now, let's dive into the key trends that will shape the future of AI in the coming years. Cloud Systems Due to the scalability and flexibility of cloud-based AI ecosystems, many organizations are moving from stand-alone software applications to cloud-native solutions. According to Gartner, 50% of new system deployments will occur in the cloud instead of separate point solutions requiring manual integration. The shift toward hybrid and cloud-based solutions will make AI more accessible to startups and small-to-medium enterprises (SMEs) that lack sufficient funds to build in-house platforms. Organizations will benefit from the cloud’s low latency and high throughput, as cloud-based platforms have integrated GPUs to optimize AI models. Edge AI The need to process data at the point of generation is increasing as organizations prioritize real-time insights and compliance with data privacy regulations. Gartner predicts that over 55% of deep neural networks will analyze data at the source by 2025. Businesses can identify deeper patterns by processing data at the source and deploying AI algorithms on local devices. These include sensors, cameras, and other Internet-of-things (IoT) devices. In addition, edge AI allows businesses to streamline AI deployment through seamless integration and orchestration of AI workflows, helping them create more advanced AI models. Generative AI Gen AI is reshaping how personal and business users interact with AI to perform multiple tasks. According to the latest McKinsey survey, 65% of organizations use Gen AI, and 75% of respondents expect the technology to result in disruptive change. Respondent’s Use of Gen AI by Function The survey reports that sales and marketing, service development, and IT functions are the most prominent areas where organizations deploy Gen AI technologies. Further, Gartner reports that 38% of executives invest in Gen AI to improve customer experience and retention, increase revenue, and reduce costs. As Gen AI models become open-source, their adoption will likely soar in the near future, encouraging more businesses to implement Gen AI frameworks to solve complex issues and boost operational efficiency. Responsible AI As AI spreads across multiple aspects of human life, the concern for ethical AI deployments is rising. The trend involves addressing user sentiments regarding transparency, accountability, risk, trust, and societal value associated with AI initiatives. With only 1% of AI vendors owing large pre-trained models, the need for responsible AI is rapidly increasing. As such, organizations should adopt best practices for managing risk and preventing bias when building frameworks using these pre-trained models. Data-centric AI Data-centric AI is focuses on building frameworks that ensure data is clean, accurate, and consistent rather than just improving algorithms. This approach helps create platforms that enable users to quickly pre-process, curate, and label datasets with AI-based models, automating the entire workflow. For instance, the Encord platform is an end-to-end solution that offers AI tools to curate and annotate image, video, and medical data. It provides micro-models that users can train on a few data samples and automatically label remaining data points for better results. Data-centric AI also involves generating synthetic data using Gen AI tools to make up for the lack of real-world data needed for training complex CV and NLP models. According to reports, about 60% of data will be synthetic by the end of 2024. Accelerated AI Investments AI investments are increasing with the rise of foundation models. Gartner forecasts that around $10 billion will be spent on AI startups relying on such models. Also, around 70% of organizations are exploring Gen AI solutions, while 19% are already in the pilot phase. The increased investment will likely result in more AI innovations in real-world applications and stronger collaboration between research institutes, corporations, and the government. Popular Use Cases With the increasing prevalence of mobile technology, the use of AI-based voice assistants and chatbots is increasing. Reports predict there will be around 8 billion voice assistants by the end of 2024. Moreover, the telecommunications industry is one of the most significant users of chatbots, with 52% of telecom businesses using the technology to improve productivity. Popular Consumer Use Cases For consumers, the most popular AI use cases include: Responding to messages and emails, Answering financial questions, Planning travel itineraries, Crafting emails, Preparing for job interviews, Writing social media posts, Summarizing long copies Learn more about computer vision use cases in our detailed blog. Top Picks Machine learning’s projected market size will reach $79.29 billion by the end of 2024. Global AI software spending will reach $297.9 billion by 2027. The ML Operations (MLOps) market is predicted to have a compound annual growth rate (CAGR) of 43.2 between 2024 and 2033. According to Bloomberg, generative AI (Gen AI) will be worth $1.3 trillion by 2032. Financial Times reports that OpenAI’s revenue surpassed $2 billion as demand for ChatGPT explodes. Around 92% of Fortune 500 companies are using Open AI products. 80% of business leaders think that Gen AI will increase efficiency. AI & ML Trends: Key Takeaways The above statistics and trends clearly show that organizations wishing to stay ahead of the competition must invest in AI and ML technologies to boost revenue, improve customer experience, and reduce costs. Below are a few critical points to remember regarding AI. Generative AI has the Highest Adoption: Organizations are rushing to implement generative AI technologies in multiple business functions to improve operational efficiency. Customer Experience is Key: The motive behind significant investments in AI is to improve customer experience and relationships. Workforce Reskilling: Significant workforce reskilling is necessary to counter AI’s job displacement effects. Key Trends: The most prominent trends in 2024 are the shift to cloud systems, edge AI, and a focus on building data-centric frameworks. References BIS Research Bloomberg Deloitte Exploding Topics Financial Times Forbes Advisor Fortune Business Insights Gartner Ipsos Market.us Scoop Mckinsey Statista The Guardian\n\nAug 16 2024\n\n5 M\n\nTop 10 Multimodal Datasets\n\nMultimodal datasets are like the digital equivalent of our senses. Just as we use sight, sound, and touch to interpret the world, these datasets combine various data formats—text, images, audio, and video—to offer a richer understanding of content. Think of it this way: if you tried to understand a movie just by reading the script, you'd miss out on the visual and auditory elements that make the story come alive. Multimodal datasets provide those missing pieces, allowing AI to catch subtleties and context that would be lost if it were limited to a single type of data. Another example is analyzing medical images alongside patient records. This approach can reveal patterns that might be missed if each type of data were examined separately, leading to breakthroughs in diagnosing diseases. It's like assembling multiple puzzle pieces to create a clearer, more comprehensive picture. In this blog, we've gathered the best multimodal datasets with links to these data sources. These datasets are crucial for Multimodal Deep Learning, which requires integrating multiple data sources to enhance performance in tasks such as image captioning, sentiment analysis, medical diagnostics, video analysis, speech recognition, emotion recognition, autonomous vehicles, and cross-modal retrieval. What is Multimodal Deep Learning? Multimodal deep learning, a subfield of Machine Learning, involves using deep learning techniques to analyze and integrate data from multiple data sources and modalities such as text, images, audio, and video simultaneously. This approach uses the complementary information from different types of data to improve model performance, enabling tasks like enhanced image captioning, audio-visual speech recognition, and cross-modal retrieval. Next-GPT: A Multimodal LLM Benefits of Multimodal Datasets in Computer Vision Multimodal datasets significantly enhance computer vision applications by providing richer and more contextual information. Here's how: By combining visual data with other modalities and data sources like text, audio, or depth information, models can achieve higher accuracy in tasks such as object detection, image classification, and image segmentation. Multimodal models are less susceptible to noise or variations in a single modality. For instance, combining visual and textual data can help in overcoming challenges like occlusions or ambiguous image content. Multimodal datasets allow models to learn deeper semantic relationships between objects and their context. This enables more sophisticated tasks like visual question answering (VQA) and image generation. Multimodal dataset opens up possibilities for novel applications in computer vision, large language models, augmented reality, robotics, text-to-image generation, VQA, NLP and medical image analysis. By integrating information from data sources of different modalities, models can better understand the context of visual data, leading to more intelligent and human-like large language models. Top 10 Multimodal Datasets Flickr30K Entities Dataset The Flickr30K Entities dataset is an extension of the popular Flickr30K dataset, specifically designed to improve research in automatic image description and understand how language refers to objects in images. It provides more detailed annotations for image-text understanding tasks. Flickr30K Entities dataset built upon the Flickr30k dataset, which contains 31K+ images collected from Flickr. Each image in Flickr30k Entities is associated with five crowd-sourced captions describing the image content. The dataset adds bounding box annotations for all entities (people, objects, etc.) mentioned in the image captions. Flickr30K allows to develop better large language models with vision capabilities for image captioning, where the model can not only describe the image content but also pinpoint the location of the entities being described. It also allows the development of an improved grounded language understanding, which refers to a machine's ability to understand language in relation to the physical world. Research Paper: Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models Authors: Bryan A. Plummer, Liwei Wang, Chris M. Cervantes, Juan C. Caicedo, Julia Hockenmaier, and Svetlana Lazebnik Dataset Size: 31,783 real-world images, 158,915 captions (5 per image), approximately 275,000 bounding boxes, 44,518 unique entity instances. Licence: The dataset typically follows the original Flickr30k dataset licence, which allows for research and academic use on non-commercial projects. However, you should verify the current licensing terms as they may have changed. Access Links: Bryan A. Plummer Website Visual Genome The Visual Genome dataset is a multimodal dataset, bridging the gap between image content and textual descriptions. It offers a rich resource for researchers working in areas like image understanding, VQA, and multimodal learning. Visual Genome combines two modalities, first is Visual, containing over 108,000 images from the MSCOCO dataset are used as the visual component, and second is Textual, where images are extensively annotated with textual information (i.e. objects, relationships, region captions, question-answer pairs). The multimodal nature of this dataset offers advantages like deeper image understanding to allow identify meaning and relationships between objects in a scene beyond simple object detection, VQA to understand the context and answer questions that require reasoning about the visual content, and multimodal learning that can learn from both visual and textual data. Research Paper: Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations Authors: Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A. Shamma, Michael S. Bernstein, Fei-Fei Li Dataset Size: 108,077 real-world image, 5.4 Million Region Descriptions, 1.7 Million VQA, 3.8 Million Object Instances, 2.8 Million Attributes, 2.3 Million Relationships Licence: Visual Genome by Ranjay Krishna is licensed under a Creative Commons Attribution 4.0 International License. Access Links: Visual Gnome Dataset at Hugging Face MuSe-CaR MuSe-CaR (Multimodal Sentiment Analysis in Car Reviews) is a multimodal dataset specifically designed for studying sentiment analysis in the \"in-the-wild\" context of user-generated video reviews. MuSe-CaR combines three modalities (i.e. text, audio, video) to understand sentiment in car reviews. The text reviews are presented as spoken language, captured in the video recordings, audio consists of vocal qualities (like tone, pitch, and emphasis) to reveal emotional aspects of the review beyond just the spoken words, and video consists of facial expressions, gestures, and overall body language provide additional cues to the reviewer's sentiment. MuSe-CaR aims to advance research in multimodal sentiment analysis by providing a rich dataset for training and evaluating models capable of understanding complex human emotions and opinions expressed through various modalities. Research Paper: The Multimodal Sentiment Analysis in Car Reviews (MuSe-CaR) Dataset: Collection, Insights and Improvements Authors: Lukas Stappen, Alice Baird, Lea Schumann, Björn Schuller Dataset Size: 40 hours of user-generated video material with more than 350 reviews and 70 host speakers (as well as 20 overdubbed narrators) from YouTube. Licence: End User Licence Agreement (EULA) Access Links: Muse Challenge Website CLEVR CLEVR, which stands for Compositional Language and Elementary Visual Reasoning, is a multimodal dataset designed to evaluate a machine learning model's ability to reason about the physical world using both visual information and natural language. It is a synthetic multimodal dataset created to test AI systems' ability to perform complex reasoning about visual scenes. CLEVR combines two modalities, visual and textual. Visual modality comprises rendered 3D scenes containing various objects. Each scene features a simple background and a set of objects with distinct properties like shape (cube, sphere, cylinder), size (large, small), color (gray, red, blue, etc.), and material (rubber, metal). Textual modality consists of questions posed in natural language about the scene. These questions challenge models to not only \"see\" the objects but also understand their relationships and properties to answer accurately. CLEVR is used in applications like visual reasoning in robotics and other domains to understand the spatial relationships between objects in real-time (e.g., \"Which object is in front of the blue rubber cube?\"), counting and comparison to enumerate objects with specific properties (e.g., \"How many small spheres are there?\"), and logical reasoning to understand the scene and the question to arrive at the correct answer, even if the answer isn't directly visible (e.g., \"The rubber object is entirely behind a cube. What color is it?\"). Research Paper: CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning Authors: Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Fei-Fei Li, Larry Zitnick, Ross Girshick Dataset Size: 100,000 images, 864986 questions, 849,980 answers, 85,000 scene graph annotations and functional program representations. Licence: Creative Commons CC BY 4.0 licence. Access Links: Stanford University CLEVR Page InternVid InternVid is a relatively new multimodal dataset specifically designed for tasks related to video understanding and generation using generative models. InternVid focuses on the video-text modality, combining a large collection of videos containing everyday scenes and activities accompanied by detailed captions describing the content, actions, and objects present in the video. InternVid aims to support various video-related tasks such as video captioning, video understanding, video retrieval and video generation. Research Paper: InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation Authors: Yi Wang, Yinan He, Yizhuo Li, Kunchang Li, Jiashuo Yu, Xin Ma, Xinhao Li, Guo Chen, Xinyuan Chen, Yaohui Wang, Conghui He, Ping Luo, Ziwei Liu, Yali Wang, LiMin Wang, Yu Qiao Dataset Size: The InternVid dataset contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words. Licence: The InternVid dataset is licensed under the Apache License 2.0 Access Links: InternVid Dataset at Huggingface MovieQA MovieQA is a multimodal dataset designed specifically for the task of video question answering (VideoQA) using text and video information. MovieQA combines three modalities i.e. video, text and question and answer pairs. The dataset consists of video clips from various movie clips that are accompanied by subtitles or transcripts, providing textual descriptions of the spoken dialogue and on-screen actions. Each video clip is paired with multiple questions that require understanding both the visual content of the video and the textual information from the subtitles/transcript to answer accurately. MovieQA aims to evaluate how well a model can understand the actions, interactions, and events happening within the video clip. It can utilize textual information such as subtitles/transcript to complement the visual understanding and answer questions that might require information from both modalities and provide informative answers. Research Paper: MovieQA: Understanding Stories in Movies through Question-Answering Authors: Makarand Tapaswi, Yukun Zhu, Rainer Stiefelhagen, Antonio Torralba, Raquel Urtasun, Sanja Fidler Dataset Size: This dataset consists of 15,000 questions about 400 movies with high semantic diversity. Licence: Unknown Access Links: Dataset at Metatext MSR-VTT MSR-VTT, which stands for Microsoft Research Video to Text, is a large-scale multimodal dataset designed for training and evaluating models on the task of automatic video captioning. The primary focus of MSR-VTT is to train models that can automatically generate captions for unseen videos based on their visual content. MSR-VTT combines two modalities, videos and text descriptions. Video is a collection of web videos covering a diverse range of categories and activities and each video is paired with multiple natural language captions describing the content, actions, and objects present in the video. MSR-VTT helps in large-scale learning using vast amounts of data which allows models to learn robust video representations and generate more accurate and descriptive captions. Videos from various categories help models generalize well to unseen video content and multiple captions per video provides a richer understanding of the content. Research Paper: MSR-VTT: A Large Video Description Dataset for Bridging Video and Language Authors: Jun Xu , Tao Mei , Ting Yao, Yong Rui Dataset Size: Large video captioning dataset with 10,000 clips (38.7 hours) and 200,000 descriptions. It covers diverse categories and has the most sentences/vocabulary compared to other similar datasets. Each clip has around 20 captions written by human annotators. Licence: Unknown Access Links: Dataset at Kaggle VoxCeleb2 VoxCeleb2 is a large-scale multimodal dataset designed for tasks related to speaker recognition and other audio-visual analysis. VoxCeleb2 combines two modalities, audio and video. Audio consists of recordings of speech from various individuals and corresponding video clips of the speakers, allowing for the extraction of visual features. VoxCeleb2 primarily focuses on speaker recognition, which involves identifying or verifying a speaker based on their voice. However, the audio-visual nature of the dataset also allows for face recognition and speaker verification. Research Paper: VoxCeleb2: Deep Speaker Recognition Authors: Joon Son Chung, Arsha Nagrani, Andrew Zisserman Dataset Size: VoxCeleb2 is a large-scale dataset containing over 1 million utterances for 6,112 celebrities, extracted from videos uploaded to YouTube. Licence: VoxCeleb2 metadata is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. Access Links: The VoxCeleb2 Dataset VaTeX VaTeX (VAriational Text and video) is a multimodal dataset designed specifically for research on video-and-language tasks. Modalities: VaTeX combines two modalities, A collection of videos depicting various activities and scenes, and text descriptions for each video describing the content in both English and Chinese. Some caption pairs are parallel translations, allowing for video-guided machine translation research. VaTeX supports several research areas related to video and language such as multilingual video captioning to generate captions for videos in multiple languages, video-guided machine translation to improve the accuracy of machine translation, and video understanding to analyze and understand the meaning of video content beyond simple object recognition. Research Paper: VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research Authors: Xin Wang, Jiawei Wu, Junkun Chen, Lei Li, Yuan-Fang Wang, William Yang Wang Dataset Size: The dataset contains over 41,250 videos and 825,000 captions in both English and Chinese. Licence: The dataset is under a Creative Commons Attribution 4.0 International License. Access Links: VATEX Dataset WIT WIT, which stands for Wikipedia-based Image Text, is an state-of-the-art large-scale dataset designed for tasks related to image-text retrieval and other multimedia learning applications. Modalities: WIT combines two modalities, Images which are a massive collection of unique images from Wikipedia and text descriptions for each image extracted from the corresponding Wikipedia article. These descriptions provide information about the content depicted in the image. WIT primarily focuses on tasks involving the relationship between images and their textual descriptions. Some key applications are Image-Text Retrieval to retrieve images using text query, Image Captioning to generate captions for unseen images, and Multilingual Learning that can understand and connect images to text descriptions in various languages. Research Paper: WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning Authors: Krishna Srinivasan, Karthik Raman, Jiecao Chen, Michael Bendersky, Marc Najork Dataset Size: WIT contains a curated set of 37.6 million entity rich image-text examples with 11.5 million unique images across 108 Wikipedia languages. I Licence: This data is available under the Creative Commons Attribution-ShareAlike 3.0 Unported licence. Access Links: Google research dataset github Key Takeaways: Multimodal Datasets Multimodal datasets, which blend information from diverse data sources such as text, images, audio, and video, provide a more comprehensive representation of the world. This fusion allows AI models to decipher complex patterns and relationships, enhancing performance in tasks like image captioning, video understanding, and sentiment analysis. By encompassing diverse data aspects, multimodal datasets push the boundaries of artificial intelligence, fostering more human-like understanding and interaction with the world. These datasets, sourced from various data sources, drive significant advancements across various fields, from superior image and video analysis to more effective human-computer interaction. As technology continues to advance, multimodal datasets will undoubtedly play a crucial role in shaping the future of AI. Embracing this evolution, we can look forward to smarter, more intuitive AI systems that better understand and interact with our multifaceted world.\n\nAug 15 2024\n\n5 M\n\nONNX Standardized Format: The Universal Translator for AI Models\n\nModern artificial intelligence (AI) is moving beyond the traditional machine learning (ML) models involving straightforward statistical calculations. With the emergence of advanced computational resources and big data, AI frameworks are now more sophisticated, performing complex inferences on extensive datasets. However, as model complexity increases, so does the need for interoperability as developers begin using multiple frameworks to build, test, and deploy AI systems. Also, using AI-based solutions with legacy infrastructure calls for solutions that allow businesses to seamlessly integrate AI tools with existing tech stack. This lack of interoperability often results in time-consuming and error-prone conversion processes, creating significant obstacles to the smooth deployment of AI solutions. Enter the Open Neural Network Exchange (ONNX) framework. ONNX addresses this interoperability challenge by offering a standardized, open-source format for representing AI models. With ONNX, developers can build, share, and run models across various platforms without worrying about compatibility issues, thereby streamlining the entire model development and deployment lifecycle. In this article, we will discuss in detail what ONNX is and its key features, benefits, challenges, and best practices. It will help you understand how to use ONNX optimally to streamline your model development lifecycle. What is ONNX? ONNX is a unified open-source format designed to enable interoperability between different AI and ML algorithms. A standard format allows users to execute models between multiple frameworks without implementing complex conversion pipelines. Originally developed by Facebook and Microsoft in 2017, ONNX has gained support from numerous tech giants, including IBM, Intel, and Qualcomm. Traditionally, developers used the HD5 format to save a model in Keras, the SavedModel format to store the model in TensorFlow, and Pickle for Scikit-Learn. These formats are framework-specific, and their support in other development environments is limited. ONNX lets you overcome these limitations through the following key features: Open-source: ONNX is an open-source project on GitHub, with a large and active community that contributed to the development and enhancement of the framework’s ecosystem. Standardized Format: Standardization allows developers to use an ONNX-based model with any framework to provide smooth cross-platform integrations. Conversion Tools: ONNX includes extensive tools and APIs that enhance the ML lifecycle. For instance, it supports multiple libraries that enable the conversions of models built in popular frameworks such as TensorFlow, Keras, and PyTorch to ONNX. Visualization and Optimization Libraries: ONNX offers tools to visualize models and provides optimization solutions to remove redundant nodes and improve performance. Users can also deploy ONNX models using runtime libraries that support multiple hardware such as CPUs, GPUs, and accelerators. Interoperability: ONNX enables seamless import and export models across multiple ML frameworks. The ability enables developers to leverage the strengths of a particular framework during model development, convert the model into ONNX, and export it to a suitable lightweight and low-latency runtime environment. Focus on Inference: ONNX Runtime is a tool for efficiently deploying machine learning models in production with faster inferencing and broad compatibility with different hardware platforms. Format Flexibility: The ONNX standard supports traditional and state-of-the-art (SOTA) deep learning models such as complex computer vision (CV) and natural language processing (NLP) architectures. Performance Optimizations: ONNX Runtime supports multiple performance-enhancing graph optimizations through node elimination and fusion techniques, which help improve model execution efficiency. Popular Frameworks Compatible with ONNX ONNX supports multiple frameworks that let developers build a wide range of deep learning and traditional machine learning models more flexibly and efficiently. The following list highlights a few of the popular frameworks that are compatible with ONNX. PyTorch: Meta's PyTorch is a Python-based library that offers robust GPU-accelerated tensor computation to build complex CV and NLP models. PyTorch is particularly favored for its dynamic computational graph (also known as reverse-mode auto-differentiation), which allows developers to modify the graph on the fly. TensorFlow: Google’s TensorFlow is an end-to-end ML framework that offers intuitive APIs to build AI applications. It offers tools for developing and deploying models across various environments, including edge devices, the web, and mobile platforms. TensorFlow also includes utilities for creating input pipelines for data preprocessing. Scikit-Learn: Scikit-Learn is a Python-based platform for building traditional ML models for classification, regression, and clustering. It also offers tools for dimensionality reduction, model selection, and data preprocessing, making it a comprehensive framework for standard ML tasks. Keras: Keras is a high-level API for developing ML-powered apps with straightforward code that is quick to debug, deploy, and maintain. Microsoft Cognitive Toolkit (CNTK): CNTK is an open-source deep-learning library representing neural networks through directed computational graphs. The feature makes CNTK suitable for building architectures involving feed-forward, convolutional, and recurrent neural nets. Converting Models to ONNX ONNX offers libraries to convert models in different frameworks to ONNX format. The format consists of an ONNX graph that describes the ML model through mathematical operations. The operations transform input features to generate relevant predictions. For instance, a developer may create a linear regression model in Python and convert it to an ONNX graph. The model is a function of three variables, an addition, and a multiplication operation. Linear Regression Model Converting it to ONNX means using ONNX operators to represent the model in a standard graph that the developer can run and execute on any platform. The conversion involves writing the linear regression model in the ONNX language to declare the variables, define nodes, create the graph, and add relevant metadata. ONNX Graph for Linear Regression Model Although developers can manually write models in the ONNX language, a more convenient alternative is using pre-built ONNX conversion libraries. These libraries automatically convert Python-based models in supported frameworks to ONNX format. The following is a brief list of conversion libraries: sklearn-onnx: Helps convert scikit-learn models tf2onnx: Enables developers to transform TensorFlow, Keras, TensorFlow.js, and Tflite models to ONNX. onnx-coreml: Facilitates the conversion of ONNX models to CoreML format. torch.onnx: Supports converting Pytorch-based models to ONNX. YOLOv8 to ONNX Example YOLOv8 is an open-source PyTorch-based CV model by Ultralytics. It helps you with object detection and tracking, image classification, pose estimation, and instance segmentation tasks. CV Tasks in YOLOv8 Converting the model to ONNX format is straightforward. The following code snippet from Ultralytics demonstrates you can quickly export and run YOLO-v8 in ONNX. from ultralytics import YOLO # Load the YOLOv8 model model = YOLO(\"yolov8n.pt\") # Export the model to ONNX formatmodel.export(format=\"onnx\") # creates 'yolov8n.onnx' # Load the exported ONNX model onnx_model = YOLO(\"yolov8n.onnx\") # Run inference results = onnx_model(\"https://ultralytics.com/images/bus.jpg\") Curious how YOLO works? Learn more about the algorithm in our detailed guide on YOLO Object Detection Pre-Trained Models in ONNX While you can convert models to ONNX, the ONNX Model Zoo is a GitHub repository that offers multiple pretrained CV, NLP, Generative AI, and Graph ML models in ONNX format. The source of the models includes open-source repositories such as transformers, torchvision, timm, and torch_hub. Vision models include frameworks for image classification, object detection, image segmentation, pose estimation, and image manipulation tasks. Language models include machine translation and comprehension algorithms. Lastly, it offers models for speech recognition and visual question answering (VQA) tasks. Optimizing ONNX Models Developers can optimize ONNX models for better performance using ONNX Optimizer - an open-source library based on C++. The framework helps developers perform arbitrary optimizations that require custom backend information. In addition, ONNX Runtime is the official ONNX production engine, which lets you tailor ONNX-based deployments to specific hardware across multiple platforms. The framework applies relevant optimizations to run models efficiently on CPUs, GPUs, and accelerators. Developers can use ONNX Runtime to deploy models on web, mobile, edge, and cloud-based environments. The library also allows them to boost training speed and accuracy for large language models (LLMs) and perform on-device model learning to protect user privacy. Applications of ONNX Models in Computer Vision ONNX models are versatile and flexible frameworks that help you build and deploy models for multiple use cases. Below is a list of ONNX-based CV applications in various domains. ONNX for Image Classification: ONNX models can perform complex image classification tasks, such as classifying medical images to diagnose diseases. Medical Image Classification ONNX for Object Detection: CV applications often require object detection models with high inference speeds. For instance, models for self-driving cars must recognize objects in real-time without delay. Developers can achieve such performance by deploy"
    }
}