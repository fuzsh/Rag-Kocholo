{
    "id": "dbpedia_442_1",
    "rank": 64,
    "data": {
        "url": "https://www.mediastudies.press/pub/wwai-main",
        "read_more_link": "",
        "language": "en",
        "title": "What Was Artificial Intelligence?",
        "top_image": "https://assets.pubpub.org/uozkw8iq/61648391241756.png",
        "meta_img": "https://assets.pubpub.org/uozkw8iq/61648391241756.png",
        "images": [
            "https://resize-v3.pubpub.org/eyJidWNrZXQiOiJhc3NldHMucHVicHViLm9yZyIsImtleSI6Ijdyb2dlcmYzLzAxNTg3NjczMDYzMDU5LnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJoZWlnaHQiOjUwLCJmaXQiOiJpbnNpZGUiLCJ3aXRob3V0RW5sYXJnZW1lbnQiOnRydWV9fX0=",
            "https://resize-v3.pubpub.org/eyJidWNrZXQiOiJhc3NldHMucHVicHViLm9yZyIsImtleSI6Im51MGlwNWxxLzcxNjQ4NDI0NjY4OTQ1LnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6ODAwLCJmaXQiOiJpbnNpZGUiLCJ3aXRob3V0RW5sYXJnZW1lbnQiOnRydWV9fX0= 1x,https://resize-v3.pubpub.org/eyJidWNrZXQiOiJhc3NldHMucHVicHViLm9yZyIsImtleSI6Im51MGlwNWxxLzcxNjQ4NDI0NjY4OTQ1LnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MTYwMCwiZml0IjoiaW5zaWRlIiwid2l0aG91dEVubGFyZ2VtZW50Ijp0cnVlfX19 2x,https://resize-v3.pubpub.org/eyJidWNrZXQiOiJhc3NldHMucHVicHViLm9yZyIsImtleSI6Im51MGlwNWxxLzcxNjQ4NDI0NjY4OTQ1LnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MjQwMCwiZml0IjoiaW5zaWRlIiwid2l0aG91dEVubGFyZ2VtZW50Ijp0cnVlfX19 3x",
            "https://www.mediastudies.press/static/license/cc-by-nc.svg",
            "https://assets.pubpub.org/7rogerf3/01587673063059.png",
            "https://www.mediastudies.press/static/logoBlack.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Sue Curry Jansen"
        ],
        "publish_date": "2022-03-01T00:00:00",
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "https://assets.pubpub.org/6firippy/11608603362406.png",
        "meta_site_name": "mediastudies.press",
        "canonical_link": "https://www.mediastudies.press/pub/wwai-main",
        "text": "We are all astronauts in this technological age, but the astronautic body of technological functioning there on the launch pad prepared and ready to depart the earth is a masculine figure. And the shadow of the abandoned body, the body left behind, exiled, imprisoned, and enchained, is the figÂ­ure of the woman.\n\nâRobert D. Romanyshyn, Technology as Symptom and Dream, 1989\n\nPrometheus Rebound: Evolving Models of Mind\n\nThe strong research program for developing artificial intelligence was a Cold War ideological formation. Describing the artificial intelligence movement in the past tense is an ironic reversal since it always described itself in the future tense. It never fully existed in the present. It was always becoming: its sucÂ­cess forever contingent on a next step, a discovery that was just across the frontier of knowledge.\n\nThe artificial intelligence movement (AIM) emerged as an identifiable, if not yet organized, approach in the early 1950s. The computer, a technology with a long prehistory, became a reality at the end of World War II. With the subsequent invention of the transistor in 1949, the stage was set for the computer to become the defining technology of the late twentieth century.\n\nGerminal ideas for artificial intelligence (Al) can be traced to separate but related attempts by Pascal and Leibniz to build machines that could calculate and thereby simulate functions of the human mind. The modern conception of artificial intelligence entered into the discourse of computer science with the 1950 publication of Alan Turingâs manifesto, âComputing Machinery and Intelligence,â which outlined a plan for creating computers that could think: a feat that Turing predicted would be achieved by the year 2000. A two-month-long conference of leading computer scientists in 1956, the Dartmouth Summer Research Project on Artificial Intelligence, marked the formal emergence of artificial intelligence research as a âmovement.â\n\nImmediate inspiration for the project was drawn from the work of four generative thinkers of early computing. In addition to Turing, whose 1936 paper âOn Computable Numbersâ described the theory of, specifications for, and limitations of âlogic machines,â they included John von Neumann, who headed the research team that designed and developed the modern, memoryÂ­-based computer central processing unit (CPU), the computer architecture that is still used today; Norbert Wiener, who envisioned a new science of âcyberÂ­neticsâ; and Claude Shannon, who developed information theory and inspired early interest in the social scientific study of communication. The researchers who actually formed and led the movement to develop AI included, among others, Alan Newell and Herbert Simon, both jointly affiliated with the RAND Corporation and Carnegie Institute of Technology (now Carnegie Mellon University); Marvin Minsky and Seymour Papert of Massachusetts Institute of Technology; and John McCarthy of Dartmouth and later Stanford. Most contemporary AI scientists have studied with one or more of these pioneers.\n\nWhat brought these men together was a common commitment to move beyond the then-prevalent understanding of computers as mere tools, advanced adding machines which could only do what they were told to do. The domiÂ­nant view of the time was expressed in the familiar programmerâs motto: âgarbage in, garbage out.â The goal of the AIM was to create computers that could âthinkâ and learn. As Simon put it, the statement that âcomputers can do only what they are programmed to do is intuitively obvious, indubitably true, and supports none of the implications that are commonly drawn from it.â AIM sought to create programs that would simulate the complexity of the huÂ­man mind. These simulations would, however, amplify human reasoning powÂ­ers, and would ultimately be more powerful than any single human mind: âIt will be a program that analyzes, by some means, its own performance, diagnoses its failures, and makes changes that enhance its future effectiveness.â\n\nAIM is now a half century old. Some former enthusiasts speak of it in the past tense: as a self-correcting intellectual movement that has transcended itÂ­self by serving as a launchpad to other endeavors. Others conceive of the movement as ongoing, but view its history as made up of two distinctive periods. Various pairings of adjectives have been used to define the shift in emphasis. The first period, in which the âstrong,â âtop-down,â or âtraditionalâ approach envisioned by Simon and Newell held sway, extended from the inception of the field to the mid-1980s. The second period of âweak,â âbottoms-up,â âemergent,â or ânew waveâ approaches emerged in the mid-1980s. The bottoms-up approach does continue some of the research program launched by the older, top-down traditionâfor example, developing expert systems, roÂ­botics, and other commercial applications of AI. What marks the new wave as distinctive, however, is the reconfiguration of the metaphoric definitions of the field of inquiry. Logico-mathematical models give way to or merge with biological metaphors, as the research goal is reconceived as the creation of arÂ­tificial life (âA-lifeâ) rather than artificial intelligence.\n\nThe top-down approach focuses on patterns and rules operating at the highÂ­ level, symbol-processing structures of the brain, while ignoring its lowerÂ­-level physical processes. The bottoms-up approach was a reaction against the failure of the top-down approach to produce significant results after more than thirty years of research. Whereas the top-down approach ignored biology, the bottoms-up approach took the position that the physical structure of the brain may account for its cognitive capacities. The bottoms-up approach seeks to design computing devices that mimic the structure of the brainâs neuÂ­ral networks: that is, devices modeled on child development which can obÂ­serve and learn. This approach is also known as âconnectionismâ and is enÂ­compassed under the broad umbrella of the ânew sciences of complexity.â Some chroniclers of the history of AI see the publication of Minskyâs The SoÂ­ciety of Mind (1987) as the benchmark; some date it to a conference on A-Life in 1987. Most regard it as a more gradual shift away from the original vision: an evolutionary shift rather than a revolutionary displacement of paradigms.\n\nWhile the top-down versus bottoms-up distinction is useful for explaining the internal history of AI, it is already in some ways an arcane and, in the current fast-paced environment of technological change, archaic distinction. The end of the Cold War triggered a restructuring of big science that was far more rapid, pervasive, and, by its own measures, much more successful than even the movers and shakers of this transformation anticipated in their most optiÂ­mistic projections. The new research and development model streamlined and mainstreamed the old defense model for research and development by creatÂ­ing new, comprehensive partnerships of government, university, and corpoÂ­rate research and development initiativesâa model the Japanese had pioÂ­neered, to the dismay of the US government, in the 1970s and 1980s. Computer science and technologies, genetics, and bioengineering have been the leading edges of this new technological initiative; and commercialization of these fields fueled the unparalleled growth of US stock markets during the 1990s. The infusion of corporate capital has produced rapid advances in comÂ­puter networking, robotics, and nanotechnologies that have transcended AI without leaving it behind. Some of the leading AI scientists and all of the sites that housed leading AI laboratories continue to be key players in the creation of the scientific and technological infrastructure of the information economy. It is not too much of a stretch to say that many of the technovisions that were incubated in AI laboratories have been mainstreamed into our brave new infoÂ­ world. Just a decade ago, the utopian and dystopic projections of Al maniÂ­festos seemed unbelievable, woolly-headed sci-fi fantasies. Now, we are building the global infrastructure that supports them.\n\nThe rise and fall of the âstrongâ artificial intelligence program roughly parallels the duration of the academic careers of the founding generation, although Minsky, who was a graduate student when he participated in the formÂ­ative Dartmouth summer project, serves as a bridging figure. Its rise and decline also appears to coincide with the influence of the unity of science movement, of which it was part. The funding and fate of top-down AI were closely tied to the duration of the Cold War, with the bottoms-up transitional period coinciding with the US governmentâs expansion of its defense funding priorities to include economic âcompetitiveness.â The competitiveness thrust created the preconditions for jump-starting the information economy by underwriting the so-called greening of artificial intelligence: the period when entrepreneurial AI scientists began aggressively promoting the comÂ­mercial applications of their work, sometimes to the dismay of more idealisÂ­tic Al founders like John McCarthy.\n\nPure Science and the Cold War\n\nLike virtually all university-based computer science research during the Cold War, AI research was funded by the Department of Defenseâs Advanced Research Projects Agency (ARPA). Therefore, it was a player in the arms race with the Soviet Union and later the âcompetitivenessâ race with Japan. Taken at face value, it was not a very effective player. In fact, it might have been viewed as an academic boondoggle: a metaphoric equivalent of a $7,000 Pentagon hammer. But taking AIM at face value grossly underestimates its accomplishments. Scientists associated with the movement made definitive conÂ­tributions to the development of robotics and expert systems, which have had significant military and commercial applications. Top-down AI was also a very successful learning experience that taught scientists a great deal about the complexity of the brain and thereby provided the impetus for the development of what would become a new branch of psychology: cognitive science.\n\nArtificial intelligence was part cover story as well as an important part of the real story of the early development of computer science. It leveraged the spectacular successes of the generation of Turing, von Neumann, Wiener, and Shannon, whose work had been supported by unlimited wartime resources, into an equally ambitious ongoing program for basic research in computer science. âBasicâ and âpureâ were crucial adjectives for naming and claiming significant degrees of intellectual autonomy for government-funded research during the Cold War. The terms referred to research that did not have immeÂ­diately apparent instrumental applications: for example, developing a comÂ­puterized chess game that was smart enough to defeat the worldâs top chess champions and thereby pass the Turing test for intelligence. This relative nonÂ­-instrumentality was, of course, very instrumental to the research programs and careers of computer scientists.\n\nâBasicâ still retains some of this patina in scientific grantsmanship. âPureâ was, however, a crucial descriptor in the ideological and institutional struggles of the early Cold War period. Scientists, who chased defense dollars, proÂ­fessed their purity to try to fend off charges of scientific prostitution in the days when the governmentâs growing presence in the funding of private uniÂ­versities was unsettling to many in the academy. The unsettled ranged from traditionalists, who wanted to preserve the relative insularity (cum purity) of the ivory tower, to liberals and leftists, critical of the Cold War policy and of threats to intellectual freedom posed by what President Eisenhower called âthe military-industrial complex.â\n\nWhen I use the term âpureâ here, I am not suggesting a pristine practice free of social and political influences and interests. To the contrary, I treat it as a strategic, ideological stance that artificial intelligence and other scientists used during the Cold War to justify their dual careers as defense researchers and academics. The ideology of pure science also sometimes served as a temporary safe harbor during a politically complex and compromising era: the dark period of US government interrogations and purges of academics, inÂ­tellectuals, writers, and other culture workers by the House Un-American AcÂ­tivities Committee and by Senator Joseph McCarthy.\n\nScientists doing defense work were, by definition, always under intense scrutiny as potential national security risks. Much of their work was classified and only accessible to those with government security clearances. In those days, the purer the science, the safer the scientist. I am not, however, suggesting that the scientists who embraced the sanctity of pure science were cynics, liars, propagandists, or scientific prostitutes, although some individual scientists may have been. Rather, I am saying that pure science was an ideal, an aspiration that had pragmatic as well as intellectual resonance. Like all potent ideological formations, it was a complex and fluid construct, part truth, part self-serving shield; it was a tool of power that could sometimes be used to hold the powerful accountable.\n\nThe technovisions that now support the growth of the domestic US econÂ­omy and its globalizing thrust are inspired to a significant degree by the achievements of the pure and impure sciences of AIM. Although some influential figures associated with AIM are now uncharacteristically modest about their achievements, and, it would seem, almost eager to acknowledge their âfailures,â the distance from the AI laboratories to the information economy is small. In fact, in some instances, it is just across the threshold: that much-vaunted next step. Both figuratively and literally, it is a step, sometimes direct, sometimes faltering, from publicly funded military research to publicly and privately supported applications of digital technologies, including the inÂ­ternet. âConvergence,â the hot techno buzzword of the 1990s, is being actualized in this century as a reengineering of society as well as technology.\n\nThe significance of this reengineering is profoundly transformative. An Wang, founder of Wang computers, maintained, âThe digitalization of information in all of its forms will probably be known as the most fascinating deÂ­velopment of the twentieth century.â Ivan Illich underscored the revolutionÂ­ary structural changes that digitization is bringing about. Conceiving of computers as agents of a new enclosure movement, he warns that computers âare doing to communications what fences did to pastures and cars did to streets.â In short, the digital revolution marks a deep structural shift in how we think, what we think about, how we communicate, how we relate to the material world and to one another, how we organize our work, and how we construct communities.\n\nContext and Limits of This Chapter\n\nThe purpose of this chapter is not to assess the successes or failures of AI science as science. That is beyond my expertise. My goal is much more modest: to explore the rhetoric and mythopoetics of the parascientific discourse of arÂ­tificial intelligence scientists. By parascientific discourse, I mean the proÂ­grammatic descriptions, manifestos, and interviews that artificial intelligence scientists have used to explain what they think they are doing when they do AI science.\n\nThis paradiscourse might be conceived as functioning in academic science in the way that mission statements function in the corporate world. Both articulate the values, means, goals, and hopes of their enterprises. Like corporate mission statements, parascientific statements are, in a special sense, also public relations efforts. That is, they are purposively constructed to cultivate and promote positive perceptions; in the case of the parascientific discourse of Al, the intended audience appears to be other scientists, potential governÂ­ment and private sponsors, science buffs, and the general public. During the heyday of top-down Al, the forefathers and the founders of AI functioned as the practical philosophers of computer science; their influence was not limÂ­ited to AI practitioners.\n\nThe rhetoric of the parascientific discourses of the artificial intelligence movement is remarkable on a number of counts. It does not use the flat, carefully measured language that experts on scientific writing recommend. To the contrary, it is frequently provocative and hyperbolic. Aphorisms, puns, and slogans are common, as are learned allusions to philosophy, litÂ­erature, art, and music. Intrinsically interesting numerical and visual puzÂ­zles and paradoxes are often used to illustrate points, and, I suspect, to enÂ­gage and entertain readers who cannot fully follow or who might be bored by the accompanying technical explanations. Self-deprecating modesty and humor are sometimes deployed, but they are usually accompanied by dissembling winks. Expressions of self-doubt are, however, hard to find. Normally, authorial voices that aggressively flaunt their superiority, even hubris, disturb and alienate readers; however, in the parascientific disÂ­course of AI, this mode of address functions as a seductive hook. It uses inclusive pronouns and generous displays of encompassing âof courseâ constructions to flatter readers. It models readers as peers, colleagues, knowing and supportive companions; if readers take the hook, this mode of address seems to say that they too will be admitted to Mount Olympus where they will also see like gods and be like gods (or astronauts). Some AI spokesmen have spent most of their careers modeling natural language; they are acutely aware of how languages work, and how irony, poetry, and Aesopean indirection resist, mislead, and charm AI modeling attempts. And some of these men are very adept at using these tropes to engage readÂ­ers. For example, Minskyâs discussion of metaphor is cutting-edge postÂ­-structuralism, but it has been cleanly shaven into clear, concise, and easily accessible prose. When these writers use synecdoche, they mean it: For Minsky, mind is a âsociety.â Top-downers are prone to what bottom-upper Douglas Hofstadter refers to as ââBuck Rogersâ fantasies.â Some of these fantasies are presented in whimsically engaging prose, prefaced by almost child-like âwhat ifs.â Most of the writing is artful. A few authors need to be taken seriously as writers as well as thinkers: Hofstadter won a Pulitzer Prize for his remarkable book GÃ¶del, Escher, Bach (1979). Clever, arroÂ­gant, self-serving, engaging, propagandistic, literate, playful, often facile, occasionally profound, sometimes outrageous, and usually interesting, the parascientific discourse of AIM inspires believers and incenses critics.\n\nWhile parascientific texts are clearly intended as a form of scientific outreach, frequently even proselytization, nonscientists are not encouraged to critically interrogate them. The late Isaac Asimov, who is regarded as the paÂ­tron saint of ârobotic ethicsâ by the AI community, celebrated this resistance to external criticism of science in âEvery Real Problem Can and Will Be Solvedâ:\n\nIâm a great one for iconoclasm. Given half a chance, I love to say something shattering about some revered institution, and wax sarcastically cynical about Motherâs Day or apple pie or baseball. Naturally, though, I draw the line at havÂ­ing people say nasty things about institutions I personally revere. Like Science and Scientist, for instance (Capital S, youâll notice).\n\nParascientific discourse is frequently treated with the same reverence as science. Where in traditional (preconstructivist) philosophies of science, the scientist is seen as a kind of miner who goes off and discovers precious ore, the parascientific writer, even the nonscientists among them, seem to see themselves as sharing the charisma of scientific discovery. They go off and mine the texts and the talk of scientists, translate what they find into reader-friendly language, and then offer to share that precious metal with readers. Sociological analysis and rhetorical criticism seems to be all but proscribed.\n\nTuring himself imputed theological and philosophical significance to AI modeling; as a result, philosophers, unlike sociologists, have been part of AI paradiscourse almost since its inception. They have extensively criticized the ontological, logical, and linguistic assumptions of the models of mind proposed by top-down AI scientists; see, for example, Dreyfus, Searle, Boden, Collins, and Pemose. Elsewhere, I explored some of the ways that the logical structures of top-down AI models incorporate gendered asÂ­sumptions. See, for example, the comparisons and conflations of Maruyamaâs concept of âclassificatory informationâ and Gilliganâs typificaÂ­tion of masculine modes of decision-making, or âmorality of rules.â\n\nMy purpose here is not to reiterate the philosophical critiques, but rather to use some of their scaffolding as support for investigating some of the underÂ­examined social constituents of the AI project. These constituents include the gendering of the language and assumptions of AI paradiscourse, and, to a lesser extent, the historically specific Cold War social formations of that gendered languageâfor example, doomsday thinking.\n\nAIM is an especially rich and unusually accessible site for excavating the poetry in the paradigms of scientific thought. The nature of the AI project itself, simulating or modeling minds, forced artificial intelligence scientists to consciously reflect upon the godlike roles they were playing in daring to try to create artificial life. It also required them to carefully weigh the qualities of the human mind they wanted to incorporate in their models and the qualiÂ­ties they wanted to leave behind.\n\nAI science is unusualâan extreme caseâin the history of Western sciÂ­enceâs long struggle with dualism. As a mind modeling mind, the artificial intelligence scientist is both subject and object: the observer and the observed. He cannot deny his agency. Unlike other forms of scientific discourse, which attempt to erase all social fingerprints from scientific reason, artificial intelliÂ­gence scientists recognize that their fingerprints are indelible. Some even seem to celebrate their presence: to engage in conscious myth-making about the significance of their work. For these reasons, the extreme case is also an ideal case for exploring the mythopoetics of scientific vision.\n\nAI scientists have spoken very freely and often quite extravagantly about their roles as modelers and about the qualities of their models. During World War II, women played substantial roles in wartime computing; however, nearly all artificial intelligence scientists during the Cold War era were men. They formed the so-called nerd or, until it became a pejorative term, hacker masculine subcultures of elite science and engineering schools; it is therefore not surprising that the AI manifesto writers are all male.\n\nIndeed the subworld of pre-PC academic and scientific computing was perhaps the purest post-World War II articulation of the monastic culture of sciÂ­ence so painstakingly documented by David Noble in his underappreciated but groundbreaking contribution to both the history of science and the feminist critique of science, A World Without Women: The Christian Clerical CulÂ­ture of Western Science (1992). The nature of early computer technology and the rigid gender socialization of the Cold War era combined to make the subworlds of serious academic and scientific computing an exclusively male preserve. Use of mainframe computers was based on time-sharing. Typically, by day the mainframe did the routine business of the university, its instructional and administrative tasks, and perhaps some of the work of senior reÂ­searchers. By night, computer centers belonged to engineering and computer science graduate students, who basically lined up to run, then debug, then reÂ­-run the complex programs that demanded a lot of the computerâs time and memory. These graduate students, who attended and taught classes by day, did their real work in and near the computer labs by night. Within the comÂ­puter subculture, the mainframe was referred to as God, who determined the life (a successful run) or death (a glitch that needed debugging) of programs.\n\nThe lumbering technology of the machines themselves demanded a kind of de facto near-equivalent of a vow of celibacy from their supplicants. They were expected to demonstrate their seriousness by periodically eatÂ­ing, sleeping, and socializing in the building that housed the computer. The overachievers, the nerds and hackers, virtually lived in and for the nightÂ­time worlds of the labs. Like most all-male subcultures, this one had a dark underside in which male bonding was frequently mediated by shared misogynist and repressed homoerotic fantasies, jokes, and storytelling. Technology itself is sometimes eroticized within the subcultures of elite science, creating a kind of technoporn âthat rouses prurient interest, demeans the powerless, eroticizes domination,â and sets up boundaries that signal they are off-limits to women and other outsiders.\n\nMy analysis opens a rather narrow window onto that masculine subculture by exploring the mythopoetics of the technovisions of AI. It also examines the anxious image of masculinity that accompanies the generative metaphors that animate these visions.\n\nDreams of Reason: When Dreamers Dream They Are Dreaming, Are They Awake?\n\nWorking largely independently of each other, constructivist and feminist analyses of science have exposed the fiction of âpureâ science. They have established that science, like other noble and ignoble human enterprises, is the work of mortal men and women, not of gods. Science is a social and cultural practice, which supports some of humankindâs highest aspirations to and achievements of excellence.\n\nUntil the twentieth centuryâand then only in atypical cases, for example Heisenbergâs physics, GÃ¶delâs Theorem, and AI modelingâscience has been a practice that has been secured in denial of its own nature. This denial has been deftly concealed and papered over for centuries by official histories and laundered origin stories. Anchored in the Western mind-body dualism, this denial makes doing science an âout-of-body experience.â The scientist seeks domination over nature by denying, implicitly or explicitly, that he is part of nature. His pretense to objectivity is maintained by detaching his mind from his body and the world, and by denying his mortality. This stance allows the scientist to believe that he is spying on the world from afar: viewing it dispassionately through Godâs eyes or through the eyes of an astronaut. The gendering of the pronouns in this paragraph is conscious and purposeful, for in Western culture this kind of disembodied Promethean objectivity has been a masculinist preserve and privilege. Within its assumptions, woman has been conceived as part of nature, as âthe sex,â and always embodied. In his Sixth Meditation, RenÃ© Descartes provides the definitive articulation of this (masÂ­culine) stance when he asserts, âI am truly distinct from my body, and â¦ I can exist without it.â\n\nAlâs positioning vis-a-vis the mind-body problem is shot through with contradiction. On the one hand, the Cartesian flight from embodiment and mateÂ­rialism reaches one of its clearest and most thorough articulations in the viÂ­sionary statements of AIM, because the computer is âthe embodiment of the world as the logician would like it to be,â not as it is. The goal of the AI sciÂ­entist is to release mind from body: to download its contents into programs. On the other hand, however, AI and the new sciences of complexity are fuÂ­turistic visions: âdreams of reason.â They are exercises of scientific imaginaÂ­tion rather than faithful codings of empirical reality. The dreamers know they are dreaming: They are not in denial about that.\n\nThey simultaneously share and surrender the Cartesian dream of pure reason, of a âPromethean flight from embodiment,â to borrow Susan Bordoâs words. Their top-down struggle to release mind from body has, in the course of the history of AI research, paradoxically pulled AI researchers back to biÂ­ology. It is the body, the human biological system, with its brain, nervous sysÂ­tem, nerve endings, and mercurial emotional apparatus, that weighs so heavÂ­ily against AI and keeps its flight grounded. The more successful AI scientists are in advancing the Promethean dream, the more the model comes to reÂ­semble what they want to escape. From a bottoms-up perspective, Hofstadter describes the paradox that locks the AI scientist in a recursive loop: â[A]ll inÂ­telligences are just variations on a single theme: to create true intelligence, AI workers will just have to keep pushing to ever lower levels, closer and closer to brain mechanisms, if they wish their machines to attain the capacities which we have.â The better the bottoms-up machines get, the slower they will get. The microworlds of the bottoms-up dream are the complete antitheÂ­sis of the Buck Rogerian top-down supercomputer.\n\nThe resulting discourse is, understandably, profoundly ambivalent about embodiment. The body is the enemy as well as the portal to knowledge that can transcend the body. In the Buck Rogers versions of the dream, the program becomes the spaceship that allows the AI scientist-astronaut to escape from the enemy (e.g., the body, woman, morality, or nuclear annihilation). The scientist moves into another dimension, no longer human or embodied. The best of what he has to offer survives in this new dimension. In HofÂ­stadterâs scenario, however, the scientist assumes a Zen-like stance and learns to live with, even savor, the intellectual and aesthetic pleasures of contradicÂ­tion. He faces the paradox of the recursive loop head-on and demonstrates the intellectual and aesthetic pleasures of life lived on its rim.\n\nWhether Hofstadterâs version marks the end of AIM, the point where it transcends itself and mutates into the new sciences of complexity, or whether it marks Alâs rebirth as a mature research program, may still be an open question. He describes the top-down approach as overââRetrospectsââand the bottoms-up perspective in the future tenseââProspects.â These prospects are based on wholism rather than on reductionism, in computerese, parallel processing units and neural nets: â[M]any trains moving simultaneously down many parallel and crisscrossing tracks, their cars being pushed and pulled, attached and detached, switched from track to track by a myriad neural shunting-engines.â\n\nThe Poetry in the Paradigms\n\nLike Descartes and Boyle, AI researchers embrace mechanical metaphors of mind. They conceive of mind as machine: a computer, a grid of electrical relay switches, âmany trains moving simultaneously,â and so on. While some, like Turing, acknowledge the limitations of this conception within AI parascientific discourse and top-down AI modeling, the âprogramâ is a metonymic surrogate for intelligence. AI constructs computer models of operations of mind by reducing its cognitive and biological processes to maÂ­chine-recognizable inputs. AI modelers assume that all interesting manifestations of intelligence can be âcapturedâ and âcontained withinâ programs. According to one journalistic chronicler of AI, some AI modelers even beÂ­lieve it is possible to precisely quantify and program the âodd little chemical electrical cloud of activity that is our personality.â\n\nMetaphors are usually thought of as tools of humanists, not scientists. The eighteenth-century English poet William Wordsworth was apparently the first thinker to argue that poets and scientists share similar relationships to nature, even though their languages differ. The scientist uses Royal Academy prose and the poet uses meter to interpret nature. Both approach the unknown through the portals of the known, and scientist, no less than poet, uses analoÂ­gies to construct bridges between the two. Although scientists from Francis Bacon to the present wish it were not so, the bridges the scientist builds beÂ­tween the familiar and the mysterious, like the poetâs spans, are constructed of bricks baked in the cultural and linguistic kilns of historical time.\n\nScientific vision, like poetic vision, is expressed most palpably through metaphors. The metaphors used by scientists are not, however, incidental to the scientific enterprise. To the contrary, they empower scientific vision; they provide the scaffolding for arguments, color the language of assertion, and guide inquiry. Indeed, Richard Dawkins claims, âSkill in wielding metaphors and symbols is one of the hallmarks of scientific genius.â In short, they are the magic carpets that make science possible.\n\nMetaphors are not, however, all that make science possible. Mathematics formalizes and refines scientific vision; instrumentation amplifies and standardizes it; and systematic, repetitive, and controlled observation tests its reÂ­liability. Yes, metaphors lurk within and enable these practices tooâlike GÃ¶delâs Theorem, reminding us of the limits of all human knowledge. But lost at sea, who amongst us would not rather have a compass than a sonnet? Science has demonstrated its potency in practice. Studies in the history, philosophy, and sociology of science have nonetheless firmly established that metaphors are a necessary, though far from sufficient, component of scientific thought. Bacon was right! They are also mischief-makers that smuggle âthe idols of the tribeâ into science. This mischief does not negate or invalidate scientific claims, but it does humanize them.\n\nSocial constructivist unpackings of the poetry in the paradigms have knit many scientific brows into exasperated consternation. But mythology! What are scientists to make of it? Hofstadter would probably advise art, music, or some more science; and he would be right. Mythology is a testament to human aspirations, not just a graveyard of human fallacies and foolishness. We are all, in some sense, poets, although there are very few Wordsworths, Shakespeares, Byrons, Bacons, Turings, or von Neumanns among us. All of our poetry, including the poetry of science is, however, a record of what humans value, aspire to, and fear.\n\nThe Enlightenment cast scientists in the role of supermen. In its cosmolÂ­ogy, nature displaced God as first principle; the scientist replaced the priest as authoritative interpreter of the reality. Scientists were expected to see with the eyes of gods and to be natureâs ventriloquists. The voice of scientific reason was conceivedâimpossiblyâas the unmediated and therefore objective voice of nature. Scientific instrumentation and calculations created and preÂ­served this construction of objectivity, which did, in fact, prove to be an exÂ­traordinarily productive way of interpreting and imputing patterns to nature. In short, the Kantian trick usually worked.\n\nIn making their daring claims at the height of the Inquisition, the members of the Royal Society not only risked the wrath of the God (if they were wrong) but the swords of inquisitors (if they were right). To weather the fury of the storm, fear was repressed in the tough-minded, even macho, Baconian vision of the masculine future of science. It was a brave vision that took modem science far. Like most brave visions, however, its monological and monovocal structure and resonance left their imprimatur on both the vision and the visionaries.\n\nFear is, of course, a proscribed emotion for men in the West (perhaps for men everywhere); if they have it, they are supposed to repress it. Repressed sentiments and ideas do, however, have a habit of returning; mythology is a primary staging ground for this return. Male fear seems almost to be the axis upon which modern science has turned; and the momentum generated by this axis has been simultaneously constructive and destructive to the species and the planet. For example, scientists did not seek to understand natural disasters just because they posed interesting scientific problems. Well-warranted fear, as much or more than cool-headed rationality, provided the momentum for the quest for scientific predictability and control. Earthquakes, hurricanes, volcanic eruptions, fires, floods, deadly diseases, nuclear explosions, and, yes, women have variously terrified many scientists as well as fascinated them. Not surprisingly, both terror and fascination are encoded in the mythopoetics of scientific thought.\n\nMetaphors and Minds\n\nMetaphors based upon images of sexual relations and reproduction are both common and deeply embedded in the discourses of Western science and culture. Bacon himself incorporated them in the foundation documents of modÂ­ern science, including his fragmentary The Masculine Birth of Time (1602 or 1603). These metaphors place the scientist in a hierarchical relationship of domination and control of nature. Within the mythopoetics of computer sciÂ­entists, reproductive metaphors occupy a much more prominent position than copulative imagery, although the latter are invoked in predictable ways to repÂ­resent inputs, circuitry, and connections.\n\nImages of male birthing have been a common motif (even, for those so inclined, a Jungian archetype) of Western origin storiesâfor example, Zeus giving birth to Athene from his head and God creating Eve from Adamâs rib. Lionel Tiger claims rites of male bonding are âthe male equivalent of child reproduction, which is related to work, defense, politics, and perhaps even the violent mastery and destruction of others.â Brian Easlea makes a similar point when he asserts:\n\nMen in prescientific societies, it may be generally argued, attempt to affirm masÂ­culine and, for them therefore, dominant status through secret exclusively male rituals. Quite often these rituals have a very direct âpregnant phallusâ aspect to them, the male participants thereby demonstrating that through their special phallic powers they, like women, are able to give birth.\n\nBoth Easlea and Evelyn Fox Keller demonstrate the continuing presence of the images of the âpregnant phallusâ in the mythopoetics of contemporary science.\n\nBirth is the primary (perhaps even primal) source of most of the poetry in the paradigms of computer science. Computers are the sites of the generative process. They are, in the words of AI scientists Roger Schank and Harold Abelson, âomnipotentâ; Schank and Robert Abelson describe them as âgod.â They are also incubators, (male) wombs that are conceived as mediums for generating new forms of life. According to David Gelernter, these incubators will soon produce âmirror worldsâ: You will be able to look into a âgenie botÂ­tle on your deskâ and see âreality.â Computers will soon become âcrystal balls, telescopes, stained glass windowsâwine, poetry or whateverâthings that make you see vividly.â They will put âthe universe in a shoebox.â Why? Because â[a] bottled institution cannot intimidate, confound or ignore its memÂ­bers; they dominate itâ (emphasis in original).\n\nThe virility and reproductive prowess of computers is expressed through three interconnected sets of birth images: images representing creativity, immortality, and progress.\n\nImages of Creativity\n\nMuch of the mythologizing of the computer science fraternity is conscious, inÂ­tentional, and programmatic: It serves a community-building function in AIM. It makes the work and the sacrifices it requiresâthe deferred gratification of always becoming, never fully arrivingâspecial, ordained, daring, and even godlike. In God and Golem, Inc. (1964), Norbert Wiener, widely referred to as the âfather of cybernetics,â maintains that machines that learn, reproduce themselves, and coexist with men pose profound theological questions. Wiener points out that if a contemporary of Francis Bacon had claimed to be able to make machines that could âlearn to play games or that should propaÂ­gate themselves,â he would surely have been burned by the Inquisition, âunÂ­less he could convince some great patron that he could transmute the base metals into gold, as Rabbi Low of Prague, who claimed that his incantations blew breath into the Golem of clay, had persuaded the Emperor Rudolf.â\n\nAccording to the folklore of the computer science subculture, Wiener, John von Neumann, Gerald Sussman, Marvin Minsky, and Joel Moses all claimed to be actual descendants of Rabbi Low, perhaps the first mortal man to be credited with creating life without using woman as a vessel. Moreover, Lowâs descendants believe they are carrying on the family tradition. By the mid-1980s, these latter-day alchemists maintained that they had already given birth to four generations of Golem. The labor pains they were then experiÂ­encing in their attempt to give birth to âthe fifth generationâ of computers were extraordinary because the âpregnant phallusâ was more pregnant than usual. It was struggling to bring forth very special progeny: a superchild who will be able to reproduce itself without the agency of either man or woman.\n\nSome enthusiasts herald âneural netsâ as this special progeny. Indeed, to cross the border from one genre of scientific vision to another, an episode of Star Trek featured conscious, intentional, and ethical neural nets contemplatÂ­ing the injustices of their human sires. The crossover from science to science fiction is a common one: Science feeds the imagination of science fiction writers, and many scientists feed off of science fiction. As Freeman Dyson puts it, âScience is my territory, but science fiction is the landscape of my dreams.â Scientist and science fiction writer share the same imaginative field and vocabularies of motive: They are both posed on the precipice of the possible and asking, âWhat if . . . ?â In Greek mythology, the lesser Greek god Prometheus incites the wrath of Zeus by giving fire to man. Contemporary Prometheans invert the flight trajectory: Their leaps of imagination are intended to make them godlike. They seek to transcend embodiment, biology, and gravity, and give birth to a new, superior species of ideational forms.\n\nImages of Immortality\n\nAccording to the fathers-to-be, this much-anticipated superchild may cut through the genetic coding of the universe and produce âthe next step in human evolution.â Some computer scientists believe this generation of computers will possess the power to transform their fathers into âsupermen.â They claim this vaunted son of the computer god will allow them to download the contents of their own minds into programs and thereby achieve immortality.\n\nOne proud papa, Hans Moravec, director of the Mobile Robot Laboratory at Carnegie Mellon University, maintains, âThe things we are building are our children, the next generations. Theyâre carrying on all our abilities, only theyâre doing it better.â In Mind Children: The Future of Robot and Human Intelligence (1988), Moravec acknowledges that today âour machines are still simple creations, requiring the parental care and hovering attention of any newborn, hardly worthy of the word âintelligent.ââ Within the next century, however, he promises âthey will mature into entities as complex as ourselves, and eventually into something transcending everything we knowâin whom we can take pride when they refer to themselves as our descendants.â\n\nThe gender of these children is seldom in doubt. When references to AI or robotics are personified, male pronouns are typically used. Within the often too transparently Freudian imagery of the lore of infotech, however, software and software designs are sometimes personified as femalesâfor example, Eliza and Linda. This practice departs from common, humanistically inspired conventions of tech-talk because technology is usually personified as female. Andreas Huyssen attributes this practice to fear of autonomous technology: âAs soon as the machine came to be perceived as a demonic, inexplicable threat and as the harbinger of chaos and destruction â¦ writers began to imagine the Maschinenmensch as woman.â This move also has mythological precedence, as, for example, Pandoraâs box.\n\nFor top-down Al, the signs are changed: The prospect of autonomous technology is exciting, a source of wonder and daring defiance of JudeoÂ­-Christian understandings of life and death and of conventional American values like God, motherhood, and apple pie. Sometimes this defiance gives practitioners pause, leads to self-interrogations of the ethical implications of AI. Yet, self-interrogations of the godlike powers of mind-makers are also, by definition, celebrations of those godlike powers, which separate the dilemmas of AI scientists from the problems of ordinary folks, who are still stuck back in an earlier stage of evolution. An exception to top-downersâ embrace of autonomous technology is, however, made in the case of computer viruses, which carry the regressive stigma of biological life and usually infect only (female) software.\n\nThe telos of AI is autonomous technology. It is AIâs ticket to immortality. Marvin Sussman, for example, conceives of the mind children, produced by AI, as delivering their fathers to the threshold of life everlasting: â[T]he machine can last forever,â and âif it doesnât last forever, you can always dump it out onto tape and make backups.â As we shall see, bottoms-up AI is having difficulty sustaining this optimism. The return of biology not only refills Pandoraâs box; it also opens the door to Mary Shelleyâs humanist and femiÂ­nist nightmare of the deformed progeny of phallic pregnancies: the FrankenÂ­stein monster.\n\nThe Cartesian disconnection of AI researchers that permits them to conflate mind and machine also allows them to conceive of biological death as a miÂ­nor episode in the life cycle of a superman: âIf you make a machine that conÂ­tains the contents of your mind, then that machine is you.â Indeed, within the mythos of AI modelers, biological man (as well as woman) becomes an obstacle to be conquered and rationalized.\n\nThe contents of the mind cannot be downloaded into immortality until the information channels are cleaned up. For this reason, AI simulation requires modelers to subject cognitive processes to the Law of the Hammer, albeit reluctantly and only for the time being until more complex forms of modeling become possible. The AI modeler must reduce complex cognitive and biological processes to a series of discrete and univocal binary commands. Modeling even a very simple movement like raising the arm of a man to press a lever may require identifying, mapping, and simulating hundreds, even thouÂ­sands, of cognitive and neurological messages. Add to this the fact that within biological man, these messages are often confounded by the ânoiseâ of indeÂ­cision, procrastination, memory, reflection, love, lust, and other sentiments, values, and intentions that appear to be irrelevant to the immediate task at hand.\n\nCleaning up the information channels to create models that will program a robot to push a lever with the same cool efficiency, regardless of whether the lever releases bombs or coffee cups, is therefore a genuine achievement of Cartesian logic. Faulting the AI modeler for preferring clean channels to cluttered ones is like faulting the plumber for preferring clean drains to clogged ones. Both find their efforts blocked by the waste products of biological man. The AI modelerâs dream of a clean machine is a dream of Cartesian tranÂ­scendence, perhaps even redemption. But where Descartes wanted to control the noise of embodiment, AI researchers frequently express a desire to elimÂ­inate the body. The late Heinz Pagels, then-director of the New York AcadÂ­emy of Sciences, found serious humor in the Cartesian mind-body problem: the incompatibility of rationality and sexuality, in this instance male sexuality. He opens his survey of the sciences of complexity, The Dreams of Reason: The Computer and the Rise of the Sciences of Complexity (1988), with a quotation from Robert Hutchins: âWhen the penis goes up, reason goes out the winÂ­dow.â Computers, it seems, can eliminate this distraction.\n\nRodney Brooks explains why he wants to eliminate âthe wet stuffââhuman bodiesâfrom the equation: âWe are sort of locked into our genetic structure. At the moment we might be able to tweak our genetic structure a little bit, but nothing severe.â Brooks sees âan advantage to building robots out of silicon and stuff like that, because we know how to control that fabrication process pretty well,â whereas we have âtrouble withâ biology: âWe canât add more brain cells to us, but we can add more processors, more siliÂ­con, to a robot.â In short, robots are easier to expand, repair, and control than their messy and unpredictable prototypes.\n\nBecause the legend of the pregnant phallus requires the scientist to make love to himselfâto give birth to a âsacred imageâ of himselfâit encourages narcissism. Sherry Turkle reports the following conversation between AI scientists. Don Norman says, âI have a dream to create my own robot. To give it my intelligence. To make it mine, my mind, to see myself in it. Ever since I was a kid.â Roger Schank responds, âSo who doesnât? I have always wanted to make a mind. Create something like that. It is the most exciting thing you could do. The most important thing anyone could do.â Gary Drescher tells Turkle, âWe have the right to create life, but not the right to take our act lightly.â Drescher believes scientists have ethical obligations in a society where human and artificial intelligence live together.\n\nFollowing the lead of science fiction writer Isaac Asimov, Drescher entertains the idea that AI may make a new form of murder possible:\n\nPeople always talk about pulling the plug on computers as though when it comes to that they will be saving the world, performing the ultimate moral act. But that is science fiction. In real life, it will probably be the other way around. We are going to be creating consciousness, creating lives, and then people may simply want to pull the plug when one of these intelligences doesnât agree with them.\n\nImages of Progress in AI Discourse\n\nSome AI scientists acknowledge that the next step in evolution may render humans obsolete. Marvin Minsky thinks âpeople will get fed up with bodies after a while.â He predicts that like the dinosaurs we might disappear, leaving behind a âsocietyâ of interacting and self-generating computer systems.\n\nEvolutionary analogies are common in AI discourse. They appear to repreÂ­sent a form of masculine display: a way of saying my science is bigger (more potent or pregnant) than yours. However, evolutionary images are also used to convey disdain for and distance from conventional conceptions of life, death, thought, and morality. That is, they are used to signal a radical departure from all previous ways of knowing and being in the world. Thus, Moravec asserts, âI have no loyalty to DNA,â and Mike Blackwell claims, âBodies have served their purpose.â\n\nMoravec valorizes the departure, the irrevocable break with the past: âWe are on a threshold of a change in the universe comparable to the transition from non-life to life.â On one level, AI scientists seem to be embracing a reÂ­turn to pre-Baconian animism in which matter, cum machine, is endowed with life and anthropomorphosized. There is, however, more to the equation. The transition is not to life. There is a change in signs, which negates the value of human life: Machines evolve, humans download or die. Within AIâs mechanistic reconstruction of evolutionary theory, the pregnant phallus finally achieves deliverance: Mind is released from body and man is released from his biological dependence on woman. Moravec describes the brave new âpost-biologicalâ world of AI:\n\nAll our culture can be taken over by robots. Itâll be boring to be human. . . . We canât beat the computers. So it opens another possibility. We can survive by movÂ­ing over into their forms . . . because we exist in a competitive economy, because each increment in technology provides an advantage for the possessor. . . . Even if you can keep them [the machines] slaves for a long time, more and more decision-Â­making will be passed over to them because of the competitiveness.\n\nWe may still be left around, like the birds. It may be that we can arrange things so the machines leave us alone. But sooner or later theyâll accidentally step on us. Theyâll need the material of the earth.\n\nReproduction as Destruction in AI Discourse\n\nIn the transition from life to program, the clean machine supersedes its sweaty, plodding, loving, lusting, and aging progenitor. And, the pregnant phallus eliminates the âwet stuffâ that permitted its prototype to penetrate BaÂ­conian âholes and corners.â The violence of the vision is neatly occluded by comic strip captions. Robots will accidentally step on âus,â but thatâs okay because âweâ wonât really be there anyhow: âourâ now immortal minds will be able to abandon mother Earth entirely. Indeed, some AI scientists invoking the doomsday scenario believe it is imperative that âweâ get some minds off of this nuclear and ecologically endangered planet and into space colonies before it is too late.\n\nInevitably, the question must be raised: Which minds? Since the capacity of the most powerful parallel processing machines (connection machines) will be finite, not everyone will be able to get out of their bodies or off of the planet. Some of âusâ will be stepped on, incinerated, or poisoned by toxic waste. So, who gets downloaded into the programs? The new evolutionary logic dictates the answer. The best minds, of course, the kinds of minds that are most readily available for modeling in the AI laboratories at MIT, Stanford, and Carnegie Mellon University: minds of upper middle-class, white, American, predominantly male computer scientists. These are, not incidenÂ­tally, some of the same minds and bodies that are most sought after by sperm bank entrepreneurs and their customers.\n\nThese are also some of the same minds that envision a future in which AI will render participatory democracy obsolete. Among them are minds that herald the coming of a time when machines, not people, will control the worldâs nuclear arsenals; when new forms of slavery will be introduced in which living machines (cyborgs) programmed to be âethicalâ will serve as slaves; when robots will be programmed to meet all (in- and out-of body) erotic needs and thereby render human intercourse and biological reproducÂ­tion redundant. In short, these are minds that embrace what Neil Postman calls âtechnopoly,â or totalitarian technocracy.\n\nThe mythos and metaphors of Al talk and texts display a familiar design. AI discourse is a discourse of control; it builds hierarchy into the hard-wiring of its circuitry. The robotic fantasies of AI researchers presuppose the necesÂ­sity of âthe violent mastery and destruction of others.â Comic book talk paÂ­pers over the perversity of AI concepts of creativity, immortality, and progress, but MIT researcher and outspoken in-house critic of AI ideology and eschatology, Joseph Weizenbaum, cuts through the cartoon images and conceives the perversity within the same frame history has used to comprehend its previous incarnations: genocide.\n\nThe faded mythology encoded in AI talk and texts demonstrates that AI is not the univocal discourseânot the pure Cartesian reasonâthat its architects thought they were encoding. Like the technostrategic discourse of the Cold War defense intellectuals analyzed by Carol Cohn, AI is also a discourse, which fails according to its own criteria: It is as far from a âparagon of coolÂ­ headed rationalityâ as was Francis Baconâs belief in the diabolical powers of witches. Weizenbaumâs characterization of AI scientists as big children who have not given up their âsandbox fantasiesâ or sublimated their dreams of omnipotence may be correct. But lest we swell with the satisfaction of oneÂ­-upping would-be gods, we should remember that we all harbor lost children within us, and that fear can usually be counted upon to release them from capÂ­tivity. And fear was the generative core of Cold War cosmology.\n\nLet us remind ourselves that the big children of AIM possess some of the best scientific and mathematical minds of the age. They are members of a powerful scientific elite: researchers, teachers, and gatekeepers of the most advanced and prestigious academic and commercial computer research centers in the world. The metaphors these men use to conceive nature, gender, and computer architectures are far more potent (and pregnant) than yours or mine. Donna Haraway contends that biology has already undergone a cybernetic revolution, in which natural objects have been retheorized as âtechnological devices properly understood in terms of mechanisms of production and storÂ­age of information.â This metaphoric reconfiguration of the territory of sciÂ­ence has fundamentally changed the character of scientific interventions in the biological and material worlds, and has thereby changed the nature of those worlds. The generative metaphors of information processing have transÂ­formed humans into cyborgs and astronautsâall of us: technophiles and technophobes, feminists and misogynists, acrobats and apple growers too.\n\nUnlike Baconâs patriarchal metaphors, which saw knowledge issuing from a chaste marriage between menâs mind and nature, top-down cybernetic metaphors locate the genesis of knowledge in the marriage of menâs minds and male machines. The mythos of male bonding encoded in AI discourse bears little resemblance to Platoâs homoerotic vision. AI metaphors replace Eros with objects: fetishes made of circuits and chips. Where Baconian epistemology suppressed the female principle, AIMâs technovisions negate the human principle, and as Weizenbaum points out, âThereâs nothing left after youâve destroyed the human species.â\n\nCoitus Interruptus\n\nThe strong top-down AI research program is both a tribute to and testimony against Western dualism and Enlightenment conceptions of reason. The selfÂ­-correcting elements in the hyperrationality of the top-down AI program were powerful enough to discover AIMâs own limits. This discovery, in turn, invalidated the essential tenet of AIâs premise: that reason exists in a dimension apart from and beyond history, culture, and sentient beings. The failure of the top-down program was a triumph for biology: a regrounding of mind in body and of mental processes as human, learned, and socially situated. Promethean man was pulled back to earth, as he always is when he flies too high: too far from his origins. In the mythopoetics of Western dualism, the triumph of the body is a triumph of the feminine principle.\n\nIn AI parascientific discourse, the latent symbolic ascent of the feminine that accompanied the paradigmatic shift to the bottoms-up approach was never grasped, and appears in any case to have been ephemeral: a transitory return of the repressed feminine dimension. It was briefly ascendant at the point of impact and (yes, I will say it) intercourse of thesis (top-down) and antithesis (bottoms-up), and in the period of the reconceptualization and reÂ­birthing of research programs for AI that immediately followed. That this moÂ­ment of opening occurred at the same time that the larger social, cultural, and political formations of global power were also undergoing profound, even epochal, transformations is, as we have seen, not coincidental. The crises that the end of the Cold War posed for the defense industry and for research funded by the Defense Department were widely chronicled in the media in the late 1980s and early 1990s. The permanent war economy had been very costly, but it had insulated postwar America against the extremes of the boom and bust cycles of capitalism. What was at the time dubbed by The New York Times as ârisks of peaceâ included not only displacing the economic stabilization of defense spending but also displacing defense workÂ­ers, which included a highly educated techno-scientific strata that could be very dangerous if it became alienated.\n\nThe dramaturgical accompaniments of the Persian Gulf War launched what President George Bush called a ânew world order,â which, counterfactually, sought to keep the old power-knowledge of the military-industrial complex intact. It did not work, except as television, and it was not, in any case, a strategy that held much long-term promise: It was too expensive and morally reÂ­pellent. For example, the US military estimates that the brief war took someÂ­where between one hundred thousand and two hundred thousand Iraqi lives, most of them civilians. As a dazzling, well-edited, globally broadcast television display of the triumphs of American technoculture, it did, however, foreshadow the future. The ClintonÂ­-Gore Administration defined that future in its technovision, the National InÂ­formation Infrastructure, and in its policies, treaties, and legislative initiatives (NAFTA, GATT, and the omnibus US Telecommunications Act of 1996), which supported the creation of a US-dominated global information econÂ­omy. Clinton-Gore went where no Republicans could have dared to go in acÂ­celerating the growth of corporate power and in defining corporate âcompetitivenessâ as a defense initiative.\n\nThe âsmartâ bombs profiled in the Persian Gulf War drama were protoÂ­types for the smart technologies that would build the new information econÂ­omy. By the early 1990s, the bombs were almost smart enough; and the reÂ­search that produced them had already had some success in the consumer marketplaceâfor example, the original computer game, Flight Simulator, and search-and-destroy video games. Virtual reality simulations showed commerÂ­cial promise as techno-entertainments as well. AI research, like other forms of defense research, was encouraged to redefine itself, and generous governÂ­ment funding was dedicated to moving American science, scientists, and deÂ­fense contractors through the transitional period. Research agendas were expanded to include educational, entertainment, biotechnologies, and other commercial applications. Visionary high-tech ideas were brought to bear on mundane tasks. Military and commercial agendas were often pursued in tandem. The development of robotic vision, for example, retains military appliÂ­cations, making those smart bombs even smarter in hitting targets, but its poÂ­tential applications as prosthetics for the blind are also smart commercial (and humane) investments.\n\nThis commercialized technovision appears to support somewhat more humane agendas than the mature top-down AI approach, insofar as it is less overtly tied to the monovocal agenda of Cold War demonologyâfor example, eradicating the âevil empire.â The level of fear and doomsday paranoia that accompanied the Cold War vision had largely disappeared from mass-mediated articulations of ideology and public policy until the 2001 terrorist attacks on the US and the USâs subsequent launching of its global War on Terrorism. This demonology continued to thrive in defense think tanks, and it prospers among fringe militia, survivalist, and white supremacist groups: groups made up primarily of white males who claim to be disenfranchised by the moderÂ­ately more inclusive post-Cold War definitions of social reality.\n\nWithin computer science, doomsday scenarios have, interestingly enough, been transferred to the programs themselves. They revolve around fears of techno-terrorism, including hacker breaches of government and corporate security, scenarios of contamination of networked systems by massive selfÂ­-replicating viruses, and dystopias involving techno-wars and extermination of the human race by a future species of intelligent robots.\n\nWill the Pregnant Phallus Deliver Self-Replicating Powers and a New Generation of Anti-Human Terrors?\n\nWhat does the future hold? That is the perennial question that is posed to, and by, AI and robotics research and development scientists. The AI research community is no longer fully a male preserve, âa world without women.â Women are a growing, though still small, presence within the ranks of AI and robotics research and development, although they have not yet issued any manifestos. Whether they will ultimately forge new metaphors and new ways of thinking about conceiving artificial life remains an open question.\n\nAt present, the US government under President George W. Bush is gearÂ­ing up once more to strongly reassert its presence in computer science reÂ­search and development by reviving development of the ill-fated (and, many scientists believe, ill-conceived) Cold War Star Wars missile defense system, originally proposed and funded under the Reagan-Bush I Administration. It appears, at this point, that the War on Terrorism has given the Bush Administration the mandate it needs to override scientific reservations and congresÂ­sional opposition to reviving the missile defense program. Moreover, the US government has announced that it now needs aggressive as well as defensive weapons to conduct cyber-warfare. The huge reinfusion of defense funds will define the futures of AI and AL.\n\nWill the mature research program of the bottoms-up approach of AI be more humane than the mature program of the top-down approach? There is no reason to assume it will be; indeed, it could be more inhumane. The sandbox fantasies have not disappeared; in fact, they may have moved closer to becoming technological realities. Hans Moravec is still around, and still believes that âbiological humansâ will âbe squeezed out of existence.â Danny Hillis, now known as the father of parallel processing, is still thinking about escaping the grim reaper: âIâm as fond of my body as anyone, but if I can be 200 with a body of silicon, Iâll take it.â Ray Kurzweil is predicting we will become robots or fuse with robots.\n\nIn âWhy the Future Doesnât Need Usâ (Wired, March 2000), Bill Joy, cofounder and chief scientist of Sun Microsystems and co-chair of a presÂ­idential commission on the future of information technology research, wonders how other techno-wizards can silently live with their fears. Joy reports that the kind of technology Moravec envisions will be feasible by 2030:\n\nWhat was different in the 20th century? Certainly, the technologies underlyÂ­ing the weapons of mass destruction (WMD)ânuclear, biological, and chemÂ­ical (NBC)âwere powerful, and the weapons an enormous threat. But buildÂ­ing nuclear weapons required, at least for a time, access to both rareâindeed, effectively unavailableâraw materials and highly protected information; biÂ­ological and chemical weapons programs also tended to require large-scale activities.\n\nThe 21st-century technologiesâgenetics, nanotechnology, and robotics (GNR)âare so powerful that they can spawn whole new classes of accidents and abuses. Most dangerously, for the first time, these accidents and abuses are widely within the reach of individuals or small groups. They will not require large facilities or rare raw materials. Knowledge alone will enable the use of them.\n\nThus we have the possibility not just of weapons of mass destruction but of knowledge-enabled mass destruction (KMD), this destructiveness hugely amplified by the power of self-replication.\n\nI think it is no exaggeration to say we are on the cusp of the further perfecÂ­tion of extreme evil, an evil whose possibility spreads well beyond that which weapons of mass destruction bequeathed to the nation-states, on to a surprisingly terrible empowerment of extreme individuals.\n\nWhere the NBC technologies of the twentieth century were largely develÂ­oped by the military in government-controlled laboratories, Joy points out, âWe are aggressively pursuing the promises of these new technologies within the now-unchallenged system of global capitalism and its manifold financial incentives and competitive pressures.â He envisions scenarios where corporations may be forced into something like voluntary disarmament or the equivalent of biological weapons inspections if the species is to survive. Lest we blame the messenger, Joy is pushing the panic button precisely because he wants to initiate public dialogue about techno-futures, which, to date, have been shaped without it. He sees the astronautic fantasies of scientists, which call for evacuating the earth, as forms of denial that abdicate responsibility.\n\nIn the aftermath of the anthrax attacks on the US Postal Service, ConÂ­gress, the media, and the public that immediately followed the September 11, 2001 terrorist attacks in New York, Washington, and Pennsylvania, Joyâs jeremiad resonates with even greater gravity. No one has taken responsibility for the anthrax attacks, which are at present assumed to be the work of a domesÂ­tic terrorist, not the al-Qaida network. Government forces, from federal to loÂ­cal levels, remain on high alert for further biological and chemical terrorist attacks. As a result, the scenario Joy describes takes on a new and chilling sense of reality.\n\nJoy does not address the gendered components of these technovisions or the gender orders they will support, but he does try to see beyond the conventional horizons of Western science and culture. Siding with the biological life on planet Earth, he is a de facto ally in the struggle for a more human, and therefore a future friendlier to women, the species, and the planet. Moreover, by virtue of the authority his background gives to his argument, it is a valuÂ­able addition to the arsenal of ideas that can be mobilized in âthe semiologiÂ­cal warfareâ that is required to interrupt the privatization of policy making that the new enclosure movement has empowered and normalized. Joyâs goal is to open up a broadly based dialogue about the deployment of techÂ­nologies before they are deployed, not to provide lay readers with a definitive take on the science of the future. If his scenario is alarmist, then open, inÂ­formed, critical, democratic dialogue can serve as a corrective. In any case, democratic dialogue about techno-futures is urgently needed if democracy is to retain (or recover) any meaning beyond the symbolic or spectral.\n\nNew Science Requires New Poetry: Returning to the Launch Pad\n\nThe process of interrupting and correcting the talk and texts of technoscience has just begun. Haraway describes such interventions as forms of practicing âpolitics by other means.â Yes, and poetry too! For the first step in scientific revolutions (as in political revolutions) is to change the names, because scientific revolutions are metaphoric redescriptions of nature, not (or not only) codÂ­ings of revolutionary new insights into the intrinsic nature of phenomena.\n\nMost, though certainly not all, constructivist and Western feminist conceptions of nature and humankind break with the astronautic vision. Feminist perÂ­spectives support metaphors, models, and taxonomies for describing nature that are less hierarchical, more contextual and permeable, and perhaps more reflexÂ­ive than their masculinist predecessors. The achievements (and perversions) of Western science have been possible because they have taken flight on tranÂ­scendent metaphorsâfor example, Prometheus, Icarus, Faust, Superman, cyborg, and astronaut. These metaphors deny embodiment and mortality, whereas imÂ­ages of domesticity, embodiment, and material necessityâimages drawn from womenâs experienceâkeep our feet on the ground. Fully human conceptions of nature and being must do both or both/and. That is, they must allow usÂ­âall of us!âto dream dreams that make the impossible possible. But they must also recognize that it takes many dreamersâmany diverse, self-reflexive, huÂ­man agentsâto dream life-affirming dreams: women and men in life-sustainÂ­ing communities, not insular enclaves of scientific geniuses or self-replicating forms of hardware and software.\n\nThis new way of thinking is, however, unlikely to emerge from truces, whether voluntary or mandated, in the so-called scientific wars. Adding women to science and stirring will not do the job. Indeed such a strategy, no matter how well intended, is likely to either kill the spirit of the women who are added to science or kill the spirit of science. Rather, species-friendly conceptions of nature are far more likely to find incubation within new generaÂ­tive metaphors that will, in turn, prove to be more illuminating, inspiring, and effective in meeting the life-sustaining challenges that lie ahead. Or, to put it pragmatically, expanding the landscape of the scientific imagination may prove to be more important to twenty-first-century earth science than it was to twentieth-century space science.\n\nIf scientists like Moravec, Kurzweil, Joy, and others are right about the fuÂ­ture, survival of the planet now requires terminating the exterminating eleÂ­ments in the self-replicating technologies of genetics, nanotechnology, and robotics. Our interventions need to attend to the problem from the launchÂ­ pad rather than the space station. We need to cast our collective lot with Earth, not the stars. We need to find our metaphors closer to home: to come back to Earth, back to our aging, sweating, imperfect, mortal bodies. We need to face the responsibilities, tensions, ambiguities, and pleasures of a fully human life and death. In short, we need to dream a new cultural dream: a dream that reÂ­quires nothing less than interruption and redirection of the out-of-body expeÂ­riences of modern and postmodern science.\n\nThis chapter is a reprint of Sue Curry Jansen, âWhat Was Artificial Intelligence?â in Critical Communication Theory: Power, Media, Gender, and Technology (Lanham, MD: Rowman & Littlefield, 2002). The text appears as originally published, with the exception of reference formatting and minor corrections. Reprinted by permission."
    }
}