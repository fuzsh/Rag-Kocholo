{
    "id": "dbpedia_442_2",
    "rank": 56,
    "data": {
        "url": "https://issues.org/mathematizing-the-world/",
        "read_more_link": "",
        "language": "en",
        "title": "Mathematizing the World",
        "top_image": "https://issues.org/wp-content/uploads/2019/01/A-Mind-at-Play.jpg",
        "meta_img": "https://issues.org/wp-content/uploads/2019/01/A-Mind-at-Play.jpg",
        "images": [
            "https://issues.org/wp-content/themes/ristretto/img/header-logo.svg",
            "https://issues.org/wp-content/uploads/2019/01/A-Mind-at-Play-672x1024.jpg",
            "https://issues.org/wp-content/uploads/2024/07/saulrevisedHR-1800x1562.jpg",
            "https://issues.org/wp-content/uploads/2024/06/IRL-lede-Brent-1800x1200.jpg",
            "https://issues.org/wp-content/themes/ristretto/img/issues-logo-black.png",
            "https://issues.org/wp-content/uploads/2024/04/nas-logo-white-space-1.png",
            "https://issues.org/wp-content/themes/ristretto/img/asu-logo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Jay Lloyd",
            "Saul Perlmutter",
            "Molly Galvin",
            "Brent Blevins",
            "Lisa Margonelli",
            "Lav R. Varshney"
        ],
        "publish_date": "2019-02-04T14:00:58+00:00",
        "summary": "",
        "meta_description": "The American engineering theorist Claude Shannon has largely been written out of popular history, despite developing the mathematical foundations of communication, data compression, digital computers, cryptography, circuit complexity, and networking, as well as laying the foundations for human-computer interaction and artificial intelligence—the defining technologies of the information age. In A Mind at Play, biographers Jimmy […]",
        "meta_lang": "en",
        "meta_favicon": "https://issues.org/wp-content/uploads/2019/04/cropped-issues-favicon-32x32.png",
        "meta_site_name": "Issues in Science and Technology",
        "canonical_link": "https://issues.org/mathematizing-the-world/",
        "text": "The American engineering theorist Claude Shannon has largely been written out of popular history, despite developing the mathematical foundations of communication, data compression, digital computers, cryptography, circuit complexity, and networking, as well as laying the foundations for human-computer interaction and artificial intelligence—the defining technologies of the information age.\n\nIn A Mind at Play, biographers Jimmy Soni and Rob Goodman aim to bring Shannon to popular prominence through an engaging tome with 32 snappy chapters divided into three parts over 286 main pages. The story is presented chronologically, from Shannon’s childhood days to his battle with Alzheimer’s disease at the end, but this history is really just backdrop for painting a cognitive portrait of the man—the psychology and mental processes that shaped Shannon’s life and career. The book explores his external environment and his curiosity-driven motivations from numerous angles, but especially focuses on explaining his thought processes, his way of “doing the cognitive thing.” In this sense, the book can be read as a popular contribution to the cognitive history project of Reviel Netz, a historian of ancient Greek mathematics.\n\nThe authors note that “we expect our greatest minds to bear the greatest scars; we prefer our geniuses tortured … [Shannon] was, at once, abnormally brilliant and normally human.” Focusing the book on the details of Shannon’s playful thinking provides a skillful escape from this “tortured genius” cliché prevalent in similar biographies. Let me add that previous biographical treatments of Shannon—as embedded in larger historical narratives such as The Information by James Gleick, The Idea Factory by Jon Gertner, and The Cybernetics Moment by Ronald Kline (which are all excellent)—focus on Shannon’s technical results rather than the process by which he obtained them.\n\nShannon was quite introverted and stepped back from nearly every opportunity for fame or self-promotion. He was not a memoirist like his contemporaries, including the theorists Norbert Wiener and Richard Feynman (or even romantic partners like Shannon’s first wife, Norma Barzman, née Levor, and his subsequent girlfriend, Maria Mouton-Barrett). Moreover, he was rarely self-reflective in public. As such, Soni and Goodman largely construct their cognitive insights using interviews with colleagues and latter-day researchers, as well as from direct analyses of published papers and extant artifacts. The one exception is Chapter 25, “Constructive Dissatisfaction,” where they depart from the historical flow and use the transcript of an obscure talk Shannon gave on creative thinking. There, they write, “presuming that one was blessed with the right blend of talent, training, curiosity, irritation, and joy,” the authors recount Shannon describing how to “go about solving an actual mathematical or design problem,” providing six strategies. These general problem-solving strategies of simplification, ingenious incrementalism, restatement, structural analysis, inversion, and stretching are as useful to the modern reader as to Shannon’s audience at the time.\n\nThe book begins with young Claude Shannon in Gaylord, Michigan. A good student but not an extraordinary one, he played the alto horn and tinkered with electrical technologies such as barbed-wire telegraph systems and radio-controlled boats of his own construction. This initial chapter draws on new research in the archives of local newspapers. Shannon goes on to the University of Michigan where he joins the gymnastics team, gets his first taste of communication engineering (the most mathematical of the engineering sciences), submits problem solutions to a mathematical magazine, and earns simultaneous degrees in electrical engineering and mathematics (not too onerous given the curriculum overlap). The luckiest thing in his life, however, would be seeing a notice to work at the Massachusetts Institute of Technology (MIT) with Vannevar Bush, then the dean of the engineering school, on the differential analyzer, a large-scale analog computer—a mechanical brain.\n\nThe differential analyzer solved all kinds of differential equations, serving as the workhorse of numerous phenomenological engineering sciences such as thermodynamics and fluid dynamics. But it was difficult to reconfigure and impossible to program. As explained in the book, his exposure to this very practical engineering problem, together with his understanding of switching circuits from telephony and telegraphy and his knowledge of Boolean algebra from a philosophy class at Michigan, all came together in Shannon’s initial research. This yielded what is often called the best master’s thesis of all time and led to all of digital computing. The book details the connection among a practical engineering problem; physical implementation; and mathematical model, solution, or both; and this exposition of Shannon’s abstraction process provides insight into his research style and aesthetic that he would carry throughout his career. This elucidation of Shannon’s work is quite commendable since engineering systems theories, which capture the myriad possibilities of what can be imagined (and what cannot), in contrast to theories in physics that explain the world as it is, may be unfamiliar to many readers.\n\nThe remainder of Part 1 discusses Shannon’s doctoral work on an algebra for genetics at Cold Spring Harbor Laboratory and his wartime move to Bell Laboratories to work on cryptography and fire control, a method of improving the accuracy of weapons systems. This section also describes his failed first marriage, subsequent life in Greenwich Village, and meetings with the English mathematician Alan Turing. In my view, the work on fire control is given short shrift: it independently derived so-called Wiener filtering using a mathematical model much more conducive to circuit implementation and demonstrates Shannon’s key concern for engineering practice. As the authors note elsewhere, “it is a puzzle of his life that someone so skilled at abstracting his way past the tangible world was also so gifted at manipulating it.”\n\nAn underlying current through this first part is the role Vannevar Bush played in Shannon’s graduate training and future career. From his wartime perch atop the United States’ science system, the authors say, Bush “may not have groomed Shannon explicitly in his own image, but he understood that Shannon’s talents, properly harnessed, would serve him well outside of a university setting, the same way Bush’s talents had taken him to a position of national prominence.… Eventually Shannon would be transformed into an applied mathematician of the first rank.” Although Shannon did indeed achieve prominence, the book fails to emphasize that his approach was almost opposite to Bush’s. Whereas Bush was an applied mathematician who solved mathematical models formulated by others, Shannon was a creator of models: his genius lay in determining the core of a problem and removing details that could be reinserted later. In this way, he moved beyond Bush’s computational positivism. Although Shannon could have maneuvered his way to a high position in government, as Bush did, he always stepped back and went alone to where his curiosity took him. Moreover, Bush cast science and engineering as an endless frontier, but the central result of Shannon’s information theory was to establish fundamental limits to reliable communication, no matter how much ingenuity an engineer might bring to bear on the problem.\n\nPart 2 of the book focuses on information theory, the mathematical theory of communication that Shannon developed in the evenings over an eight-year period (1940 to 1948), when employed by Bell Labs. Reflecting on this time, Shannon “remembered the flashes of intuition. The work wasn’t linear, ideas came when they came.” Although Soni and Goodman suggest that most of the mathematical work was already done by the time Shannon drafted his landmark 1948 paper, “A Mathematical Theory of Communication,” archival evidence unearthed by the independent scholar S. W. Thomsen suggests that the main theorems had not been expressed in mathematical detail until just before publication.\n\nShannon’s paper, often called “the Magna Carta of the Information Age,” created the formal study of information in one fell swoop, delineating what is possible from what is impossible. It was received, the authors say, like a “bomb” not just within engineering but throughout numerous fields of study (e.g., the unmentioned Macy conferences on cybernetics, held between 1946 and 1953). Soni and Goodman lucidly explain the nature of abstracting what communication is, the basic ideas of redundancy and error-correcting codes, the nonconstructive proofs for the noisy channel coding theorem, and beyond, allowing the reader to really grasp what Shannon accomplished in fairly precise terms. This is no mean feat for a few small chapters: I teach these concepts in a graduate-level course on information theory over an entire semester. Notably, there is a chapter devoted to the work of the electronics pioneer Ralph Hartley, which influenced Shannon significantly. Whereas Hartley’s conception of information was through possibilities, Shannon’s conception of information was through probabilities—and this made all the difference.\n\nAround the time his seminal paper was published, Shannon met Betty Moore, an analyst at Bell Labs, and they soon created a musical and mathematical family. With his growing celebrity, he also acted to tamp down the (mis)application of his ideas to fields much beyond communications. Moreover, his interests began to move to artificial intelligence, developing the maze-solving artificial mouse Theseus, computers for playing chess, and approaches for predicting stock markets. In a missed opportunity for explaining this shift, the book fails to mention that Shannon believed “the most promising new developments in information theory will come from work on very complex machines, especially from research into artificial intelligence,” as noted in Jeremy Campbell’s Grammatical Man (1982).\n\nAs described in Part 3 of the book, upon leaving Bell Labs and moving back to MIT, Shannon spent much energy on pursuits such as customized unicycles, flame-throwing trumpets, wearable computers to beat roulette in Las Vegas, and robots that could juggle. Popular accounts of Shannon often focus on this physical tinkering; nary a profile of Shannon is complete without mentioning him juggling on a unicycle down the halls of Bell Labs or his toy room at Entropy House, the mansion outside Boston in which he and his family lived. These activities are usually dismissed as playful leisure activities, but Soni and Goodman’s cognitive portrait of a playful mind really shines new light in speaking against this traditional narrative. As they write, “what other people called hobbies, he thought of as experiments: exercises in the practice of simplification, models that filed a problem down to its barest interesting form.” Further on they argue that if you “wish away the dilettante who spent the bulk of his later life on chess, machines, and juggling … you’d also wish away the curious genius who invented information; it came, all of it, from the same place.”\n\nRecent research in artificial intelligence and autonomous systems have demonstrated the importance of Shannon’s chess playing and similar pursuits. I wonder if Shannon’s playful theorem on the fundamental limits of juggling is in fact a stepping stone to determine the limits of short-term memory, multitasking, and executive control in the brain. If so, I hope Shannon would be pleased that his ideas help enable a way to lessen a new informational problem: the problem of information overload. Claude Shannon was a giant of the twentieth century, as Soni and Goodman forcefully argue, and yet there has been no previous full-length biography. Notwithstanding my quibbles, this wonderful book rectifies the situation and demonstrates the societal impact of a generalist who can not only tinker but also reduce big problems to their essential abstract core. Notably, with their cognitive history approach focusing on Shannon’s playful mind, the authors have taken special care to explain the technical beauty of his work, which has seduced many a mathematically inclined engineer, myself included. Although describing the nature of abstraction is difficult, they have, I believe, succeeded in making both the man and his work accessible to a wide audience."
    }
}