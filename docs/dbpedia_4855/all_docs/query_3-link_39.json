{
    "id": "dbpedia_4855_3",
    "rank": 39,
    "data": {
        "url": "https://paperswithcode.com/author/tomas-hodan",
        "read_more_link": "",
        "language": "en",
        "title": "Papers With Code",
        "top_image": "https://paperswithcode.com/static/index.jpeg",
        "meta_img": "https://paperswithcode.com/static/index.jpeg",
        "images": [
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000553-467cdf5d_SvoYQZ2.jpg",
            "https://production-media.paperswithcode.com/tasks/default.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000001767-3c6c5a0d.jpg",
            "https://production-media.paperswithcode.com/tasks/default.gif",
            "https://production-media.paperswithcode.com/tasks/default.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/0d834282-fd21-4e57-be69-d5c2ed538690.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000002042-8135da6d.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/74caa0c7-6c6e-4d74-9e80-1af1b299c47e.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif",
            "https://production-media.paperswithcode.com/tasks/default.gif",
            "https://production-media.paperswithcode.com/tasks/default.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000780-3d4e01ee.jpg",
            "https://production-media.paperswithcode.com/tasks/default.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000363-06d10c79.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000001767-3c6c5a0d.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif",
            "https://production-media.paperswithcode.com/tasks/default.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000001767-3c6c5a0d.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000001767-3c6c5a0d.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif",
            "https://production-media.paperswithcode.com/tasks/default.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000001767-3c6c5a0d.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000001767-3c6c5a0d.jpg",
            "https://production-media.paperswithcode.com/thumbnails/task/task-0000000769-75ee95fc_C3z4Kbi.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Papers by Tomas Hodan with links to code and results.",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": "https://paperswithcode.com/search?q=author%3ATomas+Hodan",
        "text": "Introducing HOT3D: An Egocentric Dataset for 3D Hand and Object Tracking\n\nno code implementations • • Prithviraj Banerjee, Sindi Shkodrani, Pierre Moulon, Shreyas Hampali, Fan Zhang, Jade Fountain, Edward Miller, Selen Basol, Richard Newcombe, Robert Wang, Jakob Julian Engel, Tomas Hodan\n\nThe dataset offers over 833 minutes (more than 3. 7M images) of multi-view RGB/monochrome image streams showing 19 subjects interacting with 33 diverse rigid objects, multi-modal signals such as eye gaze or scene point clouds, as well as comprehensive ground truth annotations including 3D poses of objects, hands, and cameras, and 3D models of hands and objects.\n\nObject Tracking\n\nDiffH2O: Diffusion-Based Synthesis of Hand-Object Interactions from Textual Descriptions\n\nno code implementations • • Sammy Christen, Shreyas Hampali, Fadime Sener, Edoardo Remelli, Tomas Hodan, Eric Sauser, Shugao Ma, Bugra Tekin\n\nIn the grasping stage, the model only generates hand motions, whereas in the interaction phase both hand and object poses are synthesized.\n\nObject\n\nBOP Challenge 2023 on Detection, Segmentation and Pose Estimation of Seen and Unseen Rigid Objects\n\nno code implementations • • Tomas Hodan, Martin Sundermeyer, Yann Labbe, Van Nguyen Nguyen, Gu Wang, Eric Brachmann, Bertram Drost, Vincent Lepetit, Carsten Rother, Jiri Matas\n\nIn the new tasks, methods were required to learn new objects during a short onboarding stage (max 5 minutes, 1 GPU) from provided 3D object models.\n\n6D Pose Estimation using RGB\n\nFoundPose: Unseen Object Pose Estimation with Foundation Features\n\nno code implementations • • Evin Pınar Örnek, Yann Labbé, Bugra Tekin, Lingni Ma, Cem Keskin, Christian Forster, Tomas Hodan\n\nWe find that reliable correspondences can be established by kNN matching of patch descriptors from an intermediate DINOv2 layer.\n\n6D Pose Estimation Object +1\n\nAssemblyHands: Towards Egocentric Activity Understanding via 3D Hand Pose Estimation\n\nno code implementations • CVPR 2023 • Takehiko Ohkawa, Kun He, Fadime Sener, Tomas Hodan, Luan Tran, Cem Keskin\n\nTo obtain high-quality 3D hand pose annotations for the egocentric images, we develop an efficient pipeline, where we use an initial set of manual annotations to train a model to automatically annotate a much larger dataset.\n\n3D Hand Pose Estimation Action Classification\n\nBOP Challenge 2022 on Detection, Segmentation and Pose Estimation of Specific Rigid Objects\n\nno code implementations • • Martin Sundermeyer, Tomas Hodan, Yann Labbe, Gu Wang, Eric Brachmann, Bertram Drost, Carsten Rother, Jiri Matas\n\nIn 2022, we witnessed another significant improvement in the pose estimation accuracy -- the state of the art, which was 56. 9 AR$_C$ in 2019 (Vidal et al.) and 69. 8 AR$_C$ in 2020 (CosyPose), moved to new heights of 83. 7 AR$_C$ (GDRNPP).\n\n6D Pose Estimation using RGB object-detection +1\n\nIn-Hand 3D Object Scanning from an RGB Sequence\n\nno code implementations • CVPR 2023 • Shreyas Hampali, Tomas Hodan, Luan Tran, Lingni Ma, Cem Keskin, Vincent Lepetit\n\nAs direct optimization over all shape and pose parameters is prone to fail without coarse-level initialization, we propose an incremental approach that starts by splitting the sequence into carefully selected overlapping segments within which the optimization is likely to succeed.\n\nObject\n\nUmeTrack: Unified multi-view end-to-end hand tracking for VR\n\nno code implementations • • Shangchen Han, Po-Chen Wu, Yubo Zhang, Beibei Liu, Linguang Zhang, Zheng Wang, Weiguang Si, Peizhao Zhang, Yujun Cai, Tomas Hodan, Randi Cabezas, Luan Tran, Muzaffer Akbay, Tsz-Ho Yu, Cem Keskin, Robert Wang\n\nIn this paper, we present a unified end-to-end differentiable framework for multi-view, multi-frame hand tracking that directly predicts 3D hand pose in world space.\n\nNeural Correspondence Field for Object Pose Estimation\n\nno code implementations • • Lin Huang, Tomas Hodan, Lingni Ma, Linguang Zhang, Luan Tran, Christopher Twigg, Po-Chen Wu, Junsong Yuan, Cem Keskin, Robert Wang\n\nUnlike classical correspondence-based methods which predict 3D object coordinates at pixels of the input image, the proposed method predicts 3D object coordinates at 3D query points sampled in the camera frustum.\n\n3D Reconstruction Object +1\n\nPose Estimation of Specific Rigid Objects\n\nno code implementations • • Tomas Hodan\n\nSecond, we present HashMatch, an RGB-D method that slides a window over the input image and searches for a match against templates, which are pre-generated by rendering 3D object models in different orientations.\n\n6D Pose Estimation using RGB Autonomous Driving +1\n\nBOP Challenge 2020 on 6D Object Localization\n\n4 code implementations • • Tomas Hodan, Martin Sundermeyer, Bertram Drost, Yann Labbe, Eric Brachmann, Frank Michel, Carsten Rother, Jiri Matas\n\nThis paper presents the evaluation methodology, datasets, and results of the BOP Challenge 2020, the third in a series of public competitions organized with the goal to capture the status quo in the field of 6D object pose estimation from an RGB-D image.\n\n6D Pose Estimation 6D Pose Estimation using RGB +4\n\nLearning Surrogates via Deep Embedding\n\nno code implementations • ECCV 2020 • Yash Patel, Tomas Hodan, Jiri Matas\n\nThe effectiveness of the proposed technique is demonstrated in a post-tuning setup, where a trained model is tuned using the learned surrogate.\n\nScene Text Recognition\n\nEPOS: Estimating 6D Pose of Objects with Symmetries\n\n1 code implementation • CVPR 2020 • Tomas Hodan, Daniel Barath, Jiri Matas\n\nA data-dependent number of corresponding 3D locations is selected per pixel, and poses of possibly multiple object instances are estimated using a robust and efficient variant of the PnP-RANSAC algorithm.\n\n6D Pose Estimation 6D Pose Estimation using RGB +2"
    }
}