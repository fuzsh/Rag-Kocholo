{
    "id": "correct_subsidiary_00051_2",
    "rank": 71,
    "data": {
        "url": "https://embeddedcomputing.com/application/industrial/expert-panel-is-eda-as-easy-as-1-2-3-these-days",
        "read_more_link": "",
        "language": "en",
        "title": "EXPERT PANEL: Is EDA as easy as 1, 2, 3 these days?",
        "top_image": "https://data.embeddedcomputing.com/uploads/resize/1256/756/external/data.embeddedcomputing.com/uploads/articles/wp/345435891/ECD6070-figures-3",
        "meta_img": "https://data.embeddedcomputing.com/uploads/resize/1256/756/external/data.embeddedcomputing.com/uploads/articles/wp/345435891/ECD6070-figures-3",
        "images": [
            "https://embeddedcomputing.com/assets/img/ECDlogo_whiteREV2016@2x.png",
            "https://embeddedcomputing.com/assets/img/ECDlogo_whiteREV2016@2x.png",
            "https://data.embeddedcomputing.com/uploads/resize/1256/756/external/data.embeddedcomputing.com/uploads/articles/wp/345435891/ECD6070-figures-3",
            "https://embeddedcomputing.com/assets/img/authors/profile-image.jpg",
            "https://data.embeddedcomputing.com/uploads/resize/320/200/external/data.embeddedcomputing.com/uploads/articles/primary_images/1721665140.png",
            "https://data.embeddedcomputing.com/uploads/resize/320/200/external/data.embeddedcomputing.com/uploads/articles/primary_images/1721223487.png",
            "https://data.embeddedcomputing.com/uploads/resize/320/200/external/data.embeddedcomputing.com/uploads/articles/primary_images/1721401264.png",
            "https://data.embeddedcomputing.com/uploads/resize/320/200/external/data.embeddedcomputing.com/uploads/articles/primary_images/1721656947.jpeg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "OpenSystems Media"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "No doubt about it. Today&rsquo;s ever-shifting SoC, IC, PCB, and electronic systems design paradigm is burdened with challenges including: soaring dev...",
        "meta_lang": "en",
        "meta_favicon": "/ecd-favicon-safari-180x180.png",
        "meta_site_name": "Embedded Computing Design",
        "canonical_link": "https://embeddedcomputing.com/application/industrial/expert-panel-is-eda-as-easy-as-1-2-3-these-days",
        "text": "ECD: Remind us briefly about your organization, when started, what its technical focus is, and what it provides to which industries.\n\nBrett Cline, Forte Design Systems: Forte Design Systems helps designers improve their productivity and quality of results with SystemC high-level synthesis. We've been doing this since the early 2000s. In addition, Forte has a number of sophisticated Intellectual Property (IP) offerings anchored by its floating-point implementations. Forte's software is used by virtually every market segment doing digital design and its IP is primarily used by 3D graphics and GPU applications.\n\nMarc Serughetti, Synopsys: Synopsys, Inc. provides EDA products and services that accelerate innovation in the global electronics market. Our system-level, IP, implementation, verification, manufacturing, optical, and FPGA solutions help address the key challenges designers face such as power and yield management, system-to-silicon verification, and time-to-results. Founded in 1986, Synopsys expanded into the prototyping space with the acquisition of the COSSAP product in 1994 and focuses on enabling companies to accelerate both the development and deployment of virtual prototypes via next-gen virtual prototyping technology.\n\nWalden (Wally) Rhines, Mentor Graphics: Mentor Graphics provides electronic hardware and software design solutions for worldwide electronic, semiconductor, and systems companies. We offer a broad portfolio of best-in-class hardware and software design solutions focused on IC design and physical verification, functional verification, FPGA/PLD, design-for-test, PCB design, and embedded software.\n\nMichał Siwi´nski, Cadence: Cadence Design Systems, Inc. was formed in 1988 by the merger of ECAD and SDA Systems. Today Cadence is a major provider of EDA software, hardware, and IP for the design of ICs, PCBs, and electronic systems. Cadence provides end-to-end solutions for custom/analog design, digital IC design, silicon-package-board, and functional verification, as well as design and verification IP. Major vertical market segments served by Cadence include mobile, consumer, and communications, as well as automotive, medical, mil/aero, and industrial. Main horizontal market segments served are semiconductor companies and system companies.\n\nBill Neifert, Carbon Design Systems: Carbon Design Systems was founded in 2002. Our primary focus is to provide virtual prototypes that can be used throughout the design process, from IP selection and architectural exploration to O/S boot and software development. Instead of providing a range of different virtual prototypes to address the different speed and accuracy requirements through the design cycle, we provide a unified virtual prototype. It is capable of running at tens to hundreds of MIPS but also can run with 100 percent accuracy. Industry teams designing using virtual prototypes are focused primarily on developing leading-edge SoCs, especially in the mobile, consumer, and networking markets.\n\nECD: Which technology has been the most influential in forging the embedded industry's current EDA paradigm?\n\nCLINE: Most likely, virtual system prototyping, such as the tools supplied by Carbon Design Systems. High-level models used in products like Carbon's can be utilized in Forte's HLS flow.\n\nSERUGHETTI: Today's electronic systems – ranging from a System-on-Chip (SoC) to an electronic device/product – rely heavily on software executing on a chip. Software executing on a chip and prototyping are very closely linked to deliver to the end user the expected functionality and performance and today represent half the cost and half the time-to-market of an SoC design. They also have very important implications on the SoC development. Designers must get the architecture right, as no amount of downstream tools will compensate for a fundamentally wrong architecture.\n\nThus, prototyping has been the key to moving away from a standard project flow where architecture design, SoC hardware development, manufacturing, and software development, hardware/software integration, and system validation are done serially to a development process; this enables the parallelization of SoC hardware development with software development integration and system validation. Prototyping includes virtual and FPGA-based prototyping with the objectives of architecture design, early software development, hardware/software integration, and system validation.\n\nRHINES: Codesign and verification of embedded software with hardware has been the most important technology advancement for embedded development in EDA. Issues almost always occur in the \"system integration\" phase, when the hardware and software are finally tested together, causing major program delays, functional problems, cost overruns, and unhappy customers.\n\nOur company first tried addressing the system integration problem in 1995, when we rolled out our corporate \"integrated system design\" strategy. The goal was to compress the time and effort required to do system integration by having both the hardware and software work in the same integrated environment. What we failed to appreciate was the enormous gulf between the hardware and software engineers, who work in their native environments with different toolsets. To bridge this gap, we recently announced the Mentor Embedded Virtual Platform, suitable for both hardware and software teams.\n\nSIWI´NSKI: EDA enables the development of ICs with billions of transistors at advanced semiconductor process nodes, making it possible to build today's smartphones, tablets, servers, and other electronic products. One influential technology that made all this possible was the move from gate-level design to Register Transfer Level (RTL) design in the 1990s. RTL design is a much higher level of abstraction, and it permits design using specialized programming languages (Hardware Description Languages or HDLs) such as IEEE standard Verilog as opposed to wiring gates together. Tools that enable RTL design include logic synthesis and RTL verification.\n\nToday the abstraction level is moving even higher to Transaction Level Modeling (TLM) using the IEEE standard SystemC programming language. This is made possible by such technologies as high-level synthesis, which can automatically convert SystemC into RTL, and virtual prototyping, which allows early software development using SystemC models. While EDA has historically focused on IC and System-on-Chip (SoC) development and verification, a new paradigm is emerging in which EDA tools are facilitating hardware/software codevelopment and coverification, due to the dominant role that software is starting to play in today's electronics. As a result, the gap between traditional EDA and embedded software development is closing.\n\nNEIFERT: The embedded technology requirement driving EDA approaches now is more a realignment of design from being a hardware-focused task to being a more software-focused one. While there are fewer and fewer hardware starts, the number of software engineers continues to grow rapidly. Traditional EDA companies continue to make most of their revenue selling back-end implementation tools for the design cycle, which continues to grow in complexity. They are making attempts to develop a pricing model to sell tools to the large group of embedded software designers. Most EDA advances seem confined to back-end implements processes, far removed from the daily needs of most embedded designers, though necessary to enable many advanced designs. However, from the front-end design and software perspective where Carbon focuses, three hot trends are emerging:\n\n1. The restructuring of EDA toward the design IP space: Synopsys is already [a major] IP company … The string of recent purchases by Cadence demonstrates that this is an important part of its strategy as well.\n\n2. The consolidation of IP offerings as packaged subsystems: As designs get bigger, blocks being purchased and reused are moving from single design blocks to entire compute subsystems, complete with software, changing the rules on what companies need to do to differentiate their end products.\n\n3. The strong push to introduce accuracy into virtual prototypes: As emulation becomes ubiquitous, there is a strong push to integrate it with virtual prototypes as a way to introduce the accuracy needed throughout the design cycle.\n\nECD: What are the three hottest EDA technology trends right now?\n\nCLINE: Electronic System Level (ESL) continues to be one of the hottest areas in EDA. Of course, high-level synthesis is only one aspect of ESL. Others, including virtual system prototyping, design modeling, and verification are also in the forefront.\n\nIP reuse has been a trend for two decades. We are now seeing IP developed at a higher level of abstraction, making it much more usable. While Register Transfer Level (RTL) IP reuse has sustained momentum longer than most people thought it would, behavioral IP is starting to gain traction with several startups in this area appearing over the past year or two.\n\nThird, but certainly not last, is anything that has to do with low power. Everyone wants power to be lower, end of story. As it turns out, the earlier that power is considered in the design process, the more control designers have over the power. ESL happens to help with that as well.\n\nSERUGHETTI: The hottest EDA technology trends, specific to embedded systems, relate to virtual prototyping. Among them are earlier and more robust architectural exploration and analysis. There are more functions, more software, and more resource sharing in systems that are dynamic. As a result, it makes performance hard to predict and the hot questions from architects become: \"Will my SoC architecture meet the performance requirements … for the required combinations of application use cases? … without overdesign? This architectural exploration/analysis needs to be done before software is available, via industry tools that enable earlier analysis while avoiding both under- and over-design.\n\nAnother hot trend is early software development. From a software development perspective, the integration of increasingly complex hardware and software is a significant challenge for semiconductor and OEM companies developing next-generation wireless, consumer, and automotive devices. Traditional methods of serialized hardware and software development – where the vast majority of software is developed and verified after the silicon design is complete – often fail to meet aggressive product development schedules. Virtual prototyping enables software engineers to start development months before the hardware design is complete, enabling full system bring-up to occur within days of silicon availability.\n\nRHINES: 1) For EDA's core hardware design market, the semiconductor industry must continue to deliver increased functionality per dollar with lower power, as it has done so reliably over the past half century. However, shrinking feature dimensions can no longer shoulder the entire burden, because of the rising costs associated with reliably manufacturing 28 nm devices and below. Semiconductor manufacturers are now deploying new approaches to achieve the same results: multi-die packaging, 3D stacks, interposers, etc., which will become increasingly important and require a wide range of newer EDA solutions, many already available.\n\n2) More exciting for EDA going forward is the growth of embedded software development. Software design now consumes more than half the effort required to create an SoC or system. And the rapid growth of hardware acceleration products (close to 100 percent per year the past two years) has created a verification platform for hardware and software that is replacing simulation for the leading-edge chip and system development programs.\n\n3) There is promise of growth of EDA applications in system design beyond PCB layout and Electronic System Level (ESL), although both are expanding again in response to new challenges. The opportunity lies in addressing the enormous challenge of designing and verifying complex electronics for macro systems such as automobiles, aerospace, commercial vehicles, and other equipment. EDA for automotive and aerospace applications is growing faster than the market for IC design software.\n\nSIWI´NSKI: One clear trend is the move to a higher level of abstraction, sometimes called Electronic System Level (ESL). Hardware/software codevelopment is made possible by such tools as virtual prototyping, simulation, acceleration and emulation, and FPGA-based prototyping. An integrated set of development platforms, such as the Cadence System Development Suite, for example, can serve these needs, enabling early software design ahead of the accurate hardware representation or with mixed abstractions, hardware-software integration, and system validation of the hardware running hardware-dependent software.\n\nAnother trend is support for semiconductor process nodes at 20 nm and below. Here, lithography is so difficult that a technology called \"double patterning,\" which requires extra mask layers, is required. This is resulting in many changes to IC implementation tools. Additionally, a new transistor technology – the FinFET – will be supported by most foundries at 16 nm or 14 nm. While FinFETs promise huge power and performance advantages, IC design tools must adapt to support them.\n\nA third new trend that's received a lot of notice is the emergence of 3D-ICs. This may involve multiple chips laid side-by-side on a silicon interposer layer (called \"2.5D\" IC), or true 3D stacking in which chips are placed on top of each other and connected with Through-Silicon Vias (TSVs).\n\nECD: What are the biggest EDA engineering hurdles these days – faced by your organization and also by your customers? How are these challenges being solved?\n\nCLINE: The \"system\" continues to become more complex. Integrating IP from multiple vendors, custom accelerators designed in-house, embedded software, and more is an extremely difficult task. Creating an implementation model that ties closely to embedded software and provides significant time-to-market advantages allows design teams to get more done with fewer resources.\n\nSERUGHETTI: SoC architects face big challenges as their chips move to finer-grain silicon geometries and the costs of system architecture inefficiencies become prohibitive. A good starting point to address these challenges is to use early architecture simulation to better understand and optimize multicore hardware-software partitioning and its relationship to performance, power, and cost of the SoC. This is more than optimizing the number of processors; it is optimizing how the software is mapped or assigned to each core. Another technique used during early architecture simulation and exploration is sensitivity analysis. This enables the architect to look at many factors to understand how performance and power metrics are sensitive to changes in various system parameters.\n\nFor virtual prototyping to enable these techniques, a complete solution needs to be available to users and must support the creation of virtual prototypes and their use by software developers. This creation requires model libraries for different IP used in an SoC (examples: ARM processor models, DesignWare IP models), tools to create customer-specific IP models, and tools to assemble and debug the virtual prototype model. Once created, the virtual prototype must be provided as a VDK to the end user who will use it as an embedded target. It must include integration with software debuggers, access to advance scripting, debug and analysis capabilities unique to a virtual prototype, and depending on the application, interface to the environment in which the SoC will reside (for example, the ability to connect to a physical Internet network, ability to cosimulate with analog or mechanical simulation tools).\n\nRHINES: The single biggest challenge is the rising cost of system development – whether it is for a complex SoC module or the electronics for a new car. Hardware and software subsystem complexity has not only increased recently, but also the interactions and dependencies between hardware and software subsystems create bottlenecks in the release process. Ideally, the embedded software development for an SoC or system would be completed ahead of the actual hardware. But that requires a virtual representation of the hardware that can run sufficiently fast and be robust enough for developers to thoroughly verify their code.\n\nAlthough software development and hardware development are deeply intertwined, they are intensely unique disciplines and development tools must focus on a specific domain while providing insight into the other. Forcing software engineers to adopt hardware tools is a nonstarter as it not only forces an unfamiliar and inefficient experience on developers but also doesn't provide insight into software concerns at the firmware, operating system, and application software level. Emerging to address this is a cohesive embedded software development environment that is the same, whether the target is a simulation, emulation, prototype, or final product. This environment embeds the most advanced pre-prototype technology available from the hardware design tool flow deeply into the native software environment, resulting in a significant time-to-market advantage for software development. Now software developer teams can remain in their core development environment and develop, debug, and optimize their complete software stack on virtual prototypes and emulation platforms, before and after first prototype.\n\nSIWI´NSKI: The move to 16 nm/14 nm FinFETs demands major changes in tools such as parasitic (resistance/capacitance) extraction, as well as new foundry design rules. Cadence is making a major R&D investment to adapt its IC physical implementation tools to FinFET technology, and has successfully participated in several FinFET test chip efforts. Work is ongoing in both custom/analog design and digital design to ease FinFET implementation.\n\nFurther, today's large SoCs are not designed from scratch; they use semiconductor IP sourced from other design groups or outside providers. Accordingly, Cadence provides silicon-proven design IP and verification IP.\n\nThe growing role of software, with software teams now becoming larger than hardware teams in both system and semiconductor companies, is also driving an evolution of needs. In particular, the ability to continue to provide offerings to feed the \"shift-left\" notion of early software development, hardware-software integration, and system validation continues to be a big and growing focus.\n\nPulling it all together into overall end-product creation is another big challenge, requiring broad front-to-back solutions and ecosystem collaboration to address the needs of both semiconductor and system companies across the plethora of vertical markets with their distinct needs.\n\nNEIFERT: The biggest problem I see is how to differentiate products in an environment where more and more of the IP is coming from commercial sources. This means that there are typically fewer areas in which to differentiate, at least using traditional hardware approaches.\n\nCompanies are solving this by differentiating using varied approaches. They are doing so by configuring their IP uniquely so that various pieces of IP play together in an optimal fashion. This is accomplished using a virtual prototype to sweep through the matrix of configuration settings for various pieces of IP while running the real system software to find which combination yields the optimal result.\n\nThey're also optimizing the system power while running Register Transfer Level (RTL) code by instrumenting their virtual prototype using real system software to identify hot spots in the design. Finally, they're differentiating by getting software up and running early on a virtual prototype and using that to achieve a time-to-market advantage.\n\nECD: Which technologies or standards are needed in EDA now but not yet available?\n\nCLINE: It's difficult to say. Design flows continue to evolve and project teams want access to the best-in-class technologies. To implement these sophisticated methodologies, standards must continue to evolve with the flows. IEEE 1666-2011 is a great example of a standard that has continued to evolve with the ESL design flow. The SystemC organizations continue to enhance the standard to move quickly with the ESL design flows being used today. (The latest IEEE 1666 information can be found at http://standards.ieee.org/findstds/standard/1666-2011.html.)\n\nSERUGHETTI: Fortunately for designers in the embedded space, there are enough standards to support existing use models such as virtual prototyping; a number of system IP blocks and verification IP blocks are interacting with a combination of simulator, emulator, and virtual prototypes through SystemC (IEEE 1666) and TLM standards. The industry is working on IP-XACT (IEEE 1685), UPF (IEEE 1801), IP Encryption (IEEE 1785), and SystemRDL (Accellera) to name a few. Most of these standards are in their second or third incarnation, going through evolutionary enhancements as recommended by real users who are identifying the shortcomings.\n\nRHINES: One area ripe for standards is the automotive electronics market. More than 35-40 percent of the cost of a premium-class car today is software and electronics. Many of these embedded systems support safety-critical features such as automatic braking systems or airbag deployment. There is also significant development around in-vehicle infotainment systems that entertain and inform passengers.\n\nIn the past few years, the emergence of the AUTOSAR and GENIVI standards has provided a basic infrastructure for developing vehicle software within the automotive market. What is needed is a complete software design environment that unifies standards-based development between the real-time deterministic and safety-oriented systems with a richer infotainment and telematics system. With such an environment, embedded designers could support multiple operating systems on a single processor, or migrate applications from single core to multiple cores, and make use of hybrid or heterogeneous architecture SoCs. This will reduce overall development and Bill-of-Material (BOM) costs, while enabling development of customized, feature-rich automotive applications.\n\nSIWI´NSKI: With the evolving demands placed on system and semi companies, there is a need to enable faster and better end-product creation. This means that EDA will continue to evolve beyond its classical IC automation roots toward a greater focus on system needs. In turn, that will result in more collaboration across software, electrical, and mechanical domains, which will also fuel growth in standards to enable development of complex systems across many domains.\n\nNEIFERT: A real standard for Transaction Level Modeling (TLM) interchange and configuration is needed to enable higher-level system exploration and development. TLM-2.0 lays the framework for some of this, but there is no guarantee that the AMBA TLM IP model created by one vendor will work with the AMBA TLM IP model created by another vendor. Additionally, it's not clear how well they'll integrate with the virtual prototype tool tying it all together. Finally, once all models are talking to each other at a functional level, they still have different interfaces for control, configuration, and inspection.\n\nECD: How can future EDA innovation best be fostered?\n\nCLINE: Innovation in EDA comes from small companies. Large systems and semiconductor companies are best served by making sure these small, innovative companies thrive and continue to challenge conventional wisdom.\n\nSERUGHETTI: Gaining and sharing experience constitute the best approach to foster innovation while ensuring that there is a viable industry on both the user and vendor side. Collaborative and open engagements are key, which are fostered by establishing one-to-one relationships between users and vendors as well as by participating in industry events, user forums, and technical communities such as OSCI and the Embedded Vision Alliance to promote an exchange of ideas and solutions.\n\nRHINES: How can future EDA innovation best be fostered?\n\nIt is important to examine historic trends when predicting the future. Over the past decade, nearly all growth in EDA came from new design methodologies in response to emerging design challenges. The largest growth was in Design For Manufacturing (DFM) with 28 percent compounded annual growth, followed by formal verification, ESL, and IC/ASIC analysis (principally power estimation). In contrast, the rest of traditional EDA – including custom IC, ASIC, and PCB design – grew only 1 percent compounded over the entire decade.\n\nWith history as our guide, there is no doubt that the EDA industry should focus on solving new problems and finding new users for EDA technology, while continuing to invest heavily in maintaining and upgrading traditional design methodologies.\n\nSIWI´NSKI: Traditionally a lot of EDA innovation has come from startups. In recent years there have been fewer startups, due to a lack of venture capital funding and a more difficult environment for IPOs. This, in turn, has rekindled in-house incubator and innovation investments in the EDA companies to make sure that daunting customer challenges can continue to be addressed.\n\nThe starting point, as always, has to be the market and the customers, posing new challenges. The good news is that we live at a time when electronics are evolving at an unprecedented rate, providing a very good driver for EDA innovation indeed.\n\nNEIFERT: The best innovations are driven by close partnerships between EDA companies and their industry partners. This way, real-world designs are used to drive the innovation that can be rolled out to the broader market. Carbon has been using this type of partnership with Samsung to drive virtual prototyping innovations.\n\nBrett Cline is VP of Marketing and Sales for Forte Design Systems. Previously, he was Director of Marketing at Summit Design and held positions in development, applications, and technical marketing at Cadence and General Electric. He holds a Bachelor of Science degree in Electrical Engineering from Northeastern University.\n\nMarc Serughetti is Director of Business Development at Synopsys, where he drives deployment of virtual prototypes and embedded software technologies. He has more than 18 years’ experience in software development technologies, having led product marketing and business development teams at Integrated Systems, Wind River, and CoWare.\n\nWalden (Wally) Rhines is Chairman and Chief Executive Officer of Mentor Graphics. Prior to joining Mentor Graphics, he was Executive Vice President of Texas Instruments’ Semiconductor Group, sharing responsibility for TI’s Components Sector and having direct responsibility for the entire semiconductor business comprising more than 30,000 people.\n\nMichał Siwi´nski is the Senior Director of Product Marketing for System and Software Realization Group (SSG) at Cadence, responsible for strategy, products, partnerships, business development, and communications. He focuses on the realization of the EDA360 vision by concentrating on emerging and established offerings used by system and semiconductor companies.\n\nBill Neifert, CTO and Cofounder of Carbon, has 13 years of electronics engineering experience and more than 18 years in EDA including C-level design and quickturn systems. Bill has designed high-performance verification and system integration solutions and developed an architecture and coding style for high-performance RTL simulation in C/C++. He has Bachelor of Science and Master of Science degrees in Computer Engineering from Boston University."
    }
}