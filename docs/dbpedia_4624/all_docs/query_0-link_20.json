{
    "id": "dbpedia_4624_0",
    "rank": 20,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/",
        "read_more_link": "",
        "language": "en",
        "title": "Scene-Based Contextual Cueing in Pigeons",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-nihpa.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f1.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f2.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f3.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f4.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f5.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f6.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f7.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f8.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f9.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/bin/nihms601200f10.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Edward A. Wasserman",
            "Yuejia Teng",
            "Daniel I. Brooks"
        ],
        "publish_date": "2014-10-28T00:00:00",
        "summary": "",
        "meta_description": "Repeated pairings of a particular visual context with a specific location of a target stimulus facilitate target search in humans. We explored an animal model of such contextual cueing. Pigeons had to peck a target which could appear in one of four locations ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4280084/",
        "text": "The environment is replete with visual information. At any given time, people must attend to relevant stimuli and ignore irrelevant stimuli in order to engage in adaptive behavior. For example, to safely cross the street, we attend to the color of the traffic lights as well as to the motion of nearby cars and pedestrians, while we simultaneously ignore the buildings and trees along the roadway.\n\nSalient visual objects can unconditionally command our attention (Awh, Belopolsky, & Theeuwes, 2012). Yet, such “bottom-up” control may not tell the full story of how we navigate the complex visual contexts that we confront in everyday life; experience-dependent “top-down” control may also play a key part in behavioral adaptation (Chun, 2000). For instance, should we be looking for a pharmacy in France, we would do well to peer above the doorways where a green cross is most likely to be displayed; but, should we be seeking a street sign, we would best be advised to gaze toward corner buildings where road placards are most likely to be affixed.\n\nThe significance of context to visual object identification has long been appreciated (e.g., Biederman, 1972). Still more recent research by Chun and Jiang (1998) initiated a new chapter on the importance of contextual stimuli to adaptive visual behavior. These investigators discovered that the spatial configuration of objects in a visual scene can serve as a powerful contextual cue, facilitating an individual's search for a target item.\n\nSpecifically, Chun and Jiang found that, when the specific location of a target was consistently associated with a particular spatial arrangement of distractor items in the display, reaction times (RTs) to identify the target became reliably shorter than when the target appeared in newly generated spatial arrangements of the same distractor items. Chun and Jiang called this RT benefit the contextual cueing effect and proposed that contextual cueing is due to attention being guided toward the location of the target, owing to learned associations between the context and the location of the target.\n\nSubsequent research has sought to elucidate the perceptual and cognitive mechanisms underlying contextual cueing in humans. Possible animal models of contextual cueing have only recently been developed (for pigeons: Brooks, Rasmussen, Hollingworth, & Wasserman, 2008; for rhesus monkeys: Brooks, Dai, & Sheinberg, 2011), with the recent paper by Goujon and Fagot (2013: for baboons) being the first published demonstration. Here, we report the results of a new pigeon analog of the human contextual cueing task in the hope of shedding fresh light on the comparative and associative mechanisms underlying contextual cueing.\n\nChun (2000) offered two compelling justifications for the comparative study of contextual cueing. First, most research in visual processing gives little consideration to the history of the observer; being endowed with the capacity to see also requires that organisms learn to interpret their visual world based on their experience in it. Second, more needs to be understood concerning the neural mechanisms and evolutionary origins of attentional guidance. For these reasons, animal models are critical for controlling and isolating the role of learning in contextual cueing as well as for elucidating its physiological and phylogenetic foundations (Lazareva, Shimizu, & Wasserman, 2012).\n\nA critical feature of our present project was that it used photographs of real scenes as experimental contexts. Although contextual cueing has been demonstrated in humans using both naturalistic scenes and arrays of abstract distractors (e.g., Brockmole & Henderson, 2006a; Brockmole & Henderson, 2006b; Rosenbaum & Jiang, 2013), experiments have consistently shown that lifelike scene-target associations are learned faster and more strongly contribute to search time benefits than do distractor array-target associations. Thus, we used color photographs of real-world scenes in order to maximize the effect of contextual cueing on pigeons' visually guided behavior.\n\nWe also investigated the time between context and target presentation (Stimulus Onset Asynchrony, SOA) from 0 s to 8 s to see if different SOAs differentially affect contextual cueing. In most human studies of contextual cueing, the context and target are simultaneously presented. Only a few studies have programmed a nonzero SOA between context and target presentation, ranging from 250 ms to 1,500 ms (Geyer, Zehetleitner, & Müller, 2010; Goujon, 2011; Jiang, Sigstad, & Swallow, 2013; Kunar, Flusberg, & Wolfe, 2006, 2008; Ogawa & Kumada, 2008; Peterson, & Kramer, 2001). Even fewer studies have parametrically investigated the effect of the SOA on contextual cueing. Kunar et al. (2006) found a slight weakening of contextual cueing with increasing SOAs and Kunar et al. (2008) observed a more robust SOA effect when placeholders demarcated the possible target locations. More recently, Jiang et al. (2012) reported that contextual cueing was similar across SOAs from 0 ms to 1,000 ms.\n\nThis manipulation of SOA also afforded us the ability to explore the possible role of attentional guidance by closely monitoring the pigeons' behavior during the 1 s to 8 s prior to the presentation of the target. Here, we leveraged the fact that pigeons will make unsolicited anticipatory reports in the location of impending stimuli that predict reward (Brooks, 2010), which can be used as an on-line measure of attentional guidance similar to the use of eye and hand movements in human subjects (see Peterson & Kramer, 2001; Spivey 2008).\n\nIn overview, the present project used photographs of real-world scenes to explore contextual cueing and its possible mechanisms in pigeons. In Experiments 1 and 2, we gave the same experimental procedures to two different sets of birds in different orders. On half of the daily trials, each of four scenes perfectly predicted the target's location (Predictive condition); on the other half of the trials, none of four other scenes predicted the target's location, with the target randomly appearing in one of the same four possible locations (Random condition). Evidence of contextual cueing would come from shorter RTs in the Predictive condition than in the Random condition. Furthermore, we manipulated the temporal delay between presentations of the contextual stimuli and the target stimuli to see what effect this delay would have on contextual cueing. We also monitored pecking during the delay to see if such anticipatory responding provided any clues as to the associative nature of contextual cueing.\n\nFinally, in Experiment 3, we vertically and horizontally reversed the Predictive photographic scenes to see whether the global scene contexts and/or the local cues in the immediate vicinity of the upcoming target exerted greater control over pigeons' visually directed responding. Assessing the contributions of global and local cues has been a topic of considerable interest to researchers studying animal spatial cognition (Brown & Cook, 2006).\n\nResults and Discussion\n\nFirst, we analyzed RTs to the target stimulus on all Training and Testing trials to confirm that the Predictive and Random Training contexts again differed from one another as well as that the Training and Testing contexts differed from one another. These RTs ( ) were submitted to a repeated-measures ANOVA with condition (Predictive vs. Random vs. Horizontal Global vs. Horizontal Local vs. Vertical Global vs. Vertical Local) and day (1 to 16) as within-subjects factors. The significant main effect of day, F(15, 105) = 2.21, p < .01, ηp2=.24, 95% CIs = .02, .27, indicated that RTs decreased over sessions, perhaps because of the pigeons' increasing familiarity with the reversed backgrounds. The main effect of condition was also significant, F(5, 35) = 106.46, p < .001, ηp2=.94, 95% CIs = .88, .95. The Predictive condition (M = 693 ms, SE = 18.43) supported significantly briefer RTs than the Random condition (M = 1,140 ms, SE = 24.59) and all four Testing conditions. Because the Predictive condition supported faster RTs than all four Testing conditions, it appears that global and local cues each controlled pigeons' visual search behavior as both were changed in our experimental design; subsequent analyses more precisely examined the respective contributions of these cues. The Random condition also supported significantly longer RTs than the Horizontal Global condition and significantly shorter RTs than the Horizontal Local condition, but it did not support significantly different RTs from the Vertical Global or Vertical Local conditions. Thus, our manipulation of local and global scene cues, as in the Horizontal Local condition, was strong enough to yield RTs with predictive scene backgrounds that were even slower than with random scene backgrounds. The Condition × Day interaction was also significant, F(75, 525) = 2.37, p < .001, ηp2=.25, 95% CIs = .09, .15. Nevertheless, in both the first and second half of the experiment, the pigeons' pattern of responding in all six conditions remained the same; the RT disparities among the four Testing conditions became slightly smaller, with RTs in the Predictive and Random conditions remaining unchanged.\n\nSecond, we focused our main RT analyses on the Testing trials alone, in order to factorially assess how global vs. local cues affected RTs to horizontally vs. vertically reversed contexts. These RTs were submitted to a repeated-measures ANOVA with reversal type (horizontal vs. vertical reversal), cueing type (global vs. local cue), and day (1 to 16) as within-subjects factors. A significant main effect of day, F(15, 105) = 2.31, p < .01, ηp2=.25, 95% CIs = .02, .28, again indicated that RTs decreased over sessions. The main effect of cueing type was also significant, F(1, 7) = 32.84, p < .001, ηp2=.82, 95% CIs = .30, .90, with Global Cue contexts (M = 1,065 ms, SE = 26.16) supporting shorter RTs than Local Cue contexts (M = 1,524 ms, SE = 38.07). The Cueing Type × Day interaction was significant, F(15, 105) = 5.21, p < .001, ηp2=.43, 95% CIs = .20, .47, with the RT disparities among the four testing conditions becoming slightly smaller from the first to the second half of the experiment.\n\nIn both the Horizontal and Vertical Reversal conditions, RTs were faster in the Global than in the Local Cue conditions ( ). However, the interaction between cueing type and reversal type was significant, F(1, 7) = 27.13, p < .001, ηp2=.79, 95% CIs = .24, .89, indicating a greater global-local disparity for Horizontal than for Vertical reversals.\n\nTukey post hoc analyses indicated that the Horizontal Global condition (M = 953 ms, SE = 31.66) supported significantly shorter RTs than the other three conditions ( ), p < .05; in addition, RTs in the Vertical Global condition (M = 1,179 ms, SE = 39.31) were significantly shorter than those in the two Local conditions, p < .05; RTs in the Horizontal Local condition (M = 1,609 ms, SE = 56.83) and in the Vertical Local condition (M = 1,441 ms, SE = 49.79) did not differ significantly. The Cueing Type × Reversal Type × Day interaction was also significant, F(15, 105) = 1.80, p < .05, ηp2=.20, 95% CIs = .00, .23. In both the first and second half of the experiment, the RT pattern captured by the Cueing Type × Reversal Type interaction remained the same, with the disparities among the four conditions becoming slightly smaller in the second half. No other main effect or interaction was significant.\n\nHow can these reliable differences best be understood? The Horizontal Global trials and the Horizontal Local trials displayed the same visual scene; in the former case the target appeared in the correct absolute position on the screen but in the incorrect position relative to the local scene cues, whereas in the latter condition the target appeared in the correct position relative to the local scene cues but in the incorrect absolute position on the screen. The faster RTs on Horizontal Global trials than on Horizontal Local trials clearly document stronger global than local cue control. The same trend was obtained on Vertical Global and Vertical Local trials, but with the disparity between the vertical reversal conditions being smaller than between the horizontal reversal conditions. The smaller disparity in the vertical reversal conditions suggests that horizontal reversals better supported the recognition of visual scenes than did vertical reversals. Categorization studies using naturalistic stimuli with intact backgrounds have also found that horizontal and vertical reversals of the same images differentially affected pigeons' discriminative performance. When category-trained birds were later tested with reversed stimuli, their accuracy dropped significantly when the images were vertically reversed; however, no drop in accuracy was observed when the training stimuli were horizontally reversed (Wasserman, Kiedinger, & Bhatt, 1988, Experiment 3).\n\nFinally, consider the Horizontal Local and Vertical Global contexts. In the former case, when overall performance indicated that the scene was less disruptively reversed, the target appeared in the correct position relative to local scene cues, but it was put into the incorrect absolute position on the screen; in the latter case, when overall performance indicated that the scene was more disruptively reversed, the target appeared in the incorrect position relative to local scene cues, but it was put into the correct absolute position on the screen. Nevertheless, the Vertical Global contexts supported faster RTs than the Horizontal Local contexts. This disparity again documents stronger global than local cue control.\n\nWe then analyzed our pigeons' anticipatory responses during the SOA to see how the Training and Testing scenes may have guided the birds' attention and facilitated their target search. For anticipatory responses on Training trials, our analyses replicated the results in Experiments 1a and 2c. The rate of anticipatory responding was submitted to a repeated-measures ANOVA with condition (Predictive vs. Random) and day (1 to 16) as within-subjects factors. The main effect of condition was marginally significant, F(1, 7) = 5.14, p = .06, ηp2=.42, 95% CIs = .00, .69, with the Predictive contexts again supporting generally higher rates of anticipatory responding (M = 0.88 pecks per s, SE = 0.05) than the Random contexts (M = 0.46 pecks per s, SE = 0.06). The main effect of day was significant, F(15,105) = 2.28, p < .01, ηp2=.25, 95% CIs = .02, .28, indicating an increasing rate of anticipatory responding as training progressed. The interaction between condition and days was not significant, F < 1.\n\nWe also examined the location of anticipatory pecks to the Predictive contexts on Training trials. The corrected rate of anticipatory responding was submitted to a repeated-measures ANOVA with response type (correct vs. incorrect anticipatory response) and day (1 to 16) as within-subjects factors. The main effect of response type was significant, F(1, 7) = 33.51, p < .001, ηp2=.53, 95% CIs = .31, .91, with the rate of correct anticipatory responding (M = 1.16 pecks per s, SE = 0.08) exceeding the rate of incorrect anticipatory responding (M = 0.08 pecks per s, SE = 0.02). Also significant were the main effect of day, F(15, 105) = 2.14, p < .05, ηp2=.23, 95% CIs = .01, .27, and the interaction between response type and day, F(15, 105) = 1.91, p < .05, ηp2=.21, 95% CIs = .00, .24; from the first half to the second half of the experiment, the Correct-Incorrect disparity in pecking became smaller.\n\nTo determine how global or local cues may have directed the pigeons' attention and responding, we analyzed the rate of anticipatory pecking to the contexts on Testing trials. For this analysis, we divided the entire scene area into four equal-sized quadrants. We denoted the quadrants as follows: Global Cue (GC), Local Cue (LC), Possible Location (PO), and Impossible Location (IM) ( ). The Global Cue location refers to the quadrant to which the pigeons should have directed their pecks based on the entire composition of the scene, despite the fact that the scene was now reversed either horizontally or vertically; this quadrant continued to contain the target on Predictive Training trials. The Local Cue location refers to the quadrant to which the pigeons should have directed their pecks based on the cues that were closest to the target on Predictive Training trials, despite the fact that those local cues were now either horizontally or vertically reversed. The Possible Location and the Impossible Location refer to the pair of quadrants to which the pigeons should never direct their pecks because these regions never contained the target stimulus on Predictive training trials. We counted pecking in those quadrants as a control for pigeons' indiscriminate pecking. We separated these quadrants into those that, in our factorial design, could contain the target on Testing trials (Possible Location) and those that could not (Impossible Location); in neither case, did we expect the pigeons to peck very much.\n\nRecall that our RT analyses clearly indicated that global cues exerted stronger control over pigeons' RTs than local cues. Thus, we expected more anticipatory pecks to be made to the GC locations than to the LC locations. Additionally, because the RT disparity between the global and local conditions was greater in the horizontal reversal conditions than in the vertical reversal conditions, we expected the disparity between anticipatory pecks to the GC locations and those to the LC locations to be greater in the horizontal reversal conditions than in the vertical reversal conditions. Because anticipatory responses were made prior to the presentations of the target, the Global Cue vs. Local Cue conditions arranged in the experiment were irrelevant to the present analysis; we only examined in which of the four types of quadrants greater anticipatory responding occurred to the Horizontally vs. Vertically reversed contexts.\n\nThe rate of anticipatory responding was analyzed using a repeated-measures ANOVA with day (1 to 16), reversal type (horizontal vs. vertical reversal), and response type (global cue vs. local cue vs. possible location vs. impossible location) as within-subjects factors. The main effect of response type was significant, F(3, 21) = 184.84, p < .001, ηp2=.96, 95% CIs = .91, .97, indicating that different parts of the Testing scenes differentially controlled anticipatory responding. Tukey post hoc analyses indicated that, compared to pecking in the other three locations, the rate of anticipatory responding in the GC location (M = 0.47 pecks per s, SE = 0.03) was reliably greatest, p < .05, as evidence that the global information in the visual contexts directed the pigeons' anticipatory responding. The rate of pecking in the LC location (M = 0.17 pecks per s, SE = 0.01) also differed reliably from pecking in both the PO location (M = 0.09 pecks per s, SE = 0.01) and the IM location (M = 0.11 pecks per s, SE = 0.01), suggesting that local cues too exerted weaker, but nevertheless reliable control over anticipatory responding. Pecking to the PO and IM locations did not reliably differ. The main effect of reversal type was also significant, F(1, 7) = 20.47, p < .001, ηp2=.96, 95% CIs = .78, .98, with the rate of anticipatory responding being higher in the Horizontal Reversal location (M = 0.24 pecks per s, SE = 0.03) than in the Vertical Reversal location (M = 0.18 pecks per s, SE = 0.01).\n\nMoreover, the interaction between response type and reversal type was significant, F(3, 21) = 42.85, p < .001, ηp2=.86, 95% CIs = .68, .90. Tukey post hoc analyses revealed that, in the Horizontal Reversal condition, the rate of anticipatory responding in the GC location was significantly higher than in the other three locations, p < .05, whereas the rate of anticipatory responding in the LC, PO, and IM locations did not differ from each other ( , top). This result suggests that, when the contexts were horizontally reversed, the pigeons' attention was predominantly controlled by global cues.\n\nIn the Vertical Reversal Condition, the rate of anticipatory responding in the GC location was again significantly higher than in the other three locations; in addition, the rate of anticipatory responding in the LC location differed reliably from the PO location, but not from the IM location; the rate of anticipatory responding in the PO and IM locations did not reliably differ ( , bottom). No other main effect or interaction was reliable. This pattern of results suggests that, when the contexts were vertically reversed, both global and local contexts exerted attentional control. Perhaps because global cues were more strongly disrupted when the scenes were vertically reversed, local information surrounding the target was more effective for pigeons' anticipating the location of the upcoming target. Indeed, Tukey post hoc analyses indicate that significantly more anticipatory pecks were directed to the LC location in the Vertical Reversal Condition than in the Horizontal Reversal Condition.\n\nFinally, we explored whether anticipatory responding to the quadrant where the target was about to appear (correct responding vs. adjusted incorrect responding) in the Predictive Condition and in each of the four Testing conditions could have contributed to our overall pattern of RT results. We calculated the five mean RTs (Predictive vs. Horizontal Global vs. Horizontal Local vs. Vertical Global vs. Vertical Local) as well as the five mean disparity scores for anticipatory contextual responses (correct location vs. incorrect location) across all 16 days and then correlated them with one another ( ). The resulting correlation was -0.99, p < .001. This extremely high correlation suggests that pigeons' specific pattern of anticipatory responding to the various scene contexts reliably contributed to their overall pattern of RT performance, with increases in correctly directed anticipatory responding supporting progressively briefer RTs.\n\nTable 1\n\nConditionLatency (LogMs)Correct Anticipatory Response (pecks per s)Incorrect Anticipatory Response (pecks per s)Anticipatory Response Disparity (pecks per s)Predictive6.252.320.172.15Horizontal Global6.651.280.300.97Vertical Global6.850.900.400.50Vertical Local7.010.740.410.32Horizontal Local7.140.420.60-0.18\n\nThe results of Experiment 3 thus indicate that global scene properties more effectively controlled pigeons' visual search behavior than did local scene details; nevertheless, local details did promote target detection when global scene processing was made less accessible for target search by mirror-image reversal. These results are broadly consistent with the earlier discussed eye movement studies of Brockmole and Henderson (2006), which suggested that detailed local cues could be used for target localization when global cues were sufficiently disrupted. These results do not agree with the findings of Brooks, Rasmussen, and Hollingworth (2010), which suggested that disrupting the global context should interfere with access to local information or the results of Rosenbaum and Jiang (2014), which suggested that local information should be poorly learned because of the overwhelming salience of global cues.\n\nAlthough our pigeons exhibited exceptionally strong global control, it may be possible to reconcile the birds' also evidencing reliable local control with the fact that pigeons are often deemed to be adept processors of particulate visual information (see Wasserman & Biederman, 2012). For example, although vertical scene reversals are much more disruptive to categorization behavior than are horizontal scene reversals (Wasserman, Kiedinger, & Bhatt, 1988), pigeons still respond well above chance with vertically reversed stimuli, suggesting that the local cues that were learned in training are still sufficient to support correct categorization behavior.\n\nOne issue with the use of naturalistic stimuli in both human and animal research is that they may constrain the results of certain stimulus transformations. Whereas artificial stimuli can be designed so that horizontal or vertical reversals equally disrupt stimulus identity, the superstructure of a “naturalistic scene” may impart a kind of regularity that systematically affects such transformations. For example, common features of naturalistic scenes, such as “sky” and “ground,” each extend horizontally, but not vertically; this factor ought to make vertical reversals more unlike the original scenes than horizontal reversals.\n\nTo assess the similarity of the context across horizontal and vertical reversals in our study, we utilized the Gist Descriptor, which analyzes the energy spectra of images in various regions (Oliva & Torralba, 2001), and has earlier been used to assess scene similarity. We computed the Gist Descriptors for each image and for each of the reversed versions. To compare the similarity of those images, we then took the sum of the squared differences between the Gist Descriptor of each original context and the Gist Descriptor its two reversed versions. These similarity scores were then compared using a paired t-test. Across the four predictive contexts alone (t(3) = 3.93, Cohen's d = 2.46, p < .05) and across all eight contexts (t(7) = 3.09, Cohen's d = 1.59, p < .05), horizontal reversals were more similar to the original contexts than were the vertical reversals.\n\nNotwithstanding this disparity in stimulus similarity associated with horizontal and vertical reversals of naturalistic scene backgrounds, our overall finding that global image properties dominated the local cues that immediately surrounded the target expands our understanding of the stimulus control of spatially-directed behavior.\n\nThe role of global vs. local cues in spatial cognition has been extensively examined using the familiar landmark-based spatial search paradigm (Spetch, Cheng, & Mondloch, 1992). In such studies, pigeons must use a visual landmark to find a hidden target and then peck the area containing the hidden target to receive food. Results show that, when the landmark is shifted, the peak place of pigeons' pecking moves along with the shifted landmark, indicating that the birds use the landmark, which conveys detailed spatial information for target localization.\n\nCheng and Spetch (1995) subsequently investigated whether, in addition to the landmark, pigeons can use a global cue—the square outline (frame) of the search array—to find a hidden goal. Although search was primarily controlled by the landmark for some pigeons, for other pigeons search was primarily controlled by the frame; indeed, still other birds used the relation between the frame and the landmark. Evidently, the control of visual search by global or local information may differ from individual to individual.\n\nOvershadowing among competing landmarks further underscores the importance of local cues for target localization. Both pigeons and humans show stronger control by closer landmarks than by farther landmarks when both are simultaneously presented and signal target location (Spetch, 1995; Leising, Garlick, & Blaisdell, 2011).\n\nOur study, by contrast, yielded stronger evidence for global than for local control of spatially-directed responding. This empirical disparity between our study and many earlier landmark search studies may stem from several sharp differences in the experimental paradigms. We always made the target visible to the pigeons after nonzero SOAs; during the SOAs, the birds were free to peck at the (target-absent) contexts, but they were never required do so. In the landmark search paradigm, the birds had to discover where the (never-visible) target was located and to peck within its unmarked boundaries to receive food (Spetch et al., 1992; Cheng & Spetch, 1995). Moreover, our study entailed photographic scenes which were rich with visual information that could be associated with the location of the target; the traditional landmark search paradigm entails only a small number of local landmarks in the immediate vicinity of the hidden target. Even though the earlier overshadowing studies involving multiple local cues were more similar to our global scene study, the small number of landmarks that were presented in those studies does not approximate the richness of real-world scenes (Spetch, 1995; Leising, Garlick, & Blaisdell, 2011).\n\nOur study also suggests that global and local cueing effects may be interdependent in pigeons as well as humans. Although the associations between the global contexts and the locations of the upcoming target more strongly contributed to the contextual cueing effect, local features associated with the placement of the upcoming target also influenced spatially controlled attention and responding. When both global and local information were intact (in the Predictive condition), the pigeons most quickly pecked the target; when either global or local cues misdirected the pigeons away from the current target location, pecking the target was slowed.\n\nLandmark-based studies too have found that the strength of local control can depend on the configuration of global cues (Legge, Spetch, & Batty, 2009). Local versus global control turned out to depend on the horizontal, vertical, and diagonal patterns of 2-, 3-, 4-, or 5-element linear strings of items (as well as on the individual pigeons being studied). When linear arrays were horizontally arranged, pigeons attended more to local cues; when linear arrays were vertically or diagonally arranged, pigeons attended more to global cues."
    }
}