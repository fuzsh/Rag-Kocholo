{
    "id": "dbpedia_6652_2",
    "rank": 62,
    "data": {
        "url": "https://www.wired.com/story/christopher-nolan-oppenheimer-ai-apocalypse/",
        "read_more_link": "",
        "language": "en",
        "title": "How Christopher Nolan Learned to Stop Worrying and Love AI",
        "top_image": "https://media.wired.com/photos/64875f770b67c709cbcaaa29/191:100/w_1280,c_limit/Nolan%2014.jpg",
        "meta_img": "https://media.wired.com/photos/64875f770b67c709cbcaaa29/191:100/w_1280,c_limit/Nolan%2014.jpg",
        "images": [
            "https://www.wired.com/verso/static/wired/assets/logo-header.svg",
            "https://media.wired.com/photos/648762356279e36472844580/master/w_2560%2Cc_limit/WI070123_FF_ChristopherNolan_01.jpg",
            "https://media.wired.com/photos/648b613982d37ced55dff5ca/master/w_1600%2Cc_limit/WIRED_3107_3108_cover.jpg",
            "https://media.wired.com/photos/646fd9bac859c4a1cdecc265/master/w_1600%2Cc_limit/final-art---The-Big-Interview.jpg",
            "https://media.wired.com/photos/66ce04da03d7b60062bfabd5/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ccde0e112ec31a2d5ea664/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66cc8f4dc22b7f7e67bd61ad/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce68ba5d7ab5e913a2ec1a/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/64875f770b67c709cbcaaa29/master/w_1600%2Cc_limit/Nolan%252014.jpg",
            "https://media.wired.com/photos/66ce04da03d7b60062bfabd5/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ccde0e112ec31a2d5ea664/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66cc8f4dc22b7f7e67bd61ad/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce68ba5d7ab5e913a2ec1a/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/64822b13a6c1fece8f4bb2f5/master/w_1600%2Cc_limit/WI070123_FF_ChristopherNolan_02.jpg",
            "https://media.wired.com/photos/66ce04da03d7b60062bfabd5/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ccde0e112ec31a2d5ea664/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66cc8f4dc22b7f7e67bd61ad/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce68ba5d7ab5e913a2ec1a/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/64822c686b2fffe52ad78fdb/master/w_1600%2Cc_limit/WI070123_FF_ChristopherNolan_03.jpg",
            "https://media.wired.com/photos/66ce04da03d7b60062bfabd5/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ccde0e112ec31a2d5ea664/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66cc8f4dc22b7f7e67bd61ad/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce68ba5d7ab5e913a2ec1a/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce04da03d7b60062bfabd5/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ccde0e112ec31a2d5ea664/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66cc8f4dc22b7f7e67bd61ad/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce68ba5d7ab5e913a2ec1a/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/64875f662cc57777ec67f085/master/w_1600%2Cc_limit/Nolan_GF-03819_MSG.jpg",
            "https://media.wired.com/photos/66ce04da03d7b60062bfabd5/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ccde0e112ec31a2d5ea664/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66cc8f4dc22b7f7e67bd61ad/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce68ba5d7ab5e913a2ec1a/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce04da03d7b60062bfabd5/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ccde0e112ec31a2d5ea664/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66cc8f4dc22b7f7e67bd61ad/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce68ba5d7ab5e913a2ec1a/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce04da03d7b60062bfabd5/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ccde0e112ec31a2d5ea664/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66cc8f4dc22b7f7e67bd61ad/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66ce68ba5d7ab5e913a2ec1a/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/64822eb76b2fffe52ad78fdd/master/w_1600%2Cc_limit/WI070123_FF_ChristopherNolan_04.jpg",
            "https://media.wired.com/photos/663a7781e324938b5ccfaa9e/1:1/w_270%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b15556efbdab25018b8444/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66bd02c0ceeb94a5c619da8f/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b6419459497c7dda2511d5/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b4ec39a251cdd39609344c/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b12048cabb7f268cc85fe9/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66a83357b9a83def56ceb758/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66bcfe7ef5cef6fa241bf0a3/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/65d510e7f518cfb89616b1cd/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://www.wired.com/verso/static/wired/assets/logo-reverse.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "cover story",
            "longreads",
            "christopher nolan",
            "movies",
            "interviews",
            "nuclear war",
            "big interview",
            "artificial intelligence",
            "magazine-31.07/31.08"
        ],
        "tags": null,
        "authors": [
            "Maria Streshinsky",
            "Anna Lagos",
            "Andy Greenberg",
            "Matt Kamen",
            "Julian Chokkattu",
            "Jennifer M. Wood",
            "Joel Khalili",
            "Brian Stelter",
            "Kate Knibbs",
            "Adrienne So"
        ],
        "publish_date": "2023-06-20T06:00:00-04:00",
        "summary": "",
        "meta_description": "The Oppenheimer director says AI is not the bomb. His new movie might still scare you shitless.",
        "meta_lang": "en",
        "meta_favicon": "https://www.wired.com/verso/static/wired/assets/favicon.ico",
        "meta_site_name": "WIRED",
        "canonical_link": "https://www.wired.com/story/christopher-nolan-oppenheimer-ai-apocalypse/",
        "text": "When wired heard that Christopher Nolan and his producer—and wife—Emma Thomas were coming out with a biopic of J. Robert Oppenheimer, we were perplexed. At least for a moment. It is hard for WIRED to resist a Nolan–Thomas film. Nolan has a real love of science, just like us. (We know this because, well, it's pretty obvious in some of his movies, but also because Nolan guest­-edited an issue of WIRED back in 2014 when his film Interstellar came out and we got him to geek out over physics.) Add to that, the duo like to bend their audience's minds. And their eyeballs. They make superhero movies! It's so much chum for WIRED.\n\nSo, Oppenheimer. A biopic, a look back at history. Alas. WIRED parlance is more often about looking ahead. (Not that we didn't like Dunkirk.) So we kinda thought maybe we weren't the magazine to dive into this one.\n\nBut we couldn't get the idea out of our minds, because so many conversations in the office and in meetings and around technology were about the potentially apocalyptic time we are living in. Climate, war, yes. But also, generative AI. Over and over, I was hearing people compare this moment to the mid-1940s, when we stepped across the threshold into the nuclear age, or to the years when Oppenheimer was heading up the project to build the bomb in New Mexico.\n\nHere comes the full disclosure: I know something about Oppenheimer, and his path to Los Alamos. I helped edit a biography about him and three women who were central to his life, written by my mother, Shirley Streshinsky, and the historian Patricia Klaus. I started to want to know what Christopher Nolan thinks of the time we are in, considering he has spent his last few years steeped in the time so many people kept referring to. Perhaps Nolan and Thomas line up with WIRED interests all over again.\n\nSo I headed to LA, to a quiet neighborhood where the couple keep an office. I had hoped to talk to them both, and as I entered a glass-walled, stylish conference room overlooking a garden, happily, Thomas was standing there too. I burbled something about how often her name gets left out of interviews. She thanked me for that. Turns out she couldn't stick around. But toward the end of my conversation with Nolan, he told me, “Everything we do is in lockstep. I mean, she's the best producer in Hollywood, without question.” And their latest film, though it's set firmly in the past, might just be their most forward-looking yet.\n\nMARIA STRESHINSKY: Maybe this is presumptuous, but looking at your films in reverse, it feels like your and Emma's work has been, all the while, leading up to Oppenheimer. In ways, it makes so much sense.\n\nCHRISTOPHER NOLAN: I don't think that's at all presumptuous. It's how I feel about the film.\n\n(Also, I don't mean to say your career is over.)\n\nI've tended to feel this way with every project I've done. Because I'm trying to build on what I've learned before. Every time you finish a film, there are questions left hanging. And so with the next film, you kind of pick up the thread. In the case of Oppenheimer, very literally, there is a reference to Oppenheimer in Tenet [Nolan's previous movie].\n\nSo he's been in your head for a while.\n\nOppenheimer's story has been with me for years. It's just an incredible idea—people doing these calculations, and looking at the relationship between theory and the real world, and deciding there's a very small possibility they're going to destroy the entire world. And yet they pushed the button.\n\nIt's very dramatic.\n\nI mean, it's literally the most dramatic moment in history. In history.\n\nA lot of people may not know that when we dropped the bomb in 1945, it was not only a horrifying moment but maybe also the one in which it was understood that humans could now wipe out all humanity.\n\nMy feeling on Oppenheimer was, a lot of people know the name, and they know he was involved with the atomic bomb, and they know that something else happened that was complicated in his relationship to US history. But not more specific than that. Frankly, for me, that's the ideal audience member for my film. The people who know nothing are going to get the wildest ride. Because it's a wild story.\n\nHis personal story, you mean.\n\nAnd they need to, because, you know, he's the most important man who ever lived.\n\nYou have a line in the movie, someone says to Oppenheimer, You can get anybody to do anything. Something like that. He was a brilliant manager. He was brilliant at knowing, in that room, those scientists are doing x, and in that other room, those scientists are doing y. He was the one who could keep it all in his mind.\n\nHe knew how to motivate people through the theatricality of his persona, the projection of his own brilliance. He gave all the scientists and officials and everyone a focal point.\n\nHe had real charisma.\n\nCharisma. That's the perfect word. It made it all come together. The film deals with this a lot, the idea that these academics, these theorists could come together and build something with their own hands of this magnitude, of this importance. It's miraculous.\n\nSpeaking of building something of magnitude, I was at the TED conference in Vancouver recently, and one of the most interesting sessions was a series of talks about generative AI. So many of the speakers mentioned the atomic bomb, nuclear weapons. The last speaker was a technologist—who happened to grow up in Los Alamos, by the way—who talked about the inevitable growth of the use of AI in weaponry. He ended his talk by saying that the only way to keep world order was to have better AI weapons. That it was a deterrent. Which sounded a lot like how people thought of the atomic bomb. Feels like you couldn't have planned your film release for a better time.\n\nI think the relationship is an interesting one. It's not the same. But it's the best analogy—which is why I used it in Tenet—for the dangers of unthinkingly unleashing a new technology on the world. It's a cautionary tale. There are lessons to be learned from it. Having said that, I do believe the atomic bomb is in a class of its own as far as technologies that have changed and endangered the world.\n\nAnd the origins of these technologies weren't the same.\n\nThere is a fundamental difference. The scientists dealing with the splitting of the atom kept trying to explain to the government, This is a fact of nature. God has done this. Or the creator or whoever you want it to be. This is Mother Nature. And so, inevitably, it's just knowledge about nature. It's going to happen. There's no hiding it. We don't own it. We didn't create it. They viewed it as that.\n\nIn other words, they felt they were just revealing something that was already there.\n\nAnd I think you'd be very hard-pressed to make that argument about AI. I mean, I'm sure some will.\n\nYou must've grown up in the shadow of the bomb.\n\nI grew up in the 1980s in the UK, and we had the Campaign for Nuclear Disarmament, all that. People were very, very aware. When I was 13, me and my friends, we were convinced we would die in a nuclear holocaust.\n\nBut you didn't, and the world moved on.\n\nI was talking to Steven Spielberg about this the other day. He grew up under the threat of the Cuban Missile Crisis in the '60s. Same thing. Absolutely. There are times in human history when the danger of nuclear warfare has been so palpable and tactile and visible to us that we're very aware of it. And then we can only be worried for so long, and we move on. We worry about other things. Um, the problem is that the danger doesn't actually go away.\n\nRight. I mean, I feel like a month ago we were all worried that Putin might be serious about using a nuclear weapon.\n\nWhat I remember from the '80s is that the fear of nuclear war had receded in favor of fear of environmental destruction. It was almost like we couldn't sustain the fear of it for that long. We have a complicated relationship with our fear. And yes, Putin has been using that doomsday threat and that fear to saber-rattle. It's extremely unnerving.\n\nAs unnerving as the threat of an AI apocalypse?\n\nWell, the growth of AI in terms of weapons systems and the problems that it is going to create have been very apparent for a lot of years. Few journalists bothered to write about it. Now that there's a chatbot that can write an article for a local newspaper, suddenly it's a crisis.\n\nWe, folks in the media, have been doing that for years. Navel-gazing. Some of us are writing about AI because it can put us out of a job.\n\nThat's part of the problem. Everybody has a very—call it a partisan point of view. The issue with AI, to me, is a very simple one. It's like the term algorithm. We watch companies use algorithms, and now AI, as a means of evading responsibility for their actions.\n\nSay more about that.\n\nIf we endorse the view that AI is all-powerful, we are endorsing the view that it can alleviate people of responsibility for their actions—militarily, socio­economically, whatever. The biggest danger of AI is that we attribute these godlike characteristics to it and therefore let ourselves off the hook. I don't know what the mythological underpinnings of this are, but throughout history there's this tendency of human beings to create false idols, to mold something in our own image and then say we've got godlike powers because we did that.\n\nThat feels very, very right now. Like we're at that tipping point.\n\nExactly.\n\nWith these large language models, the machines might even be able to teach themselves the next step.\n\nThere was an interesting article in the LA Times about ChatGPT and OpenAI. It basically said it's a sales pitch, that they're a private company now. And they have the greatest sales pitch in the world, which is, This is a really dangerous thing. Maybe we shouldn't put it out there. So now everyone wants it. Doesn't mean there isn't a real danger here, because I feel that there is. But I personally, and this is just my opinion, I identify the danger as the abdication of responsibility.\n\nPeople keep saying there needs to be a governing body for this stuff. They say you all need to deal with it. Like you governments. There should be an international agency.\n\nBut that's the oldest political trick in the book of the tech companies. Right? That's what, you know, SBF was doing with FTX. Zuckerberg's been asking to be regulated for years. That's the oldest political trick. 'Cause they know that our elected officials can't possibly understand these issues.\n\nAs we see from congressional hearings.\n\nAnd how could they? I mean, it's very specialist stuff, and it's incumbent on the creators and Oppenheimer—to bring it back to Oppenheimer—\n\nPlease do.\n\nBecause it's an interesting conversation. The thing with Oppenheimer is that he very much saw the role of scientists postwar as being the experts who had to figure out how to regulate this power in the world. And when you see what happened to him, you understand that that was never going to be allowed to happen. It's a very complicated relationship between science and government, and it's never been more brutally exposed than in Oppenheimer's story. I think there are all kinds of lessons to be learned from it.\n\nSuch as?\n\nSo he tried to work from within the establishment and not just turn around and say, you know, what we need is love or whatever. He was very practical in his approach, but he still got crushed. It's very complex, and I think from our inventors now, it's very disingenuous for them to say, “We need to be regulated.”\n\nThere was a moment when Oppenheimer wanted the science to be shared.\n\nCandor was the word he used. Candor.\n\nThat seems to have shifted with the H-bomb, or do I have that wrong?\n\nNo, no, he believed it about the H-bomb as well. He—I mean, it's funny talking about it, because in a way these are spoilers for the film. But in another way it's history, you can Google it. There is this important moment where, as the H-bomb program gears up, he took to making speeches where he would say, I wish I could tell you what I knew. I can't. If you knew what I knew, you'd understand that we all have to share information. It's the only way we'll not destroy the world, essentially. So candor was what he viewed as the most practical means of that. We were all coming together, and he viewed the UN as being a powerful body in the future, with real teeth. He viewed international control of atomic energy as the only way to ensure world peace. That hasn't happened, obviously.\n\nHe didn't foresee what's happening now, the slow decline of democracies. The rise of autocracies. The North Koreas.\n\nI don't think he saw that at all. It was a very optimistic moment.\n\nThat's what I worry about with the talk of needing a worldwide governing body for AI. We have nonstate actors, or state actors …\n\nRight. But that's the thing in dealing with tech companies who have refused to be bound by geographical limitations. Systemically, tech companies are encouraged and enabled to circumvent government regulation. It's an ethos. By the way, I'm coming across like I think that Silicon Valley's evil and all these people are terrible. I don't. It's just the system. It's just the way it works.\n\nPlus, there's an odd element of, well, safety I guess, with nuclear weapons, because you have to have specific ingredients to build a bomb. That's very different than facing the potential of supercomputing.\n\nDuring World War II, the British program for their bomb was very sophisticated. They had a lot of great scientists. But Churchill and his government realized they just didn't have the resources. So they gave the Americans everything they had. They said, You have the size, the distance from the front line, the industrial base. I read a statistic at some point in my research about the number of Americans who were involved in making the first atomic bomb. It was something on the order of 500,000. It was all these companies. It was a massive physical process, which is why to this day it's easy to spot when a country's doing it. So there's certain things that give us a bit of reassurance that the process can be managed. And I don't think any of this applies to AI.\n\nNo, I don't think it does—especially when some of what we're talking about with AI is a softer threat. Disinformation on hyperspeed, technological unemployment.\n\nIt is, but I'm less—I feel that AI can still be a very powerful tool for us. I'm optimistic about that. I really am. But we have to view it as a tool. The person who wields it still has to maintain responsibility for wielding that tool. If we accord AI the status of a human being, the way at some point legally we did with corporations, then yes, we're going to have huge problems.\n\nAre you seeing anything in AI that could be wonderful for, in particular, filmmaking?\n\nOh definitely. The whole machine learning as applied to deepfake technology, that's an extraordinary step forward in visual effects and in what you could do with audio. There will be wonderful things that will come out, longer term, in terms of environments, in terms of building a doorway or a window, in terms of pooling the massive data of what things look like, and how light reacts to materials. Those things are going to be enormously powerful tools.\n\nWill you take advantage, personally?\n\nI'm, you know, very much the old analog fusty filmmaker. I shoot on film. And I try to give the actors a complete reality around it. My position on technology as far as it relates to my work is that I want to use technology for what it's best for. Like if we do a stunt, a hazardous stunt. You could do it with much more visible wires, and then you just paint out the wires. Things like that.\n\nIt'll improve the ease and efficiency of visual effects, you're saying.\n\nIt's not starting from nothing. It's starting from a much more detailed and data-driven idea. It might finally break the barrier between animation and photography. Because it's a hybrid. If you tell an artist to, say, draw a picture of an astronaut, they're inventing from memory or looking at references. With AI, it's a different approach, where you're actually using the entire history of imagery.\n\nUsing actual images.\n\nUsing actual images, but in a completely, fundamentally rebuilt manner—which of course raises significant artists' rights issues, and that will have to be dealt with.\n\nLet's get back to science and your films. In the December 2014 issue of WIRED that you guest-edited, there was a line where you said, “The relationship between storytelling and the scientific method fascinates me. It wasn't really about an intellectual understanding. It was a feeling of grasping something.” Talk to me about your love of science.\n\nWell, I've always been interested in astronomy, in questions of physics. I got to explore that in Interstellar. When my brother wrote the script, he would look at Einstein's thought experiments, and he identified a particular melancholy that some of them had. It's all to do with parts in time. All to do with, like, twins who get separated and one goes away and comes back and the other's older, you know? There's a very literary quality to Einstein onward in terms of thinking about physics and how you would do these thought experiments, how you conceive of these ideas and how they work. The process of visualization that physicists need isn't so different from a literary process.\n\nDo you feel something like that at the editing stage of a film?\n\nI feel it at every phase, at every phase. A lot of my job is trying to articulate instincts and feelings about the shape of things. It can be difficult and complicated.\n\nI find that if I'm working on a story and I don't know the structure, I don't know the flow, something's wrong. I can't speak of the piece in a way that makes sense.\n\nThere's a geometry or a geography. I think in very geographical terms or geometric terms about structures and patterns. Over the years I've tried adopting a sort of ground-up approach to structure, but ultimately it's very much an instinctive process: Does the feeling have the shape of a narrative, and how does that come together? And I was fascinated to realize that physicists have a very similar process going on. It's really fun.\n\nMaybe this is a nod to Interstellar, but physicists always seem so in love. In love with physics, that is.\n\nI'm passionately committed to truth. I love the scientific method. I hate to see it distorted either by scientists in the media or by media speaking for scientists. The pure scientific method, the idea that science seeks to disprove itself constantly, it so elevated human thinking beyond any other form—religion, ­whatever—that we've chosen to engage in as a species.\n\nBefore this interview, my mom and I watched some of your films together—because of her book, she was curious about what you'd do with Oppenheimer—and at one point she said it feels like your movies can have a very anti-nihilistic message. Dunkirk. Interstellar. Batman. Or, is it optimism?\n\nI mean, the end of Inception, it's exactly that. There is a nihilistic view of that ending, right? But also, he's moved on and is with his kids. The ambiguity is not an emotional ambiguity. It's an intellectual one for the audience. It's funny, I think there is an interesting relationship between the endings of Inception and Oppenheimer to be explored. Oppenheimer's got a complicated ending. Complicated feelings.\n\nHow are early viewers reacting?\n\nSome people leave the movie absolutely devastated. They can't speak. I mean, there's an element of fear that's there in the history and there in the underpinnings. But the love of the characters, the love of the relationships, is as strong as I've ever done.\n\nAnd the complexity of the subject matter.\n\nOppenheimer's story is all impossible questions. Impossible ethical dilemmas, paradox. There are no easy answers in his story. There are just difficult questions, and that's what makes the story so compelling. I think we were able to find a lot of things to be optimistic about in the film, genuinely, but there's this sort of overriding bigger question that hangs over it. It felt essential that there be questions at the end that you leave rattling in people's brains, and prompting discussion.\n\nI have a strange question, a weird one. My husband fought cancer for four years. Since he died, I'm so raw, emotionally. My head is a mess. I worry about the world's ills, the people in war zones, the cats that are not being fed, all of it. I know this is far from the same, but I've been thinking, what would it have been like to be in Oppenheimer's head before—and god, after—the bomb was dropped? What do you think it was like to be in his head?\n\nIt's not a strange question at all. The answer is very much in the film. I wrote this script in the first person. It's what I told Cillian [Murphy, who plays Oppenheimer]: You are the eyes of the audience. And he takes us there. The bulk of the storytelling, we don't go outside his experience. It's my best attempt to convey the answer to that question.\n\nI'm a little nervous about seeing the whole thing.\n\nI think you might have to wait a long time before you do. It is an intense experience, because it's an intense story. I showed it to a filmmaker recently who said it's kind of a horror movie. I don't disagree. It's interesting that you used the word nihilism earlier, because I don't think I'd quite managed to put my finger on it. But as I started to finish the film, I started to feel this color that's not in my other films, just darkness. It's there. The film fights against that.\n\nDoes that get into you? Do you sleep OK?\n\nI do now that I—you know, I was relieved to be finished with it, actually. But I enjoy watching the film tremendously. I think you'll understand when you see the film. It's a complicated set of feelings to be entertained by awful things, you know? Which is where the horror dimension comes in.\n\nHave your kids seen it?\n\nOh yeah.\n\nHad they known anything about Oppenheimer before?\n\nI told one of my sons about it as I started to write it, and he literally said to me: But nobody really worries about that anymore. Nuclear weapons. Two years later, he's not saying that. The world's changed again. And that's a lesson for all of us, but particularly for the young. The world changes fast.\n\nIf you buy something using links in our stories, we may earn a commission. This helps support our journalism. Learn more.\n\nThis article appears in the Jul/Aug 2023 issue. Subscribe now.\n\nLet us know what you think about this article. Submit a letter to the editor at mail@wired.com."
    }
}