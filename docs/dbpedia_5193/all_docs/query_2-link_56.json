{
    "id": "dbpedia_5193_2",
    "rank": 56,
    "data": {
        "url": "https://is.enes.org/sdm-how-to-provide-data/",
        "read_more_link": "",
        "language": "en",
        "title": "How to Provide Data?",
        "top_image": "https://is.enes.org/assets/img/favicon-32x32.png",
        "meta_img": "https://is.enes.org/assets/img/favicon-32x32.png",
        "images": [
            "https://raw.githubusercontent.com/IS-ENES3/IS-ENES-Website/main/assets/img/mobile-button.png",
            "https://raw.githubusercontent.com/IS-ENES3/IS-ENES-Website/main/images/flag_eu_h40px.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "www.facebook.com",
            "phlow.media"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "IS-ENES3 Website",
        "meta_lang": "en",
        "meta_favicon": "https://is.enes.org/assets/img/favicon-32x32.png",
        "meta_site_name": "IS-ENES-Website",
        "canonical_link": "https://is.enes.org/sdm-how-to-provide-data/",
        "text": "The ENES infrastructure project (IS-ENES) provides to data producers and managers tools and information on the quality of the datasets hosted at the ESGF portals.\n\nData Ingestion: the ESGF data ingestion steps provides guidance on how to publish data to ESGF.\n\nData Quality: the Quality Assurance tool QA-DKRZ checks conformance of meta-data of climate simulations given in NetDCF format with CF Conventions, CORDEX, CMIP5 and 6 conventions and rules.\n\nData Citation: the World Data Center for Climate WDCC offers the ENES community the assignment of a DataCite DOI for model data citation to long-term archived data. DOI assignment is combined with further quality checks. Find specific information on the CORDEX Data Citation process.\n\nData Ingestion\n\nExcept replications, which are treated differently, ESGF data ingestion consists of the steps shown below:\n\nSteps of ESGF data ingestion\n\nAt the end of the publishing step, the data are visible in the ESGF and can be downloaded from there. For long-term archiving and DataCite DOI assignment, additional ingestion steps have to be appended.\n\nAggregation, format and unit conversion, generation of metadata, and additional data*\n\nThese steps have to be performed by the data provider.\n\nData with time frequency day, month, season and year are usually aggregated. Depending on the nature of the variable and the rules of the project, an integral (e.g. for precipitation), a mean, minimum or maximum has to be calculated. Sometimes, more than one aggregation step is necessary, for example monthly CORDEX sfcWindmax is a mean of the daily maxima.\n\nMetadata are usually inquired with a form and are project-dependent. If the utilized grid is not the usual latitude-longitude grid, additional data for grid description are needed, rotation angles in case of rotated poles or a grid map file in case of curvilinear coordinates.\n\nRewriting of NetCDF file\n\nNetCDF allows many data structures, variable definitions and attributes. To guarantee uniformity within a project, each project defines rules and translates them into machine-readable tables, the CMOR tables. The program CMOR (Climate Model Output Rewriter) is able to read these tables and adapts the attributes in the NetCDF header according the project’s rules, i.e. overwrites them. It is able to perform unit conversions (if not already done) and can calculate auxiliar variables as time bounds or grid points from the grid map. It also performs some quality checks, e.g. it can detect gaps in time series.\n\nOriginal CMOR is a subroutine library. Climate data projects usually have a main program and routines for reading the data developed or reuse existing software. Usually, the data provider has to perform the rewriting of the data files. IS-ENES offers guidance.\n\nQuality assurance\n\nThis step is usually done in the data centre but the quality assurance tool can also be used by the data provider. The tool has been developed in the IS-ENES project and is freely available. The quality assurance tool can check the consistency with the CF standard, with CMIP5 and CORDEX rules. The checks are not limited to the data itself, the directory structure can also be examined. Which tests are performed is project-dependent. The quality assurance tool throws a warning if a rule is violated. It does not perform corrections. In case quality assurance detects inconsistencies with the project’s rules, the data are returned to the data provider for adaptation.\n\nESGF publisher\n\nThis last step can only be launched by an ESGF data node administrator. The ESGF publisher script fills-in data and metadata. It also checks readability again.\n\nCMIP Data Quality\n\nCMIP6\n\nCMIP6 Model Output Requirements: File Contents and Format, Data Structure and Metadata\n\nCMIP6 ESGF Publication Requirements\n\nCMIP6 Data Request\n\nQuality check software\n\nCMIP5\n\nFor CMIP5 a three stage quality assurance process was agreed on. This process has been an important ENES contribution to the international CMIP5 data management effort. The following list collects information related to the CMIP5 quality check (QC) process:\n\nOverview of ESGF related CMIP5 QC services\n\nStatus and history information of CMIP5 QC process\n\nResults of CMIP5 QC\n\nCIM QC documents (Warning: This feed contains more than 30000 notes! Use Internet Explorer or a tool. Firefox will need several minutes to show the feed.)\n\nQuality check software\n\nCitation information service (to get citation information for a specific file)\n\nSummary of responsibility assignment to perform the QC for the different modeling groups\n\nQuality checked data is the basis of the ENES long term archival of CMIP5 data in the Data Distribution Centre (DDC) hosted at DKRZ.\n\nCORDEX Data Citation\n\nWDC Climate data citation service As for CMIP5, the World Data Center for Climate (WDCC) offers the assignment of DataCite DOIs to CORDEX data to support the citation of CORDEX data. This service is provided for stable data for long-term usage.\n\nProcess:\n\nContact WDCC at data@dkrz.de including “DOI CORDEX” in your email subject and information on your affiliation in the email body\n\nData replication (if necessary) by WDCC in cooperation with you\n\nAdditional quality control checks on data by WDCC\n\nLong-term archiving of data at WDCC\n\nTechnical Quality Assurance (TQA) checks by WDCC: consistency of data and metadata\n\nScientific Quality Assurance (SQA) by you: check of WDCC’s metadata and additional documentation of citation and scientific quality information\n\nDataCite DOI assignment and notification of the data creator/author by WDCC\n\nDOI granularity for CORDEX:\n\nThe targeted granularity for a DataCite DOI / citation entity for CORDEX is: one DOI for data of a single domain created with the same RCM by the same institute\n\nExample: EUR-44 results of SMHI for RCA4-v1 for all driving models\n\nDocumentation and Overview:\n\nWDCC’s DataCite DOI process is documented here.\n\nContact and Information:"
    }
}