{
    "id": "dbpedia_8714_3",
    "rank": 5,
    "data": {
        "url": "https://www.linkedin.com/posts/reshmi-ghosh_knowledge-rag-languagemodels-activity-7209043707554082816-8WMX",
        "read_more_link": "",
        "language": "en",
        "title": "Reshmi Ghosh on LinkedIn: #knowledge #rag #languagemodels #parametric",
        "top_image": "https://media.licdn.com/dms/image/D4E22AQGIT99bAXqjYQ/feedshare-shrink_800/0/1718769956818?e=2147483647&v=beta&t=vJifeYJ_Bn4G43jKldeabvhvyfxvR0wRYjL4wbwbMR4",
        "meta_img": "https://media.licdn.com/dms/image/D4E22AQGIT99bAXqjYQ/feedshare-shrink_800/0/1718769956818?e=2147483647&v=beta&t=vJifeYJ_Bn4G43jKldeabvhvyfxvR0wRYjL4wbwbMR4",
        "images": [
            "https://static.licdn.com/aero-v1/sc/h/5q92mjc5c51bjlwaj3rs9aa82"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Reshmi Ghosh"
        ],
        "publish_date": "2024-06-19T04:05:57.407000+00:00",
        "summary": "",
        "meta_description": "üì¢New paper alert from Microsoft in collaboration with University of Massachusetts Amherst: &quot; From RAGs to rich parameters: Probing how language models utilize‚Ä¶ | 10 comments on LinkedIn",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/posts/reshmi-ghosh_knowledge-rag-languagemodels-activity-7209043707554082816-8WMX",
        "text": "üöÄ #NewResearch \" From RAGs to rich parameters: Probing how language models utilize external knowledge over parametric information for factual queries\" Super stoked to have been working in the paradigm of mechanistic interpretability of #RAG models, specifically the interplay between parametric knowledge and externally retrieved information for the task of #Factual QA. In collaboration with an incredible team at University of Massachusetts Amherst and Microsoft, for the first time, we explored whether language models favor #RAG context over their internal #parametric knowledge using different probing techniques: Causal Mediation Analysis, norm of Attention Contribution, and Attention Knockouts. Our #pioneering research not only enhance our understanding of language model processing but also pave the way for advancing the science of future #AI innovations. Dive into our findings here:üîóhttps://lnkd.in/eXMGCfm3\n\nPhi-2: The surprising power of small language models 1. Phi-2: A Small Language Model with Outstanding Reasoning and Language Understanding Capabilities - The title and main topic of the web page, which introduces a new 2.7 billion-parameter language model developed by Microsoft Research1. 2. Training Data Quality and Knowledge Transfer - The key insights behind Phi-2‚Äôs performance, which include using ‚Äútextbook-quality‚Äù data and scaling up from a smaller model, Phi-1.5. 3. Benchmark Results and Prompts - The evaluation of Phi-2 on various academic and proprietary benchmarks, as well as some examples of its responses to common prompts from the research community. #Phi2 #MicrosoftResearch #LanguageModel #AzureAI https://lnkd.in/dmqEGhnC\n\nMicrosoft Phi-2.7b parameters Microsoft‚Äôs 2.7 billion-parameter model Phi-2 showcases outstanding reasoning and language understanding capabilities, setting a new standard for performance among base language models with less than 13 billion parameters. Phi-2 builds upon the success of its predecessors, Phi-1 and Phi-1.5, by matching or surpassing models up to 25 times larger‚Äîthanks to innovations in model scaling and training data curation. The compact size of Phi-2 makes it an ideal playground for researchers, facilitating exploration in mechanistic interpretability, safety improvements, and fine-tuning experimentation across various tasks.\n\nRAG has always been problematic The Novel RAG approach has a few limitations including: It can answer questions over document collections, but struggles with global queries. For example : 'What are the major topics discussed in the Context Docs?\" Answering a global question as stated above is extremely difficult for Baseline RAG. To Cater this problem a solution is proposed by Microsoft Research The Solution involves two stages ‚Äì creating an entity knowledge graph from source documents and generating community summaries for closely-related entities. Summaries are then used to answer questions Following is the detail of what approach is used: Graph RAG Approach & Pipeline Source Documents ‚Üí Text Chunks: Splitting documents into manageable text chunks. Text Chunks ‚Üí Element Instances: LLMs extract entities and relationships to form the graph elements. Element Instances ‚Üí Element Summaries: Summarizing extracted elements into coherent descriptions. Element Summaries ‚Üí Graph Communities: Using algorithms like Leiden to detect communities within the graph. Graph Communities ‚Üí Community Summaries: Generating summaries for each community. Community Summaries ‚Üí Community Answers ‚Üí Global Answer: Using these summaries to generate partial answers which are then aggregated into a final answer. Limitations: Costly if you use Propriety Language Models like GPT4o or Gemini For a detailed article on this topic follow Tomaz Bratanic Tutorial on Medium Link: https://lnkd.in/dWTz2gwv\n\nBedtime read. Cool research by Microsoft : https://lnkd.in/eerEMfnd Large language models are useful because they can be expanded to ‚Äúunknown tasks‚Äù by providing examples through the prompt itself. Microsoft just published an interesting paper : where Small Language Models (SLMs) can perform much better (while running on a single laptop) for a fixed set of tasks. One example they use is using SLM to enable natural language conversation to generate code for querying Supply Chain information.\n\nYet another fine-tuning trick... This paper by Microsoft is yet another example of how the structure of the #finetuning training data makes a difference -- https://lnkd.in/dqpv9A6g They found that re-structuring the data as reading comprehension tasks (see diagram) improved performance, especially on financial, legal and medical data, helping to avoid a failure mode known as \"catastrophic forgetting\". This method in general is called supervised fine-tuning. Notably, under certain test conditions, a 7B model outperformed the much larger #BloombergGPT pre-trained domain-specific model. Some commentators have expressed a kind of frustration that the performance gains in LLM use cases often involves discovery of some kind of \"trick\" like this, not too dissimilar to #promptengineering However, that is the nature of language and large models with unfathomable datasets -- https://lnkd.in/g7FZgcXK LLMs have learned something about language structure, most of it in ways that are unexplainable. They weren't programmed with \"language rules\", but just asked to model joint probabilities. These experiments, like re-structuring the fine-tuning data, exploit some of that underlying structure in unpredictable ways. It is exciting because it suggests that there are still plenty of approaches to LLM use-case optimization. It also hints at the need for an experimental approach to LLMs in the enterprise on a use-case by use-case basis.\n\nMicrosoft's paper \"Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine\" was a really interesting one. It showed, that generalist models (like GPT-4) actually perform better than specialised models when using Retrieval Augmented Generation (RAG) and Chain of Thought Prompting. I dug through what this means for businesses looking to build their own LLM on the last episode of ùô≤ùöòùöóùöùùöéùö°ùöù. You can watch the full thing on my LinkedIn feed, or the Voiceflow YouTube.\n\nüåü Discover the Top 13 Use Cases for Large Language Models! üåü Are you curious about how large language models are revolutionizing industries with their capabilities? Look no further! I‚Äôve stumbled upon a fascinating blog by Data Science Dojo that outlines the top 13 impactful use cases for LLMs. This insightful read covers everything from enhancing customer service with natural language understanding to streamlining data analysis processes. üîó Dive deeper into the world of LLMs and explore the potential they hold: [Read the blog]( https://hubs.la/Q02p-8P-0 ) Let‚Äôs engage in a conversation about the future of technology. What applications of LLMs excite you the most? #ArtificialIntelligence #MachineLearning #TechTrends #Innovation #DataScience #FutureofTech"
    }
}