{
    "id": "dbpedia_6448_3",
    "rank": 40,
    "data": {
        "url": "https://www.linkedin.com/posts/cspenn_ai-largelanguagemodels-chatgpt-activity-7089407009992704000-Q21L",
        "read_more_link": "",
        "language": "en",
        "title": "Christopher Penn on LinkedIn: #ai #largelanguagemodels #chatgpt #artificialintelligence #generatieveai",
        "top_image": "https://media.licdn.com/dms/image/v2/D5622AQFLi8h-R2ndEw/feedshare-shrink_800/feedshare-shrink_800/0/1690246345355?e=2147483647&v=beta&t=C9Qc4QwVUOqPaowYe242OdIBaOd4R70Wlvf1WY6gTkA",
        "meta_img": "https://media.licdn.com/dms/image/v2/D5622AQFLi8h-R2ndEw/feedshare-shrink_800/feedshare-shrink_800/0/1690246345355?e=2147483647&v=beta&t=C9Qc4QwVUOqPaowYe242OdIBaOd4R70Wlvf1WY6gTkA",
        "images": [
            "https://media.licdn.com/dms/image/D4E16AQE1Sl77ILc0cg/profile-displaybackgroundimage-shrink_200_800/0/1663776019221?e=2147483647&v=beta&t=YWOE-lynnf4aN7ODV0ggKRZQnJDz0WnUe-yGXUuPJLM"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Christopher Penn"
        ],
        "publish_date": "2023-07-25T00:52:25.976000+00:00",
        "summary": "",
        "meta_description": "Tonight, I moderated a focus group. \n\nExcept that I was the only person there. \n\nWell, the only human.\n\nThere were three other participants - Nellie Novice‚Ä¶",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/posts/cspenn_ai-largelanguagemodels-chatgpt-activity-7089407009992704000-Q21L",
        "text": "Proving content authenticity is going to be a matter of lineage. Here's what I mean. AI companies in consumer interfaces are adding things like watermarks & fingerprints. But when you dig into the architecture, these artifacts are added AFTER the generation. If you use the actual models themselves, these fingerprints are not part of the generation. Which means that you have to trust that users will allow systems to add watermarks. If it's a malicious actor, the likelihood of that is... low. Take something like the C2PA image certification standard. It's a system that injects metadata into images that says where the image came from. Platforms like ChatGPT add this data into the image's metadata. It's also trivial to remove or redact because it's not part of the image itself. No AI image model can create any kind of watermark in the image itself. None. It's not how diffuser models work. The same is true for text generation. In clumsy prompts, it's easy to tell that a piece of text was AI-generated. \"In summary, this article delved into...\" But today's state of the art models, with talented prompting, can write in nearly any style, and claims that text can be fingerprinted are mostly hype. So how do you know what's authentic? Well, you don't, except by old-fashioned detective work. 1. Is the information published by the source? I saw a post attributed to Celine Dion the other day. I checked her official account and to my surprise, it was actually from her. 2. Is the information available across multiple, disparate sources? A photo can be generated. Lots of photos and videos from professional and amateur sources is much harder to stage. 3. Is the creation of the content documented? Someone showing the making of content in a series of videos or better, a livestream, is proving the lineage of the content. Show your work. As AI tools advance, assume that if someone doesn't present lineage in some fashion, it may not be true. #AI #GenerativeAI #GenAI #ChatGPT #ArtificialIntelligence #LargeLanguageModels #MachineLearning #IntelligenceRevolution\n\nPaul Roetzer started my day with this question: Can LLMs come up with ‚Äúnew‚Äù ideas and ‚Äúinnovate?‚Äù If we're talking about divergent creative thinking, then we should first know how we, the humans, create, before we can answer the question about how AI creates. I put 30 divergent creative thinking fMRI (brain scan) studies into NotebookLM and asked how humans think creatively. Here's the short version: - Ideas arise in the right hemisphere prefrontal cortex (RHPFC) where memory encoding operates - Ideas are filtered in the left dorsolateral prefrontal cortex (LDLPFC), where we apply constraints, learned rules like language, and short-term memory - Ideas then go to the medial prefrontal cortex (MPFC) to retrieve memories (long-term memory) and make associations with the idea - Ideas then go into an iterative loop, getting more idea variations from the RHPFC, applying less or more rigid rules in the LDLPFC, and augmenting them in the MPFC. Let's compare to how an LLM generates ideas. - An LLM is given a prompt. The prompt is broken down into tokens and embedded. - Retrieval heads take the embeddings and go into the latent space (long-term memory) to activate related embeddings. - The decoder takes the embeddings and reassembles them back into words, concepts, and ideas. - Rules are then applied based on the model's environment (prohibited topics, etc.) - The output is then stored in the short-term memory (context window). What's different about humans versus machines? - Machines have FAR more long-term memory than we do. A model like GPT-4-omni has read every book available online that's open to the public. How much of Project Gutenberg have you read? AI has read all of it. - Machines lack selective memory. Our memory associations, particularly for long-term memory, are rooted in emotion. That's how we store our embeddings, based on feeling. You can't remember what you had for lunch three days ago because it's not emotionally resonant but you can remember what you had to eat on that first date with that special person, even decades later. - Machines lack sensory information. Sensory information adds dimensions to concepts that aren't linear, whereas token retrieval is always statistical in nature. What can we conclude about AI creative thinking? It depends on the task and observed data. Can AI brainstorm a new corporate strategy? Absolutely. And it'll do better than any human, with appropriate prompting, because that's not a high sensory task. Can AI brainstorm a high sensory task like conceiving a new taste combination for a dish? Yes, but it will not reach human heights currently because it doesn't have that sensory data. It can see what past combinations have existed in its literature, but it has no objective way to get the data and evaluate whether something tastes good or not. #AI #GenerativeAI #GenAI #ChatGPT #ArtificialIntelligence #LargeLanguageModels #MachineLearning #IntelligenceRevolution\n\nIn the image attached to this post, an artist posts in celebration that the court case against Stability.ai is allowed to move ahead. This post is on Twitter/X, one of the social networks that overtly says it takes your data and trains on it, and the Terms of Service permit that. The artist then posts their artwork immediately after... for xAI to use as training data. ü§¶‚ôÄÔ∏è This is why AI education is vital. This is why understanding intellectual property law, rights, contracts, and terms of service is important. Companies like Stability.ai and OpenAI did not obtain permission to use copyrighted works as training data. Companies like Twitter/X, Meta, and Google did, because the Terms of Service permit it under the derivative works clause. Every word you write on LinkedIn, on Facebook, on WhatsApp, every image you post in Facebook Messenger, Instagram, and Threads, every livestream and voice call you have on Twitter/X - all of that is licensed to the respective companies to use for AI. And if you do sue, you will almost certainly lose a very expensive lawsuit. Know what your rights are. Know what you sign away when you agree to the Terms of Service. Disclaimer: I am not a lawyer. I cannot give legal advice. Consult a qualified attorney in your jurisdiction for legal advice about your specific situation. #AI #GenerativeAI #GenAI #ChatGPT #ArtificialIntelligence #LargeLanguageModels #MachineLearning #IntelligenceRevolution"
    }
}