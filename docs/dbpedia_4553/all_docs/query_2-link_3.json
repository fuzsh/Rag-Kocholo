{
    "id": "dbpedia_4553_2",
    "rank": 3,
    "data": {
        "url": "https://twit.tv/posts/transcripts/twit-news-403-transcript",
        "read_more_link": "",
        "language": "en",
        "title": "TWiT News 403 Transcript",
        "top_image": "https://twit.tv/images/meta-image-default-v4.jpg",
        "meta_img": "https://twit.tv/images/meta-image-default-v4.jpg",
        "images": [
            "https://elroy.twit.tv/sites/default/files/styles/twit_thumb_720x405/public/images/episodes/2024/05/851531/hero/TWITnews0403_thumbnail.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "0:00:01 - Leo Laporte / VOPodcasts you love. From people you trust. This is TWiT. This is TWiT News 403, recorded May 13th, 2024: OpenAI's Spring Eevent.0:00:10 - Leo",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "TWiT.tv",
        "canonical_link": "https://twit.tv/posts/transcripts/twit-news-403-transcript",
        "text": "0:00:01 - Leo Laporte / VO\n\nPodcasts you love. From people you trust. This is TWiT. This is TWiT News 403, recorded May 13th, 2024: OpenAI's Spring Eevent.\n\n0:00:10 - Leo Laporte\n\nSo hello everybody and welcome to a impromptu live stream covering the announcements that will be coming up momentarily from OpenAI, from Sam Altman. They call it their spring update, but of course, the reason we're doing this is because there's a lot of chatter going around, most of it encouraged by Sam Altman himself, that OpenAI is going to announce something big.\n\nHe's already said it's not ChatGPT 5. And it's not a search engine. And it's not a search engine. The smart money is on some sort of chat interface. There is, of course, the rumor that Apple is very close to doing a deal with OpenAI to put ChatGPT on their next iPhone or their next iOS. I you know I was saying before we started, jeff that if you follow the Singularity Reddit, which is the best place to go if you really want to know what the future holds they are really believing that we are getting close to the singularity it could be. We'll look back on May 13th 2024, as the day the machines became sentient. No, no, no, oops, this machine just became sentient. I have a sentient camera.\n\n0:01:43 - Jeff Jarvis\n\nLeo, it had to look away. You know what it was a signal.\n\n0:01:44 - Leo Laporte\n\nWhoa, hey, I'm over camera. Leo, it had to look away. You know what it was a signal Whoa, hey, I'm over here. Hey, whoa, hey over here. This is me here down here. Well, there you go. That, in a nutshell, is what will happen when the machines take over. I'm going to do manual control of my camera now and let's get ready for an event. John, you have the video from OpenAI up. I hear soothing music created no doubt by an AI.\n\n0:02:21 - Jeff Jarvis\n\nThe question we had earlier was whether the birds are artificial also.\n\n0:02:28 - Leo Laporte\n\nThe birds are real. Everyone knows that.\n\n0:02:30 - Jeff Jarvis\n\nThere is no reality.\n\n0:02:33 - Leo Laporte\n\nYou know, as you know, I am an AI optimist, a bullish kind of AI guy.\n\n0:02:39 - Jeff Jarvis\n\nNo, you're an accelerationist Leo, I am ready, I am ready.\n\n0:02:43 - Leo Laporte\n\nI was saying yesterday on Twitter, I think that, or maybe on Ask the Tech Guys the real reason I want sentient AI is because I feel like we humans have done such a terrible job. And it may be. Oh look, the numbers are multiplying. What does that mean? It's a countdown, leo. Oh, it's a countdown.\n\n0:03:02 - Jeff Jarvis\n\nThanks. I'm reading Mustafa Suleiman's book the Next Wave and I got to say Leo at one point. He goes on quite optimistically about the future. I regret being old.\n\n0:03:15 - Leo Laporte\n\nI think I'm not going to see all this. Oh, we'll see it. It's going to happen any minute now. Oh, it is. Huh, we're going to see it today, as we're going to see. You know, I think there's a very legitimate question about whether AI could ever achieve sentience, whether we'll ever have a singularity. I think that's still very much a question mark, but we're going to find out right now what OpenAI's got. It's time for Sam Altman's spring update. Let's watch.\n\n0:03:46 - Jeff Jarvis\n\nThe crocuses are blooming.\n\n0:03:52 - Leo Laporte\n\nOh, it's a small group gathered at their offices.\n\n0:03:55 - OpenAI Presentation\n\nThank you, it's great to have you here today. This is Mira Marotti.\n\n0:04:00 - Leo Laporte\n\nCTO. That's it, three things CTO.\n\n0:04:02 - OpenAI Presentation\n\nThat's it. We will start with why it's so important to us to have a product that we can make freely available and broadly available to everyone, and we're always trying to find out ways to reduce friction so everyone can use ChatGPT wherever they are. So today we'll be releasing the desktop version of ChatGP and the refreshed ui.\n\nthat makes it simpler to use, much more natural GPT-4o the big news today is that we are launching our new flagship model and we are calling it GPT-4o. The special thing about GPT-4o is that it brings GPT-4 level intelligence to everyone, including our free users. We'll be showing some live demos today to show the full extent of the capabilities of our new model and we'll be rolling them out intuitively over the next few weeks, all right, so let's get started.\n\nfew weeks, all right, so let's get started. A very important part of our mission is to be able to make our advanced AI tools available to everyone for free. We think it's very, very important that people have an intuitive feel for what the technology can do, and so we really want to pair it with this broader understanding. And we're always finding ways to reduce that friction. And recently we made ChildGPT available without the sign-up flow, and today we're also bringing the desktop app to ChildGPT, because we want you to be able to use it wherever you are. As you can see, it's easy's simple. It integrates very, very easily in your workflow. Along with it, we've also refreshed the UI. We know that these models get more and more complex, but we want the experience of interaction to actually become more natural, easy, and for you not to focus on the UI at all, but just focus on the collaboration which had GPT. And now the big news Today we are releasing our newest flagship model. This is GPT-4o. Woo.\n\n0:06:25 - Leo Laporte\n\nWoo, woo, yeah. Mira Maradi is the CTO of OpenAI and an Albanian engineer GPT-4o provides GPT-4-level intelligence, but it is much faster. Also a math wizard.\n\n0:06:38 - OpenAI Presentation\n\nAnd it improves on its capabilities across text, vision and audio. For the past couple of years, we've been very focused on improving the intelligence of these models, but this is the first time that we are really making a huge step forward when it comes to the ease of use, and this is incredibly important because we're looking at the future of interaction between ourselves and the machines.\n\n0:07:08 - Jeff Jarvis\n\nSo the free model was 3.5, right.\n\n0:07:11 - Leo Laporte\n\nYes, that's right.\n\n0:07:12 - OpenAI Presentation\n\nIt's really shifting that paradigm 4 is really good.\n\n0:07:15 - Leo Laporte\n\nI mean, 4 is kind of the gold standard for AI chatbots right now.\n\n0:07:22 - OpenAI Presentation\n\nBut you know, making this happen is actually quite complex because when we interact with one another, there's a lot of stuff that we take for granted. You know the ease of our dialogue when we interrupt one another.\n\n0:07:35 - Leo Laporte\n\nShe was also, when Sam Altman was briefly fired, the CEO of OpenAI. Briefly CEO, yes, briefly, like literally three days.\n\n0:07:44 - OpenAI Presentation\n\nAll of these things are actually quite complex for these models and until now, with voice mode, we had three models that come together to deliver this experience. We have transcription intelligence and then text-to-speech. All comes together in orchestration to deliver voice mode. This also brings a lot of latency to the experience and it really breaks that immersion in the collaboration which had gpt. But now with GPT-4o, this all happens natively.\n\nGpt 4.0 reasons across voice, text and vision, and with these incredible efficiencies, it also allows us to bring the GPT-4 class intelligence to our free users. This is something that we've been trying to do for many, many months and we're very, very excited to finally bring GPT-4o to all of our users. Today we have 100 million people more than 100 million in fact. They use ChatGPT to create, work, learn and we have these advanced tools that are only available to our paid users, at least until now. With the efficiencies of 4.0, we can bring these tools to everyone. So, starting today, you can use GPTs and the GPT store. So far, we've had more than a million users create amazing experiences with GPTs. These are custom chat GPTs for specific use cases. They're available in the store.\n\n0:09:34 - Leo Laporte\n\nAnd now our builders have a much bigger audience where university professors?\n\n0:09:39 - OpenAI Presentation\n\ncan create content for their students, or podcasters can create content for their listeners.\n\n0:09:45 - Leo Laporte\n\nWhat can we do? Oh you mean like a podcast?\n\n0:09:49 - OpenAI Presentation\n\nSo now you can upload screenshots, photos, documents containing both text and images and you can start conversations with ChatGPT about all of this content. You can also use memory, where it makes ChatGPT far more useful and helpful, because now it has a sense of continuity across all your conversations.\n\n0:10:12 - Jeff Jarvis\n\nYou still have to pay to get to the GPT store.\n\n0:10:14 - OpenAI Presentation\n\nAnd you can use browse where you can search for real-time information.\n\n0:10:18 - Leo Laporte\n\nThat's actually really what taught me the.\n\n0:10:20 - OpenAI Presentation\n\nAdvanced data analysis where you can. What was possible?\n\n0:10:24 - Leo Laporte\n\nwith an AI. This is AI companion that I created in ChatGPT.\n\n0:10:30 - OpenAI Presentation\n\nHad a walk on the beach.\n\n0:10:32 - Leo Laporte\n\nNo, no, yeah, come on.\n\n0:10:34 - OpenAI Presentation\n\nLastly, we have also improved on the quality and speed in 50 different languages for ChatGPT, and this is very, very important because we want to be able to bring this experience to as many people out there as possible I wonder how much?\n\n0:10:52 - Jeff Jarvis\n\ntraining, yeah exactly my question.\n\n0:10:55 - OpenAI Presentation\n\nYou'd almost have to retrain it completely for each language, I would think and for the paid users, they will continue to have up to five times the capacity limits.\n\n0:11:04 - Leo Laporte\n\nYou also have to remember that tomorrow is Google IO, and some of this is kind of to preempt.\n\n0:11:09 - OpenAI Presentation\n\nGoogle. It's not only available in ChatGPT, we're also bringing it to the API.\n\n0:11:18 - Leo Laporte\n\nSo these are all I'm sure in the audience open AI employees.\n\n0:11:22 - OpenAI Presentation\n\nSo our developers can start building today with GPT-4o and making amazing ai applications, deploying them at scale. 4.0 is available at 2x faster, 50 percent cheaper and five times higher rate limits compared to gpt for turbo that's a big deal because there are a lot of people using the api now for their apps, bring these technologies into the world.\n\n0:11:46 - Jeff Jarvis\n\nI just asked a question in German and it answered in German. Nice.\n\n0:11:50 - OpenAI Presentation\n\nSo in a way that's both useful and also safe, and GPT-4o presents new challenges for us when it comes to safety, because we're dealing with real-time audio real-time vision Forget safety. And our team has been hard at work figuring out how to build in mitigations, so we're just going to forget it.\n\n0:12:13 - Leo Laporte\n\nForget safety, which is impossible, yeah, and I think, also a waste of energy, and a number of AI research teams have decided not to worry about safety.\n\n0:12:26 - OpenAI Presentation\n\nI think this is political.\n\n0:12:27 - Jeff Jarvis\n\nYou can't anticipate every bad thing that anyone could ever do.\n\n0:12:29 - Leo Laporte\n\nThis is political. It's not technically necessary.\n\n0:12:36 - OpenAI Presentation\n\nBut today I want to show you all these capabilities, so we'll do some live demos. It's interesting I will bring on two of our research leads.\n\n0:12:45 - Leo Laporte\n\nAre we going to see Sam is the question I wonder, maybe only at the end.\n\n0:12:57 - OpenAI Presentation\n\nHi, I'm Barrett. Hey, I'm Mark Barrett.\n\n0:13:00 - OpenAI Presentation\n\nZoff and Mark Chen. One of the key capabilities we're really excited to share with you today is real-time conversational speech. Let's just get a demo fired up. So I'm taking out a phone If you are wondering about this, I already have it and if you see, there's this little icon on the bottom right of the ChatGPT app and this will open up GPT-4o's audio capabilities. Hey, ChatGPT, I'm Mark. How are you?\n\n0:13:26 - OpenAI Presentation\n\nOh, mark, I'm doing. Great Thanks for asking, how about you, hey?\n\n0:13:32 - OpenAI Presentation\n\nso she's sounding more and more like Scarlett.\n\n0:13:34 - Leo Laporte\n\nJohansson.\n\n0:13:35 - OpenAI Presentation\n\nAnd, frankly, I'm feeling a little bit nervous.\n\n0:13:36 - OpenAI Presentation\n\nCan you help me calm my nerves a little bit?\n\n0:13:39 - OpenAI Presentation\n\nEven that little oh, you're doing a live demo right now. That's awesome.\n\n0:13:43 - Jeff Jarvis\n\nKevin Ruse is scary. I have another new friend yeah.\n\n0:13:47 - Leo Laporte\n\nYou're the expert and I bet she loves me.\n\n0:13:50 - OpenAI Presentation\n\nLet me try a couple deep breaths. Can you give me feedback on my breaths? Okay, here I go, wow.\n\n0:13:56 - OpenAI Presentation\n\nWow, whoa slow, slow A little bit there. Mark, you're not a vacuum cleaner, breathe in or a count of four. Mark, you're not a vacuum cleaner, breathe in or a count of four.\n\n0:14:08 - OpenAI Presentation\n\nOkay, let me try again. So I'm going to breathe in deeply.\n\n0:14:15 - OpenAI Presentation\n\nAnd then breathe out and then exhale slowly.\n\n0:14:19 - OpenAI Presentation\n\nOkay, I'll try again. Breathing in and breathe out. That's it. How do you feel? I feel a lot better. Thank you so much.\n\n0:14:30 - OpenAI Presentation\n\nSo, Mark, you've been working on these capabilities for a while now. Can you tell us a bit how it's different from voice mode?\n\n0:14:37 - OpenAI Presentation\n\nRight. So if you've used our voice mode experience before, you'll notice a couple key differences which I have. First, you know you can now interrupt the model. You don't have to wait for it to finish your turn before you can start speaking, and you know you can just butt in whenever you want. Second, the model is real-time responsiveness, so that means that you don't have this awkward two to three second lag before you wait for the model to give a response. And finally, the model picks up on emotion. Right when I was breathing super hard there, it could tell and you, hey, you might want to calm down a little bit, you're kind of running a little bit too fast. So you know it really has that capability across the board to perceive your emotion. Not only that, though the model is able to generate a variety of different emotive styles, and it really has a wide dynamic range. So I'm going to fire up another demo for that.\n\n0:15:26 - Jeff Jarvis\n\nYeah, as Eric Schmidt would say, it crosses the creepy line, creepy line.\n\n0:15:31 - OpenAI Presentation\n\nThat's it. How are you doing?\n\n0:15:33 - OpenAI Presentation\n\nI'm doing fantastic. Thanks for asking. How about you? Oh jeez, that's crazy. Very fast.\n\n0:15:40 - OpenAI Presentation\n\nMuch faster, and I want you to tell him a bedtime story about robots and love.\n\n0:15:45 - OpenAI Presentation\n\nOh, a bedtime story about robots and love. I got you covered. Gather round, barrett. Once upon a time, in a world not too different from ours, there was a robot named Bite.\n\n0:15:59 - OpenAI Presentation\n\nBite was a curious robot, I think it's a little risky to have the AI sound so humanoid yes, I think it's a little risky to have the AI sound so humanoid.\n\n0:16:05 - Leo Laporte\n\nYes, because it really encourages anthropomorphizing something that is basically a machine process Bingo exactly by the way, this is someone I would hate to be next to on an airplane. Oh, you're having trouble breathing. Let me tell you a bedtime story. I'm fantastic Once upon a time, in a world not too different from ours Tone the prosody way down.\n\n0:16:33 - OpenAI Presentation\n\nCan you say this in a robotic voice?\n\n0:16:35 - OpenAI Presentation\n\nnow Initiating dramatic robotic voice Once upon a time, in a world not too different from ours.\n\n0:16:44 - Leo Laporte\n\nSo this sounds like a human imitating a robot. It does, but what it really is is a robot imitating a human imitating a robot.\n\n0:16:53 - OpenAI Presentation\n\nCan you end the story, but do it in a singing voice?\n\n0:16:57 - OpenAI Presentation\n\nOh no. And so I found another robot friend and he lived circuitly ever after oh, this is just. And lived circuitly ever after, oh great.\n\n0:17:07 - OpenAI Presentation\n\nThank you so much.\n\n0:17:09 - OpenAI Presentation\n\nI definitely feel a lot more relaxed.\n\n0:17:12 - Leo Laporte\n\nNot me, I don't. I feel a lot more nervous yeah.\n\n0:17:17 - OpenAI Presentation\n\nYou've just seen the voice capabilities, but we also want to show you the vision capabilities, as the model can also see the whole world around us.\n\n0:17:25 - OpenAI Presentation\n\nYeah, absolutely, as you can see, you know, you can chat with ChatGPT in real time, but you can also interact with it with video as well, okay.\n\n0:17:33 - Leo Laporte\n\nI'm sure this is the pitch that they gave Apple to replace Siri, hey, ChatGPT, and I'd be interested to see what Google does because they are, of course, positioning Gemini to replace Google Voice does, because they are, of course, positioning Gemini to replace Google Voice.\n\n0:17:47 - OpenAI Presentation\n\nI'm all ears. What math problem can I help you tackle today?\n\n0:17:51 - OpenAI Presentation\n\nSo I'm going to write down a linear equation on a sheet of paper and I'll show you, and then I'd love your help working me through it. But importantly, don't tell me the solution, just help give me hints along the way.\n\n0:18:00 - OpenAI Presentation\n\nGot it? Oh, okay, I see it.\n\n0:18:05 - OpenAI Presentation\n\nNo, I didn't show you yet. Just give me a little too scripted.\n\n0:18:13 - OpenAI Presentation\n\nI'm ready when you are how canned is that Leo?\n\n0:18:20 - Leo Laporte\n\nwell, I don't think it's canned.\n\n0:18:21 - OpenAI Presentation\n\nIn fact, I think there's accidents show that it's not canned unless they're planned accidents. What equation did I write down there?\n\n0:18:29 - OpenAI Presentation\n\nAh, I see it now. You wrote down 3x plus 1 equals 4.\n\n0:18:35 - OpenAI Presentation\n\nYep exactly. So what's the first step I should take to try to solve this?\n\n0:18:39 - OpenAI Presentation\n\nThe first step is to get all the terms, with x on one side and the constants on the other side.\n\n0:18:45 - Leo Laporte\n\nMostly, they're demonstrating how they can interrupt her. So what do you think?\n\n0:18:47 - OpenAI Presentation\n\nwe should do with that plus one.\n\n0:18:49 - Leo Laporte\n\nSo mansplainers are going to love this one.\n\n0:18:53 - OpenAI Presentation\n\nGreat idea, perfect. Now what do you get when you subtract one?\n\n0:18:59 - Leo Laporte\n\nTo some degree this feels like a bunch of incels in Silicon Valley desperate for a girlfriend. It's like weird science. They're inventing their new little buddy.\n\n0:19:11 - Jeff Jarvis\n\nWell, do you see Kevin Roos' story about making friends with all the various chats?\n\n0:19:16 - Leo Laporte\n\nKevin's going to knock that off. Yes, but it is something people want.\n\n0:19:25 - OpenAI Presentation\n\nNormals want, I guess. I'm dubious if this voice is what they actually do Close, but think of the opposite of multiplication.\n\n0:19:35 - Leo Laporte\n\nSee close, but I'm not no, that's just applying prosody. It's not hard to do. Google's been doing it for a long time with you. Know what was the name of the Google assistant called? And make reservations for you. Right, and note it's doing some of the same things going ah, ah, ooh. To cover the pauses, the thinking.\n\n0:19:54 - OpenAI Presentation\n\nSo ChatGPT, this is what I ended up with. How does this look?\n\n0:19:58 - OpenAI Presentation\n\nIt looks perfect. You've solved it, and X equals one. Nicely done. How do you feel about solving linear equations now?\n\n0:20:07 - OpenAI Presentation\n\nYeah, honestly, I'm not pretty confident. I can solve linear equations, but why would you ever need to use this in the real world? I'm really skeptical. I can solve linear equations, but why would you ever need to use this in the real world? I'm really skeptical.\n\n0:20:15 - Leo Laporte\n\nWell, if you're an eighth grade math student.\n\n0:20:17 - OpenAI Presentation\n\nLinear equations pop up in a lot of everyday situations, even if we don't realize it, for example, calculating expenses, planning, travel, cooking and even in business.\n\n0:20:28 - Jeff Jarvis\n\nWhen do you use it to calculate expenses?\n\n0:20:30 - OpenAI Presentation\n\nIt's basically a way to solve problems. You need to find an unknown. I did use it.\n\n0:20:36 - Leo Laporte\n\nI did use it in day 21 of Advent of Code.\n\n0:20:39 - OpenAI Presentation\n\nso I'm going to learn math, okay.\n\n0:20:43 - OpenAI Presentation\n\nIt comes up. I love that attitude. Math can definitely help solve some of life's mysteries. Whenever you're ready to dive into more math, I'm here for you. Anything else you'd like to tackle into more math, I'm here for you. Anything else you'd like to tackle today so ChatGPT, I really love that.\n\n0:20:56 - OpenAI Presentation\n\nYou, you know, taught the value of math to my friend mark and I wrote uh, one last thing I'd love if you could take a look at of course, I'd love to see what you wrote.\n\n0:21:05 - OpenAI Presentation\n\nShow it to me whenever you're ready okay, so this is this is they, they are going for her.\n\n0:21:21 - Leo Laporte\n\nThis was the kind of the rumor was they were going to do a her like interface.\n\n0:21:26 - OpenAI Presentation\n\nWow, like, like the spike jones movie, as we can see. You know we can chat in real time. Look, look up, chat you can interrupt it.\n\n0:21:37 - OpenAI Presentation\n\nIt's the most important thing we've heard. Look at Barrett's GPT-S3. It's all equations like this.\n\n0:21:42 - Jeff Jarvis\n\nI want a feminist perspective on this.\n\n0:21:45 - OpenAI Presentation\n\nCan you show us something more complex?\n\n0:21:47 - OpenAI Presentation\n\nI think so.\n\n0:21:49 - Leo Laporte\n\nCan you have a male voice Now? Obviously you'll be able to change voices and almost certainly be able to change the prosody. That's one of the things you can do. In the default prompts you can say talk like a normal person.\n\n0:22:02 - OpenAI Presentation\n\nLike Mira was talking about before.\n\n0:22:04 - Leo Laporte\n\nTalk like a normal machine.\n\n0:22:06 - OpenAI Presentation\n\nOkay, and to give a bit of background on what's going on. So here we have a computer and on the screen we have some code and then the ChatGPT voice app is on the right. So ChatGPT will be able to hear me, but it can't see anything on the screen. So I'm going to highlight the code, command C, and then that will send it to ChatGPT and then I'm going to talk about the code to ChatGPT.\n\n0:22:27 - OpenAI Presentation\n\nHey, ChatGPT, hey there.\n\n0:22:29 - OpenAI Presentation\n\nHow's it going? Yeah, it's going really well. I was wondering if you could help me with a coding problem today. This is actually Mark Chen's specialty.\n\n0:22:36 - OpenAI Presentation\n\nHe's using code to train LLMs.\n\n0:22:38 - OpenAI Presentation\n\nOkay, I'm going to share with you some code. One second.\n\n0:22:41 - OpenAI Presentation\n\nSure thing, take your time.\n\n0:22:44 - Leo Laporte\n\nAnd of course, this is what they're doing at GitHub, so I just shared some code with you Using. Openai.\n\n0:22:48 - OpenAI Presentation\n\nCan you give me a really brief, one-sentence description of what's going on in the code?\n\n0:22:52 - OpenAI Presentation\n\nThis code fetches daily weather data for a specific location and time period, smooths the temperature data using a rolling average, annotates a significant weather event on the resulting plot and then displays the plot with the average minimum and maximum temperatures over the year.\n\n0:23:08 - OpenAI Presentation\n\nThat's pretty cool. It is pretty cool Okay.\n\n0:23:10 - Leo Laporte\n\nThat's great, well done.\n\n0:23:11 - OpenAI Presentation\n\nThere's this function, foo. Can you describe to me what the plot would look like if I had versus, didn't have this function? Oh wow, sure.\n\n0:23:18 - OpenAI Presentation\n\nThe function foo x y takes in a data frame x containing temperature data and a window size y for calculating the rolling mean. It smooths the average temperature, minimum temperature and maximum temperature columns by applying a rolling mean over the specified window. With the foo function, the plot would show smoother temperature lines because the rolling mean reduces the noise or fluctuations in the data.\n\n0:23:44 - Leo Laporte\n\nAwesome.\n\n0:23:48 - OpenAI Presentation\n\nThanks so much.\n\n0:23:49 - OpenAI Presentation\n\nSo yeah, I definitely will apply this function Enough, I'm going to generate the plot and then show it to you.\n\n0:23:53 - OpenAI Presentation\n\nGive me one second Awesome, stop Enough. And so I'm going to generate the plot and then show it to you.\n\n0:23:55 - OpenAI Presentation\n\nGive me one second, absolutely. Take your time. I'm excited to see the plot when you're ready.\n\n0:23:59 - OpenAI Presentation\n\nI have all the time in the world, so our ChatGPT has only been able to see the code, and now I'm going to run it and then I'll use the overview of what you see.\n\n0:24:24 - OpenAI Presentation\n\nThe plot displays smoothed average minimum and maximum temperatures throughout 2018, with a notable annotation marking a big rainfall event in late September.\n\n0:24:36 - OpenAI Presentation\n\nFantastic. I have another question for you which months do you see the hottest temperatures, and roughly what temperatures do those correspond to?\n\n0:24:44 - OpenAI Presentation\n\nThe hottest temperatures occur around July and August.\n\n0:24:48 - Leo Laporte\n\nThis really reminds me of Apple's very famous Knowledge Navigator video. And 30 degrees In fact, I wonder if it's consciously aping it, because this was the promise 20, 30 years ago Of an assistant.\n\n0:25:06 - OpenAI Presentation\n\nThe temperatures are labeled accordingly, such as average temperature.\n\n0:25:10 - Leo Laporte\n\nIn that video, the AI was a gentleman with a bow tie.\n\n0:25:15 - OpenAI Presentation\n\nSo, as we can see, not only can ChatGPT help me solve very easy linear algebra equations that I need help with.\n\n0:25:21 - Leo Laporte\n\nIt is one of the very first things I did with 3.5 was show it regular expressions and say, hey, what the heck is this? And it was very good at that. So this is kind of a continuation of the same thing.\n\n0:25:35 - OpenAI Presentation\n\nA few minutes ago, we asked a live audience on X to submit a few requests for what they would like us to try out here. Yx, YX, YY, YY. So I will take a couple of prompts.\n\n0:25:46 - Leo Laporte\n\nAlthough it's a good way to get real-world feedback. Well, promotion.\n\n0:25:50 - Jeff Jarvis\n\nThe.\n\n0:25:50 - OpenAI Presentation\n\nQPT for O is capable of real-time translation. Mike, you want to try this one Sure.\n\n0:25:56 - OpenAI Presentation\n\nYeah, let's do it, I speak.\n\n0:25:57 - OpenAI Presentation\n\nItalian, so we can just do English-Italian.\n\n0:26:01 - Leo Laporte\n\nShe's from Albania, which is, I guess, a former Italian colony.\n\n0:26:05 - OpenAI Presentation\n\nHey chatGPT.\n\n0:26:05 - OpenAI Presentation\n\nHow are you? I'm doing fantastic. Thanks for asking. How about you? How's your day?\n\n0:26:10 - OpenAI Presentation\n\ngoing. I'm doing great. Thanks for asking how about you? How's your day going? I'm doing great. So I would like you to function as a translator. I have a friend here who only speaks Italian and I only speak English.\n\n0:26:20 - Leo Laporte\n\nAnd every time you hear English I want you to translate to Italian. It's a capability of course Google and Microsoft both have had in their translators for at least five years. Yeah.\n\n0:26:35 - OpenAI Presentation\n\nMike. She wonders if whales could talk. What would they tell us?\n\n0:26:40 - OpenAI Presentation\n\nThey might ask how do we solve linear equations?\n\n0:26:49 - OpenAI Presentation\n\nThat's pretty cool.\n\n0:26:52 - Leo Laporte\n\nThis is such a kind of standard demo now in Silicon Valley.\n\n0:26:56 - OpenAI Presentation\n\nGreat, it looks like it works.\n\n0:26:59 - Leo Laporte\n\nAnd almost certainly Google will be doing this tomorrow All right. Might as well show it.\n\n0:27:08 - Jeff Jarvis\n\nImagine somewhere in Googleplex they're rewriting script Right.\n\n0:27:13 - OpenAI Presentation\n\nBarrett, do you want to give?\n\n0:27:14 - Leo Laporte\n\nus some advicewriting the script Right, that's interesting, absolutely that's really interesting hey.\n\n0:27:22 - OpenAI Presentation\n\nChatGPT. Hey there, what's up? How can I help you today?\n\n0:27:25 - OpenAI Presentation\n\nOkay, yeah, so I'm going to show you a selfie of what I look like, and then I'd like you to try to see what emotions I'm feeling based on how I'm looking.\n\n0:27:33 - OpenAI Presentation\n\nSounds like a fun challenge. Go ahead and show me that selfie and I'll put my emotional detective hat on.\n\n0:27:39 - OpenAI Presentation\n\nOkay, so here's me. So what kind of emotions do you think I'm feeling?\n\n0:27:45 - OpenAI Presentation\n\nHmm, it seems like. I'm looking at a picture of a wooden surface.\n\n0:27:48 - OpenAI Presentation\n\nOh, you know what? That was the thing I sent you before. Don't worry, I'm not actually a table.\n\n0:27:56 - OpenAI Presentation\n\nOkay, so take another look that makes more sense, a wooden surface.\n\n0:28:01 - Leo Laporte\n\nThere we go. Well, he is rather wooden.\n\n0:28:03 - OpenAI Presentation\n\nYou're feeling pretty happy and cheerful, with a big smile and maybe even a touch of excitement.\n\n0:28:08 - Leo Laporte\n\nA human would not say this.\n\n0:28:09 - OpenAI Presentation\n\nIt seems like you're in a great mood.\n\n0:28:11 - OpenAI Presentation\n\nYou're filled with trepidation that this will fail no, the reason I'm in a really good mood, my smile is tight showcasing how useful and amazing you are you're a human trying to act human, stop it you're making me amazing.\n\n0:28:29 - OpenAI Presentation\n\nWell, that's it for today on live demos. As you can see, this just feels so magical and that's wonderful, but we also want to remove some of the mysticism from the technology.\n\n0:28:42 - Leo Laporte\n\nOne of our chatters in Discord. Pretty fly for us. This guy says you look like a career criminal. I'm alerting the authorities now.\n\n0:28:49 - OpenAI Presentation\n\nToday has been very much focused on the free users and the new modalities and new products, but we also care a lot about the next frontier.\n\n0:28:57 - Leo Laporte\n\nHello citizen.\n\n0:28:58 - OpenAI Presentation\n\nSo soon. We'll be updating you on our progress towards the next big thing. And before we wrap up, I just want to thank the incredible OpenAI team I got out of bed for this and the NVIDIA team for're bringing the most advanced GPUs to make this demo possible today, and thank you all very, very much A shout out to NVIDIA.\n\n0:29:23 - Leo Laporte\n\nVery interesting. Well, that was quick 20 minutes, 25 minutes and done, although I have to say I love the backdrop. Those offices look so nice.\n\n0:29:35 - Jeff Jarvis\n\nLeo, Leo, stop, stop. You don't want offices anymore. Offices are yesterday. No, what I want is your own garage. I'm going to have a green screen with that office.\n\n0:29:44 - Leo Laporte\n\nOh, all right, that's fine, yeah, a lot cheaper. So what do you think, jeff?\n\n0:29:49 - Jeff Jarvis\n\nShrug, so they took what they already have. They offered shrug, so they took what they already have. They offered it, uh, more to the public, which I think was a response to meta being so open. Um, they showed a voice thing that I still can't wait to actually hear it, to hear how much this was canned or not. Um, that seems um impressive. The coding stuff seems impressive. The, the emotional detection seems creepy, and I don't use that word often.\n\n0:30:15 - Leo Laporte\n\nWhat do you think? Yeah, I think creepy is a good word for it and really more of a parlor trick than something you'd want to use. I'm going to our singularity to see what they're talking about right now and so far no response to they're crying.\n\n0:30:36 - Jeff Jarvis\n\nThey're so disappointed. They thought they were going to get the future of.\n\n0:30:39 - Leo Laporte\n\nThey were really thinking this was going to be the there will be. I don't know, maybe not, but it seems to me there might be a day like any other, a normal day, where we get up and we watch one of these presentations and we say, oh my God, the singularity has happened. This is a real machine that is acting like that we can, seems to be exactly like a human. That was not today. In fact, this was almost cringy in its attempt to imitate humans, and I'll stand by what I said earlier, which is that's a bad direction to go, because it it, it. It's a lie, it's it's telling us the machine you're interacting with is a human and we're very tuned to that. I think they did a good job of simulating, as you said, a human. You really wouldn't want to sit next to on an airplane, but I don't know if that's the way we should be headed. To be honest, I couldn't agree more.\n\n0:31:38 - Jeff Jarvis\n\nI mean, emily Bender, one of the co-authors of the Stochastic Parents paper, talks about this often, that by trying to impugn humanity into the machine, it's all wrong, the information is all wrong. And she also points out that whenever we think, wow, the machine understood it. Um, it's not. Um, the machine that has meaning. We are imputing meaning in what we hear. It's made to fool us, to make us think there's meaning there, to think there's emotion there, to think there's a connection there, and um, that's that's going to lead to bad uses. And it's not as if this isn't an amazing machine that can do amazing things. It can. Yeah, that gets all messed up.\n\n0:32:21 - Leo Laporte\n\nI think, um, with this scheme of a human replacement and uh, honestly, I don't want it to look at my face and tell me what emotions, uh, I'm having. I think that's a very risky road to go down. I don't want it to look at my face and tell me what emotions I'm having. I think that's a very risky road to go down.\n\nI don't want human beings to do that. I know, tell me what my code's doing, but don't pretend to understand what's going on in my mind. From Reddit's subreddit on Singularity, grand Dork writes well, I'm happy for the normies, hopefully better stuff will come next update. I'm happy for the normies, hopefully better stuff will come next update. Pretending to be talking to her will be fun for a lot of people, but this update doesn't come anywhere near addressing the most glaring issues people have with GPT-4. Free users very excited and I understand that. The more that you give people for free, the better.\n\nImpressive voice to voice mode. You can now interrupt the model. Mid-sentence Voice is very impressive. Yes, I guess I mean, if what you're looking for is an imitated human actually has personality Cheery, as far as I can see from the demo Too. Cheery, yeah, oh, very cheeryery. Real-time audio and video is big. I agree with that. The uh lags that you normally see when interacting with chat gpt as a chatbot uh were much reduced. It seemed to be that may be actually the biggest thing that they did.\n\n0:33:47 - Jeff Jarvis\n\nYeah, I think, uh, which is not a not a huge deal, but it it does make a difference in that level of interaction.\n\n0:33:53 - Leo Laporte\n\nIt's interesting because somebody else pointed out the similarity to Apple's Knowledge Navigator video from 1987. So that is what 44 years ago. We have that and there is a link in Reddit if you want to see it. It's a video I've showed before. It's a video Apple made for the original TED conference back when they were in Monterey, back when they were okay, yeah, and the video really was. You know, it's like the AT&T, you Will videos. Here's what someday you'll be able to do. It was a laptop, probably something akin to Jeff Raskin's vision of a non-computer computer. It didn't have a keyboard. The little guy with a bow tie popped up and said here we go. Your mother called and if you skip ahead a little bit, you'll see the professor interacting with it, and one of the things he does is he's preparing a paper. Here we go.\n\n0:34:58 - OpenAI Presentation\n\nRight.\n\n0:35:03 - Jeff Jarvis\n\nOf course these days it'll give you sales on Amazon.\n\n0:35:09 - Leo Laporte\n\nIt's actually slower than ChatGPT.\n\n0:35:13 - Jeff Jarvis\n\nPull up all the new articles I haven't read yet.\n\n0:35:16 - Leo Laporte\n\nWe don't have to keep showing this. It's a good thing for you to watch because this is kind of what the vision at least Apple's vision was for an AI assistant of the future, and obviously you know this kind of thing informs the work people do, people do. Alan's AGI countdown, which has been at 72% since March, is now at 73%. That's his conservative countdown to AGI. Another person on the singularity subreddit says holy S, this is amazing. Yeah, voice-to-voice integration just dropped. Interesting In the ultimate troll. Openai delivers what the Gemini Ultra video faked, and that was the video you remember that I was so excited about but turned out to be a completely fake representation of what Gemini or, I'm sorry, gemini could do. We will see more tomorrow from Google. I hope they won't show us a fake like that.\n\n0:36:21 - Jeff Jarvis\n\nI hope not too. I haven't watched it yet. I was preparing to watch it for tomorrow. Sundar gave a half an hour interview, I think, to Businessweek.\n\n0:36:30 - OpenAI Presentation\n\nYeah.\n\n0:36:31 - Jeff Jarvis\n\nAnd said the one part that I did get to watch that was promoted that LLMs are not sufficient to get us where he imagines going. There's another, there are more leaps needed, and I've been thinking about this. Leo, I don't know whether it's possible to get to a sense of meaning, forget sentience and all that BS, just simply meaning. Is that something that a machine can do?\n\n0:37:04 - Leo Laporte\n\nBecause I don't know. I think in the coding demo was a very good example and admittedly, code is designed for machines to read. It was a good example of a chatbot kind of translating what the machine reads into something a human can understand. That's almost a translation job, I mean. I thought it was effective. It was quite good.\n\nI think people are upset at least our slash singularity, that it is not the singularity. I guess it was a little much to expect. Yeah, sorry, but they're making kind of generally making some good progress. I think Sundar Pichai is absolutely right. Llm is just one way that AIs work. There's neural networks, there's GAN, there's a lot of other things that you know, techniques for AI and eventually, at some point, what I think surprises everybody is how good the LLMs are at simulating human speech, conversation, music and art, better than anybody really expected from an LLM. But will it take us all the way to AGI? Can anything? I don't know. I think that Sundar is right. We're going to have to. We can't just say, oh, we got it. Llms, it's everything we need, it's not.\n\n0:38:23 - Jeff Jarvis\n\nWhen I went to that last World Economic Forum AI governance session in San Francisco, the AI pros in the room the true AI geniuses in the room scoff at the idea that LLMs and chat interfaces are some leap. It's a progression, a straight progression. The difference is that we who don't speak computer suddenly said, holy crap, we can speak to it and it can speak to us, and that seemed like to most of the world a huge leap. But it's not. It's a progression. And I'm not sure where we go.\n\n0:38:56 - Leo Laporte\n\nAnd I think that that's kind of what this demo was today. It wasn't for people who are really following what's going on in AI. That's why our singularity is disappointed. It was to show really a new interface to AI that normal people will perhaps embrace and get excited about. It's really wrapping paper on something that's not new and something that's been around for a long time, but it's important. I think I mean this is going to get a lot of attention. Watch tonight on the nightly news. You'll see some of this demo. In the weeks to come, there'll be a lot of YouTube videos with people talking to this new 4.0 version of chat GPT. It's not, by the way, but it's a new wrapping.\n\n0:39:46 - Jeff Jarvis\n\nYou still can't get to the 4.0 on the web interface. Oh interesting, so I was wrong before. I don't know what the deal is Did they did.\n\n0:39:52 - Leo Laporte\n\nThey say did they intimate when that would happen? I don't think they did.\n\n0:39:57 - Jeff Jarvis\n\nThey didn't, and the same for the web interface. I don't think they did. They didn't, and the same for the web interface. So I don't pay.\n\n0:40:02 - Leo Laporte\n\nOh well, let me see what I've got, because, I'm sad to say, do pay for all of these.\n\n0:40:09 - Jeff Jarvis\n\nLet me see Instead of buying actual gadgets you can touch, you now buy all those virtual stuff.\n\n0:40:13 - Leo Laporte\n\nI do I do and I like it. I'm very excited. All right, so I've got chat GPT-4. No, I don't see anything. No, 4.0. Besides chat GPT-4. Let me go into the settings and see if there's something in the settings that gives me more capability Personalization. They're talking about memory. You do have custom instructions and don't forget that you can say less cheery, more authoritative. They were using the voice. I believe they were using the voice that I use, called Ember. I don't think I see any new voices. It looks like the interface is exactly the same, so maybe that'll be coming later today or maybe weeks from now, I don't know.\n\nThey didn't really say um I have to say gemini is is also been very impressive.\n\nI will be very interested to see what google announces tomorrow. We'll be covering that 10 am pacific 1, 1 pm Eastern. Jeff will join me. We've also got Alex Kantrowitz from the Big Technology Podcast and Newsletter. He's an interesting fellow, both a supporter and a strong critic of big technology, so I will enjoy getting Alex's take on the Google IO keynote.\n\nIt will be this Week in Google for this week we're moving. This Week in Google and MacBreak Weekly we're flip-O keynote. It will be this week in Google for this week we're moving this week in Google and MacBreak Weekly we're flip-flopping. So MacBreak Weekly will be on Wednesday, which is good, because by then we should have the new iPads. We'll be able to show those. Jason Snell will by then certainly have the new iPad Pro. So that will be Wednesday afternoon instead of this week in Google, and this week in Google will be tomorrow instead of Mac break weekly and starting an hour early at 10 AM. Jeff, you'll be there. I look forward to comparing what Google is doing, you know, compared to what open AI is doing. I think, in summary, you and I both agree Open AI really didn't announce much except a better prosody on the speech which, yeah, you know, in the, in the final analysis might not even be a good idea, right, yeah?\n\n0:42:29 - Jeff Jarvis\n\nIn fact, it may not only just to our mind, but I think, to media, moral panicking media and legislators.\n\n0:42:40 - Leo Laporte\n\nIt could freak them out. It could freak them out, it might freak them out. That's a good point. I think they're hoping it will reassure them and it's just your little plastic pal who's fun to be with. Maybe you're right, maybe not. The other thing that I guess is fairly important is that they're moving ChatGPT4 into the free space, which I guess is preparatory to getting something like chat GPT-5 out to the paid space.\n\n0:43:05 - Jeff Jarvis\n\nWell, leo, I think that's a response to metaai. Absolutely, I think it's a spoiler.\n\n0:43:12 - Leo Laporte\n\nAnd Miramarati also started off at the very first saying we're open. You know, that's what we're about. We're about open development and it is in the name OpenAI. There's some debate about how open they've been lately. They certainly don't tell us how they train their LLMs. In fact, that's what Elon Musk has been upset about is that OpenAI has kind of become a closed for-profit operation. So it was interesting that they kind of implied that oh no, no, we're open. This is all about open development and that's why we're making ChatGPT-4o free. Let me ask you an elementary question.\n\n0:43:47 - Jeff Jarvis\n\nLeo, if I may, yeah, so with the various OpenLama models, I can take the entire model onto my machine and download it. That's right. I can't with any of the OpenAI.\n\n0:43:58 - Leo Laporte\n\nNo, what OpenAI does is gives you an API key, api right, and then you could put that in your software, but you're still making calls to the OpenAI servers. Where?\n\n0:44:09 - OpenAI Presentation\n\nthe work is done.\n\n0:44:10 - Leo Laporte\n\nWith Lama and Mistral and the other OpenLLMs. You download the model. You can tune it yourself. That's what I have tried to do to to duplicate what my custom gpt does um, and it's never quite as good, I'll be honest with you.\n\n0:44:26 - Jeff Jarvis\n\nOr as fast as what chat gpt is doing speed is truly interesting too, right you can also right yeah, is that just hardware, or is that because the model is is uh deprecated in some way? I'm doing it on what is that? Because the model is deprecated in some way?\n\n0:44:40 - Leo Laporte\n\nI'm doing it on what is currently the best consumer, I think, machine learning hardware, which is the Apple M3 Max. But you know, yeah, they have some pretty powerful NVIDIA GPUs working and they're a lot faster. I haven't tried it on a PC with an NVIDIA GPUs working and they're a lot faster. I haven't tried it on a PC with an NVIDIA card, and maybe probably our own. Anthony Nielsen, who's our resident AI buff, has tried that. I don't know if it's much faster Local, you know local is to be desired, for sure it's what we want. But I think ChatGPT in fact, I think what's going on is even today was OpenAI showing, yeah, you can do it locally, but we're so much faster and we've got Scarlett Johansson's voice and things like that.\n\n0:45:33 - Jeff Jarvis\n\nScarlett Johansson on some extra to see, but yes, yeah, very happy, very happy, Scott."
    }
}