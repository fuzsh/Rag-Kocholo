{
    "id": "dbpedia_6855_3",
    "rank": 14,
    "data": {
        "url": "https://mne.tools/stable/generated/mne.io.Raw.html",
        "read_more_link": "",
        "language": "en",
        "title": "mne.io.Raw — MNE 1.7.1 documentation",
        "top_image": "https://mne.tools/stable/_static/favicon.ico",
        "meta_img": "https://mne.tools/stable/_static/favicon.ico",
        "images": [
            "https://mne.tools/stable/_static/mne_logo_small.svg",
            "https://mne.tools/stable/_images/sphx_glr_find_ref_artifacts_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eog_artifact_histogram_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_45_projectors_background_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_50_artifact_correction_ssp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_make_fixed_length_epochs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_90_compute_covariance_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_simulate_evoked_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_temporal_whitening_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_kernel_phantom_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_50_artifact_correction_ssp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_make_fixed_length_epochs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_visualize_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_preprocessing_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_filtering_resampling_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_50_artifact_correction_ssp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_59_head_positions_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_spectrum_class_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_80_brainstorm_phantom_elekta_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eeg_csd_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_find_ref_artifacts_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_topo_customized_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_events_from_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_annotate_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_handling_bad_channels_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_filtering_resampling_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_45_projectors_background_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_55_setting_eeg_reference_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_maxwell_filtering_sss_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_baseline_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_publication_figure_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_find_ref_artifacts_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_otp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_events_from_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_event_arrays_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_annotate_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_visualize_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_preprocessing_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_handling_bad_channels_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_rejecting_bad_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_filtering_resampling_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_45_projectors_background_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_55_setting_eeg_reference_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_59_head_positions_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_maxwell_filtering_sss_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_make_fixed_length_epochs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_eeg_erp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_sensors_time_frequency_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_epochs_metadata_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_otp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_preprocessing_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_rejecting_bad_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_50_artifact_correction_ssp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_55_setting_eeg_reference_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_kernel_phantom_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_25_background_filtering_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_filtering_resampling_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_35_artifact_correction_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_artifact_correction_ica_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_autogenerate_metadata_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_eeg_erp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_75_cluster_ftest_spatiotemporal_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eog_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_ica_comparison_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_otp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_xdawn_denoising_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_3d_to_2d_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_evoked_whitening_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_topo_customized_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_linear_regression_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_decoding_spatio_temporal_source_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_decoding_time_generalization_conditions_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_decoding_unsupervised_spatial_filter_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_decoding_xdawn_eeg_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_ems_filtering_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_kernel_phantom_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_info_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_rejecting_bad_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_filtering_resampling_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_publication_figure_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_3d_to_2d_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_35_artifact_correction_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_50_artifact_correction_ssp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_3d_to_2d_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_evoked_ers_source_power_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_report_thumb.svg",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_rejecting_bad_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_35_artifact_correction_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_artifact_correction_ica_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_55_setting_eeg_reference_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_maxwell_filtering_sss_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_baseline_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_eeg_erp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_eeg_mri_coords_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_publication_figure_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eeg_csd_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_3d_to_2d_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_linear_regression_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_ems_filtering_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_multi_dipole_model_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_kernel_phantom_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_events_from_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_reading_eyetracking_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_event_arrays_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_annotate_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_visualize_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_preprocessing_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_handling_bad_channels_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_rejecting_bad_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_filtering_resampling_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_35_artifact_correction_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_45_projectors_background_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_50_artifact_correction_ssp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_55_setting_eeg_reference_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_autogenerate_metadata_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_eeg_erp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_whitened_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_80_brainstorm_phantom_elekta_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eeg_csd_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_find_ref_artifacts_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_movement_compensation_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_otp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_visualize_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_sensor_locations_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_visualize_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_eeg_erp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_eeg_mri_coords_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_eeg_erp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_find_ref_artifacts_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_filtering_resampling_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_events_from_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_annotate_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_rejecting_bad_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_reading_eeg_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_35_artifact_correction_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_55_setting_eeg_reference_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_90_compute_covariance_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_eeg_mri_coords_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_point_spread_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_simulate_raw_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eeg_csd_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_compute_mne_inverse_raw_in_label_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_sensor_locations_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_reading_eeg_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_eeg_mri_coords_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_compute_mne_inverse_raw_in_label_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_inplace_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_events_from_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_info_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_sensor_locations_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_report_thumb.svg",
            "https://mne.tools/stable/_images/sphx_glr_20_reading_eeg_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_ctf_bst_auditory_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_raw_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_event_arrays_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_annotate_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_visualize_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_preprocessing_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_handling_bad_channels_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_rejecting_bad_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_filtering_resampling_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_35_artifact_correction_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_artifact_correction_ica_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_45_projectors_background_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_50_artifact_correction_ssp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_55_setting_eeg_reference_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_59_head_positions_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_maxwell_filtering_sss_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_15_baseline_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_visualize_epochs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_autogenerate_metadata_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_make_fixed_length_epochs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_evoked_overview_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_30_eeg_erp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_whitened_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_spectrum_class_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_sensors_time_frequency_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_source_alignment_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_90_compute_covariance_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_eeg_mri_coords_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_80_brainstorm_phantom_elekta_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_40_cluster_1samp_time_freq_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_50_cluster_between_time_freq_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_cluster_rmANOVA_time_freq_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_75_cluster_ftest_spatiotemporal_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_cluster_1samp_spatiotemporal_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_60_cluster_rmANOVA_spatiotemporal_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_20_seeg_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_array_objs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_70_point_spread_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_10_publication_figure_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_elekta_epochs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_read_neo_format_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_simulate_evoked_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_simulate_raw_data_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_css_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_define_target_events_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eeg_csd_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eog_artifact_histogram_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eog_regression_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_epochs_metadata_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_find_ref_artifacts_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_ica_comparison_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_movement_compensation_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_otp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_xdawn_denoising_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_3d_to_2d_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_channel_epochs_image_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_eeg_on_scalp_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_evoked_whitening_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_topo_compare_conditions_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_topo_customized_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_compute_csd_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_compute_source_psd_epochs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_source_label_time_frequency_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_source_power_spectrum_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_source_space_time_frequency_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_temporal_whitening_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_cluster_stats_evoked_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_fdr_stats_evoked_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_linear_regression_raw_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_sensor_permutation_test_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_decoding_spatio_temporal_source_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_decoding_time_generalization_conditions_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_decoding_unsupervised_spatial_filter_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_decoding_xdawn_eeg_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_ems_filtering_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_compute_mne_inverse_epochs_in_label_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_compute_mne_inverse_raw_in_label_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_dics_epochs_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_evoked_ers_source_power_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_multi_dipole_model_thumb.png",
            "https://mne.tools/stable/_images/sphx_glr_kernel_phantom_thumb.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-07-02T04:32:46.875116+00:00",
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "../_static/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://mne.tools/stable/index.html",
        "text": "mne.io.Raw#\n\nclassmne.io.Raw(fname, allow_maxshield=False, preload=False, on_split_missing='raise', verbose=None)[source]#\n\nRaw data in FIF format.\n\nParameters:\n\nfnamepath-like | file-like\n\nThe raw filename to load. For files that have automatically been split, the split part will be automatically loaded. Filenames not ending with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, or _ieeg.fif (with or without an optional additional .gz extension) will generate a warning. If a file-like object is provided, preloading must be used.\n\nChanged in version 0.18: Support for file-like objects.\n\nallow_maxshieldbool | str (default False)\n\nIf True, allow loading of data that has been recorded with internal active compensation (MaxShield). Data recorded with MaxShield should generally not be loaded directly, but should first be processed using SSS/tSSS to remove the compensation signals that may also affect brain activity. Can also be “yes” to load without eliciting a warning.\n\npreloadbool or str (default False)\n\nPreload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory).\n\non_split_missingstr\n\nCan be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when split file is missing.\n\nNew in v0.22.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nAttributes:\n\ninfomne.Info\n\nThe mne.Info object with information about the sensors and methods of measurement.\n\nch_nameslist of str\n\nChannel names.\n\nn_timesint\n\nNumber of time points.\n\ntimesndarray\n\nTime points.\n\npreloadbool\n\nIndicates whether raw data are in memory.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nMethods\n\n__contains__(ch_type)\n\nCheck channel type membership.\n\n__getitem__(item)\n\nGet raw data and times.\n\n__len__()\n\nReturn the number of time points.\n\nadd_channels(add_list[, force_update_info])\n\nAppend new channels to the instance.\n\nadd_events(events[, stim_channel, replace])\n\nAdd events to stim channel.\n\nadd_proj(projs[, remove_existing, verbose])\n\nAdd SSP projection vectors.\n\nadd_reference_channels(ref_channels)\n\nAdd reference channels to data that consists of all zeros.\n\nanonymize([daysback, keep_his, verbose])\n\nAnonymize measurement information in place.\n\nappend(raws[, preload])\n\nConcatenate raw instances as if they were continuous.\n\napply_function(fun[, picks, dtype, n_jobs, ...])\n\nApply a function to a subset of channels.\n\napply_gradient_compensation(grade[, verbose])\n\nApply CTF gradient compensation.\n\napply_hilbert([picks, envelope, n_jobs, ...])\n\nCompute analytic signal or envelope for a subset of channels/vertices.\n\napply_proj([verbose])\n\nApply the signal space projection (SSP) operators to the data.\n\nclose()\n\nClean up the object.\n\ncompute_psd([method, fmin, fmax, tmin, ...])\n\nPerform spectral analysis on sensor data.\n\ncompute_tfr(method, freqs, *[, tmin, tmax, ...])\n\nCompute a time-frequency representation of sensor data.\n\ncopy()\n\nReturn copy of Raw instance.\n\ncrop([tmin, tmax, include_tmax, verbose])\n\nCrop raw data file.\n\ncrop_by_annotations([annotations, verbose])\n\nGet crops of raw data file for selected annotations.\n\ndel_proj([idx])\n\nRemove SSP projection vector.\n\ndescribe([data_frame])\n\nDescribe channels (name, type, descriptive statistics).\n\ndrop_channels(ch_names[, on_missing])\n\nDrop channel(s).\n\nexport(fname[, fmt, physical_range, ...])\n\nExport Raw to external formats.\n\nfilter(l_freq, h_freq[, picks, ...])\n\nFilter a subset of channels/vertices.\n\nfix_mag_coil_types()\n\nFix Elekta magnetometer coil types.\n\nget_channel_types([picks, unique, only_data_chs])\n\nGet a list of channel type for each channel.\n\nget_data([picks, start, stop, ...])\n\ninterpolate_bads([reset_bads, mode, origin, ...])\n\nInterpolate bad MEG and EEG channels.\n\nload_data([verbose])\n\nLoad raw data.\n\nnotch_filter(freqs[, picks, filter_length, ...])\n\nNotch filter a subset of channels.\n\npick(picks[, exclude, verbose])\n\nPick a subset of channels.\n\npick_channels(ch_names[, ordered, verbose])\n\nWarning\n\nLEGACY: New code should use inst.pick(...).\n\npick_types([meg, eeg, stim, eog, ecg, emg, ...])\n\nWarning\n\nLEGACY: New code should use inst.pick(...).\n\nplot([events, duration, start, n_channels, ...])\n\nPlot raw data.\n\nplot_projs_topomap([ch_type, sensors, ...])\n\nPlot SSP vector.\n\nplot_psd([fmin, fmax, tmin, tmax, picks, ...])\n\nWarning\n\nLEGACY: New code should use .compute_psd().plot().\n\nplot_psd_topo([tmin, tmax, fmin, fmax, ...])\n\nWarning\n\nLEGACY: New code should use .compute_psd().plot_topo().\n\nplot_psd_topomap([bands, tmin, tmax, ...])\n\nWarning\n\nLEGACY: New code should use .compute_psd().plot_topomap().\n\nplot_sensors([kind, ch_type, title, ...])\n\nPlot sensor positions.\n\nrename_channels(mapping[, allow_duplicates, ...])\n\nRename channels.\n\nreorder_channels(ch_names)\n\nReorder channels.\n\nresample(sfreq, *[, npad, window, ...])\n\nResample all channels.\n\nsave(fname[, picks, tmin, tmax, ...])\n\nSave raw data to file.\n\nsavgol_filter(h_freq[, verbose])\n\nFilter the data using Savitzky-Golay polynomial method.\n\nset_annotations(annotations[, emit_warning, ...])\n\nSetter for annotations.\n\nset_eeg_reference([ref_channels, ...])\n\nSpecify which reference to use for EEG data.\n\nset_meas_date(meas_date)\n\nSet the measurement start date.\n\nset_montage(montage[, match_case, ...])\n\nSet EEG/sEEG/ECoG/DBS/fNIRS channel positions and digitization points.\n\ntime_as_index(times[, use_rounding, origin])\n\nConvert time to indices.\n\nto_data_frame([picks, index, scalings, ...])\n\nExport data in tabular structure as a pandas DataFrame.\n\n__contains__(ch_type)[source]#\n\nCheck channel type membership.\n\nParameters:\n\nch_typestr\n\nChannel type to check for. Can be e.g. 'meg', 'eeg', 'stim', etc.\n\nReturns:\n\ninbool\n\nWhether or not the instance contains the given channel type.\n\nExamples\n\nChannel type membership can be tested as:\n\n>>> 'meg' in inst True >>> 'seeg' in inst False\n\n__getitem__(item)[source]#\n\nGet raw data and times.\n\nParameters:\n\nitemtuple or array_like\n\nSee below for use cases.\n\nReturns:\n\ndatandarray, shape (n_channels, n_times)\n\nThe raw data.\n\ntimesndarray, shape (n_times,)\n\nThe times associated with the data.\n\nExamples\n\nGenerally raw data is accessed as:\n\n>>> data, times = raw[picks, time_slice]\n\nTo get all data, you can thus do either of:\n\n>>> data, times = raw[:]\n\nWhich will be equivalent to:\n\n>>> data, times = raw[:, :]\n\nTo get only the good MEG data from 10-20 seconds, you could do:\n\n>>> picks = mne.pick_types(raw.info, meg=True, exclude='bads') >>> t_idx = raw.time_as_index([10., 20.]) >>> data, times = raw[picks, t_idx[0]:t_idx[1]]\n\n__len__()[source]#\n\nReturn the number of time points.\n\nReturns:\n\nlenint\n\nThe number of time points.\n\nExamples\n\nThis can be used as:\n\n>>> len(raw) 1000\n\npropertyacqparser#\n\nThe AcqParserFIF for the measurement info.\n\nSee also\n\nmne.AcqParserFIF\n\nadd_channels(add_list, force_update_info=False)[source]#\n\nAppend new channels to the instance.\n\nParameters:\n\nadd_listlist\n\nA list of objects to append to self. Must contain all the same type as the current object.\n\nforce_update_infobool\n\nIf True, force the info for objects to be appended to match the values in self. This should generally only be used when adding stim channels for which important metadata won’t be overwritten.\n\nNew in v0.12.\n\nReturns:\n\ninstinstance of Raw, Epochs, or Evoked\n\nThe modified instance.\n\nSee also\n\ndrop_channels\n\nNotes\n\nIf self is a Raw instance that has been preloaded into a numpy.memmap instance, the memmap will be resized.\n\nExamples using add_channels:\n\nFind MEG reference channel artifacts\n\nFind MEG reference channel artifacts\n\nadd_events(events, stim_channel=None, replace=False)[source]#\n\nAdd events to stim channel.\n\nParameters:\n\neventsndarray, shape (n_events, 3)\n\nEvents to add. The first column specifies the sample number of each event, the second column is ignored, and the third column provides the event value. If events already exist in the Raw instance at the given sample numbers, the event values will be added together.\n\nstim_channelstr | None\n\nName of the stim channel to add to. If None, the config variable ‘MNE_STIM_CHANNEL’ is used. If this is not found, it will default to 'STI 014'.\n\nreplacebool\n\nIf True the old events on the stim channel are removed before adding the new ones.\n\nNotes\n\nData must be preloaded in order to add events.\n\nExamples using add_events:\n\nShow EOG artifact timing\n\nShow EOG artifact timing\n\nadd_proj(projs, remove_existing=False, verbose=None)[source]#\n\nAdd SSP projection vectors.\n\nParameters:\n\nprojslist\n\nList with projection vectors.\n\nremove_existingbool\n\nRemove the projection vectors currently in the file.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nselfinstance of Raw | Epochs | Evoked\n\nThe data container.\n\nExamples using add_proj:\n\nBackground on projectors and projections\n\nBackground on projectors and projections\n\nRepairing artifacts with SSP\n\nRepairing artifacts with SSP\n\nDivide continuous data into equally-spaced epochs\n\nDivide continuous data into equally-spaced epochs\n\nComputing a covariance matrix\n\nComputing a covariance matrix\n\nGenerate simulated evoked data\n\nGenerate simulated evoked data\n\nTemporal whitening with AR model\n\nTemporal whitening with AR model\n\nKernel OPM phantom data\n\nKernel OPM phantom data\n\nadd_reference_channels(ref_channels)[source]#\n\nAdd reference channels to data that consists of all zeros.\n\nAdds reference channels to data that were not included during recording. This is useful when you need to re-reference your data to different channels. These added channels will consist of all zeros.\n\nParameters:\n\nref_channelsstr | list of str\n\nName of the electrode(s) which served as the reference in the recording. If a name is provided, a corresponding channel is added and its data is set to 0. This is useful for later re-referencing.\n\nReturns:\n\ninstinstance of Raw | Epochs | Evoked\n\nThe modified instance.\n\npropertyannotations#\n\nAnnotations for marking segments of data.\n\nanonymize(daysback=None, keep_his=False, verbose=None)[source]#\n\nAnonymize measurement information in place.\n\nParameters:\n\ndaysbackint | None\n\nNumber of days to subtract from all dates. If None (default), the acquisition date, info['meas_date'], will be set to January 1ˢᵗ, 2000. This parameter is ignored if info['meas_date'] is None (i.e., no acquisition date has been set).\n\nkeep_hisbool\n\nIf True, his_id of subject_info will not be overwritten. Defaults to False.\n\nWarning\n\nThis could mean that info is not fully anonymized. Use with caution.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\ninstinstance of Raw | Epochs | Evoked\n\nThe modified instance.\n\nNotes\n\nRemoves potentially identifying information if it exists in info. Specifically for each of the following we use:\n\nmeas_date, file_id, meas_id\n\nA default value, or as specified by daysback.\n\nsubject_info\n\nDefault values, except for ‘birthday’ which is adjusted to maintain the subject age.\n\nexperimenter, proj_name, description\n\nDefault strings.\n\nutc_offset\n\nNone.\n\nproj_id\n\nZeros.\n\nproc_history\n\nDates use the meas_date logic, and experimenter a default string.\n\nhelium_info, device_info\n\nDates use the meas_date logic, meta info uses defaults.\n\nIf info['meas_date'] is None, it will remain None during processing the above fields.\n\nOperates in place.\n\nNew in v0.13.0.\n\nappend(raws, preload=None)[source]#\n\nConcatenate raw instances as if they were continuous.\n\nNote\n\nBoundaries of the raw files are annotated bad. If you wish to use the data as continuous recording, you can remove the boundary annotations after concatenation (see mne.Annotations.delete()).\n\nParameters:\n\nrawslist, or Raw instance\n\nList of Raw instances to concatenate to the current instance (in order), or a single raw instance to concatenate.\n\npreloadbool, str, or None (default None)\n\nPreload data into memory for data manipulation and faster indexing. If True, the data will be preloaded into memory (fast, requires large amount of memory). If preload is a string, preload is the file name of a memory-mapped file which is used to store the data on the hard drive (slower, requires less memory). If preload is None, preload=True or False is inferred using the preload status of the instances passed in.\n\nExamples using append:\n\nThe Raw data structure: continuous data\n\nThe Raw data structure: continuous data\n\napply_function(fun, picks=None, dtype=None, n_jobs=None, channel_wise=True, verbose=None, **kwargs)[source]#\n\nApply a function to a subset of channels.\n\nThe function fun is applied to the channels or vertices defined in picks. The raw object’s data is modified in-place. If the function returns a different data type (e.g. numpy.complex128) it must be specified using the dtype parameter, which causes the data type of all the data to change (even if the function is only applied to channels/vertices in picks). The object has to have the data loaded e.g. with preload=True or self.load_data().\n\nNote\n\nIf n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.\n\nNote\n\nIf the data type changes (dtype != None), more memory is required since the original and the converted data needs to be stored in memory.\n\nParameters:\n\nfuncallable()\n\nA function to be applied to the channels. The first argument of fun has to be a timeseries (numpy.ndarray). The function must operate on an array of shape (n_times,) if channel_wise=True and (len(picks), n_times) otherwise. The function must return an ndarray shaped like its input.\n\nNote\n\nIf channel_wise=True, one can optionally access the index and/or the name of the currently processed channel within the applied function. This can enable tailored computations for different channels. To use this feature, add ch_idx and/or ch_name as additional argument(s) to your function definition.\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\ndtypenumpy.dtype\n\nData type to use after applying the function. If None (default) the data type is not modified.\n\nn_jobsint | None\n\nThe number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs. Ignored if channel_wise=False as the workload is split across channels.\n\nchannel_wisebool\n\nWhether to apply the function to each channel individually. If False, the function will be applied to all channels at once. Default True.\n\nNew in v0.18.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\n**kwargsdict\n\nAdditional keyword arguments to pass to fun.\n\nReturns:\n\nselfinstance of Raw\n\nThe raw object with transformed data.\n\nExamples using apply_function:\n\nModifying data in-place\n\nModifying data in-place\n\napply_gradient_compensation(grade, verbose=None)[source]#\n\nApply CTF gradient compensation.\n\nWarning\n\nThe compensation matrices are stored with single precision, so repeatedly switching between different of compensation (e.g., 0->1->3->2) can increase numerical noise, especially if data are saved to disk in between changing grades. It is thus best to only use a single gradient compensation level in final analyses.\n\nParameters:\n\ngradeint\n\nCTF gradient compensation level.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nrawinstance of Raw\n\nThe modified Raw instance. Works in-place.\n\napply_hilbert(picks=None, envelope=False, n_jobs=None, n_fft='auto', *, verbose=None)[source]#\n\nCompute analytic signal or envelope for a subset of channels/vertices.\n\nParameters:\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick all data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nenvelopebool\n\nCompute the envelope signal of each channel/vertex. Default False. See Notes.\n\nn_jobsint | None\n\nThe number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.\n\nn_fftint | None | str\n\nPoints to use in the FFT for Hilbert transformation. The signal will be padded with zeros before computing Hilbert, then cut back to original length. If None, n == self.n_times. If ‘auto’, the next highest fast FFT length will be use.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nselfinstance of Raw, Epochs, Evoked or SourceEstimate\n\nThe raw object with transformed data.\n\nNotes\n\nParameters\n\nIf envelope=False, the analytic signal for the channels/vertices defined in picks is computed and the data of the Raw object is converted to a complex representation (the analytic signal is complex valued).\n\nIf envelope=True, the absolute value of the analytic signal for the channels/vertices defined in picks is computed, resulting in the envelope signal.\n\nIf envelope=False, more memory is required since the original raw data as well as the analytic signal have temporarily to be stored in memory. If n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.\n\nAlso note that the n_fft parameter will allow you to pad the signal with zeros before performing the Hilbert transform. This padding is cut off, but it may result in a slightly different result (particularly around the edges). Use at your own risk.\n\nAnalytic signal\n\nThe analytic signal “x_a(t)” of “x(t)” is:\n\nx_a = F^{-1}(F(x) 2U) = x + i y\n\nwhere “F” is the Fourier transform, “U” the unit step function, and “y” the Hilbert transform of “x”. One usage of the analytic signal is the computation of the envelope signal, which is given by “e(t) = abs(x_a(t))”. Due to the linearity of Hilbert transform and the MNE inverse solution, the enevlope in source space can be obtained by computing the analytic signal in sensor space, applying the MNE inverse, and computing the envelope in source space.\n\nExamples using apply_hilbert:\n\nModifying data in-place\n\nModifying data in-place\n\napply_proj(verbose=None)[source]#\n\nApply the signal space projection (SSP) operators to the data.\n\nParameters:\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nselfinstance of Raw | Epochs | Evoked\n\nThe instance.\n\nNotes\n\nOnce the projectors have been applied, they can no longer be removed. It is usually not recommended to apply the projectors at too early stages, as they are applied automatically later on (e.g. when computing inverse solutions). Hint: using the copy method individual projection vectors can be tested without affecting the original data. With evoked data, consider the following example:\n\nprojs_a = mne.read_proj('proj_a.fif') projs_b = mne.read_proj('proj_b.fif') # add the first, copy, apply and see ... evoked.add_proj(a).copy().apply_proj().plot() # add the second, copy, apply and see ... evoked.add_proj(b).copy().apply_proj().plot() # drop the first and see again evoked.copy().del_proj(0).apply_proj().plot() evoked.apply_proj() # finally keep both\n\nExamples using apply_proj:\n\nRepairing artifacts with SSP\n\nRepairing artifacts with SSP\n\nDivide continuous data into equally-spaced epochs\n\nDivide continuous data into equally-spaced epochs\n\npropertych_names#\n\nChannel names.\n\nclose()[source]#\n\nClean up the object.\n\nDoes nothing for objects that close their file descriptors. Things like Raw will override this method.\n\npropertycompensation_grade#\n\nThe current gradient compensation grade.\n\ncompute_psd(method='welch', fmin=0, fmax=inf, tmin=None, tmax=None, picks=None, exclude=(), proj=False, remove_dc=True, reject_by_annotation=True, *, n_jobs=1, verbose=None, **method_kw)[source]#\n\nPerform spectral analysis on sensor data.\n\nParameters:\n\nmethod'welch' | 'multitaper'\n\nSpectral estimation method. 'welch' uses Welch’s method , 'multitaper' uses DPSS tapers . Note that \"multitaper\" cannot be used if reject_by_annotation=True and there are \"bad_*\" annotations in the Raw data; in such cases use \"welch\". Default is 'welch'.\n\nfmin, fmaxfloat\n\nThe lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).\n\ntmin, tmaxfloat | None\n\nFirst and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nexcludelist of str | ‘bads’\n\nChannel names to exclude. If 'bads', channels in info['bads'] are excluded; pass an empty list to include all channels (including “bad” channels, if any).\n\nprojbool\n\nWhether to apply SSP projection vectors before spectral estimation. Default is False.\n\nremove_dcbool\n\nIf True, the mean is subtracted from each segment before computing its spectrum.\n\nreject_by_annotationbool\n\nWhether to omit bad spans of data before spectral estimation. If True, spans with annotations whose description begins with bad will be omitted.\n\nn_jobsint | None\n\nThe number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\n**method_kw\n\nAdditional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details.\n\nReturns:\n\nspectruminstance of Spectrum\n\nThe spectral representation of the data.\n\nNotes\n\nNew in v1.2.\n\nReferences\n\nExamples using compute_psd:\n\nOverview of MEG/EEG analysis with MNE-Python\n\nOverview of MEG/EEG analysis with MNE-Python\n\nBuilt-in plotting methods for Raw objects\n\nBuilt-in plotting methods for Raw objects\n\nOverview of artifact detection\n\nOverview of artifact detection\n\nFiltering and resampling data\n\nFiltering and resampling data\n\nRepairing artifacts with SSP\n\nRepairing artifacts with SSP\n\nExtracting and visualizing subject head movement\n\nExtracting and visualizing subject head movement\n\nThe Spectrum and EpochsSpectrum classes: frequency-domain data\n\nThe Spectrum and EpochsSpectrum classes: frequency-domain data\n\nBrainstorm Elekta phantom dataset tutorial\n\nBrainstorm Elekta phantom dataset tutorial\n\nTransform EEG data using current source density (CSD)\n\nTransform EEG data using current source density (CSD)\n\nFind MEG reference channel artifacts\n\nFind MEG reference channel artifacts\n\nPlot custom topographies for MEG sensors\n\nPlot custom topographies for MEG sensors\n\ncompute_tfr(method, freqs, *, tmin=None, tmax=None, picks=None, proj=False, output='power', reject_by_annotation=True, decim=1, n_jobs=None, verbose=None, **method_kw)[source]#\n\nCompute a time-frequency representation of sensor data.\n\nParameters:\n\nmethod'morlet' | 'multitaper' | None\n\nSpectrotemporal power estimation method. 'morlet' uses Morlet wavelets, 'multitaper' uses DPSS tapers . None (the default) only works when using __setstate__ and will raise an error otherwise.\n\nfreqsarray_like | None\n\nThe frequencies at which to compute the power estimates. Must be an array of shape (n_freqs,). None (the default) only works when using __setstate__ and will raise an error otherwise.\n\ntmin, tmaxfloat | None\n\nFirst and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nprojbool\n\nWhether to apply SSP projection vectors before spectral estimation. Default is False.\n\noutputstr\n\nWhat kind of estimate to return. Allowed values are \"complex\", \"phase\", and \"power\". Default is \"power\".\n\nreject_by_annotationbool\n\nWhether to omit bad spans of data before spectrotemporal power estimation. If True, spans with annotations whose description begins with bad will be represented with np.nan in the time-frequency representation.\n\ndecimint | slice\n\nDecimation factor, applied after time-frequency decomposition.\n\nif int, returns tfr[..., ::decim] (keep only every Nth sample along the time axis).\n\nif slice, returns tfr[..., decim] (keep only the specified slice along the time axis).\n\nNote\n\nDecimation is done after convolutions and may create aliasing artifacts.\n\nn_jobsint | None\n\nThe number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\n**method_kw\n\nAdditional keyword arguments passed to the spectrotemporal estimation function (e.g., n_cycles, use_fft, zero_mean for Morlet method or n_cycles, use_fft, zero_mean, time_bandwidth for multitaper method). See tfr_array_morlet() and tfr_array_multitaper() for additional details.\n\nReturns:\n\ntfrinstance of RawTFR\n\nThe time-frequency-resolved power estimates of the data.\n\nNotes\n\nNew in v1.7.\n\nReferences\n\ncopy()[source]#\n\nReturn copy of Raw instance.\n\nReturns:\n\ninstinstance of Raw\n\nA copy of the instance.\n\nExamples using copy:\n\nModifying data in-place\n\nModifying data in-place\n\nParsing events from raw data\n\nParsing events from raw data\n\nThe Raw data structure: continuous data\n\nThe Raw data structure: continuous data\n\nAnnotating continuous data\n\nAnnotating continuous data\n\nHandling bad channels\n\nHandling bad channels\n\nFiltering and resampling data\n\nFiltering and resampling data\n\nBackground on projectors and projections\n\nBackground on projectors and projections\n\nSetting the EEG reference\n\nSetting the EEG reference\n\nSignal-space separation (SSS) and Maxwell filtering\n\nSignal-space separation (SSS) and Maxwell filtering\n\nRegression-based baseline correction\n\nRegression-based baseline correction\n\nMake figures more publication ready\n\nMake figures more publication ready\n\nFind MEG reference channel artifacts\n\nFind MEG reference channel artifacts\n\nPlot sensor denoising using oversampled temporal projection\n\nPlot sensor denoising using oversampled temporal projection\n\ncrop(tmin=0.0, tmax=None, include_tmax=True, *, verbose=None)[source]#\n\nCrop raw data file.\n\nLimit the data from the raw file to go between specific times. Note that the new tmin is assumed to be t=0 for all subsequently called functions (e.g., time_as_index(), or Epochs). New first_samp and last_samp are set accordingly.\n\nThus function operates in-place on the instance. Use mne.io.Raw.copy() if operation on a copy is desired.\n\nParameters:\n\ntminfloat\n\nStart time of the raw data to use in seconds (must be >= 0).\n\ntmaxfloat\n\nEnd time of the raw data to use in seconds (cannot exceed data duration).\n\ninclude_tmaxbool\n\nIf True (default), include tmax. If False, exclude tmax (similar to how Python indexing typically works).\n\nNew in v0.19.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nrawinstance of Raw\n\nThe cropped raw object, modified in-place.\n\nExamples using crop:\n\nModifying data in-place\n\nModifying data in-place\n\nParsing events from raw data\n\nParsing events from raw data\n\nThe Raw data structure: continuous data\n\nThe Raw data structure: continuous data\n\nWorking with events\n\nWorking with events\n\nAnnotating continuous data\n\nAnnotating continuous data\n\nBuilt-in plotting methods for Raw objects\n\nBuilt-in plotting methods for Raw objects\n\nOverview of artifact detection\n\nOverview of artifact detection\n\nHandling bad channels\n\nHandling bad channels\n\nRejecting bad data spans and breaks\n\nRejecting bad data spans and breaks\n\nFiltering and resampling data\n\nFiltering and resampling data\n\nBackground on projectors and projections\n\nBackground on projectors and projections\n\nSetting the EEG reference\n\nSetting the EEG reference\n\nExtracting and visualizing subject head movement\n\nExtracting and visualizing subject head movement\n\nSignal-space separation (SSS) and Maxwell filtering\n\nSignal-space separation (SSS) and Maxwell filtering\n\nDivide continuous data into equally-spaced epochs\n\nDivide continuous data into equally-spaced epochs\n\nEEG analysis - Event-Related Potentials (ERPs)\n\nEEG analysis - Event-Related Potentials (ERPs)\n\nFrequency and time-frequency sensor analysis\n\nFrequency and time-frequency sensor analysis\n\nAutomated epochs metadata generation with variable time windows\n\nAutomated epochs metadata generation with variable time windows\n\nPlot sensor denoising using oversampled temporal projection\n\nPlot sensor denoising using oversampled temporal projection\n\ncrop_by_annotations(annotations=None, *, verbose=None)[source]#\n\nGet crops of raw data file for selected annotations.\n\nParameters:\n\nannotationsinstance of Annotations | None\n\nThe annotations to use for cropping the raw file. If None, the annotations from the instance are used.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nrawslist\n\nThe cropped raw objects.\n\ndel_proj(idx='all')[source]#\n\nRemove SSP projection vector.\n\nNote\n\nThe projection vector can only be removed if it is inactive (has not been applied to the data).\n\nParameters:\n\nidxint | list of int | str\n\nIndex of the projector to remove. Can also be “all” (default) to remove all projectors.\n\nReturns:\n\nselfinstance of Raw | Epochs | Evoked\n\nThe instance.\n\nExamples using del_proj:\n\nOverview of artifact detection\n\nOverview of artifact detection\n\nRejecting bad data spans and breaks\n\nRejecting bad data spans and breaks\n\nRepairing artifacts with SSP\n\nRepairing artifacts with SSP\n\nSetting the EEG reference\n\nSetting the EEG reference\n\ndescribe(data_frame=False)[source]#\n\nDescribe channels (name, type, descriptive statistics).\n\nParameters:\n\ndata_framebool\n\nIf True, return results in a pandas.DataFrame. If False, only print results. Columns ‘ch’, ‘type’, and ‘unit’ indicate channel index, channel type, and unit of the remaining five columns. These columns are ‘min’ (minimum), ‘Q1’ (first quartile or 25% percentile), ‘median’, ‘Q3’ (third quartile or 75% percentile), and ‘max’ (maximum).\n\nReturns:\n\nresultNone | pandas.DataFrame\n\nIf data_frame=False, returns None. If data_frame=True, returns results in a pandas.DataFrame (requires pandas).\n\ndrop_channels(ch_names, on_missing='raise')[source]#\n\nDrop channel(s).\n\nParameters:\n\nch_namesiterable or str\n\nIterable (e.g. list) of channel name(s) or channel name to remove.\n\non_missing‘raise’ | ‘warn’ | ‘ignore’\n\nCan be 'raise' (default) to raise an error, 'warn' to emit a warning, or 'ignore' to ignore when entries in ch_names are not present in the raw instance.\n\nNew in v0.23.0.\n\nReturns:\n\ninstinstance of Raw, Epochs, or Evoked\n\nThe modified instance.\n\nSee also\n\nreorder_channels\n\npick_channels\n\npick_types\n\nNotes\n\nNew in v0.9.0.\n\nExamples using drop_channels:\n\nThe Raw data structure: continuous data\n\nThe Raw data structure: continuous data\n\nKernel OPM phantom data\n\nKernel OPM phantom data\n\nexport(fname, fmt='auto', physical_range='auto', add_ch_type=False, *, overwrite=False, verbose=None)[source]#\n\nExport Raw to external formats.\n\nSupported formats:\n\nBrainVision (.vhdr, .vmrk, .eeg, uses pybv)\n\nEEGLAB (.set, uses eeglabio)\n\nEDF (.edf, uses edfio)\n\nWarning\n\nSince we are exporting to external formats, there’s no guarantee that all the info will be preserved in the external format. See Notes for details.\n\nParameters:\n\nfnamestr\n\nName of the output file.\n\nfmt‘auto’ | ‘brainvision’ | ‘edf’ | ‘eeglab’\n\nFormat of the export. Defaults to 'auto', which will infer the format from the filename extension. See supported formats above for more information.\n\nphysical_rangestr | tuple\n\nThe physical range of the data. If ‘auto’ (default), the physical range is inferred from the data, taking the minimum and maximum values per channel type. If ‘channelwise’, the range will be defined per channel. If a tuple of minimum and maximum, this manual physical range will be used. Only used for exporting EDF files.\n\nadd_ch_typebool\n\nWhether to incorporate the channel type into the signal label (e.g. whether to store channel “Fz” as “EEG Fz”). Only used for EDF format. Default is False.\n\noverwritebool\n\nIf True (default False), overwrite the destination file if it exists.\n\nNew in v0.24.1.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nNotes\n\nNew in v0.24.\n\nExport to external format may not preserve all the information from the instance. To save in native MNE format (.fif) without information loss, use mne.io.Raw.save() instead. Export does not apply projector(s). Unapplied projector(s) will be lost. Consider applying projector(s) before exporting with mne.io.Raw.apply_proj().\n\nFor EEGLAB exports, channel locations are expanded to full EEGLAB format. For more details see eeglabio.utils.cart_to_eeglab().\n\nAlthough this function supports storing channel types in the signal label (e.g. EEG Fz or MISC E), other software may not support this (optional) feature of the EDF standard.\n\nIf add_ch_type is True, then channel types are written based on what they are currently set in MNE-Python. One should double check that all their channels are set correctly. You can call mne.io.Raw.set_channel_types() to set channel types.\n\nIn addition, EDF does not support storing a montage. You will need to store the montage separately and call mne.io.Raw.set_montage().\n\nThe physical range of the signals is determined by signal type by default (physical_range=\"auto\"). However, if individual channel ranges vary significantly due to the presence of e.g. drifts/offsets/biases, setting physical_range=\"channelwise\" might be more appropriate. This will ensure a maximum resolution for each individual channel, but some tools might not be able to handle this appropriately (even though channel-wise ranges are covered by the EDF standard).\n\npropertyfilenames#\n\nThe filenames used.\n\nfilter(l_freq, h_freq, picks=None, filter_length='auto', l_trans_bandwidth='auto', h_trans_bandwidth='auto', n_jobs=None, method='fir', iir_params=None, phase='zero', fir_window='hamming', fir_design='firwin', skip_by_annotation=('edge', 'bad_acq_skip'), pad='reflect_limited', verbose=None)[source]#\n\nFilter a subset of channels/vertices.\n\nParameters:\n\nl_freqfloat | None\n\nFor FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.\n\nh_freqfloat | None\n\nFor FIR filters, the upper pass-band edge; for IIR filters, the upper cutoff frequency. If None the data are only high-passed.\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nfilter_lengthstr | int\n\nLength of the FIR filter to use (if applicable):\n\n‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).\n\nstr: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase=\"zero\", or the shortest power-of-two length at least that duration for phase=\"zero-double\".\n\nint: Specified length in samples. For fir_design=”firwin”, this should not be used.\n\nl_trans_bandwidthfloat | str\n\nWidth of the transition band at the low cut-off frequency in Hz (high pass or cutoff 1 in bandpass). Can be “auto” (default) to use a multiple of l_freq:\n\nmin(max(l_freq * 0.25, 2), l_freq)\n\nOnly used for method='fir'.\n\nh_trans_bandwidthfloat | str\n\nWidth of the transition band at the high cut-off frequency in Hz (low pass or cutoff 2 in bandpass). Can be “auto” (default in 0.14) to use a multiple of h_freq:\n\nmin(max(h_freq * 0.25, 2.), info['sfreq'] / 2. - h_freq)\n\nOnly used for method='fir'.\n\nn_jobsint | str\n\nNumber of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.\n\nmethodstr\n\n'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).\n\niir_paramsdict | None\n\nDictionary of parameters to use for IIR filtering. If iir_params=None and method=\"iir\", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().\n\nphasestr\n\nPhase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method=\"fir\":\n\n\"zero\" (default)\n\nThe delay of this filter is compensated for, making it non-causal.\n\n\"minimum\"\n\nA minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().\n\n\"zero-double\"\n\nThis is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).\n\n\"minimum-half\"\n\nThis is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.\n\nWhen method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().\n\nNew in v0.13.\n\nChanged in version 1.7: The behavior for phase=\"minimum\" was fixed to use a filter of the requested length and improved suppression.\n\nfir_windowstr\n\nThe window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.\n\nNew in v0.15.\n\nfir_designstr\n\nCan be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.\n\nNew in v0.15.\n\nskip_by_annotationstr | list of str\n\nIf a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.\n\nNew in v0.16..\n\npadstr\n\nThe type of padding to use. Supports all numpy.pad() mode options. Can also be \"reflect_limited\", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\ninstinstance of Epochs, Evoked, SourceEstimate, or Raw\n\nThe filtered data.\n\nSee also\n\nmne.filter.create_filter\n\nmne.Evoked.savgol_filter\n\nmne.io.Raw.notch_filter\n\nmne.io.Raw.resample\n\nmne.filter.create_filter\n\nmne.filter.filter_data\n\nmne.filter.construct_iir_filter\n\nNotes\n\nApplies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. The data are modified inplace.\n\nThe object has to have the data loaded e.g. with preload=True or self.load_data().\n\nl_freq and h_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:\n\nl_freq < h_freq: band-pass filter\n\nl_freq > h_freq: band-stop filter\n\nl_freq is not None and h_freq is None: high-pass filter\n\nl_freq is None and h_freq is not None: low-pass filter\n\nself.info['lowpass'] and self.info['highpass'] are only updated with picks=None.\n\nNote\n\nIf n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.\n\nWhen working on SourceEstimates the sample rate of the original data is inferred from tstep.\n\nFor more information, see the tutorials Background information on filtering and Filtering and resampling data and mne.filter.create_filter().\n\nNew in v0.15.\n\nExamples using filter:\n\nModifying data in-place\n\nModifying data in-place\n\nBackground information on filtering\n\nBackground information on filtering\n\nFiltering and resampling data\n\nFiltering and resampling data\n\nRepairing artifacts with regression\n\nRepairing artifacts with regression\n\nRepairing artifacts with ICA\n\nRepairing artifacts with ICA\n\nAuto-generating Epochs metadata\n\nAuto-generating Epochs metadata\n\nEEG analysis - Event-Related Potentials (ERPs)\n\nEEG analysis - Event-Related Potentials (ERPs)\n\nSpatiotemporal permutation F-test on full sensor data\n\nSpatiotemporal permutation F-test on full sensor data\n\nReduce EOG artifacts through regression\n\nReduce EOG artifacts through regression\n\nCompare the different ICA algorithms in MNE\n\nCompare the different ICA algorithms in MNE\n\nPlot sensor denoising using oversampled temporal projection\n\nPlot sensor denoising using oversampled temporal projection\n\nXDAWN Denoising\n\nXDAWN Denoising\n\nHow to convert 3D electrode positions to a 2D image\n\nHow to convert 3D electrode positions to a 2D image\n\nWhitening evoked data with a noise covariance\n\nWhitening evoked data with a noise covariance\n\nPlot custom topographies for MEG sensors\n\nPlot custom topographies for MEG sensors\n\nRegression on continuous data (rER[P/F])\n\nRegression on continuous data (rER[P/F])\n\nDecoding source space data\n\nDecoding source space data\n\nDecoding sensor space data with generalization across time and conditions\n\nDecoding sensor space data with generalization across time and conditions\n\nAnalysis of evoked response using ICA and PCA reduction techniques\n\nAnalysis of evoked response using ICA and PCA reduction techniques\n\nXDAWN Decoding From EEG data\n\nXDAWN Decoding From EEG data\n\nCompute effect-matched-spatial filtering (EMS)\n\nCompute effect-matched-spatial filtering (EMS)\n\nKernel OPM phantom data\n\nKernel OPM phantom data\n\npropertyfirst_samp#\n\nThe first data sample.\n\nSee first_samp.\n\npropertyfirst_time#\n\nThe first time point (including first_samp but not meas_date).\n\nfix_mag_coil_types()[source]#\n\nFix Elekta magnetometer coil types.\n\nReturns:\n\nrawinstance of Raw\n\nThe raw object. Operates in place.\n\nNotes\n\nThis function changes magnetometer coil types 3022 (T1: SQ20483N) and 3023 (T2: SQ20483-A) to 3024 (T3: SQ20950N) in the channel definition records in the info structure.\n\nNeuromag Vectorview systems can contain magnetometers with two different coil sizes (3022 and 3023 vs. 3024). The systems incorporating coils of type 3024 were introduced last and are used at the majority of MEG sites. At some sites with 3024 magnetometers, the data files have still defined the magnetometers to be of type 3022 to ensure compatibility with older versions of Neuromag software. In the MNE software as well as in the present version of Neuromag software coil type 3024 is fully supported. Therefore, it is now safe to upgrade the data files to use the true coil type.\n\nNote\n\nThe effect of the difference between the coil sizes on the current estimates computed by the MNE software is very small. Therefore the use of mne_fix_mag_coil_types is not mandatory.\n\nget_channel_types(picks=None, unique=False, only_data_chs=False)[source]#\n\nGet a list of channel type for each channel.\n\nParameters:\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nuniquebool\n\nWhether to return only unique channel types. Default is False.\n\nonly_data_chsbool\n\nWhether to ignore non-data channels. Default is False.\n\nReturns:\n\nchannel_typeslist\n\nThe channel types.\n\nExamples using get_channel_types:\n\nThe Info data structure\n\nThe Info data structure\n\nget_data(picks=None, start=0, stop=None, reject_by_annotation=None, return_times=False, units=None, *, tmin=None, tmax=None, verbose=None)[source]#\n\nGet data in the given range.\n\nParameters:\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nstartint\n\nThe first sample to include. Defaults to 0.\n\nstopint | None\n\nEnd sample (first not to include). If None (default), the end of the data is used.\n\nreject_by_annotationNone | ‘omit’ | ‘NaN’\n\nWhether to reject by annotation. If None (default), no rejection is done. If ‘omit’, segments annotated with description starting with ‘bad’ are omitted. If ‘NaN’, the bad samples are filled with NaNs.\n\nreturn_timesbool\n\nWhether to return times as well. Defaults to False.\n\nunitsstr | dict | None\n\nSpecify the unit(s) that the data should be returned in. If None (default), the data is returned in the channel-type-specific default units, which are SI units (see Internal representation (units) and data channels). If a string, must be a sub-multiple of SI units that will be used to scale the data from all channels of the type associated with that unit. This only works if the data contains one channel type that has a unit (unitless channel types are left unchanged). For example if there are only EEG and STIM channels, units='uV' will scale EEG channels to micro-Volts while STIM channels will be unchanged. Finally, if a dictionary is provided, keys must be channel types, and values must be units to scale the data of that channel type to. For example dict(grad='fT/cm', mag='fT') will scale the corresponding types accordingly, but all other channel types will remain in their channel-type-specific default unit.\n\ntminint | float | None\n\nStart time of data to get in seconds. The tmin parameter is ignored if the start parameter is bigger than 0.\n\nNew in v0.24.0.\n\ntmaxint | float | None\n\nEnd time of data to get in seconds. The tmax parameter is ignored if the stop parameter is defined.\n\nNew in v0.24.0.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\ndatandarray, shape (n_channels, n_times)\n\nCopy of the data in the given range.\n\ntimesndarray, shape (n_times,)\n\nTimes associated with the data samples. Only returned if return_times=True.\n\nNotes\n\nNew in v0.14.0.\n\nExamples using get_data:\n\nModifying data in-place\n\nModifying data in-place\n\nThe Raw data structure: continuous data\n\nThe Raw data structure: continuous data\n\nRejecting bad data spans and breaks\n\nRejecting bad data spans and breaks\n\nFiltering and resampling data\n\nFiltering and resampling data\n\nMake figures more publication ready\n\nMake figures more publication ready\n\nget_montage()[source]#\n\nGet a DigMontage from instance.\n\nReturns:\n\nmontageNone | str | DigMontage\n\nA montage containing channel positions. If a string or DigMontage is specified, the existing channel information will be updated with the channel positions from the montage. Valid strings are the names of the built-in montages that ship with MNE-Python; you can list those via mne.channels.get_builtin_montages(). If None (default), the channel positions will be removed from the Info.\n\nExamples using get_montage:\n\nHow to convert 3D electrode positions to a 2D image\n\nHow to convert 3D electrode positions to a 2D image\n\ninterpolate_bads(reset_bads=True, mode='accurate', origin='auto', method=None, exclude=(), verbose=None)[source]#\n\nInterpolate bad MEG and EEG channels.\n\nOperates in place.\n\nParameters:\n\nreset_badsbool\n\nIf True, remove the bads from info.\n\nmodestr\n\nEither 'accurate' or 'fast', determines the quality of the Legendre polynomial expansion used for interpolation of channels using the minimum-norm method.\n\noriginarray_like, shape (3,) | str\n\nOrigin of the sphere in the head coordinate frame and in meters. Can be 'auto' (default), which means a head-digitization-based origin fit.\n\nNew in v0.17.\n\nmethoddict | str | None\n\nMethod to use for each channel type.\n\n\"meg\" channels support \"MNE\" (default) and \"nan\"\n\n\"eeg\" channels support \"spline\" (default), \"MNE\" and \"nan\"\n\n\"fnirs\" channels support \"nearest\" (default) and \"nan\"\n\n\"ecog\" channels support \"spline\" (default) and \"nan\"\n\n\"seeg\" channels support \"spline\" (default) and \"nan\"\n\nNone is an alias for:\n\nmethod=dict(meg=\"MNE\", eeg=\"spline\", fnirs=\"nearest\")\n\nIf a str is provided, the method will be applied to all channel types supported and available in the instance. The method \"nan\" will replace the channel data with np.nan.\n\nWarning\n\nBe careful when using method=\"nan\"; the default value reset_bads=True may not be what you want.\n\nNew in v0.21.\n\nexcludelist | tuple\n\nThe channels to exclude from interpolation. If excluded a bad channel will stay in bads.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\ninstinstance of Raw, Epochs, or Evoked\n\nThe modified instance.\n\nNotes\n\nThe \"MNE\" method uses minimum-norm projection to a sphere and back.\n\nNew in v0.9.0.\n\npropertylast_samp#\n\nThe last data sample.\n\nload_bad_channels(bad_file=None, force=False, verbose=None)[source]#\n\nMark channels as bad from a text file.\n\nThis function operates mostly in the style of the C function mne_mark_bad_channels. Each line in the text file will be interpreted as a name of a bad channel.\n\nParameters:\n\nbad_filepath-like | None\n\nFile name of the text file containing bad channels. If None (default), bad channels are cleared, but this is more easily done directly with raw.info['bads'] = [].\n\nforcebool\n\nWhether or not to force bad channel marking (of those that exist) if channels are not found, instead of raising an error. Defaults to False.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nload_data(verbose=None)[source]#\n\nLoad raw data.\n\nParameters:\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nrawinstance of Raw\n\nThe raw object with data.\n\nNotes\n\nThis function will load raw data if it was not already preloaded. If data were already preloaded, it will do nothing.\n\nNew in v0.10.0.\n\nExamples using load_data:\n\nOverview of MEG/EEG analysis with MNE-Python\n\nOverview of MEG/EEG analysis with MNE-Python\n\nRepairing artifacts with regression\n\nRepairing artifacts with regression\n\nRepairing artifacts with SSP\n\nRepairing artifacts with SSP\n\nHow to convert 3D electrode positions to a 2D image\n\nHow to convert 3D electrode positions to a 2D image\n\nCompute evoked ERS source power using DICS, LCMV beamformer, and dSPM\n\nCompute evoked ERS source power using DICS, LCMV beamformer, and dSPM\n\npropertyn_times#\n\nNumber of time points.\n\nnotch_filter(freqs, picks=None, filter_length='auto', notch_widths=None, trans_bandwidth=1.0, n_jobs=None, method='fir', iir_params=None, mt_bandwidth=None, p_value=0.05, phase='zero', fir_window='hamming', fir_design='firwin', pad='reflect_limited', skip_by_annotation=('edge', 'bad_acq_skip'), verbose=None)[source]#\n\nNotch filter a subset of channels.\n\nParameters:\n\nfreqsfloat | array of float | None\n\nSpecific frequencies to filter out from data, e.g., np.arange(60, 241, 60) in the US or np.arange(50, 251, 50) in Europe. None can only be used with the mode 'spectrum_fit', where an F test is used to find sinusoidal components.\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick all data channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nfilter_lengthstr | int\n\nLength of the FIR filter to use (if applicable):\n\n‘auto’ (default): The filter length is chosen based on the size of the transition regions (6.6 times the reciprocal of the shortest transition band for fir_window=’hamming’ and fir_design=”firwin2”, and half that for “firwin”).\n\nstr: A human-readable time in units of “s” or “ms” (e.g., “10s” or “5500ms”) will be converted to that number of samples if phase=\"zero\", or the shortest power-of-two length at least that duration for phase=\"zero-double\".\n\nint: Specified length in samples. For fir_design=”firwin”, this should not be used.\n\nWhen method=='spectrum_fit', this sets the effective window duration over which fits are computed. See mne.filter.create_filter() for options. Longer window lengths will give more stable frequency estimates, but require (potentially much) more processing and are not able to adapt as well to non-stationarities.\n\nThe default in 0.21 is None, but this will change to '10s' in 0.22.\n\nnotch_widthsfloat | array of float | None\n\nWidth of each stop band (centred at each freq in freqs) in Hz. If None, freqs / 200 is used.\n\ntrans_bandwidthfloat\n\nWidth of the transition band in Hz. Only used for method='fir' and method='iir'.\n\nn_jobsint | str\n\nNumber of jobs to run in parallel. Can be 'cuda' if cupy is installed properly and method='fir'.\n\nmethodstr\n\n'fir' will use overlap-add FIR filtering, 'iir' will use IIR forward-backward filtering (via filtfilt()).\n\niir_paramsdict | None\n\nDictionary of parameters to use for IIR filtering. If iir_params=None and method=\"iir\", 4th order Butterworth will be used. For more information, see mne.filter.construct_iir_filter().\n\nmt_bandwidthfloat | None\n\nThe bandwidth of the multitaper windowing function in Hz. Only used in ‘spectrum_fit’ mode.\n\np_valuefloat\n\nP-value to use in F-test thresholding to determine significant sinusoidal components to remove when method='spectrum_fit' and freqs=None. Note that this will be Bonferroni corrected for the number of frequencies, so large p-values may be justified.\n\nphasestr\n\nPhase of the filter. When method='fir', symmetric linear-phase FIR filters are constructed with the following behaviors when method=\"fir\":\n\n\"zero\" (default)\n\nThe delay of this filter is compensated for, making it non-causal.\n\n\"minimum\"\n\nA minimum-phase filter will be constructed by decomposing the zero-phase filter into a minimum-phase and all-pass systems, and then retaining only the minimum-phase system (of the same length as the original zero-phase filter) via scipy.signal.minimum_phase().\n\n\"zero-double\"\n\nThis is a legacy option for compatibility with MNE <= 0.13. The filter is applied twice, once forward, and once backward (also making it non-causal).\n\n\"minimum-half\"\n\nThis is a legacy option for compatibility with MNE <= 1.6. A minimum-phase filter will be reconstructed from the zero-phase filter with half the length of the original filter.\n\nWhen method='iir', phase='zero' (default) or equivalently 'zero-double' constructs and applies IIR filter twice, once forward, and once backward (making it non-causal) using filtfilt(); phase='forward' will apply the filter once in the forward (causal) direction using lfilter().\n\nNew in v0.13.\n\nChanged in version 1.7: The behavior for phase=\"minimum\" was fixed to use a filter of the requested length and improved suppression.\n\nfir_windowstr\n\nThe window to use in FIR design, can be “hamming” (default), “hann” (default in 0.13), or “blackman”.\n\nNew in v0.15.\n\nfir_designstr\n\nCan be “firwin” (default) to use scipy.signal.firwin(), or “firwin2” to use scipy.signal.firwin2(). “firwin” uses a time-domain design technique that generally gives improved attenuation using fewer samples than “firwin2”.\n\nNew in v0.15.\n\npadstr\n\nThe type of padding to use. Supports all numpy.pad() mode options. Can also be \"reflect_limited\", which pads with a reflected version of each vector mirrored on the first and last values of the vector, followed by zeros. Only used for method='fir'. The default is 'reflect_limited'.\n\nNew in v0.15.\n\nskip_by_annotationstr | list of str\n\nIf a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately (i.e., as independent signals). The default (('edge', 'bad_acq_skip') will separately filter any segments that were concatenated by mne.concatenate_raws() or mne.io.Raw.append(), or separated during acquisition. To disable, provide an empty list. Only used if inst is raw.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nrawinstance of Raw\n\nThe raw instance with filtered data.\n\nSee also\n\nmne.filter.notch_filter\n\nmne.io.Raw.filter\n\nNotes\n\nApplies a zero-phase notch filter to the channels selected by “picks”. By default the data of the Raw object is modified inplace.\n\nThe Raw object has to have the data loaded e.g. with preload=True or self.load_data().\n\nNote\n\nIf n_jobs > 1, more memory is required as len(picks) * n_times additional time points need to be temporarily stored in memory.\n\nFor details, see mne.filter.notch_filter().\n\nExamples using notch_filter:\n\nModifying data in-place\n\nModifying data in-place\n\npick(picks, exclude=(), *, verbose=None)[source]#\n\nPick a subset of channels.\n\nParameters:\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nexcludelist | str\n\nSet of channels to exclude, only used when picking based on types (e.g., exclude=”bads” when picks=”meg”).\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nNew in v0.24.0.\n\nReturns:\n\ninstinstance of Raw, Epochs, or Evoked\n\nThe modified instance.\n\nExamples using pick:\n\nModifying data in-place\n\nModifying data in-place\n\nGetting started with mne.Report\n\nGetting started with mne.Report\n\nThe Raw data structure: continuous data\n\nThe Raw data structure: continuous data\n\nRejecting bad data spans and breaks\n\nRejecting bad data spans and breaks\n\nRepairing artifacts with regression\n\nRepairing artifacts with regression\n\nRepairing artifacts with ICA\n\nRepairing artifacts with ICA\n\nSetting the EEG reference\n\nSetting the EEG reference\n\nSignal-space separation (SSS) and Maxwell filtering\n\nSignal-space separation (SSS) and Maxwell filtering\n\nRegression-based baseline correction\n\nRegression-based baseline correction\n\nEEG analysis - Event-Related Potentials (ERPs)\n\nEEG analysis - Event-Related Potentials (ERPs)\n\nEEG source localization given electrode locations on an MRI\n\nEEG source localization given electrode locations on an MRI\n\nMake figures more publication ready\n\nMake figures more publication ready\n\nTransform EEG data using current source density (CSD)\n\nTransform EEG data using current source density (CSD)\n\nHow to convert 3D electrode positions to a 2D image\n\nHow to convert 3D electrode positions to a 2D image\n\nRegression on continuous data (rER[P/F])\n\nRegression on continuous data (rER[P/F])\n\nCompute effect-matched-spatial filtering (EMS)\n\nCompute effect-matched-spatial filtering (EMS)\n\nComputing source timecourses with an XFit-like multi-dipole model\n\nComputing source timecourses with an XFit-like multi-dipole model\n\nKernel OPM phantom data\n\nKernel OPM phantom data\n\npick_channels(ch_names, ordered=True, *, verbose=None)[source]#\n\nWarning\n\nLEGACY: New code should use inst.pick(…).\n\nPick some channels.\n\nParameters:\n\nch_nameslist\n\nThe list of channels to select.\n\norderedbool\n\nIf True (default), ensure that the order of the channels in the modified instance matches the order of ch_names.\n\nNew in v0.20.0.\n\nChanged in version 1.7: The default changed from False in 1.6 to True in 1.7.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nNew in v1.1.\n\nReturns:\n\ninstinstance of Raw, Epochs, or Evoked\n\nThe modified instance.\n\nSee also\n\ndrop_channels\n\npick_types\n\nreorder_channels\n\nNotes\n\nThe channel names given are assumed to be a set, i.e. the order does not matter. The original order of the channels is preserved. You can use reorder_channels to set channel order if necessary.\n\nNew in v0.9.0.\n\npick_types(meg=False, eeg=False, stim=False, eog=False, ecg=False, emg=False, ref_meg='auto', *, misc=False, resp=False, chpi=False, exci=False, ias=False, syst=False, seeg=False, dipole=False, gof=False, bio=False, ecog=False, fnirs=False, csd=False, dbs=False, temperature=False, gsr=False, eyetrack=False, include=(), exclude='bads', selection=None, verbose=None)[source]#\n\nWarning\n\nLEGACY: New code should use inst.pick(…).\n\nPick some channels by type and names.\n\nParameters:\n\nmegbool | str\n\nIf True include MEG channels. If string it can be ‘mag’, ‘grad’, ‘planar1’ or ‘planar2’ to select only magnetometers, all gradiometers, or a specific type of gradiometer.\n\neegbool\n\nIf True include EEG channels.\n\nstimbool\n\nIf True include stimulus channels.\n\neogbool\n\nIf True include EOG channels.\n\necgbool\n\nIf True include ECG channels.\n\nemgbool\n\nIf True include EMG channels.\n\nref_megbool | str\n\nIf True include CTF / 4D reference channels. If ‘auto’, reference channels are included if compensations are present and meg is not False. Can also be the string options for the meg parameter.\n\nmiscbool\n\nIf True include miscellaneous analog channels.\n\nrespbool\n\nIf True include respiratory channels.\n\nchpibool\n\nIf True include continuous HPI coil channels.\n\nexcibool\n\nFlux excitation channel used to be a stimulus channel.\n\niasbool\n\nInternal Active Shielding data (maybe on Triux only).\n\nsystbool\n\nSystem status channel information (on Triux systems only).\n\nseegbool\n\nStereotactic EEG channels.\n\ndipolebool\n\nDipole time course channels.\n\ngofbool\n\nDipole goodness of fit channels.\n\nbiobool\n\nBio channels.\n\necogbool\n\nElectrocorticography channels.\n\nfnirsbool | str\n\nFunctional near-infrared spectroscopy channels. If True include all fNIRS channels. If False (default) include none. If string it can be ‘hbo’ (to include channels measuring oxyhemoglobin) or ‘hbr’ (to include channels measuring deoxyhemoglobin).\n\ncsdbool\n\nEEG-CSD channels.\n\ndbsbool\n\nDeep brain stimulation channels.\n\ntemperaturebool\n\nTemperature channels.\n\ngsrbool\n\nGalvanic skin response channels.\n\neyetrackbool | str\n\nEyetracking channels. If True include all eyetracking channels. If False (default) include none. If string it can be ‘eyegaze’ (to include eye position channels) or ‘pupil’ (to include pupil-size channels).\n\nincludelist of str\n\nList of additional channels to include. If empty do not include any.\n\nexcludelist of str | str\n\nList of channels to exclude. If ‘bads’ (default), exclude channels in info['bads'].\n\nselectionlist of str\n\nRestrict sensor channels (MEG, EEG, etc.) to this list of channel names.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\ninstinstance of Raw, Epochs, or Evoked\n\nThe modified instance.\n\nSee also\n\npick_channels\n\nNotes\n\nNew in v0.9.0.\n\nplot(events=None, duration=10.0, start=0.0, n_channels=20, bgcolor='w', color=None, bad_color='lightgray', event_color='cyan', scalings=None, remove_dc=True, order=None, show_options=False, title=None, show=True, block=False, highpass=None, lowpass=None, filtorder=4, clipping=1.5, show_first_samp=False, proj=True, group_by='type', butterfly=False, decim='auto', noise_cov=None, event_id=None, show_scrollbars=True, show_scalebars=True, time_format='float', precompute=None, use_opengl=None, *, picks=None, theme=None, overview_mode=None, splash=True, verbose=None)[source]#\n\nPlot raw data.\n\nParameters:\n\neventsarray | None\n\nEvents to show with vertical bars.\n\ndurationfloat\n\nTime window (s) to plot. The lesser of this value and the duration of the raw file will be used.\n\nstartfloat\n\nInitial time to show (can be changed dynamically once plotted). If show_first_samp is True, then it is taken relative to raw.first_samp.\n\nn_channelsint\n\nNumber of channels to plot at once. Defaults to 20. The lesser of n_channels and len(raw.ch_names) will be shown. Has no effect if order is ‘position’, ‘selection’ or ‘butterfly’.\n\nbgcolorcolor object\n\nColor of the background.\n\ncolordict | color object | None\n\nColor for the data traces. If None, defaults to:\n\ndict(mag='darkblue', grad='b', eeg='k', eog='k', ecg='m', emg='k', ref_meg='steelblue', misc='k', stim='k', resp='k', chpi='k')\n\nbad_colorcolor object\n\nColor to make bad channels.\n\nevent_colorcolor object | dict | None\n\nColor(s) to use for events. To show all events in the same color, pass any matplotlib-compatible color. To color events differently, pass a dict that maps event names or integer event numbers to colors (must include entries for all events, or include a “fallback” entry with key -1). If None, colors are chosen from the current Matplotlib color cycle. Defaults to 'cyan'.\n\nscalings‘auto’ | dict | None\n\nScaling factors for the traces. If a dictionary where any value is 'auto', the scaling factor is set to match the 99.5th percentile of the respective data. If 'auto', all scalings (for all channel types) are set to 'auto'. If any values are 'auto' and the data is not preloaded, a subset up to 100 MB will be loaded. If None, defaults to:\n\ndict(mag=1e-12, grad=4e-11, eeg=20e-6, eog=150e-6, ecg=5e-4, emg=1e-3, ref_meg=1e-12, misc=1e-3, stim=1, resp=1, chpi=1e-4, whitened=1e2)\n\nNote\n\nA particular scaling value s corresponds to half of the visualized signal range around zero (i.e. from 0 to +s or from 0 to -s). For example, the default scaling of 20e-6 (20µV) for EEG signals means that the visualized range will be 40 µV (20 µV in the positive direction and 20 µV in the negative direction).\n\nremove_dcbool\n\nIf True remove DC component when plotting data.\n\norderarray of int | None\n\nOrder in which to plot data. If the array is shorter than the number of channels, only the given channels are plotted. If None (default), all channels are plotted. If group_by is 'position' or 'selection', the order parameter is used only for selecting the channels to be plotted.\n\nshow_optionsbool\n\nIf True, a dialog for options related to projection is shown.\n\ntitlestr | None\n\nThe title of the window. If None, and either the filename of the raw object or ‘<unknown>’ will be displayed as title.\n\nshowbool\n\nShow figure if True.\n\nblockbool\n\nWhether to halt program execution until the figure is closed. Useful for setting bad channels on the fly by clicking on a line. May not work on all systems / platforms. (Only Qt) If you run from a script, this needs to be True or a Qt-eventloop needs to be started somewhere else in the script (e.g. if you want to implement the browser inside another Qt-Application).\n\nhighpassfloat | None\n\nHighpass to apply when displaying data.\n\nlowpassfloat | None\n\nLowpass to apply when displaying data. If highpass > lowpass, a bandstop rather than bandpass filter will be applied.\n\nfiltorderint\n\nFiltering order. 0 will use FIR filtering with MNE defaults. Other values will construct an IIR filter of the given order and apply it with filtfilt() (making the effective order twice filtorder). Filtering may produce some edge artifacts (at the left and right edges) of the signals during display.\n\nChanged in version 0.18: Support for filtorder=0 to use FIR filtering.\n\nclippingstr | float | None\n\nIf None, channels are allowed to exceed their designated bounds in the plot. If “clamp”, then values are clamped to the appropriate range for display, creating step-like artifacts. If “transparent”, then excessive values are not shown, creating gaps in the traces. If float, clipping occurs for values beyond the clipping multiple of their dedicated range, so clipping=1. is an alias for clipping='transparent'.\n\nChanged in version 0.21: Support for float, and default changed from None to 1.5.\n\nshow_first_sampbool\n\nIf True, show time axis relative to the raw.first_samp.\n\nprojbool\n\nWhether to apply projectors prior to plotting (default is True). Individual projectors can be enabled/disabled interactively (see Notes). This argument only affects the plot; use raw.apply_proj() to modify the data stored in the Raw object.\n\ngroup_bystr\n\nHow to group channels. 'type' groups by channel type, 'original' plots in the order of ch_names, 'selection' uses Elekta’s channel groupings (only works for Neuromag data), 'position' groups the channels by the positions of the sensors. 'selection' and 'position' modes allow custom selections by using a lasso selector on the topomap. In butterfly mode, 'type' and 'original' group the channels by type, whereas 'selection' and 'position' use regional grouping. 'type' and 'original' modes are ignored when order is not None. Defaults to 'type'.\n\nbutterflybool\n\nWhether to start in butterfly mode. Defaults to False.\n\ndecimint | ‘auto’\n\nAmount to decimate the data during display for speed purposes. You should only decimate if the data are sufficiently low-passed, otherwise aliasing can occur. The ‘auto’ mode (default) uses the decimation that results in a sampling rate least three times larger than min(info['lowpass'], lowpass) (e.g., a 40 Hz lowpass will result in at least a 120 Hz displayed sample rate).\n\nnoise_covinstance of Covariance | str | None\n\nNoise covariance used to whiten the data while plotting. Whitened data channels are scaled by scalings['whitened'], and their channel names are shown in italic. Can be a string to load a covariance from disk. See also mne.Evoked.plot_white() for additional inspection of noise covariance properties when whitening evoked data. For data processed with SSS, the effective dependence between magnetometers and gradiometers may introduce differences in scaling, consider using mne.Evoked.plot_white().\n\nNew in v0.16.0.\n\nevent_iddict | None\n\nEvent IDs used to show at event markers (default None shows the event numbers).\n\nNew in v0.16.0.\n\nshow_scrollbarsbool\n\nWhether to show scrollbars when the plot is initialized. Can be toggled after initialization by pressing z (“zen mode”) while the plot window is focused. Default is True.\n\nNew in v0.19.0.\n\nshow_scalebarsbool\n\nWhether to show scale bars when the plot is initialized. Can be toggled after initialization by pressing s while the plot window is focused. Default is True.\n\nNew in v0.20.0.\n\ntime_format‘float’ | ‘clock’\n\nStyle of time labels on the horizontal axis. If 'float', labels will be number of seconds from the start of the recording. If 'clock', labels will show “clock time” (hours/minutes/seconds) inferred from raw.info['meas_date']. Default is 'float'.\n\nNew in v0.24.\n\nprecomputebool | str\n\nWhether to load all data (not just the visible portion) into RAM and apply preprocessing (e.g., projectors) to the full data array in a separate processor thread, instead of window-by-window during scrolling. The default None uses the MNE_BROWSER_PRECOMPUTE variable, which defaults to 'auto'. 'auto' compares available RAM space to the expected size of the precomputed data, and precomputes only if enough RAM is available. This is only used with the Qt backend.\n\nNew in v0.24.\n\nChanged in version 1.0: Support for the MNE_BROWSER_PRECOMPUTE config variable.\n\nuse_openglbool | None\n\nWhether to use OpenGL when rendering the plot (requires pyopengl). May increase performance, but effect is dependent on system CPU and graphics hardware. Only works if using the Qt backend. Default is None, which will use False unless the user configuration variable MNE_BROWSER_USE_OPENGL is set to 'true', see mne.set_config().\n\nNew in v0.24.\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick all channels. Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nthemestr | path-like\n\nCan be “auto”, “light”, or “dark” or a path-like to a custom stylesheet. For Dark-Mode and automatic Dark-Mode-Detection, qdarkstyle and darkdetect, respectively, are required. If None (default), the config option MNE_BROWSER_THEME will be used, defaulting to “auto” if it’s not found. Only supported by the 'qt' backend.\n\nNew in v1.0.\n\noverview_modestr | None\n\nCan be “channels”, “empty”, or “hidden” to set the overview bar mode for the 'qt' backend. If None (default), the config option MNE_BROWSER_OVERVIEW_MODE will be used, defaulting to “channels” if it’s not found.\n\nNew in v1.1.\n\nsplashbool\n\nIf True (default), a splash screen is shown during the application startup. Only applicable to the qt backend.\n\nNew in v1.6.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\nReturns:\n\nfigmatplotlib.figure.Figure | mne_qt_browser.figure.MNEQtBrowser\n\nBrowser instance.\n\nNotes\n\nThe arrow keys (up/down/left/right) can typically be used to navigate between channels and time ranges, but this depends on the backend matplotlib is configured to use (e.g., mpl.use(‘TkAgg’) should work). The left/right arrows will scroll by 25% of duration, whereas shift+left/shift+right will scroll by 100% of duration. The scaling can be adjusted with - and + (or =) keys. The viewport dimensions can be adjusted with page up/page down and home/end keys. Full screen mode can be toggled with the F11 key, and scrollbars can be hidden/shown by pressing ‘z’. Right-click a channel label to view its location. To mark or un-mark a channel as bad, click on a channel label or a channel trace. The changes will be reflected immediately in the raw object’s raw.info['bads'] entry.\n\nIf projectors are present, a button labelled “Prj” in the lower right corner of the plot window opens a secondary control window, which allows enabling/disabling specific projectors individually. This provides a means of interactively observing how each projector would affect the raw data if it were applied.\n\nAnnotation mode is toggled by pressing ‘a’, butterfly mode by pressing ‘b’, and whitening mode (when noise_cov is not None) by pressing ‘w’. By default, the channel means are removed when remove_dc is set to True. This flag can be toggled by pressing ‘d’.\n\nMNE-Python provides two different backends for browsing plots (i.e., raw.plot(), epochs.plot(), and ica.plot_sources()). One is based on matplotlib, and the other is based on PyQtGraph. You can set the backend temporarily with the context manager mne.viz.use_browser_backend(), you can set it for the duration of a Python session using mne.viz.set_browser_backend(), and you can set the default for your computer via mne.set_config('MNE_BROWSER_BACKEND', 'matplotlib') (or 'qt').\n\nNote\n\nFor the PyQtGraph backend to run in IPython with block=False you must run the magic command %gui qt5 first.\n\nNote\n\nTo report issues with the PyQtGraph backend, please use the issues of mne-qt-browser.\n\nExamples using plot:\n\nOverview of MEG/EEG analysis with MNE-Python\n\nOverview of MEG/EEG analysis with MNE-Python\n\nModifying data in-place\n\nModifying data in-place\n\nParsing events from raw data\n\nParsing events from raw data\n\nImporting Data from Eyetracking devices\n\nImporting Data from Eyetracking devices\n\nWorking with events\n\nWorking with events\n\nAnnotating continuous data\n\nAnnotating continuous data\n\nBuilt-in plotting methods for Raw objects\n\nBuilt-in plotting methods for Raw objects\n\nOverview of artifact detection\n\nOverview of artifact detection\n\nHandling bad channels\n\nHandling bad channels\n\nRejecting bad data spans and breaks\n\nRejecting bad data spans and breaks\n\nFiltering and resampling data\n\nFiltering and resampling data\n\nRepairing artifacts with regression\n\nRepairing artifacts with regression\n\nBackground on projectors and projections\n\nBackground on projectors and projections\n\nRepairing artifacts with SSP\n\nRepairing artifacts with SSP\n\nSetting the EEG reference\n\nSetting the EEG reference\n\nAuto-generating Epochs metadata\n\nAuto-generating Epochs metadata\n\nEEG analysis - Event-Related Potentials (ERPs)\n\nEEG analysis - Event-Related Potentials (ERPs)\n\nPlotting whitened data\n\nPlotting whitened data\n\nBrainstorm Elekta phantom dataset tutorial\n\nBrainstorm Elekta phantom dataset tutorial\n\nTransform EEG data using current source density (CSD)\n\nTransform EEG data using current source density (CSD)\n\nFind MEG reference channel artifacts\n\nFind MEG reference channel artifacts\n\nMaxwell filter data with movement compensation\n\nMaxwell filter data with movement compensation\n\nPlot sensor denoising using oversampled temporal projection\n\nPlot sensor denoising using oversampled temporal projection\n\nplot_projs_topomap(ch_type=None, *, sensors=True, show_names=False, contours=6, outlines='head', sphere=None, image_interp='cubic', extrapolate='auto', border='mean', res=64, size=1, cmap=None, vlim=(None, None), cnorm=None, colorbar=False, cbar_fmt='%3.1f', units=None, axes=None, show=True)[source]#\n\nPlot SSP vector.\n\nParameters:\n\nch_type‘mag’ | ‘grad’ | ‘planar1’ | ‘planar2’ | ‘eeg’ | None | list\n\nThe channel type to plot. For 'grad', the gradiometers are collected in pairs and the RMS for each pair is plotted. If None it will return all channel types present.. If a list of ch_types is provided, it will return multiple figures. Defaults to None.\n\nsensorsbool | str\n\nWhether to add markers for sensor locations. If str, should be a valid matplotlib format string (e.g., 'r+' for red plusses, see the Notes section of plot()). If True (the default), black circles will be used.\n\nshow_namesbool | callable()\n\nIf True, show channel names next to each sensor marker. If callable, channel names will be formatted using the callable; e.g., to delete the prefix ‘MEG ‘ from all channel names, pass the function lambda x: x.replace('MEG ', ''). If mask is not None, only non-masked sensor names will be shown.\n\nNew in v1.2.\n\ncontoursint | array_like\n\nThe number of contour lines to draw. If 0, no contours will be drawn. If a positive integer, that number of contour levels are chosen using the matplotlib tick locator (may sometimes be inaccurate, use array for accuracy). If array-like, the array values are used as the contour levels. The values should be in µV for EEG, fT for magnetometers and fT/m for gradiometers. If colorbar=True, the colorbar will have ticks corresponding to the contour levels. Default is 6.\n\noutlines‘head’ | dict | None\n\nThe outlines to be drawn. If ‘head’, the default head scheme will be drawn. If dict, each key refers to a tuple of x and y positions, the values in ‘mask_pos’ will serve as image mask. Alternatively, a matplotlib patch object can be passed for advanced masking options, either directly or as a function that returns patches (required for multi-axis plots). If None, nothing will be drawn. Defaults to ‘head’.\n\nspherefloat | array_like | instance of ConductorModel | None | ‘auto’ | ‘eeglab’\n\nThe sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. If 'auto' the sphere is fit to digitization points. If 'eeglab' the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz'). None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.\n\nNew in v0.20.\n\nChanged in version 1.1: Added 'eeglab' option.\n\nimage_interpstr\n\nThe image interpolation to be used. Options are 'cubic' (default) to use scipy.interpolate.CloughTocher2DInterpolator, 'nearest' to use scipy.spatial.Voronoi or 'linear' to use scipy.interpolate.LinearNDInterpolator.\n\nextrapolatestr\n\nOptions:\n\n'box'\n\nExtrapolate to four points placed to form a square encompassing all data points, where each side of the square is three times the range of the data in the respective dimension.\n\n'local' (default for MEG sensors)\n\nExtrapolate only to nearby points (approximately to points closer than median inter-electrode distance). This will also set the mask to be polygonal based on the convex hull of the sensors.\n\n'head' (default for non-MEG sensors)\n\nExtrapolate out to the edges of the clipping circle. This will be on the head circle when the sensors are contained within the head circle, but it can extend beyond the head when sensors are plotted outside the head circle.\n\nNew in v0.20.\n\nChanged in version 0.21:\n\nThe default was changed to 'local' for MEG sensors.\n\n'local' was changed to use a convex hull mask\n\n'head' was changed to extrapolate out to the clipping circle.\n\nborderfloat | ‘mean’\n\nValue to extrapolate to on the topomap borders. If 'mean' (default), then each extrapolated point has the average value of its neighbours.\n\nNew in v0.20.\n\nresint\n\nThe resolution of the topomap image (number of pixels along each side).\n\nsizefloat\n\nSide length of each subplot in inches. Only applies when plotting multiple topomaps at a time.\n\ncmapmatplotlib colormap | (colormap, bool) | ‘interactive’ | None\n\nColormap to use. If tuple, the first value indicates the colormap to use and the second value is a boolean defining interactivity. In interactive mode the colors are adjustable by clicking and dragging the colorbar with left and right mouse button. Left mouse button moves the scale up and down and right mouse button adjusts the range. Hitting space bar resets the range. Up and down arrows can be used to change the colormap. If None, 'Reds' is used for data that is either all-positive or all-negative, and 'RdBu_r' is used otherwise. 'interactive' is equivalent to (None, True). Defaults to None.\n\nWarning\n\nInteractive mode works smoothly only for a small amount of topomaps. Interactive mode is disabled by default for more than 2 topomaps.\n\nvlimtuple of length 2 | “joint”\n\nLower and upper bounds of the colormap, typically a numeric value in the same units as the data. Elements of the tuple may also be callable functions which take in a NumPy array and return a scalar.\n\nIf both entries are None, the bounds are set at ± the maximum absolute value of the data (yielding a colormap with midpoint at 0), or (0, max(abs(data))) if the (possibly baselined) data are all-positive. Providing None for just one entry will set the corresponding boundary at the min/max of the data. If vlim=\"joint\", will compute the colormap limits jointly across all projectors of the same channel type (instead of separately for each projector), using the min/max of the data for that channel type. If vlim is \"joint\", info must not be None. Defaults to (None, None).\n\ncnormmatplotlib.colors.Normalize | None\n\nHow to normalize the colormap. If None, standard linear normalization is performed. If not None, vmin and vmax will be ignored. See Matplotlib docs for more details on colormap normalization, and the ERDs example for an example of its use.\n\nNew in v1.2.\n\ncolorbarbool\n\nPlot a colorbar in the rightmost column of the figure.\n\ncbar_fmtstr\n\nFormatting string for colorbar tick labels. See Format Specification Mini-Language for details.\n\nNew in v1.2.\n\nunitsstr | None\n\nThe units to use for the colorbar label. Ignored if colorbar=False. If None the label will be “AU” indicating arbitrary units. Default is None.\n\nNew in v1.2.\n\naxesinstance of Axes | list of Axes | None\n\nThe axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of projectors. Default is None.\n\nshowbool\n\nShow the figure if True.\n\nReturns:\n\nfiginstance of Figure\n\nFigure distributing one image per channel across sensor topography.\n\nExamples using plot_projs_topomap:\n\nBuilt-in plotting methods for Raw objects\n\nBuilt-in plotting methods for Raw objects\n\nplot_psd(fmin=0, fmax=inf, tmin=None, tmax=None, picks=None, proj=False, reject_by_annotation=True, *, method='auto', average=False, dB=True, estimate='auto', xscale='linear', area_mode='std', area_alpha=0.33, color='black', line_alpha=None, spatial_colors=True, sphere=None, exclude='bads', ax=None, show=True, n_jobs=1, verbose=None, **method_kw)[source]#\n\nWarning\n\nLEGACY: New code should use .compute_psd().plot().\n\nPlot power or amplitude spectra.\n\nSeparate plots are drawn for each channel type. When the data have been processed with a bandpass, lowpass or highpass filter, dashed lines (╎) indicate the boundaries of the filter. The line noise frequency is also indicated with a dashed line (⋮). If average=False, the plot will be interactive, and click-dragging on the spectrum will generate a scalp topography plot for the chosen frequency range in a new figure.\n\nParameters:\n\nfmin, fmaxfloat\n\nThe lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=np.inf (spans all frequencies present in the data).\n\ntmin, tmaxfloat | None\n\nFirst and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).\n\npicksstr | array_like | slice | None\n\nChannels to include. Slices and lists of integers will be interpreted as channel indices. In lists, channel type strings (e.g., ['meg', 'eeg']) will pick channels of those types, channel name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given channels. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None (default) will pick good data channels (excluding reference MEG channels). Note that channels in info['bads'] will be included if their names or indices are explicitly provided.\n\nprojbool\n\nWhether to apply SSP projection vectors before spectral estimation. Default is False.\n\nreject_by_annotationbool\n\nWhether to omit bad spans of data before spectral estimation. If True, spans with annotations whose description begins with bad will be omitted.\n\nmethod'welch' | 'multitaper' | 'auto'\n\nSpectral estimation method. 'welch' uses Welch’s method , 'multitaper' uses DPSS tapers . 'auto' (default) uses Welch’s method for continuous data and multitaper for Epochs or Evoked data.\n\naveragebool\n\nIf False, the PSDs of all channels is displayed. No averaging is done and parameters area_mode and area_alpha are ignored. When False, it is possible to paint an area (hold left mouse button and drag) to plot a topomap.\n\ndBbool\n\nPlot Power Spectral Density (PSD), in units (amplitude**2/Hz (dB)) if dB=True, and estimate='power' or estimate='auto'. Plot PSD in units (amplitude**2/Hz) if dB=False and, estimate='power'. Plot Amplitude Spectral Density (ASD), in units (amplitude/sqrt(Hz)), if dB=False and estimate='amplitude' or estimate='auto'. Plot ASD, in units (amplitude/sqrt(Hz) (dB)), if dB=True and estimate='amplitude'.\n\nestimatestr, {‘auto’, ‘power’, ‘amplitude’}\n\nCan be “power” for power spectral density (PSD), “amplitude” for amplitude spectrum density (ASD), or “auto” (default), which uses “power” when dB is True and “amplitude” otherwise.\n\nxscale‘linear’ | ‘log’\n\nScale of the frequency axis. Default is 'linear'.\n\narea_modestr | None\n\nMode for plotting area. If ‘std’, the mean +/- 1 STD (across channels) will be plotted. If ‘range’, the min and max (across channels) will be plotted. Bad channels will be excluded from these calculations. If None, no area will be plotted. If average=False, no area is plotted.\n\narea_alphafloat\n\nAlpha for the area.\n\ncolorstr | tuple\n\nA matplotlib-compatible color to use. Has no effect when spatial_colors=True.\n\nline_alphafloat | None\n\nAlpha for the PSD line. Can be None (default) to use 1.0 when average=True and 0.1 when average=False.\n\nspatial_colorsbool\n\nWhether to color spectrum lines by channel location. Ignored if average=True.\n\nspherefloat | array_like | instance of ConductorModel | None | ‘auto’ | ‘eeglab’\n\nThe sphere parameters to use for the head outline. Can be array-like of shape (4,) to give the X/Y/Z origin and radius in meters, or a single float to give just the radius (origin assumed 0, 0, 0). Can also be an instance of a spherical ConductorModel to use the origin and radius from that object. If 'auto' the sphere is fit to digitization points. If 'eeglab' the head circle is defined by EEG electrodes 'Fpz', 'Oz', 'T7', and 'T8' (if 'Fpz' is not present, it will be approximated from the coordinates of 'Oz'). None (the default) is equivalent to 'auto' when enough extra digitization points are available, and (0, 0, 0, 0.095) otherwise.\n\nNew in v0.20.\n\nChanged in version 1.1: Added 'eeglab' option.\n\nNew in v0.22.0.\n\nexcludelist of str | ‘bads’\n\nChannels names to exclude from being shown. If ‘bads’, the bad channels are excluded. Pass an empty list to plot all channels (including channels marked “bad”, if any).\n\nNew in v0.24.0.\n\naxinstance of Axes | list of Axes | None\n\nThe axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must match the number of channel types present in the object.. Default is None.\n\nshowbool\n\nShow the figure if True.\n\nn_jobsint | None\n\nThe number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and mne.verbose() for details. Should only be passed as a keyword argument.\n\n**method_kw\n\nAdditional keyword arguments passed to the spectral estimation function (e.g., n_fft, n_overlap, n_per_seg, average, window for Welch method, or bandwidth, adaptive, low_bias, normalization for multitaper method). See psd_array_welch() and psd_array_multitaper() for details.\n\nReturns:\n\nfiginstance of Figure\n\nFigure with frequency spectra of the data channels.\n\nNotes\n\nThis method exists to support legacy code; for new code the preferred idiom is inst.compute_psd().plot() (where inst is an instance of Raw, Epochs, or Evoked).\n\nplot_psd_topo(tmin=None, tmax=None, fmin=0, fmax=100, proj=False, *, method='auto', dB=True, layout=None, color='w', fig_facecolor='k', axis_facecolor='k', axes=None, block=False, show=True, n_jobs=None, verbose=None, **method_kw)[source]#\n\nWarning\n\nLEGACY: New code should use .compute_psd().plot_topo().\n\nPlot power spectral density, separately for each channel.\n\nParameters:\n\ntmin, tmaxfloat | None\n\nFirst and last times to include, in seconds. None uses the first or last time present in the data. Default is tmin=None, tmax=None (all times).\n\nfmin, fmaxfloat\n\nThe lower- and upper-bound on frequencies of interest. Default is fmin=0, fmax=100.\n\nprojbool\n\nWhether to apply SSP projection vectors before spectral estimation. Default is False.\n\nmethod'welch' | 'multitaper' | 'auto'\n\nSpectral estimation method. 'welch' uses Welch’s method , 'multitaper' uses DPSS tapers . 'auto' (default) uses Welch’s method for continuous data and multitaper for Epochs or Evoked data.\n\ndBbool\n\nWhether to plot on a decibel-like scale. If True, plots 10 × log₁₀(spectral power). Ignored if normalize=True.\n\nlayoutinstance of Layout | None\n\nLayout instance specifying sensor positions (does not need to be specified for Neuromag data). If None (default), the layout is inferred from the data (if possible).\n\ncolorstr | tuple\n\nA matplotlib-compatible color to use for the curves. Defaults to white.\n\nfig_facecolorstr | tuple\n\nA matplotlib-compatible color to use for the figure background. Defaults to black.\n\naxis_facecolorstr | tuple\n\nA matplotlib-compatible color to use for the axis background. Defaults to black.\n\naxesinstance of Axes | list of Axes | None\n\nThe axes to plot into. If None, a new Figure will be created with the correct number of axes. If Axes are provided (either as a single instance or a list of axes), the number of axes provided must be length 1 (for efficiency, subplots for each channel are simulated within a single Axes object). Default is None.\n\nblockbool\n\nWhether to halt program execution until the figure is closed. May not work on all systems / platforms. Defaults to False.\n\nshowbool\n\nShow the figure if True.\n\nn_jobsint | None\n\nThe number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_config context manager that sets another value for n_jobs.\n\nverbosebool | str | int | None\n\nControl verbosity of the logging output. If None, use the default verbosity level. See the logging documentation and m"
    }
}