{
    "id": "dbpedia_3787_1",
    "rank": 66,
    "data": {
        "url": "https://docs.newrelic.com/docs/nrql/nrql-syntax-clauses-functions/",
        "read_more_link": "",
        "language": "en",
        "title": "NRQL reference",
        "top_image": "https://docs.newrelic.com/favicon-32x32.png?v=c6adf0dad65cc1d73c93c5e0b1680678",
        "meta_img": "https://docs.newrelic.com/favicon-32x32.png?v=c6adf0dad65cc1d73c93c5e0b1680678",
        "images": [
            "https://docs.newrelic.com/static/nrql_screenshot-crop_example-faceted-inner-join-7469e44421e970b91167efe55b4cff61.webp",
            "https://docs.newrelic.com/static/nrql_screenshot-crop_example-faceted-left-join-7be7b4fdf03c570bb8444fa6ce50f6ce.webp",
            "https://docs.newrelic.com/static/nrql_screenshot-crop_example-columnar-inner-join-603be1caec707138109c33b385c8cc92.webp",
            "https://docs.newrelic.com/static/queries-nrql_screenshot-full_apdex-NRQL-query-builder-10c2ba427bab8e7217aef5052046149e.webp",
            "https://docs.newrelic.com/static/queries-nrql_screenshot-full_filter-NRQL-query-builder-28b2e788d45725c4cd5805e7300f72a0.webp",
            "https://docs.newrelic.com/static/nrql_screenshot-crop_example-joined-median-8f45567931ccda56dfcdedd5cce6ee8c.webp",
            "https://docs.newrelic.com/static/queries-nrql_screenshot-full_percentile-NRQL-query-builder-733a1fd46d913bcf778e0949dcbc9916.webp",
            "https://docs.newrelic.com/static/nrql_screenshot-crop_example-joined-percentile-7961c718257fabc7e2539b7b05e076ab.webp",
            "https://docs.newrelic.com/static/lowerExample-9dc669d4c68848ae52d20524cd230242.webp",
            "https://docs.newrelic.com/static/positionExample-521c58e6e9fb3c3774f36385131fc158.webp",
            "https://docs.newrelic.com/static/substringExample-787c6f33f95588c97863d19249374cf8.webp",
            "https://docs.newrelic.com/static/upperExample-2a839b0b0402da604068a502a064e278.webp",
            "https://px.ads.linkedin.com/collect/?pid=7273&fmt=gif"
        ],
        "movies": [
            "//www.youtube.com/embed/b9WVyb1wU6w?modestbranding=1",
            "//www.youtube.com/embed/9UArmB4QiVM?modestbranding=1",
            "//www.youtube.com/embed/hOPrTWYgPHg?modestbranding=1"
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "A detailed reference list of clauses and functions in NRQL, the New Relic query language.",
        "meta_lang": "en",
        "meta_favicon": "/favicon-32x32.png?v=c6adf0dad65cc1d73c93c5e0b1680678",
        "meta_site_name": "",
        "canonical_link": "https://docs.newrelic.com/docs/nrql/nrql-syntax-clauses-functions/",
        "text": "To write good NRQL queries, it helps to understand how our various NRQL clauses and functions work. This doc contains definitions of NRQL clauses and functions, and gives examples of how to use them.\n\nLooking for basic NRQL syntax rules? See How to use NRQL. For a tutorial, see Introductory NRQL tutorial.\n\nQuery components\n\nAs noted in our basic NRQL syntax doc, every NRQL query will contain a SELECT clause and a FROM clause, with all other clauses being optional. The clause definitions below also contain example NRQL queries.\n\nRequired clauses\n\nSELECT attribute ...\n\nSELECTfunction(attribute)...\n\nThe SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can:\n\nGet the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction.\n\nGet values associated with a specified attribute or multiple attributes specified in a comma separated list.\n\nGet aggregated values from specified attributes by selecting an aggregator function.\n\nLabel the results returned in each argument with the AS clause.\n\nYou can also use SELECT with basic math functions.\n\nThis query returns the average response time since last week.\n\nSELECT average(duration)FROM PageView SINCE 1 week ago\n\nSELECT...\n\nFROMdatatype\n\n...\n\nUse the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list.\n\nThis query returns the count of all APM transactions over the last seven days:\n\nSELECTcount(*)FROMTransaction SINCE 7 days ago\n\nThis query returns the count of all APM transactions and browser events over the last three days:\n\nSELECTcount(*)FROMTransaction, PageView SINCE 3 days ago\n\nOptional clauses\n\nSELECT...\n\nAS'label'\n\n...\n\nUse the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Note that AS clause labels in time series charts will not be displayed if a FACET clause is used.\n\nThis query returns the number of page views per session:\n\nSELECTcount(*)/uniqueCount(session)AS'Pageviews per Session'\n\nFROM PageView\n\nThis query returns a count of people who have visited both the main page and the careers page of a site over the past week:\n\nSELECT funnel(SESSION,\n\nWHERE name='Controller/about/main'AS'Step 1',\n\nWHERE name ='Controller/about/careers'AS'Step 2')\n\nFROM PageView SINCE 1 week ago\n\nSELECT...(SINCE or UNTIL)(integer units) AGO\n\nCOMPARE WITH(integer units) AGO\n\n...\n\nUse the COMPARE WITH clause to compare the values for two different time ranges.\n\nCOMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before.\n\nThe time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm.\n\nCOMPARE WITH can be formatted as either a line chart or a billboard:\n\nWith TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time.\n\nWithout TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value.\n\nExample: This query returns data as a line chart showing the 95th percentile for the past week compared to the same range one week ago. First as a single value, then as a line chart.\n\nSELECT percentile(duration,95)FROM PageView\n\nSINCE 1 week ago COMPARE WITH1 week AGO\n\nSELECT percentile(duration,95)FROM PageView\n\nSINCE 1 week ago COMPARE WITH1 week AGO TIMESERIES AUTO\n\nImportant\n\nFor FACET queries using COMPARE WITH, the facets in the result are selected based on the time range specified using SINCE and UNTIL and not the prior time range being compared. The results of a FACET query for the prior time range alone may include a different set of facets.\n\nYou can use this clause with these data types:\n\nTransaction\n\nTransactionError\n\nCustom events reported via agent APIs\n\nThe purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system.\n\nThis clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events.\n\nWhen EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect.\n\nImportant\n\nNote that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()).\n\nThis clause works only with NRQL queries that use one of the following aggregator functions:\n\napdex\n\naverage\n\ncount\n\nhistogram\n\nsum\n\npercentage (if function it takes as an argument supports EXTRAPOLATE)\n\nrate (if function it takes as an argument supports EXTRAPOLATE)\n\nstddev\n\nA query that will show the extrapolated throughput of a service named interestingApplication.\n\nSELECTcount(*)FROMTransactionWHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE\n\nA query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series.\n\nSELECTcount(*)FROMTransactionWHERE appName='interestingApplication'\n\nSINCE 60 minutes ago FACET name TIMESERIES 1minute EXTRAPOLATE\n\nSELECT...\n\nFACET attribute\n\n...\n\nUse FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices.\n\nUse the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas.\n\nThe facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 5,000 unique values, a subset of facet values is selected and sorted according to the query type. Note that if a time series chart returns no data (NRQL matches no matching data, invalid NRQL, etc.) then it will only show a flat line with the label matching the first table in the FROM clause.\n\nWhen selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted.\n\nThis query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered.\n\nSELECTcount(*)FROM PageView FACET city\n\nThis query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered.\n\nSELECT uniqueCount(pageUrl)FROM PageView FACET city\n\nAdvanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data.\n\nCohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times.\n\nImportant\n\nWhen using functions to aggregate attribute values, it's important the attribute being aggregated in the first function of your query contains non-null values. Facets will only be chosen for rows which contain a non-null value for the attribute in the first function.\n\nExample:\n\nFROM Event SELECT average(attribute) FACET name\n\nNames will only be chosen from rows where attribute is not null.\n\nTo check if the attribute you're using in your function contains non-null values, run the following query:\n\nFROM Event SELECT attribute, name WHERE attribute ISNOTNULL\n\nUse FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries.\n\nFACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves.\n\nFROMTransactionSELECTcount(*) FACET response.headers.contentType AS'content type'\n\nSELECT...\n\nFACET CASES (\n\nWHERE attribute operator value,WHERE attribute operator value,...\n\n)\n\n...\n\nUse FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match.\n\nYou may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases.\n\nSELECTcount(*)FROM PageView FACET CASES (WHERE duration <1,WHERE duration >1and duration <10,WHERE duration >10)\n\nThis example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user:\n\nSELECTcount(*)FROMTransaction FACET CASES (WHERE name LIKE'%login%',WHERE name LIKE'%feature%'AND customer_type='Paid')\n\nThis example uses the AS selector to give your results a human-readable name:\n\nSELECTcount(*)FROMTransaction FACET CASES (WHERE name LIKE'%login%'AS'Total Logins',WHERE name LIKE'%feature%'AND customer_type='Paid'AS'Feature Visits from Paid Users')\n\nThis example uses the OR operator to facet results that didn't match any of your cases:\n\nSELECTcount(*)FROMTransaction FACET CASES (WHERE name LIKE'%login%',WHERE name LIKE'%feature%'AND customer_type='Paid')OR name\n\nIn NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming.\n\nThis example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection.\n\nFROMTransactionSELECT average(duration) TIMESERIES FACET appName ORDERBYmax(responseSize)\n\nKeep in mind that if you use the FACET ... ORDER BY clause, you can't change the sort order by adding the ASC and DESC modifiers. By default, this clause uses DESC.\n\nTip\n\nBecause the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-time series queries.\n\nImportant\n\nThe ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause.\n\nUse the JOIN clause to combine data from one event type with the results of a subquery based on a common attribute or key.\n\nFROM Event [INNER|LEFT]JOIN(SELECT...FROM...)ON[key=]keySELECT...\n\nThere are a few simple rules for subquery joins:\n\nThe JOIN clause must always follow immediately after the FROM clause.\n\nPrefixing a join type (INNER or LEFT) is optional. When omitted, the join type defaults to INNER.\n\nParenthesis containing a subquery must immediately follow JOIN.\n\nThe ON clause must immediately follow the subquery.\n\nJoin types\n\nJoin ON clause\n\nON parentKey = subqueryKey\n\nDefines the key values to compare in the subquery and the outer query. The only comparison operator allowed is equality.\n\nThe left-hand side is always the key used in the parent query and may be an attribute or function.\n\nThe right-hand side is used for the subquery key value, and must be an identifier.\n\nON key\n\nThis is an abbreviated syntax for when the key identifier is the same in both contexts. It is equivalent to ON key = key.\n\nRestrictions and limitations to consider:\n\nThe joined subquery will continue to have a default LIMIT of 10, with a maximum LIMIT of 5,000. Note that the outer query's LIMIT does not affect the inner query.\n\nThe use of TIMESERIES in the joined subquery is not supported. If your outer query uses TIMESERIES, keep in mind that the joined subquery will provide a single result for the full query timespan.\n\nLike all subqueries, joined subqueries cannot be used in alert conditions.\n\nWhile SELECT * is supported in the parent query, it is not supported in the joined subquery.\n\nThe cardinality of the join is limited to 1:100, meaning a single join key cannot map to more than one hundred rows in the subquery result.\n\nFor an in depth look at the JOIN clause, please see the NRQL subquery joins tutorial.\n\nThis query finds the count of events faceted by browserTransactionName from the PageView event type, and then by currentUrl from the PageAction event type. This joins the two event types based on common session attribute values.\n\nFROM PageView\n\nJOIN(FROM PageAction SELECTcount(*) FACET session, currentUrl)ONsession\n\nSELECTcount(*) FACET browserTransactionName, currentUrl\n\nThis example queries the same data as the faceted INNER JOIN example, but as a LEFT JOIN query, the results include items in the PageView table that do not have matching session values in the results of the PageAction subquery.\n\nFROM PageView\n\nLEFTJOIN(FROM PageAction SELECTcount(*) FACET session, currentUrl)ONsession\n\nSELECTcount(*) FACET browserTransactionName, currentUrl\n\nHere we are performing an unaggregated, row-wise subquery, with the outer query finding the count of events faceted by currentUrl from the PageAction event type, and then by browserTransactionNamed from the PageView event type. This joins the two event types based on common session attribute values.\n\nNote that the session value 34d5ce6acf4c60be has two browserTransactionName values from the subquery's PageView event type, adding additional rows to the result.\n\nFROM PageAction\n\nleftJOIN(FROM PageView SELECTsession, browserTransactionName LIMIT MAX)ONsession\n\nSELECTcount(*) FACET session, currentUrl, browserTransactionName LIMIT MAX\n\nSELECT...\n\nLIMIT count\n\n...\n\nUse the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries.\n\nThe maximum allowed value for the LIMIT clause is 5,000. Queries can use the LIMIT MAX clause instead of a specific value, which automatically defaults to the current maximum value. You can use this if you always want to post the maximum number of results, even if it changes in the future. If you want your query's behavior to remain unchanged, specify an explicit value instead of using LIMIT MAX.\n\nThis query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only.\n\nSELECT uniqueCount(session), percentile(duration,95)\n\nFROM PageView WHERE userAgentOS ='Windows'\n\nFACET countryCode LIMIT20 SINCE YESTERDAY\n\nSELECT...\n\nLIMIT count OFFSET count\n\n...\n\nUse the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT.\n\nOFFSET rows are skipped starting from the most recent record.\n\nFor example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one.\n\nThe ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row.\n\nThis query orders two specific transaction attributes by duration.\n\nFROMTransactionSELECT appName, duration ORDERBY duration\n\nThe default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers.\n\nThis query orders all transaction attributes by duration in descending order.\n\nFROMTransactionSELECT*ORDERBY duration DESC\n\nImportant\n\nThe ORDER BY clause does not apply to FACET queries. It should not be confused with the FACET ... ORDER BY clause, which guides facet selection. For more information, see FACET ... ORDER BY.\n\nSHOW EVENT TYPES...\n\nSHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT.\n\nImportant\n\nIn this context, \"event types\" refers to the data types you can access with a NRQL query.\n\nThis query will return all the data types present over the past day:\n\nSHOW EVENT TYPES SINCE 1day ago\n\nSELECT...\n\nSINCE [numerical units AGO | phrase]\n\n...\n\nThe default value is 1 hour ago.\n\nUse the SINCE clause to define the inclusive beginning of a time range for the returned data. You can specify a time zone for the query but not for the results. NRQL results are based on your system time.\n\nWhen using NRQL, you can set a UTC timestamp, a relative time, or a DateTime string. See Specifying a time.\n\nSee also:\n\nSetting a query's time range\n\nUNTIL\n\nThe SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time.\n\nTo use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on.\n\nSELECT average(duration)FROMTransaction TIMESERIES 5 minutes SLIDE BY1minute\n\nTo learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Or, watch this short video (approx. 3:20 minutes).\n\nYou can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY.\n\nThis query will automatically decide a SLIDE BY window interval.\n\nSELECT average(duration)FROMTransaction TIMESERIES 5 minutes SLIDE BY AUTO\n\nThis query will set the SLIDE BY window to the maximum interval granularity.\n\nSELECT average(duration)FROMTransaction TIMESERIES 5 minutes SLIDE BY MAX\n\nImportant\n\nThe SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results.\n\nSELECT...\n\nTIMESERIES integer units\n\n...\n\nUse the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value.\n\nTo indicate the time range, use integer units. For example:\n\nTIMESERIES 1 minute\n\nTIMESERIES 30 minutes\n\nTIMESERIES 1 hour\n\nTIMESERIES 30 seconds\n\nTIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below.\n\nImportant\n\nFor functions such as average() or percentile(), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows.\n\nThe value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments:\n\nSELECT... SINCE 1day AGO TIMESERIES 30 minutes\n\nTIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals.\n\nThis query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours.\n\nSELECT average(duration), percentile(duration,50,90)\n\nFROM PageView SINCE 1 week AGO TIMESERIES AUTO\n\nYou can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366.\n\nFor example, the following query creates 4-minute intervals, which is the ceiling for a daily chart.\n\nSELECT average(duration)FROMTransaction since 1day ago TIMESERIES MAX\n\nSELECT...\n\nUNTIL integer units AGO\n\n...\n\nUse the UNTIL clause to define the end of the time range to query. The value is exclusive, meaning the time range will go to the specified instant in time, but not include it.\n\nThe default value is NOW. Only use UNTIL to specify an end point other than the default.\n\nSee also:\n\nSetting a query's time range\n\nSINCE\n\nUse the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause.\n\nSELECTfunction(attribute)...\n\nWHERE attribute [operator 'value'|IN('value'[,'value'])|IS[NOT]NULL]\n\n[AND|OR...]\n\n...\n\nIf you specify more than one condition, separate the conditions by the operators AND or OR.\n\nOperators that the WHERE clause accepts\n\nDescription\n\nThis query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours.\n\nSELECT histogram(duration,50,20)FROM PageView\n\nWHERE countryCode IN('CA','US')AND userAgentName='Safari'AND pageUrl LIKE'%checkout%'\n\nSINCE 1day ago\n\nSELECT...WITH TIMEZONE (selected zone)\n\n...\n\nUse the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it.\n\nIf you include the WITH TIMEZONE clause without specifying a time zone in a date time, the since and until clauses keep in the provided time zone.\n\nIf you don't include the WITH TIMEZONE clause, but you include a time zone in a date time string, your date time string time zone keeps.\n\nImportant\n\nThe default time zone is always UTC if one is not specified. The raw timestamp values (as seen in the JSON view) in the results are always UTC. The UI displays the results in the time zone you've specified in your account settings. A time zone in a time stamp string always works. It supersedes the WITH TIMEZONE zone.\n\nFor example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' returns data recorded from Monday at midnight, America/New York time, until midnight Tuesday, America/New York time.\n\nHere are some examples of query timespan clauses:\n\nNo time zone in date time string using the WITH TIMEZONE clause:\n\nSINCE today UNTIL '2022-05-19T12:00'WITH TIMEZONE 'America/Los_Angeles'\n\nThis resolves as \"beginTime\": \"2022-05-19T07:00:00Z\" and \"endTime\": \"2022-05-19T19:00:00Z\".\n\nTime zone in date time string, not using the WITH TIMEZONE clause:\n\nSINCE today UNTIL '2022-05-19T12:00-0500'\n\nThis resolves as \"beginTime\": \"2022-05-19T00:00:00Z\" and \"endTime\": \"2022-05-19T17:00:00Z\".\n\nTime zone in date time string, using the WITH TIMEZONE clause America/Los Angeles, which is -0700 during daylight saving time:\n\nSINCE today UNTIL '2022-05-19T12:00-0500'WITH TIMEZONE 'America/Los_Angeles'\n\nThis resolves as \"beginTime\": \"2022-05-19T07:00:00Z\" and \"endTime\": \"2022-05-19T19:00:00Z\".\n\nSee the available Zone IDs list.\n\nSee Set time range on dashboards and charts for detailed information and examples.\n\nQuery metric data\n\nMetric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines:\n\nQuery dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration).\n\nQuery metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and .\n\nFor more details about how we report metric data, see Metric data types.\n\nFunctions\n\nIn this section we explain NRQL functions, both aggregator functions and non-aggregator functions.\n\nAggregator functions\n\nYou can use aggregator functions to filter and aggregate data. Some tips for using these:\n\nSee New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries.\n\nIf you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example:\n\nSELECT median(one_metric)as'med-a', median(another_metric)as'med-b'\n\nData type \"coercion\" is not supported. Read about available type conversion functions.\n\nFor how to display results over time, see Group results over time.\n\nExamples:\n\nSELECT histogram(duration,10,20)FROM PageView SINCE 1 week ago\n\nUse the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a time series query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period.\n\nUse the apdex function to return an Apdex score for a single transaction or for all your transactions. The default Apdex score is 0.5 seconds. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds.\n\nThe Apdex score returned by the apdex() function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex () function.\n\nIf you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer:\n\nSELECT apdex(duration, t: 0.4)FROMTransaction\n\nWHERE customerName='ReallyImportantCustomer' SINCE 1day ago\n\nUse the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour:\n\nSELECT apdex(duration, t: 0.5)fromTransaction\n\nWHERE name='Controller/notes/index' SINCE 1hour ago\n\nThis example query returns an overall Apdex for the application over the last three weeks:\n\nSELECT apdex(duration, t: 0.08)FROMTransaction SINCE 3 week ago\n\nUse the average() function to return the mean average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null.\n\nThe bucketPercentile() function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100.\n\nUse the bucketPercentile() function to calculate the quantile from the histogram data in a Prometheus format.\n\nIt takes the bucket name as an argument and reports percentiles along the bucket's boundaries:\n\nSELECT bucketPercentile(duration_bucket)FROM Metric SINCE 1day ago\n\nOptionally, you can add percentile specifications as an argument:\n\nSELECT bucketPercentile(duration_bucket,50,75,90)FROM Metric SINCE 1day ago\n\nBecause multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>.\n\nFor example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _bucket is added to the end of the <basename> as a suffix.\n\nSee the Prometheus.io documentation for more information.\n\nUse the cardinality() function to obtain the number of combinations of all the dimensions (attributes) on a metric.\n\nIt takes three arguments, all optional:\n\nMetric name: if present, cardinality() only computes the metric specified.\n\nInclude: if present, the include list restricts the cardinality computation to those attributes.\n\nExclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation.\n\ncdfPercentage() is an implementation of the cumulative distribution function, returning percentages of attribute values whose value is less than or equal to one or more thresholds.\n\ncdfPercentage() aggregates on its attribute argument, which can be either a numeric attribute or a distribution metric attribute. Mixed types in one query are accepted. Other types (such as string) are ignored. Up to 10 thresholds can be specified.\n\nThis query returns the percentage of events where firstPaint is less than or equal to 0.5 seconds, and the percentage of events where firstPaint is less than or equal to 1 second.\n\nFROM PageView SELECT cdfPercentage(firstPaint,0.5,1.0)\n\nUse the count() function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument.\n\nSince count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format.\n\nderivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value.\n\nThe time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute.\n\nUse the earliest() function to return the earliest value for an attribute over the specified time range.\n\nIt takes a single argument.\n\nIf used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets.\n\nThis query returns the earliest country code per each user agent from the PageView event.\n\nSELECT earliest(countryCode)FROM PageView FACET userAgentName\n\nUse the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as:\n\nSELECT filter(sum(x),WHERE attribute='a')AS'A', filter(sum(x),WHERE attribute='b')AS'B'...\n\nOtherwise, it's better to just use the standard WHERE clause.\n\nYou could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't:\n\nUse the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas.\n\nFor details and examples, see the funnels documentation.\n\nUse the histogram() function to generate histograms, which are useful for visualizing the distribution of a dataset. It divides the dataset into a specified number of buckets and counts the number of data points that fall into each bucket.\n\nArguments:\n\nattribute The first argument is required and specifies the attribute for which to count values that fall within each histogram bucket range.\n\nwidth: Inidicates the width of the sample range. The maximum value of the range is the start argument value plus this width value.\n\nWhen using positional (non-labeled) arguments, width is the second argument.\n\nDefault: 10\n\nbuckets: Total number of buckets (between 1 and 500, inclusive).\n\nWhen using positional (non-labeled) arguments, buckets is the third argument.\n\nDefault: 40\n\nstart: The beginning of the histogram range.\n\nWhen using positional (non-labeled) arguments, start is the fourth argument.\n\nDefault: 0\n\nNote\n\nValues that fall outside the defined histogram range are included in the first or last buckets. The first bucket count will include items that are smaller than the histogram range, and the last bucket count will include items that are larger than the histogram range. To exclude these values from the histogram results, include a filter in the query's where clause. (Example: WHERE attribute >= [start] AND attribute <= [start + width])\n\nThis query results in a histogram of response times ranging up to 10 seconds over 40 buckets. This means each bucket covers a 0.25 second range of values. (10 / 40 = 0.25). Any duration values larger than 10 seconds are included in the last bucket. If duration could be less than zero, those values would be included in the first bucket.\n\nSELECT histogram(duration)FROM PageView SINCE 1 week ago\n\nThese equivalent queries result in a histogram of response times ranging up to 5 seconds over 10 buckets.\n\nSELECT histogram(duration,5,10)FROM PageView SINCE 1 week ago\n\nSELECT histogram(duration, width: 5, buckets: 10)FROM PageView SINCE 1 week ago\n\nThese equivalent queries result in a histogram of response times ranging from 1 to 4 seconds over 3 buckets.\n\nHere is a breakdown of the buckets:\n\nBucket 1\n\nBucket 2\n\nBucket 3\n\nSELECT histogram(duration,3,3,1)FROM PageView SINCE 1 week ago\n\nSELECT histogram(duration, width: 3, buckets: 3,start: 1)FROM PageView SINCE 1 week ago\n\nhistogram() accepts Prometheus histogram buckets:\n\nSELECT histogram(duration_bucket,10,20)FROM Metric SINCE 1 week ago\n\nhistogram() accepts Distribution metric as an input:\n\nSELECT histogram(myDistributionMetric,10,20)FROM Metric SINCE 1 week ago\n\nUse histogram() with a FACET clause to generate a heatmap chart:\n\nSELECT histogram(duration)FROM PageView FACET appName SINCE 1 week ago\n\nUsing keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys.\n\nThis query returns the attributes found for PageView events from the last day:\n\nSELECT keyset()FROM PageView SINCE 1day ago\n\nUse the latest() function to return the most recent value for an attribute over a specified time range.\n\nIt takes a single argument.\n\nIf used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets.\n\nThis query returns the most recent country code per each user agent from the PageView event.\n\nSELECT latest(countryCode)FROM PageView FACET userAgentName\n\nUse the latestrate() function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval.\n\nThis function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends.\n\nThis query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument.\n\nSELECT latestrate(duration,1SECOND)FROM PageView\n\nUse the max() function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null.\n\nUse the median() function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile().\n\nTip\n\nThe median() query is only available when using the query builder.\n\nThis query will generate a line chart for the median value.\n\nSELECT median(duration)FROM PageView TIMESERIES AUTO\n\nMedian in a JOIN clause:\n\nBecause median is simply a shortcut for percentile(attribute, 50), a median() result from a joined subquery is a compound data type, which maps the 50th percentile to its calculated value.\n\nTo reference the actual median value in the outer query, you can use the getField() function. Note, the mapped key is a string representation of a double value, so for median() it is '50.0'.\n\nFROM PageView\n\nJOIN(FROM PageAction SELECT median(timeSinceLoad) FACET session, currentUrl)ONsession\n\nSELECT latest(getField(median,'50.0'))as median\n\nFACET browserTransactionName, currentUrl\n\nUse the min() function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null.\n\nUse the percentage() function to return the percentage of a target data set that matches some condition.\n\nThe first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%.\n\nFROMTransactionSELECT percentage(count(*),WHERE error istrue)AS'Error Percent'Where host LIKE'%west%' EXTRAPOLATE\n\nUse the percentile() function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved.\n\nUse TIMESERIES to generate a line chart with percentiles mapped over time.\n\nOmit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles.\n\nIf no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median().\n\nThis query will generate a line chart with lines for the 5th, 50th, and 95th percentile.\n\nSELECT percentile(duration,5,50,95)FROM PageView TIMESERIES AUTO\n\nPercentile in a JOIN clause:\n\nWhen using percentiles in a joined subquery, please note the results from the subquery are a compound data type, which maps each percentile to its calculated value.\n\nTo reference any of the individual percentile values in the outer query, you can use the getField() function. Note, the mapped key is a string representation of a double value, so you need to add .0 to integers. For example, the key for the 95th percentile is '95.0'.\n\nFROM PageView\n\nJOIN(FROM PageAction SELECT percentile(timeSinceLoad,95,99.5)as pctl FACET session, currentUrl)ONsession\n\nSELECT latest(getField(pctl,'95.0'))as`95th`, latest(getField(pctl,'99.5'))as`99.5th`\n\nFACET browserTransactionName, currentUrl\n\npredictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset.\n\nThe time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window.\n\nGenerally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends.\n\nSince predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions.\n\nAny dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions.\n\nNew Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the time series forward.\n\nUse the rate() function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period.\n\nUse TIMESERIES to generate a line chart with rates mapped over time.\n\nOmit TIMESERIES to generate a billboard showing a single rate value averaged over time.\n\nHere's a basic query that will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours:\n\nSELECT rate(count(*),10minute)FROMTransaction SINCE 6 hours ago\n\nTIMESERIES\n\nHere's a short video (3:21 minutes) explaining how to use rate to compare data across different time windows:\n\nUse the stdvar() function to return the standard variance for a numeric attribute over the time range specified.\n\nIt takes a single argument. If the attribute is not numeric, it will return a value of zero.\n\nUse the sum() function to return the sum recorded values of a numeric attribute over the time range specified.\n\nIt takes a single argument. If the attribute is not numeric, it will return a value of zero.\n\nUse the uniqueCount() function to return the number of unique values recorded for an attribute over the time range specified.\n\nTip\n\nTo optimize query performance, this function returns approximate results for queries that inspect 256 or more unique values.\n\nUse the uniques() function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value.\n\nThe limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques() function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency.\n\nThe maximum number of values that can be returned in a query result is the product of the uniques() limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000).\n\nDepending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed.\n\nFromTransactionSELECT uniques(host,5000) FACET appName LIMIT1000\n\nIf you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ... to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination.\n\nFROM NodeStatus SELECT uniques(tuple(index, cellName),5)\n\nNon-aggregator functions\n\nUse non-aggregator functions for non-numerical data in NRQL queries.\n\nUse the accountId() function to return the account ID associated with queried data. This function takes no arguments. Here are some example queries:\n\nThis query returns the account ID associated with each Transaction event returned:\n\nSELECT accountId()FROMTransaction SINCE 1day ago\n\nThis query returns the number of Transaction events in the last day that are associated with each account ID:\n\nSELECTcount(*)FROMTransaction FACET accountId() SINCE 1day ago\n\nThis query returns the number of Transaction events in the last day where the account ID is specifically one of 1, 2, or 3:\n\nSELECTcount(*)FROMTransactionWHERE accountId()IN(1,2,3) SINCE 1day ago\n\nUse the anchor parse function, aparse() to extract specific values from a string. This is an alternative to capture().\n\naparse() takes two arguments:\n\nA string attribute\n\nA pattern string with anchor strings and extract characters. For example, you could use www.*.com to extract the domain from a URL.\n\nWhen using aparse(), the pattern string should contain anchors, like www. and .com above, to identify the location of the intended extracted string, noted by *.\n\naparse() uses the following characters in pattern strings:\n\n%: Non-capturing wildcard, as you'd see in the LIKE clause\n\n*: Capturing wildcard, similar to using regex capture\n\nIn practice, the anchor strings often occur in the middle of a string attribute, and not at the beginning or end.\n\nIn this case, use the % wildcard to ignore unwanted values: for example, %www.*.com%.\n\nLike capture(), all results from aparse() are strings. To use these results in math functions they must cast with the numeric() function.\n\nNote: aparse() is case-insensitive.\n\nFROM PageView\n\nSELECT aparse(browserTransactionName,'website.com/*')\n\nTo extract a value from the middle of a string, use the non-capturing wildcard, %, at the beginning and end of the pattern string. For example:\n\nFROM Log\n\nSELECTcount(*)\n\nFACET aparse(string,'%\"itemId\":\"*\"%')\n\nWhen extracting multiple values as variables, note that the order matters. For example:\n\nFROM Log\n\nWITH aparse(string,'POST: * body: {\"itemId\":\"*\",\"unitPrice\":*}\\n')AS(url, itemId, unitPrice)\n\nSELECT url, itemId, unitPrice\n\nFor more on variables, see NRQL variables.\n\nUse the blob() function on a blob type attribute to return a base-64 encoded string of that attribute.\n\nThis function has the following restrictions:\n\nQueries containing calls to blob() have a max LIMIT value of 20\n\nblob() cannot be called in the WHERE clause of a query\n\nblob() cannot be used in faceted queries or time series queries\n\nFor more information about how this is used in Logging, see Find data in long logs (blobs).\n\nTo decode a base-64 encoded blob, see the decode() function.\n\nSELECT message,blob(`newrelic.ext.message`)FROM Log WHERE newrelic.ext.message ISNOTNULL\n\nUse the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database.\n\nIt takes three arguments:\n\nAttribute name\n\nMaximum value of the sample range (any outliers will appear in the final bucket)\n\nTotal number of buckets\n\nFor more information and examples, see Split your data into buckets.\n\nUse the concat() function to return the string resulting from concatenating its arguments.\n\nUp to 20 arguments of numeric, boolean, tuple, or array types may be provided. Null arguments and arguments of unsupported types are ignored. If no arguments are provided, the result is the empty string.\n\nThe optional precision argument may be provided in order to limit the number of decimal places included when concatenating floating-point numeric values.\n\nThe resulting string may have a maximum length of 4096 characters.\n\nThis query returns backend and network durations from the PageView event, formatted with two decimal places and labels, as a single string.\n\nFROM PageView SELECT concat('Backend Duration: ', backendDuration,', Network Duration: ', networkDuration,precision: 2)\n\nThis would return responses in a format like:\n\nBackend Duration: 0.69, Network Duration: 0\n\nThis query returns the average connection setup duration from the PageView event, faceted by a string composed of the user's city, region, and country.\n\nFROM PageView SELECT average(connectionSetupDuration) FACET concat(city,', ', regionCode,' ', countryCode)WHERE countryCode IN('US','CA')\n\nUse the convert() function to perform unit conversion between the provided units on the given input value.\n\nCommon units and abbreviations for time, length, weight, volume, and data are supported using the UCUM standards to align with OpenTelemetry specifications. For convenience, the standardized abbreviations are augmented by some natural language alternatives like ft in addition to ft_us, kilobytes, and µs.\n\nThe units are case sensitive. All units are lowercase, unless their specification requires them to be uppercase. For example, the data units 'bits' is valid for bits and 'By' must have a capital B for bytes.\n\nThe largest unit of time is the Julian year, which is always 365.25 days.\n\nFROMTransactionSELECTconvert(duration,'ms','min')AS durationMin\n\nFROM Product SELECTconvert(sum(itemWeight),'grams','lbs')\n\nThis query assumes you have the unit information stored as a string attribute in the event itself, and that you'd like to standardized the values to seconds.\n\nFROM Metric SELECT average(convert(apm.mobile.external.duration, unit,'s'))WHERE appName ='my-application'\n\nUse capture() to extract values from an attribute using a regular expression with RE2 syntax.\n\nIt takes two arguments:\n\nAttribute name\n\nRegular expression with capture syntax (regex expressions in NRQL use Python-like syntax, r'...')\n\nWhen capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name.\n\nMultiple values can be captured by specifying additional capture groups in a regular expression. For example: ...(?P<name1> pattern1)...(?P<name2> pattern2)...\n\nNote: When capturing multiple values, each capture statement can have up to 16 capture groups, and each NRQL query can have up to 5 capture statements.\n\nRead how to use regex capture to improve your query results.\n\nTip\n\nThe regular expression must match its entire input. If a capture expression is not extracting the expected results, check whether it needs .* at the beginning or end, which is the pattern for a partial match regex. However, the partial match regex may cause a slower query execution.\n\nHere's a short video (3:05 minutes) showing how to use capture() to improve dashboard readability:\n\nFor more information, see the examples below:\n\nThe following will select the domain name of the website, removing https:// and any paths following the .com\n\nSELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+')FROM PageView SINCE 1day ago\n\nThe following will capture only the first word of the error message.\n\nSELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+')FROMTransaction SINCE 1hour ago where errorMessage isnotnull\n\nThe following will facet by the captured HTTP method.\n\nSELECTcount(*)FROM Log WHERE message like'%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*')\n\nThe following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob.\n\nSELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*')='ExampleJob' SINCE 10 minutes ago\n\nThe following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations.\n\nSELECTsum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)')))FROM Log WHERE message like'%CpuTime:%' SINCE 1hour ago\n\nIn this example NRQL Variables are used to store multiple captured values from a log message.\n\nFROM Log\n\nWITH capture(message, r'POST to carts: (?P<URL>.*) body: {\"itemId\":\"(?P<UUID>.*)\",\"unitPrice\":(?P<unitPrice>.*)}.*')\n\nAS(URL, UUID, unitPrice)\n\nSELECT URL, UUID, unitPrice\n\nWHERE URL ISNOTNULL\n\nSee more on NRQL Variables here.\n\nUse decode() to perform base-64 conversions on strings and blobs. The input value (the first argument) will be decoded using the base-64 standard specified by the encoding (the second argument).\n\nThe following string values are supported encoding parameters:\n\n'base64': Uses the RFC4648 base-64 standard\n\n'base64mime': Uses the RFC2045 base-64 standard (MIME)\n\n'base64url': Uses the RFC4648 base-64 standard with URL and filename safe alphabet\n\nAs blob() is not allowed in WHERE or FACET clauses, decode() with blob types is not supported in the WHERE clause or for faceted queries.\n\nTo encode strings, see the encode() function.\n\nFROM Span SELECT entity.guid, decode(entity.guid,'base64')WHERE entity.guid ISNOTNULL\n\nFROM Span SELECTcount(*)WHERE entity.guid ISNOTNULL FACET entity.guid, decode(entity.guid,'base64')\n\nFROM Span SELECTcount(*)WHERE entity.guid ISNOTNULLAND decode(entity.guid,'base64')NOTLIKE'%APM%'\n\nFROM Log\n\nWITHblob(`newrelic.ext.message`)as encodedBlob,\n\ndecode(encodedBlob,'base64')as decodedBlob\n\nSELECT encodedBlob, decodedBlob\n\nWHERE newrelic.ext.message ISNOTNULL\n\nLIMIT10\n\nUse the dimensions() function to return all the dimensional values on a data type.\n\nYou can explicitly include or exclude specific attributes using the optional arguments:\n\nInclude: if present, the include list limits dimensions() to those attributes.\n\nExclude: if present, the dimensions() calculation ignores those attributes.\n\nFROM Metric SELECTcount(node_filesystem_size) TIMESERIES FACET dimensions()\n\nWhen used with a FACET clause, dimensions() produces a unique time series for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries.\n\nUse encode() to perform base-64 conversions on strings. The input value (the first argument) will be encoded using the base-64 standard specified by the encoding (the second argument).\n\nThe following string values are supported encoding parameters:\n\n'base64': Uses the RFC4648 base-64 standard\n\n'base64mime': Uses the RFC2045 base-64 standard (MIME)\n\n'base64url': Uses the RFC4648 base-64 standard with URL and filename safe alphabet\n\nTo decode strings or blobs, see the decode() function. encode() is not supported for blobs.\n\nFROM PageView SELECTsession, encode(session,'base64')\n\nUse the cidrAddress() function to obtain the base network address from a CIDR IP address.\n\ncidrAddress() takes the following arguments:\n\nattribute - A string value that contains either an IP address on its own or with a prefix length in CIDR notation.\n\nThis can be a string attribute or a string literal in quotes.\n\nThe IP address must be an IPv4 address.\n\nnumber - An integer value which represents the prefix length.\n\nThis can be an integer attribute or an integer value.\n\nIf the attribute parameter is in CIDR notation this parameter is optional and takes precedence over the prefix length provided in the CIDR String.\n\ncidrFormat - An optional boolean value that is used to determine if the network address output should be formatted in CIDR notation. This will default to true.\n\nThe cidrAddress() function will return a value as long as the attribute and number parameters contain a valid IP address and prefix length. If the parameter input is invalid, cidrAddress() will return null.\n\nThe following query returns the subnets which are processing the most requests from the SyntheticRequest event type.\n\nFROM SyntheticRequest SELECTcount(*) FACET cidrAddress(serverIPAddress,24)\n\nThis would return responses in a format like:\n\nCidr Address of Server IPAddress\n\nCount\n\nThis query returns all IP addresses in the serverIPAddress attribute that exist within the CIDR range of 10.0.0.0 to 10.0.0.255.\n\nFROM SyntheticRequest SELECT uniques(serverIPAddress)WHERE cidrAddress(serverIPAddress,24)='10.0.0.0/24'\n\nThis query returns a count of all records while excluding records which contain an serverIPAddress value that falls into the CIDR range of 10.0.0.0/24 or 10.10.1.0/24.\n\nFROM SyntheticRequest SELECTcount(*)WHERE cidrAddress(serverIPAddress,24)NOTIN('10.0.0.0/24','10.10.1.0/24')\n\n...WHERE eventType()='EventNameHere'...\n\n...FACET eventType()...\n\nUse the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions.\n\nImportant\n\nIn this context, \"event type\" refers to the types of data you can access with a NRQL query.\n\nThis query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function.\n\nSELECT100* filter(count(*),where eventType()='TransactionError')/ filter(count(*),where eventType()='Transaction')FROMTransaction, TransactionError WHERE appName ='App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago\n\nThis query displays a count of how many records each data type (Transaction and TransactionError) returns.\n\nSELECTcount(*)FROMTransaction, TransactionError FACET eventType() TIMESERIES\n\nUse the getField() function to extract a field from compound data types, such as dimensional metric data.\n\nIt takes the following arguments:\n\nMetric type\n\nSupported fields\n\nsummary\n\ncount, total, max, min, type\n\ngauge\n\ncount, total, max, min, latest, type\n\ndistribution\n\ncount, total, max, min, type\n\ncount\n\ncount, type\n\ncumulativeCount\n\ncount, cumulative, type\n\ntimeslice\n\ncount, total, totalExclusive, min, max, sumOfSquares\n\nExamples:\n\nSELECTmax(getField(mySummary, count))from Metric\n\nSELECTsum(mySummary)from Metric where getField(mySummary, count)>10\n\ngetCdfCount() is an implementation of the cumulative distribution function, returning the number of values in attribute at or below threshold.\n\nOnly one threshold is allowed. Attribute may be either a numeric attribute or a distribution metric attribute. Mixed types in one query are accepted.\n\nFor a numeric type, it returns 1 if the attribute is less than or equal to threshold, otherwise it returns 0. For a distribution, it returns the count in the dataset represented by the distribution. For all other types, it returns 0.\n\nThis query returns the number of events where firstPaint is less than or equal to 1 second.\n\nFROM PageView SELECTsum(getCdfCount(firstPaint,1.0))\n\nUse if() to perform if-then-else control flow operations throughout a query.\n\nif() takes 3 arguments:\n\ncondition - an expression that can evaluate to true or false\n\ntrueValue - this value is returned if boolean expression is true\n\nfalseValue - this optional value is returned if boolean expression is false, or if not provided NULL, is returned\n\nFROM Log\n\nSELECTcount(*)\n\nFACET if(level_name ='ERROR','ERROR','NOT_ERROR')\n\nFROM Log\n\nSELECTcount(*)\n\nFACET if(level_name ='INFO'OR level_name ='WARNING','NOT_ERROR','ERROR')\n\nUse a nested if() function to add additional conditional logic.\n\nFROMTransactionSELECTcount(*)\n\nFACET if(appName LIKE'%java%','Java',\n\nif(appName LIKE'%kafka%','Kafka','Other'))\n\nUse the JSON parse function, jparse(), to parse a string value and produce a map/list of values (or nested structures) which can be handled like any other first-class value type in NRQL.\n\njparse() takes two arguments:\n\nattribute - A JSON string value.\n\npath - An optional string value that is used to directly reference a particular piece of the JSON within the attribute parameter. See the JSON Parse Path Syntax Reference section below.\n\nThe jparse() function follows the RFC 8259 format to parse JSON values. When the jparse() function is used without the path parameter, it will return the deserialized JSON value.\n\nYou can use square brackets to pull out individual values from a jparse() result via a key/index, and map JSON keys directly to attributes using the WITH clause.\n\nReferencing a key\n\nThe following query references the key userNames within the jsonString attribute and will return ['abc', 'xyz'].\n\nWITH'{\"userNames\": [\"abc\", \"xyz\"]}'as jsonString SELECT jparse(jsonString)[userNames]\n\nReferencing an index\n\nThe following query references index 0 within the jsonString attribute and will return 'abc'.\n\nWITH'[\"abc\", \"xyz\"]'as jsonString SELECT jparse(jsonString)[0]\n\nThe following query uses jparse() in the WITH clause to map the JSON keys userName and id into NRQL variables so they can be used in the rest of the query.\n\nWITH'{\"userName\": \"test\", \"unused\": null, \"id\": 100}'as jsonString, jparse(jsonString)AS(userName, id)SELECT userName, id\n\nTo parse specific values from the JSON string, you can use the path parameter.\n\nIt's common for JSON data to be nested in several layers in non-trivial shapes. The path syntax allows you to directly reference a particular piece of the JSON data.\n\nExample data:\n\n{\n\n\"valueA\": \"test\",\n\n\"valueB\": {\n\n\"nestedValue1\": [1, 2, 3],\n\n\"nestedValue2\": 100\n\n},\n\n\"valueC: [\n\n{ \"id\": 1, \"label\": \"A\", \"other\": 7 },\n\n{ \"id\": 2, \"label\": \"B\", \"other\": 9 },\n\n{ \"id\": 3, \"label\": \"C\", \"other\": 13 }\n\n]\n\n}\n\nPath syntax examples using the data above:\n\nPath Syntax Example\n\nResult Description\n\nResult\n\nExamples:\n\nThe following query parses the JSON string within the jsonString attribute.\n\nWITH'{\"user\": {\"name\": \"John\", \"id\": 5}}'as jsonString SELECT jparse(jsonString)\n\nThis query will return the deserialized JSON string:\n\n{\"user\":{\"name\":\"John\",\"id\":5}}\n\nA common problem is having rich and structured data hiding within a log message. You can leverage aparse() and jparse() to trim away noise and find specific values.\n\nThe following query:\n\nCalls aparse() to extract JSON data from the the logMessage attribute\n\nParses the user.name field from the extracted JSON data using jparse() and the user.name path parameter.\n\nWITH'1693242121842: value=\\'{\"user\": {\"name\": \"John\", \"id\": 5}}\\', useless=stuff'as logMessage, aparse(logMessage,'%: value=\\'*\\'%')AS jsonString SELECT jparse(jsonString,'user.name')\n\nThe following query parses each id field from the list of objects within the jsonString attribute and outputs these values as an array.\n\nWITH'{\"users\": [{\"name\": \"A\", \"id\": 5}, {\"name\": \"B\", \"id\": 10}]}'as jsonString, jparse(jsonString,'users[*].id')as ids SELECT ids\n\nThe above query will return [5, 10].\n\nRelated functions: mapKeys(), mapValues()\n\nUse the length() function to return the length of a string value or the number of elements in an array value.\n\nIt takes a single argument.\n\nThis query returns the length of each URL string from the PageView event.\n\nSELECT length(pageUrl)FROM PageView\n\nIf you've uploaded a lookup table, you can use this function with a table name to access that table's data in a query. Here's an example query:\n\nFROM Log\n\nSELECTcount(*)\n\nWHERE hostname IN(FROM lookup(myHosts)SELECT uniques(myHost))\n\nFor more information, see How to query lookup table data.\n\nUse the lower() function to change all alphabetic characters of a string value to lower case.\n\nArguments:\n\nstr - The string value to be lower-cased\n\nThis can be anything that evaluates to a string, including a literal string in quotes, a queried string attribute, a function that returns a string, or even a subquery that returns a single string value.\n\nIf this argument evaluates to null, the lower() function will return null.\n\nThis query demonstrates use of the lower() function in various parts of a query.\n\nFROM PageAction\n\nSELECT latest(lower(actionName))\n\nWHERE lower(actionName)= lower('acmePageRenderedEvent')OR lower(actionName)= lower('SubmitLogin')\n\nFACET concat(actionName,':', lower(actionName))\n\nRelated function: upper()\n\nUse the mapKeys() function to return a list of keys when provided a map as input within the attribute parameter.\n\nWITH'{\"userResult1\": 100, \"userResult2\": 200, \"userResult3\": 4}'as jsonString SELECT mapKeys(jparse(jsonString))ASkeys\n\nThe above query:\n\nDeserializes the JSON string within the jsonString attribute into a map using the jparse() function\n\nCalls the mapKeys() function to extract a list of all the keys within this map\n\nBinds this list of keys to the keys attribute\n\nAfter running the above query, keys will contain the list ['userResult1', 'userResult2', 'userResult3'].\n\nWITH'{\"value1\": \"test\", \"value2\": {\"nestedValue1\": [1, 2, 3], \"nestedValue2\": 100}}'as jsonString SELECT mapKeys(jparse(jsonString))ASkeys\n\nThe above query will extract only the outermost keys from the JSON string within the jsonString attribute. After running the query, keys will contain the list ['value1', 'value2'].\n\nUse the mapValues() function to return a list of values when provided a map as input within the attribute parameter.\n\nWITH'{\"userResult1\": 100, \"userResult2\": 200, \"userResult3\": 4}'as jsonString SELECT mapValues(jparse(jsonString))ASvalues\n\nThe above query:\n\nDeserializes the JSON string within the jsonString attribute into a map using the jparse() function\n\nCalls the mapValues() function to extract a list of all the values within this map\n\nBinds this list of values to the values attribute\n\nAfter running the above query, values will contain the list [100, 200, 4].\n\nWITH'{\"value1\": \"test\", \"value2\": {\"nestedValue1\": [1, 2, 3], \"nestedValue2\": 100}}'as jsonString SELECT mapValues(jparse(jsonString))ASvalues\n\nThe above query extracts the outermost values from the JSON string within the jsonString attribute. After running the query, values will contain a list of the \"test\" string and nested object.\n\nThis can be seen in the JSON view:\n\n\"contents\":[\n\n{\n\n\"function\":\"alias\",\n\n\"alias\":\"values\",\n\n\"contents\":{\n\n\"constant\":[\n\n\"test\",\n\n{\n\n\"nestedValue1\":[\n\n1,\n\n2,\n\n3\n\n],\n\n\"nestedValue2\":100\n\n}\n\n]\n\n}\n\n}\n\n],\n\nUse the minuteOf() function to extract only the minute portion (that is, minutes 0 to 59) of an attribute holding a valid timestamp value. This also works for functions like hourOf(), weekOf(), and so on. For a full list of time-based functions, see the table in our group results across time doc\n\nUse the mod() function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set.\n\nFROMTransactionSELECT*WHEREmod(port,2)=1\n\nFROM NrConsumption SELECT uniques(hostId,10000) SINCE 1day AGO FACET mod(hostId,10)\n\nUse the position() function to find the location of a substring within a string. Matching is case-sensitive.\n\nArguments:\n\nstr - the string in which to find the substring.\n\nThis can be anything that evaluates to a string, including a literal string in quotes, a queried string attribute, a function that returns a string, or even a subquery that returns a single string value.\n\nsubstr - the string for which to search within str.\n\noccurrence - indicates which occurrence of substr of which to return the position.\n\nDefault: 0\n\nIf positive, find the nth occurrence of the substr from the beginning of str, zero based\n\nIf negative, find the nth occurrence of the substr from the end of str. The last occurrence of substr would be the -1 occurrence.\n\nAlias: indexOf(str, substr [, occurrence] ) - indexOf() is an alternative name for the position() function\n\nReturns:\n\nThe 0-based index of the starting character of the substr within str\n\nNull is returned if str is null, substr is null, or the referenced occurrence of substr is not found\n\nThis query demonstrates the use of the position() function to find the positional index of various substrings within a string. Use of the position() function within the substring() function arguments is also demonstrated here.\n\nFROM PageView\n\nWITH position(pageUrl,':')as FirstColon,\n\nposition(pageUrl,'/',1)+1as DomainBegin, position(pageUrl,'/',2)as DomainEnd, DomainEnd - DomainBegin as DomainLength\n\nSELECT pageUrl, FirstColon, substring(pageUrl,0, FirstColon)as Protocol,\n\nDomainBegin, DomainEnd, DomainLength, substring(pageUrl, DomainBegin, DomainLength)as Domain,\n\nposition(pageUrl,'/',-1)as LastSlash, substring(pageUrl, position(pageUrl,'/',-1))as PathEnd\n\nUse the round() function to return the rounded value of an attribute.\n\nOptionally round() can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional.\n\nSELECTround(n [, to_nearest])\n\nUse the stddev() function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero.\n\nUse the string() function to convert a numeric, boolean, tuple, or array value to a string value.\n\nIt takes two arguments, one optional:\n\nAttribute name\n\nPrecision: if present, enforces a limit on the number of decimal places included when converting floating-point numeric values.\n\nThis query returns PageView duration as a string, with two decimal places.\n\nFROM PageView SELECT string(duration,precision: 2)\n\nThis query returns the average of PageView duration as a string, with two decimal places.\n\nFROM PageView SELECT string(average(duration),precision: 2)\n\nUse string() to facet by a floating-point value without losing decimal places.\n\nFROM PageView SELECTcount(*) FACET string(tuple(asnLatitude, asnLongitude),precision: 2)\n\nUse the substring() function to extract a portion of a string.\n\nArguments:\n\nstr - the string from which to extract a substring.\n\nThis can be anything that evaluates to a string, including a literal string in quotes, a queried string attribute, a function that returns a string, or even a subquery that returns a single string value.\n\nIf this argument evaluates to null, the substring() function will return null.\n\nstart - the position within str from which to begin the extraction.\n\nThe first character in str is position 0.\n\nA negative value will find the position relative to the end of str, with the last character of the string being position -1.\n\nIf start is larger or equal to the length of str, the substring() function will return an empty string.\n\nIf start is negative, and its absolute value is larger than the length of str, the extracted substring will begin at position 0.\n\nlength - the length, or number of characters, of the substring to extract from str.\n\nOptional - if length is not provided, all characters in str after the resolved start position will be included.\n\nThis query returns parts of the session value.\n\nFROM PageView\n\nSELECTsession, substring(session,0,3)as First3,\n\nsubstring(session,3)as After3rd,\n\nsubstring(session,-3)as Last3\n\nSee the position() function for examples of using substring() and position() together.\n\nUse the toDatetime() function to translate a timestamp to a formatted datetime string.\n\ntoDatetime() takes the following arguments:\n\ntimestamp - A numeric timestamp to be translated into a datetime string. This can be a numeric value or an attribute, and will be converted to a long internally.\n\npattern - An optional datetime pattern used to format the result. See the Patterns for Formatting and Parsing section in the DatetimeFormatter documentation for how to construct a pattern string.\n\nThis must be a constant string value and will default to yyyy-MM-dd'T'HH:mm:ss.SSSXXX if a pattern is not provided.\n\ntimezone - An optional timezone value that is used to interpret the datetime string(ex. UTC).\n\nThis must be a constant string value and will default to UTC, or the value provided in WITH TIMEZONE if available.\n\nAs long as the input is a valid numeric, the toDatetime() function will always return a value.\n\nAlias: fromTimestamp() is an alternative name for the toDatetime() function.\n\nExamples:\n\nThe following query translates the timestampValue attribute using the default pattern of yyyy-MM-dd'T'HH:mm:ss.SSSXXX. This will return the datetime string 1970-01-01T00:20:34.567Z.\n\nWITH1234567as timestampValue SELECT toDatetime(timestampValue)\n\nThe following query translates the timestampValue attribute using the pattern string yyyy-MM-dd with the timezone set to 'America/Los_Angeles'. This will return the datetime string 1969-12-31.\n\nWITH1234567as timestampValue SELECT toDatetime(timestampValue,'yyyy-MM-dd', timezone:'America/Los_Angeles')\n\nThe following query translates the timestampValue attribute using the timezone provided in the WITH TIMEZONE clause. This will return the datetime string 1969-12-31.\n\nWITH1234567as timestampValue SELECT toDatetime(timestampValue,'yyyy-MM-dd')FROM Event WITH TIMEZONE 'America/Los_Angeles'\n\nUse the toTimestamp() function to parse a timestamp in epoch milliseconds from a datetime string.\n\ntoTimestamp() takes the following arguments:\n\ndatestring - A datetime string to be translated into a timestamp (epoch milliseconds). This can be a string attribute or a string literal in quotes.\n\npattern - An optional datetime pattern used to parse the datestring parameter. See the Patterns for Formatting and Parsing section in the DatetimeFormatter documentation for how to construct a pattern string.\n\nThis must be a constant string value and will default to yyyy-MM-dd'T'HH:mm:ss[.SSS][XXX] if a pattern isn't provided.\n\ntimezone - An optional timezone value that is used to interpret the datestring parameter (ex. PST).\n\nThis must be a constant string value and will default to UTC, or the value provided in WITH TIMEZONE if available.\n\nAlias: fromDatetime() is an alternative name for the toTimestamp() function.\n\nTip\n\nIf the string found doesn't match the given pattern, it will return null. If you happen to have datetime strings in a variety of patterns, you can coalesce results by using OR to cascade until one of the values is non-null. You can also use optional pattern segments. The default pattern uses square brackets to make the milliseconds and zone-offset parts optional.\n\nScenario\n\nDetail\n\nSample pattern\n\nSample datetime\n\nResolves to\n\nExamples:\n\nThe following query parses the datetime string '2023-10-18T15:27:03.123Z' using the default pattern of yyyy-MM-dd'T'HH:mm:ss[.SSS][XXX]. This returns the timestamp value 1697642823123.\n\nSELECT toTimestamp('2023-10-18T15:27:03.123Z')FROM Event\n\nThe following query parses the datetime string '2023-11-03 11:00:32' with the timezone set to 'America/Los_Angeles'. This returns the timestamp value 1699034432000.\n\nSELECT toTimestamp('2023-11-03 11:00:32','yyyy-MM-dd HH:mm:ss', timezone:'America/Los_Angeles')FROM Event\n\nThe following query parses the datetime string '2023-11-03 11:00:32' with the timezone provided in the WITH TIMEZONE clause. This returns the timestamp value 1699034432000.\n\nSELECT toTimestamp('2023-11-03 11:00:32','yyyy-MM-dd HH:mm:ss')FROM Event WITH TIMEZONE 'America/Los_Angeles'\n\nImportant\n\nThe UI will automatically detect the toTimestamp() value as a timestamp and format it as a datetime value. To display the actual numeric timestamp, wrap the toTimestamp() function in a string() function.\n\nUse the upper() function to change all alphabetic characters of a string value to upper case.\n\nArguments:\n\nstr - The string value to be upper-cased\n\nThis can be anything that evaluates to a string, including a literal string in quotes, a queried string attribute, a function that returns a string, or even a subquery that returns a single string value.\n\nIf this argument evaluates to null, the upper() function will return null.\n\nThis query demonstrates use of the upper() function in various parts of a query.\n\nFROM PageAction\n\nSELECT latest(upper(actionName))\n\nWHERE upper(actionName)= upper('acmePageRenderedEvent')OR upper(actionName)= upper('SubmitLogin')\n\nFACET concat(actionName,':', upper(actionName))\n\nRelated function: lower()\n\nType conversion\n\nNRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values.\n\nYou can convert a string with a numeric value or a boolean with a string value to their numeric and boolean equivalents, or convert a non-string value to a string value, with these functions:\n\nUse the numeric() function to convert a number with a string format to a numeric value. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average().\n\nUse the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.\n\nUse the string() function to convert a numeric, boolean, tuple, or array value to a string value. See string() above for more information.\n\nWhen writing a NRQL query, you can add comments, which can help your team members better understand and use the query.\n\nHere are syntax details:\n\n-- Two dashes will comment out all text to the right of this indicator on the same line.\n\n// Two slashes will comment out all text to the right of this indicator on the same line.\n\n/* */ Any text in between these character sets will be commented out. This indicator can apply to multiple lines.\n\nNote that comments aren't displayed everywhere. Some views, like \"recent queries\" and \"view query,\" won't show comments.\n\nSome example queries that include comments:\n\nFROMTransactionSELECT uniqueCount(appId)\n\nFROM TransactionError\n\nSELECTcount(*) SINCE 1day ago\n\nFROM TransactionTrace\n\nSELECTcount(*)\n\nRelated docs\n\nOther popular resources for understanding NRQL syntax and rules include:\n\nNRQL instructional course from New Relic University\n\nLearn how to query the Metric data type\n\nUse subqueries\n\nUse funnels to evaluate a series of related data"
    }
}