{
    "id": "dbpedia_3787_0",
    "rank": 15,
    "data": {
        "url": "https://confluence.atlassian.com/display/ENTERPRISE/Traffic%2Bdistribution%2Bwith%2BAtlassian%2BData%2BCenter",
        "read_more_link": "",
        "language": "en",
        "title": "Traffic distribution with Atlassian Data Center",
        "top_image": "https://confluence.atlassian.com/staticassets/4.6.11/dist/common/images/favicon.png",
        "meta_img": "https://confluence.atlassian.com/staticassets/4.6.11/dist/common/images/favicon.png",
        "images": [
            "https://confluence.atlassian.com/staticassets/4.6.11/dist/common/images/media-viewer-image-icon.svg",
            "https://confluence.atlassian.com/staticassets/4.6.11/dist/common/images/header-atlassian-logo.svg",
            "https://confluence.atlassian.com/enterprise/files/895912660/935392925/3/1583726800807/DataCenter-4node-architecture_diagram.png",
            "https://confluence.atlassian.com/enterprise/files/895912660/896578745/3/1583726801076/capacity.png",
            "https://confluence.atlassian.com/enterprise/files/895912660/935392933/5/1583726800405/DataCenter-RESTnode-architecture_diagram.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/staticassets/4.6.11/dist/common/images/favicon.png",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "In this guide, we'll take you through the basics of traffic handling for Atlassian Data Center products.\n\nOverview\n\nThe load balancer you deploy with Data Center is a key component that allows you to manage traffic across the cluster to ensure application stability and an optimal user experience as usage increases. Load balancing serves three essential functions:\n\nDistributes traffic efficiently across multiple\n\nEnsures high availability by sending traffic only to nodes that are online (requires health check monitoring)\n\nFacilitates adding or removing nodes based on demand\n\nThis article focuses on the first point and describes how using a load balancer for standard traffic distribution and more advanced traffic shaping helps you manage the performance of your application.\n\nData Center supports any software or hardware load balancer and requires \"sticky sessions\" to be enabled to bind a user to a single node during an entire session. This article assumes you're monitoring your application cluster.\n\nStandard traffic distribution\n\nWhen deployed with Data Center, your application runs on a cluster configuration consisting of two or more nodes connected to a load balancer, a shared database, and a shared file system:\n\nIn a basic configuration, each application node redundantly runs a copy of the application. So if you're running Jira Software 7.3.2, each node runs the same copy of Jira Software 7.3.2. Typically, these nodes don't communicate with each other and all data is stored in the shared database and file system connected to each node. The load balancer acts as the single point of entry into the cluster.\n\nLoad balancer operation\n\nIn the basic configuration, the load balancer distributes traffic across the cluster nodes to minimize response time and avoid overload of any single node. The general process\n\nA user's client attempts to connect to the application cluster via the load balancer.\n\nAfter accepting the connection, the load balancer selects the optimal destination application node and routes the connection to it.\n\nThe application node accepts the connection and responds to the client via the load balancer.\n\nThe client receives the response from the application node and continues all requests and activities with that same node, via the load balancer's sticky session configuration.\n\nThe process by which the load balancer selects the target application node . Algorithms for selecting nodes include, but aren't limited to, round-robin polling, nodes with fewer connections, and nodes with lower CPU utilization. By efficiently balancing traffic across your cluster, the load balancer increases your application's capacity for concurrent users while maintaining its stability.\n\nAs you increase the number of nodes, you increase concurrent usage capacity. As an example, our internal load testing showed a nearly linear increase in concurrent user capacity using two-node and four-node clusters compared to a single Jira Software Server with the same response time:\n\nSetup and sticky sessions\n\nAtlassian doesn't recommend any particular load balancer or balancing algorithm, and you're free to choose whichever software or hardware solution best fits your environment. The only configuration requirement for Data Center applications is for sticky sessions, or session affinity, to be enabled on your load balancer. It guarantees that user requests and activities are bound to the same node during a session. In the event of a node failure and failover, users may have to log in to the application again.\n\nYou can find product-specific suggestions regarding load balancing configurations at the end of this article.\n\nTraffic shaping\n\nWhile standard operation of a load balancer helps you increase concurrency capacity, you can use the Data Center load balancer to take even more granular control using traffic shaping. Traffic shaping allows you to categorize and prioritize particular types of traffic and redirect that traffic to a specific node in your cluster.\n\nFor example, to achieve traffic shaping in a cluster with four nodes, you could dedicate the fourth node to receive only a particular type of traffic and then configure the load balancer to send all traffic of that type exclusively to the fourth node. The load balancer would distribute the remaining traffic among the other three nodes as described above. We've seen customers shape their traffic using Data Center in various ways including compartmentalizing API calls to one node and directing traffic from particular teams to specific nodes.\n\nREST API traffic\n\nAn increasingly popular traffic shaping technique among our customers is to direct external REST API traffic to a dedicated node or a set of nodes.\n\nAs your application usage grows, you may find that many users are building their own services using the application REST API. They may be creating computationally intensive services to accomplish necessary tasks, such as automatically retrieving reports on a periodic basis. These potentially numerous external services can degrade application responsiveness, particularly during peak times when users are performing standard operations, such as filing and updating Jira Software tickets.\n\nYou can choose to either block users from this behavior or find a way to accommodate them. In the latter scenario, it may be challenging to rely on the users to take the necessary steps to develop or redevelop their services to reference a dedicated node. Therefore, a better solution is to configure the load balancer for traffic shaping.\n\nTo take advantage of traffic shaping, you will configure the load balancer to identify all external REST API traffic and send it to a dedicated node (or a set of nodes) that only handles REST API traffic. This ensures that the other application nodes in your and aren't slowed down by other services:\n\nWhile we've only currently tested this traffic shaping technique with Jira Software, it can likely be applied to any Atlassian application using REST calls such as Bitbucket.\n\nConfiguration\n\nFirst, if one doesn't exist, you need to provision a dedicated node in your cluster that will handle all external REST API traffic. Nothing special needs to be done with the node as the load balancer will facilitate the shaping.\n\nWhen configuring your load balancer to send REST API traffic to the dedicated node, it's important to identify only external REST API traffic. For example, Jira Software uses a lot of REST calls within itself, so identifying and redirecting all REST API traffic would impede the normal operation of the application.\n\nAdditionally, you don't want to redirect the REST API traffic that is hitting the login page. It would create a user session on the dedicated node and subsequent responses would go to other nodes where the user wouldn't have an initiated session. It's necessary to check the referrer and the requested path before redirecting REST API traffic.\n\nConfigure the load balancer to only direct REST API traffic with the following conditions:\n\nReferred externally from the application\n\nNot requesting the login page\n\nFor the four-node cluster setup,\n\nYou may need to reboot the load balancer to apply the configuration that will shape your traffic. Test the configuration to ensure that it's working as expected.\n\nResults\n\nOne of our customers recently implemented traffic shaping in their Jira Software Data Center:\n\nThey saw four times the amount of traffic on their REST API node than their application nodes.\n\nTheir application nodes experienced decreased CPU utilization relative to their single instance Jira deployment.\n\nLoad balancer setup\n\nConfluence Data Center load balancer configuration suggestions\n\nJira Data Center load balancer examples\n\nJira Data Center using NGINX Plus load balancer\n\nBitbucket Data Center load balancer setup\n\nCustomer stories\n\nHow to Scale Jira Software to 10,000+ Users\n\nOther"
    }
}