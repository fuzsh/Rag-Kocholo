{
    "id": "correct_subsidiary_00121_2",
    "rank": 78,
    "data": {
        "url": "https://www.w3.org/2005/03/plenary-minutes",
        "read_more_link": "",
        "language": "en",
        "title": "Minutes: W3C Technical Plenary 2 March 2005",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.w3.org/Icons/w3c_home",
            "https://www.w3.org/2005/03/photos/shirt.jpg",
            "https://www.w3.org/2005/03/photos/circle.jpg",
            "https://www.w3.org/2005/03/photos/salz.jpg",
            "https://www.w3.org/2005/03/photos/sue.jpg",
            "https://www.w3.org/2005/03/photos/seeman.jpg",
            "https://www.w3.org/2005/03/photos/walsh.jpg",
            "https://www.w3.org/2005/03/photos/break2.jpg",
            "https://www.w3.org/2005/03/photos/slide.jpg",
            "https://www.w3.org/2005/03/photos/thorpe.jpg",
            "https://www.w3.org/2005/03/photos/marsh.jpg",
            "https://www.w3.org/2005/03/photos/harborday.jpg",
            "https://www.w3.org/2005/03/photos/SessionOne.jpg",
            "https://www.w3.org/2005/03/photos/bratt.jpg",
            "https://www.w3.org/2005/03/photos/panel.jpg",
            "https://www.w3.org/2005/03/photos/mendelsohn.jpg",
            "https://www.w3.org/2005/03/photos/berjon.jpg",
            "https://www.w3.org/2005/03/photos/melton.jpg",
            "https://www.w3.org/2005/03/photos/curran.jpg",
            "https://www.w3.org/2005/03/photos/chisholm.jpg",
            "https://www.w3.org/2005/03/photos/lunch.jpg",
            "https://www.w3.org/2005/03/photos/table.jpg",
            "https://www.w3.org/2005/03/photos/bos.jpg",
            "https://www.w3.org/2005/03/photos/hands.jpg",
            "https://www.w3.org/2005/03/photos/hass.jpg",
            "https://www.w3.org/2005/03/photos/plain.jpg",
            "https://www.w3.org/2005/03/photos/lightning.jpg",
            "https://www.w3.org/2005/03/photos/pepper.jpg",
            "https://www.w3.org/2005/03/photos/ballroom.jpg",
            "https://www.w3.org/2005/03/photos/ballroom2.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Minutes: W3C Technical Plenary\n\n2 March 2005\n\nThese are the minutes of the fifth annual W3C Technical Plenary held on 2 March 2005 at the Hyatt Harborside hotel in Boston, Massachusetts, USA. In addition to the day-long event, thirty W3C Working Groups and Interest Groups held face-to-face meetings over four days at the same location. The public plenary consisted of eight sessions. This meeting record is transcribed from the IRC log (Member only) and is not verbatim. Please send corrections to the W3C Communications Team.\n\nW3C wishes to thank Plenary Day scribes Matthew May, Ian Jacobs, Henry Thompson, Thomas Roessler, Max Froumentin, Gerald Oskoboiny, Sandro Hawke and Bert Bos; and photographers Paul Downey (BT), Stuart Williams (HP Labs), Libby Miller (Asemantics), Max Froumentin, Masayasu Ishikawa, Jose Kahan and Susan Lesch.\n\nThe first annual W3C Technical Plenary took place on 28 February 2001, the second on 27 February 2002, the third on 5 March 2003 and the fourth on 3 March 2004.\n\nPlenary Day Agenda\n\nSession One: Welcome to Technical Plenary Day\n\nSession Two: Extensibility and Versioning\n\nSession Three: Where XML is Going, and Where it Should (or Shouldn't) Go\n\nSession Four: Issues in Developing Multiple Specification Test Suites\n\nLunch Discussion Topic: Joint Tests Suite Development\n\nSession Five: The Future of Web Applications\n\nSession Six: Lost in W3C Web Space\n\nSession Seven: Lightning Tech Talks\n\nSession Eight: Voice and Multimodal Interaction Demonstrations\n\nSession One\n\nWelcome\n\nSteve Bratt (W3C Chief Operating Officer) presented Welcome to Technical Plenary Day.\n\nSteve Bratt (W3C): Welcome to the fifth annual Technical Plenary Day. This is the only time of the year where Working Groups, the TAG, the AB, and others get together in one place. That is very important, as are the informal get-togethers available here. The plenary is a great opportunity to get you all into one room, and put your work in the context of the broader work going on within W3C. It's a chance to learn something about others' activities and how that affects your work, a chance to reflect and look ahead and at the past year's achievements. When I look at what my kids are doing on the Web, it's not changed that much, people exchanging words and pictures. But also meaningful, with more computers interacting with one another, working on different devices, in different countries, some with disabilities.\n\nSteve Bratt: The Comm team has worked on our About pages recently. It's a good resource for getting to know what we're doing. The W3C Tenth Anniversary Celebration was held in December. The forward-looking part of this covered the Web of Meaning, Web on Everything, and Web for Everyone approach.\n\nSteve Bratt: We published 15 W3C Recommendations in the last year. This includes the Architecture document, the Character Model, binary-enabled Web Services, DOM Level 3, Voice and Speech Recs, XInclude, and a Schema update. We now have over 600 translations of W3C documents. We have four domains, Architecture, Interaction, Technology and Society, and Web Accessibility Initiative, assisted by the Administration, Communications and Systems teams.\n\nSteve Bratt: We can show how our Working Groups depend on one another via this chart (SVG from RDF, PNG). Our Patent Policy has been a great success. Consensus in the consortium, has become a model for other organizations working on patent policies. Most of our groups have transitioned to the new patent policy, and a majority of the rest of them are on the way. So far, we have no insurmountable problems. We have new policies on Contribution of Test Cases, policy requiring meeting venues not to require a signed NDA, and a policy on Invited Expert selection.\n\nSteve Bratt: The Web of Meaning is important to the Web Services space, to bring players together into one space, to aid interoperability. We had Workshops on Semantic Web Services, and Constraints and Capabilities. The Rules Workshop in Washington DC will be held the end of April. We are working on the Semantic Web Best Practices document. After the successful Life Sciences Workshop, we may be looking at other application-level Workshops in the future. Lots of talk about security: phishing, spam, privacy, and enabling contractual transactions on the Web. We are looking at next steps. The XML Binary Characterization group is finishing its requirements. We are discussing a Community Meeting on the Future of XML.\n\nSteve Bratt: The Web on Everything... the mobile Web: Currently, it stinks. High cost and limited access to the broader Web. A projection is that there will be more mobile Web-capable devices than computers in the near future. The Team and other organizations working on putting a group together. We will be talking more about Web Applications. Dave Raggett is also looking at the Ubiquitous Web, a seamless interaction between users and the Web across devices and environments.\n\nSteve Bratt: The Web for Everyone: The Web Accessibility Initiative has laid out a plan for the next several years. The Internationalization Activity has expanded. When looking at distribution of membership by country, 41.4% in US, 35.7% in Europe, ~9% in Japan, large segments of the world are uncovered. We are working on outreach in developing countries. The Mobile Web Initiative should be of interest to many of those countries.\n\nSteve Bratt: We are talking about an Incubator process in W3C, to make starting up discussion faster. It is an opportunity to have a place to discuss new ideas broadly. The final deliverable is essentially a report. Then these xGs can move their proposals to the Recommendation Track. I am looking for input on this. I think we'll do this in the next couple of months.\n\nSteve Bratt: Today the lunch topic is joint test-suite development. The afternoon is on usability and accessibility, and lightning talks 3-5 minutes long. The reception is at 7:00 p.m. in this room.\n\nSession Two\n\nExtensibility and Versioning\n\nModerator: Michael Sperberg-McQueen (W3C; Chair XML Coordination Group, XML Schema Working Group, XSL Working Group). Panel: Dan Connolly (W3C; Chair RDF Data Access Working Group, Semantic Web Coordination Group, Technical Architecture Group, URI Coordination Group), Noah Mendelsohn (IBM; Technical Architecture Group, XML Protocol Working Group, XML Schema Working Group), David Orchard (BEA; Technical Architecture Group, Web Services Addressing Working Group, Web Services Description Working Group, XML Protocol Working Group), Henry Thompson (W3C; Technical Architecture Group, XML Schema Working Group, XSL Working Group), Mark Baker (Justsystem; Compound Document Formats Working Group), Hoylen Sue (DSTC Pty Ltd; XML Query Working Group, XML Schema Working Group), Tim Boland (NIST; CSS Working Group, QA Working Group, WCAG Working Group), Chris Lilley (W3C; Chair SVG Working Group, Technical Architecture Group)\n\nPaul Downey presented Versioning and Extensibility - Its part in my downfall (PDF, text version Member only)\n\nPaul Downey (BT): I am here to recount the tale of how versioning and extensibility have affected my life. [PD shows an example on the screen of COBOL code]. Because you could not change the messages, we found ourselves with lots of copies of services. [shows slide with handwritten \"Type Length value\" on an envelope]. The beauty of TLV was that you could focus on parts of messages that you were interested in, and ignore the rest. So the language was extensible (in some ways)\n\nPaul Downey: We adopted these rules: a) Ignore what you don't understand, b) Don't change the meaning of things, c) Do what's expected [comment missing]\n\nPaul Downey: We bought tools but they came with an Interface Description Language (IDL). As soon as you describe the messages, they are dead. IDL led us to a lot of one-to-one relationships between message formats and customers. Lots of copies of services (e.g., 13 copies of one service to get contact info). The information superhighway was very loosey-goosey. People kept extending HTML but not centrally. This led to fragmentation.\n\nPaul Downey: W3C established XHTML namespaces and said, \"This space is mine.\" XML redundancy is ok, since it is self-describing. More pipes! If you change a format, you have to have a new namespace. [shows slide \"NO FUTURE\"]\n\nDiscussion\n\nMichael Sperberg-McQueen: Now, an exercise. If you are working on a spec, one of your jobs is to ensure that your users don't have this problem: you don't have a housecat, but one that's dead. The question is how to save Schroedinger's cat. [asks panelists]\n\nPaul Downey: Dear W3C: a) Anoint the MUST IGNORE rule. b) Use namespaces for ownership of names, but not for fine-grained version control. c) We need to be able to communicate breaks in compatibility between versions. d) Descriptions to enable natural evolution.\n\nTim Boland (NIST): Representing the QA WG perspective. Versioning is implicitly addressed through deprecation, one of our dimensions of variability. Versioning is also mentioned in the QA Primer. Versioning may impact or influence extensibility, which is discussed in the QA Specification Guidelines. Managing versioning requires that we can describe the problem. Versioning requirements may vary depending on application requirements.\n\nHoylen Sue (DSTC Pty Ltd): Mechanisms people use for versioning must be simple and on by default. The W3C needs to crack the whip on versioning. Need a \"V10G\" Working Group to promote versioning.\n\nChris Lilley (W3C): Versioning is so hard, it should never be attempted. Take all the time in the world and get version 1 right. Then freeze your format for all time.\n\nDavid Orchard (BEA): +1. Think about versioning in version 1. Think about how to identify versions. For specs, we can start formalizing the extensibility and versioning points. List the areas that are E+V points, and identify your strategies.\n\nDan Connolly (W3C): Pattern, Anti-Pattern, Exhortation. Pattern - Ground your terms in URI space. E.g., XSLT suggests that if you want to create some functions, create your own namespace. Anti-Pattern - untested extensibility hooks. Test your extensibility hooks lest they become vestigial. Exhortation - community values are maintained by community review. We have to read each other's specs. The spec you don't read may bite you later!\n\nNoah Mendelsohn (IBM): There is no one right way to process data. There are degrees of understanding. Your problem goes beyond \"How does v2 of doc interact with v1\"? We need to look at both apps and formats. The MUST IGNORE rule is too simple to accommodate this need. Indeed, in some cases, an app doesn't ignore but processed data by passing it on to another app. We need to build architectures that look good after lots of revisions. Prepare for things to be broken. In some cases schemas form trees, in some cases they don't. A consequence of the rule about repeated versioning and what I just said is that you may not always want to write a schema as a delta with respect to the previous schema.\n\nMark Baker (Justsystem): This is my personal view (not that of the CDF WG). MUST IGNORE in version 1 is critical. In general, don't validate. With important labels like media types and namespaces, only change them when keeping them the same would break something.\n\nHenry Thompson (W3C/University of Edinburgh): We should start by reminding ourselves that we are in a well-known minefield. It is helpful to remind myself from time to time what has been done in other areas. The most modest step we can take is to provide and encourage a mechanism for representing version history/dependencies. We don't have, to my knowledge in XML Schema a way of saying in the language \"This is a revision of that.\"\n\nDan Connolly: OWL has that.\n\nHenry Thompson: A more ambitious idea (stolen from Noah): If you can identify your predecessor(s), you could have a CVS for document structure definitions. The CVS mechanism gives you a way to say a) who you revise, and b) how you revise. All of this is founded on something we don't have across the board - we don't have names for languages. We have URIs for schema documents, but we don't have names for the set of documents that a schema defines. We can say something in human language, but don't have machine names.\n\n[Michael Sperberg-McQueen turns to the audience]\n\nPaul Thorpe (OSS Nokalva): ASN.1 has had extensibility points since the early 90s. Could incorporate something like those mechanisms into XML Schema.\n\nRotan Hanrahan (Mobileaware): I'd like an automated process that let's me compare versions, sets of versions. It is difficult for someone to establish compatibility between content versions by machine. We are thinking about a device repository. I am interested in being able to know automatically whether a piece of content that works with one device will work with another. Automation of discovery of compatibility of different versions.\n\nChris Lilley: When I look at an RFC, I look for the string \"obsoletes.\" I agree that this could be further automated.\n\nDan Connolly: If you mix SPARQL and OWL, you can do this.\n\nNoah Mendelsohn: In the Schema WG, we have been looking at how to say \"Does this element definition subsume that one\" and if so, by \"how much\" (e.g., an attribute different). We have postulated that this mechanism will help people to think about versioning.\n\nCharles McCathieNevile: This versioning problem is very old. I'm a formal medieval historian. If you think something is not a breaking change, it ususally means you don't have much implementation around to break, or you haven't considered the use cases widely. It's pretty easy to break something when you make a change. Indeed, it's perhaps best to think that you will break something, and then think how people will be affected.\n\nPatrick Stickler (Nokia): I believe Henry Thompson has pointed the way forward on this issue. I think the issue is about lack of clarity in relation between namespace and functionality. Move away from syntactic details. Think instead about names. There's a lot of utility in using Semantic Web machinery for describing versioning relations.\n\nKen Laskey (MITRE): I work with a lot of communities with lots of vocabularies. The US Dept. of Defense refers to \"communities of interest\" that will identify and develop their own vocabularies. There seems to be a need for relating vocabularies, which sounds like relating versions. I encourage us to think less about controlling versions, and more about describing relations among versions. How do we capture what people are actually doing.\n\nTom Baker (Fraunhofer Gesellschaft): One thing Dublin Core does is to manage a small vocabulary of properties and classes. For Dublin Core, we started with 1.0 and then 1.1, and realized that was a dead end. So we moved to another means: each term gets a URI. Four classes of changes: a) Editorial changes do not change URI, b) Anything that is substantive triggers creation of new term/URI, c) We assign URIs to specific historical states of a term; descriptions get URIs - this happens at Web site in the background. [d missing] This looks like the W3C's \"this version\" and \"latest version\" URIs. We find that there are uses of both types of URI.\n\nDavid Orchard: I like the Dublin Core approach. Versioning plus extensibility requires finer grain management than we've traditionally considered. In the extreme, each namespace has one name. I think at W3C we can help people move closer to a finer grained world.\n\nTom Baker: At DCMI, we avoid talking about \"namespace\". We use namespaces to assign URIs to an individual term but don't talk about namespaces per se.\n\nHenry Thompson: I think this is a catastrophe, a recipe for disaster. This means that to write a query, for example, I may have to use 100 namespace URIs. I want to find the author of \"Moby Dick\"; I don't want to find 100 names for \"author.\"\n\nRick Salz: The concept of major/minor revision numbers works as well as anything else. Interoperability will break if you go too granular. Generic rules and generic best practices are a mistake in this area. I think semantics depend on applications.\n\nDaniel Weitzner (W3C): There is similarity between technical standards processes and the legal world. In the US legal system and other common law systems, this is a very real problem: what obsoletes what? The lesson from that domain - it's useful to have identifiers, but those systems that allow one to discover the state of any given legal resource only work when people put a lot of editorial effort into specifying relationships. Maintaining descriptions does not come for free or automatically.\n\nMartin Dürst (W3C): For things like query languages, or CSS, or XPath, it could, in some cases, make sense to say \"this XPath prefix stands for these N namespaces.\"\n\nJeff Michkinski (Oracle): What is versioning? We keep talking about it as though we all knew what it was. I suspect that until we answer this question in a concrete way, all the detailed discussion won't help much.\n\nDan Connolly: It's hard to say \"what will be a version\", but it's easy to say that there were versions in the past.\n\nHoylen Sue: In the XML Schema WG we are putting together a use cases document related to versioning. Please send comments and use cases to the Schema WG.\n\nMark Baker: I think versioning is what you get when you break a big project into little ones.\n\nNoah Mendelsohn: I think we have to drop back to prose descriptions of relations among versions. I think there are things we agree on (e.g., a patient record is not a different version of an invoice). I think we would agree that we are talking about things in a problem space.\n\nDavid Orchard: There are substitution/compatibility issues. What guarantees do you have about a version. The TAG is working to define more formally what it means by \"language,\" \"term,\" \"compatibility.\"\n\nChris Lilley: You need to take into account the entity that cares about the result of the compatibility comparison. Versioning depends on application.\n\nMichael Rhys (Microsoft): There are trade-offs when considering versioning. I've seen, in the past 1.5 years at W3C, that many of the technologies that were versioned have been failing in their goals because the cost of adopting new versions was so high as to make adoption of the new version prohibitive. We need to examine cost of creating and deploying a new version before creating it.\n\nDan Connolly: Versioning exploits reputation capital. Version numbers shows line of succession of kings, an argument against version numbers.\n\n[Michael Sperberg-McQueen asks for one word]\n\nTim Boland: Effective management of change\n\nHoylen Sue: Inheritance\n\nChris Lilley: Don't procrastinate\n\nDavid Orchard: Identifiers\n\nDan Connolly: Agreements are very valuable\n\nNoah Mendelsohn: Partial understanding\n\nMark Baker: Compatibility\n\nHenry Thompson: pass\n\ndezell: Please note that there is a new public mailing list for ongoing versioning discussions: public-xml-versioning. XML Schema WG will periodically send notifications of posting of resources for community review, we invite others to do likewise.\n\nSession Three\n\nWhere XML is Going, and Where it Should (or Shouldn't) Go\n\nModerator: Rich Salz (DataPower; XKMS and Web Services Addressing Working Groups). Panel: Jim Melton (Oracle; co-Chair, XML Query Working Group), Norm Walsh (Sun Microsystems; co-Chair, XML Core Working Group; co-Chair, URI Coordination Group; TAG participant), Liam Quin (W3C; XML Activity Lead), Robin Berjon (Expway; Chair, XML Binary Characterization Working Group), Noah Mendelsohn (IBM; Technical Architecture Group, XML Protocol Working Group, XML Schema Working Group)\n\nRobin Berjon presented XML Binary Characterization: Almost a Year in Review (PDF)\n\nNoah Mendelsohn presented Making the XML Stack Work With XML 1.1 (PDF)\n\nDiscussion\n\nRich Salz: Noah Mendelsohn will start with a reprise of last year's talk.\n\nNoah Mendelsohn: This is from my lightening talk last year -- a tutorial on the changes from XML 1.0 to XML 1.1. The major change is charsets and where they can be used. [Noah imagines buying his own island and getting a Unicode character to use in the national language there.] Can he use his new character in an XML name? In 1.0 No, in 1.1 Yes. In content, allowed in both. But in content, charref to C0 control is allowed in 1.1, but not in 1.0. Could I declare an element with such a name in XML Schema 1.0? No, because it uses a definition of Name from XML 1.0. What about charref to C0 control in an enumerated value in a schema? No, because definition of String depends on XML 1.0 Char. So XML 1.1 presents some challenges going forward.\n\n[Rich Salz introduces Robin Berjon, Chair of XML Binary Characterization Working Group]\n\nRobin Berjon (Expway): Review of nearly a year's work of the XML BCWG. Original plan: produce 4 documents: 1) Use Cases, who wants it for what, 2) Properties appropriate for describing serializations and their performance, 3) Measurement technologies. Once we finished that work, produce a recommendation to W3C (NOT a Recommendation Track document) whether to proceed with binary XML format. We may go to a charter then. We published an update on use cases a week ago. 18 use cases covering a large amount of ground. These aren't short use cases, but detailed, multi-page ones. They explain with detail why different industries may or may not benefit from more efficient XML. Why so many? We had the option to delete use cases, but didn't have to. There are many communities that want XML goodness/coolness. There are really good reasons for that, not just coolness factor. People who have been kept from using XML in their industries want to use that global architecture. Don't blame binary XML people for binary XML. XML 1.0 people got it so right that people who couldn't get it want in. We can say a lot about data formats... exhaustive, about 38 relevant properties translate into features, requirements. Not a laundry list of what to put into binary XML format. The document provides a common vocabulary. Useful to have everyone on the same page. The measurements document provides measurement methodologies for these properties, not a perfect benchmark. People often have instincts about this or that being faster or smaller. Give people who want binary XML solid arguments. Give people who don't want it a solid base. That helps discussion both ways. The fourth document, a draft, is not yet published. It provides a set of \"critical properties,\" not looking at every single use case. \"Which properties, if not supported, would prevent you from using it?\" It identifies the minimum baseline for adopting a format, a much shorter list of properties. You will see them in a doc soon. That's the decision tree. Can something be added elsewhere in the XML stack to apply to XML and binary XML? Then define that elsewhere. There is not yet 100% consensus but that document is coming out soon. XML that's faster and smaller, not bells and whistles. Make it faster, make it smaller. There is a good surprise, proof of existence. The Working Group reviewed the set of candidate technologies. We are confident that there are at least 5 or 6 technologies that have properties. Then we went ahead and said \"this is something that can be done\" and will make our recommendation to W3C as to whether W3C should pursue work on defining a binary format. We reached consensus at last face-to-face: \"YES.\" The Working Group as a whole believes W3C should provide a binary XML format. How does that integrate into the XML stack? I hope that the group's documents have provided at least suggestions as to how that works. In a number of ways Noah Mendelsohn's presentation was interesting. Binary XML may be less disruptive than other changes.\n\nNorman Walsh (Sun Microsystems): When we think about the future of XML, possible directions that the community could pursue... expect that the right direction, if there is one, fits somewhere between these. One option is purely editorial work, so new users who come along have clearer description of technology we have today. Another option, party like it's 1997. Pretend we didn't have XML 1.0, pretend we know what we know. Take off the sharper edges. Fix some of the obvious problems. Refactor things perhaps. Develop essentially the same technology. We could start over, understand problems better. New technology that solves them better than XML . A fourth option: the future is now. We have investment in specs. Work as community on specs we have, develop them further [missing comment]. The last point we need to keep in mind is that investment in XML is enormous. XML 1.1 is almost XML 1.0, but failed. ROI in XML 1.1 is not large enough so people want to switch. We need to be sure that any direction we pursue is one that addresses the needs of current community so dramatically that we all decide to go there together.\n\n[A panelist is not feeling well. Jim Melton, co-Chair of the XML Query Working Group is filling in.]\n\nJim Melton (Oracle): I would like to talk today about where we are, and the near future. Where we are is less obvious than what we think. What is XML? A language? A technology? Disruptive tech [pundits]? A markup language -- of what, data, documents, the Web? All of the above. None of the above. A solution looking for a problem? A cult? Customer: \"how quickly should we convert data to XML?\" That's scary. Answer: never. New data goes in XML, don't convert the old data. We need to be careful about how to pitch the notion of XML. XML is right now filled with words, many coming from its history. Not just 1997, but also an imperfect simplification of SGML. My good friend, Chuck Campbell: \"XML, we make your data fatter.\" Good for disk drive manufacturers, and ultimately, not a positive asset. Binary XML is an important approach to minimizing that problem. Many believe that binary XML pays lots of attention to the XPath/XSL data model. Binary XML would be better off with a close relationship to the query data model near term. Longer term? Stop changing things. XML 1.1 is too disruptive. Personally, I am a huge fan of 1.1. My employer was not. It is too disruptive. We had a panel on versioning. There are lots of difficulties caused by changing things. We can try to make problems related to changing less difficult. But also minimize change. XML is not a silver bullet, does not stop world hunger, AIDS, wars. It is just a tool, just another data representation markup language, essentially no different than ASCII. We have had binary encoding standards, relational data model. XML is just another way to represent data. It is not relevant to database firms like Oracle. We deal with data. It doesn't matter in what format the data came. XML offers neither an advantage, nor a disadvantage. A major problem is the proliferation of query languages. I have been in the middle of a Working Group that spent too much time on developing THE XML query language. Seeing concurrent development of SPARQL? Why multiple query languages in parallel? Different focus for SPARQL? But maybe requirements were wrong? For the future of XML, I hope it disappears, not stopping to exist. I hope nobody thinks about it any more, like ASCII and Unicode.\n\nDanC_: (i.e. maybe the requirements for XQuery should have accommodated the requirements of SPARQL)\n\nLiam Quin, wearing fool's cap, W3C XML Activity Lead: Taking hat off, but don't take me too seriously. I have a crystal ball, but it doesn't work. I will talk about four things. Mostly want to listen and set the context for listening, stability, 4 layers of XML, how to move forward, and invite issues for brainstorming. I used computer system that used baudot code to encode text. I worked for the late Yuri Rubinski who talked about SGML under the promise that you're still able to read data in 100 years. The magic wand people had the same promise. In 100 years, we may be able to follow XML document. Four layers, have written down five layers. Partially, because I am not good at counting, partially because the application layer is there, too.\n\nchaalsBOS: difference between SGML and magic wand is that SGML had open spec. stability is important, but one of the real problems is physical media, not just spec changes (hard to read an 8\" floppy these days, even if it has SGML on it)\n\nLiam Quin: The major areas - XML itself, schema, specifying constraints coming from DTDs. There was XLink that was a simplification of HyTime. Transformation languages, querying, can make links between documents, format them, make PDF/PostScript, and now, you can query over it. XML Query is moving forward with specs. They are getting much more stable. Where else should we be going? All these specs are built on the next layer down. Have XML Infoset which provides glossary. What is the result of processing XML documents? I forgot to say: the only two things an XML processor has to return to app are normalized attributes, and white space. The XPath data model (shared between XSL and XQuery) will be used by many other specs.\n\nDanC_: (I remember that doing infoset later was a schedule choice, not an oversight)\n\nLiam Quin: Using that combined with XPath, functions and operators used over data model, formal semantics, markup layer. Includes things like XML Base, XInclude, serializations (how to get from the data model to the pointy bracket world). Beneath that, transfer -- had XML 1.1 ... I understand why people still use XML 1.0. There is one hand up about using XML 1.1 \"from someone shipping 100 million clients.\" We have binary on the horizon. Is this the way forward? ...\n\nHixie: (i think he meant about using XML 1.0. i also think it was a joke!)\n\nLiam Quin: There may be people here who'd wish binary XML doesn't happen. People may have the power to say \"here's a way to transfer things efficiently.\" If W3C has a spec, we'll use it if it works for us. Where does it fit? Clearly, it doesn't fit alongside XML Query. Where does it fit? A new encoding for XML? Have UTF-8 here, binary here. There are coding issues: with application/xml coming in over some connection, have to do sniffing of the content. What about the story, there's one XML that every XML processor understands: encoding. Things like SOAP. But the story is good fiction, it's a widespread one. If we get the situation that 200 million processors understand binary, but 100 million don't, then we have a problem. I won't answer that question, because I am here to listen. What is the way forward? Steve Bratt mentioned community meetings. The next meeting is at XTAG in Amsterdam. We have one Web conference in Japan. We thought about having a Workshop but the idea of having group with 40 people establish the future of XML makes no sense. What idea invites every stakeholder? Has anyone been at one of the Java conferences where they have 3/4 of world's population? Anyone here whose language is written in aethiopic script? We don't have a group of people here who'd represent the people of the planet. We're the worldwide Web. People on the panel have and I have given some areas where future work may be. XML version of versioning? When we have efficient transfer, don't lose authoring aides. People are working on overlapping markup. I read a book on XML and DBs some time ago. It didn't mention mixed content. Is XML a great fit for databases? Yes, if you pick the subset, that is. It can be a great fit, but it's not that simple. People are working on linking, processing models. Should we give up? Do more work? ...\n\nMichael Rhys (Microsoft): Question for Liam. Which population on the planet speaks binary XML? ...\n\nRobin Berjon: About a billion? ...\n\nMichael Rees: We have to be careful, living in high-rises. XML 1.0 and some of that stuff is foundation level. We need to be careful about mucking with the foundation. Several recent attempts at mucking with foundations affected higher levels in way that makes high-rise more unstable. It gets wobbly. Everytime I hear someone talk about XML NG, I start to shudder. If you go to XML NG, consider that some person's wart is the other's beauty mark. You can profile it down to something which fits into one area, but leave interop out. Some people don't care about foundations because they want to build other buildings. But mucking with foundations endangers interop. I see binary XML as another encoding besides UTF-8 or UTF-16. I don't have a problem with binary XML when used as another encoding. If you mandate a specific binary XML format as a model, some user communities who are interested in binary XML may be unhappy, because they don't want to support UTF-8, UTF-16. To conclude, the future for XML is, don't muck with foundations, build on 20th floor. Continue innovation on query language layer. Leave the foundation alone. If you do binary XML, make sure that interop is guaranteed for future and for existing users. Don't be disruptive to existing customer base. If that happens, we have bifurcation ...\n\nNoah Mendelsohn: I agree with what Michael said. There's a psychological factor in being involved with something as successful as XML. Java beans, Java lead architect was Graham Hamilton. We had a success. The instinct to make things ever fancier: be suspicious of that. The cost-benefit trade-off -- benefits are also to not changing things.\n\nLiam Quin: I started out by mentioning stability. We have problems reading files from 9bit systems, 36 bit words. The 100 year promise is important. The stability of XML is important. When talking about interop with a larger community, there is a lot of work to be done. We can't stop binary XML, but we can try to assure interop ...\n\nLisa Seeman (Invited Expert): User requirements, scenarios. Facilitate collecting different use cases about how people not represented in this room use it. A second non-technical suggestion. Lots of decision-makers are not as technical as this room. We often have a one-pager about cost benefit. Why move from HTML forms to XML forms? ...\n\nHixie: why indeed. ;-)\n\nLisa Seeman: People who would have to change their investment certainly don't know that. There is a deployment problem.\n\nPhilip Hallam-Baker (VeriSign): I'd like to make a plea for \"a subset can be the best upgrade for a protocol.\" The problem with XML is not the features it provides, but the SGML legacy that have no interest in it. The Web services decision about schema was the right one. XML 2.0 should be smaller than 1.0. If you want one protocol to talk to another one, you have to have a policy layer. The big problem with traditional Internet protocols is no policy layer. Maybe add policy negotiation to DNS? Maybe say \"you want to talk XML schema, not DTD.\"\n\nPGrosso: I've never heard a customer/user ask for a reduction in capabilities. How can one provide a cost/benefit ROI to a user for subsetting?\n\nLiam Quin: If you can't use XML 1.0, you probably appreciate having 1.1.\n\nJonathan Marsh: XML 1.1 is not a success. Not just not being adopted, but also causing the instability Michael Rees fears. There's got to be a solution in Schema if XML 1.1 going to continue to exist. There's damage to having XML 1.1 out as a Recommendation. Maybe rescind that one. What Liam said happens to other standards, too. The existence of two versions of the bottom layer causes significant headache.\n\nDon Brutzman (Web3D Consortium): The XML Binary Working Group did a super job in defining the problem. Make sure you don't break interop ...\n\nChris Lilley: Rescind XML 1.1, and just remove that Unicode stuff from the OSs. ASCII was good enough for my grandfather.\n\nNoah Mendelsohn: We need to be very careful about the difference between point-to-point and other scenarios. XML can go in lots of places -- spreadsheet, word processors. The working understanding is if it's in UTF-8 or UTF-16, then it's going to work in all places. We are not going to draw simple conclusion whether binary XML is good as a standard ..\n\nchaalsBOS: [having XML 1.1 might include inducing the headache of getting an ASCII-based group of developers to realise why people thought it was important enough to make a shift in what you can represent]\n\nSession Four\n\nIssues in Developing Multiple Specification Test Suites\n\nModerator: Wendy Chisholm (W3C; WAI ERT Working Group, WCAG Working Group). Organizer: Jon Gunderson (DRES; Chair, UAAG Working Group), Patrick Curran (Sun Microsystems; QA Working Group), Vincent Hardy (Sun Microsystems; Chair, Compound Document Formats Working Group)\n\nWendy Chisholm (W3C): Interop is why we're here. Test suites are a key part in making that happen. We'll outline issues opportunities and experiences. In the WCAG WG we look at whether someone is using CSS accessibly. We need to look at multiple related technologies. But only 40% of our Recommendations have test suites, which means we need more work on interop.\n\nJon Gunderson presented on Joint Test Suites and Implementation Reports\n\nJon Gunderson (Invited Expert): We use test suites to clarify and publicize our requirements [shows test suite in development now]. The subject is more complex than a win/lose outcome. UAs need a sliding scale in many cases. We focus on communication between WGs via Test Suites. If you see your requirement enshrined in a test suite, you know you're going to be taken seriously.\n\nDanC_: \"200 staff years\" in the Java test suite.\n\nPatrick Curran presented The Complexity Continuum\n\nPatrick Curran (Sun Microsystems): I have limited resources, and am looking to you because you provide me with test suites. W3C has rich re-use/dependencies between specs. This has its pitfalls -- versions, rates of progress, etc. Focus is however on matching the re-use of specs with re-use of test suites for interop. So what happens developing a test suite for a spec that references another one? Do I have to test all of that spec as well? Better if I can reference an existing test suite? If not, can you at least pick up some individual tests I can incorporate? Best practices for designing re-usable tests. The QA WG has a set of proposals to improve this: package, document, etc. Be sure to identify the part(s) of the spec each test addresses. Document how much of the spec is covered overall. Give clear instructions for how to runthe tests and interpret results. More than a pass/fail bit, particularly when fail -- give as much detail as possible about what went wrong, what was expected, etc. An example from J2SE testing. Lots of referenced/included technologies, and many are W3C. I'm looking at building the tests which cover this stuff. We discourage subsetting -- incorporation means full incorporation. We'd like to test by reference, but that rarely works in practice so far. But we still want to, because incorporation of tests makes a huge test suite which takes forever to run. So please give me the hooks I need to say \"You can be the [whatever] component of J2EE IFF you pass the W3C test suite [whatever_tests]\"\n\nVincent Hardy presented Compound Document Formats Testing Strategy (PDF)\n\nVincent Hardy (Sun Microsystems): I'll present what the CDFWG is doing about testing. We are chartered to combine multiple markups, where the integration points are e.g. multiple namespace mixing, or use of the object tag. Re-use the existing test suites for the existing components. Our focus is on the integration. Follow QA recommendations. Specify in terms of features. Features in terms of testable assertions. Tests for each testable assertion. Challenges. Writing the right tests is really hard. Test involves both starting resources and expected results. SVG example: Here's the file, conformant behavior is the following rendering. Interactivity makes specifying the result much harder. Sometimes the best you can do is prose. Driving a spec from tests is a hard discipline, helps to keep the spec clear and simple. If you could do it thoroughly, specs would be much more robust.\n\nDiscussion\n\nWendy Chisholm: We have 90 minutes for discussion, just not in this room. We are divided up to separate you from your own WG, to encourage connections across WGs. There are instructions on each table for how to proceed. You must appoint a scribe, so we can get feedback. Lists are outside the doors, on the registration desk and in the hall.\n\nLunch Discussion Topic\n\nJoint Tests Suite Development\n\nSession Five\n\nThe Future of Web Applications\n\nModerator: Rhys Lewis (Volantis; Chair, Device Independence Working Group). Presentations: Bert Bos (W3C; Style Activity Lead), Dave Raggett (W3C/Canon; Multimodal Interaction Activity and Voice Browser Activity Lead). Panel: Rich Schwerdtfeger (IBM; HTML, Protocols & Format, User Agent Accessibility Guidelines Working Groups), Brad Porter (Tellme; Multimodal Interaction and Voice Browser Working Groups), Mark Birbeck (x-port; W3C Invited Expert; HTML, XForms Working Groups), Ian Hickson (Opera; CDF and SVG Working Groups), Jon Ferraiolo (Adobe; SVG Working Group), Kevin Kelly (IBM; CDF Working Group)\n\nBert Bos presented on Is it possible to make mobile, accessible and skinnable client-side Web applications?\n\nDave Raggett presented The Ubiquitous Web (PDF)\n\nDiscussion\n\nJon Ferraiolo (Adobe): W3C had a Workshop on compound documents and Web applications. The CDF Working Group started, but not Web apps. I strongly encourage that it happen. Bert has set requirements. But it should also use existing standards\n\nIan Hickson (Opera): We have standards that do all that. Look at Gmail, etc. used by millions of people. So we should maintain those specs. The WHAT WG have been writing proposals for that. I agree with Bert, except that I think HTML, the DOM, JavaScript and CSS already do what he is asking for. Half a billion people are already using these technologies on computers, mobile phones, etc. W3C needs to actively maintain these technologies, fixing errors in the specs and adding incremental new features that authors need. CSS and ECMAScript are already being maintained. While we wait for W3C to create a group to maintain HTML and DOM, a group of us are working on proposals for those specs. You can join in and read the proposals at http://www.whatwg.org/.\n\nMark Birbeck: We have a lot of things we want already. A document framework: HTML, XHTML, XHTML2, which is a fairly abstract container for anything you like. In terms of functionality we have SVG, XForms, etc. Already a lot of stuff. So we should make them work together first.\n\nRich Schwerdtfeger (IBM): With JavaScript we don't have enough metadata for accessibility. But JS isn't the problem. It's the lack of metadata. There are short-term and long-term solutions (XHTML2). There's a need to put semantics back into the content. We're moving toward that direction. XForms is fantastic for accessibility. We don't address the temporarily disabled person: a person arriving in a room where the light is different, etc. Thanks Dave for bringing up adaptation to environment.\n\nBrad Porter (Tellme): I have a negative reaction to the word \"content\". We need to look at our core technologies. They're the best, but aren't necessarily good. Raise your hands if you've written HTML.\n\n[raise of hands]\n\nBrad Porter: A table within a table?\n\nBrad Porter: A spacer GIF?\n\n[fewer and fewer hands]\n\nBrad Porter: JavaScript to [missing]?\n\ntimbl: \"Just because you are the best doesn't mean you are good\"\n\nIanJ: (create some impromptu UI)\n\nBrad Porter: How many have connected a database to your HTML?\n\nBrad Porter: Done it with standard technology?\n\nBrad Porter: Used proprietary tech (not W3C)?\n\nBrad Porter: HTML in a string literal in a server-side program?\n\nBrad Porter: Is it acceptable??\n\n[laughter]\n\nBrad Porter: [missing]\n\nKevin Kelly: I believe we need a standards-based compound of namespaces with enclosing schemas including all the specs we care about. It's important to ride the wave of pervasive devices. But don't forget the desktop. Referring to other documents, including documents, mixed namespaces, etc. I believe that the W3C can make a different in this space. It's important not to continue to fragment the document specs.\n\nRhys Lewis (Volantis): Encourage people to look at what CC/PP is doing\n\nKeith Waters (France Telecom): UbiWeb is quite interesting. We see a wide variety of devices, all the way down to devices including RFID tags, or subnetwork arrays. Where does the boundary lie?\n\nDave Raggett: The idea is to abstract away some of the difficulties. I encourage requirements to be brought to the Working Group.\n\nUnidentified speaker: Directions in small devices supporting [missing].\n\nTV Raman (IBM): Why is it relevant to build on new standards as opposed to standards of 1996? The Web succeeded because it allowed many people to use it. Now we can step back to see what the standards have done.\n\nTantek: TV: HTML succeeded because it moved the ability to create from the few to the many.\n\nTV Raman: They have shown design patterns. The next set of standards will be a democratization of this process. It's not what you can do today or not, it's about maintenance.\n\nIan Hickson: Make sure it's simple to write the content.\n\nTantek> IH: the important thing is to make sure it is always simple to write the content.\n\nAnn Bassetti (Boeing): I am interested in UbiWeb. But in the factory environment, we cannot tolerate crashing. Recently a single printer crashed our entire firewall.\n\nDave Raggett: Yes, robustness is important.\n\nLisa Seeman: It's not trivial to make the Web ubiquitous. It's difficult to give the user control of the interface, translation, localization. All this kind of information to tailor the interface, I don;t see it supported in mainstream markup.\n\nsandro: ( I wonder how one uses an ontology to make the web more ubiquitous.... Anyone know her angle? )\n\nMark Birbeck: The UbiWeb is desirable, and Bert described how it might be. But today we have tools. XForms provides the separation.\n\nUnidentified speaker from a WAI group: Maybe there are some critical areas like safety issues. Ubiquity of everything also includes ubiquity of some really important things.\n\nRhys Lewis: This might be more a device independent statement. DI has the idea of delivering to anybody regardless of device. The concept is not that different from \"regardless of disability.\"\n\nUnidentified speaker from Nokia: Be careful when insisting on splitting content and presentation. Often, layout is part of the application.\n\nSession Six\n\nLost in W3C Web Space\n\nPresentations: Shawn Lawton Henry (W3C; WAI Education and Outreach Working Group), Chris Hass (American Institutes for Research [AIR])\n\nPresentations\n\nShawn Lawton Henry presented Lost in W3C Web Space: Lessons from the WAI Site Redesign\n\nChris Hass of AIR presented\n\n[movie: Lost in W3C Space]\n\nShawn Henry: Those were some clips from our usability testing of the W3C site.\n\n[they showed lots of unhappiness]\n\nShawn Henry: Everyone please go to w3.org/WAI and find information about making data table accessible. People get really lost on the WAI sub-site. People can't find the stuff they know is there. People say \"you really should do ...\" but we did it a year ago and they couldn't find it. Myth: people think accessible sites have to be dull and boring. Our site perpetuates that myth. So WAI site resign was a priority. Our primary goal: increased use of WAI resources due to improved usability. This is not directly related to accessibility. We used the User-Centered Design process.\n\n[Shawn asks people to try a search on a new site prototype but the network isn't working well.]\n\nsimon: I did find info on making tables more accessible by looking under guidelines.\n\n[People asked to reset their wireless links.]\n\nsandro: ( My wireless is working for IRC but ut2 still hasn't loaded after 2-3 minutes )\n\nsimon: works ok for me :^)\n\n[Chris Hass asks for a show of hands of people who have done usability testing.]\n\nChris Hass: It takes a lot of grace to be on the team watching people fail in trying to use your work. \"Using this Web site is like walking into a firehose.\" People recognized how useful the information on the site was, but found it very very hard to use. Redesign prototype had much feedback. With the first version people gave up after about 10 minutes. The second version took about 40 seconds. A clear win. We also asked subjective questions of users.\n\n[chart of before/after, color coded red/yellow/green]\n\nChris Hass: Comments about TR pages: \"Just whoa! It looks like rules and regulations. It doesn't look warm. Here we go, another regulation!\"\n\nChris Hass: \"It looks old, it looks dated!\"\n\nChris Hass: \"There is no list... of guidelines\"\n\n[she wanted guidelines and didn't find them, but didn't like the page full of guidelines? What's the lesson about usability testing here?]\n\nChris Hass: TRs : \"very plain, boring. This page is too long to begin with. All these guidelines...\"\n\n[The lesson is that she wants guidelines but not an overwhelming list of them, maybe?]\n\nChris Hass: A firehose is no fun, even if you are thirsty. Being proud of one's site is not enough.\n\nChris Hass: Comments about prototype:\n\nvideo: \"very user friendly, to the average navigator\".\n\nvideo: \"it has an aura of professionalism\"\n\nvideo: \"probably the best Web accessibility site I've seen so far\"\n\nShawn Henry: We're very eager to get this new site out. We hope you are motivated to think about this for more of the W3C site. Lots of challenges in time, priorities, skills. But it's worth it! Cisco's intranet redesign was calculated to save US $3 million in navigation time. Discount usability? We did it rigorously, but [missing]. Think about why your pages exist, their priority. Think about the users not just your Working Group members.\n\nbjoern: Is this expected to become the new WAI logo?\n\ndom: bjoern, no, she mentioned it was only a placeholder\n\nbjoern: ok, thx\n\nSteve Bratt: It's important to leverage this across the W3C site.\n\nSession Seven\n\nLightning Tech Talks\n\nModerators: Paul Downey (BT; Web Services Addressing and Description Working Groups) and Dominique Hazaël-Massieux (W3C; Quality Assurance Activity Lead and W3C Systems Team)\n\n\"Test Suite Lunch Time Exercise Results\", Wendy Chisholm (W3C; WAI ERT Working Group, WCAG Working Group)\n\nWendy Chisholm: There seems to be a knowledge problem about what good test suites are and how to create them. People want tools, and want people within the Working Group who can create test suites and tools to manage dependencies between tests. We may want to have a QA test suite summit and maybe a QA orientation page for people joining Working Groups. The data gathered from the lunch session will be forwarded to the QA Working Group.\n\nwendy: FYI, partial lunch summary\n\n\"Tools to Support Working Groups\", Dominique Hazaël-Massieux (W3C; Quality Assurance Activity Lead and W3C Systeam)\n\nDominique Hazaël-Massieux: Jose Kahan and I both have some time committed to working on Working Group tools, so if you need something come talk to us. Also, please, contribute ideas and requirements to the w3c-tools@w3.org mailing list (archive Member only).\n\nMartin Dürst (W3C): If there is an effort to do something for issue tracking to serve lots of Working Groups, it should serve the Working Groups as well as individuals making the comments.\n\n\"Should Formatting Properties be Standardized Between Working Groups?\", Steve Zilles (AB Chair, XSL Working Group)\n\nSteve Zilles: Different technologies can interact with each other. For example, SVG inherits text-align from the surrounding context. But if the same property means different things in different contexts, chaos results. I encourage Working Groups to talk to each other. If a property doesn't do what you want, try to reach agreement instead of forking the set of values.\n\ndbaron: A problem with Alternative 3 is what happens when WGs disagree, don't reach consensus, and just publish specs that disagree, which has happened.\n\n\"XML For Everyone?\", Richard Ishida (W3C; Chair I18N GEO Working Group, I18N Tag Set Working Group)\n\nRichard Ishida: Some languages cannot be adequately represented in XML 1.0, because their characters are not in Unicode 2. This affects the languages in use by 150 million people. There is a solution: XML 1.1.\n\n\"Web Services and Composition\", Glen Daniels (Sonic Software; Web Services Addressing Working Group, Web Services Description Working Group)\n\nGlen Daniels: We want to be able to extend WSDL, and to make RDF/OWL assertions about these extensions. Please use the SOAP extensibility model. It just says to give your extensions a name. Please think about metadata/policy in your extensions. Unambiguous identifiers aren't hard to add.\n\nJacek Kopecky: Isn't the purpose of the Web that everything is identifiable?\n\nUnidentified speaker: Yes\n\n\"Topic Maps and the Semantic Web\", Steve Pepper (Ontopia; Convenor SC34/WG3, Semantic Web Best Practices Working Group)\n\nSteve Pepper: RDF and topic maps have many similarities. Why two of them? Why not unify? They have different roots, levels of semantics, models, community goals. The RDF/Topic Maps Interop Task Force is a task force within the Semantic Web Best Practices Working Group.\n\nAnn Bassetti: When is Extreme 2005?\n\nUnidentified speaker: Beginning of August, Montreal\n\nPGrosso: Extreme 2005\n\n\"Project SIMILE: Helping build the Semantic Web\", Ryan Lee (MIT), Stefano Mazzocchi (MIT)\n\n[Stefano Mazzocchi demonstrates Longwell metadata browser.]\n\nStefano Mazzocchi: The point of Longwell is to give librarians a tool that hides the complexity of RDF.\n\n[demonstrates Piggy Bank, a Firefox extension that provides a sidebar that lets people collect and browse semantic data from ordinary Web pages]\n\nTim Berners-Lee (W3C): I'm not sure that everyone will understand what a faceted browser is. Please explain.\n\nStefano Mazzocchi: Faceted browsing is kind of a query built in as you browse. As you click around, more structure is added and limits your view. This is done using RDF's graph structure.\n\n\"Privacy and Transparency in data mining on the Web\", Danny Weitzner (W3C Technology & Society domain leader)\n\nDaniel Weitzner: My goal is to provoke you to think a bit differently about privacy. Privacy and transparency have an important and synergistic relationship. In order to guarantee that data is used for the purpose for which it was given, we need more transparency.\n\nUnidentified speaker: That sounds like The Transparent Society by David Brin.\n\nUnidentified speaker: Asimov also wrote this up.\n\n(anyone know where?)\n\ntvraman: see Grep Law for analog short story from Asimov referred to in a Phil Zimmerman interview.\n\nDaniel Weitzner: I believe that by separating data into different processing spheres, you will either compromise a lot of processing power that you could have, or have impossible complexity. There have been attempts to keep data within its own spheres but I don't believe that will scale.\n\n\"Standards-based Internet Applications ... Today\", Mark Birbeck (x-port.net, HTML Working Group, XForms Working Group)\n\n[Mark Birbeck demonstrates an IE sidebar built using XForms. Shows a calculator widget which is an XForms styled with XBL and SVG.]\n\ndom: demonstration of applications written using declarative markup (XForms, SVG, ...)\n\n\"Evolution vs. Revolution\", Håkon Wium Lie (Opera; Cascading Style Sheets Working Group)\n\nHåkon Wium Lie: Specifications introduced in this century often introduce new paradigms that are not backwards compatible. Working Groups close after producing Recommendations, so maintenance work has less attention than it should. Why? Maintaining specs is not glamorous, and test suites take time and effort. We should realize that current HTML-based designs will live long. We need to allow maintenance on old specs, yet allow for groups to plan revolutions. If something results that really is 10x better, we want it to become adopted. Viva la evolucion!\n\n\"Evolution vs. Revolution\", Steven Pemberton (W3C; Chair HTML Working Group, Chair XForms Working Group, Hypertext Coordination Group)\n\n[Steven Pemberton models front of his Che Guevara t-shirt. Models the back, saying it is an Opera Software shirt.]\n\nSteven Pemberton: Evolution is when you can still use the content in old software. Revolution requires new software. [Discusses various HTML, HTTP, CSS specs over the years, whether each was evolution, revolution, or a combination of both.] It's not a choice between evolution and revolution. We need both. Don't wait until the last minute to provide feedback on specs!\n\nMark Birbeck: Not a matter of evolution/revolution. Also a matter of what baggage you want to bring along with you. You need justification to keep old stuff around. Why deny the possibility to make things better?\n\nChris Lilley: If we don't provide a way to do revolutionary new things, people will find a way elsewhere, e.g. using Flash.\n\ndbaron: 2 points I wanted to make: 1) with 3 programmers in 4 months you might be able to make something that you can demo, but you can't do it right\n\nTantek: +1 on dbaron\n\ndbaron: 2) You can't assume that browser makers are following everything that's going on in the W3C. There's *tons* of stuff going on, much of which is designed for other Web-related things (not for browsers), and many browsers are developed by small teams. There's nothing wrong with the W3C doing more, but you can't expect certain member companies to implement standards that they weren't involved in developing.\n\nHixie: (not to mention that Netscape did comment on XForms years before Steven suggested that they did -- the comments were largely ignored)\n\ngerald: Hixie, Steven said \"Opera and Apple\", I think\n\nHixie: gerald: the people who were at Opera and Apple who complained about XForms were at Netscape when Netscape complained.\n\nSession Eight\n\nVoice and Multimodal Interaction Demonstrations\n\nModerator: Scott McGlashan (HP; co-Chair, Voice Browser Working Group)\n\nScott McGlashan: Most everything has been done so far with proprietary technology. But now a a Web model is being promoted. Multimodal differs from desktop. In mobile there is much more variety in devices, capabilities and interfaces. In mobile, 90% is still voice communication. 10% is data. But there is potential for growth. W3C has two groups in this area: the Voice Browser Working Group and the Multimodal Interaction Working Group. Convergence is on state-based language for control and sequencing. VoiceXML is at the base of a big, multi-million dollar industry. Predictions are that it will dominate the market by 2007. There are several ways to integrate: Web browsers enhanced with voice/multimodal, and coordination between Web browsers and voice browsers. We will show 5 demos.\n\nGerald McCobb, IBM: Mobile multimodal for enterprise\n\nGerald McCobb, IBM: The goal is to use voice and multimodal to sync PIM, email, and business data. [diagram of architecture: lots of components] [demos JK Insurance Co. Gerald speaks into microphone. System speaks back. System reprompts after misunderstood word. Gerald speaks a number of commands to repair and replace motor parts. System speaks the results that are also shown, for verification. The local system now tries to call up the customer on Gerald's request.]\n\nMikko Honkala, HUT: Voice enabling XForms\n\nMikko Honkala, HUT: [Speech enabled XForms.] Not using VoiceXML, because it doesn't allow us to use anything else than voice. Not abstract enough. XForms has the required abstraction. It also has other advantages for multimodal interfaces. The demo is implemented in pure Java. [Diagram: the various components to connect speech recognizer, synthesizer and the forms.] [Demo starts. Rent-a-car. Screen shows and speech speaks the form. The voice prompts and suggests. Data types are used to help the recognition. Voice: \"Even W3C Members cannot rent for more than 100 days\" (laughter) Speaking the labels shown on the controls selects those controls. XForms helps to do some local calculations to keep parts of the form up to date. Voice speaks the result and asks for confirmation. 2nd part of demo: authoring process. XForms markup to add some options to the interface. Apart from adding that markup, no other changes necessary.]\n\nDave Raggett, Canon/W3C: Voice enabling web browsers with XSLT and SSML\n\nDave Raggett: Visual/aural rendering of RSS. RSS is a popular format for sets of news items. Can de rendered visually on current Web browsers. Using SSML to add aural Demo is done through an extension to Mozilla, using their published interface and written in C++. Uses an external speech synthesizer as a server. XSLT used to map RSS to XHTML (for visual) or SSML (for speech). Goal is support the MMI Working Group. May have more demos at next year's Technical Plenary. [Demo starts. Web page shows BBC news feed and others: RSS displayed visually. A voice reads out the news items.]\n\nStuart: Almost a BBC voice :-)\n\nRotan> OK, now *this* is something I could use. Fortunate to be sighted, it would still be great while driving in the car. Great demo.\n\nDemo continues: [Dave can select a different \"style\" and the voices change.]\n\nKeith Waters, France Telecom: Mobile multimodal games\n\nKeith Waters, France Telecom: Mobile games. Games are a good vehicle for testing and getting feedback. There are two modes of interaction: voice and joystick. Making use of the time the player needs to think to overcome network latencies. Speech synthesis is done on remote server. Feedback sought from users is what they use most or prefer among the two modes. [Demo starts. Game to find hidden words. Screen shows a number of letters with words hidden and a timer. Can select letters with the joystick. But it is difficult, due to the size of the device/joystick. Speech can speed things up. Can say the hidden word directly, without pointing at it with the joystick.]\n\npauld: likes the game soduku\n\nScott McGlashan, HP: VoiceXML and video SSML\n\nScott McGlashan: VoiceXML allows us to point to video. We can use many different protocols, HTTP, SIP, RTP.... [Demo starts. Shows telephone keypad and a video playing. VoiceXML allows fallbacks. Same demo, but with broken URL: the fallback in this case is a voice that speaks a text. Result of pressing 1 is a video. Same also works with Japanese voices.]\n\nDiscussion\n\nHåkon Lie: This works in Opera beta 8 (Windows) as well.\n\nCharles McCathieNevile: Is it available?\n\nUnidentified speaker: Yes, there is Open Source available for everything, even the speech synthesis.\n\nUnidentified speaker: Good benefit for accessibility, but talk with screen reader vendors so you don't get into fights about who owns the device.\n\nJim Larson (Intel): Does the XSmiles demo work on any XForms?\n\nUnidentified speaker: Some limitations, but yes, that is the eventual goal.\n\nSteve Bratt thanks all participants, the meeting planners Susan Westhaver, Amy van der Hiel, Marisol Diaz, Josh Friel and Coralie Mercier, and all scribes.\n\nAdjourned"
    }
}