{
    "id": "correct_subsidiary_00121_2",
    "rank": 41,
    "data": {
        "url": "https://adactio.com/journal/tags/chrome",
        "read_more_link": "",
        "language": "en",
        "title": "Adactio: Journal—Tagged with chrome",
        "top_image": "https://adactio.com/images/photo-300.jpg",
        "meta_img": "https://adactio.com/images/photo-300.jpg",
        "images": [
            "https://i.ytimg.com/vi/llAHyqGqw8o/mqdefault.jpg",
            "https://adactio.com/images/uploaded/16393-1/small.png",
            "https://adactio.com/images/uploaded/16393-2/small.png",
            "https://adactio.s3.amazonaws.com/images/chrome-https-transition.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Jeremy Keith"
        ],
        "publish_date": "2024-07-16T14:57:05+00:00",
        "summary": "",
        "meta_description": "The thoughts and ramblings of Jeremy Keith, a web developer living in Brighton in southern England.",
        "meta_lang": "en",
        "meta_favicon": "/apple-touch-icon.png",
        "meta_site_name": "",
        "canonical_link": "https://adactio.com/journal/tags",
        "text": "Back when South by Southwest wasn’t terrible, there used to be an annual panel called Browser Wars populated with representatives from the main browser vendors (except for Apple, obviously, who would never venture onto a stage outside of their own events).\n\nI remember getting into a heated debate with the panelists during the 2010 edition. I was mad about web fonts.\n\nJust to set the scene, web fonts didn’t exist back in 2010. That’s what I was mad about.\n\nThere was no technical reason why we couldn’t have web fonts. The reason why we didn’t get web fonts for years and years was because browser makers were concerned about piracy and type foundries.\n\nThat’s nice and all, but as I said during that panel, I don’t recall any such concerns being raised for photographers when the img element was shipped. Neither was the original text-only web held back by the legimate fear by writers of plagiarism.\n\nMy point was not that these concerns weren’t important, but that it wasn’t the job of web browsers to shore up existing business models. To use standards-speak, these concerns are orthogonal.\n\nI’m reminded of this when I see browser makers shoring up the business of behavioural advertising.\n\nI subscribe to the RSS feed of updates to Chrome. Not all of it is necessarily interesting to me, but all of it is supposedly aimed at developers. And yet, in amongst the posts about APIs and features, there’ll be something about the Orwellianly-titled “privacy sandbox”.\n\nThis is only of interest to one specific industry: behavioural online advertising driven by surveillance and tracking. I don’t see any similar efforts being made for teachers, cooks, architects, doctors or lawyers.\n\nIt’s a ludicrous situation that I put down to the fact that Google, the company that makes Chrome, is also the company that makes its money from targeted advertising.\n\nBut then Mozilla started with the same shit.\n\nNow, it’s one thing to roll out a new so-called “feature” to benefit behavioural advertising. It’s quite another to make it enabled by default. That’s a piece of deceptive design that has no place in Firefox. Defaults matter. Browser makers know this. It’s no accident that this “feature” was enabled by default.\n\nThis disgusts me.\n\nIt disgusts me all the more that it’s all for nothing. Notice that I’ve repeatly referred to behavioural advertising. That’s the kind that relies on tracking and surveillance to work.\n\nThere is another kind of advertising. Contextual advertising is when you show an advertisement related to the content of the page the user is currently on. The advertiser doesn’t need to know anything about the user, just the topic of the page.\n\nConventional wisdom has it that behavioural advertising is much more effective than contextual advertising. After all, why would there be such a huge industry built on tracking and surveillance if it didn’t work? See, for example, this footnote by John Gruber:\n\nSo if contextual ads generate, say, one-tenth the revenue of targeted ads, Meta could show 10 times as many ads to users who opt out of targeting. I don’t think 10× is an outlandish multiplier there — given how remarkably profitable Meta’s advertising business is, it might even need to be higher than that.\n\nSeems obvious, right?\n\nBut the idea that behavioural advertising works better than contextual advertising has no basis in reality.\n\nIf you think you know otherwise, Jon Bradshaw would like to hear from you:\n\nBradshaw challenges industry to provide proof that data-driven targeting actually makes advertising more effective – or in fact makes it worse. He’s spoiling for a debate – and has three deep, recent studies that show: broad reach beats targeting for incremental growth; that the cost of targeting outweighs the return; and that second and third party data does not outperform a random sample. First party data does beat the random sample – but contextual ads massively outperform even first party data. And they are much, much cheaper. Now, says Bradshaw, let’s see some counter-evidence from those making a killing.\n\nIf targeted advertising is going to get preferential treatment from browser makers, I too would like to see some evidence that it actually works.\n\nFurther reading:\n\nThe new dot com bubble is here: it’s called online advertising by Jesse Frederik and Maurits Martijn.\n\nAfter GDPR, The New York Times cut off ad exchanges in Europe — and kept growing ad revenue by Jessica Davies.\n\nSubprime Attention Crisis by Tim Hwang.\n\nClean advertising by me.\n\nI updated my Mac to the newest operating system, Sonoma. I did this to try out the new “add to Dock” feature in Safari. It’s like the “add to Homescreen” action on iOS.\n\nBefore I get into what’s good, I have to start by ranting about a big problem on both desktop and mobile: discovery.\n\nFirst of all, you have to know that a square with an arrow sticking out of it means “share”.\n\nOkay, I can buy it. It’s no better or worse than the three horizontal lines of a hamburger icon, or the three horizontal dots of a kebab icon. And whereas the hamburger and kebab icons are used as a catch-all cupboard to sweep all your rubbish into, at least this icon has a specific meaning. It means share, right?\n\nWell, it used to. But now it’s also home to “add to Homescreen” and “add to Dock”. Neither of those actions are sharing.\n\nStretching semantics, I suppose you could say you’re sharing something with yourself.\n\nAnyway, this is the biggest issue with progressive web apps on both iOS and Mac. Regardless of how well they work, there’s not much point if most people don’t know the option exists.\n\n(Update: Jen rightly points out that you can also get to “add to Dock” from the file menu. Doh! How did I miss that‽)\n\nDiscovery aside, I was interested to see how Safari handles web apps on desktop compared to how Chrome does it.\n\nI’ve had one or two web apps in my dock for a while, installed through Chrome. Google Meet is one of them. I use it quite a bit, and honestly it feels no different to using a native desktop app.\n\nOne annoyance is that the Chrome browser also automatically launches whenever I launch the Google Meet icon in my dock. This wouldn’t matter if Chrome were my default browser, but I use Firefox. So whenever I’m using the Google Meet web app, there’s a Google Chrome icon hanging around in my dock, saying “gizza job, I can do that.”\n\nI opened Google Meet in Safari and then selected “add to Dock” from the square with an arrow sticking out of it. Then I quit Safari. I was delighted to see that when I launched the Google Meet web app from the dock, it didn’t automatically launch Safari! Excellent!\n\nEven better, links within a Safari-installed web app respect your default browser choice. What I mean is, previously when I had Google Meet installed via Chrome, if I clicked an external link in Google Meet it opened in Chrome. But now with the Google Meet installed via Safari, external links open in Firefox, my browser of choice. Very good!\n\nBut the Safari-installed version of Google Meet is, alas, over-zealous with permissions. I have to grant access to my microphone and camera every single time I launch it. Previously—with the version installed via Chrome—it remembered my choice.\n\nNow I don’t know if the behaviour in the Safari-installed version is a deliberate choice made for security reasons, or if it’s a bug. I suspect it’s a bug. After all, on iOS you get access to more permissions if a site is added to the homescreen—it’s the only way to ask for permissions for notifications, for example.\n\nI added a few more sites to my dock: mastodon.social and thesession.org. They both work really well as standalone apps.\n\nInterestingly, if I click a link to thesession.org from within the mastodon.social standalone web app (or the other way around), the link opens in my default browser. So the web apps don’t “own” the domains. That’s fine, although I wonder if it violates the principle of least surprise—perhaps the expectation is that the installed web app is the preffered owner of that link.\n\nI also tried adding Google Calendar to my dock. Ironically, I can only do this with Safari. For some reason, Google have chosen not to make their calendar a progressive web app …which means there’s no option to install it from Google Chrome.\n\nThey’re missing a trick there. It’s the perfect candidate for being a standalone app.\n\nActually, I take that back. Gmail is the perfect candidate for being a standalone app …and yet it’s not a progressive web app. Very odd!\n\nWith Safari, you can add any website to the dock. It doesn’t need to be a progressive web app. But the installation experience works best if there’s a manifest file pointing to some nice icons.\n\nAs it turned out, Google Calendar runs like an absolute dog in Safari (and therefore as a Safari-installed web app). Before you cry conspiracy, note that it runs absolutely fine in Firefox. I know because I use it in Firefox every day. But I can’t add it to my dock from Firefox because Mozilla turned their back on progressive web apps a while back. A bad decision.\n\nGoogle Calendar isn’t the only thing that runs slowly in Safari’s engine. This page on The Session has a very large DOM and a badly-coded in-page search (I know, I know, I need to improve it). It works fine in other browsers but Safari struggles mightily.\n\n(Update: I tried using Google Calendar from Safari again and it seems to be running just fine now. Maybe I caught it on a bad day? In any case, I’ve added it to the dock now and it’s feeling good as a standalone app.)\n\nStill, aside from a few annoying little things around permissions and performance—and the situation with discovery—it feels great to have websites that act just like other apps. I like that some of the icons in my dock are native, some are web apps, and I mostly don’t notice the difference.\n\nI wonder if there’s much point using wrappers like Electron any more? I feel like they were mostly aiming to get that parity with native apps in having a standalone application launched from the dock.\n\nNow all you need is a website.\n\nI must admit, when Jake told me he was leaving Google, I got very worried about the future of the View Transitions API.\n\nTo recap: Chrome shipped support for the API, but only for single page apps. That had me worried:\n\nIf the View Transitions API works across page navigations, it could be the single best thing to happen to the web in years.\n\nIf the View Transitions API only works for single page apps, it could be the single worst thing to happen to the web in years.\n\nWell, the multi-page version still hasn’t yet shipped in Chrome stable, but it is available in Chrome Canary behind a flag, so it looks like it’s almost here!\n\nRobin took the words out of my mouth:\n\nAnyway, even this cynical jerk is excited about this thing.\n\nAre you the kind of person who flips feature flags on in nightly builds to test new APIs?\n\nMe neither.\n\nBut I made an exception for the View Transitions API. So did Dave:\n\nI think the most telling predictor for the success of the multi-page View Transitions API – compared to all other proposals and solutions that have come before it – is that I actually implemented this one. Despite animations being my bread and butter for many years, I couldn’t be arsed to even try any of the previous generation of tools.\n\nDave’s post is an excellent step-by-step introduction to using view transitions on your website. To recap:\n\nEnable these two flags in Chrome Canary:\n\nchrome://flags#view-transition chrome://flags#view-transition-on-navigation\n\nThen add this meta element to the head of your website:\n\n<meta name=\"view-transition\" content=\"same-origin\">\n\nYou could stop there. If you navigate around your site, you’ll see that the navigations now fade in and out nicely from one page to another.\n\nBut the real power comes with transitioning page elements. Basically, you want to say “this element on this page should morph into that element on that page.” And when I say morph, I mean morph. As Dave puts it:\n\nBehind the scenes the browser is rasterizing (read: making an image of) the before and after states of the DOM elements you’re transitioning. The browser figures out the differences between those two snapshots and tweens between them similar to Apple Keynote’s “Magic Morph” feature, the liquid metal T-1000 from Terminator 2: Judgement Day, or the 1980s cartoon series Turbo Teen.\n\nIf those references are lost on you, how about the popular kids book series Animorphs?\n\nSome classic examples would be:\n\nA thumbnail of a video on one page morphs into the full-size video on the next page.\n\nA headline and snippet of an article on one page morphs into the full article on the next page.\n\nI’ve added view transitions to The Session. Where I’ve got index pages with lists of titles, each title morphs into the heading on the next page.\n\nAgain, Dave’s post was really useful here. Each transition needs a unique name, so I used Dave’s trick of naming each transition with the ID of the individual item being linked to.\n\nIn the recordings section, for example, there might be a link like this on the index page:\n\n<a href=\"/recordings/7812\" style=\"view-transition-name: recording-7812\">The Banks Of The Moy</a>\n\nWhich, if you click on it, takes you to the page with this heading:\n\n<h1><span style=\"view-transition-name: recording-7812\">The Banks Of The Moy</span></h1>\n\nWhy the span? Well, like Dave, I noticed some weird tweening happening between block and inline elements. Dave solved the problem with width: fit-content on the block-level element. I just stuck in an extra inline element.\n\nAnyway, the important thing is that the name of the view transition matches: recording-7812.\n\nI also added a view transition to pages that have maps. The position of the map might change from page to page. Now there’s a nice little animation as you move from one page with a map to another page with a map.\n\nThat’s all good, but I found myself wishing that I could just have those enhancements. Every single navigation on the site was triggering a fade in and out—the default animation. I wondered if there was a way to switch off the default fading.\n\nThere is! That default animation is happening on a view transition named root. You can get rid of it with this snippet of CSS:\n\n::view-transition-image-pair(root) { isolation: auto; } ::view-transition-old(root), ::view-transition-new(root) { animation: none; mix-blend-mode: normal; display: block; }\n\nVoila! Now only the view transitions that you name yourself will get applied.\n\nYou can adjust the timing, the easing, and the animation properites of your view transitions. Personally, I was happy with the default morph.\n\nIn fact, that’s one of the things I like about this API. It’s another good example of declarative design. I say what I want to happen, but I don’t need to specify the details. I’ll let the browser figure all that out.\n\nThat’s what’s got me so excited about this API. Yes, it’s powerful. But just as important, it’s got a very low barrier to entry.\n\nChris has gathered a bunch of examples together in his post Early Days Examples of View Transitions. Have a look around to get some ideas.\n\nIf you like what you see, I highly encourage you to add view transitions to your website now.\n\n“But wait,” I hear you cry, “this isn’t supported in any public-facing browser yet!”\n\nTo which, I respond “So what?” It’s a perfect example of progressive enhancement. Adding one meta element and a smidgen of CSS will do absolutely no harm to your website. And while no-one will see your lovely view transitions yet, once browsers do start shipping with support for the API, your site will automatically get better.\n\nYour website will be enhanced. Progressively.\n\nUpdate: Simon Pieters quite rightly warns against adding view transitions to live sites before the API is done:\n\nin general, using features before they ship in a browser isn’t a great idea since it can poison the feature with legacy content that might break when the feature is enabled. This has happened several times and renames or so were needed.\n\nGood point. I must temper my excitement with pragmatism. Let me amend my advice:\n\nI highly encourage you to experiment with view transitions on your website now.\n\nThe Competition and Markets Authority (CMA) recently published an interim report on their mobile ecosystems market study. It’s well worth reading, especially the section on competition in the supply of mobile browsers:\n\nOn iOS devices, Apple bans the use of alternative browser engines – this means that Apple has a monopoly over the supply of browser engines on iOS. It also chooses not to implement – or substantially delays – a wide range of features in its browser engine. This restriction has 2 main effects:\n\nlimiting rival browsers’ ability to differentiate themselves from Safari on factors such as speed and functionality, meaning that Safari faces less competition from other browsers than it otherwise could do; and\n\nlimiting the functionality of web apps – which could be an alternative to native apps as a means for mobile device users to access online content – and thereby limits the constraint from web apps on native apps. We have not seen compelling evidence that suggests Apple’s ban on alternative browser engines is justified on security grounds.\n\nThat last sentence is a wonderful example of British understatement. Far from protecting end users from security exploits, Apple have exposed everyone on iOS to all of the security issues of Apple’s Safari browser (regardless of what brower the user thinks they are using).\n\nThe CMA are soliciting responses to their interim report:\n\nTo respond to this consultation, please email or post your submission to:\n\nEmail: mobileecosystems@cma.gov.uk\n\nPost:\n\nMobile Ecosystems Market Study\n\nCompetition and Markets Authority\n\n25 Cabot Square\n\nLondon\n\nE14 4QZ\n\nPlease respond by no later than 5pm GMT on 7 February 2022.\n\nI encourage you to send a response before this coming Monday. This is the email I’ve sent.\n\nHello,\n\nThis response is regarding competition in the supply of mobile browsers and contains no confidential information.\n\nI read your interim report with great interest.\n\nAs a web developer and the co-founder of a digital design agency, I could cite many reasons why Apple’s moratorium on rival browser engines is bad for business. But the main reason I am writing to you is as a consumer and a user of Apple’s products.\n\nI own two Apple computing devices: a laptop and a phone. On both devices, I can install apps from Apple’s App Store. But on my laptop I also have the option to download and install an application from elsewhere. I can’t do this on my phone. That would be fine if my needs were met by what’s available in the app store. But clause 2.5.6 of Apple’s app store policy restricts what is available to me as a consumer.\n\nOn my laptop I can download and install Mozilla’s Firefox or Google’s Chrome browsers. On my phone, I can install something called Firefox and something called Chrome. But under the hood, they are little more than skinned versions of Safari. I’m only aware of this because I’m au fait with the situation. Most of my fellow consumers have no idea that when they install the app called Firefox or the app called Chrome from the app store on their phone, they are being deceived.\n\nIt is this deception that bothers me most.\n\nKind regards,\n\nJeremy Keith\n\nTo be fair to Apple, this deception requires collusion from Mozilla, Google, Microsoft, and other browser makers. Nobody’s putting a gun to their heads and forcing them to ship skinned versions of Safari that bear only cosmetic resemblance to their actual products.\n\nBut of course it would be commercially unwise to forego the app store as a distrubution channel, even if the only features they can ship are superficial ones like bookmark syncing.\n\nStill, imagine what would happen if Mozilla, Google, and Microsoft put their monies where their mouths are. Instead of just complaining about the unjust situation, what if they actually took the financial hit and pulled their faux-browsers from the iOS app store?\n\nIf this unjustice is as important as representatives from Google, Microsoft, and Mozilla claim it is, then righteous indignation isn’t enough. Principles without sacrifice are easy.\n\nIf nothing else, it would throw the real situation into light and clear up the misconception that there is any browser choice on iOS.\n\nI know it’s not going to happen. I also know I’m being a hypocrite by continuing to use Apple products in spite of the blatant misuse of monopoly power on display. But still, I wanted to plant that seed. What if Microsoft, Google, and Mozilla were the ones who walk away from Omelas.\n\nThere was quite a kerfuffle recently about a feature being removed from Google Chrome. To be honest, the details don’t really matter for the point I want to make, but for the record, this was about removing alert and confirm dialogs from cross-origin iframes (and eventually everywhere else too).\n\nIt’s always tricky to remove a long-established feature from web browsers, but in this case there were significant security and performance reasons. The problem was how the change was communicated. It kind of wasn’t. So the first that people found out about it about was when things suddenly stopped working (like CodePen embeds).\n\nThe Chrome team responded quickly and the change has now been pushed back to next year. Hopefully there will be significant communication before that to let site owners know about the upcoming breakage.\n\nSo all’s well that ends well and we’ve all learned a valuable lesson about the importance of communication.\n\nOr have we?\n\nWhile this was going on, Emily Stark tweeted a more general point about breakage on the web:\n\nBreaking changes happen often on the web, and as a developer it’s good practice to test against early release channels of major browsers to learn about any compatibility issues upfront.\n\nYikes! To me, this appears wrong on almost every level.\n\nFirst of all, breaking changes don’t happen often on the web. They are—and should be—rare. If that were to change, the web would suffer massively in terms of predictability.\n\nSecondly, the onus is not on web developers to keep track of older features in danger of being deprecated. That’s on the browser makers. I sincerely hope we’re not expected to consult a site called canistilluse.com.\n\nI wasn’t the only one surprised by this message.\n\nSimon says:\n\nNo, no, no, no! One of the best things about developing for the web is that, as a rule, browsers don’t break old code. Expecting every website and application to have an active team of developers maintaining it at all times is not how the web should work!\n\nEdward Faulkner:\n\nMost organizations and individuals do not have the resources to properly test and debug their website against Chrome canary every six weeks. Anybody who published a spec-compliant website should be able to trust that it will keep working.\n\nEvan You:\n\nThis statement seriously undermines my trust in Google as steward for the web platform. When did we go from “never break the web” to “yes we will break the web often and you should be prepared for it”?!\n\nIt’s worth pointing out that the original tweet was not an official Google announcement. As Emily says right there on her Twitter account:\n\nOpinions are my own.\n\nStill, I was shaken to see such a cavalier attitude towards breaking changes on the World Wide Web. I know that removing dangerous old features is inevitable, but it should also be exceptional. It should not be taken lightly, and it should certainly not be expected to be an everyday part of web development.\n\nIt’s almost miraculous that I can visit the first web page ever published in a modern web browser and it still works. Let’s not become desensitised to how magical that is. I know it’s hard work to push the web forward, constantly add new features, while also maintaining backward compatibility, but it sure is worth it! We have collectively banked three decades worth of trust in the web as a stable place to build a home. Let’s not blow it.\n\nIf you published a website ten or twenty years ago, and you didn’t use any proprietary technology but only stuck to web standards, you should rightly expect that site to still work today …and still work ten and twenty years from now.\n\nThere was something else that bothered me about that tweet and it’s not something that I saw mentioned in the responses. There was an unspoken assumption that the web is built by professional web developers. That gave me a cold chill.\n\nThe web has made great strides in providing more and more powerful features that can be wielded in learnable, declarative, forgiving languages like HTML and CSS. With a bit of learning, anyone can make web pages complete with form validation, lazily-loaded responsive images, and beautiful grids that kick in on larger screens. The barrier to entry for all of those features has lowered over time—they used to require JavaScript or complex hacks. And with free(!) services like Netlify, you could literally drag a folder of web pages from your computer into a browser window and boom!, you’ve published to the entire world.\n\nBut the common narrative in the web development community—and amongst browser makers too apparently—is that web development has become more complex; so complex, in fact, that only an elite priesthood are capable of making websites today.\n\nAbsolute bollocks.\n\nYou can choose to make it really complicated. Convince yourself that “the modern web” is inherently complex and convoluted. But then look at what makes it complex and convoluted: toolchains, build tools, pipelines, frameworks, libraries, and abstractions. Please try to remember that none of those things are required to make a website.\n\nThis is for everyone. Not just for everyone to consume, but for everyone to make.\n\nI’ve always liked the way that web browsers are called “user agents” in the world of web standards. It’s such a succinct summation of what browsers are for, or more accurately who browsers are for. Users.\n\nThe term makes sense when you consider that the internet is for end users. That’s not to be taken for granted. This assertion is now enshrined in the Internet Engineering Task Force’s RFC 8890—like Magna Carta for the network age. It’s also a great example of prioritisation in a design principle:\n\nWhen there is a conflict between the interests of end users of the Internet and other parties, IETF decisions should favor end users.\n\nSo when a web browser—ostensibly an agent for the user—prioritises user-hostile third parties, we get upset.\n\nGoogle Chrome—ostensibly an agent for the user—is running an origin trial for Federated Learning of Cohorts (FLoC). This is not a technology that serves the end user. It is a technology that serves third parties who want to target end users. The most common use case is behavioural advertising, but targetting could be applied for more nefarious purposes.\n\nThe Electronic Frontier Foundation wrote an explainer last month: Google Is Testing Its Controversial New Ad Targeting Tech in Millions of Browsers. Here’s What We Know.\n\nLet’s back up a minute and look at why this is happening. End users are routinely targeted today (for behavioural advertising and other use cases) through third-party cookies. Some user agents like Apple’s Safari and Mozilla’s Firefox are stamping down on this, disabling third party cookies by default.\n\nSeeing which way the wind is blowing, Google’s Chrome browser will also disable third-party cookies at some time in the future (they’re waiting to shut that barn door until the fire is good’n’raging). But Google isn’t just in the browser business. Google is also in the ad tech business. So they still want to advertisers to be able to target end users.\n\nYes, this is quite the cognitive dissonance: one part of the business is building a user agent while a different part of the company is working on ways of tracking end users. It’s almost as if one company shouldn’t simultaneously be the market leader in three separate industries: search, advertising, and web browsing. (Seriously though, I honestly think Google’s search engine would get better if it were split off from the parent company, and I think that Google’s web browser would also get better if it were a separate enterprise.)\n\nAnyway, one possible way of tracking users without technically tracking individual users is to assign them to buckets, or cohorts of interest based on their browsing habits. Does that make you feel safer? Me neither.\n\nThat’s what Google is testing with the origin trial of FLoC.\n\nIf you, as an end user, don’t wish to be experimented on like this, there are a few things you can do:\n\nDon’t use Chrome. No other web browser is participating in this experiment. I recommend Firefox.\n\nIf you want to continue to use Chrome, install the Duck Duck Go Chrome extension.\n\nAlternatively, if you manually disable third-party cookies, your Chrome browser won’t be included in the experiment.\n\nOr you could move to Europe. The origin trial won’t be enabled for users in the European Union, which is coincidentally where GDPR applies.\n\nThat last decision is interesting. On the one hand, the origin trial is supposed to be on a small scale, hence the lack of European countries. On the other hand, the origin trial is “opt out” instead of “opt in” so that they can gather a big enough data set. Weird.\n\nThe plan is that if and when FLoC launches, websites would have to opt in to it. And when I say “plan”, I mean “best guess.”\n\nI, for one, am filled with confidence that Google would never pull a bait-and-switch with their technologies.\n\nIn the meantime, if you’re a website owner, you have to opt your website out of the origin trial. You can do this by sending a server header. A meta element won’t do the trick, I’m afraid.\n\nI’ve done it for my sites, which are served using Apache. I’ve got this in my .conf file:\n\n<IfModule mod_headers.c> Header always set Permissions-Policy \"interest-cohort=()\" </IfModule>\n\nIf you don’t have access to your server, tough luck. But if your site runs on Wordpress, there’s a proposal to opt out of FLoC by default.\n\nInterestingly, none of the Chrome devs that I follow are saying anything about FLoC. They’re usually quite chatty about proposals for potential standards, but I suspect that this one might be embarrassing for them. It was a similar situation with AMP. In that case, Google abused its monopoly position in search to blackmail publishers into using Google’s format. Now Google’s monopoly in advertising is compromising the integrity of its browser. In both cases, it makes it hard for Chrome devs claiming to have the web’s best interests at heart.\n\nBut one of the advantages of having a huge share of the browser market is that Chrome can just plough ahead and unilaterily implement whatever it wants even if there’s no consensus from other browser makers. So that’s what Google is doing with FLoC. But their justification for doing this doesn’t really work unless other browsers play along.\n\nHere’s Google’s logic:\n\nThird-party cookies are on their way out so advertisers will no longer be able to use that technology to target users.\n\nIf we don’t provide an alternative, advertisers and other third parties will use fingerprinting, which we all agree is very bad.\n\nSo let’s implement Federated Learning of Cohorts so that advertisers won’t use fingerprinting.\n\nThe problem is with step three. The theory is that if FLoC gives third parties what they need, then they won’t reach for fingerprinting. Even if there were any validity to that hypothesis, the only chance it has of working is if every browser joins in with FLoC. Otherwise ad tech companies are leaving money on the table. Can you seriously imagine third parties deciding that they just won’t target iPhone or iPad users any more? Remember that Safari is the only real browser on iOS so unless FLoC is implemented by Apple, third parties can’t reach those people …unless those third parties use fingerprinting instead.\n\nGoogle have set up a situation where it looks like FLoC is going head-to-head with fingerprinting. But if FLoC becomes a reality, it won’t be instead of fingerprinting, it will be in addition to fingerprinting.\n\nGoogle is quite right to point out that fingerprinting is A Very Bad Thing. But their concerns about fingerprinting sound very hollow when you see that Chrome is pushing ahead and implementing a raft of browser APIs that other browser makers quite rightly point out enable more fingerprinting: Battery Status, Proximity Sensor, Ambient Light Sensor and so on.\n\nWhen it comes to those APIs, the message from Google is that fingerprinting is a solveable problem.\n\nBut when it comes to third party tracking, the message from Google is that fingerprinting is inevitable and so we must provide an alternative.\n\nWhich one is it?\n\nGoogle’s flimsy logic for why FLoC is supposedly good for end users just doesn’t hold up. If they were honest and said that it’s to maintain the status quo of the ad tech industry, it would make much more sense.\n\nThe flaw in Google’s reasoning is the fundamental idea that tracking is necessary for advertising. That’s simply not true. Sacrificing user privacy is fundamental to behavioural advertising …but behavioural advertising is not the only kind of advertising. It isn’t even a very good kind of advertising.\n\nMarko Saric sums it up:\n\nFLoC seems to be Google’s way of saving a dying business. They are trying to keep targeted ads going by making them more “privacy-friendly” and “anonymous”. But behavioral profiling and targeted advertisement is not compatible with a privacy-respecting web.\n\nWhat’s striking is that the very monopolies that make Google and Facebook the leaders in behavioural advertising would also make them the leaders in contextual advertising. Almost everyone uses Google’s search engine. Almost everyone uses Facebook’s social network. An advertising model based on what you’re currently looking at would keep Google and Facebook in their dominant positions.\n\nGoogle made their first many billions exclusively on contextual advertising. Google now prefers to push the message that behavioral advertising based on personal data collection is superior but there is simply no trustworthy evidence to that.\n\nI sincerely hope that Chrome will align with Safari, Firefox, Vivaldi, Brave, Edge and every other web browser. Everyone already agrees that fingerprinting is the real enemy. Imagine the combined brainpower that could be brought to bear on that problem if all browsers made user privacy a priority.\n\nUntil that day, I’m not sure that Google Chrome can be considered a user agent.\n\nI think I’ve found some more strange service worker behaviour in Chrome.\n\nIt all started when I was checking out the very nice new redesign of WebPageTest. I figured while I was there, I’d run some of my sites through it. I passed in a URL from The Session. When the test finished, I noticed that the “screenshot” tab said that something was being logged to the console. That’s odd! And the file doing the logging was the service worker script.\n\nI fired up Chrome (which isn’t my usual browser), and started navigating around The Session with dev tools open to see what appeared in the console. Sure enough, there was a failed fetch attempt being logged. The only time my service worker script logs anything is in the catch clause of fetching pages from the network. So Chrome was trying to fetch a web page, failing, and logging this error:\n\nThe service worker navigation preload request failed with a network error.\n\nBut all my pages were loading just fine. So where was the error coming from?\n\nAfter a lot of spelunking and debugging, I think I’ve figured out what’s happening…\n\nFirst of all, I’m making use of navigation preloads in my service worker. That’s all fine.\n\nSecondly, the website is a progressive web app. It has a manifest file that specifies some metadata, including start_url. If someone adds the site to their home screen, this is the URL that will open.\n\nThirdly, Google recently announced that they’re tightening up the criteria for displaying install prompts for progressive web apps. If there’s no network connection, the site still needs to return a 200 OK response: either a cached copy of the URL or a custom offline page.\n\nSo here’s what I think is happening. When I navigate to a page on the site in Chrome, the service worker handles the navigation just fine. It also parses the manifest file I’ve linked to and checks to see if that start URL would load if there were no network connection. And that’s when the error gets logged.\n\nI only noticed this behaviour because I had specified a query string on my start URL in the manifest file. Instead of a start_url value of /, I’ve set a start_url value of /?homescreen. And when the error shows up in the console, the URL being fetched is /?homescreen.\n\nCrucially, I’m not seeing a warning in the console saying “Site cannot be installed: Page does not work offline.” So I think this is all fine. If I were actually offline, there would indeed be an error logged to the console and that start_url request would respond with my custom offline page. It’s just a bit confusing that the error is being logged when I’m online.\n\nI thought I’d share this just in case anyone else is logging errors to the console in the catch clause of fetches and is seeing an error even when everything appears to be working fine. I think there’s nothing to worry about.\n\nUpdate: Jake confirmed my diagnosis and agreed that the error is a bit confusing. The good news is that it’s changing. In Chrome Canary the error message has already been updated to:\n\nDOMException: The service worker navigation preload request failed due to a network error. This may have been an actual network error, or caused by the browser simulating offline to see if the page works offline: see https://w3c.github.io/manifest/#installability-signals\n\nMuch better!\n\nI started getting some emails recently from people having issues using The Session. The issues sounded similar—an interactive component that wasn’t, well …interacting.\n\nWhen I asked what device or browser they were using, the answer came back the same: Safari on iPad. But not a new iPad. These were older iPads running older operating systems.\n\nNow, remember, even if I wanted to recommend that they use a different browser, that’s not an option:\n\nSafari is the only browser on iOS devices.\n\nI don’t mean it’s the only browser that ships with iOS devices. I mean it’s the only browser that can be installed on iOS devices.\n\nYou can install something called Chrome. You can install something called Firefox. Those aren’t different web browsers. Under the hood they’re using Safari’s rendering engine. They have to.\n\nIt gets worse. Not only is there no choice when it comes to rendering engines on iOS, but the rendering engine is also tied to the operating system.\n\nIf you’re on an old Apple laptop, you can at least install an up-to-date version of Firefox or Chrome. But you can’t install an up-to-date version of Safari. An up-to-date version of Safari requires an up-to-date version of the operating system.\n\nIt’s the same on iOS devices—you can’t install a newer version of Safari without installing a newer version of iOS. But unlike the laptop scenario, you can’t install any version of Firefox of Chrome.\n\nIt’s disgraceful.\n\nIt’s particularly frustrating when an older device can’t upgrade its operating system. Upgrades for Operating system generally have some hardware requirements. If your device doesn’t meet those requirements, you can’t upgrade your operating system. That wouldn’t matter so much except for the Safari issue. Without an upgraded operating system, your web browsing experience stagnates unnecessarily.\n\nFor want of a nail…\n\nA website feature isn’t working so\n\nyou need to upgrade your browser which means\n\nyou need to upgrade your operating sytem but\n\nyou can’t upgrade your operating system so\n\nyou need to buy a new device.\n\nApple doesn’t allow other browsers to be installed on iOS devices so people have to buy new devices if they want to use the web. Handy for Apple. Bad for users. Really bad for the planet.\n\nIt’s particularly galling when it comes to iPads. Those are exactly the kind of casual-use devices that shouldn’t need to be caught in the wasteful cycle of being used for a while before getting thrown away. I mean, I get why you might want to have a relatively modern phone—a device that’s constantly with you that you use all the time—but an iPad is the perfect device to just have lying around. You shouldn’t feel pressured to have the latest model if the older version still does the job:\n\nAn older tablet makes a great tableside companion in your living room, an effective e-book reader, or a light-duty device for reading mail or checking your favorite websites.\n\nHang on, though. There’s another angle to this. Why should a website demand an up-to-date browser? If the website has been built using the tried and tested approach of progressive enhancement, then everyone should be able to achieve their goals regardless of what browser or device or operating system they’re using.\n\nOn The Session, I’m using progressive enhancement and feature detection everywhere I can. If, for example, I’ve got some JavaScript that’s going to use querySelectorAll and addEventListener, I’ll first test that those methods are available.\n\nif (!document.querySelectorAll || !window.addEventListener) { // doesn't cut the mustard. return; }\n\nI try not to assume that anything is supported. So why was I getting emails from people with older iPads describing an interaction that wasn’t working? A JavaScript error was being thrown somewhere and—because of JavaScript’s brittle error-handling—that was causing all the subsequent JavaScript to fail.\n\nI tracked the problem down to a function that was using some DOM methods—matches and closest—as well as the relatively recent JavaScript forEach method. But I had polyfills in place for all of those. Here’s the polyfill I’m using for matches and closest. And here’s the polyfill I’m using for forEach.\n\nThen I spotted the problem. I was using forEach to loop through the results of querySelectorAll. But the polyfill works on arrays. Technically, the output of querySelectorAll isn’t an array. It looks like an array, it quacks like an array, but it’s actually a node list.\n\nSo I added this polyfill from Chris Ferdinandi.\n\nThat did the trick. I checked with the people with those older iPads and everything is now working just fine.\n\nFor the record, here’s the small collection of polyfills I’m using. Polyfills are supposed to be temporary. At some stage, as everyone upgrades their browsers, I should be able to remove them. But as long as some people are stuck with using an older browser, I have to keep those polyfills around.\n\nI wish that Apple would allow other rendering engines to be installed on iOS devices. But if that’s a hell-freezing-over prospect, I wish that Safari updates weren’t tied to operating system updates.\n\nApple may argue that their browser rendering engine and their operating system are deeply intertwingled. That line of defence worked out great for Microsoft in the ‘90s.\n\nSafari is the only browser on iOS devices.\n\nI don’t mean it’s the only browser that ships with iOS devices. I mean it’s the only browser that can be installed on iOS devices.\n\nYou can install something called Chrome. You can install something called Firefox. Those aren’t different web browsers. Under the hood they’re using Safari’s rendering engine. They have to. The app store doesn’t allow other browsers to be listed. The apps called Chrome and Firefox are little more than skinned versions of Safari.\n\nIf you’re a web developer, there are two possible reactions to hearing this. One is “Duh! Everyone knows that!”. The other is “What‽ I never knew that!”\n\nIf you fall into the first category, I’m guessing you’ve been a web developer for a while. The fact that Safari is the only browser on iOS devices is something you’ve known for years, and something you assume everyone else knows. It’s common knowledge, right?\n\nBut if you’re relatively new to web development—heck, if you’ve been doing web development for half a decade—you might fall into the second category. After all, why would anyone tell you that Safari is the only browser on iOS? It’s common knowledge, right?\n\nSo that’s the situation. Safari is the only browser that can run on iOS. The obvious follow-on question is: why?\n\nApple at this point will respond with something about safety and security, which are certainly important priorities. So let me rephrase the question: why on iOS?\n\nWhy can I install Chrome or Firefox or Edge on my Macbook running macOS? If there are safety or security reasons for preventing me from installing those browsers on my iOS device, why don’t those same concerns apply to my macOS device?\n\nAt one time, the mobile operating system—iOS—was quite different to the desktop operating system—OS X. Over time the gap has narrowed. At this point, the operating systems are converging. That makes sense. An iPhone, an iPad, and a Macbook aren’t all that different apart from the form factor. It makes sense that computing devices from the same company would share an underlying operating system.\n\nAs this convergence continues, the browser question is going to have to be decided in one direction or the other. As it is, Apple’s laptops and desktops strongly encourage you to install software from their app store, though it is still possible to install software by other means. Perhaps they’ll decide that their laptops and desktops should only be able to install software from their app store—a decision they could justify with safety and security concerns.\n\nImagine that situation. You buy a computer. It comes with one web browser pre-installed. You can’t install a different web browser on your computer.\n\nYou wouldn’t stand for it! I mean, Microsoft got fined for anti-competitive behaviour when they pre-bundled their web browser with Windows back in the 90s. You could still install other browsers, but just the act of pre-bundling was seen as an abuse of power. Imagine if Windows never allowed you to install Netscape Navigator?\n\nAnd yet that’s exactly the situation in 2020.\n\nYou buy a computing device from Apple. It might be a Macbook. It might be an iPad. It might be an iPhone. But you can only install your choice of web browser on one of those devices. For now.\n\nIt is contradictory. It is hypocritical. It is indefensible.\n\nLast month I wrote some musings on default browser behaviours. When it comes to all the tasks that browsers do for us, the most fundamental is taking a URL, fetching its contents and giving us the results. As part of that process, browsers also show us the URL of the page currently loaded in a tab or window.\n\nBut even at this fundamental level, there are some differences from browser to browser.\n\nSafari only shows you the domain name—and any subdomain names—by default. It looks like nice and tidy, but it obfuscates what page you’re on (until you click on the domain name). This is bad.\n\nChrome shows you the full URL, nice and straightforward. This is neutral.\n\nFirefox, like Chrome, shows you the full URL, but with a subtle difference. The important part of the URL—usually the domain name—is subtly highlighted in a darker shade of grey. This is good.\n\nThe reason I say that what it highlights is usually the domain name is because what it actually highlights is eTLD+1.\n\nThe what now?\n\nWell, if you’re looking at a page on adactio.com, that’s the important bit. But what if you’re looking at a page on adactio.github.io? The domain name is important, but so is the subdomain.\n\nIt turns out there’s a list out there of which sites and top level domains allow registrations like this. This is the list that Firefox is using for its shading behaviour in displaying URLs.\n\nSafari, by the way, does not use this list. These URLs are displayed identically in Safari, the phisherman’s friend:\n\nexample.com\n\nexample.github.io\n\ngithub.example.com\n\nWhereas Firefox displays them as:\n\nexample.com\n\nexample.github.io\n\ngithub.example.com\n\nI learned all this from Jake on a recent edition of HTTP 203. Nicolas Hoizey has writen a nice little summary.\n\nJake acknowledges that what Apple is doing is shi… suboptimal, what Firefox is doing is good, and then puts forward an idea for what Chrome could do. (But please note that this is Jake’s personal opinion; not an official proposal from the Chrome team.)\n\nThere’s some prior art here. It used to be that, if your SSL certificate included extended validation, the name would be shown in green next to the padlock symbol. So while my website—which uses regular SSL from Let’s Encrypt—would just have a padlock, Medium—which uses EV SSL—would have a padlock and the text “A Medium Corporation”.\n\nExtended validation wasn’t quite the bulletproof verification it was cracked up to be. So browsers don’t use that interface pattern any more.\n\nJake suggests repurposing this pattern for all URLs. Pull out the important bit—eTLD+1—and show it next to the padlock.\n\nI like this. The full URL is still displayed. This proposal is more of an incremental change. An enhancement that is applied progressively, if you will.\n\nI also like that it builds on existing interface patterns—Firefox’s URL treatment and the deprecated treatment of EV certs. In fact, I think the first step for Chrome should be to match Firefox’s current behaviour, and then go further with something like Jake’s proposal.\n\nThis kind of gradual change was exactly what Chrome did with displaying https and http domains.\n\nJake mentions this in the video\n\nWe’ve already seen that you have to take small steps here, like we did with the https change.\n\nThere’s a fascinating episode of the Freakonomics podcast called In Praise of Incrementalism. I’ve huffduffed it.\n\nIn Praise of Incrementalism (Ep. 264) - Freakonomics Freakonomics on Huffduffer\n\nI’m a great believer in the HTML design principle, Evolution Not Revolution:\n\nIt is better to evolve an existing design rather than throwing it away.\n\nI’d love to see Chrome take the first steps to Jake’s proposal by following Firefox’s lead.\n\nThen again, I’d love it if Chrome followed Firefox’s lead in implementing subgrid.\n\nIt’s official. Microsoft’s Edge browser is running on the Blink rendering engine and it’s available now.\n\nJust over a year ago, I wrote about my feelings on this decision:\n\nI’m sure the decision makes sound business sense for Microsoft, but it’s not good for the health of the web.\n\nThe importance of browser engine diversity is beautifully illustrated (literally) in Rachel’s The Ecological Impact of Browser Diversity.\n\nBut I was chatting to Amber the other day, and I mentioned how I can see the theoretical justification for Microsoft’s decision …even if I don’t quite buy it myself.\n\nPicture, if you will, something I’ll call the bar of unity. It’s a measurement of how much collaboration is happening between browser makers.\n\nIn the early days of the web, the bar of unity was very low indeed. The two main browser vendors—Microsoft and Netscape—not only weren’t collaborating, they were actively splintering the languages of the web. One of them would invent a new HTML element, and the other would invent a completely different element to do the same thing (remember abbr and acronym). One of them would come up with one model for interacting with a document through JavaScript, and the other would come up with a completely different model to the same thing (remember document.all and document.layers).\n\nThere wasn’t enough collaboration. Our collective anger at this situation led directly to the creation of The Web Standards Project.\n\nEventually, those companies did start collaborating on standards at the W3C. The bar of unity was raised.\n\nThis has been the situation for most of the web’s history. Different browser makers agreed on standards, but went their own separate ways on implementation. That’s where they drew the line.\n\nNow that line is being redrawn. The bar of unity is being raised. Now, a number of separate browser makers—Google, Samsung, Microsoft—not only collaborate on standards but also on implementation, sharing a codebase.\n\nThe bar of unity isn’t right at the top. Browsers can still differentiate in their user interfaces. Edge, for example, can—and does—offer very sensible defaults for blocking trackers. That’s much harder for Chrome to do, given that Google are amongst the worst offenders.\n\nSo these browsers are still competing, but the competition is no longer happening at the level of the rendering engine.\n\nI can see how this looks like a positive development. In fact, from this point of view, Mozilla are getting in the way of progress by having a separate codebase (yes, this is a genuinely-held opinion by some people).\n\nOn the face of it, more unity sounds good. It sounds like more collaboration. More cooperation.\n\nBut then I think of situations where complete unity isn’t necessarily a good thing. Take political systems, for example. If you have hundreds of different political parties, that’s not ideal. But if you only have one political party, that’s very bad indeed!\n\nThere’s a sweet spot somewhere in between where there’s a base of level of agreement and cooperation, but there’s also plenty of room for disagreement and opposition. Right now, the browser landscape is just about still in that sweet spot. It’s like a two-party system where one party has a crushing majority. Checks and balances exist, but they’re in peril.\n\nFirefox is one of the last remaining representatives offering an alternative. The least we can do is support it.\n\nShockwaves rippled across the web standards community recently when it appeared that Google Chrome was unilaterally implementing a new element called toast. It turns out that’s not the case, but the confusion is understandable.\n\nFirst off, this all kicked off with the announcement of “intent to implement”. That makes it sounds like Google are intending to, well, …implement this. In fact “intent to implement” really means “intend to mess around with this behind a flag”. The language is definitely confusing and this is something that will hopefully be addressed.\n\nSecondly, Chrome isn’t going to ship a toast element. Instead, this is a proposal for a custom element currently called std-toast. I’m assuming that should the experiment prove successful, it’s not a foregone conclusion that the final element name will be called toast (minus the sexually-transmitted-disease prefix). If this turns out to be a useful feature, there will surely be a discussion between implementators about the naming of the finished element.\n\nThis is the ideal candidate for a web component. It makes total sense to create a custom element along the lines of std-toast. At first I was confused about why this was happening inside of a browser instead of first being created as a standalone web component, but it turns out that there’s been a fair bit of research looking at existing implementations in libraries and web components. So this actually looks like a good example of paving an existing cowpath.\n\nBut it didn’t come across that way. The timing of announcements felt like this was something that was happening without prior discussion. Terence Eden writes:\n\nIt feels like a Google-designed, Google-approved, Google-benefiting idea which has been dumped onto the Web without any consideration for others.\n\nI know that isn’t the case. And I know how many dedicated people have worked hard on this proposal.\n\nAdrian Roselli also remarks on the optics of this situation:\n\nTo be clear, while I think there is value in minting a native HTML element to fill a defined gap, I am wary of the approach Google has taken. A repo from a new-to-the-industry Googler getting a lot of promotion from Googlers, with Googlers on social media doing damage control for the blowback, WHATWG Googlers handling questions on the repo, and Google AMP strongly supporting it (to reduce its own footprint), all add up to raise alarm bells with those who advocated for a community-driven, needs-based, accessible web.\n\nDave Cramer made a similar point:\n\nBut my concern wasn’t so much about the nature of the new elements, but of how we learned about them and what that says about how web standardization works.\n\nSo there’s a general feeling (outside of Google) that there’s something screwy here about the order of events. A lot discussion and research seems to have happened in isolation before announcing the intent to implement:\n\nIt does not appear that any discussions happened with other browser vendors or standards bodies before the intent to implement.\n\nWhy is this a problem? Google is seeking feedback on a solution, not on how to solve the problem.\n\nGoing back to my early confusion about putting a web component directly into a browser, this question on Discourse echoes my initial reaction:\n\nWhy not release std-toast (and other elements in development) as libraries first?\n\nIt turns out that std-toast and other in-browser web components are part of an idea called layered APIs. In theory this is an initiative in the spirit of the extensible web manifesto.\n\nThe extensible web movement focused on exposing low-level APIs to developers: the fetch API, the cache API, custom elements, Houdini, and all of those other building blocks. Layered APIs, on the other hand, focuses on high-level features …like, say, an HTML element for displaying “toast” notifications.\n\nLayered APIs is an interesting idea, but I’m worried that it could be used to circumvent discussion between implementers. It’s a route to unilaterally creating new browser features first and standardising after the fact. I know that’s how many features already end up in browsers, but I think that the sooner that authors, implementers, and standards bodies get a say, the better.\n\nI certainly don’t think this is a good look for Google given the debacle of AMP’s “my way or the highway” rollout. I know that’s a completely different team, but the external perception of Google amongst developers has been damaged by the AMP project’s anti-competitive abuse of Google’s power in search.\n\nRight now, a lot of people are jumpy about Microsoft’s move to Chromium for Edge. My friends at Microsoft have been reassuring me that while it’s always a shame to reduce browser engine diversity, this could actually be a good thing for the standards process: Microsoft could theoretically keep Google in check when it comes to what features are introduced to the Chromium engine.\n\nBut that only works if there is some kind of standards process. Layered APIs in general—and std-toast in particular—hint at a future where a single browser vendor can plough ahead on their own. I sincerely hope that’s a misreading of the situation and that this has all been an exercise in miscommunication and misunderstanding.\n\nLike Dave Cramer says:\n\nI hear a lot about how anyone can contribute to the web platform. We’ve all heard the preaching about incubation, the Extensible Web, working in public, paving the cowpaths, and so on. But to an outside observer this feels like Google making all the decisions, in private, and then asking for public comment after the feature has been designed.\n\nIt’s browser updatin’ time! Firefox 65 just dropped. So did Chrome 72. Safari 12.1 is shipping with iOS 12.2.\n\nIt’s interesting to compare the release notes for each browser and see the different priorities reflected in them (this is another reason why browser diversity is A Good Thing).\n\nA lot of the Firefox changes are updates to dev tools; they just keep getting better and better. In fact, I’m not sure “dev tools” is the right word for them. With their focus on layout, typography, and accessibility, “design tools” might be a better term.\n\nOh, and Firefox is shipping support for some CSS properties that really help with print style sheets, so I’m disproportionately pleased about that.\n\nIn Safari’s changes, I’m pleased to see that the datalist element is finally getting implemented. I’ve been a fan of that element for many years now. (Am I a dork for having favourite HTML elements? Or am I a dork for even having to ask that question?)\n\nAnd, of course, it wouldn’t be a Safari release without a new made up meta tag. From the people who brought you such hits as viewport and apple-mobile-web-app-capable, comes …supported-color-schemes (Apple likes to make up meta tags almost as much as Google likes to make up rel values).\n\nThere’ll be a whole bunch of improvements in how progressive web apps will behave once they’ve been added to the home screen. We’ll finally get some state persistence if you navigate away from the window!\n\nUpdated the behavior of websites saved to the home screen on iOS to pause in the background instead of relaunching each time.\n\nMaximiliano Firtman has a detailed list of the good, the bad, and the “not sure yet if good” for progressive web apps on iOS 12.2 beta. Thomas Steiner has also written up the progress of progressive web apps in iOS 12.2 beta. Both are published on Ev’s blog.\n\nAt first glance, the release notes for Chrome 72 are somewhat paltry. The big news doesn’t even seem to be listed there. Maximiliano Firtman again:\n\nChrome 72 for Android shipped the long-awaited Trusted Web Activity feature, which means we can now distribute PWAs in the Google Play Store!\n\nVery interesting indeed! I’m not sure if I’m ready to face the Kafkaesque process of trying to add something to the Google Play Store just yet, but it’s great to know that I can. Combined with the improvements coming in iOS 12.2, these are exciting times for progressive web apps!\n\nMicrosoft’s Edge browser is going to switch its rendering engine over to Chromium.\n\nI am deflated and disappointed.\n\nThere’s just no sugar-coating this. I’m sure the decision makes sound business sense for Microsoft, but it’s not good for the health of the web.\n\nVery soon, the vast majority of browsers will have an engine that’s either Blink or its cousin, WebKit. That may seem like good news for developers when it comes to testing, but trust me, it’s a sucky situation of innovation and agreement. Instead of a diverse browser ecosystem, we’re going to end up with incest and inbreeding.\n\nThere’s one shining exception though. Firefox. That browser was originally created to combat the seemingly unstoppable monopolistic power of Internet Explorer. Now that Microsoft are no longer in the rendering engine game, Firefox is once again the only thing standing in the way of a complete monopoly.\n\nI’ve been using Firefox as my main browser for a while now, and I can heartily recommend it. You should try it (and maybe talk to your relatives about it at Christmas). At this point, which browser you use no longer feels like it’s just about personal choice—it feels part of something bigger; it’s about the shape of the web we want.\n\nJeffrey wrote that browser diversity starts with us:\n\nThe health of Firefox is critical now that Chromium will be the web’s de facto rendering engine.\n\nEven if you love Chrome, adore Gmail, and live in Google Docs or Analytics, no single company, let alone a user-tracking advertising giant, should control the internet.\n\nAndy Bell also writes about browser diversity:\n\nI’ll say it bluntly: we must support Firefox. We can’t, as a community allow this browser engine monopoly. We must use Firefox as our main dev browsers; we must encourage our friends and families to use it, too.\n\nYes, it’s not perfect, nor are Mozilla, but we can help them to develop and grow by using Firefox and reporting issues that we find. If we just use and build for Chromium, which is looking likely (cough Internet Explorer monopoly cough), then Firefox will fall away and we will then have just one major engine left. I don’t ever want to see that.\n\nUncle Dave says:\n\nIf the idea of a Google-driven Web is of concern to you, then I’d encourage you to use Firefox. And don’t be a passive consumer; blog, tweet, and speak about its killer features. I’ll start: Firefox’s CSS Grid, Flexbox, and Variable Font tools are the best in the business.\n\nMozilla themselves came out all guns blazing when they said Goodbye, EdgeHTML:\n\nMicrosoft is officially giving up on an independent shared platform for the internet. By adopting Chromium, Microsoft hands over control of even more of online life to Google.\n\nTim describes the situation as risking a homogeneous web:\n\nI don’t think Microsoft using Chromium is the end of the world, but it is another step down a slippery slope. It’s one more way of bolstering the influence Google currently has on the web.\n\nWe need Google to keep pushing the web forward. But it’s critical that we have other voices, with different viewpoints, to maintain some sense of balance. Monocultures don’t benefit anyone.\n\nAndre Alves Garzia writes that while we Blink, we lose the web:\n\nLosing engines is like losing languages. People may wish that everyone spoke the same language, they may claim it leads to easier understanding, but what people fail to consider is that this leads to losing all the culture and way of thought that that language produced. If you are a Web developer smiling and happy that Microsoft might be adopting Chrome, and this will make your work easier because it will be one less browser to test, don’t be! You’re trading convenience for diversity.\n\nI like that analogy with language death. If you prefer biological analogies, it’s worth revisiting this fantastic post by Rachel back in August—before any of us knew about Microsoft’s decision—all about the ecological impact of browser diversity:\n\nLet me be clear: an Internet that runs only on Chrome’s engine, Blink, and its offspring, is not the paradise we like to imagine it to be.\n\nThat post is a great history lesson, documenting how things can change, and how decisions can have far-reaching unintended consequences.\n\nSo these are the three browser engines we have: WebKit/Blink, Gecko, and EdgeHTML. We are unlikely to get any brand new bloodlines in the foreseeable future. This is it.\n\nIf we lose one of those browser engines, we lose its lineage, every permutation of that engine that would follow, and the unique takes on the Web it could allow for.\n\nAnd it’s not likely to be replaced."
    }
}