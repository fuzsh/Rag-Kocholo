{
    "id": "dbpedia_3483_3",
    "rank": 79,
    "data": {
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html",
        "read_more_link": "",
        "language": "en",
        "title": "Query string query",
        "top_image": "https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt280217a63b82a734/6202d3378b1f312528798412/elastic-logo.svg",
        "meta_img": "https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt280217a63b82a734/6202d3378b1f312528798412/elastic-logo.svg",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/apple-icon-57x57.png",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Query string syntaxedit\n\nThe query string “mini-language” is used by the Query string and by the q query string parameter in the search API.\n\nThe query string is parsed into a series of terms and operators. A term can be a single word — quick or brown — or a phrase, surrounded by double quotes — \"quick brown\" — which searches for all the words in the phrase, in the same order.\n\nOperators allow you to customize the search — the available options are explained below.\n\nField namesedit\n\nYou can specify fields to search in the query syntax:\n\nwhere the status field contains active\n\nstatus:active\n\nwhere the title field contains quick or brown\n\ntitle:(quick OR brown)\n\nwhere the author field contains the exact phrase \"john smith\"\n\nauthor:\"John Smith\"\n\nwhere the first name field contains Alice (note how we need to escape the space with a backslash)\n\nfirst\\ name:Alice\n\nwhere any of the fields book.title, book.content or book.date contains quick or brown (note how we need to escape the * with a backslash):\n\nbook.\\*:(quick OR brown)\n\nwhere the field title has any non-null value:\n\n_exists_:title\n\nWildcard searches can be run on individual terms, using ? to replace a single character, and * to replace zero or more characters:\n\nqu?ck bro*\n\nBe aware that wildcard queries can use an enormous amount of memory and perform very badly — just think how many terms need to be queried to match the query string \"a* b* c*\".\n\nPure wildcards \\* are rewritten to exists queries for efficiency. As a consequence, the wildcard \"field:*\" would match documents with an empty value like the following:\n\n{ \"field\": \"\" }\n\n... and would not match if the field is missing or set with an explicit null value like the following:\n\n{ \"field\": null }\n\nAllowing a wildcard at the beginning of a word (eg \"*ing\") is particularly heavy, because all terms in the index need to be examined, just in case they match. Leading wildcards can be disabled by setting allow_leading_wildcard to false.\n\nOnly parts of the analysis chain that operate at the character level are applied. So for instance, if the analyzer performs both lowercasing and stemming, only the lowercasing will be applied: it would be wrong to perform stemming on a word that is missing some of its letters.\n\nBy setting analyze_wildcard to true, queries that end with a * will be analyzed and a boolean query will be built out of the different tokens, by ensuring exact matches on the first N-1 tokens, and prefix match on the last token.\n\nRegular expressionsedit\n\nRegular expression patterns can be embedded in the query string by wrapping them in forward-slashes (\"/\"):\n\nname:/joh?n(ath[oa]n)/\n\nThe supported regular expression syntax is explained in Regular expression syntax.\n\nThe allow_leading_wildcard parameter does not have any control over regular expressions. A query string such as the following would force Elasticsearch to visit every term in the index:\n\n/.*n/\n\nUse with caution!\n\nYou can run fuzzy queries using the ~ operator:\n\nquikc~ brwn~ foks~\n\nFor these queries, the query string is normalized. If present, only certain filters from the analyzer are applied. For a list of applicable filters, see Normalizers.\n\nThe query uses the Damerau-Levenshtein distance to find all terms with a maximum of two changes, where a change is the insertion, deletion or substitution of a single character, or transposition of two adjacent characters.\n\nThe default edit distance is 2, but an edit distance of 1 should be sufficient to catch 80% of all human misspellings. It can be specified as:\n\nquikc~1\n\nAvoid mixing fuzziness with wildcards\n\nMixing fuzzy and wildcard operators is not supported. When mixed, one of the operators is not applied. For example, you can search for app~1 (fuzzy) or app* (wildcard), but searches for app*~1 do not apply the fuzzy operator (~1).\n\nProximity searchesedit\n\nWhile a phrase query (eg \"john smith\") expects all of the terms in exactly the same order, a proximity query allows the specified words to be further apart or in a different order. In the same way that fuzzy queries can specify a maximum edit distance for characters in a word, a proximity search allows us to specify a maximum edit distance of words in a phrase:\n\n\"fox quick\"~5\n\nThe closer the text in a field is to the original order specified in the query string, the more relevant that document is considered to be. When compared to the above example query, the phrase \"quick fox\" would be considered more relevant than \"quick brown fox\".\n\nRanges can be specified for date, numeric or string fields. Inclusive ranges are specified with square brackets [min TO max] and exclusive ranges with curly brackets {min TO max}.\n\nAll days in 2012:\n\ndate:[2012-01-01 TO 2012-12-31]\n\nNumbers 1..5\n\ncount:[1 TO 5]\n\nTags between alpha and omega, excluding alpha and omega:\n\ntag:{alpha TO omega}\n\nNumbers from 10 upwards\n\ncount:[10 TO *]\n\nDates before 2012\n\ndate:{* TO 2012-01-01}\n\nCurly and square brackets can be combined:\n\nNumbers from 1 up to but not including 5\n\ncount:[1 TO 5}\n\nRanges with one side unbounded can use the following syntax:\n\nage:>10 age:>=10 age:<10 age:<=10\n\nTo combine an upper and lower bound with the simplified syntax, you would need to join two clauses with an AND operator:\n\nage:(>=10 AND <20) age:(+>=10 +<20)\n\nThe parsing of ranges in query strings can be complex and error prone. It is much more reliable to use an explicit range query.\n\nUse the boost operator ^ to make one term more relevant than another. For instance, if we want to find all documents about foxes, but we are especially interested in quick foxes:\n\nquick^2 fox\n\nThe default boost value is 1, but can be any positive floating point number. Boosts between 0 and 1 reduce relevance.\n\nBoosts can also be applied to phrases or to groups:\n\n\"john smith\"^2 (foo bar)^4\n\nBoolean operatorsedit\n\nBy default, all terms are optional, as long as one term matches. A search for foo bar baz will find any document that contains one or more of foo or bar or baz. We have already discussed the default_operator above which allows you to force all terms to be required, but there are also boolean operators which can be used in the query string itself to provide more control.\n\nThe preferred operators are + (this term must be present) and - (this term must not be present). All other terms are optional. For example, this query:\n\nquick brown +fox -news\n\nstates that:\n\nfox must be present\n\nnews must not be present\n\nquick and brown are optional — their presence increases the relevance\n\nThe familiar boolean operators AND, OR and NOT (also written &&, || and !) are also supported but beware that they do not honor the usual precedence rules, so parentheses should be used whenever multiple operators are used together. For instance the previous query could be rewritten as:\n\n((quick AND fox) OR (brown AND fox) OR fox) AND NOT news\n\nThis form now replicates the logic from the original query correctly, but the relevance scoring bears little resemblance to the original.\n\nIn contrast, the same query rewritten using the match query would look like this:\n\n{ \"bool\": { \"must\": { \"match\": \"fox\" }, \"should\": { \"match\": \"quick brown\" }, \"must_not\": { \"match\": \"news\" } } }\n\nMultiple terms or clauses can be grouped together with parentheses, to form sub-queries:\n\n(quick OR brown) AND fox\n\nGroups can be used to target a particular field, or to boost the result of a sub-query:\n\nstatus:(active OR pending) title:(full text search)^2\n\nReserved charactersedit\n\nIf you need to use any of the characters which function as operators in your query itself (and not as operators), then you should escape them with a leading backslash. For instance, to search for (1+1)=2, you would need to write your query as \\(1\\+1\\)\\=2. When using JSON for the request body, two preceding backslashes (\\\\) are required; the backslash is a reserved escaping character in JSON strings.\n\nresponse = client.search( index: 'my-index-000001', body: { query: { query_string: { query: 'kimchy\\\\!', fields: [ 'user.id' ] } } } ) puts response\n\nconst response = await client.search({ index: \"my-index-000001\", query: { query_string: { query: \"kimchy\\\\!\", fields: [\"user.id\"], }, }, }); console.log(response);\n\nGET /my-index-000001/_search { \"query\" : { \"query_string\" : { \"query\" : \"kimchy\\\\!\", \"fields\" : [\"user.id\"] } } }\n\nThe reserved characters are: + - = && || > < ! ( ) { } [ ] ^ \" ~ * ? : \\ /\n\nFailing to escape these special characters correctly could lead to a syntax error which prevents your query from running.\n\n< and > can’t be escaped at all. The only way to prevent them from attempting to create a range query is to remove them from the query string entirely.\n\nWhitespaces and empty queriesedit\n\nWhitespace is not considered an operator.\n\nIf the query string is empty or only contains whitespaces the query will yield an empty result set.\n\nAvoid using the query_string query for nested documentsedit\n\nquery_string searches do not return nested documents. To search nested documents, use the nested query.\n\nSearch multiple fieldsedit\n\nYou can use the fields parameter to perform a query_string search across multiple fields.\n\nThe idea of running the query_string query against multiple fields is to expand each query term to an OR clause like this:\n\nfield1:query_term OR field2:query_term | ...\n\nFor example, the following query\n\nresp = client.search( body={ \"query\": { \"query_string\": { \"fields\": [\"content\", \"name\"], \"query\": \"this AND that\", } } }, ) print(resp)\n\nresponse = client.search( body: { query: { query_string: { fields: [ 'content', 'name' ], query: 'this AND that' } } } ) puts response\n\nres, err := es.Search( es.Search.WithBody(strings.NewReader(`{ \"query\": { \"query_string\": { \"fields\": [ \"content\", \"name\" ], \"query\": \"this AND that\" } } }`)), es.Search.WithPretty(), ) fmt.Println(res, err)\n\nconst response = await client.search({ query: { query_string: { fields: [\"content\", \"name\"], query: \"this AND that\", }, }, }); console.log(response);\n\nGET /_search { \"query\": { \"query_string\": { \"fields\": [ \"content\", \"name\" ], \"query\": \"this AND that\" } } }\n\nmatches the same words as\n\nresp = client.search( body={ \"query\": { \"query_string\": { \"query\": \"(content:this OR name:this) AND (content:that OR name:that)\" } } }, ) print(resp)\n\nresponse = client.search( body: { query: { query_string: { query: '(content:this OR name:this) AND (content:that OR name:that)' } } } ) puts response\n\nres, err := es.Search( es.Search.WithBody(strings.NewReader(`{ \"query\": { \"query_string\": { \"query\": \"(content:this OR name:this) AND (content:that OR name:that)\" } } }`)), es.Search.WithPretty(), ) fmt.Println(res, err)\n\nconst response = await client.search({ query: { query_string: { query: \"(content:this OR name:this) AND (content:that OR name:that)\", }, }, }); console.log(response);\n\nGET /_search { \"query\": { \"query_string\": { \"query\": \"(content:this OR name:this) AND (content:that OR name:that)\" } } }\n\nSince several queries are generated from the individual search terms, combining them is automatically done using a dis_max query with a tie_breaker. For example (the name is boosted by 5 using ^5 notation):\n\nresp = client.search( body={ \"query\": { \"query_string\": { \"fields\": [\"content\", \"name^5\"], \"query\": \"this AND that OR thus\", \"tie_breaker\": 0, } } }, ) print(resp)\n\nresponse = client.search( body: { query: { query_string: { fields: [ 'content', 'name^5' ], query: 'this AND that OR thus', tie_breaker: 0 } } } ) puts response\n\nres, err := es.Search( es.Search.WithBody(strings.NewReader(`{ \"query\": { \"query_string\": { \"fields\": [ \"content\", \"name^5\" ], \"query\": \"this AND that OR thus\", \"tie_breaker\": 0 } } }`)), es.Search.WithPretty(), ) fmt.Println(res, err)\n\nconst response = await client.search({ query: { query_string: { fields: [\"content\", \"name^5\"], query: \"this AND that OR thus\", tie_breaker: 0, }, }, }); console.log(response);\n\nGET /_search { \"query\": { \"query_string\" : { \"fields\" : [\"content\", \"name^5\"], \"query\" : \"this AND that OR thus\", \"tie_breaker\" : 0 } } }\n\nSimple wildcard can also be used to search \"within\" specific inner elements of the document. For example, if we have a city object with several fields (or inner object with fields) in it, we can automatically search on all \"city\" fields:\n\nresp = client.search( body={ \"query\": { \"query_string\": { \"fields\": [\"city.*\"], \"query\": \"this AND that OR thus\", } } }, ) print(resp)\n\nresponse = client.search( body: { query: { query_string: { fields: [ 'city.*' ], query: 'this AND that OR thus' } } } ) puts response\n\nres, err := es.Search( es.Search.WithBody(strings.NewReader(`{ \"query\": { \"query_string\": { \"fields\": [ \"city.*\" ], \"query\": \"this AND that OR thus\" } } }`)), es.Search.WithPretty(), ) fmt.Println(res, err)\n\nconst response = await client.search({ query: { query_string: { fields: [\"city.*\"], query: \"this AND that OR thus\", }, }, }); console.log(response);\n\nGET /_search { \"query\": { \"query_string\" : { \"fields\" : [\"city.*\"], \"query\" : \"this AND that OR thus\" } } }\n\nAnother option is to provide the wildcard fields search in the query string itself (properly escaping the * sign), for example: city.\\*:something:\n\nresp = client.search( body={ \"query\": { \"query_string\": {\"query\": \"city.\\\\*:(this AND that OR thus)\"} } }, ) print(resp)\n\nresponse = client.search( body: { query: { query_string: { query: 'city.\\\\*:(this AND that OR thus)' } } } ) puts response\n\nres, err := es.Search( es.Search.WithBody(strings.NewReader(`{ \"query\": { \"query_string\": { \"query\": \"city.\\\\*:(this AND that OR thus)\" } } }`)), es.Search.WithPretty(), ) fmt.Println(res, err)\n\nconst response = await client.search({ query: { query_string: { query: \"city.\\\\*:(this AND that OR thus)\", }, }, }); console.log(response);\n\nGET /_search { \"query\": { \"query_string\" : { \"query\" : \"city.\\\\*:(this AND that OR thus)\" } } }\n\nSince \\ (backslash) is a special character in json strings, it needs to be escaped, hence the two backslashes in the above query_string.\n\nThe fields parameter can also include pattern based field names, allowing to automatically expand to the relevant fields (dynamically introduced fields included). For example:\n\nresp = client.search( body={ \"query\": { \"query_string\": { \"fields\": [\"content\", \"name.*^5\"], \"query\": \"this AND that OR thus\", } } }, ) print(resp)\n\nresponse = client.search( body: { query: { query_string: { fields: [ 'content', 'name.*^5' ], query: 'this AND that OR thus' } } } ) puts response\n\nres, err := es.Search( es.Search.WithBody(strings.NewReader(`{ \"query\": { \"query_string\": { \"fields\": [ \"content\", \"name.*^5\" ], \"query\": \"this AND that OR thus\" } } }`)), es.Search.WithPretty(), ) fmt.Println(res, err)\n\nconst response = await client.search({ query: { query_string: { fields: [\"content\", \"name.*^5\"], query: \"this AND that OR thus\", }, }, }); console.log(response);\n\nGET /_search { \"query\": { \"query_string\" : { \"fields\" : [\"content\", \"name.*^5\"], \"query\" : \"this AND that OR thus\" } } }\n\nAdditional parameters for multiple field searchesedit\n\nWhen running the query_string query against multiple fields, the following additional parameters are supported.\n\ntype\n\n(Optional, string) Determines how the query matches and scores documents. Valid values are:\n\nbest_fields (Default)\n\nFinds documents which match any field and uses the highest _score from any matching field. See best_fields.\n\nbool_prefix\n\nCreates a match_bool_prefix query on each field and combines the _score from each field. See bool_prefix.\n\ncross_fields\n\nTreats fields with the same analyzer as though they were one big field. Looks for each word in any field. See cross_fields.\n\nmost_fields\n\nFinds documents which match any field and combines the _score from each field. See most_fields.\n\nphrase\n\nRuns a match_phrase query on each field and uses the _score from the best field. See phrase and phrase_prefix.\n\nphrase_prefix\n\nRuns a match_phrase_prefix query on each field and uses the _score from the best field. See phrase and phrase_prefix.\n\nNOTE: Additional top-level multi_match parameters may be available based on the type value.\n\nHow minimum_should_match works for multiple fieldsedit\n\nresp = client.search( body={ \"query\": { \"query_string\": { \"fields\": [\"title\", \"content\"], \"query\": \"this that thus\", \"minimum_should_match\": 2, } } }, ) print(resp)\n\nresponse = client.search( body: { query: { query_string: { fields: [ 'title', 'content' ], query: 'this that thus', minimum_should_match: 2 } } } ) puts response\n\nres, err := es.Search( es.Search.WithBody(strings.NewReader(`{ \"query\": { \"query_string\": { \"fields\": [ \"title\", \"content\" ], \"query\": \"this that thus\", \"minimum_should_match\": 2 } } }`)), es.Search.WithPretty(), ) fmt.Println(res, err)\n\nconst response = await client.search({ query: { query_string: { fields: [\"title\", \"content\"], query: \"this that thus\", minimum_should_match: 2, }, }, }); console.log(response);\n\nGET /_search { \"query\": { \"query_string\": { \"fields\": [ \"title\", \"content\" ], \"query\": \"this that thus\", \"minimum_should_match\": 2 } } }\n\nThe example above creates a boolean query:\n\n((content:this content:that content:thus) | (title:this title:that title:thus))\n\nthat matches documents with the disjunction max over the fields title and content. Here the minimum_should_match parameter can’t be applied.\n\nresp = client.search( body={ \"query\": { \"query_string\": { \"fields\": [\"title\", \"content\"], \"query\": \"this OR that OR thus\", \"minimum_should_match\": 2, } } }, ) print(resp)\n\nresponse = client.search( body: { query: { query_string: { fields: [ 'title', 'content' ], query: 'this OR that OR thus', minimum_should_match: 2 } } } ) puts response\n\nres, err := es.Search( es.Search.WithBody(strings.NewReader(`{ \"query\": { \"query_string\": { \"fields\": [ \"title\", \"content\" ], \"query\": \"this OR that OR thus\", \"minimum_should_match\": 2 } } }`)), es.Search.WithPretty(), ) fmt.Println(res, err)\n\nAdding explicit operators forces each term to be considered as a separate clause.\n\nThe example above creates a boolean query:\n\n((content:this | title:this) (content:that | title:that) (content:thus | title:thus))~2\n\nthat matches documents with at least two of the three \"should\" clauses, each of them made of the disjunction max over the fields for each term."
    }
}