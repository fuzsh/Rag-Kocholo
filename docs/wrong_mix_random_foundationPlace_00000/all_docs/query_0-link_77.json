{
    "id": "wrong_mix_random_foundationPlace_00000_0",
    "rank": 77,
    "data": {
        "url": "https://www.slideshare.net/slideshow/statistical-methods-for-integration-and-analysis-of-online-opinionated-text-data/43837831",
        "read_more_link": "",
        "language": "en",
        "title": "Statistical Methods for Integration and Analysis of Online Opinionated Text Data",
        "top_image": "https://cdn.slidesharecdn.com/ss_thumbnails/opinion-analysis-150123152122-conversion-gate02-thumbnail.jpg?width=640&height=640&fit=bounds",
        "meta_img": "https://cdn.slidesharecdn.com/ss_thumbnails/opinion-analysis-150123152122-conversion-gate02-thumbnail.jpg?width=640&height=640&fit=bounds",
        "images": [
            "https://public.slidesharecdn.com/images/next/logo-slideshare-scribd-company.svg?w=128&q=75 1x, https://public.slidesharecdn.com/images/next/logo-slideshare-scribd-company.svg?w=256&q=75 2x",
            "https://cdn.slidesharecdn.com/profile-photo-KavitaGanesan1-48x48.jpg?cb=1523558206",
            "https://image.slidesharecdn.com/opinion-analysis-150123152122-conversion-gate02/85/Statistical-Methods-for-Integration-and-Analysis-of-Online-Opinionated-Text-Data-1-320.jpg 320w, https://image.slidesharecdn.com/opinion-analysis-150123152122-conversion-gate02/85/Statistical-Methods-for-Integration-and-Analysis-of-Online-Opinionated-Text-Data-1-638.jpg 638w, https://image.slidesharecdn.com/opinion-analysis-150123152122-conversion-gate02/75/Statistical-Methods-for-Integration-and-Analysis-of-Online-Opinionated-Text-Data-1-2048.jpg 2048w"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2015-01-23T15:21:22+00:00",
        "summary": "",
        "meta_description": "Statistical Methods for \u000bIntegration and Analysis of \u000bOnline Opinionated Text Data   - Download as a PDF or view online for free",
        "meta_lang": "en",
        "meta_favicon": "https://public.slidesharecdn.com/_next/static/media/favicon.7bc3d920.ico",
        "meta_site_name": "SlideShare",
        "canonical_link": "https://www.slideshare.net/slideshow/statistical-methods-for-integration-and-analysis-of-online-opinionated-text-data/43837831",
        "text": "1. Statistical Methods for Integration and Analysis of Online Opinionated Text Data ChengXiang (“Cheng”) Zhai Department of Computer Science University of Illinois at Urbana-Champaign http://www.cs.uiuc.edu/homes/czhai 1 Joint work with Yue Lu, Qiaozhu Mei, Kavita Ganesan, Hongning Wang, and others\n\n2. Online opinions cover all kinds of topics 65M msgs/day Topics: People Events Products Services, … Sources: Blogs Microblogs Forums Reviews ,… 53M blogs 1307M posts 115M users 10M groups 45M reviews … … 2\n\n3. Great opportunities for many applications “Which cell phone should I buy?” “What are the winning features of iPhone over blackberry?” “How do people like this new drug?” “How is Obama’s health care policy received?” “Which presidential candidate should I vote for?” … Opinionated Text Data Decision Making & Analytics 3\n\n4. How can I digest them all? How can I digest them all? However, it’s not easy to for users to make use of the online opinions How can I collect all opinions? How can I collect all opinions? How can I …?How can I …? How can I …?How can I …? 4\n\n5. Research Questions • How can we integrate scattered opinions? • How can we summarize opinionated text articles? • How can we analyze online opinions to discover patterns and understand consumer preferences? • How can we do all these in a general way with no or minimum human effort? – Must work for all topics – Must work for different natural languages 5 Solutions: Statistical Methods for Text Data Mining (Statistical Language Models)\n\n6. Rest of the talk: general methods for 1. Opinion Integration 2. Opinion Summarization 3. Opinion Analysis 6\n\n7. Outline 1. Opinion Integration 2. Opinion Summarization 3. Opinion Analysis 7\n\n8. How to digest all scattered opinions? 190,451 posts 4,773,658 results Need tools to automatically integrate all scattered opinions 8\n\n9. 4,773,658 results Observation: two kinds of opinions Expert opinions •CNET editor’s review •Wikipedia article •Well-structured •Easy to access •Maybe biased •Outdated soon 190,451 posts Ordinary opinions •Forum discussions •Blog articles •Represent the majority •Up to date •Hard to access •fragmented Can we combine them? 9\n\n10. Opinion Integration Strategy 1 [Lu & Zhai WWW 08] Align scattered opinions with well-structured expert reviews Yue Lu, ChengXiang Zhai. Opinion Integration Through Semi-supervised Topic Modeling, Proceedings of the World Wide Conference 2008 ( WWW'08), pages 121-130. 10\n\n11. 11 Review-Based Opinion Integration cute… tiny… ..thicker.. last many hrs die out soon could afford it still expensive DesignB atteryPr ice.. DesignB atteryPr ice.. Topic: iPod Expert review with aspects Text collection of ordinary opinions, e.g. Weblogs Integrated Summary Design Battery Price Design Battery Price iTunes … easy to use… warranty …better to extend.. ReviewAspectsExtraAspec Similar opinions Supplementary opinions Input Output\n\n12. Solution is based on probabilistic latent semantic analyis (PLSA) [Hofmann 99] 1 - λB w Topics Collection background λB B Document Is 0.05 the 0.04 a 0.03 .. … θ1 θ2 θk πd1 πd2 πdk battery 0.3 life 0.2.. design 0.1 screen 0.05 price 0.2 purchase 0.15 Generate a word in a document Generate a word in a document Topic model = unigram language model = multinomial distribution 12\n\n13. Basic PLSA: Estimation • Parameters estimated with Maximum Likelihood Estimator (MLE) through an EM algorithm Generate a word in a document Generate a word in a document Log-likelihood of the collection Log-likelihood of the collection Count of word in the document 13\n\n14. Semi-supervised Probabilistic Latent Semantic Analysis Maximum A Posterior (MAP) Estimation Maximum A Posterior (MAP) Estimation Maximum Likelihood Estimation (MLE) Maximum Likelihood Estimation (MLE) Cast review aspects as conjugate Dirichlet priors Cast review aspects as conjugate Dirichlet priors 1 - λB w Topics Collection background λB BIs 0.05 the 0.04 a 0.03 .. … θ1 θ2 θk πd1 πd2 πdk Document battery life design screen r1 r2 14\n\n15. Results: Product (iPhone) • Opinion Integration with review aspects Review article Similar opinions Supplementary opinions You can make emergency calls, but you can't use any other functions… N/A … methods for unlocking the iPhone have emerged on the Internet in the past few weeks, although they involve tinkering with the iPhone hardware… rated battery life of 8 hours talk time, 24 hours of music playback, 7 hours of video playback, and 6 hours on Internet use. iPhone will Feature Up to 8 Hours of Talk Time, 6 Hours of Internet Use, 7 Hours of Video Playback or 24 Hours of Audio Playback Playing relatively high bitrate VGA H.264 videos, our iPhone lasted almost exactly 9 freaking hours of continuous playback with cell and WiFi on (but Bluetooth off). Unlock/hack iPhone Activation Battery Confirm the opinions from the review Additional info under real usage 15\n\n16. Results: Product (iPhone) • Opinions on extra aspects support Supplementary opinions on extra aspects 15 You may have heard of iASign … an iPhone Dev Wiki tool that allows you to activate your phone without going through the iTunes rigamarole. 13 Cisco has owned the trademark on the name \"iPhone\" since 2000, when it acquired InfoGear Technology Corp., which originally registered the name. 13 With the imminent availability of Apple's uber cool iPhone, a look at 10 things current smartphones like the Nokia N95 have been able to do for a while and that the iPhone can't currently match... Another way to activate iPhone iPhone trademark originally owned by Cisco A better choice for smart phones? 16\n\n17. As a result of integration… What matters most to people? Price Bluetooth & Wireless Activation 17\n\n18. 4,773,658 results What if we don’t have expert reviews? Expert opinions •CNET editor’s review •Wikipedia article •Well-structured •Easy to access •Maybe biased •Outdated soon 190,451 posts Ordinary opinions •Forum discussions •Blog articles •Represent the majority •Up to date •Hard to access •fragmented How can we organize scattered opinions? Exploit online ontology! 18\n\n19. Opinion Integration Strategy 2 [Lu et al. COLING 10] Organize scattered opinions using an ontology Yue Lu, Huizhong Duan, Hongning Wang and ChengXiang Zhai. Exploiting Structured Ontology to Organize Scattered Online Opinions, Proceedings of COLING 2010 (COLING 10), pages 734-742. 19\n\n21. Ontology-Based Opinion Integration Topic = “Abraham Lincoln” (Exists in ontology) Aspects from Ontology (more than 50) Online Opinion Sentences ProfessionsProfessions QuotationsQuotations ParentsParents … … Date of BirthDate of Birth Place of DeathPlace of Death ProfessionsProfessions QuotationsQuotations Subset of Aspects Matching Opinions Ordered to optimize readability Two key tasks: 1. Aspect Selection. 2. Aspect Ordering 21\n\n22. 1. Aspect Selection: Conditional Entropy-based Method ProfessionsProfessions … … Collection: K-means Clustering C1 C2 C3 … … … ParentsParents PositionPosition … … Clusters: C Aspect Subset: A A = argmin H(C|A) p(Ai,Ci) = argmin - ∑i p(Ai,Ci) log ---------- p(Ai) A1 A2 A3 22\n\n23. 2. Aspect Ordering: Coherence Order Original Articles Date of BirthDate of Birth Place of DeathPlace of DeathA1 A2 Coherence(A1, A2)  #( is before ) Coherence(A2, A1)  #( is before ) … So, Coherence(A2, A1) > Coherence (A1, A2) Π(A) = argmax ∑ Ai before Aj Coherence(Ai, Aj) 23\n\n24. Sample Results:Sony Cybershot DSC-W200 Freebase Aspects sup Representative Opinion Sentences Format: Compact 13 Quality pictures in a compact package. …amazing is that this is such a small and compact unit but packs so much power Supported Storage Types: Memory Stick Duo 11 This camera can use Memory Stick Pro Duo up to 8 GB Using a universal storage card and cable (c’mon Sony) Sensor type: CCD 10 I think the larger ccd makes a difference. but remember this is a small CCD in a compact point-and- shoot. Digital zoom: 2X 47 once the digital :smart” zoom kicks in you get another 3x of zoom. I would like a higher optical zoom, the W200 does a great digital zoom translation... 24\n\n25. More opinion integration results are available at: http://sifaka.cs.uiuc.edu/~yuelu2/opinionintegration/ 25\n\n26. Outline 1. Opinion Integration 2. Opinion Summarization 3. Opinion Analysis 26\n\n27. Need for opinion summarization 1,432 customer reviews How can we help users digest these opinions? How can we help users digest these opinions? 27\n\n28. Nice to have…. Can we do this in a general way? 28\n\n29. Opinion Summarization 1: [Mei et al. WWW 07] Multi-Aspect Topic Sentiment Summarization Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, ChengXiang Zhai, Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs, Proceedings of the World Wide Conference 2007 ( WWW'07), pages 171-180 29\n\n30. A Topic-Sentiment Mixture Model θk θ1 θ2 B Facet θ1 Facet θk Facet θ2 … Background B Choose a facet (subtopic) θi battery 0.3 life 0.2.. nano 0.1 release 0.05 screen 0.02 .. apple 0.2 microsoft 0.1 compete 0.05 .. Is 0.05 the 0.04 a 0.03 .. … love 0.2 awesome 0.05 good 0.01 .. suck 0.07 hate 0.06 stupid 0.02 .. P N P F N P F N P F N battery love hate the Draw a word from the mixture of topics and sentiments ( )F P N 30\n\n31. ))]|()|()|(( )1()|(log[),()(log ,,,,,, 1 NNdjPPdjjFdj Cd Vw k j djBB wpwpwp BwpdwcCp θδθδθδ πλλ ++× −+= ∑∑ ∑∈ ∈ = Count of word w in document d The Likelihood Function Generating w using the background model Choosing a faceted opinion Generating w using the neutral topic model Generating w using the positive sentiment model Generating w using the negative sentiment model 31\n\n32. Two Modes for Parameter Estimation • Training Mode: Learn the sentiment model • Testing Mode: Extract the Topic models ))]|()|()|(( )1()|(log[),()log( ,,,,,, 1 NNdjPPdjjFdj Cd Vw k j djBB wpwpwp BwpdwcC θδθδθδ πλλ ++× −+= ∑∑ ∑∈ ∈ = ))]|()|()|(( )1()|(log[),()log( ,,,,,, 1 NNdjPPdjjFdj Cd Vw k j djBB wpwpwp BwpdwcC θδθδθδ πλλ ++× −+= ∑∑ ∑∈ ∈ = Fixed for each d Feed strong prior on sentiment models One of them is zero for d EM algorithm can be used for estimation 32\n\n33. 33 Results: General Sentiment Models • Sentiment models trained from diversified topic mixture v.s. single topics Pos-Mix Neg-Mix Pos-Cities Neg-Cities love suck beautiful hate awesome hate love suck good stupid awesome people miss ass amaze traffic amaze fuck live drive pretty horrible good fuck job shitty night stink god crappy nice move yeah terrible time weather bless people air city excellent evil greatest transport More diversified topics More general sentiment model\n\n34. 34 Multi-Faceted Sentiment Summary (query=“Da Vinci Code”) Neutral Positive Negative Facet 1: Movie ... Ron Howards selection of Tom Hanks to play Robert Langdon. Tom Hanks stars in the movie,who can be mad at that? But the movie might get delayed, and even killed off if he loses. Directed by: Ron Howard Writing credits: Akiva Goldsman ... Tom Hanks, who is my favorite movie star act the leading role. protesting ... will lose your faith by ... watching the movie. After watching the movie I went online and some research on ... Anybody is interested in it? ... so sick of people making such a big deal about a FICTION book and movie. Facet 2: Book I remembered when i first read the book, I finished the book in two days. Awesome book. ... so sick of people making such a big deal about a FICTION book and movie. I’m reading “Da Vinci Code” now. … So still a good book to past time. This controversy book cause lots conflict in west society.\n\n35. Separate Theme Sentiment Dynamics “book” “religious beliefs” 35\n\n36. 36 Can we make the summary more concise? Neutral Positive Negative Facet 1: Movie ... Ron Howards selection of Tom Hanks to play Robert Langdon. Tom Hanks stars in the movie,who can be mad at that? But the movie might get delayed, and even killed off if he loses. Directed by: Ron Howard Writing credits: Akiva Goldsman ... Tom Hanks, who is my favorite movie star act the leading role. protesting ... will lose your faith by ... watching the movie. After watching the movie I went online and some research on ... Anybody is interested in it? ... so sick of people making such a big deal about a FICTION book and movie. Facet 2: Book I remembered when i first read the book, I finished the book in two days. Awesome book. ... so sick of people making such a big deal about a FICTION book and movie. I’m reading “Da Vinci Code” now. … So still a good book to past time. This controversy book cause lots conflict in west society. What if the user is using a smart phone?\n\n37. Opinion Summarization 2: [Ganesan et al. WWW 12] “Micro” Opinion Summarization Kavita Ganesan, Chengxiang Zhai and Evelyne Viegas, Micropinion Generation: An Unsupervised Approach to Generating Ultra-Concise Summaries of Opinions, Proceedings of the World Wide Conference 2012 ( WWW'12), pages 869-878, 2012. 37\n\n38. Micro Opinion Summarization “Good service” “Delicious soup dishes” “Good service” “Delicious soup dishes” “Room is large” “Room is clean” “large clean room” 38\n\n39. A general unsupervised approach • Main idea: – use existing words in original text to compose meaningful summaries – leverage Web-scale n-gram language model to assess meaningfulness • Emphasis on 3 desirable properties of a summary: – Compactness • summaries should use as few words as possible – Representativeness • summaries should reflect major opinions in text – Readability • summaries should be fairly well formed 39\n\n40. Optimization Framework to capture compactness, representativeness & readability { } [ ]kmmsim )(mS )(mS m )(mS)(mSM jisimji readiread repirep ss k i i k i ireadirep...mkm ,1( subject to maxarg ,), 1 1 1 ∈∀≤ ≥ ≥ ≤ += ∑ ∑ = = σ σ σ σ 2.3 very clean rooms 2.1 friendly service 1.8 dirty lobby and pool 1.3 nice and polite staff 2.3 very clean rooms 2.1 friendly service 1.8 dirty lobby and pool 1.3 nice and polite staff Micropinion Summary, M Size of summary Redundancy Minimum rep. & readability 40\n\n41. Representativeness scoring: Srep(mi) • 2 properties of a highly representative phrase: – Words should be strongly associated in text – Words should be sufficiently frequent in text • Captured by modified pointwise mutual information )()( ),(),( log)(' 2, ji jiji ji wpwp wwcwwp wwpmi × × = Add frequency of occurrence within a window ]),(' 2 1 [)( ∑ + −= = Ci Cij jiilocal wwpmi C wpmi ∑= = n i ilocalnrep wpmi n )w(wS 1 ..1 )( 1 41\n\n42. Readability scoring, Sread(mi) • Phrases are constructed from seed words, thus we can have new phrases not in original text • Readability scoring based on N-gram language model (normalized probabilities of phrases) – Intuition: A phrase is more readable if it occurs more frequently on the web )|(log 1 )( 1...12... −+− = ∏= kqk n qk knkread wwwp K wwS “battery life sucks” -2.93“battery life sucks” -2.93“sucks life battery” -4.51“sucks life battery” -4.51 “life battery is poor” -3.66“life battery is poor” -3.66 “battery life is poor” -2.37“battery life is poor” -2.37 Ungrammatical Grammatical 42\n\n43. Overview of summarization algorithm Text to be summarized …. very nice place clean problem dirty room … …. very nice place clean problem dirty room … Step 1: Shortlist high freq unigrams (count > median) Unigrams Step 2: Form seed bigrams by pairing unigrams. Shortlist by Srep. (Srep > σrep) very + nice very + clean very + dirty clean + place clean + room dirty + place … very + nice very + clean very + dirty clean + place clean + room dirty + place … Srep > σrep Seed BigramsInput 43\n\n44. Overview of summarization algorithm Step 3: Generate higher order n-grams. • Concatenate existing candidates + seed bigrams • Prune non-promising candidates (Srep & Sread) • Eliminate redundancies (sim(mi,mj)) • Repeat process on shortlisted candidates (until no possbility of expansion) Higher order n-grams very clean very dirty very nice Candidates Seed Bi-grams+ + + + clean rooms clean bed dirty room dirty pool nice place nice room Step 4: Final summary. Sort by objective function value. Add phrases until |M|< σss 0.9 very clean rooms 0.8 friendly service 0.7 dirty lobby and pool 0.5 nice and polite staff ….. ….. 0.9 very clean rooms 0.8 friendly service 0.7 dirty lobby and pool 0.5 nice and polite staff ….. ….. Sorted Candidates Summary = = = very clean rooms very clean bed very dirty room very dirty pool very nice place very nice room = New Candidates Srep<σrep ; Sread<σread 44\n\n45. Performance comparisons (reviews of 330 products) Proposed method works the best 45\n\n46. The program can generate meaningful novel phrases Example: “wide screen lcd monitor is bright” readability : -1.88 representativeness: 4.25 “wide screen lcd monitor is bright” readability : -1.88 representativeness: 4.25 Unseen N-Gram (Acer AL2216 Monitor) “…plus the monitor is very bright…” “…it is a wide screen, great color, great quality…” “…this lcd monitor is quite bright and clear…” “…plus the monitor is very bright…” “…it is a wide screen, great color, great quality…” “…this lcd monitor is quite bright and clear…” Related snippets in original text 46\n\n47. A Sample Summary Canon Powershot SX120 IS Easy to use Good picture quality Crisp and clear Good video quality Easy to use Good picture quality Crisp and clear Good video quality E-reader/ Tablet Smart Phones Cell Phones Useful for pushing opinions to devices where the screen is small Useful for pushing opinions to devices where the screen is small 47\n\n48. Outline 1. Opinion Integration 2. Opinion Summarization 3. Opinion Analysis 48\n\n49. Motivation How to infer aspect ratings? Value Location Service … How to infer aspect weights? Value Location Service …\n\n50. Opinion Analysis: [Wang et al. KDD 2010] & [Wang et al. KDD 2011] Latent Aspect Rating Analysis Hongning Wang, Yue Lu, ChengXiang Zhai. Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach, Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'10), pages 115-124, 2010. Hongning Wang, Yue Lu, ChengXiang Zhai, Latent Aspect Rating Analysis without Aspect Keyword Supervision, Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'11), 2011, pages 618-626. 50\n\n51. Latent Aspect Rating Analysis • Given a set of review articles about a topic with overall ratings • Output – Major aspects commented on in the reviews – Ratings on each aspect – Relative weights placed on different aspects by reviewers • Many applications – Opinion-based entity ranking – Aspect-level opinion summarization – Reviewer preference analysis – Personalized recommendation of products – …\n\n52. Solving LARA in two stages: Aspect Segmentation + Rating Regression Reviews + overall ratings Aspect segments location:1 amazing:1 walk:1 anywhere:1 0.1 1.7 0.1 3.9 nice:1 accommodating:1 smile:1 friendliness:1 attentiveness:1 Term Weights Aspect Rating 0.0 2.9 0.1 0.9 room:1 nicely:1 appointed:1 comfortable:1 2.1 1.2 1.7 2.2 0.6 Aspect Segmentation Latent Rating Regression 3.9 4.8 5.8 Aspect Weight 0.2 0.2 0.6 Observed + Latent!\n\n53. Latent Rating Regression Aspect segments location:1 amazing:1 walk:1 anywhere:1 0.1 0.7 0.1 0.9 nice:1 accommodating:1 smile:1 friendliness:1 attentiveness:1 Term Weights Aspect Rating 0.0 0.9 0.1 0.3 room:1 nicely:1 appointed:1 comfortable:1 0.6 0.8 0.7 0.8 0.9 1.3 1.8 3.8 Aspect Weight 0.2 0.2 0.6 Conditional likelihood\n\n54. Excellent location in walking distance to Tiananmen Square and shopping streets. That’s the best part of this hotel! The rooms are getting really old. Bathroom was nasty. The fixtures were falling off, lots of cracks and everything looked dirty. I don’t think it worth the price.Service was the most disappointing part, especially the door men. this is not how you treat guests, this is not hospitality. A Unified Generative Model for LARA Aspects location amazing walk anywhere terrible front-desk smile unhelpful room dirty appointed smelly Location Room Service Aspect Rating Aspect Weight 0.86 0.04 0.10 Entity Review\n\n55. Latent Aspect Rating Analysis Model • Unified framework Excellent location in walking distance to Tiananmen Square and shopping streets. That’s the best part of this hotel! The rooms are getting really old. Bathroom was nasty. The fixtures were falling off, lots of cracks and everything looked dirty. I don’t think it worth the price.Service was the most disappointing part, especially the door men. this is not how you treat guests, this is not hospitality. Rating prediction module Aspect modeling module\n\n56. Hotel Value Room Location Cleanliness Grand Mirage Resort 4.2(4.7) 3.8(3.1) 4.0(4.2) 4.1(4.2) Gold Coast Hotel 4.3(4.0) 3.9(3.3) 3.7(3.1) 4.2(4.7) Eurostars Grand Marina Hotel 3.7(3.8) 4.4(3.8) 4.1(4.9) 4.5(4.8) Sample Result 1: Rating Decomposition • Hotels with the same overall rating but different aspect ratings • Reveal detailed opinions at the aspect level (All 5 Stars hotels, ground-truth in parenthesis.)\n\n57. Sample Result 2: Comparison of reviewers • Reviewer-level Hotel Analysis – Different reviewers’ ratings on the same hotel – Reveal differences in opinions of different reviewers Reviewer Value Room Location Cleanliness Mr.Saturday 3.7(4.0) 3.5(4.0) 3.7(4.0) 5.8(5.0) Salsrug 5.0(5.0) 3.0(3.0) 5.0(4.0) 3.5(4.0) (Hotel Riu Palace Punta Cana)\n\n58. Sample Result 3:Aspect-Specific Sentiment Lexicon Uncover sentimental information directly from the data Value Rooms Location Cleanliness resort 22.80 view 28.05 restaurant 24.47 clean 55.35 value 19.64 comfortable 23.15 walk 18.89 smell 14.38 excellent 19.54 modern 15.82 bus 14.32 linen 14.25 worth 19.20 quiet 15.37 beach 14.11 maintain 13.51 bad -24.09 carpet -9.88 wall -11.70 smelly -0.53 money -11.02 smell -8.83 bad -5.40 urine -0.43 terrible -10.01 dirty -7.85 road -2.90 filthy -0.42 overprice -9.06 stain -5.85 website -1.67 dingy -0.38\n\n59. Sample Result 4: Validating preference weights • Analysis of hotels preferred by different types of reviewers – Reviewers emphasizing the ‘value’ aspect more would prefer cheaper hotels City AvgPrice Group Val/Loc Val/Rm Val/Ser Amsterdam 241.6 top-10 190.7 214.9 221.1 bot-10 270.8 333.9 236.2 Barcelona 280.8 top-10 270.2 196.9 263.4 bot-10 330.7 266.0 203.0 San Francisco 261.3 top-10 214.5 249.0 225.3 bot-10 321.1 311.1 311.4 Florence 272.1 top-10 269.4 248.9 220.3 bot-10 298.9 293.4 292.6\n\n60. Application 1: Rated Aspect Summarization Aspect Summary Rating Value Truly unique character and a great location at a reasonable price Hotel Max was an excellent choice for our recent three night stay in Seattle. 3.1 Overall not a negative experience, however considering that the hotel industry is very much in the impressing business there was a lot of room for improvement. 1.7 Location The location, a short walk to downtown and Pike Place market, made the hotel a good choice. 3.7 When you visit a big metropolitan city, be prepared to hear a little traffic outside! 1.2 Business Service You can pay for wireless by the day or use the complimentary Internet in the business center behind the lobby though. 2.7 My only complaint is the daily charge for internet access when you can pretty much connect to wireless on the streets anymore. 0.9 (Hotel Max in Seattle)\n\n61. Application 2: Discover consumer preferences • Amazon reviews: no guidance battery life accessory service file format volume video\n\n62. Application 3: User Rating Behavior Analysis Reviewers focus differently on ‘expensive’ and ‘cheap’ hotels Expensive Hotel Cheap Hotel 5 Stars 3 Stars 5 Stars 1 Star Value 0.134 0.148 0.171 0.093 Room 0.098 0.162 0.126 0.121 Location 0.171 0.074 0.161 0.082 Cleanliness 0.081 0.163 0.116 0.294 Service 0.251 0.101 0.101 0.049\n\n63. Application 4: Personalized Ranking of Entities Query: 0.9 value 0.1 others Non-Personalized Personalized\n\n64. Summary 1. Opinion Integration 2. Opinion Summarization 3. Opinion Analysis - Leverage expert reviews [WWW 08] - Leverage ontology [COLING 10] - Aspect sentiment summary [WWW 07] - Micro opinion summary [WWW 12] - Two-stage rating analysis [KDD 10] - Unified rating analysis [KDD 11] Rapidly growing opinionated text data open up many applications Users face significant challenges in collecting and digesting opinions 64\n\n65. www.findilike.com 2. Opinion Summarization Future Work (Short Term): Put all together 1. Opinion Integration 3. Opinion Analysis 65\n\n66. Findilike: Opinion-Based Decision-Support “clean”, “safe” $30-$60, Within 5 miles of.. Structured prefsOpinion prefs Query Review BrowsingReview Browsing Review Tag CloudsReview Tag Clouds Opinion SummariesOpinion Summaries ResultsResults Opinion Tools Combined Entity Scoring Combined Entity Scoring Results Summarization Results Summarization Query Parsing Query Parsing Opinon Expansion Opinon Expansion Entity Scoring Entity Scoring Entity Scoring Entity Scoring Opinion Repository Structured Data Query Parsing Query Parsing Ranking Engine Opinion Matching Structured Matching www.findilike.com 66\n\n67. Opinion-Based Entity Ranking Query =“near ohare airport, free internet” http://www.findilike.com/ 67\n\n69. Future Work (Long Term): Towards an Intelligent Knowledge Service System Information Retrieval Text Mining Decision Support Big Raw Data Small Relevant Data Applications: Bioinformation, Medical/Health Informatics, Business Intelligence, Web, … 69 More information can be found at: http://timan.cs.uiuc.edu/"
    }
}