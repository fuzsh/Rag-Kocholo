{
    "id": "wrong_mix_domainrange_subsidiary_00087_0",
    "rank": 9,
    "data": {
        "url": "https://iopscience.iop.org/issue/1748-0221/13/02",
        "read_more_link": "",
        "language": "en",
        "title": "Journal of Instrumentation",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://static.iopscience.com/3.60.0-SNAPSHOT/img/icon-search.svg",
            "https://cms.iopscience.org/9a40b4cd-08b9-11e2-a7df-4d5160a0f0b4/sissa.gif?guest=true",
            "https://cms.iopscience.org/9a40b4cd-08b9-11e2-a7df-4d5160a0f0b4/sissa.gif?guest=true",
            "https://cdn.images.iop.org/Entities/barP.gif",
            "https://cdn.images.iop.org/Entities/barP.gif",
            "https://cdn.images.iop.org/Entities/barP.gif",
            "https://cdn.images.iop.org/Entities/barP.gif",
            "https://cdn.images.iop.org/Entities/barP.gif",
            "https://cdn.images.iop.org/Entities/barP.gif",
            "https://cdn.images.iop.org/Entities/barP.gif",
            "https://cdn.images.iop.org/Entities/barP.gif",
            "https://cdn.images.iop.org/Entities/barP.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "F.M. Brunbauer",
            "M. Lupberger",
            "E. Oliveri",
            "F. Resnati",
            "L. Ropelewski",
            "C. Streli",
            "P. Thuiner",
            "M. van Stenis",
            "P. Smolyanskiy",
            "B. Bergmann"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "We present a model for the Global Quantum Efficiency (GQE) of the MicroBooNE optical units. An optical unit consists of a flat, circular acrylic plate, coated with tetraphenyl butadiene (TPB), positioned near the photocathode of a 20.2-cm diameter photomultiplier tube. The plate converts the ultra-violet scintillation photons from liquid argon into visible-spectrum photons to which the cryogenic phototubes are sensitive. The GQE is the convolution of the efficiency of the plates that convert the 128 nm scintillation light from liquid argon to visible light, the efficiency of the shifted light to reach the photocathode, and the efficiency of the cryogenic photomultiplier tube. We develop a GEANT4-based model of the optical unit, based on first principles, and obtain the range of probable values for the expected number of detected photoelectrons (NPE) given the known systematic errors on the simulation parameters. We compare results from four measurements of the NPE determined using alpha-particle sources placed at two distances from a TPB-coated plate in a liquid argon cryostat test stand. We also directly measured the radial dependence of the quantum efficiency, and find that this has the same shape as predicted by our model. Our model results in a GQE of 0.0055±0.0009 for the MicroBooNE optical units. While the information shown here is MicroBooNE specific, the approach to the model and the collection of simulation parameters will be widely applicable to many liquid-argon-based light collection systems.\n\nWe developed a simple, low cost user-friendly automated indirect ion beam fluence measurement system for ion irradiation and analysis experiments requiring indirect beam fluence measurements unperturbed by sample conditions like low temperature, high temperature, sample biasing as well as in regular ion implantation experiments in the ion implanters and electrostatic accelerators with continuous beam. The system, which uses simple, low cost, off-the-shelf components/systems and two distinct layers of in-house built softwarenot only eliminates the need for costly data acquisition systems but also overcomes difficulties in using properietry software. The hardware of the system is centered around a personal computer, a PIC16F887 based embedded system, a Faraday cup drive cum monitor circuit, a pair of Faraday Cups and a beam current integrator and the in-house developed software include C based microcontroller firmware and LABVIEW based virtual instrument automation software. The automatic fluence measurement involves two important phases, a current sampling phase lasting over 20–30 seconds during which the ion beam current is continuously measured by intercepting the ion beam and the averaged beam current value is computed. A subsequent charge computation phase lasting 700–900 seconds is executed making the ion beam to irradiate the samples and the incremental fluence received by the sampleis estimated usingthe latest averaged beam current value from the ion beam current sampling phase. The cycle of current sampling-charge computation is repeated till the required fluence is reached. Besides simplicity and cost-effectiveness, other important advantages of the developed system include easy reconfiguration of the system to suit customisation of experiments, scalability, easy debug and maintenance of the hardware/software, ability to work as a standalone system. The system was tested with different set of samples and ion fluences and the results were verified using Rutherford backscattering technique which showed the satisfactory functioning of the system. The accuracy of the fluence measurements is found to be less than 2% which meets the demands of the irradiation experiments undertaken using the developed set up. The system was incorporated for regular use at the existing ultra high vacuum (UHV) ion irradiation chamber of 1.7 MV Tandem accelerator and several ion implantation experiments on a variety of samples like SS304, D9, ODS alloys have been successfully carried out.\n\nSingle electron noise which persists for many milliseconds is known to follow ionizing events in liquid/gas xenon emission detectors. Due to the long timescale, this noise can be mistaken for a genuine signal. Therefore, it is a limiting background to the low-energy threshold of dark matter searches, and could prevent discovery-class searches for MeV scale hidden sector dark matter. A systematic study reveals distinct fast and slow components to the noise. The fast component is compatible with the hypothesis of electrons which were trapped below the liquid surface, and can be reduced by increasing the electric field across the liquid/gas interface. However, the slow component increases linearly with electric field. Hypotheses for the origin of this effect are discussed, and techniques for mitigation are suggested.\n\nMore target mass is required in current TPC based directional dark matter detectors for improved detector sensitivity. This can be achieved by scaling up the detector volumes, but this results in the need for more analogue signal channels. A possible solution to reducing the overall cost of the charge readout electronics is to multiplex the signal readout channels. Here, we present a multiplexer system in expanded mode based on LMH6574 chips produced by Texas Instruments, originally designed for video processing. The setup has a capability of reducing the number of readouts in such TPC detectors by a factor of 20. Results indicate that the important charge distribution asymmetry along an ionization track is retained after multiplexed signals are demultiplexed.\n\nThe High Energy X-ray Imaging Technology (HEXITEC) ASIC is designed on a 0.35 μm CMOS process to read out CdTe or CZT detectors and hence provide fine-pixellated spectroscopic imaging in the range 2–200 keV. In this paper, we examine the tolerance of HEXITEC to both potentially destructive cumulative and single event radiation effects. Bare ASICs are irradiated with X-rays up to a total ionising dose (TID) of 1 Mrad (SiO2) and bombarded with heavy ions with linear energy transfer (LET) up to 88.3 MeV mg−1 cm−2. HEXITEC is shown to operate reliably below a TID of 150 krad, have immunity to fatal single event latchup (SEL) and have high tolerance to non-fatal SEL up to LETs of at least 88.3 MeV mg−1 cm−2. The results are compared to predictions of TID and SELs for various Earth-orbits and aluminium shielding thicknesses. It is found that HEXITEC's radiation tolerance to both potentially destructive cumulative and single event effects is sufficient to reliably operate in these environments with moderate shielding.\n\nBolometric experiments searching for rare events usually require an extremely low radioactive background to prevent spurious signals from mimicking those of interest, spoiling the sensitivity of the apparatus. In such contexts, radioactive sources cannot be used to produce a known signal to calibrate the measured energy spectrum during data taking. In this paper we present an instrument designed to generate ultra-stable and very precise calibrating pulses, which can be used to stabilize the response of bolometers during data taking. The instrument is characterized by the presence of multi-outputs, a completely programmable pulse width and amplitude and a dedicated daisy-chained optical trigger line. It can be fully controlled and monitored remotely via CAN bus protocol. An energy resolution of the order of 20 eV FWHM at 1 MeV (2 eV FWHM at 10 keV) and a thermal stability of the order of 0.1 ppm/oC have been achieved. The device can also provide an adjustable power to compensate the low frequency thermal fluctuations that typically occur in cryogenic experiments.\n\nIn this paper, we report on design, modelling and construction of a simple continuous nuclear gauge for measuring the fluid levels in vessels. In this instrument, a point source and a point detector are used on top and bottom sides of the vessel. The theoretical framework that is needed for analyzing the instrument data is described and it is shown that with this type of design, any unknown systematic error during the measurements can be removed. The developed theoretical relations and the instrument modelling by the MCNPX code, demonstrate its linear response in the entire measuring span. By using a cesium-137 gamma radiation source and a NaI (Tl) scintillation detector in the construction of the nuclear level gauge, the linear response of the instrument is also experimentally confirmed. It is shown that the mean relative error in determination of water level in the entire range of an 85 cm height vessel was less than 3.57%, which is reasonably acceptable for this simple design.\n\nThis paper presents a 12-bit pipelined successive approximation register (SAR) ADC for CZT-based hard X-ray Imager. The proposed ADC is comprised of a first-stage 6-bit SAR-based Multiplying Digital Analog Converter (MDAC) and a second-stage 8-bit SAR ADC. A novel MDAC architecture using Vcm-based Switching method is employed to maximize the energy efficiency and improve the linearity of the ADC. Moreover, the unit-capacitor array instead of the binary-weighted capacitor array is adopted to improve the conversion speed and linearity of the ADC in the first-stage MDAC. In addition, a new layout design method for the binary-weighted capacitor array is proposed to reduce the capacitor mismatches and make the routing become easier and less-time-consuming. Finally, several radiation-hardened-by-design technologies are adopted in the layout design against space radiation effects. The prototype chip was fabricated in 0.18 μm mixed-signal 1.8V/3.3V process and operated at 1.8 V supply. The chip occupies a core area of only 0.58 mm2. The proposed pipelined SAR ADC achieves a peak signal-to-noise-and-distortion ratio (SNDR) of 66.7 dB and a peak spurious-free dynamic range (SFDR) of 78.6 dB at 10 MS/s sampling rate and consumes 10 mW. The figure of merit (FOM) of the proposed ADC is 0.56 pJ/conversion-step.\n\nCUORE is an array of thermal calorimeters composed of 988 crystals held at about 10 mK, whose absorbed energy is read out with semiconductor thermistors. The composition of the crystal is TeO2, and the aim is the study of the double beta decay of 130Te on very long and stable runs. CUPID-0 is an array of 26 Zn82Se crystals with double thermistor readout to study the double beta decay of 82Se. In the present paper, we present an overview of the entire front-end electronic readout chain, from the preamplifier to the anti-aliasing filter. This overview includes motivations, design strategies, circuit implementation and performance results of the electronic system, including other auxiliary yet important elements like power supplies and the slow control communication system. The stringent requirements of stability on the very long experimental runs that are foreseen during CUORE and CUPID-0 operation, are achieved thanks to novel solutions of the front-end preamplifier and of the detector bias circuit setup.\n\nIn this study, to detect the light element lithium (Li) and to detect low dosed Boron (B) in the local area at nm order, we developed an analytical electron microscope equipped with an improved serial (S)-type WDX (wavelength dispersive X-ray spectroscopy) system. In detail, to detect Li, we developed a high-conductivity multi-capillary X-ray (MCX) lens, and a diffractor with a lattice spacing (d) of 15 nm, and with a spacing variation (δ d) of 0.8 nm. Moreover, to detect low dosed light element B, we designed a high-conductivity MCX lens based on the soft X-ray reflectivity in the capillary and calculation. We developed a large-solid-angle MCX lens whose conductivity of the characteristic X-rays of B became 20 times higher than that of an MCX lens with a 30-mm focal length. Our developed analytical electron microscope was applied to a LiAl specimen and a low B-doped Si substrate specimen, and the performance of this analytical electron microscope was evaluated. As a results, this analytical electron microscope could detect the characteristic X-rays of Li with a minimum mass fraction (MMF) of 8.4 atomic % (at. %). The energy resolution was 1 eV at 55 eV. From the results of measuring the line profile of B for the unpatterned B-implantation area on a B-doped Si substrate specimen, the measured line profile data were in good agreement with secondary ion mass spectrometry data up to a depth of 100 nm with a B concentration of 0.05 at. %.\n\nA novel simultaneous streak and framing camera with continuous access, the perfect information of which is far more important for the exact interpretation and precise evaluation of many detonation events and shockwave phenomena, has been developed. The camera with the maximum imaging frequency of 2 × 106 fps and the maximum scanning velocity of 16.3 mm/μs has fine imaging properties which are the eigen resolution of over 40 lp/mm in the temporal direction and over 60 lp/mm in the spatial direction and the framing frequency principle error of zero for framing record, and the maximum time resolving power of 8 ns and the scanning velocity nonuniformity of 0.136%∼-0.277% for streak record. The test data have verified the performance of the camera quantitatively. This camera, simultaneously gained frames and streak with parallax-free and identical time base, is characterized by the plane optical system at oblique incidence different from space system, the innovative camera obscura without principle errors, and the high velocity motor driven beryllium-like rotating mirror, made of high strength aluminum alloy with cellular lateral structure. Experiments demonstrate that the camera is very useful and reliable to take high quality pictures of the detonation events.\n\nCerium-doped Gd3(Ga, Al)5O12 (GAGG:Ce) is a promising novel scintillator for gamma-ray detectors. While GAGG:Ce has already been implemented in various commercial products, its detailed characteristics and response to high-energy particles and gamma rays remain unknown. In particular, knowledge is lacking on the radiation tolerance of this scintillator against the gamma-ray and proton irradiation expected in future space satellite mission applications. In this study, we first investigate the light-yield energy dependence, energy resolution, decay time, radiation tolerance, and afterglow of GAGG:Ce scintillators under various temperature conditions. We find excellent linearity of ±3% between light yields and deposited energy over a wide range of 30–1836 keV; however, a light-yield deficit of more than 10% is observed below 30 keV of deposited gamma ray energy. We confirm that the temperature dependence of the light yield, energy resolution, and scintillation decay time is within 5–20% between −20 and 20 oC. We also evaluate the GAGG:Ce activation characteristics under proton irradiation and the light-yield degradation by accumulated dose using a 60Co source. Moreover, we successfully identify various gamma-ray lines due to activation. Finally, we find a substantial afterglow for GAGG:Ce scintillators over a few hours; such an afterglow is only minimally observed in other scintillators such as CsI:Tl and Bi4Ge3O12 (BGO). However, the afterglow can be substantially reduced through additional co-doping with divalent metal ions, such as Mg ions. These results suggest that GAGG:Ce is a promising scintillator with potential application in space satellite missions in the near future.\n\nThe Digital Cherenkov Viewing Device (DCVD) is a tool used by nuclear safeguards inspectors to verify irradiated nuclear fuel assemblies in wet storage based on the recording of Cherenkov light produced by the assemblies. One type of verification involves comparing the measured light intensity from an assembly with a predicted intensity, based on assembly declarations. Crucial for such analyses is the performance of the prediction model used, and recently new modelling methods have been introduced to allow for enhanced prediction capabilities by taking the irradiation history into account, and by including the cross-talk radiation from neighbouring assemblies in the predictions. In this work, the performance of three models for Cherenkov-light intensity prediction is evaluated by applying them to a set of short-cooled PWR 17x17 assemblies for which experimental DCVD measurements and operator-declared irradiation data was available; (1) a two-parameter model, based on total burnup and cooling time, previously used by the safeguards inspectors, (2) a newly introduced gamma-spectrum-based model, which incorporates cycle-wise burnup histories, and (3) the latter gamma-spectrum-based model with the addition to account for contributions from neighbouring assemblies. The results show that the two gamma-spectrum-based models provide significantly higher precision for the measured inventory compared to the two-parameter model, lowering the standard deviation between relative measured and predicted intensities from 15.2 % to 8.1 % respectively 7.8 %. The results show some systematic differences between assemblies of different designs (produced by different manufacturers) in spite of their similar PWR 17x17 geometries, and possible ways are discussed to address such differences, which may allow for even higher prediction capabilities. Still, it is concluded that the gamma-spectrum-based models enable confident verification of the fuel assembly inventory at the currently used detection limit for partial defects, being a 30 % discrepancy between measured and predicted intensities, while some false detection occurs with the two-parameter model. The results also indicate that the gamma-spectrum-based prediction methods are accurate enough that the 30 % discrepancy limit could potentially be lowered.\n\nWe propose an experiment to search for a new gauge boson A' in e+e− annihilation by means of a positron beam incident on a gas hydrogen target internal to the bypass at the VEPP-3 storage ring. The search method is based on a missing mass spectrum in the reaction e+e−→ γA'. It allows observation of the A' signal independently of its decay modes and life time. The projected result of this experiment corresponds to an upper limit on the square of the coupling constant ε2=3⋅ 10−8 with a signal-to-noise ratio of two to one at an A' mass of 5–20 MeV .\n\nThis paper proposes a numerical model of the dynamic time over threshold (DTOT) method for semi-Gaussian signals. The parameters are optimized accordingly in the design of a prototype DTOT circuit. A photomultiplier tube was coupled to a 2-inch LaBr3 scintillator and connected to a charge sensitive preamplifier. The signal was semi-Gaussian shaped and sent to the DTOT circuit. The feasibility of the technique has been verified by the experimental results, which achieve 2.3% integral nonlinearity and 7-bit dynamic range.\n\nThe FAMU experiment aims to accurately measure the hyperfine splitting of the ground state of the muonic hydrogen atom. A measurement of the transfer rate of muons from hydrogen to heavier gases is necessary for this purpose. In June 2014, within a preliminary experiment, a pressurized gas-target was exposed to the pulsed low-energy muon beam at the RIKEN RAL muon facility (Rutherford Appleton Laboratory, U.K.). The main goal of the test was the characterization of both the noise induced by the pulsed beam and the X-ray detectors. The apparatus, to some extent rudimental, has served admirably to this task. Technical results have been published that prove the validity of the choices made and pave the way for the next steps. This paper presents the results of physical relevance of measurements of the muon transfer rate to carbon dioxide, oxygen, and argon from non-thermalized excited μp atoms. The analysis methodology and the approach to the systematics errors are useful for the subsequent study of the transfer rate as function of the kinetic energy of the μp currently under way.\n\nIn this study, the germanium detector assembly, installed at the Accurate Neutron-Nuclear Reaction measurement Instruments (ANNRI) in the Material and Life Science Facility (MLF) operated by the Japan Proton Accelerator Research Complex (J-PARC), has been characterized for extension to the measurement of the angular distribution of individual γ-ray transitions from neutron-induced compound states. We have developed a Monte Carlo simulation code using the GEANT4 toolkit, which can reproduce the pulse-height spectra of γ-rays from radioactive sources and (n,γ) reactions. The simulation is applicable to the measurement of γ-rays in the energy region of 0.5–11.0 MeV.\n\nA 4H-SiC Schottky diode was investigated as a particle detector for Rutherford Backscattering Spectroscopy (RBS) experiment. The device was fabricated on a commercial 4H-SiC epitaxial n-type layer grown onto a 4H-SiC n+ type substrate wafer doped with nitrogen. Hafnium oxide with thickness of 1 nm was deposited by Atomic Layer Deposition and 10 nm of Ni were deposited by sputtering to form the Ni/HfO2/4H-SiC MIS Schottky structure. Current-Voltage curves with variable temperature were measured to extract the real Schottky Barrier Height (0.32 V) and ideality factor values (1.15). Reverse current and Capacitance-Voltage measurements were performed on the 4H-SiC detector and compared to a commercial Si barrier detector acquired from ORTEC. RBS data for four alpha energies (1, 1.5, 2 and 2.5 MeV) were collected from an Au/Si sample using the fabricated SiC and the commercial Si detectors simultaneously. The energy resolution for the fabricated detector was estimated to be between 75 and 80 keV.\n\nThere is an increasing interest in using Silicon Photomultipliers (SiPMs) in emerging applications where the detectors have to operate in ambient environment with high sensitivity and fast timing response in combination with narrow bandwidth light emitting sources like LEDs or VCSELs. The need to use large area detectors for optimizing the light collection efficiency, due to the low optical fluxes to be usually detected, imposes the optimization of the SiPM performance in specific wavelength ranges (usually visible or near infrared), to fully exploit the single photon sensitivity of these detectors and not to reduce at the same time their dynamic range. The use of proper optical long-pass filters on the detector's package can represent a suitable way to reach both these targets, through the reduction of environmental light absorption. Here we present the preliminary results obtained from the characterization of n+-p SiPMs with commercial long-pass filters with increasing cut-on wavelength in the range 500 nm–900 nm glued on the top side of the detector's package. The performance of the detectors has been evaluated in terms of dark current variation induced by the use of the filters and background light rejection under the illumination of white fluorescent lamps. The relevant reduction observed in the dark current (up to 90% at 13 V overvoltage) and the consistent reduction of stray light absorption (up to 90% at 3 V overvoltage with a 900 nm cut-on wavelength long-pass filter) are the main characterization results obtained and shown in this paper.\n\nDesign of a 30 MeV, 10 Amp RF linac as neutron source has been carried out by means of ASTRA simulation code. Here we discuss details of design simulations for three different cases i.e Thermionic , DC and RF photocathode guns and compare them as injectors to a 30 MeV RF linac for n-ToF production. A detailed study on choice of input parameters of the beam from point of view of transmission efficiency and beam quality at the output have been described. We found that thermionic gun isn't suitable for this application. Both DC and RF photocathode gun can be used. RF photocathode gun would be of better performance.\n\nIn order to measure the cross sections of major actinides with high precision, a Time Projection Chamber prototype named fTPC has been developed at Tsinghua University taking advantage of its ability of 3D particle track reconstruction and dE/dx measurement. One of the main sources of the uncertainties of fission cross sections measurement is the differentiation between fission fragments and alpha particles, because their energy distributions are overlapped in low energy range. In this study, using the spontaneous fission fragments and alpha particles of 252Cf source, the ability of the fTPC to differentiate these two kinds of particles is studied. Combined with simulation results, the uncertainty of cross section caused by the differentiation in fTPC is estimated, From 100 ug/cm2 to 500 ug/cm2 of the target thickness, the uncertainties are evaluated as: 0.078%, 0.17%, 0.25%, 0.33% and 0.41%. All of them are less than 1%, which makes the uncertainty of fission cross section less than 1% become possible.\n\nThe potential of a combined and simultaneous fast-neutron/γ-ray computed tomography technique using Monte Carlo simulations is described. This technique is applied on the basis of a hypothetical tomography system comprising an isotopic radiation source (americium-beryllium) and a number (13) of organic scintillation detectors for the production and detection of both fast neutrons and γ rays, respectively. Via a combination of γ-ray and fast neutron tomography the potential is demonstrated to discern nuclear materials, such as compounds comprising plutonium and uranium, from substances that are used widely for neutron moderation and shielding. This discrimination is achieved on the basis of the difference in the attenuation characteristics of these substances. Discrimination of a variety of nuclear material compounds from shielding/moderating substances (the latter comprising lead or polyethylene for example) is shown to be challenging when using either γ-ray or neutron tomography in isolation of one another. Much-improved contrast is obtained for a combination of these tomographic modalities. This method has potential applications for in-situ, non-destructive assessments in nuclear security, safeguards, waste management and related requirements in the nuclear industry.\n\nThe problem of how to accurately measure multiphase flow in the oil/gas industry remains as an important issue since the early 80 s. Meanwhile, oil-water two-phase flow rate measurement has been regarded as an important issue. Gamma-ray attenuation is one of the most commonly used methods for phase fraction measurement which is entirely dependent on the flow regime variations. The peripheral strategy applied for removing the regime dependency problem, is using a homogenization system as a preconditioning tool, as this research work demonstrates. Here, at first, TPFHL as a two-phase flow homogenizer loop has been introduced and verified by a quantitative assessment. In the wake of this procedure, SEMPF as a static-equivalent multiphase flow with an additional capability for preparing a uniform mixture has been explained. The proposed idea in this system was verified by Monte Carlo simulations. Finally, the different water-gas oil two-phase volume fractions fed to the homogenizer loop and injected into the static-equivalent system. A comparison between performance of these two systems by using gamma-ray attenuation technique, showed not only an extra ability to prepare a homogenized mixture but a remarkably increased measurement accuracy for the static-equivalent system.\n\nHV-CMOS pixel sensors are a promising option for the tracker upgrade of the ATLAS experiment at the LHC, as well as for other future tracking applications in which large areas are to be instrumented with radiation-tolerant silicon pixel sensors. We present results of testbeam characterisations of the 4th generation of Capacitively Coupled Pixel Detectors (CCPDv4) produced with the ams H18 HV-CMOS process that have been irradiated with different particles (reactor neutrons and 18 MeV protons) to fluences between 1× 1014 and 5× 1015 1−MeV− neq. The sensors were glued to ATLAS FE-I4 pixel readout chips and measured at the CERN SPS H8 beamline using the FE-I4 beam telescope. Results for all fluences are very encouraging with all hit efficiencies being better than 97% for bias voltages of 85 V. The sample irradiated to a fluence of 1× 1015 neq—a relevant value for a large volume of the upgraded tracker—exhibited 99.7% average hit efficiency. The results give strong evidence for the radiation tolerance of HV-CMOS sensors and their suitability as sensors for the experimental HL-LHC upgrades and future large-area silicon-based tracking detectors in high-radiation environments.\n\nThis paper presents a 4 GHz phase locked loop (PLL), which is implemented in a 65 nm standard CMOS process to provide low noise and high frequency sampling clocks for readout electronics to be used in the Jiangmen Underground Neutrino Observatory (JUNO) experiment. Based on the application requirements the target of the design is to find the best compromise between power consumption, area and phase noise for a highly reliable topology. The design implements a novel method for the charge pump that suppresses current mismatch when the PLL is locked. This reduces static phase offset at the inputs of the phase-frequency detector (PFD) that otherwise would introduce spurs at the PLL output. In addition, a technique of amplitude regulation for the voltage controlled oscillator (VCO) is presented to provide low noise and reliable operation. The combination of thin and thick oxide varactor transistors ensures optimum tuning range and linearity over process as well as temperature changes for the VCO without additional calibration steps. The current mismatch at the output of the charge pump for the control voltage at about half the 1 V supply voltage is below 0.3% and static phase offset down to 0.25% is reached. The total PLL consumes 18.5 mW power at 1.8 V supply for the VCO and 1 V supply for the other parts.\n\nA 384 channels (24 vertical × 16 radial) Electron Cyclotron Emission Imaging (ECEI) system has been installed on Experimental Advanced Superconducting Tokamak (EAST). With the aid of advanced front optics, high spaital resolution around 1.1cm and flexible vertical coverage 30 ∼ 70 cm have been realized. The well-designed optics also provides a long Rayleigh length up to 70 cm even with an object length larger than 2.6 m. The electronic system has a wide immediate frequency (IF) bandwidth 2 ∼ 16.5 GHz, which enables a continuous radial coverage up to 25 cm. Benefited from advanced optics design and the wide IF bandwidth, the ECEI system with high spatial resolution can provide a large and continuous view field, especially in the radial direction, which is enough for the observation of the whole q = 1 surface. The comprehensive details of the ECEI system will be presented in this paper, along with some experimental results.\n\nLarge-area PhotoMultiplier Tubes (PMT) allow to efficiently instrument Liquid Scintillator (LS) neutrino detectors, where large target masses are pivotal to compensate for neutrinos' extremely elusive nature. Depending on the detector light yield, several scintillation photons stemming from the same neutrino interaction are likely to hit a single PMT in a few tens/hundreds of nanoseconds, resulting in several photoelectrons (PEs) to pile-up at the PMT anode. In such scenario, the signal generated by each PE is entangled to the others, and an accurate PMT charge reconstruction becomes challenging. This manuscript describes an experimental method able to address the PMT charge reconstruction in the case of large PE pile-up, providing an unbiased charge estimator at the permille level up to 15 detected PEs. The method is based on a signal filtering technique (Wiener filter) which suppresses the noise due to both PMT and readout electronics, and on a Fourier-based deconvolution able to minimize the influence of signal distortions—such as an overshoot. The analysis of simulated PMT waveforms shows that the slope of a linear regression modeling the relation between reconstructed and true charge values improves from 0.769 ± 0.001 (without deconvolution) to 0.989 ± 0.001 (with deconvolution), where unitary slope implies perfect reconstruction. A C++ implementation of the charge reconstruction algorithm is available online at [1].\n\nMuon tomography system built by the 2-D readout high spatial resolution Multi-gap Resistive Plate Chamber (MRPC) detector is a project of Tsinghua University. An encoding readout method based on the fine-fine configuration has been used to minimize the number of the readout electronic channels resulting in reducing the complexity and the cost of the system. In this paper, we provide a systematic comparison of the MRPC detector performance with and without fine-fine encoding readout. Our results suggest that the application of the fine-fine encoding readout leads us to achieve a detecting system with slightly worse spatial resolution but dramatically reduce the number of electronic channels.\n\nThis paper describes a novel idea of a fine-grained fully-active plastic scintillator detector made of many optically independent 1×1×1 cm3 cubes with readout on three orthogonal projections by wavelength shifting fibers. The original purpose of this detector is to serve as an active neutrino target for the detection, measurement and identification of the final state particles down to a few tenths MeV kinetic energies. The three readout views as well as the fine granularity ensure powerful localization and measurement of the deposited energy combined with good timing properties and isotropic acceptance. The possible application as a new active target for the T2K near detector, initial simulation studies and R&D test results are reported.\n\nThis paper presents the design of two reduced size dual-band metamaterial bandpass filters and its simulation followed by measurements of proposed filters. These filters are supporting different frequency bands and primarily could be utilize in radio frequency identification (RFID) application. The filter includes three cells in which two are symmetrical and both inductively coupled with the third cell which is present in between them. In the proposed designs, three different metamaterial composite right/left handed (CRLH) cell resonators have been analysed for compactness. The CRLH cell consists of an interdigital capacitor, a stub/meander line/spiral inductor and a via to connect the top of the structure and ground plane. Finally, the proposed dual band bandpass filters (using meander line and spiral inductor) are showing size reduction by 65% and 50% (with 25% operating frequency reduction), respectively, in comparison with reference filter using stub inductor. More than 30 dB attenuation has been achieved between the two passbands.\n\nThe Ricochet experiment seeks to measure Coherent (neutral-current) Elastic Neutrino-Nucleus Scattering (CEνNS) using dark-matter-style detectors with sub-keV thresholds placed near a neutrino source, such as the MIT (research) Reactor (MITR), which operates at 5.5 MW generating approximately 2.2 × 1018 ν/second in its core. Currently, Ricochet is characterizing the backgrounds at MITR, the main component of which comes in the form of neutrons emitted from the core simultaneous with the neutrino signal. To characterize this background, we wrapped Bonner cylinders around a 32He thermal neutron detector, whose data was then unfolded via a Markov Chain Monte Carlo (MCMC) to produce a neutron energy spectrum across several orders of magnitude. We discuss the resulting spectrum and its implications for deploying Ricochet at the MITR site as well as the feasibility of reducing this background level via the addition of polyethylene shielding around the detector setup.\n\nThe KATRIN experiment is a next-generation direct neutrino mass experiment with a sensitivity of 0.2 eV (90% C.L.) to the effective mass of the electron neutrino. It measures the tritium β-decay spectrum close to its endpoint with a spectrometer based on the MAC-E filter technique. The β-decay electrons are guided by a magnetic field that operates in the mT range in the central spectrometer volume; it is fine-tuned by a large-volume air coil system surrounding the spectrometer vessel. The purpose of the system is to provide optimal transmission properties for signal electrons and to achieve efficient magnetic shielding against background. In this paper we describe the technical design of the air coil system, including its mechanical and electrical properties. We outline the importance of its versatile operation modes in background investigation and suppression techniques. We compare magnetic field measurements in the inner spectrometer volume during system commissioning with corresponding simulations, which allows to verify the system's functionality in fine-tuning the magnetic field configuration. This is of major importance for a successful neutrino mass measurement at KATRIN.\n\nWe summarize the current state of a concept for muon acceleration aimed at a future Neutrino Factory. The main thrust of these studies was to reduce the overall cost while maintaining performance by exploring the interplay between the complexity of the cooling systems and the acceptance of the accelerator complex. To ensure adequate survival for the short-lived muons, acceleration must occur at high average gradient. The need for large transverse and longitudinal acceptances drives the design of the acceleration system to an initially low RF frequency, e.g., 325 MHz, which is then increased to 650 MHz as the transverse size shrinks with increasing energy. High-gradient normal conducting RF cavities at these frequencies require extremely high peak-power RF sources. Hence superconducting RF (SRF) cavities are chosen. We consider two cost effective schemes for accelerating muon beams for a stageable Neutrino Factory: exploration of the so-called \"dual-use\" linac concept, where the same linac structure is used for acceleration of both H− and muons and, alternatively, an SRF-efficient design based on a multi-pass (4.5) \"dogbone\" RLA, extendable to multi-pass FFAG-like arcs.\n\nThe (x, y) position reconstruction method used in the analysis of the complete exposure of the Large Underground Xenon (LUX) experiment is presented. The algorithm is based on a statistical test that makes use of an iterative method to recover the photomultiplier tube (PMT) light response directly from the calibration data. The light response functions make use of a two dimensional functional form to account for the photons reflected on the inner walls of the detector. To increase the resolution for small pulses, a photon counting technique was employed to describe the response of the PMTs. The reconstruction was assessed with calibration data including 83mKr (releasing a total energy of 41.5 keV) and 3H (β− with Q = 18.6 keV) decays, and a deuterium-deuterium (D-D) neutron beam (2.45 MeV) . Within the detector's fiducial volume, the reconstruction has achieved an (x, y) position uncertainty of σ = 0.82 cm and σ = 0.17 cm for events of only 200 and 4,000 detected electroluminescence photons respectively. Such signals are associated with electron recoils of energies ∼0.25 keV and ∼10 keV, respectively. The reconstructed position of the smallest events with a single electron emitted from the liquid surface (22 detected photons) has a horizontal (x, y) uncertainty of 2.13 cm.\n\nElectron Multiplying Charge Coupled Devices (EMCCDs) have revolutionised low light level imaging, providing highly sensitive detection capabilities. Implementing Electron Multiplication (EM) in Charge Coupled Devices (CCDs) can increase the Signal to Noise Ratio (SNR) and lead to further developments in low light level applications such as improvements in image contrast and single photon imaging. Demand has grown for EMCCD devices with properties traditionally restricted to Complementary Metal-Oxide-Semiconductor (CMOS) image sensors, such as lower power consumption and higher radiation tolerance. However, EMCCDs are known to experience an ageing effect, such that the gain gradually decreases with time. This paper presents results detailing EM ageing in an Electron Multiplying Complementary Metal-Oxide-Semiconductor (EMCMOS) device and its effect on several device characteristics such as Charge Transfer Inefficiency (CTI) and thermal dark signal. When operated at room temperature an average decrease in gain of over 20% after an operational period of 175 hours was detected. With many image sensors deployed in harsh radiation environments, the radiation hardness of the device following proton irradiation was also tested. This paper presents the results of a proton irradiation completed at the Paul Scherrer Institut (PSI) at a 10 MeV equivalent fluence of 4.15× 1010 protons/cm2. The pre-irradiation characterisation, irradiation methodology and post-irradiation results are detailed, demonstrating an increase in dark current and a decrease in its activation energy. Finally, this paper presents a comparison of the damage caused by EM gain ageing and proton irradiation.\n\nThe method is proposed for numerical simulation of the radiation process of ultrarelativistic electrons in a crystalline undulator when particles fall on a crystal along one of the crystallographic planes. The method allows one to consider the processes of particle scattering and radiation at small and large bending amplitudes of the crystal planes, taking into account incoherent effects in the particle scattering. It is shown that the results of simulation of the radiation process are in good agreement with the corresponding results of analytical calculations in the case when the crystal field weakly perturbs the particle motion. The paper presents the results of 1 and 10 GeV electron radiation simulation in a crystalline undulator at different values of the plane bending amplitudes. The calculations are performed in the dipole approximation of radiation theory with taking into account the recoil effect in radiation.\n\nThe High Granularity Calorimeter (HGCAL), presently being designed by the CMS collaboration to replace the CMS endcap calorimeters for the High Luminosity phase of LHC, will feature six million channels distributed over 52 longitudinal layers. The requirements for the front-end electronics are extremely challenging, including high dynamic range (0.2 fC–10 pC), low noise (∼2000 e− to be able to calibrate on single minimum ionising particles throughout the detector lifetime) and low power consumption (∼20 mW/channel), as well as the need to select and transmit trigger information with a high granularity. Exploiting the intrinsic precision-timing capabilities of silicon sensors also requires careful design of the front-end electronics as well as the whole system, particularly clock distribution. The harsh radiation environment and requirement to keep the whole detector as dense as possible will require novel solutions to the on-detector electronics layout. Processing the data from the HGCAL imposes equally large challenges on the off-detector electronics, both for the hardware and incorporated algorithms. We present an overview of the complete electronics architecture, as well as the performance of prototype components and algorithms.\n\nCoherent transition radiation (CTR), produced by short electron bunches, is a well-known radiation mechanism which is applied for bunch length monitoring. By analyzing the CTR spectrum it is possible to reconstruct the longitudinal bunch shape. Such a technique is widely used for accelerators with electron beams possessing bunch lengths σz much larger than their transverse beam sizes σx,y (with σx,y,z the rms transverse and longitudinal beam sizes). New developments in the field of accelerator technology allow to produce and accelerate bunches with a duration of less than 1 fs with a \"pancake-like\" bunch shape, i.e. with σz ≪ σx,y. Diagnostic schemes of this kind of bunches give rise to interesting effects, for example connected with a transverse asymmetry (σx ≠ σy), with a tilting of the bunches (i.e. the bunch axis does not coincide with the velocity direction), and even more. Spectral-angular distributions of coherent backward transition radiation (BTR) were simulated taking into account a possible bunch tilt. It is shown that spectral intensity measurements of coherent BTR emitted in backward direction allow to obtain information about the bunch length.\n\nWe report on recent progress in the Geant4 electromagnetic (EM) physics sub-packages. New interfaces and models introduced recently in Geant4 10.3 are already used in LHC applications and may be useful for any type of simulation. Additional developments for EM physics are available with the new public version Geant4 10.4 (December, 2017). Important developments for calorimetry applications were carried out for the modeling of single and multiple scattering of charged particles. Corrections to scattering of positrons and to sampling of displacement have recently been added to the Geant4 default Urban model. The fully theory-based Goudsmit-Saunderson (GS) model for electron/positron multiple scattering was recently reviewed and a new improved version is available in Geant4 10.4. For testing purposes for novel calorimeters we provide a configuration of electron scattering based on the GS model or on the single scattering model (SS) instead of the Urban model. In addition, the GS model with Mott corrections enabled is included in the option4 EM physics constructor. This EM configuration provides the most accurate results for scattering of electrons and positrons.\n\nFor many reason it is tried to improve the quantum efficiency (QE) of position sensitive gas detectors. For energetic X-rays, the imaging systems usually consist of a bulk converter and gas amplification region. But the bulk converters have their own limitation. For X-rays, the converter thickness should be increased to achieve a greater detection efficiency, however in this case, the chance of escaping the photoelectrons is reduced. To overcome this limitation, a new type of converter, called a nanoporous converter such as Anodizing Aluminum Oxide (AAO) membrane with higher surface to volume ratio is proposed. According to simulation results with GATE code, for this nanoporous converter with the 1 mm thickness and inter pore distance of 627 nm, for 20–100 keV X-ray energies with a reasonable gas pressure and different pore diameters, the QE can be one order of magnitude greater than the bulk ones, which is a new approach for proposing high QE position sensitive gas detectors for medical imaging application and also high energy physics.\n\nFuture circular and linear colliders as well as the Large Hadron Collider in the High-Luminosity era have been imposing unprecedented challenges on the radiation hardness of particle detectors that will be used for specific purposes e.g. forward calorimeters, beam and luminosity monitors. We perform research on the radiation-hard active media for such detectors, particularly calorimeters, in two distinct categories: quartz plates coated with thin, radiation-hard organic or inorganic compounds, and intrinsically radiation-hard scintillators. In parallel to the effort on identifying radiation-hard scintillator materials, we also perform R&D on radiation-hard wavelength shifting fibers in order to facilitate a complete active medium for detectors under harsh radiation conditions. Here we describe the recent advances in the developments of radiation-hard scintillators and wavelength shifting fibers. We will discuss recent and projected measurements and future directions in development of radiation-hard active media.\n\nWe developed a general method for evaluating the energy spectrum evolution of relativistic charged particles that have undergone small quantum losses, such as the ionization losses when the electrons pass through matter and the radiation losses in the periodic fields. These processes are characterized by a small magnitude of the recoil quantum as compared with the particle's initial energy. The 'detector' function for arbitrary recoil spectrum is derived in addition to the straggling function. These functions are determined by the average number of scattering events undergone by the particle over the length of the detector (ionization losses) or the periodic field and the specific spectrum of the recoil. Moments for both the straggling function and the detector function are derived. The minimum average number of recoils, above which both functions depend only upon the mean energy of recoil quantum, is estimated. The average of this number is about 10 recoil events.\n\nThe Dual-Readout calorimetry, developed to overcome the main limiting factor in hadronic energy measurements, has been thoroughly investigated by the DREAM/RD52 collaboration during the last 15 years. The latest results show that very interesting performance may be obtained for both e.m. and hadronic showers, together with excellent standalone e/pi separation. These results and the plans (and the expected performance) for dual-readout calorimetry in the CepC/FCC-ee environment, are presented and discussed.\n\nThe UFXC32k is a single photon counting hybrid pixel detector with 75 μm pixel pitch. It was designed to cope with high X-ray intensities and therefore it is a very good candiate for synchrotron applications. In order to use this detector in an application, a dedicated setup must be designed and built allowing proper operation of the detector within the experiment. The paper presents two setups built for the purpose of Pump-Probe-Probe experiments at the Synchrotron SOLEIL and XPCS experiments at the APS.\n\nThe possibility of increasing the current density of a beam of fast electrons passes through glass cone-shaped channels was demonstrated in [1]. But the fraction of the electrons that passed through the conical channels without loss of the initial energy was not cleared up. Measurements of X-ray spectra generated by transmitted electrons in copper target mounted in vicinity of capillary output were performed for a detailed study of the contactless passage of 10 keV electrons through conical capillaries. All the measurements were made at different tilting angles with respect to the incident beam axis. It is shown that a significant part of electrons retains its initial energy even at the angles exceeding geometric opening of the capillary.\n\nSampling calorimeter is indispensable for physics measurement at collider experiment with PFA. Uncertainty of deposit energy at absorber layer degrades energy resolution. This problem will be solved by using lead glass as absorber, which is clear and heavy. High energy particles produce Cherenkov lights whose light yield corresponds to the track length in the lead glass. This information from the absorber will improve the energy resolution of the calorimeter. Performance of this calorimeter prototype tested for electrons at ELPH beam at Tohoku University has been described. We discuss the problems and its capabilities.\n\nA surprising small dechanneling length was observed at (111) channeling of ultrarelativistic electrons in a 60 μm thick silicon single crystal with a bending radius of 0.15 m. The experiments were conducted at beam energies between 3.35 and 14 GeV at the Facility for Advanced Accelerator Experimental Tests (FACET at SLAC, U.S.A.). It is shown in this paper that the small dechanneling lengths can well be reproduced with a modified Fokker-Planck equation for plane crystals in which a crystal bending has been heuristically introduced. Encouraged by this result experiments have been reconsidered which were performed at the Mainz Microtron MAMI with (110) silicon undulator crystals. The results obtained with the modified Fokker-Planck equation suggest that the observed rather low undulator peak intensity originates from the strongly reduced dechanneling length of electrons in the bent sections of the undulator. A scaling law derived on the basis of the modified Fokker-Planck equation reveals optimized parameters of electron based undulators as possible radiation sources in the X- and γ-ray region.\n\nAs part of its HL-LHC upgrade program, CMS is developing a High Granularity Calorimeter (HGCAL) to replace the existing endcap calorimeters. The HGCAL will be realised as a sampling calorimeter, including an electromagnetic compartment comprising 28 layers of silicon pad detectors with pad areas of 0.5–1.0 cm2 interspersed with absorbers. Prototype modules, based on 6-inch hexagonal silicon pad sensors with 128 channels, have been constructed and include many of the features required for this challenging detector. In 2016, beam tests of sampling configurations made from these modules have been conducted both at FNAL and at CERN using the Skiroc2 front-end ASIC (designed by the CALICE collaboration for ILC). In 2017, the setup has been extended with CALICE's AHCAL prototype, a scinitillator based sampling calorimeter, and it was further tested in dedicated beam tests at CERN. There, the new Skiroc2-CMS front-end ASIC was used for the first time. We highlight final results from our studies in 2016, including position resolution as well as precision timing-measurements. Furthermore, the extended setup in 2017 is discussed and first results from beam tests with electrons and pions are shown.\n\nThe High Luminosity LHC (HL-LHC) will integrate 10 times more luminosity than the LHC, posing significant challenges for radiation tolerance and event pileup on detectors, especially for forward calorimetry, and hallmarks the issue for future colliders. As part of its HL-LHC upgrade program, the CMS collaboration is designing a High Granularity Calorimeter to replace the existing endcap calorimeters. It features unprecedented transverse and longitudinal segmentation for both electromagnetic (ECAL) and hadronic (HCAL) compartments. This will facilitate particle-flow calorimetry, where the fine structure of showers can be measured and used to enhance pileup rejection and particle identification, whilst still achieving good energy resolution. The ECAL and a large fraction of HCAL will be based on hexagonal silicon sensors of 0.5–1 cm2 cell size, with the remainder of the HCAL based on highly-segmented scintillators with silicon photomultiplier (SiPM) readout. The intrinsic high-precision timing capabilities of the silicon sensors will add an extra dimension to event reconstruction, especially in terms of pileup rejection.\n\nThe upgrade of the particle detectors for the HL-LHC or for future colliders requires an extensive program of tests to qualify different detector prototypes with dedicated test beams. A common data-acquisition system, H4DAQ, was developed for the H4 test beam line at the North Area of the CERN SPS in 2014 and it has since been adopted in various applications for the CMS experiment and AIDA project. Several calorimeter prototypes and precision timing detectors have used our system from 2014 to 2017. H4DAQ has proven to be a versatile application and has been ported to many other beam test environments. H4DAQ is fast, simple, modular and can be configured to support various kinds of setup. The functionalities of the DAQ core software are split into three configurable finite state machines: data readout, run control, and event builder. The distribution of information and data between the various computers is performed using ZEROMQ (0MQ) sockets. Plugins are available to read different types of hardware, including VME crates with many types of boards, PADE boards, custom front-end boards and beam instrumentation devices. The raw data are saved as ROOT files, using the CERN C++ ROOT libraries. A Graphical User Interface, based on the python gtk libraries, is used to operate the H4DAQ and an integrated data quality monitoring (DQM), written in C++, allows for fast processing of the events for quick feedback to the user. As the 0MQ libraries are also available for the National Instruments LabVIEW program, this environment can easily be integrated within H4DAQ applications.\n\nThis paper describes the basic ideas and the first simulation results of a new electro-magnetic calorimeter concept, named SplitCal, aimed at optimising the measurement of photon direction in fixed-target experiment configuration, with high photon detection efficiency. This calorimeter was designed for the invariant mass reconstruction of axion-like particles decaying into two photons in the mass range 200 MeV to 1 GeV for the proposed proton beam dump experiment SHiP at CERN. Preliminary results indicate that angular resolutions better than obtained by past experiments can be achieved with this design. An implementation of this concept with real technologies is under study.\n\nDuring LHC Run II the centre-of-mass energy of pp collisions has increased from 8 TeV up to 13 TeV and the instantaneous luminosity has progressed towards 2 × 1034 cm−2s−1. In order to guarantee a successful and ambitious physics programme under these conditions, the CMS trigger system has been upgraded. The upgraded CMS Level-1 trigger is designed to improve performance at high luminosity and large number of simultaneous inelastic collisions per crossing. The trigger design, implementation and commissioning are summarised, and performance results are described.\n\nThe biomedically focused brain research is largely performed on laboratory mice considering a high homology between the human and mouse genomes. A brain has an intricate and highly complex geometrical structure that is hard to display and analyse using only 2D methods. Applying some fast and efficient methods of brain visualization in 3D will be crucial for the neurobiology in the future. A post-mortem analysis of experimental animals' brains usually involves techniques such as magnetic resonance and computed tomography. These techniques are employed to visualize abnormalities in the brains' morphology or reparation processes. The X-ray computed microtomography (micro CT) plays an important role in the 3D imaging of internal structures of a large variety of soft and hard tissues. This non-destructive technique is applied in biological studies because the lab-based CT devices enable to obtain a several-micrometer resolution. However, this technique is always used along with some visualization methods, which are based on the tissue staining and thus differentiate soft tissues in biological samples. Here, a modified chemical contrasting protocol of tissues for a micro CT usage is introduced as the best tool for ex vivo 3D imaging of a post-mortem mouse brain. This way, the micro CT provides a high spatial resolution of the brain microscopic anatomy together with a high tissue differentiation contrast enabling to identify more anatomical details in the brain. As the micro CT allows a consequent reconstruction of the brain structures into a coherent 3D model, some small morphological changes can be given into context of their mutual spatial relationships.\n\nHigh precision physics at future colliders as the International Linear Collider (ILC) require unprecedented high precision in the determination of the energy of final state particles. The needed precision will be achieved thanks to the Particle Flow algorithms (PF) which require highly granular and hermetic calorimeters systems. The physical proof of concept of the PF was performed in the previous campaign of beam tests of physic prototypes within the CALICE collaboration. One of these prototypes was the physics prototype of the Silicon-Tungsten Electromagnetic Calorimeter (SiW-ECAL) for the ILC. In this document we present the latest news on R&D of the next generation prototype, the technological prototype with fully embedded very front-end (VFE) electronics, of the SiW-ECAL. Special emphasis is given to the presentation and discussion of the first results from the beam test done at DESY in June 2017. The physics program for such beam test consisted in the calibration and commissioning of the current set of available SiW ECAL modules; the test of performance of individual slabs under 1T magnetic fields; and the study of electromagnetic showers events.\n\nThe Mu2e experiment at Fermilab will search for Charged Lepton Flavor Violating conversion of a muon to an electron in an atomic field. The Mu2e detector is composed of a tracker, an electromagnetic calorimeter and an external system, surrounding the solenoid, to veto cosmic rays. The calorimeter plays an important role to provide: a) excellent particle identification capabilities; b) a fast trigger filter; c) an easier tracker track reconstruction. Two disks, located downstream of the tracker, contain 674 pure CsI crystals each. Each crystal is read out by two arrays of UV-extended SiPMs. The choice of the crystals and SiPMs has been finalized after a thorough test campaign. A first small scale prototype consisting of 51 crystals and 102 SiPM arrays has been exposed to an electron beam at the BTF (Beam Test Facility) in Frascati. Although the readout electronics were not final, results show that the current design is able to meet the timing and energy resolution required by the Mu2e experiment.\n\nThis work focuses on the design of a semiconductor pixelated γ-ray camera with a pixel size of 1 mm2. The cost of semiconductor manufacturing is mainly driven by economies of scale, which makes silicon the cheapest semiconductor material due to its widespread utilization. The energy of γ-photons used in radiation therapy are in a range, in which the dominant interaction mechanism is Compton scattering in every conceivable sensor material. Since the Compton scattering cross section is linearly dependent upon Z, it is less rewarding to utilize high Z sensor materials, than it is in the case of X-ray detectors (X-rays interact also via the photoelectric effect whose cross section scales proportional to Zn, where n is ≈ 4,5). For the stated reasons it was decided to use the low Z material silicon (Z = 14) despite its worse detection efficiency. The proposed detector is designed as a portal detector to be used in radiation cancer therapy. The purpose of the detector is to ensure correct patient alignment, spatial dose monitoring and to provide the feedback necessary for an emergency shutdown should the spatial dose rate profile deviate from the treatment plan. Radiation therapy equipment is complex and thus failure prone and the consequences of malfunction are often life threatening. High spatial resolution and high detection efficiency are not a high design priority. The detector design priorities are focused up on radiation hardness, robustness and the ability to cover a large area cost efficiently. The quintessential idea of the PanterPix detector exploits the relaxed spatial resolution requirement to achieve the stated goals. The detector is composed of submodules, each submodule consisting of a Si sensor with an array of fully depleted detection diodes and 8 miniature custom design readout ASICs collecting and measuring the minuscule charge packets generated due to ionization in the PN junctions.\n\nIn this letter, we report the observation of fast neutrons generated when a positive acceleration potential is applied to an array of orientated carbon nanotubes, which are used as an ion source. The neutrons with energy of 2.45 MeV are generated as a result of D-D fusion reaction. The dependencies of the neutron yield on the value of the applied potential and residual pressure of deuterium are measured. The proposed approach is planned to be used for the development of compact neutron generators.\n\nIn the framework of quantum electrodynamics the theory of a new type of X-ray radiation emitted by relativistic electrons at channeling conditions is developed beyond the dipole approximation. This radiation takes place when the electron is reflected by or crossed the crystal surface which coincides with one of the crystallographic planes. It is shown that in this case one reveals two kinds of radiation: channeling radiation by reflected particles and diffracted channeling radiation by passed particles. The radiation can be applied for investigation of the crystal surface.\n\nWe develop an original method for calculation of radiation from a charge moving in the presence of a dielectric object. The method can be applied to objects which are larger than the wavelengths under consideration. First, the field of a charge in an infinite medium (without external boundaries) is calculated. Further the field at the external boundary of the object (\"the aperture\") is found using the Snell's and Fresnel's laws. At final step of this technique, we calculate the field outside the target using Stratton-Chu formulae (\"aperture integrals\"). Contrary to the ray-optic technique, this method is valid for the observation point with arbitrary wave parameter (including Fraunhofer area) as well as in neighborhoods of focuses and caustics. We apply the method developed to the cone with vacuum channel where the charge moves (axially symmetrical problem). As well, this problem is simulated using COMSOL Multiphysics. Comparing results of both techniques one can conclude that the aperture method can be applied even for relatively small objects which have the size of several wavelengths. It is important as well that the accuracy of calculations increases with an increase in the distance from the aperture.\n\nThe Tile Calorimeter (TileCal) is the hadronic sampling calorimeter of the ATLAS experiment at the Large Hadron Collider (LHC). TileCal uses iron absorbers and scintillators as active material and it covers the central region | η| < 1.7. Jointly with the other sub-detectors it is designed for measurements of hadrons, jets, tau-particles and missing transverse energy. It also assists in muon identification. TileCal is regularly monitored and calibrated by several different calibration systems: a Cs radioactive source, a laser light system to check the PMT response, and a charge injection system (CIS) to check the front-end electronics. These calibration systems, in conjunction with data collected during proton-proton collisions, Minimum Bias (MB) events, provide extensive monitoring of the instrument and a means for equalizing the calorimeter response at each stage of the signal propagation. The performance of the calorimeter has been established with cosmic ray muons and the large sample of the proton-proton collisions and compared to Monte Carlo (MC) simulations. The response of high momentum isolated muons is also used to study the energy response at the electromagnetic scale, isolated hadrons are used as a probe of the hadronic response. The calorimeter time resolution is studied with multijet events. A description of the different TileCal calibration systems and the results on the calorimeter performance during the LHC Run 2 are presented. The results on the pile-up noise and response uniformity studies are also discussed.\n\nA Multi Purpose Detector (MPD) is being constructed for the Heavy-Ion Collider at Dubna (NICA). One of the important components of MPD setup is an Electromagnetic Calorimeter, which will operate in the magnetic field of MPD solenoid 0.5 T and provide good energy and space resolution to detect particles in the energy range from ∼20 MeV to few GeV . For this purpose the, so-called, \"shashlyk\" sampling structure with the fiber readout to the silicon Multi Pixel Avalanche Photodetector is used. Serious modifications in comparison to conventional \"shaslyk\" calorimeter are proposed to improve the properties of device. These modifications are presented in the report along with the beam test results obtained with the MPD/NICA module prototypes.\n\nWe proceed with investigation of specific dielectric target that effectively concentrates Cherenkov radiation from a charged particle bunch into a small vicinity of the focus point located at the symmetry axis of the target. The case of \"non-ideal concentration\" where the charge velocity differs from the designed one was considered theoretically in our previous paper. In particular, we have noted that geometrical rays form caustics in this case, and areas of radiation concentration are shifted with respect to the designed focus point. Since the direction of this shift relates to the sign of the charge velocity deviation, this effect can be used for diagnostics of bunch velocity. Here we perform numerical simulations in COMSOL using frequency domain solver and compare simulated results with theoretical ones. In particular, we show that simulated focus area is indeed shifted with change in charge velocity and the position of this area correlate very well with analytical predictions.\n\nFunctional Magnetic Resonance Imaging (fMRI) based on Blood Oxygenation Level Dependent (BOLD) contrast has become one of the most powerful tools in neuroscience research. On the other hand, fMRI approaches have seen limited use in the study of spinal cord and subcortical brain regions (such as the brainstem and portions of the diencephalon). Indeed obtaining good BOLD signal in these areas still represents a technical and scientific challenge, due to poor control of physiological noise and to a limited overall quality of the functional series. A solution can be found in the combination of optimized experimental procedures at acquisition stage, and well-adapted artifact mitigation procedures in the data processing. In this framework, we studied two different data processing strategies to reduce physiological noise in cortical and subcortical brain regions and in the spinal cord, based on the aCompCor and RETROICOR denoising tools respectively. The study, performed in healthy subjects, was carried out using an ad hoc isometric motor task. We observed an increased signal to noise ratio in the denoised functional time series in the spinal cord and in the subcortical brain region.\n\nAdvancement in synchrotron and free electron laser facilities means that X-ray beams with higher intensity than ever before are being created. The high brilliance of the X-ray beam, as well as the ability to use a range of X-ray energies, means that they can be used in a wide range of applications. One such application is Resonant Inelastic X-ray Scattering (RIXS). RIXS uses the intense and tuneable X-ray beams in order to investigate the electronic structure of materials. The photons are focused onto a sample material and the scattered X-ray beam is diffracted off a high resolution grating to disperse the X-ray energies onto a position sensitive detector. Whilst several factors affect the total system energy resolution, the performance of RIXS experiments can be limited by the spatial resolution of the detector used. Electron-Multiplying CCDs (EM-CCDs) at high gain in combination with centroiding of the photon charge cloud across several detector pixels can lead to sub-pixel spatial resolution of 2–3 μm. X-ray radiation can cause damage to CCDs through ionisation damage resulting in increases in dark current and/or a shift in flat band voltage. Understanding the effect of radiation damage on EM-CCDs is important in order to predict lifetime as well as the change in performance over time. Two CCD-97s were taken to PTB at BESSY II and irradiated with large doses of soft X-rays in order to probe the front and back surfaces of the device. The dark current was shown to decay over time with two different exponential components to it. This paper will discuss the use of EM-CCDs for readout of RIXS spectrometers, and limitations on spatial resolution, together with any limitations on instrument use which may arise from X-ray-induced radiation damage.\n\nA two-phase argon detector is generally suitable for the direct detection of weakly interacting massive particle (WIMP) dark matter owing to its high rejection power against electron recoil background events. However, ionization signal (S2) has not been effectively used for argon in current experiments because its basic properties and discrimination power from S2 signal in the low-energy region are not well known, as compared with xenon. The scope of this study is evaluation of S2 properties at a low-energy region of about 40 keVnr and its discrimination power between electron recoils and nuclear recoils based on results from a prototype LAr time projection chamber. The drift-field was varied from null to 3 kV/cm. The detection feasibility for low-mass WIMP with argon is also discussed.\n\nThe \"trap pumping\" technique has seen considerable use over recent years as a means to probe the intrinsic properties of silicon defects that can impact charge transfer performance within CCD-based technologies. While the theory behind the technique is reasonably well understood, it has to date only been applied to relatively simple pixel designs where the motion of charge between pixel phases is fairly easy to predict. For some devices, the intrinsic pixel architecture is more complex and can consist of unequal phase sizes and additional implants that deform the electronic potential. Here, we present the implementation of the trap pumping technique for the CCD201-20, a 2-phase Teledyne e2v EMCCD. Clocking schemes are presented that can provide the location of silicon defects to sub-micron resolution. Experimental techniques that allow determination of trap energy levels and emission cross sections are presented. These are then implemented on an irradiated CCD201-20 to determine the energy level and emission cross section for defects thought to be the double acceptor state of the silicon divacancy (VV−−) and carbon-phosphorus (CiPs) pairs. An improvement in charge transfer performance through optimised parallel clock delay is demonstrated and found to correlate with the properties of defects found using the trap pumping technique.\n\nIn the first 10 seconds of a core-collapse supernova, almost all of its progenitor's gravitational potential, O(1053 ergs), is carried away in the form of neutrinos. These neutrinos, with O(10 MeV) kinetic energy, can interact via coherent elastic neutrino-nucleus scattering (CEνNS) depositing O(1 keV) in detectors. In this work we describe the performances of low-background dark matter detectors, such as LUX-ZEPLIN (LZ), optimized for detecting low-energy depositions, in detecting these neutrino interactions. For instance, a 27 M⊙ supernova at 10 kpc is expected to produce ∼350 neutrino interactions in the 7-tonne liquid xenon active volume of LZ. Based on the LS220 EoS neutrino flux model for a SN, the Noble Element Simulation Technique (NEST), and predicted CEνNS cross-sections for xenon, to study energy deposition and detection of SN neutrinos in LZ. We simulate the response of the LZ data acquisition system (DAQ) and demonstrate its capability and limitations in handling this interaction rate. We present an overview of the LZ detector, focusing on the benefits of liquid xenon for supernova neutrino detection. We discuss energy deposition and detector response simulations and their results. We present an analysis technique to reconstruct the total number of neutrinos and the time of the supernova core bounce.\n\nCompared to conventional TFT-based X-ray imaging devices, CMOS-based X-ray imaging sensors are considered next generation because they can be manufactured in very small pixel pitches and can acquire high-speed images. In addition, CMOS-based sensors have the advantage of integration of various functional circuits within the sensor. The image quality can also be improved by the high fill-factor in large pixels. If the size of the subject is small, the size of the pixel must be reduced as a consequence. In addition, the fill factor must be reduced to aggregate various functional circuits within the pixel. In this study, 3T-APS (active pixel sensor) with photodiodes of four different sizes were fabricated and evaluated. It is well known that a larger photodiode leads to improved overall performance. Nonetheless, if the size of the photodiode is > 1000 μm2, the degree to which the sensor performance increases as the photodiode size increases, is reduced. As a result, considering the fill factor, pixel-pitch > 32 μm is not necessary to achieve high-efficiency image quality. In addition, poor image quality is to be expected unless special sensor-design techniques are included for sensors with a pixel pitch of 25 μm or less.\n\nDuring the so-called Phase-2 Upgrade, the CMS experiment at CERN will undergo significant improvements to cope with the 10-fold luminosity increase of the High Luminosity LHC (HL-LHC) era. Especially the forward calorimetry will suffer from very high radiation levels and intensified pileup in the detectors. For this reason, the CMS collaboration is designing a High Granularity Calorimeter (HGCAL) to replace the existing endcap calorimeters. It features unprecedented transverse and longitudinal segmentation for both electromagnetic (CE-E) and hadronic (CE-H) compartments. The CE-E and a large fraction of CE-H will consist of a sandwich structure with silicon as active detector material. This paper presents an overview of the ongoing sensor development for the HGCAL and highlights important design features and measurement techniques. The design and layout of an 8-inch silicon sensor prototype is shown. The hexagonal sensors consist of 235 pads, each with an area of about 1 cm2. Furthermore, Synopsys TCAD simulations regarding the high voltage stability of the sensors for different geometric parameters are performed. Finally, two different IV characterisation methods are compared on the same sensor.\n\nCurrent high energy particle physics experiments at the LHC use hybrid silicon detectors, in both pixel and strip configurations, for their inner trackers. These detectors have proven to be very reliable and performant. Nevertheless, there is great interest in depleted CMOS silicon detectors, which could achieve a similar performance at lower cost of production. We present recent developments of this technology in the framework of the ATLAS CMOS demonstrator project. In particular, studies of two active sensors from LFoundry, CCPD_LF and LFCPIX, are shown.\n\nThe problem of the stability of planar channeling of high-energy positively charged particles in a crystal was studied on the basis of analytical calculation and numerical simulation. The evolution of the spectral density of radiation of particles with a decrease of the angle between particle momentum and atomic strings was investigated. The frequency of the peak in radiation, that corresponds to scattering by individual atomic strings in the case of planar channeling, was found. The analytical calculation was carried out in the parabolic planar potential approximation, while in the numerical simulation the Doyle-Turner approximation was used.\n\nA shashlik-type electromagnetic calorimeter will be produced in Hall A of Jefferson Laboratory for the Solenoidal Large Intensity Device (SoLID). Wavelength-shifting (WLS) fibers and clear fibers will be used as the light guide part of the calorimeter. The blue light from scintillators is converted into green light by WLS fibers and is carried out to the back of the calorimeters for readout. Since the magnetic field of SoLID reaches about 1.5 T behind the calorimeters, the design is to use clear fibers to further guide the light out of the solenoid for readout by PMTs. Therefore, it is important to study the perfomance of WLS and clear fibers. This paper describes a comparative test of two different WLS fibers and a light attenuation test for a clear fiber. The results show that the performance of the two WLS fibers is the same under large curvature bending, and that the bending has no effect on the light transmission through the clear fiber. In addition, a comparison test for two fiber end-face reflective materials is also reported. It reveals that the use of silver ink as a reflective material can increase the light yield by 30%. Thereby, an optimized prototype based on the above experimental results was built and the basic performance was tested.\n\nIn this paper the effective potential describing interaction of a scalar quantum particle with arbitrary nonuniform laser field is derived for a wide spectrum of the particle energies. The presented method allows to take into account all the features of the effective potential for a scalar particle. The derived expression for effective potential for quantum particle has the same form as the one presented earlier for a classical particle. A special case for channeling of a quantum particle as well as accompanying channeling radiation in a field formed by two crossed plane laser waves is considered. It is shown that relativistic particles moving near the laser channel bottom should be examined as quantum ones at both arbitrarily large longitudinal energies and laser fields of accessible intensities.\n\nThere is a particular class of unavoidable backgrounds that plague low-background experiments and rare event searches, particularly those searching for nuclear recoil event signatures: decaying daughters of the 238U nuclear decay chain, which result from radon plate-out on detector materials. One such daughter isotope, 210Po, undergoes α-decay and produces a recoiling 103 keV 206Pb nucleus. To characterize this important background in the context of noble element detectors, we have implemented a triggered source for these 206Pb recoils in a dual-phase xenon time projection chamber (Xe TPC) within the Davis Xenon R&D testbed system (DAX). By adhering 210Po to the surface of a PIN diode and electrically floating the diode on the cathode of the TPC, we tag the α signals produced in the PIN diode and trigger on the correlated nuclear recoils in the liquid xenon (LXe). We discuss our methods for 210Po deposition, electronic readout of the PIN diode signals at high voltage, and analysis methods for event selection.\n\nThe expected increase of the particle flux at the high luminosity phase of the LHC (HL-LHC) with instantaneous luminosities up to 7.5⋅1034 cm−2s−1 will have a severe impact on the ATLAS detector performance. The pile-up is expected to increase on average to 200 interactions per bunch crossing. The reconstruction performance for electrons, photons as well as jets and transverse missing energy will be severely degraded in the end-cap and forward region. A High Granularity Timing Detector (HGTD) is proposed in front of the liquid Argon end-cap and forward calorimeters for pile-up mitigation. This device should cover the pseudo-rapidity range of 2.4 to about 4.0. Low Gain Avalanche Detectors (LGAD) technology has been chosen as it provides an internal gain good enough to reach large signal over noise ratio needed for excellent time resolution. The requirements and overall specifications of the High Granular Timing Detector at the HL-LHC will be presented as well as the conceptual design of its mechanics and electronics. Beam test results and measurements of irradiated LGAD silicon sensors, such as gain and timing resolution, will be shown.\n\nThe first proof of principle experiment with a prototype of a Time-of-Flight (TOF) - Cherenkov detector of relativistic heavy ions (RHI) exploiting a liquid Iodine Naphthalene radiator has been performed at Cave C at GSI (Darmstadt, Germany). A conceptual design for a liquid Cherenkov detector was proposed as a prototype for the future TOF measurements at the Super-FRS by detection of total number of Cherenkov photons. The ionization energy loss of RHI in a liquid radiator decreases only slightly this number, while in a solid radiator changes sufficiently not the total number of ChR photons, but ChR angular and spectral distributions. By means of computer simulations, we showed that these distributions are very sensitive to the isotope mass, due to different stopping powers of isotopes with initial equal relativistic factors. The results of simulations for light (Li, Be) and heavy (Xe) isotopes at 500–1000 MeV/u are presented indicating the possibility to use the isotopic effect in ChR of RHI as the mass selector.\n\nThe paper presents the performance of the UFXC32K—a hybrid pixel detector readout chip working with CdTe detectors. The UFXC32K has a pixel pitch of 75 μm and can cope with both input signal polarities. This functionality allows operating with widely used silicon sensors collecting holes and CdTe sensors collecting electrons. This article describes the chip focusing on solving the issues connected to high-Z sensor material, namely high leakage currents, slow charge collection time and thick material resulting in increased charge-sharring effects. The measurements were conducted with higher X-ray energies including 17.4 keV from molybdenum. Conclusions drawn inside the paper show the UFXC32K's usability for CdTe sensors in high X-ray energy applications.\n\nIn this work, we have focused on Timepix detectors coupled with the semi-insulating GaAs material sensor. We used undoped bulk GaAs material with the thickness of 350 μm. We prepared and tested four pixelated detectors with 165 μm and 220 μm pixel size with two versions of technology preparation, without and with wet chemically etched trenches around each pixel. We have carried out adjustment of GaAs Timepix detectors to optimize their performance. The energy calibration of one GaAs Timepix detector in Time-over-threshold mode was performed with the use of 241Am and 133Ba radioisotopes. We were able to detect γ-photons with the energy up to 160 keV. The X-ray imaging quality of GaAs Timepix detector was tested with X-ray source using various samples. After flat field we obtained very promising imaging performance of tested GaAs Timepix detectors.\n\nWe consider a point charge and Gaussian bunch of charged particles moving along the axis of a circular perfectly conducting pipe with uniform dielectric filling and open end. It is supposed that this semi-infinite waveguide is located in collinear infinite vacuum pipe with perfectly conducting walls and larger diameter. We deal with two cases corresponding to the open end of the inner waveguide with and without flange. Radiation produced by a charge or bunch flying from dielectric part to wide vacuum part is analyzed. We use modified residue-calculus technique and construct rigorous analytical theory describing scattered field in each sub-area of the structure. Cherenkov radiation generated in the dielectric waveguide and penetrating into the vacuum regions of the structure is of main interest throughout the present paper. We show that this part of radiation can be easily analyzed using the presented formalism. We also perform numerical simulation in CST PS code and verify the analytical results.\n\nA dispersion interferometer (DI) system is one of the more promising density measurement methods for large, high density fusion devices as they have considerable immunity to mechanical vibration and a shorter wavelength which helps to prevent fringe jump errors. In this paper, a DI system with a photoelastic modulator (PEM) has been designed for high density measurements on the EAST tokamak with vertical double pass optical layout. The bench test of all system components was done, especially for the specific nonlinear crystal for DI system. The second hamonic power with the AgGaSe2 nonlinear crystal can reach to 22.85 μW at 20 W fundamental power of CO2 laser. The second-harmonic power based on the AgGaSe2 show a good linear relationship with the various power of the CO2 laser. Based on the bench test results, the new DI system design will be realized and utilized on EAST.\n\nThe ANDA experiment at FAIR will use DIRC detectors for the separation of hadrons. The compactness of the ANDA detector requires the image planes of these detectors to be placed inside the magnetic field of the solenoid. Due to this and other boundary conditions MCP-PMTs were identified as the only suitable photon sensors. Until recently the major obstacle for an application of MCP-PMTs in high rate experiments like ANDA were serious aging problems which led to damage at the photo-cathode and a fast declining quantum efficiency as the integrated anode charge (IAC) increased. With new countermeasures against the aging, in particular due to the application of an atomic layer deposition (ALD) technique to coat the MCP pores, the lifetime of MCP-PMTs has meanwhile increased by a factor >50 which is fully sufficient for ANDA. The recent results of our long-term lifetime measurements are discussed. New 2-inch MCP-PMT prototypes from Hamamatsu show an encouraging behavior. However, the currently best performing MCP-PMT is a 2-inch PHOTONIS tube with two ALD-layers which reaches an IAC of >16 C/cm2 without any visible sign of aging. In the second part of these proceedings a new data acquisition system of the PADIWA/TRB type is presented which allows a quasi-parallel measurement of many MCP-PMT performance parameters. Especially unwanted effects like dark-count rate, crosstalk, ion after-pulsing, and recoil electrons can be studied in more detail than ever before. Exemplary results for these parameters are shown. The discussed DAQ system will be used for the comprehensive data quality checks of the MCP-PMTs being built into the DIRCs.\n\nToroidal interferometry/polarimetry (TIP), poloidal polarimetry (PoPola), and Thomson scattering systems (TS) are major optical diagnostics being designed and developed for ITER. Each of them relies upon a sophisticated quantitative understanding of the electron response to laser light propagating through a burning plasma. Review of the theoretical results for two different applications is presented: interferometry/polarimetry (I/P) and polarization of Thomson scattered light, unified by the importance of relativistic (quadratic in vTe/c) electron kinetic effects. For I/P applications, rigorous analytical results are obtained perturbatively by expansion in powers of the small parameter τ = Te/me c2, where Te is electron temperature and me is electron rest mass. Experimental validation of the analytical models has been made by analyzing data of more than 1200 pulses collected from high-Te JET discharges. Based on this validation the relativistic analytical expressions are included in the error analysis and design projects of the ITER TIP and PoPola systems. The polarization properties of incoherent Thomson scattered light are being examined as a method of Te measurement relevant to ITER operational regimes. The theory is based on Stokes vector transformation and Mueller matrices formalism. The general approach is subdivided into frequency-integrated and frequency-resolved cases. For each of them, the exact analytical relativistic solutions are presented in the form of Mueller matrix elements averaged over the relativistic Maxwellian distribution function. New results related to the detailed verification of the frequency-resolved solutions are reported. The precise analytic expressions provide output much more rapidly than relativistic kinetic numerical codes allowing for direct real-time feedback control of ITER device operation.\n\nLiquid Argon Time Projection Chambers (LArTPCs) are ideally suited to perform long-baseline neutrino experiments aiming to measure CP violation in the lepton sector, and determine the ordering of the three neutrino mass eigenstates. LArTPCs have used projective wire readouts for charge detection since their conception in 1977. However, wire readouts are notoriously fragile and therefore a limiting factor in the design of any large mass detectors. Furthermore, a wire readout also introduces intrinsic ambiguities in event reconstruction. Within the ArgonCube concept—the liquid argon component of the DUNE near detector—we are developing a pixelated charge readout for LArTPCs. Pixelated charge readout systems represent the single largest advancement in the sensitivity of LArTPCs. They are mechanically robust and provide direct 3D readout, serving to minimise reconstruction ambiguities, enabling more advanced triggers, further reducing event pile-up and improving background rejection. This article presents first results from a pixelated LArTPC prototype built and operated in Bern.\n\nDiagnostic imaging based on the Nuclear Magnetic Resonance phenomenon has increasingly spread in the recent few decades, mainly owing to its exquisite capability in depicting a contrast between soft tissues, to its generally non-invasive nature, and to the priceless advantage of using non-ionizing radiation. Magnetic Resonance (MR)-based acquisition techniques allow gathering information on the structure (through Magnetic Resonance Imaging— MRI), the metabolic composition (through Magnetic Resonance Spectroscopy—MRS), and the functioning (through functional MRI —fMRI) of the human body. MR investigations are the methods of choice for studying the brain in vivo, including anatomy, structural wiring and functional connectivity, in healthy and pathological conditions. Alongside the efforts of the clinical research community in extending the acquisition protocols to allow the exploration of a large variety of pathologies affecting diverse body regions, some relevant technological improvements are on the way to maximize the impact of MR in medical diagnostic. The development of MR scanners operating at ultra-high magnetic field (UHF) strength (⩾ 7 tesla), is pushing forward the spatial resolution of MRI and the spectral resolution of MRS, and it is increasing the specificity of fMRI to grey matter signal. UHF MR systems are currently in use for research purposes only; nevertheless, UHF technological advances are positively affecting MR investigations at clinical field strengths. To overcome the current major limitation of MRI, which is mostly based on contrast between tissues rather than on absolute measurements of physical quantities, a new acquisition modality is under development, which is referred as Magnetic Resonance Fingerprinting technique. Finally, as neuroimaging data acquired worldwide are reaching the typical size of Big Data, dedicated technical solutions are required to mine large amount of information and to identify specific biomarkers of pathological conditions.\n\nIn DUNE, the event timing provided by the detection of the relatively prompt scintillation photons will improve spatial resolution in the drift direction of the time-projection chamber (TPC) and is especially useful for non-beam physics topics such as supernova neutrinos and nucleon decay. The baseline design for the first 10kt single phase TPC fits the photon detector system in the natural gap between the wire planes of adjacent TPC volumes. A prototype photon detector design utilizes wavelength-shifter coated plates to convert the vacuum ultraviolet scintillation light to the optical and commercially-produced wavelength-shifting light guides to trap some of this light and transport it to an array of silicon photomultipliers at the end. This system and the testing performed to characterize the system and determine the efficiency are discussed.\n\nDouble silicon-on-insulator (DSOI) sensors composed of two thin silicon layers and one thick silicon layer have been developed since 2011. The thick substrate consists of high resistivity silicon with p-n junctions while the thin layers are used as SOI-CMOS circuitry and as shielding to reduce the back-gate effect and crosstalk between the sensor and the circuitry. In 2014, a high-resolution integration-type pixel sensor, INTPIX8, was developed based on the DSOI concept. This device is fabricated using a Czochralski p-type (Cz-p) substrate in contrast to a single SOI (SSOI) device having a single thin silicon layer and a Float Zone p-type (FZ-p) substrate. In the present work, X-ray spectra of both DSOI and SSOI sensors were obtained using an Am-241 radiation source at four gain settings. The gain of the DSOI sensor was found to be approximately three times that of the SSOI device because the coupling capacitance is reduced by the DSOI structure. An X-ray imaging demonstration was also performed and high spatial resolution X-ray images were obtained.\n\nImaging technology based on gamma-ray sources has been extensively used in non-destructive testing (NDT) to detect any possible internal defects in products without changing their shapes or functions. However, such technology has been subject to increasingly stricter regulations, and an international radiation-safety management system has been recently established. Consequently, radiation source location in NDT systems has become an essential process, given that it can prevent radiation accidents. In this study, we focused on developing a monitoring system that can detect, in real time, the position of a radioactive source in the source guide tube of a projector. We fabricated a lead iodide (PbI2) dosimeter based on the particle-in-binder method, which has a high production yield and facilitates thickness and shape adjustment. Using a gamma-ray source, we then tested the reproducibility, linearity of the dosimeter response, and the dosimeter's percentage interval distance (PID). It was found that the fabricated PbI2 dosimeter yields highly accurate, reproducible, and linear dose measurements. The PID analysis—conducted to investigate the possibility of developing a monitoring system based on the proposed dosimeter—indicated that the valid detection distance was approximately 11.3 cm. The results of this study are expected to contribute to the development of an easily usable radiation monitoring system capable of significantly reducing the risk of radiation accidents.\n\nThe radioactive daughters isotope of 222Rn are one of the highest risk contaminants in liquid xenon detectors aiming for a small signal rate. The noble gas is permanently emanated from the detector surfaces and mixed with the xenon target. Because of its long half-life 222Rn is homogeneously distributed in the target and its subsequent decays can mimic signal events. Since no shielding is possible this background source can be the dominant one in future large scale experiments. This article provides an overview of strategies used to mitigate this source of background by means of material selection and on-line radon removal techniques.\n\nThe accurate characterization of a photomultiplier tube (PMT) is crucial in a wide-variety of applications. However, current methods do not give fully accurate representations of the response of a PMT, especially at very low light levels. In this work, we present a new and more realistic model of the response of a PMT, called the cascade model, and use it to characterize two different PMTs at various voltages and light levels. The cascade model is shown to outperform the more common Gaussian model in almost all circumstances and to agree well with a newly introduced model independent approach. The technical and computational challenges of this model are also presented along with the employed solution of developing a robust GPU-based analysis framework for this and other non-analytical models.\n\nPrompt fission Υ -ray energy spectra in spontaneous fission of 252Cf has been measured using a 3'' × 6'' LaBr3(Ce) detector. Unfolding of the measured Υ -ray energy spectra has been carried out using GRAVEL method. The response matrix of the detector has been simulated using GEANT4 and the unfolding of Υ -ray energy spectra for 60Co and 137Cs sources have been validated. This unfolding technique has then been applied to the prompt gamma spectra obtained from the spontaneous fission of 252Cf.\n\nThe Muon g−2 Experiment at Fermilab is expected to start data taking"
    }
}