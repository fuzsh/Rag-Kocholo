{
    "id": "dbpedia_2236_2",
    "rank": 36,
    "data": {
        "url": "https://vcell.org/webstart/VCell_Tutorials/VCell_Help/topics/ch_3/BioModelApplications/ParameterEstimation/parameterEstimationMethods.html",
        "read_more_link": "",
        "language": "en",
        "title": "COPASI Optimization Methods Overview",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Evolutionary Programming\n\nEvolutionary programming (EP) is a computational technique that mimics evolution and is based on reproduction and selection. An EP algorithm is composed of individuals that reproduce and compete, each one is a potential solution to the (optimization) problem and is represented by a 'genome' where each gene corresponds to one adjustable parameter. At each generation of the EP, each individual reproduces asexually, i.e. divides into two individuals. One of these contains exactly the same 'genome' as the parent while the other suffers some mutations(the parameter values of each gene change slightly). At the end of the generation, the algorithm has double the number of individuals. Then each of the individuals is confronted with a number of others to count how many does it outperform (the number of wins is the number of these competitors that represent worse solutions than itself).All the individuals are ranked by their number of wins, and the population is again reduced to the original number of individuals by eliminating those which have worse fitness (solutions).\n\nEvolution Strategy (SRES)\n\nEvolutionary Strategies with Stochastic Ranking (SRES) [Runarsson00] is similar to . However, a parent has multiple offsprings during each generation. Each offspring will contain a recombination of genes with another parent and additional mutations. The algorithm assures that each parameter value will be within its boundaries. But constraints to the solutions may be violated.\n\nGenetic Algorithm\n\nThe genetic algorithm (GA) [Baeck97 Baeck93 Michalewicz94 Mitchell95] is a computational technique that mimics evolution and is based on reproduction and selection. A GA is composed of individuals that reproduce and compete, each one is a potential solution to the (optimization) problem and is represented by a 'genome' where each gene corresponds to one adjustable parameter. At each generation of the GA, each individual is paired with one other at random for reproduction.Two offspring are produced by combining their genomes and allowing for 'cross-over', i.e., the two new individuals have genomes that are formed from a combination of the genomes of their parents. Also each new gene might have mutated, i.e.the parameter value might have changed slightly. At the end of the generation, the algorithm has double the number of individuals. Then each of the individuals is confronted with a number of others to count how many does it outperform (the number of wins is the number of these competitors that represent worse solutions than itself). All the individuals are ranked by their number of wins, and the population is again reduced to the original number of individuals by eliminating those which have worse fitness (solutions).\n\nGenetic Algorithm SR\n\nThe genetic algorithm with stochastic ranking is very similar to the before described with tournament selection. With two exception which are the mutations are not forced to be within the boundaries and the selection is done through a bubble sort with a random factor\n\nHooke and Jeeves\n\nThe method of Hooke and Jeeves is a direct search algorithm that searches for the minimum of a nonlinear function without requiring (or attempting to calculate) derivatives of the function. Instead it is based on a heuristic that suggests a descent direction using the values of the function calculated in a number of previous iterations.\n\nLevenberg - Marquardt\n\nLevenberg-Marquardt is a gradient descent method. It is a hybrid between the steepest descent and the Newton methods.\n\nNelder - Mead\n\nThis method also known as the simplex method is due to Nelder and Mead [Nelder65]. A simplex is a polytope of N+1 vertices in N dimensions. The objective function is evaluated at each vertex. Dependent on these calculated values a new simplex is constructed. The simplest step is to replace the worst point with a point reflected through the centroid of the remaining N points.If this point is better than the best current point, then we can try stretching exponentially out along this line. On the other hand,if this new point isn't much better than the previous value then we are stepping across a valley, so we shrink the simplex towards the best point.\n\nParticle Swarm\n\nThe particle swarm optimization method suggested by Kennedy and Eberhart [Kennedy95] is inspired by a flock of birds or a school of fish searching for food. Each particle has a position Xi and a velocity Vi in the parameter space. Additionally, it remembers its best achieved objective value O and position Mi. Dependent on its own information and the position of its best neighbor (a random subset of particles of the swarm) a new velocity is calculated. With this information the position is updated.\n\nRandom Search\n\nRandom search is an optimization method that attempts to find the optimum by testing the objective function's value on a series of combinations of random values of the adjustable parameters. The random values are generated complying with any boundaries selected by the user, furthermore, any combinations of parameter values that do not fulfill constraints on the variables are excluded. This means that the method is capable of handling bounds on the adjustable parameters and fulfilling constraints. For infinite number of iterations this method is guaranteed to find the global optimum of the objective function. In general one is interested in processing a very large number of iterations.\n\nSimulated Annealing\n\nSimulated annealing is an optimization algorithm first proposed by Kirkpatrick et al. [Kirkpatrick83] and was inspired by statistical mechanics and the way in which perfect crystals are formed. Perfect crystals are formed by first melting the substance of interest, and then cooling it very slowly. At large temperatures the particles vibrate with wide amplitude and this allows a search for global optimum.As the temperature decreases so do the vibrations until the system settles to the global optimum (the perfect crystal). The simulated annealing optimization algorithm uses a similar concept: the objective function is considered a measure of the energy of the system and this is maintained constant for a certain number of iterations (a temperature cycle). In each iteration, the parameters are changed to a nearby location in parameter space and the new objective function value calculated; if it decreased, then the new state is accepted, if it increased then the new state is accepted with a probability that follows a Boltzmann distribution (higher temperature means higher probability of accepting the new state). After a fixed number of iterations, the stopping criterion is checked; if it is not time to stop, then the system's temperature is reduced and the algorithm continues.\n\nSteepest Descent\n\nSteepest descent is an optimization method that follows the direction of steepest descent on the hyper-surface of the objective function to find a local minimum. The direction of steepest descent is defined by the negative of the gradient of the objective function.\n\nPraxis\n\nPraxis is a direct search method (for a review see [Swann72]) that searches for the minimum of a nonlinear function without requiring(or attempting to calculate) derivatives of that function. Praxis was developed by Brent after the method proposed by Powell. The inspiration for Praxis was the well-known method of minimising each adjustable parameter (direction) at a time - the principal axes method.In Praxis directions are chosen that do not coincide with the principal axes, in fact if the objective function is quadratic then these will be conjugate directions, assuring a fast convergence rate.\n\nTruncated Newton\n\nThe Truncated Newton method is a sophisticated variant of the Newton optimization method. The Newton optimization method searches for theminimum of a nonlinear function by following descent directions determined from the function's first and second partial derivatives. TheTruncated Newton method does an incomplete (truncated) solution of a system of linear equations to calculate the Newton direction. This meansthat the actual direction chosen for the descent is between the steepest descent direction and the true Newton direction."
    }
}