{
    "id": "dbpedia_2236_0",
    "rank": 26,
    "data": {
        "url": "https://github.com/copasi/python-copasi-testsuite",
        "read_more_link": "",
        "language": "en",
        "title": "testsuite: Python COPASI testing",
        "top_image": "https://opengraph.githubassets.com/bad624129b19d8d576244228cf088eea6e85e1aa5a47636acaffaa29860b63e9/copasi/python-copasi-testsuite",
        "meta_img": "https://opengraph.githubassets.com/bad624129b19d8d576244228cf088eea6e85e1aa5a47636acaffaa29860b63e9/copasi/python-copasi-testsuite",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Python COPASI testing. Contribute to copasi/python-copasi-testsuite development by creating an account on GitHub.",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/copasi/python-copasi-testsuite",
        "text": "This project hosts a testing framework for COPASI. Next to a collection of tests found under the test-suite folder. Under the copasi_test folder all the manipulation / comparison routines are housed.\n\nThe test suite should work with python 2.x and python 3.x, provided the following packages are installed:\n\npython-copasi\n\npandas\n\nStill work in progress, currently most inspection is done interactively using jupyter notebooks. To invoke from the command line:\n\nwhere\n\n<Test> is a full path to the folder of the test suite, or a test subfolder thereof. All tests found will be run.\n\n<CopasiSE> is the full path to a COPASI SE executable that is to be tested.\n\n<OutDir> is the output folder in which temporary models are created to run the tests, along with the test results.\n\n[Task Name] is an optional task name that the test suite should be filtered for, so that only tasks with that name will be run. Examples here include: Steady-State, Time-Course, Scan...\n\nTo simply invoke the comparison routines (and not re-run the tests), invoke from the command line:\n\nwhere\n\n<Test> is a full path to the folder of the test suite, or a test subfolder thereof. All tests found will be run.\n\n<CopasiSE> is the full path to a COPASI SE executable that is to be tested.\n\n<OutDir> is the output folder in which temporary models are created to run the tests, along with the test results.\n\nTo simply invoke the comparison routines (and not re-run the tests), invoke from the command line:\n\nwhere\n\n<Test> is a full path to the folder of the test suite, or a test subfolder thereof. All tests found will be run.\n\n<CopasiSE1> is the full path to a COPASI SE executable that is to be tested.\n\n<OutDir1> is the output folder in which temporary models are created to run the tests, along with the test results.\n\n<CopasiSE2> is the full path to a COPASI SE executable that is to be tested.\n\n<OutDir2> is the output folder in which temporary models are created to run the tests, along with the test results.\n\nWhen running the tests, usually an abbreviated output is expected, that would look something like:\n\nwhere basically a dot '.' is printed for each test / model that is being run, a 'W' for occurring warnings and an 'E' for a test failure. All failures will be printed once all tests are run.\n\nIt is possible to get the full output by specifying the environment variable COPASI_TEST_PRINT=1 prior to invoking the script. If that variable is set, the full output will be printed which would look something like this:\n\nhere the first column indicates the time in msecs, since the tests began, the second column the status information and the third one the message that was logged."
    }
}