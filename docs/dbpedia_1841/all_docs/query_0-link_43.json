{
    "id": "dbpedia_1841_0",
    "rank": 43,
    "data": {
        "url": "https://www.science.gov/topicpages/v/vlsi%2Bchip%2Bdesign",
        "read_more_link": "",
        "language": "en",
        "title": "vlsi chip design: Topics by Science.gov",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.science.gov/scigov/desktop/en/images/SciGov_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "VLSI design of a single chip reed-solomon encoder\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nTruong, T.K.; Deutsch, L.J.; Reed, I.S.\n\nA design for a single chip implementation of a Reed-Solomon encoder is presented. The architecture that leads to this single VLSI chip design makes use of a bit serial finite field multiplication algorithm.\n\nThe VLSI design of a single chip Reed-Solomon encoder\n\nNASA Technical Reports Server (NTRS)\n\nTruong, T. K.; Deutsch, L. J.; Reed, I. S.\n\n1982-01-01\n\nA design for a single chip implementation of a Reed-Solomon encoder is presented. The architecture that leads to this single VLSI chip design makes use of a bit serial finite field multiplication algorithm.\n\nOn testing VLSI chips for the big Viterbi decoder\n\nNASA Technical Reports Server (NTRS)\n\nHsu, I. S.\n\n1989-01-01\n\nA general technique that can be used in testing very large scale integrated (VLSI) chips for the Big Viterbi Decoder (BVD) system is described. The test technique is divided into functional testing and fault-coverage testing. The purpose of functional testing is to verify that the design works functionally. Functional test vectors are converted from outputs of software simulations which simulate the BVD functionally. Fault-coverage testing is used to detect and, in some cases, to locate faulty components caused by bad fabrication. This type of testing is useful in screening out bad chips. Finally, design for testability, which is included in the BVD VLSI chip design, is described in considerable detail. Both the observability and controllability of a VLSI chip are greatly enhanced by including the design for the testability feature.\n\nUW VLSI chip tester\n\nNASA Astrophysics Data System (ADS)\n\nMcKenzie, Neil\n\n1989-12-01\n\nWe present a design for a low-cost, functional VLSI chip tester. It is based on the Apple MacIntosh II personal computer. It tests chips that have up to 128 pins. All pin drivers of the tester are bidirectional; each pin is programmed independently as an input or an output. The tester can test both static and dynamic chips. Rudimentary speed testing is provided. Chips are tested by executing C programs written by the user. A software library is provided for program development. Tests run under both the Mac Operating System and A/UX. The design is implemented using Xilinx Logic Cell Arrays. Price/performance tradeoffs are discussed.\n\nA single VLSI chip for computing syndromes in the (225, 223) Reed-Solomon decoder\n\nNASA Technical Reports Server (NTRS)\n\nHsu, I. S.; Truong, T. K.; Shao, H. M.; Deutsch, L. J.\n\n1986-01-01\n\nA description of a single VLSI chip for computing syndromes in the (255, 223) Reed-Solomon decoder is presented. The architecture that leads to this single VLSI chip design makes use of the dual basis multiplication algorithm. The same architecture can be applied to design VLSI chips to compute various kinds of number theoretic transforms.\n\nArchitecture for VLSI design of Reed-Solomon encoders\n\nNASA Technical Reports Server (NTRS)\n\nLiu, K. Y.\n\n1981-01-01\n\nThe logic structure of a universal VLSI chip called the symbol-slice Reed-Solomon (RS) encoder chip is discussed. An RS encoder can be constructed by cascading and properly interconnecting a group of such VLSI chips. As a design example, it is shown that a (255,223) RD encoder requiring around 40 discrete CMOS ICs may be replaced by an RS encoder consisting of four identical interconnected VLSI RS encoder chips. Besides the size advantage, the VLSI RS encoder also has the potential advantages of requiring less power and having a higher reliability.\n\nUsing Ant Colony Optimization for Routing in VLSI Chips\n\nNASA Astrophysics Data System (ADS)\n\nArora, Tamanna; Moses, Melanie\n\n2009-04-01\n\nRapid advances in VLSI technology have increased the number of transistors that fit on a single chip to about two billion. A frequent problem in the design of such high performance and high density VLSI layouts is that of routing wires that connect such large numbers of components. Most wire-routing problems are computationally hard. The quality of any routing algorithm is judged by the extent to which it satisfies routing constraints and design objectives. Some of the broader design objectives include minimizing total routed wire length, and minimizing total capacitance induced in the chip, both of which serve to minimize power consumed by the chip. Ant Colony Optimization algorithms (ACO) provide a multi-agent framework for combinatorial optimization by combining memory, stochastic decision and strategies of collective and distributed learning by ant-like agents. This paper applies ACO to the NP-hard problem of finding optimal routes for interconnect routing on VLSI chips. The constraints on interconnect routing are used by ants as heuristics which guide their search process. We found that ACO algorithms were able to successfully incorporate multiple constraints and route interconnects on suite of benchmark chips. On an average, the algorithm routed with total wire length 5.5% less than other established routing algorithms.\n\nVLSI Design of SVM-Based Seizure Detection System With On-Chip Learning Capability.\n\nPubMed\n\nFeng, Lichen; Li, Zunchao; Wang, Yuanfa\n\n2018-02-01\n\nPortable automatic seizure detection system is very convenient for epilepsy patients to carry. In order to make the system on-chip trainable with high efficiency and attain high detection accuracy, this paper presents a very large scale integration (VLSI) design based on the nonlinear support vector machine (SVM). The proposed design mainly consists of a feature extraction (FE) module and an SVM module. The FE module performs the three-level Daubechies discrete wavelet transform to fit the physiological bands of the electroencephalogram (EEG) signal and extracts the time-frequency domain features reflecting the nonstationary signal properties. The SVM module integrates the modified sequential minimal optimization algorithm with the table-driven-based Gaussian kernel to enable efficient on-chip learning. The presented design is verified on an Altera Cyclone II field-programmable gate array and tested using the two publicly available EEG datasets. Experiment results show that the designed VLSI system improves the detection accuracy and training efficiency.\n\nA single chip VLSI Reed-Solomon decoder\n\nNASA Technical Reports Server (NTRS)\n\nShao, H. M.; Truong, T. K.; Hsu, I. S.; Deutsch, L. J.; Reed, I. S.\n\n1986-01-01\n\nA new VLSI design of a pipeline Reed-Solomon decoder is presented. The transform decoding technique used in a previous design is replaced by a time domain algorithm. A new architecture that implements such an algorithm permits efficient pipeline processing with minimum circuitry. A systolic array is also developed to perform erasure corrections in the new design. A modified form of Euclid's algorithm is implemented by a new architecture that maintains the throughput rate with less circuitry. Such improvements result in both enhanced capability and a significant reduction in silicon area, therefore making it possible to build a pipeline (31,15)RS decoder on a single VLSI chip.\n\nVLSI chips for vision-based vehicle guidance\n\nNASA Astrophysics Data System (ADS)\n\nMasaki, Ichiro\n\n1994-02-01\n\nSensor-based vehicle guidance systems are gathering rapidly increasing interest because of their potential for increasing safety, convenience, environmental friendliness, and traffic efficiency. Examples of applications include intelligent cruise control, lane following, collision warning, and collision avoidance. This paper reviews the research trends in vision-based vehicle guidance with an emphasis on VLSI chip implementations of the vision systems. As an example of VLSI chips for vision-based vehicle guidance, a stereo vision system is described in detail.\n\nArchitecture for VLSI design of Reed-Solomon encoders\n\nNASA Technical Reports Server (NTRS)\n\nLiu, K. Y.\n\n1982-01-01\n\nA description is given of the logic structure of the universal VLSI symbol-slice Reed-Solomon (RS) encoder chip, from a group of which an RS encoder may be constructed through cascading and proper interconnection. As a design example, it is shown that an RS encoder presently requiring approximately 40 discrete CMOS ICs may be replaced by an RS encoder consisting of four identical, interconnected VLSI RS encoder chips, offering in addition to greater compactness both a lower power requirement and greater reliability.\n\nArchitecture for VLSI design of Reed-Solomon encoders\n\nNASA Astrophysics Data System (ADS)\n\nLiu, K. Y.\n\n1982-02-01\n\nA description is given of the logic structure of the universal VLSI symbol-slice Reed-Solomon (RS) encoder chip, from a group of which an RS encoder may be constructed through cascading and proper interconnection. As a design example, it is shown that an RS encoder presently requiring approximately 40 discrete CMOS ICs may be replaced by an RS encoder consisting of four identical, interconnected VLSI RS encoder chips, offering in addition to greater compactness both a lower power requirement and greater reliability.\n\nVLSI design of an RSA encryption/decryption chip using systolic array based architecture\n\nNASA Astrophysics Data System (ADS)\n\nSun, Chi-Chia; Lin, Bor-Shing; Jan, Gene Eu; Lin, Jheng-Yi\n\n2016-09-01\n\nThis article presents the VLSI design of a configurable RSA public key cryptosystem supporting the 512-bit, 1024-bit and 2048-bit based on Montgomery algorithm achieving comparable clock cycles of current relevant works but with smaller die size. We use binary method for the modular exponentiation and adopt Montgomery algorithm for the modular multiplication to simplify computational complexity, which, together with the systolic array concept for electric circuit designs effectively, lower the die size. The main architecture of the chip consists of four functional blocks, namely input/output modules, registers module, arithmetic module and control module. We applied the concept of systolic array to design the RSA encryption/decryption chip by using VHDL hardware language and verified using the TSMC/CIC 0.35 m 1P4 M technology. The die area of the 2048-bit RSA chip without the DFT is 3.9 Ã 3.9 mm2 (4.58 Ã 4.58 mm2 with DFT). Its average baud rate can reach 10.84 kbps under a 100 MHz clock.\n\nNASA Space Engineering Research Center for VLSI System Design\n\nNASA Technical Reports Server (NTRS)\n\n1993-01-01\n\nThis annual report outlines the activities of the past year at the NASA SERC on VLSI Design. Highlights for this year include the following: a significant breakthrough was achieved in utilizing commercial IC foundries for producing flight electronics; the first two flight qualified chips were designed, fabricated, and tested and are now being delivered into NASA flight systems; and a new technology transfer mechanism has been established to transfer VLSI advances into NASA and commercial systems.\n\nThe design plan of a VLSI single chip (255, 223) Reed-Solomon decoder\n\nNASA Technical Reports Server (NTRS)\n\nHsu, I. S.; Shao, H. M.; Deutsch, L. J.\n\n1987-01-01\n\nThe very large-scale integration (VLSI) architecture of a single chip (255, 223) Reed-Solomon decoder for decoding both errors and erasures is described. A decoding failure detection capability is also included in this system so that the decoder will recognize a failure to decode instead of introducing additional errors. This could happen whenever the received word contains too many errors and erasures for the code to correct. The number of transistors needed to implement this decoder is estimated at about 75,000 if the delay for received message is not included. This is in contrast to the older transform decoding algorithm which needs about 100,000 transistors. However, the transform decoder is simpler in architecture than the time decoder. It is therefore possible to implement a single chip (255, 223) Reed-Solomon decoder with today's VLSI technology. An implementation strategy for the decoder system is presented. This represents the first step in a plan to take advantage of advanced coding techniques to realize a 2.0 dB coding gain for future space missions.\n\nNASA Space Engineering Research Center for VLSI systems design\n\nNASA Technical Reports Server (NTRS)\n\n1991-01-01\n\nThis annual review reports the center's activities and findings on very large scale integration (VLSI) systems design for 1990, including project status, financial support, publications, the NASA Space Engineering Research Center (SERC) Symposium on VLSI Design, research results, and outreach programs. Processor chips completed or under development are listed. Research results summarized include a design technique to harden complementary metal oxide semiconductors (CMOS) memory circuits against single event upset (SEU); improved circuit design procedures; and advances in computer aided design (CAD), communications, computer architectures, and reliability design. Also described is a high school teacher program that exposes teachers to the fundamentals of digital logic design.\n\nAn Integrated Unix-based CAD System for the Design and Testing of Custom VLSI Chips\n\nNASA Technical Reports Server (NTRS)\n\nDeutsch, L. J.\n\n1985-01-01\n\nA computer aided design (CAD) system that is being used at the Jet Propulsion Laboratory for the design of custom and semicustom very large scale integrated (VLSI) chips is described. The system consists of a Digital Equipment Corporation VAX computer with the UNIX operating system and a collection of software tools for the layout, simulation, and verification of microcircuits. Most of these tools were written by the academic community and are, therefore, available to JPL at little or no cost. Some small pieces of software have been written in-house in order to make all the tools interact with each other with a minimal amount of effort on the part of the designer.\n\nCascaded VLSI Chips Help Neural Network To Learn\n\nNASA Technical Reports Server (NTRS)\n\nDuong, Tuan A.; Daud, Taher; Thakoor, Anilkumar P.\n\n1993-01-01\n\nCascading provides 12-bit resolution needed for learning. Using conventional silicon chip fabrication technology of VLSI, fully connected architecture consisting of 32 wide-range, variable gain, sigmoidal neurons along one diagonal and 7-bit resolution, electrically programmable, synaptic 32 x 31 weight matrix implemented on neuron-synapse chip. To increase weight nominally from 7 to 13 bits, synapses on chip individually cascaded with respective synapses on another 32 x 32 matrix chip with 7-bit resolution synapses only (without neurons). Cascade correlation algorithm varies number of layers effectively connected into network; adds hidden layers one at a time during learning process in such way as to optimize overall number of neurons and complexity and configuration of network.\n\nSpecification and Design Methodologies for High-Speed Fault-Tolerant Array Algorithms and Structures for VLSI.\n\nDTIC Science & Technology\n\n1987-06-01\n\nevaluation and chip layout planning for VLSI digital systems. A high-level applicative (functional) language, implemented at UCLA, allows combining of...operating system. 2.1 Introduction The complexity of VLSI requires the application of CAD tools at all levels of the design process. In order to be...effective, these tools must be adaptive to the specific design. In this project we studied a design method based on the use of applicative languages\n\nA VLSI chip set for real time vector quantization of image sequences\n\nNASA Technical Reports Server (NTRS)\n\nBaker, Richard L.\n\n1989-01-01\n\nThe architecture and implementation of a VLSI chip set that vector quantizes (VQ) image sequences in real time is described. The chip set forms a programmable Single-Instruction, Multiple-Data (SIMD) machine which can implement various vector quantization encoding structures. Its VQ codebook may contain unlimited number of codevectors, N, having dimension up to K = 64. Under a weighted least squared error criterion, the engine locates at video rates the best code vector in full-searched or large tree searched VQ codebooks. The ability to manipulate tree structured codebooks, coupled with parallelism and pipelining, permits searches in as short as O (log N) cycles. A full codebook search results in O(N) performance, compared to O(KN) for a Single-Instruction, Single-Data (SISD) machine. With this VLSI chip set, an entire video code can be built on a single board that permits realtime experimentation with very large codebooks.\n\nA new VLSI architecture for a single-chip-type Reed-Solomon decoder\n\nNASA Technical Reports Server (NTRS)\n\nHsu, I. S.; Truong, T. K.\n\n1989-01-01\n\nA new very large scale integration (VLSI) architecture for implementing Reed-Solomon (RS) decoders that can correct both errors and erasures is described. This new architecture implements a Reed-Solomon decoder by using replication of a single VLSI chip. It is anticipated that this single chip type RS decoder approach will save substantial development and production costs. It is estimated that reduction in cost by a factor of four is possible with this new architecture. Furthermore, this Reed-Solomon decoder is programmable between 8 bit and 10 bit symbol sizes. Therefore, both an 8 bit Consultative Committee for Space Data Systems (CCSDS) RS decoder and a 10 bit decoder are obtained at the same time, and when concatenated with a (15,1/6) Viterbi decoder, provide an additional 2.1-dB coding gain.\n\nLearning and optimization with cascaded VLSI neural network building-block chips\n\nNASA Technical Reports Server (NTRS)\n\nDuong, T.; Eberhardt, S. P.; Tran, M.; Daud, T.; Thakoor, A. P.\n\n1992-01-01\n\nTo demonstrate the versatility of the building-block approach, two neural network applications were implemented on cascaded analog VLSI chips. Weights were implemented using 7-b multiplying digital-to-analog converter (MDAC) synapse circuits, with 31 x 32 and 32 x 32 synapses per chip. A novel learning algorithm compatible with analog VLSI was applied to the two-input parity problem. The algorithm combines dynamically evolving architecture with limited gradient-descent backpropagation for efficient and versatile supervised learning. To implement the learning algorithm in hardware, synapse circuits were paralleled for additional quantization levels. The hardware-in-the-loop learning system allocated 2-5 hidden neurons for parity problems. Also, a 7 x 7 assignment problem was mapped onto a cascaded 64-neuron fully connected feedback network. In 100 randomly selected problems, the network found optimal or good solutions in most cases, with settling times in the range of 7-100 microseconds.\n\nVLSI chip-set for data compression using the Rice algorithm\n\nNASA Technical Reports Server (NTRS)\n\nVenbrux, J.; Liu, N.\n\n1990-01-01\n\nA full custom VLSI implementation of a data compression encoder and decoder which implements the lossless Rice data compression algorithm is discussed in this paper. The encoder and decoder reside on single chips. The data rates are to be 5 and 10 Mega-samples-per-second for the decoder and encoder respectively.\n\nA VLSI VAX chip set\n\nNASA Astrophysics Data System (ADS)\n\nJohnson, W. N.; Herrick, W. V.; Grundmann, W. J.\n\n1984-10-01\n\nFor the first time, VLSI technology is used to compress the full functinality and comparable performance of the VAX 11/780 super-minicomputer into a 1.2 M transistor microprocessor chip set. There was no subsetting of the 304 instruction set and the 17 data types, nor reduction in hardware support for the 4 Gbyte virtual memory management architecture. The chipset supports an integral 8 kbyte memory cache, a 13.3 Mbyte/s system bus, and sophisticated multiprocessing. High performance is achieved through microcode optimizations afforded by the large control store, tightly coupled address and data caches, the use of internal and external 32 bit datapaths, the extensive aplication of both microlevel and macrolevel pipelining, and the use of specialized hardware assists.\n\nOn the VLSI design of a pipeline Reed-Solomon decoder using systolic arrays\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nShao, H.M.; Reed, I.S.\n\nA new VLSI design of a pipeline Reed-Solomon decoder is presented. The transform decoding technique used in a previous paper is replaced by a time domain algorithm through a detailed comparison of their VLSI implementations. A new architecture that implements the time domain algorithm permits efficient pipeline processing with reduced circuitry. Erasure correction capability is also incorporated with little additional complexity. By using a multiplexing technique, a new implementation of Euclid's algorithm maintains the throughput rate with less circuitry. Such improvements result in both enhanced capability and significant reduction in silicon area, therefore making it possible to build a pipelinemoreÂ Â» Reed-Solomon decoder on a single VLSI chip.Â«Â less\n\nTowards an Analogue Neuromorphic VLSI Instrument for the Sensing of Complex Odours\n\nNASA Astrophysics Data System (ADS)\n\nAb Aziz, Muhammad Fazli; Harun, Fauzan Khairi Che; Covington, James A.; Gardner, Julian W.\n\n2011-09-01\n\nAlmost all electronic nose instruments reported today employ pattern recognition algorithms written in software and run on digital processors, e.g. micro-processors, microcontrollers or FPGAs. Conversely, in this paper we describe the analogue VLSI implementation of an electronic nose through the design of a neuromorphic olfactory chip. The modelling, design and fabrication of the chip have already been reported. Here a smart interface has been designed and characterised for thisneuromorphic chip. Thus we can demonstrate the functionality of the a VLSI neuromorphic chip, producing differing principal neuron firing patterns to real sensor response data. Further work is directed towards integrating 9 separate neuromorphic chips to create a large neuronal network to solve more complex olfactory problems.\n\nAsynchronous transfer mode distribution network by use of an optoelectronic VLSI switching chip.\n\nPubMed\n\nLentine, A L; Reiley, D J; Novotny, R A; Morrison, R L; Sasian, J M; Beckman, M G; Buchholz, D B; Hinterlong, S J; Cloonan, T J; Richards, G W; McCormick, F B\n\n1997-03-10\n\nWe describe a new optoelectronic switching system demonstration that implements part of the distribution fabric for a large asynchronous transfer mode (ATM) switch. The system uses a single optoelectronic VLSI modulator-based switching chip with more than 4000 optical input-outputs. The optical system images the input fibers from a two-dimensional fiber bundle onto this chip. A new optomechanical design allows the system to be mounted in a standard electronic equipment frame. A large section of the switch was operated as a 208-Mbits/s time-multiplexed space switch, which can serve as part of an ATM switch by use of an appropriate out-of-band controller. A larger section with 896 input light beams and 256 output beams was operated at 160 Mbits/s as a slowly reconfigurable space switch.\n\nThe Fifth NASA Symposium on VLSI Design\n\nNASA Technical Reports Server (NTRS)\n\n1993-01-01\n\nThe fifth annual NASA Symposium on VLSI Design had 13 sessions including Radiation Effects, Architectures, Mixed Signal, Design Techniques, Fault Testing, Synthesis, Signal Processing, and other Featured Presentations. The symposium provides insights into developments in VLSI and digital systems which can be used to increase data systems performance. The presentations share insights into next generation advances that will serve as a basis for future VLSI design.\n\nA Single Chip VLSI Implementation of a QPSK/SQPSK Demodulator for a VSAT Receiver Station\n\nNASA Technical Reports Server (NTRS)\n\nKwatra, S. C.; King, Brent\n\n1995-01-01\n\nThis thesis presents a VLSI implementation of a QPSK/SQPSK demodulator. It is designed to be employed in a VSAT earth station that utilizes the FDMA/TDM link. A single chip architecture is used to enable this chip to be easily employed in the VSAT system. This demodulator contains lowpass filters, integrate and dump units, unique word detectors, a timing recovery unit, a phase recovery unit and a down conversion unit. The design stages start with a functional representation of the system by using the C programming language. Then it progresses into a register based representation using the VHDL language. The layout components are designed based on these VHDL models and simulated. Component generators are developed for the adder, multiplier, read-only memory and serial access memory in order to shorten the design time. These sub-components are then block routed to form the main components of the system. The main components are block routed to form the final demodulator.\n\nNoise-margin limitations on gallium-arsenide VLSI\n\nNASA Technical Reports Server (NTRS)\n\nLong, Stephen I.; Sundaram, Mani\n\n1988-01-01\n\nTwo factors which limit the complexity of GaAs MESFET VLSI circuits are considered. Power dissipation sets an upper complexity limit for a given logic circuit implementation and thermal design. Uniformity of device characteristics and the circuit configuration determines the electrical functional yield. Projection of VLSI complexity based on these factors indicates that logic chips of 15,000 gates are feasible with the most promising static circuits if a maximum power dissipation of 5 W per chip is assumed. While lower power per gate and therefore more gates per chip can be obtained by using a popular E/D FET circuit, yields are shown to be small when practical device parameter tolerances are applied. Further improvements in materials, devices, and circuits wil be needed to extend circuit complexity to the range currently dominated by silicon.\n\nThe 1991 3rd NASA Symposium on VLSI Design\n\nNASA Technical Reports Server (NTRS)\n\nMaki, Gary K.\n\n1991-01-01\n\nPapers from the symposium are presented from the following sessions: (1) featured presentations 1; (2) very large scale integration (VLSI) circuit design; (3) VLSI architecture 1; (4) featured presentations 2; (5) neural networks; (6) VLSI architectures 2; (7) featured presentations 3; (8) verification 1; (9) analog design; (10) verification 2; (11) design innovations 1; (12) asynchronous design; and (13) design innovations 2.\n\nDriving a car with custom-designed fuzzy inferencing VLSI chips and boards\n\nNASA Technical Reports Server (NTRS)\n\nPin, Francois G.; Watanabe, Yutaka\n\n1993-01-01\n\nVehicle control in a-priori unknown, unpredictable, and dynamic environments requires many calculational and reasoning schemes to operate on the basis of very imprecise, incomplete, or unreliable data. For such systems, in which all the uncertainties can not be engineered away, approximate reasoning may provide an alternative to the complexity and computational requirements of conventional uncertainty analysis and propagation techniques. Two types of computer boards including custom-designed VLSI chips were developed to add a fuzzy inferencing capability to real-time control systems. All inferencing rules on a chip are processed in parallel, allowing execution of the entire rule base in about 30 microseconds, and therefore, making control of 'reflex-type' of motions envisionable. The use of these boards and the approach using superposition of elemental sensor-based behaviors for the development of qualitative reasoning schemes emulating human-like navigation in a-priori unknown environments are first discussed. Then how the human-like navigation scheme implemented on one of the qualitative inferencing boards was installed on a test-bed platform to investigate two control modes for driving a car in a-priori unknown environments on the basis of sparse and imprecise sensor data is described. In the first mode, the car navigates fully autonomously, while in the second mode, the system acts as a driver's aid providing the driver with linguistic (fuzzy) commands to turn left or right and speed up or slow down depending on the obstacles perceived by the sensors. Experiments with both modes of control are described in which the system uses only three acoustic range (sonar) sensor channels to perceive the environment. Simulation results as well as indoors and outdoors experiments are presented and discussed to illustrate the feasibility and robustness of autonomous navigation and/or safety enhancing driver's aid using the new fuzzy inferencing hardware system and some human\n\nAdaptive WTA with an analog VLSI neuromorphic learning chip.\n\nPubMed\n\nHÃ¤fliger, Philipp\n\n2007-03-01\n\nIn this paper, we demonstrate how a particular spike-based learning rule (where exact temporal relations between input and output spikes of a spiking model neuron determine the changes of the synaptic weights) can be tuned to express rate-based classical Hebbian learning behavior (where the average input and output spike rates are sufficient to describe the synaptic changes). This shift in behavior is controlled by the input statistic and by a single time constant. The learning rule has been implemented in a neuromorphic very large scale integration (VLSI) chip as part of a neurally inspired spike signal image processing system. The latter is the result of the European Union research project Convolution AER Vision Architecture for Real-Time (CAVIAR). Since it is implemented as a spike-based learning rule (which is most convenient in the overall spike-based system), even if it is tuned to show rate behavior, no explicit long-term average signals are computed on the chip. We show the rule's rate-based Hebbian learning ability in a classification task in both simulation and chip experiment, first with artificial stimuli and then with sensor input from the CAVIAR system.\n\nGaAs VLSI for aerospace electronics\n\nNASA Technical Reports Server (NTRS)\n\nLarue, G.; Chan, P.\n\n1990-01-01\n\nAdvanced aerospace electronics systems require high-speed, low-power, radiation-hard, digital components for signal processing, control, and communication applications. GaAs VLSI devices provide a number of advantages over silicon devices including higher carrier velocities, ability to integrate with high performance optical devices, and high-resistivity substrates that provide very short gate delays, good isolation, and tolerance to many forms of radiation. However, III-V technologies also have disadvantages, such as lower yield compared to silicon MOS technology. Achieving very large scale integration (VLSI) is particularly important for fast complex systems. At very short gate delays (less than 100 ps), chip-to-chip interconnects severely degrade circuit clock rates. Complex systems, therefore, benefit greatly when as many gates as possible are placed on a single chip. To fully exploit the advantages of GaAs circuits, attention must be focused on achieving high integration levels by reducing power dissipation, reducing the number of devices per logic function, and providing circuit designs that are more tolerant to process and environmental variations. In addition, adequate noise margin must be maintained to ensure a practical yield.\n\nElectro-optic techniques for VLSI interconnect\n\nNASA Astrophysics Data System (ADS)\n\nNeff, J. A.\n\n1985-03-01\n\nA major limitation to achieving significant speed increases in very large scale integration (VLSI) lies in the metallic interconnects. They are costly not only from the charge transport standpoint but also from capacitive loading effects. The Defense Advanced Research Projects Agency, in pursuit of the fifth generation supercomputer, is investigating alternatives to the VLSI metallic interconnects, especially the use of optical techniques to transport the information either inter or intrachip. As the on chip performance of VLSI continues to improve via the scale down of the logic elements, the problems associated with transferring data off and onto the chip become more severe. The use of optical carriers to transfer the information within the computer is very appealing from several viewpoints. Besides the potential for gigabit propagation rates, the conversion from electronics to optics conveniently provides a decoupling of the various circuits from one another. Significant gains will also be realized in reducing cross talk between the metallic routings, and the interconnects need no longer be constrained to the plane of a thin film on the VLSI chip. In addition, optics can offer an increased programming flexibility for restructuring the interconnect network.\n\nVery Large Scale Integration (VLSI).\n\nERIC Educational Resources Information Center\n\nYeaman, Andrew R. J.\n\nVery Large Scale Integration (VLSI), the state-of-the-art production techniques for computer chips, promises such powerful, inexpensive computing that, in the future, people will be able to communicate with computer devices in natural language or even speech. However, before full-scale VLSI implementation can occur, certain salient factors must beâ¦\n\nAn engineering methodology for implementing and testing VLSI (Very Large Scale Integrated) circuits\n\nNASA Astrophysics Data System (ADS)\n\nCorliss, Walter F., II\n\n1989-03-01\n\nThe engineering methodology for producing a fully tested VLSI chip from a design layout is presented. A 16-bit correlator, NPS CORN88, that was previously designed, was used as a vehicle to demonstrate this methodology. The study of the design and simulation tools, MAGIC and MOSSIM II, was the focus of the design and validation process. The design was then implemented and the chip was fabricated by MOSIS. This fabricated chip was then used to develop a testing methodology for using the digital test facilities at NPS. NPS CORN88 was the first full custom VLSI chip, designed at NPS, to be tested with the NPS digital analysis system, Tektronix DAS 9100 series tester. The capabilities and limitations of these test facilities are examined. NPS CORN88 test results are included to demonstrate the capabilities of the digital test system. A translator, MOS2DAS, was developed to convert the MOSSIM II simulation program to the input files required by the DAS 9100 device verification software, 91DVS. Finally, a tutorial for using the digital test facilities, including the DAS 9100 and associated support equipments, is included as an appendix.\n\nParallel optimization algorithms and their implementation in VLSI design\n\nNASA Technical Reports Server (NTRS)\n\nLee, G.; Feeley, J. J.\n\n1991-01-01\n\nTwo new parallel optimization algorithms based on the simplex method are described. They may be executed by a SIMD parallel processor architecture and be implemented in VLSI design. Several VLSI design implementations are introduced. An application example is reported to demonstrate that the algorithms are effective.\n\nVLSI research\n\nNASA Astrophysics Data System (ADS)\n\nBrodersen, R. W.\n\n1984-04-01\n\nA scaled version of the RISC II chip has been fabricated and tested and these new chips have a cycle time that would outperform a VAX 11/780 by about a factor of two on compiled integer C programs. The architectural work on a RISC chip designed for a Smalltalk implementation has been completed. This chip, called SOAR (Smalltalk On a RISC), should run program s4-15 times faster than the Xerox 1100 (Dolphin), a TTL minicomputer, and about as fast as the Xerox 1132 (Dorado), a $100,000 ECL minicomputer. The 1983 VLSI tools tape has been converted for use under the latest UNIX release (4.2). The Magic (formerly called Caddy) layout system will be a unified set of highly automated tools that cover all aspects of the layout process, including stretching, compaction, tiling and routing. A multiple window package and design rule checker for this system have just been completed and compaction and stretching are partially implemented. New slope-based timing models for the Crystal timing analyzer are now fully implemented and in regular use. In an accuracy test using a dozen critical paths from the RISC II processor and cache chips it was found that Crystal's estimates were within 5-10% of SPICE's estimates, while being a factor of 10,000 times faster.\n\nAssociative Pattern Recognition In Analog VLSI Circuits\n\nNASA Technical Reports Server (NTRS)\n\nTawel, Raoul\n\n1995-01-01\n\nWinner-take-all circuit selects best-match stored pattern. Prototype cascadable very-large-scale integrated (VLSI) circuit chips built and tested to demonstrate concept of electronic associative pattern recognition. Based on low-power, sub-threshold analog complementary oxide/semiconductor (CMOS) VLSI circuitry, each chip can store 128 sets (vectors) of 16 analog values (vector components), vectors representing known patterns as diverse as spectra, histograms, graphs, or brightnesses of pixels in images. Chips exploit parallel nature of vector quantization architecture to implement highly parallel processing in relatively simple computational cells. Through collective action, cells classify input pattern in fraction of microsecond while consuming power of few microwatts.\n\nSSI/MSI/LSI/VLSI/ULSI.\n\nERIC Educational Resources Information Center\n\nAlexander, George\n\n1984-01-01\n\nDiscusses small-scale integrated (SSI), medium-scale integrated (MSI), large-scale integrated (LSI), very large-scale integrated (VLSI), and ultra large-scale integrated (ULSI) chips. The development and properties of these chips, uses of gallium arsenide, Josephson devices (two superconducting strips sandwiching a thin insulator), and futureâ¦\n\nSummary of workshop on the application of VLSI for robotic sensing\n\nNASA Technical Reports Server (NTRS)\n\nBrooks, T.; Wilcox, B.\n\n1984-01-01\n\nIt was one of the objectives of the considered workshop to identify near, mid, and far-term applications of VLSI for robotic sensing and sensor data preprocessing. The workshop was also to indicate areas in which VLSI technology can provide immediate and future payoffs. A third objective is related to the promotion of dialog and collaborative efforts between research communities, industry, and government. The workshop was held on March 24-25, 1983. Conclusions and recommendations are discussed. Attention is given to the need for a pixel correction chip, an image sensor with 10,000 dynamic range, VLSI enhanced architectures, the need for a high-density serpentine memory, an LSI-tactile sensing program, an analog-signal preprocessor chip, a smart strain gage, a protective proximity envelope, a VLSI-proximity sensor program, a robot-net chip, and aspects of silicon micromechanics.\n\nThe VLSI design of error-trellis syndrome decoding for convolutional codes\n\nNASA Technical Reports Server (NTRS)\n\nReed, I. S.; Jensen, J. M.; Truong, T. K.; Hsu, I. S.\n\n1985-01-01\n\nA recursive algorithm using the error-trellis decoding technique is developed to decode convolutional codes (CCs). An example, illustrating the very large scale integration (VLSI) architecture of such a decode, is given for a dual-K CC. It is demonstrated that such a decoder can be realized readily on a single chip with metal-nitride-oxide-semiconductor technology.\n\nOrientation-selective aVLSI spiking neurons.\n\nPubMed\n\nLiu, S C; Kramer, J; Indiveri, G; DelbrÃ¼ck, T; Burg, T; Douglas, R\n\n2001-01-01\n\nWe describe a programmable multi-chip VLSI neuronal system that can be used for exploring spike-based information processing models. The system consists of a silicon retina, a PIC microcontroller, and a transceiver chip whose integrate-and-fire neurons are connected in a soft winner-take-all architecture. The circuit on this multi-neuron chip approximates a cortical microcircuit. The neurons can be configured for different computational properties by the virtual connections of a selected set of pixels on the silicon retina. The virtual wiring between the different chips is effected by an event-driven communication protocol that uses asynchronous digital pulses, similar to spikes in a neuronal system. We used the multi-chip spike-based system to synthesize orientation-tuned neurons using both a feedforward model and a feedback model. The performance of our analog hardware spiking model matched the experimental observations and digital simulations of continuous-valued neurons. The multi-chip VLSI system has advantages over computer neuronal models in that it is real-time, and the computational time does not scale with the size of the neuronal network.\n\nImplementation of neuromorphic systems: from discrete components to analog VLSI chips (testing and communication issues).\n\nPubMed\n\nDante, V; Del Giudice, P; Mattia, M\n\n2001-01-01\n\nWe review a series of implementations of electronic devices aiming at imitating to some extent structure and function of simple neural systems, with particular emphasis on communication issues. We first provide a short overview of general features of such \"neuromorphic\" devices and the implications of setting up \"tests\" for them. We then review the developments directly related to our work at the Istituto Superiore di SanitÃ (ISS): a pilot electronic neural network implementing a simple classifier, autonomously developing internal representations of incoming stimuli; an output network, collecting information from the previous classifier and extracting the relevant part to be forwarded to the observer; an analog, VLSI (very large scale integration) neural chip implementing a recurrent network of spiking neurons and plastic synapses, and the test setup for it; a board designed to interface the standard PCI (peripheral component interconnect) bus of a PC with a special purpose, asynchronous bus for communication among neuromorphic chips; a short and preliminary account of an application-oriented device, taking advantage of the above communication infrastructure.\n\nRecovery Act - CAREER: Sustainable Silicon -- Energy-Efficient VLSI Interconnect for Extreme-Scale Computing\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nChiang, Patrick\n\n2014-01-31\n\nThe research goal of this CAREER proposal is to develop energy-efficient, VLSI interconnect circuits and systems that will facilitate future massively-parallel, high-performance computing. Extreme-scale computing will exhibit massive parallelism on multiple vertical levels, from thouÂ­ sands of computational units on a single processor to thousands of processors in a single data center. Unfortunately, the energy required to communicate between these units at every level (onÂ­ chip, off-chip, off-rack) will be the critical limitation to energy efficiency. Therefore, the PI's career goal is to become a leading researcher in the design of energy-efficient VLSI interconnect for future computing systems.\n\nThe 1992 4th NASA SERC Symposium on VLSI Design\n\nNASA Technical Reports Server (NTRS)\n\nWhitaker, Sterling R.\n\n1992-01-01\n\nPapers from the fourth annual NASA Symposium on VLSI Design, co-sponsored by the IEEE, are presented. Each year this symposium is organized by the NASA Space Engineering Research Center (SERC) at the University of Idaho and is held in conjunction with a quarterly meeting of the NASA Data System Technology Working Group (DSTWG). One task of the DSTWG is to develop new electronic technologies that will meet next generation electronic data system needs. The symposium provides insights into developments in VLSI and digital systems which can be used to increase data systems performance. The NASA SERC is proud to offer, at its fourth symposium on VLSI design, presentations by an outstanding set of individuals from national laboratories, the electronics industry, and universities. These speakers share insights into next generation advances that will serve as a basis for future VLSI design.\n\nNASA Space Engineering Research Center Symposium on VLSI Design\n\nNASA Technical Reports Server (NTRS)\n\nMaki, Gary K.\n\n1990-01-01\n\nThe NASA Space Engineering Research Center (SERC) is proud to offer, at its second symposium on VLSI design, presentations by an outstanding set of individuals from national laboratories and the electronics industry. These featured speakers share insights into next generation advances that will serve as a basis for future VLSI design. Questions of reliability in the space environment along with new directions in CAD and design are addressed by the featured speakers.\n\nOptical printed circuit board (O-PCB) and VLSI photonic integrated circuits: visions, challenges, and progresses\n\nNASA Astrophysics Data System (ADS)\n\nLee, El-Hang; Lee, S. G.; O, B. H.; Park, S. G.; Noh, H. S.; Kim, K. H.; Song, S. H.\n\n2006-09-01\n\nA collective overview and review is presented on the original work conducted on the theory, design, fabrication, and in-tegration of micro/nano-scale optical wires and photonic devices for applications in a newly-conceived photonic systems called \"optical printed circuit board\" (O-PCBs) and \"VLSI photonic integrated circuits\" (VLSI-PIC). These are aimed for compact, high-speed, multi-functional, intelligent, light-weight, low-energy and environmentally friendly, low-cost, and high-volume applications to complement or surpass the capabilities of electrical PCBs (E-PCBs) and/or VLSI electronic integrated circuit (VLSI-IC) systems. These consist of 2-dimensional or 3-dimensional planar arrays of micro/nano-optical wires and circuits to perform the functions of all-optical sensing, storing, transporting, processing, switching, routing and distributing optical signals on flat modular boards or substrates. The integrated optical devices include micro/nano-scale waveguides, lasers, detectors, switches, sensors, directional couplers, multi-mode interference devices, ring-resonators, photonic crystal devices, plasmonic devices, and quantum devices, made of polymer, silicon and other semiconductor materials. For VLSI photonic integration, photonic crystals and plasmonic structures have been used. Scientific and technological issues concerning the processes of miniaturization, interconnection and integration of these systems as applicable to board-to-board, chip-to-chip, and intra-chip integration, are discussed along with applications for future computers, telecommunications, and sensor-systems. Visions and challenges toward these goals are also discussed.\n\nVerification of VLSI designs\n\nNASA Technical Reports Server (NTRS)\n\nWindley, P. J.\n\n1991-01-01\n\nIn this paper we explore the specification and verification of VLSI designs. The paper focuses on abstract specification and verification of functionality using mathematical logic as opposed to low-level boolean equivalence verification such as that done using BDD's and Model Checking. Specification and verification, sometimes called formal methods, is one tool for increasing computer dependability in the face of an exponentially increasing testing effort.\n\nHighly efficient simulation environment for HDTV video decoder in VLSI design\n\nNASA Astrophysics Data System (ADS)\n\nMao, Xun; Wang, Wei; Gong, Huimin; He, Yan L.; Lou, Jian; Yu, Lu; Yao, Qingdong; Pirsch, Peter\n\n2002-01-01\n\nWith the increase of the complex of VLSI such as the SoC (System on Chip) of MPEG-2 Video decoder with HDTV scalability especially, simulation and verification of the full design, even as high as the behavior level in HDL, often proves to be very slow, costly and it is difficult to perform full verification until late in the design process. Therefore, they become bottleneck of the procedure of HDTV video decoder design, and influence it's time-to-market mostly. In this paper, the architecture of Hardware/Software Interface of HDTV video decoder is studied, and a Hardware-Software Mixed Simulation (HSMS) platform is proposed to check and correct error in the early design stage, based on the algorithm of MPEG-2 video decoding. The application of HSMS to target system could be achieved by employing several introduced approaches. Those approaches speed up the simulation and verification task without decreasing performance.\n\nVLSI processors for signal detection in SETI\n\nNASA Technical Reports Server (NTRS)\n\nDuluk, J. F.; Linscott, I. R.; Peterson, A. M.; Burr, J.; Ekroot, B.; Twicken, J.\n\n1989-01-01\n\nThe objective of the Search for Extraterrestrial Intelligence (SETI) is to locate an artificially created signal coming from a distant star. This is done in two steps: (1) spectral analysis of an incoming radio frequency band, and (2) pattern detection for narrow-band signals. Both steps are computationally expensive and require the development of specially designed computer architectures. To reduce the size and cost of the SETI signal detection machine, two custom VLSI chips are under development. The first chip, the SETI DSP Engine, is used in the spectrum analyzer and is specially designed to compute Discrete Fourier Transforms (DFTs). It is a high-speed arithmetic processor that has two adders, one multiplier-accumulator, and three four-port memories. The second chip is a new type of Content-Addressable Memory. It is the heart of an associative processor that is used for pattern detection. Both chips incorporate many innovative circuits and architectural features.\n\nVLSI processors for signal detection in SETI.\n\nPubMed\n\nDuluk, J F; Linscott, I R; Peterson, A M; Burr, J; Ekroot, B; Twicken, J\n\n1989-01-01\n\nThe objective of the Search for Extraterrestrial Intelligence (SETI) is to locate an artificially created signal coming from a distant star. This is done in two steps: (1) spectral analysis of an incoming radio frequency band, and (2) pattern detection for narrow-band signals. Both steps are computationally expensive and require the development of specially designed computer architectures. To reduce the size and cost of the SETI signal detection machine, two custom VLSI chips are under development. The first chip, the SETI DSP Engine, is used in the spectrum analyzer and is specially designed to compute Discrete Fourier Transforms (DFTs). It is a high-speed arithmetic processor that has two adders, one multiplier-accumulator, and three four-port memories. The second chip is a new type of Content-Addressable Memory. It is the heart of an associative processor that is used for pattern detection. Both chips incorporate many innovative circuits and architectural features.\n\nA special purpose silicon compiler for designing supercomputing VLSI systems\n\nNASA Technical Reports Server (NTRS)\n\nVenkateswaran, N.; Murugavel, P.; Kamakoti, V.; Shankarraman, M. J.; Rangarajan, S.; Mallikarjun, M.; Karthikeyan, B.; Prabhakar, T. S.; Satish, V.; Venkatasubramaniam, P. R.\n\n1991-01-01\n\nDesign of general/special purpose supercomputing VLSI systems for numeric algorithm execution involves tackling two important aspects, namely their computational and communication complexities. Development of software tools for designing such systems itself becomes complex. Hence a novel design methodology has to be developed. For designing such complex systems a special purpose silicon compiler is needed in which: the computational and communicational structures of different numeric algorithms should be taken into account to simplify the silicon compiler design, the approach is macrocell based, and the software tools at different levels (algorithm down to the VLSI circuit layout) should get integrated. In this paper a special purpose silicon (SPS) compiler based on PACUBE macrocell VLSI arrays for designing supercomputing VLSI systems is presented. It is shown that turn-around time and silicon real estate get reduced over the silicon compilers based on PLA's, SLA's, and gate arrays. The first two silicon compiler characteristics mentioned above enable the SPS compiler to perform systolic mapping (at the macrocell level) of algorithms whose computational structures are of GIPOP (generalized inner product outer product) form. Direct systolic mapping on PLA's, SLA's, and gate arrays is very difficult as they are micro-cell based. A novel GIPOP processor is under development using this special purpose silicon compiler.\n\nThe VLSI design of an error-trellis syndrome decoder for certain convolutional codes\n\nNASA Technical Reports Server (NTRS)\n\nReed, I. S.; Jensen, J. M.; Hsu, I.-S.; Truong, T. K.\n\n1986-01-01\n\nA recursive algorithm using the error-trellis decoding technique is developed to decode convolutional codes (CCs). An example, illustrating the very large scale integration (VLSI) architecture of such a decode, is given for a dual-K CC. It is demonstrated that such a decoder can be realized readily on a single chip with metal-nitride-oxide-semiconductor technology.\n\nTesting Methods for Integrated Circuit Chips.\n\nDTIC Science & Technology\n\n1986-03-27\n\nDWf <I IAV ~IMi MORY OUT LOGIC~~ IPOGRAM ASYC S’E4i E...* 16o, CO% T ROL CO%TROL 32 Figure 2 . 14 VLSI Tester Block Diagram. registers, memory and test...neral-pIurpos’ processor wi th standard bus- inte-rfaco se-rves as,- th- test control Ii’r and ( 2 ) a c-ustom VLSI test Controller inti-rfacing direc(_t1...Engineering 2 WTWTY ABSTRACT Provision for the functional testing of fabricated VLSI chips frequently involves as much design effort as the orig- _ inal\n\nA multichip aVLSI system emulating orientation selectivity of primary visual cortical cells.\n\nPubMed\n\nShimonomura, Kazuhiro; Yagi, Tetsuya\n\n2005-07-01\n\nIn this paper, we designed and fabricated a multichip neuromorphic analog very large scale integrated (aVLSI) system, which emulates the orientation selective response of the simple cell in the primary visual cortex. The system consists of a silicon retina and an orientation chip. An image, which is filtered by a concentric center-surround (CS) antagonistic receptive field of the silicon retina, is transferred to the orientation chip. The image transfer from the silicon retina to the orientation chip is carried out with analog signals. The orientation chip selectively aggregates multiple pixels of the silicon retina, mimicking the feedforward model proposed by Hubel and Wiesel. The chip provides the orientation-selective (OS) outputs which are tuned to 0 degrees, 60 degrees, and 120 degrees. The feed-forward aggregation reduces the fixed pattern noise that is due to the mismatch of the transistors in the orientation chip. The spatial properties of the orientation selective response were examined in terms of the adjustable parameters of the chip, i.e., the number of aggregated pixels and size of the receptive field of the silicon retina. The multichip aVLSI architecture used in the present study can be applied to implement higher order cells such as the complex cell of the primary visual cortex.\n\nMEDIPIX: a VLSI chip for a GaAs pixel detector for digital radiology\n\nNASA Astrophysics Data System (ADS)\n\nAmendolia, S. R.; Bertolucci, E.; Bisogni, M. G.; Bottigli, U.; Ceccopieri, A.; Ciocci, M. A.; Conti, M.; Delogu, P.; Fantacci, M. E.; Maestro, P.; Marzulli, V.; Pernigotti, E.; Romeo, N.; Rosso, V.; Rosso, P.; Stefanini, A.; Stumbo, S.\n\n1999-02-01\n\nA GaAs pixel detector designed for digital mammography, equipped with a 36-channel single photon counting discrete read-out electronics, was tested using a test object developed for quality control purposes in mammography. Each pixel was 200Ã200 Î¼m 2 large, and 200 Î¼m deep. The choice of GaAs with respect to silicon (largely used in other applications and with a more established technique) has been made because of the much better detection efficiency at mammographic energies, combined with a very good charge collection efficiency achieved thanks to new ohmic contacts. This GaAs detector is able to perform a measurement of low-contrast details, with minimum contrast lower (nearly a factor two) than that typically achievable with standard mammographic film+screen systems in the same conditions of clinical routine. This should allow for an earlier diagnosis of breast tumour masses. Due to these encouraging results, the next step in the evolution of our imaging system based on GaAs detectors has been the development of a VLSI front-end prototype chip (MEDIPIX ) in order to cover a much larger diagnostic area. The chip reads 64Ã64 channels in single photon counting mode, each one 170 Î¼m wide. Each channel contains also a test input where a signal can be simulated, injecting a known charge through a 16 f F capacitor. Fake signals have been injected via the test input measuring and equalizing minimum thresholds for all the channels. On an average, in most of the performing chips available up to now, we have found that it is possible to set a threshold as low as 1800 electrons with an RMS of 150 electrons (10 standard deviations lower than the 20 keV photon signal roughly equivalent to 4500 electrons). The detector, bump-bonded to the chip, will be tested and a ladder of detectors will be prepared to be able to scan large surface objects.\n\nAssimilation of Biophysical Neuronal Dynamics in Neuromorphic VLSI.\n\nPubMed\n\nWang, Jun; Breen, Daniel; Akinin, Abraham; Broccard, Frederic; Abarbanel, Henry D I; Cauwenberghs, Gert\n\n2017-12-01\n\nRepresenting the biophysics of neuronal dynamics and behavior offers a principled analysis-by-synthesis approach toward understanding mechanisms of nervous system functions. We report on a set of procedures assimilating and emulating neurobiological data on a neuromorphic very large scale integrated (VLSI) circuit. The analog VLSI chip, NeuroDyn, features 384 digitally programmable parameters specifying for 4 generalized Hodgkin-Huxley neurons coupled through 12 conductance-based chemical synapses. The parameters also describe reversal potentials, maximal conductances, and spline regressed kinetic functions for ion channel gating variables. In one set of experiments, we assimilated membrane potential recorded from one of the neurons on the chip to the model structure upon which NeuroDyn was designed using the known current input sequence. We arrived at the programmed parameters except for model errors due to analog imperfections in the chip fabrication. In a related set of experiments, we replicated songbird individual neuron dynamics on NeuroDyn by estimating and configuring parameters extracted using data assimilation from intracellular neural recordings. Faithful emulation of detailed biophysical neural dynamics will enable the use of NeuroDyn as a tool to probe electrical and molecular properties of functional neural circuits. Neuroscience applications include studying the relationship between molecular properties of neurons and the emergence of different spike patterns or different brain behaviors. Clinical applications include studying and predicting effects of neuromodulators or neurodegenerative diseases on ion channel kinetics.\n\nChip level modeling of LSI devices\n\nNASA Technical Reports Server (NTRS)\n\nArmstrong, J. R.\n\n1984-01-01\n\nThe advent of Very Large Scale Integration (VLSI) technology has rendered the gate level model impractical for many simulation activities critical to the design automation process. As an alternative, an approach to the modeling of VLSI devices at the chip level is described, including the specification of modeling language constructs important to the modeling process. A model structure is presented in which models of the LSI devices are constructed as single entities. The modeling structure is two layered. The functional layer in this structure is used to model the input/output response of the LSI chip. A second layer, the fault mapping layer, is added, if fault simulations are required, in order to map the effects of hardware faults onto the functional layer. Modeling examples for each layer are presented. Fault modeling at the chip level is described. Approaches to realistic functional fault selection and defining fault coverage for functional faults are given. Application of the modeling techniques to single chip and bit slice microprocessors is discussed.\n\nThe VLSI design of a Reed-Solomon encoder using Berlekamps bit-serial multiplier algorithm\n\nNASA Technical Reports Server (NTRS)\n\nTruong, T. K.; Deutsch, L. J.; Reed, I. S.; Hsu, I. S.; Wang, K.; Yeh, C. S.\n\n1982-01-01\n\nRealization of a bit-serial multiplication algorithm for the encoding of Reed-Solomon (RS) codes on a single VLSI chip using NMOS technology is demonstrated to be feasible. A dual basis (255, 223) over a Galois field is used. The conventional RS encoder for long codes ofter requires look-up tables to perform the multiplication of two field elements. Berlekamp's algorithm requires only shifting and exclusive-OR operations.\n\nTesting interconnected VLSI circuits in the Big Viterbi Decoder\n\nNASA Technical Reports Server (NTRS)\n\nOnyszchuk, I. M.\n\n1991-01-01\n\nThe Big Viterbi Decoder (BVD) is a powerful error-correcting hardware device for the Deep Space Network (DSN), in support of the Galileo and Comet Rendezvous Asteroid Flyby (CRAF)/Cassini Missions. Recently, a prototype was completed and run successfully at 400,000 or more decoded bits per second. This prototype is a complex digital system whose core arithmetic unit consists of 256 identical very large scale integration (VLSI) gate-array chips, 16 on each of 16 identical boards which are connected through a 28-layer, printed-circuit backplane using 4416 wires. Special techniques were developed for debugging, testing, and locating faults inside individual chips, on boards, and within the entire decoder. The methods are based upon hierarchical structure in the decoder, and require that chips or boards be wired themselves as Viterbi decoders. The basic procedure consists of sending a small set of known, very noisy channel symbols through a decoder, and matching observables against values computed by a software simulation. Also, tests were devised for finding open and short-circuited wires which connect VLSI chips on the boards and through the backplane.\n\nA procedural method for the efficient implementation of full-custom VLSI designs\n\nNASA Technical Reports Server (NTRS)\n\nBelk, P.; Hickey, N.\n\n1987-01-01\n\nAn imbedded language system for the layout of very large scale integration (VLSI) circuits is examined. It is shown that through the judicious use of this system, a large variety of circuits can be designed with circuit density and performance comparable to traditional full-custom design methods, but with design costs more comparable to semi-custom design methods. The high performance of this methodology is attributable to the flexibility of procedural descriptions of VLSI layouts and to a number of automatic and semi-automatic tools within the system.\n\nBuilt-in self-repair of VLSI memories employing neural nets\n\nNASA Astrophysics Data System (ADS)\n\nMazumder, Pinaki\n\n1998-10-01\n\nThe decades of the Eighties and the Nineties have witnessed the spectacular growth of VLSI technology, when the chip size has increased from a few hundred devices to a staggering multi-millon transistors. This trend is expected to continue as the CMOS feature size progresses towards the nanometric dimension of 100 nm and less. SIA roadmap projects that, where as the DRAM chips will integrate over 20 billion devices in the next millennium, the future microprocessors may incorporate over 100 million transistors on a single chip. As the VLSI chip size increase, the limited accessibility of circuit components poses great difficulty for external diagnosis and replacement in the presence of faulty components. For this reason, extensive work has been done in built-in self-test techniques, but little research is known concerning built-in self-repair. Moreover, the extra hardware introduced by conventional fault-tolerance techniques is also likely to become faulty, therefore causing the circuit to be useless. This research demonstrates the feasibility of implementing electronic neural networks as intelligent hardware for memory array repair. Most importantly, we show that the neural network control possesses a robust and degradable computing capability under various fault conditions. Overall, a yield analysis performed on 64K DRAM's shows that the yield can be improved from as low as 20 percent to near 99 percent due to the self-repair design, with overhead no more than 7 percent.\n\nA Coherent VLSI Design Environment\n\nDTIC Science & Technology\n\n1987-12-31\n\ncontract the total research volume in VLSI rose from an estimated $3,000,000 to over 3 $10,000,000, and a state-of-the-art VLSI fabrication facility costing...Research\" 11:30 John Melngailic , \"Submicron Structures Research at M.I.T.\" 11:55 Dimitri A. Antoniadis, \"Status of the M.I.T. LSI Fabrication Facility ...1984. Contributions were made by Prof. Antoniadis and, to a small degree, ProÂ£ Glasser. Objective: â¢ To develop techniques for fabricating integrated\n\nVLSI architectures for computing multiplications and inverses in GF(2m)\n\nNASA Technical Reports Server (NTRS)\n\nWang, C. C.; Truong, T. K.; Shao, H. M.; Deutsch, L. J.; Omura, J. K.\n\n1985-01-01\n\nFinite field arithmetic logic is central in the implementation of Reed-Solomon coders and in some cryptographic algorithms. There is a need for good multiplication and inversion algorithms that are easily realized on VLSI chips. Massey and Omura recently developed a new multiplication algorithm for Galois fields based on a normal basis representation. A pipeline structure is developed to realize the Massey-Omura multiplier in the finite field GF(2m). With the simple squaring property of the normal-basis representation used together with this multiplier, a pipeline architecture is also developed for computing inverse elements in GF(2m). The designs developed for the Massey-Omura multiplier and the computation of inverse elements are regular, simple, expandable and, therefore, naturally suitable for VLSI implementation.\n\nVLSI architectures for computing multiplications and inverses in GF(2-m)\n\nNASA Technical Reports Server (NTRS)\n\nWang, C. C.; Truong, T. K.; Shao, H. M.; Deutsch, L. J.; Omura, J. K.; Reed, I. S.\n\n1983-01-01\n\nFinite field arithmetic logic is central in the implementation of Reed-Solomon coders and in some cryptographic algorithms. There is a need for good multiplication and inversion algorithms that are easily realized on VLSI chips. Massey and Omura recently developed a new multiplication algorithm for Galois fields based on a normal basis representation. A pipeline structure is developed to realize the Massey-Omura multiplier in the finite field GF(2m). With the simple squaring property of the normal-basis representation used together with this multiplier, a pipeline architecture is also developed for computing inverse elements in GF(2m). The designs developed for the Massey-Omura multiplier and the computation of inverse elements are regular, simple, expandable and, therefore, naturally suitable for VLSI implementation.\n\nvPELS: An E-Learning Social Environment for VLSI Design with Content Security Using DRM\n\nERIC Educational Resources Information Center\n\nDewan, Jahangir; Chowdhury, Morshed; Batten, Lynn\n\n2014-01-01\n\nThis article provides a proposal for personal e-learning system (vPELS [where \"v\" stands for VLSI: very large scale integrated circuit])) architecture in the context of social network environment for VLSI Design. The main objective of vPELS is to develop individual skills on a specific subject--say, VLSI--and share resources with peers.â¦\n\nSystolic VLSI Reed-Solomon Decoder\n\nNASA Technical Reports Server (NTRS)\n\nShao, H. M.; Truong, T. K.; Deutsch, L. J.; Yuen, J. H.\n\n1986-01-01\n\nDecoder for digital communications provides high-speed, pipelined ReedSolomon (RS) error-correction decoding of data streams. Principal new feature of proposed decoder is modification of Euclid greatest-common-divisor algorithm to avoid need for time-consuming computations of inverse of certain Galois-field quantities. Decoder architecture suitable for implementation on very-large-scale integrated (VLSI) chips with negative-channel metaloxide/silicon circuitry.\n\nVLSI neuroprocessors\n\nNASA Technical Reports Server (NTRS)\n\nKemeny, Sabrina E.\n\n1994-01-01\n\nElectronic and optoelectronic hardware implementations of highly parallel computing architectures address several ill-defined and/or computation-intensive problems not easily solved by conventional computing techniques. The concurrent processing architectures developed are derived from a variety of advanced computing paradigms including neural network models, fuzzy logic, and cellular automata. Hardware implementation technologies range from state-of-the-art digital/analog custom-VLSI to advanced optoelectronic devices such as computer-generated holograms and e-beam fabricated Dammann gratings. JPL's concurrent processing devices group has developed a broad technology base in hardware implementable parallel algorithms, low-power and high-speed VLSI designs and building block VLSI chips, leading to application-specific high-performance embeddable processors. Application areas include high throughput map-data classification using feedforward neural networks, terrain based tactical movement planner using cellular automata, resource optimization (weapon-target assignment) using a multidimensional feedback network with lateral inhibition, and classification of rocks using an inner-product scheme on thematic mapper data. In addition to addressing specific functional needs of DOD and NASA, the JPL-developed concurrent processing device technology is also being customized for a variety of commercial applications (in collaboration with industrial partners), and is being transferred to U.S. industries. This viewgraph p resentation focuses on two application-specific processors which solve the computation intensive tasks of resource allocation (weapon-target assignment) and terrain based tactical movement planning using two extremely different topologies. Resource allocation is implemented as an asynchronous analog competitive assignment architecture inspired by the Hopfield network. Hardware realization leads to a two to four order of magnitude speed-up over conventional\n\nGaAs VLSI technology and circuit elements for DSP\n\nNASA Astrophysics Data System (ADS)\n\nMikkelson, James M.\n\n1990-10-01\n\nRecent progress in digital GaAs circuit performance and complexity is presented to demonstrate the current capabilities of GaAs components. High density GaAs process technology and circuit design techniques are described and critical issues for achieving favorable complexity speed power and cost tradeoffs are reviewed. Some DSP building blocks are described to provide examples of what types of DSP systems could be implemented with present GaAs technology. DIGITAL GaAs CIRCUIT CAPABILITIES In the past few years the capabilities of digital GaAs circuits have dramatically increased to the VLSI level. Major gains in circuit complexity and power-delay products have been achieved by the use of silicon-like process technologies and simple circuit topologies. The very high speed and low power consumption of digital GaAs VLSI circuits have made GaAs a desirable alternative to high performance silicon in hardware intensive high speed system applications. An example of the performance and integration complexity available with GaAs VLSI circuits is the 64x64 crosspoint switch shown in figure 1. This switch which is the most complex GaAs circuit currently available is designed on a 30 gate GaAs gate array. It operates at 200 MHz and dissipates only 8 watts of power. The reasons for increasing the level of integration of GaAs circuits are similar to the reasons for the continued increase of silicon circuit complexity. The market factors driving GaAs VLSI are system design methodology system cost power and reliability. System designers are hesitant or unwilling to go backwards to previous design techniques and lower levels of integration. A more highly integrated system in a lower performance technology can often approach the performance of a system in a higher performance technology at a lower level of integration. Higher levels of integration also lower the system component count which reduces the system cost size and power consumption while improving the system reliability\n\nVLSI Design of Trusted Virtual Sensors.\n\nPubMed\n\nMartÃ­nez-RodrÃ­guez, Macarena C; Prada-Delgado, Miguel A; Brox, Piedad; Baturone, Iluminada\n\n2018-01-25\n\nThis work presents a Very Large Scale Integration (VLSI) design of trusted virtual sensors providing a minimum unitary cost and very good figures of size, speed and power consumption. The sensed variable is estimated by a virtual sensor based on a configurable and programmable PieceWise-Affine hyper-Rectangular (PWAR) model. An algorithm is presented to find the best values of the programmable parameters given a set of (empirical or simulated) input-output data. The VLSI design of the trusted virtual sensor uses the fast authenticated encryption algorithm, AEGIS, to ensure the integrity of the provided virtual measurement and to encrypt it, and a Physical Unclonable Function (PUF) based on a Static Random Access Memory (SRAM) to ensure the integrity of the sensor itself. Implementation results of a prototype designed in a 90-nm Complementary Metal Oxide Semiconductor (CMOS) technology show that the active silicon area of the trusted virtual sensor is 0.86 mm 2 and its power consumption when trusted sensing at 50 MHz is 7.12 mW. The maximum operation frequency is 85 MHz, which allows response times lower than 0.25 Î¼ s. As application example, the designed prototype was programmed to estimate the yaw rate in a vehicle, obtaining root mean square errors lower than 1.1%. Experimental results of the employed PUF show the robustness of the trusted sensing against aging and variations of the operation conditions, namely, temperature and power supply voltage (final value as well as ramp-up time).\n\nVLSI Design of Trusted Virtual Sensors\n\nPubMed Central\n\n2018-01-01\n\nThis work presents a Very Large Scale Integration (VLSI) design of trusted virtual sensors providing a minimum unitary cost and very good figures of size, speed and power consumption. The sensed variable is estimated by a virtual sensor based on a configurable and programmable PieceWise-Affine hyper-Rectangular (PWAR) model. An algorithm is presented to find the best values of the programmable parameters given a set of (empirical or simulated) input-output data. The VLSI design of the trusted virtual sensor uses the fast authenticated encryption algorithm, AEGIS, to ensure the integrity of the provided virtual measurement and to encrypt it, and a Physical Unclonable Function (PUF) based on a Static Random Access Memory (SRAM) to ensure the integrity of the sensor itself. Implementation results of a prototype designed in a 90-nm Complementary Metal Oxide Semiconductor (CMOS) technology show that the active silicon area of the trusted virtual sensor is 0.86 mm2 and its power consumption when trusted sensing at 50 MHz is 7.12 mW. The maximum operation frequency is 85 MHz, which allows response times lower than 0.25 Î¼s. As application example, the designed prototype was programmed to estimate the yaw rate in a vehicle, obtaining root mean square errors lower than 1.1%. Experimental results of the employed PUF show the robustness of the trusted sensing against aging and variations of the operation conditions, namely, temperature and power supply voltage (final value as well as ramp-up time). PMID:29370141\n\nVLSI architectures for computing multiplications and inverses in GF(2m).\n\nPubMed\n\nWang, C C; Truong, T K; Shao, H M; Deutsch, L J; Omura, J K; Reed, I S\n\n1985-08-01\n\nFinite field arithmetic logic is central in the implementation of Reed-Solomon coders and in some cryptographic algorithms. There is a need for good multiplication and inversion algorithms that can be easily realized on VLSI chips. Massey and Omura recently developed a new multiplication algorithm for Galois fields based on a normal basis representation. In this paper, a pipeline structure is developed to realize the Massey-Omura multiplier in the finite field GF(2m). With the simple squaring property of the normal basis representation used together with this multiplier, a pipeline architecture is developed for computing inverse elements in GF(2m). The designs developed for the Massey-Omura multiplier and the computation of inverse elements are regular, simple, expandable, and therefore, naturally suitable for VLSI implementation.\n\nSmart vision chips: An overview\n\nNASA Technical Reports Server (NTRS)\n\nKoch, Christof\n\n1994-01-01\n\nThis viewgraph presentation presents four working analog VLSI vision chips: (1) time-derivative retina, (2) zero-crossing chip, (3) resistive fuse, and (4) figure-ground chip; work in progress on computing motion and neuromorphic systems; and conceptual and practical lessons learned.\n\nA new VLSI complex integer multiplier which uses a quadratic-polynomial residue system with Fermat numbers\n\nNASA Technical Reports Server (NTRS)\n\nTruong, T. K.; Hsu, I. S.; Chang, J. J.; Shyu, H. C.; Reed, I. S.\n\n1986-01-01\n\nA quadratic-polynomial Fermat residue number system (QFNS) has been used to compute complex integer multiplications. The advantage of such a QFNS is that a complex integer multiplication requires only two integer multiplications. In this article, a new type Fermat number multiplier is developed which eliminates the initialization condition of the previous method. It is shown that the new complex multiplier can be implemented on a single VLSI chip. Such a chip is designed and fabricated in CMOS-pw technology.\n\nA new VLSI complex integer multiplier which uses a quadratic-polynomial residue system with Fermat numbers\n\nNASA Technical Reports Server (NTRS)\n\nShyu, H. C.; Reed, I. S.; Truong, T. K.; Hsu, I. S.; Chang, J. J.\n\n1987-01-01\n\nA quadratic-polynomial Fermat residue number system (QFNS) has been used to compute complex integer multiplications. The advantage of such a QFNS is that a complex integer multiplication requires only two integer multiplications. In this article, a new type Fermat number multiplier is developed which eliminates the initialization condition of the previous method. It is shown that the new complex multiplier can be implemented on a single VLSI chip. Such a chip is designed and fabricated in CMOS-Pw technology.\n\nSpike Neuromorphic VLSI-Based Bat Echolocation for Micro-Aerial Vehicle Guidance\n\nDTIC Science & Technology\n\n2007-03-31\n\nIFinal 03/01/04 - 02/28/07 4. TITLE AND SUBTITLE 5a. CONTRACT NUMBER Neuromorphic VLSI-based Bat Echolocation for Micro-aerial 5b.GRANTNUMBER Vehicle...uncovered interesting new issues in our choice for representing the intensity of signals. We have just finished testing the first chip version of an echo...timing-based algorithm (’openspace’) for sonar-guided navigation amidst multiple obstacles. 15. SUBJECT TERMS Neuromorphic VLSI, bat echolocation\n\nParallel VLSI architecture emulation and the organization of APSA/MPP\n\nNASA Technical Reports Server (NTRS)\n\nOdonnell, John T.\n\n1987-01-01\n\nThe Applicative Programming System Architecture (APSA) combines an applicative language interpreter with a novel parallel computer architecture that is well suited for Very Large Scale Integration (VLSI) implementation. The Massively Parallel Processor (MPP) can simulate VLSI circuits by allocating one processing element in its square array to an area on a square VLSI chip. As long as there are not too many long data paths, the MPP can simulate a VLSI clock cycle very rapidly. The APSA circuit contains a binary tree with a few long paths and many short ones. A skewed H-tree layout allows every processing element to simulate a leaf cell and up to four tree nodes, with no loss in parallelism. Emulation of a key APSA algorithm on the MPP resulted in performance 16,000 times faster than a Vax. This speed will make it possible for the APSA language interpreter to run fast enough to support research in parallel list processing algorithms.\n\nVLSI Microsystem for Rapid Bioinformatic Pattern Recognition\n\nNASA Technical Reports Server (NTRS)\n\nFang, Wai-Chi; Lue, Jaw-Chyng\n\n2009-01-01\n\nA system comprising very-large-scale integrated (VLSI) circuits is being developed as a means of bioinformatics-oriented analysis and recognition of patterns of fluorescence generated in a microarray in an advanced, highly miniaturized, portable genetic-expression-assay instrument. Such an instrument implements an on-chip combination of polymerase chain reactions and electrochemical transduction for amplification and detection of deoxyribonucleic acid (DNA).\n\nVLSI realization of learning vector quantization with hardware/software co-design for different applications\n\nNASA Astrophysics Data System (ADS)\n\nAn, Fengwei; Akazawa, Toshinobu; Yamasaki, Shogo; Chen, Lei; JÃ¼rgen Mattausch, Hans\n\n2015-04-01\n\nThis paper reports a VLSI realization of learning vector quantization (LVQ) with high flexibility for different applications. It is based on a hardware/software (HW/SW) co-design concept for on-chip learning and recognition and designed as a SoC in 180 nm CMOS. The time consuming nearest Euclidean distance search in the LVQ algorithmâs competition layer is efficiently implemented as a pipeline with parallel p-word input. Since neuron number in the competition layer, weight values, input and output number are scalable, the requirements of many different applications can be satisfied without hardware changes. Classification of a d-dimensional input vector is completed in n Ã \\\\lceil d/p \\\\rceil + R clock cycles, where R is the pipeline depth, and n is the number of reference feature vectors (FVs). Adjustment of stored reference FVs during learning is done by the embedded 32-bit RISC CPU, because this operation is not time critical. The high flexibility is verified by the application of human detection with different numbers for the dimensionality of the FVs.\n\nA VLSI implementation for synthetic aperture radar image processing\n\nNASA Technical Reports Server (NTRS)\n\nPremkumar, A.; Purviance, J.\n\n1990-01-01\n\nA simple physical model for the Synthetic Aperture Radar (SAR) is presented. This model explains the one dimensional and two dimensional nature of the received SAR signal in the range and azimuth directions. A time domain correlator, its algorithm, and features are explained. The correlator is ideally suited for VLSI implementation. A real time SAR architecture using these correlators is proposed. In the proposed architecture, the received SAR data is processed using one dimensional correlators for determining the range while two dimensional correlators are used to determine the azimuth of a target. The architecture uses only three different types of custom VLSI chips and a small amount of memory.\n\nOn VLSI Design of Rank-Order Filtering using DCRAM Architecture\n\nPubMed Central\n\nLin, Meng-Chun; Dung, Lan-Rong\n\n2009-01-01\n\nThis paper addresses on VLSI design of rank-order filtering (ROF) with a maskable memory for real-time speech and image processing applications. Based on a generic bit-sliced ROF algorithm, the proposed design uses a special-defined memory, called the dual-cell random-access memory (DCRAM), to realize major operations of ROF: threshold decomposition and polarization. Using the memory-oriented architecture, the proposed ROF processor can benefit from high flexibility, low cost and high speed. The DCRAM can perform the bit-sliced read, partial write, and pipelined processing. The bit-sliced read and partial write are driven by maskable registers. With recursive execution of the bit-slicing read and partial write, the DCRAM can effectively realize ROF in terms of cost and speed. The proposed design has been implemented using TSMC 0.18 Î¼m 1P6M technology. As shown in the result of physical implementation, the core size is 356.1 Ã 427.7Î¼m2 and the VLSI implementation of ROF can operate at 256 MHz for 1.8V supply. PMID:19865599\n\nConvolving optically addressed VLSI liquid crystal SLM\n\nNASA Astrophysics Data System (ADS)\n\nJared, David A.; Stirk, Charles W.\n\n1994-03-01\n\nWe designed, fabricated, and tested an optically addressed spatial light modulator (SLM) that performs a 3 X 3 kernel image convolution using ferroelectric liquid crystal on VLSI technology. The chip contains a 16 X 16 array of current-mirror-based convolvers with a fixed kernel for finding edges. The pixels are located on 75 micron centers, and the modulators are 20 microns on a side. The array successfully enhanced edges in illumination patterns. We developed a high-level simulation tool (CON) for analyzing the performance of convolving SLM designs. CON has a graphical interface and simulates SLM functions using SPICE-like device models. The user specifies the pixel function along with the device parameters and nonuniformities. We discovered through analysis, simulation and experiment that the operation of current-mirror-based convolver pixels is degraded at low light levels by the variation of transistor threshold voltages inherent to CMOS chips. To function acceptable, the test SLM required the input image to have an minimum irradiance of 10 (mu) W/cm2. The minimum required irradiance can be further reduced by adding a photodarlington near the photodetector or by increasing the size of the transistors used to calculate the convolution.\n\nOptical Interconnections for VLSI Computational Systems Using Computer-Generated Holography.\n\nNASA Astrophysics Data System (ADS)\n\nFeldman, Michael Robert\n\nOptical interconnects for VLSI computational systems using computer generated holograms are evaluated in theory and experiment. It is shown that by replacing particular electronic connections with free-space optical communication paths, connection of devices on a single chip or wafer and between chips or modules can be improved. Optical and electrical interconnects are compared in terms of power dissipation, communication bandwidth, and connection density. Conditions are determined for which optical interconnects are advantageous. Based on this analysis, it is shown that by applying computer generated holographic optical interconnects to wafer scale fine grain parallel processing systems, dramatic increases in system performance can be expected. Some new interconnection networks, designed to take full advantage of optical interconnect technology, have been developed. Experimental Computer Generated Holograms (CGH's) have been designed, fabricated and subsequently tested in prototype optical interconnected computational systems. Several new CGH encoding methods have been developed to provide efficient high performance CGH's. One CGH was used to decrease the access time of a 1 kilobit CMOS RAM chip. Another was produced to implement the inter-processor communication paths in a shared memory SIMD parallel processor array.\n\nA VLSI design of a pipeline Reed-Solomon decoder\n\nNASA Technical Reports Server (NTRS)\n\nShao, H. M.; Truong, T. K.; Deutsch, L. J.; Yuen, J. H.; Reed, I. S.\n\n1985-01-01\n\nA pipeline structure of a transform decoder similar to a systolic array was developed to decode Reed-Solomon (RS) codes. An important ingredient of this design is a modified Euclidean algorithm for computing the error locator polynomial. The computation of inverse field elements is completely avoided in this modification of Euclid's algorithm. The new decoder is regular and simple, and naturally suitable for VLSI implementation.\n\nDesign of Tactile Sensor Using Dynamic Wafer Technology Based on VLSI Technique\n\nDTIC Science & Technology\n\n2001-10-25\n\nCharles Noback, Rober Carola,\" Human Anatomy and Physiology\" third edition, 1995. [5] M.H. Raibert and John E. Tanner, \"Design and Implementation of VLSI Tactile Sensing Computer\" Robotics Research vol 1, 1983.\n\nLeak detection utilizing analog binaural (VLSI) techniques\n\nNASA Technical Reports Server (NTRS)\n\nHartley, Frank T. (Inventor)\n\n1995-01-01\n\nA detection method and system utilizing silicon models of the traveling wave structure of the human cochlea to spatially and temporally locate a specific sound source in the presence of high noise pandemonium. The detection system combines two-dimensional stereausis representations, which are output by at least three VLSI binaural hearing chips, to generate a three-dimensional stereausis representation including both binaural and spectral information which is then used to locate the sound source.\n\nApplication of a VLSI vector quantization processor to real-time speech coding\n\nNASA Technical Reports Server (NTRS)\n\nDavidson, G.; Gersho, A.\n\n1986-01-01\n\nAttention is given to a working vector quantization processor for speech coding that is based on a first-generation VLSI chip which efficiently performs the pattern-matching operation needed for the codebook search process (CPS). Using this chip, the CPS architecture has been successfully incorporated into a compact, single-board Vector PCM implementation operating at 7-18 kbits/sec. A real time Adaptive Vector Predictive Coder system using the CPS has also been implemented.\n\nOn the VLSI design of a pipeline Reed-Solomon decoder using systolic arrays\n\nNASA Technical Reports Server (NTRS)\n\nShao, H. M.; Deutsch, L. J.; Reed, I. S.\n\n1987-01-01\n\nA new very large scale integration (VLSI) design of a pipeline Reed-Solomon decoder is presented. The transform decoding technique used in a previous article is replaced by a time domain algorithm through a detailed comparison of their VLSI implementations. A new architecture that implements the time domain algorithm permits efficient pipeline processing with reduced circuitry. Erasure correction capability is also incorporated with little additional complexity. By using a multiplexing technique, a new implementation of Euclid's algorithm maintains the throughput rate with less circuitry. Such improvements result in both enhanced capability and significant reduction in silicon area.\n\nOn the VLSI design of a pipeline Reed-Solomon decoder using systolic arrays\n\nNASA Technical Reports Server (NTRS)\n\nShao, Howard M.; Reed, Irving S.\n\n1988-01-01\n\nA new very large scale integration (VLSI) design of a pipeline Reed-Solomon decoder is presented. The transform decoding technique used in a previous article is replaced by a time domain algorithm through a detailed comparison of their VLSI implementations. A new architecture that implements the time domain algorithm permits efficient pipeline processing with reduced circuitry. Erasure correction capability is also incorporated with little additional complexity. By using multiplexing technique, a new implementation of Euclid's algorithm maintains the throughput rate with less circuitry. Such improvements result in both enhanced capability and significant reduction in silicon area.\n\nHigh data rate Reed-Solomon encoding and decoding using VLSI technology\n\nNASA Technical Reports Server (NTRS)\n\nMiller, Warner; Morakis, James\n\n1987-01-01\n\nPresented as an implementation of a Reed-Solomon encode and decoder, which is 16-symbol error correcting, each symbol is 8 bits. This Reed-Solomon (RS) code is an efficient error correcting code that the National Aeronautics and Space Administration (NASA) will use in future space communications missions. A Very Large Scale Integration (VLSI) implementation of the encoder and decoder accepts data rates up 80 Mbps. A total of seven chips are needed for the decoder (four of the seven decoding chips are customized using 3-micron Complementary Metal Oxide Semiconduction (CMOS) technology) and one chip is required for the encoder. The decoder operates with the symbol clock being the system clock for the chip set. Approximately 1.65 billion Galois Field (GF) operations per second are achieved with the decoder chip set and 640 MOPS are achieved with the encoder chip.\n\nA Systolic VLSI Design of a Pipeline Reed-solomon Decoder\n\nNASA Technical Reports Server (NTRS)\n\nShao, H. M.; Truong, T. K.; Deutsch, L. J.; Yuen, J. H.; Reed, I. S.\n\n1984-01-01\n\nA pipeline structure of a transform decoder similar to a systolic array was developed to decode Reed-Solomon (RS) codes. An important ingredient of this design is a modified Euclidean algorithm for computing the error locator polynomial. The computation of inverse field elements is completely avoided in this modification of Euclid's algorithm. The new decoder is regular and simple, and naturally suitable for VLSI implementation.\n\nA novel configurable VLSI architecture design of window-based image processing method\n\nNASA Astrophysics Data System (ADS)\n\nZhao, Hui; Sang, Hongshi; Shen, Xubang\n\n2018-03-01\n\nMost window-based image processing architecture can only achieve a certain kind of specific algorithms, such as 2D convolution, and therefore lack the flexibility and breadth of application. In addition, improper handling of the image boundary can cause loss of accuracy, or consume more logic resources. For the above problems, this paper proposes a new VLSI architecture of window-based image processing operations, which is configurable and based on consideration of the image boundary. An efficient technique is explored to manage the image borders by overlapping and flushing phases at the end of row and the end of frame, which does not produce new delay and reduce the overhead in real-time applications. Maximize the reuse of the on-chip memory data, in order to reduce the hardware complexity and external bandwidth requirements. To perform different scalar function and reduction function operations in pipeline, this can support a variety of applications of window-based image processing. Compared with the performance of other reported structures, the performance of the new structure has some similarities to some of the structures, but also superior to some other structures. Especially when compared with a systolic array processor CWP, this structure at the same frequency of approximately 12.9% of the speed increases. The proposed parallel VLSI architecture was implemented with SIMC 0.18-Î¼m CMOS technology, and the maximum clock frequency, power consumption, and area are 125Mhz, 57mW, 104.8K Gates, respectively, furthermore the processing time is independent of the different window-based algorithms mapped to the structure\n\nA cost-effective methodology for the design of massively-parallel VLSI functional units\n\nNASA Technical Reports Server (NTRS)\n\nVenkateswaran, N.; Sriram, G.; Desouza, J.\n\n1993-01-01\n\nIn this paper we propose a generalized methodology for the design of cost-effective massively-parallel VLSI Functional Units. This methodology is based on a technique of generating and reducing a massive bit-array on the mask-programmable PAcube VLSI array. This methodology unifies (maintains identical data flow and control) the execution of complex arithmetic functions on PAcube arrays. It is highly regular, expandable and uniform with respect to problem-size and wordlength, thereby reducing the communication complexity. The memory-functional unit interface is regular and expandable. Using this technique functional units of dedicated processors can be mask-programmed on the naked PAcube arrays, reducing the turn-around time. The production cost of such dedicated processors can be drastically reduced since the naked PAcube arrays can be mass-produced. Analysis of the the performance of functional units designed by our method yields promising results.\n\nVLSI (Very Large Scale Integration) Design Tools, Reference Manual, Release 3.0.\n\nDTIC Science & Technology\n\n1985-08-01\n\ngenerators/mult prior to running mult. The generated layout is output in directory 1ca in caesar cells with names of the form \"caesarame*oca. Mut is a cft ...vlsa) spice(1.vlsi), User’s Guide to AML VLSI Dodgen Tools Reference Manual, UW/NW VLSI Consortium, University of Washington, (Christopher Terman, MIT...of the form ’caesarname..ca. Muls is a cft -based program and therefore also produces *.bd fiIls ’Caesaramew may not begin with the string mule. The\n\nModeling selective attention using a neuromorphic analog VLSI device.\n\nPubMed\n\nIndiveri, G\n\n2000-12-01\n\nAttentional mechanisms are required to overcome the problem of flooding a limited processing capacity system with information. They are present in biological sensory systems and can be a useful engineering tool for artificial visual systems. In this article we present a hardware model of a selective attention mechanism implemented on a very large-scale integration (VLSI) chip, using analog neuromorphic circuits. The chip exploits a spike-based representation to receive, process, and transmit signals. It can be used as a transceiver module for building multichip neuromorphic vision systems. We describe the circuits that carry out the main processing stages of the selective attention mechanism and provide experimental data for each circuit. We demonstrate the expected behavior of the model at the system level by stimulating the chip with both artificially generated control signals and signals obtained from a saliency map, computed from an image containing several salient features.\n\nParallel algorithms for placement and routing in VLSI design. Ph.D. Thesis\n\nNASA Technical Reports Server (NTRS)\n\nBrouwer, Randall Jay\n\n1991-01-01\n\nThe computational requirements for high quality synthesis, analysis, and verification of very large scale integration (VLSI) designs have rapidly increased with the fast growing complexity of these designs. Research in the past has focused on the development of heuristic algorithms, special purpose hardware accelerators, or parallel algorithms for the numerous design tasks to decrease the time required for solution. Two new parallel algorithms are proposed for two VLSI synthesis tasks, standard cell placement and global routing. The first algorithm, a parallel algorithm for global routing, uses hierarchical techniques to decompose the routing problem into independent routing subproblems that are solved in parallel. Results are then presented which compare the routing quality to the results of other published global routers and which evaluate the speedups attained. The second algorithm, a parallel algorithm for cell placement and global routing, hierarchically integrates a quadrisection placement algorithm, a bisection placement algorithm, and the previous global routing algorithm. Unique partitioning techniques are used to decompose the various stages of the algorithm into independent tasks which can be evaluated in parallel. Finally, results are presented which evaluate the various algorithm alternatives and compare the algorithm performance to other placement programs. Measurements are presented on the parallel speedups available.\n\nVLSI Research\n\nDTIC Science & Technology\n\n1984-04-01\n\nOusterhout, G.T. Hamachi, R.N. Mayo, W.S. Scott, and G.S. Taylor , \"A Collection of Papers on Magic,\" Technical Report No. UCB/CSD 83/154, Computer Science...Division, University of California, Berkeley, December 1983. (3) J.K Ousterhout, G.T. Hamachi, R.N. Mayo, W.S. Scott, and G.S. Taylor , \"Magic: A...VLSI Layout System.\" to appear, Slst Design Automation Confer- ence, June 1984. (4) G.S. Taylor and J.K Ousterhout, \"Magic’s Incremental Design-Rule\n\nA Streaming PCA VLSI Chip for Neural Data Compression.\n\nPubMed\n\nWu, Tong; Zhao, Wenfeng; Guo, Hongsun; Lim, Hubert H; Yang, Zhi\n\n2017-12-01\n\nNeural recording system miniaturization and integration with low-power wireless technologies require compressing neural data before transmission. Feature extraction is a procedure to represent data in a low-dimensional space; its integration into a recording chip can be an efficient approach to compress neural data. In this paper, we propose a streaming principal component analysis algorithm and its microchip implementation to compress multichannel local field potential (LFP) and spike data. The circuits have been designed in a 65-nm CMOS technology and occupy a silicon area of 0.06Â mm. Throughout the experiments, the chip compresses LFPs by 10 at the expense of as low as 1% reconstruction errors and 144-nW/channel power consumption; for spikes, the achieved compression ratio is 25 with 8% reconst"
    }
}