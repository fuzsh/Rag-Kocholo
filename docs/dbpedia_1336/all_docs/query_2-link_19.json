{
    "id": "dbpedia_1336_2",
    "rank": 19,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2950651/",
        "read_more_link": "",
        "language": "en",
        "title": "On the incrementality of pragmatic processing: An ERP investigation of informativeness and pragmatic abilities",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-nihpa.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2950651/bin/nihms218221f1.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2950651/bin/nihms218221f2.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2950651/bin/nihms218221f3.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2950651/bin/nihms218221f4.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2950651/bin/nihms218221f5.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2950651/bin/nihms218221f6.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Mante S. Nieuwland",
            "Tali Ditman",
            "Gina R. Kuperberg"
        ],
        "publish_date": "2010-10-01T00:00:00",
        "summary": "",
        "meta_description": "In two event-related potential (ERP) experiments, we determined to what extent Grice’s maxim of informativeness as well as pragmatic ability contributes to the incremental build-up of sentence meaning, by examining the impact of underinformative ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2950651/",
        "text": "INTRODUCTION\n\nAccording one of the key principles of pragmatics, addressees by default presume that speakers communicate efficiently by uttering messages that are informative (Grice, 1975; Sperber & Wilson, 1986). This so-called conversational maxim of quantity is based on the idea that communication has evolved as a cooperative effort, and it often implicitly shapes our communicative interactions (e.g., Engelhardt, Bailey & Ferreira, 2006; see also Clark, 1996). Of course, that does not mean that everything that we say or write is genuinely informative. We easily adjust our expectations to who we are talking to (e.g., children, people who know more or less than we do), reflecting the fact that what is informative or relevant to one individual might be trivial or irrelevant to another. Moreover, there is abundant literature to suggest that individuals can vary greatly in their abilities to produce and comprehend pragmatic language, which could mean that some people are simply more focused on the logic of utterances than others (e.g., Baron-Cohen, 2008).\n\nAlthough Grice’s account of pragmatic principles was not intended to serve as a psychological model of cognitive processing (see Bach, 2005; Bezuidenhout & Cutting, 2002), it may be that the addressee’s default presumptions have important ramifications for how language is processed online (e.g., Wilson & Sperber, 2004). One way in which Grice’s maxim of quantity may play out in online sentence processing is by influencing the addressee’s expectations of what kind of words will come next (e.g., Federmeier, 2007; Van Berkum, 2009). For example, following the sentence fragment “Some people have…”, the addressee might expect the upcoming word to denote something that not all people have (e.g., ‘pets’, ‘tattoos’), instead of something that all people possess (e.g., ‘lungs’, ‘bodies’). As a result, one can hypothesize that trivially true, underinformative statements (e.g., “Some people have lungs”) incur semantic processing costs because they deviate from the addressee’s expectations. In the two experiments reported below, we determined to what extent Grice’s maxim of informativeness contributes to the incremental build-up of sentence meaning. Specifically, we explored differences in individual’s reliance on this maxim for interpretation, and also investigated the role of general contextual factors on the processing of underinformative utterances. We addressed these issues by examining the impact of underinformative versus informative scalar sentences (e.g. “Some people have lungs/pets....”) on the N400 event-related potential (ERP), an electrophysiological index of semantic processing (Kutas & Hillyard, 1980, 1984).\n\nEver since Aristotle’s science of logic, quantifiers and logical operators have been important windows into human reasoning, and have maintained a crucial role in logic and linguistics because of their association with truth-value (e.g., see Gamut, 1991). The scalar quantifier ‘some’ has received much attention because it allows for two disparate readings: a pragmatic interpretation and a logical interpretation. The pragmatic interpretation approximates to ‘some but not all’ or ‘only some’. This interpretation constitutes a conversational inference, by which language comprehenders attribute an implicit meaning beyond the logical or literal meaning. This inference is termed a scalar inference or scalar implicature because it is thought that comprehenders base this pragmatic interpretation on the assumption that the communicator had a reason for not using a more informative or stronger term on the same quantity scale (some < many < all; see Horn, 1972). In other words, comprehenders assume that the communicator would have said ‘all’ if he/she thought ‘all’ was true, and assume that the communicator says ‘some’ because he/she thinks that stronger expressions like ‘many’ and ‘all’ are false.\n\nThe logical interpretation approximates to ‘at least some’ or ‘some and possibly all’. This interpretation makes sense when communicators use the expression ‘some’ when they lack all the relevant information (for example, “Some guests are coming to my party, but not everybody has RSVPed yet”, in which case it is possible that many or all invitees will come to the party), or when they are not referring to a specific subset (e.g., “Some people were crossing the street”).\n\nImportantly, the pragmatic and logical interpretation may yield different truth values. For a simple, informative statement like “Some people have pets”, each interpretation yields an outcome that is true with respect to world knowledge; it is true that ‘some but not all people have pets’, consistent with the pragmatic interpretation, and it is also true that there exist people with pets, consistent with the logical interpretation. However, for an underinformative statement like “Some people have lungs”, whereas the logical interpretation yields a true outcome (because people with lungs do exist), the pragmatic interpretation yields a false outcome (because all people have lungs, not just some). The fact that ‘some’ may yield disparate truth-values can be used to examine how language comprehenders apply their pragmatic knowledge during sentence comprehension and establish sentence truth-value (for reviews see Noveck & Reboul, 2008; Noveck & Sperber, 2007; Sedivy, 2007).\n\nTheoretical accounts of how people deal with scalar quantifiers predominantly differ in whether they assume that scalar inferences are generated by default or whether scalar inferences are context-dependent (see also Geurts, 2009; Horn, 2006; Recanati, 2003). In what has been dubbed the Levinsonian account, scalar inferences are generated automatically upon encountering ‘some’. The idea behind this is that, because the pragmatic meaning of scalars is so dominant in our language use, it has become ‘lexicalized’ (see Levinson, 2000; for related accounts see Chierchia, 2004; Gadzar, 1979) such that the intended message can be efficiently communicated. The pragmatic meaning, however, can be cancelled when the subsequent context requires so. For example, upon encountering the sentence “John wanted some of the cookies”, addressees automatically generate the pragmatic interpretation and interpret the sentences as meaning John wanted some, but not all, of the cookies. However, at a later point, upon encountering the sentence “In fact, he wanted all of them”, they revise their initial interpretation to be consistent with the logical interpretation. According to this account, it is this undoing of the scalar inference that is costly.\n\nIn contrast, proponents of Relevance Theory have posited that the generation of scalar inferences is chiefly a function of whether the inference is required to meet the addressee’s standard of relevance (e.g., Sperber & Wilson, 1986; Carston, 1998). The logical interpretation of ‘some’ (i.e., “some and possibly all”) could very well lead to a satisfying interpretation of the utterance, but the discourse context may require the addressee to derive a scalar inference to arrive at the pragmatic interpretation. Since this pragmatic interpretation involves ‘narrowing’ (negation of the stronger expressions ‘many’ and ‘all’), it constitutes a fully fledged inferential process which requires processing time and effort beyond the ‘easier’ logical interpretation.\n\nNeither the Levinsonian framework nor Relevance Theory constitutes a psychological model of scalar inferences with explicit implications for processing. Yet, experimental psychologists have tried to infer testable predictions about the time course of scalar inferences. It has been argued that if scalar inferences are generated automatically, as advocated in the Levinsonian account, they are also generated relatively rapidly and their cancellation would incur additional processing costs (e.g., Bott & Noveck, 2004). In contrast, if scalar inferences are truly context-dependent, then they would incur processing costs in situations where they are not licensed by the context. According to Breheny, Katsos and Williams (2006), Relevance Theory predicts that in a neutral context (i.e., without a discourse context that biases towards either a logical or a pragmatic interpretation), no scalar inference will initially be computed, and only when the logical interpretation is deemed insufficient will addressees invest additional cognitive effort to generate a scalar inference.\n\nTo examine the time course for the generation of scalar inferences, behavioral research on scalar inferences has often used the sentence-verification paradigm (e.g., Bott & Noveck, 2004; Noveck, 2001; Noveck & Posada, 2003; Feeney, Scafton, Duckworth & Handley, 2004; Pijnacker, Hagoort, Buitelaar, Teunisse & Geurts, 2008; De Neys & Schaeken, 2007; for reviews, see Bezuidenhout & Morris, 2004; Noveck & Reboul, 2008; Noveck & Sperber, 2004, 2007; Huang & Snedeker, 2009; Sedivy, 2007). In sentence-verification tasks participants are asked to judge the truth of a statement, and in speeded sentence-verification tasks participants are asked to do this as fast as possible. Because the logical and pragmatic interpretation of informative sentences yield identical truth-values, the dependent measure of whether a scalar inference has been made is whether participants respond ‘false’ to an underinformative scalar statement (e.g., “Some people have lungs”). An often reported finding is that participants who respond ‘false’ to underinformative sentences are slower than those who respond ‘true’ (e.g., Bott & Noveck, 2004; Noveck & Posada, 2003; Rips, 1975). This is the case regardless of whether participants are explicitly instructed to respond ‘false’ or whether they spontaneously decide to do so (e.g., Bott & Noveck, 2004). These results have been interpreted as suggesting that scalar inferences are associated with additional processing costs and result from a delayed decision process (e.g., Bott & Noveck, 2004; Noveck & Posada, 2003; Noveck & Reboul, 2008).\n\nAlthough using a sentence-verification task makes intuitive sense when dealing with truth-value, its interpretation is subject to a number of important caveats, as has already been noted by several researchers (Feeney et al., 2004; Grodner et al., 2010; Huang & Snedeker, 2009). For example, evaluating the logical meaning of an underinformative sentence may be inherently easier than evaluating its pragmatic meaning because one needs only one or two examples to verify the logical meaning (one or two people that have lungs) whereas one may need to do a more extended analysis to falsify the pragmatic meaning (e.g., search of, and failing to find counterexamples in memory; see also Grodner et al., 2010; Huang & Snedeker, 2009). Thus, it may not necessarily be the case that generating the pragmatic meaning requires additional processing effort and time, but rather refuting it. Another important concern is that speeded sentence verification is a relatively unnatural task that may encourage participants to ignore their pragmatic knowledge (Feeney et al., 2004), and it is hardly representative of how people process language in everyday life. Importantly, people who do generate scalar inferences are also slower in other conditions (e.g., Noveck & Posada, 2003), suggestive of a more general difference in task-related strategic processing. Finally, reaction times in verification tasks are generally quite slow, over 600 ms when statements are presented word by word (e.g., Noveck & Posada, 2003, Bott & Noveck, 2004) or even in the order of seconds when sentences are presented as a whole (e.g., Pijnacker et al., 2008; De Neys & Schaeken, 2007). In this regard, the results from verification tasks should be taken to reflect the combination of early stages of language processing as well as the output of downstream decision processes that follow them (e.g. Kounios & Holcomb, 1992).\n\nRecently, researchers have overcome these problems by using a more indirect, high temporal resolution measure of scalar processing – the visual-world paradigm. Using this paradigm, Huang & Snedeker (2009) recorded eye-movements while participants received auditory instructions such as “Click on the girl that has some of the socks” or “Click on the girl that has all of the soccer balls” in the presence of a display in which one girl had two socks from the four socks that were present in the display, and another girl had all three soccer balls that were present in the display. The temporary referential ambiguity in the instruction at the point of ‘some’ could, in principle, be resolved immediately if participants made a scalar inference that would restrict ‘some’ to a proper subset. Participants, however, were substantially delayed, to ‘some’, but not when the instruction contained the word ‘all’. Based on this observation, Huang and Snedeker argued that ‘pragmatic’ scalar inferences are delayed relative to the ‘semantic’ logical interpretation (see also Bott & Noveck, 2004; Breheny et al., 2006; De Neys & Schaeken, 2007; Noveck & Posada, 2003).\n\nHowever, Grodner and colleagues (Grodner, Klein, Carbary & Tanenhaus, 2010) note that ‘some’ is not unambiguously associated with a scalar inference (e.g., “Click on the girl with some socks” does not imply other socks are in the discourse), and that it was the partitive construction ‘of the’ that allowed for identification of the target in the Huang and Snedeker study. In contrast, for all, the quantifier itself was sufficient to identify the target. In a related study by Grodner et al. (2010) that circumvented these and some additional issues, scalar inference associated with pragmatic-some was not delayed relative to expressions that did not require a scalar inference. Thus, in contrast to the Huang & Snedeker (2009) results, the Grodner et al. results suggest that the pragmatic meaning of scalar expressions is rapidly available.\n\nIn the present study on scalar processing, we employed another indirect, high temporal resolution measure of language comprehension, namely Event-Related Potentials (ERPs). An important advantage of ERPs is that they provide both quantitative and qualitative information about language processing well in advance of (and without the principled need for) an explicit behavioral response (e.g., Van Berkum, 2004). In particular, we focus on the N400 ERP component (Kutas & Hillyard, 1980, 1984; see Kutas, Van Petten & Kluender, 2006, for review), a negative deflection in the ERP that emerges somewhere between 150 and 300 milliseconds after the onset of a word and that peaks at about 400 ms, with a maximum over the back of the head (i.e., electrodes at parietal locations). The N400 is, in principle, elicited by every content word, and its amplitude decreases in size and in a gradual manner when the word fits the context better (e.g., Kutas et al., 2006; Van Berkum, Brown, Zwitserlood, Kooijman, & Hagoort, 2005). A differential effect of two conditions on the N400 amplitude is referred to as an N400 effect. The functional significance of the N400 is still under debate (e.g., Kutas et al., 2006; Lau, Phillips & Poeppel, 2008; Van Berkum, 2009), but there is a general consensus that its amplitude reflects the fit between the lexical-semantic meaning of an incoming word and the interaction between linguistic context (at the level of single words, sentences and discourse) with information stored in memory (e.g., semantic memory, real-world knowledge and pragmatic knowledge of what a speaker is likely to say), henceforth referred to as ‘semantic fit’1. The results from recent ERP studies have shown that the interaction between context and real-world knowledge can lead people to generate expectations about the semantic properties of specific upcoming words (e.g., De Long, Urbach, & Kutas, 2005; Federmeier, 2007; Van Berkum, 2009; Van Berkum et al., 2005), although it may be that, under other circumstances, the three-way mapping process is initiated only once the word is encountered. Importantly, in a recent study on negation processing, we showed that the N400 ERP is also sensitive to the informativeness of an utterance (Nieuwland & Kuperberg, 2008). In this study, participants read sentences that were true but underinformative due to pragmatically unlicensed negation (e.g., “Bulletproof vests aren’t very dangerous…”, in which case negation is used to deny something that makes no sense to begin with, namely that bulletproof vests are dangerous). Critical words (‘dangerous’) in these sentences elicited an increased N400 responses in the same way that false sentences did. In contrast, true sentences that contained pragmatically licensed negation (e.g., “With proper equipment, scuba-diving isn’t very dangerous…”) elicited N400 responses that were indistinguishable from those elicited by true affirmative sentences (e.g., “With proper equipment, scuba-diving is very safe…”). These results suggest that pragmatic knowledge of what is an informative thing to say influences an early stage of semantic processing, and may even contribute to building up broad pragmatic expectancies about what upcoming words are likely to be encountered.\n\nThere has been one previous study investigating whether the N400 is modulated by scalar inferences. Noveck and Posada (2003) recorded readers’ electrophysiological responses to sentence-final words in underinformative sentences (e.g., “Some elephants have trunks”), patently false sentences (e.g., “Some crows have radios”) and patently true sentences (e.g., “Some houses have bricks”). Similar to previous behavioral studies, participants were asked to make a speeded sentence verification response following each sentence. The results indicated that patently true and patently false sentences elicited a larger N400 ERP than underinformative sentences, and that the N400 responses to underinformative sentences were not modulated by whether participants responded true or false to these sentences. Consistent with previous behavioral findings, the reaction time data indicated that those participants who made scalar inferences (i.e. responded ‘false’ to underinformative sentences) were much slower to respond than those who followed a literal interpretation (i.e., responded ‘true’ to underinformative sentences). Critically, however, participants who made scalar inferences were much slower in all conditions, suggesting that these participants were using a more cautious strategy overall (see Feeney et al., 2004, for a related discussion). Noveck and Posada interpreted the smaller N400 for underinformative sentences, in combination with the slow time course of scalar implicatures, as being inconsistent with a Levinsonian account. They also suggested that scalar implicatures may likely be the product of a post-semantic decision process, that, once the critical word has been encountered, computes the truth-value of the complete proposition, whereas the initial stage of semantic processing after the critical word is determined only by simple lexical-semantic relationships (e.g., see also Fischler et al., 1983; Kounios & Holcomb, 1992). Later accounts by Noveck and colleagues suggest that, under certain conditions, the pragmatic scalar meaning may be generated without having to traverse through a logical interpretation first (Noveck & Sperber, 2007). However, the general idea that pragmatic processing costs are incurred after lexico-semantic processing is complete has persisted in some models of language processing (e.g. Bornkessel-Schlesewsky & Schlesewsky, 2008; Cutler & Clifton, 1999; Fodor, 1983; Forster, 1979; Regel, Gunter & Friederici, 2010).\n\nSeveral problems with interpreting the initial ERP study by Noveck and Poseda. First, the materials in the different conditions were not matched or counterbalanced, and the words were presented in at a very fast pace (a presentation duration of 200 ms per word and an inter-word interval of 40 ms, which is about half of what is customarily used in ERP research using serial visual presentation2). Second, they employed a sentence-verification task that may have evoked decision-related positive ERPs that overlap in time and scalp distribution with the N400, and that may obscure modulations of the N400 (e.g., Kuperberg, 2007). In light of these concerns, it is important to note that patently false sentences did not evoke larger N400 responses than patently true sentences, whereas violations of real-world knowledge have consistently been associated with larger N400 responses in other studies (e.g., Fischler, Bloom, Childers, Roucos & Perry, 1983; Fischler, Childers, Achariyapaopan, & Perry 1984; Hagoort, Hald, Bastiaansen & Petersson, 2004; Hald, Steenbeek-Planting & Hagoort, 2007; Nieuwland & Kuperberg, 2008). This is problematic because these violations were included to establish a benchmark comparison for the main results.\n\nIn the current study, we addressed some of these concerns and used ERPs to examine how rapidly different individuals use their pragmatic knowledge of what is an informative versus uninformative thing to say during the processing of scalar sentences. We compared ERP responses elicited by critical words in underinformative scalar statements (e.g., ”Some people have lungs, …”) to those elicited by critical words in informative scalar statements (e.g., ”Some people have pets, …”, see for more examples). If the pragmatic meaning of weak scalar quantifiers can be used incrementally during sentence comprehension (i.e., scalar inferences are made on-line), this may guide expectations about upcoming words so that readers and listeners will expect new input to be informative (e.g., Crain & Steedman, 1985; Altmann & Steedman 1988; Tanenhaus & Trueswell, 1995; see also MacDonald, Pearlmutter, & Seidenberg, 1994). Given that the N400 is sensitive to how well a word fits the context based on both semantic and pragmatic constraints (Coulson, 2004; Kutas et al., 2006; Nieuwland & Kuperberg, 2008; Van Berkum, 2009; Van Berkum, Van den Brink, Tesink, Kos, & Hagoort, 2008), this incremental account predicts that critical words in an underinformative statement would yield a larger N400 than in an informative statement.\n\nIn contrast, if the pragmatic meaning of weak scalar quantifiers is not readily available when readers encounter the critical word, then the N400 ERP would not be sensitive to whether the statement is informative or underinformative. Rather, sentence processing and modulation of the N400 may be driven purely by lexico-semantic relationships (e.g., Otten & Van Berkum, 2007; Van Petten, 1993; Van Petten, Weckerly, McIsaac, & Kutas, 1997; for review, see Kutas et al., 2006). Because critical words in the underinformative condition (e.g., ‘lungs’) had a stronger lexical-semantic relationship to the main noun phrase in the preceding phrase (e.g., ‘people’) than in the informative condition (supported by their higher values on a Latent Semantic Analysis, LSA Landauer & Dumais, 1997), see Methods section), this would predict a smaller N400 to informative than non-informative sentences (as shown by Noveck and Poseda, 2003). This prediction also follows from Grice’s original account (for discussion see Geurts, 2009), and is generally consistent with models of language comprehension that assume that pragmatic factors come into play after an initial stage of ‘context-free’, linguistic-semantic processing (e.g. Fodor, 1983; Forster, 1979).\n\nPrevious studies have reported that individuals can vary significantly in whether and how they apply their pragmatic knowledge (e.g., Joliffe & Baron-Cohen, 1999; Musolino & Lidz, 2006; Noveck, 2001; Schindele, Lüdtke & Kaup, in press; Stanovich & West, 2001; Tager-Flusberg, 1981). Moreover, there have been several reports of individual differences in scalar inference generation (e.g., Bott & Noveck, 2004; Feeney et al., 2004; Noveck & Posada, 2003), suggesting that different people may preferentially and consistently adopt either a literal or a pragmatic interpretation when asked to evaluate underinformative sentences. Our hypothesis, which we will describe in more detail below, is that individuals with good real-world pragmatic skills are, at least initially, relatively more sensitive to the pragmatic ‘violation’ of underinformativeness and therefore more likely to show a pragmatic N400 effect, whereas processing in people with poorer real-world pragmatic skills is more likely to be driven by pure lexico-semantic association."
    }
}