{
    "id": "wrong_mix_property_spouse_00090_1",
    "rank": 13,
    "data": {
        "url": "https://worldwidescience.org/topicpages/b/based%2Bfitting%2Bmethod.html",
        "read_more_link": "",
        "language": "en",
        "title": "based fitting method: Topics by WorldWideScience.org",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/WWSlogo_wTag650px-min.png",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/OSTIlogo.svg",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/ICSTIlogo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Multiple Beta Spectrum Analysis Method Based on Spectrum Fitting\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nLee, Uk Jae; Jung, Yun Song; Kim, Hee Reyoung [UNIST, Ulsan (Korea, Republic of)\n\n2016-05-15\n\nWhen the sample of several mixed radioactive nuclides is measured, it is difficult to divide each nuclide due to the overlapping of spectrums. For this reason, simple mathematical analysis method for spectrum analysis of the mixed beta ray source has been studied. However, existing research was in need of more accurate spectral analysis method as it has a problem of accuracy. The study will describe the contents of the separation methods of the mixed beta ray source through the analysis of the beta spectrum slope based on the curve fitting to resolve the existing problem. The fitting methods including It was understood that sum of sine fitting method was the best one of such proposed methods as Fourier, polynomial, Gaussian and sum of sine to obtain equation for distribution of mixed beta spectrum. It was shown to be the most appropriate for the analysis of the spectrum with various ratios of mixed nuclides. It was thought that this method could be applied to rapid spectrum analysis of the mixed beta ray source.\n\nHybrid PSO-ASVR-based method for data fitting in the calibration of infrared radiometer\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nYang, Sen; Li, Chengwei, E-mail: heikuanghit@163.com [School of Electrical Engineering and Automation, Harbin Institute of Technology, Harbin 150001 (China)\n\n2016-06-15\n\nThe present paper describes a hybrid particle swarm optimization-adaptive support vector regression (PSO-ASVR)-based method for data fitting in the calibration of infrared radiometer. The proposed hybrid PSO-ASVR-based method is based on PSO in combination with Adaptive Processing and Support Vector Regression (SVR). The optimization technique involves setting parameters in the ASVR fitting procedure, which significantly improves the fitting accuracy. However, its use in the calibration of infrared radiometer has not yet been widely explored. Bearing this in mind, the PSO-ASVR-based method, which is based on the statistical learning theory, is successfully used here to get the relationship between the radiation of a standard source and the response of an infrared radiometer. Main advantages of this method are the flexible adjustment mechanism in data processing and the optimization mechanism in a kernel parameter setting of SVR. Numerical examples and applications to the calibration of infrared radiometer are performed to verify the performance of PSO-ASVR-based method compared to conventional data fitting methods.\n\nA library based fitting method for visual reflectance spectroscopy of human skin\n\nInternational Nuclear Information System (INIS)\n\nVerkruysse, Wim; Zhang Rong; Choi, Bernard; Lucassen, Gerald; Svaasand, Lars O; Nelson, J Stuart\n\n2005-01-01\n\nThe diffuse reflectance spectrum of human skin in the visible region (400-800 nm) contains information on the concentrations of chromophores such as melanin and haemoglobin. This information may be extracted by fitting the reflectance spectrum with an optical diffusion based analytical expression applied to a layered skin model. With the use of the analytical expression, it is assumed that light transport is dominated by scattering. For port wine stain (PWS) and highly pigmented human skin, however, this assumption may not be valid resulting in a potentially large error in visual reflectance spectroscopy (VRS). Monte Carlo based techniques can overcome this problem but are currently too computationally intensive to be combined with previously used fitting procedures. The fitting procedure presented herein is based on a library search which enables the use of accurate reflectance spectra based on forward Monte Carlo simulations or diffusion theory. This allows for accurate VRS to characterize chromophore concentrations in PWS and highly pigmented human skin. The method is demonstrated using both simulated and measured reflectance spectra. An additional advantage of the method is that the fitting procedure is very fast\n\nA library based fitting method for visual reflectance spectroscopy of human skin\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nVerkruysse, Wim [Beckman Laser Institute, University of California, Irvine, CA 92612 (United States); Zhang Rong [Beckman Laser Institute, University of California, Irvine, CA 92612 (United States); Choi, Bernard [Beckman Laser Institute, University of California, Irvine, CA 92612 (United States); Lucassen, Gerald [Personal Care Institute, Philips Research, Prof Holstlaan 4, Eindhoven (Netherlands); Svaasand, Lars O [Department of Physical Electronics Norwegian University of Science and Technology, N-7491 Trondheim (Norway); Nelson, J Stuart [Beckman Laser Institute, University of California, Irvine, CA 92612 (United States)\n\n2005-01-07\n\nThe diffuse reflectance spectrum of human skin in the visible region (400-800 nm) contains information on the concentrations of chromophores such as melanin and haemoglobin. This information may be extracted by fitting the reflectance spectrum with an optical diffusion based analytical expression applied to a layered skin model. With the use of the analytical expression, it is assumed that light transport is dominated by scattering. For port wine stain (PWS) and highly pigmented human skin, however, this assumption may not be valid resulting in a potentially large error in visual reflectance spectroscopy (VRS). Monte Carlo based techniques can overcome this problem but are currently too computationally intensive to be combined with previously used fitting procedures. The fitting procedure presented herein is based on a library search which enables the use of accurate reflectance spectra based on forward Monte Carlo simulations or diffusion theory. This allows for accurate VRS to characterize chromophore concentrations in PWS and highly pigmented human skin. The method is demonstrated using both simulated and measured reflectance spectra. An additional advantage of the method is that the fitting procedure is very fast.\n\nA library based fitting method for visual reflectance spectroscopy of human skin\n\nScience.gov (United States)\n\nVerkruysse, Wim; Zhang, Rong; Choi, Bernard; Lucassen, Gerald; Svaasand, Lars O.; Nelson, J. Stuart\n\n2005-01-01\n\nThe diffuse reflectance spectrum of human skin in the visible region (400-800 nm) contains information on the concentrations of chromophores such as melanin and haemoglobin. This information may be extracted by fitting the reflectance spectrum with an optical diffusion based analytical expression applied to a layered skin model. With the use of the analytical expression, it is assumed that light transport is dominated by scattering. For port wine stain (PWS) and highly pigmented human skin, however, this assumption may not be valid resulting in a potentially large error in visual reflectance spectroscopy (VRS). Monte Carlo based techniques can overcome this problem but are currently too computationally intensive to be combined with previously used fitting procedures. The fitting procedure presented herein is based on a library search which enables the use of accurate reflectance spectra based on forward Monte Carlo simulations or diffusion theory. This allows for accurate VRS to characterize chromophore concentrations in PWS and highly pigmented human skin. The method is demonstrated using both simulated and measured reflectance spectra. An additional advantage of the method is that the fitting procedure is very fast.\n\nValidation of some FM-based fitness for purpose methods\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nBroekhoven, M J.G. [Ministry of Social Affairs, The Hague (Netherlands)\n\n1988-12-31\n\nThe reliability of several FM-based fitness-for-purpose methods has been investigated on a number of objects for which accurate fracture data were available from experiments or from practice, viz. 23 wide plates, 30 mm thickness (surface and through thickness cracks, cracks at holes, with and without welds), 45 pipelines sections with cracks, pressure vessels and a T-joint. The methods applied mainly comprise ASME XI, PD 6493 and R6. This contribution reviews the results. (author). 11 refs.\n\nTHE CPA QUALIFICATION METHOD BASED ON THE GAUSSIAN CURVE FITTING\n\nDirectory of Open Access Journals (Sweden)\n\nM.T. Adithia\n\n2015-01-01\n\nFull Text Available The Correlation Power Analysis (CPA attack is an attack on cryptographic devices, especially smart cards. The results of the attack are correlation traces. Based on the correlation traces, an evaluation is done to observe whether significant peaks appear in the traces or not. The evaluation is done manually, by experts. If significant peaks appear then the smart card is not considered secure since it is assumed that the secret key is revealed. We develop a method that objectively detects peaks and decides which peak is significant. We conclude that using the Gaussian curve fitting method, the subjective qualification of the peak significance can be objectified. Thus, better decisions can be taken by security experts. We also conclude that the Gaussian curve fitting method is able to show the influence of peak sizes, especially the width and height, to a significance of a particular peak.\n\nFuzzy Analytic Hierarchy Process-based Chinese Resident Best Fitness Behavior Method Research.\n\nScience.gov (United States)\n\nWang, Dapeng; Zhang, Lan\n\n2015-01-01\n\nWith explosive development in Chinese economy and science and technology, people's pursuit of health becomes more and more intense, therefore Chinese resident sports fitness activities have been rapidly developed. However, different fitness events popularity degrees and effects on body energy consumption are different, so bases on this, the paper researches on fitness behaviors and gets Chinese residents sports fitness behaviors exercise guide, which provides guidance for propelling to national fitness plan's implementation and improving Chinese resident fitness scientization. The paper starts from the perspective of energy consumption, it mainly adopts experience method, determines Chinese resident favorite sports fitness event energy consumption through observing all kinds of fitness behaviors energy consumption, and applies fuzzy analytic hierarchy process to make evaluation on bicycle riding, shadowboxing practicing, swimming, rope skipping, jogging, running, aerobics these seven fitness events. By calculating fuzzy rate model's membership and comparing their sizes, it gets fitness behaviors that are more helpful for resident health, more effective and popular. Finally, it gets conclusions that swimming is a best exercise mode and its membership is the highest. Besides, the memberships of running, rope skipping and shadowboxing practicing are also relative higher. It should go in for bodybuilding by synthesizing above several kinds of fitness events according to different physical conditions; different living conditions so that can better achieve the purpose of fitness exercises.\n\nA GPS Satellite Clock Offset Prediction Method Based on Fitting Clock Offset Rates Data\n\nDirectory of Open Access Journals (Sweden)\n\nWANG Fuhong\n\n2016-12-01\n\nFull Text Available It is proposed that a satellite atomic clock offset prediction method based on fitting and modeling clock offset rates data. This method builds quadratic model or linear model combined with periodic terms to fit the time series of clock offset rates, and computes the model coefficients of trend with the best estimation. The clock offset precisely estimated at the initial prediction epoch is directly adopted to calculate the model coefficient of constant. The clock offsets in the rapid ephemeris (IGR provided by IGS are used as modeling data sets to perform certain experiments for different types of GPS satellite clocks. The results show that the clock prediction accuracies of the proposed method for 3, 6, 12 and 24 h achieve 0.43, 0.58, 0.90 and 1.47 ns respectively, which outperform the traditional prediction method based on fitting original clock offsets by 69.3%, 61.8%, 50.5% and 37.2%. Compared with the IGU real-time clock products provided by IGS, the prediction accuracies of the new method have improved about 15.7%, 23.7%, 27.4% and 34.4% respectively.\n\nA graph-based method for fitting planar B-spline curves with intersections\n\nDirectory of Open Access Journals (Sweden)\n\nPengbo Bo\n\n2016-01-01\n\nFull Text Available The problem of fitting B-spline curves to planar point clouds is studied in this paper. A novel method is proposed to deal with the most challenging case where multiple intersecting curves or curves with self-intersection are necessary for shape representation. A method based on Delauney Triangulation of data points is developed to identify connected components which is also capable of removing outliers. A skeleton representation is utilized to represent the topological structure which is further used to create a weighted graph for deciding the merging of curve segments. Different to existing approaches which utilize local shape information near intersections, our method considers shape characteristics of curve segments in a larger scope and is thus capable of giving more satisfactory results. By fitting each group of data points with a B-spline curve, we solve the problems of curve structure reconstruction from point clouds, as well as the vectorization of simple line drawing images by drawing lines reconstruction.\n\nA Data Forward Stepwise Fitting Algorithm Based on Orthogonal Function System\n\nDirectory of Open Access Journals (Sweden)\n\nLi Han-Ju\n\n2017-01-01\n\nFull Text Available Data fitting is the main method of functional data analysis, and it is widely used in the fields of economy, social science, engineering technology and so on. Least square method is the main method of data fitting, but the least square method is not convergent, no memory property, big fitting error and it is easy to over fitting. Based on the orthogonal trigonometric function system, this paper presents a data forward stepwise fitting algorithm. This algorithm takes forward stepwise fitting strategy, each time using the nearest base function to fit the residual error generated by the previous base function fitting, which makes the residual mean square error minimum. In this paper, we theoretically prove the convergence, the memory property and the fitting error diminishing character for the algorithm. Experimental results show that the proposed algorithm is effective, and the fitting performance is better than that of the least square method and the forward stepwise fitting algorithm based on the non-orthogonal function system.\n\nConvolution based profile fitting\n\nInternational Nuclear Information System (INIS)\n\nKern, A.; Coelho, A.A.; Cheary, R.W.\n\n2002-01-01\n\nFull text: In convolution based profile fitting, profiles are generated by convoluting functions together to form the observed profile shape. For a convolution of 'n' functions this process can be written as, Y(2Î¸)=F 1 (2Î¸)x F 2 (2Î¸)x... x F i (2Î¸)x....xF n (2Î¸). In powder diffractometry the functions F i (2Î¸) can be interpreted as the aberration functions of the diffractometer, but in general any combination of appropriate functions for F i (2Î¸) may be used in this context. Most direct convolution fitting methods are restricted to combinations of F i (2Î¸) that can be convoluted analytically (e.g. GSAS) such as Lorentzians, Gaussians, the hat (impulse) function and the exponential function. However, software such as TOPAS is now available that can accurately convolute and refine a wide variety of profile shapes numerically, including user defined profiles, without the need to convolute analytically. Some of the most important advantages of modern convolution based profile fitting are: 1) virtually any peak shape and angle dependence can normally be described using minimal profile parameters in laboratory and synchrotron X-ray data as well as in CW and TOF neutron data. This is possible because numerical convolution and numerical differentiation is used within the refinement procedure so that a wide range of functions can easily be incorporated into the convolution equation; 2) it can use physically based diffractometer models by convoluting the instrument aberration functions. This can be done for most laboratory based X-ray powder diffractometer configurations including conventional divergent beam instruments, parallel beam instruments, and diffractometers used for asymmetric diffraction. It can also accommodate various optical elements (e.g. multilayers and monochromators) and detector systems (e.g. point and position sensitive detectors) and has already been applied to neutron powder diffraction systems (e.g. ANSTO) as well as synchrotron based\n\nAutomated Model Fit Method for Diesel Engine Control Development\n\nNARCIS (Netherlands)\n\nSeykens, X.; Willems, F.P.T.; Kuijpers, B.; Rietjens, C.\n\n2014-01-01\n\nThis paper presents an automated fit for a control-oriented physics-based diesel engine combustion model. This method is based on the combination of a dedicated measurement procedure and structured approach to fit the required combustion model parameters. Only a data set is required that is\n\nAutomated model fit method for diesel engine control development\n\nNARCIS (Netherlands)\n\nSeykens, X.L.J.; Willems, F.P.T.; Kuijpers, B.; Rietjens, C.J.H.\n\n2014-01-01\n\nThis paper presents an automated fit for a control-oriented physics-based diesel engine combustion model. This method is based on the combination of a dedicated measurement procedure and structured approach to fit the required combustion model parameters. Only a data set is required that is\n\nvFitness: a web-based computing tool for improving estimation of in vitro HIV-1 fitness experiments\n\nDirectory of Open Access Journals (Sweden)\n\nDemeter Lisa\n\n2010-05-01\n\nFull Text Available Abstract Background The replication rate (or fitness between viral variants has been investigated in vivo and in vitro for human immunodeficiency virus (HIV. HIV fitness plays an important role in the development and persistence of drug resistance. The accurate estimation of viral fitness relies on complicated computations based on statistical methods. This calls for tools that are easy to access and intuitive to use for various experiments of viral fitness. Results Based on a mathematical model and several statistical methods (least-squares approach and measurement error models, a Web-based computing tool has been developed for improving estimation of virus fitness in growth competition assays of human immunodeficiency virus type 1 (HIV-1. Conclusions Unlike the two-point calculation used in previous studies, the estimation here uses linear regression methods with all observed data in the competition experiment to more accurately estimate relative viral fitness parameters. The dilution factor is introduced for making the computational tool more flexible to accommodate various experimental conditions. This Web-based tool is implemented in C# language with Microsoft ASP.NET, and is publicly available on the Web at http://bis.urmc.rochester.edu/vFitness/.\n\nFractal Image Coding Based on a Fitting Surface\n\nDirectory of Open Access Journals (Sweden)\n\nSheng Bi\n\n2014-01-01\n\nFull Text Available A no-search fractal image coding method based on a fitting surface is proposed. In our research, an improved gray-level transform with a fitting surface is introduced. One advantage of this method is that the fitting surface is used for both the range and domain blocks and one set of parameters can be saved. Another advantage is that the fitting surface can approximate the range and domain blocks better than the previous fitting planes; this can result in smaller block matching errors and better decoded image quality. Since the no-search and quadtree techniques are adopted, smaller matching errors also imply less number of blocks matching which results in a faster encoding process. Moreover, by combining all the fitting surfaces, a fitting surface image (FSI is also proposed to speed up the fractal decoding. Experiments show that our proposed method can yield superior performance over the other three methods. Relative to range-averaged image, FSI can provide faster fractal decoding process. Finally, by combining the proposed fractal coding method with JPEG, a hybrid coding method is designed which can provide higher PSNR than JPEG while maintaining the same Bpp.\n\nDEM4-26, Least Square Fit for IBM PC by Deming Method\n\nInternational Nuclear Information System (INIS)\n\nRinard, P.M.; Bosler, G.E.\n\n1989-01-01\n\n1 - Description of program or function: DEM4-26 is a generalized least square fitting program based on Deming's method. Functions built into the program for fitting include linear, quadratic, cubic, power, Howard's, exponential, and Gaussian; others can easily be added. The program has the following capabilities: (1) entry, editing, and saving of data; (2) fitting of any of the built-in functions or of a user-supplied function; (3) plotting the data and fitted function on the display screen, with error limits if requested, and with the option of copying the plot to the printer; (4) interpolation of x or y values from the fitted curve with error estimates based on error limits selected by the user; and (5) plotting the residuals between the y data values and the fitted curve, with the option copying the plot to the printer. 2 - Method of solution: Deming's method\n\nA New Method to Estimate Changes in Glacier Surface Elevation Based on Polynomial Fitting of Sparse ICESatâGLAS Footprints\n\nDirectory of Open Access Journals (Sweden)\n\nTianjin Huang\n\n2017-08-01\n\nFull Text Available We present in this paper a polynomial fitting method applicable to segments of footprints measured by the Geoscience Laser Altimeter System (GLAS to estimate glacier thickness change. Our modification makes the method applicable to complex topography, such as a large mountain glacier. After a full analysis of the planar fitting method to characterize errors of estimates due to complex topography, we developed an improved fitting method by adjusting a binary polynomial surface to local topography. The improved method and the planar fitting method were tested on the accumulation areas of the Naimonaânyi glacier and Yanong glacier on along-track facets with lengths of 1000 m, 1500 m, 2000 m, and 2500 m, respectively. The results show that the improved method gives more reliable estimates of changes in elevation than planar fitting. The improved method was also tested on Guliya glacier with a large and relatively flat area and the Chasku Muba glacier with very complex topography. The results in these test sites demonstrate that the improved method can give estimates of glacier thickness change on glaciers with a large area and a complex topography. Additionally, the improved method based on GLAS Data and Shuttle Radar Topography Mission-Digital Elevation Model (SRTM-DEM can give estimates of glacier thickness change from 2000 to 2008/2009, since it takes the 2000 SRTM-DEM as a reference, which is a longer period than 2004 to 2008/2009, when using the GLAS data only and the planar fitting method.\n\nCurve fitting methods for solar radiation data modeling\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nKarim, Samsul Ariffin Abdul, E-mail: samsul-ariffin@petronas.com.my, E-mail: balbir@petronas.com.my; Singh, Balbir Singh Mahinder, E-mail: samsul-ariffin@petronas.com.my, E-mail: balbir@petronas.com.my [Department of Fundamental and Applied Sciences, Faculty of Sciences and Information Technology, Universiti Teknologi PETRONAS, Bandar Seri Iskandar, 31750 Tronoh, Perak Darul Ridzuan (Malaysia)\n\n2014-10-24\n\nThis paper studies the use of several type of curve fitting method to smooth the global solar radiation data. After the data have been fitted by using curve fitting method, the mathematical model of global solar radiation will be developed. The error measurement was calculated by using goodness-fit statistics such as root mean square error (RMSE) and the value of R{sup 2}. The best fitting methods will be used as a starting point for the construction of mathematical modeling of solar radiation received in Universiti Teknologi PETRONAS (UTP) Malaysia. Numerical results indicated that Gaussian fitting and sine fitting (both with two terms) gives better results as compare with the other fitting methods.\n\nCurve fitting methods for solar radiation data modeling\n\nScience.gov (United States)\n\nKarim, Samsul Ariffin Abdul; Singh, Balbir Singh Mahinder\n\n2014-10-01\n\nThis paper studies the use of several type of curve fitting method to smooth the global solar radiation data. After the data have been fitted by using curve fitting method, the mathematical model of global solar radiation will be developed. The error measurement was calculated by using goodness-fit statistics such as root mean square error (RMSE) and the value of R2. The best fitting methods will be used as a starting point for the construction of mathematical modeling of solar radiation received in Universiti Teknologi PETRONAS (UTP) Malaysia. Numerical results indicated that Gaussian fitting and sine fitting (both with two terms) gives better results as compare with the other fitting methods.\n\nCurve fitting methods for solar radiation data modeling\n\nInternational Nuclear Information System (INIS)\n\nKarim, Samsul Ariffin Abdul; Singh, Balbir Singh Mahinder\n\n2014-01-01\n\nThis paper studies the use of several type of curve fitting method to smooth the global solar radiation data. After the data have been fitted by using curve fitting method, the mathematical model of global solar radiation will be developed. The error measurement was calculated by using goodness-fit statistics such as root mean square error (RMSE) and the value of R 2 . The best fitting methods will be used as a starting point for the construction of mathematical modeling of solar radiation received in Universiti Teknologi PETRONAS (UTP) Malaysia. Numerical results indicated that Gaussian fitting and sine fitting (both with two terms) gives better results as compare with the other fitting methods\n\nA chord error conforming tool path B-spline fitting method for NC machining based on energy minimization and LSPIA\n\nOpenAIRE\n\nHe, Shanshan; Ou, Daojiang; Yan, Changya; Lee, Chen-Han\n\n2015-01-01\n\nPiecewise linear (G01-based) tool paths generated by CAM systems lack G1 and G2 continuity. The discontinuity causes vibration and unnecessary hesitation during machining. To ensure efficient high-speed machining, a method to improve the continuity of the tool paths is required, such as B-spline fitting that approximates G01 paths with B-spline curves. Conventional B-spline fitting approaches cannot be directly used for tool path B-spline fitting, because they have shortages such as numerical...\n\nMethod for fitting crystal field parameters and the energy level fitting for Yb3+ in crystal SC2O3\n\nInternational Nuclear Information System (INIS)\n\nQing-Li, Zhang; Kai-Jie, Ning; Jin, Xiao; Li-Hua, Ding; Wen-Long, Zhou; Wen-Peng, Liu; Shao-Tang, Yin; Hai-He, Jiang\n\n2010-01-01\n\nA method to compute the numerical derivative of eigenvalues of parameterized crystal field Hamiltonian matrix is given, based on the numerical derivatives the general iteration methods such as LevenbergâMarquardt, Newton method, and so on, can be used to solve crystal field parameters by fitting to experimental energy levels. With the numerical eigenvalue derivative, a detailed iteration algorithm to compute crystal field parameters by fitting experimental energy levels has also been described. This method is used to compute the crystal parameters of Yb 3+ in Sc 2 O 3 crystal, which is prepared by a co-precipitation method and whose structure was refined by Rietveld method. By fitting on the parameters of a simple overlap model of crystal field, the results show that the new method can fit the crystal field energy splitting with fast convergence and good stability. (condensed matter: electronic structure, electrical, magnetic, and optical properties)\n\nTwo-Stage Method Based on Local Polynomial Fitting for a Linear Heteroscedastic Regression Model and Its Application in Economics\n\nDirectory of Open Access Journals (Sweden)\n\nLiyun Su\n\n2012-01-01\n\nFull Text Available We introduce the extension of local polynomial fitting to the linear heteroscedastic regression model. Firstly, the local polynomial fitting is applied to estimate heteroscedastic function, then the coefficients of regression model are obtained by using generalized least squares method. One noteworthy feature of our approach is that we avoid the testing for heteroscedasticity by improving the traditional two-stage method. Due to nonparametric technique of local polynomial estimation, we do not need to know the heteroscedastic function. Therefore, we can improve the estimation precision, when the heteroscedastic function is unknown. Furthermore, we focus on comparison of parameters and reach an optimal fitting. Besides, we verify the asymptotic normality of parameters based on numerical simulations. Finally, this approach is applied to a case of economics, and it indicates that our method is surely effective in finite-sample situations.\n\nFATAL, General Experiment Fitting Program by Nonlinear Regression Method\n\nInternational Nuclear Information System (INIS)\n\nSalmon, L.; Budd, T.; Marshall, M.\n\n1982-01-01\n\n1 - Description of problem or function: A generalized fitting program with a free-format keyword interface to the user. It permits experimental data to be fitted by non-linear regression methods to any function describable by the user. The user requires the minimum of computer experience but needs to provide a subroutine to define his function. Some statistical output is included as well as 'best' estimates of the function's parameters. 2 - Method of solution: The regression method used is based on a minimization technique devised by Powell (Harwell Subroutine Library VA05A, 1972) which does not require the use of analytical derivatives. The method employs a quasi-Newton procedure balanced with a steepest descent correction. Experience shows this to be efficient for a very wide range of application. 3 - Restrictions on the complexity of the problem: The current version of the program permits functions to be defined with up to 20 parameters. The function may be fitted to a maximum of 400 points, preferably with estimated values of weight given\n\nSimultaneous pattern recognition and track fitting by the Kalman filtering method\n\nInternational Nuclear Information System (INIS)\n\nBilloir, P.\n\n1990-01-01\n\nA progressive pattern recognition algorithm based on the Kalman filtering method has been tested. The algorithm starts from a small track segment or from a fitted track of a neighbouring detector, then extends the candidate tracks by adding measured points one by one. The fitted parameters and weight matrix of the candidate track are updated when adding a point, and give an increasing precision on prediction of the next point. Thus, pattern recognition and track fitting can be accomplished simultaneously. The method has been implemented and tested for track reconstruction for the vertex detector of the ZEUS experiment at DESY. Detailed procedures of the method and its performance are presented. Its flexibility is described as well. (orig.)\n\nPerformance of spectral fitting methods for vegetation fluorescence quantification\n\nNARCIS (Netherlands)\n\nMeroni, M.; Busetto, D.; Colombo, R.; Guanter, L.; Moreno, J.; Verhoef, W.\n\n2010-01-01\n\nThe Fraunhofer Line Discriminator (FLD) principle has long been considered as the reference method to quantify solar-induced chlorophyll fluorescence (F) from passive remote sensing measurements. Recently, alternative retrieval algorithms based on the spectral fitting of hyperspectral radiance\n\nA comparison of fitness-case sampling methods for genetic programming\n\nScience.gov (United States)\n\nMartÃ­nez, Yuliana; Naredo, Enrique; Trujillo, Leonardo; Legrand, Pierrick; LÃ³pez, Uriel\n\n2017-11-01\n\nGenetic programming (GP) is an evolutionary computation paradigm for automatic program induction. GP has produced impressive results but it still needs to overcome some practical limitations, particularly its high computational cost, overfitting and excessive code growth. Recently, many researchers have proposed fitness-case sampling methods to overcome some of these problems, with mixed results in several limited tests. This paper presents an extensive comparative study of four fitness-case sampling methods, namely: Interleaved Sampling, Random Interleaved Sampling, Lexicase Selection and Keep-Worst Interleaved Sampling. The algorithms are compared on 11 symbolic regression problems and 11 supervised classification problems, using 10 synthetic benchmarks and 12 real-world data-sets. They are evaluated based on test performance, overfitting and average program size, comparing them with a standard GP search. Comparisons are carried out using non-parametric multigroup tests and post hoc pairwise statistical tests. The experimental results suggest that fitness-case sampling methods are particularly useful for difficult real-world symbolic regression problems, improving performance, reducing overfitting and limiting code growth. On the other hand, it seems that fitness-case sampling cannot improve upon GP performance when considering supervised binary classification.\n\nPrediction of Pressing Quality for Press-Fit Assembly Based on Press-Fit Curve and Maximum Press-Mounting Force\n\nDirectory of Open Access Journals (Sweden)\n\nBo You\n\n2015-01-01\n\nFull Text Available In order to predict pressing quality of precision press-fit assembly, press-fit curves and maximum press-mounting force of press-fit assemblies were investigated by finite element analysis (FEA. The analysis was based on a 3D Solidworks model using the real dimensions of the microparts and the subsequent FEA model that was built using ANSYS Workbench. The press-fit process could thus be simulated on the basis of static structure analysis. To verify the FEA results, experiments were carried out using a press-mounting apparatus. The results show that the press-fit curves obtained by FEA agree closely with the curves obtained using the experimental method. In addition, the maximum press-mounting force calculated by FEA agrees with that obtained by the experimental method, with the maximum deviation being 4.6%, a value that can be tolerated. The comparison shows that the press-fit curve and max press-mounting force calculated by FEA can be used for predicting the pressing quality during precision press-fit assembly.\n\nA kinematic fit method for all-photon events\n\nInternational Nuclear Information System (INIS)\n\nDu Shuxian; Yuan Changzheng; Chinese Academy of Sciences, Beijing\n\n2006-01-01\n\nAn improved kinematic fit method is developed for analyzing all-photon events, where the interaction point is unknown. The fitting algorithm is checked with Monte Carlo samples to ensure that the fitting program works properly. This is applied to the Monte Carlo simulated Ï(2S) decays. A higher efficiency is achieved. This method can be generally applied to analyzing all-photon events at electron-positron collider. (authors)\n\nUncertainty evaluation for ordinary least-square fitting with arbitrary order polynomial in joule balance method\n\nInternational Nuclear Information System (INIS)\n\nYou, Qiang; Xu, JinXin; Wang, Gang; Zhang, Zhonghua\n\n2016-01-01\n\nThe ordinary least-square fitting with polynomial is used in both the dynamic phase of the watt balance method and the weighting phase of joule balance method but few researches have been conducted to evaluate the uncertainty of the fitting data in the electrical balance methods. In this paper, a matrix-calculation method for evaluating the uncertainty of the polynomial fitting data is derived and the properties of this method are studied by simulation. Based on this, another two derived methods are proposed. One is used to find the optimal fitting order for the watt or joule balance methods. Accuracy and effective factors of this method are experimented with simulations. The other is used to evaluate the uncertainty of the integral of the fitting data for joule balance, which is demonstrated with an experiment from the NIM-1 joule balance. (paper)\n\nSpectrum interrogation of fiber acoustic sensor based on self-fitting and differential method.\n\nScience.gov (United States)\n\nFu, Xin; Lu, Ping; Ni, Wenjun; Liao, Hao; Wang, Shun; Liu, Deming; Zhang, Jiangshan\n\n2017-02-20\n\nIn this article, we propose an interrogation method of fiber acoustic sensor to recover the time-domain signal from the sensor spectrum. The optical spectrum of the sensor will show a ripple waveform when responding to acoustic signal due to the scanning process in a certain wavelength range. The reason behind this phenomenon is the dynamic variation of the sensor spectrum while the intensity of different wavelength is acquired at different time in a scanning period. The frequency components can be extracted from the ripple spectrum assisted by the wavelength scanning speed. The signal is able to be recovered by differential between the ripple spectrum and its self-fitted curve. The differential process can eliminate the interference caused by environmental perturbations such as temperature or refractive index (RI), etc. The proposed method is appropriate for fiber acoustic sensors based on gratings or interferometers. A long period grating (LPG) is adopted as an acoustic sensor head to prove the feasibility of the interrogation method in experiment. The ability to compensate the environmental fluctuations is also demonstrated.\n\nA chord error conforming tool path B-spline fitting method for NC machining based on energy minimization and LSPIA\n\nDirectory of Open Access Journals (Sweden)\n\nShanshan He\n\n2015-10-01\n\nFull Text Available Piecewise linear (G01-based tool paths generated by CAM systems lack G1 and G2 continuity. The discontinuity causes vibration and unnecessary hesitation during machining. To ensure efficient high-speed machining, a method to improve the continuity of the tool paths is required, such as B-spline fitting that approximates G01 paths with B-spline curves. Conventional B-spline fitting approaches cannot be directly used for tool path B-spline fitting, because they have shortages such as numerical instability, lack of chord error constraint, and lack of assurance of a usable result. Progressive and Iterative Approximation for Least Squares (LSPIA is an efficient method for data fitting that solves the numerical instability problem. However, it does not consider chord errors and needs more work to ensure ironclad results for commercial applications. In this paper, we use LSPIA method incorporating Energy term (ELSPIA to avoid the numerical instability, and lower chord errors by using stretching energy term. We implement several algorithm improvements, including (1 an improved technique for initial control point determination over Dominant Point Method, (2 an algorithm that updates foot point parameters as needed, (3 analysis of the degrees of freedom of control points to insert new control points only when needed, (4 chord error refinement using a similar ELSPIA method with the above enhancements. The proposed approach can generate a shape-preserving B-spline curve. Experiments with data analysis and machining tests are presented for verification of quality and efficiency. Comparisons with other known solutions are included to evaluate the worthiness of the proposed solution.\n\nDetection of concrete dam leakage using an integrated geophysical technique based on flow-field fitting method\n\nScience.gov (United States)\n\nDai, Qianwei; Lin, Fangpeng; Wang, Xiaoping; Feng, Deshan; Bayless, Richard C.\n\n2017-05-01\n\nAn integrated geophysical investigation was performed at S dam located at Dadu basin in China to assess the condition of the dam curtain. The key methodology of the integrated technique used was flow-field fitting method, which allowed identification of the hydraulic connections between the dam foundation and surface water sources (upstream and downstream), and location of the anomalous leakage outlets in the dam foundation. Limitations of the flow-field fitting method were complemented with resistivity logging to identify the internal erosion which had not yet developed into seepage pathways. The results of the flow-field fitting method and resistivity logging were consistent when compared with data provided by seismic tomography, borehole television, water injection test, and rock quality designation.\n\nDevelopment of fitting methods using geometric progression formulae of gamma-ray buildup factors\n\nInternational Nuclear Information System (INIS)\n\nYoshida, Yoshitaka\n\n2006-01-01\n\nThe gamma ray buildup factors are represented by an approximation method to speed up calculation using the point attenuation kernel method. The fitting parameters obtained by the GP formula and Taylor's formula are compiled in ANSI/ANS 6.4.3, available without any limitation. The GP formula featured high accuracy but required a high-level fitting technique. Thus the GP formula was divided into a curved line and a part representing the base values and used to develop the a fitting method and X k fitting method. As a result, this methodology showed that (1) when the fitting ranges were identical, there was no change in standard deviation when the unit penetration depth was varied; (2) even with fitting up to 300 mfp, the average standard deviation of 26 materials was 2.9% and acceptable GP parameters were extracted; (3) when the same end points of the fitting were selected and the starting points of fitting were identical with the unit penetration depth, the deviation became smaller with increasing unit penetration depth; and (4) even with the deviation adjusted to the positive side from 0.5 mfp to 300 mfp, the average standard deviation of 26 materials was 5.6%, which was an acceptable value. However, the GP parameters obtained by this methodology cannot be used for direct interpolation using gamma ray energy or materials. (author)\n\nGLOBAL AND STRICT CURVE FITTING METHOD\n\nNARCIS (Netherlands)\n\nNakajima, Y.; Mori, S.\n\n2004-01-01\n\nTo find a global and smooth curve fitting, cubic BÂ­Spline method and gatheringÂ­ line methods are investigated. When segmenting and recognizing a contour curve of character shape, some global method is required. If we want to connect contour curves around a singular point like crossing points,\n\nAn ellipse-fitting based method for efficient registration of breast masses on two mammographic views\n\nInternational Nuclear Information System (INIS)\n\nPu Jiantao; Zheng Bin; Leader, Joseph Ken; Gur, David\n\n2008-01-01\n\nWhen reading mammograms, radiologists routinely search for and compare suspicious breast lesions identified on two corresponding craniocaudal (CC) and mediolateral oblique (MLO) views. Automatically identifying and matching the same true-positive breast lesions depicted on two views is an important step for developing successful multiview based computer-aided detection (CAD) schemes. The authors developed a method to automatically register breast areas and detect matching strips of interest used to identify the matched mass regions depicted on CC and MLO views. The method uses an ellipse based model to fit the breast boundary contour (skin line) and set a local Cartesian coordinate system for each view. One intersection point between the major/minor axis and the fitted ellipse perimeter passed through breast boundary is selected as the origin and the majoraxis and the minoraxis of the ellipse are used as the two axis of the Cartesian coordinate system. When a mass is identified on one view, the scheme computes its position in the local coordinate system. Then, the distance is mapped onto the local coordinate of the other view. At the end of the mapped distance a registered centerline of the matching strip is created. The authors established an image database that includes 200 test examinations each depicting one verified mass visible on the two views. They tested whether the registered centerline identified on another view can be used to locate the matched mass region. The experiments show that the average distance between the mass region centers and the registered centerlines was Â±8.3 mm and in 91% of testing cases the registered centerline actually passes through the matched mass regions. A matching strip width of 47 mm was required to achieve 100% sensitivity for the test database. The results demonstrate the feasibility of the proposed method to automatically identify masses depicted on CC and MLO views, which may improve future development of multiview based\n\nSimplified pressure method for respirator fit testing.\n\nScience.gov (United States)\n\nHan, D; Xu, M; Foo, S; Pilacinski, W; Willeke, K\n\n1991-08-01\n\nA simplified pressure method has been developed for fit testing air-purifying respirators. In this method, the air-purifying cartridges are replaced by a pressure-sensing attachment and a valve. While wearers hold their breath, a small pump extracts air from the respirator cavity until a steady-state pressure is reached in 1 to 2 sec. The flow rate through the face seal leak is a unique function of this pressure, which is determined once for all respirators, regardless of the respirator's cavity volume or deformation because of pliability. The contaminant concentration inside the respirator depends on the degree of dilution by the flow through the cartridges. The cartridge flow varies among different brands and is measured once for each brand. The ratio of cartridge to leakflow is a measure of fit. This flow ratio has been measured on human subjects and has been compared to fit factors determined on the same subjects by means of photometric and particle count tests. The aerosol tests gave higher values of fit.\n\nComparison of estimation methods for fitting weibull distribution to ...\n\nAfrican Journals Online (AJOL)\n\nComparison of estimation methods for fitting weibull distribution to the natural stand of Oluwa Forest Reserve, Ondo State, Nigeria. ... Journal of Research in Forestry, Wildlife and Environment ... The result revealed that maximum likelihood method was more accurate in fitting the Weibull distribution to the natural stand.\n\nFitting methods to paradigms: are ergonomics methods fit for systems thinking?\n\nScience.gov (United States)\n\nSalmon, Paul M; Walker, Guy H; M Read, Gemma J; Goode, Natassia; Stanton, Neville A\n\n2017-02-01\n\nThe issues being tackled within ergonomics problem spaces are shifting. Although existing paradigms appear relevant for modern day systems, it is worth questioning whether our methods are. This paper asks whether the complexities of systems thinking, a currently ubiquitous ergonomics paradigm, are outpacing the capabilities of our methodological toolkit. This is achieved through examining the contemporary ergonomics problem space and the extent to which ergonomics methods can meet the challenges posed. Specifically, five key areas within the ergonomics paradigm of systems thinking are focused on: normal performance as a cause of accidents, accident prediction, system migration, systems concepts and ergonomics in design. The methods available for pursuing each line of inquiry are discussed, along with their ability to respond to key requirements. In doing so, a series of new methodological requirements and capabilities are identified. It is argued that further methodological development is required to provide researchers and practitioners with appropriate tools to explore both contemporary and future problems. Practitioner Summary: Ergonomics methods are the cornerstone of our discipline. This paper examines whether our current methodological toolkit is fit for purpose given the changing nature of ergonomics problems. The findings provide key research and practice requirements for methodological development.\n\nIdea of integrating fitness concepts and methods into human anatomy teaching\n\nDirectory of Open Access Journals (Sweden)\n\nPAN Guojian\n\n2013-08-01\n\nFull Text Available According to the authorâ²s many years of experience and practice in teaching human anatomy,it is summed up that an idea of integrating fitness concepts and methods into teaching of human anatomy is envisaged.It is beneficial to the cultivation of undergraduates majoring in sports about thoughts of lifelong physical education,enable students to master the basic structure based on human body and learn and master physical fitness related basic theory and practical operation skills in order to be social competitive sports workers with practical skills.\n\nBoundary fitting based segmentation of fluorescence microscopy images\n\nScience.gov (United States)\n\nLee, Soonam; Salama, Paul; Dunn, Kenneth W.; Delp, Edward J.\n\n2015-03-01\n\nSegmentation is a fundamental step in quantifying characteristics, such as volume, shape, and orientation of cells and/or tissue. However, quantification of these characteristics still poses a challenge due to the unique properties of microscopy volumes. This paper proposes a 2D segmentation method that utilizes a combination of adaptive and global thresholding, potentials, z direction refinement, branch pruning, end point matching, and boundary fitting methods to delineate tubular objects in microscopy volumes. Experimental results demonstrate that the proposed method achieves better performance than an active contours based scheme.\n\nReview of track-fitting methods in counter experiments\n\nInternational Nuclear Information System (INIS)\n\nRegler, M.; Eichinger, H.\n\n1981-01-01\n\nWe review track-fitting methods recently used in high-energy physics experiments. Assuming that the problem of pattern recognition, i.e. of grouping the often ambiguous coordinate information (as frequently measured by wire chambers) together to form track candidates, has already been solved, we try to point out the way to obtain the ultimate geometrical resolution with the smallest and fastest possible program; owing to the wide variety of detectors and experimental set-ups, no universal method has been found. Some applications will serve as examples, and based on the experience gained we will try to indicate when and under which conditions a known algorithm could be used, and this might even help in designing future experiments. (orig.)\n\nMethodology review: evaluating person fit\n\nNARCIS (Netherlands)\n\nMeijer, R.R.; Sijtsma, Klaas\n\n2001-01-01\n\nPerson-fit methods based on classical test theory-and item response theory (IRT), and methods investigating particular types of response behavior on tests, are examined. Similarities and differences among person-fit methods and their advantages and disadvantages are discussed. Sound person-fit\n\nFitting method of pseudo-polynomial for solving nonlinear parametric adjustment\n\nInstitute of Scientific and Technical Information of China (English)\n\né¶åå­¦; å®«ç§å; é­éè¿\n\n2001-01-01\n\nThe optimal condition and its geometrical characters of the least-square adjustment were proposed. Then the relation between the transformed surface and least-squares was discussed. Based on the above, a non-iterative method, called the fitting method of pseudo-polynomial, was derived in detail. The final least-squares solution can be determined with sufficient accuracy in a single step and is not attained by moving the initial point in the view of iteration. The accuracy of the solution relys wholly on the frequency of Taylor's series. The example verifies the correctness and validness of the method.\n\nDecomposition and correction overlapping peaks of LIBS using an error compensation method combined with curve fitting.\n\nScience.gov (United States)\n\nTan, Bing; Huang, Min; Zhu, Qibing; Guo, Ya; Qin, Jianwei\n\n2017-09-01\n\nThe laser induced breakdown spectroscopy (LIBS) technique is an effective method to detect material composition by obtaining the plasma emission spectrum. The overlapping peaks in the spectrum are a fundamental problem in the qualitative and quantitative analysis of LIBS. Based on a curve fitting method, this paper studies an error compensation method to achieve the decomposition and correction of overlapping peaks. The vital step is that the fitting residual is fed back to the overlapping peaks and performs multiple curve fitting processes to obtain a lower residual result. For the quantitative experiments of Cu, the Cu-Fe overlapping peaks in the range of 321-327Â nm obtained from the LIBS spectrum of five different concentrations of CuSO 4 Â·5H 2 O solution were decomposed and corrected using curve fitting and error compensation methods. Compared with the curve fitting method, the error compensation reduced the fitting residual about 18.12-32.64% and improved the correlation about 0.86-1.82%. Then, the calibration curve between the intensity and concentration of the Cu was established. It can be seen that the error compensation method exhibits a higher linear correlation between the intensity and concentration of Cu, which can be applied to the decomposition and correction of overlapping peaks in the LIBS spectrum.\n\nThree-Step Predictor-Corrector of Exponential Fitting Method for Nonlinear Schroedinger Equations\n\nInternational Nuclear Information System (INIS)\n\nTang Chen; Zhang Fang; Yan Haiqing; Luo Tao; Chen Zhanqing\n\n2005-01-01\n\nWe develop the three-step explicit and implicit schemes of exponential fitting methods. We use the three-step explicit exponential fitting scheme to predict an approximation, then use the three-step implicit exponential fitting scheme to correct this prediction. This combination is called the three-step predictor-corrector of exponential fitting method. The three-step predictor-corrector of exponential fitting method is applied to numerically compute the coupled nonlinear Schroedinger equation and the nonlinear Schroedinger equation with varying coefficients. The numerical results show that the scheme is highly accurate.\n\nThickness and fit of mouthguards according to heating methods.\n\nScience.gov (United States)\n\nMizuhashi, Fumi; Koide, Kaoru; Takahashi, Mutsumi\n\n2014-02-01\n\nThe purpose of this study was to examine the difference in the thickness and fit of mouthguards made by four different heating methods of the mouthguard sheet material. A Sports Mouthguard(Â®) of 3.8-mm thickness was used in this study. Four heating methods were performed. In one method, the sheet was heated only one side. In the other methods, one side of the sheet was heated first until the center of the sheet was displaced by 0.5Â cm, 1.0Â cm, and 1.5Â cm from the baseline, and then turned upside down and heated. The sheets were adapted using a vacuum former when the heated sheets hung 1.5Â cm from the baseline. We measured the thickness and fit of the mouthguard at the areas of the central incisor and first molar. The difference in thickness at the central incisor and first molar regions was analyzed by two-way anova. The difference in fit with different heating methods was analyzed by one-way anova. The results showed that the thickness of the mouthguard differed in the central incisor and first molar areas (PÂ heating methods. The fit of the mouthguard at the central incisor and first molar areas was significantly different among the heating methods (PÂ heated surface of the sheet contacted the surface of the working model. This finding may help to fabricate accurate mouthguards. Â© 2013 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd.\n\nA new non-iterative method for fitting Lorentzian to Moessbauer spectra\n\nInternational Nuclear Information System (INIS)\n\nMukoyama, T.; Vegh, J.\n\n1980-01-01\n\nA new method for fitting a Lorentzian function without an iterative procedure is presented. The method is quicker and simpler than the previously proposed method of non-iterative fitting. Comparison with the previous method and with the conventional iterative method has been made. It is shown that the present method gives satisfactory results. (orig.)\n\nFretting wear simulation of press-fitted shaft with finite element analysis and influence function method\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nLee, Dong Hyong; Kwon, Seok Jin [Korea Railroad Research Institute, Uiwang (Korea, Republic of); Choi, Jae Boong; Kim, Young Jin [Sungkyunkwan University, Suwon (Korea, Republic of)\n\n2008-01-15\n\nIn this paper the fretting wear of press-fitted specimens subjected to a cyclic bending load was simulated using finite element analysis and numerical method. The amount of microslip and contact variable at press-fitted and bending load condition in a press-fitted shaft was analysed by applying finite element method. With the finite element analysis result, a numerical approach was applied to predict fretting wear based on modified Archard's equation and updating the change of contact pressure caused by local wear with influence function method. The predicted wear profiles of press-fitted specimens at the contact edge wear compared with the experimental results obtained by rotating bending fatigue tests. It is shown that the depth of fretting wear by repeated slip between shaft and boss reaches the maximum value at the contact edge. The initial surface profile is continuously changed by the wear at the contact edge, and then the corresponding contact variables are redistributed. The work establishes a basis for numerical simulation of fretting wear on press fits.\n\nFretting wear simulation of press-fitted shaft with finite element analysis and influence function method\n\nInternational Nuclear Information System (INIS)\n\nLee, Dong Hyong; Kwon, Seok Jin; Choi, Jae Boong; Kim, Young Jin\n\n2008-01-01\n\nIn this paper the fretting wear of press-fitted specimens subjected to a cyclic bending load was simulated using finite element analysis and numerical method. The amount of microslip and contact variable at press-fitted and bending load condition in a press-fitted shaft was analysed by applying finite element method. With the finite element analysis result, a numerical approach was applied to predict fretting wear based on modified Archard's equation and updating the change of contact pressure caused by local wear with influence function method. The predicted wear profiles of press-fitted specimens at the contact edge wear compared with the experimental results obtained by rotating bending fatigue tests. It is shown that the depth of fretting wear by repeated slip between shaft and boss reaches the maximum value at the contact edge. The initial surface profile is continuously changed by the wear at the contact edge, and then the corresponding contact variables are redistributed. The work establishes a basis for numerical simulation of fretting wear on press fits\n\nHealth-Related Fitness Knowledge Development through Project-Based Learning\n\nScience.gov (United States)\n\nHastle, Peter A.; Chen, Senlin; Guarino, Anthony J.\n\n2017-01-01\n\nPurpose: The purpose of this study was to examine the process and outcome of an intervention using the project-based learning (PBL) model to increase students' health-related fitness (HRF) knowledge. Method: The participants were 185 fifth-grade students from three schools in Alabama (PBL group: n = 109; control group: n = 76). HRF knowledge wasâ¦\n\nTheoretical bases and possibilities of program BRASIER for experimental data fitting and management\n\nInternational Nuclear Information System (INIS)\n\nQuintero, B.; Santos, J.; Garcia Yip, F.; Lopez, I.\n\n1992-01-01\n\nIn the paper the theoretical bases and primary possibilities of the program BRASIER are shown. It was performed for the management and fitting of experimental data. Relevant characteristics are: Utilization of several regression methods, errors treatment, P oint-Drop Technique , multidimensional fitting, friendly interactivity, graphical possibilities and file management. The fact of using various regression methods has resulted in greater convergence possibility with respect to other similar programs that use an unique algorithm\n\nSelf-reported physical fitness of older persons : A substitute for performance-based measures of physical fitness?\n\nNARCIS (Netherlands)\n\nvanHeuvelen, MJG; Kempen, GIJM; Ormel, J; de Greef, M.H.G.\n\n1997-01-01\n\nTo evaluate the validity of self-report measures of physical fitness as substitutes for performance-based tests, self-reports and performance-based tests of physical fitness were compared. Subjects were a community-based sample of older adults (N = 624) aged 57 and over. The performance-based tests\n\nAn examination of resource-based and fit-based theories of stereotyping under cognitive load and fit\n\nNARCIS (Netherlands)\n\nNolan, MA; Haslam, SA; Spears, R; Oakes, PJ\n\n1999-01-01\n\nShould stereotyping be characterised as an act of cognitive miserliness of one of rational meaning-seeking? This paper uses a cognitive load paradigm to investigate the adequacy of popular resource-based explanations of stereotyping in comparison to art alternative fit-based or meaning-based\n\nA non-iterative method for fitting decay curves with background\n\nInternational Nuclear Information System (INIS)\n\nMukoyama, T.\n\n1982-01-01\n\nA non-iterative method for fitting a decay curve with background is presented. The sum of an exponential function and a constant term is linearized by the use of the difference equation and parameters are determined by the standard linear least-squares fitting. The validity of the present method has been tested against pseudo-experimental data. (orig.)\n\nHot Spots Detection of Operating PV Arrays through IR Thermal Image Using Method Based on Curve Fitting of Gray Histogram\n\nDirectory of Open Access Journals (Sweden)\n\nJiang Lin\n\n2016-01-01\n\nFull Text Available The overall efficiency of PV arrays is affected by hot spots which should be detected and diagnosed by applying responsible monitoring techniques. The method using the IR thermal image to detect hot spots has been studied as a direct, noncontact, nondestructive technique. However, IR thermal images suffer from relatively high stochastic noise and non-uniformity clutter, so the conventional methods of image processing are not effective. The paper proposes a method to detect hotspots based on curve fitting of gray histogram. The result of MATLAB simulation proves the method proposed in the paper is effective to detect the hot spots suppressing the noise generated during the process of image acquisition.\n\nCURVE LSFIT, Gamma Spectrometer Calibration by Interactive Fitting Method\n\nInternational Nuclear Information System (INIS)\n\nOlson, D.G.\n\n1992-01-01\n\n1 - Description of program or function: CURVE and LSFIT are interactive programs designed to obtain the best data fit to an arbitrary curve. CURVE finds the type of fitting routine which produces the best curve. The types of fitting routines available are linear regression, exponential, logarithmic, power, least squares polynomial, and spline. LSFIT produces a reliable calibration curve for gamma ray spectrometry by using the uncertainty value associated with each data point. LSFIT is intended for use where an entire efficiency curve is to be made starting at 30 KeV and continuing to 1836 KeV. It creates calibration curves using up to three least squares polynomial fits to produce the best curve for photon energies above 120 KeV and a spline function to combine these fitted points with a best fit for points below 120 KeV. 2 - Method of solution: The quality of fit is tested by comparing the measured y-value to the y-value calculated from the fitted curve. The fractional difference between these two values is printed for the evaluation of the quality of the fit. 3 - Restrictions on the complexity of the problem - Maxima of: 2000 data points calibration curve output (LSFIT) 30 input data points 3 least squares polynomial fits (LSFIT) The least squares polynomial fit requires that the number of data points used exceed the degree of fit by at least two\n\nA new method for curve fitting to the data with low statistics not using the chi2-method\n\nInternational Nuclear Information System (INIS)\n\nAwaya, T.\n\n1979-01-01\n\nA new method which does not use the chi 2 -fitting method is investigated in order to fit the theoretical curve to data with low statistics. The method is compared with the usual and modified chi 2 -fitting ones. The analyses are done for data which are generated by computers. It is concluded that the new method gives good results in all the cases. (Auth.)\n\nRadial artery pulse waveform analysis based on curve fitting using discrete Fourier series.\n\nScience.gov (United States)\n\nJiang, Zhixing; Zhang, David; Lu, Guangming\n\n2018-04-19\n\nRadial artery pulse diagnosis has been playing an important role in traditional Chinese medicine (TCM). For its non-invasion and convenience, the pulse diagnosis has great significance in diseases analysis of modern medicine. The practitioners sense the pulse waveforms in patients' wrist to make diagnoses based on their non-objective personal experience. With the researches of pulse acquisition platforms and computerized analysis methods, the objective study on pulse diagnosis can help the TCM to keep up with the development of modern medicine. In this paper, we propose a new method to extract feature from pulse waveform based on discrete Fourier series (DFS). It regards the waveform as one kind of signal that consists of a series of sub-components represented by sine and cosine (SC) signals with different frequencies and amplitudes. After the pulse signals are collected and preprocessed, we fit the average waveform for each sample using discrete Fourier series by least squares. The feature vector is comprised by the coefficients of discrete Fourier series function. Compared with the fitting method using Gaussian mixture function, the fitting errors of proposed method are smaller, which indicate that our method can represent the original signal better. The classification performance of proposed feature is superior to the other features extracted from waveform, liking auto-regression model and Gaussian mixture model. The coefficients of optimized DFS function, who is used to fit the arterial pressure waveforms, can obtain better performance in modeling the waveforms and holds more potential information for distinguishing different psychological states. Copyright Â© 2018 Elsevier B.V. All rights reserved.\n\nStudy on residual discharge time of lead-acid battery based on fitting method\n\nScience.gov (United States)\n\nLiu, Bing; Yu, Wangwang; Jin, Yueqiang; Wang, Shuying\n\n2017-05-01\n\nThis paper use the method of fitting to discuss the data of C problem of mathematical modeling in 2016, the residual discharge time model of lead-acid battery with 20A,30A,â¦,100A constant current discharge is obtained, and the discharge time model of discharge under arbitrary constant current is presented. The mean relative error of the model is calculated to be about 3%, which shows that the model has high accuracy. This model can provide a basis for optimizing the adaptation of power system to the electrical motor vehicle.\n\nPerson Fit Based on Statistical Process Control in an Adaptive Testing Environment. Research Report 98-13.\n\nScience.gov (United States)\n\nvan Krimpen-Stoop, Edith M. L. A.; Meijer, Rob R.\n\nPerson-fit research in the context of paper-and-pencil tests is reviewed, and some specific problems regarding person fit in the context of computerized adaptive testing (CAT) are discussed. Some new methods are proposed to investigate person fit in a CAT environment. These statistics are based on Statistical Process Control (SPC) theory. Aâ¦\n\nFit of screw-retained fixed implant frameworks fabricated by different methods: a systematic review.\n\nScience.gov (United States)\n\nAbduo, Jaafar; Lyons, Karl; Bennani, Vincent; Waddell, Neil; Swain, Michael\n\n2011-01-01\n\nThe aim of this study was to review the published literature investigating the accuracy of fit of fixed implant frameworks fabricated using different materials and methods. A comprehensive electronic search was performed through PubMed (MEDLINE) using Boolean operators to combine key words. The search was limited to articles written in English and published through May 2010. In addition, a manual search through articles and reference lists retrieved from the electronic search and peer-reviewed journals was also conducted. A total of 248 articles were retrieved, and 26 met the specified inclusion criteria for the review. The selected articles assessed the fit of fixed implant frameworks fabricated by different techniques. The investigated fabrication approaches were one-piece casting, sectioning and reconnection, spark erosion with an electric discharge machine, computer-aided design/computer-assisted manufacturing (CAD/CAM), and framework bonding to prefabricated abutment cylinders. Cast noble metal frameworks have a predictable fit, and additional fit refinement treatment is not indicated in well-controlled conditions. Base metal castings do not provide a satisfactory level of fit unless additional refinement treatment is performed, such as sectioning and laser welding or spark erosion. Spark erosion, framework bonding to prefabricated abutment cylinders, and CAD/CAM have the potential to provide implant frameworks with an excellent fit; CAD/CAM is the most consistent and least technique-sensitive of these methods.\n\nValidating the JobFit system functional assessment method\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nJenny Legge; Robin Burgess-Limerick\n\n2007-05-15\n\nWorkplace injuries are costing the Australian coal mining industry and its communities $410 Million a year. This ACARP study aims to meet those demands by developing a safe, reliable and valid pre-employment functional assessment tool. All JobFit System Pre-Employment Functional Assessments (PEFAs) consist of a musculoskeletal screen, balance test, aerobic fitness test and job-specific postural tolerances and material handling tasks. The results of each component are compared to the applicant's job demands and an overall PEFA score between 1 and 4 is given with 1 being the better score. The reliability study and validity study were conducted concurrently. The reliability study examined test-retest, intra-tester and inter-tester reliability of the JobFit System Functional Assessment Method. Overall, good to excellent reliability was found, which was sufficient to be used for comparison with injury data for determining the validity of the assessment. The overall assessment score and material handling tasks had the greatest reliability. The validity study compared the assessment results of 336 records from a Queensland underground and open cut coal mine with their injury records. A predictive relationship was found between PEFA score and the risk of a back/trunk/shoulder injury from manual handling. An association was also found between PEFA score of 1 and increased length of employment. Lower aerobic fitness test results had an inverse relationship with injury rates. The study found that underground workers, regardless of PEFA score, were more likely to have an injury when compared to other departments. No relationship was found between age and risk of injury. These results confirm the validity of the JobFit System Functional Assessment method.\n\nA systematic way for the cost reduction of density fitting methods\n\nInternational Nuclear Information System (INIS)\n\nKÃ¡llay, MihÃ¡ly\n\n2014-01-01\n\nWe present a simple approach for the reduction of the size of auxiliary basis sets used in methods exploiting the density fitting (resolution of identity) approximation for electron repulsion integrals. Starting out of the singular value decomposition of three-center two-electron integrals, new auxiliary functions are constructed as linear combinations of the original fitting functions. The new functions, which we term natural auxiliary functions (NAFs), are analogous to the natural orbitals widely used for the cost reduction of correlation methods. The use of the NAF basis enables the systematic truncation of the fitting basis, and thereby potentially the reduction of the computational expenses of the methods, though the scaling with the system size is not altered. The performance of the new approach has been tested for several quantum chemical methods. It is demonstrated that the most pronounced gain in computational efficiency can be expected for iterative models which scale quadratically with the size of the fitting basis set, such as the direct random phase approximation. The approach also has the promise of accelerating local correlation methods, for which the processing of three-center Coulomb integrals is a bottleneck\n\nAccuracy of Digital Impressions and Fitness of Single Crowns Based on Digital Impressions\n\nScience.gov (United States)\n\nYang, Xin; Lv, Pin; Liu, Yihong; Si, Wenjie; Feng, Hailan\n\n2015-01-01\n\nIn this study, the accuracy (precision and trueness) of digital impressions and the fitness of single crowns manufactured based on digital impressions were evaluated. #14-17 epoxy resin dentitions were made, while full-crown preparations of extracted natural teeth were embedded at #16. (1) To assess precision, deviations among repeated scan models made by intraoral scanner TRIOS and MHT and model scanner D700 and inEos were calculated through best-fit algorithm and three-dimensional (3D) comparison. Root mean square (RMS) and color-coded difference images were offered. (2) To assess trueness, micro computed tomography (micro-CT) was used to get the reference model (REF). Deviations between REF and repeated scan models (from (1)) were calculated. (3) To assess fitness, single crowns were manufactured based on TRIOS, MHT, D700 and inEos scan models. The adhesive gaps were evaluated under stereomicroscope after cross-sectioned. Digital impressions showed lower precision and better trueness. Except for MHT, the means of RMS for precision were lower than 10 Î¼m. Digital impressions showed better internal fitness. Fitness of single crowns based on digital impressions was up to clinical standard. Digital impressions could be an alternative method for single crowns manufacturing. PMID:28793417\n\nAccuracy of Digital Impressions and Fitness of Single Crowns Based on Digital Impressions\n\nDirectory of Open Access Journals (Sweden)\n\nXin Yang\n\n2015-06-01\n\nFull Text Available In this study, the accuracy (precision and trueness of digital impressions and the fitness of single crowns manufactured based on digital impressions were evaluated. #14-17 epoxy resin dentitions were made, while full-crown preparations of extracted natural teeth were embedded at #16. (1 To assess precision, deviations among repeated scan models made by intraoral scanner TRIOS and MHT and model scanner D700 and inEos were calculated through best-fit algorithm and three-dimensional (3D comparison. Root mean square (RMS and color-coded difference images were offered. (2 To assess trueness, micro computed tomography (micro-CT was used to get the reference model (REF. Deviations between REF and repeated scan models (from (1 were calculated. (3 To assess fitness, single crowns were manufactured based on TRIOS, MHT, D700 and inEos scan models. The adhesive gaps were evaluated under stereomicroscope after cross-sectioned. Digital impressions showed lower precision and better trueness. Except for MHT, the means of RMS for precision were lower than 10 Î¼m. Digital impressions showed better internal fitness. Fitness of single crowns based on digital impressions was up to clinical standard. Digital impressions could be an alternative method for single crowns manufacturing.\n\nMixFit\n\nDEFF Research Database (Denmark)\n\nHaller, Toomas; Leitsalu, Liis; Fischer, Krista\n\n2017-01-01\n\nAncestry information at the individual level can be a valuable resource for personalized medicine, medical, demographical and history research, as well as for tracing back personal history. We report a new method for quantitatively determining personal genetic ancestry based on genome-wide data....... Numerical ancestry component scores are assigned to individuals based on comparisons with reference populations. These comparisons are conducted with an existing analytical pipeline making use of genotype phasing, similarity matrix computation and our addition-multidimensional best fitting by Mix......Fit. The method is demonstrated by studying Estonian and Finnish populations in geographical context. We show the main differences in the genetic composition of these otherwise close European populations and how they have influenced each other. The components of our analytical pipeline are freely available...\n\nResolving overlapping peaks in ARXPS data: The effect of noise and fitting method\n\nInternational Nuclear Information System (INIS)\n\nMuÃ±oz-Flores, Jaime; Herrera-Gomez, Alberto\n\n2012-01-01\n\nHighlights: âº Noise is an important factor affecting the fitting of overlapping peaks in XPS data. âº The combined information in ARXPS data can be used to improve fitting reliability. âº The error on the estimation of the peak parameters depends on the peak-fitting method. âº Simultaneous fitting method is much more robust against noise than sequential fitting. âº The estimation of the error range is better done with ARXPS data than with XPS data. - Abstract: Peak-fitting of X-ray photoelectron spectroscopy (XPS) data can be very sensitive to noise when the difference on the binding energy among the peaks is smaller than the width of the peaks. This sensitivity depends on the fitting algorithm. Angle-resolved XPS (ARXPS) analysis offers the opportunity of employing the combined information contained in the data at the various angles to reduce the sensitivity to noise. The assumption of shared peak parameters (center and width) among the spectra for the different angles, and how it is introduced into the analysis, plays a basic role. Sequential fitting is the usual practice in ARXPS data peak-fitting. It consist on first estimating the center and width of the peaks from the data acquired at one of the angles, and then using those parameters as a starting approximation for fitting the data for each of the rest of the angles. An improvement of this method consists of averaging the centers and widths of the peaks obtained at the different angles, and then employing these values to assess the areas of the peaks for each angle. Another strategy for using the combined information is by assessing the peak parameters from the sum of the experimental data. The complete use of the combined information contained in the data-set is optimized by the simultaneous fitting method. It consists of the assessment of the center and width of the peaks by fitting the data at all the angles simultaneously. Computer-generated data was employed to compare the sensitivity with respect\n\nAddressing Phase Errors in Fat-Water Imaging Using a Mixed Magnitude/Complex Fitting Method\n\nScience.gov (United States)\n\nHernando, D.; Hines, C. D. G.; Yu, H.; Reeder, S.B.\n\n2012-01-01\n\nAccurate, noninvasive measurements of liver fat content are needed for the early diagnosis and quantitative staging of nonalcoholic fatty liver disease. Chemical shift-based fat quantification methods acquire images at multiple echo times using a multiecho spoiled gradient echo sequence, and provide fat fraction measurements through postprocessing. However, phase errors, such as those caused by eddy currents, can adversely affect fat quantification. These phase errors are typically most significant at the first echo of the echo train, and introduce bias in complex-based fat quantification techniques. These errors can be overcome using a magnitude-based technique (where the phase of all echoes is discarded), but at the cost of significantly degraded signal-to-noise ratio, particularly for certain choices of echo time combinations. In this work, we develop a reconstruction method that overcomes these phase errors without the signal-to-noise ratio penalty incurred by magnitude fitting. This method discards the phase of the first echo (which is often corrupted) while maintaining the phase of the remaining echoes (where phase is unaltered). We test the proposed method on 104 patient liver datasets (from 52 patients, each scanned twice), where the fat fraction measurements are compared to coregistered spectroscopy measurements. We demonstrate that mixed fitting is able to provide accurate fat fraction measurements with high signal-to-noise ratio and low bias over a wide choice of echo combinations. PMID:21713978\n\nMultimodal determination of Rayleigh dispersion and attenuation curves using the circle fit method\n\nScience.gov (United States)\n\nVerachtert, R.; Lombaert, G.; Degrande, G.\n\n2018-03-01\n\nThis paper introduces the circle fit method for the determination of multi-modal Rayleigh dispersion and attenuation curves as part of a Multichannel Analysis of Surface Waves (MASW) experiment. The wave field is transformed to the frequency-wavenumber (fk) domain using a discretized Hankel transform. In a Nyquist plot of the fk-spectrum, displaying the imaginary part against the real part, the Rayleigh wave modes correspond to circles. The experimental Rayleigh dispersion and attenuation curves are derived from the angular sweep of the central angle of these circles. The method can also be applied to the analytical fk-spectrum of the Green's function of a layered half-space in order to compute dispersion and attenuation curves, as an alternative to solving an eigenvalue problem. A MASW experiment is subsequently simulated for a site with a regular velocity profile and a site with a soft layer trapped between two stiffer layers. The performance of the circle fit method to determine the dispersion and attenuation curves is compared with the peak picking method and the half-power bandwidth method. The circle fit method is found to be the most accurate and robust method for the determination of the dispersion curves. When determining attenuation curves, the circle fit method and half-power bandwidth method are accurate if the mode exhibits a sharp peak in the fk-spectrum. Furthermore, simulated and theoretical attenuation curves determined with the circle fit method agree very well. A similar correspondence is not obtained when using the half-power bandwidth method. Finally, the circle fit method is applied to measurement data obtained for a MASW experiment at a site in Heverlee, Belgium. In order to validate the soil profile obtained from the inversion procedure, force-velocity transfer functions were computed and found in good correspondence with the experimental transfer functions, especially in the frequency range between 5 and 80 Hz.\n\nA Family of Trigonometrically-fitted Partitioned Runge-Kutta Symplectic Methods\n\nInternational Nuclear Information System (INIS)\n\nMonovasilis, Th.; Kalogiratou, Z.; Simos, T. E.\n\n2007-01-01\n\nWe are presenting a family of trigonometrically fitted partitioned Runge-Kutta symplectic methods of fourth order with six stages. The solution of the one dimensional time independent Schroedinger equation is considered by trigonometrically fitted symplectic integrators. The Schroedinger equation is first transformed into a Hamiltonian canonical equation. Numerical results are obtained for the one-dimensional harmonic oscillator and the exponential potential\n\nAn Electronic Method for Measuring the Fit of Removable Partial Denture Frameworks to Dental Casts\n\nDirectory of Open Access Journals (Sweden)\n\nRobert J Williams\n\n2009-06-01\n\nFull Text Available It is well established that the Removable Partial Denture (RPD is an effective treatment prosthesis. The objectives of a successful RPD are: to preserve the health of remaining oral structure, restore function and restore esthetics. To achieve these objectives, an RPD framework must fit accurately to the supporting structures. This paper presents a method for measuring the gaps or spaces present between the RPD framework and supporting structures which will enable the dentist and the dental technician to evaluate the accuracy of fitting of the prosthesis before it is delivered to the patient. The method used in this research is based on the principle of electric capacitance and uses a specially designed prototype measurement system.\n\nMethod of fitting a cage structure\n\nInternational Nuclear Information System (INIS)\n\nTakeuchi, Mamoru; Iwasaki, Tsutomu; Ishida, Akira; Yokota, Hirakazu.\n\n1971-01-01\n\nHerein disclosed is a method of fitting together cage structures, each made of a different material. The cage structure may be an ultrahigh speed rotary drum for a centrifuge. An inner cylinder of, for example, Al alloy, to be inserted in an outer cylinder made of a material such as carbon fiber reinforced plastic is filament-wound with a resin-impregnated carbon fiber under application of an axial tensile force to the inner cylinder so as to contract the radius thereof, and then after-cured to cool down to room temperature. The tensile force is then released to permit the radially contracted inner cylinder to elastically recover its original form and to thereby eliminate a gap formed between both cylinders due to aftercure, providing that the width of the gap is equal to that of the radial contraction, determined by Poisson's ratio, of the Al alloy material. Thus, the inner cylinder can be firmly fitted within the outer cylinder in accordance with the elastic deformation of the material. (Ohno, Y.)\n\nA comparative analysis on computational methods for fitting an ERGM to biological network data\n\nDirectory of Open Access Journals (Sweden)\n\nSudipta Saha\n\n2015-03-01\n\nFull Text Available Exponential random graph models (ERGM based on graph theory are useful in studying global biological network structure using its local properties. However, computational methods for fitting such models are sensitive to the type, structure and the number of the local features of a network under study. In this paper, we compared computational methods for fitting an ERGM with local features of different types and structures. Two commonly used methods, such as the Markov Chain Monte Carlo Maximum Likelihood Estimation and the Maximum Pseudo Likelihood Estimation are considered for estimating the coefficients of network attributes. We compared the estimates of observed network to our random simulated network using both methods under ERGM. The motivation was to ascertain the extent to which an observed network would deviate from a randomly simulated network if the physical numbers of attributes were approximately same. Cut-off points of some common attributes of interest for different order of nodes were determined through simulations. We implemented our method to a known regulatory network database of Escherichia coli (E. coli.\n\nShort-arc measurement and fitting based on the bidirectional prediction of observed data\n\nScience.gov (United States)\n\nFei, Zhigen; Xu, Xiaojie; Georgiadis, Anthimos\n\n2016-02-01\n\nTo measure a short arc is a notoriously difficult problem. In this study, the bidirectional prediction method based on the Radial Basis Function Neural Network (RBFNN) to the observed data distributed along a short arc is proposed to increase the corresponding arc length, and thus improve its fitting accuracy. Firstly, the rationality of regarding observed data as a time series is discussed in accordance with the definition of a time series. Secondly, the RBFNN is constructed to predict the observed data where the interpolation method is used for enlarging the size of training examples in order to improve the learning accuracy of the RBFNNâs parameters. Finally, in the numerical simulation section, we focus on simulating how the size of the training sample and noise level influence the learning error and prediction error of the built RBFNN. Typically, the observed data coming from a 5{}^\\\\circ short arc are used to evaluate the performance of the Hyper method known as the âunbiased fitting method of circleâ with a different noise level before and after prediction. A number of simulation experiments reveal that the fitting stability and accuracy of the Hyper method after prediction are far superior to the ones before prediction.\n\nAn Improved Iterative Fitting Method to Estimate Nocturnal Residual Layer Height\n\nDirectory of Open Access Journals (Sweden)\n\nWei Wang\n\n2016-08-01\n\nFull Text Available The planetary boundary layer (PBL is an atmospheric region near the Earthâs surface. It is significant for weather forecasting and for the study of air quality and climate. In this study, the top of nocturnal residual layersâwhich are what remain of the daytime mixing layerâare estimated by an elastic backscatter Lidar in Wuhan (30.5Â°N, 114.4Â°E, a city in Central China. The ideal profile fitting method is widely applied to determine the nocturnal residual layer height (RLH from Lidar data. However, the method is seriously affected by an optical thick layer. Thus, we propose an improved iterative fitting method to eliminate the optical thick layer effect on RLH detection using Lidar. Two typical case studies observed by elastic Lidar are presented to demonstrate the theory and advantage of the proposed method. Results of case analysis indicate that the improved method is more practical and precise than profile-fitting, gradient, and wavelet covariance transform method in terms of nocturnal RLH evaluation under low cloud conditions. Long-term observations of RLH performed with ideal profile fitting and improved methods were carried out in Wuhan from 28 May 2011 to 17 June 2016. Comparisons of Lidar-derived RLHs with the two types of methods verify that the improved solution is practical. Statistical analysis of a six-year Lidar signal was conducted to reveal the monthly average values of nocturnal RLH in Wuhan. A clear RLH monthly cycle with a maximum mean height of about 1.8 km above ground level was observed in August, and a minimum height of about 0.7 km was observed in January. The variation in monthly mean RLH displays an obvious quarterly dependence, which coincides with the annual variation in local surface temperature.\n\nESTIMATE OF STAND DENSITY INDEX FOR EUCALYPTUS UROPHYLLA USING DIFFERENT FIT METHODS\n\nDirectory of Open Access Journals (Sweden)\n\nErnani Lopes Possato\n\nFull Text Available ABSTRACT The Reineke stand density index (SDI was created on 1933 and remains as target of researches due to its importance on helping decision making regarding the management of population density. Part of such works is focused on the manner by which plots were selected and methods for the fit of Reineke model parameters in order to improve the definition of SDI value for the genetic material evaluated. The present study aimed to estimate the SDI value for Eucalyptus urophylla using the Reineke model fitted by the method of linear regression (LR and stochastic frontier analysis (SFA. The database containing pairs of data number of stems per hectare (N and mean quadratic diameter (Dq was selected in three intensities, containing the 8, 30 and 43 plots of greatest density, and models were fitted by LR and SFA on each selected intensities. The intensity of data selection altered slightly the estimates of parameters and SDI when comparing the fits of each method. On the other hand, the adjust method influenced the mean estimated values of slope and SDI, which corresponded to -1.863 and 740 for LR and -1.582 and 810 for SFA.\n\nFitting methods for baryon acoustic oscillations in the Lyman-Î± forest fluctuations in BOSS data release 9\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nKirkby, David; Margala, Daniel; Blomqvist, Michael [Department of Physics and Astronomy, University of California, Irvine, 92697 (United States); Slosar, AnÅ¾e [Brookhaven National Laboratory, Blgd 510, Upton NY 11375 (United States); Bailey, Stephen; Carithers, Bill [Lawrence Berkeley National Laboratory, 1 Cyclotron Road, Berkeley, CA 94720 (United States); Busca, NicolÃ¡s G.; Bautista, Julian E. [APC, UniversitÃ© Paris Diderot-Paris 7, CNRS/IN2P3, CEA, Observatoire de Paris, 10, rue A. Domon and L. Duquet, Paris (France); Delubac, TimothÃ©e; Rich, James; Palanque-Delabrouille, Nathalie [CEA, Centre de Saclay, IRFU, F-91191 Gif-sur-Yvette (France); Brownstein, Joel R.; Dawson, Kyle S. [Department of Physics and Astronomy, University of Utah, 115 S 1400 E, Salt Lake City, UT 84112 (United States); Croft, Rupert A.C. [Bruce and Astrid McWilliams Center for Cosmology, Carnegie Mellon University, Pittsburgh, PA 15213 (United States); Font-Ribera, Andreu [Institute of Theoretical Physics, University of Zurich, 8057 Zurich (Switzerland); Miralda-EscudÃ©, Jordi [InstituciÃ³ Catalana de Recerca i Estudis AvanÃ§ats, Barcelona, Catalonia (Spain); Myers, Adam D. [Department of Physics and Astronomy, University of Wyoming, Laramie, WY 82071 (United States); Nichol, Robert C. [Institute of Cosmology and Gravitation, Dennis Sciama Building, University of Portsmouth, Portsmouth, PO1 3FX (United Kingdom); PÃ¢ris, Isabelle; Petitjean, Patrick, E-mail: dkirkby@uci.edu [UniversitÃ© Paris 6 et CNRS, Institut d' Astrophysique de Paris, 98bis blvd. Arago, 75014 Paris (France); and others\n\n2013-03-01\n\nWe describe fitting methods developed to analyze fluctuations in the Lyman-Î± forest and measure the parameters of baryon acoustic oscillations (BAO). We apply our methods to BOSS Data Release 9. Our method is based on models of the three-dimensional correlation function in physical coordinate space, and includes the effects of redshift-space distortions, anisotropic non-linear broadening, and broadband distortions. We allow for independent scale factors along and perpendicular to the line of sight to minimize the dependence on our assumed fiducial cosmology and to obtain separate measurements of the BAO angular and relative velocity scales. Our fitting software and the input files needed to reproduce our main BOSS Data Release 9 results are publicly available.\n\nRecognition of Banknote Fitness Based on a Fuzzy System Using Visible Light Reflection and Near-infrared Light Transmission Images.\n\nScience.gov (United States)\n\nKwon, Seung Yong; Pham, Tuyen Danh; Park, Kang Ryoung; Jeong, Dae Sik; Yoon, Sungsoo\n\n2016-06-11\n\nFitness classification is a technique to assess the quality of banknotes in order to determine whether they are usable. Banknote classification techniques are useful in preventing problems that arise from the circulation of substandard banknotes (such as recognition failures, or bill jams in automated teller machines (ATMs) or bank counting machines). By and large, fitness classification continues to be carried out by humans, and this can cause the problem of varying fitness classifications for the same bill by different evaluators, and requires a lot of time. To address these problems, this study proposes a fuzzy system-based method that can reduce the processing time needed for fitness classification, and can determine the fitness of banknotes through an objective, systematic method rather than subjective judgment. Our algorithm was an implementation to actual banknote counting machine. Based on the results of tests on 3856 banknotes in United States currency (USD), 3956 in Korean currency (KRW), and 2300 banknotes in Indian currency (INR) using visible light reflection (VR) and near-infrared light transmission (NIRT) imaging, the proposed method was found to yield higher accuracy than prevalent banknote fitness classification methods. Moreover, it was confirmed that the proposed algorithm can operate in real time, not only in a normal PC environment, but also in an embedded system environment of a banknote counting machine.\n\nRecognition of Banknote Fitness Based on a Fuzzy System Using Visible Light Reflection and Near-infrared Light Transmission Images\n\nDirectory of Open Access Journals (Sweden)\n\nSeung Yong Kwon\n\n2016-06-01\n\nFull Text Available Fitness classification is a technique to assess the quality of banknotes in order to determine whether they are usable. Banknote classification techniques are useful in preventing problems that arise from the circulation of substandard banknotes (such as recognition failures, or bill jams in automated teller machines (ATMs or bank counting machines. By and large, fitness classification continues to be carried out by humans, and this can cause the problem of varying fitness classifications for the same bill by different evaluators, and requires a lot of time. To address these problems, this study proposes a fuzzy system-based method that can reduce the processing time needed for fitness classification, and can determine the fitness of banknotes through an objective, systematic method rather than subjective judgment. Our algorithm was an implementation to actual banknote counting machine. Based on the results of tests on 3856 banknotes in United States currency (USD, 3956 in Korean currency (KRW, and 2300 banknotes in Indian currency (INR using visible light reflection (VR and near-infrared light transmission (NIRT imaging, the proposed method was found to yield higher accuracy than prevalent banknote fitness classification methods. Moreover, it was confirmed that the proposed algorithm can operate in real time, not only in a normal PC environment, but also in an embedded system environment of a banknote counting machine.\n\nTarget 3-D reconstruction of streak tube imaging lidar based on Gaussian fitting\n\nScience.gov (United States)\n\nYuan, Qingyu; Niu, Lihong; Hu, Cuichun; Wu, Lei; Yang, Hongru; Yu, Bing\n\n2018-02-01\n\nStreak images obtained by the streak tube imaging lidar (STIL) contain the distance-azimuth-intensity information of a scanned target, and a 3-D reconstruction of the target can be carried out through extracting the characteristic data of multiple streak images. Significant errors will be caused in the reconstruction result by the peak detection method due to noise and other factors. So as to get a more precise 3-D reconstruction, a peak detection method based on Gaussian fitting of trust region is proposed in this work. Gaussian modeling is performed on the returned wave of single time channel of each frame, then the modeling result which can effectively reduce the noise interference and possesses a unique peak could be taken as the new returned waveform, lastly extracting its feature data through peak detection. The experimental data of aerial target is for verifying this method. This work shows that the peak detection method based on Gaussian fitting reduces the extraction error of the feature data to less than 10%; utilizing this method to extract the feature data and reconstruct the target make it possible to realize the spatial resolution with a minimum 30 cm in the depth direction, and improve the 3-D imaging accuracy of the STIL concurrently.\n\nIntroducing the fit-criteria assessment plot - A visualisation tool to assist class enumeration in group-based trajectory modelling.\n\nScience.gov (United States)\n\nKlijn, Sven L; Weijenberg, Matty P; Lemmens, Paul; van den Brandt, Piet A; Lima Passos, ValÃ©ria\n\n2017-10-01\n\nBackground and objective Group-based trajectory modelling is a model-based clustering technique applied for the identification of latent patterns of temporal changes. Despite its manifold applications in clinical and health sciences, potential problems of the model selection procedure are often overlooked. The choice of the number of latent trajectories (class-enumeration), for instance, is to a large degre"
    }
}