{
    "id": "dbpedia_7752_0",
    "rank": 73,
    "data": {
        "url": "https://www.niskanencenter.org/faster_fairer/reviving_innovation_and_dynamism.html",
        "read_more_link": "",
        "language": "en",
        "title": "Faster Growth, Fairer Growth: Reviving Innovation and Dynamism",
        "top_image": "https://www.niskanencenter.org/faster_fairer/images/Part_iv_card.png",
        "meta_img": "https://www.niskanencenter.org/faster_fairer/images/Part_iv_card.png",
        "images": [
            "https://www.niskanencenter.org/faster_fairer/images/niskanen logo (transparent).png",
            "https://www.niskanencenter.org/faster_fairer/images/Part iv thumbnail.png",
            "https://www.niskanencenter.org/faster_fairer/images/figures/iv_federalrd.png",
            "https://www.niskanencenter.org/faster_fairer/images/figures/iv_effort.png",
            "https://www.niskanencenter.org/faster_fairer/images/figures/iv_migration.png",
            "https://www.niskanencenter.org/faster_fairer/images/figures/EIS.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2020-10-05T12:56:51-04:00",
        "summary": "",
        "meta_description": "Policies for a High Road, High Performance Economy",
        "meta_lang": "en",
        "meta_favicon": "https://www.niskanencenter.org/wp-content/uploads/2019/08/Niskanen_favicon-1.png",
        "meta_site_name": "Niskanen Center",
        "canonical_link": "https://www.niskanencenter.org/faster_fairer/reviving_innovation_and_dynamism.html",
        "text": "By Brink Lindsey & Samuel Hammond\n\nA ny serious effort to upgrade American capitalismâs capacity for innovation and dynamism must begin with the recognition that powerful forces are pushing the other way. As we discussed earlier in the paper, declining population growth, relatively high levels of labor force participation and educational attainment, and a century-plus of harvesting the lowest-hanging fruit of organized, systematic research and development mean that various opportunities for continued increases in output per capita are narrowing or closing altogether. Advances on the horizon may soon change that, from machine learning to genetic engineering. But for now, the unpleasant but undeniable fact is that economic growth is getting harder, and therefore the path of least resistance is toward a steady sapping of Americaâs wealth-creating vigor. Policymakers will need to up their game to resist, much less overcome, the headwinds that now confront us.\n\nRising to the challenge will require a decided shift in attitudes, as politicians typically care much more about dividing the economic pie than growing it. This is obvious with progressives, as their emphasis on protecting the less well-off is premised on the idea that the immense productive power of American capitalism is up to the task: What is missing are the redistribution and regulations needed to channel that power in more egalitarian ways. Conservatives, by contrast, talk much more about growth and the \"supply side,\" but the policy prescriptions most associated with this rhetoric make clear that their concerns are predominantly distributional as well â in the other direction. Their favorite nostrums for boosting growth, notwithstanding how poorly designed they are to accomplish their aim, are invariably cuts in top tax rates and reductions in health, safety, and environmental regulations â in other words, remedies that will directly improve the individual and corporate bottom lines of the well-to-do constituencies of the right but do little to spur fundamental innovation.\n\nOnce we face squarely the challenge of slowing growth, there are two broad paths that policy responses can take. First, we can take steps to achieve a more efficient allocation of resources, thereby producing a one-time increase in the level of output â a movement along the technological frontier and thus a temporary increase in the rate of growth. Second, we can take steps to extend the technological frontier itself, thereby raising the rate of growth indefinitely â i.e., on an ongoing basis. Here, there are only two practicable options: increase the rate of innovation, or the development of useful new ideas; and increase the rate of technology diffusion, or the reallocation of resources that results from the adoption of useful new ideas.\n\nAlthough there is a clear analytical distinction between changes in the level of output and changes in the rate of output growth, in practice measures that accomplish the former will frequently be helpful in achieving the latter as well. This is true because the kinds of policies that result in significant misallocations of resources â whose reform will lead to a more efficient allocation â also tend to distort the incentives to innovate and adopt new ways of doing things. In other words, moving along the technological frontier will make it easier to also push that frontier outward.\n\nThus, in the previous section on liberating the captured economy, we advocated policy reforms to eliminate rents created by the regulation of finance, intellectual property, health care, and housing, thereby correcting massive misallocations of resources. These reforms would lead the U.S. economy to a higher level of output by eliminating grossly wasteful spending and redirecting it to higher, better uses; in addition, reducing the artificial scarcity of housing in the nationâs most productive cities would raise the level of output by enabling workers to move to the parts of the country with the best opportunities. Consequently, these reforms would boost the economyâs growth rate during the transition to a new, higher output level.\n\nAt the same time, our proposals to reverse regulatory capture would also work to improve the incentives to innovate and diffuse new technologies, thus holding out the promise of an accelerating growth rate. Our excessively large financial sector, for example, draws in significant amounts of human capital, up to and including many would-be theoretical physicists, only to employ that quantitative genius toward winning zero-sum games involving the exploitation of small discrepancies in asset prices. Accordingly, shrinking the sector will not only produce a one-time improvement in resource allocation; it stands to boost the rate of productivity growth rate itself, shifting talent into sectors that push out, rather than merely move along, the technological frontier. Similarly, restoring patent and copyright protections to something like their traditional confines will reduce rents for law firms and patent trolls, but also speed the diffusion of innovation by narrowing monopoly privileges and accelerating their expiration, while preserving incentives for those who need the temporary protection they afford. Increasing competition in the health sector should likewise sharpen incentives to innovate, especially in how medicine is organized. And lastly, scaling back barriers to building new housing will facilitate a more efficient allocation of labor around the country â but also increase the rate of productivity growth thanks to the increasing returns of urban agglomeration.\n\nAccordingly, our proposals to fight back against regulatory capture constitute, on their own, an ambitious pro-growth agenda. In this section, we round out that agenda with a further package of reforms aimed at improving prospects for growth through a mix of output-level and growth-rate changes. A vigorous response to the problem of climate change, with a carbon tax as its centerpiece, is a necessary element of any larger strategy to encourage innovation, as decarbonization is one of the most important innovation challenges now facing the United States and the world. Robust levels of immigration directly boost output by increasing labor inputs; in addition, immigrants are a vital contributor to new firm formation, especially in high tech sectors, and immigration encourages innovation more generally by supporting population growth. Reversing the decades-long slide in public R&D spending, coupled with changes in how public dollars are awarded, can help to revitalize Americaâs innovation system. Economic development policies to diversify Americaâs productive capacity, foster excellence in engineering and manufacturing, and encourage greater regional balance in economic output can simultaneously boost dynamism while reducing skill- and geography-based economic polarization. In conjunction with liberalizing new housing construction, reducing other barriers to geographic mobility can facilitate the reallocation of labor to the places that can best make use of it. And streamlining the environmental review process can not only clear the way for productivity-enhancing investments in infrastructure, but also facilitate all innovation and diffusion that requires moving atoms around on a large scale.\n\nThe reform proposals discussed in this section round out our agenda for creating a high road, high performance American economy for the 21st century. We understand that this agenda diverges in important ways from the predominant thinking in both the Republican and Democratic parties. We realize further that, even were this agenda to be endorsed fully by powerful political actors on this side or that, or some combination of actors on both sides, it is a highly ambitious program of deep and extensive structural change that would tax the capabilities of any political system, let alone one as plagued by polarization and dysfunction as our own. In particular, many elements of this agenda would encounter ferocious opposition from powerful and well-organized interest groups with a stake in maintaining the status quo or moving in a different direction.\n\nWe are therefore fully cognizant of the tremendous obstacles that stand between the articulation of this policy vision and its implementation. Nevertheless, we believe that simply articulating a new way forward, one that attempts to blend the best ideas from the left and the right into a new synthesis, is itself an important step. As the saying goes, the best time to plant a tree was 20 years ago, but the second-best time is now.\n\nPursue Decarbonization for Long-Term Prosperity and Well-being\n\nIn formulating proposals to stimulate innovation and dynamism, we must never lose sight of the fact that economic growth is not an end in itself. We seek rising levels of specialization and exchange, conventionally measured in terms of real GDP per capita, because increases in economic output generally track with an upward trajectory for living standards and well-being.\n\nSuch tracking, though, cannot be assumed in cases when economic activity generates negative externalities. When some industryâs output causes harmful side-effects whose costs fall on others, that industryâs expansion may be good for the GDP statistics that year but bad for society overall (and, indeed, bad for GDP in the long run). Accordingly, rules that limit and discourage incidental harms caused by economic activity are vital to proper market functioning. Regulations to reduce air and water pollution, ban unsafe products, and the like are not in any way \"anti-market\"; on the contrary, they are an essential part of the Invisible Hand, helping to ensure ongoing correspondence between private profit-seeking and the public good.\n\nOne ubiquitous side-effect of modern economic activity now threatens harms on a planetary scale: climate change caused by human-produced emissions of carbon and other greenhouse gases. To date, greenhouse gas emissions have increased atmospheric CO2 levels by about 45 percent and global temperatures have increased about 1 degree Celsius since the middle of the 19th century. Such warming is projected to continue until greenhouse gas emissions can be brought to zero and will carry with it significant changes to the climate of nearly every region of the planet, along with intensified weather extremes and sea level rise. Those changes will disturb natural and human systems and pose significant risks in the coming decades and centuries.\n\nClimate change is a massive risk management problem, with a range of possible outcomes from decisions about how much greenhouse gases should be emitted. Despite the solid consensus about the human effect on the climate and the dangers it poses, there is a great deal of uncertainty about future levels of warming, the effect of warming on regional climates, and the effects on economic activity. The remaining physical uncertainty in climate projections â a doubling of preindustrial CO2 can be expected to raise average temperatures somewhere between 1.5 and 4.5 degrees Celsius â leaves room for the effects of climate change to range from manageably bad to catastrophic. As to the resulting economic damage, best estimates predict that such warming will reduce global income by up to 5 percent, but uncertainty permits much larger losses. [1] For instance, if the effects of climate change reduce the rate of economic growth or cause economic shocks [2] , the losses could be much larger than expected. And as we have just learned the hard way with the coronavirus outbreak, failing to manage long-term risks because they seem distant and abstract is a recipe for disaster.\n\nUnder the circumstances, there is only one responsible course of action: Move as quickly as politically practicable to cut carbon emissions and transition to clean energy sources. [3] Today the generally accepted goal for global climate policy is to keep likely warming below 2 degrees Celsius, which would require emissions to reach zero in the second part of the 21st century. Meeting that goal does not guarantee that catastrophic consequences, either localized or systemic, will be avoided altogether, but the risks will be less. Given that there is a rock-solid relationship between reducing the risks of climate change and reducing total emissions, rapid decarbonization is warranted even if specific temperature goals are practically impossible to achieve. [4]\n\nAnd the most efficient, least costly way to pursue this goal is by putting a price on carbon via a tax on carbon emissions. Rather than micromanaging the energy transition through command-and-control regulations, it is far better to allow market actors to decide for themselves how, when, and where cutting emissions makes the most economic sense. A carbon tax gives them the incentive to do precisely that. A carbon tax also raises government revenue, which can be used to reduce the burdens of the new tax on lower-income people, to reduce other taxes, or to support research and development of clean technology.\n\nHow high should the tax be? Although the theoretical challenges involved in estimating an optimal tax rate are daunting, as a practical matter the correct path is straightforward: Make the rate as high as politically possible and set the rate to increase above inflation. Furthermore, some kind of border tax adjustment is needed to level the playing field between domestic and foreign producers and avoid creating incentives for companies to shift production to carbon tax shelters. Where the new tax creates duplicative efforts with existing regulatory authority in the United States, then it is reasonable to supersede those regulations or to pause the implementation of new regulations while emissions fall due to the carbon tax.\n\nCarbon pricing is the centerpiece of any well-designed policy response to climate change because of its unparalleled ability to align incentives properly for economic actors across the board, encouraging both energy producers to innovate and energy consumers to conserve. But since these incentives are most potent, and least disruptive, to the extent that economically viable clean-energy alternatives to fossil fuels are available, taxing carbon alone is not enough. In addition, a direct assault on the technical and policy problems that limit the availability of cost-competitive clean-energy sources is necessary.\n\nTo that end, we advocate a major increase in federal support for clean energy R&D. In a later section we will detail our broader proposals to revive public R&D more generally after a decades-long slump. While mission-oriented R&D initiatives and programs to promote diffusion and adoption can help to accelerate progress and productivity across a range of emerging technologies â including artificial intelligence, quantum computing, nanotechnology, biotechnology, new materials, 3D printing, and automated vehicles â nowhere is the need greater than in the energy field. Renewable energy, nuclear power, batteries, low-carbon fuels, clean manufacturing, clean aviation, clean agriculture, carbon capture, and geoengineering â further work is urgently needed on all these fronts, through a combination of grants, prizes, dedicated research centers, extension services, and ARPA-style initiatives.\n\nAccelerating the development and availability of cheaper clean energy will require policy measures that go beyond what is typically regarded as R&D. After all, the goal here is not technical viability as demonstrated in a laboratory and measured in terms of performance benchmarks, but rather economic viability as demonstrated in the field and measured in accounting data. And the path from technical to economic viability is traversed through the steady, gradual accumulation of countless incremental improvements in the production process â in other words, through learning by doing. Fortunately, we know that this path exists: The phenomenon of the learning curve, in which production costs fall at a predictable rate as cumulative production totals rise, has been documented in industry after industry and is one of the most well-established regularities found in the study of business. And indeed, we are presently witnessing heartening progress along the learning curve for clean energy technologies: The cost of electricity from solar power drops 25-30 percent with every doubling of production, the cost of wind power drops 15-20 percent, and battery costs drop 20-30 percent. [5] To reach our clean-energy future before the harms caused and threatened by climate change grow too severe, we need to speed up these moves down the learning curve.\n\nAll of this puts renewables mandates, clean energy standards, and subsidies for clean energy deployment in a very different light. Ignoring the effect of the learning curve, these policies look like classic command-and-control regulation of the type that supporters of markets can usually be expected to roundly condemn. But given the existence of learning-curve effects, and their proven relevance to cost structures for clean energy, policies that accelerate cumulative production totals are better seen as a nontraditional form of R&D support: It is the development of new technologies to the point of cost-competitiveness that these policies support, and they do it better and faster than any known alternative. Accordingly, we endorse well-designed mandates and subsidies that accelerate the deployment of clean technologies as an important additional component of sound climate policy. Furthermore, public financing of supporting infrastructure for clean energy deployment â for example, electric vehicle chargers and CO2 pipelines â can also help to accelerate the rollout of new technology and associated learning-curve effects.\n\nFuel Growth with Expanded Immigration\n\nOf all the possible ways to spur faster growth, none is more obvious and straightforward than expanding immigration. Since economic output is a function of two main inputs, labor and capital, increasing those inputs is the easiest path to higher output. (Increasing output per unit of input, otherwise known as productivity, is a considerably trickier challenge â one that absorbs much of our attention throughout this paper.) And since large numbers of people around the world are eager and willing to move to the United States, increasing the size of the American labor force requires only that we stop turning so many of them away.\n\nExpanding immigration can help to compensate for demographic trends that are highly unfavorable for growth. Declining birthrates since the end of the Baby Boom have paced a decades-long decline in population growth: The rate of increase in 2019 was the slowest for the United States in a century, since World War I and the global influenza pandemic combined to cause the population to actually dip slightly in 1918. [6] Falling fertility, together with a plateauing of womenâs entry into paid work, have produced a corresponding decline in labor force growth: Averaging 1.6 percent a year between 1950 and 2000, annual labor force growth then dipped to 1.1 percent in the first decade of the 21st century before plunging to 0.5 percent since then, with further growth projected to continue at the current low rate. [7]\n\nThe slowdown in population and labor force growth exerts strong downward pressure on American GDP growth. Absent an unexpected productivity-growth miracle, this slide will keep going and the size of the overall U.S. economy relative to that of faster-growing countries (most notably, China) will continue to shrink. This relative decline has important implications for national security, as American primacy in military strength and \"soft power\" have been anchored in economic primacy. Robust immigration is the best bet for slowing or arresting this decline.\n\nWhile immigration surely can boost aggregate U.S. output, what about the per capita output on which living standards depend? Adding more people to the economy increases both the numerator (GDP) and the denominator (population), so the effect on the ratio between the two is not obvious.\n\nIt is clear enough, though, that at least high-skill immigration raises productivity and thus output per capita. Most obviously, immigrants with higher education attainment and earnings potential than native-born workers raise the skill level, and thus the productivity, of the overall workforce. Already, immigrants are more likely to have graduate degrees than native-born Americans (at the same time, though, immigrants are overrepresented at the low end of the skill spectrum as well); shifts in the composition of immigration toward higher skills could amplify this boost to Americaâs human capital endowment.\n\nIn addition, for decades now, studies have been documenting the disproportionate role of immigrants in founding Americaâs biggest and most innovative companies. According to a 2018 survey, 55 percent of U.S. startups valued at over a billion dollars have at least one immigrant founder. [8] The rise of Silicon Valley, and the dominant U.S. role in leading the information technology and Internet revolutions, are simply unimaginable without the myriad contributions made by people born all over the world â and the relative U.S. openness that made those contributions possible. Alas, we have no idea what world-changing companies we missed out on because their would-be founders were not allowed to come here, or were forced to leave after graduate school.\n\nWhile the role of high-skill immigrants in spurring American innovation is inarguable, the connection between immigration and innovation is unlikely to stop there. According to important new research, there are good reasons to believe that boosting aggregate immigration across all skill levels is also a boon for productivity growth. Namely, it is becomingly increasingly clear that the slowdown in population (and labor force) growth, and with it the aging of the population, are very bad for innovation and productivity. A 2016 study found that a 10 percent increase in the share of the population 60 years or older reduces growth in GDP per capita by 5.5 percent; a 2018 study followed up to estimate that between a quarter- and a full percentage point of the recent decline in productivity growth is attributable to aging. [9] Meanwhile, another 2018 study found that a drop in population growth leads to a fall in the rate of new firm formation, a critical component of the creative destruction that drives innovation. [10]\n\nThese studies suggest that growth per capita, not just aggregate growth, hinges on the overall populationâs age structure and rate of increase. It follows that expanding immigration, regardless of skill level, can promote dynamism and innovation by pushing back against demographic headwinds affecting the native-born population.\n\nUnfortunately, we are not taking advantage of our countryâs attractiveness to would-be migrants. As a result of the Trump administrationâs travel bans, clampdown on granting asylum to refugees, and general hostility to immigration, net international migration to the United States fell to 595,000 in 2019 â down sharply from 1,047,000 in 2016 in the final year of the Obama administration. This is a move in the wrong direction: In our view, the recent historical norm of 1 million green cards granted annually should be seen as a floor to build on, not a ceiling we struggle to reach.\n\nThe Niskanen Center has been a leading voice for sound, well-designed, and politically sustainable immigration policy across a wide range of different issues. We understand that immigration policy implicates many concerns beyond productivity and economic growth, and that good policy must balance those competing concerns as well as reconcile sharply clashing perspectives within the electorate. [11] For present purposes, though, we want to identify a few broad principles of immigration reform that would align policy with the needs of a high road, high performance economy.\n\nSpecifically, we believe that a reform package with the following three basic components could provide the basis for a workable new consensus: 1) a healthy increase in annual legal immigration; 2) a shift in the composition of legal immigration to reflect a greater emphasis on potential economic contributions; and 3) a well-functioning system of visa tracking (to identify and locate overstayers) and workplace enforcement based on national identification cards. Of course, the devil is in the details, and there are a great number of details to work through. But reforms that incorporate these basic elements can preserve Americaâs heritage as a haven for immigrants and leverage that heritage to improve long-term growth prospects, while at the same time addressing legitimate concerns about the actual and perceived shortcomings of current policy.\n\nDouble Down on Science and R&D\n\nScience built the modern world. From the light bulb to the microchip, the wealth of our civilization owes itself to the curiosity of our species, and thus the drive of countless tinkerers and experimentalists who merely sought a better understanding of how the world works. Science will also be what ultimately resolves the COVID-19 crisis. As the pandemic wreaks havoc on our lives and the economy, researchers are working at a breakneck pace to understand the virus from top to bottom, and to apply those insights in the development of vaccines and treatments.\n\nThe United States plays a central role in these and most other scientific pursuits. As host to the worldâs top research institutions, and through our broad institutional support for entrepreneurship and innovation, our nation is uniquely well positioned to push outward along the scientific frontier and find out if itâs truly endless.\n\nYet while the societal benefits of robust federal investments in science and technology are large and compounding, the fruits from any particular project can take years to materialize. As a result, policymakers often look to cut critical research programs to shore up discretionary spending, trading long-term gains for short-term savings. Our Global Positioning System, for example, began as a DARPA research project within the U.S. Department of Defense. It was primarily conceived of as a weapons support system and no one could have predicted that 50 years hence, a constellation of satellites whirling around Earth would revolutionize navigation and communications the world over. On the contrary: In 1979 the fledgling GPS program faced a massive setback when its budget was cut by $500 million, or roughly 30 percent, forcing multiple satellites to be dropped and new capabilities to be delayed. The programâs budget was zeroed out from 1980 to 1982, and ultimately survived only because of strong internal advocacy from the Office of the Secretary of Defense. [12]\n\nStories like this can be found throughout the recent history of U.S. federal R&D programs. In fact, federal spending on basic research has fallen nearly 35 percent over the last 40 years as a fraction of GDP. [13] Private sector R&D has filled the gap, leaving our economyâs total research effort roughly constant. But while private R&D is important, it tends to be focused on producing proprietary knowledge and techniques with near-term commercial viability. The public sector, by contrast, is unique in its ability to take the long view â to support the foundational investments in science and technology that may be unprofitable now, but which promise to transform our society generations later.\n\nAs federal research funding has become scarce, it has also become increasingly competitive. Funding rates for grant applications have steadily declined since the 1970s, when it was common for every other grant application to secure support. Today, in contrast, approval rates at the National Science Foundation (NSF) and National Institutes for Health (NIH) run as low as 10 to 20 percent.\n\nIn 2014, for example, the NIHâs National Institute of Allergy and Infectious Diseases (NIAID) awarded funding to only 9 percent of submitted research projects. [14] Ten meticulously prepared proposals were thus rejected for every one that was successful, representing an enormous waste of researchersâ time. Fortunately, one of the lucky winners was a project called \"Understanding the Risk of Bat Coronavirus Emergence,\" which produced a series of prescient studies of the origins and dynamics of viruses like COVID-19 at a cost of about $3.7 million over five years. [15] Unfortunately, the project was suddenly terminated in April 2020 for seemingly political reasons, while a new proposal from the same investigator was rejected. [16] What potential insights into this or the next pandemic have been lost to the NIAIDâs cutting room floor, weâll never know.\n\nThe increasingly zero-sum competition for grant funding has had perverse effects on the culture of academia more broadly. The imperative to demonstrate near-term results in peer-reviewed publications rewards those who can make incremental progress within an existing scientific program, at the expense of heterodox or truly novel ideas. Meanwhile, young researchers can pour hundreds of hours into perfecting a grant application, only to be beaten out by established teams at more prestigious institutions. At the NIH, for instance, just 2 percent of NIH-supported institutions receive 53 percent of all research project grants. [17] And as Daniel Bier has noted, \"In 1980, the National Institutes of Health (NIH) funded twice as many researchers under 40 as those over 50. Now, five times as many grants go to those over 50.\" [18] In turn, the typical American scientist no longer gets to direct their own major project until theyâre gray in the hair, despite substantial evidence that scientific creativity peaks quite early in oneâs career. [19]\n\nThe grant-making process itself creates enormous barriers to scientific progress. Principal investigators of federally sponsored research report that they spend over 40 percent of their time on administrative tasks associated with compliance. [20] On the financial reporting side alone, federal grants typically require every expenditure to be tracked and justified in detail, no matter how minor, and impose arbitrary purchasing restrictions on basic supplies. These administrative tasks often fall on the investigators, as the very same rules limit their ability to flexibly hire support personnel. Compliance effort, itâs important to stress, does not necessarily correlate with better compliance outcomes. Past a point of diminishing returns, the effort put into ensuring resources are used effectively can itself become the dominant source of waste in the system.\n\nYet the real bureaucratic nightmare is reserved for studies involving human subjects, which are required by federal law to earn approval from one or more Institutional Review Boards (IRBs). IRBs are independent committees designed to ensure a study protocol meets the highest ethical standards and established in 1974 in response to the appalling Tuskegee Syphilis Study in which Black men with syphilis were misled about their condition to study the untreated progression of the disease â years after penicillin was known to be a cure. Human experimentation of this sort is a moral abomination and has no place in our society. Today, however, IRB supervision, and the voluminous informed consent forms that accompany it, are routinely triggered for studies where the risks to human subjects are trivial or nonexistent, including simple surveys or studies involving archival data. [21] While this often involves a time-consuming risk-benefit analysis, the relative risks and benefits of bureaucratizing the research process â an involuntary human experiment in its own right â is treated as beyond reproach. Indeed, as Carl Schneider persuasively documents in The Censorâs Hand: The Misregulation of Human-Subject Research, the mission creep of the IRB process has systematically undermined Americaâs research capacity, and very likely costs thousands of lives every year through delayed and diverted research in the biomedical setting alone. [22]\n\nIn short, federal spending on basic science and R&D has both declined relative to our economyâs size and become much less efficient per dollar spent. And this retreat has occurred even as â due to the progressive exhaustion of lower-hanging fruit â finding important new ideas is getting ever harder and therefore requires ongoing intensification of research effort. [23]\n\nWeâre living the consequences. Multifactor productivity growth (the type associated with new ideas) has stagnated since the early 1970s, contributing to middle-class wage stagnation. The evidence suggests that a dramatic slowdown in the rate of scientific discovery per dollar spent is at least part of the explanation. \"That evidence demands a large-scale institutional response,\" Patrick Collison and Michael Nielsen write. \"It should be a major subject in public policy, and at grant agencies and universities. Better understanding the cause of this phenomenon is important, and identifying ways to reverse it is one of the greatest opportunities to improve our future.\" [24]\n\nThe alternative is to succumb to what technologist J. Storrs Hall has dubbed the scientific establishmentâs \"failure of nerve\" and \"failure of imagination.\" Failures of nerve occur when the basic ingredients for a technological breakthrough are known but working out the details is discouraged because it has been preemptively declared impossible. Heavier-than-air flying machines, for example, were unanimously dismissed as impossible by the scientific community until the Wright brothers had the nerve to combine existing engineering and physics and prove them wrong. Failures of imagination, meanwhile, are harder to diagnose, but no less consequential. As Hall notes, \"If the fin de siecle pundits had been pooh-poohing transitors and lasers instead of airplanes, we would not fault them to the same degree, because quantum mechanics was not understood â but they would have been wrong just the same.\" [25]\n\nDoubling down on federal support for research and development has the potential to break us out of this stagnation. Yet without deeper reforms to the federal grant-making process, new funding wonât get the appropriate bang for its buck and would risk papering over the institutional sclerosis at the heart of Americaâs waning scientific productivity.\n\nFixing the way we fund science will itself require a scientific approach. Rather than be beholden to any one model, Congress should provide a waiver authority to the heads of NSF and NIH and require they set aside a substantial portion of their annual budget â say, 10 percent â to conduct head-to-head experiments in alternative models of grant-making. Half of the allotment could be constrained to iterations on existing processes, including tweaks to peer review, how submissions are ranked, or the required length of proposals, holding everything else constant. Under the status quo, in contrast, such modest changes often require a drawn-out rulemaking process, making trial-and-error impossible. The remaining 5 percent, meanwhile, could be reserved for genuinely experimental models trialed over a multiyear period.\n\nKevin Gross and Carl Bergstrom, for example, have proposed replacing the existing process with a partial lottery. [26] Proposals would be evaluated as worthy of funding or not, as usual, but with awards allocated randomly to a subset of the highest-ranking proposals. Using the economic theory of contests, they argue this would lower the bar that applicants must clear to have a chance at funding, and thus reduce the time wasted writing and rewriting proposals. In 2013, New Zealand's Health Research Council became the first major science funding agency to use a lottery system, setting aside 2 percent of its annual budget to award \"Explorer Grants\" for proposals that promise to be \"transformative, innovative, exploratory or unconventional, and have potential for major impact.\" Seven years on, and New Zealandâs Explorer Grants program has proven quite popular among Kiwi scientists. [27] Whether a lottery system ultimately makes sense for U.S. science funding is beside the point. We should instead be setting aside the resources to continuously test a variety of approaches against objective performance indicators â from alternative allocation schemes to no-strings-attached grants for promising young researchers.\n\nWe support the Endless Frontier Act as a step in the right direction, at least in terms of the scale of its ambition. [28] Introduced by Sens. Chuck Schumer and Todd Young and Reps. Ro Khanna and Mike Gallagher, the Act would rename the NSF the National Science and Technology Foundation, and establish a new Technology Directorate with a $100 billion budget over five years. An additional $10 billion would be directed toward the creation of 10 technology hubs throughout the country, with the twin goals of spurring regional economic development while diversifying access to federal R&D investments. [29] Sen. Chris Coons and Sen. Dick Durbinâs Innovation Centers Acceleration Act of 2020 proposes something similar, namely a national competition to identify nine up-and-coming metro areas as new \"American Innovation Centers\" eligible for a suite of public R&D investments. [30] As MIT economists Jonathan Gruber and Simon Johnson argued in their recent book Jump-Starting America, establishing new technology hubs beyond the Boston and Bay Area corridors is an idea whose time has come. [31]\n\nWith a focus on technologies such as advanced manufacturing, applied machine learning, and synthetic biology, the Endless Frontier Act would represent a major departure from the NSFâs traditional focus on basic science. Nevertheless, the Actâs most important innovation is the broad, DARPA-like authority it provides to the program managers selected by the Technology Directorate to issue grants, prizes, and contracts to academic institutions, individual investigators, private research groups, industry consortia, and more. Institutional flexibility of that sort, combined with a broader decentralization of the research endeavor, is precisely whatâs needed to jump-start scientific and technological progress, test new ideas, and ensure that research supported by U.S. taxpayers is ultimately commercialized by U.S. companies.\n\nIt is often remarked that the key to DARPAâs history of success \"lies with its program managers,\" [32] but itâs worth unpacking exactly what that means. DARPAâs director has unusually flexible hiring authority, but in exchange the internal program is kept quite small at around 100 program managers and a couple dozen support staff. PMs are hired on the basis of their talent and self-motivation and have at least one area of deep technical expertise â the sort of driven, abstract thinkers one could see founding a successful start-up company. A PMâs tenure lasts only four to five years, during which they design and pitch a program concept and, once approved, execute the program with limited oversight. DARPAâs exploratory tranche, for example, provides PMs with about $1.5 million to spend on \"seedling projects\" that acid-test whether an idea is even possible. This includes the ability to award research grants without preapproval or peer review, as well the ability to pull grants to redeploy resources elsewhere. As Ben Reinhardt notes, \"Restrictions on spending money happen when you reach trust limits, so this low-oversight spending is another reason why DARPA depends on high trust in badass PMs.\" [33]\n\nAttempts to clone the DARPA model that donât appreciate the high trust and autonomy provided to PMs are doomed to underwhelm. [34] And indeed, in so many ways, the bureaucratization of American science â from risk-averse grant-making to the IRBâs mission creep â is symbolic of our institutional lack of trust in researchers and program officers alike. The Endless Frontier Act seeks to change this by not only boosting our investment in science and technology across the board, but by doing so in a way that puts trust in American scientists front and center.\n\nWhether itâs restoring robust wage growth or tackling global challenges like climate change and COVID-19, the need for massive federal investments in research and development has never been greater. But without trust, our research institutions will fail to move fast and take the risks necessary for truly big rewards. Structural reform of how we fund and regulate science is thus imperative. A scientific and technological renaissance could be on the horizon. With the right policies in place, the United States can lead the way.\n\nPromote Diversified Economic Development\n\nOnce-vibrant regions across the United States are grappling with deindustrialization, population decline, and shrinking tax bases. Meanwhile, prosperous cities have failed to properly absorb newcomers in search of opportunity, driving up rents and exacerbating urban inequality. These seemingly distinct issues may have quite different short-run policy implications, but what if they are two sides of the same phenomenon?\n\nWe donât normally think of the rural, working-class Trump-voter as having much in common with the metropolitan millennial who became radicalized in their struggle to afford a studio apartment. Yet they neednât be friends in the making to have their relative precarity linked by some common set of factors. In particular, the last two decades have borne witness to both the accelerated loss of American manufacturing jobs to offshoring and underinvestment, and to the rise of \"knowledge work\" that sorts college educated professionals into a handful of magnet cities. Both were the result of underlying trends in technology and globalization that combined to accentuate Americaâs comparative advantage in college-educated labor â what trade economists would call our \"abundant factor\" â at the expense of other forms of human capital. [35]\n\nThis shift is captured in the college wage premium, which can be interpreted as reflecting either the increased returns to higher education or the deterioration of labor market opportunities for the two-thirds of working-age Americans without a college degree. Seeing only the first interpretation, policymakers have tended to promote \"college for all,\" rather than fill the void of alternative modes of skill acquisition. As a result, college programs have experienced substantial grade inflation, [36] producing a glut of college graduates with modest career prospects despite substantial student loan debt. The college wage premium has thus stopped rising, and shifted to those with post-secondary degrees. [37]\n\nSluggish wage growth is a widely recognized phenomenon, but a focus on the median worker doesnât tell the full story. In the background, rising job polarization [38] has hollowed out the availability of \"middle skill\" occupations, creating bifurcated labor markets in which \"high skill\" professionals live side-by-side with \"low skill\" service sector workers just barely scraping by. [39] We put \"skill\" in scare quotes here because economists donât measure skill directly, but instead use educational attainment as a proxy. Being skilled and having a college diploma are clearly not synonymous; nor does skill map onto a one-dimensional spectrum that runs from \"low\" to \"high.\" Instead, human capital displays as much heterogeneity as the goods and services it goes into producing. An electrician and a plumber may both be categorized as \"middle-skill,\" for example, but one cannot do the job of the other. Americaâs college-tracked education system systematically fails to account for this heterogeneity of interests and aptitudes and has thus done little to provided non-college-educated workers with pathways to the middle-class.\n\nThese same forces can also help explain rising political polarization. As Will Wilkinson has observed, the propensity of college-educated liberals to self-sort into cities, while those with conservative temperaments stay rooted to home, has made population density the single best predictor of a locationâs partisan bent. [40] Dense, liberal places have become more uniformly Democratic, while rural, conservative places have become more uniformly Republican. The homogeneity of local electorates thus undermines the traditional political advantages enjoyed by moderates and rewards politicians for their ideological purity, pulling the Democratic and Republican Parties as a whole to their respective extremes.\n\nIn other words, unbalanced economic development creates unbalanced politics. Developing countries provide many examples of this dynamic that the United States can learn from. Left to their own devices, market forces can lead an emerging economy to overspecialize in its abundant factor, be it natural resources or low-wage labor. The former gives rise to petro states and the Dutch disease, whereby currency appreciation suppresses the development of productive export sectors, and turns politics into a zero-sum conflict over resource rents. The latter gives rise to the so-called \"middle-income trap,\" whereby a country specialized in labor-intensive production underinvests in the capital, technology, and education necessary to transition to a high-wage equilibrium, and so enters a developmental cul-de-sac. [41]\n\nBoth the Dutch disease and the middle-income trap stem from the failure of an economy to properly diversify, and in many ways the contemporary U.S. economy exhibits symptoms of each. Following the collapse of the Soviet Union, the U.S. adopted an explicit strong-dollar policy, only rather than export oil, we exported the safety and stability of dollar-denominated assets like Treasury securities. The U.S. dollar now denominates two-thirds of international foreign currency reserves, 90 percent of foreign-exchange trades, and trillions of dollars in private assets held abroad. [42] This makes the U.S. the most attractive economy in the world to park oneâs excess savings, which we absorb in the form of our ever greater public and household debt. [43] Where a petro state might invest in pipelines and refineries, the U.S. invested in Wall Street â the de facto pipes of global finance. In the mid-1990s, the U.S. corporate sector thus transitioned from being a net borrower to being a net lender, while aggregate investment in tangible assets like structures and equipment withered on the vine. [44]\n\nAnd while the U.S. is no doubt a high-income country, our specialization in a particular kind of college-educated knowledge production â buttressed by financialization and the growth of intangible assets like intellectual property â puts us at risk of walking down a developmental cul-de-sac of our own. [45] We therefore reject the misleading distinction between developing and developed countries, as if the United States has reached some kind of end-state. On the contrary, economic development is a process that never ends, and without proactive diversification, even frontier economies can fall short of their full growth potential.\n\nUnfortunately, the U.S. lacks any coherent economic development policy to speak of. At the state and local level, policymakers tend to focus on firm-specific tax incentives, designed to attract major businesses and create jobs for a region. [46] This forces jurisdictions into a zero-sum competition that favors companies with political connections and places that are already prospering. For poorer states and cities to compete, business incentives can even come at the expense of investments in human capital and public infrastructure, jeopardizing development in the longer run.\n\nThe contest over the site location for Amazonâs next headquarters, known as HQ2, was a perfect illustration. More than 200 cities across North America submitted proposals, each offering more outlandish inducements than the last. In essence, state and local governments were stuck in a collective action problem, which Amazon exploited to extract the largest possible rents in the form of income and property tax abatements and other bespoke incentives.\n\nYet Amazon is just the tip of the iceberg. Consider Louisianaâs Industrial Tax Exemption Program (ITEP), the largest state corporate subsidy program in the nation. ITEP is unique in providing a state-level board with the authority to exempt businesses from locally administered property taxes. From 1998 to 2016, the board rubber-stamped 99.95 percent of all ITEP applications, resulting in roughly $2,800 in annual corporate subsidies per Louisiana resident â 10 times the national average. Across the entire state, between 66 percent and 99 percent of industrial property is exempted from property taxes in perpetuity. [47] Local governments forego tax revenues equal to about 20 percent of total state and local school funding. Caddo Parish alone, population 254,969, exempted more corporate property taxes in 2016 than the entire state of Texas. [48]\n\nRecent reforms to give municipalities a say in ITEP approvals have been stymied. [49] Thanks to corporate lobbying, the majority of existing exemptions were grandfathered in, and in 2019 the governor added a favorable appeals process for industries that lost their tax break. With local governments unable to invest in basic public goods, Louisiana thus presents a paradox. The state is a bona fide Silicon Valley for the petrochemical industry, and consistently ranks first in the nation for foreign direct investment. At the same time, Louisiana ranks last or near last across a wide variety of socioeconomic indicators, including health and life expectancy, math and reading scores, and household income. [50] Location and firm-specific tax incentives do little to create good-paying jobs under the best of circumstances. [51] But when the target industries are oil refineries and salt mines â production thatâs literally tied to the ground â they represent little more than a blank check for those polluting the air that impoverished Louisianans are forced to breathe on a daily basis. [52]\n\nThe conventional policy arsenal that local governments use for investment promotion, from beggar-thy-neighbor tax incentives to outright corporate welfare, points to the need for a new coordinating institution. As Niskanen Center Senior Fellow Nathan Jensen has shown, [53] transparency rules can help bring sunlight to the degree of corruption, but do little to change politiciansâ basic \"incentive to pander.\" [54] Likewise, an interstate compact can promote a ceasefire in the site selection bidding war, but it wouldnât address corporate subsidies for companies already within a stateâs borders. \"There is no easy solution to reforming economic development, but any solution must acknowledge that asking people to simply be better isnât scalable or sustainable,\" writes Jensen. \"Economic development reforms will most likely require some action by the federal government.\" [55]\n\nThe opportunity for reform is ripe. In 2015, the Government Accounting Standards Board began requiring state and local governments to disclose information about tax abatements and similar subsidy arrangements. [56] Similar disclosure rules are scheduled to come into effect for the business sector as well. [57] As these new accounting practices come into effect, Congress could use the window into firm-specific subsidies to withhold federal grants to states that poach jobs from neighboring states [58] or discourage the use of subterranean development incentives by other means. [59]\n\nLooking forward, we believe the federal government is in a far better position to coordinate economic development across the 50 states. But rather than lean into existing industries, or dubious forms of development like real estate, strategic federal investments should focus on spurring the creation of new markets and capacities, with the complementary goals of jump-starting productivity growth and reversing regional decline. Ideally, this would be achieved through a dedicated agency â an Office of Regional Development â that would bring our multifarious development programs under one roof. [60]\n\nConsider the U.S. manufacturing sector. At first glance it seems healthy, with manufacturing output near an all-time high. Yet look beneath the surface, and one sees that essentially all the net growth in U.S. manufacturing output since the early 2000s derives from a single subindustry: semiconductors. [61] Indeed, for all the worries of robots taking our jobs, American manufacturing productivity has been stagnant or declining for over two decades. [62]\n\nInternational trade can be a powerful tool for pushing domestic industries to level up their capabilities to compete on a global stage. In globalized world, however, this often requires substantial public support lest firms discover the path of least resistance is to move production abroad or shut down altogether. The Manufacturing Extension Partnership program exists for precisely this reason, and every year provides grants and technical resources to small and medium manufacturers looking to upgrade their processes. [63] Yet with an annual budget of only $140 million, the MEP is roughly two-thirds the size of the equivalent program in Canada, a country with one-tenth our population. Germanyâs Fraunhofer Institutes, meanwhile, receive over $1 billion annually to support domestic manufacturers through grants, contracts, and publicly financed research projects, contributing to one of the most competitive manufacturing sectors in the world. The U.S. MEP program should be at least as big. Note $1 billion is only half of what Louisianaâs local governments lose to tax abatements every year.\n\nWith such feeble public support, one U.S. industry after another has embraced offshoring as the path of least resistance. As a result, the United States has experienced a troubling erosion in what Stephen Cohen and Brad DeLong call \"communities of engineering and technological practice\" â those vital clusters of technical knowledge, know-how, collaboration, and competition that are the fountainhead whose spillovers drive technological and material progress. [64]\n\nOf course, not all manufacturing jobs are made equal, nor is manufacturing somehow more noble than the service sector. Yet as a rule of thumb, high value-added manufacturers produce the very sort of \"middle skill\" labor market opportunities that have otherwise evaporated. The postwar manufacturing boom, for example, helped lift less educated Irish and Italian immigrants into the middle class. The same was beginning to be true for African Americans, from Flint, Michigan, to St. Louis, Missouri, with Black high school graduation rates finally converging with those of whites around 1970. Tragically, however, the 1970s were the same decade in which U.S. manufacturing employment peaked. [65]\n\nEven the legacy of slavery can be understood through the lens of deindustrialization. [66] After all, plantations in the Cotton Belt treated human beings as literal machines, reducing the need for the South to industrialize as fast as the North. This \"specialization\" in labor-intensive production persisted long after the formal end of slavery. Without the necessary catch-up investments in productivity-enhancing technology and infrastructure, emancipation was thus in a deeper sense incomplete.\n\nOf course, given the forward march of automation and global economic development since then, there is no possibility of a return to mass employment in labor-intensive manufacturing that the U.S. economy experienced during the middle decades of the 20th century. Nevertheless, there is no law of nature that compels the extent of labor market polarization that has occurred in more recent decades. The structure of economic production, and therefore the structure of employment, can be and is heavily influenced by policy choices. With better choices, a more diversified economy and a more balanced labor market are both possible.\n\nA robust national economic development strategy therefore promises to boost our national productivity while also promoting inclusive growth for those whoâve been left behind. Whatever the sector, the focus should be on enabling new industries to rise as others fall, while pushing existing industries to innovate, invest, and compete in global markets, [67] not chase tax cuts or trade protections. In the case of manufacturing, for example, policymakers should focus on ensuring the next generation of high-tech manufacturers have the capital they need to scale; [68] promote the transfer and commercialization of the sorts of basic research we discussed in the previous section; and invest in comprehensive employment and training programs so those disrupted by trade or technological change donât have their existing skills go to waste.\n\nHistorically, the term for rebalancing an economy away from a half-dozen lucrative cities and professions is \"industrial policy.\" [69] Since, in this country at least, that term has become so associated with corporate welfare for politically powerful but declining or never-to-rise industries, we offer the term \"development policy\" as an alternative â one that appropriately signals that healthy economic development is an ongoing and never-ending challenge for rich and poor countries alike. Whatever the label affixed to them, policies aimed at reviving meaningful, well-paid work in rural regions and smaller cities would create the kind of jobs in the kind of places that are most conducive to family life. At the same time, a more diversified economy would lessen the demand surge in magnet cities by expanding labor market opportunities for those most likely to be net losers in the professional classâs place-based bidding war. If weâre lucky, our hyperpolarized politics could even moderate in the process.\n\nIn an era of wage stagnation and two-tiered labor markets, we simply reject the notion that deindustrialization is inevitable. But rather than attempt to turn back the clock, our leaders must rediscover the definite optimism required to invent the high-wage industries of the future. The late Andy Grove put it best: \"If we want to remain a leading economy, we change on our own, or change will continue to be forced upon us.\" [70]\n\nReduce Barriers to Geographic and Labor Mobility\n\nWe have already discussed how policies that discourage new housing construction are responsible for an enormous misallocation of resources. Millions of Americans who want to move to and work in the countryâs most productive cities are prevented from doing so by high housing prices caused by artificial supply constraints. As a result, those Americans excluded from opportunity are not as productive as they could be, and overall economic output suffers significantly as a result.\n\nRestrictions on new housing, though, are not the only major barrier to geographic mobility. And the cost of these barriers is not limited to a one-off hit to output due to resource misallocation. Here we will address two other obstacles to freedom of movement: state-based occupational licensing, and variations in the levels and application procedures for state benefit programs. Together with land use restrictions, these obstacles to mobility exact an ongoing toll on productivity growth by hindering the ability of people to move to opportunity and into occupations that best match their skills.\n\nHere it is worth recalling that productivity growth does not spring automatically and frictionlessly from innovation. The origination of new, superior ways of doing things is only the first step in the process; what must follow is technology diffusion, or the restructuring of production to take full advantage of that innovation. For example, from the development of electric arc furnaces to make steel from scrap came the first steel \"minimills\"; that breakthrough eventually enabled a massive reduction in the number of worker-hours needed to make a ton of steel, but only after many years in which new minimills proliferated and the range of steel products they could make expanded, gradually ramping up minimill market share and the percentage of total steel produced by the new, less-labor-intensive methods.\n\nTechnology diffusion thus consists of the reallocation of resources so that an innovationâs full productive potential can be realized â and those reallocated resources include labor as well as capital. For new, more productive firms and industries to rise and old, less productive firms and industries to shrink, it is frequently necessary for large numbers of people to move from one area of the country to another â as it often happens that sunrise and sunset sectors are located in different places. Accordingly, geographic mobility is a prerequisite for robust creative destruction.\n\nUnfortunately, geographic mobility in the United States has declined considerably in recent decades: The percentage of Americans who move across state lines over the course of a year is now about half what it was 30 years ago. [71] To some extent, the waning of American wanderlust reflects appropriate responsiveness to changed circumstances â namely, a drop in the geographic variation in employment opportunities, combined with improved ability to learn about other places (whether online or through inexpensive travel) without moving there. [72] On the other hand, for many Americans the financial incentives to relocate are actually up sharply. Research by Scott Winship shows that the income gap between people who have moved across state lines at least once and those who havenât has grown significantly since the 1970s â and the difference is especially stark for people who grew up in low-income households. [73]\n\nWhile many different economic and noneconomic factors influence the willingness to move, one important contributor to reduced geographic mobility is public policy. As discussed previously, land use regulations that discourage the construction of new housing are a major deterrent to moving, as they effectively build moats around the countryâs richest, most productive cities. These moats, in the form of artificially inflated housing prices, are especially effective at screening out less-educated workers. Knowledge workers with college or graduate degrees typically earn big enough wage premiums in big-city human capital hubs to come out ahead even with higher rent or mortgage payments, but for workers without a college degree the extra pay isnât enough to compensate for more expensive housing. [74]\n\nLand use restrictions are not the only policy-created barriers to mobility that have worsened over time. Here we will mention two other important examples: state-based occupational licensing and differences in state benefit programs. [75] We have already discussed problems caused by the licensing of doctors and other health care workers, but the scope of licensing extends far more broadly: The share of American workers in occupations subject to state licensing has jumped from around 10 percent in 1970 to almost one quarter today. [76] Although such licensing is typically justified on the grounds of consumer protection, there is little evidence that it actually improves service or effectively screens out bad actors. On the other hand, there is ample evidence that licensing benefits incumbent service providers in licensed occupations by limiting the number of would-be competitors. These artificial restrictions on supply have a number of unfortunate consequences â higher prices, less consumer choice, fewer occupational options for workers deterred by licensing â but for present purposes the key point is that they discourage interstate migration because of the need to get relicensed. Although workers in licensed occupations move just as frequently as other workers, they are 24 percent less likely to move across state lines. [77]\n\nThe rise of occupational licensing is yet another baleful instance, all too common in recent American political economy, of rent-seeking run amok. [78] In almost all cases, the goal of consumer protection could be achieved more effectively â and without the unjust enrichment and collateral damage to consumers â through programs of voluntary certification. As to the specific problem of licensing interfering with mobility, the most direct reforms are ones that either harmonize licensing requirements across states or else â whether through state legislation or interstate compacts â recognize licenses granted in other states as valid. New York Stateâs temporary suspension of restrictions on health care professionals licensed out of state during the COVID-19 crisis should point the way to permanent reforms along similar lines. [79] And more generally, Arizonaâs recently signed universal licensing-recognition law, the first state legislation in the country to unilaterally extend recognition to out-of-state licenses, offers a promising path that we urge other states to follow. [80] For its part, the federal government can facilitate reform by encouraging new interstate compacts, wider participation in existing ones, and adoption of universal recognition laws like Arizonaâs.\n\nThe wide variation among states regarding eligibility criteria and benefit levels for social welfare programs constitutes another significant impediment to interstate migration. Since the 1980s, the general trend in welfare policy has been to expand statesâ operational control over the provision of benefits. [81] Alas, this decentralization has not been accompanied by any parallel effort to equalize resources at the state level through federal intergovernmental transfers; indeed, the only program that extended unconditional federal assistance to the states â revenue sharing â was terminated in 1986. [82] The result has been a big increase in eligibility and benefit differences across states, a state of affairs that naturally discourages moves from richer, high-benefit states to poorer, low-benefit ones. In addition to its other benefits, overhauling federal grants to the states to promote fiscal equalization, as proposed by Joshua McCabe [83] , would help to promote interstate mobility by reducing the state-level policy variations that currently discourage it.\n\nRelated to the trend of declining mobility among places is a parallel trend of declining mobility among jobs. Employment churn â or worker flows in and out of existing jobs â has fallen by more than a quarter during the 21st century, along with the pace of job creation and destruction. [84] This slowdown in labor market turnover is a broader phenomenon than the drop in interstate mobility, since job changes can and frequently do occur locally. As with falling geographic mobility, the reasons for this decline are not fully understood. But to the extent that artificial barriers play a role, the implications for economic dynamism are clearly negative: Anything that blocks the redeployment of labor resources from less-productive to more-productive positions is bad for technology diffusion and productivity growth.\n\nOne potentially significant barrier to labor mobility that has received increasing scrutiny in recent years is the rise in noncompete agreements imposed on workers by their employers. These agreements, which aim to prevent employees from going to work for a rival company for some specified period of time, now affect almost one-fifth of all workers. [85] Such contracts are justified as necessary for protecting trade secrets and recouping investment in worker training, but their use is much more extensive than such relatively narrow concerns would warrant, covering many low-wage occupations.\n\nIn higher wage sectors, the ability of skilled workers to take their industry know-how to the competitor next door is a key ingredient to building a strong innovation economy. Most famously, the unenforceability of noncompete provisions in California contributed to the rise of Silicon Valley, as frequent job switching enabled knowledge about nascent best practices to diffuse across the broader ecosystem. Thus, even in an occupational category where the standard justifications for noncompete agreements seem to apply, their value fundamentally derives from a collective action problem: Employers rationally wish to hoard the knowledge and skill of employees, but when their competitors do the same their behavior is collectively self-defeating, and the industry as a whole suffers. [86]\n\nBesides California, Oklahoma and North Dakota are the only other states that refuse to enforce noncompete provisions. All other states enforce them to at least some extent. However, momentum for reform is growing: In 2019, Maine, New Hampshire, and Maryland all moved to prohibit noncompete agreements with low-wage workers, while Sens. Chris Murphy and Todd Young introduced the Workplace Mobility Act to restrict the use of noncompetes across the board. [87] We support reforms along these lines to expand worker choice and liberalize labor market flows.\n\nOverhaul Environmental Review to Bring Down Sky-High Infrastructure Costs\n\nAmerica was once famous for its can-do spirit and \"Yankee ingenuity.\" That spirit was most obviously and spectacularly visible in the American capacity to build â bigger, faster, and better than anywhere else. The transcontinental railroad, the Panama Canal, the Golden Gate Bridge, Hoover Dam, the New York City skyline: All are iconic manifestations of Americaâs once unmatched ability to remake the physical environment to serve human ends.\n\nThe United States today remains an outlier when it comes to construction and infrastructure â but now its exceptionalism runs in the other direction. Where once American building projects stood apart in the scale of their ambition and the speed of their completion, now they set records for stratospheric costs, interminable delays, and bureaucratic bloat.\n\nFor a glimpse at the new American exceptionalism, consider the first phase of New York Cityâs Second Avenue subway project, completed in 2017 (five years after the originally scheduled completion date) at a cost of $1.7 billion per kilometer â compared to around $250 million per kilometer for recent, comparable projects in Paris, Copenhagen, and Berlin. [88] However bad that seems, at least something was actually completed. In California, meanwhile, Gov. Gavin Newsom announced in February 2019 that he was pulling the plug on most of the project to build high-speed rail from Anaheim to San Francisco, following a decade-plus of spiraling cost estimates and lengthening delays. And if you think the problem is confined to complex megaprojects, think again. The 232-foot Anderson Memorial Bridge, which connects Boston and Harvard Square, took 11 months to build in 1912; repairs during the past decade dragged on more than four times as long. [89]\n\nRising infrastructure costs are matched by shrinking investment and declining quality. Infrastructure spending as a percentage of GDP has been falling consistently since 1970 â an alarming trend not seen in other countries. [90] According to the World Economic Forumâs most recent Global Competitiveness Report, the United States ranks 13th in the world for overall infrastructure quality â down from 5th place in 2002. [91] The U.S. Department of Transportation, meanwhile, has found that 47,000 bridges are structurally deficient, or in need of repair, while almost one-fifth of all passenger rail lines are in poor condition. [92]\n\nWell-developed infrastructure is essential for supporting and promoting economic growth. This is perhaps easiest to see when we consider the negative effects of poor infrastructure: Excessive transportation expenses, delays that render supply chains unreliable, traffic congestion that puts potential workers and customers out of reach, and intermittent blackouts all undermine productivity by adding frictions that inflate the costs of production and distribution. Looking ahead, enormous investments in new infrastructure will be needed as we face perhaps the greatest innovation challenge of the 21st century: negotiating the transition to a carbon-free energy future. There is simply no way we can rise to that challenge in a timely and efficient manner without major overhauls in our dysfunctional infrastructure construction process. [93]\n\nWhatâs wrong with the American way of building? In a word, everything. As economic columnist Noah Smith puts it, \"U.S. costs are high due to general inefficiency â inefficient project management, an inefficient government contracting process, and inefficient regulation.\" [94] In other words, as is the case in the health care sector, Americans are plagued by a system run for the benefit of providers rather than users â and a complacency that deems paying through the nose preferable to rooting out waste and abuse.\n\nOne policy shift in particular, though, appears to have played a crucial role in the United Statesâ transformation from leader to laggard on infrastructure: what Harvard economist and former Secretary of the Treasury Lawrence Summers has called the \"promiscuous distribution of the power to hold things up.\" [95] In the 1960s and â70s, in reaction to the neighborhood-destroying and city-blighting excesses of \"urban renewal,\" progressive reformers instituted reforms to greatly expand public voice and input regarding changes to the built environment. In doing so, they ended up exchanging one species of dysfunction for another: We have gone from high-handed and unaccountable urban planners, exemplified by Robert Moses in New York, to so many Gullivers pinioned under webs of Lilliputian restraints.\n\nIn a recent paper for the Brookings Institution, Leah Brooks and Zachary Liscow document the policy sea change and its consequences. Specifically, they find that spending per mile on interstate highway construction tripled between the 1960s and 1980s, with an inflection point in the early 1970s â that is, just as the new \"citizen voice\" reforms were starting to take effect. [96] In a recent in-depth piece for Politico, the exasperating tale of the three-decades-and-counting effort to renovate and upgrade Penn Station in New York City brings home the unforeseen consequences of those well-intended reforms â namely, the mad proliferation of veto points in the planning and construction process and the resulting paralysis and stagnation. \"The project to diffuse power to the public has succeeded,\" the author concludes, \"[b]ut the pendulum has swung too far in the other direction. The leftâs zeal to hamstring government has helped to burnish the rightâs argument that government would mess up a one-car parade.\" [97]\n\nAt the center of the miscarried \"citizen voice\" revolution is one particular piece of federal legislation: the 1970 National Environmental Policy Act, which requires \"environmental impact statements\" for \"major federal actions\" that could \"significantly affect\" the environment. Projects that do not meet this threshold must still be accompanied by an \"environmental assessment\" that establishes that an EIS is not needed. It is important to note that NEPA imposes no substantive environmental standards; if a court holds up a project because the EIS is deemed insufficient, the cure is to add a section to the EIS, and the agency is legally able to proceed with the project even if negative impacts are found.\n\nIn the early days, NEPAâs procedural requirements were modest: An EIS could be as short as 10 pages, and the legislation didnât provide for a private right of action. Courts soon declared a private right of action, though, and under the pressure of litigation the lawâs demands grew ever more onerous: Today the average EIS runs more than 600 pages, plus appendices that typically exceed 1,000 pages. The average EIS now takes 4.5 years to complete; between 2010 and 2017, four such statements were completed after delays of 17 years or more. And remember, no ground can be broken on a project until the EIS has made it through the legal gauntlet â and this includes both federal projects and private projects that require a federal permit. Meanwhile, the far more numerous environmental assessments (the federal government performs more than 12,000 of them a year, compared to 20-something Environmental Impact Statements) have likewise become much lengthier and more time-consuming to complete. [98]\n\nNEPAâs chilling effect on investment extends well beyond the obvious case of physical infrastructure. In 1973, for example, the FAA issued a preemptive ban on civil supersonic flights overland due to concerns that the Concorde heralded a new era of faster-than-sound aviation. The primary concern was the potential noise pollution generated by sonic booms, and yet with advances in carbon fiber manufacturing and computer-optimized designs it is now theoretically possible to design supersonic jets with a \"low boom\" noise profile. [99] But how quiet is quiet enough? The answer to that question is clearly needed for any aerospace company to invest in a quiet supersonic jet. And yet the FAA has kept the ban in place because without real-world noise data because they are unable to complete a proper environment assessment. NASA is thus funding a \"low boom demonstration project\" just to get around a NEPA-created Catch-22. [100]\n\nEarlier this year the Trump administration proposed changes to NEPAâs implementing regulations that would try to rein in the excesses of environmental review: Environmental assessments would need to be no longer than 75 pages and completed within a year, while an EIS would be limited to 150 pages and finished within two years. These presumptions, however, could be overridden â and therefore, in all likelihood, would be. After all, before this latest effort, the Clinton, Bush, and Obama administrations all made previous â and unavailing â attempts to find some administrative fix for NEPAâs problems\n\nTo really tame the NEPA monster and chasten the distribution of veto power, we believe that legislation will be needed. An appropriately overhauled review process would include (1) binding deadlines and page limits; (2) consolidation of decision-making, with federal preemption of permitting authority on all interstate projects and ultimate permitting authority clearly vested in specific agencies for specific kinds of projects; and (3) a significant narrowing of the scope of judicial review. [101]"
    }
}