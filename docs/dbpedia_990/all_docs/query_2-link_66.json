{
    "id": "dbpedia_990_2",
    "rank": 66,
    "data": {
        "url": "https://www.the-scientist.com/the-brain-interprets-spoken-and-written-language-the-same-way-66602",
        "read_more_link": "",
        "language": "en",
        "title": "The Brain Interprets Spoken and Written Language the Same Way",
        "top_image": "https://cdn.the-scientist.com/assets/articleNo/66602/aImg/34117/seeing-is-hearing-m.png",
        "meta_img": "https://cdn.the-scientist.com/assets/articleNo/66602/aImg/34117/seeing-is-hearing-m.png",
        "images": [
            "https://cdn.the-scientist.com/assets/magazineIssueNo/2045/iImg/53430/ts-augd1-cover-s.jpg",
            "https://cdn.the-scientist.com/static/8.0.4/assets/icons/TS-Digest.svg",
            "https://cdn.the-scientist.com/assets/magazineIssueNo/2043/iImg/53031/06-24-cover-s.jpg",
            "https://cdn.the-scientist.com/static/8.0.4/assets/icons/logo_ts_notagline.svg",
            "https://cdn.the-scientist.com/assets/articleNo/66602/hImg/34139/semanticmaps-web-s.png",
            "https://cdn.the-scientist.com/assets/articleNo/66602/aImg/34117/seeing-is-hearing-s.png",
            "https://cdn.the-scientist.com/assets/authorNo/41/iImg/36778/cofford-s.png",
            "https://cdn.the-scientist.com/assets/authorNo/41/iImg/36778/cofford-s.png",
            "https://cdn.the-scientist.com/assets/magazineIssueNo/1963/iImg/34011/november-cover-s.jpg",
            "https://cdn.the-scientist.com/static/8.0.4/assets/icons/logo_ts_notagline.svg",
            "https://cdn.the-scientist.com/assets/authorNo/41/iImg/36778/cofford-s.png",
            "https://cdn.the-scientist.com/assets/articleNo/72041/aImg/53691/8b65ac1b-8204-4bd2-af13-e10e3b3e932c-t.jpg",
            "https://cdn.the-scientist.com/assets/articleNo/71965/aImg/53425/article-08-24-sciencesnapshot-t.jpg",
            "https://cdn.the-scientist.com/assets/articleNo/72036/aImg/53670/70500-800-x-560-t.jpg",
            "https://cdn.the-scientist.com/assets/articleNo/72035/aImg/53668/istock-1475054812-800x560-t.jpg",
            "https://cdn.the-scientist.com/static/8.0.4/assets/TSNewsAlerts.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Catherine Offord"
        ],
        "publish_date": "2019-11-01T00:00:00",
        "summary": "",
        "meta_description": "Neural activity associated with the meaning of words is independent of whether those words are read or listened to, a study finds.",
        "meta_lang": "en",
        "meta_favicon": "https://cdn.the-scientist.com/static/8.0.4/favicon.ico",
        "meta_site_name": "The Scientist Magazine®",
        "canonical_link": "https://www.the-scientist.com/the-brain-interprets-spoken-and-written-language-the-same-way-66602",
        "text": "ABOVE: Functional maps of brain activity show that the meaning of particular concepts or phrases is represented almost identically during reading and listening.\n\n© FATMA DENIZ\n\nEDITOR’S CHOICE IN NEUROSCIENCE\n\nThe paper\n\nF. Deniz et al., “The representation of semantic information across human cerebral cortex during listening versus reading is invariant to stimulus modality,” J Neurosci, 39:7722–36, 2019.\n\nResearchers know that similar brain regions become active in response to the semantic content, or meaning, of language, whether it is read or listened to. But brain-imaging studies haven’t had the resolution to determine if it’s the same neural circuits, or just adjacent ones, within those regions that respond to the two language modes, says University of California, Berkeley, neuroscientist Jack Gallant.\n\nTo find out, Gallant, postdoc Fatma Deniz, and colleagues transcribed several 10- to 15-minute clips from The Moth Radio Hour, in which speakers tell stories to an...\n\nUsing the imaging data and computer modeling, the team created detailed maps of brain activity for each participant. These maps indicated that the brain circuits responding to the semantic content of each concept within the stories were almost identical within each individual, regardless of whether people were reading or listening. After discounting the different sensory areas of the brain that process sound and sight, says Gallant, “essentially you can’t tell the difference between the semantic maps.”\n\n“It’s a very impressive paper,” says Rik Vandenberghe, a neurologist at KU Leuven who was not involved in the work. He highlights the team’s “courage to address language in its full complexity” by using stories, rather than single words, as stimuli. While it’s not surprising the brain uses common pathways to process meaning, “the beauty of this paper is more the way that they demonstrate this in a very convincing way.”\n\nThe researchers are now studying how semantic concepts are represented in people who are bilingual. “If you have two language representations, are they the same?” says Gallant. “We think we might be able to answer that question.”\n\nCatherine Offord is an associate editor at The Scientist. Email her at cofford@the-scientist.com."
    }
}