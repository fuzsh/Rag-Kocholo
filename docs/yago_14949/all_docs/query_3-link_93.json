{
    "id": "yago_14949_3",
    "rank": 93,
    "data": {
        "url": "https://journals.ametsoc.org/view/journals/wefo/21/2/waf913_1.xml",
        "read_more_link": "",
        "language": "en",
        "title": "Bayesian Approach to Decision Making Using Ensemble Weather Forecasts",
        "top_image": "https://journals.ametsoc.org/cover/journals/wefo/21/2/cover.jpg",
        "meta_img": "https://journals.ametsoc.org/cover/journals/wefo/21/2/cover.jpg",
        "images": [
            "https://journals.ametsoc.org/fileasset/AMET-Journals-Logo-Mobile.png",
            "https://journals.ametsoc.org/fileasset/AMS-Logo-Lockup-Journals-01.png",
            "https://journals.ametsoc.org/fileasset/AMS-Logo-Lockup-Journals-01.png",
            "https://journals.ametsoc.org/fileasset/AMET-Journals-Logo-Mobile.png",
            "https://journals.ametsoc.org/fileasset/AMS-Logo-Lockup-Journals-01.png",
            "https://journals.ametsoc.org/fileasset/AMS-Logo-Lockup-Journals-01.png",
            "https://journals.ametsoc.org/fileasset/AMET-Journals-Logo-Mobile.png",
            "https://journals.ametsoc.org/fileasset/AMS-Logo-Lockup-Journals-01.png",
            "https://journals.ametsoc.org/fileasset/AMS-Logo-Lockup-Journals-01.png",
            "https://journals.ametsoc.org/fileasset/AMET-Journals-Logo-Mobile.png",
            "https://journals.ametsoc.org/fileasset/AMS-Logo-Lockup-Journals-01.png",
            "https://journals.ametsoc.org/fileasset/AMS-Logo-Lockup-Journals-01.png",
            "https://journals.ametsoc.org/coverimage?doc=%2Fjournals%2Fwefo%2F21%2F2%2Fwefo.21.issue-2.xml&width=200",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f01.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f02.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f03.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f04.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f05.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f01.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f02.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f03.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f04.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f05.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e5.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e5.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e5.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e6.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e6.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e6.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e7.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e7.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e7.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e8.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e8.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e8.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e9.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e9.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e9.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e10.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e10.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e10.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e11.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e11.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e11.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eq1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eq1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eq1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e12.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e12.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e12.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e13.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e13.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e13.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e14.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e14.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e14.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e15.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e15.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e15.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e16.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e16.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e16.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e17.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e17.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e17.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e18.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e18.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e18.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e19.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e19.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e19.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e20.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e20.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e20.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e21.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e21.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e21.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e22.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e22.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-e22.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea5.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea5.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-ea5.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb1.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb2.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb3.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f01.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f01.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f01.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f02.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f02.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f02.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f03.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f03.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f03.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f04.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f04.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f04.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f05.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f05.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f05.gif",
            "https://journals.ametsoc.org/coverimage?doc=%2Fjournals%2Fwefo%2F21%2F2%2Fwefo.21.issue-2.xml&width=200",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f01.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f02.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f03.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f04.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f05.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f01.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f02.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f03.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f04.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/inline-i1520-0434-21-2-220-f05.gif",
            "https://journals.ametsoc.org/fileasset/footer-logo.png",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-eb4.gif",
            "https://journals.ametsoc.org/view/journals/wefo/21/2/images/i1520-0434-21-2-220-f05.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Richard W. Katz",
            "Martin Ehrendorfer"
        ],
        "publish_date": "2006-04-01T00:00:00",
        "summary": "",
        "meta_description": "Abstract The economic value of ensemble-based weather or climate forecasts is generally assessed by taking the ensembles at “face value.” That is, the forecast probability is estimated as the relative frequency of occurrence of an event among a limited number of ensemble members. Despite the economic value of probability forecasts being based on the concept of decision making under uncertainty, in effect, the decision maker is assumed to ignore the uncertainty in estimating this probability. Nevertheless, many users are certainly aware of the uncertainty inherent in a limited ensemble size. Bayesian prediction is used instead in this paper, incorporating such additional forecast uncertainty into the decision process. The face-value forecast probability estimator would correspond to a Bayesian analysis, with a prior distribution on the actual forecast probability only being appropriate if it were believed that the ensemble prediction system produces perfect forecasts. For the cost–loss decision-making model, the economic value of the face-value estimator can be negative for small ensemble sizes from a prediction system with a level of skill that is not sufficiently high. Further, this economic value has the counterintuitive property of sometimes decreasing as the ensemble size increases. For a more plausible form of prior distribution on the actual forecast probability, which could be viewed as a “recalibration” of face-value forecasts, the Bayesian estimator does not exhibit this unexpected behavior. Moreover, it is established that the effects of ensemble size on the reliability, skill, and economic value have been exaggerated by using the face-value, instead of the Bayesian, estimator.",
        "meta_lang": "en",
        "meta_favicon": "/skin/74df12695855117a235c65909eacf705ab236dfb/favicon.ico",
        "meta_site_name": "AMETSOC",
        "canonical_link": "https://journals.ametsoc.org/view/journals/wefo/21/2/waf913_1.xml",
        "text": "1. Introduction\n\nEnsemble weather forecasting is a promising technique for providing users with beneficial information about forecast uncertainty (Anderson 1996; Ehrendorfer 1997; Sivillo et al. 1997). In previous studies of the economic value of ensemble-based weather forecasts, the ensembles have been generally taken at “face value” (Jolliffe and Stephenson 2003, chapter 8; Richardson 2001; Zhu et al. 2002). That is, the forecast probability is estimated as the relative frequency of occurrence of an event among the ensemble members. In effect, the user of the forecasts is assumed to ignore any uncertainty attributable to the forecast probability being estimated from a limited ensemble size. It should be noted that many users are certainly aware of this source of uncertainty.\n\nSuch face-value forecast probabilities can be quite unreliable for small ensemble sizes, with negative skill scores and negative economic value sometimes even being obtained. In some cases, this issue has been circumvented by assuming that the forecasts were “recalibrated” to be perfectly reliable (Jolliffe and Stephenson 2003, chapter 7; Richardson 2000). These somewhat discouraging results concerning the properties of the face-value forecast probability estimator for small ensemble sizes have been obtained despite commonly only considering a “perfect model” ensemble prediction system (EPS). In other words, an EPS that accurately reflects the uncertainty on a particular forecasting occasion, with perfectly reliable forecast probabilities being produced if an infinite number of ensemble members were available (e.g., Wilks 2002). This assumption of a perfect model EPS will be retained in this paper.\n\nTo assess the economic value of probabilistic weather forecasts, a decision-theoretic concept of the value of imperfect information is used. In practice, the economic value of ensemble-based weather forecasts has been assessed for a prototypical decision-making model known as the cost–loss ratio situation (Katz and Murphy 1997, chapter 6; Palmer 2002). One exception is Wilks and Hamill (1995), in which ensemble weather forecasts were valued for a decision-making model with more complex structure. In this paper, the form of the decision-making model will likewise be limited to the cost–loss ratio situation.\n\nThe decision maker takes into account the uncertainty inherent in imperfect information, such as probabilistic weather forecasts, by adopting some criterion such as maximizing expected return or minimizing expected expense. Here the expectation is taken with respect to the probability distribution for the future weather outcome as specified by the forecast. This approach is based upon the tenets of Bayesian decision theory (Clemen 1996; Winkler 2003). But the principles of Bayesian inference and prediction (e.g., Epstein 1985) provide a natural mechanism to incorporate the additional uncertainty, due to estimating the forecast probability from a limited number of ensemble members, into the decision-making process. It should be noted that Thompson and Zucchini (1990) studied the effect of uncertainty in estimating forecast probabilities on the optimal use and economic value for the cost–loss decision-making model, but not in the context of ensemble prediction and without making use of Bayesian methods.\n\nIn section 2 the Bayesian approach is described, with a comparison being made between Bayesian and face-value forecast probability estimators. The reliability and skill of the face-value and Bayesian estimators are considered in section 3. For the cost–loss decision-making model, expressions for the economic value of these two estimators are presented in section 4. Some specific examples of the relationship between the ensemble size and economic value for these two estimators are treated in more detail in section 5. Finally, section 6 consists of a discussion focusing on the potential implications of this work.\n\n2. Bayesian approach\n\nAttention is focused on a single adverse weather event, denoted by A, which either occurs or does not occur (e.g., “rain” or “no rain” or whether or not the temperature exceeds a high threshold). An EPS produces a set of m ≥ 1 ensemble members for a particular occasion. Suppose that the event A occurs for k out of m ensemble members, 0 ≤ k ≤ m. Let the forecast probability of A occurring on the present occasion be denoted by p, 0 < p < 1 (i.e., the value that would be produced by a perfect model EPS with m = ∞). For clarity, we refer to this quantity p as the “actual” forecast probability.\n\nThe statistical problem at hand is to develop an estimation procedure for this unknown probability. The face-value estimator of p is But this estimator has the undesirable property of assuming the values of zero (i.e., if k = 0) and one (i.e., if k = m), indicative of ignoring the uncertainty because of the ensemble size being finite.\n\nSo some sort of “smoothing” of the ensemble members would be desirable. For instance, Roulston and Smith (2002) introduced the concept of a “fictitious ensemble,” eliminating the possibility of ever obtaining an estimated probability of zero or one. The actual forecast probability p is estimated by (i.e., assigning “half” of the fictitious ensemble to the frequency of occurrence of the event, the other half to nonoccurrence). In practice, there are other reasons why ensemble members need to be smoothed or “postprocessed,” such as correcting for a tendency to be underdispersed (Hamill and Colucci 1997; Wilks 2002).\n\na. Bayesian prediction for a Bernoulli process\n\nThe ensemble members generated by an EPS on a particular occasion can be viewed as a Bernoulli process, that is, a sequence of m random variables, X1, X2, . . . , Xm, with Xi = 1 if the event A occurs (Xi = 0 otherwise) and Pr(Xi = 1) = p, the actual forecast probability. In the Bayesian approach, to facilitate the treatment of uncertainty in inference and prediction, the parameter p is itself treated as a random variable (Epstein 1985, chapter 3; Lindley and Phillips 1976). Because p is random, the Bayesian framework requires the specification of a “prior” distribution on the parameter p (representing the information available about p before receipt of the ensemble members), as well as a likelihood function for the ensemble members conditional on p. Then the prior and likelihood are combined to produce a “posterior” distribution of p conditional on the ensemble members (i.e., a revision of the prior in light of the ensemble members).\n\nLet f (p) denote the prior probability density function for the Bernoulli probability p. Given p, the sequence X1, X2, . . . , Xm constitutes m independent Bernoulli trials. So the likelihood function, denoted by L(x1, x2, . . . , xm | p), for the observations X1 = x1, X2 = x2, . . . , Xm = xm (i.e., xi = 0 or 1, i = 1, 2, . . . , m) is proportional to a binomial probability distribution with parameters m and p. That is, where k = x1 + x2 + · · · + xm is the number of occurrences of the event A out of the m ensemble members (i.e., 0 ≤ k ≤ m). Finally, let g(p | x1, x2, . . . , xm) denote the posterior probability density function for p. It is obtained by combining, through use of Bayes’s theorem (e.g., Winkler 2003), the prior density with the likelihood function; that is,\n\nIt is convenient to assume that the prior for the actual forecast probability p is a beta distribution, say with parameters r0 > 0 and s0 > 0 (see appendix A for the definition and properties of the beta distribution). Then it is straightforward to show that the posterior probability distribution of p is also the beta, but with revised parameters, combining the prior parameters r0 and s0 with the information contained in the ensemble members (i.e., k occurrences of the event in the m ensemble members) (e.g., Epstein 1985, chapter 3).\n\nFor the purpose of forecasting, this posterior probability distribution needs to be converted into the corresponding “predictive” probability distribution for a new observation, Xm+1 say (i.e., thinking of the observed weather as an additional ensemble member, as would be valid for a perfect model EPS). Conditional on the actual forecast probability p, Xm+1 = 1 with probability p, Xm+1 = 0 with probability 1 − p. But p is still unknown, being specified by its posterior distribution. So this uncertainty needs to be integrated out, obtaining a marginal probability for Xm+1.\n\nLet the random variable S = X1 + X2 + · · · + Xm denote the number of occurrences of the event A out of the m ensemble members. Then it is straightforward to show that the predictive probability for Xm+1 given S = k is (e.g., Epstein 1985, chapter 3). This probability (6) is just the mean of the posterior beta distribution for p with parameters specified by (5) [see (A2) in appendix A]. For any prior parameters r0 > 0 and s0 > 0, the predictive probability (6) reflects a smoothing of the face-value estimator (1). In other words, the prior parameters have the interpretation of corresponding to the situation in which r0 + s0 additional ensemble members were available with the event A occurring r0 times.\n\nb. Ensemble-based forecast probability estimators\n\nThe primary motivation for an EPS is that the actual forecast probability p does not remain constant, but rather varies from one occasion to another (e.g., Anderson 1996). Ideally, the prior probability distribution of the decision maker should encompass this variation in forecast uncertainty characteristic of the EPS. In the Bayesian approach, the actual forecast probability is estimated using (6), explicitly taking into account the uncertainty from having only a limited ensemble size available. A Bayesian interpretation can also be attached to other estimators, such as the face-value and fictitious-ensemble types [(1) and (2), respectively], even if they arise in a non-Bayesian context. Figure 1 shows some examples of the beta probability density function used as a prior for the actual forecast probability.\n\n1) Face value\n\nThe face-value forecast probability estimator (1) corresponds to a Bayesian estimator (6), with the prior for the actual forecast probability p being a limiting case of a beta distribution (i.e., r0 = 0, s0 = 0). Technically, this prior does not correspond to a proper probability distribution [i.e., its integral over the interval (0, 1) is infinite], having a “U” shape with infinite modes at zero and one (see Fig. 1). In the context of ensemble forecasting, it would be appropriate for a perfect EPS (i.e., not just a perfect model EPS) that always issues a forecast probability of either zero or one.\n\n2) Fictitious ensemble\n\nThe fictitious-ensemble forecast probability estimator (2) corresponds to a Bayesian estimator (6), with the prior for the actual forecast probability p being a beta distribution with parameters r0 = ½, s0 = ½. Also known as the arc sine distribution, this prior is U shaped with infinite modes at zero and one (see Fig. 1). Assigning higher probabilities to intermediate values of p than in the face-value case, it would be appropriate for an EPS roughly intermediate in skill between that for climatological information and that for perfect information.\n\n3) Uniform prior\n\nThe assumption that all probability values in the interval (0, 1) are equally likely (i.e., a uniform distribution) corresponds to a Bayesian forecast probability estimator (6), with the prior for the actual forecast probability p being a beta distribution with parameters r0 = 1, s0 = 1 (see Fig. 1). In this case, the Bayesian estimator (6) reduces to This prior would be appropriate for an EPS whose skill is somewhere between that for climatological information and the fictitious-ensemble prior.\n\n4) Informative prior\n\nIn practice, it would be desirable to make use of a prior for the actual forecast probability that more closely corresponds to the information available about the EPS [in Bayesian terminology, an “informative” prior; Winkler et al. (2002)]. Depending on the perceived skill level of the EPS, the appropriate form of prior distribution would range between the one corresponding to the face-value estimator and one tightly concentrated about the climatological probability of the adverse weather event, pA = Pr(Xm+1 = 1) say (i.e., a beta distribution with relatively large parameters r and s). In particular, the mean of the prior beta distribution [see (A2) in appendix A] could be constrained to equal pA through the relationship (i.e., pA = ½ corresponds to r0 = s0). Also included in Fig. 1 is an example of an informative prior reflecting an EPS with skill much closer to climatology than to perfect forecasts.\n\nc. Probabilistic model for ensembles\n\nA probabilistic model, consistent with the Bayesian framework just described, can be used to generate ensemble members with appropriate statistical properties. Yet it would remain a natural model, even if the forecast probability were estimated in a non-Bayesian manner. For instance, Richardson (2001) assumed this form of probabilistic model for ensemble members, but still used the face-value estimator (1).\n\nSuppose that a perfect model EPS produces an actual forecast probability according to a beta distribution with parameters r∞ and s∞ (the subscript ∞ is used to reflect the correspondence to m = ∞). The procedure to generate the ensemble members is as follows:\n\n(i) generate an actual forecast probability p from the beta distribution (parameters r∞, s∞);\n\n(ii) generate m independent Bernoulli trials X1, X2, . . . , Xm with probability parameter p, and\n\n(iii) independently of X1, X2, . . . , Xm, generate the actual weather observation as an additional Bernoulli variable, Xm+1 say, with the same probability parameter p.\n\nFor this probabilistic model, the number of ensemble members S for which the event A occurs has a conditional binomial distribution, given the actual forecast probability p from the beta distribution. Unconditionally (i.e., taking into account the variation in this probability from one occasion to another), S has a beta-binomial distribution [(A3) in appendix A with parameters m, r∞, and s∞]. Although the variables X1, X2, . . . , Xm, Xm+1 are generated independently of one another, unconditionally they are dependent (because they are all determined from a common probability parameter for a particular forecast occasion). So the observed weather event Xm+1, as produced by this probabilistic model, would be unconditionally correlated with the ensemble forecasts [see (A5) in appendix A], with the degree of correlation corresponding to the skill of the EPS. We note that the predictive probability (6) is also a special case of a beta-binomial distribution [i.e., n = 1 in (A3) in appendix A].\n\nIn constructing an informative prior for the actual forecast probability, it seems plausible that a well-informed decision maker would have some knowledge about the parameters, r∞ and s∞, of the beta distribution for the EPS. In fact, it will be assumed in most of the subsequent analysis that the decision maker uses as a prior a beta distribution with parameters coinciding with those of the EPS; that is, r0 = r∞ and s0 = s∞. Discussion of the realism of this assumption will be deferred until section 6.\n\n3. Ensemble forecast reliability and skill\n\nThe reliability and skill of these forecast probability estimators can be evaluated through the probabilistic model for ensembles members just introduced. To reflect the situation before the decision maker actually has received the ensemble members, the estimator (6) can be viewed as a random variable [i.e., replacing k with the random variable S in the right-hand side of (6)]: From (9), it is evident that the statistical properties of this estimator are determined by the corresponding properties of S, the number of occurrences of the adverse weather event A out of the m ensemble members, which has a beta-binomial distribution [(A3) in appendix A]. Such an analysis is termed preposterior in Bayesian statistics, and is also necessary to attach economic value to probabilistic forecasts (Clemen 1996; Winkler 2003).\n\na. Reliability\n\nThe reliability of these forecast probability estimators can be determined from the “calibration function,” h(p̂) say, or the conditional probability of the adverse weather event A as a function of p̂: (Jolliffe and Stephenson 2003; Wilks 1995). The “reliability diagram” consists of a plot of h(p̂) versus p̂, with the forecasting system being perfectly reliable if h(p̂) = p̂, for all p̂ (i.e., if all the points in the reliability diagram fall on the line of equality). One consequence of forecasts being perfectly reliable is that they are “unconditionally unbiased” (Jolliffe and Stephenson 2003, p. 30). In particular, a perfect model EPS would necessarily satisfy (8) with r∞ and s∞ in place of r0 and s0, respectively.\n\nThe Bayesian forecast probability estimator assumes the values of the predictive probability (6), k = 0, 1, . . . , m, with the corresponding values of the calibration function being given by the same expression (6) with r∞ and s∞ in place of r0 and s0, respectively. In other words, where This reliability diagram always consists of a straight line, but with a slope of less than one unless r0 = r∞ and s0 = s∞, corresponding to probability forecasts that are “overconfident.”\n\nAs an example, Fig. 2 shows a reliability diagram for the face-value, fictitious-ensemble, and Bayesian (with a uniform prior) forecast probability estimators from an EPS with r∞ = 2 and s∞ = 2 and an ensemble size of m = 10. In this example, the lack of reliability is greatest for the face-value estimator, less for the fictitious-ensemble estimator, and least for a uniform prior. By (11), the line of perfect reliability in Fig. 2 would correspond to the Bayesian estimator with r0 = r∞ = 2 and s0 = s∞ = 2. It should be noted that Richardson (2001) obtained (11) for the special case of the face-value estimator (i.e., r0 = 0 and s0 = 0).\n\nOne measure of the overall reliability of the forecast probability estimator (9), rel(p̂) say, is the mean squared difference between h(p̂) and p̂: In other words, the squared deviations of the reliability diagram from the line of equality are weighted by the relative frequency with which a particular forecast probability estimate is produced. An expression for rel(p̂), as a function of ensemble size m, prior parameters r0 and s0, and EPS parameters r∞ and s∞, is given by (B1) in appendix B. This measure increases as a function of the squared distance of (r0, s0) from (r∞, s∞), with rel(p̂) = 0 for perfectly reliability (i.e., if r0 = r∞ and s0 = s∞). Further, rel(p̂) → 0 as the ensemble size m → ∞.\n\nb. Brier score\n\nOne measure of the accuracy of these forecast probability estimators is the Brier score, bs(p̂) say, or mean-squared error (i.e., comparing the estimate p̂ with the observation Xm+1, a 0–1 variable indicating whether or not the event A occurs): (Jolliffe and Stephenson 2003, chapter 7; Wilks 1995, chapter 7). This scoring rule can be decomposed into three terms, consisting of the reliability measure (12), the variance of the observation Xm+1 [i.e., var(Xm+1) = pA (1 − pA)], and the “resolution” of the forecasts {i.e., var[h(p̂)]} [see Kharin and Zwiers (2003) and (B2) in appendix B].\n\nIt is convenient to rescale (13), obtaining the Brier skill score, bss(p̂) say, ranging from zero for climatology to one for perfect information: Here the Brier score for climatology is var(Xm+1), or the denominator of the second term on the right-hand side of (14). In the case of perfectly reliable forecasts, the Brier skill score is related to the ordinary correlation coefficient between the forecast and the observation by bss(p̂) = [corr(Xm+1, p̂)]2 [see (B3) in appendix B].\n\nFor the actual forecast probabilities produced by a perfect model EPS (i.e., m = ∞ with parameters r∞ and s∞), the Brier skill score can be expressed as a result obtained by Richardson (2001). So the Brier skill score for an EPS with r∞ = 0 and s∞ = 0 (i.e., consistent with the face-value prior) equals one (or the score for perfect information); the score for an EPS with r∞ = ½ and s∞ = ½ (i.e., consistent with the fictitious-ensemble prior) equals ½ (or halfway between the scores for climatological and perfect information); and the score for an EPS with r∞ = 1 and s∞ = 1 (i.e., consistent with a uniform prior) equals ⅓ (or closer to the score for the fictitious-ensemble case than to that for climatology).\n\nFor the face-value forecast probability estimator (1), the Brier skill score is given by a result also obtained by Richardson (2001). This expression (16) makes explicit how the skill of the face-value estimator is reduced relative to the infinite-ensemble case (15), with a negative skill score being obtained for small ensemble size (i.e., if m < r∞ + s∞) because the reliability term dominates in the decomposition of the Brier score [(B2) in appendix B].\n\nAs an example, Fig. 3 shows the Brier skill score for the face-value forecast probability estimator from an EPS with r∞ = 1.5 and s∞ = 1.5 as a function of the ensemble size. In this example, the score (15) for the actual forecast probabilities produced by the EPS equals ¼, or one-quarter of the way from climatological to perfect information. Consistent with (16), the score for the face-value estimator is negative for ensemble sizes m = 1, 2, with its score being nearly as high as that for the EPS if m ≥ 50.\n\nFor the perfectly reliable Bayesian forecast probability estimator [i.e., if r0 = r∞ and s0 = s∞ in (6)], the Brier skill score can be expressed as [the derivation of (17) is outlined in appendix B]. It is likewise evident how this score is reduced from that for the infinite-ensemble case (15), yet it always remains nonnegative and always exceeds the skill score for the face-value estimator (16). Figure 3 also includes the Brier skill score for the Bayesian estimator as a function of the ensemble size m, in this case the excess in skill over the face-value estimator being negligible for m ≥ 20.\n\n4. Economic value of ensemble forecasts\n\nFor the cost–loss decision-making model, one way to measure the economic value of these forecast probability estimators is in terms of the reduction in expected expense incurred by the decision maker. This measure involves a comparison of the expected expense using an estimator with that if climatological information alone were available to the decision maker.\n\na. Cost–loss decision-making model\n\nThe cost–loss ratio situation is a simple form of prototypical decision-making model. In the face of uncertainty about whether the adverse weather event A will occur, the decision maker must decide whether to take protective action. If protective action is taken, then a cost C is incurred. If protective action is not taken but the event does occur, then a loss L is incurred (0 < C < L for protective action to be admissible). The decision maker adopts the criterion of selecting the action (i.e., protect or do not protect) that minimizes the expected expense (in general, equivalent to maximizing expected return or profit).\n\nFor climatological information, the decision maker should protect if pA > C/L. So the expected expense for climatology, denoted by ECLIM, is given by (for convenience, all expense expressions are scaled relative to the loss L) (Katz and Murphy 1987; Katz and Murphy 1997, chapter 6). This expression depends on the two economic parameters, C and L, only through the cost–loss ratio C/L.\n\nb. Forecast value\n\nTo focus on the effect of ensemble size, the economic value of the face-value and Bayesian forecast probability estimators is compared with that for the actual forecast probabilities from a perfect model EPS. Now the decision maker should take protective action whenever the forecast probability estimate p̂ > C/L. An outline of the derivation of the expressions for the expected expense of these estimators is provided in appendix B.\n\n1) Perfect model EPS\n\nFor the actual forecast probabilities from a perfect model EPS (i.e., m = ∞), the expected expense, denoted by EEPS, can be expressed as Here, Fβ() denotes the cumulative distribution function corresponding to the beta probability density function [(A1) in appendix A]. Comparing (19) with (18), the economic value of the actual forecast probabilities is always nonnegative (see appendix B).\n\n2) Face value\n\nFor the face-value forecast probability estimator (1), the expected expense, denoted by EFACE, can be expressed as Here, pk = (r∞ + k)/(r∞ + s∞ + m), fb() denotes the beta-binomial probability function [(A3) in appendix A], and ID() denotes the indicator function of the set D [i.e., ID(x) = 1 if x ∈ D, ID(x) = 0 otherwise]. Comparing (20) with (18), the economic value of the face-value estimator can be negative for small ensemble sizes (as noted in Richardson 2001), and does not necessarily increase as the ensemble size increases (as will be illustrated in section 5).\n\n3) Perfectly reliable Bayesian\n\nFor the perfectly reliable Bayesian forecast probability estimator (9) (i.e., r0 = r∞ and s0 = s∞), the expected expense, denoted by EBAYES, can be expressed as This expression is identical to that for the face-value estimator (20), except that the indicator function is evaluated at pk = (r∞ + k)/(r∞ + s∞ + m) instead of k/m. Comparing (21) with (18), the economic value of the Bayesian estimator is always nonnegative and never decreases as the ensemble size increases (see appendix B).\n\n5. Examples\n\nSome specific examples of the economic value of the face-value and Bayesian forecast probability estimators for the cost–loss decision-making model are now presented. The primary purpose of these examples is to illustrate some counterintuitive features of the face-value estimator, contrasting these features with those for the perfectly reliable Bayesian estimator. To focus on the effect of ensemble size, the economic value of these two estimators is rescaled relative to the economic value of the actual forecast probabilities from a perfect model EPS (so that the relative economic value is unity for m = ∞). That is, the relative economic value of the face-value estimator VFACE, and of the Bayesian estimator VBAYES, are defined as respectively [using (18)–(21)].\n\na. Example 1 (r∞ = 0.75, s∞ = 0.75, C = 0.2, L = 1)\n\nThe first example involves a perfect model EPS with r∞ = 0.75 and s∞ = 0.75 and cost–loss ratio C/L = 0.2. Substituting into (15), the Brier skill score for the actual forecast probabilities from the EPS equals 0.4. By (8), the climatological probability of adverse weather pA = ½ > C/L. So, if only climatological information were available, the decision maker should always take protective action. Figure 4 shows the relative economic value (22) of the face-value and perfectly reliable Bayesian estimators [i.e., if r0 = r∞ = 0.75 and s0 = s∞ = 0.75 in (9)] for ensemble sizes m = 1, 2, . . . , 10. For m = 1, 2, the economic value of the face-value estimator is negative, whereas the Bayesian estimator has no value. For m ≥ 50 (results not included in Fig. 4), the relative economic value of the face-value estimator is quite close to, but smaller than, that of the Bayesian estimator (e.g., 94% versus 95% at m = 50), with both being fairly close to that for the actual forecast probabilities when m ≥ 100 (e.g., both about 97% at m = 100).\n\n1) Ensemble size m = 2\n\nThe perfectly reliable Bayesian forecast probability estimator (6) produces the estimated probabilities p̂ = 3/14, 7/14, and 11/14, for k = 0, 1, and 2, respectively, all greater than C/L, so protection is always optimal. Because the behavior of the decision maker is identical to that for climatological information alone, the Bayesian estimator must have no economic value. However, the face-value estimator (1) produces the estimated probabilities p̂ = 0, ½, and 1, for k = 0, 1, and 2, respectively, so that protective action would not be taken when k = 0. The negative economic value of the face-value estimator is attributable to this departure from the optimal behavior (as determined by the perfectly reliable Bayesian estimator). Richardson (2001) likewise found that the face-value estimator could have negative economic value for small ensemble sizes.\n\nb. Example 2 (r∞ = 0.75, s∞ = 0.75, C = 0.3, L = 1)\n\nThe second example involves the same perfect model EPS, but a different cost–loss ratio C/L = 0.3. If only climatological information were available, the decision maker should always take protective action because again pA > C/L. Figure 5 shows the relative economic value (22) of the face-value and perfectly reliable Bayesian forecast probability estimators for ensemble sizes m = 1, 2, . . . , 10. Unlike example 1, the economic value of the face-value estimator is never negative. However, a decrease in value from ensemble size m = 3 to m = 4 is evident [similarly, in example 1 (Fig. 4) a decrease in economic value occurs from m = 4 to m = 5]. For m ≥ 20 (results not included in Fig. 5), the relative economic value of the face-value estimator is quite close to that of the Bayesian estimator (e.g., 91% versus 92% at m = 20), with both being fairly close to that for the actual forecast probabilities when m ≥ 50 (e.g., both about 97% at m = 50).\n\n1) Ensemble size m = 3\n\nThe perfectly reliable Bayesian forecast probability estimator (6) produces the estimated probabilities p̂ = 3/18, 7/18, 11/18, and 15/18, for k = 0, 1, 2, and 3, respectively, so that protective action should be taken unless k = 0. Similarly, the face-value estimator (1) produces the estimated probabilities p̂ = 0, 1/3, 2/3, and, 1, for k = 0, 1, 2, and 3, respectively, so that protective action should be taken unless k = 0. Because the behavior of the decision maker is identical for both the face-value and Bayesian estimators with m = 3 ensemble members, their economic value must be identical.\n\n2) Ensemble size m = 4\n\nThe perfectly reliable Bayesian forecast probability estimator (6) produces the estimated probabilities p̂ = 3/22, 7/22, 11/22, 15/22, and 19/22, for k = 0, 1, 2, 3, and 4, respectively, so that protective action should be taken unless k = 0. On the other hand, the face-value estimator (1) produces the estimated probabilities p̂ = 0, ¼, ½, ¾, and 1, for k = 0, 1, 2, 3, and 4, respectively, so that protective action would not be taken if k = 0, 1. This departure from the optimal behavior is sufficient to cause the economic value of the face-value estimator to fall not only below that for the Bayesian estimator, but to actually decrease from m = 3 to m = 4.\n\nIt should be noted that Richardson (2001) constructed a generalized skill score, as an overall measure of the economic value of the face-value forecast probability estimator to a group of users (i.e., involving a distribution of cost–loss ratios). For an EPS with a low Brier skill score and for certain forms of user distribution, he found that this measure can decrease with increases in ensemble size. Because we deal with a single decision maker at a time, the reversals in economic value obtained in the present paper are much more abrupt.\n\n6. Discussion\n\nA Bayesian framework for decision making using ensemble forecasts has been introduced. Among other things, this approach provides a rationale for smoothing ensembles to take into account uncertainty in estimating a forecast probability from a limited number of ensemble members. It is also consistent with the fact that many users are aware of the uncertainty inherent in a limited ensemble size. The Bayesian approach has been contrasted with more ad hoc techniques, particularly taking the ensembles at face value (i.e., ignoring any uncertainty in estimating the forecast probability) or simply adding a single fictitious ensemble member. In particular, it has been shown that the economic value of the face-value forecast probability estimator may not only be negative for small ensemble sizes, but may even decrease as the ensemble size increases.\n\nWhat is the explanation for such counterintuitive results? Rather than some heretofore unappreciated feature of the economic value of probability forecasts, we feel that this behavior is indicative of unrealistic assumptions having been made about the behavior of the decision maker. It is implausible that the decision maker would be capable of making decisions under uncertainty about the future weather, yet would be willing to ignore any additional uncertainty arising in estimating the forecast probability.\n\nFor the most part, it has been assumed that the decision maker makes use of a prior distribution for the actual forecast probability identical to the beta distribution of the underlying perfect model EPS. But how realistic is this requirement in practice? It could be argued that it amounts to a recalibration of the face-value estimator. By simultaneously adjusting all the possible forecast probability estimates, the Bayesian approach would be much more efficient than standard recalibration techniques that adjust each probability separately (e.g., Jolliffe and Stephenson 2003, chapter 7). Ideally, it ought to be feasible for a meteorological service to evaluate the performance of its EPS and make estimates of the parameters of this beta distribution readily available to users. If not, sophisticated decision makers could certainly obtain rough estimates of these parameters on their own. For instance, it would be straightforward to obtain them as solutions to their relationships with the climatological probability of adverse weather (8) and with the Brier skill score for the face-value estimator (16).\n\nAll of the results presented concerning the economic value of forecast probability estimators have been predicated upon the EPS being a perfect model (i.e., produces perfectly reliable probabilities if an infinite ensemble size were available). So the question remains of how to deal with the underdispersion typical of an EPS in practice. One option would be the multimodel ensembles approach as advocated by Palmer et al. (2004) and others. Raftery et al. (2005) have applied a Bayesian approach to the problem of calibrating underdispersed ensemble members.\n\nAcknowledgments\n\nResearch was partially supported by NSF Grants DMS-98-15344 and DMS-03-55474 to the NCAR Geophysical Statistics Project. We thank Ian Jolliffe and David Stephenson for comments. The first author thanks the Institute for Meteorology and Geophysics, University of Innsbruck, for support during a sabbatical visit.\n\nREFERENCES\n\nAnderson, J. L., 1996: A method for producing and evaluating probabilistic forecasts from ensemble model integrations. J. Climate, 9 , 1518–1530.\n\nCrossref\n\nAnderson, J. L., 1996: A method for producing and evaluating probabilistic forecasts from ensemble model integrations.J. Climate, 9, 1518–1530.10.1175/1520-0442(1996)009<1518:AMFPAE>2.0.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nClemen, R. T., 1996: Making Hard Decisions: An Introduction to Decision Analysis. .\n\nClemen, R. T., 1996: Making Hard Decisions: An Introduction to Decision Analysis.2d ed. Duxbury, 688 pp.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nEhrendorfer, M., 1997: Predicting the uncertainty of numerical weather forecasts: A review. Meteor. Z., 6 , 147–183.\n\nEhrendorfer, M., 1997: Predicting the uncertainty of numerical weather forecasts: A review.Meteor. Z., 6, 147–183.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nEhrendorfer, M., and MurphyA. H. , 1988: Comparative evaluation of weather forecasting systems: Sufficiency, quality, and accuracy. Mon. Wea. Rev., 116 , 1757–1770.\n\nCrossref\n\nEhrendorfer, M., and MurphyA. H. , 1988: Comparative evaluation of weather forecasting systems: Sufficiency, quality, and accuracy.Mon. Wea. Rev., 116, 1757–1770.10.1175/1520-0493(1988)116<1757:CEOWFS>2.0.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nEpstein, E. S., 1985: .\n\nCrossref\n\nEpstein, E. S., 1985: Statistical Inference and Prediction in Climatology: A Bayesian Approach Meteor. Monogr., No. 42, Amer. Meteor. Soc., 199 pp.10.1007/978-1-935704-27-0)| false\n\nExport Citation\n\nHamill, T. M., and ColucciS. J. , 1997: Verification of Eta–RSM short-range ensemble forecasts. Mon. Wea. Rev., 125 , 1312–1327.\n\nCrossref\n\nHamill, T. M., and ColucciS. J. , 1997: Verification of Eta–RSM short-range ensemble forecasts.Mon. Wea. Rev., 125, 1312–1327.10.1175/1520-0493(1997)125<1312:VOERSR>2.0.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nJolliffe, I. T., and StephensonD. B. , 2003: Forecast Verification: A Practitioner’s Guide in Atmospheric Science. .\n\nJolliffe, I. T., and StephensonD. B. , 2003: Forecast Verification: A Practitioner’s Guide in Atmospheric Science.John Wiley, 240 pp.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nKatz, R. W., and MurphyA. H. , 1987: Quality/value relationship for imperfect information in the umbrella problem. Amer. Stat., 41 , 187–189.\n\nKatz, R. W., and MurphyA. H. , 1987: Quality/value relationship for imperfect information in the umbrella problem.Amer. Stat., 41, 187–189.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nKatz, R. W., and MurphyA. H. , 1997: Economic Value of Weather and Climate Forecasts. .\n\nKatz, R. W., and MurphyA. H. , 1997: Economic Value of Weather and Climate Forecasts.Cambridge University Press, 222 pp.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nKharin, V. V., and ZwiersF. W. , 2003: Improved seasonal probability forecasts. J. Climate, 16 , 1684–1701.\n\nCrossref\n\nKharin, V. V., and ZwiersF. W. , 2003: Improved seasonal probability forecasts.J. Climate, 16, 1684–1701.10.1175/1520-0442(2003)016<1684:ISPF>2.0.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nKrzysztofowicz, R., and LongD. , 1991: Forecast sufficiency characteristic: Construction and application. Int. J. Forecasting, 7 , 39–45.\n\nCrossref\n\nKrzysztofowicz, R., and LongD. , 1991: Forecast sufficiency characteristic: Construction and application.Int. J. Forecasting, 7, 39–45.10.1016/0169-2070(91)90031-P)| false\n\nSearch Google Scholar\n\nExport Citation\n\nLindley, D. V., and PhillipsL. D. , 1976: Inference for a Bernoulli process (a Bayesian view). Amer. Stat., 30 , 112–119.\n\nLindley, D. V., and PhillipsL. D. , 1976: Inference for a Bernoulli process (a Bayesian view).Amer. Stat., 30, 112–119.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nPalmer, T. N., 2002: The economic value of ensemble forecasts as a tool for risk assessment: From days to decades. Quart. J. Roy. Meteor. Soc., 128 , 747–774.\n\nCrossref\n\nPalmer, T. N., 2002: The economic value of ensemble forecasts as a tool for risk assessment: From days to decades.Quart. J. Roy. Meteor. Soc., 128, 747–774.10.1256/0035900021643593)| false\n\nSearch Google Scholar\n\nExport Citation\n\nPalmer, T. N., and Coauthors, 2004: Development of a European Multimodel Ensemble System for Seasonal to Interannual Prediction (DEMETER). Bull. Amer. Meteor. Soc., 85 , 853–872.\n\nCrossref\n\nPalmer, T. N., and Coauthors, 2004: Development of a European Multimodel Ensemble System for Seasonal to Interannual Prediction (DEMETER).Bull. Amer. Meteor. Soc., 85, 853–872.10.1175/BAMS-85-6-853)| false\n\nSearch Google Scholar\n\nExport Citation\n\nRaftery, A. E., GneitingT. , BalabdaouiF. , and PolakowskiM. , 2005: Using Bayesian model averaging to calibrate forecast ensembles. Mon. Wea. Rev., 133 , 1155–1174.\n\nCrossref\n\nRaftery, A. E., GneitingT. , BalabdaouiF. , and PolakowskiM. , 2005: Using Bayesian model averaging to calibrate forecast ensembles.Mon. Wea. Rev., 133, 1155–1174.10.1175/MWR2906.1)| false\n\nSearch Google Scholar\n\nExport Citation\n\nRichardson, D. S., 2000: Skill and relative economic value of the ECMWF Ensemble Prediction System. Quart. J. Roy. Meteor. Soc., 126 , 649–667.\n\nCrossref\n\nRichardson, D. S., 2000: Skill and relative economic value of the ECMWF Ensemble Prediction System.Quart. J. Roy. Meteor. Soc., 126, 649–667.10.1002/qj.49712656313)| false\n\nSearch Google Scholar\n\nExport Citation\n\nRichardson, D. S., 2001: Measures of skill and value of ensemble prediction systems, their interrelationship and the effect of ensemble size. Quart. J. Roy. Meteor. Soc., 127 , 2473–2489.\n\nCrossref\n\nRichardson, D. S., 2001: Measures of skill and value of ensemble prediction systems, their interrelationship and the effect of ensemble size.Quart. J. Roy. Meteor. Soc., 127, 2473–2489.10.1002/qj.49712757715)| false\n\nSearch Google Scholar\n\nExport Citation\n\nRoulston, M. S., and SmithL. A. , 2002: Evaluating probabilistic forecasts using information theory. Mon. Wea. Rev., 130 , 1653–1660.\n\nCrossref\n\nRoulston, M. S., and SmithL. A. , 2002: Evaluating probabilistic forecasts using information theory.Mon. Wea. Rev., 130, 1653–1660.10.1175/1520-0493(2002)130<1653:EPFUIT>2.0.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nSivillo, J. K., AhlquistJ. E. , and TothZ. , 1997: An ensemble forecasting primer. Wea. Forecasting, 12 , 809–818.\n\nCrossref\n\nSivillo, J. K., AhlquistJ. E. , and TothZ. , 1997: An ensemble forecasting primer.Wea. Forecasting, 12, 809–818.10.1175/1520-0434(1997)012<0809:AEFP>2.0.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nThompson, M. L., and ZucchiniW. , 1990: Assessing the value of probability forecasts. Mon. Wea. Rev., 118 , 2696–2706.\n\nCrossref\n\nThompson, M. L., and ZucchiniW. , 1990: Assessing the value of probability forecasts.Mon. Wea. Rev., 118, 2696–2706.10.1175/1520-0493(1990)118<2696:ATVOPF>2.0.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nvan Tiel, J., 1984: Convex Analysis: An Introductory Text. .\n\nvan Tiel, J., 1984: Convex Analysis: An Introductory Text.John Wiley, 125 pp.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nWilks, D. S., 1995: Statistical Methods in the Atmospheric Sciences. .\n\nWilks, D. S., 1995: Statistical Methods in the Atmospheric Sciences.Academic Press, 464 pp.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nWilks, D. S., 2002: Smoothing forecast ensembles with fitted probability distributions. Quart. J. Roy. Meteor. Soc., 128 , 2821–2836.\n\nCrossref\n\nWilks, D. S., 2002: Smoothing forecast ensembles with fitted probability distributions.Quart. J. Roy. Meteor. Soc., 128, 2821–2836.10.1256/qj.01.215)| false\n\nSearch Google Scholar\n\nExport Citation\n\nWilks, D. S., and HamillT. M. , 1995: Potential economic value of ensemble-based surface weather forecasts. Mon. Wea. Rev., 123 , 3565–3575.\n\nCrossref\n\nWilks, D. S., and HamillT. M. , 1995: Potential economic value of ensemble-based surface weather forecasts.Mon. Wea. Rev., 123, 3565–3575.10.1175/1520-0493(1995)123<3565:PEVOEB>2.0.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nWinkler, R. L., 2003: Introduction to Bayesian Inference and Decision. .\n\nWinkler, R. L., 2003: Introduction to Bayesian Inference and Decision.2d ed. Probabilistic Publishing, 452 pp.)| false\n\nSearch Google Scholar\n\nExport Citation\n\nWinkler, R. L., SmithJ. E. , and FrybackD. G. , 2002: The role of informative priors in zero-numerator problems: Being conservative versus being candid. Amer. Stat., 56 , 1–4.\n\nCrossref\n\nWinkler, R. L., SmithJ. E. , and FrybackD. G. , 2002: The role of informative priors in zero-numerator problems: Being conservative versus being candid.Amer. Stat., 56, 1–4.10.1198/000313002753631295)| false\n\nSearch Google Scholar\n\nExport Citation\n\nZhu, Y., TothZ. , WobusR. , RichardsonD. , and MylneK. , 2002: The economic value of ensemble-based weather forecasts. Bull. Amer. Meteor. Soc., 83 , 73–83.\n\nCrossref\n\nZhu, Y., TothZ. , WobusR. , RichardsonD. , and MylneK. , 2002: The economic value of ensemble-based weather forecasts.Bull. Amer. Meteor. Soc., 83, 73–83.10.1175/1520-0477(2002)083<0073:TEVOEB>2.3.CO;2)| false\n\nSearch Google Scholar\n\nExport Citation\n\nAPPENDIX A\n\nDefinition and Properties of Beta and Beta-Binomial Distributions\n\nBeta distribution\n\nThe beta distribution, with parameters r and s, has the following probability density function: where the beta function B(r, s) = [Γ(r) Γ(s)]/Γ(r + s) and Γ() denotes the gamma function (Epstein 1985, appendix A; Wilks 1995, chapter 4). The mean and variance of a beta distribution are given by For r > 1 and s > 1, it has a unique mode at (r − 1)/(r + s − 2) (otherwise, it has infinite modes at zero and/or one).\n\nBeta-binomial distribution\n\nThe beta-binomial distribution, with parameters n a positive integer and r, s > 0, is given by where the binomial coefficient Cn,k = n!/[k!/(n − k)!] (e.g., Epstein 1985, chapter 3 and appendix A). The mean and variance of the beta-binomial distribution can be expressed in terms of the corresponding mean and variance of the beta distribution (A2) as\n\nThe beta-binomial distribution (A4) arises for the number of occurrences S in a sequence of n Bernoulli variables, X1, X2, . . . , Xn say, where the probability of occurrence varies according to a beta distribution (A1). Although the Xi are conditionally independent given the probability of occurrence, they are unconditionally dependent with\n\nAPPENDIX B\n\nReliability, Skill, and Expected Expense of Ensemble Forecasts\n\nReliability\n\nThe reliability measure (12) for the Bayesian forecast probability estimator (9) can be expressed in terms of the variance of the beta-binomial distribution (A4) as Richardson (2001) obtained (B1) in the special case of face-value forecasts (i.e., r0 = 0, s0 = 0).\n\nBrier skill score\n\nThe Brier score (13) for the Bayesian forecast probability estimator (9) can be decomposed as (e.g., Kharin and Zwiers 2003) where the first term is the “uncertainty” or variance of the observed weather variable Xm+1, the second term is the reliability measure (B1), and the third term is a measure of the resolution of the forecasts.\n\nThe expression (17) for the Brier skill score of the perfectly reliable Bayesian forecast probability estimator can be derived as follows. Because of perfect reliability, the decomposition (B2) reduces to only two terms. In this case, the Brier skill score can be decomposed as where var(p̂) = [m/(r∞ + s∞ + m)] var(p). Here, var(p) denotes the variance of a beta distribution with parameters r∞ and s∞ [see expression in (A2)]. The relationship between var(p̂) and var(p) follows from p̂ being a linear transformation (9) of S, with an expression for var(S) being given in (A4).\n\nExpected expense\n\nConditional on an estimated forecast probability p̂, the expected expense is given by min{C, p̂ L}, consistent with the result for climatological information (18). So, unconditionally, this expected expense can be expressed as\n\nFor actual forecast probabilities from a perfect model EPS, (19) is obtained by replacing p̂ with p in (B4) and using the properties of the beta distribution (with parameters r∞ and s∞) for p. Comparing the left-hand side of (B4) with (18), because min(C, pL) is a concave function of p and because E(p) = pA, Jensen’s inequality (e.g., van Tiel 1984, chapter 1) implies that the economic value of the actual forecast probabilities (i.e., ECLIM − EEPS) must be nonnegative.\n\nFor the face-value forecast probability estimator [i.e., (9) with r0 = 0, s0 = 0)], (20) is obtained from (B4) by using the fact that S has a beta-binomial distribution (A3). Similarly, for the perfectly reliable Bayesian estimator [i.e., (9) with r0 = r∞, s0 = s∞], (21) is obtained from (B4) by using p̂ = (r∞ + k)/(r∞ + s∞ + m) instead of p̂ = k/m. Essentially the same reasoning as above for the actual forecast probabilities implies that the economic value of the Bayesian estimator must be nonnegative. The sufficiency relation (Ehrendorfer and Murphy 1988; Krzysztofowicz and Long 1991) implies that this economic value must be a nondecreasing function of the ensemble size."
    }
}