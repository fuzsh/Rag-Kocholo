{
    "id": "correct_spouse_00132_1",
    "rank": 23,
    "data": {
        "url": "https://www.edge.org/responses/what-will-change-everything",
        "read_more_link": "",
        "language": "en",
        "title": "Edge.org",
        "top_image": "https://www.edge.org/sites/default/files/annualimage/bookimage/Unknowns_cover500_0.jpg",
        "meta_img": "",
        "images": [
            "https://www.edge.org/sites/default/files/edge_logo.jpg",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_193_pz_myers.jpg?itok=We4mXKEC",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_489_dean__ornish.jpg?itok=SQvnBFJx",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_366_joseph_traub.jpg?itok=Ar0E0Ze2",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-577-1422400465.jpg?itok=Auf1jNeD",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_45_richard_dawkins.jpg?itok=S99nq3O6",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-381-1387379389.jpg?itok=WFTncHom",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-143-1491501783.jpg?itok=BT4W9a_a",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_62_paul_w_ewald.jpg?itok=4-Y9VFgA",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_212_bruce_parker.jpg?itok=K0nTBW-p",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_412_henry_warwick.jpg?itok=c-pUhnGJ",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_568_corey_s__powell.jpg?itok=jd43Nwl-",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-573-1435588393.png?itok=-rwy_Wsi",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-105-1462301801.png?itok=Tv62RppI",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_559_david_bodanis.jpg?itok=Lmru3mWa",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_572_philippe_parreno.jpg?itok=obAYN3Up",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-100-1616512543.jpg?itok=DwskmEsc",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_565_bart_kosko.jpg?itok=u6NuC4w9",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_19_jamshed_bharucha.jpg?itok=bFJTh2pL",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_394_david_berreby.jpg?itok=fFfzlXNa",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-481-1494260839.jpg?itok=1NZv0y8C",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_217_antony_garrett_lisi.jpg?itok=FlDZlSn5",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_574_betsy_devine.jpg?itok=ugdOyRRN",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-57-1516219856.jpg?itok=-hWwEYN7",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-64-1450130666.jpg?itok=bCgVPXeN",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_454_alexander_vilenkin.jpg?itok=cuFgaky0",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_119_gloria_origgi.jpg?itok=siQp5OK9",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_337_verena_huber_dyson.jpg?itok=yWYZkY4A",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_141_scott_sampson.jpg?itok=pa5oY4sZ",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-11-1435076671.png?itok=ep9w4or3",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_131_lisa_randall.jpg?itok=bSVghT95",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_164_john_tooby.jpg?itok=4YITiaI4",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_140_paul_saffo.jpg?itok=C9D1-6-E",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-48-1360100722.jpg?itok=32hlN8vl",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_512_eric_r_kandel.jpg?itok=KD1dlK06",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_166_sherry_turkle.jpg?itok=MALvjoy7",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_202_j_craig_venter.jpeg?itok=0pSNtleZ",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_550_dominique_gonzalez-foerster.jpg?itok=fEV1NwtQ",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-169-1456851431.jpg?itok=pYETiIok",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_148_robert_shapiro.gif?itok=8HLewrEh",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_554_austin_dacey.jpg?itok=0QIwcre0",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_83_sam_harris.jpg?itok=I1aN4Ocn",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_159_nassim_nicholas_taleb.JPG?itok=KKS_spzl",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_23_stefano_boeri.jpg?itok=FIOJbTHF",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-28-1517503882.jpg?itok=XzUHWn7f",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_145_peter_schwartz.jpg?itok=kWO2_DVz",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_99_kai_krause.jpg?itok=cUgvz5GO",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_170_ian_wilmut.gif?itok=dOVH8dFa",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-116-1402067929.jpg?itok=Ls5B7wWP",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-519-1661887052.jpg?itok=GzqHO3WD",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_224_oliver_morton.jpg?itok=AkO78phT",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_59_brian_eno.gif?itok=uPe8iPul",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-88-1440448631.png?itok=PaBeUBzt",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-438-1518646717.jpg?itok=ef95-fZZ",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_104_seth_lloyd.jpg?itok=Ez9mCI2b",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_482_marco_iacoboni.jpg?itok=-tx_vgoI",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_65_eric_fischl.jpg?itok=v8EdOBpc",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_53_k_eric_drexler.jpg?itok=z9AV13oQ",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-153-1372370496.jpg?itok=BKk5dW54",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_97_terence_koh.jpg?itok=2pEbdwMC",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-35-1435265979.png?itok=iKRByP7o",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_86_marti_hearst.jpg?itok=UKam1I_l",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_532_marcel_kinsbourne.jpg?itok=aiRSrr8Y",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-72-1422300249.jpg?itok=BhEX9N_B",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_79_april_gornik.jpg?itok=6a3jbiZh",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_42_mihalyi_csikszentmihalyi.jpg?itok=ZvD0PS1j",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_173_anton_zeilinger.jpg?itok=Ku7QbXfn",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_461_joel_garreau.jpg?itok=4RLgvUc5",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_194_dimitar_d_sasselov.jpg?itok=lE1KeeFE",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_16_yochai_benkler.jpg?itok=SbGi6QP8",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_430_rupert__sheldrake.jpg?itok=mwx5sIET",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_267_paul_davies.jpg?itok=q1ieruxV",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_229_roger_highfield.jpg?itok=6WNTDLDr",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-26-1410826638.jpg?itok=Bpctc5ws",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_7_alun_anderson.jpg?itok=B3ROWZv_",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-114-1457448738.jpg?itok=PSCn84BE",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_347_patrick_bateson.jpg?itok=nW42LEE1",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_420_martin_seligman.jpg?itok=MZPPEodO",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_71_david_gelernter.jpg?itok=aqzdBqs4",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_134_howard_rheingold.jpg?itok=169GKhju",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-161-1509030663.jpg?itok=hDlvCsm4",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_782_monica_narula.jpg?itok=05VLpAjO",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-96-1517511541.jpg?itok=iHmi4RbM",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_98_stephen_m_kosslyn.jpeg?itok=HjXtRQfl",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-253-1384456015.jpg?itok=wqghRw2F",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-44-1402073870.jpg?itok=Y7TeGzE2",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_78_alison_gopnik.jpg?itok=iD2TSTY3",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_524_kenneth_w_ford.jpg?itok=M_aS7bGX",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_123_irene_pepperberg.jpg?itok=Qj9siWmJ",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_50_keith_devlin.jpg?itok=ZDVmS0WU",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_215_john_d_barrow.gif?itok=M4UlqwVy",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-533-1482781051.jpg?itok=TFhP4t_7",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_81_haim_harari.jpg?itok=mGI9HXom",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-162-1435871030.png?itok=k2hLu_NJ",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-307-1488469700.jpg?itok=ENA-9pVn",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-149-1450743743.jpg?itok=s9cOrxTL",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_146_charles_seife.jpeg?itok=u6N1tWuR",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-385-1372370396.jpg?itok=FFgZxeiE",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-147-1450800406.png?itok=mVVNLO7-",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_305_stephen_schneider.jpg?itok=YUl5Q6zY",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_61_daniel_l_everett.jpg?itok=kMud1Dzc",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_203_gino_segre.jpg?itok=1p9EAOQg",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_121_mark_pagel.jpg?itok=QjsBd4Xm",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-66-1484250338.jpg?itok=siX21jow",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_46_aubrey_de_grey.jpg?itok=SjaWo3Qd",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-110-1482586516.jpg?itok=6m9uViKt",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_760_steven_pinker.jpeg?itok=aJsGytnX",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_356_brian_goodwin.jpg?itok=d0PJj4C0",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-24-1361384196.jpg?itok=3URDIsns",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-89-1579706298.jpg?itok=z0Ay5_HR",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_18_jesse_bering.jpg?itok=V7Ujwnbq",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_178_lewis_wolpert.jpg?itok=eGptZjYL",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-474-1517516604.jpg?itok=rVXFzWv_",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_707_tor.jpg?itok=1AoQ1GnU",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-117-1516222249.jpg?itok=YUNict0_",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_68_richard_foreman.jpg?itok=TLUazIzz",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-281-1434559831.png?itok=uny14ylM",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_469_jonathan_haidt.jpg?itok=9PnCLhkN",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_49_emanuel_derman.jpg?itok=Om8_RZX4",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-409-1517502960.jpg?itok=uCGfuxum",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_124_clifford_pickover.jpg?itok=lXnyuoBj",
            "https://www.edge.org/q2009/images/pickover_equation.gif",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-128-1515600607.jpg?itok=MgYmTagG",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-37-1357520053.jpg?itok=f_QJr8c1",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_538_gregory_cochran.jpg?itok=cj13vtHD",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_530_steve_nadis.jpg?itok=yxnxHpW2",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_210_nicholas_humphrey.jpg?itok=Hpz5VCSD",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_6_alan_alda.jpg?itok=s3Fx0vYw",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-34-1516738719.png?itok=ULAq86uu",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_151_barry_c_smith.gif?itok=ju0o8XxK",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-191-1584376381.jpg?itok=J_Pj9zSx",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_396_gerald_holton.jpg?itok=DDN2RsCa",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-152-1572032429.jpg?itok=k9lIs4Xt",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_17_susan_blackmore.jpg?itok=rFvzjqEG",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_138_douglas_rushkoff.jpg?itok=cYUlYgKj",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_122_gregory_paul.jpg?itok=QvoW2dGA",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-60-1515601734.jpg?itok=G-EFSjMD",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_56_george_dyson.jpg?itok=cDpUo_OW",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_144_roger_schank.jpg?itok=X0_iyv9a",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_349_stuart_a_kauffman.jpg?itok=zGPXkxZ0",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-139-1559856569.jpg?itok=7IYGdF2D",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_94_kevin_kelly.jpg?itok=Fkvz_nZb",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-27-1563309314.png?itok=B_DJYnT9",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-70-1515600888.jpg?itok=LliUWcBA",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_473_marcelo_gleiser.jpg?itok=o8jp5Dc8",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-160-1421438510.jpg?itok=tzF7QBHO",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/picture-25-1418870049.jpg?itok=tliYMjnl",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_440_john_gottman.jpg?itok=kdm7KFTu",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_30_william_h_calvin.jpg?itok=wdkjkGGt",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_133_ed_regis.jpg?itok=XtJs3cyT",
            "https://www.edge.org/sites/default/files/styles/mini-thumbnail/public/member-pictures/bk_8_chris_anderson.jpg?itok=v9unEya8",
            "https://www.edge.org/sites/all/modules/service_links/images/printmail.png",
            "https://www.edge.org/sites/all/modules/service_links/images/print.png",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/Unknowns_cover500_0.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/Brilliant_cover_0.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/y648.png",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/Machines_Cover.png",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/This%20Idea%20Must%20ies%20pb%20c.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/51r44cx05sL._SL160_.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/556_ThisExplainsEverything_1.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/751_twmys300_3.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/903_internetcov150_1.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/201_ThisWillChangeEverything150_1.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/309_9780061686542_1.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/605_Cover_Optimism_US_3.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/113_Cover_Dangerous_US_3.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/978_Cover_Believe_US_3.jpg",
            "https://www.edge.org/sites/default/files/annualimage/bookimage/greatestinventions.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "https://www.edge.org/favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Cheap individual genotyping will give a new life to dating services and marriage arrangers. There is a market for sperm and egg donors today, but the information available to consumers about donors is limited. This industry will flourish as individual genotyping costs go down and knowledge of genomics grows.\n\nPotential consumers will be able to evaluate not only whether or not a gamete provider has brown eyes, is tall or short, has a professional degree, but also whether the donor has the appropriate MHC genotypes, long or short androgen receptors, the desired dopamine receptor types, and so on. The list of criteria and the sophistication of algorithms matching consumers and donors will grow at an increasing rate in the next decade.\n\nThe idea of a \"compatible couple\" will have a whole new dimension. Consumers will have information about hundreds of relevant donor genetic polymorphisms to evaluate in the case of gamete markets. In marriage markets there will be evaluation by both parties. Where will all this lead? Three possibilities come immediately to mind:\n\nA. Imagine that Sally is looking at the sperm donor market. Perhaps she is shopping for someone genetically compatible, for example with the right MHC types. She is a homozygote for the 7R allele of the DRD4 genetic locus so she is seeking a sperm donor homozygous for the 4R allele so she won't have to put up with a 7R homozygous child like she was. In other words whether Tom or Dick is a more desirable donor depends on characteristics specific to Sally.\n\nB. But what if Sally values something like intelligence, which is almost completely unidimensional and of invariant polarity: nearly everyone values high intelligence. In this case Sally will evaluate Tom and Dick on simple scales that Sally shares with most other women, Tom will almost always be of higher value than Dick, and he will be able to obtain a higher price for his sperm.\n\nC. Perhaps a new President has red-haired children. Suddenly Sally, along with most other women in the market, wants red-haired children because they are fashionable. Dick, with his red hair, is the sellout star of the sperm market but only for a short time. There is a cohort of children born with red hair, then the fad soon goes away as green eyes, say, become the new hot seller. Dick loses his status in the market and is forced to get a real job.\n\nThese three scenarios or any mix of them is a possible future for love and marriage among those prosperous enough to indulge in this market. Scenario A corresponds to traditional views of marriage: for everyone there is someone special and unique. Scenario B corresponds somewhat more closely to how marriage markets really work-every Sally prefers rich to poor, smart to dumb, and a BMW to a Yugo. Scenario C is close to one mechanism of what biologists call sexual selection: male mallards have green heads essentially because it is just the fashion. I would not wager much on which of these scenarios will dominate the coming gamete market but I favor scenario B.\n\nThe question, \"what will change everything?\" is in the wrong tense: it should be \"what is changing everything right now?\" We're in the midst of an ongoing revision of our understanding of what it means to be human—we are struggling to redefine humanity, and it's going to radically influence our future.\n\nThe redefinition began in the 19th century with the work of Charles Darwin, who changed the game by revealing the truth of human history. We are not the progeny of gods, we are the children of worms; not the product of divine planning, but of cruel chance and ages of brutal winnowing. That required a shift in the way we view ourselves that is still working its way through the culture. Creationism is an instance of a reaction against the dethroning of Homo sapiens. Embracing the perspective of evolution, however, allows us to see the value of other species and to appreciate our place in the system as a whole, and is a positive advance.\n\nThere are at least two more revolutions in the works. The first is in developmental biology: we're learning how to reprogram human tissues, enabling new possibilities in repair and regeneration. We are acquiring the tools that will make the human form more plastic, and it won't just stop with restoring damaged bodies to a prior state, but will someday allow us to resculpt ourselves, add new features and properties to our biology, and maybe, someday, even free us completely from the boundaries of the fixed form of a bipedal primate. Even now with our limited abilities, we have to rethink what it means to be human. Does a blastocyst really fit the definition? How about a 5-week embryo, or a three-month-old fetus?\n\nThe second big revelation is coming from neuroscience. Mind is clearly a product of the brain, and the old notions of souls and spirits are looking increasingly ludicrous…yet these are nearly universal ideas, all tangled up in people's rationalizations for an afterlife, for ultimate reward and punishment, and their concept of self. If many object to the lack of exceptionalism in our history, if they're resistant to the idea that human identity emerges gradually during development, they're most definitely going to find the idea of soullessness and mind as a byproduct of nervous activity horrifying.\n\nThis will be our coming challenge, to accommodate a new view of ourselves and our place in the universe that isn't encumbered with falsehoods and trivializing myths. That's going to be our biggest change—a change in who we are.\n\nIn just a few years, we’ll see the first generation of adults whose every breath has been drawn on the grid. A generation for whom every key moment (e.g., birth) has been documented and distributed globally. Not just the key moments, of course, but also the most banal: eating pasta, missing the train, and having a bad day at the office. Ski trips and puppies.\n\nThese trips and puppies are not simply happening, they are becoming data, building up the global database of distributed memories. They are networked digital photos – 3 billion on Flickr, 10 billion on Facebook. They were blog posts, and now they are tweets, too (a billion in 18 months). They are Facebook posts, Dopplr journals, Last.FM updates.\n\nFurther, more and more of these traces we produce will be passive or semi-passive. Consider Loopt, which allows us to track ourselves, our friends through GPS. Consider voicemail transcription bots that transcribe the voice messages we leave into searchable text in email boxes on into eternity. The next song you listen to will likely be stored in a database record somewhere. Next time you take a phonecam photo, it may well have the event’s latitude and longitude baked into the photo’s metadata.\n\nThe sharp upswing in all of this record-keeping – both active and passive – are redefining one of the core elements of what it means to be human, namely to remember. We are moving towards a culture that has outsourced this essential quality of existence to machines, to a vast and distributed prosthesis. This infrastructure exists right now, but very soon we’ll be living with the first adult generation whose entire lives are embedded in it.\n\nIn 1992, the artist Thomas Bayrle wrote that the great mistakes of the future would be that as everything became digital, we would confusememory with storage. What’s important about genuine memory and how it differs from digital storage is that human memory is imperfect, fallible, and malleable. It disappears over time in a rehearsal and echo of mortality; our abilities to remember, distort and forget are what make us who we are.\n\nWe have built the infrastructure that makes it impossible to forget. As it hardens and seeps into every element of daily life, it will make it impossible to remember. Changing what it means to remember changes what it means to be.\n\nThere are a few people with who already have perfect episodic memory, total recall, neurological edge cases. They are harbingers of the culture to come. One of them, Jill Price, was profiled in Der Spiegel:\n\n\"In addition to good memories, every angry word, every mistake, every disappointment, every shock and every moment of pain goes unforgotten. Time heals no wounds for Price. 'I don't look back at the past with any distance. It's more like experiencing everything over and over again, and those memories trigger exactly the same emotions in me. It's like an endless, chaotic film that can completely overpower me. And there's no stop button.'\"\n\nThis also describes the life of Steve Mann, passively recording his life through wearable computers for many years. This is an unlikely future scenario, but like any caricature, it is based on human features that will be increasingly recognizable. The processing, recording and broadcasting prefigured in Mann’s work will be embedded in everyday actions like the twittering, phonecam shots and GPS traces we broadcast now. All of them entering into an outboard memory that is accessible (and searchable) everywhere we go.\n\nToday is New Year’s Eve. I read today (on Twitter) that three friends, independent of each other, were looking back at Flickr to recall what they were doing a year ago. I would like to start the New Year being able to remember 2008, but also to forget it.\n\nFor the next generation, it will be impossible to forget it, and harder to remember. What will change everything is our ability to remember what everything is. Was. And wasn’t.\n\nFrom the Neolithic revolution to the information age, the major changes in the human condition—none of them changing everything, needless to say—have been consequences of new technologies. There is now a glut of new technologies in the offing that will alter the way we live more rapidly and radically than anything before in ways we cannot properly foresee. I wish I could just wax lyrical about some of the developments we can at least sensibly speculate about, but others will do so more competently. So, let me focus on the painfully obvious that we would rather not think about.\n\nMany new technologies can provide new weapons or new ways to use old ones. Access to these technologies is every day easier. In the near future we should expect, with near certainty, that atomic, chemical, and biological weapons of mass destruction will be used in a variety of conflicts. The most important change this will bring about is not that so many will die. Hundreds of thousands have died all these years in wars and natural catastrophes, with an unspeakable impact on the population affected, but, alas, massacres and other forms of collective death have been part and parcel of the human condition. This time, however, many of the victims will belong to powerful modern societies that, since the Second World War, have on the whole been spared. People in these societies are, neither less nor more than the usual poorer and powerless victims of massive violence, entitled to live full decent lives, and have a right to fight for this. What may bring about radical changes is that they will be in a much stronger position to exert and possibly abuse this right. Recent large-scale murderous attacks resulted in the acceptance of fewer checks on executive power, limitation of civil rights, preventive warfare, ethnically targeted public suspicion. In the future, people who will have witnessed even direr events at close quarters may well support even more drastic measures. I am not discussing here the rationality of fears to come, or the extent to which they are likely to be biased and manipulated. I just assume that, for good or bad reasons, they will weigh in favor of limitations to the liberties of individuals and to the independence of countries.\n\nOne must hope that, in part thanks to the changes brought about by novel technologies, new forms of social and political understanding and action will develop to help address at the root issues that otherwise might give rise to ever more lethal conflicts. Still, while more and more powerful technologies are becoming more and more accessible, there is no reason to believe that humans are becoming commensurately wiser and more respectful of one another's rights. There will be, then, at least in most people's perception, a direct clash between their safety and their liberty and even more between their safety and the liberty of others. The history of this century—our history, that of our children and grandchildren—will in good part be that of the ways in which this clash is played out, or overcome.\n\nWe humans are pretty impressive when it comes to being able to extract information, to discern patterns from lots of little itsy bitsy data points. Take a musician sitting down with a set of instructions on a piece of paper — sheet music — and being able to turn it into patterned sound. And one step further is the very well-trained musician who can sit and read through printed music, even an entire orchestral score, and hear it in his head, and even feel swept up in emotion at various points in the reading. Even more remarkable is the judge in a composition competition, reading through a work that she has never heard before, able to turn that novel combination of notes into sounds in her head that can be judged to be hackneyed and derivative, or beautiful and original.\n\nAnd, obviously, we do it in the scientific realm in a pretty major way. We come to understand how something works by being able to make sense of how a bunch of different independent variables interact in generating some endpoint. Oh, so that's how mitochondria have evolved to solve that problem, that's what a temperate zone rain forest does to balance those different environmental forces challenging it. Now I know.\n\nThe trouble is that it is getting harder to do that in the life sciences, and this is where something is going to have to happen which will change everything.\n\nThe root of the problem is technology outstripping our ability to really make use of it. This isn't so much about the ability to get increasingly reductive biological information. It was relatively some time ago that scientists figured out how to sequence a gene, identify a mutation, get the crystallographic structure of a protein, or measure ion flow through a single channel in a cell.\n\nWhat the recent development has been is to be able to get staggeringly large amounts of that type of information. We have not just sequenced genes, but sequenced our entire human genome. And we can compare it to that of other species, or can look at genome-wide differences between human populations, or even individuals, or information about tens of thousands of different genes. And then we can look at expression of those genes — which ones are active at which time in which cell types in which individuals in which populations in which species.\n\nWe can do epigenomics, where instead of cataloging which genes exist in an individual, we can examine which genes have been modified in a long-term manner to make it easier or harder to activate them (in each particular cell type). Or we can do proteomics, examining which proteins and in what abundance have been made as the end product of the activation of those genes, or post-translational proteomics, examining how those proteins have been modified to change their functions.\n\nMeanwhile, the same ability to generate massive amounts of data has emerged in other realms of the life sciences. For example, it is possible to do near continuous samplings of blood glucose levels, producing minute-by-minute determinations, or do ambulatory cardiology, generating heart beat data 24/7 for days from an individual going about her business, or use state-of-the-art electrophysiological techniques to record the electrical activity of scores of individual neurons simultaneously.\n\nSo we are poised to be able to do massive genomo-epigenomo-proteonomo-glyco-endo-neurono-orooni-omic comparisons of the Jonas Brothers with Nelson Mandela with a dinosaur pelvis with Wall-E and thus better understand the nature of life.\n\nThe problem, of course, is that we haven't a clue what to do with that much data. By that, I don't mean \"merely\" how to store, or quantitatively analyze, or present it visually. I mean how to really think about it.\n\nYou can already see evidence of this problem in too many microarray papers (this is the approach where you can ask, \"In this particular type of tissue, which genes are more active and which less active than usual under this particular circumstance\"). With the fanciest versions of this approach, you've got yourself thousands of bits of information at the end. And far too often, what is done with all this suggests that the scientists have hit a wall in terms of being able to squeeze insight out of their study.\n\nFor example, the conclusion in the paper might be, \"Eleventy genes are more active under this circumstance, whereas umpteen genes are less active, and that's how things work.\" Or maybe the punch line is, \"Of those eleventy genes that are more active, an awful lot of them have something to do with, say, metabolism, how's about that?\" Or in a sheepish tone, it might be, \"So changes occurred in the activity of eleventy + umpteen different genes, and we don't know what most of them do, but here are three that we do know about and which plausibly have something to do with this circumstance, so we're now going to focus on those three that we already know something about and ignore the rest.\"\n\nIn other words, the technologies have outstripped our abilities to be insightful far too often. We have some crutches — computer graphics allow us to display a three-dimensional scatter plot, rotate it, change it over time. But we still barely hold on.\n\nThe thing that is going to change everything will have to wait for, probably, our grandkids. It will come from their growing up with games and emergent networks and who knows what else that (obviously) we can't even imagine. And they'll be able to navigate that stuff as effortlessly as we troglodytes can currently change radio stations while driving while talking to a passenger. In other words, we're not going to get much out of these vast data sets until we have people who can intuit in six-dimensions. And then, watch out.\n\nThirteen decades ago, Louis Pasteur and Robert Koch led an intellectual revolution referred to as the germ theory of disease, which proposes that many common ailments are caused by microbes. Since then the accepted spectrum of infectious causation has been increasingly steadily and dramatically. The diseases that are most obviously caused by infection were accepted as such by the end of the 19th century; almost all of them were acute diseases. Acute diseases with a transmission twist, mosquito-borne malaria for example, were accepted a bit later at the beginning of the 20th century. Since the early 20th century, the spectrum has been broadened mostly by recognition of infectious causation of chronic diseases. The first of these had distinctly infectious acute phases, which made infectious causation of the chronic disease more obvious. Infectious causation of shingles, for example, was made more apparent by its association with chicken pox. Over the past thirty years, the spectrum of infectious causation has been broadened mostly through inclusion of chronic diseases without obvious acute phases. With years or even decades between the onset of infection and the onset of such diseases, demonstration of infectious causation is difficult.\n\nTechnological advances have been critical to resolving the ambiguities associated with infectious causation of such cryptic infectious causation. In the early 1990s Kaposi's Sarcoma Associated Herpes Virus was discovered using a molecular technique that stripped away the human genetic material from Kaposi's sarcoma cells and found what remained. A similar approach revealed Hepatitis C virus in blood transfusions. In these cases there were strong epidemiological signs that an infectious agent was present. When the cause was discovered, acceptance did not have to confront the barrier of entrenched opinions favoring other non-infectious causes. If such special interests are present the evidence has to be proportionately more compelling. Such is the case for schizophrenia, atherosclerosis, Alzheimer's disease, breast cancer, and many other chronic diseases, which are now the focus of vehement disagreements.\n\nAdvances in molecular/bioinformatic technology are poised to help resolve these controversies. This potential is illustrated by two discoveries, which seem cutting edge now, but will soon be considered primitive first steps. About a decade ago, one member of Stanford team scraped spots on two teeth of another team member, and amplified the DNA from the scrapings. They found sequences that were sufficiently unique to represent more than 30 new species. This finding hinted at the magnitude of the challenge--tens or perhaps even hundreds of thousands of viruses and bacteria may need to be considered to evaluate hypotheses of infectious causation.\n\nThe second discovery provides a glimpse of how this challenge may be addressed. Samples from prostate tumors were tested on a micro-array that contained 20,000 DNA snippets from all known viruses. The results documented a significant association with an obscure retrovirus related to one that normally infects mice. If this virus is a cause of prostate cancer, it causes only a small portion that occurs in men with a particular genetic background. Other viruses have been associated with prostate cancer in patients without this genetic background. So, not only may thousands of viruses need to be tested to find one correlated with a chronic disease, but even then it may be one of perhaps many different infectious causes.\n\nThe problems of multiple pathogens and ingrained predispositions are now coming to a head in research on breast cancer. Presently, three viruses have been associated with breast cancer: mouse mammary tumor virus, Epstein Barr virus, and human papillomavirus. Researchers are still arguing about whether these correlations reflect causation. If they do, these viruses account for somewhere between half and about 95% of breast cancer, depending on the extent to which they act synergistically. Undoubtedly array technology will soon be used to assess this possibility and to identify other viruses that may be associated with breast cancers.\n\nThere is a caveat. These technological advancements provide sophisticated approaches to identifying correlations between pathogens and disease. They do not bridge the gulf between correlation and causation. One might hope that with enough research all aspects of the pathological process could be understood, from the molecular level up to the whole patient. But as one moves from molecular to the macro levels, the precision of interpretation becomes confounded by the complex web of interactions that intervene, especially in chronic diseases. Animal models are generally inadequate for chronic human diseases because the disease in animals is almost never quite the same as the human disease. The only way out of this conundrum, I think, will be to complement the technological advancements in identifying candidate pathogens with clever clinical trials. These clinical trials will need to use special states, such as temporary immune suppression, to identify those infections that are exacerbated concurrently with exacerbations of the chronic disease in question. Such correlations will then need to be tested for causation by treatment of the exacerbated infection to determine whether the suppression of the infection is associated with amelioration of the disease.\n\nWhy will this process change things? For those of us who live in prosperous countries, infectious causes are implicated but not accepted in most common lethal diseases: cancers, heart attacks, stroke, Alzheimer's disease. Infectious causes are also implicated in the vast majority of nonlethal, incapacitating illness of uncertain cause, such as arthritis, fibromyalgia, and Crohn's disease. If infectious causes of these diseases are identified medical history tells us that they will tend to be resolved.\n\nA reasonable estimate of the net effect would be a rise in healthy life expectancy by two or three decades, pushing lifespan up against the ultimate boundary of longevity molded by natural selection, probably an age range between 95 and 105 years. Being pushed up against this barrier people could be expected to live healthy lives into their 90s and then go downhill quickly. This demographic transition toward healthy survival will improve productivity, lower medial costs, and enhance quality of life. In short it will be one of medicine's greatest contributions.\n\nEven with all the scientific and technological advances of the last two millennia and especially of the last century, humankind itself has not really changed. The stories we read in our most ancient books do not seem alien to us. On the contrary, the humans who wrote those works had the same needs and desires that we have today, though the means of meeting those needs and of fulfilling those desires may have changed in some of the details.\n\nThe human species has managed to survive a great number of truly monumental catastrophes, some naturally caused (floods, droughts, tsunamis, glaciations, etc,) and some the result of its own doing, often with the help of science and technology (especially in creating the tools of war). But such calamities did not really \"change everything.\" (This statement is certainly not meant to minimize the tragedy of the millions of lives lost in these catastrophes.) Though we worry about the possible dramatic effects that an anthropogenically changed global climate might have, humankind itself will survive such changes (because of its science and technology), though we cannot predict how many people might tragically die because of it.\n\nIn terms of \"what will change everything\" the larger view is what will significantly change humankind itself. From this human perspective, the last \"event\" that truly changed everything was over some period of time around 50,000 years ago when evolutionary advances finally led to intelligent humans who left Africa and spread out over the rest of the world, literally changing everything in the entire world.\n\nPrior to that evolutionary advance in Africa, our ancestors' main motivations in life were like any other animal — find food and avoid death until they could reproduce. After they evolved into intelligent beings their motivations in life expanded. Although they still pursued food and sex and tried to avoid death, they also spent increasing amounts of time on activities aimed at preventing boredom and making them feel good about themselves. These motivations have not changed in the succeeding millennia, though the means of satisfying themhave changed often.\n\nHow humankind came to be what it is today was a result of natural selection. Humans survived in the hostile environment around them (and went on to Earthly dominance) because of the evolved improvements in their brains. One improvement was the development of curiosity and a desire to learn about the environment in which they lived. But it was not simply a matter of becoming smarter. The human species survived and succeeded in this world as much because of an evolved need for affection or connection with other human beings, a social bond. It was both its increased intelligence and its increased social cooperation that led to increasing knowledge and eventually science and technology. Not all individuals, of course, had the same degree of these characteristics, as shown by the wars and horrendous atrocities that humankind was capable of, but social evolution driven by qualities acquired from the previous species evolution did make progress overall. The greatest progress and the greatest gain in knowledge only happened when people worked with each other in harmony and did not kill each other.\n\nThe evolution of human intelligence and cooperative social bonding tendencies took a very long time, though it seems quite fast when appreciating the incredible complexity of this intelligence and social bonding. How many genes must have mutated and been naturally selected for to achieve this complexity? We are here today as both a species and a society because of those gene changes and the natural selection process that over this long time period weeded out the bad changes and allowed the good changes to remain.\n\nTechnically, evolution of the human species as a result of natural selection stopped when we became a social animal — when the strong began protecting the weak and when our scientific and technological advances allowed us to extend the lives of those individuals unfortunate enough to have genetic weaknesses that would have killed them. With humans, artificial selection (selective breeding) was never a serious replacement for natural selection possibility, and as a result there have been no significant changes to the human species since its societies began.\n\nBut now, with the recent great advances in genetic engineering, we are in a position to change the human species for the first time in 50,000 years. We will be able to put new genes in any human egg or sperm we wish. The children born with these new genes will grow up and pass them on to their children. The extensive use of this genetic selection (or should we call it anthropogenic selection) will rapidly pass new genes and their corresponding (apparently desired) traits throughout the population. But what will be the overall consequence? When selecting particular genes that we want while perhaps not understanding how particular gene combinations work, might we unknowingly begin a process that could change our good human qualities? While striving for higher intelligence could we somehow genetically diminish our capacity for compassion, or our inherent need for social bonding? How might the human species be changed in the long run? The qualities that got us here — the curiosity, the intelligence, the compassion and cooperation resulting from our need for social bonding– involve an incredibly complex combination of genes. Could these have been produced through genetic planning?\n\nOur ever-expanding genetic capabilities will certainly \"change everything\" with respect to medicine and health, which will be a great benefit. Our life span will also be greatly extended, a game-changing benefit to be sure, but it will also add to our overpopulation, the ultimate source of so many problems on our planet. But the ultimate effect may be on the human species itself. How many generations might it take before the entire human race is significantly altered genetically? From a truly human perspective, that would really \"change everything.\"\n\nThe tricky, slippery word in this question is \"expect.\" There is nothing that I expect to see with 100 percent certainty, and there are some remarkable things that I expect to see with perhaps 10 or 5 percent certainty (but I sure would be excited if that 5 percent paid off). With that bit of preamble, I'd like to lay out my game-changing predictions ranked by order of expectation, starting with the near-sure things and ending with the thrilling hey-you-never-knows.\n\nThe real end of oil. Technology will make liquid fuels obsolete — not just petroleum but also alternatives like biodiesel, ethanol, etc. Fossil fuel supplies are too volatile and limited, the fuels themselves far too environmentally costly, and biofuels will never be more than niche players. More broadly, moving around fuels in liquid form is just too cumbersome. In the future, energy for personal transit might be delivered by wire or by beam. It might not be delivered at all — the Back to the Future \"Mr. Fusion\" device is not so farfetched (see below). But whatever comes next, in another generation or so pumping fuel into a car will seem as quaint as getting out and cranking the engine to get it started.\n\nOdds: 95 percent.\n\nDark matter found. The hunt for the Higgs boson is a yawn from my perspective: Finding it will only confirm a theory that most physicists are fairly sure about already. Identifying dark matter particles — either at the Large Hadron Collider or at one of the direct detectors, like Xenon100 — would be much more significant. It would tell us what the other 6/7ths of all matter in the universe consists of, it would instantly rule out a lot of kooky cosmological theories, and it would allow us to construct a complete history of the universe.\n\nOdds: 90 percent.\n\nGenetically engineered kids. I'm not just talking about screening out major cancer genes or selecting blue eyes; I'm talking about designing kids who can breathe underwater or who have radically enhance mental capabilities. Such offspring will rewrite the rules of evolution and redefine what it means to be human. They may very well qualify as totally new species. From a scientific point of view I think this capability is extremely likely, but legal and ethical considerations may prevent it from happening.\n\nWith all that, I put the odds at: 80 percent.\n\nLife detected on an exoplanet. Astronomers have already measured the size, density, temperature, and atmospheric composition of several alien worlds as they transit in front of their parent stars. The upcoming James Webb Space Telescope may be able to do the same for earth-size planets. We haven't found these planets yet but it's a shoo-in that the Kepler mission, launching this spring, or one of the ground-based planet searches will find them soon. The real question is whether the chemical evidence of alien life will be conclusive enough to convince most scientists. (As for life on Mars, I'd say the odds are similar that we'll find evidence of fossil life there, but the likelihood of cross-contamination between Mars and Earth makes Martian life inherently less interesting.)\n\nOdds: 75 percent.\n\nSynthetic telepathy. Rudimentary brain prostheses and brain-machine interfaces already exist. Allowing one person to control another person's body would be a fairly simple extension of that technology. Enabling one person to transmit his thoughts directly to another person's brain is a much trickier proposition, but not terribly farfetched, and it would break down one of the most profound isolations associated with the human condition. Broadcasting the overall state or \"mood\" of a brain would probably come first. Transmitting specific, conscious thoughts would require elaborate physical implants to make sure the signals go to exactly the right place — but such implants could soon become common anyway as people merge their brains with computer data networks.\n\nOdds: 70 percent.\n\nLifespan past 200 (or 1,000). I have little doubt that progress in fighting disease and patching up our genetic weaknesses will make it possible for people to routinely reach the full human lifespan of about 120. Going far beyond that will require halting or reversing the core aging process, which involves not just genetic triggers but also oxidation and simple wear-and-tear. Engineering someone to have gills is probably a much easier proposition. Still, if we can hit 200 I see no reason why the same techniques couldn't allow people to live to 1,000 or more.\n\nOdds: 60 percent.\n\nConscious machines. Intelligent machines are inevitable — by some measures they are already here. Synthetic consciousness would be a much greater breakthrough, in some ways a more profound one than finding life on other planets. One problem: We don't understand how consciousness works, so recreating it will require learning a lot more about what it means to be both smart and self-aware. Another problem: We don't understand what consciousness is, so it's not clear what \"smart\" and \"self-aware\" mean, exactly. Gerald Edelman's brain-based devices are a promising solution. Rather than trying to deconstruct the brain as a computer, they construct neural processing from the bottom up, mimicking the workings of actual neurons.\n\nOdds: 50-50.\n\nGeoengineering. We may be able to deal with global warming through a combination of new energy sources, carbon sequestration, and many local and regional adaptations to a warmer climate. All of these will be technologically challenging but not truly \"game-changing.\" It is possible, though, that the climate impact of our environmental follies will be so severe, and the progress of curative scientific research so dramatic, that some of the pie-in-the-sky geoengineering schemes now being bandied about will actually come to pass. Giant space mirrors and sunshades strike me as the most appealing options, both because they would support an aggressive space program and because they are adjustable and correctable. (Schemes that aim to fight carbon pollution with sulfur pollution seem like a frightening mix of hubris and folly.) Geoengineering techniques are also a good first step toward being able to terraform other planets.\n\nOdds: 25 percent.\n\nDesktop fusion. The ITER project will prove that it is possible to spend billions of dollars to construct an enormous device that produces controlled hydrogen fusion at a net loss of energy. A few left-field fusion researchers — most notably the ones associated with Tri-Alpha — are exploring a much more ambitious approach that would lead to the construction of cheap, compact reactors. These devices could in theory take advantage of more exotic, neutron-free fusion reactions that would allow almost direct conversion of fusion energy to electricity. The old dream of a limitless power plant that could fit under the hood of your car or in a closet in your house might finally come true. Since energy is the limiting factor for most economic development, the world economy (and the potential for research and exploration) would be utterly transformed.\n\nOdds: 20 percent.\n\nCommunication with other universes. Studies of gravitational wave patterns etched into the cosmic microwave background could soon provide hints of the existence of universes outside of our own. Particle collisions at the LHC could soon provide hints of the existence of higher dimensions. But what would really shake the world would be direct measurements of other universes. How exactly that would work is not at all clear, since any object or signal that crossed over directly from another universe could have devastating consequences; indirect evidence, meanwhile, might not be terribly convincing (eg, looking for the gravitational pull from shadow matter on a nearby brane). I hold out hope all the same.\n\nOdds: 10 percent\n\nAntigravity devices. Currentphysics theory doesn't allow such things, but from time to time fringe experiments (mostly involving spinning superconducting disks) allegedly turn up evidence for an antigravity phenomenon. Even NASA has invested dribbles of money in this field, hoping that something exciting and unexpected will pop up. If antigravity really exists it would require revising Einstein's general theory of relativity. It would also vindicate all those science-fiction TV shows in which everyone clomps around heavily in outer space. Given how little we know about how gravity works, antigravity or artificially generated gravity don't seem impossible…just highly improbable.\n\nOdds: 5 percent\n\nESP verified!Probably the closest thing I've seen to a scientific theory of ESP is Rupert Sheldrake's concept of \"morphic fields.\" Right now there's nary a shred of evidence to support the idea — unless you count anecdotes of dogs who know when their owners are about to return home, and people who can \"feel\" when someone is looking at them — but Sheldrake is totally correct that such off-the-wall ideas merit serious scientific investigation. After all, scientists investigate counterintuitive physics concepts all the time; why not conduct equally serious investigations of the intuitive feelings that people have all the time? Everything I know about science, and about human subjectivity, says that there's nothing to find here. And yet, when I think of a discovery that would change everything this is one of the first that springs to mind.\n\nOdds: 0.1 percent\n\nJ. Craig Venter may be on the brink of creating the first artificial life form, but one game-changing scientific idea I expect to live to see is the moment when a robotic device achieves the status of \"living thing.\" What convinces me of this is not some amazing technological breakthrough, but watching some videos of the annual RoboCup soccer tournament organized by Georgia Tech in Atlanta. The robotics researchers behind RoboCup are determined to build a squad of robots capable of winning against the world champion human soccer team. For now, they are just competing against other robots.\n\nFor a human being to raise a foot and kick a soccer ball is an amazingly complex event, involving millions of different neural computations co-ordinated across several different brain regions. For a robot to do it — and to do it as gracefully as members of the RoboCup Humanoid League — is a major technical accomplishment. The cuddlier, though far less accomplished quadrupeds in the Four Legged League are also a wonder to behold. Plus, the robots are not programmed to do this stuff; they learn to do it, just like you and me.\n\nThese robots are marvels of technological ingenuity. They are also \"living\" proof of how easily, eagerly even, we can anthropomorphize robots — and why I expect there won't be much of a fuss when these little metallic critters start infiltrating our homes, offices, and daily lives.\n\nI also expect to see the day when robots like these have biological components (i.e. some wetware to go along with their hardware) and when human beings have internal technological components (i.e. some hardware to go along with our wetware). Researchers at the University of Pittsburgh have trained two monkeys to munch marshmallows using a robotic arm controlled by their own thoughts. During voluntary physical movements, such as reaching for food, nerve cells in the brain start firing well before any movement actually takes place. It's as if the brain warms up for an impending action by directing specific clusters of neurons to fire, just as a driver warms up a car by pumping the gas pedal. The University of Pittsburgh team implanted electrodes in this area of the monkeys' brains and connected them to a computer operating the robotic limb. When the monkeys thought about reaching for a marshmallow, the mechanical arm obeyed that command. In effect, the monkeys had three arms for the duration of the experiments.\n\nIn humans, this type of brain-machine interface (BMI) could allow paralyzed individuals to control prosthetic body parts as well as open up new fields of entertainment and exploration. \"The body's going to be very different 100 years from now,\" Miguel Nicolelis, Anne W. Deane Professor of Neuroscience at Duke University and one of the pioneers of the BMI, has said. \"In a century's time you could be lying on a beach on the east coast of Brazil, controlling a robotic device roving on the surface of Mars, and be subjected to both experiences simultaneously, as if you were in both places at once. The feedback from that robot billions of miles away will be perceived by the brain as if it was you up there.\"\n\nIn robots, a BMI could become a kind of mind. If manufacturers create such robots with big wet puppy dog eyes — or even wearing the face of a loved one or a favorite film star — I think we'll grow to like them pretty quickly. When they have enough senses and \"intelligence,\" then I'm convinced that these machines will qualify as living things. Not human beings, by any means; but kind of like high-tech pets. And turning one off will be the moral equivalent of shooting your dog.\n\nWithin my lifetime (or soon thereafter) scientists will finally decode the language of the brain. At present, we understand a bit about the basic alphabet of neural function, how neurons fire, and how they come together to form synapses, but haven't yet pieced together the words, let alone the sentences. Right now, we're sort of like Mendel, at the dawn of genetics: he knew there must be something like genes (what he called \"factors\"), but couldn't say where they lived (in the protein? in the cytoplasm?) or how they got their job done. Today, we know that thought has something to do with neurons, and that our memories are stored in brain matter, but we don't yet know how to decipher the neurocircuitry within.\n\nDoing that will require a quantum leap. The most popular current techniques for investigating the brain, like functional magnetic resonance imaging (fMRI), are far too coarse. A single three dimensional \"voxel\" in an fMRI scan lumps together the actions of tens or even hundreds of thousands of neurons — yielding a kind of rough geography of the brain (emotion in the amygdala, decision-making in the prefrontal cortex) but little in the way of specifics. How does the prefrontal cortex actually do its thing? How does the visual cortex represent the difference between a house and a car, or a Hummer and a taxi? How does Broca's area know the difference between a noun and verb?\n\nTo answer questions like these, we need to move beyond the broad scale geographies of fMRI and down to the level of individual neurons.\n\nAt the moment, that's a big job. For one thing, in the human brain there are billions of neurons and trillions of connections between them; the sheer amount of data involved is overwhelming. For another, until recently we've lacked the tools to understand the function of individual neurons in action, within the context of microcircuits.\n\nBut there's good reason to think all that's about to change. Computers continue to advance at a dizzying pace. Then there's the truly unprecedented explosion in databases like the Human Genome and the Allen Brain Atlas, enormously valuable datasets that are shared publically and instantly available to all researchers, everywhere; even a decade ago there was nothing like them. Finally, genetic neuroimaging is just around the corner — scientists can now induce individual neurons to fire and (literally) light up on demand, allowing us to understand individual neural circuits in a brand new way.\n\nTechnical advances alone won't be enough, though — we'll need a scientist with the theoeretical vision of Francis Crick, who not only helped identify the physical basis of genes — DNA — but also the code by which the individual nucleotides of a gene get translated (in groups of three) into amino acids. When it comes to the brain, we already know that neurons are the physical basis of thinking and knowledge, but not the laws of translation that relate one to the other.\n\nI don't expect that there will be one single code. Although every creature uses essentially the same translation between DNA and amino acids, different parts of the brain may translate between neurons and information in different ways. Circuits that control muscles, for example, seem to work on a system of statistical averaging; the angle at which a monkey extends its arm seems, as best we can tell, to be a kind of statistical average of the actions of hundreds of individual neurons, each representing a slightly different angle of possible motion, 44 degrees, 44.1 degrees, and so forth. Alas, what works for muscles probably can't work for sentences and ideas, so-called declarative knowledge like the proposition that \"Michael Bloomberg is the Mayor of New York\" or the idea that my fight to Montreal leaves at noon. It's implausible that the brain would have vast population of neurons reserved for each specific thought I might entertain (\"my flight to Montreal leaves at 11:58 am\", \"my flight to Montreal leave leaves at 11:59 am\", etc). Instead, the brain, like language itself, needs some sort of combinatorial code, a way of putting together smaller pieces (Montreal, flight, noon) into larger elements.\n\nWhen we crack that nut, when we figure out how the brain manages to encode declarative knowledge , an awful lot is going to change. For one thing, our relationship to computers will be completely and irrevocably altered; clumsy input devices like mice, windows, keyboards, and even heads-up displays and speech recognizers will go the way of typewriters and fountain pens; our connection to computers will be far more direct. Education, too, will fundamentally change, as engineers and cognitive sciences begin to leverage an understanding of brain code into ways of directly uploading information into the brain. Knowledge will become far cheaper than it already has become in the Internet era; with luck and wisdom, we as species could advance immeasurably.\n\nIt should be an easy transition. Instead of thinking about energy as a commodity to harvest, new sources of power will be manufactured. The medieval quest for new sources of that life force called energy will be over including all those white knights on horses conquering the wild lands where those sources happen to be. Technologically this will mean a shift from an energy industry dominated by geologists and engineers to a wave of innovations driven by biologists and chemists.\n\nThe thought process itself has already been set in motion. The surge of first generation bio-fuels has been based on the idea of renewable sources of energy. Still most alternative energies like solar and wind power are still based on the old way of thinking about harvesting. Most bio-fuels are preceded by a literal harvest of crops. Craig Venter's work on a microorganism that can transform CO2, sunlight and water into fuel is already jumping quite a few steps ahead.\n\nThis new approach will drastically reduce the EIoER formula, which has so far slowed down the commercial viability of most innovations in the search for alternative sources of energy. Any fuel that can be synthetically \"grown\" in a lab or factory will be economically much more viable for mass production than the conversion of sunlight, wind or agricultural goods.\n\nLab-based production of synthetic sources of energy will also end the geopolitical dependencies now tied to the consumption of power and thus change the course of recent history in the most dramatic fashion. This will eliminate the sources of many current and future conflicts, first and foremost in the Gulf region, but also in the Northern part of South America, in the Black Sea region and the increasingly exploitable Arctic.\n\nThe introduction of biological processes into the energy cycle will also minimize the impact of energy consumption on the environment. If made available cheaply, possibly as an open source endeavor, it will allow emerging nations to develop new arable land and create wealth while avoiding conflict and environmental negligence.\n\nThere could of course be downsides to the emergence of new sources of energy. Transitions are never easy, no matter how benign or progressive. The loss of economical and political power by oil- and gas-producing nations and corporations could become a new, if temporary source of conflict. Unforeseen dangers in the production might emerge impacting environment and public health. New monopolies could be formed.\n\nThe shift from harvesting to manufacturing energy would not only impact economy, politics and environment. Turning mankind from mere harvesters of energy into manufacturers would lead to a whole new way of thinking, that could lead to even greater innovations. Because every form of economical and technological empowerment always initiates leaps that go way beyond the practical application of new technologies. It's hard to predict where a new mindset will lead. One thing is for sure it almost always leads to new freedoms and enlightenments.\n\nSociety will change when the poor and middle class have easy access to cryonic suspension of their cognitive remains — even if the future technology involved ultimately fails.\n\nToday we almost always either bury dead brains or burn them. Both disposal techniques result in irreversible loss of personhood information because both techniques either slowly or quickly destroy all the brain tissue that houses a person's unique neural-net circuitry. The result is a neural information apocalypse and all the denial and superstition that every culture has evolved to cope with it.\n\nSome future biocomputing technology may extract and thus back-up this defining neural information or wetware. But no such technology is in sight despite the steady advances of Moore's Law doubling of transistor density on computer chips every two years or so. Nor have we cracked the code of the random pulse train from a single neuron. Hence we are not even close to making sense of the interlocking pulse trains of the billions of chattering neurons in a functioning human brain.\n\nSo far the only practical alternative to this information catastrophe is to vitrify the brain and store it indefinitely in liquid nitrogen at about -320 degrees Fahrenheit. Even the best vitrification techniques still produce massive cell damage that no current or even medium-term technology can likely reverse. But the shortcomings of early twenty-first century science and engineering hardly foreclose the technology options that will be available in a century and far less so in a millennium. Suspended brain tissue needs only periodic replacement of liquid nitrogen to wait out the breakthroughs.\n\nYet right now there are only about 100 brains suspended in liquid nitrogen in a world where each day about 150,000 people die.\n\nThat comes to fewer than three suspended brains per year since a 40-year-old and post-Space Odyssey Stanley Kubrick hailed the promise of cryonic suspension in his 1968 Playboy interview. Kubrick cast death as a problem of bioengineering: \"Death is no more natural or inevitable than smallpox or diphtheria. Death is a disease and as susceptible to cure as any other disease.\" The Playboy interviewer asked Kubrick if he was interested in being frozen. Kubrick said that he \"would be if there were adequate facilities available.\" But just over three decades later Kubrick opted for the old neural apocalypse when he could easily have afforded a first-class cryonic suspension in quite adequate facilities.\n\nThe Kubrick case shows that dollar cost is just one factor that affects the ease of mass access to cryonics. Today many people can afford a brain-only suspension by paying moderate premiums for a life-insurance policy that would cover the expenses. But almost no one accepts that cryonics wager. There are also stigma costs from the usual scolds in the church and in bioethics. There is likewise no shortage of biologists who will point out that you cannot get back the cow from the hamburger.\n\nAnd there remains the simple denial of the inexorable neural catastrophe. That denial is powerful enough that it keeps the majority of citizens from engaging in rational estate planning. The probate code in some states such as California even allows valid handwritten wills that an adult can pen (but not type) and sign in minutes and without any witnesses. But only a minority of Californians ever executes these handwritten wills or the more formal attested wills. The great majority dies intestate and thus they let the chips fall where the state says they fall.\n\nSo it is not too surprising that the overwhelming majority of the doomed believe that the real or imagined transaction costs of brain suspension outweigh its benefits if they think about the matter at all. But those costs will only fall as technology marches on ever faster and as the popular culture adapts to those tech changes. One silver lining of the numbing parade of comic-book action movies is how naturally the younger viewing audience tends to embrace the fanciful information and biotechnology involved in such fare even if the audience lacks a like enthusiasm for calculus.\n\nAgain none of this means that brain suspension in liquid nitrogen will ever work in the sense that it leads to some type of future resurrection of the dead. It may well never work because the required neuro-engineering may eventually prove too difficult or too expensive or because future social power groups outlaw the practice or because of many other technical or social factors. But then again it may work if enough increased demand for such brain suspensions produces enough economies of scale and spurs enough technical and business innovation to pull it off. There is plenty of room for skepticism and variation in all the probability estimates.\n\nBut just having an affordable and plausible long shot at some type of resurrection here on Earth will in time affect popular belief systems and lengthen consumer time horizons. That will in turn affect risk profiles and consumption patterns and so society will change and perhaps abruptly so. A large enough popular demand for brain suspensions would allow democracies to directly represent some of the interests from potential far-future generations because no one would want themselves or their loved ones to revive and find a spoiled planet. Our present dead-by-100 life spans make it all too easy to treat the planet like a rental car as we run up the social credit cards for unborn debtors.\n\nThe cryonics long shot lets us see our pending brain death not as the solipsistic obliteration of our world but as the dreamless sleep that precedes a very major surgery.\n\nAn understanding of how brains synchronize — or fail to do so — will be a game-changing scientific development.\n\nFew behavioral forces are as strong as the delineation of in-groups and out-groups: 'us' and 'them'. Group affiliation requires alignment, coupling or synchronization of the brain states of members. Synchronization yields cooperative behavior, promotes group cohesion, and creates a sense of group agency greater than the sum of the individuals in the group. In the extreme, synchronization yields herding behavior. The absence of synchronization yields conflict.\n\nPeople come under the grip of ideologies, emotions and moods are infectious, and memes spread rapidly through populations. Ethnic, religious, and political groups act as monolithic forces. Mobs, cults and militias are characterized by the melding of large numbers of individuals into larger units, such that the brains of individuals operate in lockstep – a single organism controlled by a single — distributed — nervous system.\n\nLeaders who mobilize large followings have an intuitive ability to synchronize brains or to plug into systems that already are synchronized.\n\nHerding behavior has received a great deal of attention in economics. In the recent financial bubble that eventually burst, investors and regulators were swept up by a wave of blinding optimism and over-confidence. Contrary information was discounted, and analysis from first principles ignored.\n\nHerding behavior is prevalent in times of war. A group that perceives itself to be under attack binds together as a collective fighting unit, without questioning. When swift synchronization is critical and the stakes are high, psychological forces such as duty, loyalty, conformity, compliance – all of which promote group cohesion — come to the fore, overwhelming the rational faculties of individual brains.\n\nSynchronization is found in many species, although the mechanisms may not be the same. Flocks of birds fly in tight formation. Fish swim in schools, and to a distant observer appear as one aggregated organism. Wolves hunt in packs. Some instances of synchronization are driven by environmental cues that regulate individual brains in the same way. For example, light cycles and seasonal cycles can entrain biorhythms of individuals who share the genetic predisposition to be regulated in this way. In other cases, the co-evolution of certain behaviors together with the perception of these behaviors holds individuals together, as in the ability to both produce and recognize species-specific vocalizations.\n\nSynchronization is mediated by communication between brains. Communicative channels include language as well as non-verbal modes such as facial expressions, gestures, tone of voice, and music. Communication across regions of an individual brain is simply a special case of a system that includes communication between brains.\n\nElsewhere I have argued that music serves to synchronize brain states involved in emotion, movement, and the recognition of patterns — thereby promoting group cohesion. As with tradition or ritual, what's being synchronized needn't have intrinsic utility; it may not matter what's being synchronized. The very fact of synchronization can be a powerful source of group agency.\n\nJust around the corner is an explosion of research that regards individual brains as nodes in a system bound together by multiple channels of communication. Information technology has provided novel ways for brains to align across great distances and over time. When a song becomes a hit, millions around the world are aligned, forming a virtual unit. In the future, brain prostheses and artificial interfaces for biological systems will add to the picture.\n\nSome clues are emerging about how brains synchronize. The hot recent discovery is the existence of mirror neurons — brain cells that respond to the actions of other individuals as if one were making them oneself. Mirror systems are thought to generate simulations of the behavior of others in one's own brain, enabling mimicking and empathy. Other pieces of the puzzle have been accumulating for a while. Certain cases of frontal lobe damage result in asocial behavior.\n\nRecent work on autism has drawn attention to the mechanisms whereby individuals connect with others. The brain facilitates (sometimes in unfortunate ways) the categorization of oneself and others into in-groups and out-groups. When white participants in an MRI machine view pictures of faces, the amygdala in the left hemisphere of the brain is more strongly activated when the faces are black than when they are white. The brain has circuits specialized for the perception of faces, which convey enormous amounts of information that enable us to recognize people and gauge their emotions and intentions.\n\nUnderstanding how brains synchronize to form larger systems of behavior will have vast consequences for our grasp of group dynamics, interpersonal relations, education and politics. It will influence how we make sense of — and manage — the powerful unifying forces that constitute group behavior. For better and for worse, it will guide the development of technologies designed to interface with brains, spread knowledge, shape attitudes, elicit emotions, and stimulate action. As with all technological advances, leaders will seize on them to either improve the human condition or consolidate power.\n\nNot all individuals are susceptible to synchronizing with others. Some reject the herd and lose out. Some chart a new course and become leaders. Being contrarian often requires enduring the psychological forces of stigma and ridicule. Understanding the conditions under which people resist will be part of the larger understanding of synchronization.\n\nUnderstanding how brains synchronize – or fail to do so — will not emerge from a single new idea, but rather from a complex puzzle of scientific advances woven together. What is game-changing is that only recently have researchers begun to frame questions about brain function in terms not of individual brains but rather in terms of how individual brains are embedded in larger social and environmental systems that drive their evolution and development. This new way of framing brain and cognitive science — together with unforeseen technological developments — promises transformational integrations of current and future knowledge about how brains interact.\n\nGlobal 21st-century society depends on an 18th-century worldview. It's an Enlightenment-era model that says the essence of humanity — and our best guide in life — is cool, conscious reason. Though many have noted, here on Edge and elsewhere, that this is a poor account of the mind, the rationalist picture still sustains institutions that, in turn, shape our daily lives.\n\nIt is because we are rational that governments guarantee our human rights: To \" use one's understanding without guidance\" (Kant's definition of enlightenment), one needs freedom to inquire, think and speak. Rationality is the reason for elections (because governments not chosen by thoughtful, evidence-weighing citizens would be irrational). Criminal justice systems assume that impartial justice is possible, which means they assume judges and juries can reason their way through a case. Our medical system assumes that drugs work for biochemical reasons, applicable to all human bodies — and not the price on the pill bottle makes a difference in its effectiveness.\n\nAnd free markets presume that all players are avatars of Rational Economic Man: He who consciously and consistently perceives his own interests, relates those to possible actions, reasons his way through the options, and then acts according to his calculations. When Adam Smith famously wrote that butchers, brewers and bakers worked efficiently out of \"regard for their own interest,\" he was doing more than asserting that self-interest could be good. He was also asserting that self-interest — a long-lasting, fact-based, explicit sense of \"what's good for me\" — is possible.\n\nThe rationalist model also suffuses modern culture. Rationalist politics requires tolerance for diversity — we can't reason together if we agree on everything. Rationalist economics teaches the same lesson. If everyone agrees on the proper price for all stocks on the market, then there's no reason for those brokers to go to work. This tolerance for diversity makes it impossible to unite society under a single creed or tradition, and that has the effect of elevating the authority of the scientific method. Data, collected and interpreted according to rigorous standards, elucidating material causes and effects, has become our lingua franca. Our modern notions of the unity of humanity are not premised on God or tribe, but on research results. We say \"we all share the same genes,\" or \" we are all working with the same evolved human nature\" or appeal in some other way to scientific findings.\n\nThis rationalist framework is so deeply embedded in modern life that its enemies speak in its language, even when they violate its tenets. Those who loathe the theory of evolution felt obligated to come up with \"creation science.\"\n\nBusinesses proclaim their devotion to the free market even as they ask governments to interfere with its workings. Then too, tyrants who take the trouble to rig elections only prove that elections are now a universal standard.\n\nSo that's where the world stands today, with banks, governments, medical systems, nation-states resting, explicitly or implicitly, on this notion that human beings are rational deciders.\n\nAnd of course this model looks to be quite wrong. That's fact is not what changes everything, but it's a step in that direction.\n\nWhat's killing Rational Economic Man is an accumulation of scientific evidence suggesting people have (a) strong built-in biases that make it almost impossible to separate information's logical essentials from the manner and setting in which the information is presented; and (b) a penchant for changing their beliefs and preferences according to their surroundings, social setting, mood or simply some random fact they happened to have noticed. The notion that \"I\" can \" know\" consistently what my \" preferences\" are — this is in trouble. (I won't elaborate the case against the rationalist model as recently made by, among others, Gary Marcus, Dan Ariely, Cass Sunstein, because it has been well covered in the recent Edge colloquium on behavioral economics.)\n\nWhat changes is everything is not this ongoing intellectual event, but the next one.\n\nIn the next 10 or 15 years, after the burial of Rational Economic Man, neuroscientists and people from the behavioral disciplines will converge on a better model of human decision-making. I think it will picture people as inconsistent, unconscious, biased, malleable corks on a sea of fast-changing influences, and the consequences of that will be huge for our sense of personhood (to say nothing of sales tricks and marketer manipulations).\n\nBut I think the biggest shocks might come to, and through, institutions that are organized on rationalist premises. If we accept that people are highly influenced by other people, and by their immediate circumstances, then what becomes of our idea of impartial justice? (Jon Hanson at Harvard has been working on that for some time.) How do we understand and protect democracy, now that Jonah Berger has shown that voters are more likely to support education spending just because they happen to cast their ballots in a school? What are we to make of election results, after we've accepted that voters have, at best, \"incoherent, inconsistent, disorganized positions on issues,\" as William Jacoby puts it? How do you see a town hall debate, once you know that people are more tolerant of a new idea if they're sitting in a tidy room than if they're in a messy one?\n\nHow do we understand medical care, now that we know that chemically identical pills have different effects on people who think their medicine is expensive than they do on patient who were told it was cheap? How should we structure markets after learning that even MBAs can be nudged to see a $7 per item as a fair price — just by exposing them to the number 7 a few minutes before? What do we do about standardized testing, when we know that women reminded that they're female score worse on a math test than fellow women who were reminded instead that they were elite college students?\n\nPerhaps we need a new Adam Smith, to reconcile our political, economic and social institutions with present-day knowledge about human nature. In any event, I expect to see the arrival of Post-Rational Economic (and Political and Psychological) Humanity. And I do expect that will change everything.\n\nEvery manmade object — all the things in our homes and workplace — has an invisible back story, a litany of sorry impacts over the course of the journey from manufacture to use to disposal. Take running shoes.\n\nDespite the bells and whistles meant to make one brand of running shoe appeal more than another, at base they all reduce to three parts. The shoe's upper consists of nylon with decorative bits of plastics or synthetic leather. The \"rubber\" sole for most shoes is a petroleum-based synthetic, as is the spongy midsole, composed of ethylene vinyl acetate. Like any petrochemical widget, manufacturing the soles produces unfortunate byproducts, among them benzene, toluene, ethyl benzene, and xylene. In environmental health circles these are known as the \"Big Four\" toxics, being variously carcinogens, central nervous system disrupters, and respiratory irritants, among other biological irritants.\n\nThose bouncy air pockets in some shoe soles contain an ozone-depleting gas. The decorative bits of plastic piping harbor PVC, which endangers the health of workers who make it, and contaminate the ecosystems around the dumps where we eventually send our shoes. The solvents in glues that bind the outsole to midsole can damage the lungs of the workers who apply it. Tanning leather shoe tops can expose workers to hexavalent chromium and other carcinogens.\n\nI remember my high school chemistry teacher's enthusiasm for the chemical reaction that rendered nitrogen fertilizer from ammonia (he moonlighted in a local fertilizer factory); we never heard a word about eutrophication, the dying of aquatic life due to fertilizer runoff that creates a frenzy of algae growth, depleting the water's oxygen. Likewise, coal-burning electric plants seemed a marvel when first deployed: cheap electricity from a virtually inexhaustible source. Who knew about respiratory disease from particulates, let alone global warming?\n\nThe full list of adverse impacts on the environment or the health of those who make or use any product can run into hundreds of such details. The reason: most all of the manufacturing methods and industrial chemicals in common use today were invented in a day when little or no attention was paid to their negative impacts on the planet or its people.\n\nWe have inherited an industrial legacy from the 20th-century which no longer meets the needs of the 21st. As we awaken from our collective naivete about such hidden costs, we are reaching a pivot point where we can question hidden assumptions. We can ask, for example, why not have running shoes that are not just devoid of toxins, but also can eventually be tossed out in a compost pile to biodegrade? We can rethink everything we make, developing alternative ingredients and processes with far less — or ideally, no — adverse health or environmental impacts.\n\nThe singular force that can drive this transformation of every manmade thing for the better is neither government fiat nor the standard tactics of environmentalists, but rather radical transparency in the marketplace. If we as buyers can know the actual ecological impacts of the stuff we buy at the point of purchase, and can compare those impacts to competing products, we can make better choices. The means for such radical transparency has already launched. Software innovations now allow any of us to access a vast database about the hidden harms in whatever we are about to buy, and to do this where it matters most, at the point of purchase. As we stand in the aisle of a store, we can know which brand has the fewest chemicals of concern, or the better carbon footprint. In the Beta version of such software, you click your cell phone's camera on a product's bar code, and get an instant readout of how this brand compares to competitors on any of hundreds of environmental, health, or social impacts. In a planned software upgrade, that same comparison would go on automatically with whatever you buy on your credit card, and suggestions for better purchases next time you shop would routinely come your way by email.\n\nSuch transparency software converts shopping into a vote, letting us target manufacturing processes and product ingredients we want to avoid, and rewarding smarter alternatives. As enough of us apply these decision rules, market share will shift, giving companies powerful, direct data on what shoppers want — and want to avoid — in their products.\n\nCreating a market force that continually leverages ongoing upgrades throughout the supply chain could open the door to immense business opportunities over the next several decades. We need to reinvent industry, starting with the most basic platforms in industrial chemistry and manufacturing design. And that would change every thing.\n\nHuman beings have an amazingly flexible sense of self. If we don a pair of high resolution goggles showing the point of view from another body, with feedback and control, we perceive ourselves to be that body. As we use rudimentary or complex tools, these quickly become familiar extensions of our bodies and minds. This flexibility, and our indefatigable drive to learn, invent, have fun, and seek new adventure, will lead us down future paths that will dramatically alter human experience and our very nature.\n\nBecause we adapt so quickly, the changes will feel gradual. In the next few years solid state memory will replace hard drives, removing the mechanical barrier to miniaturization of our computational gadgetry. Battery size remains as a barrier to progress, but this will improve, along with increased efficiency of our electronics, and we will live with pervasive computational presence. Privacy will vanish. People will record and share their sensorium feeds with the world, and the world will share experiences. Every physical location will be geo-tagged with an overlay of information. Cities will become more pleasant as the internal combustion engine is replaced with silent electric vehicles that don't belch toxic fumes. We'll be drawn in to the ever evolving and persistently available conversations among our social networks. Primitive EEG's will be replaced by magnetoencephalography and functional MRI backed by the computational power to recognize our active thought patterns and translate them to transmittable words, images, and actions. Our friends and family who wish it, and our entire external and internal world, will be reachable with our thoughts. This augmentation will change what it means to be human. Many people will turn away from their meat existence, to virtual worlds, which they will fill with meaning — spending time working on science, virtual constructions, socializing, or just playing games. And we humans will create others like us, but not.\n\nSynthetic intelligence will arrive, but slowly, and it will be different enough that many won't acknowledge it for what it is. People used to think a computer mastering chess, voice recognition, and automated driving would signal the arrival of artificial intelligence. But these milestones have been achieved, and we now consider them the result of brute force computation and clever coding rather than bellwethers of synthetic intelligence. Similarly, computers are just becoming able to play the game of Go at the dan level, and will soon surpass the best human players. They will pass Turing's test. But this synthetic intelligence, however adaptable, is inhuman and foreign, and many people won't accept it as more than number crunching and good programming. A more interesting sign that synthetic intelligence has arrived will be when captchas and reverse Turing tests appear that exclude humans. The computers will have a good laugh about that. If it doesn't happen earlier, this level of AI will arrive once computers achieve the computational power to run real-time simulations of an entire human brain. Shortly after that, we will no longer be the game changers. But by then, humans may have significantly altered themselves through direct biological manipulation.\n\nThe change I expect to see that will most affect human existence will come from biohacking: purposefully altering genomes, tissue engineering, and other advances in biology. Humans are haphazardly assembled biological machines. Our DNA was written by monkeys banging away at... not typewriters, but each other, for millions of years. Imagine how quickly life will transform when DNA and biochemistry are altered with thoughtful intent. Nanotechnology already exists as the machinery within our own biological cells; we're just now learning how these machines work, and how to control them. Pharmaceuticals will be customized to match our personal genome. We're going to be designing and growing organisms to suit our purposes. These organisms will sequester carbon, process raw material, and eventually repair and replace our own bodies.\n\nIt may not happen within my lifetime, but the biggest game change will be the ultimate synthesis of computation and biology. Biotech will eventually allow our brains to be scanned at a level sufficient to preserve our memories and reproduce our consciousness when uploaded to a more efficient computational substrate. At this point our mind may be copied, and, if desired, embedded and connected to the somatic helms of designed biological forms. We will become branching selves, following many different paths at once for the adventure, the fun, and the love of it. Life in the real world presents extremely rich experiences, and uploaded intelligences in virtual worlds will come outside where they can fly as a falcon, sprint as a cheetah, love, play, or even just breath — with superhuman consciousness, no lag, and infinite bandwidth. People will dance with nature, in all its possible forms. And we'll kitesurf.\n\nKitesurfing, you see, is a hell of a lot of fun — and kites are the future of sailing. Even though the sport is only a few years old and kite design is not yet mature, kitesurfers have recently broken the world sailing speed record, reaching over 50 knots. Many in the sailing world are resisting the change, and disputing the record, but kites provide efficient power and lift, and the speed gap will only grow as technology improves. Kitesurfing is a challenging dynamic balance of powerful natural forces. It feels wonderful; and it gets even more fun in waves.\n\nAll of these predicted changes are extrapolations from the seeds of present science and technology; the biggest surprises will come from what can't be extrapolated. It is uncertain how many of these changes will happen within our lifetimes, because that timescale is a dependent variable, and life is uncertain. It is both incredibly tragic and fantastically inspiring that our generation may be the last to die of old age. If extending our lives eludes us, cryonics exists as a stopgap gamble — Pascal's wager for singularitarians, with an uncertain future preferable to a certain lack of one. And if I'm wrong about these predictions, death will mean I'll never know.\n\nThe long-term prospects of our civilization here on Earth are very uncertain. We can be destroyed by an asteroid impact or a nearby supernova explosion, or we can self-destruct in a nuclear or bacteriological war. It is a matter of not if but when the disaster will strike, and the only sure way for humans to survive in the long run is to spread beyond the Earth and colonize the Galaxy. The problem is that our chances of doing that before we are wiped out by some sort of catastrophe appear to be rather bleak.\n\nThe Doomsday argument\n\nThe probability for a civilization to survive the existential challenges and colonize its galaxy may be small, but it is non-zero, and in a vast universe such civilizations should certainly exist. We shall call them large civilizations. There will also be small civilizations which die out before they spread much beyond their native planets.\n\nFor the sake of argument, let us assume that small civilizations do not grow much larger than ours and die soon after they reach their maximum size. The total number of individuals who lived in such a civilization throughout its entire history is then comparable to the number of people who ever lived on Earth, which is about 400 billion people, 60 times the present Earth population.\n\nA large civilization contains a much greater number of individuals. A galaxy like ours has about 100 billion stars. We don't know what fraction of stars have planets suitable for colonization, but with a conservative estimate of 0.01% we would still have about 10 million habitable planets per galaxy. Assuming that each planet will reach a population similar to that of the Earth, we get 4 million trillion individuals. (For definiteness, we focus on human-like civilizations, disregarding the planets inhabited by little green people with 1000 people per square inch.) The numbers can be much higher if the civilization spreads well beyond its galaxy. The crucial question is: what is the probability P for a civilization to become large?\n\nIt takes 10 million (or more) small civilizations to provide the same number of individuals as a single large civilization. Thus, unless P is extremely small (less than one in 10 million), individuals live predominantly in large civilizations. That's where we should expect to find ourselves if we are typical inhabitants of the universe. Furthermore, a typical member of a large civilization should expect to live at a time when the civilization is close to its maximum size, since that is when most of its inhabitants are going to live. These expectations are in a glaring conflict with what we actually observe: we either live in a small civilization or at the very beginning of a large civilization. With the assumption that P is not very small, both of these options are very unlikely – which indicates that the assumption is probably wrong.\n\nIf indeed we are typical observers in the universe, then we have to conclude that the probability P for a civilization to survive long enough to become large must be very tiny. In our example, it cannot be much more than one in 10 million.\n\nThis is the notorious \"Doomsday argument\". First suggested by Brandon Carter about 35 years ago, it inspired much heated debate and has often been misinterpreted. In the form given here it was discussed by Ken Olum, Joshua Knobe, and me.\n\nBeating the odds\n\nThe Doomsday argument is statistical in nature. It does not predict anything about our civilization in particular. All it says is that the odds for any given civilization to grow large are very low. At the same time, some rare civilizations do beat the odds.\n\nWhat distinguishes these exceptional civilizations? Apart from pure luck, civilizations that dedicate a substantial part of their resources to space colonization, start the colonization process early, and do not stop, stand a better chance of long-term survival.\n\nWith many other diverse and pressing needs, this strategy may be difficult to implement, but this may be one of the reasons why large civilizations are so rare. And then, there is no guarantee. Only when the colonization is well underway, and the number of colonies grows faster than they are dying out, can one declare a victory. But if we ever reach this stage in colonization of our Galaxy, this would truly be a turning point in the history of our civilization.\n\nWhere are they?\n\nOne question that needs to be addressed is: why is our Galaxy not yet colonized? There are stars in the Galaxy that are billions of years older than our Sun, and it should take much less than a billion years to colonize the entire Galaxy. So, we are faced with Enrico Fermi's famous question: Where are they? The most probable answer, in my view, is that we may be the only intelligent civilization in the entire observable universe.\n\nOur cosmic horizon is set by the distance that light has traveled since the big bang. It sets the absolute limit to space colonization, since no civilization can spread faster than the speed of light. There is a large number of habitable planets within our horizon, but are these planets actually inhabited? Evolution of life and intelligence require some extremely improbable events. Theoretical estimates (admittedly rather speculative) suggest that their probability is so low that the nearest planet with intelligent life may be far beyond the horizon. If this is really so, then we are responsible for a huge chunk of real estate, 80 billion light years in diameter. Our crossing the threshold to a space-colonizing civilization would then really change everything. It will make a difference between a \"flicker\" civilization that blinks in and out of existence and a civilization that spreads through much of the observable universe, and possibly transforms it.\n\nWhen asked about what will change our future, the most straightforward reply that comes to mind is, of course, the Internet. But how the Internet will change things that it has not already changed, what is the next revolution ahead on the net, this is a harder matter. The Internet is a complex geography of information technology, networking, multimedia content and telecommunication. This powerful alliance of different technologies has provided not only a brand new way of producing, storing and retrieving information, but a giant network of ranking and rating systems in which information is valued as long as it has been already filtered by other people.\n\nMy prediction for the Big Change is that the Information Age is being replaced by a Reputation Age in which the reputation of an item — that is how others value and rate the item — will be the only way we have to extract information about it. This passion of ranking is a central feature of our contemporary practices of filtering information, in and out of the net (take as two different examples of it — one inside and the other outside the net - www.ebay.com and the recent financial crisis).\n\nThe next revolution will be a consequence of the impact of reputation on our practices of information gathering. Notice that this won’t mean a world of collective ignorance in which everyone has no other chances to know something than to rely on the judgment of someone else, in a sort of infinite chain of blind trust where nobody seems to know anything for sure anymore: The age of reputation will be a new age of knowledge gathering guided by new rules and principles. This is possible now thanks to the tremendous potential of the social web in aggregating individual preferences and choices to produce intelligent outcomes. Let me explain how more precisely.\n\nOne of the main revolution of Internet technologies has been the introduction by Google of the « PageRank » algorithm for retrieving information, that is, an algorithm that bases its search for relevant information on the structure of the links on the Web. Algorithms such as these extract the cultural information contained in each preference users express by putting a link from a page to another with a mathematical cocktail of formulas that gives a special weight to each of these connections. This determines which pages are going to be in the first positions of a search result.\n\nFears about these tools are obviously many, because our control on the design of the algorithms, on the way the weights are assigned to determine the rank is very poor, nearly inexistent. But let us imagine a new generation of search engines whose ranking procedures are simply generated by the aggregation of individual preferences expressed on these pages: no big calculations, no secret weights: the results of a query are organized just according to the « grades » each of these pages has received by the users that have crossed that page at least once and taken the time to rank it.\n\nA social search engine based on the power of the « soft » social computing, will be able to take advantage of the reputation each site and page has cumulated simply by the votes users have expressed on it. The new algorithms for extracting information will exploit the power of the judgments of the many to produce their result. This softer Web, more controlled by human experiences than complex formulas, will change our interaction with the net, as well as our fears and hopes about it. The potential of social filtering of information is that of a new way of extracting information by relying on the previous judgments of others.\n\nHegel thought that universal history was made by universal judgments: our history will be written from now on in the language of « good » and « bad », that is, in terms of the judgments people express on things and events around them, that will become the more and more crucial for each of us to extract information about these events. According to Frederick Hayek,Civilization rests on the fact that we all benefit from knowledge we do not possess: that’s exactly the kind of civilized cyber-world that will be made possible by social tools of aggregating judgments on the Web.\n\nWhat will change everything is radical paradigm shift in the scientific method that opens up horizons beyond the reach of Boolean Logic, Digital Manipulations and Numerical Evaluations.\n\nDue to my advanced age, I am not likely to witness the change. But I am seeing signs and have my hunches. These I will briefly spell out.\n\nTo change Everything a radical paradigm shift must interrupt the scientific method's race:\n\nSTOP for a moment's reflection; what are you up to?\n\nHow do you know your dog would rather be a cat — just because you prefer cats. Did you asked him, have you figured out how to ask him?\n\nHaving figured out how to do something is not enough reason for actually doing it. That's one aspect of the paradigm shift I am expecting; coming from inside the ranks. Evaluation of scientific results and their potential effects on the world as we know it is of particular urgency these days when news are spreading so easily all over the population. Of course we do not want to regress to a system of classified information that generates elitism. Well this problem is creating the, not so new anymore, philosophical discipline of applied Ethics; if only it keeps scientifically well informed and focused down to earth on concrete issues.\n\nThe goal of this part of the shift is a tightening of the structure of the whole conglomerate of the sciences and their presentation in the media.\n\nBut this brings me to the more radical effect of the shift I am envisaging; a healing effect on the rift between the endeavors that are bestowed the label \"scientific\" and the proliferation of so-called \"alternative\" enterprises, many of which are striving to achieve the blessings of scientific grounding by experimentations, theories and statistical evaluations, whether appropriate or not. A true and fruitful symbiosis that leads to a deeper understanding of the meaning of Human Existence than the models of a machine or of a token created by a Superior Being for the mysterious purpose of suffering through life in the service of His Glory.\n\nWhere do I expect the decisive push to come from? Possibly from the young discipline of cognitive science, provided psychology, philosophy and physiology are ready to cooperate. There are shoots rising up all over, but I won't embark on a list. Once the \"real thing\" is found or constructed it will be recognized. It will have shape and make sense.\n\nThe myth of the scientific method as the only approach to reality will become obsolete without loss to man's interaction with this world. The path to understanding has to be prepared by a direct, still somewhat mysterious approach of hunches and intuitions in addition to direct perceptions and sensations. Moreover the results of that procedure are useless unless suitably interpreted.\n\nWell, this is as far as I am ready to go with this explanation of a hunch. The alternative to my current vagueness would be rigidity prone to misinterpretation.\n\nAs to my own turf, Mathematics, I do not believe there will be any radical change. Mathematics is a rock of a structure, here to stay. Mathematical insights do not change, they become clearer, dead ends are recognized as such, but what is proved beyond doubt what is cumulative.\n\nBut methodological changes here are in order as well as meta-mathematical and philosophical interpretation of the nature of results. So is the evolution of an ever more lucid language.\n\nI personally believe we'd do well to focus on Mathematical Intuitionism as our Foundations. Boolean thinking has done its service by now.\n\nTo sum up what I am expecting of this paradigm shift are: clarification, simplification and unification of our understanding and with it the emergence of a more lucidly expressive language conducive to the End of Fragmentation of Knowledge.\n\nEvolution is the scientific idea that will change everything within next several decades.\n\nI recognize that this statement might seem improbable. If evolution is defined generally, simply as change over time, the above statement borders on meaningless. If regarded in the narrower, Darwinian sense, as descent with modification, any claim for evolution's starring role also appears questionable, particularly given that 2009 is the 150th anniversary of the publication of On the Origin of Species. Surely Darwin's \"Dangerous Idea,\" however conceived, has made its mark by now. Nevertheless, I base my claim on evolution's probable impacts in two great spheres: human consciousness and science and technology.\n\nToday, the commonly accepted conception of evolution is extremely narrow, confined largely to the realm of biology and a longstanding emphasis on mutation and natural selection. In recent decades, this limited perspective has become further entrenched by the dominance of molecular biology and its \"promise\" of human-engineered cells and lifeforms. Emphasis has been placed almost entirely on the generation of diversity — a process referred to as \"complexification\" — reflecting the reductionist worldview that has driven science for four centuries.\n\nYet science has also begun to explore another key element of evolution — unification — which transcends the biological to encompass evolution of physical matter. The numerous and dramatic increases in complexity, it turns out, have been achieved largely through a process of integration, with smaller wholes becoming parts of larger wholes. Again and again we see the progressive development of multi-part individuals from simpler forms. Thus, for example, atoms become integrated into molecules, molecules into cells, and cells into organisms. At each higher, emergent stage, older forms are enveloped and incorporated into newer forms, with the end result being a nested, multilevel hierarchy.\n\nAt first glance, the process of unification appears to contravene the second law of thermodynamics by increasing order over entropy. Again and again during the past 14 billion years, concentrations of energy have emerged and self-organized as islands of order amidst a sea of chaos, taking the guise of stars, galaxies, bacteria, gray whales, and, on at least one planet, a biosphere. Although the process of emergence remains somewhat of a mystery, we can now state with confidence that the epic of evolution has been guided by counterbalancing trends of complexification and unification. This journey has not been an inevitable, deterministic march, but a quixotic, creative unfolding in which the future could not be predicted.\n\nHow will a more comprehensive understanding of evolution affect science and technology? Already a nascent but fast-growing industry called \"biomimicry\" taps into nature's wisdom, imitating sustainable, high performance designs and processes acquired during four billion years of evolutionary R&D. Water repellant lotus plants inspire non-toxic fabrics. Termite mounds inspire remarkable buildings that make use of passive cooling. Spider silk may provide inspiration for a new, strong, flexible, yet rigid material with innumerable possible uses. Ultimately, plant photosynthesis may reveal secrets to an unlimited energy supply with minimal waste products.\n\nThe current bout of biomimicry is just the beginning. I am increasingly convinced that ongoing research into such phenomena as complex adaptive systems will result in a new synthesis of evolution and energetics — let's call it the \"Unified Theory of Evolution\" — that will trigger a cascade of novel research and designs. Science will relinquish its unifocal downward gaze on reductionist nuts and bolts, turning upward to explore the \"pattern that connects.\" An understanding of complex adaptive systems will yield transformative technologies we can only begin to imagine. Think about the potential for new generations of \"smart\" technologies, with the capacity to adapt, indeed to evolve and transform, in response to changing conditions.\n\nAnd what of human consciousness? Reductionism has yielded stunning advances in science and technology. However, its dominant metaphor, life-as-machine, has left us with a gaping chasm between the human and non-human worlds. With \"Nature\" (the non-human world) reduced merely to resources, humanity's ever-expanding activities have become too much for the biosphere to absorb. We have placed ourselves, and the biosphere, on the precipice of a devastating ecological crisis, without the consciousness for meaningful progress toward sustainability.\n\nAt present, Western culture lacks a generally accepted cosmology, a story that gives life meaning. One of the greatest contributions of the scientific enterprise is the epic of evolution, sometimes called the Univers"
    }
}