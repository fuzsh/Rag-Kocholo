{
    "id": "dbpedia_109_1",
    "rank": 94,
    "data": {
        "url": "https://realpython.com/python-encodings-guide/",
        "read_more_link": "",
        "language": "en",
        "title": "Unicode & Character Encodings in Python: A Painless Guide â€“ Real Python",
        "top_image": "https://files.realpython.com/media/Encodings--Number-Systems_Watermarked.906d62e907dc.jpg",
        "meta_img": "https://files.realpython.com/media/Encodings--Number-Systems_Watermarked.906d62e907dc.jpg",
        "images": [
            "https://realpython.com/static/real-python-logo.893c30edea53.svg",
            "https://realpython.com/static/pytrick-dict-merge.4201a0125a5e.png",
            "https://files.realpython.com/media/Encodings--Number-Systems_Watermarked.906d62e907dc.jpg",
            "https://files.realpython.com/media/encode-decode.3e665ad9b455.png",
            "https://realpython.com/static/pytrick-dict-merge.4201a0125a5e.png",
            "https://realpython.com/cdn-cgi/image/width=1188,height=1188,fit=crop,gravity=auto,format=auto/https://files.realpython.com/media/Screen_Shot_2021-09-28_at_3.13.21_PM.3310c56e90bd.jpg",
            "https://realpython.com/cdn-cgi/image/width=1188,height=1188,fit=crop,gravity=auto,format=auto/https://files.realpython.com/media/Screen_Shot_2021-09-28_at_3.13.21_PM.3310c56e90bd.jpg",
            "https://realpython.com/cdn-cgi/image/width=500,height=500,fit=crop,gravity=auto,format=auto/https://files.realpython.com/media/IMG_0116.f88cbfca15da.jpg",
            "https://realpython.com/cdn-cgi/image/width=959,height=959,fit=crop,gravity=auto,format=auto/https://files.realpython.com/media/PP.9b8b026f75b8.jpg",
            "https://realpython.com/cdn-cgi/image/width=800,height=800,fit=crop,gravity=auto,format=auto/https://files.realpython.com/media/jjablonksi-avatar.e37c4f83308e.jpg",
            "https://realpython.com/static/videos/lesson-locked.f5105cfd26db.svg",
            "https://realpython.com/static/videos/lesson-locked.f5105cfd26db.svg",
            "https://realpython.com/static/videos/lesson-locked.f5105cfd26db.svg",
            "https://files.realpython.com/media/pytricks-book-mockup.e2bdf7273464.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Real Python"
        ],
        "publish_date": "2019-05-20T14:00:00+00:00",
        "summary": "",
        "meta_description": "In this tutorial, you'll get a Python-centric introduction to character encodings and unicode. Handling character encodings and numbering systems can at times seem painful and complicated, but this guide is here to help with easy-to-follow Python examples.",
        "meta_lang": "en",
        "meta_favicon": "/static/favicon.68cbf4197b0c.png",
        "meta_site_name": "",
        "canonical_link": "https://realpython.com/python-encodings-guide/",
        "text": "Table of Contents\n\nHandling character encodings in Python or any other language can at times seem painful. Places such as Stack Overflow have thousands of questions stemming from confusion over exceptions like UnicodeDecodeError and UnicodeEncodeError. This tutorial is designed to clear the Exception fog and illustrate that working with text and binary data in Python 3 can be a smooth experience. Pythonâ€™s Unicode support is strong and robust, but it takes some time to master.\n\nThis tutorial is different because itâ€™s not language-agnostic but instead deliberately Python-centric. Youâ€™ll still get a language-agnostic primer, but youâ€™ll then dive into illustrations in Python, with text-heavy paragraphs kept to a minimum. Youâ€™ll see how to use concepts of character encodings in live Python code.\n\nBy the end of this tutorial, youâ€™ll:\n\nGet conceptual overviews on character encodings and numbering systems\n\nUnderstand how encoding comes into play with Pythonâ€™s str and bytes\n\nKnow about support in Python for numbering systems through its various forms of int literals\n\nBe familiar with Pythonâ€™s built-in functions related to character encodings and numbering systems\n\nCharacter encoding and numbering systems are so closely connected that they need to be covered in the same tutorial or else the treatment of either would be totally inadequate.\n\nWhatâ€™s a Character Encoding?\n\nThere are tens if not hundreds of character encodings. The best way to start understanding what they are is to cover one of the simplest character encodings, ASCII.\n\nWhether youâ€™re self-taught or have a formal computer science background, chances are youâ€™ve seen an ASCII table once or twice. ASCII is a good place to start learning about character encoding because it is a small and contained encoding. (Too small, as it turns out.)\n\nIt encompasses the following:\n\nLowercase English letters: a through z\n\nUppercase English letters: A through Z\n\nSome punctuation and symbols: \"$\" and \"!\", to name a couple\n\nWhitespace characters: an actual space (\" \"), as well as a newline, carriage return, horizontal tab, vertical tab, and a few others\n\nSome non-printable characters: characters such as backspace, \"\\b\", that canâ€™t be printed literally in the way that the letter A can\n\nSo what is a more formal definition of a character encoding?\n\nAt a very high level, itâ€™s a way of translating characters (such as letters, punctuation, symbols, whitespace, and control characters) to integers and ultimately to bits. Each character can be encoded to a unique sequence of bits. Donâ€™t worry if youâ€™re shaky on the concept of bits, because weâ€™ll get to them shortly.\n\nThe various categories outlined represent groups of characters. Each single character has a corresponding code point, which you can think of as just an integer. Characters are segmented into different ranges within the ASCII table:\n\nCode Point Range Class 0 through 31 Control/non-printable characters 32 through 64 Punctuation, symbols, numbers, and space 65 through 90 Uppercase English alphabet letters 91 through 96 Additional graphemes, such as [ and \\ 97 through 122 Lowercase English alphabet letters 123 through 126 Additional graphemes, such as { and | 127 Control/non-printable character (DEL)\n\nThe entire ASCII table contains 128 characters. This table captures the complete character set that ASCII permits. If you donâ€™t see a character here, then you simply canâ€™t express it as printed text under the ASCII encoding scheme.\n\nCode Point Character (Name) Code Point Character (Name) 0 NUL (Null) 64 @ 1 SOH (Start of Heading) 65 A 2 STX (Start of Text) 66 B 3 ETX (End of Text) 67 C 4 EOT (End of Transmission) 68 D 5 ENQ (Enquiry) 69 E 6 ACK (Acknowledgment) 70 F 7 BEL (Bell) 71 G 8 BS (Backspace) 72 H 9 HT (Horizontal Tab) 73 I 10 LF (Line Feed) 74 J 11 VT (Vertical Tab) 75 K 12 FF (Form Feed) 76 L 13 CR (Carriage Return) 77 M 14 SO (Shift Out) 78 N 15 SI (Shift In) 79 O 16 DLE (Data Link Escape) 80 P 17 DC1 (Device Control 1) 81 Q 18 DC2 (Device Control 2) 82 R 19 DC3 (Device Control 3) 83 S 20 DC4 (Device Control 4) 84 T 21 NAK (Negative Acknowledgment) 85 U 22 SYN (Synchronous Idle) 86 V 23 ETB (End of Transmission Block) 87 W 24 CAN (Cancel) 88 X 25 EM (End of Medium) 89 Y 26 SUB (Substitute) 90 Z 27 ESC (Escape) 91 [ 28 FS (File Separator) 92 \\ 29 GS (Group Separator) 93 ] 30 RS (Record Separator) 94 ^ 31 US (Unit Separator) 95 _ 32 SP (Space) 96 ` 33 ! 97 a 34 \" 98 b 35 # 99 c 36 $ 100 d 37 % 101 e 38 & 102 f 39 ' 103 g 40 ( 104 h 41 ) 105 i 42 * 106 j 43 + 107 k 44 , 108 l 45 - 109 m 46 . 110 n 47 / 111 o 48 0 112 p 49 1 113 q 50 2 114 r 51 3 115 s 52 4 116 t 53 5 117 u 54 6 118 v 55 7 119 w 56 8 120 x 57 9 121 y 58 : 122 z 59 ; 123 { 60 < 124 | 61 = 125 } 62 > 126 ~ 63 ? 127 DEL (delete)\n\nThe string Module\n\nPythonâ€™s string module is a convenient one-stop-shop for string constants that fall in ASCIIâ€™s character set.\n\nHereâ€™s the core of the module in all its glory:\n\nPython\n\n# From lib/python3.7/string.py whitespace = ' \\t\\n\\r\\v\\f' ascii_lowercase = 'abcdefghijklmnopqrstuvwxyz' ascii_uppercase = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' ascii_letters = ascii_lowercase + ascii_uppercase digits = '0123456789' hexdigits = digits + 'abcdef' + 'ABCDEF' octdigits = '01234567' punctuation = r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\" printable = digits + ascii_letters + punctuation + whitespace\n\nCopied!\n\nMost of these constants should be self-documenting in their identifier name. Weâ€™ll cover what hexdigits and octdigits are shortly.\n\nYou can use these constants for everyday string manipulation:\n\nPython\n\n>>> import string >>> s = \"What's wrong with ASCII?!?!?\" >>> s.rstrip(string.punctuation) 'What's wrong with ASCII'\n\nCopied!\n\nNote: string.printable includes all of string.whitespace. This disagrees slightly with another method for testing whether a character is considered printable, namely str.isprintable(), which will tell you that none of {'\\v', '\\n', '\\r', '\\f', '\\t'} are considered printable.\n\nThe subtle difference is because of definition: str.isprintable() considers something printable if â€œall of its characters are considered printable in repr().â€\n\nA Bit of a Refresher\n\nNow is a good time for a short refresher on the bit, the most fundamental unit of information that a computer knows.\n\nA bit is a signal that has only two possible states. There are different ways of symbolically representing a bit that all mean the same thing:\n\n0 or 1\n\nâ€œyesâ€ or â€œnoâ€\n\nTrue or False\n\nâ€œonâ€ or â€œoffâ€\n\nOur ASCII table from the previous section uses what you and I would just call numbers (0 through 127), but what are more precisely called numbers in base 10 (decimal).\n\nYou can also express each of these base-10 numbers with a sequence of bits (base 2). Here are the binary versions of 0 through 10 in decimal:\n\nDecimal Binary (Compact) Binary (Padded Form) 0 0 00000000 1 1 00000001 2 10 00000010 3 11 00000011 4 100 00000100 5 101 00000101 6 110 00000110 7 111 00000111 8 1000 00001000 9 1001 00001001 10 1010 00001010\n\nNotice that as the decimal number n increases, you need more significant bits to represent the character set up to and including that number.\n\nHereâ€™s a handy way to represent ASCII strings as sequences of bits in Python. Each character from the ASCII string gets pseudo-encoded into 8 bits, with spaces in between the 8-bit sequences that each represent a single character:\n\nPython\n\n>>> def make_bitseq(s: str) -> str: ... if not s.isascii(): ... raise ValueError(\"ASCII only allowed\") ... return \" \".join(f\"{ord(i):08b}\" for i in s) >>> make_bitseq(\"bits\") '01100010 01101001 01110100 01110011' >>> make_bitseq(\"CAPS\") '01000011 01000001 01010000 01010011' >>> make_bitseq(\"$25.43\") '00100100 00110010 00110101 00101110 00110100 00110011' >>> make_bitseq(\"~5\") '01111110 00110101'\n\nCopied!\n\nNote: .isascii() was introduced in Python 3.7.\n\nThe f-string f\"{ord(i):08b}\" uses Pythonâ€™s Format Specification Mini-Language, which is a way of specifying formatting for replacement fields in format strings:\n\nThe left side of the colon, ord(i), is the actual object whose value will be formatted and inserted into the output. Using the Python ord() function gives you the base-10 code point for a single str character.\n\nThe right hand side of the colon is the format specifier. 08 means width 8, 0 padded, and the b functions as a sign to output the resulting number in base 2 (binary).\n\nThis trick is mainly just for fun, and it will fail very badly for any character that you donâ€™t see present in the ASCII table. Weâ€™ll discuss how other encodings fix this problem later on.\n\nWe Need More Bits!\n\nThereâ€™s a critically important formula thatâ€™s related to the definition of a bit. Given a number of bits, n, the number of distinct possible values that can be represented in n bits is 2n:\n\nPython\n\ndef n_possible_values(nbits: int) -> int: return 2 ** nbits\n\nCopied!\n\nHereâ€™s what that means:\n\n1 bit will let you express 21 == 2 possible values.\n\n8 bits will let you express 28 == 256 possible values.\n\n64 bits will let you express 264 == 18,446,744,073,709,551,616 possible values.\n\nThereâ€™s a corollary to this formula: given a range of distinct possible values, how can we find the number of bits, n, that is required for the range to be fully represented? What youâ€™re trying to solve for is n in the equation 2n = x (where you already know x).\n\nHereâ€™s what that works out to:\n\nPython\n\n>>> from math import ceil, log >>> def n_bits_required(nvalues: int) -> int: ... return ceil(log(nvalues) / log(2)) >>> n_bits_required(256) 8\n\nCopied!\n\nThe reason that you need to use a ceiling in n_bits_required() is to account for values that are not clean powers of 2. Say you need to store a character set of 110 characters total. Naively, this should take log(110) / log(2) == 6.781 bits, but thereâ€™s no such thing as 0.781 bits. 110 values will require 7 bits, not 6, with the final slots being unneeded:\n\nPython\n\n>>> n_bits_required(110) 7\n\nCopied!\n\nAll of this serves to prove one concept: ASCII is, strictly speaking, a 7-bit code. The ASCII table that you saw above contains 128 code points and characters, 0 through 127 inclusive. This requires 7 bits:\n\nPython\n\n>>> n_bits_required(128) # 0 through 127 7 >>> n_possible_values(7) 128\n\nCopied!\n\nThe issue with this is that modern computers donâ€™t store much of anything in 7-bit slots. They traffic in units of 8 bits, conventionally known as a byte.\n\nNote: Throughout this tutorial, I assume that a byte refers to 8 bits, as it has since the 1960s, rather than some other unit of storage. You are free to call this an octet if you prefer.\n\nThis means that the storage space used by ASCII is half-empty. If itâ€™s not clear why this is, think back to the decimal-to-binary table from above. You can express the numbers 0 and 1 with just 1 bit, or you can use 8 bits to express them as 00000000 and 00000001, respectively.\n\nYou can express the numbers 0 through 3 with just 2 bits, or 00 through 11, or you can use 8 bits to express them as 00000000, 00000001, 00000010, and 00000011, respectively. The highest ASCII code point, 127, requires only 7 significant bits.\n\nKnowing this, you can see that make_bitseq() converts ASCII strings into a str representation of bytes, where every character consumes one byte:\n\nPython\n\n>>> make_bitseq(\"bits\") '01100010 01101001 01110100 01110011'\n\nCopied!\n\nASCIIâ€™s underutilization of the 8-bit bytes offered by modern computers led to a family of conflicting, informalized encodings that each specified additional characters to be used with the remaining 128 available code points allowed in an 8-bit character encoding scheme.\n\nNot only did these different encodings clash with each other, but each one of them was by itself still a grossly incomplete representation of the worldâ€™s characters, regardless of the fact that they made use of one additional bit.\n\nOver the years, one character encoding mega-scheme came to rule them all. However, before we get there, letâ€™s talk for a minute about numbering systems, which are a fundamental underpinning of character encoding schemes.\n\nCovering All the Bases: Other Number Systems\n\nIn the discussion of ASCII above, you saw that each character maps to an integer in the range 0 through 127.\n\nThis range of numbers is expressed in decimal (base 10). Itâ€™s the way that you, me, and the rest of us humans are used to counting, for no reason more complicated than that we have 10 fingers.\n\nBut there are other numbering systems as well that are especially prevalent throughout the CPython source code. While the â€œunderlying numberâ€ is the same, all numbering systems are just different ways of expressing the same number.\n\nIf I asked you what number the string \"11\" represents, youâ€™d be right to give me a strange look before answering that it represents eleven.\n\nHowever, this string representation can express different underlying numbers in different numbering systems. In addition to decimal, the alternatives include the following common numbering systems:\n\nBinary: base 2\n\nOctal: base 8\n\nHexadecimal (hex): base 16\n\nBut what does it mean for us to say that, in a certain numbering system, numbers are represented in base N?\n\nHere is the best way that I know of to articulate what this means: itâ€™s the number of fingers that youâ€™d count on in that system.\n\nIf you want a much fuller but still gentle introduction to numbering systems, Charles Petzoldâ€™s Code is an incredibly cool book that explores the foundations of computer code in detail.\n\nOne way to demonstrate how different numbering systems interpret the same thing is with Pythonâ€™s int() constructor. If you pass a str to int(), Python will assume by default that the string expresses a number in base 10 unless you tell it otherwise:\n\nPython\n\n>>> int('11') 11 >>> int('11', base=10) # 10 is already default 11 >>> int('11', base=2) # Binary 3 >>> int('11', base=8) # Octal 9 >>> int('11', base=16) # Hex 17\n\nCopied!\n\nThereâ€™s a more common way of telling Python that your integer is typed in a base other than 10. Python accepts literal forms of each of the 3 alternative numbering systems above:\n\nType of Literal Prefix Example n/a n/a 11 Binary literal 0b or 0B 0b11 Octal literal 0o or 0O 0o11 Hex literal 0x or 0X 0x11\n\nAll of these are sub-forms of integer literals. You can see that these produce the same results, respectively, as the calls to int() with non-default base values. Theyâ€™re all just int to Python:\n\nPython\n\n>>> 11 11 >>> 0b11 # Binary literal 3 >>> 0o11 # Octal literal 9 >>> 0x11 # Hex literal 17\n\nCopied!\n\nHereâ€™s how you could type the binary, octal, and hexadecimal equivalents of the decimal numbers 0 through 20. Any of these are perfectly valid in a Python interpreter shell or source code, and all work out to be of type int:\n\nDecimal Binary Octal Hex 0 0b0 0o0 0x0 1 0b1 0o1 0x1 2 0b10 0o2 0x2 3 0b11 0o3 0x3 4 0b100 0o4 0x4 5 0b101 0o5 0x5 6 0b110 0o6 0x6 7 0b111 0o7 0x7 8 0b1000 0o10 0x8 9 0b1001 0o11 0x9 10 0b1010 0o12 0xa 11 0b1011 0o13 0xb 12 0b1100 0o14 0xc 13 0b1101 0o15 0xd 14 0b1110 0o16 0xe 15 0b1111 0o17 0xf 16 0b10000 0o20 0x10 17 0b10001 0o21 0x11 18 0b10010 0o22 0x12 19 0b10011 0o23 0x13 20 0b10100 0o24 0x14\n\nItâ€™s amazing just how prevalent these expressions are in the Python Standard Library. If you want to see for yourself, navigate to wherever your lib/python3.7/ directory sits, and check out the use of hex literals like this:\n\nShell\n\n$ grep -nri --include\"*\\.py\" -e\"\\b0x\" lib/python3.7\n\nCopied!\n\nThis should work on any Unix system that has grep. You could use \"\\b0o\" to search for octal literals or â€œ\\b0bâ€ to search for binary literals.\n\nWhatâ€™s the argument for using these alternate int literal syntaxes? In short, itâ€™s because 2, 8, and 16 are all powers of 2, while 10 is not. These three alternate number systems occasionally offer a way for expressing values in a computer-friendly manner. For example, the number 65536 or 216, is just 10000 in hexadecimal, or 0x10000 as a Python hexadecimal literal.\n\nEnter Unicode\n\nAs you saw, the problem with ASCII is that itâ€™s not nearly a big enough set of characters to accommodate the worldâ€™s set of languages, dialects, symbols, and glyphs. (Itâ€™s not even big enough for English alone.)\n\nUnicode fundamentally serves the same purpose as ASCII, but it just encompasses a way, way, way bigger set of code points. There are a handful of encodings that emerged chronologically between ASCII and Unicode, but they are not really worth mentioning just yet because Unicode and one of its encoding schemes, UTF-8, has become so predominantly used.\n\nThink of Unicode as a massive version of the ASCII tableâ€”one that has 1,114,112 possible code points. Thatâ€™s 0 through 1,114,111, or 0 through 17 * (216) - 1, or 0x10ffff hexadecimal. In fact, ASCII is a perfect subset of Unicode. The first 128 characters in the Unicode table correspond precisely to the ASCII characters that youâ€™d reasonably expect them to.\n\nIn the interest of being technically exacting, Unicode itself is not an encoding. Rather, Unicode is implemented by different character encodings, which youâ€™ll see soon. Unicode is better thought of as a map (something like a dict) or a 2-column database table. It maps characters (like \"a\", \"Â¢\", or even \"á‰ˆ\") to distinct, positive integers. A character encoding needs to offer a bit more.\n\nUnicode contains virtually every character that you can imagine, including additional non-printable ones too. One of my favorites is the pesky right-to-left mark, which has code point 8207 and is used in text with both left-to-right and right-to-left language scripts, such as an article containing both English and Arabic paragraphs.\n\nNote: The world of character encodings is one of many fine-grained technical details over which some people love to nitpick about. One such detail is that only 1,111,998 of the Unicode code points are actually usable, due to a couple of archaic reasons.\n\nUnicode vs UTF-8\n\nIt didnâ€™t take long for people to realize that all of the worldâ€™s characters could not be packed into one byte each. Itâ€™s evident from this that modern, more comprehensive encodings would need to use multiple bytes to encode some characters.\n\nYou also saw above that Unicode is not technically a full-blown character encoding. Why is that?\n\nThere is one thing that Unicode doesnâ€™t tell you: it doesnâ€™t tell you how to get actual bits from textâ€”just code points. It doesnâ€™t tell you enough about how to convert text to binary data and vice versa.\n\nUnicode is an abstract encoding standard, not an encoding. Thatâ€™s where UTF-8 and other encoding schemes come into play. The Unicode standard (a map of characters to code points) defines several different encodings from its single character set.\n\nUTF-8 as well as its lesser-used cousins, UTF-16 and UTF-32, are encoding formats for representing Unicode characters as binary data of one or more bytes per character. Weâ€™ll discuss UTF-16 and UTF-32 in a moment, but UTF-8 has taken the largest share of the pie by far.\n\nThat brings us to a definition that is long overdue. What does it mean, formally, to encode and decode?\n\nEncoding and Decoding in Python 3\n\nPython 3â€™s str type is meant to represent human-readable text and can contain any Unicode character.\n\nThe bytes type, conversely, represents binary data, or sequences of raw bytes, that do not intrinsically have an encoding attached to it.\n\nEncoding and decoding is the process of going from one to the other:\n\nIn .encode() and .decode(), the encoding parameter is \"utf-8\" by default, though itâ€™s generally safer and more unambiguous to specify it:\n\nPython\n\n>>> \"rÃ©sumÃ©\".encode(\"utf-8\") b'r\\xc3\\xa9sum\\xc3\\xa9' >>> \"El NiÃ±o\".encode(\"utf-8\") b'El Ni\\xc3\\xb1o' >>> b\"r\\xc3\\xa9sum\\xc3\\xa9\".decode(\"utf-8\") 'rÃ©sumÃ©' >>> b\"El Ni\\xc3\\xb1o\".decode(\"utf-8\") 'El NiÃ±o'\n\nCopied!\n\nThe results of str.encode() is a bytes object. Both bytes literals (such as b\"r\\xc3\\xa9sum\\xc3\\xa9\") and the representations of bytes permit only ASCII characters.\n\nThis is why, when calling \"El NiÃ±o\".encode(\"utf-8\"), the ASCII-compatible \"El\" is allowed to be represented as it is, but the n with tilde is escaped to \"\\xc3\\xb1\". That messy-looking sequence represents two bytes, 0xc3 and 0xb1 in hex:\n\nPython\n\n>>> \" \".join(f\"{i:08b}\" for i in (0xc3, 0xb1)) '11000011 10110001'\n\nCopied!\n\nThat is, the character Ã± requires two bytes for its binary representation under UTF-8.\n\nNote: If you type help(str.encode), youâ€™ll probably see a default of encoding='utf-8'. Be careful about excluding this and just using \"rÃ©sumÃ©\".encode(), because the default may be different in Windows prior to Python 3.6.\n\nPython 3: All-In on Unicode\n\nPython 3 is all-in on Unicode and UTF-8 specifically. Hereâ€™s what that means:\n\nPython 3 source code is assumed to be UTF-8 by default. This means that you donâ€™t need # -*- coding: UTF-8 -*- at the top of .py files in Python 3.\n\nAll text (str) is Unicode by default. Encoded Unicode text is represented as binary data (bytes). The str type can contain any literal Unicode character, such as \"Î”v / Î”t\", all of which will be stored as Unicode.\n\nPython 3 accepts many Unicode code points in identifiers, meaning rÃ©sumÃ© = \"~/Documents/resume.pdf\" is valid if this strikes your fancy.\n\nPythonâ€™s re module defaults to the re.UNICODE flag rather than re.ASCII. This means, for instance, that r\"\\w\" matches Unicode word characters, not just ASCII letters.\n\nThe default encoding in str.encode() and bytes.decode() is UTF-8.\n\nThere is one other property that is more nuanced, which is that the default encoding to the built-in open() is platform-dependent and depends on the value of locale.getpreferredencoding():\n\nPython\n\n>>> # Mac OS X High Sierra >>> import locale >>> locale.getpreferredencoding() 'UTF-8' >>> # Windows Server 2012; other Windows builds may use UTF-16 >>> import locale >>> locale.getpreferredencoding() 'cp1252'\n\nCopied!\n\nAgain, the lesson here is to be careful about making assumptions when it comes to the universality of UTF-8, even if it is the predominant encoding. It never hurts to be explicit in your code.\n\nOne Byte, Two Bytes, Three Bytes, Four\n\nA crucial feature is that UTF-8 is a variable-length encoding. Itâ€™s tempting to gloss over what this means, but itâ€™s worth delving into.\n\nThink back to the section on ASCII. Everything in extended-ASCII-land demands at most one byte of space. You can quickly prove this with the following generator expression:\n\nPython\n\n>>> all(len(chr(i).encode(\"ascii\")) == 1 for i in range(128)) True\n\nCopied!\n\nUTF-8 is quite different. A given Unicode character can occupy anywhere from one to four bytes. Hereâ€™s an example of a single Unicode character taking up four bytes:\n\nPython\n\n>>> ibrow = \"ðŸ¤¨\" >>> len(ibrow) 1 >>> ibrow.encode(\"utf-8\") b'\\xf0\\x9f\\xa4\\xa8' >>> len(ibrow.encode(\"utf-8\")) 4 >>> # Calling list() on a bytes object gives you >>> # the decimal value for each byte >>> list(b'\\xf0\\x9f\\xa4\\xa8') [240, 159, 164, 168]\n\nCopied!\n\nThis is a subtle but important feature of len():\n\nThe length of a single Unicode character as a Python str will always be 1, no matter how many bytes it occupies.\n\nThe length of the same character encoded to bytes will be anywhere between 1 and 4.\n\nThe table below summarizes what general types of characters fit into each byte-length bucket:\n\nDecimal Range Hex Range Whatâ€™s Included Examples 0 to 127 \"\\u0000\" to \"\\u007F\" U.S. ASCII \"A\", \"\\n\", \"7\", \"&\" 128 to 2047 \"\\u0080\" to \"\\u07FF\" Most Latinic alphabets* \"Ä™\", \"Â±\", \"ÆŒ\", \"Ã±\" 2048 to 65535 \"\\u0800\" to \"\\uFFFF\" Additional parts of the multilingual plane (BMP)** \"à´¤\", \"á„‡\", \"á®ˆ\", \"â€°\" 65536 to 1114111 \"\\U00010000\" to \"\\U0010FFFF\" Other*** \"ð•‚\", \"ð€€\", \"ðŸ˜“\", \"ðŸ‚²\",\n\n*Such as English, Arabic, Greek, and Irish\n\n**A huge array of languages and symbolsâ€”mostly Chinese, Japanese, and Korean by volume (also ASCII and Latin alphabets)\n\n***Additional Chinese, Japanese, Korean, and Vietnamese characters, plus more symbols and emojis\n\nNote: In the interest of not losing sight of the big picture, there is an additional set of technical features of UTF-8 that arenâ€™t covered here because they are rarely visible to a Python user.\n\nFor instance, UTF-8 actually uses prefix codes that indicate the number of bytes in a sequence. This enables a decoder to tell what bytes belong together in a variable-length encoding, and lets the first byte serve as an indicator of the number of bytes in the coming sequence.\n\nWikipediaâ€™s UTF-8 article does not shy away from technical detail, and there is always the official Unicode Standard for your reading enjoyment as well.\n\nWhat About UTF-16 and UTF-32?\n\nLetâ€™s get back to two other encoding variants, UTF-16 and UTF-32.\n\nThe difference between these and UTF-8 is substantial in practice. Hereâ€™s an example of how major the difference is with a round-trip conversion:\n\nPython\n\n>>> letters = \"Î±Î²Î³Î´\" >>> rawdata = letters.encode(\"utf-8\") >>> rawdata.decode(\"utf-8\") 'Î±Î²Î³Î´' >>> rawdata.decode(\"utf-16\") # ðŸ˜§ 'ë‡Žë‹ŽëŽë“Ž'\n\nCopied!\n\nIn this case, encoding four Greek letters with UTF-8 and then decoding back to text in UTF-16 would produce a text str that is in a completely different language (Korean).\n\nGlaringly wrong results like this are possible when the same encoding isnâ€™t used bidirectionally. Two variations of decoding the same bytes object may produce results that arenâ€™t even in the same language.\n\nThis table summarizes the range or number of bytes under UTF-8, UTF-16, and UTF-32:\n\nEncoding Bytes Per Character (Inclusive) Variable Length UTF-8 1 to 4 Yes UTF-16 2 to 4 Yes UTF-32 4 No\n\nOne other curious aspect of the UTF family is that UTF-8 will not always take up less space than UTF-16. That may seem mathematically counterintuitive, but itâ€™s quite possible:\n\nPython\n\n>>> text = \"è¨˜è€… é„­å•Ÿæº ç¾…æ™ºå …\" >>> len(text.encode(\"utf-8\")) 26 >>> len(text.encode(\"utf-16\")) 22\n\nCopied!\n\nThe reason for this is that the code points in the range U+0800 through U+FFFF (2048 through 65535 in decimal) take up three bytes in UTF-8 versus only two in UTF-16.\n\nIâ€™m not by any means recommending that you jump aboard the UTF-16 train, regardless of whether or not you operate in a language whose characters are commonly in this range. Among other reasons, one of the strong arguments for using UTF-8 is that, in the world of encoding, itâ€™s a great idea to blend in with the crowd.\n\nNot to mention, itâ€™s 2019: computer memory is cheap, so saving 4 bytes by going out of your way to use UTF-16 is arguably not worth it.\n\nPython String Literals: Ways to Skin a Cat\n\nRather than using the str() constructor, itâ€™s commonplace to type a str literally:\n\nPython\n\n>>> meal = \"shrimp and grits\"\n\nCopied!\n\nThat may seem easy enough. But the interesting side of things is that, because Python 3 is Unicode-centric through and through, you can â€œtypeâ€ Unicode characters that you probably wonâ€™t even find on your keyboard. You can copy and paste this right into a Python 3 interpreter shell:\n\nPython\n\n>>> alphabet = 'Î±Î²Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¾Î¿Ï€ÏÏ‚ÏƒÏ„Ï…Ï†Ï‡Ïˆ' >>> print(alphabet) Î±Î²Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¾Î¿Ï€ÏÏ‚ÏƒÏ„Ï…Ï†Ï‡Ïˆ\n\nCopied!\n\nBesides placing the actual, unescaped Unicode characters in the console, there are other ways to type Unicode strings as well.\n\nOne of the densest sections of Pythonâ€™s documentation is the portion on lexical analysis, specifically the section on string and bytes literals. Personally, I had to read this section about one, two, or maybe nine times for it to really sink in.\n\nPart of what it says is that there are up to six ways that Python will allow you to type the same Unicode character.\n\nThe first and most common way is to type the character itself literally, as youâ€™ve already seen. The tough part with this method is finding the actual keystrokes. Thatâ€™s where the other methods for getting and representing characters come into play. Hereâ€™s the full list:\n\nEscape Sequence Meaning How To Express \"a\" \"\\ooo\" Character with octal value ooo \"\\141\" \"\\xhh\" Character with hex value hh \"\\x61\" \"\\N{name}\" Character named name in the Unicode database \"\\N{LATIN SMALL LETTER A}\" \"\\uxxxx\" Character with 16-bit (2-byte) hex value xxxx \"\\u0061\" \"\\Uxxxxxxxx\" Character with 32-bit (4-byte) hex value xxxxxxxx \"\\U00000061\"\n\nHereâ€™s some proof and validation of the above:\n\nPython\n\n>>> ( ... \"a\" == ... \"\\x61\" == ... \"\\N{LATIN SMALL LETTER A}\" == ... \"\\u0061\" == ... \"\\U00000061\" ... ) True\n\nCopied!\n\nNow, there are two main caveats:\n\nNot all of these forms work for all characters. The hex representation of the integer 300 is 0x012c, which simply isnâ€™t going to fit into the 2-hex-digit escape code \"\\xhh\". The highest code point that you can squeeze into this escape sequence is \"\\xff\" (\"Ã¿\"). Similarly for \"\\ooo\", it will only work up to \"\\777\" (\"Ç¿\").\n\nFor \\xhh, \\uxxxx, and \\Uxxxxxxxx, exactly as many digits are required as are shown in these examples. This can throw you for a loop because of the way that Unicode tables conventionally display the codes for characters, with a leading U+ and variable number of hex characters. The key is that Unicode tables most often do not zero-pad these codes.\n\nFor instance, if you consult unicode-table.com for information on the Gothic letter faihu (or fehu), \"ð†\", youâ€™ll see that it is listed as having the code U+10346.\n\nHow do you put this into \"\\uxxxx\" or \"\\Uxxxxxxxx\"? Well, you canâ€™t fit it in \"\\uxxxx\" because itâ€™s a 4-byte character, and to use \"\\Uxxxxxxxx\" to represent this character, youâ€™ll need to left-pad the sequence:\n\nPython\n\n>>> \"\\U00010346\" 'ð†'\n\nCopied!\n\nThis also means that the \"\\Uxxxxxxxx\" form is the only escape sequence that is capable of holding any Unicode character.\n\nNote: Hereâ€™s a short function to convert strings that look like \"U+10346\" into something Python can work with. It uses str.zfill():\n\nPython\n\n>>> def make_uchr(code: str): ... return chr(int(code.lstrip(\"U+\").zfill(8), 16)) >>> make_uchr(\"U+10346\") 'ð†' >>> make_uchr(\"U+0026\") '&'\n\nCopied!\n\nOther Encodings Available in Python\n\nSo far, youâ€™ve seen four character encodings:\n\nASCII\n\nUTF-8\n\nUTF-16\n\nUTF-32\n\nThere are a ton of other ones out there.\n\nOne example is Latin-1 (also called ISO-8859-1), which is technically the default for the Hypertext Transfer Protocol (HTTP), per RFC 2616. Windows has its own Latin-1 variant called cp1252.\n\nNote: ISO-8859-1 is still very much present out in the wild. The requests library follows RFC 2616 â€œto the letterâ€ in using it as the default encoding for the content of an HTTP or HTTPS response. If the word â€œtextâ€ is found in the Content-Type header, and no other encoding is specified, then requests will use ISO-8859-1.\n\nThe complete list of accepted encodings is buried way down in the documentation for the codecs module, which is part of Pythonâ€™s Standard Library.\n\nThereâ€™s one more useful recognized encoding to be aware of, which is \"unicode-escape\". If you have a decoded str and want to quickly get a representation of its escaped Unicode literal, then you can specify this encoding in .encode():\n\nPython\n\n>>> alef = chr(1575) # Or \"\\u0627\" >>> alef_hamza = chr(1571) # Or \"\\u0623\" >>> alef, alef_hamza ('Ø§', 'Ø£') >>> alef.encode(\"unicode-escape\") b'\\\\u0627' >>> alef_hamza.encode(\"unicode-escape\") b'\\\\u0623'\n\nCopied!\n\nYou Know What They Say About Assumptionsâ€¦\n\nJust because Python makes the assumption of UTF-8 encoding for files and code that you generate doesnâ€™t mean that you, the programmer, should operate with the same assumption for external data.\n\nLetâ€™s say that again because itâ€™s a rule to live by: when you receive binary data (bytes) from a third party source, whether it be from a file or over a network, the best practice is to check that the data specifies an encoding. If it doesnâ€™t, then itâ€™s on you to ask.\n\nAll I/O happens in bytes, not text, and bytes are just ones and zeros to a computer until you tell it otherwise by informing it of an encoding.\n\nHereâ€™s an example of where things can go wrong. Youâ€™re subscribed to an API that sends you a recipe of the day, which you receive in bytes and have always decoded using .decode(\"utf-8\") with no problem. On this particular day, part of the recipe looks like this:\n\nPython\n\n>>> data = b\"\\xbc cup of flour\"\n\nCopied!\n\nIt looks as if the recipe calls for some flour, but we donâ€™t know how much:\n\nPython\n\n>>> data.decode(\"utf-8\") Traceback (most recent call last): File \"<stdin>\", line 1, in <module> UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbc in position 0: invalid start byte\n\nCopied!\n\nUh oh. Thereâ€™s that pesky UnicodeDecodeError that can bite you when you make assumptions about encoding. You check with the API host. Lo and behold, the data is actually sent over encoded in Latin-1:\n\nPython\n\n>>> data.decode(\"latin-1\") 'Â¼ cup of flour'\n\nCopied!\n\nThere we go. In Latin-1, every character fits into a single byte, whereas the â€œÂ¼â€ character takes up two bytes in UTF-8 (\"\\xc2\\xbc\").\n\nThe lesson here is that it can be dangerous to assume the encoding of any data that is handed off to you. Itâ€™s usually UTF-8 these days, but itâ€™s the small percentage of cases where itâ€™s not that will blow things up.\n\nIf you really do need to abandon ship and guess an encoding, then have a look at the chardet library, which uses methodology from Mozilla to make an educated guess about ambiguously encoded text. That said, a tool like chardet should be your last resort, not your first.\n\nOdds and Ends: unicodedata\n\nWe would be remiss not to mention unicodedata from the Python Standard Library, which lets you interact with and do lookups on the Unicode Character Database (UCD):\n\nPython\n\n>>> import unicodedata >>> unicodedata.name(\"â‚¬\") 'EURO SIGN' >>> unicodedata.lookup(\"EURO SIGN\") 'â‚¬'\n\nCopied!\n\nWrapping Up\n\nIn this article, youâ€™ve decoded the wide and imposing subject of character encoding in Python.\n\nYouâ€™ve covered a lot of ground here:\n\nFundamental concepts of character encodings and numbering systems\n\nInteger, binary, octal, hex, str, and bytes literals in Python\n\nPythonâ€™s built-in functions related to character encoding and numbering systems\n\nPython 3â€™s treatment of text versus binary data\n\nNow, go forth and encode!\n\nResources\n\nFor even more detail about the topics covered here, check out these resources:\n\nJoel Spolsky: The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)\n\nDavid Zentgraf: What every programmer absolutely, positively needs to know about encodings and character sets to work with text\n\nMozilla: A composite approach to language/encoding detection\n\nWikipedia: UTF-8\n\nJohn Skeet: Unicode and .NET\n\nCharles Petzold: Code: The Hidden Language of Computer Hardware and Software\n\nNetwork Working Group, RFC 3629: UTF-8, a transformation format of ISO 10646\n\nUnicode Technical Standard #18: Unicode Regular Expressions\n\nThe Python docs have two pages on the subject:\n\nWhatâ€™s New in Python 3.0\n\nUnicode HOWTO"
    }
}