{
    "id": "dbpedia_5795_3",
    "rank": 98,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/",
        "read_more_link": "",
        "language": "en",
        "title": "Logicality and the picture theory of language",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-springeropen.png",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figa_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figb_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figc_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figd_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Fige_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figf_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figg_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figh_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figi_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figj_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figk_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figl_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figm_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Fign_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figo_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figp_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figq_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figr_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figs_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figt_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figu_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figv_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figw_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figx_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figy_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figz_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figab_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figac_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figad_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figae_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figaf_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figag_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/bin/11229_2024_4549_Figaa_HTML.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Tue Trinh"
        ],
        "publish_date": "2024-08-29T00:00:00",
        "summary": "",
        "meta_description": "I argue that there is tension in Wittgenstein’s position on trivialities (i.e. tautologies and contradictions) in the Tractatus, as it contains the following claims: (A) sentences are pictures; (B) trivialties are not pictures; (C) trivialities ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11021330/",
        "text": "The picture theory of language\n\nWittgenstein (1921), commonly known as Tractatus Logico-Philosophicus,1 purports to have found the conclusive solution to all philosophical problems (“die Probleme endgültig gelöst zu haben”). This solution consists in showing that there are really no problems, or more precisely, that the formulation of these problems (“die Fragestellung dieser Probleme”) will be recognized as gibberish, once the logic of our language (“die Logik unserer Sprache”) is understood.\n\nThe main contribution of the Tractatus, in my opinion, is the thesis that “the logic of our language” is to be identified with what has traditionally been called “grammar”. Grammar, in the classic sense, is what distinguishes between sentences and non-sentences.2 It defines what a sentence is, thereby delineating what can be expressed as either true or false. This is precisely Wittgenstein’s stated objective in the Tractatus. “The book [...] aims to draw a limit [...] to the expression of thoughts,” he says in the preface. This limit, as he subsequently clarifies, will be drawn “in language”, and will serve to separate the intelligible from “nonsense”.3\n\nBut what does identifying logic with grammar amount to exactly? To repeat: grammar distinguishes between sentences and non-sentences. It accounts for the fact that (1a) is a sentence but (1b) is not, for example.\n\nLogic, on the other hand, is what distinguishes between valid and invalid arguments. It accounts for the fact, for example, that the inference in (2a) is justified but the inference in (2b) is not.\n\nThe suprising claim made by Wittgenstein in the Tractatus is that the phenomenon exemplified by (1) and the phenomenon exemplified by (2) should receive a unified explanation. Specifically, the contrast with respect to sentencehood and the contrast with respect to validity should be accounted for by one and the same theory. This theory will tell us what a sentence is and, in addition, will tell us, for any sentence ϕ, what other sentences are true if ϕ is true. Last but certainly not least, it will also dissolve all philosophical problems.\n\nThe theory in question is known as the “picture theory of language” (Keyt, 1964), henceforth PTL. The essence of PTL is presented in 4.01: “A sentence is a picture of reality”.4 Sentences, Wittgenstein maintains, are pictorial. They represent states of affairs in the same way as, say, the score of Schubert’s Unvollendete represents the sound of this symphony: “A gramophone record, the musical thought, the musical notation, the sound waves, all stand to one another in that internal relation of depicting that holds between language and world” (4.014). The structure of a sentence, then, is isomorphic to the structure of the state of affairs it describes (Daitz, 1953): “The configuration of simple signs in a propositional sign corresponds to the configuration of objects in a state of affairs” (3.21). To see how PTL accounts for both sentencehood and validity, we will discuss an example.5\n\nSuppose the linguistically relevant reality has three basic elements, i.e. three “objects” (“Gegenstände”): (i) John, (ii) Mary, and (iii) the property of smoking.6 Logical space would then contain four possible worlds: one where both John and Mary smoke, one where only John smokes, one where only Mary smokes, and one where neither of them smokes. Let us now consider two languages. The first is familiar: John is symbolized as j, Mary as m, smoking as s, that John smokes as s(j), that Mary doesn’t smoke as ¬s(m), that John smokes but Mary doesn’t as s(j)∧¬s(m), etc. We will call this language LF, with the subscript “F” being mnemonic for ‘Fregean’. The second language, call it LW, will be the one which approaches more closely the “pictorial” ideal envisioned by Wittgenstein. In LW, John is symbolized as a pebble , Mary as a marble , and smoking as a jar . The fact that an individual smokes or does not smoke will be represented by placing the symbol for that individual inside or outside of the symbol for smoking, respectively. We now compare some sentences in the two languages as to the correspondence between them and the states of affairs they describe.7\n\nLet us ask in what sense LW is “pictorial”, i.e. “isomorphic” to reality, but LF is not. First, note that a necessary condition for the isomorphism between two structures is that they have the same number of primitive elements. This condition is satisfied by LW but not LF. The reality to be represented has three objects: John, Mary, and smoking. LW has three basic symbols, i.e. names: the pebble, the marble, and the jar. This is not the case for LF, which has seven names: j, m, s, (, ), ¬, and ∧. Sentences of LW contain nothing but names hanging in one another “like the links of a chain” (2.03), i.e. by virtue of their form alone, just as in the represented states of affairs objects hang in one another without any kind of “logical frame” into which they fit (Hintikka, 1994). Sentences of LF, on the other hand, contain not only names but also “syncategorematic glue” (i.e. the brackets and the connectives) which holds them together. There is another sense in which LW is more pictorial than LF. Consider the shape of the names. In LF, the name for smoking is s, a letter, just like the names for John (j) and Mary (m). In LW, it is the jar, which differs from the pebble and the marble in that it is a container which allows the distinction to be made between things that are inside and things that are outside of it. The property of smoking, by nature, distinguishes between smokers and non-smokers. There is thus a higher degree of verisimilitude, in the relevant sense, between smoking and the jar than between smoking and the letter s.8\n\nThis last point about the shapes of names brings us to the issue of sentencehood. The claim, to repeat, is that PTL accounts for sentencehood: it includes sentences and excludes non-sentences. Let us start by considering what would be non-sentences in LF: j(s), s(s), m(j), etc. How are these excluded? Obviously, the shape of the symbols themselves would not do the job: writing s(j) is just as easy as writing j(s). What would be required is an extrinsic theory of syntax which (i) categorizes the basic symbols into different “parts of speech”, i.e. “types”, and then (ii) imposes rules of combination upon these types. For example, it would say that s is an adjective, j is a noun, and if α is an adjective and β is a noun then α(β) is a sentence but β(α) is not a sentence, etc.9 Let us now turn to LW. What would be the LW counterpart of the non-sentence j(s)? Well, it would be the jar placed inside the pebble. But we cannot place the jar inside the pebble: the forms of these symbols do not allow such a configuration. Thus, the pictorial counterpart of j(s) is ineffable.10 The same holds for the pictorial counterparts of s(s) and m(j): there is no way to place the jar inside of itself or the pebble inside of the marble. As we can see, there is no need for an extrinsic theory of syntax. The shapes of the symbols themselves determine which combinations are possible and which ones are not, thereby distinguishing between sentences and non-sentences. Grammar, thus, emerges from the pictorial nature of representation: PTL accounts for sentencehood.\n\nHow does PTL account for validity? Again, we first consider LF. What guarantees, for instance, that LF-3 entails LF-1 but not vice versa? Obviously, it cannot be the shape of the expressions themselves. The logic of LF, just like its syntax, has to be imposed extrinsically by way of a theory which tells us that the inference in (4a) is valid but the inference in (4b) is not.11\n\nLet us now ask a parallel question for LW: what guarantees that LW-3 entails LW-1 but not vice versa? The answer seems to be that the question itself is ridiculous. I can see, with my own eyes, that the pebble is inside of the jar in LW-3. There is no way for me not to see the pebble inside the jar when I see the pebble inside and the marble outside the jar. In other words, I cannot conceive of the possibility that LW-3 is true while LW-1 is false, simply because I see LW-1 in LW-3. What about the fact that LW-1 does not entail LW-3? Well, this fact is also obvious: looking at LW-1, I do not see the marble, which means I do not see the marble outside the jar, which means I do not see both the pebble inside the jar and the marble outside the jar. In other words, I do not see LW-3 in LW-1.12 If we had to posit “rules” which allow the inference from LW-3 to LW-1 but disallow the inference in the opposite direction, they would say something banal and empty like “Look!” or “Think!” Thus, rules of inference are “superfluous” for LW (5.132). “That the truth of one proposition follows from the truth of other propositions can be seen from the structure of the propositions” (5.13). Therefore, logic “take[s] care of itself” (5.473) (cf. McGinn, 2006). Logic, as it were, emerges from the pictorial nature of representation: PTL accounts for validity.\n\nFinally, how does PTL dissolve all philosophical problems? Here is Wittgenstein’s reasoning, as I see it. First, a “problem” exists only to the extent that it can be formulated. How is a problem formulated? By asking whether a sentence is true, which means, given PTL, asking whether a picture corresponds to reality. But pictures are empirical: we can only know whether they are true by observation (2.224, 2.225). This means that every problem can in principle be settled by observation, which is to say by natural science. Philosophy, however, “is not one of the natural sciences” (4.111). It then follows that there are no problems for philosophy to solve.\n\nMy main aim in the preceding paragraphs has been to argue that Wittgenstein’s picture theory of language (PTL) serves the double function of (i) distinguishing between sentences and non-sentences and (ii) distinguishing between valid and invalid arguments. I will now turn to a discussion on sentences that are either a contradiction or a tautology. Following a practice common in the linguistic literature, I will call these sentences “trivialities”. This, I should note, is not a term Wittgenstein uses in the Tractatus. My use of it is purely to reduce the number of words on the page: instead of saying “contradictions and tautologies” every time, I say “trivialities”.\n\nLet us start, again, with LF. Take s(j)∧¬s(j), for example. This is a contradiction. It is, of course, a sentence of LF, given that the syntax of LF should (i) include s(j) as a sentence, (ii) allow any sentence to be negated, and (iii) allow any two sentences to be conjoined.13 It follows, then, that the negation of s(j)∧¬s(j), i.e. ¬(s(j)∧¬s(j)), a tautology, is also a sentence.14 Thus, trivialities are sentences of LF. Now let us ask what the LW counterpart of s(j)∧¬s(j) would be. Presumably, it would be a configuration in which the pebble is inside as well as outside of the jar. This configuration, of course, is ineffable. Thus, contradictions in LF have no “translation” in LW. The shapes of the symbols in LW just do not allow such arrangements. What about tautologies, which are the negation of contradictions? Do they have LW translations? I propose that the answer is no. Note that tautologies are the negation of contradictions. Let us make the conjecture in (5).\n\nI will now make a brief excursus on NC. First, I emphasize that it is a conjecture. At this point, I do not have a general account of how negation works for such a pictorial language as LW. The cases we have considered are simple: ¬S(m) is represented by placing the marble outside of the jar, for example. But how do we represent ¬(S(j)∧¬S(m))? I do not have an answer. It is intuitively clear how conjunction is represented pictorially. But that is not the case for negation. And it is not clear to me, from what Wittgenstein says in the Tractatus, whether he has a cogent and general proposal with respect to pictorial negation. Hintikka (2000) and Eisenthal (2023) sketch some ideas which are, in my opinion, quite vague, and to the extent that I can make out what these authors say, I do not see how they would represent ¬(S(j)∧¬S(m)). Note that once we figure out how negation works pictorially, we will also have disjunction and implication, as these functions are definable in terms of negation and conjunction. For present purposes, I will assume NC, and leave the task of deriving this conjecture, either from Wittgenstein’s text or from elaborations of it, to future work. My hope is that the readers will not find NC so implausible as to stop reading.15 This is the end of the excursus.\n\nLet us now come back to the main discussion. Given NC and the fact that contradictions are ineffable in LW, it follows that tautologies are also ineffable in LW. Thus, LW excludes contradictions as well as tautologies, i.e. it excludes trivialities, from the set of sentences. This fact, of course, lies in the nature of pictures. A picture, as was mentioned above, is empirical: it has to match some state of affairs and fail to match some other. Thus, it cannot be trivial. Just as we cannot use musical notation to produce a score which matches every or no possible piece of music, we cannot use linguistic signs to construct a model of every or no possible state of affairs. At various places in the Tractatus, Wittgenstein seems to concede that trivialities are non-sentences. “Tautology and contradiction are not pictures of reality”, he admits in 4.462. It should then follow that they are non-sentences, since sentences, by hypothesis, are pictures of reality. “[P]ropositions that are true for every state of affairs cannot be combinations of signs at all”, Wittgenstein says in 4.466. And because they are not combinations of signs, their negations are not either: “Tautology and contradiction are the limiting cases of the combination of symbols, namely, their dissolution” (4.466). But Wittgenstein, curiously, stops short of considering trivialities non-sentences. He calls non-sentences, i.e. arrangement of signs that are excluded by logical syntax, “nonsensical” (“unsinnig”). For example, John likes and Socrates is identical would be nonsensical, because in both cases a transitive predicate is lacking its direct object, incurring a violation of what linguists call the Θ-Criterion.16 However, Wittgenstein insists that that is not the case with trivialities. He declares, explicitly, that “tautology and contradiction are [...] not nonsensical”, and confirms that they are “part of the symbolism” (4.4611). Thus, he takes trivialities to be sentences. This is baffling: given the theory Wittgenstein proposes (PTL), he should exclude trivialities from the symbolism, i.e. should consider them nonsensical, but he does not. It should be noted, nevertheless, that Wittgenstein does end up describing trivialities using a word which is very close to “nonsensical”. The word is “senseless” (“sinnlos”). “Tautology and contradiction are senseless”, he says in 4.461. Thus, non-sensicality and senselessness both implies non-interpretability, but only non-sensicality implies non-sentencehood (von Wright, 2006; Biletzki & Matar, 2021; Proops, to appear). The morphological and semantic similarity between “senseless” and “non-sensical”, I think, is not accidental. It suggests that Wittgenstein finds trivialities to be “almost” non-sentences. One might say he thinks they should be non-sentences but refrain from going as far as saying they actually are.\n\nThe question that arises at this point is whether there is inconsistency in Wittgenstein’s theory of language. I will consider, first, the negative answer. Suppose we say there is no inconsistency. The challenge we face would then be to make sense of the fact that Wittgenstein says\n\nHow would we do that? Well, let us claim that A has existential, not universal, quantificational force. Specifically, the word “sentences” in A means ‘some sentences’, not ‘all sentences’.17 Under this reading, A is compatible with B and C. This account, of course, requires us to say that PTL does not apply generally to all sentences. We need to exclude trivialities from its domain. One way to do that is to say that PTL applies only to what Wittgenstein calls “sinnvolle Sätze” (meaningful sentences). Trivialities are “sinnlos”, hence are not in the domain of PTL. Another way to exclude trivialities from PTL is to restrict PTL to atomic sentences. Trivialities cannot be atomic, since they involve at least one sentence and its negation, so they will not be in the domain of PTL. Restricting the domain of PTL, therefore, is a strategy to save Wittgenstein from inconsistency. It is not my aim, in this paper, to provide a conclusive argument for or against this strategy. I would just note here that I do not think it squares well with the text. Consider Wittgenstein’s use of the phrase “sinnvoller Satz”, for example. It is quite clear from the text that the adjective “sinnvoll” is not pleonastic: it restricts the set of sentences to a proper subset.18 But this fact strongly suggests that Wittgenstein’s use of “Satz” is not restricted. In other words, it suggests that the null hypothesis is correct: when Wittgenstein says “Satz”, he means ‘Satz’, and when he says “sinnvoller Satz”, he means ‘sinnvoller Satz’. Consequently, when he says “[d]er Satz is ein Bild der Wirklichkeit” (“sentences are pictures of realities”), he is not talking about a specific subset of sentences, but about sentences tout court.19 In fact, Eisenthal (2023) has argued, quite convincingly in my opinion, that there is textual evidence from both the Tractatus and Wittgenstein’s Notebooks (Wittgenstein, 1989) that “Wittgenstein consistently treated the picture theory as applying to all propositions” (Eisenthal, 2023, p. 165), and that “in many of Wittgenstein’s canonical statements to the effect that propositions are pictures, the claim is put forward in complete generality” (Eisenthal, 2023, p. 167).\n\nThus, while I acknowledge, and do not rule out, the possibility of making sense of A, B and C by interpreting A as an existential statement, i.e. by restricting the domain of PTL, I would like to explore an alternative. This alternative does not ask how A can be interpreted so that Wittgenstein’s theory is consistent, but accepts that the theory is inconsistent and asks why Wittgenstein commits to C. Note, first, that A and B are not inconsistent: they both follow from PTL. It is C in conjunction with A and B that causes a problem. Second, note that I am not claiming Wittgenstein is unaware of the inconsistency. I believe he is. He proposes a theory of language which is, in a way, overwhelmingly intuitive: symbols stand for objects, and configurations of symbols stand for configurations of objects. This is A. It is also overwhelmingly intuitive that such pictorial representations cannot be a priori true or a priori false, i.e. cannot be trivial. Wittgenstein realizes this, and stresses it in the text (2.225). This is B. The consequence of A and B is clearly that trivialities is not part of the language, because they cannot be pictured. Wittgenstein, however, says they are part of the language. This is C. Is he aware that C conflicts with A and B? I think he is, and I think that is why he calls trivialities “sinnlos”. Thus, they are sentences that are “defective” in some sense. One can say: they are halfway between “sinnvoll” and “unsinnig”. But this move by Wittgenstein, in my view, does not solve the problem. Grammar specifies a set of sentences. Something is either in the set or not. Saying that trivialities are in the set but defective does not resolve the conflict between A and B on the one hand, which together entail trivialities are not in the set, and C on the other, which says they are. Thus, what I am saying is not that Wittgenstein is unaware of the inconsistency in his theory, but that he tries but in the end fails to resolve it.20\n\nLet us now ask why Wittgenstein commits to C, which contradicts the theory he proposes. The reason, in my view, has a phenomenological component as well as a logical one. On the one hand, Wittgenstein experiences such expressions as (6a) and (6b) as sentences of the language, i.e. as structures which can be built using the rules of the grammar.\n\nOne the other hand, he interprets them as trivialities: he analyzes (6a) as ϕ∧¬ϕ, a contradiction, and (6b) as ϕ∨¬ϕ, a tautology. The experience and the interpretation, together, lead to Wittgenstein’s conclusion that trivialities are sentences, which is inconsistent with the rest of his theory. Restoring consistency to Wittgenstein’s position, then, requires contesting this conclusion, which means either contesting the experience or contesting the interpretation. There is, of course, no point in the first course of action: visceral experiences such as those pertaining to sentencehood are basic facts from which we start. It is left, then, to question Wittgenstein’s analysis of (6a) and (6b). I will now turn to the discussion of a hypothesis about natural language which says that this analysis is incorrect. More specifically, it says that (6a) and (6b) are perceived as sentences precisely because they are not trivial.\n\nLogicality\n\nThe hypothesis in question goes by the name of “Logicality”. Logicality states that universal grammar interfaces with a natural deductive system and filters out sentences expressing tautologies or contradictions (Chierchia, 2006; Del Pinal, 2019, 2022). In other words, Logicality claims that trivialities are ill-formed. I will present this intriguing thesis by discussing two cases, one illustrating the ill-formedness of contradictions, the other that of tautologies. Both pertain to the distribution of quantifiers, exemplified by universal every and existential a.\n\nBefore I proceed, a terminological clarification is in order. In section 1, I said grammar distinguishes between “sentences” and “non-sentences”. From now on I will speak of this distinction as one between “well-formed sentences” and “ill-formed sentences”, or equivalently, between “grammatical sentences” and “ungrammatical sentences”. Thus, the notion of sentencehood will be verbalized as one of “well-formedness” or “grammaticality”. Nothing of substance hinges on this change of labels, which is made just to bring our discussion closer to how linguists talk. The fact remains that some but not all arrangements of symbols are part of the language and grammar separates those that are (“sentences”, “well-formed sentences”, “grammatical sentences”) from those that are not (“non-sentences”, “ill-formed sentences”, “ungrammatical sentences”).21\n\nLet us start by considering the contrast in (7). Following standard practice, I will mark ill-formedness with #.\n\nA fact about exceptive constructions, i.e. sentences of the form D(P except E)(Q), is that they are well-formed only if D, the determiner, is universal.22 When D is existential, ill-formedness results.\n\nThis fact suggests that interpretation can be relevant for grammaticality. I will assume the standard semantics of quantifiers according to which they express relations between two sets. For every the relation is ‘is a subset of’, and for a, ‘has a non-empty intersection with’ (Barwise & Cooper, 1981; Heim & Kratzer, 1998).23\n\nOur intuition about (7a) is that it is a normal sentence, i.e. something that could be said and understood. On the other hand, we feel that (7b) is just gibberish: it sounds weird, and we don’t really know what it means. The most well-known account of the contrast is one proposed by von Fintel (1993). What is interesting about this account, and pertinent to our discussion, is that it explains the ill-formedness of (7b) as resulting from this sentence being contradictory. Specifically, von Fintel assigns to exceptive constructions the semantics in (9), where X−Y is the complement of Y in X, i.e. the set of things in X that are not in Y.\n\nThis analysis accomplishes two things at once. First, it captures the right meaning of (7a). Second, it determines (7a) to be contingent and (7b) to be trivial, thereby making a crucial distinction between the well-formed and the ill-formed sentence. Let us see how. Consider (7a) first. Given (9), this sentence is predicted to have the following truth condition.24\n\nTogether, (10a) and (10b) means that (i) John is a student, (ii) John did not come, and (iii) every other student came, as the reader is invited to verify for herself. This is precisely the truth condition which we intuitively associate with (7a). It is, of course, contingent: we get truth if John is the only student who did not come and falsehood otherwise. Note that C in (10b) ranges over all sets including ∅. As X- ∅ = X, we predict (11) to be an entailment of (10b), hence an entailment of (7a).\n\nNow let us apply (9) to (7b). The truth condition we get for this sentence is (12).\n\nThis condition, as it turns out, is trivial. Recall, again, that C can be ∅. Thus, we predict (13) to be an entailment of (12b), hence an entailment of (7b).\n\nObviously, (13) is contradictory: its first conjunct entails that a student came while its second conjunct says that this is not the case. This fact is considered by von Fintel to be responsible for the ill-formedness of (7b).25\n\nLet us now turn to an example which illustrates ill-formedness of a sentence due to its being a tautology. Consider the contrast between the two existential sentences in (14).26\n\nAgain, we see two sentences which are identical with respect to syntactic category and constituency: they are both of the form there(D(P)).27 What distinguishes them is the semantics of D: existential in (14a), universal in (14b). This case, then, is also one where interpretation seems to affect grammaticality, as the difference between (14a) and (14b) feels like that between a well-formed and an ill-formed sentence. The standard account for (14) is Barwise and Cooper (1981). What it amounts to, basically, is that the word there says that its argument is true of the universe of discourse U, i.e. the set of all entities. This semantics is given in (15). The truth condition predicted for (14a) and (14b) are spelled out in (15a) and (15b), respectively.28\n\nWhat (15a) says is that the set of flies in my soup is not empty. This condition, of course, is not trivial. It is met in case there is at least one fly in my soup and not met otherwise. What (15b) says, on the other hand, is trivial: since U is the set of everything, it is a superset of the set of flies in my soup, whether or not the latter is empty (given that ∅ is a subset of every set). It is this semantic difference between (14a) and (14b) which Barwise and Cooper (1981) take to be responsible for the grammatical contrast between these sentences.\n\nThe two cases we have just examined, (7) and (14), illutrate the claim that the language system interacts with logic. More specifically, it corroborates Logicality, which states that trivialites are filtered out as ill-formed. The cases pertain to the difference in distribution between universal and existential quantifiers and show how sentences can be analyzed so that a grammatical contrast aligns with a logical contrast: well-formed sentences are contingent, ill-formed sentences are trivial. Similar explanations have been proposed for many other phenomena, among which are the distinction between mass and count nouns (Chierchia, 1998, 2010), the distinction between individual-level and stage-level predicates (Magri, 2009), the distribution of polarity items (Krifka, 1995; Chierchia, 2013; Crnič, 2019), free choice (Menéndez-Benito, 2005; Crnič and Haida, 2020), numerals (Bylinina & Nouwen, 2018; Haida & Trinh, 2020, 2021), comparatives (Gajewski, 2008a), island effects (Fox & Hackl, 2006; Abrusán, 2007), question embedding (Uegaki & Sudo, 2017), just to name a few. The body of works carried out under the perspective of Logicality is large and growing.\n\nI will now turn to the discussion of a problem for Logicality and a solution to it. This solution will be the key to resolving the inconsistency in Wittgenstein’s position on trivialities.\n\nThe problem might have become quite obvious to the astute reader, who will have noticed something strange in what we have said so far. On the one hand, we claim that sentences such as (7b) and (14b), repeated below as (16a) and (17a), are ill-formed because they have the trivial entailments in (16b) and (17b), respectively.\n\nOn the other hand, we seem to have no problem accepting these trivial entailments themselves, or more precisely, the sentences we use to convey them, as perfectly grammatical. Neither (16b) nor (17b) are ill-formed. But how do we square this fact with Logicality? Doesn’t Logicality predict all four sentences in (16) and (17) to be ungrammatical? The problem, in fact, can be illustrated more simply, but more dramatically, by the sentences in (6), repeated below.\n\nIf Logicality is correct, grammar should mark both of these sentences as ill-formed, given that (18a) is a contradiction and (18b) a tautology. But it clearly doesn’t. We can debate the reasons why someone would use (18a) or (18b), but we cannot deny that that person speaks English. Our perception of someone who produces (16a) or (17a), on the other hand, is very different: we would think that he has not mastered English. Thus, (18a) and (18b) are clearly well-formed in a way that (16a) and (17a) are not.\n\nThe problem for Logicality, then, is that it excludes more sentences than it should. It predicts all trivialities to be ungrammatical, while in fact only some are. To solve this problem, we have to find a way to distinguish between trivialities that are well-formed, such as (18a) and (18b), and trivialities that are ill-formed, such as (16a) and (17a). The solution I am going to present is one proposed by Del Pinal (2019); Pistoia-Reda and Sauerland (2021); Del Pinal (2022), among others. It is sometimes refered to as “contextualism”.29 What it says is that natural language grammar contains a covert, context-sensitive “rescaling” operator, Rc, which attaches to non-logical expressions and modulates their meaning. The logical form of (18a) is then not (19a) but (19b).\n\nSimilarly, the logical form of (18b) is not (20a) but (20b).\n\nNote, importantly, that one and the same expression may attach to differently indexed rescaling operators. In other words, we allow non-logical terms to shift their meaning within the same sentence. The meaning of Rc(raining), then, does not have to be identical to that of Rc'(raining). This means (18a) has a non-trivial reading as saying ‘it is raining in some sense and not raining in some other sense’. In the same way, (18b) has a non-trivial reading. These readings kick in and rescue the sentences from being trivial, hence from being ill-formed. Speakers, however, may not be consciously aware of this process, just as they are not conciously aware of the fact that (16a) and (17a) are ill-formed because the former entails the contradiction in (16b) and the latter the tautology in (17b). The interaction between universal grammar and the natural deductive system takes place at a subconscious level. It results in intuitions on acceptability which speakers can viscerally experience but cannot explicate.\n\nThe question now is why the same rescaling process does not kick in and rescue (16a) and (17a) from being trivial, making them well-formed. Well, the answer is that even if it does kick in, it still cannot rescue these sentences from being trivial. Recall a condition on the rescaling operator: it can only attach to non-logical terms. Thus, it would not attach to except, every, a, and there, which are logical constants. Let us look at the logical form of (16a) and (17a).\n\nThe reader is invited to verify for herself that both (21a) and (21b) are trivial. Given the semantics proposed in (9), a(P except E)(Q) is contradictory under all values of P, E, and Q. Similarly, the semantics proposed in (15) predicts that there(every(P)) is tautologous under all values of P. Rescaling does not help in these cases.\n\nI will end this section by mentioning an issue which the proponents of Logicality must address and which is also raised by Wittgenstein in the Tractatus. This is the issue of how to distinguish between logical and non-logical constants? For Wittgenstein, the logical constants are those expressions that will disappear in the proper semantic analysis: what they express, namely entailment relations, would emerge from the pictorial nature of the symbols in the ideal notation. Until we succeed in constructing such a notation, however, we have to deal with logical constants in our non-ideal language. Wittgenstein says of such expressions that they “do not represent” (4.0312). This description more or less captures our intution about such words as every, a, except, and there. The rescaling story works under the assumption that these words are logical constants. It is true, in some sense, that they do not “represent” anything. However, this description turns out to be too vague. It is not clear what would prevent me from saying, for example, that every represents the relation ‘is a subset of’, which is the set of pairs <X,Y> such that X ⊆ Y. We need a more rigorous definition of logical constants.\n\nIt turns out, however, that such a definition is quite difficult to formulate.30 Gajewski (2003), based on ideas from previous works, suggests to define logical constants in terms of “permutation invariance”. Logical constants, then, would be those expressions whose denotation remains constant across permutations of individuals in the domain (Mautner, 1946; Mostowski, 1957; Tarski, 1986; van Benthem, 1989; McGee, 1996). This definition, for example, would include every in, and exclude student from, the set of logical constants. To illustrate, suppose our domain is {a,b,c}, where a and b are students while c is not. The denotation of student is then {a,b}. This set will become a different set, {b,c}, under the permutation [a → b,b → c,c → a], which means student is not permutation invariant, hence not a logical constant. In contrast, every will denote the set in (22).\n\nThis set will obviously remain the same under all permutations, as switching the individuals around does not affect whether a set is a subset of another set: {a} will still be a subset of {a,b}, hence the pair <{a},{a,b}> will still end up in the denotation of every, for example. This means every is a logical constant, a good result. Gajewski’s suggestion is widely known and cited. However, it clearly cannot be the whole story, as it classifies predicates like exists or is self-identical, which supposedly denote the universe of discourse U, as logical,31 even though these do not incur ill-formedness as we would expect (Abrusán, 2019; Del Pinal, 2022).\n\nNo matter how we modulate the meaning of man and student, the sets they denote will be a subset of U. There would then be no reading of these sentences in which they are not trivial. However, neither (23a) nor (23b) is ill-formed. This means that exists and self-identical are in fact not logical constants, as far as the language system is concerned, and that (23a) and (23b) can be analyzed as (24a) and (24b), where Rc(exists) and Rc(self-identical) do not denote U.\n\nTo the best of my knowledge, an adequate intensional definition of logical constants is still missing. At this stage, a wealth of data find illuminating explanations in terms of Logicality. These explanations appeal to an intuitive notion of “logical constants”, but the distinction they draw between logical and non-logical terms is, in the end, stipulative. It is, of course, also possible that the distinction will turn out to be essentially stipulative (Quine, 1951). The jury is still out.\n\nTransformative analysis\n\nLet us recap. In section 1, I argue that Wittgenstein takes trivialities to be well-formed even though the theory of language which he proposes, PTL, predicts them to be ill-formed. My hypothesis is that Wittgenstein’s inconsistency is rooted in his inadequate analysis of a class of natural language expressions: he analyzes a sentence such as (25), which is perceived to be perfectly well-formed, as having the logical form in (25a), which is a triviality. In section 2, I present a thesis recently developed in theoretical linguistics, Logicality, which provides a way to overcome this inadequacy: Logicality makes it possible, in fact necessary, to analyze (25) not as (25a) but as (25b), which is not a triviality.\n\nIn this section, I will comment on some points of contact between analytic philosophy and theoretical linguistics which have been brought into relief by our discussion.\n\nAnalytic philosophy began with the insight that the “logical form” of a sentence, i.e. one which captures its semantic properties, might be quite different from its “surface form”, i.e. one which captures its syntactic, morphological and phonological properties. To illustrate, consider the sentence in (26). Its surface form is (26a), while its logical form would be (26b).32\n\nOne can see how (26a) and (26b) differ with respect to their constituency. For example, there is no constituent of (26b) which corresponds to the object DP every boy in (26a). There are, in addition, four sentential constituents in (26b) – i.e. α, β, γ, and δ – while there is only one such constituent in (26a), namely S.33 The idea that (26b) could in principle be how (26) looks at some level of description constitutes a “revolution” in the way we think about natural language sentences: semantic analysis must be carried out on a structure different from one which inputs pronunciation or writing. Beaney (2016, p. 235) puts it succinctly: “[T]here is no decomposition without interpretation”. The term “interpretation” here is to be understood as ‘translation’ or ‘transformation’. Thus, semantic analysis consists of (i) the step of “transformative analysis” which translate the surface form of the sentence into its logical form, and (ii) the step of “decompositional analysis” which dissects the logical form and computes its consequences (Beaney, 2000, 2002, 2003, 2016, 2017).34\n\nIt is at the step of transformative analysis, I submit, that Wittgenstein commits an error with sentences such as those in (18). He takes it for granted that the two instances of rain are one and the same symbol. It never occured to him to see this as a case of homophony, i.e. a case of two different symbols, Rc(rain) and Rc'(rain), having one and the same pronunciation. Curiously, Wittgenstein does discuss homophony in the Tractatus: “In everyday language it occurs extremely often that the same word signifies in different ways – that is, belongs to different symbols” (3.323). He even provides an example: “In the proposition ‘Green is green’ – where the first word is a person’s name, the last an adjective – these words [...] involve different symbols” (3.323). Note that the homophonous symbols in this case, “Green” and “green”, belong to different syntactic categories (noun and adjective). It is also obvious that the meaning of the first, the person named Green, and the meaning of the second, the color green, are different. Thus, it is much easier to see homophony here than to see it in the case of Rc(rain) and Rc'(rain), where the two symbols not only belong to the same syntactic category (verb), but also have meanings which differ in a much more subtle way (‘rain in one sense’ and ‘rain in another sense’).\n\nBeaney’s dictum, that there is no decomposition without interpretation, implies that a sentence is associated with at least one structure which inputs pronunciation and one other structure which inputs interpretation. Transformative analysis is the step that relates the two. As it happens, the idea that a sentence is associated with more than one structure is foundational to modern linguistics. It brought about the “generative revolution” in the 1950’s (cf. Chomsky, 1988). In the current “minimalist” version of generative grammar which has established itself more or less as cannonical (Chomsky, 1991, 1995; Radford, 2004), a sentence is associated with two structures: a “phonological form” (PF) and a “logical form” (LF). PF inputs pronunciation while LF inputs interpretation. PF and LF are related by “transformational rules” which build complex structures from lexical items step by step.35 Note that the LF of a sentence, just like the logical form which results from transformative analysis, can differ drastically from how we hear the sentence or see it written on paper. For example, the LF of (26) is (27) (Heim & Kratzer, 1998; Fox, 2000, 2003).\n\nWe can thus witness an interesting parallel between the “analytic revolution” in philosophy and the “generative revolution” in linguistics. A notable fact is that the former came much earlier. Its beginning can be dated to Frege’s 1879 debut, Begriffsschrift, wherein he proposes quantificational predicate logic (Beaney, 2016, 228). The beginning of generative grammar, in contrast, came with Chomsky’s (1955) magnum opus The Logical Structure of Linguistic Theory, wherein he proposes transformations. And it would take the linguists about 20 years more to come up with the idea of LF as a structure which disambiguates scopal relations between quantificational elements in the sentence (May, 1977; Chomsky, 1981; Huang, 1982; May, 1985).36 What is the reason for this delay?\n\nThe answer, I believe, lies in the difference between early analytic philosophers and generative grammarians with respect to their view on the surface form of natural language sentences. For the former, it is more or less a mess. Serious investigation can only begin after transformative analysis, which is carried out by the philosopher contemplating on what the sentence means. However, the step of transformative analysis is itself shrouded in mystery: there is no theory of it. Coming up with the logical form of a sentence is, therefore, similar to scientific discovery in its spontaneous and revelatory nature. In contrast, generative grammarians take the relation between PF and LF to be systematic: both are derived by transformational rules, which are codified in a unified theory. This theory imposes constraints on possible sound–meaning associations and can thus account for intuitions which, I think, would remain puzzling to the philosophers. Take the phenomenon of “weak crossover”, for example. It is observed that (28a) can be associated with the meaning expressed by (28b) but (29a) cannot be associated with the meaning expressed by (29b). It is not clear how analytic philosophers would explain this contrast. Generative grammarians, on the other hand, have proposed several accounts of it (Koopman & Sportiche, 1983; Reinhart, 1983; May, 1985).\n\nPart of generative grammar, then, can be seen as a proposal on how transformative analysis really works, thereby providing a missing link in analytic philosophy, which considers this step a black box. This would also make sense of the fact that the grammarians’ LF came long after the philosophers’ logical form: it is understandable that it takes more time to figure out how something works than to realize that it works.\n\nIs there any missing link in generative grammar which is provided by analytic philosophy? At this point, I can only say “maybe”. Recall what Logicality claims: trivialities are ill-formed. The unacceptability of sentences excluded by Logicality is, crucially, of a different kind from that of sentences which violate “pragmatic” rules. To illustrate, compare (30a) and (30b).\n\nBoth sentences in (30) sound “odd”. However, there is a clear difference. A person who produces (30b) might be making a joke, or trying to be philosophical, or having some sort of mental problem, or all three, but she is speaking English.37 Her sentence is well-formed. In contrast, a person who produces (30a) is not speaking English. Whatever rules out (30a), therefore, must be a component of formal grammar. Obviously, it is not phonology or morphology. There are no illegitimate combinations of phonemes or morphemes in (30a). This means (30a) fails at syntax. There are two possibilities for a sentence to “fail at syntax”. The first is that it cannot be derived by syntactic rules: formal properties of the words just do not allow them to be put together to build the sentence. An apt metaphor for this scenario would be a computer constructed with parts that do not fit. The second possibility is that the sentence can be derived by syntactic rules but the output “crashes” at the interface between syntax and the interpretive systems: it is not accepted by these systems as legitimate input. A metaphor for this scenario would be a computer which is built with parts that fit perfectly but which has no power port. In both cases, we have a defective product of syntax. It is syntactic defect that gives sentences such as (30a) their distinctive feel of “gibberish”. As far as I know, proponents of Logicality share the view that sentences such as (30a) fail in the second way: they can be derived by the syntactic rules but crash at the syntax-semantics interface. In other words, semantics imposes a “contingency constraint” on the output of syntax (Abrusán, 2019). I have not encountered claims in the literature to the effect that trivialities cannot be derived by syntactic rules, and it is not hard to see why. Syntactic rules are commonly assumed to be “blind” to interpretation. What they care about is whether something is a determiner, not whether its quantificational force is universal or existential. In that sense, syntactic rules do not distinguish between a and every.\n\nA question that has not been raised, to the best of my knowledge, is why there should be a contingency constraint on the output of syntax. Why should structures which express trivialities be markedss as defective syntactic products? Analytic philosophy, I surmise, might help us towards settling this explanatory question. Specifically, the picture theory of language might provide a starting point for developing an answer to it. Thus, suppose we say that interpretation of syntactic structures means mapping them into expressions of a “translation language” TL which is, as it were, the “language of thought”.38 And suppose, furthermore, that TL is “pictorial” in the sense envisioned by Wittgenstein. Then trivialities would be marked as defective products of syntax for the reason that they are “untranslatable”. This is, of course, speculative. My objective in this paper is to point out a tension in Wittgenstein’s theory of language and argue that it can be resolved in light of recent advances in linguistic research. This objective, I believe, can be achieved independently of whether my speculation about TL has merits. I do hope, however, that future work will show that it does.39"
    }
}