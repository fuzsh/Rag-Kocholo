{
    "id": "dbpedia_3180_3",
    "rank": 29,
    "data": {
        "url": "https://arxiv.org/html/2401.13893v1",
        "read_more_link": "",
        "language": "en",
        "title": "A Survey on Indoor Visible Light Positioning Systems: Fundamentals, Applications, and Challenges",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/x1.png",
            "https://arxiv.org/html/x2.png",
            "https://arxiv.org/html/x3.png",
            "https://arxiv.org/html/x4.png",
            "https://arxiv.org/html/x5.png",
            "https://arxiv.org/html/x6.png",
            "https://arxiv.org/html/x7.png",
            "https://arxiv.org/html/x8.png",
            "https://arxiv.org/html/x9.png",
            "https://arxiv.org/html/x10.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.\n\nfailed: cuted\n\nfailed: bigstrut\n\nAuthors: achieve the best HTML results from your LaTeX submissions by following these best practices.\n\nLicense: arXiv.org perpetual non-exclusive license\n\narXiv:2401.13893v1 [eess.SP] 25 Jan 2024\n\nA Survey on Indoor Visible Light Positioning Systems: Fundamentals, Applications, and Challenges\n\nZhiyu Zhu, Yang Yang, , Mingzhe Chen, , Caili Guo, , Julian Cheng, , and Shuguang Cui Z. Zhu and Y. Yang are with the Beijing Key Laboratory of Network System Architecture and Convergence, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: zhuzy@bupt.edu.cn; yangyang01@bupt.edu.cn). M. Chen is with the Department of Electrical and Computer Engineering and Institute for Data Science and Computing, University of Miami, Coral Gables, FL, 33146, USA (e-mail: mingzhe.chen@miami.edu). C. Guo is with the Beijing Laboratory of Advanced Information Networks, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: guocaili@bupt.edu.cn). J. Cheng is with the Faculty of Applied Science, School of Engineering, The University of British Columbia, Kelowna, BC V1V 1V7, Canada (e-mail: julian.cheng@ubc.ca). S. Cui is currently with the School of Science and Engineering, Shenzhen Research Institute of Big Data and Future Network of Intelligence Institute (FNii), the Chinese University of Hong Kong, Shenzhen, China, 518172 (email: shuguangcui@cuhk.edu.cn).\n\nAbstract\n\nThe growing demand for location-based services in areas like virtual reality, robot control, and navigation has intensified the focus on indoor localization. Visible light positioning (VLP), leveraging visible light communications (VLC), becomes a promising indoor positioning technology due to its high accuracy and low cost. This paper provides a comprehensive survey of VLP systems. In particular, since VLC lays the foundation for VLP, we first present a detailed overview of the principles of VLC. Then, we provide an in-depth overview of VLP algorithms. The performance of each positioning algorithm is also compared in terms of various metrics such as accuracy, coverage, and orientation limitation. Beyond the physical layer studies, the network design for a VLP system is also investigated, including multi-access technologies resource allocation, and light-emitting diode (LED) placements. Next, the applications of the VLP systems are overviewed. Finally, this paper outlines open issues, challenges, and future research directions for the research field. In a nutshell, this paper constitutes the first holistic survey on VLP from state-of-the-art studies to practical uses.\n\nIndex Terms—LED, visible light positioning, visible light communication, network design, positioning algorithms.\n\nI Introduction\n\nLocation-aware service is one of the most important functions of existing wireless networks, which enables a series of key applications such as the Internet of Things, automatic drive, and Industry 4.0 [1, 2, 3]. While wireless communication has seen remarkable advancements in recent decades, attaining low-cost and accurate indoor positioning through wireless systems remains a significant challenge. With the advent of the intelligent era, the demand for location-aware services intensifies. Various indoor positioning systems like radio-frequency (RF), ultra-wideband (UWB), WiFi, Zigbee, and others have emerged. While the existing indoor positioning technologies can either achieve accurate or low-cost positioning, it is still challenging to balance the cost and positioning performance. For instance, WiFi is one of the most widely deployed low-cost indoor wireless technology. However, WiFi can only achieve 1 to 7 meter positioning accuracy [4]. In contrast, UWB can achieve accurate positioning at a relatively high cost [5].\n\nIn this context, visible light positioning (VLP) with visible light communication (VLC) has gained increasing attention. VLP utilizes ubiquitous, economical light-emitting diodes (LEDs) as transmitters, which consistently flick at a speed that cannot be detected by humans and transmit unique positioning identification (ID) information. The popularity of LEDs makes VLP an easy-to-deploy choice in extensive applications since almost all indoor scenarios need to deploy LEDs, and many of them, such as offices, supermarkets, and subways, require LEDs for day illumination. Furthermore, owing to the directional propagation of visible light, its limited coverage necessitates a significant number of LEDs to ensure adequate illumination. However, this multitude of LEDs contributes to providing ample positioning information within indoor spaces. Moreover, due to the propagation characteristics of visible light, the signals are barely interfering with each other, and thus the receiver has more accurate measurements such as received signal strength (RSS) for positioning. Therefore, VLP can typically achieve accurate positioning due to the deterministic correspondence between the position and the received signals.\n\nAt the receiver, a commercial off-the-shelf camera or a photodiode (PD) can be used to capture the visible light signals. These devices—cameras and PDs—are widely integrated into smart terminals such as smartphones, tablets, and vehicles. These extensively equipped hardware devices can be used to receive visible light signals from LEDs by proper software drivers without additional hardware cost. By receiving the signals from one or multiple LEDs, the terminals employ positioning algorithm to estimate their precise location, underscoring the cost-effectiveness of VLP. In addition, VLP stands out as a secure option for electromagnetic-sensitive scenarios such as airplane cabins and hospitals. The combination of its cost-efficiency, utilization of prevalent hardware, and electromagnetic safety makes VLP a promising solution to tackle the ”last meter” positioning challenge.\n\nI-A Historical View of VLC and VLP\n\nI-A1 Development of VLC\n\nWhile VLC has garnered significant attention in recent years, the utilization of light for communication traces back centuries. From ancient times, light has served as a medium for transmitting information, evident in early practices like torch signals and smoke signals. Since the earliest times, the light was already used in information transmission, such as torches and smoke signals.\n\nIn the modern era, the roots of VLC extend back to the 1880s in Washington, D.C., with Alexander Graham Bell’s invention of the photophone. This groundbreaking device modulated sunlight to transmit speech, and the transmission distance can reach to several hundred meters. Fast forward over a century later, the advent of LED technology sparked a new era for VLC, presenting a fresh frontier for technological advancement. VLC based on LED dates back to 1999, when researchers from Hong Kong University first proposed to modulate visible light signals on LED [6, 7], and the proposed system has been used for intelligent transportation. Subsequently, in 2000, the Nakagawa Laboratory in Keio University, Japan, in collaboration with Sony’s Computer Science Laboratories, introduced the concept of employing visible light LEDs for indoor data transmission [8]. They successfully established a data transmission system using a white LED bulb within an indoor environment [9], marking a pivotal moment in VLC research in the 21st century. Following these developments, the first standardization for VLC, IEEE 802.15.7, was spearheaded by the IEEE 802.15 working group in 2011. The same year witnessed Harald Haas demonstrating Li-Fi in a TED Talk, and Li-Fi was named by Time magazine as one of the top 50 inventions. This milestone propelled VLC into an extensive realm of study encompassing modulation technology, multiple input multiple output (MIMO) technology, networking, and beyond [10]. Simultaneously, the exploration of VLC applications garnered increasing attention, extending into diverse fields including indoor access, positioning technology, and even underwater communication. The subsequent section will delve deeper into the history of VLP, outlining its evolution and early accomplishments.\n\nI-A2 Development of VLP\n\nAs VLC emerged, it spurred the development of VLP, a highly promising indoor positioning technology. This section will delve into the evolution of VLP, highlighting key milestones and achievements during its initial phases of development.\n\nThe origins of VLP can be traced back to as early as 2001, when Pang and Liu modulation of location codes within an LED location beacon system [11]. This innovative system used a complementary metal-oxide semiconductor (CMOS) vision sensor to extract location code for calibration of a vehicle positioning system, which may consist of a Global Positioning System, Inertial Navigation System (INS), and other sensors. While serving as an auxiliary positioning scheme, this work marked the pioneering introduction of LED beacons into positioning methodologies. The first dedicated VLP system tailored for indoor positioning emerged through the work of Horikawa et al. from Japan [12]. This system employed optical intensity modulation for LED illumination, transmitting visible light signals received by an image sensor. To compute the receiver’s position, at least three LEDs and two image sensors were required, assuming the receiver was oriented toward the ceiling. Then, in 2008, the “collinearity condition” was proposed to calculate not only the receiver’s position but also its orientation [13]. This condition stipulates that for each spatial point, its corresponding projection on the image plane, and the center of the lens of the receiver must be on the same straight line.\n\nFollowing the inception of VLP, researchers began to investigate innovative methods to enhance the performance of VLP. The earliest positioning techniques within VLP [11, 12, 13, 14] predominantly centered around image sensing, often coupled with trilateration or triangulation methodologies. For instance, the authors used two image sensors to establish the geometrical relationship between the distance and the position difference of the LED images and to calculate the distances between the center point of two lenses and three LEDs [14]. In a preliminary study [14], researchers employed two image sensors to establish a geometric relationship among the positional differences observed in LED images. Subsequently, distances were computed by analyzing the interplay between the center points of the lenses and three LEDs. The three distances were used to formulate the equations for location estimation according to triangulation. Subsequently, researchers identified and capitalized on geometric attributes such as circular features [15, 16] and rectangular features [17], leveraging these distinctive shapes to further refine the accuracy and efficiency of VLC-based positioning techniques.\n\nIn 2010, a pioneering step was taken with the introduction of the initial fingerprinting algorithm for VLP [18]. This innovative algorithm introduced the correlation sum ratio (CSR), a novel value derived from received signal strength (RSS) information obtained from four LEDs. CSR functioned as distinct fingerprints corresponding to various locations. Utilizing pre-assigned information obtained offline, a receiver could determine its position by analyzing CSRs received at any given location. Subsequently, Vongkulbhisal et al. formally categorized this approach as the fingerprinting-based positioning method in VLP [19]. Their work expanded on this concept, processing multiple signals from six transmitters to generate the fingerprint map in the offline stage or estimate its location in the online stage.\n\nThen, the technique based on RSS was introduced for VLP in 2011 [20]; however, it can only achieve a one-dimensional (1D) or two-dimensional (2D) positioning. Another RSS-based VLP scheme [21] was proposed in 2012. The proposed scheme used four LEDs and assumed Lambertian model to formulate a transmission equation group that can be solved for three-dimensional (3D) location estimation. Since, RSS algorithms are an extensively used algorithm in VLP.\n\nMeanwhile, researchers developed a time difference of arrival (TDOA) approach for VLP in 2011. For instance, Bai et al. proposed a TDOA-based VLP technique that can determine a vehicle’s position by using photodiodes LED traffic lights [22]. This approach leveraged TDOA measurements between the traffic light signals and two photodiodes, formulating equations to estimate position. They proposed two distinct methods tailored for scenarios involving one traffic light and those with two traffic lights. In addition, Jung et al. also developed a TDOA-based indoor positioning algorithm [23]. This method synchronized the frequency address of each LED. Using the Hilbert transform, they extracted the phase difference to estimate distances, subsequently employing these distance values to determine the receiver’s position.\n\nFurthermore, the pioneering VLP technique utilizing Angle of Arrival (AOA) was introduced in 2012 [24]. This method presented an AOA estimation algorithm tailored for pinpointing the location of LEDs within a VLC environment. Leveraging a circular PD array, the system aimed to accurately determine AOA, supplemented by a truncated weighting algorithm designed to bolster AOA estimation precision. In 2014, Yamazato and Haruyama used image sensors to detect AOAs of light emitted from visible light transmitters, which were further used in pose estimation [25]. The researchers also systematically introduced the pose and position estimation method by introducing the computer vision method.\n\nAs the field of VLP advanced, efforts intensified toward integrating two or more VLP techniques to enhance the accuracy and practicability of indoor positioning [25, 26]. Notably, these endeavors included amalgamating AOA with image sensing [25] and blending RSS with AOA [26] for more comprehensive pose and position estimation methodologies.\n\nTo offer a clear overview, we have encapsulated the historical evolution of VLC and VLP in Figure 1. Despite having about two decades of development, VLP has already achieved centimeter-level high positioning accuracy and is one of the most promising positioning technologies in indoor positioning. In Section III-B, we will delve into the principles and latest advancements across diverse VLP techniques to provide a comprehensive understanding.\n\nI-B Existing VLP Survey Papers\n\nPrevious surveys and tutorials on VLP [27, 28, 29, 30, 31, 32, 33] have contributed significantly to this field. For instance, Zhang and Kavehrad [27] offered a broad overview of VLP algorithm principles and the factors influencing their performance. However, this survey did not extensively delve into specific studies within each algorithm type. Hassan et al. [28] classified the existing VLP systems into PD-based systems and camera-based systems, and comprehensively investigated VLP algorithms in both systems. Do and Yoo [29] provided an in-depth survey on VLC-based positioning systems ranging from pioneering works to the state-of-the-art works, as well as the multiplexing techniques, current issues, and the research trends. Luo et al. [30] introduced LED technology and modulation schemes and provided an updated literature review of the VLP systems. Zhuang et al. [31] provided a clear distinction between PD-based VLP systems and camera-based VLP systems, and the parameters such as field of view (FoV) and Lambertian orders were also explicitly discussed.\n\nWhile extensive literature surveys have explored VLP algorithms and systems, they exhibit certain limitations. Current surveys primarily offer a general overview of principles, modulation schemes, and LED technologies in VLC. However, given that VLP is inherently tied to VLC, the integration between the two necessitates deeper investigation. Moreover, emerging hybrid algorithms in VLP remain unaddressed in these surveys. Despite the significant advantages VLP offers, complexities in some scenarios prompt the need for multiple positioning technologies. Regrettably, existing surveys overlook this critical need for comprehensive coverage. In complex scenarios, where precise positioning becomes challenging, employing a single technology may prove insufficient. This necessitates the integration of multiple positioning technologies, an area inadequately explored by current surveys. Practical issues, such as network design and LED placement, crucially impact the availability and performance of VLP systems but have been overlooked by existing surveys that predominantly focus on multiplexing techniques [28, 29, 33, 31, 30]. Network designs, especially LED placement, warrant thorough investigation as VLP algorithms heavily rely on the number of LEDs detectable by the receiver. Additionally, introductory literature on VLP often emphasizes accuracy, cost, and complexity of existing systems, but ignoring coverage, which is equally important. To bridge these gaps, a comparison between this survey and existing surveys is summarized in Table I.\n\nI-C Contributions\n\nThis paper’s primary contribution lies in its comprehensive survey of VLP. Our overarching objective is to encapsulate the emerging research advancements in VLP systems, addressing the significant opportunities and challenges in practical VLP systems. To the authors’ knowledge, this is the first survey that holistically gathers state-of-the-art and burgeoning research contributions spanning the foundational communication principles, intricate positioning algorithms, and real-world applications of VLP. Our key contributions encompass the following.\n\n•\n\nWe first overview PD- and camera-based VLC, which lay the foundation of PD- and camera-based VLP, respectively. In particular, the principles of both PD- and camera-based VLC are first introduced. Then, we analyze the constraints brought forward by VLC on VLP.\n\n•\n\nWe provide a detailed overview of VLP algorithms, including basic algorithms and new, advanced hybrid algorithms. We overview the existing algorithms from a new perspective of homogeneous VLP systems and heterogeneous positioning systems. Homogeneous VLP systems solely consist of VLP systems, while heterogeneous positioning systems integrate VLP with other positioning systems for positioning. For each category, we provide an introduction on their basic principles and a detailed survey of related research. Comparisons of the algorithms are also given in terms of the adopted receiver, the positioning accuracy, the coverage, and the orientation limitations.\n\n•\n\nWe overview a broad range of VLP’s applications such as industries, shopping malls, and museums. In addition, the network designs that are also significant for VLP’s large-scale applications are summarized, including multiple-access technologies, resource allocation, and LED placement. Then, we expose the challenges and opportunities brought forward by the use of VLP. We conclude by shedding light on the potential future works within each specific area.\n\nThe rest of this survey is organized as follows. In Section II, we introduce the basis of VLP. Section III presents the key types of VLP algorithms in homogeneous VLP systems and compares their performance in various respects. Section IV presents the positioning algorithms in heterogeneous positioning systems. In Section V, we discuss the VLP network designs and highlight the factors that can significantly affect the performance of VLP, while in Section VI, we overview the applications of VLP. In Section VII, we discuss the challenges and opportunities of VLP. Finally, we draw some key conclusions in Section VIII.\n\nII System Model\n\nVLC is a promising technology that provides high-speed, secure communication due to its abundant license-free spectrum, non-electromagnetic interference, and environmental protection [34, 35]. This section provides a concise overview of the VLC system model. The model is differentiated into two categories based on the type of receiver device employed: PD-based VLC and optical camera communication (OCC)-based VLC.\n\nII-A PD based VLC\n\nIn VLC, data is transmitted through the modulation of light waves from the visible spectrum, spanning wavelengths from 380 nm to 750 nm. Typically, LEDs are used as transmitters in VLC systems, including single-color LEDs and multi-color LEDs. The multi-color LED is packaged with multiple single-color LEDs. The most commonly used multi-color LED is red green blue (RGB) LED [36], which can be deemed as a special multi-channel transmitter that can be used to deploy multi-carrier modulation techniques [37]. Besides, VLC systems are typically equipped with PDs or cameras as receivers. PDs can typically support high-speed communications due to their high sensitivity to the light variations. In contrast, the achievable data rate of VLC based on camera typically has a low data rate due to the limited frame rate of the camera [38]. However, camera is still suitable for a series of low data rate applications such as positioning, and identification. In particular, cameras are extensively equipped in smart terminals such as smartphones and vehicles. In addition, cameras can distinguish the visible light signals from interference [39].\n\nIn VLC systems, the channel gain can be divided into the line of sight (LOS) part and the non-LOS (NLOS) part. A directed LOS link is illustrated in Fig. 2, which can be calculated as [40]\n\nh={A⁢(m+1)2⁢π⁢d2⁢g⁢(ψ)⁢cosm⁡(ϕ)⁢cos⁡(ψ),0<ψ≤ΨC0,ψ>ΨC,ℎcases𝐴𝑚12𝜋superscript𝑑2𝑔𝜓superscript𝑚italic-ϕ𝜓0𝜓subscriptΨCmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpression0𝜓subscriptΨCmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpression\\displaystyle{h}=\\left\\{{\\begin{array}[]{*{20}{l}}{\\frac{{A(m+1)}}{{2\\pi{d^{2}% }}}g(\\psi){{\\cos}^{m}}(\\phi)\\cos(\\psi)},&0<\\psi\\leq{\\Psi_{\\rm{C}}}\\\\ {0},&{\\psi>{\\Psi_{\\rm{C}}}},\\end{array}}\\right.italic_h = { start_ARRAY start_ROW start_CELL divide start_ARG italic_A ( italic_m + 1 ) end_ARG start_ARG 2 italic_π italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG italic_g ( italic_ψ ) roman_cos start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ( italic_ϕ ) roman_cos ( italic_ψ ) , end_CELL start_CELL 0 < italic_ψ ≤ roman_Ψ start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL 0 , end_CELL start_CELL italic_ψ > roman_Ψ start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT , end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL end_ROW end_ARRAY (3)\n\nwhere m=−ln⁡2ln⁡(cos⁡Φ1/2)𝑚2subscriptΦ12m=-\\frac{{\\ln 2}}{{\\ln(\\cos{\\Phi_{1/2}})}}italic_m = - divide start_ARG roman_ln 2 end_ARG start_ARG roman_ln ( roman_cos roman_Φ start_POSTSUBSCRIPT 1 / 2 end_POSTSUBSCRIPT ) end_ARG is the order of the Lambertian emission, Φ1/2subscriptΦ12{\\Phi_{1/2}}roman_Φ start_POSTSUBSCRIPT 1 / 2 end_POSTSUBSCRIPT is the semi-angle of LEDs at the half illumination power value, A𝐴Aitalic_A is the detector area, d𝑑ditalic_d is the distance between the LED and the PD, and g⁢(ψ)𝑔𝜓g(\\psi)italic_g ( italic_ψ ) denotes the gain of optical concentrator\n\ng⁢(ψ)={nr2sin2⁡ΨC,0<ψ≤ΨC0,ψ>ΨC,𝑔𝜓casessuperscriptsubscript𝑛𝑟2superscript2subscriptΨC0𝜓subscriptΨC0𝜓subscriptΨC\\displaystyle g(\\psi)=\\left\\{\\begin{array}[]{l}\\frac{{{n_{r}}^{2}}}{{{{\\sin}^{% 2}}{\\Psi_{\\rm{C}}}}},\\hskip 5.0pt0<\\psi\\leq{\\Psi_{\\rm{C}}}\\\\ 0,\\hskip 28.0pt\\psi>{\\Psi_{\\rm{C}}},\\end{array}\\right.italic_g ( italic_ψ ) = { start_ARRAY start_ROW start_CELL divide start_ARG italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG roman_sin start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_Ψ start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_ARG , 0 < italic_ψ ≤ roman_Ψ start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL 0 , italic_ψ > roman_Ψ start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT , end_CELL end_ROW end_ARRAY (6)\n\nwhere nrsubscript𝑛𝑟{{n_{r}}}italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT is the refractive index, ΨCsubscriptΨC{\\Psi_{\\rm{C}}}roman_Ψ start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT is the receiver field of vision semi-angle. In (3), ϕitalic-ϕ\\phiitalic_ϕ and ψ𝜓\\psiitalic_ψ is the angle of emergence with respect to the transmitter axis and the angle of incidence with respect to the receiver axis, respectively. Besides, the NLOS link consists of multiple NLOS paths, and the signals experience multiple reflections with a specific reflection order in each NLOS path [41]. The reflection order refers to the number of reflections that a multipath component goes through before it reaches the receiver. Most of the existing studies use paths with order less than three to represent the complete channel to improve computation efficiency [42].\n\nThe VLC-based indoor positioning system is one of the typical applications of VLC [28, 31].\n\nFig. 3 presents a typical indoor room equipped with multiple LEDs for lighting. Each LED has a unique location coordinates (x,y,z)𝑥𝑦𝑧\\left({x,y,z}\\right)( italic_x , italic_y , italic_z ) with respect to the origin 𝐎𝐎{\\bf{O}}bold_O, while the receiver determines its local position in the room based on the LED location coordinates. VLP is jointly achieved by the modulation module at the LED side and the demodulation modulate at the receiver side. In detail, a processor is used to encode addresses and identification (ID) numbers into bits at each LED, and then LED broadcasts its location information to the receiver. At the receiver, the optical signals are captured and converted into electrical current by PDs. Then, a positioning algorithm based on the measured signal is used to determine the location coordinates of the receiver. The PD-based VLP system requires a multiplexing protocol to distinguish signals emitted from different LEDs [43]. In contrast, in the camera-based VLP system, signals emitted from different LEDs are distinguished by taking successive images at high frequencies. In the next subsection, we will detail OCC and OCC-based VLP.\n\nII-B OCC based VLP\n\nOCC is equipped with cameras as receivers. The camera captures images or video streams of the intensity-modulated light sources and obtains the information by image processing [44].\n\nIn the OCC systems, a CMOS camera is typically utilized, which is widely employed in mobile devices such as smartphones. The rolling shutter exposure mode of CMOS camera is used to scan a horizontal row of pixels. In particular, when the LED is on, the bright pixels are captured at the scanned row of pixels, whereas when the LED is off, the dark fringe is captured at the scanned row of pixels. Hence, the intensity-modulated LEDs can be captured as interleaving bright and dark fringes in a single image, as shown in Fig. 4. Note that the modulation frequency of LEDs should be higher than the frame rate of the CMOS camera. Then, when capturing the encoded and modulated LEDs’ signals as fringe images, image processing techniques are applied to assist in decoding the information. The bright and dark rows are detected by calculating pixel values. Thus, an intensity sample stream can be obtained, which will be decoded to obtain the VLC information according to the coding rules.\n\nSimilar to PD-based VLP, the OCC-based VLP also requires the LED to broadcast its location and ID information. The receiver uses the camera to receive the optical signals and locates itself by positioning algorithms. The main difference is that OCC-based VLP does not rely on the channel model. It analyzes the relative position relation between the LEDs and the receiver by using imaging theory and geometric theory to achieve positioning.\n\nIII Homogeneous VLP systems\n\nIII-A Integration of VLC and VLP\n\nRecently, VLC and VLP have been identified as promising candidates to provide high-speed-data transmission and high-accuracy positioning in indoor environments [45, 46, 47, 48, 49, 50, 51, 52], where almost 80% of mobile data traffic is generated indoors [53]. Most of the existing studies only focused on VLC or VLP independently, while in practical indoor environments such as offices, hospitals, supermarkets, etc., it is desirable to provide both communication and positioning services at the same time [54]. So far, the research on the integration of VLC and VLP (VLCP) can be divided into three categories: interference cancellation, resource allocation, and network structure design.\n\nIn many indoor environments, a large number of LEDs are used for illumination, which may lead to inter-cell interference (ICI) in VLP and VLC. To solve this problem, the transmit time division multiplex (TDM) or frequency division multiplex (FDM) signals encoded with the unique position information of LED was appied [45]. A quasi-gapless integrated VLC and VLP system was experimentally demonstrated based on filter bank multicarrier-based subcarrier multiplexing [46]. A system that realizes VLC and VLP simultaneously in the same band using orthogonal frequency division multiple access (OFDMA) was proposed [47, 48], and the experiment results [47] showed that the OFDMA base VLC positioning system provides indoor positioning, data communications and flexible bandwidth allocation.\n\nGiven that the VLP signal operates within the limited time or wavelength resources designated for VLC, several researchers investigated the resource allocation in multi-user integrated VLC and VLP systems under different quality-of-service (QoS) and positioning accuracy requirements [49]. Yang et al. proposed a scheme that jointly optimized access point selection, bandwidth allocation, adaptive modulation, and power allocation to satisfy different QoS requirements [54]. Then, they also investigated a coordinated resource allocation approach to maximize the sum rate while guaranteeing the minimum data rates and positioning accuracy requirements [51].\n\nMoreover, in a bid to accommodate the massive connectivity needs and diverse service requirements of Internet of Things (IoT) devices, there’s a proposition for a multi-layer network architecture. This architecture integrates VLC and VLP into the fifth generation (5G) networks, aiming to support massive connectivity [52].\n\nIII-B Visible Light Positioning Algorithms\n\nExisting VLP algorithms can be classified into several categories: i) proximity, ii) TOA/TDOA, iii) AOA, iv) RSS, v) fingerprinting, vi) image sensing and vii) hybrid algorithm. In particular, hybrid algorithms refer to the ones that combine two or multiple algorithms. This section provides a comprehensive survey for each type of above algorithms.\n\nIII-B1 Proximity\n\nProximity is the simplest positioning technique among the existing VLP techniques. Proximity takes the location of the closest transmitter as the location of the receiver, and thus this technique can only provide an approximate position result. In particular, each transmitter constantly broadcasts a unique ID code [55], which is associated with a specific location of the transmitter stored in a database. The receiver captures and detects the ID information that will be matched to the locations of the transmitters so that the receiver can estimate its location. When simultaneously receiving ID signals from multiple transmitters, the PD-based receiver will determine its position by the transmitter with the strongest RSS value since RSS is closely related to the distance between the transmitter and the receiver. To deal with the data transmission and identification in such multiple signals scenarios, Cherntanomwong et al. [56] used TDM in their proximity-based VLP system for identification in the light overlapping area. In addition, the camera can also be leveraged for proximity. For instance, Xie et al. [57] identified the IDs of the transmitters by processing the proposed LED-ID recognition method on the captured image based on the Fisher discriminant analysis method.\n\nOverall, proximity is simple and highly feasible in practice. However, it can only provide limited positioning accuracy, which significantly depends on the density of the LEDs.\n\nIII-B2 Time of Arrival (TOA) And Time Difference of Arrival (TDOA)\n\nTOA is the absolute arrival time of signals from the transmitter to the receiver, which is a common technique for Global Positioning System (GPS) [58]. In particular, TOA algorithms estimate the distances between transmitters and receivers according to the arrival time of signals, and further use the estimated distances to derive the location of the receivers. In VLC-based TOA algorithms, once the propagation delay of the signal is measured, the distance can be obtained by multiplying the delay and the speed of light. Then, TOA typically utilizes the trilateration method to obtain the position of the receiver.\n\nFig. 7 illustrates the principle of the trilateration method. The LEDs locate at the center of the circles, and the radius denotes the distance between the transmitter and the receiver. Suppose that (x,y,z)𝑥𝑦𝑧\\left(x,y,z\\right)( italic_x , italic_y , italic_z ) is the coordinate of the receiver, (xi,yi,zi),i=1,2,…,nformulae-sequencesubscript𝑥𝑖subscript𝑦𝑖subscript𝑧𝑖𝑖12…𝑛\\left(x_{i},y_{i},z_{i}\\right),i=1,2,...,n( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_i = 1 , 2 , … , italic_n are the coordinates of n𝑛nitalic_n LEDs, and τi,i=1,2,…,nformulae-sequencesubscript𝜏𝑖𝑖12…𝑛\\tau_{i},i=1,2,...,nitalic_τ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_i = 1 , 2 , … , italic_n are the times of arrival. Then, the distance from LED i𝑖iitalic_i to the receiver can be expressed as\n\ndi=(x−xi)2+(y−yi)2+(z−zi)2=c⋅τisubscript𝑑𝑖superscript𝑥subscript𝑥𝑖2superscript𝑦subscript𝑦𝑖2superscript𝑧subscript𝑧𝑖2⋅𝑐subscript𝜏𝑖{{d}_{i}}=\\sqrt{{{\\left(x-{{x}_{i}}\\right)}^{2}}+{{\\left(y-{{y}_{i}}\\right)}^{% 2}}+{{(z-{{z}_{i}})}^{2}}}=c\\cdot{{\\tau}_{i}}italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = square-root start_ARG ( italic_x - italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_y - italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_z - italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG = italic_c ⋅ italic_τ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (7)\n\nwhere c𝑐citalic_c represents the speed of the light prorogation. On the 2-D plane, each TOA can determine a circle, and thus the location of the receiver can be determined by calculating the intersection of the three circles. In the 3-D space, each TOA can determine a sphere, and thus four LEDs are needed to form four spheres and intersect at a unique point, which is the location of the receiver. Wang et al. [59] proposed a TOA positioning system, in which, the LEDs and the receiver were assumed to be synchronized perfectly. The LEDs used the orthogonal frequency division multiplexing (OFDM) technique to transmit the signals, so that the receiver can separate the signals from different LEDs and estimate the location of the receiver.\n\nHowever, due to the imperfect hardware, the measured distance usually deviates slightly from the truth, and thus the drawn circles or spheres may not exactly intersect at a point. Instead, the intersection forms an overlapped area. Therefore, the least square method is applied to obtain the optimal solution [60], and the cost function can be expressed as\n\nF⁢(x,y)=∑i=1n(c⁢τi−(x−xi)2+(y−yi)2+(z−zi)2).𝐹𝑥𝑦superscriptsubscript𝑖1𝑛𝑐subscript𝜏𝑖superscript𝑥subscript𝑥𝑖2superscript𝑦subscript𝑦𝑖2superscript𝑧subscript𝑧𝑖2F(x,y)=\\sum\\limits_{i=1}^{n}{\\left(c{{\\tau}_{i}}-\\sqrt{{{\\left(x-{{x}_{i}}% \\right)}^{2}}+{{\\left(y-{{y}_{i}}\\right)}^{2}}+{{(z-{{z}_{i}})}^{2}}}\\right)}.italic_F ( italic_x , italic_y ) = ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_c italic_τ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - square-root start_ARG ( italic_x - italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_y - italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_z - italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ) . (8)\n\nSince the arrival time is typically rather short in VLP, TOA requires that transmitters and receivers have extremely accurate time synchronization, which is difficult to implement. Therefore, to avoid such rigorous requirements, a TDOA is proposed. TDOA algorithms typically need at least three receivers to measure the time difference between the receivers, and it only requires time synchronization among transmitters[61]. TDOA algorithms measure the propagation time difference between the mobile device and transmitters. Based on the time difference, the distance difference can also be derived. Letting the distances between the receiver and LED i𝑖iitalic_i be disubscript𝑑𝑖d_{i}italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and that between the receiver and LED j𝑗jitalic_j be djsubscript𝑑𝑗d_{j}italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, the distance difference between disubscript𝑑𝑖d_{i}italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and djsubscript𝑑𝑗d_{j}italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT can be expressed as\n\ndi⁢j=di−dj =⁢(x−xi)2+(y−yi)2+(z−zi)2−⁢(x−xj)2+(y−yj)2+(z−zj)2=c⁢(τi−τj).subscript𝑑𝑖𝑗subscript𝑑𝑖subscript𝑑𝑗 =superscript𝑥subscript𝑥𝑖2superscript𝑦subscript𝑦𝑖2superscript𝑧subscript𝑧𝑖2superscript𝑥subscript𝑥𝑗2superscript𝑦subscript𝑦𝑗2superscript𝑧subscript𝑧𝑗2𝑐subscript𝜏𝑖subscript𝜏𝑗\\begin{split}{{d}_{ij}}&={{d}_{i}}-{{d}_{j}}\\\\ &\\text{ =}\\sqrt{{{\\left(x-{{x}_{i}}\\right)}^{2}}+{{\\left(y-{{y}_{i}}\\right)}^{% 2}}+{{(z-{{z}_{i}})}^{2}}}-\\\\ &\\text{ }\\sqrt{{{\\left(x-{{x}_{j}}\\right)}^{2}}+{{\\left(y-{{y}_{j}}\\right)}^{2% }}+{{(z-{{z}_{j}})}^{2}}}=c\\left({{\\tau}_{i}}-{{\\tau}_{j}}\\right).\\\\ \\end{split}start_ROW start_CELL italic_d start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_CELL start_CELL = italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL = square-root start_ARG ( italic_x - italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_y - italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_z - italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG - end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL square-root start_ARG ( italic_x - italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_y - italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_z - italic_z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG = italic_c ( italic_τ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_τ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) . end_CELL end_ROW (9)\n\nAccording to (9), a hyperbolic positioning method can be used to determine the location of the receiver [62, 61]. The positioning principle of TDOA is shown in Fig. 6. Each distance difference can determine a hyperbola, where the two LEDs are the two focal points, and three hyperbolas corresponding to three LEDs can intersect at a point, which is the 2-D location of the receiver. Similarly, the 3-D location can be determined by four LEDs. T. H. Do et al. [61] proposed a positioning system based on TDOA values. In the system, the receiver was a single photo diode, which received pilot signals from the LEDs. The TDOA values of the pilot signals are used to estimate the location of the receiver. The proposed system can be employed easily since the receiver can achieve positioning without embedded ID information at the LEDs. In addition, J. H. Y. Nah et al. considered additive white Gaussian noise (AWGN) in the TDOA-based VLP system [62], and they proposed a Fuzzy logic algorithm and a Spring model to minimize the noise affect after position estimation. Then, a practical TDOA-based VLP system that used a virtual local oscillator to replace the real local one was proposed [63], which could reduce the hardware complexity. This sytem also applied cubic spline interpolation to the correlation function to reduce the rigorous requirement on the sampling rate and enhance the time resolution of cross correlation. Pergoloni et al. [64] proposed wavelength-based localization and color-based localization mechanisms by combining traditional RSS and TDOA approaches. They assumed that each anchor point used a unique spectral signature on the wavelength domain so that the receiver could identify it and compute its location through RSS or TDOA approaches. After that, the combination of TDOA with other received information, such as RSS and fingerprinting, was applied in the VLP systems [65, 66].\n\nIII-B3 Angle of Arrival (AOA)\n\nThe AOA algorithms estimate the location of the receiver based on the angles between the transmitters and receivers. Fig. 7 illustrates the principle of AOA algorithm. When the AOA information from multiple VLC links is obtained, the location of the receiver can be determined as the intersection of VLC links according to geometric relationships. Suppose that the angles of incidence of the receiver from two LEDs are θ1subscript𝜃1\\theta_{1}italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and θ2subscript𝜃2\\theta_{2}italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, respectively, and the coordinates of the receiver and the transmitters are (x,y)𝑥𝑦\\left(x,y\\right)( italic_x , italic_y ) and (xi,yi)subscript𝑥𝑖subscript𝑦𝑖\\left(x_{i},y_{i}\\right)( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), respectively. We have\n\ntan⁡θi=y−yix−xi,i=1,2,…formulae-sequencesubscript𝜃𝑖𝑦subscript𝑦𝑖𝑥subscript𝑥𝑖𝑖12…\\tan{{\\theta}_{i}}=\\frac{y-{{y}_{i}}}{x-{{x}_{i}}},i=1,2,...roman_tan italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG italic_y - italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG italic_x - italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG , italic_i = 1 , 2 , … (10)\n\nThen, triangulation can be used for AOA algorithms according to (10) [26, 67, 68]. In particular, at least two transmitters are needed for 2-D AOA positioning algorithm, while at least three transmitters are needed for 3-D positioning. Sun et al. [69] provided a traditional AOA algorithm, and the authors derived Cramer-Rao bound to analyze the theoretical accuracy of the algorithm. Yu et al. [70] employed an optimal optical omnidirectional angle estimator for AOA system, which can mitigate the side effect of the uncertain orientation of the receiver. When more than two LEDs were exploited, two supplemented methods that selected the LEDs with more reliable measured power data were proposed to reduce the estimation error. In addition, Soner et al. [71] proposed a quadrant photodiode-based AOA algorithm for vehicle positioning to avoid collision and platooning.\n\nThe performance of AOA algorithms significantly depends on the acquisition of AOA values. AOA values are often calculated by the VLC signals received by PDs and the image captured by the camera. The first approach estimates AOA based on the Lambertian channel model, which is relative to radiation angle and incidence angle according to (3). Therefore, it is typically assumed that the transmitter plane should be horizontal and parallel to the receiver plane [67, 69, 70], which is inapplicable to scenarios with random receiver orientation. To overcome this limitation, a positioning framework was proposed based on angle differences of arrival in a 3-D coordinates system [4], which had no receiver orientation limitations. Some researchers investigated different designs of AOA detectors [72, 73, 74] to relax the orientation limitation at the receiver. For instance, Zhu et al. [72] proposed to use pairs of PDs, namely complementary PDs, to construct AOA estimators. Stefanie et al. [73] investigated a new form of AOA detector that was a quadrant PD placed below a transparent aperture in an opaque screen. Zhang et al. [74] used two optical AOA estimators for locating LEDs. The AOA estimators had fixed relative positions, and each estimator consisted of four PDs with different orientations. In addition, MEMS sensors like accelerators and gyroscopes were also used to measure the orientation of the receiver, including azimuth, roll, and pitch angles [68]. There are also approaches that use the camera to estimate the position of the receiver. They obtain the three angles by calculating the trigonometric relationship between the coordinates of the transmitters and the receivers from the captured image. For instance, Hossei et al. [75] proposed a geometrical optics positioning algorithm (GPOA) based on AOA to locate smartphones.\n\nIII-B4 Received Signal Strength (RSS) and Received Signal Strength Ratio (RSSR)\n\nThe RSS algorithm is one of the most widely-used methods in indoor VLP, and it estimates the location of the receiver based on the power of the received signal, i.e., RSS values from LEDs. RSS values can be easily obtained using PDs equipped on the receiver. As illustrated in (3), the RSS increases as the distance between the transmitter and the receiver decreases. When the angles of incidence and radiation are fixed, the distance between the receiver and the corresponding LED can be calculated using the detected RSS values based on the Lambertian channel model. Then, the trilateration method can be applied for positioning. Gu et al. [76] proposed to calculate the horizontal coordinates of the receiver given the RSS information from four LEDs, after which the height of the receiver was also estimated. It also used Kalman and particle filters to realize target tracking. An RSS-based trilateration method using the code division multiple access technique was proposed by Guan et al. [77]. Assuming that the transmitter and the receiver planes were parallel, they used RSS to estimate the distance by increasing the height of the transmitter from 0, and the distance was used to calculate the location of the receiver using the trilateration method. Zhang et al. [78] proposed a deep neural network (DNN)-based RSS positiong system. The DNN was trained by the Bayesian regularization based on the Levenberg-Marquardt algorithm, so that unknown positions across the same area can be estimated by using the trained DNN on limited training points. Then, Saboundji et al. [79] implemented the artificial neural network learning for an RSS algorithm to achieve highly accurate and efficient indoor positioning. Salman et al. [80] suggested the demonstration of a 3D VLP system, combining RSS and trilateration solution so that the speed of the computation may be increased considerably. Shen et al. [81] used hybrid maximum likelihood/maximum a posteriori principle for a multiple LEDs - multiple PDs system to achieve positioning, which took into account the presence of prior information on the orientation.\n\nIn addition, RSSR algorithms are also applied to VLP. Different from RSS algorithms that directly use the received power to calculate the distance between the transmitter and the receiver, RSSR algorithms calculate the ratio of distances according to the ratio of the received power from multiple transmitters and estimate the location based on the distance ratios. RSSR has the advantage that the ratio of received power can avoid the error caused by the non-zero irradiance [29], and thus it has less error than the distance directly obtained from the power. However, RSSR algorithms typically require the receiver plane to be parallel to the transmitter plane [82, 83], so that the incidence angle can be equal to the irradiance angle. Hence, the received power can be derived from (3) as\n\nPr=Pt⁢(m+1)⁢A2⁢π⁢d2⁢g⁢(ψ)⁢cosm⁡(ϕ)⁢cos⁡(ψ)=Udm+3subscript𝑃𝑟subscript𝑃𝑡𝑚1𝐴2𝜋superscript𝑑2𝑔𝜓superscript𝑚italic-ϕ𝜓𝑈superscript𝑑𝑚3{{P}_{r}}={{P}_{t}}\\frac{(m+1)A}{2\\pi{{d}^{2}}}g(\\psi){{\\cos}^{m}}(\\phi){\\cos}% (\\psi)=\\frac{U}{{{d}^{m+3}}}italic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = italic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT divide start_ARG ( italic_m + 1 ) italic_A end_ARG start_ARG 2 italic_π italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG italic_g ( italic_ψ ) roman_cos start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ( italic_ϕ ) roman_cos ( italic_ψ ) = divide start_ARG italic_U end_ARG start_ARG italic_d start_POSTSUPERSCRIPT italic_m + 3 end_POSTSUPERSCRIPT end_ARG (11)\n\nwhere U=(m+1)⁢Pt⁢A⁢g⁢(ψ)⁢hm+12⁢π𝑈𝑚1subscript𝑃𝑡𝐴𝑔𝜓superscriptℎ𝑚12𝜋U=\\frac{(m+1){P_{t}}Ag(\\psi)h^{m+1}}{2\\pi}italic_U = divide start_ARG ( italic_m + 1 ) italic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_A italic_g ( italic_ψ ) italic_h start_POSTSUPERSCRIPT italic_m + 1 end_POSTSUPERSCRIPT end_ARG start_ARG 2 italic_π end_ARG is a constant that can be calculated. Then, the distance ratio can be expressed as\n\nd1d2=Pr2Pr⁢1m+3.subscript𝑑1subscript𝑑2𝑚3subscript𝑃subscript𝑟2subscript𝑃𝑟1\\frac{{{d}_{1}}}{{{d}_{2}}}=\\sqrt[{}^{{}^{m+3}}]{\\frac{{{P_{r_{2}}}}}{{{P_{r1}% }}}}.divide start_ARG italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG = nth-root start_ARG start_FLOATSUPERSCRIPT start_FLOATSUPERSCRIPT italic_m + 3 end_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT end_ARG start_ARG divide start_ARG italic_P start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_ARG start_ARG italic_P start_POSTSUBSCRIPT italic_r 1 end_POSTSUBSCRIPT end_ARG end_ARG . (12)\n\nBy substituting the coordinates of two LEDs, (x1,y1,z1)subscript𝑥1subscript𝑦1subscript𝑧1({{x}_{1}},{{y}_{1}},{{z}_{1}})( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) and (x2,y2,z2)subscript𝑥2subscript𝑦2subscript𝑧2({{x}_{2}},{{y}_{2}},{{z}_{2}})( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) into (12), we have\n\n(x−x1)2+(y−y1)2+(z−z1)2(x−x2)2+(y−y2)2+(z−z2)2=d1d2.superscript𝑥subscript𝑥12superscript𝑦subscript𝑦12superscript𝑧subscript𝑧12superscript𝑥subscript𝑥22superscript𝑦subscript𝑦22superscript𝑧subscript𝑧22subscript𝑑1subscript𝑑2\\frac{\\sqrt{{{\\left(x-{{x}_{1}}\\right)}^{2}}+{{\\left(y-{{y}_{1}}\\right)}^{2}}+% {{(z-{{z}_{1}})}^{2}}}}{\\sqrt{{{\\left(x-{{x}_{2}}\\right)}^{2}}+{{\\left(y-{{y}_% {2}}\\right)}^{2}}+{{(z-{{z}_{2}})}^{2}}}}=\\frac{{{d}_{1}}}{{{d}_{2}}}.divide start_ARG square-root start_ARG ( italic_x - italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_y - italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_z - italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG end_ARG start_ARG square-root start_ARG ( italic_x - italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_y - italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_z - italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG end_ARG = divide start_ARG italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG . (13)\n\nIn this way, two simultaneous equations can achieve 2-D positioning when three LEDs are detected. Three simultaneous equations with four LEDs used can achieve 3-D positioning.\n\nSince RSS or RSSR algorithms rely on a perfect channel model, they are susceptible to the incidence and irradiance angles. Several RSS and RSSR algorithms have been proposed to tackle the transmitter and receiver orientation limitations [84, 85, 86]. Wang et al. proposed two designs for RSSR-based VLP algorithms, including multiple directional LED array [84] and multiple direction PD array [85], to reduce the error caused by the orientation of transmitters and receivers, respectively. In addition, Li et al. [86] also considered the orientation uncertainty of the receiver by coping with the non-linear relationship between the RSS and the orientation uncertainty. They utilized the first and second-order Taylor series expansion of RSS to find an accurate approximation for the RSS when the orientation of the receiver was uncertain.\n\nIII-B5 Fingerprinting\n\nIn fingerprinting algorithms, one or multiple features related to the receiver’s position are selected as fingerprints. The position of the receiver is estimated by matching the measured data with the prestored location-related data. In particular, there are two phases for the fingerprinting algorithm, including the offline phase and the online phase. In the offline phase, the data related to the location are collected and stored in the database. In the online phase, the location of the target is estimated by matching the currently measured data to the pre-stored database.\n\nThere are various features of the signal can be selected as fingerprints. Most of the existing literatures adopted RSS as the fingerprints, and they typically used RSS vector to further enhance the positioning accuracy[87, 88, 89, 90]. RSS vector consists of several RSS values from multiple transmitters [91, 92, 93]. Received signal strength indicator (RSSI), as another representation of RSS, was used as a fingerprint [94, 95]. In addition, the channel impulse responses (CIR) were also selected as a fingerprint [96]. Yang et al. [97] chose the extinction ratio that represented the ratio of received powers when bit 1 and bit 0 are transmitted as the fingerprint. In another work [98], light power distribution calculated from grayscale images was used as fingerprints for indoor positioning and tracking. Moreover, Zhao et al. [99] proposed a LightPrint as the fingerprint, which is a vector of multiple light intensity values obtained from existing lighting infrastructure with any unmodified light source during the user’s walks.\n\nTo match the measured data to the database accurately, a number of match methods have been studied. In particular, probabilistic methods and k-nearest neighbors (kNN) algorithms are extensively used.\n\nThe probabilistic method utilizes the probability distribution of RSS to estimate the location of the target with the Bayesian method. Supposing that the transmitters are independent of each other, the probability of a location candidate Lisubscript𝐿𝑖L_{i}italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can be calculated as the probability of the RSS from all transmitters by\n\nP⁢(𝑹|Li)=∏j=1nP⁢(Rj|Li)𝑃conditional𝑹subscript𝐿𝑖superscriptsubscriptproduct𝑗1𝑛𝑃conditionalsubscript𝑅𝑗subscript𝐿𝑖P\\left(\\bm{R}|{{L}_{i}}\\right)=\\prod\\limits_{j=1}^{n}{P\\left({{R}_{j}}|{{L}_{i% }}\\right)}italic_P ( bold_italic_R | italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = ∏ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_P ( italic_R start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) (14)\n\nwhere 𝑹=(R1,R2,…,Rn)𝑹subscript𝑅1subscript𝑅2…subscript𝑅𝑛\\bm{R}=\\left({{R}_{1}},{{R}_{2}},...,{{R}_{n}}\\right)bold_italic_R = ( italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_R start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) is an RSS vector composed of RSS values from n𝑛nitalic_n transmitters, and P⁢(Rj|Li)𝑃conditionalsubscript𝑅𝑗subscript𝐿𝑖P\\left({{R}_{j}}|{{L}_{i}}\\right)italic_P ( italic_R start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) represents the probability of the RSS value Rjsubscript𝑅𝑗R_{j}italic_R start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT from the j𝑗jitalic_jth transmitter when the receiver locates at location Lisubscript𝐿𝑖L_{i}italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. The probability distribution of the RSS is calculated and stored in the offline stage. Then, the positioning coordinate can be estimated by a weighted average of the coordinates as\n\n(x^,y^)=∑i=1nP⁢(Li|𝑹)⁢(xLi,yLi)^𝑥^𝑦superscriptsubscript𝑖1𝑛𝑃conditionalsubscript𝐿𝑖𝑹subscript𝑥subscript𝐿𝑖subscript𝑦subscript𝐿𝑖\\left(\\widehat{x},\\widehat{y}\\right)=\\sum\\limits_{i=1}^{n}{P\\left({{L}_{i}}|% \\bm{R}\\right)}\\left({{x}_{{{L}_{i}}}},{{y}_{{{L}_{i}}}}\\right)( over^ start_ARG italic_x end_ARG , over^ start_ARG italic_y end_ARG ) = ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_P ( italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | bold_italic_R ) ( italic_x start_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) (15)\n\nin the online stage. Kail et al. [100] proposed a probabilistic positioning system that addressed the problem of unpredictable obstructions and synchronization error based on a Bayesian model. Another research [101] proposed a light-signal decomposition method to extract fingerprints, and then a Bayesian localization framework was applied to improve the precision. Ou et al. [102] used kernel functions to model the spatial correlation nature for the reflected lights. Based on that, target location estimates are given by the Bayesian inference both in a discrete setup and a continuous framework, which are the probabilistic fingerprinting and the maximum likelihood estimate.\n\nThe kNN method is another typical method adopted in fingerprinting algorithms based on Euclidean distance [87, 88, 89, 90, 91]. The Euclidean distance Djsubscript𝐷𝑗D_{j}italic_D start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT between the online measured RSS vector 𝑹=(R1,R2,…,Rn)𝑹subscript𝑅1subscript𝑅2…subscript𝑅𝑛\\bm{R}=\\left({{R}_{1}},{{R}_{2}},...,{{R}_{n}}\\right)bold_italic_R = ( italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_R start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) and the offline RSS vector 𝑺j=(Sj,1,Sj,2,…,Sj,n)subscript𝑺𝑗subscript𝑆𝑗1subscript𝑆𝑗2…subscript𝑆𝑗𝑛{{\\bm{S}}_{j}}=\\left({{S}_{j,1}},{{S}_{j,2}},...,{{S}_{j,n}}\\right)bold_italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = ( italic_S start_POSTSUBSCRIPT italic_j , 1 end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_j , 2 end_POSTSUBSCRIPT , … , italic_S start_POSTSUBSCRIPT italic_j , italic_n end_POSTSUBSCRIPT ) can be calculated by\n\nDj=∑i=1n(Ri−Sj,i)2subscript𝐷𝑗superscriptsubscript𝑖1𝑛superscriptsubscript𝑅𝑖subscript𝑆𝑗𝑖2{{D}_{j}}=\\sqrt{\\sum\\limits_{i=1}^{n}{{{\\left({{R}_{i}}-{{S}_{j,i}}\\right)}^{2% }}}}italic_D start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = square-root start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_S start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG (16)\n\nwhere Sj,isubscript𝑆𝑗𝑖{S}_{j,i}italic_S start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT denotes the prestored RSS value from the i𝑖iitalic_ith transmitter in RSS vector, 𝑺jsubscript𝑺𝑗{{\\bm{S}}_{j}}bold_italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, which is related to the j𝑗jitalic_jth location candidate. According to the Euler distance, there are usually several location candidates can be selected. When k𝑘kitalic_k location candidates are selected, the final location of the target is determined by averaging k𝑘kitalic_k location candidates. For simplicity, k=1𝑘1k=1italic_k = 1 was typically selected [19, 96].\n\nAlthough the kNN method is simple and highly feasible, it is limited by the size of the cell, i.e., the density of the grid. To address this issue, weighted K-nearest neighbors (WkNN) was adopted for fingerprinting algorithms [87, 88, 89, 95, 103]. The WkNN method assigns weights to the distances so that the neighbor with a smaller distance has a greater weight compared with the neighbor with a greater distance. Based on the WkNN method, Cui et al. [95] proposed a clustering algorithm and used Spearman distance to improve the performance of the fingerprint algorithm. Oh et al. [103] constructed a fingerprinting database based on the channel characteristics of VLC and obtained the approximate location of the user by applying WkNN. In addition to kNN, extreme learning machine (ELM) and random forest were also applied to fingerprinting [90].\n\nIII-B6 Image Sensing\n\nWith the popularity of the camera equipment, the image sensing-based VLP technique has also attracted massive attention. This technique estimates the location of the target by analyzing the geometric relation between the LEDs’ coordinates and their corresponding projection on the image. The image sensing in VLP is similar to the multi-view geometry in computer vision. The key difference is that the camera can receive the VLC signals to obtain the information of transmitters in VLP.\n\nTo identify the transmitters and obtain the information in image sensing algorithms, the VLC signals should be received and decoded. Thus the under-sampled phase shift on-off keying [104] based modulation and camera rolling shutter effect [105, 106] based modulation methods are adopted for communications.\n\nIn image sensing, there are four coordinate systems established for calculating the geometric relation between the corresponding points. They are a 3D world coordinate system, a 3D camera coordinate system, a 2D image coordinate system, and a 2D pixel coordinate system. The image coordinate (xi,yi)Tsuperscriptsuperscript𝑥isuperscript𝑦iT\\left(x^{\\rm{i}},y^{\\rm{i}}\\right)^{\\rm{T}}( italic_x start_POSTSUPERSCRIPT roman_i end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT roman_i end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT can be easily obtained through image processing [107], while the world coordinate of the LED (xw,yw,zw)Tsuperscriptsuperscript𝑥wsuperscript𝑦wsuperscript𝑧wT\\left(x^{\\rm{w}},y^{\\rm{w}},z^{\\rm{w}}\\right)^{\\rm{T}}( italic_x start_POSTSUPERSCRIPT roman_w end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT roman_w end_POSTSUPERSCRIPT , italic_z start_POSTSUPERSCRIPT roman_w end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT can be obtained by receiving the modulated VLC signal from the LED. The camera coordinate (xc,yc,zc)Tsuperscriptsuperscript𝑥csuperscript𝑦csuperscript𝑧cT\\left(x^{\\rm{c}},y^{\\rm{c}},z^{\\rm{c}}\\right)^{\\rm{T}}( italic_x start_POSTSUPERSCRIPT roman_c end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT roman_c end_POSTSUPERSCRIPT , italic_z start_POSTSUPERSCRIPT roman_c end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT can be calculated by\n\n(xi,yi,1)T=𝐀⁢(xc,yc,zc,1)Tsuperscriptsuperscript𝑥isuperscript𝑦i1T𝐀superscriptsuperscript𝑥csuperscript𝑦csuperscript𝑧c1T{{\\left({{x}^{\\text{i}}},{{y}^{\\text{i}}},1\\right)}^{\\text{T}}}=\\mathbf{A}{{% \\left({{x}^{\\text{c}}},{{y}^{\\text{c}}},{{z}^{\\text{c}}},1\\right)}^{\\text{T}}}( italic_x start_POSTSUPERSCRIPT i end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT i end_POSTSUPERSCRIPT , 1 ) start_POSTSUPERSCRIPT T end_POSTSUPERSCRIPT = bold_A ( italic_x start_POSTSUPERSCRIPT c end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT c end_POSTSUPERSCRIPT , italic_z start_POSTSUPERSCRIPT c end_POSTSUPERSCRIPT , 1 ) start_POSTSUPERSCRIPT T end_POSTSUPERSCRIPT (17)\n\naccording to pinhole camera model as illustrated in Fig. 8, where\n\n𝐀=[f0000f000010]𝐀matrix𝑓0000𝑓000010\\mathbf{A}=\\begin{bmatrix}f&0&0&0\\\\ 0&f&0&0\\\\ 0&0&1&0\\\\ \\end{bmatrix}bold_A = [ start_ARG start_ROW start_CELL italic_f end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL italic_f end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 1 end_CELL start_CELL 0 end_CELL end_ROW end_ARG ] (18)\n\nis the calibration matrix of the camera, which can be calibrated and known in advance, and f𝑓fitalic_f is the focal length of the lens. Then the geometric relation between the world coordinate system and the image coordinate system can be described as\n\n(xi,yi,1)T=𝐀⋅(𝐑𝐓𝟎𝟏)⁢(xw,yw,zw,1)Tsuperscriptsuperscript𝑥isuperscript𝑦i1T⋅𝐀matrix𝐑𝐓01superscriptsuperscript𝑥wsuperscript𝑦wsuperscript𝑧w1T{{\\left({{x}^{\\text{i}}},{{y}^{\\text{i}}},1\\right)}^{\\text{T}}}=\\mathbf{A}% \\cdot\\left(\\begin{matrix}\\mathbf{R}&\\mathbf{T}\\\\ \\mathbf{0}&\\mathbf{1}\\\\ \\end{matrix}\\right){{\\left({{x}^{\\text{w}}},{{y}^{\\text{w}}},{{z}^{\\text{w}}},% 1\\right)}^{\\text{T}}}( italic_x start_POSTSUPERSCRIPT i end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT i end_POSTSUPERSCRIPT , 1 ) start_POSTSUPERSCRIPT T end_POSTSUPERSCRIPT = bold_A ⋅ ( start_ARG start_ROW start_CELL bold_R end_CELL start_CELL bold_T end_CELL end_ROW start_ROW start_CELL bold_0 end_CELL start_CELL bold_1 end_CELL end_ROW end_ARG ) ( italic_x start_POSTSUPERSCRIPT w end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT w end_POSTSUPERSCRIPT , italic_z start_POSTSUPERSCRIPT w end_POSTSUPERSCRIPT , 1 ) start_POSTSUPERSCRIPT T end_POSTSUPERSCRIPT (19)\n\nwhere 𝐑𝐑\\mathbf{R}bold_R is a 3×3333\\times 33 × 3 rotation matrix representing the pose of the receiver, and 𝐓𝐓\\mathbf{T}bold_T is a 3×1313\\times 13 × 1 translation vector representing the location of the receiver. The goal of image sensing algorithms is to find the pose and location of the receiver, i.e., the camera.\n\nSingle view geometry is widely used in image sensing based VLP algorithms [106, 107, 108, 109, 15, 110, 111]. Guan et al. [106] proposed a double-LED positioning system (DLP) using CMOS image sensor. The authors utilized a rolling shutter mechanism and machine learning algorithm to identify the IDs of LEDs. DLP required the camera to parallel to the LEDs and solved the symmetry problem in this circumstance. Lain et al. [109] proposed a K𝐾Kitalic_K-pairwise LED image-sensor-based VLP (IS-VLP) algorithm for indoor positioning. K𝐾Kitalic_K-parwise LED IS-VLP identified the mapping between the received LED IDs and their images to determine the coordinates of the LEDs, which was then used to estimate the location of the receiver. Moreover, Huang et al. [112] proposed a 3-D NLOS VLP system using a single LED and an image sensor (IS) to address the problem of obstructed LOS paths. Two virtual LEDs reflected from the ground together with the real LED are captured for positioning. In addition, the researchers also gradually focus on the geometric features captured by the image sensing. For instance, Zhang et al. [15] extracted the feature of a single circular LED to locate the target by assuming a weak projection model with the assistance of another built-in sensor. Zhu et al. [16] proposed a VLC-assisted perspective circle and arc algorithm (V-PCA), which exploited the geometric features between two LEDs and their circle images for positioning. To reduce the required luminaires to one, they further proposed a visual odometry-assisted VLP algorithm [113]. Meanwhile, Bai et al. [17] considered the rectangular features of a single luminaire in the positioning process.\n\nIII-B7 Hybrid VLP algorithms\n\nTo attain practical and highly accurate positioning, recent research has focused on merging existing VLP algorithms, termed as hybrid VLP algorithms in this context. These approaches often amalgamate two classical VLP algorithms to achieve superior positioning performance. We categorize these hybrid algorithms into several distinct types for clarity and classification.\n\nRSS and AOA hybrid algorithm\n\nThe combination of RSS and AOA has been studied [26, 114, 115, 116, 117], since both RSS and AOA values can be simply detected by PDs. Yang et al. [26], used a multiple-PD structure to obtain RSS and AOA values simultaneously. Then 3-D positioning was achieved based on RSS and AOA values without the limitation of the tilted angles at the receiver. Othman et al. [114] also utilized RSS and AOA values simultaneously and applied a weight least square estimation to find the location of the target. In addition, an RSS-based approach using a nonlinear least squares (NLS) estimator was proposed [115]. This approach also developed an analytical learning rule based on the Newton-Raphson method to reduce the complexity of the NLS estimator, which used AOA-based localization as an initial point for the learning rule. Hou et al. [116] proposed to use one LED lamp to position, and a smartphone was used to receive RSS and AOA to estimate its 3-D location. Aparicio et al. [117] presented an AOA-based triangulation algorithm that used the acquired RSS values to estimate the image points for each LED and then implemented a Least Squares Estimator (LSE) and trigonometric considerations to estimate the receiver’s position.\n\nTDOA and fingerprinting hybrid algorithm\n\nAn indoor VLP method combining TDOA and fingerprints was proposed [66]. A visible light fingerprint database was first built, and then the TDOA algorithm was used to determine the application range of the fingerprint. The final location of the target was obtained via WkNN.\n\nRSS and image sensing hybrid algorithm\n\nGiven the prevalence of commercial mobile devices equipped with both cameras and PD, researchers have explored combining information captured by these components for positioning purposes. For instance, Bai et al. [118] proposed a camera-assisted RSSR (CA-RSSR) positioning algorithm by jointly using the camera and PD in the smartphone to position. The authors used the image captured by the camera to calculate the incidence angle of the receiver, which facilitated accurate positioning without limitation of the orientation at the receiver. To improve the accuracy of this hybrid positioning system, the authors further proposed an enhanced CA-RSSR (eCA-RSSR) algorithm [119] to mitigate the error caused by the distance between the PD and the camera. Meanwhile, they also proposed a location method [120] that integrates visual and RSS information from three LEDs, irrespective of their orientations, and receivers. By analyzing images captured by the camera, they derived incidence angles through geometric principles. Combining these angles with RSS values, they estimated the desired irradiance angles and distances between LEDs and the receiver, subsequently estimating the receiver’s location. Furthermore, Hua et al. [121] proposed a FusionVLP system based on the fusion of the measurements from a PD and a low-cost camera, in which an Ensemble Kalman Filter (EnKF) module was used for real-time positioning, and a Fixed-Lag Ensemble Kalman Smoother (FLEnKS) module was used for semi-real-time positioning. To improve the accuracy, they introduced a new two-step adjusted PD RSS model, including interference adjustment and Lambert Coefficient adjustment.\n\nAOA and image sensing algorithm\n\nWith the geometric relation between the transmitters and their projections on the image plane, AOA is also exploited in image sensing-based VLP algorithms [75, 122, 123], and the AOA value can be obtained by the projection model of the camera. For instance, Hossei et al. [75] proposed GPOA based on AOA using the front-facing camera of the smartphone. GPOA designed space-color-coded identifiers and balanced the number of different colored LEDs to keep the lighting white. Then, GPOA used the similarity relation in the projection model to estimate the location of the target. In addition, luminaire reference points (LRPs) and hybrid imaging-photodiode (HIP) receivers were investigated for VLP [122], in which, AOA was measured by the HIP receiver. The receiver can be located when only one luminaire is in the FoV of the receiver by precisely defining multiple LRPs on the single luminaire. Liu et al. [123] proposed to fuse AOA and TDOA with a Time of Flight camera as the receiver. This proposed fusion algorithm leveraged a hybrid Chan/Taylor series expansion method [124] for positioning, and the experimental results demonstrated that the fusion algorithm can achieve more accurate positioning compared to using a single algorithm.\n\nWe summarize compare the above VLP algorithms in Table II. We mainly compare the number of LEDs required in 3D positioning, whether the auxiliary device is required, and the advantages and weaknesses of each algorithm. For instance, the existing image sensing research recognizes that image sensors can use more visual information, but it needs to consider the problem of positioning delay. Compared with the traditional VLP algorithms, the hybrid VLP algorithms are dedicated to solving the challenges of VLP in practice, such as the orientation limitation at the receiver and the requirement of multiple LEDs. However, this approach also increases the complexity of the receiver devices since they often need the PD and image sensor simultaneously at the receiver.\n\nIII-C Comparisons of VLP algorithms\n\nThis subsection evaluates the positioning accuracy and the coverage ratio of several representative VLP algorithms. In particular, we consider the following four algorithms, the RSS positioning algorithm, the DLP algorithm [106], the eCA-RSSR algorithm [119], and the V-PCA algorithm [16] to represent the traditional trilateration method, image sensing, hybrid VLP algorithm, and a novel image sensing-based algorithm.\n\nV-PCA takes the visual features of the LED’s circle contour into consideration and requires two LEDs for 3D positioning. The rest of the three algorithms treat the LEDs as point light sources. DLP, eCA-RSSR and RSS require two, three, and four LEDs to achieve 3D positioning, respectively. In addition, RSS and DLP require the receiver to be parallel to the transmitter, while V-PCA and eCA-RSSR can estimate the orientation directly. For fairness, the performances of the above algorithms are all simulated in a room of 5 m ×\\times× 5 m ×\\times× 3 m. There are four LEDs placed at the locations of (1.75 m, 1.75 m), (1.75 m, 3.25 m), (3.25 m, 3.25 m), and (1.75 m, 1.75 m) with the height of 3 m. The radius of the LEDs is 10 cm.\n\nFig. 9 compares the positioning accuracy of the four algorithms in terms of cumulative distribution function (CDF) curves. There are 10,000 location samples generated randomly in the room with random tilted angles. We simulate the performance of the RSS and DLP algorithms when the orientation of the receiver is known and unknown. From Fig. 9, it can be observed that when the orientation is unknown, the V-PCA algorithm can achieve a 93th percentile accuracy of about 10 cm. The eCA-RSSR algorithm can achieve a 78th percentile accuracy of about 10 cm. However, RSS and DLP cannot work in this circumstance. When the orientation of the receiver is given, DLP achieves a 98th percentile accuracy of about 10 cm, while RSS achieves an 80th percentile accuracy of about 10 cm. In this circumstance, DLP and RSS even outperform V-PCA and eCA-RSSR, respectively. This is because, in the process of estimating the orientation of the receiver in V-PCA and eCA-RSSR, there exists an estimation error. To sum up, the V-PCA algorithm has the best performance in terms of positioning accuracy and robustness since it needs only two LEDs and has no orientation limitation at the receiver. In addition, DLP and RSS are extremely sensitive to the tilted angles of the receiver.\n\nFig. 10 shows the coverage ratio of 3D positioning by positioning algorithms versus the FoV of the receiver. The coverage ratio is calculated by\n\nRcov=AeffectiveAtotal×100%,subscript𝑅covsubscript𝐴effectivesubscript𝐴totalpercent100R_{\\rm{cov}}=\\frac{A_{\\rm{effective}}}{A_{\\rm{total}}}\\times 100\\%,italic_R start_POSTSUBSCRIPT roman_cov end_POSTSUBSCRIPT = divide start_ARG italic_A start_POSTSUBSCRIPT roman_effective end_POSTSUBSCRIPT end_ARG start_ARG italic_A start_POSTSUBSCRIPT roman_total end_POSTSUBSCRIPT end_ARG × 100 % , (20)\n\nwhere Aeffectivesubscript𝐴effectiveA_{\\rm{effective}}italic_A start_POSTSUBSCRIPT roman_effective end_POSTSUBSCRIPT represents the effective area that the receiver can locate itself, and Atotalsubscript𝐴totalA_{\\rm{total}}italic_A start_POSTSUBSCRIPT roman_total end_POSTSUBSCRIPT represents the total area of the room. In Fig. 10, FoV varies from 0∘superscript00^{\\circ}0 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT to 80∘superscript8080^{\\circ}80 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT. The location samples are chosen along the length, width, and height of the room, with a 5 cm separation from each other. For RSS and eCA-RSSR, an SNR of 13.6 dB is considered to ensure reliable communication. In addition, RSS and DLP both require the receiver to be parallel to the transmitter, while V-PCA and eCA-RSSR do not. Hence, for V-PCA and eCA-RSSR, the receiver is tilted to test how many LEDs can be available at each location sample. For RSS and DLP, the receiver is always oriented vertically upward. From Fig. 10, it can be seen that V-PCA always achieves the highest coverage ratio for all FoV values. It performs consistently well from 25∘superscript2525^{\\circ}25 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT to 80∘superscript8080^{\\circ}80 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT, whose Rc⁢o⁢vsubscript𝑅𝑐𝑜𝑣R_{cov}italic_R start_POSTSUBSCRIPT italic_c italic_o italic_v end_POSTSUBSCRIPT exceed 90% and about 20% better than eCA-RSSR. This is because eCA-RSSR needs three LEDs for positioning, while V-PCA only needs two, although both eCA-RSSR and V-PCA have no strict requirements for orientation. In addition, although DLP also only needs two LEDs for positioning, it has an unsatisfactory performance of coverage ratio when compared to V-PCA. This is because DLP requires the receiver to face up vertically. It can also be observed that RSS has the lowest coverage ratio among the four algorithms. This is because four LEDs and a fixed orientation of the receiver are required for RSS to achieve positioning. In conclusion, the coverage ratio of the positioning algorithms is related to the required number of LEDs and the orientation of the receiver. When the orientation of the receiver is not restricted, the coverage ratio will be greatly improved. Additionally, a higher coverage ratio of the positioning algorithm is achieved as the algorithms demand fewer LEDs.\n\nIV heterogeneous positioning Systems\n\nIn this section, we outline heterogeneous positioning systems, which amalgamate VLP with other positioning methods such as WiFi, Bluetooth, and motion sensors. Despite VLP offering high precision and cost-effectiveness, achieving satisfactory performance in intricate indoor settings remains challenging. For instance, if lighting is completely obstructed, VLP cannot provide positioning services, necessitating the use of alternative techniques. Conversely, when visible light signals are accessible, VLP can augment the accuracy of other positioning methods. In essence, heterogeneous positioning systems are crafted to leverage the strengths of multiple positioning techniques.\n\nIV-A VLP with Wireless Systems\n\nThe combination of VLP and other wireless systems, such as RF, Bluetooth, and acoustic, have been studied [125, 126, 127, 128, 129, 130, 131, 132]. When combined with RF, a heterogeneous indoor positioning system using both LiFi and WiFi was envisaged to improve the accuracy of indoor positioning [125]. Zigbee wireless network was constructed in a VLP system to transmit VLC data to reduce the position estimation error caused by nearby visible light channels [126]. There was also a two-stage positioning system developed [127]. In the first stage, RF was used to detect the room where the device located. In the second stage, LiFi was employed to detect the specific position of the device. The estimation error was reported to be only 5.8 cm. In addition, Shi et al. [128] proposed a 5G indoor positioning scheme based on VLC and indoor broadband communication for the museum. The system utilized unlicensed visible light of the electromagnetic spectrum to provide visitors with high-accuracy positioning on a mobile device, realizing a mean positioning error of 0.18 m.\n\nWhen combined with Bluetooth, Luo et al. [129] proposed a Bluetooth signal based spring model to hybrid VLP and Bluetooth positioning. The intensity of visible light signals was detected through the Bluetooth beacon set in advance to match the fingerprint database. Simulation results showed that the system can achieve an average positioning accuracy of 6 cm. Hussain et al. [130] used a VLC-based indoor mapping application to facilitate Bluetooth MAC address mapping. In this way, the advantages of VLC and Bluetooth can be combined to achieve superior positioning performance.\n\nIn addition, the combination of acoustic positioning and VLP has also been studied [131] and [132]. Akiyama et al. [131] measured the propagation time of acoustic signal through an acoustic sensor equipped in the phone. With the obtained propagation time, TOA was then used in VLP to achieve precise localization. Experiments showed that the positioning accuracy can be achieved up to 100 to 200 mm. Png et al. [132] integrated two acoustic sensors on the Arduino hardware board. The sensors can detect the moving distance of pedestrians on the X and Y axes in a 2-D plane respectively, which improved the positioning readings to centimeters and helped the system obtain higher accuracy.\n\nIV-B VLP with Motion Sensors\n\nThe tracking and positioning of moving objects are inseparable from various motion sensors, and different sensors perform different measuring functions. The accelerometer can detect the velocity information in specific directions, while the gyroscope can obtain the angle information of moving targets. The magnetometer can monitor the strength of the magnetic field in the surrounding environment, and the pressure meter is sensitive to interaction and external forces. Due to the need for the comprehensive processing of the above various motion information, complex sensors integrating the above components have been gradually produced, such as the inertial measurement unit (IMU), which integrates the accelerometer, gyroscope, and magnetometer, and the six-axis angle sensor which can measure the direction angle and inclination angle. The appearance and development of motion sensors also directly promote the development of inertial navigation, which can track the position and trajectory of a moving target by collecting motion data. The combination of VLP and IMU has also attracted increasing attention. It improves the performance of the positioning system through the assistance of inertial navigation [133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148].\n\nAs mentioned above, the accelerometer is used to measure the acceleration of the moving object in specific directions. Yasir et al. [133] proposed a positioning scheme fusing light intensity sensors and accelerometers. The accelerometer was used to determine the direction of the receiver, which can simplify the posture calculation process and reduce the average positioning error to 25 cm. Nakajima et al. [134] integrated magnetic positioning with VLP to construct the hybrid scheme, in which the pedestrian direction and the walking angle were measured through a magnetometer equipped with the phone and VLC system. The scheme helped travelers to estimate the LED node at the destination more accurately and then determined its approximate location by using the nearest neighbor method of VLP. The experimental results confirmed that positioning accuracy can be improved through the assistance of geomagnetic value correction. Sertthin et al. [135] proposed a switching receiver position estimation scheme for a VLC-ID and 6-axes sensor-based positioning system. The positioning performance was improved by optimizing the estimated error distance, and the accuracy was improved by more than 30% compared with the traditional positioning scheme only based on VLC-ID. Then, Wang et al. [136] used two kinds of information to obtain the posture of the receiver, achieving sub-meter accuracy in typical office corridor areas.\n\nIMU can measure the acceleration and angular velocity of the object jointly in real-time, and thus it can be combined with VLP when visible light signals are not available. Liang et al. [138] proposed an EKF-based visual and inertial fusion method for visible light positioning with an IMU and a rolling shutter camera. The results showed that the method can keep the RMSE errors of positioning to 5 cm. Zhang et al. [139] developed an indoor positioning system based on VLP and sensor fusion techniques. The system enhanced positioning accuracy by fusing data collected by the image sensor and motion sensors of a smartphone. The experiment results showed that the proposed algorithm improves the position accuracy by 44% when compared with the algorithm employing a single image sensor. Then, Qin et al. [140] fused the IMU and VLC information in a tightly coupled scheme so that the VLP system could continually provide location service under the aforementioned intermittent outage condition. Experimental results showed that the proposed method had better stability than the PnP methods. At the same time, fusion positioning schemes using a single circular LED were proposed [141, 142]. In particular, the geometric features of LED projection and plane intersection lines were used for deriving relative position relation between the LED and the receiver, and IMU was used to estimate the orientation of the receiver [141].\n\nAdditionally, inertial navigation and pedestrian dead reckoning (PDR) can achieve positioning without GPS by analyzing the data obtained by IMU. Due to the accumulation of external noise and internal drift error, PDR is arduous to be adopted as an independent navigation or positioning scheme without proper correction [143]. However, its accuracy can be significantly improved with the assistance of a VLP system. There have been studies on the combination of VLP and PDR[144, 145, 146, 147]. Li et al. [144] proposed to simultaneously process the data from PDR and VLP by particle filter. In particular, after obtaining positioning data of PDR in some specific positions, the system put it into a particle filter together with VLP data. Filter processed two kinds of data and obtained the final coordinates of pedestrians. The scheme solved the performance degradation caused by the multipath effect and light transmission-blocking and alleviated the problem of cumulative error of inertial navigation. The experimental results showed that positioning error could be as low as 0.14 m. After that, they have also proposed to use the Kalman filter to simultaneously process VLP and PDR data [145]. The inertial navigation without requiring external sources improved the positioning performance of the VLP system in the region with weak visible light intensity or occlusion, while the accumulated error of inertial navigation was reduced with the assistance of VLP data. The experimental results showed that the hybrid system was better compared to the single VLP or inertial navigation. Different from works using PD as the receiver [144, 145], some works [146, 147] employed the image sensor. In particular, Huang et al. [146] completed cell recognition and 3D positioning by capturing the image of a single luminaire, realizing continuous and stable indoor positioning by using sparse light source beacons in actual scenes. Wang et al. [147] proposed to use mode average to process heading angle data for pedestrian positioning, which improved positioning accuracy and shortened reliable running time. In the positioning process, the LED with modulation code was used as the absolute position beacon, and then the LED image was captured and decoded by the camera to obtain the absolute position. The information would be used to periodically correct the position of the PDR, thereby avoiding the accumulation of PDR technology and obtaining high precision. In addition, there was the combination of VLP and geomagnetic and gyroscopic sensors [148], in which, the position information was first obtained by VLP, and then the direction information of dead reckoning was detected through sensors. Finally, the multiple information was processed by the Kalman filter to provide essential data correction. Experimental results showed that the direction error of the proposed system was always less than 6 degrees.\n\nMeanwhile, the combination of simultaneous localization and mapping (SLAM) and VLP [149, 150] has been studied. In particular, the work [149] proposed a loosely coupled multi-sensor hybrid method based on VLP and SLAM. The multi-sensor hybrid system could achieve an average accuracy of 2 cm in milliseconds even when the number of received LEDs was insufficient, or the link was blocked. The work [150] exploited VL-GraghSLAM to improve the accuracy of trajectory estimation, and a Kalman filter was used to fuse visible light fingerprint and inertial sensor data, to complete locating users. Comprehensive experiments showed that the performance of the system was better than the traditional WiFi-based fingerprint recognition method. Moreover, some researchers designed and implemented hybrid schemes of VLP and robotic operating systems (ROS) [151, 152]. Guan et al. [151] utilized the principle of double-lamp positioning and implementing locating through loosely coupled ROS nodes based on the loose coupling characteristics. The images of LEDs were captured by the industrial camera node and subscribed by the locator node, and then the position results were computed. Experimental results showed that the proposed system can provide indoor localization within 2 cm and only 0.35 seconds for one-time positioning. Besides, a VLP system with an improved calibration program was proposed [152], which used mobile robots to collect data and obtained environmental maps with beacon position and identity. The performance of the new method was significantly improved, and the error was almost halved.\n\nIV-C VLP with Other Systems\n\nThere are also some other VLP-based heterogeneous positioning systems [153, 154, 155]. Wu et al. [153] proposed an indoor positioning method combining VLP and quick response (QR) code. The initial positioning was realized by loading a QR code image containing LED position information on the LED lamp. The receiver recognized and decoded the image and then positioned the receiver position. Experimental results showed that the proposed method can achieve an average error of 4.0326 cm, which greatly improves the indoor positioning accuracy compared with the original positioning method. Cao et al. [154] proposed a memory-artificial neural network (M-ANN) in the 3D indoor RSS-VLP system. M-ANN can efficiently search and retrieve the missing data from an offline simulation database to prevent the VLP outage caused by the blocked LED. The average positioning error of 1.04 cm was experimentally achieved in a test region of 0.6 m ×\\times× 0.6 m ×\\times× 0.8 m. In addition, an RSS-based integrating VLC and power-line communication (PLC) indoor positioning system [155] was developed for smart hospital applications. The new indoor tracking system consisted of host LED bulbs, user-end optical tags, an LED triangular positioning algorithm, and a PLC interface. Both the simulation and experimental results verified that the proposed hybrid system can achieve centimeter positioning accuracy.\n\nWe summarize the above articles that are based on the heterogeneous positioning system in Table III. We mainly compare the accuracy, system cost, and the need for auxiliary devices. The emergence of heterogeneous positioning systems is to achieve better performance for LED-based positioning systems. From Table III, the accuracies of most heterogeneous positioning systems have been enhanced, and the works also verified the improvement when compared to a single positioning system. However, the cost of the heterogeneous positioning systems remains an issue in this field, and there are large differences among different systems. In addition, the use of auxiliary devices will also bring different levels of implementation difficulties. For instance, the combination of Bluetooth beacons requires additional Bluetooth beacons placement. Therefore, in addition to positioning performance, the design of future heterogeneous positioning algorithms should also consider positioning cost and practicality.\n\nV VLP Network Design\n\nIn this section, we survey the network design of VLP systems. First, we review the technologies in the VLP network design, including multiplexing protocols, resource allocation, and LED placement. Then, we provide some possible objectives and constraints for designing the VLP network.\n\nV-A Technologies in VLP Network Design\n\nV-A1 Multiplexing schemes\n\nVLP algorithms such as RSS typically require simultaneously receiving multiple visible light signals for positioning. Therefore, appropriate multiplexing schemes are needed to ensure that signals from different LEDs can be differentiated. Here, we summarize the state-of-the-art multiplexing as follows:\n\nTime Division Multiplexing (TDM): In TDM, each lamp is assigned to a time slot and transmits its unique code sequence in its time slot. In the remaining time slots, the LEDs keep illuminating without transmitting any information. Therefore, TDM requires strict time synchronization among LEDs. Zhou et al. [21] developed a TDM method, in which each time was encoded into three 16-bit location codes representing the x𝑥xitalic_x, y𝑦yitalic_y, and z𝑧zitalic_z coordinates of the LEDs. To keep the transmission power stable, the TDM slot structure was also specially designed so as to provide stable illuminations. However, since each lamp must take up a time slot, the positioning delay can be large when there are a large number of LED lamps, which can limit the application of VLP in mobile scenarios. To tackle this challenge, Hou et al. [156] proposed a novel block encoding TDM scheme, in which nine LEDs composed one block to reduce the system delay. Meanwhile, in order to reduce inter-cell interference, an extended binary coded decimal code was used to encode signals transmitted by the LEDs. In addition, two TDM schemes [157] were proposed for VLP systems with/without communication capability, and the required total time slots for estimating channel gains are studied to facilitate positioning.\n\nFrequency Division Multiplexing (FDM): In FDM, each lamp is assigned to a carrier frequency and the transmitted information will be modulated on this frequency. With the assigned carrier frequencies, the LEDs can send information continuously. At the receiver side, light signals from different LEDs can be distinguished by filters. Kim et al. [158] proposed a carrier allocation VLC system to mitigate inter-cell interference. At the transmitter side, the QPSK signals with 2 MHz, 2.5 MHz and 3 MHz carriers are generated. The receiver position can be calculated by the trilateration method. For instance, a VLP system based on FDM method was proposed [159], which utilized the properties of square waves in the frequency domain. Neighboring LEDs used multiples of the ground frequency of the first LED, and the receiver performed an FFT on the received signals to obtain the RSS values. The system can utilize unsynchronized low-bandwidth transmitters, thus achieving an easy implementation with current high-efficiency LED drivers.\n\nCode Division Multiplexing (CDM): In CDM, each lamp is assigned to a unique code and these codes are orthogonal to each other. The LEDs use digital modulation to send information, and the receiver utilizes the same codes to obtain different signals. The work [160] used the CDM scheme for the VLC system and evaluated uni- and bi- polar codes with the appropriated receiver. The results showed that bipolar codes can reduce the distance error caused by surrounding light. Then, Szabo et al. [161] designed and built an experimental platform for the VLC CDM system, and verified the functionality of the system. Ho et al. [162] formulated a nonconvex optimization problem to find the optimal code and used majorization theory analytically to solve this optimization problem. It has been proved that a combinational code is an optimal code that simultaneously attains the minimum values of both total noise variance and maximum noise variance. Through the optimal code, a bound on the fundamental trade-off between the total noise variance and codeword length is derived. Saed et al. [163] used combinational code as a coding scheme for channel estimation, and the experimental results showed that combinational code significantly outperforms the other two schemes based on TDM in terms of noise variance. Another work [164] proposed an encoding scheme based on 1023-bit Kasami sequences for every transmission, which provided multiple access capability and robustness against low signal-to-noise ratios and harsh conditions, such as multipath and near-far effect.\n\nOrthogonal Frequency Division Multiplexing (OFDM): In OFDM, the transmission bandwidth is divided into a series of orthogonal subcarriers, and different lamps are assigned to different subcarriers. There is no need for bandwidth protection between subcarriers, and the spectrums can overlap with each other. Therefore, compared to FDM, OFDM can fully utilize the bandwidt"
    }
}