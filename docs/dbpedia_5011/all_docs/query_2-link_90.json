{
    "id": "dbpedia_5011_2",
    "rank": 90,
    "data": {
        "url": "https://www.linkedin.com/posts/future-media-hub_ai-generativeai-aiact-activity-7171157581573316609-6eQt",
        "read_more_link": "",
        "language": "en",
        "title": "Future Media Hub on LinkedIn: #ai #generativeai #aiact #technology",
        "top_image": "https://media.licdn.com/dms/image/v2/D4D22AQGsrpNc7lYMnw/feedshare-shrink_800/feedshare-shrink_800/0/1702314494365?e=2147483647&v=beta&t=bEoQ-WNGKye490-S9vDVxkM_7jVOdHpm7Y6sYRuw0Rk",
        "meta_img": "https://media.licdn.com/dms/image/v2/D4D22AQGsrpNc7lYMnw/feedshare-shrink_800/feedshare-shrink_800/0/1702314494365?e=2147483647&v=beta&t=bEoQ-WNGKye490-S9vDVxkM_7jVOdHpm7Y6sYRuw0Rk",
        "images": [
            "https://media.licdn.com/dms/image/v2/D4E3DAQFpOn-ORuwpRw/image-scale_191_1128/image-scale_191_1128/0/1684917335517/future_media_hub_cover?e=2147483647&v=beta&t=4DQLzmNBYrHo_QTH3z8aIdF15PvBdBQUCNCVcbDfqT4"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Future Media Hub"
        ],
        "publish_date": "2024-03-06T15:00:01.096000+00:00",
        "summary": "",
        "meta_description": "On 9 December 2023, the European Parliament and the Council reached a political agreement on the AI Act. Here is a quick guide highlighting the key aspects of‚Ä¶",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/posts/future-media-hub_ai-generativeai-aiact-activity-7171157581573316609-6eQt",
        "text": "üí•The implications of the AI Law mentioned in the news, which includes several key aspects: 1Ô∏è‚É£Risk-based system implementation: High-risk AI systems require clear obligations, including an obligatory impact assessment on human rights. 2Ô∏è‚É£Regulation of basic models: Following the Biden administration's approach, large language models will be subject to regulation, affecting models whose training required 10^25 floating-point operations per second (FLOPS). 3Ô∏è‚É£Prohibition of certain systems: The following systems will be prohibited for a period of six months to ensure compliance: categorization biometric systems, facial recognition systems, emotion recognition systems in the workplace, social scoring based on behavior or personal characteristics, AI systems that manipulate human behavior to avoid free will, and AI systems that exploit people's vulnerabilities (based on age, disability, social or economic situation). 4Ô∏è‚É£Transparency requirements: High-risk AI systems must comply with transparency requirements, including documentation of methods, capacity building, datasets used, and measures taken for monitoring and control. 5Ô∏è‚É£Design and development of AI systems: High-risk AI systems must be designed and developed to effectively manage biases, respect human rights, and minimize risks. 6Ô∏è‚É£Documentation and record-keeping: AI system providers must maintain exhaustive documentation to demonstrate compliance with the regulation, including records of programming methods and capacity building, datasets used, and measures adopted for monitoring and control. 7Ô∏è‚É£Human supervision: High-risk AI systems require human supervision to minimize risks and ensure that human decision-making is part of the system's deployment. 8Ô∏è‚É£Penalties: Non-compliance may result in significant fines, ranging from 35 million euros or 7% of global sales to 7.5 million euros or 1.5% of sales, depending on the violation and company size. üëçCompanies that have invested heavily in prohibited technologies, such as categorization biometric systems and facial recognition, may face the need for significant strategic changes. üëâAdditionally, the improvement of documentation requirements could jeopardize the protection of intellectual property, requiring a balance between disclosure and maintaining commercial secrets. üëâCompanies may also need to invest in higher-quality data and advanced tools for managing biases, which could increase operational costs but improve the equity and quality of AI systems. The requirements for documentation and record-keeping impose a significant administrative burden, potentially affecting the commercialization time of new AI products. üëâIntegrating human supervision into high-risk AI systems requires changes in system design and implementation, as well as possible training for personnel. ‚úÖThe potential financial penalties represent a significant financial risk. üíØ#Management #Future of #Artificialintelligence #Technology #Innovation in #India\n\nQuick summary of European Union(EU) AI Act To promote rules on trustworthy AI at international level, the European Union will continue to work in fora such as the G7, the OECD, the Council of Europe, the G20 and the UN. The fines for violations of the AI act were set as a percentage of the offending company‚Äôs global annual turnover in the previous financial year or a predetermined amount, whichever is higher. This would be ‚Ç¨35 million or 7% for violations of the banned AI applications, ‚Ç¨15 million or 3% for violations of the AI act‚Äôs obligations and ‚Ç¨7.5 million or 1.5% for the supply of incorrect information. However, the provisional agreement provides for more proportionate caps on administrative fines for SMEs and start-ups in case of infringements of the provisions of the AI act. Source: https://lnkd.in/dz-KBt5T #AI #Law #europeanunion #penalties"
    }
}