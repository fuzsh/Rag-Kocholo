{
    "id": "dbpedia_2334_0",
    "rank": 45,
    "data": {
        "url": "https://worldwidescience.org/topicpages/f/feature%2Btransform%2Bsift.html",
        "read_more_link": "",
        "language": "en",
        "title": "feature transform sift: Topics by WorldWideScience.org",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/WWSlogo_wTag650px-min.png",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/OSTIlogo.svg",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/ICSTIlogo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Homomorphic encryption-based secure SIFT for privacy-preserving feature extraction\n\nScience.gov (United States)\n\nHsu, Chao-Yung; Lu, Chun-Shien; Pei, Soo-Chang\n\n2011-02-01\n\nPrivacy has received much attention but is still largely ignored in the multimedia community. Consider a cloud computing scenario, where the server is resource-abundant and is capable of finishing the designated tasks, it is envisioned that secure media retrieval and search with privacy-preserving will be seriously treated. In view of the fact that scale-invariant feature transform (SIFT) has been widely adopted in various fields, this paper is the first to address the problem of secure SIFT feature extraction and representation in the encrypted domain. Since all the operations in SIFT must be moved to the encrypted domain, we propose a homomorphic encryption-based secure SIFT method for privacy-preserving feature extraction and representation based on Paillier cryptosystem. In particular, homomorphic comparison is a must for SIFT feature detection but is still a challenging issue for homomorphic encryption methods. To conquer this problem, we investigate a quantization-like secure comparison strategy in this paper. Experimental results demonstrate that the proposed homomorphic encryption-based SIFT performs comparably to original SIFT on image benchmarks, while preserving privacy additionally. We believe that this work is an important step toward privacy-preserving multimedia retrieval in an environment, where privacy is a major concern.\n\nImage feature extraction in encrypted domain with privacy-preserving SIFT.\n\nScience.gov (United States)\n\nHsu, Chao-Yung; Lu, Chun-Shien; Pei, Soo-Chang\n\n2012-11-01\n\nPrivacy has received considerable attention but is still largely ignored in the multimedia community. Consider a cloud computing scenario where the server is resource-abundant, and is capable of finishing the designated tasks. It is envisioned that secure media applications with privacy preservation will be treated seriously. In view of the fact that scale-invariant feature transform (SIFT) has been widely adopted in various fields, this paper is the first to target the importance of privacy-preserving SIFT (PPSIFT) and to address the problem of secure SIFT feature extraction and representation in the encrypted domain. As all of the operations in SIFT must be moved to the encrypted domain, we propose a privacy-preserving realization of the SIFT method based on homomorphic encryption. We show through the security analysis based on the discrete logarithm problem and RSA that PPSIFT is secure against ciphertext only attack and known plaintext attack. Experimental results obtained from different case studies demonstrate that the proposed homomorphic encryption-based privacy-preserving SIFT performs comparably to the original SIFT and that our method is useful in SIFT-based privacy-preserving applications.\n\nMultiscale registration of remote sensing image using robust SIFT features in Steerable-Domain\n\nDirectory of Open Access Journals (Sweden)\n\nXiangzeng Liu\n\n2011-12-01\n\nFull Text Available This paper proposes a multiscale registration technique using robust Scale Invariant Feature Transform (SIFT features in Steerable-Domain, which can deal with the large variations of scale, rotation and illumination between images. First, a new robust SIFT descriptor is presented, which is invariant under affine transformation. Then, an adaptive similarity measure is developed according to the robust SIFT descriptor and the adaptive normalized cross correlation of feature pointâs neighborhood. Finally, the corresponding feature points can be determined by the adaptive similarity measure in Steerable-Domain of the two input images, and the final refined transformation parameters determined by using gradual optimization are adopted to achieve the registration results. Quantitative comparisons of our algorithm with the related methods show a significant improvement in the presence of large scale, rotation changes, and illumination contrast. The effectiveness of the proposed method is demonstrated by the experimental results.\n\nFace recognition via sparse representation of SIFT feature on hexagonal-sampling image\n\nScience.gov (United States)\n\nZhang, Daming; Zhang, Xueyong; Li, Lu; Liu, Huayong\n\n2018-04-01\n\nThis paper investigates a face recognition approach based on Scale Invariant Feature Transform (SIFT) feature and sparse representation. The approach takes advantage of SIFT which is local feature other than holistic feature in classical Sparse Representation based Classification (SRC) algorithm and possesses strong robustness to expression, pose and illumination variations. Since hexagonal image has more inherit merits than square image to make recognition process more efficient, we extract SIFT keypoint in hexagonal-sampling image. Instead of matching SIFT feature, firstly the sparse representation of each SIFT keypoint is given according the constructed dictionary; secondly these sparse vectors are quantized according dictionary; finally each face image is represented by a histogram and these so-called Bag-of-Words vectors are classified by SVM. Due to use of local feature, the proposed method achieves better result even when the number of training sample is small. In the experiments, the proposed method gave higher face recognition rather than other methods in ORL and Yale B face databases; also, the effectiveness of the hexagonal-sampling in the proposed method is verified.\n\nMBR-SIFT: A mirror reflected invariant feature descriptor using a binary representation for image matching.\n\nDirectory of Open Access Journals (Sweden)\n\nMingzhe Su\n\nFull Text Available The traditional scale invariant feature transform (SIFT method can extract distinctive features for image matching. However, it is extremely time-consuming in SIFT matching because of the use of the Euclidean distance measure. Recently, many binary SIFT (BSIFT methods have been developed to improve matching efficiency; however, none of them is invariant to mirror reflection. To address these problems, in this paper, we present a horizontal or vertical mirror reflection invariant binary descriptor named MBR-SIFT, in addition to a novel image matching approach. First, 16 cells in the local region around the SIFT keypoint are reorganized, and then the 128-dimensional vector of the SIFT descriptor is transformed into a reconstructed vector according to eight directions. Finally, the MBR-SIFT descriptor is obtained after binarization and reverse coding. To improve the matching speed and accuracy, a fast matching algorithm that includes a coarse-to-fine two-step matching strategy in addition to two similarity measures for the MBR-SIFT descriptor are proposed. Experimental results on the UKBench dataset show that the proposed method not only solves the problem of mirror reflection, but also ensures desirable matching accuracy and speed.\n\nMBR-SIFT: A mirror reflected invariant feature descriptor using a binary representation for image matching.\n\nScience.gov (United States)\n\nSu, Mingzhe; Ma, Yan; Zhang, Xiangfen; Wang, Yan; Zhang, Yuping\n\n2017-01-01\n\nThe traditional scale invariant feature transform (SIFT) method can extract distinctive features for image matching. However, it is extremely time-consuming in SIFT matching because of the use of the Euclidean distance measure. Recently, many binary SIFT (BSIFT) methods have been developed to improve matching efficiency; however, none of them is invariant to mirror reflection. To address these problems, in this paper, we present a horizontal or vertical mirror reflection invariant binary descriptor named MBR-SIFT, in addition to a novel image matching approach. First, 16 cells in the local region around the SIFT keypoint are reorganized, and then the 128-dimensional vector of the SIFT descriptor is transformed into a reconstructed vector according to eight directions. Finally, the MBR-SIFT descriptor is obtained after binarization and reverse coding. To improve the matching speed and accuracy, a fast matching algorithm that includes a coarse-to-fine two-step matching strategy in addition to two similarity measures for the MBR-SIFT descriptor are proposed. Experimental results on the UKBench dataset show that the proposed method not only solves the problem of mirror reflection, but also ensures desirable matching accuracy and speed.\n\nImproved Feature Detection in Fused Intensity-Range Images with Complex SIFT (âSIFT\n\nDirectory of Open Access Journals (Sweden)\n\nBoris Jutzi\n\n2011-09-01\n\nFull Text Available The real and imaginary parts are proposed as an alternative to the usual Polar representation of complex-valued images. It is proven that the transformation from Polar to Cartesian representation contributes to decreased mutual information, and hence to greater distinctiveness. The Complex Scale-Invariant Feature Transform (âSIFT detects distinctive features in complex-valued images. An evaluation method for estimating the uniformity of feature distributions in complex-valued images derived from intensity-range images is proposed. In order to experimentally evaluate the proposed methodology on intensity-range images, three different kinds of active sensing systems were used: Range Imaging, Laser Scanning, and Structured Light Projection devices (PMD CamCube 2.0, Z+F IMAGER 5003, Microsoft Kinect.\n\nImage Mosaic Method Based on SIFT Features of Line Segment\n\nDirectory of Open Access Journals (Sweden)\n\nJun Zhu\n\n2014-01-01\n\nFull Text Available This paper proposes a novel image mosaic method based on SIFT (Scale Invariant Feature Transform feature of line segment, aiming to resolve incident scaling, rotation, changes in lighting condition, and so on between two images in the panoramic image mosaic process. This method firstly uses Harris corner detection operator to detect key points. Secondly, it constructs directed line segments, describes them with SIFT feature, and matches those directed segments to acquire rough point matching. Finally, Ransac method is used to eliminate wrong pairs in order to accomplish image mosaic. The results from experiment based on four pairs of images show that our method has strong robustness for resolution, lighting, rotation, and scaling.\n\nCurrency recognition using a smartphone: Comparison between color SIFT and gray scale SIFT algorithms\n\nDirectory of Open Access Journals (Sweden)\n\nIyad Abu Doush\n\n2017-10-01\n\nFull Text Available Banknote recognition means classifying the currency (coin and paper to the correct class. In this paper, we developed a dataset for Jordanian currency. After that we applied automatic mobile recognition system using a smartphone on the dataset using scale-invariant feature transform (SIFT algorithm. This is the first attempt, to the best of the authors knowledge, to recognize both coins and paper banknotes on a smartphone using SIFT algorithm. SIFT has been developed to be the most robust and efficient local invariant feature descriptor. Color provides significant information and important values in the object description process and matching tasks. Many objects cannot be classified correctly without their color features. We compared between two approaches colored local invariant feature descriptor (color SIFT approach and gray image local invariant feature descriptor (gray SIFT approach. The evaluation results show that the color SIFT approach outperforms the gray SIFT approach in terms of processing time and accuracy.\n\nSIFT based algorithm for point feature tracking\n\nDirectory of Open Access Journals (Sweden)\n\nAdrian BURLACU\n\n2007-12-01\n\nFull Text Available In this paper a tracking algorithm for SIFT features in image sequences is developed. For each point feature extracted using SIFT algorithm a descriptor is computed using information from its neighborhood. Using an algorithm based on minimizing the distance between two descriptors tracking point features throughout image sequences is engaged. Experimental results, obtained from image sequences that capture scaling of different geometrical type object, reveal the performances of the tracking algorithm.\n\nSIFT-CCH: Increasing the SIFT distinctness by color co-occurrence histograms\n\nOpenAIRE\n\nANCUTI, Cosmin; BEKAERT, Philippe\n\n2007-01-01\n\nDescribing regions in a distinctive way, in order to find correct correspondences in images of two separated views, represents a complex and essential task of computer vision. Until now, SIFT (Scale Invariant Feature Transform) has been proven to be the most reliable descriptor among the others. One of the main drawbacks of SIFT is its vulnerability to color images, being designed mainly for the gray images. To overcome this problem and also to increase the overall distinctness of the SIFT ...\n\nPerformance Analysis of the SIFT Operator for Automatic Feature Extraction and Matching in Photogrammetric Applications\n\nDirectory of Open Access Journals (Sweden)\n\nFrancesco Nex\n\n2009-05-01\n\nFull Text Available In the photogrammetry field, interest in region detectors, which are widely used in Computer Vision, is quickly increasing due to the availability of new techniques. Images acquired by Mobile Mapping Technology, Oblique Photogrammetric Cameras or Unmanned Aerial Vehicles do not observe normal acquisition conditions. Feature extraction and matching techniques, which are traditionally used in photogrammetry, are usually inefficient for these applications as they are unable to provide reliable results under extreme geometrical conditions (convergent taking geometry, strong affine transformations, etc. and for bad-textured images. A performance analysis of the SIFT technique in aerial and close-range photogrammetric applications is presented in this paper. The goal is to establish the suitability of the SIFT technique for automatic tie point extraction and approximate DSM (Digital Surface Model generation. First, the performances of the SIFT operator have been compared with those provided by feature extraction and matching techniques used in photogrammetry. All these techniques have been implemented by the authors and validated on aerial and terrestrial images. Moreover, an auto-adaptive version of the SIFT operator has been developed, in order to improve the performances of the SIFT detector in relation to the texture of the images. The Auto-Adaptive SIFT operator (A2 SIFT has been validated on several aerial images, with particular attention to large scale aerial images acquired using mini-UAV systems.\n\nCurrency recognition using a smartphone: Comparison between color SIFT and gray scale SIFT algorithms\n\nOpenAIRE\n\nIyad Abu Doush; Sahar AL-Btoush\n\n2017-01-01\n\nBanknote recognition means classifying the currency (coin and paper) to the correct class. In this paper, we developed a dataset for Jordanian currency. After that we applied automatic mobile recognition system using a smartphone on the dataset using scale-invariant feature transform (SIFT) algorithm. This is the first attempt, to the best of the authors knowledge, to recognize both coins and paper banknotes on a smartphone using SIFT algorithm. SIFT has been developed to be the most robust a...\n\nColor Independent Components Based SIFT Descriptors for Object/Scene Classification\n\nScience.gov (United States)\n\nAi, Dan-Ni; Han, Xian-Hua; Ruan, Xiang; Chen, Yen-Wei\n\nIn this paper, we present a novel color independent components based SIFT descriptor (termed CIC-SIFT) for object/scene classification. We first learn an efficient color transformation matrix based on independent component analysis (ICA), which is adaptive to each category in a database. The ICA-based color transformation can enhance contrast between the objects and the background in an image. Then we compute CIC-SIFT descriptors over all three transformed color independent components. Since the ICA-based color transformation can boost the objects and suppress the background, the proposed CIC-SIFT can extract more effective and discriminative local features for object/scene classification. The comparison is performed among seven SIFT descriptors, and the experimental classification results show that our proposed CIC-SIFT is superior to other conventional SIFT descriptors.\n\nImproving scale invariant feature transform-based descriptors with shape-color alliance robust feature\n\nScience.gov (United States)\n\nWang, Rui; Zhu, Zhengdan; Zhang, Liang\n\n2015-05-01\n\nConstructing appropriate descriptors for interest points in image matching is a critical aspect task in computer vision and pattern recognition. A method as an extension of the scale invariant feature transform (SIFT) descriptor called shape-color alliance robust feature (SCARF) descriptor is presented. To address the problem that SIFT is designed mainly for gray images and lack of global information for feature points, the proposed approach improves the SIFT descriptor by means of a concentric-rings model, as well as integrating the color invariant space and shape context with SIFT to construct the SCARF descriptor. The SCARF method developed is more robust than the conventional SIFT with respect to not only the color and photometrical variations but also the measuring similarity as a global variation between two shapes. A comparative evaluation of different descriptors is carried out showing that the SCARF approach provides better results than the other four state-of-the-art related methods.\n\nSIFT applied to CBIR\n\nDirectory of Open Access Journals (Sweden)\n\nALMEIDA, J.\n\n2009-12-01\n\nFull Text Available Content-Based Image Retrieval (CBIR is a challenging task. Common approaches use only low-level features. Notwithstanding, such CBIR solutions fail on capturing some local features representing the details and nuances of scenes. Many techniques in image processing and computer vision can capture these scene semantics. Among them, the Scale Invariant Features Transform~(SIFT has been widely used in a lot of applications. This approach relies on the choice of several parameters which directly impact its effectiveness when applied to retrieve images. In this paper, we discuss the results obtained in several experiments proposed to evaluate the application of the SIFT in CBIR tasks.\n\nUnsupervised semantic indoor scene classification for robot vision based on context of features using Gist and HSV-SIFT\n\nScience.gov (United States)\n\nMadokoro, H.; Yamanashi, A.; Sato, K.\n\n2013-08-01\n\nThis paper presents an unsupervised scene classification method for actualizing semantic recognition of indoor scenes. Background and foreground features are respectively extracted using Gist and color scale-invariant feature transform (SIFT) as feature representations based on context. We used hue, saturation, and value SIFT (HSV-SIFT) because of its simple algorithm with low calculation costs. Our method creates bags of features for voting visual words created from both feature descriptors to a two-dimensional histogram. Moreover, our method generates labels as candidates of categories for time-series images while maintaining stability and plasticity together. Automatic labeling of category maps can be realized using labels created using adaptive resonance theory (ART) as teaching signals for counter propagation networks (CPNs). We evaluated our method for semantic scene classification using KTH's image database for robot localization (KTH-IDOL), which is popularly used for robot localization and navigation. The mean classification accuracies of Gist, gray SIFT, one class support vector machines (OC-SVM), position-invariant robust features (PIRF), and our method are, respectively, 39.7, 58.0, 56.0, 63.6, and 79.4%. The result of our method is 15.8% higher than that of PIRF. Moreover, we applied our method for fine classification using our original mobile robot. We obtained mean classification accuracy of 83.2% for six zones.\n\nAutomated mitosis detection using texture, SIFT features and HMAX biologically inspired approach.\n\nScience.gov (United States)\n\nIrshad, Humayun; Jalali, Sepehr; Roux, Ludovic; Racoceanu, Daniel; Hwee, Lim Joo; Naour, Gilles Le; Capron, FrÃ©dÃ©rique\n\n2013-01-01\n\nAccording to Nottingham grading system, mitosis count in breast cancer histopathology is one of three components required for cancer grading and prognosis. Manual counting of mitosis is tedious and subject to considerable inter- and intra-reader variations. The aim is to investigate the various texture features and Hierarchical Model and X (HMAX) biologically inspired approach for mitosis detection using machine-learning techniques. We propose an approach that assists pathologists in automated mitosis detection and counting. The proposed method, which is based on the most favorable texture features combination, examines the separability between different channels of color space. Blue-ratio channel provides more discriminative information for mitosis detection in histopathological images. Co-occurrence features, run-length features, and Scale-invariant feature transform (SIFT) features were extracted and used in the classification of mitosis. Finally, a classification is performed to put the candidate patch either in the mitosis class or in the non-mitosis class. Three different classifiers have been evaluated: Decision tree, linear kernel Support Vector Machine (SVM), and non-linear kernel SVM. We also evaluate the performance of the proposed framework using the modified biologically inspired model of HMAX and compare the results with other feature extraction methods such as dense SIFT. The proposed method has been tested on Mitosis detection in breast cancer histological images (MITOS) dataset provided for an International Conference on Pattern Recognition (ICPR) 2012 contest. The proposed framework achieved 76% recall, 75% precision and 76% F-measure. Different frameworks for classification have been evaluated for mitosis detection. In future work, instead of regions, we intend to compute features on the results of mitosis contour segmentation and use them to improve detection and classification rate.\n\nUnsupervised Video Shot Detection Using Clustering Ensemble with a Color Global Scale-Invariant Feature Transform Descriptor\n\nDirectory of Open Access Journals (Sweden)\n\nYuchou Chang\n\n2008-02-01\n\nFull Text Available Scale-invariant feature transform (SIFT transforms a grayscale image into scale-invariant coordinates of local features that are invariant to image scale, rotation, and changing viewpoints. Because of its scale-invariant properties, SIFT has been successfully used for object recognition and content-based image retrieval. The biggest drawback of SIFT is that it uses only grayscale information and misses important visual information regarding color. In this paper, we present the development of a novel color feature extraction algorithm that addresses this problem, and we also propose a new clustering strategy using clustering ensembles for video shot detection. Based on Fibonacci lattice-quantization, we develop a novel color global scale-invariant feature transform (CGSIFT for better description of color contents in video frames for video shot detection. CGSIFT first quantizes a color image, representing it with a small number of color indices, and then uses SIFT to extract features from the quantized color index image. We also develop a new space description method using small image regions to represent global color features as the second step of CGSIFT. Clustering ensembles focusing on knowledge reuse are then applied to obtain better clustering results than using single clustering methods for video shot detection. Evaluation of the proposed feature extraction algorithm and the new clustering strategy using clustering ensembles reveals very promising results for video shot detection.\n\nUnsupervised Video Shot Detection Using Clustering Ensemble with a Color Global Scale-Invariant Feature Transform Descriptor\n\nDirectory of Open Access Journals (Sweden)\n\nHong Yi\n\n2008-01-01\n\nFull Text Available Abstract Scale-invariant feature transform (SIFT transforms a grayscale image into scale-invariant coordinates of local features that are invariant to image scale, rotation, and changing viewpoints. Because of its scale-invariant properties, SIFT has been successfully used for object recognition and content-based image retrieval. The biggest drawback of SIFT is that it uses only grayscale information and misses important visual information regarding color. In this paper, we present the development of a novel color feature extraction algorithm that addresses this problem, and we also propose a new clustering strategy using clustering ensembles for video shot detection. Based on Fibonacci lattice-quantization, we develop a novel color global scale-invariant feature transform (CGSIFT for better description of color contents in video frames for video shot detection. CGSIFT first quantizes a color image, representing it with a small number of color indices, and then uses SIFT to extract features from the quantized color index image. We also develop a new space description method using small image regions to represent global color features as the second step of CGSIFT. Clustering ensembles focusing on knowledge reuse are then applied to obtain better clustering results than using single clustering methods for video shot detection. Evaluation of the proposed feature extraction algorithm and the new clustering strategy using clustering ensembles reveals very promising results for video shot detection.\n\nSecuring SIFT: Privacy-preserving Outsourcing Computation of Feature Extractions Over Encrypted Image Data.\n\nScience.gov (United States)\n\nHu, Shengshan; Wang, Qian; Wang, Jingjun; Qin, Zhan; Ren, Kui\n\n2016-05-13\n\nAdvances in cloud computing have greatly motivated data owners to outsource their huge amount of personal multimedia data and/or computationally expensive tasks onto the cloud by leveraging its abundant resources for cost saving and flexibility. Despite the tremendous benefits, the outsourced multimedia data and its originated applications may reveal the data owner's private information, such as the personal identity, locations or even financial profiles. This observation has recently aroused new research interest on privacy-preserving computations over outsourced multimedia data. In this paper, we propose an effective and practical privacy-preserving computation outsourcing protocol for the prevailing scale-invariant feature transform (SIFT) over massive encrypted image data. We first show that previous solutions to this problem have either efficiency/security or practicality issues, and none can well preserve the important characteristics of the original SIFT in terms of distinctiveness and robustness. We then present a new scheme design that achieves efficiency and security requirements simultaneously with the preservation of its key characteristics, by randomly splitting the original image data, designing two novel efficient protocols for secure multiplication and comparison, and carefully distributing the feature extraction computations onto two independent cloud servers. We both carefully analyze and extensively evaluate the security and effectiveness of our design. The results show that our solution is practically secure, outperforms the state-of-theart, and performs comparably to the original SIFT in terms of various characteristics, including rotation invariance, image scale invariance, robust matching across affine distortion, addition of noise and change in 3D viewpoint and illumination.\n\nSecSIFT: Privacy-preserving Outsourcing Computation of Feature Extractions Over Encrypted Image Data.\n\nScience.gov (United States)\n\nHu, Shengshan; Wang, Qian; Wang, Jingjun; Qin, Zhan; Ren, Kui\n\n2016-05-13\n\nAdvances in cloud computing have greatly motivated data owners to outsource their huge amount of personal multimedia data and/or computationally expensive tasks onto the cloud by leveraging its abundant resources for cost saving and flexibility. Despite the tremendous benefits, the outsourced multimedia data and its originated applications may reveal the data owner's private information, such as the personal identity, locations or even financial profiles. This observation has recently aroused new research interest on privacy-preserving computations over outsourced multimedia data. In this paper, we propose an effective and practical privacy-preserving computation outsourcing protocol for the prevailing scale-invariant feature transform (SIFT) over massive encrypted image data. We first show that previous solutions to this problem have either efficiency/security or practicality issues, and none can well preserve the important characteristics of the original SIFT in terms of distinctiveness and robustness. We then present a new scheme design that achieves efficiency and security requirements simultaneously with the preservation of its key characteristics, by randomly splitting the original image data, designing two novel efficient protocols for secure multiplication and comparison, and carefully distributing the feature extraction computations onto two independent cloud servers. We both carefully analyze and extensively evaluate the security and effectiveness of our design. The results show that our solution is practically secure, outperforms the state-of-theart, and performs comparably to the original SIFT in terms of various characteristics, including rotation invariance, image scale invariance, robust matching across affine distortion, addition of noise and change in 3D viewpoint and illumination.\n\nAutomated mitosis detection using texture, SIFT features and HMAX biologically inspired approach\n\nDirectory of Open Access Journals (Sweden)\n\nHumayun Irshad\n\n2013-01-01\n\nFull Text Available Context: According to Nottingham grading system, mitosis count in breast cancer histopathology is one of three components required for cancer grading and prognosis. Manual counting of mitosis is tedious and subject to considerable inter- and intra-reader variations. Aims: The aim is to investigate the various texture features and Hierarchical Model and X (HMAX biologically inspired approach for mitosis detection using machine-learning techniques. Materials and Methods: We propose an approach that assists pathologists in automated mitosis detection and counting. The proposed method, which is based on the most favorable texture features combination, examines the separability between different channels of color space. Blue-ratio channel provides more discriminative information for mitosis detection in histopathological images. Co-occurrence features, run-length features, and Scale-invariant feature transform (SIFT features were extracted and used in the classification of mitosis. Finally, a classification is performed to put the candidate patch either in the mitosis class or in the non-mitosis class. Three different classifiers have been evaluated: Decision tree, linear kernel Support Vector Machine (SVM, and non-linear kernel SVM. We also evaluate the performance of the proposed framework using the modified biologically inspired model of HMAX and compare the results with other feature extraction methods such as dense SIFT. Results: The proposed method has been tested on Mitosis detection in breast cancer histological images (MITOS dataset provided for an International Conference on Pattern Recognition (ICPR 2012 contest. The proposed framework achieved 76% recall, 75% precision and 76% F-measure. Conclusions: Different frameworks for classification have been evaluated for mitosis detection. In future work, instead of regions, we intend to compute features on the results of mitosis contour segmentation and use them to improve detection and\n\nSensor Fusion - Sonar and Stereo Vision, Using Occupancy Grids and SIFT\n\nDEFF Research Database (Denmark)\n\nPlascencia, Alfredo; Bendtsen, Jan Dimon\n\n2006-01-01\n\nto the occupied and empty regions. SIFT (Scale Invariant Feature Transform) feature descriptors areÂ interpreted using gaussian probabilistic error models. TheÂ use of occupancy grids is proposed for representing the sonarÂ as well as the features descriptors readings. The Bayesian estimation approach is applied...... to update the sonar and the SIFT descriptors' uncertainty grids. The sensor fusion yields a significant reduction in the uncertainty of the occupancy grid compared to the individual sensor readings....\n\nAn Improved SIFT Algorithm for Unmanned Aerial Vehicle Imagery\n\nInternational Nuclear Information System (INIS)\n\nLi, J M; Yan, D M; Wang, G; Zhang, L\n\n2014-01-01\n\nThe Unmanned Aerial Vehicle (UAV) platform has the benefits of low cost and convenience compared with satellites. Recently, UAVs have shown a wide range of applications such as land use change, mineral resources management and local topographic mapping. Because of the instability of the UAV air gesture, an image matching method is necessary to match different images of an object or scene. Scale Invariant Feature Transform (SIFT) features are invariant to image scaling, rotation and translation. However, the main drawback of a SIFT algorithm is its significant memory consumption and low computational speed, particularly in the case of high-resolution imagery. In this study, in order to overcome these drawbacks, we have analysed the construction of the scale-space in the SIFT algorithm and selected new parameters to construct the SIFT scale-space to improve the memory consumption and computational speed for the processing of UAV imagery. Here, we propose a restriction on the number of octaves and levels for Gaussian image pyramids. Our experiment shows that the proposed algorithm effectively reduces memory consumption and significantly improves the operational efficiency of the feature point extraction and matching under the premise of maintaining the precision of the extracted feature points\n\nSIFT Based Vein Recognition Models: Analysis and Improvement\n\nDirectory of Open Access Journals (Sweden)\n\nGuoqing Wang\n\n2017-01-01\n\nFull Text Available Scale-Invariant Feature Transform (SIFT is being investigated more and more to realize a less-constrained hand vein recognition system. Contrast enhancement (CE, compensating for deficient dynamic range aspects, is a must for SIFT based framework to improve the performance. However, evidence of negative influence on SIFT matching brought by CE is analysed by our experiments. We bring evidence that the number of extracted keypoints resulting by gradient based detectors increases greatly with different CE methods, while on the other hand the matching result of extracted invariant descriptors is negatively influenced in terms of Precision-Recall (PR and Equal Error Rate (EER. Rigorous experiments with state-of-the-art and other CE adopted in published SIFT based hand vein recognition system demonstrate the influence. What is more, an improved SIFT model by importing the kernel of RootSIFT and Mirror Match Strategy into a unified framework is proposed to make use of the positive keypoints change and make up for the negative influence brought by CE.\n\nTraffic sign recognition based on a context-aware scale-invariant feature transform approach\n\nScience.gov (United States)\n\nYuan, Xue; Hao, Xiaoli; Chen, Houjin; Wei, Xueye\n\n2013-10-01\n\nA new context-aware scale-invariant feature transform (CASIFT) approach is proposed, which is designed for the use in traffic sign recognition (TSR) systems. The following issues remain in previous works in which SIFT is used for matching or recognition: (1) SIFT is unable to provide color information; (2) SIFT only focuses on local features while ignoring the distribution of global shapes; (3) the template with the maximum number of matching points selected as the final result is instable, especially for images with simple patterns; and (4) SIFT is liable to result in errors when different images share the same local features. In order to resolve these problems, a new CASIFT approach is proposed. The contributions of the work are as follows: (1) color angular patterns are used to provide the color distinguishing information; (2) a CASIFT which effectively combines local and global information is proposed; and (3) a method for computing the similarity between two images is proposed, which focuses on the distribution of the matching points, rather than using the traditional SIFT approach of selecting the template with maximum number of matching points as the final result. The proposed approach is particularly effective in dealing with traffic signs which have rich colors and varied global shape distribution. Experiments are performed to validate the effectiveness of the proposed approach in TSR systems, and the experimental results are satisfying even for images containing traffic signs that have been rotated, damaged, altered in color, have undergone affine transformations, or images which were photographed under different weather or illumination conditions.\n\nRetinal Identification Based on an Improved Circular Gabor Filter and Scale Invariant Feature Transform\n\nDirectory of Open Access Journals (Sweden)\n\nXiaoming Xi\n\n2013-07-01\n\nFull Text Available Retinal identification based on retinal vasculatures in the retina provides the most secure and accurate means of authentication among biometrics and has primarily been used in combination with access control systems at high security facilities. Recently, there has been much interest in retina identification. As digital retina images always suffer from deformations, the Scale Invariant Feature Transform (SIFT, which is known for its distinctiveness and invariance for scale and rotation, has been introduced to retinal based identification. However, some shortcomings like the difficulty of feature extraction and mismatching exist in SIFT-based identification. To solve these problems, a novel preprocessing method based on the Improved Circular Gabor Transform (ICGF is proposed. After further processing by the iterated spatial anisotropic smooth method, the number of uninformative SIFT keypoints is decreased dramatically. Tested on the VARIA and eight simulated retina databases combining rotation and scaling, the developed method presents promising results and shows robustness to rotations and scale changes.\n\nRegistration of 3D spectral OCT volumes using 3D SIFT feature point matching\n\nScience.gov (United States)\n\nNiemeijer, Meindert; Garvin, Mona K.; Lee, Kyungmoo; van Ginneken, Bram; AbrÃ moff, Michael D.; Sonka, Milan\n\n2009-02-01\n\nThe recent introduction of next generation spectral OCT scanners has enabled routine acquisition of high resolution, 3D cross-sectional volumetric images of the retina. 3D OCT is used in the detection and management of serious eye diseases such as glaucoma and age-related macular degeneration. For follow-up studies, image registration is a vital tool to enable more precise, quantitative comparison of disease states. This work presents a registration method based on a recently introduced extension of the 2D Scale-Invariant Feature Transform (SIFT) framework1 to 3D.2 The SIFT feature extractor locates minima and maxima in the difference of Gaussian scale space to find salient feature points. It then uses histograms of the local gradient directions around each found extremum in 3D to characterize them in a 4096 element feature vector. Matching points are found by comparing the distance between feature vectors. We apply this method to the rigid registration of optic nerve head- (ONH) and macula-centered 3D OCT scans of the same patient that have only limited overlap. Three OCT data set pairs with known deformation were used for quantitative assessment of the method's robustness and accuracy when deformations of rotation and scaling were considered. Three-dimensional registration accuracy of 2.0+/-3.3 voxels was observed. The accuracy was assessed as average voxel distance error in N=1572 matched locations. The registration method was applied to 12 3D OCT scans (200 x 200 x 1024 voxels) of 6 normal eyes imaged in vivo to demonstrate the clinical utility and robustness of the method in a real-world environment.\n\nVisual Thing Recognition with Binary Scale-Invariant Feature Transform and Support Vector Machine Classifiers Using Color Information\n\nOpenAIRE\n\nWei-Jong Yang; Wei-Hau Du; Pau-Choo Chang; Jar-Ferr Yang; Pi-Hsia Hung\n\n2017-01-01\n\nThe demands of smart visual thing recognition in various devices have been increased rapidly for daily smart production, living and learning systems in recent years. This paper proposed a visual thing recognition system, which combines binary scale-invariant feature transform (SIFT), bag of words model (BoW), and support vector machine (SVM) by using color information. Since the traditional SIFT features and SVM classifiers only use the gray information, color information is still an importan...\n\nStereo matching based on SIFT descriptor with illumination and camera invariance\n\nScience.gov (United States)\n\nNiu, Haitao; Zhao, Xunjie; Li, Chengjin; Peng, Xiang\n\n2010-10-01\n\nStereo matching is the process of finding corresponding points in two or more images. The description of interest points is a critical aspect of point correspondence which is vital in stereo matching. SIFT descriptor has been proven to be better on the distinctiveness and robustness than other local descriptors. However, SIFT descriptor does not involve color information of feature point which provides powerfully distinguishable feature in matching tasks. Furthermore, in a real scene, image color are affected by various geometric and radiometric factors,such as gamma correction and exposure. These situations are very common in stereo images. For this reason, the color recorded by a camera is not a reliable cue, and the color consistency assumption is no longer valid between stereo images in real scenes. Hence the performance of other SIFT-based stereo matching algorithms can be severely degraded under the radiometric variations. In this paper, we present a new improved SIFT stereo matching algorithms that is invariant to various radiometric variations between left and right images. Unlike other improved SIFT stereo matching algorithms, we explicitly employ the color formation model with the parameters of lighting geometry, illuminant color and camera gamma in SIFT descriptor. Firstly, we transform the input color images to log-chromaticity color space, thus a linear relationship can be established. Then, we use a log-polar histogram to build three color invariance components for SIFT descriptor. So that our improved SIFT descriptor is invariant to lighting geometry, illuminant color and camera gamma changes between left and right images. Then we can match feature points between two images and use SIFT descriptor Euclidean distance as a geometric measure in our data sets to make it further accurate and robust. Experimental results show that our method is superior to other SIFT-based algorithms including conventional stereo matching algorithms under various\n\nA Novel Image Retrieval Based on Visual Words Integration of SIFT and SURF.\n\nDirectory of Open Access Journals (Sweden)\n\nNouman Ali\n\nFull Text Available With the recent evolution of technology, the number of image archives has increased exponentially. In Content-Based Image Retrieval (CBIR, high-level visual information is represented in the form of low-level features. The semantic gap between the low-level features and the high-level image concepts is an open research problem. In this paper, we present a novel visual words integration of Scale Invariant Feature Transform (SIFT and Speeded-Up Robust Features (SURF. The two local features representations are selected for image retrieval because SIFT is more robust to the change in scale and rotation, while SURF is robust to changes in illumination. The visual words integration of SIFT and SURF adds the robustness of both features to image retrieval. The qualitative and quantitative comparisons conducted on Corel-1000, Corel-1500, Corel-2000, Oliva and Torralba and Ground Truth image benchmarks demonstrate the effectiveness of the proposed visual words integration.\n\nRobot path Planning UsingÂ SIFT and Sonar Sensor Fusion\n\nDEFF Research Database (Denmark)\n\nPlascencia, Alfredo; Raposo, Hector\n\n2007-01-01\n\nand evidential grid maps, respectively. The approach is illustrated using actual measurements from a laboratory robot. The sensory information is obtained from a sonar array and the Scale Invariant Feature Transform (SIFT) algorithm. Finally, the resulting two evidential maps based on Bayes and Dempster theories...\n\nSIFT Meets CNN: A Decade Survey of Instance Retrieval.\n\nScience.gov (United States)\n\nZheng, Liang; Yang, Yi; Tian, Qi\n\n2018-05-01\n\nIn the early days, content-based image retrieval (CBIR) was studied with global features. Since 2003, image retrieval based on local descriptors (de facto SIFT) has been extensively studied for over a decade due to the advantage of SIFT in dealing with image transformations. Recently, image representations based on the convolutional neural network (CNN) have attracted increasing interest in the community and demonstrated impressive performance. Given this time of rapid evolution, this article provides a comprehensive survey of instance retrieval over the last decade. Two broad categories, SIFT-based and CNN-based methods, are presented. For the former, according to the codebook size, we organize the literature into using large/medium-sized/small codebooks. For the latter, we discuss three lines of methods, i.e., using pre-trained or fine-tuned CNN models, and hybrid methods. The first two perform a single-pass of an image to the network, while the last category employs a patch-based feature extraction scheme. This survey presents milestones in modern instance retrieval, reviews a broad selection of previous works in different categories, and provides insights on the connection between SIFT and CNN-based methods. After analyzing and comparing retrieval performance of different categories on several datasets, we discuss promising directions towards generic and specialized instance retrieval.\n\nColor-SIFT model: a robust and an accurate shot boundary detection algorithm\n\nScience.gov (United States)\n\nSharmila Kumari, M.; Shekar, B. H.\n\n2010-02-01\n\nIn this paper, a new technique called color-SIFT model is devised for shot boundary detection. Unlike scale invariant feature transform model that uses only grayscale information and misses important visual information regarding color, here we have adopted different color planes to extract keypoints which are subsequently used to detect shot boundaries. The basic SIFT model has four stages namely scale-space peak selection, keypoint localization, orientation assignment and keypoint descriptor and all these four stages were employed to extract key descriptors in each color plane. The proposed model works on three different color planes and a fusion has been made to take a decision on number of keypoint matches for shot boundary identification and hence is different from the color global scale invariant feature transform that works on quantized images. In addition, the proposed algorithm possess invariance to linear transformation and robust to occlusion and noisy environment. Experiments have been conducted on the standard TRECVID video database to reveal the performance of the proposed model.\n\nAutomatic registration of remote sensing images based on SIFT and fuzzy block matching for change detection\n\nDirectory of Open Access Journals (Sweden)\n\nCai Guo-Rong\n\n2011-10-01\n\nFull Text Available This paper presents an automated image registration approach to detecting changes in multi-temporal remote sensing images. The proposed algorithm is based on the scale invariant feature transform (SIFT and has two phases. The first phase focuses on SIFT feature extraction and on estimation of image transformation. In the second phase, Structured Local Binary Haar Pattern (SLBHP combined with a fuzzy similarity measure is then used to build a new and effective block similarity measure for change detection. Experimental results obtained on multi-temporal data sets show that compared with three mainstream block matching algorithms, the proposed algorithm is more effective in dealing with scale, rotation and illumination changes.\n\n3D-SIFT-Flow for atlas-based CT liver image segmentation.\n\nScience.gov (United States)\n\nXu, Yan; Xu, Chenchao; Kuang, Xiao; Wang, Hongkai; Chang, Eric I-Chao; Huang, Weimin; Fan, Yubo\n\n2016-05-01\n\nIn this paper, the authors proposed a new 3D registration algorithm, 3D-scale invariant feature transform (SIFT)-Flow, for multiatlas-based liver segmentation in computed tomography (CT) images. In the registration work, the authors developed a new registration method that takes advantage of dense correspondence using the informative and robust SIFT feature. The authors computed the dense SIFT features for the source image and the target image and designed an objective function to obtain the correspondence between these two images. Labeling of the source image was then mapped to the target image according to the former correspondence, resulting in accurate segmentation. In the fusion work, the 2D-based nonparametric label transfer method was extended to 3D for fusing the registered 3D atlases. Compared with existing registration algorithms, 3D-SIFT-Flow has its particular advantage in matching anatomical structures (such as the liver) that observe large variation/deformation. The authors observed consistent improvement over widely adopted state-of-the-art registration methods such as ELASTIX, ANTS, and multiatlas fusion methods such as joint label fusion. Experimental results of liver segmentation on the MICCAI 2007 Grand Challenge are encouraging, e.g., Dice overlap ratio 96.27% Â± 0.96% by our method compared with the previous state-of-the-art result of 94.90% Â± 2.86%. Experimental results show that 3D-SIFT-Flow is robust for segmenting the liver from CT images, which has large tissue deformation and blurry boundary, and 3D label transfer is effective and efficient for improving the registration accuracy.\n\nNonuniform multiview color texture mapping of image sequence and three-dimensional model for faded cultural relics with sift feature points\n\nScience.gov (United States)\n\nLi, Na; Gong, Xingyu; Li, Hongan; Jia, Pengtao\n\n2018-01-01\n\nFor faded relics, such as Terracotta Army, the 2D-3D registration between an optical camera and point cloud model is an important part for color texture reconstruction and further applications. This paper proposes a nonuniform multiview color texture mapping for the image sequence and the three-dimensional (3D) model of point cloud collected by Handyscan3D. We first introduce nonuniform multiview calibration, including the explanation of its algorithm principle and the analysis of its advantages. We then establish transformation equations based on sift feature points for the multiview image sequence. At the same time, the selection of nonuniform multiview sift feature points is introduced in detail. Finally, the solving process of the collinear equations based on multiview perspective projection is given with three steps and the flowchart. In the experiment, this method is applied to the color reconstruction of the kneeling figurine, Tangsancai lady, and general figurine. These results demonstrate that the proposed method provides an effective support for the color reconstruction of the faded cultural relics and be able to improve the accuracy of 2D-3D registration between the image sequence and the point cloud model.\n\nImproving scale invariant feature transform with local color contrastive descriptor for image classification\n\nScience.gov (United States)\n\nGuo, Sheng; Huang, Weilin; Qiao, Yu\n\n2017-01-01\n\nImage representation and classification are two fundamental tasks toward version understanding. Shape and texture provide two key features for visual representation and have been widely exploited in a number of successful local descriptors, e.g., scale invariant feature transform (SIFT), local binary pattern descriptor, and histogram of oriented gradient. Unlike these gradient-based descriptors, this paper presents a simple yet efficient local descriptor, named local color contrastive descriptor (LCCD), which captures the contrastive aspects among local regions or color channels for image representation. LCCD is partly inspired by the neural science facts that color contrast plays important roles in visual perception and there exist strong linkages between color and shape. We leverage f-divergence as a robust measure to estimate the contrastive features between different spatial locations and multiple channels. Our descriptor enriches local image representation with both color and contrast information. Due to that LCCD does not explore any gradient information, individual LCCD does not yield strong performance. But we verified experimentally that LCCD can compensate strongly SIFT. Extensive experimental results on image classification show that our descriptor improves the performance of SIFT substantially by combination on three challenging benchmarks, including MIT Indoor-67 database, SUN397, and PASCAL VOC 2007.\n\nLocalisation of the brain in fetal MRI using bundled SIFT features.\n\nScience.gov (United States)\n\nKeraudren, Kevin; Kyriakopoulou, Vanessa; Rutherford, Mary; Hajnal, Joseph V; Rueckert, Daniel\n\n2013-01-01\n\nFetal MRI is a rapidly emerging diagnostic imaging tool. Its main focus is currently on brain imaging, but there is a huge potential for whole body studies. We propose a method for accurate and robust localisation of the fetal brain in MRI when the image data is acquired as a stack of 2D slices misaligned due to fetal motion. We first detect possible brain locations in 2D images with a Bag-of-Words model using SIFT features aggregated within Maximally Stable Extremal Regions (called bundled SIFT), followed by a robust fitting of an axis-aligned 3D box to the selected regions. We rely on prior knowledge of the fetal brain development to define size and shape constraints. In a cross-validation experiment, we obtained a median error distance of 5.7mm from the ground truth and no missed detection on a database of 59 fetuses. This 2D approach thus allows a robust detection even in the presence of substantial fetal motion.\n\n3D-SIFT-Flow for atlas-based CT liver image segmentation\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nXu, Yan, E-mail: xuyan04@gmail.com [State Key Laboratory of Software Development Environment and Key Laboratory of Biomechanics and Mechanobiology of Ministry of Education, Beihang University, Beijing 100191, China and Research Institute of Beihang University in Shenzhen and Microsoft Research, Beijing 100080 (China); Xu, Chenchao, E-mail: chenchaoxu33@gmail.com; Kuang, Xiao, E-mail: kuangxiao.ace@gmail.com [School of Biological Science and Medical Engineering, Beihang University, Beijing 100191 (China); Wang, Hongkai, E-mail: wang.hongkai@gmail.com [Department of Biomedical Engineering, Dalian University of Technology, Dalian 116024 (China); Chang, Eric I-Chao, E-mail: eric.chang@microsoft.com [Microsoft Research, Beijing 100080 (China); Huang, Weimin, E-mail: wmhuang@i2r.a-star.edu.sg [Institute for Infocomm Research (I2R), Singapore 138632 (Singapore); Fan, Yubo, E-mail: yubofan@buaa.edu.cn [Key Laboratory of Biomechanics and Mechanobiology of Ministry of Education, Beihang University, Beijing 100191 (China)\n\n2016-05-15\n\nPurpose: In this paper, the authors proposed a new 3D registration algorithm, 3D-scale invariant feature transform (SIFT)-Flow, for multiatlas-based liver segmentation in computed tomography (CT) images. Methods: In the registration work, the authors developed a new registration method that takes advantage of dense correspondence using the informative and robust SIFT feature. The authors computed the dense SIFT features for the source image and the target image and designed an objective function to obtain the correspondence between these two images. Labeling of the source image was then mapped to the target image according to the former correspondence, resulting in accurate segmentation. In the fusion work, the 2D-based nonparametric label transfer method was extended to 3D for fusing the registered 3D atlases. Results: Compared with existing registration algorithms, 3D-SIFT-Flow has its particular advantage in matching anatomical structures (such as the liver) that observe large variation/deformation. The authors observed consistent improvement over widely adopted state-of-the-art registration methods such as ELASTIX, ANTS, and multiatlas fusion methods such as joint label fusion. Experimental results of liver segmentation on the MICCAI 2007 Grand Challenge are encouraging, e.g., Dice overlap ratio 96.27% Â± 0.96% by our method compared with the previous state-of-the-art result of 94.90% Â± 2.86%. Conclusions: Experimental results show that 3D-SIFT-Flow is robust for segmenting the liver from CT images, which has large tissue deformation and blurry boundary, and 3D label transfer is effective and efficient for improving the registration accuracy.\n\n3D-SIFT-Flow for atlas-based CT liver image segmentation\n\nInternational Nuclear Information System (INIS)\n\nXu, Yan; Xu, Chenchao; Kuang, Xiao; Wang, Hongkai; Chang, Eric I-Chao; Huang, Weimin; Fan, Yubo\n\n2016-01-01\n\nPurpose: In this paper, the authors proposed a new 3D registration algorithm, 3D-scale invariant feature transform (SIFT)-Flow, for multiatlas-based liver segmentation in computed tomography (CT) images. Methods: In the registration work, the authors developed a new registration method that takes advantage of dense correspondence using the informative and robust SIFT feature. The authors computed the dense SIFT features for the source image and the target image and designed an objective function to obtain the correspondence between these two images. Labeling of the source image was then mapped to the target image according to the former correspondence, resulting in accurate segmentation. In the fusion work, the 2D-based nonparametric label transfer method was extended to 3D for fusing the registered 3D atlases. Results: Compared with existing registration algorithms, 3D-SIFT-Flow has its particular advantage in matching anatomical structures (such as the liver) that observe large variation/deformation. The authors observed consistent improvement over widely adopted state-of-the-art registration methods such as ELASTIX, ANTS, and multiatlas fusion methods such as joint label fusion. Experimental results of liver segmentation on the MICCAI 2007 Grand Challenge are encouraging, e.g., Dice overlap ratio 96.27% Â± 0.96% by our method compared with the previous state-of-the-art result of 94.90% Â± 2.86%. Conclusions: Experimental results show that 3D-SIFT-Flow is robust for segmenting the liver from CT images, which has large tissue deformation and blurry boundary, and 3D label transfer is effective and efficient for improving the registration accuracy.\n\nIndonesian Sign Language Number Recognition using SIFT Algorithm\n\nScience.gov (United States)\n\nMahfudi, Isa; Sarosa, Moechammad; Andrie Asmara, Rosa; Azrino Gustalika, M.\n\n2018-04-01\n\nIndonesian sign language (ISL) is generally used for deaf individuals and poor people communication in communicating. They use sign language as their primary language which consists of 2 types of action: sign and finger spelling. However, not all people understand their sign language so that this becomes a problem for them to communicate with normal people. this problem also becomes a factor they are isolated feel from the social life. It needs a solution that can help them to be able to interacting with normal people. Many research that offers a variety of methods in solving the problem of sign language recognition based on image processing. SIFT (Scale Invariant Feature Transform) algorithm is one of the methods that can be used to identify an object. SIFT is claimed very resistant to scaling, rotation, illumination and noise. Using SIFT algorithm for Indonesian sign language recognition number result rate recognition to 82% with the use of a total of 100 samples image dataset consisting 50 sample for training data and 50 sample images for testing data. Change threshold value get affect the result of the recognition. The best value threshold is 0.45 with rate recognition of 94%.\n\nA comparative study of image low level feature extraction algorithms\n\nDirectory of Open Access Journals (Sweden)\n\nM.M. El-gayar\n\n2013-07-01\n\nFull Text Available Feature extraction and matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods for assessing the performance of popular image matching algorithms are presented and rely on costly descriptors for detection and matching. Specifically, the method assesses the type of images under which each of the algorithms reviewed herein perform to its maximum or highest efficiency. The efficiency is measured in terms of the number of matches founds by the algorithm and the number of type I and type II errors encountered when the algorithm is tested against a specific pair of images. Current comparative studies asses the performance of the algorithms based on the results obtained in different criteria such as speed, sensitivity, occlusion, and others. This study addresses the limitations of the existing comparative tools and delivers a generalized criterion to determine beforehand the level of efficiency expected from a matching algorithm given the type of images evaluated. The algorithms and the respective images used within this work are divided into two groups: feature-based and texture-based. And from this broad classification only three of the most widely used algorithms are assessed: color histogram, FAST (Features from Accelerated Segment Test, SIFT (Scale Invariant Feature Transform, PCA-SIFT (Principal Component Analysis-SIFT, F-SIFT (fast-SIFT and SURF (speeded up robust features. The performance of the Fast-SIFT (F-SIFT feature detection methods are compared for scale changes, rotation, blur, illumination changes and affine transformations. All the experiments use repeatability measurement and the number of correct matches for the evaluation measurements. SIFT presents its stability in most situations although its slow. F-SIFT is the fastest one with good performance as the same as SURF, SIFT, PCA-SIFT show its advantages in rotation and illumination changes.\n\nImage stack alignment in full-field X-ray absorption spectroscopy using SIFT_PyOCL.\n\nScience.gov (United States)\n\nPaleo, Pierre; Pouyet, Emeline; Kieffer, JÃ©rÃ´me\n\n2014-03-01\n\nFull-field X-ray absorption spectroscopy experiments allow the acquisition of millions of spectra within minutes. However, the construction of the hyperspectral image requires an image alignment procedure with sub-pixel precision. While the image correlation algorithm has originally been used for image re-alignment using translations, the Scale Invariant Feature Transform (SIFT) algorithm (which is by design robust versus rotation, illumination change, translation and scaling) presents an additional advantage: the alignment can be limited to a region of interest of any arbitrary shape. In this context, a Python module, named SIFT_PyOCL, has been developed. It implements a parallel version of the SIFT algorithm in OpenCL, providing high-speed image registration and alignment both on processors and graphics cards. The performance of the algorithm allows online processing of large datasets.\n\nSIFT-based Ear Recognition by Fusion of Detected Keypoints from Color Similarity Slice Regions\n\nOpenAIRE\n\nKisku, Dakshina Ranjan; Mehrotra, Hunny; Gupta, Phalguni; Sing, Jamuna Kanta\n\n2010-01-01\n\nEar biometric is considered as one of the most reliable and invariant biometrics characteristics in line with iris and fingerprint characteristics. In many cases, ear biometrics can be compared with face biometrics regarding many physiological and texture characteristics. In this paper, a robust and efficient ear recognition system is presented, which uses Scale Invariant Feature Transform (SIFT) as feature descriptor for structural representation of ear images. In order to make it more robus...\n\nModel-independent phenotyping of C. elegans locomotion using scale-invariant feature transform.\n\nDirectory of Open Access Journals (Sweden)\n\nYelena Koren\n\nFull Text Available To uncover the genetic basis of behavioral traits in the model organism C. elegans, a common strategy is to study locomotion defects in mutants. Despite efforts to introduce (semi-automated phenotyping strategies, current methods overwhelmingly depend on worm-specific features that must be hand-crafted and as such are not generalizable for phenotyping motility in other animal models. Hence, there is an ongoing need for robust algorithms that can automatically analyze and classify motility phenotypes quantitatively. To this end, we have developed a fully-automated approach to characterize C. elegans' phenotypes that does not require the definition of nematode-specific features. Rather, we make use of the popular computer vision Scale-Invariant Feature Transform (SIFT from which we construct histograms of commonly-observed SIFT features to represent nematode motility. We first evaluated our method on a synthetic dataset simulating a range of nematode crawling gaits. Next, we evaluated our algorithm on two distinct datasets of crawling C. elegans with mutants affecting neuromuscular structure and function. Not only is our algorithm able to detect differences between strains, results capture similarities in locomotory phenotypes that lead to clustering that is consistent with expectations based on genetic relationships. Our proposed approach generalizes directly and should be applicable to other animal models. Such applicability holds promise for computational ethology as more groups collect high-resolution image data of animal behavior.\n\nFingerprint Identification Using SIFT-Based Minutia Descriptors and Improved All Descriptor-Pair Matching\n\nDirectory of Open Access Journals (Sweden)\n\nJiuqiang Han\n\n2013-03-01\n\nFull Text Available The performance of conventional minutiae-based fingerprint authentication algorithms degrades significantly when dealing with low quality fingerprints with lots of cuts or scratches. A similar degradation of the minutiae-based algorithms is observed when small overlapping areas appear because of the quite narrow width of the sensors. Based on the detection of minutiae, Scale Invariant Feature Transformation (SIFT descriptors are employed to fulfill verification tasks in the above difficult scenarios. However, the original SIFT algorithm is not suitable for fingerprint because of: (1 the similar patterns of parallel ridges; and (2 high computational resource consumption. To enhance the efficiency and effectiveness of the algorithm for fingerprint verification, we propose a SIFT-based Minutia Descriptor (SMD to improve the SIFT algorithm through image processing, descriptor extraction and matcher. A two-step fast matcher, named improved All Descriptor-Pair Matching (iADM, is also proposed to implement the 1:N verifications in real-time. Fingerprint Identification using SMD and iADM (FISiA achieved a significant improvement with respect to accuracy in representative databases compared with the conventional minutiae-based method. The speed of FISiA also can meet real-time requirements.\n\nA feature extraction algorithm based on corner and spots in self-driving vehicles\n\nDirectory of Open Access Journals (Sweden)\n\nYupeng FENG\n\n2017-06-01\n\nFull Text Available To solve the poor real-time performance problem of the visual odometry based on embedded system with limited computing resources, an image matching method based on Harris and SIFT is proposed, namely the Harris-SIFT algorithm. On the basis of the review of SIFT algorithm, the principle of Harris-SIFT algorithm is provided. First, Harris algorithm is used to extract the corners of the image as candidate feature points, and scale invariant feature transform (SIFT features are extracted from those candidate feature points. At last, through an example, the algorithm is simulated by Matlab, then the complexity and other performance of the algorithm are analyzed. The experimental results show that the proposed method reduces the computational complexity and improves the speed of feature extraction. Harris-SIFT algorithm can be used in the real-time vision odometer system, and will bring about a wide application of visual odometry in embedded navigation system.\n\nAutomated Photogrammetric Image Matching with Sift Algorithm and Delaunay Triangulation\n\nDEFF Research Database (Denmark)\n\nKaragiannis, Georgios; AntÃ³n Castro, Francesc/FranÃ§ois; Mioc, Darka\n\n2016-01-01\n\nAn algorithm for image matching of multi-sensor and multi-temporal satellite images is developed. The method is based on the SIFT feature detector proposed by Lowe in (Lowe, 1999). First, SIFT feature points are detected independently in two images (reference and sensed image). The features detec...... of each feature set for each image are computed. The isomorphism of the Delaunay triangulations is determined to guarantee the quality of the image matching. The algorithm is implemented in Matlab and tested on World-View 2, SPOT6 and TerraSAR-X image patches....\n\nA Mean-Shift-Based Feature Descriptor for Wide Baseline Stereo Matching\n\nDirectory of Open Access Journals (Sweden)\n\nYiwen Dou\n\n2015-01-01\n\nFull Text Available We propose a novel Mean-Shift-based building approach in wide baseline. Initially, scale-invariance feature transform (SIFT approach is used to extract relatively stable feature points. As to each matching SIFT feature point, it needs a reasonable neighborhood range so as to choose feature points set. Subsequently, in view of selecting repeatable and high robust feature points, Mean-Shift controls corresponding feature scale. At last, our approach is employed to depth image acquirement in wide baseline and Graph Cut algorithm optimizes disparity information. Compared with the existing methods such as SIFT, speeded up robust feature (SURF, and normalized cross-correlation (NCC, the presented approach has the advantages of higher robustness and accuracy rate. Experimental results on low resolution image and weak feature description in wide baseline confirm the validity of our approach.\n\nBilateral symmetry detection on the basis of Scale Invariant Feature Transform.\n\nDirectory of Open Access Journals (Sweden)\n\nHabib Akbar\n\nFull Text Available The automatic detection of bilateral symmetry is a challenging task in computer vision and pattern recognition. This paper presents an approach for the detection of bilateral symmetry in digital single object images. Our method relies on the extraction of Scale Invariant Feature Transform (SIFT based feature points, which serves as the basis for the ascertainment of the centroid of the object; the latter being the origin under the Cartesian coordinate system to be converted to the polar coordinate system in order to facilitate the selection symmetric coordinate pairs. This is followed by comparing the gradient magnitude and orientation of the corresponding points to evaluate the amount of symmetry exhibited by each pair of points. The experimental results show that our approach draw the symmetry line accurately, provided that the observed centroid point is true.\n\nAn Innovative SIFT-Based Method for Rigid Video Object Recognition\n\nDirectory of Open Access Journals (Sweden)\n\nJie Yu\n\n2014-01-01\n\nFull Text Available This paper presents an innovative SIFT-based method for rigid video object recognition (hereafter called RVO-SIFT. Just like what happens in the vision system of human being, this method makes the object recognition and feature updating process organically unify together, using both trajectory and feature matching, and thereby it can learn new features not only in the training stage but also in the recognition stage, which can improve greatly the completeness of the video objectâs features automatically and, in turn, increases the ratio of correct recognition drastically. The experimental results on real video sequences demonstrate its surprising robustness and efficiency.\n\nGun bore flaw image matching based on improved SIFT descriptor\n\nScience.gov (United States)\n\nZeng, Luan; Xiong, Wei; Zhai, You\n\n2013-01-01\n\nIn order to increase the operation speed and matching ability of SIFT algorithm, the SIFT descriptor and matching strategy are improved. First, a method of constructing feature descriptor based on sector area is proposed. By computing the gradients histogram of location bins which are parted into 6 sector areas, a descriptor with 48 dimensions is constituted. It can reduce the dimension of feature vector and decrease the complexity of structuring descriptor. Second, it introduce a strategy that partitions the circular region into 6 identical sector areas starting from the dominate orientation. Consequently, the computational complexity is reduced due to cancellation of rotation operation for the area. The experimental results indicate that comparing with the OpenCV SIFT arithmetic, the average matching speed of the new method increase by about 55.86%. The matching veracity can be increased even under some variation of view point, illumination, rotation, scale and out of focus. The new method got satisfied results in gun bore flaw image matching. Keywords: Metrology, Flaw image matching, Gun bore, Feature descriptor\n\nEVALUATION OF SIFT AND SURF FOR VISION BASED LOCALIZATION\n\nDirectory of Open Access Journals (Sweden)\n\nX. Qu\n\n2016-06-01\n\nFull Text Available Vision based localization is widely investigated for the autonomous navigation and robotics. One of the basic steps of vision based localization is the extraction of interest points in images that are captured by the embedded camera. In this paper, SIFT and SURF extractors were chosen to evaluate their performance in localization. Four street view image sequences captured by a mobile mapping system, were used for the evaluation and both SIFT and SURF were tested on different image scales. Besides, the impact of the interest point distribution was also studied. We evaluated the performances from for aspects: repeatability, precision, accuracy and runtime. The local bundle adjustment method was applied to refine the pose parameters and the 3D coordinates of tie points. According to the results of our experiments, SIFT was more reliable than SURF. Apart from this, both the accuracy and the efficiency of localization can be improved if the distribution of feature points are well constrained for SIFT.\n\nAge and gender estimation using Region-SIFT and multi-layered SVM\n\nScience.gov (United States)\n\nKim, Hyunduk; Lee, Sang-Heon; Sohn, Myoung-Kyu; Hwang, Byunghun\n\n2018-04-01\n\nIn this paper, we propose an age and gender estimation framework using the region-SIFT feature and multi-layered SVM classifier. The suggested framework entails three processes. The first step is landmark based face alignment. The second step is the feature extraction step. In this step, we introduce the region-SIFT feature extraction method based on facial landmarks. First, we define sub-regions of the face. We then extract SIFT features from each sub-region. In order to reduce the dimensions of features we employ a Principal Component Analysis (PCA) and a Linear Discriminant Analysis (LDA). Finally, we classify age and gender using a multi-layered Support Vector Machines (SVM) for efficient classification. Rather than performing gender estimation and age estimation independently, the use of the multi-layered SVM can improve the classification rate by constructing a classifier that estimate the age according to gender. Moreover, we collect a dataset of face images, called by DGIST_C, from the internet. A performance evaluation of proposed method was performed with the FERET database, CACD database, and DGIST_C database. The experimental results demonstrate that the proposed approach classifies age and performs gender estimation very efficiently and accurately.\n\nNew Analysis Method Application in Metallographic Images through the Construction of Mosaics Via Speeded Up Robust Features and Scale Invariant Feature Transform\n\nDirectory of Open Access Journals (Sweden)\n\nPedro Pedrosa RebouÃ§as Filho\n\n2015-06-01\n\nresults and expediting the decision making process. Two different methods are proposed: One using the transformed Scale Invariant Feature Transform (SIFT, and the second using features extractor Speeded Up Robust Features (SURF. Although slower, the SIFT method is more stable and has a better performance than the SURF method and can be applied to real applications. The best results were obtained using SIFT with Peak Signal-to-Noise Ratio = 61.38, Mean squared error = 0.048 and mean-structural-similarity = 0.999, and processing time of 4.91 seconds for mosaic building. The methodology proposed shows be more promissory in aiding specialists during analysis of metallographic images.\n\nAutomated Orthorectification of VHR Satellite Images by SIFT-Based RPC Refinement\n\nDirectory of Open Access Journals (Sweden)\n\nHakan Kartal\n\n2018-06-01\n\nFull Text Available Raw remotely sensed images contain geometric distortions and cannot be used directly for map-based applications, accurate locational information extraction or geospatial data integration. A geometric correction process must be conducted to minimize the errors related to distortions and achieve the desired location accuracy before further analysis. A considerable number of images might be needed when working over large areas or in temporal domains in which manual geometric correction requires more labor and time. To overcome these problems, new algorithms have been developed to make the geometric correction process autonomous. The Scale Invariant Feature Transform (SIFT algorithm is an image matching algorithm used in remote sensing applications that has received attention in recent years. In this study, the effects of the incidence angle, surface topography and land cover (LC characteristics on SIFT-based automated orthorectification were investigated at three different study sites with different topographic conditions and LC characteristics using Pleiades very high resolution (VHR images acquired at different incidence angles. The results showed that the location accuracy of the orthorectified images increased with lower incidence angle images. More importantly, the topographic characteristics had no observable impacts on the location accuracy of SIFT-based automated orthorectification, and the results showed that Ground Control Points (GCPs are mainly concentrated in the âForestâ and âSemi Natural Areaâ LC classes. A multi-thread code was designed to reduce the automated processing time, and the results showed that the process performed 7 to 16 times faster using an automated approach. Analyses performed on various spectral modes of multispectral data showed that the arithmetic data derived from pan-sharpened multispectral images can be used in automated SIFT-based RPC orthorectification.\n\nAmbient analysis of trace compounds in gaseous media by SIFT-MS.\n\nScience.gov (United States)\n\nSmith, David; SpanÄl, Patrik\n\n2011-05-21\n\nThe topic of ambient gas analysis has been rapidly developed in the last few years with the evolution of the exciting new techniques such as DESI, DART and EESI. The essential feature of all is that analysis of trace gases can be accomplished either in the gas phase or those released from surfaces, crucially avoiding sample collection or modification. In this regard, selected ion flow tube mass spectrometry, SIFT-MS, also performs ambient analyses both accurately and rapidly. In this focused review we describe the underlying ion chemistry underpinning SIFT-MS through a discourse on the reactions of different classes of organic and inorganic molecules with H(3)O(+), NO(+) and O(2)(+)Ë studied using the SIFT technique. Rate coefficients and ion products of these reactions facilitate absolute SIFT-MS analyses and can also be useful for the interpretation of data obtained by the other ambient analysis methods mentioned above. The essential physics and flow dynamics of SIFT-MS are described that, together with the reaction kinetics, allow SIFT-MS to perform absolute ambient analyses of trace compounds in humid atmospheric air, exhaled breath and the headspace of aqueous liquids. Several areas of research that, through pilot experiments, are seen to benefit from ambient gas analysis using SIFT-MS are briefly reviewed. Special attention is given to exhaled breath and urine headspace analysis directed towards clinical diagnosis and therapeutic monitoring, and some other areas researched using SIFT-MS are summarised. Finally, extensions to current areas of application and indications of other directions in which SIFT-MS can be exploited for ambient analysis are alluded to.\n\nObject detection based on improved color and scale invariant features\n\nScience.gov (United States)\n\nChen, Mengyang; Men, Aidong; Fan, Peng; Yang, Bo\n\n2009-10-01\n\nA novel object detection method which combines color and scale invariant features is presented in this paper. The detection system mainly adopts the widely used framework of SIFT (Scale Invariant Feature Transform), which consists of both a keypoint detector and descriptor. Although SIFT has some impressive advantages, it is not only computationally expensive, but also vulnerable to color images. To overcome these drawbacks, we employ the local color kernel histograms and Haar Wavelet Responses to enhance the descriptor's distinctiveness and computational efficiency. Extensive experimental evaluations show that the method has better robustness and lower computation costs.\n\nFeature extraction and descriptor calculation methods for automatic georeferencing of Philippines' first microsatellite imagery\n\nScience.gov (United States)\n\nTupas, M. E. A.; Dasallas, J. A.; Jiao, B. J. D.; Magallon, B. J. P.; Sempio, J. N. H.; Ramos, M. K. F.; Aranas, R. K. D.; Tamondong, A. M.\n\n2017-10-01\n\nThe FAST-SIFT corner detector and descriptor extractor combination was used to automatically georeference DIWATA-1 Spaceborne Multispectral Imager images. Features from the Fast Accelerated Segment Test (FAST) algorithm detects corners or keypoints in an image, and these robustly detected keypoints have well-defined positions. Descriptors were computed using Scale-Invariant Feature Transform (SIFT) extractor. FAST-SIFT method effectively SMI same-subscene images detected by the NIR sensor. The method was also tested in stitching NIR images with varying subscene swept by the camera. The slave images were matched to the master image. The keypoints served as the ground control points. Random sample consensus was used to eliminate fall-out matches and ensure accuracy of the feature points from which the transformation parameters were derived. Keypoints are matched based on their descriptor vector. Nearest-neighbor matching is employed based on a metric distance between the descriptors. The metrics include Euclidean and city block, among others. Rough matching outputs not only the correct matches but also the faulty matches. A previous work in automatic georeferencing incorporates a geometric restriction. In this work, we applied a simplified version of the learning method. RANSAC was used to eliminate fall-out matches and ensure accuracy of the feature points. This method identifies if a point fits the transformation function and returns inlier matches. The transformation matrix was solved by Affine, Projective, and Polynomial models. The accuracy of the automatic georeferencing method were determined by calculating the RMSE of interest points, selected randomly, between the master image and transformed slave image.\n\nIllumination invariant feature point matching for high-resolution planetary remote sensing images\n\nScience.gov (United States)\n\nWu, Bo; Zeng, Hai; Hu, Han\n\n2018-03-01\n\nDespite its success with regular close-range and remote-sensing images, the scale-invariant feature transform (SIFT) algorithm is essentially not invariant to illumination differences due to the use of gradients for feature description. In planetary remote sensing imagery, which normally lacks sufficient textural information, salient regions are generally triggered by the shadow effects of keypoints, reducing the matching performance of classical SIFT. Based on the observation of dual peaks in a histogram of the dominant orientations of SIFT keypoints, this paper proposes an illumination-invariant SIFT matching method for high-resolution planetary remote sensing images. First, as the peaks in the orientation histogram are generally aligned closely with the sub-solar azimuth angle at the time of image collection, an adaptive suppression Gaussian function is tuned to level the histogram and thereby alleviate the differences in illumination caused by a changing solar angle. Next, the suppression function is incorporated into the original SIFT procedure for obtaining feature descriptors, which are used for initial image matching. Finally, as the distribution of feature descriptors changes after anisotropic suppression, and the ratio check used for matching and outlier removal in classical SIFT may produce inferior results, this paper proposes an improved matching procedure based on cross-checking and template image matching. The experimental results for several high-resolution remote sensing images from both the Moon and Mars, with illumination differences of 20Â°-180Â°, reveal that the proposed method retrieves about 40%-60% more matches than the classical SIFT method. The proposed method is of significance for matching or co-registration of planetary remote sensing images for their synergistic use in various applications. It also has the potential to be useful for flyby and rover images by integrating with the affine invariant feature detectors.\n\nQuantification of organ motion based on an adaptive image-based scale invariant feature method\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nPaganelli, Chiara [Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, piazza L. Da Vinci 32, Milano 20133 (Italy); Peroni, Marta [Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, piazza L. Da Vinci 32, Milano 20133, Italy and Paul Scherrer Institut, Zentrum fÃ¼r Protonentherapie, WMSA/C15, CH-5232 Villigen PSI (Italy); Baroni, Guido; Riboldi, Marco [Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, piazza L. Da Vinci 32, Milano 20133, Italy and Bioengineering Unit, Centro Nazionale di Adroterapia Oncologica, strada Campeggi 53, Pavia 27100 (Italy)\n\n2013-11-15\n\nPurpose: The availability of corresponding landmarks in IGRT image series allows quantifying the inter and intrafractional motion of internal organs. In this study, an approach for the automatic localization of anatomical landmarks is presented, with the aim of describing the nonrigid motion of anatomo-pathological structures in radiotherapy treatments according to local image contrast.Methods: An adaptive scale invariant feature transform (SIFT) was developed from the integration of a standard 3D SIFT approach with a local image-based contrast definition. The robustness and invariance of the proposed method to shape-preserving and deformable transforms were analyzed in a CT phantom study. The application of contrast transforms to the phantom images was also tested, in order to verify the variation of the local adaptive measure in relation to the modification of image contrast. The method was also applied to a lung 4D CT dataset, relying on manual feature identification by an expert user as ground truth. The 3D residual distance between matches obtained in adaptive-SIFT was then computed to verify the internal motion quantification with respect to the expert user. Extracted corresponding features in the lungs were used as regularization landmarks in a multistage deformable image registration (DIR) mapping the inhale vs exhale phase. The residual distances between the warped manual landmarks and their reference position in the inhale phase were evaluated, in order to provide a quantitative indication of the registration performed with the three different point sets.Results: The phantom study confirmed the method invariance and robustness properties to shape-preserving and deformable transforms, showing residual matching errors below the voxel dimension. The adapted SIFT algorithm on the 4D CT dataset provided automated and accurate motion detection of peak to peak breathing motion. The proposed method resulted in reduced residual errors with respect to standard SIFT\n\nFINGER KNUCKLE PRINT RECOGNITION WITH SIFT AND K-MEANS ALGORITHM\n\nDirectory of Open Access Journals (Sweden)\n\nA. Muthukumar\n\n2013-02-01\n\nFull Text Available In general, the identification and verification are done by passwords, pin number, etc., which is easily cracked by others. Biometrics is a powerful and unique tool based on the anatomical and behavioral characteristics of the human beings in order to prove their authentication. This paper proposes a novel recognition methodology of biometrics named as Finger Knuckle print (FKP. Hence this paper has focused on the extraction of features of Finger knuckle print using Scale Invariant Feature Transform (SIFT, and the key points are derived from FKP are clustered using K-Means Algorithm. The centroid of K-Means is stored in the database which is compared with the query FKP K-Means centroid value to prove the recognition and authentication. The comparison is based on the XOR operation. Hence this paper provides a novel recognition method to provide authentication. Results are performed on the PolyU FKP database to check the proposed FKP recognition method.\n\nCurvature histogram features for retrieval of images of smooth 3D objects\n\nInternational Nuclear Information System (INIS)\n\nZhdanov, I; Scherbakov, O; Potapov, A; Peterson, M\n\n2014-01-01\n\nWe consider image features on the base of histograms of oriented gradients (HOG) with addition of contour curvature histogram (HOG-CH), and also compare it with results of known scale-invariant feature transform (SIFT) approach in application to retrieval of images of smooth 3D objects.\n\nDependency Parsing with Transformed Feature\n\nDirectory of Open Access Journals (Sweden)\n\nFuxiang Wu\n\n2017-01-01\n\nFull Text Available Dependency parsing is an important subtask of natural language processing. In this paper, we propose an embedding feature transforming method for graph-based parsing, transform-based parsing, which directly utilizes the inner similarity of the features to extract information from all feature strings including the un-indexed strings and alleviate the feature sparse problem. The model transforms the extracted features to transformed features via applying a feature weight matrix, which consists of similarities between the feature strings. Since the matrix is usually rank-deficient because of similar feature strings, it would influence the strength of constraints. However, it is proven that the duplicate transformed features do not degrade the optimization algorithm: the margin infused relaxed algorithm. Moreover, this problem can be alleviated by reducing the number of the nearest transformed features of a feature. In addition, to further improve the parsing accuracy, a fusion parser is introduced to integrate transformed and original features. Our experiments verify that both transform-based and fusion parser improve the parsing accuracy compared to the corresponding feature-based parser.\n\nExposing region duplication through local geometrical color invariant features\n\nScience.gov (United States)\n\nGong, Jiachang; Guo, Jichang\n\n2015-05-01\n\nMany advanced image-processing softwares are available for tampering images. How to determine the authenticity of an image has become an urgent problem. Copy-move is one of the most common image forgery operations. Many methods have been proposed for copy-move forgery detection (CMFD). However, most of these methods are designed for grayscale images without any color information used. They are usually not suitable when the duplicated regions have little structure or have undergone various transforms. We propose a CMFD method using local geometrical color invariant features to detect duplicated regions. The method starts by calculating the color gradient of the inspected image. Then, we directly take the color gradient as the input for scale invariant features transform (SIFT) to extract color-SIFT descriptors. Finally, keypoints are matched and clustered before their geometrical relationship is estimated to expose the duplicated regions. We evaluate the detection performance and computational complexity of the proposed method together with several popular CMFD methods on a public database. Experimental results demonstrate the efficacy of the proposed method in detecting duplicated regions with various transforms and poor structure.\n\nOn the use of INS to improve Feature Matching\n\nScience.gov (United States)\n\nMasiero, A.; Guarnieri, A.; Vettore, A.; Pirotti, F.\n\n2014-11-01\n\nThe continuous technological improvement of mobile devices opens the frontiers of Mobile Mapping systems to very compact systems, i.e. a smartphone or a tablet. This motivates the development of efficient 3D reconstruction techniques based on the sensors typically embedded in such devices, i.e. imaging sensors, GPS and Inertial Navigation System (INS). Such methods usually exploits photogrammetry techniques (structure from motion) to provide an estimation of the geometry of the scene. Actually, 3D reconstruction techniques (e.g. structure from motion) rely on use of features properly matched in different images to compute the 3D positions of objects by means of triangulation. Hence, correct feature matching is of fundamental importance to ensure good quality 3D reconstructions. Matching methods are based on the appearance of features, that can change as a consequence of variations of camera position and orientation, and environment illumination. For this reason, several methods have been developed in recent years in order to provide feature descriptors robust (ideally invariant) to such variations, e.g. Scale-Invariant Feature Transform (SIFT), Affine SIFT, Hessian affine and Harris affine detectors, Maximally Stable Extremal Regions (MSER). This work deals with the integration of information provided by the INS in the feature matching procedure: a previously developed navigation algorithm is used to constantly estimate the device position and orientation. Then, such information is exploited to estimate the transformation of feature regions between two camera views. This allows to compare regions from different images but associated to the same feature as seen by the same point of view, hence significantly easing the comparison of feature characteristics and, consequently, improving matching. SIFT-like descriptors are used in order to ensure good matching results in presence of illumination variations and to compensate the approximations related to the estimation\n\nImproved medical image modality classification using a combination of visual and textual features.\n\nScience.gov (United States)\n\nDimitrovski, Ivica; Kocev, Dragi; Kitanovski, Ivan; Loskovska, Suzana; DÅ¾eroski, SaÅ¡o\n\n2015-01-01\n\nIn this paper, we present the approach that we applied to the medical modality classification tasks at the ImageCLEF evaluation forum. More specifically, we used the modality classification databases from the ImageCLEF competitions in 2011, 2012 and 2013, described by four visual and one textual types of features, and combinations thereof. We used local binary patterns, color and edge directivity descriptors, fuzzy color and texture histogram and scale-invariant feature transform (and its variant opponentSIFT) as visual features and the standard bag-of-words textual representation coupled with TF-IDF weighting. The results from the extensive experimental evaluation identify the SIFT and opponentSIFT features as the best performing features for modality classification. Next, the low-level fusion of the visual features improves the predictive performance of the classifiers. This is because the different features are able to capture different aspects of an image, their combination offering a more complete representation of the visual content in an image. Moreover, adding textual features further increases the predictive performance. Finally, the results obtained with our approach are the best results reported on these databases so far. Copyright Â© 2014 Elsevier Ltd. All rights reserved.\n\nA Novel Real-Time Feature Matching Scheme\n\nDirectory of Open Access Journals (Sweden)\n\nYing Liu\n\n2014-02-01\n\nFull Text Available Affine Scale Invariant Feature Transform (ASIFT can obtain fully affine invariance, however, its time cost reaches about twice that in Scale Invariant Feature Transform (SIFT. We propose an improved ASIFT algorithm based on feature points in scale space for real-time application. In order to detect the affine invariant feature point, we establish a second-order difference of Gaussian (DOG pyramid and replace the extreme detection in the DOG pyramid by zero detection in the proposed second-order DOG pyramid, which decreases the complexity of the scheme. Experimental results show that the proposed method has a big progress in the real-time performance compared to the traditional one, while preserving the fully affine invariance and precision.\n\nContact-free palm-vein recognition based on local invariant features.\n\nDirectory of Open Access Journals (Sweden)\n\nWenxiong Kang\n\nFull Text Available Contact-free palm-vein recognition is one of the most challenging and promising areas in hand biometrics. In view of the existing problems in contact-free palm-vein imaging, including projection transformation, uneven illumination and difficulty in extracting exact ROIs, this paper presents a novel recognition approach for contact-free palm-vein recognition that performs feature extraction and matching on all vein textures distributed over the palm surface, including finger veins and palm veins, to minimize the loss of feature information. First, a hierarchical enhancement algorithm, which combines a DOG filter and histogram equalization, is adopted to alleviate uneven illumination and to highlight vein textures. Second, RootSIFT, a more stable local invariant feature extraction method in comparison to SIFT, is adopted to overcome the projection transformation in contact-free mode. Subsequently, a novel hierarchical mismatching removal algorithm based on neighborhood searching and LBP histograms is adopted to improve the accuracy of feature matching. Finally, we rigorously evaluated the proposed approach using two different databases and obtained 0.996% and 3.112% Equal Error Rates (EERs, respectively, which demonstrate the effectiveness of the proposed approach.\n\nContact-free palm-vein recognition based on local invariant features.\n\nScience.gov (United States)\n\nKang, Wenxiong; Liu, Yang; Wu, Qiuxia; Yue, Xishun\n\n2014-01-01\n\nContact-free palm-vein recognition is one of the most challenging and promising areas in hand biometrics. In view of the existing problems in contact-free palm-vein imaging, including projection transformation, uneven illumination and difficulty in e"
    }
}