{
    "id": "wrong_mix_range_subsidiary_00024_1",
    "rank": 11,
    "data": {
        "url": "https://www.infoworld.com/article/2616171/cloudera-ceo-we-re-taking-hadoop-beyond-mapreduce.html",
        "read_more_link": "",
        "language": "en",
        "title": "Cloudera CEO: We’re taking Hadoop beyond MapReduce",
        "top_image": "https://www.infoworld.com/wp-content/themes/iw-b2b-child-theme/src/static/img/favicon-32x32.png",
        "meta_img": "https://www.infoworld.com/wp-content/themes/iw-b2b-child-theme/src/static/img/favicon-32x32.png",
        "images": [
            "https://www.infoworld.com/wp-content/uploads/2024/06/ericknorr_crop-100796856-orig.jpg?quality=50&strip=all&w=150",
            "https://www.infoworld.com/wp-content/uploads/2024/06/ericknorr_crop-100796856-orig.jpg?quality=50&strip=all&w=150",
            "https://www.infoworld.com/wp-content/uploads/2024/07/482983-0-25090900-1721775055-paulkrill_crop-100796855-orig.jpg?quality=50&strip=all&w=484",
            "https://www.infoworld.com/wp-content/uploads/2024/07/serdaryegulalp2_crop-100796854-orig-30.jpg?quality=50&strip=all&w=1024",
            "https://www.infoworld.com/wp-content/uploads/2024/06/nick_hodges-100924628-orig.jpg?quality=50&strip=all&w=200",
            "https://www.infoworld.com/wp-content/uploads/2024/07/2245414-0-31228800-1721725267-shutterstock_1811123305.jpg?quality=50&strip=all&w=375",
            "https://www.infoworld.com/wp-content/uploads/2024/07/2518705-0-97894400-1721723464-shutterstock_561931702-100932824-orig-100944253-orig-100962784-orig.jpg?quality=50&strip=all&w=405",
            "https://www.infoworld.com/wp-content/uploads/2024/07/3476079-0-23502300-1721690286-shutterstock_2299528137.jpg?quality=50&strip=all&w=375",
            "https://www.infoworld.com/wp-content/uploads/2024/07/Youtube-Thumbnails_Template-OLD-1.png?w=444",
            "https://www.infoworld.com/wp-content/uploads/2024/06/youtube-thumbnails_template-old-100963211-orig.jpg?quality=50&strip=all&w=444",
            "https://www.infoworld.com/wp-content/uploads/2024/06/youtube-thumbnails_template-old-100963201-orig.jpg?quality=50&strip=all&w=444"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Eric Knorr",
            "Eric Knorr Contributing",
            "Serdar Yegulalp Senior",
            "Nick Hodges Contributing"
        ],
        "publish_date": "2012-12-13T09:00:00-05:00",
        "summary": "",
        "meta_description": "In an exclusive interview, the voluble CEO of Cloudera, Mike Olson, holds forth on the company's new Impala project and the boundless potential of Hadoop",
        "meta_lang": "en",
        "meta_favicon": "https://www.infoworld.com/wp-content/themes/iw-b2b-child-theme/src/static/img/favicon.ico",
        "meta_site_name": "InfoWorld",
        "canonical_link": "https://www.infoworld.com/article/2283788/cloudera-ceo-we-re-taking-hadoop-beyond-mapreduce-2.html",
        "text": "Q: What do you see across your customer base? Are they tackling old problems in better, newer ways or are they tackling new problems that they wouldn’t have even tried with the other sets of technologies?\n\nA: I’ll be a weasely guy and say yes.\n\nQ: I had a feeling you might go in that direction…\n\nA: We see both use cases. I’ll say that there’s a certain class of innovative, transformative user at enterprises who say: You know what? I want to do behavioral analytics in a way that we could never do before, and I want to tie that to our marketing efforts to make better recommendations for customers. We’ve never done that before, but this platform seems a perfect build for it and I read about how Facebook is doing that and so we want to do some of that. Those folks have brought us in and they’ve built those systems and they’ve got their recommendation engines up and running and they work really well.\n\nThe number of people with that vision and the right command of both technical chops and business sense is a modest population. Until that’s shrink-wrapped and purchasable more easily, it’s going to be challenging to sell that vision, because some implementation execution is required.\n\nThere’s this other class of problems that folks have been struggling with for a long time. In financial services, noticing fraud in your transaction flow is a huge deal. A lot of companies make a lot of money watching transaction flows over relatively short periods of time and suggesting when fraud may be happening. If you carry a credit card, I’m sure you’ve had it happen that you just happened to be down at Walmart buying a TV, and that’s not a thing you do every day, and they declined your credit card because they made a bad decision. It happens, right? There are human escalations for that. But that’s a problem that has existed for a long time.\n\nWhat our customers are able to do now is go beyond watching short-duration transaction flows. Rather than the last week’s or month’s or even quarter’s worth of data, why don’t we store the last decade’s worth of transactions? Let’s look for fraudulent patterns using machine learning that span not hours or days, but a year. Can we find patterns that suggest money laundering over very long periods of time? The bad guys often know how the good guys are detecting bad behavior and design their attacks to get around that. More data gives you more ways to search for and see those patterns. Actually there are patterns that are visible in a lot of data that are just invisible in a small amount of data.\n\nQ: Can you talk about how you commercialize the technology and bring it to market?\n\nA: Doug Cutting, who created the Hadoop project, works here. He’s chief architect at Cloudera. We bundle a collection of open source projects into one big distribution that anybody can install. One hundred percent open-source: freely available, don’t give us your name, download it, use it for free.\n\nWe believe deeply in the value of that open source channel — not for political reasons, not for religious reasons. CIOs have learned over time that open source insulates them from bad vendor behavior. Open source tends to keep infrastructure vendors more honest. When we go into an account with open source, we’re a lap and a half ahead of all of our proprietary competitors. We’ve [sold] past one big objection, which is lock-in and bad behavior.\n\nWe created the Impala project. We built it, but we released it 100 percent open source. We employ committers and contributors to all of the software that we distribute. In fact, 70 percent of the committers for the projects we bundle are Cloudera employees. About half our engineering expense goes to stuff that we give away to the open source community. We benefit a lot as well. The global Apache community is making Hadoop better. Much of it is happening off my payroll, so I get all that benefit as well.\n\nQ: How are you monetizing?\n\nA: We monetize in the following way. In addition to making the platform software available open source, we’ve also built a proprietary piece of software called Cloudera Manager. You gang together a thousand computers to run Hadoop. Our distribution is actually not one computer program, it’s dozens of computer programs, and those get spread out among the thousand computers in different combinations. They get configured differently. As you said, there’s user code in the mix. I want to run analytics, so I’ve got to write Java code, and when there’s a bug in that collection it’s just a mess.\n\nHow do you track it down? How do you understand provisioning new users, capacity planning, setting and enforcing security policies, and so on? Cloudera Manager abstracts everything we know about running a Hadoop cluster and renders it into software. It’s the spotlight you can shine into an operating Hadoop cluster to understand it. Why is the storage layer slow? Hey, John’s job is not finishing. What’s going on? It knows all that stuff. That’s unique software to us. No one else has it.\n\nWe bundle it with open source distribution and we deliver that combination on an annual subscription basis with 24/7 support. That’s how we make a living. We do, in addition, have a training business and a consulting business and they’re both good businesses. The subscription business is already the dominant component, the majority of our revenues. The way we think about training and the way we think about consulting is make the market smarter and get customers productive faster, but really it feeds our subscription business. When we train you, we make you more able to deploy our open source platform and, we hope, our proprietary Cloudera enterprise bundle. Likewise, if we come on site and deliver consulting services to you, we get you productive faster on Hadoop and that expands your dependence on our enterprise offering and that turns you into a long-term renewable subscription customer, which is the goal.\n\nQ: At the beginning of that process, why would the customer choose your open source distribution over others?\n\nA: Let me talk about why I think we get chosen. First of all, we’ve been in business for about 4 1/2 years. We’ve got an enormous installed base now. More people run our software in production than all other distributions combined.\n\nOver that time period, over that big installed base, we’ve seen more failures than anybody else. I believe that we are better at supporting the platform for that experience. In fact, if your Hadoop cluster goes down, we help you get it back up and running. We also can go back and do root-cause analysis. We’ll look over your log files. What should we have seen three days ago that would have twigged us to the problem that something bad was going to happen and we didn’t know enough then? That stuff is now built into Cloudera Manager and we’ll alert on it. We’ll proactively tell you — hey, you might be getting low on space on node 19. We’ve seen enough of those failures that we’ve made it a part of the product.\n\nImpala — and frankly the vision we’ve got for diversity on the platform, the new engines that we’ll be adding — set us apart. Nobody else is doing that; we are the only vendor in the space that does it. It’s driven in part, again, by our time in market. We started working on that two years ago because of demand that we saw back then.\n\nThe other point is that nobody buys our software because we make it manageable. They buy our software because it solves a business problem. There’s an application that they’re running that matters to them and they need it to be manageable. So we get the sale.\n\nOur partner ecosystem is much, much larger than any other vendor: more than 400 companies that build on, integrate with, deliver services for, or can provide operating systems. If you want a platform that’s got the most tooling, that gives you the most choices, then we think we’re a good choice.\n\nQ: Who do you consider your core competitors?\n\nA: I know why you ask that question and I just hate it, because first, I don’t want to give those guys air time. Second, I don’t like quotes that get posted on locker room walls. Let me answer a different question, if I may. I’m going to be weasely, and you can even quote me as saying, “I’m going to be weasely.”\n\nI think what’s interesting right now is what’s happening in the data management market broadly. Twenty-five years of my career was building and selling relational databases. It was boring. Tighten the screws, polish the chrome, charge 30 percent more every single year. We made a good living, but nothing ever happened.\n\nOut of Google comes this new platform. We had no idea. We were taking care of our great big enterprise relational customers with a very demanding workload. We had an innovator’s dilemma problem. We were concentrating on the high end of the market and not what was happening anywhere else. So we got totally smoked by the introduction of this platform.\n\nI’ll go further. Like most of the rest of the relational industry, I read the Google paper in 2004. I thought it was a joke. No query language, no transactions. I mean, we knew how to build data management. This was nothing like that. The scale of problem, the scale of data available today is so quantitatively larger that it’s become qualitatively different. You’re struggling not to store terabytes but petabytes. Facebook’s latest publicly announced single cluster manages 105 petabytes of data on spinning disk — just incalculable amounts of information.\n\nWhen you’ve got that much data, you start to think about it differently. You can ask different questions, you can attack new problems. I think what’s really exciting is the opportunity for data capture and data analysis that is suddenly here because of the combination of data availability, all this machine-generated data.\n\nAlso, consider the compute infrastructure: blade-based servers that are rack mountable that you can buy in bulk to attack these problems. That combination lets us do stuff that just wasn’t possible a few years ago. We will answer important questions about disease, about feeding the world, producing energy. Yeah, by the way, about fraud and money laundering and transaction flows and about recommendation engines for consumers.\n\nWe’re going to be able to attack problems that have never been here before. I wouldn’t say that I’m competing with any established vendor for that. It’s a brand new opportunity that somebody is going to dominate, and we want to be that company. It’s the very early days, but we’d argue that we’re number one. But to become that company, survive long term, remain independent, deliver the breadth of service…a lot of flawless execution needs to happen.\n\nQ: Do you think existing database companies can be players in this market?\n\nA: In 1988, maybe ’87, if you had asked me, the highly insightful 25 year old that I was at the time, I would have told you IBM is the walking dead. I mean they’ve got the stink of a corpse on them. They gave away the PC market; their mainframe market is doomed. What I learned from that is that one should never discount the value of an enormous installed base and billions of dollars in cash.\n\nBig vendors with assets like that will survive. Will they be the dominant players in subsequent years? Will they drive the standard? Will they drive the market? I don’t know. Often a disruptive new entrant gets to do that. Think about what Oracle did in the database space. It wasn’t even first, right? But it executed extraordinarily well.\n\nQ: Who are some of your key partners and what are they doing for you?\n\nA: I talked a little bit about some of the ISV ecosystem partners: Informatica, MicroStrategy, QlikTech (just announced), Tableau, Talant. Anyone making tools or applications that unlock this big data value for business users is huge for us because we don’t do any of that. We just make it work for the data centers.\n\nQ: You don’t intend to go to the application level?\n\nA: I had the advantage of watching how Oracle, Microsoft, and IBM became dominant in the database space. They stayed relentlessly focused on the platform layer and left the ecosystem to create the absent tools on top. That gets a lot of other vendors innovating and creating diverse offerings and making money at it. Every one of those sales pulls the platform in.\n\nIt’s a long, long time before this platform is so ubiquitous that my growth is constrained and I have to move up the stack. Vendors like that are good partners for us. We’ve got a great consulting business, but my goal is to be a software company. I don’t want to build a huge cadre of systems integration guys that I bill out by the hour. We’ve got great relationships with systems integrators — Capgemini is a good example — that help drive the product into deployment.\n\nThe other category of vendors that we work with are the hardware folks: Dell, Hewlett-Packard, SGI, Network Appliance, and, this one’s a little surprising, but in their engineered systems division, Oracle. All five of those companies build and sell hardware to enterprises and resell Cloudera software for us. If you go to Oracle and buy their big data appliance, it’s running Cloudera enterprise.\n\nHadoop is tricky to sell. It’s still true that the vast majority of our revenue is our direct field, getting out and talking to customers. The last thing I’d say, and you didn’t directly ask, but our sales model looks a whole lot more like IBM’s or Oracle’s than it looks like MySQL or JBoss. This isn’t downloaded over the Internet and bought with a credit card. The expertise required to deploy a big distributed processing system on hundreds of nodes demands a lot more support from us, and so we’ve got a very high touch, a very typical enterprise software sales team.\n\nQ: Who buys it within that IT organization? Is it the same person who was buying the relational database?\n\nA: Yeah, actually, it is. The real trick to that answer is there’s no one person who buys a relational database. There are people in the data center, IT staff, who are responsible for choosing infrastructure to run workloads. Those folks typically choose on the basis of tech specs and SLAs and vendor expertise. We win much of that business.\n\nWe sell into the data center. We’ll go all the way up to the CIO or the director or VP-level people in the data center. Likewise, every now and then we go find one of those mavericks. A line-of-business owner or senior marketing exec has a vision for solving a business problem that the enterprise never tackled, and that guy makes a different decision. Often, we have to find both those parties. We’ve got to get the business guy excited about the potential of the platform and then the technical staff in the data center enthusiastic about our support for that.\n\nQ: That seems to be the hurdle on a lot of big data stuff — there really needs to be a business champion. But the business champion doesn’t understand the ways to make that happen. You either have to make the tools so easy they can go off and do some of it themselves, or you have to get these guys involved on the IT side in a more proactive way. So how do you go about bridging those two worlds?\n\nA: It’s an excellent observation. The answer is yeah, we ain’t done building that bridge yet. Here’s how it has worked so far and why we’re optimistic. First, you get a good sales force that knows how to sell infrastructure software. Folks who sell data management for a living can sell this new kind of data management. Really, the ability to tell use-case-based stories relevant to the industry is enormous. If I can say — oh, yeah, banker, we know from the other work we do on Wall Street about this equities pricing or risk analysis problem. Or tell credit card processors about this fraud or money laundering application. We built that; we know how it works.\n\nQ: What are the other gating factors? What keeps more people from going in this direction?\n\nA: Skill set and accurate information about what the platform can do. A lot of people have heard about big data. A lot of people have heard about Hadoop, but they don’t really have a clue as to what problems they should attack. That kind of evangelism, helping them understand that, is a big deal.\n\nIt had been the case that the maturity of the platform really impeded its adoption. Reliability and availability are largely fixed, but not all the way. We at Cloudera, the community broadly, still have some pathway in front of us on that stuff, but it’s a lot better than it was a while ago.\n\nQ: The incumbent business intelligence vendors say that what Hadoop is really good for is exploration: Just dump a bunch of data in there, decide what the patterns are that you want to pursue, and then organize it and port it into a conventional business intelligence tool. What’s your reaction to that?\n\nA: It absolutely has been true. I would argue even today that yeah, you could make that case. In fact many of the BI tools are used as the exploratory dashboards now looking through Cloudera Impala to explore your data.\n\nTo tell that story in a slightly different way, Hadoop MapReduce has been awesome at using machine learning to build models of user behavior, but when you want to recommend apps to people in real time, you extract those models that you’ve built and you roll them out in different infrastructures. You have a special-purpose, every-single-day tool, and you use Hadoop for back-end, large, ruminative workloads.\n\nThat’s largely an artifact of MapReduce. As I told you earlier, MapReduce was the first engine and Impala is the second. What’s really going to be interesting is what are three through n, right? There is no reason to believe that the shortcomings of Hadoop today are endemic to Hadoop. The platform that we sell today is going to be as much more capable, and much more general, than it is today five years from now."
    }
}