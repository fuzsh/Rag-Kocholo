{
    "id": "dbpedia_6615_3",
    "rank": 63,
    "data": {
        "url": "https://courses.lumenlearning.com/suny-natural-resources-biometrics/chapter/chapter-1-descriptive-statistics-and-the-normal-distribution/",
        "read_more_link": "",
        "language": "en",
        "title": "Natural Resources Biometrics",
        "top_image": "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170447/Image35759_fmt.png",
        "meta_img": "",
        "images": [
            "http://textbooks.opensuny.org/wp-content/uploads/OST-SOS-SUNY-logos_SOS-white.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170447/Image35759_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170449/958.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170450/948.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170451/927.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170452/910.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170452/902.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170453/893.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170455/Image35835_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170456/877.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170458/Image35846_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170501/860.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170502/852.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170503/842.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170504/832.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170506/823.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170507/816.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170508/809.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170509/761.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170510/750.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170510/Image35864_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170511/728.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170512/721.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170512/703.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170513/694.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170515/685.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170516/678.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170519/661.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170520/654.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170522/644.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170524/634.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170526/625.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170528/618.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170530/008_1_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170534/008_2_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170537/009_2_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170540/009_1_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170544/542.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170547/534.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170550/012_2_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170552/012_1_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170554/013_2_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170556/013_1_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170558/014_2_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170600/014_1_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170603/Kiernan_media015_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170605/Image36036_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170607/Image36045_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170609/438.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170612/429.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170614/Image36062_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170616/Image36070_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170618/Image36080_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170620/393.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170621/386.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170623/Image36090_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170625/369.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170627/Image36098_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170629/352.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170630/Image36106_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170632/Image36118_fmt.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170634/325.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170636/314.png",
            "https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170638/304.png",
            "https://courses.lumenlearning.com/suny-natural-resources-biometrics/wp-content/themes/bombadil/assets/images/FooterLumenCandela.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Diane Kiernan"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Natural Resources Biometrics begins with a review of descriptive statistics, estimation, and hypothesis testing. The following chapters cover one- and two-way analysis of variance (ANOVA), including multiple comparison methods and interaction assessment, with a strong emphasis on application and interpretation. Simple and multiple linear regressions in a natural resource setting are covered in the next chapters, focusing on correlation, model fitting, residual analysis, and confidence and prediction intervals. The final chapters cover growth and yield models, volume and biomass equations, site index curves, competition indices, importance values, and measures of species diversity, association, and community similarity.",
        "meta_lang": "en",
        "meta_favicon": "https://courses.lumenlearning.com/suny-natural-resources-biometrics/wp-content/themes/bombadil/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://courses.lumenlearning.com/suny-natural-resources-biometrics/chapter/chapter-1-descriptive-statistics-and-the-normal-distribution/",
        "text": "Statistics has become the universal language of the sciences, and data analysis can lead to powerful results. As scientists, researchers, and managers working in the natural resources sector, we all rely on statistical analysis to help us answer the questions that arise in the populations we manage. For example:\n\nHas there been a significant change in the mean sawtimber volume in the red pine stands?\n\nHas there been an increase in the number of invasive species found in the Great Lakes?\n\nWhat proportion of white tail deer in New Hampshire have weights below the limit considered healthy?\n\nDid fertilizer A, B, or C have an effect on the corn yield?\n\nThese are typical questions that require statistical analysis for the answers. In order to answer these questions, a good random sample must be collected from the population of interests. We then use descriptive statistics to organize and summarize our sample data. The next step is inferential statistics, which allows us to use our sample statistics and extend the results to the population, while measuring the reliability of the result. But before we begin exploring different types of statistical methods, a brief review of descriptive statistics is needed.\n\nStatistics is the science of collecting, organizing, summarizing, analyzing, and interpreting information.\n\nGood statistics come from good samples, and are used to draw conclusions or answer questions about a population. We use sample statistics to estimate population parameters (the truth). So let’s begin there…\n\nSection 1\n\nDescriptive Statistics\n\nA population is the group to be studied, and population data is a collection of all elements in the population. For example:\n\nAll the fish in Long Lake.\n\nAll the lakes in the Adirondack Park.\n\nAll the grizzly bears in Yellowstone National Park.\n\nA sample is a subset of data drawn from the population of interest. For example:\n\n100 fish randomly sampled from Long Lake.\n\n25 lakes randomly selected from the Adirondack Park.\n\n60 grizzly bears with a home range in Yellowstone National Park.\n\nPopulations are characterized by descriptive measures called parameters. Inferences about parameters are based on sample statistics. For example, the population mean (µ) is estimated by the sample mean (x̄). The population variance (σ2) is estimated by the sample variance (s2).\n\nVariables are the characteristics we are interested in. For example:\n\nThe length of fish in Long Lake.\n\nThe pH of lakes in the Adirondack Park.\n\nThe weight of grizzly bears in Yellowstone National Park.\n\nVariables are divided into two major groups: qualitative and quantitative. Qualitative variables have values that are attributes or categories. Mathematical operations cannot be applied to qualitative variables. Examples of qualitative variables are gender, race, and petal color. Quantitative variables have values that are typically numeric, such as measurements. Mathematical operations can be applied to these data. Examples of quantitative variables are age, height, and length.\n\nQuantitative variables can be broken down further into two more categories: discrete and continuous variables. Discrete variables have a finite or countable number of possible values. Think of discrete variables as “hens.” Hens can lay 1 egg, or 2 eggs, or 13 eggs… There are a limited, definable number of values that the variable could take on.\n\nContinuous variables have an infinite number of possible values. Think of continuous variables as “cows.” Cows can give 4.6713245 gallons of milk, or 7.0918754 gallons of milk, or 13.272698 gallons of milk … There are an almost infinite number of values that a continuous variable could take on.\n\nDescriptive Measures\n\nDescriptive measures of populations are called parameters and are typically written using Greek letters. The population mean is μ (mu). The population variance is σ2 (sigma squared) and population standard deviation is σ (sigma).\n\nDescriptive measures of samples are called statistics and are typically written using Roman letters. The sample mean is (x-bar). The sample variance is s2 and the sample standard deviation is s. Sample statistics are used to estimate unknown population parameters.\n\nIn this section, we will examine descriptive statistics in terms of measures of center and measures of dispersion. These descriptive statistics help us to identify the center and spread of the data.\n\nMeasures of Center\n\nMean\n\nThe arithmetic mean of a variable, often called the average, is computed by adding up all the values and dividing by the total number of values.\n\nThe population mean is represented by the Greek letter μ (mu). The sample mean is represented by x̄(x-bar). The sample mean is usually the best, unbiased estimate of the population mean. However, the mean is influenced by extreme values (outliers) and may not be the best measure of center with strongly skewed data. The following equations compute the population mean and sample mean.\n\nwhere xi is an element in the data set, N is the number of elements in the population, and n is the number of elements in the sample data set.\n\nMedian\n\nThe median of a variable is the middle value of the data set when the data are sorted in order from least to greatest. It splits the data into two equal halves with 50% of the data below the median and 50% above the median. The median is resistant to the influence of outliers, and may be a better measure of center with strongly skewed data.\n\nThe calculation of the median depends on the number of observations in the data set.\n\nTo calculate the median with an odd number of values (n is odd), first sort the data from smallest to largest.\n\nExample 3\n\n23, 27, 29, 31, 35, 39, 40, 42, 44, 47, 51\n\nThe median is 39. It is the middle value that separates the lower 50% of the data from the upper 50% of the data.\n\nTo calculate the median with an even number of values (n is even), first sort the data from smallest to largest and take the average of the two middle values.\n\nExample 4\n\n23, 27, 29, 31, 35, 39, 40, 42, 44, 47\n\nMode\n\nThe mode is the most frequently occurring value and is commonly used with qualitative data as the values are categorical. Categorical data cannot be added, subtracted, multiplied or divided, so the mean and median cannot be computed. The mode is less commonly used with quantitative data as a measure of center. Sometimes each value occurs only once and the mode will not be meaningful.\n\nUnderstanding the relationship between the mean and median is important. It gives us insight into the distribution of the variable. For example, if the distribution is skewed right (positively skewed), the mean will increase to account for the few larger observations that pull the distribution to the right. The median will be less affected by these extreme large values, so in this situation, the mean will be larger than the median. In a symmetric distribution, the mean, median, and mode will all be similar in value. If the distribution is skewed left (negatively skewed), the mean will decrease to account for the few smaller observations that pull the distribution to the left. Again, the median will be less affected by these extreme small observations, and in this situation, the mean will be less than the median.\n\nMeasures of Dispersion\n\nMeasures of center look at the average or middle values of a data set. Measures of dispersion look at the spread or variation of the data. Variation refers to the amount that the values vary among themselves. Values in a data set that are relatively close to each other have lower measures of variation. Values that are spread farther apart have higher measures of variation.\n\nExamine the two histograms below. Both groups have the same mean weight, but the values of Group A are more spread out compared to the values in Group B. Both groups have an average weight of 267 lb. but the weights of Group A are more variable.\n\nThis section will examine five measures of dispersion: range, variance, standard deviation, standard error, and coefficient of variation.\n\nRange\n\nThe range of a variable is the largest value minus the smallest value. It is the simplest measure and uses only these two values in a quantitative data set.\n\nExample 5\n\nFind the range for the given data set.\n\n12, 29, 32, 34, 38, 49, 57\n\nRange = 57 – 12 = 45\n\nVariance\n\nThe variance uses the difference between each value and its arithmetic mean. The differences are squared to deal with positive and negative differences. The sample variance (s2) is an unbiased estimator of the population variance (σ2), with n-1 degrees of freedom.\n\nDegrees of freedom: In general, the degrees of freedom for an estimate is equal to the number of values minus the number of parameters estimated en route to the estimate in question.\n\nThe sample variance is unbiased due to the difference in the denominator. If we used “n” in the denominator instead of “n – 1”, we would consistently underestimate the true population variance. To correct this bias, the denominator is modified to “n – 1”.\n\nPopulation variance Sample variance\n\nσ2 = s2 =\n\nStandard Deviation\n\nThe standard deviation is the square root of the variance (both population and sample). While the sample variance is the positive, unbiased estimator for the population variance, the units for the variance are squared. The standard deviation is a common method for numerically describing the distribution of a variable. The population standard deviation is σ (sigma) and sample standard deviation is s.\n\nPopulation standard deviation Sample standard deviation\n\nStandard Error of the Means\n\nCommonly, we use the sample mean x̄ to estimate the population mean μ. For example, if we want to estimate the heights of eighty-year-old cherry trees, we can proceed as follows:\n\nRandomly select 100 trees\n\nCompute the sample mean of the 100 heights\n\nUse that as our estimate\n\nWe want to use this sample mean to estimate the true but unknown population mean. But our sample of 100 trees is just one of many possible samples (of the same size) that could have been randomly selected. Imagine if we take a series of different random samples from the same population and all the same size:\n\nSample 1—we compute sample mean x̄\n\nSample 2—we compute sample mean x̄\n\nSample 3—we compute sample mean x̄\n\nEtc.\n\nEach time we sample, we may get a different result as we are using a different subset of data to compute the sample mean. This shows us that the sample mean is a random variable!\n\nThe sample mean (x̄) is a random variable with its own probability distribution called the sampling distribution of the sample mean. The distribution of the sample mean will have a mean equal to µ and a standard deviation equal to .\n\nThe standard error is the standard deviation of all possible sample means.\n\nIn reality, we would only take one sample, but we need to understand and quantify the sample to sample variability that occurs in the sampling process.\n\nThe standard error is the standard deviation of the sample means and can be expressed in different ways.\n\nNote: s2 is the sample variance and s is the sample standard deviation\n\nThe Central Limit Theorem (CLT) states that the sampling distribution of the sample means will approach a normal distribution as the sample size increases. If we do not have a normal distribution, or know nothing about our distribution of our random variable, the CLT tells us that the distribution of the x̄’s will become normal as n increases. How large does n have to be? A general rule of thumb tells us that n ≥ 30.\n\nThe Central Limit Theorem tells us that regardless of the shape of our population, the sampling distribution of the sample mean will be normal as the sample size increases.\n\nCoefficient of Variation\n\nTo compare standard deviations between different populations or samples is difficult because the standard deviation depends on units of measure. The coefficient of variation expresses the standard deviation as a percentage of the sample or population mean. It is a unitless measure.\n\nPopulation data Sample data\n\nCV = CV =\n\nVariability\n\nVariability is described in many different ways. Standard deviation measures point to point variability within a sample, i.e., variation among individual sampling units. Coefficient of variation also measures point to point variability but on a relative basis (relative to the mean), and is not influenced by measurement units. Standard error measures the sample to sample variability, i.e. variation among repeated samples in the sampling process. Typically, we only have one sample and standard error allows us to quantify the uncertainty in our sampling process.\n\nBasic Statistics Example using Excel and Minitab Software\n\nConsider the following tally from 11 sample plots on Heiburg Forest, where Xi is the number of downed logs per acre. Compute basic statistics for the sample plots.\n\n(1) Sample mean:\n\n(2) Median = 35\n\n(3) Variance:\n\n(4) Standard deviation:\n\n(5) Range: 55 – 5 = 50\n\n(6) Coefficient of variation:\n\n(7) Standard error of the mean:\n\nSoftware Solutions\n\nMinitab\n\nOpen Minitab and enter data in the spreadsheet. Select STAT>Descriptive stats and check all statistics required.\n\nDescriptive Statistics: Data\n\nVariable\n\nN\n\nN*\n\nMean\n\nSE Mean\n\nStDev\n\nVariance\n\nCoefVar\n\nMinimum\n\nQ1\n\nData\n\n11\n\n0\n\n32.27\n\n4.83\n\n16.03\n\n256.82\n\n49.66\n\n5.00\n\n20.00\n\nVariable\n\nMedian\n\nQ3\n\nMaximum\n\nIQR\n\nData\n\n35.00\n\n45.00\n\n55.00\n\n25.00\n\nExcel\n\nOpen up Excel and enter the data in the first column of the spreadsheet. Select DATA>Data Analysis>Descriptive Statistics. For the Input Range, select data in column A. Check “Labels in First Row” and “Summary Statistics”. Also check “Output Range” and select location for output.\n\nData\n\nMean\n\n32.27273\n\nStandard Error\n\n4.831884\n\nMedian\n\n35\n\nMode\n\n25\n\nStandard Deviation\n\n16.02555\n\nSample Variance\n\n256.8182\n\nKurtosis\n\n-0.73643\n\nSkewness\n\n-0.05982\n\nRange\n\n50\n\nMinimum\n\n5\n\nMaximum\n\n55\n\nSum\n\n355\n\nCount\n\n11\n\nGraphical Representation\n\nData organization and summarization can be done graphically, as well as numerically. Tables and graphs allow for a quick overview of the information collected and support the presentation of the data used in the project. While there are a multitude of available graphics, this chapter will focus on a specific few commonly used tools.\n\nPie Charts\n\nPie charts are a good visual tool allowing the reader to quickly see the relationship between categories. It is important to clearly label each category, and adding the frequency or relative frequency is often helpful. However, too many categories can be confusing. Be careful of putting too much information in a pie chart. The first pie chart gives a clear idea of the representation of fish types relative to the whole sample. The second pie chart is more difficult to interpret, with too many categories. It is important to select the best graphic when presenting the information to the reader.\n\nBar Charts and Histograms\n\nBar charts graphically describe the distribution of a qualitative variable (fish type) while histograms describe the distribution of a quantitative variable discrete or continuous variables (bear weight).\n\nIn both cases, the bars’ equal width and the y-axis are clearly defined. With qualitative data, each category is represented by a specific bar. With continuous data, lower and upper class limits must be defined with equal class widths. There should be no gaps between classes and each observation should fall into one, and only one, class.\n\nBoxplots\n\nBoxplots use the 5-number summary (minimum and maximum values with the three quartiles) to illustrate the center, spread, and distribution of your data. When paired with histograms, they give an excellent description, both numerically and graphically, of the data.\n\nWith symmetric data, the distribution is bell-shaped and somewhat symmetric. In the boxplot, we see that Q1 and Q3 are approximately equidistant from the median, as are the minimum and maximum values. Also, both whiskers (lines extending from the boxes) are approximately equal in length.\n\nWith skewed left distributions, we see that the histogram looks “pulled” to the left. In the boxplot, Q1 is farther away from the median as are the minimum values, and the left whisker is longer than the right whisker.\n\nWith skewed right distributions, we see that the histogram looks “pulled” to the right. In the boxplot, Q3 is farther away from the median, as is the maximum value, and the right whisker is longer than the left whisker.\n\nSection 2\n\nProbability Distribution\n\nOnce we have organized and summarized your sample data, the next step is to identify the underlying distribution of our random variable. Computing probabilities for continuous random variables are complicated by the fact that there are an infinite number of possible values that our random variable can take on, so the probability of observing a particular value for a random variable is zero. Therefore, to find the probabilities associated with a continuous random variable, we use a probability density function (PDF).\n\nA PDF is an equation used to find probabilities for continuous random variables. The PDF must satisfy the following two rules:\n\nThe area under the curve must equal one (over all possible values of the random variable).\n\nThe probabilities must be equal to or greater than zero for all possible values of the random variable.\n\nThe area under the curve of the probability density function over some interval represents the probability of observing those values of the random variable in that interval.\n\nThe Normal Distribution\n\nMany continuous random variables have a bell-shaped or somewhat symmetric distribution. This is a normal distribution. In other words, the probability distribution of its relative frequency histogram follows a normal curve. The curve is bell-shaped, symmetric about the mean, and defined by µ and σ (the mean and standard deviation).\n\nThere are normal curves for every combination of µ and σ. The mean (µ) shifts the curve to the left or right. The standard deviation (σ) alters the spread of the curve. The first pair of curves have different means but the same standard deviation. The second pair of curves share the same mean (µ) but have different standard deviations. The pink curve has a smaller standard deviation. It is narrower and taller, and the probability is spread over a smaller range of values. The blue curve has a larger standard deviation. The curve is flatter and the tails are thicker. The probability is spread over a larger range of values.\n\nProperties of the normal curve:\n\nThe mean is the center of this distribution and the highest point.\n\nThe curve is symmetric about the mean. (The area to the left of the mean equals the area to the right of the mean.)\n\nThe total area under the curve is equal to one.\n\nAs x increases and decreases, the curve goes to zero but never touches.\n\nThe PDF of a normal curve is .\n\nA normal curve can be used to estimate probabilities.\n\nA normal curve can be used to estimate proportions of a population that have certain x-values.\n\nThe Standard Normal Distribution\n\nThere are millions of possible combinations of means and standard deviations for continuous random variables. Finding probabilities associated with these variables would require us to integrate the PDF over the range of values we are interested in. To avoid this, we can rely on the standard normal distribution. The standard normal distribution is a special normal distribution with a µ = 0 and σ = 1. We can use the Z-score to standardize any normal random variable, converting the x-values to Z-scores, thus allowing us to use probabilities from the standard normal table. So how do we find area under the curve associated with a Z-score?\n\nStandard Normal Table\n\nThe standard normal table gives probabilities associated with specific Z-scores.\n\nThe table we use is cumulative from the left.\n\nThe negative side is for all Z-scores less than zero (all values less than the mean).\n\nThe positive side is for all Z-scores greater than zero (all values greater than the mean).\n\nNot all standard normal tables work the same way.\n\nExample 10\n\nWhat is the area associated with the Z-score 1.62?\n\nReading the Standard Normal Table\n\nRead down the Z-column to get the first part of the Z-score (1.6).\n\nRead across the top row to get the second decimal place in the Z-score (0.02).\n\nThe intersection of this row and column gives the area under the curve to the left of the Z-score.\n\nFinding Z-scores for a Given Area\n\nWhat if we have an area and we want to find the Z-score associated with that area?\n\nInstead of Z-score → area, we want area → Z-score.\n\nWe can use the standard normal table to find the area in the body of values and read backwards to find the associated Z-score.\n\nUsing the table, search the probabilities to find an area that is closest to the probability you are interested in.\n\nArea in between Two Z-scores\n\nCommon Z-scores\n\nThere are many commonly used Z-scores:\n\nZ.05 = 1.645 and the area between -1.645 and 1.645 is 90%\n\nZ.025 = 1.96 and the area between -1.96 and 1.96 is 95%\n\nZ.005 = 2.575 and the area between -2.575 and 2.575 is 99%\n\nApplications of the Normal Distribution\n\nTypically, our normally distributed data do not have μ = 0 and σ = 1, but we can relate any normal distribution to the standard normal distributions using the Z-score. We can transform values of x to values of z.\n\nFor example, if a normally distributed random variable has a μ = 6 and σ = 2, then a value of x = 7 corresponds to a Z-score of 0.5.\n\nThis tells you that 7 is one-half a standard deviation above its mean. We can use this relationship to find probabilities for any normal random variable.\n\nTo find the area for values of X, a normal random variable, draw a picture of the area of interest, convert the x-values to Z-scores using the Z-score and then use the standard normal table to find areas to the left, to the right, or in between.\n\nAssessing Normality\n\nIf the distribution is unknown and the sample size is not greater than 30 (Central Limit Theorem), we have to assess the assumption of normality. Our primary method is the normal probability plot. This plot graphs the observed data, ranked in ascending order, against the “expected” Z-score of that rank. If the sample data were taken from a normally distributed random variable, then the plot would be approximately linear.\n\nExamine the following probability plot. The center line is the relationship we would expect to see if the data were drawn from a perfectly normal distribution. Notice how the observed data (red dots) loosely follow this linear relationship. Minitab also computes an Anderson-Darling test to assess normality. The null hypothesis for this test is that the sample data have been drawn from a normally distributed population. A p-value greater than 0.05 supports the assumption of normality.\n\nCompare the histogram and the normal probability plot in this next example. The histogram indicates a skewed right distribution.\n\nThe observed data do not follow a linear pattern and the p-value for the A-D test is less than 0.005 indicating a non-normal population distribution.\n\nNormality cannot be assumed. You must always verify this assumption. Remember, the probabilities we are finding come from the standard NORMAL table. If our data are NOT normally distributed, then these probabilities DO NOT APPLY."
    }
}