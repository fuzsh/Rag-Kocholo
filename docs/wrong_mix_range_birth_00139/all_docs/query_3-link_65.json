{
    "id": "wrong_mix_range_birth_00139_3",
    "rank": 65,
    "data": {
        "url": "https://www.linkedin.com/posts/ronnyk_abtesting-experimentguide-pvalue-activity-7137182337276014592-Pw3K",
        "read_more_link": "",
        "language": "en",
        "title": "Ron Kohavi on LinkedIn: #abtesting #experimentguide #pvalue #power",
        "top_image": "https://media.licdn.com/dms/image/D5622AQHDiWGnGjfcRg/feedshare-shrink_2048_1536/0/1701636870314?e=2147483647&v=beta&t=49obSmBfD4y4IWuRnHki0DUV4GMdJTx-jv-G_pGe1qA",
        "meta_img": "https://media.licdn.com/dms/image/D5622AQHDiWGnGjfcRg/feedshare-shrink_2048_1536/0/1701636870314?e=2147483647&v=beta&t=49obSmBfD4y4IWuRnHki0DUV4GMdJTx-jv-G_pGe1qA",
        "images": [
            "https://media.licdn.com/dms/image/C5616AQF9HUlWeLWp-A/profile-displaybackgroundimage-shrink_200_800/0/1569344235626?e=2147483647&v=beta&t=_3It9yBHtZxYh09jXN-VW58VQYdpFxSrpOFQoO_j8Lc"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Ron Kohavi"
        ],
        "publish_date": "2023-12-03T20:54:31.611000+00:00",
        "summary": "",
        "meta_description": "Why positive A/B test results should always be given a haircut.\n\nWhenever you apply a thresholding criterion, such as p-value &lt; 0.05, for determining… | 58 comments on LinkedIn",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/posts/ronnyk_abtesting-experimentguide-pvalue-activity-7137182337276014592-Pw3K",
        "text": "Evidoo – another great resource for online sites to find promising ideas/patterns to evaluate with A/B tests. How do you generate ideas to A/B test? One of the best sources are proven patterns that others have found to be successful. In my course (https://bit.ly/ABClassRKLI), I point people to two sources of such patterns: Jakub Linowski's https://goodui.org, and Deborah O'Malley's https://guessTheTest.com. There is now a third good source: Jurjen Jongejan's http://evidoo.io . (To be clear, I am not paid any fee from any of these companies.) I recently evaluated Evidoo and here are my initial impressions: 1. Rich set of 3,000 patterns from Valantic customers. Jurgen told me that this represents about 20 years experiments from about 20 consultants involved with many clients. It's impressive that they signed contracts allowing them to share such aggregated data. 2. Pricing ranges from $299/month to $599/month, billed annually. A free tier provides access to 1% of the database. While this is expensive for small shops, a single new idea that works will justify this for many. 3. About 1,000, or 1/3 are marked as “best practices.” 4. Most experiments are focused on “transactions” (aka purchases). I usually pitch the need to more sophisticated Overall Evaluation Criteria and guardrails, but this is a great start. 5. About 70% of experiments are mobile experiments, the rest desktop. 6. Many experiments are sufficiently powered for small effects, a big benefit relative to the other two sites mentioned above, where low power remains a big issue. 7. An Evidoo rating is given to each pattern, which is an unpublished linear combination of the number of A/B tests, the win-ratio, the loss-ratio, the average impact, and the effort to implement. Jurjen shared the formula with me, and I’m not convinced of the weights (e.g., number of tests is given a large weight whether it’s a win or a loss), but it’s V1, and they will evolve it over time. 8. They use Bayesian statistics and not Frequentist, but there is little documentation on how the priors are set. My guess is that this is likely to align well with Frequentist approaches. 9. Each pattern shows the total number of users from all experiments, which is a strange statistic, as it may be dwarfed by one experiment. There is no sense of whether most experiments in the overall count were sufficiently powered. I would love to see some statistics like the Z-curve from Ulrich Schimmack. Note that the average impact is a double average: compute the average effect of each experiment and average those. Overall, I find this a great new resource, and I’d love to hear more feedback. To me, there is large ROI (Return-On-Investment) to trying patterns that were previously successful, and I have recently started a project to look at a small subset of patterns: https://lnkd.in/gWf35F7M . #abtest #experimentguide\n\nWant to read some fun theories about colors and shapes for websites? Here is an article with tons of references (including to the rounded shapes article I commented about in https://lnkd.in/gWuFZYzN) with amazing theories that just scream Twyman's Law (https://bit.ly/twymanLaw). For example, here is a hypothesis they claim is supported by the data: Perception of a colored website (red, blue) leads to higher pleasure, lower arousal and distrust, and more positive attitude than the same website without colors. I recommend 200,000 users for large treatment effects of 5% to websites (https://lnkd.in/g7akMisn). This paper relies on... 38 participants to evaluate multiple hypotheses. I usually look at metrics that are easy to measure, such as clicks, revenue, conversions, whereas they are evaluating \"pleasure,\" \"arousal,\" \"trust,\" \"attitude.\" It seems to me that there's a parallel universe where peer reviewed articles can be published based on a lot of references, pictures of the brain, and massive treatment effects based on tiny counts. This is *after* the replication crisis in Psychology: a 2024 paper. Article PDF: https://lnkd.in/gipGs-sA P.S. I wrote \"fun\" in the opening line because I filed this under comedy.\n\n24 June 2024 - in a week, my course on Accelerating Innovation with A/B Testing starts: https://bit.ly/ABClassRKLI . 23 Sept 2024 - registration is open for the next cohort, a quarter out. 9 Oct 2024 - Mini-course (3 hours) on advanced A/B Testing at EXL 2024: https://lnkd.in/gFvggxU3 . If you register for EXL (https://speero.com/exl), you will get a $500 off coupon for my Maven course since it (or equivalent knowledge) is a pre-requisite. Feedback from recent cohorts (see all at https://lnkd.in/gnTrpJhc): Even if you've been in the field of experimentation for a couple decades, there's so much to learn from his wisdom. Engaging classes, conversations, explanations, and meta-analyses! Ron passionately shares practical experimentation guidance for software companies and beyond. -- Principal Data Scientist, Microsoft The course provided great insight in all facets of testing and was exceptionally helpful being in the early stages of A/B test adoption. -- Director of Product Management, Expedia This was a great training course! I would recommend for anyone involved in a/b testing. -- Senior Manager, Software Engineering, Kohl's Engaging course content and a very knowledgeable instructor. The 5 sessions flew by and we covered a lot, plus you get resources for offline reading and research later too. I'd recommend it for experimenters of all roles who want to do more with A/B testing and more importantly, get it right. -- Product Manager, Amazon #abtesting #experimentguide Ben Labay"
    }
}