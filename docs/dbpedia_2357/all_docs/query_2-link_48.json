{
    "id": "dbpedia_2357_2",
    "rank": 48,
    "data": {
        "url": "https://ee.iisc.ac.in/storage/2021/12/seminars.htm",
        "read_more_link": "",
        "language": "en",
        "title": "Seminars",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://ee.iisc.ac.in/storage/2021/Users/Champaka/Desktop/0001.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Events and Seminars Archieve\n\n(Click on each item for details)\n\nEvent : Thesis Defence\n\nTitle : Techniques for estimating the direction of pointing gestures using depth images in the presence of orientation and distance variations from the depth sensor\n\nSpeaker : Shome Subhra Das\n\nDegree Registered :PhD<\n\nDate : 17/11/2021\n\nVenue : Online\n\nAbstract : Currently, we interact with computers, robots, drones, and virtual reality interfaces using pointing devices such as mouse, touchpad, joystick, virtual reality wand, drone controller, etc. These devices have one or more of the following limitations: being cumbersome, non-immersive, immobile, and having a steep learning curve. The target of this work is to explore ways to replace existing pointing devices with pointing gesture-based interfaces.\n\nThis thesis addresses two problems, namely estimating the direction being indicated by a pointing gesture (PDE) and detection of pointing gestures. The proposed techniques use a single depth sensor and use only the hand region. To our knowledge, this is the maiden attempt at creating depth and orientation tolerant, accurate methods for estimating the pointing direction using only depth images of the hand region. The proposed methods achieve accuracies comparable to or better than those of existing methods while avoiding their limitations.\n\nSignificant contributions of the thesis:\n\nProposing a real-time technique for estimating the pointing direction using a nine-axis inertial motion unit (IMU) and an RGB-D sensor. It is the first method to compute the pointing direction (PD) by finding the axis vector of the index finger. It is also the first method to fuse information from the IMU and depth sensor to obtain the PD. Further, this is the first method to obtain the ground-truth pointing direction of pointing gestures using depth data of the index finger region.\n\nCreation of a large (100k+ samples) dataset with accurate ground truth for PDE from depth images. Each sample consists of the segmented depth image of a hand, the fingertip location (2D + 3D), the pointing vector (as a unit vector and in terms of the yaw and pitch values), and the mean depth of the hand. This is the first public dataset for depth image based PDE that has accurate ground truth and a large number of samples.\n\nProposing a new 3D convolutional neural network-based method to estimate pointing direction. This is the first deep learning-based method for PDE that uses only the depth images of the hand region for PDE, without the use of RGB data. It is tolerant to variation in orientation and depth of the hand with respect to the camera and is suitable for real-time applications.\n\nProposing another technique for estimating the pointing direction using global registration of the test data point cloud with a pointing hand model captured using Kinect fusion-based method. It is tolerant to the variation in the orientation and depth of the hand w.r.t. the RGB-D sensor. It does not have the limitation of the previously proposed methods since it does not require the attachment of any device such as IMU nor does it require any dataset for training. It achieves less net angular error than most techniques in the literature using only the hand region.\n\nCreation of a large dataset of positive and negative samples for detection of pointing gestures from depth images of the hand region. A technique is also proposed using deep learning to distinguish pointing gestures from other hand gestures. This achieves higher accuracy than the only other existing technique by Cordo et al. for detection of pointing gestures from depth images of the hand.\n\nGo to\n\nEvent : Seminar\n\nTitle :\n\nSpeaker : Dr. Kannan Tirugnanam\n\nDate : 20/20/2021\n\nVenue : Online\n\nAbstract :\n\nSpeaker Biodata :\n\nGo to\n\nEvent : Thesis Colloquium\n\nTitle : Modelling, Stabilization Methods and Power Amplification for Power Hardware-in-Loop Simulation with Improved Accuracy\n\nSpeaker : Kapil Upamanyu\n\nDegree Registered :PhD\n\nAdvisor : Prof. G Narauyanan\n\nDate : 13/10/2021\n\nVenue : Online\n\nAbstract : Simulations of physical systems are conducted extensively for research and design purpose. Potential of a simulation can be extended significantly by conducting it in real-time. Real-time simulation allows for hardware-in-loop (HIL) simulation of a system, i.e., a part of the system represented by a mathematical model in conventional simulation is replaced by a physical hardware. When the power level of the physical hardware is considerably higher than that of RTS signals, the output of RTS is applied to the physical hardware through a power amplifier (PA), and such an HIL is known as power HIL (PHIL). PHIL simulation allows for the testing of a physical hardware (device under test), in a safe and controlled environment, without the rest of the system being available. Among other factors, the dynamics of the PA, which are not present in the actual system, cause the response of the PHIL simulation to differ from that of the actual system. Conventional switched-mode PAs, which utilize passive filters to attenuate the switching harmonics, have limited dynamic response. These PAs, when employed in a PHIL simulation, are unable to accurately replicate the fast transients of the system. A high-bandwidth switched-mode PA without output filter is proposed for improved accuracy of PHIL simulations. Even with fast PAs, inaccuracies are present in a PHIL simulation due to finite computation time of RTS, the transport lag of signals and the sampling effects of RTS. The inaccuracy can be so significant that the PHIL simulation of a system can be unstable even though the actual system is stable, and vice versa. A discrete-time domain modelling is proposed, which estimates the instability of a PHIL simulation much better than the conventional continuous-time domain approach. An unstable PHIL simulation can be stabilized by employing compensation algorithms. Novel compensation algorithms are proposed for stabilizing those PHIL simulation which cann ot be stabilized using conventional compensation algorithms. An output filter-less voltage source inverter is proposed as a PA suitable to be interfaced with inductive loads (e.g., most of the power system loads). Such a PA has a reference tracking bandwidth comparable to the switching frequency. Unlike the output of the conventional PAs, the output of the proposed PA is completely unaffected by the sudden changes in the current drawn by the loads. The proposed PA, realized through an IGBT-based converter stack, is utilized to emulate the transients of synchronous generator, including the fast transient corresponding to the field excitation controller, while feeding a passive linear load. A modified synchronous generator emulation method is proposed, which is capable of replicating the stator transients accurately for balanced, unbalanced and non-linear loads. The applicability of the proposed PA is extended for it to be interfaced to PWM converters by proposing an in-phase synchronization of PWM carriers of the PA and the converter under test. The PA is utilized for emulating unbalanced and harmonic (up to 23rd order) grid voltages while testing the control of a three-phase 415 V, 3kW PWM rectifier. Accurate current responses are also obtained when the step changes in the grid voltage and the rectifier dc bus reference are considered. For various applications, a PA is required to have power sinking capability, which can be achieved by supplying it from a grid-connected bidirectional PWM rectifier. A simple input voltage sensor-less vector control of PWM rectifier is proposed. While the performance of the proposed method, in terms of THD and power factor, is comparable to the sensor-based method and existing sensor-less methods, its computation time requirement is much lower than those for these methods. The proposed control is validated through simulations and experiments on a three-phase 415 V, 3 kW grid-connected PWM rectifier, generating 800 V dc supply. A discrete-time domain modelling of the PI-controlled current loop of PWM converters, which is accurate even when the bandwidth of the loop is close to the switching frequency, is presented. Conventionally, the continuous-time domain models approximate the time delay in the system and hence are inaccurate for high-bandwidth current loops. The discrete-time domain model is used to derive closed-form time-domain expressions of the current for step changes in the current reference and the disturbance voltage, for a given set of controller and hardware parameters. Based on the derived expressions, a pre-filter to the PI-controlled current loop is proposed to achieve the dead-beat response (two-switching cycle settling time) for the reference tracking, while having a settling time much lesser than those with the existing dead-beat control methods for a step change in the disturbance. Conventionally, continuous-time domain methods are used to model PHIL simulations. For PHIL simulation having fast PAs, the effects of sampling at the input and zero-order hold at the output of RTS are significant and are not adequately modelled through continuous-time domain approach. Since, a PHIL simulation consists of discrete-time RTS, a more accurate discrete-time domain modelling approach is proposed. The proposed model is used to conduct stability analysis of a PHIL simulation. The stability limits in terms of the parameters of the simulated and physical quantities are more accurately estimated through the proposed method as compared to the conventional methods. The stability limits of PHIL simulation are verified through simulations and experiments. Compensation algorithms, such as feedback current filtering method, are employed for stabilizing an unstable PHIL simulation. The proposed modelling method is further utilized to conduct the stability analysis of PHIL simulation employing existing compensation algorithms. The analysis provides the stability limits in terms of the cut-off frequency of the filters used for the compensation. The proposed discrete-time model can also be used to design the parameters of the compensation. The effectiveness of the proposed model in predicting the stability of PHIL simulation and the design of compensation are validated through simulations and experiments. Further, novel compensation algorithms, based on lag compensator and cross coupled compensator, are proposed. These are used to stabilize PHIL simulations which are originally unstable without and with existing compensation algorithms. A novel fault-tolerant synchronous inverter, i.e., a renewable energy fed grid-connected voltage source inverter emulated as a synchronous generator, is realized based on the proposed cross-coupled compensator.\n\nSpeaker Biodata :\n\nGo to\n\nEvent : Seminar\n\nTitle : Sustainability through High Voltage Engineering and Research\n\nSpeaker : Dr. Prem Ranjan\n\nDate : 14/10/2021\n\nVenue : Online\n\nAbstract : Through this talk, we will take a glance at applications of high voltage engineering in three different sustainable technologies. (a) Direct application of high voltage and pulsed power will be shown for economical generation of nanoparticles (NPs) through wire explosion process (WEP). Control of NPs size, phase and formation mechanism will be discussed through modelling studies and different material characterisation techniques. Application of WEP-synthesized semiconductor NPs will be discussed for wastewater treatment. (b) Then, we will go through the need of high voltage electric system in more electric aircraft (MEA) to reduce the carbon footprint. Different tools available to evaluate the arc faults and damage caused to the neighbouring systems will be detailed through mathematical and experimental tools. (c) Drive towards sustainable environment is leading to search of SF6 alternatives in power equipment, which are responsible for more than 80% of total SF6 emission. Research towards SF6 alternatives in gas insulated systems to reduce the global warming potential will be discussed in brief. Finally, the prospective of high voltage engineering and research in some other areas will be discussed.\n\nSpeaker Biodata : Prem Ranjan is working as a postdoc researcher at High Voltage Lab, The University of Manchester, UK, since Nov. 2019. He obtained the B. Tech. degree in Electrical and Electronics Engineering from NIT Calicut, India in 2015 and the integrated MS, PhD degrees in Electrical Engineering from IIT Madras, Chennai, India in 2019. He worked as an exchange researcher at Nagaoka University of Technology, Japan for 4 months during 2016 and 2017. His research interests are focused on sustainable applications of high voltage engineering including exploding wire, gas insulation (SF6 alternatives), arc-tracking in more electric aircraft and condition monitoring of power apparatus.\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Analysis and Enhancement of Stability of Power Systems with Utility-scale Photovoltaic Power Plants\n\nSpeaker : Indla Rajitha Sai Priyamvada\n\nDegree Registered : PhD\n\nAdvisor : Dr. Sarasij Das\n\nDate : 14/10/20221\n\nVenue : Online\n\nAbstract : Owing to the negative impact of carbon emissions on the environment, power systems are experiencing a paradigm shift in power generation. The fossil fuel-based generators that utilize synchronous machines are increasingly being replaced by the renewables such as Photovoltaic (PV) generators. Utility-scale PV power plants are coming up in the various parts of the world. Power electronic interface, control strategies and lack of inherent rotational element are the main factors that distinguish PV generation from Synchronous Generators (SGs). In addition, the time constants of the PV control loops and Phase Locked Loop (PLL) are of the same order unlike the SGs. The power electronic interface offers a better control over the electrical energy generated by the PV generators. However, the power electronic interface brings new challenges to power system stability. This research work focuses on addressing transient and small-signal stability issues of grid connected utility scale PV power plants.\n\nIn conventional power systems, swing equation of SGs and (extended) equal area criterion are used to assess the transient stability of power system. However, the same analysis techniques may not be applicable for PV generators. In this research work, transient stability assessment criteria are developed for grid connected PV generator with two different control strategies viz., Vdc-Q control and PQ control (with/without support functionalities). The proposed criteria are developed considering the outer and inner control loop, PLL and filter dynamics of PV generator. PSCAD simulations are carried out on a two-bus system and a modified IEEE-39 bus system to validate the proposed criterion. The stability criteria are found to effectively assess the stability of grid connected utility scale PV generators.\n\nThe power transfer capability of transmission network is limited by thermal limits, voltage limits and stability limits. Power transfer capability of transmission lines emanating from PV generators considering thermal and voltage limits is explored well in the literature. However, there is a lack of literature on stability constrained power transfer capability limit. In this research work, adaptive control-based tuning laws are proposed for grid connected PV generators to improve the stability constrained power transfer capability. The adaptive tuning laws are derived based on the Lyapunov energy function analysis. The Lyapunov functions are formulated using the summation of squares of the PI block errors and difference between the PI parameter values from their optimal values. Time domain simulations are carried out on a two-bus system and a modified IEEE-39 bus system to validate the proposed tuning laws. From time domain simulations, it is observed that the proposed tuning laws are found to effectively improve the stability limit on power transfer to the voltage limit.\n\nThe increased penetration of PV generations into power systems has also brought qualitative changes in small signal stability of power systems. Two new categories of oscillation modes are introduced into power systems which have participation from PV state variables. As the mode shape of the two new categories of oscillation modes is different from that of SG modes, the power system stabilizer design should be revisited. In this research work, control-based power system stabilizer is developed considering the controllability and observability of the new categories of oscillation modes. The effectiveness of the developed stabilizer in providing sufficient damping to the new categories of oscillation modes is validated through PSCAD simulations on a modified IEEE-39 bus system.\n\nAs power systems are large interconnected systems, the increased penetration of PV generation has resulted in notable interaction among PV generators and SGs. Investigation of the interaction among generators is important to understand the dynamic behaviour of overall power system when subjected to disturbances. This research work is carried out to understand the interaction among PV and SGs. The interaction is analysed through investigation of interaction among oscillation modes of PV generation and SG. A mathematical formulation to quantify the interaction among the oscillation modes of PV generations and SGs is proposed. A modified IEEE-39 bus system is considered to carry out the interaction study and validate the results obtained from mathematical formulations.\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Acoustic-Articulatory Mapping: Analysis and Improvements with Neural Network Learning Paradigms\n\nSpeaker : Aravind Illa\n\nDegree Registered :PhD\n\nAdvisor : Prof. Prasanta Kumar Ghosh\n\nDate : 29/09/2021\n\nVenue : Online\n\nAbstract : Human speech is one of many acoustic signals we perceive, which carries linguistic and paralinguistic (e.g: speaker identity, emotional state) information. Speech acoustics are produced as a result of different temporally overlapping gestures of speech articulators (such as lips, tongue tip, tongue body, tongue dorsum, velum, and larynx) each of which regulates constriction in different parts of the vocal tract. Estimating speech acoustic representations from articulatory movements is known as articulatory-to-acoustic forward (AAF) mapping i.e., articulatory speech synthesis. While estimating articulatory movements back from the speech acoustics is known as acoustic-to-articulatory inverse (AAI) mapping. These acoustic-articulatory mapping functions are known to be complex and nonlinear.\n\nComplexity of this mapping depends on a number of factors. These include the kind of representations used in the acoustic and articulatory spaces. Typically these representations capture both linguistic and paralinguistic aspects in speech. How each of these aspects contributes to the complexity of the mapping is unknown. These representations and, in turn, the acoustic-articulatory mapping are affected by the speaking rate as well. The nature and quality of the mapping varies across speakers. Thus, complexity of mapping also depends on the amount of the data from a speaker as well as number of speakers used in learning the mapping function. Further, how the language variations impact the mapping requires detailed investigation. This thesis analyzes few of such factors in detail and develops neural network based models to learn mapping functions robust to many of these factors.\n\nElectromagnetic articulography (EMA) sensor data has been used directly in the past as articulatory representations (ARs) for learning the acoustic-articulatory mapping function. In this thesis, we address the problem of optimal EMA sensor placement such that the air-tissue boundaries as seen in the mid-sagittal plane of the real-time magnetic resonance imaging (rtMRI) is reconstructed with minimum error. Following optimal sensor placement work, acoustic-articulatory data was collected using EMA from 41 subjects with speech stimuli in English and Indian native languages (Hindi, Kannada, Tamil and Telugu) which resulted in a total of ~23 hours of data, used in this thesis. Representations from raw waveform are also learnt for AAI task using convolutional and bidirectional long short term memory neural networks (CNN-BLSTM), where the learned filters of CNN are found to be similar to those used for computing Mel-frequency cepstral coefficients (MFCCs), typically used for AAI task. In order to examine the extent to which a representation having only the linguistic information can recover ARs, we replace MFCC vectors with one-hot encoded vectors representing phonemes, which were further modified to remove the time duration of each phoneme and keep only phoneme sequence. Experiments with phoneme sequence using attention network achieve an AAI performance that is identical to that using phoneme with timing information, while there is a drop in performance compared to that using MFCC.\n\nExperiments to examine variation in speaking rate reveal that, the errors in estimating the vertical motion of tongue articulators from acoustics with fast speaking rate, is significantly higher than those with slow speaking rate. In order to reduce the demand for data from a speaker, low resource AAI is proposed using a transfer learning approach. Further, we show that AAI can be modeled to learn acoustic-articulatory mappings of multiple speakers through a single AAI model rather than building separate speaker-specific models. This is achieved by conditioning an AAI model with speaker embeddings, which benefits AAI in seen and unseen speaker evaluations. Finally, we show the benefit of estimated ARs in voice conversion application. Experiments revealed that ARs estimated from speaker independent AAI preserves linguistic information and suppress speaker-dependent factors. These ARs (from unseen speaker and language) are used to drive target speaker specific AAF to synthesis speech, which preserves linguistic information and target speaker’s voice characteristics.\n\nGo to\n\nEvent : Thesis Colloquium\n\nTitle : Robust Nonconvex Penalties for Solving Sparse Linear Inverse Problems and Applications to Computational Imaging\n\nSpeaker : Praveen Kumar Pokala\n\nDegree Registered : PhD\n\nAdvisor : Prof. Chandra Sekhar Seelamantula\n\nDate : 06/08/2021\n\nVenue : Online\n\nAbstract : Sparse linear inverse problems require the solution to the l-0-regularized least-squares cost, which is not computationally tractable. Approximate and computationally tractable solutions are obtained by employing convex/nonconvex relaxations of the l-0-pseudonorm. One such approximation is obtained by considering the l-1-norm, which is a convex relaxation of the l-0-pseudonorm. However, l-1 regularization is known to result in biased estimates due to over-relaxation of the l-0-pseudonorm but it comes with the advantage of convexity of the regularized least-squares cost. Several nonconvex approximations of the l-0 pseudonorm have been proposed to overcome the bias introduced by the l-1-norm and to ensure better sparsity. However, certain aspects of nonconvex sparse regularization have not been explored. Some of these are as follows:\n\nNonconvex sparse priors have been explored in the synthesis-sparse framework, but not in the analysis-sparse framework due to the unavailability of proximal operators in closed-form in the analysis setting. Existing nonconvex approaches attach the same regularization weights across all the components of a sparse vector and treat them as fixed hyperparameters. Considering different weights for the entries and adapting them iteratively is likely to result in a superior performance.\n\nPrior learning networks based on deep-unfolded architectures for solving nonconvex penalties have not been explored. This thesis addresses the above aspects in three parts and considers applications to various computational imaging problems.\n\nPart-1: Nonconvex Analysis-sparse Recovery\n\nIn this part, we solve the analysis-sparse recovery problem based on three regularization approaches:\n\nConvexity-preserving nonconvex regularization: We propose the analysis variants of the generalized Moreau envelope and generalized minimax concave penalty (GMCP) over a complex domain. Since the cost is a real-valued function defined over a complex domain, it is nonholomorphic, i.e., it does not satisfy Cauchy-Riemann (CR) conditions. To circumvent this problem, we rely upon on Wirtinger calculus to derive the proximal operator for the analysis l-1 prior and develop an efficient optimization strategy employing projected proximal algorithms. The projection transform maps the analysis-sparse recovery problem into an equivalent constrained synthesis-sparse formulation.\n\nNonconvex sparse regularization: We consider the problem of nonconvex analysis sparse recovery in which the signal is assumed to be sparse in a redundant analysis operator. Standard nonconvex sparsity promoting priors do not have a proximal operator in closed-form under a redundant analysis operator and therefore, proximal approaches cannot be applied directly. This led us to develop two alternatives -- Moreau envelope regularization and projected transformation.\n\nGeneralized weighted l-1 regularization: We develop a generalized weighted l-1 regularization strategy, which allows for efficient weight-update strategies for iteratively reweighted l-1-minimization under tight frames. Further, we impose sufficient conditions on the weight function that leads to a reweighting strategy, which follows the interpretation originally given by Candès et al., but is more efficient than theirs. Since the objective function is nonholomorphic, we resort to Wirtinger calculus for deriving the update equations. We develop an algorithm called generalized iteratively reweighted soft-thresholding algorithm (GIRSTA) and its fast variant, namely, generalized fast iteratively reweighted soft-thresholding algorithm (GFIRSTA). We provide convergence guarantees for GIRSTA and empirical convergence results for GFIRSTA.\n\nWe demonstrate the efficacy of the proposed regularization strategies in comparison with the benchmark techniques considering compressive-sensing magnetic resonance image (CS-MRI) reconstruction under a redundant analysis operator, more specifically, shift-invariant discrete wavelet transform (SIDWT).\n\nPart-2: Weighted Minimax Concave p-pseudonorm Minimization\n\nIn this part, we develop techniques for accurate low-rank plus sparse matrix decomposition (LSD) and low-rank matrix recovery. We proposed weighted minimax-concave penalty (WMCP) as the nonconvex regularizer and show that it admits a certain equivalent representation that is more amenable to weight adaptation. Similarly, an equivalent representation to the weighted matrix gamma norm (WMGN) enables weight adaptation for the low-rank part. The optimization algorithms are based on the alternating direction method of multipliers. The optimization frameworks relying on the two penalties, WMCP and WMGN, coupled with a novel iterative weight-update strategy, result in accurate low-rank plus sparse matrix decomposition and low-rank matrix recovery techniques. Further, we derive an algorithm, namely, iteratively reweighted MGN (iReMaGaN) algorithm, which has a superior low-rank matrix recovery performance. The proposed algorithms are shown to satisfy descent properties and convergence guarantees. On the applications front, we consider the problems of foreground-background separation and image denoising. Simulations and validations on standard datasets show that the proposed techniques outperform the benchmark techniques. Next, we extended the idea to obtain a generalized l-p-penalty, namely, minimax concave p-pseudonorm (MCpN) based on a novel p-Huber function as the sparsity promoting function, and its weighted counterpart, weighted MCpN (WMCpN) as a regularizer for solving the sparse linear inverse problem. WMCpN is a generalization of which several penalties, namely, l-1-norm, minimax concave penalty (MCP), l-p penalty, weighted l-1-norm, and weighted l-p penalty become special cases. However, MCpN and WMCpN regularizers do not have closed-form proximal operators, which makes the optimization problem challenging. To overcome this hurdle, we develop an equivalent representation that is more amenable to optimization and allows for an analytical weight-update strategy. MCpN is a special case of WMCpN where all the weights are fixed and equal. The optimization algorithms are based on the alternating direction method of multipliers. Considering the application of interferometric phase estimation, we demonstrate that MCpN and WMCpN result in accurate interferometric phase estimation. Simulations and experimental validations on standard datasets show that the proposed techniques outperform the benchmark techniques.\n\nPart-3: Nonconvex Sparse Regularization and Deep-Unfolding\n\nIn the final part, we transition from fixed analytical priors to data-driven priors. To begin with, we develop a deep-unfolded architecture, namely, FirmNet, for sparse recovery. FirmNet has two parameters -- one that controls the noise variance, and the other that allows for explicit sparsity control. We show that FirmNet is better than Learned-ISTA (LISTA) by at least three-fold in terms of the probability of error in support (PES), and about 2 to 4 dB higher reconstruction SNR. Further, we solve the problem of reflectivity inversion, which deals with estimating the subsurface structure from seismic data through FirmNet. As an application, we consider the problem of seismic reflectivity inversion. We demonstrate the efficacy of FirmNet over the benchmark techniques for the reflectivity inversion problem by testing on synthetic 1-D seismic traces and 2-D wedge models. We also report validations on simulated 2-D Marmousi2 model and real data from the Penobscot 3D survey off the coast of Nova Scotia, Canada. Next, we propose convolutional FirmNet (ConFirmNet), which is an extension of the FirmNet approach to solve the problem of convolutional sparse coding. As an application, we build a ConFirmNet based sparse autoencoder (ConFirmNet-SAE) and demonstrate suitability for image denoising and inpainting. Further, we also show that training ConFirmNet-SAE with the Huber loss imparts robustness to outliers. ConFirmNet-SAE also proves to be robust to mismatch between training and test noise conditions than convolutional learned iterative soft-thresholding algorithm (CLISTA). Finally, we propose a sparse recovery formulation that employs a nonuniform, nonconvex synthesis sparse model comprising a combination of convex and nonconvex regularizers, which results in accurate approximations of the l-0 pseudo-norm. The resulting iterative optimization employs proximal averaging. When unfolded, the iterations give rise to a nonuniform sparse proximal average network (NuSPAN) that can be optimized in a data-driven fashion. We demonstrate the efficacy of NuSPAN also for solving the problem of seismic reflectivity inversion.\n\nSpeaker Biodata : Praveen Kumar Pokala received his B.Tech. degree in Electronics and Telecommunication Engineering from Jawaharlal Nehru Technological University, Hyderabad, India, in 2006 and M. Tech degree in Signal Processing from Indian Institute of Technology (IIT), Guwahati, India, in 2009. Subsequently, he worked as an Assistant Professor in LPU university, Jalandhar, India and GITAM university, Hyderabad, India. He is currently pursuing Ph.D. in the Department of Electrical Engineering, Indian Institute of Science, Bangalore. His current research interests are machine learning, deep learning, and nonconvex optimization algorithms, with applications to inverse problems in computational imaging.\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Robust learning under label noise with Neural networks\n\nSpeaker : Deep B Patel\n\nDegree Registered :M.Tech. (Research)\n\nAdvisor : Prof. P S Sastry\n\nDate : 23/07/2021\n\nVenue : Online\n\nAbstract : Label noise is inevitable when employing supervised learning based algorithms in practice. In many applications involving neural networks one needs a large training set and the process of obtaining such labelled data (e.g., crowd sourcing, employing automatic web searches etc.) often lead to training set labels being noisy. In the context of neural networks, it is demonstrated that standard algorithms (such as minimizing empirical risk with cross entropy loss function) are susceptible to overfitting in the presence of noise. This thesis explores the problem of robust learning under label noise. There are many approaches proposed for designing learning algorithms that are robust to label noise. We look at the sample reweighting methods where in one tries to assign weights to different examples so that examples with noisy labels are assigned small or zero weights. This can be viewed as a kind of curriculum learning where in the clean (easy) samples are to be given more weightage than the corrupted (hard) samples. Based on such heuristics, we propose a simple, adaptive curriculum based learning strategy called BAtch REweighting (BARE). The statistics of loss values of all samples in a mini-batch are used to decide which examples in each mini-batch would be allowed to update the weights. This yields an adaptive curriculum where the sample selection is naturally tied to current state of learning. Our algorithm does not need any clean validation data, needs no knowledge at all of the noise rates and also does not have any hyperparameters. We empirically demonstrate the effectiveness of our algorithm on benchmark data sets such as MNIST, CIFAR-10 and Clothing-1M, and show that it is much more efficient in terms of time and has as good or better robustness compared to other current algorithms based on sample reweighting. We next consider another aspect of the susceptibility of deep networks to label noise. It is shown recently that deep networks trained on data with random labels can memorize the data in the sense of being able to drive the training error to zero. This phenomena of memorization is confirmed by multiple studies and it is seen that none of the standard regularization techniques can mitigate it. This depends on the kind of local minima that SGD can take the network to. Hence it could depend on the topography of the empirical risk that is minimized. Thus, the choice of loss function can be critical in determining this. However, none of the studies on memorization investigate the role of loss function. We present extensive empirical results to show that while standard loss functions like CCE and MSE result in memorization, symmetric loss functions such as RLL can resist such memorization to a good degree. We formally define what resisting memorization means and then provide some theoretical justification for the empirical results.\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Developmental Studies of a Solid-State Pulsed Power System for Liquid Food Sterilisation\n\nSpeaker : Tanmaya Pradhan\n\nDegree Registered :M.Tech. (Research)\n\nAdvisor : Dr. Joy Thomas\n\nDate : 22/07/2021\n\nVenue : Online\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Speaker verification using whispered speech\n\nSpeaker : Abinay Reddy Naini\n\nDegree Registered :MTech (Research\n\nAdvisor : Prof. Prasanta Kumar Ghosh\n\nDate : 13/07/2021\n\nVenue : Online\n\nAbstract : Like neutral speech, whispered speech is one of the natural modes of speech production, and it is often used by speakers in their day-to-day life. For some people, such as laryngectomees, whispered speech is the only mode of communication. Despite the absence of voicing in whispered speech and difference in characteristics compared to the neutral speech, previous works in the literature demonstrated that whispered speech contains adequate information about the content and the speaker.\n\nIn recent times, virtual assistants have become more natural and widespread. This led to an increase in the scenarios, where the device has to detect the speech and verify the speaker even if the speaker whispers. Due to the noise-like characteristics, detecting whispered speech is a challenge. On the other hand, a typical speaker verification system, where neutral speech is used for enrolling the speakers but whispered speech for testing, often performs poorly due to the difference in acoustic characteristics between the whispered and the neutral speech. Hence, the aim of this thesis is two-fold: 1) develop a robust whisper activity detector specifically for speaker verification task, 2) improve whispered speech based speaker verification performance.\n\nThe contributions in this thesis lie in whisper activity detection as well as whispered speech based speaker verification. It is shown how an Attention-based average pooling in a speaker verification model can be used to detect the whispered speech regions in noisy audio more accurately than the best of the baseline schemes available. For improving speaker verification using whispered speech, we proposed features based on formant gaps, and we showed that these features are more invariant to the modes of the speech compared to the best of the existing features. We also proposed two feature mapping methods to convert the whispered features to neutral features for speaker verification. In the first method, we introduced a novel objective function, based on cosine similarity, for training a DNN, used for feature mapping. In the second method, we iteratively optimized the feature mapping model using cosine similarity based objective function and the total variability space likelihood in the i-vector based background model. The proposed optimization provided a more reliable mapping from whispered features to neutral features resulting in an improvement of speaker verification equal error rate by 44.8% (relative) over an existing DNN based feature mapping scheme.\n\nGo to\n\nEvent : Thesis Colloquium\n\nTitle : Spectrotemporal Processing of Speech Signals Using the Riesz Transform\n\nSpeaker : Jitendra Kumar Dhiman\n\nDegree Registered :Ph.D.\n\nAdvisor : Prof. Chandra Sekhar Seelamantula\n\nDate : 12/07/2021\n\nVenue : Online\n\nAbstract : Speech signals have time-varying spectra. Spectrograms have served as a useful tool for the visualization and analysis of speech signals in the joint time-frequency plane. In this thesis, we consider 2-D analysis of speech spectrograms. We consider a spectrotemporal patch and model it as a 2-D amplitude-modulated and frequency-modulated (AM-FM) sinusoid. Demodulation of the spectrogram yields the 2-D AM and FM components, which correspond to the slowly varying vocal-tract envelope and the excitation, respectively. For solving the demodulation problem, we rely on the complex Riesz transform, which is a 2-D extension of the 1-D Hilbert transform. The demodulation viewpoint brings forth many interesting properties of the speech signal. The spectrotemporal carrier helps us identify the regions that are coherent and those that are not. Based on this idea, we introduce the coherencegram corresponding to a given spectrogram. The temporal evolution of the pitch harmonics can also be characterized by the orientation at each time-frequency coordinate, resulting in the orientationgram. We show that these features collectively enable solutions for the important problems of voiced/unvoiced segmentation, aperiodicity estimation, periodic/aperiodic signal separation, and pitch tracking. We compare the performance of the proposed methods with benchmark methods. The spectrotemporal amplitude characterizes the time-varying magnitude response of the vocal-tract filter. We show how the formants and their bandwidths manifest in the spectrotemporal amplitude. It turns out that the formant bandwidths are mildly overestimated, which are perceptible when one performs speech synthesis using the estimated parameters. We propose a method for correcting the formant bandwidths, which also restores the speech quality. Finally, we use the curated spectrotemporal amplitude, pitch, aperiodicity, and voiced/unvoiced decisions for the task of speech reconstruction in a spectral synthesis model and a neural vocoder, namely, WaveNet. We show that conditioning WaveNet on the spectrotemporal features results in high-quality speech synthesis. The quality of the synthesized speech is assessed using both objective and subjective measures.\n\nWe rely on the Perceptual Evaluation of Speech Quality (PESQ) measure and standard Mean Opinion Score (MOS) test for objective and subjective evaluation, respectively. The performance of the proposed parameters is evaluated in a vocoder framework that uses the spectral synthesis model for speech reconstruction. The objective evaluation shows that the performance of the Riesz transform-based speech parameters is on par with the baseline systems. Using the spectral synthesis model, we report an average PESQ score in the range from 2.30 to 3.45 over a total of 200 speech waveforms taken from the CMU-ARCTIC database comprising both male and female speakers. In comparison, WaveNet-based speech reconstruction gave an average PESQ score of 3.65.\n\nSubjective evaluation was carried out through listening tests conducted in an acoustic test chamber on volunteers in the age group of 21 to 30. The average MOS score was 4.30 when the Riesz transform-based features were used in WaveNet for speech reconstruction, which was also comparable with the baseline systems: STRAIGHT and WORLD. Both objective and subjective evaluations also showed that the quality of reconstructed speech waveforms was superior with the proposed features in a WaveNet vocoder than in the spectral synthesis model.\n\nAn audio demonstration is available at the GitHub link: http://jitendradhiman.github.io/Demo\n\nSpeaker Biodata : Jitendra Kumar Dhiman received his B.Tech. degree in Electronics and Telecommunication Engineering from the Institution of Electronics and Telecommunication Engineering, Delhi, India, in 2010, and M.Tech. degree in Signal Processing from Indian Institute of Technology Hyderabad in 2013. Subsequently, he joined as a project assistant in Spectrum Lab (EE Department, IISc) and worked on prosody modification of speech signals, and then as a PhD student working on spectrotemporal models for speech processing. His research interests include speech and audio signal processing and machine learning.\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Dynamics of a Stratified Population of Optimum Seeking Agents on a Network\n\nSpeaker : Nirabhra Mandal\n\nDegree Registered :M. Tech (Research)\n\nAdvisor : Dr. Pavankumar Tallapragada\n\nDate : 06/07/2021\n\nVenue : Online\n\nAbstract : Very large scale multi-agent systems occur both naturally and in engineering applications. In many of these systems, the agents are either selfish or act with varying levels of coordination. Understanding the evolution of large populations of such agents has been of interest in diverse domains such as biology, ecology, sociology, economics, transportation engineering, robotics and control engineering. One specific area that has not been studied enough is that of evolution of large populations on networks of choices. This specific setting has potential applications in the contexts of fleet redistribution of ride sharing services, evolution of transportation mode choices of a population, opinion dynamics, human and insect swarm migrations and robotics swarms.\n\nIn this thesis, we consider a population composed of a continuum of agents that seek to maximize a payoff function by moving on a network. The nodes in the network may represent physical locations or abstract choices. The population is stratified and hence agents opting for the same choice may not get the same payoff. In particular, we assume payoff functions that model diminishing returns, that is, agents in ``newer'' strata of a node receive a smaller payoff compared to ``older'' strata. Moreover, at each time instant, the network imposes constraints on the set of choices that an agent can revise to.\n\nWe first model the population dynamics under three choice revision policies, each having varying levels of coordination - (i). no coordination and the agents are selfish, (ii). coordination among agents in each node and (iii). coordination across the entire population. To model the case with selfish agents, we generalize the Smith dynamics to our setting, where we have a stratified population and network constraints. We refer to this dynamics as stratified Smith dynamics or SSD. To model nodal coordination, we allow the fraction of population in a node, as a whole, to take the `best response' to the state of the population in the node's neighborhood. We call this as nodal best response dynamics or NBRD. For the case of population-wide coordination, we explore a dynamics where the population evolves according to centralized gradient ascent of the social utility, though constrained by the network. We call this dynamics as network restricted payoff maximization or NRPM. In each case, we show that the dynamics has existence and uniqueness of solutions. We also show that the solutions from any initial condition asymptotically converge to the set of Nash equilibria and the social utility converges to a constant.\n\nWe then study the steady state of the population and the steady state social utility for the three dynamics SSD, NBRD and NRPM. We provide sufficient conditions on the network parameters under which there exists a unique Nash equilibrium. We then utilize positive correlation properties of the dynamics to in order to provide an upper bound on the steady state social utility as a function of the initial population configuration. Finally, we extend the idea behind the sufficient condition for the existence of a unique Nash equilibrium to partition the graph appropriately in order to provide a lower bound on the steady state social utility. We then illustrate interesting cases as well as our results using simulations.\n\nLastly, we discuss some preliminary ideas to utilize this framework to control the population to a desired configuration. We try to achieve this by changing the payoff functions at a much slower rate than the rate at which the population converges. We also look at ways to compute an optimal control action that achieves this.\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Probabilistic source-filter model of speech\n\nSpeaker : Achuth Rao M V\n\nDegree Registered :PhD\n\nAdvisor : Prof. Prasanta Kumar Ghosh\n\nDate : 28/06/2021\n\nVenue : Online\n\nAbstract : The human respiratory system plays a crucial role in breathing and swallowing. However, it also plays an essential role in speech production, which is unique to humans. Speech production involves expelling air from the lungs. As the air flows from the lungs to the lips, some kinetic energy gets converted to sound. Different structures modulate the generated sound, which is finally radiated out of the lips. The speech consists of various information such as linguistic content, speaker identity, emotional state, accent, etc. Apart from speech, there are various scenarios where the sound is generated in the human respiratory system. These could be due to abnormalities in the muscles, motor control unit, or the lungs, which can directly affect generated speech as well. A variety of sounds are also generated by these structures while breathing including snoring, Stridor, Dysphagia, and Cough.\n\nThe source filter (SF) model of speech is one of the earlier models of speech production. It assumes that speech is a result of filtering an excitation or source signal by a linear filter. The source and filter are assumed to be independent. Even though the SF model represents the speech production mechanism, there needs to be a tractable way of estimating the excitation and the filter. The estimation of both of them given speech falls under the general category of signal deconvolution problem, and, hence, there is no unique solution. There are several variations of the source-filter model in the literature by assuming different structures on the source/filter. There are various ways to estimate the parameters of the source and the filter. The estimated parameters are used in various speech applications such as automatic speech recognition, text to speech, speech enhancement etc. Even though the SF model is a model of speech production, it is used in applications including Parkinson's Disease classification, asthma classification.\n\nThe existing source filter models show much success in various applications, however, we believe that the models mainly lack two respects. The first limitation is that these models lack the connection to the physics of sound generation or propagation. The second limitation of the current models is that they are not fully probabilistic. The inherent nature of the airflow is stochastic because of the presence of turbulence. Hence, probabilistic modeling is necessary to model the stochastic process. The probabilistic models come with several other advantages: 1) systematically inducing the prior knowledge into the models through probabilistic priors, 2) the estimation of the uncertainty of the model parameters, 3) allows sampling of new data points 4) evaluation of the likelihood of the observed speech.\n\nWe start with the governing equation of sound generation and use a simplified geometry of the vocal folds. We show that the sound generated by the vocal folds consists of two parts. The first part is because of the difference between the subglottal and supra glottal pressure difference. The second part is because of the sound generated by turbulence. The first kind is dominant in the voiced sounds, and the second part is dominant in the unvoiced sounds. We further assume the plane wave propagation in the vocal tract, and there is no feedback from the vocal tract on the vocal folds. The resulting model is the excitation passing through an all-pole filter, and the excitation is the sum of two signals. The first signal is quasi-periodic, and the shape of each cycle depends on the time-varying area of the glottis. The second part is stochastic because the turbulence is modeled as a white noise passed through a filter. We further convert the model into a probabilistic one by assuming the following distribution on the excitations and filters. We model the excitation using a Bernoulli Gaussian distribution. Filter coefficients are modeled using the Gaussian distribution. The noise distribution is also Gaussian. Given these distributions, the likelihood of the speech can be derived as a closed-form expression. Similarly, we impose an appropriate prior to the model’s parameters and make a maximum a posteriori estimation of the parameters. But the model assumption can be changed/approximated with respect to the application and resulting in different estimation procedures. To validate the model, we apply this model to seven applications as follows:\n\n1. Analysis and Synthesis: This application is to understand the representation power of the model.\n\n2. Robust GCI detection: This shows the usefulness of estimated excitation, and the probabilistic modeling helps to incorporate the second-order statistics for robust the excitation estimation.\n\n3. Probabilistic glottal inverse filtering: This application shows the usefulness of the prior distribution on filters.\n\n4. Neural speech synthesis: We show that the model’s reformulation with the neural network results in a computationally efficient neural speech synthesis.\n\n5. Prosthetic esophageal (PE) to normal speech conversion: We use the probabilistic model for detecting the impulses in the noisy signal to convert the PE speech to normal speech.\n\n6. Robust essential vocal tremor classification: The usefulness of robust excitation estimation in pathological speech such as essential vocal tremor.\n\n7. Snorer group classification: Based on the analogy between voiced speech production and snore production, the derived model is applicable for snore signals. We also use the parameter of the model to classify the snorer groups.\n\nGo to\n\nEvent : Thesis Colloquium\n\nTitle : Spacially Adaptive Regularization for Image Restoration\n\nSpeaker : Sanjay Viswanath\n\nDegree Registered : PhD\n\nAdvisor : Dr. Muthuvel Arigovindan\n\nDate : 07/06/2021\n\nVenue : Online\n\nAbstract : Image restoration/reconstruction refers to the estimation of the underlying image from measurements generated by imaging devices. This problem is generally ill-posed due to the fact that measurements are corrupted because of the physical limitations of the imaging device, and the inherent noise involved in the measurement process. There are three main classes of methods in the current literature. The first class of methods is based on the regularization framework that enforces an ad-hoc prior on the restored image. The second class of methods uses regression-based learning paradigms, where a training set of clean images and the corresponding distorted measurements are used to generate a trained prior. The third class of methods adopts trained priors similar to the ones utilized in the second class of methods but within the regularization framework. This third class of methods, the trained regularization methods, are getting increasing attention because of their versatility as the regularization methods, while also encompassing natural priors obtained from training. However, the need for training data can limit their applicability. In this thesis, we propose spatially adaptive regularization methods where the adaptation information is retrieved from the measured data that undergoes reconstruction. Due to the adaption, the enforced prior is more natural than the existing regularization methods. At the same time, our methods do not require training data.\n\nSummary of Contributions:\n\nIn the first part, we propose a novel regularization method that adaptively combines the well-known second-order regularization, called Hessian-Schatten (HSN) norm regularization, and first-order TV (TV-1) functionals with spatially varying weights. The relative weight involved in combining the first- and second-order terms becomes an image and this weight is determined through the minimization of a composite cost function, without user intervention. Our contributions in this part can be summarized as follows:\n\n• We construct a composite regularization functional containing two parts: (i) the first part is constructed as the sum of TV-1 and HSN with spatially varying relative weights; (ii) the second part is an additional regularization term for preventing rapid spurious variations in the relative weights. The total composite cost functional is convex with respect to either the required image or the relative weight, but it is non-convex jointly.\n\n• We construct a block coordinate descent method involving minimizations w.r.t. the required image and the relative weight alternatively with the following structure: the minimization w.r.t. the required image is carried out using the Alternating Direction Method of Multipliers (ADMM), and the minimization w.r.t. the relative weight is carried out as a single-step exact minimization using a formula that we derive.\n\n• Since the total cost is non-convex, the reconstruction results are highly dependent on the initialization for block-coordinate descent method. We handle this problem using a multi-resolution approach, where a series of coarse-to-fine reconstructions are performed by minimization of cost functionals defined through upsampling operators. Here, minimization w.r.t. the relative weight and the required image is carried out alternatively, as we progress from coarse to final resolution levels. At the final resolution level, the above-mentioned block coordinate descent method is applied.\n\n• The sub-problem of minimization w.r.t. to the required image involves spatially varying relative weights. Further, this sub-minimization problem in the above-mentioned multi-resolution loop involves upsampling operators. Hence, the original ADMM method proposed by Papafitsoros et al. turns out to be unsuitable. We propose an improved variable splitting method and computational formulas to handle this issue.\n\n• We prove that the overall block coordinate descent method converges to a local minimum of the total cost function using Zangwill’s convergence theorem.\n\nWe name our method Combined Order Regularization with Optimal Spatial Adaptation (COROSA). We provide restoration examples involving deconvolution of TIRF images and reconstruction of Magnetic Resonance Imaging (MRI) images from under-sampled Fourier data. We demonstrate that COROSA outperforms existing regularization methods and selected deep learning methods.\n\nIn the second part, we make COROSA more adaptive by replacing the HSN with a spatially varying weighted combination of Eigenvalues of the Hessian. This means that the resulting regularization will be in the form of a spatially varying weighted sum of three terms involve the gradient and two Eigenvalues of Hessian. This allows the function to restore fine image structures through directional weighting, in terms of the local Eigenvalues. We again adopt a BCD scheme that alternates between the spatially varying weight estimation and image computation, as done in the first part. However, both steps are more complex with the new form. The first task of weight estimation is more complex as it involves three terms. The second task of image computation is more complex because there is no known proximal operator for regularization involving unequally weighted Hessian Eigenvalues. We solve the first problem by constructing a novel iterative method, and the second problem by deriving a novel proximal formula. Here too, we adopt a multi-resolution approach to initialize the BCD method. We call our method the Hessian Combined Order Regularization with Optimal Spatial Adaptation (H-COROSA). We experimentally compare H-COROSA with well-known regularization methods and selected learning-based methods for MRI reconstruction from under-sampled Fourier data.\n\nCompressive Sensing based methods have shown the advantage of l0 based sparsity enforcing functionals in restoration. For practical applications, lp, 0 < p ≤1 functionals have been found to perform better than l1 functionals. In the last part, we propose an lp-based generalization of the previous COROSA and H-COROSA formulations. We replace the corresponding l1 based functionals with lp norm enforced on the combined multi-order functionals. Additionally for H-COROSA, we also consider two forms of penalty for the spatial weights. We construct an iteration scheme that is a merging of the majorization-minimization method for lp norm and BCD method used in the first two parts of the thesis. Again, we use a similar multi-resolution method for initialization. We demonstrate the advantage of using lp norm using MRI reconstruction examples involving severe undersampling in the Fourier domain.\n\nGo to\n\nEvent :\n\nTitle :\n\nSpeaker :\n\nDegree Registered :\n\nAdvisor :\n\nDate :\n\nVenue :\n\nAbstract :\n\nSpeaker Biodata :\n\nGo to\n\nEvent : Thesis Colloquium\n\nTitle : Novel Regularized Image Reconstruction Methods for Sparse Photoacoustic Tomography\n\nSpeaker : Rejesh N A\n\nDegree Registered : PhD\n\nAdvisor : Dr. Muthuval Arigovindan\n\nDate : 13/05/2021\n\nVenue : Online\n\nAbstract : Among all tissue imaging modalities, photoacoustic tomography (PAT), has been getting increasing attention in the recent past due to the fact that it has high contrast, high penetrability, and has the capability of retrieving high resolution. By using the combination of optical absorption and acoustic wave propagation, PAT has been able to image tissues at relatively large depths with high resolution compared to purely optical modalities. Upon shining with a laser pulse, the substance under investigation absorbs optical energy and undergoes thermoelastic expansion; as a result, the spatial distribution of the concentration of the substance gets translated into the distribution of pressure-rise. This initial pressure rise travels outwards as ultrasound waves which are collected by ultrasound transducers placed at the boundary. From the ultrasound signal measured by the transducers as a function of time, a PAT reconstruction method recovers an estimate of the initial pressure-rise by solving the associated inverse problem. The inverse problem is however challenging. It is challenging because the image has to be recovered for the entire cross-sectional plane, whereas the samples of the acoustics pressure are available only from the points lying in the periphery of the imaging specimen where the transducers are located. In this thesis, we make contributions in two widely used types of reconstructions methods known as the time-reversal method, and the model-based method.\n\nSummary of Contributions:\n\nIn the first part, we develop an improved model-based method. Model-based reconstruction methods in PAT express the measured pressure samples as a linear transformation on the initial pressure-rise and perform a regularized reconstruction. Model-based methods yield superior image quality even in the situation where measured data size is small. We propose a model-based image reconstruction method for PAT involving a novel form of regularization and demonstrate its ability to recover good quality images from datasets of significantly reduced size. The regularization is constructed to suit the physical structure of typical PAT images. We construct it by combining second-order derivatives and intensity into a non-convex form to exploit a structural property of PAT images that we observe: in PAT images, high intensities and high second-order derivatives are jointly sparse. This regularization is combined with a data fidelity cost, and the required image is obtained as the minimizer of this cost. As this regularization is non-convex, the efficiency of the minimization method is crucial in obtaining artefact-free reconstructions. We develop a custom minimization method for efficiently handling this non-convex minimization problem. Further, as non-convex minimization requires a large number of iterations and the PAT forward model in the data-fidelity term has to be applied in the iterations, we propose a computational structure for efficient implementation of the forward model with reduced memory requirements. We evaluate the proposed method on both simulated and real measured data sets and compare them with a recent reconstruction method that is based on well-known total variation regularization.\n\nAppropriate tuning of the regularization weight, λ, plays a crucial role in determining the quality of reconstructed images in PAT. To make any regularization method practicable, we need to have a way to determine the λ from the measured data. Unfortunately, an appropriately tuned value of the regularization weight varies significantly with the variation in the noise level, as well as, with the variation in the high-resolution contents of the image, in a way that has not been well understood. In the part of the work described above, we did not address this problem as the focus has been to demonstrate the suitability of the intensity-augmented regularization for PAT image recovery; in the experimental demonstration, we determined the required regularization weight by using the models that generated data. In the second part of the thesis, we develop a semi-automatic method for determining the regularization weight from measured data. As a first step, we introduce a relative smoothness constraint with a parameter; this parameter computationally maps into the actual regularization parameter, but its tuning does not vary significantly with variation in the noise level, as well as with the variation in the high-resolution contents of the image. Next, we construct an algorithm that integrates the task of determining this mapping along with obtaining the reconstruction. Finally, we demonstrate experimentally that we can run this algorithm with a nominal value of the relative smoothness parameter---a value independent of the noise level and the structure of the underlying image---to obtain good quality reconstructions. We compare the structural similarity (SSIM) scores of reconstructions obtained this way to that of reconstructions in which the regularization weight was determined using the models themselves; we show that the SSIM scores are comparable. This means that, from a practical point of view, our work solves the problem of determining the required regularization weight from measured images.\n\nIn the first two parts, we assumed that the forward model that measures the signal from the target object be ideal. In particular, we assumed that the excitation pulse and transducers' impulse response are Dirac deltas. We focused only on the non-ideality of the transducer configuration, i.e., we handled the case where the transducer locations do not densely sample the detection surface as required by the well-known back-projection method to work. Both excitation pulse and transducer impulse response have a finite width, and this leads to some distortions in the reconstructed image. In the last part of the thesis, we propose a pre-processing method for correcting the distortions in the context of using time-reversal methods which are similar to the back-projection method. To this end, we formulate the broadening of the PA signals as a convolution between the impulse response of the system and the input excitation pulse. A deconvolution method using Tikhonov regularization is proposed to correct the PA signals before applying the time-reversal method. This resulted in improved resolution in the reconstructed images. A two-level deconvolution with the Tikhonov regularization method is also proposed to remove the blurring caused by the finite bandwidth of transducers and by the broad excitation pulses. We evaluate the usefulness of our method using numerical simulations and demonstrate that the reconstructed images from the deconvolved PA signals remain unaffected by changes in pulse widths or pulse shapes, as well as by the limited bandwidth of the ultrasound detectors.\n\nGo to\n\nEvent : Thesis Colloqium\n\nTitle : Techniques for estimating the direction of pointing gestures using depth images in the presence of orientation and distance variations from the depth sensor\n\nSpeaker : Shome Subhra Das\n\nDegree Registered :PhD\n\nAdvisor : --\n\nDate : 26/04/2021\n\nVenue : Online\n\nAbstract : Currently the interaction with computers, robots, drones, and virtual reality interfaces is through the use of mouse, touch-pad, joystick, virtual reality wand, drone controller etc. These devices have one or more of the following limitations: being cumbersome, non-immersive, immobile, and having a steep learning curve. The target of this work is to explore ways to replace existing pointing devices with pointing gesture-based interfaces.\n\nThis thesis addresses two problems, namely estimating the direction being indicated by a pointing gesture (PDE) and detection of pointing gestures. The proposed techniques use a single depth sensor and use only the hand region. To our knowledge, this is the maiden attempt at creating a depth and orientation tolerant, accurate method for estimating the pointing direction using only depth images. The proposed methods achieve accuracies comparable to or better than those of existing methods while avoiding their limitations.\n\nSignificant contributions of the thesis:\n\n(i) Proposing a real-time technique for estimating the pointing direction using a nine-axis inertial motion unit (IMU) and an RGB-D sensor. It is the first method to compute the pointing direction (PD) by finding the axis vector of the index finger. It is also the first method to fuse information from the IMU and depth sensor to obtain the PD. Further, this is the first method to obtain the accurate ground-truth pointing direction of index finger-based pointing gestures.\n\n(ii) Creation of a large (100k+ samples) data-set with accurate ground truth for PDE from depth images. Each sample consists of the segmented depth image of a hand, the fingertip location (2D + 3D), the pointing vector (as a unit vector and in terms of the yaw and pitch values), and the mean depth of the hand. This is the first public data-set for depth image-based PDE that has accurate ground truth and a large number of samples.\n\n(iii) Proposing a new 3D convolutional neural network-based method to estimate pointing direction. This is the first deep learning-based method for PDE that uses only the depth images for PDE, without the use of RGB data. It is tolerant to variation in orientation and depth of the hand with respect to the camera and is suitable for real-time applications.\n\n(iv) Proposing another technique for estimating the pointing direction using global registration of the test data point cloud with a pointing hand model captured using Kinect fusion based method. It is tolerant to the variation in the orientation and depth of the hand w.r.t. the RGB-D sensor. It does not have the limitation of the previously proposed methods since it does not require the attachment of any device such as IMU nor does it require any data-set for training. It achieves less net angular error than most techniques in the literature using only the hand region.\n\n(v) Creation of a large data-set of positive and negative samples for detection of pointing gestures from depth images of the hand region. A technique is also proposed using deep learning to distinguish pointing gestures from other hand gestures. This achieves higher accuracy than the only other technique in the literature by Cordo et al. for all the depths of the hand covering the entire range of the depth sensor.\n\nGo to\n\nEvent : Thesis Colloquium\n\nTitle : Study of Robust Learning under Label Noise with Neural Networks\n\nSpeaker : Deep Patel\n\nDegree Registered :MTech (Research)\n\nAdvisor : Prof. P S Sastry\n\nDate : 23/04/2021\n\nVenue : Online\n\nAbstract : Label noise is inevitable when employing supervised learning based algorithms in practice. In many applications involving neural networks one needs a large training set and the process of obtaining such labelled data (e.g., crowd sourcing, employing automatic web searches etc.) often lead to training set labels being noisy. In the context of neural networks, it is demonstrated that standard algorithms (such as minimizing empirical risk with cross entropy loss function) are susceptible to overfitting in the presence of noise. This thesis explores the problem of robust learning under label noise. There are many approaches proposed for designing learning algorithms that are robust to label noise. We look at the sample reweighting methods where in one tries to assign weights to different examples so that examples with noisy labels are assigned small or zero weights. This can be viewed as a kind of curriculum learning where in the clean (easy) samples are to be given more weightage than the corrupted (hard) samples. Based on such heuristics, we propose a simple, adaptive curriculum based learning strategy called BAtch REweighting (BARE). The statistics of loss values of all samples in a mini-batch are used to decide which examples in each mini-batch would be allowed to update the weights. This yields an adaptive curriculum where the sample selection is naturally tied to current state of learning. Our algorithm does not need any clean validation data, needs no knowledge at all of the noise rates and also does not have any hyperparameters. We empirically demonstrate the effectiveness of our algorithm on benchmark data sets such as MNIST, CIFAR-10 and Clothing-1M, and show that it is much more efficient in terms of time and has as good or better robustness compared to other current algorithms based on sample reweighting. We next consider another aspect of the susceptibility of deep networks to label noise. It is shown recently that deep networks trained on data with random labels can memorize the data in the sense of being able to drive the training error to zero. This phenomena of memorization is confirmed by multiple studies and it is seen that none of the standard regularization techniques can mitigate it. This depends on the kind of local minima that SGD can take the network to. Hence it could depend on the topography of the empirical risk that is minimized. Thus, the choice of loss function can be critical in determining this. However, none of the studies on memorization investigate the role of loss function. We present extensive empirical results to show that while standard loss functions like CCE and MSE result in memorization, symmetric loss functions such as RLL can resist such memorization to a good degree. We formally define what resisting memorization means and then provide some theoretical justification for the empirical results.\n\nGo to\n\nEvent : Thesis Colloquium\n\nTitle : Lipschitz Regularization of Convolutional Neural Networks\n\nSpeaker : Anirudh Singh\n\nDegree Registered :MTech (Res)\n\nAdvisor : Prof. Kunal Narayan Chaudhury\n\nDate : 16/04/2021\n\nVenue : Online\n\nAbstract : We consider the problem of estimating the Lipschitz constant of (the end-to-end mapping in) convolutional neural networks (CNNs) and regulating it during the training process. This has applications ranging from stable training of generative models and robustness to adversarial attacks to stability analysis of CNN-based closed-loop systems and the derivation of generalization bounds.\n\nThe challenge in this regard is that computing the exact Lipschitz constant of even simple neural networks is known to be NP-hard. In practice, the product of the largest singular values of the convolutional layers is used to bound the Lipschitz constant. However, even computing the singular values for a single convolutional layer is computationally prohibitive; moreover, this has to be done for each layer in every backpropagation pass. Methods not using an explicit SVD still rely on the power method, which requires inner iterations within the already iterative training procedure. In this context, our contributions are the following:\n\n(i) We propose a simple bound for the singular value of a convolutional layer, which can be computed efficiently using FFTs and does away with the need for SVD or power iterations.\n\n(ii) We study the effect of Lipschitz regularization on constrained convolutional architectures which reveals the role played by overparameterization.\n\nWe test the performance of Lipschitz regularization using the proposed bound on the CIFAR-10 image classification dataset. Though our bound is loose, quite remarkably, we can improve the generalization accuracy by more than 2% without practically introducing any computational overhead. In comparison to algorithms that use the exact singular values, we perform marginally better in terms of accuracy while taking significantly less time to complete the training. In addition, we study convolutional architectures with significantly fewer trainable parameters than regular convolutions. This study reveals that CNNs may be able to model certain distributions using multiple parameterizations, and it is this redundancy in parameterization that allows Lipschitz regularization to be successful.\n\nGo to\n\nEvent : Thesis Collowquium\n\nTitle : Deep Learning Methods for Audio EEG Analysis\n\nSpeaker : Jaswanth Reddy Katthi\n\nDegree Registered :MTech (Research)\n\nAdvisor : Dr. Sriram Ganapathy\n\nDate : 15/04/2021, 11.00am\n\nVenue : Online\n\nAbstract : The perception of speech and audio is one of the defining features of humans. Much of the brain's underlying processes as we listen to acoustic signals are unknown, and significant research efforts are needed to unravel them. The non-invasive recordings capturing the brain activations like electroencephalogram (EEG) and magnetoencephalogram (MEG) are commonly deployed to capture the brain responses to auditory stimuli. But these non-invasive techniques capture artifacts and signals not related to the stimuli, which distort the stimulus-response analysis. The effect of the artifacts becomes more evident for naturalistic stimuli. To reduce the inter-subject redundancies and amplify the components related to the stimuli, the EEG responses from multiple subjects listening to a common naturalistic stimulus need to be normalized. The currently used normalization and pre-processing methods are the canonical correlation analysis (CCA) models and the temporal response function based forward/backward models. However, these methods assume a simplistic linear relationship between the audio features and the EEG responses and therefore, may not alleviate the recording artifacts and interfering signals in EEG. This talk proposes novel methods using machine learning advances to improve the audio-EEG analysis.\n\nWe propose a deep learning framework for audio-EEG analysis in intra-subject and inter-subject settings. The deep learning based intra-subject analysis methods are trained with a Pearson correlation-based cost function between the stimuli and EEG responses. This model allows the transformation of the audio and EEG features that are maximally correlated. The correlation-based cost function can be optimized with the learnable parameters of the model trained using standard gradient descent-based methods. This model is referred to as the deep CCA (DCCA) model. Several experiments are performed on the EEG data recorded when the subjects are listening to naturalistic speech and music stimuli. We show that the deep methods obtain better representations than the linear methods and results in statistically significant improvements in correlation values.\n\nFurther, we propose a neural network model with shared encoders that align the EEG responses from multiple subjects listening to the same audio stimuli. This inter-subject model boosts the signals common across the subjects and suppresses the subject-specific artifacts. The impact of improving stimulus-response correlations are highlighted based on multi-subject EEG data from speech and music tasks. This model is referred to as the deep multi-way canonical correlation analysis (DMCCA). The combination of inter-subject analysis using DMCCA and intra-subject analysis using DCCA is shown to provide the best stimulus-response in audio-EEG experiments.\n\nThe talk will conclude with a discussion on future challenges in audio-EEG analysis. We will highlight how much of the audio signal can be recovered purely from the non-invasive EEG recordings with modern machine learning methods.\n\nSpeaker Biodata : Jaswanth Reddy Katthi is a third year M. Tech (Research) student in EE department under the program System Science and Signal Processing. He is a part of LEAP lab, and pursuing his research under the guidance of Dr. Sriram Ganapathy. He did his bachelors from Jawaharlal Nehru Technological University, Anantapur in Electronics and Communication Engineering, during 2013-2017. His research interests involve machine learning, speech processing and cognitive neuroscience. He is an IEEE student member. He is from Kurnool, Andhra Pradesh.\n\nGo to\n\nEvent : Seminar\n\nTitle : Novel condition monitoring and diagnostic techniques for insulating materials\n\nSpeaker : Ashiwn Desai\n\nDate : 11/03/2021\n\nVenue : Online\n\nAbstract : With the growing demand for uninterrupted power supply, the reliable operation of the power system is very important. The reliability of power system depends on its insulation design and maintenance. Partial discharges (PD) such as corona, developed from a weak link, at the edge of the winding or due to the protrusion from the winding conductor, surface discharges due to high tangential electric field, and discharges due to particle movement tend to cause characteristic changes in the insulation properties of the material and can result in catastrophic failure of the insulation system. The trend is changing from time-based maintenance to condition-based maintenance so that system can be immediately repaired as and when required, which will avoid any catastrophic damage. Hence, it is essential to deploy continuous, non-intrusive, onsite condition monitoring technique to ensure trouble-free and reliable operation of the power system.\n\nAmongst different PD detection techniques, Ultra High Frequency (UHF) method is superior in identifying the incipient discharge activity. Condition monitoring involves classification and localization of these incipient discharges which has become a challenge to researchers worldwide. The first part of the talk describes the investigation of the partial discharge activity using the UHF technique. Phase resolved partial discharge (PRPD) measurement by IEC 60270 method in conjunction with statistical parameters like kurtosis and skewness of the pulse height or phase-distribution, number of discharges per period, etc. are generally used for classification. The main limitation of such an analysis is that the parameters are purely descriptive and are not physical parameters like duration of the signal or rise time of the signal. Time-Frequency transformation for discharge classification has been proposed which uses true physical parameters of the UHF signals: duration of the signal, bandwidth of the signal and rise time of the signal.\n\nIn addition, the use of Cross Recurrence Plot (CRP) for estimation of Time Difference Of Arrival (TDOA) of UHF signals has been proposed. This method of TDOA estimation is shown to be superior to traditional methods under very noisy conditions thereby increasing localization accuracy remarkably.\n\nFurther, application of novel, non-intrusive and non-destructive techniques like Laser Induced Breakdown Spectroscopy (LIBS ) and Optical Emission Spectroscopy (OES) for condition monitoring and diagnosis of outdoor polymeric insulators will be discussed. These methods are shown to be a quick and reliable way of ranking the performance of the insulators.\n\nGrounding is an important aspect of the power system from the viewpoint of power system reliability, equipment protection, and human safety. Designing a suitable grounding system requires reasonably accurate quantification of soil parameter values; particularly conductivity, σ, and for high frequency (transients) the relative permittivity, εr. The second part of the talk will be on characterization of non-linearities in soil conductivity and permittivity. The effect of frequency and current magnitude on ground impedance should be accounted for in grounding system design. Practical verification of grounding installations is commonly achieved by measuring ground resistance or ground impedance using low voltage AC or switched DC test equipment. Such equipment may inject only a few amperes of current into the grounding system, sometimes of the order of mA, which represents a small fraction of the actual current that may flow under fault conditions. IEEE standards 80, 81 recognize the effect of current magnitude on soil resistivity and grounding impedance in terms of thermal effects at high current causing drying out and soil ionization; however, no reference is made to the non-linear characteristics of resistivity (or permittivity) and ground electrode (rod) impedance over a low magnitude current range. The investigation revealed the dependency of soil parameters on current density and values obtained at low current density are overestimated compared to that observed under fault conditions. This dependency is due to the interface formed between the metallic electrodes and soil, further, this was found to significantly affect the measured values at low frequencies. A theoretical model has been developed to account for the observed dispersion in the soil parameters.\n\nSpeaker Biodata : Dr. Ashwin Desai is a Postdoctoral fellow, Khalifa University, Abu Dhabi, UAE. He got his PhD from IIT Madras, Chennai, India in 2019. His area of research is Condition monitoring of high voltage insulation systems and electrical grounding systems.\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Emulation of wind turbine and sensorless control of doubly-fed induction generator for wind energy application\n\nSpeaker : Ramu Nair\n\nDegree Registered :PhD\n\nAdvisor : Prof. G Narayanan\n\nDate : 08/03/2021\n\nVenue : Online\n\nAbstract : Wind energy utilization has been growing at a rapid rate, fuelling research and development in wind turbine – generator systems. Doubly fed induction generator (DFIG) driven by a wind turbine is a commonly used wind energy conversion system. To advance research and education in wind energy conversion systems, a controlled test bed is necessary that does not depend on wind availability. Hence this thesis deals with emulation of wind turbine using a power electronic controlled squirrel cage induction motor (SCIM). The thesis also concerns improved control techniques for the DFIG to enhance the performance of the wind energy system.\n\nWind turbine emulation involves controlling the SCIM drive such that the motor exhibits the characteristics of a wind turbine. The inertia of the motor being much lower than the inertia of the emulated turbine is an important challenge in such wind turbine emulation schemes. This thesis proposes one degree of freedom (1-DOF) and two degree of freedom (2-DOF) control structures for wind turbine emulation, overcoming this challenge.\n\nRegarding control of DFIG in wind energy applications, position sensorless operation of DFIG is desirable from considerations of cost, maintenance, cabling and reliability. This thesis proposes two stator flux based model reference adaptive observers (SF-MRAOs) for estimation of rotor speed and position in stand-alone DFIG. One of the proposed SF-MRAO is shown to work with good dynamic performance in vector control of stand-alone DFIG. The thesis also proposes a PLL based MRAO (PLL-MRAO) which does not require integration of sensed quantities, unlike other existing MRAOs. The linearized SF-MRAO is further utilized to propose a modified direct voltage control (DVC) of stand-alone DFIG with simplified design of controllers compared to existing DVC.\n\nGrid integration of DFIG system requires synchronization of stator induced voltages with grid voltages before grid connection, and active and reactive power (PQ) control after grid connection. This thesis also proposes a unified control algorithm for synchronization and power control, enabling a seamless transfer from synchronization mode to PQ control mode. Synchronization requires initial rotor position information, obtained through either a novel rotor parking scheme or PLL-MRAO. It is shown that the unified control has negligible transients during grid integration of DFIG.\n\nAll the proposed observers and control algorithms are validated through simulations and experiments, performed on a 7.5 kW doubly-fed induction generator coupled to a 5.5 kW squirrel cage induction motor, available in the laboratory.\n\nAll are welcome\n\nGo to\n\nEvent : Thesis Defense\n\nTitle : Parallel Computing Techniques for High Speed Power System Solutions\n\nSpeaker : R. Gnanavignesh\n\nDegree Registered :PhD\n\nAdvisor : Dr. U J Shenoy\n\nDate : 12/03/2021\n\nVenue : Online\n\nAbstract : Modern power systems are enormously large and complex entities. Increase in system size, introduction of complex controls, uncertainties in forecasting, etc. necessitate faster software tools to handle power system planning, operation and operator training. This thesis aims to improve the performance of power system software tools by proposing parallel algorithms with the objective of reducing their execution time.\n\nSolution of a sparse set of linear algebraic equations is one of the most essential modules used in almost all power system software tools. The thesis addresses the issue of reducing the execution time of sparse linear algebraic solver by parallelizing sparse matrix factorization. A LU factorization algorithm which is more amenable for parallelization is identified and chosen. In this work, the structural symmetry property of power system sparse matrices is exploited to maximize the column or node level parallelism. Results obtained from the implementation of the proposed algorithm on Graphical Processing Units (GPUs) corroborate its efficacy by achieving significant reduction in the solution time when compared with state of the art CPU based sequential sparse linear solvers.\n\nPower flow algorithm is one of the most frequently executed algorithms with respect to the steady state realm of the power system. Reduction in the solution time for the power flow algorithm would further boost other applications like contingency analysis, optimal power flow, dynamic studies, etc. This thesis proposes a parallel power flow algorithm based on Newton-Raphson method. Inclusion of reactive power limit constraints at generator buses in the problem formulation stage itself eradicates the need to use heuristic techniques. In this work, the given power system network for which the power flow solution is desired, is decomposed into smaller sub-networks and processed in an independent as well as in a concurrent manner. Partial results from the sub-networks are consolidated to arrive at the solution of original network. Results obtained indicate preservation of the superior convergence property of Newton-Raphson method and a significant reduction in the solution time required for the parallel version of the power flow when compared with the sequential version.\n\nTransient stability assessment is an important module within the Dynamic Security Assessment application. Time domain simulation for the stability assessment by solving thousands of Differential Algebraic Equations (DAEs), even though is the preferred method, is computationally intensive and becomes a major computing challenge as system size increases. The thesis proposes a parallel algorithm based on spatial domain decomposition employing relaxation conditions to speedup the transient stability simulation to handle the aforementioned challenge. A convergence enhancing mechanism through selection of appropriate admittance parameters for the network emulating fictitious buses which mimic the remainder of the system for each sub-network is derived. Results obtained corroborate the scalability and improved speedup features of the methodology which achieves a significant reduction in the simulation execution time.\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Price of Privacy of Smart Meter Data\n\nSpeaker : Soumyajit Gangopadhyay\n\nDegree Registered : M. Tech (Research)\n\nAdvisor : Dr. Sarasij Das\n\nDate : 17/02/2021\n\nVenue : online\n\nAbstract : Smart meter data form the backbone of various data-driven distribution system applications ranging from demand response, outage management, power theft detection, capacitor bank switching to distribution network planning and asset management. However, privacy concerns often inhibit consumers from sharing their smart meter data. Privacy preserving algorithms have been proposed in the literature to address the privacy concern of consumers. However, privacy preservation often tends to reduce the usability of data by limiting the information that can be extracted from the data. Consumers incur privacy loss if they give up their privacy right over smart meter energy data to the utility. Compensating the consumers for their privacy loss can be an alternate approach to encourage smart meter data sharing. The advantage of this approach is that it does not reduce the data usability. There is a lack of literature on the price of privacy of smart meter data.\n\nIn this work, a novel privacy pricing framework is proposed which can be used by the power utility to determine the price of privacy of consumers' energy data. The proposed framework is intended to compensate the consumers who agree to give up their privacy right over their smart meter energy data. At first, the notion of smart meter data privacy is presented. Estimation of the price of privacy of energy consumption data of smart meters is a challenging task due to the lack of a mathematical privacy model. So, a privacy model is proposed to quantify the private information content of consumers' energy consumption data based on the privacy notion. Then, a nonlinear convex optimization problem is formulated using the proposed privacy model to determine the price of privacy of the consumers for a given budget of the utility. A constraint is incorporated in the optimization problem to ensure that the privacy price does not exceed the electricity bill of a consumer. The impact of the utility's budget (allocated for privacy pricing) on a consumer's price of privacy is shown using practical smart meter data. The results show that a consumer's price of privacy also depends on the total number of consumers (participating in privacy pricing) and the privacy content of their data. The results also indicate that the proposed pricing framework can be effective in incentivizing consumers to share their smart meter data.\n\nGo to\n\nEvent : Thesis Colloquium\n\nTitle : Analysis and Enhancement of Stability of Power Systems with Grid-scale Photovoltaic Power Plants\n\nSpeaker : Indla Rajitha Sai Priyamvada\n\nDegree Registered :PhD\n\nAdvisor : Dr. Sarasij Das\n\nDate : 09/02/2021\n\nVenue : Online\n\nAbstract : Owing to the negative impact of carbon emissions on environment, power systems are experiencing a paradigm shift in power generation. The fossil fuel-based generators that utilize synchronous machines are increasingly being replaced by the grid scale PhotoVoltaic (PV) generators. The energy conversion technology and the power electronic interface are the main factors that differentiate grid scale PVs from Synchronous Generators (SGs). The PV generators are equipped with power electronic converters which act as an efficient interface between generators and grid. The power electronic interface offers a better control over the electrical energy generated by the PV generators. However, the power electronic interface brings new challenges to power system stability. The small-signal stability and transient stability must be analyzed in detail to ensure reliable operation of power grid. This research work focuses on addressing transient and small-signal stability issues of grid connected grid scale PV generators.\n\nIn conventional power systems, swing equation of SGs and (extended) equal area criterion are used to assess the transient stability of power system. However, the same analysis techniques may not be applicable for PV generators. In this research work, transient stability assessment criteria are developed for grid connected PV generator (with two different control strategies viz., P-Q control and Vdc-Q control with/without support functionalities). The proposed criteria are developed considering the outer and inner control loop, Phase Locked Loop, and filter dynamics of PV generator. PSCAD simulations are carried out on a two-bus system and a modified IEEE-39 bus system to validate the proposed criterion. The stability criteria are found to effectively assess the stability of grid connected PV generators.\n\nThe power transfer capability of transmission network is limited by thermal limits, voltage limits and stability limits. Power transfer capability of transmission lines emanating from PV generators considering thermal and voltage limits is explored well in the literature. However, there is a lack of literature on stability constrained power transfer capability limit. In this research work, adaptive control-based tuning laws are proposed for grid connected PV generators to improve the stability constrained power transfer capability. The adaptive tuning laws are derived based on the Lyapunov energy function analysis. The Lyapunov functions are formulated using the summation of squares of the PI block errors and difference between the PI parameter values from their optimal values. PSCAD simulations are carried out to validate the proposed criterion. From the studies, it is observed that the proposed tuning laws are found to effectively improve the stability limit on power transfer to be equal to the voltage limit.\n\nThe increased penetration of PV generations into power systems has also brought qualitative changes in the small signal stability of power systems. Two new categories of oscillation modes are introduced into power systems that have participation from PV state variables. As the mode shape of the two new categories of oscillation modes is different from that of SG modes, the power system stabilizer design should be revisited. In this research work, H-infinity control-based power system stabilizer is developed considering the controllability and observability of the new categories of oscillation modes. The effectiveness of the developed stabilizer in providing sufficient damping to the new categories of oscillation modes is validated through PSCAD simulations on a modified IEEE-39 bus system.\n\nAs power systems are large interconnected systems, the increased penetration of PV generation has resulted in notable interaction among PV generators and SGs. Investigation of the interaction among generators is important to understand the dynamic behavior of overall power system when subjected to disturbances. This research work is carried out to understand the interaction among PV and SGs. The interaction is analyzed through investigation of interaction among oscillation modes of PV generation and SG. A mathematical formulation to quantify the interaction among the oscillation modes of PV generations and SGs is proposed. A modified IEEE-39 bus system is considered to carry out the interaction study and validate the results obtained from mathematical formulations.\n\nSpeaker Biodata :\n\nGo to\n\nEvent : Thesis Defence\n\nTitle : Neural Representation Learning of Speech and Audio Signals\n\nSpeaker : Purvi Agrawal\n\nDegree Registered : PhD\n\nAdvisor : Dr. Sriram Ganapathy\n\nDate : 28/01/2021\n\nVenue : Online\n\nAbstract : Representation learning is the branch of machine learning consisting of techniques that are capable of automatically discovering meaningful representations from raw data for efficient information extraction. In the recent years, following the trends in other streams of machine learning, representation learning using neural networks has attracted significant interest. In the speech processing field, representation learning has been a challenging task. This talk is focused on developing neural methods for representation learning of speech and audio signals, with the goal of improving downstream applications that rely on these representations. For representation learning, we pursue two broad directions - supervised and unsupervised. In the case of speech/audio signals, we identify two stages of representation learning. The first stage is the learning of a time-frequency representation (equivalent of spectrogram) from the raw audio waveform. The second stage is the learning of modulation representations (filtering the time-frequency representations along the temporal domain, called rate filtering and spectral domain, called scale filtering). In the first part of the talk, we propose an interpretable supervised representation learning framework for speech and audio data. Here, a two-stage representation learning approach from raw waveform is proposed, consisting of acoustic filter-bank learning (time-frequency representation learning) from raw waveform followed by a modulation representation learning. This two-stage learning is directly optimized for the task at hand. The key novelty in the proposed framework consists of a relevance weighting mechanism that acts as a feature selection modul"
    }
}