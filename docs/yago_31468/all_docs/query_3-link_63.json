{
    "id": "yago_31468_3",
    "rank": 63,
    "data": {
        "url": "https://www.ibm.com/topics/artificial-intelligence",
        "read_more_link": "",
        "language": "en",
        "title": "What Is Artificial Intelligence (AI)?",
        "top_image": "https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/64/ea/content-hub-analytic-page-leadspace-short.png/_jcr_content/renditions/cq5dam.web.1280.1280.png",
        "meta_img": "https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/64/ea/content-hub-analytic-page-leadspace-short.png/_jcr_content/renditions/cq5dam.web.1280.1280.png",
        "images": [
            "https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/64/ea/content-hub-analytic-page-leadspace-short.component.xl.ts=1724358847248.png/content/adobe-cms/us/en/topics/artificial-intelligence/_jcr_content/root/leadspace"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Artificial intelligence"
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-08-09T00:00:00",
        "summary": "",
        "meta_description": "Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision-making, creativity and autonomy.",
        "meta_lang": "en",
        "meta_favicon": "/content/dam/adobe-cms/default-images/favicon.svg",
        "meta_site_name": "",
        "canonical_link": "https://www.ibm.com/topics/artificial-intelligence",
        "text": "AI offers numerous benefits across various industries and applications. Some of the most commonly cited benefits include:\n\nAutomation of repetitive tasks.\n\nMore and faster insight from data.\n\nEnhanced decision-making.\n\nFewer human errors.\n\n24x7 availability.\n\nReduced physical risks.\n\nAutomation of repetitive tasks\n\nAI can automate routine, repetitive and often tedious tasks—including digital tasks such as data collection, entering and preprocessing, and physical tasks such as warehouse stock-picking and manufacturing processes. This automation frees to work on higher value, more creative work.\n\nEnhanced decision-making\n\nWhether used for decision support or for fully automated decision-making, AI enables faster, more accurate predictions and reliable, data-driven decisions. Combined with automation, AI enables businesses to act on opportunities and respond to crises as they emerge, in real time and without human intervention.\n\nFewer human errors\n\nAI can reduce human errors in various ways, from guiding people through the proper steps of a process, to flagging potential errors before they occur, and fully automating processes without human intervention. This is especially important in industries such as healthcare where, for example, AI-guided surgical robotics enable consistent precision.\n\nMachine learning algorithms can continually improve their accuracy and further reduce errors as they're exposed to more data and \"learn\" from experience.\n\nRound-the-clock availability and consistency\n\nAI is always on, available around the clock, and delivers consistent performance every time. Tools such as AI chatbots or virtual assistants can lighten staffing demands for customer service or support. In other applications—such as materials processing or production lines—AI can help maintain consistent work quality and output levels when used to complete repetitive or tedious tasks.\n\nReduced physical risk\n\nBy automating dangerous work—such as animal control, handling explosives, performing tasks in deep ocean water, high altitudes or in outer space—AI can eliminate the need to put human workers at risk of injury or worse. While they have yet to be perfected, self-driving cars and other vehicles offer the potential to reduce the risk of injury to passengers.\n\nIn order to contextualize the use of AI at various levels of complexity and sophistication, researchers have defined several types of AI that refer to its level of sophistication:\n\nWeak AI: Also known as “narrow AI,” defines AI systems designed to perform a specific task or a set of tasks. Examples might include “smart” voice assistant apps, such as Amazon’s Alexa, Apple’s Siri, a social media chatbot or the autonomous vehicles promised by Tesla.\n\nStrong AI: Also known as “artificial general intelligence” (AGI) or “general AI,” possess the ability to understand, learn and apply knowledge across a wide range of tasks at a level equal to or surpassing human intelligence. This level of AI is currently theoretical and no known AI systems approach this level of sophistication. Researchers argue that if AGI is even possible, it requires major increases in computing power. Despite recent advances in AI development, self-aware AI systems of science fiction remain firmly in that realm.\n\nThe idea of \"a machine that thinks\" dates back to ancient Greece. But since the advent of electronic computing (and relative to some of the topics discussed in this article) important events and milestones in the evolution of AI include the following:\n\n1950\n\nAlan Turing publishes Computing Machinery and Intelligence (link resides outside ibm.com). In this paper, Turing—famous for breaking the German ENIGMA code during WWII and often referred to as the \"father of computer science\"—asks the following question: \"Can machines think?\"\n\nFrom there, he offers a test, now famously known as the \"Turing Test,\" where a human interrogator would try to distinguish between a computer and human text response. While this test has undergone much scrutiny since it was published, it remains an important part of the history of AI, and an ongoing concept within philosophy as it uses ideas around linguistics.\n\n1956\n\nJohn McCarthy coins the term \"artificial intelligence\" at the first-ever AI conference at Dartmouth College. (McCarthy went on to invent the Lisp language.) Later that year, Allen Newell, J.C. Shaw and Herbert Simon create the Logic Theorist, the first-ever running AI computer program.\n\n1967\n\nFrank Rosenblatt builds the Mark 1 Perceptron, the first computer based on a neural network that \"learned\" through trial and error. Just a year later, Marvin Minsky and Seymour Papert publish a book titled Perceptrons, which becomes both the landmark work on neural networks and, at least for a while, an argument against future neural network research initiatives.\n\n1980\n\nNeural networks, which use a backpropagation algorithm to train itself, became widely used in AI applications.\n\n1995\n\nStuart Russell and Peter Norvig publish Artificial Intelligence: A Modern Approach (link resides outside ibm.com), which becomes one of the leading textbooks in the study of AI. In it, they delve into four potential goals or definitions of AI, which differentiates computer systems based on rationality and thinking versus acting.\n\n1997\n\nIBM's Deep Blue beats then world chess champion Garry Kasparov, in a chess match (and rematch).\n\n2004\n\nJohn McCarthy writes a paper, What Is Artificial Intelligence? (link resides outside ibm.com), and proposes an often-cited definition of AI. By this time, the era of big data and cloud computing is underway, enabling organizations to manage ever-larger data estates, which will one day be used to train AI models.\n\n2011\n\nIBM Watson® beats champions Ken Jennings and Brad Rutter at Jeopardy! Also, around this time, data science begins to emerge as a popular discipline.\n\n2015\n\nBaidu's Minwa supercomputer uses a special deep neural network called a convolutional neural network to identify and categorize images with a higher rate of accuracy than the average human.\n\n2016\n\nDeepMind's AlphaGo program, powered by a deep neural network, beats Lee Sodol, the world champion Go player, in a five-game match. The victory is significant given the huge number of possible moves as the game progresses (over 14.5 trillion after just four moves). Later, Google purchased DeepMind for a reported USD 400 million.\n\n2022\n\nA rise in large language models or LLMs, such as OpenAI’s ChatGPT, creates an enormous change in performance of AI and its potential to drive enterprise value. With these new generative AI practices, deep-learning models can be pretrained on large amounts of data.\n\n2024\n\nThe latest AI trends point to a continuing AI renaissance. Multimodal models that can take multiple types of data as input are providing richer, more robust experiences. These models bring together computer vision image recognition and NLP speech recognition capabilities. Smaller models are also making strides in an age of diminishing returns with massive models with large parameter counts."
    }
}