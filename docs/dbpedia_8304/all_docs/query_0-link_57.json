{
    "id": "dbpedia_8304_0",
    "rank": 57,
    "data": {
        "url": "https://arxiv.org/html/2406.15669v1",
        "read_more_link": "",
        "language": "en",
        "title": "CARE: a Benchmark Suite for the Classification and Retrieval of Enzymes",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/extracted/5684441/figures/fig_overview.png",
            "https://arxiv.org/html/extracted/5684441/figures/fig_similarity.png",
            "https://arxiv.org/html/extracted/5684441/figures/fig_CREEP.png",
            "https://arxiv.org/html/extracted/5684441/figures/fig_flowchart.png",
            "https://arxiv.org/html/extracted/5684441/figures/fig_distribution.png",
            "https://arxiv.org/html/extracted/5684441/figures/fig_extrapolation.png",
            "https://arxiv.org/html/extracted/5684441/figures/fig_piechart.png",
            "https://arxiv.org/html/extracted/5684441/figures/fig_downstream.png",
            "https://arxiv.org/html/extracted/5684441/figures/fig_lineplots.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Jason Yang\n\nChemistry and Chemical Engineering\n\nCalifornia Institute of Technology\n\n&Ariane Mora\n\nChemistry and Chemical Engineering\n\nCalifornia Institute of Technology\n\n&Shengchao Liu\n\nComputing and Mathematical Sciences\n\nCalifornia Institute of Technology\n\n&Bruce J. Wittmann\n\nOffice of the Chief Scientific Officer\n\nMicrosoft Corporation\n\n&Anima Anandkumar\n\nComputing and Mathematical Sciences\n\nCalifornia Institute of Technology\n\n&Frances H. Arnold\n\nChemistry and Chemical Engineering\n\nBiology and Biological Engineering\n\nCalifornia Institute of Technology\n\n&Yisong Yue\n\nComputing and Mathematical Sciences\n\nCalifornia Institute of Technology\n\nCorespondance: yyue@caltech.edu\n\nAbstract\n\nEnzymes are important proteins that catalyze chemical reactions. In recent years, machine learning methods have emerged to predict enzyme function from sequence; however, there are no standardized benchmarks to evaluate these methods. We introduce CARE, a benchmark and dataset suite for the Classification And Retrieval of Enzymes (CARE). CARE centers on two tasks: (1) classification of a protein sequence by its enzyme commission (EC) number and (2) retrieval of an EC number given a chemical reaction. For each task, we design train-test splits to evaluate different kinds of out-of-distribution generalization that are relevant to real use cases. For the classification task, we provide baselines for state-of-the-art methods. Because the retrieval task has not been previously formalized, we propose a method called Contrastive Reaction-EnzymE Pretraining (CREEP) as one of the first baselines for this task. CARE is available at https://github.com/jsunn-y/CARE/.\n\n1 Introduction\n\nProteins, which are sequences of amino acid building blocks, are not only integral components of all living organisms, but also important for a myriad of commercial applications spanning from the health domain to the bio-economy. Enzymes are a subclass of proteins that can catalyze chemical reactions, and they have many applications in areas such as bioremediation, plastic degradation, gene editing, and drug synthesis [1, 2, 3].\n\nIdentifying the specific chemical reactions that an enzyme is capable of performing (i.e. the enzyme’s function) is a key first step for many applications [4]. For instance, during standard metagenomic analyses, enzyme genes are annotated for their functions, which enables determination of an organism’s critical metabolic pathways and specialization [5, 6, 7]. When applied to chemical synthesis, enzyme annotations are needed to identify catalysts that can replace existing step(s) in drug synthesis procedures–known as retrobiosynthesis [8]. Likewise, enzyme engineering for new-to-nature function [9] involves discovering an enzyme starting point with a desired function before improving activity for that function using protein engineering techniques [10, 11]. Historically, similarity search algorithms, most notably BLAST, have been the most common methods used to assign function to protein sequences [12, 13]. These methods work by finding similar sequences in annotated reference databases, as similar sequences are likely to share function. Still, there is a need for more abundant, high-quality annotations of enzymes and automated workflows to identify enzymes with desired functions.\n\nIn recent years, there has been increasing interest in using machine learning (ML) for a broad range of applications related to the functional prediction and design of enzymes [11, 14, 15]. In particular, ML models have emerged to classify protein sequences based on their function, which are reviewed here [16] with some more recent examples listed here [17, 7, 18, 19, 20, 21, 22]. Despite these advancements, there is no standard benchmark or dataset for evaluating computational models for enzyme function prediction. A challenge associated with classification is that a given enzyme is often able to perform multiple reactions [23], and many reactions are not annotated. Moreover, complex tasks such as extrapolation to unannotated reactions have yet to be evaluated.\n\nIn this work, we present a benchmark suite for the Classification And Retrieval of Enzymes (CARE). Our contributions can be summarized as: (1) formalizing model evaluation into two tasks which are directly relevant to scientists and engineers: classification of an enzyme by function (Task 1), and retrieval of enzyme sequences based on a reaction (Task 2); (2) curating high-quality and easy-to-use datasets; (3) providing train-test splits that mimic challenging extrapolations in real-world use cases; and (4) benchmarking state-of-the-art models for Task 1, and providing the first baselines for Task 2. Because Task 2 has not been previously explored, we introduce a model called Contrastive Reaction-EnzymE Pretraining (CREEP) to serve as an initial baseline. CREEP can perform contrastive learning across three different modalities (protein, reaction, and textual description), and the learned representations are then used for retrieval. Overall, we anticipate that CARE will be a useful and easy-to-use resource for ML researchers to benchmark their enzyme function prediction models.\n\n2 Related Work\n\nDatasets. Various databases have emerged to help researchers store, share, and identify functionally annotated enzymes. Protein sequence databases such as UniProt [24] and Pfam [25] are catalogues of annotated protein sequences. While most databases reference protein sequences, increasingly, these sequences can be linked to protein structures, either experimentally validated, as in the Protein Data Bank (PDB), or via structural prediction tools [26] in databases such as the AlphaFold Database [27]. BRENDA [28] is a curated database specific for reaction and enzyme sequence information. Rhea [29] consolidates information from BRENDA, and other sources, such as pathway databases including KEGG [30]. There is ongoing work to compile and clean/standardize reactions from multiple databases, namely ECReact [31] and EnzymeMap [32]. Related to these databases, RetroBioCat is a database and retrobiosynthesis planning tool [33, 34], and Selenzyme is tool to retrieve enzymes to perform a target reaction [35].\n\nProtein Benchmarks. Our work takes inspiration from existing protein fitness prediction benchmarks, where fitness is a quantification of some function. TAPE [36] and FLIP [37] evaluate representations from protein language models for the prediction of a broad range of general and specific protein properties (stability, secondary structure, binding etc.) ProteinGym considers sequence variant effect prediction by using likelihoods from these language models [38]. While benchmarks for protein fitness prediction tasks are well defined, there are no standardized benchmarks for protein function prediction, which is more qualitative/categorical rather than quantitative. Here, we focus on proteins that perform chemical reactions (i.e., enzymes).\n\nClassification of Enzyme Function. ML models have emerged to predict the outcomes of enzymatic reactions [39, 40, 41] and for classification of enzyme function. Enzyme function is usually expressed using enzyme commission (EC) numbers, which is a hierarchical scheme for classifying enzyme function into classes (families) and consists of four levels of descriptions (Figure 1A). Some classification models are general protein function prediction models, which encompass all proteins, not just enzymes, such as ProtCNN/ENN [20] and ProteInfer [21]. Many models utilize representations from protein language models [42, 43, 44], and others incorporate protein structure as information, such as DeepFRI [19] and BioCLIP [45]. Methods related to supervised contrastive learning [46] have been particularly useful here, such as CLEAN and HiFi-NN [18, 7], likely by reducing imbalances in the number of sequences representing each EC number. Recently, combining ML with BLAST has enabled retrieval-augmented function prediction in ProtEx [22].\n\nLarge Language Models. Recently, there has been an explosion in pretrained models in the biological and chemical domains, particularly large language models (LLMs) [47]. For example, ChatGPT is capable of answering questions related to general scientific knowledge. These language models can be further finetuned for applications such as answering questions about protein sequences (Pika, [48]) and for reaction synthesis planning (ChemCrow, [49]), among others. LLMs present important benchmarks for enzyme functional classification and retrieval, given the widespread adoption of LLMs as science facilitators and their ease of use (in particular webserver-based approaches), compared to domain-specific methods. In this study, we include ChatGPT as a baseline.\n\nMultimodal Contrastive Learning. Contrastive learning is an efficient and effective pretraining paradigm that aligns positive pairs and contrasts negative pairs simultaneously. The design of these pairs depends on the specific tasks, such as using data augmentations of the same image [50] or considering the topology and geometry of molecules [51]. More recently, contrastive learning has shown success in aligning the representation space of different biological and chemical modalities, e.g., text and chemical structure alignment in MoleculeSTM [52], text and protein sequence alignment in ProteinDT [53] and ProteinCLIP [54], reaction structure and protein structure alignment in CLIPZyme [55], and protein sequence and structure alignment in BioCLIP [45] and with text in ProTrek [56], among others [57, 47]. Cross-modal alignment in the representation space has been shown to improve generalizability and improve performance on challenging tasks, such as out-of-distribution learning, zero-shot learning, and text-guided molecule design and optimization [53]. Consideration of multiple modalities may be especially important for the prediction of qualitative functions.\n\n3 Overview of CARE\n\nThough there are many studies using ML models to perform enzyme classification based on EC numbers (Figure 1A), there is no standardized benchmark to evaluate how well these models generalize to unseen protein sequences. To address this need, we present a benchmark suite for the classification and retrieval of enzymes (CARE, Figure 1B). CARE formalizes classification of an enzyme sequence by EC number as \"Task 1\" (Figure 1C). For this task, we design train-test splits of protein sequences to test out-of-domain generalizations that are relevant to real-world use cases. In addition, CARE addresses another key limitation of current studies: classification is limited to EC numbers, which is a closed vocabulary of functions (reactions), so existing models cannot generalize to unannotated reactions. Thus, we introduce an entirely new task, retrieval of an EC number given a reaction, which we call \"Task 2\" (Figure 1D). For this task, we design train-test splits to evaluate how well models can generalize to out-of-domain reactions, ensuring that the splits pose different levels of difficulty.\n\nTo streamline benchmarking, we curate a dataset of enzymes, reactions, and their associated EC numbers for CARE. At a high level, we build two datasets, one that links protein sequence to EC and one that links reaction to EC (Figure 1A). The former is processed from Swiss-Prot, the expert-validated portion of UniProt [24] and filtered to protein sequences between length 100 and 650 with annotated EC number(s). The latter is formed as a combination of EnzymeMap [32] and ECReact [31], where ECReact is only used to supplement EC numbers that are missing in EnzymeMap. Our workflow for generating the datasets used in this work is explained in detail in Appendix A.1 and shown visually in Appendix Figure A.1.\n\nThe overall workflow for benchmarking using CARE is shown in Figure 1B. For each task, domain-specific train-test splits are provided from the processed datasets. Model training can use any of the data in the train split, and each model is evaluated on the associated test split. In the rest of this study, we explain the specific design choices used to generate train-test splits and analyze benchmarking results of state-of-the-art methods on these splits. The curated datasets and splits used in CARE can be accessed at https://github.com/jsunn-y/CARE/.\n\n4 Task 1: Enzyme Classification\n\nTask 1, classification of an enzyme sequence, tests the ability of a model to extrapolate to unseen protein sequences. Task 1 is a fairly well studied task [16], but model evaluation has not been previously standardized. Task 1 applies to use cases where a scientist is given an unannotated enzyme sequence and seeks to understand the enzymatic function associated with that sequence (Figure 1C). For example, an environmental biologist using metagenomic data may seek to understand which microbes in a community are utilizing energy from alkane degradation, or a retrobiosynthesis planner may look for unannotated proteins to improve a synthesis workflow. With the emergence of conditional generative models for protein sequences, it is also important to have high-throughput computational methods that can predict the function of generated sequences [58, 59, 60, 61]. For this task, a query protein is passed through a trained model to predict an EC number. The EC number is then associated with likely reactions that the protein will be able to perform.\n\nSplits for Task 1. Task 1 can be framed as evaluating how models generalize toward unseen sequences with different types of difficulty, visualized in Appendix Figure A.3A. The train-test splits for Task 1 are summarized in Table 1.\n\n•\n\n<30%, 30-50%, 50-70%, and 70-90% identity splits: these four test splits contain sequences with sequence identities falling in the respective range, to sequences in the training set. Sequence identity is related to the normalized Levenshtein distance between two sequences. Natural sequences with high (>50%) sequence identity at the protein sequence level are likely to share function. It is expected that the lower the sequence identity, the more difficult it is to assign functional annotation.\n\n•\n\npreviously misclassified (Price et al.) [5] split: challenging to assign because some have low sequence identity to other proteins, and many may lie near activity cliffs, where function can change sharply in sequence space.\n\n•\n\npromiscuous split: in this study, we define promiscuous enzymes as those mapping to multiple EC numbers (thus lying on multiple activity peaks). These enzymes are particularly interesting for enzyme engineers, as new-to-nature activity can be found in between activity peaks [11].\n\nFor Task 1, the training split is constructed by holding out all of the pooled sequences in the test splits. The classification output vocabulary (EC numbers) is closed rather than open. We verify that sequences in the test sets generally fall within the expected sequence identities, relative to the training set (Figure 2A). Notably, the Price test set has a wide distribution of sequence identities, while the promiscuous test set has high sequence similarity to the training set. The sequences in the test splits are distributed generally evenly across all different EC numbers (Figure A.4 in Appendix). More details can be found in Appendix A.2.\n\nTask 1 benchmarking results. Benchmarking results for Task 1 are summarized in Table 2. We start with two methods as baselines, classification using a random order of EC numbers (Random), and npysearch (a python implementation of BLAST at the protein sequence level, herein referred to as BLASTp), which is a workhorse bioinformatics tool which performs local-alignment to determine the most similar sequence(s) given a target query and a database [12].\n\nWhile there exist many ML tools to perform EC number classification, CLEAN [18], HiFi-NN [7], and ProtEx [22] seem to report the current state-of-the-art. HiFi-NN and ProtEx are not included in this study, as they are not publicly available yet. CLEAN generally performs better than BLASTp across the board, but there are certain cases where the performance is similar. We additionally benchmark ProteInfer [21], a neural network classification tool, but its performance is likely inflated as reported here, as we were unable to retrain it for this study to ensure no data leakage from the test set. ChatGPT was also tested, but it appeared to often hallucinate as it was forced to provide an answer, with results similar to the random baseline. Models that are soon to be released, such as Pika, may bridge the gap between standard LLMs and enzyme classification [48].\n\nOverall, these results suggest that there is still room to improve classification of protein sequences with low sequence identity (<30%) and that lie near multiple activity peaks (Price). The promiscuous split is not easy for all methods, even though the test sequences have high sequence identity to the train set. Interestingly, BLAST performs close to the state-of-the-art, even when compared to more complex ML models. Future models could take advantage of this finding to augment training, as ProtEx does [22]. Additional details on the implementation of each method can be found in Appendix A.4.\n\n5 Task 2: Enzyme Retrieval\n\nTask 2, enzyme retrieval from a query reaction, tests the ability of a model to extrapolate to unseen reactions. Task 2 has not been formalized or explored in previous studies, but it is equally as important as Task 1, as it applies to a use case where a scientist or engineer is seeking to identify a previously characterized enzyme sequence that can perform a novel (unannotated) reaction (Figure 1D). Typical applications include: an environmental engineer looking for an enzyme to degrade a toxic pollutant [63], an enzyme engineer looking for an enzyme to catalyze a selective reaction for drug synthesis [64, 65], or a gene annotator identifying the gene for an \"orphan\" enzyme with known function but unknown sequence [66]. For Task 2, a query reaction is passed through a trained model to perform retrieval to an EC number. The EC number is then associated with proteins that are likely to be able to perform that reaction.\n\nSplits for Task 2. Task 2 aims to evaluate how well a model generalizes to unseen reactions with different levels of difficulty. The train-test splits for Task 2 (easy, medium, and hard) are summarized in Table 3 and visualized in Appendix Figure A.3B. We equate greater difficulty with a more challenging train-test split; in a harder set, the test reactions are less similar to reactions in the corresponding train set. We decide similarity based on the amount of overlap in EC number (e.g., a reaction from 4.2.1.20 is more similar to another one in 4.2.1.20 than one from 4.2.1.1).\n\n•\n\neasy split: EC numbers are randomly sampled at EC level 4 (X.X.X.X) and then randomly mapped to reactions, which are held out as the test set.\n\n•\n\nmedium split: the same reactions are used for testing as the easy set, but all other reaction-EC pairs which share the same EC level 4 (X.X.X.X) are held out from training.\n\n•\n\nhard split: random EC numbers are sampled at EC level 3 (X.X.X.-) and all reactions under that EC3 are held out from training, while a subset of reactions from the held-out EC numbers are used for testing.\n\nThe sequences in the test splits are distributed generally evenly across different EC numbers (Appendix Figure A.4). From easy to medium to hard, the test set reactions also become more dissimilar to their respective training sets (Figure 2B). Reaction similarity was quantified by DRFP, which is a reaction representation that uses set differences between product and reactant fingerprints and has demonstrated solid performance with requiring model training [62]. Overall, Task 2 is more complex than Task 1, because unlike Task 1, entire EC numbers are held out from the training set (i.e., the classification output vocabulary is open rather than closed), so multiple modalities must be considered. More details on splitting can be found in Appendix A.2.\n\nCREEP baseline method. There are no existing models that have been tested for their ability to generalize beyond annotated reactions, so we develop a contrastive learning method for this task, called Contrastive Reaction-EnzymE Pretraining (CREEP) (Figure 3). Our approach is related to CLIPZyme [55], which uses contrastive alignment of reactions represented as 2D graphs and protein structures represented as 3D graphs. CREEP leverages finetuning of pretraining language models, rxnfp [67] and ProtT5 [44], respectively, to learn aligned representations of reactions and proteins. Rxnfp is a BERT-style [68] language model that was trained on reactions represented as SMILES/SMARTS strings and has demonstrated state-of-the-art performance on reaction type classification. ProtT5 is a T5 protein language model that has been used for prediction of various protein properties. We used these language models for simplicity and their ease of finetuning. Uniquely, CREEP can learn on a third modality (CREEP w/ Text): textual description of the EC number based on gene ontology [69], which is encoded using SciBERT [70]. More details on CREEP training can be found in Appendix A.3.\n\nTask 2 benchmarking results. Benchmarking results for Task 2 are summarized in Table 4. We start with two methods as baselines: randomly guessing a ranking of EC numbers (Random) and finding the most similar reaction in the train set to the test query (Similarity Baseline). For the Similarity Baseline, we used DRFP to represent chemical reactions [62]. Details on the downstream multimodal retrieval process can be found in Appendix A.3 and Figure A.4.\n\nOverall, the Similarity Baseline is quite strong and performs much better than Random. ChatGPT performs generally well, but it has access to held-out information, which means that it is not the best measure of generalization to unannotated reactions. ChatGPT was prompted with reactions written using compound IUPAC names rather than SMILES strings, both with (ChatGPT w/ Text) and without (ChatGPT) textual descriptions from gene ontology [69]. We also included CLIPZyme [55] as a baseline, but the performance is likely inflated, as we were not yet able to retrain the model.\n\nOn the more difficult test sets, CREEP offers an advantage compared to the Similarity Baseline, and particularly when combined with textual description: CREEP (w/ Text). This suggests that utilizing protein sequence information as a modality is useful. Still, performance on the harder splits is quite weak across the board, which suggests that there is significant room for future improvement. We anticipate that contrastive alignment with textual descriptions will play an increasingly important role in enzyme retrieval [54, 53, 47], and there is opportunity for better curation of these descriptions. Combining other modalities, such as reactions and protein structures as graphs as in CLIPZyme, could also yield improvements in performance. Additional details on the implementation of each method are in Appendix A.4, and additional benchmarking results are presented in Figure A.6.\n\n6 Conclusion\n\nPredicting the functions of enzymes is important for many applications ranging from gene annotation to enzyme engineering. While many models exist to classify enzyme function via EC numbers, there are no standardized benchmarks for evaluation of these models. Furthermore, no existing models have been tested for generalization beyond annotated reactions. To address this need, we introduce CARE, which is a benchmarking suite to formalize model evaluation for these two tasks. We also present CREEP, a model which uses multimodal contrastive learning and is one of the first models that can perform the latter task. A more detailed discussion of limitations and future work is included in Appendix A.6. Overall, CARE is an important tool for encouraging progress in enzyme functional annotation. We believe that we are just seeing the beginning of the widespread adoption of multimodal models for protein functional prediction, and we expect that many researchers will find CARE useful for formulating and evaluating their models.\n\nAcknowledgments and Disclosure of Funding\n\nThis material is based upon work supported by the U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, under Award Number DE-SC0022218. This report was prepared as an account of work sponsored by an agency of the United States Government. Neither the United States Government nor any agency thereof, nor any of their employees, makes any warranty, express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. Reference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government or any agency thereof. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof. J.Y. is partially supported by the National Science Foundation Graduate Research Fellowship. A.M. is supported by the Schmidt Science Fellows, in partnership with the Rhodes Trust. The authors thank Peter Mikhael and Itamar Chinn for helpful discussions on CLIPZyme implementation.\n\nReferences\n\nBuller et al. [2023] R. Buller, S. Lutz, R. J. Kazlauskas, R. Snajdrova, J. C. Moore, and U. T. Bornscheuer. From nature to industry: Harnessing enzymes for biocatalysis. Science, 382(6673):eadh8615, November 2023. ISSN 0036-8075, 1095-9203. doi: 10.1126/science.adh8615.\n\nArnold [2018] Frances H. Arnold. Directed Evolution: Bringing New Chemistry to Life. Angewandte Chemie International Edition, 57(16):4143–4148, April 2018. ISSN 1433-7851, 1521-3773. doi: 10.1002/anie.201708408.\n\nChen and Arnold [2020] Kai Chen and Frances H. Arnold. Engineering new catalytic activities in enzymes. Nature Catalysis, 3(3):203–213, January 2020. ISSN 2520-1158. doi: 10.1038/s41929-019-0385-5.\n\nRadivojac et al. [2013] Predrag Radivojac, Wyatt T Clark, Tal Ronnen Oron, Alexandra M Schnoes, Tobias Wittkop, Artem Sokolov, Kiley Graim, Christopher Funk, Karin Verspoor, Asa Ben-Hur, Gaurav Pandey, Jeffrey M Yunes, Ameet S Talwalkar, Susanna Repo, Michael L Souza, Damiano Piovesan, Rita Casadio, Zheng Wang, Jianlin Cheng, Hai Fang, Julian Gough, Patrik Koskinen, Petri Törönen, Jussi Nokso-Koivisto, Liisa Holm, Domenico Cozzetto, Daniel W A Buchan, Kevin Bryson, David T Jones, Bhakti Limaye, Harshal Inamdar, Avik Datta, Sunitha K Manjari, Rajendra Joshi, Meghana Chitale, Daisuke Kihara, Andreas M Lisewski, Serkan Erdin, Eric Venner, Olivier Lichtarge, Robert Rentzsch, Haixuan Yang, Alfonso E Romero, Prajwal Bhat, Alberto Paccanaro, Tobias Hamp, Rebecca Kaßner, Stefan Seemayer, Esmeralda Vicedo, Christian Schaefer, Dominik Achten, Florian Auer, Ariane Boehm, Tatjana Braun, Maximilian Hecht, Mark Heron, Peter Hönigschmid, Thomas A Hopf, Stefanie Kaufmann, Michael Kiening, Denis Krompass, Cedric Landerer, Yannick Mahlich, Manfred Roos, Jari Björne, Tapio Salakoski, Andrew Wong, Hagit Shatkay, Fanny Gatzmann, Ingolf Sommer, Mark N Wass, Michael J E Sternberg, Nives Škunca, Fran Supek, Matko Bošnjak, Panče Panov, Sašo Džeroski, Tomislav Šmuc, Yiannis A I Kourmpetis, Aalt D J Van Dijk, Cajo J F Ter Braak, Yuanpeng Zhou, Qingtian Gong, Xinran Dong, Weidong Tian, Marco Falda, Paolo Fontana, Enrico Lavezzo, Barbara Di Camillo, Stefano Toppo, Liang Lan, Nemanja Djuric, Yuhong Guo, Slobodan Vucetic, Amos Bairoch, Michal Linial, Patricia C Babbitt, Steven E Brenner, Christine Orengo, Burkhard Rost, Sean D Mooney, and Iddo Friedberg. A large-scale evaluation of computational protein function prediction. Nature Methods, 10(3):221–227, March 2013. ISSN 1548-7091, 1548-7105. doi: 10.1038/nmeth.2340.\n\nPrice et al. [2018] Morgan N. Price, Kelly M. Wetmore, R. Jordan Waters, Mark Callaghan, Jayashree Ray, Hualan Liu, Jennifer V. Kuehl, Ryan A. Melnyk, Jacob S. Lamson, Yumi Suh, Hans K. Carlson, Zuelma Esquivel, Harini Sadeeshkumar, Romy Chakraborty, Grant M. Zane, Benjamin E. Rubin, Judy D. Wall, Axel Visel, James Bristow, Matthew J. Blow, Adam P. Arkin, and Adam M. Deutschbauer. Mutant phenotypes for thousands of bacterial genes of unknown function. Nature, 557(7706):503–509, May 2018. ISSN 0028-0836, 1476-4687. doi: 10.1038/s41586-018-0124-0.\n\nPavlopoulos et al. [2023] Georgios A. Pavlopoulos, Fotis A. Baltoumas, Sirui Liu, Oguz Selvitopi, Antonio Pedro Camargo, Stephen Nayfach, Ariful Azad, Simon Roux, Lee Call, Natalia N. Ivanova, I. Min Chen, David Paez-Espino, Evangelos Karatzas, Novel Metagenome Protein Families Consortium, Silvia G. Acinas, Nathan Ahlgren, Graeme Attwood, Petr Baldrian, Timothy Berry, Jennifer M. Bhatnagar, Devaki Bhaya, Kay D. Bidle, Jeffrey L. Blanchard, Eric S. Boyd, Jennifer L. Bowen, Jeff Bowman, Susan H. Brawley, Eoin L. Brodie, Andreas Brune, Donald A. Bryant, Alison Buchan, Hinsby Cadillo-Quiroz, Barbara J. Campbell, Ricardo Cavicchioli, Peter F. Chuckran, Maureen Coleman, Sean Crowe, Daniel R. Colman, Cameron R. Currie, Jeff Dangl, Nathalie Delherbe, Vincent J. Denef, Paul Dijkstra, Daniel D. Distel, Emiley Eloe-Fadrosh, Kirsten Fisher, Christopher Francis, Aaron Garoutte, Amelie Gaudin, Lena Gerwick, Filipa Godoy-Vitorino, Peter Guerra, Jiarong Guo, Mussie Y. Habteselassie, Steven J. Hallam, Roland Hatzenpichler, Ute Hentschel, Matthias Hess, Ann M. Hirsch, Laura A. Hug, Jenni Hultman, Dana E. Hunt, Marcel Huntemann, William P. Inskeep, Timothy Y. James, Janet Jansson, Eric R. Johnston, Marina Kalyuzhnaya, Charlene N. Kelly, Robert M. Kelly, Jonathan L. Klassen, Klaus Nüsslein, Joel E. Kostka, Steven Lindow, Erik Lilleskov, Mackenzie Lynes, Rachel Mackelprang, Francis M. Martin, Olivia U. Mason, R. Michael McKay, Katherine McMahon, David A. Mead, Monica Medina, Laura K. Meredith, Thomas Mock, William W. Mohn, Mary Ann Moran, Alison Murray, Josh D. Neufeld, Rebecca Neumann, Jeanette M. Norton, Laila P. Partida-Martinez, Nicole Pietrasiak, Dale Pelletier, T. B. K. Reddy, Brandi Kiel Reese, Nicholas J. Reichart, Rebecca Reiss, Mak A. Saito, Daniel P. Schachtman, Rekha Seshadri, Ashley Shade, David Sherman, Rachel Simister, Holly Simon, James Stegen, Ramunas Stepanauskas, Matthew Sullivan, Dawn Y. Sumner, Hanno Teeling, Kimberlee Thamatrakoln, Kathleen Treseder, Susannah Tringe, Parag Vaishampayan, David L. Valentine, Nicholas B. Waldo, Mark P. Waldrop, David A. Walsh, David M. Ward, Michael Wilkins, Thea Whitman, Jamie Woolet, Tanja Woyke, Ioannis Iliopoulos, Konstantinos Konstantinidis, James M. Tiedje, Jennifer Pett-Ridge, David Baker, Axel Visel, Christos A. Ouzounis, Sergey Ovchinnikov, Aydin Buluç, and Nikos C. Kyrpides. Unraveling the functional dark matter through global metagenomics. Nature, 622(7983):594–602, October 2023. ISSN 0028-0836, 1476-4687. doi: 10.1038/s41586-023-06583-7.\n\nAyres et al. [2024] Gavin Ayres, Geraldene Munsamy, Michael Heinzinger, Noelia Ferruz, Kevin Yang, and Philipp Lorenz. HiFi-NN annotates the microbial dark matter with Enzyme Commission numbers. 2024.\n\nYu et al. [2023a] Tianhao Yu, Aashutosh Girish Boob, Michael J. Volk, Xuan Liu, Haiyang Cui, and Huimin Zhao. Machine learning-enabled retrobiosynthesis of molecules. Nature Catalysis, 6(2):137–151, February 2023a. ISSN 2520-1158. doi: 10.1038/s41929-022-00909-w.\n\nJain et al. [2024] Shubhanshu Jain, Felipe Ospina, and Stephan C. Hammer. A New Age of Biocatalysis Enabled by Generic Activation Modes. JACS Au, page jacsau.4c00247, May 2024. ISSN 2691-3704, 2691-3704. doi: 10.1021/jacsau.4c00247.\n\nRomero and Arnold [2009] Philip A Romero and Frances H Arnold. Exploring protein fitness landscapes by directed evolution. Nature Reviews Molecular Cell Biology, 10:866–876, 2009. doi: 10.1038/nrm2805.\n\nYang et al. [2024] Jason Yang, Francesca-Zhoufan Li, and Frances H. Arnold. Opportunities and Challenges for Machine Learning-Assisted Enzyme Engineering. ACS Central Science, page acscentsci.3c01275, February 2024. ISSN 2374-7943, 2374-7951. doi: 10.1021/acscentsci.3c01275.\n\nAltschuP et al. [1990] Stephen F AltschuP, Warren Gish, Webb Miller, Eugene W Myers, and David J Lipman. Basic local alignment search tool. Journal of Molecular Biology, 1990.\n\nFinn et al. [2015] Robert D. Finn, Jody Clements, William Arndt, Benjamin L. Miller, Travis J. Wheeler, Fabian Schreiber, Alex Bateman, and Sean R. Eddy. HMMER web server: 2015 update. Nucleic Acids Research, 43(W1):W30–W38, July 2015. ISSN 0305-1048, 1362-4962. doi: 10.1093/nar/gkv397.\n\nKouba et al. [2023] Petr Kouba, Pavel Kohout, Faraneh Haddadi, Anton Bushuiev, Raman Samusevich, Jiri Sedlar, Jiri Damborsky, Tomas Pluskal, Josef Sivic, and Stanislav Mazurenko. Machine Learning-Guided Protein Engineering. ACS Catalysis, 13(21):13863–13895, October 2023. ISSN 2155-5435, 2155-5435. doi: 10.1021/acscatal.3c02743.\n\nJohnston et al. [2023] Kadina E. Johnston, Clara Fannjiang, Bruce J. Wittmann, Brian L. Hie, Kevin K. Yang, and Zachary Wu. Machine Learning for Protein Engineering, May 2023. arXiv:2305.16634 [q-bio].\n\nRamakrishnan and Bromberg [2023] Prabakaran Ramakrishnan and Yana Bromberg. Functional profiling of the sequence stockpile: a review and assessment of in silico prediction tools, July 2023.\n\nRyu et al. [2019] Jae Yong Ryu, Hyun Uk Kim, and Sang Yup Lee. Deep learning enables high-quality and high-throughput prediction of enzyme commission numbers. Proceedings of the National Academy of Sciences, 116(28):13996–14001, July 2019. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.1821905116.\n\nYu et al. [2023b] Tianhao Yu, Haiyang Cui, Jianan Canal Li, Yunan Luo, Guangde Jiang, and Huimin Zhao. Enzyme function prediction using contrastive learning. 379(6639):1358–1363, 2023b. doi: 10.1126/science.adf2465.\n\nGligorijević et al. [2021] Vladimir Gligorijević, P. Douglas Renfrew, Tomasz Kosciolek, Julia Koehler Leman, Daniel Berenberg, Tommi Vatanen, Chris Chandler, Bryn C. Taylor, Ian M. Fisk, Hera Vlamakis, Ramnik J. Xavier, Rob Knight, Kyunghyun Cho, and Richard Bonneau. Structure-based protein function prediction using graph convolutional networks. Nature Communications, 12(1):1–14, May 2021. ISSN 2041-1723. doi: 10.1038/s41467-021-23303-9.\n\nBileschi et al. [2022] Maxwell L. Bileschi, David Belanger, Drew H. Bryant, Theo Sanderson, Brandon Carter, D. Sculley, Alex Bateman, Mark A. DePristo, and Lucy J. Colwell. Using deep learning to annotate the protein universe. Nature Biotechnology, 40(6):932–937, June 2022. ISSN 1087-0156, 1546-1696. doi: 10.1038/s41587-021-01179-w.\n\nSanderson et al. [2023] Theo Sanderson, Maxwell L Bileschi, David Belanger, and Lucy J Colwell. ProteInfer, deep neural networks for protein functional inference. eLife, 12:e80942, February 2023. ISSN 2050-084X. doi: 10.7554/eLife.80942.\n\nShaw et al. [2024] Peter Shaw, Bhaskar Gurram, David Belanger, Andreea Gane, Maxwell L Bileschi, Lucy J Colwell, Kristina Toutanova, and Ankur P Parikh. ProtEx: A Retrieval-Augmented Approach for Protein Function Prediction. 2024.\n\nTawfik [2010] Olga Khersonsky and Dan S. Tawfik. Enzyme Promiscuity: A Mechanistic and Evolutionary Perspective. Annual Review of Biochemistry, 79(1):471–505, June 2010. ISSN 0066-4154, 1545-4509. doi: 10.1146/annurev-biochem-030409-143718.\n\nThe UniProt Consortium et al. [2023] The UniProt Consortium, Alex Bateman, Maria-Jesus Martin, Sandra Orchard, Michele Magrane, Shadab Ahmad, Emanuele Alpi, Emily H Bowler-Barnett, Ramona Britto, Hema Bye-A-Jee, Austra Cukura, Paul Denny, Tunca Dogan, ThankGod Ebenezer, Jun Fan, Penelope Garmiri, Leonardo Jose Da Costa Gonzales, Emma Hatton-Ellis, Abdulrahman Hussein, Alexandr Ignatchenko, Giuseppe Insana, Rizwan Ishtiaq, Vishal Joshi, Dushyanth Jyothi, Swaathi Kandasaamy, Antonia Lock, Aurelien Luciani, Marija Lugaric, Jie Luo, Yvonne Lussi, Alistair MacDougall, Fabio Madeira, Mahdi Mahmoudy, Alok Mishra, Katie Moulang, Andrew Nightingale, Sangya Pundir, Guoying Qi, Shriya Raj, Pedro Raposo, Daniel L Rice, Rabie Saidi, Rafael Santos, Elena Speretta, James Stephenson, Prabhat Totoo, Edward Turner, Nidhi Tyagi, Preethi Vasudev, Kate Warner, Xavier Watkins, Rossana Zaru, Hermann Zellner, Alan J Bridge, Lucila Aimo, Ghislaine Argoud-Puy, Andrea H Auchincloss, Kristian B Axelsen, Parit Bansal, Delphine Baratin, Teresa M Batista Neto, Marie-Claude Blatter, Jerven T Bolleman, Emmanuel Boutet, Lionel Breuza, Blanca Cabrera Gil, Cristina Casals-Casas, Kamal Chikh Echioukh, Elisabeth Coudert, Beatrice Cuche, Edouard De Castro, Anne Estreicher, Maria L Famiglietti, Marc Feuermann, Elisabeth Gasteiger, Pascale Gaudet, Sebastien Gehant, Vivienne Gerritsen, Arnaud Gos, Nadine Gruaz, Chantal Hulo, Nevila Hyka-Nouspikel, Florence Jungo, Arnaud Kerhornou, Philippe Le Mercier, Damien Lieberherr, Patrick Masson, Anne Morgat, Venkatesh Muthukrishnan, Salvo Paesano, Ivo Pedruzzi, Sandrine Pilbout, Lucille Pourcel, Sylvain Poux, Monica Pozzato, Manuela Pruess, Nicole Redaschi, Catherine Rivoire, Christian J A Sigrist, Karin Sonesson, Shyamala Sundaram, Cathy H Wu, Cecilia N Arighi, Leslie Arminski, Chuming Chen, Yongxing Chen, Hongzhan Huang, Kati Laiho, Peter McGarvey, Darren A Natale, Karen Ross, C R Vinayaka, Qinghua Wang, Yuqi Wang, and Jian Zhang. UniProt: the Universal Protein Knowledgebase in 2023. Nucleic Acids Research, 51(D1):D523–D531, January 2023. ISSN 0305-1048, 1362-4962. doi: 10.1093/nar/gkac1052.\n\nMistry et al. [2021] Jaina Mistry, Sara Chuguransky, Lowri Williams, Matloob Qureshi, Gustavo A Salazar, Erik L L Sonnhammer, Silvio C E Tosatto, Lisanna Paladin, Shriya Raj, Lorna J Richardson, Robert D Finn, and Alex Bateman. Pfam: The protein families database in 2021. Nucleic Acids Research, 49(D1):D412–D419, January 2021. ISSN 0305-1048, 1362-4962. doi: 10.1093/nar/gkaa913.\n\nAbramson et al. [2024] Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, Lindsay Willmore, Andrew J. Ballard, Joshua Bambrick, Sebastian W. Bodenstein, David A. Evans, Chia-Chun Hung, Michael O’Neill, David Reiman, Kathryn Tunyasuvunakool, Zachary Wu, Akvilė Žemgulytė, Eirini Arvaniti, Charles Beattie, Ottavia Bertolli, Alex Bridgland, Alexey Cherepanov, Miles Congreve, Alexander I. Cowen-Rivers, Andrew Cowie, Michael Figurnov, Fabian B. Fuchs, Hannah Gladman, Rishub Jain, Yousuf A. Khan, Caroline M. R. Low, Kuba Perlin, Anna Potapenko, Pascal Savy, Sukhdeep Singh, Adrian Stecula, Ashok Thillaisundaram, Catherine Tong, Sergei Yakneen, Ellen D. Zhong, Michal Zielinski, Augustin Žídek, Victor Bapst, Pushmeet Kohli, Max Jaderberg, Demis Hassabis, and John M. Jumper. Accurate structure prediction of biomolecular interactions with AlphaFold 3. Nature, May 2024. ISSN 0028-0836, 1476-4687. doi: 10.1038/s41586-024-07487-w.\n\nVaradi et al. [2024] Mihaly Varadi, Damian Bertoni, Paulyna Magana, Urmila Paramval, Ivanna Pidruchna, Malarvizhi Radhakrishnan, Maxim Tsenkov, Sreenath Nair, Milot Mirdita, Jingi Yeo, Oleg Kovalevskiy, Kathryn Tunyasuvunakool, Agata Laydon, Augustin Žídek, Hamish Tomlinson, Dhavanthi Hariharan, Josh Abrahamson, Tim Green, John Jumper, Ewan Birney, Martin Steinegger, Demis Hassabis, and Sameer Velankar. AlphaFold Protein Structure Database in 2024: providing structure coverage for over 214 million protein sequences. Nucleic Acids Research, 52(D1):D368–D375, January 2024. ISSN 0305-1048, 1362-4962. doi: 10.1093/nar/gkad1011.\n\nChang et al. [2021] Antje Chang, Lisa Jeske, Sandra Ulbrich, Julia Hofmann, Julia Koblitz, Ida Schomburg, Meina Neumann-Schaal, Dieter Jahn, and Dietmar Schomburg. BRENDA, the ELIXIR core data resource in 2021: new developments and updates. Nucleic Acids Research, 49(D1):D498–D508, January 2021. ISSN 0305-1048, 1362-4962. doi: 10.1093/nar/gkaa1025.\n\nBansal et al. [2022] Parit Bansal, Anne Morgat, Kristian B Axelsen, Venkatesh Muthukrishnan, Elisabeth Coudert, Lucila Aimo, Nevila Hyka-Nouspikel, Elisabeth Gasteiger, Arnaud Kerhornou, Teresa Batista Neto, Monica Pozzato, Marie-Claude Blatter, Alex Ignatchenko, Nicole Redaschi, and Alan Bridge. Rhea, the reaction knowledgebase in 2022. Nucleic Acids Research, 50(D1):D693–D700, January 2022. ISSN 0305-1048, 1362-4962. doi: 10.1093/nar/gkab1016.\n\nKanehisa et al. [2023] Minoru Kanehisa, Miho Furumichi, Yoko Sato, Masayuki Kawashima, and Mari Ishiguro-Watanabe. Kegg for taxonomy-based analysis of pathways and genomes. Nucleic Acids Research, 51(D1):D587–D592, January 2023. ISSN 0305-1048. doi: 10.1093/nar/gkac963.\n\nProbst et al. [2022a] Daniel Probst, Matteo Manica, Yves Gaetan Nana Teukam, Alessandro Castrogiovanni, Federico Paratore, and Teodoro Laino. Biocatalysed synthesis planning using data-driven learning. Nature Communications, 13(1):964, February 2022a. ISSN 2041-1723. doi: 10.1038/s41467-022-28536-w.\n\nHeid et al. [2023] Esther Heid, Daniel Probst, William H. Green, and Georg K. H. Madsen. EnzymeMap: curation, validation and data-driven prediction of enzymatic reactions. Chemical Science, 14(48):14229–14242, 2023. ISSN 2041-6520, 2041-6539. doi: 10.1039/D3SC02048G.\n\nFinnigan et al. [2021] William Finnigan, Lorna J. Hepworth, Sabine L. Flitsch, and Nicholas J. Turner. RetroBioCat as a computer-aided synthesis planning tool for biocatalytic reactions and cascades. Nature Catalysis, 4(2):98–104, January 2021. ISSN 2520-1158. doi: 10.1038/s41929-020-00556-z.\n\nFinnigan et al. [2023] William Finnigan, Max Lubberink, Lorna J. Hepworth, Joan Citoler, Ashley P. Mattey, Grayson J. Ford, Jack Sangster, Sebastian C. Cosgrove, Bruna Zucoloto Da Costa, Rachel S. Heath, Thomas W. Thorpe, Yuqi Yu, Sabine L. Flitsch, and Nicholas J. Turner. RetroBioCat Database: A Platform for Collaborative Curation and Automated Meta-Analysis of Biocatalysis Data. ACS Catalysis, 13(17):11771–11780, September 2023. ISSN 2155-5435, 2155-5435. doi: 10.1021/acscatal.3c01418.\n\nCarbonell et al. [2018] Pablo Carbonell, Jerry Wong, Neil Swainston, Eriko Takano, Nicholas J Turner, Nigel S Scrutton, Douglas B Kell, Rainer Breitling, and Jean-Loup Faulon. Selenzyme: enzyme selection tool for pathway design. Bioinformatics, 34(12):2153–2154, June 2018. ISSN 1367-4803, 1367-4811. doi: 10.1093/bioinformatics/bty065.\n\nRao et al. [2019] Roshan Rao, Nicholas Bhattacharya, Neil Thomas, Yan Duan, Xi Chen, John Canny, Pieter Abbeel, and Yun S. Song. Evaluating Protein Transfer Learning with TAPE. June 2019.\n\nDallago et al. [2021] Christian Dallago, Jody Mou, Kadina E. Johnston, Bruce J. Wittmann, Nicholas Bhattacharya, Samuel Goldman, Ali Madani, and Kevin K. Yang. FLIP: Benchmark tasks in fitness landscape inference for proteins. Technical report, November 2021.\n\nNotin et al. [2023] Pascal Notin, Aaron W Kollasch, Daniel Ritter, Lood van Niekerk, Steffanie Paul, Hansen Spinner, Nathan Rollins, Ada Shaw, Ruben Weitzman, Jonathan Frazer, Mafalda Dias, Dinko Franceschi, Rose Orenbuch, Yarin Gal, and Debora S Marks. ProteinGym: Large-Scale Benchmarks for Protein Fitness Prediction and Design. 2023.\n\nMikhael et al. [2024a] Peter G Mikhael, Itamar Chinn, and Regina Barzilay. Graph-based forward synthesis prediction of biocatalyzed reactions. 2024a.\n\nSchwaller et al. [2019] Philippe Schwaller, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A. Hunter, Costas Bekas, and Alpha A. Lee. Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction. ACS Central Science, 5(9):1572–1583, September 2019. ISSN 2374-7943, 2374-7951. doi: 10.1021/acscentsci.9b00576.\n\nKreutter et al. [2021] David Kreutter, Philippe Schwaller, and Jean-Louis Reymond. Predicting enzymatic reactions with a molecular transformer. Chemical Science, 12(25):8648–8659, 2021. ISSN 2041-6520, 2041-6539. doi: 10.1039/D1SC02362D.\n\nRives et al. [2021] Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. Proceedings of the National Academy of Sciences, 118(15), April 2021. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.2016239118.\n\nLin et al. [2023] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, Maryam Fazel-Zarandi, Tom Sercu, Salvatore Candido, and Alexander Rives. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science, 379(6637):1123–1130, 2023. doi: https://doi.org/10.1126/science.ade2574.\n\nElnaggar et al. [2021] Ahmed Elnaggar, Michael Heinzinger, Christian Dallago, Ghalia Rehawi, Yu Wang, Llion Jones, Tom Gibbs, Tamas Feher, Christoph Angerer, Martin Steinegger, Debsindhu Bhowmik, and Burkhard Rost. ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Learning. 14(8):29, 2021.\n\nRobinson et al. [2023] Louis Callum Butler Robinson, Timothy Atkinson, Liviu Copoiu, Patrick Bordes, Thomas Pierrot, and Thomas Barrett. Contrasting Sequence with Structure: Pre-training Graph Representations with PLMs. preprint, Bioinformatics, December 2023.\n\nKhosla et al. [2021] Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, and Dilip Krishnan. Supervised Contrastive Learning, March 2021. arXiv:2004.11362 [cs, stat].\n\nZhang et al. [2024] Qiang Zhang, Keyang Ding, Tianwen Lyv, Xinda Wang, Qingyu Yin, Yiwen Zhang, Jing Yu, Yuhao Wang, Xiaotong Li, Zhuoyi Xiang, Xiang Zhuang, Zeyuan Wang, Ming Qin, Mengyao Zhang, Jinlu Zhang, Jiyu Cui, Renjun Xu, Hongyang Chen, Xiaohui Fan, Huabin Xing, and Huajun Chen. Scientific Large Language Models: A Survey on Biological & Chemical Domains, January 2024. arXiv:2401.14656 [cs].\n\nCarrami and Sharifzadeh [2024] Eli M. Carrami and Sahand Sharifzadeh. PQA: Zero-shot Protein Question Answering for Free-form Scientific Enquiry with Large Language Models, February 2024. arXiv:2402.13653 [cs].\n\nBran et al. [2023] Andres M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D. White, and Philippe Schwaller. ChemCrow: Augmenting large-language models with chemistry tools, October 2023. arXiv:2304.05376 [physics, stat].\n\nChen et al. [2020] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A Simple Framework for Contrastive Learning of Visual Representations. arXiv:2002.05709 [cs, stat], June 2020. arXiv: 2002.05709.\n\nLiu et al. [2023a] Shengchao Liu, Weitao Du, Zhiming Ma, Hongyu Guo, and Jian Tang. A Group Symmetric Stochastic Differential Equation Model for Molecule Multi-modal Pretraining. 2023a.\n\nLiu et al. [2023b] Shengchao Liu, Weili Nie, Chengpeng Wang, Jiarui Lu, Zhuoran Qiao, Ling Liu, Jian Tang, Chaowei Xiao, and Animashree Anandkumar. Multi-modal molecule structure–text model for text-based retrieval and editing. Nature Machine Intelligence, 5(12):1447–1457, December 2023b. ISSN 2522-5839. doi: 10.1038/s42256-023-00759-6.\n\nLiu et al. [2023c] Shengchao Liu, Yanjing Li, Zhuoxinran Li, Anthony Gitter, Yutao Zhu, Jiarui Lu, Zhao Xu, Weili Nie, Arvind Ramanathan, Chaowei Xiao, Jian Tang, Hongyu Guo, and Anima Anandkumar. A Text-guided Protein Design Framework, December 2023c. arXiv:2302.04611 [cs, q-bio, stat].\n\nWu et al. [2024] Kevin E Wu, Howard Chang, and James Zou. ProteinCLIP: enhancing protein language models with natural language. 2024.\n\nMikhael et al. [2024b] Peter G. Mikhael, Itamar Chinn, and Regina Barzilay. CLIPZyme: Reaction-Conditioned Virtual Screening of Enzymes, February 2024b. arXiv:2402.06748 [q-bio].\n\nSu et al. [2024] Jin Su, Xibin Zhou, Xuting Zhang, and Fajie Yuan. ProTrek: Navigating the Protein Universe through Tri-Modal Contrastive Learning. 2024.\n\nSingh et al. [2023] Rohit Singh, Samuel Sledzieski, Bryan Bryson, Lenore Cowen, and Bonnie Berger. Contrastive learning in protein language space predicts interactions between drugs and protein targets. Proceedings of the National Academy of Sciences, 120(24):e2220778120, June 2023. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.2220778120.\n\nAlamdari et al. [2023] Sarah Alamdari, Nitya Thakkar, Alex X Lu, Nicolo Fusi, Ava P Amini, and Kevin K Yang. Protein generation with evolutionary diffusion: sequence is all you need. 2023.\n\nMunsamy et al. [2024] Geraldene Munsamy, Ramiro Illanes-Vicioso, Silvia Funcillo, Sebastian Lindner, Gavin Ayres, Lesley S Sheehan, Steven Moss, Ulrich Eckhard, Philipp Lorenz, and Noelia Ferruz. Conditional language models enable the efficient design of proficient enzymes. 2024.\n\nMadani et al. [2023] Ali Madani, Ben Krause, Eric R. Greene, Subu Subramanian, Benjamin P. Mohr, James M. Holton, Jose Luis Olmos, Caiming Xiong, Zachary Z. Sun, Richard Socher, James S. Fraser, and Nikhil Naik. Large language models generate functional protein sequences across diverse families. Nature Biotechnology, January 2023. ISSN 1087-0156, 1546-1696. doi: 10.1038/s41587-022-01618-2.\n\nFerruz et al. [2022] Noelia Ferruz, Steffen Schmidt, and Birte Höcker. ProtGPT2 is a deep unsupervised language model for protein design. Nature Communications, 13(1):4348, July 2022. ISSN 2041-1723. doi: 10.1038/s41467-022-32007-7.\n\nProbst et al. [2022b] Daniel Probst, Philippe Schwaller, and Jean-Louis Reymond. Reaction classification and yield prediction using the differential reaction fingerprint DRFP. Digital Discovery, 1(2):91–97, 2022b. ISSN 2635-098X. doi: 10.1039/D1DD00006C.\n\nRichman et al. [2022] Tess Richman, Elyssa Arnold, and Antony J. Williams. Curation of a list of chemicals in biosolids from EPA National Sewage Sludge Surveys & Biennial Review Reports. Scientific Data, 9(1):180, April 2022. ISSN 2052-4463. doi: 10.1038/s41597-022-01267-9.\n\nSamusevich et al. [2024a] Raman Samusevich, Teo Hebra, Roman Bushuiev, Anton Bushuiev, Tereza Čalounová, Helena Smrčková, Ratthachat Chatpatanasiri, Jonáš Kulhánek, Milana Perković, Martin Engst, Adéla Tajovská, Josef Sivic, and Tomáš Pluskal. Highly accurate discovery of terpene synthases powered by machine learning reveals functional terpene cyclization in Archaea, January 2024a.\n\nSamusevich et al. [2024b] Raman Samusevich, Téo Hebra, Roman Bushuiev, Anton Bushuiev, Jonáš Kulhánek, Tereza Čalounová, Milana Perković, Adéla Tajovská, Josef Sivic, and Tomáš Pluskal. Discovery and Characterization of Terpene Synthases Powered by Machine Learning. 2024b.\n\nHirota et al. [2024] Keisuke Hirota, Felix Salim, and Takuji Yamada. DeepES: Deep learning-based enzyme screening to identify orphan enzyme genes. 2024.\n\nSchwaller et al. [2021] Philippe Schwaller, Daniel Probst, Alain C. Vaucher, Vishnu H. Nair, David Kreutter, Teodoro Laino, and Jean-Louis Reymond. Mapping the space of chemical reactions using attention-based neural networks. Nature Machine Intelligence, 3(2):144–152, January 2021. ISSN 2522-5839. doi: 10.1038/s42256-020-00284-w.\n\nDevlin et al. [2019] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:1810.04805 [cs], May 2019. arXiv: 1810.04805.\n\nAshburner et al. [2000] Michael Ashburner, Catherine A. Ball, Judith A. Blake, David Botstein, Heather Butler, J. Michael Cherry, Allan P. Davis, Kara Dolinski, Selina S. Dwight, Janan T. Eppig, Midori A. Harris, David P. Hill, Laurie Issel-Tarver, Andrew Kasarskis, Suzanna Lewis, John C. Matese, Joel E. Richardson, Martin Ringwald, Gerald M. Rubin, and Gavin Sherlock. Gene Ontology: tool for the unification of biology. Nature Genetics, 25(1):25–29, May 2000. ISSN 1061-4036, 1546-1718. doi: 10.1038/75556.\n\nBeltagy et al. [2019] Iz Beltagy, Kyle Lo, and Arman Cohan. SciBERT: A Pretrained Language Model for Scientific Text, September 2019. arXiv:1903.10676 [cs].\n\nSteinegger and Söding [2017] Martin Steinegger and Johannes Söding. MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets. Nature Biotechnology, 35(11):1026–1028, November 2017. ISSN 1546-1696. doi: 10.1038/nbt.3988. Number: 11 Publisher: Nature Publishing Group.\n\nLiu et al. [2022] Shengchao Liu, Hanchen Wang, Weiyang Liu, Joan Lasenby, Hongyu Guo, and Jian Tang. Pre-training molecular graph representation with 3d geometry. In International Conference on Learning Representations, 2022.\n\nAppendix A Appendix\n\nA.1 Dataset Processing\n\nOur data processing and splitting workflow is shown in Figure A.1. Protein sequence data, paired to EC number(s), were downloaded from UniProt, selecting only reviewed sequences in Swiss-Prot, resulting in a total of 571,282 sequences on the 13th of May 2024. These were filtered to only retain sequences with an EC number. After, sequences were filtered to length between 100 and 650, partial EC numbers (containing a dash) were removed, and duplicate entries (based on EC and sequence) were dropped, leaving 183,162 sequence-EC pairs. We call this the protein2EC dataset.\n\nReaction data were downloaded from ECReact and EnzymeMap. ECReact contains 62,222 entries of reaction in SMILES as SMARTS strings format coupled with EC number from a range of data sources. EnzymeMap had 349,458 entries containing sequence-reaction-EC triplets with the reaction in several formats, SMILES as SMARTS string, an atom-level mapping of bond formation and breaking (mapped reaction), and reactions written as text based on IUPAC compound names. Starting with EnzymeMap, protein sequence information was dropped, and duplicate reaction-EC pairs were removed leaving 62,896 reaction-EC pairs. EC numbers that existed in ECReact but not in Enzyme map were added to EnzymeMap providing our reaction dataset of 72,490 reaction-EC pairs. Note the ECReact only contains reactions formatted as SMILES/SMARTS. We call this the reaction2EC dataset.\n\nFinally, we filtered the protein2EC and reaction2EC datasets, such that only EC numbers present in both datasets are retained, leaving 59,122 reaction-EC pairs and 169,865 sequence-EC pairs, with 4,673 unique EC numbers. Clustering using MMseqs2 [71] was performed at 30%, 50%, 70%, and 90% sequence identity and included in the protein2EC dataset for downstream use. The distributions of the curated datasets are shown in Figure A.2.\n\nA.2 Dataset Splitting Details\n\nFirst, we sought to create test sets capturing different types of out-of-domain generalization for Task 1, EC classification (visualized in Figure A.3A).\n\nUsing the results from clustering, we generated four test sets, with approximately <30%, 30-50%, 50-70%, and 70-90% sequence identity, respectively, to sequences in the training set. We also only considered ECs at level 4 which had isolated clusters, in other words, an MMseqs2 cluster with only a single member. For every EC level 3 (X.X.X.-), we sampled a random EC at level 4 (X.X.X.X), and then randomly selected a single isolated sequence within that class to add to the test set. This provided balanced test datasets across the functions at EC level 3. For this set, we also enforced that the sequences did not map to multiple EC numbers. Test sets were balanced across functions (e.g. EC number), rather than across their prevalence as protein sequences in nature, based on the idea that most synthesis planners and enzyme engineers would find more value in predictive ability across a broad range of functions.\n\nNext, we looked for \"promiscuous\" enzymes, which in this work, we define as those annotated with multiple EC numbers. For our promiscuous test set, we only considered using promiscuous enzymes that had a combination of ECs that occurred at least twice. From this set we only took a single sample from each EC combination, and finally randomly selected a single entry from those which have ECs with high surprise levels (i.e. X.X.-.-, where variation occurs at the third EC level or higher).\n\nFinally, we compiled a commonly misclassified test set from Price et al., filtered to sequences of length 100-650, and dropped test sequences that are present in our protein2EC dataset. The pooled set of all proteins in the test sets were removed from our training data leaving 168,682 sequence-EC pairs for training. As a result of the holdout process, 3 of the 4,673 EC numbers are missing from the train set, which should minimally affect performance on the test sets.\n\nFor Task 2, we sought to test reaction extrapolation, namely, retrieval of enzymes based on unseen reactions (visualized in Figure A.3B). For the easy and medium test sets we randomly sampled an EC level 4 EC (X.X.X.X) from every level three EC (X.X.X.-). From each of the held-out level 4 ECs, a random reaction was sampled to be in the test set. For the test set, we only considered (1) reactions that do not map to multiple EC numbers, (2) EC numbers with at least two reactions, and (3) reactions from EnzymeMap, which are higher fidelity and consequently have fewer misannotatations.\n\nFor the easy set, only the test set reactions were held out. For the medium set, all reactions under the corresponding level 4 ECs were held out. Note that the easy and medium test sets are exactly the same, but the easy set has fewer held out reactions compared to the medium set, thus their training sets are different.\n\nThe hard set was evenly balanced across a random sample from EC level 2 (X.X.-.-) to ensure there was an even distribution across level 3 (EC3, X.X.X.-), from which 54 random EC3s are sampled, with all reactions under the 54 EC3s held out. 171 reactions associated with the 54 ECs were used as the test set, which are evenly spread across the ECs at level 3. Note we ensure the hard test reactions are shared with the easy and medium ones, when possible, to correlate the performance of our test splits. It should be noted that the hard train-test split is different from the easy and medium splits. For Task 2, all of the protein-EC pairs can be used during training.\n\nA.3 CREEP Model Details\n\nAll steps needed to reproduce CREEP training and downstream retrieval can be found at https://github.com/jsunn-y/CARE/.\n\nDuring the pretraining stage, we follow the contrastive learning paradigm that maximizes mutual information between two views [72]. For each enzyme family (EC number) 𝒙𝒙{\\bm{x}}bold_italic_x, we extract three views: protein sequence 𝒙psubscript𝒙𝑝{\\bm{x}}_{p}bold_italic_x start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT (protein), reactions smiles 𝒙rsubscript𝒙𝑟{\\bm{x}}_{r}bold_italic_x start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT (reaction), and textual description of EC number from gene ontology 𝒙tsubscript𝒙𝑡{\\bm{x}}_{t}bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT (text) [69]. In CREEP, the goal is to maximize the mutual information between all three modalities. For illustration purposes, we use the example of protein-reaction contrastive learning, but the derivations for reaction-text and text-protein contrastive learning follow a similar approach.\n\nWe follow the method proposed in GraphMVP by adopting EBM-NCE to estimate mutual information between our modalities [72]. In our case, EBM-NCE aligns the protein sequence and reaction SMILES pairs for the same enzyme family and contrasts the pairs for different enzyme families simultaneously. The objective function is\n\nℒEBM-NCE=subscriptℒEBM-NCEabsent\\displaystyle\\mathcal{L}_{\\text{EBM-NCE}}=caligraphic_L start_POSTSUBSCRIPT EBM-NCE end_POSTSUBSCRIPT = −12(𝔼𝐱p,𝐱r[logσ(E(𝐱p,𝐱r)]+𝔼𝐱p,𝐱r′[log(1−σ(E(𝐱p,𝐱r′))])\\displaystyle-\\frac{1}{2}\\Big{(}\\mathbb{E}_{{\\bm{x}}_{p},{\\bm{x}}_{r}}\\big{[}% \\log\\sigma(E({\\bm{x}}_{p},{\\bm{x}}_{r})\\big{]}+\\mathbb{E}_{{\\bm{x}}_{p},{\\bm{x% }}_{r}^{\\prime}}\\big{[}\\log(1-\\sigma(E({\\bm{x}}_{p},{\\bm{x}}_{r}^{\\prime}))% \\big{]}\\Big{)}- divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( blackboard_E start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ roman_log italic_σ ( roman_E ( bold_x start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT ) ] + blackboard_E start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ roman_log ( 1 - italic_σ ( roman_E ( bold_x start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ) ] ) (1) +𝔼𝐱p,𝐱r[logσ(E(𝐱p,𝐱r)]+𝔼𝐱p′,𝐱r[log(1−σ(E(𝐱p′,𝐱r))]),\\displaystyle\\;\\;\\;\\;\\;\\;+\\mathbb{E}_{{\\bm{x}}_{p},{\\bm{x}}_{r}}\\big{[}\\log% \\sigma(E({\\bm{x}}_{p},{\\bm{x}}_{r})\\big{]}+\\mathbb{E}_{{\\bm{x}}_{p}^{\\prime},{% \\bm{x}}_{r}}\\big{[}\\log(1-\\sigma(E({\\bm{x}}_{p}^{\\prime},{\\bm{x}}_{r}))\\big{]}% \\Big{)},+ blackboard_E start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ roman_log italic_σ ( roman_E ( bold_x start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT ) ] + blackboard_E start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , bold_x start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ roman_log ( 1 - italic_σ ( roman_E ( bold_x start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , bold_x start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT ) ) ] ) ,\n\nwhere 𝒙psubscript𝒙𝑝{\\bm{x}}_{p}bold_italic_x start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT and 𝒙rsubscript𝒙𝑟{\\bm{x}}_{r}bold_italic_x start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT form the (protein sequence, reaction SMILES) pair for each reaction, and 𝒙p′subscript𝒙superscript𝑝′{\\bm{x}}_{p^{\\prime}}bold_italic_x start_POSTSUBSCRIPT italic_p start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT and 𝒙r′subscript𝒙superscript𝑟′{\\bm{x}}_{r^{\\prime}}bold_italic_x start_POSTSUBSCRIPT italic_r start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT are the negative samples which are produced by randomly sampling from a Gaussian distribution, which we use as an approximation for the empirical data distribution. E⁢(⋅)𝐸⋅E(\\cdot)italic_E ( ⋅ ) is the energy function with a flexible formulation, and we use the dot product as a metric for similarity within the latent space.\n\nFor our default CREEP model, we project representations to 256 dimensions in the shared latent space for all modalities. We train for 40 epochs, and in each epoch, we loop over each EC number and mine each batch such that all protein-reaction-text triplets come from different EC numbers. Note that we also use 50% sequence clustering to help select protein sequences with increased diversity.\n\nDownstream retrieval using models such as CREEP and CLIPZyme is shown in Figure A.5. The standard workflow starts with a query reaction and ranks ECs by sorting based on distance from the reaction representation to the EC cluster centroids of protein sequence representations belonging to each EC number (Figure A.5A). For CREEP (w/ Text), a similar ranking can be determined by using text as a query (Figure A.5B), and the overall ranking can be calculated as an average of the two rankings. To reduce inference time, we used protein sequences clustered at 50% identity to calculate the protein representation centroids clustered by EC. Finally, the similarity baseline can be understood as sorting based on distance from a query reaction to reaction cluster centroids of reactions in the train set, clustered by EC (Figure A.5C).\n\nA.4 Implementation Details for Other Methods\n\nAll implementation details for methods used in the study can be found at https://github.com/jsunn-y/CARE/.\n\nChatGPT. ChatGPT was used for both Task 1 and Task 2, using the API and gpt-4 model. We performed minimal prompt engineering, with our initial prompt being the most standard initial question: \"give me the top N EC numbers associated with this amino acid sequence:\" for Task 1. See Table A.1 for example responses. The query was modified to: \"You are protein engineer capable of predicting EC numbers from the sequence alone. You are also a skilled programmer and able to execute the code necessary to predict an EC number when you can’t use reason alone. Given a protein sequence you are able to determine the most likely enzyme class for a sequence because you are that skilled. You don’t give up when faced with a sequence you don’t know, you will use tools to resolve the most likely enzyme sequence. You only return enzyme commission numbers in a comma separated list, no other text is returned, you have failed if you do not return the EC numbers. You only return the exact number of EC numbers that a user has provided requested, ordered by their likelihood.\" This resulted in a returned list of comma separated EC classification numbers in the majority of cases, however, we still received several failed responses.\n\nFor Task 2, the query was maintained to be relatively consistent with the Task 1 query, and modified to: \"Return the top 10 most likely EC numbers as a comma separated list for this reaction: naloxone + NAD(P)H = 6alpha-naloxol + NADP+, which associates with the following text: oxidoreductase; oxidoreductase, acting on CH-OH group of donors; oxidoreductase, acting on the CH-OH group of donors, NAD or NADP as acceptor; morphine 6-dehydrogenase.\", where a sample reaction has been bolded. Using the system prompt of: \"You are protein engineer capable of predicting EC numbers from a combination of textual information and a reaction that corresponds to a specific protein. You are also a skilled programmer and able to execute the code necessary to predict an EC number when you can’t use reason alone. Given a reaction and text information of an EC you are able to determine the most likely enzyme class for a reaction. You don’t give up when faced with a reaction you don’t know, you will use tools to resolve the most likely enzyme number. You only return enzyme commission numbers in a comma separated list, no other text is returned, you have failed if you do not return the EC numbers. You only return the exact number of EC numbers that a user has provided requested, ordered by their likelihood of being correct.\". For Task 2 without the reaction text, we used the same prompt as above except with the reaction text components removed.\n\nBLASTp. BLAST (Basic Alignment Search Tool) is an efficient algorithm for finding similar sequences in a reference database, to a query sequence [12]. We opted to use npyBlast at the protein sequence level which is a python implementation of BLASTp. For each test set, the training dataset was provided as the fasta file reference database, and the test set was provided as the query fasta. k=10𝑘10k=10italic_k = 10 hits were returned for each query, sorted based on similarity, using default parameters with a minimum required sequence similarity of 0.1. The EC number classification was then inferred from the returned sequence(s).\n\nProteInfer. ProteInfer is a classification model released in 2023 [21], and we used the pretrained version to test our datasets, which may inflate the reported accuracies. Variable numbers of ECs were returned for ProteInfer depending on the query. Future work should include re-training ProteInfer using the train-test splits proposed in CARE.\n\nCLEAN. CLEAN is a supervised contrastive model, which trains a classification head using embeddings from the ESM protein language model [42] by aligning embeddings from the same EC category and contrasting embeddings from different EC categories [18]. For Task 1, we retrained CLEAN using our training set, following the instructions provided in their codebase. We did not perform any clustering before training. Because our training set size was approximately similar in size, we used the recommended 7000 epochs of training. We used the default script with triplet margin loss. After, we performed inference but added our own code into the original CLEAN code to output the classification results into a format compatible with our downstream analysis.\n\nPika. Pika is a finetuned LLM, which accepts protein sequence as an auxiliary input and can perform reasoning and protein function prediction [48]. Pika did not have a publicly available pretrained model at the time of release, or example datasets for training, so this model was omitted from the current study. We expect to add it as a baseline in the future.\n\nCLIPZyme. CLIPZyme is a multimodal contrastive model, between reactions represented as 2D graphs and protein structures represented as 3D graphs [55]. CLIPZyme was trained on direct reaction-protein pairs from the EnzymeMap dataset [32]. In this study, we used the pretrained CLIPZyme model using default parameters and the EGNN protein structure representation for retrieval on Task 2. Future work will involve modifying the CLIPZyme code and retraining the model using the CARE train-test splits.\n\nChemCrow. ChemCrow is an LLM for chemistry problems, primarily synthesis planning [49]. It was unable to answer the results for Task 1, responding with the answers in Table A.1. For Task 2, we again tested a similar query to that input into ChatGPT, and received the responses in Table A.1. It should be noted, we use the public version so the private model may provide answers. Future work could involve building a biosynthesis-focused version of ChemCrow.\n\nA.5 Extended Benchmarking Results\n\nAdditional benchmarking results can be found at https://github.com/jsunn-y/CARE/.\n\nA.6 Limitations & Future Work\n\nOne limitation of our work is that classification and retrieval are performed at the coarse-grained level of EC numbers. Enzymes can often perform many reactions, meaning it is an acceptable assumption that enzymes belonging to the same EC number will share the capacity to perform similar reactions, even if they are not directly annotated for all reactions. However, the ultimate task in this domain is to perform direct reaction to protein sequence retrieval and vice-versa (as in CLIPZyme [55]). However, currently the data for validation is extremely limited. As experimentalists obtain higher resolution annotations of proteins and their associated reactions, this will become more realistic.\n\nIn the future, the proposed train-test splits could also be refined for both tasks. For the Task 1 splits, there is some leakage in the sequence identity, with some sequences in test sets lying outside of the enforced sequence identity ranges, likely due to the different sequence similarity algorithms used (MMseqs2 vs npysearch). MMseqs2 utilizes cascaded clustering which pre-filters based on initial clusters in the target set [71], while npysearch attempts to identify the closest sequence within the specified set based on similarity. Another limitation is that while there are no duplicate reactions present in both the train and test sets, some of the test reactions are very similar to reactions in the training set despite having different ECs. It would be beneficial to do a more detailed analysis of reaction similarities and explore other representations of reactions to understand which reactions can be considered equivalent. Over time, the train-test splits should be updated as additional functional annotations are acquired and compiled in databases. For example, while over 36 million sequences in BRENDA/Uniprot have EC numbers associated with them, these are mostly detected with homology, which means that they might not be the most accurate annotations.\n\nWe opted to assess performance using accuracy due to its simplicity and interpretability, but other retrieval and virtual screening metrics such as BEDROC and enrichment could also be explored. For the promiscuous enzymes with multiple EC numbers, we reported accuracy averaged across all of the true labels, for a fixed k=5 number of retrieved ECs, but other classification metrics such as precision and recall could be considered. The number of retrieved ECs could also be chosen using strategies like max separation and p-value as implemented in CLEAN [18].\n\nThe machine learning tools included in our study were selected for their reported recent outstanding performance for enzyme functional annotation and screening. We include the random baseline to give an understanding of what the expected random rate is and the two similarities (BLAST and DRFP) as baselines for simple non-ML methods. ChatGPT was included as the standard LLM baseline owing to its broad applicability across domains. However, it should be noted that this field is moving quickly, and there exist many other relevant tools that were not included here. For example, many state-of-the-art methods are not publicly available yet [7, 22], or just released at the time of writing [55]. Our benchmark was designed to be modular and we encourage the community to include other tools in the benchmark package.\n\nThere is also significant opportunity to use other modalities such as textual description and protein structure for more effective representations of enzymes and reactions. In the future, we will retrain models including CLIPZyme and ProteInfer directly on our train-test splits. We also plan to do a more detailed analysis of the representations learned by CREEP, in addition to an ablation study. The addition of textual description in CREEP potentially introduces indirect data leakage between the train and test sets (for example ChatGPT already has access to extensive resources) so future iterations of CARE will need to consider this. Future work should also consider how to include protein function prediction models that go beyond enzymes–or models that would like to use additional data/modalities [56]–into the CARE evaluation framework. There is also room to improve the prompt engineering of ChatGPT and ChemCrow which could be further explored to enhance the performance of these models.\n\nA.7 License\n\nThe codebase is open source under the MIT license."
    }
}