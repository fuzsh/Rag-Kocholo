{
    "id": "dbpedia_8304_1",
    "rank": 47,
    "data": {
        "url": "https://www.cs.jhu.edu/department-seminars/",
        "read_more_link": "",
        "language": "en",
        "title": "Department of Computer Science",
        "top_image": "https://www.cs.jhu.edu/wp-content/themes/wse/favicons/favicon-32x32.png",
        "meta_img": "https://www.cs.jhu.edu/wp-content/themes/wse/favicons/favicon-32x32.png",
        "images": [
            "https://www.facebook.com/tr?id=255832078289375&ev=PageView&noscript=1"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-05-24T13:47:53+00:00",
        "summary": "",
        "meta_description": "Details: WHERE: Hackerman B-17, unless otherwise noted WHEN: 10:30 a.m. refreshments available, seminar runs from 10:45 a.m. to 12 p.m., unless otherwise noted Recordings will be available online after each…",
        "meta_lang": "en",
        "meta_favicon": "https://www.cs.jhu.edu/wp-content/themes/wse/favicons/apple-touch-icon.png",
        "meta_site_name": "Department of Computer Science",
        "canonical_link": "https://www.cs.jhu.edu/department-seminars/",
        "text": "Zoom link >>\n\nComputer Science Seminar Series\n\n“Generative AI for (Molecular) Sciences”\n\nAbstract: Massive efforts are under way to develop and adapt generative AI to solve any and all inferential and design tasks across engineering and science disciplines. Framing or reframing problems in terms of distributional modeling can bring a number of benefits, but also comes with substantial technical and statistical challenges. Tommi S. Jaakkola’s work has focused on advancing machine learning methods for controlled generation of complex objects, ranging from molecular interactions (e.g., docking) and 3D structures to new materials tailored to exhibit desirable characteristics such as carbon capture. In this talk, Jaakkola will cover a few research vignettes along with their specific challenges, focusing on diffusion and flow models that surpass traditional or alternative approaches to docking, protein design, or conformational ensembles. Time permitting, he will highlight general challenges and opportunities in this area.\n\nSpeaker Biography: Tommi S. Jaakkola is the Thomas Siebel Professor of Electrical Engineering and Computer Science in the Massachusetts Institute of Technology’s Department of Electrical Engineering and Computer Science and the MIT Institute for Data, Systems, and Society; he is also an investigator at the MIT Computer Science and Artificial Intelligence Laboratory. He is a fellow of the Association for the Advancement of Artificial Intelligence with many awards for his publications. His research covers how machines can learn, generate, or control and do so at scale in an efficient, principled, and interpretable manner, from foundational theory to modern design challenges. Over the past several years, Jaakkola’s applied work has been focused on molecular modeling and design.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nApril 25, 2024\n\nAbstract: We have begun grappling with difficult questions related to the rise of AI, including: What rights do individuals have in the age of AI? When should we regulate AI and when should we abstain? What degree of transparency is needed to monitor AI systems? These questions are all concerned with AI accountability. In this talk, Sarah Cen discusses the two components of her research on AI accountability and illustrates them through a case study on auditing social media. Within the context of social media, she will focus on how social media platforms filter (or curate) the content that users see. In particular, Cen will propose a way to implement regulations on social media that is compatible with free speech protections and Section 230. She will then present a way to test whether a content curation algorithm complies with regulations, producing what we call a “counterfactual audit.” In studying the properties of this approach, she will show that it has strong theoretical guarantees, does not violate user privacy, and uses only black-box access to the algorithm (thereby requiring minimal access to proprietary algorithms and data). She will demonstrate how this audit can be applied in practice using LLMs on a live social media platform.\n\nSpeaker Biography: Sarah Cen is a final-year PhD student in the Massachusetts Institute of Technology’s Department of Electrical Engineering and Computer Science, where she is advised by Professors Aleksander Mądry and Devavrat Shah. Cen utilizes methods from machine learning, statistical inference, causal inference, and game theory to study responsible computing and AI policy. Previously, she has written about social media, trustworthy algorithms, algorithmic fairness, and more. She is currently interested in AI auditing, AI supply chains, and the intellectual property rights of data providers.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nApril 12, 2024\n\nAbstract: Humans have an innate ability to construct detailed mental representations of the world from limited sensory data. These “world models” are central to natural intelligence, allowing us to perceive, reason about, and act in the physical world. Krishna Murthy’s research seeks to create “computational world models”—artificial intelligence techniques that enable robots to understand and operate in the world around as effectively as humans. Despite the impressive successes of modern machine learning approaches in media such as text, images, and video—where abundant training data is readily available—these advancements have not translated to robotics. Building generally capable robotic systems presents unique challenges, including this lack of data and the need to adapt learning algorithms to a wide variety of embodiments, environments, and tasks of interest. In his talk, Murthy will present how his research contributes to the design of computational models for spatial, physical, and multimodal understanding. He will discuss differentiable computing approaches that have advanced the field of spatial perception, enabling an understanding of the structure of the 3D world, its constituent objects, and their semantic and physical properties from videos. He will also detail how his work interfaces advances in large image, language, and audio models with 3D scenes, enabling robots and computer vision systems to flexibly query these structured world models for a wide range of tasks. Finally, he will outline his vision for the future, where structured world models and modern scaling-based approaches work in tandem to create versatile robot perception and planning algorithms with the potential to meet and ultimately surpass human-level capabilities.\n\nSpeaker Biography: Krishna Murthy is a postdoctoral researcher at the Massachusetts Institute of Technology working with Antonio Torralba and Josh Tenenbaum. He previously completed his PhD at Mila and the University of Montreal, where he was advised by Liam Paull. Murthy’s research focuses on building computational world models to help embodied agents perceive, reason about, and act in the physical world. He has led the organization of multiple workshops on themes spanning differentiable programming, physical reasoning, 3D vision and graphics, and ML research dissemination. His research has been recognized with graduate fellowship awards from NVIDIA and Google (2021); a Best Paper Award from the Institute of Electrical and Electronics Engineers’ Robotics and Automation Letters (2019); and an induction to the Robotics: Science and Systems Pioneers cohort (2020).\n\nView the recording >>\n\nComputer Science Seminar Series\n\nApril 11, 2024\n\nAbstract: In the last few decades, most robotics success stories have been limited to structured or controlled environments. A major challenge is to develop robot systems that can operate in complex or unstructured environments corresponding to homes, dense traffic, outdoor terrains, public places, etc. In this talk, Dinesh Manocha gives an overview of his ongoing work on developing robust planning and navigation technologies that use recent advances in computer vision, sensor technologies, machine learning, and motion planning algorithms. He presents new methods that utilize multimodal observations from an RGB camera, 3D LiDAR, and robot odometry for scene perception, along with deep reinforcement learning for reliable planning; the latter is also used to compute dynamically feasible and spatially aware velocities for a robot navigating among mobile obstacles and uneven terrains. These methods have been integrated with wheeled robots, home robots, and legged platforms and their performance has been highlighted in crowded indoor scenes, home environments, and dense outdoor terrains.\n\nSpeaker Biography: Dinesh Manocha is the Paul Chrisman Iribe Professor of Computer Science and Electrical and Computer Engineering and a Distinguished University Professor at the University of Maryland, College Park. His research interests include virtual environments, physically based modeling, and robotics. His group has developed a number of software packages that are standard and licensed to 60+ commercial vendors. He has published more than 750 papers and supervised 50 PhD dissertations. He is a fellow of the Association for the Advancement of Artificial Intelligence, the American Association for the Advancement of Science, the ACM, the Institute of Electrical and Electronics Engineers (IEEE), and the National Academy of Inventors. He is also a member of the ACM’s Special Interest Group on Computer Graphics and Interactive Techniques and the IEEE Visualization and Graphics Technical Community’s Virtual Reality Academy. Manocha is the recipient of a Pierre Bézier Award from the Solid Modeling Association, a Distinguished Alumni Award from the Indian Institute of Technology Delhi, and a Distinguished Career Award in Computer Science from the Washington Academy of Sciences. He was also a co-founder of Impulsonic, a developer of physics-based audio simulation technologies that was acquired by Valve Corporation in November of 2016.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nApril 8, 2024\n\nAbstract: Recent years have seen unprecedented advancements in the development of machine learning and artificial intelligence. For the applied sciences, these tools offer new paradigms for combining insights developed from theory, computation, and experiments towards design and discovery, and for bridging the microscopic world with the macroscopic. Beyond treating them as black boxes, however, uncovering and distilling the fundamental principles behind how systems built with neural networks work is a grand challenge, and one that can be aided by ideas, tools, and methodologies from physics. Yasaman Bahri will describe one pillar of her research that takes a first-principles approach to deep learning through the lens of statistical physics, exactly solvable models and mean-field theories, and nonlinear dynamics. She will discuss new connections she discovered between large-width deep neural networks, Gaussian processes, and kernels; the emergence of linear models during training and phase transitions away from them; experimentally-consistent insights into scaling laws; and an outlook on the next frontiers in this research program. She will then discuss the early stages of a second research program proceeding in the reverse direction, in which a deeper understanding of ML and AI can be used to advance the quantum sciences and quantum materials. As an early example, Bahri considers physics as a domain to examine recall and reasoning in large language models. She will describe work investigating the ability of such models to perform analytic Hartree-Fock mean-field calculations in quantum many-body physics.\n\nSpeaker Biography: Yasaman Bahri is a research scientist at Google DeepMind. Her research lies at the confluence of machine learning and the physical sciences. She completed her PhD in physics at the University of California, Berkeley as an NSF Graduate Fellow, specializing in the theory of quantum condensed matter. Her doctoral work investigated quantum matter through the themes of topology, symmetry, and localization. She has been an invited lecturer at the Les Houches School of Physics, is a past Rising Star in Electrical Engineering and Computer Science, and was a co-organizer of a recent program on deep learning at the Kavli Institute for Theoretical Physics.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nApril 5, 2024\n\nAbstract: History repeats itself—sometimes in a bad way. Preventing natural or man-made disasters requires being aware of these patterns and taking preemptive action to address and reduce them—or ideally, eliminate them. Emerging events, such as the COVID pandemic and the Ukraine crisis, require a time-sensitive, comprehensive understanding of the situation to allow for appropriate decision-making and effective action response. Automated generation of situation reports can significantly reduce the time, effort, and cost for domain experts when preparing their official, human-curated reports. However, AI research toward this goal has been very limited and no successful trials have yet been conducted to automate such report generation and “what-if” disaster forecasting. Preexisting natural language processing and information retrieval techniques are insufficient to identify, locate, and summarize important information and lack detailed, structured, and strategic awareness. In this talk, Heng Ji will present SmartBook, a novel framework that cannot be solved by large language models alone to consume large volumes of multimodal multilingual news data and produce a structured situation report with multiple hypotheses (claims) summarized and grounded with rich links to factual evidence through multimodal knowledge extraction, claim detection, fact checking, misinformation detection, and factual error correction. Furthermore, SmartBook can also serve as a novel news event simulator or an intelligent prophetess. Given “what-if” conditions and dimensions elicited from a domain expert user concerning a disaster scenario, SmartBook will induce schemas from historical events and automatically generate a complex event graph along with a timeline of news articles that describe new simulated events and character-centric stories based on a new Λ-shaped attention mask that can generate text with infinite length. By effectively simulating disaster scenarios in both event graph and natural language formats, SmartBook is expected to greatly assist humanitarian workers and policymakers to exercise reality checks and thus better prevent and respond to future disasters.\n\nSpeaker Biography: Heng Ji is a professor of computer science at the University of Illinois Urbana-Champaign, where she is an affiliated faculty member of the Electrical and Computer Engineering Department and the Coordinated Science Laboratory. She is an Amazon Scholar and is the founding director of the Amazon-Illinois Center on AI for Interactive Conversational Experiences. Ji received her BA and MA in computational linguistics from Tsinghua University and her MS and PhD in computer science from New York University. Her research interests focus on natural language processing—especially on multimedia multilingual information extraction, knowledge-enhanced large language Models, knowledge-driven generation, and conversational AI. Ji was selected as a Young Scientist to attend the 6th World Laureates Forum and was selected to participate in DARPA’s 2023 AI Forward initiative. She was selected as a Young Scientist and a member of the Global Future Council on the Future of Computing by the World Economic Forum in 2016 and 2017. Other awards she has received include being named a Women Leader of Conversational AI (Class of 2023) by Project Voice; an “AI’s 10 to Watch” Award by IEEE Intelligent Systems in 2013; an NSF CAREER Award in 2009; Best Paper Runner-Up at the 26th Pacific Asia Conference on Language, Information, and Computation; a Best Paper Award at the 2013 Institute of Electrical and Electronics Engineers’ (IEEE) International Conference on Data Mining; a Best Paper Award at the 2013 Society for Industrial and Applied Mathematics’ International Conference on Data Mining; a nomination for Best Demo Paper at the 2018 Annual Meeting of the Association for Computational Linguistics (ACL); a Best Demo Paper Award at ACL 2020; a Best Demo Paper Award at the 2021 Annual Conference of the North American Chapter of the ACL (NAACL); Google Research Awards in 2009 and 2014; an IBM Faculty Award in 2012 and 2014; and Bosch Research Awards in 2014 through 2018. Ji was invited to testify to the United States House of Representatives Cybersecurity, Information Technology, and Government Innovation Subcommittee as an AI expert in 2023; she was also invited by the Secretary of the U.S. Air Force and the Air Force Research Laboratory (AFRL) to join the Department of the Air Force Data, Analytics, and AI Forum to inform Air Force Strategy in 2030 and was invited to speak at the federal Information Integrity R&D Interagency Working Group briefing in 2023. She is the lead of many multi-institution projects and tasks, including United States Army Research Laboratory (ARL) projects on information fusion and knowledge networks construction, the DARPA Environment-Driven Conceptual Learning program’s Multimodal InteRActive Conceptual Learning team, the DARPA Knowledge-directed Artificial Intelligence Reasoning Over Schemas program’s Reasoning about Event Schemas for Induction of kNowledge team, and the DARPA Deep Exploration and Filtering of Text’s Tinker Bell team. Ji coordinated the National Institute of Standards and Technology Text Analysis Conference Knowledge Base Population task from 2010 to 2022. She was the associate editor for the IEEE/ACM Transactions on Audio, Speech, and Language Processing and has served as program committee co-chair of many conferences, including the 2018 Conference of the NAACLL Human Language Technologies and 2022 Conference of the Asia-Pacific Chapter of the ACL and the International Joint Conference on Natural Language Processing. Ji was elected as the secretary of the NAACL from 2020 to 2023. Her research has been widely supported by U.S. government agencies (e.g., DARPA, NSF, the Department of Energy, ARL, the Intelligence Advanced Research Projects Activity, AFRL, the Department of Homeland Security) and industry partners (e.g., Apple, Amazon, Google, Meta, Bosch, IBM, Disney).\n\nView the recording >>\n\nComputer Science Seminar Series\n\nApril 4, 2024\n\nAbstract: As predictive and generative models are increasingly being deployed in various high-stakes applications in critical domains including health care, law, policy, and finance, it is important to ensure that relevant stakeholders understand the behaviors and outputs of these models so that they can determine if and when to intervene. To this end, several techniques have been proposed in recent literature to explain these models; in addition, multiple regulatory frameworks (e.g., the General Data Protection Regulation, the California Consumer Privacy Act) introduced in recent years also emphasize the importance of enforcing the key principle of “right to explanation” to ensure that individuals who are adversely impacted by algorithmic outcomes are provided with an actionable explanation. In this talk, Himabindu Lakkaraju will discuss the gaps that exist between regulations and state-of-the-art technical solutions when it comes to explainability of predictive and generative models. She will then present some of her latest research that attempts to address some of these gaps. She will conclude her talk by discussing bigger challenges that arise as we think about enforcing right to explanation in the context of large language models and other large generative models.\n\nSpeaker Biography: Himabindu “Hima” Lakkaraju is an assistant professor at Harvard University focusing on the algorithmic, theoretical, and applied aspects of explainability, fairness, and robustness of machine learning models. Lakkaraju has been named as one of the world’s top innovators under 35 by both MIT Tech Review and Vanity Fair. She has also received several prestigious awards, including an NSF CAREER Award, an AI2050 Early Career Fellowship by Schmidt Futures, and multiple Best Paper Awards at top-tier ML conferences; she has also received grants from the NSF, Google, Amazon, J.P. Morgan, and Bayer. Lakkaraju has given keynote talks at various top ML conferences and associated workshops, including the Conference on Information and Knowledge Management, the International Conference on Machine Learning, the Conference and Workshop on Neural Information Processing Systems, the International Conference on Learning Representations, the Association for the Advancement of Artificial Intelligence, and the Conference on Computer Vision and Pattern Recognition; her research has also been showcased by popular media outlets including The New York Times, MIT Tech Review, TIME, and Forbes. More recently, she co-founded the Trustworthy ML Initiative to enable easy access to resources on trustworthy ML and to build a community of researchers and practitioners working on the topic.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nApril 3, 2024\n\nAbstract: Data-driven machine learning methods are making advances in many long-standing problems in robotics, including grasping, legged locomotion, perception, and more. There are, however, robotics applications for which data-driven methods are less effective. Data acquisition can be expensive, time consuming, or dangerous—to the surrounding workspace, humans in the workspace, or the robot itself. In such cases, generating data via simulation might seem a natural recourse, but simulation methods come with their own limitations, particularly when nondeterministic effects are significant or when complex dynamics are at play, requiring heavy computation and exposing the so-called sim2real gap. Another alternative is to rely on a set of demonstrations, limiting the amount of required data by careful curation of the training examples; however, these methods fail when confronted with problems that were not represented in the training examples (so-called out-of-distribution problems) and this precludes the possibility of providing provable performance guarantees. In this talk, Seth Hutchinson will describe recent work on robotics problems that do not readily admit data-driven solutions, including flapping flight by a bat-like robot, vision-based control of soft continuum robots, a cable-driven graffiti-painting robot, and ensuring safe operation of mobile manipulators in human-robot interaction scenarios. He will describe some specific difficulties that confront data-driven methods for these problems and how model-based approaches can provide workable solutions. Along the way, he will also discuss how judicious incorporation of data-driven machine learning tools can enhance performance of these methods.\n\nSpeaker Biography: Seth Hutchinson is the executive director of the Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology, where he is also a professor and the KUKA Chair for Robotics in the School of Interactive Computing. Hutchinson received his PhD from Purdue University in 1988, and in 1990 he joined the University of Illinois in Urbana-Champaign, where he was a professor of electrical and computer engineering (ECE) until 2017 and served as the associate department head for ECE from 2001 to 2007. A fellow of the Institute of Electrical and Electronics Engineers (IEEE), Hutchinson served as the president of the IEEE Robotics and Automation Society (RAS) from 2020 to 2021 and has previously served as a member of the RAS Administrative Committee, as the editor-in-chief for IEEE Transactions on Robotics, and as the founding editor-in-chief of the RAS Conference Editorial Board. He has served on the organizing committees for more than 100 conferences, has more than 300 publications on the topics of robotics and computer vision, and is co-author of the books Robot Modeling and Control (Wiley), Principles of Robot Motion: Theory, Algorithms, and Implementations (MIT Press), and the forthcoming Introduction to Robotics and Perception (Cambridge University Press).\n\nView the recording >>\n\nComputer Science Seminar Series\n\nMarch 28, 2024\n\nAbstract: The ever-increasing scale of foundation models, such as ChatGPT and AlphaFold, has revolutionized AI and science more generally. However, increasing scale also steadily raises computational barriers, blocking almost everyone from studying, adapting, or otherwise using these models for anything beyond static API queries. In this talk, Tim Dettmers will present research that significantly lowers these barriers for a wide range of use cases, including inference algorithms that are used to make predictions after training, fine-tuning approaches that adapt a trained model to new data, and finally, full training of foundation models from scratch. For inference, he will describe the LLM.int8() algorithm, which showed how to enable high-precision 8-bit matrix multiplication that is both fast and memory efficient. LLM.int8() is based on the discovery and characterization of sparse outlier sub-networks that only emerge at large model scales, but are crucial for effective Int8 quantization. For fine-tuning, he will introduce the QLoRA algorithm, which pushes such quantization much further to unlock fine-tuning of very large models on a single GPU by only updating a small set of the parameters while keeping most of the network in a new information-theoretically optimal 4-bit representation. For full training, he will present SWARM parallelism, which allows collaborative training of foundation models across continents on standard internet infrastructure while still being 80% as effective as the prohibitively expensive supercomputers that are currently used. Finally, he will close by outlining his plans to make foundation models 100x more accessible, which will be needed to maintain truly open AI-based scientific innovation as models continue to scale.\n\nSpeaker Biography: Tim Dettmers’ research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements. This involves developing novel compression and networking algorithms and building systems that allow for memory-efficient, fast, and cheap deep learning. These methods enable many more people to use, adapt, or train foundation models without affecting the quality of AI predictions or generations. Dettmers is a PhD candidate at the University of Washington and has won oral, spotlight, and best paper awards at conferences such as the International Conference on Learning Representations and the Conference and Workshop on Neural Information Processing Systems. He created the bitsandbytes library for efficient deep learning, which is growing at 1.4 million installations per month, and has received Google Open Source and PyTorch Foundation awards.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nMarch 21, 2024\n\nAbstract: Data is today generated on smart devices at the edge, shaping a decentralized data ecosystem comprised of multiple data owners (clients) and a service provider (server). Clients interact with the server with their personal data for specific services, while the server performs analysis on the joint dataset. However, the sensitive nature of the data involved, coupled with the inherent misalignment of incentives between clients and the server, breeds mutual distrust. Consequently, a key question arises: How can we facilitate private data analytics within a decentralized data ecosystem comprised of multiple distrusting parties? Amrita Roy Chowdhury’s research shows a way forward by designing systems that offer strong and provable privacy guarantees while preserving complete data functionality. She accomplishes this by systematically exploring the synergy between cryptography and differential privacy, exposing their rich interconnections in both theory and practice. In this talk, she will focus on two systems, CryptE and EIFFeL, which enable privacy-preserving query analytics and machine learning, respectively.\n\nSpeaker Biography: Amrita Roy Chowdhury is a Computing Research Association and Computing Community Consortium Computing Innovation Fellow working with Kamalika Chaudhuri at the University of California San Diego. She graduated with her PhD from University of Wisconsin—Madison, where she was advised by Somesh Jha. Chowdhury completed her BE in computer science from the Indian Institute of Engineering Science and Technology, Shibpur, where she was awarded the President of India Gold Medal. Her work explores the synergy between differential privacy and cryptography through novel algorithms that expose the rich interconnections between the two areas, both in theory and practice. Chowdhury has been recognized as a Rising Star in Electrical Engineering and Computer Science in 2020 and 2021. She was also both a Facebook Fellowship finalist and selected as a Rising Star in Data Science by the University of Chicago in 2021.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nMarch 20, 2024\n\nAbstract: Decision-making in robotics domains is complicated by continuous state and action spaces, long horizons, and sparse feedback. One way to address these challenges is to perform bilevel planning, where decision-making is decomposed into reasoning about “what to do” (task planning) and “how to do it” (continuous optimization). Bilevel planning is powerful, but it requires multiple types of domain-specific abstractions that are often difficult to design by hand. In this talk, Tom Silver will give an overview of his work on learning these abstractions from data; this work represents the first unified system for learning all the abstractions needed for bilevel planning. In addition to learning to plan, he will also discuss planning to learn, where the robot uses planning to collect additional data that it can use to improve its abstractions. His long-term goal is to create a virtuous cycle where learning improves planning and planning improves learning, leading to a very general library of abstractions and a broadly competent robot.\n\nSpeaker Biography: Tom Silver is a final-year PhD student at the Massachusetts Institute of Technology’s Department of Electrical Engineering and Computer Science, advised by Leslie Kaelbling and Josh Tenenbaum. His research is at the intersection of machine learning and planning with applications to robotics and often uses techniques from task and motion planning, program synthesis, and neuro-symbolic learning. Before graduate school, he was a researcher at Vicarious AI and received his BA with highest honors in computer science and mathematics from Harvard in 2016. Silver has also interned at Google Research (in brain robotics) and currently splits his time between MIT and the Boston Dynamics AI Institute. His work is supported by an NSF Fellowship and an MIT Presidential Fellowship.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nMarch 19, 2024\n\nAbstract: Decentralized systems enable mutually distrusting parties to collaboratively control a system; this fosters trust as no single corrupted party can break the system, while utility is ensured through collective participation. In recent years, decentralized systems have found many applications, particularly within the blockchain ecosystem. Traditionally, the robustness and security of a decentralized system increase with the number of participating parties. Consequently, the primary objective of decentralization is to scale the system to accommodate as many parties as possible. However, the existing framework for realizing threshold cryptography, the core cryptographic primitive enabling decentralization, still relies on interactive setup processes, posing significant scalability challenges in real-world scenarios. Additionally, it lacks the flexibility to handle advanced features such as weights, dynamism, and multiverse, which are highly desired in practice. In this talk, Mingyuan Wang will discuss his research work that proposes new techniques to address these issues, which pave the way for truly scalable decentralized cryptographic systems. He will conclude the talk by briefly discussing other research problems that he is interested in.\n\nSpeaker Biography: Mingyuan Wang is a postdoctoral researcher at the University of California, Berkeley, hosted by Sanjam Garg. He received his PhD from Purdue University, where he was advised by Hemanta K. Maji. Wang is interested in cryptography and its interplay with theoretical computer science and security. His research covers a wide range of topics, including threshold cryptography, secure multiparty computation, leakage-resilient cryptography, and cryptographic applications in machine learning. His work has been published at top venues, such as Crypto, Eurocrypt, the IEEE Symposium on Security and Privacy, the ACM Conference on Computer and Communications Security, the Conference on Neural Information Processing Systems, the Theory of Cryptography Conference, the IEEE International Symposium on Information Theory, and more.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nMarch 15, 2024\n\nAbstract: Natural language provides an intuitive and powerful interface to access knowledge at scale. Modern language systems draw information from two rich knowledge sources: (1) information stored in their parameters during massive pretraining and (2) documents retrieved at inference time. Yet we are far from building systems that can reliably provide information from such knowledge sources. In this talk, Eunsol Choi will discuss paths for more robust systems. In the first part of her talk, she will present a module for scaling retrieval-based knowledge augmentation, learning a compressor that maps retrieved documents into textual summaries prior to in-context integration; this not only reduces the computational costs but also filters irrelevant or incorrect information. In the second half of her talk, she will discuss the challenges of updating knowledge stored in model parameters and propose a method to prevent models from reciting outdated information by identifying facts that are prone to rapid change. She will conclude her talk by proposing an interactive system that can elicit information from users when needed.\n\nSpeaker Biography: Eunsol Choi is an assistant professor of computer science at the University of Texas (UT) at Austin. Prior to teaching at UT, she spent a year at Google AI as a visiting researcher. Choi’s research area spans natural language processing and machine learning; she is particularly interested in interpreting and reasoning about text in a dynamic, real-world context. She is a recipient of a Meta Research PhD Fellowship, a Google Faculty Research Award, a Sony Research Award, and an Outstanding Paper Award at the Conference on Empirical Methods in Natural Language Processing. She received a PhD in computer science and engineering from the University of Washington and a BA in mathematics and computer science from Cornell University.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nMarch 12, 2024\n\nAbstract: Building multisensory AI systems that learn from multiple sensory inputs—such as text, speech, video, real-world sensors, wearable devices, and medical data—holds great promise for many scientific areas in terms of practical benefits, such as supporting human health and well-being, enabling multimedia content processing, and enhancing real-world autonomous agents. In this talk, Paul Liang will discuss his research on the machine learning principles of multisensory intelligence, as well as practical methods for building multisensory foundation models over many modalities and tasks. In the first half of the seminar, Liang will present a theoretical framework formalizing how modalities interact with each other to give rise to new information for a task. These interactions are the basic building blocks in all multimodal problems and their quantification enables users to understand multimodal datasets and design principled approaches to learn these interactions. In the second half of the seminar, Liang will present his work in cross-modal attention and the multimodal transformer architectures that now underpin many of today’s multimodal foundation models. Finally, he will discuss his collaborative efforts in scaling AI to many modalities and tasks for real-world impact on affective computing, mental health, and cancer prognosis.\n\nSpeaker Biography: Paul Liang is a PhD student in machine learning at Carnegie Mellon University, advised by Louis-Philippe Morency and Ruslan Salakhutdinov. He studies the machine learning foundations of multisensory intelligence to design practical AI systems that integrate, learn from, and interact with a diverse range of real-world sensory modalities. His work has been applied in affective computing, mental health, pathology, and robotics. He is a recipient of the Siebel Scholars Award, the Waibel Presidential Fellowship, a Meta Research PhD Fellowship, the Center for Machine Learning and Health Fellowship and was named a Rising Star in data science. He has additionally received three Best Paper or Honorable Mention Awards at International Conference on Multimodal Interaction and Conference on Neural Information Processing Systems workshops. Outside of research, Liang received the Alan J. Perlis Graduate Student Teaching Award for instructing courses on multimodal machine learning and advising students around the world in directed research.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nMarch 7, 2024\n\nAbstract: Efficiency is increasingly tied to quality in machine learning, with more efficient training algorithms leading to more powerful models. However, today’s most popular machine learning models are built on asymptotically inefficient primitives. For example, attention in transformers scales quadratically with input size, while multilayer perceptrons scale quadratically with model dimension. In this talk, Dan Fu discusses his work on improving the efficiency of core primitives in machine learning, with an emphasis on hardware-aware algorithms and long-context applications. First, he focuses on replacing attention with gated state space models (SSMs) and convolutions, which scale sub-quadratically in context length. He describes the H3 (Hungry Hungry Hippos) architecture, a gated SSM architecture that matches transformers in quality up to 3B parameters and achieves 2.4x faster inference. Second, he focuses on developing hardware-aware algorithms for SSMs and convolutions; he describes FlashFFTConv, a fast algorithm for computing SSMs and convolutions on GPU by optimizing the fast Fourier transform (FFT). FlashFFTConv yields up to 7x speedup and 5x memory savings, even over vendor solutions from NVIDIA. Third, he will briefly touch on how these same techniques can also be used to develop sub-quadratic scaling in the model dimension. He will describe Monarch Mixer, which uses a generalization of the FFT to achieve sub-quadratic scaling in both sequence length and model dimension. Throughout the talk, he will give examples of how these ideas are beginning to take hold, with gated SSMs and their variants now leading to state-of-the-art performance in long-context language models, embedding models, and DNA foundation models.\n\nSpeaker Biography: Dan Fu is a PhD student in the Computer Science Department at Stanford University, where he is co-advised by Christopher Ré and Kayvon Fatahalian. His research interests are at the intersection of systems and machine learning. Recently, Fu has focused on developing algorithms and architectures to make machine learning more efficient, especially for enabling longer-context applications. His research has appeared as oral and spotlight presentations at the Conference on Neural Information Processing Systems, the International Conference on Machine Learning, and the International Conference on Learning Representations; he additionally received the Best Student Paper Runner-Up Award at the Conference on Uncertainty in Artificial Intelligence and has been supported by a National Defense Science and Engineering Graduate Fellowship.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nMarch 1, 2024\n\nAbstract: Recent advances in large language models have enabled them to process texts exceeding 100,000 tokens in length, fueling demand for long-form language processing tasks such as the summarization or translation of books. However, LLMs struggle to take full advantage of the information within such long contexts, which contributes to factually incorrect and incoherent text generation. In this talk, Mohit Iyyer will first demonstrate an issue that plagues even modern LLMs: their tendency to assign high probability to implausible long-form continuations of their input. He will then describe a contrastive sequence-level ranking model that mitigates this problem at decoding time and that can also be adapted to the reinforcement learning from human feedback alignment paradigm. Next, he will consider the growing problem of long-form evaluation: As the length of the inputs and outputs of long-form tasks grows, how do we even measure progress (via both humans and machines)? He proposes a high-level framework that first decomposes a long-form text into simpler atomic units before then evaluating each unit on a specific aspect. He demonstrates the framework’s effectiveness at evaluating factuality and coherence on tasks such as biography generation and book summarization. He will also discuss the rapid proliferation of LLM-generated long-form text, which plagues not only evaluation (e.g., via Mechanical Turkers using ChatGPT to complete tasks) but also society as a whole, and he will describe novel watermarking strategies to detect such text. Finally, he will conclude by discussing his future research vision, which aims to extend long-form language processing to multilingual, multimodal, and collaborative human-centered settings.\n\nSpeaker Biography: Mohit Iyyer is an associate professor in computer science at the University of Massachusetts Amherst, with a primary research interest in natural language generation. He is the recipient of Best Paper Awards at the 2016 and 2018 Annual Conferences of the North American Chapter of the Association for Computational Linguistics, an Outstanding Paper Award at the 2023 Conference of the European Chapter of the Association for Computational Linguistics, and a Best Demo Award at the 2015 Conference on Neural Information Processing Systems; he also received the 2022 Samsung AI Researcher of the Year award. Iyyer obtained his PhD in computer science from the University of Maryland, College Park in 2017 and spent the following year as a researcher at the Allen Institute for AI.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nFebruary 28, 2024\n\nAbstract: Machine learning models pre-trained on internet data have acquired broad knowledge about the world, but struggle to solve complex tasks that require extended reasoning and planning. Sequential decision-making, on the other hand, has empowered AlphaGo’s superhuman performance, but lacks visual, language, and physical knowledge about the world. In this talk, Sherry Yang will present her research towards enabling decision making with internet-scale knowledge. First, she will illustrate how language models and video generation are unified interfaces that can integrate internet knowledge and represent diverse tasks, enabling the creation of a generative simulator to support real-world decision-making. Second, she will discuss her work on designing decision-making algorithms that can take advantage of generative language and video models as agents and environments. Combining pre-trained models with decision-making algorithms can effectively enable a wide range of applications such as developing chatbots, learning robot policies, and discovering novel materials.\n\nSpeaker Biography: Sherry Yang is a final-year PhD student at the University of California, Berkeley, advised by Pieter Abbeel; she is also a senior research scientist at Google DeepMind. Her research aims to develop machine learning models with internet-scale knowledge to make better-than-human decisions. To this end, she has developed techniques for generative modeling and representation learning from large-scale vision, language, and structured data, coupled with developing algorithms for sequential decision-making such as imitation learning, planning, and reinforcement learning. Yang initiated and led the Foundation Models for Decision Making workshop at the 2022 and 2023 Conferences on Neural Information Processing Systems, bringing together research communities in vision, language, planning, and reinforcement learning to solve complex decision-making tasks at scale. Before her current role, Yang received her bachelor’s and master’s degrees from the Massachusetts Institute of Technology, where she was advised by Patrick Winston and Julian Shun.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nFebruary 22, 2024\n\nAbstract: Today, access to high-quality data has become the key bottleneck to deploying machine learning. Often, the data that is most valuable is locked away in inaccessible silos due to unfavorable incentives and ethical or legal restrictions. This is starkly evident in health care, where such barriers have led to highly biased and underperforming tools. In his talk, Sai Praneeth Karimireddy will describe how collaborative systems, such as federated learning, provide a natural solution; they can remove barriers to data sharing by respecting the privacy and interests of the data providers. Yet for these systems to truly succeed, three fundamental challenges must be confronted: These systems need to 1) be efficient and scale to large networks, 2) provide reliable and trustworthy training and predictions, and 3) manage the divergent goals and interests of the participants. Karimireddy will discuss how tools from optimization, statistics, and economics can be leveraged to address these challenges.\n\nSpeaker Biography: Sai Praneeth Karimireddy is a postdoctoral researcher at the University of California, Berkeley with Mike I. Jordan. Karimireddy obtained his undergraduate degree from the Indian Institute of Technology Delhi and his PhD at the Swiss Federal Institute of Technology Lausanne (EPFL) with Martin Jaggi. His research builds large-scale machine learning systems for equitable and collaborative intelligence and designs novel algorithms that can robustly and privately learn over distributed data (i.e., edge, federated, and decentralized learning). He also closely engages with industry and public health organizations (e.g., Doctors Without Borders, the Red Cross, the Cancer Registry of Norway) to translate his research into practice. His work has previously been deployed across industry by Meta, Google, OpenAI, and Owkin and has been awarded with the EPFL Patrick Denantes Memorial Prize for the best computer science thesis, the Dimitris N. Chorafas Foundation Award for exceptional applied research, an EPFL thesis distinction award, a Swiss National Science Foundation fellowship, and best paper awards at the International Workshop on Federated Learning for User Privacy and Data Confidentiality at the 2021 International Conference on Machine Learning and the International Workshop on Federated Learning: Recent Advances and New Challenges at the Thirty-Sixth Annual Conference on Neural Information Processing Systems.\n\nView the recording >>\n\nInstitute for Assured Autonomy & Computer Science Seminar Series\n\nFebruary 20, 2024\n\nAbstract: Sensing and actuation systems are entrusted with increasing intelligence to perceive and react to the environment, but their reliability often relies on the trustworthiness of sensors. As process automation and robotics keep evolving, sensing methods such as pressure, temperature, and motion sensing are extensively used in conventional systems and rapidly emerging applications. This talk aims to investigate the threats incurred by the out-of-band signals and discuss the low-cost defense methods against physical injection attacks on sensors. Hei will present her paper results from the USENIX Security Symposium, ACM Conference on Computer and Communications Security (CCS), ACM Asia CSS, Secure and Trustworthy Deep Learning Systems Workshop, Joint Workshop on CPS & IoT Security and Privacy, and European Alliance for Innovation’s International Conference on Security and Privacy in Cyber-Physical Systems and Smart Vehicles.\n\nSpeaker Biography: Xiali “Sharon” Hei has been an Alfred and Helen M. Lamson Endowed Associate Professor in the School of Computing and Informatics at the University of Louisiana at Lafayette since August, 2023. She was previously an Alfred and Helen M. Lamson Endowed Assistant Professor from August 2017 to July 2023. Prior to joining the University of Louisiana at Lafayette, she was an assistant professor at Delaware State University from 2015–2017 and an assistant professor at Frostburg State University from 2014–2015. Hei has received a number of awards, including an Alfred and Helen M. Lamson Endowed Professorship; an Outstanding Achievement Award in Externally Funded Research; numerous recognitions from the NSF, including a Track 4 Faculty Fellowship, a Secure and Trustworthy Cyberspace award, a Major Research Instrumentation award, an Established Program to Stimulate Competitive Research RII Track 1 award, a Computer and Information Science and Engineering Research Initiation Initiative award; a Meta research award; funding from the Lousiana Board of Regents Support Fund; a Delaware Economic Development Office grant; a Best Paper Award at the European Alliance for Innovation’s International Conference on Security and Privacy in Cyber-Physical Systems and Smart Vehicles; a Best Poster Runner-Up Award at the 2014 ACM International Symposium on Mobile Ad Hoc Networking and Computing; a Dissertation Completion Fellowship; the Bronze Award Best Graduate Project in Future of Computing Competition, and more. Her papers have been published at venues such as the USENIX Security Symposium, the ACM Conference on Computer and Communications Security, the Institute of Electrical and Electronics Engineers (IEEE) International Conference on Computer Communications (ICC), the IEEE European Symposium on Security and Privacy (EuroS&P), the International Symposium on Research in Attacks, Intrusions and Defenses, and the ACM Asia Conference on Computer and Communications Security. Hei is a TPC member of the USENIX Security Symposium, IEEE EuroS&P, PST, the IEEE Global Communications Conference, SafeThings, AutoSec, IEEE ICC, the International Conference on Wireless Artificial Intelligent Computing Systems and Applications, and more. She has also been an IEEE senior member since 2019. Hei earned a BS in electrical engineering from Xi’an Jiaotong University and an MS in software engineering from Tsinghua University.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nFebruary 12, 2024\n\nAbstract: There is an enormous data gap between how AI systems and children learn language: The best LLMs now learn language from text with a word count in the trillions, whereas it would take a child roughly 100K years to reach those numbers through speech. There is also a clear generalization gap: Whereas machines struggle with systematic generalization, people excel. For instance, once a child learns how to “skip,” they immediately know how to “skip twice” or “skip around the room with their hands up” due to their compositional skills. In this talk, Brenden Lake will describe two case studies in addressing these gaps. The first addresses the data gap, in which deep neural networks were trained from scratch, not on large-scale data from the web, but through the eyes and ears of a single child. Using head-mounted video recordings from a child, this study shows how deep neural networks can acquire many word-referent mappings, generalize to novel visual referents, and achieve multi-modal alignment. The results demonstrate how today’s AI models are capable of learning key aspects of children’s early knowledge from realistic input. The second case study addresses the generalization gap. Can neural networks capture human-like systematic generalization? This study addresses a 35-year-old debate catalyzed by Fodor and Pylyshyn’s classic article, which argued that standard neural networks are not viable models of the mind because they lack systematic compositionality—the algebraic ability to understand and produce novel combinations from known components. This study shows how neural networks can achieve humanlike systematic generalization when trained through meta-learning for compositionality (MLC), a new method for optimizing the compositional skills of neural networks through practice. With MLC, a neural network can match human performance and solve several machine learning benchmarks. Given this work, we’ll discuss the paths forward for building machines that learn, generalize, and interact in more humanlike ways based on more natural input.\n\nSpeaker Biography: Brenden M. Lake is an assistant professor of psychology and data science at New York University. He received his MS and BS in symbolic systems from Stanford University in 2009 and his PhD in cognitive science from the Massachusetts Institute of Technology in 2014. Lake was a postdoctoral data science fellow at NYU from 2014–2017. He is a recipient of the Robert J. Glushko Prize for Outstanding Doctoral Dissertation in Cognitive Science, he was named an Innovator Under 35 by MIT Technology Review, and his research was selected by Scientific American as one of the 10 most important advances of 2016. Lake’s research focuses on computational problems that are easier for people than they are for machines, such as learning new concepts, creating new concepts, learning to learn, and asking questions.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nFebruary 1, 2024\n\nAbstract: This talk will discuss the area of algorithms with predictions, also known as learning-augmented algorithms. These methods parameterize algorithms with machine-learned predictions, enabling the algorithms to tailor their decisions to input distributions and to allow for improved performance on runtime, space, or solution quality. This talk will discuss recent developments on how to leverage machine-learned predictions to improve the runtime efficiency of algorithms for optimization and data structures. The talk will also discuss how to achieve “instance-optimal” algorithms when the predictions are accurate and the algorithm’s performance gracefully degrades when there are errors in the predicted advice. The talk will illustrate via examples such as bipartite matching the potential of the area to realize significant performance improvements for algorithm efficiency.\n\nSpeaker Biography: Ben Moseley is the Carnegie-Bosch Associate Professor of Operations Research at Carnegie Mellon University and is a consulting scientist at Relational AI. He obtained his PhD from the University of Illinois. During his career, his papers have won best paper awards at IPDPS (2015), SPAA (2013), and SODA (2010). His papers have been recognized as top publications with honors such as Oral Presentations at NeurIPS (2021, 2017) and NeurIPS Spotlight Papers (2023, 2018). He has served as area chair for ICML, ICLR, and NeurIPS every year since 2020 and has been on many program committees, including SODA (2022, 2018), ESA (2017), and SPAA (2024, 2022, 2021, 2016). He was an associate editor for IEEE Transactions on Knowledge and Data Engineering from 2018–2022 and has served as associate editor of Operations Research Letters since 2017. He has won an NSF CAREER Award, two Google Research Faculty Awards, a Yahoo ACE Award, and an Infor faculty award. He was selected as a Top 50 Undergraduate Professor by Poets & Quants. His research interests broadly include algorithms, machine learning, and discrete optimization. He is currently excited about robustly incorporating machine learning into decision-making processes.\n\nView the recording >>\n\nComputer Science Seminar Series\n\nJanuary 18, 2024\n\nAbstract: Mobile (cellular) networks traditionally have been closed systems, developed as vertically integrated, black-box appliances by a few equipment vendors and deployed by a handful of national-scale mobile network operators in each country—all in all, a small ecosystem. However, we have witnessed a radical transformation in the design and deployment of mobile networking systems in the recent past that reflects a path toward greater openness. In this talk, Marina will give his perspective on the key drivers, economic and beyond, behind this trend and the main enablers for this transformation. He will complement this by outlining his key research contributions in this direction. Further, he will highlight two of his recent works: (1) on rearchitecting the mobile core control plane for efficient cloud-native operation and to be more open (i.e., better suited for multi-vendor realization); and (2) on radio access network root cause analysis as a key challenge for Open RAN, as well as a compelling use case of the AI-powered and data-driven operations it enables.\n\nSpeaker Biography: Mahesh Marina is a professor in the School of Informatics at the University of Edinburgh, where he leads the Networked Systems Research Group. He is currently spending his sabbatical time at the Johns Hopkins University’s Department of Computer Science as a visiting professor. Previously, Marina was a Turing Fellow at the Alan Turing Institute, the UK’s national institute for data science and AI, for five years, 2018–2023; he also served as the director of the Institute for Computing Systems Architecture within Informatics@Edinburgh for four years, until July 2022. Prior to joining the University of Edinburgh, Marina had a two-year postdoctoral stint at the UCLA Computer Science Department after earning his PhD in computer science from the State University of New York at Stony Brook. He has previously held visiting researcher positions at ETH Zurich and at Ofcom, the UK’s telecommunications regulator, at its headquarters in London. Marina is an ACM Distinguished Member and an IEEE Senior Member.\n\nView the recording >>\n\nInstitute for Assured Autonomy & Computer Science Seminar Series\n\nJanuary 16, 2024\n\nAbstract: In early 2020, the U.S. government revealed its belief that China might be able to eavesdrop on 5G communications through Huawei network equipment. This has enormous ramifications for DOD and State Department communications overseas, since these backdoors could provide our adversaries with information that allows them to glean insights into operations or harm personnel. Later that same year, wired and wireless networks in the greater Nashville area failed when a bomb damaged a single network facility. The outage affected nearly every aspect of modern society, including grounding flights, disrupting economic activity, and disconnecting 911. These two events highlight the enormous challenge of securing critical communications: We need to secure our communications against threats within the telecommunications infrastructure and secure it from external attack. This talk will discuss both of these challenges. First, Marder will use the Nashville outage as a blueprint to show that it remains surprisingly easy for attackers to induce large-scale communications outages around the U.S. without any insider information or specialized access. Second, he will discuss innovative methods for identifying and circumventing the potential threats placed by nation-state adversaries within the infrastructure, along with methods for ensuring that communications only traverse benign infrastructure.\n\nSpeaker Biography: Alex Marder is an assistant professor of computer science at Johns Hopkins University and a member of the Institute for Assured Autonomy. Marder’s research covers a wide breadth of networking areas, including the use of empirical analyses and machine learning to evaluate and improve the security and performance of wired and wireless networks. His current work leverages a deep understanding of network architecture and deployment to design secure 5G communication networks for the Department of Defense, reveal security weaknesses in domestic internet access networks, and provide a better understanding of broadband inequity. He received a BS from Brandeis University and a PhD from the University of Pennsylvania. Prior to joining Johns Hopkins, he was a research scientist at CAIDA at UC San Diego."
    }
}