{
    "id": "dbpedia_1356_3",
    "rank": 19,
    "data": {
        "url": "https://www.linkedin.com/posts/veereshshringari_language-ai-for-all-smashing-barriers-with-activity-7177072161520525312-QUQ4",
        "read_more_link": "",
        "language": "en",
        "title": "Veeresh Shringari on LinkedIn: â€œLanguage AI for All: Smashing Barriers with Smaller, Smarter, Leanerâ€¦",
        "top_image": "https://media.licdn.com/dms/image/sync/v2/D4E27AQEbFhzFShI6_Q/articleshare-shrink_800/articleshare-shrink_800/0/1711146926954?e=2147483647&v=beta&t=lOhcoYdClzian4imcX-1MGdlCiz_XY6DLHLwbz-EaJ0",
        "meta_img": "https://media.licdn.com/dms/image/sync/v2/D4E27AQEbFhzFShI6_Q/articleshare-shrink_800/articleshare-shrink_800/0/1711146926954?e=2147483647&v=beta&t=lOhcoYdClzian4imcX-1MGdlCiz_XY6DLHLwbz-EaJ0",
        "images": [
            "https://static.licdn.com/aero-v1/sc/h/5q92mjc5c51bjlwaj3rs9aa82"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Veeresh Shringari"
        ],
        "publish_date": "2024-03-22T22:42:26.831000+00:00",
        "summary": "",
        "meta_description": "Of late there areÂ different techniques of LLM for making LLM models more accessible to everyone and everything let it be sharding, 1-bit LLM, SLM, and SLLM. Iâ€¦",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/posts/veereshshringari_language-ai-for-all-smashing-barriers-with-activity-7177072161520525312-QUQ4",
        "text": "Are you confused about which LLM to use? What does \"Instruct\", \"GGUF\", \"4bit\", etc. mean, and how should your company navigate an increasingly complicated model landscape? Should you really switch to the latest Llama 3 405B? I've been getting these questions all the time, and so I decided to write up my thoughts in a blog post [linked in the comments]. Key takeaways: (1) Understand the 3 main LLM categories: Closed, proprietary (e.g., GPT, Claude); Open, restrictively licensed; and Open, permissively licensed (e.g., Llama 3, Mistral). (2) Model family evolution typically follows this path: Base â†’ Instruct â†’ Community proliferation. (3) Decoding model names is crucial. Look for size indicators (8B, 13B, 70B), task optimization (Instruct, Chat, Code), and hardware optimization (GGUF, 4bit, GGML). (3) When making decisions, consider your use case, available resources, privacy requirements, and licensing needs. ðŸ’¡ Pro tip: For most inference tasks, \"Instruct\" or otherwise fine-tuned models outperform base models. #AIStrategy #MachineLearning #TechLeadership #LLM #LLMs #GenerativeAI (cc Prediction Guard)"
    }
}