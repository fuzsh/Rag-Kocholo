{
    "id": "correct_foundationPlace_00126_1",
    "rank": 60,
    "data": {
        "url": "https://science.osti.gov/bes/Community-Resources/Reports/Abstracts",
        "read_more_link": "",
        "language": "en",
        "title": "U.S. DOE Office of Science (SC)",
        "top_image": "https://science.osti.gov/assets/favicons/coast-228x228.png",
        "meta_img": "https://science.osti.gov/assets/favicons/coast-228x228.png",
        "images": [
            "https://science.osti.gov/assets/img/doe-logos/logo.png",
            "https://science.osti.gov/-/media/bes/images/reports/2017/SS_rpt_cover-thmb.jpg",
            "https://science.osti.gov/-/media/bes/images/reports/2017/Future_Electron_Source_Worskhop_Report-thmb.jpg",
            "https://science.osti.gov/-/media/ascr/images/2017/DOE-ExascaleReport_BES-thmb.jpg",
            "https://science.osti.gov/-/media/bes/images/reports/2016/BRNQM_cover-thmb.jpg",
            "https://science.osti.gov/-/media/bes/images/reports/2016/SustainableAmmoniaReport-Thmb.jpg",
            "https://science.osti.gov/-/media/ascr/images/Program-Document-Thumbnails/2016/Neuromorphic-Computing-Report_FNLBLP-1.jpg",
            "https://science.osti.gov/-/media/bes/images/reports/2016/BRNEM_FrontCover_thumb.jpg",
            "https://science.osti.gov/-/media/bes/besac/images/banner-images/CFME_tmb.jpg",
            "https://science.osti.gov/-/media/bes/images/reports/2015/BES_CSFFF_rtp.jpg",
            "https://science.osti.gov/-/media/bes/images/reports/Future_of_Electron_Scattering.jpg?h=129&w=100&hash=1368B30BE5DF9310615C7E6FA6E142B5512CDE1BF3F25B3E2E27832832DB16E9",
            "https://science.osti.gov/-/media/bes/images/reports/Future_of_Electron_Scattering-9.jpg",
            "https://science.osti.gov/-/media/bes/images/reports/XRO_xlg.jpg?h=129&w=100&hash=1A1E540C53D3D5814A8E5BD54DCCE0535678A6FDB92B3F84E36C1BED85EEF84F",
            "https://science.osti.gov/-/media/bes/images/reports/NXD_tn.JPG",
            "https://science.osti.gov/-/media/bes/images/reports/OFMS_sm.jpg?w=100&h=129&as=1&hash=E66AC40AB571FCECCD308F6F4580BCB71731A22767CC1167742738B724BD7E3D",
            "https://science.osti.gov/-/media/bes/images/reports/2015/ASCR_BES_Data_xsm.jpg?h=129&w=100&hash=34F0E13A1F900876269C3A823A73A7F92F17E46D8CDDD32F77058B418DBCF36F",
            "https://science.osti.gov/-/media/bes/images/presice.jpg?w=100&h=129&as=1&hash=54AB6F7663D1D68559C23B9DAD00891B4E2BBF9451245D8F672FB32112E75D0F",
            "https://science.osti.gov/-/media/bes/images/CLS_x.jpg?w=100&h=129&as=1&hash=69B0A5CAA7E20E74B45B7DCEA2B456F1FEA8CC8CC4D49FE5EEAF1AC00A6837A7",
            "https://science.osti.gov/-/media/bes/images/ccb-2020-rpt.jpg?w=98&h=129&as=1&hash=9FABC923B96B8190B3AB156D6C8666C6B1C87A3E615F2E4AA0CE95C29B8A9102",
            "https://science.osti.gov/-/media/bes/images/reports/cmsc-xlg.jpg?w=100&h=129&as=1&hash=3828B55B6A667BAFEB47D7CC7ABCD566D2D93666DABEEEA90F532852FE79088D",
            "https://science.osti.gov/-/media/bes/images/reports/nsssef-xlg.jpg?w=100&h=129&as=1&hash=9F1473C44FA34D5B5EAF53B917E90A6EBB7CE203C8C694414A12F53A8C16FEDA",
            "https://science.osti.gov/-/media/bes/images/reports/setf-xlg.jpg?w=100&h=129&as=1&hash=6D88F448D4FDB72F6011F9B45F8E5D94E1D344169A8ADB9A988C0DF113C34C3E",
            "https://science.osti.gov/-/media/bes/images/reports/set-xlg.jpg?w=100&h=129&as=1&hash=9FF7FE6FD821888457F822425A1D5C3F83697EDAB944630D46089AAB32113CD6",
            "https://science.osti.gov/-/media/bes/images/reports/ngps-xlg.jpg?w=100&h=129&as=1&hash=CB25B45FE94E20E223D0EE6778ADB3FB0B68370DF92DC3CF6041B7AE2A03BB2F",
            "https://science.osti.gov/-/media/bes/images/reports/gc-xlg.jpg?w=100&h=129&as=1&hash=8FD7B9E5794D01E9297DFA57F6C2FA83F22A6526FA9B79A554195E298B00F1E2",
            "https://science.osti.gov/-/media/bes/images/reports/muee-xlg.jpg?w=100&h=129&as=1&hash=C2BA5AEFADF180FD99E4578A3DC4CEA92DD27EFD6AA7FD23A0F680A74ACFFA8C",
            "https://science.osti.gov/-/media/bes/images/reports/cat-xlg.jpg?w=100&h=129&as=1&hash=57A261B960B41EE956D5C24D23B8E4EB59BB21B81A622F82207A79342BAA437C",
            "https://science.osti.gov/-/media/bes/images/reports/es-xlg.jpg?w=100&h=129&as=1&hash=97FAF5EE23848F5B543F3F647A82829ECF9C23E7B081C5B35354EA2476A1610F",
            "https://science.osti.gov/-/media/bes/images/reports/ees-xlg.jpg?w=100&h=129&as=1&hash=478BECABFBBBC7DD8B6F3949E7AC7724A272AD98A834E9FCA015AE869723608C",
            "https://science.osti.gov/-/media/bes/images/reports/geo-xlg.jpg?w=100&h=129&as=1&hash=558BF50AEF44356A5F646A367F1692A4E6319A00E30BE3B191A01A160B722B8D",
            "https://science.osti.gov/-/media/bes/images/reports/ctf-xlg.jpg?w=100&h=129&as=1&hash=671C7B20D9F460ACAE492705C1300F22014CF95919A76F2EE534B6426C1AF432",
            "https://science.osti.gov/-/media/bes/images/reports/anes-xlg.jpg?w=100&h=129&as=1&hash=F3D887E627B8BF6A8272C879834367B2A3FFD2B5B2B13D434697256D95132175",
            "https://science.osti.gov/-/media/bes/images/reports/ssl-xlg.jpg?w=100&h=129&as=1&hash=9D74252E6358617FEA7A2D6E562A57BCFC36E37DC8C23A98A380B5125945D961",
            "https://science.osti.gov/-/media/bes/images/reports/sc-xlg.jpg?w=100&h=129&as=1&hash=29E2C6B2C579F21B5F48DF5CC56E01A1E931E00686AAD82907D480EC2F20F5AD",
            "https://science.osti.gov/-/media/bes/images/reports/psne-xlg.jpg?w=100&h=129&as=1&hash=934E234BEC8D49482E3A803B3066CF794F4E9CA08D26ED04AC89715CC35BDA42",
            "https://science.osti.gov/-/media/bes/images/reports/seu-xlg.jpg?w=100&h=129&as=1&hash=8510167404D19C0C43D6771A8315E03CA8D3FA8D8DC4F6386ADDA8D9C39408F8",
            "https://science.osti.gov/-/media/bes/images/reports/acms-xlg.jpg?w=100&h=129&as=1&hash=1B9AD486CCDAEE103C7A7F05DD34E02FB7F39A00B91354595F64739EAA09AF1A",
            "https://science.osti.gov/-/media/bes/images/reports/od-xlg.jpg?w=100&h=129&as=1&hash=125C7C43F65F59EDDE1DFD59064A68DFD7AE05471BBEE9653E0E6B03771C6BC5",
            "https://science.osti.gov/-/media/bes/images/reports/nren-xlg.jpg?w=100&h=129&as=1&hash=AD136B1B5B1BBE0828CA91DE827BD2BFEB8E1C8089B5A7D09271690A0959B811",
            "https://science.osti.gov/-/media/bes/images/reports/thz-xlg.jpg?w=100&h=129&as=1&hash=2C853C37E4D8D5EEA118B7FDF7F8E6E320B6199FDEEF5E4780F180A79BCE03E6",
            "https://science.osti.gov/-/media/bes/images/reports/nhe-xlg.jpg?w=100&h=129&as=1&hash=97BC574EFF1956802CE0925DD15C696598CCDB20EFB382AE010392705C83E4B1",
            "https://science.osti.gov/-/media/bes/images/reports/tmn-xlg.jpg?w=100&h=129&as=1&hash=7B98C67D04B9A07AABCF8EF131A03B29BD712FFC9F6BC1485545AC964BBCDDF0",
            "https://science.osti.gov/-/media/bes/images/reports/oc-xlg.jpg?w=100&h=129&as=1&hash=73DC48CF70B1E064A4858DB71BC7EAA807DD6450D6B6E1A2E3CA44A68D492837",
            "https://science.osti.gov/-/media/bes/images/reports/bm-xlg.jpg?w=100&h=129&as=1&hash=D57A747DC25D40D06CFCD87DA86F966CC6C29417F14FADDA272FA84AD8248453",
            "https://science.osti.gov/-/media/bes/images/reports/sef-xlg.jpg?w=100&h=129&as=1&hash=72FFD8C675A64461A91CD956B10CDE3FB2E5527CE7D52CF36CFC041F7AA89506",
            "https://science.osti.gov/-/media/bes/images/reports/nct-xlg.jpg?w=100&h=129&as=1&hash=1DD84C8CFF2602E8E4C1F5CD8C28762695796D5369BB825DDA2AF71D5644DE76",
            "https://science.osti.gov/-/media/bes/images/reports/cs-xlg.jpg?w=100&h=129&as=1&hash=438F51518027DC6A71D1769418E65F92F53E26B82BB00A09C737FA52830D4AC8",
            "https://science.osti.gov/-/media/bes/images/reports/nset-xlg.jpg?w=100&h=129&as=1&hash=2986D0E2B83E54357388A36E2F83BF589E41F1901BCF67EDB9BC8ABE9D5CE0D0",
            "https://science.osti.gov/-/media/bes/images/highlights/2024/Zhou-Highlight.png?h=508&w=553&la=en&hash=400DA64A11E44604A3BD91CFAF600636321B67FDD1570C7E1345474849C8D69F",
            "https://science.osti.gov/-/media/bes/images/highlights/2024/Highlight_Kurtz.png?h=630&w=800&la=en&hash=8376579D6DE1CB79CBA182AD12704F63FB8443A070058D28E4EBE938BD11E965",
            "https://science.osti.gov/assets/img/doe-logos/logo-white-small-2x.png",
            "https://science.osti.gov/assets/img/doe-logos/logo-white-small.png",
            "https://science.osti.gov/assets/img/doe-logos/logo-white-small.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Office of Science"
        ],
        "publish_date": "2023-06-28T14:19:28",
        "summary": "",
        "meta_description": "The page provides the BES Abstracts.",
        "meta_lang": "en",
        "meta_favicon": "/assets/favicons/apple-touch-icon-57x57.png",
        "meta_site_name": "",
        "canonical_link": "https://science.osti.gov/bes/Community-Resources/Reports/Abstracts",
        "text": "Abstracts\n\nBasic Research Needs Workshop on Synthesis Science for Energy Relevant Technology\n\nBES Workshop on Future Electron Sources\n\nBES Computing and Data Requirements in the Exascale Age\n\nBasic Research Needs Workshop on Quantum Materials for Energy Relevant Technology\n\nSustainable Ammonia Synthesis – Exploring the scientific challenges associated with discovering alternative, sustainable processes for ammonia production\n\nNeuromorphic Computing – From Materials Research to Systems Architecture Roundtable\n\nBasic Research Needs for Environmental Management\n\nChallenges at the Frontiers of Matter and Energy: Transformative Opportunities for Discovery Science\n\nControlling Subsurface Fractures and Fluid Flow: A Basic Research Agenda\n\nFuture of Electron Scattering and Diffraction\n\nX-ray Optics for BES Light Source Facilities\n\nNeutron and X-ray Detectors\n\nFrom Quanta to the Continuum: Opportunities for Mesoscale Science\n\nData and Communications in Basic Energy Sciences: Creating a Pathway for Scientific Discovery\n\nResearch Needs and Impacts in Predictive Simulation for Internal Combustion Engines (PreSICE)\n\nReport of the Basic Energy Sciences Workshop on Compact Light Sources\n\nBasic Research Needs for Carbon Capture: Beyond 2020\n\nComputational Materials Science and Chemistry: Accelerating Discovery and Innovation through Simulation-Based Engineering and Science\n\nNew Science for a Secure and Sustainable Energy Future\n\nScience for Energy Technology: Strengthening the Link between Basic Research and Industry\n\nNext-Generation Photon Sources for Grand Challenges in Science and Energy\n\nDirecting Matter and Energy: Five Challenges for Science and the Imagination\n\nBasic Research Needs for Materials under Extreme Environments\n\nBasic Research Needs: Catalysis for Energy\n\nFuture Science Needs and Opportunities for Electron Scattering: Next-Generation Instrumentation and Beyond\n\nBasic Research Needs for Electrical Energy Storage\n\nBasic Research Needs for Geosciences: Facilitating 21st Century Energy Systems\n\nBasic Research Needs for Clean and Efficient Combustion of 21st Century Transportation Fuels\n\nBasic Research Needs for Advanced Nuclear Energy Systems\n\nBasic Research Needs for Solid-State Lighting\n\nBasic Research Needs for Superconductivity\n\nThe Path to Sustainable Nuclear Energy Basic and Applied Research Opportunities for Advanced Fuel Cycles\n\nBasic Research Needs for Solar Energy Utilization\n\nAdvanced Computational Materials Science: Application to Fusion and Generation IV Fission Reactors\n\nOpportunities for Discovery: Theory and Computation in Basic Energy Sciences\n\nNanoscience Research for Energy Needs\n\nDOE-NSF-NIH Workshop on Opportunities in THz Science\n\nBasic Research Needs for the Hydrogen Economy\n\nTheory and Modeling in Nanoscience\n\nOpportunities for Catalysis in the 21st Century\n\nBiomolecular Materials\n\nBasic Research Needs To Assure A Secure Energy Future\n\nBasic Research Needs for Countering Terrorism\n\nComplex Systems: Science for the 21st Century\n\nNanoscale Science, Engineering and Technology Research Directions\n\nBasic Research Needs Workshop on Synthesis Science for Energy Relevant Technology\n\nThis report, which is the result of the Basic Energy Sciences Workshop on Basic Research Needs for Synthesis Science for Energy Technologies, lays out the scientific challenges and opportunities in synthesis science.\n\nThe workshop was attended by more than 100 leading national and international scientific experts. Its five topical and two crosscutting panels identified four priority research directions (PRDs) for realizing the vision of predictive, science-directed synthesis:\n\nAchieve mechanistic control of synthesis to access new states of matter\n\nThe opportunities for synthesizing new materials are almost limitless. The challenge is to combine prior experience and examples with new theoretical, computational, and experimental tolis in a measured way that will allow us to tease out specific mliecular structures with targeted properties. Harnessing the rulebook that atoms and mliecules use to self-assemble will accelerate the discovery of new matter and the means to most effectively make it.\n\nAccelerate materials discovery by exploiting extreme conditions, complex chemistries and mliecules, and interfacial systems\n\nEven as our theoretical understanding of synthetic processes increases, many future discoveries will come from regions of parameter space that are relatively unexplored and beyond current predictive capabilities. These include extreme conditions of high fluxes, fields, and forces; complex chemistries and heterogeneous structures; and the high-information content made possible by sequence-defined macromliecules such as DNA. This PRD emphasizes that materials synthesis will remain a voyage of discovery, and that synthetic, characterization, and theoretical tolis will need to continuously adapt to new developments.\n\nHarness the complex functionality of hierarchical matter\n\nHierarchical matter exploits the coupling among the different types of atomic assemblies, or heterogeneities, distributed across multiple length scales. These interactions lead to emergent properties not possible in homogeneous materials. Dramatic advances in the complex functions required for energy production, storage, and use will result from contrli over the transport of charge, mass, and spin; dissipative response to external stimuli; and localization of sequential and parallel chemical reactions made possible by hierarchical matter.\n\nIntegrate emerging theoretical, computational, and in situ characterization tolis to achieve directed synthesis with real time adaptive contrli\n\nTheory, computation, and characterization are critical components to the effective discovery and design of new mliecules and materials. Important but insufficient is the prediction of the final composition and structure. Critical to the process is knowing and predicting how materials assemble and the consequences of the assembly for final material properties. Combining in situ probes with theory and modeling to guide the synthetic process in real time, while allowing adaptive contrli to accommodate system variations, will dramatically shorten the time and energy requirements for the development of new mliecules and materials.\n\nThe historical impact of chemistry and materials on society makes a compelling case for developing a foundational science of synthesis. Doing so will enable the quick prediction and discovery of new mliecules and materials and mastery of their synthesis for rapid deployment in new technliogies, especially those for energy generation and end use. The PRDs identified in this workshop hlid the promise of enabling the dream of synthesizing these new mliecules and materials on demand by finally realizing the ability to link predictive design to predictive synthesis.\n\nBES Workshop on Future Electron Sources\n\nThe DOE Office of Basic Energy Sciences (BES) sponsored the Future Electron Sources workshop to identify opportunities and needs for injector developments at the existing and future BES facilities. The workshop was held at the SLAC National Accelerator Laboratory on September 8-9, 2016. The workshop assessed the state of the art and future development requirements, with emphasis on the underlying engineering, science and technology necessary to realize the next generation of electron injectors to advance photon based science. A major objective was to optimize the performance of free electron laser facilities, which are presently limited in x-ray power and spectrum coverage due to the unavailability of suitable injectors. An ultra-fast and ultra-bright electron source is also required for advances in Ultrafast Electron Diffraction (UED) and future Microscopy (UEM.) The scope included normal conducting and superconducting RF injectors, including better performance cathodes and simulation tools. The workshop explored opportunities for discovery enabled by advanced electron sources, and identified processes to enhance interactions and collaborations among DOE laboratories to most effectively use their resources and skills to advance scientific frontiers in energy-relevant areas, as well as the challenges anticipated by advances in source brightness.\n\nThe goals of this workshop were to:\n\nEvaluate the present state of the art in electron injectors\n\nIdentify the gaps in current electron source capabilities, and what developments should have high priority to support current and future photon based science\n\nIdentify the engineering, science and technology challenges\n\nIdentify methods of interaction and collaboration among the facilities so that resources are most effectively focused onto key problems.\n\nGenerate a report of the workshop activities including a prioritized list of the research directions to address the key challenges.\n\nWorkshop participants emphasized that advances in all major technical areas of electron sources are required to meet future X-ray and electron scattering instrument needs.\n\nBES Computing and Data Requirements in the Exascale Age\n\nComputers have revolutionized every aspect of our lives. Yet in science, the most tantalizing applications of computing lie just beyond our reach. The current quest to build an exascale computer with one thousand times the capability of today’s fastest machines (and more than a million times that of a laptop) will take researchers over the next horizon. The field of materials, chemical reactions, and compounds is inherently complex. Imagine millions of new materials with new functionalities waiting to be discovered — while researchers also seek to extend those materials that are known to a dizzying number of new forms. We could translate massive amounts of data from high precision experiments into new understanding through data mining and analysis. We could have at our disposal the ability to predict the properties of these materials, to follow their transformations during reactions on an atom-by-atom basis, and to discover completely new chemical pathways or physical states of matter. Extending these predictions from the nanoscale to the mesoscale, from the ultrafast world of reactions to long-time simulations to predict the lifetime performance of materials, and to the discovery of new materials and processes will have a profound impact on energy technology. In addition, discovery of new materials is vital to move computing beyond Moore’s law. To realize this vision, more than hardware is needed. New algorithms to take advantage of the increase in computing power, new programming paradigms, and new ways of mining massive data sets are needed as well. This report summarizes the opportunities and the requisite computing ecosystem needed to realize the potential before us.\n\nIn addition to pursuing new and more complete physical models and theoretical frameworks, this review found that the following broadly grouped areas relevant to the U.S. Department of Energy (DOE) Office of Advanced Scientific Computing Research (ASCR) would directly affect the Basic Energy Sciences (BES) mission need.\n\nBasic Research Needs Workshop on Quantum Materials for Energy Relevant Technology\n\nImagine future computers that can perform calculations a million times faster than today’s most powerful supercomputers at only a tiny fraction of the energy cost. Imagine power being generated, stored, and then transported across the national grid with nearly no loss. Imagine ultrasensitive sensors that keep us in the loop on what is happening at home or work, warn us when something is going wrong around us, keep us safe from pathogens, and provide unprecedented control of manufacturing and chemical processes. And imagine smart windows, smart clothes, smart buildings, supersmart personal electronics, and many other items — all made from materials that can change their properties “on demand” to carry out the functions we want. The key to attaining these technological possibilities in the 21st century is a new class of materials largely unknown to the general public at this time but destined to become as familiar as silicon. Welcome to the world of quantum materials — materials in which the extraordinary effects of quantum mechanics give rise to exotic and often incredible properties..\n\nSustainable Ammonia Synthesis – Exploring the scientific challenges associated with discovering alternative, sustainable processes for ammonia production\n\nAmmonia (NH3) is essential to all life on our planet. Until about 100 years ago, NH3 produced by reduction of dinitrogen (N2) in air came almost exclusively from bacteria containing the enzyme nitrogenase..\n\nDOE convened a roundtable of experts on February 18, 2016.\n\nParticipants in the Roundtable discussions concluded that the scientific basis for sustainable processes for ammonia synthesis is currently lacking, and it needs to be enhanced substantially before it can form the foundation for alternative processes. The Roundtable Panel identified an overarching grand challenge and several additional scientific grand challenges and research opportunities:\n\nDiscovery of active, selective, scalable, long-lived catalysts for sustainable ammonia synthesis.\n\nDevelopment of relatively low pressure (<10 atm) and relatively low temperature (<200 C) thermal processes.\n\nIntegration of knowledge from nature (enzyme catalysis), molecular/homogeneous and heterogeneous catalysis.\n\nDevelopment of electrochemical and photochemical routes for N2 reduction based on proton and electron transfer\n\nDevelopment of biochemical routes to N2 reduction\n\nDevelopment of chemical looping (solar thermochemical) approaches\n\nIdentification of descriptors of catalytic activity using a combination of theory and experiments\n\nCharacterization of surface adsorbates and catalyst structures (chemical, physical and electronic) under conditions relevant to ammonia synthesis.\n\nNeuromorphic Computing – From Materials Research to Systems Architecture Roundtable\n\nComputation in its many forms is the engine that fuels our modern civilization. Modern computation—based on the von Neumann architecture—has allowed, until now, the development of continuous improvements, as predicted by Moore’s law. However, computation using current architectures and materials will inevitably—within the next 10 years—reach a limit because of fundamental scientific reasons.\n\nDOE convened a roundtable of experts in neuromorphic computing systems, materials science, and computer science in Washington on October 29-30, 2015 to address the following basic questions:\n\nCan brain-like (“neuromorphic”) computing devices based on new material concepts and systems be developed to dramatically outperform conventional CMOS based technology? If so, what are the basic research challenges for materials sicence and computing?\n\nThe overarching answer that emerged was:\n\nThe development of novel functional materials and devices incorporated into unique architectures will allow a revolutionary technological leap toward the implementation of a fully “neuromorphic” computer.\n\nTo address this challenge, the following issues were considered:\n\nThe main differences between neuromorphic and conventional computing as related to: signaling models, timing/clock, non-volatile memory, architecture, fault tolerance, integrated memory and compute, noise tolerance, analog vs. digital, and in situ learning\n\nNew neuromorphic architectures needed to: produce lower energy consumption, potential novel nanostructured materials, and enhanced computation\n\nDevice and materials properties needed to implement functions such as: hysteresis, stability, and fault tolerance\n\nComparisons of different implementations: spin torque, memristors, resistive switching, phase change, and optical schemes for enhanced breakthroughs in performance, cost, fault tolerance, and/or manufacturability\n\nBasic Research Needs for Environmental Management\n\nThis report is based on a BES/BER/ASCR workshop on Basic Research Needs for Environmental Management, which was held on July 8-11, 2015. The workshop goal was to define priority research directions that will provide the scientific foundations for future environmental management technologies, which will enable more efficient, cost-effective, and safer cleanup of nuclear waste.\n\nOne of the US Department of Energy’s (DOE) biggest challenges today is cleanup of the legacy resulting from more than half a century of nuclear weapons production. The research and manufacturing associated with the development of the nation’s nuclear arsenal has left behind staggering quantities of highly complex, highly radioactive wastes and contaminated soils and groundwater. Based on current knowledge of these legacy problems and currently available technologies, DOE projects that hundreds of billions of dollars and more than 50 years of effort will be required for remediation.\n\nOver the past decade, DOE’s progress towards cleanup has been stymied in part by a lack of investment in basic science that is foundational to innovation and new technology development. During this decade, amazing progress has been made in both experimental and computational tools that have been applied to many energy problems such as catalysis, bioenergy, solar energy, etc. Our abilities to observe, model, and exploit chemical phenomena at the atomic level along with our understanding of the translation of molecular phenomena to macroscopic behavior and properties have advanced tremendously; however, remediation of DOE’s legacy waste problems has not yet benefited from these advances because of the lack investment in basic science for environmental cleanup.\n\nAdvances in science and technology can provide the foundation for completing the cleanup more swiftly, inexpensively, safely, and effectively. The lack of investment in research and technology development by DOE’s Office of Environmental Management (EM) was noted in a report by a task force to the Secretary of Energy’s Advisory Board (SEAB 2014). Among several recommendations, the report suggested a workshop be convened to develop a strategic plan for a “fundamental research program focused on developing new knowledge and capabilities that bear on the EM challenges.” This report summarizes the research directions identified at a workshop on Basic Research Needs for Environmental Management. This workshop, held July 8-11, 2015, was sponsored by three Office of Science offices: Basic Energy Sciences, Biological and Environmental Research, and Advanced Scientific Computing Research. The workshop participants included 65 scientists and engineers from universities, industry, and national laboratories, along with observers from the DOE Offices of Science, EM, Nuclear Energy, and Legacy Management.\n\nAs a result of the discussions at the workshop, participants articulated two Grand Challenges for science associated with EM cleanup needs. They are as follows:\n\nInterrogation of Inaccessible Environments over Extremes of Time and Space\n\nWhether the contamination problem involves highly radioactive materials in underground waste tanks or large volumes of contaminated soils and groundwaters beneath the Earth’s surface, characterizing the problem is often stymied by an inability to safely and cost effectively interrogate the system. Sensors and imaging capabilities that can operate in the extreme environments typical of EM’s remaining cleanup challenges do not exist. Alternatively, large amounts of data can sometimes be obtained about a system, but appropriate data analytics tools are lacking to enable effective and efficient use of all the information for performance regression or prediction. Research into new approaches for remote and in situ sensing, and new algorithms for data analytics are critically needed. Depending on the cleanup problem, these new approaches must span temporal and spatial scales—from seconds to millennia, from atoms to kilometers.\n\nUnderstanding and Exploiting Interfacial Phenomena in Extreme Environments\n\nWhile many of EM’s remaining cleanup problems involve unprecedented extremes in complexity, an additional layer is provided by the numerous contaminant forms and their partitioning across interfaces in these wastes, including liquid-liquid, liquid-solid, and others. For example, the wastes in the high-level radioactive waste tanks can have consistencies of paste, gels, or Newtonian slurries, where water behaves more like a solute than a solvent. Unexpected chemical forms of the contaminants and radionuclides partition to unusual solids, colloids, and other phases in the tank wastes, complicating their efficient separation. Mastery of the chemistry controlling contaminant speciation and its behavior at the solid-liquid and liquid-liquid interfaces in the presence of large quantities of ionizing radiation is needed to develop improved waste treatment approaches and enhance the operating efficiencies of treatment facilities. These same interfacial processes, if understood, can be exploited to develop entirely new approaches for effective separations technologies, both for tank waste processing and subsurface remediation.\n\nBased on the findings of the technical panels, six Priority Research Directions (PRDs) were identified as the most urgent scientific areas that need to be addressed to enable EM to meet its mission goals. All of these PRDs are also embodied in the two Grand Challenges. Further, these six PRDs are relevant to all aspects of EM waste issues, including tank wastes, waste forms, and subsurface contamination. These PRDs include the following:\n\nElucidating and exploiting complex speciation and reactivity far from equilibrium\n\nUnderstanding and controlling chemical and physical processes at interfaces\n\nHarnessing physical and chemical processes to revolutionize separations\n\nMechanisms of materials degradation in harsh environments\n\nMastering hierarchical structures to tailor waste forms\n\nPredictive understanding of subsurface system behavior and response to perturbations.\n\nTwo recurring themes emerged during the course of the workshop that cut across all of the PRDs. These crosscutting topics give rise to Transformative Research Capabilities. The first such capability, Multidimensional characterization of extreme, dynamic, and inaccessible environments, centers on the need for obtaining detailed chemical and physical information on EM wastes in waste tanks and during waste processing, in wastes forms, and in the environment. New approaches are needed to characterize and monitor these highly hazardous and/or inaccessible materials in their natural environment, either using in situ techniques or remote monitoring. These approaches are particularly suited for studying changes in the wastes over time and distances, for example. Such in situ and remote techniques are also critical for monitoring the effectiveness of waste processes, subsurface transport, and long-term waste form stability. However, far more detailed information will be needed to obtain fundamental insight into materials structure and molecular-level chemical and physical processes required for many of the PRDs. For these studies, samples must be retrieved and studied ex situ, but the hazardous nature of these samples requires special handling. Recent advances in nanoscience have catalyzed the development of high-sensitivity characterization tools—many of which are available at DOE user facilities, including radiological user facilities—and the means of handling ultrasmall samples, including micro- and nanofluidics and nanofabrication tools. These advances open the door to obtaining unprecedented information that is crucial to formulating concepts for new technologies to complete EM’s mission.\n\nThe sheer magnitude of the data needed to fully understand the complexity of EM wastes is daunting, but it is just the beginning. Additional data will need to be gathered to both monitor and predict changes—in tank wastes, during processing, in waste forms and in the subsurface over broad time and spatial scales. Therefore, the second Transformative Research Capability, Integrated simulation and data-enabled discovery, identified the need to develop curated databases and link experiments and theory through big-deep data methodologies. These state-of-the-art capabilities will be enabled by high-performance computing resources available at DOE user facilities.\n\nThe foundational knowledge to support innovation for EM cannot wait as the tank wastes continue to deteriorate and result in environmental, health, and safety issues. As clearly stated in the 2014 Secretary of Energy Advisory Board report, completion of EM’s remaining responsibilities will simply not be possible without significant innovation and that innovation can be derived from use-inspired fundamental research as described in this report. The breakthroughs that will evolve from this investment in basic science will reduce the overall risk and financial burden of cleanup while also increasing the probability of success. The time is now ripe to proceed with the basic science in support of more effective solutions for environmental management. The knowledge gleaned from this basic research will also have broad applicability to many other areas central to DOE’s mission, including separations methods for critical materials recovery and isotope production, robust materials for advanced reactor and steam turbine designs, and new capabilities for examining subsurface transport relevant to the water/energy nexus.\n\nChallenges at the Frontiers of Matter and Energy: Transformative Opportunities for Discovery Science\n\nFIVE TRANSFORMATIVE OPPORTUNITIES FOR DISCOVERY SCIENCE\n\nAs a result of this effort, it has become clear that the progress made to date on the five Grand Challenges has created a springboard for seizing five new Transformative Opportunities that have the potential to further transform key technologies involving matter and energy. These five new Transformative Opportunities and the evidence supporting them are discussed in this new report, “Challenges at the Frontiers of Matter and Energy: Transformative Opportunities for Discovery Science.”\n\nMastering Hierarchical Architectures and Beyond-Equilibrium Matter\n\nComplex materials and chemical processes transmute matter and energy, for example from CO2 and water to chemical fuel in photosynthesis, from visible light to electricity in solar cells and from electricity to light in light emitting diodes (LEDs) Such functionality requires complex assemblies of heterogeneous materials in hierarchical architectures that display time-dependent away-from-equilibrium behaviors. Much of the foundation of our understanding of such transformations however, is based on monolithic single- phase materials operating at or near thermodynamic equilibrium. The emergent functionalities enabling next-generation disruptive energy technologies require mastering the design, synthesis, and control of complex hierarchical materials employing dynamic far-from-equilibrium behavior. A key guide in this pursuit is nature, for biological systems prove the power of hierarchical assembly and far- from-equilibrium behavior. The challenges here are many: a description of the functionality of hierarchical assemblies in terms of their constituent parts, a blueprint of atomic and molecular positions for each constituent part, and a synthesis strategy for (a) placing the atoms and molecules in the proper positions for the component parts and (b) arranging the component parts into the required hierarchical structure. Targeted functionality will open the door to significant advances in the harvesting, transforming (e.g., reducing CO2, splitting water, and fixing nitrogen), storing, and use of energy to create new materials, manufacturing processes, and technologies—the lifeblood of human societies and economic growth.\n\nBeyond Ideal Materials and Systems: Understanding the Critical Roles of Heterogeneity, Interfaces, and Disorder\n\nReal materials, both natural ones and those we engineer, are usually a complex mixture of compositional and structural heterogeneities, interfaces, and disorder across all spatial and temporal scales. It is the fluctuations and disorderly states of these heterogeneities and interfaces that often determine the system’s properties and functionality. Much of our fundamental scientific knowledge is based on “ideal” systems, meaning materials that are observed in “frozen” states or represented by spatially or temporally averaged states. Too often, this approach has yielded overly simplistic models that hide important nuances and do not capture the complex behaviors of materials under realistic conditions. These behaviors drive vital chemical transformations such as catalysis, which initiates most industrial manufacturing processes, and friction and corrosion, the parasitic effects of which cost the U.S. economy billions of dollars annually. Expanding our scientific knowledge from the relative simplicity of ideal, perfectly ordered, or structurally averaged materials to the true complexity of real-world heterogeneities, interfaces, and disorder should enable us to realize enormous benefits in the materials and chemical sciences, which translates to the energy sciences, including solar and nuclear power, hydraulic fracturing, power conversion, airframes, and batteries.\n\nHarnessing Coherence in Light and Matter\n\nQuantum coherence in light and matter is a measure of the extent to which a wave field vibrates in unison with itself at neighboring points in space and time. Although this phenomenon is expressed at the atomic and electronic scales, it can dominate the macroscopic properties of materials and chemical reactions such as superconductivity and efficient photosynthesis. In recent years, enormous progress has been made in recognizing, manipulating, and exploiting quantum coherence. This progress has already elucidated the role that symmetry plays in protecting coherence in key materials, taught us how to use light to manipulate atoms and molecules, and provided us with increasingly sophisticated techniques for controlling and probing the charges and spins of quantum coherent systems. With the arrival of new sources of coherent light and electron beams, thanks in large part to investments by the U.S. Department of Energy’s Office of Basic Energy Sciences (BES), there is now an opportunity to engineer coherence in heterostructures that incorporate multiple types of materials and to control complex, multistep chemical transformations. This approach will pave the way for quantum information processing and next-generation photovoltaic cells and sensors.\n\nRevolutionary Advances in Models, Mathematics, Algorithms, Data, and Computing\n\nScience today is benefiting from a convergence of theoretical, mathematical, computational, and experimental capabilities that put us on the brink of greatly accelerating our ability to predict, synthesize, and control new materials and chemical processes, and to understand the complexities of matter across a range of scales. Imagine being able to chart a path through a vast sea of possible new materials to find a select few with desired properties. Instead of the time-honored forward approach, in which materials with desired properties are found through either trial-and-error experiments or lucky accidents, we have the opportunity to inversely design and create new materials that possess the properties we desire. The traditional approach has allowed us to make only a tiny fraction of all the materials that are theoretically possible. The inverse design approach, through the harmonious convergence of theoretical, mathematical, computational, and experimental capabilities, could usher in a virtual cornucopia of new materials with functionalities far beyond what nature can provide. Similarly, enhanced mathematical and computational capabilities significantly enhance our ability to extract physical and chemical insights from vastly larger data streams gathered during multimodal and multidimensional experiments using advanced characterization facilities.\n\nExploiting Transformative Advances in Imaging Capabilities across Multiple Scales\n\nHistorically, improvements in imaging capabilities have always resulted in improved understanding of scientific phenomena. A prime challenge today is finding ways to reconstruct raw data, obtained by probing and mapping matter across multiple scales, into analyzable images. BES investments in new and improved imaging facilities, most notably synchrotron x-ray sources, free-electron lasers, electron microscopes, and neutron sources, have greatly advanced our powers of observation, as have substantial improvements in laboratory- scale technologies. Furthermore, BES is now planning or actively discussing exciting new capabilities. Taken together, these advances in imaging capabilities provide an opportunity to expand our ability to observe and study matter from the 3D spatial perspectives of today to true “4D” spatially and temporally resolved maps of dynamics that allow quantitative predictions of time-dependent material properties and chemical processes. The knowledge gained will impact data storage, catalyst design, drug delivery, structural materials, and medical implants, to name just a few key technologies.\n\nENABLING SUCCESS\n\nSeizing each of these five Transformative Opportunities, as well as accelerating further progress on Grand Challenge research, will require specific, targeted investments from BES in the areas of synthesis, meaning the ability to make the materials and architectures that are envisioned; instrumentation and tools, a category that includes theory and computation; and human capital, the most important asset for advancing the Grand Challenges and Transformative Opportunities. While “Challenges at the Frontiers of Matter and Energy: Transformative Opportunities for Discovery Science” could be viewed as a sequel to the original Grand Challenges report, it breaks much new ground in its assessment of the scientific landscape today versus the scientific landscape just a few years ago. In the original Grand Challenges report, it was noted that if the five Grand Challenges were met, our ability to direct matter and energy would be measured only by the limits of human imagination. This new report shows that, prodded by those challenges, the scientific community is positioned today to seize new opportunities whose impacts promise to be transformative for science and society, as well as dramatically accelerate progress in the pursuit of the original Grand Challenges.\n\nControlling Subsurface Fractures and Fluid Flow: A Basic Research Agenda\n\nFrom beneath the surface of the earth, we currently obtain about 80-percent of the energy our nation consumes each year. In the future we have the potential to generate billions of watts of electrical power from clean, green, geothermal energy sources. Our planet’s subsurface can also serve as a reservoir for storing energy produced from intermittent sources such as wind and solar, and it could provide safe, long-term storage of excess carbon dioxide, energy waste products and other hazardous materials. However, it is impossible to underestimate the complexities of the subsurface world. These complexities challenge our ability to acquire the scientific knowledge needed for the efficient and safe exploitation of its resources.\n\nTo more effectively harness subsurface resources while mitigating the impacts of developing and using these resources, the U.S. Department of Energy established SubTER – the Subsurface Technology and Engineering RD&D Crosscut team. This DOE multi-office team engaged scientists and engineers from the national laboratories to assess and make recommendations for improving energy-related subsurface engineering. The SubTER team produced a plan with the overall objective of “adaptive control of subsurface fractures and fluid flow.”This plan revolved around four core technological pillars—Intelligent Wellbore Systems that sustain the integrity of the wellbore environment; Subsurface Stress and Induced Seismicity programs that guide and optimize sustainable energy strategies while reducing the risks associated with subsurface injections; Permeability Manipulation studies that improve methods of enhancing, impeding and eliminating fluid flow; and New Subsurface Signals that transform our ability to see into and characterize subsurface systems.\n\nThe SubTER team developed an extensive R&D plan for advancing technologies within these four core pillars and also identified several areas where new technologies would require additional basic research. In response, the Office of Science, through its Office of Basic Energy Science (BES), convened a roundtable consisting of 15 national lab, university and industry geoscience experts to brainstorm basic research areas that underpin the SubTER goals but are currently\n\nunderrepresented in the BES research portfolio. Held in Germantown, Maryland on May 22, 2015, the round-table participants developed a basic research agenda that is detailed in this report.\n\nHighlights include the following:\n\nA grand challenge calling for advanced imaging of stress and geological processes to help understand how stresses and chemical substances are distributed in the subsurface—knowledge that is critical to all aspects of subsurface engineering;\n\nA priority research direction aimed at achieving control of fluid flow through fractured media;\n\nA priority research direction aimed at better understanding how mechanical and geochemical perturbations to subsurface rock systems are coupled through fluid and mineral interactions;\n\nA priority research direction aimed at studying the structure, permeability, reactivity and other properties of nanoporous rocks, like shale, which have become critical energy materials and exhibit important hallmarks of mesoscale materials;\n\nA cross-cutting theme that would accelerate development of advanced computational methods to describe heterogeneous time-dependent geologic systems that could, among other potential benefits, provide new and vastly improved models of hydraulic fracturing and its environmental impacts;\n\nA cross-cutting theme that would lead to the creation of “geo-architected materials” with controlled repeatable heterogeneity and structure that can be tested under a variety of thermal, hydraulic, chemical and mechanical conditions relevant to subsurface systems;\n\nA cross-cutting theme calling for new laboratory studies on both natural and geo-architected subsurface materials that deploy advanced high-resolution 3D imaging and chemical analysis methods to determine the ;rates and mechanisms of fluid-rock processes, and to test predictive models of such phenomena.\n\nMany of the key energy challenges of the future demand a greater understanding of the subsurface world in all of its complexity. This greater under- standing will improve the ability to control and manipulate the subsurface world in ways that will benefit both the economy and the environment. This report provides specific basic research pathways to address some of the most fundamental issues of energy-related subsurface engineering.\n\nFuture of Electron Scattering and Diffraction\n\nThe ability to correlate the atomic- and nanoscale-structure of condensed matter with physical properties (e.g., mechanical, electrical, catalytic, and optical) and functionality forms the core of many disciplines. Directing and controlling materials at the quantum-, atomic-, and molecular-levels creates enormous challenges and opportunities across a wide spectrum of critical technologies, including those involving the generation and use of energy. The workshop identified next generation electron scattering and diffraction instruments that are uniquely positioned to address these grand challenges. The workshop participants identified four key areas where the next generation of such instrumentation would have major impact:\n\nA – Multidimensional Visualization of Real Materials\n\nB – Atomic-scale Molecular Processes\n\nC – Photonic Control of Emergence in Quantum Materials\n\nD – Evolving Interfaces, Nucleation, and Mass Transport\n\nReal materials are comprised of complex three-dimensional arrangements of atoms and defects that directly determine their potential for energy applications. Understanding real materials requires new capabilities for three-dimensional atomic scale tomography and spectroscopy of atomic and electronic structures with unprecedented sensitivity, and with simultaneous spatial and energy resolution. Many molecules are able to selectively and efficiently convert sunlight into other forms of energy, like heat and electric current, or store it in altered chemical bonds. Understanding and controlling such process at the atomic scale require unprecedented time resolution. One of the grand challenges in condensed matter physics is to understand, and ultimately control, emergent phenomena in novel quantum materials that necessitate developing a new generation of instruments that probe the interplay among spin, charge, orbital, and lattice degrees of freedom with intrinsic time- and length-scale resolutions. Molecules and soft matter require imaging and spectroscopy with high spatial resolution without damaging their structure. The strong interaction of electrons with matter allows high-energy electron pulses to gather structural information before a sample is damaged.\n\nImaging, diffraction, and spectroscopy are the fundamental capabilities of electron-scattering instruments. The DOE BES-funded TEAM (Transmission Electron Aberration-corrected Microscope) project achieved unprecedented sub-atomic spatial resolution in imaging through aberration-corrected transmission electron microscopy. To further advance electron scattering techniques that directly enable groundbreaking science, instrumentation must advance beyond traditional two-dimensional imaging. Advances in temporal resolution, recording the full phase and energy spaces, and improved spatial resolution constitute a new frontier in electron microscopy, and will directly address the BES Grand Challenges, such as to “control the emergent properties that arise from the complex correlations of atomic and electronic constituents” and the “hidden states” “very far away from equilibrium”. Ultrafast methods, such as the pump-probe approach, enable pathways toward understanding, and ultimately controlling, the chemical dynamics of molecular systems and the evolution of complexity in mesoscale and nanoscale systems. Central to understanding how to synthesize and exploit functional materials is having the ability to apply external stimuli (such as heat, light, a reactive flux, and an electrical bias) and to observe the resulting dynamic process in situ and in operando, and under the appropriate environment (e.g., not limited to UHV conditions).\n\nTo enable revolutionary advances in electron scattering and science, the participants of the workshop recommended three major new instrumental developments:\n\nA. Atomic-Resolution Multi-Dimensional Transmission Electron Microscope: This instrument would provide quantitative information over the entire real space, momentum space, and energy space for visualizing dopants, interstitials, and light elements; for imaging localized vibrational modes and the motion of charged particles and vacancies; for correlating lattice, spin, orbital, and charge; and for determining the structure and molecular chemistry of organic and soft matter. The instrument will be uniquely suited to answer fundamental questions in condensed matter physics that require understanding the physical and electronic structure at the atomic scale. Key developments include stable cryogenic capabilities that will allow access to emergent electronic phases, as well as hard/soft interfaces and radiation- sensitive materials.\n\nB. Ultrafast Electron Diffraction and Microscopy Instrument: This instrument would be capable of nano-diffraction with 10 fs temporal resolution in stroboscopic mode, and better than 100 fs temporal resolution in single shot mode. The instrument would also achieve single- shot real-space imaging with a spatial/temporal resolution of 10 nm/10 ps, representing a thousand fold improvement over current microscopes. Such a capability would be complementary to x-ray free electron lasers due to the difference in the nature of electron and x-ray scattering, enabling space-time mapping of lattice vibrations and energy transport, facilitating the understanding of molecular dynamics of chemical reactions, the photonic control of emergence in quantum materials, and the dynamics of mesoscopic materials.\n\nC. Lab-In-Gap Dynamic Microscope: This instrument would enable quantitative measurements of materials structure, composition, and bonding evolution in technologically relevant environments, including liquids, gases and plasmas, thereby assuring the understanding of structure function relationship at the atomic scale with up to nanosecond temporal resolution. This instrument would employ a versatile, modular sample stage and holder geometry to allow the multi-modal (e.g., optical, thermal, mechanical, electrical, and electrochemical) probing of materials’ functionality in situ and in operando. The electron optics encompasses a pole piece that can accommodate the new stage, differential pumping, detectors, aberration correctors, and other electron optical elements for measurement of materials dynamics.\n\nTo realize the proposed instruments in a timely fashion, BES should aggressively support research and development of complementary and enabling instruments, including new electron sources, advanced electron optics, new tunable specimen pumps and sample stages, and new detectors. The proposed instruments would have transformative impact on physics, chemistry, materials science, engineering\n\nX-ray Optics for BES Light Source Facilities\n\nEach new generation of synchrotron radiation sources has delivered an increase in average brightness 2 to 3 orders of magnitude over the previous generation. The next evolution toward diffraction-limited storage rings will deliver another 3 orders of magnitude increase. For ultrafast experiments, free electron lasers (FELs) deliver 10 orders of magnitude higher peak brightness than storage rings. Our ability to utilize these ultrabright sources, however, is limited by our ability to focus, monochromate, and manipulate these beams with X-ray optics. X-ray optics technology unfortunately lags behind source technology and limits our ability to maximally utilize even today’s X-ray sources. With ever more powerful X-ray sources on the horizon, a new generation of X-ray optics must be developed that will allow us to fully utilize these beams of unprecedented brightness.\n\nThe increasing brightness of X-ray sources will enable a new generation of measurements that could have revolutionary impact across a broad area of science, if optical systems necessary for transporting and analyzing X-rays can be perfected. The high coherent flux will facilitate new science utilizing techniques in imaging, dynamics, and ultrahigh-resolution spectroscopy. For example, zone-plate-based hard X-ray microscopes are presently used to look deeply into materials, but today’s resolution and contrast are restricted by limitations of the current lithography used to manufacture nanodiffractive optics. The large penetration length, combined in principle with very high spatial resolution, is an ideal probe of hierarchically ordered mesoscale materials, if zone-plate focusing systems can be improved. Resonant inelastic X-ray scattering (RIXS) probes a wide range of excitations in materials, from charge-transfer processes to the very soft excitations that cause the collective phenomena in correlated electronic systems. However, although RIXS can probe high-energy excitations, the most exciting and potentially revolutionary science involves soft excitations such as magnons and phonons; in general, these are well below the resolution that can be probed by today’s optical systems. The study of these low-energy excitations will only move forward if advances are made in high-resolution gratings for the soft X-ray energy region, and higher-resolution crystal analyzers for the hard X-ray region. In almost all the forefront areas of X-ray science today, the main limitation is our ability to focus, monochromate, and manipulate X-rays at the level required for these advanced measurements.\n\nTo address these issues, the U.S. Department of Energy (DOE) Office of Basic Energy Sciences (BES) sponsored a workshop, X-ray Optics for BES Light Source Facilities, which was held March 27–29, 2013, near Washington, D.C. The workshop addressed a wide range of technical and organizational issues. Eleven working groups were formed in advance of the meeting and sought over several months to define the most pressing problems and emerging opportunities and to propose the best routes forward for a focused R&D program to solve these problems. The workshop participants identified eight principal research directions (PRDs), as follows:\n\nDevelopment of advanced grating lithography and manufacturing for high-energy resolution techniques such as soft X-ray inelastic scattering.\n\nDevelopment of higher-precision mirrors for brightness preservation through the use of advanced metrology in manufacturing, improvements in manufacturing techniques, and in mechanical mounting and cooling.\n\nDevelopment of higher-accuracy optical metrology that can be used in manufacturing, verification, and testing of optomechanical systems, as well as at wavelength metrology that can be used for quantification of individual optics and alignment and testing of beamlines.\n\nDevelopment of an integrated optical modeling and design framework that is designed and maintained specifically for X-ray optics.\n\nDevelopment of nanolithographic techniques for improved spatial resolution and efficiency of zone plates.\n\nDevelopment of large, perfect single crystals of materials other than silicon for use as beam splitters, seeding monochromators, and high-resolution analyzers.\n\nDevelopment of improved thin-film deposition methods for fabrication of multilayer Laue lenses and high-spectral-resolution multilayer gratings.\n\nDevelopment of supports, actuator technologies, algorithms, and controls to provide fully integrated and robust adaptive X-ray optic systems.\n\nDevelopment of fabrication processes for refractive lenses in materials other than silicon.\n\nThe workshop participants also addressed two important nontechnical areas: our relationship with industry and organization of optics within the light source facilities. Optimization of activities within these two areas could have an important effect on the effectiveness and efficiency of our overall endeavor. These are crosscutting managerial issues that we identified as areas that needed further in-depth study, but they need to be coordinated above the individual facilities.\n\nFinally, an issue that cuts across many of the optics improvements listed above is routine access to beamlines that ideally are fully dedicated to optics research and/or development. The success of the BES X-ray user facilities in serving a rapidly increasing user community has led to a squeezing of beam time for vital instrumentation activities. Dedicated development beamlines could be shared with other R&D activities, such as detector programs and novel instrument development.\n\nIn summary, to meet the challenges of providing the highest-quality X-ray beams for users and to fully utilize the high-brightness sources of today and those that are on the horizon, it will be critical to make strategic investments in X-ray optics R&D. This report can provide guidance and direction for effective use of investments in the field of X-ray optics and potential approaches to develop a better-coordinated program of X-ray optics development within the suite of BES synchrotron radiation facilities. Due to the importance and complexity of the field, the need for tight coordination between BES light source facilities and with industry, as well as the rapid evolution of light source capabilities the workshop participants recommend holding similar workshops at least biannually.\n\nNeutron and X-ray Detectors\n\nThe Basic Energy Sciences (BES) X-ray and neutron user facilities attract more than 12,000 researchers each year to perform cutting-edge science at these state-of-the-art sources. While impressive breakthroughs in X-ray and neutron sources give us the powerful illumination needed to peer into the nano- to mesoscale world, a stumbling block continues to be the distinct lag in detector development, which is slowing progress toward data collection and analysis. Urgently needed detector improvements would reveal chemical composition and bonding in 3-D and in real time, allow researchers to watch “movies” of essential life processes as they happen, and make much more efficient use of every X-ray and neutron produced by the source\n\nThe immense scientific potential that will come from better detectors has triggered worldwide activity in this area. Europe in particular has made impressive strides, outpacing the United States on several fronts. Maintaining a vital U.S. leadership in this key research endeavor will require targeted investments in detector R&D and infrastructure.\n\nTo clarify the gap between detector development and source advances, and to identify opportunities to maximize the scientific impact of BES user facilities, a workshop on Neutron and X-ray Detectors was held August 1-3, 2012, in Gaithersburg, Maryland. Participants from universities, national laboratories, and commercial organizations from the United States and around the globe participated in plenary sessions, breakout groups, and joint open-discussion summary sessions.\n\nSources have become immensely more powerful and are now brighter (more particles focused onto the sample per second) and more precise (higher spatial, spectral, and temporal resolution). To fully utilize these source advances, detectors must become faster, more efficient, and more discriminating. In supporting the mission of today’s cutting-edge neutron and X-ray sources, the workshop identified six detector research challenges (and two computing hurdles that result from the corresponding increase in data volume) for the detector community to overcome in order to realize the full potential of BES neutron and X-ray facilities.\n\nResolving these detector impediments will improve scientific productivity both by enabling new types of experiments, which will expand the scientific breadth at the X-ray and neutron facilities, and by potentially reducing the beam time required for a given experiment. These research priorities are summarized in the table below. Note that multiple, simultaneous detector improvements are often required to take full advantage of brighter sources.\n\nHigh-efficiency hard X-ray sensors: The fraction of incident particles that are actually detected defines detector efficiency. Silicon, the most common direct-detection X-ray sensor material, is (for typical sensor thicknesses) 100% efficient at 8 keV, 25%efficient at 20 keV, and only 3% efficient at 50 keV. Other materials are needed for hard X-rays.\n\nReplacement for 3He for neutron detectors: 3He has long been the neutron detection medium of choice because of its high cross section over a wide neutron energy range for the reaction 3He + n —> 3H + 1H + 0.764 MeV. 3He stockpiles are rapidly dwindling, and what is available can be had only at prohibitively high prices. Doped scintillators hold promise as ways to capture neutrons and convert them into light, although work is needed on brighter, more efficient scintillator solutions. Neutron detectors also require advances in speed and resolution.\n\nFast-framing X-ray detectors: Today’s brighter X-ray sources make time-resolved studies possible. For example, hybrid X-ray pixel detectors, initially developed for particle physics, are becoming fairly mature X-ray detectors, with considerable development in Europe. To truly enable time-resolved studies, higher frame rates and dynamic range are required, and smaller pixel sizes are desirable.\n\nHigh-speed spectroscopic X-ray detectors: Improvements in the readout speed and energy resolution of X-ray detectors are essential to enable chemically sensitive microscopies. Advances would make it possible to take images with simultaneous spatial and chemical information.\n\nVery high-energy-resolution X-ray detectors: The energy resolution of semiconductor detectors, while suitable for a wide range of applications, is far less than what can be achieved with X-ray optics. A direct detector that could rival the energy resolution of optics could dramatically improve the efficiency of a multitude of experiments, as experiments are often repeated at a number of different energies. Very high-energy-resolution detectors could make these experiments parallel, rather than serial.\n\nLow-background, high-spatial-resolution neutron detectors: Low-background detectors would significantly improve experiments that probe excitations (phonons, spin excitations, rotation, and diffusion in polymers and molecular substances, etc.) in condensed matter. Improved spatial resolution would greatly benefit radiography, tomography, phase-contrast imaging, and holography.\n\nImproved acquisition and visualization tools: In the past, with the limited variety of slow detectors, it was straightforward to visualize data as it was being acquired (and adjust experimental conditions accordingly) to create a compact data set that the user could easily transport. As detector complexity and data rates explode, this becomes much more challenging. Three goals were identified as important for coping with the growing data volume from high-speed detectors:\n\nFacilitate better algorithm development. In particular, algorithms that can minimize the quantity of data stored.\n\nImprove community-driven mechanisms to reduce data protocols and enhance quantitative, interactive visualization tools.\n\nDevelop and distribute community-developed, detector-specific simulation tools.\n\nAim for parallelization to take advantage of high-performance analysis platforms.\n\nImproved analysis work flows: Standardize the format of metadata that accompanies detector data and describes the experimental setup and conditions. Develop a standardized user interface and software framework for analysis and data management.\n\nThe diversity of detector improvements required is necessarily as broad as the range of scientific experimentation at BES facilities. This workshop identified a variety of avenues by which detector R&D can enable enhanced science at BES facilities. The Research Directions listed above will be addressed by focused R&D and detector engineering, both of which require specialized infrastructure and skills. While U.S. leadership in neutron and X-ray detectors lags behind other countries in several areas, significant talent exists across the complex. A forum of technical experts, facilities management, and BES could be a venue to provide further definition.\n\nFrom Quanta to the Continuum: Opportunities for Mesoscale Science\n\nWe are at a time of unprecedented challenge and opportunity. Our economy is in need of a jump start, and our supply of clean energy needs to dramatically increase. Innovation through basic research is a key means for addressing both of these challenges. The great scientific advances of the last decade and more, especially at the nanoscale, are ripe for exploitation. Seizing this key opportunity requires mastering the mesoscale, where classical, quantum, and nanoscale science meet. It has become clear that—in many important areas—the functionality that is critical to macroscopic behavior begins to manifest itself not at the atomic or nanoscale but at the mesoscale, where defects, interfaces, and non-equilibrium structures are the norm. With our recently acquired knowledge of the rules of nature that govern the atomic and nanoscales, we are well positioned to unravel and control the complexity that determines functionality at the mesoscale. The reward for breakthroughs in our understanding at the mesoscale is the emergence of previously unrealized functionality. The present report explores the opportunity and defines the research agenda for mesoscale science—discovering, understanding, and controlling interactions among disparate systems and phenomena to reach the full potential of materials complexity and functionality. The ability to predict and control mesoscale phenomena and architectures is essential if atomic and molecular knowledge is to blossom into a next generation of technology opportunities, societal benefits, and scientific advances.\n\nMesoscale science and technology opportunities build on the enormous foundation of nanoscience that the scientific community has created over the last decade and continues to create. New features arise naturally in the transition to the mesoscale, including the emergence of collective behavior; the interaction of disparate electronic, mechanical, magnetic, and chemical phenomena; the appearance of defects, interfaces and statistical variation; and the self assembly of functional composite systems. The mesoscale represents a discovery laboratory for finding new science, a self-assembly foundry for creating new functional systems, and a design engine for new technologies.\n\nThe last half-century and especially the last decade have witnessed a remarkable drive to ever smaller scales, exposing the atomic, molecular, and nanoscale structures that anchor the macroscopic materials and phenomena we deal with every day. Given this knowledge and capability, we are now starting the climb up from the atomic and nanoscale to the greater complexity and wider horizons of the mesoscale. The constructionist path up from atomic and nanoscale to mesoscale holds a different kind of promise than the reductionist path down: it allows us to re-arrange the nanoscale building blocks into new combinations, exploit the dynamics and kinetics of these new coupled interactions, and create qualitatively different mesoscale architectures and phenomena leading to new functionality and ultimately new technology. The reductionist journey to smaller length and time scales gave us sophisticated observational tools and intellectual understanding that we can now apply with great advantage to the wide opportunity of mesoscale science following a bottom-up approach.\n\nRealizing the mesoscale opportunity requires advances not only in our knowledge but also in our ability to observe, characterize, simulate, and ultimately control matter. Mastering mesoscale materials and phenomena requires the seamless integration of theory, modeling, and simulation with synthesis and characterization. The inherent complexity of mesoscale phenomena, often including many nanoscale structural or functional units, requires theory and simulation spanning multiple space and time scales. In mesoscale architectures the positions of individual atoms are often no longer relevant, requiring new simulation approaches beyond density functional theory and molecular dynamics that are so successful at atomic scales. New organizing principles that describe emergent mesoscale phenomena arising from many coupled and competing degrees of freedom wait to be discovered and applied. Measurements that are dynamic, in situ, and multimodal are needed to capture the sequential phenomena of composite mesoscale materials. Finally, the ability to design and realize the complex materials we imagine will require qualitative advances in how we synthesize and fabricate materials and how we manage their metastability and degradation over time. We must move from serendipitous to directed discovery, and we must master the art of assembling structural and functional nanoscale units into larger architectures that create a higher level of complex functional systems.\n\nWhile the challenge of discovering, controlling, and manipulating complex mesoscale architectures and phenomena to realize new functionality is immense, success in the pursuit of these research directions will have outcomes with the potential to transform society. The body of this report outlines the need, the opportunities, the challenges, and the benefits of mastering mesoscale science.\n\nData and Communications in Basic Energy Sciences: Creating a Pathway for Scientific Discovery\n\nThis report is based on the Department of Energy (DOE) Workshop on “Data and Communications in Basic Energy Sciences: Creating a Pathway for Scientific Discovery” that was held at the Bethesda Marriott in Maryland on October 24-25, 2011. The workshop brought together leading researchers from the Basic Energy Sciences (BES) facilities and Advanced Scientific Computing Research (ASCR). The workshop was co-sponsored by these two Offices to identify opportunities and needs for data analysis, ownership, storage, mining, provenance and data transfer at light sources, neutron sources, microscopy centers and other facilities.\n\nTheir charge was to identify current and anticipated issues in the acquisition, analysis, communication and storage of experimental data that could impact the progress of scientific discovery, ascertain what knowledge, methods and tools are needed to mitigate present and projected shortcomings and to create the foundation for information exchanges and collaboration between ASCR and BES supported researchers and facilities.\n\nThe workshop was organized in the context of the impending data tsunami that will be produced by DOE’s BES facilities. Current facilities, like SLAC National Accelerator Laboratory’s Linac Coherent Light Source, can produce up to 18 terabytes (TB) per day, while upgraded detectors at Lawrence Berkeley National Laboratory’s Advanced Light Source will generate ~10TB per hour. The expectation is that these rates will increase by over an order of magnitude in the coming decade. The urgency to develop new strategies and methods in order to stay ahead of this deluge and extract the most science from these facilities was recognized by all. The four focus areas addressed in this workshop were:\n\nWorkflow Management - Experiment to Science: Identifying and managing the data path from experiment to publication.\n\nTheory and Algorithms: Recognizing the need for new tools for computation at scale, supporting large data sets and realistic theoretical models.\n\nVisualization and Analysis: Supporting near-real-time feedback for experiment optimization and new ways to extract and communicate critical information from large data sets.\n\nData Processing and Management: Outlining needs in computational and communication approaches and infrastructure needed to handle unprecedented data volume and information content.\n\nIt should be noted that almost all participants recognized that there were unlikely to be any turn-key solutions available due to the unique, diverse nature of the BES community, where research at adjacent beamlines at a given light source facility often span everything from biology to materials science to chemistry using scattering, imaging and/or spectroscopy. However, it was also noted that advances supported by other programs in data research, methodologies, and tool development could be implemented on reasonable time scales with modest effort. Adapting available standard file formats, robust workflows, and in-situ analysis tools for user facility needs could pay long-term dividends.\n\nWorkshop participants assessed current requirements as well as future challenges and made the following recommendations in order to achieve the ultimate goal of enabling transformative science in current and future BES facilities:\n\nTheory and analysis components should be integrated seamlessly within experimental workflow.\n\nDevelop new algorithms for data analysis based on common data formats and toolsets.\n\nMove analysis closer to experiment.\n\nMove the analysis closer to the experiment to enable real-time (in-situ) streaming capabilities, live visualization of the experiment and an increase of the overall experimental efficiency.\n\nMatch data management access and capabilities with advancements in detectors and sources.\n\nRemove bottlenecks, provide interoperability across different facilities/beamlines and apply forefront mathematical techniques to more efficiently extract science from the experiments.\n\nThis workshop report examines and reviews the status of several BES facilities and highlights the successes and shortcomings of the current data and communication pathways for scientific discovery. It then ascertains what methods and tools are needed to mitigate present and projected data bottlenecks to science over the next 10 years. The goal of this report is to create the foundation for information exchanges and collaborations among ASCR and BES supported researchers, the BES scientific user facilities, and ASCR computing and networking facilities.\n\nTo jumpstart these activities, there was a strong desire to see a joint effort between ASCR and BES along the lines of the highly successful Scientific Discovery through Advanced Computing (SciDAC) program in which integrated teams of engineers, scientists and computer scientists were engaged to tackle a complete end-to-end workflow solution at one or more beamlines, to ascertain what challenges will need to be addressed in order to handle future increases in data\n\nResearch Needs and Impacts in Predictive Simulation for Internal Combustion Engines (PreSICE)\n\nThis report is based on a SC/EERE Workshop to Identify Research Needs and Impacts in Predictive Simulation for Internal Combustion Engines (PreSICE), held March 3, 2011, to determine strategic focus areas that will accelerate innovation in engine design to meet national goals in transportation efficiency.\n\nThe U.S. has reached a pivotal moment when pressures of energy security, climate change, and economic competitiveness converge. Oil prices remain volatile and have exceeded $100 per barrel twice in five years. At these prices, the U.S. spends $1 billion per day on imported oil to meet our energy demands. Because the transportation sector accounts for two-thirds of our petroleum use, energy security is deeply entangled with our transportation needs. At the same time, transportation produces one-quarter of the nation’s carbon dioxide output. Increasing the efficiency of internal combustion engines is a technologically proven and cost-effective approach to dramatically improving the fuel economy of the nation’s fleet of vehicles in the near- to mid-term, with the corresponding benefits of reducing our dependence on foreign oil and reducing carbon emissions. Because of their relatively low cost, high performance, and ability to utilize renewable fuels, internal combustion engines—including those in hybrid vehicles—will continue to be critical to our transportation infrastructure for decades. Achievable advances in engine technology can improve the fuel economy of automobiles by over 50% and trucks by over 30%. Achieving these goals will require the transportation sector to compress its product development cycle for cleaner, more efficient engine technologies by 50% while simultaneously exploring innovative design space. Concurrently, fuels will also be evolving, adding another layer of complexity and further highlighting the need for efficient product development cycles. Current design processes, using “build and test” prototype engineering, will not suffice. Current market penetration of new engine technologies is simply too slow—it must be dramatically accelerated.\n\nThese challenges present a unique opportunity to marshal U.S. leadership in science-based simulation to develop predictive computational design tools for use by the transportation industry. The use of predictive simulation tools for enhancing combustion engine performance will shrink engine development timescales, accelerate time to market, and reduce development costs, while ensuring the timely achievement of energy security and emissions targets and enhancing U.S. industrial competitiveness.\n\nIn 2007 Cummins achieved a milestone in engine design by bringing a diesel engine to market solely with computer modeling and analysis tools. The only testing was after the fact to confirm performance. Cummins achieved a reduction in development time and cost. As important, they realized a more robust design, improved fuel economy, and met all environmental and customer constraints. This important first step demonstrates the potential for computational engine design. But, the daunting complexity of engine combustion and the revolutionary increases in efficiency needed require the development of simulation codes and computation platforms far more advanced than those available today.\n\nBased on these needs, a Workshop to Identify Research Needs and Impacts in Predictive Simulation for Internal Combustion Engines (PreSICE) convened over 60 U.S. leaders in the engine combustion field from industry, academia, and national laboratories to focus on two critical areas of advanced simulation, as identified by the U.S. automotive and engine industries. First, modern engines require precise control of the injection of a broad variety of fuels that is far more subtle than achievable to date and that can be obtained only through predictive modeling and simulation. Second, the simulation, understanding, and control of these stochastic in-cylinder combustion processes lie on the critical path to realizing more efficient engines with greater power density. Fuel sprays set the initial conditions for combustion in essentially all future transportation engines; yet today designers primarily use empirical methods that limit the efficiency achievable. Three primary spray topics were identified as focus areas in the workshop:\n\nThe fuel delivery system, which includes fuel manifolds and internal injector flow,\n\nThe multi-phase fuel–air mixing in the combustion chamber of the engine, and\n\nThe heat transfer and fluid interactions with cylinder walls.\n\nCurrent understanding and modeling capability of stochastic processes in engines remains limited and prevents designers from achieving significantly higher fuel economy. To improve this situation, the workshop participants identified three focus areas for stochastic processes:\n\nImprove fundamental understanding that will help to establish and characterize the physical causes of stochastic events,\n\nDevelop physics-based simulation models that are accurate and sensitive enough to capture performance-limiting variability, and\n\nQuantify and manage uncertainty in model parameters and boundary conditions.\n\nImproved models and understanding in these areas will allow designers to develop engines with reduced design margins and that operate reliably in more efficient regimes. All of these areas require improved basic understanding, high-fidelity model development, and rigorous model validation. These advances will greatly reduce the uncertainties in current models and improve understanding of sprays and fuel–air mixture preparation that limit the investigation and development of advanced combustion technologies.\n\nThe two strategic focus areas have distinctive characteristics but are inherently coupled. Coordinated activities in basic experiments, fundamental simulations, and engineering-level model development and validation can be used to successfully address all of the topics identified in the PreSICE workshop. The outcome will be:\n\nNew and deeper understanding of the relevant fundamental physical and chemical processes in advanced combustion technologies,\n\nImplementation of this understanding into models and simulation tools appropriate for both exploration and design, and\n\nSufficient validation with uncertainty quantification to provide confidence in the simulation results.\n\nThese outcomes will provide the design tools for industry to reduce development time by up to 30% and improve engine efficiencies by 30% to 50%. The improved efficiencies applied to the national mix of transportation applications have the potential to save over 5 million barrels of oil per day, a current cost savings of $500 million per day.\n\nJPG\n\nReport\n\nReport of the Basic Energy Sciences Workshop on Compact Light Sources\n\nThis report is based on a BES Workshop on Compact Light Sources, held May 11-12, 2010, to evaluated the advantages and disadvantages of compact light source approaches and compared their performance to the third generation storage rings and free-electron lasers. The workshop examined the state of the technology for compact light sources and their expected progress. The workshop evaluated the cost efficiency, user access, availability, and reliability of such sources. Working groups evaluated the advantages and disadvantages of Compact Light Source (CLS) approaches, and compared their performance to the third-generation storage rings and free-electron lasers (FELs). The primary aspects of comparison were 1) cost effectiveness, 2) technical availability v. time frame, and 3) machine reliability and availability for user access. Five categories of potential sources were analyzed: 1) inverse Compton scattering (ICS) sources, 2) mini storage rings, 3) plasma sources, 4) sources using plasma-based accelerators, and 5) laser high harmonic generation (HHG) sources.\n\nCompact light sources are not a substitute for large synchrotron and FEL light sources that typically also incorporate extensive user support facilities. Rather they offer attractive, complementary capabilities at a small fraction of the cost and size of large national user facilities. In the far term they may offer the potential for a new paradigm of future national user facility. In the course of the workshop, we identified overarching R&D topics over the next five years that would enhance the performance potential of both compact and large-scale sources:\n\nDevelopment of infrared (IR) laser systems delivering kW-class average power with femtosecond pulses at kHz repetition rates. These have application to ICS sources, plasma sources, and HHG sources.\n\nDevelopment of laser storage cavities for storage of 10-mJ picosecond and femtosecond pulses focused to micron beam sizes.\n\nDevelopment of high-brightness, high-repetition-rate electron sources.\n\nDevelopment of continuous wave (cw) superconducting rf linacs operating at 4 K, while not essential, would reduce capital and operating cost.\n\nBasic Research Needs for Carbon Capture: Beyond 2020\n\nThis report is based on a SC/FE workshop on Carbon Capture: Beyond 2020, held March 4–5, 2010, to assess the basic research needed to address the current technical bottlenecks in carbon capture processes and to identify key research priority directions that will provide the foundations for future carbon capture technologies.\n\nThe problem of thermodynamically efficient and scalable carbon capture stands as one of the greatest challenges for modern energy researchers. The vast majority of US and global energy use derives from fossil fuels, the combustion of which results in the emission of carbon dioxide into the atmosphere. These anthropogenic emissions are now altering the climate. Although many alternatives to combustion are being considered, the fact is that combustion will remain a principal component of the global energy system for decades to come. Today’s carbon capture technologies are expensive and cumbersome and energy intensive. If scientists could develop practical and cost-effective methods to capture carbon, those methods would at once alter the future of the largest industry in the world and provide a technical solution to one of the most vexing problems facing humanity.\n\nThe carbon capture problem is a true grand challenge for today’s scientists. Postcombustion CO2 capture requires major new developments in disciplines spanning fundamental theoretical and experimental physical chemistry, materials design and synthesis, and chemical engineering. To start with, the CO2 molecule itself is thermodynamically stable and binding to it requires a distortion of the molecule away from its linear and symmetric arrangement. This binding of the gas molecule cannot be too strong, however; the sheer quantity of CO2 that must be captured ultimately dictates that the capture medium must be recycled over and over. Hence the CO2 once bound, must be released with relatively little energy input. Further, the CO2 must be rapidly and selectively pulled out of a mixture that contains many other gaseous components. The related processes of precombustion capture and oxycombustion pose similar challenges. It is this nexus of high-speed capture with high selectivity and minimal energy loss that makes this a true grand challenge problem, far beyond any of today’s artificial molecular manipulation technologies, and one whose solution will drive the advancement of molecular science to a new level of sophistication.\n\nWe have only to look to nature, where such chemical separations are performed routinely, to imagine what may be achieved. The hemoglobin molecule transports oxygen in the blood rapidly and selectively and releases it with minimal energy penalty. Despite our improved understanding of how this biological system works, we have yet to engineer a molecular capture system that uses the fundamental cooperativity process that lies at the heart of the functionality of hemoglobin. While such biological examples provide inspiration, we also note that newly developed theoretical and computational capabilities; the synthesis of new molecules, materials, and membranes; and the remarkable advances in characterization techniques enabled by the Department of Energy’s measurement facilities all create a favorable environment for a major new basic research push to solve the carbon capture problem within the next decade.\n\nThe Department of Energy has established a comprehensive strategy to meet the nation’s needs in the carbon capture arena. This framework has been developed following a series of workshops that have engaged all the critical stakeholder communities. The strategy that has emerged is based upon a tiered approach, with Fossil Energy taking the lead in a series of applied research programs that will test and extend our current systems. ARPA-E (Advanced Research Projects Agency–Energy) is supporting potential breakthroughs based upon innovative proposals to rapidly harness today’s technical capabilities in ways not previously considered. These needs and plans have been well summarized in the report from a recent workshop—Carbon Capture 2020, held in October 5 and 6, 2009—focused on near-term strategies for carbon capture improvements (http://www.netl.doe.gov/publications/ proceedings/09/CC2020/pdfs/Richards_Summary.pdf ). Yet the fact remains that when the carbon capture problem is looked at closely, we see today’s technologies fall far short of making carbon capture an economically viable process. This situation reinforces the need for a parallel, intensive use-inspired basic research effort to address the problem. This was the overwhelming conclusion of a recent workshop—Carbon Capture: Beyond 2020, held March 4 and 5, 2010—and is the subject of the present report. To prepare for the second workshop, an in-depth assessment of current technologies for carbon capture was conducted; the result of this study was a factual document, Technology and Applied R&D Needs for Carbon Capture: Beyond 2020. This document, which was prepared by experts in current carbon capture processes, also summarized the technological gaps or bottlenecks that limit currently available carbon capture technologies. The report considered the separation processes needed for all three CO2 emission reduction strategies—postcombustion, precombustion, and oxycombustion—and assessed three primary separation technologies based on liquid absorption, membranes, and solid adsorption.\n\nThe workshop “Carbon Capture: Beyond 2020” convened approximately 80 attendees from universities, national laboratories, and industry to assess the basic research needed to address the current technical bottlenecks in carbon capture processes and to identify key research priority directions that will provide the foundations for future carbon capture technologies. The workshop began with a plenary session including speakers who summarized the extent of the carbon capture challenge, the various current approaches, and the limitations of these technologies. Workshop attendees were then given the charge to identify high-priority basic research directions that could provide revolutionary new concepts to form the basis for separation technologies in 2020 and beyond. The participants were divided into three major panels corresponding to different approaches for separating gases to reduce carbon emissions—liquid absorption, solid adsorption, and membrane separations. Two other panels were instructed to attend each of these three technology panels to assess crosscutting issues relevant to characterization and computation. At the end of the workshop, a final plenary session was convened to summarize the most critical research needs identified by the workshop attendees in each of the three major technical panels and from the two cross-cutting panels.\n\nThe reports of the three technical panels included a set of high level Priority Research Directions meant to serve as inspiration to researchers in multiple disciplines—materials science, chemistry, biology, computational science, engineering, and others—to address the huge scientific challenges facing this nation and the world as we seek technologies for large-scale carbon capture beyond 2020. These Priority Research Directions were clustered around three main areas, all tightly coupled:\n\nUnderstand and control the dynamic atomic-level and molecular-level interactions of the targeted species with the separation media.\n\nDiscover and design new materials that incorporate designed structures and functionalities tuned for optimum separation properties.\n\nTailor capture/release processes with alternative driving forces, taking advantage of a new generation of materials.\n\nIn each of the technical panels, the participants identified two major crosscutting research themes. The first was the development of new analytical tools that can characterize materials structure and molecular processes across broad spatial and temporal scales and under realistic conditions that mimic those encountered in actual separation processes. Such tools are needed to examine interfaces and thin films at the atomic and molecular levels, achieving an atomic/molecular-scale understanding of gas–host structures, kinetics, and dynamics, and understanding and control of nanoscale synthesis in multiple dimensions. A second major crosscutting theme was the development of new computational tools for theory, modeling, and simulation of separation processes. Computational techniques can be used to elucidate mechanisms responsible for observed separations, predict new desired features for advanced separations materials, and guide future experiments, thus complementing synthesis and characterization efforts. These two crosscut areas underscored the fact that the challenge for future carbon capture technologies will be met only with multidisciplinary teams of scientists and engineers. In addition, it was noted that success in this fundamental research area must be closely coupled with successful applied research to ensure the continuing assessment and maturation of new technologies as they undergo scale-up and deployment.\n\nCarbon capture is a very rich scientific problem, replete with opportunity for basic researchers to advance the frontiers of science as they engage on one of the most important technical challenges of our times. This workshop report outlines an ambitious agenda for addressing the very difficult problem of carbon capture by creating foundational new basic science. This new science will in turn pave the way for many additional advances across a broad range of scientific disciplines and technology sectors.\n\nComputational Materials Science and Chemistry: Accelerating Discovery and Innovation through Simulation-Based Engineering and Science\n\nThis report is based on a SC Workshop on Computational Materials Science and Chemistry for Innovation on July 26-27, 2010, to assess the potential of state-of-the-art computer simulations to accelerate understanding and discovery in materials science and chemistry, with a focus on potential impacts in energy technologies and innovation.\n\nThe urgent demand for new energy technologies has greatly exceeded the capabilities of today's materials and chemical processes. To convert sunlight to fuel, efficiently store energy, or enable a new generation of energy production and utilization technologies requires the development of new materials and processes of unprecedented functionality and performance. New materials and processes are critical pacing elements for progress in advanced energy systems and virtually all industrial technologies.\n\nOver the past two decades, the United States has developed and deployed the world's most powerful collection of tools for the synthesis, processing, characterization, and simulation and modeling of materials and chemical systems at the nanoscale, dimensions of a few atoms to a few hundred atoms across. These tools, which include world-leading x-ray and neutron sources, nanoscale science facilities, and high-performance computers, provide an unprecedented view of the atomic-scale structure and dynamics of materials and the molecular-scale basis of chemical processes. For the first time in history, we are able to synthesize, characterize, and model materials and chemical behavior at the length scale where this behavior is controlled. This ability is transformational for the discovery process and, as a result, confers a significant competitive advantage.\n\nPerhaps the most spectacular increase in capability has been demonstrated in high performance computing. Over the past decade, computational power has increased by a factor of a million due to advances in hardware and software. This rate of improvement, which shows no sign of abating, has enabled the development of computer simulations and models of unprecedented fidelity.\n\nWe are at the threshold of a new era where the integrated synthesis, characterization, and modeling of complex materials and chemical processes will transform our ability to understand and design new materials and chemistries with predictive power. In turn, this predictive capability will transform technological innovation by accelerating the development and deployment of new materials and processes in products and manufacturing.\n\nHarnessing the potential of computational science and engineering for the discovery and development of materials and chemical processes is essential to maintaining leadership in these foundational fields that underpin energy technologies and industrial competitiveness. Capitalizing on the opportunities presented by simulation-based engineering and science in materials and chemistry will require an integration of experimental capabilities with theoretical and computational modeling; the development of a robust and sustainable infrastructure to support the development and deployment of advanced computational models; and the assembly of a community of scientists and engineers to implement this integration and infrastructure. This community must extend to industry, where incorporating predictive materials science and chemistry into design tools can accelerate the product development cycle and drive economic competitiveness.\n\nThe confluence of new theories, new materials synthesis capabilities, and new computer platforms has created an unprecedented opportunity to implement a \"materials-by-design\" paradigm with wide-ranging benefits in technological innovation and scientific discovery. The Workshop on Computational Materials Science and Chemistry for Innovation was convened in Bethesda, Maryland, on July 26-27, 2010. Sponsored by the Department of Energy (DOE) Offices of Advanced Scientific Computing Research and Basic Energy Sciences, the workshop brought together 160 experts in materials science, chemistry, and computational science representing more than 65 universities, laboratories, and industries, and four agencies.\n\nThe workshop examined seven foundational challenge areas in materials science and chemistry: materials for extreme conditions, self-assembly, light harvesting, chemical reactions, designer fluids, thin films and interfaces, and electronic structure. Each of these challenge areas is critical to the development of advanced energy systems, and each can be accelerated by the integrated application of predictive capability with theory and experiment.\n\nThe workshop concluded that emerging capabilities in predictive modeling and simulation have the potential to revolutionize the development of new materials and chemical processes. Coupled with world-leading materials characterization and nanoscale science facilities, this predictive capability provides the foundation for an innovation ecosystem that can accelerate the discovery, development, and deployment of new technologies, including advanced energy systems. Delivering on the promise of this innovation ecosystem requires the following:\n\nIntegration of synthesis, processing, characterization, theory, and simulation and modeling. Many of the newly established Energy Frontier Research Centers and Energy Hubs are exploiting this integration.\n\nAchieving/strengthening predictive capability in foundational challenge areas. Predictive capability in the seven foundational challenge areas described in this report is critical to the development of advanced energy technologies.\n\nDeveloping validated computational approaches that span vast differences in time and length scales. This fundamental computational challenge crosscuts all of the foundational challenge areas. Similarly challenging is coupling of analytical data from multiple instruments and techniques that are required to link these length and time scales.\n\nExperimental validation and quantification of uncertainty in simulation and modeling. Uncertainty quantification becomes increasingly challenging as simulations become more complex.\n\nRobust and sustainable computational infrastructure, including software and applications. For modeling and simulation, software equals infrastructure. To validate the computational tools, software is critical infrastructure that effectively translates huge arrays of experimental data into useful scientific understanding. An integrated approach for managing this infrastructure is essential.\n\nEfficient transfer and incorporation of simulation-based engineering and science in industry. Strategies for bridging the gap between research and industrial applications and for widespread industry adoption of integrated computational materials engineering are needed.\n\nNew Science for a Secure and Sustainable Energy Future\n\nThis Basic Energy Sciences Advisory Committee (BESAC) report summarizes a 2008 study by the Subcommittee on Facing our Energy Challenges in a New Era of Science to: (1) assimilate the scientific research directions that emerged from the BES Basic Research Needs workshop reports into a comprehensive set of science themes, and (2) identify the new implementation strategies and tools required to accomplish the science.\n\nThe United States faces a three-fold energy challenge:\n\nEnergy Independence. U.S. energy use exceeds domestic production capacity by the equivalent of 16 million barrels of oil per day, a deficit made up primarily by importing oil and natural gas. This deficit has nearly tripled since 1970.\n\nEnvironmental Sustainability. The United States must reduce its emissions of carbon dioxide and other greenhouse gases that accelerate climate change. The primary source of these emissions is combustion of fossil fuel, comprising about 85% of U.S. national energy supply.\n\nEconomic Opportunity. The U.S. economy is threatened by the high cost of imported energy—as much as $700 billion per year at recent peak prices. We need to create next-generation clean energy technologies that do not depend on imported oil. U.S. leadership would not only provide solutions at home but also create global economic opportunity.\n\nThe magnitude of the challenge is so immense that existing energy approaches—even with improvements from advanced engineering and improved technology based on known concepts—will not be enough to secure our energy future. Instead, meeting the challenge will require new technologies for producing, storing and using energy with performance levels far beyond what is now possible. Such technologies spring from scientific breakthroughs in new materials and chemical processes that govern the transfer of energy between light, electricity and chemical fuels. Integrating a major national mobilization of basic energy research—to create needed breakthroughs—with appropriate investments in technology and engineering to accelerate bringing new energy solutions to market will be required to meet our three-fold energy challenge. This report identifies three strategic goals for which transformational scientific breakthroughs are urgently needed:\n\nMaking fuels from sunlight\n\nGenerating electricity without carbon dioxide emissions\n\nRevolutionizing energy efficiency and use\n\nMeeting these goals implies dramatic changes in our technologies for producing and consuming energy. We will manufacture chemical fuel from sunlight, water and carbon dioxide instead of extracting it from the earth. We will generate electricity from sunlight, wind, and high-efficiency clean coal and advanced nuclear plants instead of conventional coal and nuclear technology. Our cars and light trucks will be driven by efficient electric motors powered by a new generation of batteries and fuel cells.\n\nThese new, advanced energy technologies, however, require new materials and control of chemical change that operate at dramatically higher levels of functionality and performance. Converting sunlight to electricity with double or triple today's efficiency, storing electricity in batteries or supercapacitors at ten times today's densities, or operating coal-fired and nuclear power plants at far higher temperatures and efficiencies requires materials with atom by atom design and control, tailored nanoscale structures where every atom has a specific function. Such high performing materials would have complexity far higher than today's energy materials, approaching that of biological cells and proteins. They would be able to seamlessly control the ebb and flow of energy between chemical bonds, electrons, and light, and would be the foundation of the alternative energy technologies of the future.\n\nCreating these advanced materials and chemical processes requires characterizing the structure and dynamics of matter at levels beyond our present reach. The physical and chemical phenomena that capture, store and release energy take place at the nanoscale, often involving subtle changes in single electrons or atoms, on timescales faster than we can now resolve. Penetrating the secrets of energy transformation between light, chemical bonds, and electrons requires new observational tools capable of probing the still-hidden realms of the ultrasmall and ultrafast. Observing the dynamics of energy flow in electronic and molecular systems at these resolutions is necessary if "
    }
}