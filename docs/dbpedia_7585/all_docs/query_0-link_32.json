{
    "id": "dbpedia_7585_0",
    "rank": 32,
    "data": {
        "url": "https://arxiv.org/html/2312.03014v1",
        "read_more_link": "",
        "language": "en",
        "title": "Foundation Models for Weather and Climate Data Understanding: A Comprehensive Survey",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/x1.png",
            "https://arxiv.org/html/x2.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Foundation Models",
            "Weather & Climate Analysis",
            "Deep Learning",
            "Time Series",
            "Spatio-Temporal data",
            "Earth System."
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.\n\nfailed: mdwmath\n\nfailed: mdwtab\n\nfailed: eqparbox\n\nfailed: utfsym\n\nfailed: forest\n\nAuthors: achieve the best HTML results from your LaTeX submissions by selecting from this list of supported packages.\n\nLicense: arXiv.org perpetual non-exclusive license\n\narXiv:2312.03014v1 [cs.LG] 05 Dec 2023\n\nFoundation Models for Weather and Climate Data Understanding: A Comprehensive Survey\n\nShengchao Chen, Guodong Long, Jing Jiang, Dikai Liu, and Chengqi Zhang Shengchao Chen, Guodong Long, Jing Jiang, and Chengqi Zhang are with the Australian Artificial Intelligence Institute, School of Computer Science, Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW, 2007, Australia. (Email: pavelchen@ieee.org, guodong.long@uts.edu.au, jing.jiang@uts.edu.au, chengqi.zhang@uts.edu.au)Dikai Liu is with the Robotics Institute, University of Technology Sydney, Sydney, NSW, 2007, Australia. (Email: dikai.liu@uts.edu.au) Corresponding Author: guodong.long@uts.edu.au (Guodong Long) Github-https://github.com/shengchaochen82/Awesome-Large-Models-for-Weather-and-Climate. Survey Version Dec. 4, 2023.\n\nAbstract\n\n{justify}\n\nAs artificial intelligence (AI) continues to rapidly evolve, the realm of Earth and atmospheric sciences is increasingly adopting data-driven models, powered by progressive developments in deep learning (DL). Specifically, DL techniques are extensively utilized to decode the chaotic and nonlinear aspects of Earth systems, and to address climate challenges via understanding weather and climate data. Cutting-edge performance on specific tasks within narrower spatio-temporal scales has been achieved recently through DL. The rise of large models, specifically large language models (LLMs), has enabled fine-tuning processes that yield remarkable outcomes across various downstream tasks, thereby propelling the advancement of general AI. However, we are still navigating the initial stages of crafting general AI for weather and climate. In this survey, we offer an exhaustive, timely overview of state-of-the-art AI methodologies specifically engineered for weather and climate data, with a special focus on time series and text data. Our primary coverage encompasses four critical aspects: types of weather and climate data, principal model architectures, model scopes and applications, and datasets for weather and climate. Furthermore, in relation to the creation and application of foundation models for weather and climate data understanding, we delve into the field’s prevailing challenges, offer crucial insights, and propose detailed avenues for future research. This comprehensive approach equips practitioners with the requisite knowledge to make substantial progress in this domain. Our survey encapsulates the most recent breakthroughs in research on large, data-driven models for weather and climate data understanding, emphasizing robust foundations, current advancements, practical applications, crucial resources, and prospective research opportunities.\n\nIndex Terms:\n\nFoundation Models, Weather & Climate Analysis, Deep Learning, Time Series, Spatio-Temporal data, Earth System.\n\n1 Introduction\n\nConcept 1.\n\nWeather and Climate are distinct concepts with notable differences in spatial and temporal scales, variability, and predictability. The dissimilarities between the two can be elucidated as follows:\n\n•\n\nTemporal Scale. Weather pertains to the immediate state of atmospheric conditions, typically within a short-term timeframe. Conversely, climate represents a statistical summary of long-term weather patterns.\n\n•\n\nSpatial Scale. Weather represents atmospheric conditions at a specific location, whereas climate encompasses a comprehensive summary of typical weather patterns within a region over an extended period.\n\n•\n\nVariability. Weather exhibits rapid and frequent changes, while climate change occurs at a slower pace and encompasses long-term shifts in weather patterns.\n\n•\n\nPredictability. Weather prediction focuses on forecasting weather conditions in the next few days or shorter time scales. In contrast, climate prediction aims to forecast climate trends over the following months to decades.\n\nClimate change delineates noticeable alterations in global temperature and weather patterns over protracted periods. Currently, our planet is experiencing a proliferation in extreme natural phenomena, such as droughts [1, 2], floods [1], earthquakes [3], heatwaves [4], and intense rainfall [5], propelled by escalating climate change. Further amplifying these challenges are the alarming threats to ecosystems from mounting global warming and sea-level reductions [6, 7]. Given the projected augmentation in surface temperatures this century, we foresee an intensification in the harshness and frequency of these extreme phenomena [8].\n\nLeveraging advanced climate modeling and prediction techniques, which integrate a plethora of atmospheric and surface variables - encompassing atmospheric conditions, ocean currents, terrestrial ecosystems, and biosphere interactions - can enhance our comprehension of climate change [9, 10]. These insights can guide the formulation of bespoke mitigation strategies [11]. Long-term, accurate predictions of sea level changes can strengthen urban planning and disaster preparedness in coastal cities [12, 13, 14]. In the short term, precise forecasts of rainfall, temperature, and humidity can heighten the safety of human activities, including agricultural planning and transportation scheduling [15, 16, 17].\n\nTraditionally, general circulation models (GCMs) [18] and numerical weather prediction models (NWPs) [19, 20, 21] have been favored tools for studying climate change trends and predicting future weather and climate scenarios. These models assimilate major Earth system components, including the atmosphere, surface, and oceans, to emulate the multidimensional dynamics of the Earth system. They identify potential nonlinear correlations between these components through complex physical equations, such as atmospheric dynamics, to generate predictions within a wide spectrum of physical parameters [22]. However, despite their considerable maturation, numerically constrained weather prediction models still encounter numerous challenges and limitations. One of these is their oversimplified representation of local geographical features [23], as they often fail to capture the intricate nuances of local topography, which exerts a critical influence on regional weather and climate patterns. Another obstacle is the effective integration of observational data from disparate sources, such as weather stations, radars, and satellites [8]. Traditional models often struggle with incorporating these data, with varying spatial and temporal resolutions, into their modeling frameworks. Moreover, they require substantial computational resources to manage the myriad of physical constraints [24]. The complexity and scale of the Earth system demand extensive calculations, presenting challenges to computational capacity and efficiency.\n\nThe rapid advancement of AI technology has introduced cost-effective, direct, and simplified solution strategies for weather and cliamte modeling. In particular, Machine Learning (ML) and Deep Learning (DL) technologies can discern potential trend representations in weather and climate data, bypassing the need for intricate physical relationships. Initially, ML techniques were sparingly used for short-term, localized forecasts of weather and climate conditions, given their limited capabilities compared with large-scale, time-extensive physical models. However, the past decade has witnessed an exponential surge in the application of data-driven deep learning methods in weather and climate research, propelled by the explosive expansion of global weather and climate data [25, 26]. Capitalizing on abundant data resources and advancements in computational technology [27, 28], these models are revolutionizing climate science [29]. Employing voluminous data, deep learning models unravel the intricate nonlinear relationships concealed within climate variables, thereby capturing the dynamism and complexity of the climate system with enhanced precision [30, 31]. However, these models are often designed for specific tasks and trained with data in particular formats, such as regional weather forecasting or downscaling on a microscale. Differences in the representations of training data sources have resulted in an overly compartmentalized functionality of data-driven deep learning models for understanding weather and climate data. Consequently, it poses a significant challenge to develop a versatile climate model that can be fine-tuned for simulating the global weather and climate system.\n\nThe recent emergence and swift advancement of large models have yielded significant gains across various fields, including natural language processing (NLP), computer vision (CV) [32], robotics [33], and a range of interdisciplinary areas encompassing life sciences [34, 35, 36, 37, 38]. Particularly in the NLP field, large models, or large language models (LLMs), are evolving rapidly, trained on large-scale corpora and fine-tuned for various downstream tasks [39, 40, 41]. In computer vision, large vision models trained on substantial natural images [42, 43, 44] demonstrate exceptional zero-shot capabilities [45, 46]. The impressive performance of these models across tasks arises from their substantial parameter counts and large-scale pre-training data. For instance, GPT-3 [47, 48] possesses nearly 120 times the parameters of GPT-2 [49], enabling it to learn more powerfully from fewer samples, while GPT-4 [50] has less than ten times the parameters of GPT-3, yet excels in text generation and image understanding. The rapid ascension of LLMs has redefined the path forward for deep learning, despite long-standing developments in areas such as unsupervised/semi-supervised and transfer learning. A notable example is the vision-language large model [51, 46, 52, 53], such as CLIP [46], which is trained on numerous natural image-text pairs and fine-tuned to achieve promising results in tasks like image segmentation [54, 55, 56] and video subtitle generation [57, 58]. Recently, the extension of large models into domains such as speech [59, 60], physics [61], and mathematical analysis [62] has catalyzed advancements in fundamental science and specialized areas.\n\nThe groundbreaking success of pre-trained foundation models has propelled the domains of NLP and CV significantly closer to the realization of versatile AI. This advancement prompts an intriguing question: The success of pre-trained foundation models has allowed the fields of NLP and CV to take a meaningful step towards realizing general-purpose AI, which not only leads one to wonder: Is it possible to develop a universal foundation model for weather and climate data understanding that effectively addresses a myriad of related tasks?\n\nBuilding upon the theory of pre-trained models, ClimaX[25] introduces an innovative approach towards the development of a weather and climate base model. It leverages the Transformer to pre-train large-scale weather and climate data, yielding a flexible foundation model proficient in short- to medium-term forecasting,, climate projection, and downscaling. Both PanGu-Weather [63] and W-MAE [64] exhibit robust climate prediction capabilities by modeling the global climate system using copious data. However, the quest for large-scale, universal climate models faces significant obstacles. A primary challenge is the scarcity of large, diverse, and high-quality training datasets. Existing datasets (refer to Table. IV for more details) struggle with inconsistent measurements, spatial-temporal biases, and limited functionality, hampering the progression of all-encompassing, multipurpose large-scale foundation models. Additionally, the computational demands of these models add another dimension of complexity, with the required infrastructure potentially unachievable in resource-limited settings. Ideally, a weather/climate foundation model should seamlessly handle multi-source observations and incorporate detailed representations of geographic features to generate more precise simulations of weather and climate trends. Unfortunately, this remains a largely uncharted territory for current weather and climate base models. Moreover, the interpretability of these models, often perceived as ”black boxes,” is a significant concern. In tasks related to weather and climate, where erroneous predictions can wreak havoc on ecosystems and societies, the need for interpretability is especially accentuated[65, 66, 36]. Despite the remarkable strides and potential in understanding weather and climate data, the distinct challenges associated with the development of large-scale foundation models, as outlined above, necessitate concentrated research (refer to Sec. 9 for more details). This emphasizes the need for a thorough review of advancements in this nascent field.\n\nIn this paper, we conduct a comprehensive review of data-driven models explicitly designed for weather and climate data. Our survey encompasses a wide array of large foundation models/task-specific models spanning various data types, model architectures, application domains, and representative tasks. This review amplifies the scope of insights derived from weather and climate data, encouraging novel strategies and fostering the cross-application of large models in the weather and climate. By leveraging the power of DL in large-scale models, we aim to reveal complex climate patterns, augment predictions, and deepen our comprehension of the climate system, thereby empowering society to more effectively adapt to the challenges posed by climate change. Our contributions are summarized as follows:\n\n•\n\nFirst Comprehensive and Contemporary Survey. To the best of our knowledge, this paper constitutes the inaugural comprehensive survey that thoroughly encapsulates the state-of-the-art developments of large, and task-specific models for weather and climate data understanding, spanning across time series, video streams, and text sequences. We furnish an in-depth and current panorama that covers the broad spectrum of the domain, simultaneously delving into the subtleties of distinct methodologies, thereby providing the reader with a comprehensive and current apprehension of this field.\n\n•\n\nSystematic and In-depth Categorization. We introduce and discuss an organized and detailed categorization, dividing existing related research into two main categories: large climate foundation models and task-specific climate models. Furthermore, we further classify them based on the underlying model architectures, including RNNs, Transformers, GANs, Diffusion models, and Graph Neural Networks. Subsequent divisions are made based on the models’ application domains and specific tasks, with detailed explanations of these task definitions. This multidimensional categorization provides readers with a coherent roadmap.\n\n•\n\nAbundant Resource Compilation. e have assembled a substantial collection of datasets and open-source implementations pertinent to the field of weather and climate science. Each dataset is supplemented with an exhaustive description of its structure, pertinent tasks, and direct hyperlinks for expedient access. This compilation serves as an invaluable resource for prospective research and developmental endeavors in the domain.\n\n•\n\nFuture Outlook and Research Opportunities. We have delineated several promising trajectories for future exploration. These viewpoints span across various domains, including data post-processing, model architectures, interpretability, privacy, and training paradigms, among others. This discourse equips the readers with an intricate understanding of the current status of the field and potential avenues for future exploration.\n\n•\n\nInsights for Designing. We discuss and pinpoint crucial design elements for promising weather and climate foundation models. These design components incorporate the selection of temporal and spatial scales, dataset choice, data representation and model design, learning strategies, and evaluation schemes. Adherence to this systematic design pipeline enables practitioners to rapidly comprehend the design principles and construct robust weather and climate foundation models, thereby fostering the expeditious advancement of the weather and climate domain.\n\nPaper Organization. The remainder of this survey is structured as follows: Section 2 delineates the distinctions between our survey and other corresponding studies. Section 3 instills the reader with fundamental knowledge on foundational models, primary depictions of weather and climate data, and related tasks. Section 4 expounds upon the core architecture of paramount models for weather and climate tasks. Section 6, we present a synopsis of the principal model classifications currently in use for weather and climate tasks, encompassing climate basic models and task-specific models. This section furnishes a holistic view of the field prior to probing into the complexities of individual methodologies. Section 5 imparts a concise introduction to climate basic models and task-specific models, further stratifying task-specific models based on dissimilar model architectures. Subsequently, Section 7 undertakes an extensive exploration of data-driven deep learning models for specific weather and climate tasks. Considering the lack of a unified and comprehensive index for weather and climate datasets, Section 8 presents an exhaustive collection of dataset resources and introductions, aiming to impart convenience and efficiency for readers. Section 9 delineates the challenges currently impeding the evolution of weather and climate basic models, as well as prospective future directions in this field. Section 10 proposes a potential blueprint for the construction of weather and meteorological basic models, aiding contemplation and execution by practitioners, and fostering the development of climate foundation models. Finally, Sec. 11 provides a summary and concluding remarks on the content of the survey.\n\n2 Related Work and Differences\n\nWhile numerous expansive surveys have been executed to model weather and climate-related data from various vantage points, none of them emphasize the broad-spectrum scope of weather data. For example, Ren et al.[31] undertook a survey on deep learning-based weather forecasting, focusing on neural network architecture design and spatial and temporal scales, yet it omitted models pertinent to the era of the weather data explosion. Both Fang et al.[67] and Jones et al.[71] reviewed deep learning-based weather forecasting within the confines of specific scenarios, namely extreme weather conditions and climate impacts on flood risk. Conversely, Bochenek et al.[68] and Jaseena et al.[74] exclusively addressed and summarized machine learning/deep learning-based works concerning ordinary time series. Chen et al.[70] provided a survey of machine learning methodologies in weather and climate, but the focus remained restricted to forecasting tasks. Furthermore, Molina et al.[72] primarily emphasized the application of machine learning in climate modeling, such as sources of predictability in climate variability models, feature detection, extreme weather and climate prediction, observational model integration, downscaling, and bias correction. Materia[8] primarily centered on reviewing literature that employed machine learning techniques for extreme weather detection and understanding. These aforementioned surveys lack thorough investigation into the applications of foundational models in weather data understanding. Mukkavilli et al.[73] discussed the application of large models to weather and climate tasks and the architectural design, which bears similarity to our endeavor, but does not include more detailed task-specific models and a wider range of data modalities. Globally, these surveys also lack a structured delineation and an exhaustive discussion of deep learning-based models for weather data understanding, as well as adequate resources (datasets, open-source models and tools, etc.) that are either not provided or are limited in their availability. Given the recent multiplication of large-scale models in domains such as vision[75, 45], audio [50], and text [56], our intention with this survey is to provide an exhaustive and up-to-date overview of large-scale models for weather data understanding, as well as a structured delineation, synthesis, and discussion of pertinent task-specific models, with the objective of establishing a robust foundation for the design of weather and climate base models. Our aim surpasses merely documenting recent advances; we also focus on available resources, practical applications, and potential research directions. Table. II encapsulates the discrepancies between our survey and other analogous reviews.\n\n3 Background and Preliminary\n\nThis study aims to review the recent progress in implementing data-driven models, with a primary emphasis on DL techniques, to address weather and climate tasks. The objective is to illuminate potential pathways for developing foundation models dedicated to weather and climate data understanding. We direct our attention towards two principal categories of models in the weather and climate domains: large-scale foundational models and task-specific models. In this section, we commence by discussing these two model types and elucidate their distinctions and connections. Subsequently, we delineate weather and climate-related data types and representative tasks across diverse domains. We conclude with an introduction to four prevalent base model architectures employed in weather and climate tasks.\n\n3.1 Foundation Models\n\nFoundation Models (FMs) originated as pre-trained LLMs with a broad capability to undertake a myriad of downstream tasks through fine-tuning strategies. These models constitute a versatile class, separate from task-specific models, due to their capacity to accommodate a range of downstream tasks and integrate heterogeneous representations. The prowess of FMs can be classified into two categories: (1) Cross-Modal Representation and (2) Reasoning and Interaction.\n\nCross-Modal Representation. his category involves multi-modal models, including vision-language models (VLMs)[51, 76, 46, 77]. These models merge and align linguistic and visual modalities, demonstrating a significant potential for modal unification. A prime example is CLIP (Contrastive Language-Image Pre-training)[46], which concurrently trains on text and image data using the contrastive learning method. It displays substantial Zero-Shot Learning (ZSL) and Few-Shot Learning (FSL) abilities on downstream tasks. Another innovative model, SAM (Segment Anything Model)[45], integrates the concept of prompting into visual tasks, yielding remarkable zero-shot segmentation performance. Models like InstructBLIP[78], CoCa[79], BEIT-3 [80], InstructGPT [81], and LLaMa [82, 83] further expand the reach of cross-modal foundation models, accommodating a broader spectrum of tasks and modal representations. In weather prediction and climate change applications, data typically exhibit large-scale and multimodal characteristics, such as radar observations [84, 85], satellite images [86], ground-based observatories [24, 87], and organized gridded data [88, 89, 90]. These characteristics provide impetus for the development of data-driven FMs for weather and climate tasks.\n\nReasoning and Interaction. FMs demonstrate exceptional reasoning and planning ablities, exemplified by models like CoT [91], ToT [92], and GoT [93], in addition to task planning agents. This category also involves interaction abilities, encompassing operations and communication. This study emphasizes the application of data-driven FMs for weather and climate tasks. Nonetheless, this area remains uncharted, offering abundant opportunities for innovation.\n\n3.2 Task-Specific Models\n\nContrary to previously mentioned FMs, the majority of DL models for weather and climate are mainly domain-specific (e.g., global/regional precipitation forecasting, extreme weather comprehension, climate model downscaling). This survey classifies these task-specific models into two categories based on the nature of task for time series: (1) Time Series-based Weather and Climate Analysis; (2) Spatio-Temporal Series-based Weather and Climate Analysis. We also delineate an area for climate text data: Climate Text Analysis Tasks.\n\nTime Series-based Weather and Climate Analysis. This category primarily comprises DL models for weather and climate analysis that leverage time series data. These models typically utilize weather time series data obtained from a single weather station to determine sequential relationships between one or multiple variables from past observations, thereby facilitating future trend predictions for specific weather variables.\n\nA classic example of a data-driven model for weather forecasting is the Auto Regressive Integrated Moving Average (ARIMA) [94], which enables non-stationary data to become stationary through a differencing operation, and subsequently employs a combination of auto-regression and moving averages to model the time series. Given the significant seasonality often present in weather data, such as fluctuations in temperature and rainfall, Seasonal ARIMA (SARIMA) [95] and Seasonal ARIMA with eXogenous variables (SARIMAX) [96] have been developed to model weather series, building upon seasonal auto-regression/moving average principles. Vector Autoregression (VAR) serves as an alternate method capable of modelling and predicting multiple correlated variables concurrently. Deep Learning-based models, such as families of Recurrent Neural Networks (RNNs) [97, 98, 99], convolutional neural network (CNN)-based architectures, and models based on the Transformer (e.g., Informer[100], Autoformer [101], Crossformer [102], ETSFormer [103], Reformer [104], FEDformer [105]), have exhibited superior performance when dealing with non-stationary time series. These models are particularly useful due to their lack of reliance on additional statistical knowledge and their efficiency in long-term forecasting.\n\nSpatio-Temporal Series-based Weather and Climate Analysis. Another focal area is DL models for weather and climate analysis that employ spatio-temporal series. Unlike time-series data, spatio-temporal data covers weather variable observations across multiple locations over time, allowing for the extraction of intricate spatio-temporal patterns. In this context, continuous radar echoes or satellite images that represent independent weather times are also considered as spatio-temporal sequences.\n\nData-driven models designed for analysing spatio-temporal series for weather and climate analysis are often required to capture both temporal and spatial correlations. For instance, the convolutional LSTM [97], a variant of the LSTM, incorporates convolutional operations to the LSTM to capture additional spatial correlations. 3D Convolutional Neural Networks (3D-CNNs) are frequently employed to consider spatio-temporal correlations of sequences simultaneously. Spatio-Temporal Graph Neural Networks [106], and other graph-based structures, effectively encode different spatial information into graphs that capture spatial correlations as well as temporal trends of weather variables. Transformer models utilize self-attention mechanisms to assess the importance of different locations and time points when making predictions [107]. Recent advancements in the field have also seen the exploration of generative AI, such as generative adversarial networks [108] and diffusion models [109], for weather prediction and climate change based on spatio-temporal sequences, owing to their excellent generative quality.\n\n3.3 Types of Weather and Climate Data\n\nInvestigations into weather and climate typically necessitate the exploration of both temporal and textual data. The primary objectives of these tasks involve discerning the relationships between historical weather patterns — often characterized by numerous meteorological variables — and future changes. This process also includes the extraction of specific features from textual sequences to aid detailed subsequent analysis. In these scenarios, our discussion mainly revolves around three primary data types: time series, spatio-temporal, and textual data. n the context of weather and climate analysis, time series can be broadly divided into two types: univariate and multivariate. A univariate time series might be represented by the daily mean temperature at a single observation point, while a multivariate time series may include daily precipitation and humidity data collected from the same observation point. Here, we first discuss the definition of univariate/multivariate time series. Formally, we follow the definitions of time series data in Ref. [110], which we summarize below.\n\nDefinition 3.1 (Time Series Data).\n\nFor a single point observation, a univariate time series sole weather variables (such as temperature) x={x1,x2,x3,…,xT}∈ℝTxsubscript𝑥1subscript𝑥2subscript𝑥3…subscript𝑥𝑇superscriptℝ𝑇{\\textnormal{x}}=\\{x_{1},x_{2},x_{3},...,x_{T}\\}\\in{\\mathbb{R}}^{T}x = { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT } ∈ blackboard_R start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT is a sequence of T𝑇Titalic_T time step indexed in time order, where xt∈ℝsubscript𝑥𝑡ℝx_{t}\\in{\\mathbb{R}}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ blackboard_R is the variable value of the time series at time t𝑡titalic_t. A multivariate time series including different climate variables (i.e., temperature, humidity, precipitation, etc.) 𝐗={x1,x2,x3,…,xT}∈ℝT×D𝐗subscriptx1subscriptx2subscriptx3…subscriptx𝑇superscriptℝ𝑇𝐷{\\mathbf{X}}=\\{{\\textnormal{x}}_{1},{\\textnormal{x}}_{2},{\\textnormal{x}}_{3},% ...,{\\textnormal{x}}_{T}\\}\\in{\\mathbb{R}}^{T\\times D}bold_X = { x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT } ∈ blackboard_R start_POSTSUPERSCRIPT italic_T × italic_D end_POSTSUPERSCRIPT is a sequence of T𝑇Titalic_T time steps indexed in time order but with D𝐷Ditalic_D dimensions (variables), in which x∈ℝDxsuperscriptℝ𝐷{\\textnormal{x}}\\in{\\mathbb{R}}^{D}x ∈ blackboard_R start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT denotes the values of the time series at time t𝑡titalic_t along D𝐷Ditalic_D channels.\n\nGlobal climate data are often represented as spatio-temporal series, i.e., chaotic correlations with both temporal (change trend) and spatial dimensions (geographic location). We define two distinct Spatio-Temporal Series: univerate spatio-temporal series and multivariate spatio-temporal series. They are both sequence of data points organized by both temporal and spatial dimensions.\n\nDefinition 3.2 (Spatio-Temporal Series).\n\nFor univerate spatio-temporal series, follow Definition 2.1, there exist N𝑁Nitalic_N points on the Earth system, at each point there exits a time series x={x1,x2,x3,…,xT}∈ℝTxsubscript𝑥1subscript𝑥2subscript𝑥3…subscript𝑥𝑇superscriptℝ𝑇{\\textnormal{x}}=\\{x_{1},x_{2},x_{3},...,x_{T}\\}\\in{\\mathbb{R}}^{T}x = { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT } ∈ blackboard_R start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT, where xt∈ℝsubscript𝑥𝑡ℝx_{t}\\in{\\mathbb{R}}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ blackboard_R, the spatio-temporal series is formulated as 𝑿u={x1,x2,x3,…,xN}∈ℝT×Nsubscript𝑿𝑢subscriptx1subscriptx2subscriptx3…subscriptx𝑁superscriptℝ𝑇𝑁{\\bm{X}}_{u}=\\{{\\textnormal{x}}_{1},{\\textnormal{x}}_{2},{\\textnormal{x}}_{3},% ...,{\\textnormal{x}}_{N}\\}\\in{\\mathbb{R}}^{T\\times N}bold_italic_X start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = { x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT } ∈ blackboard_R start_POSTSUPERSCRIPT italic_T × italic_N end_POSTSUPERSCRIPT. Similarly, for multivariate spatio-temporal sequences, the series can be formulated as 𝑿m⁢u={𝐗1,𝐗2,𝐗3,…,𝐗N}∈ℝT×D×Nsubscript𝑿𝑚𝑢subscript𝐗1subscript𝐗2subscript𝐗3…subscript𝐗𝑁superscriptℝ𝑇𝐷𝑁{\\bm{X}}_{mu}=\\{{\\mathbf{X}}_{1},{\\mathbf{X}}_{2},{\\mathbf{X}}_{3},...,{% \\mathbf{X}}_{N}\\}\\in{\\mathbb{R}}^{T\\times D\\times N}bold_italic_X start_POSTSUBSCRIPT italic_m italic_u end_POSTSUBSCRIPT = { bold_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_X start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , bold_X start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , bold_X start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT } ∈ blackboard_R start_POSTSUPERSCRIPT italic_T × italic_D × italic_N end_POSTSUPERSCRIPT, where 𝐗Nsubscript𝐗𝑁{\\mathbf{X}}_{N}bold_X start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT denote the multivariate time series at the N𝑁Nitalic_N space point.\n\nNotably that graph-based structure usually utilized to construct a spatio-temporal series, such as spatio-temporal graphs (STGs), temporal knowledge graphs (TKGs), video streams, and others. In this survey, we mainly focus above-mentioned classes, which are higly representative and align closely with the current spatio-temporal series-based weather forecasting and climate analysis tasks. And we follow the Ref. to define STGs and TKGs firstly, as follows.\n\nDefinition 3.3 (Spatio-Temporal Graphs).\n\nA spatio-temporal graph 𝒢={𝒢1,𝒢2,𝒢3,…,𝒢T}𝒢subscript𝒢1subscript𝒢2subscript𝒢3…subscript𝒢𝑇{\\mathcal{G}}=\\{{\\mathcal{G}}_{1},{\\mathcal{G}}_{2},{\\mathcal{G}}_{3},...,{% \\mathcal{G}}_{T}\\}caligraphic_G = { caligraphic_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , caligraphic_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , caligraphic_G start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , caligraphic_G start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT } denotes a sequence of T static graph snapshots (also named time steps) indexed in time order, in which 𝒢t=(𝒱t,ϵt)subscript𝒢𝑡subscript𝒱𝑡subscriptitalic-ϵ𝑡{\\mathcal{G}}_{t}=({\\mathcal{V}}_{t},{\\epsilon}_{t})caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( caligraphic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_ϵ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) presents a snapshot at t𝑡titalic_t-th time step; 𝒱tsubscript𝒱𝑡{\\mathcal{V}}_{t}caligraphic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and ϵtsubscriptitalic-ϵ𝑡{\\epsilon}_{t}italic_ϵ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT are sets of nodes and edges at time t𝑡titalic_t. The adjacent matrix represents the correlation between nodes in the graph and node feature matrices are defined as 𝐀t∈ℝN×Nsubscript𝐀𝑡superscriptℝ𝑁𝑁{\\mathbf{A}}_{t}\\in{\\mathbb{R}}^{N\\times N}bold_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_N × italic_N end_POSTSUPERSCRIPT and 𝐗t∈ℝN×Dsubscript𝐗𝑡superscriptℝ𝑁𝐷{\\mathbf{X}}_{t}\\in{\\mathbb{R}}^{N\\times D}bold_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_N × italic_D end_POSTSUPERSCRIPT, where 𝐀t={ai,jt}subscript𝐀𝑡superscriptsubscript𝑎𝑖𝑗𝑡{\\mathbf{A}}_{t}=\\{a_{i,j}^{t}\\}bold_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = { italic_a start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT } and ai,jt≠0superscriptsubscript𝑎𝑖𝑗𝑡0a_{i,j}^{t}\\neq 0italic_a start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ≠ 0 if there is an edge between node i𝑖iitalic_i and j𝑗jitalic_j. In addition, N=|𝒱t|𝑁subscript𝒱𝑡N=|{\\mathcal{V}}_{t}|italic_N = | caligraphic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | is the number of nodes and D𝐷Ditalic_D is the dimension of node features.\n\nDefinition 3.4 (Temporal Knowledge Graphs).\n\nFollow the definition of STGs, a temporal knowledge graph 𝒢={𝒢1,𝒢2,𝒢3,…,𝒢T}𝒢subscript𝒢1subscript𝒢2subscript𝒢3…subscript𝒢𝑇{\\mathcal{G}}=\\{{\\mathcal{G}}_{1},{\\mathcal{G}}_{2},{\\mathcal{G}}_{3},...,{% \\mathcal{G}}_{T}\\}caligraphic_G = { caligraphic_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , caligraphic_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , caligraphic_G start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , caligraphic_G start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT } is a sequence of T𝑇Titalic_T knowledge graph snapshots indexed in time order, where 𝒢t=(ϵt⁢m⁢ℛt)subscript𝒢𝑡subscriptitalic-ϵ𝑡𝑚subscriptℛ𝑡{\\mathcal{G}}_{t}=(\\epsilon_{t}m{\\mathcal{R}}_{t})caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( italic_ϵ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_m caligraphic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) is a snapshot consisting of the entity and relation sets at time t𝑡titalic_t. Specifically, ϵtsubscriptitalic-ϵ𝑡\\epsilon_{t}italic_ϵ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT encapsulates both subject and object entities, and ℛtsubscriptℛ𝑡{\\mathcal{R}}_{t}caligraphic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT presents the set of relations between them. In a temporal knowledge graph, entities and relations may posses different features, denoted by 𝐗∈ℝ|ϵt|×De𝐗superscriptℝsubscriptitalic-ϵ𝑡subscript𝐷𝑒{\\mathbf{X}}\\in{\\mathbb{R}}^{|\\epsilon_{t}|\\times D_{e}}bold_X ∈ blackboard_R start_POSTSUPERSCRIPT | italic_ϵ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | × italic_D start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT end_POSTSUPERSCRIPT and 𝐗tr∈ℝ|ℛ|×Drsuperscriptsubscript𝐗𝑡𝑟superscriptℝℛsubscript𝐷𝑟{\\mathbf{X}}_{t}^{r}\\in{\\mathbb{R}}^{|{\\mathcal{R}}|\\times D_{r}}bold_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT | caligraphic_R | × italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, where Desubscript𝐷𝑒D_{e}italic_D start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT and Drsubscript𝐷𝑟D_{r}italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT are feature dimensions.\n\nSpatio-temporal video streams belong to a species of spatio-temporal series, which are represented as regular spatial shapes and sequences organized in time order. In weather forecasting and climate analysis tasks, regional contiguous weather radar echoes and satellite images that symbolize specific climate events belong to this type, and we define spatio-temporal video streams based on the definition of spatio-temporal sequences as follows.\n\nDefinition 3.5 (Spatio-Temporal Video Streams).\n\nAssume a spatio-temporal video streams 𝑽={𝐅1,𝐅2,𝐅3,…,𝐅T}𝑽subscript𝐅1subscript𝐅2subscript𝐅3…subscript𝐅𝑇{\\bm{V}}=\\{{\\mathbf{F}}_{1},{\\mathbf{F}}_{2},{\\mathbf{F}}_{3},...,{\\mathbf{F}}% _{T}\\}bold_italic_V = { bold_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , bold_F start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , bold_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT } is a set of continue frames that cover T𝑇Titalic_T time steps indexed in time order, where 𝐅tsubscript𝐅𝑡{\\mathbf{F}}_{t}bold_F start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT denotes the t𝑡titalic_t-th frame (or time step). Each frame is viewed as a matrix of pixels can be formulated as 𝐅t∈ℝC×H×Wsubscript𝐅𝑡superscriptℝ𝐶𝐻𝑊{\\mathbf{F}}_{t}\\in{\\mathbb{R}}^{C\\times H\\times W}bold_F start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_C × italic_H × italic_W end_POSTSUPERSCRIPT, where C,H,W𝐶𝐻𝑊C,H,Witalic_C , italic_H , italic_W denote the channels, height, and width of the frame, respectively.\n\nDefinition 3.6 (Text Sequence).\n\nLet S𝑆Sitalic_S be a text sequence, where each element in the sequence represents a word or character. The text sequence can be represented as S={x1,x2,…,xn}𝑆subscript𝑥1subscript𝑥2…subscript𝑥𝑛S=\\{x_{1},x_{2},\\ldots,x_{n}\\}italic_S = { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }, where xisubscript𝑥𝑖x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents the i𝑖iitalic_i-th element in the sequence. The length of the text sequence, denoted as (N), can be defined as N=|S|𝑁𝑆N=|S|italic_N = | italic_S |, where |⋅||\\cdot|| ⋅ | represents the cardinality or number of elements in the sequence. Furthermore, each element in the text sequence can be represented as a one-hot encoded vector, denoted as X𝑋Xitalic_X. The one-hot encoded vector Xisubscript𝑋𝑖X_{i}italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for the i𝑖iitalic_i-th element in the sequence is a binary vector of length M𝑀Mitalic_M, where M𝑀Mitalic_M represents the total number of unique words or characters in the text corpus. The one-hot encoded vector Xisubscript𝑋𝑖X_{i}italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT has a value of 1 at the position corresponding to the index of the word or character in the vocabulary, and 0 elsewhere.\n\n3.4 Mainstream Tasks for Weather and Climate\n\nBased on the above definitions, we will present representative weather and climate analysis tasks associated with the above data types and structures.\n\n•\n\nWeather/Climate Time Series Tasks. Time series analysis forms the bedrock of weather and climate studies. Researchers frequently harness this methodology to extract meteorological trends from sequential data, projecting these tendencies onto multiple variable values across a specified temporal span for granular analysis. This overarching task encompasses three subtasks: Forecasting, Classification, and Imputation. In the forecasting task, the primary goal in to precisely predict a specific variable for a designated future temporal window grounded on historical observation. This task can be bifurcated, based on the magnitude of the prediction window, into short-term forecasting (typically spanning several hours to a few days) and long-term forecasting (generally a week or beyond). Short-term weather forecasting is often employed in immediate weather prediction and urban planning, whereas long-term forecasting predominantly serves climate studies, agriculture, and energy sectors. Subsequently, the classification task is aimed at mapping distinct meteorological phenomena, such as drought intensities, based on a historical chronology of atmospheric observations. Finally, the imputation task is structured to fill missing values in the series. This task exploits potential information embedded in the series, accounting for data gaps that might emanate from sensor malfunctions or severe climate events, among other factors.\n\n•\n\nGraph Structure-based Tasks. The mainstream task of graph structure-based for climate change is forecasting. We explore graph structure-based tasks in terms of both STGs and TKGs, as previously mentioned. STGs and TKGs is extensions for representing and reasoning about spatio-temporal information, fusing the relationships between time, space, and entities into a unified graph structure. Forecasting tasks aim to infer weather conditions at future spatio-temporal points based on historical observations and model predictions. Such tasks involve multiple variables, such as temperature, humidity, and barometric pressure, as well as temporal and spatial dimensions. The key challenges of spatio-temporal map prediction tasks are how to effectively capture and model spatio-temporal dependencies and how to cope with data uncertainty and missingness.\n\n•\n\nSpatio-Temporal Video Streams Tasks. Video data stands as a crucial asset in the examination of climate change and weather forecasting. In meteorological contexts, spatio-temporal video streams typically manifest as sequences of frames that depict weather fluctuations over a fixed period. These sequences may include regularly shaped radar images, satellite images, and other types of weather-related visual data. Therefore, the primary interest in spatio-temporal video stream data lies in prediction tasks—namely, the forecasting of future images based on a series of past consecutive frames. The quintessential task in this context involves the prediction of imminent rainfall based on radar echoes or the extrapolation of satellite imagery.\n\n•\n\nClimate Text Tasks. The analysis of climate textual data, or climate text analysis, aspires to distill significant patterns and insights. This process encapsulates several subtasks including Sentiment Analysis, Topic Modeling, Information Extraction, and Trend Analysis. Sentiment analysis endeavors to preceive the sentiment or perspectives encapsulated in cliamte text data (e.g., public perceptions of climate change). Topic modeling, conversely, strives to identify and classify the cardinal themes or subjects broached within climate texts, thereby fostering a comprehensive understanding of pivotal focus areas.Information extraction constitutes the extraction of specific details from climate texts, such as instances of extreme weather events or particulars of climate policy. Finally, trend analysis concentrates on pinpointing and examining trends within climate texts, aiding in the monitoring of shifts in public dialogue, scientific research, or policy discussions over time. Collectively, these tasks converge to a deeper discernment of climate issues. The insights harvested can enlighten decision-making mechanisms, policy development, and initiatives to amplify public cognizance.\n\nConsidering the aforementioned types of weather and climate data, we will now expound on a variety of tasks pertinent to weather and climate analysis. Note that we have omitted the explicit outline and definition of the Climate Text Analysis task due to its closely related subtasks, and instead adopted the aforementioned Climate Task as a proxy for the Climate Text Analysis definition. A succinct description of each task is as follows:\n\n•\n\nForecasting Tasks. These tasks span from a few hours (nowcasting) to days and weeks (short- and medium-range forecasting). They may include regional forecasting for continental states, counties, or cities. Sub-seasonal to seasonal prediction involves forecasting weather between 2 weeks and 2 months in advance, bridging the gap between weather forecasts and seasonal climate predictions, which is imperative for disaster mitigation.\n\n•\n\nPrecipitation nowcasting tasks. Precipitation Nowcasting is a weather forecasting technique designed to predict precipitation over the next few hours. Unlike traditional weather forecasting, it focuses on short-term changes in precipitation, usually predicted on time scales of minutes to hours. This task employs data from radar systems, satellites, weather observation facilities, and numerical models, combined with image processing techniques, to predict the distribution, intensity, and movement of precipitation over a brief future period via real-time monitoring and analysis of atmospheric clouds and precipitation systems. Therefore, we have isolated it from the general forecasting task.\n\n•\n\nDownscaling tasks. Given the coarse spatial resolution of global climate models, they can only offer general estimates of climate conditions at local or regional scales. Simulations often exhibit systematic biases that diverge from trends in observed data. Downscaling climate models aims to generate locally precise climate information from global climate projections by correlating this climate information to observed local climate conditions. This process enhances the data’s spatial and temporal resolution, rendering it more suitable for local and regional analysis.\n\n•\n\nBias correction tasks. Bias correction is vital in weather and climate applications. It aims to minimize or eliminate systematic biases in model outputs and observational data, which emerge due to uncertainties in weather models and measurement errors. In weather forecasting, bias correction enhances the accuracy of model predictions by adjusting variables such as temperature and precipitation to match actual observations. In climate research, bias correction is crucial for aligning climate model outputs with observational data, facilitating accurate analysis of climate change trends, evaluation of model performance, and reliable predictions of future climate changes. Various methods, including statistical, machine learning, and deep learning techniques, can be employed for bias correction, tailoring the approach based on the specific application and data characteristics. By minimizing or eliminating systematic biases, bias correction improves the quality and reliability of weather and climate data.\n\n•\n\nWeather pattern understanding tasks. This task strives to analyze weather data to comprehend the variations and trends in weather patterns and the climate system. It involves modeling and analyzing various elements of the weather system, such as pressure, temperature, humidity, wind speed, and wind direction, to disclose their relationships and interactions. The objective is to identify and interpret different weather patterns, such as cyclones, fronts, and high-pressure systems, and deduce their impacts on weather changes and extreme weather events. By gaining a deeper understanding of weather patterns, we can enhance our knowledge of weather forecasting and climate change, providing decision-makers and researchers with more accurate and comprehensive information about the weather system.\n\n4 Basic Structure for Weather & Climate\n\nConsidering the different types of data present in weather and climate tasks, we mainly consider the use of Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Graph Neural Networks (GNNs), Transformers, Generative Adversarial Networks (GANs), and Diffusion Models to mine complex correlations from these data. In this survey, we mainly focus on Recurrent Neural Networks, Transformers, Generative Adversarial Networks, Graph Neural Networks, and Diffusion Models. Considering the particular representations of weather and climate data, we focus on spatio-temporal graphical neural networks in our discussion of GNNs.\n\n4.1 Recurrent Neural Networks\n\nRecurrent Neural Networks [111] (RNNs) are a neural network architecture specialized in processing sequential data. In RNNs, information is passed on all the time, enabling the RNN to utilize previous information to influence subsequent outputs. RNNs are fundamental modules in deep learning and are widely used in language modeling [112, 113, 114], time series analysis [98, 115, 116], and many other sequence-related tasks. RNNs have also pioneered the use of deep learning techniques to deal with weather and climate modeling [97]. The update rule for a general RNN can be expressed as:\n\nht=σ⁢(Wh⁢xt+Uh⁢ht−1+bh),subscriptℎ𝑡𝜎subscript𝑊ℎsubscript𝑥𝑡subscript𝑈ℎsubscriptℎ𝑡1subscript𝑏ℎh_{t}=\\sigma(W_{h}x_{t}+U_{h}h_{t-1}+b_{h}),italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_σ ( italic_W start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_U start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ) , (1)\n\nwhere htsubscriptℎ𝑡h_{t}italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the hidden state at t𝑡titalic_t-th time step, xtsubscript𝑥𝑡x_{t}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the input at t𝑡titalic_t-th time step, Whsubscript𝑊ℎW_{h}italic_W start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT and Uhsubscript𝑈ℎU_{h}italic_U start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT are the weight matrices, bhsubscript𝑏ℎb_{h}italic_b start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT is the bias, and σ𝜎\\sigmaitalic_σ is a nonlinear activation function such as tanh or ReLU.\n\nHowever, ordinary RNNs often encounter the problems of gradient vanishing and gradient explosion in practice, making it difficult to handle long sequences. To solve this problem, some improved RNN structures have been proposed, such as Long Short-Term Memory [99] (LSTM) and Gated Recurrent Unit [117] (GRU). ConvLSTM [97] and ConvGRU [97] are variants that introduce convolutional operations into LSTM and GRU, allowing them to process spatially structured data such as images or videos, they usually have utilized to process weather spatio-temporal series data such as radar echo or satellite image sequences. In these models, fully connected operations are replaced by convolutional operations. For example, the update rule of ConvLSTM can be expressed as:\n\nftsubscript𝑓𝑡\\displaystyle f_{t}italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =σ⁢(Wx⁢f*xt+Wh⁢f*ht−1+bf)absent𝜎subscript𝑊𝑥𝑓subscript𝑥𝑡subscript𝑊ℎ𝑓subscriptℎ𝑡1subscript𝑏𝑓\\displaystyle=\\sigma(W_{xf}*x_{t}+W_{hf}*h_{t-1}+b_{f})= italic_σ ( italic_W start_POSTSUBSCRIPT italic_x italic_f end_POSTSUBSCRIPT * italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_f end_POSTSUBSCRIPT * italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ) (2) itsubscript𝑖𝑡\\displaystyle i_{t}italic_i start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =σ⁢(Wx⁢i*xt+Wh⁢i*ht−1+bi)absent𝜎subscript𝑊𝑥𝑖subscript𝑥𝑡subscript𝑊ℎ𝑖subscriptℎ𝑡1subscript𝑏𝑖\\displaystyle=\\sigma(W_{xi}*x_{t}+W_{hi}*h_{t-1}+b_{i})= italic_σ ( italic_W start_POSTSUBSCRIPT italic_x italic_i end_POSTSUBSCRIPT * italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_i end_POSTSUBSCRIPT * italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) otsubscript𝑜𝑡\\displaystyle o_{t}italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =σ⁢(Wx⁢o*xt+Wh⁢o*ht−1+bo)absent𝜎subscript𝑊𝑥𝑜subscript𝑥𝑡subscript𝑊ℎ𝑜subscriptℎ𝑡1subscript𝑏𝑜\\displaystyle=\\sigma(W_{xo}*x_{t}+W_{ho}*h_{t-1}+b_{o})= italic_σ ( italic_W start_POSTSUBSCRIPT italic_x italic_o end_POSTSUBSCRIPT * italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_o end_POSTSUBSCRIPT * italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ) C~tsubscript~𝐶𝑡\\displaystyle\\tilde{C}_{t}over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =tanh⁡(Wx⁢c*xt+Wh⁢c*ht−1+bc)absentsubscript𝑊𝑥𝑐subscript𝑥𝑡subscript𝑊ℎ𝑐subscriptℎ𝑡1subscript𝑏𝑐\\displaystyle=\\tanh(W_{xc}*x_{t}+W_{hc}*h_{t-1}+b_{c})= roman_tanh ( italic_W start_POSTSUBSCRIPT italic_x italic_c end_POSTSUBSCRIPT * italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_c end_POSTSUBSCRIPT * italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) Ctsubscript𝐶𝑡\\displaystyle C_{t}italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =ft∘Ct−1+it∘C~tabsentsubscript𝑓𝑡subscript𝐶𝑡1subscript𝑖𝑡subscript~𝐶𝑡\\displaystyle=f_{t}\\circ C_{t-1}+i_{t}\\circ\\tilde{C}_{t}= italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∘ italic_C start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_i start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∘ over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT htsubscriptℎ𝑡\\displaystyle h_{t}italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =ot∘tanh⁡(Ct)absentsubscript𝑜𝑡subscript𝐶𝑡\\displaystyle=o_{t}\\circ\\tanh(C_{t})= italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∘ roman_tanh ( italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n\nwhere ftsubscript𝑓𝑡f_{t}italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, itsubscript𝑖𝑡i_{t}italic_i start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, otsubscript𝑜𝑡o_{t}italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and C~tsubscript~𝐶𝑡\\tilde{C}_{t}over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT are forgetting gates, input gates, output gates, and candidate memory cells, respectively, *** denotes the convolution operation, and ∘\\circ∘ denotes the Hadamard product. The ConvGRU update rules can be represented as follows:\n\nrtsubscript𝑟𝑡\\displaystyle r_{t}italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =σ⁢(Wx⁢r*xt+Wh⁢r*ht−1+br)absent𝜎subscript𝑊𝑥𝑟subscript𝑥𝑡subscript𝑊ℎ𝑟subscriptℎ𝑡1subscript𝑏𝑟\\displaystyle=\\sigma(W_{xr}*x_{t}+W_{hr}*h_{t-1}+b_{r})= italic_σ ( italic_W start_POSTSUBSCRIPT italic_x italic_r end_POSTSUBSCRIPT * italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_r end_POSTSUBSCRIPT * italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) (3) ztsubscript𝑧𝑡\\displaystyle z_{t}italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =σ⁢(Wx⁢z*xt+Wh⁢z*ht−1+bz)absent𝜎subscript𝑊𝑥𝑧subscript𝑥𝑡subscript𝑊ℎ𝑧subscriptℎ𝑡1subscript𝑏𝑧\\displaystyle=\\sigma(W_{xz}*x_{t}+W_{hz}*h_{t-1}+b_{z})= italic_σ ( italic_W start_POSTSUBSCRIPT italic_x italic_z end_POSTSUBSCRIPT * italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_z end_POSTSUBSCRIPT * italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT ) h~tsubscript~ℎ𝑡\\displaystyle\\tilde{h}_{t}over~ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =tanh⁡(Wx⁢h*xt+rt∘(Wh⁢h*ht−1)+bh)absentsubscript𝑊𝑥ℎsubscript𝑥𝑡subscript𝑟𝑡subscript𝑊ℎℎsubscriptℎ𝑡1subscript𝑏ℎ\\displaystyle=\\tanh(W_{xh}*x_{t}+r_{t}\\circ(W_{hh}*h_{t-1})+b_{h})= roman_tanh ( italic_W start_POSTSUBSCRIPT italic_x italic_h end_POSTSUBSCRIPT * italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∘ ( italic_W start_POSTSUBSCRIPT italic_h italic_h end_POSTSUBSCRIPT * italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) + italic_b start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ) htsubscriptℎ𝑡\\displaystyle h_{t}italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT =(1−zt)∘ht−1+zt∘h~tabsent1subscript𝑧𝑡subscriptℎ𝑡1subscript𝑧𝑡subscript~ℎ𝑡\\displaystyle=(1-z_{t})\\circ h_{t-1}+z_{t}\\circ\\tilde{h}_{t}= ( 1 - italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ∘ italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∘ over~ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n\nwhere rtsubscript𝑟𝑡r_{t}italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and ztsubscript𝑧𝑡z_{t}italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT are the reset and update gates, respectively. These gating mechanisms allow ConvGRU to handle long time dependencies more efficiently. These formulas show that ConvGRU first computes the reset and update gates at each time step, then computes the candidate hidden state h~tsubscript~ℎ𝑡\\tilde{h}_{t}over~ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and finally computes the new hidden state htsubscriptℎ𝑡h_{t}italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. The update gate ztsubscript𝑧𝑡z_{t}italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT plays a role in determining how many new candidate hidden states to use when computing new hidden states.\n\n4.2 Diffusion Models\n\nDiffusion Models (DMs) [118, 119] have achieved promising achievements in extensive applications across a range of fields including computer vision [109, 120, 121, 122], natural language processing [123, 124, 125], due to their efficacy in emulating intricate, high-dimensional data distributions. DMs comprise a category of probabilistic generative models and the core of these lie the principles of diffusion process, which are stochastic procedures delineating the continuous stochastic motion of particles over time. At the core of these models lie the principles of diffusion processes, which are stochastic procedures delineating the continuous stochastic motion of particles over time. These processes model spatial or temporal diffusion wherein particles incline towards transitioning from zones of high concentration to those with lower densities, facilitating a gradual assimilation or blending of quantities. The principal concept involves conducting a sequence of diffusion steps, with each step updating the data’s probability distribution. This is accomplished by incorporating Gaussian noise into the current data samples and iteratively refining them. The noise addition in each diffusion step perturbs the data points, and the iterative refinement guides these perturbed points to gradually converge to the target distribution. This iterative process is akin to a random walk in the data space, where the random perturbations, guided by the model, eventually lead to the generation of new data points following the target distribution.\n\nMathematically, a diffusion model describes a Markov chain that begins with the data and ends with noise. Let’s denote the data as x and the noise as z. The Markov chain has the following form:\n\nxt=(1−dt)*x(t−1)+(dt)*ztx_{t}=\\sqrt{(}1-dt)*x_{(}t-1)+\\sqrt{(}dt)*z_{t}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = square-root start_ARG ( end_ARG 1 - italic_d italic_t ) * italic_x start_POSTSUBSCRIPT ( end_POSTSUBSCRIPT italic_t - 1 ) + square-root start_ARG ( end_ARG italic_d italic_t ) * italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT (4)\n\nwhere ztsubscript𝑧𝑡z_{t}italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is sampled from a standard Gaussian distribution, d⁢t𝑑𝑡dtitalic_d italic_t is a small time step and t is the current step. The goal of the diffusion model is to learn the reverse transition of this Markov chain, i.e., to generate data from noise. This is done by estimating the conditional distribution p(x(t−1)|xt)p(x_{(}t-1)|x_{t})italic_p ( italic_x start_POSTSUBSCRIPT ( end_POSTSUBSCRIPT italic_t - 1 ) | italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) and sampling from it. With enough steps, the chain will transform the noise z𝑧zitalic_z into the data x𝑥xitalic_x.\n\n4.3 Transformers\n\nTransformer is a DL model and has become a key infrastructure for existing state-of-the-art (SOTA) large models applied to NLP and other sequence-to-sequence tasks (i.e., weather forecasting) [126]. The key to this is its ability to handle dependencies between any part of the input sequence and any part of the output sequence without having to rely on the order of the sequences as in RNNs [127].\n\nVanilla Transformer utilizes an encoder-decoder architecture, where both the encoder and decoder are comprised of a series of stacked blocks. Each Transformer layer is composed of a self-attention layer and a fully-connected feed-forward network (FFN). Additionally, the decoder block incorporates an additional cross-attention layer on top of the self-attention layer to capture information from the encoder. To facilitate information flow and alleviate the vanishing gradient problem, residual connections [128] and layer normalization modules are implemented between each layer.\n\nMulti-Head Self-Attention. At the heart of the Transformer achitecture lies in the self-attention mechanism. This mechanism plays a pivotal role in capturing relationships within an input sequence. It accomplishes this by calculating attention scores for each element in the sequence in relation to the other elements. These scores are then utilized to assign weights to the input sequence, resulting in the generation of a new weighted sequence. The formula for the self-attention mechanism is as follows:\n\n𝐇=Attention⁢(𝐐,𝐊,𝐕)=softmax⁢(𝐐𝐊Tdk)⁢𝐕,𝐇Attention𝐐𝐊𝐕softmaxsuperscript𝐐𝐊𝑇subscript𝑑𝑘𝐕{\\mathbf{H}}=\\text{Attention}({\\mathbf{Q}},{\\mathbf{K}},{\\mathbf{V}})=\\text{% softmax}\\left(\\frac{{\\mathbf{Q}}{\\mathbf{K}}^{T}}{\\sqrt{d_{k}}}\\right){\\mathbf% {V}},bold_H = Attention ( bold_Q , bold_K , bold_V ) = softmax ( divide start_ARG bold_QK start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT end_ARG start_ARG square-root start_ARG italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG end_ARG ) bold_V , (5)\n\nwhere the dksubscript𝑑𝑘d_{k}italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT denotes the dimension of the key, 𝐐∈ℝn×dk𝐐superscriptℝ𝑛subscript𝑑𝑘{\\mathbf{Q}}\\in{\\mathbb{R}}^{n\\times d_{k}}bold_Q ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝐊∈ℝm×dk𝐊superscriptℝ𝑚subscript𝑑𝑘{\\mathbf{K}}\\in{\\mathbb{R}}^{m\\times d_{k}}bold_K ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝐕∈ℝm×dv𝐕superscriptℝ𝑚subscript𝑑𝑣{\\mathbf{V}}\\in{\\mathbb{R}}^{m\\times d_{v}}bold_V ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_d start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT end_POSTSUPERSCRIPT are the query matrix, key matrix and value matrix respectively, which are linear transformations of the same input sequence 𝐗∈ℝn×d𝐗superscriptℝ𝑛𝑑{\\mathbf{X}}\\in{\\mathbb{R}}^{n\\times d}bold_X ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_d end_POSTSUPERSCRIPT (or feature matrix from the previous layer) based on three weight matrices 𝐖q∈ℝd×dksubscript𝐖𝑞superscriptℝ𝑑subscript𝑑𝑘{\\mathbf{W}}_{q}\\in{\\mathbb{R}}^{d\\times d_{k}}bold_W start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝐖k∈ℝd×dksubscript𝐖𝑘superscriptℝ𝑑subscript𝑑𝑘{\\mathbf{W}}_{k}\\in{\\mathbb{R}}^{d\\times d_{k}}bold_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝐖v∈ℝd×dvsubscript𝐖𝑣superscriptℝ𝑑subscript𝑑𝑣{\\mathbf{W}}_{v}\\in{\\mathbb{R}}^{d\\times d_{v}}bold_W start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_d start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, as\n\n𝐐=𝐗𝐖q,𝐊=𝐗𝐖k,𝐕=𝐗𝐖v,formulae-sequence𝐐subscript𝐗𝐖𝑞formulae-sequence𝐊subscript𝐗𝐖𝑘𝐕subscript𝐗𝐖𝑣{\\mathbf{Q}}={\\mathbf{X}}{\\mathbf{W}}_{q},{\\mathbf{K}}={\\mathbf{X}}{\\mathbf{W}% }_{k},{\\mathbf{V}}={\\mathbf{X}}{\\mathbf{W}}_{v},bold_Q = bold_XW start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , bold_K = bold_XW start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , bold_V = bold_XW start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT , (6)\n\nThe attention score is obtained by computing the dot product of the query martix and key matrix, then dividing by dksubscript𝑑𝑘\\sqrt{d_{k}}square-root start_ARG italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG for scaling, and finally normalizing by softmax.\n\nTransformer uses multi-head self-attention with multiple sets of 𝐐(i),𝐊(i),𝐕(i)superscript𝐐𝑖superscript𝐊𝑖superscript𝐕𝑖{\\mathbf{Q}}^{(i)},{\\mathbf{K}}^{(i)},{\\mathbf{V}}^{(i)}bold_Q start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , bold_K start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , bold_V start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT, each set corresponding to a distinct set of linear transformation matrix 𝐖q(i)∈ℝd×dksuperscriptsubscript𝐖𝑞𝑖superscriptℝ𝑑subscript𝑑𝑘{\\mathbf{W}}_{q}^{(i)}\\in{\\mathbb{R}}^{d\\times d_{k}}bold_W start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝐖k(i)∈ℝd×dksuperscriptsubscript𝐖𝑘𝑖superscriptℝ𝑑subscript𝑑𝑘{\\mathbf{W}}_{k}^{(i)}\\in{\\mathbb{R}}^{d\\times d_{k}}bold_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝐖v(i)∈ℝd×dhsuperscriptsubscript𝐖𝑣𝑖superscriptℝ𝑑subscript𝑑ℎ{\\mathbf{W}}_{v}^{(i)}\\in{\\mathbb{R}}^{d\\times d_{h}}bold_W start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_d start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, where dhsubscript𝑑ℎd_{h}italic_d start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT is set to dvhsubscript𝑑𝑣ℎ\\frac{d_{v}}{h}divide start_ARG italic_d start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT end_ARG start_ARG italic_h end_ARG, hℎhitalic_h is the number of heads. The final output of the multi-head self-attention is obtained by projecting the concatenation of a series of 𝐇isubscript𝐇𝑖{\\mathbf{H}}_{i}bold_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT into a new feature space with a new weight matrix 𝐖p⁢r⁢o⁢j∈ℝdv×dp⁢r⁢o⁢jsubscript𝐖𝑝𝑟𝑜𝑗superscriptℝsubscript𝑑𝑣subscript𝑑𝑝𝑟𝑜𝑗{\\mathbf{W}}_{proj}\\in{\\mathbb{R}}^{d_{v}\\times d_{proj}}bold_W start_POSTSUBSCRIPT italic_p italic_r italic_o italic_j end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT × italic_d start_POSTSUBSCRIPT italic_p italic_r italic_o italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, as follows:\n\n𝐇𝐇\\displaystyle{\\mathbf{H}}bold_H =Multi-Head Self-Attention⁢(𝐐,𝐊,𝐕)absentMulti-Head Self-Attention𝐐𝐊𝐕\\displaystyle=\\text{Multi-Head Self-Attention}({\\mathbf{Q}},{\\mathbf{K}},{% \\mathbf{V}})= Multi-Head Self-Attention ( bold_Q , bold_K , bold_V ) (7) =Concat⁢(𝐇1,𝐇2,…,𝐇h)⁢𝐖p⁢r⁢o⁢j,absentConcatsubscript𝐇1subscript𝐇2…subscript𝐇ℎsubscript𝐖𝑝𝑟𝑜𝑗\\displaystyle=\\text{Concat}({\\mathbf{H}}_{1},{\\mathbf{H}}_{2},...,{\\mathbf{H}}% _{h}){\\mathbf{W}}_{proj},= Concat ( bold_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , bold_H start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ) bold_W start_POSTSUBSCRIPT italic_p italic_r italic_o italic_j end_POSTSUBSCRIPT , 𝐇isubscript𝐇𝑖\\displaystyle{\\mathbf{H}}_{i}bold_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT =Attention(𝐐(i),𝐊(i),𝐕(i).\\displaystyle=\\text{Attention}({\\mathbf{Q}}^{(i)},{\\mathbf{K}}^{(i)},{\\mathbf{% V}}^{(i)}.= Attention ( bold_Q start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , bold_K start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , bold_V start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT .\n\nFor decoder, there is an additional mask mechanism that prevents query vectors from attending to the future positions yet to be decoded. In addition, an extra cross-attention following the self-attention, where the 𝐐𝐐{\\mathbf{Q}}bold_Q is derived from the output of the previous layer in the decoder, and the 𝐊𝐊{\\mathbf{K}}bold_K and 𝐕𝐕{\\mathbf{V}}bold_V are transformed from the output of the last layer of the encoder. It is designed to avoid foreseeing the true label while considering information from the encoder when encoding.\n\nFully-connected Feed-Forward Layer. Fully-connected feed-forward Layers following the attention layer is consists of linear transformation and a non-linear activation function. Denote the input matrix 𝐗∈ℝn×di𝐗superscriptℝ𝑛subscript𝑑𝑖{\\mathbf{X}}\\in{\\mathbb{R}}^{n\\times d_{i}}bold_X ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, the output of the feed-forward layer is\n\n𝐅=FFN⁢(𝐗)=σ⁢(𝐖1⁢𝐗+𝒃1)+𝒃2,𝐅FFN𝐗𝜎subscript𝐖1𝐗subscript𝒃1subscript𝒃2{\\mathbf{F}}=\\text{FFN}({\\mathbf{X}})=\\sigma({\\mathbf{W}}_{1}{\\mathbf{X}}+{\\bm% {b}}_{1})+{\\bm{b}}_{2},bold_F = FFN ( bold_X ) = italic_σ ( bold_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_X + bold_italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + bold_italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , (8)\n\nwhere σ⁢(⋅)𝜎⋅\\sigma(\\cdot)italic_σ ( ⋅ ) presents the activation function, and 𝐖1∈ℝdi×dmsubscript𝐖1superscriptℝsubscript𝑑𝑖subscript𝑑𝑚{\\mathbf{W}}_{1}\\in{\\mathbb{R}}^{d_{i}\\times d_{m}}bold_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT × italic_d start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝒃1∈ℝdmsubscript𝒃1superscriptℝsubscript𝑑𝑚{\\bm{b}}_{1}\\in{\\mathbb{R}}^{d_{m}}bold_italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝐖2∈ℝdm×dosubscript𝐖2superscriptℝsubscript𝑑𝑚subscript𝑑𝑜{\\mathbf{W}}_{2}\\in{\\mathbb{R}}^{d_{m}\\times d_{o}}bold_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT × italic_d start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, 𝒃2∈ℝdosubscript𝒃2superscriptℝsubscript𝑑𝑜{\\bm{b}}_{2}\\in{\\mathbb{R}}^{d_{o}}bold_italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT end_POSTSUPERSCRIPT are all learnable parameters.\n\nResidual Connection and Normalization. Following each attention layer and each feed-forward layer, residual connection and layer normalization are applied. They conduct to retaining information when the model is considerably deep and thus guarantees the model performance. Formally, given a neural layer f⁢(⋅)𝑓⋅f(\\cdot)italic_f ( ⋅ ), the residual connection and normalization layer is defined as\n\nAdd & Norm⁢(𝐗,f)=LayerNorm⁢(𝐗+f⁢(𝐗)).Add & Norm𝐗𝑓LayerNorm𝐗𝑓𝐗\\text{Add \\& Norm}({\\mathbf{X}},f)=\\text{LayerNorm}({\\mathbf{X}}+f({\\mathbf{X}% })).Add & Norm ( bold_X , italic_f ) = LayerNorm ( bold_X + italic_f ( bold_X ) ) . (9)\n\nTransformer Layer. The design of the Transformer model enables parallel processing of the entire sequence, eliminating the need for sequential processing of elements as in RNNs. This parallel processing enhances its efficiency in handling long sequences. By utilizing a multi-layer self-attention mechanism, the Transformer model effectively captures long-distance dependencies in sequences, which is crucial for tasks involving translation, summarization, and other sequence-to-sequence operations.\n\n4.4 Generative Adversarial Networks\n\nGenerative Adversarial Networks (GANs) [108] aim to train a generative model via adversarial processes, it have widely used to image generation [29, 129, 130], super-resolution [131, 132], style transferring [133, 134], and image-based weather forecasting [135]. The fundamental concept of GANs involves training two NNs adversarially: a Generator G𝐺Gitalic_G and a Discriminator D𝐷Ditalic_D. The objective of the Generator G𝐺Gitalic_G is to learn the underlying data distribution and generate novel samples accordingly. The discriminator (D𝐷Ditalic_D)’s objective is to differentiate between the samples generated by the generator and the real samples.During training, the generator aims to produce samples that can effectively fool the discriminator, while the discriminator strives to enhance its ability to differentiate between real and generated samples. This process can be regarded as a two-player zero-sum game, ultimately leading to an equilibrium where the discriminator cannot distinguish between the generator-generated samples and the real samples.\n\nThe objective function of GANs can be expressed as the following optimization problem:\n\nminG⁡maxD⁡V⁢(D,G)=subscript𝐺subscript𝐷𝑉𝐷𝐺absent\\displaystyle\\min_{G}\\max_{D}V(D,G)=roman_min start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT italic_V ( italic_D , italic_G ) = 𝔼x∼pdata⁢(x)⁢[log⁡D⁢(x)]subscript𝔼similar-to𝑥subscript𝑝data𝑥delimited-[]𝐷𝑥\\displaystyle\\mathbb{E}_{x\\sim p_{\\rm{data}}(x)}[\\log D(x)]blackboard_E start_POSTSUBSCRIPT italic_x ∼ italic_p start_POSTSUBSCRIPT roman_data end_POSTSUBSCRIPT ( italic_x ) end_POSTSUBSCRIPT [ roman_log italic_D ( italic_x ) ] (10) +𝔼z∼pz⁢(z)⁢[log⁡(1−D⁢(G⁢(z)))],subscript𝔼similar-to𝑧subscript𝑝𝑧𝑧delimited-[]1𝐷𝐺𝑧\\displaystyle+\\mathbb{E}_{z\\sim p_{z}(z)}[\\log(1-D(G(z)))],+ blackboard_E start_POSTSUBSCRIPT italic_z ∼ italic_p start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT ( italic_z ) end_POSTSUBSCRIPT [ roman_log ( 1 - italic_D ( italic_G ( italic_z ) ) ) ] ,\n\nwhere x𝑥xitalic_x is a sample from the true data distribution pdatasubscript𝑝datap_{\\rm{data}}italic_p start_POSTSUBSCRIPT roman_data end_POSTSUBSCRIPT, z𝑧zitalic_z is a sample from some a prior noisy distribution pzsubscript𝑝𝑧p_{z}italic_p start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT, G⁢(z)𝐺𝑧G(z)italic_G ( italic_z ) is the sample generated by the generator using the noisy sample z𝑧zitalic_z, and Dxsubscript𝐷𝑥D_{x}italic_D start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT is the discriminator’s estimate of whether the sample x𝑥xitalic_x (either the true sample or the generated sample) is the true sample. Training of GANs typically involves alternately optimizing two of this objective function. First, the generator is fixed and the discriminator is optimized. Then, fix the discriminator and optimize the generator. This process is repeated until some equilibrium is reached, at which point the samples generated by the generator should be indistinguishable from the true samples by the discriminator.\n\n4.5 Spatio-Temporal Graph Neural Networks\n\nSpatio-Temporal Graph Neural Networks (STGNNs) [106] is a concept in machine learning that combines spatial and temporal information using graph structures. It is particularly useful for analyzing data with both spatial and temporal dependencies. In STGNN, the basic concept involves representing the data as a graph, where each node represents a spatial location and the edges capture the spatial connectivity. Additionally, each node also contains temporal information, representing the state of the variable at different time steps.\n\nSpatial Graph Structure. Let 𝒢=(𝒱,E)𝒢𝒱𝐸{\\mathcal{G}}=({\\mathcal{V}},E)caligraphic_G = ( caligraphic_V , italic_E ) be the graph representing the spatial connections, where V is the set of nodes representing spatial locations, and E is the set of edges representing the spatial relationships. Each node visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents the feature vector xisubscript𝑥𝑖x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of the corresponding location i.\n\nTemporal Information. Let X=xit𝑋superscriptsubscript𝑥𝑖𝑡X=x_{i}^{t}italic_X = italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT be the set of feature vectors for all locations at time t. Each feature vector xitsuperscriptsubscript𝑥𝑖𝑡x_{i}^{t}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT represents the state of the variable at location i and time t.\n\nSpatio-temporal Graph Convolution. STGNN incorporates both spatial and temporal information through graph convolution operations, which capture the relationships between variables at different locations and time steps. The spatio-temporal graph convolution can be represented as:\n\nhit+1=f⁢(∑j∈N⁢(i)wi⁢j⋅hjt+bit).superscriptsubscriptℎ𝑖𝑡1𝑓subscript𝑗𝑁𝑖⋅subscript𝑤𝑖𝑗superscriptsubscriptℎ𝑗𝑡superscriptsubscript𝑏𝑖𝑡h_{i}^{t+1}=f(\\sum_{j\\in N(i)}w_{ij}\\cdot h_{j}^{t}+b_{i}^{t}).italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT = italic_f ( ∑ start_POSTSUBSCRIPT italic_j ∈ italic_N ( italic_i ) end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ⋅ italic_h start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT + italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ) . (11)\n\nHere, hit+1superscriptsubscriptℎ𝑖𝑡1h_{i}^{t+1}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT represents the updated feature vector of node i𝑖iitalic_i at time t+1𝑡1t+1italic_t + 1, N⁢(i)𝑁𝑖N(i)italic_N ( italic_i ) denotes the set of neighbors of node i𝑖iitalic_i, capturing the spatial connections between locations, wi⁢jsubscript𝑤𝑖𝑗w_{ij}italic_w start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT represents the weight between node i𝑖iitalic_i and its neighbor j𝑗jitalic_j, indicating the strength of their relationship, hjtsuperscriptsubscriptℎ𝑗𝑡h_{j}^{t}italic_h start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT represents the feature vector of the neighboring node j𝑗jitalic_j at time t𝑡titalic_t. bitsuperscriptsubscript𝑏𝑖𝑡b_{i}^{t}italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT is a bias term for node i𝑖iitalic_i at time t𝑡titalic_t. f⁢(⋅)𝑓⋅f(\\cdot)italic_f ( ⋅ ) represents an activation function, such as ReLU or Sigmoid, applied element-wise to the sum of weighted inputs. The spatio-temporal graph convolution operation combines the spatial connectivity and temporal dependencies to effectively capture the evolving patterns and relationships in the data.\n\n5 Overview and Categorization\n\nIn this section, we provide an overview and categorization of DL models for weather and climate. Our survey is structured along three main dimensions: data types, model architectures, and application domains. A detailed synopsis of the related works can be found in the Table. III. Based on the scope of application, we primarily divide the existing literature into two main categories: Large Foundation Models and Task-Specific Weather and Climate Models. Considering the task generality of weather/climate foundation models, we discuss them at a high level without further subdivisions. For task-specific weather/climate models, we categorize them based on specific underlying architectures to facilitate readers in indexing and referencing specific works according to model architectures, including Recurrent Neural Networks, Generative Adversarial Networks, Transformers, Diffusion Models, and Graph Neural Networks. Subsequently, at the application level, we divide the existing literature into two main categories based on specific data categories: Time Series for Weather and Climate and Text for Weather and Climate.\n\nIn the first category, we further dissect the existing literature into six primary classes predicated on the domains of application: Forecasting, Precipitation Nowcasting, Downscaling, Data Assimilation, Bias Correction, and Weather Pattern Understanding. For the second category, we explore it as a general subject (Climate Text Analysis), refraining from subdividing it into different subtasks. This is because these often originate from pre-trained LLMs, and the specific task characteristics are typically delineated based on downstream datasets rather than the model itself.\n\n6 Models for Weather & Climate\n\nIn this section, we will delve into the advancements of Foundation Models and Task-Specific Models for weather and climate data understanding. A categorization of representative methods and detailed information can be found in Table. III.\n\n6.1 Foundation Models for Weather & Climate\n\nThe burgeoning development of foundation models in NLP [200, 82, 47] and CV [45, 46] has piqued research interest in foundation models for weather and climate data understanding. Large Foundation Models, created through pre-training strategies, can substantially enhance the generalization capability of AI-based climate models and can be fine-tuned for specific downstream tasks. Pre-training of such models necessitates large-scale sequence data, not typically sourced from ordinary time-series data.\n\nMindful of computational efficiency and the demand for timely climate predictions, Pathak et al. proposed FourCastNet[136], a climate pre-trained foundation model based on Vision Transformer and Adaptive Fourier Neural Network Operator (AFNO)[201], for high-resolution predictions and rapid inference. Its training process consists of self-supervised pre-training and autoregressive fine-tuning based on the pre-trained model. Pangu-Weather [63], a data-driven model leveraging the 3D Earth-specific Transformer, is notable for its swift, precise global predictions and superior performance. It predicts atmospheric states over time based on the current state, described by five upper-air variables and four surface variables on a 0.25° horizontal grid with 13 vertical layers for the upper-air variables. On the other hand, ClimaX [25] introduces the concept of fundamental modeling to weather prediction with its fully supervised pre-training based on the Transformer. It proposes variable disambiguation and variable aggregation strategies for merging and revealing potential relationships between different weather variations at various altitudes, offering promising flexibility for adapting to diverse downstream tasks, including global/regional/seasonal forecasting, climate mapping, and downscaling tasks. FengWu [138] tackles the medium-term forecasting problem from a multimodal, multitask perspective with a uniquely designed deep learning architecture. It features a model-specific decoder and a cross-modal fusion Transformer that balances the optimization of different predictors in a regionally adaptive manner under the supervision of uncertainty loss. Given that the aforementioned large-scale models are trained via a fully supervised approach, W-MAE[64] implements unsupervised training of weather prediction models using a Masked Auto-Encoder (MAE)-based[202, 203] approach, which can be fine-tuned for downstream tasks through various data sources. MetePFL [24] and FedWing [154] also propose a Prompt-based federated learning [204] for training large foundation models, considerably reducing the cost of collaborative model training across regions while safeguarding data privacy. The rapid advancement of LLMs has led to the processing of weather and climate tasks that are no longer restricted to visual or time-series models. OceanGPT[197], based on LLMs, proposes a methodology for processing a wide range of ocean-related tasks. Beyond the foundation models used for forecasting and simulation, ClimateBert[195] is an NLP-based foundation model for processing climate-related texts. It is trained on over 2 million climate-related paragraphs from diverse sources such as news articles, research papers, and company climate reports [205].\n\n6.2 Task-specific Models for Weather & Climate\n\nIn the realm of weather and climate analysis, task-specific models have been utilized for a myriad of specific tasks. This section will delve into the progress made in task-specific models for weather and climate, focusing on these principal architectures: RNNs, Transformers, GANs, Diffusion Models, and Graph Neural Networks (GNNs).\n\n•\n\nRecurrent Neural Networks (RNNs). RNNs serve as the backbone of numerous weather forecasting models [206, 207, 208, 209, 85, 210, 97, 211, 175, 145, 212, 213]. In addition to weather and climate prediction models built on RNNs architectures, hybrid models fusing RNN with other mechanisms have also gained traction [147, 146, 214, 215, 216, 217]. For instance, the amalgamation of Swin Transformer [218] with RNN has given birth to models like SwinVRNN [147], which capitalize on the advantages of both architectures. Moreover, the fusion of SwinRNN with generative models has led to models for the diffusion model SwinRDM [146] and for GAN [216, 217]. Added to this, physical-informed based approaches have been introduced [219]. Concurrently, with the evolution of Transformer-based spatio-temporal extraction, the integration of RNN architecture and Transformer models to address this problem has been on the rise [214, 215].\n\n•\n\nDiffusion Models. Standard diffusion models, comprising forward noisy processes and backward denoising processes, are widely employed for learning data distribution and generating data representations in meteorological and climatic contexts [220, 150, 221, 222, 177, 152, 146, 147, 223] [164, 224]. For instance, SwinRDM [146] amalgamates SwinRNN [147] and diffusion models to attain high-resolution weather forecasting. However, it is important to note that the application of diffusion models in weather and climate studies is still in its nascent stage.\n\n•\n\nGenerative Adversarial Networks (GANs). GANs have widely used in image generation tasks, ranging from generating handwritten digits [225] to generating large-scale image datasets [226, 227]. They are commonly employed in weather and climate tasks for spatiotemporal video stream prediction [228, 229], aiming to generate realistic and temporally coherent sequences and match high-dimensional data distributions between them. Therefore, GAN-based architecture is common in weather and climate prediction tasks aims to generate predicted future frames like ground-truth as same as possible [230, 231, 84, 232] [167][233, 170, 234, 235, 216, 217, 236, 237] [238, 239]. Additional physical constraints are often introduced to improve the accuracy of weather and climate modeling in these hybrid models [240, 229, 241, 242, 243, 244, 245, 246, 247, 248].\n\n•\n\nTransformers. Transformer-based models are widely used for tasks related to time series analysis due to its powerful long series modeling capabilities, which also include responding to weather and climate change [149]. It focuses on short-term/long-term forecasting tasks in weather and climate applications and can be categorized into two types, the former focusing on one-/two-dimensional forecasts of weather and climate, such as predicting trends in relevant weather variables globally or regionally on single atmosphere level, and the latter focusing on multidimensional forecasts, such as extrapolations based on radar-echo imagery [249], satellite cloud images [250] and multi-layer atmosphere status, thus contributing to the understanding of weather patterns in the region. For the first category, the Transformer is used to perform short- and long-term forecasts, modeling dependencies on variables at different points in time through positional coding as well as self-attention mechanisms [251, 252, 253, 178, 254, 255]. As for the second category, Transformers are expected to establish complex multilayered spatio-temporal relationships of meteorological variables at different atmospheric pressures, and the results of this type of Transformer are usually challenged based on the characteristics of the data itself (atmospheric pressures, spatio-temporal correlations, variable correlations), and so on [63, 25, 138, 64, 148]. Inspired by the fields of NLP and CV, the Transformer structure has also been redesigned for the development of large-scale weather and climate foundation models [25, 63, 138]. In addition, in the filed of NLP-based climate text analysis, Transformers is a general architecture [196, 256, 198, 257, 196, 199, 258, 259].\n\n•\n\nGraph Neural Networks. In the field of weather and climate, numerous studies have explored the application of graph neural networks, particularly spatial-temporal graph neural networks, due to their ability to establish potential spatial-temporal relationships of the Earth system. [181]. Two common applications include spatial-temporal sequence prediction [142, 143, 260, 144, 261, 262, 183, 263, 184, 264, 265, 137, 221] and spatial-temporal video stream prediction in weather forecasting [168]. In spatial-temporal sequence prediction, graph neural networks are used to model the spatio-temporal dependencies and correlations in weather data. This involves predicting future weather conditions based on historical observations at different locations [24, 154]. The graph structure is used to capture the spatial relationships between nodes, and the temporal dependencies are modeled using recurrent [264, 265] or convolutional layers [144, 183]. In spatial-temporal video stream prediction, graph neural networks are employed to predict future weather conditions in the form of video-like sequences [168]. This involves predicting the evolution of weather patterns over time, taking into account both spatial and temporal dependencies.\n\n7 Applications\n\nThis section presents an overview of prevalent DL models, categorized by their applications in weather and climate analysis. These applications include forecasting, precipitation nowcasting, downscaling, bias correction, data assimilation, climate text analysis, and weather pattern understanding.\n\n7.1 Forecasting\n\nAccurate weather and climate forecasting is critical for environmental and societal planning. Significant strides have been made in developing robust DL methods that model the nonlinear associations between historical and future weather patterns. This section mainly focuses on discuss the advancement in the task of weather and climate forecasting based on time series and spatio-temporal series. The most common in such tasks are RNNs-based architecture, which are widely used due to their autoregressive (AR) architecture [146, 145, 212, 213, 147]. For instance, DWFH introduces conductive long and short-term memory models to enhance data-driven deep weather prediction models [145]. Ref. [212] merges the LSTM and an adaptive neuro-fuzzy inference system (ANFIS) for atmospheric pressure forecasting. SwinRDM introduces the SwinRNN as a fundamental component for high-resolution weather forecasting [146], and diffusion models to achieve high-resolution weather forecasting at 0.25 degrees using a two-step training strategy: first, cyclic prediction of future atmospheric fields is performed at low resolution, followed by high-resolution and fine-grained atmospheric detail reconstruction based on the diffusion-based super-resolution model. Moreover, Swinvrnn employs a Recurrent Neural Network-based architecture with variations loss to improve long-lead weather forecasts [147]. In addition, Transformer, especially Vision Transformer, is also widely used in weather and climate prediction based on spatio-temporal series due to its bright performance in modeling potential representational associations between image regions using Patch mechanism and self-attention mechanism. FourCastNet [136] delivers impressive performance in various weather forecasting tasks using 0.25° resolution. This achievement is based on the Vision Transformer (ViT)[266] and Adaptive Fourier Neural Network Operators (AFNO). PoET [148] introduces hierarchical ensemble transformers to enhance medium-range ensemble weather forecasts on a global scale. TeleViT [153] integrates fine-grained local-scale and global-scale inputs, treating the Earth as one interconnected system for seasonal wildfire forecasting. Large models came out of nowhere when considering the ultra-large-scale, high-resolution global medium-term forecasting task. Pangu-Weather[63], a data-driven model based on 3D Earth-specific transformers, is lauded for its rapid and accurate global forecasts. This model predicts the atmospheric state at a given time based on the current state, described by five upper-air variables on a 0.25° horizontal grid and four surface variables, with 13 vertical levels for the upper-air variables. FengWu [138] addresses the medium-range forecasting problem from a multi-modal, multi-task perspective, with its elaborate deep learning architecture with model-specific decoders and cross-modal fusion transformers that learn under the supervision of uncertainty loss to balance the optimization of different predictors in a regionally adaptive manner. FuXi [139] cascades cubic embeddings and U-transformers and is trained using 39 years of high-resolution in-analysis data. It delivers forecast performance comparable to that of the ECMWF EM with a temporal resolution of 6 hr and a spatial resolution of 0.25° in a 15-day forecast. The FuXi-Extreme model [155] employs a denoising diffusion probabilistic model (DDPM) [118] to refine the surface forecast data generated by the FuXi model [139] in 5-day forecasts, thereby enhancing extreme rainfall/wind forecasting. As an all-purpose foundation model, ClimaX [25] introduces the concept of foundation modeling to the field of weather prediction, with its fully supervised pre-training based on the Transformer, and proposes variable tokenization and variable aggregation strategies for fusing and mining the potential relationships of different weather variations at different heights, which gives it very promising flexibility to adapt to different downstream tasks, including global/regional/seasonal prediction, as well as the tasks of climate mapping, and downscaling. While the aforementioned models are trained in a fully supervised-based pre-training, W-MAE[64] leverages a Masked Auto-Encoder (MAE)-based approach [202, 203] for self-supervised training in weather forecasting models, potentially allowing fine-tuning by different data sources to adapt to downstream tasks.\n\nGenerative AI are carving a niche in the field of climate and weather forecasting, with several promising approaches recently reported. SEEDS[150], for instance, employs an array of finely-tuned ensemble simulators to generate probabilistic weather forecasts. These forecasts are akin to the “seeds“ of weather states provided during the inference process, with two different ensemble simulators generating two distinct event predictions. However, the self-regression mechanism underpinning this approach, similar to the RNN architecture used in diffusion model training, is susceptible to instability and feature dissipation over time, particularly in long-range forecasting tasks. Contrastingly, Dyfussion [151] uses pristine initial conditions, while the PDE-Refiner [222] enhances the diffusion process-based predictions by iteratively observing them to capture low-amplitude information that may not be immediately evident in the data. DITTO [152] adopts a unique approach, generating a continuous interpolation between the initial and final time steps, and using time fireworks instead of incremental noise in the forward process. TemperatureGAN [242], a conditional GAN, considers factors such as the month, location, and time period to generate atmospheric temperature predictions at an hourly resolution above ground level.\n\nFurthermore, GANs that integrate physical information constraints are being deployed to emulate ocean systems, thereby enhancing climate prediction capabilities [244, 245, 246, 247, 248].For instance, Refs. [244, 245] describe GAN-based models that learn underlying physical relationships between surface and subsurface temperatures in numerical models. Subsequent calibration of model parameters using observational data leads to enhanced predictions. PGnet [248] is a generative neural network model that uses a mask matrix to identify regions of low-quality prediction generated during the initial physical stage. The generative neural network then uses this mask as a prior for the second stage of fine prediction. WGC-LSTM [260] harnesses graph convolutions to capture spatial relationships and amalgamates these with LSTM to concurrently consider both spatial and temporal relationships.\n\nReflecting upon the intricate interconnections between atmospheric elements, surface variables, and precise terrestrial coordinates within the Earth system, a substantial amount of research has utilized graph-based methodologies for weather and climate prediction tasks. Fo"
    }
}