{
    "id": "dbpedia_8568_3",
    "rank": 34,
    "data": {
        "url": "https://medium.com/%40santosh.shukla/fastai-identify-who-is-batman-54e7ab3dee06",
        "read_more_link": "",
        "language": "en",
        "title": "FastAI : Identify who is Batman. Introduction",
        "top_image": "https://miro.medium.com/v2/resize:fit:890/1*_6zQfv6cO8a2J8zsY9KIXg.jpeg",
        "meta_img": "https://miro.medium.com/v2/resize:fit:890/1*_6zQfv6cO8a2J8zsY9KIXg.jpeg",
        "images": [
            "https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:88:88/0*Fv312nyMAU-4Vjep.jpg",
            "https://miro.medium.com/v2/resize:fill:144:144/0*Fv312nyMAU-4Vjep.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Santosh Shukla",
            "medium.com",
            "@santosh.shukla"
        ],
        "publish_date": "2020-08-03T19:35:33.445000+00:00",
        "summary": "",
        "meta_description": "Over the weekend, I got my hands on Deep Learning for Coders with FastAI and PyTorch written by Jeremy Howard and Sylvian Gugger. I read Chapter 2, titled From Model to Production and it showed a way…",
        "meta_lang": "en",
        "meta_favicon": "https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19",
        "meta_site_name": "Medium",
        "canonical_link": "https://medium.com/@santosh.shukla/fastai-identify-who-is-batman-54e7ab3dee06",
        "text": "Introduction\n\nOver the weekend, I got my hands on Deep Learning for Coders with FastAI and PyTorch written by Jeremy Howard and Sylvian Gugger. I read Chapter 2, titled From Model to Production and it showed a way to classify three bear classes with a good accuracy and deploy it to a web server for production. The sheer simplicity of such a system, encouraged me to try something similar.\n\nAt the same moment, my inner self said to me, “You know what would be a cool classifier? Identifying the actor behind the mask of Batman”. This is how I came up with my project for the Sunday Afternoon. The problem statement was clear. Can a neural network classify image of batman to the actor who portrays it?\n\nI finalized to have two classes, namely “Christian Bale” and “Ben Affleck”. The reason for selecting two classes was, the fact that, batman as played by both actors had lot of visual similarities. In some close up shots, it becomes difficult even for a human to identify, who the actor is. So, this was already a difficult problem to begin with.\n\nPreparing the Dataset\n\nThis took most of the time in the project. I decided on having 30 images per class. Thus, the dataset would consist of total 60 images. There were two sources for the images.\n\nGoogle Image Search\n\nI used an extension in Google Chrome called “Download All Images”. It is an amazing piece of software that downloads all the images on a page as a zip file. All this happens with a single click.\n\nSimply go to images.google.com and search “Ben Affleck as Batman”, click on the extension and Baam! All images on the page are downloaded into a zip file. Do the same for “Christian Bale”.\n\nExtract each into a folder named as ben_affleck and christian_bale. Clean up the data, as it will contain many junk images. The count of images will certainly be more than 30. So, you can delete a few. Select images that have only batman visible with somewhat closeup shot. You can also crop out only batman from images where there are other people in the image.\n\nI could create only 20 such images as there were lot of repetition of images. This is where I used the second method.\n\nSnapshot from movies\n\nI needed 10 more images for each classes. So, I captured screens from The Dark Knight and The Dark Knight Rises for Christian Bale. Justice League and Batman vs. Superman for Ben Affleck.\n\nOnce images are ready. Place the two folders(christian_bale and ben_affleck) in a directory named batman and convert it to .zip. Now the dataset is ready.\n\nTraining and Evaluating the Model\n\nThe fun part begins here! Most of the part, here onward, is based on the fastai book. I used Google Colab for this. Open your notebooks and get started.\n\n!pip install fastai2 > /dev/null\n\nfrom fastai2.vision.all import *\n\nfrom pathlib import Path\n\nThe first step is to import the relevant libraries. Currently (in Aug, 2020), Colab does not have support for fastai2 So, we have to install it before using.\n\nNext, we have to upload the dataset, to access it in Colab.\n\nfrom google.colab import files\n\nuploaded = files.upload()\n\nThis opens up a widget to help you select and upload the dataset, in our case it’s batman.zip.\n\nGreat, the file is uploaded. We have to extract it before we can use it.\n\n!unzip batman.zip\n\nLet’s set the variables with the appropriate path and data values.\n\nactors = ['christian_bale', 'ben_affleck']\n\npath = Path('batman')\n\nfns = get_image_files(path)\n\nNow, we have the classes in variable actors and path to image files in fns\n\nWe need to create a Datablock, to correctly map the input image with its respective labels, split the data for training and testing and apply data augmentation to it.\n\nbatmans = DataBlock(blocks=(ImageBlock, CategoryBlock),\n\nget_items=get_image_files,\n\nsplitter=TrainTestSplitter(test_size=0.2, random_seed=42),\n\nget_y=parent_label)batmans = batmans.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms())\n\nThe above code tells the Datablock that the dataset is comprised of Image and the output block is category. It gives provides a function to get the Image data and splitter is defined to split the data with 20% data kept reserved for Testing. The parent_label is provided to the parameterget_y It indicates that the label for an image is the name of its parent folder.\n\nTo iterate over the dataset, we create a DataLoader with batch size 4.\n\ndls = batmans.dataloaders(path, bs=4)\n\nWe define a learner with a pretrained resnet18 architecture. With this, we fine tune the network for 2 epochs.\n\nlearn = cnn_learner(dls, resnet18, metrics=error_rate)\n\nlearn.fine_tune(2)\n\nThe output we get is,\n\nThis suggests an accuracy of ~92% on the validation set. This seems quite a good network as it used only 24 images for each class to train. Let’s have a look at the confusion matrix.\n\nSo, of the 12 images in the validation set, the network incorrectly identified only one image. The rest were classified correctly. Let’s have a look at the incorrectly classified image.\n\nThe network was confidant 67% that it was Christian Bale, however the ground truth was that it was Ben Affleck. I won’t blame the network, it is pretty difficult for me to decide between the actors.\n\nTesting the model\n\nThe network performance is impressive. Let’s take add code to upload and test the prediction capability of the model.\n\nuploader = widgets.FileUpload()\n\nuploader\n\nThis adds a widget to upload image. Search for a batman image on Google and upload it using the uploader widget.\n\nThen, use the following code to make predictions with the trained network.\n\nimg = PILImage.create(uploader.data[0])\n\nactor,_,probs = learn.predict(img)\n\nprint(f\"Who's the actor behind mask?: {actor}.\")\n\nprint(f\"With a probability of {probs[1].item():.6f}\")\n\nSo, I used a new image as input to the trained network,\n\nThe network output:\n\nWho's the actor behind mask?: christian_bale.\n\nWith a probability of 0.909068\n\nIf you remove the mask, you’ll find Christian Bale saying, “I’m Batman!” :P"
    }
}