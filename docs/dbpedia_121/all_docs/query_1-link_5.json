{
    "id": "dbpedia_121_1",
    "rank": 5,
    "data": {
        "url": "https://www.ibm.com/topics/data-labeling",
        "read_more_link": "",
        "language": "en",
        "title": "What Is Data Labeling?",
        "top_image": "https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/64/ea/content-hub-analytic-page-leadspace-short.png/_jcr_content/renditions/cq5dam.web.1280.1280.png",
        "meta_img": "https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/64/ea/content-hub-analytic-page-leadspace-short.png/_jcr_content/renditions/cq5dam.web.1280.1280.png",
        "images": [
            "https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/64/ea/content-hub-analytic-page-leadspace-short.component.xl.ts=1712905748212.png/content/adobe-cms/us/en/topics/data-labeling/_jcr_content/root/leadspace"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Data labeling"
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2021-09-28T00:00:00",
        "summary": "",
        "meta_description": "Data labeling, or data annotation, is part of the preprocessing stage when developing a machine learning (ML) model.",
        "meta_lang": "en",
        "meta_favicon": "/content/dam/adobe-cms/default-images/favicon.svg",
        "meta_site_name": "",
        "canonical_link": "https://www.ibm.com/topics/data-labeling",
        "text": "Companies integrate software, processes and data annotators to clean, structure and label data. This training data becomes the foundation for machine learning models. These labels allow analysts to isolate variables within datasets, and this, in turn, enables the selection of optimal data predictors for ML models. The labels identify the appropriate data vectors to be pulled in for model training, where the model, then, learns to make the best predictions.\n\nAlong with machine assistance, data labeling tasks require “human-in-the-loop (HITL)” participation. HITL leverages the judgment of human “data labelers” toward creating, training, fine-tuning and testing ML models. They help guide the data labeling process by feeding the models datasets that are most applicable to a given project.\n\nLabeled data vs. unlabeled data\n\nComputers use labeled and unlabeled data to train ML models, but what is the difference?\n\nLabeled data is used in supervised learning, whereas unlabeled data is used in unsupervised learning.\n\nLabeled data is more difficult to acquire and store (i.e. time consuming and expensive), whereas unlabeled data is easier to acquire and store.\n\nLabeled data can be used to determine actionable insights (e.g. forecasting tasks), whereas unlabeled data is more limited in its usefulness. Unsupervised learning methods can help discover new clusters of data, allowing for new categorizations when labeling.\n\nComputers can also use combined data for semi-supervised learning, which reduces the need for manually labeled data while providing a large annotated dataset.\n\nData labeling is a critical step in developing a high-performance ML model. Though labeling appears simple, it’s not always easy to implement. As a result, companies must consider multiple factors and methods to determine the best approach to labeling. Since each data labeling method has its pros and cons, a detailed assessment of task complexity, as well as the size, scope and duration of the project is advised.\n\nHere are some paths to labeling your data:\n\nInternal labeling - Using in-house data science experts simplifies tracking, provides greater accuracy, and increases quality. However, this approach typically requires more time and favors large companies with extensive resources.\n\nSynthetic labeling - This approach generates new project data from pre-existing datasets, which enhances data quality and time efficiency. However, synthetic labeling requires extensive computing power, which can increase pricing.\n\nProgrammatic labeling - This automated data labeling process uses scripts to reduce time consumption and the need for human annotation. However, the possibility of technical problems requires HITL to remain a part of the quality assurance (QA) process.\n\nOutsourcing - This can be an optimal choice for high-level temporary projects, but developing and managing a freelance-oriented workflow can also be time-consuming. Though freelancing platforms provide comprehensive candidate information to ease the vetting process, hiring managed data labeling teams provides pre-vetted staff and pre-built data labeling tools.\n\nCrowdsourcing - This approach is quicker and more cost-effective due to its micro-tasking capability and web-based distribution. However, worker quality, QA, and project management vary across crowdsourcing platforms. One of the most famous examples of crowdsourced data labeling is Recaptcha. This project was two-fold in that it controlled for bots while simultaneously improving data annotation of images. For example, a Recaptcha prompt would ask a user to identify all the photos containing a car to prove that they were human, and then this program could check itself based on the results of other users. The input of from these users provided a database of labels for an array of images.\n\nThe general tradeoff of data labeling is that while it can decrease a business’s time to scale, it tends to come at a cost. More accurate data generally improves model predictions, so despite its high cost, the value that it provides is usually well worth the investment. Since data annotation provides more context to datasets, it enhances the performance of exploratory data analysis as well as machine learning (ML) and artificial intelligence (AI) applications. For example, data labeling produces more relevant search results across search engine platforms and better product recommendations on e-commerce platforms. Let’s delve deeper into other key benefits and challenges:\n\nBenefits\n\nData labeling provides users, teams and companies with greater context, quality and usability. More specifically, you can expect:\n\nMore Precise Predictions: Accurate data labeling ensures better quality assurance within machine learning algorithms, allowing the model to train and yield the expected output. Otherwise, as the old saying goes, “garbage in, garbage out.” Properly labeled data provide the “ground truth” (i.e., how labels reflect “real world” scenarios) for testing and iterating subsequent models.\n\nBetter Data Usability: Data labeling can also improve usability of data variables within a model. For example, you might reclassify a categorical variable as a binary variable to make it more consumable for a model. Aggregating data in this way can optimize the model by reducing the number of model variables or enable the inclusion of control variables. Whether you’re using data to build computer vision models (i.e. putting bounding boxes around objects) or NLP models (i.e. classifying text for social sentiment), utilizing high-quality data is a top priority.\n\nChallenges\n\nData labeling is not without its challenges. In particular, some of the most common challenges are:\n\nExpensive and time-consuming: While data labeling is critical for machine learning models, it can be costly from both a resource and time perspective. If a business takes a more automated approach, engineering teams will still need to set up data pipelines prior to data processing, and manual labeling will almost always be expensive and time-consuming.\n\nProne to Human-Error: These labeling approaches are also subject to human-error (e.g. coding errors, manual entry errors), which can decrease the quality of data. This, in turn, leads to inaccurate data processing and modeling. Quality assurance checks are essential to maintaining data quality."
    }
}