{
    "id": "correct_subsidiary_00059_2",
    "rank": 18,
    "data": {
        "url": "https://www.scaruffi.com/svhistory/sil9.html",
        "read_more_link": "",
        "language": "en",
        "title": "A History of Silicon Valley",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "history timeline USA Silicon Valley chronology"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "A History of Silicon Valley",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "9. The Warriors (1980-83)\n\nby Piero Scaruffi\n\nThe Coming of Microsoft\n\nIn 1980 IBM, which enjoyed a virtual monopoly in the mainframe-computer market, decided to enter the personal-computer market. They opened a small Entry Systems Division in Florida under the direction of Donald Estridge, who opted for building a computer from off-the-shelf, widely available components. One of the reasons for this decision was that IBM was still wary of an antitrust lawsuit brought against them by the government in 1969. The best way to avoid accusations of monopolistic practices was to make the specifications available to its competitors. IBM put William Lowe in charge of the top-secret project, code-named \"Acorn\". To start with, they chose the Intel 8088 microprocessor instead of a proprietary IBM microprocessor (IBM had already acquired the rights to manufacture Intel chips). IBM did not have an operating system for Intel's processors, so it was necessary to buy one from a third party. When (in 1978), Intel had introduced the 8086, a young Seattle programmer, Tim Paterson, had been hired by Seattle Computer Products (SCP) to develop a CP/M-compatible operating system for it, and in december 1980 he finished work on his 86-DOS. Asked by IBM to deliver an operating system for the 8086, in 1981 Bill Gates' Microsoft bought the rights on 86-DOS from SCP and hired Paterson to port 86-DOS to the first prototype of the PC provided by IBM. It was renamed MS-DOS, and Microsoft decided to retain the rights on the operating system. IBM launched its PC in august 1981. The basic version with 16 kilobytes of RAM and a cassette unit sold for $1,600. Another revolutionary move by IBM was to let outside distributors (initially Sears & Roebucks and Computerland) sell the PC. The best-selling computer in the history of IBM had sold only 25,000 units over five years: the PC would sell a million units in less than three years.\n\nThe business models chosen by IBM and Microsoft would have far-reaching consequences. Because IBM had used off-the-shelf components for their PC, and because Microsoft had retained the rights on MS-DOS, it didn't take long for engineers all over the world to realize that one could build a \"clone\" of the IBM PC. The only difficult trick was to replicate the BIOS (Basic Input/Output System), the software written to \"bootstrap\" the computer. Rod Canion and other former Texas Instruments engineers founded Compaq to reverse engineer IBM's BIOS; and in january 1983, after licensing MS-DOS from Microsoft, introduced the 8088-based Portable PC, fully compatible with the IBM PC but even smaller (a premonition of the laptop), equipped with 128 kilobytes of RAM and priced at $3,000 (the same configuration cost $3,800 on the IBM PC). Soon there would be an entire PC-clone industry worth more than the entire personal-computer industry of the previous years. Compaq was the most aggressive because it had hired marketing and sales executives from IBM. It was not a garage-style start-up but a carefully planned large-scale operation. Compaq's strategy was to sell almost exclusively through retailers and resellers.\n\nThe personal-computer industry was already mature before the introduction of the PC. 1.4 million personal computers were sold in 1981, half of them in the USA. However, less than 1% of all households in the USA had one. That changed in 1982. Another winner of 1981 (at the low end of the spectrum) was the Commodore VIC20, still based on the MOS 6502 CPU like the PET. It sold 800,000 units in 1982. Even better would fare its successor, the slightly more powerful Commodore 64 introduced in august 1982 with a price tag of only $600. It was the first affordable color computer, it could directly be plugged into a television set, and it came with 64 kilobytes of RAM. The technology was only part of the reason for its success: Commodore decided to sell it in retail stores instead of electronics stores, thus addressing a much bigger audience. It went on to sell more than 20 million units (four times the Apple II).\n\nNext to these giants there were the many makers of microcomputers based on the Zilog Z80: Sinclair, Osborne, Sony, Sharp, NCR, Olivetti, Philips and, of course, most models of the popular Radio Shack TRS-80 series, which was still a best-seller. Notably in april 1981 Osborne Computer, founded in 1980 in Hayward by British-born hobbyist Adam Osborne (an old member of the Homebrew Computer Club), delivered the Osborne 1, a portable computer running the CP/M operating system that weighed only 11 kgs and cost $1,800, designed by hardware engineer Lee Felsenstein, a fellow member of the Homebrew Computer Club who had already integrated a video and a keyboard in the Sol-20; basically, it was a commercial version of the Xerox NoteTaker. A few months later, in 1982, Japanese manufacturer Epson introduced an even smaller computer, the HC-20, designed around a Motorola microprocessor dressed up by Hitachi. In april 1982 GRiD Systems, founded in 1979 in Mountain View by a former Xerox PARC scientist of the Alto team, John Ellenby, and already IPO-ed before it had a product (1981), introduced a portable computer based on the Intel 8086 microprocessor, the 1101. Manuel Fernandez, a refugee from Cuba who had become the CEO of Zilog during the Z80 era, founded Gavilan and in may 1983 introduced the first portable MS-DOS computer marketed as a \"laptop\" ($4,000).\n\nFinally, there was Apple. In 1982 it became the first personal-computer company to pass the $1 billion mark in revenues. Unlike the IBM PC, which featured an operating system used by many other manufacturers, the Apple II relied on a proprietary Apple operating system that did not encourage independent software companies. Willingly or unwillingly, IBM had established an open software standard, whereas Apple still lived in the era of closed proprietary architectures. It wasn't clear which of the two strategies would be the winning one.\n\nThat year almost three million personal computers were sold worldwide.\n\nThe Coming of Software\n\nA major reason for the skyrocketing sales in personal computers was that, quite simply, they were becoming more useful. And that was due to the software, not the hardware. A number of word-processing and spreadsheet programs could run on the IBM PC. In the next few years a wealth of software applications turned the PC into a necessity for any office.\n\nIn 1981 Los Angeles-based Context Management Systems had introduced Context MBA for Apple computers: a software package that integrated spreadsheet, database, charting, word-processing and communication functions. In 1982 they ported it to the PC. In january 1983 in Massachusetts the Lotus Development Corporation, founded the year before by Mitch Kapor, who had been responsible for VisiCalc at VisiCorp, introduced the spreadsheet program \"Lotus 1-2-3\" for MS-DOS developed by MIT alumnus and Lotus' co-founder Jonathan Sachs. Visicorp's VisiCalc was not running on the PC, and the other spreadsheets for the PC were slow or inadequate. 1-2-3, on the other hand, was written specifically for the IBM PC in assembly language, and it became a bestseller. Lotus instantly became the second largest software company for personal computers after Microsoft, with sales in 1983 of $53 million.\n\nSoftware Plus, founded in 1980 by George Tate and Hal Lashlee, was a Los Angeles-based distributor and publisher of software for personal computers, a booming business. In 1981 they stumbled into the Vulcan database management system for the CP/M operating system developed at home by Wayne Ratliff, an employee of NASA's Jet Propulsion Labs, modeled after the database system of his lab's Univac mainframe. Software Plus acquired the program, changed its own name to Ashton-Tate, turned Vulcan into a popular product, dBase ($700), and in 1982 ported it to MS-DOS.\n\nIntuit, founded in 1983 by Scott Cook and Tom Proulx in Palo Alto, offered Quicken, a personal finance management tool for the Apple II. Designed by Proulx, it was a personal finance management tool running on the IBM PC and the Apple II. It was originally conceived for the younger people saddled with school debts and struggling to make ends meet at the end of the month, but, recession after recession, tools like this would become popular with an ever broader audience.\n\nRay Noorda's Novell in Utah in 1982 came up with the idea of a network operating system to allow several personal computers to share the same files and printers. Their NetWare for DOS was the first stepping-stone to enable personal-computer users to work as a team.\n\nThe IBM PC could not run the many applications written for the CP/M operating system, but that rapidly became a non-issue. Thanks to IBM's charisma and to Microsoft's licensing skills, in 1982 fifty companies bought a MS-DOS license. The more computers using MS-DOS, the stronger the motivation for software developers to port their applications to MS-DOS. The more applications written for MS-DOS, the stronger the motivation for hardware manufacturers to buy a MS-DOS license. Furthermore, Microsoft invested the money in greatly improving the operating system. In march 1983 release 2.0 of MS-DOS offered features derived from the Unix operating system (such as subdirectories and pipes) that made it much more competitive against CP/M on technical grounds.\n\nAn impressive number of software companies were started in 1982 in Silicon Valley, a fact that began to alter the relative proportion between hardware and software. Autodesk was founded in 1981 in Mill Valley (north bay) to commercialize Mike Riddle's Interact, the first Computer-Aided Design (CAD) program for CP/M and MS-DOS personal computers, the first affordable tool for creating detailed technical drawings. Riddle, a user of ComputerVision's CAD system for graphical workstations, teamed up with John Walker's Marinchip Systems that had built a computer based on a Texas Instrument microprocessor. Both had a second life. Riddle, based in Arizona, was an inventor who had built a successful electric guitar tuner. Walker, a libertarian-leaning intellectual, had designed one of the first Trojan viruses, Animal (1975). Walker renamed Riddle's Interact as AutoCAD, ported it to the Victor 9000, one of the early graphics Intel-based personal computers, and turned it into a novelty hit.\n\nSymantec was founded in March 1982 in Sunnyvale to pursue artificial intelligence-based research, notably in natural-language processing. Gary Hendrix, a pioneer of neural networks who had worked at the SRI International with Charlie Rosen on Shakey the Robot, and later had joined Rosen's start-up Machine Intelligence Corporation, hired a group of specialists from Stanford University. Symantec went on to specialize in development tools for software engineers, i.e. software to help build other software.\n\nBorland was founded in 1983 in Scotts Valley (between San Jose and Santa Cruz) by three Danish developers (Niels Jensen, Ole Henriksen, and Mogens Glad) and Philippe Kahn, a Frenchman who had cut his teeth on the Micral project. They targeted the growing needs not of the end user but of the software developer.\n\nActivision was founded in october 1979 by music industry executive Jim Levy and a group of Atari game designers to become the first company focused on game design. Until then the games for a console had been published exclusively by the console manufacturer. Activision introduced the practice of giving credit and even publicizing the creators. Its first success, \"Pitfall\" (1982), drove many others to start similar companies.\n\nApple's marketing manager Trip Hawkins founded Electronic Arts in may 1982 in Redwood City to market home computer games, viewed not as mere games but as a form of interactive digital media. Both their business plan and their ethics treated game publishing just like book publishing, and treated videogame production just like a movie studio treats movie production.\n\nJohn Warnock (a former employee of Evans & Sutherland) and Charles Geschke left Xerox PARC, where they had worked on the page-description language InterPress for Xerox's laser printer, to develop a simpler language, PostScript, and they founded Adobe in december 1982 in Mountain View to commercialize it. PostScript was the first building block for desktop publishing, which still needed a viable computer platform and a suitable software environment (both unsuccessfully pioneered by Xerox's Star). Apple was at work on the Macintosh, and Adobe collaborated on designing its printer, the LaserWriter, based on PostScript, a collaboration that launched the revolution of desktop publishing. PostScript enabled home computers to talk with a new class of home printers, largely replacing the print shop. Unlike most startups, Adobe was profitable from its first year.\n\nThe first inkjet printer had been built by Rune Elmqvist at Elema in Sweden (later acquired by Siemens) in 1948 (ten years later the same man invented the pacemaker). It had taken almost 30 years for Siemens to introduce a commercial inkjet printer: the PT80 of 1977. Siemens' inkjet products as well as similar products from other competitors were mainly used for medical applications. By then IBM had acquired inkjet technology from Stanford University (Richard Sweet's technology) to make its IBM 4640 printer, but that was another failed product. The winning technology was invented in 1977 by Ichiro Endo at Canon: a new inkjet technology called \"thermal inkjet\", reinvented independently in 1979 by John Vaught at Hewlett-Packard.\n\nThe Argentine-born mathematician Trabb Pardo and Les Earnest (who had previously built the first spelling checker at the MIT in 1961) founded Imagen in 1980 to commercialize a pioneering desktop publishing system used at the Stanford Artificial Intelligence Laboratory.\n\nVisicalc had opened up the market of offices to the computer industry. Electronic Arts understood that the same device could be used by millions of people to play games, and Xerox PARC scientists that computers could be used for education and for publishing.\n\nGenerally speaking, an important transition was underway. Computers are formed by two interacting substances: hardware and software. At the beginning the cost of a computer was entirely the cost of its hardware parts and of assembling them. Until the 1970s the hardware still represented most of the cost. However, in the 1980s the falling prices of hardware components had enabled ever more sophisticated software applications and triggered a growing demand for them. This meant that the cost of software was escalating at the same time that the cost of hardware was plunging. This vicious loop also constituted a new powerful motivation for the hardware industry to continue producing more powerful chips in order to support ever-larger software applications. Semiconductor components had become commodities, while software now represented the luxury item. Software was also the place where profit margins could be very high.\n\nOne could see the same phenomenon in the world of mainframes, which still accounted for the majority of IT revenues. Computer Associates, formed in 1976 by two Standard Data employees and Columbia University alumni, Chinese-born Charles Wang and Russell Artzt, as a joint venture with a company owned by Swiss billionaire Walter Haefner, was initially focused on system utilities for mainframe computers, but in the early 1980s it inaugurated a cynical strategy of growth not through invention but through ruthless acquisitions that would eventually gobble up all the historical software companies of the mainframe world (Uccel in 1987 for a record $830 million, ADR in 1988, Pansophic in 1991, Cullinet in 1989).\n\nLosers\n\nThe growing complexity of computer applications also induced a growing concern for the user experience. User interfaces were still too technical for a machine that aimed at becoming a home appliance used by ordinary people. After Xerox invested in Apple, in november 1979 Steve Jobs of Apple was given a \"demo\" of the Alto, and that demo set the course of Apple for the 1980s. Jobs hired some of the Xerox engineers (such as Larry Tesler) and discovered that, unbeknownst to him, his own early employee Jef Raskin, in charge of writing the manuals for the Apple II, had already advocated a similar vision, the vision of a \"computer appliance\". Bypassing Jobs, Raskin (a computer hobbyist and journalist, one of the first reporters of the personal computer world, who had taught computers, art and music at UC San Diego, and a musician who even conducted the San Francisco Chamber Opera) had already started working on such a machine and had hired his former student Bill Atkinson from UC San Diego. Raskin too was aware of the Alto via his friends at Xerox PARC, in particular Doug Wyatt with whom he had built one of the first personal computers based on the Altair. In january 1983 Apple introduced the Lisa, the first personal computer with a GUI, the \"WIMP\" (Window, Icons, Mouse, Pull-down menus) paradigm pioneered by the Xerox Alto. The Lisa, based on a Motorola 68000 microprocessor and equipped with one megabyte of RAM and five megabytes of hard-disk storage, heralded the second building block of desktop publishing. Unfortunately, it was too expensive ($10,000) and too slow to truly capture the imagination (and the wallets) of the masses. In october VisiCorp introduced the equivalent GUI for the IBM PC, VisiOn. Neither maintained the expectations of their creators.\n\nThe victim of the personal-computer boom was the videogame console. In the early 1980s there were many best-sellers: Atari 2600 and 5200, Bally Astrocade, Coleco Vision, Emerson Arcadia 2001, Fairchild Channel F, Magnavox Odyssey, Mattel Intellivision, Sears Tele-Games, etc. However, personal computers were getting cheaper and beginning to offer graphics and sound. A personal computer could play videogames but also run many other useful applications. In 1983 the USA market for videogame consoles crashed. Indirectly, this crisis dealt a blow to virtual reality. In 1982 Atari opened a Sunnyvale Research Laboratory, modeled after the Xerox PARC, and appointed PARC veteran Alan Kay to head it. The center assembled the best minds in virtual reality (Tom Zimmerman, Scott Fisher, Brenda Laurel, Jaron Lanier) but lasted only two years.\n\nWinners\n\nThe semiconductor industry of Silicon Valley was instead booming, serving a market that ranged from watches to airplanes. The start-ups continued to multiply. Linear Technology, founded in 1981, and Xilinx, a Zilog spin-off formed in 1984, addressed programmable logic (chips that customers could program themselves) and in 1984 introduced the first \"field programmable gate arrays\" (FPGA); Maxim, founded in 1983 by former Fairchild's marketing executive and AMDs' co-founder Jack Gifford, perfected the analog integrated circuits that Fairchild pioneered; Cypress Semiconductor, an AMD spin-off formed in 1982 by a team of CMOS experts, and Altera, founded in 1983, focused on high-performance integrated circuits. VLSI Technology, a Fairchild spin-off of 1979, and LSI Logic, formed in 1981 by Fairchild's engineer Wilfred Corrigan, specialized in ASICs (Application-Specific Integrated Circuits) for embedded systems.\n\nMeanwhile, voice messaging became a household feature after Octel Communications, founded in 1982 by Robert Cohn and Peter Olson in Milpitas (near San Jose), introduced its voice-mail system, that was smaller and cheaper than traditional ones because it used Intel and Zilog microprocessors. AT&T had begun offering the voice-mail service 1A Voice Storage System in 1979. In 1980 Texas-based ECS had started selling its VMX (Voice Message eXchange). IBM had a voice-mail system internally since 1973 but first sold it as a product in 1982 (the Audio Distribution System). Rolm had been the first company to integrate a voice-mail system (notably its PhoneMail of 1982) with a PBX (its CBX), but Octel, which introduced its product in 1984, made the combination available to a much larger market and by the end of the decade became the largest manufacturer of voice-mail systems (acquired in 1997 by Lucent). Opcom, founded in 1981 in San Jose by former Rolm engineer David Ladd (and acquired in 1988 by the renamed VMX) introduced the automated system for multiple choices (\"press 1\" for... press \"2\" for... etc).\n\nLogitech, the first major seller of mouse devices for personal computers, was founded in 1981 in Switzerland but had its roots in Silicon Valley, as Swiss-born Daniel Borel and Italian-born Pierluigi Zappacosta had met there in graduate school and had met there the third founder, Giacomo Marini, an executive at Olivetti's Advanced Technology Center, located next door to Apple.\n\nIntimations of the Future\n\nSRI's scientist Stan Honey founded Etak in Sunnyvale in 1983 with seed money from Atari's founder Nolan Bushnell. Etak became the first company to digitize maps. In 1985 it introduced the Navigator, a navigation system for cars. It was based on the Intel 8088 and the maps were stored on cassette tapes.\n\nHewlett-Packard experimented with the touch-screen just invented in Europe with the HP-150 (1983), a personal computer based on the Intel 8088, one of the world's earliest commercial touchscreen computers.\n\nFew people heard of \"Elk Cloner\", a program that a 15-year-old high-school student, Rich Skrenta, unleashed on an Apple II in 1982: it was the first personal-computer virus. It was capable of spreading from floppy-disk to floppy-disk, and therefore from computer to computer. What this kid had implicitly realized is that the widespread adoption of personal computers had de facto connected millions of people (even though the \"connection\" still relied on copying files on floppy-disks).\n\nExpert Systems\n\nA mini-bubble within the bubble of software was represented by the start-ups that specialized in \"expert systems\". These were systems based on Artificial Intelligence (AI) techniques developed at Stanford and operating in a narrow domain (such a troubleshooting complex equipment or configuring complex equipment). The novel approach to computing by these systems consisted in emphasizing the knowledge required to solve the problem. An expert system had two fundamental components: a knowledge base, constructed by eliciting knowledge from a human expert, and an \"inference engine\", which contained a set of algorithms to perform inference on the knowledge base. This was therefore a nonsequential kind of computing that differed from most software (in which the solution is achieved via a sequence of instructions). The expert systems targeted complex problems for which a traditional program was not feasible. Just like a human expert, an expert system could only provided a \"plausible\" solution, not necessarily a perfect one. The favorite programming languages for these programs were Prolog and Lisp. In fact, there were also start-ups specializing in \"Lisp machines\". In 1981 Stanford's professor (and expert-system pioneer) Ed Feigenbaum and others founded Teknowledge, which for a while was the most hyped of the AI start-ups. In 1983 Intellicorp introduced its flagship object-oriented development environment, KEE (Knowledge Engineering Environment), also running on Lisp Machines. Brian McCune, an alumnus of the Stanford Artificial Intelligence Laboratory (SAIL), was one of the founders in 1980 of Advanced Information and Decision Systems (AIDS) in Mountain View, later renamed Advanced Decision Systems (ADS), a consulting firm specializing in Artificial Intelligence research for the Department of Defense. He and Richard Tong, a Cambridge University graduate, designed a concept-based text-retrieval system, Rubric, a progenitor of search engines.\n\nJapan was ahead in robotics, but in the early 1980s the USA was home to a few success stories of its own. One of the very first robotic arms in the world had been developed at Stanford in 1969 by Victor Scheinman, a student who had worked on the Apollo mission. In 1973 Scheinman had founded his own startup, Vicarm, which designed robotic arms for SRI, Jet Propulsion Laboratories and MIT. Vicarm was acquired by Unimation and remained their California laboratory. Vicarm, which in 1975 hired Brian Carlisle and Bruce Shimano, designed Unimation's Programmable Universal Machine for Assembly (PUMA), deployed at General Motors in 1978. The success of PUMA encouraged many to start firms to make small electric robotic arms. In 1980 Philippe Villers (cofounder of CAD pioneer Computervision in 1969), Scheinman and others founded Automatix in Boston to and in 1981 introduced Robovision for arc welding, the first commercial robot equipped with a vision system, a technology borrowed from SRI's Shakey group. In 1979 Charles Rosen, the founder of the Artificial Intelligence group at the SRI, and his engineer Earl Sacerdoti founded Machine Intelligence Corporation in Mountain View to to commercialize SRI's machine-vision technology, capable of recognizing industrial parts as they moved along a conveyor belt, a startup that in 1982 evolved into International Machine Intelligence, a joint venture with Japanese robot manufacturer Yaskawa Electric. Ted Panofsky designed their first machine-vision product, the VS-100, used for industrial robotics. In 1982 the American Robot Corporation was founded in Pittsburgh and later renamed American Cimflex before merging with A.I. pioneer Teknowledge of Palo Alto. In 1982 General Motors and Japan's Fanuc (a 1972 Fujitsu spinoff that had introduced its first robot in 1977) established the joint venture GMF Robotics. In 1981 Stan Mintz and others from Hewlett-Packard formed Intelledex in Oregon, which in 1984 introduced assembly robot programmed via Intel microprocessors. In 1983 Carlisle and Shimano founded their own startup, Adept, in Livermore to make robotic arms (a startup later acquired by Japan's Omron).\n\nWorkstations\n\nOne step up from the personal computer the world was completely different. The early 1980s were the age of the workstation, similar to a personal computer because dedicated to a single user but more powerful (especially the graphics) and designed to be connected to a network. This kind of computer targeted the engineering market. They were usually based on the Motorola 68000 (not on Intel microprocessors) and they usually ran the Unix operating system. The market came to be dominated by Apollo (founded in 1980 in Boston by former NASA scientist William Poduska), SUN (1982), Silicon Graphics (1982) and Hewlett-Packard (1983), that ate at DEC's share of (much more expensive) minicomputers. Both SUN and Silicon Graphics originated at Stanford University.\n\nSUN Microsystems was founded in february 1982 in Palo Alto by two foreign Stanford students, German-born Andy Bechtolsheim of the computer science department and Indian-born Vinod Khosla of the business school. In 1981 Bechtolsheim, while working at the Stanford University Network, had modified a Xerox PARC's Alto into a workstation running Unix and networking software. His goal was simply to have machines that would make it as easy as possible to be connected and share data. Khosla realized that this could become a business, and they joined forces with Scott McNealy, a former Stanford graduate and now at Unix start-up Onyx, and hired Berkeley graduate Bill Joy of BSD fame to develop a dialect of Unix, SunOS, based on BSD (Berkeley's version of Unix). Backed by venture capitalists such as Kleiner-Perkins, SUN was started to market that concept.\n\nThe SUN workstation was an evolution of a display terminal invented in 1971 at the Stanford Artificial Intelligence Laboratory (SAIL) and of the Xerox Alto computer (some units of which Xerox had donated to Stanford University in 1979). The SUN workstation marked a turning point in VLSI (Very Large Scale Integration) hardware technology for integrated circuits, that allowed Bechtolsheim to pack a Motorola 68000 CPU, a memory bank, a parallel port controller and a serial port controller into the main CPU board. The other two boards were a graphics display controller and an Ethernet controller (which was still a laboratory device, no commercial Ethernet controller being available in those days). The SUN workstation had more than one spin-off because Yeager's software for connecting multiple Ethernet controllers would later evolve into Cisco's first router, and the version for high-performance graphics display designed by the young James Clark would become the foundation for Clark's first startup, Silicon Graphics.\n\nUnlike the Apollo workstation, which used custom hardware and a proprietary operating system, the SUN workstation used standard off-the-shelf hardware components and a standard operating system (Unix), thus in a sense replicating the business model of the IBM PC. Soon, the concept of the SUN workstation was viewed as aimed at Microsoft: the SUN workstation was basically a more powerful personal computer that also happened to be hooked to a network. It ran Unix instead of Windows. It used a Motorola 68000 processor instead of the Intel x86 processors used by Windows-based computers. And, corporate-wise, the SUN culture was to the Microsoft culture what the counterculture was to the mainstream.\n\nEvans & Sutherland's Picture System had pioneered hardware implementations of computer graphics. At Stanford University in 1980 former Evans & Sutherland's employee Jim Clark and his student Marc Hannah developed an improved version (funded by DARPA) called the \"Geometry Engine\". In november 1981 Clark and Abbey Silverstone of Xerox started Silicon Graphics in Mountain View, with funding from Mayfield Fund, to manufacture graphic workstations. The original idea was to have Motorola 68000-based workstations connected to a DEC VAX minicomputer that boasted high-performance graphics needed for engineering design. Later those workstations became stand-alone Unix computers.\n\nThe talk of the town among workstation developers was RISC (Reduced Instruction Set Computer), which promised faster CPUs. For three decades there had been a trend towards implementing more and more complex functions directly in the hardware of a computer. The principle behind the research in RISC architectures was that, while it is nice to be able to perform complex operations, applications mostly execute simple operations. Hence, it might be more efficient to perform those (frequent) simple operations faster than to implement (infrequent) complex operations. In 1980 in Santa Clara a group of Hewlett Packard employees (including Hugh Martin) founded Ridge Computers. In 1980 David Paterson and Carlo Sequin launched the RISC project at U.C. Berkeley, and the following year John Hennessy started a RISC project at Stanford University. Hennessy eventually left Stanford, founded a company, MIPS, and in 1985 released the first major RISC processor, the R2000. Silicon Graphics would switch to MIPS processors in 1986 (the IRIS 4D series). When SUN introduced its SPARC architecture in 1986, it was based on Berkeley's RISC project; and so did Pyramid Technology, formed in 1981 by former HP employees. MIPS was also adopted by Nintendo in Japan, and by Siemens and Bull in Europe. British computer manufacturer Acorn debuted a RISC processor in 1985, the Acorn Risc Machine or ARM, designed by Sophie Wilson, that would become the company's most successful product, causing the birth in 1990 of a spin-off, Advanced RISC Machines (ARM), that in 1991 would introduce its first embeddable RISC chip.\n\nThe giant in the field of minicomputers was DEC, which in october 1977 had introduced a 32-bit family of computers, the VAX, to progressively replace the various 16-bit PDP-11 models. DEC had designed a proprietary multi-user operating system for the VAXes, the VMS. However, in 1978 Bell Labs had already ported the PDP-11 Unix to the VAX platform. Unix had become \"the\" operating system for universities and DEC hardware had always been a favorite of universities. Therefore DEC involuntarily had one of the most popular Unix platforms: DEC calculated that in 1985 about 25% of all VAXes wax running Unix. The VAX with Unix was also the computer of choice for the Internet, since Unix had become the operating system for the Internet and the PDP-11s had become the preferred minicomputers for the Internet.\n\nThe Killer Micros\n\nThe rapid increase in microprocessor performance fueled a brief fad of \"micro-mainframes\", i.e. minicomputers aimed at competing with IBM's mainframes. They all failed to deliver what they promised. Elxsi, founded in 1979 in San Jose by Joe Rizzi (previously an executive at Intersil) and Indian-born Thampy Thomas (possibly the first Indian native to found a high-tech company in Silicon Valley) to commercialize the architecture designed at Stanford by Len Shar and Balasubrimanian Kumar; Acsys (later renamed Trilogy), founded in 1980 in Cupertino by Gene Amdahl; Parsec (later renamed Convex), formed in 1982 by Bob Paluck and Steve Wallach in Texas (acquired in 1995 by HP); Sequel (later renamed Sequent) formed in 1983 in Oregon by Intel engineers of the 432 project (and acquired in 1999 by IBM); nCUBE, founded in 1983 in Oregon by another group of Intel engineers (and de facto acquired and dismantled by Oracle in 1988); MicroUnity, founded in 1988 in Los Altos by John Moussouris (previously an executive at MIPS) with veterans from several companies including Intel and HP; Stellar, founded in 1985 in Boston and headed by William Poduska (of Prime and Apollo fame), and Dana (later renamed Ardent), founded in 1985 in Sunnyvale by Alan Michaels and Matthew Sanders, two firms that in 1989 would fuse into Stardent. In 1990 Eugene Brooks of Lawrence Livermore Labs delivered a conference talk titled \"Attack of the Killer Micros\" that pretty much buried the field.\n\nElectronic Design Automation\n\nThe origins of electronic design automation (EDA) are in the Bay Area, although not quite in Silicon Valley. UC Berkeley was a pioneer of design for integrated circuits since 1962, when Don Pederson and others opened the first microfabrication facility for integrated circuits ever opened at a university (at Cory Hall). In 1971 Ronald Rohrer in Pederson's lab unveiled a design language and circuit simulator called CANCER (Computer Analysis of Nonlinear Circuits, Excluding Radiation) which in 1972 his student Laurence Nagel turned into SPICE (Simulation Program with Integrated Circuit Emphasis). SPICE became the golden standard for circuit simulation to verify designs.\n\nA few years later SCALD was developed.\n\nThe S-1 project to build a supercomputer was started by the astrophysicist Lowell Wood at the Lawrence Livermore National Lab in 1975, first ran a program in 1978 and continued until 1988. Two Stanford students, Tom McWilliams and Curt Widdoes, were recruited to develop SCALD (Structured Computer-Aided Logic Design), an influential language to design computers, written in Pascal on DEC's PDP10 released into the public domain in 1978. SCALD was based on the Stanford University Drawing System (SUDS) developed at Stanford's Artificial Intelligence Lab (SAIL) first by Phil Petit in 1969 on the PDP10 in assembly language) and later by Richard Helliwell. Petit moved to DEC and used SUDS to design the DEC KL-10 of 1973. Therefore SUDS became the first Computer Aided Design (CAD) system used to design an actual computer. Later Bechtolsheim used SUDS to design the SUN boards at SAIL. SCALD jumpstarted a whole new field, Electronic Design Automation (EDA) for electrical engineering and electronics. Tom McWilliams and Curt Widdoes started a company, initially called SCALD Corporation and later Valid Logic Systems, in 1981 in San Jose to sell SCALD on a proprietary UNIX workstation. At the same time, also in 1981 but in Mountain View, Aryeh Finegold and David Stamm used the public-domain source code for SCALD to found Daisy Systems, that also required a specialized workstation running its own Unix-like operating system. Several notable Silicon Valley founders (e.g. Vinod Khosla, Harvey Jones, Don Smith, Tony Zingale, Mike Schuh, George Haber, Dave Millman and Rick Carlson) started out at Daisy Systems. The third pioneer of EDA was Mentor Graphics, founded in 1981 in Oregon by Tektronix engineers (Tom Bruggere, Gerry Langeler and Dave Moffenbeier) and the only one that didn't require specialized hardware (it ran on regular Unix workstations).\n\nThen there was Espresso, developed in 1982 at IBM in Yorktown by Robert Brayton; and Visula, developed in Britain by Racal-Redac (later acquired by Japan's Zuken); and in 1983 John Ousterhout's team at UC Berkeley introduced Magic. The foundations of Cadence, later a major force in the field, were also in Berkeley. In 1983 James Solomon (a former Motorola and National Semiconductor scientist) joined forces with two UC Berkeley professors (Richard Newton and Alberto Sangiovanni-Vincentelli) to start Solomon Design Automation. Almost at the same time, Glen Antle and Paul Huang started ECAD in 1982 in Santa Clara (de facto a spinoff of the Sunnyvale labs of Florida's minicomputer manufacturer Systems Engineering Laboratories). Cadence was born when these two firms merged in 1988. Finally, there was a DARPA-funded project: VHDL (VHSIC Hardware Description Language where VHSIC stands for (Very High Speed Integrated Circuit). Started in 1979, this hardware description language was shaped by a 1980 report by the international CONLAN committee (named for CONsensus LANguage) and a 1981 workshop, and formalized in 1983 by Intermetrics (an MIT spinoff in Boston), Texas Instruments and IBM under contract from the US Air Force.\n\nThe Great Unix Wars\n\nIn 1983 Oracle announced that its engineers (basically Bob Miner and Bruce Scott) had rewritten its database management system in the C programming language, the language preferred by all Unix systems, an achievement that made Oracle's product easily portable across computer platforms. It was therefore ported to the most popular minicomputers and even to mainframes (that already had C compilers). It was also the first 32-bit relational database management system.\n\nSomething important happened in 1983 that had little to do with Unix technology but would have repercussions on Unix computers. The USA government decided that AT&T (the company that owned the Bell Labs and the Unix operating system) constituted a monopoly violating the anti-trust law and ordered the dismemberment of the colossal conglomerate (at the time the largest company in the world). AT&T had been forced since 1958 to make non-telephone technologies available to others, but now, broken up in separate companies, was free to make money out of the Unix operating system. Before the end of the year AT&T had a commercial version ready, which was renamed Unix System V. That was the beginning of the great Unix wars of the 1980s, pitting System V against BSD, i.e. AT&T's corporate profit-driven world versus the idealistic Bay Area hobbyists (notably SUN, which was rapidly dwarfing the competition). To further complicate the Unix landscape, in 1983 Richard Stallman at the MIT started working on a free clone of Unix that would contain no Unix code, code-named GNU, and in 1985 issued the GNU manifesto and launched the Free Software Foundation that criminalized proprietary software.\n\nIn theory, the Internet belonged to the USA government (via the DARPA). In practice, most decisions were taken by the various scientists that cooperated casually in maintaining it. For example, the SRI had always kept the \"directory\" of Internet nodes (a text file that returned a physical network address for each node). In 1983 Paul Mockapetris at SRI was assigned the task of developing the Domain Name System, so that each node would be identified by a \"domain name\" in a hierarchy of domain names. The DNS mapped domain names (such as www.scaruffi.com ) into IP addresses, replacing the old text file named HOSTS.TXT that SRI maintained on behalf of the entire Arpanet. The concept was refined (like all other concepts on the Internet) by the community via \"Requests for Comments\" (RFCs), developed and maintained by Jonathan Postel at UCLA. The following year the first DNS was implemented in Unix by students at U.C. Berkeley. This process was eventually formalized (in january 1986) in an Internet Engineering Task Force (IETF), which was open to everybody. Previously only DARPA staff was entitled to participate and vote in the Internet Configuration Control Board set up by Vint Cerf at DARPA in 1979, renamed the Internet Activities Board (IAB) in 1983. Postel was also in charge of the crucial task of assigning Internet addresses, which later became the Internet Assigned Numbers Authority (IANA), and he would remain in charge until his death in 1998 (by which time he had moved to the University of Southern California).\n\nJust like the personal computer and the Unix, the Internet too was largely shaped by a community of eccentric independents. From the beginning, despite the fact that the Arpanet was run by a powerful government agency via Bolt, Beranek and Newman, its director Lawrence Roberts had relied not on top-down decisions but on a decentralized model that involved the very users of the Internet to submit proposals for future directions. He organized retreats for Arpanet users. It was truly a government-mandated collaborative effort. It was another case in which the consumer was the producer, a community of \"prosumers\". In a sense, the Arpanet was conceived from the beginning as a project in progress, not as a fully specified project, a concept that is more likely to surface in military projects than in commercial product development. One of the side effects of this approach was that the Arpanet changed mission over time, transforming from a military project to survive a nuclear attack into a system for interpersonal communication and knowledge sharing. It fostered collaboration among geographically remote research labs, which was already not one of the initial goals. Even more unexpectedly, it became a popular tool for intranode communications and collaboration, as each node started connecting its multiple computers among themselves. E-mail itself was a user idea, never planned by the Arpanet's bureaucracy. Nobody commissioned it, approved it or promoted it. A user deployed it and other users started using it. By 1973 it probably accounted for the majority of Arpanet traffic. Again, the pseudo-socialist and anarchic idealism of the counterculture had found another form of reincarnation. The ethics of the Internet, just like the ethics of the Unix world and the ethics of the early personal-computer hobbyists, was not the brutal, heartless ethics of the corporate world nor the brutal, heartless ethics of Wall Street: it was the utopian ethics of the hippie communes transposed into a high-tech environment.\n\nIncidentally, in 1982 Scott Fahlman at Carnegie Mellon introduced the three-character sequence :-) to represent a smile in email messages, the \"smiley\", the first \"emoticon\".\n\nThe very nature of the revolution in personal computers, Unix and Internet mirrored more closely the continuous renovation of rock music than anything else. Just like rock magazines and radio stations were used to hail a \"next big thing\" every month and got music listeners addicted to expect a new genre every month, so computer magazines (and later Usenet groups) started talking about a technological \"next big thing\" every month and thus created the expectation for it in computer users.\n\nHowever, the parallel between the counterculture and the high-tech industry has an obvious limit: neither the personal computer nor Unix nor the Internet had anything to do with San Francisco itself. The headquarters of personal-computer innovation was the Santa Clara Valley, the part of the Bay Area that had witnessed the lowest amount of student riots, hippie be-ins and rock concerts (Stanford, in particular, had been largely indifferent to the whole counterculture). Unix and the Internet had now strong roots in Berkeley, but it was only in part a phenomenon of the Bay Area. It looked as if the marriage between counterculture and high-tech culture had to take place in neutral territory, close enough to the epicenter but far enough not to be affected by its extreme manifestations.\n\nShrink-wrapped Software\n\nUntil the dotcom boom of the 1990s Silicon Valley was home to many small software vendors but no major one. The 1980s witnessed a boom of software startups, but most of them remained small throughout the decade, and didn't survive more than a decade. However, the companies in Silicon Valley were among the first to adopt the \"shrink-wrapped\" model of the software business: selling software programs in boxes by mail order and through retail outlets.\n\nThe distribution channels were the visible difference, but behind it there were bigger conceptual differences. First of all, the idea behind \"boxed\" software was to sell thousands of units, not just a handful. Software had long been an artisan-kind of field, in which software companies customized a package for a customer (typically a very larger company or agency). Once boxed, a program was the same for everybody, larger or small. Secondly, the boxed product had to be priced like a consumer good, no more than the machine on which it would run. And, finally, there was no direct sales force, which made an enormous difference in client relationships. Companies like IBM invested huge amounts of resources in developing and maintaining client relationships (and would continue to do so long after the era of the mainframe). Companies in the low-price high-volume business could not afford a direct sales force of that nature, and therefore sacrificed client relationship altogether. Silicon Valley would never develop a passion for client relationships even after it became the main software center in the world. Silicon Valley engineers would always perceive custom applications as not as exciting as the application that is being used (without customizations) by thousands or millions of people.\n\nLasers and Nanotechnology\n\nThe personal computer obliterated all the other sectors, but the early 1980s were also, for example, the era of semiconductor lasers. Start-ups specializing in these high-power lasers included: Stanford Research Systems (SRS), founded in 1980 in Sunnyvale, Spectra Diode Labs, a 1983 joint venture between Spectra-Physics and Xerox PARC, and Lightwave, founded in 1984 in Mountain View. Despite the immense and rapid success of laser technology in all sorts of applications, the laser industry never took off like the computer industry. There were many parallels with the computer industry: Stanford had one of the best research teams in the world; Ed Ginzton was for laser what Terman had been for electronics; his laboratory at Stanford spun off several start-ups; employees fluctuated among those companies and founded new ones. The premises were very similar to the computer industry. However, this is a significant example of an industry based in Silicon Valley that did not achieve momentum.\n\nMicro-Electro-Mechanical Systems (MEMS) represented the infancy of nanotechnology. These were miniaturized devices made of microsensors, microactuators and microelectronics. In 1982 Kurt Petersen wrote the influential paper \"Silicon as a Mechanical Material\" and founded Transensory Devices in Fremont (later IC Sensors in Milpitas), a pioneering company in commercializing MEMS devices. Petersen envisioned \"a broad range of inexpensive, batch-fabricated, high-performance sensors and transducers easily interfaced with the rapidly proliferating microprocessor.\"\n\nIn 1980 Stanford Electrical Engineering professor John Linvill had the idea for the Center for Integrated Systems, a lab that, working in close interaction with the industry, was to bring together material, hardware and software engineers for the purpose of designing integrated circuits. This center would evolve to become the largest academic laboratory in the country for building nanostructures. For example, Gregory Kovacs would design sensor systems that combine detectors on silicon wafers the same way electrical circuits are integrated on computer chips.\n\nAnarchy\n\nThe 1980s was the age of the spiritual revival that turned so many former hippies into new-age adepts. Arguing for a return to a more natural way of life, they were fiercely opposed to science and rationalism, and viewed technology as evil. The intellectual zeitgeist of the Bay Area was hardly in sync with its high-tech boom. The dichotomy between luddites and tecnophiles would remain a distinctive contradiction of the Bay Area, just like materialism and spirituality could coexist in the lifestyle of the same \"yuppie\" (young urban professional).\n\nAn important contribution to these booming industries came from people who were completely immune to the intellectual mood of the Bay Area: immigrants. The 1970s had witnessed the first wave of immigration of engineers from Europe and Asia. In the early 1980s they contributed significantly to the boom of Silicon Valley. For example, Chinese and Indian executives ran 13% of Silicon Valley's high-tech companies founded between 1980 and 1984. Additionally, the Bay Area had been attracting young people from the other states of the USA since the 1960s. It was sunny, \"cool\", advanced, cosmopolitan, and opportunities popped up all the time. It had the mythological appeal of the Far West and the quasi-mystic appeal of the promised land. At the same time it had become a nice and wealthy place for living, a dreamland for the highly educated youth of the East Coast and the Midwest.\n\nSilicon Valley was quite unique in that it was both a place of great ethnic diversity and a place of high technological saturation.\n\nIt was also a place where the boring corporate world was inexistent and despised. In 1980 there were about 3,000 electronics firms in the Bay Area: the vast majority had less than 10 employees, and only 15% of them had more than 100.\n\nSilicon Valley exhibited a propensity towards spawning new firms even when the market was not ready for an avalanche of products. Viewed from above, the creation and destruction of companies was chaotic. The lifespan of start-ups was getting shorter, not longer. What mattered was not the life expectancy of an individual company but the success of the entire ecosystem. The price to pay for the latter was a short lifespan for most of the individual companies.\n\nHigh labor mobility was crucial to the implementation of this model of continuous regeneration as well as to sustain the breathtaking growth of successful start-ups.\n\nThe mobility of labor was also enabled by an anti-union spirit. It is not trivial to understand from what it originated. After all, San Francisco was most unionized city in the nation at the beginning of the 20th century, and socialist agit-prop groups were ubiquitous in San Francisco and Berkeley during the 1960s. Perhaps it was precisely a desire not to be identified with the old-fashioned business style of San Francisco that led Silicon Valley to adopt the opposite stance towards unions.\n\nThe old computing world (mainly based on the East Coast) was controlled top-down and not at one but two levels: the users of a mainframe or mini had to be hired by a company or university, i.e. access was controlled top-down by the owner of the expensive computer; and the technology of that mainframe or mini computer was proprietary, i.e. controlled top-down by the computer manufacturer. The personal-computer world, instead, was decentralized and anarchic at both levels.\n\nIt was certainly ironic how an invention whose original purpose was purely military and reserved to a tightly guarded small number of laboratories was rapidly evolving into a ubiquitous data processing and communication device for ordinary offices and even households."
    }
}