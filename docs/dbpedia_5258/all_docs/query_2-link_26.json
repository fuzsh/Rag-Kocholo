{
    "id": "dbpedia_5258_2",
    "rank": 26,
    "data": {
        "url": "https://www.louisaslett.com/Courses/DSSC/notes/lab-5-data-visualisation-base.html",
        "read_more_link": "",
        "language": "en",
        "title": "Data Science and Statistical Computing",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.louisaslett.com/Courses/DSSC/notes/DSSC_files/figure-html/53-lab5-012-1.png",
            "https://www.louisaslett.com/Courses/DSSC/notes/DSSC_files/figure-html/53-lab5-013-1.png",
            "https://www.louisaslett.com/Courses/DSSC/notes/DSSC_files/figure-html/53-lab5-015-1.png",
            "https://www.louisaslett.com/Courses/DSSC/notes/DSSC_files/figure-html/53-lab5-016-1.png",
            "https://www.louisaslett.com/Courses/DSSC/notes/DSSC_files/figure-html/53-lab5-019-1.png",
            "https://www.louisaslett.com/Courses/DSSC/notes/DSSC_files/figure-html/53-lab5-022-1.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "These are notes for the MATH2687 course at Durham University.",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "5.5 Movies ðï¸ data\n\nThe Internet Movie Database (IMDB, imdb.com) is a fantastic resource for film buffs. A snapshot of data on a large number of films was âweb scrapedâ and and has been made available in the R package ggplot2movies. You might have seen a similar data set in Stats II recently (if you take it), but itâs too good not to look at again here in DSSC slightly differently!\n\nIn real life data science such as you might encounter in your careers after University, there are all sorts of odd things that can get thrown up at you, so part of this course is getting used to spotting and handling these things, as well as developing a healthy inquisitiveness to dig deep into data you work with.\n\nClick for solution\n\n## SOLUTION ii. data(\"movies\", package = \"ggplot2movies\")\n\nClick for solution\n\n## SOLUTION # Look in the help file ?ggplot2movies::movies\n\nThe help file reports there are 28,819 films in the dataset. Since this is a data frame, we know that observations are in rows, variables are in columns, so to check the actual data that was loaded we just need to see how many rows there are:\n\nnrow(movies)\n\n[1] 58788\n\nUh-oh! Looks like the documentation is out of date! This highlights that you need to be careful about blindly trusting documentation.\n\nClick for solution\n\n## SOLUTION # We can just run the max directly on the budget variable. max(movies$budget)\n\n[1] NA\n\n# Ah! We have run into trouble because some of the budgets must be missing (NA) # Missing data happens in real world data outside the classroom and is a real # pain, but fortunately saw with the mean function back in the first lecture we # could use na.omit on the vector before passing to the function, or use the # na.rm argument (if you look at the documentation ?max you'll see max has the # same option) max(movies$budget, na.rm = TRUE)\n\n[1] 200000000\n\nmax(na.omit(movies$budget))\n\n[1] 200000000\n\nClick for solution You might wonder why the question tells us to subset the data first. Canât we just do a query for the film with budget equal to $200 millon? Unfortunately, the usual method of subsetting in R doesnât play well with missing values, because it will create a whole missing row when you try to match 200000000 against an NA. For example, try running the following (it is huge so the output is not embedded in these solutions)\n\n## NOT THE SOLUTION(!) movies[movies$budget==200000000,]\n\nTo understand what is happening, as regularly advised in lectures, break it down and look at what happens for just this:\n\nmovies$budget==200000000\n\nWeâll learn methods that handle this much more gracefully in the coming weeks!\n\nFor now, letâs follow the advice of the question and get rid of the rows with an NA budget before trying to identify the big budget movie.\n\n## SOLUTION movies.withbudget[movies.withbudget$budget==200000000,]\n\ntitle year length budget rating votes r1 r2 r3 r4 r5 r6 48518 Spider-Man 2 2004 127 200000000 7.9 40256 4.5 4.5 4.5 4.5 4.5 4.5 52348 Titanic 1997 194 200000000 6.9 90195 14.5 4.5 4.5 4.5 4.5 4.5 r7 r8 r9 r10 mpaa Action Animation Comedy Drama Documentary 48518 14.5 24.5 24.5 24.5 PG-13 1 0 0 0 0 52348 14.5 14.5 14.5 24.5 PG-13 0 0 0 1 0 Romance Short 48518 0 0 52348 1 0\n\nAh-ha! So actually there is a tie for the highest budget movie in the dataset, between Titanic ð§ð¥ï¸ and Spider-Man 2 ð·ï¸ð¨\n\nThe remainder of the questions should be done with the full data, donât use only the subset of those with a budget! To avoid any accident, you can remove temporary variables once you donât need them any more. Run the following code to remove the subsetted movies from your environment in R.\n\nClick for solution\n\nThere is something interesting going on here, because we can only see one visible bar right down near small values on the x-axis, and yet the x-axis goes all the way up past 5000?! We know from the lecture that R automatically scales the axis to the range of the data, so this seems to imply that there is some film in the data with a running time of nearly 3.5 days!\n\nClick for solution\n\n## SOLUTION # Just boxplot would be fine too ... I've used the horizontal option so it looks # a bit nicer (see the documentation for boxplot!) boxplot(movies$length, horizontal = TRUE)\n\nIn this instance a boxplot is much better to see what is going on, since any outlying points beyond the right tail are shown as individual points. Amazingly there are 3 films with running times over 1000 minutes (or 16.7 hours!) Letâs look at them:\n\nmovies[movies$length >1000,]\n\ntitle year length budget 11937 Cure for Insomnia, The 1987 5220 NA 18741 Four Stars 1967 1100 NA 30574 Longest Most Meaningless Movie in the World, The 1970 2880 NA rating votes r1 r2 r3 r4 r5 r6 r7 r8 r9 r10 mpaa Action 11937 3.8 59 44.5 4.5 4.5 4.5 0 0 0.0 4.5 4.5 44.5 0 18741 3.0 12 24.5 0.0 4.5 0.0 0 0 4.5 0.0 0.0 45.5 0 30574 6.4 15 44.5 0.0 0.0 0.0 0 0 0.0 0.0 0.0 64.5 0 Animation Comedy Drama Documentary Romance Short 11937 0 0 0 0 0 0 18741 0 0 0 0 0 0 30574 0 0 0 0 0 0\n\nSo in 1970, a film entitled âThe Longest Most Meaningless Movie in the Worldâ was filmed, with a running time of 2880 minutes. Perhaps such an audacious title was imprudent, since seventeen years later a film entitled âThe Cure for Insomniaâ blew that runtime out of the water! Having had a quick look it is quiiittttttttteeeeeeeeeeeeeeeee ð¤ð¤ð¤ð¤ð´\n\nSorry dropped off there!\n\nWith quite a large number of very outlying observations it is unsurprising that the histogram with any reasonable bin width was not very informative.\n\nClick for solution\n\n## SOLUTION hist(movies[movies$length<=180,\"length\"], breaks = seq(0, 180, 1))\n\nThis is a rather unusual appearance for a histogram, because there are a series of âspikesâ at somewhat regular intervals, meaning at some regular spacing in the movie length.\n\nClick for solution We save the histogram object, just like we did in the lecture, so that we can examine the detail of the histogram:\n\n## SOLUTION h <-hist(movies[movies$length<=180,\"length\"], breaks = seq(0, 180, 1))\n\nstr(h)\n\nList of 6 $ breaks : num [1:181] 0 1 2 3 4 5 6 7 8 9 ... $ counts : int [1:180] 169 116 243 185 279 726 1379 700 432 576 ... $ density : num [1:180] 0.00289 0.00199 0.00416 0.00317 0.00478 ... $ mids : num [1:180] 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 ... $ xname : chr \"movies[movies$length <= 180, \\\"length\\\"]\" $ equidist: logi TRUE - attr(*, \"class\")= chr \"histogram\"\n\nNotice that h contains the list structure we saw in lectures. We are interested in the $breaks and $counts variables. The $breaks is 1 longer than $counts since it defines the boundaries of the bins, so for example the first count of 169 applies to the interval 0â1.\n\nLetâs get the indices in descending order for the $count variable, which will correspondingly tell us the index in $breaks for the left end of the interval of the highest spikes on the histogram. We can then use perhaps the first 3 of these to get the movie length for the highest few spikes.\n\n# NOTE: check the help file ?order and you'll see order sorts ascending by # default! So we need to change to descending. desc.length <-order(h$counts, decreasing = TRUE) h$breaks[desc.length[1:3]]\n\n[1] 89 94 99\n\nSo we have these odd spikes in the intervals 89â90, 94â95, 99â100. The question also urges us to be certain about whether these are left or right open intervals. Look at the documentation:\n\nThe third paragraph of the details section confirms that by default intervals are left open, so the three highest spikes happen in: \\[(89,90] \\quad (94,95] \\quad (99,100]\\] and we can now draw a fairly reasonable conclusion that there is a rounding effect happening with some films. What does this mean? In the real world, data entry is not always perfect: sometimes the person entering the data may choose to round to the nearest whole number, or nearest 5, nearest 10, etc. It would seem plausible that what we see here is data entry rounding where times are sometimes rounded to the nearest 5 minutes.\n\nClick for solution\n\n## SOLUTION plot(movies$year, movies$length, ylim = c(0, 500)) lines(lowess(movies$year, movies$length), col = \"red\") abline(lm(movies$length ~ movies$year), col = \"green\")\n\nBoth a smoother and straight line fit appear to show movies have been getting longer over the years. The smoother seems to indicate this trend may have ceased around 1980.\n\nClick for solution (i)\n\nbootstrap <-function(x, ci = 0.99, B = 10000) { S.star <-rep(0, B) for(i in 1:B) { x.star <-sample(x, replace = TRUE) S.star[i] <-median(x.star) } lower <-sort(S.star)[round((1-ci)/2*B)] upper <-sort(S.star)[round((ci+(1-ci)/2)*B)] return(c(lower, upper)) }\n\nClick for solution (ii)\n\n# By looking at: range(movies$year)\n\n[1] 1893 2005\n\n# we see that the decades in the data run from 1890/1900 to 2000/2010. # Using the hint, we will create a NULL then rbind 1-row data frames to it # to hold the median confidence intervals med.CIs <-NULL for(decade in seq(1890, 2000, 10)) { new.CI <-bootstrap(movies[movies$year >= decade & movies$year < decade+10,\"length\"]) med.CIs <-rbind(med.CIs, data.frame(decade = decade, lower = new.CI[1], upper = new.CI[2])) } # Now we should have the required data frame: med.CIs\n\ndecade lower upper 1 1890 1.0 1 2 1900 3.0 5 3 1910 19.0 31 4 1920 69.0 75 5 1930 69.0 71 6 1940 74.0 78 7 1950 84.5 86 8 1960 91.0 93 9 1970 93.0 94 10 1980 93.0 94 11 1990 92.0 93 12 2000 90.0 90\n\nClick for solution (iii)\n\n# As explained in the lecture, we need to use plot first as this creates a new # plot, so we will call with line type. # Also we add 5 to centre the point in the middle of the decade plot(med.CIs$decade+5, med.CIs$lower, type=\"l\") # Then we add the upper confidence interval by using lines to add to the plot lines(med.CIs$decade+5, med.CIs$upper, type=\"l\")\n\nThis is really nice: with so much data the confidence intervals on our bootstrap are really tight! It looks like median lengths have actually slightly reduced toward the end of the data set.\n\nðð Done, end of lab! ðð"
    }
}