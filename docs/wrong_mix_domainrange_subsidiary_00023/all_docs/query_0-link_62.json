{
    "id": "wrong_mix_domainrange_subsidiary_00023_0",
    "rank": 62,
    "data": {
        "url": "https://www.science.gov/topicpages/r/recognition%2Bsystems%2Btechnology",
        "read_more_link": "",
        "language": "en",
        "title": "recognition systems technology: Topics by Science.gov",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.science.gov/scigov/desktop/en/images/SciGov_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Intelligent Facial Recognition Systems: Technology advancements for security applications\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nBeer, C.L.\n\n1993-07-01\n\nInsider problems such as theft and sabotage can occur within the security and surveillance realm of operations when unauthorized people obtain access to sensitive areas. A possible solution to these problems is a means to identify individuals (not just credentials or badges) in a given sensitive area and provide full time personnel accountability. One approach desirable at Department of Energy facilities for access control and/or personnel identification is an Intelligent Facial Recognition System (IFRS) that is non-invasive to personnel. Automatic facial recognition does not require the active participation of the enrolled subjects, unlike most other biological measurement (biometric) systems (e.g.,moreÂ Â» fingerprint, hand geometry, or eye retinal scan systems). It is this feature that makes an IFRS attractive for applications other than access control such as emergency evacuation verification, screening, and personnel tracking. This paper discusses current technology that shows promising results for DOE and other security applications. A survey of research and development in facial recognition identified several companies and universities that were interested and/or involved in the area. A few advanced prototype systems were also identified. Sandia National Laboratories is currently evaluating facial recognition systems that are in the advanced prototype stage. The initial application for the evaluation is access control in a controlled environment with a constant background and with cooperative subjects. Further evaluations will be conducted in a less controlled environment, which may include a cluttered background and subjects that are not looking towards the camera. The outcome of the evaluations will help identify areas of facial recognition systems that need further development and will help to determine the effectiveness of the current systems for security applications.Â«Â less\n\nPerformance Evaluation of Speech Recognition Systems as a Next-Generation Pilot-Vehicle Interface Technology\n\nNASA Technical Reports Server (NTRS)\n\nArthur, Jarvis J., III; Shelton, Kevin J.; Prinzel, Lawrence J., III; Bailey, Randall E.\n\n2016-01-01\n\nDuring the flight trials known as Gulfstream-V Synthetic Vision Systems Integrated Technology Evaluation (GV-SITE), a Speech Recognition System (SRS) was used by the evaluation pilots. The SRS system was intended to be an intuitive interface for display control (rather than knobs, buttons, etc.). This paper describes the performance of the current \"state of the art\" Speech Recognition System (SRS). The commercially available technology was evaluated as an application for possible inclusion in commercial aircraft flight decks as a crew-to-vehicle interface. Specifically, the technology is to be used as an interface from aircrew to the onboard displays, controls, and flight management tasks. A flight test of a SRS as well as a laboratory test was conducted.\n\nThe use of open and machine vision technologies for development of gesture recognition intelligent systems\n\nNASA Astrophysics Data System (ADS)\n\nCherkasov, Kirill V.; Gavrilova, Irina V.; Chernova, Elena V.; Dokolin, Andrey S.\n\n2018-05-01\n\nThe article is devoted to reflection of separate aspects of intellectual system gesture recognition development. The peculiarity of the system is its intellectual block which completely based on open technologies: OpenCV library and Microsoft Cognitive Toolkit (CNTK) platform. The article presents the rationale for the choice of such set of tools, as well as the functional scheme of the system and the hierarchy of its modules. Experiments have shown that the system correctly recognizes about 85% of images received from sensors. The authors assume that the improvement of the algorithmic block of the system will increase the accuracy of gesture recognition up to 95%.\n\nThe MITLL NIST LRE 2015 Language Recognition System\n\nDTIC Science & Technology\n\n2016-05-06\n\nThe MITLL NIST LRE 2015 Language Recognition System Pedro Torres-Carrasquillo, Najim Dehak*, Elizabeth Godoy, Douglas Reynolds, Fred Richardson...most recent MIT Lincoln Laboratory language recognition system developed for the NIST 2015 Language Recognition Evaluation (LRE). The submission...Task The National Institute of Science and Technology ( NIST ) has conducted formal evaluations of language detection algorithms since 1994. In\n\nThe MITLL NIST LRE 2015 Language Recognition system\n\nDTIC Science & Technology\n\n2016-02-05\n\nThe MITLL NIST LRE 2015 Language Recognition System Pedro Torres-Carrasquillo, Najim Dehak*, Elizabeth Godoy, Douglas Reynolds, Fred Richardson...recent MIT Lincoln Laboratory language recognition system developed for the NIST 2015 Language Recognition Evaluation (LRE). The submission features a...National Institute of Science and Technology ( NIST ) has conducted formal evaluations of language detection algorithms since 1994. In previous\n\nDevelopment of a written music-recognition system using Java and open source technologies\n\nNASA Astrophysics Data System (ADS)\n\nLoibner, Gernot; Schwarzl, Andreas; KovaÄ, Matthias; Paulus, Dietmar; PÃ¶lzleitner, Wolfgang\n\n2005-10-01\n\nWe report on the development of a software system to recognize and interpret printed music. The overall goal is to scan printed music sheets, analyze and recognize the notes, timing, and written text, and derive the all necessary information to use the computers MIDI sound system to play the music. This function is primarily useful for musicians who want to digitize printed music for editing purposes. There exist a number of commercial systems that offer such a functionality. However, on testing these systems, we were astonished on how weak they behave in their pattern recognition parts. Although we submitted very clear and rather flawless scanning input, none of these systems was able to e.g. recognize all notes, staff lines, and systems. They all require a high degree of interaction, post-processing, and editing to get a decent digital version of the hard copy material. In this paper we focus on the pattern recognition area. In a first approach we tested more or less standard methods of adaptive thresholding, blob detection, line detection, and corner detection to find the notes, staff lines, and candidate objects subject to OCR. Many of the objects on this type of material can be learned in a training phase. None of the commercial systems we saw offers the option to train special characters or unusual signatures. A second goal in this project is to use a modern software engineering platform. We were interested in how well Java and open source technologies are suitable for pattern recognition and machine vision. The scanning of music served as a case-study.\n\nSpeech recognition technology: an outlook for human-to-machine interaction.\n\nPubMed\n\nErdel, T; Crooks, S\n\n2000-01-01\n\nSpeech recognition, as an enabling technology in healthcare-systems computing, is a topic that has been discussed for quite some time, but is just now coming to fruition. Traditionally, speech-recognition software has been constrained by hardware, but improved processors and increased memory capacities are starting to remove some of these limitations. With these barriers removed, companies that create software for the healthcare setting have the opportunity to write more successful applications. Among the criticisms of speech-recognition applications are the high rates of error and steep training curves. However, even in the face of such negative perceptions, there remains significant opportunities for speech recognition to allow healthcare providers and, more specifically, physicians, to work more efficiently and ultimately spend more time with their patients and less time completing necessary documentation. This article will identify opportunities for inclusion of speech-recognition technology in the healthcare setting and examine major categories of speech-recognition software--continuous speech recognition, command and control, and text-to-speech. We will discuss the advantages and disadvantages of each area, the limitations of the software today, and how future trends might affect them.\n\nComposite Artistry Meets Facial Recognition Technology: Exploring the Use of Facial Recognition Technology to Identify Composite Images\n\nDTIC Science & Technology\n\n2011-09-01\n\nbe submitted into a facial recognition program for comparison with millions of possible matches, offering abundant opportunities to identify the...to leverage the robust number of comparative opportunities associated with facial recognition programs. This research investigates the efficacy of...combining composite forensic artistry with facial recognition technology to create a viable investigative tool to identify suspects, as well as better\n\nEvaluation of a voice recognition system for the MOTAS pseudo pilot station function\n\nNASA Technical Reports Server (NTRS)\n\nHouck, J. A.\n\n1982-01-01\n\nThe Langley Research Center has undertaken a technology development activity to provide a capability, the mission oriented terminal area simulation (MOTAS), wherein terminal area and aircraft systems studies can be performed. An experiment was conducted to evaluate state-of-the-art voice recognition technology and specifically, the Threshold 600 voice recognition system to serve as an aircraft control input device for the MOTAS pseudo pilot station function. The results of the experiment using ten subjects showed a recognition error of 3.67 percent for a 48-word vocabulary tested against a programmed vocabulary of 103 words. After the ten subjects retrained the Threshold 600 system for the words which were misrecognized or rejected, the recognition error decreased to 1.96 percent. The rejection rates for both cases were less than 0.70 percent. Based on the results of the experiment, voice recognition technology and specifically the Threshold 600 voice recognition system were chosen to fulfill this MOTAS function.\n\nLicense Plate Recognition System for Indian Vehicles\n\nNASA Astrophysics Data System (ADS)\n\nSanap, P. R.; Narote, S. P.\n\n2010-11-01\n\nWe consider the task of recognition of Indian vehicle number plates (also called license plates or registration plates in other countries). A system for Indian number plate recognition must cope with wide variations in the appearance of the plates. Each state uses its own range of designs with font variations between the designs. Also, vehicle owners may place the plates inside glass covered frames or use plates made of nonstandard materials. These issues compound the complexity of automatic number plate recognition, making existing approaches inadequate. We have developed a system that incorporates a novel combination of image processing and artificial neural network technologies to successfully locate and read Indian vehicle number plates in digital images. Commercial application of the system is envisaged.\n\n[Research on Barrier-free Home Environment System Based on Speech Recognition].\n\nPubMed\n\nZhu, Husheng; Yu, Hongliu; Shi, Ping; Fang, Youfang; Jian, Zhuo\n\n2015-10-01\n\nThe number of people with physical disabilities is increasing year by year, and the trend of population aging is more and more serious. In order to improve the quality of the life, a control system of accessible home environment for the patients with serious disabilities was developed to control the home electrical devices with the voice of the patients. The control system includes a central control platform, a speech recognition module, a terminal operation module, etc. The system combines the speech recognition control technology and wireless information transmission technology with the embedded mobile computing technology, and interconnects the lamp, electronic locks, alarms, TV and other electrical devices in the home environment as a whole system through a wireless network node. The experimental results showed that speech recognition success rate was more than 84% in the home environment.\n\nThe Army word recognition system\n\nNASA Technical Reports Server (NTRS)\n\nHadden, David R.; Haratz, David\n\n1977-01-01\n\nThe application of speech recognition technology in the Army command and control area is presented. The problems associated with this program are described as well as as its relevance in terms of the man/machine interactions, voice inflexions, and the amount of training needed to interact with and utilize the automated system.\n\nPermutation coding technique for image recognition systems.\n\nPubMed\n\nKussul, Ernst M; Baidyk, Tatiana N; Wunsch, Donald C; Makeyev, Oleksandr; MartÃ­n, Anabel\n\n2006-11-01\n\nA feature extractor and neural classifier for image recognition systems are proposed. The proposed feature extractor is based on the concept of random local descriptors (RLDs). It is followed by the encoder that is based on the permutation coding technique that allows to take into account not only detected features but also the position of each feature on the image and to make the recognition process invariant to small displacements. The combination of RLDs and permutation coding permits us to obtain a sufficiently general description of the image to be recognized. The code generated by the encoder is used as an input data for the neural classifier. Different types of images were used to test the proposed image recognition system. It was tested in the handwritten digit recognition problem, the face recognition problem, and the microobject shape recognition problem. The results of testing are very promising. The error rate for the Modified National Institute of Standards and Technology (MNIST) database is 0.44% and for the Olivetti Research Laboratory (ORL) database it is 0.1%.\n\nFormal implementation of a performance evaluation model for the face recognition system.\n\nPubMed\n\nShin, Yong-Nyuo; Kim, Jason; Lee, Yong-Jun; Shin, Woochang; Choi, Jin-Young\n\n2008-01-01\n\nDue to usability features, practical applications, and its lack of intrusiveness, face recognition technology, based on information, derived from individuals' facial features, has been attracting considerable attention recently. Reported recognition rates of commercialized face recognition systems cannot be admitted as official recognition rates, as they are based on assumptions that are beneficial to the specific system and face database. Therefore, performance evaluation methods and tools are necessary to objectively measure the accuracy and performance of any face recognition system. In this paper, we propose and formalize a performance evaluation model for the biometric recognition system, implementing an evaluation tool for face recognition systems based on the proposed model. Furthermore, we performed evaluations objectively by providing guidelines for the design and implementation of a performance evaluation system, formalizing the performance test process.\n\nA Compact Prototype of an Optical Pattern Recognition System\n\nNASA Technical Reports Server (NTRS)\n\nJin, Y.; Liu, H. K.; Marzwell, N. I.\n\n1996-01-01\n\nIn the Technology 2006 Case Studies/Success Stories presentation, we will describe and demonstrate a prototype of a compact optical pattern recognition system as an example of a successful technology transfer and continuuing development of state-of-the-art know-how by the close collaboration among government, academia, and small business via the NASA SBIR program. The prototype consists of a complete set of optical pattern recognition hardware with multi-channel storage and retrieval capability that is compactly configured inside a portable 1'X 2'X 3' aluminum case.\n\nPractical vision based degraded text recognition system\n\nNASA Astrophysics Data System (ADS)\n\nMohammad, Khader; Agaian, Sos; Saleh, Hani\n\n2011-02-01\n\nRapid growth and progress in the medical, industrial, security and technology fields means more and more consideration for the use of camera based optical character recognition (OCR) Applying OCR to scanned documents is quite mature, and there are many commercial and research products available on this topic. These products achieve acceptable recognition accuracy and reasonable processing times especially with trained software, and constrained text characteristics. Even though the application space for OCR is huge, it is quite challenging to design a single system that is capable of performing automatic OCR for text embedded in an image irrespective of the application. Challenges for OCR systems include; images are taken under natural real world conditions, Surface curvature, text orientation, font, size, lighting conditions, and noise. These and many other conditions make it extremely difficult to achieve reasonable character recognition. Performance for conventional OCR systems drops dramatically as the degradation level of the text image quality increases. In this paper, a new recognition method is proposed to recognize solid or dotted line degraded characters. The degraded text string is localized and segmented using a new algorithm. The new method was implemented and tested using a development framework system that is capable of performing OCR on camera captured images. The framework allows parameter tuning of the image-processing algorithm based on a training set of camera-captured text images. Novel methods were used for enhancement, text localization and the segmentation algorithm which enables building a custom system that is capable of performing automatic OCR which can be used for different applications. The developed framework system includes: new image enhancement, filtering, and segmentation techniques which enabled higher recognition accuracies, faster processing time, and lower energy consumption, compared with the best state of the art published\n\nAn online handwriting recognition system for Turkish\n\nNASA Astrophysics Data System (ADS)\n\nVural, Esra; Erdogan, Hakan; Oflazer, Kemal; Yanikoglu, Berrin A.\n\n2004-12-01\n\nDespite recent developments in Tablet PC technology, there has not been any applications for recognizing handwritings in Turkish. In this paper, we present an online handwritten text recognition system for Turkish, developed using the Tablet PC interface. However, even though the system is developed for Turkish, the addressed issues are common to online handwriting recognition systems in general. Several dynamic features are extracted from the handwriting data for each recorded point and Hidden Markov Models (HMM) are used to train letter and word models. We experimented with using various features and HMM model topologies, and report on the effects of these experiments. We started with first and second derivatives of the x and y coordinates and relative change in the pen pressure as initial features. We found that using two more additional features, that is, number of neighboring points and relative heights of each point with respect to the base-line improve the recognition rate. In addition, extracting features within strokes and using a skipping state topology improve the system performance as well. The improved system performance is 94% in recognizing handwritten words from a 1000-word lexicon.\n\nAn online handwriting recognition system for Turkish\n\nNASA Astrophysics Data System (ADS)\n\nVural, Esra; Erdogan, Hakan; Oflazer, Kemal; Yanikoglu, Berrin A.\n\n2005-01-01\n\nDespite recent developments in Tablet PC technology, there has not been any applications for recognizing handwritings in Turkish. In this paper, we present an online handwritten text recognition system for Turkish, developed using the Tablet PC interface. However, even though the system is developed for Turkish, the addressed issues are common to online handwriting recognition systems in general. Several dynamic features are extracted from the handwriting data for each recorded point and Hidden Markov Models (HMM) are used to train letter and word models. We experimented with using various features and HMM model topologies, and report on the effects of these experiments. We started with first and second derivatives of the x and y coordinates and relative change in the pen pressure as initial features. We found that using two more additional features, that is, number of neighboring points and relative heights of each point with respect to the base-line improve the recognition rate. In addition, extracting features within strokes and using a skipping state topology improve the system performance as well. The improved system performance is 94% in recognizing handwritten words from a 1000-word lexicon.\n\nDance recognition system using lower body movement.\n\nPubMed\n\nSimpson, Travis T; Wiesner, Susan L; Bennett, Bradford C\n\n2014-02-01\n\nThe current means of locating specific movements in film necessitate hours of viewing, making the task of conducting research into movement characteristics and patterns tedious and difficult. This is particularly problematic for the research and analysis of complex movement systems such as sports and dance. While some systems have been developed to manually annotate film, to date no automated way of identifying complex, full body movement exists. With pattern recognition technology and knowledge of joint locations, automatically describing filmed movement using computer software is possible. This study used various forms of lower body kinematic analysis to identify codified dance movements. We created an algorithm that compares an unknown move with a specified start and stop against known dance moves. Our recognition method consists of classification and template correlation using a database of model moves. This system was optimized to include nearly 90 dance and Tai Chi Chuan movements, producing accurate name identification in over 97% of trials. In addition, the program had the capability to provide a kinematic description of either matched or unmatched moves obtained from classification recognition.\n\nDesign and development of an ancient Chinese document recognition system\n\nNASA Astrophysics Data System (ADS)\n\nPeng, Liangrui; Xiu, Pingping; Ding, Xiaoqing\n\n2003-12-01\n\nThe digitization of ancient Chinese documents presents new challenges to OCR (Optical Character Recognition) research field due to the large character set of ancient Chinese characters, variant font types, and versatile document layout styles, as these documents are historical reflections to the thousands of years of Chinese civilization. After analyzing the general characteristics of ancient Chinese documents, we present a solution for recognition of ancient Chinese documents with regular font-types and layout-styles. Based on the previous work on multilingual OCR in TH-OCR system, we focus on the design and development of two key technologies which include character recognition and page segmentation. Experimental results show that the developed character recognition kernel of 19,635 Chinese characters outperforms our original traditional Chinese recognition kernel; Benchmarked test on printed ancient Chinese books proves that the proposed system is effective for regular ancient Chinese documents.\n\nThe A2iA French handwriting recognition system at the Rimes-ICDAR2011 competition\n\nNASA Astrophysics Data System (ADS)\n\nMenasri, FarÃ¨s; Louradour, JÃ©rÃ´me; Bianne-Bernard, Anne-Laure; Kermorvant, Christopher\n\n2012-01-01\n\nThis paper describes the system for the recognition of French handwriting submitted by A2iA to the competition organized at ICDAR2011 using the Rimes database. This system is composed of several recognizers based on three different recognition technologies, combined using a novel combination method. A framework multi-word recognition based on weighted finite state transducers is presented, using an explicit word segmentation, a combination of isolated word recognizers and a language model. The system was tested both for isolated word recognition and for multi-word line recognition and submitted to the RIMES-ICDAR2011 competition. This system outperformed all previously proposed systems on these tasks.\n\nBiometrics: A Look at Facial Recognition\n\nDTIC Science & Technology\n\na facial recognition system in the city’s Oceanfront tourist area. The system has been tested and has recently been fully implemented. Senator...Kenneth W. Stolle, the Chairman of the Virginia State Crime Commission, established a Facial Recognition Technology Sub-Committee to examine the issue of... facial recognition technology. This briefing begins by defining biometrics and discussing examples of the technology. It then explains how biometrics\n\nPage Recognition: Quantum Leap In Recognition Technology\n\nNASA Astrophysics Data System (ADS)\n\nMiller, Larry\n\n1989-07-01\n\nNo milestone has proven as elusive as the always-approaching \"year of the LAN,\" but the \"year of the scanner\" might claim the silver medal. Desktop scanners have been around almost as long as personal computers. And everyone thinks they are used for obvious desktop-publishing and business tasks like scanning business documents, magazine articles and other pages, and translating those words into files your computer understands. But, until now, the reality fell far short of the promise. Because it's true that scanners deliver an accurate image of the page to your computer, but the software to recognize this text has been woefully disappointing. Old optical-character recognition (OCR) software recognized such a limited range of pages as to be virtually useless to real users. (For example, one OCR vendor specified 12-point Courier font from an IBM Selectric typewriter: the same font in 10-point, or from a Diablo printer, was unrecognizable!) Computer dealers have told me the chasm between OCR expectations and reality is so broad and deep that nine out of ten prospects leave their stores in disgust when they learn the limitations. And this is a very important, very unfortunate gap. Because the promise of recognition -- what people want it to do -- carries with it tremendous improvements in our productivity and ability to get tons of written documents into our computers where we can do real work with it. The good news is that a revolutionary new development effort has led to the new technology of \"page recognition,\" which actually does deliver the promise we've always wanted from OCR. I'm sure every reader appreciates the breakthrough represented by the laser printer and page-makeup software, a combination so powerful it created new reasons for buying a computer. A similar breakthrough is happening right now in page recognition: the Macintosh (and, I must admit, other personal computers) equipped with a moderately priced scanner and OmniPage software (from Caere\n\nFacial recognition in education system\n\nNASA Astrophysics Data System (ADS)\n\nKrithika, L. B.; Venkatesh, K.; Rathore, S.; Kumar, M. Harish\n\n2017-11-01\n\nHuman beings exploit emotions comprehensively for conveying messages and their resolution. Emotion detection and face recognition can provide an interface between the individuals and technologies. The most successful applications of recognition analysis are recognition of faces. Many different techniques have been used to recognize the facial expressions and emotion detection handle varying poses. In this paper, we approach an efficient method to recognize the facial expressions to track face points and distances. This can automatically identify observer face movements and face expression in image. This can capture different aspects of emotion and facial expressions.\n\n[Application of image recognition technology in census of national traditional Chinese medicine resources].\n\nPubMed\n\nZhang, Xiao-Bo; Ge, Xiao-Guang; Jin, Yan; Shi, Ting-Ting; Wang, Hui; Li, Meng; Jing, Zhi-Xian; Guo, Lan-Ping; Huang, Lu-Qi\n\n2017-11-01\n\nWith the development of computer and image processing technology, image recognition technology has been applied to the national medicine resources census work at all stages.Among them: â In the preparatory work, in order to establish a unified library of traditional Chinese medicine resources, using text recognition technology based on paper materials, be the assistant in the digitalization of various categories related to Chinese medicine resources; to determine the representative area and plots of the survey from each census team, based on the satellite remote sensing image and vegetation map and other basic data, using remote sensing image classification and other technical methods to assist in determining the key investigation area. â¡In the process of field investigation, to obtain the planting area of Chinese herbal medicine was accurately, we use the decision tree model, spectral feature and object-oriented method were used to assist the regional identification and area estimation of Chinese medicinal materials.â¢In the process of finishing in the industry, in order to be able to relatively accurately determine the type of Chinese medicine resources in the region, based on the individual photos of the plant, the specimens and the name of the use of image recognition techniques, to assist the statistical summary of the types of traditional Chinese medicine resources. â£In the application of the results of transformation, based on the pharmaceutical resources and individual samples of medicinal herbs, the development of Chinese medicine resources to identify APP and authentic herbs 3D display system, assisted the identification of Chinese medicine resources and herbs identification characteristics. The introduction of image recognition technology in the census of Chinese medicine resources, assisting census personnel to carry out related work, not only can reduce the workload of the artificial, improve work efficiency, but also improve the census results\n\nA Fault Recognition System for Gearboxes of Wind Turbines\n\nNASA Astrophysics Data System (ADS)\n\nYang, Zhiling; Huang, Haiyue; Yin, Zidong\n\n2017-12-01\n\nCosts of maintenance and loss of power generation caused by the faults of wind turbines gearboxes are the main components of operation costs for a wind farm. Therefore, the technology of condition monitoring and fault recognition for wind turbines gearboxes is becoming a hot topic. A condition monitoring and fault recognition system (CMFRS) is presented for CBM of wind turbines gearboxes in this paper. The vibration signals from acceleration sensors at different locations of gearbox and the data from supervisory control and data acquisition (SCADA) system are collected to CMFRS. Then the feature extraction and optimization algorithm is applied to these operational data. Furthermore, to recognize the fault of gearboxes, the GSO-LSSVR algorithm is proposed, combining the least squares support vector regression machine (LSSVR) with the Glowworm Swarm Optimization (GSO) algorithm. Finally, the results show that the fault recognition system used in this paper has a high rate for identifying three states of wind turbinesâ gears; besides, the combination of date features can affect the identifying rate and the selection optimization algorithm presented in this paper can get a pretty good date feature subset for the fault recognition.\n\nLaptop Computer - Based Facial Recognition System Assessment\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nR. A. Cain; G. B. Singleton\n\n2001-03-01\n\nThe objective of this project was to assess the performance of the leading commercial-off-the-shelf (COTS) facial recognition software package when used as a laptop application. We performed the assessment to determine the system's usefulness for enrolling facial images in a database from remote locations and conducting real-time searches against a database of previously enrolled images. The assessment involved creating a database of 40 images and conducting 2 series of tests to determine the product's ability to recognize and match subject faces under varying conditions. This report describes the test results and includes a description of the factors affecting the results.moreÂ Â» After an extensive market survey, we selected Visionics' FaceIt{reg_sign} software package for evaluation and a review of the Facial Recognition Vendor Test 2000 (FRVT 2000). This test was co-sponsored by the US Department of Defense (DOD) Counterdrug Technology Development Program Office, the National Institute of Justice, and the Defense Advanced Research Projects Agency (DARPA). Administered in May-June 2000, the FRVT 2000 assessed the capabilities of facial recognition systems that were currently available for purchase on the US market. Our selection of this Visionics product does not indicate that it is the ''best'' facial recognition software package for all uses. It was the most appropriate package based on the specific applications and requirements for this specific application. In this assessment, the system configuration was evaluated for effectiveness in identifying individuals by searching for facial images captured from video displays against those stored in a facial image database. An additional criterion was that the system be capable of operating discretely. For this application, an operational facial recognition system would consist of one central computer hosting the master image database with multiple standalone systems configured with duplicates of the master\n\nEnhanced technologies for unattended ground sensor systems\n\nNASA Astrophysics Data System (ADS)\n\nHartup, David C.\n\n2010-04-01\n\nProgress in several technical areas is being leveraged to advantage in Unattended Ground Sensor (UGS) systems. This paper discusses advanced technologies that are appropriate for use in UGS systems. While some technologies provide evolutionary improvements, other technologies result in revolutionary performance advancements for UGS systems. Some specific technologies discussed include wireless cameras and viewers, commercial PDA-based system programmers and monitors, new materials and techniques for packaging improvements, low power cueing sensor radios, advanced long-haul terrestrial and SATCOM radios, and networked communications. Other technologies covered include advanced target detection algorithms, high pixel count cameras for license plate and facial recognition, small cameras that provide large stand-off distances, video transmissions of target activity instead of still images, sensor fusion algorithms, and control center hardware. The impact of each technology on the overall UGS system architecture is discussed, along with the advantages provided to UGS system users. Areas of analysis include required camera parameters as a function of stand-off distance for license plate and facial recognition applications, power consumption for wireless cameras and viewers, sensor fusion communication requirements, and requirements to practically implement video transmission through UGS systems. Examples of devices that have already been fielded using technology from several of these areas are given.\n\nFace Recognition Vendor Test 2000: Evaluation Report\n\nDTIC Science & Technology\n\n2001-02-16\n\nThe biggest change in the facial recognition community since the completion of the FERET program has been the introduction of facial recognition products...program and significantly lowered system costs. Today there are dozens of facial recognition systems available that have the potential to meet...inquiries from numerous government agencies on the current state of facial recognition technology prompted the DoD Counterdrug Technology Development Program\n\nRotation-invariant neural pattern recognition system with application to coin recognition.\n\nPubMed\n\nFukumi, M; Omatu, S; Takeda, F; Kosaka, T\n\n1992-01-01\n\nIn pattern recognition, it is often necessary to deal with problems to classify a transformed pattern. A neural pattern recognition system which is insensitive to rotation of input pattern by various degrees is proposed. The system consists of a fixed invariance network with many slabs and a trainable multilayered network. The system was used in a rotation-invariant coin recognition problem to distinguish between a 500 yen coin and a 500 won coin. The results show that the approach works well for variable rotation pattern recognition.\n\nGrowing Misconception of Technology: Investigation of Elementary Students' Recognition of and Reasoning about Technological Artifacts\n\nERIC Educational Resources Information Center\n\nFirat, Mehmet\n\n2017-01-01\n\nKnowledge of technology is an educational goal of science education. A primary way of increasing technology literacy in a society is to develop students' conception of technology starting from their elementary school years. However, there is a lack of research on student recognition of and reasoning about technology and technological artifacts. Inâ¦\n\nThe 3-D image recognition based on fuzzy neural network technology\n\nNASA Technical Reports Server (NTRS)\n\nHirota, Kaoru; Yamauchi, Kenichi; Murakami, Jun; Tanaka, Kei\n\n1993-01-01\n\nThree dimensional stereoscopic image recognition system based on fuzzy-neural network technology was developed. The system consists of three parts; preprocessing part, feature extraction part, and matching part. Two CCD color camera image are fed to the preprocessing part, where several operations including RGB-HSV transformation are done. A multi-layer perception is used for the line detection in the feature extraction part. Then fuzzy matching technique is introduced in the matching part. The system is realized on SUN spark station and special image input hardware system. An experimental result on bottle images is also presented.\n\nAdaptive remote sensing technology for feature recognition and tracking\n\nNASA Technical Reports Server (NTRS)\n\nWilson, R. G.; Sivertson, W. E., Jr.; Bullock, G. F.\n\n1979-01-01\n\nA technology development plan designed to reduce the data load and data-management problems associated with global study and monitoring missions is described with a heavy emphasis placed on developing mission capabilities to eliminate the collection of unnecessary data. Improved data selectivity can be achieved through sensor automation correlated with the real-time needs of data users. The first phase of the plan includes the Feature Identification and Location Experiment (FILE) which is scheduled for the 1980 Shuttle flight. The FILE experiment is described with attention given to technology needs, development plan, feature recognition and classification, and cloud-snow detection/discrimination. Pointing, tracking and navigation received particular consideration, and it is concluded that this technology plan is viewed as an alternative to approaches to real-time acquisition that are based on extensive onboard format and inventory processing and reliance upon global-satellite-system navigation data.\n\nExploring Techniques for Vision Based Human Activity Recognition: Methods, Systems, and Evaluation\n\nPubMed Central\n\nXu, Xin; Tang, Jinshan; Zhang, Xiaolong; Liu, Xiaoming; Zhang, Hong; Qiu, Yimin\n\n2013-01-01\n\nWith the wide applications of vision based intelligent systems, image and video analysis technologies have attracted the attention of researchers in the computer vision field. In image and video analysis, human activity recognition is an important research direction. By interpreting and understanding human activities, we can recognize and predict the occurrence of crimes and help the police or other agencies react immediately. In the past, a large number of papers have been published on human activity recognition in video and image sequences. In this paper, we provide a comprehensive survey of the recent development of the techniques, including methods, systems, and quantitative evaluation of the performance of human activity recognition. PMID:23353144\n\nGait recognition based on integral outline\n\nNASA Astrophysics Data System (ADS)\n\nMing, Guan; Fang, Lv\n\n2017-02-01\n\nBiometric identification technology replaces traditional security technology, which has become a trend, and gait recognition also has become a hot spot of research because its feature is difficult to imitate and theft. This paper presents a gait recognition system based on integral outline of human body. The system has three important aspects: the preprocessing of gait image, feature extraction and classification. Finally, using a method of polling to evaluate the performance of the system, and summarizing the problems existing in the gait recognition and the direction of development in the future.\n\nDesign and implementation of face recognition system based on Windows\n\nNASA Astrophysics Data System (ADS)\n\nZhang, Min; Liu, Ting; Li, Ailan\n\n2015-07-01\n\nIn view of the basic Windows login password input way lacking of safety and convenient operation, we will introduce the biometrics technology, face recognition, into the computer to login system. Not only can it encrypt the computer system, also according to the level to identify administrators at all levels. With the enhancement of the system security, user input can neither be a cumbersome nor worry about being stolen password confidential.\n\nPractical automatic Arabic license plate recognition system\n\nNASA Astrophysics Data System (ADS)\n\nMohammad, Khader; Agaian, Sos; Saleh, Hani\n\n2011-02-01\n\nSince 1970's, the need of an automatic license plate recognition system, sometimes referred as Automatic License Plate Recognition system, has been increasing. A license plate recognition system is an automatic system that is able to recognize a license plate number, extracted from image sensors. In specific, Automatic License Plate Recognition systems are being used in conjunction with various transportation systems in application areas such as law enforcement (e.g. speed limit enforcement) and commercial usages such as parking enforcement and automatic toll payment private and public entrances, border control, theft and vandalism control. Vehicle license plate recognition has been intensively studied in many countries. Due to the different types of license plates being used, the requirement of an automatic license plate recognition system is different for each country. [License plate detection using cluster run length smoothing algorithm ].Generally, an automatic license plate localization and recognition system is made up of three modules; license plate localization, character segmentation and optical character recognition modules. This paper presents an Arabic license plate recognition system that is insensitive to character size, font, shape and orientation with extremely high accuracy rate. The proposed system is based on a combination of enhancement, license plate localization, morphological processing, and feature vector extraction using the Haar transform. The performance of the system is fast due to classification of alphabet and numerals based on the license plate organization. Experimental results for license plates of two different Arab countries show an average of 99 % successful license plate localization and recognition in a total of more than 20 different images captured from a complex outdoor environment. The results run times takes less time compared to conventional and many states of art methods.\n\nAutomatic speech recognition technology development at ITT Defense Communications Division\n\nNASA Technical Reports Server (NTRS)\n\nWhite, George M.\n\n1977-01-01\n\nAn assessment of the applications of automatic speech recognition to defense communication systems is presented. Future research efforts include investigations into the following areas: (1) dynamic programming; (2) recognition of speech degraded by noise; (3) speaker independent recognition; (4) large vocabulary recognition; (5) word spotting and continuous speech recognition; and (6) isolated word recognition.\n\nCognitive object recognition system (CORS)\n\nNASA Astrophysics Data System (ADS)\n\nRaju, Chaitanya; Varadarajan, Karthik Mahesh; Krishnamurthi, Niyant; Xu, Shuli; Biederman, Irving; Kelley, Troy\n\n2010-04-01\n\nWe have developed a framework, Cognitive Object Recognition System (CORS), inspired by current neurocomputational models and psychophysical research in which multiple recognition algorithms (shape based geometric primitives, 'geons,' and non-geometric feature-based algorithms) are integrated to provide a comprehensive solution to object recognition and landmarking. Objects are defined as a combination of geons, corresponding to their simple parts, and the relations among the parts. However, those objects that are not easily decomposable into geons, such as bushes and trees, are recognized by CORS using \"feature-based\" algorithms. The unique interaction between these algorithms is a novel approach that combines the effectiveness of both algorithms and takes us closer to a generalized approach to object recognition. CORS allows recognition of objects through a larger range of poses using geometric primitives and performs well under heavy occlusion - about 35% of object surface is sufficient. Furthermore, geon composition of an object allows image understanding and reasoning even with novel objects. With reliable landmarking capability, the system improves vision-based robot navigation in GPS-denied environments. Feasibility of the CORS system was demonstrated with real stereo images captured from a Pioneer robot. The system can currently identify doors, door handles, staircases, trashcans and other relevant landmarks in the indoor environment.\n\nAn audiovisual emotion recognition system\n\nNASA Astrophysics Data System (ADS)\n\nHan, Yi; Wang, Guoyin; Yang, Yong; He, Kun\n\n2007-12-01\n\nHuman emotions could be expressed by many bio-symbols. Speech and facial expression are two of them. They are both regarded as emotional information which is playing an important role in human-computer interaction. Based on our previous studies on emotion recognition, an audiovisual emotion recognition system is developed and represented in this paper. The system is designed for real-time practice, and is guaranteed by some integrated modules. These modules include speech enhancement for eliminating noises, rapid face detection for locating face from background image, example based shape learning for facial feature alignment, and optical flow based tracking algorithm for facial feature tracking. It is known that irrelevant features and high dimensionality of the data can hurt the performance of classifier. Rough set-based feature selection is a good method for dimension reduction. So 13 speech features out of 37 ones and 10 facial features out of 33 ones are selected to represent emotional information, and 52 audiovisual features are selected due to the synchronization when speech and video fused together. The experiment results have demonstrated that this system performs well in real-time practice and has high recognition rate. Our results also show that the work in multimodules fused recognition will become the trend of emotion recognition in the future.\n\nWireless Technology Recognition Based on RSSI Distribution at Sub-Nyquist Sampling Rate for Constrained Devices\n\nPubMed Central\n\nLiu, Wei; Kulin, Merima; Kazaz, Tarik; De Poorter, Eli\n\n2017-01-01\n\nDriven by the fast growth of wireless communication, the trend of sharing spectrum among heterogeneous technologies becomes increasingly dominant. Identifying concurrent technologies is an important step towards efficient spectrum sharing. However, due to the complexity of recognition algorithms and the strict condition of sampling speed, communication systems capable of recognizing signals other than their own type are extremely rare. This work proves that multi-model distribution of the received signal strength indicator (RSSI) is related to the signalsâ modulation schemes and medium access mechanisms, and RSSI from different technologies may exhibit highly distinctive features. A distinction is made between technologies with a streaming or a non-streaming property, and appropriate feature spaces can be established either by deriving parameters such as packet duration from RSSI or directly using RSSIâs probability distribution. An experimental study shows that even RSSI acquired at a sub-Nyquist sampling rate is able to provide sufficient features to differentiate technologies such as Wi-Fi, Long Term Evolution (LTE), Digital Video Broadcasting-Terrestrial (DVB-T) and Bluetooth. The usage of the RSSI distribution-based feature space is illustrated via a sample algorithm. Experimental evaluation indicates that more than 92% accuracy is achieved with the appropriate configuration. As the analysis of RSSI distribution is straightforward and less demanding in terms of system requirements, we believe it is highly valuable for recognition of wideband technologies on constrained devices in the context of dynamic spectrum access. PMID:28895879\n\nWireless Technology Recognition Based on RSSI Distribution at Sub-Nyquist Sampling Rate for Constrained Devices.\n\nPubMed\n\nLiu, Wei; Kulin, Merima; Kazaz, Tarik; Shahid, Adnan; Moerman, Ingrid; De Poorter, Eli\n\n2017-09-12\n\nDriven by the fast growth of wireless communication, the trend of sharing spectrum among heterogeneous technologies becomes increasingly dominant. Identifying concurrent technologies is an important step towards efficient spectrum sharing. However, due to the complexity of recognition algorithms and the strict condition of sampling speed, communication systems capable of recognizing signals other than their own type are extremely rare. This work proves that multi-model distribution of the received signal strength indicator (RSSI) is related to the signals' modulation schemes and medium access mechanisms, and RSSI from different technologies may exhibit highly distinctive features. A distinction is made between technologies with a streaming or a non-streaming property, and appropriate feature spaces can be established either by deriving parameters such as packet duration from RSSI or directly using RSSI's probability distribution. An experimental study shows that even RSSI acquired at a sub-Nyquist sampling rate is able to provide sufficient features to differentiate technologies such as Wi-Fi, Long Term Evolution (LTE), Digital Video Broadcasting-Terrestrial (DVB-T) and Bluetooth. The usage of the RSSI distribution-based feature space is illustrated via a sample algorithm. Experimental evaluation indicates that more than 92% accuracy is achieved with the appropriate configuration. As the analysis of RSSI distribution is straightforward and less demanding in terms of system requirements, we believe it is highly valuable for recognition of wideband technologies on constrained devices in the context of dynamic spectrum access.\n\nImage quality assessment for video stream recognition systems\n\nNASA Astrophysics Data System (ADS)\n\nChernov, Timofey S.; Razumnuy, Nikita P.; Kozharinov, Alexander S.; Nikolaev, Dmitry P.; Arlazarov, Vladimir V.\n\n2018-04-01\n\nRecognition and machine vision systems have long been widely used in many disciplines to automate various processes of life and industry. Input images of optical recognition systems can be subjected to a large number of different distortions, especially in uncontrolled or natural shooting conditions, which leads to unpredictable results of recognition systems, making it impossible to assess their reliability. For this reason, it is necessary to perform quality control of the input data of recognition systems, which is facilitated by modern progress in the field of image quality evaluation. In this paper, we investigate the approach to designing optical recognition systems with built-in input image quality estimation modules and feedback, for which the necessary definitions are introduced and a model for describing such systems is constructed. The efficiency of this approach is illustrated by the example of solving the problem of selecting the best frames for recognition in a video stream for a system with limited resources. Experimental results are presented for the system for identity documents recognition, showing a significant increase in the accuracy and speed of the system under simulated conditions of automatic camera focusing, leading to blurring of frames.\n\nRandom-Profiles-Based 3D Face Recognition System\n\nPubMed Central\n\nJoongrock, Kim; Sunjin, Yu; Sangyoun, Lee\n\n2014-01-01\n\nIn this paper, a noble nonintrusive three-dimensional (3D) face modeling system for random-profile-based 3D face recognition is presented. Although recent two-dimensional (2D) face recognition systems can achieve a reliable recognition rate under certain conditions, their performance is limited by internal and external changes, such as illumination and pose variation. To address these issues, 3D face recognition, which uses 3D face data, has recently received much attention. However, the performance of 3D face recognition highly depends on the precision of acquired 3D face data, while also requiring more computational power and storage capacity than 2D face recognition systems. In this paper, we present a developed nonintrusive 3D face modeling system composed of a stereo vision system and an invisible near-infrared line laser, which can be directly applied to profile-based 3D face recognition. We further propose a novel random-profile-based 3D face recognition method that is memory-efficient and pose-invariant. The experimental results demonstrate that the reconstructed 3D face data consists of more than 50 k 3D point clouds and a reliable recognition rate against pose variation. PMID:24691101\n\nNew Ideas for Speech Recognition and Related Technologies\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nHolzrichter, J F\n\nThe ideas relating to the use of organ motion sensors for the purposes of speech recognition were first described by.the author in spring 1994. During the past year, a series of productive collaborations between the author, Tom McEwan and Larry Ng ensued and have lead to demonstrations, new sensor ideas, and algorithmic descriptions of a large number of speech recognition concepts. This document summarizes the basic concepts of recognizing speech once organ motions have been obtained. Micro power radars and their uses for the measurement of body organ motions, such as those of the heart and lungs, have been demonstratedmoreÂ Â» by Tom McEwan over the past two years. McEwan and I conducted a series of experiments, using these instruments, on vocal organ motions beginning in late spring, during which we observed motions of vocal folds (i.e., cords), tongue, jaw, and related organs that are very useful for speech recognition and other purposes. These will be reviewed in a separate paper. Since late summer 1994, Lawrence Ng and I have worked to make many of the initial recognition ideas more rigorous and to investigate the applications of these new ideas to new speech recognition algorithms, to speech coding, and to speech synthesis. I introduce some of those ideas in section IV of this document, and we describe them more completely in the document following this one, UCRL-UR-120311. For the design and operation of micro-power radars and their application to body organ motions, the reader may contact Tom McEwan directly. The capability for using EM sensors (i.e., radar units) to measure body organ motions and positions has been available for decades. Impediments to their use appear to have been size, excessive power, lack of resolution, and lack of understanding of the value of organ motion measurements, especially as applied to speech related technologies. However, with the invention of very low power, portable systems as demonstrated by McEwan at LLNL researchers\n\nBio-recognition and functional lipidomics by glycosphingolipid transfer technology\n\nPubMed Central\n\nTAKI, Takao\n\n2013-01-01\n\nThrough glycosphingolipid biochemical research, we developed two types of transcription technologies. One is a biochemical transfer of glycosphingolipids to peptides. The other is a physicochemical transfer of glycosphingolipids in silica gel to the surface of a plastic membrane. Using the first technology, we could prepare peptides which mimic the shapes of glycosphingolipid molecules by biopanning with a phage-displayed peptide library and anti-glycosphingolipid antibodies as templates. The peptides thus obtained showed biological properties and functions similar to those of the original glycosphingolipids, such as lectin binding, glycosidase modulation, inhibition of tumor metastasis and immune response against the original antigen glycosphingolipid, and we named them glyco-replica peptides. The results showed that the newly prepared peptides could be used effectively as a bio-recognition system and suggest that the glyco-replica peptides can be widely applied to therapeutic fields. Using the second technology, we could establish a functional lipidomics with a thin-layer chromatography-blot/matrix-assisted laser desorption ionization-time of flight mass spectrometry (TLC-Blot/MALDI-TOF MS) system. By transferring glycosphingolipids on a plastic membrane surface from a TLC plate, innovative biochemical approaches such as simple purification of individual glycosphingolipids, binding studies, and enzyme reactions could be developed. The combinations of these biochemical approaches and MALDI-TOF MS on the plastic membrane could provide new strategies for glycosphingolipid science and the field of lipidomics. In this review, typical applications of these two transfer technologies are introduced. PMID:23883610\n\nReview of Speech-to-Text Recognition Technology for Enhancing Learning\n\nERIC Educational Resources Information Center\n\nShadiev, Rustam; Hwang, Wu-Yuin; Chen, Nian-Shing; Huang, Yueh-Min\n\n2014-01-01\n\nThis paper reviewed literature from 1999 to 2014 inclusively on how Speech-to-Text Recognition (STR) technology has been applied to enhance learning. The first aim of this review is to understand how STR technology has been used to support learning over the past fifteen years, and the second is to analyze all research evidence to understand howâ¦\n\nDesign method of ARM based embedded iris recognition system\n\nNASA Astrophysics Data System (ADS)\n\nWang, Yuanbo; He, Yuqing; Hou, Yushi; Liu, Ting\n\n2008-03-01\n\nWith the advantages of non-invasiveness, uniqueness, stability and low false recognition rate, iris recognition has been successfully applied in many fields. Up to now, most of the iris recognition systems are based on PC. However, a PC is not portable and it needs more power. In this paper, we proposed an embedded iris recognition system based on ARM. Considering the requirements of iris image acquisition and recognition algorithm, we analyzed the design method of the iris image acquisition module, designed the ARM processing module and its peripherals, studied the Linux platform and the recognition algorithm based on this platform, finally actualized the design method of ARM-based iris imaging and recognition system. Experimental results show that the ARM platform we used is fast enough to run the iris recognition algorithm, and the data stream can flow smoothly between the camera and the ARM chip based on the embedded Linux system. It's an effective method of using ARM to actualize portable embedded iris recognition system.\n\nA framework for the recognition of 3D faces and expressions\n\nNASA Astrophysics Data System (ADS)\n\nLi, Chao; Barreto, Armando\n\n2006-04-01\n\nFace recognition technology has been a focus both in academia and industry for the last couple of years because of its wide potential applications and its importance to meet the security needs of today's world. Most of the systems developed are based on 2D face recognition technology, which uses pictures for data processing. With the development of 3D imaging technology, 3D face recognition emerges as an alternative to overcome the difficulties inherent with 2D face recognition, i.e. sensitivity to illumination conditions and orientation positioning of the subject. But 3D face recognition still needs to tackle the problem of deformation of facial geometry that results from the expression changes of a subject. To deal with this issue, a 3D face recognition framework is proposed in this paper. It is composed of three subsystems: an expression recognition system, a system for the identification of faces with expression, and neutral face recognition system. A system for the recognition of faces with one type of expression (happiness) and neutral faces was implemented and tested on a database of 30 subjects. The results proved the feasibility of this framework.\n\nEvaluation of Speech Recognition of Cochlear Implant Recipients Using Adaptive, Digital Remote Microphone Technology and a Speech Enhancement Sound Processing Algorithm.\n\nPubMed\n\nWolfe, Jace; Morais, Mila; Schafer, Erin; Agrawal, Smita; Koch, Dawn\n\n2015-05-01\n\nCochlear implant recipients often experience difficulty with understanding speech in the presence of noise. Cochlear implant manufacturers have developed sound processing algorithms designed to improve speech recognition in noise, and research has shown these technologies to be effective. Remote microphone technology utilizing adaptive, digital wireless radio transmission has also been shown to provide significant improvement in speech recognition in noise. There are no studies examining the potential improvement in speech recognition in noise when these two technologies are used simultaneously. The goal of this study was to evaluate the potential benefits and limitations associated with the simultaneous use of a sound processing algorithm designed to improve performance in noise (Advanced Bionics ClearVoice) and a remote microphone system that incorporates adaptive, digital wireless radio transmission (Phonak Roger). A two-by-two way repeated measures design was used to examine performance differences obtained without these technologies compared to the use of each technology separately as well as the simultaneous use of both technologies. Eleven Advanced Bionics (AB) cochlear implant recipients, ages 11 to 68 yr. AzBio sentence recognition was measured in quiet and in the presence of classroom noise ranging in level from 50 to 80 dBA in 5-dB steps. Performance was evaluated in four conditions: (1) No ClearVoice and no Roger, (2) ClearVoice enabled without the use of Roger, (3) ClearVoice disabled with Roger enabled, and (4) simultaneous use of ClearVoice and Roger. Speech recognition in quiet was better than speech recognition in noise for all conditions. Use of ClearVoice and Roger each provided significant improvement in speech recognition in noise. The best performance in noise was obtained with the simultaneous use of ClearVoice and Roger. ClearVoice and Roger technology each improves speech recognition in noise, particularly when used at the same time\n\nIntelligent Automatic Right-Left Sign Lamp Based on Brain Signal Recognition System\n\nNASA Astrophysics Data System (ADS)\n\nWinda, A.; Sofyan; Sthevany; Vincent, R. S.\n\n2017-12-01\n\nComfort as a part of the human factor, plays important roles in nowadays advanced automotive technology. Many of the current technologies go in the direction of automotive driver assistance features. However, many of the driver assistance features still require physical movement by human to enable the features. In this work, the proposed method is used in order to make certain feature to be functioning without any physical movement, instead human just need to think about it in their mind. In this work, brain signal is recorded and processed in order to be used as input to the recognition system. Right-Left sign lamp based on the brain signal recognition system can potentially replace the button or switch of the specific device in order to make the lamp work. The system then will decide whether the signal is âRightâ or âLeftâ. The decision of the Right-Left side of brain signal recognition will be sent to a processing board in order to activate the automotive relay, which will be used to activate the sign lamp. Furthermore, the intelligent system approach is used to develop authorized model based on the brain signal. Particularly Support Vector Machines (SVMs)-based classification system is used in the proposed system to recognize the Left-Right of the brain signal. Experimental results confirm the effectiveness of the proposed intelligent Automatic brain signal-based Right-Left sign lamp access control system. The signal is processed by Linear Prediction Coefficient (LPC) and Support Vector Machines (SVMs), and the resulting experiment shows the training and testing accuracy of 100% and 80%, respectively.\n\nKeys to the Adoption and Use of Voice Recognition Technology in Organizations.\n\nERIC Educational Resources Information Center\n\nGoette, Tanya\n\n2000-01-01\n\nPresents results from a field study of individuals with disabilities who used voice recognition technology (VRT). Results indicated that task-technology fit, training, the environment, and disability limitations were the differentiating items, and that using VRT for a trial period may be the major factor in successful adoption of the technology.â¦\n\nPilot study on the feasibility of a computerized speech recognition charting system.\n\nPubMed\n\nFeldman, C A; Stevens, D\n\n1990-08-01\n\nThe objective of this study was to determine the feasibility of developing and using a voice recognition computerized charting system to record dental clinical examination data. More specifically, the study was designed to analyze the time and error differential between the traditional examiner/recorder method (ASSISTANT) and computerized voice recognition method (VOICE). DMFS examinations were performed twice on 20 patients using the traditional ASSISTANT and the VOICE charting system. A statistically significant difference was found when comparing the mean ASSISTANT time of 2.69 min to the VOICE time of 3.72 min (P less than 0.001). No statistically significant difference was found when comparing the mean ASSISTANT recording errors of 0.1 to VOICE recording errors of 0.6 (P = 0.059). 90% of the patients indicated they felt comfortable with the dentist talking to a computer and only 5% of the sample indicated they opposed VOICE. Results from this pilot study indicate that a charting system utilizing voice recognition technology could be considered a viable alternative to traditional examiner/recorder methods of clinical charting.\n\nNonintrusive Finger-Vein Recognition System Using NIR Image Sensor and Accuracy Analyses According to Various Factors\n\nPubMed Central\n\nPham, Tuyen Danh; Park, Young Ho; Nguyen, Dat Tien; Kwon, Seung Yong; Park, Kang Ryoung\n\n2015-01-01\n\nBiometrics is a technology that enables an individual person to be identified based on human physiological and behavioral characteristics. Among biometrics technologies, face recognition has been widely used because of its advantages in terms of convenience and non-contact operation. However, its performance is affected by factors such as variation in the illumination, facial expression, and head pose. Therefore, fingerprint and iris recognitions are preferred alternatives. However, the performance of the former can be adversely affected by the skin condition, including scarring and dryness. In addition, the latter has the disadvantages of high cost, large system size, and inconvenience to the user, who has to align their eyes with the iris camera. In an attempt to overcome these problems, finger-vein recognition has been vigorously researched, but an analysis of its accuracies according to various factors has not received much attention. Therefore, we propose a nonintrusive finger-vein recognition system using a near infrared (NIR) image sensor and analyze its accuracies considering various factors. The experimental results obtained with three databases showed that our system can be operated in real applications with high accuracy; and the dissimilarity of the finger-veins of different people is larger than that of the finger types and hands. PMID:26184214\n\nNonintrusive Finger-Vein Recognition System Using NIR Image Sensor and Accuracy Analyses According to Various Factors.\n\nPubMed\n\nPham, Tuyen Danh; Park, Young Ho; Nguyen, Dat Tien; Kwon, Seung Yong; Park, Kang Ryoung\n\n2015-07-13\n\nBiometrics is a technology that enables an individual person to be identified based on human physiological and behavioral characteristics. Among biometrics technologies, face recognition has been widely used because of its advantages in terms of convenience and non-contact operation. However, its performance is affected by factors such as variation in the illumination, facial expression, and head pose. Therefore, fingerprint and iris recognitions are preferred alternatives. However, the performance of the former can be adversely affected by the skin condition, including scarring and dryness. In addition, the latter has the disadvantages of high cost, large system size, and inconvenience to the user, who has to align their eyes with the iris camera. In an attempt to overcome these problems, finger-vein recognition has been vigorously researched, but an analysis of its accuracies according to various factors has not received much attention. Therefore, we propose a nonintrusive finger-vein recognition system using a near infrared (NIR) image sensor and analyze its accuracies considering various factors. The experimental results obtained with three databases showed that our system can be operated in real applications with high accuracy; and the dissimilarity of the finger-veins of different people is larger than that of the finger types and hands.\n\nAutomatic Speech Acquisition and Recognition for Spacesuit Audio Systems\n\nNASA Technical Reports Server (NTRS)\n\nYe, Sherry\n\n2015-01-01\n\nNASA has a widely recognized but unmet need for novel human-machine interface technologies that can facilitate communication during astronaut extravehicular activities (EVAs), when loud noises and strong reverberations inside spacesuits make communication challenging. WeVoice, Inc., has developed a multichannel signal-processing method for speech acquisition in noisy and reverberant environments that enables automatic speech recognition (ASR) technology inside spacesuits. The technology reduces noise by exploiting differences between the statistical nature of signals (i.e., speech) and noise that exists in the spatial and temporal domains. As a result, ASR accuracy can be improved to the level at which crewmembers will find the speech interface useful. System components and features include beam forming/multichannel noise reduction, single-channel noise reduction, speech feature extraction, feature transformation and normalization, feature compression, and ASR decoding. Arithmetic complexity models were developed and will help designers of real-time ASR systems select proper tasks when confronted with constraints in computational resources. In Phase I of the project, WeVoice validated the technology. The company further refined the technology in Phase II and developed a prototype for testing and use by suited astronauts.\n\nKannada character recognition system using neural network\n\nNASA Astrophysics Data System (ADS)\n\nKumar, Suresh D. S.; Kamalapuram, Srinivasa K.; Kumar, Ajay B. R.\n\n2013-03-01\n\nHandwriting recognition has been one of the active and challenging research areas in the field of pattern recognition. It has numerous applications which include, reading aid for blind, bank cheques and conversion of any hand written document into structural text form. As there is no sufficient number of works on Indian language character recognition especially Kannada script among 15 major scripts in India. In this paper an attempt is made to recognize handwritten Kannada characters using Feed Forward neural networks. A handwritten Kannada character is resized into 20x30 Pixel. The resized character is used for training the neural network. Once the training process is completed the same character is given as input to the neural network with different set of neurons in hidden layer and their recognition accuracy rate for different Kannada characters has been calculated and compared. The results show that the proposed system yields good recognition accuracy rates comparable to that of other handwritten character recognition systems.\n\nFingerprint recognition system by use of graph matching\n\nNASA Astrophysics Data System (ADS)\n\nShen, Wei; Shen, Jun; Zheng, Huicheng\n\n2001-09-01\n\nFingerprint recognition is an important subject in biometrics to identify or verify persons by physiological characteristics, and has found wide applications in different domains. In the present paper, we present a finger recognition system that combines singular points and structures. The principal steps of processing in our system are: preprocessing and ridge segmentation, singular point extraction and selection, graph representation, and finger recognition by graphs matching. Our fingerprint recognition system is implemented and tested for many fingerprint images and the experimental result are satisfactory. Different techniques are used in our system, such as fast calculation of orientation field, local fuzzy dynamical thresholding, algebraic analysis of connections and fingerprints representation and matching by graphs. Wed find that for fingerprint database that is not very large, the recognition rate is very high even without using a prior coarse category classification. This system works well for both one-to-few and one-to-many problems.\n\nDevelopment of Personalized Urination Recognition Technology Using Smart Bands.\n\nPubMed\n\nEun, Sung-Jong; Whangbo, Taeg-Keun; Park, Dong Kyun; Kim, Khae-Hawn\n\n2017-04-01\n\nThis study collected and analyzed activity data sensed through smart bands worn by patients in order to resolve the clinical issues posed by using voiding charts. By developing a smart band-based algorithm for recognizing urination activity in patients, this study aimed to explore the feasibility of urination monitoring systems. This study aimed to develop an algorithm that recognizes urination based on a patient's posture and changes in posture. Motion data was obtained from a smart band on the arm. An algorithm that recognizes the 3 stages of urination (forward movement, urination, backward movement) was developed based on data collected from a 3-axis accelerometer and from tilt angle data. Real-time data were acquired from the smart band, and for data corresponding to a certain duration, the absolute value of the signals was calculated and then compared with the set threshold value to determine the occurrence of vibration signals. In feature extraction, the most essential information describing each pattern was identified after analyzing the characteristics of the data. The results of the feature extraction process were sorted using a classifier to detect urination. An experiment was carried out to assess the performance of the recognition technology proposed in this study. The final accuracy of the algorithm was calculated based on clinical guidelines for urologists. The experiment showed a high average accuracy of 90.4%, proving the robustness of the proposed algorithm. The proposed urination recognition technology draws on acceleration data and tilt angle data collected via a smart band; these data were then analyzed using a classifier after comparative analyses with standardized feature patterns.\n\nPublic domain optical character recognition\n\nNASA Astrophysics Data System (ADS)\n\nGarris, Michael D.; Blue, James L.; Candela, Gerald T.; Dimmick, Darrin L.; Geist, Jon C.; Grother, Patrick J.; Janet, Stanley A.; Wilson, Charles L.\n\n1995-03-01\n\nA public domain document processing system has been developed by the National Institute of Standards and Technology (NIST). The system is a standard reference form-based handprint recognition system for evaluating optical character recognition (OCR), and it is intended to provide a baseline of performance on an open application. The system's source code, training data, performance assessment tools, and type of forms processed are all publicly available. The system recognizes the handprint entered on handwriting sample forms like the ones distributed with NIST Special Database 1. From these forms, the system reads hand-printed numeric fields, upper and lowercase alphabetic fields, and unconstrained text paragraphs comprised of words from a limited-size dictionary. The modular design of the system makes it useful for component evaluation and comparison, training and testing set validation, and multiple system voting schemes. The system contains a number of significant contributions to OCR technology, including an optimized probabilistic neural network (PNN) classifier that operates a factor of 20 times faster than traditional software implementations of the algorithm. The source code for the recognition system is written in C and is organized into 11 libraries. In all, there are approximately 19,000 lines of code supporting more than 550 subroutines. Source code is provided for form registration, form removal, field isolation, field segmentation, character normalization, feature extraction, character classification, and dictionary-based postprocessing. The recognition system has been successfully compiled and tested on a host of UNIX workstations. This paper gives an overview of the recognition system's software architecture, including descriptions of the various system components along with timing and accuracy statistics.\n\n[Study on molecular recognition technology in active constituents extracted and isolated from Aconitum pendulum].\n\nPubMed\n\nMa, Xue-Qin; Li, Guo-Shan; Fu, Xue-Yan; Ma, Jing-Zu\n\n2011-03-01\n\nTo investigate CD molecular recognition technology applied in active constituents extracted and isolated from traditional Chinese medicine--Aconitum pendulum. The inclusion constant and form probability of the inclusion complex of Aconitum pendulum with p-CD was calculated by UV spectra method. The active constituents of Aconitum pendulum were extracted and isolated by molecular recognition technology. The inclusion complex was identified by UV. The chemical constituents of Aconitum pendulum and inclusion complex was determined by HPLC. The analgesic effects of inclusion complex was investigated by experiment of intraperitoneal injection of acetic acid in rats. The inclusion complex was identified and confirmed by UV spectra method, the chemical components of inclusion complex were simple, and the content of active constituents increased significantly, the analgesic effects of inclusion complex was well. The molecular recognition technology can be used for extracting and isolating active constituents of Aconitum pendulum, and the effects are obvious.\n\nUsing speech recognition to enhance the Tongue Drive System functionality in computer access.\n\nPubMed\n\nHuo, Xueliang; Ghovanloo, Maysam\n\n2011-01-01\n\nTongue Drive System (TDS) is a wireless tongue operated assistive technology (AT), which can enable people with severe physical disabilities to access computers and drive powered wheelchairs using their volitional tongue movements. TDS offers six discrete commands, simultaneously available to the users, for pointing and typing as a substitute for mouse and keyboard in computer access, respectively. To enhance the TDS performance in typing, we have added a microphone, an audio codec, and a wireless audio link to its readily available 3-axial magnetic sensor array, and combined it with a commercially available speech recognition software, the Dragon Naturally Speaking, which is regarded as one of the most efficient ways for text entry. Our preliminary evaluations indicate that the combined TDS and speech recognition technologies can provide end users with significantly higher performance than using each technology alone, particularly in completing tasks that require both pointing and text entry, such as web surfing.\n\nUsing Speech Recognition to Enhance the Tongue Drive System Functionality in Computer Access\n\nPubMed Central\n\nHuo, Xueliang; Ghovanloo, Maysam\n\n2013-01-01\n\nTongue Drive System (TDS) is a wireless tongue operated assistive technology (AT), which can enable people with severe physical disabilities to access computers and drive powered wheelchairs using their volitional tongue movements. TDS offers six discrete commands, simultaneously available to the users, for pointing and typing as a substitute for mouse and keyboard in computer access, respectively. To enhance the TDS performance in typing, we have added a microphone, an audio codec, and a wireless audio link to its readily available 3-axial magnetic sensor array, and combined it with a commercially available speech recognition software, the Dragon Naturally Speaking, which is regarded as one of the most efficient ways for text entry. Our preliminary evaluations indicate that the combined TDS and speech recognition technologies can provide end users with significantly higher performance than using each technology alone, particularly in completing tasks that require both pointing and text entry, such as web surfing. PMID:22255801\n\n[Development of image quality assurance support system using image recognition technology in radiography in lacked images of chest and abdomen].\n\nPubMed\n\nShibuya, Toru; Kato, Kyouichi; Eshima, Hidekazu; Sumi, Shinichirou; Kubo, Tadashi; Ishida, Hideki; Nakazawa, Yasuo\n\n2012-01-01\n\nIn order to provide a precise radiography for diagnosis, it is required that we avoid radiography with defects by having enough evaluation. Conventionally, evaluation was performed only by observation of a radiological technologist (RT). The evaluation support system was developed for providing a high quality assurance without depending on RT observation only. The evaluation support system, called as the Image Quality Assurance Support System (IQASS), is characterized in that \"image recognition technology\" for the purpose of diagnostic radiography of chest and abdomen areas. The technique of the system used in this study. Of the 259 samples of posterior-anterior (AP) chest, lateral chest, and upright abdominal x-rays, the sensitivity and specificity was 93.1% and 91.8% in the chest AP, 93.3% and 93.6% in the chest lateral, and 95.0% and 93.8% in the upright abdominal x-rays. In the light of these results, it is suggested that AIQAS could be applied to practical usage for the RT.\n\nCost-sensitive learning for emotion robust speaker recognition.\n\nPubMed\n\nLi, Dongdong; Yang, Yingchun; Dai, Weihui\n\n2014-01-01\n\nIn the field of information security, voice is one of the most important parts in biometrics. Especially, with the development of voice communication through the Internet or telephone system, huge voice data resources are accessed. In speaker recognition, voiceprint can be applied as the unique password for the user to prove his/her identity. However, speech with various emotions can cause an unacceptably high error rate and aggravate the performance of speaker recognition system. This paper deals with this problem by introducing a cost-sensitive learning technology to reweight the probability of test affective utterances in the pitch envelop level, which can enhance the robustness in emotion-dependent speaker recognition effectively. Based on that technology, a new architecture of recognition system as well as its components is proposed in this paper. The experiment conducted on the Mandarin Affective Speech Corpus shows that an improvement of 8% identification rate over the traditional speaker recognition is achieved.\n\nCost-Sensitive Learning for Emotion Robust Speaker Recognition\n\nPubMed Central\n\nLi, Dongdong; Yang, Yingchun\n\n2014-01-01\n\nIn the field of information security, voice is one of the most important parts in biometrics. Especially, with the development of voice communication through the Internet or telephone system, huge voice data resources are accessed. In speaker recognition, voiceprint can be applied as the unique password for the user to prove his/her identity. However, speech with various emotions can cause an unacceptably high error rate and aggravate the performance of speaker recognition system. This paper deals with this problem by introducing a cost-sensitive learning technology to reweight the probability of test affective utterances in the pitch envelop level, which can enhance the robustness in emotion-dependent speaker recognition effectively. Based on that technology, a new architecture of recognition system as well as its components is proposed in this paper. The experiment conducted on the Mandarin Affective Speech Corpus shows that an improvement of 8% identification rate over the traditional speaker recognition is achieved. PMID:24999492\n\nSpeech Recognition Technology for Disabilities Education\n\nERIC Educational Resources Information Center\n\nTang, K. Wendy; Kamoua, Ridha; Sutan, Victor; Farooq, Omer; Eng, Gilbert; Chu, Wei Chern; Hou, Guofeng\n\n2005-01-01\n\nSpeech recognition is an alternative to traditional methods of interacting with a computer, such as textual input through a keyboard. An effective system can replace or reduce the reliability on standard keyboard and mouse input. This can especially assist dyslexic students who have problems with character or word use and manipulation in a textualâ¦\n\nFaceIt: face recognition from static and live video for law enforcement\n\nNASA Astrophysics Data System (ADS)\n\nAtick, Joseph J.; Griffin, Paul M.; Redlich, A. N.\n\n1997-01-01\n\nRecent advances in image and pattern recognition technology- -especially face recognition--are leading to the development of a new generation of information systems of great value to the law enforcement community. With these systems it is now possible to pool and manage vast amounts of biometric intelligence such as face and finger print records and conduct computerized searches on them. We review one of the enabling technologies underlying these systems: the FaceIt face recognition engine; and discuss three applications that illustrate its benefits as a problem-solving technology and an efficient and cost effective investigative tool.\n\nDevelopment of a sonar-based object recognition system\n\nNASA Astrophysics Data System (ADS)\n\nEcemis, Mustafa Ihsan\n\n2001-02-01\n\nSonars are used extensively in mobile robotics for obstacle detection, ranging and avoidance. However, these range-finding applications do not exploit the full range of information carried in sonar echoes. In addition, mobile robots need robust object recognition systems. Therefore, a simple and robust object recognition system using ultrasonic sensors may have a wide range of applications in robotics. This dissertation develops and analyzes an object recognition system that uses ultrasonic sensors of the type commonly found on mobile robots. Three principal experiments are used to test the sonar recognition system: object recognition at various distances, object recognition during unconstrained motion, and softness discrimination. The hardware setup, consisting of an inexpensive Polaroid sonar and a data acquisition board, is described first. The software for ultrasound signal generation, echo detection, data collection, and data processing is then presented. Next, the dissertation describes two methods to extract information from the echoes, one in the frequency domain and the other in the time domain. The system uses the fuzzy ARTMAP neural network to recognize objects on the basis of the information content of their echoes. In order to demonstrate that the performance of the system does not depend on the specific classification method being used, the K- Nearest Neighbors (KNN) Algorithm is also implemented. KNN yields a test accuracy similar to fuzzy ARTMAP in all experiments. Finally, the dissertation describes a method for extracting features from the envelope function in order to reduce the dimension of the input vector used by the classifiers. Decreasing the size of the input vectors reduces the memory requirements of the system and makes it run faster. It is shown that this method does not affect the performance of the system dramatically and is more appropriate for some tasks. The results of these experiments demonstrate that sonar can be used to develop\n\nIntelligent systems technology infrastructure for integrated systems\n\nNASA Technical Reports Server (NTRS)\n\nLum, Henry\n\n1991-01-01\n\nA system infrastructure must be properly designed and integrated from the conceptual development phase to accommodate evolutionary intelligent technologies. Several technology development activities were identified that may have application to rendezvous and capture systems. Optical correlators in conjunction with fuzzy logic control might be used for the identification, tracking, and capture of either cooperative or non-cooperative targets without the intensive computational requirements associated with vision processing. A hybrid digital/analog system was developed and tested with a robotic arm. An aircraft refueling application demonstration is planned within two years. Initially this demonstration will be ground based with a follow-on air based demonstration. System dependability measurement and modeling techniques are being developed for fault management applications. This involves usage of incremental solution/evaluation techniques and modularized systems to facilitate reuse and to take advantage of natural partitions in system models. Though not yet commercially available and currently subject to accuracy limitations, technology is being developed to perform optical matrix operations to enhance computational speed. Optical terrain recognition using camera image sequencing processed with optical correlators is being developed to determine position and velocity in support of lander guidance. The system is planned for testing in conjunction with Dryden Flight Research Facility. Advanced architecture technology is defining open architecture design constraints, test bed concepts (processors, multiple hardware/software and multi-dimensional user support, knowledge/tool sharing infrastructure), and software engineering interface issues.\n\n[Creating language model of the forensic medicine domain for developing a autopsy recording system by automatic speech recognition].\n\nPubMed\n\nNiijima, H; Ito, N; Ogino, S; Takatori, T; Iwase, H; Kobayashi, M\n\n2000-11-01\n\nFor the purpose of practical use of speech recognition technology for recording of forensic autopsy, a language model of the speech recording system, specialized for the forensic autopsy, was developed. The language model for the forensic autopsy by applying 3-gram model was created, and an acoustic model for Japanese speech recognition by Hidden Markov Model in addition to the above were utilized to customize the speech recognition engine for forensic autopsy. A forensic vocabulary set of over 10,000 words was compiled and some 300,000 sentence patterns were made to create the forensic language model, then properly mixing with a general language model to attain high exactitude. When tried by dictating autopsy findings, this speech recognition system was proved to be about 95% of recognition rate that seems to have reached to the practical usability in view of speech recognition software, though there remains rooms for improving its hardware and application-layer software.\n\nReal-time optical multiple object recognition and tracking system and method\n\nNASA Technical Reports Server (NTRS)\n\nChao, Tien-Hsin (Inventor); Liu, Hua Kuang (Inventor)\n\n1987-01-01\n\nThe invention relates to an apparatus and associated methods for the optical recognition and tracking of multiple objects in real time. Multiple point spatial filters are employed that pre-define the objects to be recognized at run-time. The system takes the basic technology of a Vander Lugt filter and adds a hololens. The technique replaces time, space and cost-intensive digital techniques. In place of multiple objects, the system can also recognize multiple orientations of a single object. This later capability has potential for space applications where space and weight are at a premium.\n\nA real time mobile-based face recognition with fisherface methods\n\nNASA Astrophysics Data System (ADS)\n\nArisandi, D.; Syahputra, M. F.; Putri, I. L.; Purnamawati, S.; Rahmat, R. F.; Sari, P. P.\n\n2018-03-01\n\nFace Recognition is a field research in Computer Vision that study about learning face and determine the identity of the face from a picture sent to the system. By utilizing this face recognition technology, learning process about peopleâs identity between students in a university will become simpler. With this technology, student wonât need to browse student directory in universityâs server site and look for the person with certain face trait. To obtain this goal, face recognition application use image processing methods consist of two phase, pre-processing phase and recognition phase. In pre-processing phase, system will process input image into the best image for recognition phase. Purpose of this pre-processing phase is to reduce noise and increase signal in image. Next, to recognize face phase, we use Fisherface Methods. This methods is chosen because of its advantage that would help system of its limited data. Therefore from experiment the accuracy of face recognition using fisherface is 90%.\n\nIris recognition in the presence of ocular disease\n\nPubMed Central\n\nAslam, Tariq Mehmood; Tan, Shi Zhuan; Dhillon, Baljean\n\n2009-01-01\n\nIris recognition systems are among the most accurate of all biometric technologies with immense potential for use in worldwide security applications. This study examined the effect of eye pathology on iris recognition and in particular whether eye disease could cause iris recognition systems to fail. The experiment involved a prospective cohort of 54 patients with anterior segment eye disease who were seen at the acute referral unit of the Princess Alexandra Eye Pavilion in Edinburgh. Iris camera images were obtained from patients before treatment was commenced and again at follow-up appointments after treatment had been given. The principal outcome measure was that of mathematical difference in the iris recognition templates obtained from patients' eyes before and after treatment of the eye disease. Results showed that the performance of iris recognition was remarkably resilient to most ophthalmic disease states, including corneal oedema, iridotomies (laser puncture of iris) and conjunctivitis. Problems were, however, encountered in some patients with acute inflammation of the iris (iritis/anterior uveitis). The effects of a subject developing anterior uveitis may cause current recognition systems to fail. Those developing and deploying iris recognition should be aware of the potential problems that this could cause to this key biometric technology. PMID:19324690\n\nIris recognition in the presence of ocular disease.\n\nPubMed\n\nAslam, Tariq Mehmood; Tan, Shi Zhuan; Dhillon, Baljean\n\n2009-05-06\n\nIris recognition systems are among the most accurate of all biometric technologies with immense potential for use in worldwide security applications. This study examined the effect of eye pathology on iris recognition and in particular whether eye disease could cause iris recognition systems to fail. The experiment involved a prospective cohort of 54 patients with anterior segment eye disease who were seen at the acute referral unit of the Princess Alexandra Eye Pavilion in Edinburgh. Iris camera images were obtained from patients before treatment was commenced and again at follow-up appointments after treatment had been given. The principal outcome measure was that of mathematical difference in the iris recognition templates obtained from patients' eyes before and after treatment of the eye disease. Results showed that the performance of iris recognition was remarkably resilient to most ophthalmic disease states, including corneal oedema, iridotomies (laser puncture of iris) and conjunctivitis. Problems were, however, encountered in some patients with acute inflammation of the iris (iritis/anterior uveitis). The effects of a subject developing anterior uveitis may cause current recognition systems to fail. Those developing and deploying iris recognition should be aware of the potential problems that this could cause to this key biometric technology.\n\nHierarchical Recognition Scheme for Human Facial Expression Recognition Systems\n\nPubMed Central\n\nSiddiqi, Muhammad Hameed; Lee, Sungyoung; Lee, Young-Koo; Khan, Adil Mehmood; Truc, Phan Tran Ho\n\n2013-01-01\n\nOver the last decade, human facial expressions recognition (FER) has emerged as an important research area. Several factors make FER a challenging research problem. These include varying light conditions in training and test images; need for automatic and accurate face detection before feature extraction; and high similarity among different expressions that makes it difficult to distinguish these expressions with a high accuracy. This work implements a hierarchical linear discriminant analysis-based facial expressions recognition (HL-FER) system to tackle these problems. Unlike the previous systems, the HL-FER uses a pre-processing step to eliminate light effects, incorporates a new automatic face detection scheme, employs methods to extract both global and local features, and utilizes a HL-FER to overcome the problem of high similarity among different expressions. Unlike most of the previous works that were evaluated using a single dataset, the performance of the HL-FER is assessed using three publicly available datasets under three different experimental settings: n-fold cross validation based on subjects for each dataset separately; n-fold cross validation rule based on datasets; and, finally, a last set of experiments to assess the effectiveness of each module of the HL-FER separately. Weighted average recognition accuracy of 98.7% across three different datasets, using three classifiers, indicates the success of employing the HL-FER for human FER. PMID:24316568\n\nNew pattern recognition system in the e-nose for Chinese spirit identification\n\nNASA Astrophysics Data System (ADS)\n\nHui, Zeng; Qiang, Li; Yu, Gu\n\n2016-02-01\n\nThis paper presents a new pattern recognition system for Chinese spirit identification by using the polymer quartz piezoelectric crystal sensor based e-nose. The sensors are designed based on quartz crystal microbalance (QCM) principle, and they could capture different vibration frequency signal values for Chinese spirit identification. For each sensor in an 8-channel sensor array, seven characteristic values of the original vibration frequency signal values, i.e., average value (A), root-mean-square value (RMS), shape factor value (Sf), crest factor value (Cf), impulse factor value (If), clearance factor value (CLf), kurtosis factor value (Kv) are first extracted. Then the dimension of the characteristic values is reduced by the principle components analysis (PCA) method. Finally the back propagation (BP) neutral network algorithm is used to recognize Chinese spirits. The experimental results show that the recognition rate of six kinds of Chinese spirits is 93.33% and our proposed new pattern recognition system can identify Chinese spirits effectively. Project supported by the National High Technology Research and Development Program of China (Grant No. 2013AA030901) and the Fundamental Research Funds for the Central Universities, China (Grant No. FRF-TP-14-120A2).\n\nFuzzy Logic-Based Audio Pattern Recognition\n\nNASA Astrophysics Data System (ADS)\n\nMalcangi, M.\n\n2008-11-01\n\nAudio and audio-pattern recognition is becoming one of the most impor"
    }
}