{
    "id": "dbpedia_2232_0",
    "rank": 76,
    "data": {
        "url": "https://worldwidescience.org/topicpages/v/visualization%2Bsoftware%2Bpackage.html",
        "read_more_link": "",
        "language": "en",
        "title": "visualization software package: Topics by WorldWideScience.org",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/WWSlogo_wTag650px-min.png",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/OSTIlogo.svg",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/ICSTIlogo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Software package for analysis of completely randomized block design\n\nAfrican Journals Online (AJOL)\n\nThis study is to design and develop statistical software (package), OYSP1.0 which conveniently accommodates and analyzes large mass of data emanating from experimental designs, in particular, completely Randomized Block design. Visual Basic programming is used in the design. The statistical package OYSP 1.0Â ...\n\nVISUAL: a software package for plotting data in the RADHEAT-V4 code system\n\nInternational Nuclear Information System (INIS)\n\nSasaki, Toshihiko; Yamano, Naoki\n\n1984-03-01\n\nIn this report, the features, the capabilities and the constitution of the VISUAL Software Package are presented. The one of the features is that the VISUAL provides a versatile graphic display tool to plot a wide variety of data of the RADHEAT-V4 code system. And the other is to enable a user to handle easily the executing data in the Conversational Management Mode named ''CMM''. The program adopts the adjustable dimension system to increase its flexibility. VISUAL generates two-dimensional drawing, contour line map and three dimensional drawing on TSS (Time Sharing System) digital graphic equipment, NLP (Nihongo Laser Printer) or COM(Computer Output Microfilm). It is easily possible to display the calculated and experimental data in a DATA-POOL by using these functions. The purpose of this report is to describe sufficient information to enable a user to use VISUAL profitabily. (author)\n\nDevelopment of a software package for solid-angle calculations using the Monte Carlo method\n\nInternational Nuclear Information System (INIS)\n\nZhang, Jie; Chen, Xiulian; Zhang, Changsheng; Li, Gang; Xu, Jiayun; Sun, Guangai\n\n2014-01-01\n\nSolid-angle calculations play an important role in the absolute calibration of radioactivity measurement systems and in the determination of the activity of radioactive sources, which are often complicated. In the present paper, a software package is developed to provide a convenient tool for solid-angle calculations in nuclear physics. The proposed software calculates solid angles using the Monte Carlo method, in which a new type of variance reduction technique was integrated. The package, developed under the environment of Microsoft Foundation Classes (MFC) in Microsoft Visual C ++ , has a graphical user interface, in which, the visualization function is integrated in conjunction with OpenGL. One advantage of the proposed software package is that it can calculate the solid angle subtended by a detector with different geometric shapes (e.g., cylinder, square prism, regular triangular prism or regular hexagonal prism) to a point, circular or cylindrical source without any difficulty. The results obtained from the proposed software package were compared with those obtained from previous studies and calculated using Geant4. It shows that the proposed software package can produce accurate solid-angle values with a greater computation speed than Geant4. -- Highlights: â¢ This software package (SAC) can give accurate solid-angle values. â¢ SAC calculate solid angles using the Monte Carlo method and it has higher computation speed than Geant4. â¢ A simple but effective variance reduction technique which was put forward by the authors has been applied in SAC. â¢ A visualization function and a graphical user interface are also integrated in SAC\n\nDecon2LS: An open-source software package for automated processing and visualization of high resolution mass spectrometry data.\n\nScience.gov (United States)\n\nJaitly, Navdeep; Mayampurath, Anoop; Littlefield, Kyle; Adkins, Joshua N; Anderson, Gordon A; Smith, Richard D\n\n2009-03-17\n\nData generated from liquid chromatography coupled to high-resolution mass spectrometry (LC-MS)-based studies of a biological sample can contain large amounts of biologically significant information in the form of proteins, peptides, and metabolites. Interpreting this data involves inferring the masses and abundances of biomolecules injected into the instrument. Because of the inherent complexity of mass spectral patterns produced by these biomolecules, the analysis is significantly enhanced by using visualization capabilities to inspect and confirm results. In this paper we describe Decon2LS, an open-source software package for automated processing and visualization of high-resolution MS data. Drawing extensively on algorithms developed over the last ten years for ICR2LS, Decon2LS packages the algorithms as a rich set of modular, reusable processing classes for performing diverse functions such as reading raw data, routine peak finding, theoretical isotope distribution modelling, and deisotoping. Because the source code is openly available, these functionalities can now be used to build derivative applications in relatively fast manner. In addition, Decon2LS provides an extensive set of visualization tools, such as high performance chart controls. With a variety of options that include peak processing, deisotoping, isotope composition, etc, Decon2LS supports processing of multiple raw data formats. Deisotoping can be performed on an individual scan, an individual dataset, or on multiple datasets using batch processing. Other processing options include creating a two dimensional view of mass and liquid chromatography (LC) elution time features, generating spectrum files for tandem MS data, creating total intensity chromatograms, and visualizing theoretical peptide profiles. Application of Decon2LS to deisotope different datasets obtained across different instruments yielded a high number of features that can be used to identify and quantify peptides in the\n\nMARS software package status\n\nInternational Nuclear Information System (INIS)\n\nAzhgirej, I.L.; Talanov, V.V.\n\n2000-01-01\n\nThe MARS software package is intended for simulating the nuclear-electromagnetic cascades and the secondary neutrons and muons transport in the heterogeneous medium of arbitrary complexity in the magnetic fields presence. The inclusive approach to describing the particle production in the nuclear and electromagnetic interactions and by the unstable particles decay is realized in the package. The MARS software package was actively applied for solving various radiation physical problems [ru\n\nSoftware Package for Optics Measurement and Correction in the LHC\n\nCERN Document Server\n\nAiba, M; Tomas, R; Vanbavinckhove, G\n\n2010-01-01\n\nA software package has been developed for the LHC on-line optics measurement and correction. This package includes several different algorithms to measure phase advance, beta functions, dispersion, coupling parameters and even some non-linear terms. A Graphical User Interface provides visualization tools to compare measurements to model predictions, fit analytical formula, localize error sources and compute and send corrections to the hardware.\n\nSoftware design practice using two SCADA software packages\n\nDEFF Research Database (Denmark)\n\nBasse, K.P.; Christensen, Georg Kronborg; Frederiksen, P. K.\n\n1996-01-01\n\nTypical software development for manufacturing control is done either by specialists with consideral real-time programming experience or done by the adaptation of standard software packages for manufacturing control. After investigation and test of two commercial software packages: \"InTouch\" and ......Touch\" and \"Fix\", it is argued, that a more efficient software solution can be achieved by utilising an integrated specification for SCADA and PLC-programming. Experiences gained from process control is planned investigated for descrete parts manufacturing....\n\nDecon2LS: An open-source software package for automated processing and visualization of high resolution mass spectrometry data\n\nDirectory of Open Access Journals (Sweden)\n\nAnderson Gordon A\n\n2009-03-01\n\nFull Text Available Abstract Background Data generated from liquid chromatography coupled to high-resolution mass spectrometry (LC-MS-based studies of a biological sample can contain large amounts of biologically significant information in the form of proteins, peptides, and metabolites. Interpreting this data involves inferring the masses and abundances of biomolecules injected into the instrument. Because of the inherent complexity of mass spectral patterns produced by these biomolecules, the analysis is significantly enhanced by using visualization capabilities to inspect and confirm results. In this paper we describe Decon2LS, an open-source software package for automated processing and visualization of high-resolution MS data. Drawing extensively on algorithms developed over the last ten years for ICR2LS, Decon2LS packages the algorithms as a rich set of modular, reusable processing classes for performing diverse functions such as reading raw data, routine peak finding, theoretical isotope distribution modelling, and deisotoping. Because the source code is openly available, these functionalities can now be used to build derivative applications in relatively fast manner. In addition, Decon2LS provides an extensive set of visualization tools, such as high performance chart controls. Results With a variety of options that include peak processing, deisotoping, isotope composition, etc, Decon2LS supports processing of multiple raw data formats. Deisotoping can be performed on an individual scan, an individual dataset, or on multiple datasets using batch processing. Other processing options include creating a two dimensional view of mass and liquid chromatography (LC elution time features, generating spectrum files for tandem MS data, creating total intensity chromatograms, and visualizing theoretical peptide profiles. Application of Decon2LS to deisotope different datasets obtained across different instruments yielded a high number of features that can be used to\n\nSoftware complex for geophysical data visualization\n\nScience.gov (United States)\n\nKryukov, Ilya A.; Tyugin, Dmitry Y.; Kurkin, Andrey A.; Kurkina, Oxana E.\n\n2013-04-01\n\nThe effectiveness of current research in geophysics is largely determined by the degree of implementation of the procedure of data processing and visualization with the use of modern information technology. Realistic and informative visualization of the results of three-dimensional modeling of geophysical processes contributes significantly into the naturalness of physical modeling and detailed view of the phenomena. The main difficulty in this case is to interpret the results of the calculations: it is necessary to be able to observe the various parameters of the three-dimensional models, build sections on different planes to evaluate certain characteristics and make a rapid assessment. Programs for interpretation and visualization of simulations are spread all over the world, for example, software systems such as ParaView, Golden Software Surfer, Voxler, Flow Vision and others. However, it is not always possible to solve the problem of visualization with the help of a single software package. Preprocessing, data transfer between the packages and setting up a uniform visualization style can turn into a long and routine work. In addition to this, sometimes special display modes for specific data are required and existing products tend to have more common features and are not always fully applicable to certain special cases. Rendering of dynamic data may require scripting languages that does not relieve the user from writing code. Therefore, the task was to develop a new and original software complex for the visualization of simulation results. Let us briefly list of the primary features that are developed. Software complex is a graphical application with a convenient and simple user interface that displays the results of the simulation. Complex is also able to interactively manage the image, resize the image without loss of quality, apply a two-dimensional and three-dimensional regular grid, set the coordinate axes with data labels and perform slice of data. The\n\nSoftware package evaluation for the TJ-II Data Acquisition System\n\nInternational Nuclear Information System (INIS)\n\nCremy, C.; Sanchez, E.; Portas, A.; Vega, J.\n\n1996-01-01\n\nThe TJ-II Data Acquisition System (DAS) has to provide a user interface which will allow setup for sampling channels, discharge signal visualization and reduce data processing, all in run time. On the other hand, the DAS will provide a high level software capability for signal analysis, processing and data visualization either in run time or off line. A set of software packages including Builder Xcessory, X-designer, llog Builder, Toolmaster, AVS 5, AVS/Express, PV-WAVE and Iris Explorer, have been evaluated by the Data Acquisition Group of the Fusion Division. the software evaluation, resumed in this paper, has resulted in a global solution being found which meets all of the DAS requirements. (Author)\n\nThe Ettention software package\n\nInternational Nuclear Information System (INIS)\n\nDahmen, Tim; Marsalek, Lukas; Marniok, Nico; TuroÅovÃ¡, Beata; Bogachev, Sviatoslav; Trampert, Patrick; Nickels, Stefan; Slusallek, Philipp\n\n2016-01-01\n\nWe present a novel software package for the problem âreconstruction from projectionsâ in electron microscopy. The Ettention framework consists of a set of modular building-blocks for tomographic reconstruction algorithms. The well-known block iterative reconstruction method based on Kaczmarz algorithm is implemented using these building-blocks, including adaptations specific to electron tomography. Ettention simultaneously features (1) a modular, object-oriented software design, (2) optimized access to high-performance computing (HPC) platforms such as graphic processing units (GPU) or many-core architectures like Xeon Phi, and (3) accessibility to microscopy end-users via integration in the IMOD package and eTomo user interface. We also provide developers with a clean and well-structured application programming interface (API) that allows for extending the software easily and thus makes it an ideal platform for algorithmic research while hiding most of the technical details of high-performance computing. - Highlights: â¢ Novel software package for âreconstruction from projectionsâ in electron microscopy. â¢ Support for high-resolution reconstructions on iterative reconstruction algorithms. â¢ Support for CPU, GPU and Xeon Phi. â¢ Integration in the IMOD software. â¢ Platform for algorithm researchers: object oriented, modular design.\n\nThe Ettention software package\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nDahmen, Tim, E-mail: Tim.Dahmen@dfki.de [German Research Center for Artificial Intelligence GmbH (DFKI), 66123 SaarbrÃ¼cken (Germany); Saarland University, 66123 SaarbrÃ¼cken (Germany); Marsalek, Lukas [Eyen SE, Na NivÃ¡ch 1043/16, 141 00 Praha 4 (Czech Republic); Saarland University, 66123 SaarbrÃ¼cken (Germany); Marniok, Nico [Saarland University, 66123 SaarbrÃ¼cken (Germany); TuroÅovÃ¡, Beata [Saarland University, 66123 SaarbrÃ¼cken (Germany); IMPRS-CS, Max-Planck Institute for Informatics, Campus E 1.4, 66123 SaarbrÃ¼cken (Germany); Bogachev, Sviatoslav [Saarland University, 66123 SaarbrÃ¼cken (Germany); Trampert, Patrick; Nickels, Stefan [German Research Center for Artificial Intelligence GmbH (DFKI), 66123 SaarbrÃ¼cken (Germany); Slusallek, Philipp [German Research Center for Artificial Intelligence GmbH (DFKI), 66123 SaarbrÃ¼cken (Germany); Saarland University, 66123 SaarbrÃ¼cken (Germany)\n\n2016-02-15\n\nWe present a novel software package for the problem âreconstruction from projectionsâ in electron microscopy. The Ettention framework consists of a set of modular building-blocks for tomographic reconstruction algorithms. The well-known block iterative reconstruction method based on Kaczmarz algorithm is implemented using these building-blocks, including adaptations specific to electron tomography. Ettention simultaneously features (1) a modular, object-oriented software design, (2) optimized access to high-performance computing (HPC) platforms such as graphic processing units (GPU) or many-core architectures like Xeon Phi, and (3) accessibility to microscopy end-users via integration in the IMOD package and eTomo user interface. We also provide developers with a clean and well-structured application programming interface (API) that allows for extending the software easily and thus makes it an ideal platform for algorithmic research while hiding most of the technical details of high-performance computing. - Highlights: â¢ Novel software package for âreconstruction from projectionsâ in electron microscopy. â¢ Support for high-resolution reconstructions on iterative reconstruction algorithms. â¢ Support for CPU, GPU and Xeon Phi. â¢ Integration in the IMOD software. â¢ Platform for algorithm researchers: object oriented, modular design.\n\nAstroBlend: An astrophysical visualization package for Blender\n\nScience.gov (United States)\n\nNaiman, J. P.\n\n2016-04-01\n\nThe rapid growth in scale and complexity of both computational and observational astrophysics over the past decade necessitates efficient and intuitive methods for examining and visualizing large datasets. Here, I present AstroBlend, an open-source Python library for use within the three dimensional modeling software, Blender. While Blender has been a popular open-source software among animators and visual effects artists, in recent years it has also become a tool for visualizing astrophysical datasets. AstroBlend combines the three dimensional capabilities of Blender with the analysis tools of the widely used astrophysical toolset, yt, to afford both computational and observational astrophysicists the ability to simultaneously analyze their data and create informative and appealing visualizations. The introduction of this package includes a description of features, work flow, and various example visualizations. A website - www.astroblend.com - has been developed which includes tutorials, and a gallery of example images and movies, along with links to downloadable data, three dimensional artistic models, and various other resources.\n\nPackaging of control system software\n\nInternational Nuclear Information System (INIS)\n\nZagar, K.; Kobal, M.; Saje, N.; Zagar, A.; Sabjan, R.; Di Maio, F.; Stepanov, D.\n\n2012-01-01\n\nControl system software consists of several parts - the core of the control system, drivers for integration of devices, configuration for user interfaces, alarm system, etc. Once the software is developed and configured, it must be installed to computers where it runs. Usually, it is installed on an operating system whose services it needs, and also in some cases dynamically links with the libraries it provides. Operating system can be quite complex itself - for example, a typical Linux distribution consists of several thousand packages. To manage this complexity, we have decided to rely on Red Hat Package Management system (RPM) to package control system software, and also ensure it is properly installed (i.e., that dependencies are also installed, and that scripts are run after installation if any additional actions need to be performed). As dozens of RPM packages need to be prepared, we are reducing the amount of effort and improving consistency between packages through a Maven-based infrastructure that assists in packaging (e.g., automated generation of RPM SPEC files, including automated identification of dependencies). So far, we have used it to package EPICS, Control System Studio (CSS) and several device drivers. We perform extensive testing on Red Hat Enterprise Linux 5.5, but we have also verified that packaging works on CentOS and Scientific Linux. In this article, we describe in greater detail the systematic system of packaging we are using, and its particular application for the ITER CODAC Core System. (authors)\n\nIntercomparison of PIXE spectrometry software packages\n\nInternational Nuclear Information System (INIS)\n\n2003-02-01\n\nDuring the year 2000, an exercise was organized to make a intercomparison of widely available software packages for analysis of particle induced X ray emission (PIXE) spectra. This TECDOC describes the method used in this intercomparison exercise and presents the results obtained. It also gives a general overview of the participating software packages. This includes basic information on their user interface, graphical presentation capabilities, physical phenomena taken in account, way of presenting results, etc. No recommendation for a particular software package or method for spectrum analysis is given. It is intended that the readers reach their own conclusions and make their own choices, according to their specific needs. This TECDOC will be useful to anyone involved in PIXE spectrum analysis. This TECDOC includes a companion CD with the complete set of test spectra used for intercomparison. The test spectra on this CD can be used to test any PIXE spectral analysis software package\n\nGGT2.0: Versatile Software for visualization and analysis of genetic data\n\nNARCIS (Netherlands)\n\nBerloo, van R.\n\n2008-01-01\n\nEver since its first release in 1999, the free software package for visualization of molecular marker data, graphical genotype (GGT), has been constantly adapted and improved. The GGT package was developed in a plant-breeding context and thus focuses on plant genetic data but was not intended to be\n\nIntercomparison of alpha particle spectrometry software packages\n\nInternational Nuclear Information System (INIS)\n\n1999-08-01\n\nSoftware has reached an important level as the 'logical controller' at different levels, from a single instrument to an entire computer-controlled experiment. This is also the case for software packages in nuclear instruments and experiments. In particular, because of the range of applications of alpha-particle spectrometry, software packages in this field are often used. It is the aim of this intercomparison to test and describe the abilities of four such software packages. The main objectives of the intercomparison were the ability of the programs to determine the peak areas and the peak area uncertainties, and the statistical control and stability of reported results. In this report, the task, methods and results of the intercomparison are presented in order to asist the potential users of such software and to stimulate the development of even better alpha-particle spectrum analysis software\n\nEvaluation of a software package for automated quality assessment of contrast detail images-comparison with subjective visual assessment\n\nInternational Nuclear Information System (INIS)\n\nPascoal, A; Lawinski, C P; Honey, I; Blake, P\n\n2005-01-01\n\nContrast detail analysis is commonly used to assess image quality (IQ) associated with diagnostic imaging systems. Applications include routine assessment of equipment performance and optimization studies. Most frequently, the evaluation of contrast detail images involves human observers visually detecting the threshold contrast detail combinations in the image. However, the subjective nature of human perception and the variations in the decision threshold pose limits to the minimum image quality variations detectable with reliability. Objective methods of assessment of image quality such as automated scoring have the potential to overcome the above limitations. A software package (CDRAD analyser) developed for automated scoring of images produced with the CDRAD test object was evaluated. Its performance to assess absolute and relative IQ was compared with that of an average observer. Results show that the software does not mimic the absolute performance of the average observer. The software proved more sensitive and was able to detect smaller low-contrast variations. The observer's performance was superior to the software's in the detection of smaller details. Both scoring methods showed frequent agreement in the detection of image quality variations resulting from changes in kVp and KERMA detector , which indicates the potential to use the software CDRAD analyser for assessment of relative IQ\n\nSoftware refactoring at the package level using clustering techniques\n\nKAUST Repository\n\nAlkhalid, A.\n\n2011-01-01\n\nEnhancing, modifying or adapting the software to new requirements increases the internal software complexity. Software with high level of internal complexity is difficult to maintain. Software refactoring reduces software complexity and hence decreases the maintenance effort. However, software refactoring becomes quite challenging task as the software evolves. The authors use clustering as a pattern recognition technique to assist in software refactoring activities at the package level. The approach presents a computer aided support for identifying ill-structured packages and provides suggestions for software designer to balance between intra-package cohesion and inter-package coupling. A comparative study is conducted applying three different clustering techniques on different software systems. In addition, the application of refactoring at the package level using an adaptive k-nearest neighbour (A-KNN) algorithm is introduced. The authors compared A-KNN technique with the other clustering techniques (viz. single linkage algorithm, complete linkage algorithm and weighted pair-group method using arithmetic averages). The new technique shows competitive performance with lower computational complexity. Â© 2011 The Institution of Engineering and Technology.\n\nAstroBlend: Visualization package for use with Blender\n\nScience.gov (United States)\n\nNaiman, J. P.\n\n2015-12-01\n\nAstroBlend is a visualization package for use in the three dimensional animation and modeling software, Blender. It reads data in via a text file or can use pre-fab isosurface files stored as OBJ or Wavefront files. AstroBlend supports a variety of codes such as FLASH (ascl:1010.082), Enzo (ascl:1010.072), and Athena (ascl:1010.014), and combines artistic 3D models with computational astrophysics datasets to create models and animations.\n\nThe Ettention software package.\n\nScience.gov (United States)\n\nDahmen, Tim; Marsalek, Lukas; Marniok, Nico; TuroÅovÃ¡, Beata; Bogachev, Sviatoslav; Trampert, Patrick; Nickels, Stefan; Slusallek, Philipp\n\n2016-02-01\n\nWe present a novel software package for the problem \"reconstruction from projections\" in electron microscopy. The Ettention framework consists of a set of modular building-blocks for tomographic reconstruction algorithms. The well-known block iterative reconstruction method based on Kaczmarz algorithm is implemented using these building-blocks, including adaptations specific to electron tomography. Ettention simultaneously features (1) a modular, object-oriented software design, (2) optimized access to high-performance computing (HPC) platforms such as graphic processing units (GPU) or many-core architectures like Xeon Phi, and (3) accessibility to microscopy end-users via integration in the IMOD package and eTomo user interface. We also provide developers with a clean and well-structured application programming interface (API) that allows for extending the software easily and thus makes it an ideal platform for algorithmic research while hiding most of the technical details of high-performance computing. Copyright Â© 2015 Elsevier B.V. All rights reserved.\n\nggCyto: Next Generation Open-Source Visualization Software for Cytometry.\n\nScience.gov (United States)\n\nVan, Phu; Jiang, Wenxin; Gottardo, Raphael; Finak, Greg\n\n2018-06-01\n\nOpen source software for computational cytometry has gained in popularity over the past few years. Efforts such as FlowCAP, the Lyoplate and Euroflow projects have highlighted the importance of efforts to standardize both experimental and computational aspects of cytometry data analysis. The R/BioConductor platform hosts the largest collection of open source cytometry software covering all aspects of data analysis and providing infrastructure to represent and analyze cytometry data with all relevant experimental, gating, and cell population annotations enabling fully reproducible data analysis. Data visualization frameworks to support this infrastructure have lagged behind. ggCyto is a new open-source BioConductor software package for cytometry data visualization built on ggplot2 that enables ggplot-like functionality with the core BioConductor flow cytometry data structures. Amongst its features are the ability to transform data and axes on-the-fly using cytometry-specific transformations, plot faceting by experimental meta-data variables, and partial matching of channel, marker and cell populations names to the contents of the BioConductor cytometry data structures. We demonstrate the salient features of the package using publicly available cytometry data with complete reproducible examples in a supplementary material vignette. https://bioconductor.org/packages/devel/bioc/html/ggcyto.html. gfinak@fredhutch.org. Supplementary data are available at Bioinformatics online and at http://rglab.org/ggcyto/.\n\nVIPEX (Vital-area Identification Package EXpert) Software Verification and Validation\n\nInternational Nuclear Information System (INIS)\n\nJung, Woo Sik; Suh, Jae Seung\n\n2010-06-01\n\nThe purposes of this report are (1) to perform a Verification and Validation (V and V) test for the VIPEX(Vital-area Identification Package EXpert) software and (2) to improve a software quality through the V and V test. The VIPEX was developed in Korea Atomic Energy Research Institute (KAERI) for the Vital Area Identification (VAI) of nuclear power plants. The version of the VIPEX which was distributed is 3.2.0.0. The VIPEX was revised based on the first V and V test and the second V and V test was performed. We have performed the following tasks for the V and V test on Windows XP and VISTA operating systems: Î Testing basic functions including fault tree editing Î Testing all kind of functions Î Research for update from Visual BASIC 6.0 to Visual BASIC 2008\n\nBringing Legacy Visualization Software to Modern Computing Devices via Application Streaming\n\nScience.gov (United States)\n\nFisher, Ward\n\n2014-05-01\n\nPlanning software compatibility across forthcoming generations of computing platforms is a problem commonly encountered in software engineering and development. While this problem can affect any class of software, data analysis and visualization programs are particularly vulnerable. This is due in part to their inherent dependency on specialized hardware and computing environments. A number of strategies and tools have been designed to aid software engineers with this task. While generally embraced by developers at 'traditional' software companies, these methodologies are often dismissed by the scientific software community as unwieldy, inefficient and unnecessary. As a result, many important and storied scientific software packages can struggle to adapt to a new computing environment; for example, one in which much work is carried out on sub-laptop devices (such as tablets and smartphones). Rewriting these packages for a new platform often requires significant investment in terms of development time and developer expertise. In many cases, porting older software to modern devices is neither practical nor possible. As a result, replacement software must be developed from scratch, wasting resources better spent on other projects. Enabled largely by the rapid rise and adoption of cloud computing platforms, 'Application Streaming' technologies allow legacy visualization and analysis software to be operated wholly from a client device (be it laptop, tablet or smartphone) while retaining full functionality and interactivity. It mitigates much of the developer effort required by other more traditional methods while simultaneously reducing the time it takes to bring the software to a new platform. This work will provide an overview of Application Streaming and how it compares against other technologies which allow scientific visualization software to be executed from a remote computer. We will discuss the functionality and limitations of existing application streaming\n\nPsyToolkit: a software package for programming psychological experiments using Linux.\n\nScience.gov (United States)\n\nStoet, Gijsbert\n\n2010-11-01\n\nPsyToolkit is a set of software tools for programming psychological experiments on Linux computers. Given that PsyToolkit is freely available under the Gnu Public License, open source, and designed such that it can easily be modified and extended for individual needs, it is suitable not only for technically oriented Linux users, but also for students, researchers on small budgets, and universities in developing countries. The software includes a high-level scripting language, a library for the programming language C, and a questionnaire presenter. The software easily integrates with other open source tools, such as the statistical software package R. PsyToolkit is designed to work with external hardware (including IoLab and Cedrus response keyboards and two common digital input/output boards) and to support millisecond timing precision. Four in-depth examples explain the basic functionality of PsyToolkit. Example 1 demonstrates a stimulus-response compatibility experiment. Example 2 demonstrates a novel mouse-controlled visual search experiment. Example 3 shows how to control light emitting diodes using PsyToolkit, and Example 4 shows how to build a light-detection sensor. The last two examples explain the electronic hardware setup such that they can even be used with other software packages.\n\nSoftware package as an information center product\n\nInternational Nuclear Information System (INIS)\n\nButler, M.K.\n\n1977-01-01\n\nThe Argonne Code Center serves as a software exchange and information center for the U.S. Energy Research and Development Administration and the Nuclear Regulatory Commission. The goal of the Center's program is to provide a means for sharing of software among agency offices and contractors, and for transferring computing applications and technology, developed within the agencies, to the information-processing community. A major activity of the Code Center is the acquisition, review, testing, and maintenance of a collection of software--computer systems, applications programs, subroutines, modules, and data compilations--prepared by agency offices and contractors to meet programmatic needs. A brief review of the history of computer program libraries and software sharing is presented to place the Code Center activity in perspective. The state-of-the-art discussion starts off with an appropriate definition of the term software package, together with descriptions of recommended package contents and the Carter's package evaluation activity. An effort is made to identify the various users of the product, to enumerate their individual needs, to document the Center's efforts to meet these needs and the ongoing interaction with the user community. Desirable staff qualifications are considered, and packaging problems, reviewed. The paper closes with a brief look at recent developments and a forecast of things to come. 2 tables\n\nIntroduction to Software Packages. [Final Report.\n\nScience.gov (United States)\n\nFrankel, Sheila, Ed.; And Others\n\nThis document provides an introduction to applications computer software packages that support functional managers in government and encourages the use of such packages as an alternative to in-house development. A review of current application areas includes budget/project management, financial management/accounting, payroll, personnel,â¦\n\nUserâs Manual for the Simulation of Energy Consumption and Emissions from Rail Traffic Software Package\n\nDEFF Research Database (Denmark)\n\nCordiero, Tiago M.; Lindgreen, Erik BjÃ¸rn GrÃ¸nning; Sorenson, Spencer C\n\n2005-01-01\n\nThe ARTEMIS rail emissions model was implemented in a Microsoft Excel software package that includes data from the GISCO database on railway traffic. This report is the userâs manual for the aforementioned software that includes information on how to run the program and an overview on how...... of Excel Macros (Visual Basic) and database sheets included in one Excel file...\n\nPIV Data Validation Software Package\n\nScience.gov (United States)\n\nBlackshire, James L.\n\n1997-01-01\n\nA PIV data validation and post-processing software package was developed to provide semi-automated data validation and data reduction capabilities for Particle Image Velocimetry data sets. The software provides three primary capabilities including (1) removal of spurious vector data, (2) filtering, smoothing, and interpolating of PIV data, and (3) calculations of out-of-plane vorticity, ensemble statistics, and turbulence statistics information. The software runs on an IBM PC/AT host computer working either under Microsoft Windows 3.1 or Windows 95 operating systems.\n\nNew software for neutron data reduction and visualization\n\nInternational Nuclear Information System (INIS)\n\nWorlton, T.; Chatterjee, A.; Hammonds, J.; Chen, D.; Loong, C.K.; Mikkelson, D.; Mikkelson, R.\n\n2001-01-01\n\nDevelopment of advanced neutron sources and instruments has necessitated corresponding advances in software for neutron scattering data reduction and visualization. New sources produce datasets more rapidly, and new instruments produce large numbers of spectra. Because of the shorter collection times, users are able to make more measurements on a given sample. This rapid production of datasets requires that users be able to reduce and analyze data quickly to prevent a data bottleneck. In addition, the new sources and instruments are accommodating more users with less neutron-scattering specific expertise, which requires software that is easy to use and freely available. We have developed an Integrated Spectral Analysis Workbench (ISAW) software package to permit the rapid reduction and visualization of neutron data. It can handle large numbers of spectra and merge data from separate measurements. The data can be sorted according to any attribute and transformed in numerous ways. ISAW provides several views of the data that enable users to compare spectra and observe trends in the data. A command interpreter, which is now part of ISAW, allows scientists to easily set up a series of instrument-specific operations to reduce and visualize data automatically. ISAW is written entirely in Java to permit portability to different computer platforms and easy distribution of the software. The software was constructed using modern computer design methods to allow easy customization and improvement. ISAW currently only reads data from IPNS 'run' files, but work is underway to provide input of NeXus files. (author)\n\nNew software for neutron data reduction and visualization\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nWorlton, T.; Chatterjee, A.; Hammonds, J.; Chen, D.; Loong, C.K. [Argonne National Laboratory, Argonne, IL (United States); Mikkelson, D.; Mikkelson, R. [Univ. of Wisconsin-Stout, Menomonie, WI (United States)\n\n2001-03-01\n\nDevelopment of advanced neutron sources and instruments has necessitated corresponding advances in software for neutron scattering data reduction and visualization. New sources produce datasets more rapidly, and new instruments produce large numbers of spectra. Because of the shorter collection times, users are able to make more measurements on a given sample. This rapid production of datasets requires that users be able to reduce and analyze data quickly to prevent a data bottleneck. In addition, the new sources and instruments are accommodating more users with less neutron-scattering specific expertise, which requires software that is easy to use and freely available. We have developed an Integrated Spectral Analysis Workbench (ISAW) software package to permit the rapid reduction and visualization of neutron data. It can handle large numbers of spectra and merge data from separate measurements. The data can be sorted according to any attribute and transformed in numerous ways. ISAW provides several views of the data that enable users to compare spectra and observe trends in the data. A command interpreter, which is now part of ISAW, allows scientists to easily set up a series of instrument-specific operations to reduce and visualize data automatically. ISAW is written entirely in Java to permit portability to different computer platforms and easy distribution of the software. The software was constructed using modern computer design methods to allow easy customization and improvement. ISAW currently only reads data from IPNS 'run' files, but work is underway to provide input of NeXus files. (author)\n\nNested Cohort - R software package\n\nScience.gov (United States)\n\nNestedCohort is an R software package for fitting Kaplan-Meier and Cox Models to estimate standardized survival and attributable risks for studies where covariates of interest are observed on only a sample of the cohort.\n\nSoftware attribute visualization for high integrity software\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nPollock, G.M.\n\n1998-03-01\n\nThis report documents a prototype tool developed to investigate the use of visualization and virtual reality technologies for improving software surety confidence. The tool is utilized within the execution phase of the software life cycle. It provides a capability to monitor an executing program against prespecified requirements constraints provided in a program written in the requirements specification language SAGE. The resulting Software Attribute Visual Analysis Tool (SAVAnT) also provides a technique to assess the completeness of a software specification.\n\nvrmlgen: An R Package for 3D Data Visualization on the Web\n\nDirectory of Open Access Journals (Sweden)\n\nEnrico Glaab\n\n2010-10-01\n\nFull Text Available The 3-dimensional representation and inspection of complex data is a frequently used strategy in many data analysis domains. Existing data mining software often lacks functionality that would enable users to explore 3D data interactively, especially if one wishes to make dynamic graphical representations directly viewable on the web.In this paper we present vrmlgen, a software package for the statistical programming language R to create 3D data visualizations in web formats like the Virtual Reality Markup Language (VRML and LiveGraphics3D. vrmlgen can be used to generate 3D charts and bar plots, scatter plots with density estimation contour surfaces, and visualizations of height maps, 3D object models and parametric functions. For greater flexibility, the user can also access low-level plotting methods through a unified interface and freely group different function calls together to create new higher-level plotting methods. Additionally, we present a web tool allowing users to visualize 3D data online and test some of vrmlgen's features without the need to install any software on their computer.\n\nMOST-visualization: software for producing automated textbook-style maps of genome-scale metabolic networks.\n\nScience.gov (United States)\n\nKelley, James J; Maor, Shay; Kim, Min Kyung; Lane, Anatoliy; Lun, Desmond S\n\n2017-08-15\n\nVisualization of metabolites, reactions and pathways in genome-scale metabolic networks (GEMs) can assist in understanding cellular metabolism. Three attributes are desirable in software used for visualizing GEMs: (i) automation, since GEMs can be quite large; (ii) production of understandable maps that provide ease in identification of pathways, reactions and metabolites; and (iii) visualization of the entire network to show how pathways are interconnected. No software currently exists for visualizing GEMs that satisfies all three characteristics, but MOST-Visualization, an extension of the software package MOST (Metabolic Optimization and Simulation Tool), satisfies (i), and by using a pre-drawn overview map of metabolism based on the Roche map satisfies (ii) and comes close to satisfying (iii). MOST is distributed for free on the GNU General Public License. The software and full documentation are available at http://most.ccib.rutgers.edu/. dslun@rutgers.edu. Supplementary data are available at Bioinformatics online. Â© The Author (2017). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com\n\nSoftware packages for food engineering needs\n\nOpenAIRE\n\nAbakarov, Alik\n\n2011-01-01\n\nThe graphic user interface (GUI) software packages âANNEKsâ and âOPT-PROxâ are developed to meet food engineering needs. âOPT-RROxâ (OPTimal PROfile) is software developed to carry out thermal food processing optimization based on the variable retort temperature processing and global optimization technique. âANNEKsâ (Artificial Neural Network Enzyme Kinetics) is software designed for determining the kinetics of enzyme hydrolysis of protein at different initial reaction parameters based on the...\n\nIntercomparison of gamma ray analysis software packages\n\nInternational Nuclear Information System (INIS)\n\n1998-04-01\n\nThe IAEA undertook an intercomparison exercise to review available software for gamma ray spectra analysis. This document describes the methods used in the intercomparison exercise, characterizes the software packages reviewed and presents the results obtained. Only direct results are given without any recommendation for a particular software or method for gamma ray spectra analysis\n\nStrategic Business-IT alignment of application software packages: Bridging the Information Technology gap\n\nDirectory of Open Access Journals (Sweden)\n\nWandi Kruger\n\n2012-09-01\n\nFull Text Available An application software package implementation is a complex endeavour, and as such it requires the proper understanding, evaluation and redefining of the current business processes to ensure that the implementation delivers on the objectives set at the start of the project. Numerous factors exist that may contribute to the unsuccessful implementation of application software packages. However, the most significant contributor to the failure of an application software package implementation lies in the misalignment of the organisationâs business processes with the functionality of the application software package. Misalignment is attributed to a gap that exists between the business processes of an organisation and what functionality the application software package has to offer to translate the business processes of an organisation into digital form when implementing and configuring an application software package. This gap is commonly referred to as the information technology (IT gap. This study proposes to define and discuss the IT gap. Furthermore this study will make recommendations for aligning the business processes with the functionality of the application software package (addressing the IT gap. The end result of adopting these recommendations will be more successful application software package implementations.\n\nComparison of PV system design software packages for urban applications\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nGharakhani Siraki, Arbi; Pillay, Pragasen\n\n2010-09-15\n\nA large number of software packages are available for solar resource evaluation and PV system design. However, few of them are suitable for urban applications. In this paper a comparison has been made between two specifically designed solar tools known as the Ecotect 2010 and the PVsyst 5.05. Conclusions have been made for proper use of these packages based on their specifications and privileges. Moreover, the calculations have been repeated with HOMER software package (which is a generic tool) for the same location. The results suggest that a generic solar software tool should not be used for an urban application.\n\nAccuracy of Giovanni and Marksim Software Packages for ...\n\nAfrican Journals Online (AJOL)\n\nAccuracy of Giovanni and Marksim Software Packages for Generating Daily Rainfall Data in ... using Giovanni software over Marksim, for areas receiving bimodal rainfall regimes similar to ... EMAIL FREE FULL TEXT EMAIL FREE FULL TEXT\n\nORNL's DCAL software package\n\nInternational Nuclear Information System (INIS)\n\nEckerman, K.F.\n\n2007-01-01\n\nOak Ridge National Laboratory has released its Dose and Risk Calculation software, DCAL. DCAL, developed with the support of the U.S. Environmental Protection Agency, consists of a series of computational modules, driven in either an interactive or a batch mode for computation of dose and risk coefficients from intakes of radionuclides or exposure to radionuclides in environmental media. The software package includes extensive libraries of biokinetic and dosimetric data that represent the current state of the art. The software has unique capability for addressing intakes of radionuclides by non-adults. DCAL runs as 32-bit extended DOS and console applications under Windows 98/NT/2000/XP. It is intended for users familiar with the basic elements of computational radiation dosimetry. Components of DCAL have been used to prepare U.S. Environmental Protection Agency's Federal Guidance Reports 12 and 13 and several publications of the International Commission on Radiological Protection. (author)\n\nA software package for biomedical image processing and analysis\n\nInternational Nuclear Information System (INIS)\n\nGoncalves, J.G.M.; Mealha, O.\n\n1988-01-01\n\nThe decreasing cost of computing power and the introduction of low cost imaging boards justifies the increasing number of applications of digital image processing techniques in the area of biomedicine. There is however a large software gap to be fulfilled, between the application and the equipment. The requirements to bridge this gap are twofold: good knowledge of the hardware provided and its interface to the host computer, and expertise in digital image processing and analysis techniques. A software package incorporating these two requirements was developed using the C programming language, in order to create a user friendly image processing programming environment. The software package can be considered in two different ways: as a data structure adapted to image processing and analysis, which acts as the backbone and the standard of communication for all the software; and as a set of routines implementing the basic algorithms used in image processing and analysis. Hardware dependency is restricted to a single module upon which all hardware calls are based. The data structure that was built has four main features: hierchical, open, object oriented, and object dependent dimensions. Considering the vast amount of memory needed by imaging applications and the memory available in small imaging systems, an effective image memory management scheme was implemented. This software package is being used for more than one and a half years by users with different applications. It proved to be an excellent tool for helping people to get adapted into the system, and for standardizing and exchanging software, yet preserving flexibility allowing for users' specific implementations. The philosophy of the software package is discussed and the data structure that was built is described in detail\n\nAdoption of open source digital library software packages: a survey\n\nOpenAIRE\n\nJose, Sanjo\n\n2007-01-01\n\nOpen source digital library packages are gaining popularity nowadays. To build a digital library under economical conditions open source software is preferable. This paper tries to identify the extent of adoption of open source digital library software packages in various organizations through an online survey. It lays down the findings from the survey.\n\nGraphical representation of ribosomal RNA probe accessibility data using ARB software package\n\nDirectory of Open Access Journals (Sweden)\n\nAmann Rudolf\n\n2005-03-01\n\nFull Text Available Abstract Background Taxon specific hybridization probes in combination with a variety of commonly used hybridization formats nowadays are standard tools in microbial identification. A frequently applied technology, fluorescence in situ hybridization (FISH, besides single cell identification, allows the localization and functional studies of the microbial community composition. Careful in silico design and evaluation of potential oligonucleotide probe targets is therefore crucial for performing successful hybridization experiments. Results The PROBE Design tools of the ARB software package take into consideration several criteria such as number, position and quality of diagnostic sequence differences while designing oligonucleotide probes. Additionally, new visualization tools were developed to enable the user to easily examine further sequence associated criteria such as higher order structure, conservation, G+C content, transition-transversion profiles and in situ target accessibility patterns. The different types of sequence associated information (SAI can be visualized by user defined background colors within the ARB primary and secondary structure editors as well as in the PROBE Match tool. Conclusion Using this tool, in silico probe design and evaluation can be performed with respect to in situ probe accessibility data. The evaluation of proposed probe targets with respect to higher-order rRNA structure is of importance for successful design and performance of in situ hybridization experiments. The entire ARB software package along with the probe accessibility data is available from the ARB home page http://www.arb-home.de.\n\nHuman-machine interface software package\n\nInternational Nuclear Information System (INIS)\n\nLiu, D.K.; Zhang, C.Z.\n\n1992-01-01\n\nThe Man-Machine Interface software Package (MMISP) is designed to configure the console software of PLS 60 Mev LINAC control system. The control system of PLS 60 Mev LINAC is a distributed control system which includes the main computer (Intel 310) four local station, and two sets of industrial level console computer. The MMISP provides the operator with the display page editor, various I/O configuration such as digital signals In/Out, analog signal In/Out, waveform TV graphic display, and interactive with operator through graphic picture display, voice explanation, and touch panel. This paper describes its function and application. (author)\n\nRisk Analysis and Decision-Making Software Package (1997 Version) User Manual\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nChung, F.T.H.\n\n1999-02-11\n\nThis manual provides instructions for using the U.S. Department of Energy's (DOE) risk analysis and decision making software (1997 version) developed at BDM Petroleum Technologies by BDM-Oklahoma, Inc. for DOE, under contract No. DE-AC22-94PC91OO8. This software provides petroleum producers with a simple, handy tool for exploration and production risk analysis and decision-making. It collects useful risk analysis tools in one package so that users do not have to use several programs separately. The software is simple to use, but still provides many functions. The 1997 version of the software package includes the following tools: (1) Investment risk (Gambler's ruin) analysis; (2) Monte Carlo simulation; (3) Best fit for distribution functions; (4) Sample and rank correlation; (5) Enhanced oil recovery method screening; and (6) artificial neural network. This software package is subject to change. Suggestions and comments from users are welcome and will be considered for future modifications and enhancements of the software. Please check the opening screen of the software for the current contact information. In the future, more tools will be added to this software package. This manual includes instructions on how to use the software but does not attempt to fully explain the theory and algorithms used to create it.\n\nSoftware Package STATISTICA and Educational Process\n\nDirectory of Open Access Journals (Sweden)\n\nDemidova Liliya\n\n2016-01-01\n\nFull Text Available The paper describes the main aspects of application of the software package STATISTICA in the educational process. Technologies of data mining which can be useful for students researches have been considered. The main tools of these technologies have been discussed.\n\nAdvances in the development of the PIXEKLM-TPI software package\n\nInternational Nuclear Information System (INIS)\n\nUzonyi, I.; Szabo, Gy.\n\n2005-01-01\n\nComplete text of publication follows. During the past decade great effort has been devoted to the developments of various local analytical methods which are capable to analyze small volumes of a sample (in the range of some Î¼m 3 ) by high lateral and/or depth resolution. Among the Ion Beam Analytical (IBA) methods, Particle Induced X-Ray Fluorescence Emission (PIXE) analysis has been used for qualitative elemental imaging for a long time. Nevertheless, production of quantitative images is still a challenging and unresolved problem in general. Ryan and his co-workers were the first who developed a software package (GeoPIXE) for on-line quantitative mapping which is capable to analyze especially thick samples. Some years ago we also started to develop quantitative PIXE imaging software and suggested a different approach for the compensation of matrix effects and sample thickness. It is based on the rapid matrix transform method called Dynamic Analysis which directly converts the spectrum vector (S) into the concentration vector (C) in terms of the matrix Î. We modified the earlier version of the PIXEKLM program in order to calculate the Î matrix for materials of any thickness. Furthermore, we have developed a windows-based program (True PIXE Imaging, TPI) which calculates elemental distributions on a pixel by pixel basis and creates so called elemental images from them in bit map form using colour bars. The basic part of the new program package was published in 2005. During the past year much efforts has been devoted to develop various new options such as visualization of spectrum components in order to make the program more user-friendly and applicable. In the figure below the decomposed PIXE spectrum of an industrial material is visualized. (author)\n\nInternational Inventory of Software Packages in the Information Field.\n\nScience.gov (United States)\n\nKeren, Carl, Ed.; Sered, Irina, Ed.\n\nDesigned to provide guidance in selecting appropriate software for library automation, information storage and retrieval, or management of bibliographic databases, this inventory describes 188 computer software packages. The information was obtained through a questionnaire survey of 600 software suppliers and developers who were asked to describeâ¦\n\n3D modeling and visualization software for complex geometries\n\nInternational Nuclear Information System (INIS)\n\nGuse, Guenter; Klotzbuecher, Michael; Mohr, Friedrich\n\n2011-01-01\n\nThe reactor safety depends on reliable nondestructive testing of reactor components. For 100% detection probability of flaws and the determination of their size using ultrasonic methods the ultrasonic waves have to hit the flaws within a specific incidence and squint angle. For complex test geometries like testing of nozzle welds from the outside of the component these angular ranges can only be determined using elaborate mathematical calculations. The authors developed a 3D modeling and visualization software tool that allows to integrate and present ultrasonic measuring data into the 3D geometry. The software package was verified using 1:1 test samples (example: testing of the nozzle edge of the feedwater nozzle of a steam generator from the outside; testing of the reactor pressure vessel nozzle edge from the inside).\n\nQuantWorm: a comprehensive software package for Caenorhabditis elegans phenotypic assays.\n\nDirectory of Open Access Journals (Sweden)\n\nSang-Kyu Jung\n\nFull Text Available Phenotypic assays are crucial in genetics; however, traditional methods that rely on human observation are unsuitable for quantitative, large-scale experiments. Furthermore, there is an increasing need for comprehensive analyses of multiple phenotypes to provide multidimensional information. Here we developed an automated, high-throughput computer imaging system for quantifying multiple Caenorhabditis elegans phenotypes. Our imaging system is composed of a microscope equipped with a digital camera and a motorized stage connected to a computer running the QuantWorm software package. Currently, the software package contains one data acquisition module and four image analysis programs: WormLifespan, WormLocomotion, WormLength, and WormEgg. The data acquisition module collects images and videos. The WormLifespan software counts the number of moving worms by using two time-lapse images; the WormLocomotion software computes the velocity of moving worms; the WormLength software measures worm body size; and the WormEgg software counts the number of eggs. To evaluate the performance of our software, we compared the results of our software with manual measurements. We then demonstrated the application of the QuantWorm software in a drug assay and a genetic assay. Overall, the QuantWorm software provided accurate measurements at a high speed. Software source code, executable programs, and sample images are available at www.quantworm.org. Our software package has several advantages over current imaging systems for C. elegans. It is an all-in-one package for quantifying multiple phenotypes. The QuantWorm software is written in Java and its source code is freely available, so it does not require use of commercial software or libraries. It can be run on multiple platforms and easily customized to cope with new methods and requirements.\n\nA Study of Visualization for Mathematics Education\n\nScience.gov (United States)\n\nDaugherty, Sarah C.\n\n2008-01-01\n\nGraphical representations such as figures, illustrations, and diagrams play a critical role in mathematics and they are equally important in mathematics education. However, graphical representations in mathematics textbooks are static, Le. they are used to illustrate only a specific example or a limited set. of examples. By using computer software to visualize mathematical principles, virtually there is no limit to the number of specific cases and examples that can be demonstrated. However, we have not seen widespread adoption of visualization software in mathematics education. There are currently a number of software packages that provide visualization of mathematics for research and also software packages specifically developed for mathematics education. We conducted a survey of mathematics visualization software packages, summarized their features and user bases, and analyzed their limitations. In this survey, we focused on evaluating the software packages for their use with mathematical subjects adopted by institutions of secondary education in the United States (middle schools and high schools), including algebra, geometry, trigonometry, and calculus. We found that cost, complexity, and lack of flexibility are the major factors that hinder the widespread use of mathematics visualization software in education.\n\nAn Ada Linear-Algebra Software Package Modeled After HAL/S\n\nScience.gov (United States)\n\nKlumpp, Allan R.; Lawson, Charles L.\n\n1990-01-01\n\nNew avionics software written more easily. Software package extends Ada programming language to include linear-algebra capabilities similar to those of HAL/S programming language. Designed for such avionics applications as Space Station flight software. In addition to built-in functions of HAL/S, package incorporates quaternion functions used in Space Shuttle and Galileo projects and routines from LINPAK solving systems of equations involving general square matrices. Contains two generic programs: one for floating-point computations and one for integer computations. Written on IBM/AT personal computer running under PC DOS, v.3.1.\n\nldr: An R Software Package for Likelihood-Based Su?cient Dimension Reduction\n\nDirectory of Open Access Journals (Sweden)\n\nKofi Placid Adragni\n\n2014-11-01\n\nFull Text Available In regression settings, a su?cient dimension reduction (SDR method seeks the core information in a p-vector predictor that completely captures its relationship with a response. The reduced predictor may reside in a lower dimension d < p, improving ability to visualize data and predict future observations, and mitigating dimensionality issues when carrying out further analysis. We introduce ldr, a new R software package that implements three recently proposed likelihood-based methods for SDR: covariance reduction, likelihood acquired directions, and principal fitted components. All three methods reduce the dimensionality of the data by pro jection into lower dimensional subspaces. The package also implements a variable screening method built upon principal ?tted components which makes use of ?exible basis functions to capture the dependencies between the predictors and the response. Examples are given to demonstrate likelihood-based SDR analyses using ldr, including estimation of the dimension of reduction subspaces and selection of basis functions. The ldr package provides a framework that we hope to grow into a comprehensive library of likelihood-based SDR methodologies.\n\n'tomo_display' and 'vol_tools': IDL VM Packages for Tomography Data Reconstruction, Processing, and Visualization\n\nScience.gov (United States)\n\nRivers, M. L.; Gualda, G. A.\n\n2009-05-01\n\nOne of the challenges in tomography is the availability of suitable software for image processing and analysis in 3D. We present here 'tomo_display' and 'vol_tools', two packages created in IDL that enable reconstruction, processing, and visualization of tomographic data. They complement in many ways the capabilities offered by Blob3D (Ketcham 2005 - Geosphere, 1: 32-41, DOI: 10.1130/GES00001.1) and, in combination, allow users without programming knowledge to perform all steps necessary to obtain qualitative and quantitative information using tomographic data. The package 'tomo_display' was created and is maintained by Mark Rivers. It allows the user to: (1) preprocess and reconstruct parallel beam tomographic data, including removal of anomalous pixels, ring artifact reduction, and automated determination of the rotation center, (2) visualization of both raw and reconstructed data, either as individual frames, or as a series of sequential frames. The package 'vol_tools' consists of a series of small programs created and maintained by Guilherme Gualda to perform specific tasks not included in other packages. Existing modules include simple tools for cropping volumes, generating histograms of intensity, sample volume measurement (useful for porous samples like pumice), and computation of volume differences (for differential absorption tomography). The module 'vol_animate' can be used to generate 3D animations using rendered isosurfaces around objects. Both packages use the same NetCDF format '.volume' files created using code written by Mark Rivers. Currently, only 16-bit integer volumes are created and read by the packages, but floating point and 8-bit data can easily be stored in the NetCDF format as well. A simple GUI to convert sequences of tiffs into '.volume' files is available within 'vol_tools'. Both 'tomo_display' and 'vol_tools' include options to (1) generate onscreen output that allows for dynamic visualization in 3D, (2) save sequences of tiffs to disk\n\nWestern aeronautical test range real-time graphics software package MAGIC\n\nScience.gov (United States)\n\nMalone, Jacqueline C.; Moore, Archie L.\n\n1988-01-01\n\nThe master graphics interactive console (MAGIC) software package used on the Western Aeronautical Test Range (WATR) of the NASA Ames Research Center is described. MAGIC is a resident real-time research tool available to flight researchers-scientists in the NASA mission control centers of the WATR at the Dryden Flight Research Facility at Edwards, California. The hardware configuration and capabilities of the real-time software package are also discussed.\n\nSoftware and package applicating for network meta-analysis: A usage-based comparative study.\n\nScience.gov (United States)\n\nXu, Chang; Niu, Yuming; Wu, Junyi; Gu, Huiyun; Zhang, Chao\n\n2017-12-21\n\nTo compare and analyze the characteristics and functions of software applications for network meta-analysis (NMA). PubMed, EMbase, The Cochrane Library, the official websites of Bayesian inference Using Gibbs Sampling (BUGS), Stata and R, and Google were searched to collect the software and packages for performing NMA; software and packages published up to March 2016 were included. After collecting the software, packages, and their user guides, we used the software and packages to calculate a typical example. All characteristics, functions, and computed results were compared and analyzed. Ten types of software were included, including programming and non-programming software. They were developed mainly based on Bayesian or frequentist theory. Most types of software have the characteristics of easy operation, easy mastery, exact calculation, or excellent graphing. However, there was no single software that performed accurate calculations with superior graphing; this could only be achieved through the combination of two or more types of software. This study suggests that the user should choose the appropriate software according to personal programming basis, operational habits, and financial ability. Then, the choice of the combination of BUGS and R (or Stata) software to perform the NMA is considered. Â© 2017 Chinese Cochrane Center, West China Hospital of Sichuan University and John Wiley & Sons Australia, Ltd.\n\nSPADE - software package to aid diffraction experiments\n\nInternational Nuclear Information System (INIS)\n\nFarren, J.; Giltrap, J.W.\n\n1978-10-01\n\nA software package is described which enables the DEC PDP-11/03 microcomputer to execute several different X-ray diffraction experiments and other similar experiments where stepper motors are driven and data is gathered and processed in real time. (author)\n\nAdvancements to Visualization Control System (VCS, part of UV-CDAT), a Visualization Package Designed for Climate Scientists\n\nScience.gov (United States)\n\nLipsa, D.; Chaudhary, A.; Williams, D. N.; Doutriaux, C.; Jhaveri, S.\n\n2017-12-01\n\nClimate Data Analysis Tools (UV-CDAT, https://uvcdat.llnl.gov) is a data analysis and visualization software package developed at Lawrence Livermore National Laboratory and designed for climate scientists. Core components of UV-CDAT include: 1) Community Data Management System (CDMS) which provides I/O support and a data model for climate data;2) CDAT Utilities (GenUtil) that processes data using spatial and temporal averaging and statistic functions; and 3) Visualization Control System (VCS) for interactive visualization of the data. VCS is a Python visualization package primarily built for climate scientists, however, because of its generality and breadth of functionality, it can be a useful tool to other scientific applications. VCS provides 1D, 2D and 3D visualization functions such as scatter plot and line graphs for 1d data, boxfill, meshfill, isofill, isoline for 2d scalar data, vector glyphs and streamlines for 2d vector data and 3d_scalar and 3d_vector for 3d data. Specifically for climate data our plotting routines include projections, Skew-T plots and Taylor diagrams. While VCS provided a user-friendly API, the previous implementation of VCS relied on slow performing vector graphics (Cairo) backend which is suitable for smaller dataset and non-interactive graphics. LLNL and Kitware team has added a new backend to VCS that uses the Visualization Toolkit (VTK) as its visualization backend. VTK is one of the most popular open source, multi-platform scientific visualization library written in C++. Its use of OpenGL and pipeline processing architecture results in a high performant VCS library. Its multitude of available data formats and visualization algorithms results in easy adoption of new visualization methods and new data formats in VCS. In this presentation, we describe recent contributions to VCS that includes new visualization plots, continuous integration testing using Conda and CircleCI, tutorials and examples using Jupyter notebooks as well as\n\nEvaluation and selection of open-source EMR software packages based on integrated AHP and TOPSIS.\n\nScience.gov (United States)\n\nZaidan, A A; Zaidan, B B; Al-Haiqi, Ahmed; Kiah, M L M; Hussain, Muzammil; Abdulnabi, Mohamed\n\n2015-02-01\n\nEvaluating and selecting software packages that meet the requirements of an organization are difficult aspects of software engineering process. Selecting the wrong open-source EMR software package can be costly and may adversely affect business processes and functioning of the organization. This study aims to evaluate and select open-source EMR software packages based on multi-criteria decision-making. A hands-on study was performed and a set of open-source EMR software packages were implemented locally on separate virtual machines to examine the systems more closely. Several measures as evaluation basis were specified, and the systems were selected based a set of metric outcomes using Integrated Analytic Hierarchy Process (AHP) and TOPSIS. The experimental results showed that GNUmed and OpenEMR software can provide better basis on ranking score records than other open-source EMR software packages. Copyright Â© 2014 Elsevier Inc. All rights reserved.\n\nIDES: Interactive Data Entry System: a generalized data acquisition software package\n\nInternational Nuclear Information System (INIS)\n\nGasser, S.B.\n\n1980-04-01\n\nThe Interactive Data Entry System (IDES) is a software package which greatly assists in designing and storing forms to be used for the directed acquisition of data. Objective of this package is to provide a viable man/machine interface to any comprehensive data base. This report provides a technical description of the software and can be used as a user's manual\n\nWebStruct and VisualStruct: web interfaces and visualization for Structure software implemented in a cluster environment\n\nDirectory of Open Access Journals (Sweden)\n\nJayashree B.\n\n2008-03-01\n\nFull Text Available Structure, is a widely used software tool to investigate population genetic structure with multi-locus genotyping data. The software uses an iterative algorithm to group individuals into âKâ clusters, representing possibly K genetically distinct subpopulations. The serial implementation of this programme is processor-intensive even with small datasets. We describe an implementation of the program within a parallel framework. Speedup was achieved by running different replicates and values of K on each node of the cluster. A web-based user-oriented GUI has been implemented in PHP, through which the user can specify input parameters for the programme. The number of processors to be used can be specified in the background command. A web-based visualization tool âVisualstructâ, written in PHP (HTML and Java script embedded, allows for the graphical display of population clusters output from Structure, where each individual may be visualized as a line segment with K colors defining its possible genomic composition with respect to the K genetic sub-populations. The advantage over available programs is in the increased number of individuals that can be visualized. The analyses of real datasets indicate a speedup of up to four, when comparing the speed of execution on clusters of eight processors with the speed of execution on one desktop. The software package is freely available to interested users upon request.\n\nWebStruct and VisualStruct: Web interfaces and visualization for Structure software implemented in a cluster environment.\n\nScience.gov (United States)\n\nJayashree, B; Rajgopal, S; Hoisington, D; Prasanth, V P; Chandra, S\n\n2008-09-24\n\nStructure, is a widely used software tool to investigate population genetic structure with multi-locus genotyping data. The software uses an iterative algorithm to group individuals into \"K\" clusters, representing possibly K genetically distinct subpopulations. The serial implementation of this programme is processor-intensive even with small datasets. We describe an implementation of the program within a parallel framework. Speedup was achieved by running different replicates and values of K on each node of the cluster. A web-based user-oriented GUI has been implemented in PHP, through which the user can specify input parameters for the programme. The number of processors to be used can be specified in the background command. A web-based visualization tool \"Visualstruct\", written in PHP (HTML and Java script embedded), allows for the graphical display of population clusters output from Structure, where each individual may be visualized as a line segment with K colors defining its possible genomic composition with respect to the K genetic sub-populations. The advantage over available programs is in the increased number of individuals that can be visualized. The analyses of real datasets indicate a speedup of up to four, when comparing the speed of execution on clusters of eight processors with the speed of execution on one desktop. The software package is freely available to interested users upon request.\n\nClosing the loop on improvement: Packaging experience in the Software Engineering Laboratory\n\nScience.gov (United States)\n\nWaligora, Sharon R.; Landis, Linda C.; Doland, Jerry T.\n\n1994-01-01\n\nAs part of its award-winning software process improvement program, the Software Engineering Laboratory (SEL) has developed an effective method for packaging organizational best practices based on real project experience into useful handbooks and training courses. This paper shares the SEL's experience over the past 12 years creating and updating software process handbooks and training courses. It provides cost models and guidelines for successful experience packaging derived from SEL experience.\n\nAn overview of 3D software visualization.\n\nScience.gov (United States)\n\nTeyseyre, Alfredo R; Campo, Marcelo R\n\n2009-01-01\n\nSoftware visualization studies techniques and methods for graphically representing different aspects of software. Its main goal is to enhance, simplify and clarify the mental representation a software engineer has of a computer system. During many years, visualization in 2D space has been actively studied, but in the last decade, researchers have begun to explore new 3D representations for visualizing software. In this article, we present an overview of current research in the area, describing several major aspects like: visual representations, interaction issues, evaluation methods and development tools. We also perform a survey of some representative tools to support different tasks, i.e., software maintenance and comprehension, requirements validation and algorithm animation for educational purposes, among others. Finally, we conclude identifying future research directions.\n\nWriting virtual environments for software visualization\n\nCERN Document Server\n\nJeffery, Clinton\n\n2015-01-01\n\nThis book describes the software for creating networked, 3D multi-user virtual environments that allow users to create and remotely share visualizations of program behavior. The authors cover the major features of collaborative virtual environments and how to program them in a very high level language, and show how visualization can enable important advances in our ability to understand and reduce the costs of maintaining software. The book also examines the application of popular game-like software technologies. Â â¢ Discusses the acquisition of program behavior data to be visualized â¢ Demonstrates the integration of multiple 2D and 3D dynamic views within a 3Dscene â¢ Presents the network messaging capabilities to share those visualizations\n\nComparison of four software packages applied to a scattering problem\n\nDEFF Research Database (Denmark)\n\nAlbertsen, Niels Christian; Chesneaux, Jean-Marie; Christiansen, SÃ¸ren\n\n1999-01-01\n\nWe investigate characteristic features of four different software packages by applying them to the numerical solution of a non-trivial physical problem in computer simulation, viz., scattering of waves from a sinusoidal boundary. The numerical method used is based on boundary collocation. This le......We investigate characteristic features of four different software packages by applying them to the numerical solution of a non-trivial physical problem in computer simulation, viz., scattering of waves from a sinusoidal boundary. The numerical method used is based on boundary collocation...\n\nImproving package structure of object-oriented software using multi-objective optimization and weighted class connections\n\nDirectory of Open Access Journals (Sweden)\n\nAmarjeet\n\n2017-07-01\n\nFull Text Available The software maintenance activities performed without following the original design decisions about the package structure usually deteriorate the quality of software modularization, leading to decay of the quality of the system. One of the main reasons for such structural deterioration is inappropriate grouping of source code classes in software packages. To improve such grouping/modular-structure, previous researchers formulated the software remodularization problem as an optimization problem and solved it using search-based meta-heuristic techniques. These optimization approaches aimed at improving the quality metrics values of the structure without considering the original package design decisions, often resulting into a totally new software modularization. The entirely changed software modularization becomes costly to realize as well as difficult to understand for the developers/maintainers. To alleviate this issue, we propose a multi-objective optimization approach to improve the modularization quality of an object-oriented system with minimum possible movement of classes between existing packages of original software modularization. The optimization is performed using NSGA-II, a widely-accepted multi-objective evolutionary algorithm. In order to ensure minimum modification of original package structure, a new approach of computing class relations using weighted strengths has been proposed here. The weights of relations among different classes are computed on the basis of the original package structure. A new objective function has been formulated using these weighted class relations. This objective function drives the optimization process toward better modularization quality simultaneously ensuring preservation of original structure. To evaluate the results of the proposed approach, a series of experiments are conducted over four real-worlds and two random software applications. The experimental results clearly indicate the effectiveness\n\nConsys Linear Control System Design Software Package\n\nInternational Nuclear Information System (INIS)\n\nDiamantidis, Z.\n\n1987-01-01\n\nThis package is created in order to help engineers, researchers, students and all who work on linear control systems. The software includes all time and frequency domain analysises, spectral analysises and networks, active filters and regulators design aids. The programmes are written on Hewlett Packard computer in Basic 4.0\n\nSmile Analyzer: A Software Package for Analyzing the Characteristics of the Speech and Smile\n\nDirectory of Open Access Journals (Sweden)\n\nRoozbeh Rashed\n\n2013-01-01\n\nFull Text Available Taking into account the factors related to lip-tooth relationships in orthodontic diagnosis and treatment planning is of prime importance. Manual quantitative analysis of facial parameters on photographs during smile and speech is a difficult and time-consuming job. Since there is no comprehensive and user-friendly software package, we developed a software program called \"Smile Analyzer\" in the Department of Orthodontics of Mashhad Faculty of Dentistry for measuring the parameters related to lip-tooth relationships and other facial landmarks on the photographs taken during various facial expressions. The software was designed using visual basic. NET and the ADO. NET was used for developing its Microsoft Access database. The program runs on Microsoft Windows. It is capable of analyzing many parameters or variables in many patients' photographs, although 19 more common variables are previously defined as a default list of variables. When all variables are measured or calculated, a report can be generated and saved in either PDF or MS Excel format. Data are readily transferable to statistical software like SPSS for Windows. Â\n\nSmile Analyzer: A Software Package for Analyzing the Characteristics of the Speech and Smile\n\nDirectory of Open Access Journals (Sweden)\n\nFarzin Heravi\n\n2012-09-01\n\nFull Text Available Taking into account the factors related to lip-tooth relationships in orthodontic diagnosis and treatment planning is of prime importance. Manual quantitative analysis of facial parameters on photographs during smile and speech is a difficult and time-consuming job. Since there is no comprehensive and user-friendly software package, we developed a software program called \"Smile Analyzer\" in the Department of Orthodontics of Mashhad Faculty of Dentistry for measuring the parameters related to lip-tooth relationships and other facial landmarks on the photographs taken during various facial expressions. The software was designed using visual basic. NET and the ADO. NET was used for developing its Microsoft Access database. The program runs on Microsoft Windows. It is capable of analyzing many parameters or variables in many patients' photographs, although 19 more common variables are previously defined as a default list of variables. When all variables are measured or calculated, a report can be generated and saved in either PDF or MS Excel format. Data are readily transferable to statistical software like SPSS for Windows.\n\nA comparison of six software packages for evaluation of solid lung nodules using semi-automated volumetry: What is the minimum increase in size to detect growth in repeated CT examinations\n\nInternational Nuclear Information System (INIS)\n\nHoop, Bartjan de; Gietema, Hester; Prokop, Mathias; Ginneken, Bram van; Zanen, Pieter; Groenewegen, Gerard\n\n2009-01-01\n\nWe compared interexamination variability of CT lung nodule volumetry with six currently available semi-automated software packages to determine the minimum change needed to detect the growth of solid lung nodules. We had ethics committee approval. To simulate a follow-up examination with zero growth, we performed two low-dose unenhanced CT scans in 20 patients referred for pulmonary metastases. Between examinations, patients got off and on the table. Volumes of all pulmonary nodules were determined on both examinations using six nodule evaluation software packages. Variability (upper limit of the 95% confidence interval of the Bland-Altman plot) was calculated for nodules for which segmentation was visually rated as adequate. We evaluated 214 nodules (mean diameter 10.9 mm, range 3.3 mm-30.0 mm). Software packages provided adequate segmentation in 71% to 86% of nodules (p < 0.001). In case of adequate segmentation, variability in volumetry between scans ranged from 16.4% to 22.3% for the various software packages. Variability with five to six software packages was significantly less for nodules â¥8 mm in diameter (range 12.9%-17.1%) than for nodules <8 mm (range 18.5%-25.6%). Segmented volumes of each package were compared to each of the other packages. Systematic volume differences were detected in 11/15 comparisons. This hampers comparison of nodule volumes between software packages. (orig.)\n\nVertical bone measurements from cone beam computed tomography images using different software packages\n\nInternational Nuclear Information System (INIS)\n\nVasconcelos, Taruska Ventorini; Neves, Frederico Sampaio; Moraes, Livia Almeida Bueno; Freitas, Deborah Queiroz\n\n2015-01-01\n\nThis article aimed at comparing the accuracy of linear measurement tools of different commercial software packages. Eight fully edentulous dry mandibles were selected for this study. Incisor, canine, premolar, first molar and second molar regions were selected. Cone beam computed tomography (CBCT) images were obtained with i-CAT Next Generation. Linear bone measurements were performed by one observer on the cross-sectional images using three different software packages: XoranCatÂ®, OnDemand3DÂ® and KDIS3DÂ®, all able to assess DICOM images. In addition, 25% of the sample was reevaluated for the purpose of reproducibility. The mandibles were sectioned to obtain the gold standard for each region. Intraclass coefficients (ICC) were calculated to examine the agreement between the two periods of evaluation; the one-way analysis of variance performed with the post-hoc Dunnett test was used to compare each of the software-derived measurements with the gold standard. The ICC values were excellent for all software packages. The least difference between the software-derived measurements and the gold standard was obtained with the OnDemand3D and KDIS3D (â0.11 and â0.14 mm, respectively), and the greatest, with the XoranCAT (+0.25 mm). However, there was no statistical significant difference between the measurements obtained with the different software packages and the gold standard (p > 0.05). In conclusion, linear bone measurements were not influenced by the software package used to reconstruct the image from CBCT DICOM data. (author)\n\nVertical bone measurements from cone beam computed tomography images using different software packages\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nVasconcelos, Taruska Ventorini; Neves, Frederico Sampaio; Moraes, Livia Almeida Bueno; Freitas, Deborah Queiroz, E-mail: tataventorini@hotmail.com [Universidade Estadual de Campinas (UNICAMP), Piracicaba, SP (Brazil). Faculdade de Odontologia\n\n2015-03-01\n\nThis article aimed at comparing the accuracy of linear measurement tools of different commercial software packages. Eight fully edentulous dry mandibles were selected for this study. Incisor, canine, premolar, first molar and second molar regions were selected. Cone beam computed tomography (CBCT) images were obtained with i-CAT Next Generation. Linear bone measurements were performed by one observer on the cross-sectional images using three different software packages: XoranCatÂ®, OnDemand3DÂ® and KDIS3DÂ®, all able to assess DICOM images. In addition, 25% of the sample was reevaluated for the purpose of reproducibility. The mandibles were sectioned to obtain the gold standard for each region. Intraclass coefficients (ICC) were calculated to examine the agreement between the two periods of evaluation; the one-way analysis of variance performed with the post-hoc Dunnett test was used to compare each of the software-derived measurements with the gold standard. The ICC values were excellent for all software packages. The least difference between the software-derived measurements and the gold standard was obtained with the OnDemand3D and KDIS3D (â0.11 and â0.14 mm, respectively), and the greatest, with the XoranCAT (+0.25 mm). However, there was no statistical significant difference between the measurements obtained with the different software packages and the gold standard (p > 0.05). In conclusion, linear bone measurements were not influenced by the software package used to reconstruct the image from CBCT DICOM data. (author)\n\nA User-Friendly Software Package for HIFU Simulation\n\nScience.gov (United States)\n\nSoneson, Joshua E.\n\n2009-04-01\n\nA freely-distributed, MATLAB (The Mathworks, Inc., Natick, MA)-based software package for simulating axisymmetric high-intensity focused ultrasound (HIFU) beams and their heating effects is discussed. The package (HIFU_Simulator) consists of a propagation module which solves the Khokhlov-Zabolotskaya-Kuznetsov (KZK) equation and a heating module which solves Pennes' bioheat transfer (BHT) equation. The pressure, intensity, heating rate, temperature, and thermal dose fields are computed, plotted, the output is released to the MATLAB workspace for further user analysis or postprocessing.\n\nArticle I. Multi-platform Automated Software Building and Packaging\n\nInternational Nuclear Information System (INIS)\n\nRodriguez, A Abad; Gomes Gouveia, V E; Meneses, D; Capannini, F; Aimar, A; Di Meglio, A\n\n2012-01-01\n\nOne of the major goals of the EMI (European Middleware Initiative) project is the integration of several components of the pre-existing middleware (ARC, gLite, UNICORE and dCache) into a single consistent set of packages with uniform distributions and repositories. Those individual middleware projects have been developed in the last decade by tens of development teams and before EMI were all built and tested using different tools and dedicated services. The software, millions of lines of code, is written in several programming languages and supports multiple platforms. Therefore a viable solution ought to be able to build and test applications on multiple programming languages using common dependencies on all selected platforms. It should, in addition, package the resulting software in formats compatible with the popular Linux distributions, such as Fedora and Debian, and store them in repositories from which all EMI software can be accessed and installed in a uniform way. Despite this highly heterogeneous initial situation, a single common solution, with the aim of quickly automating the integration of the middleware products, had to be selected and implemented in a few months after the beginning of the EMI project. Because of the previous knowledge and the short time available in which to provide this common solution, the ETICS service, where the gLite middleware was already built for years, was selected. This contribution describes how the team in charge of providing a common EMI build and packaging infrastructure to the whole project has developed a homogeneous solution for releasing and packaging the EMI components from the initial set of tools used by the earlier middleware projects. An important element of the presentation is the developers experience and feedback on converging on ETICS and on the on-going work in order to finally add more widely used and supported build and packaging solutions of the Linux platforms\n\nFluxVisualizer, a Software to Visualize Fluxes through Metabolic Networks\n\nDirectory of Open Access Journals (Sweden)\n\nTim Daniel Rose\n\n2018-04-01\n\nFull Text Available FluxVisualizer (Version 1.0, 2017, freely available at https://fluxvisualizer.ibgc.cnrs.fr is a software to visualize fluxes values on a scalable vector graphic (SVG representation of a metabolic network by colouring or increasing the width of reaction arrows of the SVG file. FluxVisualizer does not aim to draw metabolic networks but to use a customerâs SVG file allowing him to exploit his representation standards with a minimum of constraints. FluxVisualizer is especially suitable for small to medium size metabolic networks, where a visual representation of the fluxes makes sense. The flux distribution can either be an elementary flux mode (EFM, a flux balance analysis (FBA result or any other flux distribution. It allows the automatic visualization of a series of pathways of the same network as is needed for a set of EFMs. The software is coded in python3 and provides a graphical user interface (GUI and an application programming interface (API. All functionalities of the program can be used from the API and the GUI and allows advanced users to add their own functionalities. The software is able to work with various formats of flux distributions (Metatool, CellNetAnalyzer, COPASI and FAME export files as well as with Excel files. This simple software can save a lot of time when evaluating fluxes simulations on a metabolic network.\n\nDevelopment of 'Enhance reconstruction package' software for whole-body PET\n\nInternational Nuclear Information System (INIS)\n\nMizuta, Tetsuro; Imanishi, Tatsuru; Ishikawa, Akihiro\n\n2011-01-01\n\nWe have developed 'Enhance Reconstruction Package' Software for our whole-body positron emission tomography (PET) Eminence series. This package improves image quality and streamlines the workflow in clinical PET and PET/CT studies. The present paper describes an outline of the applications for data collection, normalization, etc. and also reports some PET images obtained by the software. The signal to noise ratio was optimized in the phantom study, leading to the improvement in image quality. The real time display tool and the remote control tool would make a contribution to enhancement in operability in the routine workflow. (author)\n\nA Characteristics Approach to the Evaluation of Economics Software Packages.\n\nScience.gov (United States)\n\nLumsden, Keith; Scott, Alex\n\n1988-01-01\n\nUtilizes Bloom's Taxonomy to identify elements of teacher and student interest. Depicts the way in which these interests are developed into characteristics for use in analytically evaluating software. Illustrates the use of this evaluating technique by appraising the much used software package \"Running the British Economy.\" (KO)\n\nCOMPUTATIONAL MODELLING OF BUFFETING EFFECTS USING OPENFOAM SOFTWARE PACKAGE\n\nDirectory of Open Access Journals (Sweden)\n\nV. T. Kalugin\n\n2015-01-01\n\nFull Text Available In this paper, the preliminary results of computational modeling of an aircraft with the airbrake deployed are presented. The calculations were performed with OpenFOAM software package. The results outlined are a part of a research project to optimise aircraft performance using a perforated airbrake. Within this stage of the project OpenFOAM software package with hybrid RANS-LES approach was tested in respect to a given configuration of the aircraft, airbrake and then has been compared with the test data. For the worst case the amplitude of the peak force acting on the tail fin can be up to 6 times higher than the average value without airbrake deployed. To reduce unsteady loads acting on the tailfin, perforation of the airbrake was proposed.\n\nPINT, A Modern Software Package for Pulsar Timing\n\nScience.gov (United States)\n\nLuo, Jing; Ransom, Scott M.; Demorest, Paul; Ray, Paul S.; Stovall, Kevin; Jenet, Fredrick; Ellis, Justin; van Haasteren, Rutger; Bachetti, Matteo; NANOGrav PINT developer team\n\n2018-01-01\n\nPulsar timing, first developed decades ago, has provided an extremely wide range of knowledge about our universe. It has been responsible for many important discoveries, such as the discovery of the first exoplanet and the orbital period decay of double neutron star systems. Currently pulsar timing is the leading technique for detecting low frequency (about 10^-9 Hertz) gravitational waves (GW) using an array of pulsars as the detectors. To achieve this goal, high precision pulsar timing data, at about nanoseconds level, is required. Most high precision pulsar timing data are analyzed using the widely adopted software TEMPO/TEMPO2. But for a robust and believable GW detection, it is important to have independent software that can cross-check the result. In this poster we present the new generation pulsar timing software PINT. This package will provide a robust system to cross check high-precision timing results, completely independent of TEMPO and TEMPO2. In addition, PINT is designed to be a package that is easy to extend and modify, through use of flexible code architecture and a modern programming language, Python, with modern technology and libraries.\n\nMaximize Your Investment 10 Key Strategies for Effective Packaged Software Implementations\n\nCERN Document Server\n\nBeaubouef, Grady Brett\n\n2009-01-01\n\nThis is a handbook covering ten principles for packaged software implementations that project managers, business owners, and IT developers should pay attention to. The b"
    }
}