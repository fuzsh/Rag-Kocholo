{
    "id": "dbpedia_3790_1",
    "rank": 8,
    "data": {
        "url": "https://www.confluent.io/learn/real-time-data-and-analytics/",
        "read_more_link": "",
        "language": "en",
        "title": "Real-Time Data & Analytics - The Complete Guide",
        "top_image": "https://cdn.confluent.io/wp-content/uploads/seo-logo-meadow.png",
        "meta_img": "https://cdn.confluent.io/wp-content/uploads/seo-logo-meadow.png",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Real-Time Data & Analytics - The Complete Guide",
        "meta_lang": "en",
        "meta_favicon": "/favicon.ico",
        "meta_site_name": "Confluent",
        "canonical_link": "https://www.confluent.io/learn/real-time-data-and-analytics/",
        "text": "Real-time data (RTD) refers to information that is processed, consumed, and/or acted upon immediately after it's generated. While data processing is not new, real-time data is a newer paradigm that changes how businesses run.\n\nBatch vs Real-Time Data Processing\n\nIn previous years, batch data processing was the norm. Systems had to collect, process, and store large volumes of data as separate functions before data could be utilized for further action. In situations where real-time data or analytics are not needed, batch processing is still a viable process.\n\nIn contrast, real-time data processing (or streaming data) can collect, store, and analyze continuously, making data readily available to the end-user as soon as it's generated with no delay.\n\nWhile databases and offline data analysis remain valid tools, the need for real-time data has increased exponentially with the advent of modern applications. After all, the world isn’t a batch process - it runs in real-time.\n\nA customer requests a ride from Uber. A thief uses a stolen credit card. A patient’s blood pressure drops. A server fails in a data center. All of these are considered real-time data (also knows as events.\n\nWe ingest real-time data into an event log, which captures a sequence of events as they happen. It is natural to imagine the data as a stream of events flowing in time. A data stream is an abstraction built on this analogy. The purpose of streaming is the ability to take on events in-flight, without waiting for that information to be stored first. This is the largest differentiation between real-time streaming and batch processing, and allows for real-time data analytics at scale.\n\nThe basic principles of real-time data processing are simple. We distinguish between producers and consumers of data. Producers are the sources of data. Consumers are the services that use the data. In modern streaming systems, producers send messages to a message broker. The broker assigns each message to a topic and publishes it. A topic is simply a queue of related messages. Consumers can then subscribe to different topics that interest them. This is often called the publish and subscribe model (also referred to as pub-sub). It works almost like a Twitter feed.\n\nAs usual, the devil is in the detail. We want our system to be scalable and fault-tolerant. We want to have high throughput and low latency. We want an immutable record of our data, but we also want flexibility in how we use the data in our applications. We want the right architecture and the right performance guarantees. This is where Apache Kafka's stream processing technology excels."
    }
}