{
    "id": "wrong_mix_random_spouse_00126_2",
    "rank": 56,
    "data": {
        "url": "https://bookdown.org/Maxine/data-science-readings/what-is-data-science.html",
        "read_more_link": "",
        "language": "en",
        "title": "Readings in applied data science",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://bookdown.org/Maxine/data-science-readings/images/archetypes.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Qiushi Yan"
        ],
        "publish_date": "2019-11-21T00:00:00",
        "summary": "",
        "meta_description": "1 What is Data Science | Readings in applied data science",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "1.1.1 Data Science vs. Statistics\n\nThe author first starts to distinguish data science from traditional statistics. Yet 3 commonly used indicators are discredited:\n\n“Big data” is not a credible criterion for meaningful distinction between statistics and data science, for both historical and scientific reasons, viz:\n\nThe very term “statistics” was coined at the beginning of modern efforts to compile census data, roughly the size of today’s big data\n\nStatisticians have long since delved into large databases, and come up with sufficient measures\n\nAlthough some would tout “new skills” on the part of data scientists, that is another “big data” meme cloaked in another term.\n\nData science programs doesn’t necessarily guide one to a satisfying job, comapared with statistics. Even it does, a data science master degree cannot exempt you from various constraints in real workplace\n\nSo, is there any solid case for establishing an new entity called “data science” ? David proposes that data science would be a true science, an enlargement of traditional academic statistics. And the underlying motivation is intellectual rather than commerical. In the next 50 years, scientific publicatiosn in various disciplines will become a body of data that we can analyze and study, and the opportunity to improve the accuracy and validity of all science relies upon this would-be field: data science.\n\n1.1.2 Review on the concept\n\nBased on the timeline, the author then organizes insights that have been published over the years about data science, as shown below (Tukey 1962):\n\nAll in all I have come to feel that my central interest is in data analysis, which I take to include, among other things: procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data\n\nTukey identified four driving forces in the new science:\n\nThe formal theories of statistics\n\nAccelerating developments in computers and display devices\n\nThe challenge, in many fields, of more and ever larger bodies of data\n\nThe emphasis on quantification in an ever wider variety of disciplines\n\nLet’s spend a minute admiring Tukey’s prophecy…\n\nAmong other things, Tukey also pointed out that:\n\n…data analysis is a very difficult field. It must adapt itself to what people can and need to do with data. In the sense that biology is more complex than physics, and the behavioral sciences are more complex than either, it is likely that the general problems of data analysis are more complex than those of all three. It is too much to ask for close and effective guidance for data analysis from any highly formalized structure, either now or in the near future.\n\nData analysis can gain much from formal statistics, but only if the connection is kept adequately loose.\n\nJohn Chambers presented a choice between “greater” or “lesser” statistics. He argued (Chambers 1993):\n\nThe statistics profession faces a choice in its future research between continuing concentration on traditional topics—based largely on data analysis supported by mathematical statistics—and a broader viewpoint—based on an inclusive concept of learning from data. The latter course presents severe challenges as well as exciting opportunities. The former risks seeing statistics become increasingly marginal…\n\nC. F. Jeff Wu characterized statistical work as a trilogy of data collection, data modeling and analysis, and decision making, and called for courses outside out the statistics department.\n\nWilliam S. Cleveland put forward 6 foci of data science, which offered a great conceptual framework to study the filed even from today’s perspective (Cleveland 2001):\n\nMultidisciplinary investigations (25%)\n\nModels and Methods for Data (20%)\n\nComputing with Data (15%)\n\nPedagogy (15%)\n\nTool Evaluation (5%)\n\nTheory (20%)\n\nUC Berkeley statistician Leo Breiman brought his “two modeling cultures theory” into the exhortation. He asserted (Breiman and others 2001):\n\nThere are two goals in analyzing the data:\n\nPrediction: To be able to predict what the responses are going to be to future input variables;\n\n[Inference]: To [infer] how nature is associating the response variables to the input variables.\n\nProceeding from this basis, Brieman thought that the prdiction emphasis can be described as “predictive modeling” culture\", which lay stress on accuracy of prediction made by different algorithm on various datasets. But this culture, according to his estimation, is only practiced by 2% of academic statisticians.\n\n“Generative modeling culture” corresponds to the latter inference emphasis, and accounted for 98% statistical practices. Brienman said:\n\nIf our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on [generative] models\n\nFrom today’s standpoint, Breiman’s opinions is fairly justified by reality. But why? (Donoho 2017) thinks the Common Task Framework played a key role here.\n\nAn instance of the CTF has these ingredients( I actually have never heard the term before. To my mind, it’s just like a usual kaggle contest or a data visualization challenge, yet may not subjected ot choosing the “best” machine learning model or plot):\n\nA publicly available training dataset involving, for each observation, a list of (possibly many) feature measurements, and a class label for that observation.\n\nSet of enrolled competitors whose common task is to infer a class prediction rule from the training data.\n\nA scoring referee, to which competitors can submit their prediction rule. The referee runs the prediction rule against a testing dataset, which is sequestered behind a Chinese wall. The referee objectively and automatically reports the score (prediction accuracy) achieved by the submitted rule.\n\nThe synergy of minimizing prediction error with CTF is worth noting. This combination leads directly to a total focus on optimization of empirical performance, allows large numbers of researchers to compete at any given common task challenge, and allows for efficient and unemotional judging of challenge winners.\n\n1.1.6 Conclusion\n\nEach proposed notion of data science involves some enlargement of academic statistics and machine learning. The “GDS” variant specifically discussed in this article derives from insights about data analysis and modeling stretching back decades. In this variant, the core motivation for the expansion to data science is intellectual. In the future, there may be great industrial demand for the skills inculcated by GDS; however, the core questions which drive the field are scientific, not industrial.\n\nGDS(initialtive for greater data science) proposes that data science is the science of learning from data; it studies the methods involved in the analysis and processing of data and proposes technology to improve methods in an evidence-based manner. The scope and impact of this science will expand enormously in coming decades as scientific data and data about science itself become ubiquitously available.\n\nSociety already spends tens of billions of dollars yearly on scientific research, and much of that research takes place at universities. GDS inherently works to understand and improve the validity of the conclusions produced by university research, and can play a key role in all campuses where data analysis and modeling are major activities.\n\n1.2.1 3 Archetypes\n\nAccording to the responses, we can see analysts generally fall into 3 archetypes: hacker, scripter and application user.\n\nHackers are faced with the most diverse and complex tasks. They are most literate in terms of programming and thus rarely ask IT staffs fro help. More oftern than not, hackers master more than three languages, R / Matlab for analysis, Python, Perl as an scripting language, and SQL for queries.\n\nI guess for now Python has gained ground also as a data analysis language, and Matlab is less popular among analysts doing “practical” analysis, but more frquently used in labs of nature science.\n\nAlso note that with their ability to collect, manipulate data, some hackers could be in charge of managing the data warehouse of the company, and dealing with large datasets. In constrast, they perform less statistical models, and spend more time in early-stage analytic activities prior to modeling, if any.\n\nScripters take care of advanced modeling and use a software package such as R or Matlab extensively. They are less proficient when parsing log files or scraping data off the web, and the data susceptible for modeling are often prepared by IT staff.\n\nApplication user prefer operations done in a spreadsheet( Mostly in Excel ), or other analysis application (e.g., SAS / JMP, SPSS, etc.). Data are also pulled out from several relationald databases prior to their work. They typically worked on smaller datasets than other gorups, advanced application users may wrote scripts using an embedded language such as Visual Basic.\n\nTo my mind, application users dipicted here seem to be titled “data analysts” for historical reasons, and there is little case for keeping such a position when there are already hackers and scripters. Perhaps they were traditional bussiness people in charge of analysis or accountants, so they are most comforatble with Microsoft Excel or SPSS. As the “big data” meme started to present itself, all of a sudden their enterprise felr it imperative to set up a “data scientist / analyst” position to keep up with this new trend. Yet I doubt if this archetype could still survive when graduates from data science related master programs flood the talent market.\n\n1.2.2 Analysts within organization\n\nAnalysts interact closely with IT staff to complete aspects of theire job. For IT staff, his relationship includes data ingesting and acquiring, operationalizing recurring workflows, and serve as a source of documentation when analysts, say, con’t figure out how to wirte a complex SQL statement.\n\nThis reliance on IT staff was particularly true in organizations where data was distributed across many different data sources. Hackers were most likely to use the IT team explicitly for this function, as they were more likely to access data directly from the warehouse. Scripters and application users relied on this function implicitly when receiving data from members of IT.\n\nAnother thread of this topic is distributed data, which are generated from multiple departments of the enterprise. They are often stored in various databases and formats. adding to the diffculty of intergrating them.\n\nWhen analysis is finished, analysts typically shared static reports in the form of template documents. In some cases, reports could be interactive dashboards that enabled end users to filter or modify statistics computed. It’s not hard to imagine consumers of the report often give a blurred image of what they want, and hardly could analysts translate them into practical data problems.\n\nWhen it comes to collaboration, it is an exception rather than the rule for analysts. They do share some central repository data processing scriptes are kept to oneself as a rule. Ont the other hand, final reports in the form of charts or model summary are commonly shared among analytsts in planning meeting or presentations. These reports, however, are rarely parametrizable or interactive.\n\n(2012) identifies three impediemnts to collaboration:\n\nthe diversity of tools and programming languages\n\nfinding a script or inter- mediate data product someone else produced was often more time- consumingthanwritingthescriptfromscratch\n\nmany analysis process are “ad hoc”, “experimental”\n\n1.2.3 Challenges\n\n(2012) identified five high-level tasks in the workflow and challenges within each of them.\n\nDiscovering : As mentioned in 1.2.2, since data are often distributed across multiple databases and sources, finding the exact data sheet or file needed can be time-consuming, not to mention that some analysts only have restricted access to the data warehhouse. Another problem is field definitions, these definitions were often missing in relational databases and non-existent in other types of data stores.\n\nWranling: Many analysts reported parsing, ingesting semi-structured data(i.e., log files, block data ). Another difficulty is integrating the data, after analysts manage to find them in databases. Sometimes identifiers are missing or encoded inconsistantly in some databases, and sometimes there is no column than could be an identifier.\n\nProfiling : Many analysts (22 / 35) reports issues dealing with missing data and heterogeneous data in a column. When detecting outliers, there is no general agreement between visualization and traditional staistical methods.\n\nModeling: The biggest challenge in constructing an model according to respondents are feature selection, whether to choose a set of variables, which to transfrom and how to transform.\n\nThere is a great book on feature engineering and selectin by Max Kuhn and Kjell Johnson: Feature Engineering and Selection: A Practical Approach for Predictive Models\n\nMost repondents also pointed to the scalibility of existing analysis and visualization tools. Hackers are less limited by large amounts of data, obviously, but hackers were often limited by the types of analysis they could run because useful models or algorithms did not have available parallelized implementations. Visualizing model results is another pain point, analysts using more advanced machine learning methods (14/35) expressed a desire for visualization tools to help explore these models and visualize their output.\n\nR’s package broom (Robinson and Hayes 2019) are desgined to facilitate modeling diagnosis, visualization, etc. tidymodels (Kuhn and Wickham 2019) contains a burgeoning list of such packages.\n\nReporing: The two most-cited challenges in reporoting were communicating assumptions and building interactive reports. Documentation that should have been provided alongside the report are often missing or poorly written. Even when assumptions were tracked, they were often treated as footnotes instead of first-class results. Moreover, analysts complained that reports were too inflexible and did not allow interactive verification or sensitivity analysis."
    }
}