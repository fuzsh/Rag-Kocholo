{
    "id": "dbpedia_5735_0",
    "rank": 20,
    "data": {
        "url": "https://pingu98.wordpress.com/category/technology/",
        "read_more_link": "",
        "language": "en",
        "title": "James Devine's Blog",
        "top_image": "https://secure.gravatar.com/blavatar/11508a282074753b48a92b094824134a2deb4549c45d5ba3a4c981e7610f7220?s=200&ts=1723763387",
        "meta_img": "https://secure.gravatar.com/blavatar/11508a282074753b48a92b094824134a2deb4549c45d5ba3a4c981e7610f7220?s=200&ts=1723763387",
        "images": [
            "https://pingu98.wordpress.com/wp-content/uploads/2024/07/cheap_optical_computer-1.png?w=1024",
            "https://pingu98.wordpress.com/wp-content/uploads/2023/05/slide1-edited.png",
            "https://pingu98.wordpress.com/wp-content/uploads/2022/09/slide1-edited.jpeg",
            "https://pingu98.wordpress.com/wp-content/uploads/2022/04/slide1.png?w=720",
            "https://pingu98.wordpress.com/wp-content/uploads/2022/05/screenshot-2022-05-16-at-13.17.54.png?w=966",
            "https://pingu98.wordpress.com/wp-content/uploads/2022/05/screenshot-2022-05-16-at-13.53.02.png?w=1024",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/11/20080929-0001.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/11/1440px-chenrezig_sand_mandala.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/11/20080929-0016.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/11/untitled-diagram.png",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/11/20081012-0002.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/11/20080926-0002.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/11/20081003-0003-e1572802138372.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/11/20081003-0006-e1572802779204.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/04/whatgoeswhere.png",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/04/stack-for-fpga.png",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/04/hx8kdemo_tb.png",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/04/ice40hx8k-b-evn.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/04/upduino.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/04/2018-02-07t14_43_28.436z-blackice-top.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2019/04/picsoc.png",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170723_150814.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170722_195429.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170722_195446.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170722_195419.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170722_195436.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170722_191721.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170722_195434.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170722_195339.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2017/07/20170722_195356.jpg",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/08/2012-08-05-15-09-471.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/08/2012-08-05-15-08-161.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/08/2012-08-05-15-08-421.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/08/2012-08-05-15-09-291.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/08/2012-08-05-15-08-531-e1344207818215.jpg?w=225",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/08/2012-08-05-15-09-011-e1344207711512.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/08/2012-08-05-15-09-061.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/03/photo1214.jpg?w=225",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/03/photo1216.jpg?w=225",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/03/photo1212.jpg?w=225",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/03/heartbeat1.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/03/heartbeat.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/02/img_0251.jpg?w=950",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/02/img_0035.jpg?w=300",
            "https://pingu98.wordpress.com/wp-content/uploads/2012/02/img_0222.jpg?w=710",
            "https://secure.gravatar.com/blavatar/11508a282074753b48a92b094824134a2deb4549c45d5ba3a4c981e7610f7220?s=50&d=https%3A%2F%2Fs2.wp.com%2Fi%2Flogo%2Fwpcom-gray-white.png",
            "https://secure.gravatar.com/blavatar/11508a282074753b48a92b094824134a2deb4549c45d5ba3a4c981e7610f7220?s=50&d=https%3A%2F%2Fs2.wp.com%2Fi%2Flogo%2Fwpcom-gray-white.png",
            "https://pixel.wp.com/b.gif?v=noscript"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Posts about Technology written by pingu98",
        "meta_lang": "en",
        "meta_favicon": "https://secure.gravatar.com/blavatar/11508a282074753b48a92b094824134a2deb4549c45d5ba3a4c981e7610f7220?s=32",
        "meta_site_name": "James Devine's Blog",
        "canonical_link": "https://pingu98.wordpress.com/category/technology/",
        "text": "A few weeks ago I got a very exciting email, asking me what I thought about building a quantum computer out of Lego. Needless to say, it got my full attention, especially as I was very impressed with the Lego Atomic Force Microscope from back in 2012. As with all big ideas, I ended up talking about it with the sender over a coffee at the end of the week. This is the interim result. It’s going to be an adventure getting to the end of this project, and I’m looking for some help – maybe you!\n\nA very very short background to quantum computers.\n\nToday we have two mainstream types of quantum computer: Superconducting Qubits and Trapped-Ions. To make the first type you need (as an absolute minimum) a dilution refrigerator, superconducting qubits and some very fancy control systems. To make the second type you need high vacuum, high voltages, an ion source and some lasers. Trapped-ion quantum computers are generally cheaper to get started with, and indeed I found a really impressive guy on the internet has been building one in his garage. In summary, both mainstream types of quantum computers are very complicated and expensive. We cannot build one out of Lego, even with infinite money.\n\nSo, what can we build with $100?\n\nWe could get some lasers, some diffraction gratings, maybe an LCD or two and some single photon detectors to build a single quantum gate. There are some nice YouTube videos from @LookingGlassUniverse that are well worth a look. This would be very cool, but not exactly useful (and would need to be at least 2m long, unless we use lots of mirrors). Instead, we could build an optical computer. The team from Microsoft Research gave some very interesting presentations at CERN last year as part of the launch of CERN VentureConnect that I was fortunate to follow via Zoom. One of these caught my attention, discussing the use of off the shelf LCD elements for performing large matrix multiplications using light. This we could definitely do for $100 using a Raspberry Pi and hacking a few cheap LCD screens together.\n\nIntroducing the $100 optical computer!\n\nThe plan I have (so far, all plans change!) is to build a very simple optical computer that fits in a briefcase, technical details above. This will be one of the projects at the 2024 CERN Webfest hackathon, the launch of which is imminent. And as with almost everything I do for fun, it’s going to be as open source as possible (software and hardware). Once the computer is built, we will see how far down the road of computation we can go, with a quantum emulator/simulator as the ultimate goal. And, if we can do all this we should probably write a paper about it to publish somewhere.\n\nTo be clear, this is just a hackathon project. It isn’t a start-up, or a fundamental research project. We aren’t building a true quantum computer. It isn’t going to solve the worlds problems, like climate change, on its own – it’s just another powerful tool for us humans to use in achieving the challenge of the SDGs. It might be pretty neat for matrix multiplication, or it may not even work at all.\n\nDo you need help?\n\nYes! I need 5 people to help me. It’s open to anyone, some will need to be available in the Geneva region, Switzerland, for the hardware building, but you could conceivably be remote if you are willing to have a few zoom calls around lunchtime in the Central European timezone. If you are interested in, drop me a line before the 26th July (best to email devine dot jd at gmail.com) with some info about yourself and why you want to join in this adventure. No pressure, a few short sentences is plenty! Across the team, I think we will need the following skills:\n\nMechanical engineer, stability/structural calcs for our box (it will need to be sufficiently rigid) and mechanical drawings, potential 2D or 3D design/laser cutting/printing of a couple of components as necessary.\n\nPhysicist, for optics (lenses, light transmission calcs) and quantum stuff, experience with Jupyter notebooks.\n\nComputer scientist/Software Engineer/Programmer (Python and/or C preferred), vector/matrix multiplication, image processing.\n\nElectronics engineer (low level/embedded development), wiring harnesses, SPI bus connections, hardware interfaces with Linux.\n\nMathematician, but could also be a physicist or computer scientist with a strong analytical background (Build a simulator/emulator for the system in software, a digital twin), and figure out how to use this computational system to run ‘real world’ problems/port code from other systems and potential quantum emulation.\n\nRecruits will get a confirmation by the end of the day on the 26th July. And if you don’t make the team, don’t worry. You will be able to follow along via our github repo, and if you have $100 you can always try making your own version.\n\nWho will be our guides on this adventure?\n\nI’m planning to mentor the team. I think I have most of the skills and knowledge to take the project all the way to completion (but we will test that!). I will be sharing my skills with the team members to encourage them in the right directions and give feedback, I’m also providing the hardware.\n\nBeyond this, we will have access to some genuine specialists and experts in quantum and optical compute. The optical compute team at Microsoft Research in Cambridge are interested in this novel, low-cost, application of their work, I’ve already had a preliminary chat with them and plan to share progress as we build and test the box. We can ask them for advice as they have done this before with much more funding. I also have a contact with an expert in quantum computing at EPFL/ETHZ/PSI Centre for Photon Science who is going to give us some time with one of his PhD students. I have some friends and CERN Alumni who are passionate about useful things like matrix multiplications, who we can call on for support. In practice, this means we’ll have a few zoom sessions with the various experts over the two weeks of the programme, likely in the lunch hour slot.\n\nHow long is it going to take?\n\nI don’t know how far we will get, but we will start in earnest on the 26th July 2024 and it will finish on the 10th August 2024. To be clear, this is strictly a ‘spare time’ project for me – mostly lunch times, perhaps a couple of hours in the evening and a few weekend hours on the 10th August. But as a participant, you are welcome to work on it as much as you like.\n\nIs there anything else important to know?\n\nThis isn’t an official CERN project (which is why you are reading about it on my personal blog!), however it’s being done by the CERN MicroClub, which is a member based club at CERN, and will be part of Webfest 2024 that is supported by a bunch of different organisations. The main target audience for the hackathon are Summer Students at CERN, but really anyone (with at least some skills in one of the target areas) is welcome to apply.\n\nNow I want to learn everything about Quantum Computers and Optical Computers, where do I start?\n\nThe Analog Iterative Machine, a paper from the Microsoft Research Team in Cambridge.\n\nThis great paper from the 1970’s that covers much of the basics for the system we will build.\n\nThis patent from Microsoft, essentially covering the Analog Iterative Machine concept above.\n\nQiskit, the IBM framework for quantum computing and quantum computer simulation/emulation. They also have some fantastic lectures on Youtube that are must-watches.\n\nYoutube videos from @LookingGlassUniverse about quantum computing.\n\nThis is a nice looking lightweight quantum computer simulation library for Python, I think we might use it if we get that far and don’t find something better.\n\nAnd of course if you are reading this after the 10th August, you can check out the project github repo and see how far we got. You can also check out the projects from last years’ CERN Webfest 2023.\n\nDisclaimer: It’s been a while since I worked on an active data centre project (6, 7 years? Which is an eternity in such a fast moving field) so there are probably be areas below where industry practice has moved on, if you spot any errors or questionable assumptions please let me know and I’ll happily update my blog!\n\nThe other morning I woke up and read some news about how the UK PM is splashing $100M on ‘UK AI Supermodels’. It’s a good article, and it talks about the previously announced plan to build a UK supercomputer (presumably to run said models). The ever impressive Ian Hogarth has been put in charge of the group developing the models, but there isn’t any detail on the hardware yet. Whether it all actually happens remains to be seen, but it got me thinking about how you could hypothetically build such a machine, and what it would be like as a project (spoiler, I’m part way through the excellent How Big Things Get Done by By Bent Flyvbjerg and Dan Gardner). Anyone who’s been paying attention for the last decade or two should be well aware that IT projects can turn into giant fail whales, so there is clearly a high probability of failure from the outset.\n\nThe most interesting supercomputer I’ve seen recently is the Tesla Dojo. It is interesting in a number of ways, specifically:\n\nCustom chips\n\nCheap/cost effective\n\nAI focused\n\nIf the objective is to be a UK ‘homemade’ supercomputer, the main problem will be chip fabrication. Wikipedia has a long list of fabs worldwide, and unless I’m grossly mistaken there are no cutting edge ones in the UK, or even Europe. Cutting edge fabs today are <10nm, which limits you to Taiwan (TSMC), Samsung (S. Korea) or Intel (USA). The Tesla Dojo was apparently produced by TSMC on their 7nm process. Could the UK use some of the money from this project to upgrade an existing fab to 7nm? No way. The typical cost of building a new fab is in the tens of billions, so even a giant supercomputer project like this doesn’t even get close.\n\nRegular readers will know that I like to abuse the term ‘Full-Stack‘, this post will be no exception. In this case the bottom of the stack is quite literally dirt under a data centre. The top as always is a bunch of software that interfaces with humans and other machines.\n\nIf the UK can’t bake it’s own chips, what is the next best thing?\n\nNVIDIA is the current leader in AI hardware by some margin. They are a licensee of ARM, a UK centric (and once UK listed) CPU design company. One approach would be to throw money at NVIDIA for their hardware, put it in racks and call it a UK supercomputer, and if the wafers have ARM cores on them too, call it a win. It may also distract from the fact that ARM are planning to list in the US when they de-merge from Softbank.\n\nThe approach taken by Tesla was to use (more or less) RISC-V, a relatively new architecture that is based on an open standard, and increasingly the biggest competitor to ARM. This is a fundamentally different approach, which is more flexible, requires a bit more knowledge and experience on behalf of the chip designer, but looks like the way things are going in the future. The business model for RISC-V chips is very similar to ARM, you can go to a company such as SiFive and get them to design you a custom core, which you then need to get fabricated. RISC-V is really easy to get started with (not that I’m going to be designing a supercomputer myself) – you can check out this workshop I ran a few years ago about building your own chip on an FPGA. I recently read a fantastic article about Tensortorrent, who are aiming to be a specialist AI hardware house, using open RISC-V architecture as a base. If successful, this approach could be the x86 of AI.\n\nAnother option would be to throw large amounts of money at one of a small number of UK AI silicon start-ups such as Cerebras who have recently unveiled their first commercial installation. This has some advantages (domestic IP, ‘wafer scale’ deployment) and some disadvantages (custom software tooling required to run your models on it). Technically, the fundamentals are very similar to a RISC-V approach, except that the platform is entirely proprietary. There is a non-negligible risk that such a system would become obsolete in a VHS/Betamax if more players (national and corporate) go down the RISC-V route which seems likely. Of course the VCR situation isn’t exactly applicable, as it will probably always be possible to write a software interposer layer to run whatever the latest open RISC-V platform code is on a fully proprietary architecture, but this is likely to mean layers on layers which is a bad engineering idea.\n\nWhat should the UK do? Given the success of ARM, it would be tempting to throw money at them and/or NVIDIA in some combination. However, if the objective is to boost domestic industry and build a network of skilled individuals who can design cutting edge AI hardware, a RISC-V based approach seems like the right call today.\n\nWhat else do you need for a supercomputer?\n\nAll computers need a case, and for a supercomputer this means a data centre, or part of a data centre, filled with racks. Though I’ve never actually built a whole one from scratch myself (yet), I’ve worked on a few designs over the years. The fundamentals requirements are electricity and data connectivity (fiber), otherwise it will need cooling and some logistics (to move the hardware in, and upgrade it). A well designed data centre can last a long time, much longer than the hardware inside it.\n\nOne of the most interesting trends in the data centre world over the last few years has been the move to DC power distribution. Google have their own architecture that runs at 48V. There are significant savings to be made by not having each computer equipped with two (or more) redundant AC/DC converters, both in terms of money and energy.\n\nSome design questions to answer\n\nCooling – water cooling is going to be necessary at these energy densities. It gives the opportunity for heat rejection/recovery that could say heat a swimming pool. Would anyone like a new leisure centre?\n\nHow big should the box be? The minimum size of Dojo is 10 cabinets (19″ racks). You would probably want at a few extra rows of racks and cooling, as we never quite know how the insides of our data centres will evolve. Plus some office space for human operators and a logistics bay or two.\n\nIs this a standalone facility or part of another data centre/complex? Of course the cheapest option would be to find an unused corner in an existing data centre with spare power and cooling, though finding a couple of MW of spare power will be challenging even in the largest of facilities.\n\nOverall project – How long will it take to build? I don’t know how long custom CPU core development takes, but to build a datacenter from scratch is about 2-3 years give or take a few months and the overhead for local planning processes.\n\nWhat about staffing? How much of the budget should be allocated to:\n\nBuilding the facility\n\nDesigning the chips\n\nBuilding the chips\n\nSoftware to run the chips (infrastructure)\n\nActual research to be done on the chips\n\nMaintenance and upkeep for the lifetime of the facility\n\nElectricity bills\n\nThe fundamental question is what will be the Total Cost of Ownership of such a project, including end of life disposal.\n\nAnd of course we aren’t just building a computer to sit idle. Will it be a facility that people (researchers) can ask to use? One example of shared computer infrastructure is the CERN WLGC. A quick look around the WLGC wiki shows the many layers of management, governance and operation for such an undertaking, though clearly this AI supercomputer would be a little bit simpler having a national rather than international character. Who will manage operation and access, and how will this be done? It’s clearly a case that will require an organisation to oversee, going beyond the scope of the project to build the machine in the first place. The broader question is should a new organisation be created, or can an existing research/academic structure be co-opted to run this new behemoth?\n\nAll fascinating questions, we may get to see the answers if HM Treasury ever green lights a project, rather than just a pot of money.\n\nFull stack: the lower levels in review\n\nStarting from the bottom up, your data centre needs a physical location. Yes, even cloud infrastructure still lives somewhere here on earth for the time being. Your site needs:\n\nEnough space for however many racks you wish to install, you can always go multistorey (planning permission dependant)\n\nElectricity (Dojo consumes up to 2MW, for reference)\n\nPermission to make noise, as 2+MW of cooling fans and chillers are noisy.\n\nWater (You will need a reasonable amount to fill up, much more if you employ evaporative cooling)\n\nFibres, because you will need internet connectivity.\n\nRoad network connectivity, because you aren’t going to deliver anything or anyone by helicopter.\n\nPhysical infrastructure:\n\nA large concrete slab for everything to go on.\n\nWalls, which can be either blockwork or concrete depending on structural loads, the number of storeys etc.\n\nRoof, supported on either steel or concrete.\n\nDrainage and rainwater connections\n\nYour own High Voltage substation\n\nA decent fence, because you don’t want just anyone coming to your data centre.\n\nElectrical and Mechanical systems: Just like your desktop or laptop computer has a really annoying fan, and an equally annoying power cord, the same goes for your data center. The general rule here is if you need one of something to function, you actually need at least 2 of them to function reliably. You can multiply everything in the list below by 2N, or in some cases even 2N+1. The level of reliability offered by data centres is classified in Tiers, rangining from the lowest at 1, to the highest at 4, which generally includes at least 2 of everything and physical separation of systems so that a fire or failure in one room doesn’t bring your entire operation down. As a practical minimum I’d suggest:\n\nTwo complete, independent electrical high voltage connections (if you are serious about reliability). High voltage in this domain would typically be anywhere from 11kV to 66kV.\n\nTransformers to go from high voltage down to 230/400V (for europe, 110/220V for the US and other parts of the world).\n\nElectrical switchboards to turn your single 3200A circuit from a 2 MVA transformer into lots of smaller circuits.\n\nUPS (uninterruptible power supply), typically this is comprised of some power electronics and a lot of batteries. It is critical if you have a power glitch, or need to keep everything running and cooled when changing from one of your supplies to the other.\n\nDiesel generators, because even the most reliable electrical networks still fail from time to time and you wouldn’t want to lose any precious calculations.\n\nPower Distribution Units (PDU’s), which is how you distribute the power to individual racks containing computers. This may also include AC/DC conversion if you go for a DC data centre design.\n\nChillers or cooling towers, which can turn hot into cold via the addition of (electrical) energy and water.\n\nChilled water, to distribute the cooling around your computer racks – NB this is the only thing that is generally installed as a unique item. There is almost never space for the installation of two full sets of cooling pipes in a data centre.\n\nAir conditioning, depending upon your computer architecture you may be able to cool your racks with air (that is in turn cooled by the chilled water). This is viable up to a few kW of heat dissipation per rack, but to really go to high power densities water to the rack is essential. Air conditioning will be provided by Air Handling Units (AHU’s) and/or CRAC units (Computer Room Air Conditioners), which are the same but smaller and typically designed to throw cold air out into a rack room false floor. In this case we are almost certainly looking at more than 20kW of load per rack, at which point water cooling for the rack is necessary and the air conditioning is only for human comfort and auxiliary systems.\n\nFire detection, normally via ‘VESDA’, Very Early Smoke Detection Apparatus – a system of vacuum tubes that sample the air and can tell if it contains smoke. The sooner you detect the fire, the sooner you can take action to stop it and the lower the probability of major damage.\n\nSprinklers or other gas based fire suppression (depends on your jurisdiction and the assessed risk of fire spreading between parts of your data centre).\n\nLighting, because you need to have humans walking round the building to build it and install/maintain your computers.\n\nComfort heating, there will probably be an office or two for humans. Computers can generate their own heat.\n\nNetwork connectivity: Here we will need more than Wi-Fi or a tethered cell phone to provide access to the internet and/or our other data centres.\n\nAs a sensible minimum you will need two incoming optical fibres, ideally following diverse routes (i.e. not running in the same trench down the same road… because diggers have a habit of severing both simultaneously!).\n\nYou will be buying network connectivity from someone, unless you happen to also be your own Internet Service Provider (ISP). This means that you will need to provide them dedicated space inside your data centre to house their equipment that connects to the fiber and provides you somewhere to plug in. This space is sometimes called an MMR (Meet Me Room) or Comms room, and it may be a whole room, or a subdivided space with a series of cages, with one per supplier/one per supplier connection point. A design tip, don’t put your MMR’s next to each other if it can be avoided.\n\nInternal data connectivity, this can be provided by copper cables (Cat 6A/Cat 7) up to 10gbit, but increasingly fibre is also used within the data centre to provide communications in/out of racks, and also between racks. The cost of fibre connectivity can be significantly higher than copper, as the splicing and termination equipment (opto-electronic transceivers) are more costly.\n\nYou will need lots of cable trays to run these optical fibers and ethernet cables between racks, rooms and the MMRs. A design tip, put power cabling under the floor and data cabling suspended from the ceiling. You are very unlikely to change the power installation after you are up and running, but data cabling is more likely to require changing as the content of the data centre evolves.\n\nThis is a lot. What if i can’t do it all myself?\n\nThere are plenty of companies that specialise in end-to-end data centre construction as a discipline, such as Equinix. For those building supercomputers there is a niche within this market generally referred to as HPC, with a few large incumbents such as HP, Fujitsu and IBM. There are also many generalists who can also put them together, to list a couple Arup (my former employer), and AECOM (who I’ve worked with in the past).\n\nFor the last few weeks I have been thinking about an exchange with the ever dynamic Francois Grey about citizen science, and what it would take to get to an actual significant discovery. This is in the context of my involvement with the long running Cosmic Pi project, an attempt to produce open source cosmic ray detectors based on cutting edge technology, so I will also do my best to share the lessons learned from this endeavour. While we haven’t formally terminated the project, unfortunately none of the current team members has time needed to continue the project so it is currently on “pause”. Added to this, there are a lot of supply issues at the moment – so let’s just say it’s in stasis for the time being, hopefully to re-emerge at some point in the not too distant future.\n\nChoosing your battle: Physics vs Biology vs Other things\n\nHow easy is it to discover a new force or fundamental particle, in comparison to a new type of fungi? I watched the excellent documentary “Fantastic Fungi” featuring Paul Stamets recently on Netflix. It hadn’t previously occurred to me that you could potentially discover a new type of mushroom (or other biological entity) in your back garden or local wilderness – but it seems to be quite plausible with a reasonable amount of effort. And for a few hundred dollars, you can probably even get the DNA of your new find sequenced!\n\nHowever, if you wanted to discover the Higgs Boson on your own (or even with a few like minded individuals), you would need very deep pockets and a ridiculous amount of time. Forbes estimated the cost of the discovery at $13.25 billion, plus the time of over 5000 researchers, not including the efforts of all those working on the infrastructure to support the discovery (like me since 2010).\n\nThese are probably the two extremes of the science spectrum, in terms of the validity of findings and general usefulness to the wider human species. There are also doubtless many other fields of endeavour and inquiry that fall between the two extremes, with a range of cost (money, time and resources) and reward (discovery, or significant advancement in human knowledge) trade-offs.\n\nWhat does it take for Particle Physics?\n\nThe standard for a discovery in Particle Physics is 5 sigma. For those of you familiar with p-values, it’s the same principle – a statistical test to determine the likelihood that the observed result could be a fluke, rather than a real discovery. 5 sigma means 5 “standard deviations”, on a traditional bell curve. It is interesting to note that lower levels of significance can still be worth publishing, with significance of 3 sigma and beyond considered “evidence” of something new, but insufficient for a discovery. The probability of a false result at 5 sigma significance is 0.00006%, but of course it isn’t just a statistical test that determines a discovery, everything else also has to line up.\n\nMore practically, such a high level of confidence can only be reached with a large number of trials or observations. I’ve spent about a week thinking about ways to explain this concisely with some statistics examples, but to do the subject justice it really requires a full blog post on it’s own. Until I get round to writing it, I’d suggest you check out this article in Scientific American.\n\nI started working on the CosmicPi project a few years ago now (in 2014!) with some other young, enthusiastic engineers and physicists I knew at working CERN. We all did something with particle detectors and their supporting infrastructure as part of our day jobs, but each of us had only a very small slice of the overall knowledge required. We decided to build a muon detector, using the latest technology we could find. And we knew it would be difficult…\n\nIt took several years and a lot of help before we detected our first “muons”. And then a couple more years when we figured out that these weren’t actually muons, but electronic noise and to redesign things to capture the real thing. I’ve lost count of the number of prototypes we built, it’s at least 10 different versions. In short, if you want to build distributed hardware for particle physics, you will need to build a device that can take in particles of whatever type you are interested in (I would strongly recommend muons), and emit some form of TCP/IP packet that codifies the detection and goes to a central server where someone can look at it in combination with all the other packets your devices are detecting.\n\nConsumer electronics\n\nThe more astute readers will have already guessed that a device which detects a particle, and gives out a digital signal as an output, could also be described as a “product”. It is a manufactured object of non-trivial complexity, with a moderate cost associated. We were aiming to build a device 10x cheaper than the competition, and we managed this – in terms of costs, (but not sale price, because a) we haven’t started selling it yet, and b) some margin is required when selling anything).\n\nThe trap (perhaps it isn’t a trap) is that to scale your detectors you will either need someone with a lot of money (a lot), or to do some form of crowdfunding – where you sell your products to customers, who will host them. We’re not just talking about a box with a flashing light on it, but actually a very complicated, sensitive piece of equipment – an overall level of difficulty that puts most kickstarter campaigns to shame.\n\nYou also need to take the components and put them in a box. This is a very non-trivial activity, and since everything needs to fit in the box, and housings are either off the shelf, or custom molded ($$$ unless you have a huge volume of manufacture into the tens of thousands) it’s a good idea to choose your case appropriately. If you want to go the full distance, you will also need a manufacturer to put the components together in the boxes (and test them!). But even after nearly a decade we still haven’t got this far yet.\n\nLots of moving parts\n\nBuilding a cutting edge particle detector is not easy. You will need a detector medium, we chose plastic scintillators, as they can be extremely cheap – but are rather hard to get hold of commercially unless you are buying by the tonne. You will also need some electronics to read out the detector, which will include some specialist analog circuits, as this is what it takes to detect very small, fast moving particles that are only going to generate a few photons of light in your chosen medium. These electronics have to be designed and prototyped iteratively. Before we had even finished our first generation of prototype, the main microcontroller we were using was already obsolete! So a redesign was required before we could move to the next stage of manufacture.\n\nThere are plenty of other options, such as getting recycled or spare detector chips from full size physics experiments, or repurposing existing semiconductors which are sensitive to various forms of radiation. The former may run into availability issues and export constraints, while the later path can massively reduce the amount of data collected by a particular detector. Ultimately data is what can lead to discoveries, so the more you capture the better.\n\nBuilding a working detector is just the smallest Matryoshka doll. Around this you also need to build an infrastructure, both in the conventional sense (team, website, means to get your detector to the customer and their money into your bank account) and in the Physics sense. To use the oil analogy, raw data is just a resource, the value only comes when it is exploited with a means to process it. There are plenty of physics data analysis frameworks which exist, with varying degrees of complexity, but they all require significant pre-processing of the raw data and the addition of constructs that constitute the physics process you are searching for. A very reductive way of viewing a modern Physics PhD is that it involves three years writing and running data analysis scripts in order to generate some new insight from the vast array of high energy physics data collected by modern large scale detectors.\n\nFull Stack software.\n\nI find job adverts for ‘full stack’ developers rather funny. Because typically they only really want a couple of layers of the stack at most and certainly nothing that touches real hardware. The development stack for a particle detector goes all the way to the bottom. If you are building a new detector, you will need to read in an analog signal via some electronics, and somehow get it all the way up the software stack so it prints out on a screen or webpage. Practically, this means there is a need for both firmware (embedded software that runs on a microcontroller) and software, which can interface the microcontroller with a computer and share your data with the world. To build a ‘product’ appliance, that can be operated without the benefit of a full PhD, you will also need to handle everything from the calibration of the device (ideally automatic!) to setting up a device hosted Wi-Fi network and building a web interface, so that users can actually connect to your magic discovery box with their PC or Phone.\n\nWho has done this before?\n\nWe wasted an inordinate amount of time discussing the totally irrelevant. Could we manufacture our own scintillators with embedded wavelength shifting optical fibres? Should our device have a battery inside? Would a solar panel on the top be enough to power it? This was due to inexperience, but also a learning and sharing of knowledge, which (inconveniently) is not a linear process.\n\nWhat we needed was someone who had done this before to act as a mentor and guide. Someone with experience in electronics design, prototyping, manufacture. We connected with a lot of people but there are very few at the intersection of science and consumer electronics with all the relevant experience – and fewer still with sufficient free time for a project like this. There are plenty of science experts, but very few emerging experts in DIY electronics at scale, who are mostly self-educated via the mistakes of various crowd-funding campaigns they have just about survived. It’s still a rarefied skillset, even if you happen to be located at CERN.\n\nA personal inspiration to me has been Bunnie Huang, and I can’t recommend his book The Hardware Hacker highly enough. We have been using it, recommending it to other teams we cross attempting a similar challenge, and generally trying to learn from his mistakes when we haven’t already made them ourselves. In retrospect, we could really have used a mentor to guide us on this journey. We are still looking, and in the meantime the next best thing is to share our experience with others. While we have been on our journey, open science hardware communities have started to emerge, the most notable being GOSH – the Gathering for Open Science Hardware. This is also the Journal of Open Hardware, which has also started while we’ve been working on Cosmic Pi, and maybe one day we’ll even get round to publishing an article in it about our detector!\n\nThe Profit Motive\n\nWhat motivated our team? It was a lot of things, the fun of working together with like minded people, learning new skills and trying new things, the potential for discovering something, and democratising access to the technology through the code and schematics we published online. The profit motive doesn’t really feature, and as a group we are are missing a marketing department. Unfortunately (?), we are the type of people who would price our product based on what it cost to build, plus a markup we thought was reasonable. Typically in commercial electronics, if you aren’t making a 5-10x mark-up, you don’t stay in business for very long. In addition to sage advice from Bunnie, the EEVblog from Dave Jones is a resource beyond compare for those on this journey.\n\nDesign For Manufacture (DFM)\n\nOur design has many weak points, which of course have been exposed by the ‘Great components shortage’ of 2021/2/3/n. If you open up two seemingly identical consumer electronics products manufactured a few months apart, there’s a fair chance you will find they have some different components and integrated circuits inside. This is because large volume manufacturers (and smart smaller volume ones), tend to design with at least one alternate part for each critical component. This allows them to continue production when something is out of stock. The alternative is to redesign the board on the fly, based on available parts – and of course you will probably want to test it again before making a lot! Or you can pay a ridiculous amount of money to someone who has some stock of the chips you need.\n\nAnd then there is the more mundane, “traditional” side of DFM – making sure that your circuit board complies with design rules and good practices for the production process, ensuring you have sufficient margins on your passive components and design calculations to ensure that you get a reasonable yield.\n\nThis is a hugely time consuming activity. I have some friends who spend their day jobs right now redesigning existing products to work around the chip shortage. This type of operation is far beyond the resources we have as a bunch of individuals trying to build a cosmic ray detector. While it doesn’t take 100% of the effort all over again to produce a pair of design variants, even if another 20% is needed this is a lot for a volunteer project.\n\nPutting it all together\n\nI’ve filled out a typical business model canvas for the Cosmic Pi project. You can download it for your own remixing via the link below. We haven’t even started down the commercial part of this adventure, so I’ll just leave this here for now.\n\nSome Lessons Learned\n\nI have learned many things on this journey about how to build a particle detector and the top to bottom architecture of a globally-scalable IoT class device. Most of my biggest learning points come from the mistakes but not all, here are my top 5 lessons.\n\nFootprints for PCB components. The first fevered weekend of building a detector was spent painstakingly soldering tiny wires to inverted components that looked like dead spiders, all because I hadn’t verified the pad dimensions well enough on our very first prototype. Always double check your device footprints (and pin outs). Always.\n\nHumans. This project has been kind of a mash-up of science and open source, with a side helping of start-up. The most important part of the puzzle is the human element. As usual I roped in a few friends, made some new friends along the way, and we had some fallings out too! Trying to wrangle a team of very skilled, highly intelligent volunteers with divergent ideas into a project can be challenging. When conflict erupts, which it will, make sure that your friends know that any disagreements aren’t personal, and that you value your friendship independently from the project. If you see tempers rising around a particular issue, don’t wait for things to boil over before getting involved. And if you are wrong, or over the line on something, apologise as soon as you realise it. Things have been a lot of fun, but it hasn’t always been easy. I don’t think I destroyed any friendships (so far)?\n\nIgnorance. I know thing X. Thing X is obvious (to me)… but it turns out that some team members didn’t know thing X, and didn’t even know that they didn’t know it. They took on a challenge, and got into difficulties that affected the whole project because of their ignorance. We’ve all done it in different ways, with impacts that vary from expensive to time consuming. Of course, it is necessary to assume some level of common knowledge (and trust) when any two people are working together, but I find it is always worth taking the time to frame the task and go over the first principles at the start of any new collaboration.\n\nInterns are amazing. We have been fortunate enough to have a few interns working on the project, some of whom were even full time and funded. The progress they have been able to make on the project, working full time, as opposed to free evenings and weekends for the rest of the team, has been inspirational. We were able to have a good win-win relationship with all the students who worked on the project so far. The ones who were funded got paid and all of them learned valuable skills in programming, electronics and particle detector assembly, plus the lesson of how hard it all is to put together.\n\nEntropy is a problem, especially in software. Just because you have a set of awesome software for your device that’s tested on hardware platform Y.0.00.0, doesn’t mean it will work at all on hardware platform Y.0.00.1. Or even on your original platform with a version update to your OS or it’s major libraries. Software requires maintenance! The rules, settings, configuration requirements, dependent libraries are all shifting. To minimise your exposure to entropy I recommend:\n\nKeep it simple. The less code you write, the less there is to maintain (and you should have fewer bugs too). The software problem hasn’t changed fundamentally since the 1970’s, you should read The Mythical Man Month by F. Brooks Jr for wisdom and inspiration. It’s the best book I didn’t read at university.\n\nPut as much of the data processing into your embedded elements, i.e. firmware, as you can (within reason), as this will be stable across software changes. Keeping our data output format stable for versions 1.6 through 1.8 saved us a lot of time.\n\nScripts not software. It’s much easier to maintain a hundred lines of Python than something compiled. If you can rely on software platforms (InfluxDB, Grafana) for the heavy lifting that is ideal, and if not then consider ‘module’ level systems such as SQLite and Python libraries. Writing your own linux kernel drivers in C is always possible, but will require a lot of upkeep.\n\nWhen it comes to embedded binaries, make sure you keep a copy of the latest version you have compiled for distribution (and all previous versions too..). This is especially important if you are using development environments such as Arduino, where the actual .bin/.hex file can be abstracted away under the plug and play upload button.\n\nGit. Things which are put in a repository are great. Things which aren’t are usually lost over the years it takes a project to get to maturity.\n\nA conclusion, for now at least.\n\nI hope to have shared insights into at least some of the ground we covered with Cosmic Pi so far. We’ve come a long way, but just like climbing a mountain we might have scaled the first and the second rise, it’s still a long way to the summit. If you are full of enthusiasm and want to get involved please drop me a line, or if you would like to chat about your own open hardware science projects feel free to get in touch with me via twitter, where you can find me as @pingu_98.\n\nI’ve been very priviledged to have worked on some great engineering projects in my career to date. This blog post is about one of the stand-out projects that I was fortunate enough to work on while at Arup in London, back in 2007 and 2008. The Druk White Lotus School is an exemplar sustainability project, located in Ladakh, India.\n\nThe Druk White Lotus School is a boarding school in the foothills of the Himalayas which aims to foster and preserve the unique culture of the Ladakhi way of life. The school is planned based on the Dharma wheel, with classroom buildings near the entrance, and residential blocks further back within the site. It was my role to work with the client in developing the technical specification for the microgrid installation and to support them during the tender process, then at the end of the project I had the chance to go to Ladakh and get hands-on with the final commissioning and site acceptance testing in September 2018! Ladakh has a harsh climate, with extremes of hot summers and freezing winters, which was one of the drivers of the project schedule. The treacherous road to Leh closes for winter, restricting the availability of building materials. Due to the cold winter temperatures all building work outside is very difficult, meaning that all work had to be completed before the bad weather set in.\n\nThe Leh valley, where the school is situated has an intermittent electricity supply, with a typical maximum of 4-6 hours of electricity per day (at the time of construction). Electricity was rationed, based on different districts and areas, not conducive to a school lesson plan using computers or electrical equipment of any kind! The design of the Druk White Lotus School has been supported by Arup on a pro-bono basis since the inception of the project. The installation of an on-site micro-grid, with solar panels and battery storage was designed to permit the site to operate automonously, with a top-up from the grid supply when available.\n\nOne of the main challenges of the project was to install a distributed generation and electricity storage system on top of an existing electrical infrastructure. As school buildings were constructed, each was added to the three phase low voltage electrical network via copper or aluminium cable. Each building had a local single phase distribution box (or fuseboard) to supply interior lighting and sockets. The site was also equipped with a very small back-up generator, feeding in to the local distribution via a break-before-make transfer switch. A further constraint for the design was the requirement to construct a modular, scaleable system that would be able to grow with future development of the school, as new classroom buildings and accomodation blocks were added.\n\nThe system architecture is shown above, with three single phase PV installations added to the three classroom buildings at the front of the mandala site layout. Sunny Boy PV and Solar Island battery inverter systems from SMA were specified for the hardware installation, The angle and orientation of the PV installation was optimised using the freely available RetScreen software. Each was connected to a different electrical phase, providing an overall three phase balance for the site, via the existing distribution system. A new power house building was constructed to house battery storage and three single phase battery inverters with a common DC bus. The existing AC disrtibution system wiring was retained, with frequency modulation used for communication between the battery storage and distributed solar inverters, located approximately 400m away from the power house building.\n\nSystem functionality:\n\nSelf-contained micro-grid, capable of autonomous operation on PV supply\n\nPhase-Phase energy transfer via DC bus for unbalanced loads\n\nEnergy storage via lead-acid solar batteries designed for deep discharge operation on a single DC bus\n\nAbility to perform battery charging and operation from local generator (recommended for periodic full recharging of the battery system as a maintenance operation)\n\nAC distribution frequency modulation used by SMA inverters for communication without the need for additional communications wiring, using a slight lowering of the micro-grid frequency to encourage PV supply, and a frequency rise to disconnect PV supply in the case of insufficient demand and/or a fully charged battery.\n\nPotential to sell energy back to the grid, however this was disabled at commissioning due to the lack of a regulatory/legal framework in the local energy market.\n\nSunny Island inverters equipped with SD card slots providing minute by minute logging for easy remote analysis of the system performance.\n\n9kWp PV installation, in three modules of 3kWp per building.\n\nCapability to add additional PV installations on future buildings.\n\nCapability to add additional battery capacity as funding becomes available.\n\nA new earthing point was installed for off-grid operation.\n\nThe site commissioning process was very challenging, as it was the first installation of it’s type for all those concerned (contractor, site foreman and myself the design engineer), there were also significant differences, both in terms of culture and electrical installation safety standards to be overcome before the system could be commissioned. It was also necessary to borrow the only three phase rotation meter in the valley from the local airport electrician in order to ensure the correct configuration of the three phase system. The only major issue with the commissioning came when the battery system was fully operational and charged, with the solar inverters failing to connect. Upon further investigation, it transpired that the solar inverters had been shipped with firmware settings for domestic installations in Germany, rather than the micro-grid firmware required in this installation. A laptop with the new software and a suitable communication interface had to be flow in to Leh in order to make the upgrade, but once completed in October 2018 the system performed as designed.\n\nSummary:\n\nThis was a wonderful project to work on back in 2008. The challenge of designing a micro-grid system for a self-contained school, building upon existing low voltage distribution infrastructure in a remote location was significant. Then the opportunity of getting hands-on for the project commissioning in such a unique environment was possibly a once in a lifetime opportunity. Having all the system performance data logged to SD card was also very helpful in supporting the installation when I returned to the UK. Receiving the call from site in October 2008 to hear that the system was working as expected after the firmware update was a real moment of both relief and excitement.\n\nIf you would like to know more about other aspects of the multi-award winning Druk White Lotus School project you can find additional details in this article in Ingenia magazine.\n\nPost script: At the time I had the idea of filming various critical operations on the system and putting the videos on YouTube for future reference. This was really useful and something I would highly recommend for anyone doing this type of project! The videos are still online, you can view them here in this playlist.\n\nUpdate – It’s been a while since the workshop and unfortunately I deleted the VM, since I won’t be hosting any more workshops in the near future. I’ve updated the article with tips on building your own VM (or of course you could install it natively!), good luck!\n\nI’m giving a workshop next week on how to build your own RISC-V CPU within a Lattice iCE40 series FPGA using the awesome Icestorm framework by Clifford Wolf. We need two toolchains here in order to create both the processor and the code to run on it, and we will build EVERYTHING here from source. Sorry – the VM I built has now expired, so I’m afraid you’ll need to rebuild one, here’s a great site to get you started.\n\nStage 1: Create a VM\n\nThe main issue with running up your own RISC-V cores is having the toolchain ready to go. So I created an Ubuntu VM, based on 18.04 minimal and running within Oracle VirtualBox. I chose minimal because it’s lightweight, small and will have a reasonably manageable footprint when putting the VM on a USB stick, and because Ubuntu is my native Linux distro. The choice of VirtualBox was down to it’s cross-platform compatibility and the fact that it’s free to use. The VM is configured for 4Gb RAM and 30Gb HDD, AMD64 CPU, with nothing fancy on top – I would recommend a similar approach when making your own VM. In order to facilitate cross platform compatibility and carrying it round on a USB drive, I’ve also set the HDD to be split across 2Gb files, since some file systems have a restriction on the maximum size of a single file. The total size of the VM comes to >17Gb, so make sure you have plenty of hard drive free!\n\nI created the username “risc” with the password “Lattice”, but when making your own you should make wise choices! I don’t generally advocate writing your username and password on a blog, but this was a special case while I had the VM available. Evidently don’t leave this VM running, or give it open ports to the outside world when you are using it! If I do rebuild the VM (this time I’ll use Ubuntu 20.04, because it’s new.), I’ll post a link here, but unfortunately that isn’t going to be for a while – since I don’t plan on running any DIY CPU workshops during the pandemic.\n\nStage 2: Configure the VM\n\nOnce the VM has been setup, it’ll need the icestorm toolchain installing in order to program the FPGA. This comprises a number of things in more or less the following order:\n\n1. FTDI drivers from here. It’s a .tar file, so you’ll need to unzip it a couple of times and then follow the instructions for how to copy the driver files in to your system directories as a super-user.\n\nwget https://www.ftdichip.com/Drivers/D2XX/Linux/libftd2xx-x86_64-1.4.8.gz tar xfvz libftd2xx-x86_64-1.4.8.gz cd release cd build sudo -s cp libftd2xx.* /usr/local/lib chmod 0755 /usr/local/lib/libftd2xx.so.1.4.8 ln -sf /usr/local/lib/libftd2xx.so.1.4.8 /usr/local/lib/libftd2xx.so exit\n\n2. Packages to make everything work in Ubuntu (note I’ve added libeigen3-dev, not included on Clifford Wolf’s page, since I needed it):\n\nsudo apt-get install build-essential clang bison flex libreadline-dev \\ gawk tcl-dev libffi-dev git mercurial graphviz \\ xdot pkg-config python python3 libftdi-dev \\ qt5-default python3-dev libboost-all-dev cmake libeigen3-dev\n\n3. The Icestorm toolchain components from here:\n\nIceStorm Tools\n\nArachne-PNR\n\nNextPNR\n\nYosys\n\n4. A sample program to check we’ve got the FPGA compilation working, before we move to RISC-V compilation, from here. I cloned this code into a directory called flash, compiled it and uploaded it to my device to make it flash the leds in sequence. It worked first time, after I connected the USB device to the VM.\n\nIt’s worth noting at this point that I haven’t installed Icarus Verilog, since it isn’t strictly required to compile to the target, but would be needed if we wanted to test things! If I get time I’ll add it to the VM. Thanks to Oliver for pointing out this nice FPGA toolchain installation script.\n\nUPDATE: I just added Icarus Verilog (V10) built from source and the Icicle repo for some better Upduino support. The Icicle serial output doesn’t seem to be working when flashed to target, but it does make the LEDs light up on the iCE40HX8K and Upduino boards. I also added minicom and picocom for serial monitoring.\n\nStage 3: RISC-V\n\nNow that we’ve got a working toolchain for the FPGA, we need to build a working RISC-V compiler in order to have code to run on our chip. I installed Clifford Wolf’s Picorv32 from here. This basically takes you to the RISC-V mainline toolchain and picks out a particular revision and only the compiler required for smaller/less capable cores. When compiling it for the first time, I was stuck for a few hours on the ../configure line pre-compile to insure that the /opt/riscv32i toolset is used (the other toolsets are not compatible with the iCE40HX8K FPGA due to size restrictions), but eventually figured it out.\n\nWhat we are actually building in this stage is an add on for GCC that will enable us to compile binaries for execution on our soon to be created RISC-V core. There’s no point having a CPU if we can’t aslo compile code for it from a high level language.\n\nI followed the instructions in the picorv32 repo as follows:\n\ngit clone https://github.com/cliffordwolf/picorv32 picorv32 sudo apt-get install autoconf automake autotools-dev curl libmpc-dev \\ libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo \\ gperf libtool patchutils bc zlib1g-dev git libexpat1-dev sudo mkdir /opt/riscv32i sudo chown $USER /opt/riscv32i git clone https://github.com/riscv/riscv-gnu-toolchain riscv-gnu-toolchain-rv32i cd riscv-gnu-toolchain-rv32i git checkout 411d134 git submodule update --init --recursive mkdir build; cd build ../configure --with-arch=rv32i --prefix=/opt/riscv32i make -j$(nproc)\n\nStage 4: Hardware\n\nNow the software is all ready to go, we just need a hardware platform to run it on.\n\nThis tutorial is designed to run on one of the following demo boards:\n\nThe Lattice iCE40-HX8K evaluation board, available from Digikey.\n\nThe UpDuino, available from GnaryGrey.\n\nAnd the BlackIce II designed by a couple of awesome guys in the UK!\n\nStage 5: Compile and upload\n\nEverything is very nearly finished. Except it doesn’t work just yet. We also need to install the VirtualBox expansion pack in order to access USB2 devices. We can download it here and add it via the GUI.\n\nThen we need to ensure that we can find the compiler for RISC-V, which we can do by adding it to the PATH environmental variable:\n\nexport PATH=\"$PATH\":/opt/riscv32i/bin\n\nIf you fail to do this, you’ll get a tonne of “riscv32-unknown-elf-gcc command not found” errors until you correct it. Make sure you don’t wipe out the path variable in the process!\n\nAnd just to make sure we can access the device, let’s add our user to the dialout group:\n\nsudo usermod -a -G dialout risc\n\nWith all of this in the bag, we need to ensure that our VM is connected to the USB hardware, which we can do via the menu or the USB attachment icon in the bottom right of our VM window. We should enable the Lattice device, and then we can complete our build and upload with the following commands:\n\ncd /picorv32/picosoc make hx8kprog\n\nIf everything works as it should you’ll see various messages about compilation and programming of the device, followed by “VERIFY OK cdone: high… Bye.”. The LEDs on your board wil blink about once a second. Note that there are several options for alternative things to do in the /picosoc directory, all without yet writing your own code or core, they are detailed in the makefile in the picosoc directory which is definitely worth reading.\n\nIt’s worth noting that I couldn’t get my permissions quite right so I had to cheat a little for access to the USB device to do the final upload, but calling make hx8kprog as sudo. Not the best technique, but it worked!\n\nConclusion – Testing the CPU\n\nAt this point I chose to unplug my FPGA dev board from the virtual host and hook it up to a real one (with the drivers installed of course!) to check that I’d actually built the core and it was working properly. I launched my trusty Arduino IDE and fired up the serial console, baud rate 115,200bps on the correct COM port and was greeted with this:\n\nWe have now built a working RISC-V core on our FPGA board and programmed it with some compiled code. I’d like to thank the awesome Clifford Wolf for basically making it all possible (he wrote the core we used to implement RISC-V and the ICESTORM toolchain we used to generate and upload our bitstream) and RMWJones for posting some very useful scripts that helped me along the way.\n\nA couple of years ago now I taught myself how to do rudimentary metal forging using videos from the internet and the occasional digitised book. Here’s the summary of how to do it if anyone else wants to have a go!\n\nWarning: Learning to forge things in metal is dangerous, you should proceed with caution at all times. In particular you risk setting fire to things (including yourself), burns, self inflicted stab wounds and other nasty things if you aren’t sensible.\n\nSafety items you should have to try forging: A head mounted welding face mask (you will need both hands). Flameproof overalls (I use Nomex ones, also remember to wear natural fibres underneath just in case). Leather welding gloves. Tongs for manipulating very hot things. A face mask to protect you from projecting molten metal is also a good idea. A leather apron can also be useful as it’s comparatively resistant to molten metal. A bucket of water handy is also a very wise precaution.\n\nStep 1: Decide what you want to forge.\n\nThis weekend I decided to forge a moon pendant, based on the above sketch.\n\nStep 2: Carve it in wax. I used a tea light from IKEA, vanilla scent, however you can also buy proper (harder) carving wax from specialists. If you want high detail, this is a must! You can also buy it in pre-formed ring blanks. Be careful when cutting the wax, I’ve previously cut myself quite badly doing this using an Xacto craft knife, but fortunately it’s healed now!\n\nStep 3: Cast the mould. For this you should find a tin can (aluminium or steel) that’s big enough to hold the wax piece. If you’re only detailing on one side then an open mould is fine, stick something on the top of your model to allow it to be rested on top of the can. Otherwise, for more complicated castings such as rings, you should include a sprue and a cone on the top of the mould to allow you to pour in the liquid metal. To make the mould, I used pure plaster of Paris, however you can/should also add some sand to improve the strength of the mould. It’s a good idea to tap the side of the mould vigorously to ensure that any bubbles on the wax model get dislodged. Ideally you should put the mould under a vacuum to remove all air bubbles, but vacuum pumps are hard to come by. I’ve managed without one so far.\n\nStep 4: Wait for the mould to dry. There’s no shortcut for this.\n\nStep 5: Bake out the mould to melt the wax and ensure that the plaster/plaster+sand mixture is fully cured. You might want to build a mini kiln for this, here’s mine.\n\nIt is constructed from a concrete air brick, sawn in half and then drilled to create a cavity and a connection point for a heat gun. It has a top half which is the same, but with a small vent hole instead of the inlet. Here is a picture of the completed kiln.\n\nNote the small hole on the top for the hot air to come out of. I placed the cured mould, complete with the wax model, upside down in here for about 30 minutes to bake it and melt out all the wax. You could probably just pour in the molten metal, but baking out seems to be more reliable.\n\nStep 6: Whilst the mould is baking, you can set up your furnace. I used an arc welder, since it’s easy to get hold of and runs on easy to handle electricity rather than anything chemical (coal, propane, etc.). To turn the arc welder into a tool for forging, you should remove both the ground clip and the welding rod holder and replace them with large metal mole grips. These can be used to hold the electrodes and/or a crucible. I would recommend using a graphite crucible and graphite rods extracted from 6V ‘lantern’ batteries – be careful not to crack them while extracting them from the 4 zinc housings within the battery. It’s also worth noting that if you obtain them this way, they will be coated in a paraffin type wax which will burn off after the first time you strike an arc.\n\nHere is my ‘workbench’ you can see the arc welder is the yellow box at the end, with both electrodes replaced with mole grips. I used a small part of the concrete air-brick as a stand for the crucible, here’s a close up also complete with my cracked crucible which I disposed of after this casting and the mole grips holding carbon rods:\n\nStep 7: Melt the metal. For this step I can highly recommend using some borax as a flux, you can buy it (normally) from your local chemist. It’s not the nicest of chemicals, even though it was used as washing powder in the 19th century, so use sparingly (a light dusting in the crucible is plenty I find) and handle with care. Next add your metal in small chunks that fit in the crucible. For this project I used some silver elements I had left over from another project. Silver is cheap, at least compared to Gold, and melts a lot easier than Copper. Beware of metals containing Zinc as breathing in the vapour can give you the shakes and fever like symptoms. Copper is VERY HARD to melt, and once molten, re-solidifies almost instantly. I started practising with it and was mightily relived when I switched to casting in Silver.\n\nStep 8: Pour into the mould. You should remove the mould from the kiln and place it next to your crucible workstation before attempting this. Pouring the metal in is surprisingly difficult and you really don’t want molten metal splashing or pouring onto anything else (you, clothes, wood, anything that will melt or burn). Once you’ve melted the metal, be sure to lift your welding visor otherwise the mould will be invisible (along with anything else that isn’t an electrical arc or glowing metal).\n\nStep 9: Apply the plunger (carefully!). If you look carefully at the photo of my workbench you’ll see a broken stick of wood attached to the lid of a jam-jar. This is my plunger for steam casting. When you have poured the metal into the mould, you can push the plunger down on top to generate steam and force the metal into unoccupied parts of the mould. You should prime the plunger by stuffing it with newspaper and then wetting it (in your safety bucket of water). However, if you are casting in an open mould, there’s limited benefit to the above, as assuming you used a sensible amount of flux, and it’s hot enough, the metal will naturally fill the mould. In this case, I was overzealous and plunged the plunger down onto my filled mould whilst the Silver was still liquid, creating the following mess:\n\nYou can see the blobs of molten silver that were pushed out by the steam, and the blackened lump in the centre is what I pulled out of the mould itself, which was also looking rather worse for wear. It’s worth noting that metals, generally, can be purified and re-cast even when they look rather messy. The impurities will either burn off or sink to the bottom of the crucible.\n\nThe mould, after use. This type of mould is only intended for a single use. However since I was in a hurry (never cast in a hurry!), I decided to re-use it and modify my original design somewhat. I placed the lumps of silver into the mould and created an arc between the two electrodes in close proximity to the mould (1-2mm max), in order to re-melt the silver into the mould. This worked very well, though changed the nature of the end product.\n\nStep 10: Quench and finish. After re-melting, I was careful to wait for the casting to cool before dropping the whole mould in my handy nearby bucket of water. After a few seconds bubbling, I retrieved the cast using a pair of pliers and tidied it up using a grinding wheel and a wire brush polishing wheel. Since the mould had been abused during the two pours of the casting process, there were some fragments of gypsum (plaster) embedded in the surface of the final cast. These soon came out under the polishing wheel whilst I was improving the overall shape and look of the piece.\n\nHere is the front of the finished pendant, with a very lunar surface look to it. There’s a 2.4 mm hole drilled into the top for the silver chain, at a slight angle to help it sit ‘moon side up’ when worn as a necklace. I didn’t cast/make the chain, as that’s far too much like hard work, instead buying it from a local jeweller.\n\nI polished the back side of the pendant to a much smoother finish, with the idea that it would be more comfortable to wear. During the polishing process it got so hot that two tool marks imprinted into the Silver, you can see them towards the bottom. I decided to leave them as they look rather like footprints to me!\n\nCasting is a lot of fun, however it can be extremely hazardous so should only be done with extreme care. It took me about 3 months of occasional evening and weekend practice before I was able to make my first ‘proper’ cast, and I’m still a very, very long way from even a student level of proficiency. But it kind of works, and I’m very happy with the end result. I’m also not going to give up my day job!\n\nP.S. I must give credit to The King of Random for his excellent Arc Furnace video which was my inspiration for using the arc welder to melt metal!\n\nIn this post I’m going to talk about some preliminary radiation tests I’ve been performing on a couple of Arduino Uno modules and present the story so far…\n\nA while ago I attended the awesome Lift’12 conference in Geneva. I met some inspirational people and got inspired to test some arduinos in a radioactive environment. I haven’t found anyone else doing this kind of thing, which isn’t surprising as general access to radioactive environments is fortunately quite limited. However, I’m lucky enough to work at CERN and we have plenty of interesting places to test things!\n\nThis is very much a first tentative step into testing the arduino’s performance under the influence of radiation – only two devices were tested, there is no control group and I’m only writing down what I did after the event. I’ve been working on an LED lighting test for about a year now with some colleagues and last time we had access to the test facility I persuaded them to let me add two arduinos (which I named Archie and Bob) to the test bench as cheap signal conditioners to monitor the current flowing in our LED samples. I did also check with my boss (a highly recommended stage of the process for anyone else feeling similarly inspired into testing things at work…).\n\nEach arduino (UNO, R2) was mounted in an ABS enclosure with a prototype shield mounted on the top. The shields comprise:\n\nHomebrew radiation hard power supply (230V to 16ishV)\n\nScrew terminals for the connection of terminals to the outside world\n\nMiniature CT + burden resistor to measure current in the LED samples\n\nThe ABS boxes are mounted on steel plates approximately 40cms by 60cms, which also contain a set of terminal blocks (for connection to the main test chassis) and a couple of LED samples under test. I should stress at this point that the arduino isn’t an integral part of the test bench, just a cheap way for us to extract additional information.\n\nThe ‘homebrew’ radiation hard power supply is a very basic affaire, composed of a cheap PCB mounted 230V-12V transformer and a GBU8k glass passivated full bridge rectifier with an 800V breakdown voltage. The GBU8K has previously been tested at CERN and found to be a reasonably solid performer when subjected to radiation. This PSU is obviously extremely basic, providing only a wobbly DC voltage at about 14-16V with no load. This set of tests relies on the linear regulator onboard the arduino to step down the voltages to a smooth 3.3/5V level.\n\nThe CT is hooked up across a burden resistor to the Ain pins, as this is a test bench and I’m using some components which are sized to a full scale deployment (72 led’s instead of 2) the observed voltage is very low – which is where the signal conditioning of the Arduino comes in. The onboard ADC and DAC are used to sample the voltage across the CT several times, take the maximum measured value (in an effort to measure the peak current for the LEDs running on a 230V 50Hz supply), multiply it by a factor of 10 and then send an analogue output (0-5V) reflecting the multiplied value. The analogue output is sent for 5 minutes, followed by a 0V value for 5 minutes before the whole cycle is repeated and the current is re-sampled. Potentially this helps us check that the arudino can still output a 0 volt signal, that the internal clock is reasonably accurate and from the periodic change in output voltage we can rapidly conclude if it’s broken… the signal also looks rather like a heartbeat, which is intrinsically pleasing (for me as an Engineer anyway!) to see.\n\nThe justification for this is that it would be very hard to measure the raw CT signal (which is just a few mV, for a current of only a few mA in the LED’s) via the experimental infrastructure we have in place (over a kilometer of copper cables), without adding some sensitive and expensive amplifiers – which more likely than not would be rapidly destroyed by the radiation in the test environment. So in this case the Arduino gives us a cheap (<20 euro) alternative, indicating as a minimum that there is still current flowing to the LEDs, and as an added bonus we can monitor and evaluate the performance of both Archie and Bob as they soak up the rays!\n\nSo far (over a month into the ‘test beam’) both test benches are still functional, although some distinctive wobbles can be observed on the outputs of the DAC’s from both Archie and Bob. I was personally quite surprised that they lasted more than 1 day, as a previous test had destroyed a number of SMPS (switch mode power supply) within mere hours once the radiation started.\n\nSo far the conclusion is that the two arduino’s tested are still functional, after a 1 hour per day duty cycle within the radiation test area. As time goes on I’ll update this blog post with some more details about the specific type and levels of radiation experienced, plus a more scientific analysis of the outputs taken from the ADC’s. I feel obliged to point out that this is a very long way short of a formal ‘radiation qualification’ , which would require amongst other things components with a fully controlled provenance, a statistically significant sample pool, source code which tests the operation of (ideally) all the silicon within the arduino and peripherals, and of course a detailed scientific analysis of the results. But every journey starts with the first step and so far Archie and Bob are still marching down their radioactive road…\n\nThe source code (sorry it’s rather messy, but it works) running on the arduino’s is below:\n\n/*\n\narduino radiation test code version 1\n\ncurrent monitoring for led sources within CNGS tunnel, CERN. 8/3/12\n\n100:1 CT with four passes of wire (i.e. 4x amplification on current)\n\nwritten very quickly and based on a bunch of examples by\n\nDavid Cuartielles\n\n& Tom Igoe\n\n*/\n\nint sensorPin = A0; // select the input pin for the potentiometer\n\nint ledPin = 3; // select the pin for the LED\n\nint sensorValue = 0; // variable to store the value coming from the sensor\n\nint interimValue = 0;\n\nvoid setup() {\n\n// declare the ledPin as an OUTPUT:\n\n//pinMode(ledPin, OUTPUT);\n\nSerial.begin(9600);\n\n}\n\nvoid loop() {\n\n// read the value from the sensor:\n\n//init and first value read\n\nsensorValue = 0;\n\ninterimValue = analogRead(sensorPin);\n\nsensorValue = interimValue;\n\n//start the acquisition process proper\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(123);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(137);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n} interimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(123);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(137);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n} interimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(113);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(123);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\ndelay(137);\n\ninterimValue = analogRead(sensorPin);\n\nif (interimValue > sensorValue)\n\n{\n\nsensorValue = interimValue;\n\n}\n\n//Multiply by 10. Typical measured values pre-start were 15-17 raw (150-170 with multiplication)\n\n//then send this value out over the serial and the pwm ports\n\nsensorValue = sensorValue * 10;\n\nanalogWrite(ledPin, sensorValue);\n\nSerial.println(“I am alive and my name is Archie”);\n\nSerial.println(sensorValue, DEC);\n\n//now wait another 5 mins\n\ndelay(300000);\n\n//send a zero for 5mins to allow measurement calib.\n\nanalogWrite(ledPin, 0);\n\ndelay(300000);\n\n}\n\nPrinter ink is the most expensive commodity in the world (by weight, or volume.. apparently). I’m always running out of it just when I need to print out a boarding pass, or some other essential printed document. So wouldn’t it be great if you could print things out using a biro?\n\nHere is my version 0 attempt at such a device in action at Lift’12. It actually has a lot of similarities to this drawing automaton, although I only realised that after I’d finished and the video blogger Nicolas Charbonnier pointed it out to me! Nicolas did a video interview with me at Lift’12 where I had the chance to show off my creation a little. You can watch the video (which includes a fair bit of discussion about my day job at CERN) here.\n\nBasic idea: A robot arm with two drive servos and one more to move a pen (or pencil) up and down onto standard A5 paper. Plugs into a computer for the power and the drawing data. Draws following the mouse or via a crude black & white filter on a JPEG image.\n\nIngredients:\n\nArduino (I used my trusty old duemilanove), USB lead to connect it to a computer, three Futaba S3003 servos (or equivalent), a few bits of wire, and some stationary from Muji (one A5 file box, two aluminium rulers, one wooden ruler and one acryllic one to be precise). A biro (one with four colours if you are feeling fancy!). Software: Processing and some jpg’s (+a bit of patience)!\n\nBuilding it was fairly straight foreward, with the most complicated part making a cam to lift the pen up/down. I did this by drilling 1/2 of an acryllic ruler so that the pen can pass through it, with the pen attached using a single thin screw to an extremity of a servo horn. Fixing the acrylic ruler to the up/down servo didn’t work very well, hence the blue ‘LIFT’ tape in the photos.\n\nOnce assembled it should look like this – obviously you can modify the hardware build as you wish.\n\nYou can see the coins I added (wrapped in masking tape) as a counterweight on the left. It helped to resolve some issues with the lack of co-planar motion in the two arm segments.\n\nAfter trying to write my own code I gave up and used the excellent Firmata library for the arduino/processing link (my own code was doing strange things…). The computer communicates serially to the plotter, sending positions for each of the three servos.\n\nWhen I was writing the initial processing sketch, I controlled the arm directly for the first few passes. This was disasterous as I managed to snap teeth off two out of my three servos (originally they were super-micro lightweight ones… after the damage I decided to upgrade to the S3003’s). This lead me to develop my own ’emulator’ for the arm, so that I could solve the mathematical and physical constraints without breaking anything else. You can see an early demo of the arm here.\n\nHere is the processing source code:\n\nimport processing.serial.*;\n\nimport cc.arduino.*;\n\nArduino arduino;\n\nint countstart = 0;\n\nint servo1Pin = 9; // Control pin for servo motor\n\nint servo2Pin = 10; // Control pin for servo motor\n\nint servo3Pin = 11; // Control pin for servo motor\n\nint armposn;// = 0;\n\nint digitposn;// = 0;\n\n//int penposn;//= 0;\n\nint penstate = 0;\n\nint xcent = 300;\n\nint ycent = 300;\n\n//int targetX= 400;\n\n//int targetY= 200;\n\nint line1 = 130;\n\nint line2 = 130;\n\nint minimumlength = 40;\n\ncolor black = color(0);\n\nPImage img;\n\nPImage edgeImg ;\n\nvoid setup(){\n\nfloat[][] kernel = { { -1, -1, -1 },\n\n{ -1, 9, -1 },\n\n{ -1, -1, -1 } };\n\nsize (600, 600);\n\nbackground(255);\n\nimg = loadImage(“ben.jpg”); // Load the original image\n\nimg.loadPixels();\n\nedgeImg = createImage(img.width, img.height, RGB);\n\n// Loop through every pixel in the image.\n\nfor (int y = 1; y < img.height-1; y++) { // Skip top and bottom edges\n\nfor (int x = 1; x < img.width-1; x++) { // Skip left and right edges\n\nfloat sum = 0; // Kernel sum for this pixel\n\nfor (int ky = -1; ky <= 1; ky++) {\n\nfor (int kx = -1; kx <= 1; kx++) {\n\n// Calculate the adjacent pixel for this kernel point\n\nint pos = (y + ky)*img.width + (x + kx);\n\n// Image is grayscale, red/green/blue are identical\n\nfloat val = red(img.pixels[pos]);\n\n// Multiply adjacent pixels based on the kernel values\n\nsum += kernel[ky+1][kx+1] * val;\n\n}\n\n}\n\n// For this pixel in the new image, set the gray value\n\n// based on the sum from the kernel\n\nedgeImg.pixels[y*img.width + x] = color(sum);\n\n}\n\n}\n\n// State that there are changes to edgeImg.pixels[]\n\nedgeImg.updatePixels();\n\narduino = new Arduino(this, Arduino.list()[1]);\n\narduino.pinMode(servo1Pin, Arduino.OUTPUT);\n\narduino.pinMode(servo2Pin, Arduino.OUTPUT);\n\narduino.pinMode(servo3Pin, Arduino.OUTPUT);\n\narduino.analogWrite(servo1Pin, 70);\n\narduino.analogWrite(servo2Pin, 170);\n\narduino.analogWrite(servo3Pin, 50); // the servo moves to the horizontal location of the mouse\n\n// note – we are setting a digital pin to output\n\nbackground(255);\n\n}\n\nvoid draw()\n\n{\n\nif (countstart == 1){\n\nmakepic();\n\narduino.analogWrite(servo1Pin, 70);\n\narduino.analogWrite(servo2Pin, 170);\n\narduino.analogWrite(servo3Pin, 50);\n\n}\n\ncountstart = countstart +1;\n\n}\n\n//void draw(){\n\nvoid makepic(){\n\nbackground(255);\n\n//fill(50);\n\nstroke(0);\n\n//rect(350+30,320-10,130,130);\n\nimage(img, 0, 0, 130, 130); // Displays the image from point (0,0)\n\nimage(img, 130, 0, 130, 130); // Draw the new image\n\nfilter(POSTERIZE,4);\n\nfilter(THRESHOLD);\n\ncolorMode(HSB);\n\nfor (int xcycle = 130; xcycle < 259; xcycle = xcycle+2)\n\n{\n\nfor (int ycycle = 0; ycycle < 129; ycycle++)\n\n{\n\nif (get(xcycle,ycycle)<-2)\n\n{\n\nset(xcycle+350-130+30,ycycle+320-10,black);\n\nmarkpaper(xcycle+350-130+30,ycycle+320-10,110);//changed pen variable 110\n\ndelay(20);\n\nmarkpaper(xcycle+350-130+30,ycycle+320-10,170);//comment this line and the one further below out to draw lines not dots\n\n//delay(20);\n\n}\n\nelse\n\n{\n\nset(xcycle,ycycle,0);\n\nmarkpaper(xcycle+350-130+30,ycycle+320-10,170);\n\n//delay(50);\n\n}\n\n}\n\nfor (int ycycle = 129; ycycle > 0; ycycle–)\n\n{\n\nif (get(xcycle+1,ycycle)<-2)\n\n{\n\nset(xcycle+350-130+1+30,ycycle+320-10,black);\n\nmarkpaper(xcycle+350-130+1+30,ycycle+320-10,110);\n\ndelay(20);\n\nmarkpaper(xcycle+350-130+1+30,ycycle+320-10,170);//likewise comment this line out for lines not dots on your paper as well as the one further up\n\n}\n\nelse\n\n{\n\nset(xcycle+1,ycycle,0);\n\nmarkpaper(xcycle+350-130+1+30,ycycle+320-10,170);\n\n//delay(50);\n\n}\n\n}\n\n}\n\n}\n\nvoid markpaper(int targetX, int targetY, int penposn){\n\n//print(“xposn” + targetX);\n\n//println(” yposn” + targetY);\n\nfloat angle1 = atan2((targetX – xcent), (targetY – ycent));\n\nfloat sectorlength = sqrt(sq(targetX – xcent)+sq(targetY – ycent));\n\n//if it’s out of reach, shorten the length in the same direction\n\nif (sectorlength > (line1+line2))\n\n{\n\nsectorlength = line1+line2;\n\ntargetX = int(xcent + sin(angle1)*sectorlength);\n\ntargetY = int(ycent + cos(angle1)*sectorlength);\n\n}\n\nif (sectorlength < minimumlength)\n\n{\n\nsectorlength = minimumlength;\n\ntargetX = int(xcent + sin(angle1)*sectorlength);\n\ntargetY = int(ycent + cos(angle1)*sectorlength);\n\n}\n\nfloat internangle = acos((sq(sectorlength)-sq(line2)-sq(line1))/(2*line1*line2));\n\nfloat sendangle1st = (angle1+(internangle/2));\n\nif (degrees(sendangle1st) < 0 )\n\n{\n\nsendangle1st = radians(0);\n\n}\n\nif (degrees(sendangle1st) > 180 )\n\n{\n\nsendangle1st = radians(180);\n\n}\n\nint line1X = int(xcent+ sin(sendangle1st)*line1);\n\nint line1Y = int(ycent+ cos(sendangle1st)*line1);\n\nint line2X = line1X + int(sin(((angle1+(internangle/2) – internangle)))*line2);\n\nint line2Y = line1Y + int(cos(((angle1+(internangle/2) – internangle)))*line2);\n\nstroke(0,9);\n\nline(xcent, ycent, line1X, line1Y);\n\nline(line1X, line1Y, line2X-1, line2Y-1);\n\n// if (penposn == 150)\n\n// {\n\n// set(line2X,line2Y,black);\n\n// println(“TEXT”);\n\n// }\n\n// set(mouseX,mouseY,black);\n\n//if it’s too close set the minimum threshold in the same direction\n\nint sendangle1 = round(degrees(sendangle1st));\n\nint sendangle2 = round(degrees((radians(180) – internangle)-radians(35)));\n\n//println(“Send1>”+ sendangle1 + ” Send2 >” + sendangle2);\n\ndigitposn = sendangle2;\n\narmposn = sendangle1;\n\narduino.analogWrite(servo1Pin, digitposn);\n\narduino.analogWrite(servo2Pin, penposn);\n\narduino.analogWrite(servo3Pin, armposn);\n\nif (penstate != penposn)\n\n{\n\ndelay(300);\n\n}\n\nelse\n\n{\n\ndelay(1);\n\n}// the servo moves to the horizontal location of the mouse\n\npenstate = penposn;\n\n}\n\n//end of source\\\\\n\nI should add that this code is very rough, and contains hard-coded boundary limits for the drawing area which are specific to the physical configuration of my hardware (and painstakingly obtained by moving the arm and looking at where the pen is). This code is also set to draw dots rather than lines, as people generally indicated a preference for this kind of output.\n\nPerformance is ‘interesting’. I’ve set it to draw an approx 160×160 matrix, one pixel at a time. Depending upon the number of dark pixels this can take up to 1.5 hours per image. If you want to draw lines that go between all the connected pixels the time per image comes down to <20 minutes. This is mostly a function of delays added in the code to cope with mechanical oscillations in the two arms and the pen.\n\nThings that could be improved:\n\nThe code is very ropey! Like my flat, it would benefit from a tidy and the hoovering up of any stray variables.\n\nThe drawing area is still a bit sub-optimal. The arm can cover almost 100% of the space of an A5 sheet, however I’m only using about 65% for drawing at the moment. The boundary conditions for the angles would need to be carefully adjusted for this.\n\nWorst of all the image processing is very crude (simple cut for black and white). This is mostly because I’ve been lazy (it WORKS, right?) and wish to avoid re-inventing the wheel when there are so many excellent image processing suites out there. If I have time it would be great to code something to vectorise JPG’s properly rather than my current ‘quick and dirty’ approach.\n\nColour! My pen has Red, Green, Blue and Black ink.. mostly I use black or blue for clarity, but it would be very interesting to come up with a multi-pass colour image reproduction system.\n\nGood projects are never quite finished 😉\n\nA picture of Ben Bashford drawn from a JPG photo, live on the stage of Lift’12.\n\nI hope you liked my creation – please feel free to comment, suggest and contribute. I’d like to thank Amy Shen for being my first drawing subject and for helping me to figure out the maths of converting an XY co-ordinate space into a two polar variables."
    }
}