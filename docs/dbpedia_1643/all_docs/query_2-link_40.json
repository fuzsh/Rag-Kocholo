{
    "id": "dbpedia_1643_2",
    "rank": 40,
    "data": {
        "url": "https://charm.rhul.ac.uk/studies/chapters/chap8.html",
        "read_more_link": "",
        "language": "en",
        "title": "The Changing Sound of Music: Approaches to Studying Recorded Musical Performances",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://charm.rhul.ac.uk/studies/chapters/images/pubimg/thumb/thm_dlwpl9.jpg",
            "https://charm.rhul.ac.uk/studies/chapters/images/pubimg/thumb/thm_dlwfig17.jpg",
            "https://charm.rhul.ac.uk/studies/chapters/images/pubimg/thumb/thm_dlwtab5.jpg",
            "https://charm.rhul.ac.uk/studies/chapters/images/pubimg/thumb/thm_dlwfig18.jpg",
            "https://charm.rhul.ac.uk/studies/chapters/images/pubimg/thumb/thm_dlwfig19.jpg",
            "https://charm.rhul.ac.uk/studies/chapters/images/pubimg/thumb/thm_dlwpl10.jpg",
            "https://charm.rhul.ac.uk/studies/chapters/images/pubimg/thumb/thm_dlwpl11.jpg",
            "https://charm.rhul.ac.uk/studies/chapters/images/pubimg/thumb/thm_dlwfig20.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "Assets/g/i/favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "by Daniel Leech-Wilkinson\n\n8. Expressive gestures\n\n8.1. Performance expression\n\nÂ¶1 Weâve seen quite a lot of examples of performance style, and of the way it has changed, and weâve thought a bit about why. But what is it? What defines it in sound? And how does it work?\n\nÂ¶2 A style isnât easy to define fully, though itâs easier in music than in most other domains. Think of the difficulty of precisely defining style in painting or clothing, for example: at least in music itâs easy to measure the constituent elementsâthe soundsâand because they come in sequence you donât have to consider them all at once. But even so there is still the problem of drawing boundaries between styles. As weâve seen in talking about period and personal styles, a performer does some things that all performers do, and some that all performers at any one time do, as well as things that some do but not others, and things that only she herself does. To know which level we were defining weâd have to be able to say which of these stylistic features belonged to each. And to do that properly would require a database of all recorded performances and a means of analysing the data. Nicholas Cook and Craig Sapp have been doing something along these lines for recordings of Chopin mazurkasâwe looked at some of the techniques in chapter 6âand have made real progress in turning recordings into machine-readable data and developing software routines that can sort through them. The better we get at that the more useful things weâll be able to say about performance style with real precision. In the meantime we can make some worthwhile progress simply by determining what sorts of things constitute a performance style and by looking at examples of them in practice.\n\nÂ¶3 Letâs start with a simple definition. Performance style is generated by what performers habitually do with the notation to make a musical performance. This is a convenient generalisation if weâre talking about classical music. Actually we donât have to define it in relation to notation; but there has to be something that is being shaped in consistent ways for there to be style. Letâs take a more extreme example to clarify the point. Jazz uses very little notation: its common material, the bases for performances, are often no more than simple melodies whose precise details no one may quite agree about. But nevertheless they exist recognisablyâyou know them when you hear themâand itâs their elaboration that makes a performance. All that elaboration is stylistic. The performer plays and elaborates the core materials by bringing to it a manner of decoration, harmonisation, timing, pitch adjustment, dynamic shaping that could equally well be applied to many other melodies. In jazz, variations of tempo and pitch and dynamic are everything. The style is to a very large extent the music. But except for the fact that jazz players feel freer than classical musicians to make their own contribution to the harmony and melody, what makes jazz jazz are precisely the things that weâre looking at in studying classical music performance. Thereâs a âtextâ and there is elaboration of it as it is realised in sound. And the way that elaboration is done constitutes the performance style.\n\nÂ¶4 If we want to define a performance style, then, weâre going to need to look at everything except the given material, which for classical music is the notation. We can test this definition by looking at a literal performance of the notation, which if this definition is correct should have no style. Listen again to Sound File 3 (wav file) from chapter 2 and see what you think. We still have the composition style, but it doesnât make a great deal of sense. Perhaps the MIDI piano is contributing a minuscule sense of shaping to each note by its attack, which someone has programmed to sound like a person playing a piano. But thereâs not a lot left that we can easily recognise as musical. What do we mean by musical? Performance style and musicality are essentially the same phenomenon, except that âmusicalâ adds to performance style the notion of persuasiveness. Like performance style, âmusicalâ means the ability to play notes in ways not specified precisely in the score, but it also means doing that convincingly. So performing musically, or stylishly, involves modifying those aspects of the sound that our instrument allows us to modify, and doing it in a way that brings to the performance a sense that the score is more than just a sequence of pitches and durations. âMoreâ in what sense?\n\nÂ¶5 The answer is key to music-making. For perceptual reasons that will become clearer as we go along, these elaborations of the raw instructions in the score, including the modifications of the literally notated lengths, pitches and loudnesses, have the effect for the listener of making the music expressive. By making a note the wrong length (by not doing exactly what the notation says) we change it from a pitch with a duration into a sound that moves us in some way. How a sound modifies our emotional state is a big subject; weâll find some answers being suggested by the effects we see in our examples. Ultimately it is a problem for neurology and psychology and for empirical study. But for the moment we can approach a general understanding of what happens by considering it as a music-analytical problem in which we interpret the relationship between what we hear and what we feel. And that is what we shall be doing in the rest of this chapter. Weâre going to be looking at things performers do in sound and trying to work out how those things affect us as we listen.\n\nÂ¶6 The expressivity we experience through a performance seems to shift all the time, from moment to moment during a performance. One moment may seem to stand out, the next to be more restrained; one note may be rasping, the next softer-edged, and so on; and it seems to follow that expressivity is caused by brief events that happen frequently. One can take any strong example and begin to see relatively easily what kinds of events these are and why they seem to suggest certain kinds of meaning.\n\nÂ¶7 Listen to this example. (Sound File 26 (wav file)) 1 Itâs from a performance of Schubertâs âDie Allmachtâ recorded (in English) by Essie Ackland in 1932; sheâs singing about the presence of God in all things. Here the words are âseeâst it in the wave of the golden cornâ. Iâm interested in how she sings âthe waveâ. Itâs unmistakably wave-like, but how does she do that? The spectrogram shows an outline of what she does; slowing down the recording (using Sonic Visualiser, of which more below) gives us more aural detail (Sound File 27 (wav file)). As she sings âtheâ she lets the pitch glide from the notated G down to E. Then there is less clearly pitched sound as she moves her tongue from the âuhâ position of âtheâ to the âwuhâ of âwaveâ, which passes through ârrâ somewhere around C. (This seems curious to us, but a Scottish inflexion of âtheâ, ending with the tongue curving round to ârrâ, was common in early 20th-century English singing.) The âwâ starts around D and glides more slowly up to the notated F becoming the âayâ vowel on the way at about E-flat.\n\nÂ¶8 Thatâs a rather detailed description of an effect that is perceived more holistically as a wave-like start to âwaveâ, which as the spectrogram shows is exactly what it is. The wave motion covers far more pitches than the two notated (G and F for âthe waveâ), so this is very clearly something brought by the performer to the notation. And it produces a sounding image of the word in the text. Although itâs a wave in sound rather than in golden corn, our brains easily map the sound image onto the visual image and perceive them as equivalent. Itâs a metaphor, but not an abstract literary one, rather a real mental effect as the brain makes a connection between one kind of wave and another. Adding one to the other makes the textâs wave more vivid. We feel more of that wave than we would without the sound image: indeed, without the sound image we probably wouldnât feel it at all unless we had a particularly vivid imagination. So the music is doing some extra work for us, forcing us to perceive that wave whether we want to or not.\n\nÂ¶9 We have in this little example a complete demonstration of the process by which performance expressivity works. The performer does something to the sound not specified by the musical structure. What he does the listenerâs brain analyses, as a normal part of the process of âperceivingâ sound. In one of many complex processesâinvolving the analysis of pitch, loudness and timing, and the construction from them of best guesses as to the soundâs source and meaningâthe brain searches for similarities between those features and things it already knows about, and sends back into consciousness (which may simply mean that these are the strongest matches found) perceptions of those things that seem to match best. Since itâs getting incoming information from the text about waving corn, that match is made most immediately, along with memories of wave shapes and waving in general, pictures of golden corn, and whatever else each of us may individually associate with these sounds and images. Some kind of mental picture of the singer, based on the sound of her voice and what we imagine of the environment in which people sang like this may be mixed in more weakly.\n\nÂ¶10 What all this amounts to is a sense that this passing moment has meaning, of which the sounds are expressive. Itâs meaning and expressivity that is not inherent in the score but that arises from the performance. And the things the performer does to construct this meaning expressively are elements of her performance style. She does them like this because they are consistent with her own manner of being expressive in performance. In Acklandâs case they are relatively strong because that was the norm in her day, and especially in performances of religiose songs in English for a general music-loving audience. (The disc was issued in HMVâs popular series C, part of the cheap âplum labelâ.) Ackland is gauging an appropriate stylistic context within which to pitch this performance. Then she is using her own imaginative responses to the text, calling up images in vision and using her voice to convert those into similar motions in sound. She doesnât need to think this out in detail. Our brains work fast enough to manage largely through feelings this process of finding appropriate metaphors and generating sounds to represent them, which it can do in microseconds, far too fast for us to think much about. The singer draws on experience, both of singing and of sounds in life, to shape her singing in ways that feel right for the musical and textual moment. That both the making and the perceiving of these effects depends on feelings more than thinking only serves to integrate the process more fully with our emotional state, which is mainly what music modulates when we listen unanalytically (that is to say, normally) to a performance.\n\nÂ¶11 The whole process depends on our naturally selected ability to make connections within and between incoming data streams, generating perceptions of the world outside us that enable us to react appropriately in the interests of survival and reproduction. Survival and reproduction may seem rather far from performing Schubertâs âDie Allmachtâ, but we respond to sounds in this way because over time itâs enabled our evolutionary ancestors to react usefully to sounds around them, enabling them to distinguish with minute precision between the meanings of one sound and another.\n\nÂ¶12 Iâve allowed this description to go so far into perception and evolution because they are both fundamental to our normal everyday responses to music, and a lot of musical performance effects can only be properly understood in this context. Music is so powerful not because itâs a set of codes invented by individuals over that past few centuries that weâve all been required to learnâthat couldnât make it powerful, only familiarâbut because it uses naturally selected responses, most of them long pre-human, and uses them automatically without waiting for our conscious mind to work out whatâs going on. 2 No wonder, then, that expressive performance brings so much to music, indeed is essential to bring music to life. And âto lifeâ is the right metaphor, indeed itâs hardly a metaphor at all, because that is exactly what expressive performance does. It brings life to composed structures which without it exist only as ideas sketched out in notation.\n\nÂ¶13 Itâs easy to see how this process connects with the discussion of music and performance in chapter 2. Compositions become music when performers link notes with sounds, shapes, and processes we know from life. The way performers link them is strongly influenced by performance style. Using metaphorical practices common to their place and time, performers inflect notes in order to make them expressive of feelings, and thereby to bring them meaning. We can think of these inflections as expressive gestures, expressive because they represent meaning, and gestures because they shape notes over time in the same way, and for the same purpose, that humans use their hands and face to communicate information about the dynamic shape of a process and about its effect. 3 The metaphor of shape is absolutely fundamental to musical communication. Music makes shapes in sound over time: sounds gets higher or lower, louder or softer, faster or slower, and their timbre changes, and each and all of those processes we understand as shaping sound. There may be a spatial element in our perception as wellâthat remains to be demonstrated, but it is a possibility that needs testing. At any rate, itâs exactly this changing of any or several parameters of a sound that does the expressive work in performances, so âexpressive gestureâ seems as good a way of labelling these inflections as we are likely to find.\n\nÂ¶14 Thereâs one other point that needs to be made before we go on to look at many different examples of expressive gestures from recordings. How large these gestures are, and so how obvious to the listener, varies over time with changes in period performance style. Early in the 20th century, especially during the 1920s and 30s, they were very large; later, especially in the 1960s and 70s, they were often very small, barely noticeable in casual listening although one would notice at once if they were missing. In our own time gestures are typically still a lot smaller than in Essie Acklandâs day, but Iâll be focussing on her period to an unrepresentative degree because itâs much easier to understand the process if we begin with the strongest examples. For listeners today, especially for academic listeners whoâve been trained to search for unobvious meanings in music, things no one has noticed before, performance gestures this large and with metaphorical associations this obvious can be embarrassing or seem trivial. But that is simply a measure of the emotional distance between us and pre-War listeners which weâve already seen in chapter 4. In due course we can begin to work on more recent performance styles where shaping is far more subtle and far more to our taste. But if you donât like overtly expressive performance youâll have to bide your time. We need to know what kinds of processes are involved in musical performance before weâll be able to see them more subtly at work.\n\nÂ¶15 An expressive gesture can be defined as an irregularity in one or more of the principal acoustic dimensions (pitch, amplitude, duration), introduced in order to give emphasis to a note or chordâusually the start of a note or chord. Expressive gestures involve sounding notes for longer or shorter, or louder or softer, or in some other way different compared to the local average. Why the local average? Carl Seashore, and many who have followed him, described these irregularities as deviations: âthe artistic expression of feeling in music consists in esthetic deviation from the regularâfrom pure tone, true pitch, even dynamics, metronomic time, rigid rhythms etcâ. 4 The problem with that word is not only that it implies deviance, but also that it seems to suppose that there is a proper length, loudness, or pitch for a note. In terms of the score there may be, but as weâve repeatedly seen the score is not the music, and nor is a straight performance of it. So âdeviationâ from the score is normal, in fact definitive of a musical performance, and itâs not the fact that notes are not strictly as notated that generates expressivity. Rather itâs how much they differ from their surroundings and from what weâve come to accept over the last few moments of listening is the (local) norm. Difference from the score is not whatâs expressive; change is.\n\nÂ¶16 So in musical performance, these changing loudnesses, timings and frequencies work together locally, coordinated with the composed melody and harmony, to shape the sounding music; and itâs a shape that consists mainly of alternating, sometimes overlapping expansions and contractions. There are no fixed patterns, and no fixed functionsâeverything depends on context. Gestures are combined together and placed in sequence to give an expressive shape to a phrase of music, and phrases in turn can work expressively within larger passages of music. But for the listener most of what counts happens in the present, at the ânowâ moment; and that deserves more of our attention, Iâd suggest, than our music-analytical training, with its emphasis on long-term patters, leads us to expect. Itâs around the now moment that our consciousness of expressivity is most fully operational, and so itâs the local norm against which gestures are perceived as expressive. 5\n\nÂ¶17 How did expression become so crucial in western art music performance? First, we shouldnât necessarily assume that itâs absent elsewhere. Rock music is highly expressive, albeit in more consistent ways within each song (rather like early music), not using the moment-to-moment shifts of mood characteristic of art music. So are many world musics, and in a variety of ways. Perhaps what expressivity in western art music (WAM) does is to replace one kind of bodily engagement with music, typically in non-WAM contexts dance, with another, a kind that allows listeners to sit still in rows and still have a deeply satisfying emotional experience, internalising bodily engagement with the music. Expressive gesture in sound may do what physical gesture used to do, and still does elsewhere, and the close relationship may still be suggested by our strong inclination to call it âgestureâ. Itâs been turned into sound to suit a culture that thinks of music as something needing full attention, cutting out visible actions as distracting, a by-product of which has been the tendency of music as sound to become, at any rate until recently, ever more complex. Expressivity has less of a role in the performance of minimalist scores, and we may not be far wrong if we assume that it is closely tied to the nature of musical composition as it developed from the late 16th to the end of the 20th century. Of course, without sound recordings we shall never know.\n\nÂ¶18 As I have said, expressive gestures are not fixed. Any kind of departure from regularity can be expressive. But only a limited palette of gestures is used by one performer, and only a limited set is in use in any period. This is what makes it possible to use a repertoire of gestures to define an individualâs or a periodâs performance style. So a 'performance style' is a set of expressive gestures characteristic of an individual performer that taken together constitute their 'personal style'; or a set characteristic of a period ('period style'), or a group (for example, national style). Over time, the gestures that constitute a period style change. One hundred years of evidence is not much, and itâs far too soon to say whether they work to any substantial extent in cycles, or whether the process of change is to all intents and purposes continuous. What we have seen in previous chapters gives us some reason to suspect that the same gestures are perceived somewhat differently in different periods. Although they may invoke quite basic perceptual processes, the precise signification of an expressive gesture must depend on its context to a very significant degree, and this is another reason to be wary of any kind of dictionary of performance gestures that seeks to fix meanings: it is essential to be sensitive to the local and period context in assigning any kind of meaning to a gesture, and to localise that meaning within a particular performance. The one general law we can be confident about is that a gesture makes its impact in proportion to its size, that is, the degree to which it changes what was going on before.\n\n8.2. A methodology for studying expression and expressive gestures\n\nÂ¶19 For this kind of study we need first of all a way of observing gestures at work in their full sounding context. And we need to be able to examine them in more detail than our ears allow. At the least, we need a way of training our brain to hear more precisely. A means of measuring, to enable precise comparison, would be helpful.\n\nÂ¶20 One can do a lot just by listening closely. We do need to be able to listen to the same passages repeatedly, so some means of storing a performance and of replaying it, and parts of it, easily is essential. You can do this with a CD player, but you can do much more with a sound file on a computer. Computer files are far easier to navigate, and you can have several open at once and switch quickly between them, which makes comparisons possible. So Iâm going to assume in what follows that importing recordings into a computer, and listening to them and viewing them there are possible. Weâll make fuller use of the computerâs sound capabilities later on, but first Iâd like to recommend the virtues of close listening, allied to notation, pencil and paper.\n\nÂ¶21 You can practise close listening; in fact it requires practice, focussing oneâs full attention on the sound of the performance. After a time itâs surprising how much detail one can hear, far more than in casual listening. Time spent with the visualisation software weâll use below will help you to know what are the acoustical components of the sounds you hear, and youâll be increasingly able to describe instruments and voices, and momentary effects, in acoustic as well as in metaphorical terms. This isnât the natural place for an introduction to basic acoustics, but if youâve not had one you need it now. If you have, then skip to the next section.\n\nBasic acoustics\n\nÂ¶22 All natural sounds are made up of several wave forms of different periodicity sounding together. 6 For a musical pitch this typically consists of a fundamentalâwhose frequency corresponds to the pitch you think you hearâplus a number of higher frequency sounds of which youâre not consciously aware (the brain mixes them all together for you) but which provide all your perceptual knowledge of the timbre of the sound. All these frequencies are âharmonicsâ (or âpartialsâ), and the relative positions of all those above the fundamental are fixed in relation to it. The first harmonic is the fundamental itself, the second an octave above it, the third an octave and a fifth (a 12th) above, the fourth two octaves, the fifth two octaves and a third, and so on, up the harmonic series. 7 The higher they go the closer together they get and the more dissonant they become. Mostâtypically allâof the âovertonesâ are quieter than the fundamental, but the louder the highest harmonics are the brighter the timbre of the sound. So brightness is caused by the dissonances among the upper harmonics. If there are few harmonics, or they get soft as they go up the scale, youâll perceive a smoother, less strident sound.\n\nÂ¶23 Frequencies are defined by the number of cycles of the wave per second. Modern concert-pitch A above middle-C cycles 440 times per second. The number doubles with each ascending octave, so the A above is 880cps or Hz (named after Heinrich Rudolf Hertz), A below concert A is 220Hz. And so on. That means that as you go up the frequency spectrum the number of cycles per second quickly gets very large indeed. Young people can hear between about 30 and about 20,000Hz, but the ear is not able to distinguish between that many different frequencies, and as sounds go up the spectrum the ear is less and less able to tell them apart. It groups adjacent frequencies together into bands, and gives the brain information about each band, but not about the frequencies inside it. So sounds very high up seem less dissonant to us that they might if we had sharper hearing. Weâll need to know this later on when we start to look at sounds on computer displays. For similar reasons to do with the economical construction of the human ear, louder frequencies may mask quieter frequencies nearby, so we donât hear all the frequencies that machines can tell us are actually present in a sound. And this is another reason why music may sound more mellifluous to us that it otherwise might.\n\nÂ¶24 The other thing that for music perception is crucial about human hearing is our ability to distinguish sounds of different lengths. We can tell the difference between the length of two sounds to within about 30 milliseconds difference, thatâs 0.03 seconds. 8 Anything smaller than that we probably wonât notice if it comes within a sequence of other sounds. We took account of this in chapter 6 when looking at Fanny Daviesâs rubato and in chapter 5 when looking at our concerto violinistsâ portamento, and weâll come back to it when we look at spectrograms in a moment. Now we can go back to close listening.\n\nClose listening\n\nÂ¶25 Itâs possible to do a certain amount of work using just a score, pencil and paper, and your ears (and brain). In fact itâs an important exercise, because itâs all too easy to be led into hearing things one can see on a computer screen but canât perceive without one. Just listening, and writing down what one hears, is often a very good way to get started when studying a performance. Itâs a good idea to be methodical about oneâs close listening and so the next group of examples suggests a way of keeping notes.\n\nÂ¶26 Figure 17 annotates the vocal line of an extract from Schubertâs âWohin?â (the second song from Die schÃ¶ne MÃ¼llerin), in order to indicate, using notation and some fairly self-explanatory signs, how the three singers compared here shape and colour their part. You can follow it with the sound files. Thereâs no agreed system for making the annotations, so one just has to be as clear as possible.\n\nÂ¶27 Sound File 28 (wav file): Marcella Sembrich (1908) 9\n\nÂ¶28 Sound File 29 (wav file): Nigel Rogers (ca. 1975) 10\n\nÂ¶29 Sound File 30 (wav file): Peter Schreier (1989) 11\n\nÂ¶30 Table 5 suggests a way of organising comments on a number of obvious aspects of the performance style. In each case the most important features, those that seem to do most of the expressive work, are highlighted. Itâs now easy to see how the focus of singersâ attention appears to have shifted through the generations represented here (turn-of-the-century, HIP, and modern) from portamento and rubato, through articulation, to text illustration. I say âappearsâ because first of all these singers have to be shown to be representative: for that a large number of examples would be necessary. In fact it might well be argued that Peter Schreier is exceptional, closer to Fischer-Dieskau in his treatment of text than to most singers of today. So one has to be careful about the kinds of conclusion one draws if one has only a few samples to hand, and this is true, needless to say, whatever approach one takes to studying performances.\n\nÂ¶31 To get much further into details of sound one needs technological aids. Iâve said earlier that at present much the best way of listening to a passage over and over is to have it in a computer sound editing package, selecting the passage and either playing it alone or setting the play control to loop it, so that it repeats over and over. Another thing a sound editor can do that is invaluable is to align several different performances in a single window, allowing us to switch between them as they play.\n\nÂ¶32 At the time of writing an ideal freeware audio editor is Audacity. Open the program, then, using File > Open , open Sound File 13 (wav file), Elena Gerhardtâs 1911 âAn die Musikâ with Arthur Nikisch. Then select File > Import and import Sound File 31 (wav file), 12 Gerhardtâs 1924 recording of the same song, accompanied by Harold Craxton. You should now have one above the other. If you press the Play button at this point Audacity will play both together. To listen to them individually, and switch quickly from one to another, either press Solo on the track you want, or Mute on the track you donât. Pressing Solo is of course the quickest way to switch, but Mute can be useful when you have more than two tracks and wish to hear some but not all of them together. If you want to hear exactly where the differences are you can align the two tracks so that the performances coincide exactly at any point you choose, then play them together to hear where they start to differ. To do this, select the Time Shift tool (the button is in a small panel of six just to the right of the Record button, and is marked with a two-way arrow: â). Then if you place the cursor on one or other track youâll be able to move it left or right. To play both tracks together make sure that neither Solo nor Mute is selected.\n\nÂ¶33 To make the comparison easier Iâve matched the pitches of the two transfers, reducing the 1924 by 74 cents (which of course makes it a little slower too, though not nearly as slow as the 1911). 13 Listening to these two performances side by side proves to be very interesting, and shows us similarities that it would be much harder to hear by listening to one CD at a time. By switching back and forth between the two we can quickly realise that although the rubato is very different, the way she shapes the notes with vibrato and loudness is not. Itâs actually almost the same performance except that (and itâs a big exception) her rubato, though considerable, is nothing like as great in 1924 and has a somewhat different character (itâs not just proportionately reduced). Itâs a modernised performance in that single respect. 14 And this gives us a very useful clue as to the way attitudes had already changed. Rubato was still very much part of current style, but not to the same almost dangerous extent (dangerous because the performance was always on the verge of stopping altogether) as in 1911. Although itâs so different, Gerhardtâs later recording, when studied closely like this, actually confirms the tentative suggestion made above that performersâ ways of approaching pieces tend to remain relatively stable through their adult lives.\n\nÂ¶34 We can see, using the same technique, another very striking example of this in Sir George Henschelâs two recordings of Schubertâs âDas Wandernâ, made in 1914 and 1928. 15 (We looked at his 1928 performance, as well as at its coupling, âDer Leiermannâ, in chapter 4.) The CD reissue by Cheyne Records of the 1914 HMV performance is lower and slower than either their or this bookâs transfer of the Columbia 1928 version. 16 (You can hear ours (by Andrew Hallifax) in Sound File 14 (wav file).) To enable the comparison I slowed down our transfer of the 1928 so as to reduce the pitch by 110 cents. Once the pitches match, so do the speeds (which suggests that at least one of the transfers was wrong), and the two performances are almost identical. Only some rubato differences in the piano interludes, and at two of the âechoâ phrases that end each stanza, cause the two to get out of synch. It might be tempting to suppose that 1928 was a dub of 1914, but in fact we have a control against which we can test. By matching the pitch/speed of my transfer of 1928 to the Cheyne version of the 1928 recording (a reduction of 28 cents in mine), and running the two simultaneously, one can easily see that here we have two performances that are genuinely identical: there is no variation in any detail, save only for a momentary speed fluctuation in the middle caused probably by an instability in one of the turntables. This gives us a measure, and enables us to use the 1914/28 comparison to say with certainty that Henschel was able to give almost but not quite identical performances fourteen years apart. 17 Weâve seen something similar, over almost thirty years, in Cortotâs recorded performances of Chopinâs E minor Prelude, back in chapter 6. 18\n\nÂ¶35 This is really very fascinating. Itâs an article of faith in most discussions of music-making that every performance is different, and so they are; but itâs also important to know that, when a performer plays a well-loved piece over and over in recitals and studios for years on end, their performance settles into an almost unvarying ritual. It is possible, then, to give substantially the same performance twice, indeed more than twice; how unusual that is remains to be seen from further studies. 19 (One must admit, too, that this is a composition that invites a very regular performance!) Experimental evidence suggests that memory for musical tempo is extremely stable, not unlike absolute pitch but in the time domain. 20 That being so it would not be surprising if expressive gestures in which rubato was a significant component were easily memorised and reliably reproduced over long periods of time.\n\nTempo mapping\n\nÂ¶36 Weâve seen several detailed examples in chapter 6 of tempo mapping in practice, and itâs easy to see from them why tempo rubato is such a powerful means of expression. Thereâs been a lot of research on this in recent years, with many studies by musicologists and psychologists charting tempo change in performances of orchestral and piano music. 21 Itâs well established, therefore, that tempo is worth studying closely. To date, three main expressive functions of tempo rubato have been investigated: tempo changes to point up compositional structure; to bring life to a performance; and to differentiate between more and less intense feeling. Naturally all three are related, but weâll look at them in turn.\n\nÂ¶37 1) Tempo changes to point up aspects of compositional structure. Nicholas Cook has looked closely at this in two of FurtwÃ¤nglerâs recordings of Beethovenâs 9th Symphony (1951 and 1953), comparing them to Schenkerâs analytical prescriptions for performance, and has shown how varied and how subtle are FurtwÃ¤nglerâs responses to the relative weight of different structural features in the score. 22 By the time these recordings were made it was already unfashionable to respond in such detail. Toscanini, whose manner was far more influential on younger conductors, chiming with modernist preferences, 23 took a more literal approach, but still one that responded carefully to the main structural divisions. We can see the contrast between FurtwÃ¤nglerâs and Toscaniniâs approaches in recordings of Beethovenâs 3rd Symphony made only months apart in 1952 and 53. Figure 18 maps the chief tempo changes in the exposition of the first movement, which can be compared to the changes in loudness indicated by the depth of the waveform. While both conductors use tempo rubato to point up structural features of the score, itâs very obvious that FurtwÃ¤ngler uses it much more often and more flexibly, an approach that turns out in retrospect to seem old fashioned simply because in more recent times conductors have become ever more literal in their realisation of scores, as JosÃ© Bowenâs comparative study clearly shows. Bowen examined a large number of performances of Beethovenâs 5th and found a clear trend towards slower speeds, despite the first-movement second subject gradually ceasing to be played slower than the first. 24 We also saw in chapter 6 examples of Fanny Davies deploying bass anticipations, which are rather complex instances of rubato acting at different rates in right and left hands. And in the examples of Ilona EibenschÃ¼tz and Alfred Cortot there were many points at which the compositional structure was being laid out before the listener. It happened much less later in the 20th century, as audiences were expected to work harder to understand the music by themselves.\n\nÂ¶38 2) Tempo changes to bring life to a performance. In a sense that is exactly what all these performers were doing; but it happens on every level, not just the structural. Sounds that are absolutely regularly spaced are not natural: if we hear them in life we attribute them to machines. Humans, as we shall see when we look at tapping along to recordings, are not capable of completely accurate timing, and the notion that slight irregularities in the appearance of things are indications of natural growth is so built-in to our perception of the world that itâs entirely understandable that we should see them as beneficial in musical performance. The influence of body respiration and pulse is obvious. So when we look at a sequence of equally spaced notes and find that they are not equally spaced at all, we may be seeing evidence of human imperfection, but we are perceiving humanity made sound and appreciating it. Sound File 32 (wav file) is Benno Moiseiwitschâs 1948 recording of Chopinâs Prelude in C minor, Op. 28 no. 20. 25 Figure 19 maps the beat lengths. The chords sound even, and yet itâs not dull, and thatâs because (as well as changes in loudness) Moiseiwitsch is lengthening the beats we expect to be lengthened, 26 especially the third of each bar, and because of the graduated lengthening of each four-beat group through the first first-bar phrase, gradual enough that we donât notice it unless weâre listening very closely indeed. The patterns in the next four-bar phrase and its repetition are slightly more complex but make sense in relation to the score. So the performance is far from mechanical, despite its apparent regularity; in fact, it seems alive. We looked in chapter 6 at examples of Chopinâs Berceuse, emphasising the vital importance in any performance of using rubato to allow the ostinato accompaniment to âbreatheâ, and we can see now why that metaphor is appropriate.\n\nÂ¶39 3) Tempo changes in order to map intensity of feeling. For equally ânaturalâ reasons, making metaphorical connections between musical sounds and shaped experiences we know from life, tempo change can very well model changes in intensity of feeling. An increase in speed in most contexts signals an increase in excitement, metaphorically linked to faster beating heart, faster breathing, faster locomotion. A decrease in most contexts will signal the opposite. Similarly, slowing tempo, combined with other signals, can indicate intensification of painful or loving emotion, modelling the way our attention and energy is drawn away from anything we may be doing with our bodies and channelled into the experience of emotion the deeper that is. Elena Gerhardtâs âAn die Musikâ at the start of chapter 4 was a very strong example, as her performance ground almost to a complete standstill at the high-points of phrases and we understood her to be overwhelmed by the intensity of her feeling about music. Weâve seen many examples on a much smaller scale, including the subtle rubato of Patti and Joachim, the more explicitly emotional narratives of Lotte Lehmann, in which tempo change plays a large part, and the endlessly varying rubato of Cortot. Rereading the discussion of Cortotâs playing of Chopinâs E-minor prelude, Op. 28 no. 4, from chapter 6 at this point will help to show how effectively finely-calculated tempo change can effect our perception of music in performance, as well as the extent to which changes in tempo and changes in loudness are intimately bound up, something worth bearing in mind whenever one does a study of tempo on its own.\n\nÂ¶40 On other point to bear in mind before we look at how to map tempo change is that it is the one mode of expressivity that is available to all instrumentalists. In extreme cases, outstandingly harpsichords and organs, players can do nothing else at all to be musical than vary the length and onset timing of notes; and so these instruments make especially good subjects for study if one wants to understand how rubato can work (assuming one can find a player capable of managing them, easier with harpsichords than organs because the action is that much more precise). Another very interesting subject, as yet wholly unstudied, would be the basic form of player piano, in which the notes are provided by the roll, and the player is left to focus entirely on modulating tempo to generate expressivity. I offer these as suggestions for readers to pursue.\n\nMapping tempo\n\nÂ¶41 You can do a certain amount of general work on tempo simply using a metronome. Itâs far from ideal, but if you follow a performance enough times, focussing on one section at a time and adjusting the metronomeâs speed to the tempo at that point, you can assemble a rough map of tempo change through the main sections of a performance. Because you need more than a couple of beats to fix the metronome, itâs not going to show you how tempo shifts from beat to beat. For recording the exact timings between each pair of beats there are currently two common techniques in use. The first, used in most published studies by musicologists to date, involves tapping along to the recording and using a simple computer program to record the time intervals between the taps. The resulting data can then be converted into a graph whose curves show the extent to which tempo is speeding up or slowing down through each beat of the score. The main disadvantage here is that itâs hard to be accurate. To tap exactly on the beat one has to know in advance when it will come, which means a lot of practice runs. In fact itâs best to record many runs, at least five, and average the results, not including any runs with significant errors of which one is aware. Even so, error will arise through mistakes in anticipation and through slow response time from ear to brain to finger to computer processor to RAM.\n\nÂ¶42 The second common method is more accurate but more laborious. One takes a visual representation of the sound file on computer and marks it up at the start of each beat; then one measures the time between each and notes them down or, if the program allows it, the computer records them automatically and exports them to a spreadsheet, where they can be graphed. This way you can be sure that you have the beats in very nearly the ideal placesâvery nearly because the point at which a beat is perceived to begin is not exactly the start of the sound signal for that note, but for almost all performance analytical purposes this method gives good enough results. This was the method I used in the graphs provided with chapters 4-6.\n\nÂ¶43 Iâve not given detailed examples of how to use either of these methods because there is now a better one that combines the two, provided by the freeware program Sonic Visualiser. (Of course, by the time you read this there may be a better way, in which case use it!) 27 Nicholas Cook has provided an admirably clear introduction to this at http://www.charm.kcl.ac.uk/analysing/p9_0_1.html, which it would be impossible to better, so I suggest that you read it now. The strength of this program is that it enables you to tap in markers which are added to a visual representation of the sound file (which may be either a wave form, which shows loudness and timing, or a spectrogram, which shows frequency as well). Then you can adjust the position of the markers by sight, checking against the sound as the file plays (slowed down if you like). You can export the data to a spreadsheet which will graph it automatically, or you can get Sonic Visualiser to do it and lay the graph on top of the wave-form or spectrogram. This makes it extremely easy to see exactly how a performer is matching changes in timing, pitch and loudness and so gives one a very powerful resource for observing and understanding expressivity in practice.\n\nÂ¶44 Letâs look at an example. Iâll assume that youâve downloaded Sonic Visualiser (SV) and have it running on your computer, and that you know how to import audio sound files. Sound File 33 (wav file) contains the first large phrase of Elena Gerhardtâs 1911 âAn die Musikâ. 28 Open it in SV (File > Import audio file). Youâll see the recording represented as a waveform. Click on Layer > Add New Time Instants Layer. Press the Play button and tap the semi-colon key on each beat of the performance. Youâll find it hard! When youâve finished, go into SVâs edit mode by clicking on the crossed arrows symbol on the edit toolbar. Your cursor should become an upwards-pointing arrow. Then youâll find that you can use that to move your time-instant marks back or forward until youâre happy with their position. You can do this by sight, looking for the loudness peaks at the start of each beat, but youâll get a more convincing result if you do it as far as possible by ear, because the loudness peaks donât always exactly match the perceived beats. When you play the file again youâll find your time-instants sounding as clicks or swishes on top of the music, which makes it slightly easier to decide when theyâre in the right place. (You can turn these off by selecting this layer with the vertical-lined tab near the top right of your screen and clicking the small green âPlayâ button near the bottom right.) My guess is that youâll never be entirely satisfied.\n\nÂ¶45 You can get a much better result, however, if you use a spectrogram display which shows not only the loudness of each moment but also the frequency of the sounding notes. That way you can see exactly where each pitch begins. Weâre going to use spectrogram displays more subtly later on in this chapter, but tempo mapping is another thing you can do with them. So click on Layer > Add Spectrogram. All being well you should see your beats superimposed on it. Play it to see how this works. You may find it helpful to adjust the grey dials at the bottom-right of the display in order to get a more detailed picture. Pull the vertical dial down until the light grey box immediately to its left is about a quarter to a fifth of the height of the whole grey column; then drag the lighter box down to the bottom. (You can get the same result by double-clicking on the dial and then typing in a figure around 4500. All youâre doing is setting the bandwidth of the visible area of the spectrum.) Pull the horizontal dial rightwards until you have plenty of horizontal detail, allowing you to see the individual notes easily. (Or double-click it and enter a value around 50.)\n\nÂ¶46 Now you can see where the piano notes start, and where the vocal notes change. Theyâre not always in the same places, and youâll need to choose exactly where to mark the onsets of at least some of the beats (âhol-â of âholdeâ is a particularly difficult one). Again, try to put the markers where you hear a beat, even if it looks wrong, though you should find that in this display it mostly looks exactly right. Seeing the notes as frequencies really does help, because what youâre looking at here is really a kind of super-score, showing not just the pitches and notional durations but everything that the performers do in sound. If you canât be bothered with all this, or are having trouble, there's one I prepared earlier at Data File 3 (sv file). If you click on the Time Instants tab near the top right of the screen (tab 2, if you use my file) you should see the beats marked on a moderately clear spectrogram displayâmoderately clear given that this is a very old recording with a lot of surface noise that the machine faithfully records.\n\nÂ¶47 One difference youâll notice if you open Data File 3 (sv file) and compare it with yours is that mine has numbered the beats within each bar. You can achieve this as follows. Select the time instants layer again. Select all the time instants (Edit > Select All). Then set up the beat counters for four beats in a bar (Edit > Number New Instants with > Cyclical two-level counter (bar/beat); Cycle size > 4). Finally renumber the beats (Edit > Renumber Selected Instants). All being well your beats should now be numbered 1.1, 1.2, 1.3, 1.4, 2.1 etc.\n\nÂ¶48 Now we can make a tempo graph. With the Time Instants layer on top select all the instants (Edit > Select All), and Copy them; add a Time Values Layer for the graph (Layer > Add New Time Values Layer), and Paste. In the dialogue box that appears select âDuration since the previous itemâ. Your tempo graph should appear. (By all means try the other options in the dialogue box, opening a new time values layer for each, and see what happens. Choosing âTempo (bpm) based on duration since previous itemâ, for example, will give you a graph that goes up to get faster and down to get slower.) With the new layer selected (tab 4 if youâre using my version) set âPlot Typeâ to Line or Curve to get a clearer display.\n\nÂ¶49 Use Layer > Add New Text Layer to add in the words at the appropriate places: âDu holde Kunst, in wie viel grauen Stundenâ. (If you place them inaccurately you can move them by using the crossed-arrows edit tool, just as for the time instants.) Or just open my version at Data File 4 (sv file). If you work your way along the tabs at the top right you should be able to assemble a composite picture that superimposes a tempo graph on the waveform, spectrogram, time instants and text. What weâre left with is something potentially very helpful, a display that shows at a glance exactly how long and how loud each note is, what its pitch is, and how quickly the tempo is getting faster or slower. Just about everything we need to know about the sound of Gerhardtâs performance is on screen, and all we have to do is to start to think about how it relates to the experience of hearing this performance. 29\n\nÂ¶50 One of the very obvious things we can say is that the rubato relates quite closely to the words. The main ritardandi happen on key descriptive words: âDu holde Kunst (You lovely art), in wie viel (in how many) grauen Stunden (dark hours)â, and then later on âKreisâ (crisis). Note too the swoops up to âholdeâ and âgrauenâ, and the way âholdeâ is shaped by vibrato getting wider and then narrower again, each component of the sound giving that moment greater emphasis. Each in fact could be thought of as a separate expressive gesture, although in practice they combine into one: each brings some expressive value to the whole. The loudest moments in the extract are in âwieâ and âmichâ, both doing expressive work, the former emphasising just how many dark moments have been relieved by music, the latter emphasising how personal this all is (as if we couldnât tell). Of course the huge extent of the rubato, coupled with the changes of dynamic and the pitch inflections (vibrato and portamento both varying expressively), add up to something far more extreme than we could possibly consider tasteful today, but thatâs beside the point. For reasons I outlined in chapter 4, this style made perfect sense to Gerhardt, and surely to at least some of her listeners, as the most intense expression of her love of music that she could communicate. And now itâs easy to see the elements that combine to generate it.\n\nÂ¶51 If she worked on this scaleâwith modifications of parameters from note to note as relatively large as thisâall the time, we might well find her singing impossible. This has to be accepted as a special case, I think (and one which, as we have seen, she moderated somewhat in her later, 1924, recording of the piece). Nevertheless, in studying other recordings by her we can expect to see similar sorts of gestures on a smaller scaleâand indeed, in her 1924 recording (Sound File 31 (wav file) above) that is exactly what we get: essentially the same gestures, but reduced in length. Their nature, if not their size, is characteristic of, in fact defines, her personal style, and fits plausibly within her period. A thorough definition of a personal or period style, then, could use these sorts of visualisation techniques to analyse its constituent expressive gestures.\n\nÂ¶52 For contrasting examples of tempo mapping put to use in performance analysis I refer you back, if I may, to chapter 6 and the discussions of EibenschÃ¼tz compared to Kempff in Brahms Op. 119 no. 2, and of Rubinsteinâs and more recent pianistsâ recordings of Chopin Op. 17 no. 4. They were produced by a similar process to that outlined above, though the EibenschÃ¼tz/Kempff used PRAAT rather than Sonic Visualiser. You can find ready-made markup files for a great many recordings of Chopin mazurkas within the CHARM website: http://www.mazurka.org.uk/ana/markup/. Select any highlighted recording and youâll be taken to details of the markup files available. Provided that you have a copy of that recording youâll be able to import both the recording and the markup into Sonic Visualiser or the freeware sound editor Audacity and use them for performance analysis of your own. Or of course you can start from the beginning, using the procedure illustrated by the Gerhardt âAn die Musikâ extract and make your own markups on any recordings you may wish to study.\n\nÂ¶53 Itâs tempo graphs like these that Craig Sapp has used to generate the graphic comparisons of performances mentioned in chapter 6 when we were looking at the Rubinstein examples. Sapp used a mathematical technique designed for comparing curves in order to compare the graphs of pairs of performances of Op. 17 no. 4. Youâll find examples at http://mazurka.org.uk/ana/hicor/ together with explanation of how they work. The Rubinstein comparisons are particularly interesting because of the clarity with which they show just how alike his 1938 and 1961 performances are. Yet to us, as listeners, they seem distinct, each fitting well within its surrounding period style. The later performance seems (and indeed the tempo graphs confirm this) to use narrower rubato, in keeping with the practice of other pianists active in the 1960s, while the earlier fits well within the habitual style of players in the 1930s. So how is it that Sappâs maps correlating tempo curves look so similar? Presumably what have remained constant are the places where Rubinstein places rubato, and the extent of it at each spot relative to the overall range of tempo change (which is narrower in 1961). Itâs also likely that listenersâ impressions will be affected by the relationship between rubato and changes in loudness which these images do not map. That too is probably contributing to our sense that these performances belong to different stylistic worlds. Itâs an example that can tell us quite a lot about how style change works and about how performers develop. Not many change as much as Rubinstein, but even when they do their personal styles, as fingerprinted in these analyses, are still sufficiently constant to differentiate them clearly from anyone else.\n\nÂ¶54 Another thing these images show is the relative uselessness of a measure of average tempo over a whole composition. Not only do all performances look alike when one reduces them to a single measure (the tips of Sappâs triangles), but one is ceasing to look at them at a level that has anything to do with the way we perceive music. There are questions that are worth asking about these more general levels, especially about the way speeds have changed over the last hundred years, which is what Bowen showed so clearly for Beethovenâs 5th symphony. 30 But on the whole the most fruitful levels for investigation are sufficiently near the surface of a performance (and a composition) to be perceptible with close listening. Sappâs analyses are particularly interesting because they show all levels: one can read the detail near the bottom and the generality towards the top. (Schenkerians will see the value of that at once.) They suggest just how much there is to be learnt from imaginative visual mapping of performance data taken from recordings. There is surely, in techniques of data analysis like this, huge potential for a new generation of scholars wanting to discover more about how music in performance works.\n\nÂ¶55 A final point before we move on to analyse expressive gestures, a point Iâve hinted at a couple of times but that needs to be made explicit: in most music-making rubato is not just a matter of tempo. Rubato works together with changes in dynamics, and the interrelationship is too complex to be understood as yet (an area that badly needs sophisticated empirical research). Nothing makes this clearer than the examples generated by Craig Sapp and Andrew Earis, using software developed by Earis that extracts the timing information from recordings and applies it to a plain MIDI performance of the score. 31 By this means itâs possible to hear fine pianistsâ rubato without its associated dynamic changes. Sound File 34 (wav file) allows you to hear the result, derived from a performance by a very well-known contemporary pianist of Chopinâs Mazurka Op. 17 no. 4. The result, as you can hear, is musical nonsense: there seems to be no reason for notes to be as long or as short as they are. The example warns us that tempo mapping is only part of the story: timing only makes sense in relation to other parameters, and itâs understanding the interrelationship that is the key to understanding performance. It offers us the exciting prospect that there is fundamental research on musical performance waiting to be done.\n\nSpectrographic displays of expressive gestures\n\nÂ¶56 Weâre now in a position to focus on the analysis and interpretation of expressive gestures at a relatively detailed level. Iâm interested in what makes individual notes or small phrases meaningful, expressive of something. For this weâll need to use the spectrographic capability of Sonic Visualiser or any other spectrographic software. We need to begin with some introduction to spectrograms, their capabilities and their limitations. 32 Then weâll be in a better position to interpret what we see. 33 Iâm going to start with a very basic description of what you can see in two related examples. 34 If youâve seen enough spectrograms to understand this already then skip to the discussion of the second, which introduces some useful information about the spectra of words.\n\nÂ¶57 Plate 10 is a spectrogram of an extract from Heifetzâs c. 1926 recording of Schubertâs âAve Mariaâ, arranged by August Wilhelmj for violin and piano. The sound file is Sound File 35 (wav file). 35 If you have Sonic Visualiser to hand you can load Data File 5 (sv file) and use that instead of the picture. 36 On the vertical axis is frequency, indicated by a scale in Hz on the left, and you can see that this picture shows frequencies between 21Hz and 3400Hz (remember that middle A is at 440Hz); on the horizontal axis is time (this extract lasts 19 seconds, which will give you an idea of the scale); loudness is shown as colour, from dark green for the softest, through yellow and orange, to red for the loudest sounds. What you can see here is a map of all the frequencies that sound louder than about -50dB. In fact most of the musical sounds shown are louder than about -30dB, the rest is surface noise from the 78rpm disc which looks like a green snowstorm in the background. Try to ignore that and focus on the straight and wavy lines in brighter colours. The straight lines nearer the bottom of the picture are frequencies played by the piano, though the first note of the violin part is pretty straight too since Heifetz plays it with almost no vibrato. All the wavy lines, of course, are violin frequencies, wavy because of the vibrato which at its deepest is about 0.75 semitones wide. So although the violin and piano frequencies are displayed together, the violin vibrato makes it fairly easy to tell which notes are which. The violin is also much louder most of the time, especially because its notes donât die away as the pianoâs do, so the violin notes are sounding higher frequencies further up the picture. The bottom of the picture is fairly confused, which is quite normal because the fundamentals are relatively close together. We can alter this in SV by selecting âlogâ instead of âlinearâ: it produces very wide frequency lines at the bottom but at least you can see more easily where the notes are on the vertical axis. Of course itâs along the bottom that the fundamentals are shownâapart from artefacts of the recording (which we have here right along the bottom at 21Hzâignore those) the fundamentals will normally be the lowest frequencies present and the ones you perceive as the sounding pitches. All the rest of the information on the screen is about the colour or timbre of the sound.\n\nÂ¶58 You should be able to see without too much difficulty that the piano is playing short chords on fairly even (quaver) beatsâlook at the 473Hz levelâand because the display is set up to show evenly spaced harmonics, rather than evenly spaced frequencies, you can see the violin harmonics as evenly spaced wavy lines above, and much more clearly than the piano harmonics which disappear into the snowstorm much more quickly. (There are some visible though at about 600Hz and 750Hz.) Heifetzâs vibrato is quite even, and you can see that the frequencies between about 1500Hz and 2100Hz are louder than those immediately below and above. This is an important element in Heifetzâs violin tone in this recording. The fundamental and lower harmonics are obviously much stronger, giving the sound warmth, but these strong harmonics relatively low down in the overall spectrum give it a richness without the shrill effect weâd hear if these stronger harmonics were higher up. The other feature thatâs very obvious is Heifetzâs portamento about three-quarters of the way through the extract.\n\nÂ¶59 Now compare this example with Plate 11. You can find the sound in Sound File 36 (wav file) and the SV setup in Data File 6 (sv file). 37 The SV settings are the same but the two images are not to the same scale.\n\nÂ¶60 This spectrogram shows a performance of the same extract of the same composition, but now as sung by John McCormack in 1929. 38 What I want to show here is how the words make a very big difference to the sounding frequencies. McCormack sings in English, âSafe may we sleep beneath thy care, Though banish'd, outcast and reviledâ. His accent is not quite what weâd expect today; my text annotations on my SV file reflect his pronunciation. Naturally the spectrogram shows information about the colour of his voice but itâs extremely difficult to work out where that information is, because most of the patterning in the spectrum of his voice is information about his pronunciation of the words. Acoustically, vowels and consonants are patterns of relative loudness of the sounding frequencies across the spectrum. Vowels are made by changing the shape of oneâs vocal cavity, and the effect of that is to change the balance of harmonics in the sound. That balance will remain the same whatever the pitches one may be singing and (though to a lesser extent) whatever the tone of oneâs voiceâto a lesser extent because the colour of a voice colours the vowels too, making them âdarkerâ or âlighterâ, and singers can shift vowels around the vocal cavity, making them all darker or lighter, in order to change listener responses. 39 So the visible information in this spectrogram is much more informative about the words McCormack is singing than about the sound of his voice. You can see how similar the spectrum pattern is for the first two syllables, âSafe mayâ, whose vowels are the same. The same goes for âwe sleep be-â, and between âeeâ and âbeâ you can just see the âpâ of âsleepâ as a vertical line, indicating the noise element (almost all frequencies sounding for a moment as the lips are forced apart by air) in âpuhâ.\n\nÂ¶61 You can get a feeling for the way in which changing the balance of frequencies changes the vowel if you imitate McCormack saying âcairâ (of âcareâ) âarâ (of âbanishedâ, which he pronounces as something more like âbarnishedâ)ââcai arââand feel how close those vowels are in the mouth. Youâll see what changes in the picture as you move from one to the other: just as the vowel moves back and down in the mouth so higher harmonics are stronger in âairâ and lower harmonics in âarâ, and youâll sense that as lighter and heavier or brighter and warmer sounds respectively. Similarly if you compare yourself saying McCormackâs â(th)âoughâ and his âouâ(t-), youâll feel the movement of the vowel up the throat and the widening of your mouth, and itâs easy to sense how that produces the change in spectrum you can see in the spectrogram: a small loudening of the harmonics from the third harmonic upwards, producing a slightly âbrighterâ sound compared to the âdullâ âwarmthâ of âoughâ. Itâs a useful exercise that sensitises one to the ways in which harmonics colour sounds of all sorts.\n\nShortcomings of spectrograms\n\nÂ¶62 Now we know something of what weâre looking at in spectrograms itâs important to know, too, some of the pitfalls in reading them. First, although the computer maps the loudness of each frequency fairly exactly from the sounds coming off the recordingâin an ideal recording situation showing how loud each sound âreallyâ is in the physical worldâthe human ear has varying sensitivity at different frequencies. Any textbook of basic acoustics will include a chart of frequency curves which shows just how much louder (in decibels (dB) which measures sound energy) high and especially low sounds have to be before we perceive them as equal in loudness to sounds in the middle. Our greatest sensitivity to loudness is in the 1-4kHz range (esp 2-3kHz)âprobably evolved because this range was useful for identifying transient-rich natural sounds, helping our ancestors identify the sources of sounds in the environment accurately and quicklyâbut it now makes us especially sensitive to vowels in speech and tone colour in music. Nevertheless our ears seem to hear the fundamental most clearly, because itâs not interfered with by the vibrations of the harmonics to the same extent as the harmonics are by other harmonics, so itâs easier for our ears to identify with certainty (the nerve cells in our ears fire without interference from others firing with different frequencies nearby); but the loudest information is often from the harmonics. If instruments and voices had their fundamentals much higher up the scale, in the 1-4kHz band, music would be a lot less colourful. Similarly, the sensitivity to different degrees of loudness that we need for direction-finding allows us to be aware of this wide range of tone colours that we donât otherwise need in an evolutionary sense. So that range between about 1-4kHz is important for the information it carries about tone, and we perceive it as louder than the computer does. Consequently a spectrogram doesnât colour those frequencies as brightly as it would need to in order to map our perceptions.\n\nÂ¶63 Another thing to bear in mind is that the higher up the spectrum you go the more the ear integrates tones of similar frequencies into âcritical bandsâ, within which we donât perceive independent frequencies. For example, 40 a 200Hz frequencyâs higher harmonics at 3000, 3200, 3400Hz all fall within a single critical band (3000-3400) so for us are integrated, meaning they are not perceptibly different. Thereâll be no point, therefore, in trying to attribute to small details within that critical band any effects we hear in a performance. On the other hand, the auditory system enhances contrasts between these critical bands, so some sounds that look similar in a spectrogram may be perceived as quite strongly contrasting. Moreover, louder frequencies can mask quieter, so that the latter donât register with our perception at all. For all these reasons (and more), what comes into our earsâwhich is a reproduction of the same signals that the computer measuresâis different in many respects from what we perceive psychologically. 41\n\nÂ¶64 Itâs important, too, to be aware that seeing sounds in a spectrum display encourages one to hear them. This can be a very good thing, sensitising one to aspects of sound that one previously ignored. But equally it can lead one to attribute disproportionate significance to visible details. Not everything one sees on the computer screen is as audible as it is visible, and (especially in the case of synthetic effects like timbre) vice versa. So one has to use a spectrogram together with what one hears; itâs not something to be read but rather to be used as an aid to pinpointing features of which one is vaguely aware as a listener; it focuses oneâs hearing, helps one to identify and understand the function of the discriminable features of the sound. In this role itâs the most powerful tool we have.\n\nÂ¶65 Sound File 20 (wav file) is Fanny Daviesâs recording of Schumannâs DavidsbundlertÃ¤nze, book 2 no. 5, whose triple layering of melodic lines we discussed in chapter 6. Data File 7 (sv file) is a SV setup which tries to reveal the individual notes as clearly as possible (given the noisy recording). We can use this now (if we have the patience) to measure the exact timings and loudnesses of every note. I recommend playing the SV file a few times to get used to picking out the three layers visually. Then use the mouse and the readout in the top right-hand corner of the spectrogram to get the loudness of each note in dB, placing the mouse-tip on the brightest part of the start of each note. In fact the notes are not strictly layered in loudness nor as evenly played as you might think listening to the recording, but the loudness of each needs to be understood together with its timing, which can also effect our sense of its weight, as of course does the compositional structure which gives notes different perceptual weight in relation to the surrounding melody and harmony. The bass line is consistently quieter, but the inner arpeggiated accompaniment is often as loud as the melody: what makes the melody seem louder is of course its place at the top of the texture and at the start of many beats, whereas the middle voice tends to be quieter at the beginning of the bar and then to crescendo as it rises up the scale through the bar. None of this is at all surprising.\n\nÂ¶66 Much more interesting is Daviesâs rubato, of which we can get a vivid impression by using SVâs playback speed control. This is the dial in the bottom right-hand corner. Double-click on it and enter -130 in the box, which slows the performance substantially, and listen carefully. According to the score the notes come evenly on successive quavers. Daviesâs second quaver, the first of the inner voice, comes on the fourth (what would be the fourth if she were playing in time at the speed she takes the inner voice once it gets going), which establishes an intention to linger at each new minim beat. After the second melody note she waits an extra quaver before continuing with the inner voice; later this gap becomes about a quaver and half; and now we can hear much more easily just how the inner voice waits for melody and bass at the top of the phrase, and just how much the arpeggiation of the left-hand chords contributes to this miraculously subtle performance. One could map this out as a tempo graph, but actually in this instance one learns a lot more simply by listening at a slower speed, focussing the attention of oneâs ears on the placing of the notes one also sees. Itâs a powerful aid to understanding.\n\nÂ¶67 We already discussed Benno Moiseiwitschâs crescendoing piano notes and now we can use SV to see how they work. (Sound File 22 (wav file) and Data File 1 (sv file).) Click on the Select (arrow) tool in the toolbar and move the mouse across the screen and youâll see an orange ladder whose rungs mark the expected positions of the harmonics of the note at the bottom. If you move the ladder over the any of the crescendoing notes (at ca. 11 secs and 36 secs at 950Hz most obviously, but there are others) youâll see that treating those frequencies as the third harmonic above the fundamental places the fundamental on a moderately strong lower frequency, whose partials are apparently reinforcing the melody note, causing it to get louder again. Resonances are being set up which cause the melody string to vibrate more vigorously for a moment, and they may have partly to do with that particular instrument or even with the recording room or equipment: itâs interesting that the same B-flat figures twice, suggesting that one of the elements in the sound reproduction chain is particularly sensitive to that frequency. So we shouldnât wax too lyrical about Moiseiwitschâs skill in balancing harmonics! Nevertheless, the overlapping of melody notes, hanging onto the last for some while after playing the next, is very clear from the spectrogram and gives one some useful insight into his piano technique.\n\nÂ¶68 Turning to string playing, itâs extremely easy to use SV, or any program that gives a readout of frequency and timing, to measure vibrato and portamento. Sound File 37 (wav file) and Data File 8 (sv file) derive from Albert Sandlerâs 1930 HMV recording of Schubertâs âSerenadeâ, arranged for violin and piano. 42 Using SV and the select tool choose a long violin note with at least five full vibrato cycles, and choose a harmonic that gives a large clear display. The vibrato cycles are going to be the same length in time (theyâll have the same rate) and the same width in pitch (the same extent) whichever harmonic you take, but if you have a choice use one of the higher harmonics because the resolution of the spectrogram is better the higher you go. Click on the first peak and drag the mouse along five peaks (ten is better, but in most pieces not many notes are that long). Read off the duration of your selection from the numbers at the top of the selectionâit will be around 0.7 secs (the exact length depending on which note you choose, because Sandlerâs vibrato rate varies). Simple mental arithmetic (0.7*2/10) will tell you that in that case each cycle takes about 0.14 secs, which gives you Sandlerâs vibrato speed at this point (itâs about 7 cycles per second if you prefer measurement in cps).\n\nÂ¶69 Working out the depth (extent) of vibrato is a little more complicated. First of all, with the spectrogram tab selected, change âBinsâ from âAll binsâ to âFrequenciesâ. Set to âAll binsâ you see the frequency range (the width of the bin) that SV has actually measured; how wide this is depends on your choice of Window size in the box above. Thereâs a trade-off between accuracy of timing and frequency, so the larger the window size you accept the more approximate the timing information but the more precise the frequency information youâll get from the display will be. (When you increase the window size increase the overlap as well to recover some of the timing precision.) âFrequenciesâ gives you an estimate of the frequency actually present in the bin, which lies somewhere within the range SV has measured. So setting âBinsâ to âFrequenciesâ gives you a much more precise display of the frequency SV thinks you are hearing.\n\nÂ¶70 Now using the select tool, place the mouse tip at the top of a typically-sized vibrato cycle. Ideally, get it right on the band of colour representing the frequency; 43 then move the mouse down to the bottom of the cycle. If you miss, keep the mouse over the box youâve drawn and press the delete key. Try again. When youâve got it right, read off the interval width in cents displayed beneath the box. (It may be shown only in cents (e.g. 86c) or as a number of semitones (each worth 100 cents) plus or minus a certain number of cents (e.g. 1-14c): in that case youâll have to make the addition or subtraction yourself.) To assess vibrato width properly you need to measure more than one cycle. If you want an average then youâll need to measure a great many, because as weâve seen vibrato in players born after about 1875 varies according to musical context; but if you want to examine that variation then a smaller number of readings chosen from the contrasting passages that interest you will suffice.\n\nÂ¶71 Portamento can be measured using the same tools. Here weâre interested in the pitch space covered, how long it takes, what shape of curve it is, and how the loudness changes during it. Working out the properties of the curve is not a trivial task, and for most purposes may be overkill, 44 but spectrum displays can be very helpful in enabling one to understand how prominent portamenti seem to be when one listens. Anything smaller than about 0.03 secs is imperceptible so may as well be ignored except as evidence of finger technique, like the small slide up to the first violin note in this Sandler extract. The first real portamento (starting at 13.67 secs) is unmissable at about 0.2 secs long. Itâs often impossible to be precise about the length of a portamento slide, and the slide that starts at around 19.2 secs shows why. The vibrato runs into and out of the slide: thereâs no way to decide, without first conducting a programme of perceptual experiments, when the rising vibrato cycle at the end of the lower note stops and the slide begins, or when the slide ends and the new vibrato cycle on the upper note starts. 45 It is pointless to worry about these details at present. Spectrum displays make it all too easy to indulge in excessive precision which has no perceptual significance. But used sensibly they can teach us plenty about how devices like portamento work.\n\nÂ¶72 The same techniques could be used to study vibrato and portamento in singing and wind playing. Here, as also in violin playing, an important feature can be intensity vibrato, thatâs to say, regularly fluctuating loudness as well as or instead of fluctuations in pitch. For listeners itâs often extremely hard to tell intensity from pitch vibrato, 46 and measuring intensity vibrato is a little more difficult because you have to take readings in decibels from several points (and the same points) in each of a representative sample of cycles. But it is common and needs to be taken into account. 47 An interesting but challenging example is Germaine Martinelli in Schubertâs âDie junge Nonneâ, a song of which weâll hear more in a moment (Sound File 6a (wav file)and Data File 9 (sv file)). Using the spectrogram display you can see here how her vibrato is louder at the extremes of each cycle than between them, and also just how irregular it is in pitch, especially when she is modelling the young nunâs fear (compare the somewhat more even âHallelujasâ as the end). Switching in the wave-form display (tab 3 in Data File 9 (sv file)) 48 it becomes extremely easy to see the considerable extent of Martinelliâs intensity vibrato (look at 8.5 secs, for example); and the passage from 1.04 mins reveals how that extent tends to increase as she sings higher and louder, even though her pitch vibrato remains relatively steady.\n\nÂ¶73 Changes in loudness among the harmonics during vibrato produce changes in timbre or vocal colour. 49 We can study timbre vibrato quite easily using Sonic Visualiser. In Data File 9 (sv file) the layer tab with the little blue graph icon (probably tab 4, though SV sometimes reorders them) selects a spectrum analysis. This graphs the loudness of each frequency across the whole spectrum at the ânowâ point (i.e. the central white bar), and as you drag the display across the bar youâll see the graph change as the frequencies change their relative loudnesses. Using the note at 1â07â as an example, drag the display across the bar and youâll see the heights of the loudest three or four frequencies (the highest blue steps) alternating as you move through the vibrato cycles. (There are other changes, clearest below the vocal fundamental, due to the continuing orchestral accompaniment.) You can find out which harmonics these are by selecting the âMeasureâ tool (with the compass icon, at the right-hand end of the Tools toolbar above the display) and moving the mouse over the tips of the blue spectrum display. The orange full vertical line marks the fundamental and the short lines the overtones. You can do the same in the spectrogram layer if you wish. (Switch back to the âNavigateâ tool (the hand icon) before going back to the spectrum graph layer, however.)\n\nÂ¶74 You can produce a more easily readable display, albeit at the expense of obscuring almost everything else, by changing âPlot Typeâ from âStepsâ to âColoursâ. Move the display across the bar again, using the same note at 1â07â, and youâll see the loudness of each harmonic indicated by bands of colour. Itâs now very easy to see how, as each pitch/intensity cycle of the vibrato goes by, the colour (=loudness) of the fundamental and third harmonic alternate in relation to the second. If you want to see this change while the file plays, you first need to go back to the first tab, with the general settings for the session, and change âFollow Playbackâ from âPageâ to âScrollâ. Now if you return to the combined spectrogram and spectrum analysis and press âPlayâ, youâll see the spectrum analysis changing, mapping the changing timbre, while you follow the performance. You can use the speed control (bottom right dial, next to the volume control slider) to slow it down for a better chance to grasp what's going on.\n\nÂ¶75 Having looked at the changing timbre, now we need to use our ears. With the spectrogram layer on top, move ahead to approx. 1â41â and, using the âSelectâ icon (the arrow), select 1â41.3â to 1â42.4â. Press the âConstrain playbackâ and âLoop playbackâ icons (immediately to the left of the S-shaped icon). Slow the playback speed to -580%. Bring up the waveform display so that you can see how the loudness varies regularly within each vibrato cycle. (It may help to increase the horizontal magnification, using the horizontal grey dial.) Now press âPlayâ. What youâre hearing, all being well, is a significant change of timbre from the top to the bottom of each vibrato wave. 50 Although the waveform is telling us that thereâs a very large difference in loudness, the highest point of the vibrato wave much louder than the lowest, we donât hear it that way: we hear the timbre changing. And if you switch in the spectrum layer set to âStepsâ youâll see that confirmed: the loudest frequencies are more or less equally loud throughout the vibrato cycle, but their width changes. Thereâs a wider frequency band for each harmonic on the way down the vibrato curve and a narrower (more spiky) band on the way up, producing a âwarmerâ (more consonant) sound on the way down and a âbrighterâ (more focussed) sound on the way up. Itâs a very clear example of a timbre vibrato. The measurable but hardly perceptible intensity vibrato is a simply by-product.\n\nÂ¶76 These effects appear to be, to some extent, dependent on text. With the spectrogram layer back on top, place the mouse over the vertical blue line that marks the left-hand selection boundary, and when the cursor becomes a double-ended arrow, click on it and move it leftwards, back to 1â39.3â. Your selection should now cover 1â39.3â to 1â42.4â. We now have two notes selected, both on the same pitch. The French text here is â[flÃ©-]tri-eâ, and so the vowel changes. 51 Itâs the âeâ vowel that weâve been listening to and that produced such a marked timbre vibrato, whereas the âiâ is much more confused, the loudness of the harmonics in constant irregular flux. We can see that with different vowels the harmonics interact quite differently, with consequences for timbre, at least in Martinelliâs voice, that go well beyond the simple fact of the vowel having different loudnesses for each harmonic. Using the tools provided by Sonic Visualiser we can make a useful start at analysing these kinds of details.\n\nÂ¶77 Pitch, loudness and timbre may all be cycling in vibrato, therefore, and in highly complex ways; and it seems probable that this causes the effect identified by Metfessel (1932) as âa halo of tone colouringâ or âsonanceâ, enriching the perceived tone of the perceived note. 52 To make matters yet more complex, Metfessel finds that the shape of the vibrato cycle differs between singersâa phenomenon Iâve not attempted to study here but that needs much more research. 53 All this suggests that vibrato is a far more complex phenomenon, with more ramifications for the effect of a performance on the listener (including the effects we perceive as expressive), than we have yet understood. There is a lot of very fascinating work to be done.\n\n8.3. Sounds from speech, sounds from life\n\nÂ¶78 With singing there is inevitably much to be observed about the treatment of the text. Letâs begin by looking at signs of deep emotion in early 20th-century singing, and two in particular, the Italian sob and the German swoop. These seem to have much the same function and itâs not impossible that they are simply equivalents in two different stylistic languages. In an earlier article I wrote about Carusoâs sob, 54 and we can use SV to look at another example. (Sound File 38 (wav file) and Data File 10 (sv file).) This one comes from an irresistibly unlikely source, a 1930s recording by Max Meili of the late-medieval Italian lauda âGloria in cieloâ issued on the LâOiseau Lyre âAnthologie Sonoreâ label. 55 The first of several sobs comes at 14.7 secondsâaccording to SV it lasts 0.13 secsâand a second, more spectacular, at 51 secs, lasting 0.22 secs. If you select it, without the sounds on either side, and if on the toolbar you click the âConstrain Playbackâ and âLoop Playbackâ buttons and the press âPlayâ youâll hear what it is. Itâs a falsetto note approximately an octave above the destination pitch (a little lower in the first example, higher in the second) andâas youâd expect from falsettoâwith only the lower harmonics sounding. Itâs very quick and it curves up and then down, leading through an imperceptibly fast portamento into the main note. Its expressive effect relies on its similarity to an involuntary sob in a male: a sharp intake of breath reacting to sudden emotional stress forces air through the vocal chords without them having time to vibrate fullyâhence the falsetto. Itâs this effect that was such a regular feature of Italian male singing in the early 20th century and still lives on in the opera house in performances of 19th-century Italian opera. Why Meili thought it suitable in a lauda is anyoneâs guess, but the text is âGloria in cielo e pace in terra. NatâÃ¨ il nostro Salvatoreâ (Glory in heaven and peace on earth: our saviour is born), so heâs inviting us to be deeply moved at the thought of the birth of Jesus. More curious still, he was Swiss, from Winterthur, and studied in Munich. But in any case thereâs no doubt about what this sob means, nor about how it means it. Analysis of the sound provides a clear explanation for the effect we perceive. Itâs an emotional signal applied to the start of a note whose text carries special significance, used at a point in the composition where it can be achieved relatively naturally.\n\nÂ¶79 Similarly the German swoop, which is much more common and obvious in female than in male singers, leads into a note, usually setting text with special emotional value, and at places where the composition allows it. So their function and placing are similar, even though national style and gender are not. Again, swoops can be so fast that one perceives them as emphasis of some sort rather than as slides up to a note, although thatâs what they are. Weâve mentioned them already in discussing Lotte Lehmannâs style, where they are much used as signals of deeper feeling, and in Schwarzkopf where I suggested that they had, in a different and more detached expressive environment, become signals of irony. And most recently we saw striking examples in Gerhardtâs singing of âAn die Musikâ where they clearly signalled strong feeling tied to descriptive words.\n\nÂ¶80 For a detailed example Letâs look at an extract from Lotte Lehmannâs 1941 recording of Schubertâs âDie junge Nonneâ. (Sound File 39 (wav file) and Data File 11 (sv file)) 56 This is a transfer from a noisy original but one can still get a good enough spectrum display out of it to be useful. 57 A casual listen suggests that Lehmann is emphasising several of these notes, especially at âfinsterâ (dark), âNachtâ (night) and âGrabâ (grave). Itâs a Gothic-horror text in which the young nun of the title sings of the storminess of her previous life which sheâs leaving behind for the peace of the convent and marriage to God. But Schubertâs music strongly suggests that her dark past is still very much with her, 58 so Lehmann is making the most of something thatâs very clearly implied in the composition. A closer listen suggests that at least some of these notes are swooped up to from below, and that that is what gives them emphasis; and indeed if we look at the spectrogram we see that almost all are. The following table shows by roughly how much. (You get different results, incidentally, depending on how you set the Bins option: slides register as shorter the more precise the setting; for the readings below Iâve used Peak Bins.)\n\nÂ¶81 So these swoops at first get smaller and shorter. âDieâ (the) has none, since the word has no expressive content. But âNachtâ (night) is stretched out, which compensates for the narrower distance and makes it more obvious than the rest. âUndâ (and), incidentally, is probably emphasised because it starts the phrase, and this whole phrase Lehmann intends to be intensely eerie. Another thing this example shows is that you can swoop up to repeated pitches, and singers often do so in order to give emphasis where the composition doesnât help. Here the monotone has its own expressive value, which Lehmann aims to enhance. The next phrase repeats the first a semitone lower and shows a similar pattern of swoops.\n\nÂ¶82 And then the chilling conclusion, with the swoops drawn out into a glissando up to âGrabâ:\n\nÂ¶83 What does all this signal? Itâs possible that swoops make metaphorical connections with the same indrawn breath modelled by sobs, or some other index of shock and fear, providing what Iâve called the Gothic-horror element in this performance. An intermediate, or at any rate a very closely related source is to be found in speech. We compared examples of Lehmann reading and singing in chapter 4 (Sound Files 16 (wav file) and 17 (wav file)) and they illustrate a connection we can see again and again in expressive singing between song and speech. Expressive sounds from speech are taken into song, bringing with them the same expressive value. Or perhaps itâs not so much that song borrows from speech as that both draw on sounds with associations that may well pre-date speech, vocal responses of humans to deep emotion. 59\n\nÂ¶84 Iâve provided a lot of examples of speech-associated gestures in an article on âExpressive Gestures in Schubert Singing on Recordâ, using extracts from recordings of âDie junge Nonneâ and other Schubert songs from across the 20th century. 60 The following extracts are quoted here (slightly shortened and now with sound clips) because they provide a range of examples onto which we can add in order to start to assemble a list of types of analogue between musical performance gestures and sounds from life. In that article I showed a modern singer, Kathleen Battle, using the vocal signals of various states of mind to signal emotional states in Schubert songs , beginning with âDie MÃ¤nner sind mÃ©chantâ.\n\nÂ¶85 In the text, by Johann Seidl, a girl tells her mother that she was quite right to distrust her daughterâs lover; she has just seen him kissing someone else. She begins, âYou told me so, Mother, He is a tearawayâ (âEr ist ein Springinsfeltâ.) (Sound File 40 (wav file)) 61 Knowing the text, it is fairly easy for most listeners to Battleâs recording to agree that this passage makes a general impression of disgust, an emotion that Gabrielsson and Juslin tell us has rarely appeared in empirical studies of musical emotion, perhaps because it needs more clues than just sound to identify it unambiguously. 62 Here the text and sound together leave little room for doubt. But what produces that effect? âErâ starts loud and slightly sharp (suggesting a shrill manner of speech). âErâ is connected by a portamento slur to âistâ, so âErâ seems hissed by association (Errissst). âIstâ is dead straight, the pitch sounds for less than a third of length of the beat, the rest is âsssâ. The sharp âtâ of âistâ is attached to âeinâ and gives âeinâ some bite, which it couldnât otherwise have; and Battle also gives it a nasal tone and a very fast upper mordent (âe/\\inâ). âShâ (of âSpringinsfeltâ) is all higher frequency and starts early, exploding into a loud âpringâ which starts straight, then slides in a continuous portamento down through âinsâ to âfeldâ. And thereâs a hairpin crescendo-diminuendo through âinsfeldâ, giving a thrown-away end to the word that perhaps suggests dismissal.\n\nÂ¶86 These are all expressive gestures, evoking sounds from life. Some are onomatopoeic, the âisssstâ which weâve learned to associate with hate and in particular, a threatening hate that could lead at any moment to violence. Then there are the sudden explosive consonants, âT-einâ and âshPRingâ, evoking the sound of sudden violence. And the rapid diminuendo at the end of a phrase that evokes a dismissive turning away.\n\nÂ¶87 Many kinds of gestures in song come direct from speech. The meaning of a sound gesture in speech is transferred to singing by converting the speech gesture into something with a more precise pitch and duration determined by the requirements of the musical context. Often the speech gesture invoked is determined by the text, but by no means always. Thereâs an example in Battleâs recording of Schubertâs âRastlose Liebeâ (Sound File 41 (wav file)) 63 where she sings âOhne Rast und Ruhâ (without peace or rest). In Battleâs wildly restless performance âohneâ is the word given the largest gesture in the phrase, not because it is the most important word but because Schubertâs setting puts it in the most expressive place, and the singer can get the strongest effect by working with that. This emphasises that gestures borrowed from speech donât necessarily have to arise from the text in order to work; their expressive content in speech may be taken over and applied in music, either because their emotional content works effectively in a musical context or simply because the sound seems right. (Clearly this has implications for our understanding of expressivity in instrumental music, to which I shall return below.)\n\nÂ¶88 What about the general character of Battleâs voice in this performance? This is not how Battle normally sounds in Lieder. A more typical extract, which conveniently includes both her lyrical and her characteristic clipped styles would be âLachen und Weinenâ. (Sound File 42 (wav file).) 64 So whatâs different about âRastlose Liebeâ? In âRastlose Liebeâ Battle doesnât just make âOhne Rastâ a continuous portamentoâwe can hear thatâshe also changes her vibrato, speeding it up by around 10% from her usual rate (which is very roughly 135ms per cycle as opposed to 150 here) and reducing its width by around 30%. The effect is that she sounds terrified. This is a neat example because it shows so clearly how effects that we all recognise immediately as signs of terrorâracing heart, tremor in oneâs voiceâcan be reproduced analogously, indeed almost literally, in singing, and they inevitably cause us to share [or at least to recogniseâmore about this distinction below] some of the feelings that would normally evoke them. Thereâs lots of research along these lines. The motor theory of speech perception, 65 Juslinâs functionalist perspective, 66 Slobodaâs dynamic awareness , 67 Coxâs mimetic hypothesis, 68 Watt & Ashâs hypothesis that the action of music is to mimic a person, 69 and indeed, Peter Kivyâs contour theory, 70 further developed by Stephen Davies: 71 are all describing this phenomenon, and it seems evident that this is a fundamental key to understanding musical communication. We read sounds through what our bodies would do to make them. The truth of that is particularly clear in this example, because the causes and effects are so obvious and easy to identify. But the same process is likely to be working in much less obvious cases as well.\n\nÂ¶89 My next few examples all come from Schubertâs âDie junge Nonneâ, whose psychological portrait of a disturbed young woman offers us the chance to study the vocal representation of fear in more detail.\n\nÂ¶90 Meta Seinemeyer, in a recording from 1928 (Sound File 43 (wav file)), 72 contrasts the opening phrases, in which key words (Wipfel, Balken, Donner) are hit hard through initial consonants sung at full amplitude, with the softer-edged âUnd finster die Nachtâ, whose sounds crescendo up to their full strength (which is less than for the hard notes). She also slows down for them, but thatâs less crucial. The speech analogy is obvious: spitting-out sounds evoke anger in speech and by analogy the fury of the storm; crescendoing sounds evoke something more complex, since there are a number of situations in which we might crescendo through a sound in speech. Mystery tinged with fear might be one, and is perhaps what is evoked here. But one can also think of the contrast between hitting and stroking or pushing. Thinking visually one would call on hard edges contrasted with blurred. All these are obvious equivalents using different senses, equating to the perception of this passage of sound. To pin a precise meaning onto these sounds at âfinster die Nachtâ would be silly, because it would be to attempt to make prec"
    }
}