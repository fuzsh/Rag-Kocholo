{
    "id": "dbpedia_8293_0",
    "rank": 48,
    "data": {
        "url": "https://forum.proxmox.com/threads/vm-stops-crashes-while-cloning.137978/",
        "read_more_link": "",
        "language": "en",
        "title": "[SOLVED] - VM stops (crashes?) while cloning",
        "top_image": "https://forum.proxmox.com/styles/uix/images/Proxmox-logo-stacked-white-background-1200.png",
        "meta_img": "https://forum.proxmox.com/styles/uix/images/Proxmox-logo-stacked-white-background-1200.png",
        "images": [
            "https://forum.proxmox.com/styles/uix/images/Proxmox-logo-500px.png",
            "https://forum.proxmox.com/styles/uix/images/Proxmox-logo-black-800.png",
            "https://forum.proxmox.com/styles/uix/images/Proxmox-logo-500px.png",
            "https://forum.proxmox.com/styles/uix/images/Proxmox-logo-black-800.png",
            "https://forum.proxmox.com/data/avatars/s/75/75835.jpg?1566484003",
            "https://forum.proxmox.com/data/avatars/s/93/93939.jpg?1686068403",
            "https://forum.proxmox.com/data/avatars/s/118/118631.jpg?1696392992",
            "https://forum.proxmox.com/data/avatars/s/118/118631.jpg?1696392992",
            "https://forum.proxmox.com/data/avatars/s/93/93939.jpg?1686068403",
            "https://forum.proxmox.com/data/avatars/s/118/118631.jpg?1696392992"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2023-12-12T11:10:47+01:00",
        "summary": "",
        "meta_description": "I use to clone \"on the fly\" a running VM with a script recalled by crontab this way :\n\n        qm destroy 101        ### remove old clone\n        qm clone...",
        "meta_lang": "",
        "meta_favicon": "/data/assets/logo/proxmox-logo-symbol-192x192.png",
        "meta_site_name": "Proxmox Support Forum",
        "canonical_link": "https://forum.proxmox.com/threads/vm-stops-crashes-while-cloning.137978/",
        "text": "Dec 10 02:00:01 pve CRON[3656585]: pam_unix(cron:session): session opened for user root(uid=0) by (uid=0) Dec 10 02:00:01 pve CRON[3656586]: (root) CMD ( /home/backup.sh) Dec 10 02:00:01 pve qm[3656590]: <root@pam> starting task UPIDve:0037CB91:08DCB044:65750D91:qmdestroy:102:root@pam: Dec 10 02:00:01 pve qm[3656593]: destroy VM 102: UPIDve:0037CB91:08DCB044:65750D91:qmdestroy:102:root@pam: Dec 10 02:00:02 pve qm[3656590]: <root@pam> end task UPIDve:0037CB91:08DCB044:65750D91:qmdestroy:102:root@pam: OK Dec 10 02:00:02 pve qm[3656677]: <root@pam> starting task UPIDve:0037CBE6:08DCB0B0:65750D92:qmclone:100:root@pam: Dec 10 02:00:22 pve pvestatd[1968]: status update time (9.078 seconds) Dec 10 02:01:06 pve pve-firewall[1966]: firewall update time (5.350 seconds) Dec 10 02:02:05 pve kernel: task UPIDve:0 invoked oom-killer: gfp_mask=0x140cca(GFP_HIGHUSER_MOVABLE|__GFP_COMP), order=0, oom_score_adj=0 Dec 10 02:02:07 pve kernel: CPU: 3 PID: 3656678 Comm: task UPIDve:0 Tainted: P O 6.2.16-3-pve #1 Dec 10 02:02:07 pve kernel: Hardware name: HPE ProLiant MicroServer Gen10 Plus v2/ProLiant MicroServer Gen10 Plus v2, BIOS U64 06/30/2022 Dec 10 02:02:07 pve kernel: Call Trace: Dec 10 02:02:07 pve kernel: <TASK> Dec 10 02:02:07 pve kernel: dump_stack_lvl+0x48/0x70 Dec 10 02:02:07 pve kernel: dump_stack+0x10/0x20 Dec 10 02:02:07 pve kernel: dump_header+0x50/0x290 Dec 10 02:02:07 pve kernel: oom_kill_process+0x10d/0x1c0 Dec 10 02:02:07 pve kernel: out_of_memory+0x23c/0x570 Dec 10 02:02:08 pve kernel: __alloc_pages+0x1180/0x13a0 Dec 10 02:02:08 pve kernel: alloc_pages+0x90/0x1a0 Dec 10 02:02:08 pve kernel: folio_alloc+0x1d/0x60 Dec 10 02:02:08 pve kernel: filemap_alloc_folio+0xfd/0x110 Dec 10 02:02:08 pve kernel: __filemap_get_folio+0x1d4/0x3c0 Dec 10 02:02:08 pve kernel: ? psi_group_change+0x219/0x530 Dec 10 02:02:08 pve kernel: filemap_fault+0x14a/0x940 Dec 10 02:02:08 pve kernel: ? filemap_map_pages+0x14b/0x6f0 Dec 10 02:02:08 pve kernel: __do_fault+0x36/0x150 Dec 10 02:02:08 pve kernel: do_fault+0x1c7/0x430 Dec 10 02:02:08 pve kernel: __handle_mm_fault+0x6d9/0x1070 Dec 10 02:02:08 pve kernel: handle_mm_fault+0x119/0x330 Dec 10 02:02:08 pve kernel: do_user_addr_fault+0x1c1/0x720 Dec 10 02:02:08 pve kernel: exc_page_fault+0x80/0x1b0 Dec 10 02:02:08 pve kernel: asm_exc_page_fault+0x27/0x30 Dec 10 02:02:08 pve kernel: RIP: 0033:0x7fc891f7c303 Dec 10 02:02:08 pve kernel: Code: Unable to access opcode bytes at 0x7fc891f7c2d9. Dec 10 02:02:08 pve kernel: RSP: 002b:00007fffec059cf8 EFLAGS: 00010202 Dec 10 02:02:08 pve kernel: RAX: 0000000000000000 RBX: ffffffffffffff78 RCX: 00007fc891f7c303 Dec 10 02:02:08 pve kernel: RDX: 00007fffec059d10 RSI: 0000000000000000 RDI: 0000000000000000 Dec 10 02:02:08 pve kernel: RBP: 000000000000001d R08: 0000000000000000 R09: 000000000000010f Dec 10 02:02:08 pve kernel: R10: 00007fffec059d10 R11: 0000000000000202 R12: 00005578018dcf78 Dec 10 02:02:08 pve kernel: R13: 00005577fd19ec88 R14: 00005577fc426030 R15: 00007fc8921a8020 Dec 10 02:02:08 pve kernel: </TASK> Dec 10 02:02:08 pve kernel: Mem-Info: Dec 10 02:02:08 pve kernel: active_anon:1117405 inactive_anon:490517 isolated_anon:0 Dec 10 02:02:08 pve kernel: Node 0 active_anon:4469620kB inactive_anon:1962068kB active_file:168kB inactive_file:0kB unevictable:0kB isolated(anon):0kB isolated(file):0kB mapped:37732kB dirty:40kB writeback:0kB shmem:41424kB shmem_thp: 0kB shmem_pmdmapped: 0kB anon_thp: 1263616kB writeback_tmp:0kB kernel_stack:4420kB pagetables:21552kB sec_pagetables:9260kB all_unreclaimable? no Dec 10 02:02:08 pve kernel: Node 0 DMA free:13312kB boost:0kB min:64kB low:80kB high:96kB reserved_highatomic:0KB active_anon:0kB inactive_anon:0kB active_file:0kB inactive_file:0kB unevictable:0kB writepending:0kB present:15976kB managed:15360kB mlocked:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB Dec 10 02:02:08 pve kernel: lowmem_reserve[]: 0 1826 15820 15820 15820 Dec 10 02:02:08 pve kernel: Node 0 DMA32 free:59884kB boost:0kB min:7796kB low:9744kB high:11692kB reserved_highatomic:0KB active_anon:1393616kB inactive_anon:469764kB active_file:56kB inactive_file:64kB unevictable:0kB writepending:0kB present:1997392kB managed:1930660kB mlocked:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB Dec 10 02:02:08 pve kernel: lowmem_reserve[]: 0 0 13994 13994 13994 Dec 10 02:02:08 pve kernel: Node 0 Normal free:218780kB boost:109788kB min:169508kB low:184436kB high:199364kB reserved_highatomic:0KB active_anon:3076004kB inactive_anon:1492304kB active_file:468kB inactive_file:404kB unevictable:0kB writepending:40kB present:14680064kB managed:14338460kB mlocked:0kB bounce:0kB free_pcp:1112kB local_pcp:0kB free_cma:0kB Dec 10 02:02:08 pve kernel: lowmem_reserve[]: 0 0 0 0 0 Dec 10 02:02:08 pve kernel: Node 0 DMA: 0*4kB 0*8kB 0*16kB 0*32kB 0*64kB 0*128kB 0*256kB 0*512kB 1*1024kB (U) 2*2048kB (UM) 2*4096kB (M) = 13312kB Dec 10 02:02:08 pve kernel: Node 0 DMA32: 1723*4kB (M) 699*8kB (UM) 268*16kB (UM) 155*32kB (UM) 86*64kB (UM) 26*128kB (UM) 17*256kB (M) 11*512kB (M) 5*1024kB (M) 5*2048kB (UM) 1*4096kB (M) = 60004kB Dec 10 02:02:08 pve kernel: Node 0 Normal: 42679*4kB (UME) 4960*8kB (UME) 525*16kB (UME) 0*32kB 0*64kB 0*128kB 0*256kB 0*512kB 0*1024kB 0*2048kB 0*4096kB = 218796kB Dec 10 02:02:08 pve kernel: Node 0 hugepages_total=0 hugepages_free=0 hugepages_surp=0 hugepages_size=1048576kB Dec 10 02:02:08 pve kernel: Node 0 hugepages_total=0 hugepages_free=0 hugepages_surp=0 hugepages_size=2048kB Dec 10 02:02:08 pve kernel: 10468 total pagecache pages Dec 10 02:02:08 pve kernel: 0 pages in swap cache Dec 10 02:02:08 pve kernel: Free swap = 0kB Dec 10 02:02:08 pve kernel: Total swap = 0kB Dec 10 02:02:08 pve kernel: 4173358 pages RAM Dec 10 02:02:08 pve kernel: 0 pages HighMem/MovableOnly Dec 10 02:02:08 pve kernel: 102238 pages reserved Dec 10 02:02:08 pve kernel: 0 pages hwpoisoned Dec 10 02:02:08 pve kernel: Tasks state (memory values in pages): Dec 10 02:02:08 pve kernel: [ pid ] uid tgid total_vm rss pgtables_bytes swapents oom_score_adj name Dec 10 02:02:08 pve kernel: [ 885] 0 885 10308 288 110592 0 -250 systemd-journal Dec 10 02:02:08 pve kernel: [ 988] 0 988 6686 503 86016 0 -1000 systemd-udevd Dec 10 02:02:08 pve kernel: [ 1337] 103 1337 1968 160 53248 0 0 rpcbind Dec 10 02:02:08 pve kernel: [ 1348] 101 1348 2293 192 53248 0 -900 dbus-daemon Dec 10 02:02:08 pve kernel: [ 1355] 0 1355 38186 128 61440 0 -1000 lxcfs Dec 10 02:02:08 pve kernel: [ 1356] 0 1356 69538 160 81920 0 0 pve-lxc-syscall Dec 10 02:02:08 pve kernel: [ 1358] 0 1358 2970 480 61440 0 0 smartd Dec 10 02:02:08 pve kernel: [ 1359] 0 1359 1328 64 49152 0 0 qmeventd Dec 10 02:02:08 pve kernel: [ 1361] 0 1361 4157 288 73728 0 0 systemd-logind Dec 10 02:02:08 pve kernel: [ 1362] 0 1362 583 64 40960 0 -1000 watchdog-mux Dec 10 02:02:08 pve kernel: [ 1365] 0 1365 60163 320 94208 0 0 zed Dec 10 02:02:08 pve kernel: [ 1379] 0 1379 1766 115 53248 0 0 ksmtuned Dec 10 02:02:08 pve kernel: [ 1542] 0 1542 1256 96 49152 0 0 lxc-monitord Dec 10 02:02:08 pve kernel: [ 1557] 0 1557 1468 64 49152 0 0 agetty Dec 10 02:02:08 pve kernel: [ 1571] 0 1571 3850 384 69632 0 -1000 sshd Dec 10 02:02:08 pve kernel: [ 1578] 100 1578 4715 202 57344 0 0 chronyd Dec 10 02:02:08 pve kernel: [ 1584] 100 1584 2633 211 53248 0 0 chronyd Dec 10 02:02:08 pve kernel: [ 1794] 0 1794 126542 291 147456 0 0 rrdcached Dec 10 02:02:08 pve kernel: [ 1835] 0 1835 200788 11517 356352 0 0 pmxcfs Dec 10 02:02:08 pve kernel: [ 1930] 0 1930 10664 165 73728 0 0 master Dec 10 02:02:08 pve kernel: [ 1932] 104 1932 10810 192 69632 0 0 qmgr Dec 10 02:02:08 pve kernel: [ 1941] 0 1941 1652 128 57344 0 0 cron Dec 10 02:02:08 pve kernel: [ 1966] 0 1966 37371 22668 282624 0 0 pve-firewall Dec 10 02:02:08 pve kernel: [ 1968] 0 1968 36087 21364 299008 0 0 pvestatd Dec 10 02:02:08 pve kernel: [ 1971] 0 1971 615 96 40960 0 0 bpfilter_umh Dec 10 02:02:08 pve kernel: [ 1996] 0 1996 55825 31563 389120 0 0 pvedaemon Dec 10 02:02:08 pve kernel: [ 1997] 0 1997 55956 31660 397312 0 0 pvedaemon worke Dec 10 02:02:08 pve kernel: [ 1998] 0 1998 55956 31628 397312 0 0 pvedaemon worke Dec 10 02:02:08 pve kernel: [ 2001] 0 2001 55957 31660 397312 0 0 pvedaemon worke Dec 10 02:02:08 pve kernel: [ 2013] 0 2013 52837 26037 356352 0 0 pve-ha-crm Dec 10 02:02:08 pve kernel: [ 2014] 33 2014 56203 31961 409600 0 0 pveproxy Dec 10 02:02:08 pve kernel: [ 2015] 33 2015 56269 31993 413696 0 0 pveproxy worker Dec 10 02:02:08 pve kernel: [ 2016] 33 2016 56269 31993 413696 0 0 pveproxy worker Dec 10 02:02:09 pve kernel: [ 2017] 33 2017 56269 32025 413696 0 0 pveproxy worker Dec 10 02:02:09 pve kernel: [ 2021] 33 2021 19668 12554 176128 0 0 spiceproxy Dec 10 02:02:09 pve kernel: [ 2022] 33 2022 19725 12651 176128 0 0 spiceproxy work Dec 10 02:02:09 pve kernel: [ 2023] 0 2023 52691 25943 352256 0 0 pve-ha-lrm Dec 10 02:02:09 pve kernel: [ 2061] 0 2061 2417585 1543653 13611008 0 0 kvm Dec 10 02:02:09 pve kernel: [ 2298] 0 2298 51612 26201 352256 0 0 pvescheduler Dec 10 02:02:09 pve kernel: [3245162] 0 3245162 19796 96 53248 0 0 pvefw-logger Dec 10 02:02:09 pve kernel: [3656585] 0 3656585 2124 129 57344 0 0 cron Dec 10 02:02:09 pve kernel: [3656586] 0 3656586 644 64 40960 0 0 sh Dec 10 02:02:09 pve kernel: [3656587] 0 3656587 1733 96 49152 0 0 backup.sh Dec 10 02:02:09 pve kernel: [3656677] 0 3656677 51763 26013 401408 0 0 qm Dec 10 02:02:09 pve kernel: [3656678] 0 3656678 53538 26101 368640 0 0 task UPIDve:0 Dec 10 02:02:09 pve kernel: [3708720] 104 3708720 10764 224 69632 0 0 pickup Dec 10 02:02:09 pve kernel: [3748914] 0 3748914 1366 64 45056 0 0 sleep Dec 10 02:02:09 pve kernel: [3774475] 0 3774475 53420 26202 360448 0 0 pvescheduler Dec 10 02:02:09 pve kernel: [3774477] 0 3774477 51612 26170 352256 0 0 pvescheduler Dec 10 02:02:09 pve kernel: oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=cron.service,mems_allowed=0,global_oom,task_memcg=/qemu.slice/100.scope,task=kvm,pid=2061,uid=0 Dec 10 02:02:09 pve kernel: Out of memory: Killed process 2061 (kvm) total-vm:9670340kB, anon-rss:6174228kB, file-rss:384kB, shmem-rss:0kB, UID:0 pgtables:13292kB oom_score_adj:0 Dec 10 02:02:09 pve kernel: fwbr100i0: port 2(tap100i0) entered disabled state Dec 10 02:02:09 pve kernel: fwbr100i0: port 2(tap100i0) entered disabled state Dec 10 02:02:05 pve systemd[1]: 100.scope: A process of this unit has been killed by the OOM killer. Dec 10 02:02:05 pve qm[3656678]: VM 100 qmp command failed - VM 100 not running Dec 10 02:02:09 pve qmeventd[3776821]: Starting cleanup for 100 Dec 10 02:02:09 pve qmeventd[3776821]: trying to acquire lock... Dec 10 02:02:05 pve systemd[1]: 100.scope: Failed with result 'oom-kill'. Dec 10 02:02:05 pve qm[3656678]: VM 100 qmp command failed - VM 100 not running Dec 10 02:02:05 pve systemd[1]: 100.scope: Consumed 21h 44min 2.890s CPU time. Dec 10 02:02:05 pve qm[3656678]: VM 100 qmp command failed - VM 100 not running Dec 10 02:02:05 pve systemd[1]: qemu.slice: A process of this unit has been killed by the OOM killer. Dec 10 02:02:05 pve qm[3656678]: VM 100 qmp command failed - VM 100 not running Dec 10 02:02:05 pve qm[3656678]: VM 100 qmp command failed - VM 100 not running Dec 10 02:02:12 pve qmeventd[3776821]: OK Dec 10 02:02:12 pve qm[3656678]: clone failed: block job (mirror) error: VM 100 not running Dec 10 02:02:12 pve qm[3656677]: <root@pam> end task UPIDve:0037CBE6:08DCB0B0:65750D92:qmclone:100:root@pam: clone failed: block job (mirror) error: VM 100 not running Dec 10 02:02:12 pve kernel: fwbr100i0: port 1(fwln100i0) entered disabled state Dec 10 02:02:12 pve kernel: vmbr0: port 2(fwpr100p0) entered disabled state Dec 10 02:02:12 pve kernel: device fwln100i0 left promiscuous mode Dec 10 02:02:12 pve kernel: fwbr100i0: port 1(fwln100i0) entered disabled state Dec 10 02:02:12 pve kernel: device fwpr100p0 left promiscuous mode Dec 10 02:02:12 pve kernel: vmbr0: port 2(fwpr100p0) entered disabled state Dec 10 02:02:12 pve qmeventd[3776821]: Finished cleanup for 100 Dec 10 02:02:13 pve CRON[3656585]: pam_unix(cron:session): session closed for user root"
    }
}