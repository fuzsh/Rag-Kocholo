{
    "id": "dbpedia_465_0",
    "rank": 68,
    "data": {
        "url": "https://www.inulledmyself.com/2023/05/using-ai-to-find-software.html",
        "read_more_link": "",
        "language": "en",
        "title": "INulledMyself: Using AI to find software vulnerabilities in XNU: Security for mere mortals",
        "top_image": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrroy-uSEeouD-6hBjuDmrgx7qFb1Xu-SgF_yKmQMP4FuccPodLWhRF6R5gf7VlSNZZ1MSVPJmKA4OKl65xC0-k5kkXtnOZ2fgLls4mH2WUzfPadIW05O5wGCI3obfthjpyMj2Ln3-hErrgtlW9sOJ3PwZ5xVvifP9f1luUEpQ6bQfsXK_r9L2Me5_/w1200-h630-p-k-no-nu/hmmm-yeah-i-know-some-of-these-words.jpg",
        "meta_img": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrroy-uSEeouD-6hBjuDmrgx7qFb1Xu-SgF_yKmQMP4FuccPodLWhRF6R5gf7VlSNZZ1MSVPJmKA4OKl65xC0-k5kkXtnOZ2fgLls4mH2WUzfPadIW05O5wGCI3obfthjpyMj2Ln3-hErrgtlW9sOJ3PwZ5xVvifP9f1luUEpQ6bQfsXK_r9L2Me5_/w1200-h630-p-k-no-nu/hmmm-yeah-i-know-some-of-these-words.jpg",
        "images": [
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrroy-uSEeouD-6hBjuDmrgx7qFb1Xu-SgF_yKmQMP4FuccPodLWhRF6R5gf7VlSNZZ1MSVPJmKA4OKl65xC0-k5kkXtnOZ2fgLls4mH2WUzfPadIW05O5wGCI3obfthjpyMj2Ln3-hErrgtlW9sOJ3PwZ5xVvifP9f1luUEpQ6bQfsXK_r9L2Me5_/s1600/hmmm-yeah-i-know-some-of-these-words.jpg",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhCPoJoRspMA7IIBNJGLSj7z2JZWTXFhBdrJLQ4NaB-atAKCWtq2DV-mdFJmu59LBAtLBb1yXDOuWA0SHcRLIMrsGYkwHGW8iu_Ir8ngH-rCyIHXucuKVJ5ipWL7JlRdLS_9tXajB6Yjr3sWxFM2vWq4BqB4P7K23r05omwa6zuIx_LbM0c8Y1OCpWX/s16000/DavinciIsMissing.png",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjICh5ncbd6sjOxNdGrGdqvwLsBYqnmwpkprT0QOt8djI5nf4POjkNesFXhTqh5raRjpf5QzzsEWvrq-SGxmEm1wMXIYC3CXoX44N17ljGnWCy7Vg_03TaN9aFVVbFKPS2JNAJ8tZ5O6PfyGChKVTkjCVl6HlvYfvkXcXbgcLyBcZm2pmofIKd_Oh7F/w640-h87/partiallywrongexample.png",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjfojjo7z1quPY1LcXdoMg-AN_blV_kO4geOMmJHsNyLftfhumWZWJRetnTN0CtjzUt943EWqrktKxtutkpDqq2H8Y2f9mCMX9BAbVujld6s948ZILfKw6G4e1NTb-YHLlZ6eY8nmc60WpVuLIEp2FAxbLmlS_J0p_wZnTSuKIY7hwDTs1WmDg_HPM2/s320/mind-blow-galaxy.gif",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgNQXTpCEOijNLTM3VfeXwpCy_1vwjM-r2mrW0cBPbQf3igUAuUtnp50cN4x6xXKCder2sV2265Dv8gAp2fUXeVqsi6-4HQ4zsvshkqRyNpT9z88wWZLNS3BCuiN3Tq0jKKeTeawSYOSnFrj1Lt38NWzKxVkyYZmxfLrKuwWFWjzs30spZDtj8pS4BV/w640-h50/MostlyCorrect.png",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh2bMXDS4Mfl8xX-CarKPifCTRwa-bNSaAKzUL_UoDeCF80tNMbTLibip44IYixz34Bl7y-nPAX3v0qjG_ikMYjq9hVsspqWU7CY05SomHkpA7WJSHl4F0-yrPkc90BFYmncXuNXdrWt-ajmU08tYlYEP8y3zpvk7PWw_jzn3-99J7NZrrDLYWilZM4/w360-h195/giphy.gif",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNU6R294lzHolAh6b9WwQVX3cnh0k_1FU7sSJ8M8FUSwZuDqFsUpuKhNPtyGRw0dGFjcsFHabmeWZQxQkQlmDoMpTj4Sc__zst3BWCy3YsB3vFGBCyl0cB1576fznN8Y4dxoJXvHjBuUKjCJgliIhQnDZOIHiXYlYe8rXQTA4uvQeX18Eiuw6Cz_OA/s320/wrong.png",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiT4JEFv7wcmbhCCbTDWEJ79DEn3qKgcP4UJ9eY6tHhN3JxlFvsZKFxPz6PH9CMcTvRBgw7Gah1LRNHpVtlJ-sf7QBNGZr4x1AkZQ0YziWeTHBEZw1gXmwg9CjoHMYNd36eDQl8aryu1OwxJ2vryw7OTCkDFTxZDQRaIBiRYZljb_ccEF5YJSGiBY3N/s1600/Fire.png",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYdtWza9y9jRaggcyYYlRlX4_x0LZLhjUDt8C3BQxNKQ7c1D9TCtr5rwZUEjhdgBii02V2neuPQ2c2-12f961Mxpt3tTr1Dj_KLr_vEBgqTEpLMgf3URu7b87eLpj_QuXOQCG89kxyZ0zhkSTIPCl0dpQBaOySgYSrn_MYVhL0qrrAppDejJrQWR9n/s320/7kr14f.jpg",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQVEC-gGzySBQpGXTDr_0VXV7yndAYqNCjZAtIM7HMQ9OXwQki3UPPD4vgBCPkvAvSTpHWQSPygvC4Iko4zaqo2jgLYMwHbPqcS115CGWi-gIacCrCcSHs85zQ9T0etn_9GeY5ruAxZTmZE8KQu1qvXCTB0PprBNWBZ-EUUsPsjkPPtIkzfUU4TRrc/s320/7kr19y.jpg",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhaZ-jfFRMdBilbtXNUxgWgy78fOTuJGn20jMBkszL4X4CmZ6w0uHI8xP-k6tQsL1KqSHGMZ6Ae1uLVZj_Ezmvq654omstT0S1oKo0H7xhh3aHb193o5povdtDURyL-1y-R4iTswLRoTa62eYmcbv5gby3rgPxgidnoGlHn8MR5V36R5b8uI_tYQId/s320/DoItAgain.png",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiG0sOgKTV2jxcNlaMxW1Q-merRTDS_NHfijSNayahyp6Z0pVy6LDBYHgwQMSfcYI4npvRMvHopBB0Hqbu1pUWzBOVo3KOEASd6QSMfuc5BhCbbq2p_cHVJdWoDV16sDAZcso1bNjy12UCgnvCxXDLAOnt7_p9VHp6a2i54k2mRQi7QkoiwtNAX8UqB/s320/7kr1g4.jpg",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "View my complete profile"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Note : This work took place in May-Aug of 2022. It just took me this long to finally finish writing this (Too busy playing with my SRD ðŸ˜…) L...",
        "meta_lang": "",
        "meta_favicon": "https://www.inulledmyself.com/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://www.inulledmyself.com/2023/05/using-ai-to-find-software.html",
        "text": "#!/usr/bin/python3.9 #The MAJORITY of this code is from the neulab code-bert-score repo from transformers import AutoTokenizer, AutoModelForMaskedLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling from datasets import load_dataset import numpy as np import evaluate import torch def compute_metrics(eval_preds): preds, labels = eval_preds # preds have the same shape as the labels, after the argmax(-1) has been calculated # by preprocess_logits_for_metrics labels = labels.reshape(-1) preds = preds.reshape(-1) mask = labels != -100 labels = labels[mask] preds = preds[mask] return metric.compute(predictions=preds, references=labels) def preprocess_logits_for_metrics(logits, labels): if isinstance(logits, tuple): # Depending on the model and config, logits may contain extra tensors, # like past_key_values, but logits always come first logits = logits[0] return logits.argmax(dim=-1) def tokenize_function(examples): examples[\"code\"] = [line for line in examples[\"code\"] if len(line) > 0 and not line.isspace()] return tokenizer(examples[\"code\"], padding=\"max_length\", truncation=True, max_length=512,return_special_tokens_mask=True) tokenizer = AutoTokenizer.from_pretrained(\"neulab/codebert-c\") training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\") model = AutoModelForMaskedLM.from_pretrained(\"neulab/codebert-c\") model.resize_token_embeddings(len(tokenizer)) device = torch.device(\"cuda\") model.to(device) data_collator = DataCollatorForLanguageModeling( tokenizer=tokenizer, mlm=True, mlm_probability=.15, ) training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", max_steps=100000) #w/o streaming you need much larger than 1 TB of space for all the data #Likely some bias introduced due to validation + training data overlapping train_dataset = load_dataset(\"codeparrot/github-code-clean\", streaming=True, split='train', languages=['C','C++']) with training_args.main_process_first(desc=\"dataset map tokenization\"): token_train_dataset = train_dataset.map( function=tokenize_function, batched=True, remove_columns=\"code\", ) #need 2 of these since IterableDataset doesn't support train_test_split - at least not yet! #Likely some bias introduced due to validation + training data overlapping eval_dataset = load_dataset(\"codeparrot/github-code-clean\", streaming=True, split='train', languages=['C','C++']) with training_args.main_process_first(desc=\"dataset map tokenization\"): token_eval_dataset = eval_dataset.map( tokenize_function, batched=True, remove_columns=\"code\", ) metric = evaluate.load(\"accuracy\") trainer = Trainer( model=model, args=training_args, train_dataset=token_train_dataset, tokenizer=tokenizer, data_collator=data_collator, eval_dataset=token_eval_dataset, compute_metrics=compute_metrics, preprocess_logits_for_metrics=preprocess_logits_for_metrics ) #insert checkpoints here if you want to use checkpoints trainer.train() trainer.save_model(\"test_trainer\\newModel\")\n\nThis ran for ~9 days straight on a 3090 at pretty close to max capacity the entire time,\n\nAccurate representation of how I felt as my room 'warmed' up\n\nbut it finally finished! Thankfully, (And much to my families joy), I didn't have to run it again. Now that we built it, let's try the new model!\n\n#!/usr/bin/python3 from transformers import RobertaTokenizer, RobertaForMaskedLM, pipeline model = RobertaForMaskedLM.from_pretrained('test_trainer/newModel') tokenizer = RobertaTokenizer.from_pretrained('test_trainer/newModel') code_example =\"\"\" if (major(dev) <mask> nchrdev) { knote_set_error(kn, ENXIO); return 0; } \"\"\" code_ref=\"\"\" if (major(dev) > nchrdev) { knote_set_error(kn, ENXIO); return 0; } \"\"\" fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer) outputs = fill_mask(code_example,top_k=5) for output in outputs: if (output['sequence'] != code_ref): print(output)"
    }
}