{
    "id": "dbpedia_5535_2",
    "rank": 74,
    "data": {
        "url": "https://jitp.commons.gc.cuny.edu/category/issues/issue-eleven/",
        "read_more_link": "",
        "language": "en",
        "title": "Issue Eleven",
        "top_image": "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-1-IBM-360-roomview-300x224.jpg",
        "meta_img": "",
        "images": [
            "https://jitp.commons.gc.cuny.edu/wp-content/blogs.dir/614/files/2019/01/JITP-Plain-Logo.jpg",
            "https://jitp.commons.gc.cuny.edu/wp-content/blogs.dir/614/files/2017/05/15740052605_61456809a8_k-700x500.jpg",
            "https://jitp.commons.gc.cuny.edu/wp-content/blogs.dir/614/files/2017/05/2460744736_bbd842619e_b-700x500.jpg",
            "https://jitp.commons.gc.cuny.edu/wp-content/blogs.dir/614/files/2017/05/Image-7-SB-Columbia-res-e1494610748597-700x500.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-1-IBM-360-roomview-300x224.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-2-FortranCodingForm-300x190.png",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-3-FortranCardPROJ039.agr_-300x144.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-4-Fanfold-Paper-232x300.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-5-Scatterdiagram-300x254.png",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-6-Solidarity-Index-300x261.png",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-7-SB-Columbia-res-e1494610777338-300x202.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-8-Kaypro-II-300x150.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/Image-9-Gay-Cowboys-232x300.jpg",
            "https://jitp.commons.gc.cuny.edu/wp-content/blogs.dir/614/files/2017/05/cover-600x500.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure1-1024x510.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure2-690x1024.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure3.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure4-1024x221.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure5-1024x332.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure6-1-1024x217.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure7-1024x323.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure8-589x1024.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure9-743x1024.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure10.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure11-1024x344.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure12-418x1024.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure13-788x1024.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure14-961x1024.jpg",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/figure15-473x1024.jpg",
            "https://jitp.commons.gc.cuny.edu/wp-content/blogs.dir/614/files/2017/05/TP11-Figure2-700x500.png",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/TP11-Figure2.png",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/cc4.0.png",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/cc4.0.png",
            "https://jitp.commons.gc.cuny.edu/files/2017/05/cc4.0.png",
            "http://www.feedburner.com/fb/images/pub/feed-icon16x16.png",
            "http://jitp.commons.gc.cuny.edu/files/2013/07/new-mail-icon-e1373949936648.png",
            "https://jitp.commons.gc.cuny.edu/wp-content/plugins/cookies-for-comments/css.php?k=56432b1df3e67e3f4dcdbad943087b&o=i&t=172536062",
            "https://commons.gc.cuny.edu/wp-content/themes/bp-nelo/assets/img/cac-logo.png",
            "https://commons.gc.cuny.edu/wp-content/mu-plugins/assets/img/footer-logo-cuny.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Matthew K. Gold",
            "The Graduate Center",
            "sava saheli singh",
            "New York University",
            "Stephen Brier",
            "Chris Alen Sula",
            "S. E. Hackney",
            "University of Pittsburgh",
            "Phillip Cunningham",
            "Amistad Research Center"
        ],
        "publish_date": "2017-05-24T00:00:00",
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "“And you may ask yourself—Well… How did I get here?”\n\nTalking Heads, “Once In a Lifetime” (1981)\n\nMuch actual and virtual ink has been spilled over the past few years recounting how the field of Digital Humanities came into being. As a social historian and someone who has been involved in digital work of one sort or another since the mid 1970s, I am somewhat bemused by what Geoffrey Rockwell has aptly termed the “canonical Roberto Busa story of origin” offered by English department colleagues (Rockwell 2007). That canonical DH history usually starts with the famous Father Roberto Busa developing his digital concordances of St. Thomas Aquinas’s writings beginning in 1949 (the first of which was published in 1974) with critical technical support provided by Thomas Watson, head of IBM.[1] It quickly moves from there to recount the emergence of humanities computing (as it was originally known) in the 1980s, followed by the development of various digitized literary archives launched by literary scholars such as Jerry McGann (Rossetti) and Ed Folsom (Whitman) in the 1990s (Hockey 2004). In this recounting, academics in English, inspired by Father Busa, pushed ahead with the idea of using computers to conceive, create, and present the digital concordances, literary editions, and, ultimately, fully digitized and online archives of materials, using common standards embodied in the Text Encoding Initiative (TEI), which was established in 1987.[2] The new field of Digital Humanities is said to have emerged after 2004 directly out of these developments in the literary studies field, what Willard McCarty terms “literary computing” (McCarty 2011, 4).[3]\n\nAs a historian who believes in multi-causal explanations of historical phenomena (including what happens intellectually inside of universities), I think there are alternative interpretations of this origin story that help reveal a much more complicated history of DH.[4] I will argue in this piece that the history field—particularly historians working in its social, public, and quantitative history sub-fields—also made a substantial and quite different contribution to the emergence of the Digital Humanities that parallels, at times diverges from, and even anticipates the efforts of literary scholars and literary studies.[5] I will first sketch broader developments in the social, public, and quantitative history sub-fields that began more than four decades ago. These transformations in the forms and content of historical inquiry would ultimately lead a group of historians to contribute to the development of DH decades later. I will also use my own evolution over this time period (what I dub in the title of this piece my “premature” Digital Humanism), first as a social and labor historian, then as a media producer, digital historian, and finally now as a teacher of digital humanities and digital pedagogy, to illustrate the different pathways that led many historians, myself included, into contributing to the birth and evolution of the Digital Humanities. I will use my ongoing collaborations with my colleagues at the American Social History Project (which I co-founded more than 35 years ago) as well as with Roy Rosenzweig and the Center for History and New Media to help tell this alternate DH origins story. In the process, I hope to complicate the rather linear Father Busa/humanities computing/TEI/digital literary archives origin story of DH that has come to define the field.\n\nSocial and Labor History\n\nSocial history first emerged in the pre-World War II era with the founding in 1929 in France of the Annales school of historical inquiry by Lucien Febvre and Marc Bloch and carried forward by Fernand Braudel in the 1950s and Emmanuel Le Roy Ladurie in the 1970s. The field of social history found fertile new ground in the United States during the 1960s and 1970s. The “new” social history was very much a product of the rejection of traditional political history narratives and a search for new methodologies and interdisciplinary connections. Social history examined the lives and experiences of “ordinary people”—workers, immigrants, enslaved African Americans, women, urban dwellers, farmers, etc.—rather than the narrow focus on the experiences of Great White Men that had dominated both academic and popular history writing for decades if not centuries. This changed historical focus on history “from the bottom up” necessitated the development of new methodological approaches to uncover previously unused source materials that historians needed to employ to convey a fuller sense of what happened in the past. Archives and libraries had traditionally provided historians access to large collections of private and public correspondence of major politicians, important military leaders, and big businessmen (the gendered term being entirely appropriate in this context) as well as catalogued and well-archived state papers, government documents, and memoirs and letters of the rich and famous. But if the subject of history was now to change to a focus on ordinary people, how were historians to recount the stories of those who left behind few if any traditional written records? New methodologies would have to be developed to ferret out those hidden histories.[6]\n\nThe related sub-field of labor history, which, like social history, was also committed to writing history “from the bottom up,” illustrates these methodological dilemmas and possibilities. Older approaches to US labor history had focused narrowly on the structure and function of national labor unions and national political parties, national labor and party leaders, and what happened in various workplaces, drawing on government reports, national newspapers, and union records. The new labor history, which was pioneered in the early 1960s, first by British Marxist historians such as Eric Hobsbawm and E. P. Thompson, sought to move beyond those restricted confines to tell the previously unknown story of the making of the English working class (to appropriate the title of one of Thompson’s most important works). Hobsbawm and especially Thompson relied heavily in their early work on unconventional local and literary sources to uncover this lost history of English working people. The new labor history they pioneered was soon adapted by US labor historians, including David Montgomery, David Brody, and Herbert Gutman and by graduate students, deploying an array of political and cultural sources to reveal the behaviors and beliefs of US working people in all of their racial and ethnic diversity. The new US labor history embraced unorthodox historical methodologies including: oral history; a close focus on local and community studies, including a deep dive into local working-class newspapers; broadened definitions of what constituted work (e.g. women’s housework); and working-class family and community life and self-activity (including expressions of popular working-class culture and neighborhood, political, and religious associations and organizations). I committed myself to the new labor history and its innovative methodologies in graduate school at UCLA in the early 1970s when I began to shape my doctoral dissertation, which sought to portray the ways black, white, and immigrant coal miners in the West Virginia and Colorado coal fields managed to forge interracial and interethnic local labor unions in the late nineteenth and early twentieth centuries (Brier 1992).\n\nPublic History\n\nA second activist and politically engaged approach to communicating historical scholarship—public history—also emerged in the 1970s. Public history grew in parallel to and was made possible by the new academic field of social history. To be sure, while social history spoke largely to the history profession, challenging its underlying methodological and intellectual assumptions, public history and the people who self-identified as public historians often chose to move outside the academy, embedding themselves and their public history work inside unions, community-based organizations, museums, and political groups. Public historians, whether they stayed inside the academy or chose to situate themselves outside of it, were committed to making the study of the past relevant (to appropriate that overused Sixties’ phrase) to individuals and groups that could and would most benefit from exposure to and knowledge about their “lost” pasts (Novick 1988, 512–21).\n\nPublic history’s emergence in the mid-1970s signaled that at least one wing of the profession, albeit the younger, more radical one, was committed to finding new ways and new, non-print formats to communicate historical ideas and information to a broad public audience through museum exhibits, graphic novels, audio recordings and radio broadcasts, and especially film and television. A range of projects and institutions that were made possible by this new sub-field of public history began to take shape by the late 1970s. I worked with fellow radical historians Susan Porter Benson and Roy Rosenzweig and the three of us put together in 1986 the first major collection of articles and reports on US public history projects and initiatives. Entitled Presenting the Past, the collection was based on a special theme issue of the Radical History Review (the three of us were members of the RHR editorial collective) that we had co-edited five years earlier.[7] Focusing on a range of individual and local public history projects, Presenting the Past summarized a decade of academic and non-academic public history work and projects in the United States (Benson, Brier, and Rosenzweig 1986).[8]\n\nStephen Robertson, who now heads the Roy Rosenzweig Center for History and New Media (CHNM)[9] at George Mason University, has correctly noted, in a widely read 2014 blog post,[10] that we can and should trace the origins of the much newer sub-field of digital history, a major contributor to the Digital Humanities’ growth, to the public history movement that was launched a quarter century earlier (Robertson 2014). Robertson goes on to suggest that this early focus on public history led digital historians to ask different questions than literary scholars. Historians focused much more on producing digital history in a variety of presentational forms and formats rather than literary scholars’ emphasis on defining and theorizing the new Digital Humanities field and producing online literary archives. This alternative focus on public presentations of history (i.e., intended for the larger public outside of the academy and the profession) may explain why digital historians seem much less interested in staking out their piece of the DH academic turf while literary scholars seem more inclined both to theorize their DH scholarship and to assert that DH’s genesis can be located in literary scholars’ early digital work.\n\nQuantitative History\n\nA third, and arguably broader, methodological transformation in the study and writing of US history in these same years was the emergence of what was called quantitative history. “Cliometrics” (as some termed it, a bit too cutely) held out the possibility of generating new insights into historical behavior through detailed analyses of a myriad of historical data available in a variety of official sources. This included, but was certainly not limited to, raw data compiled by federal and state agencies in resources like census manuscripts.[11] Quantitative history, which had its roots in the broader turn toward social science taken by a number of US economic historians that began in the late 1950s, had in fact generated by the early 1970s a kind of fever dream among many academic historians and their graduate students (and a raging nightmare for others) (Thomas 2004).[12] Edward Shorter, a historian of psychiatry (!), for example, authored the widely-read The Historian and The Computer: A Practical Guide in 1971. Even the Annales school in France, led by Ladurie, was not immune from the embrace of quantification. Writing in a 1973 essay, Laurie argued that “history that is not quantifiable cannot claim to be scientific” (quoted in Noiret 2012). Quantitative history involved generating raw data from a variety of primary source materials (e.g., US census manuscripts) and then using a variety of statistical tools to analyze that data. The dreams and nightmares that this new methodology generated among academic historians were fueled by the publication of two studies that framed the prominence and ultimate eclipse of quantitative history: Stephan Thernstrom’s Poverty and Progress, published in 1964, and Robert Fogel and Stanley Engerman’s Time on the Cross, which appeared a decade later (Thernstrom 1964; Fogel and Engerman 1974).\n\nThernstrom’s study used US census manuscripts (the original hand-coded forms for each resident produced by census enumerators) from 1850 to 1880 as well as local bank and tax records and city directories to generate quantitative data, which he then coded and subjected to various statistical measures. Out of this analysis of data he developed his theories of the extent of social mobility, defined occupationally and geographically, that native-born and Irish immigrant residents of Newburyport, Massachusetts enjoyed in those crucial years of the nation’s industrial takeoff. The critical success of Thernstrom’s book helped launch a mini-boom in quantitative history. A three-week seminar on computing in history drew thirty-five historians in 1965 to the University of Michigan; two years later a newsletter on computing in history had more than 800 subscribers (Graham, Milligan, and Weingart 2015). Thernstrom’s early use of quantitative data (which he analyzed without the benefit of computers) and the positive critical reception it received helped launch the quantitative history upsurge that reshaped much US social and urban history writing in the following decade. Without going into much detail here or elaborating on my own deep reservations about Thernstrom’s methodology[13] and the larger political and ideological conclusions he drew from his analysis of the census manuscripts and city directories, suffice it to say that Thernstrom’s work was widely admired by his peers and emulated by many graduate students, helping him secure a coveted position at Harvard in 1973.[14]\n\nThe other influential cliometric study, Fogel and Engerman’s Time on the Cross, was widely reviewed (including in Time magazine) after it appeared in early 1974. Though neither author was a social historian (Fogel was an economist, Engerman an economic historian), they were lavishly praised by many academics and reviewers for their innovative statistical analysis of historical data drawn from Southern plantation records (such as the number of whippings meted out by slave owners and overseers to enslaved African Americans). Their use of statistical data led Fogel and Engerman to revise the standard view of the realities of the institution of slavery. Unlike the conclusions reached by earlier historians such as Herbert Aptheker and Kenneth Stampp that centered on the savage exploitation and brutalization of slaves and their active resistance to the institution of slavery, Fogel and Engerman concluded that the institution of slavery was not particularly economically inefficient, as traditional interpretations argued, that the slaves were only “moderately exploited,” and that they were only occasionally abused physically by their owners (Aptheker 1943 [1963]; Stampp 1956 [1967]). Time on the Cross was the focus of much breathless commentary both inside and outside of the academy about the appropriateness of the authors’ assessments of slavery and how quantitative history techniques, which had been around for several decades, would help historians fundamentally rewrite US history.[15] If this latter point sounds eerily prescient of the early hype about DH offered by many of its practitioners and non-academic enthusiasts, I would argue that this is not an accident. The theoretical and methodological orthodoxies of academic disciplines are periodically challenged from within, with new methodologies heralded as life- (or at least field-) changing transformations of the old. Of course, C. Vann Woodward’s highly critical review of Fogel and Engerman in the New York Review of Books and Herbert Gutman’s brilliant book-length takedown of Time on the Cross soon raised important questions and serious reservations about quantitative history’s limitations and its potential for outright distortion (Woodward 1974; Gutman 1975; Thomas 2004). Gutman’s and Woodward’s sharp critiques aside, many academic historians and graduate students (myself included) could not quite resist dabbling in (if not taking a headlong plunge into) quantitative analysis.\n\nUsing a Computer to do Quantitative History\n\nThough I had reservations about quantitative history—my skepticism stemming from a general sense that quantitative historians overpromised easy answers to complex questions of historical causation—I decided to broaden the fairly basic new labor history methodology that I was then using in my early dissertation research, which had been based on printed historical sources (government reports, nineteenth-century national newspaper accounts, print archival materials, etc.). I had been drawn to coal miners and coal mining unionism as a subject for my dissertation because of the unusual role that coal miners played historically as prototypical proletarians and labor militants, not only in the United States, but also across the globe. I was interested in understanding the roots of coal miners’ militancy and solidarity in the face of the oppressive living and working conditions they were forced to endure. I also wanted to understand how (or even if) white, black, and immigrant mineworkers had been able to navigate the struggle to forge bonds of solidarity during trade union organizing drives. I had discovered an interesting amount of quantitative data in the course of my doctoral dissertation research: an enumeration of all coal strikes (1,410 in number) that occurred in the United States in the 1881–94 period detailed in the annual reports of the US Commissioner of Labor.[16] This was what we would now call a “dataset,” a term that was not yet used in my wing of the academy in 1975. This critical fourteen-year historical period witnessed the rise and fall of several national labor union organizations among coal miners, including the Knights of Labor, the most consequential nineteenth-century US labor organization, and the birth of the United Mine Workers of America, the union that continues to represent to this day the rapidly dwindling number of US coal miners.\n\nIn my collaboration with Jon Amsden, an economic and labor historian and UCLA faculty member, the two of us decided to statistically analyze this data about the behavior and actions of striking coal miners in these years. The dataset of more than 1,400 strikes statistically presented in large tables was simply too large, however, to analyze through conventional qualitative methods to divine patterns and trends. Amsden and I consequently made a decision in 1975 to take the plunge into computer-assisted data analysis. The UCLA Computer Center was a beehive of activity in these early years of academic computing, especially focused on the emerging field of computer science.[17] The center was using an IBM 360 mainframe computer, running Fortran and the Statistical Package for the Social Sciences (the now venerable SPSS, originally released in 1968, and first marketed in 1975) to support social scientific analyses (Noiret 2012).\n\nAmsden and I began by recording some of the characteristics involved in each of the 1,410 coal strikes that occurred in those 14 years: year of the strike, cause or objective of the strike, and whether a formal union was involved. To make more detailed comparisons we drew a one-in-five systematic random sample of the coal strikes. This additional sampled data included the number of workers involved in each strike, strike duration, and miners’ wages and hours before and after the strike. We laboriously coded each strike by hand on standard 80-character IBM Fortran coding sheets.\n\nWe then had a keypunch operator at the UCLA Computer Center (no doubt a woman, sadly unknown and faceless to us, righteous labor historians though we both were!)[18] transfer the data on each strike entry to individual IBM Fortran punch cards, originally known at Hollerith cards (Lubar 1992). That process generated a card stack large enough to carry around in a flat cardboard box the size of a large shoe box.\n\nWe regularly visited the UCLA Computer Center in the afternoon to have our card stack “read” by an IBM card reading machine and then asked the IBM 360 to generate specific statistical tabulations and correlations we requested, trying to uncover trends and comparative relationships among the data.[19] The nature of this work on the mainframe computer did not require us to learn Fortran (I know DHer Steve Ramsay would disapprove![20]), though Amsden and I did have to brush up on our basic statistics to be able to figure out how to analyze and make sense of the computer output. We picked up our results (the “read outs”) the next morning, printed on large, continuous sheets of fanfold paper.\n\nIt was a slow and laborious process, with many false starts and badly declared and pointless computing requests (e.g., poor choices of different data points to try to correlate).\n\nUltimately, however, this computerized data analysis of strike data yielded significant statistical correlations that helped us uncover previously unknown and only partially visible patterns and meanings in coal miners’ self-activity and allowed us to generate new insights (or confirm existing ones) into the changing levels of class consciousness exhibited by miners. Our historical approach to quantitative analysis was an early anticipation, if I can be permitted a bit of hyperbole, of Franco Moretti’s “distant reading” techniques in literary scholarship (Moretti 2005), using statistical methods to examine all strikes in an industry, rather than relying on a very “close reading” of one, two, or a handful of important strikes that most labor historians, myself included, typically undertook in our scholarly work. Amsden and I wrote up our results in 1975 and our scholarly article appeared in the Journal of Interdisciplinary History in 1977, a relatively new journal that featured interdisciplinary and data-driven scholarship. The article received respectful notice as a solid quantitative contribution to the field and was reprinted several times over the next three decades (Amsden and Brier 1977).[21]\n\nOne of our key statistical findings was that the power and militancy of coal miners increased as their union organizations strengthened (no surprises there) and that heightened union power between 1881 and 1894 (a particularly contentious period in US labor history) generated more militant strikes in the coal industry. Our data analysis revealed that these militant strikes often moved away from narrow efforts to secure higher wages to allow miners across the country to pose more fundamental challenges to the coal operators’ near total control over productive relations inside coal pits. Below are two screen shots, both generated by SPSS, from the published article: a scatter diagram (a new technique for historians to employ, at least in 1975) and one of the tables. The two figures convey the kinds of interesting historical questions we were able to pose quantitatively and how we were able to represent the answers to those questions graphically.\n\nFigure 5 above shows the growth in the number of multi-establishment coal strikes and the increasing number of mines involved in strike activity over time, a good measure of increasing union power and worker solidarity over the critical 14-year period covered in the dataset.\n\nTable 3 employs a solidarity index that Amsden and I developed out of our analysis of the coal strike statistics, based on the ratio of the number of strikers to the total number of mine employees in a given mine whose workers had gone out on strike. The data revealed that union-called strikes were consistently able to involve a higher percentage of the overall mining workforce as compared to non-union strikes and with less variation from the norm. This table lay at the heart of why I had decided to study coal miners and their unions in the first place. I hoped to analyze why and how miners consistently put themselves and their unions at the center of militant working-class struggles in industrializing America. I might have reached some of these same conclusions by analyzing traditional qualitative sources or by looking closely at one or a handful of strikes. However, Amsden and I had managed to successfully employ a statistical analysis in new ways (at least in the history field) that allowed us to “see” these developments and trends in the data nationally and regionally. We were able therefore to argue that the evolving consciousness of miners over time was reflected in their strike demands and in their ability to successfully spread the union message across the country. I should note here that the United Mine Workers of America had become the largest union by far in these early years of the American Federation of Labor. In sum, we believed we had developed a new statistical methodology to analyze and understand late nineteenth-century working-class behavior. We had used a computer to help answer conceptual questions that were important in shaping our historical interpretation. This effort proved to be a quite early instance of the use of digital techniques to ask and at least partially answer key historical (and, by definition, humanities) questions.\n\nFrom Quantitative History to the American Social History Project\n\nAround the time of the 1977 publication of the coal miners on strike article I decided to follow my public history muse, morphing from a university-based history scholar and professor-in-training, albeit one who had begun to use new digital technologies, into an activist public historian. I had moved to New York City soon after completing the computer-aided project on coal mining strikes to learn how to produce history films. This was a conscious personal and career choice I made to leave the academy to become an independent filmmaker. My commitment to historical ideas having a greater public and political impact drove my decision to change careers. On my first job in New York in 1977 as research director for a public television series of dramatic films on major moments in US labor history I met Herbert Gutman, one of the deans of the new labor and social history whose work I had read and admired as a graduate student. I spent the next two years researching and producing historical documentaries and other kinds of dramatic films.\n\nTwo years after meeting Gutman I was invited by Herb, who taught at the CUNY Graduate Center, to co-teach a summer seminar for labor leaders for which he had secured funding from the National Endowment for the Humanities (NEH). The NEH summer seminars, in an innovative combination of academic and public history, were designed to communicate to unionized workers the fruits of the new social and labor history that Herb had done so much to pioneer and to which I had committed my nascent academic career in graduate school at UCLA. With the success of these summer seminars, which we taught at the CUNY Graduate Center in 1979 and 1980, Gutman and I decided to create the American Social History Project (ASHP) at CUNY. We reasoned that reaching 15 workers each summer in our seminars, though immensely rewarding for all involved (including the two teachers), was not as efficient as creating a new curriculum that we could make available to adult and worker education programs and teachers across the country. The project quickly received major grants in 1981 and 1982, totaling $1.2 million, from the NEH and the Ford Foundation, and under Herb’s and my leadership we rapidly hired a staff of a dozen historians, teachers, artists, and administrators to create a multimedia curriculum, entitled “Who Built America?” (WBA?). The curriculum mixed the writing of a new two-volume trade book focused on working people’s contributions to US history with a range of new multimedia productions (initially 16mm films and slide/tape shows, VHS videos and, later, a range of digital productions, including two Who Built America? CD-ROMs and several web sites such as “History Matters”). ASHP also had a second, clear orientation, in addition to developing multimedia materials: We built a vibrant education program that connected the project in its first few years with CUNY community college faculty and also New York City high school teachers who used our media materials (including specially designed accompanying viewer guides) in their classes that helped deepen and refine Who Built America?’s pedagogical impact on students. We hoped this multimedia curriculum and ASHP’s ongoing engagement with teachers would broaden the scope and popular appeal of working-class and social history and would be widely adopted in high school, community college, and worker education classrooms around the country as well as by the general public.[22]\n\nI should note here that my early exposure to electronic tools, including being a “ham” radio operator and electronics tinkerer in high school in the early 1960s and using mainframe computers at UCLA in 1975, inclined me to become an early and enthusiastic adopter of and proselytizer for personal computers when they became publicly available in the early 1980s. I insisted in 1982, for example, against resistance from some of my ASHP colleagues who expected to have secretarial help in writing and editing their WBA? chapter drafts, that we use personal computers (I was Kaypro II guy!) to facilitate the drafting and editing of the Who Built America? textbook, work on which began that year (ASHP 1990, 1992).[23]\n\nASHP stood outside of the academic history profession as traditionally understood and practiced in universities at that time. As a grant-funded, university-based project with a dozen staff members, many of us with ABDs in history who worked on the project full-time (not on traditional nine-month academic schedules), ASHP staff were clearly “alt-ac”ers several decades before anyone coined that term. We wore our non-traditional academic identities proudly and even a bit defiantly. Gutman and I also realized, nonetheless, that ASHP needed a direct link to an academic institution like CUNY to legitimize and to establish an institutional base that would allow the project to survive and thrive, which led us to instantiate ASHP inside of CUNY. The American Social History Project, in fact, celebrated its 35th anniversary in CUNY in October 2016.[24] That was a consequential decision, obviously, since ASHP might not have survived without the kind of institutional and bureaucratic support that CUNY (and the Graduate Center) have provided over the past three and a half decades. ASHP, at the same time, also stood outside of the academic history profession in believing in and in producing our work collaboratively, which militated against the “lone scholar in the archive” cult that still dominates most academic scholarship and continues to fundamentally determine the processes of promotion and tenure inside the academy. Public history, which many ASHP staff members came out of, had argued for and even privileged such collaborative work, which in a very real sense is a precursor to the more collaborative work and projects that now define much of the new digital scholarship in the Digital Humanities and in the “alt-ac” careers that have proliferated in its wake. Well before Lisa Spiro (2012) enumerated her list of key DH “values”—openness, collegiality and connectedness, diversity, and experimentation—we had embodied those very values in how we structured and operated the American Social History Project (and continue to do so), a set of values that I have also tried to incorporate and teach in all of my academic work ever since.\n\nASHP’s engagement with collaborative digital work began quite early. In 1990 we launched a series of co-ventures with social historian Roy Rosenzweig (who had been a valued and important ASHP collaborator from the outset of the project a decade earlier, including as a co-author of the Who Built America? textbook) and Bob Stein, the head of The Voyager Company, the pioneering digital publisher. Roy and I had begun in the late 1980s to ruminate about the possibilities of computer-enhanced historical presentations when Bob Stein approached me in 1990 with a proposal to turn the first volume of the WBA? trade book (which had just been published) into an electronic book (ASHP 1990).[25] Applying the best lessons Roy and I and our ASHP colleagues had learned as public historians who were committed to using visual, video, audio, and textual tools and resources to convey important moments and struggles in US history, we worked with Voyager staff to conceive, design, and produce the first Who Built America? CD-ROM in 1993, covering the years 1876 to 1914 (ASHP 1993).[26] As noted earlier, our use of multimedia forms was an essential attribute that we learned as practitioners of public history, a quite different orientation than that relied on by literary DHers who work with text analysis.\n\nThe disk, which was co-authored by Roy Rosenzweig, Josh Brown, and me, was arguably the first electronic history book and one of the first e-books ever to appear. The WBA? CD-ROM won critical popular acclaim and a number of prestigious awards, inside in the academy and beyond (Thomas 2004). It also generated, perhaps because of its success, a degree of political notoriety when its inclusion by Apple in the tens of thousands of educational packs of CD-ROMs the company gave away to K-12 schools that purchased Apple computers in 1994-95 led to a coordinated attack on WBA?, ASHP, and Apple by the Christian Right and the Moral Majority. The Radical Right was troubled by the notion conveyed in several of the literally hundreds of primary historical documents we included in the CD-ROM that “gay cowboys” might have been involved in the “taming” of the West or that abortion was common in early twentieth-century urban America. The right-wing attacks were reported in the mainstream press, including the Wall Street Journal and Newsweek.\n\nThe Right, however, ironically failed in all the furor to notice the CD-ROM’s explicitly pro-worker/anti-capitalist politics! The Right tried to get Apple to remove the WBA? CD-ROM from the education packs, but Apple ultimately backed ASHP and WBA?, though only after much contention and negative publicity.[27]\n\nDespite this political controversy, the first WBA? CD-ROM and early historical web projects like Ed Ayers’s Civil War-era The Valley of the Shadow (1993) helped imagine new possibilities for digital scholarship and digital presentations of historical work. I would suggest that the appearance of the first WBA? CD-ROM nearly a quarter century ago was one of the pioneering instances of the new digital history that contributed a decade later to the emergence of the Digital Humanities, making Roy, Josh, and me and our ASHP colleagues what I have termed in the title of this article and elsewhere in print “premature digital humanists.”[28] That said, I do believe we missed an opportunity to begin to build connections to other scholars outside of history who were undertaking similar digital work around the same time that we completed the WBA? CD-ROM in 1993. Jerry McGann, for example, was beginning his pioneering work at the University of Virginia on the Rossetti Archive and was writing his landmark study “The Rationale of HyperText” (McGann 1995). And while we became aware of each other’s work over the next half dozen years, we never quite came together to ponder the ways in which our very disparate disciplinary approaches to digital scholarship and presentation might have productively been linked up or at least put into some kind of active dialogue. As a result, digital history and digital literary studies occupied distinct academic silos, following quite different paths and embracing very different methodologies and ideas. And neither digital history nor digital literary studies had much in common with the digital new media artists who were also working in this same period and even earlier, grouped around the pioneering journal Ars Electronica.[29] This was a missed opportunity that I believe has hindered Digital Humanities from being more of a big tent and, more importantly, allowing it to become a more robust interdisciplinary force inside the academy and beyond.\n\nIn any case my digital history colleagues and I continued to pursue our own digital history work. Roy Rosenzweig, who taught at George Mason University, founded the Center for History and New Media in 1994 a year after the first WBA? CD-ROM appeared. Our two centers next collaborated on several award-winning digital history projects, including the History Matters website mentioned earlier, which made many of the public domain primary source documents presented originally in the WBA? CD-ROM available online. This proved to be a particularly useful and accessible way for teachers at both the high school and college levels to expose their students to a rich array of primary historical sources. And, following the September 11, 2001 terrorist attacks in New York and Washington, DC, our two centers were invited by the Sloan Foundation to collaborate on the development of the September 11 Digital Archive (9/11DA). As Josh Brown and I argued in an article on the creation of the 9/11DA, September 11th was “the first truly digital event of world historical importance: a significant part of its historical record—from e-mail to photography to audio to video—was expressed, captured, disseminated, or viewed in (or converted to) digital forms and formats” (Brier and Brown 2011, 101). It was also one of the first digital projects to be largely “crowdsourced,” given our open solicitation of ordinary people’s digital reminiscences, photos, and videos of the events of September 11th and its aftermath. As historians faced with the task of conceiving and building a brand new digital archive from scratch that focused on a single world historical event, we were also forced to take on additional roles as archivists and preservationists, something we had previously and happily left to professional librarians. We had to make judgments about what to include and exclude in the 9/11 archive, how and whether to display it online, how to contextualize those resources, and, when voluntary online digital submissions of materials by individuals proved insufficient to allow us to offer a fully-rounded picture of what happened, how to target particular groups (including Muslims, Latinos, and the Chinese community in lower Manhattan) with special outreach efforts to be able to include their collective and individual stories and memories in the 9/11DA. Our prior work in and long-term engagement with public history proved essential in this process. We ended up putting the archive online as we were building it, getting the initial iteration of the site up on the web in January 2002 well before the lion’s share of individual digital submissions started pouring in. The body of digital materials that came to constitute the September 11 Digital Archive ultimately totaled nearly a quarter million discrete digital items, making it one of the largest and most comprehensive digital repositories of materials on the September 11 attacks.[30]\n\nWhile literary scholars confront similar issues of preservation of and access to the materials they are presenting in digital archives, they usually have had the good fortune to be able to rely on extant and often far more circumscribed print sources as the primary materials they are digitizing, annotating, and presenting to fellow scholars and the general public. Public historians who are collecting digital historical data to capture what happened in the recent past or even the present, as we were forced to do in the September 11 Digital Archive, do not have the luxury of basing our work on a settled corpus of information or data. We also faced the extremely delicate task of putting contemporary people’s voices online, making their deepest and most painful personal insights and feelings available to a public audience. Being custodians of that kind of source material brings special responsibilities and sensitivities that most literary digital humanists don’t have to deal with when constructing their digital archives. Our methodologies and larger public imperatives as digital historians are therefore different from those of digital literary scholars. This is especially true given our commitment in the 9/11DA and other digital history archiving projects like the CHNM’s “Hurricane Digital Memory Bank” (on the devastating 2005 Gulf Coast hurricanes Katrina and Rita), as well as ASHP’s current CUNY Digital History Archive project. The latter focuses on student and faculty activism across CUNY beginning in the late 1960s and on presenting historical materials that are deeply personal and politically consequential.[31]\n\nIt is important to note that while ASHP continued to collaborate on several ongoing digital history projects with CHNM (headed first by Dan Cohen and Tom Scheinfeldt after Roy’s death in 2007, and, since 2013, by Stephen Robertson), the two centers have moved in different directions in terms of doing digital history. CHNM’s efforts have focused largely on the development of important digital software tools. CHNM’s Zotero, for example, is used to help scholars manage their research sources, while its Omeka software offers a platform for publishing online collections and exhibitions. CHNM has also established a strong and direct connection to the Digital Humanities field, especially through its THATCamps, which are participant-directed digital skills workshops and meetings.[32] On the other hand, ASHP has stayed closer to its original purpose of developing a range of well curated and pedagogically appropriate multimedia historical source materials for use by teachers and students at both the high school and college levels, intended to help them understand and learn about the past. Emblematic of ASHP’s continuing work are The Lost Museum: Exploring Antebellum American Life and Culture and HERB: Social History for Every Classroom websites as well as Mission US, an adventure-style online series of games in which younger players take on the role of young people during critical moments in US history.[33]\n\nFrom ASHP to ITP and the Digital Humanities\n\nI moved on in my own academic career after formally leaving ASHP as its executive director in 1998, though I remained actively involved in a number of ongoing ASHP digital projects. These included the development of a second WBA? CD-ROM, covering the years from 1914 to 1946, which was published in 2001 (ASHP 2001) and is still available, as well as the aforementioned 9/11 Digital Archive and the CUNY Digital History Archive. As I morphed over three decades from analog media producer, to digital media producer, to digital archivist/digital historian, I became keenly aware of the need to extend the lessons of the public and digital history movements I helped to build to my own and my graduate students’ classroom practices. That was what drove me to develop the Interactive Technology and Pedagogy (ITP) certificate program at the CUNY Graduate Center in 2002. My goal was to teach graduate students that digital tools offered real promise beyond the restricted confines of academic research in a single academic field to help us reimagine and to reshape college classrooms and the entire teaching and learning experience, as my ASHP colleagues and I began doing more than 30 years ago with the Who Built America? education program. I always tell ITP students that I take the “P” in our name (“Pedagogy”) as seriously as I take the “T” (“Technology”) as a way to indicate the centrality of teaching and learning to the way the certificate program was conceived and has operated. I have coordinated ITP for almost 15 years now and will be stepping down as coordinator at the end of the spring 2017 term. I believe that the program has contributed as much to digital pedagogy and to the Digital Humanities as anything else I’ve been involved in, not only at the CUNY Graduate Center where I have been fortunate to have labored for almost all of my academic career, but also in the City University of New York as a whole.[34] One of the ITP program’s most important and ongoing contributions to the Digital Humanities and digital pedagogy fields has been the founding in 2011 of the online Journal of Interactive Technology and Pedagogy, which is produced twice-yearly and is directed by an editorial collective of digital scholars and digital pedagogues, including faculty, graduate students, and library staff.\n\nWorking with faculty colleagues like Matt Gold, Carlos Hernandez, Kimon Keramidas, Michael Mandiberg, and Maura Smale, with many highly motivated and skilled graduate students (too numerous to name here), and committed digital administrators and leaders like Luke Waltzer, Lisa Brundage, and Boone Gorges, as well as my ongoing work with long-time ASHP colleagues and comrades Josh Brown, Pennee Bender, Andrea Ades Vasquez, and Ellen Noonan, I have been blessed with opportunities to help create a robust community of digital practice at the Graduate Center and across CUNY. This community of scholars and digital practitioners has helped develop a progressive vision of digital technology and digital pedagogy that I believe can serve as a model for Digital Humanities work in the future. Though far from where I began forty years ago as a doctoral student with an IBM 360 computer and a stack of Fortran cards, my ongoing digital work at CUNY seems to me to be the logical and appropriate culmination of a career that has spanned many identities, including as a social and labor historian, public historian, digital historian, digital producer, and, finally, as a digital pedagogue who has made what I hope has been a modest contribution to the evolution and maturation of the field of Digital Humanities.\n\nIntroduction\n\nMuch has been written of what lies inside (and outside) the digital humanities (DH). A fitting example might be the annual Day of DH, when hundreds of “DHers” (digital humanists) write about what they do and how they define the field (see https://twitter.com/dayofdh). Read enough of their stories and certain themes and patterns may emerge, but difference and pluralism will abound. More formal attempts to define the field are not hard to find—there is an entire anthology devoted to the subject (Terras, Nyhan, and Vanhoutte 2013)—and others have approached DH by studying its locations (Zorich 2008; Prescott 2016), its members (Grandjean 2014a, 2014b, 2015), their communication patterns (Ross et al. 2011; Quan-Haase, Martin, and McCay-Peet 2015), conference submissions (Weingart 2016), and so forth.\n\nA small but important subset of research looks at teaching and learning as a lens through which to view the field. Existing studies have examined course syllabi (Terras 2006; Spiro 2011) and the development of specific programs and curricula (Rockwell 1999; Siemens 2001; Sinclair 2001; Unsworth 2001; Unsworth and Butler 2001; Drucker, Unsworth, and Laue 2002; Sinclair & Gouglas 2002; McCarty 2012; Smith 2014). In addition, there are pedagogical discussions about what should be taught in DH (Hockey 1986, 2001; Mahony & Pierazzo 2002; Clement 2012) and its broader relationship to technology, the humanities, and higher education (Brier 2012; Liu 2012; Waltzer 2012).\n\nThis study adds to the literature on teaching and learning by presenting a survey of existing degree and certificate programs in DH. While these programs are only part of the activities that make up the broader world of DH, they provide a formal view of training in the field and, by extension, of the field itself. Additionally, they reflect the public face of DH at their institutions, both to potential students and to faculty and administrators outside of DH. By studying the requirements of these programs (especially required coursework), we explore the activities that make up DH, at least to the extent that they are systematically taught and represented to students during admissions and recruitment, as well as where DH programs position themselves within and across the subject boundaries of their institutions. These activities speak to broader skills and methods at play in DH, as well as some important silences. They also provide an empirical perspective on pedagogical debates, particularly the attention paid to theory and critical reflection\n\nBackground\n\nMelissa Terras (2006) was the first to point to the utility of education studies in approaching the digital humanities (or what she then called “humanities computing”). In the broadest sense, Terras distinguishes between subjects, which are usually associated with academic departments and defined by “a set of core theories and techniques to be taught” (230), and disciplines, which lack departmental status yet still have their own identities, cultural attributes, communities of practice, heroes, idols, and mythology. After analyzing four university courses in humanities computing, Terras examines other aspects of the community such as its associations, journals, discussion groups, and conference submissions. She concludes that humanities computing is a discipline, although not yet a subject: “the community exists, and functions, and has found a way to continue disseminating its knowledge and encouraging others into the community without the institutionalization of the subject” (242). Terras notes that humanities computing scholars, lacking prescribed activities, have freedom in developing their own research and career paths. She remains curious, however, about the “hidden curriculum” of the field at a time when few formal programs yet existed.\n\nFollowing Terras, Lisa Spiro (2011) takes up this study of the “hidden curriculum” by collecting and analyzing 134 English-language syllabi from DH courses offered between 2006–2011. While some of these courses were offered in DH departments (16, 11.9%), most were drawn from other disciplines, including English, history, media studies, interdisciplinary studies, library and information science, computer science, rhetoric and composition, visual studies, communication, anthropology, and philosophy. Classics, linguistics, and other languages were missing. Spiro analyzes the assignments, readings, media types, key concepts, and technologies covered in these courses, finding (among other things) that DH courses often link theory to practice; involve collaborative work on projects; engage in social media such as blogging or Twitter; focus not only on text but also on video, audio, images, games, maps, simulation, and 3D modeling; and reflect contemporary issues such as data and databases, openness and copyright, networks and networking, and interaction. Finally, Spiro presents a list of terms she expected to see more often in these syllabi, including “argument,” “statistics,” “programming,” “representation,” “interpretation,” “accessibility,” “sustainability,” and “algorithmic.”\n\nThese two studies form the broad picture of DH education. More recent studies have taken up DH teaching and learning within particular contexts, such as community colleges (McGrail 2016), colleges of liberal arts and science (Alexander & Davis 2012; Buurma & Levine 2016), graduate education (Selisker 2016), libraries (Rosenblum, et al., 2016; Varner 2016; Vedantham & Porter 2016) and library and information science education (Senchyne 2016), and the public sphere (Brennan 2016; Hsu 2016). These accounts stress common structural challenges and opportunities across these contexts. In particular, many underscore assumptions made about and within DH, including access to technology, institutional resources, and background literacies. In addition, many activities in these contexts fall outside of formal degrees and programs or even classroom learning, demonstrating the variety of spaces in which DH may be taught and trained.\n\nOther accounts have drawn the deep picture of DH education by examining the development of programs and courses at specific institutions, such as McMaster University (Rockwell 1999), University of Virginia (Unsworth 2001; Unsworth and Butler 2001; Drucker, Unsworth, and Laue 2002), University of Alberta (Sinclair & Gouglas 2002), King’s College London (McCarty 2012), and Wilfrid Laurier University (Smith 2014), among others. Abstracts from “The Humanities Computing Curriculum / The Computing Curriculum in the Arts and Humanities” Conference in 2001 contain references to various institutions (Siemens 2001), as does a subsequent report on the conference (Sinclair 2001). Not surprisingly, these accounts often focus on the histories and peculiarities of each institution, a “localization” that Knight (2011) regards as necessary in DH.\n\nOur study takes a program-based approach to studying teaching and learning in DH. While formal programs represent only a portion of the entire DH curricula, they are important in several respects: First, they reflect intentional groupings of courses, concepts, skills, methods, techniques, and so on. As such, they purport to represent the field in its broadest strokes rather than more specialized portions of it (with the exception of programs offered in specific areas, such as book history and DH). Second, these programs, under the aegis of awarding institutions and larger accrediting bodies, are responsible for declaring explicit learning outcomes of their graduates, often including required courses. These requirements form one picture of what all DHers are expected to know upon graduation (at a certain level), and this changing spectrum of competencies presumably reflects corresponding changes in the field over time. Third, formal DH programs organize teaching, research, and professional development in the field; they are channels through which material and symbolic capital flow, making them responsible, in no small part, for shaping the field itself. Finally, these programs, their requirements, and coursework are one way—perhaps the primary way—in which prospective students encounter the field and make choices about whether to enroll in a DH program and, if so, which one. These programs are also consulted by faculty and administrators developing new programs at their own institutions, both for common competencies and for distinguishing features of particular programs.\n\nIn addition to helping define the field, a study of formal DH programs also contributes to the dialogue around pedagogy in the field. Hockey, for example, has long wondered whether programming should be taught (1986) and asks, “How far can the need for analytical and critical thinking in the humanities be reconciled with the practical orientation of much work in humanities computing?” (2001). Also skeptical of mere technological skills, Simon Mahony and Elena Pierazzo (2002) argue for teaching methodologies or “ways of thinking” in DH. Tanya Clement examines multiliteracies in DH (e.g., critical thinking, commitment, community, and play), which help to push the field beyond “training” to “a pursuit that enables all students to ask valuable and productive questions that make for ‘a life worth living’” (2012, 372).\n\nOthers have called on DH to engage more fully in critical reflection, especially in relation to technology and the role of the humanities in higher education. Alan Liu notes that much DH work has failed to consider “the relation of the whole digital juggernaut to the new world order,” eschewing even clichéd topics such as “the digital divide,” “surveillance,” “privacy,” and “copyright” (2012, 491). Steve Brier (2012) points out that teaching and learning are an afterthought to many DHers, a lacuna that misses the radical potential of DH for transforming teaching and professional development. Luke Walzer (2012) observes that DH has done little to help protect and reconceptualize the role of the humanities in higher education, long under threat from austerity measures and perceived uselessness in the neoliberal academy (Mowitt 2012).\n\nThese and other concerns point to longstanding questions about the proper balance of technological skills and critical reflection in DH. While a study of existing DH programs cannot address the value of critical reflection, it can report on the presence (or absence) of such reflection in required coursework and program outcomes. Thus, it is part of a critical reflection on the field as it stands now, how it is taught to current students, and how such training will shape the future of the field. It can also speak to common learning experiences within DH (e.g., fieldwork, capstones), as well as disciplinary connections, particularly in program electives. These findings, together with our more general findings about DH activities, give pause to consider what is represented in, emphasized by, and omitted from the field at its most explicit levels of educational training.\n\nMethods\n\nThis study involved collection of data about DH programs, coding descriptions of programs and courses using a controlled vocabulary, and analysis and visualization.\n\nData Collection\n\nWe compiled a list of 37 DH programs active in 2015 (see Appendix A), drawn from listings in the field (UCLA Center for Digital Humanities 2015; Clement 2015), background literature, and web searches (e.g., “digital humanities masters”). In addition to degrees and certificates, we included minors and concentrations that have formal requirements and coursework, since these programs can be seen as co-issuing degrees with major areas of study and as inflecting those areas in significant ways. We did not include digital arts or emerging media programs in which humanities content was not the central focus of inquiry. In a few cases, the listings or literature mentioned programs that could not be found online, but we determined that these instances were not extant programs—some were initiatives or centers misdescribed, others were programs in planning or simply collections of courses with no formal requirements—and thus fell outside the scope of this study. We also asked for the names of additional programs at a conference presentation, in personal emails, and on Twitter. Because our sources and searches are all English-language, the list of programs we collected are all programs taught in Anglophone countries. This limits what we can say about global DH.\n\nFor each program, we made a PDF of the webpage on which its description appears, along with a plain text file of the description. We recorded the URL of each program and information about its title; description; institution; school, division, or department; level (graduate or undergraduate); type (degree or otherwise); year founded; curriculum (total credits, number and list of required and elective courses); and references to independent research, fieldwork, and final deliverables. After identifying any required courses for each program, we looked up descriptions of those courses in the institution’s course catalog and recorded them in a spreadsheet.\n\nCoding and Intercoder Agreement\n\nTo analyze the topics covered by programs and required courses, we applied the Taxonomy of Digital Research Activities in the Humanities (TaDiRAH 2014a), which attempts to capture the “scholarly primitives” of the field (Perkins et al. 2014). Unsworth (2000) describes these primitives as “basic functions common to scholarly activities across disciplines, over time, and independent of theoretical orientation,” obvious enough to be “self-understood,” and his preliminary list includes ‘Discovering’, ‘Annotating’, ‘Comparing’, ‘Referring’, ‘Sampling’, ‘Illustrating’, and ‘Representing’.\n\nWe doubt that any word—or classification system—works in this way. Language is always a reflection of culture and society, and with that comes questions of power, discipline/ing, and field background. Moreover, term meaning shifts over time and across locations. Nevertheless, we believe classification schema can be useful in organizing and analyzing information, and that is the spirit in which we employ TaDiRAH here.\n\nTaDiRAH is one of several classification schema in DH and is itself based on three prior sources: the arts-humanities.net taxonomy of DH projects, tools, centers, and other resources; the categories and tags originally used by the DiRT (Digital Research Tools) Directory (2014); and headings from “Doing Digital Humanities,” a Zotero bibliography of DH literature (2014) created by the Digital Research Infrastructure for Arts and Humanities (DARIAH). The TaDiRAH version used in this study (v. 0.5.1) also included two rounds of community feedback and subsequent revisions (Dombrowski and Perkins 2014). TaDiRAH’s controlled vocabulary terms are arranged into three broad categories: activities, objects, and techniques. Only activities terms were used in this study because the other terms lack definitions, making them subject to greater variance in interpretation. TaDiRAH contains forty activities terms organized into eight parent terms (‘Capture’, ‘Creation’, ‘Enrichment’, ‘Analysis’, ‘Interpretation’, ‘Storage’, ‘Dissemination’, and ‘Meta-Activities’).\n\nTaDiRAH was built in conversation with a similar project at DARIAH called the Network for Digital Methods in the Arts and Humanities (NeDiMAH) and later incorporated into that project (2015). NeDiMAH’s Methods Ontology (NeMO) contains 160 activities terms organized into five broad categories (‘Acquiring’, ‘Communicating’, ‘Conceiving’, ‘Processing’, ‘Seeking’) and is often more granular than TaDiRAH (e.g., ‘Curating’, ‘Emulating’, ‘Migrating’, ‘Storing’, and ‘Versioning’ rather than simply ‘Preservation’). While NeMO may have other applications, we believe it is too large to be used in this study. There are many cases in which programs or even course descriptions are not as detailed as NeMO in their language, and even the forty-eight TaDiRAH terms proved difficult to apply because of their number and complexity. In addition, TaDiRAH has been applied in DARIAH’s DH Course Registry of European programs, permitting some comparisons between those programs and the ones studied here.\n\nIn this study, a term was applied to a program/course description whenever explicit evidence was found that students completing the program or course would be guaranteed to undertake the activities explicitly described in that term’s definition. In other words, we coded for minimum competencies that someone would have after completing a program or course. The narrowest term was applied whenever possible, and multiple terms could be applied to the same description (and, in most cases, were). For example, a reference to book digitization would be coded as ‘Imaging’:\n\nImaging refers to the capture of texts, images, artefacts or spatial formations using optical means of capture. Imaging can be made in 2D or 3D, using various means (light, laser, infrared, ultrasound). Imaging usually does not lead to the identification of discrete semantic or structural units in the data, such as words or musical notes, which is something DataRecognition accomplishes. Imaging also includes scanning and digital photography.\n\nIf there was further mention of OCR (optical character recognition), that would be coded as ‘DataRecognition’ and so on. To take another example, a reference to visualization and other forms of analysis would be coded both as ‘Visualization’ and as its parent term, ‘Analysis’, if no more specific child terms could be identified.\n\nIn some cases, descriptions would provide a broad list of activities happening somewhere across a program or course but not guaranteed for all students completing that program or course (e.g., “Through our practicum component, students can acquire hands-on experience with innovative tools for the computational analysis of cultural texts, and gain exposure to new methods for analyzing social movements and communities enabled by new media networks.”). In these cases, we looked for further evidence before applying a term to that description.\n\nStudents may also acquire specialty in a variety of areas, but this study is focused on what is learned in common by any student who completes a specific DH program or course; as such, we coded only cases of requirements and common experiences. For the same reason, we coded only required courses, not electives. Finally, we coded programs and required courses separately to analyze whether there was any difference in stated activities at these two levels.\n\nTo test intercoder agreement, we selected three program descriptions at random and applied TaDiRAH terms to each. In only a handful of cases did all three of us agree on our term assignments. We attribute this low level of agreement to the large number of activities terms in TaDiRAH, the complexity of program/course descriptions, questions of scope (whether to use a broader or narrower term), and general vagueness. For example, a program description might allude to work with texts at some point, yet not explicitly state text analysis until later, only once, when it is embedded in a list of other examples (e.g., GIS, text mining, network analysis), with a reference to sentiment analysis elsewhere. Since texts could involve digitization, publishing, or other activities, we would not code ‘Text analysis’ immediately, and we would only code it if students would were be guaranteed exposure to this such methods in the program. To complicate matters further, there is no single term for text analysis in TaDiRAH—it spans across four (‘Content analysis’, ‘Relational analysis’, ‘Structural analysis’, and ‘Stylistic analysis’)—and one coder might apply all four terms, another only some, and the third might use the parent term ‘Analysis’, which also includes spatial analysis, network analysis, and visualization.\n\nEven after reviewing these examples and the definitions of specific TaDiRAH terms, we could not reach a high level of intercoder agreement. However, we did find comparing our term assignments to be useful, and we were able to reach consensus in discussion. Based on this experience, we decided that each of us would code every program/course description and then discuss our codings together until we reached a final agreement. Before starting our preliminary codings, we discussed our understanding of each TaDiRAH term (in case it had not come up already in the exercise). We reviewed our preliminary codings using a visualization showing whether one, two, or three coders applied a term to a program/course description. In an effort to reduce bias, especially framing effects (cognitive biases that result from the order in which information is presented), the visualization did not display who had coded which terms. If two coders agreed on a term, they explained their codings to the third and all three came to an agreement. If only one coder applied a term, the other two explained why they did not code for that term and all three came to an agreement. Put another way, we considered every term that anyone applied, and we considered it under the presumption that it would be applied until proven otherwise. Frequently, our discussions involved pointing to specific locations in the program/course descriptions and referencing TaDiRAH definitions or notes from previous meetings when interpretations were discussed.\n\nIn analyzing our final codings, we used absolute term frequencies (the number of times a term was applied in general) and weighted frequencies (a proxy for relative frequency and here a measure of individual programs and courses). To compute weighted frequencies, each of the eight parent terms were given a weight of 1, which was divided equally among their subterms. For example, the parent term ‘Dissemination’ has six subterms, so each of those were assigned an equal weight of one-sixth, whereas ‘Enrichment’ has three subterms, each assigned a weight of one-third. These weights were summed by area to show how much of an area (relatively speaking) is represented in program/course descriptions, regardless of area size. If all the subterms in an area are present, that entire area is present—just as it would be if we had applied only the broader term in the first place. These weighted frequencies are used only where programs are displayed individually.\n\nInitially, we had thought about comparing differences in stated activities between programs and required courses. While we found some variations (e.g., a program would be coded for one area of activities but not its courses and vice versa), we also noticed cases in which the language used to describe programs was too vague to code for activities that were borne out in required course descriptions. For this reason and to be as inclusive as possible with our relatively conservative codings, we compared program and course data simultaneously in our final analysis. Future studies may address the way in which program descriptions connect to particular coursework, and articulating such connections may help reveal the ways in which DH is taught (in terms of pedagogy) rather than only its formal structure (as presented here).\n\nAnalysis and Visualization\n\nIn analyzing program data, we examined the overall character of each program (its title), its structure (whether it grants degrees and, if so, at what level), special requirements (independent study, final deliverables, fieldwork), and its location, both in terms of institutional structure (e.g., departments, labs, centers) and discipline(s). We intended to analyze more thoroughly the number of required courses as compared to electives, the variety of choice students have in electives, and the range of departments in which electives are offered. These comparisons proved difficult: even within an American context, institutions vary in their credit hours and the formality of their requirements (e.g., choosing from a menu of specific electives, as opposed to any course from a department or “with permission”). These inconsistencies multiply greatly in an international context, and so we did not undertake a quantitative study of the number or range of required and elective courses.\n\nProgram data and codings were visualized using the free software Tableau Public. All images included in this article are available in a public workbook at https://public.tableau.com/views/DigitalHumanitiesProgramsSurvey/Combined. As we discuss in the final section, we are also building a public-facing version of the data and visualizations, which may be updated by members of the DH community. Thus, the data presented here can and should change over time, making these results only a snapshot of DH in some locations at the present.\n\nAnglophone Programs\n\nThe number of DH programs in Anglophone countries has risen sharply over time, beginning in 1991 and growing steadily by several programs each year since 2008 (see Figure 1). This growth speaks to increased capacity in the field, not just by means of centers, journals, conferences, and other professional infrastructure, but also through formal education. Since 2008, there has been a steady addition of several programs each year, and based on informal observation since our data collection ended, we believe this trend continues.\n\nProgram Titles\n\nMost of the programs in our collected data (22, 59%) are titled simply “Digital Humanities,” along with a few variations, such as “Book History and Digital Humanities” and “Digital Humanities Research” (see Figure 2). A handful of programs are named for particular areas of DH or related topics (e.g., “Digital Culture,” “Public Scholarship”), and only a fraction (3 programs, 8%) are called “Humanities Computing.” We did not investigate changes in program names over time, although this might be worthwhile in the future.\n\nStructure\n\nLess than half of DH programs in our collected data grant degrees: some at the level of bachelor’s (8%), most at the level of master’s (22%), and some at the doctoral (8%) level (Figure 3). The majority of DH programs are certificates, minors, specializations, and concentrations—certificates being much more common at the graduate level and nearly one-third of all programs in our collected data. The handful of doctoral programs are all located in the UK and Ireland.\n\nIn addition to degree-granting status, we also examined special requirements for the 37 DH programs in our study. Half of those programs require some form of independent research (see Figure 4). All doctoral programs require such research; most master’s programs do as well. Again, we only looked for cases of explicit requirements; it seems likely that research of some variety is conducted within all the programs analyzed here. However, we focus this study on explicit statements of academic activity in order to separate the assumptions of practitioners of DH about its activities from what appears in public-facing descriptions of the field.\n\nHalf of DH programs in our collected data require a final deliverable, referred to variously as a capstone, dissertation, portfolio, or thesis (see Figure 5). Again, discrepancies between written and unwritten expectations in degree programs abound—and are certainly not limited to DH—and some programs may have not explicitly stated this requirement, so deliverables may be undercounted. That said, most graduate programs require some kind of final deliverable, and most undergraduate and non-degree-granting programs (e.g., minors, specializations) do not.\n\nFinally, about one-quarter of programs require fieldwork, often in the form of an internship (see Figure 6). This fieldwork requirement is spread across degree types and levels.\n\nLocation and Disciplinarity\n\nAbout one-third of the DH programs in our dataset are offered outside of academic schools/departments (in centers, initiatives, and, in one case, jointly with the library), and most issue from colleges/schools of arts and humanities (see Figure 7). Although much DH work occurs outside of traditional departments (Zorich 2008), formal training in Anglophone countries remains tied to them. Most DH concentrations and specializations are located within English departments, evidence for Kirschenbaum’s claim that DH’s “professional apparatus…is probably more rooted in English than any other departmental home” (2010, 55).\n\nThe elective courses of DH programs span myriad departments and disciplines. The familiar humanities departments are well represented (art history, classics, history, philosophy, religion, and various languages), along with computer science, design, media, and technology. Several programs include electives drawn from education departments and information and library science. More surprising departments (and courses) include anthropology (“Anthropological Knowledge in the Museum”), geography (“Urban GIS”), political science (“New Media and Politics”), psychology (“Affective Interaction”), sociology (“Social and Historical Study of Information, Software, and Networks”), even criminology (“Cyber Crime”).\n\nThe number of electives required by each program and the pool from which they may be drawn varies greatly among programs, and in some cases it is so open-ended that it is nearly impossible to document thoroughly. Some programs have no elective courses and focus only on shared, required coursework. Others list dozens of potential elective courses as suggestions, rather than an exhaustive list. Because course offerings, especially in cross-disciplinary areas, change from term to term and different courses may be offered under a single, general course listing such as “Special Topics,” the list of elective course we have collected is only a sample of the type of courses students in DH programs may take, and we do not analyze them quantitatively here.\n\nTheory and Critical Reflection\n\nTo analyze the role of theory and critical reflection in DH programs, we focused our analysis on two TaDiRAH terms: ‘Theorizing’,\n\na method which aims to relate a number of elements or ideas into a coherent system based on some general principles and capable of explaining relevant phenomena or observations. Theorizing relies on techniques such as reasoning, abstract thinking, conceptualizing and defining. A theory may be implemented in the form of a model, or a model may give rise to formulating a theory.\n\nand ‘Meta: GiveOverview’, which\n\nrefers to the activity of providing information which is relatively general or provides a historical or systematic overview of a given topic. Nevertheless, it can be aimed at experts or beginners in a field, subfield or specialty.\n\nIn most cases, we used ‘Meta: GiveOverview’ to code theoretical or historical introductions to DH itself, though any explicit mention of theory was coded (or also coded) as ‘Theorizing’. We found that all DH programs, whether in program descriptions or required courses, included some mention of theory or historical/systematic overview (see Figure 8).\n\nAccordingly, we might say that each program, according to its local interpretation, engages in some type of theoretical or critical reflection. We cannot, of course, say much more about the character of this reflection, whether it is the type of critical reflection called for in the pedagogical literature, or how this reflection interfaces with the teaching of skills and techniques in these programs. We hope someone studies this aspect of programs, but it is also worth noting that only 6 of the 37 programs here were coded for ‘Teaching/Learning’ (see Figure 12). Presumably, most programs do not engage theoretically with issues of pedagogy or the relationship between DH and higher education, commensurate with Brier’s claim that these areas are often overlooked (2012). Such engagement may occur in elective courses or perhaps nowhere in these programs.\n\nEuropean Programs\n\nAll of the 37 programs discussed above are located in Anglophone countries, most of them in the United States (22 programs, 60%). We note that TaDiRAH, too, originates in this context, as does our English-language web searches for DH programs. While this data is certainly in dialogue with the many discussions of DH education cited above, it limits what we can say about DH from a global perspective. It is important to understand the various ways DH manifests around the globe, both to raise awareness of these approaches and to compare the ways in which DH education converges and diverges across these contexts. To that end, we gathered existing data on European programs by scraping DARIAH’s Digital Humanities Course Registry (DARIAH-EU 2014a) and consulting the European Association for Digital Humanities’ (EADH) education resources webpage (2016). This DARIAH/EADH data is not intended to stand in for the entirety of global DH, as it looks exclusively at European programs (and even then it is limited in interpretation by our own language barriers). DH is happening outside of this scope (e.g., Gil 2017), and we hope that future initiatives can expand the conversation about DH programs worldwide—possibly as part of our plans for data publication, which we address at the end of this article.\n\nDARIAH’s database lists 102 degree programs, 77 of which were flagged in page markup as “outdated” with the note, “This record has not been revised for a year or longer.” While inspecting DARIAH data, we found 43 programs tagged with TaDiRAH terms, and we eliminated 17 entries that were duplicates, had broken URLs and could not be located through a web search, or appeared to be single courses or events rather than formal programs. We also updated information on a few programs (e.g., specializations classified as degrees). We then added 5 programs listed by EADH but not by DARIAH, for a grand total of 93 European DH programs (only 16 of which were listed jointly by both organizations). We refer to this dataset as “DARIAH/EADH data” in the remainder of this paper. A map of these locations is provided in Figure 9, and the full list of programs considered in this paper is given in Appendices.\n\nThe DARIAH/EADH data lists 93 programs spread across parts of Europe, with the highest concentration (33%) in Germany (see Table 1). We caution here and in subsequent discussions that DARIAH and EADH may not have applied the same criteria for including programs as we did in our data collection, so results are not directly comparable. Some programs in informatics or data asset management might have been ruled out using our data collection methods, which were focused on humanities content.\n\nTable 1. Summary of programs included in our collected data and DARIAH/EADH data Country Programs in our collected data\n\nN (%) Programs in DARIAH/EADH data\n\nN (%) Australia 1 (3%) – Austria – 1 (1%) Belgium — 2 (2%) Canada 6 (16%) — Croatia — 3 (3%) Finland – 1 (1%) France – 8 (9%) Germany – 31 (33%) Ireland 3 (8%) 4 (4%) Italy – 4 94%) Netherlands – 16 (17%) Norway – 1 (1%) Portugal – 1 (1%) Spain – 2 (2%) Sweden – 1 (1%) Switzerland – 6 (7%) United Kingdom 5 (14%) 12 (13%) United States 22 (60%) –\n\nProgram Titles\n\nA cursory examination of the DARIAH/EADH program title reveals more variety, including many programs in computer linguistics and informatics (see Appendix B). We did not analyze these titles further because of language barriers. And again, we caution that some of these programs might not have been included according to the criteria for our study, though the vast majority appear relevant.\n\nStructure\n\nMost programs in the DARIAH/EADH data are degree-granting at the level of master’s (61%) or bachelor’s (25%) (see Figure 10). While we are reasonably confident in these broad trends, we are skeptical of the exact totals for two reasons. In DARIAH’s Registry, we noticed several cases of specializations being labeled as degrees. Though we rectified these cases where possible, language barriers prevented us from more thoroughly researching each program—another challenge that a global study of DH would encounter. On the other hand, it’s also possible that non-degree programs were undercounted in general, given that the Registry was meant to list degrees and courses. Based on our inspection of each program, we do not believe these errors are widespread enough to change the general distribution of the data: more European programs issue degrees, mostly at the master’s level.\n\nLocation and Disciplinarity\n\nMost European programs are also located in academic divisions called colleges, departments, faculties, or schools (see Figure 11), depending on country. Only a handful of programs are located in institutes, centres, or labs, even less frequently than in our collected data.\n\nWe did not analyze disciplinarity in the DARIAH/EADH data because the programs span various countries, education systems, and languages—things we could not feasibly study here. However, 43 programs in the DARIAH/EADH data were tagged with TaDiRAH terms, allowing for comparison with programs in our collected data. These speak to what happens in DH programs in Europe, even if their disciplinary boundaries vary.\n\nDH Activities\n\nTo analyze the skills and methods at play in DH programs, we examined our TaDiRAH codings in terms of overall term frequency (see Figure 12) and weighted frequency across individual programs (see Figures 13 and 14). Several trends were apparent in our codings, as well as DARIAH-listed programs that were also tagged with TaDiRAH terms.\n\nIn our data on Anglophone programs of DH programs, analysis and meta-activities (e.g., ‘Community building’, ‘Project management’, ‘Teaching/Learning’) make up the largest share of activities, along with creation (e.g., ‘Designing’, ‘Programming’, ‘Writing’). This is apparent in absolute term frequencies (see Figure 12, excepting ‘Theorizing’ and ‘Meta: GiveOverview’) and in a heatmap comparison of programs (see Figure 13). Again, the heatmap used weighted frequencies to adjust for the fact that some areas have few terms, while others have more than double the smallest. It is worth noting that ‘Writing’ is one of the most frequent terms (11 programs), but this activity certainly occurs elsewhere and is probably undercounted because it was not explicitly mentioned in program descriptions. The same may be true for other activities.\n\nMany program specializations seem to follow from the flavor of DH at particular institutions (e.g. the graduate certificate at Stanford’s Center for Spatial and Textual Analysis, University of Iowa’s emphasis on public engagement), commensurate with Knight’s (2011) call for “localization” in DH.\n\nIn contrast with the most frequent terms, some terms were never applied to program/course descriptions in our data, including ‘Translation’, ‘Cleanup’, ‘Editing’, and ‘Identifying’. Enrichment and storage activities (e.g., ‘Archiving’, ‘Organizing’, ‘Preservation’) were generally sparse (only 1.9% of all codings), even after compensating for the fact that these areas have fewer terms. We suspect that these activities do occur in DH programs and courses—in fact, they are assumed in broader activities such as thematic research collections, content management systems, and even dissemination. Their lack of inclusion in program/course descriptions seems constituent with claims made by librarians that their expertise in technology, information organization, and scholarly communication is undervalued in the field, whether instrumentalized as part a service model that excludes them from the academic rewards of and critical decision-making in DH work (Muñoz 2013; Posner 2013) or devalued as a form of feminized labor (Shirazi 2014). Ironically, these abilities are regarded as qualifications for academic librarian positions and as marketable job skills for humanities students and, at the same time, as a lesser form of academic work, often referred to as faculty “service” (Nowviskie 2012; Sample 2013; Takats 2013). We suspect that many program descriptions replicate this disconnect by de-emphasizing some activities (e.g., storage, enrichment) over others (e.g., analysis, project management).\n\nGenerally, there seems to be less emphasis on content (‘Capture’, ‘Enrichment’, and ‘Storage’ terms) and more focus on platforms and tools (‘Analysis’ and ‘Meta-Activities’ terms) within programs in our collected data. In interpreting this disparity, we think it’s important to attend to the larger contexts surrounding education in various locations. The Anglophone programs we studied are mostly located in the United States, where “big data” drives many decisions, including those surrounding higher education. As boyd and Crawford note, this phenomenon rests on the interplay of technology, analysis, and “[m]ythology: the widespread belief that large data sets offer a higher form of intelligence and knowledge that can generate insights that were previously impossible, with the aura of truth, objectivity, and accuracy” (2013: 663). Within this context, programs advertising analysis, visualization, and project management may appear as more attractive to prospective students and supporting institutions, two important audiences of program webpages. This influence does not mean that such activities do not occur or are not important to DH, but it again turns attention to questions about the way in which these skills are developed and deployed and whether that occurs against a backdrop of critical reflection on methods and tools. How these broad program-level descriptions play out in the context of particular courses and instruction is beyond the scope of this program-level study, but we think that surfacing the way programs are described is an important first step to a deeper analysis of these questions.\n\nWhen comparing our 37 programs to the 43 TaDiRAH-tagged European ones, several differences emerge—though we caution that these findings, in particular, may be less reliable than others presented here. In our study, we coded for guaranteed activities, explicit either in program descriptions or required course description. In DARIAH’s Registry, entries are submitted by users, who are given a link to another version of TaDiRAH (2014b) and instructed to code at least one activities keyword (DARIAH-EU 2014b). We do not know the criteria each submitter uses for applying terms, and it’s likely that intercoder agreement would be low in absence of pre-coordination. For example, programs in the Netherlands are noticeably sparser in their codings than programs elsewhere—perhaps submitted by the same coder, or coders with a shared understanding and different from the others (see Figure 14).\n\nWe tried to compare directly our codings with DARIAH data by looking at five programs listed in common. Only one of these programs had TaDiRAH terms in DARIAH data: specifically, all eight top-level terms. When examining other programs, we found several tagged with more than half of the top-level terms and one tagged with 40 of 48 activities terms. These examples alone suggest that DARIAH data may be maximally inclusive in its TaDiRAH codings. Nevertheless, we can treat this crowdsourced data as reflective of broad trends in the area and compare them, generally, to those found in our study. Moreover, there does not appear to be any geographic or degree-based bias in the DARIAH data: the 43 tagged programs span ten different countries and both graduate and undergraduate offerings, degree and non-degree programs.\n\nComparing term frequencies in our collected data and DARIAH/EADH data (see Figure 12), it appears that enrichment, capture, and storage activities are more prevalent in European programs, while analysis and meta-activities are relatively less common (see Table 2). While both datasets have roughly the same number of programs (37 and 43, respectively), the DARIAH data has over twice as many terms as our study. For this reason, we computed a relative expression of difference by dividing the total percent of a TaDiRAH area in DARIAH data by the total percent in our study. Viewed this way, ‘Enrichment’ has over five times as many weighted codings in DARIAH as our study, followed by ‘Capture’ with over twice as many; ‘Analysis’, ‘Interpretation’, and ‘Meta-activities’ are less common. Thus, Anglophone and European programs appear to focus on different areas, within the limitations mentioned above and while still overlapping in most areas. This difference might be caused by the inclusion of more programs related to informatics, digital asset management, and communication in the DARIAH data than in our collected data, or the presence of more extensive cultural heritage materials, support for them, and integration into European programs. At a deeper level, this difference may reflect a different way of thinking or talking about DH or the histories of European programs, many of which were established before programs in our collected data.\n\nTable 2. Summary of TaDiRAH term coding frequencies (grouped) TaDiRAH parent term (includes subterms) In our collected data\n\nN (%) In DARIAH\n\nN (%) Factor of difference overall (weighted) Capture 13 (6.1%) 73 (15.7%) 5.6 (2.55) Creation 35 (16.5%) 74 (15.9%) 2.1 (0.96%) Enrichment 4 (1.9%) 48 (10.3%) 12.0 (5.46) Analysis 47 (22.2%) 77 (16.5%) 1.6 (0.75) Interpretation 27 (12.7%) 40 (8.6%) 1.5 (0.67) Storage 11 (5.2%) 43 (9.2%) 3.9 (1.78) Dissemination 24 (11.3%) 63 (13.5%) 2.6 (1.19) Meta-Activities 51 (24.1%) 48 (10.3%) 0.9 (0.43)\n\nReflections on TaDiRAH\n\nSince TaDiRAH aims to be comprehensive of the field—even machine readable—we believe our challenges applying it may prove instructive to revising the taxonomy for wider application and for considering how DH is described more generally.\n\nMost examples of hard-to-code language were technical (e.g., databases, content management systems, CSS, and XML) and blurred the lines between capture, creation, and storage and, at a narrower level, web development and programming. Given the rate at which technologies change, it may be difficult to come up with stable terms for DH. At the same time, we may need to recognize that some of the most ubiquitous technologies and platforms in the field (e.g., Omeka, WordPress) actually subsume over various activities and require myriad skills. This, in turn, might give attention to skills such as knowledge organization, which seem rarely taught or mentioned on an explicit basis.\n\nA separate set of hard-to-code activities included gaming and user experience (UX). We suspect the list might grow as tangential fields intersect with DH. Arguably, UX falls under ‘Meta: Assessing’, but there are design and web development aspects of UX that distinguish it from other forms of assessment, aspects that probably belong better with ‘Creation’. Similarly, gaming might be encompassed by ‘Meta: Teaching/Learning’, which\n\ninvolves one group of people interactively helping another group of people acquire and/or develop skills, competencies, and knowledge that lets them solve problems in a specific area of research,\n\nbut this broad definition omits distinctive aspects of gaming, such as play and enjoyment, that are central to the concept. Gaming and UX, much like the technical cases discussed earlier, draw on a range of different disciplines and methods, making them difficult to classify. Nevertheless, they appear in fieldwork and are even taught in certain programs/courses, making it important to represent them in the taxonomy of DH.\n\nWith these examples in mind and considering the constantly evolving nature of DH and the language that surrounds it, it is difficult and perhaps counterproductive to suggest any concrete changes to TaDiRAH that would better represent the activities involved in “doing DH.” We present these findings as an empirical representation of what DH in certain parts of the world looks like now, with the hope that it will garner critical reflection from DH practitioners and teachers about how the next generation of students perceives our field and the skills that are taught and valued within it.\n\nConclusion and Further Directions\n\nOur survey of DH programs in the Anglophone world may be summarized by the following points.\n\nThe majority of Anglophone programs are not degree-granting; they are certificates, minors, specializations, and concentrations. By comparison, most European programs are degree-granting, often at the master’s level.\n\nAbout half of Anglophone programs require some form of independent research, and half require a final deliverable, referred to variously as a capstone, dissertation, portfolio, or thesis. About one-quarter of programs require fieldwork, often in the form of an internship.\n\nAbout one-third of Anglophone DH programs are offered outside of academic schools/departments (in centers, initiatives, and, in one case, jointly with the library). By comparison, most European programs are located in academic divisions; only a handful are offered in institutes, centres, or labs.\n\nAnalysis and meta-activities (e.g., community building, project management) make up the largest share of activities in Anglophone programs, along with creation (e.g., designing, programming, writing). By contrast, activities such as enrichment, capture, and storage seem more prevalent in European programs. Some of these areas may be over- or under-represented for various cultural reasons we’ve discussed above.\n\nAs with any survey, there may be things uncounted, undercounted, or miscounted, and we have tried to note these limitations throughout this article.\n\nOne immediate application of this data is a resource for prospective students and those planning and revising formal programs. At minimum, this data provides general information about these 37 programs, along with some indication of special areas of emphasis—a compliment to DARIAH/EADH data. As we discussed earlier, this list should be more inclusive of DH throughout the globe, and that probably requires an international team fluent in the various languages of the programs. Following our inspection of DARIAH’s Registry, we believe it’s difficult to control the accuracy of such data in a centralized way. To address both of these challenges, we believe that updates to this data are best managed by the DH community, and to that end, we have created a GitHub repository at https://github.com/dhprograms/data where updates can be forked and pulled into a master branch. This branch will be connected to Tableau Public for live versions of visualizations similar to the ones included here. Beyond this technical infrastructure, our next steps include outreach to the community to ensure that listings are updated and inclusive in ways that go beyond our resources in this study.\n\nSecond, there are possibilities for studying program change over time using the archive of program webpages and course descriptions generated by this study. Capture of program and course information in the future might allow exploration of the growth of the field as well as changes in its activities. We believe that a different taxonomy or classification system might prove useful here, as well as a different method of coding. These are active considerations as we build the GitHub repository. We also note that this study may induce some effect (hopefully positive) in the way that programs and courses are described, perhaps pushing them to be more explicit about the nature and extent of DH activities.\n\nFinally, we hope this study gives the community pause to consider how DH is described and represented, and how it is taught. If there are common expectations not reflected here, perhaps DHers could be more explicit about how we, as a community, describe the activities that make up DH work, at least in building our taxonomies and describing our formal programs and required courses. Conversely, if there are activities that seem overrepresented here, we might consider why those activities are prized in the field (and which are not) and whether this is the picture we wish to present publicly. We might further consider this picture in relationship to the cultural and political-economic contexts in which DH actually exists. Are we engaging with these larger structures? Do the activities of the field reflect this? Is it found in our teaching and learning, and in the ways that we describe those?\n\nIntroduction\n\nInformation pollution, information overload, and infoglut are some of the most common terms used to describe the “almost infinite abundance” and “surging volume” of information that “floods” and “swamps” us daily (Hemp 2009). Popular media articles appear regularly offering tips and strategies to “cope with,” “conquer,” and even “recover” from information overload (e.g., Harness 2015; Shin 2014; Tattersall 2015). Information Fatigue Syndrome, a term coined in 1996, refers to the stress and exhaustion caused by a constant bombardment of data (Vulliamy 1996). In Data Smog: Surviving the Information Glut, David Shenk (1997) argues that the surplus of information doesn’t enhance our lives, but instead undermines and overwhelms us to the point of anxiety and indecision. According to research conducted by Project Information Literacy researchers, “it turns out that students are poorly trained i"
    }
}