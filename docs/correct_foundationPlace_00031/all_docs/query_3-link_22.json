{
    "id": "correct_foundationPlace_00031_3",
    "rank": 22,
    "data": {
        "url": "https://medium.com/kantega/exploring-the-responsible-ai-landscape-books-for-every-level-of-curiosity-and-expertise-fee05a296b8d",
        "read_more_link": "",
        "language": "en",
        "title": "Exploring the Responsible AI Landscape: Books for Every Level of Curiosity and Expertise",
        "top_image": "https://miro.medium.com/v2/resize:fit:667/1*adiClTLZSan4bba4SUGfWw.jpeg",
        "meta_img": "https://miro.medium.com/v2/resize:fit:667/1*adiClTLZSan4bba4SUGfWw.jpeg",
        "images": [
            "https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:88:88/1*IS_S-KehtnmYv6x62GmnUA.jpeg",
            "https://miro.medium.com/v2/resize:fill:48:48/1*sVZcyG3XAsFObaGDXQ9g8g.png",
            "https://miro.medium.com/v2/resize:fill:144:144/1*IS_S-KehtnmYv6x62GmnUA.jpeg",
            "https://miro.medium.com/v2/resize:fill:64:64/1*sVZcyG3XAsFObaGDXQ9g8g.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Espen Haukeland Kristensen",
            "medium.com"
        ],
        "publish_date": "2023-08-24T11:11:51.894000+00:00",
        "summary": "",
        "meta_description": "Lately, I’ve immersed myself in the expansive realm of responsible AI, delving into anything that touches upon bias, fairness, privacy, and explainability — essentially, the principles that underpin…",
        "meta_lang": "en",
        "meta_favicon": "https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png",
        "meta_site_name": "Medium",
        "canonical_link": "https://medium.com/kantega/exploring-the-responsible-ai-landscape-books-for-every-level-of-curiosity-and-expertise-fee05a296b8d",
        "text": "Espen Haukeland Kristensen\n\n·\n\nFollow\n\nPublished in\n\nKantega\n\n·\n\n13 min read\n\n·\n\nAug 24, 2023\n\n--\n\nLately, I’ve immersed myself in the expansive realm of responsible AI, delving into anything that touches upon bias, fairness, privacy, and explainability — essentially, the principles that underpin ethical AI. This is a part of both my personal and Kantega’s shared commitment to responsible AI practices, which means we’re committed to always consider bias in our data, and to making responsible AI a responsibility for the entire organization.\n\nHere’s the game plan: I will dissect each book based on who it’s meant for, who else could benefit from it, how technical it gets, and my overall impression or opinion. Plus, I’m throwing in an ‘I Wish They Talked About This’ section at the end, with pointers to other reading that might scratch that itch. And if you’re curious about what I’m queuing up, I’ve got a list of books I’m eager to read, along with a few words on why they caught my attention.\n\nKudos to those who tackle the whole list, but if you’re short on time, here’s the quick version:\n\nIf you’re a beginner and can handle Norwegian, read “Maskiner som tenker”. (Anyone who has a recommendation for an English-language equivalent, DM me.)\n\nIf your perspective is political, read “The Age of AI” — if you’re looking for more actionable recommendations and opinions, pick up “Redesigning AI” when you’re done.\n\nIf your concern is ethical, read (from least to most technical) “Weapons of Math Destruction”, “Data Feminism” and “The Ethical Algorithm”.\n\nIf you’re technical or a professional you can probably benefit from the perspectives of most of the above, but “The Ethical Algorithm” and “Reliable Machine Learning” are probably best suited for you.\n\nIf you’re a insert-organization-here certified geek about anonymization and privacy, have a stab at “The Algorithmic Foundations of Differential Privacy”.\n\nThere are links to each book in the review section below.\n\nLastly, if you know any books that aren’t covered below (neither in reviews nor my to-read’s), give me a shout! You can reach me by DM on LinkedIn, or through the comments below. Like any good consultant I love to connect on LinkedIn, but any requests without a message are ignored — let me know who you are and what your interests are, and I’m sure we can connect.\n\n“Maskiner som tenker”, Inga Strümke\n\nTarget audience: Casual readers, non-technical management, politicians. Norwegian only! (A Danish version is on its way, and I’m hoping someone will pick it up for the English-speaking market.)\n\nOther people who might like it: Technical experts looking for good examples and simple ways to explain things.\n\nLevel of technicality: Low, no prior experience or knowledge necessary.\n\nSummary: “Maskiner som tenker” gives an introduction to machine learning, neural nets and transformer models. It starts from the inception of the machine learning field, moving through the various “AI winters” before ending in the world of 2023, covering the joys and horrors of our post-ChatGPT world. Everything is introduced in simple language, with understandable examples, and some historical context.\n\nOverall impression: This is really the book when it comes to giving an introduction to machine learning in 2023, for Norwegians. I can’t recommend it enough for anyone looking for an intro, and for experts it’s great at providing some simple examples and explanations. I’ll be throwing this book at my friends and relatives who want to understand what I’m actually on about whenever they ask me about my job. I really like how Strümke chooses to focus on the near-future and already-here issues of machine learning, in stead of getting nerd-sniped by the “what if Skynet”-apocalyptic worries that are still a long way away.\n\nI wish they covered: The book could potentially be a little bit more opinionated and concrete in what should be done today in terms of regulation and movement in the field, but that’s my only critique — and that might be a different book. Go read it, and while you’re at it give Inga Strümke a follow on LinkedIn — she’s brilliant.\n\n“Weapons of Math Destruction”, Cathy O’Neil\n\nTarget audience: Technical experts looking for patterns to avoid, and horror stories.\n\nOther people who might like it: Regulators looking for some ideas on what to ask your technical staff about.\n\nLevel of technicality: Mild.\n\nSummary: “Weapons of Math Destruction” focuses on the risks and harms of building such large and complex math machines as machine learning systems (and certain other systems) are. It showcases the issues that arise if you treat it all as a big black box and just “throw data at it”, blindly trusting whatever comes out the other end. A key example is that of predictive policing, where current policing biases data on where crime occurs, which is put into an ML system that predicts that crime will occur in those places, which leads to more patrols there, further increasing the amount of crime caught and predicting crime there, etc.\n\nOverall impression: A very good book that many people will benefit from reading. It’s principles on what constitutes a “Weapon of Math Destruction” is something any person implementing a big data / ML system should know by heart. It can get a little pessimistic at times, but never truly unjustified.\n\nI wish they covered: Nothing much — don’t expect to get a thorough intro or deep-dive into the technicalities of machine learning, though.\n\n“Data Feminism”, Catherine D’Ignazio & Lauren F. Klein\n\nTarget audience: Technical personnel working with any kind of big data.\n\nOther people who might like it: Management touching big data.\n\nLevel of technicality: Medium. Focus on data, not ML.\n\nSummary: “Data Feminism” takes you through a whole range of issues in how we collect and use data, in particular in the context of big data use cases (always consider bias, remember?). It gives a list of principles accompanied by examples on do’s and don’ts when it comes to data collection and use. You may have considered many of these aspects, but I can near guarantee that you have not considered all. The book also has a series of visualizations, some of them really good examples on how to display data in a way that shows the diversity and balance of your data.\n\nOverall impression: We should all be feminists, but regardless on your opinion on that: we should all be data feminists — i.e., pursuing equality in how we collect, analyze and process data. This is a handbook that will guide you through examples on how to, or not to, do that.\n\nI wish they covered: No notes. Again, this isn’t an ML book, but it’s highly relevant for anyone who will be doing ML.\n\n“The Age of AI”, Henry Kissinger, Eric Schmidt & Daniel Huttenlocher\n\nTarget audience: Non-technical staff, politicians.\n\nOther people who might like it: Technical personnel looking for a high-level, outside perspective and historical context.\n\nLevel of technicality: None.\n\nSummary: Written by (among others) that Henry Kissinger, “The Age of AI” gives a thorough background of historical context, bringing us all the way forwards to the AI reality today, and looking ahead. It takes a 10,000 foot view on the field and recent developments, focused on the question of “how do we deal with this?”.\n\nOverall impression: One of my favorite chapters was the one covering AI weapons and how it will affect military strategy and defense politics, with the key tenet being: “Once someone has offensive AI weapons, we will all need to have defensive AI weapons.” This will move us into a world where we do not understand what happens moment-to-moment, and require a massive trust in these tools. It’s obvious once stated, but something I hadn’t yet reflected on. If you, like me, are a little impatient: skip the parts with a lot of history — it’s quite slow, much of it known, and not too important for the end result.\n\nI wish they covered: The book is not too concrete, also not very opinionated. I wish it outlined in more detail what could be possible strategies for regulating (or not regulating) AI, and also that it highlighted some more detailed opinions of the authors. As is, it’s a little too general and neutral for my taste. Look to “Redesigning AI” for something that offers this.\n\n“The Ethical Algorithm”, Michael Kearns, Aaron Roth\n\nTarget audience: Technical experts/students looking for an introduction in principles and details on how to do anonymization, handle fairness, bias and explainability.\n\nOther people who might like it: Non-technical persons looking for principles and ideas — do skip the technical details, though, you probably “have people for that”.\n\nLevel of technicality: Medium plus — you don’t have to be an expert, but without at least a basic grasp on machine learning this book is probably a stretch. Look elsewhere for either an introduction (for instance “Maskiner som tenker”) or some higher-level principles (for instance “The Age of AI”).\n\nSummary: “The Ethical Algorithm” is more closely akin to a text book, diving deeper into the details. Its focus is “the science of socially aware algorithm design”, in essence how to design algorithms and systems that account for our biased and dirty reality, without causing harm. Everything from privacy and anonymization, fairness and bias, to explainability and interpretability, is covered.\n\nOverall impression: I came across this book as required reading in a course on anonymization, fairness, bias and explainability. It does a great job at introducing these concepts and explaining strategies and algorithms. It does this without going all the way down to formulas and proofs, and is verbose enough that a non-technical person should be able to follow the gist.\n\nI wish they covered: This covers everything you’d expect. There are more technical books that go all the way down to formulas and proofs, and there are books that give a more introductory or high-level view. This one strikes a good balance in-between, either as your last stop on necessary principles, or as your first step as you dive down into the true nitty-gritty of these algorithms.\n\n“Redesigning AI”, Daron Acemoglu\n\nTarget audience: Politicians or anyone with a keen political interest.\n\nOther people who might like it: Experts looking for potential opinions or arguments on how to regulate or where to focus research or development.\n\nLevel of technicality: Mild.\n\nSummary: “Redesigning AI” is a book in four parts: first, author Acemoglu gives an introduction and opinion on where AI systems are moving today, and where they should be moving. A key idea of his is to design AI automation to complement people, not replace them. The second part is a series of replies from experts in a wide variety of fields, finished by a summary (and to some degree response) from Daron Acemoglu. The final part of the book is a series of associated essays, less directly tied together with the opening section of the book.\n\nOverall impression: This puppy has opinions. It’s a concrete and highly opinionated view on AI today — and make no mistake, it’s one that lies to the left of the political center (relative to the US). I like the structure of explicitly showcasing a series of voices and opinions, although I would have liked some insight into how the selection of entrants was made.\n\nI wish they covered: Quite happy with it overall, but I would wish that someone that isn’t US-based was a part of it, giving an international perspective. Someone who could tie it together to the AI Accountability Act in EU, for instance. If the political side of things is what you prefer, this is the book for you (maybe after you read “The Age of AI”).\n\n“The Algorithmic Foundations of Differential Privacy”, Cynthia Dwork & Aaron Roth\n\nTarget audience: Students or experts looking for a deep-dive into how differential privacy works, and is implemented.\n\nOther people who might like it: No-one. Anyone non-technical: look elsewhere — potentially towards “The Ethical Algorithm”, which introduces the DP concept.\n\nLevel of technicality: Heavy. You should be comfortable with formulas and proofs. Remember to take breaks.\n\nSummary: This is “the book” on differential privacy, one of the best methods for anonymizing data. Differential privacy gives strong guarantees on protecting a dataset against guessing if someone was part of data collection, for instance like you’d need to ever conduct a survey on how many athletes in the Olympics use doping. Its ideas are trivial, implementation less so, and interpretation a lot less so.\n\nOverall impression: This is 100% a text book, and shouldn’t be seen as anything else. As far as that goes, it’s a good one, giving a proper deep dive into the method and its caveats, guarantees and variants. If you’re going to do anonymization and differential privacy seems interesting, get this one and dive in.\n\nI wish they covered: N/A. It’s a textbook on a topic, and it covers it extensively. No notes.\n\n“Reliable Machine Learning”, C. Chen, N.R. Murphy, K. Parisa, D. Sculley & T. Underwood\n\nTarget audience: Data Scientists, Data Engineers, ML Engineers, anyone backend or frontend that will deal with an ML system, DevOps engineers.\n\nOther people who might like it: Management of any company or department looking to implement or use machine learning systems.\n\nLevel of technicality: Medium.\n\nSummary: As the subtitle states, this book focuses on “applying SRE principles to ML systems in production”. It’s the bespectacled little sibling of “Site Reliability Engineering”, which breaks down how Google runs production systems (they seem to be pretty good at it). It starts off by outlining a typical lifecycle of an ML project and who should be involved in each step. The rest of the book relates each chapter to one of these lifecycle steps — they’re not too unlike the stages outlined in our article on responsible AI practices — meaning the book can be read in sections, out of order, and in byte-sized chunks of 25–30 pages per chapter.\n\nOverall impression: This really is the book you need to take your ML project from the “student toying around with a Jupyter notebook” stage, all the way to deploying an ML system into large-scale, real-world production. A part I love is how it ties it all in with regular principles and requirements in other software projects; after all, an ML project is just a specialized type of software project. Still working on it — we’re reading it as a part of my AI book club in Kantega — but enjoying it a lot, already learning tons.\n\nI wish they covered: The book tends to discuss most things as if you’re an organization of >1,000 employees, with many specialized roles to handle ML systems and their deployment into production. It accounts for data scientists, data engineers, ML engineers, DevOps engineers, SRE engineers et cetera. Some of the principles and components are not so easy to see how to implement in a smaller scale project, as most projects are. Some chapters give notes on where to start, but many of them forget to.\n\nI hope this gives you an idea on what books could be interesting for you to pick up! Whether you are a technical expert working in the field of ML or AI, or you’re someone with no technical background looking to learn, there should be something in there for you.\n\nBelow is my list of current or future reading — I’ll probably follow this up with a second part once I’ve finished them.\n\nNext up on my reading list:\n\n“Privacy is Power”, Carissa Véliz: this book has seen some criticism for being overly pessimistic, but it places a strong focus on the privacy issues raised by the current Internet world (including ML and AI).\n\n“Doing Data Science”, Cathy O’Neil: widely appraised text book on how to do data science projects, written by the same author that wrote “Weapons of Math Destruction”. Definitely looks like a must-read for anyone in the field of data science.\n\n“97 Things Every Data Engineer Should Know”, Tobias Macey: I do, after all, work as a Data Engineer — so this one goes without explaining. Just started, they’re all very byte-sized. Loving it so far.\n\n“Interpretable Machine Learning”, Christoph Molnar: a key text book on interpretability, which is becoming extremely important in this world of massive-scale black boxes (ChatGPT et al.).\n\n“Life 3.0: Being Human in the Age of Artificial Intelligence”, Max Tegmark: written by one of the key contributors to the open letter calling for a 6 month halt on the development and use of massive-scale transformer models, which is plenty reason enough to read his book. Listen to Lex Friedman’s podcast with him as a guest if you need more reasons.\n\nPossible Minds: 25 Ways of Looking at AI, John Brockman (editor): another book in the “here’s a bunch of voices on this topic” vein of “Redesigning AI”, this book promises “an unparalleled round-table examination about mind, thinking, intelligence and what it means to be human”. It’s looking like a mix of scientific and philosophical analysis, and I’m here for it.\n\n“Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence”, Kate Crawford: written by one of the respondents in “Redesigning AI”, this work focuses on the social and political dimensions of the field — aspects oft forgotten in the midst of our gold-rush-tempo AI excitement.\n\nThis should carry me through the end of the year, perhaps more if I’m not as disciplined in my reading as I’d like to be. Any other tips for reading; send them my way!"
    }
}