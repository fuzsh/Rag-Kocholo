{
    "id": "dbpedia_9220_0",
    "rank": 11,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/",
        "read_more_link": "",
        "language": "en",
        "title": "Neural Decoding and Feature Selection Techniques for Closed-Loop Control of Defensive Behavior",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-preprints.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0001.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0002.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0003.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0004.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0005.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0006.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0007.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0008.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/bin/nihpp-2024.06.06.597165v2-f0009.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Jinhan Liu",
            "Rebecca Younk",
            "Lauren M Drahos",
            "Sumedh S Nagrale",
            "Shreya Yadav",
            "Alik S Widge",
            "Mahsa Shoaran"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Many psychiatric disorders involve excessive avoidant or defensive behavior, such as avoidance in anxiety and trauma disorders or defensive rituals in obsessive-compulsive disorders. Developing algorithms to predict these behaviors from local field potentials ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11185693/",
        "text": "Version 2. bioRxiv. Preprint. 2024 Jun 6 .\n\nPMCID: PMC11185693\n\nOther versions\n\nPMC11185693.1; 2024 Jun 6\n\n➤\n\nPMC11185693.2; 2024 Jun 26\n\nPMID: 38895388\n\nThis is a preprint.\n\nIt has not yet been peer reviewed by a journal.\n\nThe National Library of Medicine is running a pilot to include preprints that result from research funded by NIH in PMC and PubMed.\n\nNeural Decoding and Feature Selection Techniques for Closed-Loop Control of Defensive Behavior\n\n,1,2,* ,3 ,3 ,3 ,3 ,3,4 and 1,2,4\n\nJinhan Liu\n\n1Institute of Electrical and Micro Engineering, EPFL, Lausanne, Switzerland\n\n2Neuro-X Institute, EPFL, Geneva, Switzerland\n\nFind articles by Jinhan Liu\n\nRebecca Younk\n\n3Department of Psychiatry and Behavioral Sciences, University of Minnesota, Minneapolis, MN, USA\n\nFind articles by Rebecca Younk\n\nLauren M Drahos\n\n3Department of Psychiatry and Behavioral Sciences, University of Minnesota, Minneapolis, MN, USA\n\nFind articles by Lauren M Drahos\n\nSumedh S Nagrale\n\n3Department of Psychiatry and Behavioral Sciences, University of Minnesota, Minneapolis, MN, USA\n\nFind articles by Sumedh S Nagrale\n\nShreya Yadav\n\n3Department of Psychiatry and Behavioral Sciences, University of Minnesota, Minneapolis, MN, USA\n\nFind articles by Shreya Yadav\n\nAlik S Widge\n\n3Department of Psychiatry and Behavioral Sciences, University of Minnesota, Minneapolis, MN, USA\n\n4These authors jointly supervised this work.\n\nFind articles by Alik S Widge\n\nMahsa Shoaran\n\n1Institute of Electrical and Micro Engineering, EPFL, Lausanne, Switzerland\n\n2Neuro-X Institute, EPFL, Geneva, Switzerland\n\n4These authors jointly supervised this work.\n\nFind articles by Mahsa Shoaran\n\n1Institute of Electrical and Micro Engineering, EPFL, Lausanne, Switzerland\n\n2Neuro-X Institute, EPFL, Geneva, Switzerland\n\n3Department of Psychiatry and Behavioral Sciences, University of Minnesota, Minneapolis, MN, USA\n\n4These authors jointly supervised this work.\n\n*Author to whom any correspondence should be addressed. hc.lfpe@uil.nahnij\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License, which allows reusers to distribute, remix, adapt, and build upon the material in any medium or format for noncommercial purposes only, and only so long as attribution is given to the creator.\n\nAbstract\n\nObjective.\n\nMany psychiatric disorders involve excessive avoidant or defensive behavior, such as avoidance in anxiety and trauma disorders or defensive rituals in obsessive-compulsive disorders. Developing algorithms to predict these behaviors from local field potentials (LFPs) could serve as foundational technology for closed-loop control of such disorders. A significant challenge is identifying the LFP features that encode these defensive behaviors.\n\nApproach.\n\nWe analyzed LFP signals from the infralimbic cortex and basolateral amygdala of rats undergoing tone-shock conditioning and extinction, standard for investigating defensive behaviors. We utilized a comprehensive set of neuro-markers across spectral, temporal, and connectivity domains, employing SHapley Additive exPlanations for feature importance evaluation within Light Gradient-Boosting Machine models. Our goal was to decode three commonly studied avoidance/defensive behaviors: freezing, bar-press suppression, and motion (accelerometry), examining the impact of different features on decoding performance.\n\nMain results.\n\nBand power and band power ratio between channels emerged as optimal features across sessions. High-gamma (80–150 Hz) power, power ratios, and inter-regional correlations were more informative than other bands that are more classically linked to defensive behaviors. Focusing on highly informative features enhanced performance. Across 4 recording sessions with 16 subjects, we achieved an average coefficient of determination of 0.5357 and 0.3476, and Pearson correlation coefficients of 0.7579 and 0.6092 for accelerometry jerk and bar press rate, respectively. Utilizing only the most informative features revealed differential encoding between accelerometry and bar press rate, with the former primarily through local spectral power and the latter via inter-regional connectivity. Our methodology demonstrated remarkably low time complexity, requiring <110 ms for training and <1 ms for inference.\n\nSignificance.\n\nOur results demonstrate the feasibility of accurately decoding defensive behaviors with minimal latency, using LFP features from neural circuits strongly linked to these behaviors. This methodology holds promise for real-time decoding to identify physiological targets in closed-loop psychiatric neuromodulation.\n\nKeywords: neural decoder, defensive behavior, machine learning, psychiatric brain-machine interfaces, neuro-marker\n\n1. Introduction\n\nFear and anxiety serve as adaptive defensive responses to threats, a phenomenon observed across a variety of species [1]. These responses are evolutionary mechanisms designed to enhance survival by preparing an organism to confront or flee from immediate danger [2, 3]. However, the same reactions, when excessive or misplaced, can significantly disrupt an individual’s overall quality of life [4, 5]. Anxiety disorders, characterized by disproportionate and persistent fear and anxiety, are among the most prevalent psychiatric conditions [6,7]. Fear and anxiety contribute to the manifestation of a wide array of psychiatric disorders, underscoring their critical role in mental health [8,9].\n\nFear and anxiety are often studied through the lens of defensive behaviors, a set of responses or patterns elicited in the face of perceived threats [10]. Rodents exhibit various defensive behaviors in response to actual or potential threats [11,12]. These behaviors are often used to model human illnesses, because anxiety can also be viewed as an excessive response to potential or actual threats [11,13]. Therefore, exposure to a threatening stimulus evokes defensive responses that resemble emotional states related to fear and anxiety [12]. Recent studies indicate that the defensive patterns observed in normal human subjects show notable similarities to those of laboratory rodents. This parallel supports the hypothesis that rodent defensive behaviors may be reasonable models of similar behaviors in human anxiety disorders [14, 15]. The subjective human experience of fear is not the same as innate defensive behaviors in lower vertebrates, but those defensive behaviors are the closest available model [16]. Furthermore, both human fear/anxiety and rodent defensive behavior load onto the same frontal-amygdala circuits [17–19]. Hence, animal defensive behaviors offer a valuable model for understanding negative-valence processes in humans [20–22]. As a result, the excessive or contextually inappropriate exhibition of these behaviors can serve as a model for certain aspects of human psychiatric disorders [23,24].\n\nThe long-term goal of modeling defensive and anxious behavior is to develop new treatments. Direct electrical stimulation of the brain is a particularly promising approach to that translation. Brain stimulation specifically improves the symptoms of multiple fear/anxiety disorders [25–28]. The approach involves the precise targeting of specific brain areas to modulate dysfunctional neural circuits associated with these conditions, which allows direct targeting of mechanisms discovered through animal models. Within the field of psychiatric brain stimulation, there is a strong drive towards closed-loop therapies [29–32]. The symptoms of psychiatric disorders, and of fear/anxiety disorders in particular, vary over time, and only some of those symptom states require neurostimulation. A closed-loop brain-machine interface (BMI) system that uses real-time neural activity from the subject to guide stimulation could help develop effective, precisely tailored therapies that stimulate only when it will be beneficial [29,33–36].\n\nThere exists a main challenge for developing such closed-loop BMIs: we need a neural decoder that is capable of estimating the disorder symptom or behavior in real-time [37–39]. The development of highly accurate and fast decoders is essential for optimizing the therapeutic outcomes, ensuring that stimulation protocols are dynamically adjusted to the fluctuating patterns of neural dysregulation associated with psychiatric disorders [40]. Consequently, advancements in BMI technology and decoding algorithms hold the promise of revolutionizing the treatment landscape for patients with psychiatric conditions, offering hope for more personalized and effective interventions.\n\nDecoding plays a pivotal role in neural engineering and the analysis of neural data [41–43]. It leverages activity recorded from the brain to forecast behaviors or symptoms [44–47]. These predictions, derived from decoding, can be utilized to manipulate devices or to enhance our understanding of the brain’s involvement in disorders [48–50]. This is achieved by assessing the extent of information that neural activity conveys about a symptom or behavior and examining how this information varies across different brain areas, experimental conditions, and states of disorder [51–53]. Decoding psychiatric states poses unique modeling challenges due to the complex and widespread network of brain regions involved in neural processes linked to neuropsychiatric states and behaviors, particularly in disorders such as chronic pain, addiction, or posttraumatic stress disorder (PTSD) [30,38,54–57].\n\nIn essence, neural decoding represents a regression or classification challenge that links neural signals to specific variables [58]. Machine Learning (ML) has emerged as a pivotal technique for elucidating the intricate patterns of neural activity, as well as the individual variations in brain function correlated with symptoms and behaviors [59]. Its utility is particularly pronounced when the primary research objective is to enhance predictive accuracy, a goal partly attributed to ML’s proven efficacy in addressing nonlinear challenges [60,61]. Despite recent advances in ML techniques, the decoding of neural activity frequently employs traditional approaches such as linear regression (LR) and support vector machine (SVM) [62–64]. The adoption of contemporary ML tools for neural decoding might yield not only a substantial performance improvement but also the possibility of gaining more profound insights into neural functionality, as shown in recent studies. Encoding-decoding frameworks, based on linear state-space models, have decoded mood and cognitive state fluctuations from multi-site intracranial electrocorticogram (ECoG) or stereo-electroencephalography (sEEG) signals [38, 62]. A Multi-layer Perceptron (MLP) has been utilized to forecast depressive states in human patients from local field potential (LFP) signals [65]. A decoder leveraging Random Forest models has been developed for the prediction of multi-class affective behaviors via intracranial electroencephalography (iEEG) recordings from the human mesolimbic network [66]. A discriminative cross-spectral factor analysis model was utilized for identifying a brain-wide oscillatory pattern for predicting resilient versus susceptible mice to stress [67]. Episodes of mental fatigue and changes in vigilance were precisely decoded from ECoG signals in Non-Human Primates (NHPs), using a gradient boosting classifier [68,69].\n\nIn the aforementioned studies, beyond the decoding model utilized for prediction, the neuro-markers derived from neural data were crucial for decoding efficacy. The majority of previous efforts to detect psychiatric symptoms and behaviors have focused on classical spectral power features [38, 62, 66,70,71]. It is not clear that spectral power is the best feature for decoding complex cognitive-emotional phenomena such as fear/defensive behaviors. For instance, spectral power features were outperformed by cross-region connectivity metrics when attempting to decode cognitive task engagement [63,72]. Spectral (wavelet entropy), temporal (Hjorth parameters), and connectivity features (partial directed coherence and phase locking index) have all been identified as significant markers for detecting mental fatigue [68]. In contrast, shifts in depressive states were more influenced by variations in spectral power features within the subcallosal cingulate than by coherence and phase-amplitude coupling [65]. Consequently, the importance of spectral power vs. other neuro-markers for modeling and decoding defensive behaviors and fear expression requires further investigation.\n\nHere, we studied the decoding of defensive behaviors from the prefrontal cortex (PFC) and amygdala, which together comprise a circuit believed to regulate the expression of threat/defense versus safety behaviors [11,24,73,74]. In prior rodent work, the balance between defensive and safety behaviors was associated with theta band (5–8 Hz) LFP synchrony between the infralimbic cortex (IL) and basolateral amygdala (BLA) [75–77]. Therefore, IL-BLA LFP connectivity and power features are promising targets for the development and testing of decoding algorithms that could be used in closed-loop psychiatric BMIs. At the same time, prior work focused on simple categorical analyses (t-tests between groups) and did not consider the more clinically relevant question of how to decode imminent behavior at the timescale of milliseconds to seconds. Rapid decoding would be crucial for a closed-loop BMI aimed at mitigating anxious or avoidance behavior in humans. It is not clear that the same LFP features that broadly discriminate two groups will be able to predict moment-to-moment behavior.\n\nWe thus developed a behavioral decoder based on IL-BLA LFP signals from rats undergoing a tone-shock conditioning and extinction protocol [78, 79]. Beyond conventional band power features, we explored and exploited a broad array of neuro-markers derived from the LFPs, across spectral, temporal, and connectivity domains. We considered three defensive behaviors: freezing, bar press suppression (bar press rate), and accelerometry, specifically the jerk (first derivative) calculated from a 3-axis head-mounted accelerometer. Freezing and bar press suppression are canonical defensive behaviors that have been studied for decades [20–22, 80–82]. Accelerometry jerk is a newer metric we have proposed and shown to correlate with, but not fully overlap the two other measures [83]. We developed a decoding framework based on Light Gradient-Boosting Machine (LightGBM), which outperformed other state-of-the-art ML-based decoders in both accuracy and latency. Our approach included a methodology to assess feature importance and a feature selection strategy utilizing the SHapley Additive exPlanations (SHAP), effectively reducing the dimensionality of the feature space. Band power and band power ratio between channels emerged as critical for decoding defensive behaviors, with the high-gamma band being particularly predictive compared to other frequency bands. By prioritizing highly-ranked neuro-markers, we enhanced decoding performance beyond that with solely band power features. Consequently, this study underscores the effectiveness of our proposed ML framework in the precise and rapid decoding of defensive behaviors within a closed-loop psychiatric Brain-Machine Interface (BMI) system.\n\n2. Methods\n\n2.1. Animals and behavior paradigm\n\nWe utilized 16 adult Long Evans rats, with weights ranging from 250 to 350 grams. Initially, rats were pair-housed in plastic cages for at least 7 days to facilitate acclimation to the research facility. Subsequent to this acclimation period, the rats underwent daily handling for 5 days to mitigate handling-related stress, after which they were individually housed in plastic cages. To prepare for experimental procedures, food intake was restricted to 10 grams per day until each rat achieved 85–95% of its initial body weight. Thereafter, the animals were allocated 15–20 grams of food daily to maintain their weight within this specified range throughout the behavioral experiments. During the first three days of food restriction, sucrose pellets were introduced into the home cages to acquaint the rats with the reward, thereby facilitating the learning of bar-pressing behavior.\n\nThe behavioral training and experiments were conducted in the Coulbourn conditioning chambers, with dimensions of 30.5 × 24.1 × 21 cm. These chambers were equipped with a grid floor, consisting of rods spaced 1.6 cm apart and with a diameter of 4.8 mm, to facilitate the delivery of foot shocks. An aluminum wall of the chamber incorporated a retractable bar and a food trough for monitoring reward-seeking behaviors, while a speaker mounted on the opposite wall emitted sound stimuli. Additionally, a camera with an attached wide-angle lens was positioned outside the conditioning chamber, above the speaker unit, to record video footage through the chamber’s plexiglass top.\n\nInitially, rats were trained to execute bar presses to obtain sucrose pellets. They subsequently underwent electrode implantation and participated in a post-surgical behavioral paradigm. To provoke defensive behaviors, the rats were exposed to a tone-shock conditioning protocol, which comprised three phases: habituation/conditioning, extinction, and extinction recall, as shown in . Electrophysiological and video recordings were systematically carried out during each experimental session. During the habituation phase on day 1, rats encountered 5 trials of the conditioned stimulus (CS: a 30-second, 82 dB tone). This was followed by the conditioning phase, where they experienced 7 instances of the CS paired with the unconditioned stimulus (US: a 0.6 mA, 0.5-second foot shock) immediately after the CS. On day 2, the extinction phase consisted of 20 presentations of the CS alone, without the US, in the same chamber. On day 3, to evaluate extinction memory (recall), the CS was presented 6 times without the US.\n\nReward-seeking behavior, indicated by bar presses, functioned as a dynamic measure for defensive behavior, with a decrease in pressing activity interpreted as an elevated threat response. Bar press events were captured in the electrophysiology event data using a Data Acquisition System (DAQ) (USB 6343-BNC or PCIe-6353, National Instruments, Woburn, MA, USA). These event data were subsequently processed to isolate bar press incidents and their associated timestamps. Assessment of freezing behavior was conducted through offline video analysis, employing a Logitech HD Pro Webcam C910 equipped with a Neewer Digital High Definition 0.45x Super Wide-angle Lens. The footage, captured at a rate of 24 frames per second with Debut Professional software, was analyzed using ANY-maze, which utilizes its integrated freezing detection functionality to assign a ‘freezing score’ to each frame. This score increased with more significant changes in pixels between consecutive frames. Meanwhile, accelerometry data were collected continuously at a 30 kHz sampling rate via the RHD 2132 electrophysiology headstage, which includes a built-in 3-axis accelerometer. These data were logged using the Open Ephys acquisition system, a widely used open-source platform for in-vivo electrophysiology research [84]. The synchronization of accelerometry records with video data was accomplished by aligning the ‘tone on’ events observed in both datasets. There were sparse bar press events for a few rats during the conditioning phase due to the bar press suppression resulting from foot shocks. We chose 10 rats with no less than 5 bar presses in the conditioning phase to ensure the threat responses were well-encoded in the following neural decoding study. All 16 rats were used for the analysis in habituation, extinction, and recall sessions.\n\n2.2. Electrodes and surgery\n\nEach electrode bundle was comprised of 8 nickel-chromium recording microwires, each measuring 12.5 μm in diameter, accompanied by one reference wire of the same diameter as the recording wires, and a platinum-iridium stimulating channel with a diameter of 127 μm [85]. The stimulation channel was used for another set of experiments not reported here, and no stimulation occurred during any of the data reported in this paper. These recording and stimulating components were collectively bundled within a 27-gauge stainless steel cannula, which also served as a pathway for the return current during stimulation. The recording wires were bonded to the individual pins of an Omnetics connector using silver paint, while the stimulating wire was soldered to a mill-max connector, enabling concurrent recording and stimulation at the same site. A ground wire was affixed to the connector, and the entire bundle was safeguarded with epoxy. Prior to surgery, the electrodes were sterilized using Ethylene Oxide (EtO).\n\nThe electrode arrays were surgically implanted into the left infralimbic cortex (IL) (+3 mm anterior-posterior (AP), +0.5 mm medial-lateral, and −3.95 mm dorsal-ventral (DV) from the brain surface) and the basolateral amygdala (BLA) (−2.28 mm AP, +5 mm medial-lateral, and −7.5 mm DV from the brain surface). Dental cement was utilized to secure the electrodes and to construct a protective head cap for the animals. The ground wire was securely wrapped around a skull screw prior to the implant fixation. A minimum recovery period of seven days was allowed for the animals before starting physiological experiments.\n\n2.3. Electrophysiology and data processing\n\nThe electrophysiological signals, specifically local field potentials (LFPs), were recorded at a sampling rate of 30 kHz using an Open Ephys acquisition system throughout all experimental sessions. The recording headstage was interfaced with two mill-max male-male connectors, each comprising eight channels, through an adaptor.\n\nQuantification of defensive behavior adhered to the methodology established in a prior study [83]. The change in total acceleration, herein referred to as “accelerometry jerk”, was computed as:\n\nj(t)=|dVX2(t)+VY2(t)+VZ2(t)dt|\n\n(1)\n\nwhere j(t) is the accelerometry jerk as a function of time t, and VX2(t), VY2(t), and VZ2(t) are the voltages of the accelerometer in X, Y, and Z axes, respectively. The accelerometry jerk was downsampled from its original sampling rate of 30k samples/second to 1k samples/second, and was then smoothed with a Gaussian filter using a 200-sample window to remove non-biological noise transients. Bar press events and their corresponding timestamps were extracted from the electrophysiological recordings, with timestamps being resampled to 1k samples/second. The counts of presses was binned into each 1-ms time interval, and then these counts were smoothed using a Gaussian filter with a 1k-sample window. This process transformed the data from a discrete count of events into an approximation of a continuous press rate, hereby referred to as the bar press rate. The resampling process utilized the downsample() function in Matlab, while Gaussian smoothing was executed with the smoothdata() function in Matlab.\n\nA total of 8 recording channels were obtained from bipolar-referenced LFP signals, with 4 channels from each of the IL and BLA regions. These bipolar-subtracted channels were subsequently band-pass filtered within the range of 1–150 Hz using a 3rd-order zero-phase Infinite Impulse Response (IIR) Butterworth filter. Subsequently, line noise was removed by applying a notch filter at 60 Hz and its harmonics. The LFP data was then demeaned across the time series for each channel. For each subject and recording session, we visually inspected the neural data and excluded time epochs that exhibited clear non-neural artifacts, such as significant sharp voltage transients. For extracting features in various frequency bands, the neural data were processed using 3rd-order zero-phase IIR Butterworth band-pass filters across 7 frequency bands: 1–4 Hz (delta), 4–8 Hz (theta), 8–13 Hz (alpha), 13–30 Hz (beta), 30–50 Hz (low-gamma), 50–80 Hz (gamma), and 80–150 Hz (high-gamma). Phase and amplitude were extracted from the band-pass filtered signal via Hilbert transform. Cross-spectral density was estimated on the neural signals before band-pass filtering using the Multitaper method in the MNE package. The other preprocessing steps were implemented using the SciPy package.\n\nBoth behavioral data and the neuro-markers were computed in overlapping 1-second sliding windows with a 0.2-second step size. Behavioral measurements were quantified by averaging the measures of accelerometry jerk, bar press rate, and freezing score within each window.\n\n2.4. Neuro-marker extraction\n\nTo investigate the neural representations in various aspects and enhance the accuracy of decoding defensive behaviors in our model, we extracted 17 types of neuro-markers across 3 representation domains as neural features for each window, as detailed in . We chose these features based on existing evidence that, in general, local power and cross-region connectivity between IL and BLA have been linked to defensive behaviors in past research [75,86]. Additionally, we computed time domain features that are pivotal in identifying patterns of neural activity associated with specific behaviors or pathological states, owing to their simplicity and the direct interpretation of neural dynamics [87–89].\n\nTable 1:\n\nSpectral domain Band powera,b BPj=1T∑t=1Tyj2(t) Relative band powera,b RBPj=BPj1T∑t=1Ty2(t) Band power ratio between bandsa,b BPRBjk=BPjBPk Temporal domain Line lengtha LL=∑t=1T−1|y(t+1)−y(t)| Hjorth parametersa,c Act=σ2(y(t)),Mob=σ2(dy(t)dt)/σ2(y(t)),Com=Mob(dy(t)dt)/Mob(y(t)) Maximuma Max=maxt=1Ty(t) Minimumaa Min=mint=1Ty(t) Nonlinear energya NE=1T−2∑t=1T−2y2(t+1)−y(t)y(t+2) Skewnessa,c,d Skewness=∑t=1T(y(t)−y¯)3(T−1)σ3 Approximate entropya,e ApEn=1T−1∑t=1T−1logCu2−1T−2∑t=1T−2logCu3 Sample entropya,e SampEn=−log(A2/B2) Connectivity domain Band power ratio between channelsa,b,f BPRCjmn=BPjmBPjn Coherencea,f, g Cohmn=∑f|Gmn(f)|2Gmm(f)Gnn(f) Phase amplitude couplinga,f,h,i PACmn=|1T∑t=1Tam(t)eiθn(t)| Phase locking valuea,f,i PLVmn=|1T∑t=1Tei(θm(t)−θn(t))| Pearson correlationa,c,d,f Corrmn=1Nσmσn∑t=1T(ym(t)−y¯m)(yn(t)−y¯n) Band Pearson correlationa,b,c,d,f BCorrjmn=1Nσjmσjn∑t=1T(yjm(t)−y¯jm)(yjn(t)−y¯jn)\n\nIn the spectral domain, band power (BP) was quantified across 7 frequency bands [38, 90, 91]. Relative band power (RBP) refers to the power in a specific frequency band relative to the total signal power [87,92,93]. Band power ratio between bands (BPRB) facilitates the pairwise comparison of power levels across different bands within a single channel [92–94].\n\nRegarding temporal features, line length (LL) calculates the absolute differences between successive time points [87,90,95]. Hjorth parameters (HP) reflect statistical attributes including variance, mean frequency, and frequency variation [87,96–98]. Maximum (Max) and minimum (Min) represent the extreme values within the window [87]. Nonlinear energy (NE) gives an estimate of the energy content of the neural signal [99]. Skewness evaluates the asymmetry of the distribution of instances within the window [100]. Approximate entropy (ApEn) and sample entropy (SampEn) assess the existence of patterns within a sequence of instances [101,102].\n\nIn the connectivity domain and cross-region representations, band power ratio between channels (BPRC) enables pairwise power level comparison across channels from two distinct brain regions [92]. Coherence (Coh) quantifies the similarities of neural oscillation between channels [103]. Phase-amplitude coupling (PAC) captures the linkage between the phase of a low-frequency band and the amplitude of a high-frequency band between channels [88,104,105]. Phase locking value (PLV) describes the phase relationship consistency between signals from different channels [77,106]. Pearson correlation (Corr) and band Pearson correlation (BCorr) quantify functional connectivity between channels, across the full band and within individual frequency bands, respectively [72].\n\nHere, BP, RBP, BPRC, Coh, PLV, and BCorr were assessed across the aforementioned 7 frequency bands. PAC analysis was performed between the amplitudes of the low-gamma, gamma, and high-gamma bands and the phases of the theta and alpha bands, with 6 phase-amplitude combinations. BPRB comparisons were made between each pair of the 7 bands, with 21 band-band combinations in total. BP, RBP, BPRB, LL, HP, Max, Min, NE, skewness, ApEn, and SampEn were calculated for each individual channel. BPRC, Coh, PAC, PLV, Corr, and BCorr were derived only from channel pairs between IL and BLA, with 16 channel-channel combinations. ApEn and SampEn were computed using the MNE-Features package.\n\n2.5. Data partitioning\n\nAfter extracting the neuro-markers and behavioral data, we partitioned them into three distinct datasets for subsequent use in training the decoding model, selecting high-rank features, and evaluating the model’s performance. For each subject, we divided the data from each recording session into training, validation, and test sets, as depicted in .\n\nA hold-out test set, constituting 20% of the entire recording, was designated from the final 20% of each behavior session, while the initial 80% served as the training and validation sets. The separation between the training and validation sets employed a sliding-window 5-fold cross-validation paradigm. The time series data were evenly divided into 9 windows. In the first fold, the initial 4 windows formed the training set, and the 5th window served as the validation set. From the second to fifth folds, we sequentially shifted the training and validation sets by one window forward in time, ensuring that validation sets were different across folds and incorporating validation sets from preceding folds into the training sets of subsequent folds. Therefore, the division ratios for training and validation sets versus test sets, and training sets versus validation sets, were maintained at 80%−20%. This method respected the chronological sequence of the time series data by consistently organizing the datasets in a training-validation-testing order. This organization assured that the model was always trained on historical data and validated/tested on subsequent data, thereby preventing data leakage across the temporal dimension.\n\nThe test set was utilized for the final evaluation of the model’s decoding accuracy, trained using the complete training and validation sets. Feature selection and parameter optimization were conducted based on the model’s validation set performance, trained on the training set data.\n\n2.6. Decoding model\n\nA diverse array of machine learning (ML) models has been employed for neuropsychiatric tasks and brain-machine interface applications, including linear regression (LR) [62, 103], support vector machine (SVM) [63,67,77,107,108], random forest (RF) [109, 110], and artificial neural network (ANN) [111, 112]. Moreover, gradient-boosted decision trees (GBDT) have demonstrated promising performance in previous neurophysiological task studies [90, 91, 97, 107, 113]. In this work, we utilized a GBDT-based model named Light Gradient-Boosting Machine (LightGBM), known for its efficiency in reducing data instances and features through gradient-based one-side sampling (GOSS) and exclusive feature bundling (EFB) [114]. GOSS retains data instances with gradients above a certain threshold while randomly discarding instances with smaller gradients, thereby maintaining the data’s substantial contribution to information gain. EFB efficiently reduces the number of effective features by bundling mutually exclusive features — those not taking non-zero values simultaneously — into a single feature. By leveraging GOSS and EFB, LightGBM achieves superior computational speed and lower memory usage compared to other GBDTs, without compromising the accuracy intrinsic to GBDT models. We configured LightGBM with 100 trees, setting the maximum number of leaves per tree to 5 to prevent overfitting. These parameters were determined through hyperparameter optimization during the cross-validation phase.\n\nIn addition to LightGBM, we evaluated a variety of ML models widely applied in neurophysiological research, employing our proposed feature set as outlined in . These models encompass traditional ML approaches such as LR, SVM with both linear (SVM-Lin) and radial basis function kernels (SVM-RBF), the tree-based RF model, and ANN models with diverse architectures, including a 3-layer multilayer perceptron (MLP), 3-layer long short-term memory (LSTM), and 3-layer convolutional neural network (CNN). The implementation of LR, SVM-Lin, SVM-RBF, and RF was conducted using the scikit-learn package, while MLP, LSTM, and CNN were implemented via the Pytorch package. The LightGBM model was implemented using the Python package provided by Microsoft. In our preliminary decoding analysis, leveraging all neural features depicted in we assessed the decoding accuracy for accelerometry jerk and bar press rate across the aforementioned ML models, averaged over subjects in each recording session. Performance evaluation was conducted using both the coefficient of determination (R2) and the Pearson correlation coefficient (r) metrics. It should be noted that here, R2 is not the squared Pearson correlation coefficient, and its value lies within the range of (-,∞ 1]. A negative R2 suggests that the decoded behavior captures less variation in the real behavior than a constant value equivalent to the average of the ground truth, indicating relatively poor decoding performance. Our findings indicate that LightGBM outperformed other ML models in decoding both accelerometry jerk and bar press rate in 14 out of 16 comparisons.\n\nTable 2:\n\nBehaviorMetricSessionLRSVM-LinSVM-RBFRFMLPLSTMCNNLightGBMAccelerometry Jerk R2 Habituation−59.52−140.80.44950.45810.46680.45540.4614 0.4677 Conditioning−1099−3.5930.3931 0.6324 0.62400.63010.62390.6310Extinction−62.73−6.9350.48150.49130.48780.46460.4779 0.4952 Recall−2.040−0.33460.49160.54170.52140.53910.5449 0.5515 r Habituation0.46600.50380.68950.69740.69140.68270.6934 0.6998 Conditioning0.24970.55430.70520.84170.83130.83570.8224 0.8425 Extinction0.53400.54430.70370.71470.69510.67820.6978 0.7187 Recall0.55150.59400.73200.76880.76140.77120.7676 0.7753 Bar Press Rate R2 Habituation−466.0−719.3−8.4510.32990.31050.32010.3281 0.3306 Conditioning−638.8−92.94−20.550.28190.26970.26100.2734 0.2848 Extinction−22.16−49.67−13.560.37130.35760.36540.3722 0.3798 Recall−2.027−2.517−9.0680.37460.36180.35970.3610 0.3761 r Habituation0.36260.3194______*0.59950.57960.58090.6064 0.6113 Conditioning0.32020.2899______* 0.5480 0.53130.52980.53340.5435Extinction0.45360.3432______*0.61150.60720.61050.6204 0.6237 Recall0.35400.3248______*0.62490.61340.60290.6212 0.6368\n\n2.7. Model training and evaluation\n\nillustrates the model training process using the dataset configuration detailed in . LightGBM models were trained in a subject-specific and session-specific manner, premised on the hypothesis that neural representations of defensive behaviors exhibit inter-subject variability. Furthermore, we fitted models separately for each recording session because we expected the neural encoding to shift over time. Tone-shock conditioning and extinction learning both involve significant plasticity in the IL-BLA circuit, and thus defensive behaviors might be driven by different activity patterns before vs. after a given stage of learning. For each subject and session, 5 LightGBM models were trained and assessed using the 5 folds designated for the training and validation sets, which were subsequently used for the selection of top-ranked features based on high feature importance values. A final LightGBM model was then trained using the aggregated training and validation sets and evaluated against the hold-out test set, incorporating either band power features, selected top-ranked features, or the entire set of extracted features.\n\nThe model’s decoding performance was quantified using R2 and r to compare ground truth with predicted behavioral measurements. The loss in R2 served to evaluate the neuro-markers’ contribution to decoding performance by their exclusion from the model, and it was also applied in the validation set’s performance analysis to guide the selection of a specific number of top-ranked features. Additionally, r was also utilized to compare the similarities between feature importance matrices. The evolution of the training curves, delineated by the percentage change in L2 Loss with increasing iterations, provided further insight into training dynamics.\n\n2.8. Feature selection\n\nIntegrating an increased number of neuro-markers across spectral, temporal, and connectivity domains may enhance the decoding accuracy for defensive behaviors. However, this augmentation results in a proliferation of features, increasing computational complexity and memory requirements. Furthermore, some features may be uninformative or redundant within the ML framework, complicating the derivation of neuroscientific insights from models based on an extensive array of features. In our study, we extracted 17 types of neuro-markers, totaling 1296 features as input into the model, which inflated the computational costs unnecessarily. Consequently, we implemented a feature selection method to reduce computational demands, mitigate the risk of model overfitting, and identify which LFP features were most informative and, thereby, potentially causal to behavior.\n\nWe utilized SHapley Additive exPlanations (SHAP) for the assessment of feature importance among neuro-markers [115]. SHAP is a comprehensive measure of feature importance based on the Shapley values from a conditional expectation function of the original model. These values offer a unique feature importance metric that adheres to three desirable properties including local accuracy, missingness, and consistency when evaluating the additive attribution of one feature to the prediction output [115].\n\nFor each defensive behavior across every recording session, we assessed the SHAP values for every feature across the 5 LightGBM models, each trained using a distinct fold. Subsequently, for each feature, we computed the mean of its absolute SHAP values across all data instances and folds, establishing this as the cumulative contribution of the feature within that session. To identify the top-ranked features that are both subject- and behavior-specific and exhibit consistency across different days, these calculated attributions were further averaged over 4 recording sessions to determine the ultimate feature importance, as shown below:\n\nimpi=15NS∑s∑f∑n|ϕn,f,s,i|\n\n(2)\n\nwhere impi is the importance of feature i∈{1,2,…,M}, ϕn,f,s,i is the SHAP value for data instance n∈{1,2,…,N}, fold f∈{1,2,…,5}, session s∈{1,2,…,S}, and feature i, and M, N, S are the numbers of features, samples, and sessions, respectively. Then we sorted the feature importance impi and ranked the neural features for subsequent selection. We employed an iterative feature selection strategy, which means features were incrementally introduced to the model in the order of SHAP rankings. This process continued until the model’s performance on the validation set was comparable to, and not significantly lower than, the peak performance determined through an exhaustive iteration over an increasing amount of top-ranked features from one to the maximum. The group of features, when this process stopped, was the final selected subset of features used for decoding corresponding defensive behavior across recording sessions.\n\n2.9. Statistical analysis\n\nWe conducted paired-sample t-tests to assess the differences in decoding performance between accelerometry jerk, bar press rate, and freezing score. Additionally, these tests compared the SHAP values of features without or with various temporal delays, by employing neural features not only from the current window, but also from the preceding windows lagged by up to 20 seconds, across all recording sessions and subjects. Because there is an inherent motor delay between perception of threat and emission of a defensive behavior, decoding might perform better if that delay were taken into account using this lagged method. We applied the same method to determine whether decoding performance using selected top-ranked features was significantly different from the optimal performance identified during feature selection.\n\nIndependent-sample t-tests were utilized to determine the statistical significance of overall SHAP feature importance within specific frequency bands relative to all other bands, across all recording sessions and subjects. This test was also applied to evaluate the significance of feature contributions to decoding performance within specific frequency bands in comparison with contributions from all other frequency bands. The Wilcoxon signed-rank test was employed to compare decoding performance when using band power features, selected top-ranked features, and the entire set of extracted features across all subjects. To account for multiple comparisons, Bonferroni corrections were applied to adjust p-values, tailored to the number of comparisons conducted. The implementation of paired-sample t-tests, independent-sample t-tests, and the Wilcoxon signed-rank tests were carried out using the SciPy package.\n\n3. Results\n\n3.1. Comparison of decodability of defensive behaviors using proposed ML framework\n\nThe comparison of training processes and decoding performances for accelerometry jerk, bar press rate, and freezing score is depicted in . depicts the training curves, showcasing the L2 loss changes, averaged across subjects and recording sessions. The models underwent training using the training set, with the percentage change in L2 loss from the initial untrained state evaluated on both the training and validation sets. For all three behaviors, the L2 loss for training sets exhibited a consistent decline with additional iterations. However, the validation set loss for the freezing score demonstrated minimal improvement (−9.5%), in contrast to accelerometry jerk (−53.6%) and bar press rate (−34.6%).\n\nThere were large differences in the degree to which the different forms of defensive behavior could be decoded from the IL/BLA LFPs (i.e., in the degree to which these behaviors were encoded within the LFPs in that brain circuit). Specifically, the freezing score was only marginally decodable across sessions, with the mean coefficient of determination (R2) averaged across subjects never surpassing 0.12 in all recording sessions, as shown in . While the bar press rate showed a higher degree of decodability, performances were slightly diminished during the conditioning session, attributed to strong bar press suppression resulting from foot shocks. Accelerometry jerk emerged as the most reliably decodable behavior, with the mean R2 values across subjects consistently exceeding 0.46 in all recording sessions. Overall, decoding accuracy varied significantly among different defensive behaviors, following a descending order from accelerometry jerk to bar press rate to freezing score. These findings remained consistent when evaluated using both R2 and the Pearson correlation coefficient (r) for performance assessment.\n\nThe variation in decoding performance may arise in part from the distinct characteristics of each behavioral signal, as illustrated in . Accelerometry jerk is characterized by a smoothly fluctuating signal that remains predominantly non-zero. In contrast, bar press rate often drops to zero but then has sharp deviations from baseline during bouts of pressing. Freezing score exhibits some local deviations even after smoothing. Regarding the freezing score in , the model succeeds in tracking the global trend, resulting in a relatively high r. Nevertheless, it struggles to capture local variations, leading to an R2 of 0.071 for the freezing score. This indicates that the decoded behavior scarcely captures variance from the actual behavior, offering only marginal predictive improvement over the expected value of the true behavior. In light of these findings, subsequent analyses concentrated on accelerometry jerk and bar press rate, given that interpretations derived from the non-predictive models of freezing score could potentially be misleading.\n\n3.2. Importance and contribution of neuro-markers to the decoding performance\n\nSubsequently, our focus shifted towards understanding the importance of each neuro-marker type in decoding defensive behaviors. and delineate the importance of three feature domains, diverse neuro-markers, and frequency bands in decoding defensive behaviors. A notable observation is that spectral, temporal, and connectivity features all play a crucial role in decoding defensive behaviors. Specifically, temporal (43.0%) and spectral (41.1%) features outweigh connectivity features (15.9%) for the prediction of accelerometry jerk. In contrast, for bar press rate prediction, connectivity (39.8%) emerges as the predominant domain, surpassing spectral (34.7%) and temporal (25.5%) features. Among the individual types of neuro-markers for accelerometry jerk decoding, band power (BP) (33.2%), line length (LL) (21.0%), and band power ratio between channels (BPRC) (10.2%) stand out as the most influential features within the spectral, temporal, and connectivity domains, respectively. This holds true despite the availability of a larger number of connectivity features compared to spectral or temporal features, owing to connectivity’s reliance on the squared number of channels. For bar press rate, BP (18.9%) and BPRC (15.5%) consistently rank as critical, with other spectral and connectivity features like band power ratio between bands (BPRB) (11.2%) and band Pearson correlation (BCorr) (8.2%) also contributing substantially to predictions, unlike other temporal features. Notably, for the leading contributors (BP and BPRC) as well as other neuro-markers that span seven frequency bands, including BCorr, coherence (Coh), and phase locking value (PLV), their high-gamma components are identified as crucial for decoding defensive behaviors, except Coh for accelerometry jerk and PLV for bar press rate, which prominently feature alpha and gamma components, respectively.\n\nBeyond quantifying feature importance by evaluating their attribution to the prediction, we also explored their impact on decoding performance, as illustrated in and . For accelerometry jerk, BP, LL, and BPRC were identified as principal contributors, aligning with their established predictive importance in . The order of neuro-marker contributions to accelerometry jerk decoding performance as shown in mirrors their predictive significance as depicted in . In the case of bar press rate, BCorr, BPRC, and BPRB maintain a substantial impact on decoding performance, consistent with . However, BP’s contribution appears noticeably diminished relative to the aforementioned features, underscoring its reduced spectral significance in comparison with BPRB for bar press rate decoding.\n\nThis analytical approach to feature importance in both prediction and decoding performance elucidates the substantial importance of neuro-markers across all three domains. BP and BPRC emerge as common key contributors for decoding both defensive behaviors, with LL for accelerometry jerk and BCorr and BPRB for bar press rate also deemed important in terms of prediction and performance.\n\n3.3. Importance and contribution of band powers in different frequency bands to the decoding performance\n\nIn , band power emerged as one of the most influential features. We delved deeper into its importance in terms of prediction and decoding performance across seven frequency bands, including delta, theta, alpha, beta, low-gamma, gamma, and high-gamma, extracted from both IL and BLA, for the decoding of accelerometry jerk and bar press rate, as detailed in . The importance matrices in - highlight the importance of band power in these frequency bands across recording sessions, brain regions, and targeted behaviors. Collectively, these matrices consistently reveal that high-gamma power in the IL and BLA is more important for predicting behavior than all other frequency bands, and that this is true across different phases of aversive learning and extinction. - compare the pairwise similarities among the elements of the importance matrices from - , examining either the significance of spectral power within identical bands and sessions across different brain regions or in decoding diverse defensive behaviors. These importance matrices exhibit substantial correlation with each other (r>0.61, p<6.0e−4), with the high-gamma components invariably displaying elevated importance values. This pattern suggests that high-gamma power maintains a consistent association with defensive behavior across various contexts.\n\nExpanding our analysis to consider the band powers from another angle, we explored their impact on decoding performance across seven frequency bands, as depicted in and . Notably, the exclusion of high-gamma power leads to a significantly stronger decline in model performance across subjects and sessions compared with all other bands, aligning with observations from - . Therefore, the comprehensive findings of underscore the pivotal role of high-gamma power as the spectral band most closely linked to defensive behavior, both in terms of attribution to prediction and decoding performance.\n\n3.4. Importance and contribution of cross-region neuro-markers in different frequency bands to the decoding performance\n\nIn , the band power ratio between IL and BLA emerged as a pivotal feature, especially in the context of bar press rate decoding. We dissected the relative contribution of different frequency bands as depicted in . Here again, high gamma features were identified as the most influential encoders of defensive behaviors. Additionally, beta band ratios from BLA to IL exhibited marginal significance for accelerometry jerk, as illustrated in . - explore the pairwise similarities among the elements of the importance matrices from - , assessing either the importance of spectral power ratios within identical bands and sessions across two reciprocal ratios (IL/BLA and BLA/IL) or in decoding various defensive behaviors. These comparisons revealed significant similarities (r>0.67, p<1.1e−4). High-gamma power ratios were distinctly more important than other bands in various analyses presented in - . This comprehensive analysis indicates a clear concordance in the significance of high-gamma power ratios between IL and BLA, aligning with the patterns of importance outlined in - .\n\nTo gain further insights into the band power ratios, we examined their impact on decoding performance, as illustrated in and . High-gamma power ratios consistently led to the most substantial decrease in performance across subjects and sessions when excluded from the ML model. Thus, high-gamma power ratios are critical to decoding performance for both accelerometry jerk and bar press rate, surpassing the impact of all other frequency bands.\n\nThe band power ratios reveal variations in the activation levels between IL and BLA, offering insights into their differential engagement during defensive behaviors. These ratios allow researchers to deduce the degree of synchronization and the dynamic interactions between IL and BLA. However, it is important to note that band power ratios alone do not directly quantify the functional connectivity of these regions. Consequently, we further explored the Pearson correlations between neural signals of IL and BLA, evaluating their significance for prediction and impact on decoding performance across various frequency bands, as depicted in . In this analysis, correlations within the high-gamma frequency band emerged as the most informative features, outperforming those of other frequency bands in decoding both accelerometry jerk and bar press rate, as shown in and . demonstrates the similarity between the elements of the importance matrices from and , revealing a significant correlation (r=0.53, p=3.6e−3). We further explored the impact of band Pearson correlations on decoding performance, as depicted in and . High-gamma correlations consistently led to the most significant decline in performance when excluded from the model.\n\nCollectively, band power ratios and band Pearson correlations elucidate the neural representations between IL and BLA through distinct lenses. Therefore, the findings presented in , and together show that, across spectral and connectivity domains, oscillations in the high-gamma range within and between IL and BLA are the most reliable encoder of defensive behaviors. Thus, they may be the most reliable features for closed-loop decoding and intervention.\n\n3.5. Feature selection chooses important neuro-markers and maintains decoding performance\n\nIn this study, we introduced 17 types of neuro-markers as features, yielding a total of 1296 features for inclusion in our ML framework. Incorporating all these features would lead to increased computational and memory demands. Feature selection is a widely recognized strategy for mitigating the computational burden of cognitive decoders [62, 116]. explores the impact of feature dimensionality on decoding performance and the proportion of various types of neuro-markers among the selected features. presents the feature selection process based on feature importance as quantified by SHAP values. Here, the decoding accuracy on the validation sets, averaged across subjects, is depicted in relation to the quantity of top-ranked features. Notably, performance improves with an increasing number of selected features, reaching a plateau at approximately 100 features. By selecting only 36 and 81 top-ranked features, we observed that decoding accuracy on validation sets across all recording sessions was comparable to, and not significantly inferior to, the optimal performance identified through an exhaustive exploration of all possible counts of top-ranked features (Paired-sample t-test; accelerometry jerk: p=1.1e−1, bar press rate: p=6.1e−2. See section 2.8). These findings underscore the feasibility of dramatically reducing feature dimensionality by 97.2% (36 out of 1296) and 93.8% (81 out of 1296) without significantly compromising decoding efficacy. Within the subset of 36 and 81 top-ranked features selected for the decoding of accelerometry jerk and bar press rate, respectively, an average of 10.7 features are concordant and can predict both defensive behaviors across subjects.\n\nand delineate the distribution of different types of neuro-markers within the selected features, aligning with the previously established importance of these markers regarding prediction and performance as depicted in . In the case of accelerometry jerk, spectral (43.8%) and temporal (40.6%) features were more frequently selected over connectivity features (15.6%). BP (37.2%), LL (12.2%), and BPRC (12.5%) emerged as the predominant feature groups within the spectral, temporal, and connectivity domains, respectively, as shown in . Conversely, for bar press rate, as illustrated in , the model exhibited a preference for selecting connectivity features (43.8%) over spectral (31.9%) and temporal (24.2%), with BPRC (16.2%), BP (15.4%), BPRB (11.0%), and BCorr (9.1%) identified as leading predictors. Across all neuro-markers that span 7 frequency bands, including BP, BPRC, BCorr, Coh, and PLV, high-gamma components were most frequently chosen for decoding both defensive behaviors, with the exception of PLV for bar press rate, where the gamma component was more prominently featured.\n\nSince there can be a lag between decisions and manifested behavior, we also evaluated the decoding results using lagged neural data, as presented in . and illustrate that neural features temporally close to the current time point yield superior decoding accuracy for both behaviors, suggesting these features encapsulate a richer neural representation regarding defensive responses than those from earlier time windows. As shown in , the inclusion of features from preceding time windows together with current features does not markedly enhance the decoding performance for accelerometry jerk. In contrast, indicates a modest improvement in the decoding of bar press rate when previous time window features are incorporated. Furthermore, and indicate that the predictive power of features for both behaviors is predominantly concentrated in recent time windows, with a significant decline in predictivity as the temporal gap widens. The findings indicate that neural representations closest to the event of interest are most informative for decoding both defensive behaviors, with immediate past features contributing more significantly to model accuracy than older ones. We thus have emphasized the importance, in preceding and subsequent analyses, of features aligned to behavior with zero lag. The demonstrated temporal gradient in feature predictivity could inform the development of a more refined real-time decoder for neuropsychiatric interventions.\n\nIn , we explore the dependency of decoding performance on the diverse types of neuro-markers employed and the dimensionality of the feature set. This comparison is made between decoding outcomes utilizing only conventional band powers, decoding with a selected group of features as identified in , and decoding with the entire set of extracted features. - present the decoding performance for accelerometry jerk and bar press rate using band power features, selected top-ranked features, and all features, assessed by R2 and r metrics, respectively. The addition of other neuro-markers beyond only band power, coupled with feature selection, significantly enhances performance across sessions (for accelerometry jerk, R2 from 0.4815 to 0.5357, r from 0.7229 to 0.7579; for bar press rate, R2 from 0.3073 to 0.3476, r from 0.5708 to 0.6092). Moreover, employing the limited feature set as delineated in does not lead to a significant reduction in performance when compared to the utilization of all features. This observation holds true for the decoding of both defensive behaviors evaluated by both R2 and r metrics. Notably, the adoption of feature selection exceptionally reduces the model’s time complexity, achieving training times of less than 110 ms and inference times of less than 1 ms across all subjects and sessions.\n\nCollectively, the results presented in and underscore that the feature selection process effectively identifies important features with significant additive attribution to the prediction output and remarkable contribution to the performance in decoding defensive behaviors. Through this process, a select group of top-ranked features not only sustains decoding performance with remarkably reduced time complexity but also enhances performance in comparison to relying exclusively on band power features.\n\n4. Discussion\n\nWe developed a machine learning framework for accurately decoding defensive behaviors from multi-channel local field potentials recorded from the infralimbic cortex and basolateral amygdala. Critically, accelerometry jerk and bar press rate exhibited higher decodability compared to the freezing score, as evidenced by both the training dynamics and performance evaluations on the test set ( ). These two decodable behaviors were encoded by distinct sets of highly informative features ( and ).\n\nThis research builds upon our previous work, which underscored that these metrics each capture unique facets of defensive behavior [83]. The variation in encoding between behaviors suggests that they may have distinct neural substrates, i.e., that a closed-loop system designed to modulate defensive processes might need to control different aspects of cortical/amygdala physiology depending on the exact process being targeted. The challenge in accurately decoding the freezing score — conceptually the inverse of freezing and calculated from video frame changes to approximate the rat’s horizontal velocity — is intriguing. Given its mathematical relationship with accelerometry jerk, which essentially represents a higher derivative of movement than freezing score, this difficulty is unexpected. On the other hand, considering that mammalian motor control often optimizes for minimum jerk [117], it stands to reason that such dynamics are more directly encoded in the neural circuitry that eventually affects motor planning.\n\nFreezing, as derived from the freezing score, is probably the single most common behavior used to study the IL, BLA, and the broader circuits of the extended amygdala [79,118,119]. Its association with various LFP processes, particularly emphasizing local oscillations and cross-regional synchrony within the theta band, is well-documented [75,86]. Therefore, our inability to decode this behavior accurately presents a notable discrepancy. One possible explanation for this difference could be our focus on decoding second-to-second changes in behavior, in contrast to previous studies that typically examined longer timescales, such as the percentage of a cue tone spent in freezing versus other behaviors. As illustrated in , our decoders demonstrated better performance in capturing these broader timescales (trends or global means) than short-term variability in freezing score. This observation aligns with our previous behavioral research, which indicated that the mean freezing score across subjects correlated more closely with the mean accelerometry jerk and bar press rate, than when analyzing individual subjects [83]. This may be attributed to the averaging process across subjects, which effectively smoothed away local variance while preserving global trends, thereby rendering freezing score more comparable with other measured behaviors.\n\nBeyond the conventional use of band power features for decoding cognitive and emotional processes [38, 62, 66], our model incorporates a broader array of neuro-markers across spectral, temporal, and connectivity domains. Temporal features demonstrated a particularly significant contribution to decoding accelerometry jerk over bar press rate, as evidenced in and . This disparity likely stems from the capability of temporal-domain features to capture changes over very short intervals, reflecting the dynamic and swift variations in the defensive behaviors that define the accelerometry jerk data. Interestingly, connectivity features played a more pronounced role in decoding bar press rate compared to accelerometry jerk. This distinction may reflect the difference in behavioral characterization underpinning these behaviors; unlike accelerometry jerk, bar press rate involves the suppression of a reward-seeking response, diverging from motion-based defensive behaviors like freezing. Hence, prior studies linking defensive behaviors with theta oscillations and cross-regional LFP connectivity may more accurately depict variations in reward-related processes. A noteworthy finding is that, alongside coherence (Coh), significant decoding insights were derived from the band power ratio between channels (BPRC) and band Pearson correlation (BCorr). Thus, BPRC and BCorr warrant increased consideration over Coh in subsequent fear regulation research. We have demonstrated that these features encompass unique information not captured by band power alone [38,67,103,120].\n\nThe high-gamma band was particularly important for decoding accelerometry jerk and bar press rate in BP, BPRC, and BCorr ( – ). This finding contrasts with earlier research, where fear-related behavior was primarily correlated with theta band power and sycnhrony [75, 86]. The divergence in findings could stem from our distinct analytical methodology. Whereas previous studies often explored categorical differences, such as contrasting animals showing low versus high freezing behavior in a dichotomized analysis, our approach aimed to directly predict behaviors within individual animals and sessions. Within this shorter timescale, the involvement of faster processes, like those within the high-gamma range, may become more pivotal. We also used different electrodes, with tighter spacing that emphasizes local signals within IL and BLA. This again would emphasize more spatially local high-frequency components over more spatially distributed low-frequency LFPs. However, this emphasis on local signals more realistically models a clinical scenario, where electrodes would be implanted within a relatively small brain region.\n\nThrough our feature selection process, we strategically chose a limited subset of features to minimize the computational complexity and memory demands of our ML framework. Utilizing only 36 and 81 top-ranked features, as depicted in , we not only significantly surpassed the decoding performance achieved with 56 BP features but also matched the performance obtained with the full set of 1296 features, as demonstrated in . This indicates that neuro-markers other than BP encode unique information critical for decoding. The analytical findings from – further support that incorporating a broader spectrum of neural representations enhances decoding effectiveness, offering a more nuanced insight into neuro-markers’ roles in modulating defensive behaviors. Additionally, our results imply the existence of a considerable number of features that are either non-predictive or redundant within the model. The feature selection process effectively eliminates less informative features for each subject, thereby significantly reducing computational expenses during training and inference phases and lowering memory requirements. These efficiencies, combined with the high decoding accuracy, underscore the importance of an optimized feature selection strategy for neural decoders in neuropsychiatric brain-machine interfaces (BMIs).\n\nAdvanced machine learning models have been shown to markedly enhance neural decoding performance over conventional approaches. In our investigation, we assessed the decoding capabilities of state-of-the-art models in neural decoding tasks, including linear regression (LR), support vector machine with linear (SVM-Lin) and radial basis function kernels (SVM-RBF), random forest (RF), multilayer perceptron (MLP), long short-term memory (LSTM), convolutional neural networks (CNN), and Light Gradient Boosting Machine (LightGBM). Building on our prior research on seizure detection [90, 91, 121], mental fatigue prediction [68], finger movement classification [107, 122], and tremor detection from electrophysiological signals [97,123], gradient-boosted decision tree models (GBDT) including LightGBM were found to outperform traditional ML models, including SVM and linear discriminant analysis (LDA). Our findings further reveal that LightGBM was the best-performing model in 14 out of 16 comparisons across decoding tasks, for accelerometry jerk and bar press rate across four recording sessions, as evaluated by the coefficient of determination (R2) and the Pearson correlation coefficient (r). Although RF performed slightly better than LightGBM in decoding accelerometry jerk during the conditioning session as per R2 and in decoding bar press rate as per r, LightGBM demonstrated significantly shorter training (accelerometry jerk: <508 ms, bar press rate: <487 ms) and inference times (accelerometry jerk: <0.8 ms, bar press rate: < 0.8 ms) compared to RF (training times: accelerometry jerk: <40 s, bar press rate: <130 s; inference times: accelerometry jerk: <19 ms, bar press rate: <30 ms). These results underscore LightGBM’s capability to deliver both precise decoding outcomes and remarkably rapid decoding speeds with the utilized neuro-markers, which are the key qualities for a decoder within a closed-loop BMI system. Furthermore, LightGBM offers additional advantages over other ML models: it supports parallel computation, greatly speeding up training and inference processes. Importantly, it exhibits low hardware complexity, as demonstrated in recent low-power hardware implementations of closed-loop neuromodulation systems [90, 98, 124]. Collectively, these attributes underscore LightGBM’s potential applicability in future fully-implantabe and closed-loop psychiatric BMIs.\n\nA notable limitation of our study is the confinement of neural signals to pre-defined neuro-markers. While these neuro-markers intuitively describe neural representations in an interpretable manner, this approach may overlook critical information present in raw neural signals. In future research, we plan to harness the capabilities of artificial neural networks (ANN) for nonlinear and complex modeling, potentially uncovering hidden neural representations not captured by conventional neuro-markers. Recurrent neural networks such as LSTM could be employed to identify concealed temporal dependencies, while CNN or self-attention mechanisms might be utilized to decode the mixed spatial and temporal information. Despite the superior performance of LightGBM over MLP, LSTM, and CNN in our current analyses, pursuing further investigations into ensemble methods that integrate LightGBM with ANNs, as well as adopting ANN-derived neural representations for LightGBM decoding, represent promising avenues. These approaches could significantly enhance decoding accuracy and the generalization capacity of our models.\n\nIn our study, we employed two metrics to assess feature importance: SHapley Additive exPlanations (SHAP) and the loss of R2 upon feature removal. While SHAP values elucidate each feature’s additive attribution to prediction, they do not explicitly evaluate the necessity of features for decoding performance. Conversely, the loss of R2 quantifies a feature’s impact on performance, yet this metric might yield ambiguous interpretations in cases of high feature correlation. Additionally, it fails to satisfy the three desirable properties of additive feature attribution methods outlined by SHAP, namely local accuracy, missingness, and consistency [115]. Thus, there is a compelling opportunity for researchers to explore alternative metrics for evaluating feature importance in terms of prediction and performance that both minimize computational complexity and embody the aforementioned properties. These metrics also highlight a specific limitation of the LightGBM approach: although we can identify which bands/features are most important for a given analysis (here, high-gamma), we cannot directly use that importance for a simple, biomarker-driven intervention. Tree-based methods focus on dichotomizing a given feature at a specific value, but can select that feature again at deeper tree levels if needed. Thus, they can model complex nonlinear and non-smooth relationships between neural signals and behavior. Unlike a simpler model such as a linear regression, however, tree-based methods do not produce clear or simple relations such as “to decrease defensive behaviors, it would be desirable to reduce BLA high-gamma power”. Inferring and testing such potential causalities would require different approaches, e.g., permuting the model’s inputs in a systematic way and measuring the outputs. On the other hand, the superior decoding accuracy, feasibility for hardware implementation, and substantial pruning potential of tree-based models, as demonstrated in [91, 98, 121] could enable more efficient and effective closed-loop interventions compared to conventional approaches that rely solely on individual biomarkers [125,126].\n\nIn this research, we evaluated our model using an offline paradigm on a dataset aimed at decoding defensive behaviors. To ascertain the robustness of our model across a wider array of neuropsychiatric applications, it would be beneficial to validate our model design using additional datasets, encompassing either identical or divergent tasks. Moreover, transitioning from offline to online neural decoding represents a significant challenge. In our future work, we intend to deploy our decoding framework within an online paradigm, thereby facilitating an assessment of our model’s performance in real-time applications.\n\n5. Conclusion\n\nIn this study, we analyzed LFP signals from IL and BLA of rats subjected to a tone-shock protocol to extract neuro-markers. These markers were subsequently utilized in our ML decoding framework, which incorporates SHAP-based feature selection and LightGBM for decoding defensive behaviors. Notably, the accelerometry jerk and bar press rate proved to be more decodable than the freezing score. We achieved an average decoding performance of R2=0.5357 and r=0.7579 for the accelerometry jerk, and R2=0.3476 and r=0.6092 for the bar press rate, with exceptionally low time complexity: less than 110 ms for training and less than 1 ms for inference. BP and BPRC emerged as significant neuro-markers for prediction and decoding performance. The high-gamma band within BP, BPRC, and BCorr was consistently identified as crucial for decoding both defensive behaviors across both brain regions. The selection of top-ranked features not only surpassed the performance achieved using only BP features but also maintained the performance level of models utilizing the entire feature set. Our findings underscore the efficacy of developing an accurate and low-latency model for decoding defensive behavior based on LFP features from circuits strongly linked to these behaviors. This work lays the groundwork for future development of an implantable closed-loop psychiatric BMI, showcasing the potential of our framework in advancing neuropsychiatric treatment modalities.\n\nAcknowledgment\n\nThis work was supported by the National Institute of Mental Health Grant R01-MH-123634.\n\nFootnotes\n\nEthical statement\n\nAll experimental details were approved by the Institutional Animal Care and Use Committee at the University of Minnesota and performed in compliance with the Guide for the Care and Use of Animals. Research facilities were accredited by the American Association for the Accreditation of Laboratory Animal Care.\n\nReferences\n\n[1] Adolphs Ralph. The biology of fear. Current biology, 23(2):R79–R93, 2013. [PMC free article] [PubMed] [Google Scholar]\n\n[2] Barlow David H. Anxiety and its disorders: The nature and treatment of anxiety and panic. Guilford press, 2004.\n\n[3] LeDoux Joseph E. The emotional brain: The mysterious underpinnings of emotional life. Simon and Schuster, 1998.\n\n[4] Stein Dan J and Nesse Randolph M. Threat detection, precautionary responses, and anxiety disorders. Neuroscience & Biobehavioral Reviews, 35(4):1075–1079, 2011. [PubMed] [Google Scholar]\n\n[5] LeDoux Joseph E. Emotion circuits in the brain. Annual review of neuroscience, 23(1):155–184, 2000. [PubMed] [Google Scholar]\n\n[6] Baxter Amanda J, Scott Kate M, Vos Theo, and Whiteford Harvey A. Global prevalence of anxiety disorders: a systematic review and meta-regression. Psychological medicine, 43(5):897–910, 2013. [PubMed] [Google Scholar]\n\n[7] Shin Lisa M and Liberzon Israel. The neurocircuitry of fear, stress, and anxiety disorders. Neuropsychopharmacology, 35(1):169–191, 2010. [PMC free article] [PubMed] [Google Scholar]\n\n[8] Bandelow Borwin and Michaelis Sophie. Epidemiology of anxiety disorders in the 21st century. Dialogues in clinical neuroscience, 17(3):327–335, 2015. [PMC free article] [PubMed] [Google Scholar]\n\n[9] Vigo Daniel, Thornicroft Graham, and Atun Rifat.Estimating the true global burden of mental illness. The Lancet Psychiatry, 3(2):171–178, 2016. [PubMed] [Google Scholar]\n\n[10] Duvarci Sevil and Pare Denis. Amygdala microcircuits controlling learned fear. Neuron, 82(5):966–980, 2014. [PMC free article] [PubMed] [Google Scholar]\n\n[11] Fenster Robert J, Lebois Lauren AM, Ressler Kerry J, and Suh Junghyup. Brain circuit dysfunction in post-traumatic stress disorder: from mouse to man. Nature Reviews Neuroscience, 19(9):535–551, 2018. [PMC free article] [PubMed] [Google Scholar]\n\n[12] Tovote Philip, Fadok Jonathan Paul, and Lüthi Andreas.Neuronal circuits for fear and anxiety. Nature Reviews Neuroscience, 16(6):317–331, 2015. [PubMed] [Google Scholar]\n\n[13] Adhikari Avishek. Distributed circuits underlying anxiety.Frontiers in behavioral neuroscience, 8:112, 2014. [PMC free article] [PubMed] [Google Scholar]\n\n[14] Janak Patricia H and Tye Kay M. From circuits to behaviour in the amygdala. Nature, 517(7534):284–292, 2015. [PMC free article] [PubMed] [Google Scholar]\n\n[15] LeDoux Joseph E and Pine Daniel S. Using neuroscience to help understand fear and anxiety: a two-system framework. American journal of psychiatry, 173(11):1083–1093, 2016. [PubMed] [Google Scholar]\n\n[16] Mobbs Dean, Hagan Cindy C, Dalgleish Tim, Silston Brian, and Prévost Charlotte. The ecology of human fear: survival optimization and the nervous system. Frontiers in neuroscience, 9:55, 2015. [PMC free article] [PubMed] [Google Scholar]\n\n[17] Adhikari Avishek, Topiwala Mihir A, and Gordon Joshua A. Synchronized activity between the ventral hippocampus and the medial prefrontal cortex during anxiety. Neuron, 65(2):257–269, 2010. [PMC free article] [PubMed] [Google Scholar]\n\n[18] Poulos Andrew M, Mehta Nehali, Lu Bryan, Amir Dorsa, Livingston Briana, Santarelli Anthony, Zhuravka Irina, and Fanselow Michael S. Conditioning-and time-dependent increases in context fear and generalization. Learning & Memory, 23(7):379–385, 2016. [PMC free article] [PubMed] [Google Scholar]\n\n[19] Roelofs Karin. Freeze for action: neurobiological mechanisms in animal and human freezing. Philosophical Transactions of the Royal Society B: Biological Sciences, 372(1718):20160206, 2017. [PMC free article] [PubMed] [Google Scholar]\n\n[20] Campos Alline C, Fogaça Manoela V, Aguiar Daniele C, and Guimaraes Francisco S. Animal models of anxiety disorders and stress. Brazilian Journal of Psychiatry, 35:S101–S111, 2013. [PubMed] [Google Scholar]\n\n[21] Colom-Lapetina José, Li Anna J, Pelegrina-Perez Tatiana C, and Shansky Rebecca M. Behavioral diversity across classic rodent models is sex-dependent. Frontiers in behavioral neuroscience, 13:45, 2019. [PMC free article] [PubMed] [Google Scholar]\n\n[22] Deslauriers Jessica, Toth Mate, Der-Avakian Andre, and Risbrough Victoria B. Current status of animal models of posttraumatic stress disorder: behavioral and biological phenotypes, and future challenges in improving translation. Biological psychiatry, 83(10):895–907, 2018. [PMC free article] [PubMed] [Google Scholar]\n\n[23] Robinson Oliver J, Pike Alexandra C, Cornwell Brian, and Grillon Christian. The translational neural circuitry of anxiety. Journal of Neurology, Neurosurgery & Psychiatry, 90(12):1353–1360, 2019. [PubMed] [Google Scholar]\n\n[24] Terburg David, Scheggia Diego, Del Rio Rodrigo Triana, Klumpers Floris, Ciobanu Alexandru Cristian, Morgan Barak, Montoya Estrella R, Bos Peter A, Giobellina Gion, van den Burg Erwin H, et al. The basolateral amygdala is essential for rapid escape: a human and rodent study. Cell, 175(3):723–735, 2018. [PMC free article] [PubMed] [Google Scholar]\n\n[25] Langevin Jean-Philippe, Koek Ralph J, Schwartz Holly N, Chen James WY, Sultzer David L, Mandelkern Mark A, Kulick Alexis D, and Krahl Scott E. Deep brain stimulation of the basolateral amygdala for treatment-refractory posttraumatic stress disorder. Biological Psychiatry, 79(10):e82–e84, 2016. [PubMed] [Google Scholar]\n\n[26] Langevin Jean-Philippe, De Salles Antonio AF, Kosoyan Hovsep P, and Krahl Scott E. Deep brain stimulation of the amygdala alleviates post-traumatic stress disorder symptoms in a rat model. Journal of psychiatric research, 44(16):1241–1245, 2010. [PubMed] [Google Scholar]\n\n[27] Holtzheimer Paul E and Mayberg Helen S. Deep brain stimulation for psychiatric disorders. Annual review of neuroscience, 34:289–307, 2011. [PMC free article] [PubMed] [Google Scholar]\n\n[28] Luyten Laura, Hendrickx Sarah, Raymaekers Simon, Gabriels Loes, and Nuttin Bart. Electrical stimulation in the bed nucleus of the stria terminalis alleviates severe obsessive-compulsive disorder. Molecular psychiatry, 21(9):1272–1280, 2016. [PubMed] [Google Scholar]\n\n[29] Widge Alik S. Closing the loop in psychiatric deep brain stimulation: physiology, psychometrics, and plasticity. Neuropsychopharmacology, pages 1–12, 2023. [PMC free article] [PubMed]\n\n[30] Widge Alik S, Ellard Kristen K, Paulk Angelique C, Basu Ishita, Yousefi Ali, Zorowitz Samuel, Gilmour Anna, Afzal Afsana, Deckersbach Thilo, Cash Sydney S, et al. Treating refractory mental illness with closed-loop brain stimulation: progress towards a patient-specific transdiagnostic approach. Experimental neurology, 287:461–472, 2017. [PubMed] [Google Scholar]\n\n[31] Shin Uisub, Ding Cong, Woods Virginia, Widge Alik S, and Shoaran Mahsa. A 16-channel low-power neural connectivity extraction and phase-locked deep brain stimulation soc. IEEE solid-state circuits letters, 6:21–24, 2023. [PMC free article] [PubMed] [Google Scholar]\n\n[32] Shin Uisub, Ding Cong, Somappa Laxmeesha, Woods Virginia, Widge Alik S, and Shoaran Mahsa. A 16-channel 60μw neural synchrony processor for multi-mode phase-locked neurostimulation. In 2022 IEEE Custom Integrated Circuits Conference (CICC), pages 01–02. IEEE, 2022. [Google Scholar]\n\n[33] Widge Alik S, Dougherty Darin D, and Moritz Chet T. Affective brain-computer interfaces as enabling technology for responsive psychiatric stimulation. Brain-Computer Interfaces, 1(2):126–136, 2014. [PMC free article] [PubMed] [Google Scholar]\n\n[34] Shanechi Maryam M. Brain-machine interfaces from motor to mood. Nature neuroscience, 22(10):1554–1564, 2019. [PubMed] [Google Scholar]\n\n[35] Shoaran Mahsa. Next-generation closed-loop neural interfaces: Circuit and ai-driven innovations. IEEE Solid-State Circuits Magazine, 15(4):41–49, 2023. [Google Scholar]\n\n[36] Yoo Jerald and Shoaran Mahsa. Neural interface systems with on-device computing: Machine learning and neuromorphic architectures. Current opinion in biotechnology, 72:95–101, 2021. [PubMed] [Google Scholar]\n\n[37] Widge AS, Zorowitz S, Basu Ishita, Paulk AC, Cash SS, Eskandar EN, Deckersbach Thilo, Miller EK, and Dougherty DD. Deep brain stimulation of the internal capsule enhances human cognitive control and prefrontal cortex function. Nature communications, 10(1):1536, 2019. [PMC free article] [PubMed] [Google Scholar]\n\n[38] Sani Omid G, Yang Yuxiao, Lee Morgan B, Dawes Heather E, Chang Edward F, and Shanechi Maryam M. Mood variations decoded from multi-site intracranial human brain activity. Nature biotechnology, 36(10):954–961, 2018. [PubMed] [Google Scholar]\n\n[39] Zhu Bingzhao, Shin Uisub, and Shoaran Mahsa. Closed-loop neural prostheses with on-chip intelligence: A review and a low-latency machine learning model for brain state detection. IEEE transactions on biomedical circuits and systems, 15(5):877–897, 2021. [PMC free article] [PubMed] [Google Scholar]\n\n[40] Sani Omid G, Yang Yuxiao, and Shanechi Maryam M. Brain-machine interfaces for closed-loop electrical brain stimulation in neuropsychiatric disorders. In Handbook of Neuroengineering, pages 1317–1342. Springer, 2023. [Google Scholar]\n\n[41] Shenoy Krishna V and Carmena Jose M. Combining decoder design and neural adaptation in brain-machine interfaces. Neuron, 84(4):665–680, 2014. [PubMed] [Google Scholar]\n\n[42] Serruya Mijail, Hatsopoulos Nicholas, Fellows Matthew, Paninski Liam, and Donoghue John. Robustness of neuroprosthetic decoding algorithms. Biological cybernetics, 88:219–228, 2003. [PubMed] [Google Scholar]\n\n[43] Ethier Christian, Oby Emily R, Bauman Matthew J, and Miller Lee E. Restoration of grasp following paralysis through brain-controlled stimulation of muscles. Nature, 485(7398):368–371, 2012. [PMC free article] [PubMed] [Google Scholar]\n\n[44] Baeg EH, Kim YB, Huh K, Mook-Jung I, Kim HT, and Jung MW. Dynamics of population code for working memory in the prefrontal cortex. Neuron, 40(1):177–188, 2003. [PubMed] [Google Scholar]\n\n[45] Ibos Guilhem and Freedman David J. Sequential sensory and decision processing in posterior parietal cortex. Elife, 6:e23743, 2017. [PMC free article] [PubMed] [Google Scholar]\n\n[46] Zhang Kechen, Ginzburg Iris, McNaughton Bruce L, and Sejnowski Terrence J. Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells. Journal of neurophysiology, 79(2):1017–1044, 1998. [PubMed] [Google Scholar]\n\n[47] Davidson Thomas J, Kloosterman Fabian, and Wilson Matthew A. Hippocampal replay of extended experience. Neuron, 63(4):497–507, 2009. [PMC free article] [PubMed] [Google Scholar]\n\n[48] Hung Chou P, Kreiman Gabriel, Poggio Tomaso, and DiCarlo James J. Fast readout of object identity from macaque inferior temporal cortex. Science, 310(5749):863–866, 2005. [PubMed] [Google Scholar]\n\n[49] Rich Erin L and Wallis Jonathan D. Decoding subjective decisions from orbitofrontal cortex. Nature neuroscience, 19(7):973–980, 2016. [PMC free article] [PubMed] [Google Scholar]\n\n[50] Dekleva Brian M, Ramkumar Pavan, Wanda Paul A, Kording Konrad P, and Miller Lee E. Uncertainty leads to persistent effects on reach representations in dorsal premotor cortex. Elife, 5:e14316, 2016. [PMC free article] [PubMed] [Google Scholar]\n\n[51] Raposo David, Kaufman Matthew T, and Church-land Anne K. A category-free neural population supports evolving demands during decision-making. Nature neuroscience, 17(12):1784–1792, 2014. [PMC free article] [PubMed] [Google Scholar]\n\n[52] Quiroga Rodrigo Quian, Snyder Lawrence H, Batista Aaron P, Cui He, and Andersen Richard A. Movement intention is better predicted than attention in the posterior parietal cortex. Journal of neuroscience, 26(13):3615–3620, 2006. [PMC free article] [PubMed] [Google Scholar]\n\n[53] Weygandt Martin, Blecker Carlo R, Schiäfer Axel, Hackmack Kerstin, Haynes John-Dylan, Vaitl Dieter, Stark Rudolf, and Schienle Anne. fmri pattern recognition in obsessive-compulsive disorder. Neuroimage, 60(2):1186–1193, 2012. [PubMed] [Google Scholar]\n\n[54] Drevets Wayne C. Neuroimaging and neuropathological studies of depression: implications for the cognitive-emotional features of mood disorders. Current opinion in neurobiology, 11(2):240–249, 2001. [PubMed] [Google Scholar]\n\n[55] Mayberg Helen S. Modulating dysfunctional limbic-cortical circuits in depression: towards development of brain-based algorithms for diagnosis and optimised treatment. British medical bulletin, 65(1):193–207, 2003. [PubMed] [Google Scholar]\n\n[56] Kupfer David J, Frank Ellen, and Phillips Mary L. Major depressive disorder: new clinical, neurobiological, and treatment perspectives. The Lancet, 379(9820):1045–1055, 2012. [PMC free article] [PubMed] [Google Scholar]\n\n[57] Mayberg Helen S. Limbic-cortical dysregulation: a proposed model of depression. The Journal of neuropsychiatry and clinical neurosciences, 9(3):471–481, 1997. [PubMed] [Google Scholar]\n\n[58] Ritchie J Brendan, Kaplan David Michael, and Klein Colin. Decoding the brain: Neural representation and the limits of multivariate pattern analysis in cognitive neuroscience. The British journal for the philosophy of science, 2019. [PMC free article] [PubMed]\n\n[59] Lydon-Staley David M, Cornblath Eli J, Blevins Ann Sizemore, and Bassett Danielle S. Modeling brain, symptom, and behavior in the winds of change. Neuropsychopharmacology, 46(1):20–32, 2021. [PMC free article] [PubMed] [Google Scholar]\n\n[60] Glaser Joshua I, Benjamin Ari S, Farhoodi Roozbeh, and Kording Konrad P. The roles of supervised machine learning in systems neuroscience. Progress in neurobiology, 175:126–137, 2019. [PMC free article] [PubMed] [Google Scholar]\n\n[61] LeCun Yann, Bengio Yoshua, and Hinton Geoffrey. Deep learning. nature, 521(7553):436–444, 2015. [PubMed] [Google Scholar]\n\n[62] Basu Ishita, Yousefi Ali, Crocker Britni, Zelmann Rina, Paulk Angelique C, Peled Noam, Ellard Kristen K, Weisholtz Daniel S, Cosgrove G Rees, Deckersbach Thilo, et al. Closed-loop enhancement and neural decoding of cognitive control in humans. Nature biomedical engineering, 7(4):576–588, 2023. [PMC free article] [PubMed] [Google Scholar]\n\n[63] Provenza Nicole R, Paulk Angelique C, Peled Noam, Restrepo Maria I, Cash Sydney S, Dougherty Darin D, Eskandar Emad N, Borton David A, and Widge Alik S. Decoding task engagement from distributed network electrophysiology in humans. Journal of neural engineering, 16(5):056015, 2019. [PMC free article] [PubMed] [Google Scholar]\n\n[64] Avvaru Sandeep, Provenza Nicole R, Widge Alik S, and Parhi Keshab K. Spectral features based decoding of task engagement: The role of theta and high gamma bands in cognitive control. In 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), pages 6062–6065. IEEE, 2021. [PubMed] [Google Scholar]\n\n[65] Alagapan Sankaraleengam, Choi Ki Sueng, Heisig Stephen, Riva-Posse Patricio, Crowell Andrea, Tiruvadi Vineet, Obatusin Mosadoluwa, Veerakumar Ashan, Waters Allison C, Gross Robert E, et al. Cingulate dynamics track depression recovery with deep brain stimulation. Nature, pages 1–9, 2023. [PMC free article] [PubMed]\n\n[66] Bijanzadeh Maryam, Khambhati Ankit N, Desai Maansi, Wallace Deanna L, Shafi Alia, Dawes Heather E, Sturm Virginia E, and Chang Edward F. Decoding naturalistic affective behaviour from spectro-spatial features in multiday human ieeg. Nature Human Behaviour, 6(6):823–836, 2022. [PMC free article] [PubMed] [Google Scholar]\n\n[67] Hultman Rainbo, Ulrich Kyle, Sachs Benjamin D, Blount Cameron, Carlson David E, Ndubuizu Nkemdilim, Bagot Rosemary C, Parise Eric M, Vu Mai-Anh T, Gallagher Neil M, et al. Brain-wide electrical spatiotemporal dynamics encode depression vulnerability. Cell, 173(1):166–180, 2018. [PMC free article] [PubMed] [Google Scholar]\n\n[68] Yao Lin, Baker Jonathan L, Schiff Nicholas D, Purpura Keith P, and Shoaran Mahsa. Predicting task performance from biomarkers of mental fatigue in global brain activity. Journal of neural engineering, 18(3):036001, 2021. [PMC free article] [PubMed] [Google Scholar]\n\n[69] Yao Lin, Baker Jonathan L, Ryou Jae-Wook, Schiff Nicholas D, Purpura Keith P, and Shoaran Mahsa. Mental fatigue prediction from multi-channel ecog signal. In ICASSP 2020–2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 1259–1263. IEEE, 2020. [Google Scholar]\n\n[70] Sellers Kristin K, Khambhati Ankit N, Stapper Noah, Fan Joline M, Rao Vikram R, Scangos Katherine W, Chang Edward F, and Krystal Andrew D. Closed-loop neurostimulation for biomarker-driven, personalized treatment of major depressive disorder. JoVE (Journal of Visualized Experiments), (197):e65177, 2023. [PubMed]\n\n[71] Wu Wei, Zhang Yu, Jiang Jing, Lucas Molly V, Fonzo Gregory A, Rolle Camarin E, Cooper Crystal, Chin-Fatt Cherise, Krepel Noralie, Cornelssen Carena A, et al. An electroencephalographic signature predicts antidepressant response in major depression. Nature biotechnology, 38(4):439–447, 2020. [PMC free article] [PubMed] [Google Scholar]\n\n[72] Avvaru Sandeep, Provenza Nicole R, Widge Alik S, and Parhi Keshab K. Decoding human cognitive control using functional connectivity of local field potentials. In 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), pages 451–454. IEEE, 2021. [PubMed] [Google Scholar]\n\n[73] Blanchard D Caroline, Hynd April L, Minke Karl A, Minemoto Tiffanie, and Blanchard Robert J. Human defensive behaviors to threat scenarios show parallels to fear-and anxiety-related defense patterns of non-human mammals. Neuroscience & Biobehavioral Reviews, 25(7–8):761–770, 2001. [PubMed] [Google Scholar]\n\n[74] Mobbs Dean and Kim Jeansok J. Neuroethological studies of fear, anxiety, and risky decision-making in rodents and humans. Current opinion in behavioral sciences, 5:8–15, 2015. [PMC free article] [PubMed] [Google Scholar]\n\n[75] Bocchio Marco, Nabavi Sadegh, and Capogna Marco. Synaptic plasticity, engrams, and network oscillations in amygdala circuits for storage and retrieval of emotional memories. Neuron, 94(4):731–743, 2017. [PubMed] [Google Scholar]\n\n[76] Likhtik Ekaterina, Stujenske Joseph M, Topiwala Mihir A, Harris Alexander Z, and Gordon Joshua A. Prefrontal entrainment of amygdala activity signals safety in learned fear and innate anxiety. Nature neuroscience, 17(1):106–113, 2014. [PMC free article] [PubMed] [Google Scholar]\n\n[77] Karalis Nikolaos, Dejean Cyril, Chaudun Fabrice, Khoder Suzana, Rozeske Robert R, Wurtz Hélène, Bagur Sophie, Benchenane Karim, Sirota Anton, Courtin Julien, et al. 4-hz oscillations synchronize prefrontal–amygdala circuits during fear behavior. Nature neuroscience, 19(4):605–612, 2016. [PMC free article] [PubMed] [Google Scholar]\n\n[78] Milad Mohammed R, Igoe Sarah, and Orr Scott P. Fear conditioning in rodents and humans. Animal Models of Behavioral Analysis, pages 111–132, 2011.\n\n[79] McDannald Michael A. Pavlovian fear conditioning is more than you think it is. Journal of Neuroscience, 43(48):8079–8087, 2023. [PMC free article] [PubMed] [Google Scholar]\n\n[80] Reis Fernando MCV, Liu Jinhan, Schuette Peter J, Lee Johannes Y, Maesta-Pereira Sandra, Chakerian Meghmik, Wang Weisheng, Canteras Newton S, Kao Jonathan C, and Adhikari Avishek. Shared dorsal periaqueductal gray activation patterns during exposure to innate and conditioned threats. Journal of Neuroscience, 41(25):5399–5420, 2021. [PMC free article] [PubMed] [Google Scholar]\n\n[81] Reis Fernando MCV, Lee Johannes Y, Maesta-Pereira Sandra, Schuette Peter J, Chakerian Meghmik, Liu Jinhan, La-Vu Mimi Q, Tobias Brooke C, Ikebara Juliane M, Kihara Alexandre Hiroaki, et al. Dorsal periaqueductal gray ensembles represent approach and avoidance states. Elife, 10:e64934, 2021. [PMC free article] [PubMed] [Google Scholar]\n\n[82] Li Yonghui, Dong Xinwen, Li Sa, and Kirouac Gilbert J. Lesions of the posterior paraventricular nucleus of the thalamus attenuate fear expression. Frontiers in behavioral neuroscience, 8:94, 2014. [PMC free article] [PubMed] [Google Scholar]\n\n[83] Younk Rebecca and Widge Alik. Quantifying defensive behavior and threat response through integrated headstage accelerometry. Journal of Neuroscience Methods, 382:109725, 2022. [PubMed] [Google Scholar]\n\n[84] Siegle Joshua H, Hale Gregory J, Newman Jonathan P, and Voigts Jakob. Neural ensemble communities: open-source approaches to hardware for large-scale electrophysiology. Current opinion in neurobiology, 32:53–59, 2015. [PMC free article] [PubMed] [Google Scholar]\n\n[85] Lo Meng-Chen, Younk Rebecca, and Widge Alik S. Paired electrical pulse trains for controlling connectivity in emotion-related brain circuitry. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 28(12):2721–2730, 2020. [PMC free article] [PubMed] [Google Scholar]\n\n[86] Totty Michael S and Maren Stephen. Neural oscillations in aversively motivated behavior. Frontiers in Behavioral Neuroscience, 16:936036, 2022. [PMC free article] [PubMed] [Google Scholar]\n\n[87] Logesparan Lojini, Casson Alexander J, and Rodriguez-Villegas Esther. Optimal features for online seizure detection. Medical & biological engineering & computing, 50:659–669, 2012. [PubMed] [Google Scholar]\n\n[88] Maling Nicholas and McIntyre Cameron. Local field potential analysis for closed-loop neuromodulation. In Closed Loop Neuroscience, pages 67–80, 2016.\n\n[89] Stavisky Sergey D, Kao Jonathan C, Nuyujukian Paul, Ryu Stephen I, and Shenoy Krishna V. A high performing brain-machine interface driven by low-frequency local field potentials alone and together with spikes. Journal of neural engineering, 12(3):036009, 2015. [PMC free article] [PubMed] [Google Scholar]\n\n[90] Shoaran Mahsa, Haghi Benyamin Allahgholizadeh, Taghavi Milad, Farivar Masoud, and Emami-Neyestanak Azita. Energy-efficient classification for resource-constrained biomedical applications. IEEE Journal on Emerging and Selected Topics in Circuits and Systems, 8(4):693–707, 2018. [Google Scholar]\n\n[91] Zhu Bingzhao, Farivar Masoud, and Shoaran Mahsa. Resot: Resource-efficient oblique trees for neural signal classification. IEEE Transactions on Biomedical Circuits and Systems, 14(4):692–704, 2020. [PubMed] [Google Scholar]\n\n[92] Bandarabadi Mojtaba, Teixeira César A, Rasekhi Jalil, and Dourado Ántonio. Epileptic seizure prediction using relative spectral power features. Clinical Neurophysiology, 126(2):237–248, 2015. [PubMed] [Google Scholar]\n\n[93] Zhang Zisheng and Parhi Keshab K. Low-complexity seizure prediction from ieeg/seeg using spectral power and ratios of spectral power. IEEE transactions on biomedical circuits and systems, 10(3):693–706, 2015. [PubMed] [Google Scholar]\n\n[94] Bandarabadi Mojtaba, Teixeira César A, Netoff Theoden I, Parhi Keshab K, and Dourado António. Robust and low complexity algorithms for seizure detection. In 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pages 4447–4450. IEEE, 2014. [PubMed] [Google Scholar]\n\n[95] Koolen Ninah, Jansen Katrien, Vervisch Jan, Matic Vladimir, De Vos Maarten, Naulaers Gunnar, and Van Huffel Sabine. Line length as a robust method to detect high-activity events: automated burst detection in premature eeg recordings. Clinical Neurophysiology, 125(10):1985–1994, 2014. [PubMed] [Google Scholar]\n\n[96] Mehmood Raja Majid and Lee Hyo Jong. Eeg based emotion recognition from human brain using hjorth parameters and svm. International Journal of Bio-Science and Bio-Technology, 7(3):23–32, 2015. [Google Scholar]\n\n[97] Yao Lin, Brown Peter, and Shoaran Mahsa. Improved detection of parkinsonian resting tremor with feature engineering and kalman filtering. Clinical Neurophysiology, 131(1):274–284, 2020. [PMC free article] [PubMed] [Google Scholar]\n\n[98] Shin Uisub, Ding Cong, Zhu Bingzhao, Vyza Yashwanth, Trouillet Alix, Revol Emilie CM, Lacour Stéphanie P, and Shoaran Mahsa. Neuraltree: A 256-channel 0.227-μj/class versatile neural activity classification and closed-loop neuromodulation soc. IEEE Journal of Solid-State Circuits, 57(11):3243–3257, 2022. [PMC free article] [PubMed] [Google Scholar]\n\n[99] Mukhopadhyay Sudipta and Ray GC. A new interpretation of nonlinear energy operator and its efficacy in spike detection. IEEE Transactions on biomedical engineering, 45(2):180–187, 1998. [PubMed] [Google Scholar]\n\n[100] Xiang Jing, Maue Ellen, Fan Yuyin, Qi Lei, Mangano Francesco T, Greiner Hansel, and Tenney Jeffrey. Kurtosis and skewness of high-frequency brain signals are altered in paediatric epilepsy. Brain communications, 2(1):fcaa036, 2020. [PMC free article] [PubMed] [Google Scholar]\n\n[101] Srinivasan Vairavan, Eswaran Chikkannan, and Sriraam Natarajan. Approximate entropy-based epileptic eeg detection using artificial neural networks. IEEE Transactions on information Technology in Biomedicine, 11(3):288–295, 2007. [PubMed] [Google Scholar]\n\n[102] Jie Xiang, Cao Rui, and Li Li. Emotion recognition based on the sample entropy of eeg. Bio-medical materials and engineering, 24(1):1185–1192, 2014. [PubMed] [Google Scholar]\n\n[103] Kirkby Lowry A., Luongo Francisco J., Lee Morgan B., Nahum Mor, Van Vleet Thomas M., Rao Vikram R., Dawes Heather E., Chang Edward F., and Sohal Vikaas S. An amygdala-hippocampus subnetwork that encodes variation in human mood. Cell, 175(6):1688–1700.e14, 2018. [PubMed] [Google Scholar]\n\n[104] Munia Tamanna TK and Aviyente Selin. Time-frequency based phase-amplitude coupling measure for neuronal oscillations. Scientific reports, 9(1):12441, 2019. [PMC free article] [PubMed] [Google Scholar]\n\n[105] Nandi Bijurika, Swiatek Peter, Kocsis Bernat, and Ding Mingzhou. Inferring the direction of rhythmic neural transmission via inter-reg"
    }
}