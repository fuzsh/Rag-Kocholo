{
    "id": "dbpedia_9220_0",
    "rank": 12,
    "data": {
        "url": "https://www.npr.org/sections/health-shots/2023/05/01/1173045261/a-decoder-that-uses-brain-scans-to-know-what-you-mean-mostly",
        "read_more_link": "",
        "language": "en",
        "title": "A decoder that uses brain scans to know what you mean â€” mostly",
        "top_image": "https://media.npr.org/assets/img/2023/05/01/brain-scan-huth-et-al_wide-9f7ba9d7b34911efc30b76df1a4c40f2874bc799.jpg?s=1400&c=100&f=jpeg",
        "meta_img": "https://media.npr.org/assets/img/2023/05/01/brain-scan-huth-et-al_wide-9f7ba9d7b34911efc30b76df1a4c40f2874bc799.jpg?s=1400&c=100&f=jpeg",
        "images": [
            "https://media.npr.org/chrome_svg/npr-logo.svg",
            "https://media.npr.org/chrome/programs/logos/morning-edition.jpg",
            "https://media.npr.org/assets/img/2019/02/26/we_otherentitiestemplatesat_sq-cbde87a2fa31b01047441e6f34d2769b0287bcd4-s100-c85.png",
            "https://media.npr.org/assets/img/2019/02/26/we_otherentitiestemplatesun_sq-4a03b35e7e5adfa446aec374523a578d54dc9bf5-s100-c85.png",
            "https://media.npr.org/chrome/programs/logos/all-things-considered.png",
            "https://media.npr.org/chrome/programs/logos/fresh-air.png",
            "https://media.npr.org/chrome/programs/logos/up-first.jpg?version=2",
            "https://media.npr.org/assets/img/2024/01/11/podcast-politics_2023_update1_sq-be7ef464dd058fe663d9e4cfe836fb9309ad0a4d-s100-c100.jpg",
            "https://media.npr.org/assets/img/2024/05/15/throughline_tile-art_sq-b72bcfb6d8705d7761d4f421f0be3047631b709c-s100-c100.jpg",
            "https://media.npr.org/assets/img/2023/11/10/trumps-trial_tile-art_small_sq-71cfb7f3a96f3029db4ca7230c5704c61a351b81-s100-c100.jpg",
            "https://media.npr.org/assets/img/2024/04/19/tile-wild-card-with-rachel-martin_sq-c9e842a167bab21c50f45fbde9d7d33776e87eda-s100-c100.jpg",
            "https://media.npr.org/chrome_svg/music-logo-dark.svg",
            "https://media.npr.org/chrome_svg/music-logo-light.svg",
            "https://media.npr.org/branding/sections/health-shots/branding_icon-9d5c5798fbff8351e5c796ffe65e5e8246c166fb-s1000-c100.png",
            "https://media.npr.org/assets/img/2011/12/30/johnhamilton_3_sq-5cea2a02614aeaa7abf049f38ed77fc78aaf2880.jpg?s=100&c=85&f=jpeg",
            "https://media.npr.org/assets/img/2023/05/01/brain-scan-huth-et-al-38cc80e5714826a9716350ffed89a5329d39556e.jpg?s=1100&c=85&f=jpeg",
            "https://media.npr.org/assets/img/2023/03/21/20220402_142342_sq-6d45c2bb3dcf2c4d3013d7d99cb806b48097c628.jpg?s=100&c=15&f=jpeg",
            "https://media.npr.org/assets/img/2023/03/31/gettyimages-1124485411_sq-12f54d1d62d6a559231cd636caf5a19f8d86e165.jpg?s=100&c=15&f=jpeg",
            "https://media.npr.org/branding/sections/health-shots/branding_icon-9d5c5798fbff8351e5c796ffe65e5e8246c166fb-s1000-c100.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Jon Hamilton"
        ],
        "publish_date": "2023-05-01T00:00:00",
        "summary": "",
        "meta_description": "Scientists have decoded streams of words in the brain using artificial intelligence and the data from MRI scans.",
        "meta_lang": "en",
        "meta_favicon": "https://media.npr.org/chrome/favicon/favicon-180x180.png",
        "meta_site_name": "NPR",
        "canonical_link": "https://www.npr.org/sections/health-shots/2023/05/01/1173045261/a-decoder-that-uses-brain-scans-to-know-what-you-mean-mostly",
        "text": "Scientists have found a way to decode a stream of words in the brain using MRI scans and artificial intelligence.\n\nThe system reconstructs the gist of what a person hears or imagines, rather than trying to replicate each word, a team reports in the journal Nature Neuroscience.\n\n\"It's getting at the ideas behind the words, the semantics, the meaning,\" says Alexander Huth, an author of the study and an assistant professor of neuroscience and computer science at The University of Texas at Austin.\n\nThis technology can't read minds, though. It only works when a participant is actively cooperating with scientists.\n\nStill, systems that decode language could someday help people who are unable to speak because of a brain injury or disease. They also are helping scientists understand how the brain processes words and thoughts.\n\nPrevious efforts to decode language have relied on sensors placed directly on the surface of the brain. The sensors detect signals in areas involved in articulating words.\n\nBut the Texas team's approach is an attempt to \"decode more freeform thought,\" says Marcel Just, a professor of psychology at Carnegie Mellon University who was not involved in the new research.\n\nThat could mean it has applications beyond communication, he says.\n\n\"One of the biggest scientific medical challenges is understanding mental illness, which is a brain dysfunction ultimately,\" Just says. \"I think that this general kind of approach is going to solve that puzzle someday.\"\n\nPodcasts in the MRI\n\nThe new study came about as part of an effort to understand how the brain processes language.\n\nResearchers had three people spend up to 16 hours each in a functional MRI scanner, which detects signs of activity across the brain.\n\nParticipants wore headphones that streamed audio from podcasts. \"For the most part, they just lay there and listened to stories from The Moth Radio Hour, Huth says.\n\nThose streams of words produced activity all over the brain, not just in areas associated with speech and language.\n\n\"It turns out that a huge amount of the brain is doing something,\" Huth says. \"So areas that we use for navigation, areas that we use for doing mental math, areas that we use for processing what things feel like to touch.\"\n\nAfter participants listened to hours of stories in the scanner, the MRI data was sent to a computer. It learned to match specific patterns of brain activity with certain streams of words.\n\nNext, the team had participants listen to new stories in the scanner. Then the computer attempted to reconstruct these stories from each participant's brain activity.\n\nThe system got a lot of help constructing intelligible sentences from artificial intelligence: an early version of the famous natural language processing program ChatGPT.\n\nWhat emerged from the system was a paraphrased version of what a participant heard.\n\nSo if a participant heard the phrase, \"I didn't even have my driver's license yet,\" the decoded version might be, \"she hadn't even learned to drive yet,\" Huth says. In many cases, he says, the decoded version contained errors.\n\nIn another experiment, the system was able to paraphrase words a person just imagined saying.\n\nIn a third experiment, participants watched videos that told a story without using words.\n\n\"We didn't tell the subjects to try to describe what's happening,\" Huth says. \"And yet what we got was this kind of language description of what's going on in the video.\"\n\nA noninvasive window on language\n\nThe MRI approach is currently slower and less accurate than an experimental communication system being developed for paralyzed people by a team led by Dr. Edward Chang at the University of California, San Francisco.\n\n\"People get a sheet of electrical sensors implanted directly on the surface of the brain,\" says David Moses, a researcher in Chang's lab. \"That records brain activity really close to the source.\"\n\nThe sensors detect activity in brain areas that usually give speech commands. At least one person has been able to use the system to accurately generate 15 words a minute using only his thoughts.\n\nBut with an MRI-based system, \"No one has to get surgery,\" Moses says.\n\nNeither approach can be used to read a person's thoughts without their cooperation. In the Texas study, people were able to defeat the system just by telling themselves a different story.\n\nBut future versions could raise ethical questions .\n\n\"This is very exciting, but it's also a little scary, Huth says. \"What if you can read out the word that somebody is just thinking in their head? That's potentially a harmful thing.\"\n\nMoses agrees.\n\n\"This is all about the user having a new way of communicating, a new tool that is totally in their control,\" he says. \"That is the goal and we have to make sure that stays the goal.\""
    }
}