{
    "id": "dbpedia_6684_0",
    "rank": 93,
    "data": {
        "url": "https://web-archive.southampton.ac.uk/opcit.eprints.org/oacitation-biblio.html",
        "read_more_link": "",
        "language": "en",
        "title": "The effect of open access and downloads ('hits') on citation impact: a bibliography of studies",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://web-archive.southampton.ac.uk/opcit.eprints.org/Opcitminilogo.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Steve Hitchcock"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Latest articles on OA impact This update service is no longer available following the closure of Connotea. It may be resumed if a suitable alternative service is found.\n\nFind your way through the bibliography\n\nSelected topic ALERTboxes: OA impact biblio rapid reader | Reviews of OA impact studies\n\nLatest additions\n\nStudies with original data\n\nWeb tools for measuring impact | Comparative reviews\n\nBackground\n\nThe financial imperative: correlating research access, impact and assessment | Citation analysis, indexes and impact factors | Open access\n\nLast updated 25 June 2013; first posted 15 September 2004. If you have any additions, corrections or comments, please tweet @stevehit #oaimpact or email Steve Hitchcock.\n\nWhat others say about this bibliography\n\n\"a brilliant source of articles\" (on impact of Open Access material)\n\nChristine Stohn, Ex Libris Initiatives (3 September 2012)\n\n\"a major bibliography on this debate\"\n\nAlan M Johnson, Charting a Course for a Successful Research Career: A Guide for Early Career Researchers, 2nd edition (April 2011), ch. 9, Where to Publish, p50\n\nA great resource!\n\nEloy Rodrigues, University of Minho, via Twitter (July 17, 2009)\n\n\"incredible resource\"\n\nOA Librarian blog, Citation Impact Bibliography Resource (December 7, 2005)\n\n\"excellent bibliography\"\n\nHeather Morrison, The Imaginary Journal of Poetic Economics (December 08, 2005)\n\nPeter Suber, American Scientist Open Access Forum (28 September 2005) http://www.ecs.soton.ac.uk/~harnad/Hypermail/Amsci/4804.html\n\n\"This ongoing chronological bibliography may be worth bookmarking and checking every few months. There's very little annotation, but it's a good brief bibliography on a narrow - but important - subject.\"\n\nWalt Crawford, Cites & Insights (November 2004, p13) http://citesandinsights.info/civ4i13.pdf\n\nOpen Access Policies. This bibliography is cited in support of the following open access policies, statements and guidelines for authors:\n\nNational Institute for Health Research (UK NHS) Health Technology Assessment programme: Resources for authors (12th edition, May 2011)\n\nOpen Access Policies Kit produced by RCAAP (Portugal Open Access Science Repository), endorsed by Confederation of Open Access Repositories (COAR) 31 March 2011\n\nLincoln University Research Committee policy of 'universal practice' for repository deposit, 30 March 2010\n\nHarvard University Library Office for Scholarly Communication in support of Harvard Open Access Policies (2010)\n\nTimes Higher Education Leader: Put all the results out in the open, 12 November 2009\n\nStudent Statement on The Right to Research (2009)\n\nCanadian Health Services Research Foundation Policy on Open Access to Research Outputs (October 2008)\n\nStanford University School of Education Open Access Policy (June 10, 2008)\n\nUK PubMed Central Guidelines for Researchers funded by the Austrian Science Fund (FWF) (2008)\n\nFraunhofer-Gesellschaft Open Access Guidelines (2008)\n\nUniversity of California Open Access Policy Proposal (February 2007)\n\nNational Institutes of Health, Policy on Enhancing Public Access to Archived Publications Resulting from NIH-Funded Research (February 3, 2005)\n\nEconomics. This bibliography cited by\n\nGoogle researchers in their evaluation of the Internet's impact on the broader macro-economy and their proposal aimed at economic policymakers for an Innovation Stimulus Agenda (Embracing an innovation stimulus package, SSRN)\n\nCitations of this bibliography found by Google Scholar\n\nWeb pages that link to this bibliography found by Google\n\nIntroduction to the bibliography\n\nDespite significant growth in the number of research papers available through open access, principally through author self-archiving in institutional archives, it is estimated that only c. 20% of the number of papers published annually are open access. It is up to the authors of papers to change this. Why might open access be of benefit to authors? One universally important factor for all authors is impact, typically measured by the number of times a paper is cited (some older studies have estimated monetary returns to authors from article publication via the role citations play in determining salaries). Recent studies have begun to show that open access increases impact. More studies and more substantial investigations are needed to confirm the effect, although a simple example demonstrates the effect.\n\nThis chronological bibliography is intended to describe progress in reporting these studies; it also lists the Web tools available to measure impact. It is a focused bibliography, on the relationship between impact and access. It does not attempt to cover citation impact, or other related topics such as open access, more generally, although some key papers in these areas are listed as jump-off points for wider study.\n\nLatest additions to the bibliography\n\nAdded 25 June 2013 Björn Brembs, Katherine Button and Marcus Munafò (2013)\n\nDeep impact: unintended consequences of journal rank\n\nFront. Hum. Neurosci., 7:291, published online: 24 June 2013. Also in arXiv.org > cs > arXiv:1301.3748, v1, 16 Jan 2013 http://arxiv.org/abs/1301.3748\n\ndoi: 10.3389/fnhum.2013.00291\n\nAbstract: Most researchers acknowledge an intrinsic hierarchy in the scholarly journals (journal rank) that they submit their work to, and adjust not only their submission but also their reading strategies accordingly. On the other hand, much has been written about the negative effects of institutionalizing journal rank as an impact measure. So far, contributions to the debate concerning the limitations of journal rank as a scientific impact assessment tool have either lacked data, or relied on only a few studies. In this review, we present the most recent and pertinent data on the consequences of our current scholarly communication system with respect to various measures of scientific quality (such as utility/citations, methodological soundness, expert ratings or retractions). These data corroborate previous hypotheses: using journal rank as an assessment tool is bad scientific practice. Moreover, the data lead us to argue that any journal rank (not only the currently-favored Impact Factor) would have this negative impact. Therefore, we suggest that abandoning journals altogether, in favor of a library-based scholarly communication system, will ultimately be necessary. This new system will use modern information technology to vastly improve the filter, sort and discovery functions of the current journal system.\n\nAdded 25 June 2013 Valeria Aman (2013)\n\nThe potential of preprints to accelerate scholarly communication - A bibliometric analysis based on selected journals\n\narXiv.org > cs > arXiv:1306.4856, 20 Jun 2013\n\nMaster Thesis. Abstract: This paper quantifies to which extent preprints in arXiv accelerate scholarly communication. The following subject fields were investigated up to the year 2012: High Energy Physics (HEP), Mathematics, Astrophysics, Quantitative Biology, and Library and Information Science (LIS). Publication and citation data was downloaded from Scopus and matched with corresponding preprints in arXiv. Furthermore, the INSPIRE HEP database was used to retrieve citation data for papers related to HEP. The bibliometric analysis deals with the growth in numbers of articles published having a previous preprint in arXiv and the publication delay, which is defined as the chronological distance between the deposit of a preprint in arXiv and its formal journal publication. Likewise, the citation delay is analyzed, which describes the time it takes until the first citation of preprints, and articles, respectively. Total citation numbers are compared for sets of articles with a previous preprint and those without. The results show that in all fields but biology a significant citation advantage exists in terms of speed and citation rates for articles with a previous preprint version on arXiv.\n\nAdded 21 June 2013 Carsten Nieder, Astrid Dalhaug and Gro Aandahl (2013)\n\nCorrelation between article download and citation figures for highly accessed articles from five open access oncology journals\n\nSpringerPlus, 2:261, 13 June 2013\n\ndoi:10.1186/2193-1801-2-261\n\nAbstract (provisional): Different approaches can be chosen to quantify the impact and merits of scientific oncology publications. These include source of publication (including journal reputation and impact factor), whether or not articles are cited by others, and access/download figures. When relying on citation counts, one needs to obtain access to citation databases and has to consider that results differ from one database to another. Accumulation of citations takes time and their dynamics might differ from journal to journal and topic to topic. Therefore, we wanted to evaluate the correlation between citation and download figures, hypothesising that articles with fewer downloads also accumulate fewer citations. Typically, publishers provide download figures together with the article. We extracted and analysed the 50 most viewed articles from 5 different open access oncology journals. For each of the 5 journals and also all journals combined, correlation between number of accesses and citations was limited (r = 0.01-0.30). Considerable variations were also observed when analyses were restricted to specific article types such as reviews only (r = 0.21) or case reports only (r = 0.53). Even if year of publication was taken into account, high correlation coefficients were the exception from the rule. In conclusion, downloads are not a universal surrogate for citation figures.\n\nAdded 17 June 2013 Vincent Lariviere, Cassidy R. Sugimoto, Benoit Macaluso, Stasa Milojevic, Blaise Cronin, Mike Thelwall (2013)\n\narXiv e-prints and the journal of record: An analysis of roles and relationships\n\narXiv.org > cs > arXiv:1306.3261, 13 Jun 2013\n\nAbstract: Since its creation in 1991, arXiv has become central to the diffusion of research in a number of fields. Combining data from the entirety of arXiv and the Web of Science (WoS), this paper investigates (a) the proportion of papers across all disciplines that are on arXiv and the proportion of arXiv papers that are in the WoS, (b) elapsed time between arXiv submission and journal publication, and (c) the aging characteristics and scientific impact of arXiv e-prints and their published version. It shows that the proportion of WoS papers found on arXiv varies across the specialties of physics and mathematics, and that only a few specialties make extensive use of the repository. Elapsed time between arXiv submission and journal publication has shortened but remains longer in mathematics than in physics. In physics, mathematics, as well as in astronomy and astrophysics, arXiv versions are cited more promptly and decay faster than WoS papers. The arXiv versions of papers - both published and unpublished - have lower citation rates than published papers, although there is almost no difference in the impact of the arXiv versions of both published and unpublished papers.\n\nAdded 17 June 2013 Pekka Olsbo (2013)\n\nDoes Openness and Open Access Policy Relate to the Success of Universities?\n\n17th International Conference on Electronic Publishing, Karlskrona, Sweden, June 13-14, 2013\n\nfull paper http://elpub.scix.net/data/works/att/110_elpub2013.content.01124.pdf\n\nExtended Abstract. Introduction: The cross reading and examination of the report The state of scientific research in Finland 2012 by The Finnish Academy and Ranking Web of Universities seem to show that there could be a connection between the internet visibility, ranking and the relative citation impact of universities in different countries. These relationships can be traced back to the effectiveness of the open access publishing, self-archiving and Open Access policies of the countries and the universities. This paper focuses on internet visibility of the University of Jyväskylä and eight European countries and how the openness of universities has developed during last two editions of the Ranking Web of Universities.\n\nAdded 17 June 2013 Mike Taylor (2013)\n\nThe Challenges of Measuring Social Impact Using Altmetrics\n\nResearch Trends, Issue 33, June 2013\n\nAbstract: Altmetrics gives us novel ways of detecting the use and consumption of scholarly publishing beyond formal citation, and it is tempting to treat these measurements as proxies for social impact. However, altmetrics is still too shallow and too narrow, and needs to increase its scope and reach before it can make a significant contribution to computing relative values for social impact. Furthermore, in order to go beyond limited comparisons of like-for-like and to become generally useful, computation models must take into account different socio-economic characteristics and legal frameworks. However, much of the necessary work can be borrowed from other fields, and the author concludes that with certain extensions and added sophistication altmetrics will be a valuable element in calculating social reach and impact.\n\nAdded 28 May 2013 Mark J. McCabe, Christopher M. Snyder (2013)\n\nThe Rich Get Richer and the Poor Get Poorer: The Effect of Open Access on Cites to Science Journals Across the Quality Spectrum\n\nSocial Science Research Network SSRN, May 25, 2013\n\nAbstract: An open-access journal allows free online access to its articles, obtaining revenue from fees charged to submitting authors. Using panel data on science journals, we are able to circumvent some problems plaguing previous studies of the impact of open access on citations. We find that moving from paid to open access increases cites by 8% on average in our sample, but the effect varies across the quality of content. Open access increases cites to the best content (top-ranked journals or articles in upper quintiles of citations within a volume) but reduces cites to lower-quality content. We construct a model to explain these findings in which being placed on a broad open-access platform can increase the competition among articles for readers attention. We can find structural parameters allowing the model to fit the quintile results quite closely.\n\nAdded 28 May 2013 San Francisco Declaration on Research Assessment (DORA) (2013)\n\nAmerican Society for Cell Biology (ASCB), 17 May 2013\n\nFrom DORA: There is a pressing need to improve the ways in which the output of scientific research is evaluated by funding agencies, academic institutions, and other parties. ... The Journal Impact Factor is frequently used as the primary parameter with which to compare the scientific output of individuals and institutions. The Journal Impact Factor, as calculated by Thomson Reuters, was originally created as a tool to help librarians identify journals to purchase, not as a measure of the scientific quality of research in an article. With that in mind, it is critical to understand that the Journal Impact Factor has a number of well-documented deficiencies as a tool for research assessment. These limitations include: A) citation distributions within journals are highly skewed; B) the properties of the Journal Impact Factor are field-specific: it is a composite of multiple, highly diverse article types, including primary research papers and reviews; C) Journal Impact Factors can be manipulated (or \"gamed\") by editorial policy; and D) data used to calculate the Journal Impact Factors are neither transparent nor openly available to the public. we make a number of recommendations for improving the way in which the quality of research output is evaluated. A number of themes run through these recommendations:\n\nthe need to eliminate the use of journal-based metrics, such as Journal Impact Factors, in funding, appointment, and promotion considerations;\n\nthe need to assess research on its own merits rather than on the basis of the journal in which the research is published; and\n\nthe need to capitalize on the opportunities provided by online publication (such as relaxing unnecessary limits on the number of words, figures, and references in articles, and exploring new indicators of significance and impact).\n\nSee also\n\nBruce Alberts, Editorial Impact Factor Distortions, Science, Vol. 340 no. 6134, 787, 17 May 2013 DOI: 10.1126/science.1240319\n\nKent Anderson, Impact Crater - Does DORA Need to Attack the Impact Factor to Reform How It Is Used in Academia? The Scholarly Kitchen, May 21, 2013\n\nAndrew Plume, San Francisco Declaration on Research Assessment (DORA) - Elsevier's view, Elsevier Connect, 3 June 2013; \"Elsevier is not signing DORA in its entirety, however, as its not our place to advocate for positions that are primarily aimed at other partners in the research community. Mendeley is signing DORA on its own.\"\n\nSimple and practical example\n\nCitation analysis is specialised and difficult. To make the case for, or against, a claim such as 'open access increases impact' requires a lot of the reader, who may not be a specialist but who wants to try and understand the point at issue and decide if it has any relevance to him or her. The following simple example is included for this reason, not as proof but as evidence of the effect within a particular domain. Draw your own conclusions, and then read the more detailed evidence of the bibliography if you are still interested.\n\n\"Measuring the effect for physics or astronomy is easy. This link returns the number of articles published in the Astrophysical Journal in 2003 and their number of citations.\n\n\"This next link shows the number of these papers which are available OA in the arXiv, and their citations.\n\n\"The result is that 75% of the papers are in the arXiv, and they represent 90% of the citations, a 250% OA effect.\n\n\"By replacing ApJ with the mnemonic for any other physics or astronomy journal one can repeat the measurement; for Nuclear Physics A (NuPhA) one gets that 32% of the articles are in the arXiv, and they represent 78% of the citations, a 740% OA effect.\"\n\nFrom Michael Kurtz, American Scientist Open Access Forum, 28 September 2005 http://users.ecs.soton.ac.uk/harnad/Hypermail/Amsci/4807.html\n\nNote, the database links are 'live', i.e. they return the current database figures, not the exact figures on which Michael Kurtz would have based his calculations, but the percentages quoted are unlikely to change dramatically, in the short term at least.\n\nElucidation of calculation (by Stevan Harnad, figures valid on 22 July 2007)\n\nFor ApJ:\n\nTOT: articles 2592 citations 70732\n\nArx: articles 1943 citations 62586 c/a 32.21 (rounded to 32)\n\nNon: articles 649 citations 8146 c/a 12.55 (rounded to 13)\n\nThen 32/13 = 2.5 (250%)\n\nFor NuPhA:\n\nTOT: articles 1134 citations 4451\n\nArx: articles 344 citations 3225 c/a 9.375\n\nNon: articles 790 citations 1226 c/a 1.552\n\nThen 9.375/1.553 = 6.041 (600%)\n\nMichael Kurtz comments: \"The differences in (NuPhA: 740% to 600% effect) results are because the database has changed over the past two years since I did it. There is a systematic error in the calculations for Nuclear Physics A (Elsevier does not give us the references) so the results will be higher than the true value. Physical Review C (Nuclear Physics) has an OA advantage number of 221%, the systematic in this case is small and in the other direction.\"\n\nStudies with original data\n\nHighlights\n\nLawrence (2001) was the first to publish data recognising the trend for online publication to increase impact, confirmed for open access papers by the work of the Open Citation Project based on arXiv (e.g. Harnad and Brody, D-Lib, 2004), and by Kurtz et al. (2004a, 2003a) looking at the NASA Astrophysics Data System. Commenting on Harnad and Brody (D-Lib, 2004) in Open Access News, Peter Suber said:\n\nThis is an important article. It's the first major study since the famous Lawrence paper documenting the proposition that OA increases impact. It's also the first to go beyond Lawrence in scope and method in order to answer doubts raised about his thesis. By confirming that OA increases impact, it gives authors the best of reasons to provide OA to their own work (21 June 2004)\n\nBroader collaborations have emerged to extend these findings (e.g. Brody et al. 2004).\n\nOpen access has become feasible because of the move towards online publication and dissemination. A new measure that becomes possible with online publication is the number of downloads or 'hits', opening a new line of investigation. Brody et al. have been prominent in showing there is a correlation between higher downloads and higher impact, particularly for high impact papers, holding out the promise not just for higher impact resulting from open access but for the ability to predict high impact papers much earlier, not waiting years for those citations to materialise (e.g. Brody and Harnad 2005). The effect can be verified with the Correlation Generator (below).\n\n(Note. The latest listings might include preprints, or even pre-preprints. This area of study is effectively a work in progress, and as such the list is intended to raise awareness of the most recent results, even where these may not be definitive or final versions. Check back for definitive versions.)\n\nAdded 13 May 2013 Cassidy R. Sugimoto, Mike Thelwall, Vincent Larivière, Andrew Tsou, Philippe Mongeon, Benoit Macaluso (2013)\n\nScientists Popularizing Science: Characteristics and Impact of TED Talk Presenters\n\nPLoS ONE, 8(4): e62403, April 30, 2013\n\ndoi:10.1371/journal.pone.0062403\n\nAbstract: The TED (Technology, Entertainment, Design) conference and associated website of recorded conference presentations (TED Talks) is a highly successful disseminator of science-related videos, claiming over a billion online views. Although hundreds of scientists have presented at TED, little information is available regarding the presenters, their academic credentials, and the impact of TED Talks on the general population. This article uses bibliometric and webometric techniques to gather data on the characteristics of TED presenters and videos and analyze the relationship between these characteristics and the subsequent impact of the videos. The results show that the presenters were predominately male and non-academics. Male-authored videos were more popular and more liked when viewed on YouTube. Videos by academic presenters were more commented on than videos by others and were more liked on YouTube, although there was little difference in how frequently they were viewed. The majority of academic presenters were senior faculty, males, from United States-based institutions, were visible online, and were cited more frequently than average for their field. However, giving a TED presentation appeared to have no impact on the number of citations subsequently received by an academic, suggesting that although TED popularizes research, it may not promote the work of scientists within the academic community.\n\nSee also\n\nSara Grossman, Giving a TED Talk? Expect More Visibility, but Not More Citations, Chronicle of Higher Education, June 19, 2013\n\nAdded 13 May 2013 Xianwen Wang, Wenli Mao, Shenmeng Xu, Chunbo Zhang (2013)\n\nAttention History Over Time of Scientific Literature: Metrics of Nature Publications\n\narXiv.org > cs > arXiv:1304.7653, 29 Apr 2013\n\nAbstract: In this study, we report findings about patterns of the Nature metrics page views over time. Using the page views data of papers published on Nature, we calculate from two perspectives. The first one is the time before their page views reach 50%/80% of the total, and the second one is the percentage of total page views in 7 days, 30 days, and 100 days after publication. Papers are viewed most frequently within a short time period after publication. Respectively, 62.16% and 100% of the papers on Nature are viewed more than half of their total times in the first week and month. 52.48% of the papers gain more than 80% of their total views in the following month. Meanwhile, the page views number reaches more than 52% of the total in the first week and more than 72% in the first month. In addition, we find that readers' attention on Open Access publications are more enduring. Using the usage data of a newly published paper, we conduct regression analysis to predict the future expected total usage count of the paper.\n\nAdded 13 May 2013 Teja Koler-Povh, Goran Turk and Primo Juni (2013)\n\nDoes the Open Access Business Model Have a Significant Impact on the Citation of Publications? Case Study in the Field of Civil Engineering\n\nProceedings of the Fifth Belgrade International Open Access Conference 2012, 26 April 2013\n\nDOI: 10.5937/BIOAC-68\n\nOriginal conference slide presentation, 18 May 2012 http://boac.ceon.rs/public/site/Koler-Povh_Juznic_Turk.pdf\n\nFrom the abstract: we have chosen to analyze the publications in three international journals in the field of civil engineering. All of them have an ISI impact factor in the Civil engineering subject category in the ISI/Web of science database (WOS). The articles were classified into two groups - the OA publications and the non-OA publications. We analyzed all the articles published in the same year and the number of their citations until the end of February 2012, seeking to find out if these two groups differ from each other. From the conclusion: It was found that OA significantly influenced the citation counts for the articles published in the Computers & Structures journal, which is ranked in the first quarter - according to both databases. Only the GS database showed a significant effect of OA on citations for the articles published in the Journal of Computing in Civil Engineering. Neither GS nor WOS databases indicate a significant effect of OA on the citation counts of articles in the Automation in Construction journal. These two journals are ranked in the second quarter among 88 journals in the same subject category, civil engineering. The present results indicate that more research is needed to give a final answer to the principle question of the paper: does open access have a significant impact on citations in the field of civil engineering. Some other potentially influential factors will be tested as well.\n\nAdded 13 May 2013 Vincent Larivière, George A. Lozano, Yves Gingras (2013)\n\nAre elite journals declining?\n\narXiv.org > cs > arXiv:1304.6460, 24 Apr 2013\n\nPrevious work indicates that over the past 20 years, the highest quality work have been published in an increasingly diverse and larger group of journals. In this paper we examine whether this diversification has also affected the handful of elite journals that are traditionally considered to be the best. We examine citation patterns over the past 40 years of 7 long-standing traditionally elite journals and 6 journals that have been increasing in importance over the past 20 years. To be among the top 5% or 1% cited papers, papers now need about twice as many citations as they did 40 years ago. Since the late 1980s and early 1990s elite journals have been publishing a decreasing proportion of these top cited papers. This also applies to the two journals that are typically considered as the top venues and often used as bibliometric indicators of \"excellence\", Science and Nature. On the other hand, several new and established journals are publishing an increasing proportion of most cited papers. These changes bring new challenges and opportunities for all parties. Journals can enact policies to increase or maintain their relative position in the journal hierarchy. Researchers now have the option to publish in more diverse venues knowing that their work can still reach the same audiences. Finally, evaluators and administrators need to know that although there will always be a certain prestige associated with publishing in \"elite\" journals, journal hierarchies are in constant flux so inclusion of journals into this group is not permanent.\n\nSee also\n\nHadas Shema, Elite journals: to hell in a handbasket? Scientific American blogs, May 2, 2013\n\nAdded 13 May 2013 Paola Bongiovani, Sandra Miguel, Nancy Diana Gómez\n\nAcceso abierto, impacto científico y la producción científica en dos universidades argentinas en el campo de la medicina (Open Access, scientific impact and the scientific production in two Argentine universities in the field of medicine)\n\nRevista Cubana de Información en Ciencias de la Salud, Vol 24, No 2, 2013\n\nAbstract: this paper studies the scientific production published by researchers at two argentine universities (National University of La Plata and National University of Rosario) in the discipline of medicine. Objective: to establish the volume and evolution of scientific production published in open access journals and in subscription journals that allow self-archiving in repositories. Methods: The scientific production for both institutions was determined by taking a sample from Scopus and covers the period 2006-2010. It applies a methodology based on the analysis of the access models of journals used by researchers to publish their articles established through searches performed using Romeo-Sherpa, Dulcinea, DOAJ, SciELO, RedALyC and PubMed Central. Additionally, the study explores the citation levels of articles from both institutions according to access models of journals, comparing impact indicators from average citation per article. Results: The two institutions generally show similar patterns to those found at national level, although UNR, following international trends in Medicine, has a higher percentage of articles published in open access journals. In both cases, about half of the production could be deposited in repositories, being pre-print versions and the author's post print mostly allowed by editors. Conclusions: From the perspective of the impact levels achieved, the results indicate a higher level of citation in subscription journals with self-archiving permissions, and this is encouraging for the promotion and development of institutional repositories in both universities.\n\nAdded 9 April 2013 Xin Shuai, Zhuoren Jiang, Xiaozhong Liu, Johan Bollen (2013)\n\nA Comparative Study of Academic impact and Wikipedia Ranking\n\nAuthor preprint. Joint Conference on Digital Libraries JCDL 2013, Indianapolis, IN, July 22-26, 2013, to be presented\n\nAbstract: In addition to its broad popularity Wikipedia is also widely used for scholarly purposes. Many Wikipedia pages pertain to academic papers, scholars and topics providing a rich ecology for scholarly uses. Although many recognize the scholarly potential of Wikipedia, as a crowdsourced encyclopedia its authority and quality is questioned due to the lack of rigorous peer-review and supervision. Scholarly references and mentions on Wikipedia may thus shape the societal impact of a certain scholarly communication item, but it is not clear whether they shape actual academic impact. In this paper we compare the impact of papers, scholars, and topics according to two different measures, namely scholarly citations and Wikipedia mentions. Our results show that academic and Wikipedia impact are positively correlated. Papers, authors, and topics that are mentioned on Wikipedia have higher academic impact than those are not mentioned. Our findings validate the hypothesis that Wikipedia can help assess the impact of scholarly publications and underpin relevance indicators for scholarly retrieval or recommendation systems.\n\nAdded 9 April 2013 Heather Piwowar, Todd J Vision (2013)\n\nData reuse and the open data citation advantage\n\nPeerJ PrePrints, v1, 4 Apr 2013\n\ndoi: 10.7287/peerj.preprints.1\n\nFrom the Abstract: Previous studies have found that papers with publicly available datasets receive a higher number of citations than similar studies without available data. However, few previous analyses have had the statistical power to control for the many variables known to predict citation rate, which has led to uncertain estimates of the citation boost. Furthermore, little is known about patterns in data reuse over time and across datasets. METHOD AND RESULTS: Here, we look at citation rates while controlling for many known citation predictors, and investigate the variability of data reuse. In a multivariate regression on 10,555 studies that created gene expression microarray data, we found that studies that made data available in a public repository received 9% (95% confidence interval: 5% to 13%) more citations than similar studies for which the data was not made available. Date of publication, journal impact factor, open access status, number of authors, first and last author publication history, corresponding author country, institution citation history, and study topic were included as covariates. The citation boost varied with date of dataset deposition: a citation boost was most clear for papers published in 2004 and 2005, at about 30%. ... CONCLUSION: After accounting for other factors affecting citation rate, we find a robust citation benefit from open data, although a smaller one than previously reported. We conclude there is a direct effect of third-party data reuse that persists for years beyond the time when researchers have published most of the papers reusing their own data.\n\nAdded 9 April 2013 Philip M. Davis (2013)\n\nPublic accessibility of biomedical articles from PubMed Central reduces journal readership - retrospective cohort analysis\n\nThe FASEB Journal, Federation of American Societies for Experimental Biology, April 3, 2013\n\ndoi: 10.1096/fj.13-229922\n\nAbstract: Does PubMed Centrala government-run digital archive of biomedical articlescompete with scientific society journals? A longitudinal, retrospective cohort analysis of 13,223 articles (5999 treatment, 7224 control) published in 14 society-run biomedical research journals in nutrition, experimental biology, physiology, and radiology between February 2008 and January 2011 reveals a 21.4% reduction in full-text hypertext markup language (HTML) article downloads and a 13.8% reduction in portable document format (PDF) article downloads from the journals websites when U.S. National Institutes of Health-sponsored articles (treatment) become freely available from the PubMed Central repository. In addition, the effect of PubMed Central on reducing PDF article downloads is increasing over time, growing at a rate of 1.6% per year. There was no longitudinal effect for full-text HTML downloads. While PubMed Central may be providing complementary access to readers traditionally underserved by scientific journals, the loss of article readership from the journal website may weaken the ability of the journal to build communities of interest around research papers, impede the communication of news and events to scientific society members and journal readers, and reduce the perceived value of the journal to institutional subscribers.\n\nAdded 28 March 2013 David J Solomon, Mikael Laakso, Bo-Christer Björk (2013)\n\nA longitudinal comparison of citation rates and growth among open access journals\n\nAuthor preprint, 27 March 2013. In Journal of Informetrics, accepted for publication\n\nAbstract: The study documents the growth in the number of journals and articles along with the increase in normalized citation rates of open access (OA) journals listed in the Scopus bibliographic database between 1999 and 2010. Longitudinal statistics on growth in journals/articles and citation rates are broken down by funding model, discipline, and whether the journal was launched or had converted to OA. The data were retrieved from the web sites of SCIMago Journal and Country Rank (journal /article counts), JournalM3trics (SNIP2 values), Scopus (journal discipline) and Directory of Open Access Journals (DOAJ) (OA and funding status). OA journals/articles have grown much faster than subscription journals but still make up less that 12% of the journals in Scopus. Two-year citation averages for journals funded by article processing charges (APCs) have reached the same level as subscription journals. Citation averages of OA journals funded by other means continue to lag well behind OA journals funded by APCs and subscription journals. We hypothesize this is less an issue of quality than due to the fact that such journals are commonly published in languages other than English and tend to be located outside the four major publishing countries.\n\nAdded 4 March 2013, updated 13 May 2013 Jerome Vanclay (2013)\n\nFactors affecting citation rates in Environmental Science\n\nePublications@SCU, Southern Cross University, 2013. In Journal of Informetrics, Vol 7, No 2, April 2013, 265-271 http://www.sciencedirect.com/science/article/pii/S1751157712000995\n\nhttp://dx.doi.org/10.1016/j.joi.2012.11.009\n\nAbstract: Analysis of 131 publications during 2006-07 by staff of the School of Environmental Science and Management at Southern Cross University reveals that the journal impact factor, article length and type (i.e., article or review), and journal self-citations affect the citations accrued to 2012. Authors seeking to be well cited should aim to write comprehensive and substantial review articles, and submit them to journals with a high impact factor which has previously carried articles on the topic. Nonetheless, strategic placement of articles is complementary to, and no substitute for careful crafting of good quality research. Evidence remains equivocal regarding the contribution of an authors prior publication success (h-index) and of open-access journals.\n\nAdded 4 March 2013, updated 13 May 2013 Caitlin Rivers (2013)\n\nScholarly impact of open access journals\n\n18 March 2013 (originally written on 26 January 2013)\n\nData sources for this work also available on Figshare http://figshare.com/articles/Open_access_journal_impacts/154346\n\nExtracts: I downloaded a list of open access journals from the Directory of Open Access Journals (DOAJ). I also downloaded a spreadsheet of 2011 impact data from Journal Metrics, an offshoot of Scopus that assesses journal impact. Journal Metrics provides two impact measures: Source Normalized Impact per Paper (SNIP) and SCImago Journal Rank (SGR). ... In terms of impact, open access still lags behind non-OA journals. The mean SNIP of non-OA journals in 2011 was 0.83 with a max of 41, while OA journals had a mean SNIP of .57 and a max of less than 5. The mean SJR of non-OA was .64 (max of 36), and the OA mean was .38 (max of 7.6).\n\nAdded 19 March 2013, updated 13 May 2013 Mark J. McCabe, Christopher M. Snyder (2013)\n\nDoes Online Availability Increase Citations? Theory and Evidence from a Panel of Economics and Business Journals\n\nSocial Science Research Network (SSRN), 14 March 2013, also at http://mccabe.people.si.umich.edu/McCabe_Snyder_Revised_3_2013.pdf. Submitted to Review of Economics and Statistics.\n\nRevised preprint. Abstract: Does online availability boost citations? The answer has implications for issues ranging from the value of a citation to the sustainability of open-access journals. Using panel data on citations to economics and business journals, we show that the enormous effects found in previous studies were an artifact of their failure to control for article quality, disappearing once we add fixed effects as controls. The absence of an aggregate effect masks heterogeneity across platforms: JSTOR stands apart from others, boosting citations around 10%. We examine other sources of heterogeneity including whether JSTOR increases cites from authors in developing more than developed countries and increases cites to long-tail more than superstar articles. Our theoretical analysis informs the econometric specification and allows us to translate our results for citation increases into welfare terms.\n\nAdded 4 March 2013 Richard C. Doty (2013)\n\nTenure-Track Science Faculty and the 'Open Access Citation Effect'\n\nJournal of Librarianship and Scholarly Communication, 1 (3), Mar 2013\n\ninfo:doi/10.7710/2162-3309.1052\n\nFrom the Abstract: The observation that open access (OA) articles receive more citations than subscription-based articles is known as the OA citation effect (OACE). Implicit in many OACE studies is the belief that authors are heavily invested in the number of citations their articles receive. This study seeks to determine what influence the OACE has on the decision-making process of tenure-track science faculty when they consider where to submit a manuscript for publication. METHODS Fifteen tenure-track faculty members in the Departments of Biology and Chemistry at the University of North Carolina at Chapel Hill participated in semi-structured interviews employing a variation of the critical incident tecnique. RESULTS Seven of the fifteen faculty members said they would consider making a future article freely-available based on the OACE. Due to dramatically different expectations with respect to the size of the OACE, however, only one of them is likely to seriously consider the OACE when deciding where to submit their next manuscript for publication. DISCUSSION Journal reputation and audience, and the quality of the editorial and review process are the most important factors in deciding where to submit a manuscript for publication. Once a subset of journals has satisfied these criteria, financial and access issues compete with the OACE in making a final decision.\n\nAdded 19 March 2013 Mazda Farshad, Claudia Sidler, Christian Gerber (2013)\n\nAssociation of scientific and nonscientific factors to citation rates of articles of renowned orthopedic journals\n\nEuropean Orthopaedics and Traumatology, March 2013\n\ninfo:doi/10.1007/s12570-013-0174-6\n\nFrom the Abstract: This investigation studied associations of scientific and nonscientific criteria with the citation frequency of articles in two top-ranked international orthopedic journals. Methods: The 100 most (mean, 88 citations/5 years for cases) and 100 least (mean, two citations/5 years for controls) cited articles published between 2000 and 2004 in the Journal of Bone and Joint Surgery and the Bone & Joint Journal (formerly known as JBJS (Br)), two of the most distributed general orthopedic journals, were identified. The association of scientific and nonscientific factors on their citation rate was quantified. Results: Randomized controlled trials, as well as multicenter studies with large sample sizes, were significantly more frequent in the high citation rate group. The unadjusted odds of a highly cited article to be supported by industry were 2.8 (95 % confidence interval 1.5, 5.6; p<0.05) if compared with a lowly cited article.\n\nAdded 4 March 2013 Steffen Bernius, Matthias Hanauske, Berndt Dugall, and Wolfgang Konig (2013)\n\nExploring the Effects of a Transition to Open Access: Insights from a Simulation Study\n\nGoethe University Frankfurt, Faculty of Economics and Business Administration, 2012. In Journal of the American Society for Information Science and Technology, Vol. 64, No. 4, 701-726, April 2013, online: 21 Feb 2013\n\nDOI: 10.1002/asi.22772\n\nAbstract: The Open Access (OA) movement, which postulates gratis and unrestricted online access to publicly funded research findings, has significantly gained momentum in recent years. The two ways of achieving OA are self-archiving of scientific work by the authors (Green OA) and publishing in OA journals (Gold OA). But there is still no consensus which model should be supported in particular. The aim of this simulation study is to discover mechanisms and predict developments that may lead to specific outcomes of possible market transformation scenarios. It contributes to theories related to OA by substantiating the argument of a citation advantage of OA articles and by visualizing the mechanisms of a journal system collapsing in the long-term due to the continuation of the serials crisis. The practical contribution of this research stems from the integration of all market players: Decisions regarding potential financial support of OA models can be aligned with our findings as well as the decision of a publisher to migrate his journals to Gold OA. Our results indicate that for scholarly communication in general, a transition to Green OA combined with a certain level of subscription-based publishing and a migration of few top journals is the most beneficial development.\n\nAdded 4 March 2013 Christopher Hassall (2013)\n\nGoing green: self-archiving as a means for dissemination of research output in ecology and evolution\n\nIdeas in Ecology and Evolution, 5 (2), Feb 2013\n\ninfo:doi/10.4033/iee.v5i2.4555\n\nAbstract: There is a perception that is prevalent within the academic community that access to information is being restricted by the large publishing houses that dominate academic publishing. However, self-archiving policies that are promoted by publishers provide a method by which this restriction can be relaxed. In this paper I outline the motivation behind self-archiving publications in terms of increased impact (citations and downloads of articles), increased access for the developing world, and decreased library costs. I then describe the current state of self-archiving policies in 165 ecology and evolution journals. I demonstrate that the majority (52%) of papers published in 2011 could have been self-archived in a format close to their final form. Journals with higher impacts tend to have more restrictive policies on self-archiving, and publishers vary in the extent to which they impose these restrictions. Finally, I provide a guide to academics on how to take advantage of opportunities for self-archiving using either institutional repositories or freely-available online tools.\n\nAdded 13 May 2013 Sayed-Amir Marashi, Seyed Mohammad Amin Hosseini-Nami, Khadijeh Alishah, Mahdieh Hadi, Ali Karimi, Saeedeh Hosseinian, Rouhallah RamezaniFard, Reihaneh Sadat Mirhassani, Zhaleh Hosseini, Zahra Shojaie (2013)\n\nImpact of Wikipedia on Citation Trends\n\nEXCLI Journal (Experimental and Clinical Sciences International online journal for advances in science), Vol. 12, 15-19, January 15, 2013, Supplementary Information (dataset, methodology)\n\nGuest editorial, Abstract: It has been suggested that the \"visibility\" of an article influences its citation count. More specifically, it is believed that the social media can influence article citations. Here we tested the hypothesis that inclusion of scholarly references in Wikipedia affects the citation trends. To perform this analysis, we introduced a citation \"propensity\" measure, which is inspired by the concept of amino acid propensity for protein secondary structures. We show that although citation counts generally increase during time, the citation \"propensity\" does not increase after inclusion of a reference in Wikipedia.\n\nAdded 4 December 2012 Christian Gumpenberger, Maria-Antonia Ovalle-Perandones, and Juan Gorraiz (2012)\n\nOn the impact of Gold Open Access journals\n\nu:scholar, Universität Wien, November 2012. In Scientometrics\n\ninfo:doi/10.1007/s11192-012-0902-7\n\nAbstract: Gold Open Access (=Open Access publishing) is for many the preferred route to achieve unrestricted and immediate access to research output. However, true Gold Open Access journals are still outnumbered by traditional journals. Moreover availability of Gold OA journals differs from discipline to discipline and often leaves scientists concerned about the impact of these existent titles. This study identified the current set of Gold Open Access journals featuring a Journal Impact Factor (JIF) by means of Ulrichsweb, Directory of Open Access Journals and Journal Citation Reports (JCR). The results were analyzed regarding disciplines, countries, quartiles of the JIF distribution in JCR and publishers. Furthermore the temporal impact evolution was studied for a Top 50 titles list (according to JIF) by means of Journal Impact Factor, SJR and SNIP in the time interval 20002010. The identified top Gold Open Access journals proved to be well-established and their impact is generally increasing for all the analyzed indicators. The majority of JCR-indexed OA journals can be assigned to Life Sciences and Medicine. The success-rate for JCR inclusion differs from country to country and is often inversely proportional to the number of national OA journal titles. Compiling a list of JCR-indexed OA journals is a cumbersome task that can only be achieved with non-Thomson Reuters data sources. A corresponding automated feature to produce current lists on the fly would be desirable in JCR in order to conveniently track the impact evolution of Gold OA journals.\n\nAdded 4 December 2012 Ling-Ling Wu, Mu-Hsuan Huang, and Ching-Yi Chen (2012)\n\nCitation patterns of the pre-web and web-prevalent environments: The moderating effects of domain knowledge\n\nJournal of the American Society for Information Science and Technology, 63 (11), 2182-94, November 2012\n\ninfo:doi/10.1002/asi.22710\n\nAbstract: The Internet has substantially increased the online accessibility of scholarly publications and allowed researchers to access relevant information efficiently across different journals and databases. Because of online accessibility, academic researchers tend to read more, and reading has become more superficial, such that information overload has become an important issue. Given this circumstance, how the Internet affects knowledge transfer, or, more specifically, the citation behavior of researchers, has become a recent focus of interest. This study assesses the effects of the Internet on citation patterns in terms of 4 characteristics of cited documents: topic relevance, author status, journal prestige, and age of references. This work hypothesizes that academic scholars cite more topically relevant articles, more articles written by lower status authors, articles published in less prestigious journals, and older articles with online accessibility. The current study also hypothesizes that researcher knowledge level moderates such Internet effects. We chose the IT and Group subject area and collected 241 documents published in the pre-web period (1991-1995) and 867 documents published in the web-prevalent period (2006-2010) in the Web of Science database. The references of these documents were analyzed to test the proposed hypotheses, which are significantly supported by the empirical results.\n\nAdded 4 December 2012 V. Calcagno, E. Demoinet, K. Gollner, L. Guidi, D. Ruths, C. de Mazancourt (2012)\n\nFlows of Research Manuscripts Among Scientific Journals Reveal Hidden Submission Patterns\n\nScience, 11 October 2012\n\ninfo:doi/10.1126/science.1227833\n\nAbstract: The study of science-making is a growing discipline that builds largely on online publication and citation databases, while prepublication processes remain hidden. Here, we report results from a large-scale survey of the submission process, covering 923 scientific journals from the biological sciences in years 2006-2008. Manuscript flows among journals revealed a modular submission network, with high-impact journals preferentially attracting submissions. However, about 75% of published articles were submitted first to the journal that would publish them, and high-impact journals published proportionally more articles that had been resubmitted from another journal. Submission history affected postpublication impact: Resubmissions from other journals received significantly more citations than first-intent submissions, and resubmissions between different journal communities received significantly fewer citations.\n\nSee also\n\nPhilip Ball, Rejection improves eventual impact of manuscripts, Nature News, 11 Oct 2012: Just had your paper rejected? Dont worry - that might boost its ultimate citation tally. An excavation of scientific papers' usually hidden prepublication trajectories from journal to journal has found that papers published after having first been rejected elsewhere receive significantly more citations on average than ones accepted on first submission.\n\nRuth Williams, The Benefits of Rejection, The Scientist, 11 Oct 2012: A survey of the prepublication histories of papers reveals that manuscripts that are rejected then resubmitted are cited more often.\n\nFrom Vincent Calcagno research:\n\nMore about submission flows, October 19, 2012: Mail contact to obtain the raw data file\n\nThe benefits of rejection, continued, October 23, 2012: On Figure 4A, \"One result that attracts considerable attention in our article on Submission Flows\"\n\nAdded 4 December 2012, updated 17 June 2013 Mikael Laakso and Bo-Christer Björk (2012)\n\nDelayed Open Access - an overlooked high-impact category of openly available scientific literature\n\nHARIS (Hanken Research Information System), 10 October 2012. Journal of the American Society for Information Science and Technology, published online 23 May 2013 http://onlinelibrary.wiley.com/doi/10.1002/asi.22856/abstract\n\nDOI: 10.1002/asi.22856\n\nAbstract: Delayed open access (OA) refers to scholarly articles in subscription journals made available openly on the web directly through the publisher at the expiry of a set embargo period. Though a substantial number of journals have practiced delayed OA since they started publishing e-versions, empirical studies concerning open access have often overlooked this body of literature. This study provides comprehensive quantitative measurements by identifying delayed OA journals, collecting data concerning their publication volumes, embargo lengths, and citation rates. Altogether 492 journals were identified, publishing a combined total of 111 312 articles in 2011. 77,8 % of these articles were made open access within 12 months from publication, with 85,4 % becoming available within 24 months. A journal impact factor analysis revealed that delayed OA journals have on average twice as high average citation rates compared to closed subscription journals, and three times as high as immediate OA journals. Overall the results demonstrate that delayed OA journals constitute an important segment of the openly available scholarly journal literature, both by their sheer article volume as well as by including a substantial proportion of high impact journals.\n\nAdded 4 December 2012 Philip Davis (2012)\n\nThe Effect of Public Deposit of Scientific Articles on Readership\n\nThe Physiologist, 55 (5), 161-5, October 2012\n\nNote, this link will download the whole journal issue, not just the cited paper. Abstract: A longitudinal cohort analysis of 3,499 articles published in 12 physiology journals reveals a 14% reduction in full text article downloads when they are made publicly available from the PubMed Central archive. The loss of article readership from the journal website may weaken the ability of the publisher to build communities of interest around the research article, impede the communication of news and events with society members and reduce the perceived value of the journal to institutional subscribers.\n\nSee also\n\nPhilip Davis, Is PubMed Central Complementing or Competing with Journal Publishers? Scholarly Kitchen, September 20, 2012\n\nAdded 4 December 2012 G Mahesh (2012)\n\nOpen access and impact factors\n\nCurrent Science, 103 (6), 610, 25 September 2012\n\nCorrespondence. Extract: The case-in-point is CSIR-NISCAIR journals. The institute publishes 17 primary journals and on the First International Open Access Day on 14 October 2008, NISCAIR made two of its journals open access and by mid-2009 all its journals were available in this mode. Going by the recently released Journal Citation Reports, for the first time two CSIR-NISCAIR journals have crossed IF 1, and as shown in Figure 1, almost all journals have increased their impact factors in 2011 over the previous years. It appears that the increased 2011 IFs are a result of the journals having gone open access from 2008 to 2009 onwards.\n\nAdded 4 December 2012 Filippo Radicchi (2012)\n\nIn science \"there is no bad publicity\": Papers criticized in technical comments have high scientific impact\n\narXiv.org > physics > arXiv:1209.4997, 22 September 2012\n\nFrom the abstract: Technical comments are special types of scientific publications whose aim is to correct or criticize previously published papers. Often, comments are negatively perceived by the authors of the criticized articles because believed to make the commented papers less worthy or trusty to the eyes of the scientific community. Thus, there is a tendency to think that criticized papers are predestined to have low scientific impact. We show here that such belief is not supported by empirical evidence. We consider thirteen major publication outlets in science and perform a large-scale analysis of the citation patterns of criticized publications. We find that commented papers have not only average citation rates much higher than those of non commented articles, but also unexpectedly over-populate the set of the most cited publications within a journal. Since comments are published soon after criticized papers, comments can be viewed as early indicators of the future impact of criticized papers.\n\nAdded 14 September 2012 Sara Pérez Álvarez, Felipe P. Álvarez Arrieta, and Isidro F. Aguillo (2012)\n\nEU FP7 research in Open Access Repositories\n\nDigital.CSIC, the Institutional Repository of the Spanish National Research Council (CSIC), 21 Aug 2012. In 17th International Conference on Science and Technology Indicators (STI), 5-8 September 2012, Montreal, http://sticonference.org/Proceedings/vol1/Alvarez_EU_58.pdf\n\nAbstract: Open access repositories are a reliable source of academic items that can be used for testing the capabilities of the webometric analysis. This paper deals with actions needed for extracting web indicators from bibliographic records in open access repositories, provides guidelines to support a further webometric study and presents the results of a preliminary web impact evaluation carried out over a sample of 1386 EU FP7 output papers available from the OpenAIRE database. The European Commission project OpenAIRE aims, among other objectives, to provide impact measures to assess the research performance from repositories contents and, especially, of Special Clause 39 project participants within EU FP7. Using URL citations, title mentions and copies of titles as main web impact indicators, this study suggests that a priori the implementation of the mandatory clause SC39 to encourage open access to European research may be resulted indeed in a greater and more immediate web visibility of these papers.\n\nAdded 4 December 2012 Melissa Terras (2012)\n\nThe Impact of Social Media on the Dissemination of Research: Results of an Experiment\n\nJournal of Digital Humanities, 1 (3), September 2012\n\nThree collected blog posts, revised with a new introduction for this journal presentation: The first, What Happens When You Tweet an Open-Access Paper discusses the correlation between talking about an individual paper online, and seeing its downloads increase. The second, Is Blogging and Tweeting About Research Papers Worth It? The Verdict discusses the overall effect of this process on all my papers, highlighting what I think the benefits of open access are. In the final post, When Was the Last Time You Asked How Your Published Research Was Doing? I talk about the link between publishers and open access, and how little we know about how often our research is accessed once it is published.\n\nAdded 16 August 2012, updated 17 June 2013 Xianwen Wang, Zhi Wang, and Shenmeng Xu (2012)\n\nTracing scientists' research trends realtimely\n\narXiv.org > cs > arXiv:1208.1349, 07 Aug 2012 In Scientometrics, 95 (2):717-729, 5 May 2013 doi: 10.1007/s11192-012-0884\n\nFrom the Abstract: In this research, we propose a method to trace scientists' research trends realtimely. By monitoring the downloads of scientific articles in the journal of Scientometrics for 744 hours, namely one month, we investigate the download statistics. Then we aggregate the keywords in these downloaded research papers, and analyze the trends of article downloading and keyword downloading.\n\nAdded 16 August 2012 Maged Boulos and Patricia Anderson (2012)\n\nPreliminary survey of leading general medicine journals use of Facebook and Twitter\n\nJournal of the Canadian Health Libraries Association, 33 (02), 38-47, 01 Aug 2012\n\ninfo:doi/10.5596/c2012-010\n\nFrom the Abstract: Methods: We selected the top 25 general medicine journals on the Thomson Reuters Journal Citation Report (JCR) list. We surveyed their Facebook and Twitter presences and scanned their Web sites for any Facebook and (or) Twitter features as of November 2011. Results/Discussion: 20 of 25 journals had some sort of Facebook presence, with 11 also having a Twitter presence. Total Likes across all of the Facebook pages for journals with a Facebook presence were 321,997, of which 259, 902 came from the New England Journal of Medicine (NEJM) alone. The total numbers of Twitter Followers were smaller by comparison when compiled across all surveyed journals. Likes and Followers are not the equivalents of total accesses but provide some proxy measure for impact and popularity. Those journals in our sample making best use of the open sharing nature of social media are closed-access; with the leading open access journals on the list lagging behind by comparison.\n\nSee also this similar finding: Sandra L De Groote, Promoting health sciences journal content with Web 2.0: A snapshot in time, First Monday, Vol 17, No 8, 6 August 2012: \"Traditional journals were more likely to use Web 2.0 technology than open access journals.\"\n\nAdded 16 August 2012 Bo-Christer Björk and David Solomon (2012)\n\nOpen access versus subscription journals: a comparison of scientific impact\n\nBMC Medicine, 10 (1), 17 Jul 2012\n\ninfo:doi/10.1186/1741-7015-10-73\n\nFrom the Abstract: In the past few years there has been an ongoing debate as to whether the proliferation of open access (OA) publishing would damage the peer review system and put the quality of scientific journal publishing at risk. Our aim was to inform this debate by comparing the scientific impact of OA journals with subscription journals, controlling for journal age, the country of the publisher, discipline and (for OA publishers) their business model. A total of 610 OA journals were compared with 7,609 subscription journals using Web of Science citation data while an overlapping set of 1,327 OA journals were compared with 11,124 subscription journals using Scopus data. Overall, average citation rates, both unweighted and weighted for the number of articles per journal, were about 30% higher for subscription journals. However, after controlling for discipline (medicine and health versus other), age of the journal (three time periods) and the location of the publisher (four largest publishing countries versus other countries) the differences largely disappeared in most subcategories except for journals that had been launched prior to 1996. OA journals that fund publishing with article processing charges (APCs) are on average cited more than other OA journals. In medicine and health, OA journals founded in the last 10 years are receiving about as many citations as subscription journals launched during the same period.\n\nSee also\n\nOpen access means business: Pay-to-publish approaching same impact factor as subscription journals, Science Codex, 17 Jul 2012\n\nDavid Solomon and Bo-Christer Björk, Opinion: OA Coming of Age, The Scientist, 06 Aug 2012\n\nAdded 16 August 2012 Bertil Dorch (2012)\n\nOn the Citation Advantage of linking to data\n\nhprints.org, Nordic Arts and Humanities and Social Sciences e-print repository, 05 Jul 2012\n\nAbstract: This paper present some indications of the existence of a Citation Advantage related to linked data, using astrophysics as a case. Using simple measures, I find that the Citation Advantage presently (at the least since 2009) amounts to papers with links to data receiving on the average 50% more citations per paper per year, than the papers without links to data. A similar study by other authors should a cummulative effect after several years amounting to 20%. Hence, a Data Sharing Citation Advantage seems inevitable.\n\nAdded 4 December 2012 Adam Eyre-Walker (2012)\n\nCan we assess the quality and impact of science? (video)\n\nYouTube, 02 July 2012\n\nIn International workshop on Evolution in the Time of Genomics - part 08, May 2012, Venice. Quoted extracts: \"(F1000) assessors are highly influenced by the impact factor of the journal and less by the actual intrinsic quality of the paper\" \"Without the information of what journal that paper is published in you have very little power to tell the ultimate impact of that paper\" \"People tend to over-rate the quality of science in high-impact factor journals and that is a very important influence\" \"The difference between the really high impact journals and the medium quality journals is nothing like as dramatic as we might think\" There is a brief mention of open access impact only in questions following the presentation - assumes open access journals.\n\nAdded 27 June 2012 Sharon Mathelus, Ginny Pittman, and Jill Yablonski-Crepeau (2012)\n\nPromotion of research articles to the lay press: a summary of a three-year project\n\nLearned Publishing, Vol 25, No 3, July 2012, 207-212\n\nAbstract: The promotion of scholarly journal articles to journalists and bloggers via the dissemination of press releases generates a positive impact on the number of citations that publicized journal articles receive. Research by John Wiley & Sons, Inc. shows that article-level publicity efforts and media coverage boosts downloads by an average of 1.8 times and were found to increase citations by as much as 2.0-2.2 times in the articles analyzed in this study. We evaluated scholarly journal articles published in nearly 100 Wiley journals, which were also covered in 296 press releases. The results in this case study suggest a need for greater investment in media support for scholarly journals publishing research that sparks interest to a broad news audience, as it could increase citations.\n\nAdded 27 June 2012 M. Riera and E. Aibar (2012)\n\nDoes open access publishing increase the impact of scientific articles? An empirical study in the field of intensive care medicine\n\nMedicina intensiva / Sociedad Espanola de Medicina Intensiva y Unidades Coronarias, 07 June 2012. Via NCBI PubMed.gov\n\ninfo:pmid/22683044 | info:doi/10.1016/j.medin.2012.04.002\n\nMETHODS: We evaluated a total of 161 articles (76% being non-open access articles) published in Intensive Care Medicine in the year 2008. Citation data were compared between the two groups up until April 30, 2011. Potentially confounding variables for citation counts were adjusted for in a linear multiple regression model. RESULTS: The median number (interquartile range) of citations of non-open access articles was 8 (4-12) versus 9 (6-18) in the case of open access articles (p=0.084). In the highest citation range (>8), the citation count was 13 (10-16) and 18 (13-21) (p=0.008), respectively. The mean follow-up was 37.5±3 months in both groups. In the 30-35 months after publication, the average number (mean±standard deviation) of citations per article per month of non-open access articles was 0.28±0.6 versus 0.38±0.7 in the case of open access articles (p=0.043). Independent factors for citation advantage were the Hirsch index of the first signing author (=0.207; p=0.015) and open access status (=3.618; p=0.006). CONCLUSIONS: Open access publishing and the Hirsch index of the first signing author increase the impact of scientific articles. The open access advantage is greater for the more highly cited articles, and appears in the 30-35 months after publication.\n\nAdded 27 June 2012 Judit Bar-Ilan, Stefanie Haustein, Isabella Peters, Jason Priem, Hadas Shema, Jens Terliesner (2012)\n\nBeyond citations: Scholars' visibility on the social Web\n\narXiv.org > cs > arXiv:1205.5611, 25 May 2012. In 17th International Conference on Science and Technology Indicators, Montreal, 5-8 Sept. 2012, http://sticonference.org/Proceedings/vol1/Bar-Ilan_Beyond_98.pdf\n\nAbstract: Traditionally, scholarly impact and visibility have been measured by counting publications and citations in the scholarly literature. However, increasingly scholars are also visible on the Web, establishing presences in a growing variety of social ecosystems. But how wide and established is this presence, and how do measures of social Web impact relate to their more traditional counterparts? To answer this, we sampled 57 presenters from the 2010 Leiden STI Conference, gathering publication and citations counts as well as data from the presenters' Web \"footprints.\" We found Web presence widespread and diverse: 84% of scholars had homepages, 70% were on LinkedIn, 23% had public Google Scholar profiles, and 16% were on Twitter. For sampled scholars' publications, social reference manager bookmarks were compared to Scopus and Web of Science citations; we found that Mendeley covers more than 80% of sampled articles, and that Mendeley bookmarks are significantly correlated (r=.45) to Scopus citation counts.\n\nAdded 27 June 2012 George Lozano, Vincent Lariviere, and Yves Gingras (2012)\n\nThe weakening relationship between the Impact Factor and papers' citations in the digital age\n\narXiv.org > cs > arXiv:1205.4328, 19 May 2012. In Journal of the American Society for Information Science and Technology, Vol 63, No 11, 21402145, November 2012 http://onlinelibrary.wiley.com/doi/10.1002/asi.22731/abstract\n\nFrom the Abstract: We compare the strength of the relationship between journals' Impact Factors and the actual citations received by their respective papers from 1902 to 2009. Throughout most of the 20th century, papers' citation rates were increasingly linked to their respective journals' Impact Factors. However, since 1990, the advent of the digital age, the strength of the relation between Impact Factors and paper citations has been decreasing. This decrease began sooner in physics, a field that was quicker to make the transition into the electronic domain. Furthermore, since 1990, the proportion of highly cited papers coming from highly cited journals has been decreasing, and accordingly, the proportion of highly cited papers not coming from highly cited journals has also been increasing. Should this pattern continue, it might bring an end to the use of the Impact Factor as a way to evaluate the quality of journals, papers and researchers.\n\nSee also\n\nGeorge Lozano, The demise of the Impact Factor: The strength of the relationship between citation rates and IF is down to levels last seen 40 years ago, Impact of Social Sciences, 08 June 2012: Lozano discusses the recent paper that he co-authored.\n\nRobinson Meyer, Thanks to the Web, Even Scientists Are Reading for the Articles, the Atlantic, July 9, 2012\n\nStudy reveals declining influence of high impact factor journals, Université de Montréal News, 07 Nov 2012\n\nComment on this paper:\n\nPhil Davis, Is the Relationship Between Journal Impact Factors and Article Citations Growing Weaker? Scholarly Kitchen, Nov 13, 2012: \"The paper continues a controversy between those who believe that digital publishing is narrowing the attention of scientists and those who believe it is expanding it. There are theories to support each viewpoint. .. the authors are posing an interesting question and have the data to answer it. Unfortunately, the authors seemed too eager to make strong conclusions from inappropriate and rudimentary analyses, and the authors' unwillingness to share their data for validation purposes does not give me confidence in their results.\"\n\nAdded 27 June 2012 Henk Moed (2012)\n\nDoes open access publishing increase citation or download rates?\n\nResearch Trends, No. 28, May 2012\n\nThe effect of \"Open Access\" (OA) on the visibility or impact of scientific publications is one of the most important issues in the fields of bibliometrics and information science. During the past 10 years numerous empirical studies have been published that examine this issue using various methodologies and viewpoints. Comprehensive reviews and bibliographies are given amongst others by OPCIT, Davis and Walters and Craig et al. The aim of this article is not to replicate nor update these thorough reviews. Rather, it aims to presents the two main methodologies that were applied in these OA-related studies and discusses their potentialities and limitations. The first method is based on citation analyses; the second on usage analyses.\n\nComment on this paper:\n\nStevan Harnad, Henk Moed's Overview of the OA Advantage in Citations and Downloads, GOAL - Global Open Access List, 29 May 2012: \"All the points made in Henk Moed's overview of the effect of open access (not just \"open access *publishing*!) on citations and download below are very welcome, timely and valid.\"\n\nAdded 27 June 2012 Brian Kelly and Jenny Delasalle (2012)\n\nCan LinkedIn and Academic.edu Enhance Access to Open Repositories?\n\nOpus: Online Publications Store, University of Bath, May 2012. In OR2012: 7th International Conference on Open Repositories, 9-13 July 2012, Edinburgh\n\nFrom the Abstract: we are witnessing the increasing take-up of a range of third-party services such as LinkedIn and Academia which are being used by researchers to publish information related to their professional activities, including details of their research publications. The paper provides evidence which suggests that personal use of such services can increase the number of downloads by increasing SEO (Search Engine Optimisation) rankings through inbound links from highly ranked web sites. A survey of use of such services across Russell Group universities shows the popularity of a number of social media services. In the light of existing usage of these services this paper proposes that institutional encouragement of their use by researchers may generate increased accesses to institutional research publications at little cost to the institution. This paper concludes by describing further work which is planned in order to investigate the SEO characteristics of institutional repositories.\n\nAdded 27 June 2012 Carlos Paiva, Joao da Silveira, and Bianca Ribeiro (2012)\n\nArticles with short titles describing the results are cited more often\n\nClinics, 67 (5), 509-13, May 2012. Via PubMed Central\n\ninfo:doi/10.6061/clinics/2012(05)17\n\nFrom the Abstract: OBJECTIVE: The aim of this study was to evaluate some features of article titles from open access journals and to assess the possible impact of these titles on predicting the number of article views and citations. RESULTS: Short-titled articles had higher viewing and citation rates than those with longer titles. Titles containing a question mark, containing a reference to a specific geographical region, and that used a colon or a hyphen were associated with a lower number of citations. Articles with results-describing titles were cited more often than those with methods-describing titles. After multivariate analysis, only a low number of characters and title typology remained as predictors of the number of citations.\n\nAdded 27 June 2012 Tom Rees, Katherine Ayling-Rouse, and Sheelah Smith (2012)\n\nAccesses versus citations: Why you need to measure both to assess publication impact\n\n8th Annual Meeting of ISMPP (International Society for Medical Publication Professionals), Baltimore, MD, April 23-25, 2012\n\nPoster paper. Abstract OBJECTIVE: Article accesses and citations provide 2 metrics to assess article impact. However, the relationship between the 2 is not constant or well understood. We investigated the relationship between article accesses and citations in 3 general medicine journals with different journal rankings. RESEARCH DESIGN AND METHODS: We collected the numbers of article accesses and citations from a representative selection of original research articles published in 2009 and 2010 in 3 peer-reviewed, international, online- only, open-access journals: PLoS Medicine, BMC Medicine, and the International Journal of General Medicine (IJGM) (SCImago journal ranking 1.04, 0.49, and 0.06, respectively). RESULTS: The sample included 104 articles (2 outliers were excluded). CONCLUSION: The relationship between article accesses and citations varies, with the highest ratio of citations:access for journals with the highest journal ranking. For open-access journals with a low impact factor, overall article reach may be higher than expected on the basis of citations.\n\nAdded 27 June 2012 Patrick Vandewalle (2012)\n\nCode Sharing is Associated with Research Impact in Image Processing\n\nReproducible Research Repository, EPFL, Lausanne, 23 Apr 2012. IEEE Computing in Science and Engineering, Vol 14, No 4, 42-47, July-Aug 2012\n\nhttp://dx.doi.org/10.1109/MCSE.2012.63\n\nAbstract: In computational sciences such as image processing, the publication itself is often not enough to allow other researchers to verify the results by repeating the described experiments. In many cases, supplementary material such as source code and measurement data are required, or can at least be very helpful. Still, only approximately 10% of recently published papers in image processing have code available online. One of the arguments for not making code available is the extra time required to prepare the material. In this paper, we claim that this additional time may be well spent, as the availability of code for a publication is associated with an increase in the expected number of citations. We show this with exploratory analyses of the relationship between code availability and the number of citations for image processing papers.\n\nNote on open access citation impact on results (p4): As can be seen in the open access citation studies (such as the one by Lawrence), papers for which an online version is freely available have an increased number of citations. I did not take this into account in my analyses by adding the open access availability as another variable. Articles that have code available generally also have an online version of the article. The citation effect seen above is therefore the combined effect of the open access availability of the paper and the availability of code.\n\nAdded 23 April 2012 Henk Moed (2012)\n\nThe Effect of Open Access upon Citation Impact\n\nEditors' Update, Elsevier.com, 22 Mar 2012\n\nDoes Open Access publishing increase citation rates? From a methodological point of view, the debate focuses on biases, control groups, sampling, and the degree to which conclusions from case studies can be generalized. This note does not give a complete overview of studies that were published during the past decade but highlights key events. An extended version of this paper will be published\n\nComment on this paper:\n\nStevan Harnad, Tireless Ad Hoc Critiques of OA Study After OA Study: Will Wishful Thinking Ever Cease? Open Access Archivangelism, 22 Mar 2012: No study based on sampling and statistical significance-testing has the force of an unassailable mathematical proof. But how many studies showing that OA articles are downloaded and cited more have to be published before the ad hoc critiques (many funded and promoted by an industry not altogether disinterested in the outcome!) and the special pleading tire of the chase?\n\nRe: Tireless Ad Hoc Critiques of OA Study After OA Study, Global Open Access List, 23 Mar 2012: Various contributions to a mail list thread following Stevan Harnad's post in response to Henk Moed's article.\n\nAdded 23 April 2012 Jason Priem, Heather Piwowar, and Bradley Hemminger (2012)\n\nAltmetrics in the wild: Using social media to explore scholarly impact\n\narXiv.org > cs > arXiv:1203.4745, 20 Mar 2012\n\nFrom the Abstract: In growing numbers, scholars are integrating social media tools like blogs, Twitter, and Mendeley into their professional communications. The online, public nature of these tools exposes and reifies scholarly processes once hidden and ephemeral. Metrics based on this activities could inform broader, faster measures of impact, complementing traditional citation metrics. This study explores the properties of these social media-based metrics or \"altmetrics\", sampling 24,331 articles published by the Public Library of Science.\n\nSee also\n\nHeather Piwowar, Altmetrics shows that citations can't stand up to the full 31 flavours of research impact, Impact of Social Sciences, 04 Apr 2012\n\nAdded 23 April 2012 Xin Shuai, Alberto Pepe, and Johan Bollen (2012)\n\nHow the Scientific Community Reacts to Newly Submitted Preprints: Article Downloads, Twitter Mentions, and Citations\n\narXiv.org > cs > arXiv:1202.2461, 11 Feb 2012. PLoS ONE, 7(11): e47523, November 1, 2012 http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0047523\n\ndoi:10.1371/journal.pone.0047523\n\nAbstract: We analyze the online response of the scientific community to the preprint publication of scholarly articles. We employ a cohort of 4,606 scientific articles submitted to the preprint database arXiv.org between October 2010 and April 2011. We study three forms of reactions to these preprints: how they are downloaded on the arXiv.org site, how they are mentioned on the social media site Twitter, and how they are cited in the scholarly record. We perform two analyses. First, we analyze the delay and time span of article downloads and Twitter mentions following submission, to understand the temporal configuration of these reactions and whether significant differences exist between them. Second, we run correlation tests to investigate the relationship between Twitter mentions and both article downloads and article citations. We find that Twitter mentions follow rapidly after article submission and that they are correlated with later article downloads and later article citations, indicating that social media may be an important factor in determining the scientific impact of an article.\n\nComment on this paper:\n\nReview: How the Scientific Community Reacts to Newly Submitted Preprints, Astronomy Journal Club, February 19, 2012. \"The 22nd meeting of the astronomy twitter journal club focused on an intriguing question: Does tweeting really help get a paper more citations? The discussion was loosely based on a recent paper, How the Scientific Community Reacts to Newly Submitted Preprints: Article Downloads, Twitter Mentions, and Citations by Shuai et al.\"\n\nAdded 12 February 2012 Heekyung Kim (2012)\n\nThe Effect of Free Access on the Diffusion of Scholarly Ideas\n\nMIS Speaker's Series, University of Arizona, 24 January 2012\n\nFrom the Abstract: By using a dataset from the Social Science Research Network (SSRN), an open repository of research articles, and employing a natural experiment that allows the estimation of the value of free access separate from confounding factors such as early viewership and quality differential, this study identifies the causal effect of free access on the citation counts. The natural experiment in this study is that a select group of published articles is posted on SSRN at a time chosen by their authors' affiliated organizations or SSRN, not by their authors. Using a difference-in-difference method and comparing the citation profiles of the articles before and after the posting time on SSRN against a group of control articles with similar characteristics, I estimated the effect of the SSRN posting on citation counts. The articles posted on SSRN receive more citations even prior to being posted on SSRN, suggesting that they are of higher quality. Their citation counts further increase after being posted, gaining an additional 10-20% of citations. This gain is likely to be caused by the free access that SSRN provides.\n\nAdded 12 February 2012 Jingfeng Xia and Ying Liu (2012)\n\nUsage Patterns of Open Genomic Data\n\nCollege & Research Libraries, 09 January 2012\n\nPre-print. Abstract: This paper uses Genome Expression Omnibus (GEO), a data repository in biomedical sciences, to examine the usage patterns of open data repositories. It attempts to identify the degree of recognition of data reuse value and understand how e-science has impacted a large-scale scholarship. By analyzing a list of 1,211 publications that cite GEO data to support their independent studies, it discovers that free data can support a wealth of high quality investigations, that the rate of open data use keeps growing over the years, and that scholars in different countries show different rates of complying with data sharing policies.\n\nAdded 12 February 2012 Jingfeng Xia and Katie Nakanishi (2012)\n\nSelf-Selection and the Citation Advantage of Open Access Articles\n\nOnline Information Review, 36 (1), 2012\n\n(Subscription access required.) From the Abstract: This research examines the relationship between the open access availability of journal papers in anthropology and their citation conditions. We apply a statistical logistic regression model to explore this relationship, and compare two groups of papers those published in high-ranked journals and those in low-ranked journals, based on journal impact factor to examine the likelihood that open access status is correlated to scholarly impact. The results reveal that open access papers in general receive more citations. Moreover this research finds that 1) papers in high-ranked journals do not have a higher open access rate, and 2) papers in lower-ranked journals have a greater rate of citations if they are freely accessible. The findings are contrary to the existing theory that the higher citation rate of open access papers is caused by authors posting their best papers online.\n\nAdded 12 February 2012 Patricia Shields, Nandhini Rangarajan, and Lewis Stewart (2012)\n\nOpen Access Digital Repository: Sharing Student Research with the World\n\nJournal of Public Affairs Education, 18 (1), 157-81, 2012\n\nNote, this link will download the pdf of the full Winter 2012 journal issue - go to page 157. From the Abstract: We study the impact of content factors and search engine optimization factors on download rates of capstone papers. We examined all 290 MPA capstone papers at Texas State University which have been made available through an online digital repository for public consumption. Results show strong support for the impact of search engine factors on download rates. The implications of high download rates of MPA capstone papers on public administration research, practice, and education are discussed in this paper.\n\nAdded 12 February 2012 Gunther Eysenbach (2011)\n\nCan Tweets Predict Citations? Metrics of Social Impact Based on Twitter and Correlation with Traditional Metrics of Scientific Impact\n\nJournal of Medical Internet Research, 13 (4), 16 December 2011\n\ninfo:doi/10.2196/jmir.2012\n\nFrom the Abstract: Between July 2008 and November 2011, all tweets containing links to articles in the Journal of Medical Internet Research (JMIR) were mined. A total of 4208 tweets cited 286 distinct JMIR articles. Highly tweeted articles were 11 times more likely to be highly cited than less-tweeted articles (9/12 or 75% of highly tweeted article were highly cited, while only 3/43 or 7% of less-tweeted articles were highly cited; rate ratio 0.75/0.07 = 10.75, 95% confidence interval, 3.433.6). Top-cited articles can be predicted from top-tweeted articles with 93% specificity and 75% sensitivity. Conclusions: Tweets can predict highly cited articles within the first 3 days of article publication. Social media activity either increases citations or reflects the underlying qualities of the article that also predict citations, but the true use of these metrics is to measure the distinct concept of social impact. Social impact measures based on tweets are proposed to complement traditional citation metrics. The proposed twimpact factor may be a useful and timely metric to measure uptake of research findings and to filter research findings resonating with the public in real time.\n\nSee also\n\nGunther Eysenbach, Correction: Can Tweets Predict Citations? Metrics of Social Impact Based on Twitter and Correlation with Traditional Metrics of Scientific Impact, Journal of Medical Internet Research, 14 (1), 04 January 2012\n\ninfo:doi/10.2196/jmir.2041\n\nA minor error in the references section in the originally published version of the editorial by Eysenbach (J Med Internet Res 2011;13[4]:e123) on the relationship between citations and tweetations has been corrected; in addition, references being part of the dataset are no longer cited as references. The now corrected problem with the references was a formatting/presentation problem only and had no impact on the study findings.\n\nHaydn Shaughnessy, How Could Twitter Influence Science (And Why Scientists Are on Board), Forbes, 15 Jan 2012\n\nAdded 12 February 2012 Hyeon-Eui Kim, Xiaoqian Jiang, Jihoon Kim, Lucila Ohno-Machado (2011)\n\nTrends in biomedical informatics: most cited topics from recent years\n\nJournal of the American Medical Informatics Association, 18 (Suppl 1), 01 December 2011\n\ninfo:pmid/22180873 | info:doi/10.1136/amiajnl-2011-000706\n\nAbstract: Biomedical informatics is a young, highly interdisciplinary field that is evolving quickly. It is important to know which published topics in generalist biomedical informatics journals elicit the most interest from the scientific community, and whether this interest changes over time, so that journals can better serve their readers. It is also important to understand whether free access to biomedical informatics articles impacts their citation rates in a significant way, so authors can make informed decisions about unlock fees, and journal owners and publishers understand the implications of open access. The topics and JAMIA articles from years 2009 and 2010 that have been most cited according to the Web of Science are described. To better understand the effects of free access in article dissemination, the number of citations per month after publication for articles published in 2009 versus 2010 was compared, since there was a significant change in free access to JAMIA articles between those years. Results suggest that there is a positive association between free access and citation rate for JAMIA articles.\n\nAdded 12 February 2012; updated 4 March 2013 Sears, J. R. (2011)\n\nData Sharing Effect on Article Citation Rate in Paleoceanography\n\nAmerican Geophysical Union, Fall Meeting 2011\n\nAbstract: The validation of scientific results requires reproducible methods and data. Often, however, data sets supporting research articles are not openly accessible and interlinked. This analysis tests whether open sharing and linking of supporting data through the PANGAEA data library measurably increases the citation rate of articles published between 1993 and 2010 in the journal Paleoceanography as reported in the Thomson Reuters Web of Science database. The 12.85% (171) of articles with publicly available supporting data sets received 19.94% (8,056) of the aggregate citations (40,409). Publicly available data were thus significantly (p=0.007, 95% confidence interval) associated with about 35% more citations per article than the average of all articles sampled over the 18-year study period (1,331), and the increase is fairly consistent over time (14 of 18 years). This relationship between openly available, curated data and increased citation rate may incentivize researchers to share their data.\n\nSee also\n\nMichael Diepenbroek, Data Sharing Effect on Article Citation Rate in Paleoceanography, KomFor blog, November 27, 2011. Includes data plot.\n\nAdded 25 November 2011 Henneken, E. and Accomazzi, A. (2011)\n\nLinking to Data - Effect on Citation Rates in Astronomy\n\narXiv.org > cs > arXiv:1111.3618, 15 Nov 2011. In Proceedings of ADASS XXI (Astronomical Data Analysis Software & Systems), Paris, 6-10 November 2011\n\nFrom the Abstract: Is there a difference in citation rates between articles that were published with links to data and articles that were not? In this presentation we will show this is indeed the case: articles with links to data result in higher citation rates than articles without such links.\n\nSee also\n\nAdded 06 July 2011 Linking to Data - Effect on Citation Rates in Astronomy\n\nMeters, Metrics and More, 03 Jun 2011\n\nExtracts: Using the data holdings of the SAO/NASA Astrophysics Data System, our analysis shows that articles with data links are indeed cited more than articles without these links - for this data set, articles with data links acquired 20% more citations (compared to articles without these links).\n\nAdded 25 November 2011 Xia, J., Wilhoite, S. K. and Myers, R. L. (2011)\n\nA librarian-LIS faculty divide in open access practice\n\nJournal of Documentation, 67 (5), 791-805 (2011)\n\ninfo:doi/10.1108/00220411111164673\n\n(Subscription access required) From the Abstract: This paper measures the OA availabilities and citations of scholarly articles from 20 top-ranked LIS journals published in 2006.\n\nAdded 25 November 2011 Henneberger, S. (2011)\n\nEntwicklung einer Analysemethode für Institutional Repositories unter Verwendung von Nutzungsdaten (Development of an analytical method for Institutional Repositories using usage data)\n\nThesis, edoc-Server der Humboldt-Universität zu Berlin, 31 Oct 2011\n\nFrom the English abstract: Download data are the subject of scientific investigations, in which the concept of the Citation Impact is applied to the rate of use of a publication and the so-called Download Impact is formed. Analyzed with nonparametric methods, download data give information about the visibility of electronic publications on the Internet. These methods form the core of NoRA (Non-parametric Repository Analysis). The analytical method NoRA was successfully applied to data from Institutional Repositories of four universities. In each case, groups of publications were identified that differed significantly in their usage. Similarities in the results reveal factors that influence the usage data, which have not been taken into account previously. The presented results imply further applications of NoRA but also raise doubts about the value of download data of single publications.\n\nAdded 25 November 2011 Tarrant, D. (2011)\n\nA Study of Early Indication Citation Metrics\n\nPhD thesis, ECS EPrints Repository, University of Southampton, 24 Oct 2011\n\nFrom the Abstract: Each new citation establishes a large number of co-citation relationships between that publication and older material whose citation impact is already well established. By taking advantage of this co-citation property, this thesis investigates the possibility of developing a metric that can provide an earlier indicator of a publications citation impact. This thesis proposes a new family of co-citation based impact measures, describes a system to evaluate their effectiveness against a large citation database, and justifies the results of this evaluation against an analysis of a diverse range of research metrics.\n\nAdded 25 November 2011 Yuan, S. and Hua, W. (2011)\n\nScholarly impact measurements of LIS open access journals: based on citations and links\n\nThe Electronic Library, 29 (5), 682, 2011\n\n(Subscription access required) From the Abstract: The study selected 97 LIS OA journals as a sample and measured their scholarly impact on the basis of citations and links. The citation counts in WoS, coverage in LISA, Web links, WIFs and Page Rank of the journals are retrieved and calculated, and correlations between citation counts, links, pages, WIFs, and Page Rank are also analyzed. The results indicate that LIS OA journals have become a significant component of the scholarly communication system.\n\nAdded 25 November 2011 Priem, J., Piwowar, H. and Hemminger, B. (2011)\n\nAltmetrics in the wild: An exploratory study of impact metrics based on social media\n\nPoster at Metrics 2011: Symposium on Informetric and Scientometric Research, New Orleans, LA, 12 October\n\nExtracts: As growing numbers of scholars publicly read, bookmark, share, discuss, and rate using online tools, these invisible impacts are beginning to be seen. Because measurements of these new traces may inform alternatives to traditional citation metrics, they been dubbed altmetrics. The goal of this study is to better understand the potential of altmetrics. We gathered altmetrics for a large sample of scholarly articles all 24,334 articles published by the Public Library of Science (PLoS) before December 23, 2010.\n\nAdded 25 November 2011 Wang, M.-L. (2011)\n\nThe impact of open access journals on library and information scientists' research in Taiwan\n\nUniversiti Teknologi Mara Digital Repository, 07 Oct 2011. In Asia-Pacific Conference On Library & Information Education & Practice 2011 (A-LIEP2011), 22-24 June 2011, Malaysia\n\nFrom the Abstract: the objectives of the study is to explore the scholarly productivity of LIS scholars in Taiwan, to find out what articles they publish and OA articles as a percentage of all titles, and to calculate the mean citation rate of open access articles and articles not freely available online. To determine whether a difference in research impact existed, two research impact indicators were used, that is, open access articles as a percentage of all published titles and mean citation rate of open access articles and those not freely available online. Data on published articles with citation counts by the LIS scholars in Taiwan from 2000 to 2009 was collected from the ACI Database and Social Science Citation Index Database. The study shows that for 72 LIS scholars who were subjects of the investigation, 64 of them had published 745 articles within the previous ten years: 679 articles in Chinese and 66 articles in English; 499 of these were OA articles, and 264 were non-OA articles; OA articles constituted 66.98% of the total number of academic articles. The mean citation rate of OA versus non-OA article citation was 1.29.\n\nAdded 25 November 2011 Chuanfu Chen, Yuan Yu, Qiong Tang, Kuei Chiu, Yan Rao, Xuan Huang and Kai Sun (2011)\n\nAssessing the authority of free online scholarly information\n\nScientometrics, 02 Oct 2011\n\n(Subscription access required. Online preview.) From the Abstract: Using a modified version of Jim Kapouns Five criteria for evaluating web pages as framework, this research selected 32 keywords from eight disciplines, inputted them into three search engines (Google, Yahoo and AltaVista) and used Analytic Hierarchy Process to determine the weights. The first batches of results (web pages) from keyword searching were selected as evaluation samples (in the two search phases, the first 50 and 10 results were chosen, respectively), and a total of 3,134 samples were evaluated for authority based on the evaluation framework. The results show that the average authority value for free online scholarly information is about 3.63 (out of five), which is in the fair level (3 Z < 4) (Z is the value assigned to each sample). About 41% of all samples collected provide more authoritative scholarly information. Different domain names, resource types, and disciplines of free online scholarly information perform differently when scored in terms of authority. In conclusion, the authority of free online scholarly information has been unsatisfactory, and needs to be improved.\n\nAdded 25 November 2011 Davis, P. (2011)\n\nDo discounted journal access programs help researchers in sub-Saharan Africa? A bibliometric analysis\n\neCommons@Cornell, 23 Sep 2011. In Learned Publishing, Vol. 24, No. 4, October 2011, pp. 287-298\n\nAbstract: Prior research has suggested that providing free and discounted access to the scientific literature to researchers in low-income countries increases article production and citation. Using traditional bibliometric indicators for institutions in sub-Saharan Africa, we analyze whether institutional access to TEEAL (a digital collection of journal articles in agriculture and allied subjects) increases: 1) article production; 2) reference length; and 3) number of citations to journals included in the TEEAL collection. Our analysis is based on nearly 20,000 articlescontaining half a million referencespublished between 1988 and 2009 at 70 institutions in 11 Afr"
    }
}