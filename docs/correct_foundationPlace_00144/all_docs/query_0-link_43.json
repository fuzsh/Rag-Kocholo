{
    "id": "correct_foundationPlace_00144_0",
    "rank": 43,
    "data": {
        "url": "https://hyd23.rssing.com/chan-12487997/all_p62.html",
        "read_more_link": "",
        "language": "en",
        "title": "Intel Developer Zone Articles",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://pixel.quantserve.com/pixel/p-KygWsHah2_7Qa.gif",
            "https://lh5.googleusercontent.com/efHKMB1tzyScwb6f2FCJUawRDW05QUAg2-GV5cWubIfl8FIMF3JGnkUQTd7HNDIT4q5ZRTgMNQt50wU10JkpU8QK-9F6SzCV0d4WtvylXvvPYpA4Yg5pLeR7VNABNXTbebyWduM",
            "https://software.intel.com/sites/default/files/managed/9b/95/fig1.png",
            "https://software.intel.com/sites/default/files/managed/e2/d2/fig2.png",
            "https://software.intel.com/sites/default/files/managed/a6/9a/fig3.png",
            "https://software.intel.com/sites/default/files/managed/f4/c8/fig4.png",
            "https://software.intel.com/sites/default/files/managed/8e/05/fig5.png",
            "https://software.intel.com/sites/default/files/managed/72/47/fig6.png",
            "https://software.intel.com/sites/default/files/managed/a9/5f/fig7.png",
            "https://software.intel.com/sites/default/files/managed/6c/6d/fig8.png",
            "https://software.intel.com/sites/default/files/managed/b1/c8/fig9.png",
            "https://software.intel.com/sites/default/files/managed/ff/a4/fig10.png",
            "https://software.intel.com/sites/default/files/managed/41/63/fig1%20compile%20patterns.png",
            "https://software.intel.com/sites/default/files/managed/f2/97/fig2%20includes%20dir.png",
            "https://software.intel.com/sites/default/files/managed/0d/a5/fig3%20copying%20wolfssl%20libraries.png",
            "https://software.intel.com/sites/default/files/managed/68/11/fig1.png",
            "https://software.intel.com/sites/default/files/managed/07/8d/fig2.png",
            "https://software.intel.com/sites/default/files/managed/cd/ba/fig3.png",
            "https://software.intel.com/sites/default/files/managed/16/a8/fig4.png",
            "https://software.intel.com/sites/default/files/managed/a3/ab/fig5.png",
            "https://software.intel.com/sites/default/files/managed/91/e1/Figure-1-KNL_Package_Overview.JPG",
            "https://software.intel.com/sites/default/files/managed/a8/ce/Figure-2-KNL_Tile.jpg",
            "https://software.intel.com/sites/default/files/managed/c2/32/Figure-3-Bandwidth_Profile_0.JPG",
            "https://software.intel.com/sites/default/files/managed/1f/bc/Figure-4-L3_Miss_Profile_0.JPG",
            "https://software.intel.com/sites/default/files/managed/ea/0d/Figure-5-AnalyzeL3_Miss_0.JPG",
            "https://software.intel.com/sites/default/files/managed/20/d9/Figure-6-Top_Contributor_L3_Miss_0.JPG",
            "https://software.intel.com/sites/default/files/managed/a6/43/Figure-7-Source_suggestion_BW_Critical_0.JPG",
            "https://software.intel.com/sites/default/files/managed/fd/b6/Figure-8-NUMA_Simulationl_0.JPG",
            "https://software.intel.com//sites/default/files/managed/12/92/CTC-Cambridge_logo_125.png",
            "https://software.intel.com//sites/default/files/managed/74/48/human-like-senses-on-devices-with-intel-realsense.jpg",
            "https://software.intel.com//sites/default/files/managed/74/48/natural-interaction-with-intuitive-computer-control-fig1.jpg",
            "https://software.intel.com//sites/default/files/managed/74/48/natural-interaction-with-intuitive-computer-control-fig2.jpg",
            "https://software.intel.com//sites/default/files/managed/74/48/natural-interaction-with-intuitive-computer-control-fig3.jpg",
            "https://software.intel.com/sites/default/files/managed/2e/74/test-scene-raycasting-demo-650.png",
            "https://software.intel.com//sites/default/files/managed/b3/15/fig-01-make-sure-you-connect.png",
            "https://software.intel.com//sites/default/files/managed/b3/15/fig-02-next-select-system-view.png",
            "https://software.intel.com//sites/default/files/managed/b3/15/fig-03-system-analyzer-tool.png",
            "https://software.intel.com//sites/default/files/managed/c2/2d/University-of-Chicago.png",
            "https://software.intel.com//sites/default/files/managed/0b/53/Mark-F-Adams.jpg",
            "https://software.intel.com//sites/default/files/managed/c0/fb/Matthew-G-Knepley.jpg",
            "https://software.intel.com//sites/default/files/managed/6f/36/Jed-Brown.jpg",
            "https://software.intel.com/sites/default/files/managed/7b/2f/WebAppLogin.png",
            "https://software.intel.com//file/453234/download",
            "https://software.intel.com//file/453235/download",
            "https://software.intel.com//file/453236/download",
            "https://software.intel.com//file/453238/download",
            "https://software.intel.com//sites/all/themes/isn3/css/images/attachment_icon.png",
            "https://software.intel.com/sites/default/files/managed/2e/74/test-scene-raycasting-demo-650.png",
            "https://software.intel.com//sites/default/files/managed/3a/b3/hardware-software-configuration.jpg",
            "https://software.intel.com//sites/default/files/managed/b4/38/performance-gains.png",
            "https://software.intel.com//sites/default/files/managed/3f/38/accelerating-ssl-load-balancers-with-intel-xeon-v3-processors-fig1.png",
            "https://software.intel.com//sites/default/files/managed/38/b3/OpenSSL.jpg",
            "https://software.intel.com//sites/default/files/managed/04/8d/maximum-transfer-rates.png",
            "https://software.intel.com//sites/default/files/managed/d8/61/max-cpu-utilization.png",
            "https://software.intel.com//sites/default/files/managed/71/6f/mtricks-looting-crown.jpg",
            "https://software.intel.com//sites/default/files/managed/c2/2d/compare-cpu-and-gpu.png",
            "https://software.intel.com//sites/default/files/managed/9c/de/mtricks-vsync.jpg",
            "https://software.intel.com//sites/default/files/managed/84/f1/modify-frequency.png",
            "https://software.intel.com//sites/default/files/managed/b9/78/04-intel-gpa-frame-analyzer.png",
            "https://software.intel.com//sites/default/files/managed/16/0e/05-the-terrain.png",
            "https://software.intel.com//sites/default/files/managed/e8/db/06-grass-texture.png",
            "https://software.intel.com//sites/default/files/managed/6d/45/07-changed-terrain.png",
            "https://software.intel.com//sites/default/files/managed/de/dd/08-cpu-and-gpu-load.png",
            "https://software.intel.com//sites/default/files/managed/21/1d/09-character-reduced.png",
            "https://software.intel.com//sites/default/files/managed/43/82/10-decoupled-animation.jpg",
            "https://software.intel.com//sites/default/files/managed/87/b8/11-ocean-drawing.png",
            "https://software.intel.com//sites/default/files/managed/c7/c9/12-grass-drawing.png",
            "https://software.intel.com//sites/default/files/managed/97/b3/13-ocean-drawing-two.png",
            "https://software.intel.com//sites/default/files/managed/ae/14/14-mtricks-looting-crown.jpg",
            "https://software.intel.com//sites/default/files/managed/12/2a/15-fps-increase.png",
            "https://software.intel.com//sites/all/themes/isn3/css/images/attachment_icon.png",
            "https://software.intel.com//sites/all/themes/isn3/css/images/attachment_icon.png",
            "https://software.intel.com//sites/default/files/managed/fe/19/flashcard-speech-recognition-app-using-intel-realsense-sdk-fig1.png",
            "https://software.intel.com//sites/default/files/managed/fe/19/flashcard-speech-recognition-app-using-intel-realsense-sdk-fig2.png",
            "https://www.trueshayari.in/wp-content/uploads/2018/12/Mahadev-Status-in-Hindi.jpg",
            "https://www.greytrix.com/blogs/sagex3/wp-content/uploads/2020/08/Criteria-in-stock-screen.png",
            "https://1.bp.blogspot.com/-_msqplafums/WoFP6BwVd6I/AAAAAAAAJiE/juU5uOC6Bb04hWSl3jpnZ5hFowZxDCZAwCLcBGAs/s1600/email2.PNG",
            "https://i.imgur.com/mOQICGl.jpg",
            "https://static2.businessinsider.com/image/4eaad6e46bb3f7506c00000f/the-wachowskis.jpg",
            "https://3.bp.blogspot.com/-t9tmD26L-0w/WOGSliUCVmI/AAAAAAAACbA/n5WrxmJekUEcYLBcetmU3gjWAlxBKz_rQCLcB/s320/page%2B1.jpg",
            "https://www.thesun.co.uk/wp-content/uploads/2024/07/jack-grealish-shares-uefa-super-839674000_761ccd.jpg?strip=all&w=960",
            "https://busyteacher.org/uploads/posts/2011-04/thumbs/1303484475_tw.jpg",
            "https://3.bp.blogspot.com/-tMQtu4f6dsc/Urb0sD55GxI/AAAAAAAA9gU/FL-p5wroTYw/s1600/INPUT.bmp.jpg",
            "https://augustacrime.com/wp-content/uploads/2017/01/Bryan-Sampay-43-of-Grovetown-DUI-200x300.jpg",
            "https://chrisukorg.files.wordpress.com/2015/02/perry.jpg?w=529&h=511",
            "https://3.bp.blogspot.com/-HBHyCcGBgf8/Wn1yke7zLmI/AAAAAAAAEhI/K7xGK0DnW94EUDg4PXG7m9d5uDemlygEgCLcBGAs/s400/class12-bilogy-ncert-solutions-in-hindi-ch3-2.png",
            "https://s3.amazonaws.com/nixle/uploads/pub_media/md/user24872-1464275450-media1_a5a7a6_240_180_PrsMe_.jpeg",
            "https://i.pinimg.com/originals/e6/33/6d/e6336d1dad962eae5f8162806efe68ce.png",
            "https://i2.wp.com/www.twincities.com/wp-content/uploads/2019/06/Cha-e1560483258563.jpg?fit=620%2C9999px&ssl=1",
            "https://i.imgur.com/IulQREl.png",
            "https://www.digitalkhabar.in/wp-content/uploads/मतलबी-दोस्त-स्टेट्स.jpg",
            "https://4.bp.blogspot.com/-D2ybkIpqREU/Wti4IoCYwLI/AAAAAAAABEg/UTVmhPWy1QcrZg6t-w8mJpp49Ho6MfwfQCLcBGAs/s640/Anasuya%2B3.png",
            "https://www.workloadautomation-community.com/uploads/1/0/2/7/102707030/published/bhoodev.jpg?1560455651",
            "https://www.the-sun.com/wp-content/uploads/sites/6/2024/07/NINTCHDBPICT000917543334.jpg?strip=all&w=960",
            "https://www.thesun.co.uk/wp-content/uploads/2024/07/1ee020d6-6281-4105-9f2e-d5f1c327aa77.jpg?strip=all&w=600",
            "https://www.cnx-software.com/wp-content/uploads/2024/07/Radxa-X4-specifications-1200x668.webp",
            "https://www.wric.com/wp-content/uploads/sites/74/2024/07/mariehorton2.jpg",
            "https://www.thesun.co.uk/wp-content/uploads/2024/07/closeup-housefly-reflection-glass-window-476211353.jpg?strip=all&w=960",
            "https://www.thescottishsun.co.uk/wp-content/uploads/sites/2/2024/07/WhatsApp-Image-2024-07-20-at-15.32.33-1.jpeg?strip=all&w=720",
            "https://cdn.singpromos.com/wp-content/uploads/2016/07/Istana-2-Jul-2016-550x336.jpg",
            "https://is1-ssl.mzstatic.com/image/thumb/Music126/v4/a6/c2/38/a6c2384e-401f-ddf4-8a9b-8e256f435655/196922815096_Cover.jpg/296x296bb.webp",
            "https://audioz.download/uploads/posts/2024-07/thumbs/1721477430_1727426616.webp",
            "https://www.sweepstakesbible.com/img/sweepstakes/21/coca-cola-free-gas-and-groceries-giveaway.jpg",
            "https://footwearnews.com/wp-content/uploads/2024/07/kobe-6-wnba.png?w=1024"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "//www.rssing.com/favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Introduction\n\nNew Intel processors introduce enhanced instruction set extensions to improve performance or strengthen security of an application. Instruction set extensions like Intel AVX1 and AVX21 are used to improve performance and Intel SHA2 instructions are used for SHA acceleration to increase security of an application.\n\nWhat happens if developers want to create applications using these new instructions while their current hardware does not support these instructions? How does a company justify buying new systems supporting the new instructions while ensuring their applications can take advantage of these new instructions to improve performance?\n\nThe Intel® Software Development Emulator is used to execute applications containing new instructions on systems that don’t support them.\n\nThis article will discuss the benefit of using SDE to test code using new instructions.\n\nWhat is the Intel Software Development Emulator (SDE)?\n\nAs its name implies, SDE is an emulator that allows code with new instruction sets to run on systems that don’t support these instructions. More information about SDE can be found at [3]. It should be noted that the SDE is useful to assess functionality, but not performance, as it runs programs many times more slowly than native hardware. SDE can be downloaded here.\n\nTo test an application with new instruction sets using SDE, the application first needs to be compiled using appropriate compilers that support the new instruction sets. For example, to compile applications having AVX2 instructions, use the Intel compiler 14.0, gcc 4.7 or Microsoft* Visual Studio* or later versions of these compilers. SDE lists all instructions in assembly language. It not only lists instructions of user applications but also those in the libraries and kernel.\n\nTo display the full list of SDE options, use the following command at the command prompt:\n\nsde –help\n\nFigure 1. List all SDE options\n\nTo display the longer list of SDE options type:\n\nsde -help -long\n\nHow to Use SDE\n\nThis article will show how to use two popular SDE options. A video showing where to download and how to install and run SDE can be found at [4].\n\nNot all but two most common SDE options will be mentioned here:\n\nmix\n\nFigure 2. mix option\n\nFigure 2 shows the mix option with the default output or user-defined output files.The “-mix” and “-omix” options will list all dynamic instructions that are executed along with instruction length, instruction category, and ISA extension grouping. Run SDE using this option by typing the following command at the command prompt:\n\nsde.exe -mix -- <application name>\n\nThe result will be written to a file called mix.out. To specify a different name for the output file, use the following command:\n\nsde.exe –omix <user-defined output file name> -- <application name>\n\nast\n\nFigure 3. ast option\n\nFigure 3 shows the ast option with the default output or user-defined output files.Use the “-ast” or “-oast” options to detect whether there are transitions between SSE and AVX/AVX2 instructions. This option is very useful since these kinds of transition activities cost a lot of execution cycles. Reducing instruction transitions will improve the performance of an application. Run SDE using this option by typing the following command at the command prompt:\n\nsde.exe -ast -- <application name>\n\nThe result will be written to a file called avx-sse-transition.out. To specify a different name for the output file, use the following command:\n\nsde.exe -oast <user-defined output file name> -- <application name>\n\nNote: The options can also be combined into one single command as follows:\n\nsde.exe -mix -ast -- <application name>\n\nor\n\nsde.exe –omix < output mix file name> -oast < output ast file name> -- <application name>\n\nA closer look at the output of the ‘mix’ Option\n\nThe output file resulting from using the mix option contains a great deal of information which will not all be explained in this article. Let’s focus on certain portions of the file.\n\nFigure 4. This portion of the output file shows that the application (linkpack_xeon64) has 28 threads currently running.\n\nFigure 5. The output shows a portion of thread 0 (TID 0) in which instructions are used along with instruction types (AVX, FMA and SSE).\n\nFigure 6. At the end of the thread there is a summary of which instructions were used in the threads along with how frequently they were called.\n\nFigure 7. At the end of the output file, there is a summary of all instructions in the applications and libraries that are used by the application.\n\nA closer look at the output of the ‘ast’ Option\n\nThe output from running SDE using the ast option helps identify transitions from SSE to AVX and vice versa.\n\nFigure 8. SSE-AVX and AVX-SSE transitions do not exist\n\nFigure 8 shows the case when there is no SSE-AVX and AVX-SSE transitions. Transitions between SSE-AVX and vice versa consume a lot of valuable execution cycles. Sometimes these transitions can reach up to 20,000 cycles. It is important to reduce these transitions. In case7 there are transitions, the transition output file will look like in figure 9.\n\nFigure 9. SSE-AVX and AVX-SSE transitions exist\n\nThere is a good article about how to avoid these transaction penalties at [9].\n\nBenefits of using SDE\n\nDetecting Instructions​\n\nSDE only counts instructions that are executed (dynamic) while the application is running, not instructions existing in the code (static). This is a very good way to debug the application in case there is a problem assuming that certain instructions are expected to be executed within certain portions of the code. If no expected instructions were detected in a specific block of addresses corresponding to certain portions of the code, then something must have happened like an unexpected/unaware branching condition. SDE provides some options like start-address and stop-address to handle this situation. Note that these options are not documented5. Hopefully, these options will be documented in future SDE releases.\n\nOne important thing should be noted here is that running an application with different options or input will also trigger different behavior and dynamic execution, so one cannot assume that a single run of an application will tell them the whole story. It is always a good idea to run an application under different workloads to observe the application behavior.\n\nPotential Performance Improvement\n\nSDE can detect SSE-AVX and AVX-SSE transitions. By reducing these transitions, performance can be improved.\n\nChecking for Bad Pointers and Data Misalignment\n\nSDE has the ability to check for bad pointers and data misalignment. Below is a snapshot of the options for these two features from SDE documentation8.\n\nFigure 10. Options for debugging\n\nConclusion\n\nSDE is used to test applications that utilize new Intel instruction sets in the absence of hardware supporting these instructions; thus it helps assess whether an application might benefit from a new or future platform released by Intel. It should be noted that SDE runs considerably more slowly than a native platform, and is not intended to provide insight on future performance. SDE dynamically counts instructions that are executed and not instructions in the code, as well as SSE-AVX and AVX-SSE transitions. These features can be used for debugging and optimization purposes. SDE can also aid in debugging in the form of detecting bad pointers and data misalignment. These are only a few of the features offered by this emulation environment: we invite you to explore more by looking at the documentation included in the Reference section of this article.\n\nReferences\n\n[1] http://en.wikipedia.org/wiki/Advanced_Vector_Extensions\n\n[2] http://en.wikipedia.org/wiki/Intel_SHA_extensions\n\n[3] https://software.intel.com/en-us/articles/intel-software-development-emulator\n\n[4] http://goparallel.sourceforge.net/installing-running-intel-software-development-emulator/\n\n[5] https://software.intel.com/en-us/forums/topic/533825\n\n[6] http://en.wikipedia.org/wiki/Intrinsic_function\n\n[7] https://software.intel.com/en-us/forums/topic/538142\n\n[8] https://software.intel.com/en-us/articles/intel-software-development-emulator#BASIC\n\n[9] https://software.intel.com/en-us/articles/avoiding-avx-sse-transition-penalties\n\nNotices INFORMATION IN THIS DOCUMENT IS PROVIDED IN CONNECTION WITH INTEL PRODUCTS. NO LICENSE, EXPRESS OR IMPLIED, BY ESTOPPEL OR OTHERWISE, TO ANY INTELLECTUAL PROPERTY RIGHTS IS GRANTED BY THIS DOCUMENT. EXCEPT AS PROVIDED IN INTEL'S TERMS AND CONDITIONS OF SALE FOR SUCH PRODUCTS, INTEL ASSUMES NO LIABILITY WHATSOEVER AND INTEL DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTY, RELATING TO SALE AND/OR USE OF INTEL PRODUCTS INCLUDING LIABILITY OR WARRANTIES RELATING TO FITNESS FOR A PARTICULAR PURPOSE, MERCHANTABILITY, OR INFRINGEMENT OF ANY PATENT, COPYRIGHT OR OTHER INTELLECTUAL PROPERTY RIGHT. UNLESS OTHERWISE AGREED IN WRITING BY INTEL, THE INTEL PRODUCTS ARE NOT DESIGNED NOR INTENDED FOR ANY APPLICATION IN WHICH THE FAILURE OF THE INTEL PRODUCT COULD CREATE A SITUATION WHERE PERSONAL INJURY OR DEATH MAY OCCUR. Intel may make changes to specifications and product descriptions at any time, without notice. Designers must not rely on the absence or characteristics of any features or instructions marked \"reserved\" or \"undefined.\" Intel reserves these for future definition and shall have no responsibility whatsoever for conflicts or incompatibilities arising from future changes to them. The information here is subject to change without notice. Do not finalize a design with this information. The products described in this document may contain design defects or errors known as errata which may cause the product to deviate from published specifications. Current characterized errata are available on request. Contact your local Intel sales office or your distributor to obtain the latest specifications and before placing your product order. Copies of documents which have an order number and are referenced in this document, or other Intel literature, may be obtained by calling 1-800-548-4725, or go to: http://www.intel.com/design/literature.htm Any software source code reprinted in this document is furnished under a software license and may only be used or copied in accordance with the terms of that license. Intel, the Intel logo, Intel Core, and Intel Xeon are trademarks of Intel Corporation in the U.S. and/or other countries. Copyright © 2015 Intel Corporation. All rights reserved.\n\n*Other names and brands may be claimed as the property of others.\n\nThe Intel® Galileo development board is an Arduino*-certified development and prototyping board. Built on the Yocto 1.4 Poky Linux* release, Galileo merges an Arduino development environment with a complete Linux-based computer system allowing enthusiasts to incorporate Linux system calls and OS-provided services in their Ardunio sketches.\n\nOne long-standing limitation in the Arduino platform has been a lack of SSL support. Without SSL Arduino-based devices are incapable of securely transmitting data using HTTPS, and are thus forced to communicate insecurely using plain HTTP. In order to work around this limitation, devices that participate in the build out of the Internet of Things must rely on secondary devices which serve as bridges to the internet. The Arduino device communicates using HTTP to the bridge, which in turn communicates to the internet-based service using HTTPS.\n\nThis solution works well for devices that have a fixed network location, but it does require additional hardware and introduces a concentration point for multiple devices that itself may be vulnerable to attack. For mobile devices that may occasionally rely on public wireless networks, this approach can be entirely impractical. The best level of protection for connected devices is achieved with SSL support directly on the device itself.\n\nOn Galileo an Arduino sketch is just a C++ program that is cross-compiled into machine code and executed as a process that is managed by the operating system. That means that it has access to the same system resources as any other compiled program, and specifically that program can be linked against arbitrary, compiled libraries. The implication here is that adding SSL support is as simple as linking the Arduino sketch to an existing SSL library.\n\nThis paper examines two methods for adding SSL support to Arduino sketches running on Galileo via the wolfSSL library from wolfSSL, Inc.* (formerly named the CyaSSL library). The wolfSSL library is a lightweight SSL/TLS library that is designed for resource-constrained environments and embedded applications, and is distributed under the GPLv2 license.\n\nThis paper looks at two methods for linking the wolfSSL library to an Arduino sketch, but both of them follow the same basic steps:\n\nBuild wolfSSL for Yocto\n\nInstall the wolfSSL shared library onto your Galileo image\n\nModify the compile patterns for the Arduino IDE for Galileo\n\nInstall the wolfSSL build files onto the system hosting the Arduino IDE\n\nThis procedure is moderately complex and does require a firm grasp of the Linux environment, shell commands, software packages and software build procedures, as well as methods of transferring files to and from a Linux system. While this paper does go into some detail on specific Linux commands, it is not a step-by-step instruction manual and it assumes that the reader knows how to manipulate files on a Linux system.\n\nThese procedures should work on both Galileo and Galileo 2 boards.\n\nMethod 1: Dynamic linking\n\nIn the dynamic linking method the Arduino sketch is dynamically linked with the shared object library, libwolfssl.so. This method is the easiest to program for since the sketch just calls the library functions directly.\n\nThere are disadvantages to this approach, however:\n\nThe Arduino IDE for Galileo uses a single configuration for compiling all sketches, so the linker will put a reference to libwolfssl.so in the resulting executable whether or not it’s needed by a sketch. This is not a problem if the target Galileo system has the wolfSSL library installed on it, but if any sketch is compiled for another system that does not have the library then those sketches will not execute.\n\nThe system hosting the Arduino IDE for Galileo must have the cross-compiled wolfSSL library installed into the Arduino IDE build tree.\n\nMethod 2: Dynamic loading\n\nIn the dynamic loading method the Arduino sketch is linked with the dynamic linking loader library, libdl. The wolfSSL library and its symbols are loaded dynamically during execution using dlopen() and dlsym(). This method is more tedious to program for since the function names cannot be resolved directly by the linker and must be explicitly loaded by the code and saved as function pointers.\n\nThe advantages over the dynamic linking method are:\n\nlibdl is part of the Galileo SD card image, so arbitrary sketches compiled by the modified IDE will still run on other Galileo systems.\n\nThe system hosting the Arduino IDE for Galileo only needs to have the wolfSSL header files installed into the build tree.\n\nAny dynamic library is available to the Arduino sketch with just this single modification.\n\nThe first step in bringing SSL support to the Arduino environment is to build the wolfSSL library for Yocto using uClibc as the C library. This is accomplished using the cross compiler that is bundled with Intel’s Arduino IDE for Linux. This step must be performed on a Linux system.\n\nThere have been multiple releases of the IDE since the original Galileo release and any of them will do, but because path names have changed from release to release this document assumes that you will be using the latest build as of this writing, which is the Intel bundle version 1.0.4 with Arduino IDE version 1.6.0.\n\nChoose the 32-bit or 64-bit archive, whichever is correct for your Linux distribution.\n\nConfiguring the cross-compiler\n\nIf you have already used this version of the IDE to build sketches for your Galileo device then it has already been configured properly and you can skip this task.\n\nIf you have not built a sketch with it yet, then you will need to run the installation script in order to correctly set the path names in the package configuration files. This script, install_script.sh, is located in the hardware/tools/i586 directory inside the root of your IDE package. Run it with no arguments:\n\n~/galileo/arduino-1.6.0+Intel/hardware/tools/i586$ ./install_script.sh Setting it up.../tmp/tmp.7FGQfwEaNz/relocate_sdk.sh /nfs/common/galileo/arduino-1.6.0+Intel/hardware/tools/i586/relocate_sdk.sh link:/nfs/common/galileo/arduino-1.6.0+Intel/hardware/tools/i586/sysroots/x86_64-pokysdk-linux/lib/ld-linux-x86-64.so.2 link:/nfs/common/galileo/arduino-1.6.0+Intel/hardware/tools/i586/sysroots/x86_64-pokysdk-linux/lib/libpthread.so.0 link:/nfs/common/galileo/arduino-1.6.0+Intel/hardware/tools/i586/sysroots/x86_64-pokysdk-linux/lib/libnss_compat.so.2 link:/nfs/common/galileo/arduino-1.6.0+Intel/hardware/tools/i586/sysroots/x86_64-pokysdk-linux/lib/librt.so.1 link:/nfs/common/galileo/arduino-1.6.0+Intel/hardware/tools/i586/sysroots/x86_64-pokysdk-linux/lib/libresolv.so.2 … SDK has been successfully set up and is ready to be used.\n\nThe cross-compiler is now ready for use.\n\nDownloading the wolfSSL source\n\nTo build the wolfSSL library for Galileo you need to download the source code from wolfSSL, Inc. As of this writing, the latest version is 3.4.0 and is distributed as a Zip archive. Unzip the source into a directory of your choosing.\n\nBuilding the library\n\nIn order to build the library, you must first set up your shell environment to reference the cross compiler. The environment setup files assume a Bourne shell environment so you must perform these steps in an appropriate and compatible shell such as sh or bash. Starting from a clean shell environment is strongly recommended.\n\nFirst, source the environment setup file from the Intel Arduino IDE. Be sure to use the path to your Intel Arduino IDE instead of the path given in the example:\n\n~/src/wolfssl-3.4.0$ . ~/galileo/arduino-1.6.0+Intel/hardware/tools/i586/environment-setup-i586-poky-linux-uclibc\n\nThis step will not generate any output.\n\nNow, you are ready to run the configure script for wolfSSL. It is necessary to provide configure with a number of options in order to properly initialize it for a cross compile.\n\n~/src/wolfssl-3.4.0$ ./configure --prefix=$HOME/wolfssl --host=i586-poky-linux-uclibc \\ --target=i586-poky-linux-uclibc\n\nNote that you must supply absolute paths to the configure script, and cannot use ~ as a shortcut for your home directory. Use the $HOME shell variable instead.\n\nThe --prefix option tells build system where to install the library. Since you won’t actually be installing the library on this system, any directory will do. This example shows it going in $HOME/wolfssl.\n\nThe --host and --target options tell the build system that this will be a cross-compile, targeting the architecture identified as i586-poky-linux-uclibc.\n\nThe configure script will generate a lot of output. When it finishes, assuming there are no errors, you can build the software using “make”.\n\n~/src/wolfssl-3.4.0$ make make[1]: Entering directory `/nfs/users/johnm/src/wolfssl-3.4.0' CC wolfcrypt/test/testsuite_testsuite_test-test.o CC examples/client/testsuite_testsuite_test-client.o CC examples/server/testsuite_testsuite_test-server.o CC examples/client/tests_unit_test-client.o CC examples/server/tests_unit_test-server.o CC wolfcrypt/src/src_libwolfssl_la-hmac.lo CC wolfcrypt/src/src_libwolfssl_la-random.lo … CCLD examples/client/client CCLD examples/echoserver/echoserver CCLD testsuite/testsuite.test CCLD tests/unit.test make[1]: Leaving directory `/nfs/users/johnm/src/wolfssl-3.4.0'\n\nAnd then install it to the local/temporary location via “make install”:\n\n~/src/wolfssl-3.4.0$ make install\n\nYour library will now be in the directory you specified to the --prefix option of configure, in the lib subdirectory:\n\n~/src/wolfssl-3.4.0$ cd $HOME/wolfssl/lib~/wolfssl/lib$ ls -CFs total 188 4 libwolfssl.la* 0 libwolfssl.so.0@ 4 pkgconfig/ 0 libwolfssl.so@ 180 libwolfssl.so.0.0.0*\n\nYou’re now ready to install the wolfSSL library onto Galileo.\n\nThere are two general approaches for installing the wolfSSL package onto Galileo: the first is to copy the files directly to the Galileo filesystem image, and the second is to copy the files onto a running Galileo system over a network connection. In either case, however, you do need to know which image you are running on your system, the SD-Card Linux image, or the IoT Developer Kit image.\n\nFor Galileo running the SD-Card Linux image\n\nThe SD-Card Linux image is the original system image for Galileo boards. It is a very minimal system image which is less than 312 MB in size. It lacks development tools (e.g., there is no compiler) and advanced Linux utilities. As of this writing, the latest version of the SD-Card image is 1.0.4.\n\nBoth installation methods are discussed below, but installing directly to the Galileo filesystem image is preferred because you have more powerful utilities at your disposal.\n\nInstalling wolfSSL to the filesystem image\n\nThis method is easier and less error-prone than the other since you have file synchronization tools available to you, and you don’t have the added complexities of networking. All that is necessary is to mount the Galileo filesystem image as a filesystem on the build machine and then you can use rsync to copy the wolfSSL package into place. You can either copy this file to your build system, or mount the microSD card with the image directly on your Linux system using a card reader.\n\nIn the Galileo SD Card filesystem tree, the main Galileo filesystem image is called image-full-galileo-clanton.ext3 and it can be mounted using the loop device. Create a mount point (directory) on your build system—the example below uses /mnt/galileo—and then use the mount command to mount it:\n\n~/wolfssl$ cd /mnt/mnt$ sudo mkdir galileo/mnt$ mount –t ext3 –o loop /path/to/image-full-galileo-clanton.ext3 /mnt/galileo\n\nThe Galileo filesystem should now be visible as /mnt/galileo.\n\nUse rsync to copy the shared library and its symlinks into place. They should be installed into /usr/lib on your Galileo system:\n\n/mnt$ rsync –a $HOME/wolfssl/lib/lib* /mnt/galileo/usr/lib\n\nBe sure to replace $HOME/wolfSSL with the actual location of your local wolfSSL build.\n\nInstalling wolfSSL over the network\n\nFor this method, the Galileo system must be up and running with an active network connection and you will need to know its IP address. Because Galileo lacks file synchronization utilities such as rsync, files will have to be copied using tar to ensure that symbolic links are handled correctly.\n\nFirst, use cd to switch to the lib subdirectory of your local wolfSSL build.\n\n~/wolfssl$ cd $HOME/wolfssl/lib\n\nNow use tar to create an archive of the shared library and its symlinks, and the copy it to Galileo with scp.\n\n~/wolfssl/lib$ tar cf /tmp/wolfssl.tar lib*~/wolfssl/lib$ cd /tmp/tmp$ scp wolfssl.tar root@192.168.1.2:/tmp root@192.168.1.2’s password:\n\nBe sure to enter the IP address of your Galileo instead of the example.\n\nNow log in to your Galileo device and untar the archive:\n\n/tmp$ ssh root@192.168.1.2 root@192.168.1.2’s password: root@clanton:~# cd /usr/libroot@clanton:/usr/lib# tar xf /tmp/wolfssl.tar\n\nFor Galileo running the IoT Developer Kit image\n\nThe IoT Developer Kit image is a much larger and more traditional Linux system image which includes developer tools and many useful system utilities and daemons. It is distributed as a raw disk image which includes both FAT32 and ext3 disk partitions, and it must be direct-written to an SD card.\n\nSoftware archive:\n\nhttps://software.intel.com/en-us/iot/downloads\n\nTarget file:\n\niotdk-galileo-image.bz2\n\nBoth installation methods are discussed below.\n\nAs of this writing, you also need to replace the uClibc library on your Developer Kit image with the one bundled with your Intel Arduino IDE. Due to differences in the build procedure used for these two copies of the library, not all of the symbols that are exported in the IDE version are present in the Developer Kit version and that can lead to runtime crashes of Arduino sketches. The wolfSSL library, in particular, introduces a dependency on one of these symbols that is missing from the Developer Kit’s build of uClibc, and if you do not replace the library on the Galileo system attempts to use libwolfssl will fail.\n\nInstalling wolfSSL to the filesystem image\n\nThis method is easiest if you connect an SD card reader to your Linux system. Since the Developer Kit image contains an ext3 partition, most Linux distributions will automatically mount it for you, typically under /media or /mnt. Use the df command with the -T option to help you determine the mount point.\n\n~$ df -T | grep ext3 /dev/sde2 ext3 991896 768032 172664 82% /media/johnm/048ce1b1-be13-4a5d-8352-2df03c0d9ed8\n\nIn this case, the mount point is /media/johnm/048ce1b1-be13-4a5d-8352-2df03c0d9ed8:\n\n~$ /bin/ls -CFs /media/johnm/048ce1b1-be13-4a5d-8352-2df03c0d9ed8 total 96 4 bin/ 4 home/ 4 media/ 4 proc/ 4 sys/ 4 www/ 4 boot/ 4 lib/ 4 mnt/ 4 run/ 4 tmp/ 4 dev/ 4 lib32/ 4 node_app_slot/ 4 sbin/ 4 usr/ 4 etc/ 16 lost+found/ 4 opt/ 4 sketch/ 4 var/\n\nThe libraries used by Arduino sketches are kept in /lib32. Use cd to change to that directory and copy the wolfSSL shared libraries and their symlinks into this directory using rsync in order to preserve the symbolic links.\n\n~/wolfssl$ cd /path-to-mountpoint/lib32lib32$ rsync –a $HOME/wolfssl/lib/lib* .\n\nBe sure to replace path-to-mountpoint with the actual mount point for your SD card’s Galileo filesystem.\n\nNow, you need to replace the Developer Kit’s uClibc library with the one from your Intel Arduino IDE package. Instead of removing it or overwriting it, the following procedure will simply rename it, effectively disabling the original copy of the library but without permanently deleting it:\n\nlib32$ mv libuClibc-0.9.34-git.so libuClibc-0.9.34-git.so.distlib32$ cp ~/galileo/arduino-1.6.0+Intel/hardware/tools/i586/sysroots/i586-poky-linux-uclibc/lib/libuClibc-0.9.34-git.so .\n\nRemember to use your actual path to your Intel Arduino IDE in place of the example one.\n\nInstalling wolfSSL over the network\n\nFor this method, the Galileo system must be up and running with an active network connection and you will need to know its IP address. Because Galileo lacks file synchronization utilities such as rsync, files will have to be copied using tar to ensure that symbolic links are handled correctly.\n\nFirst, use cd to switch to the lib subdirectory of your local wolfSSL build.\n\n~/wolfssl$ cd $HOME/wolfssl/lib\n\nNow use tar to create an archive of the shared library and its symlinks, and the copy it to Galileo with scp.\n\n~/wolfssl/lib$ tar cf /tmp/wolfssl.tar lib*~/wolfssl/lib$ cd /tmp/tmp$ scp wolfssl.tar root@192.168.1.2:/tmp root@192.168.1.2’s password:\n\nBe sure to enter the IP address of your Galileo instead of the example.\n\nNow log in to your Galileo device and untar the archive:\n\n/tmp$ ssh root@192.168.1.2 root@192.168.1.2’s password: root@quark:~# cd /lib32root@quark:/lib32# tar xf /tmp/wolfssl.tar\n\nNext, you need to replace the Developer Kit’s uClibc library with the one from your Intel Arduino IDE package. Instead of removing it or overwriting it, the following procedure will simply rename it, effectively disabling the original copy of the library but without permanently deleting it (this will also prevent the actively running sketch from crashing):\n\nroot@quark:/lib32$ mv libuClibc-0.9.34-git.so libuClibc-0.9.34-git.so.dist\n\nLog out of your Galileo system and use scp to copy the library from your Intel Arduino IDE to your Galileo:\n\n~$ scp ~/galileo/arduino-1.6.0+Intel/hardware/tools/i586/sysroots/i586-poky-linux-uclibc/lib/libuClibc-0.9.34-git.so root@192.168.1.2:/lib32\n\nRemember to use your actual path to your Intel Arduino IDE in place of the example one, and your Galileo’s IP address.\n\nTo compile sketches that want to use the wolfSSL library you need to modify the compile patterns for the Arduino IDE for Galileo. The specific modification that is necessary depends on the method you have chosen for linking to libwolfssl, but no matter the method compile patters live inside of hardware/intel/i586-uclibc for the Intel 1.0.4 with Arduino IDE 1.5.3 and later.\n\nModifying the compile patterns\n\nThe file that holds your compile patterns is named platform.txt.\n\nYou will be editing the line “recipe.c.combine.pattern”, which looks similar to this:\n\n## Combine gc-sections, archives, and objects recipe.c.combine.pattern=\"{compiler.path}{compiler.c.elf.cmd}\" {compiler.c.elf.flags} -march={build.mcu} -o \"{build.path}/{build.project_name}.elf\" {object_files} \"{build.path}/{archive_file}\"\"-L{build.path}\" -lm -lpthread\n\nDynamic linking\n\nIf you are using the dynamic linking method, then you need to tell the linker to add libwolfssl to the list of libraries when linking the executable. Add -lwolfssl to the end of the line.\n\n## Combine gc-sections, archives, and objects recipe.c.combine.pattern=\"{compiler.path}{compiler.c.elf.cmd}\" {compiler.c.elf.flags} -march={build.mcu} -o \"{build.path}/{build.project_name}.elf\" {object_files} \"{build.path}/{archive_file}\"\"-L{build.path}\" -lm –lpthread -lwolfssl\n\nBe sure not to add any line breaks.\n\nDynamic loading\n\nIn the dynamic loading method, you need to tell the linker to add the dynamic loader library to the list of libraries. Add -ldl to the end of the line.\n\n## Combine gc-sections, archives, and objects recipe.c.combine.pattern=\"{compiler.path}{compiler.c.elf.cmd}\" {compiler.c.elf.flags} -march={build.mcu} -o \"{build.path}/{build.project_name}.elf\" {object_files} \"{build.path}/{archive_file}\"\"-L{build.path}\" -lm -ldl\n\nBe sure not to add any line breaks.\n\nThe last step before you can compile sketches is to install the wolfSSL build files into the Arduino IDE for Galileo build tree. For the 1.6.0 release, the build tree is in hardware/tools/i586/i586-poky-linux-uclibc. In there you will find a UNIX-like directory structure containing directories etc, lib, usr, and var.\n\nInstalling the wolfSSL header files\n\nWhether you are using the dynamic loading or dynamic linking method you will need to have the wolfSSL header files installed where the Arduino IDE can find them so that you can include them in your sketches with:\n\n#include <wolfssl/ssl.h>\n\nYou can find the header files in the local installation of wolfSSL that you created in Step 1, in include subdirectory. For backwards compatability reasons, the wolfSSL distribution includes header files in include/cyassl and include/wolfssl.\n\nThe wolfSSL header files must but installed into usr/include:\n\nInstalling the wolfSSL libraries\n\nIf you are using the dynamic linking method, then you must also install the cross-compiled libraries into usr/lib. You can skip this step if you are using the dynamic loading method.\n\nThe libraries are in the local installation that was created in Step 1, inside the lib directory. From there copy:\n\nlibwolfssl.la libwolfssl.so libwolfssl.so.*\n\nAll but one of the shared object files will be symlinks, but it is okay for them to be copied as just regular files.\n\nThe following example sketches show how to interact with the wolfSSL library using both the dynamic linking and dynamic loading methods. They perform the same function: connect to a target web server and fetch a web page using SSL. The page source is printed to the Arduino IDE for Galileo’s serial console.\n\nThese sketches are licensed under the Intel Sample Source Code license. In addition to browsing the source here, you can download them directly.\n\nDynamic linking example\n\n/* Copyright 2015 Intel Corporation All Rights Reserved. The source code, information and material (\"Material\") contained herein is owned by Intel Corporation or its suppliers or licensors, and title to such Material remains with Intel Corporation or its suppliers or licensors. The Material contains proprietary information of Intel or its suppliers and licensors. The Material is protected by worldwide copyright laws and treaty provisions. No part of the Material may be used, copied, reproduced, modified, published, uploaded, posted, transmitted, distributed or disclosed in any way without Intel's prior express written permission. No license under any patent, copyright or other intellectual property rights in the Material is granted to or conferred upon you, either expressly, by implication, inducement, estoppel or otherwise. Any license under such intellectual property rights must be express and approved by Intel in writing. Include any supplier copyright notices as supplier requires Intel to use. Include supplier trademarks or logos as supplier requires Intel to use, preceded by an asterisk. An asterisked footnote can be added as follows: *Third Party trademarks are the property of their respective owners. Unless otherwise agreed by Intel in writing, you may not remove or alter this notice or any other notice embedded in Materials by Intel or Intel's suppliers or licensors in any way. */ #include <LiquidCrystal.h> #include <dlfcn.h> #include <wolfssl/ssl.h> #include <Ethernet.h> #include <string.h> const char server[]= \"www.example.com\"; // Set this to a web server of your choice const char req[]= \"GET /Main_Page HTTP/1.0\\r\\n\\r\\n\"; // Get the root page int repeat; int wolfssl_init (); int client_send (WOLFSSL *, char *, int, void *); int client_recv (WOLFSSL *, char *, int, void *); LiquidCrystal lcd(8, 9, 4, 5, 6, 7); void *handle; EthernetClient client; WOLFSSL_CTX *ctx= NULL; WOLFSSL *ssl= NULL; WOLFSSL_METHOD *method= NULL; void setup() { Serial.begin(9600); Serial.println(\"Initializing\"); lcd.begin(16,2); lcd.clear(); if ( wolfssl_init() == 0 ) goto fail; Serial.println(\"OK\"); // Set the repeat count to a maximum of 5 times so that we aren't // fetching the same URL over and over forever. repeat= 5; return; fail: Serial.print(\"wolfSSL setup failed\"); repeat= 0; } int wolfssl_init () { char err[17]; // Create our SSL context method= wolfTLSv1_2_client_method(); ctx= wolfSSL_CTX_new(method); if ( ctx == NULL ) return 0; // Don't do certification verification wolfSSL_CTX_set_verify(ctx, SSL_VERIFY_NONE, 0); // Specify callbacks for reading to/writing from the socket (EthernetClient // object). wolfSSL_SetIORecv(ctx, client_recv); wolfSSL_SetIOSend(ctx, client_send); return 1; } int client_recv (WOLFSSL *_ssl, char *buf, int sz, void *_ctx) { int i= 0; // Read a byte while one is available, and while our buffer isn't full. while ( client.available() > 0 && i < sz) { buf[i++]= client.read(); } return i; } int client_send (WOLFSSL *_ssl, char *buf, int sz, void *_ctx) { int n= client.write((byte *) buf, sz); return n; } void loop() { char errstr[81]; char buf[256]; int err; // Repeat until the repeat count is 0. if (repeat) { if ( client.connect(server, 443) ) { int bwritten, bread, totread; Serial.print(\"Connected to \"); Serial.println(server); ssl= wolfSSL_new(ctx); if ( ssl == NULL ) { err= wolfSSL_get_error(ssl, 0); wolfSSL_ERR_error_string_n(err, errstr, 80); Serial.print(\"wolfSSL_new: \"); Serial.println(errstr); } Serial.println(req); bwritten= wolfSSL_write(ssl, (char *) req, strlen(req)); Serial.print(\"Bytes written= \"); Serial.println(bwritten); if ( bwritten > 0 ) { totread= 0; while ( client.available() || wolfSSL_pending(ssl) ) { bread= wolfSSL_read(ssl, buf, sizeof(buf)-1); totread+= bread; if ( bread > 0 ) { buf[bread]= '\\0'; Serial.print(buf); } else { Serial.println(); Serial.println(\"Read error\"); } } Serial.print(\"Bytes read= \"); Serial.println(bread); } if ( ssl != NULL ) wolfSSL_free(ssl); client.stop(); Serial.println(\"Connection closed\"); } --repeat; } // Be polite by sleeping between iterations delay(5000); }\n\nDynamic loading example\n\n/* Copyright 2015 Intel Corporation All Rights Reserved. The source code, information and material (\"Material\") contained herein is owned by Intel Corporation or its suppliers or licensors, and title to such Material remains with Intel Corporation or its suppliers or licensors. The Material contains proprietary information of Intel or its suppliers and licensors. The Material is protected by worldwide copyright laws and treaty provisions. No part of the Material may be used, copied, reproduced, modified, published, uploaded, posted, transmitted, distributed or disclosed in any way without Intel's prior express written permission. No license under any patent, copyright or other intellectual property rights in the Material is granted to or conferred upon you, either expressly, by implication, inducement, estoppel or otherwise. Any license under such intellectual property rights must be express and approved by Intel in writing. Include any supplier copyright notices as supplier requires Intel to use. Include supplier trademarks or logos as supplier requires Intel to use, preceded by an asterisk. An asterisked footnote can be added as follows: *Third Party trademarks are the property of their respective owners. Unless otherwise agreed by Intel in writing, you may not remove or alter this notice or any other notice embedded in Materials by Intel or Intel's suppliers or licensors in any way. */ #include <dlfcn.h> #include <wolfssl/ssl.h> #include <Ethernet.h> #include <string.h> /* Set this to the location of your wolfssl shared library. By default you shouldn't need to specify a path unless you put it somewhere other than /usr/lib (SD-Card image) or /lib32 (IoT Developer Kit image). */ #define WOLFSSL_SHLIB_PATH \"libwolfssl.so\" const char server[]= \"www.example.com\"; // Set this to a web server of your choice const char req[]= \"GET / HTTP/1.0\\r\\n\\r\\n\"; // Get the root page int repeat; int wolfssl_dlload (); int wolfssl_init (); int client_send (WOLFSSL *, char *, int, void *); int client_recv (WOLFSSL *, char *, int, void *); void *handle; EthernetClient client; WOLFSSL_CTX *ctx= NULL; WOLFSSL *ssl= NULL; WOLFSSL_METHOD *method= NULL; typedef struct wolfssl_handle_struct { WOLFSSL_METHOD *(*wolfTLSv1_2_client_method)(); WOLFSSL_CTX *(*wolfSSL_CTX_new)(WOLFSSL_METHOD *); void (*wolfSSL_CTX_set_verify)(WOLFSSL_CTX *, int , VerifyCallback); int (*wolfSSL_connect)(WOLFSSL *); int (*wolfSSL_shutdown)(WOLFSSL *); int (*wolfSSL_get_error)(WOLFSSL *, int); void (*wolfSSL_ERR_error_string_n)(unsigned long, char *, unsigned long); WOLFSSL *(*wolfSSL_new)(WOLFSSL_CTX *); void (*wolfSSL_free)(WOLFSSL *); void (*wolfSSL_SetIORecv)(WOLFSSL_CTX *, CallbackIORecv); void (*wolfSSL_SetIOSend)(WOLFSSL_CTX *, CallbackIORecv); int (*wolfSSL_read)(WOLFSSL *, void *, int); int (*wolfSSL_write)(WOLFSSL *, void *, int); int (*wolfSSL_pending)(WOLFSSL *); } wolfssl_t; wolfssl_t wolf; void setup() { Serial.begin(9600); Serial.println(\"Initializing\"); if ( wolfssl_dlload() == 0 ) goto fail; if ( wolfssl_init() == 0 ) goto fail; // Set the repeat count to a maximum of 5 times so that we aren't // fetching the same URL over and over forever. repeat= 5; return; fail: Serial.print(\"wolfSSL setup failed\"); repeat= 0; } int wolfssl_init () { char err[17]; // Create our SSL context method= wolf.wolfTLSv1_2_client_method(); ctx= wolf.wolfSSL_CTX_new(method); if ( ctx == NULL ) return 0; // Don't do certification verification wolf.wolfSSL_CTX_set_verify(ctx, SSL_VERIFY_NONE, 0); // Specify callbacks for reading to/writing from the socket (EthernetClient // object). wolf.wolfSSL_SetIORecv(ctx, client_recv); wolf.wolfSSL_SetIOSend(ctx, client_send); return 1; } int wolfssl_dlload () { // Dynamically load our symbols from libwolfssl.so char *err; // goto is useful for constructs like this, where we need everything to succeed or // it's an overall failure and we abort. If just one of these fails, print an error // message and return 0. handle= dlopen(WOLFSSL_SHLIB_PATH, RTLD_NOW); if ( handle == NULL ) { err= dlerror(); goto fail; } wolf.wolfTLSv1_2_client_method= (WOLFSSL_METHOD *(*)()) dlsym(handle, \"wolfTLSv1_2_client_method\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_CTX_new= (WOLFSSL_CTX *(*)(WOLFSSL_METHOD *)) dlsym(handle, \"wolfSSL_CTX_new\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_CTX_set_verify= (void (*)(WOLFSSL_CTX* , int , VerifyCallback)) dlsym(handle, \"wolfSSL_CTX_set_verify\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_connect= (int (*)(WOLFSSL *)) dlsym(handle, \"wolfSSL_connect\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_get_error= (int (*)(WOLFSSL *, int)) dlsym(handle, \"wolfSSL_get_error\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_ERR_error_string_n= (void (*)(unsigned long, char *, unsigned long)) dlsym(handle, \"wolfSSL_ERR_error_string_n\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_new= (WOLFSSL *(*)(WOLFSSL_CTX *)) dlsym(handle, \"wolfSSL_new\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_free= (void (*)(WOLFSSL *)) dlsym(handle, \"wolfSSL_free\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_SetIORecv= (void (*)(WOLFSSL_CTX *, CallbackIORecv)) dlsym(handle, \"wolfSSL_SetIORecv\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_SetIOSend= (void (*)(WOLFSSL_CTX *, CallbackIORecv)) dlsym(handle, \"wolfSSL_SetIOSend\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_read= (int (*)(WOLFSSL *, void *, int)) dlsym(handle, \"wolfSSL_read\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_write= (int (*)(WOLFSSL *, void *, int)) dlsym(handle, \"wolfSSL_write\"); if ( (err= dlerror()) != NULL ) goto fail; wolf.wolfSSL_pending= (int (*)(WOLFSSL *)) dlsym(handle, \"wolfSSL_pending\"); if ( (err= dlerror()) != NULL ) goto fail; Serial.println(\"OK\"); return 1; fail: Serial.println(err); return 0; } int client_recv (WOLFSSL *_ssl, char *buf, int sz, void *_ctx) { int i= 0; // Read a byte while one is available, and while our buffer isn't full. while ( client.available() > 0 && i < sz) { buf[i++]= client.read(); } return i; } int client_send (WOLFSSL *_ssl, char *buf, int sz, void *_ctx) { int n= client.write((byte *) buf, sz); return n; } void loop() { char errstr[81]; char buf[256]; int err; // Repeat until the repeat count is 0. if (repeat) { if ( client.connect(server, 443) ) { int bwritten, bread, totread; Serial.print(\"Connected to \"); Serial.println(server); ssl= wolf.wolfSSL_new(ctx); if ( ssl == NULL ) { err= wolf.wolfSSL_get_error(ssl, 0); wolf.wolfSSL_ERR_error_string_n(err, errstr, 80); Serial.print(\"wolfSSL_new: \"); Serial.println(errstr); } Serial.println(req); bwritten= wolf.wolfSSL_write(ssl, (char *) req, strlen(req)); Serial.print(\"Bytes written= \"); Serial.println(bwritten); if ( bwritten > 0 ) { totread= 0; while ( client.available() || wolf.wolfSSL_pending(ssl) ) { bread= wolf.wolfSSL_read(ssl, buf, sizeof(buf)-1); totread+= bread; if ( bread > 0 ) { buf[bread]= '\\0'; Serial.print(buf); } else { Serial.println(); Serial.println(\"Read error\"); } } Serial.print(\"Bytes read= \"); Serial.println(totread); } if ( ssl != NULL ) wolf.wolfSSL_free(ssl); client.stop(); Serial.println(\"Connection closed\"); } --repeat; } // Be polite by sleeping between iterations delay(5000); }\n\nINFORMATION IN THIS DOCUMENT IS PROVIDED IN CONNECTION WITH INTEL PRODUCTS. NO LICENSE, EXPRESS OR IMPLIED, BY ESTOPPEL OR OTHERWISE, TO ANY INTELLECTUAL PROPERTY RIGHTS IS GRANTED BY THIS DOCUMENT. EXCEPT AS PROVIDED IN INTEL'S TERMS AND CONDITIONS OF SALE FOR SUCH PRODUCTS, INTEL ASSUMES NO LIABILITY WHATSOEVER AND INTEL DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTY, RELATING TO SALE AND/OR USE OF INTEL PRODUCTS INCLUDING LIABILITY OR WARRANTIES RELATING TO FITNESS FOR A PARTICULAR PURPOSE, MERCHANTABILITY, OR INFRINGEMENT OF ANY PATENT, COPYRIGHT OR OTHER INTELLECTUAL PROPERTY RIGHT.\n\nUNLESS OTHERWISE AGREED IN WRITING BY INTEL, THE INTEL PRODUCTS ARE NOT DESIGNED NOR INTENDED FOR ANY APPLICATION IN WHICH THE FAILURE OF THE INTEL PRODUCT COULD CREATE A SITUATION WHERE PERSONAL INJURY OR DEATH MAY OCCUR.\n\nIntel may make changes to specifications and product descriptions at any time, without notice. Designers must not rely on the absence or characteristics of any features or instructions marked \"reserved\" or \"undefined.\" Intel reserves these for future definition and shall have no responsibility whatsoever for conflicts or incompatibilities arising from future changes to them. The information here is subject to change without notice. Do not finalize a design with this information.\n\nThe products described in this document may contain design defects or errors known as errata which may cause the product to deviate from published specifications. Current characterized errata are available on request.\n\nContact your local Intel sales office or your distributor to obtain the latest specifications and before placing your product order.\n\nCopies of documents which have an order number and are referenced in this document, or other Intel literature, may be obtained by calling 1-800-548-4725, or go to: http://www.intel.com/design/literature.htm\n\nIntel, the Intel logo, VTune, Cilk and Xeon are trademarks of Intel Corporation in the U.S. and other countries.\n\n*Other names and brands may be claimed as the property of others\n\nCopyright© 2012 Intel Corporation. All rights reserved.\n\n§\n\nBackground\n\nThe whole point of simulation is to model the behavior of a design and potential changes against various conditions to determine whether we are getting an expected response; and simulation in software is far cheaper than building hardware and performing a physical simulation and modifying the hardware model each time.\n\nDassault Systèmes [1] through its SIMULIA* brand, is creating a new paradigm to establish Finite Element Analysis and mulitphysics simulation software as an integral business process in the engineering value chain. More information about SIMULIA can be found here [2].\n\nThe Abaqus* Unified Finite Elements Analysis product suite, from Dassault Systèmes* SIMULIA, offers powerful and complete solutions for both routine and sophisticated engineering problems covering a vast spectrum of industrial applications in Automotive, Aerospace, Consumer Packaged Goods, Energy, High Tech, Industrial Equipment and Life Sciences. As an example, automotive industry engineering work groups are able to consider full vehicle loads, dynamic vibration, multibody systems, impact/crash, nonlinear static, thermal coupling, and acoustic-structural coupling using a common model data structure and integrated solver technology.\n\nWhat is Finite Element Analysis (FEA)?\n\nFEA is a computerized method of simulating the behavior of engineering structures and components under a variety of conditions. It is the application of the Finite Element method (FEM)[3] [8]. It works by breaking down an object into a large number of finite elements and each element is represented by an equation. By integrating all the element’s equations, the whole object can be mathematical modeled.\n\nHow Abaqus/Standard take advantage of Intel® AVX2\n\nAbaqus/Standard is general purpose FEA. It includes many analysis capabilities. According to Dassault Systèmes web site, it “employs solution technology ideal for static and low-speed dynamic events where highly accurate stress solutions are critically important. Examples include sealing pressure in a gasket joint, steady-state rolling of a tire, or crack propagation in a composite airplane fuselage. Within a single simulation, it is possible to analyze a model both in the time and frequency domain. For example, one may start by performing a nonlinear engine cover mounting analysis including sophisticated gasket mechanics. Following the mounting analysis, the pre-stressed natural frequencies of the cover can be extracted, or the frequency domain mechanical and acoustic response of the pre-stressed cover to engine induced vibrations can be examined.” More information about Abaqus/Standard can be found at [9].\n\nAccording to Dassault Systèmes web site, Abaqus/Standard uses Hilber-Hughes-Taylor time [12] integration by default. The time integration is implicit, meaning that the operator matrix must be inverted and a set of simultaneous nonlinear dynamic equilibrium equations must be solved at each time increment. This solution is done iteratively using Newton’s [13] method. This solution utilizes a function called DGEMM [5] (Double-Precision General Matrix Multiplication) in the Intel® Math Kernel Libraries (Intel® MKL [4]) to handle matrix multiplication involving double-precision values.\n\nAnalysis of Abaqus workloads using performance monitoring tools, such as Intel® VTune™, showed a significant number of them spend 40% to 50% of their runtime time in DGEMM. Further analysis of the DGEMM function showed that it makes extensively used of the multiply-add operation since DGEMM is, basically, matrix multiplication.\n\nOne of the new feature of the Intel® Xeon® E5-2600 v3 Product Family is the support of a new extension set called Intel AVX2 [7]. One of the new instructions in Intel AVX2 is the three-operand fused multiply-add (FMA3 [6]). By implementing the combined multiply-addition operation in the hardware, the speed of this operation is considerably improved.\n\nAbaqus/Standard uses Intel® MKL’s DGEMM implementation. It should also be noted that in Intel MKL version 11 update 5, and later versions, DGEMM was optimized to use Intel AVX2 extensions, thus allowing DGEMM to run optimally on the Intel® Xeon® E5-2600 v3 Product Family.\n\nPerformance test procedure\n\nTo prove the performance improvement brought forth by using a newer DGEMM implementation that takes advantage of Intel AVX2, we performed tests on two platforms. One system was equipped with Intel Xeon E5-2697 v3 and the other with Intel Xeon E5-2697 v2. The duration of the tests were measured in seconds.\n\nPerformance test Benchmarks\n\nThe following four benchmarks from Abaqus/Standard were used: s2a, s3a, s3b and s4b.\n\nFigure 1. S2a is a nonlinear static analysis of a flywheel with centrifugal loading.\n\nFigure 2. S3 extracts the natural frequencies and mode shapes of a turbine impeller.\n\nS3 has three versions.\n\nS3a is a 360,000 degrees of freedom (DOF) using Lanczos Eigensolver [11] version.\n\nS3b is a 1,100,000 degrees of freedom (DOF) using Lanczos Eigensolver version.\n\nFigure 3. S4 is a benchmark that simulates the bolting of a cylinder head onto an engine block.\n\nS4b is S4 version with 5,000,000 degrees of freedom (DOF) using direct solver version.\n\nNote that these pictures are properties of Dassault Systèmes*. They are reprinted with the permission from Dassault Systèmes.\n\nTest configurations\n\nSystem equipped with Intel Xeon E5-2697 v3\n\nSystem: Pre-production\n\nProcessors: Xeon E5-2697 v3 @2.6GHz\n\nMemory: 128GB DDR4-2133MHz\n\nSystem equipped with Intel Xeon E5-2697 v2\n\nSystem: Pre-production\n\nProcessors: Xeon E5-2697 v2 @2.7GHz\n\nMemory: 64GB DDR4-1866MHz\n\nOperating System: Red Hat* Enterprise Linux Server release 6.4\n\nApplication: Abaqus/Standard benchmarks version 6.13-1\n\nNote:\n\n1) Although the system equipped with the Intel® Xeon® E5-2697 v3 processor has more memory, the memory capacity does not affect the tests results, as the largest workload only used 43GB of memory.\n\n2) The duration was measured by wall-clock time in seconds.\n\nTest Results\n\nFigure 4. Comparison between Intel Xeon E5-2697 v3 and E5-2697 v2\n\nFigure 4 shows the benchmarks running on a system equipped with Intel Xeon E5-2697 v3 and on a system equipped with E5-2697 v2. Performance improvement due to Intel AVX2 and hardware advantage ranging from 1.11X to 1.39X.\n\nFigure 5. Comparison between benchmarks with Intel AVX2 enabled and disabled\n\nFigure 5 shows the results of benchmarks with Intel AVX2 enabled and disabled on a system equipped with Intel Xeon E5-2697 v3. Using Intel AVX2 allows benchmarks to finish faster than without using Intel AVX2. The performance increase due to Intel AVX2 is ranging from 1.03X to 1.11X.\n\nNote: Software and workloads used in performance tests may have been optimized for performance only on Intel microprocessors. Performance tests, such as SYSmark* and MobileMark*, are measured using specific computer systems, components, software, operations and functions. Any change to any of those factors may cause the results to vary. You should consult other information and performance tests to assist you in fully evaluating your contemplated purchases, including the performance of that product when combined with other products. For more information go to http://www.intel.com/performance\n\nConclusion\n\nSimulation software performance is very critical since it can significantly reduce the model development and analysis time. Abaqus/Standard is well-known for FEA that relies on DGEMM for its solvers. As a result of the introduction of Intel® AVX2 in the Intel® Xeon® E5-2600 v3 Product Family, and as a result of the Intel MKL augmentation to take advantage of Intel AVX2, a simple change to the Abaqus/Standard to use the latest libraries yielded a considerable performance improvement.\n\nReferences\n\n[1] www.3ds.com\n\n[2] http://www.3ds.com/products-services/simulia/\n\n[3] http://en.wikipedia.org/wiki/Finite_element_method\n\n[4] http://en.wikipedia.org/wiki/Math_Kernel_Library\n\n[5] https://software.intel.com/en-us/node/429920\n\n[6] http://en.wikipedia.org/wiki/FMA_instruction_set\n\n[7] http://en.wikipedia.org/wiki/Advanced_Vector_Extensions\n\n[8] http://people.maths.ox.ac.uk/suli/fem.pdf\n\n[9] http://www.3ds.com/products-services/simulia/products/abaqus/abaqusstandard/\n\n[10] http://www.simulia.com/support/v66/v66_performance.html#s2\n\n[11] http://en.wikipedia.org/wiki/Lanczos_algorithm\n\n[12] http://sbel.wisc.edu/People/schafer/mdexperiments/node13.html\n\n[13] http://en.wikipedia.org/wiki/Newton%27s_method\n\nNotices INFORMATION IN THIS DOCUMENT IS PROVIDED IN CONNECTION WITH INTEL PRODUCTS. NO LICENSE, EXPRESS OR IMPLIED, BY ESTOPPEL OR OTHERWISE, TO ANY INTELLECTUAL PROPERTY RIGHTS IS GRANTED BY THIS DOCUMENT. EXCEPT AS PROVIDED IN INTEL'S TERMS AND CONDITIONS OF SALE FOR SUCH PRODUCTS, INTEL ASSUMES NO LIABILITY WHATSOEVER AND INTEL DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTY, RELATING TO SALE AND/OR USE OF INTEL PRODUCTS INCLUDING LIABILITY OR WARRANTIES RELATING TO FITNESS FOR A PARTICULAR PURPOSE, MERCHANTABILITY, OR INFRINGEMENT OF ANY PATENT, COPYRIGHT OR OTHER INTELLECTUAL PROPERTY RIGHT. UNLESS OTHERWISE AGREED IN WRITING BY INTEL, THE INTEL PRODUCTS ARE NOT DESIGNED NOR INTENDED FOR ANY APPLICATION IN WHICH THE FAILURE OF THE INTEL PRODUCT COULD CREATE A SITUATION WHERE PERSONAL INJURY OR DEATH MAY OCCUR. Intel may make changes to specifications and product descriptions at any time, without notice. Designers must not rely on the absence or characteristics of any features or instructions marked \"reserved\" or \"undefined.\" Intel reserves these for future definition and shall have no responsibility whatsoever for conflicts or incompatibilities arising from future changes to them. The information here is subject to change without notice. Do not finalize a design with this information. The products described in this document may contain design defects or errors known as errata which may cause the product to deviate from published specifications. Current characterized errata are available on request. Contact your local Intel sales office or your distributor to obtain the latest specifications and before placing your product order. Copies of documents which have an order number and are referenced in this document, or other Intel literature, may be obtained by calling 1-800-548-4725, or go to: http://www.intel.com/design/literature.htm Any software source code reprinted in this document is furnished under a software license and may only be used or copied in accordance with the terms of that license. Intel, the Intel logo, Intel Core, and Intel Xeon are trademarks of Intel Corporation in the U.S. and/or other countries. Copyright © 2015 Intel Corporation. All rights reserved.\n\n*Other names and brands may be claimed as the property of others.\n\nThis article demonstrates some of the techniques application developers can use to best prepare their applications for the upcoming Intel® Xeon Phi™ x200 product family – codename Knights Landing (KNL).\n\nQuick links\n\nIntroduction\n\nAbout This Document\n\nIntel® Xeon Phi™ x200 Product Overview\n\nApplication Readiness for KNL\n\n​Scaling\n\nVectorization\n\nHigh Bandwidth Memory (MCDRAM)\n\nOther Optimization Techniques\n\nReferences\n\nAppendix A - HBWMALLOC\n\nAppendix B - SimpleDAXPY Application\n\n1. Introduction\n\nThe Intel® Xeon Phi™ x100 family of coprocessors was the first generation of the Intel® Xeon Phi™ product family. It offered energy efficient scaling, enhanced vectorization capabilities and exploited local memory bandwidth. Some of its important features include more than 60 cores (240+ threads), up to 16 GB GDDR5 memory with 352 GB/s bandwidth, and the ability to run Linux* with standard tools and languages. Some applications used these many-core processors by offloading compute intensive workload while others simultaneously used both the Intel® Xeon® host system and Intel® Xeon Phi™ coprocessors each crunching its own portion of the workload.\n\nThere are applications which perform well under this paradigm while there are others where the benefit of accelerated computing is not enough to make up for the cost of moving data between the host and the coprocessor over PCIe. From the application developer’s perspective, this can be a serious problem.\n\nThe Intel® Xeon Phi™ x200 product family – codename Knights Landing (KNL) – is offered both as a processor and as a coprocessor. As a processor, KNL has no need for a host to support it. It can boot the full operating system by itself. For the applications which were limited by the overhead of data transfer on KNC, all the data processing can be completed on the KNL node itself, either in high bandwidth near memory or slower DDR4, without worrying about moving the data back and forth across a PCIe bus between host and accelerator. The coprocessor version of KNL offers an offload paradigm similar to KNC, the first generation of Intel® Xeon Phi™ coprocessors, but now with an added advantage of improved parallelism and greater single thread performance. However for both the processor and the coprocessor versions of the Intel® Xeon Phi™ x200 product family, it is important that the applications use as many cores as possible in parallel effectively and also explore and utilize the enhanced vectorization capabilities to achieve significant performance gains. Cluster applications must also support fabric scaling. Moreover, it is highly likely that applications optimized for Knights Corner will also perform well for the next generation of Intel® Xeon Phi™ product family.\n\n2. About This Document\n\nThe first part of this document lists important features of the Intel® Xeon Phi™ x200 product family. Secondly, it demonstrates how currently available tools like the Intel® Software Development Emulator and Intel® VTune Amplifier can be used to prepare for upcoming KNL processors and coprocessors. It also enlists programming/optimization techniques which are already known from the Intel® Xeon Phi™ x100 products and new techniques suitable for the Intel® Xeon Phi™ x200 processors and coprocessors. Wherever possible, pointers are given to already published best known methods which can assist application developers to apply these optimization techniques. This document will not explain any architecture or instruction level details. It is also not intended for system administrators who wants to setup or manage their Knights Landing systems. Most of the discussions in this document will hover around the KNL processor as it will be the first release of Intel® Xeon Phi™ x200 product family.\n\n3. Intel® Xeon Phi™ x200 Product Overview\n\nFigure 1. KNL package[1] overview\n\n3.1 On Package Micro-architecture Information\n\nSome of the architectural highlights for Intel® Xeon Phi™ x200 product family – codename Knights Landing - are as follows:\n\nUp to 72 cores (in 36 Tiles) connected in a 2D Mesh architecture with improved on-package latency\n\n6 Channel of DDR4 supporting up to 384GB with a sustained bandwidth of more than 80 GB/s\n\nUp to 16GB of high performance on-package memory (MCDRAM) with a sustained bandwidth of ~500 GB/s, supporting flexible memory modes including cache and flat\n\nEach tile can be drawn as follows:\n\nFigure 2. KNL Tile\n\nHere each core is based on Intel® Atom™ core with many HPC enhancements such as:\n\n4 Threads/core\n\nDeep Out-of-Order buffers\n\nGather/scatter in hardware\n\nAdvanced branch prediction\n\nHigh cache bandwidth\n\n2x 512b Vector Processing Units per core with support for Intel® Advanced Vector Extensions 512 (Intel® AVX-512)\n\n3x Single-thread performance compared to Knights Corner\n\nBinary compatible with Intel® Xeon® processors\n\nCache-coherent\n\nSupport for Intel® Omni Scale™ fabric integration\n\n3.2 Performance\n\n3+ Teraflops of double-precision peak theoretical performance per single KNL node\n\nPower efficiency (over 25% better than discrete coprocessor)[2] – over 10 GF/W\n\nStandalone bootable processor with ability to run Linux and Windows OS\n\nPlatform memory capacity comparable to Intel® Xeon® processors\n\n3.3 Programming Standards Supported\n\nOpenMP\n\nMessage Passing Interface (MPI)\n\nFortran\n\nIntel® Threading Building Blocks and Intel® Cilk™ Plus\n\nC/C++\n\n4. Application Readiness for Knights Landing\n\nSimilar to the first generation of Intel® Xeon Phi™ coprocessors, scaling and vectorization are two fundamental considerations to achieve high performance on Knights Landing. Moreover, the Intel® Xeon Phi™ x200 processors have the ability to use high bandwidth memory (MCDRAM) as a separate addressable memory. For certain memory bound applications, modifying allocations of some data structures to utilize this high bandwidth memory can also boost the performance further.\n\n4.1 Scaling\n\nIn order to obtain performance benefits with Intel® Xeon Phi™ product families, it is very important for the application to scale with respect to the increasing number of cores. To check scaling, you can create a graph of performance as you run your application with various numbers of threads either on Intel® Xeon® processors or Intel® Xeon Phi™ x100 coprocessors. Depending on your programming environment, you can either change an appropriate environment variable (for example, OMP_NUM_THREADS for OpenMP) or configuration parameters to vary the number of threads. In some cases, as you increase the number of cores, you may also want to increase the size of the dataset to ensure there is enough work for all the threads and the benefits of parallel performance are not subsumed by overhead in thread creation and maintenance.\n\n4.2 Vectorization\n\nThe Intel® Xeon Phi™ x200 product family supports Intel® Advanced Vector Extensions 512 (Intel® AVX-512) instructions in addition to Intel® SSE, AVX, AVX2 instructions sets. This enables processing of twice the number of data elements as AVX/AVX2 with a single instruction and four times that of SSE. These instructions also represent a significant leap in 512-bit SIMD support which was also available with the first generation Intel® Xeon Phi™ coprocessors.\n\nWith AVX-512, the Intel® Xeon Phi™ x200 product family offers higher performance for the most demanding computational tasks. It features the AVX-512 foundation instructions to support 32 vector registers each 512 bits wide, eight dedicated mask registers, 512-bit operations on packed floating point data or packed integer data, embedded rounding controls (override global settings), embedded broadcast, embedded floating-point fault suppression, embedded memory fault suppression, new operations, additional gather/scatter support, high speed math instructions, and compact representation of large displacement value. In addition to foundation instructions, Knights Landing will also support three additional capabilities: Intel® AVX-512 Conflict Detection Instructions (CDI), Intel® AVX-512 Exponential and Reciprocal Instructions (ERI) and Intel® AVX-512 Prefetch Instructions (PFI). These capabilities provide efficient conflict detection to allow more loops to be vectorized, exponential and reciprocal operations, and new prefetch capabilities, respectively.\n\nAs part of the application readiness efforts for the Intel® Xeon Phi™ x200 product family, support for AVX-512 can be currently evaluated using the Intel® Software Development Emulator (Intel® SDE) on an Intel® Xeon® processor. It has been extended for AVX-512 and is available at https://software.intel.com/en-us/articles/intel-software-development-emulator. Intel® SDE is a software emulator and it is mainly used to emulate future instructions. It is not cycle accurate and can be very slow (up to 100x). However with the instruction mix report it can give useful information like a dynamic instruction execution count and function based instruction count breakdown for evaluating compiler code generation.\n\nThe Compiler Switch to enable AVX512 for KNL is -xMIC_AVX512 (14.0 and later Intel® Compilers)\n\n4.2.1 SDE Example\n\nSample code, as shown in Appendix B can be used to demonstrate how Intel® SDE can help evaluate differences in compiler code generation for AVX, AVX2 and AVX-512.\n\nDownload the latest version of Intel® SDE from https://software.intel.com/en-us/articles/intel-software-development-emulator. The version used in the following example is 7.15.\n\nExtract the SDE and set the environment variable to use sde/sde64\n\n$ tar -xjvf sde-external-7.15.0-2015-01-11-lin.tar.bz2 $ cd sde-external-7.15.0-2015-01-11-lin $ export PATH=`pwd`:$PATH\n\nUse the latest Intel® Compilers (14.0+) and compiling with the “-xMIC-AVX512” knob to generate Knights Landing (KNL) binary\n\n//Compiling for KNL $ icc -openmp -g -O3 -xMIC-AVX512 -o simpleDAXPY_knl simpleDAXPY.c //Compiling for Haswell $ icc -openmp -g -O3 -xCORE-AVX2 -o simpleDAXPY_hsw simpleDAXPY.c //Compiling for Ivy Bridge $ icc -openmp -g -O3 -xCORE-AVX-I -o simpleDAXPY_ivb simpleDAXPY.c\n\nIn order to simplify the analysis, set the number of threads to 1\n\n$ export OMP_NUM_THREADS=1\n\nGenerate instruction mix reports for AVX, AVX2[3] and AVX-512 to compare performance metrics\n\n//Generating report for KNL $ sde -knl -mix -top_blocks 100 -iform 1 -omix sde-mix-knl.txt -- ./simpleDAXPY_knl 64 40 // Generating report for Ivy Bridge $ sde -ivb -mix -top_blocks 100 -iform 1 -omix sde-mix-ivb.txt -- ./simpleDAXPY_ivb 64 40 // Generating report for Haswell $ sde -hsw -mix -top_blocks 100 -iform 1 -omix sde-mix-hsw.txt -- ./simpleDAXPY_hsw 64 40\n\nWe compare dynamic count of total instructions executed to get a rough estimate of overall improvement in application performance by running AVX512 against AVX and AVX2 instructions sets. This can be quickly done by parsing the generated instruction mix reports as follows:\n\n//Getting instruction count with AVX-512 $ grep total sde-mix-knl.txt | head -n 1 *total 5493008680 //Getting instruction count with AVX2 $ grep total sde-mix-hsw.txt | head -n 1 *total 6488866275 //Getting instruction count with AVX $ grep total sde-mix-ivb.txt | head -n 1 *total 7850210690\n\nReduction in total dynamic instruction execution count\n\nChange of Instruction setReduction in dynamic instruction countAVX -> AVX-51230.03%AVX2 -> AVX-51215.34%\n\nThus it can be observed that current and future generations of Intel hardware strongly rely on SIMD[4] performance. In order to write efficient and unconstrained parallel programs, it is important that the application developers fully exploit vectorization capabilities of hardware and understand benefits of using explicit vector programming. This can be achieved by either restructuring vector loops, using explicit SIMD directives (#pragma simd) or using compiler intrinsics. Compiler auto-vectorization may also help achieve the goal in most of the cases.\n\n4.3 High Bandwidth Memory and Supported Memory Modes\n\n4.3.1 Introduction to MCDRAM\n\nThe next generation of Intel® Xeon Phi™ product family can include up to 16GB of On-Package High Bandwidth Memory – Multi Channel DRAM (MCDRAM). It can provide up to 5x the bandwidth as compared to DDR and 5x the power efficiency compared to GDDR5. MCDRAM supports NUMA [5] and can be configured in Cache, Flat and Hybrid modes. The modes must be selected and configured at boot time.\n\n4.3.2 Cache Mode\n\nIn cache mode, all of MCDRAM behaves as a memory-side direct mapped cache in front of DDR4. As a result, there is only a single visible pool of memory and you see MCDRAM as high bandwidth/high capacity L3 cache. Advantage of using MCDRAM as cache is that your legacy application would not require any modifications. So if your application cares about data locality, is not memory bound (i.e., DDR bandwidth bound), and the majority of the critical data structures fit in MCDRAM then this mode will work great for you.\n\n4.3.3 Flat Mode\n\nIn flat mode, MCDRAM is used as a SW visible and OS managed addressable memory (as a separate NUMA node), so that memory can be selectively allocated to your advantage on either DDR4 or MCDRAM. With slight modifications to your software to enable use of both types of memory at the same time, the flat model can deliver uncompromising performance. If your application is DDR bandwidth limited, you can certainly boost your application performance by investigating bandwidth critical hotspots and selectively allocating critical data structures to high bandwidth memory.\n\n4.3.4 Hybrid Mode\n\nThe hybrid model offers a bit of both worlds – some MCDRAM is configured as addressable memory and some is configured as cache. In order to enable this mode at boot, MCDRAM is configured in flat mode and portion (25% or 50%) of MCDRAM is configured as cache.\n\n4.3.5 DDR Bandwidth Analysis\n\nOne of the important steps to decide which memory mode will work best for you, is to analyze memory behavior of your application. This can be done by asking yourself if your application is DDR bandwidth bound. If yes, is it possible to find hotspots where peak bandwidth is often attained for some of the data structures involved i.e. can you identify which data structures are BW critical? Is it possible to fit those bandwidth critical data structures in MCDRAM?\n\nIn order to help us answer the above questions, we will use the sample source as shown in Appendix B to demonstrate how Intel® VTune Amplifier can be used to analyze peak DDR bandwidth and also identify bandwidth critical data structures.\n\n4.3.5.1 Sample Kernels\n\nDAXPY – We use a simplified daxpy routine where a vector is multiplied by a constant and added to another vector. It has been modified to use OpenMP parallel with explicit vectorization using simd clause\n\n//A simple DAXPY kernel void run_daxpy(double A[], double PI, double B[], unsigned long vectorSize){ unsigned long i = 0; #pragma omp parallel for simd for(i=0; i<vectorSize; i++){ B[i] = PI*A[i] + B[i]; } return; }\n\nswap_low_and_high()– A dummy subroutine to do a special swap as given below:\n\nA similar kind of rearrangement is commonly seen after the filtering step of Discrete Wavelet Transform to separate low and high frequency elements.\n\n//Rearranging Odd and Even Position elements into Low and High Vectors void swap_low_and_high(unsigned long vectorSize, double C[]){ unsigned long i = 0, j=0; unsigned long half = vectorSize/2; double temp = 0.0; #pragma omp parallel for private(temp) for(i=0, j=half; i<half; i+=2, j+=2){ temp = C[i+1]; C[i+1] = C[half]; C[half] = temp; } return; }\n\n4.3.5.2 Analysis Using Sample Source\n\nSet up the environment for Compiler and Intel® VTune Amplifier\n\n$ source /opt/intel/composerxe/bin/compilervars.sh intel64 $ source /opt/intel/vtune_amplifier_xe/amplxe-vars.sh\n\nCompile and profile bandwidth for simpleDAXPY application\n\n$ icc -g -O3 -o simpleDAXPY_ddr simpleDAXPY.c -openmp –lpthread $ amplxe-cl --collect bandwidth -r daxpy_swap_BW -- numactl --membind=0 --cpunodebind=0 ./simpleDAXPY_ddr_debug 512 5\n\nNote\n\n- In order to simplify the analysis we bind the application to run only on one socket.\n\n- Number of array elements selected here is 512M(512 x 1024 x 1024) and both DAXPY and SWAP_LOW_HIGH is repeated 5 times to generate enough samples for analysis\n\nAnalyze the bandwidth profile using Intel® VTune Amplifier\n\n$ amplxe-gui daxpy_swap_BW\n\nFigure 3. Bandwidth Profile\n\nFrom figure 3, it can be seen that the simpleDAXPY application attains single socket bandwidth of ~57 GB/s, which is comparable to practical peak bandwidth for a Haswell[6] system with 4 DDR channels per socket. Hence it can be inferred that the application is DDR memory bandwidth bound.\n\nNote\n\n- Peak bandwidth here is referenced as per the STREAM benchmark Triad results in GB/s\n\n- Single socket peak theoretical bandwidth for experimental setup can be given as\n\n2133 (MT/s) * 8 (Bytes/Clock) * 4 (Channels/socket)/1000 = ~68 GB/s\n\nIdentify bandwidth critical data structures\n\nTo identify which data structures should be allocated to high bandwidth memory, it is important to look at some of the core counters which correlate to DDR bandwidth. Two such counters we are interested in are MEM_LOAD_UOPS_RETIRED.L3_MISS and MEM_LOAD_RETIRED.L2_MISS_PS. These core hardware event counters can be collected by profiling application with Intel® VTune Amplifier as follows:\n\n$ amplxe-cl -collect-with runsa -data-limit=0 -r daxpy_swap_core_counters -knob event-config=UNC_M_CAS_COUNT.RD,UNC_M_CAS_COUNT.WR,CPU_CLK_UNHALTED.THREAD,CPU_CLK_UNHALTED.REF_TSC,MEM_LOAD_UOPS_RETIRED.L3_MISS,MEM_LOAD_UOPS_RETIRED.L2_MISS_PS numactl --membind=0 --cpunodebind=0 ./simpleDAXPY_ddr_debug 512 5\n\nAnalyze the core hardware event counters using Intel® VTune Amplifier GUI\n\n$ amplxe-gui daxpy_swap_core_counters\n\nWith Hardware Event Counts viewpoint selected, we look at PMU Events graph.\n\nIn order to see the filtered graph as shown in figure 4, Thread box is unchecked and Hardware Event Count drop-down box is selected to be MEM_LOAD_UOPS_RETIRED.L3_MISS\n\nNow looking at the sources of maximum LLC[7] misses, the data structures that contribute to peak bandwidth can be identified. As seen in Figure 5, region of peak LLC misses can be zoomed in and filtered by selection to get further information about contributors of peak LLC misses.\n\nFigure 4. MEM_LOAD_UOPS_RETIRED.L3_MISS Profile\n\nFigure 5. Zoom In and Filter the region of peak L3 cache misses\n\nAs shown in Figure 6, for the top contributor right click and view the source to get the exact line in source code where the LLC misses are at peak.\n\nFigure 6. Top Contributor of L3 Misses\n\nFigure 7. Suggestions for BW Critical data structures\n\nChanging allocations to high bandwidth memory\n\nHBWMALLOC is a new memory allocation library which abstracts NUMA programming details and helps application developers use high bandwidth memory on Intel® Xeon and Intel® Xeon Phi™ x200 product families in both FORTRAN and C. Use of this interface is as simple as replacing malloc calls with hbw_malloc in C, or placing explicit declarations in Fortran as shown below:\n\nC - Application program interface\n\n//Allocate 1000 floats from DDR float *fv; fv = (float *)malloc(sizeof(float) * 1000); //Allocate 1000 floats from MCDRAM float *fv; fv = (float *)hbw_malloc(sizeof(float) * 1000);\n\nFORTRAN – Application program interface\n\n//Allocate arrays from MCDRAM & DDR c Declare arrays to be dynamic REAL, ALLOCATABLE:: A(:), B(:), C(:) !DEC$ ATTRIBUTES, FASTMEMORY :: A NSIZE=1024 c c allocate array ‘A’ from MCDRAM c ALLOCATE (A(1:NSIZE)) c c Allocate arrays that will come from DDR c ALLOCATE (B(NSIZE), C(NSIZE))\n\nPlease refer to the Appendix A for further details about hbwmalloc - high bandwidth memory allocation library.\n\nThe above profiling results suggests that array A and array B are the data structures which should be preferentially allocated in High bandwidth memory.\n\nIn order to allocate array A and array B in high bandwidth memory, the following modifications are done:\n\n. . . #ifndef USE_HBM //If not using high bandwidth memory double *A = (double *)_mm_malloc(limit * sizeof(double),ALIGNSIZE); double *B = (double *)_mm_malloc(limit * sizeof(double), ALIGNSIZE); double *C = (double *)_mm_malloc(limit * sizeof(double), ALIGNSIZE); #else //Allocating A and B in High Bandwidth Memory double *A, *B, *C; hbw_posix_memalign((void**)(&(A)), ALIGNSIZE, limit*sizeof(double)); if(A == NULL){ printf(\"Unable to allocate on HBM: A\"); } printf(\"Allocating array A in High Bandwidth Memory\\n\"); hbw_posix_memalign((void**)(&(B)), ALIGNSIZE, limit*sizeof(double)); if(B == NULL){ printf(\"Unable to allocate on HBM: B\"); } printf(\"Allocating array B in High Bandwidth Memory\\n\"); C = (double *)_mm_malloc(limit * sizeof(double), ALIGNSIZE); #endif . . . #ifndef USE_HBW _mm_free(A); _mm_free(B); _mm_free(C); #else hbw_free(A); hbw_free(B); _mm_free(C); #endif . . .\n\nNote\n\n- In order to compile your application with high bandwidth memory allocations LD_LIBRARY_PATH environment variable must be updated to include paths to memkind and jemalloc libraries\n\n- For example: $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/build/memkind/lib:$HOME/build/jemalloc/lib\n\nSimulation of low bandwidth and high bandwidth performance gap\n\nFigure 8. Simulating KNL NUMA behavior using 2 socket Intel® Xeon®\n\nAt this time, since we do not have access to actual KNL hardware, we will study the behavior of high bandwidth memory using the concept of Non Uniform Memory Access (NUMA). We simulate the scenario of low bandwidth and high bandwidth regions by allocating and accessing arrays from two separate NUMA nodes (i.e. near memory and far memory).\n\nExample:\n\nLets first compile and execute simpleDAXPY without use of high bandwidth memory allocations. Here we bind the application to socket 1 and bind all the memory allocations to Socket 2.\n\n$ icc -g -O3 -o simpleDAXPY_ddr simpleDAXPY.c -openmp –lpthread $ numactl --membind=1 --cpunodebind=0 ./simpleDAXPY_ddr 512 5 //Output Running with selected parameters: No. of Vector Elements : 512M Repetitions = 5 Threads = 16 Time - DAXPY (ms): 4074 Time – SWAP_LOW_HIGH (ms): 2051\n\nSet the NUMA node 0 (Socket 0) as High Bandwidth Memory Node as follows:\n\n$ export MEMKIND_HBW_NODES=0\n\nNote\n\n- Explicit configuration of HBW node is only required for simulation. In presence of actual high bandwidth memory (MCDRAM) MEMKIND library will be automatically able to identify high bandwidth memory nodes\n\nNow we will compile and execute simpleDAXPY with high bandwidth allocations using the memkind library as follows. Since we bind memory allocations to node 1 (i.e. socket 1) and bind application to node 0 (i.e. socket 0), by default all the allocations are done in far memory and the memory on NUMA node 0 is selected for allocations only if high bandwidth allocations are explicitly done using hbw_malloc* calls. This simulates the KNL behavior which we might observe when MCDRAM is configured in flat or hybrid mode.\n\n$ icc -O3 -DUSE_HBM -I$HOME/build/memkind/include -L$HOME/build/memkind/lib/ -L$HOME/build/jemalloc/lib/ -o simpleDAXPY_hbm simpleDAXPY.c -openmp -lmemkind -ljemalloc -lnuma -lpthread $ numactl --membind=1 --cpunodebind=0 ./simpleDAXPY_hbm 512 5 //Output Running with selected parameters: No. of Vector Elements : 512M Repetitions = 5 Allocating array A in High Bandwidth Memory Allocating array B in High Bandwidth Memory Threads = 16 Time - DAXPY (ms): 2355 Time – SWAP_LOW_HIGH (ms): 2068\n\nNote\n\n- The above performance improvement reported here is due to both reduced latency and improved bandwidth\n\n- At the time this white paper was written, difference in execution times with and without hbw_malloc could only be observed on systems with RHEL* 7.0 and later. This could be because of some software bug in handling membind for operating systems before RHEL* 7.0\n\n4.4 Other Optimization Techniques\n\nIn addition to better scaling, increased vectorization intensity and exploring high bandwidth memory, there are a number of possible user-level optimizations which can be applied to improve application performance. These advanced techniques proved successful for the first generation of Intel® Xeon Phi™ coprocessors and should be helpful for application development on the Intel® Xeon Phi™ x200 product family as well. Some of these optimizations aid compilers while others involve restructuring code to extract additional performance for your application. In order to achieve peak performance, the following optimizations should be kept in mind:\n\n5. References\n\nIntel® Xeon Phi™ Coprocessor code named “Knights Landing” - Application Readiness (https://software.intel.com/en-us/articles/intel-xeon-phi-coprocessor-code-named-knights-landing-application-readiness)\n\nWhat disclosures has Intel made about Knights Landing (https://software.intel.com/en-us/articles/what-disclosures-has-intel-made-about-knights-landing)\n\nAn Overview of Programming for Intel® Xeon® processors and Intel® Xeon Phi™ coprocessors (https://software.intel.com/sites/default/files/article/330164/an-overview-of-programming-for-intel-xeon-processors-and-intel-xeon-phi-coprocessors_1.pdf)\n\nKnights Corner: Your Path to Knights Landing (https://software.intel.com/en-us/videos/knights-corner-your-path-to-knights-landing)\n\nIntel® Software Development Emulator (https://software.intel.com/en-us/articles/intel-software-development-emulator)\n\nIntel® Architecture Instruction Set Extensions Programming Reference - Intel® AVX-512 is detailed in Chapters 2-7 (https://software.intel.com/en-us/intel-architecture-instruction-set-extensions-programming-reference)\n\nAVX-512 Instructions (https://software.intel.com/en-us/blogs/2013/avx-512-instructions)\n\nHigh Bandwidth Memory (HBM): how will it benefit your application? (https://software.intel.com/en-us/articles/high-bandwidth-memory-hbm-how-will-it-benefit-your-application)\n\nGitHub - memkind and jemalloc (https://github.com/memkind)\n\nAppendix A – HBWMALLOC\n\nNAME hbwmalloc - The high bandwidth memory interface SYNOPSIS #include <hbwmalloc.h> Link with -ljemalloc -lnuma -lmemkind -lpthread int hbw_check_available(void); void* hbw_malloc(size_t size); void* hbw_calloc(size_t nmemb, size_t size); void* hbw_realloc (void *ptr, size_t size); void hbw_free(void *ptr); int hbw_posix_memalign(void **memptr, size_t alignment, size_t size); int hbw_posix_memalign_psize(void **memptr, size_t alignment, size_t size, int pagesize); int hbw_get_policy(void); void hbw_set_policy(int mode);\n\nInstalling jemalloc\n\n//jemalloc and memkind can be downloaded from https://github.com/memkind $ unzip jemalloc-memkind.zip $ cd jemalloc-memkind $ autoconf $ mkdir obj $ cd obj/ $ ../configure --enable-autogen --with-jemalloc-prefix=je_ --enable-memkind --enable-safe --enable-cc-silence --prefix=$HOME/build/jemalloc $ make $ make build_doc $ make install\n\nInstalling memkind\n\n$ unzip memkind-master.zip $ cd memkind-master $ ./autogen.sh $ ./configure --prefix=$HOME/build/memkind --with-jemalloc=$HOME/build/jemalloc $ make && make install\n\nUpdate LD_LIBRARY_PATH to include locations of memkind and jemalloc\n\nAppendix B – simpleDAXPY.c\n\n/* * Copyright (c) 2015 Intel Corporation. * Intel Corporation All Rights Reserved. * * Portions of the source code contained or described herein and all documents related * to portions of the source code (\"Material\") are owned by Intel Corporation or its * suppliers or licensors. Title to the Material remains with Intel * Corporation or its suppliers and licensors. The Material contains trade * secrets and proprietary and confidential information of Intel or its * suppliers and licensors. The Material is protected by worldwide copyright * and trade secret laws and treaty provisions. No part of the Material may * be used, copied, reproduced, modified, published, uploaded, posted, * transmitted, distributed, or disclosed in any way without Intel's prior * express written permission. * * No license under any patent, copyright, trade secret or other intellectual * property right is granted to or conferred upon you by disclosure or * delivery of the Materials, either expressly, by implication, inducement, * estoppel or otherwise. Any license under such intellectual property rights * must be express and approved by Intel in writing. */ #include<stdio.h> #include<stdlib.h> #include<sys/time.h> #include<omp.h> #define ALIGNSIZE 64 //A simple DAXPY kernel void run_daxpy(double A[], double PI, double B[], unsigned long vectorSize){ unsigned long i = 0; #pragma omp parallel for simd for(i=0; i<vectorSize; i++){ B[i] = PI*A[i] + B[i]; } return; } //Rearranging Odd and Even Position into Low and High Vectors void swap_low_and_high(unsigned long vectorSize, double C[]){ unsigned long i = 0, j=0; unsigned long half = vectorSize/2; double temp = 0.0; #pragma omp parallel for private(temp) for(i=0, j=half; i<half; i+=2, j+=2){ temp = C[i+1]; C[i+1] = C[half]; C[half] = temp; } return; } int main (int argc, char * argv[]){ struct timeval tBefore, tAfter; unsigned long timeDAXPY = 0,timeAverage=0; unsigned long i = 0; unsigned int j = 0; unsigned long limit = 0; unsigned int repetitions = 0; if (argc < 3){ printf(\"Enter Number of Elements in Millions and number of repetitions\\nEg: ./simpleDAXPY 64 5\\n\"); printf(\"Running with default settings:\\n\"); printf(\"No. of Vector Elements : 64M\\nRepetitions = 1\\n\"); limit = 64 * 1024 * 1024; repetitions = 1; } else { limit = atoi(argv[1]) * 1024 * 1024; repetitions = atoi(argv[2]); printf(\"Running with selected parameters:\\n\"); printf(\"No. of Vector Elements : %dM\\nRepetitions = %d\\n\", atoi(argv[1]), atoi(argv[2])); } #ifndef USE_HBW double *A = (double *)_mm_malloc(limit * sizeof(double),ALIGNSIZE); double *B = (double *)_mm_malloc(limit * sizeof(double), ALIGNSIZE); double *C = (double *)_mm_malloc(limit * sizeof(double), ALIGNSIZE); #else double *A, *B, *C; //Allocating A and B in High Bandwidth Memory hbw_posix_memalign((void**)(&(A)), ALIGNSIZE, limit*sizeof(double)); if(A == NULL){ printf(\"Unable to allocate on HBM: A\"); } printf(\"Allocating array A in High Bandwidth Memory\\n\"); hbw_posix_memalign((void**)(&(B)), ALIGNSIZE, limit*sizeof(double)); if(B == NULL){ printf(\"Unable to allocate on HBM: B\"); } printf(\"Allocating array B in High Bandwidth Memory\\n\"); C = (double *)_mm_malloc(limit * sizeof(double), ALIGNSIZE); #endif #pragma omp parallel for simd for(i=0; i<limit; i++){ A[i] = (double)1.0*i; B[i] = (double)2.0*i; C[i] = (double)4.0*i; } double PI = (double)22/7; printf(\"Threads = %d\\n\", omp_get_max_threads()); for(j = 0; j<repetitions; j++){ gettimeofday(&tBefore, NULL); run_daxpy(A, PI*(j+1), B, limit); gettimeofday(&tAfter, NULL); timeDAXPY += ((tAfter.tv_sec - tBefore.tv_sec)*1000L +(tAfter.tv_usec - tBefore.tv_usec)/1000); gettimeofday(&tBefore, NULL); swap_low_and_high(limit, C); gettimeofday(&tAfter, NULL); timeAverage += ((tAfter.tv_sec - tBefore.tv_sec)*1000L +(tAfter.tv_usec - tBefore.tv_usec)/1000); } printf(\"Time - DAXPY (ms): %ld\\n\", timeDAXPY); printf(\"Time – SWAP_LOW_HIGH (ms): %ld\\n\", timeAverage); #ifndef USE_HBW _mm_free(A); _mm_free(B); _mm_free(C); #else hbw_free(A); hbw_free(B); _mm_free(C); #endif return 1; }\n\n[1] This diagram is for conceptual purposes only and only illustrates a processor and memory – it is not to scale and does not include all functional areas of the processor, nor does it represent actual component layout. All products, computer systems, dates and figures specified are preliminary based on current expectations, and are subject to change without notice.\n\n[2] Projected result based on internal Intel analysis using estimated performance and power consumption of a rack sized deployment of Intel® Xeon® processors and Knights Landing coprocessors as compared to a rack with Knights Landing processors only\n\n[3]Instruction mix report for AVX2 was generated using non OpenMP version of the code. At this time, the version of SDE available externally fails to generate instruction mix report when used with \"-hsw\" flag and OpenMP. This issue is fixed and will be released in next version of SDE.\n\n[4] SIMD – Single Instruction Multiple Data\n\n2 Socket 14 core Intel® Xeon® CPU E5-2697 v3 @ 2.60GHz\n\n4 DDR channels per socket\n\nRed Hat* Enterprise Linux Server release 7.0\n\n[7]LLC – Last Level Cache\n\nTransforming the UI—Designing Tomorrow’s Interface Today (5 of 5):\n\nNatural Interaction with Intuitive Computer Control\n\nBy Dominic Milano\n\nHuman-like senses on devices with Intel® RealSense™ technology are broadening perceptual computing. Explore apps that will let you navigate through virtual worlds with gestures and words.\n\nAdvances in perceptual computing are bringing human-like senses to devices. Able to see and hear the world around them, devices equipped with Intel® RealSense™ technology recognize hand and finger gestures, analyze facial expressions, understand and synthesize spoken words, and more. As a result, people are enjoying more natural interactivity—pushing, pulling, lifting, and grabbing virtual objects; starting, stopping, and pausing content creation and entertainment apps; and navigating virtual worlds without touching their devices.\n\nIn this article, the last in a five-part series, the Virtual Air Guitar Company (VAGC) and Intel software developers share insights on using Intel RealSense technology to move human-computer interaction (HCI) beyond the keyboard and mouse.\n\nVirtual Air Guitar Company\n\nFounded in 2006 by computer vision and virtual reality researchers based in Espoo, Finland, VAGC specializes in creating unique motion games and applications that utilize full-body actions and precise fingertip control. The indie studio’s portfolio includes console and PC games as well as Windows* and Android*perceptual computing applications.\n\nFor Aki Kanerva, lead designer and founder, the natural interaction (NI) models enabled by Intel RealSense technology make computer use easier and more enjoyable. Although most of us learned to use computers that relied on traditional keyboard and mouse or trackpad-based interaction, touch screens opened a world of new possibilities. “Give a touch-screen device to a two-year-old and they’ll be able to use it almost immediately,” Kanerva said. “There’s no learning curve to speak of, which makes devices more fun to use. And even for serious tasks, you can work more intuitively.”\n\nWhether you’re using a mouse, trackpad, or touch screen, the interaction takes place in two dimensions. Natural interaction based on gestures or voice commands provides a greater degree of freedom. When gesturing with your hands, you’re in 3D space, which gives six degrees of freedom and enables new use cases. “Let’s say you’re cooking or using a public terminal and don’t want to touch the device. Gesture and voice commands provide touch-free interaction,” said Kanerva.\n\nNatural interaction can also be used to perform complex tasks, eliminating the need to memorize keyboard shortcuts. Or as Kanerva put it, “Natural interaction enables complex controls without being complicated.”\n\nSimple Isn’t Easy\n\nKanerva spent years researching human-computer interaction models and knows from experience how difficult it can be to distill complex tasks and make them appear easy to do. The mouse and keyboard act as middlemen and translate user intention. In a game, for example, moving a mouse left or right could translate to directing a character’s movement. “It takes practice to correctly make that motion.” Kanerva said. “With natural interaction, you’re removing the middlemen. With five or six degrees of freedom, tracking the moves you make with your hands—up, down, left, right, forward, back—translates to character motion on the screen in a more intuitive manner.”\n\n“A ‘natural interface’ can combine all six degrees of movement in such a way that the user never has to think about individual commands,” he continued. Creating a UI that responds to such a complex set of user actions is no simple feat. And Kanerva advises against designing UIs capable of responding to every possible motion.\n\nThe key is to create experiences in which the interface lets the users know what they can do before they do it. “Limit interaction to only the things that are necessary for your application, and focus your coding efforts on making those things feel responsive.”\n\nWorking with Intel, VAGC is developing an app that will let users fly a virtual helicopter through any location (Figure 1) using hand gestures tracked with an Intel®RealSense™ 3D camera. “By design, our helicopter cannot do barrel rolls—rotate around its axis. That could be fun, but adding a control for doing such a roll would have overlapped with the other controls, so we didn’t include that capability.”\n\nFigure 1: The Helicopter’s Point of View\n\nAnatomy of the Gesture-controlled App\n\nThe Web-based app will be for Microsoft Internet Explorer, Google Chrome, and Mozilla Firefox on Windows*. The app uses a browser extension to provide localization services, was written in JavaScript and HTML, and runs in the browser. Its code is reliable and lightweight.\n\n“This project has a lot of moving parts,” Kanerva explained. “The Web itself is a moving target, especially when it comes to extensions because we needed to write a different extension for each supported browser.”\n\nIntel supplied VAGC with invaluable feedback and VAGC reciprocated by demonstrating real use cases that helped the Intel team refine the Intel RealSense SDK. “One of the early challenges with the SDK was that it had difficulty seeing a flat hand held vertically,” Kanerva explained (see Figure 2). “You cannot prevent a user from doing that.” Thanks to VAGC’s input, the latest version of the SDK supports that condition.\n\nFigure 2: Camera view of vertical flat hand\n\nTesting, Testing, Testing\n\nPrevious motion games by VAGC employed a proprietary automated test suite, but Kanerva prefers a different tact when testing gesture interaction. “With natural interaction, users have a knack for doing the unexpected, so we hire a usability testing firm.” Kanerva said that the best results come from shooting video of experienced and inexperienced users playing through the flight.\n\nTutorials, in spite of being expensive to produce, are an essential ingredient for NI projects. “Because the range of possible movements is so broad, you need very clear tutorials or animations that give users a starting point,” Kanerva said. “Put hand here. Hold in position 30cm (12 inches) from the screen. Now do this... You must be very specific.” Kanerva advises developers to plan tutorials early in the design process. “It’s tempting to leave tutorials to the last minute, but they are critical. Even if you need to change them several times throughout your development workflow, tutorials should be an integral part of your process.”\n\nLessons Learned\n\nSummarizing his experience with the Intel RealSense SDK and Intel RealSense3D camera, Kanerva offered these rules of thumb for developers:\n\nDesign applications that don’t lend themselves to—or aren’t even possible with— traditional input modalities.\n\nEmulating traditional input is a license for disaster.\n\nDesign natural interactions specific to your use case.\n\nFor control devices in flight simulator designs, arrow keys aren’t as effective as joysticks, and gesture control is an effective alternative.\n\nTry to be continuous and minimize control latency.\n\nDon’t wait long or expect a gesture to be complete before translating motion into your experience.\n\nProvide immediate feedback—user input should be reflected on screen at all times.\n\nRemember not to fatigue your users.\n\nFor game developers, continuous feedback is key—games typically use button pushes to produce actions. Mapping traditional game input to natural interaction creates too much latency and requires a steep learning curve.\n\nRegarding fatigue, Kanerva counsels that you design controls that don’t require a user to be still for a long time. “I like the term ‘motion control,’ because it’s a reminder that you want users to move around so they’re not getting tired. We don’t ask users to rotate their wrist at right angles. For example, to fly forward, they simply point the hand straight while keeping it relaxed. Avoid strain and remind users it’s their responsibility to take breaks.”\n\nNatural Entertainment\n\n“Natural interaction is great for entertainment apps,” Kanerva concluded. His company got its name from their first app, which let users play air-guitar chords and solos using nothing more than hand gestures. “Hollywood often depicts people using gestures to browse data. It looks cool and there’s a wow factor, but simplicity driven by natural interaction will make computing accessible to a wider user base.”\n\nTo that end, the idea of having Intel RealSense technology embedded in tablets, 2 in 1s, and all-in-one devices thrills Kanerva. “Ubiquitous access to natural interaction through Intel RealSense technology will be great for marketing and sales, but it will be priceless to developers.”\n\nDriving Windows with Hand Gestures\n\nYinon Oshrat spent seven years at Omek Studio, the first developer to use the nascent Intel RealSense SDK, before being purchased by Intel. As a member of the Intel RealSense software development team, Oshrat has been working on a standalone application called Intel® RealSense™ Navigator. “Intel RealSense Navigator controls the Windows UI, enhancing current touch-based experiences and enabling hand gesture-based interaction.” The app allows users to launch programs and scroll through selections using hand gestures (Figure 3).\n\nFigure 3: Natural human-computer interaction\n\nIntel RealSense Navigator relies on the Intel® RealSense™ 3D Camera to track hand gestures at distances up to 60 cm (24 inches). “Think of Navigator as a driver and a mouse,” Oshrat said. “It’s an active controller. To use it, you simply enable it for zooming, mouse simulation, and so on.”\n\nBuilding Blocks for Developers\n\nIn creating Intel RealSense Navigator, the Intel team has been providing building blocks for the Intel RealSense SDK that will give developers the ability to implement the same experiences that Navigator enables in other standalone Windows applications.\n\nLike other modules of the Intel RealSense SDK, the Intel RealSense Navigator module is in both C and C++. JavaScript support is planned for a future release.\n\nDescribing Intel RealSense Navigator gesture support, Oshrat said, “Think of it as a language. Tap to select. Pinch to grab. Move left or right to scroll. Move hand forward or back to zoom in or out. A hand wave returns users to the Start Screen.” Intel RealSense Navigator ships with video tutorials that demonstrate how to make accurate hand gestures. “The videos are much more effective than written documentation.”\n\nInventing a Language\n\nFor more than a year, Oshrat and his colleagues designed and tested gestures by literally approaching people on the street and watching them react to a particular motion. “We worked in cycles, experimenting with what worked, what users’ expectations were versus what we thought they’d be. We discovered what felt natural and what didn’t.”\n\nFor example, people interpreted three “swipes” in a row as a “wave” and not a swipe. “That taught us to separate those gestures,” Oshrat said. It surprised him that defining effective gestures was so difficult. “It’s not programming. It’s working with user experiences.”\n\nLessons Learned\n\nFor developers interested in implementing gesture control in their applications using Intel RealSense Navigator, Oshrat offered this advice:\n\nUtilize the gesture models and building blocks supplied with the SDK; they will save you time by jump-starting your project with ideas that have been carefully vetted.\n\nTake advantage of Intel support channels such as user forums.\n\nLike Aki Kanerva, Oshrat advises developers to think of gesture-based interaction a"
    }
}