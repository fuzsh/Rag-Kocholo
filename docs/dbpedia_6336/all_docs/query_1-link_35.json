{
    "id": "dbpedia_6336_1",
    "rank": 35,
    "data": {
        "url": "https://worldwidescience.org/topicpages/b/barcelona%2Bsupercomputing%2Bcenter.html",
        "read_more_link": "",
        "language": "en",
        "title": "barcelona supercomputing center: Topics by WorldWideScience.org",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/WWSlogo_wTag650px-min.png",
            "https://worldwidescience.org/topicpages/b/images/arrow-up.gif",
            "https://worldwidescience.org/topicpages/b/images/arrow-down.gif",
            "https://worldwidescience.org/topicpages/b/images/arrow-up.gif",
            "https://worldwidescience.org/topicpages/b/images/arrow-down.gif",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/OSTIlogo.svg",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/ICSTIlogo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Dust modelling and forecasting in the Barcelona Supercomputing Center: Activities and developments\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nPerez, C; Baldasano, J M; Jimenez-Guerrero, P; Jorba, O; Haustein, K; Basart, S [Earth Sciences Department. Barcelona Supercomputing Center. Barcelona (Spain); Cuevas, E [Izanaa Atmospheric Research Center. Agencia Estatal de Meteorologia, Tenerife (Spain); Nickovic, S [Atmospheric Research and Environment Branch, World Meteorological Organization, Geneva (Switzerland)], E-mail: carlos.perez@bsc.es\n\n2009-03-01\n\nThe Barcelona Supercomputing Center (BSC) is the National Supercomputer Facility in Spain, hosting MareNostrum, one of the most powerful Supercomputers in Europe. The Earth Sciences Department of BSC operates daily regional dust and air quality forecasts and conducts intensive modelling research for short-term operational prediction. This contribution summarizes the latest developments and current activities in the field of sand and dust storm modelling and forecasting.\n\nDust modelling and forecasting in the Barcelona Supercomputing Center: Activities and developments\n\nInternational Nuclear Information System (INIS)\n\nPerez, C; Baldasano, J M; Jimenez-Guerrero, P; Jorba, O; Haustein, K; Basart, S; Cuevas, E; Nickovic, S\n\n2009-01-01\n\nThe Barcelona Supercomputing Center (BSC) is the National Supercomputer Facility in Spain, hosting MareNostrum, one of the most powerful Supercomputers in Europe. The Earth Sciences Department of BSC operates daily regional dust and air quality forecasts and conducts intensive modelling research for short-term operational prediction. This contribution summarizes the latest developments and current activities in the field of sand and dust storm modelling and forecasting.\n\nKAUST Supercomputing Laboratory\n\nKAUST Repository\n\nBailey, April Renee\n\n2011-11-15\n\nKAUST has partnered with IBM to establish a Supercomputing Research Center. KAUST is hosting the Shaheen supercomputer, named after the Arabian falcon famed for its swiftness of flight. This 16-rack IBM Blue Gene/P system is equipped with 4 gigabyte memory per node and capable of 222 teraflops, making KAUST campus the site of one of the worldâs fastest supercomputers in an academic environment. KAUST is targeting petaflop capability within 3 years.\n\nKAUST Supercomputing Laboratory\n\nKAUST Repository\n\nBailey, April Renee; Kaushik, Dinesh; Winfer, Andrew\n\n2011-01-01\n\nKAUST has partnered with IBM to establish a Supercomputing Research Center. KAUST is hosting the Shaheen supercomputer, named after the Arabian falcon famed for its swiftness of flight. This 16-rack IBM Blue Gene/P system is equipped with 4 gigabyte memory per node and capable of 222 teraflops, making KAUST campus the site of one of the worldâs fastest supercomputers in an academic environment. KAUST is targeting petaflop capability within 3 years.\n\nSupercomputing Centers and Electricity Service Providers\n\nDEFF Research Database (Denmark)\n\nPatki, Tapasya; Bates, Natalie; Ghatikar, Girish\n\n2016-01-01\n\nfrom a detailed, quantitative survey-based analysis and compare the perspectives of the European grid and SCs to the ones of the United States (US). We then show that contrary to the expectation, SCs in the US are more open toward cooperating and developing demand-management strategies with their ESPs......Supercomputing Centers (SCs) have high and variable power demands, which increase the challenges of the Electricity Service Providers (ESPs) with regards to efficient electricity distribution and reliable grid operation. High penetration of renewable energy generation further exacerbates...... this problem. In order to develop a symbiotic relationship between the SCs and their ESPs and to support effective power management at all levels, it is critical to understand and analyze how the existing relationships were formed and how these are expected to evolve. In this paper, we first present results...\n\nAn assessment of worldwide supercomputer usage\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nWasserman, H.J.; Simmons, M.L.; Hayes, A.H.\n\n1995-01-01\n\nThis report provides a comparative study of advanced supercomputing usage in Japan and the United States as of Spring 1994. It is based on the findings of a group of US scientists whose careers have centered on programming, evaluating, and designing high-performance supercomputers for over ten years. The report is a follow-on to an assessment of supercomputing technology in Europe and Japan that was published in 1993. Whereas the previous study focused on supercomputer manufacturing capabilities, the primary focus of the current work was to compare where and how supercomputers are used. Research for this report was conducted through both literature studies and field research in Japan.\n\nA training program for scientific supercomputing users\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nHanson, F.; Moher, T.; Sabelli, N.; Solem, A.\n\n1988-01-01\n\nThere is need for a mechanism to transfer supercomputing technology into the hands of scientists and engineers in such a way that they will acquire a foundation of knowledge that will permit integration of supercomputing as a tool in their research. Most computing center training emphasizes computer-specific information about how to use a particular computer system; most academic programs teach concepts to computer scientists. Only a few brief courses and new programs are designed for computational scientists. This paper describes an eleven-week training program aimed principally at graduate and postdoctoral students in computationally-intensive fields. The program is designed to balance the specificity of computing center courses, the abstractness of computer science courses, and the personal contact of traditional apprentice approaches. It is based on the experience of computer scientists and computational scientists, and consists of seminars and clinics given by many visiting and local faculty. It covers a variety of supercomputing concepts, issues, and practices related to architecture, operating systems, software design, numerical considerations, code optimization, graphics, communications, and networks. Its research component encourages understanding of scientific computing and supercomputer hardware issues. Flexibility in thinking about computing needs is emphasized by the use of several different supercomputer architectures, such as the Cray X/MP48 at the National Center for Supercomputing Applications at University of Illinois at Urbana-Champaign, IBM 3090 600E/VF at the Cornell National Supercomputer Facility, and Alliant FX/8 at the Advanced Computing Research Facility at Argonne National Laboratory. 11 refs., 6 tabs.\n\nComputational fluid dynamics research at the United Technologies Research Center requiring supercomputers\n\nScience.gov (United States)\n\nLandgrebe, Anton J.\n\n1987-01-01\n\nAn overview of research activities at the United Technologies Research Center (UTRC) in the area of Computational Fluid Dynamics (CFD) is presented. The requirement and use of various levels of computers, including supercomputers, for the CFD activities is described. Examples of CFD directed toward applications to helicopters, turbomachinery, heat exchangers, and the National Aerospace Plane are included. Helicopter rotor codes for the prediction of rotor and fuselage flow fields and airloads were developed with emphasis on rotor wake modeling. Airflow and airload predictions and comparisons with experimental data are presented. Examples are presented of recent parabolized Navier-Stokes and full Navier-Stokes solutions for hypersonic shock-wave/boundary layer interaction, and hydrogen/air supersonic combustion. In addition, other examples of CFD efforts in turbomachinery Navier-Stokes methodology and separated flow modeling are presented. A brief discussion of the 3-tier scientific computing environment is also presented, in which the researcher has access to workstations, mid-size computers, and supercomputers.\n\nTOP500 Supercomputers for November 2003\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nStrohmaier, Erich; Meuer, Hans W.; Dongarra, Jack; Simon, Horst D.\n\n2003-11-16\n\n22nd Edition of TOP500 List of World s Fastest Supercomputers Released MANNHEIM, Germany; KNOXVILLE, Tenn.; BERKELEY, Calif. In what has become a much-anticipated event in the world of high-performance computing, the 22nd edition of the TOP500 list of the worlds fastest supercomputers was released today (November 16, 2003). The Earth Simulator supercomputer retains the number one position with its Linpack benchmark performance of 35.86 Tflop/s (''teraflops'' or trillions of calculations per second). It was built by NEC and installed last year at the Earth Simulator Center in Yokohama, Japan.\n\nPublisher Correction\n\nDEFF Research Database (Denmark)\n\nBonÃ s-Guarch, SÃ­lvia; Guindo-MartÃ­nez, Marta; Miguel-Escalada, Irene\n\n2018-01-01\n\nIn the originally published version of this Article, the affiliation details for Santi GonzÃ¡lez, Jian'an Luan and Claudia Langenberg were inadvertently omitted. Santi GonzÃ¡lez should have been affiliated with 'Barcelona Supercomputing Center (BSC), Joint BSC-CRG-IRB Research Program in Computatio......In the originally published version of this Article, the affiliation details for Santi GonzÃ¡lez, Jian'an Luan and Claudia Langenberg were inadvertently omitted. Santi GonzÃ¡lez should have been affiliated with 'Barcelona Supercomputing Center (BSC), Joint BSC-CRG-IRB Research Program...\n\nFirst Barcelona Conference on Epigenetics and Cancer\n\nScience.gov (United States)\n\nPalau, Anna; Perucho, Manuel; Esteller, Manel; Buschbeck, Marcus\n\n2014-01-01\n\nThe Barcelona Conference on Epigenetics and Cancer (BCEC) entitled âChallenges, opportunities and perspectivesâ took place November 21â22, 2013 in Barcelona. The 2013 BCEC is the first edition of a series of annual conferences jointly organized by five leading research centers in Barcelona. These centers are the Institute of Predictive and Personalized Medicine of Cancer (IMPPC), the Biomedical Campus Bellvitge with its Program of Epigenetics and Cancer Biology (PEBC), the Centre for Genomic Regulation (CRG), the Institute for Biomedical Research (IRB), and the Molecular Biology Institute of Barcelona (IBMB). Manuel Perucho and Marcus Buschbeck from the Institute of Predictive and Personalized Medicine of Cancer put together the scientific program of the first conference broadly covering all aspects of epigenetic research ranging from fundamental molecular research to drug and biomarker development and clinical application. In one and a half days, 23 talks and 50 posters were presented to a completely booked out audience counting 270 participants. PMID:24413145\n\nAssessment techniques for a learning-centered curriculum: evaluation design for adventures in supercomputing\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nHelland, B. [Ames Lab., IA (United States); Summers, B.G. [Oak Ridge National Lab., TN (United States)\n\n1996-09-01\n\nAs the classroom paradigm shifts from being teacher-centered to being learner-centered, student assessments are evolving from typical paper and pencil testing to other methods of evaluation. Students should be probed for understanding, reasoning, and critical thinking abilities rather than their ability to return memorized facts. The assessment of the Department of Energy`s pilot program, Adventures in Supercomputing (AiS), offers one example of assessment techniques developed for learner-centered curricula. This assessment has employed a variety of methods to collect student data. Methods of assessment used were traditional testing, performance testing, interviews, short questionnaires via email, and student presentations of projects. The data obtained from these sources have been analyzed by a professional assessment team at the Center for Children and Technology. The results have been used to improve the AiS curriculum and establish the quality of the overall AiS program. This paper will discuss the various methods of assessment used and the results.\n\nIntegration of Panda Workload Management System with supercomputers\n\nScience.gov (United States)\n\nDe, K.; Jha, S.; Klimentov, A.; Maeno, T.; Mashinistov, R.; Nilsson, P.; Novikov, A.; Oleynik, D.; Panitkin, S.; Poyda, A.; Read, K. F.; Ryabinkin, E.; Teslyuk, A.; Velikhov, V.; Wells, J. C.; Wenaus, T.\n\n2016-09-01\n\nThe Large Hadron Collider (LHC), operating at the international CERN Laboratory in Geneva, Switzerland, is leading Big Data driven scientific explorations. Experiments at the LHC explore the fundamental nature of matter and the basic forces that shape our universe, and were recently credited for the discovery of a Higgs boson. ATLAS, one of the largest collaborations ever assembled in the sciences, is at the forefront of research at the LHC. To address an unprecedented multi-petabyte data processing challenge, the ATLAS experiment is relying on a heterogeneous distributed computational infrastructure. The ATLAS experiment uses PanDA (Production and Data Analysis) Workload Management System for managing the workflow for all data processing on over 140 data centers. Through PanDA, ATLAS physicists see a single computing facility that enables rapid scientific breakthroughs for the experiment, even though the data centers are physically scattered all over the world. While PanDA currently uses more than 250000 cores with a peak performance of 0.3+ petaFLOPS, next LHC data taking runs will require more resources than Grid computing can possibly provide. To alleviate these challenges, LHC experiments are engaged in an ambitious program to expand the current computing model to include additional resources such as the opportunistic use of supercomputers. We will describe a project aimed at integration of PanDA WMS with supercomputers in United States, Europe and Russia (in particular with Titan supercomputer at Oak Ridge Leadership Computing Facility (OLCF), Supercomputer at the National Research Center \"Kurchatov Institute\", IT4 in Ostrava, and others). The current approach utilizes a modified PanDA pilot framework for job submission to the supercomputers batch queues and local data management, with light-weight MPI wrappers to run singlethreaded workloads in parallel on Titan's multi-core worker nodes. This implementation was tested with a variety of Monte-Carlo workloads\n\nWhat is supercomputing ?\n\nInternational Nuclear Information System (INIS)\n\nAsai, Kiyoshi\n\n1992-01-01\n\nSupercomputing means the high speed computation using a supercomputer. Supercomputers and the technical term ''supercomputing'' have spread since ten years ago. The performances of the main computers installed so far in Japan Atomic Energy Research Institute are compared. There are two methods to increase computing speed by using existing circuit elements, parallel processor system and vector processor system. CRAY-1 is the first successful vector computer. Supercomputing technology was first applied to meteorological organizations in foreign countries, and to aviation and atomic energy research institutes in Japan. The supercomputing for atomic energy depends on the trend of technical development in atomic energy, and the contents are divided into the increase of computing speed in existing simulation calculation and the acceleration of the new technical development of atomic energy. The examples of supercomputing in Japan Atomic Energy Research Institute are reported. (K.I.)\n\nTOP500 Supercomputers for June 2003\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nStrohmaier, Erich; Meuer, Hans W.; Dongarra, Jack; Simon, Horst D.\n\n2003-06-23\n\n21st Edition of TOP500 List of World's Fastest Supercomputers Released MANNHEIM, Germany; KNOXVILLE, Tenn.;&BERKELEY, Calif. In what has become a much-anticipated event in the world of high-performance computing, the 21st edition of the TOP500 list of the world's fastest supercomputers was released today (June 23, 2003). The Earth Simulator supercomputer built by NEC and installed last year at the Earth Simulator Center in Yokohama, Japan, with its Linpack benchmark performance of 35.86 Tflop/s (teraflops or trillions of calculations per second), retains the number one position. The number 2 position is held by the re-measured ASCI Q system at Los Alamos National Laboratory. With 13.88 Tflop/s, it is the second system ever to exceed the 10 Tflop/smark. ASCIQ was built by Hewlett-Packard and is based on the AlphaServerSC computer system.\n\nTOP500 Supercomputers for June 2002\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nStrohmaier, Erich; Meuer, Hans W.; Dongarra, Jack; Simon, Horst D.\n\n2002-06-20\n\n19th Edition of TOP500 List of World's Fastest Supercomputers Released MANNHEIM, Germany; KNOXVILLE, Tenn.;&BERKELEY, Calif. In what has become a much-anticipated event in the world of high-performance computing, the 19th edition of the TOP500 list of the worlds fastest supercomputers was released today (June 20, 2002). The recently installed Earth Simulator supercomputer at the Earth Simulator Center in Yokohama, Japan, is as expected the clear new number 1. Its performance of 35.86 Tflop/s (trillions of calculations per second) running the Linpack benchmark is almost five times higher than the performance of the now No.2 IBM ASCI White system at Lawrence Livermore National Laboratory (7.2 Tflop/s). This powerful leap frogging to the top by a system so much faster than the previous top system is unparalleled in the history of the TOP500.\n\nComprehensive efficiency analysis of supercomputer resource usage based on system monitoring data\n\nScience.gov (United States)\n\nMamaeva, A. A.; Shaykhislamov, D. I.; Voevodin, Vad V.; Zhumatiy, S. A.\n\n2018-03-01\n\nOne of the main problems of modern supercomputers is the low efficiency of their usage, which leads to the significant idle time of computational resources, and, in turn, to the decrease in speed of scientific research. This paper presents three approaches to study the efficiency of supercomputer resource usage based on monitoring data analysis. The first approach performs an analysis of computing resource utilization statistics, which allows to identify different typical classes of programs, to explore the structure of the supercomputer job flow and to track overall trends in the supercomputer behavior. The second approach is aimed specifically at analyzing off-the-shelf software packages and libraries installed on the supercomputer, since efficiency of their usage is becoming an increasingly important factor for the efficient functioning of the entire supercomputer. Within the third approach, abnormal jobs â jobs with abnormally inefficient behavior that differs significantly from the standard behavior of the overall supercomputer job flow â are being detected. For each approach, the results obtained in practice in the Supercomputer Center of Moscow State University are demonstrated.\n\nApplications of supercomputing and the utility industry: Calculation of power transfer capabilities\n\nInternational Nuclear Information System (INIS)\n\nJensen, D.D.; Behling, S.R.; Betancourt, R.\n\n1990-01-01\n\nNumerical models and iterative simulation using supercomputers can furnish cost-effective answers to utility industry problems that are all but intractable using conventional computing equipment. An example of the use of supercomputers by the utility industry is the determination of power transfer capability limits for power transmission systems. This work has the goal of markedly reducing the run time of transient stability codes used to determine power distributions following major system disturbances. To date, run times of several hours on a conventional computer have been reduced to several minutes on state-of-the-art supercomputers, with further improvements anticipated to reduce run times to less than a minute. In spite of the potential advantages of supercomputers, few utilities have sufficient need for a dedicated in-house supercomputing capability. This problem is resolved using a supercomputer center serving a geographically distributed user base coupled via high speed communication networks\n\nAutomatic discovery of the communication network topology for building a supercomputer model\n\nScience.gov (United States)\n\nSobolev, Sergey; Stefanov, Konstantin; Voevodin, Vadim\n\n2016-10-01\n\nThe Research Computing Center of Lomonosov Moscow State University is developing the Octotron software suite for automatic monitoring and mitigation of emergency situations in supercomputers so as to maximize hardware reliability. The suite is based on a software model of the supercomputer. The model uses a graph to describe the computing system components and their interconnections. One of the most complex components of a supercomputer that needs to be included in the model is its communication network. This work describes the proposed approach for automatically discovering the Ethernet communication network topology in a supercomputer and its description in terms of the Octotron model. This suite automatically detects computing nodes and switches, collects information about them and identifies their interconnections. The application of this approach is demonstrated on the \"Lomonosov\" and \"Lomonosov-2\" supercomputers.\n\nSupercomputational science\n\nCERN Document Server\n\nWilson, S\n\n1990-01-01\n\nIn contemporary research, the supercomputer now ranks, along with radio telescopes, particle accelerators and the other apparatus of \"big science\", as an expensive resource, which is nevertheless essential for state of the art research. Supercomputers are usually provided as shar.ed central facilities. However, unlike, telescopes and accelerators, they are find a wide range of applications which extends across a broad spectrum of research activity. The difference in performance between a \"good\" and a \"bad\" computer program on a traditional serial computer may be a factor of two or three, but on a contemporary supercomputer it can easily be a factor of one hundred or even more! Furthermore, this factor is likely to increase with future generations of machines. In keeping with the large capital and recurrent costs of these machines, it is appropriate to devote effort to training and familiarization so that supercomputers are employed to best effect. This volume records the lectures delivered at a Summer School ...\n\nResearch center Juelich to install Germany's most powerful supercomputer new IBM System for science and research will achieve 5.8 trillion computations per second\n\nCERN Multimedia\n\n2002-01-01\n\n\"The Research Center Juelich, Germany, and IBM today announced that they have signed a contract for the delivery and installation of a new IBM supercomputer at the Central Institute for Applied Mathematics\" (1/2 page).\n\nEnabling department-scale supercomputing\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nGreenberg, D.S.; Hart, W.E.; Phillips, C.A.\n\n1997-11-01\n\nThe Department of Energy (DOE) national laboratories have one of the longest and most consistent histories of supercomputer use. The authors summarize the architecture of DOE`s new supercomputers that are being built for the Accelerated Strategic Computing Initiative (ASCI). The authors then argue that in the near future scaled-down versions of these supercomputers with petaflop-per-weekend capabilities could become widely available to hundreds of research and engineering departments. The availability of such computational resources will allow simulation of physical phenomena to become a full-fledged third branch of scientific exploration, along with theory and experimentation. They describe the ASCI and other supercomputer applications at Sandia National Laboratories, and discuss which lessons learned from Sandia`s long history of supercomputing can be applied in this new setting.\n\nTryton Supercomputer Capabilities for Analysis of Massive Data Streams\n\nDirectory of Open Access Journals (Sweden)\n\nKrawczyk Henryk\n\n2015-09-01\n\nFull Text Available The recently deployed supercomputer Tryton, located in the Academic Computer Center of Gdansk University of Technology, provides great means for massive parallel processing. Moreover, the status of the Center as one of the main network nodes in the PIONIER network enables the fast and reliable transfer of data produced by miscellaneous devices scattered in the area of the whole country. The typical examples of such data are streams containing radio-telescope and satellite observations. Their analysis, especially with real-time constraints, can be challenging and requires the usage of dedicated software components. We propose a solution for such parallel analysis using the supercomputer, supervised by the KASKADA platform, which with the conjunction with immerse 3D visualization techniques can be used to solve problems such as pulsar detection and chronometric or oil-spill simulation on the sea surface.\n\nCentralized supercomputer support for magnetic fusion energy research\n\nInternational Nuclear Information System (INIS)\n\nFuss, D.; Tull, G.G.\n\n1984-01-01\n\nHigh-speed computers with large memories are vital to magnetic fusion energy research. Magnetohydrodynamic (MHD), transport, equilibrium, Vlasov, particle, and Fokker-Planck codes that model plasma behavior play an important role in designing experimental hardware and interpreting the resulting data, as well as in advancing plasma theory itself. The size, architecture, and software of supercomputers to run these codes are often the crucial constraints on the benefits such computational modeling can provide. Hence, vector computers such as the CRAY-1 offer a valuable research resource. To meet the computational needs of the fusion program, the National Magnetic Fusion Energy Computer Center (NMFECC) was established in 1974 at the Lawrence Livermore National Laboratory. Supercomputers at the central computing facility are linked to smaller computer centers at each of the major fusion laboratories by a satellite communication network. In addition to providing large-scale computing, the NMFECC environment stimulates collaboration and the sharing of computer codes and data among the many fusion researchers in a cost-effective manner\n\nBarcelona A ja B = Barcelona A and B / Inga Raukas\n\nIndex Scriptorium Estoniae\n\nRaukas, Inga, 1967-\n\n2006-01-01\n\nBarcelona arendamisest. Herzog ja de Meuroni bÃ¼roos kavandatud Foorumi nÃ¤itusekeskuses 2006. a. mÃ¤rtsist juuni alguseni avatud nÃ¤itusest \"Barcelona in Progress\", mis pÃ¼Ã¼ab haarata eduloo ajalugu ja tulevikku. Bibliograafia lk. 71\n\nComputational Dimensionalities of Global Supercomputing\n\nDirectory of Open Access Journals (Sweden)\n\nRichard S. Segall\n\n2013-12-01\n\nFull Text Available This Invited Paper pertains to subject of my Plenary Keynote Speech at the 17th World Multi-Conference on Systemics, Cybernetics and Informatics (WMSCI 2013 held in Orlando, Florida on July 9-12, 2013. The title of my Plenary Keynote Speech was: \"Dimensionalities of Computation: from Global Supercomputing to Data, Text and Web Mining\" but this Invited Paper will focus only on the \"Computational Dimensionalities of Global Supercomputing\" and is based upon a summary of the contents of several individual articles that have been previously written with myself as lead author and published in [75], [76], [77], [78], [79], [80] and [11]. The topics of these of the Plenary Speech included Overview of Current Research in Global Supercomputing [75], Open-Source Software Tools for Data Mining Analysis of Genomic and Spatial Images using High Performance Computing [76], Data Mining Supercomputing with SASâ¢ JMPÂ® Genomics ([77], [79], [80], and Visualization by Supercomputing Data Mining [81]. ______________________ [11.] Committee on the Future of Supercomputing, National Research Council (2003, The Future of Supercomputing: An Interim Report, ISBN-13: 978-0-309-09016- 2, http://www.nap.edu/catalog/10784.html [75.] Segall, Richard S.; Zhang, Qingyu and Cook, Jeffrey S.(2013, \"Overview of Current Research in Global Supercomputing\", Proceedings of Forty- Fourth Meeting of Southwest Decision Sciences Institute (SWDSI, Albuquerque, NM, March 12-16, 2013. [76.] Segall, Richard S. and Zhang, Qingyu (2010, \"Open-Source Software Tools for Data Mining Analysis of Genomic and Spatial Images using High Performance Computing\", Proceedings of 5th INFORMS Workshop on Data Mining and Health Informatics, Austin, TX, November 6, 2010. [77.] Segall, Richard S., Zhang, Qingyu and Pierce, Ryan M.(2010, \"Data Mining Supercomputing with SASâ¢ JMPÂ®; Genomics: Research-in-Progress, Proceedings of 2010 Conference on Applied Research in Information Technology, sponsored by\n\nJapanese supercomputer technology\n\nInternational Nuclear Information System (INIS)\n\nBuzbee, B.L.; Ewald, R.H.; Worlton, W.J.\n\n1982-01-01\n\nIn February 1982, computer scientists from the Los Alamos National Laboratory and Lawrence Livermore National Laboratory visited several Japanese computer manufacturers. The purpose of these visits was to assess the state of the art of Japanese supercomputer technology and to advise Japanese computer vendors of the needs of the US Department of Energy (DOE) for more powerful supercomputers. The Japanese foresee a domestic need for large-scale computing capabilities for nuclear fusion, image analysis for the Earth Resources Satellite, meteorological forecast, electrical power system analysis (power flow, stability, optimization), structural and thermal analysis of satellites, and very large scale integrated circuit design and simulation. To meet this need, Japan has launched an ambitious program to advance supercomputer technology. This program is described\n\nStatus of supercomputers in the US\n\nInternational Nuclear Information System (INIS)\n\nFernbach, S.\n\n1985-01-01\n\nCurrent Supercomputers; that is, the Class VI machines which first became available in 1976 are being delivered in greater quantity than ever before. In addition, manufacturers are busily working on Class VII machines to be ready for delivery in CY 1987. Mainframes are being modified or designed to take on some features of the supercomputers and new companies with the intent of either competing directly in the supercomputer arena or in providing entry-level systems from which to graduate to supercomputers are springing up everywhere. Even well founded organizations like IBM and CDC are adding machines with vector instructions in their repertoires. Japanese - manufactured supercomputers are also being introduced into the U.S. Will these begin to compete with those of U.S. manufacture. Are they truly competitive. It turns out that both from the hardware and software points of view they may be superior. We may be facing the same problems in supercomputers that we faced in videosystems\n\nRole of supercomputers in magnetic fusion and energy research programs\n\nInternational Nuclear Information System (INIS)\n\nKilleen, J.\n\n1985-06-01\n\nThe importance of computer modeling in magnetic fusion (MFE) and energy research (ER) programs is discussed. The need for the most advanced supercomputers is described, and the role of the National Magnetic Fusion Energy Computer Center in meeting these needs is explained\n\nIntegration Of PanDA Workload Management System With Supercomputers for ATLAS and Data Intensive Science\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nDe, K [University of Texas at Arlington; Jha, S [Rutgers University; Klimentov, A [Brookhaven National Laboratory (BNL); Maeno, T [Brookhaven National Laboratory (BNL); Nilsson, P [Brookhaven National Laboratory (BNL); Oleynik, D [University of Texas at Arlington; Panitkin, S [Brookhaven National Laboratory (BNL); Wells, Jack C [ORNL; Wenaus, T [Brookhaven National Laboratory (BNL)\n\n2016-01-01\n\nThe Large Hadron Collider (LHC), operating at the international CERN Laboratory in Geneva, Switzerland, is leading Big Data driven scientific explorations. Experiments at the LHC explore the fundamental nature of matter and the basic forces that shape our universe, and were recently credited for the discovery of a Higgs boson. ATLAS, one of the largest collaborations ever assembled in the sciences, is at the forefront of research at the LHC. To address an unprecedented multi-petabyte data processing challenge, the ATLAS experiment is relying on a heterogeneous distributed computational infrastructure. The ATLAS experiment uses PanDA (Production and Data Analysis) Workload Management System for managing the workflow for all data processing on over 150 data centers. Through PanDA, ATLAS physicists see a single computing facility that enables rapid scientific breakthroughs for the experiment, even though the data centers are physically scattered all over the world. While PanDA currently uses more than 250,000 cores with a peak performance of 0.3 petaFLOPS, LHC data taking runs require more resources than Grid computing can possibly provide. To alleviate these challenges, LHC experiments are engaged in an ambitious program to expand the current computing model to include additional resources such as the opportunistic use of supercomputers. We will describe a project aimed at integration of PanDA WMS with supercomputers in United States, Europe and Russia (in particular with Titan supercomputer at Oak Ridge Leadership Computing Facility (OLCF), MIRA supercomputer at Argonne Leadership Computing Facilities (ALCF), Supercomputer at the National Research Center Kurchatov Institute , IT4 in Ostrava and others). Current approach utilizes modified PanDA pilot framework for job submission to the supercomputers batch queues and local data management, with light-weight MPI wrappers to run single threaded workloads in parallel on LCFs multi-core worker nodes. This implementation\n\nSupercomputing and related national projects in Japan\n\nInternational Nuclear Information System (INIS)\n\nMiura, Kenichi\n\n1985-01-01\n\nJapanese supercomputer development activities in the industry and research projects are outlined. Architecture, technology, software, and applications of Fujitsu's Vector Processor Systems are described as an example of Japanese supercomputers. Applications of supercomputers to high energy physics are also discussed. (orig.)\n\nFlux-Level Transit Injection Experiments with NASA Pleiades Supercomputer\n\nScience.gov (United States)\n\nLi, Jie; Burke, Christopher J.; Catanzarite, Joseph; Seader, Shawn; Haas, Michael R.; Batalha, Natalie; Henze, Christopher; Christiansen, Jessie; Kepler Project, NASA Advanced Supercomputing Division\n\n2016-06-01\n\nFlux-Level Transit Injection (FLTI) experiments are executed with NASA's Pleiades supercomputer for the Kepler Mission. The latest release (9.3, January 2016) of the Kepler Science Operations Center Pipeline is used in the FLTI experiments. Their purpose is to validate the Analytic Completeness Model (ACM), which can be computed for all Kepler target stars, thereby enabling exoplanet occurrence rate studies. Pleiades, a facility of NASA's Advanced Supercomputing Division, is one of the world's most powerful supercomputers and represents NASA's state-of-the-art technology. We discuss the details of implementing the FLTI experiments on the Pleiades supercomputer. For example, taking into account that ~16 injections are generated by one core of the Pleiades processors in an hour, the âshallowâ FLTI experiment, in which ~2000 injections are required per target star, can be done for 16% of all Kepler target stars in about 200 hours. Stripping down the transit search to bare bones, i.e. only searching adjacent high/low periods at high/low pulse durations, makes the computationally intensive FLTI experiments affordable. The design of the FLTI experiments and the analysis of the resulting data are presented in âValidating an Analytic Completeness Model for Kepler Target Stars Based on Flux-level Transit Injection Experimentsâ by Catanzarite et al. (#2494058).Kepler was selected as the 10th mission of the Discovery Program. Funding for the Kepler Mission has been provided by the NASA Science Mission Directorate.\n\nHISTORIC CENTRE(S OF BARCELONA: PRACTICAL AND SYMBOLIC ELEMENTS IN TRADITIONAL URBAN SPACE\n\nDirectory of Open Access Journals (Sweden)\n\nVerÃ³nica MartÃ­nez Robles\n\n2007-09-01\n\nThe model of compact city that Barcelona aims, has required the renewal of its historical areas, and in order to improve their level of centrality, taking into account, that in addition of its historical centre âCiutat Vellaâ, Barcelona contains diverse traditional neighborhoods each of them having their own historical centre. The difference centreâperiphery should also be perceived among these other historical centers. Integration should not be confused with standardization, neither differentiation with segregation.\n\nRecerca i ensenyament agronÃ²mic a la Catalunya del vuit-cents : la granja experimental de Barcelona\n\nOpenAIRE\n\nCartaÃ±Ã i PinÃ©n, Jordi\n\n2008-01-01\n\nBarcelonaÂs Experimental Farm was the agronomic center of reference of BarcelonaÂs regions between 1853 and 1911. In addition to its educational function, it was an experimental center where many of the new features that agronomic science was developing in Europe were tested, emphasizing among others the studies on the performance of fodders, cereals, tobacco, beet and other vegetables, as well as the diffusion of new technologies. It was one of the first state institutions ...\n\nTOP500 Supercomputers for June 2004\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nStrohmaier, Erich; Meuer, Hans W.; Dongarra, Jack; Simon, Horst D.\n\n2004-06-23\n\n23rd Edition of TOP500 List of World's Fastest Supercomputers Released: Japan's Earth Simulator Enters Third Year in Top Position MANNHEIM, Germany; KNOXVILLE, Tenn.;&BERKELEY, Calif. In what has become a closely watched event in the world of high-performance computing, the 23rd edition of the TOP500 list of the world's fastest supercomputers was released today (June 23, 2004) at the International Supercomputer Conference in Heidelberg, Germany.\n\nBuilding the Teraflops/Petabytes Production Computing Center\n\nInternational Nuclear Information System (INIS)\n\nKramer, William T.C.; Lucas, Don; Simon, Horst D.\n\n1999-01-01\n\nIn just one decade, the 1990s, supercomputer centers have undergone two fundamental transitions which require rethinking their operation and their role in high performance computing. The first transition in the early to mid-1990s resulted from a technology change in high performance computing architecture. Highly parallel distributed memory machines built from commodity parts increased the operational complexity of the supercomputer center, and required the introduction of intellectual services as equally important components of the center. The second transition is happening in the late 1990s as centers are introducing loosely coupled clusters of SMPs as their premier high performance computing platforms, while dealing with an ever-increasing volume of data. In addition, increasing network bandwidth enables new modes of use of a supercomputer center, in particular, computational grid applications. In this paper we describe what steps NERSC is taking to address these issues and stay at the leading edge of supercomputing centers.; N\n\nA workbench for tera-flop supercomputing\n\nInternational Nuclear Information System (INIS)\n\nResch, M.M.; Kuester, U.; Mueller, M.S.; Lang, U.\n\n2003-01-01\n\nSupercomputers currently reach a peak performance in the range of TFlop/s. With but one exception - the Japanese Earth Simulator - none of these systems has so far been able to also show a level of sustained performance for a variety of applications that comes close to the peak performance. Sustained TFlop/s are therefore rarely seen. The reasons are manifold and are well known: Bandwidth and latency both for main memory and for the internal network are the key internal technical problems. Cache hierarchies with large caches can bring relief but are no remedy to the problem. However, there are not only technical problems that inhibit the full exploitation by scientists of the potential of modern supercomputers. More and more organizational issues come to the forefront. This paper shows the approach of the High Performance Computing Center Stuttgart (HLRS) to deliver a sustained performance of TFlop/s for a wide range of applications from a large group of users spread over Germany. The core of the concept is the role of the data. Around this we design a simulation workbench that hides the complexity of interacting computers, networks and file systems from the user. (authors)\n\nTOP500 Supercomputers for June 2005\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nStrohmaier, Erich; Meuer, Hans W.; Dongarra, Jack; Simon, Horst D.\n\n2005-06-22\n\n25th Edition of TOP500 List of World's Fastest Supercomputers Released: DOE/L LNL BlueGene/L and IBM gain Top Positions MANNHEIM, Germany; KNOXVILLE, Tenn.; BERKELEY, Calif. In what has become a closely watched event in the world of high-performance computing, the 25th edition of the TOP500 list of the world's fastest supercomputers was released today (June 22, 2005) at the 20th International Supercomputing Conference (ISC2005) in Heidelberg Germany.\n\nIntegration Of PanDA Workload Management System With Supercomputers for ATLAS and Data Intensive Science\n\nScience.gov (United States)\n\nKlimentov, A.; De, K.; Jha, S.; Maeno, T.; Nilsson, P.; Oleynik, D.; Panitkin, S.; Wells, J.; Wenaus, T.\n\n2016-10-01\n\nThe.LHC, operating at CERN, is leading Big Data driven scientific explorations. Experiments at the LHC explore the fundamental nature of matter and the basic forces that shape our universe. ATLAS, one of the largest collaborations ever assembled in the sciences, is at the forefront of research at the LHC. To address an unprecedented multi-petabyte data processing challenge, the ATLAS experiment is relying on a heterogeneous distributed computational infrastructure. The ATLAS experiment uses PanDA (Production and Data Analysis) Workload Management System for managing the workflow for all data processing on over 150 data centers. Through PanDA, ATLAS physicists see a single computing facility that enables rapid scientific breakthroughs for the experiment, even though the data centers are physically scattered all over the world. While PanDA currently uses more than 250,000 cores with a peak performance of 0.3 petaFLOPS, LHC data taking runs require more resources than grid can possibly provide. To alleviate these challenges, LHC experiments are engaged in an ambitious program to expand the current computing model to include additional resources such as the opportunistic use of supercomputers. We will describe a project aimed at integration of PanDA WMS with supercomputers in United States, in particular with Titan supercomputer at Oak Ridge Leadership Computing Facility. Current approach utilizes modified PanDA pilot framework for job submission to the supercomputers batch queues and local data management, with light-weight MPI wrappers to run single threaded workloads in parallel on LCFs multi-core worker nodes. This implementation was tested with a variety of Monte-Carlo workloads on several supercomputing platforms for ALICE and ATLAS experiments and it is in full pro duction for the ATLAS since September 2015. We will present our current accomplishments with running PanDA at supercomputers and demonstrate our ability to use PanDA as a portal independent of the\n\nIntegration Of PanDA Workload Management System With Supercomputers for ATLAS and Data Intensive Science\n\nInternational Nuclear Information System (INIS)\n\nKlimentov, A; Maeno, T; Nilsson, P; Panitkin, S; Wenaus, T; De, K; Oleynik, D; Jha, S; Wells, J\n\n2016-01-01\n\nThe.LHC, operating at CERN, is leading Big Data driven scientific explorations. Experiments at the LHC explore the fundamental nature of matter and the basic forces that shape our universe. ATLAS, one of the largest collaborations ever assembled in the sciences, is at the forefront of research at the LHC. To address an unprecedented multi-petabyte data processing challenge, the ATLAS experiment is relying on a heterogeneous distributed computational infrastructure. The ATLAS experiment uses PanDA (Production and Data Analysis) Workload Management System for managing the workflow for all data processing on over 150 data centers. Through PanDA, ATLAS physicists see a single computing facility that enables rapid scientific breakthroughs for the experiment, even though the data centers are physically scattered all over the world. While PanDA currently uses more than 250,000 cores with a peak performance of 0.3 petaFLOPS, LHC data taking runs require more resources than grid can possibly provide. To alleviate these challenges, LHC experiments are engaged in an ambitious program to expand the current computing model to include additional resources such as the opportunistic use of supercomputers. We will describe a project aimed at integration of PanDA WMS with supercomputers in United States, in particular with Titan supercomputer at Oak Ridge Leadership Computing Facility. Current approach utilizes modified PanDA pilot framework for job submission to the supercomputers batch queues and local data management, with light-weight MPI wrappers to run single threaded workloads in parallel on LCFs multi-core worker nodes. This implementation was tested with a variety of Monte-Carlo workloads on several supercomputing platforms for ALICE and ATLAS experiments and it is in full pro duction for the ATLAS since September 2015. We will present our current accomplishments with running PanDA at supercomputers and demonstrate our ability to use PanDA as a portal independent of the\n\nINTEL: Intel based systems move up in supercomputing ranks\n\nCERN Multimedia\n\n2002-01-01\n\n\"The TOP500 supercomputer rankings released today at the Supercomputing 2002 conference show a dramatic increase in the number of Intel-based systems being deployed in high-performance computing (HPC) or supercomputing areas\" (1/2 page).\n\nWorld's fastest supercomputer opens up to users\n\nScience.gov (United States)\n\nXin, Ling\n\n2016-08-01\n\nChina's latest supercomputer - Sunway TaihuLight - has claimed the crown as the world's fastest computer according to the latest TOP500 list, released at the International Supercomputer Conference in Frankfurt in late June.\n\nOpenMP Performance on the Columbia Supercomputer\n\nScience.gov (United States)\n\nHaoqiang, Jin; Hood, Robert\n\n2005-01-01\n\nThis presentation discusses Columbia World Class Supercomputer which is one of the world's fastest supercomputers providing 61 TFLOPs (10/20/04). Conceived, designed, built, and deployed in just 120 days. A 20-node supercomputer built on proven 512-processor nodes. The largest SGI system in the world with over 10,000 Intel Itanium 2 processors and provides the largest node size incorporating commodity parts (512) and the largest shared-memory environment (2048) with 88% efficiency tops the scalar systems on the Top500 list.\n\nOrÃ­genes del FÃºtbol en Barcelona (1892-1903. | Origins of Fooball in Barcelona (1892-1903.\n\nDirectory of Open Access Journals (Sweden)\n\nXavier Torrebadella Flix\n\n2012-01-01\n\nFull Text Available This article shows some unpublished data that seek to clarify the origins of football in Spain and particularly in Barcelona. Apart from the influence of the English colony in the dissemination of football, the background of school sport is described and evaluated. It is provided data about football in Barcelona which reveal that before the constitution of the Football Club Barcelona, often considered the first team of the city, there were ten associations that practiced this sport. It emphasizes the importance of the British colony, gyms and sports clubs of Barcelona from 1892 to 1903, to generate the enabling environment that made ââthe modern sport of football triumph, stimulating in turn the context Regenerationism and the emergence of associations sports from the early twentieth century. The research method has focused on historical analysis techniques, with the treatment of the original documentary sources and complemented with historicist indirect sources.ResumenEn este artÃ­culo se presentan algunos datos inÃ©ditos que pretenden esclarecer los orÃ­genes del fÃºtbol en EspaÃ±a y mÃ¡s concretamente en Barcelona. Aparte de la influencia que ejerce la colonia inglesa en la divulgaciÃ³n del fÃºtbol, se describen y se valoran los antecedentes del deporte escolar. Sobre el fÃºtbol en Barcelona se aportan datos que revelan que antes de la constituciÃ³n del FÃºtbol Club Barcelona, considerado frecuentemente como el primer equipo de fÃºtbol de la ciudad, existieron una decena de asociaciones que practicaron este deporte. Se acentÃºa la importancia que tuvo la colonia inglesa, los gimnasios y las sociedades deportivas de Barcelona entre 1892 y 1903, para generar el ambiente favorable que hizo que el fÃºtbol triunfase como deporte moderno, estimulando a su vez el contexto regeneracionista y la emergencia del asociacionismo deportivo de principios del siglo XX. El mÃ©todo de investigaciÃ³n se ha centrado en tÃ©cnicas de anÃ¡lisis histÃ³rico en\n\nSupercomputing - Use Cases, Advances, The Future (1/2)\n\nCERN Multimedia\n\nCERN. Geneva\n\n2017-01-01\n\nSupercomputing has become a staple of science and the poster child for aggressive developments in silicon technology, energy efficiency and programming. In this series we examine the key components of supercomputing setups and the various advances â recent and past â that made headlines and delivered bigger and bigger machines. We also take a closer look at the future prospects of supercomputing, and the extent of its overlap with high throughput computing, in the context of main use cases ranging from oil exploration to market simulation. On the first day, we will focus on the history and theory of supercomputing, the top500 list and the hardware that makes supercomputers tick. Lecturer's short bio: Andrzej Nowak has 10 years of experience in computing technologies, primarily from CERN openlab and Intel. At CERN, he managed a research lab collaborating with Intel and was part of the openlab Chief Technology Office. Andrzej also worked closely and initiated projects with the private sector (e.g. HP an...\n\nSupercomputing - Use Cases, Advances, The Future (2/2)\n\nCERN Multimedia\n\nCERN. Geneva\n\n2017-01-01\n\nSupercomputing has become a staple of science and the poster child for aggressive developments in silicon technology, energy efficiency and programming. In this series we examine the key components of supercomputing setups and the various advances â recent and past â that made headlines and delivered bigger and bigger machines. We also take a closer look at the future prospects of supercomputing, and the extent of its overlap with high throughput computing, in the context of main use cases ranging from oil exploration to market simulation. On the second day, we will focus on software and software paradigms driving supercomputers, workloads that need supercomputing treatment, advances in technology and possible future developments. Lecturer's short bio: Andrzej Nowak has 10 years of experience in computing technologies, primarily from CERN openlab and Intel. At CERN, he managed a research lab collaborating with Intel and was part of the openlab Chief Technology Office. Andrzej also worked closely and i...\n\nAdvanced parallel processing with supercomputer architectures\n\nInternational Nuclear Information System (INIS)\n\nHwang, K.\n\n1987-01-01\n\nThis paper investigates advanced parallel processing techniques and innovative hardware/software architectures that can be applied to boost the performance of supercomputers. Critical issues on architectural choices, parallel languages, compiling techniques, resource management, concurrency control, programming environment, parallel algorithms, and performance enhancement methods are examined and the best answers are presented. The authors cover advanced processing techniques suitable for supercomputers, high-end mainframes, minisupers, and array processors. The coverage emphasizes vectorization, multitasking, multiprocessing, and distributed computing. In order to achieve these operation modes, parallel languages, smart compilers, synchronization mechanisms, load balancing methods, mapping parallel algorithms, operating system functions, application library, and multidiscipline interactions are investigated to ensure high performance. At the end, they assess the potentials of optical and neural technologies for developing future supercomputers\n\nDesktop supercomputer: what can it do?\n\nScience.gov (United States)\n\nBogdanov, A.; Degtyarev, A.; Korkhov, V.\n\n2017-12-01\n\nThe paper addresses the issues of solving complex problems that require using supercomputers or multiprocessor clusters available for most researchers nowadays. Efficient distribution of high performance computing resources according to actual application needs has been a major research topic since high-performance computing (HPC) technologies became widely introduced. At the same time, comfortable and transparent access to these resources was a key user requirement. In this paper we discuss approaches to build a virtual private supercomputer available at user's desktop: a virtual computing environment tailored specifically for a target user with a particular target application. We describe and evaluate possibilities to create the virtual supercomputer based on light-weight virtualization technologies, and analyze the efficiency of our approach compared to traditional methods of HPC resource management.\n\nBARCELONA: URBANSCAPES OF MODERNITY\n\nDirectory of Open Access Journals (Sweden)\n\nAntoni Remesar\n\n2015-04-01\n\nThe Do.Co.Mo.Moâs. database, referring to Barcelona, lists 34 buildings that could be classified as rationalists and / or modern. According to other sources, we could reach fifty constructed buildings between the late 1920s and the end of the war in Spain. The article presents the results of a field work that, using different sources, has tried to to order and record the architectural production that can be considered modern / rationalist in Barcelona in the 1920s and 1930s\n\nAdaptability of supercomputers to nuclear computations\n\nInternational Nuclear Information System (INIS)\n\nAsai, Kiyoshi; Ishiguro, Misako; Matsuura, Toshihiko.\n\n1983-01-01\n\nRecently in the field of scientific and technical calculation, the usefulness of supercomputers represented by CRAY-1 has been recognized, and they are utilized in various countries. The rapid computation of supercomputers is based on the function of vector computation. The authors investigated the adaptability to vector computation of about 40 typical atomic energy codes for the past six years. Based on the results of investigation, the adaptability of the function of vector computation that supercomputers have to atomic energy codes, the problem regarding the utilization and the future prospect are explained. The adaptability of individual calculation codes to vector computation is largely dependent on the algorithm and program structure used for the codes. The change to high speed by pipeline vector system, the investigation in the Japan Atomic Energy Research Institute and the results, and the examples of expressing the codes for atomic energy, environmental safety and nuclear fusion by vector are reported. The magnification of speed up for 40 examples was from 1.5 to 9.0. It can be said that the adaptability of supercomputers to atomic energy codes is fairly good. (Kako, I.)\n\n[On the way to shortening tuberculosis treatments: clinical trials of the Unitat d' InvestagaciÃ³ en Tuberculosi de Barcelona supported by the Centers for Disease Control and Prevention].\n\nScience.gov (United States)\n\nMoreno, Antonio; SÃ¡nchez, Francesca; Nelson, Jeanne; MirÃ³, JosÃ© M; CaylÃ , Joan A\n\n2010-01-01\n\nNew treatment guidelines are required to improve the tuberculosis control strategies that have been used for 30 years. Seven centers of the Barcelona Tuberculosis Research Unit (BTRU) (Unitat d'InvestigaciÃ³ en Tuberculosi de Barcelona) are collaborating with the Division of Tuberculosis Elimination of the United States Centers for Disease Control and Prevention in a series of clinical trials on latent tuberculosis infection and tuberculosis disease. BTRU participation began in 2004 with Study 26, an evaluation of the efficacy and tolerability of rifapentine plus isoniazid administered once weekly for 3 months compared with the standard treatment for latent tuberculosis infection. The BTRU centers together enrolled 246 patients (3% of the total). General enrollment was completed in February, 2008. HIV-infected patient and child enrollment continues. Treatment with 12 doses instead of 270 doses is expected to be a clear success. However, the analysis will be completed in 2010. Study 28 (started in 2006), designed for the treatment of pulmonary tuberculosis, compared standard treatment with an experimental regimen substituting moxifloxacin for isoniazid. BTRU centers together enrolled 15 patients (3.5% of the total). The provisional results (presented at the 47th Interscience Conference on Antimicrobial Agents and Chemotherapy in Chicago, 2007) showed no difference between the sputum conversion rate of each regimen at week 8 of treatment. Study 29 is currently underway, in which rifapentine was introduced in the experimental regimen for active tuberculosis treatment. Copyright (c) 2009 SESPAS. Published by Elsevier Espana. All rights reserved.\n\nVisualization at supercomputing centers: the tale of little big iron and the three skinny guys.\n\nScience.gov (United States)\n\nBethel, E W; van Rosendale, J; Southard, D; Gaither, K; Childs, H; Brugger, E; Ahern, S\n\n2011-01-01\n\nSupercomputing centers are unique resources that aim to enable scientific knowledge discovery by employing large computational resources-the \"Big Iron.\" Design, acquisition, installation, and management of the Big Iron are carefully planned and monitored. Because these Big Iron systems produce a tsunami of data, it's natural to colocate the visualization and analysis infrastructure. This infrastructure consists of hardware (Little Iron) and staff (Skinny Guys). Our collective experience suggests that design, acquisition, installation, and management of the Little Iron and Skinny Guys doesn't receive the same level of treatment as that of the Big Iron. This article explores the following questions about the Little Iron: How should we size the Little Iron to adequately support visualization and analysis of data coming off the Big Iron? What sort of capabilities must it have? Related questions concern the size of visualization support staff: How big should a visualization program be-that is, how many Skinny Guys should it have? What should the staff do? How much of the visualization should be provided as a support service, and how much should applications scientists be expected to do on their own?\n\nDesktop supercomputer: what can it do?\n\nInternational Nuclear Information System (INIS)\n\nBogdanov, A.; Degtyarev, A.; Korkhov, V.\n\n2017-01-01\n\nThe paper addresses the issues of solving complex problems that require using supercomputers or multiprocessor clusters available for most researchers nowadays. Efficient distribution of high performance computing resources according to actual application needs has been a major research topic since high-performance computing (HPC) technologies became widely introduced. At the same time, comfortable and transparent access to these resources was a key user requirement. In this paper we discuss approaches to build a virtual private supercomputer available at user's desktop: a virtual computing environment tailored specifically for a target user with a particular target application. We describe and evaluate possibilities to create the virtual supercomputer based on light-weight virtualization technologies, and analyze the efficiency of our approach compared to traditional methods of HPC resource management.\n\nModelling of pollen dispersion in the atmosphere: evaluation with a continuous 1Î²+1Î´ lidar\n\nScience.gov (United States)\n\nSicard, MichaÃ«l; Izquierdo, Rebeca; Jorba, Oriol; AlarcÃ³n, Marta; Belmonte, Jordina; ComerÃ³n, Adolfo; De Linares, ConcepciÃ³n; Baldasano, JosÃ© Maria\n\n2018-04-01\n\nPollen allergenicity plays an important role on human health and wellness. It is thus of large public interest to increase our knowledge of pollen grain behavior in the atmosphere (source, emission, processes involved during their transport, etc.) at fine temporal and spatial scales. First simulations with the Barcelona Supercomputing Center NMMB/BSC-CTM model of Platanus and Pinus dispersion in the atmosphere were performed during a 5-day pollination event observed in Barcelona, Spain, between 27 - 31 March, 2015. The simulations are compared to vertical profiles measured with the continuous Barcelona Micro Pulse Lidar system. First results show that the vertical distribution is well reproduced by the model in shape, but not in intensity, the model largely underestimating in the afternoon. Guidelines are proposed to improve the dispersion of airborne pollen by numerical prediction models.\n\nGeodetic infrastructure at the Barcelona harbour for sea level monitoring\n\nScience.gov (United States)\n\nMartinez-Benjamin, Juan Jose; Gili, Josep; Lopez, Rogelio; Tapia, Ana; Pros, Francesc; Palau, Vicenc; Perez, Begona\n\n2015-04-01\n\nThe presentation is directed to the description of the actual geodetic infrastructure of Barcelona harbour with three tide gauges of different technologies for sea level determination and contribution to regional sea level rise and understanding past and present sea level rise in the Barcelona harbour. It is intended that the overall system will constitute a CGPS Station of the ESEAS (European Sea Level) and TIGA (GPS Tide Gauge Benchmark Monitoring) networks. At Barcelona harbour there is a MIROS radar tide gauge belonging to Puertos del Estado (Spanish Harbours).The radar sensor is over the water surface, on a L-shaped structure which elevates it a few meters above the quay shelf. 1-min data are transmitted to the ENAGAS Control Center by cable and then sent each 1 min to Puertos del Estado by e-mail. The information includes wave forescast (mean period, significant wave height, sea level, etc.This sensor also measures agitation and sends wave parameters each 20 min. There is a GPS station Leica Geosystems GRX1200 GG Pro and antenna AX 1202 GG. The Control Tower of the Port of Barcelona is situated in the North dike of the so-called Energy Pier in the Barcelona harbor (Spain). This tower has different kind of antennas for navigation monitoring and a GNSS permanent station. As the tower is founded in reclaimed land, and because its metallic structure, the 50 m building is subjected to diverse movements, including periodic fluctuations due to temperature changes. In this contribution the 2009, 2011, 2012, 2013 and 2014 the necessary monitoring campaigns are described. In the framework of a Spanish Space Project, the instrumentation of sea level measurements has been improved by providing the Barcelona site with a radar tide gauge Datamar 2000C from Geonica S.L. in June 2014 near an acoustic tide gauge from the Barcelona Harbour installed in 2013. Precision levelling has been made several times in the last two years because the tower is founded in reclaimed land and\n\nTOP500 Supercomputers for November 2004\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nStrohmaier, Erich; Meuer, Hans W.; Dongarra, Jack; Simon, Horst D.\n\n2004-11-08\n\n24th Edition of TOP500 List of World's Fastest Supercomputers Released: DOE/IBM BlueGene/L and NASA/SGI's Columbia gain Top Positions MANNHEIM, Germany; KNOXVILLE, Tenn.; BERKELEY, Calif. In what has become a closely watched event in the world of high-performance computing, the 24th edition of the TOP500 list of the worlds fastest supercomputers was released today (November 8, 2004) at the SC2004 Conference in Pittsburgh, Pa.\n\nStatus reports of supercomputing astrophysics in Japan\n\nInternational Nuclear Information System (INIS)\n\nNakamura, Takashi; Nagasawa, Mikio\n\n1990-01-01\n\nThe Workshop on Supercomputing Astrophysics was held at National Laboratory for High Energy Physics (KEK, Tsukuba) from August 31 to September 2, 1989. More than 40 participants of physicists, astronomers were attendant and discussed many topics in the informal atmosphere. The main purpose of this workshop was focused on the theoretical activities in computational astrophysics in Japan. It was also aimed to promote effective collaboration between the numerical experimentists working on supercomputing technique. The various subjects of the presented papers of hydrodynamics, plasma physics, gravitating systems, radiative transfer and general relativity are all stimulating. In fact, these numerical calculations become possible now in Japan owing to the power of Japanese supercomputer such as HITAC S820, Fujitsu VP400E and NEC SX-2. (J.P.N.)\n\nComments on the parallelization efficiency of the Sunway TaihuLight supercomputer\n\nOpenAIRE\n\nVÃ©gh, JÃ¡nos\n\n2016-01-01\n\nIn the world of supercomputers, the large number of processors requires to minimize the inefficiencies of parallelization, which appear as a sequential part of the program from the point of view of Amdahl's law. The recently suggested new figure of merit is applied to the recently presented supercomputer, and the timeline of \"Top 500\" supercomputers is scrutinized using the metric. It is demonstrated, that in addition to the computing performance and power consumption, the new supercomputer i...\n\nThe ETA10 supercomputer system\n\nInternational Nuclear Information System (INIS)\n\nSwanson, C.D.\n\n1987-01-01\n\nThe ETA Systems, Inc. ETA 10 is a next-generation supercomputer featuring multiprocessing, a large hierarchical memory system, high performance input/output, and network support for both batch and interactive processing. Advanced technology used in the ETA 10 includes liquid nitrogen cooled CMOS logic with 20,000 gates per chip, a single printed circuit board for each CPU, and high density static and dynamics MOS memory chips. Software for the ETA 10 includes an underlying kernel that supports multiple user environments, a new ETA FORTRAN compiler with an advanced automatic vectorizer, a multitasking library and debugging tools. Possible developments for future supercomputers from ETA Systems are discussed. (orig.)\n\nConstruyendo la Barcelona creativa: nuevos actores, nuevas estrategias\n\nDirectory of Open Access Journals (Sweden)\n\nMontserrat Pareja-Eastaway\n\n2010-12-01\n\nFull Text Available Building A creative Barcelona: new actors, new strategies.Barcelona is under the international spotlight. The city that triumphed with the organisation of the Olympic Games in 1992 now wants to become a 21st Century creative city. In order to achieve this goal, the city must establish conditions that facilitate the emergence of a shared discourse around its ability to become an attractive city for creative talent and for businesses. The recognition of the historical-economic heritage, as a starting point for the creative city, along with the driving role played by culture in the generation of a exclusive and distinctive experience, turnBarcelona into a unique city. However, this is not sufficient. The participation and involvement of all the actors in a shared strategy pose significant challenges to Barcelona, as does the need to minimise the negative effects that inevitably accompany success. Companies, institutions and citizens constitute the cityâs best assets: they must work in partnership and take advantage of the synergies generated amongst them. Consensus and participation are more than mere utopias in Barcelona: they have become requirements for the city of tomorrow. Moreover, leadership in Barcelona is largely left to public initiative: the emergence of linkages across the needs of the various creative sectors, based on public intervention mechanisms is the best way to ensure success.\n\nOptimal football strategies: AC Milan versus FC Barcelona\n\nOpenAIRE\n\nPapahristodoulou, Christos\n\n2012-01-01\n\nIn a recent UEFA Champions League game between AC Milan and FC Barcelona, played in Italy (final score 2-3), the collected match statistics, classified into four offensive and two defensive strategies, were in favour of FC Barcelona (by 13 versus 8 points). The aim of this paper is to examine to what extent the optimal game strategies derived from some deterministic, possibilistic, stochastic and fuzzy LP models would improve the payoff of AC Milan at the cost of FC Barcelona.\n\nAir pollution and mortality in Barcelona.\n\nOpenAIRE\n\nSunyer, J; CastellsaguÃ©, J; SÃ¡ez, M; Tobias, A; AntÃ³, J M\n\n1996-01-01\n\nSTUDY OBJECTIVES: Studies conducted in Barcelona reported a short term relation between daily air pollutant values and emergency department admissions for exacerbation of chronic obstructive pulmonary diseases and asthma. Air pollution in Barcelona is mainly generated by vehicle exhaust and is below the World Health Organization air quality guidelines. The acute relation between air pollution and mortality was assessed. DESIGN: Daily variations in total mortality, mortality in subjects older ...\n\nPatrimonios incÃ³modos para la imagen que Barcelona ofrece al mundo\n\nDirectory of Open Access Journals (Sweden)\n\nReventÃ³s Gil de Biedma, Ana\n\n2007-01-01\n\nFull Text Available Barcelona is today a city of reference within the worldâs tourist map. Created as a process of both an economic evolution towards the third sector as well as a powerful brand image, from the Olympics up to nowadays. Within this scene, Culture and Arts have been pushed at the center of the strategy, building a âcultural spectacleâ aimed to differentiate the cityâs offer in the market. Furthermore, some specific icons oriented to give it a Catalan, Cosmopolitan and Modern identity are promoted, adding also new symbolic values such as diversity, tolerance or Mediterranean character. Meaning that some range of cultural heritages should be reinforced while others are put aside or even hidden. Barcelona appears then as the result of a perfectly drawn political strategic planning, under the appearance of social consensus and citizensâ involvement\n\nSupercomputers to transform Science\n\nCERN Multimedia\n\n2006-01-01\n\n\"New insights into the structure of space and time, climate modeling, and the design of novel drugs, are but a few of the many research areas that will be transforned by the installation of three supercomputers at the Unversity of Bristol.\" (1/2 page)\n\nConvex unwraps its first grown-up supercomputer\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nManuel, T.\n\n1988-03-03\n\nConvex Computer Corp.'s new supercomputer family is even more of an industry blockbuster than its first system. At a tenfold jump in performance, it's far from just an incremental upgrade over its first minisupercomputer, the C-1. The heart of the new family, the new C-2 processor, churning at 50 million floating-point operations/s, spawns a group of systems whose performance could pass for some fancy supercomputers-namely those of the Cray Research Inc. family. When added to the C-1, Convex's five new supercomputers create the C series, a six-member product group offering a performance range from 20 to 200 Mflops. They mark an important transition for Convex from a one-product high-tech startup to a multinational company with a wide-ranging product line. It's a tough transition but the Richardson, Texas, company seems to be doing it. The extended product line propels Convex into the upper end of the minisupercomputer class and nudges it into the low end of the big supercomputers. It positions Convex in an uncrowded segment of the market in the $500,000 to $1 million range offering 50 to 200 Mflops of performance. The company is making this move because the minisuper area, which it pioneered, quickly became crowded with new vendors, causing prices and gross margins to drop drastically.\n\nSupercomputer debugging workshop 1991 proceedings\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nBrown, J.\n\n1991-01-01\n\nThis report discusses the following topics on supercomputer debugging: Distributed debugging; use interface to debugging tools and standards; debugging optimized codes; debugging parallel codes; and debugger performance and interface as analysis tools. (LSP)\n\nSupercomputer debugging workshop 1991 proceedings\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nBrown, J.\n\n1991-12-31\n\nThis report discusses the following topics on supercomputer debugging: Distributed debugging; use interface to debugging tools and standards; debugging optimized codes; debugging parallel codes; and debugger performance and interface as analysis tools. (LSP)\n\nThe ETA systems plans for supercomputers\n\nInternational Nuclear Information System (INIS)\n\nSwanson, C.D.\n\n1987-01-01\n\nThe ETA Systems, is a class VII supercomputer featuring multiprocessing, a large hierarchical memory system, high performance input/output, and network support for both batch and interactive processing. Advanced technology used in the ETA 10 includes liquid nitrogen cooled CMOS logic with 20,000 gates per chip, a single printed circuit board for each CPU, and high density static and dynamic MOS memory chips. Software for the ETA 10 includes an underlying kernel that supports multiple user environments, a new ETA FORTRAN compiler with an advanced automatic vectorizer, a multitasking library and debugging tools. Possible developments for future supercomputers from ETA Systems are discussed\n\nPNNL supercomputer to become largest computing resource on the Grid\n\nCERN Multimedia\n\n2002-01-01\n\nHewlett Packard announced that the US DOE Pacific Northwest National Laboratory will connect a 9.3-teraflop HP supercomputer to the DOE Science Grid. This will be the largest supercomputer attached to a computer grid anywhere in the world (1 page).\n\nBarcelona mÃ¡s allÃ¡ de Barcelona. La ciudad cinematogrÃ¡fica transformada en otras ciudades\n\nDirectory of Open Access Journals (Sweden)\n\nCarlota Bonet Balaguer\n\n2016-07-01\n\nFull Text Available Since the late twentieth century, the duality tourism and cinema, commonly referred to as film-induced tourism, has become one of the most emerging and dynamic tourist modalities. Amongst the various types of film-induced tourism accepted by the academia, this research has been based on one that has a double filmic identity: as film destination and as film setting. Meaning a film that is shot in a particular place but is actually representing elsewhere. The main objective of this research is to identify and analyse the international audio-visual productions or co-productions that have been partially or completely shot in Barcelona yet in fiction represent another city. The results were essentially obtained from an analytical-descriptive methodology. As a main conclusion of the study, it can be stated that international films which are shot in Barcelona but represent elsewhere in the film, have great potential to strengthen or create a competitive offer of film-induced tourism in Barcelona.\n\nPolycentricity, Performance and Planning: Concepts, Evidence and Policy in Barcelona, Catalonia\n\nDirectory of Open Access Journals (Sweden)\n\nJaume Masip-Tresserra\n\n2017-11-01\n\neffects over its surrounding areas, meaning that the number of firms and the amount of urban development (growth in areas near a center will be limited because of fierce competition effects. Second, this thesis has proposed a conceptual framework for exploring the link between polycentricity (on the intra-urban scale and metropolitan performance aimed at enabling broad testing of the effects of polycentricity. Building upon the relationship between theories of agglomeration and polycentricity in the literature, this thesis argues that the consideration of three distinct dimensions of a polycentric spatial structure that play a role in the development of agglomeration economies in a metropolitan areaânamely, (1 the size of centers, (2 the (geographic proximity to centers, and (3 the aggregate size of centers through their integrationâallows scholars to arrive at broader conclusions about the effects of polycentricity. The translation of these three dimensions of a polycentric metropolitan structure into a more comprehensive, systematic empirical framework has required an examination of the effects (1 of being located in or oriented toward centers, (2 of being located close to centers, and (3 of interaction patterns among centers. Conclusions Below are the main conclusions regarding the three general research questions. How has the conceptualization of polycentric development in spatial plans evolved over time, and what can be learned from this evolution? Envisioning polycentric development in spatial plans has become a hallmark of planning practice in Catalonia. The first vision of polycentric development appeared in the 1930s as a response to the debate about the urban-rural opposition between Barcelona (city and Catalonia (countryside that resulted from increasing demands to address the (negative challenges posed by citiesâ industrialization. Since then, the vision of polycentric development in spatial plans evolved, showing two transitions in its conceptualization\n\nCinco puntos sobre la revista Barcelona\n\nOpenAIRE\n\nBertone Crippa, Mauro\n\n2012-01-01\n\nEl humor, como gÃ©nero y narrativa mediÃ¡tica, ocupa un lugar destacado al interior del campo del periodismo grÃ¡fico argentino. Como emergente contemporÃ¡neo dentro de este Ã¡mbito, la revista Barcelona se vuelve un objeto de estudio sugestivo al trabajar, a partir del registro del humor, sobre la agenda y la enunciaciÃ³n de los medios grÃ¡ficos de actualidad. De esta manera, se analizan las condiciones de producciÃ³n del discurso de Barcelona para ver quÃ© novedades aporta al campo del hu...\n\nCooperative visualization and simulation in a supercomputer environment\n\nInternational Nuclear Information System (INIS)\n\nRuehle, R.; Lang, U.; Wierse, A.\n\n1993-01-01\n\nThe article takes a closer look on the requirements being imposed by the idea to integrate all the components into a homogeneous software environment. To this end several methods for the distribtuion of applications in dependence of certain problem types are discussed. The currently available methods at the University of Stuttgart Computer Center for the distribution of applications are further explained. Finally the aims and characteristics of a European sponsored project, called PAGEIN, are explained, which fits perfectly into the line of developments at RUS. The aim of the project is to experiment with future cooperative working modes of aerospace scientists in a high speed distributed supercomputing environment. Project results will have an impact on the development of real future scientific application environments. (orig./DG)\n\nSaalivalvurid varastavad ka Barcelonas\n\nIndex Scriptorium Estoniae\n\n2000-01-01\n\nHispaania politsei tabas Barcelona Arheoloogiamuuseumi saalivalvuri Manuel Gasca, kes varastas muuseumi hoidlaist umbes 35 miljoni Eesti krooni ulatuses vana-egiptuse, foiniikia, etruski ja vana-rooma arheoloogilisi leide (mÃ¼ndid, keraamika, skulptuur jt.) ning itaalia graafiku Giambattista Piranesi 150 gravÃ¼Ã¼ri.\n\nSupercomputers Of The Future\n\nScience.gov (United States)\n\nPeterson, Victor L.; Kim, John; Holst, Terry L.; Deiwert, George S.; Cooper, David M.; Watson, Andrew B.; Bailey, F. Ron\n\n1992-01-01\n\nReport evaluates supercomputer needs of five key disciplines: turbulence physics, aerodynamics, aerothermodynamics, chemistry, and mathematical modeling of human vision. Predicts these fields will require computer speed greater than 10(Sup 18) floating-point operations per second (FLOP's) and memory capacity greater than 10(Sup 15) words. Also, new parallel computer architectures and new structured numerical methods will make necessary speed and capacity available.\n\nNASA Advanced Supercomputing Facility Expansion\n\nScience.gov (United States)\n\nThigpen, William W.\n\n2017-01-01\n\nThe NASA Advanced Supercomputing (NAS) Division enables advances in high-end computing technologies and in modeling and simulation methods to tackle some of the toughest science and engineering challenges facing NASA today. The name \"NAS\" has long been associated with leadership and innovation throughout the high-end computing (HEC) community. We play a significant role in shaping HEC standards and paradigms, and provide leadership in the areas of large-scale InfiniBand fabrics, Lustre open-source filesystems, and hyperwall technologies. We provide an integrated high-end computing environment to accelerate NASA missions and make revolutionary advances in science. Pleiades, a petaflop-scale supercomputer, is used by scientists throughout the U.S. to support NASA missions, and is ranked among the most powerful systems in the world. One of our key focus areas is in modeling and simulation to support NASA's real-world engineering applications and make fundamental advances in modeling and simulation methods.\n\nATLAS Software Installation on Supercomputers\n\nCERN Document Server\n\nUndrus, Alexander; The ATLAS collaboration\n\n2018-01-01\n\nPowerPC and high performance computers (HPC) are important resources for computing in the ATLAS experiment. The future LHC data processing will require more resources than Grid computing, currently using approximately 100,000 cores at well over 100 sites, can provide. Supercomputers are extremely powerful as they use resources of hundreds of thousands CPUs joined together. However their architectures have different instruction sets. ATLAS binary software distributions for x86 chipsets do not fit these architectures, as emulation of these chipsets results in huge performance loss. This presentation describes the methodology of ATLAS software installation from source code on supercomputers. The installation procedure includes downloading the ATLAS code base as well as the source of about 50 external packages, such as ROOT and Geant4, followed by compilation, and rigorous unit and integration testing. The presentation reports the application of this procedure at Titan HPC and Summit PowerPC at Oak Ridge Computin...\n\nJINR supercomputer of the module type for event parallel analysis\n\nInternational Nuclear Information System (INIS)\n\nKolpakov, I.F.; Senner, A.E.; Smirnov, V.A.\n\n1987-01-01\n\nA model of a supercomputer with 50 million of operations per second is suggested. Its realization allows one to solve JINR data analysis problems for large spectrometers (in particular DELPHY collaboration). The suggested module supercomputer is based on 32-bit commercial available microprocessor with a processing rate of about 1 MFLOPS. The processors are combined by means of VME standard busbars. MicroVAX-11 is a host computer organizing the operation of the system. Data input and output is realized via microVAX-11 computer periphery. Users' software is based on the FORTRAN-77. The supercomputer is connected with a JINR net port and all JINR users get an access to the suggested system\n\n@City: technologising Barcelona\n\nDirectory of Open Access Journals (Sweden)\n\nRojas, JesÃºs\n\n2007-05-01\n\nFull Text Available This article is about the concept of the contemporary city - the influence that technology has when one thinks about, plans and lives in a city. The conjunction of technology and city reformulates customs and social practices; it can even determine the way one constitutes one's own identity. One can see how close the relation is between technology (specifically, TICS and the structures of the city in a wide variety of situations: in social interactions on the street, in transport, and in ways of buying, of working and entertainment. \"@City\" is a concept that very well reflects the emergent properties of a current city, that is, the coexistence of a physical and a virtual urban space. The \"22@Barcelona\" project attempts to bring together different types of spaces. By combining the physical with the virtual, 22@Barcelona, as a neighborhood of @City, creates an uncertain and blurred border between both spaces.The article also examines the impact that these spaces have on the psycho-social processes involved in the daily life of a traditionally working-class neighborhood, now strongly limited by technological boundaries.\n\nSupercomputers and quantum field theory\n\nInternational Nuclear Information System (INIS)\n\nCreutz, M.\n\n1985-01-01\n\nA review is given of why recent simulations of lattice gauge theories have resulted in substantial demands from particle theorists for supercomputer time. These calculations have yielded first principle results on non-perturbative aspects of the strong interactions. An algorithm for simulating dynamical quark fields is discussed. 14 refs\n\nLymphogranuloma venereum: a hidden emerging problem, Barcelona, 2011.\n\nScience.gov (United States)\n\nVargas-Leguas, H; Garcia de Olalla, P; Arando, M; Armengol, P; Barbera, Mj; Vall, M; Vives, A; Martin-Ezquerra, G; Alsina, M; Blanco, J; Munoz, C; Caballero, E; Andreu, A; Ros, M; Gorrindo, P; Dominguez, A; Cayla, Ja\n\n2012-01-12\n\nFrom the beginning of 2007 until the end of 2011, 146 cases of lymphogranuloma venereum (LGV) were notified to the Barcelona Public Health Agency. Some 49% of them were diagnosed and reported in 2011, mainly in men who have sex with men. Almost half of them, 32 cases, were reported between July and September. This cluster represents the largest since 2004. This article presents the ongoing outbreak of LGV in Barcelona.\n\nAdventures in supercomputing: An innovative program for high school teachers\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nOliver, C.E.; Hicks, H.R.; Summers, B.G. [Oak Ridge National Lab., TN (United States); Staten, D.G. [Wartburg Central High School, TN (United States)\n\n1994-12-31\n\nWithin the realm of education, seldom does an innovative program become available with the potential to change an educator`s teaching methodology. Adventures in Supercomputing (AiS), sponsored by the U.S. Department of Energy (DOE), is such a program. It is a program for high school teachers that changes the teacher paradigm from a teacher-directed approach of teaching to a student-centered approach. {open_quotes}A student-centered classroom offers better opportunities for development of internal motivation, planning skills, goal setting and perseverance than does the traditional teacher-directed mode{close_quotes}. Not only is the process of teaching changed, but the cross-curricula integration within the AiS materials is remarkable. Written from a teacher`s perspective, this paper will describe the AiS program and its effects on teachers and students, primarily at Wartburg Central High School, in Wartburg, Tennessee. The AiS program in Tennessee is sponsored by Oak Ridge National Laboratory (ORNL).\n\nSupercomputer applications in nuclear research\n\nInternational Nuclear Information System (INIS)\n\nIshiguro, Misako\n\n1992-01-01\n\nThe utilization of supercomputers in Japan Atomic Energy Research Institute is mainly reported. The fields of atomic energy research which use supercomputers frequently and the contents of their computation are outlined. What is vectorizing is simply explained, and nuclear fusion, nuclear reactor physics, the hydrothermal safety of nuclear reactors, the parallel property that the atomic energy computations of fluids and others have, the algorithm for vector treatment and the effect of speed increase by vectorizing are discussed. At present Japan Atomic Energy Research Institute uses two systems of FACOM VP 2600/10 and three systems of M-780. The contents of computation changed from criticality computation around 1970, through the analysis of LOCA after the TMI accident, to nuclear fusion research, the design of new type reactors and reactor safety assessment at present. Also the method of using computers advanced from batch processing to time sharing processing, from one-dimensional to three dimensional computation, from steady, linear to unsteady nonlinear computation, from experimental analysis to numerical simulation and so on. (K.I.)\n\nCiudadanos del este de Europa consumidores de drogas en Barcelona Injecting drug users from Eastern Europe in Barcelona, Spain\n\nDirectory of Open Access Journals (Sweden)\n\nM. GonzÃ¡lez\n\n2003-06-01\n\nFull Text Available Desde mayo de 1999 hasta mayo de 2001, hemos contactado en el SAPS (Servicio de AtenciÃ³n Social y Sanitaria de Barcelona con usuarios de drogas de paÃ­ses del este de Europa. Acuden a centros terapÃ©uticos gratuitos, aunque pagan por la organizaciÃ³n del viaje unos 500 euros. Son jÃ³venes entre 18 y 30 aÃ±os y mantienen el contacto con sus familiares. Conocen los riesgos de transmisiÃ³n de enfermedades, pero suelen reutilizar las jeringas. Es alta la prevalencia de hepatitis C (92% y B (62% y menor la de infecciÃ³n por el VIH (19%. Si no abandonan las drogas, el retorno es un fracaso y tienen dificultades para proseguir los tratamientos con metadona o antirretrovirales. La respuesta asistencial ha de adecuarse a sus necesidades. Se debe procurar la mediaciÃ³n cultural y la informaciÃ³n en los lugares de origen, supervisar los centros terapÃ©uticos y diseÃ±ar alternativas a los abandonos. Hay que desarrollar la colaboraciÃ³n internacional, estimular programas de disminuciÃ³n de riesgos derivados del consumo y evitar que del tratamiento se haga un comercio.From May 1999 to May 2001, we made contact with injecting drug users from Eastern Europe in the healthcare and prevention service of the Red Cross (servicio de atenciÃ³n y prevenciÃ³n sociosanitaria [SAPS] in Barcelona (Spain. The users attended free therapeutic centers, but paid approximately 500 â¬ for the trip. The users were aged between 18 and 30 years old and maintained family contact. The knew the risk of disease transmission, but often exchanged needles. The prevalence of hepatitis C (92% and B (62% was high but less than that of HIV (19%. If they did not stop taking drugs their return would be a failure and they would have difficulties in following methadone and antiretroviral treatments in their countries of origin. The healthcare provided in these centers should respond to user' needs: cultural mediation should be sought, as well as information from users' countries of origin\n\nComputational plasma physics and supercomputers\n\nInternational Nuclear Information System (INIS)\n\nKilleen, J.; McNamara, B.\n\n1984-09-01\n\nThe Supercomputers of the 80's are introduced. They are 10 to 100 times more powerful than today's machines. The range of physics modeling in the fusion program is outlined. New machine architecture will influence particular codes, but parallel processing poses new coding difficulties. Increasing realism in simulations will require better numerics and more elaborate mathematics\n\nMistral Supercomputer Job History Analysis\n\nOpenAIRE\n\nZasadziÅski, MichaÅ; MuntÃ©s-Mulero, Victor; SolÃ©, Marc; Ludwig, Thomas\n\n2018-01-01\n\nIn this technical report, we show insights and results of operational data analysis from petascale supercomputer Mistral, which is ranked as 42nd most powerful in the world as of January 2018. Data sources include hardware monitoring data, job scheduler history, topology, and hardware information. We explore job state sequences, spatial distribution, and electric power patterns.\n\nInteractive real-time nuclear plant simulations on a UNIX based supercomputer\n\nInternational Nuclear Information System (INIS)\n\nBehling, S.R.\n\n1990-01-01\n\nInteractive real-time nuclear plant simulations are critically important to train nuclear power plant engineers and operators. In addition, real-time simulations can be used to test the validity and timing of plant technical specifications and operational procedures. To accurately and confidently simulate a nuclear power plant transient in real-time, sufficient computer resources must be available. Since some important transients cannot be simulated using preprogrammed responses or non-physical models, commonly used simulation techniques may not be adequate. However, the power of a supercomputer allows one to accurately calculate the behavior of nuclear power plants even during very complex transients. Many of these transients can be calculated in real-time or quicker on the fastest supercomputers. The concept of running interactive real-time nuclear power plant transients on a supercomputer has been tested. This paper describes the architecture of the simulation program, the techniques used to establish real-time synchronization, and other issues related to the use of supercomputers in a new and potentially very important area. (author)\n\nPorting Ordinary Applications to Blue Gene/Q Supercomputers\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nMaheshwari, Ketan C.; Wozniak, Justin M.; Armstrong, Timothy; Katz, Daniel S.; Binkowski, T. Andrew; Zhong, Xiaoliang; Heinonen, Olle; Karpeyev, Dmitry; Wilde, Michael\n\n2015-08-31\n\nEfficiently porting ordinary applications to Blue Gene/Q supercomputers is a significant challenge. Codes are often originally developed without considering advanced architectures and related tool chains. Science needs frequently lead users to want to run large numbers of relatively small jobs (often called many-task computing, an ensemble, or a workflow), which can conflict with supercomputer configurations. In this paper, we discuss techniques developed to execute ordinary applications over leadership class supercomputers. We use the high-performance Swift parallel scripting framework and build two workflow execution techniques-sub-jobs and main-wrap. The sub-jobs technique, built on top of the IBM Blue Gene/Q resource manager Cobalt's sub-block jobs, lets users submit multiple, independent, repeated smaller jobs within a single larger resource block. The main-wrap technique is a scheme that enables C/C++ programs to be defined as functions that are wrapped by a high-performance Swift wrapper and that are invoked as a Swift script. We discuss the needs, benefits, technicalities, and current limitations of these techniques. We further discuss the real-world science enabled by these techniques and the results obtained.\n\nThe TESS Science Processing Operations Center\n\nScience.gov (United States)\n\nJenkins, Jon M.; Twicken, Joseph D.; McCauliff, Sean; Campbell, Jennifer; Sanderfer, Dwight; Lung, David; Mansouri-Samani, Masoud; Girouard, Forrest; Tenenbaum, Peter; Klaus, Todd;\n\n2016-01-01\n\nThe Transiting Exoplanet Survey Satellite (TESS) will conduct a search for Earth's closest cousins starting in early 2018 and is expected to discover approximately 1,000 small planets with R(sub p) less than 4 (solar radius) and measure the masses of at least 50 of these small worlds. The Science Processing Operations Center (SPOC) is being developed at NASA Ames Research Center based on the Kepler science pipeline and will generate calibrated pixels and light curves on the NASA Advanced Supercomputing Division's Pleiades supercomputer. The SPOC will also search for periodic transit events and generate validation products for the transit-like features in the light curves. All TESS SPOC data products will be archived to the Mikulski Archive for Space Telescopes (MAST).\n\nFeasibility study of introducing smart technologies in Barcelona Airport\n\nOpenAIRE\n\nGarcia Guiu, Anna\n\n2016-01-01\n\nThe objectives of the projectÂ are to define and evaluate the diferent alternatives for implementing new Smart concepts and technologies in Barcelona Airport. The structure of the project activities will follow an initial approach (not exhaustive) consisting of: Context and background, justification of the project,Â assessment of Barcelona Airport baseline, identification of needs, technolgy Stae-of the art, definition of potential solutions and implementation scenarios, evaluation of altern...\n\nXafardera?. No, esclava. Etnografia sobre les porteres de Barcelona\n\nDirectory of Open Access Journals (Sweden)\n\nJoana Brufau\n\n2010-06-01\n\nFull Text Available Bestard, Joan (ed. (2006. Les porteries a Barcelona. Entre lâespai pÃºblic i lâespai privat. Barcelona: Generalitat de Catalunya. Departament de Cultura. âUn poco dura esta profesiÃ³n. Aunque ellos [els veÃ¯ns] no lo crean, o es. Siempre hay un mal humor de ellos. Siempre hay alguna cosa, que la paga el trabajadorâ Testimoni dâuna portera recollit en el llibre\n\nUse of high performance networks and supercomputers for real-time flight simulation\n\nScience.gov (United States)\n\nCleveland, Jeff I., II\n\n1993-01-01\n\nIn order to meet the stringent time-critical requirements for real-time man-in-the-loop flight simulation, computer processing operations must be consistent in processing time and be completed in as short a time as possible. These operations include simulation mathematical model computation and data input/output to the simulators. In 1986, in response to increased demands for flight simulation performance, NASA's Langley Research Center (LaRC), working with the contractor, developed extensions to the Computer Automated Measurement and Control (CAMAC) technology which resulted in a factor of ten increase in the effective bandwidth and reduced latency of modules necessary for simulator communication. This technology extension is being used by more than 80 leading technological developers in the United States, Canada, and Europe. Included among the commercial applications are nuclear process control, power grid analysis, process monitoring, real-time simulation, and radar data acquisition. Personnel at LaRC are completing the development of the use of supercomputers for mathematical model computation to support real-time flight simulation. This includes the development of a real-time operating system and development of specialized software and hardware for the simulator network. This paper describes the data acquisition technology and the development of supercomputing for flight simulation.\n\nReactive flow simulations in complex geometries with high-performance supercomputing\n\nInternational Nuclear Information System (INIS)\n\nRehm, W.; Gerndt, M.; Jahn, W.; Vogelsang, R.; Binninger, B.; Herrmann, M.; Olivier, H.; Weber, M.\n\n2000-01-01\n\nIn this paper, we report on a modern field code cluster consisting of state-of-the-art reactive Navier-Stokes- and reactive Euler solvers that has been developed on vector- and parallel supercomputers at the research center Juelich. This field code cluster is used for hydrogen safety analyses of technical systems, for example, in the field of nuclear reactor safety and conventional hydrogen demonstration plants with fuel cells. Emphasis is put on the assessment of combustion loads, which could result from slow, fast or rapid flames, including transition from deflagration to detonation. As a sample of proof tests, the special tools have been tested for specific tasks, based on the comparison of experimental and numerical results, which are in reasonable agreement. (author)\n\nExtracting the Textual and Temporal Structure of Supercomputing Logs\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nJain, S; Singh, I; Chandra, A; Zhang, Z; Bronevetsky, G\n\n2009-05-26\n\nSupercomputers are prone to frequent faults that adversely affect their performance, reliability and functionality. System logs collected on these systems are a valuable resource of information about their operational status and health. However, their massive size, complexity, and lack of standard format makes it difficult to automatically extract information that can be used to improve system management. In this work we propose a novel method to succinctly represent the contents of supercomputing logs,"
    }
}