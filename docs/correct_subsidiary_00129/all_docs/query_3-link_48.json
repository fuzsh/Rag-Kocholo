{
    "id": "correct_subsidiary_00129_3",
    "rank": 48,
    "data": {
        "url": "https://patents.google.com/patent/US5708828A/en",
        "read_more_link": "",
        "language": "en",
        "title": "US5708828A - System for converting data from input data environment using first format to output data environment using second format by executing the associations between their fields - Google Patent",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://patentimages.storage.googleapis.com/9d/7e/1d/0626ce72a87d85/US5708828-drawings-page-2.png",
            "https://patentimages.storage.googleapis.com/ef/11/39/9775e73654deea/US5708828-drawings-page-3.png",
            "https://patentimages.storage.googleapis.com/b4/ec/0c/c16f57695f30d0/US5708828-drawings-page-4.png",
            "https://patentimages.storage.googleapis.com/0f/45/cf/cf3684444b1102/US5708828-drawings-page-5.png",
            "https://patentimages.storage.googleapis.com/ac/bb/e5/3be04134e7f57c/US5708828-drawings-page-6.png",
            "https://patentimages.storage.googleapis.com/d4/f7/07/a9d30ccaa9c5c7/US5708828-drawings-page-7.png",
            "https://patentimages.storage.googleapis.com/24/8e/b3/f26944a133a418/US5708828-drawings-page-8.png",
            "https://patentimages.storage.googleapis.com/93/61/ed/891ba2075b886e/US5708828-drawings-page-9.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "1995-05-25T00:00:00",
        "summary": "",
        "meta_description": "A data conversion system and method which converts data between different software and hardware platforms. The DCLE of the present invention converts data from any number of different types or formats from any of various platforms to a single common data standard having a pre-defined generic data type, and the data is then converted from this generic type to a new desired format or type and stored on an existing or new destination platform. Thus, the system and method of the present invention allows for multiple database conversions to be created easily and efficiently. The data conversion process begins by first defining a complete data map of the input and output data environments, as well as zero or more intermediate environments. Data objects referred to as data bridges and streams are created to logically connect or associate the input and output environments as well as the tables in the input and output data environments. In response to user input, the data conversion system and method creates an association between fields or parts in the tables (units) in the input environment and the fields in the output environment. This essentially involves creating user specified mappings between fields in the input data environment and fields in the output data environment. When an execute command is received, the data conversion system and method accesses data from the first input environment, i.e., accesses data from the storage medium storing the data to be converted, and converts the data from the first input data environment to data having a pre-defined generic data type. Converting the data first to a pre-defined generic data type greatly simplifies the conversion process, since conversion code is only required to and from the generic data type and is not required between every possible data format. Thus, the development of conversion code is much simpler and more efficient. Once data has been converted to the generic data object, the associations are executed to convert the data from the pre-defined genetic data type to the output data using the second data format.",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": "https://patents.google.com/patent/US5708828A/en",
        "text": "FIELD OF THE INVENTION\n\nThe present invention relates to methods for converting data between different formats, and more particularly to a data conversion language/engine which can be adapted to convert data from any of a number of first formats to any number of second formats.\n\nDESCRIPTION OF THE RELATED ART\n\nThe information systems (IS) departments of many corporations and business organizations have undergone radical change in recent years, including downsizing, rightsizing, or restructuring/reengineering. One component of this change has been the need for companies to perpetually upgrade their hardware, software, and data storage systems. Many corporations currently store data in legacy mainframe systems in the same manner as when the system was purchased, decades ago. However, as the data storage paradigm moves from mainframe storage systems to more cost-effective platforms, such as PC-based client-server systems, businesses with decades worth of archived business-dependent information stored in mainframe systems have faced difficulties in moving to PC-based client-server systems. In general, moving data between systems having different data storage formats, for example, from mainframe systems to PC-based client-server systems, is a very difficult, time-consuming task, which can take months or even years to complete and all too often fails before any of the promised cost savings are realized.\n\nTherefore, the process of data conversion, i.e., the process by which a large amount of information is moved from one informational system platform to another, has been very difficult. Today, corporations and other organizations process a large amount of transactions on any given day, including transactions related to financial reports, sales and accounting, human resources and personnel, or manufacturing and production. In general, information storage and information flow within an organization or business is very important to the success and well being of the business. As a result of the downsizing and corporate reengineering trends mentioned above, and due to the importance of information to a business or organization. Information systems and software processes are a prime target for corporate reengineering. This has traditionally involved converting data from large, mainframe-based systems to more cost-effective PC-based client server systems.\n\nOne difficulty in converting data between systems is that different data storage hierarchies are used in different systems. For example, mainframe systems use a hierarchical data storage method, whereas client-server systems use a relational database storage method. In addition, there are a large number of different data formats used in various systems.\n\nOne data conversion method that has been used historically can be referred to as the straightforward brute force method of data conversion. For this task, a core team of programmers is assembled for the sole purpose of creating one or more custom built programs from the ground up that will translate information from the platform currently in use to the format required by the destination platform. This process is time-consuming, cost-prohibitive and, more often than not, results in failure. This process also requires the use of highly-skilled programmers. Further, due to the custom nature of the software, the software is extremely difficult to change as problems arise.\n\nA second method of data conversion that has appeared more recently is an attempt to automate the processes utilized in the above \"brute force\" method. This method involves writing a \"code-generating\" program. According to this method, organizations use the skills of a programming team to develop a small engine capable of generating custom-built programs which perform the information transfer. In other words, a team of programmers creates a code-generating engine, and this code-generating engine can then be used to facilitate the development of custom-built programs to perform the information transfer. This method includes many of the drawbacks discussed above, and generally only automates the above \"brute force\" process. In essence, this method only removes a handful of the time and cost constraints which make the data conversion process a difficult task.\n\nApplicant is aware of a company called Evolutionary Technologies, Inc. located in Austin, Tex. which sells a product referred to as the Extract Migration package which performs data conversions. Applicant believes that this company is using one of the prior art methods described above. Some of the drawbacks of the Extract product is that this product is not easily adaptable to new environments without detailed programming knowledge of those environments. Also, all environments must be pre-defined and written before use of the Extract Migration package. Applicant is also aware of a company called Prism Software which uses similar methods to that described above.\n\nTherefore, an improved system and method for data conversion is desired to assist organizations in converting data between different hardware/software/application platforms.\n\nSUMMARY OF THE INVENTION\n\nThe present invention comprises a data conversion system and method which provides a simpler and more cost-effective method for converting data between different software and hardware platforms. The data conversion system and method of the present invention comprises a data conversion language/engine (DCLE) which is a powerful, hardware-independent, multi-user engine which requires no custom programming code. The DCLE of the present invention converts data from any number of different types or formats from any of various platforms to a single common data standard having a pre-defined generic data type, and the data is then converted from this generic type to a new desired format or type and stored on an existing or new destination platform. Thus, the system and method of the present invention allows for multiple data base conversions to be created easily and efficiently.\n\nThe present invention comprises an object-oriented software system including a plurality of data objects which represent the data being converted as well as perform the data conversion between different platforms. The present invention includes an environment data object which refers to a collection of tables, generally from a single application or data store, that have been grouped together into a single file. The tables within an environment are data objects referred to as units. In general, a table comprises a plurality of records in various formats. The present invention further comprises a data mapping object for the fields of the records themselves. A record comprises a plurality of fields, and the present invention uses field definition data objects referred to as parts which define the inner workings of a record, i.e., the type, the size, and the format, etc. of each field in a record.\n\nThe data conversion system and method preferably executes on a general purpose computer. The computer is preferably connected to the source storage medium storing the input data and a destination storage medium where the output data is to be stored. It is noted that the source and destination storage mediums can be the same medium. A user can either directly use the computer executing the data conversion system and method, or the user can remotely connect to the DCLE application.\n\nThe data conversion process begins by first placing the data to be converted into a form usable by the conversion engine. This step can have many different variations. The present invention makes the following assumptions regarding input data. First, since environments can only be bridged in a one to one or a one to many relationship, all input data destined for a single output environment is grouped in a single file. Secondly, all like records are grouped together into separate tables and have table delineations.\n\nThe first step in the data conversion is creating and defining input and/or output environments for the data within the DCLE engine. The user first defines a complete key map or data map of the data to import exactly as the DCLE engine must read the data from the data store file. This process begins by declaring all imported tables. The user then details these tables or units by declaring the data fields or parts that define each of the individual table's records. Once this process is completed, a completely defined input data file has been created. The user also defines a complete data map of the output data environment, i.e., defines the tables and parts of the data format of the output environment. It is noted that the only difference between the creation of input environments and output environments is the conceptual notion that the input environment is defined by the format of the data to be converted, whereas the data formatting fields of the output environment are created by the user based on his desires.\n\nDepending upon the complexity of changes to the data hierarchy itself, i.e., the arrangement and relationship of the units and parts between the different formats to be converted, one or more intermediate output environments may be created. Intermediate output environments are used for a variety of reasons including, first, to simplify the migration process itself by separating the process into smaller, more workable parts; second, to move a single store of imported data to multiple data base output files or even multiple different data base platforms; and third, to parse records into different output files for loading into separate databases or even separate database platforms. Intermediate output environments behave identically to normal output environments, and the process used to declare or create an intermediate output environment is identical to the process used to create input or output environments described above.\n\nIn order to logically connect the input data environment and the output data environment, an object referred to as a data bridge is created to logically connect or associate the environments in a one-to-one or one-to-many relationship. Bridges can be created between an input environment and one or more output environments or between an input environment and one or more intermediate environments. Bridges can also be created between an intermediate and one or more output environments. Bridges can only have a one-to-one or one-to-many mapping relationship.\n\nA user then enters logical associations between tables in the input and output data environments, and the data conversion system and method creates a logical association between tables in the respective input environment and tables in the respective output environment. These logical associations are referred to as a stream data objects. Unlike bridges, streams can form any relationship between input and output tables or units including one-to-one, one-to-many, many-to-one, and many-to-many.\n\nIn response to user input, the data conversion system and method creates an association between fields or parts in the tables (units) in the input environment and the fields in the output environment. This essentially involves creating user specified mappings between fields in the input data environment and fields in the output data environment. The user enters a plurality of commands referred to as MapTo commands, and these commands specify the mappings between fields or parts of tables. The MapTo command used in the present invention preferably follows similar guidelines to the syntax of an industry accepted standard transact SQL \"select\" statement.\n\nMapTo commands or associations are used to create different types of associations between fields or parts of individual units in respective environments. In addition to creating mappings between fields or parts, the MapTo command can also be used to create mathematical, logical, or conditional associations or statements.\n\nMathematical associations are created to perform mathematical manipulations or mathematical operations on fields or multiple fields. Logical associations are used to place logical true or false values into an output field based on a logical comparison that is performed. Conditional logic is used to evaluate one or more logical comparisons and then perform certain operations based on the result. One example of the use of a conditional association or statement is to input certain values into an output table only if certain logical assumptions are true.\n\nTherefore, from high to low level, bridge data objects are used to connect input data environments and output data environments. Streams comprise a subset of bridges and are used to connect individual tables or units in their respective input and output data environments. The data mappings or MapTo commands are a subset of each stream and represent the mapping themselves between fields or parts.\n\nWhen the above steps have been completed, the data conversion system and method has received essentially all the information required to begin a data conversion. The data conversion system and method then receives an execute command from a user to perform an indicated data conversion. In response to the execute command, the data conversion system and method accesses data from the first input environment, i.e., accesses data from the storage medium storing the data to be converted, and converts the data from the first input data environment to data having a pre-defined generic data type. Converting the data first to a pre-defined generic data type greatly simplifies the conversion process, since conversion code is only required to and from the generic data type and is not required between every possible data format. Thus, the development of conversion code is much simpler and more efficient.\n\nThe Generic data object comprises a block of memory which stores data of any type using one or more pre-defined format fields. In the preferred embodiment, the Generic data object comprises a Store field and a Type field for each piece of data, and a new instance of the Gdata object is created for each piece of data. The Store field is a buffer or segment of memory which stores the information portion of the data, and the Type field stores the type of the data. For example, if the data being converted is a Social Security number, the Store field stores the actual eight numbers comprising the Social Security Number, and the Type field stores the data type, in this case an integer data type. In the preferred embodiment, the Type field stores a numerical value which indexes into a list of types. Thus, a single instance of a Gdata object comprises a single data store and a single type field corresponding to that store.\n\nOnce data has been converted to the generic data object, the associations or MapTo commands are executed to convert the data from the pre-defined generic data type to the output data using the second data format. Execution of the MapTo commands comprises, for each table in the output data environment and for each stream to a respective table in the output data environment, performing a data conversion for each of the MapTo commands pointing to the respective output table for all of the streams to the respective output table. Once the MapTo commands have been executed, the data is converted to the new desired format. The converted output data is stored in a destination medium. It is noted that this destination medium may be the same medium on which the input data was stored or may be a new medium.\n\nTherefore, the present invention comprises an improved system and method for converting data between different formats or types. The present invention converts data to a pre-defined generic data object or generic data type and then converts data from this generic type to the new format. This simplifies the conversion process.\n\nBRIEF DESCRIPTION OF THE DRAWINGS\n\nA better understanding of the present invention can be obtained when the following detailed description of the preferred embodiment is considered in conjunction with the following drawings, in which:\n\nFIG. 1 illustrates the data conversion system and method executing on a computer system to convert data from a first storage medium to a second storage medium;\n\nFIG. 2A illustrates data conversions between different input and output data formats using prior art methods;\n\nFIG. 2B illustrates data conversions between different input and output data formats using the data conversion system and method of the present invention;\n\nFIG. 3 is a flowchart diagram illustrating operation of the data conversion system and method of the present invention;\n\nFIG. 4 illustrates the steps involved in creating a data environment as shown in FIG. 3;\n\nFIG. 5 illustrates structure of the generic data object;\n\nFIG. 6 illustrates the conversion of data from a first input data environment to data having a pre-defined generic data type and then to output data;\n\nFIG. 7 illustrates execution of associations or MapTo commands to produce converted output data;\n\nFIG. 8 illustrates generally the objects in the data conversion system and method; and\n\nFIG. 9 illustrates mapping from an input environment to an output environment and also illustrates objects comprised in the Workplace object of FIG. 8.\n\nDETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT\n\nReferring now to FIG. 1, the data conversion system and method of the present invention is preferably executed on a general purpose computer system. The present invention is used to convert data stored on a first storage medium 24 in a first data format to a second storage medium 26 in a second data format, possibly located on the same physical computer system. The data conversion system and method is also referred to herein as the \"data conversion language engine\" or DCLE. As used herein, the term \"data format\" means any of various configurations or arrangements of data, including data types, among others.\n\nIt is noted that the present invention not only performs conversions between different data types, but rather the present invention can also be used to perform conversions of the file formats, the headers and the footers of the file itself, as well as other conversions, as desired. Thus the present invention performs a plurality of different conversions other than, or in addition to, converting the data between data types. For example, the present invention can be used to convert a record having 5 fields to a record having 4 fields, or a record having 1 field, or a record having 7 fields. The present invention can be used to convert a record having 5 fields to a record having 5 fields but changing the data types of one or more of the records, or changing the delimiters, i.e., placing commas in between the fields, or adjusting the formatting, such as text formatting, placing \"enters\" in the data so that the data appears differently, etc.\n\nAs shown in FIG. 1, the computer system 22 executing the data conversion system and method of the present invention first receives input data from a user regarding the formats of the input and output data. The present invention then accesses the data in the first data format on the first storage medium 24 and provides the converted data to the second storage medium 26, wherein the converted output data has the second data format. FIG. 1 is an illustrative example only and shows conversion from a mainframe computer system 24 to a PC-based system 26. However, it is noted that the data conversion system and method of the present invention may be used when converting data from many of various storage mediums having any of various data formats to any of various output storage mediums also having any of various data formats. It is also noted that the first and second storage mediums may be the same medium, i.e., the data conversion system and method executing on the computer 22 can read data from the storage medium 24, convert the data to a new format, and then output the converted data back to the same medium, i.e., the medium 24, as shown by the dotted line between the computer 22 and the computer 24.\n\nIn one embodiment of the invention, a user enters various information into the computer 22 and then executes the data conversion system and method to perform the data conversion. In an alternate embodiment, one or more users may be at various remote locations from the computer 22 and can access the computer 22 via Internet or TCP/IP connections to access the data conversion system and method executing on the computer system 22. Also, it is noted that the computer systems 22 and 26 may be the same computer system.\n\nIt is also noted that the present invention may be used to convert data between any of various types of formats. For example, the data conversion system and method of the present invention can be used to convert data from a database in a first data format to a database having a second data format. Alternatively, the present invention may be used to convert video data having a first compressed format to video data having a second compressed format. Various other types of data format conversions can be performed using the present invention.\n\nThe data conversion system and method is a multi-user, object-oriented migration engine which converts or moves massive amounts of information between dissimilar platforms. The DCLE system of the present invention offers true multi-platform design capabilities, allowing conversion of legacy mainframe data to any modern relational database management system (RDBMS), or from any RDBMS to any mainframe platforms such as HP9000 running INFORMIX, or custom applications can be connected to the platform of choice. The present invention may also be used to convert data to a non-platform basis for data warehouse usage. Batch automation allows for hands-free data conversion on a nightly, weekly, or yearly basis--also perfectly suited for data warehousing.\n\nThe data conversion system of the present invention is preferably configured to operate with a variety of platforms, including Oracle, Sybase and other major RDBMS. The present invention preferably includes interfaces to the DCLE for Xwindows/Motif, MS Windows, OS/2, DOS, and UNIX. In the preferred embodiment, the data conversion system comprises a UNIX engine capable of converting and manipulating massive amounts of information. Alternate embodiments use MS Windows or OS/2 based engines, as desired. The present invention further includes multi-user socket functionality coupled with object-orientated application development, and also includes full security at both the user and object level to allow for complete protection of both environment and data. The present invention includes batch automation suited for both two and three tiered environments. Also, the data conversion system can be continually changed or modified according to the desired migration process, and is easily adaptable to new environments without detailed programming knowledge of those environments.\n\nFIG. 2A illustrates prior art data conversion methods which assume a plurality of input platforms on the left labeled A, B, C, D, E, and a plurality of output platforms also labeled A, B, C, D, E, as shown. As discussed in the background section, prior art methods require custom conversion code to perform conversions between each input data platform and each output data platform having different formats. Thus, a developer would have to create a complete library of programs, one for each combination of source and destination databases having different formats.\n\nAs shown in FIG. 2B, the present invention converts data from any of various different types of input data formats to a common pre-defined generic data format. Once the data has been converted to this common generic data format, the data is then converted to the desired output data format as shown. This greatly simplifies the data conversion method and allows for multiple data base conversions to be created easily and more efficiently.\n\nData Conversion Method\n\nIn order to perform data conversion between data having different formats, the input and output data are broken down into their respective component parts. The present invention uses a plurality of data objects which represent the input and output data. The term \"environment\" is used herein to refer to the respective data, i.e., to the input data and to the output data. More specifically, the term \"environment\" refers to a collection of tables normally from a single data store or application that are grouped together in a single file. The tables within an environment are referred to herein as units. A table comprises a plurality of records of data wherein each table has a different record format. According to the present invention, table-to-table conversions can have any of four mapping relationships including one-to-one, one-to-many, many-to-one, and many-to-many. A table or unit can be defined simply as a collection of like records, i.e., a collection of records of like type. One example of a table would be an employee's name, social security number, salary, date of birth, etc. The present invention also includes a data mapping object for records which utilize this field definition referred to herein as parts. Parts define the actual interworkings of a record, i.e., the type, the size, and the format of a respective record. In the example described above, the parts of the above employee data record would be the name field, the social security number field, the salary field, the date of birth field, etc.\n\nThe data conversion system and method of the present invention makes certain assumptions regarding the input data. First, the present invention assumes that since environments are only bridged in a one-to-one or one-to-many relationship, all input destined for a single output environment is grouped in a single file. The system and method of the present invention also assumes that all like records are grouped together in separate tables and the input file includes a table delineation.\n\nIn order to begin the data conversion process, a user is first required to input information regarding the input data in input data format and the desired output data format for the converted data. In a system where the user is remote from the computer system 22 where the present invention is executing, the user first connects to the system. The user can connect to the system in various manners including a TCP/IP connection utilities using a simple VT-100 style terminal connection program such as Telnet or UNIX Host Presenter or other types of connection methods. Once a connection has been made to the computer system 22 executing the data conversion system and method, the user is then queried for the account name and password. If the user enters the correct values, the user then may access the command interpreter of the system and may begin work. Alternatively, if the user is physically located at the computer system 22 executing the data conversion system and method of the present invention, the user simply logs on and optionally enters an account name and/or password before beginning operation.\n\nReferring now to FIG. 3, the dam conversion method is shown. In step 200, the system receives a user specified definition of the first data format, i.e., of the input environment where the data to be converted is stored. In other words, here the user enters information regarding the units and parts (tables and fields) of the input data. FIG. 4 illustrates more detail regarding the creation of a data environment. As shown, creation of a data environment in step 400 includes specifying (or creating) all tables or units in step 402 and specifying (or creating) all fields or parts in step 404. Thus, here the user specifies the data format of the input environment including all of the tables or units and all of the parts or fields of the respective records in each of the respective tables.\n\nIn creating the initial input environment, the user enters a command similar to the following:\n\nMKENV INPUT\n\nThis command is used to begin the creation of the input environment. Commands are entered either through physical keyboard entry, or a GUI (graphical user interface) point and click command, or creating a batch command and uploading the command in the DCLE engine.\n\nThe user also defines, from the ground up, a complete key or data map of the input data exactly as the conversion system must read the data from the data store file. This process begins by declaring imported tables using commands similar to the following:\n\nThis process begins by declaring all imported tables using commands similar to:\n\nMK UNIT INPUT:TABLE 1\n\nMK UNIT INPUT:TABLE 2\n\nMK UNIT INPUT:TABLE 3\n\nMK UNIT INPUT:TABLE N\n\nThe user then details these tables or units by declaring the data fields or parts that define each of the individual table's records. This step uses commands similar to the following:\n\nMK PART INPUT:TABLE 1:PART 1\n\nMK PART INPUT:TABLE 1:PART 2\n\nMK PART INPUT:TABLE 1:PART N\n\nOnce this process is completed, a completely defined input data file has been created.\n\nIt is noted that the user can save his work in this environment by using the command:\n\nSAVE ENV OUT\n\nAlso, if the user desired to leave the session and reopen it later, the commands upon reentry would be:\n\nLOAD ENV INPUT\n\nLOAD ENV OUTPUT\n\nOptionally, the user could place both environments in a work file. The commands to add and remove items from the work file are:\n\nADD WK INPUT.ENV\n\nADD WK OUTPUT.ENV\n\nRM WK INPUT.ENV\n\nRM WK OUTPUT.ENV\n\nIn addition, the user can load all of the items presently listed in the work file by simply using the command LOAD WK. A command referred to as SHOW WK is used to show the work file and is used if the user is unsure of the objects currently in the work file.\n\nIt is also noted that the input data format may be defined by a data dictionary associated with the input data environment. In this embodiment, the definition of the first data format is received by receiving the data dictionary of the first data format and then converting the data dictionary into a definition of the first data format useable by the data conversion system and method.\n\nIn step 201, the data conversion system and method receives a definition of any desired intermediate data formats, i.e., any desired intermediate environments. In some data conversion applications, it may be undesirable and/or impractical to perform a full conversion between the source or input data environment and the destination or output data environment. In these situations, it may be easier to create one or more intermediate data environments where the input data is converted first to the intermediate data environment and then converted from the intermediate data environment to the output data environment. Thus, depending upon the complexity of changes to the data hierarchy itself, i.e., the arrangement and relationship of the units and parts between the different formats to be converted, one or more intermediate output environments may need to be created.\n\nIntermediate output environments are used for a variety of reasons including, first, to simplify the migration process itself by separating the process into smaller, more workable parts; second, to move a single store of imported data to multiple data base output files or even multiple different data base platforms; and third, to parse records into different output files for loading into separate data bases or even separate data base platforms. Intermediate output environments behave identically to normal output environments. The only difference between a normal output environment and an intermediate output environment is that an intermediate output environment is used after execution as the input environment for another execution later on in the conversion process. The process used to declare or create an output environment or an intermediate output environment is identical to the process used to create input environments described above. The primary difference between the creation of input environments and output environments is the conceptual notion that the input environment is defined by the format of the data to be converted, whereas the data formatting fields of the output environment are created by the user based on his desires.\n\nTherefore, in step 201, if the user desires to use one or more intermediate data environments in the data conversion process, the user enters information regarding the respective intermediate environments and units and parts for each of the respective intermediate environments. These definitions are received by the system in step 201. It is noted that the creation of intermediate environments is optional depending upon the user's application.\n\nIn step 202 the data conversion system and method receives a definition of a second data format--in this example, the data format for the output environment. This involves the user entering information regarding the output or destination environment, including the desired tables that the output environment will have as well as the parts or fields for each of the respective tables. This step is discussed in greater detail with respect to FIG. 4. It is noted that the creation of data formats does not require that the format be specified as an input format or an output format. Rather, once a data format environment has been created, this data format environment can be used as either an input, intermediate, or output data format.\n\nAfter steps 200, 201 and 202 have completed, the data conversion system and method has received the full information regarding a fully defined data migration or conversion process from an initial input environment to one or more output environments and including one or more intermediate environments as desired.\n\nCreate Bridge Object\n\nIn order to logically connect or logically associate the input data environment and the output data environment, an object referred to as a data bridge is created to connect the environments in a one-to-one or one-to-many relationship. Bridges can be created between an input environment and one or more output environments or between an input environment and one or more intermediate environments. Bridges can also be created between an intermediate and one or more output environments. Bridges can only have a one-to-one or one-to-many mapping relationship. The command to create bridges between environments is:\n\nCREATE BRIDGE INT ENV! OUT ENV!\n\nAs shown in step 204, a bridge essentially comprises a logical association between first and second environments--in this example between input and output data environments. A bridge can also be created between input and intermediate data environments, between intermediate and intermediate data environments and intermediate and output data environments.\n\nWhen a bridge object is created, i.e., when a logical association is created between environments, the data conversion system creates pointers to the two environments. A bridge object includes a pointer to the first environment and a pointer to the second environment, and also includes a pointer to a linked list of the respective streams between the two environments.\n\nCreate Stream Objects\n\nIn step 206, in response to a user entering logical associations between tables in the input and output data environments, the data conversion system and method creates a logical association between tables in the respective input environment and tables in the respective output environment. These logical associations are referred to as a stream data objects. The command to create a stream between input and output tables is:\n\nCREATE STREAM IN:TABLE! OUT:TABLE!\n\nUnlike bridges, streams can form any relationship between input and output tables or units including one-to-one, one-to-many, many-to-one, and many-to-many. The bridges and streams created in steps 204 and 206 are essentially logical connections between data areas, and it is noted that no information at the record level has been specified for conversion.\n\nWhen a stream object is created, i.e., when a logical association is created between tables or units, the data conversion system creates a pointer to the respective source and destination tables. A stream object includes a pointer to the respective bridge, a pointer to the source table, a pointer to the one or more destination tables, and also includes a pointer to a linked list of the respective MapTo commands within the respective stream object.\n\nCreate MapTo Commands\n\nIn step 208, in response to user input, the data conversion system and method creates an association between fields or parts in the tables (units) in the input environment and the fields in the output environment. Therefore, step 208 essentially involves creating user specified mappings between fields in the input data environment and fields in the output data environment. In step 208, the user enters a plurality of commands referred to as MapTo commands and these commands specify the mappings between fields or parts of tables. The MapTo command used in the present invention preferably follows similar guidelines to the syntax of a transact SQL \"select\" statement. As is well known, the transact SQL select statement is the backbone of all SQL servers, examples of which include Sybase, oracle, INFORMIX, ingres, etc. The format of a transact SQL select statement is as follows:\n\n__________________________________________________________________________ SELECT INTO <output>.sub.-- table> : <(dest.sub.-- var1, dest.sub.-- var2, dest.sub.-- var3, . . . , dest.sub.-- varN> FROM <input.sub.-- table> : <src.sub.-- var1, const 12345, src.sub.-- var3, . . . , src.sub.-- varN> WHERE <src.sub.-- varx || constant> <operator> <src.sub. -- vary || constant> <<operator> <another expression as above>> < . . . ad infinitum . . . > __________________________________________________________________________\n\nThe MapTo command according to the system and method of the present invention is similar to the above SQL select statement and is as follows:\n\n______________________________________ MAP10 <outenv:outtable> {dest.sub.-- col1, dest.sub.-- col2, dest.sub.-- col3, . . . , dest.sub.-- colN> FROM <inenv:intable> {src.sub.-- var1, const 12345, src.sub.-- col3, . . . , src.sub.-- colN> WHERE <src.sub.-- varx || constant> <operator> <src.sub. -- vary || constant> <<operator> <another expression as above>> <. . . ad infinitum . . . > ______________________________________\n\nThus, the core of every command has 3 distinct parts.\n\nMAPTO part: this part details the destination of the information processing\n\n<outenv:outtable> this tells you where the bridge/stream attaches on the destination side.\n\n<dest-- column list> this list is preferably comprehensive, i.e., there is preferably a column in this list for every column in the output table. If not, then for each record, columns not included will be populated with NULLS or 0.00's. The order of this list is unimportant, except that it must match the list on the input side, i.e., the FROM part of the MapTo statement.\n\nFROM part: this part details the source side of the information processing.\n\n<inenv:intable> this indicates where the bridge/stream attaches on the source side.\n\n<Src-- column list> this list need not be a complete list of all variables present in the source-- env:source-- table, but simply a comprehensive list of all variables the user desires to transfer into the destination table. The order of these variables destination side will be filled with the value of the first input column or the first constant provided in the FROM section <src-- column list>. Note: Expressions are also allowed within the src column list, so that if the first column of the destination list were a string called `Column1` then the following would be acceptable examples of items to place as the first element of the FROM <src-- column list>:\n\n______________________________________ FROM <inenv:intable>in.sub.-- column1 `Test Column` `12345` (in.sub.-- column1 + in .sub.-- column2) (`AAA`=`bbb`) /*this last would enter the string `FALSE`*/ ______________________________________\n\nWhere Part: The where section is the conditional logic section of this MapTo statement, i.e., for each record processed by this MapTo statement, only perform the mapping if this WHERE statement is evaluated to be TRUE.\n\n<src-- varxâ¥constant><operator><src-- varxâ¥constant> this is a standard expression, and may be coupled with other expressions using standard parenthetical operators to result in a final evaluation of either TRUE or FALSE. Whenever TRUE, the MapTo command will proceed with the mapping as specified in the MapTo and FROM sections of the statement, and when FALSE, this record will be skipped and no action will be taken. Note: The where section is optional. If the intention of the user is to migrate every record of the input table to the output table, with no conditions whatsoever, then the WHERE statement and all of its component parts can be eliminated from the MapTo command entirely.\n\nMapTo Associations\n\nMapTo commands or associations are used to create different types of associations between fields or parts of respective environments. In addition to creating mappings between fields or parts, the MapTo command can be used to create either mathematical, logical, or conditional associations or statements.\n\nMathematical associations are created to perform mathematical manipulations or mathematical operations on fields or multiple fields. For example, mathematical associations are used to multiply certain fields by certain values to obtain new data, such as multiplying a salary field times a constant or another field within the record, or adding a certain value to the salary to obtain a new value for the salary to be placed in the output table.\n\nLogical associations are used to place logical true or false values into an output field based on a logical comparison that is performed. For example, if the user desires to fill in a string or Boolean field on the output side with the values 0 or 1 or true or false, the result of the logical association would place a TRUE or FALSE value in the field. One example of a logical association is \"Sex=Male\". The output of this association is a 1 or true value if the field of the record being examined indicates a male. If not, then it would enter a 0 or false value in the field. A logic association or statement differs from a conditional statement because a mapping is performed regardless of the result of the comparison, i.e., for this record a value will be placed into the field of the respective output table. The only question is whether a true or false, or 0 or 1, will be placed based on this logical equation.\n\nConditional logic is used to perform a logical comparison and then perform certain operations based on the result. One example of the use of a conditional association or statement is to input certain values into a output table only if certain logical assumptions are true. A specific example is, if number of years employed is greater than X, then map name, street, address to the respective table. Thus, conditional logic allows a user to create an association that doesn't necessarily populate for every record on the input side to the output side, but rather only the ones that fulfill the specified criteria.\n\nThe data conversion system includes a parser/map engine including an expression parser. The expression parser or engine examines expressions such as (((3+X)Ã4) or sign true)Ã50)>=30 and returns a true or false value, depending on the values of X or Y or whatever variables are included in the expression. The expression engine also executes expression and returns the appropriate values, such as 50Ã20+XÃ4 divided by 30 times Y.\n\nThe map engine allows a user to include expression statements in MapTo commands. For example, if a user desired to multiply a salary value by a certain fraction to compute a raise, the user includes the appropriate mathematical expression in the MapTo command, and the map engine executes the expression. As another example, is a user were performing a data conversion and desired to compute stock options for key employees, the user would enter the appropriate expression which is then executed during the data conversion to compute the stock options. As another example, if the data being converted includes three classifications for a call center and it is desired that the output data have a much greater number of classifications for the call center, the user can include an expression including mathematical calculations on, for example, sales as a percentage of unit sold minus variable cost, wherein the result places data in a respective call center classification.\n\nTherefore, from high to low level, bridge data objects are used to connect input data environments and output data environments. Streams comprise a subset of bridges and are used to connect individual tables or units in their respective input and output data environments. The data mappings or MapTo commands are part of each stream and represent the mapping themselves between fields or part and are created using MapTo commands as previously described.\n\nWhen steps 200-208 have been completed, the data conversion system and method has received essentially all the information required to begin a data conversion. In step 210, the data conversion system and method receives an execute command from a user to perform an indicated data conversion. The format of the execute command is described below.\n\nData Conversion\n\nIn step 212, the data conversion system and method accesses data from the first input environment, i.e., accesses data from the storage medium storing the data to be converted. In step 214, the data conversion system and method converts the data from the first input data environment to data having a pre-defined generic data type. When an execute command is received, the input data is accessed, and the data conversion method immediately converts data from any of various data types including int, char, string, byte, float, packed, etc. to a generic data type. The generic data type is a defined object referred to as Gdata (generic data) and has the capabilities of storing information regardless of the original format of the input data. Thus the data conversion system and method of the present invention includes its own data type.\n\nAs described further below, conversion of data to the Gdata type comprises creating an instance of the Gdata object and storing the information portion of the data in a first field and storing the type information of the data in a second field. Converting the data fast to a pre-defined generic data type greatly simplifies the conversion process, since conversion code is only required to and from the generic data type and is not required between every possible data format. Thus, as shown in FIGS. 2A and 2B, the development of conversion code is much simpler and more efficient.\n\nSystems which do not use a generic data type require a much greater mount of mapping code than the present invention. For example, consider 6 data types such as integer, character, string, byte, float, and packed. In order to convert from each of these data types to the other respective types, a program would have to be specifically developed for each conversion, such as integer to byte, integer to character, integer to string. Instead, the present invention uses a specific conversion to a pre-defined generic data type. Any data type can be converted to the generic data type, and the generic data can be converted to any data type. When it is desired to convert to or from a new data type, it is only necessary to create conversion code from the new data type to the generic data type and from the generic data type to the new data type. It is not necessary to create conversion code specifically for each data type to and from the new data type. This reduces the amount of coding substantially.\n\nThe step of converting the data from the first input data environment to data having a pre-defined genetic data type is discussed in greater detail with reference to FIGS. 5 and 6 below. Further, a source code listing is included with the present disclosure which further describes the operation of the genetic data (Gdata) object of the present invention.\n\nIn step 216, the associations created in step 208 are executed to produce converted output data using the second data format. Execution of these associations or MapTo commands converts the data from the generic data type to data having the second format. It is noted that steps 212-216 are essentially performed together, i.e., the respective data is accessed to convert it from the first input data environment to the pre-defined generic data type, and then the associations are executed to convert the data from the pre-defined genetic data type to the output data using the second data format. In step 218 the converted output data is stored in a destination medium. It is noted that this destination medium may be the same medium on which the input data was stored or may be a new medium.\n\nGeneric Data Object\n\nReferring now to FIG. 5, the Gdata or Generic Data Type object accommodates or consolidates all of the possible data types, including, but not limited to, string, integer, float, byte, packed, decimal. Data of any type can be converted to or from the genetic data type, as desired.\n\nIn the preferred embodiment, the Gdata object is a standard block of memory which stores data of any type using one or more pre-defined format fields. In the preferred embodiment, the Gdata object comprises a single large buffer space including a \"Store\" field and a \"Type\" field. The Store field is a buffer or segment of memory which stores the information portion of the data, and the Type field stores the type of the data. For example, if the data being converted is a Social Security number, the Store field stores the actual eight numbers comprising the Social Security Number, and the Type field stores the data type, in this case an integer data type. In the preferred embodiment, the Type field stores a numerical value which indexes into a list of types. Thus, a single instance of a Gdata object comprises a single data store and a single type field corresponding to that store. In the preferred embodiment, a new instance of the Gdata object is created for each piece of data.\n\nVarious operators may be applied to the Gdata object, including Equal To (EQ), Not Equal To (NE), Less Than (LT), Greater Than (GT), Less Than/Equal To (LE), Compare (CMP), Greater Than/Equal To (GE), Multiply (MPY), Addition (ADD), Subtraction (SUB), and Division (DIV), among others. As shown at the bottom of FIG. 5, input data is first converted to the Gdata object, i.e., to the generic data format, and is then converted from the Gdata format to the output format.\n\nIn an alternate and less preferred embodiment, the Gdata object does not include a single \"Store\" field, but rather includes a plurality of \"space-holders\" or variables which are full or empty depending on the nature of the data type being converted. In one embodiment, the Gdata object includes a float space, an integer space, and a string space which is used for all of the information being converted of any data type. If the data type being converted is a string, the variable for string data types is created and contains data, if the data type being converted is an integer, the variable for integer data types is created and contains data, etc. Thus, in this embodiment, the Gdata object includes a plurality of variables within the object corresponding to different data types, and respective individual variables in the Gdata object are formed depending on the type of data being converted. It is noted that some of the variables are used for multiple data types. For example, the packed, fixed, and character data types are stored in the string variable or space. Also, the integer variable holds various types of variables, including short integers, long integers, etc.\n\nOperator overwrites are included on the Gdata object to enable comparisons between the respective Gdata object and other Gdata objects. These operator overwrites allow various types of manipulations or operations on data in the Gdata object, allow comparisons and operations between different Gdata objects, and allow comparisons and operations between and among data in a respective Gdata object.\n\nReferring now to FIG. 6, a diagram is shown illustrating the conversion of data from an input record to the Gdata format, and then from the Gdata format to output data. An input record comprises a plurality of parts, and the operations shown in FIG. 6 are performed for each input record part. As shown, an input record part such as part PN is first converted to the Gdata format. Conversion of input data to the generic data format comprises storing the \"data\" or \"information\" portion of the data in a Store field and storing the type information of the data in a Type field as described above.\n\nOnce the data has been converted to the generic data type, one or more operators are invoked on the data, depending on whether the user has specified operations on the data. In performing these operations, one or more Gdata objects or other constants may be called, as necessary. The MapTo executions are then performed to generate the output data in the correct output record part format.\n\nA source code listing is included with the present specification to further describe the operation of converting data to the Gdata object.\n\nMapTo Command Execution\n\nReferring now to FIG. 7, a more detailed flowchart diagram illustrating the steps performed in step 216 on FIG. 3 is shown. Execution of the MapTo commands in step 216 comprises, for each table in the output data environment and for each stream to a respective table in the output data environment performing a data conversion for each of the MapTo commands pointing to the respective output table for all of the streams to the respective output table as shown in steps 422-426.\n\nObject Descriptions\n\nThe data conversion system and method comprises a plurality of software objects executing on the computer system 22 of FIG. 1. These objects are shown generally in FIGS. 8 and 9. Referring now to FIG. 8, the data conversion system and method includes a Server object which is an instance of the data conversion program. The data conversion system further includes a Userlist object comprising a linked list of all User objects, and an Interface object comprising a list of all Connection objects. The data conversion system further includes a Workplacelist object comprising a linked list of all Workplace objects. The objects comprised in the Workplace object are shown generally in FIG. 9 in the context of mapping from an input environment to an output environment.\n\nAs shown in FIG. 9, the Workplace object includes environment, unit and part objects, as well as bridge and stream objects, among others. The various objects comprised in the data conversion system are described below.\n\nServer. The server object is an instance of the entire data conversion program and is \"at the top\" of the object hierarchy. The server allows a user to call or invoke the entire program to bind to a single port. Thus if the user desired that one copy of a program run on three separate ports, each having its own isolated workplaces, user entry and user list, this can be accomplished within a single execution of the program running three different times. Thus the entire program itself comprises a large object.\n\nInterface. The interface object connects to the socket which allows users to log in and connect to the data conversion system. The interface object also allows for multi-user connectivity. An analogy can be made to a house where, if the server itself is a plot of land with the house on it, the interface is the front door, or more closely is akin to a butler that constantly listens for new people arriving at the house.\n\nConnection. Whenever a new person connects to the data conversion system and method, a new connection object is created. In the analogy above, a connection is created every time a single user comes in and knocks on the door.\n\nUser. The user object is similar to the connection object except that the user actually has permission, i.e., the user actually has a name, a password and possibly other information that allows the user object access to the data conversion system. In contrast, a connection is simply a raw connection within the interface.\n\nWorkplace. The workplace is where the \"work\" is performed, i.e., where the environments are created. Everything pertaining to a conversion is comprised within a single workplace, including environments, tables, and parts as well as streams, bridges, and MapTo's. In the analogy above, the workplace is the room that a person works within. Thus if a first user is working in one workplace and a second user is working in a second different workplace, the first and second users do not see each others information and cannot work on the same data conversion. It is noted that a user can be moved into a new workplace to work on a common data conversion, and that environments can be cloned for passing into other workplaces.\n\nUserlist. Workplacelist. Two objects referred to as Userlist and Workplacelist are used internally as commands to determine the current users and workplaces. Userlist is simply a linked list of all the users on line, i.e., a linked list of user objects. The workplace list object comprises a linked list of all currently opened workplaces.\n\nEnvironment. The environment object refers to the respective data, i.e., to input data, output data, or any intermediate data. More specifically, the term \"environment\" refers to a collection of tables normally from a single data store or application that are grouped together in a single file.\n\nUnit. The unit object comprises a plurality of records of data wherein each unit or table has a different record format. A table or unit object can be defined as a collection of like records, i.e., a collection of records of like type. One example of a table would be an employee's name, social security number, salary, date of birth, etc.\n\nPart. The part object comprises the actual interworkings of a record, i.e., the type, the size, and the format of a respective record. In the example described above, the parts of the above employee data record would be the name field, the social security number field, the salary field, the date of birth field, etc.\n\nBridge. The bridge object comprises a logical association between two environments. More specifically, a bridge object comprises pointers to two or more different environments.\n\nStream. The stream object comprises a logical association between unit objects within two or more environments connected by a bridge object.\n\nExpression. An expression object is used internally for the MapTo command. A general MapTo command is more than a single object, but rather comprises a linked list of expression objects. In general, an expression object is a collection of pointers between parts in different environments. Thus, a bridge object comprises a pointer to two different environments. A stream object is a subset of a bridge object and includes pointers to the streams in the respective bridge object. The stream object includes pointers to the input and output tables, and the MapTo commands within a stream comprise a linked list of expressions. Each expression object includes a pointer on the input side and may include one or more constants and/or operators that performs either mathematical, logical, or conditional operations on the data. The data conversion system and method resolves each expression object when executing a MapTo command.\n\nFormat. The format object contains the formatting for inputting and outputting data. For example, the string (%4 b) indicates 4 bytes; the string (#%6 SË) indicates a constant number sign plus a 6 byte string followed by a tilde or return. This format is similar but not identical to standard data referencing used in the C programming language.\n\nI/O Queue and InterruptQueue. The I/O queue object and the interrupt queue object are used in the multi-user engine of the data conversion system to provide a buffering system for each user. Thus if a user is typing a command from a remote location and the connection starts going slowly, the engine buffers one or more commands to enable the user to continue working and these commands are fed through later. Thus if the system lags or slows down and the user continues entering data, the data conversion system will not lose any of the user's commands or data.\n\nOrdlist. The Ordlist object is a linked list template or object class. The data conversion system uses a plurality of linked lists, and thus the Ordlist object serves as a higher level object class for each of the linked lists. Many of the objects in the data conversion system are of type \"linked list\" or Ordlist. For example, the workplace list and the user list.\n\nMember. The member object comprises a portion of the expression object and is used in the internal parsing of the MapTo command.\n\nFile Mgr. A user declares a file within the UNIX system by providing a filename and requesting a new instance of the file. The File Manager object allows a user to perform open, close, read, write, and other operations on a file object. The File Manager object comprises a linked list of all files.\n\nFile. The File object is used for reading the input and output data stores, and is also used for the introduction and the help screens where the user logs in.\n\nString. The string object facilitates manipulations that are required for strings, including concatenating strings, reading strings, writing strings, performing string to string compares, string to strings compares assuming all uppercase, strings to strings compares assuming all lowercase, adding, subtracting, etc.\n\nGdata. The Gdata or the generic data object is a large object which embodies the pre-defined generic data type. The Gdata object performs conversions to and from the generic data type according to the present invention. Operator overwrites are included to enable the Gdata object to add strings to integers, integers to strings, is string greater than 5, etc. As discussed above, conversions are performed from the Gdata object to and from all the other defined objects. As new objects are received, for example, a new packing algorithm is necessary for a new data type, it is only necessary to create conversion code for conversions to and from the Gdata object, and it is unnecessary to specifically develop conversion code for and between each of the types of objects.\n\nSystem Commands\n\nThe system commands used in the data conversion system and method are as follows:\n\n______________________________________ Shutdown Clear Syslog Chmod Dc Goto Clone Pass Rename Version Who Finger Whoami Last Passwd Useradd Userdel Mkenv Rmenv Loadenv Saveenv Loadbridge Savebridge Loadwork Addwk Rmwk Listwk Mkunit Rmunit Mkpart Rmpart Mksubpart Rmsubpart Show View Msg Send Wall Users Log Mapto Execute Rmmapto Create Move Quit ______________________________________\n\nCommand Definitions\n\nShutdown\n\nsyntax: shutdown\n\nThis command allow the system administrator to instantly shutdown the DCLE process, killing any child processes without saving any of the conversion information. All connections to the engine are also instantly cut. The DCLE process does not reinitialize unless it is initialized again from Unix.\n\nClear\n\nsyntax: clear\n\nThis command simply allows any user to clear his/her screen of old information.\n\nSyslog\n\nsyntax: syslog<onâ¥off>\n\nThis command allows the systems administrator to toggle the system log on or off. This informs the engine whether or not to display certain system information to the administrator including connections, dc's, hangups, logins, logouts and executions. It is noted that, regardless of whether the system administrator has syslog on or off, the information is saved to a log file in Unix for later reference.\n\nChmod\n\nsyntax: chmod<workplacename><username><newsecuritylevel>\n\nThis command allows the systems administrator or workgroup owner to change the security permissions for a given user in a given workplace. This command overrides a user's general security level to give or restrict access to sensitive information. If a * is used for <username> then this command globally assigns the security level to every user except the system administrator.\n\nDc\n\nsyntax: dc <socketnum>\n\nThis command allows the system administrator to disconnect a user from his socket connection. For security purposes or for general maintenance it sometimes becomes necessary to remove a user from his connection to the DCLE.\n\nGoto\n\nsyntax: goto <workplacename>\n\nThis command allows a user to change workplaces within the DCLE work environment. For security reasons a user cannot simply access any given workplace unless his security level for that workplace allows it.\n\nClone\n\nsyntax: clone <environname><newenvironname>\n\nFor purposes of sharing work, this command allows a user to make a copy of an environment including all units, parts, subparts, etc., but not including bridges and streams.\n\nPass\n\nsyntax: pass <environname><destworkplace>\n\nAfter an environment has been Cloned, this command allows the user to transfer the environment to another workplace so that other users can manipulate the environment.\n\nRename\n\nsyntax: rename <environname><newenvironname>rename <env:unitname><env:newunitname>rename <env:unit:partname><env:unit:newpartname>\n\nThis command allows a user to change the name of an environment, unit, part, or subpart.\n\nVersion\n\nsyntax: version\n\nThis command displays the current version number of the DCLE program.\n\nWho\n\nsyntax: who\n\nThis command allows a user to see who is logged on to the DCLE program. This command displays the name, workplace, and last command for every user that is logged on.\n\nFinger\n\nsyntax: finger <user>\n\nThis command allows a user to find out information about other users. This command shows a user's real name, workplaces owned, date and time of last login, date and time of account creation, and the last site from which the user logged in.\n\nWhoami\n\nsyntax: whoami\n\nThis command shows a user the account name of the connection he/she currently has open in the DCLE program.\n\nLast\n\nsyntax: last <user>\n\nThis command allows a user to see when another user last logged in to the DCLE program. This command displays the account name, time and date of last login, and the last site from which the user logged in.\n\nPasswd\n\nsyntax: passwd <user><newpassword><oldpassword>\n\nThis command allows a user or the system administrator to change a user's account password. A user can only change his/her own password and must enter his/her old password for security reasons. The system administrator can change any user's password and does not have to enter that user's old password.\n\nUseradd\n\nsyntax: <useradd><user><passwd><seclevel><usersrealname>\n\nThis command allows a system administrator to enable a new user account. The system administrator must provide the new user name, password, and security level. A new user defaults to the common workgroup. At the system administrator's discretion, the user's real name can be added to the account information. However, this field is completely optional.\n\nUserdel\n\nsyntax: userdel <user>\n\nThis command allows a system administrator to disable an existing user account. This does not clean out a user's workplaces or destroy his/her work. Any workplace owned by the disabled account is reassigned to the system administrator and no other security levels are changed on those workplaces.\n\nMkenv\n\nsyntax: mkenv <envname>\n\nThis command allows a user to create a new environment. The new environment occurs within the user's current workplace and can be manipulated by any other user in that workplace.\n\nRmenv\n\nsyntax: rmenv <envname>\n\nThis command allows a user to delete an existing environment. When an existing environment is deleted, all attached units and parts are also lost.\n\nLoadenv\n\nsyntax: loadenv <env.filename>\n\nThis command loads an existing environment into the DCLE program from Unix. All attached units, parts, and subunits are also loaded. An environment is loaded into whatever workplace the user is in at the time. Note: Multiple environment of the same name cannot be loaded at the same time.\n\nSaveenv\n\nsyntax: saveenv <envname><env.filename>\n\nThis command allows a user to save the current environment loaded in his workplace. The user must provide the name of the environment and a filename under which the environment is to be saved. All attached units and parts are also saved.\n\nLoadbdg\n\nsyntax: loadbdg <bridge.filename>\n\nThis command allows a user to load all existing bridges, streams, and mappings associated with a given environment into the DCLE program from Unix. All instances of conditional logic are also loaded. All bridges are loaded into whatever workplace the user is in at the time.\n\nSavebdg\n\nsyntax: savebdg <bridge><bridge.filename>\n\nThis command allows a user to save the current set of bridges currently in use in a given workplace. The user must provide the name of the bridge and a filename under which the bridge is to be saved. All streams, maptos, and instances of conditional logic associated with a given bridge are also saved.\n\nLoadwork\n\nsyntax: loadwork <workfile.name>\n\nFor the sake of convenience, this command allows a user to load an environment and bridges all at one time. This command is a combination of the loadbdg and loadenv commands and is simply used as a time saver.\n\nAddwk\n\nsyntax: addwk <work.filename><workfile.name>\n\nThis command allows users to include a new environment or bridge file to the existing workfile index. The next time the loadwork command is executed the new file is loaded. It is noted that the actual filename of the environment or bridge file must be used.\n\nRmwork\n\nsyntax: rmwork <work.filename><workfile.name>\n\nThis command allows a user to remove an existing environment or bridge file from the workfile index. The next time the loadwork command is executed the removed file is not loaded. It is noted that the actual filename of the environment or bridge file must be used.\n\nListwk\n\nsyntax: listwork <workfile.name>\n\nThis command simply allows the user to display what filenames are included in the workfile index.\n\nMkunit\n\nsyntax: mkunit <env:unitname><unitformat>\n\nThis command allows a user to create a new unit within an existing environment. The user must specify which environment the unit is to be attached and the format of the unit, especially on the output environment. When a new unit is created it is added to the bottom of the list of all existing units.\n\nRmunit\n\nsyntax: rmunit <env:unit>\n\nThis command allows a user to remove an existing unit from the list of units within a given environment. After a unit has been removed all other units are renumbered to prevent holes in the list. All existing parts and subunits attached to a unit are also lost.\n\nMkpart\n\nsyntax: mkpart <env:unit:partname><dataformat><datatype><bytelength>\n\nThis command allows the user to create a new part under an existing unit or subunit within the existing environment.\n\nRmpart\n\nsyntax: rmpart <env:unit:(subunit):partname>\n\nThis command allows a the user to delete a part under an existing unit or subunit within the existing environment. All mappings associated with the part still remain, however all references to that part are removed.\n\nShow\n\nsyntax: show <env:unit:(subunit):part>\n\nThis command allows the user to display information about a given environment. The user provides the detail level he wants displayed within the environment. If only an environment name is provided the command shows all units and parts within the environment. If environment name, subunit, and part name are given then only the part is displayed.\n\nView\n\nsyntax: view <bridge:stream:mapto>\n\nThis command is similar to the show command and allows a user to display information about a given bridge down to the detail level provided. If only a bridge name is provided the command shows all streams and mapto within the bridge. If bridge name, stream and mapto are provided then only the mapto is displayed.\n\nMsg\n\nsyntax: msg <text>\n\nThis command allows the user to send messages to every other user within the user's respective workplace. The name of the sending user is given followed by the message.\n\nSend\n\nsyntax: send <user><text>\n\nThis command allows the user to send message to any user on the engine. Only the user specified receives the message and the name of the sending user is displayed along with the message.\n\nWall\n\nsyntax: wall <text>\n\nThis command allows the system administrator to send a message to every user on the engine. This is extremely useful for making general announcements.\n\nUsers\n\nsyntax: users\n\nThis command allows the system administrator to display information about every user logged into the DCLE process. Information displayed includes socket number, user name, workplace, time connected, and site called from.\n\nLog\n\nsyntax: log <onâ¥off>\n\nThis command allows the users to toggle their log on or off. This simply tells the engine whether or not to display information to the user consisting of operations during an execution. The log is generally used for debugging purposes.\n\nMapto (MapTo)\n\nsyntax: mapto <from><where>\n\nThis command allows the user to create a link between parts for mapping purposes. After a mapto has been created the mapto command is attached to an existing stream within a bridge, and is given a virtual name. Any time after creation of the mapto command the user can refer to a mapto by streamname (i.e. <bridgename%streamname%maptoXX>).\n\nFor further information on the mapto command, please see the discussion on the mapto command structure above.\n\nExecute\n\nsyntax: execute <bridge:stream:mapto>\n\nThis command allows the user to initiate the data conversion process. The command executes the conversion down to the lowest detail level provided. In most cases, this is the entire bridge and all streams and maptos are executed. However, for purposes of debugging, the user may specify a given stream or mapto within a bridge to execute.\n\nRmmapto\n\nsyntax: rmmapto <bridge:stream:mapto>\n\nThis command allows the user to delete a mapto within an existing stream. For purposes of this command a mapto may be referred to by its virtual name.\n\nCreate\n\nsyntax: create bridge <bridgename><inenv><outenv>create stream <bridge:streamname><inunit><outunit>create stream <streamname><inenv:inunit><outenv:outunit>\n\nThis command allows the user to create a new bridge or create a stream within an existing bridge. When a new bridge is created, linking two environments, it is noted that a single input environment may have multiple outputs, but an output may have only one input. For easy reference the bridge name is often a combination of the source and destination environment names (i.e. environment `input` and environment `output` have bridge `inout`). The creation of a stream is similar except that it creates a link between tables and is attached to an existing bridge.\n\nMove\n\nsyntax: move <envnum:unitnum><envnum:unitnum>move <envnum:unitnum:partnum><envnum:unitnum:partnum>\n\nThis command allows the user to reshuffle the order of units, subunits, or parts within a given environment, or to go back and add a new unit, subunit or part to the list within an existing environment. Since pieces are read and written in the order they are created this command allows for easy manipulation\n\nQuit\n\nsyntax: quit\n\nThis command logs a user off the DCLE process and closes his/her connection to the server. None of the user's work is saved and the time of logout is logged.\n\nEXAMPLE MIGRATION PROJECT\n\nThe following illustrates a simple example data conversion problem and illustrates the general design and commands necessary to use the data conversion system and method of the present invention. The following example, it is assumed that the physical origination and destination of the information is irrelevant. A common data conversion involves converting data from a mainframe hierarchical database to one or more relational database systems. However, for the purpose of this example, the example assumes a flat file to flat file conversion and that the platforms on either end of the conversion have no bearing on the conversion itself.\n\n______________________________________ Input Side Output Side ______________________________________ 2 Tables, 3 Output Tables Customer-1 Out-Customer-1 Customer-2 Out-Customer-2A Out-Customer-2B ______________________________________\n\nThe Table Definitions are as follows:\n\n______________________________________ Input Tables Output Tables ______________________________________ name: Customer 1 name: Out Customer 1 fields: Name {Name Soc. Sec. Num. Soc. Sec. Num. Sex Sex Sales New - Sales name: Customer 2 name: Out Customer 2A fields: Name fields: Name Soc. Sec. Num. Soc. Sec. Num. Sex Sex Sales New.sub.-- Sales name: Out Customer 2B fields: Name Soc. Sec. Num. Sex ______________________________________\n\nIn order to make use of every possible table-to-table relationship (one-to-one, one-to-many, many-to-one, many-to-many) we shall create a third, intermediate environment through which the data will be transferred in order to reach our destination (output) environment.\n\nThe Intermediate Environment\n\n3 Tables\n\nFem-Customer-1\n\nMale-Customer-1\n\nCustomer-2-Temp\n\nThe Table definitions are as follows:\n\nIntermediates\n\nname: Fem-- Customer-- 1\n\nfields: Name Soc. Sec. Num. Sales\n\nname: Male-- Customer-- 1\n\nfields: Name Soc. Sec. Num. Sales\n\nname: Customer -- 2-- Temp\n\nfields: Name Soc. Sec. Num. Sex Sales\n\nThe relationships, input to intermediate to output, will be:\n\n______________________________________ In: Customer-1 (one to many) Fem-Customer-1 Male-Customer-1 Customer-2 (many-to many) Customer-2-Temp Inter: Fem-Customer- 1 (many-to-one) Out-Customer-1 Male-Customer-1 Customer-2-Temp (one-to-many) Out-Customer-2A Out-Customer-2B Out: Out-Customer-1 Out-Customer-2A Out-Customer-2B THE NECESSARY MAPPINGS WOULD BE AS FOLLOWS: Environment Bridge: Input to Intermediate 1 Stream: Customer.sub.-- 1 to Fem.sub.-- Customer.sub.-- 1 {Put all female mobs into the 1 Maps: Name -> Name SSNum -> SSNum Sales -> Sales Conds: (Sex == \"female\") 2 Stream: Customer.sub.-- 1 to Male-Customer.sub.-- 1 {Put all male customers into 1 Maps: Name -> Name SSNum -> SSNum Sales -> Sales Conds: (Sex == \"male\") 1 Stream: Customer.sub.-- 2 to Customer.sub.-- 2.sub.-- Temp {If a customer is female, set intermediate sales to double the original amount } 1 Maps: Name -> Name SSNum -> SSNum Sex -> Sex Sales*2 -> Sales Conds: (Sex == \"female\") 2Maps (ALL) -> (ALL) {If not female, Conds: (Sex| = \"Female\") map straight Environment Bridge: Intermediate to Output 1 Stream: Fem.sub.-- Cust.sub.-- 1 to Out.sub.-- Customer.sub.-- 1 {Put all female customers 1 Maps: Name -> Name SSNum -> SSNum Sales -> Sales \"Female\" -> Sex Conds: (Sex == \"female\") 2 Stream: Male.sub.-- Cust.sub.-- 1 to Out.sub.-- Customer.sub.-- {Put all male customers into 1 Maps: Name -> Name SSNum -> SSNum Sales -> Sales \"Male\" -> Sex Conds: (Sex == \"male\") 3 Stream: Customer.sub.-- 2.sub.-- Temp to Out.sub.-- Cust.sub.-- 2.sub.-- 2A {If customer sales are >= 100,000 then parse them out into a separate (2A) table} 1 Maps: Name -> Name SSNum -> SSNum Sex -> Sex Sales -> Sales Conds: (Sales >= 100,000) 4 Stream: Customer.sub.-- 2.sub.-- Temp to Out.sub.-- Cust.sub.-- {Master output table for in:customer.sub.-- 2, contains all records} 1Maps (ALL) -> (ALL) Conds: (None) THE NECESSARY COMMANDS FOR THESE MAPPINGS Commands for Mapping and Execution create bridge input intermediate create stream input.customer.sub.-- 1 intermediate.fem.sub.-- customer.sub .-- 1 MapTo (intermediate.fem.sub.-- customer.sub.-- 1.sub.-- :name, ssnum, sales) from (input.customer.sub.-- 1: name, ssnum, sales) where (sex = \"female\") create stream input.customer.sub.-- 1 intermediate.male.sub.-- customer.su b.-- 1 MapTo (intermediate.male.sub.-- customer.sub.-- 1.sub.-- :name, ssnum, sales) from (input.customer.sub.-- 1: name, ssnum, sales) where (sex = \"male\") create stream input.customer.sub.-- 2 intemediate.customer.sub.-- 2.sub.-- temp MapTo (intermediate.customer.sub.-- 2.sub.-- name, ssnum, sales) from (input.customer.sub.-- 2: name, ssnum, sales*2) where (sex = \"female\") MapTo (intermediate.customer.sub.-- 2.sub.-- temp:*) from (input.customer.sub.-- 2: *) where (sex| = \"female\") create bridge intermediate output create stream intermediate.fem.sub.-- customer.sub.-- 1 output.out.sub.-- customer.sub.-- 1 MapTo (output.out.sub.-- customer.sub.-- 1: name, ssnum, sales, sex) from (intermediate.fem.sub.-- customer.sub.-- 1: name, ssnum, sales, \"Female\") where create stream intermediate.male.sub.-- customer.sub.-- 1 output.out.sub.-- customer.sub.-- 1 MapTo (output.out.sub.-- customer.sub.-- 1: name, ssnum, sales, sex) from (intermediate.fem.sub.-- customer.sub.-- 1: name, ssnum, sales, \"Male\") where create stream intermediate.customer.sub.-- 2.sub.-- temp output.out.sub.-- customer.sub.-- 2a MapTo (output.out.sub.-- customer.sub.-- 2a: name, ssnum, sex, sales) from (intermediate.customer.sub.-- 2.sub.-- temp: name, ssnum, sex, sales) where sales >= 100,000) create stream intermediate.customer.sub.-- 2.sub.-- temp output.out.sub.-- customer.sub.-- 2b MapTo (output.out.sub.-- customer.sub.-- 2b: name, ssnum, sex, sales) from (output.out.sub.-- customer.sub.-- temp: name, ssnum, sex, sales) where execute input intermediate execute intermediate output ______________________________________ ##SPC1##\n\nConclusion\n\nTherefore, the present invention comprises a data conversion system and method which is used to convert data between different formats. The present invention may be used to convert data between any of various types of formats. The present invention uses a pre-defined generic data type object (Gdata), and other data types are converted to and from the Gdata object to simplify the migration process.\n\nAlthough the system and method of the present invention has been described in connection with the preferred embodiment, it is not intended to be limited to the specific form set forth herein, but on the contrary, it is intended to cover such alternatives, modifications, and equivalents, as can be reasonably included within the spirit and scope of the invention as defined by the appended claims."
    }
}