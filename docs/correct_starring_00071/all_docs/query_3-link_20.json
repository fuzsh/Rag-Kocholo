{
    "id": "correct_starring_00071_3",
    "rank": 20,
    "data": {
        "url": "https://neo4j.com/developer-blog/knowledge-graph-structured-semantic-search/",
        "read_more_link": "",
        "language": "en",
        "title": "The Future of Knowledge Graph: Will Structured and Semantic Search Become One?",
        "top_image": "https://dist.neo4j.com/wp-content/uploads/20240425095625/node-embedding-e1714064236703.jpeg",
        "meta_img": "https://dist.neo4j.com/wp-content/uploads/20240425095625/node-embedding-e1714064236703.jpeg",
        "images": [
            "https://dist.neo4j.com/wp-content/uploads/20230926084108/Logo_FullColor_RGB_TransBG.svg",
            "https://dist.neo4j.com/wp-content/uploads/20230926084108/Logo_FullColor_RGB_TransBG.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240402072516/Icon-GraphAcademy.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240401103728/Icon-Documentation.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240401103728/Icon-Documentation.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240402072516/Icon-GraphAcademy.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240402072514/Icon-Events.svg",
            "https://dist.neo4j.com/wp-content/uploads/20230926084108/Logo_FullColor_RGB_TransBG.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240327092936/gdb.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240327092934/auradb.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240329130329/genai.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240401103728/Icon-Documentation.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240401103728/Icon-Documentation.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240402072516/Icon-GraphAcademy.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240402072514/Icon-Events.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240708132519/Logo-GraphSummit-reverse.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240402072012/Logo-Connections.svg",
            "https://dist.neo4j.com/wp-content/uploads/20180103013951/Fanghua-Joshua-Yu-Neo4j.jpg",
            "https://cdn-images-1.medium.com/max/1024/1*EsHltP_w3iEY1IkgtuQrTQ.png",
            "https://cdn-images-1.medium.com/max/1024/0*S6pC66kqLMWpA3q-.png",
            "https://cdn-images-1.medium.com/max/1024/1*ZdRY6WYkD5piQbjWTrE40g.png",
            "https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=952d33951df3",
            "https://dist.neo4j.com/wp-content/uploads/20240321094132/Blog-Asset-AuraDB-Logo.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240321094136/Blog-Asset-AuraDB-Cloud.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240321094134/Blog-Asset-GraphAcademy-Trophy.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240514071251/node-24-logo.svg",
            "https://dist.neo4j.com/wp-content/uploads/20240514071252/nodes-patterns.svg",
            "https://dist.neo4j.com/wp-content/uploads/20180103013951/Fanghua-Joshua-Yu-Neo4j.jpg",
            "https://dist.neo4j.com/wp-content/uploads/20240718095939/1wqqqBzPj1HYMk-R_joBW4A-e1721322291903.png",
            "https://dist.neo4j.com/wp-content/uploads/20240717084326/unstructured-io-knowledge-graph-e1721231081572.jpg",
            "https://dist.neo4j.com/wp-content/uploads/20240715065226/chemical-reaction-graph-e1721051577357.jpg",
            "https://dist.neo4j.com/wp-content/uploads/20230921083327/homepage-viz_ART-left.svg",
            "https://dist.neo4j.com/wp-content/uploads/20230921083329/homepage-viz_ART-right.svg",
            "https://dist.neo4j.com/wp-content/uploads/20230921082858/homepage-viz_left-side-art_375.svg",
            "https://dist.neo4j.com/wp-content/uploads/20230921082910/homepage-viz_right-side-art_375.svg",
            "https://dist.neo4j.com/wp-content/uploads/20210608133508/icon-tooltip-info.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-04-25T13:08:00+00:00",
        "summary": "",
        "meta_description": "With the rise of LLMs, we can now store both structure and semantic meaning as vector embeddings in knowledge graphs.",
        "meta_lang": "en",
        "meta_favicon": "/apple-touch-icon.png?v=bOXynyJWa61",
        "meta_site_name": "Graph Database & Analytics",
        "canonical_link": "https://neo4j.com/developer-blog/knowledge-graph-structured-semantic-search/",
        "text": "What LLM & Graph May Bring to the Future of Knowledge Graphs\n\nAbstract\n\nIn the last several decades, when people consider building a knowledge-related solution, they tend to look into two distinct directions based on whether data is structured or unstructured. Accordingly, there is the so-called structured search using a query language over a database or semantic search using inferencing and reasoning over the meaning of data, mostly text.\n\nThere are also methods to bring certain structures into unstructured data via technologies like entity extraction, entity linking, relation extraction, and so on in order to achieve better accuracy and performance. With the rise of Large Language Models (LLM), there is a new and promising way to bring the two into ONE, i.e., to store both structure and meaning (in the form of vectors created by the text embedding process) in a knowledge graph (KG). We will further explore this idea with an example.\n\nA Brief History of Knowledge Graph\n\nKnowledge graphs have roots in diverse fields, including artificial intelligence, semantic web, and graph theory, and have been built to support various applications over decades. Let’s briefly review KG’s history in the last 60 or so years(already!).\n\n1. 1960s and 1970s — Semantic Networks\n\nEarly AI researchers introduced semantic networks as a way to represent knowledge. These graphical structures represented objects (nodes) and relations (edges) between them.\n\n2. 1980s — Frames and Expert Systems\n\nMarvin Minsky introduced the concept of frames, which are data structures for representing stereotypical situations.\n\nExpert systems, computer systems that emulate the decision-making ability of a human expert, became popular. These systems relied heavily on knowledge bases.\n\n3. 1990s — Ontologies and RDF:\n\nThe term “ontology” started to be widely used in the context of knowledge representation. It referred to a set of concepts and categories in a subject area, and their relationships.\n\nThe Resource Description Framework (RDF) was introduced by the World Wide Web Consortium (W3C) as a standard for describing resources on the web.\n\n4. 2000s — SPARQL and DBpedia:\n\nSPARQL, a query language for Resource Description Framework (RDF), was introduced, allowing for more complex querying of web data.\n\nThe launch of DBpedia, which aimed to extract structured information from Wikipedia and to make this information available on the web, was a crucial milestone.\n\n5. 2010s — Rise of Commercial Knowledge Graphs\n\n– Google’s Knowledge Graph: In 2012, Google announced its Knowledge Graph, a structured knowledge base to enhance search results with information gathered from various sources. It changed how information is presented in search, offering direct answers and rich snippets.\n\n— Facebook’s Open Graph: Around the same period, Facebook introduced the Open Graph Protocol, which allowed third-party websites to integrate more seamlessly with the platform.\n\n— Wikidata: Launched by the Wikimedia Foundation in 2012, it acts as a central storage for the structured data of its Wikimedia sister projects, including Wikipedia and Wikimedia Commons.\n\n— Neo4j: This graph database, though not a knowledge graph per se, has been instrumental in the growth of knowledge graph technology. It provides tools and infrastructure for creating, querying, and maintaining graph data structures under a schema called Labelled Property Graph.\n\nRDF Triple Stores vs. Labeled Property Graphs: What’s the Difference? – Graph Database & Analytics\n\n6. 2020s and Beyond: The Era of Neural Knowledge Graph?\n\nA neural knowledge graph combines the structured representation of knowledge graphs with the learning capabilities of neural networks, especially deep learning. The rise of neural knowledge graphs is part of a broader trend in AI research that aims to marry symbolic, rule-based AI (which is interpretable and can be reasoned about explicitly) with subsymbolic, statistical AI (which is adept at handling noisy, real-world data). Early studies have shown promising outcomes from such an approach, and its future is yet to be seen.\n\nStructured or Semantic Search?\n\nStructured Search typically requires certain schema to be defined; e.g., column, row, and fields in a relational database, or node, relationship, and property in a graph database. The biggest benefit of having a predefined schema, which means you need to know what fields or columns are available and their data types, is the precision and powerful features of manipulating data through a query language like SQL for RDBMS and Cypher for graph database.\n\nMeanwhile, Semantic Search aims to understand the intent and contextual meaning of search phrases to produce highly relevant results. Instead of focusing solely on matching keywords, it seeks to understand the context in which keywords are used. For instance, the word “apple” could refer to the fruit or the tech company, and a semantic search system would attempt to discern which meaning was intended based on additional context.\n\nSemantic Search often uses NLP techniques to understand context, synonyms, user intent, and more. Many semantic search systems use knowledge graphs to understand the relationships between different entities and concepts.\n\nBecause of the nature of the stored information and the capabilities offered, structured search excels in environments where data is well-organized, and the user knows precisely what they are querying for. Semantic search shines in more complex, natural language environments where user intent and context play a significant role in retrieving the right information.\n\nBring Structured & Semantic Search into One\n\nThe most amazing thing about text embedding generated by an LLM is it can encode any text (unstructured) into a fixed-size list of floats (vector), which can then be matched by using one of the Similarity algorithms.\n\nThe post below has a more complete explanation of text embedding.\n\nText Embedding — What, Why and How?\n\nLLMs also show surprisingly strong reasoning, summarizing, and completion capability over text. Because people often don’t differentiate between structured and unstructured data when posing questions, an integrated approach that combines LLM with KG can understand natural language queries and fetch information regardless of its underlying structure, leading to a smoother and more intuitive search experience.\n\nMore importantly, integrating structured and semantic search allows for a more robust feedback mechanism. The system can learn from explicit feedback (e.g., users rating the relevance of results) and implicit feedback (e.g., tracking which results users click on most often) to refine its algorithms over time.\n\nAn Experiment Using The Movies Graph\n\nThe Movie Graph\n\nIn the following sections, I will showcase how to implement natural language Q&A on the famous Movie Graph, using ChatGPT API and Neo4j Graph Database in just a few easy steps!\n\nFor steps of creating the Movie Graph on Neo4j AuraDB, save text embeddings generated by OpenAI API. Please check my previous post:\n\nEnhance Semantic Search of Text Embeddings through Collaborative Filtering over A Knowledge Graph\n\nThe Design\n\nThere are already many posts on generating a Cypher query from a question in natural language using GPT-3 and other similar LLMs. In this pattern, the query is generated by LLM based on examples provided, which is then executed by the underlying database to return results.\n\nHowever, there are common challenges in this pattern:\n\nLLM can’t always generate correct labels, relationships, or property names, even if the schema is given as part of the prompt.\n\nLLM can’t generate complex queries if there is no sample given.\n\nDue to the prompt size limit, it’s not possible to provide enough samples, so LLM may not be able to learn all available syntax of the query language.\n\nLLM can mess up with relationship directions.\n\nAdding Q&A Features to Your Knowledge Graph in 3 Simple Steps\n\nEnglish to Cypher with GPT-3 in Doctor.ai\n\nLangChain Cypher Search: Tips & Tricks\n\nInstead of expecting LLM to generate structured queries based on unstructured questions, I will demonstrate a different approach which follows these three steps:\n\nCreate text embeddings for nodes, relationships, and node-relationship-node patterns, which are then saved in KG. (=> 4.3)\n\nCreate a vector index. (=>4.4)\n\nFor a question, generate the text embedding of it, do a similarity search in KG to retrieve as many contents as possible, and let LLM generate answers from it. (=>4.5)\n\nEmbeddings Are All You Need\n\nNode Embedding\n\nThe Movie Graph has a quite simple schema:\n\nThe node embedding is basically a text embedding of:\n\nnode label\n\nnode property\n\nnode property value\n\nFor example, for Person node Tom Hanks, node embedding is the text embedding generated by OpenAI Embedding API of the following content:\n\nPerson name \"Tom Hanks\" born 1956\n\nand Movie node Apollo 13 is generated from:\n\nMovie title \"Apollo 13\" tagline \"Houston, we have a problem.\"\n\nEmbedding of Node-Relationship-Node\n\nThis is similar to embedding triples. For an example:\n\nThe embedding is generated for:\n\n\"Tom Hanks\" ACTED_IN \"Apollo 13\"\n\nSave & Index Text Embeddings in Neo4j\n\nEmbedding is represented as a vector, which is an array of float values. In Neo4j, vectors are saved as property value, and indexed through Vector Index. The link below gives more details.\n\n​​Neo4j’s Vector Search: Unlocking Deeper Insights for AI-Powered Applications – Graph Database & Analytics\n\nFor a given question, a call to OpenAI Embedding API is made to get its embedding, which is then used to retrieve similar contents in Neo4j through the vector index. The similarity is calculated using COSINE Similarity.\n\nCALL db.index.vector.queryNodes('embeddingIndex', topK, $questionEmbedding)\n\nYIELD node, score\n\nRETURN node.text AS context, score;\n\nDifferent from other posts, the Cypher above is the ONLY query to run, which has one parameter, i.e., the embedding of the question. There is no need to generate Cypher for a given question.\n\nGenerate Answers\n\nWhen sufficient contents are retrieved from KG for the given question, another OpenAI Completion API call is made to let LLM generate an answer from the context.\n\nThe Instruction below is used for the prompt (or System Message if using Chat API from GPT-3.5/4 model):\n\nYou are an intelligent chatbot. Please answer the questions only based on the context provided below as truly as possible. If you can’t find the answer from the context, simply say, “Sorry, I don’t have enough context for your question.”.\n\nTest Results of Sample Questions\n\nThis section lists some Q&A results over the Movie Graph.\n\n1. Single entity: What-is\n\nQuestion: Who is Kevin Bacon?\n\nContext: (only the first 5 lines are given. Same for all following samples)\n\nPerson name “Kevin Bacon” born 1958\n\n“Kevin Bacon” ACTED_IN “Apollo 13”\n\n“Kevin Bacon” ACTED_IN “A Few Good Men”\n\n“Kevin Bacon” ACTED_IN “Frost/Nixon”\n\nPerson name “Kevin Pollak” born 1957\n\n… … … …\n\nAnswer: Kevin Bacon is an actor born in 1958.\n\n2. Single entity: Fact-based logical reasoning\n\nQuestion: is Top Gun a movie?\n\nContext:\n\n“Tony Scott” DIRECTED “Top Gun”\n\n“Tom Skerritt” ACTED_IN “Top Gun”\n\nMovie title “Top Gun” tagline “I feel the need, the need for speed.”\n\n“Meg Ryan” ACTED_IN “Top Gun”\n\n“Tom Cruise” ACTED_IN “Top Gun”\n\n… … … …\n\nAnswer: Yes, “Top Gun” is a movie.\n\n3. Single entity: Fact-based logical reasoning, negative\n\nQuestion: is Tom Hanks a movie?\n\nContext:\n\n“Tom Hanks” ACTED_IN “Sleepless in Seattle”\n\n“Tom Hanks” DIRECTED “That Thing You Do”\n\n“Tom Hanks” ACTED_IN “You’ve Got Mail”\n\n“Tom Hanks” ACTED_IN “That Thing You Do”\n\n“Tom Hanks” ACTED_IN “Cast Away”\n\n… … … …\n\nAnswer:\n\nNo, Tom Hanks is not a movie. Tom Hanks is an actor who has appeared in many movies.\n\n4. Simple aggregation\n\nQuestion: how many movies Kevin Bacon acted in?\n\nContext: (note the order of results are slightly different from #1)\n\n“Kevin Bacon” ACTED_IN “A Few Good Men”\n\n“Kevin Bacon” ACTED_IN “Apollo 13”\n\n“Kevin Bacon” ACTED_IN “Frost/Nixon”\n\nPerson name “Kevin Bacon” born 1958\n\n“Kevin Pollak” ACTED_IN “A Few Good Men”\n\n… … … …\n\nAnswer: Kevin Bacon acted in 3 movies. (Correct as per Cypher query result.)\n\n5. Single entity + relation\n\nQuestion: what movies did Tom Hanks act in?\n\nContext:\n\n“Tom Hanks” ACTED_IN “Sleepless in Seattle”\n\n“Tom Hanks” ACTED_IN “A League of Their Own”\n\n“Tom Hanks” ACTED_IN “That Thing You Do”\n\n“Tom Hanks” ACTED_IN “You’ve Got Mail”\n\n“Tom Hanks” ACTED_IN “Cast Away”\n\n… … … …\n\nAnswer: Tom Hanks acted in the following movies:- Sleepless in Seattle- A League of Their Own- That Thing You Do- You’ve Got Mail- Cast Away- Charlie Wilson’s War- The Green Mile- Apollo 13- Joe Versus the Volcano- The Da Vinci Code- The Polar Express- Cloud Atlas\n\n6. Two entities, logical reasoning\n\nQuestion: Is Tom Cruise older than Tom Hanks?\n\nContext:\n\nPerson name “Tom Hanks” born 1956\n\nPerson name “Tom Cruise” born 1962\n\n“Tom Hanks” ACTED_IN “Apollo 13”\n\n“Tom Hanks” ACTED_IN “Cast Away”\n\n“Tom Hanks” ACTED_IN “Joe Versus the Volcano”\n\n… … … …\n\nAnswer: No, Tom Hanks is older than Tom Cruise.\n\n7. Entity-relation, out-of-scope\n\nQuestion: Did Tom Cruise act in Mission Impossible 7?\n\nContext:\n\n“Tom Cruise” ACTED_IN “Top Gun”\n\n“Tom Cruise” ACTED_IN “A Few Good Men”\n\n“Tom Cruise” ACTED_IN “Jerry Maguire”\n\n“Tom Skerritt” ACTED_IN “Top Gun”\n\n“Tom Hanks” ACTED_IN “Apollo 13”\n\n… … … …\n\nAnswer: Sorry, I don’t have enough context for your question.\n\n8. Two-entity-relationship, 1-hop\n\nQuestion: Did Tom Hanks and Hogo Weaving act in same movie ever?\n\nContext:\n\n“Tom Hanks” ACTED_IN “A League of Their Own”\n\n“Tom Hanks” ACTED_IN “That Thing You Do”\n\n“Tom Hanks” ACTED_IN “Sleepless in Seattle”\n\n“Tom Hanks” ACTED_IN “Cast Away”\n\n“Tom Hanks” ACTED_IN “Charlie Wilson’s War”\n\n… … … …\n\nAnswer: Yes, Tom Hanks and Hugo Weaving acted in the movie “Cloud Atlas” together.\n\n9. Single-entity, multiple-relationship, summarization\n\nQuestion: tell me something about Top Gun?\n\nContext:\n\n“Tony Scott” DIRECTED “Top Gun”\n\n“Tom Skerritt” ACTED_IN “Top Gun”\n\n“Val Kilmer” ACTED_IN “Top Gun”\n\nMovie title “Top Gun” tagline “I feel the need, the need for speed.”\n\n“Kelly McGillis” ACTED_IN “Top Gun”\n\n… … … …\n\nAnswer: “Top Gun” is a movie directed by Tony Scott. It stars Tom Cruise, Tom Skerritt, Val Kilmer, Kelly McGillis, Meg Ryan, and Anthony Edwards. The tagline of the movie is “I feel the need, the need for speed.”\n\n10. Multiple-entity, multiple-relationship, summarization\n\nQuestion: Recommend some movies similar to The Matrix ordered by actors or directors\n\nContext:\n\n“Lilly Wachowski” DIRECTED “The Matrix”\n\n“Lilly Wachowski” DIRECTED “The Matrix Reloaded”\n\n“Lana Wachowski” DIRECTED “The Matrix”\n\n“Lilly Wachowski” DIRECTED “The Matrix Revolutions”\n\n“Lana Wachowski” DIRECTED “The Matrix Revolutions”\n\n… … … …\n\nAnswer: First 3 parts are listed here\n\n1. Movies directed by Lana Wachowski:\n\n— Cloud Atlas\n\n— Speed Racer\n\n2. Movies directed by Lilly Wachowski:\n\n— The Matrix Reloaded\n\n— The Matrix Revolutions\n\n3. Movies directed by Robert Zemeckis:\n\n— Cast Away\n\n— The Polar Express\n\n… … … …\n\n11. Multiple-entity, multiple-hop, collaborative filtering, summarization\n\nQuestion: The co-actors of Tom Hanks, what other movies they acted in? list actor name and movie title\n\nContext:\n\n“Tom Hanks” ACTED_IN “A League of Their Own”\n\n“Tom Hanks” ACTED_IN “Sleepless in Seattle”\n\n“Tom Hanks” ACTED_IN “That Thing You Do”\n\n“Tom Hanks” ACTED_IN “You’ve Got Mail”\n\n“Tom Hanks” ACTED_IN “Joe Versus the Volcano”\n\n… … … …\n\nAnswer:\n\nBill Pullman — Sleepless in Seattle\n\nBill Paxton — A League of Their Own, Apollo 13, Twister\n\nSteve Zahn — You’ve Got Mail\n\nMeg Ryan — Sleepless in Seattle, You’ve Got Mail, When Harry Met Sally, Joe Versus the Volcano, Top Gun\n\n… … … …\n\nFurther Discussions\n\nWe can continue with more Q&As, but the accuracy and relevance of the results shown so far were truly impressive to me. Some further development on it will focus on the following areas:\n\nMore efficient and relevant context generation.\n\nThe intelligence of deciding whether a question should be answered by text-based context or structured query execution.\n\nLeveraging metadata or domain knowledge (e.g., ontology) of the dataset to improve the efficiency.\n\nA fine-tuned model with domain-specific data.\n\nWhen both structured knowledge and its semantics are stored in the Neo4j graph database, it is very achievable to combine semantic match with structured traversal over the graph to provide further processing of the results, which makes this approach huge potential to be further explored.\n\nTo conclude, I’d like to quote some words from this amazing paper by Luna Dong:\n\nThe future (of KG): With the above analysis, we envision a KG that encodes knowledge both in the form of knowledge triples and in the form of LLM embeddings, where the former are easier to use for human understanding and explainability, whereas the latter is easier for machine comprehension.\n\nLook forward to what’s next!"
    }
}