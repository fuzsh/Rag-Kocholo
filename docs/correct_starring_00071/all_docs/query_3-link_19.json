{
    "id": "correct_starring_00071_3",
    "rank": 19,
    "data": {
        "url": "https://www.linkedin.com/pulse/knowledge-graphs-rag-part-10-my-graph-series-blogs-ajay-taneja-hkeyf",
        "read_more_link": "",
        "language": "en",
        "title": "Knowledge Graphs for RAG: Part 10 of my Graph series of blogs",
        "top_image": "https://media.licdn.com/dms/image/D4D12AQG_JjjdlcnVfA/article-cover_image-shrink_720_1280/0/1721204795203?e=2147483647&v=beta&t=lOqGB3jjJUBDIx3xR6tE04Eid0M9Nw7d7txaGc5g5uI",
        "meta_img": "https://media.licdn.com/dms/image/D4D12AQG_JjjdlcnVfA/article-cover_image-shrink_720_1280/0/1721204795203?e=2147483647&v=beta&t=lOqGB3jjJUBDIx3xR6tE04Eid0M9Nw7d7txaGc5g5uI",
        "images": [
            "https://media.licdn.com/dms/image/D4D12AQG_JjjdlcnVfA/article-cover_image-shrink_720_1280/0/1721204795203?e=2147483647&v=beta&t=lOqGB3jjJUBDIx3xR6tE04Eid0M9Nw7d7txaGc5g5uI",
            "https://media.licdn.com/dms/image/D4D12AQG647jROtdLxw/article-inline_image-shrink_400_744/0/1721209340191?e=1726704000&v=beta&t=gyTLgTR5u2uXBr9Uk0BJvGo7S0-7O8eNpOMFfYOppJ8",
            "https://media.licdn.com/dms/image/D4D12AQH5IChWXfaLSA/article-inline_image-shrink_1000_1488/0/1721181514082?e=1726704000&v=beta&t=yHUWh2ZlDniuHD1aBUb6PeqvUEsJkl2-gMKvL9dVGac",
            "https://media.licdn.com/dms/image/D4D12AQF5wnSjfsZ5jA/article-inline_image-shrink_1000_1488/0/1721180249858?e=1726704000&v=beta&t=GVxOduSgejziAcdzW2Hz4o7jvuMn_FXzzEuUSF-RdpM",
            "https://media.licdn.com/dms/image/D4D12AQGIz8q5iSKYbg/article-inline_image-shrink_1000_1488/0/1721183187641?e=1726704000&v=beta&t=YU9hUbyhOTQp-u0bxDUA3lMfWHMjsaycO9ACQKH3iNI",
            "https://media.licdn.com/dms/image/D4D12AQF_z7e9q1RLtQ/article-inline_image-shrink_400_744/0/1721207683827?e=1726704000&v=beta&t=KVA5WRPkW_ilpvyVGkm3Rkv2Of2Ivi0-xO8BkL5PpaU",
            "https://media.licdn.com/dms/image/D4D12AQF9UoP8W5JVNA/article-inline_image-shrink_400_744/0/1721203734765?e=1726704000&v=beta&t=nGg2en-K18BySr1I6n_4FC9UT4Iyo39WEJIzJLMnX9M",
            "https://media.licdn.com/dms/image/D4D12AQH4dvY97DiI2A/article-inline_image-shrink_1000_1488/0/1721203929485?e=1726704000&v=beta&t=5m5G9ZwuZOUZdZXNpm2gXNKg--BlKrR_HMdmC37oItI",
            "https://media.licdn.com/dms/image/D4D12AQFadzFCvBCQDA/article-inline_image-shrink_400_744/0/1721202593831?e=1726704000&v=beta&t=-PDqnFlfIKTL6ZXIELBcJ4weEkRx3t8wRarwI_EzzMw",
            "https://media.licdn.com/dms/image/D4D12AQHkNjuO4zz-8Q/article-inline_image-shrink_400_744/0/1721205158535?e=1726704000&v=beta&t=BwR2COpuyMAe4cjdOIPu2utIS0XF-2fASOtoaOjM2lo",
            "https://media.licdn.com/dms/image/D4D12AQHrgGStkELy9w/article-inline_image-shrink_400_744/0/1721209351135?e=1726704000&v=beta&t=OlaCukAzsCu2I8OAxqSWFWVvpr6Xcmzkt_Xhlkb98gc",
            "https://media.licdn.com/dms/image/D4D12AQFFY0JdoxFjwQ/article-inline_image-shrink_1000_1488/0/1721209503895?e=1726704000&v=beta&t=TQjehjqb_0rL085m-IZ2f_XRpQYib6U0bbRPh1JjEBI",
            "https://media.licdn.com/dms/image/D4D12AQHUORJS7Q_Yiw/article-inline_image-shrink_400_744/0/1721203375014?e=1726704000&v=beta&t=1uropEBlDlxNhZosv_lZsJPzH_ezt-Mxk0zmRJ1Iiew",
            "https://media.licdn.com/dms/image/D4D12AQEe-TUpIX01Fw/article-inline_image-shrink_1000_1488/0/1721209532342?e=1726704000&v=beta&t=-vxzBrZJOo6MoDwHMWZRHB4RpXKqOxjiUXNkXUAqen4",
            "https://media.licdn.com/dms/image/D4D12AQEBwz1AVCqauw/article-inline_image-shrink_400_744/0/1721203131603?e=1726704000&v=beta&t=btqYnfsopDK0J2x0kAYrcu2XktB27HlqlxCOtblYnUI",
            "https://media.licdn.com/dms/image/D4D12AQG4XPIs7LSLBQ/article-inline_image-shrink_1000_1488/0/1721201713662?e=1726704000&v=beta&t=jy3jkuhqqxEGIFgnxPba3gGz_5q-8-W_nZ3Bn_m_IEM",
            "https://media.licdn.com/dms/image/D4D12AQF4o-7VE8FpLA/article-inline_image-shrink_1000_1488/0/1721199638454?e=1726704000&v=beta&t=WjZZQksaFLLvHeB6Irl0Th_MEIXm-_ziP4auAPwYK24",
            "https://media.licdn.com/dms/image/D4D12AQEOcpkTkFzHWA/article-inline_image-shrink_400_744/0/1721187853295?e=1726704000&v=beta&t=EAYXW33WlACcrmTIBixfFOF_Z2XzGANbszZMPAK6Trk",
            "https://media.licdn.com/dms/image/D4D12AQGCjljjCVFYMQ/article-inline_image-shrink_400_744/0/1721180655305?e=1726704000&v=beta&t=qOQncxn1MtT9AqHV-AYSp-hyMKKaQSERTKe-gDFXPOk",
            "https://media.licdn.com/dms/image/D4D12AQGemS2ogXfbvQ/article-inline_image-shrink_1000_1488/0/1721180743473?e=1726704000&v=beta&t=bfoerKvyANRDfeN7QTmYe1qYtGdw_56cdTZW6t82fLo",
            "https://media.licdn.com/dms/image/D4D12AQGc6-ma91EpYg/article-inline_image-shrink_1000_1488/0/1721182985124?e=1726704000&v=beta&t=Y9YCQf7_m1x0qTZNzjPB-c4uHxyMNeaD8iwjhdwOCgM",
            "https://media.licdn.com/dms/image/D4D12AQGy7Azyc4g2Bw/article-inline_image-shrink_400_744/0/1721183240167?e=1726704000&v=beta&t=D0iOAfm99-zH2xzb3HOs3CO45R6eapWiaw_d3PWyMTw",
            "https://media.licdn.com/dms/image/D4D12AQHJrmDY9_cizA/article-inline_image-shrink_400_744/0/1721183053319?e=1726704000&v=beta&t=i1nAH-o8C7Wuf0Xb4zLqRx_LBTFbUwkZxEbSQcM04fM",
            "https://media.licdn.com/dms/image/D4D12AQHjFcUn3oFypg/article-inline_image-shrink_1000_1488/0/1721180569837?e=1726704000&v=beta&t=5xBVBJ824TaoVqpTc7FDacIVm1Aio7QsyS1B85dVn64",
            "https://media.licdn.com/dms/image/D4D12AQEVI7xZP1gAQA/article-inline_image-shrink_400_744/0/1721180080551?e=1726704000&v=beta&t=b0l4e0OolPyUhKExfTlZWdnVTG61Z--agknWaKz5AL4",
            "https://media.licdn.com/dms/image/D4D12AQGNc1hcYDk2Qg/article-inline_image-shrink_400_744/0/1721187316623?e=1726704000&v=beta&t=4HKa1U9nQuQXtVxkX2wsjWzIY7iO78r0tZ5xGt23rvQ",
            "https://media.licdn.com/dms/image/D4D12AQFexGKsVl_5jw/article-inline_image-shrink_1000_1488/0/1721181931875?e=1726704000&v=beta&t=zR6b7LZl7pZF0E1TbH9DQCrZw6RpSt3wgsNRxFjSx-I",
            "https://media.licdn.com/dms/image/D4D12AQH0fELmmaAYGA/article-inline_image-shrink_1000_1488/0/1721180966949?e=1726704000&v=beta&t=JEBZx2dUMl33posE7KrMMUNm9rCEzI9DEYNP-YjA-J4",
            "https://media.licdn.com/dms/image/D4D12AQHOMpNS4yvpZw/article-inline_image-shrink_400_744/0/1721181971497?e=1726704000&v=beta&t=8qh1__gb8OU_Dn4CYzUB4LWQ56d6sC7bYb-_MCgohMs",
            "https://media.licdn.com/dms/image/D4D12AQHVeONGTsJD1Q/article-inline_image-shrink_1000_1488/0/1721181334384?e=1726704000&v=beta&t=f6SDb2elAPu88hIXIyz4vJ4v2iWCJxKI8XewvSH1QTI",
            "https://media.licdn.com/dms/image/D4D12AQFa99HV6h5mHA/article-inline_image-shrink_1000_1488/0/1721180783591?e=1726704000&v=beta&t=USHe_KtVGjbEFhG0ZAc1YjIVvjwlMYOHajJfIb3MBDc",
            "https://media.licdn.com/dms/image/D4D12AQFjEOfHmCswuA/article-inline_image-shrink_1000_1488/0/1721181815295?e=1726704000&v=beta&t=KxEzAHmg9qfLV6dhYUDvdvZ8mhvtdGeg6V4KRix6VdI",
            "https://media.licdn.com/dms/image/D4D12AQHV12vXNgkMDQ/article-inline_image-shrink_1000_1488/0/1721188791697?e=1726704000&v=beta&t=Ywe80ZwPhJtp2uY0mmzIZV9dYO1Vy_E3w3AJE2gwdzw",
            "https://media.licdn.com/dms/image/D4D12AQHQxECHD5pC4Q/article-inline_image-shrink_1000_1488/0/1721182015094?e=1726704000&v=beta&t=2f4mGbKS_7fB5eBblu62kKVQ7yrdrmc5S1zNQxECUrU",
            "https://media.licdn.com/dms/image/D4D12AQEN5MsABPb7Cg/article-inline_image-shrink_1000_1488/0/1721180867934?e=1726704000&v=beta&t=qSKNeo2RFefe95wc0-Fk0JiWA55kxvB02farhRtBO5g",
            "https://media.licdn.com/dms/image/D4D12AQGjO1fqX_QS0A/article-inline_image-shrink_1000_1488/0/1721181518378?e=1726704000&v=beta&t=u8vtTO21neUGXrSjSlifgAGNSDtENFWnuwDZQLUgpkE",
            "https://media.licdn.com/dms/image/D4D12AQHCo4VPZXXbJA/article-inline_image-shrink_1000_1488/0/1721180860871?e=1726704000&v=beta&t=Vgx6xHi3JIpFMyQpp-nwE3p1tECZmpV08e9iaSRzDik",
            "https://media.licdn.com/dms/image/D4D12AQEE41AkOOkcKg/article-inline_image-shrink_1000_1488/0/1721179125453?e=1726704000&v=beta&t=WHpK_fM8jHY34Pcs_czx1QMGcVodxPsVO6Whe3G9XGA",
            "https://media.licdn.com/dms/image/D4D12AQGzhIrd_If7cw/article-inline_image-shrink_1000_1488/0/1721180808017?e=1726704000&v=beta&t=rBZ6u5_tZHYTF3I6FTxxcVQe5TErPeXV-N0LHtJax_8",
            "https://media.licdn.com/dms/image/D4D12AQGOFPwyBZCliQ/article-inline_image-shrink_1000_1488/0/1721181312708?e=1726704000&v=beta&t=liJQAt6kCbRs0FDBROgqStvTOyBVD3qrCFPSDiTReQU",
            "https://media.licdn.com/dms/image/D4D12AQH0i3gQ4SFLCg/article-inline_image-shrink_1000_1488/0/1721180499798?e=1726704000&v=beta&t=0fXmnVO8zSmiZtw-VRJiHsqg1vssmhNMoawC9fWNw1Q",
            "https://media.licdn.com/dms/image/D4D12AQF3HGNWOcYs_g/article-inline_image-shrink_1000_1488/0/1721182782562?e=1726704000&v=beta&t=dzghc17M4hQ3KOBmS9CEbDbKQOGN9OltJ1OhZQHZDLs",
            "https://media.licdn.com/dms/image/D4D12AQGm1g5z8WVdhA/article-inline_image-shrink_1000_1488/0/1721182796109?e=1726704000&v=beta&t=HhPr_KXKlNPPVBDWINAoVVpiCW0ZD9boHElE7-CQbrs",
            "https://media.licdn.com/dms/image/D4D12AQFwL4ufoQo-gQ/article-inline_image-shrink_1000_1488/0/1721180081183?e=1726704000&v=beta&t=6u3aoZGrxUbSingQhDsgFSJ1-neHDN09rBDujgoQFn4",
            "https://media.licdn.com/dms/image/D4D12AQFe0RLJFfI7yg/article-inline_image-shrink_400_744/0/1721182690610?e=1726704000&v=beta&t=1CGcePPIPkcDzOovzWKVOVPwbxsIt9qQJVVjpTZu2uc",
            "https://media.licdn.com/dms/image/D4D12AQHWvXuyh5oGgA/article-inline_image-shrink_1000_1488/0/1721183807370?e=1726704000&v=beta&t=5fcMy96j_CD58SrRHWdceDLt8u47j3leYY9gWdUKAMA",
            "https://media.licdn.com/dms/image/D4D12AQFhqM-gwssaLg/article-inline_image-shrink_1000_1488/0/1721182020174?e=1726704000&v=beta&t=jUFZ5syfV2lbWqDXRWdNWEuIDEwN1h9t64NiamD6foo",
            "https://media.licdn.com/dms/image/D4D12AQGRx2MRQGTHpQ/article-inline_image-shrink_400_744/0/1721182232297?e=1726704000&v=beta&t=OnGUDw2estWhH2CyzXKwRNzDvzCL3CNhM0RwlJ8tSgY",
            "https://media.licdn.com/dms/image/D4D12AQEZ5_frEMdh9Q/article-inline_image-shrink_1000_1488/0/1721180775751?e=1726704000&v=beta&t=lps6vz1tct_10hSytvjOCQDoHV3GIUtJlb8f8yYqpQw",
            "https://media.licdn.com/dms/image/D4D12AQHXjQ7-V_WG2g/article-inline_image-shrink_1000_1488/0/1721183358034?e=1726704000&v=beta&t=gvxmHX2zxwH9Q5n6_XN0DItxeplt4aQ5hSnR3kTGh1Q",
            "https://media.licdn.com/dms/image/D4D12AQFVm43G9nyo9w/article-inline_image-shrink_1000_1488/0/1721183001279?e=1726704000&v=beta&t=mZ27p9jL6iC0-hvC2PQ_txJ2ZoxLHU0x1YnWoaJukvI",
            "https://media.licdn.com/dms/image/D4D12AQFpM-XpXQJvSQ/article-inline_image-shrink_1000_1488/0/1721180031193?e=1726704000&v=beta&t=kM_AUyRaWWj7BTVNhlso2u8QKR4UEvtapfPVVGYot1E",
            "https://media.licdn.com/dms/image/D4D12AQGmEHyddbtreg/article-inline_image-shrink_400_744/0/1721186970114?e=1726704000&v=beta&t=w80dUwspDq8GuzFt1xJwckBQA9z-is0jIat909bLhec",
            "https://media.licdn.com/dms/image/D4D12AQF0FJZC5DHW7g/article-inline_image-shrink_1000_1488/0/1721187275729?e=1726704000&v=beta&t=acjaX0keP4NUiwDjEwo09uF0HU9XPdED6BTRiBzEM_Q",
            "https://media.licdn.com/dms/image/D4D12AQGEtjztTevLyQ/article-inline_image-shrink_400_744/0/1721187203035?e=1726704000&v=beta&t=1ldEn9CMnnZPTbx6AFyNHDYccAlURPS-pnzCKeRAMto",
            "https://media.licdn.com/dms/image/D4D12AQEZYdoZqHpqkA/article-inline_image-shrink_1000_1488/0/1721180862382?e=1726704000&v=beta&t=wAob1Ufyf1sAw_ayCTukEo-QV1NOIYCCqoY_Sc6I6lw",
            "https://media.licdn.com/dms/image/D4D12AQE5KBvpiua7uQ/article-inline_image-shrink_400_744/0/1721185742374?e=1726704000&v=beta&t=EchSi-s1HTogCDNjCtOuLMNss-jbdoD8KcSQ1eAiGEE",
            "https://media.licdn.com/dms/image/D4D12AQEi3cR3fl9gzQ/article-inline_image-shrink_400_744/0/1721182053780?e=1726704000&v=beta&t=z9oQ1gvqWTn6KJXetE_G5h5vrqHdwJkb2Mu6BeuNF40",
            "https://media.licdn.com/dms/image/D4D12AQFSBUQs5FC3uw/article-inline_image-shrink_400_744/0/1721187284153?e=1726704000&v=beta&t=mTvzdAVA1Zs0dTZMCcHczBxrrvYXMAfWns0Fvdvmqc8",
            "https://media.licdn.com/dms/image/D4D12AQEVBP5ELaNYzQ/article-inline_image-shrink_400_744/0/1721180641966?e=1726704000&v=beta&t=599XYpvTED7odb0pfcvUdPEqOeNbiryr78Xt_1wqHV4",
            "https://media.licdn.com/dms/image/D4D12AQGGMVe8rONdSQ/article-inline_image-shrink_400_744/0/1721180515346?e=1726704000&v=beta&t=269kv0E9laDsO_aucfQ0LJAFyfNE36J2dYeoDcC_GdM",
            "https://media.licdn.com/dms/image/D4D12AQFBDlOd7s7uCA/article-inline_image-shrink_400_744/0/1721186066640?e=1726704000&v=beta&t=lVx2eZPUz471ofunBhigkPhjeeF1navWiHBCRSDcx7A",
            "https://media.licdn.com/dms/image/D4D12AQFpj84SeJKD0g/article-inline_image-shrink_400_744/0/1721180731014?e=1726704000&v=beta&t=3ipbPzn_gPcZ-IS_hgLfARGPdQsYXAh6JhPE48yy_qo",
            "https://media.licdn.com/dms/image/D4D12AQH3Cg_9qQB0LQ/article-inline_image-shrink_400_744/0/1721182234990?e=1726704000&v=beta&t=9VAfhxrYhUpV3X7i0aleLlMz0-43lap2nygiM3Zia30",
            "https://media.licdn.com/dms/image/D4D12AQFPICinpOzZ0Q/article-inline_image-shrink_400_744/0/1721177302021?e=1726704000&v=beta&t=UQ9uscJDHprrU4O7x6BajMER2UsJCQEIVumuFvAQ2fM",
            "https://media.licdn.com/dms/image/D4D12AQGuvK0OO-3P3A/article-inline_image-shrink_400_744/0/1721181480059?e=1726704000&v=beta&t=QVhCrtjtrkVhs0B0726Ez_DHK2XDeENdIKLUk4Cxn-Q",
            "https://media.licdn.com/dms/image/D4D12AQEpaAbE9e1KHQ/article-inline_image-shrink_1000_1488/0/1721181667961?e=1726704000&v=beta&t=psEBS5OLM_4gX9yHrJQyh9w9U8gce3v4EZ4gMH9xL-U",
            "https://media.licdn.com/dms/image/D4D12AQHy4sTjYTJl2A/article-inline_image-shrink_400_744/0/1721182785491?e=1726704000&v=beta&t=TCHMbGg7muwA_J2v-iSxRYLOqn9wyO8j9d1c0gOQ5BY",
            "https://media.licdn.com/dms/image/D4D12AQELjXNlWjD5Ew/article-inline_image-shrink_400_744/0/1721180560607?e=1726704000&v=beta&t=BK98S83ZsTCyW3jtIoikDTMc_XbTL9F-_f58M3qMNIA",
            "https://media.licdn.com/dms/image/D4D12AQG8lxVuZWz5ZA/article-inline_image-shrink_400_744/0/1721185808606?e=1726704000&v=beta&t=G2icSDCobtX9pRIyc78VqdlRu_5J7kU3wS6-3SQw8Pc",
            "https://media.licdn.com/dms/image/D4D12AQGUXMotbuSSTg/article-inline_image-shrink_1000_1488/0/1721187282384?e=1726704000&v=beta&t=zg9IDNc6CaUTGV8TJvdwU-yYnEJUN55Ji_CXYEJtIeo",
            "https://media.licdn.com/dms/image/D4D12AQFhyxDuzrgmKQ/article-inline_image-shrink_1000_1488/0/1721179906574?e=1726704000&v=beta&t=n3qVgM9WCXdp1iPPYJLvPCruyaLc02uiTByFtFWMawU"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Ajay Taneja"
        ],
        "publish_date": "2024-05-26T15:56:10+00:00",
        "summary": "",
        "meta_description": "1.Introduction: Few weeks ago, I had taken a course titled: “Knowledge Graphs for RAG” – the course is offered by DeepLearning.",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/pulse/knowledge-graphs-rag-part-10-my-graph-series-blogs-ajay-taneja-hkeyf",
        "text": "1.Introduction:\n\nFew weeks ago, I had taken a course titled: “Knowledge Graphs for RAG” – the course is offered by DeepLearning.ai . The course generally talks about using Language models together with Graph Databases and attempts to detail how when LLMs are combined together with Graph Databases have interesting interactions. The focus of the course was to explain how Graph Databases have a huge potential for creating Retrieval Augmented Generation (RAG) Systems.\n\nIn this article I have attempted to document my course notes and thus describe the course content – chapter by chapter. The course comprised of the following chapters:\n\n1. Knowledge Graph: Fundamentals\n\n2. Querying Knowledge Graphs\n\n3. Preparing Text with RAG\n\n4. Constructing a Knowledge Graph with text documents\n\n5. Adding relationship to a SEC Graph\n\n6. Expanding the SEC Graph\n\n7. Chatting with Knowledge Graphs\n\nUsing RAG systems with Knowledge Graphs involves firstly creating a graph from all the unstructured data which might be available in form of pdf files or markdown documents or xml files and then building a RAG system over the graph. The details of how this is done is explained twice in these notes:\n\nFirstly, in section 4 (the chapter related to “Preparing Text with Graph” as pointed out above) where a RAG system is built over a simple Person-Movie Graph as shown in the figure below:\n\nThe above Graph shows the relationship between people (part of the “person” node) and the movie (part of the movie node). More details related to this Graph are discussed in section 3 and 4 of this article.\n\nAs well as in section 5 where RAG system is built over a Knowledge Graph which is constructed from the scratch as shown in the figure below:\n\nThe figure 2 is the schema of the Graph – constructed from the scratch: we have the managers (Capital Investment Firms) who own stock in companies and the companies file some forms that are being chunked. These forms comprise a comprehensive report filed annually by public companies that details their financial performance. The Managers and the companies are also connected to Addresses. Details of construction of the Knowledge Graph are discussed in sections 5, 6, 7 and the graph is constructed incrementally, and the RAG system is built over it incrementally.\n\nSection 5 also details the steps related to the cleansing of the data before inserting it into the Graph and a notebook walkthrough of various steps involving: cleansing of the data, splitting it into chunks and loading / merging these chunks into the Graph through a Graph query and then genearting the embeddings for every chunk.\n\nSection 6 is about adding the relationships to the Graph after the nodes are built and the embeddings added into the relevantmt node objects.\n\nSection 7 and 8 shows how one can generate the graph (cypher query here) query corresponding to English language using few-shot learning that is – providing an LLM such as GPT3.5 or GPT4.0 examples of English prompt and the corresponding cypher query. This is possible if the LLM is already familiar with Graph query as a result of its training data.\n\nFinally, in the last section I have pointed out to my GitHub repository which has all the notebooks discussed in this article.\n\n2. Why Graphs?\n\nOne might think that if we have all the unstructured data for creating the graph, then, why not slap all the documents into a vector index and run a similarity search between the prompt and the available data and then based on the established similarity, pass the prompt and the context to the LLM to obtain the answer. This is what is done in conventional RAG systems. The Graphs give much better results for multi-hop searches.\n\nFor example, the answer to the user’s question might be located across different documents so rather than looking for an answer to something simple like: “What is the healthcare policy of the company?” wherein the answer is typically located over one section of the document, but if we want to combine the information across different documents, then, vector similarity does not go very far typically for a complex query.\n\nSecondly, what makes Graphs very elegant as well as efficient is both the nodes and the relationships can have properties/attributes that are searchable, for example: a person may be related to a project, and we can have the dates the person is working on the project as attributes (properties) of the corresponding edge. We can also have the sentiment – the experience of the person who was working on the project and if that information is available, we can search for all the person and the project relationship.\n\nFor example, we can search whether the sentiment was negative or positive and embed that in the relationship.\n\nFurther, Graphs offer a flexible data model – well suited for incrementally increasing the amount of data - the number of nodes in the Graph. Thus, offering the flexibility for schema changes. This is clearer through sections 5, 6 and 7 where the Graph as shown in Figure 2 above is incrementally constructed.\n\nLet us now start discussing the course content as mentioned in the introduction section of this article, lets first start writing some cypher queries on an existing person-movie example graph as shown in Figure 1.\n\n3. Querying Knowledge Graphs\n\nTo begin with let us examine the basic steps involving querying Knowledge Graphs. Here, we will connect to a neo4j database through LangChain and query the person-movie graph of Figure 1 , partly shown below:\n\nIn the person node of the Graph, it has properties/attributes: title, tagline, release_date as shown in the figure below:\n\nAll the relationships between person and movie node are as shown in the Figure below:\n\nThe connection to a neo4j database is made through LangChain specifying the port of the Graph, the username and password. This requires importing a Neo4j Graph Class called: Neo4jGraph. An instance of the neo4j Graph class is created which is the driver to the connection to the neo4j graph:\n\nOnce the instance is created, we start sending Cypher queries to the Knowledge Graph. Cypher is the Graph query language supported by neo4j. Some of the example queries are shown below:\n\n4. Preparing Text for RAG\n\nRAG systems start by using vector representation of text to match the prompt to relevant section of text in the unstructured data. Therefore, to be able to find the relevant text from the knowledge graph in the same way, we will have to create the embedding of the text field in the knowledge graph.\n\nThe chapter incorporates the same environment variables as in the one querying knowledge graphs discussed in the section 3 but also uses an Open AI API key for in order to use Open AI embeddings model.\n\nAgain, an instance of the neo4j graph class is created to be able to connect to the knowledge graph as shown below.\n\nAs per the neo4j architecture, a vector index is created to store the embeddings of the movie names and the corresponding tag lines. You will have to specify the vector dimension as 1536 and cosine similarity function.\n\nYou can see the vector indexes through the query below:\n\nFollowing the creation of the vector index object, the contents are populated through a cypher query language as below:\n\nThe contents include the embedding vectors which are obtained through the Open AI embedding model – hence, the query to populate the embedding vectors requires the Open AI API key as shown above.\n\nOnce the embeddings are populated, they can be visualized through a cypher query as below:\n\nOnce the embeddings are populated in the vector index, we can start asking questions that will make use of vector similarity search like:\n\n“What movies are about love”?\n\nThis will involve first calculating the embedding for the question using the cypher query again using the Open API key as shown below:\n\nIn the above query, the top k (k = 5) results are returned following a cosine similarity search:\n\nDifferent questions through which the answer can be obtained through the taglines of the movies can be asked.\n\n5. Constructing a Knowledge Graph from text documents\n\nThis chapter involves building a knowledge graph with financial documents that companies have to file with securities and exchange commission (SEC). An important form in filing the financial documents is the form 10-K which is an annual report of company’s activities. By definition: A 10-K is a comprehensive report filed annually by a publicly traded company about its financial performance and is required by the U.S. Securities and Exchange Commission (SEC).\n\nThese forms become public records and can be accessed through SEC’s Edge database. The figure below shows an example form for Qualcomm:\n\nData cleansing before starting to build up the KG:\n\nAll of the above data is first filled into a Knowledge Graph in order to have a chat with the documents. The forms are available for download as xml files. The xml files were cleansed with regex and parsed into python data structures using beautiful soup. The data cleansing also extracted central index key (CIK) which is the company identifier used by the SEC and then extracted specific sections of the form.\n\nAfter all the cleansing was completed, the data was converted into json format in order to easily create the knowledge graph.\n\nFollowing is the overall process of creating the knowledge graph using the cleansed data:\n\nSplit the section into chunks using the LangChain text splitter.\n\nOnce we have the chunks set up, each of the chunk will be a node in the graph. The node will have the original text and the metadata as properties.\n\nOnce that is done, the vector index is created as described in section 5.2.\n\nAnd next, the embedding vectors corresponding to each chunk are calculated and vector index populated.\n\nFinally, with all that done, similarity search can be easily carried out using cosine similarity.\n\nNotebook walkthrough of above steps:\n\nImport of Python packages:\n\nSetting up of environment variables:\n\nThe steps in the notebook correspond to a single 10K document but can be repeated for all the documents.\n\nThe json file and the json object are loaded.\n\nThe keys available in the json include the information that has to be included in the question-answering as shown below:\n\nThe text in the json object looks as below:\n\nChunking is carried out using the text splitter from LangChain. Recursive Character text splitter is used with a chunk overlap of 200 as shown below:\n\nThe first chunk text looks as shown below:\n\nHelper function to split the text in the file into chunks and load it to the nodes in a Graph.\n\nThis is the function that splits the text into chunks and loads it to the nodes in a Graph. The function takes in a file and accumulates all the chunks in a list. The function lops through all the items stated in section XX and pulls out the item text from the object.\n\nThe text is split into chunks using LangChain’s Recursive Character text splitter and then the meta data is built for each chunk as shown in the function.\n\nWe can call the helper function and see how the splitting is done:\n\nEach chunk of text with the meta data looks as shown below:\n\nMerging chunks using a cypher query:\n\nWe use a cypher query to merge chunks into a graph as shown below:\n\nAn instance of the neo4j graph is created and the query is run:\n\nA new node is created with metadata set before and text already seen.\n\nAnother cypher query is created to make the chunk id a uniqueness constraint as shown below:\n\nThe above step of merging the chunk into the Knowledge Graph is done for every chunk thus creating 23 nodes in all.\n\nCreating vector index\n\nNext, we create a vector index and populate it with embeddings for chunks as shown in the figure below:\n\nNow that we have the chunks, we can set the embeddings for each of the node:\n\nNow, we have the chunks in each node along with the text embedding, we create the helper function to perform similarity search exactly as discussed in section 4 above.\n\nNetapp is one of the companies filed the 10K form.\n\nBuilding RAG systems with LangChain:\n\nAbove, we have only performed vector search. IF we went to build a chatbot, we build a RAG system using LangChain to create a chatbot that provides answers to the questions.\n\nThis is done using neo4j’s vector interface which makes neo4j look like a vector store.\n\nLangChain object is used for doing question answering. The interaction with OpenAI is done using LangChain.\n\nWith this, the chatbot is ready for question-answering!\n\n6. Adding Relationships to the SEC Graph\n\nHaving added the chunks from the text from the documents into the nodes in the graph, it is now time to add relationships between the nodes to preserve the individual structure of the documents. We import packages from Python and set up the global variables as shown below:\n\nAdding the form:\n\nThis is the form associated with the 10K Document. It may be recalled from the section above that there will be a form associated with each 10K document. The form node is created through the cyper query. The chunks are connected to each other and the newly created form node as shown in the figure below:\n\nA linked list is created connecting all the chunks together – this is done through cyper queries as shown below:\n\nOnce the connections are made, cypher queries can be added to explore the graph. Once can retrieve a chuck through it’s chunk id as well as a window of chunks by specifying a hunk id and the number of chunks on either side. With a RAG application,you can find a node using semantic search, one can then find extra context using a pattern match in the graph.\n\nWith the graph, the information is stored in the nodes and relationship. We can find a pattern by defining nodes and relationship and can find a path using shortest path/likewise using those algorithms.\n\nExtending the SEC Graph\n\nThrough this section, we will have a second SEC dataset to expand the context of the original filing forms. The second set of forms provide information of the institutional investment managers and the interests they hold in the companies. By adding this data to the graph, you will be able to ask complex questions with combined datasets to help you understand market dynamics.\n\nThis has not been elaborated but the notebook can be found in the GitHub repo as pointed out in section 9.\n\n7. Chatting with the SEC Documents\n\nLet us now recapitulate about the steps in section 5: we created a Knowledge Graph and started with a minimum viable Graph. We followed a pattern: we extracted some data, enhanced the data and then expanded upon the data to create a Graph.\n\nBy extracting the data, we mean taking the data from the sources and populating it in the nodes. Enhancing the data means supercharging the data with vector embedding and expanding the data means connecting the data to the graph we already have.\n\nTo start with: we had the form 10K, we split the raw data and did the chunking. We created nodes for each of the chunk. We added the embedding and finally connected the nodes. That was the pattern – as illustrated in the Figure below:\n\nThen, we had the new data from the companies and then the Managers. We had the companies who filed the form and finally we had the managers who owned stock in the company.\n\nOne can continue to grow the knowledge graph in different ways to enhance the context of the questions that you are asking.\n\nThe resulting graph looks like as follows:\n\nThat is the schema of the Graph: we have the managers who own stock in companies and the companies file some forms that are being chunked. The Managers and the companies are also connected to Addresses.\n\nWith the addresses and other entities in the Graph, we can ask questions like:\n\nWhat companies are near each other?\n\nHow many investment firms are near the company they invested in?\n\nHow many investment forms are in the same city as the company they invested in?\n\nEtc.\n\nThis is the schema worked on in the final notebook, which has the following:\n\nExplore the Knowledge Graph and Cypher Queries.\n\nUse LangChain to create question and answer chat.\n\nFinally – LLM to combine both the technologies.\n\nLet us go through the above steps as we have the complete Knowledge Graph now.\n\nExploring the Knowledge graph with cypher queries:\n\nAs usual, we connect to a graph in the neo4j database through LangChain. We start by importing the libraries and then create an instance of the neo4j graph as shown in the figures below:\n\nAgain, we then define the global and environment variables:\n\nWe create an instance of the neo4j graph:\n\nWe then do some exploration with cypher:\n\na) Let us find a random manager:\n\nb) We then find a specific manager – we find a manager named “Royal Bank”.\n\nc) We can combine two queries, looking out for royal bank and then find out where they are located as shown below:\n\nd) We can then do a query to find out which state has the most investment firms:\n\ne) We can ask the same type of question: which state has the most public companies listed:\n\nf) We can drill down into California and ask which are the cities in California with most investment firms.\n\ng) Which companies are in Santa Claura?\n\nh) Which companies are near Santa Claura? The latitude and longitude information helps here.\n\ni) We can take individual queries and combine them to do some interesting things like:\n\nWhich investment forms are near Palo Alto networks?\n\n(Note: this is a misspelt company name]\n\nUsing Generative AI to write Cypher Queries:\n\nOpen AI GPT 3.5 is good at writing Cypher queries. To ask the LLM to write cypher queries we can use a technique called “few shot learning”. With few shot learning, you provide examples in your prompt and teach the LLM how to complete a task and then you ask the LLM to perform a task.\n\nLet us look at how you can teach the LLM to learn cypher. Here we have provided just one example corresponding to few shot learning:\n\nThis is like asking the LLM to only follow your instructions. We can then provide the LLM with actual schema.\n\nSchema\n\n{}\n\nWithin the curly braces, the schema for the LLM will get passed. As a standard practice, for the LLM To generate Cypher, provide all the explanations you can. For example,\n\nNote:\n\nDo not include any explanation or apologies in your responses. Do not respond to questions that might ask anything other than you to construct a cypher statement. Do not include any test other than the generated cypher statement.\n\nFew shot learning:\n\nProvide example to the LLM of cypher queries corresponding to English language. This is possible because GPT 3.5 / GPT 4 is already trained with Cypher.\n\n2. Creating a workflow with LangChain\n\nTo create a workflow around this, we use LangChain integration which is pretty convenient.\n\nWe take the Cypher Generation Template and turn it into a Cypher generation prompt with a prompt template class.\n\nTo create a workflow around this, we use LangChain integration which is pretty convenient.\n\nWe take the Cypher Generation Template and turn it into a Cypher generation prompt with a prompt template class.\n\nWe create a chain – Graph Cypher QA, Question and Answer Chain\n\nUtility class: To make things look tidy\n\nIf necessary, we can provide more shot learning examples to the LLM As shown below:\n\n8. GitHub repository"
    }
}