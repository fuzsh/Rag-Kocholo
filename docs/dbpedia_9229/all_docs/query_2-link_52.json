{
    "id": "dbpedia_9229_2",
    "rank": 52,
    "data": {
        "url": "https://www.intechopen.com/chapters/19222",
        "read_more_link": "",
        "language": "en",
        "title": "Introduction to Remote Sensing of Biomass",
        "top_image": "https://cdnintech.com/books/459/1718266687-294532015/web-cover.jpg",
        "meta_img": "https://cdnintech.com/books/459/1718266687-294532015/web-cover.jpg",
        "images": [
            "https://cdnintech.com/web/frontend/www/assets/45.89/svg/logo.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/journals/OpenAccessLock.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-share.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-copy.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-checkmark-circle-checked.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-share.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-copy.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-checkmark-circle-checked.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/svg/logoSmall_red.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/eye-icon.png",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/bookmark_red.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/quotation_red.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/institutions/dimension-trimmed.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/institutions/crossref.svg",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image1.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image2.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image3.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image4.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image5.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image6.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image7.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image8.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image9.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image10.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image11.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image12.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image13.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image14.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image15.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image36.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image37.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image38.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image39.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image40.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image41.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image42.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image43.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image44.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image45.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image46.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image47.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image48.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image49.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image50.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image51.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image52.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image53.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image54.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image55.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image56.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image57.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image58.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image59.png",
            "https://cdnintech.com/media/chapter/19222/1512345123/media/image60.png",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-share.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-copy.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-checkmark-circle-checked.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-open-book.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/svg/logoSmall_red.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-share.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-copy.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/series/icons/ic-checkmark-circle-checked.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/svg/x.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/svg/facebook.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/svg/linkedin.svg",
            "https://cdnintech.com/web/frontend/www/assets/45.89/svg/instagram.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Muhammad Aqeel Ashraf *",
            "Mohd. Jamil Maah",
            "Ismail Yusoff",
            "Muhammad Aqeel Ashraf"
        ],
        "publish_date": "2011-09-06T00:00:00",
        "summary": "",
        "meta_description": "Open access peer-reviewed chapter",
        "meta_lang": "en",
        "meta_favicon": "/apple-touch-icon.png",
        "meta_site_name": "",
        "canonical_link": "https://www.intechopen.com/chapters/19222",
        "text": "1.3.1. Orbits and swaths\n\nThe path followed by a satellite is referred to as its orbit. Satellites which view the same portion of the earth’s surface at all times have geostationaryorbits. Weather and communication satellites commonly have these types of orbits. Many satellites are designed to follow a north south orbit which, in conjunction with the earth’s rotation (west-east), allows them to cover most of the earth’s surface over a period of time. These are Near-polar orbits. Many of these satellites orbits are also Sun-synchronous such that they cover each area of the world at a constant local time of day. Near polar orbits also means that the satellite travels northward on one side of the earth and the southward on the second half of its orbit. These are called Ascending and Descending passes. As a satellite revolves around the earth, the sensor sees a certain portion of the earth’s surface. The area imaged is referred to as the Swath. The surface directly below the satellite is called the Nadir point. Steerable sensors on satellites can view an area (off nadir) before and after the orbits passes over a target.\n\n1.3.1.1. Satellite sensor characteristics\n\nThe basic functions of most satellite sensors are to collect information about the reflected radiation along a pathway, also known as the field of view (FOV), as the satellite orbits the Earth. The smallest area of ground that is sampled is called the instantaneous field of view (IFOV). The IFOV is also described as the pixel size of the sensor. This sampling or measurement occurs in one or many spectral bands of the EM spectrum. The data collected by each satellite sensor can be described in terms of spatial, spectral and temporal resolution.\n\n1.3.1.2. Spatial resolution\n\nThe spatial resolution (also known as ground resolution) is the ground area imaged for the instantaneous field of view (IFOV) of the sensing device. Spatial resolution may also be described as the ground surface area that forms one pixel in the satellite image. The IFOV or ground resolution of the Landsat Thematic Mapper (TM) sensor, for example, is 30 m. Theground resolution of weather satellite sensors is often larger than a square kilometre. There are satellites that collect data at less than one meter ground resolution but these are classified military satellites or very expensive commercial systems.\n\n1.3.1.3. Temporal resolution\n\nTemporal resolution is a measure of the repeat cycle or frequency with which a sensor revisits the same part of the Earth’s surf ace. The frequency will vary from several times per day, for a typical weather satellite, to 8—20 times a year for a moderate ground resolution satellite, such as Landsat TM. The frequency characteristics will be determined by the design of the satellite sensor and its orbit pattern\n\n1.3.1.4. Spectral resolution\n\nThe spectral resolution of a sensor system is the number and width of spectral bands in the sensing device. The simplest form of spectral resolution is a sensor with one band only, which senses visible light. An image from this sensor would be similar in appearance to a black and white photograph from an aircraft. A sensor with three spectral bands in the visible region of the EM spectrum would collect similar information to that of the human vision system. The Landsat TM sensor has seven spectral bands located in the visible and near to mid infrared parts of the spectrum.\n\nA panchromatic image consists of only one band. It is usually displayed as a grey scale image, i.e. the displayed brightness of a particular pixel is proportional to the pixel digital number which is related to the intensity of solar radiation reflected by the targets in thepixel and detected by the detector. Thus, a panchromatic image may be similarly interpreted as a black-and-white aerial photograph of the area, though at a lower resolution.\n\nMultispectral and hyperspectral images consist of several bands of data. For visual display, each band of the image may be displayed one band at a time as a grey scale image, or in combination of three bands at a time as a color composite image. Interpretation of a multispectral color composite image will require the knowledge of the spectral reflectancesignature of the targets in the scene.\n\n1.3.2. Platforms\n\nAerial photography has been used in agricultural and natural resource management for many years. These photographs can be black and white, colour, or colour infrared. Depending on the camera, lens, and flying height these images can have a variety of scales. Photographs can be used to determine spatial arrangement of fields, irrigation ditches, roads, and other features or they can be used to view individual features within a field.\n\nInfrared images can detect stress in crops before it is visible with the naked eye. Healthy canopies reflect strongly in the infrared spectral range, whereas plants that are stressed will reflect a dull colour. These images can tell a farmer that there is a problem but does not tell him what is causing the problem. The stress might be from lack of water, insect damage, improper nutrition or soil problems, such as compaction, salinity or inefficient drainage. The farmer must assess the cause of the stress from other information. If the dull areas disappear on subsequent pictures, the stress could have been lack of water that was eased with irrigation. If the stress continues it could be a sign of insect infestation. The farmer still has to conduct in-field assessment to identify the causes of the problem. The development of cameras that measure reflectance in a wider range of wavelengths may lead to better quantify plant stress. The uses of these multi-spectral cameras are increasing and will become an important tool in precision agriculture.\n\nSatellite remote sensing is becoming more readily available for use in precision agriculture. The Landsat and the NOAA polar-orbiting satellites carry instruments that can be used to determine crop types and conditions, and to measure crop acreage. The Advanced Very High ResolutionRadiometer (AVHRR) carried onboard NOAA polar orbiting satellites measure reflectance from the earth’s surface in the visible, near infrared, and thermal infrared portions of the electromagnetic spectrum.\n\nThis spectral sensitivity makes it suitable for measuring vegetative condition and because the satellite passes overhead twice a day, it can be used to detect rapidly changing conditions.Unfortunately, its use as a precision agriculture tool is limited because the spatial resolution of the sensor is nominally 1.1km. A possible application of this scanner would be to use the thermal infrared sensor to estimate daily maximum and minimum temperatures. These temperature estimates could then be used to determine degree-days that will drive pest development models.\n\nDegree-day models are an essential part of IPM programs and the enhanced spatial coverage provided by satellites would allow for assessment of spatial variability in predicted events that is not possible with data from sparsely spaced weather stations currently used for these models. Remotely sensed data can also be used to determine irrigation scheduling and adequacy of irrigation systems for uniformly wetting an entire field. The sensors aboard the Landsat satellite measures reflected radiation in seven spectral bands from the visible through the thermal infrared. The sensors high spatial resolution (approximately 30m) makes it useful in precision agriculture. The spectral response and higher spatial resolution make it suitable for assessing vegetative condition for individual fields but the overpass frequency is only once every 16 days. The less frequent overpass makes it difficult to use these data for assessing rapidly changing events such as insect outbreaks or water stress. New satellites with enhanced capabilities are planned and remotely sensed data will become more widely used in management support systems.\n\n1.6.4. Map projection coordinates\n\nA map projection is a systematic representation of all or part of the Earth on a two dimensional surface, such as a flat sheet of paper. During this process some distortion of distances, directions, scale, and area is inevitable. There are several different types of map projections. No projection is free from all distortions, but each minimizes distortions in some of the above properties, at the expense of leaving errors in others. For example, the commonly used Transverse Mercator projection represents direction accurately, but distorts distance and area, especially those farthest from the equator. Greenland, for example, appears to be much larger than it really is. The Transverse Mercator projection is useful for navigation charts.\n\n1.6.4.1. Universal Transverse Mercator (UTM)\n\nUniversal Transverse Mercator (UTM) is a global spatial system based on the Transverse Mercator projection. UTM divides the Earth into 60 equal zones, each being 6 degrees wide.Each zone is bounded by lines of longitude extending from the North Pole to the South Pole. Imagine an orange consisting of 60 segments. Each segment would be equivalent to a UTM zone. A rectangular grid coordinate system is used in most map projections. These coordinates are referred to as Eastings and Northings, being distances East and North of an origin. They are usually expressed in metres. Under the UTM system, each East and North coordinate pair could refer to one of sixty points on Earth — one point in each of the sixty zones. Because of this, the zone number needs to be quoted to ensure the correct point on Earth is being identified.\n\n1.6.4.2. Global Positioning System\n\nThe Global Positioning System (GPS) is a satellite based system that gives real time three dimensional (3D) latitude, longitude, and height information at sub-meter accuracy. The system was developed by the United States military in the late 1970’s to give troops accurate position and navigational information. A GPS receiver calculates its position on earth from radio signals broadcast by satellites orbiting the earth. There are currently twenty-four GPS satellites in this system. GPS equipment is capable of measuring a position to within centimetres but the accuracy suffers due to errors in the satellite signals. Errors in the signal can be caused by atmospheric interference, proximity of mountains, trees, or tall buildings. The government can also introduce errors in the signal for security purposes. This intentional degradation of the satellite signals is known as selective availability. The accuracy of the position information can be improved by using differential GPS. In differential GPS, one receiver is mounted in a stationary position, usually at the farm office, while the other is on the tractor or harvesting equipment. The stationary receiver calculates the error and transmits the necessary correction to the mobile receiver. GPS equipment suitable for precision agricultural cost several thousand dollars. Less expensive equipment is becoming available but the accuracy and capability is reduced.\n\n1.6.4.3. Geographic Information System (GIS)\n\nA Geographic Information System (GIS) is a computer-assisted system for handling spatial information. GIS software can be considered as a collection of software programs to acquire, store, analyze, and display information. The input data can be maps, charts, spreadsheets, or pictures. The GIS software can analyze these data using image processing and statistical procedures. Data can be grouped together and displayed as overlays. Overlays could be information such as soil type, topography, crop type, crop yield, pest levels, irrigation, and management information as shown.\n\nRelationships can be examined and new data sets produced by combining a number of overlays. These data sets can be combined with models and decision support systems to construct a powerful management tool. For example, we could assess how far a field was from roads or non-agricultural crops. This information could be important in pest infestation or in planning chemical application. We could also examine crop yield relationship to soil type or other factors as show in the following figure. A number of GIS software packages are now commercially available. Spatial data for the GIS is often collected using GPS equipment but another source of spatial information is aerial and satellite imagery.\n\n1.6.4.4. Pixels, images and colours\n\n1.6.4.4.1. Colour composite images\n\nIn displaying a colour composite image, three primary colors (red, green and blue) are used when these three colours are combined in various proportions, they produce different colors in the visible spectrum. Associating each spectral band (not necessarily a visible band) to a separate primary colour results in a colour composite image.\n\nMany colours can be formed by combining the three primary colours (Red, Green, Blue) in various proportions.\n\n1.6.4.4.2. False colour composite\n\nThe display colour assignment for any band of a multispectral image can be done in an entirely arbitrary manner. In this case, the colour of a target in the displayed image does not have any resemblance to its actual colour. The resulting product is known as a false color composite image. There are many possible schemes of producing false color composite images. However, some scheme may be more suitable for detecting certain objects in the image.\n\n1.6.4.4.3. Natural colour composite\n\nWhen displaying a natural colour composite image, the spectral bands (some of which may not be in the visible region) are combined in such a way that the appearance of the displayed image resembles a visible colour photograph, i.e. vegetation in green, water in blue, soil in brown or grey, etc. Many people refer to this composite as a \"true colour\" composite. However, this term may be misleading since in many instances the colours are only simulated to look similar to the \"true\" colours of the targets. For example, the bands 3 (red band), 2 (green band) and 1 (blue band) of a AVHRR image can be assigned respectively to the R, G, and B colours for display. In this way, the colour of the resulting colour composite image resembles closely what the human eyes would observe.\n\n1.9.1. Remote sensing\n\nRemote sensing is the science and art of obtaining information about an object, area or phenomenon through the analysis of data acquired by a device that is not in contact with the object, area, or phenomenon under investigation. As the term indicates, it applies to any information gathering device or method where the object of observation is remote from the device.\n\nOut of a number of devices involved in remote sensing, the most common platforms are aircraft and satellites. The sensors associated with these devices are of two types, namely passive and active sensors. In a passive system, the instrument gathers information from the radiation that happens to arrive. The main sources of radiation for such systems are either solar radiation or thermal emissions. In the active system, it is the instrument itself on board the device that is the source of radiation. It sends signals to target under investigation, and receives the return signal, having the unique characteristics of the target features. As far as satellite remote sensing is concerned, systems operating in the visible and infrared part of the electromagnetic spectrum are passive while microwave instruments are either active or passive.\n\nCurrently, satellites are the main devices in remote sensing. And the two main types of satellites are the Polar or Near-polarOrbiting and Geostationary satellites. The Polar or Near Polar orbiting satellites are Sun-synchronous i.e. the satellites keep a precise pace with the Sun's westward progress as the earth rotates so that they always cross the equator at precisely the same solar time. Examples can be Landsat and NOAA satellites. Geostationary satellites are satellites which travel with an angular velocity that matches the earth's rotation. As a result, they remain at the same point above the earth at all times. An example is Meteosat. These satellites are helpful in obtaining constant and persistent image of a particular area at fixed interval which is a great advantage in monitoring a location with high temporal resolution to capture the transient behavior of objects such as rain clouds.\n\nEstimation of biomass production will provide guidance to energy development polices including:\n\nThe impact of improved stoves on fuel wood and dung energy consumption.\n\nThe potential of increasing the supply of fuel wood through the establishment of small scale \"forest plantations\"\n\nThe potential of dung and other fuels for biomass energy supply.\n\n1.9.2. Principles involved\n\n1.9.2.1. The photon and radiometric quantities\n\nMost remote sensing texts begin by giving a survey of the main principles, to build a theoretical background, mainly in the physics of radiation. While it is important to have such a framework to pursue many aspects of remote sensing, we do not delve into this complex subject in much detail at this point. Instead, we offer on this and the next several pages an outline survey of the basics of relevant electromagnetic concepts. On this page, the nature of the photon is the prime topic. Photons of different energy values are distributed through what is called the Electromagnetic Spectrum.\n\nHereafter in this Introduction and in the Sections that follow, we limit the discussion and scenes examined to remote sensing products obtained almost exclusively by measurements within the Electromagnetic Spectrum (force field and acoustic remote sensing are briefly covered elsewhere in the Tutorial). Our emphasis is on pictures (photos) and images (either TV-like displays on screens or \"photos\" made from data initially acquired as electronic signals, rather than recorded directly on film). We concentrate mainly on images produced by sensors operating in the visible and near-IR segments of the electromagnetic spectrum but also inspect a fair number of images obtained by radar and thermal sensors.\n\nThe underlying basis for most remote sensing methods and systems is simply that of measuring the varying energy levels of a single entity, the fundamental unit in the electromagnetic (which may be abbreviated \"EM\") force field known as the photon. As you will see later on this page, variations in photon energies (expressed in Joules or ergs) are tied to the parameter wavelength or its inverse, frequency. EM radiation that varies from high to low energy levels comprises the ElectroMagnetic spectrum (EMS). Radiation from specific parts of the EM spectrum contain photons of different wavelengths whose energy levels fall within a discrete range of values. When any target material is excited by internal processes or by interaction with incoming EM radiation, it will emit or reflect photons of varying wavelengths whose radiometric quantities differ at different wavelengths in a way diagnostic of the material. Photon energy received at detectors is commonly stated in power units such as Watts per square meter per wavelength unit. The plot of variation of power with wavelength gives rise to a specific pattern or curve that is the spectral signature for the substance or feature being sensed.\n\nNow, in more detail: The photon is the physical form of a quantum, the basic particle of energy studied in quantum mechanics (which deals with the physics of the very small, that is, particles and their behavior at atomic and subatomic levels). The photon is also described as the messenger particle for EM force or as the smallest bundle of light. This subatomic massless particle, which also does not carry an electric charge, comprises radiation emitted by matter when it is excited thermally, or by nuclear processes (fusion, fission), or by bombardment with other radiation (as well as by particle collisions). It also can become involved as reflected or absorbed radiation. Photons move at the speed of light: 299,792.46 km/sec (commonly rounded off to 300,000 km/sec or ~186,000 miles/sec).\n\nPhoton particles also move as waves and hence, have a \"dual\" nature. These waves follow a pattern that can be described in terms of a sine (trigonometric) function, as shown in two dimensions in the figure below.\n\nThe distance between two adjacent peaks on a wave is its wavelength. The total number of peaks (top of the individual up-down curve) that pass by a reference lookpoint in a second is that wave's frequency (in units of cycles per second, whose SI version [SI stands for System International] is known as a Hertz [1 Hertz = 1/s-1]).\n\nA photon travels as an EM wave having two components, oscillating as sine waves mutually at right angles, one consisting of the varying electric field, the other the varying magnetic field. Both have the same amplitudes (strengths) which reach their maxima-minima at the same time. Unlike other wave types which require a carrier (e.g., water waves), photon waves can transmit through a vacuum (such as in space). When photons pass from one medium to another, e.g., air to glass, their wave pathways are bent (follow new directions) and thus experience refraction.\n\nA photon is said to be quantized, in that any given one possesses a certain quantity of energy. Some other photon can have a different energy value. Photons as quanta thus show a wide range of discrete energies. The amount of energy characterizing a photon is determined using Planck's general equation:\n\nE =hvE1\n\nwhere h is Planck's constant (6.6260... x 10-34 Joules-sec)* and v is the Greek letter, nu, representing frequency (the letter \"f\" is sometimes used instead of v). Photons traveling at higher frequencies are therefore more energetic. If a material under excitation experiences a change in energy level from a higher level E2 to a lower level E1, we restate the above formula as:\n\nΔE = E2– E1=hvE2\n\nwhere v has some discrete value determined by (v2 - v1). In other words, a particular energy change is characterized by producing emitted radiation (photons) at a specific frequency v and a corresponding wavelength at a value dependent on the magnitude of the change.\n\n2.6.1.General principles for recognizing vegetation\n\nPlanet Earth is distinguished from other Solar System planets by two major categories: Oceans and Land Vegetation. The oceans cover ~70% of the Earth's surface; land comprises 30%. On the land itself, the first order categories break down as follows: Trees = 30%; Grasses = 30%; Snow and Ice = 15%; Bare Rock = 18%; Sand and Desert Rock = 7%. We have already seen in previous Sections and in the Overview that in false colour imagery the remote sensing signature of vegetation is a bright red. The landscape shown in this first image could almost be on Mars except for the presence of this bright red sign of vegetation. This is the Ouargla Oasis in the Sahara Desert of southern Algeria, a concentration of trees and plants where groundwater reaches the surface:\n\nOn Earth, the amount of vegetation within the seas is huge and important in the food chain. But for people the land provides most of the vegetation within the human diet. The primary categories of land vegetation (biomes) and their proportions is shown in this pie chart:\n\nThese biomes are defined in part by the temperature and precipitation controls that differentiate them:\n\nGlobal maps of vegetation biomes on the continents show this general distribution:\n\nA fair number of global vegetation maps have been published. These usually show slight to moderate differences, depending in part with the types and numbers of classes established in the classification. There also exists a notable correlation between vegetation classes and climate. Remote sensing has proven a powerful \"tool\" for assessing the identity, characteristics, and growth potential of most kinds of vegetative matter at several levels (from biomes to individual plants). Vegetation behaviour depends on the nature of the vegetation itself, its interactions with solar radiation and other climate factors, and the availability of chemical nutrients and water within the host medium (usually soil, or water in marine environments). A common measure of the status of a given plant, such as a crop used for human consumption, is its potential productivity (one such parameter has units of bushels/acre or tons/hectare, or similar units). Productivity is sensitive to amounts of incoming solar radiation and precipitation (both influence the regional climate), soil chemistry, water retention factors, and plant type. Examine the diagram below to see how these interact, keeping in mind that various remote sensing systems (e.g., meteorological or earth-observing satellites) can provide inputs to productivity estimation:\n\nBecause many remote sensing devices operate in the green, red, and near infrared regions of the electromagnetic spectrum, they can discriminate radiation absorption and reflectance properties of vegetation. One special characteristic of vegetation is that leaves, a common manifestation, are partly transparent allowing some of the radiation to pass through (often reaching the ground, which reflects its own signature). The general behaviour of incoming and outgoing radiation that an act on a leaf is shown in figure 21.\n\nNow, consider this diagram which traces the influence of green leafy material on incoming and reflected radiation.\n\nAbsorption centred at about 0.65 µm (visible red) is controlled by chlorophyll pigment in green-leaf chloroplasts that reside in the outer or Palisade leaf. Absorption occurs to a similar extent in the blue. With these colours thus removed from white light, the predominant but diminished reflectance of visible wavelengths is concentrated in the green. Thus, most vegetation has a green-leafy colour. There is also strong reflectance between 0.7 and 1.0 µm (near IR) in the spongy mesophyll cells located in the interior or back of a leaf, within which light reflects mainly at cell wall/air space interfaces, much of which emerges as strong reflection rays. The intensity of this reflectance is commonly greater (higher percentage) than from most inorganic materials, so vegetation appears bright in the near-IR wavelengths (which, fortunately, is beyond the response of mammalian eyes). These properties of vegetation account for their tonal signatures on multispectral images: darker tones in the blue and, especially red, bands, somewhat lighter in the green band, and notably light in the near-IR bands (maximum in Landsat's Multispectral Scanner Bands 6 and 7 and Thematic Mapper Band 4 and SPOT's Band 3).\n\nIdentifying vegetation in remote-sensing images depends on several plant characteristics. For instance, in general, deciduous leaves tend to be more reflective than evergreen needles. Thus, in infrared colour composites, the red colours associated with those bands in the 0.7 - 1.1 µm interval are normally richer in hue and brighter from tree leaves than from pine needles.\n\nThese spectral variations facilitate fairly precise detecting, identifying and monitoring of vegetation on land surfaces and, in some instances, within the oceans and other water bodies. Thus, we can continually assess changes in forests, grasslands and range, shrub lands, crops and orchards, and marine plankton, often at quantitative levels. Because vegetation is the dominant component in most ecosystems, we can use remote sensing from air and space to routinely gather valuable information helpful in characterizing and managing of these organic systems.\n\nThis discrimination capability implies that one of the most successful applications of multispectral space imagery is monitoring the state of the world's agricultural production. This application includes identifying and differentiating most of the major crop types: wheat, barley, millet, oats, corn, soybeans, rice, and others. This capability was convincingly demonstrated by an early ERTS-1 classification of several crop types being grown in Holt County, Nebraska. This pair of image subsets, obtained just weeks after launch, indicates what crops were successfully differentiated; the lower image shows the improvement in distinguishing these types by using data from two different dates of image acquisition:\n\nThis is a good point in the discussion to introduce the appearance of large area croplands as they are seen in Landsat images. We illustrate with imagery that covers the two major crop growing areas of the United States.The scene below is a part of the Great or Central Valley California, specifically the San Joaquin Valley. Agricultural here is primarily associated with such cash crops as barley, alfalfa, sugar beets, beans, tomatoes, cotton, grapes, and peach and walnut trees. In July of 1972 most of these fields are nearing full growth. Irrigation from the Sierra Nevada, whose foothills are in the upper right, compensates for the sparsity or rain in summer months (temperatures can be near 100º F). The eastern Coast Ranges appear at the lower left. The yellow-brown and blue areas flanking the Valley crops are grasslands and chapparal best suited for cattle grazing. The blue areas within the croplands (near the top) are the cities of Stockton and Modesto.\n\nMany factors combine to cause small to large differences in spectral signatures for the varieties of crops cultivated by man. Generally, we must determine the signature for each crop in a region from representative samples at specific times. However, some crop types have quite similar spectral responses at equivalent growth stages. The differences between crop (plant) types can be fairly small in the Near-Infrared, as shown in these spectral signatures (in which other variables such as soil type, ground moisture, etc. are in effect held constant).\n\nThe shape of these curves is almost identical when each crop type is compared with the others. The big difference is in the percent reflectance. The similarity in shape is explained by the fact, discussed earlier, that most vegetation matter has the same basic cell structure and similar content of chlorophyll. Yet remote sensing is reasonably effective at distinguishing and identifying different crop types.\n\n2.6.2. Factors affecting spectral signatures of field crops\n\nRead the answer to this question - it is important. The list is incomplete, but the main factors are discussed. But with so many variables involved, it is difficult to claim that each crop has a specific spectral signature. This means that, in order to identify the several crops usually present in agricultural terrain in any particular area, the most efficient course is to establish training sites, spectral characteristics are one means of identifying and classifying features in a scene. We will see how reliable this is by itself as this Section unfolds. Shape and pattern recognition are valuable inputs in determining what a feature is. The geometric shape of a field of crops sometimes is helpful in determining the actual crop itself. But field shapes tend to vary both within regions of large countries like the U.S. and in different parts of the world. This variation is evident in the illustration below\n\nThrough remote sensing it is possible to quantify on a global scale the total acreage dedicated to these and other crops at any time. Of particular import is the utility of space observations to accurately estimate (goal: best case 90%) the expected yields (production in bushels or other units) of each crop, locally, regionally or globally. We can do this by first computing the areas dedicated to each crop, and then incorporating reliable yield assessments per unit area, which agronomists can measure at representative ground-truth sites. Reliability is enhanced by using the repeat coverage of the croplands afforded by the cyclical satellite orbits assuming, of course, cloud cover is sparse enough to foster several good looks during the growing season. Usually, the yield estimates obtained from satellite data are more comprehensive and earlier (often by weeks) than determined conventionally as harvesting approaches. Information about soil moisture content, often critical to good production, can be qualitatively (and under favourable conditions, quantitatively) appraised with certain satellite observations; that information can be used to warn farmers of any impending drought conditions.\n\nUnder suitable circumstances, it is feasible to detect crop stress generally from moisture deficiency or disease and pests, and sometimes suggest treatment before the farmers become aware of problems. Stress is indicated by a progressive decrease in Near-IR reflectance accompanied by a reversal in Short-Wave IR reflectance, as shown in this general diagram:\n\nThis effect is evidenced quantitatively in this set of field spectral measurements of leaves taken from soybean plants as these underwent increasing stress that causes loss of water and breakdown of cell walls.\n\nFor the soybeans, the major change with progressive stress is the decrease in infrared reflectances. In the visible, the change may be limited to color modification (loss of greenness), as indicated in this sugar beets example, in which the leaves have browned:\n\nDifferences in vegetation vigour, resulting from variable stress, are especially evident when Near Infrared imagery or data are used. In this aerial photo made with Colour IR film shows a woodlands with healthy trees in red, and \"sick\" (stressed) vegetation in yellow-white (the red no longer dominates):\n\nFor identifying crops, two important parameters are the size and shape of the crop type. For example, soybeans have spread out leaf clumps and corn has tall stalks with long, narrow leaves and thin, tassle-topped stems. Wheat (in the cereal grass family) has long thin central stems with a few small, bent leaves on short branches, all topped by a head containing the kernels from which flour is made. Other considerations are the surface area of individual leaves, the plant height and amount of shadow it casts, and the spacing or other planting geometries of row crops (the normal arrangement of legumes, feed crops, and fruit orchards). The stage of growth (degree of crop maturity) is also a factor. For example during its development wheat passes through several distinct steps such as developing its kernel-bearing head and changing from shades of green to golden-brown.\n\nAnother related parameter is Leaf Area Index (LAI), defined as the ratio of one-half the total area of leaves (the other half is the underside) in vegetation to the total surface area containing that vegetation. If all the leaves were removed from a tree canopy and laid on the ground, their combined areas relative to the ground area projected beneath the canopy would be some number greater than 1 but usually less than 10. As a tree, for example, fully leaves, it will produce some LAI value that is dependent on leaf size and shape, the number of limbs, and other factors. The LAI is related to the the total biomass (amount of vegetative matter [live and dead] per unit area, usually measured in units of tons or kilograms per hectare [2.47 acres]) in the plant and to various measures of Vegetation Index. Estimates of biomass can be carried out with variable reliability using remote sensing inputs, provided there is good supporting field data and the quantitative (mathematical) models are efficient. Both LAI and NDVI are used in the calculations.\n\nSatellite remote sensing is an excellent means of determining LAI on a regional or sub continental scale. In principal, actual LAI must be determined on site directly by stripping off all leaves, but in practice it can be estimated by statistical sampling or by measuring some property such as reflectance. Thus, remote sensing can determine an LAI estimate if thereflectance are matched with appropriate field truth. For remotely sensed crops, LAI is\n\ninfluenced by the amount of reflecting soil between plant (thus looking straight down will see both corn and soil but at maturity a cornfield seems closely spaced when viewed from the side). For the spectral signatures shown below, the Near IR reflectances will increase with LAI.\n\nThis change in appearance and extent of surface area coverage over time is the hallmark of vegetation as compared with most other categories of ground features (especially those not weather-related). Crops in particular show strong changes in the course of a growing season, as illustrated here for these three stages - bare soil in field (A); full growth (B); fall senescence (C), seen in a false colour rendition:\n\n2.6.4. Usage of specific crop types as training sites identified (determined)?\n\nWith this survey of the role of several variables in determining crop types, let us look now at one of the most successful classifications reported to date. These are being achieved by hyper spectral sensors such as AVIRIS and Hyperion. The Hyperion hyper spectral sensor on NASA's EO-1has procured multichannel data for the Coleambally test area in Malaysia. This image, made from 3 narrow channels in the visible-Near IR, shows how the fields of corn, rice, and soybeans changed their reflectance during the (southern hemisphere) growing season: Notice the pronounced differences in crop shapes which is a big factor in producing the reflectance differences (as said above, healthy leaf vegetation generally has a spectral response that does not vary much in percent reflectance from one plant type to others, so that differences in crop shape become the distinguishing factor).\n\nThe multichannel data from Hyperion were used to plot the observed spectral signatures for the soil and three crops, as shown here (the curves identified in the upper right [the writing is too small to be decipherable on most screens] are, from top to bottom, soil, corn, rice, and soybeans):\n\nUsing a large number of selected individual Hyperion channels, this supervised classification of the four classes in the sub scene was generated; this end result is more accurate than is normally achievable with broad band data such as obtained by Landsat:\n\nActive microwave sensors, or radar, can use several variables to recognize crop vegetation and even develop a classification of crop types. Here is a SIR-C (Space Shuttle) image of farmland in the Netherlands, taken on April 4, 1994. The false colour composite was made with L-band in the HH polarization mode = red; L-band HV = green; and C-band HH = blue.\n\nAn additional image variable is the crop's background, namely the nurturing soil, whose colour and other properties can change with the particular soil type, and whose reflectance depends on the amount of moisture it holds. Moisture tends to darken a given soil colour; this condition is readily picked up in aircraft imagery as seen in this pair of images:\n\nOften, the distribution of moisture, as soil dries differentially, is variable in an imaged barren field giving rise to a mottled or blotchy appearance. Thermal imagery brings out the differential soil moisture content by virtue of temperature variations. The amount of water in the crop itself also affects the sensed temperature (stressed [water deficient] or diseased crop material is generally warmer). Soil water variations are evident in this image made by an airborne thermal sensor of several fields, where high moisture correlates with blue and drier parts of the fields with reds and yellows:\n\nA combination of visible, NIR, and thermal bands can pick up both water deficiency and the resulting stress on the crops in the fields. This set of three images was made by a Daedalus instrument flown on an aircraft. In the top image, yellow marks unplanted fields and those in blue and green are growing crops. The center image picks up patterns of water distribution in the crop fields. The bottom image shows levels of stress related in part to insufficient moisture."
    }
}