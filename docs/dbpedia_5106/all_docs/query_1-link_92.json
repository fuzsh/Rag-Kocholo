{
    "id": "dbpedia_5106_1",
    "rank": 92,
    "data": {
        "url": "https://medium.com/radio-france-engineering/on-demand-ci-cd-with-gitlab-and-kubernetes-1d395105ac45",
        "read_more_link": "",
        "language": "en",
        "title": "On-Demand CI/CD with Gitlab and Kubernetes",
        "top_image": "https://miro.medium.com/v2/resize:fit:1200/1*0anodZCgWlzeKZawoL58NQ.png",
        "meta_img": "https://miro.medium.com/v2/resize:fit:1200/1*0anodZCgWlzeKZawoL58NQ.png",
        "images": [
            "https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:88:88/2*IwrhluWHIajH79Smsvov4g.jpeg",
            "https://miro.medium.com/v2/resize:fill:48:48/1*Cqu_iP2juD0bD5Sz4cuM6Q.png",
            "https://miro.medium.com/v2/resize:fill:144:144/2*IwrhluWHIajH79Smsvov4g.jpeg",
            "https://miro.medium.com/v2/resize:fill:64:64/1*Cqu_iP2juD0bD5Sz4cuM6Q.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Julien Vey",
            "medium.com"
        ],
        "publish_date": "2020-06-02T15:24:07.618000+00:00",
        "summary": "",
        "meta_description": "Radio France is a French public service radio broadcaster. We design, build, and operate websites, mobile applications, APIs, podcast delivery, an audio streaming platform… for seven radio stations…",
        "meta_lang": "en",
        "meta_favicon": "https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19",
        "meta_site_name": "Medium",
        "canonical_link": "https://medium.com/radio-france-engineering/on-demand-ci-cd-with-gitlab-and-kubernetes-1d395105ac45",
        "text": "Culture\n\nThe main idea behind our CI/CD toolchain at Radio France is the following\n\nDon’t try to save money on CI. Developer’s time is more valuable than Gitlab’s.\n\nOptimise for speed rather than cost\n\nFail fast, give feedback early\n\nUse CI heavily, don’t be afraid of failed jobs\n\nWhen reading books and blogs about testing and CI best practices, most people will say “Run all your tests locally before pushing any new code to the repository”. We believe the opposite. Running all tests and linters on your local machine can take a lot of time, and a lot of CPU or memory resources, preventing you from doing anything else at the same time.\n\nWe prefer to push new code as soon as possible, start working on something else, and come back to our CI results when they are done. We use the same process for Code Reviews. We push code early, even unfinished work, get feedback early and refactor quickly, before too much unneeded work has been done.\n\nAnother aspect of our CI/CD culture at Radio France : we don’t enforce anything on development teams. The team in charge of CI/CD is responsible for providing tools and methods for implementing CI/CD, sharing best practices, and providing advice and counsel. Each team is responsible for its own pipelines, whether they choose to do continuous delivery on production, for instance, is their responsibility.\n\nAutomation\n\nWhen we first started to re-engineer of our CI/CD toolchain, we had been using gitlab with a few VMs as runners, only for CI. the CD part was done by Jenkins. Developers had to switch from one tool to the other to manage their whole pipeline.\n\nRunning Gitlab Runners in Kubernetes\n\nWe are currently running our fleet of gitlab runners within Kubernetes. The architecture behind the Kubernetes executor is pretty simple.\n\nOne or more gitlab-runner pods are permanent. They are in charge of querying the gitlab API to find new jobs to run. Once a job is picked. The runner will ask Kubernetes to create a new “CI pod” that will run the actual CI scripts as defined in the configuration of the job. The gitlab-runner pod itself doesn’t require a lot of memory or CPU as it only orchestrates APIs. (We allocate 64mcpu and 256MB of memory to gitlab-runner).\n\nThe “CI pod” is the actual pod where the CI scripts are executed. It’s usually composed of multiple containers. One for the script itself, one helper to prepare the script environment, get the source code. There can also be some “services” containers (a postgres container needed by the CI script). These pod usually requires more memory or CPU to run, but they are short term, and only live as long the CI script executes.\n\nWe run multiple instances of gitlab-runner. This allow us to perform upgrades without interruption. gitlab-runner gracefully handles termination when it receives a signal, letting the current jobs terminate, but not picking any new job. Each one of our gitlab-runner auto-register towards gitlab when it starts. We also use runner tags to create different pods matching different system resource requirements.\n\nWe don’t rely on Gitlab native integration with Kubernetes, for managing deployments, or for the runners. However, the gitlab-runner Helm chart does a pretty good job if you want to quickly bootstrap gitlab-runner on Kubernetes.\n\nBuilding our Docker images in Kubernetes with Kaniko\n\nNow that our CI was scalable and resilient, we needed to work on the build of our Docker Images. As we run our microservices on kubernetes, our deployment unit is a docker image, shipped with everything it needs to go to production.\n\nWe wanted our Docker Images CI to be as performant and scalable as every other job. That’s why we started to look at rootless docker builds, being able to build a docker container without the need of a docker daemon, within a Kubernetes Pod. Kaniko was the obvious choice at that time, but other tools, like img, exist. We didn’t went through an exhaustive comparison. Kaniko just worked for us.\n\nThe process of building an image with kaniko is simple\n\nCreate a build context from the source code. It’s a tar file that contains everything needed to build the docker image, including the Dockerfile.\n\nSend it to a S3 Bucket\n\nRun the kaniko_executor binary. We run kaniko within pods, as kubernetes jobs, giving it the S3 path to the build context, the registry and image where the final image should be pushed.\n\nRunning on Spot Instances\n\nAs we said previously, our CI/CD philosophy is :\n\nDon’t try to save money on CI. Developer’s time is more valuable than Gitlab’s.\n\nHowever, if we want to make this possible and make both development teams and finance teams happy, there are solutions to keep a performant CI/CD toolchain while reducing overall cost. One of them is Spot Instances.\n\nSpot Instances (or preemptible VMs for Google Cloud) are really low-cost instances, their price evolves regarding the supply and demand over several months. It doesn’t fluctuate much. When you want to purchase a spot instance, you’ll get it at the current market price if there is enough capacity for the instance type you require.\n\nHowever, your instance can be terminated by AWS at any time, with a 2 minutes termination notice. It makes it a perfect fit for short running workloads, with no strict SLA, such as CI jobs. In theory, Spot Instances can be terminated at any time. In practice, it really doesn’t happen so often.\n\nWe use Kops to manage our Kubernetes clusters on AWS. Within kops, we define multiple instance groups which map directly to autoscaling groups in EC2, one them targets Spot Instances. Kubernetes autoscaler handles the autoscaling process based on kubernetes resources requests. We only need to define, the min and max size of our instance group, and the max price we are willing to pay for a spot instance.\n\nspec:\n\nmachineType: m5.4xlarge\n\nmaxPrice: \"0.50\"\n\nmaxSize: 10\n\nminSize: 0\n\nThe most recent version of Kops handles this more gracefully, using mixedInstancePolicy where you can define multiple instance types, spot or on-demand, in a single instance group. This article describes this process in more detail.\n\nOnce our spot instances are up and running, the last thing we need to do is tell our gitlab runners and kaniko jobs to run on these instances. For gitlab, we configure both a node toleration and a node selector. Currently, gitlab-runner doesn’t support affinity.\n\n[runners.kubernetes.node_selector]\n\n\"kops.k8s.io/instancegroup\" = \"nodes_spot\"\n\n[runners.kubernetes.node_tolerations]\n\n\"dedicated=spot\" = \"NoSchedule\"\n\nFor Kaniko jobs, we use node toleration, but with node affinity this time\n\nspec:\n\ntolerations:\n\n- effect: NoSchedule\n\nkey: dedicated\n\noperator: Equal\n\nvalue: spot affinity:\n\nnodeAffinity:\n\nrequiredDuringSchedulingIgnoredDuringExecution:\n\nnodeSelectorTerms:\n\n- matchExpressions:\n\n- key: kops.k8s.io/instancegroup\n\noperator: In\n\nvalues:\n\n- nodes_spot"
    }
}