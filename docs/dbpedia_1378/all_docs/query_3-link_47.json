{
    "id": "dbpedia_1378_3",
    "rank": 47,
    "data": {
        "url": "https://automatingsociety.algorithmwatch.org/report2020/denmark/",
        "read_more_link": "",
        "language": "en",
        "title": "Automating Society Report 2020",
        "top_image": "https://automatingsociety.algorithmwatch.org/wp-content/uploads/2020/10/AS2-social-media-card-v1.png",
        "meta_img": "https://automatingsociety.algorithmwatch.org/wp-content/uploads/2020/10/AS2-social-media-card-v1.png",
        "images": [
            "https://automatingsociety.algorithmwatch.org/wp-content/themes/aw2020/gfx/aw-logo.svg",
            "https://automatingsociety.algorithmwatch.org/wp-content/themes/aw2020/gfx/sponsors/bertelsmannstiftung.svg",
            "https://automatingsociety.algorithmwatch.org/wp-content/uploads/2020/10/portr.1jpg.jpg",
            "https://automatingsociety.algorithmwatch.org/wp-content/uploads/2020/10/as2020_cover.jpg",
            "https://static.algorithmwatch.org/gfx/ccby.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Denmark has stated that it wishes to be a front-runner in digitalization (Denmark, 2018). As a result, since January 2018, all new legislation must be “ready to be digitised” (Finansministeriet, 2018), which implies the option of partially or fully automated decisions. Although Denmark is a small country with less than six million inhabitants, the fact […]",
        "meta_lang": "en",
        "meta_favicon": "/wp-content/themes/aw2020/gfx/favicon_32px.png",
        "meta_site_name": "Automating Society Report 2020",
        "canonical_link": "https://automatingsociety.algorithmwatch.org/report2020/denmark/",
        "text": "Research\n\nby Brigitte Alfter\n\nDenmark has stated that it wishes to be a front-runner in digitalization (Denmark, 2018). As a result, since January 2018, all new legislation must be “ready to be digitised” (Finansministeriet, 2018), which implies the option of partially or fully automated decisions. Although Denmark is a small country with less than six million inhabitants, the fact that digital solutions are already widespread means that this ambition does not appear to be completely unrealistic. Online solutions have long replaced annoying queues at car registration, tax, land registry offices, and other places, and today public administration is digital by default. It is true that, sometimes, cases surface about citizens who get into trouble – like a couple who did not register their baby’s name due to difficulties logging in to the birth registration system (Ritzau, 2019) – but, generally speaking, Denmark is well-positioned to become one of the world’s digital front-runners.\n\nWhen looking at Denmark, experts who work internationally point to the widespread public trust in institutions when compared to other countries. In Denmark, distrust against surveillance concepts are rare, data are widely available, including a unique individual identifier for every registered citizen in the form of a social security number in Det Centrale Personregister (The Central Person Registry, CPR). This unique identifier is required not only to register with the authorities but also for health care services, banks, insurance, education grants, work contracts, social security services, driving licenses, and so forth. These systems allow access to a wide variety of information on each individual, for that information to be analyzed, and – increasingly in some cases – used for profiling, predictions, or even for fully automated decisions.\n\nThe public discourse, particularly the critical discourse, on these developments appears to be limited to circles of specialists and elite media, except for very few cases about profiling or predictions – especially concerning children – or indeed, when it comes to platform business models (see for example Sorgenfri Kjær, 2018 or Bernsen, 2019-1).\n\nHowever, discourse does exist. Friction lines in such discussions go between a wish to digitalize swiftly based upon an intention to serve the citizens as well as to create growth – as suggested by the national strategies (Denmark 2016, Denmark 2018) – and on the other side, there is a wish to balance this with citizens’ rights as expressed by academics, civil society, and civil rights groups.\n\nDenmark is not alone in using automated predictions, assessments, and decisions. For example, major football clubs introduced face recognition systems to refuse entry to known troublemakers (Andersen 2020-3) in a similar way to developments in other countries. In this chapter, we focus on cases of profiling, decision support, and automated decisions in public administration.\n\nThe “Gladsaxe-model” was a profiling system based upon combinations of ‘risk indicators’ for the early detection of children in vulnerable families. The model started as a pilot project led by the municipality of Gladsaxe, on the outskirts of Copenhagen, along with two other municipalities. The model consisted of a points-based analytical system with parameters to estimate risk. These included such things as parental mental health (3000 points), unemployment (500 points), missed medical appointment (1000 points), missed dental appointment (300 points), and divorce (Sorgenfri Kjær, 2018). Although the overall purpose of the project was laudable, the way the task was carried out was heavily criticized and resulted in the model being put on hold. This meant that Gladsaxe and its partner municipalities were not allowed to roll out the system. However, in late 2018, the municipality stated that they had continued work on the algorithm, and had not only included data from the municipality itself but also statistical data on children who had already received special support as well as their families (Andersen, 2018). In 2019, after the data protection authorities denied permission, and critical coverage in the press, work stopped without any further explanation (Andersen, 2019). In 2020, a new research project at the University of Århus announced that it was developing “an algorithmic tool for decision support” to detect particularly vulnerable children (Andersen, 2020). This research project was also criticized for following the same line of thought as the Gladsaxe Model (Andersen, 2020-2).\n\nImagine you lose your job, and, for a while, you have to rely upon unemployment benefits. This system is a public insurance model that you contributed to while you were working. To claim your benefits, a profile of you is made to estimate how likely it is that you will end up in long-term unemployment. The profile is automatically generated, by a nationwide tool and based upon a combination of various data about you, such as your age, origin, unemployment history, previous jobs, education, and the cause of unemployment, including any health indications (Lovforslag L209, 2019. P. 212). This profile of a citizen’s likelihood to become long-term unemployed is used to assist the official dealing with the case. It is not an automated decision but a decision-supporting tool.\n\nIn May 2019, questions about this process became a full-fledged public discussion, when a new law was passed that included a passage allowing the minister of labor to develop guidelines for the use of “a digital clarification – and dialogue tool to be used by job centres and unemployment units” (Lov om aktiv beskæftigelsesindsats, 2019). The new tool was set to combine the newly unemployed person’s estimate of their working potential with other data that would then be matched against the characteristics of citizens who previously ended up in long-term unemployment. The tool would then flag those with a higher risk of long-term unemployment (Andersen, 2019-2).\n\nThe public discussion concerned both the content of the model and the process of how the law was passed without consulting the relevant public data protection authority, Datatilsynet. Exceptionally, Datatilsynet reopened its evaluation of the law, emphasizing that the ministry did not alert it to the automated tool in approximately 1000 pages of background material to the draft law (Datatilsynet, 2019). In August 2019, however, Datatilsynet concluded that the plans for automated profiling of the unemployed was compliant with the rules, but it also suggested that the tool should be re-evaluated to estimate whether the “mathematical model continued to be relevant” to ensure that the rights of those registered were respected “and to avoid unobjective discrimination” (Datatilsynet 2019-2).\n\nTwo political parties – both supporters of the current social democratic minority government – announced their objections against profiling and that they would push for evaluation and less profiling. The reason given was that citizens might feel uncomfortable and would be less trustful in sharing information with officials. Although the tool was planned to be used for decision supporting only, one of the opposition politicians was reluctant: “The reality in the employment system is that officials have far too many cases on their table. Hence a profiling tool easily can be what you turn to because it goes faster than a thorough talk,” Eva Flyvholm of Enhedslisten said to the Altinget news service. Flyvholm also argued for sufficient staffing at job centers (Kaasgaard, 2019).\n\nOne commercial solution, a so-called “assistant” by the name of “Asta”, is already available and offered by a specialized commercial company. In its advertising material, the company describes Asta as being “equipped with a toolbox containing loads of technological handles such as robot technology and artificial intelligence” and that Asta can be likened to the person peeling the potatoes for a tv-chef before a broadcast on cooking (Schultz, 2019). Asta is already used by the employment agency in Copenhagen and was described positively in the online magazine of KL, the association of Danish municipalities (Romme Andersen, 2019).\n\nUdbetaling Danmark (Payout Denmark, UDK) is a public authority responsible for payments such as study grants, child allowances, the minimum pension, maternity, and sick support for those unemployed, and many other payments under the welfare state system. Since 2012, this centralized agency has been responsible for payments previously handled and controlled by local municipalities. Today, UDK is not only responsible for payments but also for some control over the lawfulness of payments. Some payments are made automatically, for example, Statens Uddannelsesstøtte (the State Education Support or SU), which is based upon clear criteria, such as whether or not a citizen is accepted as a student at a university.\n\nCriticism, however, has surfaced about the control functions of UDK. A report published in July 2019 questioned the proportionality of the surveillance, which included the screening of “2,7 million non-unique beneficiaries” leading to only 705 cases in 2017 and 1094 cases in 2018 where the payments were stopped, adjusted, or paid back because of mistakes. In 2017, UDK handed 25 cases to the police for further investigation. (Eiriksson, 2019-3).\n\nThis criticism of the surveillance of large parts of the Danish population without actual suspicion is not new. The mindset of the limitless collection of personal data is exemplified in the comments on a case regarding the personal data of a representative of a beneficiary. The data of the representative, as well as close family, appear to have been collected. UDK said that it could not fulfill its legal obligations without collecting the data of the representatives of beneficiaries as well as the family members of such a representative. (Eiriksson, 2019-3, p. 17). What is new is a description of how the analysis of the controls is carried out. Data analysis is based upon a set of criteria that are being developed constantly, including “modular criteria” where data analysis is run on different questions, and all such sub-results are, then, included in the overall conclusion (Eiriksson, 2019-3, pp. 10-11).\n\nFor years, and with varying degrees of success, the Danish government has tried to centralize and automate tax administration. Attempts to centralize and automate tax collection in 2005 with EFI (Et Fælles Inddrivelsessystem or One Shared Tax collection system) failed, and EFI was shelved in 2015 (Alfter, 2019, 51). A new system, to collect billions of Danish crowns owed by taxpayers, was expected to be finalized by mid-2019, however, in September 2019, the Auditors of the Danish Parliament, Rigsrevision, published a critical report indicating that tax collection would only be fully up and running by the end of 2020, or later (Rigsrevisionen, 2019).\n\nMissing out on collecting billions of Danish crowns in tax revenue, however, is just one of several automatization concerns on the table of every new minister of finance. One heated discussion is about automatizing the estimation of property values – particularly in a context where housing costs are growing significantly in the capital and near larger cities while they are dropping elsewhere, thus affecting property owners in a country where large parts of the population own their own home.\n\nPassed in 2017, the Ejendomsvurderingslov (law on property assessment, 2017) states that automatic real estate valuation assessment will become standard practice. In preparation for the law, this fully automated system was described as “machine assessments” (Motzfeldt & Abkenar, 2019, p. 36-37). The system is set to include “sales prices related to the neighborhood, location and size. Sales price levels are adjusted to take into account the distance to forests and recreation areas, schools, streets, railways”. The system will also take into account whether or not there is the possibility to build on the surrounding terrain and whether or not ground pollution is an issue (Motzfeldt & Abkenar, 2019, p. 37). A total of 19 parameters will be used to automatically calculate property value (Version2 Editorial, 2019). A preparatory committee prepared an analysis to guide the government ahead of the legislation. The committee followed the overall line to move from “subjective to objective” assessments, from human to digital assessments, and from manual to automatic administration, to improve assessments and lower administration costs (Engbergudvalget, 2014, p. 68-69). While it does not explicitly mention it, this model uses a level of machine learning to develop a “statistical predictive model” (Motzfeldt & Abkenar, 2019, p. 37). Furthermore, the overall assumption of the preparatory committee was that machine assessments were more objective than human assessments, where human assessments are considered subjective.\n\nAs with many other systems, the automated property assessment system has been significantly delayed. Along the way, fears surfaced that it did not comply with Danish administrative law (Mølsted, 2018). It also proved to be more expensive than the estimate in the initial report regarding the cost of a property valuation calculated by a human (Motzfeldt, 2019-2). This project, and other problematic attempts by the Danish tax authorities to incorporate IT projects, have been described as “the ministers’ (…) IT-phantoms” (Version2 Editorial, 2019). The law to assess property values allows a variation of 40% in the value of a given property – 20% either side of the price calculated by the system – “and one does not need to hold a PhD in human behavior to predict that this will lead to protests if or when the system comes into use. Worst case we will see headlines that two newly built and identical houses will be taxed very differently. Could we blame citizens if they ask critical questions why they had to spend billions for a system with such a low level of precision” (Motzfeldt, 2019-2).\n\nYou try to control me, I outsmart you. This was the logic of a Danish high school student who, in a post on Github, described how to disable a digital exam monitor (Schou, 2019). The move was part of massive protests by the students against The Digital Exam Monitor, developed by the Danish Ministry of Education (Den Digitale Prøvevagt), and which was set to roll out in spring 2019. Following the protests against this surveillance, which included copies of the clipboard, active websites in four browsers, a key logger, a screen dump every minute, or whenever an active window changed, detection of virtual machines in the background, a list of all active programs, various unique IDs, etc.) (Møller Kjemtrup, 2019), the ministry of education put the tool on hold (Undervisningsministeriet, 2019). Yet under the new social democrat government, students continue to ask the authorities to shelve it entirely (Mejlgaard, 2019).\n\nMeanwhile, another tool that uses machine learning to detect exam fraud has been developed at Copenhagen University. This move stirred new controversies and fears about student profiling in 2019.\n\nIn 2014, high school software provider Macom supplied a tool called Lectio, which operated as an early detection system to trace students in danger of dropping out (Copenha- gen University, 2014). The tool was developed by university students and based upon information gathered through the administration and communication system used by 9 out of 10 Danish high schools, according to Macom and media reports. However, use of the algorithm was stopped about a week after it was introduced. The data used to develop it had been handed to a third party – the university and its master’s students – without permission from the high schools (Møllerhøj, 2015).\n\nMore recently, in May 2019, a group at the same department of Copenhagen University published a machine learning system by the name of Ghostwriter. The developers said that it could be used to trace the writing style of students in assignments and that it could detect with some certainty, whether or not a student had submitted a text written by someone else. The aim of Ghostwriter was to fight exam fraud, but (the university wrote in a press release) that the model could also be applied elsewhere to detect texts written in an unusual style (Copenhagen University, 2019).\n\nThe machine learning was based upon 130,000 student assignments held in the Lectio system by Macom. The ensuing controversy between the high schools, the university professor, and the director of Macom focused on a breach of contract related to the handling of the students’ data: “We feel unsafe when the data handling agreement is not respected,” a representative of the high schools stated to online technology news website Version2, (Bang Frederiksen, 2019-1; Bang Frederiksen, 2019-2; Bang Frederiksen, 2019-3).\n\nDenmark follows national digitalization strategies, and, at the moment, the 2016-2020 strategy is in action (Digitaliseringsstyrelsen, 2016). It is a strategy that, ever since 2001, builds upon previous years’ strategies (Motzfeldt, 2019 p. 20). An inherent part of this strategy requires Danish authorities at the state, regional, and local level to promise each other to push for digital solutions that are easy to use and further growth while maintaining security and trust in digital systems (Digitaliseringsstyrelsen, 2016-2). In October 2018, the center-right government introduced its digitalization policy under the title Digital service i verdensklasse (World Class Digital Service, Ministry of Finance, 2018). In 2019, this was followed, with an AI strategy “to serve all of Denmark” (Digitaliseringsstyrelsen, 2019). This strategy points out three focus areas for pilot projects, or so-called ‘signature projects’. These are health, social welfare, and labor (Motzfeldt, 2019-2, p. 35). These national-level strategies are accompanied by investment funds as well as information campaigns such as Digital Hub Denmark, which is a “public-private partnership between the Danish Government, the Confederation of Danish Industry, the Danish Chamber of Commerce and Finance Denmark” (Digital Hub Denmark, 2019).\n\nStrategies for digitalization are also being developed at the municipal level. In practice, social welfare and contact with citizens is normally handled by Denmark’s 98 local municipalities that have a certain level of autonomy, and are organized via Kommunernes Landsforening (National association of municipalities, KL). Municipalities are responsible for the care of the elderly, child care, primary schools, social welfare, and local infrastructure. KL has a four-year strategy 2016-2020 following the national agreement (KL, 2016).\n\nIn 2018, and on behalf of the 98 municipalities, KL asked the consultancy company, Dare Disrupt, to look into the potential of digitalization at the local level, particularly, when working with children, social welfare, the elderly, health, and other tasks, where municipalities directly serve citizens (Dare Disrupt, 2018; KL 2018).KL’s use of this particular consultancy group was criticized in both the specialized and the general media, as were some of the elements of the report by Dare Disrupt. In the report, Dare Disrupt emphasized the competences of the scandal-ridden British political consulting company, Cambridge Analytica, and suggested local municipalities should use similar methods for citizen involvement (KL, 2018, p. 108; Sorgenfri Kjær, 2018-2; Egedal, 2018).\n\nIt is worth mentioning that the report emphasized the opportunities of profiling and prediction. For example, it suggested that it would be possible to predict how children younger than six years old would succeed in life, “who would be successful, and who would become costly” (KL 2018, p. 54). Another scenario described how municipalities can “predict destructive behavior of the individual citizen through analysis of data in the infrastructure of the municipality even before the citizen can and definitely before the act is carried out (own abuse, abuse of others or violence…)?” (KL, 2016, p. 198).\n\nConfronted with ethical and privacy considerations, KL – who ordered the report – emphasized that the report was merely supposed to act as inspiration for possible opportunities while at the same time, KL did not address potential obstacles. Ethical considerations, a representative stated, were up to the individual municipalities themselves (Andersen, 2018-2).\n\nIn June 2019, a new government took power. It is a social-democratic minority government supported by two left-wing parties and one liberal party. The government agreement does not mention data, digitalization, automatization, or surveillance considerations explicitly – an absence that has been criticized by actors in the field. In one of its first legal packages in the field of justice, the government considered increasing camera surveillance by private and public actors (including the police), more license plate recognition systems (including longer storage of license plate data), more surveillance of gang members, and more police drones, among other actions (Justitsministeriet, 2019). The bill was tabled in February 2020 (Folketinget 2020).\n\nThe political discussion on the government’s legal package is ongoing, and the deputy chairperson of the largest opposition party, the center-right Venstre party, has brought some suggestions to the table. These include the introduction of face recognition technology in the so-called ghetto areas, labeled as such in a legal package (previously mentioned), which defines neighborhoods with rates of high unemployment, high criminality, and high numbers of immigrants. The deputy chairperson’s suggestions were commented on by a fellow Venstre party member who said that the suggestions were not official party policy (Ahrenkilde Holm, 2019).\n\nThe apparent enthusiasm to quickly digitize public administration does meet highly qualified criticism. Under the headline “Do grab the safety buoy”, in the journal for research into social work, Hanne Marie Motzfeldt, associate professor at the faculty of law at the University of Copenhagen, emphasized the need to respect good administrative practices and ethics when digitizing public administration functions. She argued that a decision by the Danish Ombudsperson – an authority in both the political and the legal contexts – should also be used in the field of digitalization to ensure a “qualified and correct basis for decisions” before implementing new tools for digital administration. “It is no longer enough to ask an external consultancy report recommending this or that” (Motzfeldt, 2019-2, p. 40).\n\nMotzfeldt has contributed significantly, not only to a qualified debate but also to the upgrading of legal competences in the field of digital administration – including various levels of automation. Most recently, she published a book targeted at lawyers working in the concept phase of new digital administration projects. In it, she suggests using clear terminology and raising awareness of the division of roles in teams preparing systems for digital administration (Motzfeldt, 2019).\n\nWhile Motzfeldt’s book is worth mentioning, it is focused on the law, legal professionals, and the use of digital tools from practical assistance up to fully automated decisions. How- ever, more popular books have been published which, more generally, address various questions related to digitalization in societies. For example, in “Digital totalitarianism”, the author – a PhD fellow of philosophy at the University of Copenhagen – takes a closer look at the much-criticized Chinese social scoring models. He argues that the surveillance and social scoring models are far more nuanced than depicted in Western media, and that very similar tools and mechanisms are applied at various levels – in both commercial and public systems – in Western countries (Vestergaard, 2019).\n\nIn April 2019, the government announced a new Data Ethics Council (Dataetisk Råd, 2019). The purpose of the council is to create a forum to address ethical questions, on the balance between the advantages of new technologies on the one side, and civil rights and liberties, as well as societal values, on the other. The council is explicitly tasked with creating a public debate and to constantly support “responsible and sustainable” use of data in both the business and the public sector. The members of the council are experts from public administration, universities, civil society, and business. The council began its work in the course of 2019.\n\nSeveral civil society and professional groups take an active part in discussions. In academia, specialists in various disciplines regularly contribute to the public debate and write books and guidance in fields such as law, civil liberties, public administration, among other areas.\n\nTwo private think-tanks focus on civil liberties (Justitia 2019) and data ethics (Dataethics.eu, 2019), respectively. Meanwhile, the Human Rights Institute, a government-supported research institute, also specializes in this field (Institut for Menneskrettigheder, 2019).\n\nMedia coverage of digitalization and automation appears sporadic. In 2019, a dedicated weekly radio program, Aflyttet, ended when the broadcaster that hosted it lost its financial support. However, a specialized online news website, called Version2, provides daily updates, focusing on tech in society and often includes critical voices. Version2 is published by Teknologiens Mediehus (Technology Publishing House), a private company owned by the trade union of Danish engineers and two pension funds. In addition, several online newsletters provide specialized information; however, this is hosted behind expensive paywalls and thus inaccessible to the wider public.\n\nDigitalization, including automated decisions, automated preparation of decisions, and profiling, is quickly gaining ground in Denmark. This development is likely to continue, and potentially even speed up, as the government’s current strategies and legislation follow the explicit purpose of paving the way for future digitalization.\n\nThe speedy development of digital solutions, rather than focusing on functioning solutions, appears to have happened in far too many instances. Critics emphasize that rapid development in several cases has been prioritized over respect for both good administrative practice and civil liberties, thus ultimately risking the population’s trust in digitalization.\n\nThis development, which has been pushed by previous center-right governments, and is also under discussion by the center-left government elected in 2019. A recent comment by the social democratic minister of finance – when he stated that there is no need to wait for the new Data Ethics Council to comment on a pool of 15 publicly-funded experimental cases on artificial intelligence in the Danish health system – indicates an eagerness in government to develop swiftly rather than prioritizing ethics (Fribo, 2019).\n\n“We need time to breath and to seriously think about which digital solutions it makes sense to invest in,” stated two senior personalities in the field in a recent oped arguing that speedy implementation alone is not valuable. They also suggested more careful, case-by-case, considerations if Danish public administrators do not want to sacrifice oversight for speed (Motzfeldt & Kjellerup Hansen, 2019)."
    }
}