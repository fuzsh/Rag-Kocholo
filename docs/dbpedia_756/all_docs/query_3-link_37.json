{
    "id": "dbpedia_756_3",
    "rank": 37,
    "data": {
        "url": "https://www.usenix.org/conference/usenixsecurity24/technical-sessions",
        "read_more_link": "",
        "language": "en",
        "title": "USENIX Security '24 Technical Sessions",
        "top_image": "https://www.usenix.org/sites/default/files/sec24_banner_social_share_1200x630.png",
        "meta_img": "https://www.usenix.org/sites/default/files/sec24_banner_social_share_1200x630.png",
        "images": [
            "https://www.usenix.org/sites/default/files/styles/neat_conference_menu_logo/public/sec24_wordmark_stacked_white_400x164.png?itok=iZ1avAhI",
            "https://www.usenix.org/modules/file/icons/application-pdf.png",
            "https://www.usenix.org/modules/file/icons/application-pdf.png",
            "https://www.usenix.org/sites/all/modules/usenix/usenix_files/images/usenix-locked.png",
            "https://www.usenix.org/modules/file/icons/application-pdf.png",
            "https://www.usenix.org/sites/default/files/styles/speaker_photo/public/brumley_david_200x230.jpg?itok=WfQ5AXP2",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Adam Doup",
            "Ruoyu Wang",
            "Yan Shoshitaishvili",
            "Aravind Machiry",
            "Liqiang Peng",
            "Jrg Schwenk",
            "Marten Oltrogge",
            "Thomas Johansson",
            "Simin Feng",
            "Yasemin Acar"
        ],
        "publish_date": "2024-06-26T18:42:42-07:00",
        "summary": "",
        "meta_description": "USENIX Security brings together researchers, practitioners, system programmers, and others to share and explore the latest advances in the security and privacy of computer systems and networks.",
        "meta_lang": "en",
        "meta_favicon": "https://www.usenix.org/sites/default/files/waves_favicon.ico",
        "meta_site_name": "USENIX",
        "canonical_link": "https://www.usenix.org/conference/usenixsecurity24/technical-sessions",
        "text": "Great ideas shouldn't remain confined to papers; they should transform the world. What does it take for our research to make a real-world impact? Are there guiding principles, and do they influence how we conduct fundamental research?\n\nIn this keynote, I will share my journey of understanding the principles that bridge the gap between fundamental research and the practical implementation of safer software and systems. Through real-world examples and case studies, I will discuss how I learned to replace \"it's more secure\" with compelling, actionable arguments. I will delve into adoption challenges that unveiled research gems and share candid moments when my academic hubris was dismantled by industry realities.\n\nThis journey has led me to identify four key principles that, I believe, are crucial for ensuring that innovative ideas transition successfully to the broader community and not get stuck as just a great research paper. Join me to explore these principles and how I believe they can help us all build a world with computers we trust.\n\nContent creators are exposed to elevated risks compared to the general Internet user. This study explores the threat landscape that creators in Pakistan are exposed to, how they protect themselves, and which support structures they rely on. We conducted a semi-structured interview study with 23 creators from diverse backgrounds who create content on various topics. Our data suggests that online threats frequently spill over into the offline world, especially for gender minorities. Creating content on sensitive topics like politics, religion, and human rights is associated with elevated risks. We find that defensive mechanisms and external support structures are non-existent, lacking, or inadequately adjusted to the sociocultural context of Pakistan.\n\nDisclaimer: This paper contains quotes describing harmful experiences relating to sexual and physical assault, eating disorders, and extreme threats of violence.\n\nAs many as 8 in 10 adults share intimate content such as nude or lewd images. Sharing such content has significant benefits for relationship intimacy and body image, and can offer employment. However, stigmatizing attitudes and a lack of technological mitigations put those sharing such content at risk of sexual violence. An estimated 1 in 3 people have been subjected to image-based sexual abuse (IBSA), a spectrum of violence that includes the nonconsensual distribution or threat of distribution of consensually-created intimate content (also called NDII). In this work, we conducted a rigorous empirical interview study of 52 European creators of intimate content to examine the threats they face and how they defend against them, situated in the context of their different use cases for intimate content sharing and their choice of technologies for storing and sharing such content. Synthesizing our results with the limited body of prior work on technological prevention of NDII, we offer concrete next steps for both platforms and security & privacy researchers to work toward safer intimate content sharing through proactive protection.\n\nContent Warning: This work discusses sexual violence, specifically, the harms of image-based sexual abuse (particularly in Sections 2 and 6).\n\nMachine learning has shown great promise in addressing several critical hardware security problems. In particular, researchers have developed novel graph neural network (GNN)-based techniques for detecting intellectual property (IP) piracy, detecting hardware Trojans (HTs), and reverse engineering circuits, to name a few. These techniques have demonstrated outstanding accuracy and have received much attention in the community. However, since these techniques are used for security applications, it is imperative to evaluate them thoroughly and ensure they are robust and do not compromise the security of integrated circuits.\n\nIn this work, we propose AttackGNN, the first red-team attack on GNN-based techniques in hardware security. To this end, we devise a novel reinforcement learning (RL) agent that generates adversarial examples, i.e., circuits, against the GNN-based techniques. We overcome three challenges related to effectiveness, scalability, and generality to devise a potent RL agent. We target five GNN-based techniques for four crucial classes of problems in hardware security: IP piracy, detecting/localizing HTs, reverse engineering, and hardware obfuscation. Through our approach, we craft circuits that fool all GNNs considered in this work. For instance, to evade IP piracy detection, we generate adversarial pirated circuits that fool the GNN-based defense into classifying our crafted circuits as not pirated. For attacking HT localization GNN, our attack generates HT-infested circuits that fool the defense on all tested circuits. We obtain a similar 100% success rate against GNNs for all classes of problems.\n\nLogic locking is a hardware-based solution that protects against hardware intellectual property (IP) piracy. With the advent of powerful machine learning (ML)-based attacks, in the last 5 years, researchers have developed several learning resilient locking techniques claiming superior security guarantees. However, these security guarantees are the result of evaluation against existing ML-based attacks having critical limitations, including (i) black-box operation, i.e., does not provide any explanations, (ii) are not practical, i.e., nonconsideration of approaches followed by the semiconductor industry, and (iii) are not broadly applicable, i.e., evaluate the security of a specific logic locking technique.\n\nIn this work, we question the security provided by learning resilient locking techniques by developing an attack (INSIGHT) using an explainable graph neural network (GNN). INSIGHT recovers the secret key without requiring scan-access, i.e., in an oracle-less setting for 7 unbroken learning resilient locking techniques, including 2 industry-adopted logic locking techniques. INSIGHT achieves an average key-prediction accuracy (KPA) of2.87,1.75,and1.67 higher than existing ML-based attacks. We demonstrate the efficacy of INSIGHT by evaluating locked designs ranging from widely used academic suites (ISCAS-85, ITC-99) to larger designs, such as MIPS, Google IBEX, and mor1kx processors. We perform 2 practical case studies: (i) recovering secret keys of locking techniques used in a widely used commercial EDA tool (Synopsys TestMAX) and (ii) showcasing the ramifications of leaking the secret key for an image processing application. We will open-source our artifacts to foster research on developing learning resilient locking techniques.\n\nIn this paper, we present ESauron  the first proof-of-concept system that can detect diverse forms of spy cameras (i.e., wireless, wired and offline devices) and quickly pinpoint their locations. The key observation is that, for all spy cameras, the captured raw images must be first digested (e.g., encoding and compression) in the video-capture devices before transferring to target receiver or storage medium. This digestion process takes place in an inbuilt read-write memory whose operations cause electromagnetic radiation (EMR). Specifically, the memory clock drives a variable number of switching voltage regulator activities depending on the workloads, causing fluctuating currents injected into memory units, thus emitting EMR signals at the clock frequency. Whenever the visual scene changes, bursts of video data processing (e.g., video encoding) suddenly aggravate the memory workload, bringing responsive EMR patterns. ESauron can detect spy cameras by intentionally stimulating scene changes and then sensing the surge of EMRs even from a considerable distance. We implemented a proof-of-concept prototype of the ESauron by carefully designing techniques to sense and differentiate memory EMRs, assert the existence of spy cameras, and pinpoint their locations. Experiments with 50 camera products show that ESauron can detect all spy cameras with an accuracy of 100% after only 4 stimuli, the detection range can exceed 20 meters even in the presence of blockages, and all spy cameras can be accurately located.\n\nHardware Trojans (HTs) pose a significant and growing threat to the field of hardware security. Several side-channel techniques, including power and electromagnetic radiation (EMR), have been proposed for HT detection, constrained by reliance on the golden chip or test vectors. In response, researchers advocate for the use of thermal radiation (TR) to identify HTs. However, existing TR-based methods are designed for the ideal HT that can fully occupy at least one pixel on the thermal radiation map (TRM). In reality, HTs may occupy multiple pixels, substantially diminishing occupancy in each pixel, thereby reducing the accuracy of existing detection methods. This challenge is exacerbated by the noise caused by the thermal camera. To this end, this paper introduces a countermeasure named noise based pixel occupation enhancement (NICE), aiming to improve the ability of TR-based HT detection. The key insight of NICE is that noise can vary the pixel occupation of HTs while disrupting HT detection. Consequently, the noise can be exploited to statistically find out the largest pixel occupation among the variations, thereby enhancing HT detection accuracy. Experimental results on a 0.13 m Digital Signal Processing (DSP) show that the detection rate of NICE exceeds the existing TR-based method by more than 47%, reaching 91.81%, while maintaining a false alarm rate of less than 9%. Both metrics of NICE are comparable to the existing power-based and EMR-based methods, eliminating the need for the golden chip and test vectors.\n\nCompartmentalization decomposes applications into isolated components, effectively confining the scope of potential security breaches. Recent approaches nest the protection monitor within processes for efficient memory isolation at the cost of security. However, these systems lack solutions for efficient multithreaded safety and neglect kernel semantics that can be abused to bypass the monitor.\n\nThe Endokernel is an intra-process security monitor that isolates memory at subprocess granularity. It ensures backwards-compatible and secure emulation of system interfaces, a task uniquely challenging due to the need to analyze OS and hardware semantics beyond mere interface usability. We introduce an inside-out methodology where we identify core OS primitives that allow bypass and map that back to the interfaces that depend on them. This approach led to the identification of several missing policies as well as aided in developing a fine-grained locking approach to deal with complex thread safety when inserting a monitor between the OS and the application. Results indicate that we can achieve fast isolation while greatly enhancing security and maintaining backwards-compatibility, and also showing a new method for systematically finding gaps in policies.\n\neBPF has become a critical component in Linux. To ensure kernel security, BPF programs are statically verified before being loaded and executed in the kernel. However, the state-of-the-art eBPF verifier has both security and complexity issues. To this end, we choose to look at BPF programs from a new perspective and regard them as a new type of kernel-mode application, thus an isolation-based rather than a verificationbased approach is needed. In this paper, we propose HIVE, an isolation execution environment for BPF programs on AArch64. To provide the equivalent security guarantees, we systematize the security aims of the eBPF verifier and categorize two types of pointers in eBPF: the inclusive type pointer that points to BPF objects and the exclusive type pointer that points to kernel objects. For the former, HIVE compartmentalizes all BPF memory from the kernel and de-privileges the memory accesses in the BPF programs by leveraging the load/store unprivileged instructions; for the latter, HIVE utilizes the pointer authentication feature to enforce access controls of kernel objects. Evaluation results show that HIVE is not only efficient but also supports complex BPF programs.\n\nDespite decades of mitigation efforts, SYN flooding attacks continue to increase in frequency and scale, and adaptive adversaries continue to evolve. Meanwhile, volumes of benign traffic in modern networks are also growing rampantly. As a result, network providers, which run thousands of servers and process 100s of Gbps of traffic, find themselves urgently requiring defenses that are secure against adaptive adversaries, scalable against large volumes of traffic, and highly performant for benign applications. Unfortunately, existing defenses local to a single device (e.g., purely software-based or hardware-based) are failing to keep up with growing attacks and struggle to provide performance, security, or both. In this paper, we present SmartCookie, the first system to run cryptographically secure SYN cookie checks on high-speed programmable switches, for both security and performance. Our novel split-proxy defense leverages emerging programmable switches to block 100% of SYN floods in the switch data plane and also uses state-of-the-art kernel technologies such as eBPF to enable scalability for serving benign traffic. SmartCookie defends against adaptive adversaries at two orders of magnitude greater attack traffic than traditional CPU-based software defenses, blocking attacks of 136.9 Mpps without packet loss. We also achieve 2x-6.5x lower end-to-end latency for benign traffic compared to existing switch-based hardware defenses.\n\nDenial-of-Service (DoS) attacks have long been a persistent threat to network infrastructures. Existing attack primitives require attackers to continuously send traffic, such as in SYN floods, amplification attacks, or application-layer DoS. In contrast, we study the threat of application-layer traffic loops, which are an almost cost-free attack primitive alternative. Such loops exist, e.g., if two servers consider messages sent to each other as malformed and respond with errors that again trigger error messages. Attackers can send a single IP-spoofed loop trigger packet to initiate an infinite loop among two servers. But despite the severity of traffic loops, to the best of our knowledge, they have never been studied in greater detail.\n\nIn this paper, we thus investigate the threat of application-layer traffic loops. To this end, we propose a systematic approach to identify loops among real servers. Our core idea is to learn the response functions of all servers of a given application-layer protocol, encode this knowledge into a loop graph, and finally, traverse the graph to spot looping server pairs. Using the proposed method, we examined traffic loops among servers running both popular (DNS, NTP, and TFTP) and legacy (Daytime, Time, Active Users, Chargen, QOTD, and Echo) UDP protocols and confirmed the prevalence of traffic loops. In total, we identified approximately 296k servers in IPv4 vulnerable to traffic loops, providing attackers the opportunity to abuse billions of loop pairs.\n\nRegular expressions (regexes) are a fundamental concept across the fields of computer science. However, they can also induce the Regular expression Denial of Service (ReDoS) attacks, which are a class of denial of service attacks, caused by super-linear worst-case matching time. Due to the severity and prevalence of ReDoS attacks, the detection of ReDoS-vulnerable regexes in software is thus vital. Although various ReDoS detection approaches have been proposed, these methods have focused mainly on backtracking regex engines, leaving the problem of ReDoS vulnerability detection on non-backtracking regex engines largely open.\n\nTo address the above challenges, in this paper, we first systematically analyze the major causes that could contribute to ReDoS vulnerabilities on non-backtracking regex engines. We then propose a novel type of ReDoS attack strings that builds on the concept of simple strings. Next we propose EvilStrGen, a tool for generating attack strings for ReDoS-vulnerable regexes on non-backtracking engines. It is based on a novel incremental determinisation algorithm with heuristic strategies to lazily find the k-simple strings without explicit construction of finite automata. We evaluate EvilStrGen against six state-of-the-art approaches on a broad range of publicly available datasets containing 736,535 unique regexes. The results illustrate the significant efficacy of our tool. We also apply our tool to 85 intensively-tested projects, and have identified 34 unrevealed ReDoS vulnerabilities.\n\nThe rise of mobile payment apps necessitates robust user authentication to ensure legitimate user access. Traditional methods, like passwords and biometrics, are vulnerable once a device is compromised. To overcome these limitations, modern solutions utilize sensor data to achieve user-agnostic and scalable behavioral authentication. However, existing solutions face two problems when deployed to real-world applications. First, it is not robust to noisy background activities. Second, it faces the risks of privacy leakage as it relies on centralized training with users' sensor data.\n\nIn this paper, we introduce FAMOS, a novel authentication framework based on federated multi-modal contrastive learning. The intuition of FAMOS is to fuse multi-modal sensor data and cluster the representation of one user's data by the action category so that we can eliminate the influence of background noise and guarantee the user's privacy. Furthermore, we incorporate FAMOS with federated learning to enhance performance while protecting users' privacy. We comprehensively evaluate FAMOS using real-world datasets and devices. Experimental results show that FAMOS is efficient and accurate for real-world deployment. FAMOS has an F1-Score of 0.91 and an AUC of 0.97, which are 42.19% and 27.63% higher than the baselines, respectively.\n\nFederated Learning (FL) trains a black-box and high-dimensional model among different clients by exchanging parameters instead of direct data sharing, which mitigates the privacy leak incurred by machine learning. However, FL still suffers from membership inference attacks (MIA) or data reconstruction attacks (DRA). In particular, an attacker can extract the information from local datasets by constructing DRA, which cannot be effectively throttled by existing techniques, e.g., Differential Privacy (DP).\n\nIn this paper, we aim to ensure a strong privacy guarantee for FL under DRA. We prove that econstruction errors under DRA are constrained by the information acquired by an attacker, which means that constraining the transmitted information can effectively throttle DRA. To quantify the information leakage incurred by FL, we establish a channel model, which depends on the upper bound of joint mutual information between the local dataset and multiple transmitted parameters. Moreover, the channel model indicates that the transmitted information can be constrained through data space operation, which can improve training efficiency and the model accuracy under constrained information. According to the channel model, we propose algorithms to constrain the information transmitted in a single round of local training. With a limited number of training rounds, the algorithms ensure that the total amount of transmitted information is limited. Furthermore, our channel model can be applied to various privacy-enhancing techniques (such as DP) to enhance privacy guarantees against DRA. Extensive experiments with real-world datasets validate the effectiveness of our methods.\n\nIn Federated Learning (FL), common privacy-enhancing techniques, such as secure aggregation and distributed differential privacy, rely on the critical assumption of an honest majority among participants to withstand various attacks. In practice, however, servers are not always trusted, and an adversarial server can strategically select compromised clients to create a dishonest majority, thereby undermining the system's security guarantees. In this paper, we present Lotto, an FL system that addresses this fundamental, yet underexplored issue by providing secure participant selection against an adversarial server. Lotto supports two selection algorithms: random and informed. To ensure random selection without a trusted server, Lotto enables each client to autonomously determine their participation using verifiable randomness. For informed selection, which is more vulnerable to manipulation, Lotto approximates the algorithm by employing random selection within a refined client pool. Our theoretical analysis shows that Lotto effectively aligns the proportion of server-selected compromised participants with the base rate of dishonest clients in the population. Large-scale experiments further reveal that Lotto achieves time-to-accuracy performance comparable to that of insecure selection methods, indicating a low computational overhead for secure selection.\n\nContrary to prevailing wisdom, we argue that the measure of binary decompiler success is not to eliminate all gotos or reduce the complexity of the decompiled code but to get as close as possible to the original source code. Many gotos exist in the original source code (the Linux kernel version 6.1 contains 3,754) and, therefore, should be preserved during decompilation, and only spurious gotos should be removed.\n\nFundamentally, decompilers insert spurious gotos in decompilation because structuring algorithms fail to recover C-style structures from binary code. Through a quantitative study, we find that the root cause of spurious gotos is compiler-induced optimizations that occur at all optimization levels (17% in non-optimized compilation). Therefore, we believe that to achieve high-quality decompilation, decompilers must be compiler-aware to mirror (and remove) the goto-inducing optimizations.\n\nIn this paper, we present a novel structuring algorithm called SAILR that mirrors the compilation pipeline of GCC and precisely inverts goto-inducing transformations. We build an open-source decompiler on angr (the angr decompiler) and implement SAILR as well as otherwise-unavailable prior work (Phoenix, DREAM, and rev.ng's Combing) and evaluate them, using a new metric of how close the decompiled code structure is to the original source code, showing that SAILR markedly improves on prior work. In addition, we find that SAILR performs well on binaries compiled with non-GCC compilers, which suggests that compilers similarly implement goto-inducing transformations.\n\nDecompilation is an important part of analyzing threats in computer security. Unfortunately, decompiled code contains less information than the corresponding original source code, which makes understanding it more difficult for the reverse engineers who manually perform threat analysis. Thus, the fidelity of decompiled code to the original source code matters, as it can influence reverse engineers' productivity. There is some existing work in predicting some of the missing information using statistical methods, but these focus largely on variable names and variable types. In this work, we more holistically evaluate decompiler output from C-language executables and use our findings to inform directions for future decompiler development. More specifically, we use open-coding techniques to identify defects in decompiled code beyond missing names and types. To ensure that our study is robust, we compare and evaluate four different decompilers. Using thematic analysis, we build a taxonomy of decompiler defects. Using this taxonomy to reason about classes of issues, we suggest specific approaches that can be used to mitigate fidelity issues in decompiled code.\n\nDecompilers, one of the widely used security tools, transform low-level binary programs back into their high-level source representations, such as C/C++. While state-of-the-art decompilers try to generate more human-readable outputs, for instance, by eliminating goto statements in their decompiled code, the correctness of a decompilation process is largely ignored due to the complexity of decompilers, e.g., involving hundreds of heuristic rules. As a result, outputs from decompilers are often not accurate, which affects the effectiveness of downstream security tasks.\n\nIn this paper, we propose D-HELIX, a generic decompiler testing framework that can automatically vet the decompilation correctness on the function level. D-HELIX uses RECOMPILER to compile the decompiled code at the functional level. It then uses SYMDIFF to compare the symbolic model of the original binary with the one of the decompiled code, detecting potential errors introduced by the decompilation process. D-HELIX further provides TUNER to help debug the incorrect decompilation via toggling decompilation heuristic rules automatically. We evaluated D-HELIX on Ghidra and angr using 2,004 binaries and object files ending up with 93K decompiled functions in total. D-HELIX detected 4,515 incorrectly decompiled functions, reproduced 8 known bugs, found 17 distinct previously unknown bugs within these two decompilers, and fixed 7 bugs automatically.\n\nConcolic execution is a powerful technique in software testing, as it can systematically explore the code paths and is capable of traversing complex branches. It combines concrete execution for environment modeling and symbolic execution for path exploration. While significant research efforts in concolic execution have been directed toward the improvement of symbolic execution and constraint solving, our study pivots toward the often overlooked yet most common aspect: concrete execution. Our analysis shows that state-of-the-art binary concolic executors have largely overlooked the overhead in the execution of concrete instructions. In light of this observation, we propose optimizations to make the common (concrete) case fast. To validate this idea, we develop the prototype, SymFit, and evaluate it on standard benchmarks and real-world applications. The results showed that the performance of pure concrete execution is much faster than the baseline SymQEMU, and is comparable to the vanilla QEMU. Moreover, we showed that the fast symbolic tracing capability of SymFit can significantly improve the efficiency of crash deduplication.\n\nThe Signal protocol and its X3DH key exchange core are regularly used by billions of people in applications like WhatsApp but are unfortunately not quantum-secure. Thus, designing an efficient and post-quantum secure X3DH alternative is paramount. Notably, X3DH supports asynchronicity, as parties can immediately derive keys after uploading them to a central server, and deniability, allowing parties to plausibly deny having completed key exchange. To satisfy these constraints, existing post-quantum X3DH proposals use ring signatures (or equivalently a form of designated-verifier signatures) to provide authentication without compromising deniability as regular signatures would. Existing ring signature schemes, however, have some drawbacks. Notably, they are not generally proven secure in the quantum random oracle model (QROM) and so the quantum security of parameters that are proposed is unclear and likely weaker than claimed. In addition, they are generally slower than standard primitives like KEMs.\n\nIn this work, we propose an efficient, deniable and post-quantum X3DH-like protocol that we call K-Waay, that does not rely on ring signatures. At its core, K-Waay uses a split-KEM, a primitive introduced by Brendel et al. [SAC 2020], to provide Diffie-Hellman-like implicit authentication and secrecy guarantees. Along the way, we revisit the formalism of Brendel et al. and identify that additional security properties are required to prove a split-KEM-based protocol secure. We instantiate split-KEM by building a protocol based on the Frodo key exchange protocol relying on the plain LWE assumption: our proofs might be of independent interest as we show it satisfies our novel unforgeability and deniability security notions. Finally, we complement our theoretical results by thoroughly benchmarking both K-Waay and existing X3DH protocols. Our results show even when using plain LWE and a conservative choice of parameters that K-Waay is significantly faster than previous work.\n\nVoice over Wi-Fi (VoWiFi) uses a series of IPsec tunnels to deliver IP-based telephony from the subscriber's phone (User Equipment, UE) into the Mobile Network Operator's (MNO) core network via an Internet-facing endpoint, the Evolved Packet Data Gateway (ePDG). IPsec tunnels are set up in phases. The first phase negotiates the cryptographic algorithm and parameters and performs a key exchange via the Internet Key Exchange protocol, while the second phase (protected by the above-established encryption) performs the authentication. An insecure key exchange would jeopardize the later stages and the data's security and confidentiality.\n\nIn this paper, we analyze the phase 1 settings and implementations as they are found in phones as well as in commercially deployed networks worldwide. On the UE side, we identified a recent 5G baseband chipset from a major manufacturer that allows for fallback to weak, unannounced modes and verified it experimentally. On the MNO side among others we identified 13 operators (totaling an estimated 140 million subscribers) on three continents that all use the same globally static set of ten private keys, serving them at random. Those not-so-private keys allow the decryption of the shared keys of every VoWiFi user of all those operators. All these operators deployed their core network from one common manufacturer.\n\nThe Signal Messenger recently introduced a new asynchronous key agreement protocol called PQXDH (PostQuantum Extended Diffie-Hellman) that seeks to provide post-quantum forward secrecy, in addition to the authentication and confidentiality guarantees already provided by the previous X3DH (Extended Diffie-Hellman) protocol. More precisely, PQXDH seeks to protect the confidentiality of messages against harvest-now-decrypt-later attacks.\n\nIn this work, we formally specify the PQXDH protocol and analyze its security using two formal verification tools, PROVERIF and CRYPTOVERIF. In particular, we ask whether PQXDH preserves the guarantees of X3DH, whether it provides post-quantum forward secrecy, and whether it can be securely deployed alongside X3DH. Our analysis identifies several flaws and potential vulnerabilities in the PQXDH specification, although these vulnerabilities are not exploitable in the Signal application, thanks to specific implementation choices which we describe in this paper. To prove the security of the current implementation, our analysis notably highlighted the need for an additional binding property of the KEM, which we formally define and prove for Kyber.\n\nWe collaborated with the protocol designers to develop an updated protocol specification based on our findings, where each change was formally verified and validated with a security proof. This work identifies some pitfalls that the community should be aware of when upgrading protocols to be post-quantum secure. It also demonstrates the utility of using formal verification hand-in-hand with protocol design.\n\nThe advent of quantum computers has sparked significant interest in post-quantum cryptographic schemes, as a replacement for currently used cryptographic primitives. In this context, lattice-based cryptography has emerged as the leading paradigm to build post-quantum cryptography. However, all existing viable replacements of the classical Diffie-Hellman key exchange require additional rounds of interactions, thus failing to achieve all the benefits of this protocol. Although earlier work has shown that lattice-based Non-Interactive Key Exchange (NIKE) is theoretically possible, it has been considered too inefficient for real-life applications. In this work, we challenge this folklore belief and provide the first evidence against it. We construct an efficient lattice-based NIKE whose security is based on the standard module learning with errors (M-LWE) problem in the quantum random oracle model. Our scheme is obtained in two steps: (i) A passively-secure construction that achieves a strong notion of correctness, coupled with (ii) a generic compiler that turns any such scheme into an actively-secure one. To substantiate our efficiency claim, we provide an optimised implementation of our passively-secure construction in Rust and Jasmin. Our implementation demonstrates the scheme's applicability to real-world scenarios, yielding public keys of approximately 220 KBs. Moreover, the computation of shared keys takes fewer than 12 million cycles on an Intel Skylake CPU, offering a post-quantum security level exceeding 120 bits.\n\nPhishing is a cybersecurity attack based on social engineering that incurs significant financial losses and erodes societal trust. While phishing detection techniques are emerging, attackers continually strive to bypass state-of-the-arts. Recent phishing campaigns have shown that emerging phishing attacks adopt CAPTCHA-based cloaking techniques, marking a new round of cat-and-mouse game. Our study shows that phishing websites, hardened by CAPTCHA-cloaking, can compromise all known state-of-the-art industrial and academic detectors with almost zero cost.\n\nIn this work, we develop PhishDecloaker, an AI-powered solution to soften the shield of the CAPTCHA-cloaking used by phishing websites. PhishDecloaker is designed to mimic human behaviors to solve the CAPTCHAs, allowing modern security-crawlers to see the uncloaked phishing content. Technically, PhishDecloaker orchestrates five deep computer vision models to detect the existence of CAPTCHAs, analyze its type, and solve the challenge in an interactive manner. We conduct extensive experiments to evaluate PhishDecloaker in terms of its effectiveness, efficiency, and robustness against potential adversaries. The results show that PhishDecloaker (1) recovers the phishing detection rate of many state-of-theart phishing detectors from 0% to up to on average 74.25% on diverse CAPTCHA-cloaked phishing websites (2) generalizes to unseen CAPTCHA (with precision of 86% and recall of 69%), and (3) is robust against various adversaries such as FGSM, JSMA, PGD, DeepFool, and DPatch, which allows the existing phishing detectors to achieve new state-of-the-art performance on CAPTCHA-cloaked phishing webpages. Our field study over 30 days shows that PhishDecloaker can help us uniquely discover 7.6% more phishing websites cloaked by CAPTCHAs, raising alarm of the emergence of CAPTCHA-cloaked features in the modern phishing campaigns.\n\nPhishing, a pervasive form of social engineering attack that compromises user credentials, has led to significant financial losses and undermined public trust. Modern phishing detection has gravitated to reference-based methods for their explainability and robustness against zero-day phishing attacks. These methods maintain and update predefined reference lists to specify domain-brand relationships, alarming phishing websites by the inconsistencies between their domain (e.g., payp0l.com) and intended brand (e.g., PayPal). However, the curated lists are largely limited by their lack of comprehensiveness and high maintenance costs in practice.\n\nIn this work, we present PhishLLM as a novel reference-based phishing detector that operates without an explicit pre-defined reference list. Our rationale lies in that modern LLMs have encoded far more extensive brand-domain information than any predefined list. Further, the detection of many webpage semantics such as credential-taking intention analysis is more like a linguistic problem, but they are processed as a vision problem now. Thus, we design PhishLLM to decode (or retrieve) the domain-brand relationships from LLM and effectively parse the credential-taking intention of a webpage, without the cost of maintaining and updating an explicit reference list. Moreover, to control the hallucination of LLMs, we introduce a search-engine-based validation mechanism to remove the misinformation. Our extensive experiments show that PhishLLM significantly outperforms state-of-the-art solutions such as Phishpedia and PhishIntention, improving the recall by 21% to 66%, at the cost of negligible precision. Our field studies show that PhishLLM discovers (1) 6 times more zero-day phishing webpages compared to existing approaches such as PhishIntention and (2) close to 2 times more zero-day phishing webpages even if it is enhanced by DynaPhish. Our code is available at https://github.com/code-philia/PhishLLM/.\n\nDigital wallets are a new form of payment technology that provides a secure and convenient way of making contactless payments through smart devices. In this paper, we study the security of financial transactions made through digital wallets, focusing on the authentication, authorization, and access control security functions. We find that the digital payment ecosystem supports the decentralized authority delegation which is susceptible to a number of attacks. First, an attacker adds the victim's bank card into their (attacker's) wallet by exploiting the authentication method agreement procedure between the wallet and the bank. Second, they exploit the unconditional trust between the wallet and the bank, and bypass the payment authorization. Third, they create a trap door through different payment types and violate the access control policy for the payments. The implications of these attacks are of a serious nature where the attacker can make purchases of arbitrary amounts by using the victim's bank card, despite these cards being locked and reported to the bank as stolen by the victim. We validate these findings in practice over major US banks (notably Chase, AMEX, Bank of America, and others) and three digital wallet apps (ApplePay, GPay, and PayPal). We have disclosed our findings to all the concerned parties. Finally, we propose remedies for fixing the design flaws to avoid these and other similar attacks.\n\nHoneywords are decoy passwords that can be added to a credential database; if a login attempt uses a honeyword, this indicates that the site's credential database has been leaked. In this paper we explore the basic requirements for honeywords to be effective, in a threat model where the attacker knows passwords for the same users at other sites. First, we show that for user-chosen (vs. algorithmically generated, i.e., by a password manager) passwords, existing honeyword-generation algorithms do not simultaneously achieve false-positive and false-negative rates near their ideals of 0 and  1/1+n, respectively, in this threat model, where n is the number of honeywords per account. Second, we show that for users leveraging algorithmically generated passwords, state-of-the-art methods for honeyword generation will produce honeywords that are not sufficiently deceptive, yielding many false negatives. Instead, we find that only a honeyword-generation algorithm that uses the same password generator as the user can provide deceptive honeywords in this case. However, when the defender's ability to infer the generator from the (one) account password is less accurate than the attacker's ability to infer the generator from potentially many, this deception can again wane. Taken together, our results provide a cautionary note for the state of honeyword research and pose new challenges to the field.\n\nSpectre v2 is one of the most severe transient execution vulnerabilities, as it allows an unprivileged attacker to lure a privileged (e.g., kernel) victim into speculatively jumping to a chosen gadget, which then leaks data back to the attacker. Spectre v2 is hard to eradicate. Even on last-generation Intel CPUs, security hinges on the unavailability of exploitable gadgets. Nonetheless, with (i) deployed mitigationseIBRS, no-eBPF, (Fine)IBTall aimed at hindering many usable gadgets, (ii) existing exploits relying on now-privileged features (eBPF), and (iii) recent Linux kernel gadget analysis studies reporting no exploitable gadgets, the common belief is that there is no residual attack surface of practical concern.\n\nIn this paper, we challenge this belief and uncover a significant residual attack surface for cross-privilege Spectre-v2 attacks. To this end, we present InSpectre Gadget, a new gadget analysis tool for in-depth inspection of Spectre gadgets. Unlike existing tools, ours performs generic constraint analysis and models knowledge of advanced exploitation techniques to accurately reason over gadget exploitability in an automated fashion. We show that our tool can not only uncover new (unconventionally) exploitable gadgets in the Linux kernel, but that those gadgets are sufficient to bypass all deployed Intel mitigations. As a demonstration, we present the first native Spectre-v2 exploit against the Linux kernel on last-generation Intel CPUs, based on the recent BHI variant and able to leak arbitrary kernel memory at 3.5 kB/sec. We also present a number of gadgets and exploitation techniques to bypass the recent FineIBT mitigation, along with a case study on a 13th Gen Intel CPU that can leak kernel memory at 18 bytes/sec.\n\nTransient execution attacks have been one of the widely explored microarchitectural side channels since the discovery of Spectre and Meltdown. However, much of the research has been driven by manual discovery of new transient paths through well-known speculative events. Although a few attempts exist in literature on automating transient leakage discovery, such tools focus on finding variants of known transient attacks and explore a small subset of instruction set. Further, they take a random fuzzing approach that does not scale as the complexity of search space increases. In this work, we identify that the search space of bad speculation is disjointedly fragmented into equivalence classes and then use this observation to develop a framework named Shesha, inspired by Particle Swarm Optimization, which exhibits faster convergence rates than state-of-the-art fuzzing techniques for automatic discovery of transient execution attacks. We then use Shesha to explore the vast search space of extensions to the x86 Instruction Set Architecture (ISAs), thereby focusing on previously unexplored avenues of bad speculation. As such, we report five previously unreported transient execution paths in Instruction Set Extensions (ISEs) on new generation of Intel processors. We then perform extensive reverse engineering of each of the transient execution paths and provide root-cause analysis. Using the discovered transient execution paths, we develop attack building blocks to exhibit exploitable transient windows. Finally, we demonstrate data leakage from Fused Multiply-Add instructions through SIMD buffer and extract victim data from various cryptographic implementations.\n\nThe Berkeley Packet Filter (BPF) has emerged as the de-facto standard for carrying out safe and performant, user-specified computation(s) in kernel space. However, BPF also increases the attack surface of the OS kernel disproportionately, especially under the presence of transient execution vulnerabilities. In this work, we present BeeBox: a new security architecture that hardens BPF against transient execution attacks, allowing the OS kernel to expose eBPF functionality to unprivileged users and applications. At a high level, BeeBox sandboxes the BPF runtime against speculative code execution in an SFI-like manner. Moreover, by using a combination of static analyses and domain-specific properties, BeeBox selectively elides enforcement checks, improving performance without sacrificing security. We implemented a prototype of BeeBox for the Linux kernel that supports popular features of eBPF (e.g., BPF maps and helper functions), and evaluated it both in terms of effectiveness and performance, demonstrating resilience against prevalent transient execution attacks (i.e., Spectre-PHT and Spectre-STL) with low overhead. On average, BeeBox incurs 20% overhead in the Katran benchmark, while the current mitigations of Linux incur 112% overhead. Lastly, BeeBox exhibits less than 1% throughput degradation in end-to-end, real-world settings that include seccomp-BPF and packet filtering.\n\nCache side-channel attacks based on speculative executions are powerful and difficult to mitigate. Existing hardware defense schemes often require additional hardware data structures, data movement operations and/or complex logical computations, resulting in excessive overhead of both processor performance and hardware resources. To this end, this paper proposes SpecLFB, which utilizes the microarchitecture component, Line-Fill-Buffer, integrated with a proposed mechanism for load security check to prevent the establishment of cache side channels in speculative executions. To ensure the correctness and immediacy of load security check, a structure called ROB unsafe mask is designed for SpecLFB to track instruction state. To further reduce processor performance overhead, SpecLFB narrows down the protection scope of unsafe speculative loads and determines the time at which they can be deprotected as early as possible. SpecLFB has been implemented in the open-source RISC-V core, SonicBOOM, as well as in Gem5. For the enhanced SonicBOOM, its register-transfer-level (RTL) code is generated, and an FPGA hardware prototype burned with the core and running a Linux-kernel-based operating system is developed. Based on the evaluations in terms of security guarantee, performance overhead, and hardware resource overhead through RTL simulation, FPGA prototype experiment, and Gem5 simulation, it shows that SpecLFB effectively defends against attacks. It leads to a hardware resource overhead of only 0.6% and the performance overhead of only 1.85% and 3.20% in the FPGA prototype experiment and Gem5 simulation, respectively.\n\nIntegration of third-party SDKs are essential in the development of mobile apps. However, the rise of in-app privacy threat against mobile SDKs called cross-library data harvesting (XLDH), targets social media/platform SDKs (called social SDKs) that handles rich user data. Given the widespread integration of social SDKs in mobile apps, XLDH presents a significant privacy risk, as well as raising pressing concerns regarding legal compliance for app developers, social media/platform stakeholders, and policymakers. The emerging XLDH threat, coupled with the increasing demand for privacy and compliance in line with societal expectations, introduces unique challenges that cannot be addressed by existing protection methods against privacy threats or malicious code on mobile platforms. In response to the XLDH threats, in our study, we generalize and define the concept of privacy-preserving social SDKs and their in-app usage, characterize fundamental challenges for combating the XLDH threat and ensuring privacy in design and utilizaiton of social SDKs. We introduce a practical, clean-slate design and end-to-end systems, called PESP, to facilitate privacy-preserving social SDKs. Our thorough evaluation demonstrates its satisfactory effectiveness, performance overhead and practicability for widespread adoption.\n\nUser interfaces (UIs) is the main channel for users to interact with mobile apps. As such, attackers often create similar-looking UIs to deceive users, causing various security problems, such as spoofing and phishing. Prior studies identify these similar UIs based on their layout trees or screenshot images. These techniques, however, are susceptible to being evaded. Guided by how users perceive UIs and the features they prioritize, we design a novel grid-based UI representation to capture UI visual appearance while maintaining robustness against evasion. We develop an approach, UIHash, to detect similar Android UIs by comparing their visual appearance. It divides the UI into a #-shaped grid and abstracts UI controls across screen regions, then calculates UI similarity through a neural network architecture that includes a convolutional neural network and a Siamese network. Our evaluation shows that UIHash achieves an F1-score of 0.984 in detection, outperforming existing tree-based methods and image-based methods. Moreover, we have discovered evasion techniques that circumvent existing detection approaches.\n\nBesides developers' code, current Android apps usually integrate code from third-party libraries, all of which may include code for TLS validation. We analyze well-known improper TLS certificate validation issues in popular Android apps, and attribute the validation issues to the offending code/party in a fine-grained manner, unlike existing work labelling an entire app for validation failures. Surprisingly, we discovered a widely used practice of overriding the global default validation functions with improper validation logic, or simply performing no validation at all, affecting the entire app's TLS connections, which we call validation hijacking. We design and implement an automated dynamic analysis tool called Marvin to identify TLS validation failures, including validation hijacking, and the responsible parties behind such dangerous practice. We use Marvin to analyze 6315 apps from a Chinese app store and Google Play, and find many occurrences of insecure TLS certificate validation instances (55.7% of the Chinese apps and 4.6% of the Google Play apps). Validation hijacking happens in 34.3% of the insecure apps from the Chinese app store and 20.0% of insecure Google Play apps. A network attacker can exploit these insecure connections in various ways, e.g., to compromise PII, app login and SSO credentials, to launch phishing and other content modification attacks, including code injection. We found that most of these vulnerabilities are related to third-party libraries used by the apps, not the app code created by app developers. The technical root cause enabling validation hijacking appears to be the specific modifications made by Google in the OkHttp library integrated with the Android OS, which is used by many developers by default, without being aware of its potential dangers. Overall, our findings provide valuable insights into the responsible parties for TLS validation issues in Android, including the validation hijacking problem.\n\nWeb crawlers are tools widely used in web security measurements whose performance and impact have been limitedly studied so far. In this paper, we bridge this gap. Starting from the past 12 years of the top security, web measurement, and software engineering literature, we categorize and decompose in building blocks crawling techniques and methodologic choices. We then reimplement and patch crawling techniques and integrate them into Arachnarium, a framework for comparative evaluations, which we use to run one of the most comprehensive experimental evaluations against nine real and two benchmark web applications and top 10K CrUX websites to assess the performance and adequacy of algorithms across three metrics (code, link, and JavaScript source coverage). Finally, we distill 14 insights and lessons learned. Our results show that despite a lack of clear and homogeneous descriptions hindering reimplementations, proposed and commonly used crawling algorithms offer a lower coverage than randomized ones, indicating room for improvement. Also, our results show a complex relationship between experiment parameters, the study's domain, and the available computing resources, where no single best-performing crawler configuration exists. We hope our results will guide future researchers when setting up their studies.\n\nWith the increasing popularity of APIs, ensuring their security has become a crucial concern. However, existing security testing methods for RESTful APIs usually lack targeted approaches to identify and detect security vulnerabilities. In this paper, we propose VOAPI2, a vulnerability-oriented API inspection framework designed to directly expose vulnerabilities in RESTful APIs, based on our observation that the type of vulnerability hidden in an API interface is strongly associated with its functionality. By leveraging this insight, we first track commonly used strings as keywords to identify APIs' functionality. Then, we generate a stateful and suitable request sequence to inspect the candidate API function within a targeted payload. Finally, we verify whether vulnerabilities exist or not through feedback-based testing. Our experiments on real-world APIs demonstrate the effectiveness of our approach, with significant improvements in vulnerability detection compared to state-of-the-art methods. VOAPI2 discovered 7 zero-day and 19 disclosed bugs on seven real-world RESTful APIs, and 23 of them have been assigned CVE IDs. Our findings highlight the importance of considering APIs' functionality when discovering their bugs, and our method provides a practical and efficient solution for securing RESTful APIs.\n\nClient-side security mechanisms implemented by Web browsers, such as cookie security attributes and the Mixed Content policy, are of paramount importance to protect Web applications. Unfortunately, the design and implementation of such mechanisms are complicated and error-prone, potentially exposing Web applications to security vulnerabilities. In this paper, we present a practical framework to formally and automatically detect security flaws in client-side security mechanisms. In particular, we leverage Web Platform Tests (WPT), a popular cross-browser test suite, to automatically collect browser execution traces and match them against Web invariants, i.e., intended security properties of Web mechanisms expressed in first-order logic. We demonstrate the effectiveness of our approach by validating 9 invariants against the WPT test suite, discovering violations with clear security implications in 104 tests for Firefox, Chromium and Safari. We disclosed the root causes of these violations to browser vendors and standard bodies, which resulted in 8 individual reports and one CVE on Safari.\n\nBrowser-based cross-platform applications have become increasingly popular as they allow software vendors to sidestep two major issues in the app ecosystem. First, web apps can be impacted by the performance deterioration affecting browsers, as the continuous adoption of diverse and complex features has led to bloating. Second, re-developing or porting apps to different operating systems and execution environments is a costly, error-prone process. Instead, frameworks like Electron allow the creation of standalone apps for different platforms using JavaScript code (e.g., reused from an existing web app) and by incorporating a stripped down and configurable browser engine. Despite the aforementioned advantages, these apps face significant security and privacy threats that are either non-applicable to traditional web apps (due to the lack of access to certain system-facing APIs) or ineffective against them (due to countermeasures already baked into browsers). In this paper we present Inspectron, an automated dynamic analysis framework that audits packaged Electron apps for potential security vulnerabilities stemming from developers' deviation from recommended security practices. Our study reveals a multitude of insecure practices and problematic trends in the Electron app ecosystem, highlighting the gap filled by Inspectron as it provides extensive and comprehensive auditing capabilities for developers and researchers.\n\nPhishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach. However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base. To address this issue, we propose an automated knowledge collection pipeline, using which we collect a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand. KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner. A second limitation of existing RBPDs is that they solely rely on the image modality, ignoring useful textual information present in the webpage HTML. To utilize this textual information, we propose a Large Language Model (LLM)-based approach to extract brand information of webpages from text. Our resulting multimodal phishing detection approach, KnowPhish Detector (KPD), can detect phishing webpages with or without logos. We evaluate KnowPhish and KPD on a manually validated dataset, and a field study under Singapore's local context, showing substantial improvements in effectiveness and efficiency compared to state-of-the-art baselines.\n\nRecently, ChatGPT has attracted great attention from the code analysis domain. Prior works show that ChatGPT has the capabilities of processing foundational code analysis tasks, such as abstract syntax tree generation, which indicates the potential of using ChatGPT to comprehend code syntax and static behaviors. However, it is unclear whether ChatGPT can complete more complicated real-world vulnerability management tasks, such as the prediction of security relevance and patch correctness, which require an all-encompassing understanding of various aspects, including code syntax, program semantics, and related manual comments.\n\nIn this paper, we explore ChatGPT's capabilities on 6 tasks involving the complete vulnerability management process with a large-scale dataset containing 70,346 samples. For each task, we compare ChatGPT against SOTA approaches, investigate the impact of different prompts, and explore the difficulties. The results suggest promising potential in leveraging ChatGPT to assist vulnerability management. One notable example is ChatGPT's proficiency in tasks like generating titles for software bug reports. Furthermore, our findings reveal the difficulties encountered by ChatGPT and shed light on promising future directions. For instance, directly providing random demonstration examples in the prompt cannot consistently guarantee good performance in vulnerability management. By contrast, leveraging ChatGPT in a self-heuristic wayextracting expertise from demonstration examples itself and integrating the extracted expertise in the prompt is a promising research direction. Besides, ChatGPT may misunderstand and misuse the information in the prompt. Consequently, effectively guiding ChatGPT to focus on helpful information rather than the irrelevant content is still an open problem.\n\nLarge language models (LLMs) have demonstrated significant potential in the realm of natural language understanding and programming code processing tasks. Their capacity to comprehend and generate human-like code has spurred research into harnessing LLMs for code analysis purposes. However, the existing body of literature falls short in delivering a systematic evaluation and assessment of LLMs' effectiveness in code analysis, particularly in the context of obfuscated code.\n\nThis paper seeks to bridge this gap by offering a comprehensive evaluation of LLMs' capabilities in performing code analysis tasks. Additionally, it presents real-world case studies that employ LLMs for code analysis. Our findings indicate that LLMs can indeed serve as valuable tools for automating code analysis, albeit with certain limitations. Through meticulous exploration, this research contributes to a deeper understanding of the potential and constraints associated with utilizing LLMs in code analysis, paving the way for enhanced applications in this critical domain.\n\nPenetration testing, a crucial industrial practice for ensuring system security, has traditionally resisted automation due to the extensive expertise required by human professionals. Large Language Models (LLMs) have shown significant advancements in various domains, and their emergent abilities suggest their potential to revolutionize industries. In this work, we establish a comprehensive benchmark using real-world penetration testing targets and further use it to explore the capabilities of LLMs in this domain. Our findings reveal that while LLMs demonstrate proficiency in specific sub-tasks within the penetration testing process, such as using testing tools, interpreting outputs, and proposing subsequent actions, they also encounter difficulties maintaining a whole context of the overall testing scenario.\n\nBased on these insights, we introduce PENTESTGPT, an LLM-empowered automated penetration testing framework that leverages the abundant domain knowledge inherent in LLMs. PENTESTGPT is meticulously designed with three self-interacting modules, each addressing individual sub-tasks of penetration testing, to mitigate the challenges related to context loss. Our evaluation shows that PENTESTGPT not only outperforms LLMs with a task-completion increase of 228.6% compared to the GPT-3.5 model among the benchmark targets, but also proves effective in tackling real-world penetration testing targets and CTF challenges. Having been open-sourced on GitHub, PENTESTGPT has garnered over 6,500 stars in 12 months and fostered active community engagement, attesting to its value and impact in both the academic and industrial spheres.\n\nJust-In-Time (JIT) compiler is a core component of JavaScript engines, which takes a snippet of JavaScript code as input and applies a series of optimization passes on it and then transforms it to machine code. The optimization passes often have some assumptions (e.g., variable types) on the target JavaScript code, and therefore will yield vulnerabilities if the assumptions do not hold. To discover such bugs, it is essential to thoroughly test different optimization passes, but previous work fails to do so and mainly focused on exploring code coverage. In this paper, we present the first optimization path guided fuzzing solution for JavaScript JIT compilers, namely OptFuzz, which focuses on exploring optimization path coverage. Specifically, we utilize an optimization trunk path metric to approximate the optimization path coverage, and use it as a feedback to guide seed preservation and seed scheduling of the fuzzing process. We have implemented a prototype of OptFuzz and evaluated it on 4 mainstream JavaScript engines. On earlier versions of JavaScript engines, OptFuzz found several times more bugs than baseline solutions. On the latest JavaScript engines, OptFuzz discovered 36 unknown bugs, while baseline solutions found none.\n\nBusyBox, an open-source software bundling over 300 essential Linux commands into a single executable, is ubiquitous in Linux-based embedded devices. Vulnerabilities in BusyBox can have far-reaching consequences, affecting a wide array of devices. This research, driven by the extensive use of BusyBox, delved into its analysis. The study revealed the prevalence of older BusyBox versions in real-world embedded products, prompting us to conduct fuzz testing on BusyBox. Fuzzing, a pivotal software testing method, aims to induce crashes that are subsequently scrutinized to uncover vulnerabilities. Within this study, we introduce two techniques to fortify software testing. The first technique enhances fuzzing by leveraging Large Language Models (LLM) to generate target-specific initial seeds. Our study showed a substantial increase in crashes when using LLM-generated initial seeds, highlighting the potential of LLM to efficiently tackle the typically labor-intensive task of generating target-specific initial seeds. The second technique involves repurposing previously acquired crash data from similar fuzzed targets before initiating fuzzing on a new target. This approach streamlines the time-consuming fuzz testing process by providing crash data directly to the new target before commencing fuzzing. We successfully identified crashes in the latest BusyBox target without conducting traditional fuzzing, emphasizing the effectiveness of LLM and crash reuse techniques in enhancing software testing and improving vulnerability detection in embedded systems. Additionally, manual triaging was performed to identify the nature of crashes in the latest BusyBox.\n\nDatabase Management Systems play an indispensable role in modern cyberspace. While multiple fuzzing frameworks have been proposed in recent years to test relational (SQL) DBMSs to improve their security, non-relational (NoSQL) DBMSs have yet to experience the same scrutiny and lack an effective testing solution in general. In this work, we identify three limitations of existing approaches when extended to fuzz the DBMSs effectively in general: being non-generic, using static constraints, and generating loose data dependencies. Then, we propose effective solutions to address these limitations. We implement our solutions into an end-to-end fuzzing framework, BUZZBEE, which can effectively fuzz both relational and non-relational DBMSs. BUZZBEE successfully discovered 40 vulnerabilities in eight DBMSs of four different data models, of which 25 have been fixed with 4 new CVEs assigned. In our evaluation, BUZZBEE outperforms state-of-the-art generic fuzzers by up to 177% in terms of code coverage and discovers 30x more bugs than the second-best fuzzer for non-relational DBMSs, while achieving comparable results with specialized SQL fuzzers for the relational counterpart.\n\nThe security guarantees of cloud computing depend on the isolation guarantees of the underlying hypervisors. Prior works have presented effective methods for automatically identifying vulnerabilities in hypervisors. However, these approaches are limited in scope. For instance, their implementation is typically hypervisor-specific and limited by requirements for detailed grammars, access to source-code, and assumptions about hypervisor behaviors. In practice, complex closed-source and recent open-source hypervisors are often not suitable for off-the-shelf fuzzing techniques.\n\nHYPERPILL introduces a generic approach for fuzzing arbitrary hypervisors. HYPERPILL leverages the insight that although hypervisor implementations are diverse, all hypervisors rely on the identical underlying hardware-virtualization interface to manage virtual-machines. To take advantage of the hardware-virtualization interface, HYPERPILL makes a snapshot of the hypervisor, inspects the snapshotted hardware state to enumerate the hypervisor's input-spaces, and leverages feedback-guided snapshot-fuzzing within an emulated environment to identify vulnerabilities in arbitrary hypervisors. In our evaluation, we found that beyond being the first hypervisor-fuzzer capable of identifying vulnerabilities in arbitrary hypervisors across all major attack-surfaces (i.e., PIO/MMIO/Hypercalls/DMA), HYPERPILL also outperforms state-of-the-art approaches that rely on access to source-code, due to the granularity of feedback provided by HYPERPILL's emulation-based approach. In terms of coverage, HYPERPILL outperformed past fuzzers for 10/12 QEMU devices, without the API hooking or source-code instrumentation techniques required by prior works. HYPERPILL identified 26 new bugs in recent versions of QEMU, Hyper-V, and macOS Virtualization Framework across four device-categories\n\nDifferential privacy (DP) via output perturbation has been a de facto standard for releasing query or computation results on sensitive data. Different variants of the classic Gaussian mechanism have been developed to reduce the magnitude of the noise and improve the utility of sanitized query results. However, we identify that all existing Gaussian mechanisms suffer from the curse of full-rank covariance matrices, and hence the expected accuracy losses of these mechanisms equal the trace of the covariance matrix of the noise. Particularly, for query results with multiple entries, in order to achieve DP, the expected accuracy loss of the classic Gaussian mechanism, that of the analytic Gaussian mechanism, and that of the Matrix-Variate Gaussian (MVG) mechanism are lower bounded by terms that scales linearly with the number of entries.\n\nTo lift this curse, we design a Rank-1 Singular Multivariate Gaussian (R1SMG) mechanism. It achieves DP on high dimension query results by perturbing the results with noise following a singular multivariate Gaussian distribution, whose covariance matrix is a randomly generated rank-1 positive semi-definite matrix. In contrast, the classic Gaussian mechanism and its variants all consider deterministic full-rank covariance matrices. Our idea is motivated by a clue from Dwork et al.'s seminal work on the classic Gaussian mechanism that has been ignored in the literature: when projecting multivariate Gaussian noise with a full-rank covariance matrix onto a set of orthonormal basis, only the coefficient of a single basis can contribute to the privacy guarantee.\n\nThis paper makes the following technical contributions.\n\n(i) The R1SMG mechanisms achieves DP guarantee on high dimension query results in, while its expected accuracy loss is lower bounded by a term that is on a lower order of magnitude by at least the dimension of query results compared with that of the classic Gaussian mechanism, of the analytic Gaussian mechanism, and of the MVG mechanism.\n\n(ii) Compared with other mechanisms, the R1SMG mechanism is more stable and less likely to generate noise with large magnitude that overwhelms the query results, because the kurtosis and skewness of the nondeterministic accuracy loss introduced by this mechanism is larger than that introduced by other mechanisms.\n\nExisting local differential privacy (LDP) techniques enable untrustworthy aggregators to perform only very simple data mining tasks on distributed private data, including statistical estimation and frequent item mining. There is currently no general LDP method that discovers relations between items. The main challenge lies in the curse of dimensionality, as the quantity of values to be estimated in mining relations is the square of the quantity of values to be estimated in mining item-level knowledge, leading to a considerable decrease in the final estimation accuracy. We propose LDP-RM, the first relation mining method under LDP. It represents items and relations in a matrix and utilizes singular value decomposition and low rank approximation to reduce the number of values to estimate from O(k2) to O(r), where k is the number of all considered items, and r < k is a parameter determined by the aggregator, signifying the rank of the approximation. LDP-RM serves as a fundamental privacy-preserving method for enabling various complex data mining tasks.\n\nDifferentially private stochastic gradient descent (DP-SGD) is the canonical approach to private deep learning. While the current privacy analysis of DP-SGD is known to be tight in some settings, several empirical results suggest that models trained on common benchmark datasets leak significantly less privacy for many datapoints. Yet, despite past attempts, a rigorous explanation for why this is the case has not been reached. Is it because there exist tighter privacy upper bounds when restricted to these dataset settings, or are our attacks not strong enough for certain datapoints? In this paper, we provide the first per-instance (i.e., \"data-dependent\") DP analysis of DP-SGD. Our analysis captures the intuition that points with similar neighbors in the dataset enjoy better data-dependent privacy than outliers. Formally, this is done by modifying the per-step privacy analysis of DP-SGD to introduce a dependence on the distribution of model updates computed from a training dataset. We further develop a new composition theorem to effectively use this new per-step analysis to reason about an entire training run. Put all together, our evaluation shows that this novel DP-SGD analysis allows us to now formally show that DP-SGD leaks significantly less privacy for many datapoints (when trained on common benchmarks) than the current data-independent guarantee. This implies privacy attacks will necessarily fail against many datapoints if the adversary does not have sufficient control over the possible training datasets.\n\nRecent developments have underscored the critical role of differential privacy (DP) in safeguarding individual data for training machine learning models. However, integrating DP oftentimes incurs significant model performance degradation due to the perturbation introduced into the training process, presenting a formidable challenge in the differentially private machine learning (DPML) field. To this end, several mitigative efforts have been proposed, typically revolving around formulating new DPML algorithms or relaxing DP definitions to harmonize with distinct contexts. In spite of these initiatives, the diminishment induced by DP on models, particularly large-scale models, remains substantial and thus, necessitates an innovative solution that adeptly circumnavigates the consequential impairment of model utility.\n\nIn response, we introduce DPAdapter, a pioneering technique designed to amplify the model performance of DPML algorithms by enhancing parameter robustness. The fundamental intuition behind this strategy is that models with robust parameters are inherently more resistant to the noise introduced by DP, thereby retaining better performance despite the perturbations. DPAdapter modifies and enhances the sharpness-aware minimization (SAM) technique, utilizing a two-batch strategy to provide a more accurate perturbation estimate and an efficient gradient descent, thereby improving parameter robustness against noise. Notably, DPAdapter can act as a plug-and-play component and be combined with existing DPML algorithms to further improve their performance. Our experiments show that DPAdapter vastly enhances state-of-the-art DPML algorithms, increasing average accuracy from 72.92% to 77.09% with a privacy budget of  = 4.\n\nArtificial Intelligence (AI) techniques have advanced to generate face images of nonexistent yet photorealistic persons. Despite positive applications, AI-synthesized faces have been increasingly abused to deceive users and manipulate opinions, such as AI-generated profile photos for fake accounts. Deception using generated realistic-appearing images raises severe trust and security concerns. So far, techniques to analyze and recognize AI-synthesized face images are limited, mainly relying on off-the-shelf classification methods or heuristics of researchers' individual perceptions.\n\nAs a complement to existing analysis techniques, we develop a novel approach that leverages crowdsourcing annotations to analyze and defend against AI-synthesized face images. We aggregate and characterize AI-synthesis artifacts annotated by multiple users (instead of by individual researchers or automated systems). Our quantitative findings systematically identify where the synthesis artifacts are likely to be located and what characteristics the synthesis patterns have. We further incorporate user annotated regions into an attention learning approach to detect AI-synthesized faces. Our work sheds light on involving human factors to enhance defense against AI-synthesized face images.\n\nDeepfake media represents an important and growing threat not only to computing systems but to society at large. Datasets of image, video, and voice deepfakes are being created to assist researchers in building strong defenses against these emerging threats. However, despite the growing number of datasets and the relative diversity of their samples, little guidance exists to help researchers select datasets and then meaningfully contrast their results against prior efforts. To assist in this process, this paper presents the first systematization of deepfake media. Using traditional anomaly detection datasets as a baseline, we characterize the metrics, generation techniques, and class distributions of existing datasets. Through this process, we discover significant problems impacting the comparability of systems using these datasets, including unaccounted-for heavy class imbalance and reliance upon limited metrics. These observations have a potentially profound impact should such systems be transitioned to practice - as an example, we demonstrate that the widely-viewed best detector applied to a typical call center scenario would result in only 1 out of 333 flagged results being a true positive. To improve reproducibility and future comparisons, we provide a template for reporting results in this space and advocate for the release of model score files such that a wider range of statistics can easily be found and/or calculated. Through this, and our recommendations for improving dataset construction, we provide important steps to move this community forward.\n\nWe present Foice, a novel deepfake attack against voice authentication systems. Foice generates a synthetic voice of the victim from just a single image of the victim's face, without requiring any voice sample. This synthetic voice is realistic enough to fool commercial authentication systems. Since face images are generally easier to obtain than voice samples, Foice effectively makes it easier for an attacker to mount large-scale attacks. The key idea lies in learning the partial correlation between face and voice features and adding to that a face-independent voice feature sampled from a Gaussian distribution. We demonstrate the effectiveness of Foice with a comprehensive set of real-world experiments involving ten offline participants and an online dataset of 1029 unique individuals. By evaluating eight state-of-the-art systems, including WeChat's Voiceprint and Microsoft Azure, we show that all these systems are vulnerable to Foice attack.\n\nUtilizing sensitive images (e.g., human faces) for training DL models raises privacy concerns. One straightforward solution is to replace the private images with synthetic ones generated by deep generative models. Among all image synthesis methods, diffusion models (DMs) yield impressive performance. Unfortunately, recent studies have revealed that DMs incur privacy challenges due to the memorization of the training instances. To preserve the existence of a single private sample of DMs, many works have explored to apply DP on DMs from different perspectives. However, existing works on differentially private DMs only consider DMs as regular deep models, such that they inject unnecessary DP noise in addition to the forward process noise in DMs, damaging the model utility. To address the issue, this paper proposes Differentially Private Diffusion Probabilistic Models for Image Synthesis, dp-promise, which theoretically guarantees approximate DP by leveraging the DM noise during the forward process. Extensive experiments demonstrate that, given the same privacy budget, dp-promise outperforms the state-of-the-art on the image quality of differentially private image synthesis across the standard metrics and datasets.\n\nIOMMU has been introduced to thwart DMA attacks. However, the performance degradation prevents it from being enabled on most systems. Even worse, recent studies show that IOMMU is still vulnerable to sub-page and deferred invalidation attacks, posing threats to systems with IOMMU enabled.\n\nThis paper aims to provide a lightweight and secure solution to defend against DMA attacks. Based on our measurement and characterizing of DMA behavior, we propose DMAAUTH, a lightweight pointer integrity-based hardware-software co-design architecture. DMAAUTH utilizes a novel technique named Arithmetic-capable Pointer AuthentiCation (APAC), which protects the DMA pointer integrity while supporting pointer arithmetic. It also places a dedicated hardware named Authenticator on the bus to authenticate all the DMA transactions. Combining APAC, per-mapping metadata, and the Authenticator, DMAAUTH achieves strict byte-grained spatial protection and temporal protection.\n\nWe implement DMAAUTH on a real FPGA hardware board. Specifically, we first realize a PCIe-customizable SoC on real FPGA, based on which we implement hardware version DMAAUTH and conduct a thorough evaluation. We also implement DMAAUTH on both ARM and RISC-V emulators to demonstrate its cross-architecture capability. Our evaluation shows that DMAAUTH is faster and safer than IOMMU while being transparent to devices, drivers, and IOMMU.\n\nA large body of work has demonstrated attacks that rely on the difference between CPUs' nominal instruction set architectures and their actual (microarchitectural) implementations. Most of these attacks, like Spectre, bypass the CPU's data-protection boundaries. A recent line of work considers a different primitive, called a microarchitectural weird machine (WM), that can execute computations almost entirely using microarchitectural side effects. While WMs would seem to be an extremely powerful tool, e.g., for obfuscating malware, thus far they have seen very limited application. This is because prior WMs must be hand-crafted by experts, and even then have trouble reliably executing complex computations.\n\nIn this work, we show that WMs are a practical, near-term threat. First, we design a new WM architecture, Flexo, that improves performance by 12 orders of magnitude and reduces circuit size by 7587%, dramatically improving the applicability of WMs to complex computation. Second, we build the first compiler from a high-level language to WMs, letting experts craft automatic optimizations and non-experts construct state-of-the-art obfuscated computations. Finally, we demonstrate the practicality of our approach by extending the popular UPX packer to encrypt its payload and use a WM for decryption, frustrating malware analysis.\n\nMicroarchitectural side-channel attacks have shaken the foundations of modern processor design. The cornerstone defense against these attacks has been to ensure that security-critical programs do not use secret-dependent data as addresses. Put simply: do not pass secrets as addresses to, e.g., data memory instructions. Yet, the discovery of data memory-dependent prefetchers (DMPs)which turn program data into addresses directly from within the memory systemcalls into question whether this approach will continue to remain secure.\n\nThis paper shows that the security threat from DMPs is significantly worse than previously thought and demonstrates the first end-to-end attacks on security-critical software using the Apple m-series DMP. Undergirding our attacks is a new understanding of how DMPs behave which shows, among other things, that the Apple DMP will activate on behalf of any victim program and attempt to \"leak\" any cached data that resembles a pointer. From this understanding, we design a new type of chosen-input attack that uses the DMP to perform end-to-end key extraction on popular constant-time implementations of classical (OpenSSL Diffie-Hellman Key Exchange, Go RSA decryption) and post-quantum cryptography (CRYSTALS-Kyber and CRYSTALS-Dilithium).\n\nAMD SEV is a trusted-execution environment (TEE), providing confidentiality and integrity for virtual machines (VMs). With AMD SEV, it is possible to securely run VMs on an untrusted hypervisor. While previous attacks demonstrated architectural shortcomings of earlier SEV versions, AMD claims that SEV-SNP prevents all attacks on the integrity.\n\nIn this paper, we introduce CacheWarp, a new software-based fault attack on AMD SEV-ES and SEV-SNP, exploiting the possibility to architecturally revert modified cache lines of guest VMs to their previous (stale) state. Unlike previous attacks on the integrity, CacheWarp is not mitigated on the newest SEV-SNP implementation, and it does not rely on specifics of the guest VM. CacheWarp only has to interrupt the VM at an attacker-chosen point to invalidate modified cache lines without them being written back to memory. Consequently, the VM continues with architecturally stale data. In 3 case studies, we demonstrate an attack on RSA in the Intel IPP crypto library, recovering the entire private key, logging into an OpenSSH server without authentication, and escalating privileges to root via the sudo binary. While we implement a software-based mitigation proof-of-concept, we argue that mitigations are difficult, as the root cause is in the hardware.\n\nThe Linux kernel extensively uses the Berkeley Packet Filter (BPF) to allow user-written BPF applications to execute in the kernel space. The BPF employs a verifier to check the security of user-supplied BPF code statically. Recent attacks show that BPF programs can evade security checks and gain unauthorized access to kernel memory, indicating that the verification process is not flawless. In this paper, we present MOAT, a system that isolates potentially malicious BPF programs using Intel Memory Protection Keys (MPK). Enforcing BPF program isolation with MPK is not straightforward; MOAT is designed to alleviate technical obstacles, such as limited hardware keys and the need to protect a wide variety of BPF helper functions. We implement MOAT on Linux (ver. 6.1.38), and our evaluation shows that MOAT delivers low-cost isolation of BPF programs under mainstream use cases, such as isolating a BPF packet filter with only 3% throughput loss.\n\nIn recent years, heap-based exploitation has become the most dominant attack against the Linux kernel. Securing the kernel heap is of vital importance for kernel protection. Though the Linux kernel allocator has some security designs in place to counter exploitation, our analytical experiments reveal that they can barely provide the expected results. This shortfall is rooted in the current strategy of designing secure kernel allocators which insists on protecting every object all the time. Such strategy inherently conflicts with the kernel nature. To this end, we advocate for rethinking the design of secure kernel allocator. In this work, we explore a new strategy which centers around the \"atomic alleviation\" concept, featuring flexibility and efficiency in design and deployment. Recent advancements in kernel design and research outcomes on exploitation techniques enable us to prototype this strategy in a tool named SeaK. We used real-world cases to thoroughly evaluate SeaK. The results validate that SeaK substantially strengthens heap security, outperforming all existing features, without incurring noticeable performance and memory cost. Besides, SeaK shows excellent scalability and stability in the production scenario.\n\nRecently, a novel method known as Page Spray emerges, focusing on page-level exploitation for kernel vulnerabilities. Despite the advantages it offers in terms of exploitability, stability, and compatibility, comprehensive research on Page Spray remains scarce. Questions regarding its root causes, exploitation model, comparative benefits over other exploitation techniques, and possible mitigation strategies have largely remained unanswered. In this paper, we conduct a systematic investigation into Page Spray, providing an in-depth understanding of this exploitation technique. We introduce a comprehensive exploit model termed the DirtyPage model, elucidating its fundamental principles. Additionally, we conduct a thorough analysis of the root causes underlying Page Spray occurrences within the Linux Kernel. We design an analyzer based on the Page Spray analysis model to identify Page Spray callsites. Subsequently, we evaluate the stability, exploitability, and compatibility of Page Spray through meticulously designed experiments. Finally, we propose mitigation principles for addressing Page Spray and introduce our own lightweight mitigation approach. This research aims to assist security researchers and developers in gaining insights into Page Spray, ultimately enhancing our collective understanding of this emerging exploitation technique and making improvements to community.\n\nDouble-fetch bugs (or vulnerabilities) stem from in-kernel system call execution fetching the same user data twice without proper data (re)sanitization, enabling TOCTTOU attacks and posing a major threat to operating systems security. Existing double-fetch protection systems rely on the MMU to trap on writes to syscall-accessed user pages and provide the kernel with a consistent snapshot of user memory. While this strategy can hinder attacks, it also introduces nontrivial runtime performance overhead due to the cost of trapping/remapping and the coarse (page-granular) write interposition mechanism.\n\nIn this paper, we propose SafeFetch, a practical solution to protect the kernel from double-fetch bugs. The key intuition is that most system calls fetch small amounts of user data (if at all), hence caching this data in the kernel can be done at a small performance cost. To this end, SafeFetch creates per-syscall caches to persist fetched user data and replay them when they are fetched again within the same syscall. This strategy neutralizes all double-fetch bugs, while eliminating trapping/remapping overheads and relying on efficient byte-granular interposition. Our Linux prototype evaluation shows SafeFetch can provide comprehensive protection with low performance overheads (e.g., 4.4% geomean on LMBench), significantly outperforming state-of-the-art solutions.\n\nThe Lightweight Directory Access Protocol (LDAP) is the standard technology to query information stored in directories. These directories can contain sensitive personal data such as usernames, email addresses, and passwords. LDAP is also used as a central, organization-wide storage of configuration data for other services. Hence, it is important to the security posture of many organizations, not least because it is also at the core of Microsoft's Active Directory, and other identity management and authentication services.\n\nWe report on a large-scale security analysis of deployed LDAP servers on the Internet. We developed LanDscAPe, a scanning tool that analyzes security-relevant misconfigurations of LDAP servers and the security of their TLS configurations. Our Internet-wide analysis revealed more than 10k servers that appear susceptible to a range of threats, including insecure configurations, deprecated software with known vulnerabilities, and insecure TLS setups. 4.9k LDAP servers host personal data, and 1.8k even leak passwords. We document, classify, and discuss these and briefly describe our notification campaign to address these concerning issues.\n\nEmail has become an essential service for global communication.In email protocols, a Delegation Mechanism allows emails to be sent by other entities on behalf of the email author. Specifically, the Sender field indicates the agent for email delivery (i.e., the Delegate). Despite well-implemented security extensions (e.g., DKIM, DMARC) that validate the authenticity of email authors, vulnerabilities in the Delegation Mechanism can still be exploited to bypass these security measures with well-crafted spoofing emails.\n\nThis paper systematically analyzes the security vulnerabilities within the Delegation Mechanism. Due to the absence of validation for the Sender field, adversaries can arbitrarily fabricate this field, thus spoofing the Delegate presented to email recipients. Our observations reveal that emails with a spoofed Sender field can pass authentications and reach the inboxes of all target providers. We also conduct a user study with 50 participants to assess the recipients' comprehension of spoofed Delegates, finding that 50% are susceptible to deceiving Delegate information. Furthermore, we propose novel email spoofing attacks where adversaries can impersonate arbitrary entities as email authors to craft highly deceptive emails while passing security extensions. We assess their impact across 16 service providers and 20 clients, observing that half of the providers and all clients are vulnerable to the discovered attacks. To mitigate the threats within the Delegation Mechanism, we propose a validation scheme to verify the authenticity of the Sender field, along with design suggestions to enhance the security of email clients.\n\nThe Domain Name System (DNS) fundamentally relies on glue records to provide authoritative nameserver IP addresses, enabling essential in-domain delegation. While previous studies have identified potential security risks associated with glue records, the exploitation of these records, especially in the context of out-domain delegation, remains unclear due to their inherently low trust level and the diverse ways in which resolvers handle them. This paper undertakes the first systematic exploration of the potential threats posed by DNS glue records, uncovering significant real-world security risks. We empirically identify that 23.18% of glue records across 1,096 TLDs are outdated yet still served in practice. More concerningly, through reverse engineering 9 mainstream DNS implementations (e.g., BIND 9 and Microsoft DNS), we reveal manipulable behaviors associated with glue records. The convergence of these systemic issues allows us to propose the novel threat model that could enable large-scale domain hijacking and denial-of-service attacks. Furthermore, our analysis determines over 193,558 exploitable records exist, placing more than 6 million domains at risk. Additional measurement studies on global open resolvers demonstrate that 90% of them use unvalidated and outdated glue records, including OpenDNS and AliDNS. Our responsible disclosure has already prompted mitigation efforts by affected stakeholders. Microsoft DNS, PowerDNS, OpenDNS, and Alibaba Cloud DNS have acknowledged our reported vulnerability. In summary, this work highlights that glue records constitute a forgotten foundation of DNS architecture requiring renewed security prioritization\n\nThe lack of trust is one of the major factors that hinder collaboration among Internet of Things (IoT) devices and harness the usage of the vast amount of data generated. Traditional methods rely on Public Key Infrastructure (PKI), managed by centralized certification authorities (CAs), which suffer from scalability issues, single points of failure, and limited interoperability. To address these concerns, Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) have been proposed by the World Wide Web Consortium (W3C) and the European Union as viable solutions for promoting decentralization and \"electronic IDentification, Authentication, and trust Services\" (eIDAS). Nevertheless, at the state-of-the-art, there are no efficient revocation mechanisms for VCs specifically tailored for IoT devices, which are characterized by limited connectivity, storage, and computational power.\n\nThis paper presents EVOKE, an efficient revocation mechanism of VCs in IoT networks. EVOKE leverages an ECC-based accumulator to manage VCs with minimal computing and storage overhead while offering additional features like mass and offline revocation. We designed, implemented, and evaluated a prototype of EVOKE across various deployment scenarios. Our experiments on commodity IoT devices demonstrate that each device only requires minimal storage (i.e., approximately 1.5 KB) to maintain verification information, and most notably half the storage required by the most efficient PKI certificates. Moreover, our experiments on hybrid networks, representing typical IoT protocols (e.g., Zigbee), also show minimal latency in the order of milliseconds. Finally, our large-scale analysis demonstrates that even when 50% of devices missed updates, approximately 96% of devices in the entire network were updated within the first hour, proving the scalability of EVOKE in offline updates.\n\nDespite the impressive capabilities of Deep Neural Networks (DNN), these systems remain fault-prone due to unresolved issues of robustness to perturbations and concept drift. Existing approaches to interpreting faults often provide only low-level abstractions, while struggling to extract meaningful concepts to understand the root cause. Furthermore, these prior methods lack integration and generalization across multiple types of faults. To address these limitations, we present a fault diagnosis tool (akin to a General Practitioner) DNN-GP, an integrated interpreter designed to diagnose various types of model faults through the interpretation of latent concepts. DNN-GP incorporates probing samples derived from adversarial attacks, semantic attacks, and samples exhibiting drifting issues to provide a comprehensible interpretation of a model's erroneous decisions. Armed with an awareness of the faults, DNN-GP derives countermeasures from the concept space to bolster the model's resilience. DNN-GP is trained once on a dataset and can be transferred to provide versatile, unsupervised diagnoses for other models, and is sufficiently general to effectively mitigate unseen attacks. DNN-GP is evaluated on three real-world datasets covering both attack and drift scenarios to demonstrate state-to the-art detection accuracy (near 100%) with low false positive rates (<5%).\n\nWe propose, FrameFlip, a novel attack for depleting DNN model inference with runtime code fault injections. Notably, Frameflip operates independently of the DNN models deployed and succeeds with only a single bit-flip injection. This fundamentally distinguishes it from the existing DNN inference depletion paradigm that requires injecting tens of deterministic faults concurrently. Since our attack performs at the universal code or library level, the mandatory code snippet can be perversely called by all mainstream machine learning frameworks, such as PyTorch and TensorFlow, dependent on the library code. Using DRAM Rowhammer to facilitate end-to-end fault injection, we implement Frameflip across diverse model architectures (LeNet, VGG-16, ResNet-34 and ResNet-50) with different datasets (FMNIST, CIFAR-10, GTSRB, and ImageNet). With a single bit fault injection, Frameflip achieves high depletion efficacy that consistently renders the model inference utility as no better than guessing. We also experimentally verify that identified vulnerable bits are almost equally effective at depleting different deployed models. In contrast, transferability is unattainable for all existing state-of-the-art model inference depletion attacks. Frameflip is shown to be evasive against all known defenses, generally due to the nature of current defenses operating at the model level (which is model-dependent) in lieu of the underlying code level.\n\nAlthough Trojan attacks on deep neural networks (DNNs) have been extensively studied, the threat of run-time Trojan injection has only recently been brought to attention. Unlike data poisoning attacks that target the training stage of a DNN model, a run-time attack executes an exploit such as Rowhammer on memory to flip the bits of the target model and thereby implant a Trojan. This threat is stealthier but more challenging, as it requires flipping a set of bits in the target model to introduce an effective Trojan without noticeably downgrading the model's accuracy. This has been achieved only under the less realistic assumption that the target model is fully shared with the adversary through memory, thus enabling them to flip bits across all model layers, including the last few layers.\n\nFor the first time, we hav"
    }
}