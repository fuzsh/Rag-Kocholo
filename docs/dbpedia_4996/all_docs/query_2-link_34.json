{
    "id": "dbpedia_4996_2",
    "rank": 34,
    "data": {
        "url": "https://www.gla.ac.uk/schools/computing/research/researchsections/systems-section/",
        "read_more_link": "",
        "language": "en",
        "title": "School of Computing Science",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.gla.ac.uk/3t4/img/cog-white.svg",
            "https://www.gla.ac.uk/3t4/img/ug-keyline.svg",
            "https://www.gla.ac.uk/3t4/img/ug-keyline-large.svg",
            "https://www.gla.ac.uk/media/Media_922846_smxx.png",
            "https://www.gla.ac.uk/media/Media_486063_smxx-200x207.jpg",
            "https://www.gla.ac.uk/1t4/generic/images/twitter_logo_white.png",
            "https://www.gla.ac.uk/3t4/img/marque.svg",
            "https://www.gla.ac.uk/3t4/img/fb.svg",
            "https://www.gla.ac.uk/3t4/img/tw.svg",
            "https://www.gla.ac.uk/3t4/img/inst.svg",
            "https://www.gla.ac.uk/3t4/img/yt.svg",
            "https://www.gla.ac.uk/media/Media_488423_smxx.png",
            "https://www.gla.ac.uk/3t4/img/svh.webp"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/3t4/img/hd_hi.png",
        "meta_site_name": "",
        "canonical_link": "https://www.gla.ac.uk/schools/computing/research/researchsections/systems-section/",
        "text": "DNN64: An ML Compiler Toolchain for the Nintendo 64 (26 June, 2024)\n\nSpeaker: Perry Gibson\n\nTitle: DNN64: An ML Compiler Toolchain for the Nintendo 64\n\nAbstract: In recent years, Deep Neural Networks (DNNs) have driven innovations in the computer hardware space, due to their increasingly high computational and memory demands. However, as shown by the TinyML community, DNNs can also operate on modest hardware such as micro-controllers such as microcontrollers through careful hardware-software-DNN co-design.\n\nThis talk explores running DNNs on retro hardware using modern tools, specifically on Nintendo‚Äôs 1996 video game console, the N64. The proposed ‚ÄúDNN64‚Äù is a compiler tailored for the N64, built using a modified Apache TVM compiler.\n\nPerry will link the project to his PhD topic (‚ÄúCompiler-centric Across-stack Deep Learning Acceleration‚Äù), and talk about things such as the goodies found in old Silicon Graphics manuals, how compilers aren‚Äôt scary (they‚Äôre just a bunch of print statements), the co-design problems that emerge when running DNNs on a whole 4MB of memory, and writing kernels for the N64‚Äôs proto-GPU (‚ú®the Reality Signal Processorü™Ñ).\n\nSpeaker Bio: Perry recently completed his PhD with Dr Jos√© Cano Reyes, and is currently exploring employment opportunities in the DNN compiler space.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nFederated PCA on Grassmann Manifold for IoT Anomaly Detection (21 May, 2024)\n\nSpeaker: Dr Nguyen H. Tran\n\nThis systems seminar is delivered by Dr Nguyen H. Tran from the University of Sydney, who is hosted by Nguyen Truong.\n\nPlease find the details below:\n\nTitle: Federated PCA on Grassmann Manifold for IoT Anomaly Detection\n\nAbstract: With the proliferation of the Internet of Things (IoT) and the rising interconnectedness of devices, network security faces significant challenges, especially from anomalous activities. While traditional machine learning-based intrusion detection systems (ML-IDS) effectively employ supervised learning methods, they possess limitations such as the requirement for labelled data and challenges with high-dimensional data. Recent unsupervised ML-IDS approaches like AutoEncoders and Generative Adversarial Networks (GAN) offer alternative solutions but pose challenges in deployment onto resource-constrained IoT devices and in interpretability. To address these concerns, this paper proposes a novel federated unsupervised anomaly detection framework -- FedPCA -- that leverages Principle Component Analysis (PCA) and the Alternatives Directions Method Multipliers (ADMM) to learn common representations of distributed non-i.i.d. datasets. Building on the FedPCA framework, we propose two algorithms, {FedPE} in Euclidean space and {FedPG} on Grassmann manifolds, and analyze their convergence characteristics. Our approach enables real-time threat detection and mitigation at the device level, enhancing network resilience while ensuring privacy. Experimental results on the UNSW-NB15 and TON-IoT datasets show that our proposed methods offer performance in anomaly detection comparable to non-linear baselines, while providing significant improvements in communication and memory efficiency, underscoring their potential for securing IoT networks.\n\nBio: Nguyen H. Tran is an Associate Professor at the School of Computer Science, at the University of Sydney. He was an Assistant Professor with the Department of Computer Science and Engineering, Kyung Hee University, from 2012 to 2017. He received BS and PhD degrees from HCMC University of Technology and Kyung Hee University in 2005 and 2011, respectively. His research group has special interests in Distributed compUting, optimizAtion, and machine Learning (DUAL group). He received several best paper awards, including IEEE ICC 2016 and ACM MSWiM 2019. He receives the Korea NRF Funding for Basic Science and Research 2016-2023, ARC Discovery Project 2020-2023, and SOAR award 2022-2023. He serves as an Editor for several journals such as IEEE Transactions on Green Communications and Networking (2016-2020), IEEE Journal of Selected Areas in Communications, and IEEE Transactions on Machine Learning in Communications Networking.\n\nZoom link: https://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nCould Erlang-Style Supervision Improve the Availability of Microservice Systems? (07 May, 2024)\n\nSpeaker: Jacob Roberts\n\nThe second half of the Systems Seminar is delivered by Jacob Roberts.\n\nPlease find the details below:\n\nTitle: Could Erlang-Style Supervision Improve the Availability of Microservice Systems?\n\nAbstract:\n\nMicroservices are a popular software architecture used by high-profile companies like Netflix, Uber, etc. The Kubernetes platform uses probes to check the health of containers. The probes must be carefully configured and may be slow to detect failure. In contrast, in Erlang supervision, child processes signal failure to a supervisor process that can take corrective action. Potentially, signalling could reduce failure detection time and be easier to configure than probes.\n\nThis talk presents an initial investigation into Erlang-style supervision of Kubernetes microservices. It outlines a prototype supervisor implementation for Kubernetes and presents experimental results comparing the new scheme to Kubernetes probes.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nSafe Human Robot Collaboration (07 May, 2024)\n\nSpeaker: Sundas Rafat Mulkana\n\nThe first part of the systems seminar is delivered by Sundas.\n\nPlease find the details below:\n\nTitle: Safe Human Robot Collaboration\n\nAbstract: The future direction of collaborative robots is shifting from having predefined rules for interaction between human and robot in structured environments, such as industrial settings, to achieving more flexibility in their actions in unstructured environments, such as households and public places. These futuristic robots, trained on learning-based methods, show promising results in simulation and controlled environments. However, when deploying these robots in the real-world ensuring human physical and cognitive safety raises major concerns. This necessitates the development of methods which provide provable safety constraints on robot motion which makes it cognizant of its proximity to humans while performing a task, thus providing formal guarantees that the robot trained on learning-based methods will not come in harmful contact with human. Additionally, studying the effect of these safety constraints on task performance and the ease of collaboration through user feedback in joint action tasks between human and robot would further help improve robot behavior. The primary objectives of this research are to develop methods that prove safety without compromising the performance of the robot, training robot to dynamically react to human behavior in the real world and identify human-preferred robot motions for collaborative tasks. This research's outcomes aim to contribute significantly to the integration of safe collaborative robots in social, healthcare, and industrial environments. By addressing the critical need for safety guarantees and naturalness in human-robot interaction, this work aims to pave the way for safer and more effective human-robot collaboration.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nRIPEn at Home Surveying Internal Domain Names using RIPE Atlas (30 April, 2024)\n\nSpeaker: Elizabeth Boswell\n\nThe second half of the Systems Seminar is delivered by Elizabeth Boswell.\n\nPlease find the details below.\n\nTitle: RIPEn at Home Surveying Internal Domain Names using RIPE Atlas\n\nAbstract:\n\nInternal domain names are domain names that are only valid in a local network. For example, many home networks use an internal name, such as \"gateway.home\", to refer to the home gateway/home router. Queries for these names are resolved by the home gateway and should not be sent to the global DNS.\n\nA name collision occurs if an internal name also exists in the global DNS, a query for the internal name is accidentally sent to the global DNS, and the response differs from the local response. This can happen, for example, if queries are accidentally sent to a public resolver. Name collisions can lead to security issues, as the global DNS domain name can be used to spoof the local device.\n\nWhile previous studies of name collisions used passive measurement data, we use active measurements on RIPE Atlas to survey the use of internal names in home networks. We discover 3092 names, used by 4305 RIPE Atlas probes, of which 2.13% are at acute risk of name collision, and 34.51% are at risk of collision if their top-level domain is delegated.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nInforming, instructing, or ignoring: challenges and considerations for designing machine learning software for users in CNI. (30 April, 2024)\n\nSpeaker: Kelsey Collington\n\nThe first part of the Systems seminar on 30/04/2024 is delivered by Kelsey Collington.\n\nPlease find the details below:\n\nTitle: Informing, instructing, or ignoring: challenges and considerations for designing machine learning software for users in CNI.\n\nAbstract: Successful integration of machine learning based software to help protect, detect and respond to cyber incidents is one means of enhancing digital resilience. Introducing such software facilitates human-machine interaction through supporting higher levels of machine automation. Importantly, existing research highlights human-machine interaction needs to be tuned to the particular groups of people involved in the human-machine interaction.\n\nThis research focuses on CNI organisations that tend to be risk adverse and prioritise the safe running of physical processes. As a result, these CNI organisations approach cyber security from a different perspective to non-safety critical CNI organisation. This is a group of end users that is underrepresented within existing research into human-machine interaction, and therefore there is a lack of understanding as to the challenges and considerations of designing machine learning software for these end users. To address this research gap, I have been conducting semi-structured interviews with personnel from the nuclear industry. Interviewees have experience with industrial control systems and cyber security. In this talk I will be discussing some of the preliminary findings of these interviews. I will then discuss how this research builds upon a related body of existing research and lays the foundation for future research directions.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nExploring 3D Human Pose Estimation and Forecasting from the Robot‚Äôs Perspective: ‚ÄãThe HARPER Dataset ‚Äã (16 April, 2024)\n\nSpeaker: Dr Emma Li\n\nThis systems seminar is delivered by Dr Emma Li, a staff member of GLASS.\n\nPlease find the detials below.\n\nTitle: Exploring 3D Human Pose Estimation and Forecasting from the Robot‚Äôs Perspective: The HARPER Dataset\n\nAbstract: In this talk, I will introduce our recent work on human-robot interaction, dataset HARPER, a novel dataset for 3D body pose estimation and forecast in dyadic interactions between users and Spot, the quadruped robot manufactured by Boston Dynamics. The key-novelty is the focus on the robot‚Äôs perspective, i.e., on the data captured by the robot‚Äôs sensors. These make 3D body pose analysis challenging because being close to the ground captures humans only partially. The scenario underlying HARPER includes 15 actions, of which 10 involve physical contact between the robot and users. The Corpus contains not only the recordings of the built-in stereo cameras of Spot, but also those of a 6-camera OptiTrack system (all recordings are synchronized). This leads to ground-truth skeletal representations with a precision lower than a millimeter. In addition, the Corpus includes reproducible benchmarks on 3D Human Pose Estimation, Human Pose Forecasting, and Collision Prediction, all based on publicly available baseline approaches. This enables future HARPER users to rigorously compare their results with those we provide in this work.\n\nBio: Emma Li is a Lecturer in Responsible & Interactive Artificial Intelligence at the School of Computing Science, University of Glasgow (UofG), UK. Prior to joining UofG, she was a senior lecturer at the Northumbria University Newcastle, UK. She visited Georgia Institute of Technology, GA, USA, in 2008-2010 and Lehigh University, PA, USA, in 2016. She leads the Interactive and Trustworthy AI lab working on human-robot interaction and cyber security. Her research goal is to accelerate human-robot partnership into industry and society. She has successfully delivered 6 projects and published 50 peer reviewed papers. Her recent work on robot behaviour-based user authentication received a best workshop paper award in IEEE INFOCOM 2021.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nBit-shift accelerators for non-uniform quantization (12 March, 2024)\n\nSpeaker: Rappy Saha\n\nThis systems seminar is delivered by Rappy Saha.\n\nPlease find the details below:\n\nTitle: Bit-shift accelerators for non-uniform quantization.\n\nAbstract:\n\nPower-of-Two quantization (PoT) represents a non-uniform quantization approach wherein data, such as weights or activations, is quantized in a power-of-two format(2N). This format offers distinct advantages, primarily in terms of memory saving and decreased communication overhead with memory. Additionally, it facilitates computational efficiency by allowing the replacement of multiplication operations with shift operations. This optimization reduces the computational cost associated with computations, making them more resource-efficient.\n\nPrior studies have showcased the utility of PoT quantization in accelerating machine learning (ML) models, introducing various methodologies and corresponding bit-shift accelerators. While some PoT strategies may enhance efficiency for certain ML models, this advantage isn't universal. Additionally, many existing schemes and accelerators are proprietary and fail to support a broad array of PoT quantization approaches.\n\nIn this work we target the development of versatile and efficient bit-shift accelerators capable of accommodating a diverse range of PoT quantization techniques. Our main objective is to design open-source bit-shift accelerator solutions that seamlessly integrate with widely-used ML frameworks, such as TF-Lite.\n\nZoom link: Meeting ID: 861 8632 5698\n\nPasscode: 803628\n\nSpecial Systems Seminar (07 March, 2024)\n\nSpeaker: Abdullah Giray and Geraldo F. Oliveira\n\nThis systems seminar talk speakers are kindly organised by Jose Cano Reyes.\n\nThe speakers are both PhD candidates from ETH Zurich.\n\nDue to the timing, this session runs longer than usual ‚Äî please note the start and end time.\n\nPlease find the details below:\n\nSpeaker: Abdullah Giray\n\nTitle: Enabling Efficient and Scalable DRAM Read Disturbance Mitigation via New Experimental Insights into Modern DRAM Chips\n\nAbstract:\n\nDRAM is the prevalent main memory technology due to its high density and low latency characteristics. The increasing need for faster access rates and larger DRAM capacity motivates improving the DRAM chip density. Manufacturing technology node size shrinks over DRAM chip generations to provide higher DRAM chip density. This technology scaling causes DRAM cell size and cell-to-cell distance to reduce significantly. As a result, DRAM cells become more vulnerable to read disturbance, i.e., accessing a DRAM cell disturbs data stored in another physically nearby cell.\n\nTo provide a deeper understanding of and solutions to DRAM read disturbance, we 1) conduct experimental studies on real DRAM chips where we investigate the effects of temperature, access patterns, intra-chip variations, and wordline voltage; and 2) propose architecture-level solutions to mitigate DRAM read disturbance while it is exacerbated by technology node scaling and existing mitigations face practicality challenges due to a fundamental need for exposing proprietary information. This talk will provide a summary of these works.\n\nBio:\n\nGiray is a Ph.D. candidate in the Safari Research Group at ETH Z√ºrich, working with Prof. Onur Mutlu. His current broader research interests are in computer architecture, systems, and hardware security with a special focus on DRAM robustness and performance. In particular, his PhD research focuses on understanding and solving DRAM read disturbance vulnerability. Giray has published several works on this topic in major venues such as HPCA, MICRO, ISCA, DSN, and SIGMETRICS. One of these works, BlockHammer, was named as a finalist by Intel in 2021 for the Intel Hardware Security Academic Award. Giray's research is in part supported by Google and the Microsoft Swiss Joint Research Center.\n\nSpeaker: Geraldo F. Oliveira\n\nTitle: Methodologies, Workloads, and Tools for Processing-in-Memory: Enabling the Adoption of Data-Centric Architectures.\n\nAbstract:\n\nThe increasing prevalence and growing size of data in modern applications have led to high costs for computation in traditional processor-centric computing systems. Moving large volumes of data between memory devices (e.g., DRAM) and computing elements (e.g., CPUs, GPUs) across bandwidth-limited memory channels can consume more than 60% of the total energy in modern systems. To mitigate these costs, the processing-in-memory (PIM) paradigm moves computation closer to where the data resides, reducing (and in some cases eliminating) the need to move data between memory and the processor. There are two main approaches to PIM: (1) processing-near-memory (PnM), where PIM logic is added to the same die as memory or to the logic layer of 3D-stacked memory; and (2) processing-using-memory (PuM), which uses the operational principles of memory cells to perform computation.\n\nMany works from academia and industry have shown the benefits of PnM and PuM for a wide range of workloads from different domains. However, fully adopting PIM in commercial systems is still very challenging due to the lack of tools and system support for PIM architectures across the computer architecture stack, which includes: (i) workload characterization methodologies and benchmark suites targeting PIM architectures; (ii) frameworks that can facilitate the implementation of complex operations and algorithms using the underlying PIM primitives; (iii) compiler support and compiler optimizations targeting PIM architectures; (iv) operating system support for PIM-aware virtual memory, memory management, data allocation, and data mapping; and (v) efficient data coherence and consistency mechanisms. Our goal in this talk is to highlight tools and system support for PnM and PuM architectures that aim to ease the adoption of PIM in current and future systems.\n\nBio:\n\nGeraldo F. Oliveira is a Ph.D. candidate in the Safari Research Group at ETH Z√ºrich, working with Prof. Onur Mutlu. His current broader research interests are in computer architecture and systems, focusing on memory-centric architectures for high-performance and energy-efficient systems. In particular, his Ph.D. research focuses on taking advantage of new memory technologies to accelerate distinct classes of applications and provide system support for novel memory-centric systems. Geraldo has published several works on this topic in major conferences and journals such as HPCA, ASPLOS, ISCA, MICRO, and IEEE Micro.\n\nZoom link: Meeting ID: 861 8632 5698\n\nPasscode: 803628\n\nSODA-OPT Compiler Frontend of the Software Defined Architectures (SODA) Toolchain (01 March, 2024)\n\nSpeaker: Nicolas Bohm Agostini\n\nThis is an ad-hoc external systems seminar organised by Jose!\n\nPlease find the details below:\n\nBio: Nicolas Bohm Agostini is a Ph.D. candidate in the Electrical and Computer Engineering Department at Northeastern University (NEU, Boston, MA) and a Computer Scientist at the Pacific Northwest National Laboratory (PNNL). He completed his bachelor‚Äôs degree in electrical engineering at the Universidade Federal do Rio Grande do Sul (UFRGS, Brazil) in 2015, followed by a Master of Science in Electrical and Computer Engineering from NEU in 2022. With a strong focus on Computer Architecture and High-Performance Computing, Nicolas has gained extensive expertise in accelerating machine learning and linear algebra applications. As a passionate educator, he has taught Compilers, GPU Programming, and Embedded Robotics courses. Nicolas joined PNNL in 2020 and is the lead developer of the SODA-OPT compiler, which automates system-level partitioning of high-level applications and enables automatic code optimizations for superior custom hardware generation outcomes.\n\nDescription: We invite you to explore the work of Nicolas Bohm Agostini, a leading researcher in high-performance computing and compilers for High-Level Synthesis (HLS). In this talk, Nicolas will present SODA-OPT, the compiler frontend of the Software Defined Architectures (SODA) toolchain. SODA-OPT harnesses the power of the MLIR compiler infrastructure to automate the generation of custom hardware accelerators for applications programmed with high-level productive programming frameworks (e.g., Tensorflow, PyTorch). By employing specialized abstractions and leveraging MLIR, SODA-OPT automates the initial steps of generating custom accelerators through HLS, enabling non-experts to create efficient FPGA or ASIC designs, reducing or eliminating the need for the manual effort of an HLS expert. The compilation flow demonstrated in this talk showcases the automatic generation of accelerators for linear algebra and deep neural networks (DNN) operators. Experimental results with kernels from the PolyBench benchmark show that the SODA-OPT optimization pipeline can improve the runtime of synthesized accelerators by up to 60x. Join us to learn how the SODA-OPT compiler and SODA toolchain can enhance your accelerator development process.\n\nZoom link: Meeting ID: 861 8632 5698\n\nPasscode: 803628\n\nThe challenges of overseeing and influencing the cybersecurity of supply chains to critical infrastructure. (27 February, 2024)\n\nSpeaker: Tania Wallis\n\nThis week's Systems seminar is delivered by Tania Wallis. Please find the detail below.\n\nTitle: The challenges of overseeing and influencing the cybersecurity of supply chains to critical infrastructure.\n\nAbstract: This talk will describe an EPSRC Impact Acceleration project that is working in the interactive space between customers, suppliers and government actors to develop a partnership framework for managing shared responsibilities and cybersecurity improvements across the supply chain networks of UK essential services. This work is examining touch points with the supply chain and the tailoring of implementations towards operational technology (OT) contexts and includes end users from the energy, rail, aviation & water sectors.\n\nZoom link: Meeting ID: 861 8632 5698\n\nPasscode: 803628\n\nGuided Equality Saturation: Semi-automatic Term Rewriting (13 February, 2024)\n\nSpeaker: Phil Trinder\n\nThis systems seminar is delivered by Prof. Phil Trinder.\n\nPlease find the detail below:\n\nAbstract: Rewriting is a principled term transformation technique with uses across theorem proving and compilation. While developing rewrite sequences manually is possible, this process doesn‚Äôt scale to larger rewrite sequences. Automated rewriting techniques, like greedy simplification or equality saturation, work well without human input but don't scale to large search spaces.\n\nThis talk proposes a semi-automatic rewriting technique as a means to scale rewriting by allowing human insight at key decision points. Specifically, we propose guided equality saturation that embraces human guidance when fully automated equality saturation does not scale. The rewriting is split into two or more simpler automatic equality saturation steps: from the original term to a human-provided intermediate guide, and from the guide to the target. A guide can be a complete term, or a relatively concise sketch containing undefined elements that are instantiated by the equality saturation search.\n\nWe demonstrate the generality and effectiveness of guided equality saturation using two case studies:\n\n1. As a tactic in the Lean 4 proof assistant. Proofs are written in the style of textbook proof sketches that omit details. Compared with unguided equality saturation more properties can be proved, and the proofs execute in seconds rather than minutes.\n\n2. In the compiler for the RISE array language unguided equality saturation fails to perform optimizations within an hour and using 60 GB of memory. Guided equality saturation performs the optimizations with at most 3 guides, within seconds, and using less than 1 GB. The generated code outperforms that produced by the state-of-the-art TVM compiler.\n\nThe talk is an extended version of our POPL'24 presentation.\n\nZoom link: Meeting ID: 861 8632 5698\n\nPasscode: 803628\n\nCan changes in the computational stack affect correctness of Deep Learning Models? (06 February, 2024)\n\nSpeaker: Dr Ajitha Rajan\n\nNext Systems Seminar is delivered by Dr Ajitha Rajan from the School of Informatics at the University of Edinburgh.\n\nDo join us in-person in SAWB422 or remotely on Zoom.\n\nPlease find the details below:\n\nTitle: Can changes in the computational stack affect correctness of Deep Learning Models?\n\nAbstract: It is well understood that deep learning models can be sensitive to small perturbations in input data and model architecture. There has been significant effort in making models more robust against these data and model perturbations. However, the effect of changes in the computational stack - deep learning frameworks, compilers, optimisations, hardware devices, during model deployment is not well understood. This talk will report on our testing and fault localisation research studying and fixing the effects of changes within the computational stack. We focus in particular on deep learning frameworks, as we found changing the framework during deployment can affect up to 72% of the output labels.\n\nBio: Dr.Ajitha Rajan is a Reader in the School of Informatics at the University of Edinburgh, where she started in 2013. She is a Royal Society Industry Fellow. Dr. Rajan's research interests are in the area of software testing, verification, robustness and interpretability of artificial intelligence applied to avionics, automotive, embedded systems, blockchains and medical diagnostics. Her work in her Royal Society Industry Fellowship focuses on testing correctness of AI algorithms in self-driving cars. Dr. Rajan has been awarded grants from EPSRC, Royal Society, H2020, Facebook, GCHQ, Huawei, and SICSA.\n\nZoom Link: https://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nLocally Predicting Task Runtimes Before Running Scientific Workflows on Heterogeneous Compute Infrastructure (30 January, 2024)\n\nSpeaker: Lauritz Thamsen\n\nThe next systems seminar is delivered by Lauritz Thamsen.\n\nPlease find the details below:\n\nTitle: Locally Predicting Task Runtimes Before Running Scientific Workflows on Heterogeneous Compute Infrastructure\n\nAbstract: Many resource management techniques for task scheduling, energy and carbon efficiency, and cost optimization in workflows rely on apriori task runtime knowledge. Yet, building runtime prediction models on historical data is often not feasible in practice as applications, data, and infrastructure change. Online methods, on the other hand, which estimate task runtimes on specific machines while the workflow is running, have to cope with a lack of measurements during start-up. Frequently, scientific workflows are executed on heterogeneous clusters consisting of machines with different CPU, I/O, and memory configurations, further complicating predicting runtimes due to different task runtimes on different machine types.\n\nIn this talk, I will present Lotaru, a method for locally predicting the runtimes of scientific workflow tasks before they are executed on heterogeneous compute clusters. Crucially, our method does not rely on historical data and copes with a lack of training data during the start-up. To this end, we use microbenchmarks, reduce the input data to efficiently profile workflow tasks locally, and predict a task‚Äôs runtime with a Bayesian linear regression based on the gathered data points from the local workflow profiling and the microbenchmarks. Our evaluation with five real-world scientific workflows shows that Lotaru outperforms state-of-the-art runtime prediction methods. In a second set of experiments, the prediction performance of our method, using the predicted runtimes for advanced workflow scheduling, carbon-aware time shifting, and cloud cost prediction, enables results close to those achieved with perfect prior knowledge of task runtimes.\n\nZoom link: https://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nSystems Seminar ‚Äî Sizzler: PLC vulnerability discovery framework (16 January, 2024)\n\nSpeaker: Kai Feng\n\nAbstract:\n\nSizzler is a PLC vulnerability discovery framework underpinned by a novel mutation-based fuzzing strategy instrumented over SeqGAN and PLC firmware emulation setup approach. Sizzler achieves the translation of PLC LDs into C code, which execute on representative MCUs such as to emulate as realistically as possible a variety of PLC firmware environments across 30 PLC applications. Moreover, the optimal synergy of SeqGAN model with a havoc-based mutation strategy for fuzzing through Sizzler demonstrates high efficiency on detecting new and deeper code paths that relate to an increase of discovering otherwise unseen PLC code vulnerabilities. In parallel, Sizzler is also successfully deployed and assessed within a wider embedded systems dataset associated to non-PLC applications indicating its superiority over commonly used fuzzing schemes.\n\nZoom link: https://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nDecoding the IETF (09 January, 2024)\n\nSpeaker: Colin Perkins\n\nThis semester's first Systems Seminar talk is delivered by Colin Perkins. Join us to see how the IETF works!\n\nPlease find the detail below:\n\nAbstract:\n\nThe Internet Engineering Task Force (IETF) is the premier technical standards development organisation for the Internet. In this talk, I'll describe the goals and operation of the IETF, review the standards development process, and discuss the evolution of the organisation and its participants over time. I'll conclude with some reflections on lessons learned from 25 years of work in Internet standards.\n\nZoom link: https://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nContinual learning in sensor-based human activity recognition (12 December, 2023)\n\nSpeaker: Dr Juan Ye (Erica)\n\nThis systems seminar is delivered by Dr Juan Ye (Erica) from University of St Andrews, School of Computer Science.\n\nShe will be delivering the talk in-person.\n\nPlease find the abstract and bio below:\n\nAbstract: Human activity recognition (HAR) is a key enabler for many applications in healthcare, factory automation, and smart home. It detects and predicts human behaviours or daily activities via a range of wearable sensors or ambient sensors embedded in an environment. As more and more HAR applications are deployed in the real-world environments, there is a pressing need for the ability of continually and incrementally learning new activities over time without retraining the HAR model. In this talk, we will present our recent progress in developing various continual learning techniques for HAR, including regularisation, generative rehearsal, and dynamic architecture techniques. We will summarise with what we have learnt from these projects and discuss future directions.\n\nBio: I am a Reader in the School of Computer Science at the University of St Andrews. My research interests centre around adaptive pervasive systems, specialising in sensor-based human activity recognition, sensor fusion, context awareness, ontologies, and uncertainty reasoning. I have a PhD degree in computer science from University College Dublin, Ireland and a BSc and MSc degree from Wuhan University, China.\n\nZoom link: https://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nTruth or Dare? Attacking the AI (28 November, 2023)\n\nSpeaker: Dr Nick Pitropakis\n\nThis Systems Seminar is delivered by Dr Nick Pitropakis from Edinburgh Napier University\n\nAbstract:\n\nMany machine learning methodologies typically function under the assumption of a benign environment. However, this assumption is not always valid, as adversaries may find it advantageous to maliciously tamper with either the training data (poisoning attacks) or the test data (evasion attacks). Given the increasing prevalence of machine learning applications in society, such attacks can have devastating consequences. Consequently, there is a pressing need to enhance the security of machine learning to ensure its safe and reliable adoption in adversarial scenarios.\n\nBio:\n\nNick Pitropakis is an Associate Professor of cybersecurity at the School of Computing of Edinburgh Napier University, and a Fellow of the HEA. He is also a core member of the Blockpass Identity Lab. Dr Pitropakis has a strong research background in attacks against machine learning. His current research interests include adversarial machine learning, trust and privacy using distributed ledger technology, advanced cyber attack attribution, and data science applied to cyber security and IoT device security. Dr Pitropakis is leading the integrated apprenticeship scheme BSc Cyber Security, which is the first in the UK to receive full NCSC accreditation. He is teaching Cyber-related graduate apprenticeship degrees, both running in Scotland and England. He is also the external examiner of The American College in Greece (ACG), covering the BSc (Hons) Information Technology and BSc (Hons) Cyber Security and Networking programmes provided by The Open University, and the Lead External Examiner for MSc Cyber Security (Newcastle and London campuses) of Northumbria University. Dr Pitropakis is currently leading the Horizon Europe project Trust and Privacy-Preserving Computing Platform for Crossborder Federation of Personal Data (TRUSTEE).\n\nPlease find the zoom details below.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nUnlocking the Power of Data-Centric Acceleration for Modern Applications (07 November, 2023)\n\nSpeaker: Dr Haiyu Mao\n\nThis week's systems seminar will be delivered by Dr Haiyu Mao visiting from ETH Zurich. Join us in-person or online!\n\nAbstract: In today's digital landscape, the exponential growth of data has become the driving force behind cutting-edge applications, such as genome analysis and machine learning applications, revolutionizing our approach to healthcare and overall living quality. However, this unprecedented deluge of data poses a formidable challenge to traditional von Neumann computer architectures. The inefficiencies arising from the constant data movement between processors and memory consume a substantial portion of both execution time and energy when running modern applications on conventional von Neumann computers. To reduce this significant data movement, data-centric architectures, particularly processing-in-memory accelerators, emerge as a promising solution by enabling the processing of data directly where it resides. Nonetheless, most existing data-centric architectures primarily focus on accelerating specific arithmetic operations, inadvertently leaving a substantial gap between the architectural enhancements and the holistic needs of modern applications. Concurrently, conventional software optimizations often treat the architecture as a black box, which inherently limits the potential acceleration of applications.\n\nThis talk seeks to bridge the gaps between modern applications and data-centric architectures and revolutionize the landscape of data-centric acceleration for two vital categories of modern applications: genome analysis and machine learning. Firstly, this talk offers a comprehensive analysis of the pressing challenges within state-of-the-art genome analysis pipelines and introduces an innovative end-to-end data-centric acceleration approach achieved through seamless software-and-hardware co-design. Secondly, this talk illuminates the path to closing the gap between data-centric accelerators and the execution of real-world applications by presenting a compelling case study centered on a crucial machine learning application based on generative adversarial networks. Furthermore, this talk delves into the intricate challenges of data-centric acceleration for modern applications and explores potential solutions to surmount these obstacles, paving the way for a future where data-centric acceleration seamlessly integrates with the ever-evolving landscape of advanced applications.\n\nSpeaker: Dr. Haiyu Mao is a postdoctoral researcher in the SAFARI Research group led by Prof. Onur Mutlu at ETH Zurich, Switzerland. In July 2020, she received her Ph.D. degree in computer science from Tsinghua University, China. Her research interests intersect between computer architecture, processing in memory, bioinformatics, machine learning accelerators, non-volatile memory, and secure memory. Visit Haiyu‚Äôs personal website for more info: .\n\nPlease find the zoom details below.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nCoherence Attacks and Defenses in 2.5D Integrated Systems (06 November, 2023)\n\nSpeaker: Prof. Paul Gratz\n\nThis special additional Systems Seminar features Professor Paul Gratz, visiting from Texas A&M University. Do come join us in-person or online!\n\nAbstract: Industry is moving towards large-scale hardware systems which bundle processor cores, memories, accelerators, etc. via 2.5D integration. These components are fabricated separately as chiplets and then integrated using an interconnect carrier, i.e., an interposer. This new design style is beneficial in terms of yield and economies of scale, as chiplets may come from various vendors and are relatively easy to integrate into one larger sophisticated system. However, the benefits of this approach come at the cost of new security and integrity challenges, especially when integrating chiplets that come from not fully trusted, third-party vendors.\n\nIn this talk, I explore these challenges for modern interposer-based systems of cache-coherent, multi-core chiplets. First, I will present a new form of coherence-oriented hardware Trojan attacks, that pose a significant threat to chiplet-based designs and demonstrate how these basic attacks can be orchestrated to pose a significant threat to interposer-based systems. Second, I will show our proposal for a novel scheme using an active interposer as a generic, secure-by-construction platform that forms a physical root of trust for modern 2.5D systems. The implementation of our scheme is confined to the interposer, resulting in little cost and leaving the chiplets and coherence system untouched. I will show that our scheme prevents a range of coherence attacks with low overheads on system performance, ~4%. Overheads reduce as workloads increase, ensuring the scheme's scalability.\n\nBio: Paul V. Gratz is a Professor in the department of Electrical and Computer Engineering at Texas A&M University. His research interests include efficient and reliable design in the context of high performance computer architecture, processor memory systems and on-chip interconnection networks. He received his B.S. and M.S. degrees in Electrical Engineering from The University of Florida in 1994 and 1997 respectively. From 1997 to 2002 he was a design engineer with Intel Corporation. He received his Ph.D. degree in Electrical and Computer Engineering from the University of Texas at Austin in 2008. His paper, \"Synchronized Progress in Interconnection Networks (SPIN) : A New Theory for Deadlock Freedom,\" was selected as a Top Pick from the architecture conferences in 2018 by IEEE Micro. His papers \"Path Confidence based Lookahead Prefetching\" and \"B-Fetch: Branch Prediction Directed Prefetching for Chip-Multiprocessors\" were nominated for best papers at MICRO '16 and MICRO '14 respectively. At ASPLOS '09, Dr. Gratz received a best paper award for \"An Evaluation of the TRIPS Computer System.\" In 2016 he received the \"Distinguished Achievement Award in Teaching ‚Äì College Level\" from the Texas A&M Association of Former Students and in 2017 he received the \"Excellence Award in Teaching, 2017\" from the Texas A&M College of Engineering.\n\nPlease find the zoom details below.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nOn the (De)centralisation of Proof-of-Work Blockchain Protocols (31 October, 2023)\n\nSpeaker: Thomas Zacharias\n\nAbstract: This talk is based on my most recent published work [1], along with a gentle introduction to the concept of Proof-of-Work blockchain protocols.\n\nOne of the most important features of these protocols is decentralisation, as their main contribution is that they formulate a distributed ledger that will be maintained and extended without the need of a trusted party. Nonetheless, Bitcoin, the most prominent Proof-of-Work blockchain system, has been criticised for its tendency to centralisation, as very few pools control the majority of the hashing power. Pass et al. proposed FruitChain [ACM PODC 17] and claimed that this blockchain protocol mitigates the formation of pools by reducing the variance of the rewards in the same way as mining pools, but in a fully decentralized fashion. Many follow up papers consider that the problem of centralisation in Proof-of-Work blockchain systems can be solved via lower rewards' variance, and that in FruitChain the formation of pools is unnecessary.\n\nContrary to the common perception, in [1], we prove that lower variance of the rewards does not eliminate the tendency of the PoW blockchain protocols to centralisation; miners have also other incentives to create large pools, and specifically to share the cost of creating the instance they need to solve the PoW puzzle. Thus, the existence of a Proof-of-Work protocol that provably provides incentives to the participants to act in a decentralised manner remains an open question.\n\n[1]. Aikaterini-Panagiota Stouka and Thomas Zacharias. ‚ÄúOn the (De)centralization of FruitChains‚Äù. In IEEE Computer Security Foundations Symposium (CSF), 2023.\n\nThe seminar will be delivered hybrid both via zoom and in-person at SAWB422\n\nPlease find the zoom details below.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nMachine Learning Systems: Opportunities in Partitioning and Pruning (10 October, 2023)\n\nSpeaker: Prof. Blesson Varghese\n\nAbstract:\n\nMy last (virtual) talk at Glasgow CS over a year ago was on our experience of making machine learning (ML) work for the edge focusing on optimising the computations within ML models. This talk will follow the same genre and I will present two techniques we have developed towards making machine learning more feasible on edge systems. The first is partitioning ML models, and this time I will focus on optimising communication bottlenecks. The second is pruning and I will present our work that builds on the Lottery Ticket Hypothesis to create compressed ML models suited for on-demand edge deployments.\n\nThe seminar will be delivered hybrid both via zoom and in-person at SAWB422\n\nProf. Blesson Varghese will be presenting in-person!\n\nPlease find the zoom details below.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\n\"Morello MicroPython: A Python Interpreter for CHERI\" and \"Exploring Neural Network Model Composition for Environment-Aware Federated Learning\" (03 October, 2023)\n\nSpeaker: Duncan Lowther and Cocoa Xu\n\nThis week's systems seminar consists of two talks delivered by Duncan Lowther and Cocoa Xu.\n\nPlease find the details below:\n\nTitle: Morello MicroPython: A Python Interpreter for CHERI\n\nSpeaker: Duncan Lowther\n\nAbstract: Arm Morello is a prototype system that supports CHERI hardware capabilities for improving runtime security. As Morello becomes more widely available, there is a growing effort to port open source code projects to this novel platform. Although high-level applications generally need minimal code refactoring for CHERI compatibility, low-level systems code bases require significant modification to comply with the stringent memory safety constraints that are dynamically enforced by Morello. In this paper, we describe our work on porting the MicroPython interpreter to Morello with the CheriBSD OS. Our key contribution is to present a set of generic lessons for adapting managed runtime execution environments to CHERI, including (1) a characterization of necessary source code changes, (2) an evaluation of runtime performance of the interpreter on Morello, and (3) a demonstration of pragmatic memory safety bug detection. Although MicroPython is a lightweight interpreter, mostly written in C, we believe that the changes we have implemented and the lessons we have learned are more widely applicable. To the best of our knowledge, this is the first published description of meaningful experience for scripting language runtime engineering with CHERI and Morello.\n\nTitle: Exploring Neural Network Model Composition for Environment-Aware Federated Learning.\n\nSpeaker: Cocoa Xu\n\nAbstract: This work explores how to discover and find environments based on data available to the device. Previous work explored the utilization of environmental information collected from on-device sensors for environment-aware neural network model composition in a federated learning system. Input samples that are in the same environment defined by a set of environmental tags will be aggregated together and contribute to the corresponding environment-aware model. This work proposes a generic workflow that helps users to discover and find different environments and has some preliminary experiments that try to automate this process.\n\nThe seminar will be delivered hybrid both via zoom and in-person at SAWB422\n\nPlease find the zoom details below.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nSystems Update plus Conservative Garbage Collection (26 September, 2023)\n\nSpeaker: Jeremy Singer\n\nAbstract: First, I will give a brief update about our Systems Section as we start a new semester. Then I will spend some time talking about conservative garbage collection algorithms and their worst-case behaviour (joint work with Dejice Jacob).\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nMarrying up Deep Learning and Random Test Case Generation for Software Bug Detection (19 September, 2023)\n\nSpeaker: Prof. Zheng Wang\n\nAbstract: Deep learning (DL) techniques have emerged as a powerful tool for constructing sophisticated models to identify software bugs and vulnerabilities. While promising, several challenges must be addressed to make DL-based bug detection practical for real-world scenarios. In this talk, I will discuss some of the research conducted by my group in leveraging deep learning and fuzzing (i.e., random test case generation) techniques to detect bugs in black-box compilers and source code. We have successfully applied our techniques to detect bugs and security flaws in Javascript compilers and C programs. Our approach has uncovered over 160 new compiler bugs across various Javascript engines, including those used in Apple Safari, Google Chrome, Microsoft Edge, and Firefox. Of these bugs, 150 have been verified, and the developers have already fixed 130 as a matter of urgency. When applying our techniques to 20 open-source projects using 200 hours of automated test runs, we discovered 53 new bugs, resulting in 30 unique CVE (Common Vulnerabilities and Exposures) IDs assigned.\n\nSpeaker Bio: Zheng Wang is a Professor of Intelligent Software Technology at the School of Computing at the University of Leeds. He works at the intersection of machine learning and software techniques and is known for his work in incorporating machine learning into compilation technology. He has published over 150 papers and received four best paper awards and four HiPEAC paper awards. His research has been successfully transferred into various industry settings and the open-source community.\n\nZoom link:\n\nhttps://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nCompiler Discovered Dynamic Scheduling of Irregular Code in High-Level Synthesis (29 August, 2023)\n\nSpeaker: Robert Szafarczyk\n\nAbstract: High-level synthesis (HLS) compilers transform code written in a high-level software language, like C++, into a hardware description of a custom architecture, promising performance and efficiency improvements over off-the-shelf von Neumann architectures. Operation scheduling, the mapping of operation execution to clock cycles, is a central problem in any HLS compiler. Commercial HLS compilers produce a static schedule at compile time, failing to adapt to unpredictable runtime conditions. Recent academic HLS compilers have explored dataflow scheduling of operations at runtime to address this shortcoming, but they produce hardware that uses more resources and achieves lower operating frequencies than static HLS compilers. We show how existing static HLS compilers can be extended to support fine grained dynamic scheduling of unpredictable parts of a code, with minimal impact on the resource usage and operating frequency of the final circuit.\n\nThis will be streamed via zoom.\n\nZoom link: https://uofglasgow.zoom.us/j/86186325698?pwd=STNMZ2Y5a1lwMzEvcWowYTFSSjJ1QT09\n\nMeeting ID: 861 8632 5698\n\nPasscode: 803628\n\nSystems/PLUG joint seminar ‚Äî OptiTrust: an Interactive Framework for Source-to-Source Transformations (27 June, 2023)\n\nSpeaker: Thomas Koehler\n\nThis is a joint seminar between Systems section and PLUG at the School of Computing Science.\n\nPlease find the detail below:\n\nAbstract: We present OptiTrust, an interactive framework for optimizing\n\ngeneral-purpose C code via series of programmer-guided, source-to-source\n\ntransformations. Optimization steps are described in transformation\n\nscripts, expressed as OCaml programs. At every step, the programmer may\n\ninteractively visualize the effect of the transformation as the\n\ndifference between two pieces of human-readable C code. OptiTrust has\n\nbeen previously employed to optimize numerical simulation code. In this\n\nwork, we showcase how to use OptiTrust to optimize matrix\n\nmultiplication. We compare against TVM, which also relies on programmer\n\nguidance, but which restricts the input language and lacks easily\n\nreadable feedback.\n\nZoom link: https://uofglasgow.zoom.us/j/86482689868?pwd=YW9jUEdXNXRaUHFPbWdTNGZYY1Rxdz09\n\nMeeting ID: 864 8268 9868\n\nPasscode: 576572\n\nExploring Neural Network Model Composition for Environment-Aware Federated Learning (20 June, 2023)\n\nSpeaker: Cocoa Xu\n\nSecond Part of the Systems Seminar on 20/06/2023 is delivered by Cocoa Xu.\n\nTitle: Exploring Neural Network Model Composition for Environment-Aware Federated Learning.\n\nAbstract: This work explores how to discover and find environments based on data available to the device. Previous work explored the utilization of environmental information collected from on-device sensors for environment-aware neural network model composition in a federated learning system. Input samples that are in the same environment defined by a set of environmental tags will be aggregated together and contribute to the corresponding environment-aware model. This work proposes a generic workflow that helps users to discover and find different environments and has some preliminary experiments that try to automate this process.\n\nZoom Link:\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nMobility multihoming duality for the Internet Protocol (20 June, 2023)\n\nSpeaker: Ryo Yanagida\n\nThe systems seminar on 20/06/2023 will be delivered by Ryo Yanagida.\n\nAbstract: In the current Internet, mobile devices with multiple connectivity are becoming increasingly common; however, the Internet protocol itself has not evolved accordingly. Instead, add-on mechanisms have emerged, but they do not integrate well. Currently, the user suffers from disruption to communication on the end-host as the physical network connectivity changes. This is because the IP address changes when the point of attachment changes, breaking the transport layer end-to-end state. Furthermore, while a device can be connected to multiple networks simultaneously, the use of IP addresses prevents end-hosts from leveraging multiple network interfaces ‚Äî a feature known as host multihoming, which can potentially improve the throughput or reliability. While solutions exist separately for mobility and multihoming, it is not possible to use them as a duality solution for the end-host.\n\nThis talk will present the overview of ILNPv6, its extension, and evaluations done with the extended ILNPv6 implementation on Linux kernel.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nFour Years of GUSS: Successes and Lessons Learned (13 June, 2023)\n\nSpeaker: Tim Storer\n\nThis systems seminar is delivered by Tim Storer. Tim will talk about the very unique journey of the GUSS.\n\nPlease see the details below:\n\nTitle: Four Years of GUSS: Successes and Lessons Learned\n\nAbstract: The School of Computing Science created the Glasgow University Software Service in the Summer of 2019. The service began life as a school summer internship, with no other funding, developers or projects. Since then we‚Äôve grown enormously and continue to do so, offering a range of software based services across the University and beyond. In May 2023 we have a management team of 6 with more than 30 active developers and UX designers and around 15 active projects. I‚Äôll talk about the history of GUSS and how we‚Äôve grown over time, noting the numerous successes as well as the lessons we‚Äôve learned along the way.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nSystems Modelling with Bigraphs (06 June, 2023)\n\nSpeaker: Blair Archibald\n\nAbstract: Bigraphs are an expressive modelling formalism, first introduced by Robin Milner, to model systems with strong notions of space and mobility. In this talk I will informally (no maths required!) introduce bigraphs---including their diagrammatic notation (really, no maths!)---and give a high-level overview of some of applications we have used them for before, some of the research and development undertaken at Glasgow, and some hints for where we might take bigraphs in the future.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nTracking IoT P2P Botnet Loaders in the Wild (16 May, 2023)\n\nSpeaker: Hatem Aied S Almazarqi\n\nHatem will be presenting a talk remotely on \"Tracking IoT P2P Botnet Loaders in the Wild\".\n\nThis will be a hybrid event hosted at SAWB422.\n\nPlease find the abstract below:\n\nAbstract: Evidently, centralised botnets are nowadays considered as easy targets for take-down efforts by law enforcement and computer security researchers. Hence, malicious actors transitioned towards the implementation of Peer-to-Peer (P2P) IoT botnets such to solidify their\n\ninfrastructures, avoid single points of failure and further evade back tracking. Consequently, due to the highly distributed persona of modern P2P botnets, the detection of critical nodes to aid for the effective capturing of emerging threat vectors in such setups evolved into a challenging task. In this work, we conduct a novel 24-month longitudinal study based on real Internet measurements from globally distributed honeypots focusing on propagation trends of P2P IoT botnets. In order to achieve this, we develop graph-based centrality metrics to attribute AS-level connectivity characteristics to botnet and malware propagation as well as relating AS-level tolerance for botnet malware hosts we refer to as loaders. In general, we argue that the proposed methodology and outcomes of the herein study, can significantly benefit security experts and network operators towards the design of mitigation measures against present and future P2P botnets.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nThe climate cost of the AI revolution (02 May, 2023)\n\nSpeaker: Wim Vanderbauwhede\n\nSummary: ChatGPT and other AI applications such as Midjourney have pushed \"Artificial Intelligence\" high on the hype cycle. In this talk, I focus specifically on the energy cost of training and using applications like ChatGPT, what their widespread adoption could mean for global CO‚ÇÇ emissions, and what we could do to limit these emissions.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nCyber Security and Human Reliability Analysis (25 April, 2023)\n\nSpeaker: Ying He\n\nYing is a GLASS alumnus now working at Nottingham. He will join our seminar next week remotely and talk about his recent cyber security work.\n\nTitle: Cyber Security and Human Reliability Analysis\n\nAbstract:\n\nOrganisations continue to suffer information security incidents and breaches as a result of human error even though humans are recognised as the weakest link with regard to information security. Organisations have realised the importance of human factor and but have not implemented a systematic approach, such as Human Reliability Analysis (HRA) which are used within high reliability sectors such as rail, aviation and energy. The objectives of our research are to define a human error related information security incident and create the novel HEART of Information Security (HEART-IS) technique which is an adaptation of the Human Error Assessment and Reduction Technique (HEART). We conducted case studies within a private sector and a pubic sector organisation using HEART-IS to establish if HRA is applicable to information security. We found that HEART-IS is applicable to the information security field with some minor amendments to the terminology. The mapping of information security incident causes to the HEART Error Producing Conditions (EPC) was successful but the in-built HEART human error probability calculations did not match the actual volumes of reported human error related incidents.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nSystems Section MSci Presentation Part 2 (22 March, 2023)\n\nSpeaker: Systems Section MSci Students\n\nThis week‚Äôs Systems Seminars are special! We have a series of talks from MSci students in Systems Section two days in a row.\n\nThis is the part 2 of the 2 sets of presentations\n\nWednesday 22/03/2023 1330‚Äì1515\n\nEthan Ingraham (Supervisor: Yehia Elkhatib)\n\nBorislav Kratchanov (Supervisor: Blair Archibald) ‚Äî ‚ÄúCompilation as a Bigraphical Reactive System‚Äù\n\nKshitiz Bisht (Supervisor Nikos Ntarmos)\n\nInesh Bose (Supervisor: Tim Storer) ‚Äî \"Understanding Developer Experience & Productivity with a Holistic Dashboard\"\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nSystems Section MSci Presentation Part 1 (21 March, 2023)\n\nSpeaker: Systems Section MSci Students\n\nThis week‚Äôs Systems Seminars are special! We have a series of talks from MSci students in Systems Section two days in a row.\n\nThis is the part 1 of the 2 sets of presentations\n\nTuesday 21/03/2023 1400‚Äì1545\n\nPeter Dodd (Supervisor: Jose Cano Reys)\n\nMairi Sillars Moya (Supervisor: Colin Perkins) ‚Äî ‚ÄúParsing State Machine Models from Standards Documents‚Äù\n\nElizabeth Boswell (Supervisor: Colin Perkins) ‚Äî ‚ÄúAnalysing NAT64 Characteristics with RIPE Atlas‚Äù\n\nJude Campbell (Supervisor:Dimitris Pezaros)\n\nJack Spreckley (Supervisor: Lito Michala)\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nA Middleware for Automatic Composition and Mediation in IoT Systems (14 March, 2023)\n\nSpeaker: Yehia Elkhatib\n\nAbstract: In this talk, I will present Hetero-Genius, a middleware architecture that enables construction and mediation in Internet of Things (IoT) systems. IoT systems are deployed across physical spaces such as urban parks, residential areas, and highways. The services provided by such IoT deployments are constrained to specific devices and deployment contexts. While existing interoperability solutions enable the ‚Äúdesign time‚Äù development and deployment of IoT systems, it is often essential to dynamically compose systems that consist of other ‚Äúsmall scale‚Äù IoT systems. To achieve this, post-deployment composition is needed, i.e., runtime composition of diverse IoT devices and capabilities. Hetero-Genius supports system and service discoverability, as well as automatic composability. We demonstrate this using a real-world Internet of Vehicles (IoV) scenario, where developers can save up to 47% of their time when using Hetero-Genius as well as improve code correctness by 55% on average.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nSystems Seminar with external speaker ‚Äî Roland Bless (28 February, 2023)\n\nSpeaker: Dr Roland Bless\n\nRoland is an associate professor at KIT <https://telematics.tm.kit.edu/english/staff_bless.php>. He will attend in person next week and would be staying overnight.\n\nRoland will be delivering two talks. Please find the titles and abstracts below:\n\n1) \"KIRA ‚Äì Scalable Routing for Autonomous Control Planes\"\n\n==========================================================\n\nThis talk presents KIRA, new, highly scalable routing architecture that was specifically designed for being used in (autonomous) control planes (in-band and/or out-of-band). It aims at providing highly robust connectivity, it is ID-based, zero-touch and scales to large networks consisting of 100,000s of nodes. In contrast to traditional data plane routing protocols, prioritizes connectivity over route efficiency. It performs well in various different topologies (sparse, dense, random, regular etc.), supports link weights and multi-path routing as well and shows fast convergence even in drastic failure scenarios. Moreover, it is loop-free, route flapping-free, and uses an approach similar to label switching to forward the control plane packets efficiently. Furthermore, it optionally provides a built-in DHT (key-value store) and a highly efficient topology discovery mechanism.\n\n2) \"On Rate-based vs. Window-based Congestion Controls\"\n\n=======================================================\n\nThis talk discusses the fundamental difference between rate-based and window-based congestion controls. The recent note on \"Deprecating The TCP Macroscopic Model\" (https://dl.acm.org/doi/10.1145/3371934.3371956) has a point that the ACK clocking mechanism is often distorted and unreliable, but goes too far that congestion window-based approaches should not be considered any more as useful (\"we see that the era of TCP dynamics built upon self-clocked, window-based congestion control is coming to a close.\"). This talks tries to shed light on the questions \"What are the effects of the sheer existence of a congestion window?\" and \"What are pitfalls of rate based and congestion window-based approaches?\" A useful direction seems to be a careful combination of both methods.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nA novel threat modelling technique for GDPR-compliance (21 February, 2023)\n\nSpeaker: Nguyen Truong\n\nAbstract:\n\nIn recent years, data-driven applications are increasingly being deployed in all aspects of life including smart homes, smart cities, healthcare, and medical services. In such applications, Artificial Intelligence (AI) is profoundly employed in which personal data is collected and aggregated from heterogeneous sources before being processed using \"black-box\" algorithms in opaque centralised servers. As a consequence, preserving the data privacy and security of these applications is of paramount importance. Since May 2018, the new data protection legislation in EU member states and the UK, namely the General Data Protection Regulations, has come into force. The GDPR establishes heavy punishment for non-compliance as failing to comply with the GDPR can be penalised by both financial fine and reprimand, ban or suspension of the violator's business. This has called for a critical need for any applications and/or services processing personal data to have modelling tools for analysing data privacy threats and analysing compliance with sophisticated GDPR requirements.\n\nModelling techniques for detecting potential threats and specifying countermeasures to mitigate the vulnerabilities play a significant role in securing personal data from a variety of data breaches and privacy attacks. Indeed, numerous threat modelling techniques have been proposed in the literature such as STRIDE, PASTA, and LINDDUN but they are only focusing on modelling security threats (STRIDE, PASTA ) and privacy threats based on the security threats (LINDDUN). None of them is sufficient to model the privacy threats, particularly the GDPR-compliance, in a complex system and/or application such as autonomous systems and heath-care services - in which a large amount of heterogeneous personal data is collected from various sources, then processed, manipulated, and shared with numerous third parties. Our research work aims to develop a novel threat modelling technique taking GDPR requirements as the baseline to address the risks of compliance for telehealth systems, and as a result, mitigate data privacy threats in the system. For this purpose, we have been developing the proposed GDPR-compliance threat modelling technique by conducting the following items:\n\nNew System Modelling: An autonomous system would be modelled utilising STRIDE Data Flow Diagram integrated with new concepts defined in the GDPR requirements.\n\nA knowledge base for GDPR-compliance threats: We are building a knowledge base for the compliance threats and integrating it with the existing knowledge base of the security and privacy threats in STRIDE.\n\nInference Engines for GDPR-compliance: We aim to develop a novel inference algorithm for reasoning the GDPR-compliance threats based on the knowledge base we develop in item-2. This inference engine can then be integrated with the STRIDE Microsoft modelling tool for better user interface and convenience.\n\nWe have demonstrated the idea of the proposed technique using the existing tool for STRIDE developed by Microsoft in the scenario of telehealth systems, which has shown the feasibility and prospect of this novel threat modelling technique. Further research to strengthen the proposal will be followed.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nLeveraging Low-Carbon Energy for Flexible Compute Workloads in Cloud and Edge Environments (14 February, 2023)\n\nSpeaker: Lauritz Thamsen\n\nThe growing energy demand for cloud and edge computing stands to have a considerable impact on the environment. Data centres already consume more than 1% of the globally produced energy and this share is expected to rise considerably over the next few decades when even more computing will be performed on cloud infrastructure. If nothing changes, this will result in large amounts of additional carbon emissions.\n\nOne approach to this problem is to take carbon emissions into account when scheduling and placing compute workloads, since the carbon intensity of power grids is often not constant, and some computational resources are also connected to renewable energy sources. Therefore, delay-tolerant workloads can be scheduled to cloud and edge resources based on the availability of low-carbon energy.\n\nIn this talk, I will summarize our recent work towards carbon-aware scheduling for cloud and edge workloads, looking at infrastructure equipped with grid energy or renewable energy sources. Our results indicate a significant potential to reduce emissions for large flexible compute workloads, such as large-scale batch processing and machine learning training, as long as there is flexibility as to when results are needed.\n\nFor instance, shifting workloads whose results are not needed before the next workday can already reduce emissions from grid energy by over 5%, while scheduling workloads over multiple days can lower emissions by around 20%. Moreover, load and energy forecasts can be used to run flexible workloads exclusively on renewable excess energy and spare compute capacity, driving down the operational carbon emissions of workloads substantially.\n\nThis seminar will be in person in SAW/b 422 and available on Zoom.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nFirst Come First Served: The Impact of File Position on Code Review (07 February, 2023)\n\nSpeaker: G√ºl Calikli\n\nThe most popular code review tools (e.g., Gerrit and GitHub) present the files to review sorted in alphabetical order. Could this choice or, more generally, the relative position in which a file is presented bias the outcome of code reviews? We investigate this hypothesis by triangulating complementary evidence in a two-step study. First, we observe developers‚Äô code review activity. We analyse the review comments pertaining to 219,476 Pull Requests (PRs) from 138 popular Java projects on GitHub. We found files shown earlier in a PR to receive more comments than files shown later, also when controlling for possible confounding factors: e.g., the presence of discussion threads or the lines added in a file. Second, we measure the impact of file position on defect finding in code review. Recruiting 106 participants, we conduct an online controlled experiment in which we measure participants‚Äô performance in detecting two unrelated defects seeded into two different files. Participants are assigned to one of two treatments in which the position of the defective files is switched. For one type of defect, participants are not affected by its file‚Äôs position; for the other, they have 64% lower odds to identify it when its file is last as opposed to first. Overall, our findings provide evidence that the relative position in which files are presented has an impact on code reviews‚Äô outcome; we discuss these results and implications for tool design and code review.\n\nThis seminar will be available online and in person.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nInferring Human Emotions from Robot's Motion in the Tele-Operation Systems (24 January, 2023)\n\nSpeaker: Emma Li\n\nTele-Operation systems allow human operators to control a remote robot to interact with the local environment and execute tasks. The systems can be applied in many fields, such as healthcare, surgery, education, entertainment, etc. Detecting operator‚Äôs emotions becomes crucial the system is used for operator to conduct mission-critical tasks, such as tele-surgery, nuclear waste cleaning and remote driving. For example, when a user controls a remote robot to perform surgery with intense or extreme emotion, the user may conduct an imprecise operation and causes serious injuries to a patient. In remote driving scenario, driver can be warned when stressed and tired emotions are detected. In addition, when emotions are detected in the operation, special AI methods could be applied to assist the robot control for better performance. In this talk, I will introduce our recent work on inferring human emotions using the data collected from the motion-controlled robot arm testbed.\n\nZoom Link: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nDesign and evaluation of IPFS: a storage layer for the decentralized web (17 January, 2023)\n\nSpeaker: Dr Ignacio Castro\n\nRecent years have witnessed growing consolidation of web operations. For example, the majority of web traffic now originates from a few organizations, and even micro-websites often choose to host on large pre-existing cloud infrastructures. In response to this, the \"Decentralized Web\" attempts to distribute ownership and operation of web services more evenly. This paper describes the design and implementation of the largest and most widely used Decentralized Web platform --- the InterPlanetary File System (IPFS) --- an open-source, content-addressable peer-to-peer network that provides distributed data storage and delivery. IPFS has millions of daily content retrievals and already underpins dozens of third-party applications. This paper evaluates the performance of IPFS by introducing a set of measurement methodologies that allow us to uncover the characteristics of peers in the IPFS network. We reveal presence in more than 2700 Autonomous Systems and 152 countries, the majority of which operate outside large central cloud providers like Amazon or Azure. We further evaluate IPFS performance, showing that both publication and retrieval delays are acceptable for a wide range of use cases. Finally, we share our datasets, experiences and lessons learned.\n\nBio: Ignacio Castro is Lecturer in Data Analytics at Queen Mary University of London. He obtained his PhD while researching at the Institute IMDEA Networks (Madrid, Spain), and visiting UC Berkeley (California, USA). His work sits at the intersection between economics and computer systems. His interest spans from online social networks and moderation to the macroscopic evolution of the Internet. He has been an investigator on three major EPSRC grants that hold over ¬£6 million in funding. His work appears in top tier journals and conferences including Web Conference, ACM SIGCOMM, ACM SIGMETRICS, ACM IMC, ICWSM, and IEEE/ACM Trans. on Networking. He also serves in multiple TPCs and organises top tier conferences including IMC, CoNEXT, and SIGCOMM.\n\nThis seminar will also be available on zoom: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nFlocking to Mastodon: Tracking the Great Twitter Migration (17 January, 2023)\n\nSpeaker: Dr Gareth Tyson\n\nOn October 27, 2022, Elon Musk acquired the world's largest micro-blogging platform, Twitter. As a self-proclaimed ``free speech absolutist'', this was a controversial and highly publicised event. The acquisition led to a series of chaotic events. As a consequence, Twitter experienced a mass migration of users. One of the recipient platforms has been Mastodon, a decentralized microblogging service. This presentation will discuss our measurements of the migration.\n\nBio: Gareth Tyson is an Assistant Professor at Hong Kong University of Science and Technology, and a Senior Lecturer at Queen Mary University of London. He regularly publishes in venues such as SIGCOMM, SIGMETRICS, WWW, INFOCOM, CoNEXT and IMC, alongside various top-tier IEEE/ACM Transactions. Over the last 5 years, he has been awarded over ¬£5 million in research funding and has received coverage from news outlets such as BBC, Washington Post, CNBC, New Scientist, MIT Tech Review, The Times, Slashdot, Daily Mail, Wired, Science Daily, Ars Technica, The Independent, Business Insider, The Register, as well as being interviewed on both TV and Radio. He regularly serves on numerous organising and program committee member for conferences such as ACM SIGCOMM, ACM SIGMETRICS, ACM IMC, ACM WWW, ACM CoNEXT, IEEE ICDCS and AAAI ICWSM.\n\nAvailable in SAWB 422 and online: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nInferring Human Emotions from Robot's Motion in the Tele-Operation Systems (13 December, 2022)\n\nSpeaker: Emma Li\n\nTele-Operation systems allow human operators to control a remote robot to interact with the local environment and execute tasks. The systems can be applied in many fields, such as healthcare, surgery, education, entertainment, etc. Detecting operator‚Äôs emotions becomes crucial the system is used for operator to conduct mission-critical tasks, such as tele-surgery, nuclear waste cleaning and remote driving. For example, when a user controls a remote robot to perform surgery with intense or extreme emotion, the user may conduct an imprecise operation and causes serious injuries to a patient. In remote driving scenario, driver can be warned when stressed and tired emotions are detected. In addition, when emotions are detected in the operation, special AI methods could be applied to assist the robot control for better performance. In this talk, I will introduce our recent work on inferring human emotions using the data collected from the motion-controlled robot arm testbed.\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nMeeting ID: 873 7115 8139\n\nPasscode: 212149\n\nTransfer-Tuning: Reusing Auto-Schedules for Efficient Tensor Program Code Generation (29 November, 2022)\n\nSpeaker: Perry Gibson\n\nAuto-scheduling for tensor programs is a process where a search algorithm automatically explores candidate schedules (program transformations) for a given program on a target hardware platform to improve its performance. However this can be a very time consuming process depending on the complexity of the tensor program and the capacity of the target device, with often many thousands of program variants being explored. To address this, in this paper we introduce the idea of transfer-tuning [1], a novel approach to identify and reuse auto-schedules between tensor programs. We demonstrate this concept using Deep Neural Networks (DNNs), taking sets of auto-schedules from pre-tuned DNNs and using them to reduce the inference time of a new DNN. We compare transfer-tuning against the state-of-the-art Ansor auto-scheduler, defining the maximum possible speedup for a given DNN model as what Ansor achieves using its recommended full tuning time. On a server-class CPU and across 11 widely used DNN models, we observe that transfer-tuning achieves up to 88.41% (49.13% on average) of this maximum speedup, while Ansor requires 6.5√ó more search time on average to match it. We also evaluate transfer-tuning on a constrained edge CPU and observe that the differences in search time are exacerbated, with Ansor requiring 10.8√ó more time on average to match transfer-tuning's speedup, which further demonstrates its value. Our code is available at https://www.github.com/gicLAB/transfer-tuning\n\n[1] https://arxiv.org/abs/2201.05587\n\nThis talk will also be available on Zoom for those unable to attend in person.\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nA Slice-Based Decentralized NFV Framework for an End-to-End QoS-Based Dynamic Resource Allocation (29 November, 2022)\n\nSpeaker: In√®s Djouela\n\nNetwork function virtualization concept has recently merged to solve network operators and service provider‚Äôs problems related to the non-flexibility of the traditional network and the increase of capital and operational expenditures (CAPEX and OPEX). ETSI has standardized an architectural framework to serve as a springboard for reflection to the application and the setup of the concept. However, that architecture presents many shortcomings and several challenges that have to be addressed. This talk focuses on two of those challenges, namely orchestration and resource allocation. To handle those challenges, we present a new original framework laying on the standardizes ETSI. The proposed framework aims at satisfying the subscriber‚Äôs Service Level Agreement and optimizes Telecom Service Provider fees under the scope of pay as you go concept. We highlight the three main steps of the NFV resource allocation process, namely chaining, mapping and scheduling.This talk will also be available on Zoom for those unable to attend in person.\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nApplying new technologies to UK MOD vehicles with UK GVA (22 November, 2022)\n\nSpeaker: Ian James\n\nIan James and Natasha Dell, will be coming into the school from Thales to present on 'Applying new technologies to UK MOD vehicles with UK GVA'.\n\nThales are involved in both standards and the latest technologies considered for UK MOD Vehicle Systems, primarily based on the UK Generic Vehicle Architecture (GVA). The UK GVA provides an electronic architecture platform which can be used to allow inclusion of a capability to a vehicle. This presentation looks at next generation capabilities such as improved situational awareness in an Urban Canyon and how an additional \"Digital Crew\" member might be able to help with workload. It looks at a Thales demonstration system built to confirm feasibility of these new capabilities. There is also a summary look at latest technology options being considered now for inclusion in the next applied research programmes.\n\nEmbedded Networks, Open systems, AI, Machine Learning, Image Processing, Optronics, Unmanned and Manned systems, Pattern of Life, Data Fusion, Safe networked capability\n\nIan and Natasha will have some time available after 3pm for additional discussion and questions.\n\nThis seminar will also be available on Zoom: https://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nThe Remarkable Longevity of the Richards Benchmark (15 November, 2022)\n\nSpeaker: Jeremy Singer\n\nThe Richards benchmark was originally developed as a low-level, portable system performance measurement tool in 1980, yet it remains in common use today and has been translated into a wid range of programming languages. In this talk, we explore the nature of the Richards benchmark and discuss how its properties contribute to its longevity, which may provide useful insights for contemporary benchmark designers.\n\nThis seminar will also be available on Zoom:\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nTruSDEd: Composable, Efficient, Secure XDP Service Function Chaining on Single-Board Computers (08 November, 2022)\n\nSpeaker: Kyle Simpson\n\nIoT and sensor networks are commonplace and are often used to monitor public infrastructure, but have earned something of a reputation for being insecure. Individual devices have questionable provenance, security fixes and software updates are not always guaranteed, and ‚Äòby-design‚Äô security of older deployments can be an afterthought.\n\nThe TruSDEd project aims to use cheap, commodity single-board compute (SBC) devices‚Äîlike Raspberry Pis and Intel NUCs‚Äîfor drop-in, reconfigurable defence via ingress/egress network traffic processing. The low traffic rates of these edge networks mean these devices are well-suited to the job in theory, but state-of-the-art service chaining frameworks rely on hardware features only found in server-grade hardware. New Linux kernel features like XDP and AF_XDP‚Äîcombined with memory-safe languages like Rust‚Äîoffer the tools to solve this mismatch, and this talk focusses on the (ongoing) design and implementation of an efficient, secure XDP-based software dataplane built to make best use of SBC devices.\n\nThis talk will also be available on Zoom for those unable to attend in person.\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nThe Web We Weave: Untangling the Social Graph of the IETF (25 October, 2022)\n\nSpeaker: Stephen McQuistin\n\nStephen will be presenting in SWAB 422 on 'The Web We Weave: Untangling the Social Graph of the IETF'\n\nAbstract: Protocol standards, defined by the Internet Engineering Task Force (IETF), are crucial to the successful operation of the Internet. In this talk, I‚Äôll describe a large-scale empirical study of IETF activities, with a focus on understanding collaborative activities, and how these underpin the publication of standards documents (RFCs). Using a unique dataset of 2.4 million emails, 8,711 RFCs and 4,512 authors, I‚Äôll show the shifts and trends within the standards development process, and how protocol complexity and time to produce standards has increased.\n\nThis talk will also be available on Zoom for those unable to attend in person.\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nClassifying the Reliability of the Microservices Architecture (18 October, 2022)\n\nSpeaker: Adrian Ramsingh\n\nMicroservices are popular for web applications as they offer better scalability and reliability than monolithic architectures. Reliability is improved by loose coupling between individual microservices. However, in production systems, some microservices are tightly coupled or chained together.\n\nWe classify the reliability of microservices: if a minor microservice fails then the application continues to operate; if a critical microservice fails, the entire application fails. Combining reliability (minor/critical) with the established classifications of dependence (individual/chained) and state (stateful/stateless) defines a new three-dimensional space: the Microservices Dependency State Reliability (MDSR) classification.\n\nUsing three web application case studies (Hipster-Shop, Jupyter and WordPress) we identify microservice instances that exemplify the six points in MDSR. We present a prototype static analyser that can identify all six classes in Flask web applications and apply it to seven applications. We explore case study examples that exhibit either a known reliability pattern or a bad smell.\n\nWe show that our prototype static analyser can identify three of six patterns/bad smells in Flask web applications. Hence MDSR provides a structured classification of microservice software with the potential to improve reliability. Finally, we evaluate the reliability implications of the different MDSR classes by running the case study applications against a fault injector.\n\nAdrian will be presenting in SWAB 422, but you can also join via zoom:\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nSystems Seminar (11 October, 2022)\n\nSpeaker: Dimitrios Pezaros\n\nOverview and update of the Section, welcome new members, and, if time allows, talk about research too.\n\nIt will be held in SAWB 422 and online.\n\nhttps://uofglasgow.zoom.us/j/87371158139?pwd=N3Y4OHZpblp1OFYzNGFOc25kT0NvQT09\n\nSECDA: Efficient Hardware/Software Co-Design of FPGA-based DNN Accelerators for Edge Inference (21 June, 2022)\n\nSpeaker: Jude Haris\n\nEdge computing devices inherently face tight resource constraints, which is especially apparent when deploying Deep Neural Networks (DNN) with high memory and compute demands. FPGAs are commonly available in edge devices. Since these reconfigurable circuits can achieve higher throughput and lower power consumption than general-purpose processors, they are especially well-suited for DNN acceleration. However, existing solutions for designing FPGA-based DNN accelerators for edge devices come with high development overheads, given the cost of repeated FPGA synthesis passes, and reimplementation in a Hardware Description Language (HDL) of the simulated design, and accelerator system integration.\n\nDuring the presentation, we discuss SECDA, a new hardware/software co-design methodology to reduce the design time of optimized DNN inference accelerators on edge devices with FPGAs. SECDA combines cost-effective SystemC simulation with hardware execution, streamlining design space exploration and the development process via reduced design evaluation time. As a case study, we use SECDA to efficiently develop two different DNN accelerator designs on a PYNQ-Z1 board, a platform that includes an edge FPGA. This work has been published at SBAC-PAD 2021.\n\nDependability and Data Analytics: A Match made in the Cloud (20 June, 2022)\n\nSpeaker: Saurabh Bagchi\n\nAbstract :\n\nWe live in a data-driven world as everyone around has been telling us for some time. Everything is generating data, in volumes and at high rates, from the sensors embedded in our physical spaces to the large number of machines in data centers which are being monitored for a wide variety of metrics. The question that we pose is: Can all this data be used for improving the dependability of cloud computing systems?\n\nDependability is the property that a computing system continues to provide its functionality despite the introduction of faults, either accidental faults (design defects, environmental effects, etc.) or maliciously introduced faults (security attacks, external or internal). We have been addressing the dependability challenge through large-scale data analytics applied end-to-end fromthe small (networked embedded systems, mobile and wearable devices) [e.g., CVPR-22, Eurosys-22, NeurIPS-20, Sensys-20,UsenixSec-20, NDSS-20] to the large (edge and cloud systems, distributed machine learning clusters) [e.g., OSDI-22, Sigmetrics-22, UsenixATC-21,DSN-20,UsenixATC-20]. In this talk, I will first give a high-level view of how data analytics has been brought to bear on dependability challenges, and key insights arising from work done by the technical community broadly. Then I will do a deep dive into the problem of configuring complex cloud systems to meet dependability and performance requirements, using data-driven decisions.\n\nFor the detailed part, I will show how distributed applications on the cloud can be configured for dependability and predictable performance even as the workloads are changing unpredictably. I will then discuss an exciting and emerging area of cloud computing called serverless applications on the cloud and show they can be configured for dependability and performance determinism.\n\nSpeaker :\n\nSaurabh Bagchi is a Professor in the School of Electrical and Computer Engineering and the Department of Computer Science at Purdue University in West Lafayette, Indiana, USA. He is the founding Director of a university-wide resiliency center at Purdue called CRISP (2017-present) and leads the Army‚Äôs Assured Autonomous Innovation Institute (A2I2) at Purdue. He is a Fellow of the Institute of Engineering and Technology (IET) and the recipient of the Alexander von Humboldt Research Award (2018), an Adobe Research Award (2021, 2017), the AT&T Labs VURI Award (2016), the Google Faculty Award (2015), and the IBM Faculty Award (2014). He serves on the IEEE Computer Society Board of Governors and is a selected member of the International Federation for Information Processing (IFIP). Saurabh's research interest is in distributed systems and dependable computing. He is proudest of the 23 PhD and about 50 Masters thesis students who have graduated from his research group and who are in various stages of building wonderful careers in industry or academia. In his group, he and his students have far too much fun building and breaking real systems for the greater good. Saurabh received his MS and PhD degrees from the University of Illinois at Urbana-Champaign and his BS degree from the Indian Institute of Technology Kharagpur, all in Computer Science. He is the co-founder and CTO of a cloud computing startup, KeyByte.\n\nContinuous Performance Testing in Virtual Time (14 June, 2022)\n\nSpeaker: Robert Chatley\n\nAbstract :\n\nTest-Driven Development (TDD) can give us a lot of information about functional correctness of a software system, but the way it is generally used currently cannot give much information on the performance characteristics of the implemented system. We typically do not find out about performance problems until the whole system is tested together, or worse, when it fails in production. In this talk we introduce new techniques for constructing unit tests that allow us to explore performance characteristics and detect problems before deploying our software. We can use virtual time to run performance experiments without waiting for real time to elapse, so we can get the fast feedback we are used to from the TDD cycle.\n\nSpeaker :\n\nDr Robert Chatley - Director of Software Engineering Practice, Imperial College London.\n\nAfter completing his PhD in software engineering, Robert spent many years working in industry as a senior engineer and a consultant before returning to university life. His work now bridges industry and academia, focussing on developing skills and knowledge in software engineers to build technical competence and improve developer productivity. His role at Imperial combines a strong focus on education with industry-focussed research. He is also director of the EdTech Lab for the Department of Computing at Imperial, leading an internal open-source community developing software supporting learning and teaching.\n\nMachine Learning on the Edge - Challenges, Opportunities and Solutions (07 June, 2022)\n\nSpeaker: Blesson Varghese\n\nAbstract\n\nMachine learning (ML) on the edge is premised on (pre)processing data nearer to the source where it is generated rather than heavily relying on distant hyperclouds. This premise underpins many high-value and emerging distributed applications of scientific and societal relevance. However, many existing ML algorithms are not designed to run in relatively resource constrained environments. This talk will present the opportunities in offloading within the context of ML to alleviate the computational burden on frugal resources by leveraging the edge. Using federated learning as an example, the talk will highlight how the challenges of stragglers due to computational heterogeneity and of adapting to changing operational conditions are addressed.\n\nSpeaker\n\nBlesson Varghese is a Reader in Computer Science at the University of St Andrews and directs the Edge Computing Hub (https://edgehub.co.uk/). He was the recipient of the 2021 IEEE Technical Committee on the Internet Rising Star Award for fundamental contributions to edge computing and held a Royal Society industry fellowship for exploring trust at the edge with UK‚Äôs largest telecoms and network providers, BT. His current interests are at the intersection of distributed systems and machine learning. More information is available at https://www.blessonv.com.\n\nWiring Circuits is easy as 0-1-Omega, or is it... (31 May, 2022)\n\nSpeaker: Jan De Muijnck-Hughes\n\nQuantitative types allow us to reason more precisely about term usage in\n\nour programming languages. There are, however, other styles of language\n\nin which quantitative typing is beneficial: Hardware Description\n\nLanguages (HDLs) for one. When wiring the components together it is\n\nimportant to ensure that there are no unused ports or dangling wires.\n\nHere the notion of usage is different to that found in general-purpose\n\nlanguages. Although many linearity checks are detectable using static\n\nanalysis tools such as Verilator, it is really interesting to\n\ninvestigate how we can use /fancy types/ (specifically\n\nquantitative-type-theory \\& dependent types) to make wire usage an\n\nintrinsic check within the type-system itself. With these /fancy types/\n\nwe can provide compile-time checks that all wires and ports have been used.\n\nPast work (unpublished) has seen me develop a novel orchestration\n\nlanguage that uses fancy types to reason about module orchestration.\n\nToday, however, I want talk about my work in /retrofitting/ a fancy-type\n\nsystem ontop of an existing HDL.\n\nSpecifically, I have concentrated my efforts at the 'bottom' of the\n\nsynthesis chain of SystemVerilog to type their netlists, a format from\n\nwhich hardware can be generated (fabless and fabbed). From this\n\nfoundation, future work will be to promote my fancy-types: up the\n\nsynthesis chain to a more comprehensive version of SystemVerilog; to new\n\nand better HDLs; or for similar application domains such as algebraic\n\ncircuits in Zero-Knowledge proofs.\n\nI will begin by introducing an unrestricted simply-typed netlist\n\nlanguage and the design issues faced when capturing SystemVerilog's\n\n/interesting/ design choices. I will then describe how we can formally\n\nattest to the type-safety of our type-system. Lastly, I will detail how\n\nwe can retrofit a linearly-wired type system ontop of the same syntax.\n\nAnomaly Diagnosis in Cyber-Physical Systems (24 May, 2022)\n\nSpeaker: Marco Cook\n\nProgrammable Logic Controllers (PLCs) play a vital role in controlling cyber-physical system (CPS) processes and consequently have become a primary target for cyber attacks that aim to disrupt CPS. By contrast, with conventional networked setups, the operational and safety-critical importance of PLCs introduce challenges for CNI operators on empirically determining if an incident is a cyber-attack or a system fault as both occurrences can display similar outputs on the physical process. In this talk, I will present a novel framework for PLC anomaly diagnosis defined by a two-stage identification and classification approach based on novelty detection that we have evaluated using a representative ICS water treatment testbed.\n\nAccelerating Quantum Circuits on FPGAs (17 May, 2022)\n\nSpeaker: Youssef Moawad\n\nWe are well in the Noisy Intermediate Scale Quantum (NISQ) era of quantum computing. With the emergence of several quantum computers with access to many tens of qubits, and hundreds of qubits being the aim of the next decade or so, the demand for the development of algorithms which can take advantage of this technology has never been higher. To facilitate this in the near-term, efficient simulators for quantum hardware have to be developed. The Quantum Circuit Model is the most used computational model for interacting with current quantum hardware. Most simulators currently developed for the purpose of simulating quantum circuits target GPUs, typically on multi-node systems with access to a large amount of distributed memory. While such systems are powerful enough to minimise the execution times of the circuits, today it is also important to consider the energy consumption of such systems. In this talk, a baseline FPGA-based architecture for the simulation of such circuits is pre"
    }
}