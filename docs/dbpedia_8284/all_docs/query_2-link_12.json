{
    "id": "dbpedia_8284_2",
    "rank": 12,
    "data": {
        "url": "https://stackoverflow.com/questions/25323560/most-efficient-way-to-insert-rows-into-mysql-database",
        "read_more_link": "",
        "language": "en",
        "title": "Most efficient way to insert Rows into MySQL Database",
        "top_image": "https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded",
        "meta_img": "https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded",
        "images": [
            "https://i.sstatic.net/mNxBk.gif?s=64",
            "https://i.sstatic.net/mNxBk.gif?s=64",
            "https://www.gravatar.com/avatar/190f1a13fc7735627a9b6720c21d9808?s=64&d=identicon&r=PG",
            "https://www.gravatar.com/avatar/cc039a638c98ade640dbc82b5ecf9d46?s=64&d=identicon&r=PG",
            "https://www.gravatar.com/avatar/1ee974306d2def46eb69534fbcf95cc5?s=64&d=identicon&r=PG",
            "https://www.gravatar.com/avatar/6bd50c6e3a3772e1162a06e99abfac9d?s=64&d=identicon&r=PG",
            "https://i.sstatic.net/MaCKR.jpg?s=64",
            "https://www.gravatar.com/avatar/2671acf34ae81acc1323e6dda264fb9c?s=64&d=identicon&r=PG&f=y&so-version=2",
            "https://www.gravatar.com/avatar/8f22fc024f7558aec045b877dbac1190?s=64&d=identicon&r=PG&f=y&so-version=2",
            "https://www.gravatar.com/avatar/1e94f8b74d12b6254ef3427017e2c1e8?s=64&d=identicon&r=PG&f=y&so-version=2",
            "https://i.sstatic.net/A4Efe.jpg?s=64",
            "https://i.sstatic.net/of7f7.png?s=64",
            "https://stackoverflow.com/posts/25323560/ivc/0d79?prg=affa98f8-7e8a-499a-a065-b70a8c472579"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2014-08-15T08:41:10",
        "summary": "",
        "meta_description": "I've read a lot of questions about that but i couldn't find one that is fast enough. I think there are better ways to insert a lot of rows into a MySQL Database\n\nI use the following code to insert ...",
        "meta_lang": "en",
        "meta_favicon": "https://cdn.sstatic.net/Sites/stackoverflow/Img/favicon.ico?v=ec617d715196",
        "meta_site_name": "Stack Overflow",
        "canonical_link": "https://stackoverflow.com/questions/25323560/most-efficient-way-to-insert-rows-into-mysql-database",
        "text": "Here is my \"multiple inserts\"-code.\n\nThe insertion of 100k rows took instead of 40 seconds only 3 seconds!!\n\npublic static void BulkToMySQL() { string ConnectionString = \"server=192.168.1xxx\"; StringBuilder sCommand = new StringBuilder(\"INSERT INTO User (FirstName, LastName) VALUES \"); using (MySqlConnection mConnection = new MySqlConnection(ConnectionString)) { List<string> Rows = new List<string>(); for (int i = 0; i < 100000; i++) { Rows.Add(string.Format(\"('{0}','{1}')\", MySqlHelper.EscapeString(\"test\"), MySqlHelper.EscapeString(\"test\"))); } sCommand.Append(string.Join(\",\", Rows)); sCommand.Append(\";\"); mConnection.Open(); using (MySqlCommand myCmd = new MySqlCommand(sCommand.ToString(), mConnection)) { myCmd.CommandType = CommandType.Text; myCmd.ExecuteNonQuery(); } } }\n\nThe created SQL-statement looks like this:\n\nINSERT INTO User (FirstName, LastName) VALUES ('test','test'),('test','test'),... ;\n\nUpdate: Thanks Salman A I added MySQLHelper.EscapeString to avoid code injection which is internally used when you use parameters.\n\nIf Add of AddWithValue does not escape strings, you must do such in advance to avoid SQL injection and syntax errors.\n\nBuild INSERT statements with only 1000 rows at a time. That should run easily 10 times as fast as what you started with (1 row per INSERT). Doing all 100K at once is risky and possibly slower. Risky because you might blow out some limit (packet size, etc); slower because of the need for a huge ROLLBACK log. COMMIT after each batch, or use autocommit=1.\n\nThis way may not be faster than the stringbuilder approach, but it is parameterized:\n\n/// <summary> /// Bulk insert some data, uses parameters /// </summary> /// <param name=\"table\">The Table Name</param> /// <param name=\"inserts\">Holds list of data to insert</param> /// <param name=\"batchSize\">executes the insert after batch lines</param> /// <param name=\"progress\">Progress reporting</param> public void BulkInsert(string table, MySQLBulkInsertData inserts, int batchSize = 100, IProgress<double> progress = null) { if (inserts.Count <= 0) throw new ArgumentException(\"Nothing to Insert\"); string insertcmd = string.Format(\"INSERT INTO `{0}` ({1}) VALUES \", table, inserts.Fields.Select(p => p.FieldName).ToCSV()); StringBuilder sb = new StringBuilder(); using (MySqlConnection conn = new MySqlConnection(ConnectionString)) using (MySqlCommand sqlExecCommand = conn.CreateCommand()) { conn.Open(); sb.AppendLine(insertcmd); for (int i = 0; i < inserts.Count; i++) { sb.AppendLine(ToParameterCSV(inserts.Fields, i)); for (int j = 0; j < inserts[i].Count(); j++) { sqlExecCommand.Parameters.AddWithValue(string.Format(\"{0}{1}\",inserts.Fields[j].FieldName,i), inserts[i][j]); } //commit if we are on the batch sizeor the last item if (i > 0 && (i%batchSize == 0 || i == inserts.Count - 1)) { sb.Append(\";\"); sqlExecCommand.CommandText = sb.ToString(); sqlExecCommand.ExecuteNonQuery(); //reset the stringBuilder sb.Clear(); sb.AppendLine(insertcmd); if (progress != null) { progress.Report((double)i/inserts.Count); } } else { sb.Append(\",\"); } } } }\n\nThis uses the helper classes as below:\n\n/// <summary> /// Helper class to builk insert data into a table /// </summary> public struct MySQLFieldDefinition { public MySQLFieldDefinition(string field, MySqlDbType type) : this() { FieldName = field; ParameterType = type; } public string FieldName { get; private set; } public MySqlDbType ParameterType { get; private set; } } /// ///You need to ensure the fieldnames are in the same order as the object[] array /// public class MySQLBulkInsertData : List<object[]> { public MySQLBulkInsertData(params MySQLFieldDefinition[] fieldnames) { Fields = fieldnames; } public MySQLFieldDefinition[] Fields { get; private set; } }\n\nAnd this helper method:\n\n/// <summary> /// Return a CSV string of the values in the list /// </summary> /// <returns></returns> /// <exception cref=\"ArgumentNullException\"></exception> private string ToParameterCSV(IEnumerable<MySQLFieldDefinition> p, int row) { string csv = p.Aggregate(string.Empty, (current, i) => string.IsNullOrEmpty(current) ? string.Format(\"@{0}{1}\",i.FieldName, row) : string.Format(\"{0},@{2}{1}\", current, row, i.FieldName)); return string.Format(\"({0})\", csv); }\n\nMaybe not super elegant but it works well. I require Progress tracking so that is included for me, feel free to remove that part.\n\nThis will produce SQL commands similar to your desired output.\n\nEDIT: ToCSV:\n\n/// <summary> /// Return a CSV string of the values in the list /// </summary> /// <param name=\"intValues\"></param> /// <param name=\"separator\"></param> /// <param name=\"encloser\"></param> /// <returns></returns> /// <exception cref=\"ArgumentNullException\"></exception> public static string ToCSV<T>(this IEnumerable<T> intValues, string separator = \",\", string encloser = \"\") { string result = String.Empty; foreach (T value in intValues) { result = String.IsNullOrEmpty(result) ? string.Format(\"{1}{0}{1}\", value, encloser) : String.Format(\"{0}{1}{3}{2}{3}\", result, separator, value, encloser); } return result; }\n\nOne way to accelerate would be wrapping all inserts into ONE transaction (SQL-Server code):\n\nusing (SqlConnection connection = new SqlConnection(CloudConfigurationManager.GetSetting(\"Sql.ConnectionString\"))) { conn.Open(); SqlTransaction transaction = conn.BeginTransaction(); try { foreach (string commandString in dbOperations) { SqlCommand cmd = new SqlCommand(commandString, conn, transaction); cmd.ExecuteNonQuery(); } transaction.Commit(); } // Here the execution is committed to the DB catch (Exception) { transaction.Rollback(); throw; } conn.Close(); }\n\nAnother way is to load the CSV-File into a datatable, and use the batching feature of DataAdapter\n\nDataTable dtInsertRows = GetDataTable(); SqlConnection connection = new SqlConnection(connectionString); SqlCommand command = new SqlCommand(\"sp_BatchInsert\", connection); command.CommandType = CommandType.StoredProcedure; command.UpdatedRowSource = UpdateRowSource.None; // Set the Parameter with appropriate Source Column Name command.Parameters.Add(\"@PersonId\", SqlDbType.Int, 4, dtInsertRows.Columns[0].ColumnName); command.Parameters.Add(\"@PersonName\", SqlDbType.VarChar, 100, dtInsertRows.Columns[1].ColumnName); SqlDataAdapter adpt = new SqlDataAdapter(); adpt.InsertCommand = command; // Specify the number of records to be Inserted/Updated in one go. Default is 1. adpt.UpdateBatchSize = 2; connection.Open(); int recordsInserted = adpt.Update(dtInsertRows); connection.Close();\n\nYou find a nice example here.\n\nOr you can use the MySQL BulkLoader C# class:\n\nvar bl = new MySqlBulkLoader(connection); bl.TableName = \"mytable\"; bl.FieldTerminator = \",\"; bl.LineTerminator = \"\\r\\n\"; bl.FileName = \"myfileformytable.csv\"; bl.NumberOfLinesToSkip = 1; var inserted = bl.Load(); Debug.Print(inserted + \" rows inserted.\");\n\nIf you do multiple inserts in one command, you might still squeeze an inch or two out by using StringBuilder instead of string.\n\nAs Stefan Steiger says, Bulk Insert is suitable for your situations.\n\nAnother trick is using staging tables, so instead of writing directly to the production table, you will write to staging one (which has the same structure). Having written all info you just swap tables. With staging aproach you will avoid locking tables for insertion (can be used for update and delete too), and this pattern is heavily used with MySQL in some projects.\n\nAlso, disabling table keys may speed up insertion, but also can introduce some problems when you enable them (only for MyISAM engine).\n\nAdded:\n\nLet's say you have table Products:\n\nProductId\n\nProductName\n\nProductPrice\n\nFor staging purpose you create a staging table called ProductsStaging, with the same set of columns.\n\nAll your operation you do on staging table:\n\nUpdateStagingTable(); SwapTables(); UpdateStagingTable();\n\nbecause after swap your staging table does not have the new data, you invoke the same method once again. In SwapTables() method you execute one SQL statement:\n\nRENAME TABLE Products TO ProductsTemp, ProductsStaging TO Products, ProductsTemp TO ProductsStagin;\n\nThe speed of data manipulations depends on the MySql engine (e.g. InnoDB, MyISAM etc.), so you can also speed up inserts by changing engine.\n\nI stumbled upon a similar problem while working with EF - MySQL. The EF inserts were way too slow and hence used the approach mentioned by fubo. To start with, the performance improved drastically (~20K records were inserted in ~10 seconds) but degraded as the table grew in size, with ~1M records in the table, the insertion took ~250 seconds.\n\nFinally figured out the issue! The PK of the table was of type GUID (UUID - char(36)). As UUIDs cannot index sequentially and every insert required the indexes to be rebuilt, it slowed down.\n\nThe fix was to replace the PK with bigint (or int) and set it as an identity column. This improved the performance, the insertions took an average of ~12 seconds with ~2M+ records in the table!\n\nThought I'd share this finding here just in case someone gets stuck on a similar problem!\n\nA bulk operation would be a good manner to lead with that. Something that read your properties and then create a bulk query for you...\n\nThere's a github repository that contains both useful methods: BulkInsert and BulkUpdate using MySql and EF6+.\n\nThe BulkUpdate/BulkInsert basically read all properties from your generic entity and then create the bulkquery for you.\n\nPs: This has been intended developed to my needs and the project is opened to who concerns to improve it or change it for a better solution that will worth to the community.\n\nPsÂ²: If it doesnt fulfill the trouble, try to make changes on the project to improve and achieve what you want, it's a good start at least.\n\nPlease, take a look at here"
    }
}