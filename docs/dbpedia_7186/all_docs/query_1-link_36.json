{
    "id": "dbpedia_7186_1",
    "rank": 36,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7855773/",
        "read_more_link": "",
        "language": "en",
        "title": "Spatial direction comprehension in images, arrows, and words in two patients with posterior cortical atrophy",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-nihpa.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7855773/bin/nihms-1651466-f0001.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7855773/bin/nihms-1651466-f0002.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7855773/bin/nihms-1651466-f0003.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7855773/bin/nihms-1651466-f0005.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7855773/bin/nihms-1651466-f0004.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Steven M. Weisberg",
            "Anjan Chatterjee"
        ],
        "publish_date": "2021-01-22T00:00:00",
        "summary": "",
        "meta_description": "To successfully move through the world, the brain constructs spatial representations that situate the body within the environment. Communicating spatial directions poses specific challenges to this process, in part because the format through which the ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7855773/",
        "text": "Getting lost, whether in the woods or in a poorly laid out hospital, can be a profoundly frightening and dangerous experience. Although spatial navigation can be cognitively demanding, informative and well-placed signs can ease the cognitive burden of knowing where one is and potentially prevent people from getting lost. Indeed, people use a variety of navigational tools - blazes on trees, compasses, maps, arrows, and verbal directions - to provide accessible and salient spatial directions. Despite the use of these tools, becoming lost is a particular challenge to the health and safety of older adults, particularly those with dementia. But what are effective ways to support spatial navigation behavior?\n\nOne approach to this question is to assess spatial direction comprehension within various formats. For example, spatial directions can be presented in words (“turn left”) in visual scenes (an image, a photograph, or a real-world scene containing distinct paths) and in what we have called schemas (like arrows pointing in particular directions). Visual schemas are a general class of a representational format in which the specific details of a concept are removed, but the depiction resembles how the concept appears in the world (Amorapanth et al., 2012; Kranjec et al., 2013; Quandt et al., 2017; Talmy, 2005). Research on actions (Quandt et al., 2017) and prepositions (Amorapanth et al., 2010) reveal distinct behavioral and neural processing of schemas compared to words and images.\n\nRecent work on spatial direction comprehension has revealed that schemas and words are processed more quickly and accurately compared to images (Weisberg et al., 2018). FMRI data has also revealed that the intraparietal sulcus (IPS) is key to representing spatial directions in real and virtual environments, as well as across formats (Schindler & Bartels, 2013; Weisberg et al., 2018). Whereas formats were processed separately by distinct regions of the brain (e.g., visual scenes activated the visual scene network; words activated the visual word-form area; and schemas activated lateral occipital complex), none of these regions contained information about spatial directions. Rather, multi-voxel pattern analysis revealed that the IPS distinguished spatial directions within images and across all three formats. These data suggest that the IPS plays a key role in transforming visual information into a usable spatial context. Although research has implicated the parietal lobes in spatial processing, no studies have determined whether alternate formats of information (e.g., from schemas or words) require the involvement of the parietal lobes. This gap has important theoretical implications for the necessity of parietal lobe function in spatial direction comprehension, as well as practical implications on how to provide spatial information to impaired navigators.\n\nPatients with posterior cortical atrophy (PCA) may provide insight into the involvement of the parietal lobes in spatial direction comprehension. A non-amnestic variant of Alzheimer’s disease, PCA results in loss of cortical tissue primarily in the parietal lobes, but also parts of the posterior temporal and occipital lobes (Crutch et al., 2017). Depending on the severity and location of the atrophy, patients produce a range of behavioral deficits, including visuospatial difficulties, 3D shape interpretation, (Gillebert et al., 2015), visual agnosias, and visual neglect. Given the involvement of the parietal lobes in processing spatial directions across formats, these patients are good candidates to test the hypothesis that the parietal lobe is involved in spatial direction comprehension.\n\nIn the present pre-registered study, we tested two PCA patients on their ability to interpret spatial directions within each of three formats: words, images, and schemas. We compared these patients to healthy older adults. Given the ambiguity in the fMRI findings on the involvement of the parietal lobes in spatial direction comprehension, we had two competing predictions about how PCA patients could show spatial deficits. On the one hand, since IPS may code for spatial information across all three formats, PCA patients might be impaired on all formats equally. On the other hand, since behavioral data suggested that words and schemas may elide the spatial processing required by the images, PCA patients may show disproportionate impairments on images, and relatively spared performance on the other formats.\n\nDiscussion\n\nDespite spatial deficits, comprehending spatial directions in words and schemas is a process that is relatively spared in posterior cortical atrophy. In a pre-registered behavioral study in two patients with PCA, one patient was significantly impaired on a non-spatial color task, suggesting processing deficits that were not confined to spatial directions. A second patient showed a classical dissociation in the predicted direction: he was significantly impaired on the spatial task, but had spared performance on the color task. This patient also showed dissociations among specific formats - words were unimpaired relative to schemas. Schemas were less impaired than images. These findings support the distinct aspects of spatial processing required by the three formats and provide a window into the role of the parietal lobes in comprehending spatial directions. This pattern of performance within the spatial task was not what we predicted in our pre-registration.\n\nIn the pre-registration, we predicted that schemas would be spared relative to words and images. Our prediction was based on prior research on PCA patients in which they have impairments on extracting relevant information from images (Crutch et al., 2012; Kas et al., 2011). Schemas, which contain and must be interpreted spatially, may have spared patients the most difficult aspects of spatial direction comprehension in images - extracting important visual cues from an informationally rich image while ignoring distracting or irrelevant details.\n\nConsistent with the behavioral data we collected in healthy young adults, we interpret the current data to indicate that schemas serve as a middle ground, sharing characteristics with both words and images. Like images, the spatial content of schemas make them more difficult to match across varying perceptual forms. Like words, schemas are easier to parse from the visual scene. In part, this latter characteristic is because of the design of the stimuli used in this experiment - schemas and words were overlaid on a white background. In a control experiment conducted in healthy young adults, we overlaid the schemas and words on backgrounds created by phase-scrambling the images. Phase-scrambling preserves the visual information in the images but scrambles the content (the phase-scrambled images appear like military tree camouflage or tie-dye). In that experiment, we observed no reaction time differences when the phase-scrambled (compared to the white) backgrounds were used. Determining whether PCA patients who show impairments on images also show impairments on schemas and words when they are overlaid on phase-scrambled images would be an important future direction.\n\nPerhaps these experiments capture the effects of mild neglect as a symptom of PCA. These patterns of performance are also consistent with observations that neglect and directional visual search deficits can emerge as visual displays become more complex (Chatterjee et al., 1999), which is more relevant for images than for schemas or words. Yet, these data are informative not because of the particular cognitive mechanism, but because the representational format (words vs. schemas vs. images) differentiates whether the spatial information can be represented. If neglect makes images more difficult to parse visually and thus more difficult to encode spatially but spares schemas and words, this provides insight into a spared processing stream that either elides the parietal lobes or relies less on their calculations.\n\nA remaining puzzle is what made schemas more difficult for the PCA patients compared to words. One possibility (for which we thank an anonymous reviewer for bringing to our attention) is that the patients had trouble assembling the visual parts of the arrows into a cohesive direction. If this were the case, we might expect spatial directions which had similarly oriented lines to be confused more frequently. Specifically, we might expect left/right turns to be more confusable in schemas, since both have the longest lines oriented in roughly the same directions for arrows (although this is not the case for chevrons). Our exploratory analysis revealed, however, that neither PCA patient was more likely to confuse left/right in schemas, although one patient did have this difficult in images.\n\nThe current study suggests that the PCA patients we tested did not have difficulty matching concepts with varying visual features. Although impaired relative to elderly control participants (who were near ceiling on all measures), both PCA patients were above chance on all tasks and formats. And, even the PCA patient who was impaired on images could activate and compare, for example, a large, blue “LEFT” to a small, orange “left.” This finding could indicate the either preserved function of the intact structure of the parietal lobes for this patient, compensation by other brain regions critically involved in non-visual matching, or the lack of necessity of the parietal lobes for this task.\n\nThese data could be critical in informing how to design spatial directions in real world environments that limit their visual complexity. For example, in settings where patients with PCA may be navigating, map and sign design may be most effective by virtue of being visually simple and free from clutter. For instance, images of intersections (at roads or buildings or railroad crossings) may be more difficult to interpret than schematic depictions of those same intersections. While the current paper suggests that words may be more effective in communicating simple directions, like left, right, or ahead, a critical future direction to consider is how to convey intermediate spatial directions (like slight or sharp turns, c.f. Weisberg et al., 2018) and how to best convey directions for multiple turns. More work is also needed to determine how different representational formats are transformed - e.g., how the word ‘left’ becomes represented in a way that guides a person’s motor system to actually turn left.\n\nOne limitation of the current study is that we do not know how the PCA patients we tested would perform in an ecologically-relevant navigational situation. The stimuli used in this study were static and non-immersive. Still, the data are consistent with the hypothesis that words, schemas, and images, for the matching task we used, are processed differently by the human brain. Overall, our findings suggest that PCA patients may struggle to extract spatial directions from visually complex scenes, yet have an intact ability to compute spatial directions from simpler stimuli for use in navigation."
    }
}