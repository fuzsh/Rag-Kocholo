{
    "id": "wrong_mix_property_subsidiary_00101_1",
    "rank": 96,
    "data": {
        "url": "https://www.intgovforum.org/en/igf-2023-reports",
        "read_more_link": "",
        "language": "en",
        "title": "Internet Governance Forum",
        "top_image": "https://www.intgovforum.org/sites/default/files/inline-images/UN_logo_2022_emblem.png",
        "meta_img": "https://www.intgovforum.org/sites/default/files/inline-images/UN_logo_2022_emblem.png",
        "images": [
            "https://www.intgovforum.org/sites/default/files/igflogo2.png",
            "https://www.intgovforum.org/sites/default/files/2021-08/About-us.svg",
            "https://www.intgovforum.org/sites/default/files/2022-06/IMG_5053_45.jpg",
            "https://www.intgovforum.org/sites/default/files/2023-11/IGF_2024.svg",
            "https://www.intgovforum.org/sites/default/files/2023-09/IGF%202023%20icon.svg",
            "https://www.intgovforum.org/sites/default/files/2021-04/Intersessional.svg",
            "https://www.intgovforum.org/sites/default/files/2021-07/IGF_Initiatives.svg",
            "https://www.intgovforum.org/sites/default/files/2021-07/Publication_Reports.svg",
            "https://www.intgovforum.org/sites/default/files/2021-08/calendar_0.svg",
            "https://www.intgovforum.org/sites/default/files/2021-04/Press_0.svg",
            "https://www.intgovforum.org/sites/default/files/inline-images/UN_logo_2022_emblem.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/sites/default/files/inline-images/UN_logo_2022_emblem.png",
        "meta_site_name": "",
        "canonical_link": "https://www.intgovforum.org/en/igf-2023-reports",
        "text": "The DC session of the Internet Rights and Principles Coalition (IRPC) took place in two separate sections, a first presentation of remarks by speakers, and a second half of interactive group workshops. Between in-person and online attendance up to 50 people participated in the session.\n\nPanel Phase\n\nHelani Galpaya\n\nThe Global Digital Compact (GDC) is praised for its focus on human rights but lacks clear guidelines on implementing business and human rights principles within its framework. The voluntary nature of these principles and ineffective stakeholder integration slow progress, with separate discussions among businesses and civil society instead of meaningful interactions. The draft document does not support effective collaboration among stakeholders, and the GDC struggles to hold nations accountable for human rights violations by private companies and states. Although the GDC acknowledges the link between human rights and socio-economic rights, addressing inequality, there is a significant gap between its vision and real-world application. Proposed regulations often restrict rights, and there's urgency in their enactment, compromising the GDC’s credibility. Additionally, the GDC underscores the importance of teaching online civic responsibility, drawing parallels with environmental protection efforts to highlight the role of individual actions in creating a safe digital space. Despite efforts to make its consultation process inclusive, it remains imperfect and dominated by privileged voices. Effective ground-level actions are essential after the GDC’s establishment to ensure national policies reflect its principles and objectives. While the GDC commits to human rights and socio-economic issues, it faces challenges in clarity, stakeholder engagement, and enforcement, undermining its impact. However, emphasizing individual online responsibilities and improving consultation inclusivity are crucial for meaningful outcomes.\n\nRaashi Saxena\n\nThe GDC is a joint effort by the UN, governments, and civil society to integrate technology with the Sustainable Development Goals (SDGs) through a multi-stakeholder approach. The Internet Rights and Principles Coalition plays a key role in the GDC by promoting digital inclusion and connectivity for marginalized groups like women, migrants, and refugees, supporting SDG 10 – Reduced Inequalities. Ensuring that human rights in digital spaces match those offline, particularly in areas like freedom of expression and net neutrality, is vital for SDG 16 – Peace, Justice, and Strong Institutions. The influence of Artificial Intelligence (AI) in sectors like finance and health, and its challenges, including privacy and the rise of deep fakes, impact SDG 3 – Good Health and Wellbeing, and SDG 8 – Decent Work and Economic Growth. The IRPC emphasizes partnerships and youth involvement, aligning with SDG 17 – Partnerships for the Goals and SDG 9 – Industry, Innovation, and Infrastructure. During IRPC events, interactive group activities foster engagement and idea exchange, promoting a collaborative digital future and advancing the SDGs.\n\nSantosh Sigdel\n\nThe Dynamic Coalition on Internet Rights and Principles is committed to upholding human rights online, creating the multilingual Charter of Human Rights and Principles for the Internet, now available in 28 languages, to facilitate global and regional stakeholder engagement. The IRPC promotes a rights-based approach to Internet frameworks and has participated in various global forums, including EuroDIG and UNESCO conferences, raising awareness about digital rights and fostering collaborations. Highlighting the importance of accurate and culturally relevant translations, the IRPC engages local stakeholders in the translation process to ensure integrity and build local understanding of the charter's principles. This not only aids in language translation but also inculcates a deep understanding of human rights among local communities, empowering them to advocate and enforce these principles. However, balancing the regulation of online misinformation with freedom of speech presents challenges, particularly as governments may use regulatory measures to suppress free expression. This issue is prevalent e.g. in South Asia, where Internet regulations often threaten freedom of speech. Moreover, awareness of the United Nations' Global Digital Compact remains low in South Asia and other developing regions, impacting its effectiveness. Ensuring broad stakeholder involvement from diverse regions is crucial for the GDC’s success. In summary, the IRPC's work in translating and promoting human rights online, while building local capacities and raising awareness, is vital. Nonetheless, ongoing efforts to maintain freedom of speech in the face of regulatory challenges and to enhance global engagement with initiatives like the GDC are essential for a rights-centric digital world.\n\nWolfgang Benedek\n\nWolfgang Benedek criticizes what we know about the Global Digital Compact for its limited progress in advancing human rights. He points out two main flaws: the compact's lack of enforcement mechanisms and the difficulty in achieving consensus among stakeholders. These weaknesses, Benedek argues, hinder the GDC's ability to effectively promote and protect digital human rights. He emphasizes the need for stronger enforcement and more collaborative decision-making to enhance the GDC’s impact on digital human rights.\n\nDennis Redeker\n\nAs far as work of the Coalition is concerned, key developments included the translation of the 10 Principles document into Japanese to engage more local stakeholders and there are concrete plans to translate the entire Charter into Japanese until IGF 2024. To support this, a task force is seeking experts in Internet governance or international law. Dennis also pointed out that the Platform Governance Survey, conducted at the University of Bremen, highlighted a discrepancy between the expected and actual influence in shaping the GDC, with technical experts viewed as ideal leaders but businesses seen as overly dominant. In addition, the general population of 41 countries does not appear to be aware of the important role of governments in the negotiation of the GDC. The results underscore the need for broader public consultation, involving citizens, NGOs, and academics to create a more inclusive digital governance framework. The Internet Rights and Principles Coalition is advancing this inclusivity by collaborating on translations with universities and student groups, enriching students' understanding of digital rights.\n\nGroup Phase\n\nDennis Redeker led a group discussion as part of the workshop, encouraging participants to analyze and discuss future challenges related to specific IRPC Charter articles. This activity aimed to deepen understanding and disseminate knowledge about the charter's relevance.\n\nAudience\n\nThe audience discussed and emphasized the following topics:\n\n1. Youth and diversity in Internet governance emphasizing the importance of involving young people in updating and translating governance documents to reflect diverse perspectives.\n\n2. Freedom of expression: Discussed the need to balance regulation and protection of free speech, emphasizing principles like legitimacy, necessity, and proportionality to prevent government overreach.\n\n3. Responsibilities in the digital space, stressing the importance of clearly defining roles for states, businesses, and stakeholders in upholding human rights when regulating online content and protecting against harmful information.\n\n4. Inclusivity and accessibility, acknowledging advancements and ongoing challenges in making technology accessible for individuals with disabilities, including variations in regional sign languages and Internet accessibility.\n\n5. Protection of children and their rights, addressing the need for careful regulation to protect children online, the potential impacts of digital certificates on human rights, and the necessity of strategic litigation to safeguard digital rights against overreaching government actions.\n\nVint Cerf (in the audience) emphasizes the need for users and providers in the digital space to understand and fulfill their responsibilities alongside rights. He links this to Rousseau's social contract concept, which balances individual freedoms with societal obligations. This approach, including the role of social norms, aims to foster a responsible, secure online environment. Ultimately, recognizing and upholding our duties can enhance harmony both online and in broader society.\n\nThe inequality of the digital economy presents an urgent challenge to development and democracy. If Agenda 2030 is to be realized, bold and committed action is needed to a) share the benefits of digitalization with all countries and peoples, b) govern digital resources democratically, and c) make digital policies and laws fit for catalyzing innovation that counts. The ultimate test for a well-guided digital transition is in the public and social value it can create, and the human freedoms it can expand. The political declaration adopted at the High-Level Political Forum on Sustainable Development in September 2023, rightly alludes to the participation of all countries in the digital economy. Its focus on infrastructure, connectivity, and the affirmation of digital rights of people is noteworthy. The Global Digital Compact (GDC) will need to carry this consensus forward, with nuances of the particularities required for our common digital future.\n\nThe 2023 Internet Governance Forum (IGF) pre-event in Kyoto on ‘A Global Compact for Digital Justice: Southern Perspectives’ was proposed by the Global Digital Justice Forum, the Dynamic Coalition on Platform Responsibility, and the Dynamic Coalition on Internet Rights and Principles to explore the central question: how can we build a GDC that furthers digital justice, especially in the majority world?\n\nThe event brought together speakers from governments and civil society in a multistakeholder dialogue structured in an innovative ‘BUILD IT, BREAK IT, FIX IT’ format.\n\nThe BUILD IT round delved into the promise of the GDC to fix global governance deficits in digital cooperation as seen from the prism of intergovernmental organizations in charge of the World Summit on the Information Society (WSIS) lines, governments, and civil society representatives. The following speakers made inputs during this round.\n\nAmandeep Singh Gill, UN Secretary-General's Envoy on Technology\n\nRegine Grienberger, Cyber Ambassador, German Federal Foreign Office\n\nShamika N. Sirimanne, Director, Division on Technology and Logistics, United Nations Conference on Trade and Development (UNCTAD)\n\nAlison Gillwald, Executive Director, Research ICT Africa\n\nRenata Avila, CEO, Open Knowledge Foundation\n\nThe session began with the UN Tech Envoy Amandeep Singh Gill’s inputs, who affirmed the idea of building through the GDC, a shared vision and a global framework for digital governance that is negotiated by governments but is open to participation by regional organizations, private sector, and civil society. He emphasized the need to a) shape a transition away from a solutions orientation to ecosystems and infrastructures for digital development, and b) go beyond the connectivity paradigm, and shift the attention towards digital public infrastructure to create inclusive innovation spaces that focus more on capacity.\n\nRegine Grienberger, Cyber Ambassador from the German Federal Foreign Office, began by acknowledging the continued digital gap/divide and its significant impact on the SDG process and suggested that this be an important focus of the GDC. Grienberger also advocated for the consultative process to take a local/national to global approach, and emphasized the need to engage in more cross-regional discussions, especially on issues like artificial intelligence (AI). Additionally, he made the critical observation that the GDC process needs to be anchored in the basic tenets enshrined in cornerstone UN documents, such as the Human Rights Charter.\n\nIn her input, Shamika Sirimanne from UNCTAD observed how the gains of connectivity have been skewed, with a few transnational corporations and nation-states being able to embrace the digital revolution optimally while others lag behind. Given that the structural inequalities in the digital order compound the effects of other inequalities, we are confronted increasingly by a digital inequality paradox, where, as more people are connected, digital inequality is amplified. In this context, Sirimanne underscored that the GDC process had an imperative to go beyond the connectivity paradigm and bridge the gap between actors who possess the technological and financial resources needed to harness the digital and those who don’t. She outlined the need for quality and affordability of access, skilling opportunities to navigate the digital economy, and equal participation of countries in the global regime to shape the rules of the game so that the opportunities of the digital paradigm could be reaped more equitably.\n\nMeanwhile, Alison Gillwald from Research ICT Africa pointed to the most pressing global challenges of our time, which include the climate crisis and the issue of widening inequality, including digital inequality as a starting point to her input. These need to be addressed through a collective and collaborative renewal of the social contract that was anchored in human rights and gender equality in order to rebuild trust and social cohesion and enhance digital inclusion. Like Sirimanne, Gillwald observed that the layering of advanced digital technologies over underlying structural inequalities compounds the effects of digital inequality, especially in regions with glaring infrastructure and capacity deficits like Africa. In this regard, she noted that the GDC process needed to focus on infrastructure and digital public goods.\n\nThe concluding input of the round came from Renata Avila from the Open Knowledge Foundation who argued that for many countries of the Global South contending with a severe debt crisis and lack of resources, decisive action that could address the geopolitics of global inequality and injustice was the top priority. Avila emphasized an urgent need for financing and international commitments for the development of digital infrastructure, skills, and regulatory capacities for all countries to navigate the terrain, as well as renewed commitments from international financial institutions towards these goals. Additionally, she pointed to the unmet promise of knowledge equality and the trend of knowledge capture of think tanks, academia, and civil society by Big Tech. In this regard, she held the reform of the IP regime as an important agenda for the GDC to take up.\n\nThe BREAK IT round in turn, critically interrogated the efficacy and effectiveness of the proposals in the GDC across its various dimensions, focusing on information disorder, AI and human rights, reining in Big Tech power, guaranteeing a free and open internet, and IGF reform for effective digital governance mechanisms at the global level. The following speakers made inputs as part of this round.\n\nHelani Galpaya, CEO, LIRNE Asia\n\nAlexandre Costa Barbosa, Fellow for the Weizenbaum Institute and Homeless Workers Movement - Technology Sector, Brazil\n\nNandini Chami, Deputy Director, IT for Change\n\nMegan Kathure, Afronomicslaw\n\nDennis Redeker, University of Bremen and Digital Constitutionalism Network\n\nHelani Galpaya from LIRNE Asia noted in her critique of the GDC process that several developing countries when faced with an immense challenge of fiscal squeeze, focused on devoting resources to basic development needs and were unable to spare attention on digital governance issues, which compromised the dialogue and involvement within the process overall. Galpaya also highlighted the inability of the GDC to address the disparity of national regulations on critical issues such as taxation and grapple with the unacknowledged reality of a highly digitally fragmented landscape, which made consensus building a difficult proposition. Additionally, she pointed out the failures of the multilateral system in being unable to hold its own member states accountable for draconian digital laws and policies that were harmful to citizen rights, something that the GDC process had not really taken into account.\n\nIn his input, Alexandre Costa Barbosa from the Weizenbaum Institute and the Homeless Workers Movement - Technology Sector, Brazil, focused on the key aspect of sustainable digital public infrastructure (DPI) and the lack of clarity around the concept. In the absence of a multistakeholder dialogue or collective definition, this important aspect of the GDC was in danger of being defined and captured by a Big Tech spin of the discourse, rather than allow for the possibilities of interoperable, open, and accessible DPIs that are locally responsive. Barbosa additionally pointed to the silence on the critical issue of labor and contended that the GDC process must have more discussions on this topic in particular its connections to the field of generative AI.\n\nNandini Chami from IT for Change in her critique, underscored how the aspirations of the WSIS seem to be forgotten and waylaid in the GDC processes. She further observed that the reduction of data rights to privacy as is prone to, in current discourse simply erases data extractivism, which continues to be the fault line of geopolitical and geo-economic power. In this context the GDC process did not fully recognize thatrights in data extend to people’s claims over data resources, and their right to collectively determine how they see value generation from digital intelligence.\n\nPointing to the inversion of basic rules for the marketplace in the way Big Tech controls public functions, recasts society and citizens into individual users and consumers, and squeezes labor in the transnational AI chains, Chami urged the audience to push back against the silent consensus that Big Tech cannot be regulated. She called on political commitment to begin the change and member states to measure up in this regard.\n\nMeanwhile, Megan Kathure from Afronomicslaw observed that the historical choices in internet governance that had enabled the rise of Big Tech had also given rise to a narrative of ‘limits of multistakeholderism’ in bringing forth a global digital constitutionalism. She stressed that the fundamental issue with the current GDC process is that it risked entrenching the regulatory dilemma of global governance of the digital and affirming this narrative. In her input, Kathure highlighted two gaps in the current GDC process. The first is that it failed to acknowledge the complementarity of rights with state duties and simply expected states to refrain from certain actions without enshrining correspondent duties. She argued that the GDC must go beyond taking multilateral commitments from states and corporate actors and needed to outline a regime of consequences for inaction, thus dealing head on with the realpolitik of global digital governance. Second, Kathure observed that the GDCprocess did not conceptualize human rights holistically and discussed the factthat current proposals did not capture the indivisibility of human rights adequately.\n\nIn the concluding input for the round, Dennis Redeker from the University of Bremen and Digital Constitutionalism Network, highlighted emerging findings from research on how the general public in various countries viewed the consultative process. Redeker highlighted the discrepancies in agendas that dominated vis-à-vis those that people held as important and expressed wanting more involvement in, and pointed to the a consensus among general public about reduced involvement of the private sector in policy processes.\n\nIn the FIX IT round, the session rounded up responses towards the issues raised in order to conclude with a forward-looking roadmap on what the GDC needs to foreground for furthering an inclusive, people-centered, development-oriented digital future. The following speakers made inputs as part of this round.\n\nAna Cristina Ruelas, Senior Program Specialist, United Nations Educational, Scientific and Cultural Organization (UNESCO)\n\nAnriette Esterhuysen, Senior Advisor, APC\n\nPrapasiri “Nan” Suttisome, Project Officer, Digital Rights, Engage Media\n\nEmma Gibson, Global Coordinator, Alliance for Universal Digital Rights for Equality Now\n\nLuca Belli, Professor, Fundação Getulio Vargas (FGV) Law School, Rio de Janeiro\n\nAna Cristina Ruelas from UNESCO, highlighted the regulatory efforts undertaken by UNESCO for a new platform society. Ruelas observed that a lot of ground needed to be covered in the local-to-global regulation of social media platforms and the algorithmic control. Additionally, she pointed to the fact that no one actor could solve all issues and proposed the idea of a regulatory framework of networks, which would allow stakeholders to take a more interconnected approach to digital governance.\n\nAnriette Esterhuysen from APC urged stakeholders to look at the existing norms and principles in the digital space as a starting point. She also held that the GDC was not being meaningfully informed by the current state of digital inequality and urged for this tokenism to be challenged. What is to be put at the center is not the techno-fascination of the corporate narrative but a people-created and -controlled narrative. Esterhusyen called for a feminist and radical vision of digital transformation in this regard. She stressed on the importance of granular data and public statistics to allow for a clear cognizance of the depth and breadth of economic injustice and the uneven distribution of opportunities associated with the digital.\n\nPrapasiri “Nan” Suttisome from Engage Media, in her input, pointed out how powerful countries use free trade agreements to stifle digital rights of peoples and countries in the Global South. Trade rules are used to arm twist governments to hyperliberalize data flows, take away local autonomy of public authorities to govern transnational corporations and their algorithms, prevent the scrutiny of source code, and legitimize a permanent dependence of developing countries on the monopoly corporations controlling data and AI power. This kind of infrastructural dependence is tantamount to a neo-colonial order and Suttisome observed that unless the indecency and impunity of some actors in the digital space is countered, and countered now, any compact is bound to fail.\n\nMeanwhile, Emma Gibson in her input presented the work being undertaken by the Alliance for Universal Digital Rights (AUDRi) for Equality Now, and called for the adoption of a universal digital rights framework, rooted in human rights law and underpinned by an intersectional feminist perspective. The GDC needs to be a feminist process to be truly transformative. She presented the nine principles developed by AUDRi based on equal protection from persecution, discrimination, and abuse; equal access to information, opportunity, and community; and equal respect for privacy, identity, and self-expression\n\nIn the concluding input, Luca Belli from FGV presented three structural challenges that made the GDC process ineffective. Belli pointed to the issues fragmented landscape, which went beyond geography and also extended to the trend oftaking siloed regulatory approaches to digital issues; the presence of outsized political and economic interests that played against policy strategies (for instance between private sector and domestic governments) and the fact that for the private sector, the bottom line of shareholder interest always trumps public interest, making regulatory compliance a challenge at all times. By way of remedies, Belli suggested moving the GDC in a manner that grapples honestly and boldly with its implementation challenges.\n\nSession report: Can (generative) AI be compatible with Data protection?\n\nIGF 2023, October 10th, 2023, WS 10 - Room I\n\nThe session explored the tension between the development and use of AI systems, particularly generative AI systems such as ChatGPT, and data protection frameworks. The DC aims to present a diverse set of views, in the spirit of multistakeholder debate, from various sectors, countries, disciplines, and theoretical backgrounds.\n\nProfessor Luca Belli, Director of the Centre for Technology and Society at FGV Law School, opened and moderated the session. He discusses the concept of AI Sovereignty – “the capacity of a given country to understand, muster and develop AI systems, while retaining control, agency and, ultimately, self-determination over such systems”. Regulating generative AI is a complex web of geopolitical, sociotechnical, and legal considerations, whose core elements compose the AI Sovereignty Stack.\n\nArmando Manzueta, Digital Transformation Director, Ministry of Economy, Planning and Development of the Dominican Republic – gave insights on how governments can try to use generative AI in their infrastructure and public services. When an AI complies with data privacy laws along with a transparent decision-making mechanism, it has the power to usher in a new era of public services that can empower citizens and help restore trust in public entities improving workforce efficiency, reducing operational costs in public sectors, and supercharging digital modernization.\n\nGbenga Sesan, Executive Director, Paradigm Initiative, Nigeria – emphasized the role of existing data protection laws, but also how this ongoing discussion on generative AI opens an opportunity for the countries that do not yet have a data protection law to start considering introducing one to regulate mass data collection and processing. There is also a need to de-mystify AI and make it more understandable to people. Sesan also pointed out that there is a lack of diversity in the models of generative AI like ChatGPT, as well as a need to establish review policies or mechanisms when they deal with information on people.\n\nMelody Musoni, Policy Officer at the European Centre for Development Policy, South Africa – spoke on how African countries are taking steps to carve out their position as competitors in the development of AI. There is a need for AI to solve the problem in the African region. E.g., the digital transformation strategy showed the urgency for Africa to start looking into AI and innovation to develop African solutions. The speaker also mentioned setting up data centers through public-private partnerships.\n\nJonathan Mendoza, Secretary for Data Protection, National Institute of Transparency Access to Information and Protection of Personal Data (INAI), Mexico - explores current and prospective frameworks, giving a descriptive account of ongoing efforts to promote transparency and accountability. Due to the diverse nature of the population in the Latin American region, generative AI can pose a threat and therefore a policy to process personal data must be in place. There is also a need to balance the ethical designing of AI models and the implementation of AI to make these models more inclusive and sustainable while reducing potential threats.\n\nCamila Leite, Brazilian Consumers Association (Idec) - explored the general risks of AI on the Brazilian consumer population. Financial and Mobility services can immensely benefit from generative AI, however there have been instances in which the output from generative AI was found to be manipulative, discriminatory, and violated the privacy of people. It is important to put consumer rights and protection at the heart of policies regulating generative AI.\n\nWei Wang, University of Kong - elucidates the disparate conceptualizations of AI accountability among various stakeholders at the Chinese level, thereby facilitating an informed discussion about the ambiguity and implementability of normative frameworks governing AI, specifically regarding Generative AI. China has a sector-specific approach contrary to the comprehensive one as seen in the EU, UK, etc. China has established measures to comply with sectoral laws and Intellectual property laws.\n\nSmriti Parsheera, Researcher, CyberBRICS Project, India - discusses the why and how of transparency obligations, as articulated in the AI governance discussions in India and select international principles. She argues that the need for transparency permeates through the lifecycle of an AI project and identifies the policy layer, the technical layer, and the operational layer as the key sites for fostering transparency in AI projects.\n\nMichael Karanicolas, Executive Director, UCLA Institute for Technology, Law and Policy - argues for the need to develop AI standards beyond the “auspices of a handful of powerful regulatory blocs”, and calls for the inclusion of the Majority World into standard-setting processes in international fora.\n\nKamesh Shekar, Senior Programme Manager, Privacy & Data Governance Vertical, The Dialogue - argues for a principle-based approach coupled with a detailed classification of AI harms and impacts. He proposes a detailed multistakeholder approach that resonates with the foundational values of responsible AI envisioned by various jurisdictions geared toward ensuring that AI innovations align with societal values and priorities.\n\nKazim Rizvi, Founding Director, The Dialogue - spoke about domestic coordination of regulation and then international coordination. Alternative regulatory approaches can also be looked upon through public-private partnerships.\n\nGiuseppe Cicu, PhD Student at the University of Turin and corporate Lawyer at Galgano Law Firm - spoke about a framework to regulate AI by Corporate Design to fit together business management and AI governance concerns into a step-by-step implementation process, from strategic planning to optimization. He provided a game plan for responsible AI by bringing transparency and accountability into the organizational structure of the firm and having a human in the loop. The approach is grounded in the human rights global framework and privacy policies. He suggests that corporations introduce an ethic algorithmic legal committee.\n\nLiisa Janssens, LLM MA, scientist department Military Operations, unit Defence, Safety and Security, TNO the Netherlands Organisation for Applied Scientific Research - provides a focused responsible AI framework for military applications, developed through a scenario-setting methodology for considering AI regulation’s virtues and shortcomings. The disruptive nature of AI is considered in the face of the demands of Rule of Law mechanisms to trace the requirements that make up responsible use of AI in military.\n\nComments and questions: What are the key privacy principles at a normative level (e.g., transparency and data minimisation, purpose limitation) that should be ensured so that generative AI can comply with them? Will the data protection laws expand their scope to include non-personal data since most of the data to train a generative AI is non-personal data.\n\nModerator Olaf Kolkman introduced this Open Forum by elaborating on the role of modern security standards in securing the internet. He emphasized that we need to secure the internet for the common good. One of the challenges that comes with securing the internet is the slow adoption of security standards. Therefore, this Open Forum highlights tools that enhance the adoption of modern security standards.\n\nThe Role of Open Standards particularly in procurement, experiences in the Netherlands\n\nModern internet standards (such as IPv6, DNSSEC, HTTPS, DMARC, DANE and RPKI) are essential for an open, secure and resilient Internet that serves as a driver of social progress and economic growth. Gerben Klein Baltink and Annemieke Toersen explained the role of standards in procurement and their experiences in the Netherlands. The role of open standards in promoting a safer, more secure, and well-connected internet has become increasingly recognized, with initiatives like the internet.nl test tool which contribute significantly to this progress. The tool is primarily aimed at organizations, attracting both technical personnel and board members, and allows them to assess if their mail, website, and local connections comply with established standards.\n\nIn the procurement and supply chain management domain, the Forum Standaardisatie think tank has been actively promoting the use of open standards, advocating for more interoperability. With 25 members from government, businesses and science, the forum advises governments on the adoption of open standards, emphasizing their importance in promoting information exchange, ensuring interoperability, security, accessibility and vendor neutrality.\n\nThe Dutch government has pursued a three-fold strategy to promote open standards. Firstly, through the implementation of a \"comply or explain\" list of 40 open standards, carefully researched and consultated with experts. This have led to increased adoption, particularly in areas such as internet and security, document management and administrative processes, like e-invoicing. Government entities are mandated to use these standards, with required reporting if not followed.\n\nSecondly, the government has fostered national and international cooperation, facilitating workshops on modern email security standards within the EU, and engaging with prominent vendors and hosting companies such as Cisco, Microsoft, and Google. They have also facilitated the reuse of internet.nl code in various projects, such as aucheck.com and top.nic.br.\n\nFinally, the Dutch government actively monitors the adoption of open standards, evaluating tenders and procurement documents, and ensuring that the standards are included. Reports are submitted to the government, and efforts are made to support and guide vendors who may lagging behind in the adoption of these standards.\n\nLessons learned from these efforts emphasize the importance of consistently checking for open standards in procurement processes and providing guidance and support to encourage their usage. The comprehensive approach taken by the Dutch government, along with collaborations with various stakeholders, has contributed significantly to the wider adoption and implementation of open standards, fostering a more secure and interconnected digital environment.\n\nProcurement and Supply Chain Management and the Business Case\n\nWout de Natris and Mallory Knodel elaborated on the role of the Internet Standards, Security, and Safety dynamic coalition in enhancing internet security and safety through various initiatives. The coalition has established three working groups targeting Security by design on the Internet of Things, Education and Skills, Procurement and Supply Chain Management and the Business Case, aiming to contribute to a more secure online environment.\n\nTheir ongoing projects involve the deployment of DNSSEC and RPKI, exploring emerging technologies, and addressing data governance and privacy issues. They strive to persuade decision-makers to invest in secure internet standards by developing a persuasive narrative incorporating political, economic, social, and security arguments. The Procurement and Supply Chain Management and the Business Case working group have released a comprehensive report comparing global procurement policies, shedding light on existing practices and advocating for more transparent and secure procurement processes.\n\nThe coalition highlights the need for greater recognition and integration of open internet standards into government policies, emphasizing the importance of universal adoption of standards for data protection, network and infrastructure security, website and application security, and communication security. They aim to provide decision-makers and procurement officers with a practical tool that includes a list of urgent internet standards to guide their decision-making and procurement processes.\n\nBy focusing on streamlining and expediting the validation process for open internet standards in public procurement, the coalition seeks to enhance procurement policies, resulting in more secure and reliable digital infrastructure. Overall, their collaborative efforts and initiatives aim to create a safer online landscape for individuals, organizations, and governments by promoting the secure design and deployment of internet standards and advocating for the adoption of open internet standards in government policies.\n\nThe report from is3coalition.org highlights a concerning trend where governments fail to recognize the critical components that enable the internet to function effectively. This issue has been a recurring question in various research endeavors, prompting the Working Group (WG) to prioritize and compile existing security-related internet standards and best practices in the field of ICT.\n\nBest practice awards go to: the GDPR in the European Union provides common understanding and harmonization with regards to the security of information systems; the Dutch Ministry of the Interior and Kingdom Relations makes mandatory standards deployment. The ‘Pas toe of leg uit’-Lijst (comply-or-explain list) of the Dutch Standardisation Forum is a document containing 43 open standards that all governments in the Netherlands have to demand when procuring ICT; and Internet.nl: the tool used to track standards adoption by an organization’s website based on three indicators: website, email and connection. The software has been adopted in Australia, Brazil, Denmark and Singapore.\n\nIS3C provides decision-takers and procurement officers involved in ICTs procurement with a list containing the most urgent internet standards and related best practices. This assists them to take into account internet security and safety requirements and procure secure by design ICT products, services and devices, making their organizations as a whole more secure and safer. By raising awareness and emphasizing the significance of internet security and safety requirements, the report seeks to prompt officials to consider and integrate these crucial standards into their operational frameworks.\n\nTo gather insights and perspectives on this critical issue, the coalition is conducting a consultation on the report until November 5th at 10:00 UTC. This consultation aims to engage stakeholders and experts to discuss and address the challenges associated with the recognition and implementation of internet security standards by governments.\n\nReport: https://is3coalition.org/docs/is3c-working-group-5-report-and-list/\n\nPerspectives from India\n\nThere are many examples of good efforts and effective tools enhancing internet security. One of these examples comes from India. Mr. Satish Babu highlighted that the Trusted Internet India Initiative was initially established at the India School of Internet Governance (inSIG) in 2016 and has since 2018 been collaborating with the Global Forum for Cyber Expertise.\n\nInSIG organized GFCE’s Internet Infrastructure Initiative (Triple-I) Workshop in 2018, 2019, 2022 and 2023 as Day 0 events of inSIG. The Triple-I workshop seeks to “...enhance justified trust in the Internet” by building awareness and capacity on Internet-related international standards, norms and best practices. In its 2023 edition, the Triple-I workshop announced a new initiative that attempts to measure periodically the compliance of Indian websites, DNS and email services to modern security standards (to begin in 2024).\n\nDuring the T3I workshop, it was emphasized that digital technology plays a crucial role in fostering India’s growth. The digital public infrastructure, which serves over a billion citizens, facilitates applications related to financial health, logistics, and more. However, the workshop shed light on the existing weak levels of compliance within these systems. In response to this observation, volunteers associated with T3I conducted extensive research to identify areas of improvement.\n\nBuilding on their research findings, the initiative now plans to conduct comprehensive testing and disseminate the results to all stakeholders. The aim of this effort is to enhance compliance levels across Indian digital platforms, ensuring that they meet modern security standards and contribute to a safer and more secure digital environment.\n\nPerspectives from Brasil\n\nMr. Flavio Kenji Yanai andGilberto Zorello shared their experiences from a Brazilian perspective. The Brazilian Network Information Center (NIC.br) is a non-profit civil entity that since 2005 has been assigned with the administrative and operational functions related to the .br domain. NIC.br is actively investing in various actions and programs to improve internet services across different sectors. Their initiatives are geared towards disseminating knowledge and best practices, contributing to a safer and more secure internet environment in the country.\n\nA key project they are currently undertaking is the TOP Teste os Padrões (Test the Standards) tool, which was initiated in December 2021 and utilizes Internet.nl provided by the Dutch government. As part of the Safer Internet program, their objectives include providing support to the internet technical community. This involves collaborating with various groups to develop technical teaching materials and promote good practices aimed at raising awareness within the technical community. Their efforts have yielded positive results, as statistics indicate a reduction in misconfigured IP addresses.\n\nFurthermore, they have implemented the Mutually Agreed Norms for Routing Security (MANRRS) in Brazil, leading to a notable increase in the number of participants. The statistics reflect continuous improvements in various aspects of internet security within the country. With significant incumbents responsible for approximately 50% of the internet traffic in Brazil, the implementation of version 1.7 of internet.nl, currently in the validation phase, has been instrumental. The tool is being widely disseminated in conjunction with the Program for a Safer Internet, with government entities also starting to utilize it to test their websites and email services. The TOP tool has proven to be of immense value in fortifying the internet infrastructure in Brazil.\n\nThis workshop proposed to discuss Intern Fragmentation through a forward looking exercise. The session opened with the moderator inviting the panel and audience to think of the Internet in 2043, what good would look like, and what it would take us to fulfil the hoped-for future we want.\n\nThe panellists started off by sharing their thoughts on what it entails imagining the future, based on past experience.\n\nOlaf Kolkman from the Internet Society highlighted it is hard to predict the future and what technologies would triumph, exemplifying with his erroneous prediction that webpages would not go beyond academic libraries. Sheetal Kumar from Global Partners Digital spoke about ubiquity of smartphones and connectivity as a crucial development and in looking to the future, encouraged the audience to think about what we want the Internet to feel like; she believes the internet will continue to grown in embeddedness and finds that how the internet will evolve will depend on what we Internet we choose to create. French Ambassador for Digital Affairs, Henri Verdier —who created his first web-based company in the 90s— shared a story about how he erroneously predicted that Wikipedia would fail to take off. Professor Izumi Aizu from Tama University mentioned that we are oftentimes overly optimistic of the future, which in reality may be composed of different shades and colours. The future is bound to surprise us with unpredictable events like Fukushima or the unfolding conflict in Gaza. Lorraine Porciuncula from the Datasphere Initiative spoke of being a digital native, and the optimism felt during the Arab spring. She recalled the sense of opportunity and “capability” brought by technology. Time showed that there are good and bad aspects to technology, yet she encouraged the audience to reconnect with a sense of optimism.\n\nThe moderator introduced the discussion paper submitted as part of the session (https://dnsrf.org/blog/the-internet-in-20-years-time-what-we-should-hav…) which lays out there potential future scenarios:\n\nScenario 1: Continued Status Quo. In the first scenario, we muddled along, continue the current course of action and end up with an internet that continues in its present trajectory with some signs of fragmentation;\n\nScenario 2: Fully Fragmented Internet. the second scenario is one of complete fragmentation, either divided at the technical layers, at ideological layers or regulatory layers or all three;\n\nScenario 3: Strengthened, non-fragmented Internet. The third scenario is one of a bright future where we get our act together.\n\nThe moderator invited the panel and audience to comment on what they see as the most likely future and why, and at what layer they see the most risk.\n\nOlaf said that in reading the scenarios, he was struck about how the future is already here. Many of the things described in the scenarios —such as drivers for the fragmentation of the technical layers of the Internet, are already happening, and if they take off, they will splinter the internet. He explained that the value he sees in the Internet lies in its openness, the scientific method of sharing knowledge, and to be able to probe, query and scrutinise one another. He commented in particular on scenario 1, where we see a mix of closed networks coexisting with the Internet. This is about being proprietary, about the Internet being closed, about the Internet developing services that people pay for, where people connect to servers to access specific services, and the interconnectivity is less important. This is an entirely different notion from the Internet that exists to connect us to the rest of the world, where we get to choose services. To Olaf, openness is a best case scenario, where the richness of the Internet really lies.\n\nThe moderator took a round of early comments from the audience.\n\nBarry Leiba said that what has driven the evolution of the Internet is the innovation in applications and services. He therefore thinks that a great idea for an application (perhaps yet to come) is what will drive the Internet of tomorrow, including another set of standards and technologies. He highlighted the role of standards in shaping the way we will experience technology.\n\nAndrew Campling stated that we are also at an inflection point. Up to now, the Internet was seen as a force for good. He finds we are now at the point where the balance is shifting to the Internet becoming a source for harm with the rise of disinformation and CSAM. Adding to the point of standards, he urged for standards development organisations (SDOs) to become more diverse.\n\nMichael Nelson from the Carnegie Endowment for International Peace came in next. He taught a class about the internet future(s), where he highlighted to his students that the best way to understand what is coming in terms of technology, is not to understand what the technology can do, or what governments want it to not do, but rather to look at what the users want. So we should ask ourselves, what will drive companies and governments to do better? He concluded by saying “I am a technology positivist but political negativist.”\n\nThe moderator returned to the panellists. Izumi described the first scenarios of mixed networks co-existing with the Internet as a scenario of chaos. He consulted a number of AI tools on the subject of the panel and shared the findings with the audience. Chat GPT said that, while there is fragmentation due to economic and political reasons, the ethos of the Internet as a tool for global communication will likely persist. Bard was even more optimistic and said the Internet might become even more unified. He challenged the audience to think not of a better internet, not for the sake of the Internet itself, but for the sake of a better society, which is a different perspective on how to understand the Internet.\n\nLorraine, on the other hand, said that in her view, we will not have an issue of fragmentation around the Internet’s technical layers, but we will have a very concrete challenge on the regulatory side. This issue is reflective of not only the fragmentation of the Internet, but of the fragmentation of society. She urged the audience to consider “how are we (as societies) going to get along? What are the incentives?” Regulators will regulate what they are scared off: they want to control national security, democratic processes, content, and so on. So when taking of regulatory-driven fragmentation, the question becomes “How will we work to find convergence?”\n\nAmbassador Verdier said that he is uncertain what scenario will materialise, but that he knows what we should fight for. We know what the Internet brought us in terms of possibilities. Now there is great centralisation, if you look for example at submarine cables. He finds that big tech does not care for decentralised internet, and that “we need to fight for that interconnected, free, decentralised internet.” He also reflected on John Perry Barlow’s notion of Cyberspace (https://www.eff.org/cyberspace-independence), where the Internet felt like it was somewhere far off in “cyberspace”. Now the digital is embedded in all aspects of life: education, health, and even war and peace. He finds that the fragmentation of the technical layer would be an extremely bad scenario, as now interdependence holds it all together. If the internet were to fully fragment, the temptation to disconnect each other’s internet would be very high, war would be waged on infrastructure itself. So far we have cyberwarfare, but no attempts to disconnect internets. Beyond the technical layer, there is a political and legal layer. From a legal point of view, he sees it would be better to have regulatory convergence but if you believe in democracy, you need to respect regulatory proposals that are reflective of local prerogatives, as is the case in France.\n\nSheetal came in next and said she finds that we have the capacity to build and design our own future, even though there are power asymmetries to be aware of. She picked up on the notion of how the Internet of the future should feel: it should feel liberating, especially to those who do not occupy those positions of power. She hopes for a future Internet that does not reflect the inequalities of our society. This will require that those who build the technologies and develop the standards, open up spaces to those communities affected by technology developments. In terms of what we should do, she highlighted “we know exactly what we need to do, we just don’t do it at the moment.” There are many useful tools and guidance on how to build a better, human-rights-respecting Internet. We should utilise and leverage those in shaping the Internet of tomorrow.\n\nThe audience came in with a new round of comments:\n\nWeb 3 and money. Georgia Osborn picked up on money being a huge incentive on the Internet, and currently money being a massive driver for the development of blockchain technologies, Web 3.0, alternative naming systems, and cryptocurrencies. She asked the panel to reflect on whether those forces are bound to further fragment the Internet, or not.\n\nInteroperable laws. Steve del Bianco from NetChoice highlighted the impact of fragmentation through regulation, and stated that regulation is the main challenge we will confront, one that is already unfolding. There appears to be no cost associated or consequences for governments, particularly authoritarian governments that want to control what their citizens see. He highlighted how IGF 2023 was largely about AI, but not about collaboration. “We have been hearing competing views about how it should be regulated and where it needs to go. That is not going to work transnationally.” He encouraged the audience to think of ways of documenting the cost of fragmentation, and raising the “pain level” for bad regulatory proposals.\n\nBertrand Le Chapelle from the Internet and Jurisdiction Network also spoke about legal interoperability. He said that fragmentation is not driven by technical objectives but by politics. The legal fragmentation is a reflection of the international political system, which today is heavily influenced by notions of national sovereignty. The legal fragmentation is what prevents us from dealing with online abuse in many cases. The framework for accessing electronic evidence is non-existing or insufficient. He agreed with Ambassador Verdier that countries have a “democratic freedom/capacity” to do what they deem right for their citizens, but if we want to preserve interoperability we need to reduce the friction at the legal level. He also thinks we need to have heterogeneous governance frameworks that allow the coexistence of government regulation, company’s self regulation, and other frameworks that operate independently yet are able to speak to and with one another.\n\nInvolvement of the global south and regions with ideological disagreement. Nikki Colosso from Roadblocks came in next. She pointed out how a lot of conversation in IGF 2022 dealt with incorporating the global south and inclusivity. She asked the panel what specific steps companies and civil society can take to involve users from countries that are not represented in these conversations or those from countries where there are differences from a geopolitical perspective.\n\nDigital Colonialism. Jerel James picked up on the issue of profit as an incentive. Money is how power gets flexed on certain communities. He asked about digital colonialism and how it may be sanctioned. As we see antitrust regulation for monopolies exists in our traditional finance system, he asked whether there are possibilities to sanction resource extraction by big tech as a means to stop digital colonialism.\n\nBad behaviour in the online realm. Jennifer Bramlet from the UN Security Council spoke next. She focuses on how bad actors exploit ICTs for terrorism, including use to recruit and radicalise individuals. They look at what is considered unlawful and harmful language across jurisdictions, from a regulatory perspective. Looking to the future, they are concerned about crime and terrorist activity in the metaverse, and how it may be tackled going forward when regulation hasn’t quite yet caught up with online criminal challenges we see today. Her question to the panel was how do you deal with bad behaviour in the online realm.\n\nCall not to lose sight of the social value of the Internet. Vittorio Bertola came next. He believes Europe is producing regulation precisely to preserve the global nature of the Internet, not to break it. Also, if the future of the internet is decided by what people want from it, people want entertainment and social media attention. If we focus on that we lose sight of the social purpose of the technology. Just doing things because we can or because money is not enough.\n\nAmbassador Verdier responded first by saying he shares the aspiration by Bertrand of interoperable legislation. But while we can work on making progress in that direction, we are not there yet. France is fighting for regulation of big tech, which they see as a private place built on the internet. In his view, “you can do that and still protect the global internet.”\n\nSheetal elaborated on what we can do. On legal fragmentation, she expressed there is need for harmonisation. She finds we have human rights standards to guide us, we have the rule of law and our institutions. We can use those human rights standards and guidance for shaping the online space. She also seconded the need to protect the openness of the Internet and the ability to build your own apps and technology. She also supported the need to protect the critical properties of the internet, and how that comes hand in hand with the need to make standards bodies more inclusive. She also encouraged all participants to take the conversation home, to ensure that we are vocalising the values we want to be reflected on the Internet of tomorrow, and ensuring that those get executed. She concluded with an invitation: “Let's not be nostalgic, let’s look forward.” That requires giving users control, and not letting governments or companies determine what the future is about.\n\nIzumi reacted to Vittorio and Bertrand. He agreed that the future of the Internet depends on the wills of people/users, and that it also depends on legal frameworks. He wanted to add additional dimensions to consider, two factors that are unknown: climate and politics. We may get together hosted by the UN in 20 years time, independently of how politics plays out, who wins what war. Climate change, however, is an existential threat, we may think it is an external factor to the internet, but may well shape the future of the Internet, it may even lead to war. In the 1940s, we killed each other a lot. We then had the Cold War, and then came the Internet. Perhaps the timing was right, as the East and West were open to coming closer together. That political will is what allowed the Internet to get picked up. China wanted to have technology and science, that is why China accepted the Internet, to have growth and innovation and technology. Now China and India have reached the point where they do not need the West anymore. He concluded by inviting us to think of not the Internet of the future. The question has to be how the present and future will offer something better for society.\n\nLorraine picked up on notions of what the Internet can do for people. She highlighted that narratives matter, so it is not about the Internet, but about the digital society. Now, when we reflect on ”what is our vision for the Internet? what do we want the Internet to feel like?” she finds that we do not have a clear, shared vision. If the issue were walled gardens, we could use tools for antitrust and competition for users to move to other platforms. But the truth is that with the Internet, one government can’t fix it all, so it’s all about governance. We need to focus on asking ourselves “how do we cooperate? how do we govern? What are our economic and social objectives?”\n\nOlaf concluded by explaining that not having infrastructure at all is the ultimate fragmentation. Empowered communities is the way forward, like IXPs, communities networks, that is truly bottom. He also added thoughts on standardisation. When you talk about economics and standardisation, standardisation is to a large extent industry driven and industry politics; we need to put that on the table and understand it. With economics, consolidation happens, even if you have open technologies, companies will try to extract money from using those open technologies. And you will have an accumulation of power to the point governments might say this is too much, and want to regulate it. But we need to remember you don’t need standards for every innovation. The founder of blockchain did permissionless innovation, open innovation (he did not innovate via standards making bodies). Innovation happens today, not just in standards organisations. If you ask me from a technical perspective, where to go in the future I say: Open architecture, so that people build on the work of others, open code so that it can be reused, and open standards.\n\nThere was a last round of comments from the audience:\n\nYug Desai, ISOC Youth Ambassador, thinks in 20 years from now we will have fragmentation, not by design, but by default due capacity gaps. He finds the standards are unable to keep up with the pace of innovation, and not sufficiently inclusive of the users.\n\nMark Dattysgeld highlighted the importance of open source and the role of research driving AI. He said we should ask ourselves whether that is the new paradigm that takes things forward. This point was reinforced by Lucien Taylor on the example of TCP/IP.\n\nThe session wrapped with final recommendations from the panel about what to do next:\n\nRaul Echeberria from ALAI finds we already have a level of internet fragmentation, and we need to live with that. The incentives of policy makers are diverse, and not always driven by the search for the best outcomes for all. Our mission has to be protecting the Internet. In terms of what to do, his proposal is to go for “gradual objectives and commitments, instead of going for the whole packet.” In sum, he suggests an incremental approach. He also said that in speaking to policy-makers, we need to make our messages sharper and clearer, and better outline what governments should not do. Lastly, he shared he recently participated in a discussion with parliamentarians, all of whom were over 50 years old. They spoke about fears, but it is important we do not develop policies based on fear, and let’s not let fear stop evolution.\n\nLorraine reiterated the points we heard so far – being clear on what the objectives are, being incremental– and added being iterative. There is no ultimate regulation that will get it right, so we need to test stuff and iterate. The system is hard to predict and it moves fast. We need processes and institutions that are more agile. Like in software development, we need to identify the bug, and have multi-stakeholder conversations to address them. True multi-stakeholderism works when it seeks to be inclusive in an intentional way, particularly of communities that are underrepresented.\n\nAmbassador Verdier added he thinks we can agree on a compass. In his view, we should stand for 3 aspects of the Internet’s golden age: unprecedented openness and access to information, which to date has not been fully accomplished as we still have a digital divide; unprecedented empowerment of communities and people; and permissionless innovation. He reiterated that fragmentation can come from the private sector, not just rogue states.\n\nOlaf emphasised the point of the compass, saying our work needs to be principles-based. We need to make a differentiation between evolution OF the internet and evolution ON the Internet. We can get to those shared principles if we talk of the evolution OF the Internet. When we talk about empowerment, individualism, autonomy ON the Internet it gets more complicated to arrive at shared principles.\n\nSheetal added we need to assess how governments do regulation, and how companies operate from a human rights perspective. Are they human rights respecting, is there accountability, transparency? Are our governance and standards body inclusive? She summarised her points as protecting critical properties as they evolve, adopting a principles based approach, building on the human rights framework, and creating more inclusive spaces.\n\nLastly, Izumi highlighted that there were no Chinese or Indian representatives in the high-level session on AI, which to him is telling of the level of fragmentation that already exists. It wasn’t like that 18 years ago, we have fears. He encouraged the audience to go out into the world of chaos, to engage where there is tension, to think outside the box.\n\nAt the beginning of the session, Dr. Arisa Ema (The University of Tokyo), one of the organizers, explained the purpose of the session. The aim of this session is to expand the concept of \"Responsible AI,” which is an important topic of AI governance, to \"Resilient and Responsible AI\" by considering the possibility of situations including crises where dynamic interactions between multiple AI systems, physical systems, and humans across a wide range of domains may lead to unpredictable outcomes.\n\nFirst, Carly and Yui who are the pilots (operators of an avatar-robot) of OriHime (an avatar robot) talked about their experiences from the user's viewpoint of the technology. They have been in wheelchairs and feel the value of participating in society through the avatar robots. On the other hand, they have encountered situations where they could not handle irregulars because of the overreliance on technology. Carly shared the experience that he was unable to turn on the power switchboard by himself and loss of communication with outside, when a power failure occurred by a lightning strike while working at home. Yui talked about the anxiety and unnecessary apologies that people who need assistance face in a social system that is becoming increasingly automated. In a technology-driven society, where manuals are available but not always put into practice, they realized that this assumption would be broken not only in ordinary times but also in times of disaster, and that she would have to rely on people. The common conclusions of both stories, that is, the balance between technology and the manpower is important and that it should be considered that sometimes technology does not work, is suggestive. Furthermore, it made us realize that the nature of the crisis can be diverse for a diverse society. Next, Dr. Hiroaki Kitano (Sony), a researcher and executive of a technology company, who is currently working on an AI project for scientific discovery, pointed out that such an AI brings some positive effects for human being, but it also has a risk by misuse. Then, he also highlighted the possibility of future large-scale earthquakes in Japan and the importance of how to avoid excessive reliance on AI. There is a risk that AI will not be available unless communication networks, stable power and PC/mobile devices are available in accidents such as large-scale power outage when the dependency of AI in society is increased.\n\nThe organizers and three panelists, Dr. Inma Martinez (Global Partnership on AI), Ms. Rebecca Finlay (Partnership on AI), and Dr. David Leslie (The Alan Turing Institute), led the discussion based on the issues raised by OriHime pilots and Dr. Kitano. Dr. Martinez mentioned the necessity of defining resilience, and emphasized that the power of technology should be rooted in the values we have learned from our families and national cultures. By doing so, empowerment can create resilience. Ms. Finlay pointed out that while the assessments of AI systems before the launch are discussed, attention is hardly paid to how they affect different communities after they are released. The resilience and control methods are always required throughout the life cycle of AI, i.e., during the research phase, before and after launch. Focusing on machine-learning which has been the mainstream of AI in recent years, Dr. Leslie pointed out that data-driven systems may become vulnerable in a dynamic environment. As society and culture are gradually change, machine learning based systems driven by past data has the limitations. He emphasized the importance of considering resilience because excessive reliance on data driven systems has possibility to lead to stagnation in human creativity. In response to these discussions, Dr. Ema pointed out that we need to consider how technological and social perspectives on the current discussions such as generative AI will change. The following three points were pointed out by the audience.\n\nThe need for society to provide people with options for solutions.\n\nThe need for a more comprehensive impact assessment (technology, ethics, human rights, etc.)\n\nThe risk of forgetting skills due to dependence on technology.\n\nThen, a participant was asked about AI as a critical infrastructure. In response to this question, at first, Dr. Martinez said that AI is an infrastructure-based service, and it creates an unknown area for society. She mentioned the resilience of the communication infrastructure in which she was involved, and introduced an example in which a specific band continues to operate even if the whole network goes down in a disaster. She also pointed out the necessity of considering the self-repair mechanism of AI in the event of an infrastructural outage, and how to build not only systems but also human resilience. Ms. Finlay touched on the possibility that AI can be introduced in various ways with various implications, in response to Dr. Martinez. And she pointed out that systems need multiple layers of resilience. The way to understand how AI interact in a system is to map the system and understand its effects. Dr. Leslie pointed out that AI is rapidly becoming an infrastructure and general-purpose technology, and that it functions as an alternative for humans to think and act. AI is becoming a kind of a utility, but if it becomes an infrastructure, the question is who should control it. Dr. Ema said that it is difficult for individual companies to be held accountable when AI become infrastructural and go beyond the scope of a company, and that governmental and global discussions will be required.\n\nAs a summary of the discussion, the panelists highlighted the need for AI to be safe and have a solid foundation for society. They also emphasized the importance of defining and monitoring resilience to support society. In addition, they agreed the necessity of international research institutions to discuss AI from scientific and technological perspectives against the rapid commercialization of AI. In response to these comments, Dr. Ema concluded this discussion with the hope that all of us will work together to realize a resilient and responsible AI. The session received a variety of comments. A participant from public sector appreciated the uniqueness of the theme and the importance of discussion. On the other hand, another participant pointed out practical aspects such as how to handle large and complex systems composed by multiple AI systems. It is important to continue the discussion on this topic.\n\nIGF 2023 DC-IoT Progressing Global Good Practice for the Internet of Things\n\nThe session considered IoT governance from various perspectives. To understand baseline IoT evolution, associated challenges, opportunities and responses, the IoT could best be understood as an internet of data, devices, systems or functions. For simplicity, we can call these “Internets of X” (IoX). Each perspective brings its understanding of what is possible, desirable or undesirable and tools and processes needed for governance.\n\nEach approach must be considered in its own terms, but they start from a common base of experience and must ultimately come together to provide good governance. This leads to the need for an ecosystem comprising of stakeholders such as technical experts, governments, service providers, manufacturers, users, standards bodies, military vs civilian organisations, etc., varying in global and regional perspectives.\n\nOne immediate consequence is that IoT governance must respect a range of perspectives. Our fundamental principles are unlikely to be universal, especially when applied to specific IoT contexts. By analogy with the sensors and actuators of the IoT itself, governance needs to ‘sense’ the interests and perspectives of all significantly affected parties and somehow balance them to inform decisions at various levels. In other words, it requires multistakeholderism. It is not that specific expert groups (e.g., engineers) are insensitive to the needs of others (e.g., end users) but that they may misunderstand their interests, capabilities and behaviour.\n\nThe session began with a consideration of simple and recognisable use cases in which major challenges can already be seen (though they will become more complex). IoX components and their complex or hybrid assemblages will and should interact with others, so they must be identified uniquely and discovered with appropriate levels of precision, reliability, and permanence and be capable of enrolment in or separation from IoX systems. The concept of ‘identity’ has some subtlety. For instance, a smart home must be able to recognise and be recognised by new IoT components added to the system on a permanent or temporary basis, accorded the right kinds of access and privileges and tracked or remembered appropriately. These identities enable necessary functions, including the granting of trust. But they need not be unique, durable or universal. Indeed, categorical or shared identities (e.g., type certification) may be more practicable, scalable, flexible, future-proof, secure and robust to, e.g., (hardware, software or data) updates and interconnection or federation to create identifiable hybrid systems. Three subtleties linked to identity that came up in the discussion were security (including but not limited to cybersecurity), privacy (including but not limited to data privacy) and ownership (including protections against identity theft or misuse and, conversely, the use of identity to carry liability or responsibility).\n\nVarious identity schemes were discussed, ranging from central registries of semi-permanent discrete identities (along the lines of the DNS model) to purely transactional or temporary mutual authentication and identification schemes. These have advantages and drawbacks ranging from theoretical to practical, including technical, legal, commercial, security and other considerations. No single approach seemed to fit all foreseeable circumstances. In placing these in context, the panel recognised that the same concepts applied to the human beings (and organisations) that create, operate and use the IoX. For example, a person is more important than devices or data attributed to him/her, and human rights and responsibilities (e.g., of association and expression) cannot safely be extended to, say, their smart digital assistants. This cuts two ways; it may not be useful to hold a human being accountable for what their devices do in response to interactions with other systems, which the ‘user’ may not even perceive, let alone understand or control. Conversely, the automation of routine functions may result in their receiving less considered and responsible human attention, with unintended, undesirable and possibly irreversible results.\n\nThe discussion also considered desirable properties that might provide an ethical framework for IoT governance. Many are familiar, e.g., interoperability, transparency and accountability, robustness, resilience, trustworthiness, user empowerment, privacy and security. They are not IoT-specific but may need to be reinterpreted in that context. For example, IoT devices can harvest a wide range of data almost invisibly, which creates general privacy and security risks and affects global development, e.g., via ‘data colonialism’ whereby devices originating in and provisioned by the global north can be used to capture data from users in the global south to produce innovations for the benefit of the north and to lock in users in the south in ways that inhibit their techno-societal development.\n\nOne desideratum came up in relation to technologies, service provision, use cases, data issues, labelling and certification schemes and legal frameworks, and scalability. This is a generic issue, but the panel highlighted aspects that stand out clearly in the IoT context. One is complexity; as systems scale quantitatively, their qualitative properties may change and, with them, the appropriate kind of governance. Rules may need to be more general, neutral, principles- or function-based. Alternatively, governance may need to move between the data, device, software, etc., planes as systems interconnect in larger and more diverse ways. Another is practicability; effective governance may require limits on scale or interoperability. A further aspect is Quality of Service (QoS). The IoT-specific emphasis on low latency can constrain system scale, security or flexibility. Beyond this, QoS considerations may lead to multi-tier systems, which may reduce economic welfare, hinder interoperability or distort innovation. Large-scale systems may also be more susceptible to intentional or accidental compromise; effective access control in large environments may lead to inappropriate inclusions or exclusions. Under laissez-faire evolution, IoT systems may reach stable sizes and configurations, but these may not be optimal. Finally, very large systems may be difficult to govern with national or self-regulatory arrangements. For example, identification and certification schemes that identify individual devices or types scale with their number but cannot identify even pairwise interactions (which scale as the square of the number of interacting entities). As scale increases, management overloads, costs increase, and utility and use eventually decline. This, however, depends on the governance architecture; a centralised system (analogous to the cloud) offers economies of scale (or diseconomies) and a natural platform for observing systemic behaviour and emergent threats (if not weak signals). However, it creates additional power asymmetries and vulnerabilities; no one governance architecture will likely fit all cases. The group also mentioned other aspects of scale, such as environmental impact.\n\nAnother aspect that ran through the various phases of the discussion was trust and trustworthiness; beyond the customary discussion of e-trust, the panel contrasted high-trust and Zero-trust approaches to the problems of identification and interoperability.\n\nThe issue of AI in the IoT comes up often but not in depth. The panel recognised that it complicated the IoT, especially when considering smart devices and the emergent intelligence of connected systems. Foreseeability and explicability were discussed, as was the possibility that data-driven systems might be particularly vulnerable to noisy or biased data.\n\nThe panel considered various legal approaches and the ‘regulatory game’ being played out among countries, industries and civil society groups. Governance competition could spur the development of innovative and effective standards if different approaches can be compared and a suitable global standard emerges through a kind of ‘Brussels Effect’. This seems more promising than a too-rapid imposition of global standards and regulations whose implications cannot be foreseen. However, this result is not guaranteed; we could see damaging fragmentation or a rich diversity of approaches matching different contexts. Research on policy initiatives in 40 countries around the world shows that governments often do not regard modern global open source standards and global good practices with security at the core as “important”. It was suggested that governments could lead the way by taking such standards actively on board in their procurement activities. Keeping the discussion going and actively engaging with other DCs guarantees a positive outcome and an increased understanding of good global practices in IoT governance. Three important takeaways:\n\n·\n\nIoT data, especially AI-enhanced, should be understandable, accessible, interoperable, reusable, up-to-date and clear regarding provenance, quality and potential bias.\n\n·\n\nAt the level of devices, there need to be robust mechanisms for finding, labelling, authenticating and trusting devices (and classes of devices). These should survive retraining, replacement or updating but be removable when necessary for functional, security or privacy reasons. To ensure IoT functionality, trustworthiness and resilience, market information and incentives should be aligned. Labels provide a powerful tool; many countries have developed and adopted IoT trust marks, and the time has come to start working towards their international harmonisation.\n\n·\n\nFunctions are not all confined to single devices, designed in or provided by system integrators; they can also be discovered by end-users or emerge from complex system interactions in cyber-physical systems (CPS) and IoT-enabled services. Governance requires methods for recognising, protecting and controlling these functions and their impacts.\n\n-=O=-\n\nDC-CIV Evolving Regulation and its impact on Core Internet Values\n\nReport on the Internet Governance Forum (IGF) Session.\n\nMain Report\n\nThe Core Internet Values, which comprise the technical architectural values by which the Internet is built and evolves, also comprise ‘social’ or, in other words, ‘universal’ values that emerge (or derive) from the way the Internet works.\n\nThe Internet is a global medium open to all regardless of geography or nationality. It is interoperable because it is a network of networks. It doesn't rely on a single application. It relies on open protocols such as TCP/IP and BGP. It is free of any centralized control, except for the needed coordination of unique identifiers. It is end to end, so traffic from one end of the network to the other end of the network goes. It is user centric and users have control over what they send and receive and it is robust and reliable.\n\nThe Dynamic Coalition on Core Internet Values held sessions at every previous IGF. During the 2023 IGF at Kyoto, the Coalition discussed the topic of \"Avoiding Internet Fragmentation\" with \"International Legal Perspectives\" as the sub theme - all part of this year’s “Internet We Want”.\n\nThe following questions were examined during the session:\n\nIn a changing world and a changing Internet, should the Internet stick to its Core Values?\n\nShould more legislation be needed? If yes, then how should it be drafted?\n\nWhat are the risks of \"changing\" the Core Internet Values for the future of the Internet?\n\nCould we end up with fragmentation? With the end of the Internet as we know it?\n\nCould we end up with a better, safer, cleaner post-Internet network of networks? Is this achievable or is this a pipe dream? Does this have an impact on democracy across the world?\n\nPanelists included Lee Rainie, Jane Coffin, Nii Quaynor, Iria Puyosa, Vint Cerf with interventions from the floor moderated by Sébastien Bachollet as Co-Chair at Kyoto together with Olivier Crépin-Leblond.\n\nDeliberations\n\nThe deliberations during this meeting by panelists' presentation, participant interventions and Q&A are reported here without attribution to the specific panelist or participant.\n\nBroadly and roughly there have been four notable 'phases' that could be seen as 'revolutions' in Internet evolution:\n\nHome broadband. It sharply increased the \"velocity of information\" into people’s lives, bringing support for the way it democratized creativity, story-telling and community building. But it also spawned concern about misinformation, for example, in the medical community – and concern about the type of content to which children might be exposed.\n\nMobile connectivity. Mobile phones became ubiquitous and became all-purpose “extra body parts and brain lobes” that allowed people to reach out and be contacted at any time, anywhere, without the need for knowledge on how to operate a computer. But a backlash grew about the ways in which phones disrupted people’s time use and attention allocation.\n\nSocial media. Exposed users to new information and allowed them new ways to share their lives and create. The backlash has focused on the impact of social media on people’s emotional and mental health (especially for younger women and girls), the way social media can be used for information war purposes, enabled political polarization and tribalism, and menacing behavior like bullying and physical threats.\n\nArtificial intelligence. Often functioning unnoticed and uncommented upon, AI allowed people to live their lives more conveniently, efficiently and safely. It promised productivity increases. But the backlash starts with people’s inherent wariness of anything that might challenge their rights, their autonomy and their agency. There are widespread concerns about job loss, bias and discrimination, and whether AI can be used ethically.\n\nIt is worth noting that these and other concerns have mostly arisen at the level of applications, rather than the essential architecture of the Internet. Unfortunately, the concerns at the cultural, legal and social level usually drive policy deliberations that could limit the way the Internet functions.\n\nUsers almost unanimously support the Core Values of the Internet: open, free, secure, interoperable, end-to-end, permissionless innovation. The revolutions and the backlash they engendered:\n\nBeyond those general concerns about digital functions, there is evidence that different people have different experiences of those revolutions. Those group differences drive concerns and calls for further regulations. At the group level, it is clear that divisions by gender, age, race/ethnicity, class, nationality, religious affiliations, affect people’s online experiences. There are also divisions along the lines of people’s level of awareness and their knowledge about technology, and their traits cause them to experience and react to technology differently.\n\nTo further complicate the picture, it is clear that individual technology users act in different ways under different circumstances. They are not necessarily predictable and their actions are often contingent, transactional, and context specific. This makes it very hard for those designing policies to take into account the variety of ways people will use technology or have concerns about its impact on them.\n\nIn global surveys and other research, there is a division that pits individuals against society. Individual actors are often confident they can navigate the problems of information and communication ecosystems, but others are incapable of doing so. That results in an almost universal sense that “I’m OK, but the rest of the world is not”.\n\nHow should policy makers understand that and take account of such an array of social, cultural, and legal variance as they try to think about regulations for the Internet? It is a chaotic picture that suggests that policy proposals affecting the basic functioning of the Internet should be undertaken with great caution and much humility.\n\nThe Internet has been self organizing its network of networks with as little regulation as possible for them to work. There is a lot of support for this self-organization on the network level even though in some cases the shared objective of developing networks for people who do not yet have access appears to have been lost.\n\nRegulate\n\nCaution is advised when facing pressure to “regulate fast... because some serious harm is upon us\". Quick and ill-designed regulations may undermine online freedoms or lead to Internet fragmentation.\n\nBefore regulating, it is necessary to assess the tradeoffs of different policies as well as the suitable technical implementations of those policies.\n\nUnfortunately, pressure to legislate is driven by public opinion on harms - often emphasized by governments to impose legislation. Law enforcement requests for access to private communications, national security, and cyber-sovereignty agendas dominate public debate in most countries.\n\nThe Internet will not be the same if it is run in a non open way - and we can see that with countries where there is a zeal to pass laws to \"protect the interests of the regimes\".\n\nThe intent may have originally been laudable but they may also have side effects.\n\nFor instance, we observe this problem in legislation threatening end-to-end encryption under the urge to provide more safety for children online, legislation establishing widespread Internet surveillance pretexting rising concerns related to violent extremism, cyber-sovereignty agendas undermining net neutrality, and cybersecurity policies that pose a risk to interoperability.\n\nTechnical solutions to online harm must ensure respect for human rights and the rule of law in line with the principles of necessity and proportionality. Any restriction of access to the Internet must be lawful, legitimate, necessary, proportional, and non-discriminatory.\n\nCivil society and the Internet technical community must continue collaborating in facing overregulation trends threatening Internet Core Values.\n\nSome participants in the meeting pointed to further study in countries like Finland and Estonia, that have advanced in terms of e-governments. It was also mentioned that the borderless nature of the Internet would expand with a more widespread use of “satellite Internet” and Internet Exchange Points in Space - thus bringing a new perspective on cross-border issues.\n\nKey Takeaways\n\nThe Internet has been self organizing with as little regulation as possible for it to work and if strong regulation is introduced it will hinder its technical functioning. Too much regulation will damage interoperation. As Internet networks evolve into Space with no borders there are question marks as to how its Core Values will be sustained.\n\nOne of the major policy tensions in digital life pits anonymity against accountability. Anonymity has been a key aspect of Internet activity, but we have painfully learned that full anonymity can be exploited in ways that allow bad actors to escape being held accountable for the harms they cause. Systems must be developed to bring accountability without compromising essential anonymity - and layering identity levels is one way to do it.\n\nSuch systems must be designed with clear and minimal implications for deep architectural changes. A layered approach (possibly in the application layer) may be desirable.\n\nCall to Action\n\nAll stakeholders should actively engage in understanding, appreciating, and expanding knowledge of the Internet’s Core Values and the damages that may arise from actions that, deliberately or as unintended consequences, impinge negatively on them. The list is not long and it starts by layered architecture, packet switching, “best effort” i.e. design for resilience against failure, interoperability, openness, robustness (Postel), end-to-end (meaning that most functions that are not packet transmission are a responsibility of the “edge”, and implying network neutrality), decentralization, scalability, and, as a consequence, universal reach and “permissionless innovation”.\n\nLaws, norms, and treaties must all be commensurate with these values and only impinge on any of them after a deep analysis by all stakeholders, and with safety valves to avoid irreversible unexpected consequences down the road.\n\nThe Internet community including the private sector, civil society, technical community should actively engage with governments to make them understand why a multistakeholder IGF is important.\n\nUse of encryption needs to continue - as without encryption many of the functions of the Internet's safety will be negatively impacted.\n\nWorkshop Report - IGF 2023 WS #209: Viewing Disinformation from a Global Governance Perspective\n\nWorkshop process\n\nPart 1:\n\nThe workshop opened with the moderator asking participants to stand and gather along an imagined line on the floor in the room based on the extent to which they agreed or disagreed with the following statement: \"Disinformation is undermining democratic political participation\". The moderator then walked around the room and asked people to share their views and why they agreed/disagreed or stood somewhere in the middle. They were encouraged to shift their position if the discussion led to them rethinking their initial opinion.\n\nViews in the room were diverse. Almost all participants stood in the area signifying agreement with the statement. Several offered examples from their countries and larger experiences that they believed demonstrated a strong causal link between disinformation and democratic erosion. Two people, including one of the speakers, stood in an intermediate position and argued that a nuanced and contextualized approach is needed in examining cases so a binary choice between “is/not causing” was not adequate. One person stood in the area signifying no impact of disinformation.\n\nThe moderator also asked the panelists to share their perspectives, and, in doing so, to respond to the question: “What is disinformation, is it a serious problem, and if so, why (or why not, if you believe it is not a serious problem)?”\n\nInteractive discussion on this question between participants and the panelists continued for about 25 minutes. One of the panelists responded by asking what impact of disinformation we care about. He also suggested that disinformation is an umbrella term that is too broad as a basis for regulation. A person from the audience added that disinformation is not new and that each media has been abused for purposes of propaganda. One panelist pointed out that there is a lack of empirical evidence about the impact of disinformation. Most of what we know concerns the production and dissemination of disinformation while its effect on people’s worldviews and voting behaviour is mostly taken for granted. Recent research suggests that disinformation amplifies extremist beliefs rather than instigating them. As a closing question, the moderator asked participants if any of them lived in\n\ncontexts where disinformation does not have a major impact. Two people responded to say that in their countries disinformation does not appear to be causing much harm due to the presence of a serious and legitimized mass media and other factors. A panelist concluded that high quality journalism is the best way to combat disinformation.\n\nPart 2\n\nThe second question put to the panel and the participants was: “Can disinformation be regulated internationally? How strong and clear a baseline do existing international instruments provide for the governance of disinformation? What are the implications for rights to access information and freedom of expression?”\n\nThere was no common view on whether disinformation can be regulated internationally. Panelists doubted whether there can be one solution for all the different forms of disinformation. There was agreement on the need for a common set of principles to guide how we think of and act upon disinformation. Human rights, particularly Article 19, which protects freedom of expression and information must be front and center of such principles.\n\nOne speaker briefly flagged three examples of efforts to devise international Internet governance responses to disinformation. These included some problematic proposals for binding treaty commitments among governments that have been floated in the UN cybersecurity and cybercrime discussions; the European Union’s Code of Practice on Disinformation; and the UN Secretary General’s proposed Code of Conduct for Information Integrity on Digital Platforms. It was pointed out that while the first example involved efforts to devise constraints on state behavior that would never be agreed in geopolitically divided UN negotiations, the second two involve codes of practice pertaining mostly to the providers and users of digital platforms. It was noted that while platforms certainly have responsibilities, focusing largely on them rather than on the governments that produce or support the production of a lot of disinformation is quite a limitation. There are also open questions around the reliance on codes and guidelines varyingly interpreted and implemented at the national level.\n\nThe next question was: “Concerning new governance initiatives, what sort of consultation and decision-making process is best suited to the governance of disinformation, and can the IGF assume a role in the process?”\n\nThis provoked a very interesting discussion. Participants involved in the Christchurch Call shared how they put multistakeholder consultation at the centre of their efforts to combat online extremism. The key lessons they shared that are relevant to responding to disinformation was (1) the multistakeholder approach has been critical to create trust among the actors involved, (2) the need to take time and form partnerships with diverse actors involved, (3) to keep the scope and focus really tight and (4) not to rush into regulatory intervention.\n\nPart 4 - Closing\n\nIn closing, panelists offered their main take-aways, including things they did and did not want to see. There were calls for better empirical research and evidence about the effects of disinformation; for more nuanced policy responses, including avoidance of governments using “moral panics” on disinformation to justify restrictions of human rights; for multistakeholder participation in crafting governance responses; and for hefty fines on Elon Musk’s X for violations of the EU’s rules.\n\nRITEC: Prioritizing Child Well-Being in Digital Design\n\nOpen Forum #52 - Session Summary\n\nSpeakers\n\nAdam Ingle, The LEGO Group\n\nAditi Singh, Young Advocate, Dream Esports India and Esports Monk\n\nProfessor Amanda Third, Western Sydney University\n\nSabrina Vorbau, EUN\n\nShuli Gilutz, PhD, UNICEF\n\nPurpose: The session introduced the concept of well-being for children in the digital age before going on to examine its importance when we consider the centrality of digital technologies in children’s lives and the rapidly growing concerns around online harms.\n\nPart 1: Setting the scene on child safety and well-being in a digital age\n\nThis part commenced with Aditi Singh, Young Advocate, describing her own experiences with online gaming and how, from a young age, games pushed her critical thinking and collaboration skills and enabled her to grow intellectually and socially. However, Aditi also described the harms, particularly those related to being a young woman online, associated with gaming. This includes how she, and other children, often don’t understand the risks of sharing personal information and prevalence of gender-based harassment.\n\nAditi then discussed how forums, like the UNICEF Game Changers Coalition, has helped her and others reimagine the role of women in online gaming and drive the design of games to make them more age-appropriate spaces. Aditi called for governments and other bodies to incentivize private firms to build experiences with children at their core and how platforms themselves need to realize that their choices can unlock the benefits of games while minimizing the risk.\n\nSabrina Vorbau from European Schoolnet followed Aditi, discussing the EU’s revised Better Internet for Kids (BIK) strategy and how the revision process ensured the new BIK onboarded diverse views, including those of children which were instrumental to shaping the strategy. Ultimately this ensured the strategy adopted a more modern approach to promoting protection, empowerment and participation of children online. Sarbina highlighted how young voices also helped inform the Safer Internet Forum conference, informing important matters like topics, speakers and themes. Sabrina reinforced the need to educate with young people, not simply to them or for them.\n\nShuli Gilutz began to discuss how design philosophies within industry are critical to embedding digital well-being into online play. Shuli unpacked the concept for ‘well-being’, noting that it’s about the subjective experiences of children and includes not just safety but also outcomes like empowerment and creativity. Shuli described how RITEC is working with designers to develop a guide for business, giving them the tools to create positive digital experiences that are safe, private but also advance well-being.\n\nPart 2: the RITEC project\n\nAdam Ingle provided an industry perspective of why designing for children’s experiences is critical, discussing how the LEGO Group is embedding the concept in its own online play products. Adam highlighted that the RITEC project is about developing an empirical basis for understanding what digital well-being looks like while also creating the tools to proliferate responsible design throughout industry. Adam discussed the LEGO Group’s internal processes that helped the company implement best practice, this includes incorporating the views of child rights experts in product development processes, adopting clear digital desi"
    }
}