{
    "id": "dbpedia_3610_0",
    "rank": 80,
    "data": {
        "url": "https://deeplearn.org/arxiv/415190/exploring-large-language-models'-cognitive-moral-development-through-defining-issues-test",
        "read_more_link": "",
        "language": "en",
        "title": "Exploring Large Language Models' Cognitive Moral Development through Defining Issues Test",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "deep learning",
            "paper",
            "arxiv",
            "twitter"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Things happening in deep learning: arxiv, twitter, reddit",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Abstract\n\nThe development of large language models has instilled widespread interestamong the researchers to understand their inherent reasoning andproblem-solving capabilities. Despite good amount of research going on toelucidate these capabilities, there is a still an appreciable gap inunderstanding moral development and judgments of these models. The currentapproaches of evaluating the ethical reasoning abilities of these models as aclassification task pose numerous inaccuracies because of over-simplification.In this study, we built a psychological connection by bridging two disparatefields-human psychology and AI. We proposed an effective evaluation frameworkwhich can help to delineate the model's ethical reasoning ability in terms ofmoral consistency and Kohlberg's moral development stages with the help ofPsychometric Assessment Tool-Defining Issues Test.\n\nQuick Read (beta)"
    }
}