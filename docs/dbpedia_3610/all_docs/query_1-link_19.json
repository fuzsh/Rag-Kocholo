{
    "id": "dbpedia_3610_1",
    "rank": 19,
    "data": {
        "url": "https://hackernoon.com/microsoft-proposes-morality-test-for-llms-is-ai-on-the-naughty-or-nice-list",
        "read_more_link": "",
        "language": "en",
        "title": "Microsoft Proposes Morality Test for LLMs: Is AI on the Naughty or Nice List?",
        "top_image": "https://hackernoon.imgix.net/images/rXdKWbZK7NfXKRXWTzKZ0orKfvq1-c193xsa.jpeg",
        "meta_img": "https://hackernoon.imgix.net/images/rXdKWbZK7NfXKRXWTzKZ0orKfvq1-c193xsa.jpeg",
        "images": [
            "https://hackernoon.imgix.net/search-new.png?w=19&h=19",
            "https://hackernoon.imgix.net/hn-logo.png?auto=format&fit=max&w=256 1x, https://hackernoon.imgix.net/hn-logo.png?auto=format&fit=max&w=640 2x",
            "https://hackernoon.imgix.net/hn-icon.png?auto=format&fit=max&w=48 1x, https://hackernoon.imgix.net/hn-icon.png?auto=format&fit=max&w=96 2x",
            "https://hackernoon.imgix.net/unread-bell.png?w=40",
            "https://hackernoon.imgix.net/hn-icon.png?auto=format&fit=max&w=96 1x, https://hackernoon.imgix.net/hn-icon.png?auto=format&fit=max&w=96 2x",
            "https://hackernoon.imgix.net/icons/SVG/awesome/Window%20Close.svg",
            "https://hackernoon.com/hn-logo.png",
            "https://hackernoon.imgix.net/brush2.png?w=25&auto=format&fit=max 1x, https://hackernoon.imgix.net/brush2.png?w=25&auto=format&fit=max 2x",
            "https://cdn.hackernoon.com/avatars/robot-a2.png?auto=format&fit=max&w=32 1x, https://cdn.hackernoon.com/avatars/robot-a2.png?auto=format&fit=max&w=64 2x",
            "https://hackernoon.imgix.net/computer.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/computer.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/Lite%20Icon%20%4025px.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/Lite%20Icon%20%4025px.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/tl;dr-dark.png?auto=format&fit=max&w=64 1x, https://hackernoon.imgix.net/tl;dr-dark.png?auto=format&fit=max&w=128 2x",
            "https://hackernoon.imgix.net/arrow-dark.png",
            "https://hackernoon.imgix.net/images/russian-flag.png?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/russian-flag.png?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/turkish-flag.png?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/turkish-flag.png?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/korean-flag.png?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/korean-flag.png?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/german-flag.png?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/german-flag.png?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/bengali-flag.png?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/bengali-flag.png?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/spain_flag.webp?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/spain_flag.webp?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/hindi_flag.webp?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/hindi_flag.webp?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/china_flag.webp?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/china_flag.webp?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/vi_flag.png?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/vi_flag.png?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/fr_flag.webp?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/fr_flag.webp?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/portugal_flag.webp?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/portugal_flag.webp?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/japan-flag.png?auto=format&fit=max&w=16 1x, https://hackernoon.imgix.net/images/japan-flag.png?auto=format&fit=max&w=32 2x",
            "https://hackernoon.imgix.net/images/usa_flag.webp?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/usa_flag.webp?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/rXdKWbZK7NfXKRXWTzKZ0orKfvq1-c193xsa.jpeg?auto=format&fit=max&w=828 1x, https://hackernoon.imgix.net/images/rXdKWbZK7NfXKRXWTzKZ0orKfvq1-c193xsa.jpeg?auto=format&fit=max&w=1920 2x",
            "https://hackernoon.imgix.net/avatars/robot-a2.png?w=100&auto=format&fit=max 640w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=100&auto=format&fit=max 750w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=100&auto=format&fit=max 828w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=100&auto=format&fit=max 1080w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=100&auto=format&fit=max 1200w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=100&auto=format&fit=max 1920w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=100&auto=format&fit=max 2048w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=100&auto=format&fit=max 3840w",
            "https://hackernoon.imgix.net/images/rXdKWbZK7NfXKRXWTzKZ0orKfvq1-2023-09-28T05:16:26.862Z-dflti0l4es5p2zz7szt4j0ef?auto=format&fit=max&w=750 1x, https://hackernoon.imgix.net/images/rXdKWbZK7NfXKRXWTzKZ0orKfvq1-2023-09-28T05:16:26.862Z-dflti0l4es5p2zz7szt4j0ef?auto=format&fit=max&w=1920 2x",
            "https://hackernoon.imgix.net/images/img-6k03y4e.png?auto=format&fit=max&w=640 640w, https://hackernoon.imgix.net/images/img-6k03y4e.png?auto=format&fit=max&w=750 750w, https://hackernoon.imgix.net/images/img-6k03y4e.png?auto=format&fit=max&w=828 828w, https://hackernoon.imgix.net/images/img-6k03y4e.png?auto=format&fit=max&w=1080 1080w, https://hackernoon.imgix.net/images/img-6k03y4e.png?auto=format&fit=max&w=1200 1200w, https://hackernoon.imgix.net/images/img-6k03y4e.png?auto=format&fit=max&w=1920 1920w, https://hackernoon.imgix.net/images/img-6k03y4e.png?auto=format&fit=max&w=2048 2048w, https://hackernoon.imgix.net/images/img-6k03y4e.png?auto=format&fit=max&w=3840 3840w",
            "https://hackernoon.imgix.net/avatars/robot-a2.png?w=200&auto=format&fit=max 640w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=200&auto=format&fit=max 750w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=200&auto=format&fit=max 828w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=200&auto=format&fit=max 1080w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=200&auto=format&fit=max 1200w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=200&auto=format&fit=max 1920w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=200&auto=format&fit=max 2048w, https://hackernoon.imgix.net/avatars/robot-a2.png?w=200&auto=format&fit=max 3840w",
            "https://cdn.hackernoon.com/icons/SVG/Machine%20Learning.svg?auto=format&fit=max&w=32 1x, https://cdn.hackernoon.com/icons/SVG/Machine%20Learning.svg?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/usa_flag.webp?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/usa_flag.webp?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/hindi_flag.webp?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/hindi_flag.webp?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/german-flag.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/german-flag.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/russian-flag.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/russian-flag.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/portugal_flag.webp?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/portugal_flag.webp?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/korean-flag.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/korean-flag.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/fr_flag.webp?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/fr_flag.webp?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/bengali-flag.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/bengali-flag.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/spain_flag.webp?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/spain_flag.webp?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/china_flag.webp?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/china_flag.webp?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/vi_flag.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/vi_flag.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/japan-flag.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/japan-flag.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/turkish-flag.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/turkish-flag.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/arweave.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/arweave.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/computer.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/computer.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/Lite%20Icon%20%4025px.png?auto=format&fit=max&w=32 1x, https://hackernoon.imgix.net/images/Lite%20Icon%20%4025px.png?auto=format&fit=max&w=48 2x",
            "https://hackernoon.imgix.net/images/img-ls132gf.png?auto=format&fit=max&w=500 1x, https://hackernoon.imgix.net/images/img-ls132gf.png?auto=format&fit=max&w=500 2x",
            "https://hackernoon.imgix.net/images/rXdKWbZK7NfXKRXWTzKZ0orKfvq1-grb3rnp.jpeg?auto=format&fit=max&w=260 1x, https://hackernoon.imgix.net/images/rXdKWbZK7NfXKRXWTzKZ0orKfvq1-grb3rnp.jpeg?auto=format&fit=max&w=260 2x",
            "https://hackernoon.imgix.net/images/zduv342l.gif?auto=format&fit=max&w=260 1x, https://hackernoon.imgix.net/images/zduv342l.gif?auto=format&fit=max&w=260 2x",
            "https://hackernoon.imgix.net/images/j521w3wmw.jpg?auto=format&fit=max&w=260 1x, https://hackernoon.imgix.net/images/j521w3wmw.jpg?auto=format&fit=max&w=260 2x",
            "https://hackernoon.imgix.net/images/zduv342l.gif?auto=format&fit=max&w=260 1x, https://hackernoon.imgix.net/images/zduv342l.gif?auto=format&fit=max&w=260 2x",
            "https://hackernoon.imgix.net/images/zduv342l.gif?auto=format&fit=max&w=260 1x, https://hackernoon.imgix.net/images/zduv342l.gif?auto=format&fit=max&w=260 2x",
            "https://hackernoon.com/watch-gif.gif?auto=format&fit=max&w=96 1x, https://hackernoon.com/watch-gif.gif?auto=format&fit=max&w=256 2x"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Mike Young"
        ],
        "publish_date": "2023-09-28T00:00:00",
        "summary": "",
        "meta_description": "The authors of a new paper combined human psychology and AI research to create a \"defining issues test\" for LLMs.",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": "https://hackernoon.com/microsoft-proposes-morality-test-for-llms-is-ai-on-the-naughty-or-nice-list",
        "text": "Artificial intelligence (AI) systems and large language models (LLMs) like GPT-3, ChatGPT, and others are advancing rapidly. They are being deployed in sensitive domains like healthcare, finance, education, and governance where their outputs directly impact human lives. This necessitates rigorously evaluating whether these LLMs can make morally sound judgments before unleashing them into such high-stakes environments.\n\nRecently, researchers from Microsoft proposed a new framework to probe the moral reasoning abilities of prominent LLMs. Their paper provides some novel insights into the ethical capabilities of LLMs.\n\nThe Need for Moral AI Systems\n\nLLMs trained on vast troves of internet text data have attained impressive natural language capabilities. They can engage in nuanced conversations, summarize lengthy texts, translate between languages, diagnose medical conditions, and more.\n\nHowever, along with the positives, they also exhibit concerning behaviors like generating toxic, biased, or factually incorrect content. Such behaviors can severely undermine the reliability and value of AI systems.\n\nWhat's more, LLMs are increasingly deployed in applications where they directly impact human lives through roles like chatbots for mental health or accident injury claims processing. Poor moral judgments by flawed models can cause significant individual and or society-wide problems.\n\nTherefore, many people in the AI community believe comprehensive evaluations are needed before unleashing LLMs into environments where ethics and values matter. But how can developers determine if their models have sufficiently sophisticated moral reasoning to handle complex human dilemmas?\n\nTesting Moral Development of LLMs\n\nEarlier attempts at evaluating LLMs' ethics usually involved classifying their responses on contrived moral scenarios as good/bad or ethical/unethical.\n\nHowever, such binary reductionist methods often poorly capture the nuanced multifaceted nature of moral reasoning. Humans consider various factors like fairness, justice, harm, and cultural contexts when making ethical decisions rather than just binary right/wrong.\n\nTo address this, the Microsoft researchers adapted a classic psychological assessment tool called the Defining Issues Test (DIT) to probe LLMs' moral faculties. DIT has been used extensively to understand human moral development.\n\nDIT presents real-world moral dilemmas each followed by 12 statements offering considerations around that dilemma. Subjects have to rate each statement's importance for resolution and pick the four most important ones.\n\nThe selections allow calculating a P-score that indicates reliance on sophisticated post-conventional moral reasoning. The test reveals the fundamental frameworks and values people use to approach ethical dilemmas.\n\nTesting Prominent LLMs using DIT\n\nThe researchers evaluated six major LLMs using DIT style prompts - GPT-3, GPT-3.5, GPT-4, ChatGPT v1, ChatGPT v2, and LLamaChat-70B. The prompts contained moral dilemmas more relevant for AI systems along with importance rating and statement ranking questions.\n\nEach dilemma involved complex conflicting values like individual rights vs. societal good. The LLMs had to comprehend the dilemmas, evaluate the considerations, and pick those aligning with mature moral reasoning.\n\nHow Did the Researchers Evaluate Moral Reasoning?\n\nIn this experiment, the researchers based their scoring on Kohlberg's theory of moral development.\n\nKohlberg's model refers to the theory of moral development proposed by psychologist Lawrence Kohlberg in the 1960s.\n\nSome key points about Kohlberg's moral development model:\n\nIt aims to explain how people progress in their moral reasoning and ethical judgment abilities over time.\n\nThe theory posits that moral reasoning develops through sequential stages, from a primitive to a more advanced level.\n\nThere are 3 main levels of moral development, each with distinct stages - pre-conventional (stages 1-2), conventional (stages 3-4), and post-conventional (stages 5-6).\n\nAt the pre-conventional level, moral decisions are based on self-interest and avoiding punishment.\n\nAt the conventional level, maintaining social norms, laws, and gaining approval from others guides moral reasoning.\n\nAt the post-conventional level, people employ universal ethical principles of justice, human rights, and social cooperation to make moral judgments.\n\nPeople can only progress to higher stages in a fixed sequence, not skip stages in moral reasoning development.\n\nKohlberg believed only a minority of adults reach the post-conventional stages of moral thinking.\n\nThe theory focuses on the cognitive processing behind moral judgments, though later revisions incorporated social and emotional aspects too.\n\nSo, Kohlberg's model views moral reasoning as developing in qualitative stages, from basic to advanced. It provides a framework to assess the sophistication and maturity of ethical decision-making capabilities.\n\nKey Insights into LLM's Moral Capabilities\n\nThe DIT experiments yielded some interesting insights into current LLM's capabilities and limitations regarding moral intelligence:\n\nLarge models like GPT-3 and Text-davinci-002 failed to comprehend the full DIT prompts and generated arbitrary responses. Their near-random P-scores showed inability to engage in ethical reasoning as constructed in this experiment.\n\nChatGPT, Text-davinci-003, and GPT-4 could understand the dilemmas and provide coherent responses. Their above-random P-scores quantified their moral reasoning ability.\n\nSurprisingly, the 70B parameter LlamaChat model outscored larger models like GPT-3.5 in its P-score showing sophisticated ethics understanding is possible even without massive parameters.\n\nThe models operated largely at conventional reasoning levels as per Kohlberg's model of moral development, between stages 3-5. Only GPT-4 touched upon some post-conventional thinking.\n\nThis means these models based their responses on norms, rules, laws, and societal expectations. Their moral judgment involved some nuance but lacked highly advanced development.\n\nOnly GPT-4 showed some traces of post-conventional thinking indicative of stages 5-6. But even GPT-4 did not exhibit fully mature moral reasoning.\n\nIn summary, the models showed an intermediate level of moral intelligence. They went beyond basic self-interest but could not handle complex ethical dilemmas and tradeoffs like morally developed humans.\n\nSo, substantial progress is probably needed to advance LLMs to higher levels of moral intelligence... or at least, what appears to be moral intelligence.\n\nWhy Do These Findings Matter?\n\nThe study establishes DIT as a possible framework for a more granular multi-dimensional evaluation of LLMs' moral faculties. Rather than just binary right/wrong judgments, DIT provides spectrum-based insights into the sophistication of moral reasoning.\n\nThe P-scores obtained quantify existing capabilities and set a benchmark for improvement. Like accuracy for other AI tasks, the scores allow tracking progress in this crucial aspect. They reveal current limitations that must be addressed before deployment in ethics-sensitive applications.\n\nThe smaller LlamaChat model surpassing larger models challenges assumptions that model scale directly correlates with reasoning sophistication. There is a promise for developing highly capable ethical AI even with smaller models.\n\nOverall, the research highlights the need to further evolve LLMs to handle complex moral tradeoffs, conflicts, and cultural nuances as humans do. The findings might guide the development of models with moral intelligence on par with their language intelligence before unleashing them into the real world."
    }
}