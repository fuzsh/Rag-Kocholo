Monitoring by holographic radar systems

NASA Astrophysics Data System (ADS)

Catapano, Ilaria; Crocco, Lorenzo; Affinito, Antonio; Gennarelli, Gianluca; Soldovieri, Francesco

2013-04-01

Nowadays, radar technology represents a significant opportunity to collect useful information for the monitoring and conservation of critical infrastructures. Radar systems exploit the non-invasive interaction between the matter and the electromagnetic waves at microwave frequencies. Such an interaction allows obtaining images of the region under test from which one can infer the presence of potential anomalies such as deformations, cracks, water infiltrations, etc. This information turns out to be of primary importance in practical scenarios where the probed structure is in a poor state of preservation and renovation works must be planned. In this framework, the aim of this contribution is to describe the potentialities of the holographic radar Rascan 4/4000, a holographic radar developed by Remote Sensing Laboratory of Bauman Moscow State Technical University, as a non-destructive diagnostic tool capable to provide, in real-time, high resolution subsurface images of the sounded structure [1]. This radar provides holograms of hidden anomalies from the amplitude of the interference signal arising between the backscattered signal and a reference signal. The performance of the holographic radar is appraised by means of several experiments. Preliminary tests concerning the imaging below the floor and inside wood structures are carried out in controlled conditions at the Electromagnetic Diagnostic Laboratory of IREA-CNR. After, with reference to bridge monitoring for security aim, the results of a measurement campaign performed on the Musmeci bridge are presented [2]. Acknowledgments This research has been performed in the framework of the "Active and Passive Microwaves for Security and Subsurface imaging (AMISS)" EU 7th Framework Marie Curie Actions IRSES project (PIRSES-GA-2010-269157). REFERENCES [1] S. Ivashov, V. Razevig, I. Vasilyev, A. Zhuravlev, T. Bechtel, L. Capineri, The holographic principle in subsurface radar technology, International Symposium to

Improved Reconstruction of Radio Holographic Signal for Forward Scatter Radar Imaging

PubMed Central

Hu, Cheng; Liu, Changjiang; Wang, Rui; Zeng, Tao

2016-01-01

Forward scatter radar (FSR), as a specially configured bistatic radar, is provided with the capabilities of target recognition and classification by the Shadow Inverse Synthetic Aperture Radar (SISAR) imaging technology. This paper mainly discusses the reconstruction of radio holographic signal (RHS), which is an important procedure in the signal processing of FSR SISAR imaging. Based on the analysis of signal characteristics, the method for RHS reconstruction is improved in two parts: the segmental Hilbert transformation and the reconstruction of mainlobe RHS. In addition, a quantitative analysis of the methodâs applicability is presented by distinguishing between the near field and far field in forward scattering. Simulation results validated the methodâs advantages in improving the accuracy of RHS reconstruction and imaging. PMID:27164114

Holographic Subsurface Radar Technique for Nondestructive Testing of Dielectric Structures

NASA Astrophysics Data System (ADS)

Ivashov, S. I.; Bugaev, A. S.; Zhuravlev, A. V.; Razevig, V. V.; Chizh, M. A.; Ivashov, A. I.

2018-02-01

Holographic subsurface radar method is compared with the conventional technology of impulse radars. Basic relationships needed for the reconstruction of complex microwave holograms are presented. Possible applications of the proposed technology are discussed. Diagnostics of polyurethane foam coatings of spacecrafts is used as an example of the efficiency of holographic subsurface radars. Results of reconstruction of complex and amplitude microwave holograms are compared. It is demonstrated that the image quality that results from reconstruction of complex microwave holograms is higher than the image quality obtained with the aid of amplitude holograms.

Holographic Radar Imaging Privacy Techniques Utilizing Dual-Frequency Implementation

DOE Office of Scientific and Technical Information (OSTI.GOV)

McMakin, Douglas L.; Hall, Thomas E.; Sheen, David M.

2008-04-18

Over the last 15 years, the Pacific Northwest National Laboratory has performed significant research and development activities to enhance the state of the art of holographic radar imaging systems to be used at security checkpoints for screening people for concealed threats hidden under their garments. These enhancement activities included improvements to privacy techniques to remove human features and providing automatic detection of body-worn concealed threats. The enhanced privacy and detection methods used both physical and software imaging techniques. The physical imaging techniques included polarization-diversity illumination and reception, dual-frequency implementation, and high-frequency imaging at 60 GHz. Software imaging techniques to enhancemoreÂ Â» the privacy of the person under surveillance included extracting concealed threat artifacts from the imagery to automatically detect the threat. This paper will focus on physical privacy techniques using dual-frequency implementation.Â«Â less

Holographic radar imaging privacy techniques utilizing dual-frequency implementation

NASA Astrophysics Data System (ADS)

McMakin, Douglas L.; Hall, Thomas E.; Sheen, David M.

2008-04-01

Over the last 15 years, the Pacific Northwest National Laboratory has performed significant research and development activities to enhance the state of the art of holographic radar imaging systems to be used at security checkpoints for screening people for concealed threats hidden under their garments. These enhancement activities included improvements to privacy techniques to remove human features and providing automatic detection of body-worn concealed threats. The enhanced privacy and detection methods used both physical and software imaging techniques. The physical imaging techniques included polarization-diversity illumination and reception, dual-frequency implementation, and high-frequency imaging at 60 GHz. Software imaging techniques to enhance the privacy of the person under surveillance included extracting concealed threat artifacts from the imagery to automatically detect the threat. This paper will focus on physical privacy techniques using dual-frequency implementation.

Extremely High-Frequency Holographic Radar Imaging of Personnel and Mail

DOE Office of Scientific and Technical Information (OSTI.GOV)

McMakin, Douglas L.; Sheen, David M.; Griffin, Jeffrey W.

2006-08-01

The awareness of terrorists covertly transporting chemical warfare (CW) and biological warfare (BW) agents into government, military, and civilian facilities to harm the occupants has increased dramatically since the attacks of 9/11. Government and civilian security personnel have a need for innovative surveillance technology that can rapidly detect these lethal agents, even when they are hidden away in sealed containers and concealed either under clothing or in hand-carried items such as mailed packages or handbags. Sensor technology that detects BW and CW agents in mail or sealed containers carried under the clothing are under development. One promising sensor technology presentlymoreÂ Â» under development to defeat these threats is active millimeter-wave holographic radar imaging, which can readily image concealed items behind paper, cardboard, and clothing. Feasibility imaging studies at frequencies greater than 40 GHz have been conducted to determine whether simulated biological or chemical agents concealed in mail packages or under clothing could be detected using this extremely high-frequency imaging technique. The results of this imaging study will be presented in this paper.Â«Â less

Three-dimensional radar imaging techniques and systems for near-field applications

DOE Office of Scientific and Technical Information (OSTI.GOV)

Sheen, David M.; Hall, Thomas E.; McMakin, Douglas L.

2016-05-12

The Pacific Northwest National Laboratory has developed three-dimensional holographic (synthetic aperture) radar imaging techniques and systems for a wide variety of near-field applications. These applications include radar cross-section (RCS) imaging, personnel screening, standoff concealed weapon detection, concealed threat detection, through-barrier imaging, ground penetrating radar (GPR), and non-destructive evaluation (NDE). Sequentially-switched linear arrays are used for many of these systems to enable high-speed data acquisition and 3-D imaging. In this paper, the techniques and systems will be described along with imaging results that demonstrate the utility of near-field 3-D radar imaging for these compelling applications.

Holographic neural networks versus conventional neural networks: a comparative evaluation for the classification of landmine targets in ground-penetrating radar images

NASA Astrophysics Data System (ADS)

Mudigonda, Naga R.; Kacelenga, Ray; Edwards, Mark

2004-09-01

This paper evaluates the performance of a holographic neural network in comparison with a conventional feedforward backpropagation neural network for the classification of landmine targets in ground penetrating radar images. The data used in the study was acquired from four different test sites using the landmine detection system developed by General Dynamics Canada Ltd., in collaboration with the Defense Research and Development Canada, Suffield. A set of seven features extracted for each detected alarm is used as stimulus inputs for the networks. The recall responses of the networks are then evaluated against the ground truth to declare true or false detections. The area computed under the receiver operating characteristic curve is used for comparative purposes. With a large dataset comprising of data from multiple sites, both the holographic and conventional networks showed comparable trends in recall accuracies with area values of 0.88 and 0.87, respectively. By using independent validation datasets, the holographic network"s generalization performance was observed to be better (mean area = 0.86) as compared to the conventional network (mean area = 0.82). Despite the widely publicized theoretical advantages of the holographic technology, use of more than the required number of cortical memory elements resulted in an over-fitting phenomenon of the holographic network.

Stereo multiplexed holographic particle image velocimeter

DOEpatents

Adrian, Ronald J.; Barnhart, Donald H.; Papen, George A.

1996-01-01

A holographic particle image velocimeter employs stereoscopic recording of particle images, taken from two different perspectives and at two distinct points in time for each perspective, on a single holographic film plate. The different perspectives are provided by two optical assemblies, each including a collecting lens, a prism and a focusing lens. Collimated laser energy is pulsed through a fluid stream, with elements carried in the stream scattering light, some of which is collected by each collecting lens. The respective focusing lenses are configured to form images of the scattered light near the holographic plate. The particle images stored on the plate are reconstructed using the same optical assemblies employed in recording, by transferring the film plate and optical assemblies as a single integral unit to a reconstruction site. At the reconstruction site, reconstruction beams, phase conjugates of the reference beams used in recording the image, are directed to the plate, then selectively through either one of the optical assemblies, to form an image reflecting the chosen perspective at the two points in time.

Stereo multiplexed holographic particle image velocimeter

DOEpatents

Adrian, R.J.; Barnhart, D.H.; Papen, G.A.

1996-08-20

A holographic particle image velocimeter employs stereoscopic recording of particle images, taken from two different perspectives and at two distinct points in time for each perspective, on a single holographic film plate. The different perspectives are provided by two optical assemblies, each including a collecting lens, a prism and a focusing lens. Collimated laser energy is pulsed through a fluid stream, with elements carried in the stream scattering light, some of which is collected by each collecting lens. The respective focusing lenses are configured to form images of the scattered light near the holographic plate. The particle images stored on the plate are reconstructed using the same optical assemblies employed in recording, by transferring the film plate and optical assemblies as a single integral unit to a reconstruction site. At the reconstruction site, reconstruction beams, phase conjugates of the reference beams used in recording the image, are directed to the plate, then selectively through either one of the optical assemblies, to form an image reflecting the chosen perspective at the two points in time. 13 figs.

Propagation phasor approach for holographic image reconstruction

PubMed Central

Luo, Wei; Zhang, Yibo; GÃ¶rÃ¶cs, ZoltÃ¡n; Feizi, Alborz; Ozcan, Aydogan

2016-01-01

To achieve high-resolution and wide field-of-view, digital holographic imaging techniques need to tackle two major challenges: phase recovery and spatial undersampling. Previously, these challenges were separately addressed using phase retrieval and pixel super-resolution algorithms, which utilize the diversity of different imaging parameters. Although existing holographic imaging methods can achieve large space-bandwidth-products by performing pixel super-resolution and phase retrieval sequentially, they require large amounts of data, which might be a limitation in high-speed or cost-effective imaging applications. Here we report a propagation phasor approach, which for the first time combines phase retrieval and pixel super-resolution into a unified mathematical framework and enables the synthesis of new holographic image reconstruction methods with significantly improved data efficiency. In this approach, twin image and spatial aliasing signals, along with other digital artifacts, are interpreted as noise terms that are modulated by phasors that analytically depend on the lateral displacement between hologram and sensor planes, sample-to-sensor distance, wavelength, and the illumination angle. Compared to previous holographic reconstruction techniques, this new framework results in five- to seven-fold reduced number of raw measurements, while still achieving a competitive resolution and space-bandwidth-product. We also demonstrated the success of this approach by imaging biological specimens including Papanicolaou and blood smears. PMID:26964671

Holographic imaging with a Shack-Hartmann wavefront sensor.

PubMed

Gong, Hai; Soloviev, Oleg; Wilding, Dean; Pozzi, Paolo; Verhaegen, Michel; Vdovin, Gleb

2016-06-27

A high-resolution Shack-Hartmann wavefront sensor has been used for coherent holographic imaging, by computer reconstruction and propagation of the complex field in a lensless imaging setup. The resolution of the images obtained with the experimental data is in a good agreement with the diffraction theory. Although a proper calibration with a reference beam improves the image quality, the method has a potential for reference-less holographic imaging with spatially coherent monochromatic and narrowband polychromatic sources in microscopy and imaging through turbulence.

Demosaiced pixel super-resolution for multiplexed holographic color imaging

PubMed Central

Wu, Yichen; Zhang, Yibo; Luo, Wei; Ozcan, Aydogan

2016-01-01

To synthesize a holographic color image, one can sequentially take three holograms at different wavelengths, e.g., at red (R), green (G) and blue (B) parts of the spectrum, and digitally merge them. To speed up the imaging process by a factor of three, a Bayer color sensor-chip can also be used to demultiplex three wavelengths that simultaneously illuminate the sample and digitally retrieve individual set of holograms using the known transmission spectra of the Bayer color filters. However, because the pixels of different channels (R, G, B) on a Bayer color sensor are not at the same physical location, conventional demosaicing techniques generate color artifacts in holographic imaging using simultaneous multi-wavelength illumination. Here we demonstrate that pixel super-resolution can be merged into the color de-multiplexing process to significantly suppress the artifacts in wavelength-multiplexed holographic color imaging. This new approach, termed Demosaiced Pixel Super-Resolution (D-PSR), generates color images that are similar in performance to sequential illumination at three wavelengths, and therefore improves the speed of holographic color imaging by 3-fold. D-PSR method is broadly applicable to holographic microscopy applications, where high-resolution imaging and multi-wavelength illumination are desired. PMID:27353242

Holographic optical coherence imaging of tumor spheroids

NASA Astrophysics Data System (ADS)

Yu, P.; Mustata, M.; Turek, J. J.; French, P. M. W.; Melloch, M. R.; Nolte, D. D.

2003-07-01

We present depth-resolved coherence-domain images of living tissue using a dynamic holographic semiconductor film. An AlGaAs photorefractive quantum-well device is used in an adaptive interferometer that records coherent backscattered (image-bearing) light from inside rat osteogenic sarcoma tumor spheroids up to 1 mm in diameter in vitro. The data consist of sequential holographic image frames at successive depths through the tumor represented as a visual video "fly-through." The images from the tumor spheroids reveal heterogeneous structures presumably caused by necrosis and microcalcifications characteristic of human tumors in their early avascular growth.

Silicon oxide nanoparticles doped PQ-PMMA for volume holographic imaging filters.

PubMed

Luo, Yuan; Russo, Juan M; Kostuk, Raymond K; Barbastathis, George

2010-04-15

Holographic imaging filters are required to have high Bragg selectivity, namely, narrow angular and spectral bandwidth, to obtain spatial-spectral information within a three-dimensional object. In this Letter, we present the design of holographic imaging filters formed using silicon oxide nanoparticles (nano-SiO(2)) in phenanthrenquinone-poly(methyl methacrylate) (PQ-PMMA) polymer recording material. This combination offers greater Bragg selectivity and increases the diffraction efficiency of holographic filters. The holographic filters with optimized ratio of nano-SiO(2) in PQ-PMMA can significantly improve the performance of Bragg selectivity and diffraction efficiency by 53% and 16%, respectively. We present experimental results and data analysis demonstrating this technique in use for holographic spatial-spectral imaging filters.

X-ray lithography using holographic images

DOEpatents

Howells, M.S.; Jacobsen, C.

1997-03-18

Methods for forming X-ray images having 0.25 {micro}m minimum line widths on X-ray sensitive material are presented. A holographic image of a desired circuit pattern is projected onto a wafer or other image-receiving substrate to allow recording of the desired image in photoresist material. In one embodiment, the method uses on-axis transmission and provides a high flux X-ray source having modest monochromaticity and coherence requirements. A layer of light-sensitive photoresist material on a wafer with a selected surface is provided to receive the image(s). The hologram has variable optical thickness and variable associated optical phase angle and amplitude attenuation for transmission of the X-rays. A second embodiment uses off-axis holography. The wafer receives the holographic image by grazing incidence reflection from a hologram printed on a flat metal or other highly reflecting surface or substrate. In this second embodiment, an X-ray beam with a high degree of monochromaticity and spatial coherence is required. 15 figs.

Three-dimensional imaging of cultural heritage artifacts with holographic printers

NASA Astrophysics Data System (ADS)

Kang, Hoonjong; Stoykova, Elena; Berberova, Nataliya; Park, Jiyong; Nazarova, Dimana; Park, Joo Sup; Kim, Youngmin; Hong, Sunghee; Ivanov, Branimir; Malinowski, Nikola

2016-01-01

Holography is defined as a two-steps process of capture and reconstruction of the light wavefront scattered from three-dimensional (3D) objects. Capture of the wavefront is possible due to encoding of both amplitude and phase in the hologram as a result of interference of the light beam coming from the object and mutually coherent reference beam. Three-dimensional imaging provided by holography motivates development of digital holographic imaging methods based on computer generation of holograms as a holographic display or a holographic printer. The holographic printing technique relies on combining digital 3D object representation and encoding of the holographic data with recording of analog white light viewable reflection holograms. The paper considers 3D contents generation for a holographic stereogram printer and a wavefront printer as a means of analogue recording of specific artifacts which are complicated objects with regards to conventional analog holography restrictions.

Sonorous images through digital holographic images

NASA Astrophysics Data System (ADS)

Azevedo, Isabel; Sandford-Richardson, Elizabeth

2017-03-01

The art of the last fifty years has significantly surrounded the presence of the body, the relationship between human and interactive technologies. Today in interactive art, there are not only representations that speak of the body but actions and behaviours that involve the body. In holography, the image appears and disappears from the observer's vision field; because the holographic image is light, we can see multidimensional spaces, shapes and colours existing on the same time, presence and absence of the image on the holographic plate. And the image can be flowing in front of the plate that sometimes people try touching it with his hands. That means, to the viewer will be interactive events, with no beginning or end that can be perceived in any direction, forward or backward, depending on the relative position and the time the viewer spends in front of the hologram. To explore that feature we are proposing an installation with four holograms, and several sources of different kind of sounds connected with each hologram. When viewers will move in front of each hologram they will activate different sources of sound. The search is not only about the images in the holograms, but also the looking for different types of sounds that this demand will require. The digital holograms were produced using the HoloCam Portable Light System with the 35 mm camera Canon 700D to capture image information, it was then edited on computer using the Motion 5 and Final Cut Pro X programs.

Space Radar Image of Ubar Optical/Radar

NASA Image and Video Library

1998-04-28

This pair of images from space shows a portion of the southern Empty Quarter of the Arabian Peninsula in the country of Oman. On the left is a radar image of the region around the site of the fabled Lost City of Ubar, discovered in 1992 with the aid of remote sensing data. On the right is an enhanced optical image taken by the shuttle astronauts. Ubar existed from about 2800 BC to about 300 AD. and was a remote desert outpost where caravans were assembled for the transport of frankincense across the desert. The actual site of the fortress of the Lost City of Ubar, currently under excavation, is too small to show in either image. However, tracks leading to the site, and surrounding tracks, show as prominent, but diffuse, reddish streaks in the radar image. Although used in modern times, field investigations show many of these tracks were in use in ancient times as well. Mapping of these tracks on regional remote sensing images provided by the Landsat satellite was a key to recognizing the site as Ubar. The prominent magenta colored area is a region of large sand dunes. The green areas are limestone rocks, which form a rocky desert floor. A major wadi, or dry stream bed, runs across the scene and appears as a white line. The radar images, and ongoing field investigations, will help shed light on an early civilization about which little in known. The radar image was taken by the Spaceborne Imaging Radar C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) and is centered at 18 degrees North latitude and 53 degrees East longitude. The image covers an area about 50 kilometers by 100 kilometers (31 miles by 62 miles). The colors in the image are assigned to different frequencies and polarizations of the radar as follows: red is L-band, horizontally transmitted, horizontally received; blue is C-band horizontally transmitted, horizontally received; green is L-band horizontally transmitted, vertically received. SIR-C/X-SAR, a joint mission of the German, Italian and the United

Holographic Optical Coherence Imaging of Rat Osteogenic Sarcoma Tumor Spheroids

NASA Astrophysics Data System (ADS)

Yu, Ping; Mustata, Mirela; Peng, Leilei; Turek, John J.; Melloch, Michael R.; French, Paul M. W.; Nolte, David D.

2004-09-01

Holographic optical coherence imaging is a full-frame variant of coherence-domain imaging. An optoelectronic semiconductor holographic film functions as a coherence filter placed before a conventional digital video camera that passes coherent (structure-bearing) light to the camera during holographic readout while preferentially rejecting scattered light. The data are acquired as a succession of en face images at increasing depth inside the sample in a fly-through acquisition. The samples of living tissue were rat osteogenic sarcoma multicellular tumor spheroids that were grown from a single osteoblast cell line in a bioreactor. Tumor spheroids are nearly spherical and have radial symmetry, presenting a simple geometry for analysis. The tumors investigated ranged in diameter from several hundred micrometers to over 1 mm. Holographic features from the tumors were observed in reflection to depths of 500-600 ÃÂµm with a total tissue path length of approximately 14 mean free paths. The volumetric data from the tumor spheroids reveal heterogeneous structure, presumably caused by necrosis and microcalcifications characteristic of some human avascular tumors.

Radar Image Interpretability Analysis.

DTIC Science & Technology

1981-01-01

the measured image properties with respect to image utility changed with image application. This study has provided useful information as to how...Eneea.d) ABSTRACT The utility of radar images with respect to trained image inter - preter ability to identify, classify and detect specific terrain... changed with image applica- tion. This study has provided useful information as to how certain image characteristics relate to radar image utility as

Laser-induced fluorescence imaging of subsurface tissue structures with a volume holographic spatial-spectral imaging system.

PubMed

Luo, Yuan; Gelsinger-Austin, Paul J; Watson, Jonathan M; Barbastathis, George; Barton, Jennifer K; Kostuk, Raymond K

2008-09-15

A three-dimensional imaging system incorporating multiplexed holographic gratings to visualize fluorescence tissue structures is presented. Holographic gratings formed in volume recording materials such as a phenanthrenquinone poly(methyl methacrylate) photopolymer have narrowband angular and spectral transmittance filtering properties that enable obtaining spatial-spectral information within an object. We demonstrate this imaging system's ability to obtain multiple depth-resolved fluorescence images simultaneously.

Experimental feasibility of multistatic holography for breast microwave radar image reconstruction.

PubMed

Flores-Tapia, Daniel; Rodriguez, Diego; Solis, Mario; Kopotun, Nikita; Latif, Saeed; Maizlish, Oleksandr; Fu, Lei; Gui, Yonsheng; Hu, Can-Ming; Pistorius, Stephen

2016-08-01

images formed using the proposed approach was 4 s, which is one order of magnitude faster than the current state-of-the-art time-domain multistatic breast microwave radar reconstruction algorithms. The images generated by the proposed method show that multistatic holography is capable of forming spatially accurate images in real-time with signal to clutter levels and contrast values higher than other published monostatic and multistatic cylindrical radar reconstruction approaches. In comparison to the monostatic holographic approach, the images generated by the proposed multistatic approach had SCR values that were at least 50% higher. The multistatic images had CCR and TFRR values at least 200% greater than those formed using a monostatic approach.

Space Radar Image of Weddell Sea

NASA Image and Video Library

1999-04-15

Two radar images are shown in this composite to compare the size of a standard spaceborne radar image small inset to the image that is created when the radar instrument is used in the ScanSAR mode large image.

Space Radar Image of Long Island Optical/Radar

NASA Technical Reports Server (NTRS)

1994-01-01

This pair of images of the Long Island, New York region is a comparison of an optical photograph (top) and a radar image (bottom), both taken in darkness in April 1994. The photograph at the top was taken by the Endeavour astronauts at about 3 a.m. Eastern time on April 20, 1994. The image at the bottom was acquired at about the same time four days earlier on April 16,1994 by the Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) system aboard the space shuttle Endeavour. Both images show an area approximately 100 kilometers by 40 kilometers (62 miles by 25 miles) that is centered at 40.7 degrees North latitude and 73.5 degrees West longitude. North is toward the upper right. The optical image is dominated by city lights, which are particularly bright in the densely developed urban areas of New York City located on the left half of the photo. The brightest white zones appear on the island of Manhattan in the left center, and Central Park can be seen as a darker area in the middle of Manhattan. To the northeast (right) of the city, suburban Long Island appears as a less densely illuminated area, with the brightest zones occurring along major transportation and development corridors. Since radar is an active sensing system that provides its own illumination, the radar image shows a great amount of surface detail, despite the night-time acquisition. The colors in the radar image were obtained using the following radar channels: red represents the L-band (horizontally transmitted and received); green represents the L-band (horizontally transmitted and vertically received); blue represents the C-band (horizontally transmitted and vertically received). In this image, the water surface - the Atlantic Ocean along the bottom edge and Long Island Sound shown at the top edge - appears red because small waves at the surface strongly reflect the horizontally transmitted and received L-band radar signal. Networks of highways and railroad lines are clearly

Space Radar Image of Long Island Optical/Radar

NASA Image and Video Library

1999-05-01

This pair of images of the Long Island, New York region is a comparison of an optical photograph (top) and a radar image (bottom), both taken in darkness in April 1994. The photograph at the top was taken by the Endeavour astronauts at about 3 a.m. Eastern time on April 20, 1994. The image at the bottom was acquired at about the same time four days earlier on April 16,1994 by the Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) system aboard the space shuttle Endeavour. Both images show an area approximately 100 kilometers by 40 kilometers (62 miles by 25 miles) that is centered at 40.7 degrees North latitude and 73.5 degrees West longitude. North is toward the upper right. The optical image is dominated by city lights, which are particularly bright in the densely developed urban areas of New York City located on the left half of the photo. The brightest white zones appear on the island of Manhattan in the left center, and Central Park can be seen as a darker area in the middle of Manhattan. To the northeast (right) of the city, suburban Long Island appears as a less densely illuminated area, with the brightest zones occurring along major transportation and development corridors. Since radar is an active sensing system that provides its own illumination, the radar image shows a great amount of surface detail, despite the night-time acquisition. The colors in the radar image were obtained using the following radar channels: red represents the L-band (horizontally transmitted and received); green represents the L-band (horizontally transmitted and vertically received); blue represents the C-band (horizontally transmitted and vertically received). In this image, the water surface - the Atlantic Ocean along the bottom edge and Long Island Sound shown at the top edge - appears red because small waves at the surface strongly reflect the horizontally transmitted and received L-band radar signal. Networks of highways and railroad lines are clearly

Spaceborne radar observations: A guide for Magellan radar-image analysis

NASA Technical Reports Server (NTRS)

Ford, J. P.; Blom, R. G.; Crisp, J. A.; Elachi, Charles; Farr, T. G.; Saunders, R. Stephen; Theilig, E. E.; Wall, S. D.; Yewell, S. B.

1989-01-01

Geologic analyses of spaceborne radar images of Earth are reviewed and summarized with respect to detecting, mapping, and interpreting impact craters, volcanic landforms, eolian and subsurface features, and tectonic landforms. Interpretations are illustrated mostly with Seasat synthetic aperture radar and shuttle-imaging-radar images. Analogies are drawn for the potential interpretation of radar images of Venus, with emphasis on the effects of variation in Magellan look angle with Venusian latitude. In each landform category, differences in feature perception and interpretive capability are related to variations in imaging geometry, spatial resolution, and wavelength of the imaging radar systems. Impact craters and other radially symmetrical features may show apparent bilateral symmetry parallel to the illumination vector at low look angles. The styles of eruption and the emplacement of major and minor volcanic constructs can be interpreted from morphological features observed in images. Radar responses that are governed by small-scale surface roughness may serve to distinguish flow types, but do not provide unambiguous information. Imaging of sand dunes is rigorously constrained by specific angular relations between the illumination vector and the orientation and angle of repose of the dune faces, but is independent of radar wavelength. With a single look angle, conditions that enable shallow subsurface imaging to occur do not provide the information necessary to determine whether the radar has recorded surface or subsurface features. The topographic linearity of many tectonic landforms is enhanced on images at regional and local scales, but the detection of structural detail is a strong function of illumination direction. Nontopographic tectonic lineaments may appear in response to contrasts in small-surface roughness or dielectric constant. The breakpoint for rough surfaces will vary by about 25 percent through the Magellan viewing geometries from low to high

Holographic Interferometry and Image Analysis for Aerodynamic Testing

DTIC Science & Technology

1980-09-01

tunnels, (2) development of automated image analysis techniques for reducing quantitative flow-field data from holographic interferograms, and (3...investigation and development of software for the application of digital image analysis to other photographic techniques used in wind tunnel testing.

Radar Image of Galapagos Island

NASA Image and Video Library

1996-10-23

This is an image showing part of Isla Isabella in the western Galapagos Islands. It was taken by the L-band radar in HH polarization from the Spaceborne Imaging Radar C/X-Band Synthetic Aperture Radar on the 40th orbit of NASAâs space shuttle Endeavour.

Spaceborne Imaging Radar-C instrument

NASA Technical Reports Server (NTRS)

Huneycutt, Bryan L.

1993-01-01

The Spaceborne Imaging Radar-C is the next radar in the series of spaceborne radar experiments, which began with Seasat and continued with SIR-A and SIR-B. The SIR-C instrument has been designed to obtain simultaneous multifrequency and simultaneous multipolarization radar images from a low earth orbit. It is a multiparameter imaging radar that will be flown during at least two different seasons. The instrument operates in the squint alignment mode, the extended aperture mode, the scansar mode, and the interferometry mode. The instrument uses engineering techniques such as beam nulling for echo tracking, pulse repetition frequency hopping for Doppler centroid tracking, generating the frequency step chirp for radar parameter flexibility, block floating-point quantizing for data rate compression, and elevation beamwidth broadening for increasing the swath illumination.

Obstacle penetrating dynamic radar imaging system

DOEpatents

Romero, Carlos E [Livermore, CA; Zumstein, James E [Livermore, CA; Chang, John T [Danville, CA; Leach, Jr Richard R. [Castro Valley, CA

2006-12-12

An obstacle penetrating dynamic radar imaging system for the detection, tracking, and imaging of an individual, animal, or object comprising a multiplicity of low power ultra wideband radar units that produce a set of return radar signals from the individual, animal, or object, and a processing system for said set of return radar signals for detection, tracking, and imaging of the individual, animal, or object. The system provides a radar video system for detecting and tracking an individual, animal, or object by producing a set of return radar signals from the individual, animal, or object with a multiplicity of low power ultra wideband radar units, and processing said set of return radar signals for detecting and tracking of the individual, animal, or object.

Integral imaging based light field display with enhanced viewing resolution using holographic diffuser

NASA Astrophysics Data System (ADS)

Yan, Zhiqiang; Yan, Xingpeng; Jiang, Xiaoyu; Gao, Hui; Wen, Jun

2017-11-01

An integral imaging based light field display method is proposed by use of holographic diffuser, and enhanced viewing resolution is gained over conventional integral imaging systems. The holographic diffuser is fabricated with controlled diffusion characteristics, which interpolates the discrete light field of the reconstructed points to approximate the original light field. The viewing resolution can thus be improved and independent of the limitation imposed by Nyquist sampling frequency. An integral imaging system with low Nyquist sampling frequency is constructed, and reconstructed scenes of high viewing resolution using holographic diffuser are demonstrated, verifying the feasibility of the method.

Holographic imaging and photostimulation of neural activity.

PubMed

Yang, Weijian; Yuste, Rafael

2018-06-01

Optical imaging methods are powerful tools in neuroscience as they can systematically monitor the activity of neuronal populations with high spatiotemporal resolution using calcium or voltage indicators. Moreover, caged compounds and optogenetic actuators enable to optically manipulate neural activity. Among optical methods, computer-generated holography offers an enormous flexibility to sculpt the excitation light in three-dimensions (3D), particularly when combined with two-photon light sources. By projecting holographic light patterns on the sample, the activity of multiple neurons across a 3D brain volume can be simultaneously imaged or optically manipulated with single-cell precision. This flexibility makes two-photon holographic microscopy an ideal all-optical platform to simultaneously read and write activity in neuronal populations in vivo in 3D, a critical ability to dissect the function of neural circuits. Copyright Â© 2018 Elsevier Ltd. All rights reserved.

Quantitative measurement of holographic image quality using Adobe Photoshop

NASA Astrophysics Data System (ADS)

Wesly, E.

2013-02-01

Measurement of the characteristics of image holograms in regards to diffraction efficiency and signal to noise ratio are demonstrated, using readily available digital cameras and image editing software. Illustrations and case studies, using currently available holographic recording materials, are presented.

Developing tools for digital radar image data evaluation

NASA Technical Reports Server (NTRS)

Domik, G.; Leberl, F.; Raggam, J.

1986-01-01

The refinement of radar image analysis methods has led to a need for a systems approach to radar image processing software. Developments stimulated through satellite radar are combined with standard image processing techniques to create a user environment to manipulate and analyze airborne and satellite radar images. One aim is to create radar products for the user from the original data to enhance the ease of understanding the contents. The results are called secondary image products and derive from the original digital images. Another aim is to support interactive SAR image analysis. Software methods permit use of a digital height model to create ortho images, synthetic images, stereo-ortho images, radar maps or color combinations of different component products. Efforts are ongoing to integrate individual tools into a combined hardware/software environment for interactive radar image analysis.

Target recognition and phase acquisition by using incoherent digital holographic imaging

NASA Astrophysics Data System (ADS)

Lee, Munseob; Lee, Byung-Tak

2017-05-01

In this study, we proposed the Incoherent Digital Holographic Imaging (IDHI) for recognition and phase information of dedicated target. Although recent development of a number of target recognition techniques such as LIDAR, there have limited success in target discrimination, in part due to low-resolution, low scanning speed, and computation power. In the paper, the proposed system consists of the incoherent light source, such as LED, Michelson interferometer, and digital CCD for acquisition of four phase shifting image. First of all, to compare with relative coherence, we used a source as laser and LED, respectively. Through numerical reconstruction by using the four phase shifting method and Fresnel diffraction method, we recovered the intensity and phase image of USAF resolution target apart from about 1.0m distance. In this experiment, we show 1.2 times improvement in resolution compared to conventional imaging. Finally, to confirm the recognition result of camouflaged targets with the same color from background, we carry out to test holographic imaging in incoherent light. In this result, we showed the possibility of a target detection and recognition that used three dimensional shape and size signatures, numerical distance from phase information of obtained holographic image.

Digital holographic 3D imaging spectrometry (a review)

NASA Astrophysics Data System (ADS)

Yoshimori, Kyu

2017-09-01

This paper reviews recent progress in the digital holographic 3D imaging spectrometry. The principle of this method is a marriage of incoherent holography and Fourier transform spectroscopy. Review includes principle, procedure of signal processing and experimental results to obtain a multispectral set of 3D images for spatially incoherent, polychromatic objects.

Textural features for radar image analysis

NASA Technical Reports Server (NTRS)

Shanmugan, K. S.; Narayanan, V.; Frost, V. S.; Stiles, J. A.; Holtzman, J. C.

1981-01-01

Texture is seen as an important spatial feature useful for identifying objects or regions of interest in an image. While textural features have been widely used in analyzing a variety of photographic images, they have not been used in processing radar images. A procedure for extracting a set of textural features for characterizing small areas in radar images is presented, and it is shown that these features can be used in classifying segments of radar images corresponding to different geological formations.

A Practical Millimeter-Wave Holographic Imaging System with Tunable IF Attenuator

NASA Astrophysics Data System (ADS)

Zhu, Yu-Kun; Yang, Ming-Hui; Wu, Liang; Sun, Yun; Sun, Xiao-Wei

2017-10-01

A practical millimeter-wave (mmw) holographic imaging system with tunable intermediate frequency (IF) attenuator has been developed. It can be used for the detection of concealed weapons at security checkpoints, especially the airport. The system is utilized to scan the passenger and detect the weapons hidden in the clothes. To reconstruct the three dimensions (3-D) image, a holographic mmw imaging algorithm based on aperture synthesis and back scattering is presented. The system is active and works at 28-33 GHz. Tunable IF attenuator is applied to compensate the intensity and phase differences between multi-channels and multi-frequencies.

Digital holographic image fusion for a larger size object using compressive sensing

NASA Astrophysics Data System (ADS)

Tian, Qiuhong; Yan, Liping; Chen, Benyong; Yao, Jiabao; Zhang, Shihua

2017-05-01

Digital holographic imaging fusion for a larger size object using compressive sensing is proposed. In this method, the high frequency component of the digital hologram under discrete wavelet transform is represented sparsely by using compressive sensing so that the data redundancy of digital holographic recording can be resolved validly, the low frequency component is retained totally to ensure the image quality, and multiple reconstructed images with different clear parts corresponding to a laser spot size are fused to realize the high quality reconstructed image of a larger size object. In addition, a filter combing high-pass and low-pass filters is designed to remove the zero-order term from a digital hologram effectively. The digital holographic experimental setup based on off-axis Fresnel digital holography was constructed. The feasible and comparative experiments were carried out. The fused image was evaluated by using the Tamura texture features. The experimental results demonstrated that the proposed method can improve the processing efficiency and visual characteristics of the fused image and enlarge the size of the measured object effectively.

Holographic leaky-wave metasurfaces for dual-sensor imaging.

PubMed

Li, Yun Bo; Li, Lian Lin; Cai, Ben Geng; Cheng, Qiang; Cui, Tie Jun

2015-12-10

Metasurfaces have huge potentials to develop new type imaging systems due to their abilities of controlling electromagnetic waves. Here, we propose a new method for dual-sensor imaging based on cross-like holographic leaky-wave metasurfaces which are composed of hybrid isotropic and anisotropic surface impedance textures. The holographic leaky-wave radiations are generated by special impedance modulations of surface waves excited by the sensor ports. For one independent sensor, the main leaky-wave radiation beam can be scanned by frequency in one-dimensional space, while the frequency scanning in the orthogonal spatial dimension is accomplished by the other sensor. Thus, for a probed object, the imaging plane can be illuminated adequately to obtain the two-dimensional backward scattered fields by the dual-sensor for reconstructing the object. The relativity of beams under different frequencies is very low due to the frequency-scanning beam performance rather than the random beam radiations operated by frequency, and the multi-illuminations with low relativity are very appropriate for multi-mode imaging method with high resolution and anti- noise. Good reconstruction results are given to validate the proposed imaging method.

Athermally photoreduced graphene oxides for three-dimensional holographic images

PubMed Central

Li, Xiangping; Ren, Haoran; Chen, Xi; Liu, Juan; Li, Qin; Li, Chengmingyue; Xue, Gaolei; Jia, Jia; Cao, Liangcai; Sahu, Amit; Hu, Bin; Wang, Yongtian; Jin, Guofan; Gu, Min

2015-01-01

The emerging graphene-based material, an atomic layer of aromatic carbon atoms with exceptional electronic and optical properties, has offered unprecedented prospects for developing flat two-dimensional displaying systems. Here, we show that reduced graphene oxide enabled write-once holograms for wide-angle and full-colour three-dimensional images. This is achieved through the discovery of subwavelength-scale multilevel optical index modulation of athermally reduced graphene oxides by a single femtosecond pulsed beam. This new feature allows for static three-dimensional holographic images with a wide viewing angle up to 52 degrees. In addition, the spectrally flat optical index modulation in reduced graphene oxides enables wavelength-multiplexed holograms for full-colour images. The large and polarization-insensitive phase modulation over Ï in reduced graphene oxide composites enables to restore vectorial wavefronts of polarization discernible images through the vectorial diffraction of a reconstruction beam. Therefore, our technique can be leveraged to achieve compact and versatile holographic components for controlling light. PMID:25901676

Image improvement and three-dimensional reconstruction using holographic image processing

NASA Technical Reports Server (NTRS)

Stroke, G. W.; Halioua, M.; Thon, F.; Willasch, D. H.

1977-01-01

Holographic computing principles make possible image improvement and synthesis in many cases of current scientific and engineering interest. Examples are given for the improvement of resolution in electron microscopy and 3-D reconstruction in electron microscopy and X-ray crystallography, following an analysis of optical versus digital computing in such applications.

Recent advances in photorefractivity of poly(4-diphenylaminostyrene) composites: Wavelength dependence and dynamic holographic images

NASA Astrophysics Data System (ADS)

Tsujimura, Sho; Kinashi, Kenji; Sakai, Wataru; Tsutsumi, Naoto

2014-08-01

To expand upon our previous report [Appl. Phys. Express 5, 064101 (2012) 064101], we provide here the modified poly(4-diphenylaminostyrene) (PDAS)-based photorefractive (PR) device on the basis of wavelength dependency, and demonstrate dynamic holographic images by using the PDAS-based PR device under the obtained appropriate conditions. The PR devices containing the triphenylamine unit have potential application to dynamic holographic images, which will be useful for real-time holographic displays.

Acoustical holographic recording with coherent optical read-out and image processing

NASA Astrophysics Data System (ADS)

Liu, H. K.

1980-10-01

New acoustic holographic wave memory devices have been designed for real-time in-situ recording applications. The basic operating principles of these devices and experimental results through the use of some of the prototypes of the devices are presented. Recording media used in the device include thermoplastic resin, Crisco vegetable oil, and Wilson corn oil. In addition, nonlinear coherent optical image processing techniques including equidensitometry, A-D conversion, and pseudo-color, all based on the new contact screen technique, are discussed with regard to the enhancement of the normally poor-resolved acoustical holographic images.

Simultaneous multiplane imaging of human ovarian cancer by volume holographic imaging

PubMed Central

Orsinger, Gabriel V.; Watson, Jennifer M.; Gordon, Michael; Nymeyer, Ariel C.; de Leon, Erich E.; Brownlee, Johnathan W.; Hatch, Kenneth D.; Chambers, Setsuko K.; Barton, Jennifer K.; Kostuk, Raymond K.; Romanowski, Marek

2014-01-01

Abstract. Ovarian cancer is the most deadly gynecologic cancer, a fact which is attributable to poor early detection and survival once the disease has reached advanced stages. Intraoperative laparoscopic volume holographic imaging has the potential to provide simultaneous visualization of surface and subsurface structures in ovarian tissues for improved assessment of developing ovarian cancer. In this ex vivo ovarian tissue study, we assembled a benchtop volume holographic imaging system (VHIS) to characterize the microarchitecture of 78 normal and 40 abnormal tissue specimens derived from ovarian, fallopian tube, uterine, and peritoneal tissues, collected from 26 patients aged 22 to 73 undergoing bilateral salpingo-oophorectomy, hysterectomy with bilateral salpingo-oophorectomy, or abdominal cytoreductive surgery. All tissues were successfully imaged with the VHIS in both reflectance- and fluorescence-modes revealing morphological features which can be used to distinguish between normal, benign abnormalities, and cancerous tissues. We present the development and successful application of VHIS for imaging human ovarian tissue. Comparison of VHIS images with corresponding histopathology allowed for qualitatively distinguishing microstructural features unique to the studied tissue type and disease state. These results motivate the development of a laparoscopic VHIS for evaluating the surface and subsurface morphological alterations in ovarian cancer pathogenesis. PMID:24676382

Shuttle Imaging Radar - Geologic applications

NASA Technical Reports Server (NTRS)

Macdonald, H.; Bridges, L.; Waite, W.; Kaupp, V.

1982-01-01

The Space Shuttle, on its second flight (November 12, 1981), carried the first science and applications payload which provided an early demonstration of Shuttle's research capabilities. One of the experiments, the Shuttle Imaging Radar-A (SIR-A), had as a prime objective to evaluate the capability of spaceborne imaging radars as a tool for geologic exploration. The results of the experiment will help determine the value of using the combination of space radar and Landsat imagery for improved geologic analysis and mapping. Preliminary analysis of the Shuttle radar imagery with Seasat and Landsat imagery from similar areas provides evidence that spaceborne radars can significantly complement Landsat interpretation, and vastly improve geologic reconnaissance mapping in those areas of the world that are relatively unmapped because of perpetual cloud cover.

Applications review for a Space Program Imaging Radar (SPIR)

NASA Technical Reports Server (NTRS)

Simonett, D. S.

1976-01-01

The needs, applications, user support, research, and theoretical studies of imaging radar are reviewed. The applications of radar in water resources, minerals and petroleum exploration, vegetation resources, ocean radar imaging, and cartography are discussed. The advantages of space imaging radar are presented, and it is recommended that imaging radar be placed on the space shuttle.

Circularly polarized antennas for active holographic imaging through barriers

DOEpatents

McMakin, Douglas L [Richland, WA; Severtsen, Ronald H [Richland, WA; Lechelt, Wayne M [West Richland, WA; Prince, James M [Kennewick, WA

2011-07-26

Circularly-polarized antennas and their methods of use for active holographic imaging through barriers. The antennas are dielectrically loaded to optimally match the dielectric constant of the barrier through which images are to be produced. The dielectric loading helps to remove barrier-front surface reflections and to couple electromagnetic energy into the barrier.

Space Radar Image of Munich, Germany

NASA Technical Reports Server (NTRS)

1994-01-01

This spaceborne radar image of Munich, Germany illustrates the capability of a multi-frequency radar system to highlight different land use patterns in the area surrounding Bavaria's largest city. Central Munich is the white area at the middle of the image, on the banks of the Isar River. Pink areas are forested, while green areas indicate clear-cut and agricultural terrain. The Munich region served as a primary 'supersite' for studies in ecology, hydrology and radar calibration during the Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) missions. Scientists were able to use these data to map patterns of forest damage from storms and areas affected by bark beetle infestation. The image was acquired by SIR-C/X-SAR onboard the space shuttle Endeavour on April 18, 1994. The image is 37 kilometers by 32 kilometers (23 miles by 20 miles) and is centered at 48.2 degrees North latitude, 11.5 degrees East longitude. North is toward the upper right. The colors are assigned to different radar frequencies and polarizations of the radar as follows: red is L-band, vertically transmitted and horizontally received; green is C-band, vertically transmitted and horizontally received; and blue is C-band vertically transmitted and received. SIR-C/X-SAR, a joint mission of the German, Italian, and United States space agencies, is part of NASA's Mission to Planet Earth.

High-resolution three-dimensional imaging radar

NASA Technical Reports Server (NTRS)

Cooper, Ken B. (Inventor); Chattopadhyay, Goutam (Inventor); Siegel, Peter H. (Inventor); Dengler, Robert J. (Inventor); Schlecht, Erich T. (Inventor); Mehdi, Imran (Inventor); Skalare, Anders J. (Inventor)

2010-01-01

A three-dimensional imaging radar operating at high frequency e.g., 670 GHz, is disclosed. The active target illumination inherent in radar solves the problem of low signal power and narrow-band detection by using submillimeter heterodyne mixer receivers. A submillimeter imaging radar may use low phase-noise synthesizers and a fast chirper to generate a frequency-modulated continuous-wave (FMCW) waveform. Three-dimensional images are generated through range information derived for each pixel scanned over a target. A peak finding algorithm may be used in processing for each pixel to differentiate material layers of the target. Improved focusing is achieved through a compensation signal sampled from a point source calibration target and applied to received signals from active targets prior to FFT-based range compression to extract and display high-resolution target images. Such an imaging radar has particular application in detecting concealed weapons or contraband.

Space radar image of New York City

NASA Technical Reports Server (NTRS)

1995-01-01

This radar image of the New York city metropolitan area. The island of Manhattan appears in the center of the image. The green-colored rectangle on Manhattan is Central Park. This image was acquired by the Spaceborne Imaging Radar-C/X-band Synthetic Aperture Radar (SIR-C/ X-SAR) aboard the space shuttle Endeavour on October 10, 1994. North is toward the upper right. The area shown is 75.0 kilometers by 48.8 kilometers (46.5 miles by 30.2 miles). The image is centered at 40.7 degrees north latitude and 73.8 degrees west longitude. In general, light blue areas correspond to dense urban development, green areas to moderately vegetated zones and black areas to bodies of water. The Hudson River is the black strip that runs from the left edge to the upper right corner of the image. It separates New Jersey, in the upper left of the image, from New York. The Atlantic Ocean is at the bottom of the image where two barrier islands along the southern shore of Long Island are also visible. John F. Kennedy International Airport is visible above these islands. Long Island Sound, separating Long Island from Connecticut, is the dark area right of the center of the image. Many bridges are visible in the image, including the Verrazano Narrows, George Washington and Brooklyn bridges. The radar illumination is from the left of the image; this causes some urban zones to appear red because the streets are at a perpendicular angle to the radar pulse. The colors in this image were obtained using the following radar channels: red represents the L-band (horizontally transmitted and received); green represents the L-band (horizontally transmitted, vertically received); blue represents the C-band (horizontally transmitted, vertically received). Radar images like this one could be used as a tool for city planners and resource managers to map and monitor land use patterns. The radar imaging systems can clearly detect the variety of landscapes in the area, as well as the density of urban

Method and apparatus for holographic wavefront diagnostics

DOEpatents

Toeppen, J.S.

1995-04-25

A wavefront diagnostic apparatus has an optic and a measuring system. The optic forms a holographic image in response to a beam of light striking a hologram formed on a surface of the optic. The measuring system detects the position of the array of holographic images and compares the positions of the array of holographic images to a reference holographic image. 3 figs.

Method and apparatus for holographic wavefront diagnostics

DOEpatents

Toeppen, John S.

1995-01-01

A wavefront diagnostic apparatus has an optic and a measuring system. The optic forms a holographic image in response to a beam of light striking a hologram formed on a surface of the optic. The measuring system detects the position of the array of holographic images and compares the positions of the array of holographic images to a reference holographic image.

APQ-102 imaging radar digital image quality study

NASA Technical Reports Server (NTRS)

Griffin, C. R.; Estes, J. M.

1982-01-01

A modified APQ-102 sidelooking radar collected synthetic aperture radar (SAR) data which was digitized and recorded on wideband magnetic tape. These tapes were then ground processed into computer compatible tapes (CCT's). The CCT's may then be processed into high resolution radar images by software on the CYBER computer.

Space Radar Image of Dublin, Ireland

NASA Image and Video Library

1999-04-15

This radar image of Dublin, Ireland, shows how the radar distinguishes between densely populated urban areas and nearby areas that are relatively unsettled. In the center of the image is the city natural harbor along the Irish Sea.

Chaos Through-Wall Imaging Radar

NASA Astrophysics Data System (ADS)

Xu, Hang; Wang, Bingjie; Zhang, Jianguo; Liu, Li; Li, Ying; Wang, Yuncai; Wang, Anbang

2017-12-01

We experimentally demonstrate a chaos through-wall imaging radar using ultra-wideband chaotic-pulse-position modulation (CPPM) microwave signal. The CPPM signal based on logistic map with 1-ns pulse width and 1-GHz bandwidth is implemented by a field programmable gate array (FPGA) and then up-converted as the radar transmitting signal. Two-dimensional image of human objects behind obstacles is obtained by correlation method and back projection algorithm. Our experiments successfully perform through-wall imaging for single and multiple human objects through 20-cm thick wall. The down-range resolution of the proposed radar is 15 cm. Furthermore, the anti-jamming properties of the proposed radar in CPPM jamming, linear frequency-modulated jamming, and Gaussian noise jamming environments are demonstrated by electromagnetic simulations using the finite-difference time-domain. The simulation results show the CPPM microwave signal possesses excellent jamming immunity to the noise and radio frequency interference, which makes it perform superbly in multiradar environments.

Phase-image-based content-addressable holographic data storage

NASA Astrophysics Data System (ADS)

John, Renu; Joseph, Joby; Singh, Kehar

2004-03-01

We propose and demonstrate the use of phase images for content-addressable holographic data storage. Use of binary phase-based data pages with 0 and Ï phase changes, produces uniform spectral distribution at the Fourier plane. The absence of strong DC component at the Fourier plane and more intensity of higher order spatial frequencies facilitate better recording of higher spatial frequencies, and improves the discrimination capability of the content-addressable memory. This improves the results of the associative recall in a holographic memory system, and can give low number of false hits even for small search arguments. The phase-modulated pixels also provide an opportunity of subtraction among data pixels leading to better discrimination between similar data pages.

Radar image of Rio Sao Francisco, Brazil

NASA Technical Reports Server (NTRS)

2000-01-01

This radar image acquired by SRTM shows an area south of the Sao Francisco River in Brazil. The area is predominantly scrub forest. Areas such as these are difficult to map by traditional methods because of frequent cloud cover and local inaccessibility. Image brightness differences in this image are caused by differences in vegetation type and density. Tributaries of the Sao Francisco are visible in the upper right. The Sao Francisco River is a major source of water for irrigation and hydroelectric power. Mapping such regions will allow scientists to better understand the relationships between flooding cycles, forestation and human influences on ecosystems.

This radar image was obtained by the Shuttle Radar Topography Mission as part of its mission to map the Earth's topography. The image was acquired by just one of SRTM's two antennas, and consequently does not show topographic data but only the strength of the radar signal reflected from the ground. This signal, known as radar backscatter, provides insight into the nature of the surface, including its roughness, vegetation cover, and urbanization. The Shuttle Radar Topography Mission (SRTM), launched on February 11, 2000, uses the same radar instrument that comprised the Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) that flew twice on the Space Shuttle Endeavour in 1994. The mission is designed to collect three-dimensional measurements of the Earth's surface. To collect the 3-D data, engineers added a 60-meter-long (200-foot) mast, an additional C-band imaging antenna and improved tracking and navigation devices. The mission is a cooperative project between the National Aeronautics and Space Administration (NASA), the National Imagery and Mapping Agency (NIMA) and the German and Italian space agencies. It is managed by NASA's Jet Propulsion Laboratory, Pasadena, CA, for NASA's Earth Science Enterprise, Washington, DC.

Space Radar Image of Manaus, Brazil

NASA Image and Video Library

1999-01-27

This false-color L-band image of the Manaus region of Brazil was acquired by NASA Spaceborne Imaging Radar-C and X-Band Synthetic Aperture Radar SIR-C/X-SAR aboard the space shuttle Endeavour on orbit 46 of the mission.

Space Radar Image of Kilauea, Hawaii

NASA Image and Video Library

1999-01-27

This color composite C-band and L-band image of the Kilauea volcano on the Big Island of Hawaii was acquired by NASA Spaceborne Imaging Radar-C/X-band Synthetic Aperture Radar SIR-C/X-SAR flying on space shuttle Endeavour.

Space Radar Image of Safsaf Oasis, Egypt

NASA Technical Reports Server (NTRS)

1994-01-01

This three-frequency space radar image of south-central Egypt demonstrates the unique capability of imaging radar to penetrate thin sand cover in arid regions to reveal hidden details below the surface. Nearly all of the structures seen in this image are invisible to the naked eye and to conventional optical satellite sensors. Features appear in various colors because the three separate radar wavelengths are able to penetrate the sand to different depths. Areas that appear red or orange are places that can be seen only by the longest wavelength, L-band, and they are the deepest of the buried structures. Field studies in this area indicate L-band can penetrate as much as 2 meters (6.5 feet) of very dry sand to image buried rock structures. Ancient drainage channels at the bottom of the image are filled with sand more than 2 meters (6.5 feet) thick and therefore appear dark because the radar waves cannot penetrate them. The fractured orange areas at the top of the image and the blue circular structures in the center of the image are granitic areas that may contain mineral ore deposits. Scientists are using the penetrating capabilities of radar imaging in desert areas in studies of structural geology, mineral exploration, ancient climates, water resources and archaeology. This image is 51.9 kilometers by 30.2 kilometers (32.2 miles by 18.7 miles) and is centered at 22.7 degrees north latitude, 29.3degrees east longitude. North is toward the upper right. The colors are assigned to different radar frequencies and polarizations as follows: red is L-band, horizontally transmitted and received; green is C-band, horizontally transmitted and received; and blue is X-band, vertically transmitted and received. The image was acquired by the Spaceborne Imaging Radar-C/X-band Synthetic Aperture Radar (SIR-C/X-SAR) on April 16, 1994, on board the space shuttle Endeavour. SIR-C/X-SAR, a joint mission of the German, Italian and United States space agencies, is part of NASA's Mission

Spaceborne Imaging Radar Symposium

NASA Technical Reports Server (NTRS)

Elachi, C.

1983-01-01

An overview of the present state of the art in the different scientific and technological fields related to spaceborne imaging radars was presented. The data acquired with the SEASAT SAR (1978) and Shuttle Imaging Radar, SIR-A (1981) clearly demonstrated the important emphasis in the 80's is going to be on in-depth research investigations conducted with the more flexible and sophisticated SIR series instruments and on long term monitoring of geophysical phenomena conducted from free-flying platforms such as ERS-1 and RADARSAT.

Holographic storage of three-dimensional image and data using photopolymer and polymer dispersed liquid crystal films

NASA Astrophysics Data System (ADS)

Gao, Hong-Yue; Liu, Pan; Zeng, Chao; Yao, Qiu-Xiang; Zheng, Zhiqiang; Liu, Jicheng; Zheng, Huadong; Yu, Ying-Jie; Zeng, Zhen-Xiang; Sun, Tao

2016-09-01

We present holographic storage of three-dimensional (3D) images and data in a photopolymer film without any applied electric field. Its absorption and diffraction efficiency are measured, and reflective analog hologram of real object and image of digital information are recorded in the films. The photopolymer is compared with polymer dispersed liquid crystals as holographic materials. Besides holographic diffraction efficiency of the former is little lower than that of the latter, this work demonstrates that the photopolymer is more suitable for analog hologram and big data permanent storage because of its high definition and no need of high voltage electric field. Therefore, our study proposes a potential holographic storage material to apply in large size static 3D holographic displays, including analog hologram displays, digital hologram prints, and holographic disks. Project supported by the National Natural Science Foundation of China (Grant Nos. 11474194, 11004037, and 61101176) and the Natural Science Foundation of Shanghai, China (Grant No. 14ZR1415500).

space Radar Image of Long Valley, California

NASA Image and Video Library

1999-05-01

An area near Long Valley, California, was mapped by the Spaceborne Imaging Radar-C and X-band Synthetic Aperture Radar aboard the space shuttle Endeavor on April 13, 1994, during the first flight of the radar instrument, and on October 4, 1994, during the second flight of the radar instrument. The orbital configurations of the two data sets were ideal for interferometric combination -- that is overlaying the data from one image onto a second image of the same area to create an elevation map and obtain estimates of topography. Once the topography is known, any radar-induced distortions can be removed and the radar data can be geometrically projected directly onto a standard map grid for use in a geographical information system. The 50 kilometer by 50 kilometer (31 miles by 31 miles) map shown here is entirely derived from SIR-C L-band radar (horizontally transmitted and received) results. The color shown in this image is produced from the interferometrically determined elevations, while the brightness is determined by the radar backscatter. The map is in Universal Transverse Mercator (UTM) coordinates. Elevation contour lines are shown every 50 meters (164 feet). Crowley Lake is the dark feature near the south edge of the map. The Adobe Valley in the north and the Long Valley in the south are separated by the Glass Mountain Ridge, which runs through the center of the image. The height accuracy of the interferometrically derived digital elevation model is estimated to be 20 meters (66 feet) in this image. http://photojournal.jpl.nasa.gov/catalog/PIA01749

Space Radar Image of Samara, Russia

NASA Technical Reports Server (NTRS)

1994-01-01

This three-frequency space radar image shows the city of Samara, Russia in pink and light green right of center. Samara is at the junction of the Volga and Samara Rivers approximately 800 kilometers (500 miles) southeast of Moscow. The wide river in the center of the image is the Volga. Samara, formerly Kuybyshev, is a busy industrial city known for its chemical, mechanical and petroleum industries. Northwest of the Volga (upper left corner of the image) are deciduous forests of the Samarskaya Luka National Park. Complex patterns in the floodplain of the Volga are caused by 'cut-off' lakes and channels from former courses of the meandering river. The three radar frequencies allow scientists to distinguish different types of agricultural fields in the lower right side of the image. For example, fields which appear light blue are short grass or cleared fields. Purple and green fields contain taller plants or rough plowed soil. Scientists hope to use radar data such as these to understand the environmental consequences of industrial, agricultural and natural preserve areas coexisting in close proximity. This image is 50 kilometers by 26 kilometers (31 by 16 miles) and is centered at 53.2 degrees north latitude, 50.1 degrees east longitude. North is toward the top of the image. The colors are assigned to different radar frequencies and polarizations as follows: red is L-band, horizontally transmitted and received; green is C-band, horizontally transmitted and vertically received; and blue is X-band, vertically transmitted and received. The image was acquired by the Spaceborne Imaging Radar-C/X-band Synthetic Aperture Radar (SIR-C/X-SAR) on October 1, 1994 onboard the space shuttle Endeavour. SIR-C/X-SAR, a joint mission of the German, Italian and the United States space agencies, is part of NASA's Mission to Planet Earth.

The Second Spaceborne Imaging Radar Symposium

NASA Technical Reports Server (NTRS)

1986-01-01

Summaries of the papers presented at the Second Spaceborne Imaging Radar Symposium are presented. The purpose of the symposium was to present an overwiew of recent developments in the different scientific and technological fields related to spaceborne imaging radars and to present future international plans.

X-ray lithography using holographic images

DOEpatents

Howells, Malcolm S.; Jacobsen, Chris

1997-01-01

Methods for forming X-ray images having 0.25 .mu.m minimum line widths on X-ray sensitive material are presented. A holgraphic image of a desired circuit pattern is projected onto a wafer or other image-receiving substrate to allow recording of the desired image in photoresist material. In one embodiment, the method uses on-axis transmission and provides a high flux X-ray source having modest monochromaticity and coherence requirements. A layer of light-sensitive photoresist material on a wafer with a selected surface is provided to receive the image(s). The hologram has variable optical thickness and variable associated optical phase angle and amplitude attenuation for transmission of the X-rays. A second embodiment uses off-axis holography. The wafer receives the holographic image by grazing incidence reflection from a hologram printed on a flat metal or other highly reflecting surface or substrate. In this second embodiment, an X-ray beam with a high degree of monochromaticity and spatial coherence is required.

Space Radar Image of Belgrade, Serbia

NASA Technical Reports Server (NTRS)

1994-01-01

This spaceborne radar image of Belgrade, Serbia, illustrates the variety of land use patterns that can be observed with a multiple wavelength radar system. Belgrade, the capital of Serbia and former capital of Yugoslavia, is the bright area in the center of the image. The Danube River flows from the top to the bottom of the image, and the Sava River flows into the Danube from the left. Agricultural fields appear in shades of dark blue, purple and brown in outlying areas. Vegetated areas along the rivers appear in light blue-green, while dense forests in hillier areas in the lower left appear in a darker shade of green. The image was acquired by the Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) onboard the space shuttle Endeavour on October 2, 1994. The image is centered at 44.5 degrees north latitude and 20.5 degrees east longitude. North is toward the upper right. The image shows an area 36 kilometers by 32 kilometers 22 miles by 20 miles). The colors are assigned to different frequencies and polarizations of the radar as follows: red is L-band, horizontally transmitted, horizontally received; green is L-band, horizontally transmitted, vertically received; blue is C-band, horizontally transmitted, vertically received. SIR-C/X-SAR, a joint mission of the German, Italian and United States space agencies, is part of NASA's Mission to Planet Earth program.

Radar Image of Galapagos Island

NASA Technical Reports Server (NTRS)

1994-01-01

This is an image showing part of Isla Isabella in the western Galapagos Islands. It was taken by the L-band radar in HH polarization from the Spaceborne Imaging Radar C/X-Band Synthetic Aperture Radar on the 40th orbit of the space shuttle Endeavour. The image is centered at about 0.5 degree south latitude and 91 degrees west longitude and covers an area of 75 by 60 kilometers (47 by 37 miles). The radar incidence angle at the center of the image is about 20 degrees. The western Galapagos Islands, which lie about 1,200 kilometers (750 miles) west of Ecuador in the eastern Pacific, have six active volcanoes similar to the volcanoes found in Hawaii. Since the time of Charles Darwin's visit to the area in 1835, there have been over 60 recorded eruptions of these volcanoes. This SIR-C/X-SAR image of Alcedo and Sierra Negra volcanoes shows the rougher lava flows as bright features, while ash deposits and smooth pahoehoe lava flows appear dark. A small portion of Isla Fernandina is visible in the extreme upper left corner of the image. The Galapagos Islands are one of the SIR-C/X-SAR supersites and data of this area will be taken several times during the flight to allow scientists to conduct topographic change studies and to search for different lava flow types, ash deposits and fault lines. Spaceborne Imaging Radar-C and X-Synthetic Aperture Radar (SIR-C/X-SAR) is part of NASA's Mission to Planet Earth. The radars illuminate Earth with microwaves allowing detailed observations at any time, regardless of weather or sunlight conditions. SIR-C/X-SAR uses three microwave wavelengths: L-band (24 cm), C-band (6 cm) and X-band (3 cm). The multi-frequency data will be used by the international scientific community to better understand the global environment and how it is changing. The SIR-C/X-SAR data, complemented by aircraft and ground studies, will give scientists clearer insights into those environmental changes which are caused by nature and those changes

A study of image quality for radar image processing. [synthetic aperture radar imagery

NASA Technical Reports Server (NTRS)

King, R. W.; Kaupp, V. H.; Waite, W. P.; Macdonald, H. C.

1982-01-01

Methods developed for image quality metrics are reviewed with focus on basic interpretation or recognition elements including: tone or color; shape; pattern; size; shadow; texture; site; association or context; and resolution. Seven metrics are believed to show promise as a way of characterizing the quality of an image: (1) the dynamic range of intensities in the displayed image; (2) the system signal-to-noise ratio; (3) the system spatial bandwidth or bandpass; (4) the system resolution or acutance; (5) the normalized-mean-square-error as a measure of geometric fidelity; (6) the perceptual mean square error; and (7) the radar threshold quality factor. Selective levels of degradation are being applied to simulated synthetic radar images to test the validity of these metrics.

Space Radar Image of Wenatchee, Washington

NASA Technical Reports Server (NTRS)

1994-01-01

This spaceborne radar image shows a segment of the Columbia River as it passes through the area of Wenatchee, Washington, about 220 kilometers (136 miles) east of Seattle. The Wenatchee Mountains, part of the Cascade Range, are shown in green at the lower left of the image. The Cascades create a 'rain shadow' for the region, limiting rainfall east of the range to less than 26 centimeters (10 inches) per year. The radar's ability to see different types of vegetation is highlighted in the contrast between the pine forests, that appear in green and the dry valley plain that shows up as dark purple. The cities of Wenatchee and East Wenatchee are the grid-like areas straddling the Columbia River in the left center of the image. With a population of about 60,000, the region produces about half of Washington state's lucrative apple crop. Several orchard areas appear as green rectangular patches to the right of the river in the lower right center. Radar images such as these can be used to monitor land use patterns in areas such as Wenatchee, that have diverse and rapidly changing urban, agricultural and wild land pressures. This image was acquired by Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) onboard the space shuttle Endeavour on October 10, 1994. The image is 38 kilometers by 45 kilometers (24 miles by 30 miles) and is centered at 47.3 degrees North latitude, 120.1 degrees West longitude. North is toward the upper left. The colors are assigned to different radar frequencies and polarizations of the radar as follows: red is L-band, horizontally transmitted and received; green is L-band, horizontally transmitted, vertically received; and blue is C-band, horizontally transmitted, vertically received. SIR-C/X-SAR, a joint mission of the German, Italian, and United States space agencies, is part of NASA's Mission to Planet Earth.

Achromatized transmission-type holographic screen for a multiview stereoscopic image system

NASA Astrophysics Data System (ADS)

Hwang, Seon-Ho; Bobrinev, V. I.; Son, Jung-Young; Shestak, S. A.; Jeon, Hyung-Wook

1997-09-01

The main drawback of the use of transmission-type holographic screens is poor color reproduction caused by their high spectral dispersion. For overcoming this drawback, a long, narrow diffusing slit is used as an object when recording the screen. The necessary size and position of the slit relative to the photoplate and to the recording and reconstruction beams are determined by the phase relations of the beams. By use of the slit, holographic screens of 30 cm 40 cm are recorded with a diverging reference beam and are used to display a multiview full-color stereoscopic image. The images displayed on the screen show no sign of color separation except near the edges of the screen. The image brightness on the screen is high enough that it can be watched in a normally illuminated room.

Space Radar Image of Boston, Massachusetts

NASA Technical Reports Server (NTRS)

1994-01-01

This radar image of the area surrounding Boston, Mass., shows how a spaceborne radar system distinguishes between densely populated urban areas and nearby areas that are relatively unsettled. The bright white area at the right center of the image is downtown Boston. The wide river below and to the left of the city is the Charles River in Boston's Back Bay neighborhood. The dark green patch to the right of the Back Bay is Boston Common. A bridge across the north end of Back Bay connects the cities of Boston and Cambridge. The light green areas that dominate most of the image are the suburban communities surrounding Boston. The many ponds that dot the region appear as dark irregular spots. Many densely populated urban areas show up as red in the image due to the alignment of streets and buildings to the incoming radar beam. North is toward the upper left. The image was acquired on October 9, 1994, by the Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) as it flew aboard the space shuttle Endeavour. This area is centered at 42.4 degrees north latitude, 71.2 degrees west longitude. The area shown is approximately 37 km by 18 km (23 miles by 11 miles). Colors are assigned to different radar frequencies and polarizations as follows: red is L-band horizontally transmitted, horizontally received; green is L-band horizontally transmitted, vertically received; blue is C-band horizontally transmitted, vertically received. SIR-C/X-SAR, a cooperative mission of the German, Italian and United States space agencies, is part of NASA's Mission to Planet Earth program.

Compound Radar Approach for Breast Imaging.

PubMed

Byrne, Dallan; Sarafianou, Mantalena; Craddock, Ian J

2017-01-01

Multistatic radar apertures record scattering at a number of receivers when the target is illuminated by a single transmitter, providing more scattering information than its monostatic counterpart per transmission angle. This paper considers the well-known problem of detecting tumor targets within breast phantoms using multistatic radar. To accurately image potentially cancerous targets size within the breast, a significant number of multistatic channels are required in order to adequately calibrate-out unwanted skin reflections, increase the immunity to clutter, and increase the dynamic range of a breast radar imaging system. However, increasing the density of antennas within a physical array is inevitably limited by the geometry of the antenna elements designed to operate with biological tissues at microwave frequencies. A novel compound imaging approach is presented to overcome these physical constraints and improve the imaging capabilities of a multistatic radar imaging modality for breast scanning applications. The number of transmit-receive (TX-RX) paths available for imaging are increased by performing a number of breast scans with varying array positions. A skin calibration method is presented to reduce the influence of skin reflections from each channel. Calibrated signals are applied to receive a beamforming method, compounding the data from each scan to produce a microwave radar breast profile. The proposed imaging method is evaluated with experimental data obtained from constructed phantoms of varying complexity, skin contour asymmetries, and challenging tumor positions and sizes. For each imaging scenario outlined in this study, the proposed compound imaging technique improves skin calibration, clearly detects small targets, and substantially reduces the level of undesirable clutter within the profile.

Space Radar Image of Safsaf Oasis, Egypt

NASA Image and Video Library

1999-04-15

This three-frequency space radar image of south-central Egypt demonstrates the unique capability of imaging radar to penetrate thin sand cover in arid regions to reveal hidden details below the surface.

Space Radar Image of Kilauea, Hawaii - Interferometry 1

NASA Image and Video Library

1999-05-01

This X-band image of the volcano Kilauea was taken on October 4, 1994, by the Spaceborne Imaging Radar-C/X-band Synthetic Aperture Radar. The area shown is about 9 kilometers by 13 kilometers (5.5 miles by 8 miles) and is centered at about 19.58 degrees north latitude and 155.55 degrees west longitude. This image and a similar image taken during the first flight of the radar instrument on April 13, 1994 were combined to produce the topographic information by means of an interferometric process. This is a process by which radar data acquired on different passes of the space shuttle is overlaid to obtain elevation information. Three additional images are provided showing an overlay of radar data with interferometric fringes; a three-dimensional image based on altitude lines; and, finally, a topographic view of the region. http://photojournal.jpl.nasa.gov/catalog/PIA01763

STS-68 radar image: Kilauea, Hawaii

NASA Image and Video Library

1994-10-10

STS068-S-054 (10 October 1994) --- This is a deformation map of the south flank of Kilauea volcano on the big island of Hawaii, centered at 19.5 degrees north latitude and 155.25 degrees west longitude. The map was created by combining interferometric radar data - that is data acquired on different passes of the Space Shuttle Endeavour which are then overlaid to obtain elevation information - acquired by the Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) during its first flight in April 1994 and its second flight in October 1994. The area shown is approximately 40 by 80 kilometers (25 by 50 miles). North is toward the upper left of the image. The colors indicate the displacement of the surface in that direction that the radar instrument was pointed (toward the right of the image) in the six months between images. The analysis of ground movement is preliminary, but appears consistent with the motions detected by the Global Positioning System ground receivers that have been used over the past five years. The south flank of the Kilauea volcano is among the most rapidly deforming terrain's on Earth. Several regions show motion over the six-month time period. Most obvious is at the base of Hilina Pali, where 10 centimeters (4 inches) or more of crustal deformation can be seen in a concentrated area near the coastline. On a more localized scale, the currently active Pu'u O'o summit also shows about 10 centimeters (4 inches) of change near the vent area. Finally, there are indications of additional movement along the upper southwest rift zone, just below the Kilauea caldera in the image. Deformation of the south flank is believed to be the result of movements along faults deep beneath the surface of the volcano, as well as injections of magma, or molten rock, into the volcano's "plumbing" system. Detection of ground motions from space has proven to be a unique capability of imaging radar technology. Scientists hope to use deformation data

Continuum generation in optical fibers for high-resolution holographic coherence domain imaging application

NASA Astrophysics Data System (ADS)

Li, Linghui; Gruzdev, Vitaly; Yu, Ping; Chen, J. K.

2009-02-01

High pulse energy continuum generation in conventional multimode optical fibers has been studied for potential applications to a holographic optical coherence imaging system. As a new imaging modality for the biological tissue imaging, high-resolution holographic optical coherence imaging requires a broadband light source with a high brightness, a relatively low spatial coherence and a high stability. A broadband femtosecond laser can not be used as the light source of holographic imaging system since the laser creates a lot of speckle patterns. By coupling high peak power femtosecond laser pulses into a multimode optical fiber, nonlinear optical effects cause a continuum generation that can be served as a super-bright and broadband light source. In our experiment, an amplified femtosecond laser was coupled into the fiber through a microscopic objective. We measured the FWHM of the continuum generation as a function of incident pulse energy from 80 nJ to 800 Î¼J. The maximum FWHM is about 8 times higher than that of the input pulses. The stability was analyzed at different pump energies, integration times and fiber lengths. The spectral broadening and peak position show that more than two processes compete in the fiber.

Radar images analysis for scattering surfaces characterization

NASA Astrophysics Data System (ADS)

Piazza, Enrico

1998-10-01

According to the different problems and techniques related to the detection and recognition of airplanes and vehicles moving on the Airport surface, the present work mainly deals with the processing of images gathered by a high-resolution radar sensor. The radar images used to test the investigated algorithms are relative to sequence of images obtained in some field experiments carried out by the Electronic Engineering Department of the University of Florence. The radar is the Ka band radar operating in the'Leonardo da Vinci' Airport in Fiumicino (Rome). The images obtained from the radar scan converter are digitized and putted in x, y, (pixel) co- ordinates. For a correct matching of the images, these are corrected in true geometrical co-ordinates (meters) on the basis of fixed points on an airport map. Correlating the airplane 2-D multipoint template with actual radar images, the value of the signal in the points involved in the template can be extracted. Results for a lot of observation show a typical response for the main section of the fuselage and the wings. For the fuselage, the back-scattered echo is low at the prow, became larger near the center on the aircraft and than it decrease again toward the tail. For the wings the signal is growing with a pretty regular slope from the fuselage to the tips, where the signal is the strongest.

Space Radar Image of North Atlantic Ocean

NASA Image and Video Library

1999-04-15

This is a radar image showing surface features on the open ocean in the northeast Atlantic Ocean. There is no land mass in this image. The purple line in the lower left of the image is the stern wake of a ship. The ship creating the wake is the bright white spot on the middle, left side of the image. The ship's wake is about 28 kilometers (17 miles) long in this image and investigators believe that is because the ship may be discharging oil. The oil makes the wake last longer and causes it to stand out in this radar image. A fairly sharp boundary or front extends from the lower left to the upper right corner of the image and separates two distinct water masses that have different temperatures. The different water temperature affects the wind patterns on the ocean. In this image, the light green area depicts rougher water with more wind, while the purple area is calmer water with less wind. The dark patches are smooth areas of low wind, probably related to clouds along the front, and the bright green patches are likely due to ice crystals in the clouds that scatter the radar waves. The overall "fuzzy" look of this image is caused by long ocean waves, also called swells. Ocean radar imagery allows the fine detail of ocean features and interactions to be seen, such as the wake, swell, ocean front and cloud effects, which can then be used to enhance the understanding of ocean dynamics on smaller and smaller scales. The image is centered at 42.8 degrees north latitude, 26.2 degrees west longitude and shows an area approximately 35 kilometers by 65 kilometers (22 by 40 miles). The colors in the image are assigned to different frequencies and polarizations of the radar as follows: red is L-band horizontally transmitted, horizontally received; green is C-band horizontally transmitted, horizontally received; blue is L-band vertically transmitted, vertically received. This image was acquired by the Spaceborne Imaging Radar-C/X-band Synthetic Aperture Radar (SIR

Space Radar Image of West Texas - SAR Scan

NASA Image and Video Library

1999-04-15

This radar image of the Midland/Odessa region of West Texas, demonstrates an experimental technique, called ScanSAR, that allows scientists to rapidly image large areas of the Earth's surface. The large image covers an area 245 kilometers by 225 kilometers (152 miles by 139 miles). It was obtained by the Spaceborne Imaging Radar-C/X-Band Synthetic Aperture Radar (SIR-C/X-SAR) flying aboard the space shuttle Endeavour on October 5, 1994. The smaller inset image is a standard SIR-C image showing a portion of the same area, 100 kilometers by 57 kilometers (62 miles by 35 miles) and was taken during the first flight of SIR-C on April 14, 1994. The bright spots on the right side of the image are the cities of Odessa (left) and Midland (right), Texas. The Pecos River runs from the top center to the bottom center of the image. Along the left side of the image are, from top to bottom, parts of the Guadalupe, Davis and Santiago Mountains. North is toward the upper right. Unlike conventional radar imaging, in which a radar continuously illuminates a single ground swath as the space shuttle passes over the terrain, a Scansar radar illuminates several adjacent ground swaths almost simultaneously, by "scanning" the radar beam across a large area in a rapid sequence. The adjacent swaths, typically about 50 km (31 miles) wide, are then merged during ground processing to produce a single large scene. Illumination for this L-band scene is from the top of the image. The beams were scanned from the top of the scene to the bottom, as the shuttle flew from left to right. This scene was acquired in about 30 seconds. A normal SIR-C image is acquired in about 13 seconds. The ScanSAR mode will likely be used on future radar sensors to construct regional and possibly global radar images and topographic maps. The ScanSAR processor is being designed for 1996 implementation at NASA's Alaska SAR Facility, located at the University of Alaska Fairbanks, and will produce digital images from the

Space Radar Image of Saline Valley, California

NASA Technical Reports Server (NTRS)

1999-01-01

This is a three-dimensional perspective view of Saline Valley, about 30 km (19 miles) east of the town of Independence, California created by combining two spaceborne radar images using a technique known as interferometry. Visualizations like this one are helpful to scientists because they clarify the relationships of the different types of surfaces detected by the radar and the shapes of the topographic features such as mountains and valleys. The view is looking southwest across Saline Valley. The high peaks in the background are the Inyo Mountains, which rise more than 3,000 meters (10,000 feet) above the valley floor. The dark blue patch near the center of the image is an area of sand dunes. The brighter patches to the left of the dunes are the dry, salty lake beds of Saline Valley. The brown and orange areas are deposits of boulders, gravel and sand known as alluvial fans. The image was constructed by overlaying a color composite radar image on top of a digital elevation map. The radar image was taken by the Spaceborne Imaging Radar-C/X-bandSynthetic Aperture Radar (SIR-C/X-SAR) on board the space shuttleEndeavour in October 1994. The digital elevation map was producedusing radar interferometry, a process in which radar data are acquired on different passes of the space shuttle. The two data passes are compared to obtain elevation information. The elevation data were derived from a 1,500-km-long (930-mile) digital topographic map processed at JPL. Radar image data are draped over the topography to provide the color with the following assignments: red is L-band vertically transmitted, vertically received; green is C-band vertically transmitted, vetically received; and blue is the ratio of C-band vertically transmitted, vertically received to L-band vertically transmitted, vertically received. This image is centered near 36.8 degrees north latitude and 117.7 degre