research-article

Open access

Use the Right Sound for the Right Job: Verbal Commands and Auditory Icons for a Task-Management System Favor Different Information Processes in the Brain

Abstract

Design recommendations for notifications are typically based on user performance and subjective feedback. In comparison, there has been surprisingly little research on how designed notifications might be processed by the brain for the information they convey. The current study uses EEG/ERP methods to evaluate auditory notifications that were designed to cue long-distance truck drivers for task-management and driving conditions, particularly for automated driving scenarios. Two experiments separately evaluated naive students and professional truck drivers for their behavioral and brain responses to auditory notifications, which were either auditory icons or verbal commands. Our EEG/ERP results suggest that verbal commands were more readily recognized by the brain as relevant targets, but that auditory icons were more likely to update contextual working memory. Both classes of notifications did not differ on behavioral measures. This suggests that auditory icons ought to be employed for communicating contextual information and verbal commands, for urgent requests.

References

[1]

Matt Adcock and Stephen Barrass. 2004. Cultivating Design Patterns for Auditory Displays. In Proceedings of ICAD 04-Tenth Meeting of the International Conference on Auditory Display. 4--7.

[2]

Claude Alain. 2007. Breaking the wave: effects of attention and learning on concurrent sound perception. Hearing research 229, 1 (2007), 225--236.

[3]

Steven M. Belz, Gary S. Robinson, and John G. Casali. 1999. A new class of auditory warning signals for complex systems: Auditory icons. Human Factors 41, 4 (1999), 608--618.

[4]

Yoav Benjamini and Yosef Hochberg. 1995. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the royal statistical society. Series B (Methodological) (1995), 289--300.

[5]

David H. Brainard. 1997. The Psychophysics Toolbox. Spatial vision 10, 4 (1997), 433--436.

[6]

Anne-Marie Brouwer, Maarten A. Hogervorst, Jan BF Van Erp, Tobias Heffelaar, Patrick H Zimmerman, and Robert Oostenveld. 2012. Estimating workload using EEG spectral power and ERPs in the n-back task. Journal of neural engineering 9, 4 (2012), 045008.

[7]

Lewis Chuang, Christiane Glatz, and Stas Krupenia. 2017. Using EEG to Understand why Behavior to Auditory In-vehicle Notifications Differs Across Test Environments. In Proceedings of the 9th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (Automotive'UI 17). ACM, New York, NY, USA.

[8]

Kate E. Crowley and Ian M. Colrain. 2004. A review of the evidence for P2 being an independent component process: Age, sleep and modality. Clinical Neurophysiology 115, 4 (2004), 732--744.

[9]

A Cummings, Rita Ceponiene, Alain Koyama, Ayse P. Saygin, Jeanne Townsend, and Frederic Dick. 2006. Auditory semantic networks for words and natural sounds. Brain Research 1115, 1 (2006), 92--107.

[10]

Arnaud Delorme and Scott Makeig. 2004. EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. Journal of neuroscience methods 134, 1 (2004), 9--21.

[11]

Arnaud Delorme, Jason Palmer, Julie Onton, Robert Oostenveld, and Scott Makeig. 2012. Independent EEG sources are dipolar. PloS one 7, 2 (2012), e30135.

[12]

Frederic Dick, Ayse Pinar Saygin, Gaspare Galati, Sabrina Pitzalis, Simone Bentrovato, Simona D'Amico, Stephen Wilson, Elizabeth Bates, and Luigi Pizzamiglio. 2007. What is Involved and What is Necessary for Complex Linguistic and Nonlinguistic Auditory Processing: Evidence from Functional Magnetic Resonance Imaging and Lesion Data. Journal of Cognitive Neuroscience 19, 5 (2007), 799--816.

[13]

Tilman Dingler, Jeffrey Lindsay, and Bruce N. Walker. 2008. Learnability of Sound Cues for Environmental Features: Auditory Icons, Earcons, Spearcons, and Speech. 14th International Conference on Auditory Display (2008), 1--6.

[14]

Emanuel Donchin and Michael G.H. Coles. 1988. Is the P300 component a manifestation of context updating? Behavioral and brain sciences 11, 3 (1988), 357--374.

[15]

Connie C. Duncan-Johnson and Emanuel Donchin. 1977. Effects of a priori and sequential probability of stimuli on event-related potential. In Psychophysiology, Vol. 14. Cambridge Univ Press 40 West 20th Street, New York, NY 10011--4211, 95--95.

[16]

Judy Edworthy. 1994. The design and implementation of non-verbal auditory warnings. Applied Ergonomics 25, 4 (1994), 202--210.

[17]

Judy Edworthy and Rachael Hards. 1999. Learning auditory warnings: The effects of sound type, verbal labelling and imagery on the identification of alarm sounds. International Journal of Industrial Ergonomics 24, 6 (1999), 603--618.

[18]

Judy Edworthy and Elizabeth Hellier. 2006. Alarms and human behaviour: Implications for medical alarms. British Journal of Anaesthesia 97, 1 (2006), 12--17.

[19]

Carles Escera, Kimmo Alho, Erich Schröger, and István Winkler Winkler. 2000. Involuntary attention and distractibility as evaluated with event-related brain potentials. Audiology and Neurotology 5, 3--4 (2000), 151--166.

[20]

Monica Fabiani, Demetrios Karis, and Emanuel Donchin. 1986. P300 and recall in an incidental memory paradigm. Psychophysiology 23, 3 (1986), 298--308.

[21]

Johan Fagerlönn, Stefan Lindberg, and Anna Sirkka. 2015. Combined Auditory Warnings For Driving-Related Information. In Proceedings of the Audio Mostly 2015 on Interaction With Sound (AM '15). ACM, New York, NY, USA, Article 11, 5 pages.

[22]

Luis García-Larrea, Anne Claire Lukaszewicz, and François Mauguiére. 1992. Revisiting the oddball paradigm. Non-target vs neutral stimuli and the evaluation of ERP attentional effects. Neuropsychologia 30, 8 (1992), 723--741.

[23]

William Gaver. 1989. The SonicFinder: An Interface That Uses Auditory Icons. Human-Computer Interaction 4, 1 (1989), 67--94.

[24]

Robert Graham. 1999. Use of auditory icons as emergency warnings: evaluation within a vehicle collision avoidance application. Ergonomics 42, 9 (Sept. 1999), 1233--48.

[25]

Robert Graham, S.J. Hirst, and C. Carter. 1995. Auditory icons for collision-avoidance warnings. In Intelligent Transportation: Serving the User Through Deployment. Proceedings of the 1995 Annual Meeting of ITS America.

[26]

Rob Gray. 2011. Looming Auditory Collision Warnings for Driving. Human Factors: The Journal of the Human Factors and Ergonomics Society 53, 1 (2011), 63--74.

[27]

David M. Groppe, Thomas P. Urbach, and Marta Kutas. 2011. Mass univariate analysis of event-related brain potentials/fields I: a critical tutorial review. Psychophysiology 48, 12 (Dec. 2011), 1711--25.

[28]

Ellen Haas and Jeffrey Schmidt. 1995. Auditory icons as warning and advisory signals in the US Army Battlefield Combat Identification System (BCIS). In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, Vol. 39. SAGE Publications Sage CA: Los Angeles, CA, 999--1003.

[29]

Cristy Ho and Charles Spence. 2005. Assessing the effectiveness of various auditory cues in capturing a driver's visual attention. Journal of Experimental Psychology: Applied 11, 3 (2005), 157--74.

[30]

Cristy Ho and Charles Spence. 2006. Verbal interface design: Do verbal directional cues automatically orient visual spatial attention? Computers in Human Behavior 22, 4 (2006), 733--748.

[31]

Mandana L.N. Kazem, Janet M. Noyes, and Nicholas J. Lieven. 2003. Design Considerations for a Background Auditory Display to Aid Pilot Situation Awareness. In Proceedings of the 2003 International Conference on Auditory Display. 6--9.

[32]

Peter Keller and Catherine Stevens. 2004. Meaning From Environmental Sounds: Types of Signal-Referent Relations and Their Effect on Recognizing Auditory Icons. Journal of Experimental Psychology: Applied 10, 1 (2004), 3--12.

[33]

Mario Kleiner, David Brainard, Denis Pelli, Allen Ingling, Richard Murray, and Christopher Broussard. 2007. What's new in Psychtoolbox-3 - Perception 36, 14 (2007), 1.

[34]

Sonja A. Kotz. 2013. Electrophysiological Indices of Speech Processing. In Encyclopedia of Computational Neuroscience. 1--5.

[35]

Nina Kraus and Trent Nicol. 2008. Auditory evoked potentials. In Encyclopedia of Neuroscience. Springer, 214--218.

[36]

Stas Krupenia, Anna Selmarker, Johan Fagerlönn, Katarina Delsing, Anders Jansson, Bengt Sandblad, and Camilla Grane. 2014. The Methods for Designing Future Autonomous Systems' (MODAS) project: Developing the cab for a highly autonomous truck. In Proceedings of the 5th International Conference on Applied Human Factors and Ergonomics (AHFE2014) (Krakow, Poland). 19--23.

[37]

Yi-Chieh Lee, Wen-Chieh Lin, Jung-Tai King, Li-Wei Ko, Yu-Ting Huang, and Fu-Yin Cherng. 2014. An EEG-based approach for evaluating audio notifications under ambient sounds. Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI '14 (2014), 3817--3826.

[38]

Ying K. Leung, Sean Smith, Simon Parker, and Russell Martin. 1997. Learning and retention of auditory warnings. Proceedings of the Third International Conference on Auditory Display (1997).

[39]

Mats Liljedahl and Johan Fagerlönn. 2010. Methods for sound design: a review and implications for research and practice. In Proceedings of the 5th Audio Mostly Conference: A Conference on Interaction with Sound. ACM, 2.

[40]

Paul A. Lucas. 1994. An evaluation of the communicative ability of auditory icons and earcons. Georgia Institute of Technology.

[41]

Steven J. Luck. 2005. An Introduction to the Event-Related Potential Technique (Cognitive Neuroscience). (2005).

[42]

Dawn C. Marshall, John D. Lee, and P. Albert Austria. 2007. Alerts for in-vehicle information systems: Annoyance, urgency, and appropriateness. Human factors 49, 1 (2007), 145--157.

[43]

David K. McGookin and Stephen A. Brewster. 2004. Understanding concurrent earcons: Applying auditory scene analysis principles to concurrent earcon recognition. ACM Transactions on Applied Perception (TAP) 1, 2 (2004), 130--155.

[44]

Denis McKeown. 2005. Candidates for within-vehicle auditory displays. Georgia Institute of Technology.

[45]

Elizabeth D. Mynatt. 1994. Designing with auditory icons: how well do we identify auditory cues?. In Conference companion on Human factors in computing systems. ACM, 269--270.

[46]

Michael A. Nees and Bruce N Walker. 2011. Auditory displays for in-vehicle technologies. Reviews of human factors and ergonomics 7, 1 (2011), 58--99.

[47]

Gerald Novak, Walter Ritter, and Herbert G. Vaughan. 1992. Mismatch detection and the latency of temporal judgments. Psychophysiology 29, 4 (1992), 398--411.

[48]

Arne Nykänen. 2008. Methods for product sound design. Ph.D. Dissertation. Luleå tekniska universitet.

[49]

Casey O'Callaghan. 2009. Auditory perception. (2009).

[50]

Eunmi L. Oh and Robert A. Lutfi. 1999. Informational masking by everyday sounds. The Journal of the Acoustical Society of America 106, 6 (1999), 3521--3528.

[51]

Guido Orgs, Kathrin Lange, Jan Henryk Dombrowski, and Martin Heil. 2006. Conceptual priming for environmental sounds and words: An ERP study. Brain and Cognition 62, 3 (2006), 267--272.

[52]

Denis G. Pelli. 1997. The VideoToolbox software for visual psychophysics: transforming numbers into movies. (1997).

[53]

Caterina Piazza, Makoto Miyakoshi, Zyenab Akalin-Acar, Chiara Cantiani, Gianluigi Reni, Anna Maria Bianchi, and Scott Makeig. 2016. An Automated Function for Identifying EEG Independent Componetns Representing Bilateral Source Activity. XIV Mediterranean Conference on Medical and Biological Engineering and Computing 2016, IFMBE Proceedings 57 (2016), 105--109.

[54]

Terence W. Picton. 2010. Human auditory evoked potentials. Plural Publishing.

[55]

Terence W. Picton. 2014. Auditory event-related potentials. Encyclopedia of Computational Neuroscience (2014), 1--6.

[56]

Terence W. Picton and Steven A. Hillyard. 1974. Human auditory evoked potentials. II: effects of attention. Electroencephalography and clinical Neurophysiology 36 (1974), 191--199.

[57]

John Polich. 2007. Updating P300: An integrative theory of P3a and P3b. Clinical Neurophysiology 118 (2007), 2128--2148.

[58]

Friedemann Pulvermüller. 1999. Words in the brain's language. Behavioral and Brain Sciences 22, 1999 (1999), 253--336.

[59]

Brock R. Riggins and John Polich. 2002. Habituation of P3a and P3b from visual stimuli. The International Journal of Creativity & Problem Solving 12, 1 (2002), 71--81.

[60]

Ayse Pinar Saygin, Frederic Dick, and Elizabeth Bates. 2005. An on-line task for contrasting auditory processing in the verbal and nonverbal domains and norms for younger and older adults. Behavior Research Methods 37, 1 (2005), 99--110.

[61]

Ayse Pinar Saygin, Frederic Dick, Stephen W. Wilson, Nina F. Dronkers, and Elizabeth Bates. 2003. Neural resources for processing language and environmental sounds: Evidence from aphasia. Brain 126, 4 (2003), 928--945.

[62]

Antoine Shahin, Daniel J. Bosnyak, Laurel J. Trainor, and Larry E. Roberts. 2003. Enhancement of neuroplastic P2 and N1c auditory evoked potentials in musicians. Journal of Neuroscience 23, 13 (2003), 5545--5552.

[63]

Carol A. Simpson and Kristine Marchionda-Frost. 1984. Synthesized speech rate and pitch effects on intelligibility of warning messages for pilots. Human factors 26, 5 (1984), 509--517.

[64]

Charles Spence and Liliana Read. 2003. Speech shadowing while driving: On the difficulty of splitting attention between eye and ear. Psychological science 14, 3 (2003), 251--256.

[65]

Mitchell Steinschneider and Michelle Dunn. 2002. Electrophysiology in developmental neuropsychology. Handbook of neuropsychology 8, 1 (2002), 91--146.

[66]

David L. Strayer and William A. Johnston. 2001. Driven to Distraction: Dual-Task Studies of Simulated Driving and Conversing on a Cellular Telephone. Psychological Science 12, 6 (2001), 462--466.

[67]

Anna Szekely, Simonetta D'Amico, Antonella Devescovi, Kara Federmeier, Dan Herron, Gowri Iyer, Thomas Jacobsen, L Arévalo Anal'a, Andras Vargha, and Elizabeth Bates. 2005. Timed action and object naming. Cortex 41, 1 (2005), 7--25.

[68]

Tuyen V. Tran, Tomasz Letowski, and Kim S. Abouchacra. 2000. Evaluation of acoustic beacon characteristics for navigation tasks. Ergonomics 43, 6 (2000), 807--827.

[69]

Kai Tuuri, Manne-Sakari Mustonen, and Antti Pirhonen. 2007. Same sound-different meanings: A novel scheme for modes of listening. Proceedings of Audio Mostly (2007), 13--18.

[70]

Pernilla Ulfvengren. 2003. Design of natural warning sounds in human-machine systems. Ph.D. Dissertation. KTH.

[71]

Bruce N. Walker and Michael A. Nees. 2011. Theory of sonification. The sonification handbook (2011), 9--39.

[72]

Emily E. Wiese and John D. Lee. 2007. Attention grounding: a new approach to in-vehicle information system implementation. Theoretical Issues in Ergonomics Science 8, 3 (2007), 255--276.

[73]

Istvan Winkler, Susan L. Denham, and Carles Escera. 2013. Auditory Event-related Potentials. In Encyclopedia of Computational Neuroscience. 1--29.

[74]

David L. Woods. 1995. The component structure of the N1 wave of the human auditory evoked potential. Electroencephalography and Clinical Neurophysiology-Supplements Only 44 (1995), 102--109.

Cited By

View all

Meinhardt LRück MZähnle JElhaidary MColley MRietzler MRukzio EHey, What's Going On?Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies10.1145/36596188:2(1-24)

Wilson MShaban JMaior HSchneegass CCox AThe CHI’24 Workshop on the Future of Cognitive Personal InformaticsExtended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems10.1145/3613905.3636296(1-6)

Figalová NBieg HReiser JLiu YBaumann MChuang LPollatos OFrom Driver to Supervisor: Comparing Cognitive Load and EEG-Based Attentional Resource Allocation Across Automation LevelsInternational Journal of Human-Computer Studies10.1016/j.ijhcs.2023.103169182(103169)

Show More Cited By

Index Terms

Use the Right Sound for the Right Job: Verbal Commands and Auditory Icons for a Task-Management System Favor Different Information Processes in the Brain

Human-centered computing

Human computer interaction (HCI)

Recommendations

The role of right prefrontal and medial cortex in response inhibition: Interfering with action restraint and action cancellation using transcranial magnetic brain stimulation

The ability of inhibiting impulsive urges is paramount for human behavior. Such successful response inhibition has consistently been associated with activity in pFC. The current study aims to unravel the differential involvement of different areas ...

Magnetic Stimulation of the Right Visual Cortex Impairs Form-specific Priming

Recent evidence suggests that priming of objects across different images (abstract priming) and priming of specific images of an object (form-specific priming) are mediated by dissociable neural processing subsystems that operate in parallel and are ...

Electrophysiological correlates of stimulus-driven reorienting deficits after interference with right parietal cortex during a spatial attention task: A tms-eeg study

TMS interference over right intraparietal sulcus (IPS) causally disrupts behaviorally and EEG rhythmic correlates of endogenous spatial orienting before visual target presentation [Capotosto, P., Babiloni, C., Romani, G. L., & Corbetta, M. Differential ...

Information & Contributors

Information

Published In

8489 pages

ISBN:9781450356206

DOI:10.1145/3173574

General Chairs:

Regan Mandryk

University of Saskatchewan, Canada

,

Mark Hancock

University of Waterloo, Canada

,

Program Chairs:

Mark Perry

Brunel University London, UK

,

Anna Cox

University College London, UK

Copyright © 2018 Owner/Author.

This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike International 4.0 License.

Publisher

Association for Computing Machinery

New York, NY, United States

Publication History

Published: 21 April 2018

Permissions

Request permissions for this article.

Check for updates

Author Tags

auditory displays

autonomous vehicles

electroencephalography

in-vehicle interfaces

notifications

Qualifiers

Research-article

Funding Sources

Deutsche Forschungsgesellschaft

Conference

CHI '18

Acceptance Rates

CHI '18 Paper Acceptance Rate 666 of 2,590 submissions, 26%;

Overall Acceptance Rate 6,199 of 26,314 submissions, 24%

Contributors

Other Metrics

Bibliometrics & Citations

Bibliometrics

Article Metrics

15

Total Citations

View Citations

901

Total Downloads

Downloads (Last 12 months)151

Downloads (Last 6 weeks)27

Other Metrics

Citations

Cited By

View all

Meinhardt LRück MZähnle JElhaidary MColley MRietzler MRukzio EHey, What's Going On?Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies10.1145/36596188:2(1-24)

Wilson MShaban JMaior HSchneegass CCox AThe CHI’24 Workshop on the Future of Cognitive Personal InformaticsExtended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems10.1145/3613905.3636296(1-6)

Figalová NBieg HReiser JLiu YBaumann MChuang LPollatos OFrom Driver to Supervisor: Comparing Cognitive Load and EEG-Based Attentional Resource Allocation Across Automation LevelsInternational Journal of Human-Computer Studies10.1016/j.ijhcs.2023.103169182(103169)

Kosch TKarolus JZagermann JReiterer HSchmidt AWoźniak PA Survey on Measuring Cognitive Workload in Human-Computer InteractionACM Computing Surveys10.1145/358227255:13s(1-39)

Schneegass CWilson MMaior HChiossi FCox AWiese JThe Future of Cognitive Personal InformaticsProceedings of the 25th International Conference on Mobile Human-Computer Interaction10.1145/3565066.3609790(1-5)

Putze FPutze SSagehorn MMicek CSolovey EUnderstanding HCI Practices and Challenges of Experiment Reporting with Brain Signals: Towards Reproducibility and ReuseACM Transactions on Computer-Human Interaction10.1145/349055429:4(1-43)

Edwards JWintersberger PClark LRough DDoyle PBanks VWyner AJanssen CCowan BCUI @ Auto-UI: Exploring the Fortunate and Unfortunate Futures of Conversational Automotive User Interfaces13th International Conference on Automotive User Interfaces and Interactive Vehicular Applications10.1145/3473682.3479717(186-189)

Frison AForster YWintersberger PGeisel VRiener AWhere We Come from and Where We Are Going: A Systematic Review of Human Factors Research in Driving AutomationApplied Sciences10.3390/app1024891410:24(8914)

Schneegass CKosch TBaumann ARusu MHassib MHussmann HBernhaupt RMueller FVerweij DAndres JMcGrenere JCockburn AAvellino IGoguey ABjørn PZhao SSamson BKocielnik RBrainCoDe: Electroencephalography-based Comprehension Detection during Reading and ListeningProceedings of the 2020 CHI Conference on Human Factors in Computing Systems10.1145/3313831.3376707(1-13)

Wallmyr MSitompul TChuang LJanssen CDonker SChuang LJu W1st workshop on user interfaces for heavy vehiclesProceedings of the 11th International Conference on Automotive User Interfaces and Interactive Vehicular Applications: Adjunct Proceedings10.1145/3349263.3350757(1-6)

Show More Cited By

View Options

View options

PDF

View or Download as a PDF file.

PDF

eReader

View online with eReader.

eReader

Get Access

Login options

Check if you have access through your login credentials or your institution to get full access on this article.

Sign in

Full Access

Media

Figures

Other

Tables

Share

Share

Share this Publication link

Copied!

Copying failed.

Share on social media

Affiliations

Christiane Glatz

Max Planck Institute for Biological Cybernetics & International Max Planck Research School for Cognitive and Systems Neuroscience, Tuebingen, Baden-Wuerttemberg, Germany

Stas S. Krupenia

Scania CV AB, Södertälje, Sweden

Heinrich H. Bülthoff

Max Planck Institute for Biological Cybernetics, Tuebingen, Germany

Lewis L. Chuang

Max Planck Institute for Biological Cybernetics, Tuebingen, Baden-Wuerttemberg, Germany

Request permissions Authors Info & Affiliations