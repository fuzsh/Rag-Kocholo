{
    "id": "dbpedia_5396_0",
    "rank": 7,
    "data": {
        "url": "https://www.linkedin.com/posts/drsimonj_my-top-3-tips-to-view-more-experiment-data-activity-7163712884877852674-uFTm",
        "read_more_link": "",
        "language": "en",
        "title": "Simon Jackson on LinkedIn: My top 3 tips to view more experiment data without making worse…",
        "top_image": "https://media.licdn.com/dms/image/D5610AQFsUl2Avw_zOg/image-shrink_1280/0/1707962221769?e=2147483647&v=beta&t=OO17CN7Rui3uHW9IFoVI4JhFuvQiW7SmIvGZWpCjHjM",
        "meta_img": "https://media.licdn.com/dms/image/D5610AQFsUl2Avw_zOg/image-shrink_1280/0/1707962221769?e=2147483647&v=beta&t=OO17CN7Rui3uHW9IFoVI4JhFuvQiW7SmIvGZWpCjHjM",
        "images": [
            "https://media.licdn.com/dms/image/v2/D5616AQHkOcWpKNgLyQ/profile-displaybackgroundimage-shrink_200_800/profile-displaybackgroundimage-shrink_200_800/0/1721966090805?e=2147483647&v=beta&t=4GLXtkwkb_DHKxwLihF52lACloTJC9HNWWDMT6HqdA8"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Simon Jackson"
        ],
        "publish_date": "2024-02-15T01:57:27.088000+00:00",
        "summary": "",
        "meta_description": "My top 3 tips to view more experiment data without making worse decisions...\n\nFirst, the problem: more metrics -&gt; more false positives -&gt; worse decisions.\n\nSo…",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/posts/drsimonj_my-top-3-tips-to-view-more-experiment-data-activity-7163712884877852674-uFTm",
        "text": "Discussing with a colleague this week, he looked at me and said \"in this project you are DATA DRIVEN GUESSING most of the time!\". I found the expression quite interesting and I think I am going to use it more often. If you look at the definition of \"guessing\" on the Oxford Dictionary you will find \"to try and give an answer or make a judgement about something without being sure of all the facts\". I think the definition of DATA DRIVEN GUESSING can be something in between what is called DATA DRIVEN and what is called DATA AWARE. These two concepts are often summarized like this: A data-driven approach relies on data to guide decision-making, while a data-informed approach treats data as just one source of information that factors into decision-making. I would say that DATA DRIVEN GUESSING can be defined as a way of using data sources as the MAIN source, but understanding that there are other factors and therefore changing the data with a bit of gut feeling. So you have data to guide you, but the data you have as a reference is build on both past data and gut feeling.\n\nIs your data telling you the whole story, or just what you want to hear? 🤔 Data doesn’t lie. Or does it? It's easy to fall into the trap of confirmation bias, especially when you’ve poured your heart and soul into collecting and analyzing that data. We look for patterns and insights that align with our preconceived notions, often ignoring the signals that might suggest a different narrative. Here's the thing - data is only as good as its interpretation. The key is to approach data analysis with a critical eye. Question everything. Seek out those anomalies and outlier values that don't fit your hypothesis – they could lead to your next big breakthrough. Embracing the full spectrum of what your data has to offer ensures robust models, innovative solutions, and ultimately, real-world impact. So next time you dive into your dataset, ask yourself – am I listening to what the data is really saying, or just hearing what I want to hear? Stay curious. Stay analytical. The truth is out there, hidden in your data. Decode it wisely.\n\n𝟎̲𝟓̲ ̲-̲ ̲𝐋̲𝐨̲𝐛̲ ̲𝐚̲𝐧̲𝐝̲ ̲𝐭̲𝐡̲𝐞̲ ̲𝐓̲𝐫̲𝐢̲𝐜̲𝐤̲𝐲̲ ̲𝐓̲𝐫̲𝐚̲𝐩̲𝐬̲ 📊 Back to the basics of the 4 (sometimes 5 but we’ll not worry about that) levels of data analytics: Descriptive: What happened? 📈 Diagnostic: Why did it happen? 🔍 Predictive: What is going to happen? 🔮 Prescriptive: What action(s) do we take? 🚀 All these types of analytics have their uses. If you don’t know what happened, you’re running on gut feeling alone. If you know what happened but don’t know why, you can’t take advantage of good changes or correct bad ones. Predicting what will happen allows you to make proactive adjustments. Creating systems that automatically adjust to accurate future predictions takes some of the effort away. However, it’s easy to get the wrong balance. Getting stuck in “What?” overload with too many dashboards often results in wasted development effort and not enough action. Being overly attracted to the shiny promise of predictive and prescriptive analytics may mean you miss out on getting the basics right. And remember, garbage in equals garbage out—so make sure you have good data governance! 🌟\n\nThere's a whole literature about how people \"lie\" with data and data visualization. Though helpful, it's narrow and does not even begin to describe the real challenge with data. The same data can be interpreted in many ways, and data do not describe reality unequivocally. Then, you have the problem that you can't really \"control\" the reader, and each of us is a \"kaleidoscope\" of inclinations. The problem with data interpretation starts much earlier than we think. Even before we decide to do anything with a given data set. Here is a slide I am using in the second lecture of my course (soon to be available online). It conveys that \"issues\" can stem much earlier from the way a given data set has been generated. Ideally, we would like to sample from a \"population.\" Because of that, we imagine that every data set is a sort of random sample of a population, which usually is not. The way data points are selected influences what we can infer from the data. Then, the way the information is recorded can affect the reliability of the values we visualize. Finally, the way the values are derived before they are included in a data set can also affect what kind of inferences and interpretations are legitimate. So ... it's way more complex than it may seem. And here, we did not even start touching the data! -- What are your thoughts? Does it make sense to you the way I describe it here? Is there anything that I am missing?\n\nEveryone is talking about big data, but what if small data is all you have available? Here's how to turn your small data into powerful models: 1. 𝗤𝘂𝗮𝗹𝗶𝘁𝘆 𝗢𝘃𝗲𝗿 𝗤𝘂𝗮𝗻𝘁𝗶𝘁𝘆: Focus on the richness of your data. Small datasets that are highly relevant and well-curated can outperform massive ones with a lot of noise in them. Make every data point count. 2. 𝗙𝗲𝗮𝘁𝘂𝗿𝗲 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴: Extract more information from your data by creating new features that highlight underlying patterns or relationships. It's not always about having more data. It's about enhancing what you have. 3. 𝗦𝗶𝗺𝗽𝗹𝗶𝗳𝘆 𝗬𝗼𝘂𝗿 𝗠𝗼𝗱𝗲𝗹𝘀: Complex models crave big data. With smaller datasets, focus on simplicity. Lean towards models that are less prone to overfitting. 4. 𝗖𝗿𝗼𝘀𝘀-𝗩𝗮𝗹𝗶𝗱𝗮𝘁𝗶𝗼𝗻: With less data, validating your model's performance becomes even more crucial. Use techniques like cross-validation to ensure your model is robust and not just memorizing your data. 5. 𝗦𝘆𝗻𝘁𝗵𝗲𝘀𝗶𝘀 𝗠𝗼𝗿𝗲 𝗗𝗮𝘁𝗮: Use the patterns of your available data and create larger synthetic datasets based on those patterns. 6. 𝗧𝗿𝗮𝗻𝘀𝗳𝗲𝗿 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴: Reuse models that have been trained with larger datasets on similar use cases. With the right approach, even the smallest datasets can reveal insights and drive decisions. It's not the size of the data that matters, but the questions you ask and how you wield it. Did you ever struggled with cases of small data? #dataanalytics #predictivemodeling #smalldata\n\nBACKGROUND: What else do we need to know about the problem to understand this data? Context serves as the crucial bridge between raw data and meaningful insights, shaping the trajectory of informed decision-making. When data lacks context, its interpretation becomes incomplete and potentially misleading. The 5 Whys technique acts as a narrative unraveler, peeling back the layers of complexity surrounding the data. Commencing with \"Why do you need this data?\" and continuing to ask \"why\" provides the initial context and lays the groundwork for a thorough understanding of the problem's root cause. Subsequently, identifying the who, where, when, and how of data collection reveals the intricacies within the workflow, enriching the interconnectedness of disparate data points. This meticulous approach transforms isolated data into an interconnected web of information, fostering a profound comprehension of its implications and paving the way for insightful, context-rich analysis as raw data elevates to information. Lastly, a straightforward \"Tell me what else I need to understand about this problem and your concerns about using this data\" serves as a powerful open-ended question, eliciting additional context from those likely to be involved in decision-making and action implementation. Have you seen data interpreted as information leading to poor decisions or actions?"
    }
}