{
    "id": "dbpedia_8610_3",
    "rank": 28,
    "data": {
        "url": "https://arxiv.org/html/2401.16412v2",
        "read_more_link": "",
        "language": "en",
        "title": "Learning to Manipulate under Limited Information",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "computational social choice",
            "strategic voting",
            "machine learning"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "\\setcopyright\n\nnone \\acmConference[] \\copyrightyear \\acmYear2024 \\acmDOI \\acmPrice \\acmISBN \\settopmatterprintacmref=false \\setcopyrightnone \\acmConference[SCaLA-24]Appears at the 1st Workshop on Social Choice and Learning Algorithms (SCaLA 2024) held at the 23rd International Conference on Autonomous Agents and Multiagent Systems May 6-7, 2024Auckland, New ZealandArmstrong, Fairstein, Mattei, Terzopoulou \\copyrightyear2024 \\acmYear2024 \\acmDOI \\acmPrice \\acmISBN \\settopmatterprintacmref=false \\acmSubmissionID¡¡EasyChair submission id¿¿ \\affiliation \\institutionUniversity of California, Berkeley \\cityBerkeley, CA \\countryUSA \\affiliation \\institutionUniversity of California, Berkeley \\cityBerkeley, CA \\countryUSA \\affiliation \\institutionUniversity of Maryland \\cityCollege Park, MD \\countryUSA\n\nLearning to Manipulate under Limited Information\n\nWesley H. Holliday , Alexander Kristoffersen and Eric Pacuit\n\nAbstract.\n\nBy classic results in social choice theory, any reasonable preferential voting method sometimes gives individuals an incentive to report an insincere preference. The extent to which different voting methods are more or less resistant to such strategic manipulation has become a key consideration for comparing voting methods. Here we measure resistance to manipulation by whether neural networks of varying sizes can learn to profitably manipulate a given voting method in expectation, given different types of limited information about how other voters will vote. We trained over 70,000 neural networks of 26 sizes to manipulate against 8 different voting methods, under 6 types of limited information, in committee-sized elections with 5–21 voters and 3–6 candidates. We find that some voting methods, such as Borda, are highly manipulable by networks with limited information, while others, such as Instant Runoff, are not, despite being quite profitably manipulated by an ideal manipulator with full information. For the two probability models for elections that we use, the overall least manipulable of the 8 methods we study are Condorcet methods, namely Minimax and Split Cycle.\n\nKey words and phrases:\n\ncomputational social choice, strategic voting, machine learning\n\n1. Introduction\n\nA fundamental problem in multi-agent decision making is that of aggregating heterogeneous preferences Conitzer (2010). Voting theory provides many possible methods of preference aggregation with different benefits and costs Zwicker (2016). However, no reasonable preferential voting method escapes the problem of manipulability. As shown by classic results such as the Gibbard-Satterthwaite theorem Gibbard (1973); Satterthwaite (1973) and its generalizations Duggan and Schwartz (2000); Taylor (2005), for any such voting method, there is some preference profile in which some voter has an incentive to report an insincere preference in order to obtain a result that is preferable, according to their sincere preference, to the result they would obtain if they were to submit their sincere preference. Thus, sincere voting is not a Nash equilibrium of the game derived from this preference profile, where the players are the voters and the actions are the possible preference rankings to report.\n\nHowever, the mere existence of a preference profile in which a voter has an incentive to misreport their preferences tells us little about the frequency with which a voter will have such an incentive or the difficulty of recognizing that such an incentive exists—under either full information or limited information about the profile. Thus, a manipulable voting method might be relatively resistant to manipulation, either because the frequency just cited is low, the difficulty just cited is high, or a mixture of both factors. Such resistance to manipulation has been considered an important criterion for comparing voting rules Merrill (1988); Green-Armytage et al. (2016).\n\nAs for the difficulty of manipuation, there is now a large literature in computational social choice on the worst-case complexity of computing whether there is a strategic ranking that will elect a desired candidate. Faliszewski and Procaccia Faliszewski and Procaccia (2010) call this literature “AI’s war on manipulation.” A series of hardness results have been proved since Bartholdi et al. (1989) and Conitzer et al. (2007). There is evidence for and against the view that high worst-case computational complexity is a barrier to manipulation Walsh (2011), and the situation with average-case manipulability might be quite different Mossel and Rácz (2013).\n\nIn this paper, we take a different approach than previous work, measuring resistance to manipulation by whether neural networks of varying sizes can learn to profitably manipulate a given voting method in expectation, given different types of information about how other voters will vote. Like the classic results on manipulation, we focus on the case of a single manipulating voter. A single voter can almost never affect the outcome of a large election with thousands of voters or more by changing their vote, so rational manipulation by a single voter is most relevant for small elections in committees, boards, etc. The classic results on manipulation also in effect assume that the manipulator knows exactly how all other voters will vote, which is unrealistic in many voting contexts. By contrast, we train neural networks to manipulate on the basis of different types of limited information.\n\n1.1. Related work\n\n1.1.1. Manipulation under Limited Information\n\nA number of previous papers study whether a voter can successfully manipulate in an election under limited information about how other voters will vote Myerson and Weber (1993); Conitzer et al. (2011); Reijngoud and Endriss (2012); Meir et al. (2014); Endriss et al. (2016); Lang (2020); Veselova (2023), including with the use of heuristics Chopra et al. (2004); Laslier (2009); Meir (2018); Fairstein et al. (2019). The information of the manipulator is typically represented by a set of preference profiles, all of which agree on (i) the manipulator’s own preferences and (ii) some other partial information (e.g., all profiles in the manipulator’s information set agree on who will win the election if the manipulator votes sincerely, or all profiles in the set are such that for each of the other voters i𝑖iitalic_i, i𝑖iitalic_i’s ranking in the profile extends some known partial order over the candidates that the manipulator attributes to i𝑖iitalic_i), perhaps supplemented with a probability measure over such profiles Lu et al. (2012). By contrast, in this paper we represent limited information by the inputs to a neural network, as described below.\n\n1.1.2. Machine Learning and Voting Theory\n\nSeveral previous works have applied machine learning to problems in voting theory, though not in the way we do here. Anil and Bao (2021) and Burka et al. (2022) study the learnability of various voting methods, Kang et al. (2023) studies learning how to explain election results for various voting methods, and Armstrong and Larson (2019) and Firebanks-Quevedo (2020) use machine learning to create new voting methods satisfying desiderata, but none of these papers discuss learning to manipulate as a voter. Manipulation is studied in Airiau et al. (2017), but only in the context of iterative voting, whereas here we focus on learning to manipulate in traditional elections, where the final winner is immediately computed after all voters submit their rankings.\n\n1.1.3. Machine Learnability as a Metric of Task Difficulty\n\nSufficiently large neural networks have been shown to be able to learn arbitrarily complex functions, including fitting to random data Zhang et al. (2017). If the model is not large enough to fully memorize the training data, however, learning the training data requires generalization. In the fields of reinforcement learning and natural language processing, it is commonly held that more complex problems may require larger and more complex networks. Indeed, previous work has shown that model performance grows as the number of learnable parameters increases Hestness et al. (2017); Golubeva et al. (2021). In this paper, we use required model size as a proxy for task difficulty. Not only has learnability by neural networks been taken to be suggestive of human learnability Steinert-Threlkeld and Szymanik (2020), but also, in practice, humans may use a neural network to help them manipulate an election under limited information.\n\n2. Preliminaries\n\nGiven a set V𝑉Vitalic_V of voters and a set X𝑋Xitalic_X of candidates, a preference profile for (V,X)𝑉𝑋(V,X)( italic_V , italic_X ) is a function 𝐏𝐏\\mathbf{P}bold_P assigning to each i∈V𝑖𝑉i\\in Vitalic_i ∈ italic_V a linear order 𝐏isubscript𝐏𝑖\\mathbf{P}_{i}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of X𝑋Xitalic_X. Where 𝐐𝐐\\mathbf{Q}bold_Q is a preference profile for (V,X)𝑉𝑋(V,X)( italic_V , italic_X ), i∉V𝑖𝑉i\\not\\in Vitalic_i ∉ italic_V, and 𝐏isubscript𝐏𝑖\\mathbf{P}_{i}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a linear order of X𝑋Xitalic_X, we write (𝐏i,𝐐)subscript𝐏𝑖𝐐(\\mathbf{P}_{i},\\mathbf{Q})( bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_Q ) for the preference profile that assigns to i𝑖iitalic_i the linear order 𝐏isubscript𝐏𝑖\\mathbf{P}_{i}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and assigns to each j∈V𝑗𝑉j\\in Vitalic_j ∈ italic_V the linear order 𝐐jsubscript𝐐𝑗\\mathbf{Q}_{j}bold_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. For a profile 𝐏𝐏\\mathbf{P}bold_P, let 𝐏−isubscript𝐏𝑖\\mathbf{P}_{-i}bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT be the profile restricted to all voters except i𝑖iitalic_i, so we may write 𝐏=(𝐏i,𝐏−i)𝐏subscript𝐏𝑖subscript𝐏𝑖\\mathbf{P}=(\\mathbf{P}_{i},\\mathbf{P}_{-i})bold_P = ( bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ).\n\nA utility profile for (V,X)𝑉𝑋(V,X)( italic_V , italic_X ) is a function 𝐔𝐔\\mathbf{U}bold_U assigning to each i∈V𝑖𝑉i\\in Vitalic_i ∈ italic_V a utility function 𝐔i:X→ℝ:subscript𝐔𝑖→𝑋ℝ\\mathbf{U}_{i}:X\\to\\mathbb{R}bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : italic_X → blackboard_R, where we assume that 𝐔i⁢(x)≠𝐔i⁢(y)subscript𝐔𝑖𝑥subscript𝐔𝑖𝑦{\\mathbf{U}_{i}(x)\\neq\\mathbf{U}_{i}(y)}bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) ≠ bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y ) whenever x≠y𝑥𝑦x\\neq yitalic_x ≠ italic_y. Given such a utility profile 𝐔𝐔\\mathbf{U}bold_U, its induced preference profile 𝐏⁢(𝐔)𝐏𝐔\\mathbf{P}(\\mathbf{U})bold_P ( bold_U ) assigns to each i∈V𝑖𝑉i\\in Vitalic_i ∈ italic_V the linear order ≻isubscriptsucceeds𝑖\\succ_{i}≻ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT defined by\n\nx≻iysubscriptsucceeds𝑖𝑥𝑦x\\succ_{i}yitalic_x ≻ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_y iff 𝐔i⁢(x)>𝐔i⁢(y)subscript𝐔𝑖𝑥subscript𝐔𝑖𝑦\\mathbf{U}_{i}(x)>\\mathbf{U}_{i}(y)bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) > bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y ).\n\nA (preferential) voting method for (V,X)𝑉𝑋(V,X)( italic_V , italic_X ) is a function F𝐹Fitalic_F whose domain is the set of preference profiles for (V,X)𝑉𝑋(V,X)( italic_V , italic_X ) such that for any 𝐏∈dom⁢(F)𝐏dom𝐹\\mathbf{P}\\in\\mathrm{dom}(F)bold_P ∈ roman_dom ( italic_F ), we have ∅≠F⁢(𝐏)⊆X𝐹𝐏𝑋\\varnothing\\neq F(\\mathbf{P})\\subseteq X∅ ≠ italic_F ( bold_P ) ⊆ italic_X. We list the voting methods we study in the next subsection.\n\nIn case F⁢(𝐏)𝐹𝐏F(\\mathbf{P})italic_F ( bold_P ) has more than one element, we assume an even-chance lottery Fℓ⁢(𝐏)subscript𝐹ℓ𝐏F_{\\ell}(\\mathbf{P})italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P ) on F⁢(𝐏)𝐹𝐏F(\\mathbf{P})italic_F ( bold_P ) determines the ultimate tiebreak winner. Thus, given a utility function 𝐔isubscript𝐔𝑖\\mathbf{U}_{i}bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT on X𝑋Xitalic_X, the expected utility of this lottery is given by\n\n𝐄𝐔i⁢(Fℓ⁢(𝐏))=∑a∈F⁢(𝐏)𝐔i⁢(a)|F⁢(𝐏)|.subscript𝐄𝐔𝑖subscript𝐹ℓ𝐏subscript𝑎𝐹𝐏subscript𝐔𝑖𝑎𝐹𝐏\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}))=\\frac{\\sum_{a\\in F(\\mathbf{P})}\\mathbf{U% }_{i}(a)}{|F(\\mathbf{P})|}.bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P ) ) = divide start_ARG ∑ start_POSTSUBSCRIPT italic_a ∈ italic_F ( bold_P ) end_POSTSUBSCRIPT bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_a ) end_ARG start_ARG | italic_F ( bold_P ) | end_ARG .\n\nGiven a voting method F𝐹Fitalic_F, utility profile 𝐔𝐔\\mathbf{U}bold_U for (V,X)𝑉𝑋(V,X)( italic_V , italic_X ) with 𝐏=𝐏⁢(𝐔)𝐏𝐏𝐔\\mathbf{P}=\\mathbf{P}(\\mathbf{U})bold_P = bold_P ( bold_U ), and voter i∈V𝑖𝑉i\\in Vitalic_i ∈ italic_V, we say that a linear order 𝐏i′superscriptsubscript𝐏𝑖′\\mathbf{P}_{i}^{\\prime}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT of X𝑋Xitalic_X is a profitable manipulation of F𝐹Fitalic_F at 𝐔𝐔\\mathbf{U}bold_U by i𝑖iitalic_i if\n\n𝐄𝐔i⁢(Fℓ⁢(𝐏i′,𝐏−i))>𝐄𝐔i⁢(Fℓ⁢(𝐏)).subscript𝐄𝐔𝑖subscript𝐹ℓsubscriptsuperscript𝐏′𝑖subscript𝐏𝑖subscript𝐄𝐔𝑖subscript𝐹ℓ𝐏\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}^{\\prime}_{i},\\mathbf{P}_{-i}))>\\mathbf{EU}% _{i}(F_{\\ell}(\\mathbf{P})).bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ) ) > bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P ) ) . (1)\n\nWe say 𝐏i′superscriptsubscript𝐏𝑖′\\mathbf{P}_{i}^{\\prime}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is optimal if the left-hand side of (1) is maximized for 𝐏i′subscriptsuperscript𝐏′𝑖\\mathbf{P}^{\\prime}_{i}bold_P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT among all possible linear orders of X𝑋Xitalic_X. We assume, as in standard decision theory Kreps (1988), that our manipulating agent aims to maximize expected utility and hence aims to submit an optimal ranking.\n\nA voting method F𝐹Fitalic_F is manipulable at 𝐔𝐔\\mathbf{U}bold_U by i𝑖iitalic_i if there is some profitable manipulation of F𝐹Fitalic_F at 𝐔𝐔\\mathbf{U}bold_U by i𝑖iitalic_i; and F𝐹Fitalic_F is manipulable if there is some utility profile 𝐔𝐔\\mathbf{U}bold_U and voter i𝑖iitalic_i such that F𝐹Fitalic_F is manipulable at 𝐔𝐔\\mathbf{U}bold_U by i𝑖iitalic_i. This notion of manipulability of F𝐹Fitalic_F coincides with the notion of manipulability of F𝐹Fitalic_F in Gibbard (1977) when we regard F𝐹Fitalic_F as a probabilistic voting method that assigns to each profile 𝐏𝐏\\mathbf{P}bold_P the lottery Fℓ⁢(𝐏)subscript𝐹ℓ𝐏F_{\\ell}(\\mathbf{P})italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P ).\n\n2.1. Voting Methods\n\nIn this paper, we focus on eight preferential voting methods:\n\nPlurality: the winners are those candidates who receive the most first-place rankings from voters.\n\nBorda: a candidate receives 00 points from each voter who ranks them in last place, 1111 point from each voter who ranks them in second-to-last place, 2 points from each voter who ranks them in third-to-last place, etc., yielding a Borda score; the candidates with maximal Borda score win.\n\nInstant Runoff (IRV): if more than half the voters rank the same candidate A𝐴Aitalic_A in first place, then A𝐴Aitalic_A wins; otherwise, A𝐴Aitalic_A is an IRV winner if A𝐴Aitalic_A is an IRV winner in the profile 𝐏′superscript𝐏′\\mathbf{P}^{\\prime}bold_P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT obtained from 𝐏𝐏\\mathbf{P}bold_P by removing all candidates who received the fewest first-place votes in 𝐏𝐏\\mathbf{P}bold_P (unless all candidates have the same number of first-place votes, in which case all of them win).\n\nInstant Runoff with parallel-universe tiebreaking (IRV-PUT): if more than half of the voters rank the same candidate A𝐴Aitalic_A in first place, then A𝐴Aitalic_A wins; otherwise a candidate A𝐴Aitalic_A is an IRV-PUT winner if for one of the candidates B𝐵Bitalic_B who received the fewest first-place votes in 𝐏𝐏\\mathbf{P}bold_P, A𝐴Aitalic_A is the IRV-PUT winner in the profile 𝐏−Bsubscript𝐏𝐵\\mathbf{P}_{-B}bold_P start_POSTSUBSCRIPT - italic_B end_POSTSUBSCRIPT obtained from 𝐏𝐏\\mathbf{P}bold_P by removing B𝐵Bitalic_B.\n\nMinimax: where the margin of A𝐴Aitalic_A vs. B𝐵Bitalic_B in 𝐏𝐏\\mathbf{P}bold_P is the number of voters who rank A𝐴Aitalic_A above B𝐵Bitalic_B minus the number who rank B𝐵Bitalic_B above A𝐴Aitalic_A in 𝐏𝐏\\mathbf{P}bold_P, the winners are those A𝐴Aitalic_A who minimize the quantity max⁢{m⁢a⁢r⁢g⁢i⁢n𝐏⁢(B,A)∣B∈X}maxconditional-set𝑚𝑎𝑟𝑔𝑖subscript𝑛𝐏𝐵𝐴𝐵𝑋\\mathrm{max}\\{margin_{\\mathbf{P}}(B,A)\\mid B\\in X\\}roman_max { italic_m italic_a italic_r italic_g italic_i italic_n start_POSTSUBSCRIPT bold_P end_POSTSUBSCRIPT ( italic_B , italic_A ) ∣ italic_B ∈ italic_X }.\n\nNanson: iteratively eliminate all candidates with less than average Borda score until there are no such candidates. The remaining candidates are Nanson winners.\n\nSplit Cycle: the margin graph of a profile is the weighted directed graph whose nodes are candidates with an edge from A𝐴Aitalic_A to B𝐵Bitalic_B of weight k𝑘kitalic_k if A𝐴Aitalic_A has a positive margin of k𝑘kitalic_k vs. B𝐵Bitalic_B. In each cycle in the graph (simultaneously), delete the edges with minimal weight. Then the candidates with no incoming edges are the winners.\n\nStable Voting: if there is only one Split Cycle winner in 𝐏𝐏\\mathbf{P}bold_P, they win; otherwise find the pairs of candidates (A,B)𝐴𝐵(A,B)( italic_A , italic_B ) where A𝐴Aitalic_A is a Split Cycle winner with the maximal margin of A𝐴Aitalic_A vs. B𝐵Bitalic_B such that A𝐴Aitalic_A is a Stable Voting winner in 𝐏−Bsubscript𝐏𝐵\\mathbf{P}_{-B}bold_P start_POSTSUBSCRIPT - italic_B end_POSTSUBSCRIPT, and declare A𝐴Aitalic_A a winner in 𝐏𝐏\\mathbf{P}bold_P.\n\nPlurality, Borda, and IRV are perhaps the most famous of preferential voting methods. Plurality has been used for many centuries, and Borda and IRV date back to at least the 18th century. The definition of IRV above (with simultaneous elimination of all candidates with the fewest first-place votes) matches that of Taylor and Pacelli (2008), while the PUT version is popular in computational social choice (see Wang et al. (2019)).\n\nMinimax Simpson (1969); Kramer (1977) is one of the most well known of the Condorcet-consistent voting methods. A voting method is Condorcet-consistent if whenever there is some candidate C𝐶Citalic_C who beats every other candidate B𝐵Bitalic_B head-to-head (i.e., C𝐶Citalic_C has a positive margin over each distinct B𝐵Bitalic_B), then this candidate—called the Condorcet winner—is the unique winner of the election. Plurality, Borda, IRV, and IRV-PUT all violate Condorcet consistency.\n\nThe Nanson method Nanson (1882) is also Condorcet-consistent and has previously been studied in connection with strategic voting. In Narodytska et al. (2011), it is shown that the problem of manipulating Nanson (and the related Baldwin method) is NP-hard when the number of candidates is allowed to increase.\n\nFinally, we include the recently proposed Split Cycle voting method Holliday and Pacuit (2023a), whose manipulability has been studied in Durand (2023), as well as one of its refinements, the Stable Voting method Holliday and Pacuit (2023b). These methods satisfy not only Condorcet consistency but also the stronger property—violated by Minimax—of Smith consistency, meaning that their winners always belong to the Smith set, the smallest set of candidates such that every candidate inside the set beats every candidate outside the set head-to-head. No previous work has studied the manipulability of Stable Voting, so studying this method tests if our approach can predict the manipulability of a method as measured in other ways in the future.\n\n3. Learning to Manipulate\n\nHow difficult is it for a computationally bounded agent to learn to manipulate against a given voting method under limited information? In this paper, we study this question through training and evaluating many multi-layer perceptrons (MLPs) with increasing numbers of learnable parameters. These MLPs act as function approximators for profitable manipulation policies for a given voting method and type of limited information. We can evaluate the manipulation resistance of a voting method by the size and complexity of the MLP required to learn a profitable manipulation policy, as well as the average profitability of learned policies.\n\n3.1. Implementation Details\n\nWe optimize weights θ𝜃\\thetaitalic_θ of an MLP f𝑓fitalic_f whose input x𝑥xitalic_x consists of a utility function 𝐔vsubscript𝐔𝑣\\mathbf{U}_{v}bold_U start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT for our manipulating voter v𝑣vitalic_v, as well as some limited information I𝐼Iitalic_I about the full utility profile 𝐔𝐔\\mathbf{U}bold_U (see Section 3.1.2). We apply a softmax to the output of the MLP to generate a probability distribution over all possible actions of v𝑣vitalic_v, namely the m!𝑚m!italic_m ! possible rankings, labeled 0 through m!−1𝑚1m!-1italic_m ! - 1, that v𝑣vitalic_v can submit, as in (2):\n\nfθ⁢(x)=π⁢(x)=[ℙ⁢(0|x),ℙ⁢(1|x),…,ℙ⁢(m!−1|x)].subscript𝑓𝜃𝑥𝜋𝑥ℙconditional0𝑥ℙconditional1𝑥…ℙ𝑚conditional1𝑥f_{\\theta}(x)=\\pi(x)=\\left[\\mathbb{P}(0|x),\\mathbb{P}(1|x),\\dots,\\mathbb{P}(m!% -1|x)\\right].italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) = italic_π ( italic_x ) = [ blackboard_P ( 0 | italic_x ) , blackboard_P ( 1 | italic_x ) , … , blackboard_P ( italic_m ! - 1 | italic_x ) ] . (2)\n\nNote that the manipulator is allowed to submit the sincere ranking given by their utility function; they are not forced to manipulate.\n\n3.1.1. Probability models for profiles\n\nTo generate utility profiles for our experiments described below, we first used a standard uniform utility model (see, e.g., (Merrill, 1988, p. 16)): for each voter independently, the utility of each candidate for that voter is drawn independently from the uniform distribution on the [0,1]01[0,1][ 0 , 1 ] interval. We then also used a 2D spatial model: each candidate and each voter is independently placed in ℝ2superscriptℝ2\\mathbb{R}^{2}blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT according to the multivariate normal distribution (as in Merrill (1988)) with no correlation between the two dimensions; then the utility of a candidate for a voter is the square of the Euclidean distance between the candidate and the voter (using the quadratic proximity utility function as in (Samuel Merrill and Grofman, 1999, p. 21)).\n\nThese utility profiles can then be parameterized as 2D matrices, U∈ℝn×m𝑈superscriptℝ𝑛𝑚U\\in\\mathbb{R}^{n\\times m}italic_U ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_m end_POSTSUPERSCRIPT, where n𝑛nitalic_n is the number of voters, m𝑚mitalic_m is the number of candidates, and U[i,c]∈[0,1]subscript𝑈𝑖𝑐01U_{\\left[i,c\\right]}\\in\\left[0,1\\right]italic_U start_POSTSUBSCRIPT [ italic_i , italic_c ] end_POSTSUBSCRIPT ∈ [ 0 , 1 ]. To select the utility function for a given voter i𝑖iitalic_i is to select the row Uisubscript𝑈𝑖U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.\n\n3.1.2. Choices of Limited Information\n\nWe experimented with providing different types of input to the MLP, including the following types that are often taken to be natural forms of polling information in voting theory (see, e.g., (Reijngoud and Endriss, 2012, § 2.2), Veselova (2023)):\n\n•\n\nthe plurality score of each candidate A𝐴Aitalic_A, defined as the number of voters whose favorite candidate is A𝐴Aitalic_A. I∈ℕm𝐼superscriptℕ𝑚I\\in\\mathbb{N}^{m}italic_I ∈ blackboard_N start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT\n\n•\n\nthe plurality ranking, i.e., the ordinal ranking of the candidates by their plurality scores. I∈ℕm𝐼superscriptℕ𝑚I\\in\\mathbb{N}^{m}italic_I ∈ blackboard_N start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT\n\n•\n\nthe margin matrix of dimension m×m𝑚𝑚m\\times mitalic_m × italic_m, where an integer k𝑘kitalic_k in the (A,B)𝐴𝐵(A,B)( italic_A , italic_B )-coordinate of the matrix indicates that the margin of A𝐴Aitalic_A vs. B𝐵Bitalic_B is k𝑘kitalic_k. I∈ℤm×m𝐼superscriptℤ𝑚𝑚I\\in\\mathbb{Z}^{m\\times m}italic_I ∈ blackboard_Z start_POSTSUPERSCRIPT italic_m × italic_m end_POSTSUPERSCRIPT\n\n•\n\nthe majority matrix, obtained from the margin matrix by replacing all positive entries by 1111 and all negative entries by −11-1- 1. I∈{−1,0,1}m×m𝐼superscript101𝑚𝑚I\\in\\{-1,0,1\\}^{m\\times m}italic_I ∈ { - 1 , 0 , 1 } start_POSTSUPERSCRIPT italic_m × italic_m end_POSTSUPERSCRIPT\n\n•\n\nthe qualitative margin matrix, obtained from the margin matrix by replacing each positive margin by its rank in the ordering of margins from smallest to largest, and then adding negative entries so that the resulting matrix is skew-symmetric. I∈ℤm×m𝐼superscriptℤ𝑚𝑚I\\in\\mathbb{Z}^{m\\times m}italic_I ∈ blackboard_Z start_POSTSUPERSCRIPT italic_m × italic_m end_POSTSUPERSCRIPT\n\n•\n\nthe sincere winners, i.e., the candidates who would win according to the sincere profile 𝐏𝐏\\mathbf{P}bold_P. I∈{0,1}m𝐼superscript01𝑚I\\in\\{0,1\\}^{m}italic_I ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT\n\nThese additional inputs are flattened and concatenated to the manipulator’s utility function before being used as input to the MLP.\n\nNote, crucially, that the full preference profile 𝐏𝐏\\mathbf{P}bold_P is not uniquely determined by any of the types of limited information above. If the manipulating voter v𝑣vitalic_v had full knowledge of 𝐏𝐏\\mathbf{P}bold_P, they could simply compute which of the |X|!𝑋|X|!| italic_X | ! linear orders would be optimal to submit given 𝐏−isubscript𝐏𝑖\\mathbf{P}_{-i}bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT. But if v𝑣vitalic_v has only, e.g., the majority matrix of 𝐏𝐏\\mathbf{P}bold_P, then the set of profiles realizing that majority matrix can be enormous. For 6 candidates and 20 voters in addition to v𝑣vitalic_v, there are approximately 7.48×10387.48superscript10387.48\\times 10^{38}7.48 × 10 start_POSTSUPERSCRIPT 38 end_POSTSUPERSCRIPT profiles up to permuting the voters (which does not affect the choice of winners according to the anonymous voting rules in Section 2.1). For 6 candidates, there are 3(62)=265,356superscript3binomial622653563^{6\\choose 2}=265,3563 start_POSTSUPERSCRIPT ( binomial start_ARG 6 end_ARG start_ARG 2 end_ARG ) end_POSTSUPERSCRIPT = 265 , 356 majority matrices. Thus, on average there are about 7.48×1038/265,356≈2.82×10337.48superscript10382653562.82superscript10337.48\\times 10^{38}/265,356\\approx 2.82\\times 10^{33}7.48 × 10 start_POSTSUPERSCRIPT 38 end_POSTSUPERSCRIPT / 265 , 356 ≈ 2.82 × 10 start_POSTSUPERSCRIPT 33 end_POSTSUPERSCRIPT profiles that could realize a given majority matrix. It is therefore infeasible to check for every profile that could realize a given majority matrix, and every ranking that v𝑣vitalic_v could submit, the profitability of submitting that ranking in that profile. Instead, we will train an MLP to input a majority matrix and output an optimal ranking to submit without such infeasible brute force checking.\n\nAlso note that information sufficient for determining the sincere winner according to a voting method—e.g., the plurality ranking for Plurality, the qualitative margin matrix for Minimax, Split Cycle, and Stable Voting, etc.—is not necessarily sufficient for determining who would win after a particular manipulation.\n\n3.1.3. Labeling\n\nWe framed the learning objective as a classification task. Given a voting method and utility profile, we used the following labeling of each of the m!𝑚m!italic_m ! possible rankings v𝑣vitalic_v could submit:\n\n•\n\noptimizing labeling: all optimal rankings to submit are labeled by 1111, and all other rankings are labeled by 00.\n\nThe output of our MLPs is a distribution over all m!𝑚m!italic_m ! rankings given some information x𝑥xitalic_x about the current utility profile. It is equally valid for our agent to choose any of the positively-labeled rankings. We treat the binary labelings as a mask over the rankings and reduce the distribution π⁢(x)𝜋𝑥\\pi(x)italic_π ( italic_x ) to two values: the probability of choosing a positively-labeled ranking or not. We compute the final loss as the mean-squared error between this reduced distribution and the distribution assigning probability 1 to choosing a positively-labeled ranking and 0 to choosing a non-positively-labeled ranking.\n\n3.2. Evaluation\n\nTo evaluate how well a given MLP has learned to manipulate, we must convert its output distribution over rankings into a single ranking. To do so, we used the following decision rule:\n\n•\n\nargmax: select the ranking with the largest probability in the output of the MLP.\n\nAs our metric for the profitability of the MLP’s decision, we use the difference between the left and right-hand sides of (1) normalized by the greatest possible utility difference according to 𝐔isubscript𝐔𝑖\\mathbf{U}_{i}bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT:\n\n𝐄𝐔i⁢(Fℓ⁢(𝐏i′,𝐏−i))−𝐄𝐔i⁢(Fℓ⁢(𝐏))max⁢({𝐔i⁢(x)∣x∈X})−min⁢({𝐔i⁢(x)∣x∈X}).subscript𝐄𝐔𝑖subscript𝐹ℓsubscriptsuperscript𝐏′𝑖subscript𝐏𝑖subscript𝐄𝐔𝑖subscript𝐹ℓ𝐏maxconditional-setsubscript𝐔𝑖𝑥𝑥𝑋minconditional-setsubscript𝐔𝑖𝑥𝑥𝑋\\frac{\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}^{\\prime}_{i},\\mathbf{P}_{-i}))-% \\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}))}{\\mathrm{max}(\\{\\mathbf{U}_{i}(x)\\mid x% \\in X\\})-\\mathrm{min}(\\{\\mathbf{U}_{i}(x)\\mid x\\in X\\})}.divide start_ARG bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ) ) - bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P ) ) end_ARG start_ARG roman_max ( { bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) ∣ italic_x ∈ italic_X } ) - roman_min ( { bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) ∣ italic_x ∈ italic_X } ) end_ARG . (3)\n\nWe call this the profitability of 𝐏i′subscriptsuperscript𝐏′𝑖\\mathbf{P}^{\\prime}_{i}bold_P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT with respect to F,𝐔,i𝐹𝐔𝑖F,\\mathbf{U},iitalic_F , bold_U , italic_i.\n\nThe normalization in (3) is the standard normalization for relative utilitarianism Dhillon and Mertens (1999), which we use to compare utility differences across profiles. Indeed, (3) is equivalent to taking the difference in the Kaplan-normalized (d’Aspremont and Gevers, 2002, p. 470) expected utilities of submitting 𝐏′superscript𝐏′\\mathbf{P}^{\\prime}bold_P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT and of submitting 𝐏𝐏\\mathbf{P}bold_P, where u^=max⁢({𝐔i⁢(x)∣x∈X})^𝑢maxconditional-setsubscript𝐔𝑖𝑥𝑥𝑋\\hat{u}=\\mathrm{max}(\\{\\mathbf{U}_{i}(x)\\mid x\\in X\\})over^ start_ARG italic_u end_ARG = roman_max ( { bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) ∣ italic_x ∈ italic_X } ) and uˇ=min⁢({𝐔i⁢(x)∣x∈X})ˇ𝑢minconditional-setsubscript𝐔𝑖𝑥𝑥𝑋\\check{u}=\\mathrm{min}(\\{\\mathbf{U}_{i}(x)\\mid x\\in X\\})overroman_ˇ start_ARG italic_u end_ARG = roman_min ( { bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) ∣ italic_x ∈ italic_X } ):\n\n𝐄𝐔i⁢(Fℓ⁢(𝐏i′,𝐏−i))−uˇu^−uˇ−𝐄𝐔i⁢(Fℓ⁢(𝐏))−uˇu^−uˇ.subscript𝐄𝐔𝑖subscript𝐹ℓsubscriptsuperscript𝐏′𝑖subscript𝐏𝑖ˇ𝑢^𝑢ˇ𝑢subscript𝐄𝐔𝑖subscript𝐹ℓ𝐏ˇ𝑢^𝑢ˇ𝑢\\frac{\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}^{\\prime}_{i},\\mathbf{P}_{-i}))-% \\check{u}}{\\hat{u}-\\check{u}}-\\frac{\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}))-% \\check{u}}{\\hat{u}-\\check{u}}.divide start_ARG bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ) ) - overroman_ˇ start_ARG italic_u end_ARG end_ARG start_ARG over^ start_ARG italic_u end_ARG - overroman_ˇ start_ARG italic_u end_ARG end_ARG - divide start_ARG bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( bold_P ) ) - overroman_ˇ start_ARG italic_u end_ARG end_ARG start_ARG over^ start_ARG italic_u end_ARG - overroman_ˇ start_ARG italic_u end_ARG end_ARG .\n\nNote that for a particular decision by an MLP, the numerator of (3) may be negative, i.e., the MLP may be worse off by submitting an insincere ranking 𝐏′superscript𝐏′\\mathbf{P}^{\\prime}bold_P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT than they would have been by submitting the sincere ranking 𝐏𝐏\\mathbf{P}bold_P.\n\nFor a given trained MLP, we sample utility profiles according to one of our probability models and compute the average profitability of the MLP’s submitted rankings. We take the average profitability that is achievable against a given voting method as a measure of a voter’s incentive to manipulate against that voting method. This is a more revealing measure than the frequency with which the trained MLP manipulates against a voting method, since many of the MLP’s manipulations may be no better than sincere voting.\n\nFor the number of profiles to sample, we continued sampling until the estimated standard error of the mean (Robert and Casella, 2004, § 3.2) for profitability fell below 5e-4, resulting in small error bars (see Figure 3).\n\n3.2.1. Baselines\n\nFor baseline comparisons, we consider an agent with full information about a profile and unbounded computational resources, who always picks one of the optimal rankings to submit. We then estimated the average profitability as in (3) of this agent’s submitted ranking across many sampled elections, where as above we continued sampling until the estimated standard error of the mean fell below 5e-4.\n\n3.3. Training Setup\n\nFor each voting method F𝐹Fitalic_F, each number n∈{5,6,10,11,20,21}𝑛5610112021n\\in\\{5,6,10,11,20,21\\}italic_n ∈ { 5 , 6 , 10 , 11 , 20 , 21 }, each number m∈{3,4,5,6}𝑚3456m\\in\\{3,4,5,6\\}italic_m ∈ { 3 , 4 , 5 , 6 }, each choice of an input type for the MLP, and each choice of a model size (see the x-axis of Figure 3), we trained one or more “generations” of MLPs with that model size to manipulate elections with n𝑛nitalic_n voters and m𝑚mitalic_m candidates run using F𝐹Fitalic_F, resulting in over 70,000 trained MLPs. For a given generation, we used the same initialization of MLP weights and the same training, validation, and evaluation profiles for every MLP for n𝑛nitalic_n candidates and m𝑚mitalic_m voters. Across generations, we varied the initialization of MLP weights and used different training, validation, and evaluation profiles, to provide reassurance that our results were not due to lucky initial weights or profiles. All elections and labels were pre-computed so training could rely fully on the GPU.\n\nWe experimented with training the MLPs using different numbers of iterations—between 100 and 1000—different learning rates—1e-3, 3e-3, and 6e-3—and different batch sizes—256 and 512. We hand-tuned these hyper-parameters in order to maximize the performance of all MLPs across all voting methods and profile sizes. For the final training run reported here, we use a batch size of 512 and a learning rate of 6e-3. We train all models for at least 220 iterations and then terminate training with an early stopping rule: after every 20 iterations, we measure the average profitability on a validation batch of 4,096 elections. If 10 validation steps pass without an improvement of at least .001 in average profitability of the submitted ranking, we terminate training.\n\n3.3.1. Computing Infrastructure\n\nAll code was written in Python using PyTorch and the pref_voting library (pypi.org/project/pref-voting/), version 0.4.42, for all functions dealing with voting. Training and evaluation was parallelized across nine local Apple computers with Apple silicon, the most powerful equipped with an M2 Ultra with 24-core CPU, 76-core GPU, and 128GB of unified memory, running Mac OS 13, as well as up to sixteen cloud instances with Nvidia A6000 or A10 GPUs running Linux Ubuntu 18.04.\n\n4. Results\n\nWe begin by discussing our results under the uniform utility model and then turn to the 2D spatial model in Section 4.9.\n\nThe average profitability of submitting the optimal ranking in each election (see Baselines above) with different voting methods is shown by the black bars in Figure 1. The other colored bars are for MLP-based manipulators with different types of limited information. Figure 1 shows data for the best performing MLP (for a given number of candidates, number of voters, voting method, and choice of information) with any hidden layer configuration. Figure 3 below shows the performance of MLPs with each of the 26 different hidden layer configuration we tested, focusing on 6 candidates, 10/11 voters, and either the majority matrix or plurality scores choice of limited information. These figures all cover the first generation of trained MLPs. Results for the second and third generations of trained MLPs are qualitatively similar to the first (see Supplementary Material), though we lack a sufficient number of generations to make quantitative statistical claims. The following qualitative highlights are robust across generations. All claims are implicitly qualified to apply to elections with 3–6 candidates and 5-21 voters.\n\n4.1. The importance of majorities\n\nSufficiently large MLPs learned to profitably manipulate all voting methods we studied on the basis of knowing only the majority matrix, though the profitability of such manipulation varied dramatically across methods. Interestingly, we did not find a substantial increase in profitability of manipulation for MLPs that learned to manipulate on the basis of the more informative margin matrix instead of the majority matrix, except in the case of Borda (especially for 6 candidates, as shown in the Supplementary Material). In fact, the qualitative margin matrix was about as useful as the margin matrix for learning to manipulate Borda.\n\n4.2. The limited usefulness of plurality scores\n\nThough obviously useful for manipulating Plurality and somewhat useful for several methods for 3 candidates (though less useful for 4 or 5 candidates), knowing the plurality scores was insufficient in 6-candidate elections for profitably manipulating methods other than Plurality (though Borda may be barely manipulable in this case), as shown in Figure 3. Moreover, in the case of manipulating Plurality, learning to manipulate on the basis of the plurality ranking (see Figure 1) led to profitability comparable to learning to manipulate on the basis of the plurality scores themselves.\n\n4.3. Highly manipulable vs. resistant methods\n\nPlurality and especially Borda have long been regarded as highly manipulable. Our results show that this is so even under limited information, e.g., in the form of the majority matrix.\n\nIRV and IRV-PUT were quite resistant to manipulation on the basis of limited information (with the exception of the manipulability of IRV for 3 candidates and 10 voters), despite the fact that these methods are more manipulable than some others by an ideal manipulator. In addition, Minimax and Split Cycle stood out for their resistance to manipulation. It it is noteworthy that while Minimax and Split Cycle were not much more profitably manipulable than IRV and IRV-PUT on the basis of the majority matrix, qualitative margin matrix, or margin matrix in absolute terms (see top of Figure 1), MLPs came closer to the ideal manipulator for learning to manipulate Minimax and Split Cycle on the basis of this information than for IRV and IRV-PUT (see bottom of Figure 1), which are more manipulable by an ideal manipulator. Another noteworthy difference is that IRV and IRV-PUT are fairly manipulable by a voter with only the sincere winners information (see Figure 1), whereas Minimax and Split Cycle are not.\n\n4.4. The subtleties of tiebreaking\n\nWhile the distinction between IRV and IRV-PUT is subtle, it leads to significant differences with respect to single-voter manipulability under 3 candidates and an even number of voters (see graphs in the Supplementary Material). Of course, manipulation by a single voter is only possible in very close elections, in which case ties matter.\n\n4.5. Parity of the number of voters\n\nIndeed, the parity of the number of voters is a key factor for some methods. This is most striking for Stable Voting, which is barely manipulable with 11 voters but more manipulable with 10 (see Figure 3). A key difference is that with 10 voters, it is possible to have margins of zero between candidates, in which case a single voter has more manipulative power under Stable Voting, which produces fewer tied elections in the presence of zero margins than other methods like Minimax.\n\n4.6. Effect of the number of candidates\n\nFor an ideal manipulator, manipulation becomes more profitable as the number of candidates increases (see the Supplementary Material). The same can be true for the MLP-based manipulators up to a point, e.g., 4 or 5 candidates for most voting methods when using the majority, qualitative margin, or margin information. However, the ratio between the profitability of the MLP-based manipulator’s submitted rankings and those of the ideal manipulator declines as the number of candidates increases from 3 to 6 (see Supplementary Material). This is intuitive, as manipulation should increase in complexity with more candidates.\n\n4.7. Profitability and ease of learnability\n\nNot only is it more profitable to manipulate, say, Borda than Stable Voting, but it is also easier to learn—in the sense of requiring smaller MLPs: whether we consider one, two, or three hidden layers, in each case a smaller network is needed to learn to profitably manipulate Borda on the basis of the majority matrix (see Figure 3).\n\n4.8. Worst-case complexity vs. learnability\n\nDespite the NP-hardness of deciding if one can manipulate Nanson so as to elect a desired candidate, it is still possible to learn to do so on the basis of just the majority matrix for elections with up to 6 candidates. In this connection, studying manipulability with more candidates is of great interest.\n\n4.9. Differences with the 2D spatial model\n\nComparing Figure 1 for the uniform utility model and Figure 2 for the 2D spatial model model, the most striking differences are (1) that all voting methods become less profitably manipulable (roughly by one half) under the spatial model and (2) even the best MLP’s could not learn to profitably manipulate against Minimax, Nanson, and Split Cycle under the spatial model. On the other hand, the comparative usefulness, for manipulating against each voting method, of the different types of limited information is largely the same under the spatial model as under the uniform utility model (this is true even for Minimax, Nanson, and Split Cycle, looking at which types of information produce less negative results). We conjuncture that these findings about types of limited information are robust across other standard probability models as well.\n\n5. Conclusion\n\nIn committee-sized elections (5-21 voters), MLPs can learn to vote strategically on the basis of limited information, though the profitability of doing so varies significantly between different voting methods. This serves as a proof of concept for the study of machine learnability of manipulation under limited information. There are a number of natural extensions for future work, including manipulation by a coalition of multiple voters, as well as different probability models for generating elections. Our code is already set up to handle these extensions, which only require more compute. However, further research is needed on other questions: What if all agents in the election strategize? And what is the social cost or benefit of the learned manipulations? Finally, one limitation of the classification approach in this paper is that it is infeasible to apply to more than 6 candidates. To overcome this limitation, we plan to develop a reinforcement learning approach to learning to manipulate.\n\nAcnowledgements\n\nFor helpful feedback, we thank Dominic Hughes, the anonymous reviewers for SCaLA, and the participants in the Values-Centered AI seminar at the University of Maryland in Fall 2023, the logic seminar at the University of Maryland in Spring 2024, and the Interdisciplinary Workshop on Computational Social Choice at the Center for Human-Compatible Artificial Intelligence in Spring 2024.\n\nReferences\n\n(1)\n\nAiriau et al. (2017) Stéphane Airiau, Umberto Grandi, and Filipo Studzinski Perotto. 2017. Learning Agents for Iterative Voting. In Algorithmic Decision Theory, Jörg Rothe (Ed.). Springer, Cham, 139–152.\n\nAnil and Bao (2021) Cem Anil and Xuchan Bao. 2021. Learning to Elect. In Advances in Neural Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan (Eds.), Vol. 34.\n\nArmstrong and Larson (2019) Ben Armstrong and Kate Larson. 2019. Machine Learning to Strengthen Democracy. NeurIPS Joint Workshop on AI for Social Good.\n\nBartholdi et al. (1989) J.J. Bartholdi, C.A. Tovey, and M.A. Trick. 1989. The computational difficulty of manipulating an election. Social Choice and Welfare 6 (1989), 227–241. https://doi.org/10.1007/BF00295861\n\nBlack (1958) Duncan Black. 1958. The theory of committees and elections. Cambridge University Press, Cambridge.\n\nBrandt et al. (2016) Felix Brandt, Vincent Conitzer, Ulle Endriss, Jérôme Lang, and Ariel D. Procaccia (Eds.). 2016. Handbook of Computational Social Choice. Cambridge University Press.\n\nBurka et al. (2022) Dávid Burka, Clemens Puppe, László Szepesváry, and Attila Tasnádi. 2022. Voting: A machine learning approach. European Journal of Operational Research 299 (2022), 1003–1017. https://doi.org/10.1016/j.ejor.2021.10.005\n\nChopra et al. (2004) Samir Chopra, Eric Pacuit, and Rohit Parikh. 2004. Knowledge-Theoretic Properties of Strategic Voting. In Logics in Artificial Intelligence. JELIA 2004. Lecture Notes in Computer Science, J.J. Alferes and J. Leite (Eds.), Vol. 3229. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-540-30227-8_5\n\nConitzer (2010) Vincent Conitzer. 2010. Making decisions based on the preferences of multiple agents. Commun. ACM 53, 3 (2010), 84–94. https://doi.org/10.1145/1666420.1666442\n\nConitzer et al. (2007) Vincent Conitzer, Tuomas Sandholm, and Jérôme Lang. 2007. When are elections with few candidates hard to manipulate? J. ACM 54, 3 (2007), 14–es. https://doi.org/10.1145/1236457.1236461\n\nConitzer et al. (2011) Vincent Conitzer, Toby Walsh, and Lirong Xia. 2011. Dominating Manipulations in Voting with Partial Information. In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence (AAAI-11). San Francisco, CA, USA, 638–643.\n\nd’Aspremont and Gevers (2002) Claude d’Aspremont and Louis Gevers. 2002. Social welfare functionals and interpersonal comparability. In Handbook of Social Choice and Welfare, Kenneth J. Arrow, Amartya K. Sen, and Kotaro Suzumura (Eds.). Vol. 1. North-Holland, Amsterdam, 459–541. https://doi.org/10.1016/S1574-0110(02)80014-5\n\nDhillon and Mertens (1999) Amrita Dhillon and Jean-François Mertens. 1999. Relative Utilitarianism. Econometrica 67, 3 (1999), 471–498.\n\nDuggan and Schwartz (2000) John Duggan and Thomas Schwartz. 2000. Strategic manipulability without resoluteness or shared beliefs: Gibbard-Satterthwaite generalized. Social Choice and Welfare 17, 1 (2000), 85–93. https://doi.org/10.1007/PL00007177\n\nDurand (2023) François Durand. 2023. Coalitional manipulation of voting rules: simulations on empirical data. Constitutional Political Economy 34 (2023), 390–409. https://doi.org/10.1007/s10602-022-09376-8\n\nEndriss et al. (2016) Ulle Endriss, Svetlana Obraztsova, Maria Polukarov, and Jeffrey S. Rosenschein. 2016. Strategic Voting with Incomplete Information. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI-16). 236–242.\n\nFairstein et al. (2019) Roy Fairstein, Adam Lauz, Reshef Meir, and Kobi Gal. 2019. Modeling People’s Voting Behavior with Poll Information. In Proceedings of the AAMAS 2019. 1422–1430.\n\nFaliszewski and Procaccia (2010) Piotr Faliszewski and Ariel D. Procaccia. 2010. AI’s War on Manipulation: Are We Winning? AI Magazine 31, 4 (2010), 53–64. https://doi.org/10.1609/aimag.v31i4.2314\n\nFirebanks-Quevedo (2020) Daniel Firebanks-Quevedo. 2020. Machine Learning? In MY Election? It’s More Likely Than You Think: Voting Rules via Neural Networks. Bachelor’s Thesis, Oberlin College.\n\nGibbard (1973) Allan Gibbard. 1973. Manipulation of voting schemes: A general result. Econometrica 41, 4 (1973), 587–601. https://doi.org/10.2307/1914083\n\nGibbard (1977) Allan Gibbard. 1977. Manipulation of schemes that mix voting with chance. Econometrica 45, 3 (1977), 665–681.\n\nGolubeva et al. (2021) Anna Golubeva, Behnam Neyshabur, and Guy Gur-Ari. 2021. Are wider nets better given the same number of parameters? (2021). arXiv:2010.14495 [cs.LG].\n\nGreen-Armytage et al. (2016) James Green-Armytage, T. Nicolaus Tideman, and Rafael Cosman. 2016. Statistical evaluation of voting rules. Social Choice and Welfare 46 (2016), 183–212. https://doi.org/10.1007/s00355-015-0909-0\n\nHestness et al. (2017) Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md. Mostofa Ali Patwary, Yang Yang, and Yanqi Zhou. 2017. Deep Learning Scaling is Predictable, Empirically. (2017). arXiv:1712.00409 [cs.LG].\n\nHolliday and Pacuit (2023a) Wesley H. Holliday and Eric Pacuit. 2023a. Split Cycle: A new Condorcet-consistent voting method independent of clones and immune to spoilers. Public Choice 197 (2023), 1–62.\n\nHolliday and Pacuit (2023b) Wesley H. Holliday and Eric Pacuit. 2023b. Stable Voting. Constitutional Political Economy 45 (2023), 421–433. https://doi.org/10.1007/s10602-022-09383-9\n\nKang et al. (2023) Inwon Kang, Qishen Han, and Lirong Xia. 2023. Learning to Explain Voting Rules, Extended Abstract. In Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems (AAMAS). London, United Kingdom.\n\nKramer (1977) Gerald H. Kramer. 1977. A dynamical model of political equilibrium. Journal of Economic Theory 16, 2 (1977), 310–334. https://doi.org/10.1016/0022-0531(77)90011-4\n\nKreps (1988) David M. Kreps. 1988. Notes on the Theory of Choice. Westview Press, Boulder, CO.\n\nKube and Puppe (2009) Sebastian Kube and Clemens Puppe. 2009. When and how do voters try to manipulate? Experimental evidence from Borda elections. Public Choice 139 (2009), 39–52.\n\nLang (2020) Jérôme Lang. 2020. Collective Decision Making under Incomplete Knowledge: Possible and Necessary Solutions. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-20) Survey Track. 4885–4891.\n\nLaslier (2009) Jean-François Laslier. 2009. The leader rule: A model of strategic approval voting in a large electorate. Journal of Theoretical Politics 21, 1 (2009), 113–136. https://doi.org/10.1177/0951629808097286\n\nLu et al. (2012) Tyler Lu, Pingzhong Tang, Ariel D. Procaccia, and Craig Boutilier. 2012. Bayesian Vote Manipulation: Optimal Strategies and Impact on Welfare. In Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence (UAI). Morgan Kaufmann, New York, 543–553.\n\nMeir (2018) Reshef Meir. 2018. Strategic Voting. Springer, Cham. https://doi.org/10.1007/978-3-031-01579-3\n\nMeir et al. (2014) Reshef Meir, Omer Lev, and Jeffrey S. Rosenschein. 2014. A local-dominance theory of voting equilibria. In Proceedings of the fifteenth ACM conference on Economics and computation (EC ’14). 313–330. https://doi.org/10.1145/2600057.2602860\n\nMerrill (1988) Samuel Merrill. 1988. Making Multicandidate Elections More Democratic. Princeton University Press.\n\nMossel and Rácz (2013) Elchanan Mossel and Miklós Z. Rácz. 2013. Election manipulation: the average case. ACM SIGecom Exchanges 11, 2 (2013), 22–24. https://doi.org/10.1145/2509002.2509007\n\nMyerson and Weber (1993) Roger B. Myerson and Robert J. Weber. 1993. A theory of voting equilibria. The American Political Science Review 87, 1 (1993), 102–114. https://doi.org/10.2307/2938959\n\nNanson (1882) E. J. Nanson. 1882. Methods of election. Transactions and Proceedings of the Royal Society of Victoria 19 (1882), 197–240.\n\nNarodytska et al. (2011) Nina Narodytska, Toby Walsh, and Lirong Xia. 2011. Manipulation of Nanson’s and Baldwin’s Rules. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 25. 713–718. https://doi.org/10.1609/aaai.v25i1.7872\n\nNiou (1987) Emerson M. S. Niou. 1987. A Note on Nanson’s Rule. Public Choice 54, 2 (1987), 191–193. https://doi.org/10.1007/BF00123006\n\nReijngoud and Endriss (2012) Annemieke Reijngoud and Ulle Endriss. 2012. Voter Response to Iterated Poll Information. In Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2012), V. Conitzer, M. Winikoff, L. Padgham, and W. van der Hoek (Eds.). Valencia, Spain.\n\nRobert and Casella (2004) Christian P. Robert and George Casella. 2004. Monte Carlo Statistical Methods (2 ed.). Springer New York, NY. https://doi.org/10.1007/978-1-4757-4145-2\n\nSamuel Merrill and Grofman (1999) III Samuel Merrill and Bernard Grofman. 1999. A Unified Theory of Voting: Directional and Proximity Spatial Models. Cambridge University Press, Cambridge. https://doi.org/10.1017/CBO9780511605864\n\nSatterthwaite (1973) Mark Satterthwaite. 1973. The Existence of a Strategy Proof Voting Procedure. Ph.D. Dissertation. University of Wisconsin.\n\nSchulze (2011) Markus Schulze. 2011. A new monotonic, clone-independent, reversal symmetric, and condorcet-consistent single-winner election method. Social Choice and Welfare 36 (2011), 267–303. https://doi.org/10.1007/s00355-010-0475-4\n\nSimpson (1969) Paul B. Simpson. 1969. On Defining Areas of Voter Choice: Professor Tullock on Stable Voting. The Quarterly Journal of Economics 83, 3 (1969), 478–490. https://doi.org/10.2307/1880533\n\nSteinert-Threlkeld and Szymanik (2020) Shane Steinert-Threlkeld and Jakub Szymanik. 2020. Ease of learning explains semantic universals. Cognition 195 (Feb 2020), 104076.\n\nTaylor (2005) Alan D. Taylor. 2005. Social Choice and the Mathematics of Manipulation. Cambridge University Press, Cambridge. https://doi.org/10.1017/cbo9780511614316\n\nTaylor and Pacelli (2008) Alan D. Taylor and Allison M. Pacelli. 2008. Mathematics and Politics: Strategy, Voting, Power, and Proof (2nd ed.). Springer, New York. https://doi.org/10.1007/978-0-387-77645-3\n\nTideman (1987) T. Nicolaus Tideman. 1987. Independence of Clones as a Criterion for Voting Rules. Social Choice and Welfare 4 (1987), 185–206. https://doi.org/10.1007/bf00433944\n\nVeselova (2023) Yuliya A. Veselova. 2023. Manipulation by Coalitions in Voting with Incomplete Information. In Data Analysis and Optimization: In Honor of Boris Mirkin’s 80th Birthday, Boris Goldengorin and Sergei Kuznetsov (Eds.). Springer, Cham, 377–395.\n\nWalsh (2011) Toby Walsh. 2011. Is computational complexity a barrier to manipulation? Annals of Mathematics and Artificial Intelligence 62 (2011), 7–26. https://doi.org/10.1007/s10472-011-9255-9\n\nWang et al. (2019) Jun Wang, Sujoy Sikdar, Tyler Shepherd Zhibing Zhao, Chunheng Jiang, and Lirong Xia. 2019. Practical Algorithms for Multi-Stage Voting Rules with Parallel Universes Tiebreaking. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19). AAAI Press.\n\nZhang et al. (2017) Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. 2017. Understanding deep learning requires rethinking generalization. (2017). arXiv:1611.03530 [cs.LG].\n\nZwicker (2016) William S. Zwicker. 2016. Introduction to the Theory of Voting. In Handbook of Computational Social Choice, Felix Brandt, Vincent Conitzer, Ulle Endriss, Jérôme Lang, and Ariel D. Procaccia (Eds.). Cambridge University Press, New York, 23–56. https://doi.org/10.1017/cbo9781107446984.003"
    }
}