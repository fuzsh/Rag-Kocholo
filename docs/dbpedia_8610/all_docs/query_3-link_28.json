{
    "id": "dbpedia_8610_3",
    "rank": 28,
    "data": {
        "url": "https://arxiv.org/html/2401.16412v2",
        "read_more_link": "",
        "language": "en",
        "title": "Learning to Manipulate under Limited Information",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "computational social choice",
            "strategic voting",
            "machine learning"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "\\setcopyright\n\nnone \\acmConference[] \\copyrightyear \\acmYear2024 \\acmDOI \\acmPrice \\acmISBN \\settopmatterprintacmref=false \\setcopyrightnone \\acmConference[SCaLA-24]Appears at the 1st Workshop on Social Choice and Learning Algorithms (SCaLA 2024) held at the 23rd International Conference on Autonomous Agents and Multiagent Systems May 6-7, 2024Auckland, New ZealandArmstrong, Fairstein, Mattei, Terzopoulou \\copyrightyear2024 \\acmYear2024 \\acmDOI \\acmPrice \\acmISBN \\settopmatterprintacmref=false \\acmSubmissionIDÂ¡Â¡EasyChair submission idÂ¿Â¿ \\affiliation \\institutionUniversity of California, Berkeley \\cityBerkeley, CA \\countryUSA \\affiliation \\institutionUniversity of California, Berkeley \\cityBerkeley, CA \\countryUSA \\affiliation \\institutionUniversity of Maryland \\cityCollege Park, MD \\countryUSA\n\nLearning to Manipulate under Limited Information\n\nWesley H. Holliday , Alexander Kristoffersen and Eric Pacuit\n\nAbstract.\n\nBy classic results in social choice theory, any reasonable preferential voting method sometimes gives individuals an incentive to report an insincere preference. The extent to which different voting methods are more or less resistant to such strategic manipulation has become a key consideration for comparing voting methods. Here we measure resistance to manipulation by whether neural networks of varying sizes can learn to profitably manipulate a given voting method in expectation, given different types of limited information about how other voters will vote. We trained over 70,000 neural networks of 26 sizes to manipulate against 8 different voting methods, under 6 types of limited information, in committee-sized elections with 5â€“21 voters and 3â€“6 candidates. We find that some voting methods, such as Borda, are highly manipulable by networks with limited information, while others, such as Instant Runoff, are not, despite being quite profitably manipulated by an ideal manipulator with full information. For the two probability models for elections that we use, the overall least manipulable of the 8 methods we study are Condorcet methods, namely Minimax and Split Cycle.\n\nKey words and phrases:\n\ncomputational social choice, strategic voting, machine learning\n\n1. Introduction\n\nA fundamental problem in multi-agent decision making is that of aggregating heterogeneous preferences Conitzer (2010). Voting theory provides many possible methods of preference aggregation with different benefits and costs Zwicker (2016). However, no reasonable preferential voting method escapes the problem of manipulability. As shown by classic results such as the Gibbard-Satterthwaite theorem Gibbard (1973); Satterthwaite (1973) and its generalizations Duggan and Schwartz (2000); Taylor (2005), for any such voting method, there is some preference profile in which some voter has an incentive to report an insincere preference in order to obtain a result that is preferable, according to their sincere preference, to the result they would obtain if they were to submit their sincere preference. Thus, sincere voting is not a Nash equilibrium of the game derived from this preference profile, where the players are the voters and the actions are the possible preference rankings to report.\n\nHowever, the mere existence of a preference profile in which a voter has an incentive to misreport their preferences tells us little about the frequency with which a voter will have such an incentive or the difficulty of recognizing that such an incentive existsâ€”under either full information or limited information about the profile. Thus, a manipulable voting method might be relatively resistant to manipulation, either because the frequency just cited is low, the difficulty just cited is high, or a mixture of both factors. Such resistance to manipulation has been considered an important criterion for comparing voting rules Merrill (1988); Green-Armytage et al. (2016).\n\nAs for the difficulty of manipuation, there is now a large literature in computational social choice on the worst-case complexity of computing whether there is a strategic ranking that will elect a desired candidate. Faliszewski and Procaccia Faliszewski and Procaccia (2010) call this literature â€œAIâ€™s war on manipulation.â€ A series of hardness results have been proved since Bartholdi et al. (1989) and Conitzer et al. (2007). There is evidence for and against the view that high worst-case computational complexity is a barrier to manipulation Walsh (2011), and the situation with average-case manipulability might be quite different Mossel and RÃ¡cz (2013).\n\nIn this paper, we take a different approach than previous work, measuring resistance to manipulation by whether neural networks of varying sizes can learn to profitably manipulate a given voting method in expectation, given different types of information about how other voters will vote. Like the classic results on manipulation, we focus on the case of a single manipulating voter. A single voter can almost never affect the outcome of a large election with thousands of voters or more by changing their vote, so rational manipulation by a single voter is most relevant for small elections in committees, boards, etc. The classic results on manipulation also in effect assume that the manipulator knows exactly how all other voters will vote, which is unrealistic in many voting contexts. By contrast, we train neural networks to manipulate on the basis of different types of limited information.\n\n1.1. Related work\n\n1.1.1. Manipulation under Limited Information\n\nA number of previous papers study whether a voter can successfully manipulate in an election under limited information about how other voters will vote Myerson and Weber (1993); Conitzer et al. (2011); Reijngoud and Endriss (2012); Meir et al. (2014); Endriss et al. (2016); Lang (2020); Veselova (2023), including with the use of heuristics Chopra et al. (2004); Laslier (2009); Meir (2018); Fairstein et al. (2019). The information of the manipulator is typically represented by a set of preference profiles, all of which agree on (i) the manipulatorâ€™s own preferences and (ii) some other partial information (e.g., all profiles in the manipulatorâ€™s information set agree on who will win the election if the manipulator votes sincerely, or all profiles in the set are such that for each of the other voters iğ‘–iitalic_i, iğ‘–iitalic_iâ€™s ranking in the profile extends some known partial order over the candidates that the manipulator attributes to iğ‘–iitalic_i), perhaps supplemented with a probability measure over such profiles Lu et al. (2012). By contrast, in this paper we represent limited information by the inputs to a neural network, as described below.\n\n1.1.2. Machine Learning and Voting Theory\n\nSeveral previous works have applied machine learning to problems in voting theory, though not in the way we do here. Anil and Bao (2021) and Burka et al. (2022) study the learnability of various voting methods, Kang et al. (2023) studies learning how to explain election results for various voting methods, and Armstrong and Larson (2019) and Firebanks-Quevedo (2020) use machine learning to create new voting methods satisfying desiderata, but none of these papers discuss learning to manipulate as a voter. Manipulation is studied in Airiau et al. (2017), but only in the context of iterative voting, whereas here we focus on learning to manipulate in traditional elections, where the final winner is immediately computed after all voters submit their rankings.\n\n1.1.3. Machine Learnability as a Metric of Task Difficulty\n\nSufficiently large neural networks have been shown to be able to learn arbitrarily complex functions, including fitting to random data Zhang et al. (2017). If the model is not large enough to fully memorize the training data, however, learning the training data requires generalization. In the fields of reinforcement learning and natural language processing, it is commonly held that more complex problems may require larger and more complex networks. Indeed, previous work has shown that model performance grows as the number of learnable parameters increases Hestness et al. (2017); Golubeva et al. (2021). In this paper, we use required model size as a proxy for task difficulty. Not only has learnability by neural networks been taken to be suggestive of human learnability Steinert-Threlkeld and Szymanik (2020), but also, in practice, humans may use a neural network to help them manipulate an election under limited information.\n\n2. Preliminaries\n\nGiven a set Vğ‘‰Vitalic_V of voters and a set Xğ‘‹Xitalic_X of candidates, a preference profile for (V,X)ğ‘‰ğ‘‹(V,X)( italic_V , italic_X ) is a function ğğ\\mathbf{P}bold_P assigning to each iâˆˆVğ‘–ğ‘‰i\\in Vitalic_i âˆˆ italic_V a linear order ğisubscriptğğ‘–\\mathbf{P}_{i}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of Xğ‘‹Xitalic_X. Where ğğ\\mathbf{Q}bold_Q is a preference profile for (V,X)ğ‘‰ğ‘‹(V,X)( italic_V , italic_X ), iâˆ‰Vğ‘–ğ‘‰i\\not\\in Vitalic_i âˆ‰ italic_V, and ğisubscriptğğ‘–\\mathbf{P}_{i}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a linear order of Xğ‘‹Xitalic_X, we write (ği,ğ)subscriptğğ‘–ğ(\\mathbf{P}_{i},\\mathbf{Q})( bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_Q ) for the preference profile that assigns to iğ‘–iitalic_i the linear order ğisubscriptğğ‘–\\mathbf{P}_{i}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and assigns to each jâˆˆVğ‘—ğ‘‰j\\in Vitalic_j âˆˆ italic_V the linear order ğjsubscriptğğ‘—\\mathbf{Q}_{j}bold_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. For a profile ğğ\\mathbf{P}bold_P, let ğâˆ’isubscriptğğ‘–\\mathbf{P}_{-i}bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT be the profile restricted to all voters except iğ‘–iitalic_i, so we may write ğ=(ği,ğâˆ’i)ğsubscriptğğ‘–subscriptğğ‘–\\mathbf{P}=(\\mathbf{P}_{i},\\mathbf{P}_{-i})bold_P = ( bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ).\n\nA utility profile for (V,X)ğ‘‰ğ‘‹(V,X)( italic_V , italic_X ) is a function ğ”ğ”\\mathbf{U}bold_U assigning to each iâˆˆVğ‘–ğ‘‰i\\in Vitalic_i âˆˆ italic_V a utility function ğ”i:Xâ†’â„:subscriptğ”ğ‘–â†’ğ‘‹â„\\mathbf{U}_{i}:X\\to\\mathbb{R}bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : italic_X â†’ blackboard_R, where we assume that ğ”iâ¢(x)â‰ ğ”iâ¢(y)subscriptğ”ğ‘–ğ‘¥subscriptğ”ğ‘–ğ‘¦{\\mathbf{U}_{i}(x)\\neq\\mathbf{U}_{i}(y)}bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) â‰  bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y ) whenever xâ‰ yğ‘¥ğ‘¦x\\neq yitalic_x â‰  italic_y. Given such a utility profile ğ”ğ”\\mathbf{U}bold_U, its induced preference profile ğâ¢(ğ”)ğğ”\\mathbf{P}(\\mathbf{U})bold_P ( bold_U ) assigns to each iâˆˆVğ‘–ğ‘‰i\\in Vitalic_i âˆˆ italic_V the linear order â‰»isubscriptsucceedsğ‘–\\succ_{i}â‰» start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT defined by\n\nxâ‰»iysubscriptsucceedsğ‘–ğ‘¥ğ‘¦x\\succ_{i}yitalic_x â‰» start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_y iff ğ”iâ¢(x)>ğ”iâ¢(y)subscriptğ”ğ‘–ğ‘¥subscriptğ”ğ‘–ğ‘¦\\mathbf{U}_{i}(x)>\\mathbf{U}_{i}(y)bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) > bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y ).\n\nA (preferential) voting method for (V,X)ğ‘‰ğ‘‹(V,X)( italic_V , italic_X ) is a function Fğ¹Fitalic_F whose domain is the set of preference profiles for (V,X)ğ‘‰ğ‘‹(V,X)( italic_V , italic_X ) such that for any ğâˆˆdomâ¢(F)ğdomğ¹\\mathbf{P}\\in\\mathrm{dom}(F)bold_P âˆˆ roman_dom ( italic_F ), we have âˆ…â‰ Fâ¢(ğ)âŠ†Xğ¹ğğ‘‹\\varnothing\\neq F(\\mathbf{P})\\subseteq Xâˆ… â‰  italic_F ( bold_P ) âŠ† italic_X. We list the voting methods we study in the next subsection.\n\nIn case Fâ¢(ğ)ğ¹ğF(\\mathbf{P})italic_F ( bold_P ) has more than one element, we assume an even-chance lottery Fâ„“â¢(ğ)subscriptğ¹â„“ğF_{\\ell}(\\mathbf{P})italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P ) on Fâ¢(ğ)ğ¹ğF(\\mathbf{P})italic_F ( bold_P ) determines the ultimate tiebreak winner. Thus, given a utility function ğ”isubscriptğ”ğ‘–\\mathbf{U}_{i}bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT on Xğ‘‹Xitalic_X, the expected utility of this lottery is given by\n\nğ„ğ”iâ¢(Fâ„“â¢(ğ))=âˆ‘aâˆˆFâ¢(ğ)ğ”iâ¢(a)|Fâ¢(ğ)|.subscriptğ„ğ”ğ‘–subscriptğ¹â„“ğsubscriptğ‘ğ¹ğsubscriptğ”ğ‘–ğ‘ğ¹ğ\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}))=\\frac{\\sum_{a\\in F(\\mathbf{P})}\\mathbf{U% }_{i}(a)}{|F(\\mathbf{P})|}.bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P ) ) = divide start_ARG âˆ‘ start_POSTSUBSCRIPT italic_a âˆˆ italic_F ( bold_P ) end_POSTSUBSCRIPT bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_a ) end_ARG start_ARG | italic_F ( bold_P ) | end_ARG .\n\nGiven a voting method Fğ¹Fitalic_F, utility profile ğ”ğ”\\mathbf{U}bold_U for (V,X)ğ‘‰ğ‘‹(V,X)( italic_V , italic_X ) with ğ=ğâ¢(ğ”)ğğğ”\\mathbf{P}=\\mathbf{P}(\\mathbf{U})bold_P = bold_P ( bold_U ), and voter iâˆˆVğ‘–ğ‘‰i\\in Vitalic_i âˆˆ italic_V, we say that a linear order ğiâ€²superscriptsubscriptğğ‘–â€²\\mathbf{P}_{i}^{\\prime}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT of Xğ‘‹Xitalic_X is a profitable manipulation of Fğ¹Fitalic_F at ğ”ğ”\\mathbf{U}bold_U by iğ‘–iitalic_i if\n\nğ„ğ”iâ¢(Fâ„“â¢(ğiâ€²,ğâˆ’i))>ğ„ğ”iâ¢(Fâ„“â¢(ğ)).subscriptğ„ğ”ğ‘–subscriptğ¹â„“subscriptsuperscriptğâ€²ğ‘–subscriptğğ‘–subscriptğ„ğ”ğ‘–subscriptğ¹â„“ğ\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}^{\\prime}_{i},\\mathbf{P}_{-i}))>\\mathbf{EU}% _{i}(F_{\\ell}(\\mathbf{P})).bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ) ) > bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P ) ) . (1)\n\nWe say ğiâ€²superscriptsubscriptğğ‘–â€²\\mathbf{P}_{i}^{\\prime}bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT is optimal if the left-hand side of (1) is maximized for ğiâ€²subscriptsuperscriptğâ€²ğ‘–\\mathbf{P}^{\\prime}_{i}bold_P start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT among all possible linear orders of Xğ‘‹Xitalic_X. We assume, as in standard decision theory Kreps (1988), that our manipulating agent aims to maximize expected utility and hence aims to submit an optimal ranking.\n\nA voting method Fğ¹Fitalic_F is manipulable at ğ”ğ”\\mathbf{U}bold_U by iğ‘–iitalic_i if there is some profitable manipulation of Fğ¹Fitalic_F at ğ”ğ”\\mathbf{U}bold_U by iğ‘–iitalic_i; and Fğ¹Fitalic_F is manipulable if there is some utility profile ğ”ğ”\\mathbf{U}bold_U and voter iğ‘–iitalic_i such that Fğ¹Fitalic_F is manipulable at ğ”ğ”\\mathbf{U}bold_U by iğ‘–iitalic_i. This notion of manipulability of Fğ¹Fitalic_F coincides with the notion of manipulability of Fğ¹Fitalic_F in Gibbard (1977) when we regard Fğ¹Fitalic_F as a probabilistic voting method that assigns to each profile ğğ\\mathbf{P}bold_P the lottery Fâ„“â¢(ğ)subscriptğ¹â„“ğF_{\\ell}(\\mathbf{P})italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P ).\n\n2.1. Voting Methods\n\nIn this paper, we focus on eight preferential voting methods:\n\nPlurality: the winners are those candidates who receive the most first-place rankings from voters.\n\nBorda: a candidate receives 00 points from each voter who ranks them in last place, 1111 point from each voter who ranks them in second-to-last place, 2 points from each voter who ranks them in third-to-last place, etc., yielding a Borda score; the candidates with maximal Borda score win.\n\nInstant Runoff (IRV): if more than half the voters rank the same candidate Ağ´Aitalic_A in first place, then Ağ´Aitalic_A wins; otherwise, Ağ´Aitalic_A is an IRV winner if Ağ´Aitalic_A is an IRV winner in the profile ğâ€²superscriptğâ€²\\mathbf{P}^{\\prime}bold_P start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT obtained from ğğ\\mathbf{P}bold_P by removing all candidates who received the fewest first-place votes in ğğ\\mathbf{P}bold_P (unless all candidates have the same number of first-place votes, in which case all of them win).\n\nInstant Runoff with parallel-universe tiebreaking (IRV-PUT): if more than half of the voters rank the same candidate Ağ´Aitalic_A in first place, then Ağ´Aitalic_A wins; otherwise a candidate Ağ´Aitalic_A is an IRV-PUT winner if for one of the candidates BğµBitalic_B who received the fewest first-place votes in ğğ\\mathbf{P}bold_P, Ağ´Aitalic_A is the IRV-PUT winner in the profile ğâˆ’Bsubscriptğğµ\\mathbf{P}_{-B}bold_P start_POSTSUBSCRIPT - italic_B end_POSTSUBSCRIPT obtained from ğğ\\mathbf{P}bold_P by removing BğµBitalic_B.\n\nMinimax: where the margin of Ağ´Aitalic_A vs. BğµBitalic_B in ğğ\\mathbf{P}bold_P is the number of voters who rank Ağ´Aitalic_A above BğµBitalic_B minus the number who rank BğµBitalic_B above Ağ´Aitalic_A in ğğ\\mathbf{P}bold_P, the winners are those Ağ´Aitalic_A who minimize the quantity maxâ¢{mâ¢aâ¢râ¢gâ¢iâ¢nğâ¢(B,A)âˆ£BâˆˆX}maxconditional-setğ‘šğ‘ğ‘Ÿğ‘”ğ‘–subscriptğ‘›ğğµğ´ğµğ‘‹\\mathrm{max}\\{margin_{\\mathbf{P}}(B,A)\\mid B\\in X\\}roman_max { italic_m italic_a italic_r italic_g italic_i italic_n start_POSTSUBSCRIPT bold_P end_POSTSUBSCRIPT ( italic_B , italic_A ) âˆ£ italic_B âˆˆ italic_X }.\n\nNanson: iteratively eliminate all candidates with less than average Borda score until there are no such candidates. The remaining candidates are Nanson winners.\n\nSplit Cycle: the margin graph of a profile is the weighted directed graph whose nodes are candidates with an edge from Ağ´Aitalic_A to BğµBitalic_B of weight kğ‘˜kitalic_k if Ağ´Aitalic_A has a positive margin of kğ‘˜kitalic_k vs. BğµBitalic_B. In each cycle in the graph (simultaneously), delete the edges with minimal weight. Then the candidates with no incoming edges are the winners.\n\nStable Voting: if there is only one Split Cycle winner in ğğ\\mathbf{P}bold_P, they win; otherwise find the pairs of candidates (A,B)ğ´ğµ(A,B)( italic_A , italic_B ) where Ağ´Aitalic_A is a Split Cycle winner with the maximal margin of Ağ´Aitalic_A vs. BğµBitalic_B such that Ağ´Aitalic_A is a Stable Voting winner in ğâˆ’Bsubscriptğğµ\\mathbf{P}_{-B}bold_P start_POSTSUBSCRIPT - italic_B end_POSTSUBSCRIPT, and declare Ağ´Aitalic_A a winner in ğğ\\mathbf{P}bold_P.\n\nPlurality, Borda, and IRV are perhaps the most famous of preferential voting methods. Plurality has been used for many centuries, and Borda and IRV date back to at least the 18th century. The definition of IRV above (with simultaneous elimination of all candidates with the fewest first-place votes) matches that of Taylor and Pacelli (2008), while the PUT version is popular in computational social choice (see Wang et al. (2019)).\n\nMinimax Simpson (1969); Kramer (1977) is one of the most well known of the Condorcet-consistent voting methods. A voting method is Condorcet-consistent if whenever there is some candidate Cğ¶Citalic_C who beats every other candidate BğµBitalic_B head-to-head (i.e., Cğ¶Citalic_C has a positive margin over each distinct BğµBitalic_B), then this candidateâ€”called the Condorcet winnerâ€”is the unique winner of the election. Plurality, Borda, IRV, and IRV-PUT all violate Condorcet consistency.\n\nThe Nanson method Nanson (1882) is also Condorcet-consistent and has previously been studied in connection with strategic voting. In Narodytska et al. (2011), it is shown that the problem of manipulating Nanson (and the related Baldwin method) is NP-hard when the number of candidates is allowed to increase.\n\nFinally, we include the recently proposed Split Cycle voting method Holliday and Pacuit (2023a), whose manipulability has been studied in Durand (2023), as well as one of its refinements, the Stable Voting method Holliday and Pacuit (2023b). These methods satisfy not only Condorcet consistency but also the stronger propertyâ€”violated by Minimaxâ€”of Smith consistency, meaning that their winners always belong to the Smith set, the smallest set of candidates such that every candidate inside the set beats every candidate outside the set head-to-head. No previous work has studied the manipulability of Stable Voting, so studying this method tests if our approach can predict the manipulability of a method as measured in other ways in the future.\n\n3. Learning to Manipulate\n\nHow difficult is it for a computationally bounded agent to learn to manipulate against a given voting method under limited information? In this paper, we study this question through training and evaluating many multi-layer perceptrons (MLPs) with increasing numbers of learnable parameters. These MLPs act as function approximators for profitable manipulation policies for a given voting method and type of limited information. We can evaluate the manipulation resistance of a voting method by the size and complexity of the MLP required to learn a profitable manipulation policy, as well as the average profitability of learned policies.\n\n3.1. Implementation Details\n\nWe optimize weights Î¸ğœƒ\\thetaitalic_Î¸ of an MLP fğ‘“fitalic_f whose input xğ‘¥xitalic_x consists of a utility function ğ”vsubscriptğ”ğ‘£\\mathbf{U}_{v}bold_U start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT for our manipulating voter vğ‘£vitalic_v, as well as some limited information Iğ¼Iitalic_I about the full utility profile ğ”ğ”\\mathbf{U}bold_U (see Section 3.1.2). We apply a softmax to the output of the MLP to generate a probability distribution over all possible actions of vğ‘£vitalic_v, namely the m!ğ‘šm!italic_m ! possible rankings, labeled 0 through m!âˆ’1ğ‘š1m!-1italic_m ! - 1, that vğ‘£vitalic_v can submit, as in (2):\n\nfÎ¸â¢(x)=Ï€â¢(x)=[â„™â¢(0|x),â„™â¢(1|x),â€¦,â„™â¢(m!âˆ’1|x)].subscriptğ‘“ğœƒğ‘¥ğœ‹ğ‘¥â„™conditional0ğ‘¥â„™conditional1ğ‘¥â€¦â„™ğ‘šconditional1ğ‘¥f_{\\theta}(x)=\\pi(x)=\\left[\\mathbb{P}(0|x),\\mathbb{P}(1|x),\\dots,\\mathbb{P}(m!% -1|x)\\right].italic_f start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x ) = italic_Ï€ ( italic_x ) = [ blackboard_P ( 0 | italic_x ) , blackboard_P ( 1 | italic_x ) , â€¦ , blackboard_P ( italic_m ! - 1 | italic_x ) ] . (2)\n\nNote that the manipulator is allowed to submit the sincere ranking given by their utility function; they are not forced to manipulate.\n\n3.1.1. Probability models for profiles\n\nTo generate utility profiles for our experiments described below, we first used a standard uniform utility model (see, e.g., (Merrill, 1988, p. 16)): for each voter independently, the utility of each candidate for that voter is drawn independently from the uniform distribution on the [0,1]01[0,1][ 0 , 1 ] interval. We then also used a 2D spatial model: each candidate and each voter is independently placed in â„2superscriptâ„2\\mathbb{R}^{2}blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT according to the multivariate normal distribution (as in Merrill (1988)) with no correlation between the two dimensions; then the utility of a candidate for a voter is the square of the Euclidean distance between the candidate and the voter (using the quadratic proximity utility function as in (Samuel Merrill and Grofman, 1999, p. 21)).\n\nThese utility profiles can then be parameterized as 2D matrices, Uâˆˆâ„nÃ—mğ‘ˆsuperscriptâ„ğ‘›ğ‘šU\\in\\mathbb{R}^{n\\times m}italic_U âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_n Ã— italic_m end_POSTSUPERSCRIPT, where nğ‘›nitalic_n is the number of voters, mğ‘šmitalic_m is the number of candidates, and U[i,c]âˆˆ[0,1]subscriptğ‘ˆğ‘–ğ‘01U_{\\left[i,c\\right]}\\in\\left[0,1\\right]italic_U start_POSTSUBSCRIPT [ italic_i , italic_c ] end_POSTSUBSCRIPT âˆˆ [ 0 , 1 ]. To select the utility function for a given voter iğ‘–iitalic_i is to select the row Uisubscriptğ‘ˆğ‘–U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.\n\n3.1.2. Choices of Limited Information\n\nWe experimented with providing different types of input to the MLP, including the following types that are often taken to be natural forms of polling information in voting theory (see, e.g., (Reijngoud and Endriss, 2012, Â§ 2.2), Veselova (2023)):\n\nâ€¢\n\nthe plurality score of each candidate Ağ´Aitalic_A, defined as the number of voters whose favorite candidate is Ağ´Aitalic_A. Iâˆˆâ„•mğ¼superscriptâ„•ğ‘šI\\in\\mathbb{N}^{m}italic_I âˆˆ blackboard_N start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT\n\nâ€¢\n\nthe plurality ranking, i.e., the ordinal ranking of the candidates by their plurality scores. Iâˆˆâ„•mğ¼superscriptâ„•ğ‘šI\\in\\mathbb{N}^{m}italic_I âˆˆ blackboard_N start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT\n\nâ€¢\n\nthe margin matrix of dimension mÃ—mğ‘šğ‘šm\\times mitalic_m Ã— italic_m, where an integer kğ‘˜kitalic_k in the (A,B)ğ´ğµ(A,B)( italic_A , italic_B )-coordinate of the matrix indicates that the margin of Ağ´Aitalic_A vs. BğµBitalic_B is kğ‘˜kitalic_k. Iâˆˆâ„¤mÃ—mğ¼superscriptâ„¤ğ‘šğ‘šI\\in\\mathbb{Z}^{m\\times m}italic_I âˆˆ blackboard_Z start_POSTSUPERSCRIPT italic_m Ã— italic_m end_POSTSUPERSCRIPT\n\nâ€¢\n\nthe majority matrix, obtained from the margin matrix by replacing all positive entries by 1111 and all negative entries by âˆ’11-1- 1. Iâˆˆ{âˆ’1,0,1}mÃ—mğ¼superscript101ğ‘šğ‘šI\\in\\{-1,0,1\\}^{m\\times m}italic_I âˆˆ { - 1 , 0 , 1 } start_POSTSUPERSCRIPT italic_m Ã— italic_m end_POSTSUPERSCRIPT\n\nâ€¢\n\nthe qualitative margin matrix, obtained from the margin matrix by replacing each positive margin by its rank in the ordering of margins from smallest to largest, and then adding negative entries so that the resulting matrix is skew-symmetric. Iâˆˆâ„¤mÃ—mğ¼superscriptâ„¤ğ‘šğ‘šI\\in\\mathbb{Z}^{m\\times m}italic_I âˆˆ blackboard_Z start_POSTSUPERSCRIPT italic_m Ã— italic_m end_POSTSUPERSCRIPT\n\nâ€¢\n\nthe sincere winners, i.e., the candidates who would win according to the sincere profile ğğ\\mathbf{P}bold_P. Iâˆˆ{0,1}mğ¼superscript01ğ‘šI\\in\\{0,1\\}^{m}italic_I âˆˆ { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT\n\nThese additional inputs are flattened and concatenated to the manipulatorâ€™s utility function before being used as input to the MLP.\n\nNote, crucially, that the full preference profile ğğ\\mathbf{P}bold_P is not uniquely determined by any of the types of limited information above. If the manipulating voter vğ‘£vitalic_v had full knowledge of ğğ\\mathbf{P}bold_P, they could simply compute which of the |X|!ğ‘‹|X|!| italic_X | ! linear orders would be optimal to submit given ğâˆ’isubscriptğğ‘–\\mathbf{P}_{-i}bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT. But if vğ‘£vitalic_v has only, e.g., the majority matrix of ğğ\\mathbf{P}bold_P, then the set of profiles realizing that majority matrix can be enormous. For 6 candidates and 20 voters in addition to vğ‘£vitalic_v, there are approximately 7.48Ã—10387.48superscript10387.48\\times 10^{38}7.48 Ã— 10 start_POSTSUPERSCRIPT 38 end_POSTSUPERSCRIPT profiles up to permuting the voters (which does not affect the choice of winners according to the anonymous voting rules in Section 2.1). For 6 candidates, there are 3(62)=265,356superscript3binomial622653563^{6\\choose 2}=265,3563 start_POSTSUPERSCRIPT ( binomial start_ARG 6 end_ARG start_ARG 2 end_ARG ) end_POSTSUPERSCRIPT = 265 , 356 majority matrices. Thus, on average there are about 7.48Ã—1038/265,356â‰ˆ2.82Ã—10337.48superscript10382653562.82superscript10337.48\\times 10^{38}/265,356\\approx 2.82\\times 10^{33}7.48 Ã— 10 start_POSTSUPERSCRIPT 38 end_POSTSUPERSCRIPT / 265 , 356 â‰ˆ 2.82 Ã— 10 start_POSTSUPERSCRIPT 33 end_POSTSUPERSCRIPT profiles that could realize a given majority matrix. It is therefore infeasible to check for every profile that could realize a given majority matrix, and every ranking that vğ‘£vitalic_v could submit, the profitability of submitting that ranking in that profile. Instead, we will train an MLP to input a majority matrix and output an optimal ranking to submit without such infeasible brute force checking.\n\nAlso note that information sufficient for determining the sincere winner according to a voting methodâ€”e.g., the plurality ranking for Plurality, the qualitative margin matrix for Minimax, Split Cycle, and Stable Voting, etc.â€”is not necessarily sufficient for determining who would win after a particular manipulation.\n\n3.1.3. Labeling\n\nWe framed the learning objective as a classification task. Given a voting method and utility profile, we used the following labeling of each of the m!ğ‘šm!italic_m ! possible rankings vğ‘£vitalic_v could submit:\n\nâ€¢\n\noptimizing labeling: all optimal rankings to submit are labeled by 1111, and all other rankings are labeled by 00.\n\nThe output of our MLPs is a distribution over all m!ğ‘šm!italic_m ! rankings given some information xğ‘¥xitalic_x about the current utility profile. It is equally valid for our agent to choose any of the positively-labeled rankings. We treat the binary labelings as a mask over the rankings and reduce the distribution Ï€â¢(x)ğœ‹ğ‘¥\\pi(x)italic_Ï€ ( italic_x ) to two values: the probability of choosing a positively-labeled ranking or not. We compute the final loss as the mean-squared error between this reduced distribution and the distribution assigning probability 1 to choosing a positively-labeled ranking and 0 to choosing a non-positively-labeled ranking.\n\n3.2. Evaluation\n\nTo evaluate how well a given MLP has learned to manipulate, we must convert its output distribution over rankings into a single ranking. To do so, we used the following decision rule:\n\nâ€¢\n\nargmax: select the ranking with the largest probability in the output of the MLP.\n\nAs our metric for the profitability of the MLPâ€™s decision, we use the difference between the left and right-hand sides of (1) normalized by the greatest possible utility difference according to ğ”isubscriptğ”ğ‘–\\mathbf{U}_{i}bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT:\n\nğ„ğ”iâ¢(Fâ„“â¢(ğiâ€²,ğâˆ’i))âˆ’ğ„ğ”iâ¢(Fâ„“â¢(ğ))maxâ¢({ğ”iâ¢(x)âˆ£xâˆˆX})âˆ’minâ¢({ğ”iâ¢(x)âˆ£xâˆˆX}).subscriptğ„ğ”ğ‘–subscriptğ¹â„“subscriptsuperscriptğâ€²ğ‘–subscriptğğ‘–subscriptğ„ğ”ğ‘–subscriptğ¹â„“ğmaxconditional-setsubscriptğ”ğ‘–ğ‘¥ğ‘¥ğ‘‹minconditional-setsubscriptğ”ğ‘–ğ‘¥ğ‘¥ğ‘‹\\frac{\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}^{\\prime}_{i},\\mathbf{P}_{-i}))-% \\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}))}{\\mathrm{max}(\\{\\mathbf{U}_{i}(x)\\mid x% \\in X\\})-\\mathrm{min}(\\{\\mathbf{U}_{i}(x)\\mid x\\in X\\})}.divide start_ARG bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ) ) - bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P ) ) end_ARG start_ARG roman_max ( { bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) âˆ£ italic_x âˆˆ italic_X } ) - roman_min ( { bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) âˆ£ italic_x âˆˆ italic_X } ) end_ARG . (3)\n\nWe call this the profitability of ğiâ€²subscriptsuperscriptğâ€²ğ‘–\\mathbf{P}^{\\prime}_{i}bold_P start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT with respect to F,ğ”,iğ¹ğ”ğ‘–F,\\mathbf{U},iitalic_F , bold_U , italic_i.\n\nThe normalization in (3) is the standard normalization for relative utilitarianism Dhillon and Mertens (1999), which we use to compare utility differences across profiles. Indeed, (3) is equivalent to taking the difference in the Kaplan-normalized (dâ€™Aspremont and Gevers, 2002, p. 470) expected utilities of submitting ğâ€²superscriptğâ€²\\mathbf{P}^{\\prime}bold_P start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT and of submitting ğğ\\mathbf{P}bold_P, where u^=maxâ¢({ğ”iâ¢(x)âˆ£xâˆˆX})^ğ‘¢maxconditional-setsubscriptğ”ğ‘–ğ‘¥ğ‘¥ğ‘‹\\hat{u}=\\mathrm{max}(\\{\\mathbf{U}_{i}(x)\\mid x\\in X\\})over^ start_ARG italic_u end_ARG = roman_max ( { bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) âˆ£ italic_x âˆˆ italic_X } ) and uË‡=minâ¢({ğ”iâ¢(x)âˆ£xâˆˆX})Ë‡ğ‘¢minconditional-setsubscriptğ”ğ‘–ğ‘¥ğ‘¥ğ‘‹\\check{u}=\\mathrm{min}(\\{\\mathbf{U}_{i}(x)\\mid x\\in X\\})overroman_Ë‡ start_ARG italic_u end_ARG = roman_min ( { bold_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) âˆ£ italic_x âˆˆ italic_X } ):\n\nğ„ğ”iâ¢(Fâ„“â¢(ğiâ€²,ğâˆ’i))âˆ’uË‡u^âˆ’uË‡âˆ’ğ„ğ”iâ¢(Fâ„“â¢(ğ))âˆ’uË‡u^âˆ’uË‡.subscriptğ„ğ”ğ‘–subscriptğ¹â„“subscriptsuperscriptğâ€²ğ‘–subscriptğğ‘–Ë‡ğ‘¢^ğ‘¢Ë‡ğ‘¢subscriptğ„ğ”ğ‘–subscriptğ¹â„“ğË‡ğ‘¢^ğ‘¢Ë‡ğ‘¢\\frac{\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}^{\\prime}_{i},\\mathbf{P}_{-i}))-% \\check{u}}{\\hat{u}-\\check{u}}-\\frac{\\mathbf{EU}_{i}(F_{\\ell}(\\mathbf{P}))-% \\check{u}}{\\hat{u}-\\check{u}}.divide start_ARG bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_P start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ) ) - overroman_Ë‡ start_ARG italic_u end_ARG end_ARG start_ARG over^ start_ARG italic_u end_ARG - overroman_Ë‡ start_ARG italic_u end_ARG end_ARG - divide start_ARG bold_EU start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_F start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ( bold_P ) ) - overroman_Ë‡ start_ARG italic_u end_ARG end_ARG start_ARG over^ start_ARG italic_u end_ARG - overroman_Ë‡ start_ARG italic_u end_ARG end_ARG .\n\nNote that for a particular decision by an MLP, the numerator of (3) may be negative, i.e., the MLP may be worse off by submitting an insincere ranking ğâ€²superscriptğâ€²\\mathbf{P}^{\\prime}bold_P start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT than they would have been by submitting the sincere ranking ğğ\\mathbf{P}bold_P.\n\nFor a given trained MLP, we sample utility profiles according to one of our probability models and compute the average profitability of the MLPâ€™s submitted rankings. We take the average profitability that is achievable against a given voting method as a measure of a voterâ€™s incentive to manipulate against that voting method. This is a more revealing measure than the frequency with which the trained MLP manipulates against a voting method, since many of the MLPâ€™s manipulations may be no better than sincere voting.\n\nFor the number of profiles to sample, we continued sampling until the estimated standard error of the mean (Robert and Casella, 2004, Â§ 3.2) for profitability fell below 5e-4, resulting in small error bars (see Figure 3).\n\n3.2.1. Baselines\n\nFor baseline comparisons, we consider an agent with full information about a profile and unbounded computational resources, who always picks one of the optimal rankings to submit. We then estimated the average profitability as in (3) of this agentâ€™s submitted ranking across many sampled elections, where as above we continued sampling until the estimated standard error of the mean fell below 5e-4.\n\n3.3. Training Setup\n\nFor each voting method Fğ¹Fitalic_F, each number nâˆˆ{5,6,10,11,20,21}ğ‘›5610112021n\\in\\{5,6,10,11,20,21\\}italic_n âˆˆ { 5 , 6 , 10 , 11 , 20 , 21 }, each number mâˆˆ{3,4,5,6}ğ‘š3456m\\in\\{3,4,5,6\\}italic_m âˆˆ { 3 , 4 , 5 , 6 }, each choice of an input type for the MLP, and each choice of a model size (see the x-axis of Figure 3), we trained one or more â€œgenerationsâ€ of MLPs with that model size to manipulate elections with nğ‘›nitalic_n voters and mğ‘šmitalic_m candidates run using Fğ¹Fitalic_F, resulting in over 70,000 trained MLPs. For a given generation, we used the same initialization of MLP weights and the same training, validation, and evaluation profiles for every MLP for nğ‘›nitalic_n candidates and mğ‘šmitalic_m voters. Across generations, we varied the initialization of MLP weights and used different training, validation, and evaluation profiles, to provide reassurance that our results were not due to lucky initial weights or profiles. All elections and labels were pre-computed so training could rely fully on the GPU.\n\nWe experimented with training the MLPs using different numbers of iterationsâ€”between 100 and 1000â€”different learning ratesâ€”1e-3, 3e-3, and 6e-3â€”and different batch sizesâ€”256 and 512. We hand-tuned these hyper-parameters in order to maximize the performance of all MLPs across all voting methods and profile sizes. For the final training run reported here, we use a batch size of 512 and a learning rate of 6e-3. We train all models for at least 220 iterations and then terminate training with an early stopping rule: after every 20 iterations, we measure the average profitability on a validation batch of 4,096 elections. If 10 validation steps pass without an improvement of at least .001 in average profitability of the submitted ranking, we terminate training.\n\n3.3.1. Computing Infrastructure\n\nAll code was written in Python using PyTorch and the pref_voting library (pypi.org/project/pref-voting/), version 0.4.42, for all functions dealing with voting. Training and evaluation was parallelized across nine local Apple computers with Apple silicon, the most powerful equipped with an M2 Ultra with 24-core CPU, 76-core GPU, and 128GB of unified memory, running Mac OS 13, as well as up to sixteen cloud instances with Nvidia A6000 or A10 GPUs running Linux Ubuntu 18.04.\n\n4. Results\n\nWe begin by discussing our results under the uniform utility model and then turn to the 2D spatial model in Section 4.9.\n\nThe average profitability of submitting the optimal ranking in each election (see Baselines above) with different voting methods is shown by the black bars in Figure 1. The other colored bars are for MLP-based manipulators with different types of limited information. Figure 1 shows data for the best performing MLP (for a given number of candidates, number of voters, voting method, and choice of information) with any hidden layer configuration. Figure 3 below shows the performance of MLPs with each of the 26 different hidden layer configuration we tested, focusing on 6 candidates, 10/11 voters, and either the majority matrix or plurality scores choice of limited information. These figures all cover the first generation of trained MLPs. Results for the second and third generations of trained MLPs are qualitatively similar to the first (see Supplementary Material), though we lack a sufficient number of generations to make quantitative statistical claims. The following qualitative highlights are robust across generations. All claims are implicitly qualified to apply to elections with 3â€“6 candidates and 5-21 voters.\n\n4.1. The importance of majorities\n\nSufficiently large MLPs learned to profitably manipulate all voting methods we studied on the basis of knowing only the majority matrix, though the profitability of such manipulation varied dramatically across methods. Interestingly, we did not find a substantial increase in profitability of manipulation for MLPs that learned to manipulate on the basis of the more informative margin matrix instead of the majority matrix, except in the case of Borda (especially for 6 candidates, as shown in the Supplementary Material). In fact, the qualitative margin matrix was about as useful as the margin matrix for learning to manipulate Borda.\n\n4.2. The limited usefulness of plurality scores\n\nThough obviously useful for manipulating Plurality and somewhat useful for several methods for 3 candidates (though less useful for 4 or 5 candidates), knowing the plurality scores was insufficient in 6-candidate elections for profitably manipulating methods other than Plurality (though Borda may be barely manipulable in this case), as shown in Figure 3. Moreover, in the case of manipulating Plurality, learning to manipulate on the basis of the plurality ranking (see Figure 1) led to profitability comparable to learning to manipulate on the basis of the plurality scores themselves.\n\n4.3. Highly manipulable vs. resistant methods\n\nPlurality and especially Borda have long been regarded as highly manipulable. Our results show that this is so even under limited information, e.g., in the form of the majority matrix.\n\nIRV and IRV-PUT were quite resistant to manipulation on the basis of limited information (with the exception of the manipulability of IRV for 3 candidates and 10 voters), despite the fact that these methods are more manipulable than some others by an ideal manipulator. In addition, Minimax and Split Cycle stood out for their resistance to manipulation. It it is noteworthy that while Minimax and Split Cycle were not much more profitably manipulable than IRV and IRV-PUT on the basis of the majority matrix, qualitative margin matrix, or margin matrix in absolute terms (see top of Figure 1), MLPs came closer to the ideal manipulator for learning to manipulate Minimax and Split Cycle on the basis of this information than for IRV and IRV-PUT (see bottom of Figure 1), which are more manipulable by an ideal manipulator. Another noteworthy difference is that IRV and IRV-PUT are fairly manipulable by a voter with only the sincere winners information (see Figure 1), whereas Minimax and Split Cycle are not.\n\n4.4. The subtleties of tiebreaking\n\nWhile the distinction between IRV and IRV-PUT is subtle, it leads to significant differences with respect to single-voter manipulability under 3 candidates and an even number of voters (see graphs in the Supplementary Material). Of course, manipulation by a single voter is only possible in very close elections, in which case ties matter.\n\n4.5. Parity of the number of voters\n\nIndeed, the parity of the number of voters is a key factor for some methods. This is most striking for Stable Voting, which is barely manipulable with 11 voters but more manipulable with 10 (see Figure 3). A key difference is that with 10 voters, it is possible to have margins of zero between candidates, in which case a single voter has more manipulative power under Stable Voting, which produces fewer tied elections in the presence of zero margins than other methods like Minimax.\n\n4.6. Effect of the number of candidates\n\nFor an ideal manipulator, manipulation becomes more profitable as the number of candidates increases (see the Supplementary Material). The same can be true for the MLP-based manipulators up to a point, e.g., 4 or 5 candidates for most voting methods when using the majority, qualitative margin, or margin information. However, the ratio between the profitability of the MLP-based manipulatorâ€™s submitted rankings and those of the ideal manipulator declines as the number of candidates increases from 3 to 6 (see Supplementary Material). This is intuitive, as manipulation should increase in complexity with more candidates.\n\n4.7. Profitability and ease of learnability\n\nNot only is it more profitable to manipulate, say, Borda than Stable Voting, but it is also easier to learnâ€”in the sense of requiring smaller MLPs: whether we consider one, two, or three hidden layers, in each case a smaller network is needed to learn to profitably manipulate Borda on the basis of the majority matrix (see Figure 3).\n\n4.8. Worst-case complexity vs. learnability\n\nDespite the NP-hardness of deciding if one can manipulate Nanson so as to elect a desired candidate, it is still possible to learn to do so on the basis of just the majority matrix for elections with up to 6 candidates. In this connection, studying manipulability with more candidates is of great interest.\n\n4.9. Differences with the 2D spatial model\n\nComparing Figure 1 for the uniform utility model and Figure 2 for the 2D spatial model model, the most striking differences are (1) that all voting methods become less profitably manipulable (roughly by one half) under the spatial model and (2) even the best MLPâ€™s could not learn to profitably manipulate against Minimax, Nanson, and Split Cycle under the spatial model. On the other hand, the comparative usefulness, for manipulating against each voting method, of the different types of limited information is largely the same under the spatial model as under the uniform utility model (this is true even for Minimax, Nanson, and Split Cycle, looking at which types of information produce less negative results). We conjuncture that these findings about types of limited information are robust across other standard probability models as well.\n\n5. Conclusion\n\nIn committee-sized elections (5-21 voters), MLPs can learn to vote strategically on the basis of limited information, though the profitability of doing so varies significantly between different voting methods. This serves as a proof of concept for the study of machine learnability of manipulation under limited information. There are a number of natural extensions for future work, including manipulation by a coalition of multiple voters, as well as different probability models for generating elections. Our code is already set up to handle these extensions, which only require more compute. However, further research is needed on other questions: What if all agents in the election strategize? And what is the social cost or benefit of the learned manipulations? Finally, one limitation of the classification approach in this paper is that it is infeasible to apply to more than 6 candidates. To overcome this limitation, we plan to develop a reinforcement learning approach to learning to manipulate.\n\nAcnowledgements\n\nFor helpful feedback, we thank Dominic Hughes, the anonymous reviewers for SCaLA, and the participants in the Values-Centered AI seminar at the University of Maryland in Fall 2023, the logic seminar at the University of Maryland in Spring 2024, and the Interdisciplinary Workshop on Computational Social Choice at the Center for Human-Compatible Artificial Intelligence in Spring 2024.\n\nReferences\n\n(1)\n\nAiriau et al. (2017) StÃ©phane Airiau, Umberto Grandi, and Filipo Studzinski Perotto. 2017. Learning Agents for Iterative Voting. In Algorithmic Decision Theory, JÃ¶rg Rothe (Ed.). Springer, Cham, 139â€“152.\n\nAnil and Bao (2021) Cem Anil and Xuchan Bao. 2021. Learning to Elect. In Advances in Neural Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan (Eds.), Vol. 34.\n\nArmstrong and Larson (2019) Ben Armstrong and Kate Larson. 2019. Machine Learning to Strengthen Democracy. NeurIPS Joint Workshop on AI for Social Good.\n\nBartholdi et al. (1989) J.J. Bartholdi, C.A. Tovey, and M.A. Trick. 1989. The computational difficulty of manipulating an election. Social Choice and Welfare 6 (1989), 227â€“241. https://doi.org/10.1007/BF00295861\n\nBlack (1958) Duncan Black. 1958. The theory of committees and elections. Cambridge University Press, Cambridge.\n\nBrandt et al. (2016) Felix Brandt, Vincent Conitzer, Ulle Endriss, JÃ©rÃ´me Lang, and Ariel D. Procaccia (Eds.). 2016. Handbook of Computational Social Choice. Cambridge University Press.\n\nBurka et al. (2022) DÃ¡vid Burka, Clemens Puppe, LÃ¡szlÃ³ SzepesvÃ¡ry, and Attila TasnÃ¡di. 2022. Voting: A machine learning approach. European Journal of Operational Research 299 (2022), 1003â€“1017. https://doi.org/10.1016/j.ejor.2021.10.005\n\nChopra et al. (2004) Samir Chopra, Eric Pacuit, and Rohit Parikh. 2004. Knowledge-Theoretic Properties of Strategic Voting. In Logics in Artificial Intelligence. JELIA 2004. Lecture Notes in Computer Science, J.J. Alferes and J. Leite (Eds.), Vol. 3229. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-540-30227-8_5\n\nConitzer (2010) Vincent Conitzer. 2010. Making decisions based on the preferences of multiple agents. Commun. ACM 53, 3 (2010), 84â€“94. https://doi.org/10.1145/1666420.1666442\n\nConitzer et al. (2007) Vincent Conitzer, Tuomas Sandholm, and JÃ©rÃ´me Lang. 2007. When are elections with few candidates hard to manipulate? J. ACM 54, 3 (2007), 14â€“es. https://doi.org/10.1145/1236457.1236461\n\nConitzer et al. (2011) Vincent Conitzer, Toby Walsh, and Lirong Xia. 2011. Dominating Manipulations in Voting with Partial Information. In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence (AAAI-11). San Francisco, CA, USA, 638â€“643.\n\ndâ€™Aspremont and Gevers (2002) Claude dâ€™Aspremont and Louis Gevers. 2002. Social welfare functionals and interpersonal comparability. In Handbook of Social Choice and Welfare, Kenneth J. Arrow, Amartya K. Sen, and Kotaro Suzumura (Eds.). Vol. 1. North-Holland, Amsterdam, 459â€“541. https://doi.org/10.1016/S1574-0110(02)80014-5\n\nDhillon and Mertens (1999) Amrita Dhillon and Jean-FranÃ§ois Mertens. 1999. Relative Utilitarianism. Econometrica 67, 3 (1999), 471â€“498.\n\nDuggan and Schwartz (2000) John Duggan and Thomas Schwartz. 2000. Strategic manipulability without resoluteness or shared beliefs: Gibbard-Satterthwaite generalized. Social Choice and Welfare 17, 1 (2000), 85â€“93. https://doi.org/10.1007/PL00007177\n\nDurand (2023) FranÃ§ois Durand. 2023. Coalitional manipulation of voting rules: simulations on empirical data. Constitutional Political Economy 34 (2023), 390â€“409. https://doi.org/10.1007/s10602-022-09376-8\n\nEndriss et al. (2016) Ulle Endriss, Svetlana Obraztsova, Maria Polukarov, and Jeffrey S. Rosenschein. 2016. Strategic Voting with Incomplete Information. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI-16). 236â€“242.\n\nFairstein et al. (2019) Roy Fairstein, Adam Lauz, Reshef Meir, and Kobi Gal. 2019. Modeling Peopleâ€™s Voting Behavior with Poll Information. In Proceedings of the AAMAS 2019. 1422â€“1430.\n\nFaliszewski and Procaccia (2010) Piotr Faliszewski and Ariel D. Procaccia. 2010. AIâ€™s War on Manipulation: Are We Winning? AI Magazine 31, 4 (2010), 53â€“64. https://doi.org/10.1609/aimag.v31i4.2314\n\nFirebanks-Quevedo (2020) Daniel Firebanks-Quevedo. 2020. Machine Learning? In MY Election? Itâ€™s More Likely Than You Think: Voting Rules via Neural Networks. Bachelorâ€™s Thesis, Oberlin College.\n\nGibbard (1973) Allan Gibbard. 1973. Manipulation of voting schemes: A general result. Econometrica 41, 4 (1973), 587â€“601. https://doi.org/10.2307/1914083\n\nGibbard (1977) Allan Gibbard. 1977. Manipulation of schemes that mix voting with chance. Econometrica 45, 3 (1977), 665â€“681.\n\nGolubeva et al. (2021) Anna Golubeva, Behnam Neyshabur, and Guy Gur-Ari. 2021. Are wider nets better given the same number of parameters? (2021). arXiv:2010.14495 [cs.LG].\n\nGreen-Armytage et al. (2016) James Green-Armytage, T. Nicolaus Tideman, and Rafael Cosman. 2016. Statistical evaluation of voting rules. Social Choice and Welfare 46 (2016), 183â€“212. https://doi.org/10.1007/s00355-015-0909-0\n\nHestness et al. (2017) Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md. Mostofa Ali Patwary, Yang Yang, and Yanqi Zhou. 2017. Deep Learning Scaling is Predictable, Empirically. (2017). arXiv:1712.00409 [cs.LG].\n\nHolliday and Pacuit (2023a) Wesley H. Holliday and Eric Pacuit. 2023a. Split Cycle: A new Condorcet-consistent voting method independent of clones and immune to spoilers. Public Choice 197 (2023), 1â€“62.\n\nHolliday and Pacuit (2023b) Wesley H. Holliday and Eric Pacuit. 2023b. Stable Voting. Constitutional Political Economy 45 (2023), 421â€“433. https://doi.org/10.1007/s10602-022-09383-9\n\nKang et al. (2023) Inwon Kang, Qishen Han, and Lirong Xia. 2023. Learning to Explain Voting Rules, Extended Abstract. In Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems (AAMAS). London, United Kingdom.\n\nKramer (1977) Gerald H. Kramer. 1977. A dynamical model of political equilibrium. Journal of Economic Theory 16, 2 (1977), 310â€“334. https://doi.org/10.1016/0022-0531(77)90011-4\n\nKreps (1988) David M. Kreps. 1988. Notes on the Theory of Choice. Westview Press, Boulder, CO.\n\nKube and Puppe (2009) Sebastian Kube and Clemens Puppe. 2009. When and how do voters try to manipulate? Experimental evidence from Borda elections. Public Choice 139 (2009), 39â€“52.\n\nLang (2020) JÃ©rÃ´me Lang. 2020. Collective Decision Making under Incomplete Knowledge: Possible and Necessary Solutions. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-20) Survey Track. 4885â€“4891.\n\nLaslier (2009) Jean-FranÃ§ois Laslier. 2009. The leader rule: A model of strategic approval voting in a large electorate. Journal of Theoretical Politics 21, 1 (2009), 113â€“136. https://doi.org/10.1177/0951629808097286\n\nLu et al. (2012) Tyler Lu, Pingzhong Tang, Ariel D. Procaccia, and Craig Boutilier. 2012. Bayesian Vote Manipulation: Optimal Strategies and Impact on Welfare. In Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence (UAI). Morgan Kaufmann, New York, 543â€“553.\n\nMeir (2018) Reshef Meir. 2018. Strategic Voting. Springer, Cham. https://doi.org/10.1007/978-3-031-01579-3\n\nMeir et al. (2014) Reshef Meir, Omer Lev, and Jeffrey S. Rosenschein. 2014. A local-dominance theory of voting equilibria. In Proceedings of the fifteenth ACM conference on Economics and computation (EC â€™14). 313â€“330. https://doi.org/10.1145/2600057.2602860\n\nMerrill (1988) Samuel Merrill. 1988. Making Multicandidate Elections More Democratic. Princeton University Press.\n\nMossel and RÃ¡cz (2013) Elchanan Mossel and MiklÃ³s Z. RÃ¡cz. 2013. Election manipulation: the average case. ACM SIGecom Exchanges 11, 2 (2013), 22â€“24. https://doi.org/10.1145/2509002.2509007\n\nMyerson and Weber (1993) Roger B. Myerson and Robert J. Weber. 1993. A theory of voting equilibria. The American Political Science Review 87, 1 (1993), 102â€“114. https://doi.org/10.2307/2938959\n\nNanson (1882) E. J. Nanson. 1882. Methods of election. Transactions and Proceedings of the Royal Society of Victoria 19 (1882), 197â€“240.\n\nNarodytska et al. (2011) Nina Narodytska, Toby Walsh, and Lirong Xia. 2011. Manipulation of Nansonâ€™s and Baldwinâ€™s Rules. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 25. 713â€“718. https://doi.org/10.1609/aaai.v25i1.7872\n\nNiou (1987) Emerson M. S. Niou. 1987. A Note on Nansonâ€™s Rule. Public Choice 54, 2 (1987), 191â€“193. https://doi.org/10.1007/BF00123006\n\nReijngoud and Endriss (2012) Annemieke Reijngoud and Ulle Endriss. 2012. Voter Response to Iterated Poll Information. In Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2012), V. Conitzer, M. Winikoff, L. Padgham, and W. van der Hoek (Eds.). Valencia, Spain.\n\nRobert and Casella (2004) Christian P. Robert and George Casella. 2004. Monte Carlo Statistical Methods (2 ed.). Springer New York, NY. https://doi.org/10.1007/978-1-4757-4145-2\n\nSamuel Merrill and Grofman (1999) III Samuel Merrill and Bernard Grofman. 1999. A Unified Theory of Voting: Directional and Proximity Spatial Models. Cambridge University Press, Cambridge. https://doi.org/10.1017/CBO9780511605864\n\nSatterthwaite (1973) Mark Satterthwaite. 1973. The Existence of a Strategy Proof Voting Procedure. Ph.D. Dissertation. University of Wisconsin.\n\nSchulze (2011) Markus Schulze. 2011. A new monotonic, clone-independent, reversal symmetric, and condorcet-consistent single-winner election method. Social Choice and Welfare 36 (2011), 267â€“303. https://doi.org/10.1007/s00355-010-0475-4\n\nSimpson (1969) Paul B. Simpson. 1969. On Defining Areas of Voter Choice: Professor Tullock on Stable Voting. The Quarterly Journal of Economics 83, 3 (1969), 478â€“490. https://doi.org/10.2307/1880533\n\nSteinert-Threlkeld and Szymanik (2020) Shane Steinert-Threlkeld and Jakub Szymanik. 2020. Ease of learning explains semantic universals. Cognition 195 (Feb 2020), 104076.\n\nTaylor (2005) Alan D. Taylor. 2005. Social Choice and the Mathematics of Manipulation. Cambridge University Press, Cambridge. https://doi.org/10.1017/cbo9780511614316\n\nTaylor and Pacelli (2008) Alan D. Taylor and Allison M. Pacelli. 2008. Mathematics and Politics: Strategy, Voting, Power, and Proof (2nd ed.). Springer, New York. https://doi.org/10.1007/978-0-387-77645-3\n\nTideman (1987) T. Nicolaus Tideman. 1987. Independence of Clones as a Criterion for Voting Rules. Social Choice and Welfare 4 (1987), 185â€“206. https://doi.org/10.1007/bf00433944\n\nVeselova (2023) Yuliya A. Veselova. 2023. Manipulation by Coalitions in Voting with Incomplete Information. In Data Analysis and Optimization: In Honor of Boris Mirkinâ€™s 80th Birthday, Boris Goldengorin and Sergei Kuznetsov (Eds.). Springer, Cham, 377â€“395.\n\nWalsh (2011) Toby Walsh. 2011. Is computational complexity a barrier to manipulation? Annals of Mathematics and Artificial Intelligence 62 (2011), 7â€“26. https://doi.org/10.1007/s10472-011-9255-9\n\nWang et al. (2019) Jun Wang, Sujoy Sikdar, Tyler Shepherd Zhibing Zhao, Chunheng Jiang, and Lirong Xia. 2019. Practical Algorithms for Multi-Stage Voting Rules with Parallel Universes Tiebreaking. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19). AAAI Press.\n\nZhang et al. (2017) Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. 2017. Understanding deep learning requires rethinking generalization. (2017). arXiv:1611.03530 [cs.LG].\n\nZwicker (2016) William S. Zwicker. 2016. Introduction to the Theory of Voting. In Handbook of Computational Social Choice, Felix Brandt, Vincent Conitzer, Ulle Endriss, JÃ©rÃ´me Lang, and Ariel D. Procaccia (Eds.). Cambridge University Press, New York, 23â€“56. https://doi.org/10.1017/cbo9781107446984.003"
    }
}