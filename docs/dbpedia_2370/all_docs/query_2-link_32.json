{
    "id": "dbpedia_2370_2",
    "rank": 32,
    "data": {
        "url": "https://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/",
        "read_more_link": "",
        "language": "en",
        "title": "Build Your First Image Classification Model in Just 10 Minutes!",
        "top_image": "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/deep-learning-image-classification.png",
        "meta_img": "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/deep-learning-image-classification.png",
        "images": [
            "https://av-public-assets.s3.ap-south-1.amazonaws.com/logos/av-logo-svg.svg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/navbar.jpg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/navbar.jpg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/navbar.jpg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/navbar.jpg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/navbar.jpg",
            "https://av-identity.s3.amazonaws.com/users/user/nocNbboBQPy1IoXTP7JInw.jpg",
            "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/deep-learning-image-classification.png",
            "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/index.jpeg",
            "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/apparel_Cover-thumbnail-1200x1200-90.jpg",
            "https://cdn.analyticsvidhya.com/wp-content/uploads/2024/01/image-classification-model.jpg",
            "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/Deep_learning_pp_1-thumbnail-1200x1200.png",
            "https://av-identity.s3.amazonaws.com/users/user/nocNbboBQPy1IoXTP7JInw.jpg",
            "https://secure.gravatar.com/avatar/d6ba4596168e4f67faca76c7887645b3?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/ae6bb90bfa985987ddd8fa65534ee701?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/d58d17587b0eef41ac1f4a88d1cfeb20?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/b0e6c4437a6555bd02b31ab04d04d277?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/1cdd2b5608de5fe80c08cd99bcb4e7ef?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/49cf86a41966db1cc7993b3dbe846cdb?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/ae6bb90bfa985987ddd8fa65534ee701?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/c71166731b3ceb3abf38dc11ac270abf?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/f6c249d91b763d93c5602cd78e5db8ff?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/c4573d71598ed757abfa5fb4e9b6a79b?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/36a0dc191f142edc9d714046c207d832?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/36a0dc191f142edc9d714046c207d832?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/5082e4272b91ff0f6703794531cd710a?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/f1689a3fb86f9047915818386ba9935b?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/e3a9b97377fa4a920b2e6b272e98c5f8?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/e82d852ceb3fcd49f4972d053f500512?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/31d5254a2a8867d0b54f13497d943686?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/bcfcc7bc40a0c18aa8c086aaec4275e5?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/e22369626b5617dd3c95ee9c74782fa7?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/9f2d1aa1220072b20c4956cb29af1221?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/8eca912bd6e66c66c5d8f39f46836245?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/6e86b4321689b513c193e2faa28c3e65?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/cd0a2415b75567624ed5fb7ec5650211?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/cd0a2415b75567624ed5fb7ec5650211?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/860fdf21fd2d977964ce457daee900cd?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/8dbe42cb391f2029ef15b40227855a39?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/80ed511e33242e36d1879a5fadfd2349?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/5b02c2668b1b21401ca7282839a73ad9?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/5b02c2668b1b21401ca7282839a73ad9?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/ad1d518627c312f270616967112a9d03?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/f355460c3603e8c64b75759db51430eb?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/401fbf5471256a56706ed5558a1231ac?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/4dce81540827fe8234812a99a578d0b5?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/152a2c73f42b9d6397dcf6b6d573e364?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/101946c781ab92db29f6075b7e7b647f?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/5082e4272b91ff0f6703794531cd710a?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/5cbc3c1129e9624d67ec3e6fbf7e3a89?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/4554ee04797af65395894edd1aad189d?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/61ffaee2b8fc116a142d48e8157e4d13?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/867834450fd9c98d621b9e29b20e7be0?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/e2510c8e99204df9b014fb08bb6a8afa?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/ebba72c6ce59a8f7f1b9bcbea0a1fbca?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/6d6a82f47d38d060121dc5e765394018?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/ca17b4743337e98f27ece9e69db0d9be?s=74&d=mm&r=g",
            "https://secure.gravatar.com/avatar/eed74e736d0a3795af0cc24f161a8a24?s=74&d=mm&r=g",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/removeAfterProdcution/path-digital.png",
            "https://av-identity.s3.amazonaws.com/users/user/bGnsep7nT0GMWuLpkDl15Q.jpg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/removeAfterProdcution/in.png",
            "https://av-identity.s3.amazonaws.com/users/user/R7HrsWl1QrGRiw_e9m4fDA.jpg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/removeAfterProdcution/in.png",
            "https://av-identity.s3.amazonaws.com/users/user/ZcU4ALTFT96MVCzfiGuhsQ.jpeg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/removeAfterProdcution/in.png",
            "https://av-identity.s3.amazonaws.com/users/user/aM3WrxdNSTGLg7LoqX-q0w.png",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/removeAfterProdcution/in.png",
            "https://av-identity.s3.amazonaws.com/users/user/zy4FL_yyQlG4PkWcyGYvhw.jpg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/removeAfterProdcution/in.png",
            "https://av-identity.s3.amazonaws.com/users/user/a4ByfUyoQRmdGzLpBzHVLw.jpeg",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/removeAfterProdcution/in.png",
            "https://av-identity.s3.amazonaws.com/users/user/ZTsmKl-1Qvqn07FUzgaBNw.png",
            "https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/images/removeAfterProdcution/in.png",
            "https://d2cd20fxv8fgim.cloudfront.net/homepage/images/Play_Store.svg",
            "https://d2cd20fxv8fgim.cloudfront.net/homepage/images/App_Store.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "PulkitS"
        ],
        "publish_date": "2019-01-10T04:36:03+00:00",
        "summary": "",
        "meta_description": "Learn the steps to build an image classification model efficiently. From data setup to model training, master the process here!",
        "meta_lang": "en",
        "meta_favicon": "https://imgcdn.analyticsvidhya.com/favicon/av-fav.ico",
        "meta_site_name": "Analytics Vidhya",
        "canonical_link": "https://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/",
        "text": "13 minutes\n\nIntroduction\n\nBuild a deep learning image classification model in a few minutes without the hassle of lengthy training. No need for a powerful machine! I’ve heard this countless times from aspiring data scientists who shy away from building deep learning models on their own machines.\n\nYou don’t need to be working for Google or other big tech firms to work on deep learning datasets! It is entirely possible to build your own neural network from the ground up in a matter of minutes without needing to lease out Google’s servers. Fast.ai’s students designed a model on the Imagenet dataset in 18 minutes – and I will showcase something similar in this article, focusing on image classification.\n\nDeep learning is a vast field so we’ll narrow our focus a bit and take up the challenge of solving an Image Classification project. Additionally, we’ll be using a very simple deep learning architecture to achieve a pretty impressive accuracy score.\n\nYou can consider the Python code we’ll see in this article as a benchmark for building Image Classification models. Once you get a good grasp on the concept, go ahead and play around with the code, participate in competitions and climb up the leaderboard!\n\nIf you’re new to deep learning and are fascinated by the field of computer vision (who isn’t?!), do check out the ‘Computer Vision using Deep Learning‘ course. It’s a comprehensive introduction to this wonderful field and will set you up for what is inevitably going to a huge job market in the near future.\n\nWhat Is Image Classification?\n\nConsider the below image:\n\nYou will have instantly recognized it – it’s a (swanky) car. Take a step back and analyze how you came to this conclusion – you were shown an image and you classified the class it belonged to (a car, in this instance). And that, in a nutshell, is what image classification is all about.\n\nThere are potentially n number of categories in which a given image can be classified. Manually checking and classifying images is a very tedious process. The task becomes near impossible when we’re faced with a massive number of images, say 10,000 or even 100,000. How useful would it be if we could automate this entire process and quickly label images per their corresponding class? This is where deep learning models for image classification come into play. They offer a solution to this challenge by leveraging advanced algorithms to automatically categorize images based on their content.\n\nSelf-driving cars are a great example to understand where image classification is used in the real-world. To enable autonomous driving, we can build deep learning models for image classification that recognize various objects, such as vehicles, people, moving objects, etc. on the road. We’ll see a couple more use cases later in this article but there are plenty more applications around us. Use the comments section below the article to let me know what potential use cases you can come with up!\n\nNow that we have a handle on our subject matter, let’s dive into how an image classification model is built, what are the prerequisites for it, and how it can be implemented in Python.\n\nSetting Up the Structure of Our Image Data\n\nOur data needs to be in a particular format in order to solve an image classification problem. We will see this in action in a couple of sections but just keep these pointers in mind till we get there.\n\nYou should have 2 folders, one for the train set and the other for the test set. In the training set, you will have a .csv file and an image folder:\n\nThe .csv file contains the names of all the training images and their corresponding true labels\n\nThe image folder has all the training images.\n\nThe .csv file in our test set is different from the one present in the training set. This test set .csv file contains the names of all the test images, but they do not have any corresponding labels. Can you guess why? Our model will be trained on the images present in the training set and the label predictions will happen on the testing set images\n\nIf your data is not in the format described above, you will need to convert it accordingly (otherwise the predictions will be awry and fairly useless).\n\nBreaking Down the Process of Model Building\n\nBefore we deep dive into the Python code, let’s take a moment to understand how an image classification model is typically designed. We can divide this process broadly into 4 stages. Each stage requires a certain amount of time to execute:\n\nLoading and pre-processing Data – 30% time\n\nDefining Model architecture – 10% time\n\nTraining the model – 50% time\n\nEstimation of performance – 10% time\n\nLet me explain each of the above steps in a bit more detail. This section is crucial because not every model is built in the first go. You will need to go back after each iteration, fine-tune your steps, and run it again. Having a solid understanding of the underlying concepts will go a long way in accelerating the entire process.\n\nStage 1: Loading and pre-processing the data\n\nData is gold as far as deep learning models are concerned. Your image classification model has a far better chance of performing well if you have a good amount of images in the training set. Also, the shape of the data varies according to the architecture/framework that we use.\n\nHence, the critical data pre-processing step (the eternally important step in any project). I highly recommend going through the ‘Basics of Image Processing in Python’ to understand more about how pre-processing works with image data.\n\nBut we are not quite there yet. In order to see how our model performs on unseen data (and before exposing it to the test set), we need to create a validation set. This is done by partitioning the training set data.\n\nIn short, we train the model on the training data and validate it on the validation data. Once we are satisfied with the model’s performance on the validation set, we can use it for making predictions on the test data.\n\nTime required for this step: We require around 2-3 minutes for this task.\n\nStage 2: Defining the model’s architecture\n\nThis is another crucial step in our deep learning model building process. We have to define how our model will look and that requires answering questions like:\n\nHow many convolutional layers do we want?\n\nWhat should be the activation function for each layer?\n\nHow many hidden units should each layer have?\n\nAnd many more. These are essentially the hyperparameters of the model which play a MASSIVE part in deciding how good the predictions will be.\n\nHow do we decide these values? Excellent question! A good idea is to pick these values based on existing research/studies. Another idea is to keep experimenting with the values until you find the best match but this can be quite a time consuming process.\n\nTime required for this step: It should take around 1 minute to define the architecture of the model.\n\nStage 3: Training the model\n\nFor training the model, we require:\n\nTraining images and their corresponding true labels\n\nValidation images and their corresponding true labels (we use these labels only to validate the model and not during the training phase)\n\nWe also define the number of epochs in this step. For starters, we will run the model for 10 epochs (you can change the number of epochs later).\n\nTime required for this step: Since training requires the model to learn structures, we need around 5 minutes to go through this step.\n\nAnd now time to make predictions!\n\nStage 4: Estimating the model’s performance\n\nFinally, we load the test data (images) and go through the pre-processing step here as well. We then predict the classes for these images using the trained model.\n\nTime required for this step: ~ 1 minute.\n\nSetting Up the Problem Statement and Understanding the Data\n\nWe will be taking on a fascinating challenge to grasp image classification. The task involves constructing a model capable of categorizing a set of images based on apparel types like shirts, trousers, shoes, socks, etc. This particular problem is a common challenge for many e-commerce retailers, adding an extra layer of intrigue to this computer vision problem\n\nThis challenge is called ‘Identify the Apparels’ and is one of the practice problems we have on our DataHack platform. You will have to register and download the dataset from the above link.\n\nWe have a total of 70,000 images (28 x 28 dimension), out of which 60,000 are from the training set and 10,000 from the test one. The training image Classification are pre-labelled according to the apparel type with 10 total classes. The test images are, of course, not labelled. The challenge is to identify the type of apparel present in all the test images.\n\nWe will build our model on Google Colab since it provides a free GPU to train our models.\n\nSteps to Build Our Model\n\nTime to fire up your Python skills and get your hands dirty. We are finally at the implementation part of our learning!\n\nSetting up Google Colab\n\nImporting Libraries\n\nLoading and Preprocessing Data – (3 mins)\n\nCreating a validation set\n\nDefining the model structure – (1 min)\n\nTraining the model – (5 min)\n\nMaking predictions – (1 min)\n\nLet’s look at each step in detail.\n\nSteps to Build Image Classification\n\nStep 1: Setting up a Google Colab\n\nSince we’re importing our data from a Google Drive link, we’ll need to add a few lines of code in our Google Colab notebook. Create a new Python 3 notebook and write the following code blocks:\n\n!pip install PyDrive\n\nThis will install PyDrive. Now we will import a few required libraries:\n\nimport os from pydrive.auth import GoogleAuth from pydrive.drive import GoogleDrive from google.colab import auth from oauth2client.client import GoogleCredentials\n\nNext, we will create a drive variable to access Google Drive:\n\nauth.authenticate_user() gauth = GoogleAuth() gauth.credentials = GoogleCredentials.get_application_default() drive = GoogleDrive(gauth)\n\nTo download the dataset, we will use the ID of the file uploaded on Google Drive:\n\ndownload = drive.CreateFile({'id': '1BZOv422XJvxFUnGh-0xVeSvgFgqVY45q'})\n\nReplace the ‘id’ in the above code with the ID of your file. Now we will download this file and unzip it:\n\ndownload.GetContentFile('train_LbELtWX.zip') !unzip train_LbELtWX.zip\n\nYou have to run these code blocks every time you start your notebook.\n\nStep 2 : Import the libraries we’ll need during our model building phase.\n\nimport keras from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D from keras.utils import to_categorical from keras.preprocessing import image import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from keras.utils import to_categorical from tqdm import tqdm\n\nStep 3: Recall the pre-processing steps we discussed earlier. We’ll be using them here after loading the data.\n\ntrain = pd.read_csv('train.csv')\n\nNext, we will read all the training images, store them in a list, and finally convert that list into a numpy array.\n\n# We have grayscale images, so while loading the images we will keep grayscale=True, if you have RGB images, you should set grayscale as False train_image = [] for i in tqdm(range(train.shape[0])): img = image.load_img('train/'+train['id'][i].astype('str')+'.png', target_size=(28,28,1), grayscale=True) img = image.img_to_array(img) img = img/255 train_image.append(img) X = np.array(train_image)\n\nAs it is a multi-class classification problem (10 classes), we will one-hot encode the target variable.\n\ny=train['label'].values y = to_categorical(y)\n\nStep 4: Creating a validation set from the training data.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n\nStep 5: Define the model structure.\n\nWe will create a simple architecture with 2 convolutional layers, one dense hidden layer and an output layer.\n\nmodel = Sequential() model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1))) model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(10, activation='softmax'))\n\nNext, we will compile the model we’ve created.\n\nmodel.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n\nStep 6: Training the model.\n\nIn this step, we will train the model on the training set images and validate it using, you guessed it, the validation set.\n\nmodel.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n\nStep 7: Making predictions!\n\nWe’ll initially follow the steps we performed when dealing with the training data. Load the test images and predict their classes using the model.predict_classes() function.\n\ndownload = drive.CreateFile({'id': '1KuyWGFEpj7Fr2DgBsW8qsWvjqEzfoJBY'}) download.GetContentFile('test_ScVgIM0.zip') !unzip test_ScVgIM0.zip\n\nLet’s import the test file:\n\ntest = pd.read_csv('test.csv')\n\nNow, we will read and store all the test images:\n\ntest_image = [] for i in tqdm(range(test.shape[0])): img = image.load_img('test/'+test['id'][i].astype('str')+'.png', target_size=(28,28,1), grayscale=True) img = image.img_to_array(img) img = img/255 test_image.append(img) test = np.array(test_image)\n\n# making predictions prediction = model.predict_classes(test)\n\nWe will also create a submission file to upload on the DataHack platform page (to see how our results fare on the leaderboard).\n\ndownload = drive.CreateFile({'id': '1z4QXy7WravpSj-S4Cs9Fk8ZNaX-qh5HF'}) download.GetContentFile('sample_submission_I5njJSF.csv')\n\n# creating submission file sample = pd.read_csv('sample_submission_I5njJSF.csv') sample['label'] = prediction sample.to_csv('sample_cnn.csv', header=True, index=False)\n\nDownload this sample_cnn.csv file and upload it on the contest page to generate your results and check your ranking on the leaderboard. This will give you a benchmark solution to get you started with any Image Classification problem!\n\nYou can try hyperparameter tuning and regularization techniques to improve your model’s performance further. I ecnourage you to check out this article to understand this fine-tuning step in much more detail – ‘A Comprehensive Tutorial to learn Convolutional Neural Networks from Scratch’.\n\nHow to build Image Classification Model?\n\nNew Practice Problem\n\nLet’s test our learning on a different dataset. We’ll be cracking the ‘Identify the Digits’ practice problem in this section. Go ahead and download the dataset. Before you proceed further, try to solve this on your own. You already have the tools to solve it – you just need to apply them! Come back here to check your results or if you get stuck at some point.\n\nIn this challenge, we need to identify the digit in a given image. We have a total of 70,000 images – 49,000 labelled ones in the training set and the remaining 21,000 in the test set (the test images are unlabelled). We need to identify/predict the class of these unlabelled images.\n\nReady to begin? Awesome! Create a new Python 3 notebook and run the following code:\n\n# Setting up Colab !pip install PyDrive\n\nimport os from pydrive.auth import GoogleAuth from pydrive.drive import GoogleDrive from google.colab import auth from oauth2client.client import GoogleCredentials\n\nauth.authenticate_user() gauth = GoogleAuth() gauth.credentials = GoogleCredentials.get_application_default() drive = GoogleDrive(gauth)\n\n# Replace the id and filename in the below codes download = drive.CreateFile({'id': '1ZCzHDAfwgLdQke_GNnHp_4OheRRtNPs-'}) download.GetContentFile('Train_UQcUa52.zip') !unzip Train_UQcUa52.zip\n\n# Importing libraries import keras from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D from keras.utils import to_categorical from keras.preprocessing import image import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from keras.utils import to_categorical from tqdm import tqdm\n\ntrain = pd.read_csv('train.csv')\n\n# Reading the training images train_image = [] for i in tqdm(range(train.shape[0])): img = image.load_img('Images/train/'+train['filename'][i], target_size=(28,28,1), grayscale=True) img = image.img_to_array(img) img = img/255 train_image.append(img) X = np.array(train_image)\n\n# Creating the target variable y=train['label'].values y = to_categorical(y)\n\n# Creating validation set X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n\n# Define the model structure model = Sequential() model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1))) model.add(Conv2D(64, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(10, activation='softmax'))\n\n# Compile the model model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n\n# Training the model model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n\ndownload = drive.CreateFile({'id': '1zHJR6yiI06ao-UAh_LXZQRIOzBO3sNDq'}) download.GetContentFile('Test_fCbTej3.csv')\n\ntest_file = pd.read_csv('Test_fCbTej3.csv')\n\ntest_image = [] for i in tqdm(range(test_file.shape[0])): img = image.load_img('Images/test/'+test_file['filename'][i], target_size=(28,28,1), grayscale=True) img = image.img_to_array(img) img = img/255 test_image.append(img) test = np.array(test_image)\n\nprediction = model.predict_classes(test)\n\ndownload = drive.CreateFile({'id': '1nRz5bD7ReGrdinpdFcHVIEyjqtPGPyHx'}) download.GetContentFile('Sample_Submission_lxuyBuB.csv')\n\nsample = pd.read_csv('Sample_Submission_lxuyBuB.csv') sample['filename'] = test_file['filename'] sample['label'] = prediction sample.to_csv('sample.csv', header=True, index=False)\n\nSubmit this file on the practice problem page to get a pretty decent accuracy number. It’s a good start but there’s always scope for improvement. Keep playing around with the hyperparameter values and see if you can improve on our basic model.\n\nConclusion\n\nWho said image classification models required hours or days to train? My aim here was to showcase that you can come up with a pretty decent image classification model in double-quick time. You should pick up similar challenges and try to code them from your end as well. There’s nothing like learning by doing!\n\nThe top data scientists and analysts have these codes ready before a Hackathon even begins. They use these codes to make early submissions before diving into a detailed analysis. Once they have a benchmark solution, they start improving their model using different techniques.\n\nFrequently Asked Questions"
    }
}