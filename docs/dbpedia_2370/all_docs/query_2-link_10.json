{
    "id": "dbpedia_2370_2",
    "rank": 10,
    "data": {
        "url": "https://forum.image.sc/t/create-tiles-with-separate-annotations/70536",
        "read_more_link": "",
        "language": "en",
        "title": "Create tiles with separate annotations",
        "top_image": "https://global.discourse-cdn.com/business4/uploads/imagej/original/2X/4/4904e8fe196486eabdbe0d9d185e94dfcab74e10.png",
        "meta_img": "https://global.discourse-cdn.com/business4/uploads/imagej/original/2X/4/4904e8fe196486eabdbe0d9d185e94dfcab74e10.png",
        "images": [
            "https://global.discourse-cdn.com/business4/uploads/imagej/optimized/3X/b/d/bd7cb30494690a328f51be747389e9b157fbe743_2_690x418.jpeg",
            "https://avatars.discourse-cdn.com/v4/letter/e/e9bcb4/48.png",
            "https://avatars.discourse-cdn.com/v4/letter/e/e9bcb4/48.png",
            "https://avatars.discourse-cdn.com/v4/letter/e/e9bcb4/48.png",
            "https://sea1.discourse-cdn.com/business4/user_avatar/forum.image.sc/petebankhead/48/1964_2.png",
            "https://sea1.discourse-cdn.com/business4/user_avatar/forum.image.sc/petebankhead/48/1964_2.png",
            "https://sea1.discourse-cdn.com/business4/user_avatar/forum.image.sc/petebankhead/48/1964_2.png",
            "https://sea1.discourse-cdn.com/business4/user_avatar/forum.image.sc/petebankhead/48/1964_2.png",
            "https://sea1.discourse-cdn.com/business4/user_avatar/forum.image.sc/petebankhead/48/1964_2.png",
            "https://global.discourse-cdn.com/business4/uploads/imagej/optimized/3X/3/b/3b3e692eca96702dc07d940b8a7e97dffa3d201d_2_690x408.jpeg",
            "https://sea1.discourse-cdn.com/business4/user_avatar/forum.image.sc/petebankhead/48/1964_2.png",
            "https://avatars.discourse-cdn.com/v4/letter/e/e9bcb4/48.png",
            "https://avatars.discourse-cdn.com/v4/letter/e/e9bcb4/48.png",
            "https://sea1.discourse-cdn.com/business4/user_avatar/forum.image.sc/biraja/48/71465_2.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "qupath"
        ],
        "tags": null,
        "authors": [
            "ericka (Ericka Liu)",
            "petebankhead (Pete)",
            "Biraja (Biraja Ghoshal)",
            "Research_Associate (MicroscopyRA)"
        ],
        "publish_date": "2022-08-10T07:23:05+00:00",
        "summary": "",
        "meta_description": "Hi, I wish to know whether there is a way to create tiles and sepearate annotation in each tile. Now my code is able to create tile along with all the annotations in that tile. However, some annotations overlap, so in or&hellip;",
        "meta_lang": "en",
        "meta_favicon": "https://global.discourse-cdn.com/business4/uploads/imagej/optimized/2X/4/4b3d366e9bd1c4abfb68ca23f7596edd29cb2f4a_2_32x32.png",
        "meta_site_name": "Image.sc Forum",
        "canonical_link": "https://forum.image.sc/t/create-tiles-with-separate-annotations/70536",
        "text": "Hi, I wish to know whether there is a way to create tiles and sepearate annotation in each tile. Now my code is able to create tile along with all the annotations in that tile. However, some annotations overlap, so in order for me to train my model, I wish to output one annotation for a tile at a time. Could someone help me revise the following code to achieve my goal? Thanks!\n\n-----------------code------------------------------------------------\n\nimport qupath.lib.images.servers.LabeledImageServer def imageData = getCurrentImageData() // Define output path (relative to project) def name = GeneralTools.getNameWithoutExtension(imageData.getServer().getMetadata().getName()) def pathOutput = buildFilePath(PROJECT_BASE_DIR, 'tiles', name) mkdirs(pathOutput) // Define output resolution double requestedPixelSize = 10.0 // Convert to downsample double downsample = 1 // Create an ImageServer where the pixels are derived from annotations def labelServer = new LabeledImageServer.Builder(imageData) .backgroundLabel(0, ColorTools.BLACK) // Specify background label (usually 0 or 255) .downsample(1) // Choose server resolution; this should match the resolution at which tiles are exported .addLabel('Eos', 1) // Choose output labels (the order matters!) .multichannelOutput(false) // If true, each label is a different channel (required for multiclass probability) .build() // Create an exporter that requests corresponding tiles from the original & labeled image servers new TileExporter(imageData) .includePartialTiles(false) .downsample(1) // Define export resolution .imageExtension('.jpg') // Define file extension for original pixels (often .tif, .jpg, '.png' or '.ome.tif') .tileSize(512) // Define size of each tile, in pixels .labeledServer(labelServer) // Define the labeled image server to use (i.e. the one we just built) .annotatedTilesOnly(true) // If true, only export tiles if there is a (labeled) annotation present .overlap(128) // Define overlap, in pixel units at the export resolution .writeTiles(pathOutput) // Write tiles to the specified directory print 'Done!'\n\nHi @ericka hope you don’t mind I edited your post to add code formatting (the </> button at the top when posting).\n\nHere is a modified version of the script that I think does what you’re asking for:\n\nimport qupath.lib.images.servers.LabeledImageServer def imageData = getCurrentImageData() // Define the target annotation class to use for export def targetClass = getPathClass('Eos') // Get the image name def name = GeneralTools.getNameWithoutExtension(imageData.getServer().getMetadata().getName()) // Define output resolution double requestedPixelSize = 10.0 // Convert to downsample double downsample = 1 // Get the relevant annotations def annotations = getAnnotationObjects().findAll(a -> a.getPathClass() == targetClass) def count = 0 for (def annotation : annotations) { count++ // Define output path (relative to project) def pathOutput = buildFilePath(PROJECT_BASE_DIR, 'tiles', name, 'annotation-' + count) mkdirs(pathOutput) // Create an ImageServer where the pixels are derived from annotations def labelServer = new LabeledImageServer.Builder(imageData) .backgroundLabel(0, ColorTools.BLACK) // Specify background label (usually 0 or 255) .downsample(1) // Choose server resolution; this should match the resolution at which tiles are exported .addLabel(targetClass, 1) // Choose output labels (the order matters!) .multichannelOutput(false) // If true, each label is a different channel (required for multiclass probability) .useFilter(p -> p == annotation) // NEW: Use *only* the current annotation .build() // Create an exporter that requests corresponding tiles from the original & labeled image servers new TileExporter(imageData) .includePartialTiles(false) .downsample(1) // Define export resolution .imageExtension('.jpg') // Define file extension for original pixels (often .tif, .jpg, '.png' or '.ome.tif') .tileSize(512) // Define size of each tile, in pixels .labeledServer(labelServer) // Define the labeled image server to use (i.e. the one we just built) .annotatedTilesOnly(true) // If true, only export tiles if there is a (labeled) annotation present .overlap(128) // Define overlap, in pixel units at the export resolution .writeTiles(pathOutput) // Write tiles to the specified directory }\n\nBasically, it creates a different labeled image for each annotation with the specified target class. Because of the limited naming options in TileExporter currently, it needs to export tiles for each annotation into a separate subdirectory.\n\nHi @ericka assuming every annotation should be treated as completely distinct, then you could try something like this:\n\nimport qupath.lib.images.servers.LabeledImageServer def imageData = getCurrentImageData() // Use this instead of targetClass in previous script def targetClassNames = ['EOS', 'Tumor', 'etc', 'Stroma'] // Get the image name def name = GeneralTools.getNameWithoutExtension(imageData.getServer().getMetadata().getName()) // Define output resolution double requestedPixelSize = 10.0 // Convert to downsample double downsample = 1 // Loop through target classes as well for (def targetClassName in targetClassNames) { // Get the class here (remove any earlier line that uses getPathClass) def targetClass = getPathClass(targetClassName) // Get the relevant annotations def annotations = getAnnotationObjects().findAll(a -> a.getPathClass() == targetClass) // Original annotation loop def count = 0 for (def annotation : annotations) { count++ // Define output path (relative to project) def pathOutput = buildFilePath(PROJECT_BASE_DIR, 'tiles', name, targetClassName, 'annotation-' + count) mkdirs(pathOutput) // Create an ImageServer where the pixels are derived from annotations def labelServer = new LabeledImageServer.Builder(imageData) .backgroundLabel(0, ColorTools.BLACK) // Specify background label (usually 0 or 255) .downsample(1) // Choose server resolution; this should match the resolution at which tiles are exported .addLabel(targetClass, 1) // Choose output labels (the order matters!) .multichannelOutput(false) // If true, each label is a different channel (required for multiclass probability) .useFilter(p -> p == annotation) // NEW: Use *only* the current annotation .build() // Create an exporter that requests corresponding tiles from the original & labeled image servers new TileExporter(imageData) .includePartialTiles(false) .downsample(1) // Define export resolution .imageExtension('.jpg') // Define file extension for original pixels (often .tif, .jpg, '.png' or '.ome.tif') .tileSize(512) // Define size of each tile, in pixels .labeledServer(labelServer) // Define the labeled image server to use (i.e. the one we just built) .annotatedTilesOnly(true) // If true, only export tiles if there is a (labeled) annotation present .overlap(128) // Define overlap, in pixel units at the export resolution .writeTiles(pathOutput) // Write tiles to the specified directory } }\n\nHey @petebankhead , sorry to bother you again. I wish to revise this code a bit. From the following attachment, you can see that the first two patches are of the same x coordinate and almost the same y coordinate. However, I wish to cut my images using the same coordinates (like one patch files with multiple files containing individual annotation). For example, if I cut my first patch with x=17920, y=16640, I wish to have all annotations in that patch to be outputted instead of output two patches and two annotations like the first two pair in the attachment. Do you know how I can do this? Thank you!\n\nHmmm, I can’t think of a straightforward way to do this. It sounds like what you want is closer to the default behavior anyway?\n\nThe purpose of the TileExporter is to make common cases much easier (previously, every kind of similar export would require a long custom script), but it doesn’t handle all scenarios. If you want something highly-specific/non-standard then it might not be the right starting point.\n\nIf neither the default nor adapted behavior is suitable for your needs, it would help if you could describe why not and also explain what happens next in your pipeline. It’s easier to give an answer or suggestion if we have the full picture of what is happening.\n\nThere are lots of other ways to export annotations, where tiling isn’t essential anyway: Exporting annotations — QuPath 0.3.0 documentation\n\nHi @petebankhead and @Research_Associate , I wish to clarify my goal. So what I want is that I cut my whole slide image into 512x512 patches. Then, I output each annotation as a separate binary mask (also 512x512) that lies in my image patches. Let’s say if now I have my 512x512 patches and there are 4 annotations in that patch, I wish to have 4 separate 512x512 binary mask (same coordinate as my patch).\n\nOne easy way I can think of is that I can output my 512x512 patches first and use the x,y coordinates as their file name. Then I can create individual annotation binary mask the same size as my original whole slide image (but I record the x,y coordinate of the annotation as the file name). I can then calculate which patch does the annotation belong to cut my annotation into 512x512 patch that matches my image patches.\n\nHope this make sense. I think now I need a code that allows me to output individual annotation binary mask the same size as my original whole slide image (but I record the x,y coordinate of the annotation as the file name).\n\nDo you want to export all possible patches across the entire whole slide image, or just ones that contain annotations?\n\nAre you exporting at full resolution? I assume so because your original script has downsample = 1 (although there’s a requestedPixelSize variable that seems to be unused).\n\nIf you just have binary images, how do you handle the fact that you have different labels (classifications) for annotations? Does the classification need to be encoded in the filename?\n\nYou mentioned that one of the complications is that annotations can overlap. If the overlapping annotations have the same classification, do these still need to be separated?\n\nBy ‘same size’ I think you mean ‘same resolution’ – but cropped?\n\nIf so, then this script seems closer to what you want: Exporting annotations — QuPath 0.4.4 documentation\n\nAnd you can use region.getX() and region.getY() to get the coordinates to use in the filename.\n\nBut I don’t really understand exactly what you mean by this process.\n\nAlso, I’m not sure if you have lots of small annotations or a few large ones. If you have large annotations, then exporting the full annotation might not be possible in any format other than OME-TIFF (because it would require a pyramidal image).\n\nKind of, although not entirely to me… and I still don’t understand what happens next. I think you’re training an AI model, I’d guess using Python? If so, then any adjustment of export could happen on the QuPath side (using Groovy) or the Python side (assuming that QuPath at least gives all the necessary information somehow).\n\nI’d like to understand this before suggesting any other solution, in case spending a lot of time trying to optimize some complicated Groovy scripts isn’t the most efficient way to solve the overall problem.\n\nWriting Groovy scripts for this kind of thing can be pretty time-consuming, since it also means generating some kind of example to test and debug them with. It’s faster if the precise behavior of the script is clearly defined and unambiguous, but I still don’t have a completely clear idea of what you need.\n\nJust ones that contain annotations.\n\nYes, full resolution. I didn’t use requestedPixelSize because I didn’t quite know how to use this but I need downsample = 1 so I simply ignore this.\n\nYes, the classification is needed to be encoded in the filename or in separate folders.\n\nSo the deep learning model I will be using next requires my individual annotations to be stored separately in a json file. If I output all annotation at a time, later when I convert my binary mask to a JSON file, it might consider two overlapping annotations to simply be one annotation.\n\nYeah, I tried this one (shown in the following screenshot). But the output is cropped to only contains the annotation. What I want is a binary mask that is of the same size as my original whole slide image and with this single annotation on it.\n\nYeah, I will be using deep learning model to learn my annotation. The input of this model requires 512x512 tiles and a COCO format file including all annotations’ info (which patch does this annotation belong to, what is the x,y coordinate of this annotation relative to the patch). Therefore, I want to have my patches cut first. Then, for each patch, I will need all annotation separately in a binary mask and then convert to COCO."
    }
}