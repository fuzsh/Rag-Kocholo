{
    "id": "dbpedia_2370_2",
    "rank": 26,
    "data": {
        "url": "https://pyimagesearch.com/2017/11/27/image-hashing-opencv-python/",
        "read_more_link": "",
        "language": "en",
        "title": "Image hashing with OpenCV and Python",
        "top_image": "https://pyimagesearch.com/wp-content/uploads/2017/11/image_hashing_header.png",
        "meta_img": "https://pyimagesearch.com/wp-content/uploads/2017/11/image_hashing_header.png",
        "images": [
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_header.png?size=126x132&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_header-285x300.png?lossy=2&strip=1&webp=1 285w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_header.png?size=378x397&lossy=2&strip=1&webp=1 378w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_header.png?lossy=2&strip=1&webp=1 600w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_header.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_blueprint.png?size=126x38&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_blueprint-300x89.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_blueprint.png?size=378x113&lossy=2&strip=1&webp=1 378w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_blueprint.png?size=504x150&lossy=2&strip=1&webp=1 504w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_blueprint-768x229.png?lossy=2&strip=1&webp=1 768w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_blueprint-1024x305.png?lossy=2&strip=1&webp=1 1024w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_blueprint.png?lossy=2&strip=1&webp=1 1472w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_blueprint.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_crypto_hash.png?size=126x42&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_crypto_hash-300x100.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_crypto_hash.png?size=378x126&lossy=2&strip=1&webp=1 378w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_crypto_hash.png?size=504x168&lossy=2&strip=1&webp=1 504w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_crypto_hash.png?lossy=2&strip=1&webp=1 600w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_crypto_hash.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_haystack.png?size=126x212&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_haystack-178x300.png?lossy=2&strip=1&webp=1 178w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_haystack.png?lossy=2&strip=1&webp=1 297w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_haystack.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_needles.png?size=126x83&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_needles-300x197.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_needles.png?size=378x248&lossy=2&strip=1&webp=1 378w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_needles.png?size=504x331&lossy=2&strip=1&webp=1 504w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_needles.png?lossy=2&strip=1&webp=1 600w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_needles.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_input.png?size=126x60&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_input-300x142.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_input.png?size=378x179&lossy=2&strip=1&webp=1 378w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_input.png?size=504x239&lossy=2&strip=1&webp=1 504w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_input-768x364.png?lossy=2&strip=1&webp=1 768w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_input-1024x485.png?lossy=2&strip=1&webp=1 1024w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_input.png?lossy=2&strip=1&webp=1 1056w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_input.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_resized.png?size=126x134&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_resized-282x300.png?lossy=2&strip=1&webp=1 282w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_resized.png?lossy=2&strip=1&webp=1 600w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_resized.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_diff.png?size=126x134&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_diff-282x300.png?lossy=2&strip=1&webp=1 282w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_diff.png?lossy=2&strip=1&webp=1 600w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2017/11/image_hashing_diff.png?lossy=2&strip=1&webp=1",
            "https://fast.wistia.com/embed/medias/kno0cmko2z/swatch",
            "https://fast.wistia.com/embed/medias/kno0cmko2z/swatch",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=410x567&lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=2&strip=1&webp=1",
            "https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&d=mm&r=g 2x",
            "https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=240&d=mm&r=g",
            "https://pyimagesearch.com/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?size=126x95&lossy=1&strip=1&webp=1 126w, https://pyimagesearch.com/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&strip=1&webp=1 200w",
            "https://pyimagesearch.com/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/02/OpenCV-Face-detection-with-Haar-cascades_large-300x200.png?size=300x200&lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/02/OpenCV-Face-detection-with-Haar-cascades_large-300x200.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2019/08/image_hashing_search_engine_header.png?size=126x81&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2019/08/image_hashing_search_engine_header-300x192.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2019/08/image_hashing_search_engine_header.png?lossy=2&strip=1&webp=1 600w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2019/08/image_hashing_search_engine_header-300x192.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header.png?size=126x71&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header-300x169.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header.png?lossy=2&strip=1&webp=1 500w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header-300x169.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header.png?size=126x81&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header-300x193.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header.png?lossy=2&strip=1&webp=1 700w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header-300x193.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header.png?size=126x75&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header-300x179.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header.png?lossy=2&strip=1&webp=1 700w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header-300x179.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header.png?size=126x81&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header-300x193.png?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header.png?lossy=2&strip=1&webp=1 700w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header-300x193.png?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=126x113&lossy=2&strip=1&webp=1 126w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-300x268.jpg?lossy=2&strip=1&webp=1 300w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=378x338&lossy=2&strip=1&webp=1 378w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=504x450&lossy=2&strip=1&webp=1 504w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=630x563&lossy=2&strip=1&webp=1 630w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-768x686.jpg?lossy=2&strip=1&webp=1 768w, https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=2&strip=1&webp=1 932w",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=2&strip=1&webp=1",
            "https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/02/pyimagesearch_university_logo.png?lossy=2&strip=1&webp=1",
            "https://fast.wistia.com/embed/medias/8ggk996ods/swatch",
            "https://fast.wistia.com/embed/medias/8ggk996ods/swatch",
            "https://www.facebook.com/tr?id=1465896023527386&ev=PageView&noscript=1"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Adrian Rosebrock"
        ],
        "publish_date": "2017-11-27T00:00:00",
        "summary": "",
        "meta_description": "This tutorial covers how to perform image hashing and perceptual hashing using computer vision and image processing via OpenCV and Python.",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "PyImageSearch",
        "canonical_link": "https://pyimagesearch.com/2017/11/27/image-hashing-opencv-python/",
        "text": "Today’s blog post is on image hashing — and it’s the hardest blog post I’ve ever had to write.\n\nImage hashing isn’t a particularly hard technique (in fact, it’s one of the easiest algorithms I’ve taught here on the PyImageSearch blog).\n\nBut the subject matter and underlying reason of why I’m covering image hashing today of all days nearly tear my heart out to discuss.\n\nThe remaining introduction to this blog post is very personal and covers events that happened in my life five years ago, nearly to this very day.\n\nIf you want to skip the personal discussion and jump immediately to the image hashing content, I won’t judge — the point of PyImageSearch is to be a computer vision blog after all.\n\nTo skip to the computer vision content, just scroll to the “Image Hashing with OpenCV and Python” section where I dive into the algorithm and implementation.\n\nBut while PyImageSearch is a computer vision and deep learning blog, I am a very real human that writes it.\n\nAnd sometimes the humanity inside me needs a place to share.\n\nA place to share about childhood.\n\nMental illness.\n\nAnd the feelings of love and loss.\n\nI appreciate you as a PyImageSearch reader and I hope you’ll let me have this introduction to write, pour out, and continue my journey to finding peace.\n\nMy best friend died in my arms five years ago, nearly to this very day.\n\nHer name was Josie.\n\nSome of you may recognize this name — it appears in the dedication of all my books and publications.\n\nJosie was a dog, a perfect, loving, caring beagle, that my dad got for me when I was 11 years old.\n\nPerhaps you already understand what it’s like to lose a childhood pet.\n\nOr perhaps you don’t see the big deal — “It’s only a dog, right?”\n\nBut to me, Josie was more than a dog.\n\nShe was the last thread that tied my childhood to my adulthood. Any unadulterated feelings of childhood innocence were tied to that thread.\n\nWhen that thread broke, I nearly broke too.\n\nYou see, my childhood was a bit of a mess, to say the least.\n\nI grew up in a broken home. My mother suffered (and still does) from bipolar schizophrenia, depression, severe anxiety, and a host of other mental afflictions, too many for me to enumerate.\n\nWithout going into too much detail, my mother’s illnesses are certainly not her fault — but she often resisted the care and help she so desperately needed. And when she did accept help, if often did not go well.\n\nMy childhood consisted of a (seemingly endless) parade of visitations to the psychiatric hospital followed by nearly catatonic interactions with my mother. When she came out of the catatonia, my home life often descended into turmoil and havoc.\n\nYou grow up fast in that environment.\n\nAnd it becomes all too easy to lose your childhood innocence.\n\nMy dad, who must have recognized the potentially disastrous trajectory my early years were on (and how it could have a major impact on my well-being as an adult), brought home a beagle puppy for me when I was 11 years old, most likely to help me hold on to a piece of my childhood.\n\nHe was right. And it worked.\n\nAs a kid, there is no better feeling than holding a puppy, feeling its heartbeat against yours, playfully squirming and wiggling in and out of your arms, only to fall asleep on your lap five minutes later.\n\nJosie gave me back some of my child innocence.\n\nWhenever I got home from school, she was there.\n\nWhenever I sat by myself, playing video games late at night (a ritual I often performed to help me “escape” and cope), she was there.\n\nAnd whenever my home life turned into screaming, yelling, and utterly incomprehensible shrieks of tortured mental illness, Josie was always right there next to me.\n\nAs I grew into those awkward mid-to-late teenage years, I started to suffer from anxiety issues myself, a condition, I later learned, all too common for kids growing up in these circumstances.\n\nDuring freshman and sophomore year of high school my dad had to pick me up and take me home from the school nurse’s office no less than twenty times due to me having what I can only figure were acute anxiety attacks.\n\nDespite my own issues as a teenager, trying to grow up and somehow grasp what was going on with myself and my family, Josie always laid next to me, keeping me company, and reminding me of what it was like to be a kid.\n\nBut when Josie died in my arms five years ago that thread broke — that single thread was all that tied the “adult me” to the “childhood me”.\n\nThe following year was brutal. I was finishing up my final semester of classes for my PhD, about to start my dissertation. I was working full-time. And I even had some side projects going on…\n\n…all the while trying to cope with not only the loss of my best friend, but also the loss of my childhood as well.\n\nIt was not a good year and I struggled immensely.\n\nHowever, soon after Josie died I found a bit of solace in collecting and organizing all the photos my family had of her.\n\nThis therapeutic, nostalgic task involved scanning physical photos, going through old SD cards for digital cameras, and even digging through packed away boxes to find long forgotten cellphones that had pictures on their memory cards.\n\nWhen I wasn’t working or at school I spent a lot of time importing all these photos into iPhoto on my Mac. It was tedious, manual work but that was just the work I needed.\n\nHowever, by the time I got ~80% of the way done importing the photos the weight became too much for me to bear on my shoulders. I needed to take a break for my own mental well-being.\n\nIt’s now been five years.\n\nI still have that remaining 20% to finish — and that’s exactly what I’m doing now.\n\nI’m in a much better place now, personally, mentally, and physically. It’s time for me to finish what I started, if for no other reason than than I owe it to myself and to Josie.\n\nThe problem is that it’s been five years since I’ve looked at these directories of JPEGs.\n\nSome directories have been imported into iPhoto (where I normally look at photos).\n\nAnd others have not.\n\nI have no idea which photos are already in iPhoto.\n\nSo how am I going to go about determining which directories of photos I still need to sort through and then import/organize?\n\nThe answer is image hashing.\n\nAnd I find it so perfectly eloquent that I can apply computer vision, my passion, to finish a task that means so much to me.\n\nThank you for reading this and being part of this journey with me.\n\nImage hashing with OpenCV and Python\n\nImage hashing or perceptual hashing is the process of:\n\nExamining the contents of an image\n\nConstructing a hash value that uniquely identifies an input image based on the contents of an image\n\nPerhaps the most well known image hashing implementation/service is TinEye, a reverse image search engine.\n\nUsing TinEye, users are able to:\n\nUpload an image\n\nAnd then TinEye will tell the user where on the web the image appears\n\nA visual example of a perceptual hashing/image hashing algorithm can be seen at the top of this section.\n\nGiven an input image, our algorithm computes an image hash based on the image’s visual appearance.\n\nImages that appear perceptually similar should have hashes that are similar as well (where “similar” is typically defined as the Hamming distance between the hashes).\n\nBy utilizing image hashing algorithms we can find near-identical images in constant time, or at worst, O(lg n) time when utilizing the proper data structures.\n\nIn the remainder of this blog post we’ll be:\n\nDiscussing image hashing/perceptual hashing (and why traditional hashes do not work)\n\nImplementing image hashing, in particular difference hashing (dHash)\n\nApplying image hashing to a real-world problem and dataset\n\nWhy can’t we use md5, sha-1, etc.?\n\nReaders with previous backgrounds in cryptography or file verification (i.e., checksums) may wonder why we cannot use md5, sha-1, etc.\n\nThe problem here lies in the very nature of cryptographic hashing algorithms: changing a single bit in the file will result in a different hash.\n\nThis implies that if we change the color of just a single pixel in an input image we’ll end up with a different checksum when in fact we (very likely) will be unable to tell that the single pixel has changed — to us, the two images will appear perceptually identical.\n\nAn example of this is seen in Figure 2 above. Here I take an input image and compute the md5 hash. I then resize the image to have a width of 250 pixels rather than 500 pixels — no other alterations to the image were made. I then recompute the md5 hash. Notice how the hash values have changed even though the visual contents of the image have not!\n\nIn the case of image hashing and perceptual hashing, we actually want similar images to have similar hashes as well. Therefore, we actually seek some hash collisions if images are similar.\n\nThe image hashing datasets for our project\n\nThe goal of this project is to help me develop a computer vision application that can (using the needle and haystack analogy):\n\nTake two input directories of images, the haystack and the needles.\n\nDetermine which needles are already in the haystack and which needles are not in the haystack.\n\nThe most efficient method to accomplish this task (for this particular project) is to use image hashing, a concept we’ll discuss later in this post.\n\nMy haystack in this case is my collection of photos in iPhotos — the name of this directory is Masters :\n\nAs we can see from the screenshots, my Masters directory contains 11,944 photos, totaling 38.81GB.\n\nI then have my needles, a set of images (and associated subdirectories):\n\nThe Josie_Backup directory contains a number of photos of my dog (Josie) along with numerous unrelated family photos.\n\nMy goal is to determine which directories and images have already been imported into iPhoto and which directories I still need to import into iPhoto and organize.\n\nUsing image hashing we can make quick work of this project.\n\nUnderstanding perceptual image hashing and difference hashing\n\nThe image hashing algorithm we will be implementing for this blog post is called difference hashing or simply dHash for short.\n\nI first remember reading about dHash on the HackerFactor blog during the end of my undergraduate/early graduate school career.\n\nMy goal here today is to:\n\nSupply additional insight to the dHash perceptual hashing algorithm.\n\nEquip you with a hand-coded dHash implementation.\n\nProvide a real-world example of image hashing applied to an actual dataset.\n\nThe dHash algorithm is only four steps and is fairly straightforward and easy to understand.\n\nStep #1: Convert to grayscale\n\nThe first step in our image hashing algorithm is to convert the input image to grayscale and discard any color information.\n\nDiscarding color enables us to:\n\nHash the image faster since we only have to examine one channel\n\nMatch images that are identical but have slightly altered color spaces (since color information has been removed)\n\nIf, for whatever reason, you are especially interested in color you can run the hashing algorithm on each channel independently and then combine at the end (although this will result in a 3x larger hash).\n\nStep #2: Resize\n\nNow that our input image has been converted to grayscale, we need to squash it down to 9×8 pixels, ignoring the aspect ratio. For most images + datasets, the resizing/interpolation step is the slowest part of the algorithm.\n\nHowever, by now you probably have two questions:\n\nWhy are we ignoring the aspect ratio of the image during the resize?\n\nWhy 9×8 — this seems a like an “odd” size to resize to?\n\nTo answer the first question:\n\nWe squash the image down to 9×8 and ignore aspect ratio to ensure that the resulting image hash will match similar photos regardless of their initial spatial dimensions.\n\nThe second question requires a bit more explanation and will be fully answered in the next step.\n\nStep #3: Compute the difference\n\nOur end goal is to compute a 64-bit hash — since 8×8 = 64 we’re pretty close to this goal.\n\nSo, why in the world would we resize to 9×8?\n\nWell, keep in mind the name of the algorithm we are implementing: difference hash.\n\nThe difference hash algorithm works by computing the difference (i.e., relative gradients) between adjacent pixels.\n\nIf we take an input image with 9 pixels per row and compute the difference between adjacent column pixels, we end up with 8 differences. Eight rows of eight differences (i.e., 8×8) is 64 which will become our 64-bit hash.\n\nIn practice we don’t actually have to compute the difference — we can apply a “greater than” test (or “less than”, it doesn’t really matter as long as the same operation is consistently used, as we’ll see in Step #4 below).\n\nIf this point is confusing, no worries, it will all become clear once we start actually looking at some code.\n\nStep #4: Build the hash\n\nThe final step is to assign bits and build the resulting hash. To accomplish this, we use a simple binary test.\n\nGiven a difference image D and corresponding set of pixels P, we apply the following test: P[x] > P[x + 1] = 1 else 0.\n\nIn this case, we are testing if the left pixel is brighter than the right pixel. If the left pixel is brighter we set the output value to one. Otherwise, if the left pixel is darker we set the output value to zero.\n\nThe output of this operation can be seen in Figure 6 above (where I have resized the visualization to 256×256 pixels to make it easier to see). If we pretend this difference map is instead 8×8 pixels the output of this test produces a set of 64 binary values which are then combined into a single 64-bit integer (i.e., the actual image hash).\n\nBenefits of dHash\n\nThere are multiple benefits of using difference hashing (dHash), but the primary ones include:\n\nOur image hash won’t change if the aspect ratio of our input image changes (since we ignore the aspect ratio).\n\nAdjusting brightness or contrast will either (1) not change our hash value or (2) only change it slightly, ensuring that the hashes will lie close together.\n\nDifference hashing is extremely fast.\n\nComparing difference hashes\n\nTypically we use the Hamming distance to compare hashes. The Hamming distance measures the number of bits in two hashes that are different.\n\nTwo hashes with a Hamming distance of zero implies that the two hashes are identical (since there are no differing bits) and that the two images are identical/perceptually similar as well.\n\nDr. Neal Krawetz of HackerFactor suggests that hashes with differences > 10 bits are most likely different while Hamming distances between 1 and 10 are potentially a variation of the same image. In practice you may need to tune these thresholds for your own applications and corresponding datasets.\n\nFor the purposes of this blog post we’ll only be examining if hashes are identical. I will leave optimizing the search to compute Hamming differences for a future tutorial here on PyImageSearch.\n\nImplementing image hashing with OpenCV and Python\n\nMy implementation of image hashing and difference hashing is inspired by the imagehash library on GitHub, but tweaked to (1) use OpenCV instead of PIL and (2) correctly (in my opinion) utilize the full 64-bit hash rather than compressing it.\n\nWe’ll be using image hashing rather than cryptographic hashes (such as md5, sha-1, etc.) due to the fact that some images in my needle or haystack piles may have been slightly altered, including potential JPEG artifacts.\n\nBecause of this, we need to rely on our perceptual hashing algorithm that can handle these slight variations to the input images.\n\nTo get started, make sure you have installed my imutils package, a series of convenience functions to make working with OpenCV easier (and make sure you access your Python virtual environment, assuming you are using one):\n\n$ workon cv $ pip install imutils\n\nFrom there, open up a new file, name it hash_and_search.py , and we’ll get coding:\n\n# import the necessary packages from imutils import paths import argparse import time import sys import cv2 import os\n\nLines 2-7 handle importing our required Python packages. Make sure you have imutils installed to have access to the paths submodule.\n\nFrom there, let’s define the dhash function which will contain our difference hashing implementation:\n\ndef dhash(image, hashSize=8): # resize the input image, adding a single column (width) so we # can compute the horizontal gradient resized = cv2.resize(image, (hashSize + 1, hashSize)) # compute the (relative) horizontal gradient between adjacent # column pixels diff = resized[:, 1:] > resized[:, :-1] # convert the difference image to a hash return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])\n\nOur dhash function requires an input image along with an optional hashSize . We set hashSize=8 to indicate that our output hash will be 8 x 8 = 64-bits.\n\nLine 12 resizes our input image down to (hashSize + 1, hashSize) — this accomplishes Step #2 of our algorithm.\n\nGiven the resized image we can compute the binary diff on Line 16, which tests if adjacent pixels are brighter or darker (Step #3).\n\nFinally, Line 19 builds the hash by converting the boolean values into a 64-bit integer (Step #4).\n\nThe resulting integer is then returned to the calling function.\n\nNow that our dhash function has been defined, let’s move on to parsing our command line arguments:\n\n# construct the argument parse and parse the arguments ap = argparse.ArgumentParser() ap.add_argument(\"-a\", \"--haystack\", required=True, help=\"dataset of images to search through (i.e., the haytack)\") ap.add_argument(\"-n\", \"--needles\", required=True, help=\"set of images we are searching for (i.e., needles)\") args = vars(ap.parse_args())\n\nOur script requires two command line arguments:\n\n--haystack : The path to the input directory of images that we will be checking the --needles path for.\n\n--needles : The set of images that we are searching for.\n\nOur goal is to determine whether each image in --needles exists in --haystack or not.\n\nLet’s go ahead and load the --haystack and --needles image paths now:\n\n# grab the paths to both the haystack and needle images print(\"[INFO] computing hashes for haystack...\") haystackPaths = list(paths.list_images(args[\"haystack\"])) needlePaths = list(paths.list_images(args[\"needles\"])) # remove the `\\` character from any filenames containing a space # (assuming you're executing the code on a Unix machine) if sys.platform != \"win32\": haystackPaths = [p.replace(\"\\\\\", \"\") for p in haystackPaths] needlePaths = [p.replace(\"\\\\\", \"\") for p in needlePaths]\n\nLines 31 and 32 grab paths to the respective images in each directory.\n\nWhen implementing this script, a number of images in my dataset had spaces in their filenames. On normal Unix systems we escape a space in a filename with a \\ , thereby turning the filename Photo 001.jpg into Photo\\ 001.jpg .\n\nHowever, Python assumes the paths are un-escaped so we must remove any occurrences of \\ in the paths (Lines 37 and 38).\n\nNote: The Windows operating system uses \\ to separate paths while Unix systems uses / . Windows systems will naturally have a \\ in the path, hence why I make this check on Line 36. I have not tested this code on Windows though — this is just my “best guess” on how it should be handled in Windows. User beware.\n\n# grab the base subdirectories for the needle paths, initialize the # dictionary that will map the image hash to corresponding image, # hashes, then start the timer BASE_PATHS = set([p.split(os.path.sep)[-2] for p in needlePaths]) haystack = {} start = time.time()\n\nLine 43 grabs the subdirectory names inside needlePaths — I need these subdirectory names to determine which folders have already been added to the haystack and which subdirectories I still need to examine.\n\nLine 44 then initializes haystack , a dictionary that will map image hashes to respective filenames.\n\nWe are now ready to extract image hashes for our haystackPaths :\n\n# loop over the haystack paths for p in haystackPaths: # load the image from disk image = cv2.imread(p) # if the image is None then we could not load it from disk (so # skip it) if image is None: continue # convert the image to grayscale and compute the hash image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) imageHash = dhash(image) # update the haystack dictionary l = haystack.get(imageHash, []) l.append(p) haystack[imageHash] = l\n\nOn Line 48 we are loop over all image paths in haystackPaths .\n\nFor each image we load it from disk (Line 50) and check to see if the image is None (Lines 54 and 55). If the image is None then the image could not be properly read from disk, likely due to an issue with the image encoding (a phenomenon you can read more about here), so we skip the image.\n\nLines 58 and 59 compute the imageHash while Lines 62-64 maintain a list of file paths that map to the same hash value.\n\nThe next code block shows a bit of diagnostic information on the hashing process:\n\n# show timing for hashing haystack images, then start computing the # hashes for needle images print(\"[INFO] processed {} images in {:.2f} seconds\".format( len(haystack), time.time() - start)) print(\"[INFO] computing hashes for needles...\")\n\nWe can then move on to extracting the hash values from our needlePaths :\n\n# loop over the needle paths for p in needlePaths: # load the image from disk image = cv2.imread(p) # if the image is None then we could not load it from disk (so # skip it) if image is None: continue # convert the image to grayscale and compute the hash image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) imageHash = dhash(image) # grab all image paths that match the hash matchedPaths = haystack.get(imageHash, []) # loop over all matched paths for matchedPath in matchedPaths: # extract the subdirectory from the image path b = p.split(os.path.sep)[-2] # if the subdirectory exists in the base path for the needle # images, remove it if b in BASE_PATHS: BASE_PATHS.remove(b)\n\nThe general flow of this code block is near identical to the one above:\n\nWe load the image from disk (while ensuring it’s not None )\n\nConvert the image to grayscale\n\nAnd compute the image hash\n\nThe difference is that we are no longer storing the hash value in haystack .\n\nInstead, we now check the haystack dictionary to see if there are any image paths that have the same hash value (Line 87).\n\nIf there are images with the same hash value, then I know I have already manually examined this particular subdirectory of images and added them to iPhoto. Since I have already manually examined it, there is no need for me to examine it again; therefore, I can loop over all matchedPaths and remove them from BASE_PATHS (Lines 89-97).\n\nSimply put: all images + associated subdirectores in matchedPaths are already in my iPhotos album.\n\nOur final code block loops over all remaining subdirectories in BASE_PATHS and lets me know which ones I still need to manually investigate and add to iPhoto:\n\n# display directories to check print(\"[INFO] check the following directories...\") # loop over each subdirectory and display it for b in BASE_PATHS: print(\"[INFO] {}\".format(b))\n\nOur image hashing implementation is now complete!\n\nLet’s move on to applying our image hashing algorithm to solve my needle/haystack problem I have been trying to solve.\n\nImage hashing with OpenCV and Python results\n\nTo see our image hashing algorithm in action, scroll down to the “Downloads” section of this tutorial and then download the source code + example image dataset.\n\nI have not included my personal iPhotos dataset here, as:\n\nThe entire dataset is ~39GB\n\nThere are many personal photos that I do not wish to share\n\nInstead, I have included sample images from the UKBench dataset that you can play with.\n\nTo determine which directories (i.e., “needles”) I still need to examine and later add to the “haystack”, I opened up a terminal and executed the following command:\n\n$ python hash_and_search.py --haystack haystack --needles needles [INFO] computing hashes for haystack... [INFO] processed 7466 images in 1111.63 seconds [INFO] computing hashes for needles... [INFO] check the following directories... [INFO] MY_PIX [INFO] 12-25-2006 part 1\n\nAs you can see from the output, the entire hashing and searching process took ~18 minutes.\n\nI then have a nice clear output of the directories I still need to examine: out of the 14 potential subdirectories, I still need to sort through two of them, MY_PIX and 12-25-2006 part 1 , respectively.\n\nBy going through these subdirectories I can complete my photo organizing project.\n\nAs I mentioned above, I am not including my personal photo archive in the “Downloads” of this post. If you execute the hash_and_search.py script on the examples I provide in the Downloads, your results will look like this:\n\n$ python hash_and_search.py --haystack haystack --needles needles [INFO] computing hashes for haystack... [INFO] processed 1000 images in 7.43 seconds [INFO] computing hashes for needles... [INFO] check the following directories... [INFO] PIX [INFO] December2014\n\nWhich effectively demonstrates the script accomplishing the same task.\n\nWhere can I learn more about image hashing?\n\nIf you’re interested in learning more about image hashing, I would suggest you first take a look at the imagehashing GitHub repo, a popular (PIL-based) Python library used for perceptual image hashing. This library includes a number of image hashing implementations, including difference hashing, average hashing, and others.\n\nFrom there, take a look at the blog of Tham Ngap Wei (a PyImageSearch Gurus member) who has written extensively about image hashing and even contributed a C++ image hashing module to the OpenCV-contrib library.\n\nSummary\n\nIn today’s blog post we discussed image hashing, perceptual hashing, and how these algorithms can be used to (quickly) determine if the visual contents of an image are identical or similar.\n\nFrom there, we implemented difference hashing, a common perceptual hashing algorithm that is (1) extremely fast while (2) being quite accurate.\n\nAfter implementing difference hashing in Python we applied it to a real-world dataset to solve an actual problem I was working on.\n\nI hope you enjoyed today’s post!"
    }
}