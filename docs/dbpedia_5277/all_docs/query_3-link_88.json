{
    "id": "dbpedia_5277_3",
    "rank": 88,
    "data": {
        "url": "https://www.linkedin.com/pulse/ai-all-why-disability-inclusion-vital-future-artificial-intelligence-z59ne",
        "read_more_link": "",
        "language": "en",
        "title": "AI for All: Why disability inclusion is vital to the future of artificial intelligence.",
        "top_image": "https://media.licdn.com/dms/image/D4E12AQEBwi2lNyk34Q/article-cover_image-shrink_720_1280/0/1715856889519?e=2147483647&v=beta&t=BuWijTRe2bltT4r8t7xziw1LD-iPImE9x_ss7hPbkJY",
        "meta_img": "https://media.licdn.com/dms/image/D4E12AQEBwi2lNyk34Q/article-cover_image-shrink_720_1280/0/1715856889519?e=2147483647&v=beta&t=BuWijTRe2bltT4r8t7xziw1LD-iPImE9x_ss7hPbkJY",
        "images": [
            "https://media.licdn.com/dms/image/D4E12AQEBwi2lNyk34Q/article-cover_image-shrink_720_1280/0/1715856889519?e=2147483647&v=beta&t=BuWijTRe2bltT4r8t7xziw1LD-iPImE9x_ss7hPbkJY"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Scope"
        ],
        "publish_date": "2024-05-16T10:44:41+00:00",
        "summary": "",
        "meta_description": "Disabled people are embracing artificial intelligence (AI) in many parts of their lives. From education and employment to communication and navigation.",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/pulse/ai-all-why-disability-inclusion-vital-future-artificial-intelligence-z59ne",
        "text": "Disabled people are embracing artificial intelligence (AI) in many parts of their lives. From education and employment to communication and navigation.\n\nMany AI tools weren't made specifically with disabled people in mind, or as assistive technology. But disabled people often use them to make the world more accessible and increase autonomy.\n\nFor example, image recognition can describe a photo or an object to someone with a visual impairment. Smart home solutions can introduce automation to everyday routines. Natural language processing can help people understand documents by summarising or communicate by suggesting responses to emails.\n\nThese tools are starting to address some of the barriers that disabled people face, especially in the digital landscape. In theory, they can create a much fairer world. Particularly as the technology continues to develop and becomes easier to access.\n\nBut for that to happen, AI must be built on a foundation of fairness.\n\nHow is inaccessibility and inequality built into AI from the outset?\n\nData from disabled people’s experiences and usage is often seen as an outlier. So it’s then left out entirely and not used for training AI systems.\n\nFor example, people with speech conditions have found that most voice-activated technology doesn’t work for them. This is because the technology wasn’t trained on voices like theirs. Because they aren't considered a 'normal' scenario.\n\nAnd people with facial differences can find that facial-recognition technology doesn’t work for them either - for the same reason.\n\nIf the data being used to train AI excludes disabled people, the result can't be inclusive.\n\nAI bias is the underlying prejudice in the data that is used to create algorithms. Algorithms themselves don’t create biases. But they can sustain prejudices and inequalities that already exist in society. We've already seen too many examples of AI systems that demonstrate racial, gender and aged-based bias, too.\n\nThese biases can enter at any point of the development process. Whether through human developer bias, a lack of data, and even organisational practices.\n\nCase study\n\nAmazon experienced this in 2015. They realised their hiring algorithm was biased against women. This was because it was trained on applications submitted over the previous decade, and much fewer of these were from women. As a result, it was inadvertently trained to favour applications from men.\n\nConsiderations for removing bias from AI.\n\nCreating unbiased algorithms is difficult. And that’s because it means using unbiased training data and relying on unbiased human involvement. But there are ways to minimise the risk. To start:\n\nWe need to be proactive in ensuring training data is non-discriminatory and representative of everyone.\n\nWe should cultivate diverse teams and workplaces to develop our AI work.\n\nWe must regularly test and audit our systems while remaining transparent about what we’re learning.\n\nAnd it cannot be an afterthought, as accessibility often is.\n\nIn the end, it's quite a simple concept to keep in mind. If AI is only trained on data from an ableist and inaccessible society, how can we expect a fair result?\n\nWe can’t.\n\nThat’s why disabled people need to be involved from beginning to end. We need to be involved in research, development, accountability, and testing. And certainly, discussions around AI fairness and ethics.\n\nAnd we must make sure this happens before we fully integrate AI into critical tasks. For example, making appointments, accessing education, and applying for jobs. We risk excluding disabled people, among other groups, if these technologies can't be used fairly by everyone.\n\nDeveloping AI with disabled people in mind.\n\nSome AI tools were created with disabled people in mind from the very beginning. And we can learn a lot from them.\n\nBe My AI, from Be My Eyes and powered by GPT-4, is described as a 'virtual volunteer'. It's currently being beta tested by people with visual impairments worldwide.\n\nIt's quick and simple to use, and reduces the need for human volunteers. You simply open the app, take a picture, and you'll be provided with a detailed description of the image. You can then ask questions about the image to help build further context and clarity. People are already using it to choose outfits, organise their homes, and identify objects.\n\nBut importantly, it doesn't entirely replace human support. Human volunteers are still available to verify the AI results, or to approach directly. It gives disabled people a choice and the autonomy to do what works best for them. And that ability to choose makes it more accessible.\n\nHow is Scope using AI?\n\nWe are still at the beginning of our journey with AI. And we're taking time to learn. But we’re making some exciting progress. We are:\n\nestablishing an AI forum to co-produce our use of AI with disabled people directly\n\nexploring ways to use generative AI and automation to improve our impact and effectiveness\n\nplanning to conduct research into the opportunities and risks of AI for disabled people\n\nworking with experts like IBM and Deloitte to develop AI processes that work in the best way for disabled people.\n\nOverall, we’re enthusiastic about the potential positive impact AI could have not just in our own work but in the lives of disabled people.\n\nAnd we’ll continue to share updates as we take this journey.\n\nWe believe in a world that is accessible and free of barriers. And while technology can’t solve everything, it can certainly go a long way if used considerately."
    }
}