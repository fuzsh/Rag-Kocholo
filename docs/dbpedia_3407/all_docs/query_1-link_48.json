{
    "id": "dbpedia_3407_1",
    "rank": 48,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6715517/",
        "read_more_link": "",
        "language": "en",
        "title": "Quantification of uncertainty in peptide-MHC binding prediction improves high-affinity peptide selection for therapeutic design",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-nihpa.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6715517/bin/nihms-1530707-f0001.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6715517/bin/nihms-1530707-f0002.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6715517/bin/nihms-1530707-f0003.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6715517/bin/nihms-1530707-f0004.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6715517/bin/nihms-1530707-f0005.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Haoyang Zeng",
            "David K. Gifford"
        ],
        "publish_date": "2019-08-28T00:00:00",
        "summary": "",
        "meta_description": "The computational identification of peptides that can bind the major histocompatibility complex (MHC) with high affinity is an essential step in developing personal immunotherapies and vaccines. We introduce PUFFIN, a deep residual network-based computational ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6715517/",
        "text": "Introduction\n\nThe major histocompatibility complex (MHC) is a set of cell surface proteins that are crucial for the extra-celluar display of peptides for surveillance by the immune system(Castellino et al., 1997; Janeway Jr et al., 2001). Peptides displayed by MHC molecules are either synthesized in the cell (class I MHC) or internalized from the extracellular medium (class II MHC). T cells routinely surveil the peptides presented on cell surfaces and trigger an immune response upon recognition of non-self peptides that arise from foreign antigens, cell infection, or mutated self-proteins. The selective binding of peptides to MHC molecules plays an essential role in individual-specific peptide presentation to the immune system. Understanding what peptides will be displayed given a disease state is crucial information for developing peptide-based vaccines and therapeutics(Kreiter et al., 2015; Ott et al., 2017; 2017; Verdegaal et al., 2016).\n\nMHC molecules are encoded by highly polymorphic gene families(Jin and Wang, 2003; Robinson et al., 2015; Williams, 2001). Each MHC genotype has its own specificity for peptide presentation. Moreover, the length of the peptides that bind to an MHC molecule varies. Class I MHC presented peptides are typically 8 to 11 amino acids(Lundegaard et al., 2008), while class II MHC presented peptides are typically 13 to 25 amino acids(Chicz et al., 1992). In class II MHC molecules a core 9-amino-acid sequence interacts with the class II MHC groove while the peptide regions outside of the binding have a secondary influence on binding affinity(Arnold et al., 2002; Holland et al., 2013).\n\nMachine learning models for MHC-peptide affinity are essential for certain therapeutic applications including predicting cancer-specific peptides that will be presented by the MHC on tumor cells and engineering peptide vaccines(Kreiter et al., 2015; Ott et al., 2017; 2017). The task of these machine learning models is to input a peptide and an MHC sequence and output the binding affinity of the peptide to the MHC molecule. Two widely used methods, NetMHCpan(Nielsen and Andreatta, 2016) (for class I MHC) and NetMHCIIpan(Jensen et al., 2018) (for class II MHC), use a one-layer fully-connected neural network to iteratively identify a peptide’s 9-mer binding core and predict its binding affinity(Nielsen and Andreatta, 2017). Other recent methods for class I MHC binding use shallow convolutional or recurrent neural networks(Bhattacharya et al., 2017; Han and Kim, 2017; O’Donnell et al., 2018; Vang and Xie, 2017).\n\nAccurate machine learning models for predicting MHC-peptide affinity depend upon sufficient training data to allow them to generalize to unseen inputs. At present model generalization is constrained by the limited size of current training datasets. The largest database of MHC-peptide binding, Immune Epitope Database and Analysis Resource (IEDB)(Vita et al., 2018), has affinity data for over 80 human and mouse alleles for class II MHC. However, only six MHC alleles have more than 5000 peptide examples, and the most abundant allele has only 10,000 examples, a tiny fraction of all possible peptides of similar lengths. Moreover, IEDB entries harbor strong measurement noise that arises from batch effects and protocol differences since they are curated from published reports from disparate laboratories. For a given input, the sufficiency of relevant training data and the level of measurement noise can be quantified by proper uncertainty metrics associated with each computational prediction (Kendall and Gal, 2017). Despite the promising results of existing machine learning methods, they do not provide an uncertainty metric for their point estimate of MHC-peptide affinity.\n\nHere we introduce PUFFIN (Prediction of Uncertainty in MHC-peptide aFFInity using residual Networks), a method for predicting MHC-peptide binding that outputs both the expected affinity of an input MHC-peptide pair as well as the uncertainty of the model about its prediction. PUFFIN has the dual advantage of providing more accurate estimates of both class I and class II MHC-peptide binding than previous methods as well as uncertainty metrics with each prediction. Our prediction uncertainty metrics characterize the uncertainty that results from inherent observational noise (aleatoric uncertainty) and bounded knowledge about model selection (epistemic uncertainty). PUFFIN’s uncertainty metrics allows for the principled comparison of alternative peptide vaccine formulations, and permits peptides to be selected based upon binding likelihood, the probability that a peptide binds to a given MHC molecule at a specified affinity threshold. Compared to the conventional approach that relies on point estimates of affinity, our proposed approach reduces false positives in high-affinity peptide design.\n\nResults\n\nModeling both epistemic and aleatoric uncertainty\n\nPUFFIN provides distinct estimates of model uncertainty (epistemic) and inherent observational uncertainty (aleatoric). Epistemic uncertainty refers to the uncertainty that arises from the lack of model knowledge and can be reduced with additional training data(Kendall and Gal, 2017). Given a fixed-size dataset, alternative models might exist to explain the observed examples well. Epistemic uncertainty describes the uncertainty that one has about the true model that generates the data, and is higher for inputs where relevant training observations are lacking. Aleatoric uncertainty refers to the uncertainty that results from the inherent noise in observations and thus cannot be reduced with more training examples(Kendall and Gal, 2017). Aleatoric uncertainty can be further categorized into homoscedastic and heteroscedastic uncertainty. Heteroscedastic uncertainty is observational noise that depends on the input value, while homoscedastic uncertainty remains constant for all inputs and thus can be considered as a special and simpler version of heteroscedastic uncertainty.\n\nWe model both the epistemic and heteroscedastic aleatoric uncertainty in MHC-peptide binding affinity using a unified framework. We model the affinity of an MHC-peptide pair as a random sample from a probability distribution (beta distribution for class I, normal distribution for class II, chosen by empirical performance in cross-validation) where the distribution’s parameters are predicted from the input MHC and peptide sequence using a deep residual convolutional network(He et al., 2016) ( , Methods). The dispersion of the probability distribution characterizes the aleatoric uncertainty specific to the corresponding input. Epistemic uncertainty reflects the existence of alternatives models that explain the observed data. The most established way to obtain epistemic uncertainty is through the posterior distribution of model parameters in a Bayesian learning framework (Kendall and Gal, 2017). Certain model selection procedures such as Stability Selection(Meinshausen and Bühlmann, 2010) also implicitly choose the model with the highest posterior probability, but the optimal model chosen from such procedures can’t provide uncertainty metrics associated with a prediction. Ensemble models have been established as an Bayesian approximation and are more scalable compared to Bayesian neural networks(Lakshminarayanan et al., 2017). Thus, we characterize epistemic uncertainty by the predictive variance across an ensemble of neural network models trained on different training-validation splits and with different random initializations (Methods).\n\nPUFFIN’s affinity point estimates demonstrates state-of-the-art accuracy\n\nWe first show that PUFFIN’s mean estimates of affinity outperform previous state-of-the-art models for MHC-peptide affinity prediction. We average the predicted means from all PUFFIN ensemble members to produce PUFFIN’s mean estimate prediction and compare it with existing methods.\n\nFor class II MHC, we trained and evaluated PUFFIN and NetMHCIIpan on binding affinity data as per Jensen et al.(Jensen et al., 2018). Jensen et al. curated class II MHC-peptide affinity data from IEDB and split it into five cross-validation folds such that different folds do not share 9-mer peptide sequences(Jensen et al., 2018; Nielsen et al., 2007). We made predictions for each fold using a model trained the other four folds so that the performance was evaluated on held out examples. The re-training of NetMHCIIpan model on this dataset is enabled by a standalone training platform published by Nielsen et al(Nielsen and Andreatta, 2017). We evaluated the prediction performance using auROC, F1 score, mean-squared-error (MSE),R2, Spearman correlation, and Point-Biserial correlation. For auROC, F1 score and Point-Biserial correlation, positive examples were defined as the ones with a binding affinity stronger than 500 nM as used in the literature(Bhattacharya et al., 2017; Jensen et al., 2018; Nielsen and Andreatta, 2016). We found that PUFFIN’s mean estimate outperforms NetMHCIIpan in all metrics considered when evaluated on all MHC-peptide pairs ( ). Combining the predictions from PUFFIN and NetMHCIIpan yields further performance improvement, suggesting complimentary features might be captured by the two approaches. Furthermore, when evaluated on each MHC allele separately, PUFFIN has a lower mean-squared-error than NetMHCIIpan for 44 of the 55 MHC alleles considered ( ).\n\nTable 1.\n\nauROCFI ScoreMean Squared ErrorR2Spearman\n\nCorrelationPoint-Biserial CorrelationNetMHCIIpan0.87270.74150.030560.55290.73670.6301PUFFIN-mean0.87740.75040.029560.56790.74500.6381PUFFIN-BL0.8795N/AN/AN/A0.74240.6561NetMHCIIpan + PUFFIN-mean0.88080.75160.029040.57510.75160.6427\n\nFor class I MHC, the Nielsen et al(Nielsen and Andreatta, 2017) training platform is not able to fully reproduce the same training procedure as published for NetMHCpan(Nielsen and Andreatta, 2016). Bhattacharya et al.(Bhattacharya et al., 2017) provided a benchmark dataset on which several recent computational methods for class I MHC-peptide binding were evaluated and their perforamnce was reported ( ). Trained and tested on the same benchmark, PUFFIN outperforms all the competing methods including NetMHCpan(Nielsen and Andreatta, 2016), MHCflurry(O’Donnell et al., 2018), and MHCNugget(Bhattacharya et al., 2017) in auROC and Kendall’s tau and shows competitive performance in F1 score ( ).\n\nTable 2.\n\nModelauROCKendall’s tauF1 ScorePoint-Biserial CorrelationMHCnuggets0.9310.5890.810-NetMHCpan0.9330.5840.803-MHCflurry0.9330.5870.785-PUFFIN-mean0.9350.5990.8020.756PUFFIN-BL0.9360.573N/A0.767\n\nUncertainty accurately reflects the predictive error in affinity prediction\n\nWe next show that uncertainty estimates from PUFFIN provide a way to gauge the predictive error on unseen examples. Uncertainty characterizes the lack of confidence in a prediction caused by either the lack of model selection and training data (epistemic uncertainty) or observation noise (aleatoric uncertainty) near the queried data point. For reliable uncertainty estimates, the level of confidence should match the predictive accuracy on a held-out dataset and indicate how much one can trust a prediction(Lakshminarayanan et al., 2017).\n\nTo examine the quality of PUFFIN’s uncertainty estimation, we predicted the affinity of all the examples in IEDB in the same cross-validation manner as described above. For each MHC-peptide pair, the mean and variance of the affinity distribution predicted by each of the networks in PUFFIN’s ensemble were calculated. Across all networks in PUFFIN’s ensemble, the average of the affinity variances was used to quantify the aleatoric uncertainty, and the variance of the affinity means was used to quantify the epistemic uncertainty. For each type of uncertainty, we binned the held-out test examples according to their uncertainty quantiles and calculated the mean-squared-error in each bin. We observed that both PUFFIN’s epistemic and aleatoric uncertainty highly correlate with the prediction error, and predictions made with lower uncertainty are more accurate ( ). This faithful stratification of predictive performance on held-out observations demonstrates that PUFFIN’s uncertainty estimations reflect its predictive confidence and provides useful guidance on how to utilize its computational predictions.\n\nEpistemic uncertainty identifies sequences foreign to the model\n\nWe next show that PUFFIN identifies sequences foreign to the model by labeling them with high epistemic uncertainty. Here we assume that reliable epistemic uncertainty should increase for examples that are distant from a model’s training examples to reflect the absence of relevant training data.\n\nWe first created a systematic survey of PUFFIN’s predicted epistemic uncertainty by characterizing examples at varying edit distances from a model’s training examples. Given a training set and a test set, we randomly sampled from the training set 10,000 MHC-peptide pairs where the peptides were at least 10 amino acids long. These peptides were used as “seed” sequences with known affinity to their respective MHC. We then created three sets of derived peptide sequences that are respectively 1, 5 or 10 amino acids different from the seeds. Specifically, for each seed, 10 sequences with the desired number of mutations (1 or 5 or 10) were randomly created. We assume that the designed distance to a seed approximates the distance to the whole training set when the sequence space is large. We focused on class II MHC as its longer input peptide sequences result in a larger sequence space than class I MHC.\n\nWe applied PUFFIN to predict the binding affinity of the seed sequences as well as the three sets of derived sequences using the five-fold cross-validation data from Jensen et al. Each cross-validation fold yields a distinctive split of training and test set, on which the seeds and three sets of derived sequences were generated as described above and evaluated on a PUFFIN model trained on the corresponding training set. We calculated the median epistemic and aleatoric uncertainty for all sequences in each set. To account for differences among the seeds, we also adopted an alternative metric: for mutation sequences derived from the same seed, we computed the median uncertainty as a representative and reported the median of representative uncertainty across all seeds. Under both metrics, we observed that sequences with increasing distance from seeds result in as much as 35% more epistemic uncertainty ( ), showing that PUFFIN’s epistemic uncertainty characterizes the lack of relevant training examples in the neighborhood of an input. Meanwhile, we found that aleatoric uncertainty remains largely unchanged as expected. These results support our hypothesis that the epistemic and aleatoric uncertainty estimates from PUFFIN respectively correspond to the uncertainty that results from a lack of model knowledge and from observational noise.\n\nUncertainty estimation improves precision in high-affinity peptide design\n\nIn the design of high-affinity peptides for therapeutic purposes, the number of distinct peptides administered is constrained(Kreiter et al., 2015; Ott et al., 2017; 2017) and reducing the false selection of peptides is essential to achieve high efficacy with a minimal dosage. False positives arise from erroneous model predictions of high peptide affinity. False predictions are not possible to detect when models do not provide uncertainty estimates. Unlike the contemporary models, PUFFIN computes the binding likelihood of a peptide, defined as the probability the peptide binds to a given MHC allele at a specified affinity threshold (Methods). We found that prioritizing peptides based on binding likelihood leads to improved precision in high-affinity peptide design.\n\nWe first hypothesized that binding likelihood at an affinity threshold of 500 nM enables a more accurate prediction of observed binding status defined by a 500 nM affinity threshold. For each allele in the held-out dataset, we scored a peptide by both the predicted affinity and the likelihood that the observed affinity is at least as strong as 500 nM under PUFFIN’s probabilistic model. Point-Biserial correlations between observed binding and our two predicted metrics, binding affinity and binding likelihood, were calculated respectively for each MHC allele. For both class I and class II MHC, we found that observed binding correlates better with binding likelihood than the predicted mean affinity for all MHC alleles with more than 2000 examples ( , 32/32 for class I MHC and 28/28 for class II MHC) and for the majority of all MHC alleles examined (94/113 for class I MHC, and 51/55 for class II MHC; Methods). Across all MHC alleles, binding likelihood shows a statistically significant improvement over predicted mean affinity in correlation (Wilcoxon one-sided signed rank test; p=1.2e-09 for class I MHC; p=1.2e-08 for class II MHC). When we evaluated PUFFIN on the Bhattacharya et al.(Bhattacharya et al., 2017) benchmark data as described above, we also observed that PUFFIN’s binding likelihood further improves the auROC and Point-Biserial correlation ( , ). As expected, we didn’t observe a stronger Spearman correlation or Kendall’s Tau which are metrics that quantify the fit to affinity values rather than the discrimination of binding status with respect to an affinity cutoff.\n\nWe next hypothesized that binding likelihood would lead to more accurate identificationof MHC-binding peptides. This is because PUFFIN makes it possible to evaluate the reliabilityof computationally predicted affinities and select peptides that are predicted to bind with high confidence. For each MHC allele, we identified the peptides from a held-out candidate set with a PUFFIN predicted binding likelihood above 95%. For these peptides, failing to bind to the target MHC molecule is unlikely under PUFFIN’s probabilistic model. Only MHC alleles with over100 training peptides were considered in view of the noise present in affinity measurements. We also identified the same number of peptides with the highest predicted mean affinity for each MHC allele to compare with a conventional strategy based solely on high-affinity peptides. For class I MHC, we observed that for 80% of the 15 MHC alleles considered, the percentage of true binders (stronger than 500 nM) among the peptides identified by PUFFIN is higher than (for 46.7% of the alleles) or equal to (for 33.3% of the alleles) that for the peptides with the highest affinity prediction. For class II MHC, the peptides predicted to bind by PUFFIN with high-confidenceare more likely (for 60.8% of the alleles) or equal likely (for 17.3% of the alleles) to bind than peptides predicted with the highest affinity for a total of 78.1% of the 23 alleles considered ( ).\n\nPublished peptide vaccine formulations can be improved by uncertainty metrics\n\nWe next applied PUFFIN’s binding likelihood estimates to examine the peptide formulation of neoantigen vaccines for melanoma. Ott et al.(Ott et al., 2017) designed personal neoantigen vaccines to induce tumor-specific T-cell responses to melanoma for six patients. Somatic mutations were identified from whole exon sequencing data from tumor and germline cells. NetMHCpan’s computational predictions were used to rank mutation-spanning peptides by the binding affinity to patient-specific MHC class I molecules. We applied PUFFIN to examine the binding likelihood (target affinity of 500 nM) of each peptide in the vaccine to the patient-specific MHC class I allele. We observed that the median binding likelihood of the peptides in the published vaccines range from 51.7% to 73.6%, with certain peptides having a binding likelihood below 20% for five of the six vaccines ( ). The low binding likelihoods we observed suggested room for improvement in the prioritization of MHC-binding peptides. For each patient, we examined the binding likelihood between all 9-mer peptides that span the somatic mutations and the MHC alleles of the same patient. The median binding likelihoods of mutation-spanning peptides for each patient are low, ranging from 9 × 10−7 to 0.0022 ( ). We found that with the same peptide count an alternative set of peptides exists with significantly higher binding likelihoods than in the published vaccines ( ). The proposed set of peptides could potentially lead to an improved rate of T cell response compared to the existing vaccine candidates that were selected by affinity point estimates predicted by conventional computational methods. This result suggests that uncertainty will be a useful metric for peptide vaccine formulation, but further testing in the context of additional constraints in a clinical setting will be necessary to confirm the utility of uncertainty for vaccine formulation.\n\nIEDB power by allele and MHC class\n\nWe next applied PUFFIN to characterize the power of the IEDB datasets to predict peptide-MHC binding affinity. As a database curated from publications in which different experimental protocols and conditions were employed, the IEDB datasets are inherently noisy.\n\nMoreover, the number of available examples for different MHC alleles is highly skewed towards a few common alleles, leading to variability in the predictive power of computational models across MHC alleles. Thus, we used PUFFIN to examine how the epistemic and aleatoric uncertainty changes across MHC alleles.\n\nWe first show that binding affinity data for class II MHC is more heterogeneous than class I ( ). For class I MHC, we found the correlation between the median aleatoric uncertainty and the dataset size is not statistically significant (Pearson r=−0.11, p=0.26). A stronger and statistically significant correlation was observed for class II (Pearson r=0.3, p=0.027), indicating that examples for the alleles with more data tend to harbor higher inherent noise. We highlight the class II MHC alleles with the top median aleatoric uncertainty in Table S1. We note that certain alleles, such as HLA-DQA10102-DQB10501, H-2-IAd, and HLA-DQA10201-DQB10301, have high aleatoric uncertainty with small datasets.\n\nWe found that a larger training set size improves prediction confidence for class I MHC but not for class II MHC ( ). For class I MHC, we found a strong negative correlation between the median epistemic uncertainty and the dataset size (Pearson r=−0.38, p=3.4e-05), suggesting that the prediction confidence on the held-out test set increases with the size of the training set. In contrast, no correlation was observed for class II (Pearson r =−0.065, p=0.64). This difference in the correlation to dataset size could result from the fact that peptides that bind to class II MHC span a much greater sequence space due to a larger range of peptide length. Thus, significantly more training data are required to sufficiently fill the sequence space and thus lead to a decrease in epistemic uncertainty for predictions made for held-out examples."
    }
}