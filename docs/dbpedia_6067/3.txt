Telling Alexa to play “Schrodinger’s Cat” by Tears for Fears. Asking Siri for directions to a quantum-themed bar or restaurant. A smartphone autocorrecting a word in a text message.

These are everyday applications of natural language processing – NLP for short – a field of artificial intelligence that focuses on training computers to understand words and conversations, which is something humans innately do.

NLP technologies have advanced rapidly in recent years with the help of increasingly powerful computing clusters that can run language models that examine reams of text and count how often certain words appear. These models train devices to retrieve information, annotate text, translate words from one language to another, answer questions, and perform other tasks.

The next step is to “teach” computers to infer meaning, understand nuance, and grasp the context of conversations. To do that, however, requires massive computational resources and multiple algorithms or data structures.

A United Kingdom-based quantum computing company believes the answer lies with qubits, superposition, and entanglement.

Cambridge Quantum recently released lambeq, a new open-source software development toolkit, that enables researchers to convert sentences into quantum circuits that can be run on quantum computers. It is the first toolkit developed specifically for quantum natural language processing – or QNLP - and was tested on our System Model H1 technology before it was released.

The software takes the text, parses it, and then uses mathematical linguistics to differentiate between a verb, noun, preposition, adjectives, etc., and label them to according to the relationships between words. This returns a connectivity diagram between the words in the text, which is then manifested as a quantum circuit ready to be run on a quantum processor.

Given a handmade dataset designed for proof-of-concept of sentences with a label denoting “topic”, Cambridge Quantum researchers trained the model on 70 sentences and tested it on 30 on the System Model H1. It was able to classify sentences into the correct topic class with 97 percent accuracy.

“We deem that a success,” said Konstantinos Meichanetzidis, a member of the CQ team. “We found that our software works well with the Honeywell technology and were able to benchmark the performance of this quantum device.”

The lambeq project also represented a first for Honeywell Quantum Solutions. It was the first QNLP problem run on the System Model H1 hardware.

“We are really excited to be a part of this work and contribute to the development of this important toolkit,” said Tony Uttley, president of Honeywell Quantum Solutions. “Applications like this help us test our system and understand how well it performs solving different problems.”

(Honeywell Quantum Solutions and Cambridge Quantum have a long-standing history of partnering together on research and other projects that benefit end-customers. The two entities announced in June they are seeking regulatory approval to combine to form a new company.)

Why QNLP?

For humans, decoding conversations to understand meaning is a complex process. We infer meaning through tone of voice, body language, context, location, and other factors. For computers, which do not rely on heuristics, decoding language is even more complex.

The only way to create some sort of “meaning-aware” NLP is to explicitly encode compositional, semantic sentence structure into language models. To do this on a classical computer, however, requires massive computational resources, which are costly, and would likely still take months to process.

Quantum computers, on the other hand, run calculations and crunch data very differently.

They harness unique properties of quantum physics, specifically superposition and entanglement, to store and process information. Because of that, these systems can examine problems with multiple states and evaluate a large space of possible answers simultaneously.

What this means in terms of NLP is that quantum computers can use quantum theory’s structure to faithfully encode the relationship between words, in terms of the structure of quantum circuits. (lambeq uses the Distributional Compositional Categorical – or DisCoCat – model to do this, which aims to combine symbolic structural methods with distributional probabilistic encodings of meaning.)

This compositional way of endowing grammatical structure to the quantum model may in the future be helpful for validating and verifying the model's performance, as well as provide insight about the inner workings of the model in regulated sectors such as finance, legal, and medicine, where transparency is critical.

Built upon previous work

The Cambridge Quantum team has long explored how quantum computing can advance natural language processing and published extensively on the topic.

In December 2020, researchers released two foundational papers that demonstrated that QNLP is inherently meaning-aware and can successfully interpret questions and respond.

Earlier this year, the team performed the first NLP experiment conducted on a quantum computer by converting more than 100 sentences into quantum circuits using an IBM technology. Researchers successfully trained two NLP models to classify words in sentences.

The release of lambeq and the testing of the open-source toolkit on our System Model H1 represents the next steps in QNLP innovation.

“Our team has been involved in foundational work that explores how quantum computers can be used to solve some of the most intractable problems in artificial intelligence,” said Bob Coecke, Cambridge Quantum’s chief scientist.

Coecke added: “In various papers published over the course of the past year,we have not only provided details on how quantum computers can enhance NLP but also demonstrated that QNLP is ‘quantum native,’ meaning the compositional structure governing language is mathematically the same as that governing quantum systems. This will ultimately move the world away from the current paradigm of AI that relies on brute force techniques that are opaque and approximate.”