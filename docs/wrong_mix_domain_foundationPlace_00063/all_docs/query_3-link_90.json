{
    "id": "wrong_mix_domain_foundationPlace_00063_3",
    "rank": 90,
    "data": {
        "url": "https://github.com/google-research/timesfm",
        "read_more_link": "",
        "language": "en",
        "title": "research/timesfm: TimesFM (Time Series Foundation Model) is a pretrained time",
        "top_image": "https://opengraph.githubassets.com/28902e40dd5f11e699b1c3b138af37e56539f2f69b0f83cead52bf3fae99647a/google-research/timesfm",
        "meta_img": "https://opengraph.githubassets.com/28902e40dd5f11e699b1c3b138af37e56539f2f69b0f83cead52bf3fae99647a/google-research/timesfm",
        "images": [
            "https://avatars.githubusercontent.com/u/8039264?s=64&v=4",
            "https://avatars.githubusercontent.com/u/5073569?s=64&v=4",
            "https://avatars.githubusercontent.com/u/9588843?s=64&v=4",
            "https://avatars.githubusercontent.com/u/8100?s=64&v=4",
            "https://avatars.githubusercontent.com/u/25877761?s=64&v=4",
            "https://avatars.githubusercontent.com/u/90601662?s=64&v=4",
            "https://avatars.githubusercontent.com/u/133781726?s=64&v=4",
            "https://avatars.githubusercontent.com/u/423552?s=64&v=4",
            "https://avatars.githubusercontent.com/u/5969910?s=64&v=4"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "google-research"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting. - google-research/timesfm",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/google-research/timesfm",
        "text": "TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.\n\nPaper: A decoder-only foundation model for time-series forecasting, to appear in ICML 2024.\n\nGoogle Research blog\n\nHugging Face checkpoint repo\n\nThis repo contains the code to load public TimesFM checkpoints and run model inference. Please visit our Hugging Face checkpoint repo to download model checkpoints.\n\nThis is not an officially supported Google product.\n\nWe recommend at least 16GB RAM to load TimesFM dependencies.\n\nUpdate - July 15, 2024\n\nTo install TimesFM, you can now simply do: pip install timesfm.\n\nLaunched finetuning support that lets you finetune the weights of the pretrained TimesFM model on your own data.\n\nLaunched ~zero-shot covariate support with external regressors. More details here.\n\ntimesfm-1.0-200m is the first open model checkpoint:\n\nIt performs univariate time series forecasting for context lengths up to 512 timepoints and any horizon lengths, with an optional frequency indicator.\n\nIt focuses on point forecasts, and does not support probabilistic forecasts. We experimentally offer quantile heads but they have not been calibrated after pretraining.\n\nIt requires the context to be contiguous (i.e. no \"holes\"), and the context and the horizon to be of the same frequency.\n\nPlease refer to our result tables on the extended benchmarks and the long horizon benchmarks.\n\nPlease look into the README files in the respective benchmark directories within experiments/ for instructions for running TimesFM on the respective benchmarks.\n\nTo install the TimesFM as a package, you can run the following command without cloning this repo:\n\npip install timesfm\n\nFor calling TimesFM, We have two environment files. Inside timesfm, for GPU installation (assuming CUDA 12 has been setup), you can create a conda environment tfm_env from the base folder through:\n\nFor a CPU setup please use,\n\nto create the environment instead.\n\nFollow by\n\nto install the package.\n\nNote:\n\nRunning the provided benchmarks would require additional dependencies. Please use the environment files under experiments instead.\n\nThe dependency lingvo does not support ARM architectures, and the code is not working for machines with Apple silicon. We are aware of this issue and are working on a solution. Stay tuned.\n\nTo from the current repository/local version (like you would have previously done with pip -e .), you can run the command\n\nThis will install the environment in the local .venv folder (depends on the configuration) and matches the python command to the poetry environment. If this is not the case, you can use poetry run python to use the local environment.\n\nRunning the provided benchmarks would require additional dependencies. Please use the environment files under experiments instead.\n\nThe dependency lingvo does not support ARM architectures, and the code is not working for machines with Apple silicon. We are aware of this issue and are working on a solution. Stay tuned.\n\nThe package can be built using the command poetry build.\n\nTo build and publish it to PyPI, the command poetry publish can be used. This command will require the user to have the necessary permissions to publish to the PyPI repository.\n\nThen the base class can be loaded as,\n\nNote that the four parameters are fixed to load the 200m model\n\nThe context_len here can be set as the max context length of the model. It needs to be a multiplier of input_patch_len, i.e. a multiplier of 32. You can provide a shorter series to the tfm.forecast() function and the model will handle it. Currently, the model handles a max context length of 512, which can be increased in later releases. The input time series can have any context length. Padding / truncation will be handled by the inference code if needed.\n\nThe horizon length can be set to anything. We recommend setting it to the largest horizon length you would need in the forecasting tasks for your application. We generally recommend horizon length <= context length but it is not a requirement in the function call.\n\nbackend is one of \"cpu\", \"gpu\" or \"tpu\", case sensitive.\n\nWe provide APIs to forecast from either array inputs or pandas dataframe. Both forecast methods expect (1) the input time series contexts, (2) along with their frequencies. Please look at the documentation of the functions tfm.forecast() and tfm.forecast_on_df() for detailed instructions.\n\nIn particular regarding the frequency, TimesFM expects a categorical indicator valued in {0, 1, 2}:\n\n0 (default): high frequency, long horizon time series. We recommend using this for time series up to daily granularity.\n\n1: medium frequency time series. We recommend using this for weekly and monthly data.\n\n2: low frequency, short horizon time series. We recommend using this for anything beyond monthly, e.g. quarterly or yearly.\n\nThis categorical value should be directly provided with the array inputs. For dataframe inputs, we convert the conventional letter coding of frequencies to our expected categories, that\n\n0: T, MIN, H, D, B, U\n\n1: W, M\n\n2: Q, Y\n\nNotice you do NOT have to strictly follow our recommendation here. Although this is our setup during model training and we expect it to offer the best forecast result, you can also view the frequency input as a free parameter and modify it per your specific use case.\n\nExamples:\n\nArray inputs, with the frequencies set to low, medium and high respectively.\n\npandas dataframe, with the frequency set to \"M\" monthly.\n\nWe now have an external regressors library on top of TimesFM that can support static covariates as well as dynamic covariates available in the future. We have an usage example in notebooks/covariates.ipynb.\n\nLet's take a toy example of forecasting sales for a grocery store:\n\nTask: Given the observed the daily sales of this week (7 days), forecast the daily sales of next week (7 days).\n\nIn this example, besides the Daily_sales, we also have covariates Category, Base_price, Weekday, Has_promotion, Daily_temperature. Let's introduce some concepts:\n\nStatic covariates are covariates for each time series.\n\nIn our example, Category is a static categorical covariate,\n\nBase_price is a static numerical covariates.\n\nDynamic covariates are covaraites for each time stamps.\n\nDate / time related features can be usually treated as dynamic covariates.\n\nIn our example, Weekday and Has_promotion are dynamic categorical covariates.\n\nDaily_temperate is a dynamic numerical covariate.\n\nNotice: Here we make it mandatory that the dynamic covariates need to cover both the forecasting context and horizon. For example, all dynamic covariates in the example have 14 values: the first 7 correspond to the observed 7 days, and the last 7 correspond to the next 7 days.\n\nWe can now provide the past data of the two products along with static and dynamic covariates as a batch input to TimesFM and produce forecasts that take into the account the covariates. To learn more, check out the example in notebooks/covariates.ipynb.\n\nWe have provided an example of finetuning the model on a new dataset in notebooks/finetuning.ipynb.\n\nIf you would like to submit a PR please make sure that you use our formatting style. We use yapf for formatting with the following options,"
    }
}