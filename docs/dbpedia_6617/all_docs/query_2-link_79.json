{
    "id": "dbpedia_6617_2",
    "rank": 79,
    "data": {
        "url": "https://www.nngroup.com/articles/nps-ux/",
        "read_more_link": "",
        "language": "en",
        "title": "Net Promoter Score: What a Customer-Relations Metric Can Tell You About Your User Experience",
        "top_image": "https://media.nngroup.com/media/articles/opengraph_images/Opengraph_-_NPS.png",
        "meta_img": "https://media.nngroup.com/media/articles/opengraph_images/Opengraph_-_NPS.png",
        "images": [
            "https://media.nngroup.com/static/img/logo-817x388.png",
            "https://media.nngroup.com/media/people/photos/Therese-021.jpg.256x256_q75_autocrop_crop-smart_upscale.jpg",
            "https://media.nngroup.com/media/editor/2024/06/21/nps-article-equation-option-1.png",
            "https://media.nngroup.com/media/videos/thumbnails/Success_Rate_vs._Completion_Rate_Thumbnail.jpg.650x364_q75_autocrop_crop-smart_upscale.jpg",
            "https://media.nngroup.com/media/videos/thumbnails/Product_Instrumentation-_3_Benefits_Thumbnail.jpg.650x364_q75_autocrop_crop-smart_upscale.jpg",
            "https://media.nngroup.com/media/videos/thumbnails/Between_Subject_vs_Within_Subject_Study_Design_in_User_Research.jpg.650x364_q75_autocrop_crop-smart_upscale.jpg",
            "https://media.nngroup.com/static/img/icons/linkedin-icon.svg",
            "https://media.nngroup.com/static/img/icons/instagram-icon.svg",
            "https://media.nngroup.com/static/img/icons/youtube-icon.svg",
            "https://media.nngroup.com/static/img/icons/podcast-icon.svg",
            "https://media.nngroup.com/static/img/icons/twitter-icon.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "net promoter score",
            "NPS",
            "measuring",
            "measurement",
            "quantifiable",
            "customer-relations",
            "metric",
            "metrics"
        ],
        "tags": null,
        "authors": [
            "Therese Fessenden"
        ],
        "publish_date": "2024-06-21T17:00:00+00:00",
        "summary": "",
        "meta_description": "NPS is a loyalty metric that correlates well with perception of usability, is easy to understand and administer, but has limitations for understanding and evaluating UX when used in isolation.",
        "meta_lang": "en",
        "meta_favicon": "https://media.nngroup.com/static/img/favicon.ico",
        "meta_site_name": "Nielsen Norman Group",
        "canonical_link": "https://www.nngroup.com/articles/nps-ux/",
        "text": "In your journeys across the web, you probably have encountered the now ubiquitous question “How likely are you to recommend this website to a friend?” This is the prompt behind a popular customer-loyalty metric known as net promoter score.\n\nDefinition and Calculation of NPS\n\nThe net promoter score (NPS) is a quantitative metric that measures how many more people are likely to strongly recommend your site or product compared to those likely to criticize it.\n\nNPS is determined by asking people to provide an answer, on a scale from 0–10, to the question: “How likely are you to recommend this website/product/service to a friend or relative?” The answers are then grouped into 3 categories:\n\nPromoters: responses of 9 or 10, which indicate high satisfaction and strong likelihood of recommendation\n\nDetractors: responses of 0 to 6, which indicate dissatisfaction and likely criticism\n\nPassives: responses of 7 or 8, which indicate moderate satisfaction, but low likelihood of recommendation\n\nThe NPS is then calculated by subtracting the percentage of detractors from the percentage of promoters:\n\nNPS can range from -100% (only detractors) to +100% (only promoters). A positive score indicates that the promoters outnumber detractors, while a negative score shows poor customer loyalty, with detractors outnumbering promoters.\n\nNote: The passives are included in the total number of respondents, but do not contribute to the score otherwise. The rationale is that these users may feel that their needs are fulfilled, but will not actively promote the product or service with family or friends.\n\nOrigins of NPS\n\nFrederick F. Reichheld, a business strategist and author of the bestseller The Loyalty Effect, first introduced the concept of NPS in Harvard Business Review in 2003. In that article, he described a 4,000-respondent survey in which he asked several questions and tracked how well the answers correlated with a number of different measurements, including repeat purchases and recommendations to friends or family. He found that the question that best predicted customer behavior was the one associated with net promoter score. NPS also strongly correlated with company growth over time.\n\nReichheld argued that the net promoter score is relevant because customer recommendations and word-of-mouth referrals are a direct driver of revenue growth in many businesses. A good NPS indicates a loyal customer base — arguably, a company’s greatest marketing asset.\n\nInternational Differences in NPS\n\nFrom a mathematical standpoint, you might expect that the average website rating be 5; so, it may seem harsh to limit promoters to scores of 9 or better and to count a 6 as a detractor, even though 6 is above the mathematical midpoint of the scale (5). However, these cutoff points are reasonable because raters generally tend to be generous and give fairly high scores. That said, a “good” net-promoter score varies depending on whom you ask — or, more accurately, where you ask.\n\nNPS Value Varies by Country\n\nA 2021 study by Qualtrics XM Institute, which surveyed 17,509 consumers across 18 countries, found that responses ranged widely across countries. Respondents were first asked to reflect on companies they liked, and whether they would recommend those companies to friends or relatives. The same was asked regarding companies they disliked. This method yielded two NPS scores for each country’s raters: a “high” NPS (for recommending liked companies) and a “low” NPS (for recommending disliked companies). There were significant differences in “high” ratings across countries. For example, in India and Mexico NPS scores for liked companies were 60% or greater. However, raters in Japan and South Korea gave negative (detractor) NPS (-47% and -11% respectively) even when reflecting on liked companies.\n\nSimilarly, differences between “high” and “low” NPS scores also varied greatly: the gap was largest in Brazil, and smallest in Japan. This finding suggests that in some cultures, people tend to choose more neutral ratings, and choosing extreme options may be culturally taboo.\n\nScoring Rationale Differs Across Countries\n\nAnother study by SurveyMonkey, which focused on whether companies “deserved” their NPS scores, also found differences in scoring rationale. Raters in the United States often cited “quality” as a key driver for their rating, while raters in the UK cited “ease of use,” and those in the Netherlands cited “innovation.” Thus, some rating differences may stem from differing service expectations within each country.\n\nShould NPS Be Adapted?\n\nThese recent findings have spurred debate on whether NPS should be adapted to reflect the rating tendencies of each country’s respondents (e.g. lowering the thresholds for “promoters” in the Netherlands, where ratings are notoriously lower than the global average).\n\nWhile the criticism of a W.E.I.R.D.-centric (Western, educated, industrialized, rich, and democratic) model may be merited, the high likelihood of variation also holds true when comparing average NPS between different industries, and even between different segments within the same industry. Changing the score calculation (for whatever reasons) risks a misrepresentation of data and may tempt teams to “bend” the metric to create more suitable outcomes. Instead, we recommend that you stick to the standard computation method for NPS, while simply acknowledging the contextual differences, as well as reporting the actual rating score (as an average and margin of error) and tracking changes over time.\n\nLimitations of NPS as a Usability Metric\n\n1. NPS does not capture the full picture when used in isolation.\n\nUsability is never entirely captured by subjective scores. We’ve seen many users struggling to complete a task, yet rating a website as highly as someone who had no difficulty whatsoever. To get a complete picture of the user experience, we recommend that you also collect behavioral metrics such as task success rates and task times.\n\nNPS, like all quantitative metrics, tells you how the experience is perceived but not why. Asking customers to report the reason for their rating might give you some insights, but self-reporting is rarely reliable and the user might not bother investing the time to explain the rating altogether.\n\n2. NPS is relevant only with a large enough sample size.\n\nNPS scores (like any metrics) are rarely relevant with a small sample size. Running a qualitative user test with 5 users and asking for the NPS at the end is unlikely to provide you with any valid data, yet many practitioners insist upon reporting these measures with small samples and they base design decisions on them, disregarding their lack of statistical significance.\n\n3. By “binning” responses, NPS ignores important information.\n\nWhile other satisfaction metrics also suffer from the disadvantages mentioned above, NPS has another major problem: its calculation method ignores a lot of the information provided by the ratings by grouping them into three bins (promoters, passives, and detractors) and then ignoring the passives. As a result, researchers must drastically increase their sample sizes in order to gain any statistically relevant information.\n\nFor example, if we could change a design from getting mostly scores of 2 (truly hated) to getting mostly scores of 5 (somewhat disliked), we would have made a major UX improvement, but all of those users would still be counted as detractors in NPS terms, even though they had changed from rabid detractors to modest detractors.\n\n4. Customer loyalty is not identical to usability.\n\nNPS is best used to assess overall customer loyalty and, indirectly, brand perception.\n\nThere are many examples of how UX design decisions impact brand perception — for example, the specific location of a logo on the web page impacts whether users remember the brand at all, or the tone of voice employed on the website changes users’ inclination to recommend the company behind the site.\n\nThat said, there are many more aspects to customer satisfaction and brand recommendations than interface design. Pricing is one obvious variable: if people feel that something is overpriced for what’s delivered, they are unlikely to recommend it, no matter how much they like an experience. Also, if users did not have a choice in the interface they are using (due, for instance, to legal compliance or mandatory use, such as with enterprise applications or operating systems), they may not feel a recommendation is relevant, even if an experience was generally positive.\n\nSo, while loyalty and usability are well correlated, they are not exactly the same.\n\n5. Customer loyalty cannot capture satisfaction with specific parts of your designs.\n\nAgain, NPS is best used to assess overall customer loyalty to an entire company or service, or at least with an entire product.\n\nIt makes less sense to utilize NPS to assess users’ satisfaction with granular details of UI design, such as a website’s checkout process, a product page, or a specific dialog box or icon. Yet these local design elements are often what we can change in everyday design projects.\n\nLet’s say that you improve the writing on some web pages or that you improve the usability of the icons in a mobile app. Don’t get too disappointed if the company’s overall NPS remains flat. It’s hard for a single localized design decision to move the needle much on overall customer loyalty. That’s why we need to supplement global NPS scores with lower-level measures of user satisfaction and task performance.\n\n6. NPS is often gamed.\n\nMany teams turn to NPS as a way to benchmark an experience and incentivize iterative design, which means this metric becomes a focal point of any design improvement. While the intention behind using NPS as a benchmark is positive — it is a good thing to improve loyalty — as Campbell’s Law states: the more important a metric is in social decision making, the more likely it is to be manipulated. In other words, it becomes more important to find ways to make the score better, as opposed to making the experience better.\n\nFor example, a call-center representative may be tempted to only mention the post-call survey after a customer appears to have a positive experience (and not in cases of negative experiences). This behavior could lead to a sampling bias where only positive ratings are collected. Or, users can be pressured, coerced, or bribed into giving a good rating (a practice known as “rating racketeering”), such as when shoppers are offered a coupon or free gift in exchange for providing a positive rating, or when an employee casually mentions that the survey helps them keep their job. All of these may artificially inflate ratings, or at the very least, will impact their validity.\n\nWhy Should You (Still) Use NPS?\n\nDespite these limitations, NPS is still valuable as a UX metric for a number of reasons.\n\nIt’s well-known and liked by upper management for its strong correlation to profits and because it is a quantifiable measurement of something as nebulous as customer loyalty.\n\nEven though it is not identical to usability, it is still closely related to the perception of user experience. In particular, scores on elaborate satisfaction questionnaires such as the System Usability Scale (SUS) are well-correlated with NPS. So, if most of your customers are reporting high loyalty to the point of putting their own reputations on the line to recommend your site, chances are that your site is also usable.\n\nIt’s fairly easy to collect. Unlike other more complex instruments, the NPS is based on a single question, so users will be more likely to respond to that one question than to a lengthy survey.\n\nAs a result, it’s become customary to include the NPS in user interviews, surveys, or even usability-testing sessions. UX practitioners often use it as a tool to promote buy-in from their company’s senior leadership. Numbers that demonstrate increased customer loyalty (and consequently, future sales and profits) after investing in the UX process are more likely to sway skeptical managers and executives than qualitative data alone. Thus, NPS can be part of a series of metrics to measure how a redesign affected loyalty. By quantifying the site usability and loyalty before and after a redesign, companies can assess whether the redesign was worth it and whether it brought enough return on investment (ROI).\n\nConclusion\n\nWhen used by itself, NPS, like any subjective metric, is fairly limited, variable in different geographic and industrial contexts, and far from being a good summary of the overall user experience. However, when combined with other UX metrics, NPS can help you track the overall perception of your user experience over time.\n\nReferences"
    }
}