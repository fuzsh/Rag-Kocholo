{
    "id": "dbpedia_2917_0",
    "rank": 29,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9651107/",
        "read_more_link": "",
        "language": "en",
        "title": "A fully automated deep learning pipeline for micro-CT-imaging-based densitometry of lung fibrosis murine models",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-rr.png",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9651107/bin/12931_2022_2236_Fig1_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9651107/bin/12931_2022_2236_Fig2_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9651107/bin/12931_2022_2236_Fig3_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9651107/bin/12931_2022_2236_Fig4_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9651107/bin/12931_2022_2236_Fig5_HTML.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9651107/bin/12931_2022_2236_Fig6_HTML.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Elena Vincenzi",
            "Alice Fantazzini",
            "Curzio Basso",
            "Annalisa Barla",
            "Francesca Odone",
            "Ludovica Leo",
            "Laura Mecozzi",
            "Martina Mambrini",
            "Erica Ferrini",
            "Nicola Sverzellati"
        ],
        "publish_date": "2022-08-19T00:00:00",
        "summary": "",
        "meta_description": "Idiopathic pulmonary fibrosis, the archetype of pulmonary fibrosis (PF), is a chronic lung disease of a poor prognosis, characterized by progressively worsening of lung function. Although histology is still the gold standard for PF assessment in preclinical ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9651107/",
        "text": "Introduction\n\nIdiopathic pulmonary fibrosis (IPF), the archetype of pulmonary fibrosis (PF), is a potentially fatal chronic lung disease characterized by a progressively worsening lung function due to the development of fibrous connective tissue as a reparative response to injury [1]. Although two antifibrotic drugs1 are now available for the treatment of IPF and other forms of progressive fibrosis, their clinical efficacy is limited and lung transplantation remains the only option to prolong the survival of such patients [2]. The development of new drugs for IPF patients strongly relies on preclinical studies, whose usefulness depends on the ability of animal models to mimic human physiology, disease pathogenesis and response to treatments. Although none of the present pulmonary fibrosis (PF) murine models fully reproduces the features of the human disease, the bleomycin (BLM)-induced PF model is widely used to study disease pathogenesis and evaluate the efficacy of potential new drugs [3]. Current outcomes measured in BLM models of PF involve time-consuming invasive approaches, such as histological scoring that requires animal sacrifice at fixed time-points, thus precluding any longitudinal examination which is essential to fully understand disease development and progression [4].\n\nIn clinical practice, computed tomography (CT) plays a key role in the diagnosis and monitoring of lung injuries [5]. It enables a highly reproducible and longitudinal quantification of lung injuries, as recommended by international diagnostic guidelines [6]. Owing to the linear relationship between X-ray attenuation and tissue density, lung densitometry has been demonstrated to be widely feasible, reproducible, and much less time consuming than visual assessment in several lung disorders [7]. Histogram-based measurements refer to Hounsfield Units (HU, also referred as CT-numbers or CT-values) frequency distribution (i.e. physical density distribution). Therefore, information on air levels in specific lung regions can be derived from lung density histograms.\n\nRecently, a miniaturized version of CT (µCT) has been optimized and validated as a tool to assess PF at different time-points in live animals [8]. This imaging modality can be used in the BLM mouse model of PF to understand the pathogenesis of fibrosis by monitoring the air content of specific lung compartments as well as to evaluate the efficacy of new antifibrotic drug candidates.\n\nIn the present study, we developed a deep learning approach aimed to localize and segment the left and right lungs in thoracic µCT scans of fibrotic mice, thus allowing an automatic quantitative analysis (lung densitometry). In particular, we propose a fully automated pipeline for left and right lung segmentation in native µCTs. This relies on a first coarse U-Net for pre-processing, followed by other U-Nets for a fine lung segmentation, accounting for spatial coherence. Furthermore, the proposed algorithm automatically subdivides the lungs into functional compartments (i.e., normo-aerated, hypo-aerated, non-aerated, and hyper-inflated) based on µCT voxel density to quantitatively assess changes in specific lung regions while monitoring disease progression.\n\nBackground\n\nLung segmentation is a prerequisite for any quantitative analysis of CT scans of the chest, including lung densitometry, but manual segmentation is time-consuming and prone to inter-observer and intra-observer variation. Therefore, the development of a fully automated segmentation algorithm to facilitate rapid quantitative analysis of CT images has become an important goal of medical imaging research. Recently, with the advent of increasingly powerful graphics processing units (GPUs), deep learning techniques have shown excellent performance in the field of medical image analysis. Indeed, several deep learning architectures have been proposed as a way to overcome the problems encountered with conventional segmentation algorithms and to handle pulmonary diseases causing lung density changes.2To name a few, Gerard et al. [9], Park et al. [10], and Jalali et al. [11] have shown that different types of deep learning approaches can be successfully applied to chest CT imaging.\n\nBesides the different pixel size (mm vs µm), pre-clinical µCT differs from clinical CT in several aspects. The acquisition time of μCT needs to be longer to collect more projections to provide accurate image reconstruction during free-breath scanning. In addition, compared to clinical CT detectors used have a limited dynamic range, typically 12–14 bits (compared with 20 bits in clinical CT). Thus, the integration of advanced automatic algorithms into image processing could pave the way to a fully automated lung densitometric investigation, where fibrosis assessment and evaluation of new candidate drugs will be completely µCT-guided.\n\nMouse organ segmentation on µCT is challenging even in healthy animals due to the intrinsically low contrast. For this reason, atlas-based approaches were initially proposed instead of intensity-based ones [12]. However, the results obtained with these methods may be affected by multiple factors such as the size of the dataset used to create the atlas, variations in mouse anatomy, and the specific methodology employed for image registration. In recent years, deep learning-based algorithms have also been proposed for organ segmentation in µCT. However, µCT imaging research is mostly performed by academic laboratories, which usually operate on a small-scale in terms of the number of healthy mice employed for experimentation.\n\nSchoppe et al. [13] presented a U-net-based architecture, called AIMOS, that automatically segments major organs, including the lungs, in 2D coronal µCT whole-body sections of healthy mice. The authors added a post-processing step based on an ensemble voting procedure to eliminate outlier predictions. Malimban et al. [14] devised a 2D and 3D U-Net-based nnU-Net architecture for lungs self-construction on µCT of mice thorax, even in the presence of a low contrast. In the work of Sforazzini et al. [15], the developed deep learning model efficiently segmented the lungs on CT images from mice with different degrees of fibrosis. The authors also explored the applicability of a transfer learning approach to achieve lung segmentation using the proposed network from µCT images of healthy mice, but the test set only consisted of four specimens.\n\nLung densitometry is not addressed in any of the proposed approaches. Birk et al. [16] proposed a deep learning approach to automatically detect the central part of the right and left lung on a µCT stack and perform lung densitometry on these portions of the lung. Many murine models of BLM-induced fibrosis show some limitations in the distribution of the disease across the lobes and more generally across the left and right lungs. Lung densitometry performed on the left and right lung separately may help overcome this limitation of the animal model. However, to the best of our knowledge, no approach proposed so far has been designed for lung segmentation in mouse µCT with significant changes in parenchymal density as those observed in severe PF. In addition, none of the reported approaches integrate an automated densitometric analysis of the entire lung volume or separate left and right lobe volumes.\n\nExperiments and results\n\nExperimental settings\n\nThe experiments were performed on 219 scans acquired at the Chiesi Farmaceutici S.p.A Laboratory in Parma (Italy). Additional 87 scans were used for testing. Both training, validation and testing were performed on a NVIDIA Tesla K40c graphic card with CUDA compute capability = 3.5 and a NVIDIA Titan Xp with CUDA compute capability = 6.1, under Ubuntu operating system. The deep learning models were implemented in Python using Keras framework based on Tensorflow with GPU support. These models, developed for Chiesi Farmaceutici S.p.A, are routinely used to perform predictions in new µCTs using an NVIDIA Tesla P40 graphics card with CUDA = 6.1 computational capability, under Windows operating system.\n\nFor model trainings, categorical cross-entropy was used as a loss function in the coarse multi-class model and the final single-view multi-class models. Binary cross entropy was used for the intermediate single-view models trained to segment the lungs jointly. The Adam optimizer with learning rate = 0.0001 was adopted to optimize the network parameters. In each iteration, a mini-batch containing 24 and 4 slices randomly sampled from the training set was provided to the coarse U-Net and single view U-Net, respectively. The training process was stopped using early stopping criteria, with patience set to 10 epochs.\n\nA data augmentation procedure was adopted: images and masks in the mini batch were modified on the fly during the training process with random rotations, shifts, and zoom factors to augment training and validation sets. The transformation parameters were extracted randomly from a uniform distribution range of maximum variation of [− 5°,5°] for rotation, [− 5%, + 5%] for shifting and [− 15%, + 15%] for zooming.\n\nOnly P02 scans were used for model training and validation because densitometric analyses are typically performed on end expiratory (P02) scans. This allows to avoid any possible bias caused by lung-entrapped respiratory air as in end-inspiratory (P01) scans where the specimen breathing capacity may affect image attenuation.\n\nFor both coarse and single-view models, fivefold split approach was adopted to evaluate the prediction on each µCT in the dataset. Specifically, 5 different models were initially trained on 5 different splits of the dataset. A final model was then trained by setting the number of epochs and the binarization thresholds as medians of the parameters obtained in the splits to train the model on as many data as possible. Approximately 5% of the data was used as a control test set. During the k-fold splitting process, models were tested on end-expiration (P02) µCTs volumes only. For single-view models, the above procedure was initially applied to Dataset A. This dataset was comprised of 167 µCTs and allowed end-to-end learning of lung segmentation. Then, the final model thus obtained was used as a starting point to perform the same procedure (k-fold splitting and end-to-end training) a second time using Dataset B. This dataset was comprised of 52 µCTs and allowed learning of right and left lung segmentation by transfer learning from models that segmented these two structures together.\n\nTable shows the number of training, validation, and test sets for each step. The proposed pipeline was further tested on the end-inspiration µCTs volumes (P01).\n\nTable 2\n\nData splitting# train# validation# testABABABSplit 1144342983610Split 293323612308Split 3108343263312Split 41073231103710Split 511536308318Final1954600146\n\nLung localization and Hounsfield unit conversion\n\nThe first U-Net has two different purposes: (1) coarsely identify the lungs to extract a bounding box through which cut µCT scans; (2) coarsely locate heart and airways to derive the transfer function from raw grey levels to HU with which to convert the µCT volume.\n\nIn the first case, our main interest was the quality of segmentation, which, therefore, was evaluated in terms of a DSC. The coarse segmentations of the lungs predicted by the preliminary model featured an average DSC of 0.933 ± 0.084 on the µCT volumes.\n\nIn the second case, however, our main interest was not segmentation but, rather, the average grey value of the segmented structures. In addition, the ground truth segmentations related to the heart and airways are not accurate enough so the DSC would provide unreliable evaluations. Therefore, coarse segmentation of the airways and heart was evaluated by comparing the mean grey values and the slope and intercept of the transfer function derived automatically, via neural network, with those derived manually in the Chiesi Farmaceutici Laboratory. Lung densitometry related to ground truth segmentation derived from automatically converted µCT scans was also compared with the original, manually converted µCT scans generated in the Chiesi Laboratory.\n\nLung compartments were calculated based on previously tested thresholds [20] using manual lung segmentation (ground truth) to construct the mask. Table shows the errors obtained regarding raw grey values detected, transfer function parameters and compartmental volume derived from densitometry. More specifically, in the first part, we report the absolute percentage error between the average grey level values derived from manual and network coarse segmentation for both airways and heart. In the second part, the absolute percentage error relative to slope and intercept of the transfer function obtained from manual and network coarse segmentation is reported. For the last evaluation, the scan was converted by two different transfer functions: one obtained from airway and heart manual segmentations and the other one from automatic segmentations. We have computed the percent absolute error (defined in Sect. 2.4) in lung densitometry of the two different conversions, using the manual lung segmentation as mask. In this way, we have verified that using a transfer function based on automatic segmentation results in a lung densitometry very similar to the one obtained using manual segmentation.\n\nTable 3\n\nHU conversion evaluationsRaw Grey levels detectedStructureAbsolute percentage errorAirways4.3% ± 1.9%Heart0.1% ± 0.1%\n\nTransfer functionParameterAbsolute percentage errorSlope3.6% ± 0.2%Intercept3.4% ± 0.3%\n\nLung densitometryCompartmental volumePercent absolute errorNormo-aerated volume0.5% ± 5.6%Hypo-aerated volume2.9% ± 4.8%Non-aerated volume0.4% ± 6.7%\n\nThe final preliminary model was then trained by keeping a small control test set. Table shows the data for this training procedure and the performance on the control test set.\n\nTable 4\n\nCoarse axial model summaryNumber of train µCTNumber of test µCTImage dimensionNumber of epochsTraining time [h]Binarization thresholdLung DSC on test setCoarse195 (99,840 2D slices)14 (7168 2D slices)(128, 128)2802:35:37[0.45, 0.45, 0.45]0.939 ± 0.040\n\nSingle-view lung segmentation\n\nAxial, sagittal, and coronal U-Nets were separately trained on the converted µCT cropped around the ROI using Dataset A. Segmentations predicted by axial, sagittal, and coronal single-view models achieve mean DSC of 0.943 ± 0.034, 0.938 ± 0.055, 0.943 ± 0.035, respectively, over the splits. Then, the final axial, sagittal, and coronal models were trained, keeping a small control test set. Table shows the data employed in this training and the performance on the control test set for the three views.\n\nTable 5\n\nSingle-view models summary on single class (lungs)Number of train µCTNumber of test µCTImage dimensionNumber of epochsTraining time [h]Binarization thresholdLung DSC on test setAxial195 (74,880 2D slices)14 (3376 2D slices)(192, 120)405:49:370.550.943 ± 0.038Sagittal195 (37,440 2D slices)14 (2688 2D slices)(192, 192)1006:52:290.550.934 ± 0.055Coronal195 (31,200 2D slices)14 (2240 2D slices)(192, 120)906:37:130.50.943 ± 0.037\n\nThese models are able to segment the lungs together but not to segment separately right and left lungs. Therefore, the decoding path of the single-view models was re-trained on µCT and related segmentation maps with the distinction between right and left lungs (Dataset B). Axial segmentations of right and left lung predicted by the model yielded a mean DSC of 0.964 ± 0.021 and 0.954 ± 0.027, respectively, over the splits. Sagittal segmentations of right and left lung featured a mean DSC of 0.948 ± 0.033 and 0.940 ± 0.029, respectively, over the splits. Coronal segmentations of right and left lung record a mean DSC of 0.965 ± 0.017 and 0.957 ± 0.020, respectively, over the splits.\n\nThen, the final axial, sagittal, and coronal models for segment left and right lungs were trained, keeping a small control test set. Table shows the data employed in this training and the performance on the test set for the three views.\n\nMulti-view aggregation\n\nMulti-view aggregation is a crucial step in the proposed pipeline. A majority Voting approach was implemented to integrate axial, sagittal, and coronal predictions into a final segmentation. In addition, by combining the left and right lung segmentations and binarizing the resulting probability map, total segmentation was achieved.\n\nThe results obtained with multi-view aggregation were compared with those generated by single-view segmentations to evaluate the impact of the proposed approach on the test set. As shown in Table , the combination of orthogonal segmentations led to better results compared to those of single-view segmentations. The models were only evaluated on Dataset B because transfer learning was performed on the models trained on Dataset A. Figure shows the ground truth and predicted segmentations overlaid on a µCT scan with a high degree of fibrosis.\n\nTable 6\n\nSingle-view models summary on multi-class (left lung/right lung)Number of train µCTNumber of test µCTImage dimensionNumber of epochsTraining time [h]Binarization thresholdLeft lung DSC on test setRight lung DSC on test setAxial46 (17,664 2D slices)6 (820 2D slices)(192, 120)602:19:12[0.45, 0.45]0.952 ± 0.0210.963 ± 0.043Sagittal46 (39,168 2D slices)6 (1152 2D slices)(192, 192)902:53:39[0.40, 0.40]0.940 ± 0.0310.950 ± 0.042Coronal46 (32,640 2D slices)6 (960 2D slices)(192, 120)1102:27:39[0.40, 0.40]0.957 ± 0.0280.964 ± 0.027\n\nTo corroborate the quality of the models, their performances were divided according to the corresponding time-points and relative DSC values were calculated (see boxplots in Fig. ). Furthermore, to test the generalization capability of the models, the optimized pipeline was also tested on P01 scans. The resulting DSC values were 0.926 ± 0.077 on the left lung, 0.950 ± 0.044 on the right lung and 0.949 ± 0.38 on both lungs.\n\nTo eliminate out-of-band voxels, the neural network-generated segmentation was thresholded in the range [− 1040, + 121] HU. The volume calculated by ground truth segmentation was compared with the volume yielded by automatic segmentation. The absolute percent error thus achieved was + 2.6 ± 1.9% on the left lung, + 1.9 ± 1.7% on the right lung and + 2.2 ± 1.6% on both lungs.\n\nLung densitometry\n\nThe clean segmentation was compartmentalized based on the corresponding voxel values in µCT scans (i.e., aeration) according to pre-defined thresholds [20]. Table shows the difference in percent points between a specific compartment detected in manual segmentation (ground truth) and in automatic neural network segmentation. As shown by the Bland Altman plots of left-lung compartments in Fig. , nearly all data are within the confidence intervals highlighted by the dashed grey lines. We also compared the percentage of normo-aerated compartments and poorly-aerated compartments (hypo-aerated + non-aerated) derived from manual volume and automatic total volume analyses. As shown by the scatter plots in Fig. , the trend lines indicate a significant correlation between manual and automatic measurements in both compartments (R2 = 0.99).\n\nTable 7\n\nLung densitometryLeft lungRight lungBoth lungNormo− 0.6% (− 2.0%, + 1.6%)− 0.3% (− 1.7%, + 1.9%)− 0.5% (− 1.9%, + 1.8%)Hypo + 1.3% (− 1.3%, + 2.9%) + 1.4% (− 1.8%, + 2.8%) + 1.5% (− 1.5%, + 2.3%)Non− 0.1% (− 3.5%, + 0.1%)− 0.4% (− 2.8%, + 0.1%)− 0.2% (− 2.8%., + 0.1%)Hyper + 0.0% (− 0.1%, + 0.1%) + 0.0% (− 0.1%, + 0.1%) + 0.0% (− 0.1%, + 0.1%)\n\nDiscussion\n\nIn this study, we present a deep learning approach for spatially coherent lung segmentation and lung densitometry based on whole lung volumetric µCT data. To the best of our knowledge, this is the first approach applied on µCT scans for lung segmentation in fibrotic mice.\n\nSeveral pulmonary segmentation approaches have previously been proposed for clinical CT analysis of IPF patients [9–11] but the preclinical setting has received considerably less attention, except for a few reports dealing with healthy animals [13–15]. These approaches, however, do not work in the presence of the marked lung parenchyma alterations associated to pulmonary diseases. Indeed, such alterations significantly affect the contrast of the lungs in µCT, making it difficult to distinguish them from the surrounding soft tissue. Our dataset, conversely, includes multiple independent µCT scans from healthy and BLM animals with different degrees of fibrosis.\n\nOur segmentation pipeline is based on the U-Net architecture proposed by Ronneberger et al. [21]. This procedure can perform efficient image segmentation using a limited number of labeled training images and it is thus considered the gold standard in medical segmentation [22].\n\nThe first step of the proposed pipeline includes automatic coarse identification of the lungs from µCT scans. This step is performed to retain only the information needed to segment the lungs, excluding some of the background and speeding up subsequent steps. This approach has been widely adopted in medical image segmentation, especially when the structures of interest are small compared to the image size. In the work proposed by Fantazzini et al. [23] for aorta segmentation in angio-CT images, a first 2D U-Net was exploited to extract the ROI from subsampled CT images, then a second 2D U-Net performs a finer segmentation on higher-resolution cropped CTs. A similar approach, based on a 3D U-Net, was proposed by Jia et al. [24] for segmentation of the left atrium in MR images.\n\nIn our pipeline, we extend these approaches by using an initial 2D U-Net to simultaneously segment airways and heart in order to obtain the information required for HU conversion in a single step without slowing down the overall pipeline. In this way, our HU conversion approach allows us to automatically examine all those scans for which a reference (e.g., a phantom) is not available for conversion. Future work will address the possibility of designing a procedure for HU conversion independently from segmentation of other structures, in order to further speed up the pipeline and eliminate its dependence on the quality of segmentations.\n\nWe preferred a multi-view orthogonal integration approach of 2D CNN rather over a single 3D CNN for finer lung segmentation.\n\n3D CNNs allow to extract more discriminative information than 2D CNNs because the kernels learn volumes rather than sections, and this is useful for segmenting large organs (such as lungs). Kleesiek et al. [25] used CNN 3D to extract brain boundaries, with an improvement of approximately 6% compared to other methods. However, 3D CNNs require a significantly higher number of parameters compared to 2D CNNs and, as a result, are much more resources- and time-demanding, usually needing image subsampling. Moreover, 3D CNNs often require very large data set to enable end-to-end learning and memory requirements are usually very high [25]. On the other hand, the multi-view integration of CNN 2D (the so-called 2.5D approach) is a widely used alternative because it offers a good balance between overall performance and computational efforts [23, 25]. In particular, it is possible to preserve an high image resolution, which is one of the most important issues, especially for small structures or low contrast images such as µCT. With our architecture, a 2D single-view Unet network has 34,535,875 parameters while a 3D Unet network has 103,546,435 parameters. The 2.5D approach requires 3 single-view Unet networks and therefore 3 × 34,535,875 = 103,607,625 parameters. Thus, the number of parameters in our 2.5D approach is slightly larger than that required by a 3D approach. However, in the 2.5D approach the three nets are trained independently, so the number of parameters involved for each single-view training is that of a 2D Unet. On the contrary, in 3D networks all the parameters are involved simultaneously and therefore the computational resources required are much greater. The huge memory requirement is often addressed by limiting the complexity of the model. Moreover, because in our 2.5D approach each µCT volume is decomposed into axial, sagittal and coronal 2D slice stacks, the single-view 2D networks can be trained with a large amount of data. This advantage is not exploited with a 3D network, that processes the whole µCT scans, thus requiring more training data than a 2D network. In addition, 2.5D approaches often return results with comparable accuracy to 3D approaches but with lower computational efforts.\n\nA thresholding step was included after segmentation to remove voxels labeled by the network as lungs but whose corresponding value in the µCT scan is outside the appropriate range [20]. Indeed, it is possible that small portions of ribs or tissue areas of the airways are erroneously included in the lung segmentation. This is because models learn from manual segmentations in a supervised manner, and manual segmentation may contain the above-mentioned errors. To limit this effect, it would be necessary to collect multi-user segmentations for each individual µCT in the training set, thus making the model more robust and limiting errors in areas that are difficult to segment. In our dataset, however, out-of-range voxels excluded from the predicted segmentations however are typically less than 1% of the total lung volume.\n\nThe final step in the proposed pipeline involves the computation of lung densitometry.\n\nConsidering only a specific portion of the lung [16], even a central one, might be reductive because the most relevant changes in lung parenchyma density are usually localized to peripheral regions such as the accessory lobe or the right apical lobe. In our work, instead, densitometry was performed on the the whole lung volume, taking into account all areas of the lungs and, consequently, more meaningful parameters were obtained. This approach also allows to determine the fractional content (percentage) of singular compartments relative to the total volume of the lungs to monitor their variation during disease development and/or treatment with candidate new drugs.\n\nConclusion\n\nIn clinical settings, chest CT is widely used for diagnostic purposes and plays a crucial role in patient management [5]. A large community of radiologists is increasingly committed to the creation and distribution of new CT-based diagnostic tools and algorithms [9–11, 26]. In the pre-clinical setting, conversely, the deployment of µCT and automatization approaches are much less common. Imaging research based on µCT is mostly performed in academic centers and is usually limited to relatively small numbers of healthy mice. This contrasts with the needs of fibrosis drug discovery, where µCT imaging has to be applied to a large number of mice and to provide useful results in a relatively short time in order to support the efforts of pharmaceutical companies, aimed at quickly identifying the most promising drug candidates for clinical development.\n\nThe key role played by µCT imaging in this drug discovery process has been corroborated by the results of several studies documenting the correlation between in-vivo µCT and ex-vivo histological analysis [8, 20].\n\nIn addition, µCT enables longitudinal studies, which in addition to a more detailed monitoring of disease progression, allows a sizable scaling down of the number of required animals. In this work, we presented a fully automated time-saving tool that enables densitometric analysis of the entire lung in murine µCT scans even in the presence of large changes in tissue density. Areas of dense tissue are particularly important when studying the mechanisms involved in pulmonary fibrosis as well as the effects of new potential antifibrotic strategies in murine models.\n\nHowever, available semi-automated software fails to detect these regions and in order to avoid potential artifacts (and associated confounding effects) segmentations must be corrected manually by trained operators. Considering that drug discovery experiments may require the analysis of up to 1000 scans/year, our approach can significantly reduce the experimental workload. To better substantiate this time-saving, we note that, on average, our pipeline took about 81 ± 15 s per scan (48 ± 9 s per segmentation, 33 ± 6 s per densitometry analysis) compared to the > 40 min required by a complete manual analysis performed under severe pathological conditions (coarse segmentation of airways and heart, accurate segmentation of right and left lungs, conversion to HU and lung densitometry). Our automated pipeline is being used successfully for drug discovery experiments and independently validated at Chiesi Farmaceutici S.p.A.\n\nWe also anticipate that the proposed pipeline, although developed in mice, could be extended and adapted to other animal models with different lung anatomies such as rabbits or rats. The only requirement to set-up a transfer learning procedure and create dedicated models for these alternative animal models, would be the availability of a sufficient number of µCT volumes and corresponding manual segmentations."
    }
}