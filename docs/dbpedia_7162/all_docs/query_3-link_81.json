{
    "id": "dbpedia_7162_3",
    "rank": 81,
    "data": {
        "url": "https://dokumen.pub/encyclopedia-of-applied-and-computational-mathematics-volume-1-a-k-9783540705284-9783540705291-9783540705307-3540705287.html",
        "read_more_link": "",
        "language": "en",
        "title": "Encyclopedia of applied and computational mathematics Volume 1. A",
        "top_image": "https://dokumen.pub/img/encyclopedia-of-applied-and-computational-mathematics-volume-1-a-k-9783540705284-9783540705291-9783540705307-3540705287.jpg",
        "meta_img": "https://dokumen.pub/img/encyclopedia-of-applied-and-computational-mathematics-volume-1-a-k-9783540705284-9783540705291-9783540705307-3540705287.jpg",
        "images": [
            "https://dokumen.pub/dokumenpub/assets/img/dokumenpub_logo.png",
            "https://dokumen.pub/img/200x200/encyclopedia-of-bioinformatics-and-computational-biology-9780128114148.jpg",
            "https://dokumen.pub/img/200x200/analytical-and-computational-methods-in-scattering-and-applied-mathematics-9780429525087-0429525087-9781420035971-1420035975.jpg",
            "https://dokumen.pub/img/200x200/encyclopedia-of-applied-ethics-9780123736321-1865843830-0123736323.jpg",
            "https://dokumen.pub/img/200x200/encyclopedia-of-applied-ethics-9780123736321-1865843830-0123736323.jpg",
            "https://dokumen.pub/img/200x200/applied-mathematics-and-computational-intelligence-icamci-2020-tripura-india-december-2324-9811981930-9789811981937.jpg",
            "https://dokumen.pub/img/200x200/applied-and-computational-measurable-dynamics-1nbsped-9781611972634-2013027536.jpg",
            "https://dokumen.pub/img/200x200/applied-mathematics-and-modelling-in-finance-marketing-and-economics-studies-in-computational-intelligence-1114-1nbsped-3031428463-9783031428463.jpg",
            "https://dokumen.pub/img/200x200/applied-mathematics-and-computational-intelligence-icamci-2020-tripura-india-december-2324-9789811981944-9789811981937-9811981949.jpg",
            "https://dokumen.pub/img/200x200/applied-and-computational-complex-analysis-discrete-fourier-analysis-cauchy-integrals-construction-of-conformal-maps-univalent-functions-pure-amp-applied-mathematics-1nbsped-0471087033-9780471087038.jpg",
            "https://dokumen.pub/img/200x200/applied-mathematics-for-engineering-sem-1.jpg",
            "https://dokumen.pub/img/200x200/encyclopedia-of-applied-and-computational-mathematics-volume-1-a-k-9783540705284-9783540705291-9783540705307-3540705287.jpg",
            "https://dokumen.pub/dokumenpub/assets/img/dokumenpub_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "EACM is a comprehensive reference work covering the vast field of applied and computational mathematics. Applied mathema...",
        "meta_lang": "en",
        "meta_favicon": "https://dokumen.pub/dokumenpub/assets/img/apple-icon-57x57.png",
        "meta_site_name": "dokumen.pub",
        "canonical_link": "https://dokumen.pub/encyclopedia-of-applied-and-computational-mathematics-volume-1-a-k-9783540705284-9783540705291-9783540705307-3540705287.html",
        "text": "Citation preview\n\nBjörn Engquist Editor\n\nEncyclopedia of Applied and Computational Mathematics 1 3Reference\n\nEncyclopedia of Applied and Computational Mathematics\n\n¨ Engquist Bjorn Editor\n\nEncyclopedia of Applied and Computational Mathematics Volume 2 L–Z\n\nWith 361 Figures and 33 Tables\n\nEditor Bj¨orn Engquist University of Texas at Austin Austin, TX, USA\n\nISBN 978-3-540-70528-4 ISBN 978-3-540-70529-1 ISBN 978-3-540-70530-7 (print and electronic bundle) DOI 10.1007/ 978-3-540-70529-1\n\n(eBook)\n\nLibrary of Congress Control Number: 2015953230 Springer Heidelberg New York Dordrecht London © Springer-Verlag Berlin Heidelberg 2015 This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made. Printed on acid-free paper Springer-Verlag GmbH Berlin Heidelberg is part of Springer Science+Business Media (www.springer.com)\n\nPreface\n\nThe scientific field of applied and computational mathematics has evolved and expanded at a very rapid rate during the last few decades. Many subfields have matured, and it is therefore natural to consider publishing an encyclopedia for the field. Traditional encyclopedias are, however, becoming part of history. For fast, simple, and up-to-date facts they cannot compete with web search engines and web-based versions of the Wikipedia type. For much more extensive and complete treatments of topics, traditional monographs and review articles in specialized journals are common. There is an advantage with web-based articles as in Wikipedia, which constantly evolves and adapts to changes. There is also an advantage with articles that do not change, have known authors, and can be referred to in other publications. With the Encyclopedia for Applied and Computational Mathematics (EACM), we are aiming at achieving the best of these two models. The goal with EACM is a publication with broad coverage by many articles, which are quality controlled through a traditional peer review process. The articles can be formally cited, and the authors can take credit for their contributions. This publication will be frozen in its current form, obviously on paper as well as on the web. In parallel there will be an electronic version, where the authors can make changes to their articles and where new articles will be added. After a couple of years, this dynamic version will result in a publication of a new edition of EACM, which can be referenced while the dynamic electronic version continues to evolve. The length of the articles is also chosen to fill the gap between the common shorter web versions and more specialized longer publications. They are here typically between 5 and 10 pages. A few are introductory overviews and a bit longer than the average article. An encyclopedia will never be complete, and the decision to define the first edition at this time is based on a compromise between the desire of covering the field well and a timely published version. This first edition has 312 articles with the overall number of 1,575 pages in 2 volumes. There are few contributions with animations, which will appear in the electronic version. This will be expanded in the future. The above discussion was about the “E” in EACM. Now we turn to rest of the acronym, “ACM.” Modern applied and computational mathematics is more applied, more computational, and more mathematical than ever. The exponential growth of computational power has allowed for much more complex mathematical models, and these new models are typically more realistic for applications. It is natural to include both applied and computational mathematics in the encyclopedia even though these two fields are philosophically different. In computational mathematics, algorithms are developed and analyzed and may in principle be independent from applications. The two fields are, however, now very tightly coupled in practice.\n\nv\n\nvi\n\nAlmost all applied mathematics has some computational components, and most computational mathematics is directly developed for applications. Computation is now mentioned as the third pillar of science together with the classical theory and experiments. Scientific progress of today is often based on critical computational components, which can be seen in the growing contribution from computations in recent Nobel Prizes. The importance of mathematical modeling and scientific computing in engineering is even more obvious. The expression “Computational Science and Engineering” has emerged to describe a scientific field where computations have merged with applications. Classical fields of applied mathematics, for example, asymptotic analysis and homogenization, are today not so often used for achieving quantitative results. They are, however, very important in mathematical modeling and in deriving and understanding a variety of numerical techniques for multiscale simulations. This is explained in different settings throughout EACM. We mentioned above that modern applied and computational mathematics are more mathematical than ever. In the early days, this coupling was natural. Many algorithms that are used today and also discussed in this encyclopedia have the names of Newton and Gauss. However, during the century before the modern computer, mathematics in its pure form evolved rapidly and became more disconnected from applications. The computational tools of pen and paper, the slide rule, and simple mechanical devices stayed roughly the same. We got a clear division between pure and applied mathematics. This has changed with the emergence of the modern computer. Models based on much more sophisticated mathematics are now bases for the quantitative computations and thus practical applications. There are many examples of this tighter coupling between applied and computational mathematics on the one hand and what we regard as pure mathematics on the other. Harmonic analysis is a typical example. It had its origin in applied and computational mathematics with the work of Fourier on heat conduction. However, only very special cases can be studied in a quantitative way by hand. In the years after this beginning, there was substantial progress in pure directions of harmonic analysis. The emergence of powerful computers and the fast Fourier transform (FFT) algorithm drastically changed the scene. This resulted, for example, in wavelets, the inverse Radon transform, a variety of spectral techniques for PDEs, computational information, and sampling theory and compressed sensing. The reader will see illustrative examples in EACM. Partial differential equations have also had a recent development where ideas have bounced back and forth between applications, computations, and fundamental theory. The field of applied and computational mathematics is of course not well defined. We will use the term in a broad sense, but we have not included areas that have their own identity and where applied and computational mathematics is not what you think of even if in a strict sense applied and computational mathematics would be correct. Statistics is the most prominent example. This was an editorial decision. Through the process of producing the EACM, there has been a form of self-selection. When section editors and authors were asked to cover an area or a topic closer to the core of applied and computational mathematics, the success rate was very high. Examples are numerical analysis and inverse problems. Many applied areas are also well covered, ranging from general topics in fluid and solid mechanics to computational aspects of chemistry and the mathematics of atmosphere and ocean science.\n\nPreface\n\nPreface\n\nvii\n\nIn fields further from the core, the response was less complete. Examples of the latter are the mathematical aspects of computer science and physics, where the researchers generally do not think of themselves as doing applied and computational mathematics even when they are. The current encyclopedia naturally does not cover all topics that should ideally have their own articles. We hope to fill these holes in the evolving web-based version and then in the future editions. Finally, I would like to thank all section editors and authors for their outstanding contributions and their patience. I also hope that you will continue to improve EACM in its dynamic form and in future editions. Joachim Heinze and Martin Peters at Springer initiated the process when they came with the idea of an encyclopedia. Martin Peters’ highly professional supervision of the development and publication process has absolutely been critical. I am also very grateful for the excellent support from Ruth Allewelt and Tina Shelton at Springer. Austin, USA September 2015\n\nBj¨orn Engquist\n\nAbout the Editor\n\nBj¨orn Engquist received his Ph.D. in Numerical Analysis from Uppsala University in the year 1975. He has been Professor of Mathematics at UCLA, Uppsala University, and the Royal Institute of Technology, Stockholm. He was Michael Henry Strater University Professor of Mathematics and Applied and Computational Mathematics at Princeton University and now holds the Computational and Applied Mathematics Chair I at the University of Texas at Austin. He was Director of the Research Institute for Industrial Applications of Scientific Computing and of the Centre for Parallel Computers at the Royal Institute of Technology, Stockholm. At Princeton University, he was Director of the Program in Applied and Computational Mathematics and the Princeton Institute for Computational Science, and he is now the Director of the ICES Center for Numerical Analysis in Austin. Engquist is a member of the American Association for the Advancement of Science, the Royal Swedish Academy of Sciences, the Royal Swedish Academy of Engineering Sciences, and the Norwegian Academy of Science and Letters. He was a Guggenheim fellow and received the first SIAM Prize in Scientific Computing 1982, the Celsius Medal 1992, the Henrici Prize 2011, the George David Birkhoff Prize in Applied Mathematics 2012, and the ICIAM Pioneer Prize 2015. He was an ICM speaker in the years 1982 and 1998. His research field is development, analysis, and application of numerical methods for differential equations. A particular focus has been multiscale problems and applications to fluid mechanics and wave propagation. He has had 40 Ph.D. students.\n\nix\n\nSection Editors\n\nMark Alber Department of Applied and Computational Mathematics and Statistics University of Notre Dame Notre Dame, IN, USA\n\nErnst Hairer Section de Math´ematiques Universit´e de Gen`eve Gen`eve, Switzerland\n\nJohan H˚astad Royal Insitute of Technology Stockholm, Sweden\n\nxi\n\nxii\n\nSection Editors\n\nArieh Iserles Department of Applied Mathematics and Theoretical Physics Centre for Mathematical Sciences University of Cambridge Cambridge, UK\n\nHans Petter Langtangen Simula Research Laboratory Center for Biomedical Computing Fornebu, Norway Department of Informatics University of Oslo, Oslo, Norway\n\nClaude Le Bris Ecole des Ponts – INRIA Paris, France\n\nChristian Lubich Mathematisches Institut University of T¨ubingen T¨ubingen, Germany\n\nSection Editors\n\nxiii\n\nAndrew J. Majda Department of Mathematics and Climate Atmosphere, Ocean Science (CAOS) Courant Institute of Mathematical Sciences New York University New York, NY, USA\n\nJoyce R. McLaughlin Department of Mathematical Sciences Rensselaer Polytechnic Institute Troy, NY, USA\n\nRisto Nieminen School of Science Aalto University Espoo, Finland\n\nJ. Tinsley Oden Institute for Computational Engineering and Science The University of Texas at Austin Austin, TX, USA\n\nxiv\n\nSection Editors\n\nAslak Tveito Simula Research Laboratory Center for Biomedical Computing Fornebu, Norway Department of Informatics University of Oslo, Oslo, Norway\n\nContributors\n\n´ Assyr Abdulle Mathematics Section, Ecole Polytechnique F´ed´erale de Lausanne (EPFL), Lausanne, Switzerland Andrew Adamatzky Unconventional Computing Centre, University of the West of England, Bristol, UK Todd Arbogast Institute for Computational Engineering and Sciences, University of Texas, Austin, TX, USA Douglas N. Arnold School of Mathematics, University of Minnesota, Minneapolis, MN, USA Simon R. Arridge Department of Computer Science, Center for Medical Image Computing, University College London, London, UK Uri Ascher Department of Computer Science, University of British Columbia, Vancouver, BC, Canada Kendall E. Atkinson Department of Mathematics and Department of Computer Science, University of Iowa, Iowa City, IA, USA Paul J. Atzberger Department of Mathematics, University of California Santa Barbara (UCSB), Santa Barbara, CA, USA Florian Augustin Technische Universit¨at M¨unchen, Fakult¨at Mathematik, Munich, Germany Winfried Auzinger Institute for Analysis und Scientific Computing, Technische Universit¨at Wien, Wien, Austria Owe Axelsson Division of Scientific Computing, Department of Information Technology, Uppsala University, Uppsala, Sweden Institute of Genomics, ASCR, Ostrava, Czech Republic Ruth E. Baker Centre for Mathematical Biology, Mathematical Institute, University of Oxford, Oxford, UK Guillaume Bal Department of Applied Physics and Applied Mathematics, Columbia University, New York, NY, USA Vijay Balasubramanian Department of Physics and Astronomy, Department of Neuroscience, University of Pennsylvania, Philadelphia, PA, USA\n\nxv\n\nxvi\n\nContributors\n\nRoberto Barrio Departamento de Matem´atica Aplicada and IUMA, University of Zaragoza, Zaragoza, Spain Timothy Barth NASA Ames Research Center, Moffett Field, CA, USA Catherine A.A. Beauchemin Department of Physics, Ryerson University, Toronto, ON, Canada Margaret Beck Department of Mathematics, Heriot-Watt University, Edinburgh, UK Mikhail I. Belishev PDMI, Saint-Petersburg, Russia Alfredo Bellen Department of Mathematics and Geosciences, University of Trieste, Trieste, Italy Ted Belytschko Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA Rafael D. Benguria Departamento de F´ısica, Pontificia Universidad Cat´olica de Chile, Santiago de Chile, Chile Fredrik Bengzon Department of Mathematics and Mathematical Statistics, Ume˚a University, Ume˚a, Sweden Jean–Paul Berrut D´epartement de Math´ematiques, Universit´e de Fribourg, Fribourg/P´erolles, Switzerland ˚ Bj¨orck Department of Mathematics, Link¨oping University, Link¨oping, Sweden Ake Petter E. Bjørstad Department of Informatics, University of Bergen, Bergen, Norway Sergio Blanes Instituto de Matem´atica Multidisciplinar, Universitat Polit`ecnica de Val`encia, Val`encia, Spain Pavel Bochev Computational Albuquerque, NM, USA\n\nMathematics,\n\nSandia\n\nNational\n\nLaboratories,\n\nLiliana Borcea Department of Mathematics, University of Michigan, Ann Arbor, MI, USA Brett Borden Physics Department, Naval Postgraduate School, Monterey, CA, USA John P. Boyd Department of Atmospheric, Oceanic and Space Science, University of Michigan, Ann Arbor, MI, USA Michal Branicki School of Mathematics, The University of Edinburgh, Edinburgh, UK Claude Brezinski Laboratoire Paul Painlev´e, UMR CNRS 8524, UFR de Math´ematiques Pures et Appliqu´ees, Universit´e des Sciences et Technologies de Lille, Villeneuve d’Ascq, France Hermann Brunner Department of Mathematics, Hong Kong Baptist University, Kowloon Tong, Hong Kong SAR, China Department of Mathematics and Statistics, Memorial University of Newfoundland, St. John’s, NL, Canada\n\nContributors\n\nxvii\n\nMartin Buhmann Mathematisches Institut, Justus-Liebig-Universit¨at, Giessen, Germany Martin Burger Institute for Computational and Applied Mathematics, Westf¨alische Wilhelms-Universit¨at (WWU) M¨unster, M¨unster, Germany John C. Butcher Department of Mathematics, University of Auckland, Auckland, New Zealand Michel Caffarel Laboratoire de Chimie et Physique Quantiques, IRSAMC, Universit´e de Toulouse, Toulouse, France Russel Caflisch UCLA – Department of Mathematics, Institute for Pure and Applied Mathematics, Los Angeles, CA, USA Xing Cai Simula Research Laboratory, Center for Biomedical Computing, Fornebu, Norway University of Oslo, Oslo, Norway Fioralba Cakoni Department of Mathematics, Rutgers University, New Brunswick, NJ, USA Daniela Calvetti Department of Mathematics, Applied Mathematics, and Statistics, Case Western Reserve University, Cleveland, OH, USA Mari Paz Calvo Departamento de Matem´atica Aplicada, Universidad de Valladolid, Valladolid, Spain Eric Canc`es Ecole des Ponts ParisTech – INRIA, Universit´e Paris Est, CERMICS, Projet MICMAC, Marne-la-Vall`ee, Paris, France Fernando Casas Departament de Matem`atiques and IMAC, Universitat Jaume I, Castell´on, Spain Jeff R. Cash Department of Mathematics, Imperial College, London, England Carlos Castillo-Chavez Mathematical and Computational Modeling Sciences Center, School of Human Evolution and Social Change, School of Sustainability, Arizona State University, Tempe, AZ, USA Santa Fe Institute, Santa Fe, NM, USA Isabelle Catto CEREMADE UMR 7534, CNRS and Universit´e Paris-Dauphine, Paris, France ˇ ık Los Alamos National Laboratory, Los Alamos, NM, USA Ondˇrej Cert´ Raymond Chan Department of Mathematics, The Chinese University of Hong Kong, Shatin, Hong Kong Philippe Chartier INRIA-ENS Cachan, Rennes, France Gui-Qiang G. Chen Mathematical Institute, University of Oxford, Oxford, UK Jiun-Shyan Chen Department of Structural Engineering, University of California, San Diego, CA, USA Margaret Cheney Department of Mathematics, Colorado State University, Fort Collins, CO, USA\n\nxviii\n\nChristophe Chipot Laboratoire International Associ´e CNRS, UMR 7565, Universit´e de Lorraine, Vandœuvre-l`es-Nancy, France Theoretical and Computational Biophysics Group, Beckman Institute for Advanced Science and Technology, University of Illinois at Urbana-Champaign, UrbanaChampaign, IL, USA Emiliano Cristiani Istituto per le Applicazioni del Calcolo “Mauro Picone”, Consiglio Nazionale delle Ricerche, Rome, RM, Italy Daan Crommelin Scientific Computing Group, Centrum Wiskunde and Informatica (CWI), Amsterdam, The Netherlands Korteweg-de Vries Institute for Mathematics, University of Amsterdam, Amsterdam, The Netherlands Felipe Cucker Department of Mathematics, City University of Hong Kong, Kowloon Tong, Hong Kong Constantine M. Dafermos Division of Applied Mathematics, Brown University, Providence, RI, USA Eric Darve Mechanical Engineering Department, Institute for Computational and Mathematical Engineering, Stanford University, Stanford, CA, USA Clint N. Dawson Institute for Computational Engineering and Sciences, University of Texas, Austin, TX, USA Ben De Lacy Costello Unconventional Computing Centre, University of the West of England, Bristol, UK Jean-Pierre Dedieu Toulouse, France Paul Dellar OCIAM, Mathematical Institute, Oxford, UK Leszek F. Demkowicz Institute for Computational Engineering and Sciences (ICES), The University of Texas at Austin, Austin, TX, USA Luca Dieci School of Mathematics, Georgia Institute of Technology, Atlanta, GA, USA Bernard Ducomet Departement de Physique Theorique et Appliquee, CEA/DAM Ile De France, Arpajon, France Iain Duff Scientific Computing Department, STFC – Rutherford Appleton Laboratory, Oxfordshire, UK CERFACS, Toulouse, France Nira Dyn School of Mathematical Sciences, Tel-Aviv University, Tel-Aviv, Israel Bo Einarsson Link¨oping University, Link¨oping, Sweden Heinz W. Engl Johann Radon Institute for Computational and Applied Mathematics (RICAM), Austrian Academy of Sciences, Linz, Austria Charles L. Epstein Departments of Mathematics and Radiology, University of Pennsylvania, Philadelphia, PA, USA\n\nContributors\n\nContributors\n\nxix\n\nMaria J. Esteban CEREMADE, CNRS and Universit´e Paris-Dauphine, Paris, France Adel Faridani Department of Mathematics, Oregon State University, Corvallis, OR, USA Jean-Luc Fattebert Lawrence Livermore National Laboratory, Livermore, CA, USA Hans Georg Feichtinger Institute of Mathematics, University of Vienna, Vienna, Austria Yusheng Feng NSF/CREST Center for Simulation, Visulization and Real-Time Prediction, The University of Texas at San Antonio, San Antonio, TX, USA David V. Finch Department of Mathematics, Oregon State University, Corvallis, OR, USA Mathias Fink Institut Langevin, ESPCI ParisTech, Paris, France Michael S. Floater Department of Mathematics, University of Oslo, Oslo, Norway Aaron L. Fogelson Departments of Mathematics and Bioengineering, University of Utah, Salt Lake City, UT, USA A.S. Fokas DAMTP Centre for Mathematical Sciences, University of Cambridge, Cambridge, UK Massimo Fornasier Department of Mathematics, Technische Universit¨at M¨unchen, Garching bei M¨unchen, Germany Bengt Fornberg Department of Applied Mathematics, University of Colorado, Boulder, CO, USA Piero Colli Franzone Dipartimento di Matematica “F. Casorati”, Universit`a degli Studi di Pavia, Pavia, Italy Avner Friedman Department of Mathematics, Ohio State University, Columbus, OH, USA Dargan M.W. Frierson Department of Atmospheric Sciences, University of Washington, Seattle, WA, USA Gero Friesecke TU M¨unchen, Zentrum Mathematik, Garching, M¨unich, Germany Martin J. Gander Section de Math´ematiques, Universit´e de Gen`eve, Geneva, Switzerland Carlos J. Garc´ıa-Cervera Mathematics Department, University of California, Santa Barbara, CA, USA Edwin P. Gerber Center for Atmosphere Ocean Science, Courant Institute of Mathematical Sciences, New York University, New York, NY, USA Dimitrios Giannakis Center for Atmosphere Ocean Science (CAOS), Courant Institute of Mathematical Sciences, New York University, New York, NY, USA Amparo Gil Departamento de Matem´atica Aplicada y Ciencias de la Computaci´on, Universidad de Cantabria, E.T.S. Caminos, Canales y Puertos, Santander, Spain\n\nxx\n\nVivette Girault Laboratoire Jacques-Louis Lions, UPMC University of Paris 06 and CNRS, Paris, France Ingrid Kristine Glad Department of Mathematics, University of Oslo, Oslo, Norway Dominik G¨oddeke Applied Mathematics, TU Dortmund, Dortmund, Germany Serdar G¨oktepe Department of Civil Engineering, Middle East Technical University, Ankara, Turkey Jerzy Gorecki Institute of Physical Chemistry and Warsaw University, Warsaw, Poland Nicholas Ian Mark Gould Scientific Computing Department, Rutherford Appleton Laboratory, Oxfordshire, UK Brian Granger Department of Physics, California Polytechnic State University, San Luis Obispo, CA, USA Frank R. Graziani Lawrence Livermore National Laboratory, Livermore, CA, USA Andrey Gritsun Institute of Numerical Mathematics, Moscow, Russia Martin Grohe Department of Computer Science, RWTH Aachen University, Aachen, Germany Nicola Guglielmi Dipartimento di Matematica Pura e Applicata, Universit`a dell’Aquila, L’Aquila, Italy ¨ Osman Guler Department of Mathematics and Statistics, University of Maryland Baltimore County, Baltimore, MD, USA Jeremy Gunawardena Department of Systems Biology, Harvard Medical School, Boston, MA, USA ¨ Michael Gunther Fachbereich Mathematik und Naturwissenschaften, Bergische Universit¨at Wuppertal, Wuppertal, Germany Max Gunzburger Department of Scientific Computing, Florida State University, Tallahassee, FL, USA Bertil Gustafsson Department of Information Technology, Uppsala University, Uppsala, Sweden Wolfgang Hackbusch Max-Planck-Institut f¨ur Mathematik in den Naturwissenschaften, Leipzig, Germany George A. Hagedorn Department of Mathematics, Center for Statistical Mechanics, Mathematical Physics, and Theoretical Chemistry, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA Ernst Hairer Section de Math´ematiques, Universit´e de Gen`eve, Gen`eve, Switzerland Nicholas Hale Oxford Centre for Collaborative Applied Mathematics (OCCAM), Mathematical Institute, University of Oxford, Oxford, UK\n\nContributors\n\nContributors\n\nxxi\n\nLaurence Halpern Laboratoire Analyse, G´eom´etrie and Applications, UMR 7539 CNRS, Universit´e Paris, Villetaneuse, France John Harlim Department of Mathematics and Department of Meteorology, Pennsylvania State University, State College, PA, USA Fr´ed´eric Hecht Laboratoire Jacques-Louis Lions, UPMC University of Paris 06 and CNRS, Paris, France Dieter W. Heermann Institute for Theoretical Physics, Heidelberg University, Heidelberg, Germany Gabor T. Herman Department of Computer Science, The Graduate Center of the City University of New York, New York, NY, USA Jan S. Hesthaven Division of Applied Mathematics, Brown University, Providence, RI, USA Nicholas J. Higham School of Mathematics, The University of Manchester, Manchester, UK Helge Holden Department of Mathematical Sciences, Norwegian University of Science and Technology, Trondheim, Norway Jan Homann Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA, USA Kai Hormann Universit`a della Svizzera italiana, Lugano, Switzerland Bei Hu Department of Applied and Computational Mathematics and Statistics, University of Notre Dame, Notre Dame, IN, USA Arne Bang Huseby Department of Mathematics, University of Oslo, Oslo, Norway Daan Huybrechs Department of Computer Science, K.U. Leuven, Leuven, Belgium Victor Isakov Department of Mathematics and Statistics, Wichita State University, Wichita, KS, USA Arieh Iserles Department of Applied Mathematics and Theoretical Physics, Centre for Mathematical Sciences, University of Cambridge, Cambridge, UK Kazufumi Ito Center for Research in Scientific Computation and Department of Mathematics, North Carolina State University, Raleigh, NC, USA Yasushi Ito Aviation Program Group, Japan Aerospace Exploration Agency, Mitaka, Tokyo, Japan Zdzisław Jackiewicz Department of Mathematics and Statistics, Arizona State University, Tempe, AZ, USA Vincent Jacquemet Centre de Recherche, Hˆopital du Sacr´e-Coeur de Montr´eal, Montr´eal, QC, Canada Department of Physiology, Universit´e de Montr´eal, Institut de G´enie Biom´edical and Groupe de Recherche en Sciences et Technologies Biom´edicales, Montr´eal, QC, Canada\n\nxxii\n\nLaurent O. Jay Department of Mathematics, The University of Iowa, Iowa City, IA, USA Shi Jin Department of Mathematics and Institute of Natural Science, Shanghai Jiao Tong University, Shanghai, China Department of Mathematics, University of Wisconsin, Madison, WI, USA Christopher R. Johnson Scientific Computing and Imaging Institute, University of Utah, Warnock Engineering Building, Salt Lake City, UT, USA ¨ Ansgar Jungel Institut f¨ur Analysis und Scientific Computing, Technische Universit¨at Wien, Wien, Austria Rajiv K. Kalia Department of Computer Science, Department of Physics and Astronomy, and Department of Chemical Engineering and Materials Science, University of Southern California, Los Angeles, CA, USA Erich L. Kaltofen Department of Mathematics, North Carolina State University, Raleigh, NC, USA George Em Karniadakis Division of Applied Mathematics, Brown University, Providence, RI, USA Boualem Khouider Department of Mathematics and Statistics, University of Victoria, Victoria, BC, Canada Isaac Klapper Department of Mathematical Sciences and Center for Biofilm Engineering, Montana State University, Bozeman, MT, USA Rupert Klein FB Mathematik and Informatik, Freie Universit¨at Berlin, Berlin, Germany Peter Kloeden FB Mathematik, J.W. Goethe-Universit¨at, Frankfurt am Main, Germany Matthew G. Knepley Searle Chemistry Laboratory, Computation Institute, University of Chicago, Chicago, IL, USA ¨ Huseyin Koc¸ak Department of Computer Science, University of Miami, Coral Gables, FL, USA Jussi T. Koivum¨aki The Center for Biomedical Computing, Simula Research Laboratory, Lysaker, Norway The Center for Cardiological Innovation, Oslo University Hospital, Oslo, Norway Anatoly B. Kolomeisky Department of Chemistry-MS60, Rice University, Houston, TX, USA Natalia L. Komarova Department of Mathematics, University of California Irvine, Irvine, CA, USA Nikos Komodakis Ecole des Ponts ParisTech, Universite Paris-Est, Champs-surMarne, France UMR Laboratoire d’informatique Gaspard-Monge, CNRS, Champs-sur-Marne, France\n\nContributors\n\nContributors\n\nxxiii\n\nAlper Korkmaz Department of Mathematics, C¸ankiri Karatekin University, C¸ankiri, Turkey Gunilla Kreiss Division of Scientific Computing, Department of Information Technology, Uppsala University, Uppsala, Sweden Peter Kuchment Mathematics Department, Texas A&M University, College Station, TX, USA ´ M. Pawan Kumar Ecole Centrale Paris, Chˆatenay-Malabry, France ´ Equipe GALEN, INRIA Saclay, ˆIle-de-France, France Angela Kunoth Institut f¨ur Mathematik, Universit¨at Paderborn, Paderborn, Germany Thomas Kurtz University of Wisconsin, Madison, WI, USA Gitta Kutyniok Institut f¨ur Mathematik, Technische Universit¨at Berlin, Berlin, Germany Michael Kwok-Po Ng Department of Mathematics, Hong Kong Baptist University, Kowloon, Hong Kong Hans Petter Langtangen Simula Research Laboratory, Center for Biomedical Computing, Fornebu, Norway Department of Informatics, University of Oslo, Oslo, Norway Mats G. Larson Department of Mathematics and Mathematical Statistics, Ume˚a University, Ume˚a, Sweden Matti Lassas Department of Mathematics and Statistics, University of Helsinki, Helsinki, Finland Chun-Kong Law Department of Applied Mathematics, National Sun Yat-sen University, Kaohsiung, Taiwan Armin Lechleiter Zentrum f¨ur Technomathematik, University of Bremen, Bremen, Germany Sunmi Lee School of Human Evolution and Social Change, Arizona State University, Tempe, AZ, USA Department of Applied Mathematics, Kyung Hee University, Giheung-gu, Yongin-si, Gyeonggi-do, Korea ¨ Ors Legeza Theoretical Solid State Physics, Hungarian Academy of Sciences, Budapest, Hungary Benedict Leimkuhler Edinburgh University School of Mathematics, Edinburgh, Scotland, UK Melvin Leok Department of Mathematics, University of California, San Diego, CA, USA Randall J. LeVeque Department of Applied Mathematics, University of Washington, Seattle, WA, USA Adrian J. Lew Mechanical Engineering, Stanford University, Stanford, CA, USA\n\nxxiv\n\nMathieu Lewin CNRS and D´epartement de Math´ematiques, Universit´e de CergyPontoise/Saint-Martin, Cergy-Pontoise, France Tien-Yien Li Department of Mathematics, Michigan State University, East Lansing, MI, USA Zhilin Li Center for Research in Scientific Computation and Department of Mathematics, North Carolina State University, Raleigh, NC, USA Knut-Andreas Lie Department of Applied Mathematics, SINTEF ICT, Oslo, Norway Guang Lin Fundamental and Computational Sciences Directorate, Pacific Northwest National Laboratory, Richland, WA, USA School of Mechanical Engineering, Purdue University, West Lafayette, IN, USA Department of Mathematics, Purdue University, West Lafayette, IN, USA Per L¨otstedt Department of Information Technology, Uppsala University, Uppsala, Sweden John S. Lowengrub Department of Mathematics, University of California, Irvine, CA, USA Benzhuo Lu Institute of Computational Mathematics and Scientific/Engineering Computing, Chinese Academy of Sciences, Beijing, China Christian Lubich Mathematisches Institut, Universit¨at T¨ubingen, T¨ubingen, Germany Franz Luef Department of Mathematics, University of California, Berkeley, CA, USA Li-Shi Luo Department of Mathematics and Statistics, Old Dominion University, Norfolk, VA, USA Beijing Computational Science Research Center, Beijing, China Mitchell Luskin School of Mathematics, University of Minnesota, Minneapolis, MN, USA Jianwei Ma Department of Mathematics, Harbin Institute of Technology, Harbin, China Yvon Maday Sorbonne Universit´es, UPMC Univ Paris 06, UMR 7598, Laboratoire Jacques-Louis Lions, Paris, France Institut Universitaire de France and Division of Applied Maths, Brown University, Providence, RI, USA Philip K. Maini Centre for Mathematical Biology, Mathematical Institute, University of Oxford, Oxford, UK Bradley T. Mallison Chevron Energy Technology Company, San Ramon, CA, USA Francisco Marcell´an Departamento de Matem´aticas, Universidad Carlos III de Madrid, Legan´es, Spain\n\nContributors\n\nContributors\n\nxxv\n\nPer-Gunnar Martinsson Department of Applied Mathematics, University of Colorado, Boulder, CO, USA Francesca Mazzia Dipartimento di Matematica, Universit`a degli Studi di Bari Aldo Moro, Bari, Italy Robert I. McLachlan Institute of Fundamental Sciences, Massey University, Palmerston North, New Zealand Joyce R. McLaughlin Department of Mathematical Sciences, Rensselaer Polytechnic Institute, Troy, NY, USA Volker Mehrmann Institut f¨ur Mathematik, MA 4-5 TU, Berlin, Germany Jens Markus Melenk Institute for Analysis and Scientific Computing, Vienna University of Technology, Wien, Austria Benedetta Mennucci Department of Chemistry, University of Pisa, Pisa, Italy Roeland Merks Life Sciences (MAC-4), Centrum Wiskunde and Informatica (CWI), Netherlands Consortium for Systems Biology/Netherlands Institute for Systems Biology (NCSB-NISB), Amsterdam, The Netherlands Aaron Meurer Department of Mathematics, New Mexico State University, Las Cruces, NM, USA Juan C. Meza School of Natural Sciences, University of California, Merced, CA, USA Owen D. Miller Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA Graeme Milton Department of Mathematics, The University of Utah, Salt Lake City, UT, USA J.D. Mireles James Department of Mathematics, Rutgers, The State University of New Jersey, Piscataway, NJ, USA Konstantin Mischaikow Department of Mathematics, Rutgers, The State University of New Jersey, Piscataway, NJ, USA Nicolas Mo¨es Ecole Centrale de Nantes, GeM Institute, UMR CNRS 6183, Nantes, France Mohammad Motamed Division of Mathematics and Computational Sciences and Engineering (MCSE), King Abdullah University of Science and Technology, Thuwal, Saudi Arabia Hans Z. Munthe-Kaas Department of Mathematics, University of Bergen, Bergen, Norway Ander Murua Konputazio Zientziak eta A.A. Saila, Informatika Fakultatea, UPV/EHU, Donostia/San Sebasti´an, Spain Aiichiro Nakano Department of Computer Science, Department of Physics and Astronomy, and Department of Chemical Engineering and Materials Science, University of Southern California, Los Angeles, CA, USA\n\nxxvi\n\nFrank Natterer Department of Mathematics and Computer Science, Institute of Computational Mathematics and Instrumental, University of M¨unster, M¨unster, Germany Philip C. Nelson Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA, USA Qing Nie Department of Mathematics, University of California, Irvine, CA, USA Harald Niederreiter RICAM, Austrian Academy of Sciences, Linz, Austria H. Frederik Nijhout Duke University, Durham, NC, USA Fabio Nobile EPFL Lausanne, Lausanne, Switzerland Dipartimento di Matematica “F. Brioschi”, Politecnico di Milano, Milan, Italy Sarah L. Noble School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA Clifford J. Nolan Department of Mathematics and Statistics, University of Limerick, Limerick, Ireland Ken-ichi Nomura Department of Computer Science, Department of Physics and Astronomy, and Department of Chemical Engineering and Materials Science, University of Southern California, Los Angeles, CA, USA Jan Martin Nordbotten Department of Mathematics, University of Bergen, Bergen, Norway W.L. Oberkampf Georgetown, TX, USA J. Tinsley Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin, Austin, TX, USA Roger Ohayon Structural Mechanics and Coupled Systems Laboratory, LMSSC, Conservatoire National des Arts et M´etiers (CNAM), Paris, France Luke Olson Department of Computer Science, University of Illinois at UrbanaChampaign, Urbana, IL, USA Sheehan Olver School of Mathematics and Statistics, The University of Sydney, Sydney, NSW, Australia Robert O’Malley Department of Applied Mathematics, University of Washington, Seattle, WA, USA Ahmet Omurtag Bio-Signal Group Inc., Brooklyn, NY, USA Department of Physiology and Pharmacology, State University of New York, Downstate Medical Center, Brooklyn, NY, USA Christoph Ortner Mathematics Institute, University of Warwick, Coventry, UK Alexander Ostermann Institut f¨ur Mathematik, Universit¨at Innsbruck, Innsbruck, Austria Jos´e-Angel Oteo Departament de F´ısica Te`orica, Universitat de Val`encia, Val`encia, Spain\n\nContributors\n\nContributors\n\nxxvii\n\nHans G. Othmer Department of Mathematics, University of Minnesota, Minneapolis, MN, USA Gianluca Panati Dipartimento di Matematica, Universit di Roma “La Sapienza”, Rome, Italy Alexander Panfilov Department of Physics and Astronomy, Gent University, Gent, Belgium Mateusz Paprocki refptr.pl, Wroclaw, Poland Nikos Paragios Ecole des Ponts ParisTech, Universite Paris-Est, Champs-surMarne, France ´ Ecole Centrale Paris, Chˆatenay-Malabry, France ´ Equipe GALEN, INRIA Saclay, ˆIle-de-France, France Lorenzo Pareschi Department of Mathematics, University of Ferrara, Ferrara, Italy John E. Pask Lawrence Livermore National Laboratory, Livermore, CA, USA Geir K. Pedersen Department of Mathematics, University of Oslo, Oslo, Norway Michele Piana Dipartimento di Matematica, Universit`a di Genova, CNR – SPIN, Genova, Italy Olivier Pinaud Department of Mathematics, Colorado State University, Fort Collins, CO, USA Gernot Plank Institute of Biophysics, Medical University of Graz, Graz, Austria Oxford e-Research Centre, University of Oxford, Oxford, UK Gerlind Plonka Institute for Numerical and Applied Mathematics, University of G¨ottingen, G¨ottingen, Germany Aleksander S. Popel Systems Biology Laboratory, Department of Biomedical Engineering, School of Medicine, The Johns Hopkins University, Baltimore, MD, USA Jason S. Prentice Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA, USA Luigi Preziosi Department of Mathematics, Politecnico di Torino, Torino, Italy Andrea Prosperetti Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA Department of Applied Sciences, University of Twente, Enschede, The Netherlands ´ Serge Prudhomme Department of Mathematics and Industrial Engineering, Ecole Polytechnique de Montr´eal, Montr´eal, QC, Canada Amina A. Qutub Department of Bioengineering, Rice University, Houston, TX, USA Venkat Raman Aerospace Engineering, University of Michigan, Ann Arbor, MI, USA\n\nxxviii\n\nRonny Ramlau Institute for Industrial Mathematics, Kepler University Linz, Linz, Austria Rakesh Ranjan NSF/CREST Center for Simulation, Visulization and Real-Time Prediction, The University of Texas at San Antonio, San Antonio, TX, USA Thilina Rathnayake Department of Computer Science, University of Moratuwa, Moratuwa, Sri Lanka Holger Rauhut Lehrstuhl C f¨ur Mathematik (Analysis), RWTH Aachen University, Aachen, Germany Stephane Redon Laboratoire Jean Kuntzmann, NANO-D – INRIA Grenoble – Rhˆone-Alpes, Saint Ismier, France Michael C. Reed Department of Mathematics, Duke University, Durham, NC, USA Peter Rentrop Technische Universit¨at M¨unchen, Fakult¨at Mathematik, Munich, Germany Nils Henrik Risebro Department of Mathematics, University of Oslo, Oslo, Norway Philip L. Roe Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI, USA Thorsten Rohwedder Institut f¨ur Mathematik, Technische Universit¨at Berlin, Berlin, Germany Dana Ron School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel Einar M. Rønquist Department of Mathematical Sciences, Norwegian University of Science and Technology, Trondheim, Norway Jos´e Ros Departament de F´ısica Te`orica and IFIC, Universitat de Val`encia-CSIC, Val`encia, Spain Christopher J. Roy Aerospace and Ocean Engineering Department, Virginia Tech, Blacksburg, VA, USA ¨ Ulrich Rude Department of Computer Science, University Erlangen-Nuremberg, Erlangen, Germany Siegfried M. Rump Institute for Reliable Computing, Hamburg University of Technology, Hamburg, Germany Faculty of Science and Engineering, Waseda University, Tokyo, Japan Ann E. Rundell School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA Weldon School of Biomedical Engineering, Purdue University, West Lafayette, IN, USA Robert D. Russell Department of Mathematics, Simon Fraser University, Burnaby, BC, Canada Lenya Ryzhik Department of Mathematics, Stanford University, Stanford, CA, USA\n\nContributors\n\nContributors\n\nxxix\n\nYousef Saad Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA Paul E. Sacks Department of Mathematics, Iowa State University, Ames, IA, USA Mikko Salo Department of Mathematics and Statistics, University of Jyv¨askyl¨a, Jyv¨askyl¨a, Finland Bj¨orn Sandstede Division of Applied Mathematics, Brown University, Providence, RI, USA J.M. Sanz-Serna Departamento de Matem´atica Aplicada, Universidad de Valladolid, Valladolid, Spain Murat Sari Department of Mathematics, Pamukkale University, Denizli, Turkey Trond Saue Laboratoire de Chimie et Physique Quantiques, CNRS/Universit´e Toulouse III, Toulouse, France Robert Schaback Institut f¨ur Numerische und Angewandte Mathematik (NAM), Georg-August-Universit¨at G¨ottingen, G¨ottingen, Germany Otmar Scherzer Computational Science Center, University of Vienna, Vienna, Austria Johann Radon Institute for Computational and Applied Mathematics (RICAM), Austrian Academy of Sciences, Linz, Austria Tamar Schlick Department of Chemistry, New York University, New York, NY, USA Reinhold Schneider Institut f¨ur Mathematik, Technische Universit¨at Berlin, Berlin, Germany John C. Schotland Department of Mathematics and Department of Physics, University of Michigan, Ann Arbor, MI, USA Christoph Schwab Seminar for Applied Mathematics (SAM), ETH Z¨urich, ETH Zentrum, Z¨urich, Switzerland Javier Segura Departamento de Matem´aticas, Estad´ıstica y Computaci´on, Universidad de Cantabria, Santander, Spain ´ Eric S´er´e CEREMADE, Universit´e Paris-Dauphine, Paris, France James A. Sethian Department of Mathematics, University of California, Berkeley, CA, USA Mathematics Department, Lawrence Berkeley National Laboratory, Berkeley, CA, USA ¨ Rudiger Seydel Mathematisches Institut, Universit¨at zu K¨oln, K¨oln, Germany Lawrence F. Shampine Department of Mathematics, Southern Methodist University, Dallas, TX, USA Qin Sheng Department of Mathematics, Baylor University, Waco, TX, USA\n\nxxx\n\nChi-Wang Shu Division of Applied Mathematics, Brown University, Providence, RI, USA Avram Sidi Computer Science Department, Technion – Israel Institute of Technology, Haifa, Israel David J. Silvester School of Mathematics, University of Manchester, Manchester, UK Bernd Simeon Department of Mathematics, Felix-Klein-Zentrum, TU Kaiserslautern, Kaiserslautern, Germany Kristina D. Simmons Department of Neuroscience, University of Pennsylvania, Philadelphia, PA, USA Mourad Sini Johann Radon Institute for Computational and Applied Mathematics (RICAM), Austrian Academy of Sciences, Linz, Austria Ralph Sinkus CRB3, Centre de Recherches Biom´edicales Bichat-Beaujon, Hˆopital Beaujon, Clichy, France Ian H. Sloan School of Mathematics and Statistics, University of New South Wales, Sydney, NSW, Australia Barry Smith Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA Moshe Sniedovich Department of Mathematics and Statistics, The University of Melbourne, Melbourne, VIC, Australia Gustaf S¨oderlind Centre for Mathematical Sciences, Numerical Analysis, Lund University, Lund, Sweden Christian Soize Laboratoire Mod´elisation et Simulation Multi-Echelle, MSME UMR 8208 CNRS, Universite Paris-Est, Marne-la-Vall´ee, France Jan Philip Solovej Department of Mathematics, University of Copenhagen, Copenhagen, Denmark Erkki Somersalo Department of Mathematics, Applied Mathematics and Statistics, Case Western Reserve University, Cleveland, OH, USA Thomas Sonar Computational Mathematics, TU Braunschweig, Braunschweig, Germany Euan A. Spence Department of Mathematical Sciences, University of Bath, Bath, UK Samuel N. Stechmann Department of Mathematics, University of Wisconsin– Madison, Madison, WI, USA Plamen Stefanov Department of Mathematics, Purdue University, West Lafayette, IN, USA Gabriel Stoltz Universit´e Paris Est, CERMICS, Projet MICMAC Ecole des Ponts, ParisTech – INRIA, Marne-la-Vall´ee, France\n\nContributors\n\nContributors\n\nxxxi\n\nArne Storjohann David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada ¨ Mathematical Institute, University of Oxford, Oxford, UK Endre Suli Joakim Sundnes Simula Research Laboratory, Lysaker, Norway Denis Talay INRIA Sophia Antipolis, Valbonne, France Martin A. Tanner Department of Statistics, Northwestern University, Evanston, IL, USA Vladimir Temlyakov Department of Mathematics, University of South Carolina, Columbia, SC, USA Steklov Institute of Mathematics, Moscow, Russia Nico M. Temme Centrum voor Wiskunde and Informatica (CWI), Amsterdam, The Netherlands ´ Tempone Division of Mathematics and Computational Sciences and EngineerRaul ing (MCSE), King Abdullah University of Science and Technology, Thuwal, Saudi Arabia Luis Tenorio Mathematical and Computer Sciences, Colorado School of Mines, Golden, CO, USA Kukatharmini Tharmaratnam Department of Mathematics, University of Oslo, Oslo, Norway Florian Theil Mathematics Institute, University of Warwick, Coventry, UK Franc¸oise Tisseur School of Mathematics, The University of Manchester, Manchester, UK Gaˇsper Tkaˇcik Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA, USA Øystein Tr˚asdahl Department of Mathematical Sciences, Norwegian University of Science and Technology, Trondheim, Norway M.V. Tretyakov School of Mathematical Sciences, University of Nottingham, Nottingham, UK Yen-Hsi Tsai Department of Mathematics, Center for Numerical Analysis, Institute for Computational Engineering and Science, University of Texas, Austin, TX, USA Xuemin Tu Department of Mathematics, University of Kansas, Lawrence, KS, USA Stefan Turek Applied Mathematics, TU Dortmund, Dortmund, Germany Gabriel Turinici D´epartement MIDO, CEREMADE, Universit´e Paris-Dauphine, Paris, France Aslak Tveito Simula Research Laboratory, Center for Biomedical Computing, Fornebu, Norway Department of Informatics, University of Oslo, Oslo, Norway\n\nxxxii\n\nGunther Uhlmann Department of Mathematics, University of Washington, Seattle, WA, USA Erik S. Van Vleck Department of Mathematics, University of Kansas, Lawrence, KS, USA Robert J. Vanderbei Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ, USA Priya Vashishta Department of Computer Science, Department of Physics and Astronomy, and Department of Chemical Engineering and Materials Science, University of Southern California, Los Angeles, CA, USA ´ Gilles Vilmart D´epartement de Math´ematiques, Ecole Normale Sup´erieure de Cachan, antenne de Bretagne, INRIA Rennes, IRMAR, CNRS, UEB, Bruz, France Gerhard Wanner Section de Math´ematiques, Universit´e de Gen`eve, Gen`eve, Switzerland Andy Wathen Mathematical Institute, Oxford University, Oxford, UK Christian Wieners Karlsruhe Institute of Technology, Institute for Applied and Numerical Mathematics, Karlsruhe, Germany Ragnar Winther Center of Mathematics for Applications, University of Oslo, Oslo, Norway Henryk Wo´zniakowski Department of Computer Science, Columbia University, New York, NY, USA Institute of Applied Mathematics, University of Warsaw, Warsaw, Poland Luiz Carlos Wrobel School of Engineering and Design, Brunel University London, Uxbridge, Middlesex, UK M. Wu Department of Mathematics, University of California, Irvine, CA, USA Christos Xenophontos Department of Mathematics and Statistics, University of Cyprus, Nicosia, Cyprus Dongbin Xiu Department of Mathematics and Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT, USA Eli Yablonovitch Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA Chao Yang Computational Research Division, MS-50F, Lawrence Berkeley National Laboratory, Berkeley, CA, USA Robert Young Department of Mathematics, University of Toronto, Toronto, ON, Canada Harry Yserentant Institut f¨ur Mathematik, Technische Universit¨at Berlin, Berlin, Germany\n\nContributors\n\nContributors\n\nxxxiii\n\nYa-xiang Yuan State Key Laboratory of Scientific/Engineering Computing, Institute of Computational Mathematics and Scientific/Engineering Computing, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, P.R. China Yong-Tao Zhang Department of Applied and Computational Mathematics and Statistics, University of Notre Dame, Notre Dame, IN, USA Ding-Xuan Zhou Department of Mathematics, City University of Hong Kong, Hong Kong, China Ting Zhou Department of Mathematics, Northeastern University, Boston, MA, USA Tarek I. Zohdi Department of Mechanical Engineering, University of California, Berkeley, CA, USA Enrique Zuazua BCAM – Basque Center for Applied Mathematics, Bilbao, Basque Country, Spain Ikerbasque – Basque Foundation for Science, Bilbao, Basque Country, Spain\n\nA\n\nproblems based on partial differential equations necessarily produces approximations that are in error when compared to the exact solutions. Methods to estimate discretization errors were proposed as early as the Serge Prudhomme 1970s [3] and initially focused on developing error estiDepartment of Mathematics and Industrial mators in terms of global (energy) norms (subdomain´ Engineering, Ecole Polytechnique de Montr´eal, residual methods, element residual methods, etc., see Montr´eal, QC, Canada [1,4,22] and references therein). One issue in those approaches is that they provide error estimates in abstract norms, which fail to inform the users about specific Synonyms quantities of engineering interest or local features of the solutions. It is only in the mid-1990s that a new type Adjoint-based method; Dual-weighted residual of error estimators was developed, usually referred to method; Goal-oriented error estimation as dual-weighted residual [6,8,9] or goal-oriented error estimators [15, 18], based on the solution of adjoint problems associated with user-defined quantities of inShort Description terest. In this case, the user is able to specify quantities A posteriori error estimation for quantities of interest of interest, written as functionals defined on the space is concerned with the development of computable es- of admissible solutions, and to assess the accuracy of timators of approximation errors (due to discretization the approximations in terms of these quantities. and/or model reduction) measured with respect to userdefined quantities of interest that are functionals of the Model Problem, Quantities of Interest, solutions to initial boundary-value problems.\n\nA Posteriori Error Estimates of Quantities of Interest\n\nand Adjoint Problem\n\nDescription A posteriori error estimation for quantities of interest is the activity in computational sciences and engineering that focuses on the development of computable estimators of the error in approximations of initialand/or boundary-value problems measured with respect to user-defined quantities of interest. The use of discretization methods (such as finite element and finite volume methods) to approximate mathematical\n\nFor the sake of simplicity in the exposition, we consider a linear boundary-value problem defined on an open bounded domain Rd ; d D 1; 2, or 3, with boundary @. Assume that the boundary is decomposed into two parts, D and N , on which Dirichlet and Neumann boundary conditions are prescribed, respectively. Let U and V be two Hilbert spaces. The weak formulation of an abstract linear problem reads: Find u 2 U such that B .u; v/ D F .v/ ; 8v 2 V (1)\n\n© Springer-Verlag Berlin Heidelberg 2015 B. Engquist (ed.), Encyclopedia of Applied and Computational Mathematics, DOI 10.1007/978-3-540-70529-1\n\n2\n\nA Posteriori Error Estimates of Quantities of Interest\n\nwhere B.; / is a bilinear form on U V and F ./ is a linear form on V . We suppose that B.; / and F ./ satisfy the hypotheses of the generalized Lax-Milgram Theorem to ensure that there exists a unique solution to the above problem. The goal of computer simulations is not necessarily to accurately approximate the solution u everywhere in the domain, but rather to predict certain quantities of the solution u. Quantities may be local averages of the solution, point-wise values (if u is sufficiently smooth), or local values of the gradient of u in some given direction. Let us suppose that the quantity of interest can be formulated as the linear functional Q: U ! R such that Z Z k .x/ u .x/ dx C kN .x/ u .x/ ds Q .u/ D\n\nN\n\nand u0 denotes the first derivative of u, subjected to the Dirichlet boundary condition u D 0 on @. We suppose that one is interested in evaluating u.x0 /; x0 2 . In this case, U D V D H01 ./ and Z Q .u/ D u .x0 / D\n\nı .x x0 / u .x/ dx\n\n(6)\n\nZ F .v/ D\n\nf .x/ v .x/ dx\n\n(7)\n\nZ\n\nu0 .x/ v 0 .x/ dx\n\nB .u; v/ D\n\n(8)\n\nwhere ı is the Dirac function. For this quantity of interest, the adjoint solution z is called the Green’s function (often denoted by G.x; x0 /) and allows one to calculate u at point x0 in terms of the loading term (2) f , i.e.,\n\nwhere k and kN represent two kernel functions (sometimes referred to as extractors) defined on and N , respectively, that are introduced in order to be able to consider local quantities. For example, the local average of u in a subdomain ! can be evaluated by choosing k as the characteristic function: ( Z 1 1 if x 2 ! k .x/ D k .x/ dx D 1 with j!j 0 otherwise (3)\n\nZ u .x0 / D Q .u/ D F .z/ D\n\nf .x/ G .x; x0 / dx (9)\n\nThe strong form of the adjoint problem reads in this case: .K T z0 /0 D ı.x x0 / in , subjected to the boundary condition z D 0 on @. We observe here that the differential operator associated with the adjoint problem is the same as that of the primal problem whenever the tensor K is symmetric.\n\nMost quantities of interest frequently encountered in Goal-Oriented Error Estimation applications can be written in the above form. With a given quantity of interest, let us introduce the We suppose that the solution u of the primal problem following problem in weak form: cannot be computed exactly and must be approximated by a discretization method such as the finite difference Find z 2 V such that B .v; z/ D Q .v/ ; 8v 2 U (4) or finite element methods. Denoting by h and p the size and polynomial degree of the finite elements, let This problem is called the dual or adjoint problem U h;p U and V h;p V be conforming finite element and its solution z 2 V is referred to as the adjoint subspaces of U and V , respectively, with dim U h;p D solution, the dual solution, the influence function, or dim V h;p . Using the Galerkin method, a finite element the generalized Green’s function. We emphasize here approximation uh;p to the primal problem (1) is given that the adjoint solution z to Problem (4) is unique by the following discrete problem: as long as the linear quantity Q./ is bounded. A fundamental observation using the primal problem (1) Find uh;p 2 U h;p such that with v D z and the adjoint problem (4) with v D u is B uh;p ; v h;p D F v h;p ; 8v h;p 2 V h;p (10) that Q .u/ D B .u; z/ D F .z/ (5) We denote by e 2 U the error in uh;p , i.e., e D u Example 1 (Green’s function) Let D .0; 1/ R. uh;p , and suppose that one is interested in evaluating We consider the problem of finding u that satisfies the quantity Q.u/: In other words, we aim at estimating .Ku0 /0 D f in , where K is a two-by-two tensor the error quantity:\n\nA Posteriori Error Estimates of Quantities of Interest\n\nE D Q .u/ Q uh;p\n\n3\n\n(11) An estimate of the error is then provided by\n\nUsing the adjoint problem (4) and the primal problem (1), the error in the quantity of interest can be represented as\n\nE D R uh;p I zQ C R uh;p I z zQ R uh;p I zQ WD (16)\n\nRemark 1 Some error estimators have been proposed that consider the approximate solution zh;p to (14) h;p in order to get and estimate h;p the error \" z z h;p (12) E R u I \" or simply, E B.u u ; \"/. See for example [15, 17–19]. where R uh;p I is the residual functional associated Remark 2 The goal-oriented error estimation procewith the primal problem. From the discrete problem dure presented so far can be easily extended to linear (10), one can also straightforwardly derive the so- initial boundary-value problem. In this case, the adjoint called orthogonality property problem is a problem that is solved backward in time.\n\nE D B .u; z/ B uh;p ; z D F .z/ B uh;p ; z WD R uh;p I z\n\nR uh;p I v h;p D F uh;p B uh;p ; v h;p D 0;\n\nv h;p 2 V h;p (13)\n\nwhich states that the solution uh;p is in some sense the “best approximation” of u in U h;p . From the error representation (12), it is clear that the error in the quantity of interest could be obtained if the adjoint solution z were known. Unfortunately, the adjoint problem (4) cannot be solved exactly and only on rare occasions is an analytical solution available. The idea is thus to compute a discrete (finite element) approximation zQ of the adjoint solution z. If one considers the finite element solution zh;p on space VQ D V h;p , with test functions vQ 2 UQ D U h;p (i.e., using the same finite element spaces as for uh;p ), i.e., by solving the problem\n\nIn order to capture errors due to the spatial and temporal discretization, the adjoint problem is approximated by halving the mesh size and time step.\n\nAdaptive Strategies The estimator D R uh;p I zQ can be used for mesh adaptation. Let h;p zQ be a projection of zQ on V h;p . Thanks to the orthogonality property, the estimate is equivalent to D R uh;p I zQ h;p zQ . The objective is then to decompose into element-wise contributions. Recalling the definition of the residual, one has D R uh;p I zQ h;p zQ D F zQ h;p zQ B uh;p I zQ h;p zQ\n\n(17)\n\nBecause F ./ and B.; / are defined as integrals over the whole computational domain , they can be h;p h;p decomposed into a sum of contributions FK ./ and Find z 2 V such that BK .; / on each element of the mesh. It follows that h;p h;p h;p DQ v ; 8v h;p 2 U h;p (14) B v ;z X D FK zQ h;p zQ BK uh;p I zQ h;p zQ then it is straightforward to show K from the orthogonal X ity property that R uh;p I zh;p D 0. In other words, WD K (18) such an approximation of the adjoint solution would K fail to bring sufficient information about the error in the quantity of interest. It implies that the adjoint needs The quantities K define contributions on each element to be approximated on a discretization vector space K to the error in the quantity of interest. The represenfiner than V h;p . In practice, one usually selects VQ D tation of these contributions is not unique as one can V h=2;p ; VQ D V h;pC1 , or even VQ D V h=2;pC1 (and actually integrate by parts the terms BK to introduce similarly for UQ ) to get the approximation: interior residuals (with respect to the strong form of the differential equation inside each element) and jump Find zQ 2 VQ such that B .v; Q zQ/ D Q .v/ Q ; 8vQ 2 UQ residuals (with respect to solution fluxes across the (15) interfaces of the elements). We do not present here\n\nA\n\n4\n\nA Posteriori Error Estimates of Quantities of Interest\n\nthe details of the different representations as these are where we have assumed that Q and B are differentiable problem-dependent. with respect to u, i.e., One can use the contributions K to determine refinement indicators in an adaptive mesh refinement h;p Q uh;p C v Q uh;p 0 Q u I v D lim (AMR) strategy. Actually, there exist several methods !0 for element marking, such as the maximum strategy, h;p h;p the fixed fraction strategy, the equidistribution strategy, B 0 uh;p I v; z D lim B u C vI z B u I v !0 etc. In the case of the maximum contribution method, (22) one considers the refinement indicator K on each element K; 0 K 1, as: and Q and B denote higher-order terms due to jK j K WD (19) the linearization of Q and B, respectively. In the maxK jK j above error representation, we have also introduced the All elements such that K ˛ can then be marked for adjoint problem: refinement (with respect to h, p; or to h and p), where ˛ is a user-defined tolerance chosen between zero and Find z 2 V such that unity. In practice, the parameter is usually chosen to be (23) B 0 uh;p I v; z D Q0 uh;p I v ; 8v 2 U ˛ D 0:5. One area of active research in AMR deals with the theoretical analysis of adaptive methods, the objective It is important to note that the adjoint problem is a being to show whether the adaptive methods ensure linear problem in z, which makes it easier to solve than convergence and provide optimal meshes [13, 14]. the primal problem. Proceeding as in the linear case, one can solve for an approximate solution zQ 2 VQ to the adjoint problem and derive the error estimator Extension to Nonlinear Problems Goal-oriented error estimators, originally defined for linear boundary-value problems and linear quantities of interest, have been extended to the case of nonlinear problems and nonlinear quantities of interest. Let u 2 U be the solution of the nonlinear problem:\n\nE D Q .u/ Q uh;p D R uh;p I zQ C R uh;p I z zQ C R uh;p I zQ WD\n\n(24)\n\nAs before, the estimator can be decomposed into Find u 2 U such that B .uI v/ D F .v/ ; 8v 2 V element-wise contributions K for mesh adaptation. (20) where B.I / is a semilinear form, possibly nonlinear with respect to the first variable. Suppose also that one Concluding Remarks is interested in the nonlinear quantity of interest Q.u/ and that uh;p is a finite element approximation of the Goal-oriented error estimation is a topic that, to date, is solution u to (20). Then, by linearization, fairly well understood. It has actually been extended to modeling error estimation, where the modeling error h;p E D Q .u/ Q u is the difference between the solutions of two differ ent models [10, 16], and has been applied to numer0 h;p h;p D Q u Iu u C Q ous applications of engineering and scientific interests (solid mechanics [21], fluid mechanics [19], wave D B 0 uh;p I u uh;p ; z C Q (21) phenomena[5], Cahn-Hilliard equations [23], multi D B.uI z/ B uh;p I z C Q B scale modeling [7, 20], partial differential equations with uncertain coefficients [2, 11, 12] etc.). The main D F .v/ B uh;p I z C Q B challenge in goal-oriented error estimation essentially WD R uh;p I z C Q B lies in the determination of approximate solutions of\n\nA Priori and A Posteriori Error Analysis in Chemistry\n\n5\n\nthe adjoint problem that provide for accurate and re- 16. Oden, J.T., Prudhomme, S.: Estimation of modeling error in computational mechanics. J. Comput. Phys. 182, 496–515 liable error estimators while being cost-effective from (2002) a computational point of view. Another challenge in 17. Paraschivoiu, M., Peraire, J., Patera, A.T.: A posteriori finite the case of nonlinear problems is the design of adapelement bounds for linear-functional outputs of elliptic partial differential equations. Comput. Methods Appl. Mech. tive methods that simultaneously control discretization Eng. 150(1–4), 289–312 (1997) errors and linearization errors.\n\nReferences 1. Ainsworth, M., Oden, J.T.: A Posteriori Error Estimation in Finite Element Analysis. Wiley, New York (2000) 2. Almeida, R.C., Oden, J.T.: Solution verification, goaloriented adaptive methods for stochastic advectiondiffusion problems. Comput. Methods Appl. Mech. Eng. 199(37–40), 2472–2486 (2010) 3. Babuˇska, I., Rheinboldt, W.C.: Error estimates for adaptive finite element computations. SIAM J. Numer. Anal. 15(4), 736–754 (1978) 4. Babuˇska, I., Strouboulis, T.: The Finite Element Method and Its Reliability. Oxford University Press, New York (2001) 5. Bangerth, W., Rannacher, R.: Adaptive finite element techniques for the acoustic wave equation. J. Comput. Acoust. 9(2), 575–591 (2001) 6. Bangerth, W., Rannacher, R.: Adaptive Finite Element Methods for Differential Equations. Lectures in Mathematics. ETH Z¨urich, Birkh¨auser (2003) 7. Bauman, P.T., Oden, J.T., Prudhomme, S.: Adaptive multiscale modeling of polymeric materials with Arlequin coupling and Goals algorithms. Comput. Methods Appl. Mech. Eng. 198, 799–818 (2009) 8. Becker, R., Rannacher, R.: A feed-back approach to error control in finite element methods: basic analysis and examples. East West J. Numer. Math. 4, 237–264 (1996) 9. Becker, R., Rannacher, R.: An optimal control approach to a posteriori error estimation in finite element methods. Acta Numer. 10, 1–102 (2001) 10. Braack, M., Ern, A.: A posteriori control of modeling errors and discretization errors. Multiscale Model. Simul. 1(2), 221–238 (2003) 11. Butler, T., Dawson, C., Wildey, T.: A posteriori error analysis of stochastic spectral methods. SIAM J. Sci. Comput. 33, 1267–1291 (2011) 12. Mathelin, L., Le Maˆıtre, O.: Dual-based a posteriori error estimate for stochastic finite element methods. Commun. Appl. Math. Comput. Sci. 2(1), 83–115 (2007) 13. Mommer, M., Stevenson, R.P.: A goal-oriented adaptive finite element method with convergence rates. SIAM J. Numer. Anal. 47(2), 861–886 (2009) 14. Nochetto, R.H., Siebert, K.G., Veeser, A.: Theory of adaptive finite element methods: An introduction. In: DeVore, R.A., Kunoth, A. (eds.) Multiscale, Nonlinear and Adaptive Approximation, pp. 409–542. Springer, Berlin (2009) 15. Oden, J.T., Prudhomme, S.: Goal-oriented error estimation and adaptivity for the finite element method. Comput. Math. Appl. 41, 735–756 (2001)\n\n18. Prudhomme, S., Oden, J.T.: On goal-oriented error estimation for elliptic problems: application to the control of pointwise errors. Comput. Methods Appl. Mech. Eng. 176, 313–331 (1999) 19. Prudhomme, S., Oden, J.T.: Computable error estimators and adaptive techniques for fluid flow problems. In: Barth, T.J., Deconinck, H. (eds.) Error Estimation and Adaptive Discretization Methods in Computational Fluid Dynamics. Lecture Notes in Computational Science and Engineering, vol. 25, pp. 207–268. Springer, Heidelberg (2003) 20. Prudhomme, S., Chamoin, L., ben Dhia, H., Bauman, P.T.: An adaptive strategy for the control of modeling error in two-dimensional atomic-to-continuum coupling simulations. Comput. Methods Appl. Mech. Eng. 198(21–26), 1887–1901 (2001) 21. Stein, E., R¨uter, M.: Finite element methods for elasticity with error-controlled discretization and model adaptivity. In: Stein, E., de Borst, R., Hughes, T.J.R. (eds.) Encyclopedia of Computational Mechanics. Solids and Structures, vol. 2, chapter 2, pp. 5–58. Wiley (2004) 22. Verf¨urth, R.: A Posteriori Error Estimation Techniques for Finite Element Methods. Oxford University Press, Oxford (2013) 23. van der Zee, K.G., Oden, J.T., Prudhomme, S., HawkinsDaarud, A.J.: Goal-oriented error estimation for CahnHilliard models of binary phase transition. Numer. Methods Partial Differ. Equ. 27(1), 160–196 (2011)\n\nA Priori and A Posteriori Error Analysis in Chemistry Yvon Maday Sorbonne Universit´es, UPMC Univ Paris 06, UMR 7598, Laboratoire Jacques-Louis Lions, Paris, France Institut Universitaire de France and Division of Applied Maths, Brown University, Providence, RI, USA\n\nSynonyms Convergence analysis; Error estimates; Guaranteed accuracy; Refinement\n\nA\n\n6\n\nDefinition For a numerical discretization chosen to approximate the solution of a given problem or for an algorithm used to solve the discrete problem resulting from the previous discretization, a priori analysis explains how the method behaves and to which extent the numerical solution that is produced from the discretization/algorithm is close to the exact one. It also allows to compare the numerical method of interest with another one. With a priori analysis though, there is no definite certainty that a given computation provides a good enough approximation. It is only when the number of degrees of freedom and the complexity of the computation is large enough that the convergence of the numerical method can be guaranteedly achieved. On the contrary, a posteriori analysis provides bounds on the error on the solution or the output coming out of the simulation. The concept of a posteriori analysis can even contain an error indicator that informs the user on the strategy he should follow in order to improve the accuracy of its results by increasing the number of degrees of freedom in case where the a posteriori estimation is not good enough.\n\nOverview Computational chemistry is a vast field including a variety of different approaches. At the root, the Schr¨odinger equation plays a fundamental role since it describes the behavior of matter, at the finest level, with no empirical constant or input. However, almost no simulation is based on the resolution of this equation since it is exceedingly expensive to solve for more than about ten atoms. The reason is that the wave function that describes at this level the state of matter is a time-dependent function of 3 .N C M / variable when a molecule with M nucleons and N electrons all around is to be simulated. Many approaches have been proposed to circumvent this impossibility to build a numerical simulation well suited for these equations. The first element takes into account the fact that the understanding of the state of the matter at the ground state, i.e., at the state of minimal energy, is already a valuable information out of which the calculation of excited states or unsteady solutions comes as a second step. This allows to get rid of the time dependency in these solution. The second element,\n\nA Priori and A Posteriori Error Analysis in Chemistry\n\nknown as the Born-Oppenheimer approximation, is based on a dimensional analysis that allows somehow to decouple, among the particles that are in presence, the heaviest ones (the nucleons) from the lightest ones (the electrons); see the entry Born–Oppenheimer Approximation, Adiabatic Limit, and Related Math. Issues. In this approximation, the behavior of the electrons is considered, given a fixed state of the nuclei, while the analysis of the behavior of the nucleons is done in a frame where the interaction with the electron is replaced by a potential in which the nucleons evolve. As for the analysis of the behavior of the electrons, the density functional theory is nowadays widely used since the seminal work of Hohenberg and Kohn [12] that establishes a one-toone correspondence between the ground state electron density and the ground state wave function of a manyparticle system. This is the archetype of ab initio approximations for electronic structures. Another approach is the Hartree-Fock and post-Hartree-Fock approximation, where the electronic wave function is sought as minimizing the ground state Schr¨odinger equation under the constraint of being a (sum of) Slater determinant(s) of one-particle orbitals. Invented by Dirac and Heisenberg, these determinants appear as a simple way to impose the antisymmetric property of the exact solution, resulting from the Pauli exclusion principle. Time dependance can be restored in these models to give rise to time-dependent Hartree or Hartree-Fock approximations. When the behavior of the electrons is understood, the analysis of the nucleons can then be based on molecular mechanics or dynamics, where the quantum electronic information is aggregated into force fields and the charged nuclei move in these force fields. Whatever model approximation is used, from ab initio approaches to empirical ones where models are added on the top of the Schr¨odinger equation, the problems are still challenging for the computation. Indeed, the complexity due to the number of variables of the N C M –body wave function solution of the linear Schr¨odinger model is replaced by complex and large nonlinearities in the resulting equations, the precise formula of which is actually not known in the DFT framework (we refer to Density Functional Theory). The most common implementation is based on the Kohn-Sham model [14]. Note that the most accurate DFT calculations employ semi-empirical corrections, whose functional form is usually derived from a lot of\n\nA Priori and A Posteriori Error Analysis in Chemistry\n\nknow-how and depends on parameters that need to be properly tuned up. The a priori and a posteriori analysis allows at this stage to quantify the quality of the actual model that is chosen as a surrogate to the Schr¨odinger equations. Let us denote as IF.U / D 0 the Schr¨odinger model and U the associated solution for conveniency and by F .u/ D 0 the chosen model with associated solution u, that is, a (set of) function(s) in three variables and from which informations about U can be reconstructed. This first stage of (modeling) approximation is complemented with a second step related to numerical implementations on computer that actually involves two associated stages of approximation. The first one, standard for approximating solution of partial differential equations, corresponds to the discretization of functions of three variables in IR by discrete functions depending on a finite (and generally high) number of degrees of freedom the most common candidates are found in the family of finite element or spectral (plane waves) discretizations when variational framework is present (generally preferred as it represents well the minimization of the associated energy traducing the ground state that is searched) or in the family of finite difference discretizations. We denote by Fı .uı / D 0 the associated discretization with uı being a function belonging to a finite dimensional space. The a priori and a posteriori analysis allows here to quantify the quality of the numerical discretization for the particular model that is considered. The second stage associated with approximation is related to the algorithms that are used in order to solve the finite dimensional problem that comes out of the discretization method. An example that illustrates this feature is provided by the way the nonlinearities of the model are treated since computers can only solve a linear system of finite dimension. Classically, this imply the use of iterative solvers, based on fixed point strategies. In order to illustrate this point, we first have to indicate that the problem to be solved is nonlinear. This can be done by writing the problem under the form Fı .uı / D F .uı I uı /; the iterative solver then consists in computing uı as the limit, when the iteration parameter k tends to infinity, of ukı solution of the fixed point iterative procedure F .ukı I uk1 ı / D 0. In order to provide a precise enough approximation in a small enough time, the algorithm that is used for these iterations must be smart enough and stopped at the right number of iterations so that the ukı is close enough to its limit uı . Here again, a priori\n\n7\n\nand a posteriori analysis allows to be confident in the convergence of the algorithm and the stopping criteria. Numerical analysis is involved in the three stages above in the approximation process and requires different pieces of analysis. All this is quite recent work and only very partially covered. We present in the following sections some details of the existing results. We refer also to Numerical Analysis of Eigenproblems for Electronic Structure Calculations for a particular focus on a priori error analysis for nonlinear eigenproblems.\n\nError on the Model On the a priori side, the number of existing work is very small. In [11] for instance, the author considers the approximation by Hartree Fock (we refer to Hartree–Fock Type Methods) and post-HartreeFock approaches of the Schr¨odinger equation (we refer to Post-Hartree-Fock Methods and Excited States Modeling) – CI (configuration interaction) and MCSCF (multiconfiguration, self-consistent field) methods. It is proven that such an approach, even if it is based on an expansion on many Slater determinant, is never exact. However, MC-SCF methods approximate energies correctly and also wavefunctions, in the limit where the number K of Slater determinants goes to infinity. An actual quantification of the decay rate of the difference between the MC-SCF energy based on K Slater determinants and the exact quantum-mechanical ground state energy as K becomes large is quoted as an open question in this entry and is still as far as we know. For a more complete analysis, where the excited states are also considered, see [17]. Another piece of a priori analysis is presented in [9] and deals with the convergence of the timedependent Hartree problem, in which the solution to the Schr¨odinger equation is searched as a sum of K tensorial products known as the MCTDH approximation. The a priori analysis of the difference between the exact solution u.t/ (to the Schr¨odinger equation) and the discrete solution uK .t/ states that the error is upper bounded by the sum of the best approximation error (of u.t/ by a sum of K tensorial products) and a linear in time growing contribution ct \" where \" measures in some sense the best approximation error in the residual (Schr¨odinger equation) norm (close to a H 2 -type norm). We refer to [9] for the precise statement of the analysis.\n\nA\n\n8\n\nAs far as we know, there exists currently no result of a posteriori type in the literature on the evaluation of the error on the model. Yet, we can remind that such an a posteriori analysis exists in other contexts (see, e.g., [4] for a coupling of two models: one full and one degenerated that are used in different regions) leading to the idea that this is a feasible mathematical and numerical tool that would be very helpful in the present context.\n\nError on the Discretization The analysis of the discretization error is certainly the one that has been the most considered in the literature, even if the current results in the chemistry field are mostly very recent and still partial. There are essentially three types of discretizations differing from the basis sets that are chosen to approximate the molecular orbitals or the density functional and from the formulation of the discrete problem: (i) those based on a strong formulation of the equations (finite difference methods; see, e.g., the entry Finite Difference Methods) where we are not aware of any full numerical analysis justification, (ii) those based on variational approximations either with universal complete basis sets (finite element; see, e.g., the entry Finite Element Methods for Electronic Structure, plane wave, wavelets methods [13]) or (iii) with linear combination of ad hoc atomic orbitals (LCAO, e.g., of Gaussian basis sets, reduced basis methods [7,19]). For the two first approaches, the universality of the discrete approximation spaces allows to state that there exists a discrete function (e.g., the best fit, i.e., the projection in some appropriated norm) that is as close to the exact solution as required, at least whenever the dimension of the discrete space goes to infinity (known, e.g., for the Hartree-Fock approximation as the Hartree-Fock limit) and provided some regularity exists on the solution. The challenge is then to propose a discrete method able to select a unique solution in the discrete space that is almost as good as the best fit. This challenge is actually quite simple to face in case of a linear problem, but is very difficult if the problem is nonlinear – and as we explained above, the problem in the current context are almost always nonlinear. For the last type of discretization, the basis set is problem dependent and is only built up to approximate the solution of the very problem under consideration.\n\nA Priori and A Posteriori Error Analysis in Chemistry\n\nThere are then two challenges: (i) does the best fit in this ad hoc discrete space eventually approximate well the exact solution and (ii) does the discrete method propose a fair enough approximation and again how does it compare with the best fit. Most of the works related to the a priori convergence analysis deal with the second type of approximation above. A summary of these results focusing on the particular case of the computation of the ground state for electronic structures (resulting in the approximation of eigenstates for a nonlinear eigenvalue problem) is presented in the above quoted entry Numerical Analysis of Eigenproblems for Electronic Structure Calculations and states a complete enough convergence analysis with optimal rate on both the energies and wave functions, provided that the numerical integration rules that are used to compute the integrals stemming out of the variational formulation are computed with a good enough accuracy. We shall thus mainly focus here on the existing results that are not detailed in the above cited entry. For LCAO variational approximations, the choice of the basis defining the discrete space is generally taken as follows: (i) to any atom A of the periodic table, a of nA linearly independent AO is associated, ˚collection nA 1nnA ; (ii) the discrete basis associated to a given molecule is built up by gathering all AO relative to the atoms in the ˚ e.g., for the molecule A-B, one ˚ system, chooses\n\nD 1A .x xN A /; ; nAA .x xN A /I 1B .x xN B /; ; nBB .x xN B /g ; where xN A , xN B denote the respective positions in IR3 of the atoms A and B. After the paper of Boys’ [2], the polynomial Gaussian basis sets have become of standard use for the variational approximations of the solution of the Hartree-Fock equations. What is remarkable – even though a large amount of know-how is required in order to define the proper AOs – is that actually very few AOs are required to yield a very good approximation of the ground state of any molecular system. There exists very few papers dedicated to the a priori convergence; most of the current studies are restricted to the particular case of hydrogenoid solutions, i.e., the solution of the Hydrogen atom, whose analytic expression is known. An example is given by the papers [16] and [3] where exponential convergence is proven. By analogy, these results are extrapolated on molecules, looking at the shape of the cusps that the solution exhibit, and explain somehow the good behavior of these approximations; currently,\n\nA Priori and A Posteriori Error Analysis in Chemistry\n\nno complete analysis exists as far as we are aware of. Based on these results related to the best fit, the numerical analysis of the variational approximation of the ground state for Hartree-Fock or Kohn-Sham equations can proceed. This analysis uses the general paradigm of definition of explicit lower and upper bounds for outputs depending on the solution of a partial differential equation and is explained in [20] for the a posteriori analysis, and latter in [8] for the a priori analysis: optimal results are proven, under a hypothesis stating a kind of local uniqueness of the ground state solution. In a different direction, another problem recently analyzed deals with the approximation of the electronic structure on perturbed lattices of atoms. This model leads to the analysis of the spectrum of perturbations of periodic operators either for the Schr¨odinger equations or the Dirac equations. The periodic operator has a spectrum that is composed of bands (that can be analyzed by Bloch-Floquet theory); the perturbed operator has a spectrum that is composed of the same bands with possibly eigenvalues in the gaps. These localized eigenvalues are of physical interest, and the numerical methods should be able to approximate them well. The problem is that, very often, reasonable enough approximations produce discrete eigenvalues that have nothing to do with exact eigenvalues. These are named as spurious eigenvalues and analyzed in [1, 5, 18] from an a priori point of view. Some constructive approaches have been proposed in these papers to avoid the phenomenon of spurious eigenvalues and get optimal a priori convergence rate for the approximation of true eigenstates both for the wave functions and associated energies.\n\n9\n\npoint of view, the correct number of iterations is not known and very few analysis is done in this direction. From the a priori point of view, the only analysis we are aware of is the self-consistent field (SCF) algorithms that has been, for years, the strategy of choice to solve the discretized Hartree-Fock equation (see e.g., Self-Consistent Field (SCF) Algorithms). In practice, though, the method has revealed successes and failures both in convergence and in convergence rates. A large amount of literature has proposed various tricks to overcome the lack of robustness of the original Roothaan algorithm. It is reported that this algorithm sometimes converges toward a solution to the HF equations but frequently oscillates between two states. The definitive answer to the questions raised by these convergence problems has been given by a series of papers of Canc`es and coauthors among which [6, 15]. An interesting cycle of order 2 has been identified in the behavior of the algorithm in frequent cases explaining why the algorithm oscillates between two states, none of which being a solution of the original nonlinear problem. The simple addition of a penalty term in the same spirit as a basic level shift or DIIS algorithms allows to avoid this oscillating behavior and corrects definitively the fixed point algorithm. This mathematical analysis has been a very important success in the community of computational chemists and has been implemented as a default method in classical softwares. The above results are almost the only ones existing in this category. We are still at the very beginning of this kind of analysis focussing on the algorithms, the variety of which is even larger than the variety of discrete schemes.\n\nConclusion Error on the Algorithm Most of the algorithms used for solving the above problems after a proper discretization has been implemented are iterative ones, either to solve a linear problem through a conjugate gradient algorithm or to solve an eigenvalue problem through a QR or a simple power algorithm (see, e.g., the entry Fast Methods for Large Eigenvalues Problems for Chemistry) or finally to take into account the nonlinearities arising in the problem being solved by a fixed point procedure. These iterative algorithms may eventually converge (or not) after a large enough number of iterations. From the practical\n\nWe have presented some results on the a priori and a posteriori analysis focussing on approximations on the model, on the discretization strategy, and on the a chosen algorithm to simulate the solutions to problems in chemistry. Most of the results are partial only, and we are quite far from a full a posteriori analysis that would tell the user, after he performed a given discretization with a given number of degrees of freedom resulting in a discrete problem solved with a given algorithm using a fixed number of iterations, how far the discrete solution coming out from the computer is from the exact solution and we are even farther from a\n\nA\n\n10\n\nprocedure able to tell what should be done in order to improve the accuracy: either to increase the number of degrees of freedom or the increase number of iterations or change the model. This procedure though exists for a totally different context as is explained in [10]. This is certainly a direction of research and effort to be done by applied mathematicians that will lead to future and helpful progress for the reliability of approximations in this field.\n\nReferences 1. Boulton, L., Boussa, N., Lewin, M.: Generalized Weyl theorem and spectral pollution in the Galerkin method. http://arxiv.org/pdf/1011.3634v2 2. Boys, S.F.: Electronic wavefunction I. A general method of calculation for the stationary states of any molecular system. Proc. R. Soc. A 200, 542–554 (1950) 3. Braess, D.: Asymptotics for the approximation of wave functions by sums of exponential sums. J. Approx. Theory 83, 93–103 (1995) 4. Brezzi, F., Canuto, C., Russo, A.: A self-adaptive formulation for the Euler/NavierStokes coupling. CMAME Arch. 73(3), 317–330 (1989) 5. Canc`es, E., Ehrlacher, V., Maday, Y.: Periodic Schrdinger operators with local defects and spectral pollution, arXiv:1111.3892 6. Canc`es, E., LeBris, C.: On the convergence of SCF algorithms for the HartreeFock equations. Math. Model. Numer. Anal. 34, 749–774 (2000) 7. Canc`es, E., LeBris, C., Maday, Y., Turinici, G.: Towards reduced basis approaches in ab initio electronic structure computations. J. Sci. Comput. 17(1), 461–469 (2002) 8. Canc`es, E., LeBris, C., Maday, Y.: M´ethodes Math´ematiques en chimie quantique: une Introduction (in French). Math´ematiques and Applications (Berlin), vol. 53. Springer, Berlin (2006) 9. Conte, D., Lubich, C.: An error analysis of the multiconfiguration time-dependent Hartree method of quantum dynamics. ESAIM M2 AN 44, 759–780 (2010) 10. El Alaoui, L., Ern, A., Vohralk, M.: Guaranteed and robust a posteriori error estimates and balancing discretization and linearization errors for monotone nonlinear problems. Comput. Method Appl. Mech. Eng. 200, 2782–2795 (2011) 11. Friesecke, G.: The multiconfiguration equations for atoms and molecules: charge quantization and existence of solutions. Arch. Ration. Mech. Anal. 169, 35–71 (2003) 12. Hohenberg, P., Kohn, W.: Inhomogeneous electron gas. Phys. Rev. 136(3B), B864–B871 (1964) 13. Kobus, J., Quiney, H.M., Wilson, S.: A comparison of finite difference and finite basis set Hartree-Fock calculations for the N2 molecule with finite nuclei. J. Phys. B Atomic Mol. Opt. Phys. 34, 10 (2001) 14. Kohn, W., Sham, L.J.: Self-consistent equations including exchange and correlation effects. Phys. Rev. 140(4A), A1133–A1138 (1965)\n\nAbsorbing Boundaries and Layers 15. Kudin, K., Scuseria, G.E., Canc`es, E.: A black-box selfconsistent field convergence algorithm: one step closer. J. Chem. Phys. 116, 8255–8261 (2002) 16. Kutzelnigg, W.: Theory of the expansion of wave functions in a Gaussian basis. Int. J. Quantum Chem. 51, 447–463 (1994) 17. Lewin, M.: Solution of multiconfiguration equations in quantum chemistry. Arch. Ration. Mech. Anal. 171, 83–114 (2004) ´ Spectral pollution and how to avoid 18. Lewin, M., S´er´e, E.: it (with applications to Dirac and periodic Schr¨odinger operators). Proc. Lond. Math. Soc. 100(3), 864–900 (2010) 19. Maday, Y., Razafison, U.: A reduced basis method applied to the restricted HartreeFock equations. Comptes Rendus Math. 346(3–4), 243–248 (2008) 20. Maday, Y., Turinici, G.: Error bars and quadratically convergent methods for the numerical simulation of the Hartree-Fock equations. Numer. Math. 94, 739–770 (2003)\n\nAbsorbing Boundaries and Layers Laurence Halpern Laboratoire Analyse, G´eom´etrie and Applications, UMR 7539 CNRS, Universit´e Paris, Villetaneuse, France\n\nSynonyms Artificial; Computational; Free-Space; Nonreflective; Open or Far-Field Boundary Conditions; Sponge Layers\n\nSummary Absorbing boundaries and layers are used to limit the computational domain in the numerical approximation of partial differential equations in infinite domains, such as wave propagation problems or computational fluid dynamics. In a typical seismic problem, the wave equation Lu D f must be solved in the subsurface with data g on the surface; the solution u is sought in the domain DS in magenta in Fig. 1. The domain in blue is a computational layer LC ; their union is the computational domain DC .\n\nAbsorbing Boundaries and Layers\n\n11\n\nAbsorbing Boundaries and Layers, Fig. 1 Absorbing layer (courtesy of L. M´etivier [19])\n\nA DS\n\nIn the theory of absorbing boundaries, the original equation is solved in DC , and a special boundary condition is imposed on its boundary to simulate the entire subsurface, which amounts to reducing as much as possible the reflection of waves inside the domain of interest DS . Note that in the early history of the theory, the computational domain and the domain of interest were the same. The layer strategy is to modify the equation inside the computational layer, using LC v D f instead, with simple boundary condition at the exterior border. In both cases, the modified problem in the computational domain is required to fulfill important properties: 1. Well posedness: For any data g, there exists a unique solution v, with estimates in some norms: kvk1 C.kf k2 C kgk3 /: 2. Transparency: For a given \", one can choose either the absorbing boundary conditions or the size of the layer, such that ku vkDS \": 3. Simplicity: The additional amount of code writing due to the layer should be limited. 4. Cost: The layer should be as small as possible. Regarding item 4, note that Dirichlet boundary conditions for the wave equation would act as a wall, thus producing a 100 % error after a time T equal to twice the size of the domain.\n\nLC\n\nAbsorbing Boundaries The question emerged in the mid-seventies, with an illustrating idea for the wave equation by the geophysicist from Berkeley W.D. Smith [23]. It relies on the plane wave analysis, which will be a useful tool all throughout. Consider the wave equation in R2 , @t t u @11 u @22 u D 0:\n\n(1)\n\nSuppose one wants to reduce the computational domain to R2 D fx; x1 < 0g. The plane waves are solutions of (1), of the form u D Ae i.!t k x / , with the dispersion relation ! 2 D jkj2 D k12 C k22 . The waves propagating toward x1 > 0 are such that their group velocity rk ! e 1 is positive, i.e., k!1 > 0. Place a fixed boundary at x1 D 0 (Dirichlet boundary condition u D 0), and launch a plane wave from x1 < 0 toward . By the Descartes’ law, it is reflected into uR D Ae i.!t Ck1x1 k2 x2 / : the reflection coefficient is equal to 1. Replace the fixed boundary by a free one (Neumann boundary condition @1 u D 0). Now the reflected wave is uR D CAe i.!t Ck1x1 k2 x2 / : the reflection coefficient is equal to 1. Perform the computation twice – once with Dirichlet, then with Neumann – and add the results to eliminate the reflection. This ingenious idea is of course too simple: if more than one boundary is required to be nonreflecting, more elementary computations have to be made. For instance, eight computations have to be made at a three-dimensional corner. Furthermore, the argument is no longer exact when the velocity is variable in\n\n12\n\nAbsorbing Boundaries and Layers\n\nN the domain. However, it launched the Holy Grail for X aj X 12 ; .1 X / a0 C 30 years. 1 bj X j D1 The breakthrough came with the plasma physicist E.L. Lindmann [18], who paved the way for much N X aj k22 of the subsequent work in the subject. His analysis : (4) G.i k2 ; i !/ D a0 C ! 2 bj k22 was purely discrete but will be presented below at the j D1 continuous level. Consider again a plane wave traveling to the right, Substituting into (2) leads to the absorbing boundary impinging the boundary , where a boundary condi- condition tion is defined via an operator G.@2 ; @t /: N X @t u C @1 u C Gj @1 u D 0; (2) @t u C G.@2 ; @t /@1 u D 0: j D1\n\nThe reflected wave is RAe i.!t Ck1x1 k2 x2 / , where R is where each Gj operates on functions ' defined on defined by the boundary condition, .0; T /, Gj ' D j solution of i ! i k1 G.i k2 ; i !/CR.i ! Ci k1 G.i k2 ; i !// D 0: ! 12 k2 2 . Then by the Define G0 .i k2 ; i !/ D 1 ! dispersion relation, the reflection coefficient is equal to G G0 RD . If G 1, the boundary operator is the G C G0 transport operator in the x1 direction and is transparent to the waves at normal incidence, i.e., if k2 D 0, R D 0. This condition will be referred to as first-order absorbing and can be generalized in\n\n@t u C\n\n1 @1 u D 0; sin 0\n\n(3)\n\nwhich is transparent to the waves impinging the boundary at incidence angle 0 . With some more caution, G0 would be the symbol of the Neumann to Dirichlet map for the wave equation and the half-space R2C . Choosing G to be G0 eliminates all reflections. A similar analysis can be made for spherical boundaries as well and led, together with fast integral methods, to some successful tools by H.B. Keller and followers (see [11] for a review). However, in the physical variables, G0 is an integral operator in time and space, therefore numerically costly. It is then worthwhile trying to get approximations to G0 , which starts by an approximation of the square root. E.L. Lindmann was the first to notice that a Taylor series expansion would lead to an unstable boundary condition and proposed a continuous fraction approximation:\n\n@t t\n\nj\n\nbj @22\n\nj\n\nD aj @22 ';\n\nwith the initial conditions j D @t j D 0. The coefficients .aj ; bj / were found such as to optimize the reflection coefficient over all angles of incidence. The idea of approximation was developed further, but with a Pad´e approximation of G01 instead of G0 , by B. Engquist and A. Majda in [7, 8]. Their first two approximations, named 15ı and 45ı , respectively, in the geophysical literature, at the boundary x1 D 0 for the half-space x1 < 0, were @t u C c@1 u D 0;\n\n1 @t t u C c@t1 u @22 u D 0: (5) 2\n\nIn those two papers, an entire theory, in the frame of the theory of reflection of singularities, permitted an extension to hyperbolic systems (elastodynamics, shallow water, Euler), variable coefficients, and curved boundaries. For instance, the extension of (3) to a circle of radius R is, with a derivative @r in the radial direction, @t u C @r u C\n\n1 u D 0 in 2D; 2R\n\n@t u C @r u C\n\n1 u D 0 in 3D: R\n\nAmong the approximations, those that generate well-posed initial boundary value problems were identified in [25]. Various extensions to other type\n\nAbsorbing Boundaries and Layers\n\n13\n\nof problems, mainly parabolic (advection-diffusion, Stokes, Navier-Stokes), followed in the 1990s; see, for instance, [13, 24]. There is not much extra cost compared to Dirichlet since the boundary conditions are local in time and space. R. Higdon [15] found an expression for the absorbing boundary conditions as a product of first orderoperators (3) that is very useful on the discrete level. Another concept of far-field boundary condition was developed by A. Bayliss and E. Turkel, based on asymptotic expansions of the solution at large distances [3]. They proposed a sequence of radiation operators for the wave equation in the form n Y 2j 1 u; LC r j D1\n\nAbsorbing Layers M. Israeli and S. Orszag introduced and analyzed in 1981 the sponge layers for the one-dimensional wave equation [17]. They added in a layer of width ı, what they called a Newtonian cooling .x/.@t u C @x u/ to the equation. The right-going waves cross the interface without seeing it, while the left-going waves, reflected by the exterior boundary of the layer, are damped. This strategy was coupled with an absorbing boundary condition at the end of the layer. For more complicated equations, the numerical performance of such layers with discontinuous coefficient is not as good as one would hope. One reduces reflections at the interface for the right-going waves by choosing .x/ > 0, vanishing to order k > 0 at the origin:\n\n.x/ D A.k C 1/.k C 2/\n\nand showed well-posedness and error estimates. At these early times, no layer was used. It is only in [10, 12] that optimized layers were introduced. The evanescent waves are damped in the layer of width ı, and the coefficients in (4) "
    }
}