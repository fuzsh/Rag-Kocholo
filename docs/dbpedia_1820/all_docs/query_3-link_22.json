{
    "id": "dbpedia_1820_3",
    "rank": 22,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/",
        "read_more_link": "",
        "language": "en",
        "title": "Survey of Motion Tracking Methods Based on Inertial Sensors: A Focus on Upper Limb Human Motion",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-sensors.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/bin/sensors-17-01257-g001.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/bin/sensors-17-01257-g002.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/bin/sensors-17-01257-g003.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/bin/sensors-17-01257-g004.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/bin/sensors-17-01257-g005.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/bin/sensors-17-01257-g006.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/bin/sensors-17-01257-g007.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/bin/sensors-17-01257-g008.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Alessandro Filippeschi",
            "Norbert Schmitz",
            "Markus Miezal",
            "Gabriele Bleser",
            "Emanuele Ruffaldi",
            "Didier Stricker"
        ],
        "publish_date": "2017-06-11T00:00:00",
        "summary": "",
        "meta_description": "Motion tracking based on commercial inertial measurements units (IMUs) has been widely studied in the latter years as it is a cost-effective enabling technology for those applications in which motion tracking based on optical technologies is unsuitable. ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492902/",
        "text": "Sensors (Basel). 2017 Jun; 17(6): 1257.\n\nPMCID: PMC5492902\n\nPMID: 28587178\n\nSurvey of Motion Tracking Methods Based on Inertial Sensors: A Focus on Upper Limb Human Motion\n\n,1,* ,2 ,3 ,2,3 ,1 and 2\n\nAlessandro Filippeschi\n\n1TeCIP Institute, Scuola Superiore Sant’Anna, 56127 Pisa, Italy; ti.asipannatnas@idlaffur.eleuname\n\nFind articles by Alessandro Filippeschi\n\nNorbert Schmitz\n\n2German Research Center for Artificial Intelligence, 67663 Kaiserslautern, Germany; moc.liamg@edoligan (N.S.); ed.ikfd@reselb.eleirbag (G.B.); ed.ikfd@rekcirtS.reidiD (D.S.)\n\nFind articles by Norbert Schmitz\n\nMarkus Miezal\n\n3Junior research group wearHEALTH, Department of Computer Science, University of Kaiserslautern, 67663 Kaiserslautern, Germany; ed.lk-inu.sc@lazeim\n\nFind articles by Markus Miezal\n\nGabriele Bleser\n\n2German Research Center for Artificial Intelligence, 67663 Kaiserslautern, Germany; moc.liamg@edoligan (N.S.); ed.ikfd@reselb.eleirbag (G.B.); ed.ikfd@rekcirtS.reidiD (D.S.)\n\n3Junior research group wearHEALTH, Department of Computer Science, University of Kaiserslautern, 67663 Kaiserslautern, Germany; ed.lk-inu.sc@lazeim\n\nFind articles by Gabriele Bleser\n\nEmanuele Ruffaldi\n\n1TeCIP Institute, Scuola Superiore Sant’Anna, 56127 Pisa, Italy; ti.asipannatnas@idlaffur.eleuname\n\nFind articles by Emanuele Ruffaldi\n\nDidier Stricker\n\n2German Research Center for Artificial Intelligence, 67663 Kaiserslautern, Germany; moc.liamg@edoligan (N.S.); ed.ikfd@reselb.eleirbag (G.B.); ed.ikfd@rekcirtS.reidiD (D.S.)\n\nFind articles by Didier Stricker\n\nGiancarlo Fortino, Academic Editor, Hassan Ghasemzadeh, Academic Editor, Wenfeng Li, Academic Editor, Yin Zhang, Academic Editor, and Luca Benini, Academic Editor\n\n1TeCIP Institute, Scuola Superiore Sant’Anna, 56127 Pisa, Italy; ti.asipannatnas@idlaffur.eleuname\n\n2German Research Center for Artificial Intelligence, 67663 Kaiserslautern, Germany; moc.liamg@edoligan (N.S.); ed.ikfd@reselb.eleirbag (G.B.); ed.ikfd@rekcirtS.reidiD (D.S.)\n\n3Junior research group wearHEALTH, Department of Computer Science, University of Kaiserslautern, 67663 Kaiserslautern, Germany; ed.lk-inu.sc@lazeim\n\n*Correspondence: ti.asipannatnas@ihcseppilif.a; Tel.: +39-50-882-552\n\nCopyright © 2017 by the authors.\n\nLicensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n\nAbstract\n\nMotion tracking based on commercial inertial measurements units (IMUs) has been widely studied in the latter years as it is a cost-effective enabling technology for those applications in which motion tracking based on optical technologies is unsuitable. This measurement method has a high impact in human performance assessment and human-robot interaction. IMU motion tracking systems are indeed self-contained and wearable, allowing for long-lasting tracking of the user motion in situated environments. After a survey on IMU-based human tracking, five techniques for motion reconstruction were selected and compared to reconstruct a human arm motion. IMU based estimation was matched against motion tracking based on the Vicon marker-based motion tracking system considered as ground truth. Results show that all but one of the selected models perform similarly (about 35 mm average position estimation error).\n\nKeywords: kinematics, sensor fusion, motion tracking, inertial measurements units\n\n1. Introduction\n\nIn recent years, the development of sensing technologies and sensor signals processing techniques paved the way for the use of wearable sensors to monitor human status and performance. These developments resulted in the need for managing efficiently such networks, as explained by Fortino et al. in [1]. Wearable body sensor networks (BSN) are nowadays used in several applications which include healthcare, ergonomics, sport and entertainment, (see [2] for a review on the argument). A field that has benefited from the research on BSN is motion tracking.\n\nMotion tracking has received the attention and the effort of generations of researchers. There are several techniques that allow for motion reconstruction based on different information sources. One of the biggest challenges in motion tracking is having an accurate estimation with non-invasive sensors and non limited workspace. In the recent years, a new generation of inertial measurement units (IMUs) based on micro-electro-mechanical systems (MEMS) technology has given a new surge to motion tracking research. These devices are cost-effective and can be successfully used for accurate, non-invasive and portable motion tracking. The big interest in these devices is mainly motivated by the fact that they overcome many issues raised by optical systems and mechanical trackers. IMUs indeed do not suffer from occlusions and have theoretically unlimited workspace compared to optical motion tracking systems, and despite the accuracy of mechanical trackers, IMUs are much more affordable and far less intrusive.\n\nInertial units-based motion tracking has been used for navigation since decades ago. Initially developed for the attitude estimation of aerial vehicles (see [3,4]), it is nowadays used for other unmanned vehicles tracking (see [5,6,7,8]). In recent years, IMUs are often used to track human motion thus becoming an enabling technology for several applications which include localization, human-robot interaction, rehabilitation and ergonomics. This development is also witnessed by the rise of companies that sell IMUs and IMU-based systems e.g., Invensense (Invensense, San Jose, CA, USA), Trivisio (Trivisio, Trier, Germany), Microstrain (Lord Microstrain, Willistone, VT, USA) and XSens (Xsens Technologies B.V., Enschede, The Netherlands) and the amount of start-ups which target IMU-based systems. The products that they sell often include attitude reconstruction, which is provided as output to the user, or even full body motion reconstruction.\n\nIMUs are typically composed of accelerometers and gyroscopes. These signals are used in different manners according to the applications as it will be explained in Section 2 (as an example see [9]). In most cases IMUs are used to reconstruct the pose or at least either the position or the orientation of the body they are attached to. The naive use of IMUs is the integration of the sensors’ signals over time to estimate velocity, position and orientation. Since both accelerometer and gyroscope measurements suffer from time varying biases and noises, this approach leads to a quick drift of the estimation that is unreliable after a few seconds. Therefore, researchers started investigating both algorithmic and hardware solutions to solve the drift issue. In many cases IMUs are equipped with a three axis magnetometer (e.g., [10,11,12,13]), we refer to these sensors as mIMUs. The magnetometer measures the local (earth) magnetic field that is used as an earth-fixed reference for the current estimation of the IMU orientation. Other solutions include exploiting ultrasonic sensors [14], GPS [15], ultra wide bands (UWB) [16], cameras [17], and magnetic field generated by actuated coils [18].\n\nMotivated through the variety of approaches to IMU-based human motion tracking (IHMT), the goal of this article is introducing the reader to IHMT. In the first part (Section 2) this article introduces the reader to IHMT main issues, then it presents a survey of the methods that have been used so far to tackle the IHMT problem. In the second part (Section 3) , the article includes a tutorial section which explains in details five selected methods for upper limb tracking. This part aims at both making concrete some of the main issues presented in the survey and letting the reader familiarize with IHMT methods. These methods are finally compared to each other in Section 4. The latter section concludes the presented work.\n\n2. IMU-Based Human Motion Tracking\n\n2.1. Reviews on Wearable Motion Tracking\n\nIn recent decades, emerging technologies allowed for a huge step forward in human motion tracking. Exoskeletons, vision-based systems as well as motion capture based on inertial systems have become commonly used firstly in laboratory settings and nowadays in everyday life. Several reviews described human motion capture under different perspectives with a focus on the application [19] and/or on technical aspects [20]. For example, Patel in [21] proposes a review of wearable sensors for human monitoring in which a great emphasis is laid on applications and on the enabling technology. Their survey moves from sensing technology including motion capture based on inertial sensors to applications, including health monitoring, wellness and safety. Similarly, Shull et al. [22] review wearable sensing systems applied to gait analysis in clinical settings. They group methods according to the sensors that are used, subject populations and measured parameters. In a recent review paper [23], Gravina et al. discuss issues and advantages of body sensor networks, then they focus on their applications to human activity recognition. Wong et al. [24] review applications of wearable sensors to biomechanics. Differently from [21], they focus on the devices and the sensors that are used for motion tracking. Moreover, they explain advantages and disadvantages of the different methods. In the recent review [9] a specific focus is laid on wearable inertial sensors. The authors analyze several medical applications of wearable inertial motion tracking, including gait analysis, stabilometry, instrumented clinical tests, upper body mobility assessment, daily-life activity monitoring and tremor assessment. For all applications, they report the methods proposed to tackle those. Interestingly, the selection of the applications provides a grouping of methods that reflects different complexity levels in using IMU sensors: for example stabilometry requires simpler algorithms and fewer sensors than upper body mobility assessment. Harle et al. [25] provide a technical review of the issues arising and methods used in IMU-based pedestrian localization. Similarly, Yang et al. in [26] target localization, reviewing sensors as well as methods with their respective sources of errors. In [27] the focus is on walking speed estimation. Sabatini in [28] proposes a review of (m)IMU-based tracking systems for 3D attitude estimation focusing on the technical aspects of IHMT methods. In particular, sensor fusion techniques and related issues are explained in details including techniques to estimate and tune filter parameters. In [29] the authors compare six algorithms for the estimation of a smartphone’s attitude. The goal of their analysis was to compare algorithms in order to select the most suited one for pedestrian localization even when magnetometer’s signal is disturbed. They test such algorithms indoor while artificially distorting the magnetic field by means of magnets. Although authors claim that two of the selected methods perform better than the others, reported average orientation errors differ less than half of the error’s standard deviation.\n\nThe survey presented in the following subsections has a different scope and target with respect to previously published surveys: both applications and technical aspects are taken into account. Moreover, it explicitly encompasses the evolution of algorithms from the estimate of one rigid body pose to full body tracking. All reported methods are listed and characterized in the Appendix A (see ). The table summarizes relevant information related to application, target, kinematic representation, sensor fusion technique and validation of each method and may help the reader in the following sections.\n\n2.2. Introductory Concepts to IHMT Methods\n\nIn the late 1990s, technological advancements made inertial systems a candidate alternative to optical ones for online human motion capture. Moving from the findings in aerial vehicles navigation and accelerometry techniques, researchers started tackling the problem of human motion tracking based on (m)IMUs [30,31]. In this, major issues are: How to represent and constrain human limbs kinematics, how to fuse measurements from multiple sensors to track these with minimal drift, also considering erroneous measurements e.g., due to magnetic disturbances, and how to make the relation between technical sensor and (anatomical) body segment frames through calibration, when several (m)IMUs are involved. Moreover, ways of and measures for assessing and comparing different methods are of major interest for evaluation purposes. In the following, these major aspects and preliminary concepts of IHMT are described in more detail in order to prepare the reader for Section 2.3, which provides the IHMT survey.\n\n2.2.1. Kinematics and Constraints\n\nAll reported techniques used for inertial body motion tracking assume that human limbs are rigid bodies. Therefore, from the point of view of kinematics IHMT reduces to determining the attitude and/or the position of these limbs. When more limbs are involved a kinematic chain can be modeled. The first multi-limb models used this kinematic chain in a second step after estimating the attitude of each limb separately (e.g., [10,32]). However, the kinematic chain can be better exploited by providing joint constraints that can be added to the sensor fusion algorithm to make the estimation more consistent with human motion.\n\nKinematics Representation\n\nWhile the position of a limb in space is typically represented through a Cartesian frame, several possibilities are proposed in literature to represent its orientation. Euler angles are a common choice since they have an intuitive physical meaning, which is the case of the roll-pitch-yaw representation of a vehicle attitude (e.g., [15,33,34,35]) or the identification of the roll-pitch-yaw angles with the anatomical degrees of freedoms (DoFs) of human limbs (e.g., [36,37] ). The major drawback of such a solution (and of all the three parameters attitude representations) is the existence of singularities that may occur in certain configurations, as in the case of the gimbal lock. This is why many methods use quaternions for the estimation (e.g., [38,39,40,41,42]). Quaternions allow for a computationally efficient and singularity-free attitude representation and are often used for the attitude representation of a single body. However, besides their non-minimal rotation parametrization, they do not provide direct access to anatomical or functional angles. Factorized quaternion algorithms [43,44] decompose attitude quaternions in order to identify physically meaningful rotations (e.g., about the articulations’ axes), thus allowing for a simpler implementation of constraints. Kinematic chains are indeed often parametrized either by means of Euler angles (e.g., [45]) or using the Denavit Hartenberg (DH) [46] convention (e.g., [47,48,49]) to represent the relative joint angles.\n\nConstraints\n\nKinematic constraints play a fundamental role in the whole estimation process, as they can prevent the relative displacement of the body segments to drift over time. Kinematic constraints are sometimes embedded in the sensor fusion algorithm to provide more consistent solutions (e.g., [45,47,50,51]). In other cases the constraints are applied after the sensor fusion algorithm has provided the attitude estimation (e.g., [39]). Since the estimated quantities are often random variables, applying limits to those variables in a consistent way is a delicate issue. This is shown by Simon in [52], where different approaches to solve the issue are reviewed. In [44] quaternions are used to represent the attitudes of the human arm limbs. Anatomical constraints such as joint angle limits and limitations of the limb motions are implemented by posing the attitude estimation as an optimization problem in which the estimated attitudes have to respect the constraints and at the same time optimize the consistency with the accelerometer measurements. Also in [45,47,48,49,50,53,54], the elbow is constrained to reduced DoFs.\n\nIn contrast to the kinematic chain model, free segments models have been proposed in [51,55]. These representations keep some of the anatomical constraints as hard constraints, e.g., the connectivity between successive limbs [55], while others are relaxed (implemented as soft constraints) in order to reduce the effects of errors related to their implementation. For example, the elbow is not a perfect hinge joint as its axis is not fixed when the ulna moves with respect to the humerus [56]. Moreover, localizing the elbow axes is a further source of error [48]. On the one hand, detrimental effects of such model errors may be mitigated by the free segments approach, on the other hand this may lead to unwanted behaviours, such as measuring elbow abduction, which is not physically plausible.\n\n2.2.2. Sensor Fusion Technique\n\nSignals gathered from accelerometers, gyroscopes, magnetometers and other sensors need suitable sensor fusion techniques to derive useful information about the attitudes and poses of the limbs. Note, sensor-to-limb calibration parameters are here assumed known. Calibration methods are addressed below. In most of the sensor fusion methods the unknown variables (e.g., Euler angles) are estimated in discrete settings at successive time steps based on previous time step estimation and current time step measures. Two main approaches are adopted for sensor fusion: complementary filters (CF) and Kalman filters (KF). More complex approaches include particle filters (PF) and optimization-based approaches, which are now suitable for online IHMT.\n\nComplementary filters exploit the different frequency spectra of gyroscope, accelerometer and magnetometer signals. Many of the methods that exploit the CF approach (e.g., [10,30,57,58,59,60]) apply the following steps: The accelerometer signal is used to estimate the acceleration due to gravity in the sensor frame. This and the magnetometer signal are then used to obtain a “low frequency” estimate of the sensor’s attitude. At the same time an estimate of this attitude is dynamically calculated from the gyroscope measurement. These two estimates are then fused in the complementary filter. Some methods assume the body acceleration being negligible, thus modeling the accelerometer signal as a noisy measurement of acceleration due to gravity (e.g., [30,60]). In other methods body acceleration is calculated and removed from the accelerometer signal (e.g., [58]). Acceleration due to gravity and measured local earth magnetic field are then used to estimate the pose of the sensor in an earth-fixed frame (world frame). Some methods (e.g., [10]) simply implement the TRIAD algorithm [61] or TRIAD-like algorithms to reconstruct the attitude with respect to the world frame. Others [30,59,60] use more complex optimization algorithms to find the attitude as best fit of the different measurements.\n\nThe most widespread sensor fusion techniques are the Kalman Filters [62]. There are many cases in which a linear KF suffices for sensor fusion (e.g., [32,63,64,65]). In most of the cases, nonlinear equations require a manipulation of the KF. The Extended Kalman Filter (EKF) is the most immediate solution that has been adopted to use the KF approach with nonlinearities (e.g., [38,40,66,67,68,69]. Alternatively, Unscented Kalman Filters (UKF) are used in [47,49,53] as they provide a more accurate estimation of probability density functions (PDF) under nonlinear transformations. The method proposed in [70] uses unscented transformations, but implements constraints through probabilistic graphical models. Particle filters have been used by [39,42] to further improve and generalize the representation of PDFs.\n\nCompared to the EKF, the UKF improves the estimation of the transformed probability density function. Moreover, the UKF keeps a convenient complexity when compared to the PF. Conversely, the PF allows to drop the hypothesis of Gaussian distributed random variables, thus permitting a more accurate PDF estimation. Comparisons between EKF and UKF provided conflicting results [71,72,73]. The most recent work highlighted the performance being highly influenced by the application. They describe the UKF as being more robust to initialization issues whereas the EKF is more computationally efficient [74]. The few comparisons that were found between the PF and the UKF are far from IMU-based motion tracking applications and are not reported.\n\nRecent improvements of computational powers made optimization approaches attractive to IHMT. The methods presented in [44,51,55] show optimization based approaches that allow for both sensor fusion and implementation of constraints. Optimization approaches make it easier to take into account large time windows for the estimate. However, a good compromise has to be found between accuracy and speed of the algorithm [51] to allow for online IHMT. These latter methods are really promising because they showed to be highly flexible to add, remove, loosen or strengthen constraints as well as to find a compromise between accuracy and computational burden.\n\n2.2.3. IHMT Common Issues\n\nThere are three main issues that recur in IHMT: how to reduce the estimate’s drift, how to handle magnetic disturbances and calibration issues.\n\nDrift\n\nA very first approach to IHMT was based on inertial navigation systems (INS) strapdown integration of gyroscope measurements which was inherited from the navigation of aerial vehicles. Though adapted to follow the dynamics of a human, this solution cannot be used alone as the estimate quickly drifts. Many methods have their main focus in reducing drifts. One solution is fusing the INS or INS-like estimate with a quasi-static one, as it is done in many CF-based approaches (e.g., [58,75], see Section 2.2.2). Since drift is mainly due to gyroscope bias, a second solution is to include the bias in the estimation and to account for it [50,75,76,77,78]. A third solution exploits constraints from the kinematic chain to avoid a drifting attitude estimate of one limb with respect to the others [41,45,47,49,50,53,58,66,67,77,79]. A further solution is used mainly in lower limbs tracking and exploits contacts of the feet with the ground [38,69,78,80]. When the foot is in contact with the ground its velocity is almost null. This information can be used to reset the speed (zero velocity update, ZUPT) and, when moving on a flat ground, to also reset the height of the foot with respect to the ground. These techniques have highly reduced drifts as demonstrated in many of the aforementioned methods.\n\nMagnetic Disturbances\n\nMany of the aforementioned methods rely on magnetometers. Despite being a valuable aid to have an absolute orientation reference, their signals are easily distorted by the presence of ferromagnetic materials in the vicinity of the sensor. Distortion effects are typically classified as hard and soft iron interferences (e.g., [38,81]), which are related respectively to permanently magnetized objects and to objects that are magnetized only when an external field is applied. Hard iron effects cause an offset of the earth magnetic field whereas soft iron effects cause a distortion. If the magnetic environment does not change, these effects can be corrected through internal sensor calibration, which is out of the scope of this article. However, for dealing with a changing magnetic field, either through a changing environment or translational motion of the sensor in an environment with inhomogeneous magnetic field, several solutions have been proposed. The simplest solution is to establish a policy to decide when the magnetometer signal is reliable. This can be done by thresholding its magnitude (e.g., [82,83]). Another common solution is limiting the contribution of the magnetometer measurement to the heading variable (e.g., [45]) or to two components (e.g., [59]). A more sophisticated solution is model-based estimation of the disturbance; e.g., in [84] the magnetic field direction is estimated simultaneously with the sensor orientation. Another approach is proposed in [85]. Under the assumption that magnetic field is constant for a given period, the authors take the magnetometer measurement at the beginning of the period as a reference. They then use the error with respect to this reference at each time step to update the error state estimate in their Kalman Filter. A survey of methods to handle earth’s magnetic field disturbances is proposed by Ligorio et Sabatini in [86].\n\nCalibration\n\nAll IMU based motion reconstruction algorithms require some parameters to be provided.\n\nA subset of these parameters defines the orientations (and sometimes the positions) of the IMU frames with respect to the tracked body segments they are attached to. In most of the cases these parameters are assumed to be known: the IMU frame is supposed to be physically aligned to the body frame (e.g., [50,60,87]). In other cases these parameters are obtained by means of a calibration procedure that is carried out at the beginning of the capturing session (e.g., [47]). Another subset is related to the dimensions of the human body: human limb lengths are typically either measured (e.g., [87]), taken from anthropometric models (e.g., [64]) or calculated by means of calibration procedures (e.g., [64,88]). In contrast to the IMU-to-segment orientations and positions, there is no need for online estimation of human limb lengths as they can safely be assumed constant during tracking.\n\nSeveral calibration procedures were proposed to obtain IMU and limb parameters when tracking humans. The most typical procedure requires the human to rest in the neutrum-pose (N-pose) that is standing still while leaving the arms vertical alongside the trunk in the sagittal plane (e.g., [39,45,47,89]). Another widespread calibration pose is the T-pose, where the user is standing still keeping the arms horizontal in the sagittal plane [47,64,90,91]. In [45] the user is asked to lean forward to define an earth-fixed reference frame. In [14] the user is required to assume a rest pose before each motion. Besides the static poses, functional calibration methods require the user to perform rotations around different joint axes in order to better align the body segment frames with anatomical axes (e.g., [54,92,93]).\n\nIn a clinical setting, it is particularly important to obtain anatomically interpretable joint angles and, hence, to obtain accurate IMU-to-segment orientations. In [48,94] calibration procedures comprising IMU placement protocols, static poses and functional movements are proposed for identifying the knee and elbow flexion/extension axes and the forearm pronation/supination axes, thus improving the estimation of the anatomical joint angles. A simpler calibration procedure based on two static poses (standing and sitting or lying) is proposed and evaluated in [89]. Picerno et al. [37] proposes a specific rig equipped with an IMU for IMU-to-segment orientation calibration based on anatomical landmarks. For this, the rig endpoints have to be manually placed on anatomical landmarks, which is applied to the thigh and the shank.\n\nThe effects of errors in the different calibration parameters on the limb orientation estimation errors have been recently investigated in [51] demonstrating a clear dominant role of the sensor-to-segment orientations compared to the positions and limb lengths.\n\n2.2.4. Methods’ Assessment\n\nThe assessment of motion tracking methods often relies on ground truth data, where the estimated trajectories are compared to ground truth trajectories using typical metrics, such as the root mean square error, namely RMSE, (e.g., [30,36,50,84,88,95,96,97]) or correlation coefficients (e.g., [49,53,58,87,88,96,98]). Two performance measures are mainly used for the evaluation: the drift and the accuracy of the target reconstruction, either based on the position of a reference point or the orientation of a rigid body.\n\nDrift assessment requires to perform relatively long trials. In [36] the proposed algorithm is evaluated with respect to its drift dependency over time. In [87] the drift of the wrist position estimate is calculated and reported for one circular and one square trajectory. Luinge and Veltink [95] report attitude estimation drifts obtained from a strapdown integration of the measured angular velocities as compared to a sensor fusion algorithm using a KF. In many papers validation trials are longer than a few seconds (e.g., [10,31,38,75,92]) so that it is possible to at least qualitatively assess drift by visual inspection of the RMSE along time. Other works (e.g., [10,32,80]) do not report long assessment trials, making it difficult to evaluate drift.\n\nAccuracy assessment requires ground truth data being at least as accurate as the method is expected to be. Single body attitude/position estimation can exploit very reliable ground truth data, such as those gathered from tilt tables (e.g., [30,43,97]). Since the IMU can be aligned very accurately to these devices, the error introduced through the evaluation device is limited and often much smaller than the estimation error. In many applications related to human motion tracking, the positions of anatomical landmarks are of interest. For this, marker-based optical motion capture (OMC) has become the gold standard (e.g., [39,40,47,48,50,55,66,77,79,91,95,99]). OMC permits to evaluate both attitude and position tracking. In the first case the main source of error resides in the alignment of the coordinate frame calculated from the OMC data with respect to the model estimation frame. The second case requires to estimate the parameters (e.g., the segment lengths) needed to calculate the reference point positions from the IMU data. Since it is not possible to measure these parameters exactly, they represent an additional source of error.\n\nOther types of reference data were also used. One example is the work of Zhu et al. [32], in which the authors constrain the hand to follow a straight line and then check the reconstructed trajectory to be straight. Other mechanical platforms and robots were used in [42,57,75,76,81] as ground truth data.\n\nAs an alternative to tilt tables, Picerno et al. used in [100] a method for assessing the orientation estimation accuracy by attaching mIMUs to a rigid plate that is oriented in 12 different ways. They use the RMSE of the reconstructed orientation angles with respect to the known plate’s poses as accuracy metric. Devices from Xsens have also been used as providers of ground truth data. Robert-Lachaine et al. recently published [91] a comparison of MVN [64] and optical motion tracking performance when using such systems either with proprietary kinematic models or when estimating angles derived from ISB (International Society of Biomechanics) recommendations. The MVN suite was also used by Pons et al. in [41] and Taunyazov in [90], whereas the attitude estimate provided by the MTx IMU units was used by Brigante et al. in [68] and by Lee et al. in [44] to validate their methods.\n\nIt is worth noting that evaluation results always depend on the assessment method, while a great variety of such methods is currently used. Hence, it is difficult to make a fair comparison between the results reported in different publications. The summary takes this into account by reporting the assessment methods along with the results.\n\n2.3. Survey of IHMT Methods\n\nThis section provides a survey of IHMT methods categorized by the targeted body parts. This categorization allows following the historical development of IHMT methods. Indeed, starting to work on methods for a specific target (e.g., the upper limbs) and then refining it before moving to other targets represents a pattern found for many teams of researchers. Note, the presentation of the different methods combines solutions introduced in Section 2.2.\n\n2.3.1. Generic Limb Orientation\n\nLimbs pose tracking has been tackled by means of (m)IMUs since the end of the last century. Works of Bachmann [30] and Marin [31] pioneered the field targeting orientation tracking of human limbs and robotic links by using mIMUs for computer graphics applications. The former proposed a quaternion-based attitude tracking method that updates the attitude quaternion by means of the gyroscope measurement and corrects it based on a “low frequency” estimate from the accelerometer and magnetometer measurements. Differently from [30] the second model assumes a time decay of the limbs’ angular velocities. This assumption is suitable for human motion as humans cannot maintain an average non-zero magnitude of their limbs’ accelerations for long time periods. The same group further investigated this matter with different approaches: Marin et al. in [31] moved to using an EKF to fuse a gyroscope-based quaternion attitude estimate with the estimate obtained from the accelerometer and magnetometer signals through an optimization procedure. Yun tackles the problem of limb attitude estimation in a similar way with two variants: In [97] the authors take into account a decay of human limb acceleration, whereas in [43] they adopt a factorized quaternion approach to limit the use of the magnetometer measurements for heading estimation. Both methods replace optimization with the QUEST (QUaternion ESTimator) algorithm [4] to determine the attitude from the accelerometer and magnetometer measurements. Hol et al. propose an alternative approach to IHMT for pose estimation of one limb based on UWB [101]. They develop a sensor composed of a 6-axes IMU and a UWB transmitter, whose pose estimation is the goal of the algorithm. First UWB measurements are modeled considering transmission time as an unknown, whereas gyroscope and accelerometer models are based on the kinematics of the sensor and they include time varying biases. Finally, an EKF is set to estimate the pose of the sensor. Kok et al. in [102] extend this method. They also propose a tightly coupled approach to fuse UWB measurements and IMU measurements to obtain a set of variables which includes poses of human limbs. A novel two-steps method for calibration of UWB is first proposed to obtain positions and time offsets of UWB receivers and transmitter, as well as the parameters of an asymmetric probability distribution, that they use to model measurements of UWB. Obtained UWB measurements are then used to set an optimization problem which includes IMU measurements to estimate the poses of human limbs. In [10] the upper limb posture is estimated using a CF which fuses accelerometer and magnetometer signals based on the TRIAD algorithm to reconstruct the attitude of each limb. Two nonlinear CFs are proposed in [75,76] to fuse accelerometer, magnetometer and gyroscope measurements to obtain an attitude quaternion estimation. The authors define an orientation error and demonstrate by means of a Lyapunov stability analysis that the proposed filters enforce the defined error to converge to zero. The method of Madgwicks et al. [59] is also based on a CF and includes two variations. The former uses inertial signals, while the latter uses also magnetometer measurements. The method with magnetometers is described in Section 2.2.2. It exploits an earth-fixed frame to reconstruct the IMU’s orientation as a quaternion q. The relation of its time derivative with the angular velocity allows the authors to use the gyroscope measurements for the CF “high frequency” estimate of q. The “low frequency” estimate is obtained from an optimization procedure in which the goal is to align vectors measured in the sensor frame with their known counterparts in the Earth fixed frame. This second part can be adapted depending on the availability of measurements; e.g., acceleration due to gravity in case of an IMU and, in addition, local magnetic field in the case of an mIMU. Finally, the method of To and Mahfouz [42] tries to improve the quaternion attitude estimation by using von Mises-Fisher and Bingham densities in a PF that provides the attitude quaternion based on the IMU signals.\n\n2.3.2. Lower Limbs Tracking\n\nIMU-based lower limbs tracking has been tackled for several purposes. In some cases it has been used for gait analysis [36,37,79,93], in other cases only parts of the lower limbs were targeted, mainly for monitoring purposes in medical settings [94,96] or rehabilitation [44,59]. In [88] a system for tracking shank and thigh orientation in the sagittal plane is presented. The authors use two IMUs (both the accelerometers and the gyroscopes were biaxial) attached to these body segments. They perform direct integration with updates according to the difference between the detected acceleration and the acceleration due to gravity.\n\nThe work in [63] aims instead at estimating the knee flexion/extension angle based on IMUs attached to the user’s thigh and shank. They use KFs to estimate the IMUs’ attitudes and model the knee as a hinge joint to obtain the flexion/extension angle assuming the orientations of the sensors with respect to the knee joint to be known. Similarly, in [98] the target is knee angle estimation, and the IMU poses with respect to the knee rotation axis are supposed to be known or determined through a calibration procedure. Favre et al. show an application of a similar approach to knee ligament injury monitoring [92,96]. The same authors further developed their method to overcome calibration issues. In [103] they propose a functional calibration procedure to obtain clinically relevant joint angles. The importance of calibration (see Section 2.2.3) for measurements in clinical settings is further witnessed by the works of Picerno et al. [37] and Cutti et al. [48,94] who developed calibration procedures to map mIMU-based 3D kinematics reconstruction to anatomical landmarks. Knee angle estimation based on two IMUs on thigh and shank is also the target of Seel et al. in [93]. They propose a calibration procedure that allows to obtain the knee joint position and knee flexion/extension axis in the sensors’ frames. Based on this, they propose two magnetometer-free joint angle estimation methods. The first method exploits IMU orientation estimation to obtain the knee angle as orientation difference about the knee axis. The second method exploits directly the hinge joint assumption to obtain the knee angle by integrating the difference of the angular speeds with respect to the knee axis. Finally, drift is removed by an acceleration-based joint angle estimation. They test their method against ground truth from an OMC system by mounting IMUs and optical markers on both human and prosthetic legs.\n\nLower limbs reconstruction has often been used to aid localization during locomotion. Examples include the methods presented in [65,104]. The first exploits detection of contacts and a lower limbs biomechanical model to correct acceleration and velocity errors. Localization is then obtained by integration of linear velocity. The second implements KFs too estimate limbs orientations from mIMUs signals. KFs estimate IMUs biases and the errors of limbs orientation quaternions, which are then used to correct orientation estimate from INS. The method implements also ZUPT and adaptive weighting of accelerometer and magnetometer signals to mitigate detrimental effects of linear acceleration and magnetic field disturbances. Estimates from left and right legs are finally merged by a KF to obtain pelvis displacement.\n\nJoukov et al. propose to use five IMUs to track locomotion for gait analysis [79]. They use two kinematics models to model the support and the swing leg. The first connects the feet to the ground by means of hinge joints (stance leg), whereas the latter connects the waist to the ground by means of three prismatic and three hinge joints. IMU data are fused in an EKF whose states comprise the joint variables and their time derivative. The method is validate on ten cycles but only knee joint angles are reported.\n\nZihajehzadeh and Park in [105] propose a method that substitute magnetometer with UWB. They use 7 IMUs attached to feet, shanks, thighs and pelvis as well as 3 UWB tags attached to feet and pelvis to reconstruct lower limbs motion and localize pelvis. Interestingly they exploit the robustness of the estimate of limbs’ inclination to remove yaw estimation drift. Their method moves from a first KF (tilt KF) that estimates inclination of the seven limbs based on accelerometer an gyroscope signals. Then they use UWB for a second KF whose output are feet positions and yaw of feet and pelvis. This output and tilt KF output are finally used to estimate shanks and thighs yaw. They obtained good results (orientation error below 5∘ and position error below 5 cm) walking, jumping and ascending validation trials.\n\n2.3.3. Upper Limbs Tracking\n\nMore than a decade ago, Luinge and Veltink in [95] exploited IMUs to track the orientation of the upper limbs by modelling the accelerometer and gyroscope measurements as a function of attitude, biases and noises and using a KF to estimate orientation errors and biases based on these models. This method was applied in [54] for tracking the relative orientation of the forearm with respect to the upper arm. Other works from these and associated researchers addressed magnetic disturbance handling [84] and extending the method to full body motion tracking [64].\n\nMihelj [50] used IMUs to track human arm motion in a rehabilitation task. In this task the user’s hand was firmly fixed to a robot and the known hand pose was used to complement the IMU information. mIMUs were also used by Jung et al. in [67] to track the motion of the trunk and the upper limbs. These were modeled as two four DoF serial kinematic chains which were connected to the trunk, while the latter had three rotational joints with respect to the pelvis.\n\nBleser et al. proposed in [45] a novel method for upper limbs tracking that exploits an egocentric camera and markers to aid mIMU-based estimation. The topic was then further investigated addressing motion tracking algorithms for general kinematic chains [66], investigation of the effects of different model calibration errors and biomechanical model representations on the segment orientation estimation accuracy [51] (studied based on arm motions), simultaneous motion and IMU-to-segment calibration estimation [106] as well as low-cost full body sensor suits [107]. Targeted applications include ergonomics in industrial manufacturing [108] and rehabilitation [109].\n\nPeppoloni proposed in [47] an mIMU-based method for arm tracking, modeling each shoulder and elbow with five DoFs and using an UKF to fuse the mIMU data. In [70], the same group proposed a method where the UKF was replaced by a probabilistic graphical model approach. The method takes into account the constraints provided by the kinematic chain model and implements a message passing approach to estimate the joint angles. Considered applications include ergonomics [110], robot teleoperation [111] and rehabilitation.\n\nParticle filters were used by Zhang et al. [39] to fuse inertial and magnetometer measurements for estimating the elbow flexion/extension angles. The same authors worked previously on an UKF-based method presented in [49].\n\nThe upper limbs tracking approach of El Gohary [53,77] exploits IMU measurements fused in an UKF. The method was eventually improved [78] by including IMU biases and ZUPTs to limit drift.\n\nTaunyazov et al. [90] adopted a simpler approach to track the upper limbs. Their method relies on one IMU mounted on the upper arm and a simple mechanical tracker equipped with a potentiometer to measure the elbow’s rotation angle.\n\nFinally, upper arm pose estimation is the goal of the methods analyzed in Section 3, i.e., [32,45,47,58,97] which are all based on mIMUs and exploit different calibration and sensor fusion techniques.\n\n2.3.4. Full Body Motion Tracking\n\nSome of the aforementioned methods were extended to full body motion tracking. Works from professor Veltink’s group led to the development of a commercially available inertial body tracking system based on a body suit with 17 mIMUs [64] (the Xsens MVN system). The motion reconstruction algorithm also benefits from the work of Schepers, Roetenberg and Slycke on the exploitation of disturbed magnetic field signals [99,112].\n\nVlasic et al. [14] developed a full body suit equipped with 18 IMUs and eight ultrasonic sources. The IMUs were equipped with microphones so that the received signals provided a reference to avoid the drift that would occur when purely integrating accelerometer and gyroscope measurements.\n\nThe full body tracking method of Pons-Moll et al. [41] is mainly based on camera images. The limbs poses are inferred from the video information within a set of possible poses. This set is reduced thanks to the orientation cues from IMUs mounted on the body.\n\nA linear CF is proposed in [58] in which the orientation quaternion of each limb is obtained as a linear combination of an estimate based on the gyroscope measurements and one based on the accelerometer and magnetometer measurements.\n\nMiezal et al. [66] exploited an EKF to develop a general framework for motion tracking of arbitrary kinematic chains based on mIMUs.\n\nAn interesting probabilistic method has been developed by Kok et al. in collaboration with XSens [55]. Instead of using a recursive filter, joint angles are estimated from IMU measurements using constrained optimization. Here, constraints from the biomechanical model and from assumptions about the average acceleration over time are included into the cost function as both hard and soft constraints. Moreover, errors due to sensor shortcomings and soft tissue artefacts are modelled by incorporating appropriate noise terms. The maximum a posteriori estimate is obtained in an offline process using an infeasible start Gauss Newton method to solve the weighted least squares problem. Recently, Miezal et al. [51] proposed a variation of Kok’s offline method to enable online constrained optimization using a sliding window approach.\n\nMultiple limbs and full body suits have been applied to several fields. In the sports field, for example, Ruffaldi et al. in [113] use IMUs to analyze rowing performance by estimating the rower’s motion based on five mIMUs. Measurements from the rowing simulator hardware (oars and seat) aids the overall estimate. Supej et al. developed a full body suit based on Xsens MTx sensors to track ski performance [114]. In [57] Miller et al. addresses remote robot control through IMU-based motion tracking. YostLabs (YostLabs, Portsmouth, OH, US), formerly YEI technologies, distributes full body IMU-based motion tracking applied to computer graphics and Virtual Reality (PrioVR). The system enables computer game players to control virtual characters through their own motions (see YEI technology, http://www.yeitechnology.com/).\n\n3. Selected Methods\n\nThis second part of the article is in the form of a tutorial, and provides more details on five methods which have been selected in order to span the different areas that were identified in Section 2. These methods differ concerning the sensor fusion technique, using either CF, KF, EKF or UKF. They also differ concerning the sensors that are used: all of them exploit IMUs, but magnetometer signals are not always used and one method requires a visual reference for tracking human upper limbs. They also differ regarding the kinematic models: some use Euler angles, some use the DH convention and others use quaternions. Moreover, they differ in how the constraints of the kinematic chain are considered. Finally, they differ in how the parameters of the algorithms are set. In the following these methods are briefly recalled, more details can be found in the cited papers.\n\nThe following notation will be used. The i-th accelerometer signal will be a˜i, the gyroscope’s will be ω˜i and the magnetometer’s will be m˜i. Vector a will denote linear acceleration of a point. The earth magnetic field and the gravity vectors will be respectively m and g. pl will specify that the vector p is written in the reference system l. In will be the size n identity matrix, 0n,m a n by m null matrix, and T is the sample time. The quaternion qi will represent the attitude of the i-th body.\n\n3.1. Method 1\n\nThe first method that is described in [32] is suitable for the reconstruction of an arbitrary kinematic chain, given that each link is provided with a nine axis mIMU. shows the block diagram that summarizes this method. Given two consecutive links in the kinematic chain, namely i and i + 1, each one provided with a frame τi ≡ (Oi, xi, yi, zi), the authors represent the orientation between the two frames by a axis-angle representation with axis kii+1 and rotation angle θi, from which the rotation matrix Rii+1 can be obtained.\n\nThe rate of change of gi and mi within the same frame τi can be calculated as\n\nig˙=S(ωi)igim˙=S(ωi)im\n\n(1)\n\nwhere ωi is the angular velocity of the frame τi and S(ω) is the skew-symmetric matrix of vector ω\n\nS(ω)=0−ωzωyωz0−ωx−ωyωx0.\n\n(2)\n\nIt is worth noting that the gyroscope measurement is treated here as a known control input, thus not taking into account the gyroscope measurement noise.\n\nUnder the assumption of slow motion (or that the linear acceleration is known) and that the i-th sensor frame is aligned with τi, then gi, mi and ωi are approximately the output of the i-th sensor, i.e.,\n\nig≈a˜iandim≈m˜i\n\n(3)\n\nThe authors hence propose to use a KF for each segment in which the state is\n\nXi=igim.\n\n(4)\n\nThe process model between steps j and j + 1 is derived from Equation (1):\n\nXj+1i=(X˙jiT+I6)Xji+wj\n\n(5)\n\nwhere wj is white noise. According to Equation (3) the measurement model is hence\n\nZji=Xji+δji\n\n(6)\n\nwhere and δi is the white measurement noise.\n\nThe KF estimation of ig and im feeds the QUEST algorithm to calculate the attitude quaternion qi. The resulting quaternion qi is converted to a rotation matrix that feeds the homogeneous matrices\n\nAii+1=Rii+1idii+101,\n\n(7)\n\nin which idi is the position of Oi+1 in the frame τi, are then recursively applied from the chain root up to the desired point to obtain its position in the root frame.\n\n3.2. Method 2\n\nIn the method proposed by Yun et al. [97] each limb is supposed to be independent of the others and equipped with a nine axes mIMU sensor. shows the block diagram that summarizes this method. The attitude of i-th limb with respect to the root frame is represented by a quaternion qi. Under the assumption that the linear acceleration of the human limbs is negligible with respect to the gravity, and that the mIMU axes are aligned with the limb ones, then qi is initially estimated by means of the QUEST algorithm fed by equally weighted accelerometer and magnetometer signals thus obtaining qmi. To compensate for the dynamic effect of the linear acceleration, the authors estimate the rate of change of qi based on the link angular velocity ωi also measured by the mIMU:\n\nq˙i=12qi⊗ωi=Q(ωi)qi\n\n(8)\n\nwhere Q(ωi) is the matrix representation of the quaternion:\n\nQ(ωi)=120−ωjiTωji−S(ωji)\n\n(9)\n\nThe authors also assume that human limb acceleration is bounded and averages to zero over a certain amount of time, hence they propose to model the angular velocity as exponentially decaying over time:\n\nω˙ki=−1tkωkik∈x,y,z\n\n(10)\n\nwhere tk is a parameter of the algorithm that determines the time horizon within which ωk averages to zero. These two methods for estimating qi are fused by means of an EKF in which the state vector is\n\nXi=ωiqi.\n\n(11)\n\nThe process model between steps j and j + 1 is derived from Equations (8) and (10):\n\nXj+1 = (ΦjT + I7)Xj + wj\n\n(12)\n\nwhere wj is white noise in a 7-dimensional space and\n\nΦj=−1/t1000−1/t2003,400−1/t304,3Q(ωji).\n\n(13)\n\nThe measurement model is the identity as ω˜i≈ωi and qi measurement is qmi. The final estimation of qi is then used to reconstruct the pose of the links composing the human arm.\n\n3.3. Method 3\n\nThe third method is presented in [58]. The attitude of the i-th limb with respect to the root is represented by the quaternion qi. They assume to attach a mIMU sensor to each moving limb. The authors propose two versions of their method. In the first version that is called pure the linear acceleration is neglected. In the second version that is called perfect the authors model the human body as a kinematic chain that allows them to calculate the linear acceleration lai of each frame. summarizes the two versions of the method. The authors assume that the mIMU axes are aligned with the limb frames, thus having im≈m˜i, and they suppose to know all the parameters that are required to define the kinematic chain.\n\nIn both versions the authors propose a complementary filter in which the “high frequency” estimation of qi, namely qpi is obtained from the limb angular velocity ωi as in Equation (8). The “low frequency\" estimation of qi, namely qmi is obtained from igi and imi by means of the QUEST algorithm. Given qi estimation at time step j, the proposed CF computes\n\nqj+1i=1k(qmi−qpi)+qji\n\n(14)\n\nwhere k is a parameter that allows us to tune the filter.\n\nThe pure and the perfect filters differ in the gi that is provided to the algorithm:\n\ngi=a˜ipureversion,a˜i−laiperfectversion.\n\n(15)\n\nThe authors associate a hierarchical model tree with the human kinematic chain so that one limb is the root and every other limb i has its parent p. Given the angular velocity of the i-th limb, lai is\n\nlai=lap+[S(ωi˙)+S2(ωi)]dip\n\n(16)\n\nwhere lap is the linear acceleration of the i-th limb’s parent, S(ω) is defined in Equation (2), and dip is the position of i-th frame origin in the parent frame.\n\nFinally qi is used to reconstruct each limbs pose according to the defined kinematic chain.\n\n3.4. Method 4\n\nThe fourth selected method [45] has two main innovations with respect to the previous ones. First it embeds the kinematic constraint equations in the sensor fusion filter. Second it proposes a visual reference to aid magnetometers under severe magnetic disturbances. This method aims at tracking the upper body (but can be extended to the full body) by means of five mIMUs attached on the chest, the upper arms and the forearms. The mIMU on the chest is also provided with a camera (CmIMU) that tracks the markers placed on the user’s wrists. The authors consider a five degree of freedom (DoF) model for each arm and also model the shoulder motion accounting for the scapulohumeral rhythm [115]. The resulting kinematic chain is rooted in the chest and organized as a hierarchical tree.\n\nThe method is based on three loosely coupled EKFs, the first returns the trunk orientation given the mIMU signals, the latter two estimate the shoulder (three DoFs) and elbow (two DoFs) joint angles q1, …, q5 of each arm based on the mIMU signals, the trunk orientation and the wrist position are obtained from the camera image. summarizes the components of the EKF that estimates the arm motion given the trunk orientation.\n\nThe state of these EKFs is X=[q1q˙1q¨1…q¨5]T, the process model is linear and it assumes constant angular acceleration between two time steps j and j + 1, thus having for the i-th angle\n\nqiq˙iq¨ij+1=1TT2/201T001qiq˙iq¨ij+wii=1,…,5\n\n(17)\n\nThe authors then propose a calibration procedure to relate the state X to the available measurements. Assumed that the mIMUs sit on the frames of the limbs, the orientation of each mIMU frame with respect to the related link frame is represented by the rotation matrix Riui that is obtained through this procedure as well as the position of the CmIMU with respect to the shoulder joint center. The other link lengths are gathered from anthropometric tables. Given Riui, the orientation of each mIMU with respect to the root is R0ui and the mIMU measurements are\n\na˜i=Riui(iap+ig)+waω˜i=vex(R0uiR˙0ui)+wom˜i=R0uim0+wh\n\n(18)\n\nwhere vex(S(ω)) = ω being S(ω) defined in Equation (2), ap is the acceleration of the link hosting the i-th mIMU, and wj are white noises. The latter measurement equation is only partially used and reduced to the heading direction. A further measurement equation relates the position of the wrist to the wrist position estimated from the camera:\n\ncd˜0w=1d0zwd0xwd0yw+wc\n\n(19)\n\nwhere d0w is the wrist position and wc is white noise. The measurement equations are then grouped as\n\nZ = h(X)\n\n(20)\n\nthat is linearized to obtain the observation matrix\n\nH=∂h∂X|Xj+1,j\n\n(21)\n\nThis method directly provides the poses of all limbs.\n\n3.5. Method 5\n\nThe last selected method [47] has two main differences with respect to the previous ones. First, it does not rely on the linearization of nonlinear equations, but it exploits the unscented transformation to cope with non-linearities. Second, it proposes refinements in the kinematics of the upper body and exploits a nonlinear sensor fusion algorithm to cope with nonlinear models. The method aims at upper limb motion tracking. Each of the clavicles, upper arm and forearm is provided with a mIMU. Taken the chest as root, a seven DoFs hierarchical kinematic model of each arm was developed according to the Denavit Hartenberg convention.\n\nThe sensor fusion technique of this method is an Unscented Kalman Filter in which the state vector is X=[q1q˙1q¨1…q¨5]T and the process model is the same as Equation (17).\n\nThe authors propose a calibration procedure to gather the parameters needed to relate the state X to the measurements. The orientation of each mIMU frame with respect to the related link frame is represented by the rotation matrix Riui, whereas its translation with respect to the parent frame is measured to obtain the homogeneous matrix Aiui that fully refer the mIMU frame to its parent’s one. Given that the sth mIMU is attached to the i-th frame whose parent frame is p, the measurements model is:\n\na˜s=Rpsap+[S(ω˙p)+S(ωp)2]rps+R0s0g+waω˜s=Rps(ωp+ϑ˙p+1z0)+wom˜s=R0sm0+wh\n\n(22)\n\nwhere Rps is the rotation matrix from the parent frame to the sensor frame, z0 = [0,0,1]T vector, and rps is the position of sensor frame relative to parent in sensor frame. The measurement equations are then grouped as Equation (20). In this case the function h is not linearized, but it is used for the unscented transformation that provides the measurement estimation based on the state prediction. As for method 4, the state already provides he pose of each limb.\n\n4. Comparison\n\n4.1. Experimental Setup\n\nSelected methods were compared to each other using OMC. Ground truth data were obtained from the Vicon (OMG plc, Oxford, UK) OMC system while tracking a healthy 28 years old male that was equipped with the mIMUs Colibri mIMUs from Trivisio Prototyping GmbH, sampled at 100 Hz), the CmIMU (Firefly MV color camera from PointGrey with diagonal field of view of 140 deg, sampled at 12.5 Hz, hardware synchronized with the mIMUs), and markers on the anatomical landmarks. After holding N-pose and T-pose as calibration procedure, he was asked to perform several movements that involved one functional degree of freedom at a time, namely elbow flexion/extension (EFE), forearm pronation/supination (EPS), shoulder flexion/extension (SFE), shoulder abduction/adduction (SAA), and shoulder internal rotation (SIR). The participant gave his informed consent for inclusion before he participated in the study. The study was conducted in accordance with the Declaration of Helsinki, and the protocol was approved by the Ethics Committee of Scuola Superiore Sant’Anna (Delibera n. 1/2017). The setup of the experiment is shown in .\n\nThe joint motion reconstruction from optical data is based on the following kinematic model: the chest was considered as a steady rigid body. Shoulder was modeled as a spherical joint, so that the humerus has three rotational DoFs with respect to the chest. The forearm was considered to have two DoFs with respect to the humerus, i.e., the flexion-extension and pronation-supination functional DoFs. The Vicon Nexus® software (Oxford Metrics, Oxford, UK) allowed us to use this kinematic model for offline adjustment of the marker positions. The marker on the acromions served to capture the shoulder joint center, that is assumed to be 4.5 cm under the acromion in the Zv direction.\n\nEach sequence lasted at least 10 s. Wrist position was used to assess the methods. Moreover, each sequence of movements includes a pair of repetitions performed at higher speed to test how methods’ performance varies as the linear acceleration increases.\n\nCaptured data include the markers positions in the Vicon reference system τv, the mIMU signals in the respective sensor reference systems, and the images gathered by the CmIMU in the camera reference system. All the data are synchronized and gathered at 100 Hz. IMU and OMC data were manually synchronized by exploiting the transitions from static postures to motion. This synchronization method may introduce a time misalignment in the data which accounts for up to 3 samples (variations in the data are sufficiently clear to identify onset of motion). This means that the maximum misalignment cannot exceed 30 ms. The dataset used for the comparison is available in Zenodo (https://zenodo.org/) and it can be found through the digital object identifier (DOI) of this paper.\n\n4.1.1. Data Alignment for the Comparison\n\nThe comparison of the estimated positions (joints and end effectors) against the OMC based ones requires to represent both in a common reference system. OMC data is available in a frame τv ≡ (Ov, xv, yv, zv) that is defined during the OMC system calibration. Since the chest frame τ0 was the root for the IMU based estimation, all these data were available in τ0. Once decided to represent all the body frames in τv, the rigid transformation between the global frame τv and the root IMU frame τ0 is sufficient for the comparison. The homogeneous transformation matrix\n\nA0v=R0vvd0v01\n\n(23)\n\nrepresents such a transformation, where R0v is the rotation matrix that aligns τ0 axes with τv ones, and vd0v is the position vector of the τ0 origin. Since in data capturing there was not enough information to calculate A0v, it was decided to estimate it for each method. Let X˜=[vx˜1,⋯,vx˜n] be a n samples set of optical captured positions and Y˜=[0y˜1,⋯,0y˜n] the corresponding estimated positions. Let then vy and 0x be the captured and reconstructed positions in the reference configuration, i.e., the N-pose for the present evaluation. If we consider two new sets of samples, namely X and Y, obtained from X˜ and Y˜ as\n\nxj=vx˜j−vxyj=0y˜j−0y.\n\n(24)\n\nthen\n\nvd0v=0.\n\n(25)\n\nThe rotation matrix R0v is calculated to minimize the reconstruction error, for any method m and a reference r the quality Q can be computed as\n\nR0v=argminR0v∑j=1n∥(yj−R0vxj)∥2.\n\n(26)\n\nFinally, the samples set Z = [vx1, ⋯ , vxn] obtained as\n\nZ=R0vY\n\n(27)\n\ncan be compared against X.\n\nThis method underestimates the absolute error of each method, but it provides a fair comparison between the methods. The quality of a set of body tracking techniques can then be evaluated against the OMC dataset by comparing the joint and end-effector points with the reference method.\n\n4.1.2. Performance Indices\n\nAligned mIMU and OMC data are then used to calculate the performance measures that we introduced in Section 2.2.4 and hence compare the algorithms. Given two random variables X and Z each sampled with N samples, the following indices will be used for this purpose:\n\nAccuracy:\n\nE=1N∑i=1N∥Zi−Xi∥\n\n(28)\n\nCorrelation:\n\nC=cor(X,Z)=cov(X,Z)var(X)var(Z)\n\n(29)\n\n4.2. Experimental Results\n\nData gathered from the mIMUs provided the input for the methods reported in Section 3 to reconstruct the arm kinematics. The parameters of each method’s filter were selected to optimize the method performance in terms of stability and accuracy. To enable the comparison of the methods, OMC and mIMU-based position estimation were aligned according to the method reported in Section 4.1.1. shows how the mIMU-based data are first translated to match OMC data in N-pose and then rotated to obtain the best alignment with OMC data.\n\nrefers to the EFE functional motion and shows how the error E (see Equation (28)) evolves over time.\n\nAfter these examples we report the values of the error and of the correlation that the different methods scored. For the comparison of the methods three functional movements were selected, namely EFE, SFE, SAA. The first movement allows us to assess how the methods behave when only one joint of the kinematic chain as well as only one mIMU moves. The latter two involve the motion of two mIMUs. With respect to the EFE motion, in the SFE and SAA motions the estimation provided by methods that use the kinematic chain is likely to differ more from the other methods’ estimation. The average of E and C in the three trials are reported in .\n\nTable 1\n\nEFESFESAAMethodE (mm)CE (mm)CE (mm)C138.80.86108.90.4666.00.66289.20.77121.40.86243.80.363-pu.45.70.84122.860.46156.00.593-pe.59.70.84100.40.50272.20.60475.70.9182.70.8686.00.73589.20.77214.40.89125.40.66\n\nTo obtain a more detailed insight of the methods’ performance, the EFE functional motion was further studied. It was divided into cycles: cycles 1–7 were carried out at a slower speed, whereas the latter two were carried out at a higher speed. shows how the error E is distributed within the cycles of the EFE trial, whereas reports the average of E and C (see Equation (28)) for the same cycles.\n\nTable 2\n\nMethodCycleIndex123-Pure3-Perfect45E (mm)143.7102.853.873.472.351.3249.9100.364.279.990.744.8346.6103.463.184.098.349.4437.7102.853.368.192.147.7535.397.144.557.679.059.6649.4102.851.364.185.789.6750.4108.445.957.590.5101.3838.9100.244.756.376.097.8923.660.927.836.559.0136.9C10.940.730.960.920.940.9320.940.770.910.870.920.8530.960.750.910.820.950.8140.950.720.960.920.960.7650.950.780.930.890.940.8760.930.810.950.920.920.8270.830.770.840.850.910.7680.880.740.860.890.950.7190.870.860.920.930.950.94\n\n4.3. Discussion\n\nThe methods can now be compared according to the indices that were proposed in Section 4.1.2. Before comparing the methods, we see from that for all the methods the error varies periodically with time. This time error may be due to residual error of mIMU-OMC data alignment. However, each of the methods may have other source of error related to biomechanical constraints: lack of kinematic constraints (methods 1, 2 and 3 pure) and too rigid constraints (method 3 perfect, 4 and 5) are all suitable candidates for periodic errors in the estimation of a periodic motion.\n\n4.3.1. Accuracy\n\nThe first measure that we proposed is accuracy, as obtained via E. Clearly, the lower E the more accurate the method is. Accuracy is a measure of reliability in accurate position estimation, accuracy is needed when an absolute measure of the position is required, for example in the analysis of motion or to provide force rendering when interacting with a Virtual Environment. From we see that method 1 is generally the most accurate and method 4 is also comparable. We note that the accuracy gap between methods 1 and 4 is smaller for SAA and SFE movements, being method 4 more accurate for the latter movement. This partially supports the finding that imposing a kinematic chain in the motion estimation improves the estimation when the measurements of mIMUs on different links are affected by the same joint variable. This hypothesis is further supported when methods 1, 2 and 3-pure are compared. Differently from methods 3-perfect, 4 and 5, the first two methods do not take into account the kinematics of the arm. The latter has a lower accuracy in the EFE motion, but has a better accuracy for the motions SAA and SFE (except for method 3-perfect in the SAA motion).\n\n4.3.2. Correlation\n\nCorrelation C is the second measure that is considered. Correlation indicates whether the estimated position follows the real pattern of the performed movement. A good correlation of the estimated human motion with the real movement suffices to teleoperate a remote robot. In facts, in this case it is anyhow needed to map the operator motion to the robot kinematics, and what matters is that this map does not vary along time. In other words, even if accuracy is poor, the human who teleoperates the robot can easily adapt motion of his arm to be able to control the robot unless there is a good correlation between the performed motion and the method’s estimate. When correlation is poor, human has to adapt the motion of the arm and eventually perform unnatural motions to control the robot (e.g., activate more DoFs to obtain a simple elbow motion). From the point of view of the correlation, shows that the best performing methods are 4 and 5.\n\n4.3.3. Fast Motion\n\nOne of the differences between the methods is the use of the kinematics of the human arm, in particular of the linear acceleration of the limbs. A reasonable hypothesis is that methods 3-perfect, 4 and 5 perform better with respect to the others when the motion of the limbs is fast and the speed changes quickly. This condition should make linear acceleration of the limbs play a bigger role. In our case, this role is enhanced by mounting the mIMUs far from the parent joint. However, looking at and at , there is no significant difference in the variation of the accuracy between slow cycles (1 to 7) and fast cycles (8 and 9). Similarly, shows that correlation does not improve between cycles 1–7 and 8–9 for methods 1,2,3-perfect and 5, whereas there is a small improvement for method 4. These results suggest that the linear acceleration of the limbs plays a minor role with respect to gravity, as assumed by several models. However, this aspect should be further investigated with specific motions in which gravity plays a minor role to identify limb’s orientation.\n\n4.3.4. Sources of Error\n\nAs a final remark of the discussion, the accuracy and the correlation that were obtained are generally comparable or worse with respect to the literature. However, apart from possible suboptimal tuning of the methods’ parameters, possible sources of error that can explain our results\n\nKnowlegde of human parameters (i.e., arm length). This source of error can be minimized by including human parameters in the estimation e.g., [51]\n\nBody to mIMUs calibration. Although the calibration procedure that we carried out suffices to determine the orientation of the mIMUs, uncertainties in the position of mIMUs with respect to their parent is still subject to assumptions. Also the effects of this source of error can be reduced by a proper calibration and by taking into account the sensor poses in the sensor fusion technique.\n\nTime alignment of OMC data with mIMU data. OMC and mIMU-based data are manually done based on a known motion from a steady condition. However, the effects of misalignment are much smaller than the error we have reported.\n\nPreprocessing of data. Here we tested only the reported algorithm, not considering possible filtering on mIMU data. For example, having a hard magnetic calibration, it would be possible to handle bad data with distorted magnetic field.\n\n5. Conclusions\n\nAfter introducing the reader to the main issues of IHMT, relevant methods from the literature were reported. Analysis of the literature revealed that several approaches perform similarly for IHMT. However, optimization-based methods seem to have the potential to bring substantial improvements to IHMT. Currently methods and solutions for lower limbs tracking such as ZUPT have not been widely applied to full body tracking yet. These methods are often capable of accurate estimation even during long walk trials. Therefore their combination with their upper limbs counterparts may improve accuracy and reduce drift of full body IHMT also when walking.\n\nFive methods that span the different techniques used for IMU data sensor fusion were presented and analysed in depth, and an evaluation of these methods was proposed based on accuracy and correlation with OMC data. Results showed that method 1 is the best performing for accuracy followed by method 4, which is the best in terms of correlation. We hence advise to use method 1 for attitude estimation and for navigation purposes. Instead we consider 4 the best method for robot teleoperation. Motion speed analysis provided minor results, possibly due to the choice of movements that make gravity play a dominant role in limb attitude estimation.\n\nAppendix A. Summary of Presented Methods\n\nA summary of the methods presented in Section 2 is reported in Appendix A in . Methods are sorted in chronological order and described according to the following categories:\n\nRef: reference to the article where the methods described.\n\nYear: publication year.\n\nBody: this category describes which part(s) of the body are targeted by the method Application: some methods are connected by the authors to one ore more applications. Most of the times this link is made explicit in the introduction. This category reports the application(s) extracted from the article. They span from computer graphics to robotics and medical applications.\n\nTarget: this category describes the physical quantities that are targeted by the method in relation to the body parts to be tracked. For example, when the body parts to be tracked are upper limbs, arm’s orientation and position are possible targets. The word “attitude” is referred to methods that are not referred to a specific part of the human body but to a generic rigid body.\n\nFocus: Most of the cited articles focuses on the description of the IHMT method. However, some articles focus on the assessment of some methods, or on their application. In these cases fewer or no details about the IHMT method are reported. Calibration and handling of magnetic disturbances are also focuses of some of the articles reported in Section 2.\n\nSensors: List of the sensors required to apply the method described in the article. Each sensor is preceded by the numbers of units that are used.\n\nKinematics and Constraints: This category lists the kinematic representation(s) that was (were) chosen in the method and the biomechanical constraints that were used. Orientation is often represented as a quaternion or a rotation matrix which is a function of three independent variables. Exponential maps have also been used to represent orientation. When a kinematic chain is used, position and orientation may be obtained through the joint variables. This is the case when “kinematic chain” is reported without other kinematic representation specifications (e.g., “quaternion orientation”). “Kinematic chain” also indicates that joints are used either to impose constraints to motion or to reconstruct limbs’ pose. This category reports also the use of free segments modelling. Other constraints specifications (e.g., hinge, soft or hard constraints) are specified for some methods. This category is linked to Section 2.2.1.\n\nParameters: Kinematic chain, constraints and sensor fusion technique require to set and tune some parameters. These parameters are grouped and reported in this category. Lengths (e.g., arm length), orientations (e.g., mIMU’s orientation with respect to the link it is attached to), Kalman Filter parameters (e.g., covariance matrices) are parameters that many models require.\n\nSensor Fusion Technique: The mathematical method(s) that was (were) used is reported in this category. Kalman Filters, Complementary Filters and Optimization are the most popular possibilities that are reported. However, some methods use other tools such as inertial navigation systems and probabilistic graphical models. This category is linked to Section 2.2.2.\n\nCalibration: When one or more calibration procedures are required to obtain the parameters needed for the method, these are here summarized. Most of the methods include static calibration, whereas other requires more complex procedures which include motion of specific articulations. This category is linked to Section 2.2.3.\n\nValidation: Validation methods are reported in this category, the number of participants and the source of ground truth data is reported.\n\nMeasure: Quantitative validation of the methods requires the definition of variables to be assessed. In many cases these variables replicate the target of the method, in other cases they are a subset of the variables need for tracking of the declared targets.\n\nRMSE: Root mean square error of the variables reported as measures for the validation when compared to ground truth data. Angular variables are reported in degrees whereas position are reported in millimetres. Drift are reported in meters per seconds.\n\nCorrelation: Correlation of estimated variables with ground truth data as reported in the referenced article.\n\nThe Notes column completes the description of each method with a few details specific of the method. Some formulas are worth to be mentioned:\n\nSens align link refers to the assumption that a sensor’s frame is supposed to be aligned to the frame of the body it is attached to; Sens sitting link is used referring to the situation of a (m)IMU attached to a human limb. In this case the the limb is supposed to be a beam and the formula refers to the assumption that the sensor’s frame origin is a point of such a beam; Bias est refers to models in which sensors’ biases are among the variables that are estimated;\n\nLin acc noise is referred to methods in which linear acceleration of the sensor is considered to be noise;\n\nShow plot refers to method for which RMSE and/or correlation are not reported as figures in the text on in tables but a plot of such quantities is available.\n\nAppendix A.1. Description of Abbreviations\n\nIn some abbreviations are used to make the table more compact. These abbreviations are listed according to the previously defined categories and described in :\n\nTable A1\n\nRef.YearBodyApplicationTargetFocusSensorsKinematics & ConstraintsParametersSensor Fusion TechniqueCalibrationValidationMeasureRMSECorrelationNotes[30]1999attitudecomputer graphicslink orimethod1 acc, 1 gyro, 1 magquat oriCF gainCF, GN optno1, tilt tableroll1.0-initial condition study, 120 s valid trial, lin acc negl[31]2001attitudecomputer graphicslink orimethod1 acc, 1 gyro, 1 magquat oriCF gainCF, GN opt-1, tilt tablequat compar--initial condition study, 25 s valid trial[10]2004attitudecomputer graphicslink orimethod1 acc, 1 gyro, 1 magrot matCF gainCF-1, robot EEroll, pitch, yaw-0.7–0.87drift, 12s valid trial, omni phantom[32]2004upper limbs-\n\narm ori\n\nforearm ori\n\nwrist pos\n\nmethod2 acc, 2 gyro, 2 magrot matlink len, KF paramsKF, QUEST-1, hor line vert linewrist pos, shoulder abd, elbow fle--lin acc negl, sens align link, sens sitting link, 25s valid trial, show plot[57]2004full bodyteleoperationlink oriapplication14 acc, 14 gyro, 14 magkinematic chain, quat oriCF gainCF like-robot EE---sens sitting link, plot traj, valid teleop robot[95]2005upper limbs, lower limbsmedicallink orimethod1 acc, 1 gyrorot matKF paramsKFstatic2, OMC\n\npelvis incli\n\ntrunk incli\n\nforearm incli\n\npelvis drift\n\ntrunk drift\n\nforearm drift\n\npelvis incli 1\n\ntrunk incli 2\n\nforearm incli 3\n\npelvis drift 0.6\n\ntrunk drift 0.4\n\nforearm drift 0.4\n\n-drift modeled, sens align link[84]2005attitude-link orimag comp1 acc, 1 gyro, 1 magrot matKF paramsKF, lin acc err, mag errstatic1, box, 1, OMC\n\nori err sta\n\nori err dyn\n\nori err sta 0.6\n\nori err dyn 2.7\n\n-linear acc noise,[75]2005attitude-link orimethod1 acc, 1 gyro, 1 magquat oriCF gainCF-mech platformlink ori--bias est, 60s trial, show plot[36]2005lower limbsmedical: locomotion\n\nlink ori\n\nlink pos\n\nmethod1 acc, 1 gyrorot mat-acc double int\n\nstatic\n\ndynamic\n\n6 static poses\n\n6 known traj speeds\n\n1, OMC\n\nlink ori\n\nlink pos\n\nlink ori 0.8–1.3\n\nlink pos 22–26\n\n-sens sitting link, sens align link, 4 s localization valid tasks[88]2006lower limbs-shank orimethod2 2d acc, 1 gyroknee hingeCF gainCF likestatic, n pose like8, OMC\n\nshank\n\nthigh\n\nshank 0.74–0.78\n\nthigh 1.42–1.69\n\n0.999motion limited sagittal[96]2006lower limbsmedical: knee function analysis post cruciate ligament lesion\n\nknee fle\n\nknee abd\n\nknee rot\n\napplication2 gyro--gyro int-5, US\n\nknee fle\n\nknee abd\n\nknee rot\n\nknee fle 4.4\n\nknee rot 2.7\n\nknee abd 4.2\n\n-target ROM, 30m walk valid trial[97]2006attitudecomputer graphicslink orimethod1 acc, 1 gyro, 1 magquat oriKF paramsEKF, QUEST-1, tilt table\n\nroll\n\npitch\n\nyaw\n\n2.0–9.0-initial condition study, 25 s valid trial[50]2006upper limbscomputer graphics\n\nshoulder ori\n\nshoulder pos\n\narm ori\n\narm pos\n\nforearm ori\n\nmethod1 2d acc, 1 1d gyro, mech track wrist poskinematic chain, quat orilink len, KF paramsKF, GN opt-1, OMC\n\nshoulder ori\n\nelbow ori\n\nwrist ori\n\n<OMC prec-sens align link, sens sitting link, bias est[38]2006attitudemedicallink orimethod1 acc, 1 gyro, 1 magquat oriKF paramsEKF-1, OMC\n\nquat err\n\nroll\n\npitch\n\nyaw\n\nquat err 4.57\n\nroll 1.31\n\npitch 1.40\n\nyaw 4.13\n\n-adaptive covariance, bias est, ZUPT like sens inline calib, 120s free movements valid trial[54]2007upper limbsmedical: monitoring, neuromuscular disorderselbow anglemethod2 acc, 2 gyroelbow hingeKF paramsKFdynamic1, OMCelbow fleelbow fle 8–25-static plus pro mov calib, variation R, 130s daily activities valid trial[99]2007full body-\n\narm ori\n\nforearm ori\n\nhand ori\n\npelvis ori\n\nthigh ori\n\nshank ori\n\nmethod\n\n1 acc, 1 gyro, 1 mag\n\nmagnetic coil\n\nrot matlink len, KF paramsINS, EKF-6, OMC\n\ntrunk ori\n\narm ori\n\nthigh ori\n\ntrunk pos\n\narm pos\n\nthigh pos\n\ntrunk pos 4.8–5.6\n\narm pos 5.0–7.9\n\nthigh pos 8.6\n\ntrunk ori 2.4–3.0\n\narm ori 2.3–3.1\n\nthigh ori 3.2\n\n-sens align link, sens sitting link, 30s walking valid trial[14]2007full bodycomputer graphics, sport\n\narm ori\n\nforearm ori\n\nhand ori\n\ntrunk ori\n\npelvis ori\n\nthigh ori\n\nshank ori\n\nmethod18 acc, 18 gyro, 18 USkinematic chain, quat orilink len, KF paramsEKFstatic, rest pose1, OMC\n\nhead ori\n\narm ori\n\nthigh ori\n\nhead ori 5.7\n\narm ori 8.0\n\nthigh ori 6.6\n\n-sens sitting link, 30s valid trials, drift observed[92]2008lower limbsmedical\n\nknee fle\n\nknee abd\n\nknee rot\n\ncalibration2 gyro--gyro intstatic, n pose, dynamic hip abd10, MAG\n\nknee fle\n\nknee abd\n\nknee rot\n\nknee fle 1.5\n\nknee rot 1.6\n\nknee abd 1.7\n\nknee fle 1.0\n\nknee rot 0.95\n\nknee abd 0.86\n\n30m walk valid trial[37]2008lower limbsmedical: gait\n\nhip fle\n\nhip abd\n\nhip rot\n\nknee fle\n\nknee abd\n\nknee rot\n\nankle fle\n\nankle abd\n\nankle rot\n\ncalibration2 acc, 2 gyro, 2 mag---static6, OMC\n\nhip fle\n\nhip abd\n\nhip rot\n\nknee fle\n\nknee abd\n\nknee rot\n\nankle fle\n\nankle abd\n\nankle rot\n\nhip fle 3.0\n\nhip abd 3.6\n\nhip rot 4.5\n\nknee fle 2.4\n\nknee abd 4.8\n\nknee rot 9.4\n\nankle fle 1.2\n\nankle abd 5.5\n\nankle rot 21.7\n\n-calibration from 6 participants[48]2008upper limbsmedical\n\nscapula pro\n\nscapula ret\n\nscapula ele\n\nshoulder fle\n\nshoulder abd\n\nshoulder rot\n\nelbow fle\n\nelbow pro\n\ncalibration4 acc, 4 gyro, 4 mag---static1, OMC\n\nscapula pro\n\nscapula ret\n\nscapula ele\n\nshoulder fle\n\nshoulder abd\n\nshoulder rot\n\nelbow fle\n\nelbow pro\n\n0.2—3.2-[43]2008attitude-link orimethod1 acc, 1 magquat oriFQA-1, tilt tableroll, pitch, yaw--sens align to link[76]2008attitude-link orimethod1 acc, 1 gyro, 1 magquat oriCF gainCF-robot EElink ori--bias est, 60 s valid trial, show plot[63]2009lower limbs-\n\nshank ori\n\nthigh ori\n\nknee fle\n\nmethod2 acc, 2 gyroknee hingeKF paramsKFstatic, n pose like7, OMC\n\nshank ori\n\nthigh ori\n\nknee fle\n\nshank ori 0.4–4.7\n\nthigh ori 0.4–1.5\n\nknee fle 0.7–3.4\n\n-[98]2009lower limbs-\n\nhip ab\n\nhip fle\n\nknee fle\n\nmethod4 acc, 4 gyroknee hingerot acc-8, OMC\n\nhip abd\n\nhip fle\n\nknee fle\n\nhip abd 3.96\n\nhip fle 4.46\n\nknee fle 3.73\n\n0.91limited motion to 80 deg, low speed valid trial[103]2009lower limbsmedical\n\nknee fle\n\nknee abd\n\nknee rot\n\ncalibration2 gyro--gyro intdynamic8, MAG\n\nknee fle\n\nknee abd\n\nknee rot\n\nknee fle 8.1\n\nknee rot 4.0\n\nknee abd 6.2\n\nknee fle 1.0\n\nknee rot 0.85\n\nknee abd 0.76\n\n[64]2009full bodycomputer graphics\n\nhead ori\n\ntrunk ori\n\npelvis ori\n\narm ori\n\nforearm ori\n\nthigh ori\n\nshank ori\n\ncalibration, application17 acc, 17 gyro, 17 mag\n\nsoft joints\n\ncardan euler\n\nhelical\n\njoint coord sys\n\nlink len, KF paramsKFstatic, t pose, dynamic, axis rot, closed loop calib----three steps calib, closed loop calib[94]2010lower limbsmedical: monitoring cerebral palsy\n\nhip fle\n\nknee fle\n\ncalibration8 acc, 8 gyro, 8 mag---static9, OMC, 2, manual\n\nankle fle par\n\nknee fle par\n\n1.4-1.8-manual measurement therapist[58]2010full bodycomputer graphics\n\npelvis ori\n\nthigh ori\n\nshank ori\n\nfoot ori\n\nmethod9 acc, 9 gyro, 9 magkinematic chain, quat orilink len, sens pos, CF gainCF, lin acc err-sim sens meas\n\npelvis ori\n\nthigh ori\n\nshank ori\n\nfoot ori\n\npelvis ori 1.64\n\nthigh ori 1.82–2.2\n\nshank ori 1.81–2.02\n\nfoot ori 2.31–2.96\n\n0.939 0.999sens align link, sens sitting link, walking gait, running gait[112]2010pose-\n\nlink ori\n\nlink pos\n\nmag comp\n\n1 acc, 1 gyro, 1 mag\n\nmagnetic coil\n\nrot mat-INS, EKF, mag sto model-static pos---[114]2010full bodysport\n\nlink ori\n\nlink pos\n\napplication16 acc, 16 gyro, 16 mag----2, GNSS\n\nlink ori\n\ntraj len\n\nlink ori 0.8–4.2\n\ntraj len 8\n\n-35 s pendulum valid trial, entire ski race[67]2010upper limbs-\n\npelvis pos\n\npelvis ori\n\ntrunk pos\n\ntrunk ori\n\narm pos\n\narm ori\n\nforearm pos\n\nforearm ori\n\nmethod6 acc, 6 gyro, 6 magkinematic chain\n\nlink len\n\nsens pos\n\nNR opt, inv kin-1, OMCwrist poswrist pos 5-sens sitting link, sens align link, 180s valid trial, lin acc negl[69]2010poselocalization\n\nfoot ori\n\nfoot pos\n\nmethod1 acc, 1 gyro, 1 magrot matKF paramsEKF, INS-1, known pathfoot posfoot pos 450–1350-bias est, lin acc est, ZUPT, ZARU, HDR, 100s valid trial 125m[87]2010upper limbs-\n\nlink ori\n\nlink pos\n\nmethod2 acc, 2 gyro, 2 magkinematic chain, rot matKF params, link lenKF, CF like-8, OMC\n\nwrist pos\n\nelbow pos\n\nwrist pos drift\n\narm ori\n\nforearm ori\n\nwrist pos 3–15\n\nelbow pos 4–6\n\nwrist pos drift 0.3\n\narm ori 2.04–2.06\n\nforearm ori 2.16–2.41\n\nwrist pos 0.95–0.97\n\nelbow pos 0.95–0.98\n\narm ori 0.94–0.98\n\nforearm ori 0.96–0.97\n\nsens sitting link, sens align link, const lin acc, const ang vel, sens reloc, 30s square and circle valid trials, 100 s daily activities valid trials[80]2010full body-link orimethod--KF paramsKF-1, OMC---lowest point alg, const height ground, lin acc noise, show plot, drift visible, ZUPT[18]2010full body-\n\narm ori\n\nforearm ori\n\nhand ori\n\npelvis ori\n\nthigh ori\n\nshank ori\n\nmethod1 acc, 1 gyro, 1 mag, mag coilrot matlink len, KF paramsINS, EKF-6, OMC\n\ntrunk ori\n\ntrunk pos\n\nthigh ori\n\nthigh pos\n\narm ori\n\narm pos\n\ntrunk ori 3.6–4.5\n\ntrunk pos 26–35\n\nthigh ori 2.8–3.6\n\nthigh pos 47–62\n\narm ori 2.8\n\narm pos 25\n\n-sens align link, sens sitting link[45]2011upper limbsindustrial assembly\n\narm ori\n\nforearm ori\n\nwrist pos\n\nmethod5 acc, 5 gyro, 5 mag, Camera markerkinematic chain, rot mat\n\nKF params\n\nsens pos\n\nlink len\n\nEKF\n\nstatic\n\nn pose, back bent\n\n1, OMCwrist pos--show plot, visual insp drift, 40 s valid trial[41]2011full bodycomputer graphics, sport\n\narm ori\n\nforearm ori\n\nhand ori\n\ntrunk ori\n\npelvis ori\n\nthigh ori\n\nshank ori\n\nmethod10 acc, 10 gyro, 10 mag\n\nkinematic chain\n\nexp map\n\nquat ori\n\nlink len, OPT paramsOPT, VMF diststatic1, MVN5 links ori7.3-sens sitting link, 20 s valid trials[59]2011attitudemedicallink orimethod1 acc, 1 gyro, 1 magquat oriCF gainCF like, OPT-1, OMC\n\nroll\n\npitch\n\nyaw\n\nroll 0.581–0.625\n\npitch 0.497–0.688\n\nyaw 1.073–1.110\n\n-sens sitting link, sens align link, average over 860 s valid trials[40]2011attitudemedicallink orimethod1 acc, 1 gyro, 1 magquat oriKF paramsEKF-1, OMC\n\nroll\n\npitch\n\nyaw\n\nroll 1.75\n\npitch 1.96\n\nyaw 5.46\n\n-sens sitting link, sens align link, adaptive covariance, bias est, 20 s valid trial, lin acc negl[68]2011full bodymedical\n\nlink ori\n\nlink pos\n\napplication1 acc, 1 gyro, 1 magquat oriKF params, link lenEKFstatic1, MTX\n\nroll\n\npitch\n\nyaw\n\nroll 1.62\n\npitch 0.8\n\nyaw 6.06\n\n-sens sitting link, sens align link, adaptive covariance, bias est, 20 s valid trial, lin acc negl[49]2011upper limbs-\n\narm ori\n\narm pos\n\nforearm ori\n\nforearm pos\n\nmethod2 acc, 2 gyro, 2 magkinematic chain, rot matKF params, link lenUKFstatic, n pose1, OMC\n\nshoulder fle\n\nshoulder abd\n\nshoulder rot\n\nelbow fle\n\nelbow pro\n\nshoulder fle 2.35\n\nshoulder abd 0.877\n\nshoulder rot 2.90\n\nelbow fle 6.18\n\nelbow pro 13.06\n\nshoulder fle 0.999\n\nshoulder abd 0.999\n\nshoulder rot 0.997\n\nelbow fle 0.887\n\nelbow pro 0.964\n\nDH, sens sitting link, sens fixed to limit soft tissue effect, lin acc negl[39]2011upper limbscomputer graphics\n\narm ori\n\narm pos\n\nforearm ori\n\nforearm pos\n\nmethod2 acc, 2 gyro, 2 mag\n\nkinematic chain\n\nquat ori\n\nfree seg\n\nPF params, link lenPFstatic, n pose1, OMC\n\nshoulder rot\n\nshoulder pitch\n\nshoulder fle\n\nelbow fle\n\nelbow pro\n\nshoulder rot 3.23\n\nshoulder pitch 1.32\n\nshoulder fle 2.52\n\nelbow fle 12.14\n\nelbow pro 6.33\n\nshoulder rot 0.999\n\nshoulder pitch 0.999\n\nshoulder fle 0.996\n\nelbow fle 0.887\n\nelbow pro 0.964\n\nbias est, lin acc negl, sens sitting link, sens fixed to limit soft tissue effect[53]2011upper limbs-\n\narm ori\n\nforearam ori\n\nmethod2 acc, 2 gyro, 2 magrot mat\n\nKF params\n\nlink len\n\nsens pos\n\nsens ori\n\nUKF-1, OMC\n\nelbow fle\n\nelbow pro\n\nshoulder fle\n\nshoulder abd\n\n-\n\nelbow fle 0.89–0.92\n\nelbow pro 0.93–0.96\n\nshoulder fle 0.94–0.97\n\nshoulder abd 0.91–0.94\n\nDH, sens sitting link, sens align link, 5 s anat movements valid trials[100]2011full body-link oriassessment9 acc, 9 gyro, 9 magquat ori--static, 12 poses1, OMC\n\nroll\n\npitch\n\nyaw\n\nrollIC 4.3–8\n\npitchIC 2.2–4.8\n\nyawIC 2–11.4\n\nrollSC 0.5–2.7\n\npitchSC 0.5–1.6\n\nyaw 1.5–3.1\n\n-inter MIMU error, intra MIMU error, static valid trial, MTX proprietary KF[77]2012upper limbs-\n\narm ori\n\nforearm ori\n\nmethod2 acc, 2 gyro, 2 magkinematic chain, rot matlink len, KF paramsUKFstatic, n pose8, OMC\n\nshoulder abd\n\nshoulder fle\n\nelbow fle\n\nelbow pro\n\nshoulder abd 4.4\n\nshoulder fle 5.5\n\nelbow fle 6.5\n\nelbow pro 5.5\n\nshoulder abd 0.99\n\nshoulder fle 0.98\n\nelbow fle 0.98\n\nelbow pro 0.95\n\nDH, sens align link, sens sitting link, bias est, calib remove gyro bias, 12 s functional movements valid trials, 12 s daily actitvities trials[81]2012full body-\n\nlink pos\n\nlink ori\n\nmag comp1 acc, 1 gyro, 1 mag--OPT-mech platform\n\nmag magnitude\n\nmag center\n\nmag magnitude 0.01\n\nmag center 0.01\n\n-[44]2012upper limbsmedical: rehabilitation\n\nlink ori\n\nlink pos\n\nmethod2 accquat oriopt paramsNR optstatic1, MTX\n\nshoulder fle\n\nshoulder rot\n\nelbow fle\n\nelbow pro\n\nshoulder fle 2.12\n\nshoulder rot 4.78\n\nelbow fle 3.7\n\nelbow pro 3.16\n\n-motion limited sagittal, lin acc negl, sens sitting link, sens align link, static poses calib, 40 s trial sagittal plane[66]2013upper limbs\n\nlink ori\n\nlink pos\n\nmethodn acc, n gyro, n magkinematc chain, rot matKF params, link lenEKF\n\nstatic, n pose\n\nback bent\n\n1, OMChand pos\n\ndistance to plane 13\n\ncircle length 14\n\n-DH, any kinematic chain[104]2013lower limbs-link ori, pelvis posmethod7 acc, 7 gyro, 7 magkinematic chain, quat oriKF params, link lenKF-1, OMCpelvis pos\n\npelivs pos x 90–120\n\npelivs pos y 40–100\n\npelivs pos z 60–80\n\n-sens align link, sens sitting link, ZUPT, 20 s hopping valid trial, walking valid trial[107]2013full body\n\nlink ori\n\nlink pos\n\napplication21 acc, 21 gyro, 21 magkinematc chain, rot matKF params, link lenEKF\n\nstatic\n\ncubic rig poses\n\nMIMUs comparison---no head[108]2013upper limbsergonomicslink ori, link posapplication21 acc, 21 gyro, 21 mag, 2 goniometerskinematic chain, rot matKF params, link lenEKF\n\nstatic, n pose\n\nback bent\n\n12 expertsexecution time, RULA class freq---[47]2013upper limbs-\n\nshoulder ori\n\nshoulder pos\n\narm ori\n\narm pos\n\nforearm ori\n\nforearm pos\n\nmethod3 acc, 3 gyro, 3 magkinematic chain, rot mat\n\nKF params\n\nsens pos\n\nlink len\n\nUKFstatic, n pose, t pose1, OMC\n\nscapula ret\n\nscapula ele\n\nshoulder abd\n\nshoulder rot\n\nshoulder fle\n\nelbow fle\n\nelbow pro\n\nshoulder pos\n\nelbow pos\n\nwrist pos\n\nscapula ret 6.19\n\nscapula ele 3.43\n\nshoulder abd 8.19\n\nshoulder rot 10.68\n\nshoulder fle 8.79\n\nelbow fle 5.00\n\nelbow pro 9.61\n\nshoulder pos 34.1\n\nelbow pos 65.5\n\nwrist pos 103.6\n\nang 0.63-0.99\n\npos 0.97-0.99\n\nDH, 160s functional movements valid trials[65]2013lower limbslocalization, trainingmethod1 acc, 1 gyro, 1 mag, 1 pressurekinematic chain, rot matKF params, link len, sens posKFstatic, three walk step poses1, OMC, known path\n\npelvis vel\n\npelvis pos\n\npelvis vel 0.03–0.13\n\npelvis pos 3.2–1832\n\n-sens sitting link, >40s walking valid trial, >40s jogging valid trial, lin acc noise[42]2013full bodymedicallink orimethod1 acc, 1 gyro, 1 magquat oriPF paramsPF, VMF diststatic1, OMC, robot EE\n\nquat ori\n\nquat thigh\n\nquat shank\n\nquat ori 0.45-0.6\n\nquat thigh 0.416–0.598\n\nquat shank 0.431-0.606\n\n-bias est, sens sitting links, init GN opt acc mag meas[60]2013attitude-link orimethod1 acc, 1 gyro, 1 magquat oriCF gain, opt paramsCF, GN optstatic, dymanic1, OMC\n\nroll\n\npitch\n\nyaw\n\nroll 0.66\n\npitch 0.60\n\nyaw 0.82\n\n-adaptive gain CF, bias from calib, bias est, 1000s valid trials, variation mag disturbance static, lin acc negl[93]2014lower limbsmedical: gait\n\nankle fle\n\nknee fle\n\nmethod6 acc, 6 gyroknee hingeCF gainCF likedynamic1, OMC\n\nankle fle\n\nknee fle\n\nankle fle 1.62\n\nknee fle 3.3\n\n-walk 10m straight valid trial[79]2014lower limbsmedical:gait, rehabilitation\n\nknee fle\n\nknee pos\n\nankle pos\n\nmethod5 acc, 5 gyrokinematic chainKF paramsEKF-5, OMC\n\nknee fle\n\nknee pos\n\nankle pos\n\nknee fle 5.03–6.46\n\nknee pos 0.9–10.3\n\nankle pos 0.3–11.9\n\n-2 full cycles valid trial[70]2014upper limbs-\n\narm ori\n\narm pos\n\nforearm ori\n\nforearm pos\n\nmethod2 acc, 2 gyro, 2 magkinematic chainU transform, link len, sens posPGMstatic, n pose, t pose1, OMC\n\nshoulder abd\n\nshoulder rot\n\nshoulder fle\n\nelbow fle\n\nelbow pro\n\nshoulder abd 6.78\n\nshoulder rot 6.64\n\nshoulder fle 3.77\n\nelbow fle 7.24\n\nelbow pro 15.49\n\nshoulder abd 0.94\n\nshoulder rot 0.81\n\nshoulder fle 0.98\n\nelbow fle 0.98\n\nelbow pro 0.74\n\nDH, 160s functional movements valid trials[55]2014lower limbs-\n\nlink pos\n\nlink ori\n\nmethod17 acc, 17 gyro, 17 mag\n\nkinematic chain\n\nquat ori\n\nrot mat\n\nfree seg\n\nopt steps, link lenOPTunspecifieds1, OMCknee ori--bias est, lin acc negl, covmat allanvar, no sens to hinge and acc model, no real time, 37s walking valid trial, show plot[89]2014lower limbs-\n\npelvis ori\n\nthigh ori\n\nshank ori\n\nfoot ori\n\ncalibration7 accrot mat-TRIAD likestatic, n pose, seat pose10, OMC\n\nhip fle\n\nhip abd\n\nhip rot\n\nknee fle\n\nankle fle\n\nankle abd\n\nankle rot\n\nhip fle 0.2–0.4\n\nhip abd 0.6–0.9\n\nhip rot 0.4–0.8\n\nknee fle 0.3–0.6\n\nankle fle 0.6–1.3\n\nankle abd 0.7–1.9\n\nankle rot 0.3–0.8\n\nhip fle 0.95–0.99\n\nhip abd 0.87–0.96\n\nhip rot 0.90–0.97\n\nknee fle 0.95-0.98\n\nankle fle 0.84–0.92\n\nankle abd 0.69–0.92\n\nankle rot 0.90–0.97\n\nlin acc negl[109]2015full bodymedical: physical activity monitoring\n\nactivity class\n\nactivity rate\n\napplication-kinematic chain, rot matKF params, link lenEKFstatic, n pose, back bent----[78]2015upper limbs-\n\narm ori\n\nforearm ori\n\nhand ori\n\nmethod2 acc, 2 gyro, 2 magkinematic chain, rot matKF params, link lenUKFstatic, n pose1, mech\n\nshoulder rot\n\nshoulder fle\n\nelbow fle\n\nelbow pro\n\nwrist fle\n\nwrist twi\n\nshoulder rot 3.0–7.8\n\nshoulder fle 0.8–2.5\n\nelbow fle 0.9–2.8\n\nelbow pro 1.1–1.3\n\nwrist fle 1.1–1.8\n\nwrist twi 1.7–2.8\n\n-DH, sens align link, sens sitting link, bias est, calib remove gyro bias, ZUPT reduce gyro bias, joint limit, mech synch crosscorrelation, 120s funct mov valid trial, 120 s norm tasks valid trial[113]2015full bodysport\n\narm ori\n\nforearm ori\n\nhand ori\n\ntrunk ori\n\narm pos\n\nforearm pos\n\nhand pos\n\ntrunk pos\n\nmethod, application5 acc, 5 gyro, 5 mag, 5 enckinematic chain, rot matKF params, link lenUKFstatic1, OMC\n\nshoulder pos\n\nelbow pos\n\nwrist pos\n\nshoulder pos 78–81\n\nelbow pos 153–158\n\nwrist pos 34–54\n\nshoulder pos 0.40–0.48\n\nelbow pos 0.83–0.91\n\nwrist pos 0.99\n\n40s rowing valid trial[110]2016upper limbsergonomics\n\narm ori\n\narm pos\n\nforearm ori\n\nforearm pos\n\napplication3 acc, 3 gyro, 3 mag, EMGkinematic chainKF params, link lenUKFstatic, n pose, t pose10, manual vs auto---[90]2016upper limbscomputer graphics\n\narm ori\n\nelbow fle\n\nmethod1 acc, 1 gyro, 1 mag, mech track elbow flequat oriKF params, link lenUKFstatic, t pose1, XsensMVN\n\nelbow pos\n\nwrist pos\n\n--lin acc negl, sens align link, sens sitting link, 5.5 s valid trial, show plot[86]2016--link orimag comp1 acc, 1 gyro, 1 magquat oriKF paramsKF-1, OMCquat oriquat ori6-180s walking valid trial, similar to [32][51]2016upper limbs-\n\nlink ori\n\nlink pos\n\nmethod3 acc, 3 gyro, 3 mag\n\nkinematic chain\n\nrot mat\n\nquat ori\n\nfree seg\n\nKF params\n\nlink len\n\nsens pos\n\nsens ori\n\nopt params\n\nEKF, OPTstatic\n\n1, sim sens meas\n\n1, OMC\n\narm ori\n\nforearm ori\n\nwrist ori\n\narm ori qs 1.68–5.31\n\nforearm ori qs 2.58–8.49\n\nwrist ori qs 2.71–4.57\n\narm ori qi\n\n1.63–4.66\n\nforearm ori qi 2.40–8.40\n\nwrist ori qi 2.52–4.46\n\narm ori op 1.27–1.88\n\nforearm ori op 2.16–2.23\n\nwrist ori op 2.28–2.33\n\n-DH, link len est, sens ori est, motion speed[91]2016full body-\n\nlink ori\n\nlink pos\n\nassessment12 acc, 12 gyro, 12 mag-link len-static1, OMC\n\nhand ori\n\nelbow ori\n\nshoulder ori\n\nneck ori\n\nback ori\n\nankle ori\n\nknee ori\n\nhip ori\n\nhand ori 5.7–14.1\n\nelbow ori 6.2–12.5\n\nshoulder ori 19.7–40.2\n\nneck ori 3.9–12.3\n\nback ori 4.4–5.9\n\nankle ori 4.3–7.3\n\nknee ori 3.2–4.1\n\nhip ori 4.0–7.5\n\nhand ori 0.80–0.89\n\nelbow ori 0.81–0.96\n\nshoulder ori 0.39–0.86\n\nneck ori 0.84-0.98\n\nback ori 0.70–0.95\n\nankle ori 0.77–0.89\n\nknee ori 0.75–0.97\n\nhip ori 0.94–0.97\n\ncomplex vs simple task valid trials, 1920s manual handling valid trial, error due to biomechanics, total err, ISB kinematic model, MVN kinematic model[85]2016attitude-link orimethod1 acc, 1 gyro, 1 magquat oriKF paramsEKF-4, OMC\n\nroll\n\npitch\n\nyaw\n\nroll 1.0–5.0\n\npitch 1.6–4.1\n\nyaw 6.2–19\n\n-bias est, lin acc negl, 120 s texting walking valid trial, 120s swinging walking valid trial, 780 s unsupervised walking valid trial[105]2016lower limbs-link ori, pelvis posmethod7 acc, 7 gyro, 3 UWBkinematic chain, rot matKF params, link lenKF-1, OMC\n\nyaw\n\nankle fle\n\nknee fle\n\nhip fle\n\nhip abd\n\nankle fle 1.4–2.1\n\nknee fle 3.5–4.5\n\nhip fle 2.7–3.4\n\nhip abd 2.9–3.7\n\n-ZUPT, 100s walking valid trial, 100s jumping valid trial, 100s ascending valid trial\n\nTable A2\n\nAbbreviationFull NameCategoriesDescriptionoriorientationTarget, Kinematics & Constraints, Measure, RMSE, Correlationorientation of a rigid bodypospositionTarget, Calibration, Parameters, Validation, Measure, RMSE, Correlation, notesposition of a point of a rigid bodyfleflexion/extensionTarget, Measure, RMSE, Correlation, Sensors,anatomical term of motionabdabduction/adductionTarget, Measure, RMSE, Correlation, Sensors,anatomical term of motionrotrotationTarget, Kinematics & Constraints, Measure, Sensor Fusion Technique, Calibration, RMSE, Correlationrotation related either to rotation about an axis or rotation matrixpropronation/supinationTarget, Measure, RMSE, Correlation, notesretretraction/protractionTarget, Measure, RMSEscapular retraction/protractioneleelevation/depressionTarget, Measure, RMSEscapular elevation/depressionmagmagnetometerFocus, Sensors, Sensor Fusion Technique, Measure, notesreferred to either 3 axis (unless otherwise specified) magnetometer or its signalcompcompensationFocusreferred to compensation of magnetic field distortionsaccaccelerometerSensorsreferred to either 3 axis (unless otherwise specified) accelerometer or its signalgyrogyroscopeSensors, Sensor Fusion technique, notes3 axis (unless otherwise specified) gyroscopexd-Sensorsx axes sensor (e.g., 2d acc means biaxial accelerometer)mechmechanicalSensors, Validation, notesmechanical is usually referred to either trackers or rigs for validationbiomechbiomechanicalnotes-tracktrackerSensors-USultrasoundSensors, Validationultrasound sensor or motion tracking system based on ultrasoundexpexponentialKinematics & Constraintsexponential maps representationsegsegmentKinematics & Constraintsreferred to free segments representationCFComplementary FilterParameters, Sensor Fusion Technique, notes-lenlengthParameters, Measures, RMSE, noteslength of human limbs or robotic linksKFKalman FilterParameters, Sensor Fusion Technique"
    }
}