{
    "id": "wrong_mix_range_subsidiary_00054_2",
    "rank": 92,
    "data": {
        "url": "https://worldwidescience.org/topicpages/i/ibm%2Bsoftware%2Bservices.html",
        "read_more_link": "",
        "language": "en",
        "title": "ibm software services: Topics by WorldWideScience.org",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/WWSlogo_wTag650px-min.png",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/OSTIlogo.svg",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/ICSTIlogo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Software Process Improvement Journey: IBM Australia Application Management Services\n\nScience.gov (United States)\n\n2005-03-01\n\nSee Section 5.1.2) - Client Relationship Management ( CRM ) processes-specifically, Solution Design and Solution Delivery - Worldwide Project Management ...plex systems life-cycle management , rapid solutions development, custom development, package selection and implementation, maintenance, minor...CarnegieMellon ___ Software Engineering Institute Software Process Improvement Journey: IBM Australia Application Management Services Robyn Nichols\n\nOnline Help from IBM.\n\nScience.gov (United States)\n\nMoore, Jack\n\n1988-01-01\n\nThe article describes the IBM/Special Needs Exchange which consists of: (1) electronic mail, conferencing, and a library of text and program files on the CompuServe Information Service; and (2) a dial-in database of special education software for IBM and compatible computers. (DB)\n\nInference in media space. The case of IBM Software Executive Briefing Center - Rome\n\nDirectory of Open Access Journals (Sweden)\n\nToni Marino\n\n2014-11-01\n\nFull Text Available In our paper we apply Peirce's model of Arguments (Statistical Deduction, Probabilistic Deduction, Induction and Abduction to a communication process where negotiating sense and meanings is emphasized. We selected a communication space where everything is planned as a medium of sense (video terminals, screens, lights, etc. namely the IBM Software Executive Briefing Center in Italy, a workplace used to exchange views, negotiate or transact. It is based in Rome in the same building as the International Development Laboratory of the IBM Software Group. The Software Center is the place where IBM welcomes its potential customers and has the opportunity to show them its technology and offer solutions. This paper focuses on \"media space\" in the Center which is structured by the seller according to his/her idea of the buyer's interpretive process. This paper analyzes the roles of visual codes in the allocation of functions. It also looks into the relation between the symbolism of the company with its marketing, past history and media space in order to define the buyer's typology of inference (deduction, induction or abduction in relation to the communication strategy of the media space design. The research is conducted directly in the field by interviewing the Manager of the IBM Center as well as asking people who use it to fill in an anonymous questionnaire, which analyses both the media space and the plan of the building.\n\n76 FR 32231 - International Business Machines (IBM), Sales and Distribution Business Unit, Global Sales...\n\nScience.gov (United States)\n\n2011-06-03\n\n... for the workers and former workers of International Business Machines (IBM), Sales and Distribution... reconsideration alleges that IBM outsourced to India and China. During the reconsideration investigation, it was..., Armonk, New York. The subject worker group supply computer software development and maintenance services...\n\nIBM Industry Practice: Challenges in Offshore Software Development from a Global Delivery Center\n\nScience.gov (United States)\n\nMusio, Ilario\n\nOffshore software development has greatly influenced competitiveness among IT companies in the last decade. Despite the fact that there are matured and developed offshoring methodologies, there is an ongoing tendency to look for new ways of improving them. Major IT corporations successfully rely on their offshore delivery centers for bridging the gap between communication and infrastructure boundaries. However, projects tend to fail, so problems have to be considered that arise between on- and offshore parts within the same corporation. Based on seven case studies from the industry, this paper describes experiences and challenges faced during the execution of offshore application development between IBM Switzerland and IBM India. Additionally, approaches on how they can be solved are proposed.\n\nMaintenance Manual for AUDIT. A System for Analyzing SESCOMP Software. Volume 4: Appendix D. Listings of the AUDIT Software for the IBM 360.\n\nScience.gov (United States)\n\n1977-08-01\n\nThe AUDIT documentation provides the maintenance programmer personnel with the information to effectively maintain and use the AUDIT software. The ...SESCOMPSPEC’s) and produces reports detailing the deviations from those standards. The AUDIT software also examines a program unit to detect and report...changes in word length on the output of computer programs. This report contains the listings of the AUDIT software for the IBM 360. (Author)\n\n75 FR 60141 - International Business Machines (IBM), Global Technology Services Delivery Division, Including On...\n\nScience.gov (United States)\n\n2010-09-29\n\n... 25, 2010, applicable to workers of International Business Machines (IBM), Global Technology Services... hereby issued as follows: All workers of International Business Machines (IBM), Global Technology... DEPARTMENT OF LABOR Employment and Training Administration [TA-W-74,164] International Business...\n\n76 FR 54800 - International Business Machines (IBM), Software Group Business Unit, Quality Assurance Group, San...\n\nScience.gov (United States)\n\n2011-09-02\n\n... DEPARTMENT OF LABOR Employment and Training Administration [TA-W-74,554] International Business Machines (IBM), Software Group Business Unit, Quality Assurance Group, San Jose, California; Notice of Negative Determination on Reconsideration On January 21, 2011, the Department of Labor (Department) issued an Affirmative Determination Regarding...\n\n76 FR 5832 - International Business Machines (IBM), Software Group Business Unit, Optim Data Studio Tools QA...\n\nScience.gov (United States)\n\n2011-02-02\n\n... DEPARTMENT OF LABOR Employment and Training Administration [TA-W-74,554] International Business Machines (IBM), Software Group Business Unit, Optim Data Studio Tools QA, San Jose, CA; Notice of Affirmative Determination Regarding Application for Reconsideration By application dated November 29, 2010, a worker and a state workforce official...\n\nEZVIDEO, DISSPLA Graphics Software Simulation on IBM PC\n\nInternational Nuclear Information System (INIS)\n\n1991-01-01\n\n1 - Description of program or function: EZVIDEO simulates a subset of the DISSPLA plotting package to make plots on the IBM PC screen. Screen dumps can also be made to an attached LaserJet or Epson printer to make hard copy without using terminal emulators. The forerunner of EZVIDEO was called EZPLOT. 2 - Method of solution: The subroutines in the EZVIDEO system are based on the Hewlett Packard HP 9000 simulation of DISSPLA. These routines manipulate the pen movements on the screen and are also capable of capturing these same movements so that a hardcopy can be made to dot matrix or laser printer. 3 - Restrictions on the complexity of the problem: For plotting on the IBM PC, the plotting emulator PCPLOT is needed\n\nIBM Software Defined Storage and ownCloud Enterprise Editon - a perfect match for hyperscale Enterprise File Sync and Share\n\nCERN Multimedia\n\nCERN. Geneva\n\n2014-01-01\n\nIBM Software Defined Storage, in particular the technology offering codenamed Elastic Storage (based on GPFS technology) has proven to be an ideal match for Enterprise File Sync and Share (EFSS) solutions that need highly scalable storage. The presentation will provide insight into the integration of Elastic Storage with the ownCloud Enterprise Edition (based on Open Source technology) software that showed impressive scalability and performance metrics during a proof-of-concept phase of an installation that is supposed to serve 300000 users when fully deployed.\n\nMultiple uses for an old ibm-pc 486 in nuclear medicine using open source software\n\nInternational Nuclear Information System (INIS)\n\nAnselmi, C.E.; Anselmi, O.E.\n\n2002-01-01\n\nMultiple uses for an old ibm-pc 486 in nuclear medicine using open source software. Aim: To use a low budget platform to: 1 - send patient's images from processing workstation to the nuclear medicine information system; 2 - backup data files from acquisition in DICOM format in cd-rom; 3 - move data across different hospitals allowing remote processing and reading of studies. Both nuclear medicine systems in the two hospitals are Siemens Icon workstations. Material and methods: The computer used is an ibm-pc 486, which sells for about US dollar 70. The operating system installed is Red Hat Linux 6.2. The sending of the patient's images to the information system is performed through AppleTalk and Samba. The backup of acquisition files is performed by the communication from the workstation through DICOM to the Storage Class Provider (Office Dicom Toolkit) running in the 486, and the files are later burned on cd-rom. A similar configuration is present in another hospital, with minor differences in processor type. Data from any of the hospitals can be sent to the other one through the remote synchronization performed by Rsync. The connection between both Linux computers is encrypted through Secure Shell (open SSH). All software installed in the 486 was downloaded from the internet at no cost. No software was installed in the workstations. Results: The whole system is recognized transparently by the workstation's system as a local storage disk, such as the acquisition cameras or the other workstations. The transfer of images from the workstation to the information system or to a remote hospital is done the same way as copying data from the acquisition cameras in the vendor's software. When transferring large files across hospitals, the synchronization may take 1 to 3 minutes through broad band internet. The backup in DICOM format in cd-rom allows review of patient data in any computer equipped with a DICOM viewing software, as well as the re-processing of that\n\nIBM PC/IX operating system evaluation plan\n\nScience.gov (United States)\n\nDominick, Wayne D. (Editor); Granier, Martin; Hall, Philip P.; Triantafyllopoulos, Spiros\n\n1984-01-01\n\nAn evaluation plan for the IBM PC/IX Operating System designed for IBM PC/XT computers is discussed. The evaluation plan covers the areas of performance measurement and evaluation, software facilities available, man-machine interface considerations, networking, and the suitability of PC/IX as a development environment within the University of Southwestern Louisiana NASA PC Research and Development project. In order to compare and evaluate the PC/IX system, comparisons with other available UNIX-based systems are also included.\n\nIBM announces global Grid computing solutions for banking, financial markets\n\nCERN Multimedia\n\n2003-01-01\n\n\"IBM has announced a series of Grid projects around the world as part of its Grid computing program. They include IBM new Grid-based product offerings with business intelligence software provider SAS and other partners that address the computer-intensive needs of the banking and financial markets industry (1 page).\"\n\nPengembangan Sistem Informasi Geografis Berbasis Node.JS untuk Pemetaan Mesin dan Tracking Engineer dengan Pemanfaatan Geolocation pada PT IBM Indonesia\n\nDirectory of Open Access Journals (Sweden)\n\nRACHMAT FAJRIN\n\n2017-09-01\n\nFull Text Available PT IBM memiliki banyak klien di Indonesia, ini membuat persebaran produk (dalam hal ini mesin atm yang semakin meluas di wilayah Indonesia. Hal ini memicu PT IBM untuk menempatkan engineer dibanyak wilayah untuk memenuhi kebutuhan services dan maintenance. Untuk itu dalam penelitian ini dikembangkan sebuah sistem informasi geografis untuk pemetaan mesin dan tracking engineer dengan pemanfaatan geolocation yang bertujuan untuk menampilkan peta digital beserta lokasi mesin dan engineer di seluruh Indonesia, yang akan memudahkan PT IBM dalam pemberian tugas kepada engineer untuk services dan maintenance ke lokasi mesin terdekat. Sistem ini dibangun menggunakan beberapa software open source yaitu, Node.JS dan Express.JS yang merupakan server-side javascript web platform, Handlebars untuk template engine, MySQL sebagai database storage, Postman yang berfungsi sebagai API (Application Program Interface testing, Google Maps API untuk implementasi peta digital dan juga Firebase Cloud Messaging (FCM untuk platform mengirim notifikasi dari web ke device engineer.Pengembangan Sistem Informasi Geografis Berbasis Node.JS untuk Pemetaan Mesin dan Tracking Engineer dengan Pemanfaatan Geolocation pada PT IBM Indonesia\n\nUsers guide for the ANL IBM SPx\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nGropp, W.; Lusk, E.\n\n1994-12-01\n\nThis guide presents the features of the IBM SPx installed in the Mathematics and Computer Science Division at Argonne National Laboratory. The guide describes the available hardware and software, access policies, and hints for using the system productively.\n\nConfiguration control plan for the ports NCS IBM RS/6000\n\nInternational Nuclear Information System (INIS)\n\nBrown, A.S.\n\n1996-01-01\n\nThis document describes the actions and responsibilities for maintaining the quality and integrity of the NS software resident on the IBM RS/6000 workstation managed by the Nuclear Criticality Safety group at the Portsmouth Gaseous Diffusion Plant. This document does not address the validation of NS software packages for the RS/6000\n\nThe Little Giant: The IBM Series/1 in Library Applications.\n\nScience.gov (United States)\n\nHendricks, Donald D.; Manino, Glenn\n\n1987-01-01\n\nThis description of the use of IBM Series/1 minicomputers to implement a library automation system includes discussion of current functions of the system, the system configuration, communications capabilities, software, and cost factors. (CLB)\n\nAn Apple for Your IBM PC--The Quadlink Board.\n\nScience.gov (United States)\n\nOwen, G. Scott\n\n1984-01-01\n\nDescribes nature and installation of the QUADLINK board which allows Apple software to be run on IBM PC microcomputers. Although programs tested ran without problems, users should test their own programs since there are some copy protection schemes that can baffle the board. (JN)\n\nIBM PC based automatic drive system for Bulat setup\n\nInternational Nuclear Information System (INIS)\n\nLuchaninov, A.A.; Tolok, V.T.\n\n1999-01-01\n\nNon-expensive computer drive system for Bulat setup is described. System's hardware consists of IBM PC and conjunction block, providing 12 output channels, Software includes the main program, utilities and technology processes database. System may be used at surface modification processes, especially multilayer multicomponent coatings deposition\n\nThe GF11 project at IBM\n\nInternational Nuclear Information System (INIS)\n\nSexton, J.C.\n\n1990-01-01\n\nThe GF11 project at IBM's T. J. Watson Research Center is entering full production for QCD numerical calculations. This paper describes the GF11 hardware and system software, and discusses the first production program which has been developed to run on GF11. This program is a variation of the Cabbibo Marinari pure gauge Monte Carlo program for SU(3) and is currently sustaining almost 6 gigaflops on 360 processors in GF11\n\nThe GF11 project at IBM\n\nScience.gov (United States)\n\nSexton, James C.\n\n1990-08-01\n\nThe GF11 project at IBM's T. J. Watson Research Center is entering full production for QCD numerical calculations. This paper describes the GF11 hardware and system software, and discusses the first production program which has been developed to run on GF11. This program is a variation of the Cabbibo Marinari pure gauge Monte Carlo program for SU(3) and is currently sustaining almost 6 gigaflops on 360 processors in GF11.\n\nIBM ThinkPad radiation testing and recovery during EUROMIR missions\n\nInternational Nuclear Information System (INIS)\n\nMartignano, M.; Harboe-Sorensen, R.\n\n1995-01-01\n\nThis paper presents the results of an experiment, conducted on-board the Russian MIR Space Station during a joint Russian and European mission, EUROMIR '94. A commercially available IBM ThinkPad 750C was evaluated by running a software system which monitored the notebook's behavior and counted the number of single event upsets. The used software system and ground verification tests are also presented. Finally, another software system, able to ruggedize normal personal computers for usage in space, is described\n\nCase study: IBM Watson Analytics cloud platform as Analytics-as-a-Service system for heart failure early detection\n\nOpenAIRE\n\nGuidi, Gabriele; Miniati, Roberto; Mazzola, Matteo; Iadanza, Ernesto\n\n2016-01-01\n\nIn the recent years the progress in technology and the increasing availability of fast connections have produced a migration of functionalities in Information Technologies services, from static servers to distributed technologies. This article describes the main tools available on the market to perform Analytics as a Service (AaaS) using a cloud platform. It is also described a use case of IBM Watson Analytics, a cloud system for data analytics, applied to the following research scope: detect...\n\nMaintenance of Microcomputers. Manual and Apple II Session, IBM Session.\n\nScience.gov (United States)\n\nCoffey, Michael A.; And Others\n\nThis guide describes maintenance procedures for IBM and Apple personal computers, provides information on detecting and diagnosing problems, and details diagnostic programs. Included are discussions of printers, terminals, disks, disk drives, keyboards, hardware, and software. The text is supplemented by various diagrams. (EW)\n\nA software program for exchanging MR data\n\nDEFF Research Database (Denmark)\n\nRing, P B; Jensen, J A; Henriksen, O\n\n1993-01-01\n\nof digital MR images of the human brain. Because there was no common data format, software package was developed for data exchange. This article describes the basic features of the developed software. The software package was written in the language of C and was successfully tested on an IBM-6150 UNIX...... workstation. The software is currently being tested on the following series of UNIX workstations: SUN SPARC, IBM RS6000, and HP 9000/700....\n\nIBM 3705 Communications Controller\n\nCERN Multimedia\n\n1972-01-01\n\nThe IBM 3705 Communications Controller is a simple computer which attaches to an IBM System/360 or System/370. Its purpose is to connect communication lines to the mainframe channel. It was a first communications controller of the popular IBM 37xx series.\n\nSoftware life after in-service\n\nInternational Nuclear Information System (INIS)\n\nTseng, M.; Eng, P.\n\n1993-01-01\n\nSoftware engineers and designers tend to conclude a software project at the in-service milestone of the software life cycle. But the reality is that the 'life after in-service' is significantly longer than other phases of the life cycle, typically 20 years or more depending on the maintainability of the hardware platform and the designed life of the plant. During this period, the software asset (as with other physical assets in the plant) continues to be upgraded to correct deficiencies, meet new requirements, cope with obsolescence of equipment and so on. The software life cycle ends with a migration of the software to a different platform. It is typical in a software development project to put a great deal of emphasis on design methodologies, techniques, tools, development environment, standard procedures, and project management to ensure quality product is delivered on schedule and within budget. More often than not, a disproportion of emphasis is placed on the issues and needs of the in-service phase. Once the software is in-service, the designers move on to other projects, while the maintenance and support staff must manage the software. This paper examines the issues in three steps. First it presents a view of software from maintenance and support staff perspectives, including complexity of software, suitability of documentation, configuration management, training, difficulties and risks associated with making changes, required skills and knowledge. Second, it identifies the concerns raised from these viewpoints, including costs of maintaining the software, ability to meet additional requirements, availability of support tools, length of time required to engineer and install changes, and a strategy for the migration of software asset. Finally it discusses some approaches to deal with the concerns. (Author) 5 refs., fig\n\nExploring the organizational impact of software-as-a-Service on software vendors the role of organizational integration in software-as-a-Service development and operation\n\nCERN Document Server\n\nStuckenberg, Sebastian\n\n2014-01-01\n\nSoftware-as-a-Service has gained momentum as a software delivery and pricing model within the software industry. Existing practices of software vendors are challenged by a potential paradigm shift. This book analyzes the implications of Software-as-a-Service on software vendors using a business model and value chain perspective. The analysis of qualitative data from software vendors highlights the role of organizational integration within software vendors. By providing insights regarding the impact of Software-as-a-Service on organizational structures and processes of software vendors, this st\n\nGeorge E. Pake Prize Lecture: Physical Sciences Research at IBM: Still at the Cutting Edge\n\nScience.gov (United States)\n\nTheis, Thomas\n\n2015-03-01\n\nThe information technology revolution is in its ``build out'' phase. The foundational scientific insights and hardware inventions are now many decades old. The microelectronics industry is maturing. An increasing fraction of the total research investment is in software and services, as applications of information technology transform every business and every sector of the public and private economy. Yet IBM Research continues to make substantial investments in hardware technology and the underlying physical sciences. While some of this investment is aimed at extending the established transistor technology, an increasing fraction is aimed at longer-term and possibly disruptive research - new devices for computing, such as tunneling field-effect transistors and nanophotonic circuits, and new architectures, such as neurosynaptic systems and quantum computing. This research investment is a bet that the old foundations of information technology are ripe for reinvention. After all, today's information technology devices and systems operate far from any fundamental limits on speed and energy efficiency. But how can IBM make risky long-term research investments in an era of global competition, with financial markets focused on the short term? One important answer is partnerships. Since its early days, IBM Research has pursued innovation in information technology and innovation in the ways it conducts the business of research. By continuously evolving new models for research and development partnerships, it has extended its global reach, increased its impact on IBM's customers, and expanded the breadth and depth of its research project portfolio. Research in the physical sciences has often led the way. Currently on assignment to the Semiconductor Research Corporation.\n\nGeneralized Information Architecture for Managing Requirements in IBM?s Rational DOORS(r) Application.\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nAragon, Kathryn M.; Eaton, Shelley M.; McCornack, Marjorie Turner; Shannon, Sharon A.\n\n2014-12-01\n\nWhen a requirements engineering effort fails to meet expectations, often times the requirements management tool is blamed. Working with numerous project teams at Sandia National Laboratories over the last fifteen years has shown us that the tool is rarely the culprit; usually it is the lack of a viable information architecture with well- designed processes to support requirements engineering. This document illustrates design concepts with rationale, as well as a proven information architecture to structure and manage information in support of requirements engineering activities for any size or type of project. This generalized information architecture is specific to IBM's Rational DOORS (Dynamic Object Oriented Requirements System) software application, which is the requirements management tool in Sandia's CEE (Common Engineering Environment). This generalized information architecture can be used as presented or as a foundation for designing a tailored information architecture for project-specific needs. It may also be tailored for another software tool. Version 1.0 4 November 201\n\nData Discovery with IBM Watson\n\nScience.gov (United States)\n\nFessler, J.\n\n2016-12-01\n\nBM Watson is a cognitive computing system that uses machine learning, statistical analysis, and natural language processing to find and understand the clues in questions posed to it. Watson was made famous when it bested two champions on TV's Jeopardy! show. Since then, Watson has evolved into a platform of cognitive services that can be trained on very granular fields up study. Watson is being used to support a number of subject domains, such as cancer research, public safety, engineering, and the intelligence community. IBM will be providing a presentation and demonstration on the Watson technology and will discuss its capabilities including Natural Language Processing, text analytics and enterprise search, as well as cognitive computing with deep Q&A. The team will also be giving examples of how IBM Watson technology is being used to support real-world problems across a number of public sector agencies\n\nBill Lang's contributions to acoustics at the International Business Machines Corp. (IBM) and to IBM in general\n\nScience.gov (United States)\n\nNobile, Matthew A.; Chu, Richard C.\n\n2005-09-01\n\nAlthough Bill Lang's accomplishments and key roles in national and international standards and in the formation of INCE are widely recognized, sometimes it has to be remembered that for nearly 35 years he also had a ``day job'' at the IBM Corporation. His achievements at IBM were no less significant and enduring than those in external standards and professional societies. This paper will highlight some of the accomplishments and activities of Bill Lang as an IBM noise control engineer, the creator of the IBM Acoustics Lab in Poughkeepsie, the founder of the global Acoustics program at IBM, and his many other IBM leadership roles. Bill was also a long-serving IBM manager, with the full set of personnel issues to deal with, so his people-management skills were often called into play. Bill ended his long and fruitful IBM career at a high point. In 1988, he took an original idea of his to the top of IBM executive management, which led directly to the formation of the IBM Academy of Technology, today the preeminent body of IBM top technical leaders from around the world.\n\nIBM 5150 computer\n\nCERN Multimedia\n\n1981-01-01\n\nIBMâs first personal computer arrived nearly 10 years after others companies, but instantly legitimized the market. IBM introduced its PC in 1981. IBM equipped the model 5150 with a cassette port for connecting a cassette drive. The first IBM PC ran on a 4.77 MHz Intel 8088 microprocessor. The PC came equipped with 16 kilobytes of memory, expandable to 256k. The PC came with one or two 160k floppy disk drives and an optional color monitor. The price tag started at $1,565, which would be nearly $4,000 (about â¬3,400) today.\n\nIBM-PC-based reactor neutronics analysis package\n\nInternational Nuclear Information System (INIS)\n\nNigg, D.W.; Wessol, D.E.; Grimesey, R.A.; Parsons, D.K.; Wheeler, F.J.; Yoon, W.Y.; Lake, J.A.\n\n1985-01-01\n\nTechnical advances over the past few years have led to a situation where a wide range of complex scientific computations can now be done on properly configured microcomputers such as the IBM-PC (personal computer). For a number of reasons, including security, economy, and user convenience, the development of a comprehensive system of reactor neutronics codes suitable for operation on the IBM-PC has been undertaken at the Idaho National Engineering Laboratory (INEL). It is anticipated that a PC-based code system could also have wide applicability in the nuclear engineering education community since conversion of software generated by national laboratories and others to college and university mainframe hardware has historically been a time-consuming process that has sometimes met with only limited success. This paper discusses the philosophy behind the INEL reactor neutronics PC code system and describes those parts of the system that are currently complete, those that are now under development, and those that are still in the planning stage\n\nPerforming data analysis using IBM SPSS\n\nCERN Document Server\n\nMeyers, Lawrence S; Guarino, A J\n\n2013-01-01\n\nThis book is designed to be a user's guide for students and other interested readers to perform statistical data analysis with IBM SPSS, which is a major statistical software package used extensively in academic, government, and business settings. This bookÂ addresses the needs, level of sophistication, and interest in introductory statistical methodology on the part of undergraduate and graduate students in social and behavioral science, business, health-related, and education programs.Â Each chapter covers a particular statistical procedure and has the following format:Â an example pr\n\nIBM-PC based high voltage controller [Paper No.: L7\n\nInternational Nuclear Information System (INIS)\n\nMondal, N.K.; Kalmani, S.D.\n\n1993-01-01\n\nA simple IBM-PC/XT based high voltage controller is designed for C.A.E.N. high voltage supply unit, which is being used for testing the prototype detector for future accelerator experiment. The high voltage output of the supply unit can be remotely programmed. The V-set Lemo connectors at the rear panel provides the remote control facility. Similarly V-mon and I-mon can be used for remotely monitoring the voltage set and the current drawn from the supply unit. The controller described here sets the high voltage through V-set and monitors the voltage set, through V-mon at a pre-determined time interval. The monitoring is a background job and is done as an interrupt service routine of IRQ3. A simple menu driven software package used is written in Q-Basic and MASM. (author). 1 fig\n\nSoftware To Go: A Catalog of Software Available for Loan.\n\nScience.gov (United States)\n\nKurlychek, Ken, Comp.\n\nThis catalog lists the holdings of the Software To Go software lending library and clearinghouse for programs and agencies serving students or clients who are deaf or hard of hearing. An introduction describes the clearinghouse and its collection of software, much of it commercial and copyrighted material, for Apple, Macintosh, and IBM (MS-DOS)â¦\n\nSoftware as a service approach to sensor simulation software deployment\n\nScience.gov (United States)\n\nWebster, Steven; Miller, Gordon; Mayott, Gregory\n\n2012-05-01\n\nTraditionally, military simulation has been problem domain specific. Executing an exercise currently requires multiple simulation software providers to specialize, deploy, and configure their respective implementations, integrate the collection of software to achieve a specific system behavior, and then execute for the purpose at hand. This approach leads to rigid system integrations which require simulation expertise for each deployment due to changes in location, hardware, and software. Our alternative is Software as a Service (SaaS) predicated on the virtualization of Night Vision Electronic Sensors (NVESD) sensor simulations as an exemplary case. Management middleware elements layer self provisioning, configuration, and integration services onto the virtualized sensors to present a system of services at run time. Given an Infrastructure as a Service (IaaS) environment, enabled and managed system of simulations yields a durable SaaS delivery without requiring user simulation expertise. Persistent SaaS simulations would provide on demand availability to connected users, decrease integration costs and timelines, and benefit the domain community from immediate deployment of lessons learned.\n\nProcedures to analyse Î³-ray spectra obtained from the ORTEC or nuclear data ND-680 system by ORTEC's analysis software packages incorporated into a separate IBM-PC computer\n\nInternational Nuclear Information System (INIS)\n\nZhang Xiu Zhen.\n\n1990-01-01\n\nA detailed description is presented for processing Î³-spectra produced by means of Ortec or Nuclear Data spectrometry systems on an off-line IBM-PC. The ORTEC analysis software packages were transferred to and implemented on the PC A/T, and the different spectra were recorded on discs and subsequently brought into the format required by the program for the calculation of photo peak areas. (author)\n\nTransfer of numeric ASCII data files between Apple and IBM personal computers.\n\nScience.gov (United States)\n\nAllan, R W; Bermejo, R; Houben, D\n\n1986-01-01\n\nListings for programs designed to transfer numeric ASCII data files between Apple and IBM personal computers are provided with accompanying descriptions of how the software operates. Details of the hardware used are also given. The programs may be easily adapted for transferring data between other microcomputers.\n\nSummary inside IBM's historic turnaround\n\nCERN Document Server\n\n2014-01-01\n\nThis work offers a summary of the book \"WHO SAYS ELEPHANTS CAN'T DANCE? Inside IBM's Historic Turnaround\" by Louis Gerstner.In nine years as the chairman and CEO of International Business Machine Corporation (IBM), Louis Gerstner brought about a dramatic change in the company's fortunes. When he took charge, IBM was on the verge of extinction as the victim of rapid changes in the computer industry. However, instead of breaking up IBM as most analysts were suggesting, Gerstner and his management team turned the company around and restored it to a position of power and influence within the indu\n\nMaterials accounting system for an IBM PC\n\nInternational Nuclear Information System (INIS)\n\nBearse, R.C.; Thomas, R.J.; Henslee, S.P.; Jackson, B.G.; Tracy, D.B.; Pace, D.M.\n\n1986-01-01\n\nWe have adapted the Los Alamos MASS accounting system for use on an IBM PC/AT at the Fuels Manufacturing Facility (FMF) at Argonne National Laboratory-West (ANL-WEST) in Idaho Falls, Idaho. Cost of hardware and proprietary software was less than $10,000 per station. The system consists of three stations between which accounting information is transferred using floppy disks accompanying special nuclear material shipments. The programs were implemented in dBASEIII and were compiled using the proprietary software CLIPPER. Modifications to the inventory can be posted in just a few minutes, and operator/computer interaction is nearly instantaneous. After the records are built by the user, it takes 4 to 5 seconds to post the results to the database files. A version of this system was specially adapted and is currently in use at the FMF facility at Argonne National Laboratory in Idaho Falls. Initial satisfaction is adequate and software and hardware problems are minimal\n\nQuantitative analysis and IBM SPSS statistics a guide for business and finance\n\nCERN Document Server\n\nAljandali, Abdulkader\n\n2016-01-01\n\nThis guide is for practicing statisticians and data scientists who use IBM SPSS for statistical analysis of big data in business and finance. This is the first of a two-part guide to SPSS for Windows, introducing data entry into SPSS, along with elementary statistical and graphical methods for summarizing and presenting data. Part I also covers the rudiments of hypothesis testing and business forecasting while Part II will present multivariate statistical methods, more advanced forecasting methods, and multivariate methods. IBM SPSS Statistics offers a powerful set of statistical and information analysis systems that run on a wide variety of personal computers. The software is built around routines that have been developed, tested, and widely used for more than 20 years. As such, IBM SPSS Statistics is extensively used in industry, commerce, banking, local and national governments, and education. Just a small subset of users of the package include the major clearing banks, the BBC, British Gas, British Airway...\n\nThe web server of IBM's Bioinformatics and Pattern Discovery group.\n\nScience.gov (United States)\n\nHuynh, Tien; Rigoutsos, Isidore; Parida, Laxmi; Platt, Daniel; Shibuya, Tetsuo\n\n2003-07-01\n\nWe herein present and discuss the services and content which are available on the web server of IBM's Bioinformatics and Pattern Discovery group. The server is operational around the clock and provides access to a variety of methods that have been published by the group's members and collaborators. The available tools correspond to applications ranging from the discovery of patterns in streams of events and the computation of multiple sequence alignments, to the discovery of genes in nucleic acid sequences and the interactive annotation of amino acid sequences. Additionally, annotations for more than 70 archaeal, bacterial, eukaryotic and viral genomes are available on-line and can be searched interactively. The tools and code bundles can be accessed beginning at http://cbcsrv.watson.ibm.com/Tspd.html whereas the genomics annotations are available at http://cbcsrv.watson.ibm.com/Annotations/.\n\nSoftware Reviews.\n\nScience.gov (United States)\n\nDwyer, Donna; And Others\n\n1989-01-01\n\nReviewed are seven software packages for Apple and IBM computers. Included are: \"Toxicology\"; \"Science Corner: Space Probe\"; \"Alcohol and Pregnancy\"; \"Science Tool Kit Plus\"; Computer Investigations: Plant Growth\"; \"Climatrolls\"; and \"Animal Watch: Whales.\" (CW)\n\nService software engineering for innovative infrastructure for global financial services\n\nOpenAIRE\n\nMAAD , Soha; MCCARTHY , James B.; GARBAYA , Samir; Beynon , Meurig; Nagarajan , Rajagopal\n\n2010-01-01\n\nInternational audience; The recent financial crisis motivates our re-thinking of the engineering principles for service software and infrastructures intended to create business value in vital sectors. Existing monolithic, inwarddirected, cost insensitive and highly regulated technical and organizational infrastructures for financial services make it difficult for the domain to benefit from opportunities offered by new computing models such as cloud computing, software as a service, hardware a...\n\nIBM Watson Analytics: Automating Visualization, Descriptive, and Predictive Statistics.\n\nScience.gov (United States)\n\nHoyt, Robert Eugene; Snider, Dallas; Thompson, Carla; Mantravadi, Sarita\n\n2016-10-11\n\nWe live in an era of explosive data generation that will continue to grow and involve all industries. One of the results of this explosion is the need for newer and more efficient data analytics procedures. Traditionally, data analytics required a substantial background in statistics and computer science. In 2015, International Business Machines Corporation (IBM) released the IBM Watson Analytics (IBMWA) software that delivered advanced statistical procedures based on the Statistical Package for the Social Sciences (SPSS). The latest entry of Watson Analytics into the field of analytical software products provides users with enhanced functions that are not available in many existing programs. For example, Watson Analytics automatically analyzes datasets, examines data quality, and determines the optimal statistical approach. Users can request exploratory, predictive, and visual analytics. Using natural language processing (NLP), users are able to submit additional questions for analyses in a quick response format. This analytical package is available free to academic institutions (faculty and students) that plan to use the tools for noncommercial purposes. To report the features of IBMWA and discuss how this software subjectively and objectively compares to other data mining programs. The salient features of the IBMWA program were examined and compared with other common analytical platforms, using validated health datasets. Using a validated dataset, IBMWA delivered similar predictions compared with several commercial and open source data mining software applications. The visual analytics generated by IBMWA were similar to results from programs such as Microsoft Excel and Tableau Software. In addition, assistance with data preprocessing and data exploration was an inherent component of the IBMWA application. Sensitivity and specificity were not included in the IBMWA predictive analytics results, nor were odds ratios, confidence intervals, or a confusion matrix\n\nA Novel Method for Mining SaaS Software Tag via Community Detection in Software Services Network\n\nScience.gov (United States)\n\nQin, Li; Li, Bing; Pan, Wei-Feng; Peng, Tao\n\nThe number of online software services based on SaaS paradigm is increasing. However, users usually find it hard to get the exact software services they need. At present, tags are widely used to annotate specific software services and also to facilitate the searching of them. Currently these tags are arbitrary and ambiguous since mostly of them are generated manually by service developers. This paper proposes a method for mining tags from the help documents of software services. By extracting terms from the help documents and calculating the similarity between the terms, we construct a software similarity network where nodes represent software services, edges denote the similarity relationship between software services, and the weights of the edges are the similarity degrees. The hierarchical clustering algorithm is used for community detection in this software similarity network. At the final stage, tags are mined for each of the communities and stored as ontology.\n\nCompiler issues associated with safety-related software\n\nInternational Nuclear Information System (INIS)\n\nFeinauer, L.R.\n\n1991-01-01\n\nA critical issue in the quality assurance of safety-related software is the ability of the software to produce identical results, independent of the host machine, operating system, or compiler version under which the software is installed. A study is performed using the VIPRE-0l, FREY-01, and RETRAN-02 safety-related codes. Results from an IBM 3083 computer are compared with results from a CYBER 860 computer. All three of the computer programs examined are written in FORTRAN; the VIPRE code uses the FORTRAN 66 compiler, whereas the FREY and RETRAN codes use the FORTRAN 77 compiler. Various compiler options are studied to determine their effect on the output between machines. Since the Control Data Corporation and IBM machines inherently represent numerical data differently, methods of producing equivalent accuracy of data representation were an important focus of the study. This paper identifies particular problems in the automatic double-precision option (AUTODBL) of the IBM FORTRAN 1.4.x series of compilers. The IBM FORTRAN version 2 compilers provide much more stable, reliable compilation for engineering software. Careful selection of compilers and compiler options can help guarantee identical results between different machines. To ensure reproducibility of results, the same compiler and compiler options should be used to install the program as were used in the development and testing of the program\n\nSafety & Service in the Skies\n\nScience.gov (United States)\n\nGrush, Mary\n\n2009-01-01\n\nAs colleges and universities rely more heavily on software as a service (SaaS), they're putting more critical data in the cloud. What are the security issues, and how are cloud providers responding? \"Campus Technology\" (\"CT\") went to three higher ed SaaS vendors--Google, IBM, and TopSchool--and asked them to share their thoughts about the state ofâ¦\n\nEducational Software: A Developer's Perspective.\n\nScience.gov (United States)\n\nArmstrong, Timothy C.; Loane, Russell F.\n\n1994-01-01\n\nExamines the current status and short-term future of computer software development in higher education. Topics discussed include educational advantages of software; current program development techniques, including object oriented programming; and market trends, including IBM versus Macintosh and multimedia programs. (LRW)\n\nSoftware Reviews: Programs Worth a Second Look.\n\nScience.gov (United States)\n\nOlds, Henry F., Jr.; And Others\n\n1988-01-01\n\nExamines four software packages: (1) \"Wordbench\"--writing and word processing, grades 9-12 (IBM and Apple); (2) \"Muppet Slate\"--language arts, grades K-2 (Apple); (3) \"Accu-Weather Forecaster\"--weather analysis and forecasting, grades 3-12 (modem with IBM or Mac); and (4) \"The Ripple That Changed Americanâ¦\n\nSoftware Reviews. Programs Worth a Second Look.\n\nScience.gov (United States)\n\nSchneider, Roxanne; Eiser, Leslie\n\n1989-01-01\n\nReviewed are three computer software packages for use in middle/high school classrooms. Included are \"MacWrite II,\" a word-processing program for MacIntosh computers; \"Super Story Tree,\" a word-processing program for Apple and IBM computers; and \"Math Blaster Mystery,\" for IBM, Apple, and Tandy computers. (CW)\n\nSOFTWARE ARCHITECTURE DESIGN OF GIS WEB SERVICE AGGREGATION BASED ON SERVICE GROUP\n\nDirectory of Open Access Journals (Sweden)\n\nJ.-C. Liu\n\n2012-08-01\n\nFull Text Available Based on the analysis of research status of domestic and international GIS web service aggregation and development tendency of public platform of GIS web service, the paper designed software architecture of GIS web service aggregation based on GIS web service group. Firstly, using heterogeneous GIS services model, the software architecture converted a variety of heterogeneous services to a unified interface of GIS services, and divided different types of GIS services into different service groups referring to description of GIS services. Secondly, a service aggregation process model was designed. This model completed the task of specific service aggregation instance, by automatically selecting member GIS Web services in the same service group. Dynamic capabilities and automatic adaptation of GIS Web services aggregation process were achieved. Thirdly, this paper designed a service evaluation model of GIS web service aggregation based on service group from three aspects, i.e. GIS Web Service itself, networking conditions and service consumer. This model implemented effective quality evaluation and performance monitoring of GIS web service aggregation. It could be used to guide the execution, monitor and service selection of aggregation process. Therefore, robustness of aggregated GIS web service was improved. Finally, the software architecture has been widely used in public platform of GIS web service and a number of geo-spatial framework constructions for digital city in Sichuan Province, and aggregated various GIS web services such as World Map(National Public Platform of Geo-spatial Service, ArcGIS, SuperMap, MapGIS, NewMap etc. Applications of items showed that this software architecture was practicability.\n\nSoftware to Go--And It Goes!\n\nScience.gov (United States)\n\nAbrams, Mary; Kurlychek, Ken\n\n1989-01-01\n\nThis article describes the Software Evaluation Clearinghouse for Educators of the Hearing Impaired at Gallaudet University (Washington, DC). Software compatible with Apple and IBM hardware is collected, rated by clearinghouse members, and described in a printed catalog. Tips on starting a software lending library are offered. (PB)\n\nSoftware as a Service - Common Service Bus (SAAS-CSB)\n\nOpenAIRE\n\nSwaminathan, R.; Karnavel, K.\n\n2013-01-01\n\nSoftware-as-a-Service (SaaS) is a form of cloud computing that relieves the user from the concern of hardware, software installation and management. It is an emerging business model that delivers software applications to the users through Web-based technology. Software vendors have varying requirements and SaaS applications most typically support such requirements. The various applications used by unique customers in a single instance are known as Multi-Tenancy. There would be a delay in serv...\n\nComparison of the AMDAHL 470V/6 and the IBM 370/195 using benchmarks\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nSnider, D.R.; Midlock, J.L.; Hinds, A.R.; Engert, D.E.\n\n1976-03-01\n\nSix groups of jobs were run on the IBM 370/195 at the Applied Mathematics Division (AMD) of Argonne National Laboratory using the current production versions of OS/MVT 21.7 and ASP 3.1. The same jobs were then run on an AMDAHL 470V/6 at the AMDAHL manufacturing facilities in Sunnyvale, California, using the identical operating systems. Performances of the two machines are compared. Differences in the configurations were minimized. The memory size on each machine was the same, all software which had an impact on run times was the same, and the I/O configurations were as similar as possible. This allowed the comparison to be based on the relative performance of the two CPU's. As part of the studies preliminary to the acquisition of the IBM 195 in 1972, two of the groups of jobs had been run on a CDC 7600 by CDC personnel in Arden Hills, Minnesota, on an IBM 360/195 by IBM personnel in Poughkeepsie, New York, and on the AMD 360/50/75 production system in June, 1971. 6 figures, 9 tables.\n\nIBM model M keyboard\n\nCERN Multimedia\n\n1985-01-01\n\nIn 1985, the IBM Model M keyboard was created. This timeless classic was a hit. IBM came out with several varients of the model M. They had the space saver 104 key which is the one most seen today and many international versions of that as well. The second type, and rarest is the 122 key model M which has 24 extra keys at the very top, dubbed the âprogrammers keyboardâ. IBM manufactured these keyboards until 1991. The model M features âcapsâ over the actual keys that can be taken off separately one at a time for cleaning or to replace them with colored keys or keys of another language, that was a very cost effective way of shipping out internationally the keyboards.\n\nEffect of system workload on operating system reliability - A study on IBM 3081\n\nScience.gov (United States)\n\nIyer, R. K.; Rossetti, D. J.\n\n1985-01-01\n\nThis paper presents an analysis of operating system failures on an IBM 3081 running VM/SP. Three broad categories of software failures are found: error handling, program control or logic, and hardware related; it is found that more than 25 percent of software failures occur in the hardware/software interface. Measurements show that results on software reliability cannot be considered representative unless the system workload is taken into account. The overall CPU execution rate, although measured to be close to 100 percent most of the time, is not found to correlate strongly with the occurrence of failures. Possible reasons for the observed workload failure dependency, based on detailed investigations of the failure data, are discussed.\n\nService-oriented Software Defined Optical Networks for Cloud Computing\n\nScience.gov (United States)\n\nLiu, Yuze; Li, Hui; Ji, Yuefeng\n\n2017-10-01\n\nWith the development of big data and cloud computing technology, the traditional software-defined network is facing new challenges (e.g., ubiquitous accessibility, higher bandwidth, more flexible management and greater security). This paper proposes a new service-oriented software defined optical network architecture, including a resource layer, a service abstract layer, a control layer and an application layer. We then dwell on the corresponding service providing method. Different service ID is used to identify the service a device can offer. Finally, we experimentally evaluate that proposed service providing method can be applied to transmit different services based on the service ID in the service-oriented software defined optical network.\n\nSoftware Reviews.\n\nScience.gov (United States)\n\nKinnaman, Daniel E.; And Others\n\n1988-01-01\n\nReviews four educational software packages for Apple, IBM, and Tandy computers. Includes \"How the West was One + Three x Four,\"\"Mavis Beacon Teaches Typing,\"\"Math and Me,\" and \"Write On.\" Reviews list hardware requirements, emphasis, levels, publisher, purchase agreements, and price. Discusses the strengthsâ¦\n\nDesign of multichannel counting system-2 for IBM PC and compatibles\n\nInternational Nuclear Information System (INIS)\n\nAhmad, Z.; Qamer, R.; Mushtaq, N.\n\n2001-04-01\n\nA multichannel, Counting System 2 (MCCS-2) data acquisition plug-in card for the IBM ISA, MCA and EISA bus architecture has been designed and developed for acquisition of pulsed signal. The card features large dynamic range is achieved with the help of 16-bit pulse counters, fast signal acquisition and a self-testing capability in a single slot card. The MCCS-2 (designed by R and D group, CD) is an upgraded version of MCCS-1 [6]. The MCCS-2 consists of a plug-in interface card (MCCS-PC) for IBM PC and compatibles and a BNC terminal module (MCCS-BNC). The MCCS-PC is address selectable and can simultaneous monitoring ten independent SCA inputs. An on board programmable timer provides elapsed time measurement. A menu-driven software program is developed for data acquisition and timer control. (author)\n\nLetter from Hong Kong: A Report on Chinese Food, Fake Apples, and IBM's Asian Strategy.\n\nScience.gov (United States)\n\nImmel, A. Richard\n\n1984-01-01\n\nNotes that microcomputer use in Hong Kong's small business community does not reflect the growth of its high-tech electronics industry and discusses IBM's influence in Hong Kong and Asia, the counterfeiting of Apple microcomputers and software, and why Apple currently has no recourse. (MBR)\n\n8-inch IBM floppy disk\n\nCERN Multimedia\n\n1971-01-01\n\nThe 8-inch floppy disk was a magnetic storage disk for the data introduced commercially by IBM in 1971. It was designed by an IBM team as an inexpensive way to load data into the IBM System / 370. Plus it was a read-only bare disk containing 80 KB of data. The first read-write version was introduced in 1972 by Memorex and could contain 175 KB on 50 tracks (with 8 sectors per track). Other improvements have led to various coatings and increased capacities. Finally, it was surpassed by the mini diskette of 5.25 inches introduced in 1976.\n\nThe Early Overseas Activities of IBM in Japan\n\nOpenAIRE\n\nåæ²¢, æ­£åº; ç°ä¸­, é ç« ; Masahiro, YOSHIZAWA; Masaaki, TANAKA; æç¥å­¦é¢å¤§å­¦; é´é¹¿ç­æå¤§å­¦; / SUZUKA JUNIOR COLLEGE\n\n1998-01-01\n\nThe purpose of this paper is to examine how IBM entered into prewar Japan and ran its wholly-owned subsidiary thereafter. Before examining something noted above, this paper surveys the process of formation of IBM and then traces its early overseas activities. Turning to the initial contacts between Japan and IBM, at first IBM carried out its mere export trade to Japan through Morimura and then Kurosawa. IBM then established its wholly-owned subsidiary, Japan Watson,in Japan to expand the busi...\n\nReviews, Software.\n\nScience.gov (United States)\n\nScience Teacher, 1988\n\n1988-01-01\n\nReviews two computer software packages for use in physical science, physics, and chemistry classes. Includes \"Physics of Model Rocketry\" for Apple II, and \"Black Box\" for Apple II and IBM compatible computers. \"Black Box\" is designed to help students understand the concept of indirect evidence. (CW)\n\nNAMMU (Release 6.1) for the IBM RS/6000: installation and running\n\nInternational Nuclear Information System (INIS)\n\nCliffe, K.A.\n\n1993-12-01\n\nNAMMU is a software package for modelling groundwater flow and transport in porous media. The package can be used to model steady-state and time-dependent behaviour, including unsaturated flow and the transport of heat and mass. An option is available for modelling radioactive decay and transport of chains of radionuclides. The software is based on an efficient implementation of the finite-element method that provides many options for modelling complex geological strata. This report describes how to install and run Release 6.1 of NAMMU on an IBM RS/6000 using version 6.1.4 of the job submission script. (Author)\n\nIBM eile, tÃ¤na ja homme / Kalle Kose\n\nIndex Scriptorium Estoniae\n\nKose, Kalle\n\n2007-01-01\n\nInfotehnoloogiafirma IBM arengust. Lisatud joonised: PC tootjate turuosad (1984-2004); IBM-i kÃ¤ive segmentide lÃµikes (2000-2005); IBM-i kÃ¤ive kvartaalselt. Vt. ka lk.13: IBM pÃ¼stitas patentide rekordi\n\nSoftware Review.\n\nScience.gov (United States)\n\nMcGrath, Diane, Ed.\n\n1989-01-01\n\nReviewed is a computer software package entitled \"Audubon Wildlife Adventures: Grizzly Bears\" for Apple II and IBM microcomputers. Included are availability, hardware requirements, cost, and a description of the program. The murder-mystery flavor of the program is stressed in this program that focuses on illegal hunting and gameâ¦\n\nS-Cube: Enabling the Next Generation of Software Services\n\nScience.gov (United States)\n\nMetzger, Andreas; Pohl, Klaus\n\nThe Service Oriented Architecture (SOA) paradigm is increasingly adopted by industry for building distributed software systems. However, when designing, developing and operating innovative software services and servicebased systems, several challenges exist. Those challenges include how to manage the complexity of those systems, how to establish, monitor and enforce Quality of Service (QoS) and Service Level Agreements (SLAs), as well as how to build those systems such that they can proactively adapt to dynamically changing requirements and context conditions. Developing foundational solutions for those challenges requires joint efforts of different research communities such as Business Process Management, Grid Computing, Service Oriented Computing and Software Engineering. This paper provides an overview of S-Cube, the European Network of Excellence on Software Services and Systems. S-Cube brings together researchers from leading research institutions across Europe, who join their competences to develop foundations, theories as well as methods and tools for future service-based systems.\n\nSoftware Service Engineering : Tenets and Challenges\n\nNARCIS (Netherlands)\n\nHeuvel, Willem-Jan van den; Zimmermann, Olaf; Leymann, Frank; Lago, Patricia; Schieferdecker, Ina; Zdun, Uwe; Avgeriou, Paris\n\n2009-01-01\n\nService-Oriented Architecture (SOA) constitutes a modern, standards-based and technology-independent paradigm and architectural style for distributed enterprise computing. The SOA style promotes the publishing, discovery, and binding of loosely-coupled, network-accessible software services. With SOA\n\nSTAFF TRAINING FOR SERVICE INDUSTRY\n\nDirectory of Open Access Journals (Sweden)\n\nO. Petrenko\n\n2015-03-01\n\nFull Text Available In all countries across the world macroeconomic shift from the production of physical things (agriculture and manufactured goods to execution of the service of public service. In headmost countries more than 70% of GDP forms by service industry, in which over half of mankind is working today (according to the information of International Labor Organization. The science of services that occurred recently upon an initiative of IBM firm, designed to explore the main principles of functioning complex services systems, ways of creation, scaling and improving such systems. In this paper considered the questions of penetration the services in engineering systems (particularly, in software structures capabilities of the engineering and staffing processes of creating and maintaining of system services.\n\nCase Study: IBM Watson Analytics Cloud Platform as Analytics-as-a-Service System for Heart Failure Early Detection\n\nDirectory of Open Access Journals (Sweden)\n\nGabriele Guidi\n\n2016-07-01\n\nFull Text Available In the recent years the progress in technology and the increasing availability of fast connections have produced a migration of functionalities in Information Technologies services, from static servers to distributed technologies. This article describes the main tools available on the market to perform Analytics as a Service (AaaS using a cloud platform. It is also described a use case of IBM Watson Analytics, a cloud system for data analytics, applied to the following research scope: detecting the presence or absence of Heart Failure disease using nothing more than the electrocardiographic signal, in particular through the analysis of Heart Rate Variability. The obtained results are comparable with those coming from the literature, in terms of accuracy and predictive power. Advantages and drawbacks of cloud versus static approaches are discussed in the last sections.\n\nPC-Link historical data base system MODCOMP/IBM at link for neutral particle beam operation\n\nInternational Nuclear Information System (INIS)\n\nThurgood, P.\n\n1989-01-01\n\nPC-Link is a combination of hardware and software that connects an IBM PC/AT to a MODCOMP minicomputer. It is designed as an aid to the Neutral Beam operations coordinator during injection into the DIII-D tokamak project. An IBM PC/AT is linked to 4 MODCOMP realtime acquisition systems, each of which controls 2 neutral particle beam sources. At various points in the shot sequence, data is sent to the IBM PC/AT. This data can then be integrated with the data from the other sources into tables or graphics displays for use by the Beam Coordinator. In this way, the coordinator gets realtime feedback on the relative settings and performance of the sources and can observe trends within a particular source at one location. The PC-Link is used for observing relative timing information and for post shot historical archiving. The concept of the PC-Link was originally proposed several years ago. In April 1988, in-house implementation of the link software was begun. The PC-Link receives approximately 2 Kbytes of data per source per shot. This data is converted from MODCOMP format to IBM PC format and archived to disk. The last 280 shots per source are stored to disk to observe trends. The data can be displayed in a number of formats depending upon the situation. For example, prior to a shot, the beam MODCOMPs are sent timing information from the DIII-D tokamak control system. This data is echoed on the PC in a graphical representation displaying all 8 sources. At the end of the shot, the actual running times are displayed along with the requested settings. Any subset of the Historical data may be displayed either graphically or in tables for realtime comparisons between sources. 4 figs\n\nAvailability of software services for a hospital information system.\n\nScience.gov (United States)\n\nSakamoto, N\n\n1998-03-01\n\nHospital information systems (HISs) are becoming more important and covering more parts in daily hospital operations as order-entry systems become popular and electronic charts are introduced. Thus, HISs today need to be able to provide necessary services for hospital operations for a 24-h day, 365 days a year. The provision of services discussed here does not simply mean the availability of computers, in which all that matters is that the computer is functioning. It means the provision of necessary information for hospital operations by the computer software, and we will call it the availability of software services. HISs these days are mostly client-server systems. To increase availability of software services in these systems, it is not enough to just use system structures that are highly reliable in existing host-centred systems. Four main components which support availability of software services are network systems, client computers, server computers, and application software. In this paper, we suggest how to structure these four components to provide the minimum requested software services even if a part of the system stops to function. The network system should be double-protected in stratus using Asynchronous Transfer Mode (ATM) as its base network. Client computers should be fat clients with as much application logic as possible, and reference information which do not require frequent updates (master files, for example) should be replicated in clients. It would be best if all server computers could be double-protected. However, if that is physically impossible, one database file should be made accessible by several server computers. Still, at least the basic patients' information and the latest clinical records should be double-protected physically. Application software should be tested carefully before introduction. Different versions of the application software should always be kept and managed in case the new version has problems. If a hospital\n\nComputer Center: Software Review.\n\nScience.gov (United States)\n\nDuhrkopf, Richard, Ed.; Belshe, John F., Ed.\n\n1988-01-01\n\nReviews a software package, \"Mitosis-Meiosis,\" available for Apple II or IBM computers with colorgraphics capabilities. Describes the documentation, presentation and flexibility of the program. Rates the program based on graphics and usability in a biology classroom. (CW)\n\nThe web server of IBM's Bioinformatics and Pattern Discovery group: 2004 update.\n\nScience.gov (United States)\n\nHuynh, Tien; Rigoutsos, Isidore\n\n2004-07-01\n\nIn this report, we provide an update on the services and content which are available on the web server of IBM's Bioinformatics and Pattern Discovery group. The server, which is operational around the clock, provides access to a large number of methods that have been developed and published by the group's members. There is an increasing number of problems that these tools can help tackle; these problems range from the discovery of patterns in streams of events and the computation of multiple sequence alignments, to the discovery of genes in nucleic acid sequences, the identification--directly from sequence--of structural deviations from alpha-helicity and the annotation of amino acid sequences for antimicrobial activity. Additionally, annotations for more than 130 archaeal, bacterial, eukaryotic and viral genomes are now available on-line and can be searched interactively. The tools and code bundles continue to be accessible from http://cbcsrv.watson.ibm.com/Tspd.html whereas the genomics annotations are available at http://cbcsrv.watson.ibm.com/Annotations/.\n\nIBM SmartCloud essentials\n\nCERN Document Server\n\nSchouten, Edwin\n\n2013-01-01\n\nA practical, user-friendly guide that provides an introduction to cloud computing using IBM SmartCloud, along with a thorough understanding of resource management in a cloud environment.This book is great for anyone who wants to get a grasp of what cloud computing is and what IBM SmartCloud has to offer. If you are an IT specialist, IT architect, system administrator, or a developer who wants to thoroughly understand the cloud computing resource model, this book is ideal for you. No prior knowledge of cloud computing is expected.\n\nETICS: the international software engineering service for the grid\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nMeglio, A D; Begin, M-E [CERN (Switzerland); Couvares, P [University of Wisconsin-Madison (United States); Ronchieri, E [INFN CNAF (Italy); Takacs, E [4D SOFT Ltd (Hungary)], E-mail: alberto.di.meglio@cern.ch\n\n2008-07-15\n\nThe ETICS system is a distributed software configuration, build and test system designed to fulfil the needs of improving the quality, reliability and interoperability of distributed software in general and grid software in particular. The ETICS project is a consortium of five partners (CERN, INFN, Engineering Ingegneria Informatica, 4D Soft and the University of Wisconsin-Madison). The ETICS service consists of a build and test job execution system based on the Metronome software and an integrated set of web services and software engineering tools to design, maintain and control build and test scenarios. The ETICS system allows taking into account complex dependencies among applications and middleware components and provides a rich environment to perform static and dynamic analysis of the software and execute deployment, system and interoperability tests. This paper gives an overview of the system architecture and functionality set and then describes how the EC-funded EGEE, DILIGENT and OMII-Europe projects are using the software engineering services to build, validate and distribute their software. Finally a number of significant use and test cases will be described to show how ETICS can be used in particular to perform interoperability tests of grid middleware using the grid itself.\n\nETICS: the international software engineering service for the grid\n\nScience.gov (United States)\n\nMeglio, A. D.; BÃ©gin, M.-E.; Couvares, P.; Ronchieri, E.; Takacs, E.\n\n2008-07-01\n\nThe ETICS system is a distributed software configuration, build and test system designed to fulfil the needs of improving the quality, reliability and interoperability of distributed software in general and grid software in particular. The ETICS project is a consortium of five partners (CERN, INFN, Engineering Ingegneria Informatica, 4D Soft and the University of Wisconsin-Madison). The ETICS service consists of a build and test job execution system based on the Metronome software and an integrated set of web services and software engineering tools to design, maintain and control build and test scenarios. The ETICS system allows taking into account complex dependencies among applications and middleware components and provides a rich environment to perform static and dynamic analysis of the software and execute deployment, system and interoperability tests. This paper gives an overview of the system architecture and functionality set and then describes how the EC-funded EGEE, DILIGENT and OMII-Europe projects are using the software engineering services to build, validate and distribute their software. Finally a number of significant use and test cases will be described to show how ETICS can be used in particular to perform interoperability tests of grid middleware using the grid itself.\n\nETICS: the international software engineering service for the grid\n\nInternational Nuclear Information System (INIS)\n\nMeglio, A D; Begin, M-E; Couvares, P; Ronchieri, E; Takacs, E\n\n2008-01-01\n\nThe ETICS system is a distributed software configuration, build and test system designed to fulfil the needs of improving the quality, reliability and interoperability of distributed software in general and grid software in particular. The ETICS project is a consortium of five partners (CERN, INFN, Engineering Ingegneria Informatica, 4D Soft and the University of Wisconsin-Madison). The ETICS service consists of a build and test job execution system based on the Metronome software and an integrated set of web services and software engineering tools to design, maintain and control build and test scenarios. The ETICS system allows taking into account complex dependencies among applications and middleware components and provides a rich environment to perform static and dynamic analysis of the software and execute deployment, system and interoperability tests. This paper gives an overview of the system architecture and functionality set and then describes how the EC-funded EGEE, DILIGENT and OMII-Europe projects are using the software engineering services to build, validate and distribute their software. Finally a number of significant use and test cases will be described to show how ETICS can be used in particular to perform interoperability tests of grid middleware using the grid itself\n\nSelf-service for software development projects and HPC activities\n\nInternational Nuclear Information System (INIS)\n\nHusejko, M; HÃ¸imyr, N; Gonzalez, A; Koloventzos, G; Asbury, D; Trzcinska, A; Agtzidis, I; Botrel, G; Otto, J\n\n2014-01-01\n\nThis contribution describes how CERN has implemented several essential tools for agile software development processes, ranging from version control (Git) to issue tracking (Jira) and documentation (Wikis). Running such services in a large organisation like CERN requires many administrative actions both by users and service providers, such as creating software projects, managing access rights, users and groups, and performing tool-specific customisation. Dealing with these requests manually would be a time-consuming task. Another area of our CERN computing services that has required dedicated manual support has been clusters for specific user communities with special needs. Our aim is to move all our services to a layered approach, with server infrastructure running on the internal cloud computing infrastructure at CERN. This contribution illustrates how we plan to optimise the management of our of services by means of an end-user facing platform acting as a portal into all the related services for software projects, inspired by popular portals for open-source developments such as Sourceforge, GitHub and others. Furthermore, the contribution will discuss recent activities with tests and evaluations of High Performance Computing (HPC) applications on different hardware and software stacks, and plans to offer a dynamically scalable HPC service at CERN, based on affordable hardware.\n\nIBM PC enhances the world's future\n\nScience.gov (United States)\n\nCox, Jozelle\n\n1988-01-01\n\nAlthough the purpose of this research is to illustrate the importance of computers to the public, particularly the IBM PC, present examinations will include computers developed before the IBM PC was brought into use. IBM, as well as other computing facilities, began serving the public years ago, and is continuing to find ways to enhance the existence of man. With new developments in supercomputers like the Cray-2, and the recent advances in artificial intelligence programming, the human race is gaining knowledge at a rapid pace. All have benefited from the development of computers in the world; not only have they brought new assets to life, but have made life more and more of a challenge everyday.\n\nIsospin invariant forms of interacting boson model (IBM)\n\nInternational Nuclear Information System (INIS)\n\nEvans, A.\n\n1989-01-01\n\nIn the original version of the interacting boson model, IBM1, there are only two quantum numbers with exact values: the angular momentum and the number of bosons. IBM2 distinguishes between two kinds of bosons. However, the IBM2 algebra does not include the operators TÂ± and consequently the states in the model have no good isospin, generally. IBM3 includes the isospin in the algebra and therefore the construction of states with any number of bosons and good isospin presents no problem. In this work, IBM3 is compared with the shell model. IBFM3 is also studied, which describes an odd nucleus as a system of N bosons plus a single nucleon that is a neutron with some probability and a proton with the complementary probability. The spectra obtained in the shell model, IBFM3 and IBFM2 for 45 Ti and 45 Sc are compared. (Author) [es\n\nA microprocessor card software server to support the Quebec health microprocessor card project.\n\nScience.gov (United States)\n\nDurant, P; BÃ©rubÃ©, J; Lavoie, G; Gamache, A; Ardouin, P; Papillon, M J; Fortin, J P\n\n1995-01-01\n\nThe Quebec Health Smart Card Project is advocating the use of a memory card software server[1] (SCAM) to implement a portable medical record (PMR) on a smart card. The PMR is viewed as an object that can be manipulated by SCAM's services. In fact, we can talk about a pseudo-object-oriented approach. This software architecture provides a flexible and evolutive way to manage and optimize the PMR. SCAM is a generic software server; it can manage smart cards as well as optical (laser) cards or other types of memory cards. But, in the specific case of the Quebec Health Card Project, SCAM is used to provide services between physicians' or pharmacists' software and IBM smart card technology. We propose to expose the concepts and techniques used to provide a generic environment to deal with smart cards (and more generally with memory cards), to obtain a dynamic an evolutive PMR, to raise the system global security level and the data integrity, to optimize significantly the management of the PMR, and to provide statistic information about the use of the PMR.\n\nConversion and distribution of bibliographic information for further use on microcomputers with database software such as CDS/ISIS\n\nInternational Nuclear Information System (INIS)\n\nNieuwenhuysen, P.; Besemer, H.\n\n1990-05-01\n\nThis paper describes methods to work on microcomputers with data obtained from bibliographic and related databases distributed by online data banks, on CD-ROM or on tape. Also, we mention some user reactions to this technique. We list the different types of software needed to perform these services. Afterwards, we report about our development of software, to convert data so that they can be entered into UNESCO's program named CDS/ISIS (Version 2.3) for local database management on IBM microcomputers or compatibles; this software allows the preservation of the structure of the source data in records, fields, subfields and field occurrences. (author). 10 refs, 1 fig\n\nFrom Product- to Service-Oriented Strategies in the Enterprise Software Market\n\nScience.gov (United States)\n\nXin, Mingdi\n\n2009-01-01\n\nThe enterprise software market is seeing the rise of a new business model--selling Software-as-a-Service (SaaS), in which a standard piece of software is owned and managed remotely by the vendor and delivered as a service over the Internet. Despite the hype, questions remain regarding the rise of this new service model and how it would impact theâ¦\n\nIBM 3380 E\n\nCERN Multimedia\n\n1985-01-01\n\nIn 1985 IBM announced a double density version. The Extended Capability Models of the 3380 (3380 E) having 5.04 gigabytes per chassis, that is, two 1.26 gigabyte actuators on two hard disk assemblies in one chassis.\n\nPC-Link historical data base system MODCOMP/IBM at link for neutral particle beam operation\n\nInternational Nuclear Information System (INIS)\n\nThurgood, P.\n\n1989-12-01\n\n''PC-Link'' is a combination of hardware and software that connects an IBM PC/AT to a MODCOMP minicomputer. It is designed as an aid to the Neutral Beam operations coordinator during injection into the DIII-D tokamak project. An IBM PC/AT is linked to 4 MODCOMP ''realtime'' acquisition systems, each of which controls 2 neutral particle beam sources. At various points in the shot sequence, data is sent to the IBM PC/AT. This data can then be integrated with the data from the other sources into tables or graphics displays for use by the Beam Coordinator. In this way, the coordinator gets realtime feedback on the relative settings and performance of the sources and can observe trends within a particular source at one location. The PC- Link is used for observing relative timing information and for post shot historical archiving. The concept of the PC-Link was originally proposed several years ago. In April 1988, in-house implementation of the link software was begun. The PC-Link receives approximately 2 Kbytes of data per source per shot. This data is converted from MODCOMP format to IBM PC format and archived to disk. The last 280 shots per source are stored to disk to observe trends. The data can be displayed in a number of formats depending upon the situation. For example, prior to a shot, the beam MODCOMPs are sent timing information from the DIII-D tokamak control system. This data is echoed on the PC in a graphical representation displaying all 8 sources. At the end of the shot, the actual running times are displayed along with the requested settings. Any subset of the Historical data may be displayed either graphically or in tables for realtime comparisons between sources. This system is designed for realtime use, not for complete archiving purposes. This same data is also sent to a VAX computer for full integration into the archive database. This system is easily upgradable and extremely versatile. 4 figs\n\nIBM-PC based data acquisition system for a laser enhanced ionisation spectrometer using a low cost GPIB card\n\nInternational Nuclear Information System (INIS)\n\nSampath Kumar, R.; Ravindranath, S.V.G.\n\n1992-01-01\n\nAn IBM-PC based data acquisition system has been developed for the existing laser enhanced ionisation spectrometer in the Division. Here the boxcar averager (type SR 250) which integrates the spectrometer output is interfaced to an IBM-PC, converted into a GPIB controller with the help of a locally available GPIB card, (Dynalog Micro Systems make PCL 848) through the GPIB port of the computer interface module (SR 245). The menu driven software developed in BASIC, triggers the scan in the dye laser through its control port, collects data from the spectrometer, plots, displays and stores it on the hard disc for further use. (author). 6 refs., 18 figs., 2 appendixes\n\nFree software and open source databases\n\nDirectory of Open Access Journals (Sweden)\n\nNapoleon Alexandru SIRITEANU\n\n2006-01-01\n\nFull Text Available The emergence of free/open source software -FS/OSS- enterprises seeks to push software development out of the academic stream into the commercial mainstream, and as a result, end-user applications such as open source database management systems (PostgreSQL, MySQL, Firebird are becoming more popular. Companies like Sybase, Oracle, Sun, IBM are increasingly implementing open source strategies and porting programs/applications into the Linux environment. Open source software is redefining the software industry in general and database development in particular.\n\nLenovo acquires IBM's x86 low-end server business\n\nDirectory of Open Access Journals (Sweden)\n\nSingh Pal Netra\n\n2015-01-01\n\nFull Text Available This paper presents an analysis of the key events, impacts and issues of Lenovo buying IBM's x86 low-end server business. The analysis include (i approval of the deal by regulatory bodies in the United States, Canada, India and China, (ii security concerns of US government departments, (iii pricing of the deals, (iv possible impact on IBM in future, and (v possibilities of Lenovo making it repeat of acquiring ThinkPad business of IBM. The paper presents analysis of qualitative and time series quantitative data. The qualitative data are mainly consists of different events before and after the acquisition of x86 server IBM business by Lenovo. The quantitative data are analyzed with respect to growth parameters of overall server business and Lenovo server business. Research paper also attempts to find out answer to specific 9 research questions with respect to impact on eco-systems of IBM and Lenovo. Based on analysis, it is inferred that IBM is not able to manage its traditional & well accepted products business in the face of fierce competition & low demand but Lenovo will manage. The deal was a financial necessity for IBM and strategic expansion in to new markets strategy for Lenovo.\n\nSemi-automated software service integration in virtual organisations\n\nScience.gov (United States)\n\nAfsarmanesh, Hamideh; Sargolzaei, Mahdi; Shadi, Mahdieh\n\n2015-08-01\n\nTo enhance their business opportunities, organisations involved in many service industries are increasingly active in pursuit of both online provision of their business services (BSs) and collaborating with others. Collaborative Networks (CNs) in service industry sector, however, face many challenges related to sharing and integration of their collection of provided BSs and their corresponding software services. Therefore, the topic of service interoperability for which this article introduces a framework is gaining momentum in research for supporting CNs. It contributes to generation of formal machine readable specification for business processes, aimed at providing their unambiguous definitions, as needed for developing their equivalent software services. The framework provides a model and implementation architecture for discovery and composition of shared services, to support the semi-automated development of integrated value-added services. In support of service discovery, a main contribution of this research is the formal representation of services' behaviour and applying desired service behaviour specified by users for automated matchmaking with other existing services. Furthermore, to support service integration, mechanisms are developed for automated selection of the most suitable service(s) according to a number of service quality aspects. Two scenario cases are presented, which exemplify several specific features related to service discovery and service integration aspects.\n\nERES--a PC software for nuclear data compilation in EXFOR format\n\nInternational Nuclear Information System (INIS)\n\nLi Shubing; Liang Qichang; Liu Tingjin\n\n1993-01-01\n\nThe major functions and implementation of the software ERES (EXFOR Edit System) are introduced. The ERES is developed for nuclear data compilation in EXFOR (EXchange FORmat) format, running on IBM-PC/XT or IBM-PC/AT. EXFOR is the format for the exchange of experimental neutron data accepted by four neutron data centers in the world\n\nPIV Data Validation Software Package\n\nScience.gov (United States)\n\nBlackshire, James L.\n\n1997-01-01\n\nA PIV data validation and post-processing software package was developed to provide semi-automated data validation and data reduction capabilities for Particle Image Velocimetry data sets. The software provides three primary capabilities including (1) removal of spurious vector data, (2) filtering, smoothing, and interpolating of PIV data, and (3) calculations of out-of-plane vorticity, ensemble statistics, and turbulence statistics information. The software runs on an IBM PC/AT host computer working either under Microsoft Windows 3.1 or Windows 95 operating systems.\n\nSecurity Risks of Cloud Computing and Its Emergence as 5th Utility Service\n\nScience.gov (United States)\n\nAhmad, Mushtaq\n\nCloud Computing is being projected by the major cloud services provider IT companies such as IBM, Google, Yahoo, Amazon and others as fifth utility where clients will have access for processing those applications and or software projects which need very high processing speed for compute intensive and huge data capacity for scientific, engineering research problems and also e- business and data content network applications. These services for different types of clients are provided under DASM-Direct Access Service Management based on virtualization of hardware, software and very high bandwidth Internet (Web 2.0) communication. The paper reviews these developments for Cloud Computing and Hardware/Software configuration of the cloud paradigm. The paper also examines the vital aspects of security risks projected by IT Industry experts, cloud clients. The paper also highlights the cloud provider's response to cloud security risks.\n\n[IBM Work and Personal Life Balance Programs.\n\nScience.gov (United States)\n\nInternational Business Machines Corp., Armonk, NY.\n\nThese five brochures describe the IBM Corporation's policies, programs, and initiatives designed to meet the needs of employees' child care and family responsibilities as they move through various stages of employment with IBM. The Work and Personal Life Balance Programs brochure outlines (1) policies for flexible work schedules, includingâ¦\n\nUji Performa Software-based Openflow Switch Berbasis Openwrt\n\nOpenAIRE\n\nKartadie, Rikie; Suryanto, Tommy\n\n2015-01-01\n\nPerkembangan pesat Software-Defined Network telah dirasakan oleh vendor vendor besar. HP, Google dan IBM, mulai merubah pola routing-switching pada network mereka dari pola routingswitching tradisional ke pola infrastruktur routing-switching Software-defined Network. Untuk melakukan eksperimen tentang OpenFlow, para peneliti sering kali harus menggunakan perangkat hardware/dedicated switch OpenFlow yang dikeluarkan oleh beberapa vendor dengan harga yang tinggi. Kenyataannya, software-based sw...\n\nContract-oriented software development for internet services\n\nDEFF Research Database (Denmark)\n\nGiambiagi, Pablo; Owe, Olaf; Ravn, Anders Peter\n\n2008-01-01\n\nCOSoDIS (Contract-Oriented Software Development for Internet Services) develops novel approaches to implement and reason about contracts in service oriented architectures (SOA). The rationale is that system developers benefit from abstraction mechanisms to work with these architectures. Therefore...... the goal is to design and test system modeling and programming language tools to empower SOA developers to deploy highly dynamic, negotiable and monitorable Internet services....\n\nProgramming portlets from JSR 168 to IBM WebSphere portal extensions\n\nCERN Document Server\n\nBernal, Joey; Lynn, Ron; Marston, Cayce; Memon, Usman\n\n2012-01-01\n\nPortals have evolved from simple Web applications with multiple links to an enterprise application delivery platform that serves composite applications. In a world where organizations are gearing up with service-oriented architecture (SOA) strategies and re-working existing apps to fit the Web 2.0 programming model, portals are strategic infrastructure components on every CIO's radar. As companies move toward SOA, portlets become an even hotter topic. Portlets provide the user interface for these services. IBM's unwavering commitment to open standards such as Java Specification Request (JSR 16\n\nETICS the international software engineering service for the grid\n\nCERN Document Server\n\nDi Meglio, A; Couvares, P; Ronchieri, E; TakÃ¡cs, E\n\n2008-01-01\n\nThe ETICS system is a distributed software configuration, build and test system designed to fulfil the needs of improving the quality, reliability and interoperability of distributed software in general and grid software in particular. The ETICS project is a consortium of five partners (CERN, INFN, Engineering Ingegneria Informatica, 4D Soft and the University of Wisconsin-Madison). The ETICS service consists of a build and test job execution system based on the Metronome software and an integrated set of web services and software engineering tools to design, maintain and control build and test scenarios. The ETICS system allows taking into account complex dependencies among applications and middleware components and provides a rich environment to perform static and dynamic analysis of the software and execute deployment, system and interoperability tests. This paper gives an overview of the system architecture and functionality set and then describes how the EC-funded EGEE, DILIGENT and OMII-Europe projects ...\n\n2-D fluid dynamics models for laser driven fusion on IBM 3090 vector multiprocessors\n\nInternational Nuclear Information System (INIS)\n\nAtzeni, S.\n\n1988-01-01\n\nFluid-dynamics codes for laser fusion are complex research codes, consisting of many distinct modules and embodying a variety of numerical methods. They are therefore good candidates for testing general purpose advanced computer architectures and the related software. In this paper, after a brief outline of the basic concepts of laser fusion, the implementation of the 2-D laser fusion fluid code DUED on the IBM 3090 VF vector multiprocessors is discussed. Emphasis is put on parallelization, performed by means of IBM Parallel FORTRAN (PF). It is shown how different modules have been optimized by using different features of PF: i) modules based on depth-2 nested loops exploit automatic parallelization; ii) laser light ray tracing is partitioned by scheduling parallel ICCG algorithm (executed in parallel by appropiately synchronized parallel subroutines). Performance results are given for separate modules of the code, as well as for typical complete runs\n\nUsing Networks For Changing Innovation Strategy: The Case of IBM\n\nOpenAIRE\n\nDittrich, Koen; Duysters, Geert; Man, Ard-Pieter\n\n2004-01-01\n\ntextabstractLarge-scale strategic change projects in companies may be supported by using alliance networks. This paper shows that IBMâs change from an exploitation strategy towards an exploration strategy required a radically different network strategy as well. By entering into more non-equity alliances, involving new partners in the network and loosening the ties with existing partners, IBM supported its transformation from a hardware manufacturing company to a global service provider and so...\n\nGuardian scram avoidance software for an IBM PC\n\nInternational Nuclear Information System (INIS)\n\nLarson, C.L.; Delvin, S.A.; Murray, R.F.\n\n1988-01-01\n\nAmong the significant factors contributing to the loss of plant capacity factor at nuclear power plants are unnecessary or inadvertent reactor scrams. The Guardian software program was developed to help plant personnel plan and carry out multiple maintenance and surveillance tasks during plant operation without causing scrams. It is also designed to aid system engineers and designers in understanding the strengths and weaknesses of their systems. Guardian software develops and maintains a list of the plant's single-failure points, or singletons, those components or operations whose failure or abnormal operating state could, as a single event, result in reactor scram. It also provides a list of doubletons or combinations of two components, which, if both failed or were placed in abnormal states, would cause scram. By monitoring the number and condition of components identified as singletons and doubletons by the Guardian program, plant personnel can enhance their chances of avoiding unnecessary reactor scrams, thereby improving plant performance. The improved performance yields important economic benefits because inadvertent scrams demand costly replacement power on very short notice, place unnecessary duty cycles on equipment, and disrupt planned work schedules\n\nSoftware-Programmed Optical Networking with Integrated NFV Service Provisioning\n\nDEFF Research Database (Denmark)\n\nMehmeri, Victor; Wang, Xi; Basu, Shrutarshi\n\n2017-01-01\n\nWe showcase demonstrations of âprogram & compileâ styled optical networking as well as open platforms & standards based NFV service provisioning using a proof-of-concept implementation of the Software-Programmed Networking Operating System (SPN OS).......We showcase demonstrations of âprogram & compileâ styled optical networking as well as open platforms & standards based NFV service provisioning using a proof-of-concept implementation of the Software-Programmed Networking Operating System (SPN OS)....\n\nDevelopment of neutron activation analysis software\n\nInternational Nuclear Information System (INIS)\n\nWang Liyu\n\n1987-10-01\n\nThe software for quantitative neutron activation analysis was developed to run under the MS/DOS operating system. The programmes of the IBM/SPAN include: spectra file transfer from and to a Canberra Series 35 multichannel analyzer, spectrum evaluation routines, calibration subprogrammes, and quantitative analysis. The programmes for spectrum analysis include fitting routine for separation of multiple lines by reproducing the peak shape with a combination of Gaussian and exponential terms. The programmes were tested on an IBM/AT-compatible computer. The programmes and the sources are available costfree for the IAEA projects of Technical Cooperation. 7 refs, 3 figs\n\n31 CFR 545.205 - Prohibited importation of goods, software, technology, or services.\n\nScience.gov (United States)\n\n2010-07-01\n\n..., software, technology, or services. 545.205 Section 545.205 Money and Finance: Treasury Regulations Relating..., software, technology, or services owned or controlled by the Taliban or persons whose property or interests... (AFGHANISTAN) SANCTIONS REGULATIONS Prohibitions Â§ 545.205 Prohibited importation of goods, software...\n\nPengembangan Sistem Informasi Geografis Berbasis Node.JS untuk Pemetaan Mesin dan Tracking Engineer dengan Pemanfaatan Geolocation pada PT IBM Indonesia\n\nOpenAIRE\n\nFajrin, Rachmat\n\n2017-01-01\n\nPT IBM memiliki banyak klien di Indonesia, ini membuat persebaran produk (dalam hal ini mesin atm) yang semakin meluas di wilayah Indonesia. Hal ini memicu PT IBM untuk menempatkan engineer dibanyak wilayah untuk memenuhi kebutuhan services dan maintenance. Untuk itu dalam penelitian ini dikembangkan sebuah sistem informasi geografis untuk pemetaan mesin dan tracking engineer dengan pemanfaatan geolocation yang bertujuan untuk menampilkan peta digital beserta lokasi mesin dan engineer di selu...\n\nMiks IBM mÃ¼Ã¼b kroonijuveeli? / Valdo Randpere\n\nIndex Scriptorium Estoniae\n\nRandpere, Valdo, 1958-\n\n2004-01-01\n\nKuna konkurents on vÃ¤ga tihe, siis IBM loobub vÃ¤ikese marginaaliga personaalarvutite Ã¤rist ning keskendub serveritele ja keerukatele Ã¤rilahendustele. Lisa: IBM mÃ¼Ã¼b personaalarvutite divisjoni hiinlastele\n\nUporaba orodja poslovne inteligence IBM Watson za predvidevanje prodaje\n\nOpenAIRE\n\nStojiÄ, Igor\n\n2016-01-01\n\nDiplomska naloga obravnava uporabo orodja IBM Watson in njegovo poslovno vrednost, ki jo ima v okviru oblikovanja napovedi prihodnje prodaje produktov. V teoretiÄnem delu podrobneje opredeljuje napovedovanje in smoter le-tega. V okviru empiriÄnega dela pa je bila izvedena primerjava uporabe ERP sistemov SAP in IBM Watson, pri Äemer je bil dosledno prikazan postopek oblikovanja napovedi, tako s SAP kot tudi z IBM Watson, s slednjim pa tudi identificiran parameter, ki vpliva na prodajo nekateri...\n\nModeling of a 3DTV service in the software-defined networking architecture\n\nScience.gov (United States)\n\nWilczewski, Grzegorz\n\n2014-11-01\n\nIn this article a newly developed concept towards modeling of a multimedia service offering stereoscopic motion imagery is presented. Proposed model is based on the approach of utilization of Software-defined Networking or Software Defined Networks architecture (SDN). The definition of 3D television service spanning SDN concept is identified, exposing basic characteristic of a 3DTV service in a modern networking organization layout. Furthermore, exemplary functionalities of the proposed 3DTV model are depicted. It is indicated that modeling of a 3DTV service in the Software-defined Networking architecture leads to multiplicity of improvements, especially towards flexibility of a service supporting heterogeneity of end user devices.\n\nThreats Management Throughout the Software Service Life-Cycle\n\nDirectory of Open Access Journals (Sweden)\n\nErlend Andreas GjÃ¦re\n\n2014-04-01\n\nFull Text Available Software services are inevitably exposed to a fluctuating threat picture. Unfortunately, not all threats can be handled only with preventive measures during design and development, but also require adaptive mitigations at runtime. In this paper we describe an approach where we model composite services and threats together, which allows us to create preventive measures at design-time. At runtime, our specification also allows the service runtime environment (SRE to receive alerts about active threats that we have not handled, and react to these automatically through adaptation of the composite service. A goal-oriented security requirements modelling tool is used to model business-level threats and analyse how they may impact goals. A process flow modelling tool, utilising Business Process Model and Notation (BPMN and standard error boundary events, allows us to define how threats should be responded to during service execution on a technical level. Throughout the software life-cycle, we maintain threats in a centralised threat repository. Re-use of these threats extends further into monitoring alerts being distributed through a cloud-based messaging service. To demonstrate our approach in practice, we have developed a proof-of-concept service for the Air Traffic Management (ATM domain. In addition to the design-time activities, we show how this composite service duly adapts itself when a service component is exposed to a threat at runtime.\n\nA theory and model for the evolution of software services\n\nNARCIS (Netherlands)\n\nAndrikopoulos, V.\n\n2010-01-01\n\nSoftware services are subject to constant change and variation. To control service development, a service developer needs to know why a change was made, what are its implications and whether the change is complete. Typically, service clients do not perceive the upgraded service immediately. As a\n\nCollaborative busi"
    }
}