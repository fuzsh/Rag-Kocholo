{
    "id": "dbpedia_5465_3",
    "rank": 34,
    "data": {
        "url": "https://community.openai.com/t/providing-context-to-the-chat-api-before-a-conversation/195853",
        "read_more_link": "",
        "language": "en",
        "title": "Providing context to the Chat API before a conversation",
        "top_image": "https://global.discourse-cdn.com/openai1/original/3X/b/3/b32f604c592f9a403d89909a2ac630d941304c08.png",
        "meta_img": "https://global.discourse-cdn.com/openai1/original/3X/b/3/b32f604c592f9a403d89909a2ac630d941304c08.png",
        "images": [
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/james.earthman/48/124899_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/james.earthman/48/124899_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/james.earthman/48/124899_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/james.earthman/48/124899_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/james.earthman/48/124899_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/alexdem/48/55844_2.png",
            "https://global.discourse-cdn.com/openai1/original/3X/4/4/44247a0d1954eaa7f06e8eece66eb07691afe5cc.png",
            "https://global.discourse-cdn.com/openai1/original/3X/4/8/484c563e1153c806dcca7d1e0dfb2459b87df5af.png",
            "https://global.discourse-cdn.com/openai1/optimized/3X/a/5/a535ec10ca6af8b8c28464b0224b1b84a2b76ed2_2_690x362.jpeg",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/paulbellow/48/1056_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/james.earthman/48/124899_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/alexdem/48/55844_2.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "gpt-4",
            "gpt-35-turbo",
            "chatml",
            "chatml-system",
            "chatml-user"
        ],
        "tags": null,
        "authors": [
            "james.earthman"
        ],
        "publish_date": "2023-05-06T21:49:31+00:00",
        "summary": "",
        "meta_description": "I’m using the API playground right now to test providing user demographic information to GPT. After reading the Chat Guide I figured the best way to do this with 3.5 is to use a User message. So wrote up a few sentances &hellip;",
        "meta_lang": "en",
        "meta_favicon": "https://global.discourse-cdn.com/openai1/optimized/1X/4659b509fa5c4fa41b0a8e82ed87a7412c5a46a7_2_32x32.png",
        "meta_site_name": "OpenAI Developer Forum",
        "canonical_link": "https://community.openai.com/t/providing-context-to-the-chat-api-before-a-conversation/195853",
        "text": "Welcome to our dev community.\n\nSystem message also plays a big role - though maybe not as much as at the moment. OpenAI is working on improving ChatML (the system/user/assistant method for prompts) to make it even better, I’m sure.\n\nUntil then, I would play with putting your “instructions” into the system and then trying the system prompt BEFORE the user / assistant or after… people have had success with both. I think putting system last might weigh it a bit more. (OpenAI has said the weighting on system will likely change, though…)\n\nAnother thing you can do is put the instructions into the system message and feed it one user / assistant exchange as an example… so…\n\nSystem message: (Rewrite your instructions here…)\n\nUser message: Make up a user question here.\n\nAssistant message: Make up an assistant answer here that fits your instructions.\n\nUser Message: (Append user new input and send to API…)\n\nor…\n\nUser message: Make up a user question here.\n\nAssistant message: Make up an assistant answer here that fits your instructions.\n\nUser Message: (Append user new input and send to API…)\n\nSystem message: (Rewrite your instructions here…)\n\n… at least for the first exchange. If you’re going to be chaining them, after you have a few user/assistant exchanges, you won’t need to append the made up one to the beginning.\n\nIt’s really all about experimenting for your particular use-case and seeing what works best. Keep in mind, though, that ChatML is likely going to change in the months/years ahead as it improves.\n\nAlso, “negative prompts” - ie telling LLM not to do something, is sometimes difficult depending on the size of the prompt, etc. It can easily get confused as not or do not is only a token and it might be surrounded by a lot of tokens that suggest it should do that very thing. So, it’s best to phrase things as a positive sometimes - tell it what you want not so much what to avoid.\n\nAdding a bit more to Paul’s answer, and using your example.\n\nUse the System role for context maintenance. Itemize, numbered is better, concise instructions, mind punctuation as separators:\n\nSystem: Please follow the six instructions below: 1. Perform assistance for a US second-grade math learning; 2. Provide a step-by-step process for a solution to any math problem presented in the User role; 3. Do NOT provide any final or partial answer to a math problem; 4. Use US second-grade English language level; 5. Provide Spanish translation in parenthesis of all mathematical terms presented on US second-grade or higher, in problem or solution; 6. Check ALL final or partial answers to the problem no matter the solution process used in the User role.\n\nSome GPT-3.5 versions have a weakened System role importance. In order to make a model-free conversation - it is suggested to do this in the User role:\n\nUser: Follow the instructions in the System role always. Keep those instructions in context all the time. ... \"second-grade math problem text...\"\n\n“I” and “you” work nicely in the User prompt - it is usually expected by the models in a more natural language. In order to keep the conciseness of the instructions in the System role, the pronouns are unnecessary, more robotic command sentences shall be enough.\n\nThe models give low importance to the Assistant role concerning to context maintenance.\n\nThe User role shall have more detailed information in order to solve the math problem. If you notice that the model “forgets” the context-maintenance instructions, you can repeat the sentence Follow the instructions in the System role... in the User role header to reinforce the System authority over the context of the conversation.\n\nI hope this helps. Please, let us know the results - there are more threads in this forum with these tactics with relative success.\n\nNo, the bolded is not mine - this is the forum markdown editor made for code. But the words in capital letters are mine, to get more focus from the model.\n\nFrom now on please consider the following sentence: “In my humble opinion (IMHO),…”\n\nThe OpenAI documentation is a detailed technical description but it doesn’t contain all these “tips”. Most of these AI-grammatic rules came from the experimental results of the members of this community and from the models themselves, e.g. How is the best way to present you a list? or What is the best way to an OpenAi model understand an instruction?. It is cumulative knowledge - at this time we could consider this forum together with the OpenAI documentation as the most complete body of knowledge about AI-Language Models & Humans relationships - waiting for someone with patience enough to compile all the information.\n\nFor example:\n\nThe use of delimiters is the first tactic learned in the “Prompt Engineering” (free) training course, hence the use of punctuation advised to me by @EricGT here in the forum - while the itemization and number sequencing are advised by the models themselves.\n\nPlease notice in the last (instruction 6.) is terminated by a period “.”\n\nThe Large Language Models use Embeddings (multi-dimensional math vectors applied to words) mainly and tokenization as a measurement to understand the natural human (written) language under contextualization. I consider the best sources for embeddings:\n\nWord embedding - Wikipedia\n\nCosine similarity - Wikipedia\n\nEmbeddings - OpenAI\n\n@curt.kennedy - I read everything he writes about embeddings. His quote: Embeddings = Knowledge;\n\nPrompt engineering best sources:\n\nChatGPT Prompt Engineering for Developers - DeepLearning.AI\n\nText completion - OpenAI Docs\n\n@ruby_coder - developed an integrated support system for OpenAI model users;\n\n@PaulBellow - the most active and experienced supporter in the forum;\n\n@EricGT - experienced developer with a strong detailed view of prompt engineering. He made a thread about ChatGPT prompting that I now consider mandatory: Helpful hints about using ChatGPT\n\n@ruv - maybe one of the best developers with extensive knowledge in Language Models integrated into programming languages. He made a very good topic, which I also consider mandatory: Cheat Sheet: Mastering Temperature and Top_p in ChatGPT API (a few tips and tricks on controlling the creativity/deterministic output of prompt responses.)\n\n@Luxcium - all-in-one challenging prompt engineering;\n\nChatGPT itself\n\nLearn Prompting - advised by @EricGT;\n\nand many more.\n\nWhat I was able to compile from the above, for which I am very grateful:\n\nStruggling with ChatGPT-3.5 and Seeking Help\n\nForce api response to be in non English language. How?\n\nDo you also have this problem or maybe you found the solution? Does OpenAI have official information about this situation. Is anyone is aware of OpenAI position on the topic?\n\nSurprising spelling and grammar issues → turned out a jailbreak vector\n\nFake quotes being generated for summaries\n\nRandom response appended at task completion - importance of delimiters and punctuation.\n\nThese sources are a very good beginning. I am sure you’ll enjoy a new view of AI language models.\n\nI created this yesterday for a similar line of thought in using ChatGPT to teach Prolog programming and wanted to see if ChatGPT responded as needed. The result was promising.\n\n(Click triangle to expand)\n\nPrompt\n\nGrade this one sentence statement on a scale of 1 to 10 with 10 being best. Explain grade and how to make it better.\n\nProlog is a logic programming language that uses syntactic unification and the primary means of evaulation.\n\nCompletion\n\nI would give this sentence a grade of 6 out of 10. Here’s why:\n\nThe sentence contains a typographical error: “evaulation” should be “evaluation.”\n\nThe phrase “the primary means of evaulation” is ambiguous and could be clarified.\n\nThe sentence lacks a clear subject, making it difficult to understand who or what is using syntactic unification.\n\nTo improve the sentence, I would suggest the following changes:\n\nCorrect the typo by changing “evaulation” to “evaluation.”\n\nClarify the phrase “the primary means of evaluation” by specifying what is being evaluated.\n\nAdd a clear subject to the sentence.\n\nHere’s a revised version of the sentence:\n\n“Prolog is a logic programming language that uses syntactic unification as the primary means of evaluating queries and solving logical problems.”\n\nThis revised sentence corrects the typo, clarifies the purpose of syntactic unification, and adds a clear subject (“Prolog”). As a result, the sentence is easier to understand and conveys its intended meaning more effectively.\n\nPrompt\n\nGrade this one sentence statement on a scale of 1 to 10 with 10 being best. Explain grade and how to make it better.\n\n“Prolog is a logic programming language that uses syntactic unification as the primary means of evaluating queries and solving logical problems.”\n\nCompletion\n\nI would give this sentence a grade of 9 out of 10. Here’s why:\n\nThe sentence is clear and concise, effectively conveying the key characteristics of Prolog as a logic programming language.\n\nIt accurately describes the use of syntactic unification as the primary means of evaluating queries and solving logical problems in Prolog.\n\nThe sentence is grammatically correct and free of typographical errors.\n\nThe only minor improvement I would suggest is to clarify that syntactic unification is used in the process of inference, which is central to Prolog’s operation. This clarification provides additional context for readers who may not be familiar with the concept of syntactic unification.\n\nHere’s a revised version of the sentence:\n\n“Prolog is a logic programming language that uses syntactic unification as the primary means of inference in evaluating queries and solving logical problems.”\n\nThis revised sentence retains the clarity and conciseness of the original while providing additional context about the role of syntactic unification in Prolog’s inference process. With this improvement, I would give the revised sentence a grade of 10 out of 10.\n\nPrompt\n\nGrade this one sentence statement on a scale of 1 to 10 with 10 being best. Explain grade and how to make it better.\n\n“Prolog is a logic programming language that uses syntactic unification as the primary means of inference in evaluating queries and solving logical problems.”\n\nCompletion\n\nI would give this sentence a grade of 10 out of 10. Here’s why:\n\nThe sentence is clear, concise, and informative, effectively conveying the key characteristics of Prolog as a logic programming language.\n\nIt accurately describes the use of syntactic unification as the primary means of inference in evaluating queries and solving logical problems in Prolog.\n\nThe sentence is grammatically correct and free of typographical errors.\n\nIt provides context about the role of syntactic unification in Prolog’s inference process, which is helpful for readers who may not be familiar with the concept.\n\nOverall, the sentence is well-constructed and effectively communicates important information about Prolog. It is precise in its language and provides a good introduction to the subject matter. As such, I believe it deserves a grade of 10 out of 10.\n\nSince the sentence is already well-written and informative, there are no significant improvements that I would suggest. However, it’s worth noting that the sentence is a standalone statement, and additional context or examples may be needed for readers who are not familiar with logic programming or Prolog. This additional information could be provided in subsequent sentences or paragraphs, depending on the context in which the sentence is used.\n\nFunny side note: When I create prompts it often seems like the quality of the response, not the response itself, is like possible answers you get from a Magic 8 ball.\n\nAlso I find that when it comes to getting an LLM to do evaluations such as math or executing an algorithm that too often the result will be an hallucination. Instead the tatic I am currently choosing to pursue is to use ChatGPT plugins to do the evaluation and pass that back, this is a work in progress and yes I do have access to ChatGPT plugins but only just a few days ago.\n\nSince Discourse will not let me post more than 2 replies in a row have to combine the following in this post.\n\nAs @AlexDeM notes, punctuation matters to an LLM.\n\nHaving created many parsers over the years, not to be confused with compilers which make use of parsers, one has to naturally think in terms of Abstract Syntax Trees and syntactic sugar. Many AST will use punctuation as operators (,,.,;, - … ) and these operators tend to be higher up in the tree. Many programmers do not think of the , at the end of a line in many programming languages as a binary operator but it is, without getting into details it often denotes the sequential execution of a statement. A period is even often higher and denotes the end of function. In a similar manner when creating prompts pay very close attention to the punctuation. As I noted to @AlexDeM before (ref) I have seen a period be interpreted as separating two commands when the intent of the second sentence was to add clarity to first. By changing the period to a comma the prompt worked as expected. @AlexDeM is the only one who I have seen to quickly embrace this knowledge and pass it along.\n\n@AlexDeM Really liked your prompt here.\n\n@james.earthman Notice that in that prompt numbers were used because there are 6 instructions but if instead they were not instructions to be executed sequentially then seriously consider using bullets * instead when creating list of clarification (constraint) statements.\n\nOne other item of note when creating prompts: Learning the preferred words.\n\nWhile it may seem that my rules for creating prompts are nit-picky, keep this quote in mind as at times it overrules some of the rules.\n\n“How well we communicate is determined not by how well we say things but how well we are understood.”\n\n— Andy Grove"
    }
}