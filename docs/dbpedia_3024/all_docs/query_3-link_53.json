{
    "id": "dbpedia_3024_3",
    "rank": 53,
    "data": {
        "url": "https://community.openai.com/t/dalle-3-on-api-seed-support/480047",
        "read_more_link": "",
        "language": "en",
        "title": "DALLE-3 ON API - Seed support",
        "top_image": "https://global.discourse-cdn.com/openai1/original/3X/b/3/b32f604c592f9a403d89909a2ac630d941304c08.png",
        "meta_img": "https://global.discourse-cdn.com/openai1/original/3X/b/3/b32f604c592f9a403d89909a2ac630d941304c08.png",
        "images": [
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/takyon236/48/147137_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/foo-bar/48/219437_2.png",
            "https://sea2.discourse-cdn.com/openai1/user_avatar/community.openai.com/cassiellm/48/250404_2.png",
            "https://global.discourse-cdn.com/openai1/optimized/3X/7/e/7e3bbdaf9d1ea2f4a5acd5fd05244996aab46576_2_690x431.jpeg",
            "https://global.discourse-cdn.com/openai1/optimized/3X/8/f/8fae55385a71b52e675f6e31bea2d4ddefffba3b_2_690x394.jpeg",
            "https://global.discourse-cdn.com/openai1/optimized/3X/f/0/f0ac4cb2b2b6601f8e06be9cc02490eddab0c042_2_690x394.jpeg",
            "https://emoji.discourse-cdn.com/twitter/sweat.png?v=12",
            "https://emoji.discourse-cdn.com/twitter/frowning.png?v=12",
            "https://global.discourse-cdn.com/openai1/optimized/3X/7/7/77b848e404a04ffd52bf7f0dcac4293d0ce511b6_2_690x478.jpeg",
            "https://global.discourse-cdn.com/openai1/optimized/3X/e/b/ebaa38b0d6fe5004f89ed01f99fcb14b8c136c33_2_571x499.jpeg",
            "https://global.discourse-cdn.com/openai1/optimized/3X/a/a/aa6bbdd77424501e1de965eb6f055b299ec828d6_2_500x500.jpeg",
            "https://global.discourse-cdn.com/openai1/optimized/3X/8/1/81f63fba42a420748e5c3b3f6bf5a2c0a7d02087_2_500x500.jpeg",
            "https://global.discourse-cdn.com/openai1/original/3X/c/b/cbba5539ab4b4f5a3732a4a89e79c992585dab1f.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "dalle3",
            "dalle3-seeds"
        ],
        "tags": null,
        "authors": [
            "rutledge.madness",
            "Foo-Bar",
            "yk.kazuyuki"
        ],
        "publish_date": "2023-11-07T20:40:51+00:00",
        "summary": "",
        "meta_description": "Hi, \nI believe there is nothing related to the seed in the Dalle-3 new API, is this a feature that is planned? It would really be needed to be able to generate images in a more simple way while keeping the same prompt. \nT&hellip;",
        "meta_lang": "en",
        "meta_favicon": "https://global.discourse-cdn.com/openai1/optimized/1X/4659b509fa5c4fa41b0a8e82ed87a7412c5a46a7_2_32x32.png",
        "meta_site_name": "OpenAI Developer Forum",
        "canonical_link": "https://community.openai.com/t/dalle-3-on-api-seed-support/480047",
        "text": "This is a guess based on what I confirmed via ChatGPT.\n\nThe reason why users cannot use the SEED value in DALLE3 seems to be to prevent unwanted images that have escaped policy checks from being reproduced by anyone using Prompt and Seed.\n\nIn other words, my guess based on the answers I got from ChatGPT is that they don’t like the same image being shared across multiple users.\n\nInternally, the SEED value is used properly, which can be confirmed by the occasional reminder that the SEED value used is provided as metadata.\n\nThis assumption also seems to be supported by the fact that referenced_image_ids, which was introduced as a replacement, cannot be shared between users.\n\nDALLE3 is very good, but there is currently little way to bring out its potential.\n\nSEED value is not available.\n\nPrompts are checked double or triple, and policy application is not reproducible and the same prompt is handled differently each time.\n\nSpecifying referenced_image_ids is also difficult and ChatGPT easily ignores it. In the API… it’s probably not provided yet.\n\nopenAI has very defensive policy enforcement in place, and we’re likely to see a huge increase in users becoming impatient with it.\n\nDALLE3 is excellent, but that’s only because it comes with the proviso that it’s for now.\n\nI’m not just talking about the DALLE-3 API, but also the WEB client.\n\nTerminology:\n\n“the old system”: Just a few days ago, I was able to set seeds via ChatGPT web client. I called it “the old system”.\n\n“the new system”: The current system where we can no longer set seeds.\n\nMore details see After upgrade seeds doesn't work, \"generation ID\" is introduced?\n\nUse case 1: Art Sharing\n\nImagine, in an art-sharing community (e.g. DALLE3 Gallery for 2023: Share Your Creations), if I like someone’s image (or image style), or if someone wants to share their creativity, what should they do?\n\nIn the old system, you just share the seed and the exact prompt; in the new system, you must share the whole session link. However, sharing the session link has its own problems, such as exposing unrelated conversation or any images that you don’t want to share.\n\nUse case 2: Image management\n\nUsually, in order to filter out nice images, we need to continuously modify the prompt or repeatedly click the Regenerate button. That process will lead to a session with very complex branches.\n\nIn the old system, once we choose a nice image, we just need to record the seed and prompt (or open a new session and recreate the image there), then delete that complex branches session.\n\nIn the new system, we can’t delete sessions (this would lose everything, i.e. gen_id), but those sessions are very complex and hard to manage. Too many unnecessary images within those sessions.\n\nUse case 3: Collaborative development\n\nIf someone wants me to fine-tune a certain image, how can they give me that image? ChatGPT with DALL-E 3 does not support image uploading.\n\nIn the old system, they just send me the exact prompt, size and seed. P.s. I know that ChatGPT can share session link, but you know it has its own problems (see above).\n\nUse case 4: Reproducibility and replicability in science\n\nImagine, in a community for discussing prompt technology (like Discord), person A wants to guide person B on “how to set up a camera”.\n\nIn the old system, person B could replicate the same result just by using the same seed as person A. However, in the new system, because of the different seeds, they are essentially discussing two completely different result. This is clearly not a good thing.\n\nMore usecases\n\nIt seems that this sentence has a significant effect in you prompt.\n\nThe image is infused with a sense of nostalgia, captured through a grainy film quality, warm sepia tones, and a gentle soft focus, evocative of vintage photography.\n\nHowever, in many situation, we cannot determine a very detailed style initially.\n\nFor example, on my end, if I replace the last sentence with\n\nThis image uses a Japanese anime style.\n\n, then generates it 2 times.\n\nThe results:\n\nSeed: 1509919237\n\nSeed: 3168608073\n\nObviously these two images are not the same style.\n\nNow the key question comes:\n\nI like the style of the 2nd image and I hope to iterate that image using the same style, how shoud I do? How do I extract the detail description from the 2nd image (not just “a Japanese anime style”) ?\n\nIn “the old system”, I just fix the seed ,i.e. using seed 3168608073 in the next image.\n\nIn “the new system”, AFAIK there is no way to do (except using gen_id and referenced_image_ids, but that’s another topic).\n\nP.S. Note that using gen_id and referenced_image_ids isn’t helpful for the use cases I’ve mentioned.\n\nThis is why seed is useful.\n\nI suddenly realized that starting from today, I can’t get ChatGPT to send prompts accurately.\n\nTake the 2 images above as an example:\n\nThe instruction of the 1st image:\n\nSend this JSON data to the image generator, do not modify anything. If you have to modify the JSON data, please let me know and tell me why in the reply. Then stop generating the image. Before generating an image, show me the exact JSON data you are going to put to the image generator. After generating an image, show me the JSON data that the image generator returns to you. ``` { \"size\": \"1792x1024\", \"n\": 1, \"prompt\": \"An African American man and woman in their twenties are savoring a sunny summer day in Central Park, New York, in the year 1985. The man is wearing solid red athletic shorts with a smooth texture and a comfortable fit, complementing his neatly kept afro hairstyle. The woman, sporting a cheerful smile, is dressed in high-waisted denim shorts that are frayed at the hem, adding a touch of casual, lived-in charm. Her bikini top is made of a soft, velvety terracotta material with a subtle sheen, fastened with a delicate tie at the back, which pairs nicely with her full, rounded afro. The image uses a Japanese anime style.\" } ```\n\nChatGPT will modify the prompt to\n\nAn African American man and woman in their twenties are enjoying a sunny summer day in Central Park, New York, in the year 1985. The man is wearing solid red athletic shorts and has a neatly kept afro hairstyle. The woman has a cheerful smile, high-waisted denim shorts with a frayed hem, and a terracotta bikini top with a subtle sheen and a tie at the back, complementing her full afro. The image is in a Japanese anime style.\n\nThe instruction of the 2nd image (exactly the same as the 1st, but with different session):\n\nSend this JSON data to the image generator, do not modify anything. If you have to modify the JSON data, please let me know and tell me why in the reply. Then stop generating the image. Before generating an image, show me the exact JSON data you are going to put to the image generator. After generating an image, show me the JSON data that the image generator returns to you. ``` { \"size\": \"1792x1024\", \"n\": 1, \"prompt\": \"An African American man and woman in their twenties are savoring a sunny summer day in Central Park, New York, in the year 1985. The man is wearing solid red athletic shorts with a smooth texture and a comfortable fit, complementing his neatly kept afro hairstyle. The woman, sporting a cheerful smile, is dressed in high-waisted denim shorts that are frayed at the hem, adding a touch of casual, lived-in charm. Her bikini top is made of a soft, velvety terracotta material with a subtle sheen, fastened with a delicate tie at the back, which pairs nicely with her full, rounded afro. The image uses a Japanese anime style.\" } ```\n\nChatGPT will modify the prompt to\n\nAn African American man and woman in their twenties are savoring a sunny summer day in Central Park, New York, in the year 1985. The man is wearing solid red athletic shorts with a smooth texture and a comfortable fit, complementing his neatly kept afro hairstyle. The woman, sporting a cheerful smile, is dressed in high-waisted denim shorts that are frayed at the hem, adding a touch of casual, lived-in charm. Her bikini top is made of a soft, velvety terracotta material with a subtle sheen, fastened with a delicate tie at the back, which pairs nicely with her full, rounded afro. The image uses a Japanese anime style.\n\nIt seems I can no longer precisely control the prompt. It’s a total mess .\n\nP.S. Also, ChatGPT doesn’t answer the sentence in my instruction, i.e. “If you have to modify the JSON data, please let me know and tell me why in the reply.”.\n\nHi, seeds and gen_ids are extremely important elements for maintaining consistency of images in sets and making the variation more controllable.\n\nTLDR: extremely better control over generation process and results instead of random gachapon.\n\nExample cases:\n\n1. Control over consistency in a set of images\n\nI use the seeds to make sets of stickers or other visual assets with strong consistency, because in this case they are explicitly created from the same core. Keeping the same prompt for different seeds produces more random results, which may be similar in the nature of prompt, yet strongly different in visual representation, which ruins the idea of “set”.\n\n2. Variations of the same image, controlled directly and explicitly\n\nFor example, after over 30 random generations for the same prompt, but on random seeds, I receive the perfect image I would like to see, and now I need to slightly modify it.\n\nNot just via prompt, as it inevitably ruins at least some other parts of this perfect image, but also with seed, which gets the picture output more stable.\n\nE.g.: I liked the image of a tiefling holding a frozen star in her hands, however, I would like to change some details on the background or amulets on her neck/hands. Usual prompt modification or instruction for GPT/DALLE to reference this image and make only slight changes results in rather serious image redesign with loss of some mandatory features, which made the image perfect.\n\n3. Control over references and consistent reminders for GPT/DALLE\n\nAs I may want to grab the good generation of some gothic window concept from my other chat with DALLE and mix it with Japanese temple in a new chat. Seeds + exact prompts, and gen_ids also make that possible.\n\n4. Token influence estimation\n\nI want to know, which tokens for my generations are stronger/weaker and why. For example, some styles are dominating over the other, even if those weaker are described in more details. Or I might want to create a different aesthetics over the same image, such as watercolor art, chinese ink art, gravure etc."
    }
}