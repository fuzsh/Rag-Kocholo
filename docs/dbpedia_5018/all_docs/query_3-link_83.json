{
    "id": "dbpedia_5018_3",
    "rank": 83,
    "data": {
        "url": "https://www.scaruffi.com/svhistory/sil14.html",
        "read_more_link": "",
        "language": "en",
        "title": "A History of Silicon Valley",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "history timeline USA Silicon Valley chronology"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "A History of Silicon Valley",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "14. The other Boomers (1995-1998)\n\nby Piero Scaruffi\n\nY2K\n\nAt the same time that the dotcoms were booming, another factor contributed to a dramatic increase in software revenues: the Y2K phenomenon. \"Y2K\" was an abbreviation for \"Year 2000\". The vast majority of business software for large computers had been written in the 1960s and 1970s, and then ported to new generations of computers. Because of the limitations of storage at the time, and because, quite frankly, very few people expected those applications to last that long, most businesses could run only until 1999: their applications had no way to represent a date beyond 1999 (the commonly used two-digit abbreviation of the year, for example \"55\" instead of \"1955\", would turn the year 2000 into the year 1900). Panic spread when the corporate world realized what that meant: as the world entered a new century, unpredictable glitches could bring down the world economy and cause all sorts of disasters. Virtually all the business software in the world had to be rewritten, or at least analyzed to make sure there was no \"Y2K bug\". At one point Gartner Group estimated the cost of fixing the Y2K bug at $600 billion. This was a boon for the software companies that serviced legacy applications. So much code needed to be rewritten that, globally, one of the main beneficiaries of the Y2K panic was India, that since 1991 had begun liberalizing its protectionist economy, and boasted a large and cheap English-speaking IT workforce. USA companies had to outsource millions of codes to Indian companies. India's National Association of Software and Service Companies (Nasscom) estimated that India's software exports in 1998-99 reached $2.65 billion, growing at a yearly rate of over 50%. Y2K-related projects accounted for $560 million or about 20% of the total. The Y2K economy fueled the software industry at the same time that the Internet was doing it, thus generating an economic bubble on top of another bubble. The mayhem was so loud that very few people realized that the year 2000 was the last year of the (20th) century, not the first year of the (21st) century, that honor belonging to the year 2001: for the age of the computer anything with a zero at the end ought to be a beginning, not an end. The second millennium of the Christian calendar lasted only 999 years (the first millennium had been from year 1 to 1000, i.e. 1000 years). A 1999 article by international consultant Peter de Jager on the reputable magazine Scientific American concluded: \"I believe that severe disruptions will occur and that they will last perhaps about a month.\" Highly educated people stockpiled food and water, and some decided to spend the last day of the year in bunkers. The apocalypse would come, but it would come a few weeks later, in march 2000, and it would have little to do with the way computers represent dates.\n\nSoftware Tools\n\nMeanwhile, the proliferation of software start-ups in Silicon Valley was not limited to the Internet and the Y2K bug. In 1998 Stanford's scientist Mendel Rosenblum (an assistant to John Hennessy on multiprocessor projects) was working on SimOS, a project to create a software simulator of hardware platforms. Such software would be able to run the operating systems written for those hardware platforms. Rosenblum and others founded VMware to pursue that mission and in may 1999 introduced VMware Workstation, which was not a workstation but a SimOS-like software environment (a \"virtual machine\") that allowed a Unix machine to run the Windows operating system (and therefore all of its applications). Eventually they would broaden the idea to allowing one physical computer to run multiple operating systems simultaneously. Server virtualization had already been popular in the mainframe era, but Rosenblum was the first one to implement it on smaller computers.\n\nRed Hat had become the darling of the Linux world. In 1998 it merged with Sunnyvale-based Cygnus Solutions, founded in 1989 by John Gilmore and Michael Tiemann to provide tools for Linux. When Red Hat finally went public in august 1999, it achieved one of the biggest first-day gains in the history of Wall Street. Meanwhile, in 1999 Marc Fleury started the Georgia-based JBoss project for a Java-based application server (JBoss would be acquired by Red Hat in 2006).\n\nThe Internet and Y2K booms on top of the pre-existing software boom increased the need for software development environments. One of the paradigms that took hold was Rapid Application Development (RAD), originally championed by James Martin at IBM in 1991 but fitting very well the frantic world of Silicon Valley. Instead of developing an application top-down, RAD calls for the immediate creation of a working prototype followed by a series of incremental improvements (in a sense, similar to what Nature does). Delphi, released by Borland in 1995, was an early example of a development environment for RAD. Java also called for a new type of development environment. Visual Cafe, released by Symantec in 1997, was an early example. There had been and there continued to be a proliferation of software tools to overcome the dearth of software engineers and the pressure to deliver ever faster.\n\nIn those years Supply Chain Management was brought to the Bay Area. Agile Software, founded in 1995 in San Jose by Bryan Stolle, sold a suite to help firms manage bills of materials (BOMs). Ariba, started in 1996 in Sunnyvale by Keith Krach (who had founded General Motors' robotics division in 1982 before moving to the Bay Area and joining Rasna) and by Paul Hegarty (NeXT's vice-president of engineering), automated the procurement process. Both pioneered business-to-business (B2B) commerce over the Internet. Supply Chain Management was as hot as ERP. Sales of i2's Rhythm went from $26 million in 1995 to $65 million in 1996, and in 1999 i2 would boast a 13% share of the $3.9 billion supply-chain software market. ERP was already well established in the Bay Area thanks to PeopleSoft and Oracle, although the German companies continued to dominate. In 1997 the total revenues for the ERP software market was $7.2 billion, with SAP, Baan, Oracle, J.D. Edwards, and PeopleSoft accounting for 62% of it.\n\nThe Computer Market at the Turn of the Century\n\nFor the time being the evolution of computers was largely independent of the dotcoms. 34 million households owned a computer in 1996 in the USA.\n\nIn 1997 IBM's revenues were $68 billion, but now a big chunk of them came from technical support to its aging mainframes, a business that employed 160,000 people. In 1997 IBM introduced a new generation of mainframes based on Intel microprocessors, the Netfinity series. In 1995 IBM purchased Lotus Development, one of the many moves that realigned IBM towards the world of personal computers.\n\nCompaq was the rising star. In 1994 it had overtaken IBM in personal-computer sales. In 1997, the year it shipped 10 million personal computers and laptops, Compaq's revenues skyrocketed to $24.6 billion. Compared with Dell and Gateway, Compaq was most successful with corporate customers. In the second half of the 1990s it moved aggressively to capture that market from IBM. In 1997 Compaq acquired Tandem Computers and their line of fault-tolerant servers, a move that gave Compaq more credibility in mission-critical business applications. In 1998 Compaq acquired Digital Equipment Company (DEC), which had been struggling to adjust to the new world of personal computers. DEC was certainly in trouble: despite reducing its workforce (in 1997 it employed 50,000 people, down from a peak of 130,000), DEC still employed about 65% more people than Compaq to generate about 50% lower revenues. However, DEC's products included both high-end servers (priced at $1 million and up) and low-end servers (priced under $100,000), plus workstations, and, more importantly, 45% percent of revenues came now from services: DEC's technical and customer support was a worldwide army of 25,000 people. That was exactly what Compaq needed to take on its rival IBM.\n\nIn 1996 Dell began selling its computers via its website. The website used NeXT's just released WebObjects technology. It allowed consumers and businesses to order directly, and even to customize the configuration of their PC. By spring 1999 Dell had erased the USA sales gap with Compaq (Compaq 16.8%, Dell 16.4%), although Compaq continued to sell more units abroad..\n\nThe market for laptop computers was dominated by Toshiba, which in 1997 enjoyed a market share of 20.4%, Toshiba also introduced the first DVD player (1996).\n\nCompared with the fortunes of IBM, Compaq, Dell and Toshiba, the two Silicon Valley giants, HP and Apple, had a mixed record. Since 1995 HP had become one of the most successful personal-computer manufacturers. It owned more than 50% of the market for printers in that market. And it looked very aggressive: in 1994 it had partnered with Intel to develop a 64-bit processor (code-named \"Merced\") that promised to be a dramatic departure from Intel's x86 architecture (never mind that, when it was eventually released in 2001 with the official name of Titanium, it was a flop because in the meantime Intel had released a faster x86-based processor, the Pentium). As for Apple, which had allied with IBM and Motorola in 1994 to use their PowerPC microprocessor for a new line of high-end Macintoshes, in 1996 it purchased NeXT, and with it the Unix-based NextStep operating system and the WebObjects technology, a Java-based application server for rapid object-oriented software development of Web-based applications. Steve Jobs was therefore back at Apple. In 1997 Apple followed Dell in using WebObjects to create a website (the \"Apple Store\") to sell customized machines directly to the end customer. However, Apple was bleeding: it couldn't compete with the DOS/Windows-based computers and in 1999 it laid off 2,700 of 11,000 employees.\n\nSteve Jobs used the experience in design that he had gained at NeXT, as well as the skills of British designer Jonathon Ive (appointed Apple's top industrial designer in 1997), to create the sexy iMac that debuted in 1998 and that, selling two million units in its first year, began the resurrection of the company. It was the beginning of the \"i\" series of products, that in 1999 continued with the iMovie, a video-editing software for the generic user. Ive applied the minimalist aesthetics of the Bauhaus art movement of 80 years earlier to the iMacs, and that neo-Bauhaus design would be later applied to the iPod in 2001 and to the iPhone in 2007.\n\n34 million households owned a computer in 1996 in the USA.\n\nA Wireless Future\n\nThe new semiconductor companies often targeted emerging niche markets. In 1994 wireless pioneer Proxim had introduced a product to let ordinary computers exchange data via the ether, which truly inaugurated the era of office wireless networks. In may 1998 John Hennessy (of MIPS fame) and Teresa Meng of Stanford University opened in Santa Clara a startup named Atheros that specialized in chipsets aimed at wireless local area networks, later known as \"Wi-Fi networks\". The story of Wi-Fi had begun in 1985, when the US government had made the so-called \"garbage bands\" (900MHz, 2.4GHz and 5.8GHz) available to anybody. In 1988 Victor Hayes of NCR (a company that was considering connecting wireless cash registers) and Bruce Tuch of Bell Labs had begun working on a wireless standard similar (in purpose) to the one devised for the Ethernet. This standard-defining committee, that came to be called 802.11, took almost a decade to complete its research, but eventually in 1997 the specifications were published. In this case it was a government decision (not a technological invention) and it was cooperation (not competition) that created the vast market of Wi-Fi devices. As wireless LANs moved to the home, this would turn out to be a lucrative market. Marvell was started in 1995 in Santa Clara by Indonesian-born Sehat Sutardjia, his Chinese-born wife Weili Dai and his brother Pantas as a fabless maker of semiconductors used in data storage and mostly serving Asian companies. Marvell too would rapidly jump onto the wireless bandwagon.\n\nGadgets\n\nThis was also the age of the gadgets propelled by digital technology but decoupled from the computer industry.\n\nIn the arena of videogames, in 1995 Sony introduced the Playstation, one of the most popular platforms of all time. In 1998 sales of videogame consoles in the USA alone amounted to $6.2 billion, which dwarfed sales of videogame software on personal computers ($1.8 billion). The situation had reversed itself one more time, and now the videogame console was rapidly gaining, thanks to a combination of lower prices and much improved performance.\n\nProgress in graphics video, animation and audio continued at a rapid pace. In 1995 the Moving Picture Experts Group (MPEG) of the International Organization for Standardization (ISO) published the \"mp3\" standard (more properly, MPEG-1 Layer 3) for digital audio and video compression, largely the 1989 thesis of German student Karlheinz Brandenburg. Mp3 had been designed to compress video and audio into the bit-rate of a CD. While Mp3 proved inadequate for videos, it became a very popular format for digital music. In march 1998 Korean-based Saehan Information Systems released the MPMan F10, the first portable Mp3 player, capable of storing nine songs. More successful was Diamond Multimedia's Rio PMP300, which came out in 1998 and became popular with Napster users. Also in 1997 Winamp was released on personal computers, a free MP3 music player developed in Arizona by Justin Frankel and Dmitry Boldyrev.\n\nDigital media companies proliferated around San Francisco's South of Market district, an area previously known mostly for night-clubs and abandoned warehouses that was now nicknamed \"Multimedia Gulch.\" More than 35,000 people worked in the multimedia sector in San Francisco in 1999. Many of them were self-employed or worked for small companies: there were almost 1,000 multimedia businesses.\n\nIronically, the company that had pioneered 3D graphics in the Bay Area was the exception to the general euphoria. Silicon Graphics' spectacular growth peaked in 1995: its market capitalization reached $7 billion in 1995 and revenues were $2.2 billion. However, the company began a rapid decline as it seemed to live in a different world where the Internet did not exist. It mostly specialized in visual effects for Hollywood.\n\nA successful movie, John Lasseter's \"Toy Story\" (that premiered in november 1995), made history for being the first feature-length computer-animated film. Lasseter, a former Walt Disney animator, worked at Lucasfilm under Ed Catmull at a groundbreaking computer-animated short, \"The Adventures of Andre and Wally B\" (1984), for which they used even a Cray supercomputer. When Jobs purchased Lucasfilms in 1986 and turned it into Pixar, Lasseter was given the power and freedom to invest in that technology, but it took almost a decade to come out with a full-length film.\n\nThis followed the short animated films made by Pacific Data Images (PDI) since the mid-1980s and was followed by their first feature films: \"Antz\" (1998), \"Shrek\" (2001) and \"Madagascar\" (2005).\n\nPersonal computers, instead, had to live with humbler features. For example, in 1997 RealNetworks introduced RealVideo to play videos on a computer, but it still used a proprietary format.\n\nIntroduced in the Bay Area in 1998, TiVo, developed by former Silicon Graphics engineers Jim Barton and Mike Ramsay and funded by Geoff Yang and Stewart Alsop, was a digital video recorder capable of digitizing and compressing analog video signal from a television set and of storing it onto a computer's hard-disk. At that point the tv viewer was able to do with television programs what a computer user could do with data. It was a relatively simple idea but it changed forever the definition of \"live event\" and ended the age in which all viewers were synchronized on the same program.\n\nA hyped event of 1996 in Silicon Valley was a hand-held pen-based computer called Palm Pilot: a computer with no keyboard, whose user interface was simply a screen on which the user could write in natural language, a successor to the GRiDPAD of seven years earlier. The founder of Palm, Jeff Hawkins, had studied automated hand-written text recognition at U.C. Berkeley and worked at Grid for a number of years. It was the first pen-based user interface to gain wide acceptance: in 1998 the Palm Pilot had almost 80% of the market for palm-sized computers, and in 1999 it would enjoy four consecutive quarters of triple-digit revenue growth. Palm had already been purchased by U.S. Robotics in 1995, which then merged with 3Com in june 1997.\n\nIn 1999 LeapFrog, founded in Emeryville in 1995 by Michael Wood and Robert Lally, introduced a hand-held computer for children, the LeapPad, a device that allowed students to read ebooks embedded with the NearTouch technology acquired from Explore Tech (founded in 1995 in Sunnyvale). This technology made touch-interactive any section of a page.\n\nThe most sensational high-tech product introduced abroad in 1996 was probably Nokia's 9000 Communicator, which de facto invented the category of \"smart phones\". Palm had tried to create a \"personal digital assistant\" (PDA) starting with a computer. Finnish conglomerate Nokia, the world leader in mobile phones, started with a mobile phone, adding computer capabilities based on an Intel 386 processor running Berkeley Softworks' GEOS operating environment on top of DOS. In 1994 IBM had done something similar with its short-lived Simon.\n\nIn 1997 Psion, the British company that had invented the personal digital assistant, adopted the ARM processor in its Series 5 in conjunction with a brand new operating system that was later renamed Symbian, a joint venture with Ericsson, Nokia, Panasonic, and Motorola.\n\nOne of most daring gadgets introduced in the mid-1990s was a by-product of the feud between Microsoft and Oracle. In 1996 Oracle introduced a disk-less desktop computer, the Network Computer. Ellison preached a world in which data did not have to reside in the house or the office of the user, but could reside on the Internet. Ellison envisioned a future in which the computing power was on the Internet and the user's machine was simply a tool to access that computing power. (Indirectly, this was also a world in which desktop computers had no need for Microsoft's operating systems). The Net Computer was the counterpart to General Magic's hand-held device, and yet another premonition of \"cloud computing\". It also became another embarrassing Silicon Valley flop.\n\nUntil then connecting devices to computer had involved different cables for different kinds of devices. In 1996 an Intel team led by the Indian-born scientist Ajay Bhatt introduced the specifications for USB (Universal Serial Bus), a method that would soon greatly simplify the lives of consumers worldwide and dramatically increase the number of devices that can be connected to a computer.\n\nIn 1998 Sony launched its own removable flash-memory card format, the Memory Stick, and \"memory stick\" would remain the affectionate term for all removable flash-memory units that one could carry in the pocket. In 1999 SanDisk, Matsushita and Toshiba unveiled yet another standard for NAND flash memories: the Secure Digital (SD) format. The SD card would displace CompactFlash as the most popular flash-memory format for consumer electronics the way that CompactFlash had displaced SmartMedia in the previous decade.\n\nA major revolution was taking place in hard disks, a revolution that would soon allow small cheap computers to store large images and videos. In 1997 IBM introduced the first hard disk that used the GMR effect for its read-out heads. The Giant Magnetoresistive (GMR) effect had been discovered in 1988 by Albert Fert and Peter Gruenberg. Stuart Parkin at IBM's Almaden Research Center applied it to data storage and created the \"spin valve\" that was used in the Deskstar 16GP Titan. This new technique would rapidly improve the storage of extremely densely-packed information. Within a decade Hitachi (having bought IBM's business) would release the Deskstar 7K1000, the first hard-disk drive capable of storing one terabytes of data.\n\n3D Printing\n\nThe inkjet printer had been popularized in the 1980s by Hewlett-Packard and Canon. A more complex kind of inkjet technology, called 3DP (also known as \"powder and inkjet\" and \"Z printing\") was developed at the MIT in 1993 by Michael Cima and Emanuel Sachs for printing objects, not pages. But Silicon Valley was still indifferent to 3D printing technology and 3DP was implemented far from the Bay Area: in 1996 South Carolina's Z Corp introduced the first 3D printer based on the MIT technology, the Z402, and in 2000 Z Corp would introduce the first multicolor 3D printer, the Z402C; and in 1997 Sanders Prototype (later Solidscape) of New Hampshire introduced the ModelMaker wax printer based on the MIT inkjet technology. In 1997 Los Angeles-based Soligen used the inkjet technology of the MIT for printing cast-metal parts and renamed it Direct Shell Production Casting (or DSPC). Another system for building metal parts, also based on MIT's 3DP inkjet technology, was ProMetal, introduced in 1999 by ExtrudeHone of Pittsburgh (later renamed Ex One). Another technique that uses a laser beam to fuse together powders, called Selective Laser Melting (SLM), was invented in 1995 at the Fraunhofer Institute in Germany. Electro Optical Systems (EOS) of Germany, that in 1991 had introduced one of the first stereolithography machines and in 1994 had introduced one of the first SLS systems in the world, turned SLM into its Eosint M250. Frank Arcella set up his company AeroMet (actually a subsidiary of MTS) only in 1997 to commercialize LAM printers. In 1996 Direct Metal Deposition (DMD), the technique invented at MIT for metal parts, mutated into Laser Engineered Net Shaping (LENS) at the Sandia National Laboratories in New Mexico. Invented by Dave Keicher, it was commercialized by Optomec in 1998. Silicon Valley was too busy with the dotcom boom to pay attention to 3D printing.\n\nGPUs\n\nPersonal computer graphics of the 16-bit, 2D generation was dominated for a while by the Canadian company Array Technology Inc (ATI), manufacturers of 1987's EGA Wonder and 1988's VGA Wonder. They had been founded in 1985 by three Hong Kong immigrants (Kwok Yuan Ho, Lee Lau and Benny Lau).\n\nComputer games ran on DOS because it was impossible to achieve high performance on Windows. The first major improvement came with the introduction of 32-bit operating systems, and not so much 1991's System 7 for the Apple Macintosh, that initially charmed few developers, but Windows 95, introduced by Microsoft in 1995. The second important factor was the drop in DRAM price: in 1995 Intel introduced the low-cost 430FX chipset that supported Extended Data Out (EDO) DRAM. Regular DRAM was becoming as fast as the expensive Video DRAM (or VRAM). Finally, standards became to emerge. In 1992 Silicon Graphics released an API for both 2D and 3D graphics, OpenGL (an evolution of their proprietary IRIS Graphical Library), that was meant for their traditional Unix market but became a standard for PC gaming in 1996 when Texas-based game developer id Software, that had revolutionised PC gaming with 1993's \"Doom\", ported its stylish 3D game \"Quake\" to Windows using OpenGL. In 1996 Microsoft released its own API, Direct3D (an evolution of the technology developed by British company RenderMorphics, founded in 1992 by Servan Keondjian and Doug Rabson). For a while, however, the winner was neither Direct3D nor OpenGL: Brian Hook of 3Dfx Interactive, a company founded in 1994 in San Jose by three former Silicon Graphics employees (Ross Smith, Gary Tarolli and Scott Sellers), wrote Glide API in 1995. Glide versions of Activision's \"MechWarrior 2\" (1996) and id Software's \"Quake II\" (1997) were among the hits that legitimized Glide as the ruling standard of the late 1990s.\n\nThe net result of these developments was a boom in 3D graphic cards for personal computers, aiming at the mainstream consumer. The first consumer 3D-graphics accelerator cards came to the market in 1996: 3Dfx Interactive (founded in 1994 in San Jose by former employees of Silicon Graphics) introduced Voodoo1, the accelerator that truly left behind the world of 2D graphics; Array Technology (a Canadian company acquired in 2006 by Advanced Micro Devices) launched its 3D RAGE; and Rendition, founded in 1993 in Mountain View, introduced the V1000 chipset based on a RISC architecture. Brian Hook at 3Dfx wrote the Glide API that would become the dominant 3D graphics API for videogame designers. While this trio competed for supremacy, the boost in speed generated a boom in videogames (with \"video\" truly meaning \"video\"). Then in 1999 Nvidia's GeForce 256 virtually defined the modern graphics processing unit (GPU), 2000's GeForce 2 GigaTexel Shader (GTS) hit 1 gigatexel/second (1 billion filtered textured pixels per second, a texel or texture pixel being the fundamental unit of texture space), and 2001's GeForce 3 (released three months after NVIDIA acquired 3dfx) introduced pixel shading, the technology that took gaming into the 21st century.\n\nBiotech\n\nFor biotech 1996 was the year that Sydney Brenner (Francis Crick's successor at Cambridge University, now at the Scripps Institute in San Diego) founded the Molecular Sciences Institute in Berkeley, and the year that Monsanto, a multinational corporation, acquired Calgene. The Human Genome Project was slow to get started, like all big projects, but at last in april 1996 human DNA sequencing began in earnest at several universities funded by the National Institute of Health. Most of these research centers were using the sequencing machines of Applied Biosystems, acquired (in february 1993) by East-coast pharmaceutical colossus Perkin-Elmer. For the media 1996 was the year when (in july) a team assembled by Ian Wilmut at the Roslin Institute in Britain cloned \"Dolly\" the sheep, the first time that a mammal had been cloned in a lab from adult cells. The experiment was centered around the ideas of Keith Campbell, who in 1995 had already succeeded in cloning a pair of lambs, albeit from embryonic cells. In may 1999 Geron of Menlo Park bought the rights on Roslin's nuclear-transfer technology for $25 million.\n\nThanks to all the sequencing machines that it had sold to the centers of the Human Genome Project, PE Biosystems, the new name of Applied Biosystems after being acquired (in february 1993) by East-Coast colossus Perkin-Elmer, had become a wealthy company with revenues of $871 million in 1998. Its new president, Michael Hunkapiller, a former assistant of Leroy Hood at CalTech, boldly attacked his academic customers by deciding to launch a private project to decode the human genome before the Human Genome Project. Basically, he was convinced that the result depended on his machines, not on the army of biologists of the research centers (and that the private industry is more efficient than government bureaucracies). He hired a man who shared his passion for automated genetic processing, Craig Venter of Maryland's Institute for Genomic Research, where the first sequencing (\"mapping\") of a living being's genome had been carried out in 1995. Venter had fallen out with Haseltine after their mutual investor Steinberg had died in 1997, since Venter was more interested in the science and Haseltine in creating a multibillion-dollar pharmaceutical conglomerate. In may 1998 Michael Hunkapiller and Venter set up a new company, Celera Genomics, which soon relocated to the Bay Area (Alameda, near Oakland). Technically, both Biosystems of Foster City and Celera Genomics of Alameda were owned by Applera, a spin-off of Perkin-Elmer's Life Sciences Division which in 2000 also became the official new name of Perkin-Elmer, except that in 2006 Applera renamed itself Applied Biosystems and spun off Celera Genomics; a confusing business story that still left two tightly related companies, one engaged in building machines and the other one in using those machines to sequence DNA. The main investor of both was Cuban-born businessman Tony White, the head of their parent company (what used to be called Perkin-Elmer) who had brokered the deal between Venter and Hunkapiller. Celera Genomics filled a staff of distinguished scholars, including Nobel laureate Hamilton Smith, and bought 300 of Applied Biosystems' most advanced machines to create the world's largest automated factory for mapping DNA.\n\nA new method to sequence DNA (\"sequencing by synthesis technology\") was devised in 1997 at Cambridge University by Shankar Balasubramanian and David Klenerman, who in 1998 founded Solexa in Hayward 9acquired in 2007 by Illumina).\n\nThe Israeli-born computer scientist Victor Markowitz, who had developed a data management system for genome databases at the Lawrence Berkeley Labs, founded the bioinformatics company Gene Logic in Berkeley in 1997 to market a database management system for gene expression data to biotech companies.\n\nIn 1997 the Department of Energy established the Joint Genome Institute (JGI) in an industrial park in Walnut Creek (northeast of Berkeley) to coordinate the three main biological laboratories involved in genomics: Lawrence Berkeley Labs, Lawrence Livermore Labs and Los Alamos (located in New Mexico). In 2010 the JGI would hire Victor Markowitz of Gene Logic fame as chief information officer.\n\nIn the 1990s Stanford held 124 biotech patents, the SRI 50, the University of California as a whole 321 (mainly at Berkeley and San Francisco), Genentech 335, Incyte 322, Alza 238, Syntex 168, Chiron 167. Genentech's former employees had opened more than thirty Bay Area-based start-ups, and South San Francisco (where the Genentech campus was located) had become a major R&D center for biomedicine (for example, Exelixis and Cytokinesis had been started in 1997 a few blocks from Genentech). Investment in biotech companies peaked at $1 billion in the year 2000, up from $668 million in 1999. Between 1995 and 2000 $3 billion in venture capital had created 71 start-ups. At the beginning of 2000 the Bay Area's 90 publicly-traded biotech companies reached a market capitalization of $82 billion.\n\nIn 1998 James Thomson at University of Wisconsin and John Gearhart at Johns Hopkins University reported that they had grown human embryonic stem cells.\n\nNanotech\n\nMeanwhile, nanotechnology finally began to take off in the second half of the 1990s, with start-ups such as NeoPhotonics, founded in 1997 by Timothy Jenks and specializing in photonic integrated circuits.\n\nA merger of biotech and nanotech (Micro-Electro-Mechanical Systems or MEMS) took place in 1996 with the founding of Cepheid in Sunnyvale by former Syntex executive Thomas Gutshall, Bill McMillan (who had invented a rapid automated analysis system at Syntex), MEMS pioneer Kurt Petersen (of Transensory fame), and Greg Kovacs of Stanford's Center for Integrated Systems. Their goal was to build machines that perform rapid molecular testing, typically to detect infectious disease and cancer, i.e. to provide DNA test results when and where they are needed.\n\nSilicon\n\nThe software boom of the 1990s was obliterating the hardware industry, which had given this region its nickname \"Silicon Valley\". However, the silicon industry was evolving towards more optimized forms of design and production. For example, a new way of building a chip was pioneered: by licensing \"pieces\" of chips from different third-party vendors. At the end of the decade, and certainly in the following decade, designing a chip was becoming the art of integrating designs of specialized sub-chips from different parties. The startups in this field were providing the design of reusable units of chip logic and making money out of selling their \"intellectual property\" to multiple chip makers. The products of startups such as Tensilica, founded in 1997 by Chris Rowen (a co-founder of MIPS Technologies) in San Jose (and acquired in 2013 by Cadence Design), were such \"semiconductor intellectual property cores\" or \"IP blocks\".\n\nMeanwhile, system-on-chip design was enabling a new generation of small, portable devices such as phones, cameras and tablets that integrated a variety of components to provide a variety of features. System-on-chip integrated circuits existed since digital watches such as the Microma watch of 1974 and Texas Instruments' LCD watch of 1976; and microcontrollers (incorporating a microprocessor, memory and input-output) were popular already in the 1980s; but these were single-function devices. During the 1990s ASIC technology evolved from the chip-set model towards a single-chip model while ASIC devices began to incorporate larger-scale system functions. The Japanese were particularly influential: in 1993 Hitachi introduced the H8-538F, a 16-bit microcontroller with on-chip flash memory, a microcontroller that was programmable; and in 1997 NEC introduced the world's first single-chip MPEG2 encoder circuit. In Europe, SGS-Thomson (soon to be renamed ST Microelectronics) introduced in 1997 the chip STi5500 Omega for use in TV set-top boxes that integrated an MPEG2 decoder, a 32-bit processor, and other functions; while ARM, which offered a small and simple microprocessor (ideal for single-chip designs in which space was needed for other functions), in 1997 introduced the Thumb 16-bit instruction set (much easier to use than the original 32-bit ARM instruction set). Progress in electronic design automation (EDA) made it easier to incorporate multiple VLSI designs (microprocessor, memories and peripherals) into the design of a single chip. New standards for the integration of functions from different providers increased the market for buying and selling electronic functions. All these developments contributed to the transition from the \"system on a board\" to the \"system on a chip\". The host chip was frequently a RISC processor (such as MIPS or ARM), which offered the advantage of being designed for modularity and the advantage of compatibility with a wide range of peripherals. The motivation to shift to system-on-chip design was also coming from the embryonic mobile phone market: a 2G phone of the early days of GSM was bulky and heavy because it contained several chips.\n\nThe role of electronic design automation became even more important. Magma Design Automation, founded in 1997 by Rajeev Madhavan in San Jose, joined the ranks of the main EDA vendors with Cadence, Mentor and Synopsis (which acquired it in 2012). US leadership in EDA was quite important in establishing world supremacy in the semiconductor field.\n\nIncidentally, in 1997 Isaac Chuang of IBM's Almaden Research Center and Mark Kubinec of UC Berkeley built the first quantum computer.\n\nCulture and Society\n\nSan Francisco's counterculture reacted again in its own idiosyncratic manner to the capitalistic culture of Silicon Valley. Since Silicon Valley had adopted the religion of ever faster and cheaper products, in 1996 Stewart Brand of Whole Earth fame and Danny Hillis, who had designed the supercomputer Connection Machine at the MIT, established the \"Long Now Foundation\" to promote slower and better thinking.\n\nReacting to the large corporate and academic laboratories (often founded by the DARPA), Nick Bertoni, who had run the artist-in-residence program at the San Francisco Exploratorium, heralded the rise of the independent \"makers\" movement when in 1997 he opened the Tinkers Workshop in Berkeley, a place where aspiring\n\nUnderground subversive, so called \"guerrilla\", art staged a significant coup in 1997 when Brian Goggin, coming out of the Burning Man culture, took over the dilapidated Hugo Hotel on 6th and Howard streets and started hanging home-built furniture provided by about 100 volunteers from the hotel's walls. (\"Defenestration\" would be razed in 2014, after the disorderly invasion of Silicon Valley and consequent gentrification of the city).\n\nMeanwhile, pop and dance musicians such as Dan Nakamura, Matmos, Kit Clayton, Kid 606, Blectum From Blechdom and Irr. App. (Ext.) were pushing the envelope of digital music, showing what could be done with a simple laptop, while the psychedelic tradition survived in Devendra Banhart.\n\nDuring the 1990s the population of the Bay Area grew by 13%. The San Francisco- Oakland- San Jose metropolitan region had seven million people in 2000, making it the fifth largest metropolis in the USA.\n\nAnthropology of the Untouchables\n\nIn the 1990s the median income in Santa Clara county was almost twice the median income in the USA, but within the valley the income gap kept increasing. There were at least three classes with widely different income levels. The common laborers (such as the security guards who worked night shifts, the cleaning people and the clerks of the gas stations) had a low income that made it difficult for them to afford the cost of living of the Bay Area. Many of them resided in the east or south bay, where rent was cheaper, and many of them lived in old-fashioned familiar nuclei. They were not very visible: you had to take one of the freeways into the Bay Area very early in the morning to see them commute to work from distant places. Then there was the huge mass of engineers, who could afford a nice car and a nice apartment. However, the cost of living was such that many of them shared a house or an apartment with someone else. Those who bought a house most likely bought a \"townhome\" in a \"subdivision\". Each subdivision provided long lines (or circles) of identical homes with minimal separation from each other. The upper class consisted of the rich: either hereditary rich or beneficiaries of the computer boom (because either their company was acquired or the company's stock skyrocketed) or highly paid executives. This third class was much larger than in any other part of the world: entire areas of Atherton, Woodside, Portola Valley and Los Gatos were carpeted with multimillion dollar homes. And yet the lower class was dreaming of sending its children to school so that they would become engineers, and the engineering class was dreaming of becoming a millionaire, so both castes happily accepted their subordinate roles. Finally, there was the old generation who bought a home in the 1960s and lived a much more relaxed life in single-family detached houses, most of them with a swimming pool and a large backyard. They paid very little for the house before the computer boom. During the 1990s, as they began to retire, many of them sold their homes to the younger generation of the computer boom. This generation of ordinary middle-class families (the bread and butter of, say, Midwestern America) quietly faded away, enyoing the profits from their investment in real estate but rapidly obsolete in the digital age."
    }
}