{
    "id": "dbpedia_1727_2",
    "rank": 46,
    "data": {
        "url": "https://jcls.io/article/id/3594/",
        "read_more_link": "",
        "language": "en",
        "title": "The Authorship of Stephen King’s Books Written Under the Pseudonym “Richard Bachman”: A Stylometric Analysis",
        "top_image": "https://jcls.io/article/id/3594/file/21455/",
        "meta_img": "https://jcls.io/article/id/3594/file/21455/",
        "images": [
            "https://jcls.io/media/cover_images/10ecc87f-dd18-426c-b2a4-67600d447a68.jpg",
            "https://orcid.org/sites/default/files/images/orcid_16x16.png",
            "https://orcid.org/sites/default/files/images/orcid_16x16.png",
            "https://orcid.org/sites/default/files/images/orcid_16x16.png",
            "https://jcls.io/article/id/3594/jcls-3594_kingbachmann-g1.png",
            "https://jcls.io/article/id/3594/jcls-3594_kingbachmann-g2.png",
            "https://jcls.io/article/id/3594/jcls-3594_kingbachmann-g3.png",
            "https://jcls.io/article/id/3594/jcls-3594_kingbachmann-g4.png",
            "https://orcid.org/sites/default/files/images/orcid_16x16.png",
            "https://orcid.org/sites/default/files/images/orcid_16x16.png",
            "https://orcid.org/sites/default/files/images/orcid_16x16.png",
            "https://jcls.io/media/cover_images/1bc0c7bd-835e-444f-8f9e-a586b23edb19.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Dorothy Modrall Sperling",
            "Vincent Neyt",
            "Mike Kestemont",
            "Dorothy Henriette Modrall Sperling"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Between 1977 and 1984, Stephen King published five novels under the pseudonym “Richard Bachman”. Reviewers noted similarities between King’s and Bachman’s writing styles when Thinner (1984) was published, ultimately leading to King’s unmasking. We investigate whether computational authorship analysis techniques can correctly identify King as the author of the Bachman books out of a selection of contemporary candidate authors – Dean Koontz, Peter Straub, and Thomas Harris. We also perform a post-hoc analysis of the use of pop-culture references and brand names in Bachman, King, Koontz, Straub, and Harris novels, based on comments in reviews of Bachman and King novels. The references extracted from the Bachman books occurred significantly more often in King’s texts than in the others’, showing that attentive readers could have “heard King’s voice” in the Bachman books through what a reviewer denigratingly called King’s “compulsion to list brand-name products and his affinity for pop-cult teenage junk”.",
        "meta_lang": "en",
        "meta_favicon": "/media/cover_images/5cbb5fb5-cfe7-4f8a-b385-c98af1fa733f.png",
        "meta_site_name": "Journal of Computational Literary Studies",
        "canonical_link": "https://jcls.io/article/id/3594/",
        "text": "1. Introduction\n\nIn February 1980, Stephen King published a lengthy essay called “On Becoming a Brand Name” in Adelina, a men’s magazine. The essay records King’s reaction to being referred to as a “Brand Name Author” in the modern American horror genre. He did not wish to oppose himself to being given that label; he was proud of his accomplishments at that point as a regular in the New York Times bestseller list and receiver of advances of well over one million dollars for a new novel. Instead, he wrote the essay to tell the story of how he had arrived at being labelled as such, emphasizing especially that he didn’t exclusively write horror. In fact, before starting on what was to become his first published novel, Carrie (1974), he had already completed four other novels – none of them horror. King described in detail when he wrote those four pre-Carrie books, and how he tried, unsuccessfully, to get them published. He does not mention their titles, but refers to them as “Book #1”, “#2”, and so on. It is understandable that an author would rather remain vague about unpublished material. But in Stephen King’s case, he had no choice but to be vague because two of those four books had by then been published under a secret pseudonym: Richard Bachman.\n\nUp to the present-day, King has published no less than seven novels under the pen name Richard Bachman: Rage (1977), The Long Walk (1979), Roadwork (1981), The Running Man (1982), Thinner (1984), The Regulators (1995), and Blaze (2007). The uncovering of Bachman’s identity sparked shortly after Thinner came out. Both readers and reviewers noticed how similar the text was to King novels in style, theme, and narrative drive. In early 1985, King was forced to admit to The Bangor Daily News that he was Bachman (Smith 1985). He later acknowledged that it was inevitable that Bachman’s true identity would come to light at some point; he had been getting letters from the publication of the very first Bachman book, which he attributed to readers recognizing his “voice” (King 1985, v–vii).\n\nIn this article, we will use techniques from computational author identification to determine – albeit, only retrospectively – whether a stylometric analysis of the Bachman books could indeed have discovered Stephen King’s distinctive voice in the texts. In stylometry, attribution and verification are commonly distinguished. Authorship attribution is the process of attributing an unknown document to an author within a set of candidate authors (Koppel et al. 2011). Authorship attribution is distinct from authorship verification in that authorship verification involves comparing an unknown text to a corpus of texts by a known author, where the aim is to determine whether the unknown document is also by that author. In authorship verification, no other candidate authors are necessarily involved, although they might serve as a point of comparison (Potha and Stamatatos 2014).\n\nThis paper is structured as follows: Below, we will first survey the seminal critical response to the Bachman novels. The next sections present related work and describe the materials used for this study, i.e., the (control) authors and the books selected for analysis. We go on to introduce the experimental setup that we chose for the analysis of the Bachman books and motivate our choice for the Juola protocol (Juola 2015). After discussing the results of our analysis, we move on to the issue of explainability, which is rarely discussed in the context of verification. We describe an experimental method to analyze counts of brand names and pop-culture references in the corpus, one of the “Bachmanesque” features that were explicitly mentioned by early critics.\n\n2. Early Criticism of Bachman Novels\n\nRage, The Long Walk, Roadwork, and The Running Man appeared as paperback originals with very small print runs. They were hardly reviewed at all. We were only able to find two reviews of Roadwork (Slotek 1981; Strachan 1981), and one of The Running Man (Frank 1982) – none of them compared Bachman to King. Sam Frank praised Bachman’s “vivid gut-level prose,” his “straight-ahead storyline”, “multi-dimensional characters”, and “stark, dank, volcanic descriptions” (1982, 6). Jim Slotek’s review of Roadwork stated: “Bachman’s frenetic, staccato writing style and his habit of throwing in one pop-culture backdrop after another (The Rolling Stones, Merv Griffin, the ever-present television) grab the reader’s eye like headlines” (Slotek 1981, 10). That this reviewer noticed enough pop-culture references in the novel to give them such attention in a short review is interesting, since the use of brand names and names of musicians, actors, songs, movies, and television programs was a “sin” that critics commonly attributed to King. For instance, one negative review of The Talisman (1984), which King wrote in collaboration with Peter Straub, posited that the novel “inherited the worst traits of both its parents. From King it has acquired, among other things, his compulsion to list brand-name products, his affinity for pop-cult teenage junk and his penchant for the endless repetition of cryptic italicized phrases” (Lehmann-Haupt 1984, C–15). Reviewer Roger Grooms drew the same conclusion: “Combined novel has King’s flavor. […] When the frost is on the ‘punkin’, the ubiquitous Stephen King pops up with yet another tale of gruesome goings-on, generally taking place right in the middle of our pop culture” (Grooms 1984, E5).\n\nAround the same time as the publication of The Talisman (fall of 1984), Richard Bachman’s Thinner arrived in bookstores. The book received more critical attention than the previous four Bachman books because it was published in hardback and review copies were widely distributed. While some reviews made no mention of King (e.g.: O’Neil 1984; Levin 1984; Williams 1984), and one reviewer remarked that the plot of Thinner contained “several gaps that a writer like King doesn’t fall through” (Denger 1985, 6D), there were also many reviewers, booksellers, and early readers who heard King’s voice in Thinner. One review included the tentative remark that “Bachman’s style is remindful of Stephen King” (Anonymous 1984, 4G), but others were less cautious. Locus Magazine wrote: “King does not acknowledge it, but this horror novel about dieting sure sounds like him” (as quoted in Ganley 1985, 5). W. Paul Ganley elaborated on this quote in his own review: “[T]his novel is pure King in style, syntax, character development, dialog, plot structure, humor, gross outs, and even in technical mistakes” (Ganley 1985, 5). Mark Graham announced that “this thriller raises an authorship question”: “If King didn’t write the end of this little narrative, his doppelganger did” (Graham 1984, 26-N).\n\nIt is striking that so many readers – independently from one another – seem to have picked up on similarities between Bachman’s and King’s writing style: Out of curiosity alone, this observation sufficiently motivates the question whether computational methods would have been able to pick on these resemblances too. Using an established method from authorship verification, we shall assess below whether that is indeed the case. Perhaps equally striking, however, is that the reviewers’ comments that we have assembled remain rather vague as to why precisely they connected Bachman to King; in fact, we could only find a single textual feature mentioned which was concrete enough to be counted using standard digital text analysis techniques: the use of brand names and other references to popular culture. Therefore, we will also explore whether King’s supposed trademark use of this device can be used to single him out as the most-likely author of the Bachman books. As such, this paper contributes to the issue of post hoc explainability in author identification for literary texts.\n\n3. Related Work\n\nStephen King’s style has received only limited scholarly attention so far. James Arthur Anderson has published two monograph-length studies on King in which he uses linguistic analysis (Anderson 2017, 2020). In The Linguistics of Stephen King he examines King’s works “using critical theory developed from linguistic studies” to “provide a close reading of how King layers language upon language to create both reality and meaning” (Anderson 2017, 7). David L. Hoover dedicated a chapter to King in his monograph Modes of Composition and the Durability of Style, examining possible changes in King’s style based on chronological periods, changes in mode of composition (handwritten, typewritten, word processed novels), and the difference between writing under the influence and sober. He encountered many categorization problems and could not computationally detect any noticeable stylistic differentiation, concluding that “Stephen’s style was not only durable in the face of changes in mode of composition, it was also durable in the face of his abuse of alcohol and drugs and his recovery from that abuse” (Hoover 2021, 165). Van Cranenburgh and Ketzan (2021) also apply computational stylometry to the work of Stephen King to quantify the literariness of 73 King novels and novellas. In their conclusion they suggest that “an exploration of King/Bachman would merit a dedicated, mixed-method study”, to determine “whether the Bachman novels (some separated by decades) can convincingly be argued to share distinctive features” and if Bachman is “a signal, or merely noise” (Van Cranenburgh and Ketzan 2021, 196). We propose our paper as a first step in such an exploration.\n\nWith the emergence of computing technology in Humanities scholarship, quantitative authorship studies initially focused primarily on two approaches: (1) unsupervised methods (such as exploratory visualization techniques, such as dendrograms and PCA scatterplots), which are still very popular in computational literary studies; or (2) casted the problem of author identification as a standard text classification problem. The latter approach casts attribution as a machine learning task, where exactly one label, from a set of (mutually exclusive) labels, has to be assigned to a previously unseen document. In such a setup, a text classifier can be trained on a set of reference documents for which the authorship can be established beyond reasonable doubt. This particular setup is often referred to as “closed-set attribution”, because the set of candidate authors is well delineated and fixed. Excellent performance has been reported in this area, although there still exist important limitations regarding text length, text variety (genre), as well as the number of author classes to be learned.\n\nIn many authorship attribution experiments, a text’s authorship is determined by calculating the similarity of that text to texts by a set of candidate authors, i.e. a form of “lazy learning”. In Burrows’s “Delta” method, for example, a text’s authorship is predicted based on the frequencies of the frequently-occurring 150 words in the entire set of reference texts (Burrows 2002). “Delta” is a measure that quantifies the similarity between a target text and texts written by potential authors. It represents the standardized difference between the observed frequencies of the 150 most frequently occurring words in the target text and the expected frequencies based on reference texts (Evert et al. 2017). Similarity-based authorship attribution, combined with machine learning methods, have been found to perform well in identifying the true authors of novels written by pseudonymous authors. For example, Jaques Savoy used Burrows’s Delta, along with Labbé’s distance, nearest shrunken centroids (NSC), naïve Bayes, k-nearest neighbors, and character n-grams to identify Domenico Starnone as the probable author of pseudonymous Italian novelist Elena Ferrante’s novels (2018). Eder, Tuzzi, and Cortelazzo corraborate Savoy’s prediction that Starnone wrote Ferrante’s novels (Eder 2018, Tuzzi and Cortelazzo 2018).\n\nIn the real world, however, there are many practical scenarios that do not fit the attribution scenario ideally, mainly because the set of potential candidate authors might be prohibitively large (the “needle in a haystack problem”) and, consequently, it might be difficult (or even impossible) to construct a training data set that can be guaranteed to include the true author of an anonymous document. In such cases, it is problematic that text classifiers will always attribute an anonymous document, no matter what, to one the available authors, even if none of the available authorial labels in reality applies. Koppel and colleagues have published seminal papers in this area, highlighting that open-set attribution is a much more difficult, but also much more realistic approach to author identification “in the wild” (Koppel and Y. Winter 2014a; Koppel et al. 2007; Koppel et al. 2009). Especially open-set attribution, or authorship verification, has emerged as an established formulation of the problem. Here, algorithms still work with a limited set of candidate authors in the foreground, but specifically take into account the possibility that the correct author might not be included, effectively introducing a “back-off option” where the system returns “None of the above”.\n\nApart from a series of applied case studies in literary studies, the authorship track in the annual shared task at the PAN workshop has played a major role in benchmarking existing approaches in this domain.1 Below, we will especially draw inspiration from the “imposter approach” that was seminally introduced by Koppel and colleagues. Variations of this approach have ranked particularly high in recent editions of the shared task on authorship attribution at PAN. Importantly, the imposter approach is dependent on a pool of “imposter authors” or “distractors”, to which anonymous documents and candidate authors (e.g. in a foreground corpus) can be compared. Researchers have observed that a larger and more diverse imposter pool is invariably beneficial to the performance of the imposter approach. Unsurprisingly, the most successful applications of the method have been applied for text varieties that were abundant and easy to collect online, such as blog posts. For many text varieties, however, it is much more difficult to collect large imposter sets, such as contemporary fiction, because of intellectual rights or digitization backlog.\n\nThis is a practical disadvantage of the method that is hard to circumvent in practice. Interestingly, this limitation is bypassed in the so-called Juola protocol that nevertheless still shares characteristics with the imposters approach. Apart from this practical advantage, Juola’s seminal case study (perhaps the most mediatized in the history of the field) bears important resemblances to the Bachman case. After initial speculation in the (social or traditional) media, the high-profile author was twice relatively quick to self-identify as the author behind the pseudonymously published novels. In both cases, moreover, the authors have no reason to consciously alter their writing styles and lacked a clear incentive to publish in an alternative “mode”. This was not the case, for instance, in the well-known French controversy surrounding Romain Gary, where the author actively resisted self-attribution, even after having been called out (Tirvengadum 1996). In the case of Rowling, however, the initial speculation was not based on stylistic similarities, which was the case for Bachman.\n\nPatrick Juola was actively involved in the verification of the authorship of The Cuckoo’s Calling, published under the pen name “Robert Galbraith” (Juola 2013a). This successful research initiative later led him to publish a so-called “protocol” (Juola 2015) that included methodological guidelines as to how such cases could be reliably tackled in the future. Juola compared Galbraith’s novel to books by (the small number of) contemporary British female crime novelists (ibid.), that served as distractors. He ultimately operated in an open-set context, because there was no guarantee that the correct author was included among the candidates. As with our Bachman case, sampling a larger pool of imposters was infeasible, because of the intellectual rights that lie on contemporary literature and also often challenging to obtain in a digital format. Thus, the Juola protocol does not implement any sampling of imposters, although it does engage in a stochastic component in the form of feature sampling: A large and diverse feature set is engineered for each of the documents involved and the similarity is measured across these sets to produce a ranking of candidate authors that stable across different feature sets. This approach is reminiscent to the iterative bootstrapping of features in the imposter approach.\n\nSurveying the state of the art in author identification is challenging, because case studies and benchmark task differ enormously, for instance across languages, historical periods, dataset sizes, documents lengths, text varieties involved or the number of candidate authors. Recently, neural models (e.g. Boenninghoff et al. 2019), in particular large foundation models in the form of embedders such as BERT, have yielded promising results. Currently, transformer models appear to be among the best performing author identification method when (1) one is dealing for a language variety for which pretrained language models are available (2) there is a substantial amount of text data available per author. A important survey of modern authorship attribution methods found that performance heavily depends on the number of available words per author in a dataset (Tyo et al. 2022). Tyo et. al found that experiments with datasets containing less than 100,000 words per author, traditional n-gram based models achieved a higher accuracy than BERT-based models (76.50% and 66.71%, respectively). They note that, in general, in experiments with fewer words per author, traditional word- and character-level n-grams outperform more sophisticated deep learning techniques. Their observation is supported across the literature – for example, Alkatori et al. found that using word- and character-level n-grams yield higher accuracy than transformer models in an authorship attribution task using a dataset of Guardian articles, with an average of 41 thousand words per author in their corpus. (Altakrori et al. 2021). Thus, while neural methods are promising, they often come with requirements that cannot always be met.\n\nWhile BERT-based models achieve state-of-the-art accuracy on authorship attribution tasks with extensive word datasets per author, applying such models in the humanities presents challenges due to the technical complexity of deep learning, which may be unfamiliar to researchers in this field. Moreover, model inspection and feature analysis are even more challenging with deep models like BERT compared to traditional n-gram approaches. n-gram models offer simplicity and transparency, making them more suitable for authorship attribution tasks in the humanities where interpretability is crucial. Therefore, in this paper, we opt for a simple similarity-based authorship attribution method that relies on transparent word- and char-level n-gram document representations.\n\n4. Materials\n\nOur corpus of distractor novels is made up of texts by three horror-thriller writers: Dean Koontz, Peter Straub, and Thomas Harris. These writers were chosen because, like King, all three are American, male authors that published popular novels in the 1970s, 80s, 90s, and 2000s in the same genre. The corpus includes 20 novels by King, 5 by Harris, 12 by Straub, and 17 by Koontz. It consists of all novels by Harris and Straub and a selection of books by Koontz and King up until 2007, which is when Blaze was published. The books were obtained in EPUB format and converted to UTF-8-encoded plain text files. Table 1 includes a selection of lexical statistics for each of the texts. The number of unique tokens, i.e., types, may be affected by text length: Type-token ratios tend to be lower in longer texts because words are more likely to reoccur in longer texts (Richards 1987). Therefore, type-token ratios (TTR) were extracted from the first 10,000 tokens of each book (Table 1).\n\nAuthor Title Date of Publication Word Count Number of Word Types TTR (First 10,000 Tokens) Bachman 1966 The Long Walk 87,333 7,928 0.197 1968 Roadwork 93,047 8,786 0.209 1970 Rage 55,909 6,203 0.209 1973 Blaze 82,444 7,720 0.187 1981 The Running Man 67,769 8579 0.252 1984 Thinner 99,272 8,582 0.221 1995 The Regulators 120,909 9,456 0.217 Harris 1975 Black Sunday 96,485 9,194 0.247 1981 Red Dragon 105,648 9,136 0.214 1988 The Silence of the Lambs 99,299 8,878 0.222 1999 Hannibal 126,831 11,588 0.240 2006 Hannibal Rising 67,575 7,671 0.231 King 1974 Carrie 62,275 7,509 0.247 1975 ‘Salem’s Lot 156,566 12,117 0.251 1977 The Shining 165,734 11,574 0.218 1978 The Stand 479,256 20,363 0.217 1979 The Dead Zone 156,648 11,689 0.246 1994 Insomnia 251,490 13,842 0.215 1995 Rose Madder 180,040 11,171 0.205 1996 The Green Mile 135,954 8,754 0.212 1996 Desperation 199,619 11,581 0.202 1997 Wizard and Glass 265,321 13,470 0.209 1998 Bag of Bones 215,488 13,045 0.214 1999 The Girl Who Loved Tom Gordon 63,368 6,102 0.201 2001 Dreamcatcher 214,223 13,051 0.195 2002 From a Buick 8 128,836 9,159 0.195 2003 Wolves of the Calla 251,658 13,232 0.199 2004 Song of Susannah 132,659 10,018 0.198 2004 The Dark Tower 283,647 14,861 0.214 2005 Colorado Kid 35,265 4,260 0.201 2006 Cell 126,858 9,235 0.208 2006 Lisey’s Story 192,276 11,719 0.220 Koontz 1968 Star Quest 35,233 5,057 0.256 1970 Beastchild 48,544 5,900 0.224 1972 Warlock 57,259 6,825 0.240 1974 After the Last Race 84,411 7,895 0.221 1976 Night Chills 94,934 8,477 0.241 1977 The Vision 66,100 6,508 0.215 1980 Whispers 177,987 11,509 0.246 1981 The Eyes of Darkness 89,325 8,299 0.245 1983 Phantoms 138,378 10,878 0.225 1986 Strangers 264,107 15,553 0.270 1988 Lightning 140,257 10,676 0.234 1990 The Bad Place 147,579 11,311 0.248 1992 Hideaway 130,796 11,235 0.253 1994 Winter Moon 118,019 10,376 0.250 1998 Fear Nothing 130,790 11,553 0.249 2000 From the Corner of His Eye 217,821 15,649 0.267 2002 By the Light of the Moon 127,314 11,920 0.302 2004 The Taking 86,104 9,857 0.280 2006 The Husband 86,316 8,797 0.231 2007 The Good Guy 84,424 8,305 0.218 Straub 1975 Julia 85,342 7,853 0.211 1977 If You Could See Me Now 110,624 8,394 0.236 1979 Ghost Story 187,951 11,283 0.217 1980 Shadowland 159,291 10,621 0.219 1982 Floating Dragon 225,917 13,022 0.252 1988 Koko 210,205 12,503 0.238 1990 Mystery 181,264 10,243 0.221 1993 The Throat 254,781 12,635 0.218 1995 Hellfire Club 191,789 11,760 0.232 1999 Mr. X 186,987 13,010 0.244 2003 Lost Boy, Lost Girl 89,152 8,044 0.244 2004 In The Night Room 103,235 9,070 0.232\n\n5. Task Operationalization\n\nIn this section, we investigate whether it is possible to identify Stephen King, only post hoc of course, as the author of the Bachman books. Our approach reproduces some of the key characteristics of Juola’s authorship verification protocol, who recommends building various feature sets (word lengths, most frequent words, character 4-grams, and word bigrams) to calculate similarities between the target and distractor texts (Juola 2013b). The author who wrote the text most similar to a target text is predicted to be the author of the target text.\n\nAs in Juola’s protocol, we convert calculated similarities to ranks. Juola takes similarities between target texts and known-author texts and ranks each author by their comparative similarity to the target text. Likewise, we take the cosine distances between book segments, i.e., sequences of consecutive tokens drawn from a book. We calculate the cosine distance between a Bachman segment and a segment by one of the candidate authors in our corpus, and rank the candidate authors by cosine distance. Consider a Bachman segment that has the cosine distances 0.43 for a Harris segment, 0.30 for a King segment, 0.70 for a Koontz segment, and 0.67 for a Straub segment. For this Bachman segment, King occupies rank 1 because the King segment had the smallest cosine distance to the Bachman segment, Harris has rank 2 because his segment was second closest, and so on.\n\nOur prediction algorithm is based on Koppel and Winter’s many-candidates method of authorship attribution (Koppel and Y. Winter 2014b). It relies on several varied (“bootstrapped”) feature sets used to make predictions. Using diverse feature sets to represent texts reduces false similarities between target texts and known-author texts that cannot be reproduced with different feature sets. Half of the features from this varied feature set are randomly subsampled to calculate the similarity between a target text and a known-author text, repeated in k iterations. Finally, candidate authors are each assigned a score representing the proportion of iterations in which the candidate’s segment was most similar to the target segment.\n\nFirst, we produce a corpus of segments. To create this corpus, we tokenize and remove punctuation from all books in our corpus. Each book is then split into segments of 1,000, 5,000, and 10,000 consecutive tokens. Trailing segments of less than each of the aforementioned lengths are not included in the dataset.\n\nSecond, we produce a large feature set from the segments. We generate the feature set by vectorizing segments using combinations of different vectorizer settings. Half of the vectorizers use tf-idf weighting, and half of the vectorizers do not use tf-idf weighting. We use char and word analyzers with ranges of 2 to 4, and 1 to 3, respectively; i.e., word vectorizers create features of unigrams, bigrams, and trigrams, and char vectorizers create features of bigrams, trigrams, and 4-grams. Each vectorizer caps the number of features/columns it extracts at 10,000 to limit the number of n-grams that only appear in one book.\n\nIn total, the combination of 2 tf-idf settings (true and false), 2 analyzers (word and char), and n-gram ranges of 3 (for both word and char n-grams) creates 12 distinct vectorizer settings to generate 12 feature spaces. The 12 feature spaces are concatenated to create one combined feature space with a maximum of 120,000 columns. Each new feature space was scaled with min-max scaling before being appended to the final feature space.\n\nThird, we calculate the cosine distance between each Bachman segment vector and a random segment vector by each distractor author.\n\nBelow is our algorithm in pseudo-code:\n\nFor each segment length (1,000, 5,000, and 10,000 tokens) s:\n\nSplit all books in the corpus into segments of s tokens;\n\nInitialize an empty list of feature spaces l;\n\nFor each collection of vectorizer settings v:\n\nInstantiate a vectorizer i with collection of settings v;\n\nCreate a feature space f by vectorizing the corpus of segments using vectorizer i;\n\nAppend the feature space f in the list of feature spaces l;\n\nHorizontally concatenate the list of feature spaces l into a 2-dimensional feature space array a;\n\nFor each row rB representing a Bachman segment in the feature space array a, repeat 1,000 times:\n\nFor each candidate author in the corpus (King, Koontz, Straub, and Harris):\n\nRandomly select a row rC representing a segment by this candidate author in the feature space a;\n\nRandomly sample 10,000 distinct features from the feature space a;\n\nCalculate the cosine distance between rB and rC using these 10,000 randomly-chosen features;\n\nConvert cosine distances into ranks (1 = segment has lowest cosine distance to Bachman segment, 4 = segment has highest cosine distance to Bachman segment).\n\nThis algorithm created 1,000 cosine distances between each Bachman segment and a segment by a candidate author – 4,000 cosine distances in total per Bachman segment. We describe the results of this analysis below.\n\n6. Authorship Attribution Results\n\nIn order to test whether authors received certain rankings significantly more or less often than if rankings were sampled from a random distribution, we performed a chi-squared test and visualized Pearson residuals using an association plot (Figure 1). The association plots show how ranking counts vary in a meaningful way across authors. They indicate that King was considerably more likely to be predicted as the author of a Bachman segment (ranking = 1). The other candidate authors were significantly less likely be predicted as the author of a Bachman segment. In plots created using 5,000 and 10,000-token segments, segments written by King were significantly less likely to be 2nd, 3rd, or 4th most similar to Bachman segments (Figure 2). However, in the plot created using 1,000-token segments, segments written by King were significantly more likely to be both the 1st and 2nd most similar to Bachman segments.\n\nFor every Bachman book, Stephen King was predicted as the author of a segment in a much greater proportion of iterations than all other candidate authors (Table 2). The Regulators had the highest proportion of iterations in which King was the predicted author, at 50.8%, 70.6%, and 81.8% of iterations with 1,000, 5,000, and 10,000-token segments. By contrast, The Running Man had the lowest proportion of iterations in which King was the predicted author for 1,000, 5,000 and 10,000-token segments, with 36.8%, 45.6%, and 47.5%, respectively. King nevertheless still received the highest proportion of iterations compared to other authors.\n\nTitle Rank Harris King Koontz Straub The Long Walk 1 0.018 0.661 0.077 0.244 2 0.101 0.238 0.214 0.446 3 0.311 0.080 0.386 0.223 4 0.569 0.021 0.323 0.087 Roadwork 1 0.079 0.491 0.108 0.322 2 0.181 0.290 0.183 0.346 3 0.322 0.156 0.303 0.219 4 0.418 0.063 0.406 0.114 Rage 1 0.043 0.526 0.062 0.370 2 0.141 0.324 0.158 0.377 3 0.342 0.117 0.362 0.178 4 0.474 0.033 0.418 0.075 Blaze 1 0.055 0.616 0.085 0.244 2 0.184 0.244 0.196 0.376 3 0.354 0.102 0.305 0.239 4 0.407 0.038 0.414 0.140 The Running Man 1 0.086 0.456 0.165 0.293 2 0.193 0.267 0.220 0.321 3 0.309 0.172 0.281 0.238 4 0.413 0.105 0.334 0.148 Thinner 1 0.032 0.604 0.104 0.260 2 0.117 0.262 0.229 0.392 3 0.296 0.103 0.363 0.239 4 0.555 0.032 0.304 0.109 The Regulators 1 0.022 0.706 0.085 0.187 2 0.115 0.203 0.250 0.432 3 0.296 0.069 0.373 0.262 4 0.567 0.021 0.293 0.118\n\n7. Brand Name and Pop-Culture References Analysis\n\nKing’s work has been described as combining the tradition of American naturalism with the classic supernatural horror genre (Bradley 1998, 96). As he himself has vehemently stated, King was in no way the first writer to take horror out of its classic gothic settings and transport it into small-town America. He has claimed that Richard Matheson, Robert Bloch, Jack Finney, and the TV show The Twilight Zone created the genre of modern American horror, which lies at the root of his poetics: “Those things formed my idea of what a horror story should do: The monster shouldn’t be in a graveyard in decadent old Europe, but in the house down the street” (Underwood and Miller 1989, 93). The craft, in King’s opinion, is to “create any kind of environment that the reader can identify with totally” (Thomases and Tebbel 1981, 95) and then to “inject [it] with the fantasy element” (Underwood and Miller 1989, 113).\n\nInserting brand names and references to pop-culture is a tool in creating the familiarity necessary for the optimal effect of the horrific. In the essay “Dean Koontz and Stephen King: Style, Invasion, and an Aesthetics of Horror”, Michael R. Collings posits that “brand-name descriptions, carefully established realism of setting and character, common images, and themes may themselves become, not trademarks of a single author (as we frequently assume when we talk of King’s brand names), but characteristics of dark fantasy itself, part of the realism of presentation that C. S. Lewis argued was essential to fantasy at any level” (Collings 1998, 76). Including brand names in their work is a practice King and Koontz share, Collings believes, because it is inherent in the genre, “although far more so in King than in Koontz” (Collings 1998, 76). Thus, in our opinion, it would be more interesting to approach the use of brand names and pop-culture references as a genre convention than as an idiosyncrasy of King’s style, and to test whether King does indeed use brand names and references to pop-culture significantly more often than other authors in the genre – so much so that attentive readers could have deduced that the brand names used by Bachman “sounded” like King.\n\nAs a first step, we aimed to quantify the references to brand names and pop-culture of all five authors. We manually compiled lists of such references in books from the authors in our corpus: Four of the five Bachman books published before King was uncovered as the author (Rage, The Long Walk, Roadwork, and Thinner),2 and three novels by Koontz, Straub, King, and Harris. We extracted references from three texts by each to avoid the risk of choosing one novel that may not accurately represent the author’s overall writing style. This allowed us to establish an average use of references for all authors. Where possible, we selected novels that were published during the same period as the early Bachman books: between 1977 and 1984.3 These were the novels that fans of the genre of modern horror would have read not long before Thinner came out.\n\nThe concepts “popular culture” and “brand name” are difficult to define and delineate, so we have opted to cast a wide net: We include not only names of contemporary celebrities (e.g., “Kitty Carlisle”, “Sting”), brand names of commercial products (e.g., “Ford”, “Shell”), TV shows (“I Love Lucy”, “Star Trek”), and movies (“Wizard of Oz”, “Psycho”), but also the names of newspapers, hotels, airlines, sports teams, banks, musicians, writers, painters, literary characters, and book titles. Each reference was counted only once, no matter how many times it occurs in the text. In King’s Cujo, for instance, a Ford Pinto plays an important role, but it only counts as one of the 235 references found in the novel. The result is presented in Table 3, and the complete lists of extracted references for each author can be viewed in subsection A.2.\n\nAuthor Title References Word Count Refs per 100,000 words King Firestarter 202 153,219 132 Cujo 235 119,497 196 Pet Sematary 215 144,961 148 average: 168 Koontz The Eyes of Darkness 60 89,325 68 Phantoms 93 135,058 68 Darkfall 63 102,550 62 average: 66 Straub Ghost Story 212 182,732 116 Shadowland 115 159,291 72 Floating Dragon 137 225,917 60 average: 82 Harris Black Sunday 114 96,485 118 Red Dragon 87 105,648 82 The Silence of the Lambs 142 99,299 144 average: 114 Bachman Rage 141 55,909 252 The Long Walk 55 87,561 62 Roadwork 225 93,272 242 Thinner 218 99,272 220 average: 190\n\nTo enable comparison, the number of references in each text was normalized to a standard rate per 100,000 words. We then calculated the average use of references for the total of all novels per author. As indicated in the table, Bachman included an average of 190 unique references per 100,000 words, followed by King with 168, Harris with 114, Straub with 82, and Koontz with 66.\n\nIn the second phase of our analysis, we sought to determine whether there was a significant overlap between the brand names and pop-culture references used by King in his Bachman books and those used in the novels published under his own name. This overlap could potentially reveal King’s “voice” in the Bachman books through his selection of references.4 To test this, we examined how many of the 517 references found in Bachman’s works also appeared in the texts of the other authors.5 All Bachman, King, Koontz, Straub, and Harris books were analyzed using a software library (SpaCy) capable of automatically tagging named entities, including those consisting of multiple tokens (e.g., “I Love Lucy”). Our algorithm is as follows:\n\nFor all books (Bachman, King, Koontz, and Harris books), repeat 100 times:\n\nInitialize a total cultural reference count of 0;\n\nRandomly select a 10,000-token segment in the book;\n\nFor each manually-collected pop-culture reference;\n\nCount the number of SpaCy-extracted named entities whose text matches the manually collected pop-culture reference and add it to the total cultural reference count;\n\nStore the total cultural reference count in a list of cultural reference counts for each book.\n\nOur algorithm produces 100 pop-culture reference counts per book in the corpus – 64,000 counts in total. Differences in the central tendencies of these pop-culture reference counts by author are compared in a pairwise fashion with a Wilcoxon rank-sums test. Wilcoxon rank-sums tests compare pop-culture reference counts in Bachman versus King books, Bachman versus Koontz books, Bachman versus Harris books, and Bachman versus Straub books. In addition, Wilcoxon rank-sums tests compare pop-culture reference counts in King versus Koontz books, King versus Harris books, and King versus Straub books.\n\nThe cultural references extracted from Bachman books were, as could be expected, significantly more common in Bachman segments than in segments by any other author in the corpus. A one-tailed two-sample Wilcoxon rank sums test indicated that the median pop-culture reference count was significantly higher in Bachman segments than in King segments (W = 963,633, p < 0.001) (Table 7). Median pop-culture reference counts in Bachman segments were also found to be significantly higher than in segments by Harris, (W = 274,381, p < 0.001), Koontz (W = 1,011,395, p < 0.001), and Straub (W = 662,439, p < 0.001). That is to be expected, however, since the reference list was compiled on the basis of these very texts.\n\nOf the distractor authors, King segments contained the most references extracted from Bachman books. One-tailed two-sample Wilcoxon rank-sums tests were applied to each pair of distractor authors – King and Straub, King and Harris, King and Koontz (Table 8). Median pop-culture reference counts in King segments were found to be significantly higher than in segments by Straub (W = 1,560,287, p < 0.001), Koontz (W = 2,222,412, p < 0.001), and Harris (W = 639,999, p < 0.001). Table 9 contains a breakdown of pop-culture reference counts by book title.\n\n8. Discussion\n\nThe results of our analysis suggest that computational methods can correctly identify King as the real author of the Bachman books. However, the chosen segment length matters – larger segments lengths seem to produce more extreme, and probably less trustworthy proportions for any given rank and author. The proportions of iterations in which a Bachman segment was predicted to be written by King increased with segment length. Likewise, authors that were more consistently ranked third or fourth, like Dean Koontz and Thomas Harris, had higher proportions of iterations with rank 3 or 4 in longer segment lengths. This trend is consistent with the observation that larger text sizes (5,000 tokens and over) tend to increase the probability that a text’s authorship will be correctly attributed (Eder 2015). The extreme proportions in 10,000-token segments are likely the result of skew by a smaller sample size.\n\nWhile Thinner led to readers outing King as the true author of the Bachman books, Thinner did not have the highest proportion of iterations predicting King as the author of its segments, The Long Walk did, a text written so early in his career that it could be classified under juvenilia. It was Thinner that led to King’s unmasking, not because it was more “King-like” than the previous Bachman books, but because it had a larger readership and was much more widely reviewed. The Regulators, the only novel conceived specifically for the alter ego “Richard Bachman” – an alter ego that had surely taken form in King’s mind by the mid-nineties – scored second-lowest (scoring only fractionally better than The Running Man), which in our opinion is mainly due to the different text-types which take up a substantial portion of the novel: long letters and sections from a screenplay; but it could also be because of King’s conscious effort, as he stated afterwards, to find “a good voice and a valid point of view that were a little different from my own” (King 1996, ix), something he did not do with the previous novels that were only published as Bachman but not written as him. While it has been argued that all Bachman books share certain features (Collings 2011, Strengell 2005), our experiment suggests that stylistically these texts are not noticeably different to his other work, which confirms David L. Hoover’s findings regarding the durability of King’s style: His literary voice was present (and detectable) from very early on and has not been subject to much change throughout his career. We support Van Cranenburgh and Ketzan’s suggestion for further exploration of King/Bachman, to perhaps identify, by computational means, the small difference in voice that King himself hears in his Bachman novels.\n\nInterestingly, Peter Straub consistently has the highest value for rank 2. King and Straub, who were friends and collaborators, have commented on each other’s styles over the years. Straub praised the style of The Shining as the “reverse” of a literary style which “made a virtue of colloquialism and transparency”, an “unprecedentedly direct style” (Straub 1984, 10). Because of this directness and transparency, it has been claimed that King in fact has “no style” (Bradley 1998, 116). The language, King believes, should not pose an interference between the reader and the story, it should be accessible to all, allowing the reader to “get through the barrier of print and into the story without too much effort”, and for that to happen, the “writer’s voice” should be “low enough” (Dewes 1981, 63). Straub’s style is more classic; referred to as “the good prose” by King, “almost always structurally correct”, “not flashy”, and “unobtrusively strong” (King 1982b, 30). King has noted stylistic differences between Straub’s early novels: He called Julia (1975) an “English ghost story”, its diction also being “English – cool, rational, almost disconnected from any kind of emotional base” (King 1982a, 285); If You Could See Me Now (1977) has a “Chandleresque first-person narrative” (King 1982b, 31); and Ghost Story (1979) – Straub’s third novel in a row to feature a ghost – is written in a “Jamesian diction” (King 1982b, 31). The slightly meandering style in Straub’s early works might in part account for Straub emerging from the experiment as the second-most-likely author of the Bachman books. Of relevance here also is that Straub has stated that King’s early novels Salem’s Lot and The Shining heavily influenced him as a writer: “[King’s] aims and ambitions were very close to my own […] [The Shining] was like a roadmap of where to go: [King] armored my ambition” (Straub 1984, 9–10). The differences between their styles did not propose a challenge when they collaborated on The Talisman. As Straub told an interviewer in 1985: “Our styles seemed to melt together. The book has its own sound; it doesn’t sound like me and it doesn’t sound like Steve. […] There were times when I deliberately imitated Steve’s style and there were times when he deliberately, playfully, imitated mine” (D. E. Winter 1985, 64). Straub’s rank 2 in our experiment is an indication that a comparative stylistic analysis of the works of King and Straub, including their two collaborations, would be a fruitful avenue of further research.\n\nThe results of the pop-culture experiments reveal that King’s use of brand names and pop-culture references was part of his style from the first stages of his career, when he wrote the early Bachman books. Rage, in particular, which he began at the age of nineteen, contains a high amount of references: 141 in a 55,909-word text. Rage is not a horror novel, but a suspense novel set in contemporary USA, as is Roadwork, which has an equally high amount of references: 225 in a 93,272-word text. Converted to averages per 100,000 words, these two books each contain over three times as many references as any of the novels by Koontz and Straub. Rage and Roadwork, both non-horror books, show that King’s use of brand names and popular culture as a technique to create a world that is familiar to the reader transcended (and in a sense predated) his views on the poetics of the modern horror genre; the real world is there even when the fantasy element is not.\n\nThe manual counts of references indicate that all four modern horror practitioners used the technique in their novels. This tentatively confirms the claim that it is inherent to the genre. However, King employed it to a much greater extent than Straub and Koontz, which irked some literary critics in the nineteen eighties. A larger-scale study of this kind, with a corpus consisting of more works by more authors, would provide a more accurate picture of the genre’s dependence on realism and familiarity in setting, for instance in comparison with other genres in popular fiction, such as romances, mystery novels, and thrillers. There is a challenge, however, in the degree to which the extraction of the references can be automated. Reliable named entity recognition is a vital first step in automating this kind of work. However, a filtering process is necessary to remove or flag irrelevant entries such as character and place names for it to be feasible for all remaining entries to be manually vetted, since the named entities in a novel easily run into the thousands.\n\n9. Conclusion\n\nStyle is elusive and idiosyncratic. While some reviewers were confident King was the real author of the Bachman books, they remained vague about the similar stylistic features they had discovered in the texts of both authors. In our paper, we showed that an authorship attribution algorithm is able to predict King to be the author of Bachman texts significantly more often than the distractor authors. But because it predicts authorship by randomly sampling large feature sets in thousands of iterations, the algorithm is a black box, which, comparable to the reviewers, only outputs scores and does not supply insights into the similarity in voice.\n\nOur research might be extended by applying machine learning and deep learning authorship attribution techniques. In this paper, we use a similarity-based authorship attribution method instead of machine learning or deep learning methods. Because pre-trained BERT models have demonstrated state-of-the-art accuracy in authorship attribution experiments where each candidate author in the corpus has a large number of words, we expect BERT-based models to achieve better results with our corpus. It remains very much the question, however, whether such gains in performance would eventually scale to lesser-resourced (e.g. historic) literary cultures.\n\nThis paper also explored how pop-culture references may be important for identifying King as the real author of the Bachman books. Brand names and pop-culture references extracted from Bachman books were found to be significantly more common in King books than in books by Koontz, Straub, or Harris. Moreover, Rage, Roadwork and Thinner contained much more references than any of the contemporary novels by Koontz, Straub, and Harris, which again pointed towards King being the author (Cujo being similarly packed with pop-culture, for instance). These findings indicate a promising direction for further exploration of this technique as an inherent feature in modern horror fiction, but also shed some light on the intuition of many readers at the time that the Bachman books had actually been written by the author who, as he suggested in his essay in Adelina, had become a brand name himself.\n\n10. Data Availability\n\nDue to copyright restrictions, the full texts and segments of the King, Straub, Harris, and Koontz books used in our experiments cannot openly be shared. Data extracted from full texts can be found here: https://zenodo.org/doi/10.5281/zenodo.7956048.\n\n11. Software Availability\n\nSoftware can be found here: https://github.com/dorothyh-ms/king_bachman_authorship_verification.\n\n12. Acknowledgements\n\nFunded in part by the FWO research project “Creating Suspense Across Versions: Genetic Narratology and Stephen King’s IT” at the University of Antwerp.\n\n13. Author Contributions\n\nDorothy Modrall Sperling: Conceptualization, Writing – original draft\n\nVincent Neyt: Conceptualization, Writing – original draft, Writing – review & editing\n\nMike Kestemont: Conceptualization, Methodology, Writing – review & editing\n\nNotes\n\nReferences\n\nAltakrori, Malik, Jackie Chi Kit Cheung, and Benjamin C. M. Fung (2021). “The Topic Confusion Task: A Novel Evaluation Scenario for Authorship Attribution”. In: Findings of the Association for Computational Linguistics: EMNLP 2021, 4242–4256. http://doi.org/10.18653/v1/2021.findings-emnlp.359.\n\nAnderson, James Arthur (2017). The Linguistics of Stephen King: Layered Language and Meaning in the Fiction. McFarland.\n\nAnderson, James Arthur (2020). Excavating Stephen King: A Darwinist Hermeneutic Study of the Fiction. Lexington Books.\n\nAnonymous (1984). “No Dieting after ‘Thinner’”. In: The Kingsport Times-News, 4G.\n\nBevendorff, Janek, BERTa Chulvi, Gretel Liz De La Peña Sarracén, Mike Kestemont, Enrique Manjavacas, Ilia Markov, Maximilian Mayerl, Martin Potthast, Francisco Rangel, Paolo Rosso, et al. (2021). “Overview of PAN 2021: Authorship Verification, Profiling Hate Speech Spreaders on Twitter, and Style Change Detection”. In: Experimental IR Meets Multilinguality, Multimodality, and Interaction: 12th International Conference of the CLEF Association, CLEF 2021, Virtual Event, September 21–24, 2021, Proceedings 12. Springer, 419–431. http://doi.org/10.1007/978-3-030-72240-1_66.\n\nBoenninghoff, Benedikt, Steffen Hessler, Dorothea Kolossa, and Robert M. Nickel (2019). “Explainable Authorship Verification in Social Media via Attention-based Similarity Learning”. In: IEEE International Conference on Big Data (IEEE Big Data 2019), Los Angeles, CA, USA, December 9-12, 2019. http://doi.org/10.1109/BigData47090.2019.9005650.\n\nBradley, Linda (1998). “The Sin Eater: Orality, Postliteracy, and the Early Stephen King”. In: Stephen King. Ed. by Harold Bloom. Bloom’s Modern Critical Views. Chelsea House, 95–124.\n\nBurrows, John (2002). “‘Delta’: a Measure of Stylistic Difference and a Guide to Likely Authorship”. In: Literary and Linguistic Computing 17 (3), 267–287. http://doi.org/10.1093/llc/17.3.267.\n\nCollings, Michael R. (1998). “Dean Koontz and Stephen King: Style, Invasion, and an Aesthetics of Horror”. In: Discovering Dean Koontz: Essays on America’s Bestselling Writer of Suspense. Ed. by Bill Munster. Wildside Press, 64–79.\n\nCollings, Michael R. (2011). Stephen King is Richard Bachman. Overlook Connection Press.\n\nDenger, Laurie (1985). “Bachman Novel has Thrills, Chills, Gaps”. In: The Dayton Daily News, 6D.\n\nDewes, Joyce Lynch (1981). “Interview: Stephen King”. In: Mystery Magazine.\n\nEder, Maciej (2015). “Does Size Matter? Authorship Attribution, Small Samples, Big Problem”. In: Digital Scholarship in the Humanities 30 (2), 167–182. http://doi.org/10.1093/llc/fqt066.\n\nEder, Maciej (2018). “Elena Ferrante: a Virtual Author”. In: Drawing Elena Ferrante’s Profile. Ed. by Arjuna Tuzzi and Michele Alberto Cortelazzo, 31–46.\n\nEvert, Stefan, Thomas Proisl, Fotis Jannidis, Isabella Reger, Steffen Pielström, Christof Schöch, and Thorsten Vitt (2017). “Understanding and Explaining Delta Measures for Authorship Attribution”. In: Digital Scholarship in the Humanities 32 (suppl2), ii4–ii16. http://doi.org/10.1093/llc/fqx023.\n\nFrank, Sam (1982). “Running Man Beats the Odds”. In: The San Francisco Examiner, 6.\n\nGanley, W. Paul (1985). “Thinner, by Richard Bachman”. In: Fantasy Mongers 13.\n\nGraham, Mark (Dec. 1984). “Fit for a King: This Thriller Raises an Authorship Question”. In: The Rocky Mountain News, 26–N.\n\nGrooms, Roger (Nov. 1984). “Combined Novel has King’s Flavor”. In: Palladium-Item, E5.\n\nHoover, David L. (2021). Modes of Composition and the Durability of Style in Literature. Routledge.\n\nJuola, Patrick (2013a). “How a Computer Program Helped Show J.K. Rowling Write A Cuckoo’s Calling”. In: Scientific American. https://www.scientificamerican.com/article/how-a-computer-program-helped-show-jk-rowling-write-a-cuckoos-calling/ (visited on 11/29/2023).\n\nJuola, Patrick (July 2013b). Rowling and ‘Galbraith’: an Authorial Analysis. Language Log. UPenn. https://languagelog.ldc.upenn.edu/nll/?p=5315 (visited on 11/29/2023).\n\nJuola, Patrick (2015). “The Rowling Case: A Proposed Standard Analytic Protocol for Authorship Questions”. In: Digital Scholarship in the Humanities 30 (suppl1), i100–i113. http://doi.org/10.1093/llc/fqv040.\n\nKing, Stephen (1982a). Danse Macabre. Futura.\n\nKing, Stephen (1982b). “Peter Straub: An Informal Appreciation”. In: Program Book, World Fantasy Convention ’82. Ed. by Kennedy Poyser. World Fantasy Convention.\n\nKing, Stephen (1985). The Bachman Books. New American Library.\n\nKing, Stephen (1996). “The Importance of Being Bachman”. In: The Bachman Books. Plume.\n\nKoppel, Moshe, Jonathan Schler, and Shlomo Argamon (2009). “Computational Methods in Authorship Attribution”. In: Journal of the American Society for Information Science and Technology 60 (1), 9–26. http://doi.org/10.1002/asi.20961.\n\nKoppel, Moshe, Jonathan Schler, and Shlomo Argamon (2011). “Authorship Attribution in the Wild”. In: Language Resources and Evaluation 45 (1), 83–94. http://doi.org/10.1007/s10579-009-9111-2.\n\nKoppel, Moshe, Jonathan Schler, and Elisheva Bonchek-Dokow (2007). “Measuring Differentiability: Unmasking Pseudonymous Authors”. In: Journal of Machine Learning Research 8 (45), 1261–1276. http://jmlr.org/papers/v8/koppel07a.html (visited on 11/29/2023).\n\nKoppel, Moshe and Yaron Winter (2014a). “Determining if Two Documents Are Written by the Same Author”. In: Journal of the Association for Information Science and Technology 65 (1), 178–187. http://doi.org/10.1002/asi.22954.\n\nKoppel, Moshe and Yaron Winter (2014b). “Determining if Two Documents Are Written by the Same Author”. In: Journal of the Association for Information Science and Technology 65 (1), 178–187. http://doi.org/10.1002/asi.22954.\n\nLehmann-Haupt (Nov. 1984). “An Ungainly Offspring”. In: The Sunday Herald-Times, C–15.\n\nLevin, Bob (Dec. 1984). “Novel Cursed by Cliches, Thin Characterizations”. In: The Atlanta Constitution, 9–J.\n\nO’Neil, Ann W. (Dec. 1984). “A Horrifying Weight-Loss Plan”. In: The Philadelphia Daily News, 51.\n\nPotha, Nektaria and Efstathios Stamatatos (2014). “A Profile-Based Method for Authorship Verification”. In: Hellenic Conference on Artificial Intelligence. Springer, Cham, 313–326. http://doi.org/10.1007/978-3-319-07064-3_25.\n\nRichards, Brian (1987). “Type/Token Ratios: What Do They Really Tell Us?” In: Journal of Child Language 14 (2), 201–209. http://doi.org/10.1017/S0305000900012885.\n\nSlotek, Jim (June 1981). “Roadwork, by Richard Bachman”. In: The Ottowa Citizen, 10.\n\nSmith, Joah H (Feb. 1985). “Pseudonym Kept Five King Novels a Mystery”. In: The Bangor Daily News, 1.\n\nStrachan, Don (Mar. 1981). “Soft Cover”. In: The Los Angeles Times, 8.\n\nStraub, Peter (1984). “Meeting Stevie”. In: Fear Itself: The Horror Fiction of Stephen King. Ed. by Tim Underwood and Chuck Miller. New American Library.\n\nStrengell, Heidi (2005). Dissecting Stephen King: from the Gothic to literary naturalism. University of Wisconsin Press.\n\nThomases, Martha and John Robert Tebbel (Jan. 1981). “Interview with Stephen King”. In: High Times Magazine.\n\nTirvengadum, Vina (1996). “Linguistic Fingerprints and Literary Fraud”. In: Digital Studies/Le Champ Numérique 2 (1). http://doi.org/10.16995/dscn.187.\n\nTuzzi, Arjuna and Michele Alberto Cortelazzo (2018). “It Takes Many Hands to Draw Elena Ferrante’s Profile”. In: Drawing Elena Ferrante’s Profile. Ed. by Arjuna Tuzzi and Michele Alberto Cortelazzo, 9–30.\n\nTyo, Jacob, Bhuwan Dhingra, and Zachary C. Lipton (2022). “On the State of the Art in Authorship Attribution and Authorship Verification”. In: arXiv preprint. http://doi.org/10.48550/arXiv.2209.06869.\n\nUnderwood, Tim and Chuck Miller, eds. (1989). Bare Bones: Conversations on Terror with Stephen King. Warner Books.\n\nVan Cranenburgh, Andreas and Erik Ketzan (2021). “Stylometric Literariness Classification: the Case of Stephen King”. In: Proceedings of LaTeCH-CLfL 2021. https://aclanthology.org/2021.latechclfl-1.21.pdf (visited on 11/29/2023).\n\nWilliams, Nick B (Nov. 1984). “Thinner”. In: The Los Angeles Times Book Review, 11.\n\nWinter, Douglas E. (Feb. 1985). “Stephen King, Peter Straub, and the Quest for the Talisman”. In: Twilight Zone Magazine."
    }
}