{
    "id": "dbpedia_8298_3",
    "rank": 5,
    "data": {
        "url": "https://ulethelectro.wordpress.com/tag/live-coding/",
        "read_more_link": "",
        "language": "en",
        "title": "Integra Contemporary & Electroacoustics at the University of Lethbridge",
        "top_image": "https://secure.gravatar.com/blavatar/01cfb4fc311d26eeca28fe4c6667c44f40cb0815568c8a71430c22fa5ed6e2e8?s=200&ts=1724010169",
        "meta_img": "https://secure.gravatar.com/blavatar/01cfb4fc311d26eeca28fe4c6667c44f40cb0815568c8a71430c22fa5ed6e2e8?s=200&ts=1724010169",
        "images": [
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://ulethelectro.wordpress.com/wp-content/uploads/2021/04/icee_13april_01.jpg?w=840",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://ulethelectro.wordpress.com/wp-content/uploads/2020/12/code_ritual_01.png?w=1200",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://ulethelectro.wordpress.com/wp-content/uploads/2020/12/iceensemble_10december_01.jpg?w=1200",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://1.gravatar.com/avatar/dbb7d88e8751ecefa37b2ad88cc60913186c630081f6365f761578f67837330f?s=49&d=identicon&r=G",
            "https://secure.gravatar.com/blavatar/01cfb4fc311d26eeca28fe4c6667c44f40cb0815568c8a71430c22fa5ed6e2e8?s=50&d=https%3A%2F%2Fs2.wp.com%2Fi%2Flogo%2Fwpcom-gray-white.png",
            "https://secure.gravatar.com/blavatar/01cfb4fc311d26eeca28fe4c6667c44f40cb0815568c8a71430c22fa5ed6e2e8?s=50&d=https%3A%2F%2Fs2.wp.com%2Fi%2Flogo%2Fwpcom-gray-white.png",
            "https://pixel.wp.com/b.gif?v=noscript"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Author dndrew"
        ],
        "publish_date": "2022-04-22T22:36:16+00:00",
        "summary": "",
        "meta_description": "Posts about live coding written by dndrew",
        "meta_lang": "en",
        "meta_favicon": "https://secure.gravatar.com/blavatar/01cfb4fc311d26eeca28fe4c6667c44f40cb0815568c8a71430c22fa5ed6e2e8?s=32",
        "meta_site_name": "ICE ensemble | Integra Contemporary & Electroacoustics at the University of Lethbridge",
        "canonical_link": "https://ulethelectro.wordpress.com/tag/live-coding/",
        "text": "The Code Ritual\n\nThursday, 10 December, 2020, 7:30PM UTC-7 (MST)\n\nOn Twitch twitch.tv/ulethelectro\n\nIn Hubs hub.link/2eycTjz\n\nMake Sound! everyone Rocket Man green ensemble Roulette collaborative code Creation blue ensemble The Code Ritual timed code\n\nRocket Man\n\nRocket man is a piece in 3 parts. The first part is the rocket readying for take-off and initiating count down. It is a sequential and rhythmic section based around an audio sound bite that starts off the piece. As the A section continues the complexity of the rhythm increases as the rocket takes off into space. The B section is lyrical, with the main melody based on a Hungarian minor scale. The rocket has reached orbit and is free falling constantly in space. Finally, the A section returns as before. However, as the end of the piece comes closer, the speed picks up and there is an increase in loudness. Slowly the rhythm devolves. The rocket is slowly failing and falling out of orbit. The piece ends suddenly, and the rhythm slows down until no sound is left, the rocket has failed and is now floating in the vacuum of space.\n\nRoulette\n\nIn this performance, the ensemble is split into two teams. Each performer adds their name to the queue on their teams coding box and when it’s their turn they have complete control of the sound! The goal is to create a collaborative coding experience where team mates play off of each other’s strengths while developing a composite musical voice.\n\nCreation\n\nCreation is a meditative piece based on the Cree Creation story, beginning with a heartbeat. The sound of the fire emerges, and the improvisation begins. There is a curious unrest midway with a faster tempo, more frantic melodic movement, and increased tension before the inevitable return to familiarity. The piece settles back to the heartbeat to conclude. Throughout the piece, the sound of rain accompanies the narration.\n\nThe Code Ritual\n\nThe Code Ritual requires ensemble members to work as a unit, creating a cohesive musical structure. While all members are coding at the same time, rarely is the entire ensemble simultaneously producing sound. Instead, The Code Ritual results in variations of quartets, trios, and duos. Through a system of visual signals created by Punctual (a programming language for generative music and visuals), members’ sounds are cued in during a period of 30 to 60 seconds – each person has 30 to 60 seconds to alter or add to the fluid musical texture. The trick here is to try to write code that can be interpreted and built upon by other members, who are standing by to take over the musical journey.\n\nThe band\n\nEvan Alexander\n\nAldrin Azucena\n\nChris Bernhardt\n\nCameron Hughes\n\nShay Hunter\n\nElliot Middleton\n\nLoryn Plante\n\nNathan Stewart\n\nPatrick Davis, Hubs support\n\nD. Andrew Stewart, director\n\nAcknowledgements\n\nIntegra Contemporary & Electroacoustics wants to acknowledge the invaluable support of the following people and entities, whose visual and musical networking ingenuity and expertise have found a home with the ICE ensemble.\n\nEstuary: David Ogborn and the Estuary development team at the Networked Imagination Laboratory (NIL) at McMaster University.\n\nTidal Cycles: Thank you to Alex McLean, and numerous active developers, for creating, building and maintaining this algorithmic composition environment.\n\nGraphic design by coder, sound artist and improviser Michał Seta.\n\nBy Jordan Berg\n\nLast semester was my first experience with live coding and one of my most profound conclusions at the time was that ‘going with the flow’ when live coding produced music that I felt was more successful than when I had tried to strictly compose material beforehand. This semester I found the same approach created more successful collaborations when improvising with the group. If I let my feelings, ideas and previously chosen sounds dominate my thinking, I ended up fighting with the unpredictability of the other sounds and choices that were made by the other performers. If I held nothing sacred in my choices and ideas I had made beforehand, remained very open minded with the direction and sounds made by the other players, I found that the overall experience was more enjoyable and always resulted in music that was original and interesting.\n\nTimbre or sound choice is one of the biggest potential issues when improvising with others in a live coding environment. When improvising with non-electronic instrumentalists it is easier to know in advance how the sound from your colleagues will blend with your own instrument/sound. When live coding, the sounds that other members of your group make can be totally unpredictable. It could be the sound of an acoustic instrument, a voice, an electronic noise, animal sound or really anything else one can think of (and beyond). When you are accustomed to traditional composition or improvisation this can be frustrating at first because your ideas for the piece and what you have composed in advance might not pair successfully with the vision and sounds of the other members. Another potentially frustrating part of live coding with a group is that you might completely disagree initially that the sounds that your colleagues make are suitable for the particular performance. One player might be taking a more serious approach, for example playing a percussive rhythm, a melody with a recognizable instrument, or a subtle sonic atmosphere, while another player might take a comedic approach (this often happens). What I found to be a surprising result of having an open mind is that when the group engaged in a discussion about our choices, sometimes it seemed that everyone else unanimously enjoyed something I thought wasn’t working. I was happy that I had kept an open mind because it made me realize that maybe the only reason that I felt that something didn’t fit was perhaps that it simply didn’t work with my idea. Maybe my idea didn’t really work in the first place. It also made me think that when I sometimes felt displeased with an abrasive sound played loudly and/or repetitively maybe others sometimes felt that same way about a sound that I was proud of. I discovered that I should definitely communicate my opinions, but that I should remain very open minded, play my sounds in a way that blend in with the others and not carry overtop all the time, and then change things up from time to time because no matter how much I loved what I had done, it would become tiring to others inevitably. Even with the seriousness vs. comedic dichotomy and the fact that there might be sounds in the mix you don’t fully appreciate, I find that live coding is very forgiving if you let it be. If you hold things you’ve come up with as too precious and you allow your idea for the piece to dominate your thinking, you will end up conflicting with other performers’ elements and feeling frustrated. If you communicate with others in a constructive and positive way and you let things fall as they may without getting precious about anything in particular and allowing for strangeness that you may not love initially, the music that results ends up sounding good even if it does have strange, surreal, or out of place sounds. I feel that communication is very necessary because you can discuss the vision for the piece and talk about strategies. It is also necessary to openly discuss relative volumes/levels because often a player doesn’t realize how their sound or performance is dominating due to their focus on it. I found the experience overall to be rewarding and will be of value every time I perform with another musician whether live coding or otherwise.\n\nBy Matthew B. Pohl\n\nImprovisatory performance has long been part of musical interpretation since the days of fugue and counterpoint, with virtuosic musicians such as Mozart and Beethoven serving as the earliest such examples in the Western art tradition. The twelve-bar blues progression and its number of variants serve as a more popular form of music containing improvisational language and techniques. Both of these examples follow the traditional idea of interacting directly with a sound source, using a number of control mechanisms – force, speed, intonation, subtlety – to invoke a desired sound from an instrument.\n\nFor example, if a drummer wanted the kick drum to make sound, they would force their foot into the pedal, which results in the kick drum being struck by a mallet with the help of some mechanics to transfer the force of motion. This somewhat complex process can normally take place in less than a quarter of a second. In the case of the ICE Ensemble and its live coding dynamic, the process changes and so do the variables: to produce a kick drum sound, one must effectively and efficiently type the name of the low-level sound location, its selection number, a gain value, and a pan value, in syntax, within an IDE containing TidalCycles. For a proficient coder/typist, this process can take anywhere from ten to thirty seconds, a far cry from the near instantaneous motion of interacting with a kick drum pedal.\n\nThe ICE Ensemble explored a very interesting perspective on performance this semester: live coding for video games. There is an exceptional range of spontaneity involved in video games, as the player alone is in control of the flow of the game and, in the case of live music creation for the game, the flow of the performance. The challenge was to explore limits when live coding for games, and what we can do to overcome this.\n\nThe first challenge is, with modern technology, exceptionally simple: overcoming the delay from slow typist speeds with copy/paste. To implement complex lines of code quickly, scenes used in performance would have to be developed and practiced beforehand by musicians and gaming performers in tandem. This cuts down on both the delayed response, but since the gamer also has practice beforehand it also cuts down on the spontaneity of live gameplay.\n\nThe second challenge becomes how one incorporates live coding into gameplay without removing its spontaneity – or at the very least the sense of spontaneity. This challenge is much more difficult to answer, partially because any observation of an audience’s perception of spontaneity would have resided in the final concert that was cancelled due to extraneous circumstances. However, one should reflect on the core idea that an interpretation of music and its related elements will vary from person to person, and that a non-performer will likely maintain a different perception than a performer concerning what is spontaneous, what is planned, and what is rehearsed.\n\nLeading up to the final concert, one of the practicing gamers commented a number of times that her perception of the in-game music changed while practicing with the ensemble, and that it was more enveloping and interactive to have it created while the game was being played by the individual as opposed to being as a computer-interpreted result of that player’s actions, and that gaming at home after the practices “just isn’t the same”. Perhaps that would be the general consensus among an audience with similar backgrounds to this individual, while taking in such a unique subtype of music creation in an exceptionally unique way. Perhaps in this case, then, spontaneity is not about being unaware of what will happen, but about the anticipation of what could happen. Remember that first time you listened to Beethoven’s 9th Symphony as a critical music listener?\n\nBy Cameron Sperling\n\nSo, you want to learn how to use Tidal? Well then, first things first, let’s start with the basics. Creating a strong foundation on which to build your understanding is vital. In this tutorial we will cover two important topics to get you started. How to create a sound, and how to modify your sound.\n\nThe first thing to do is decide which synth connection(s) you want to work on. If you’re in a group, you should number yourselves off. For these examples I’m just going to use connection one. This is inputted as d1. Connection two would be d2, connection three, d3, and so forth. Once that’s done, you need to choose a sound file and type it into the line of code. For these examples I’m going to use “bleep”. You can choose whichever file you want. If you’re unsure as to which files you can use, check the Dirt-Samples folder which comes with SuperDirt. Once you’ve decided, you type the following beginning with d1… (do not include “Eg. 1:”).\n\nEg. 1: d1 $ s “bleep”\n\nLet’s break down what all that gibberish – that strange code – means. As previously mentioned, d1 tells the program to use channel 1. $ indicates to the program what level of priority this piece of the code has. The s tells the program to play a sound, and bleep is the name of the sound file being played (see “sound bank” below). Note that it needs to be inputted inside quotation marks. Finally, all that’s left is to actually run (evaluation or execute) the program. You can do so by pressing the shift and enter keys simultaneously.\n\nSo, you got Tidal to play for you? That’s great! Now it’s time to move on to the next step, changing and modifying your sound. The first thing that we need to do is clarify some terminology. In the last section, I used the term “sound file” for simplicity’s sake, but that wasn’t really accurate. It would’ve been more accurate to have used the term “sound bank”. You see, the name that was inputted in my example was “bleep”. This isn’t actually the name of a single sound file, but a collection of sound files that are numbered off starting from 0. (Not inputting any number, as was done in Eg. 1, is the same as inputting 0) There are two ways of changing which file in the soundbank to use, a basic method (Eg. 2) and an Advanced method (Eg.3)\n\nEg. 2a: d1 $ s “bleep:0” Eg. 2b: d1 $ s “bleep:1” Eg. 3a: d1 $ n “0” s # “bleep” Eg. 3b: d1 $ n “1” s # “bleep”\n\nChanging sound files isn’t the only way that you can add variety. You can also modify the sounds that you’re using too. Tidal has many different functions, but to keep this from becoming too long, I’m just going to explain three, gain, crush, and up. Gain is the simplest of these, it just controls the volume level. If the value is less than 1, the sound is quieter. If the value is greater than 1, the sound is louder. Generally speaking, going about 1 is dangerous and make lead to digital distortion (levels to hot).\n\nEg. 4a: d1 $ s “bleep” # gain 0.8 Eg. 4b: d1 $ s “bleep” # gain 1.2\n\nThe crush function crushes the bit depth, creating a more crunchy sound. The smaller the value, the more the sound gets distorted. The value can’t go smaller than 1.0, however.\n\nEg. 5: d1 $ s “bleep” # crush 5\n\nFinally, up shifts the the pitch of the sound file. The value provided equals the number of semitones up (or down if you use a negative value) the sound file is shifted. It should be noted, the pitch and speed of a sound file are connected, and so the higher you shift it, the faster/shorter the sound will become.\n\nEg. 6: d1 $ s “bleep” # up 5\n\nYou may have noticed that in the most recent examples, a # was used. Similar to $, this symbol is used to indicate a level of priority to the program.\n\nAnd there you have it! Tidal is a complex program, with lots to learn about how to use it, but I hope that you found this tutorial useful for getting you started. Thank you for your time."
    }
}