{
    "id": "dbpedia_3434_1",
    "rank": 35,
    "data": {
        "url": "https://meetingorganizer.copernicus.org/EGU24/session/50604",
        "read_more_link": "",
        "language": "en",
        "title": "Session GI2.4",
        "top_image": "https://www.egu24.eu/favicon_egu_16x16_.ico",
        "meta_img": "https://www.egu24.eu/favicon_egu_16x16_.ico",
        "images": [
            "https://cdn.copernicus.org/apps/common/images/share_icons/mendeley.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/reddit.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/twitter.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/facebook.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/linkedin.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/mendeley.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/reddit.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/twitter.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/facebook.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/linkedin.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/mendeley.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/reddit.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/twitter.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/facebook.png",
            "https://cdn.copernicus.org/apps/common/images/share_icons/linkedin.png",
            "https://contentmanager.copernicus.org/2242971/ssl",
            "https://contentmanager.copernicus.org/2242971/ssl",
            "https://contentmanager.copernicus.org/2242972/ssl",
            "https://contentmanager.copernicus.org/2242970/839/ssl"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "https://www.egu24.eu/favicon_egu_16x16_.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Recently, there has been a substantial surge in the availability of web services offering access to geological, geochemical, crystallographic, and mineralogical data. Embracing this data-rich environment, mineralogy.rocks emerges as a pioneering outreach project, poised to harness the vast potential embedded in this information reservoir. Focused on extracting valuable insights, the project seeks to leverage the wealth of open-access data and fosters knowledge dissemination by openly sharing the underlying code of its processes under MIT, available on https://github.com/orgs/mineralogy-rocks.\n\nMineralogy.rocks' core developers recently tackled the challenge of establishing relationships between minerals and their associated entities such as synonyms, varieties, and parental groups. Often, these related entries lack distinct properties; synonyms may only have a name and historical context, chemical varieties might differ only in impurity presence, and structural variations may diverge solely in crystal system. Database-wise, all other properties remain identical to the parent mineral.\n\nIn response, we introduce the concept of Data Inheritance, drawing parallels with Object-Oriented Programming's class inheritance mechanism. This concept permits multiple base classes, enabling a derived class to override methods of its base class or classes, thus allowing objects to encompass diverse and arbitrary data. Applied to a data warehouse dimension, this concept facilitates the retrieval of the actual properties of a related entry defined in the database and the inherited properties not defined for this specific entry but established for the parental mineral.\n\nTo implement this, we calculate the inheritance chain, representing the chain of relations from the bottom-most child entry to the top-most parental mineral, such as in the case of agate—chalcedony—quartz. The chain, coupled with specific code rules and patterns, enables the retrieval of properties for each entry in the chain, effectively determining which properties are pertinent to the child species. This systematic approach adds precision and clarity to the extraction and utilization of mineralogical data in the context of inherited properties.\n\nmineralogy.rocks is dedicated to open science, prioritizing innovation, quality, and public impact in mineralogical research. Our commitment is evident through actions that swiftly share research outcomes and metadata, fostering accessibility and reuse. Embracing open science principles, we contribute to advancing the field with transparent and collaborative practices.\n\nThis project, No. 3007/01/01, has received funding from the European Union’s Horizon 2020 research and innovation Programme based on a grant agreement under the Marie Skłodowska-Curie scheme No. 945478 and was supported by the Slovak Research and Development Agency (contracts APVV-19-0065 and APVV-22-0092).\n\nHow to cite: Gavryliv, L., Ponomar, V., and Putiš, M.: Data inheritance concept in mineralogical warehouse, EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-2695, https://doi.org/10.5194/egusphere-egu24-2695, 2024.\n\nThe ground-source heat pump (GSHP) is an efficient thermal exchange system that utilizes natural environmental heat for heating and cooling. Heat exchange efficiency depends not only on factors such as pipe material and diameter but also on groundwater's flow field and soil's thermal parameters. This study aims to estimate hydraulic and geothermal parameters by utilizing convolutional encoder-decoder architecture neural networks and hydraulic tomography, a data collection strategy. The proposed method is named THT-NN. To examine the capability of the THT-NN on parameter estimation, we developed numerical experiments to test THT-NN. Further, to produce the training and validation data pairs, we create a two-dimensional heterogeneous groundwater and heat transport model by TOUGH2 with constant injection patterns and 10000+ realizations of parameter fields. The groundwater heads and temperature collected from the monitoring well groups are used to develop two channels of the input layers, and four parameters' fields (hydraulic conductivity, porosity, heat conductivity, and specific heat) are used to develop four channels of the output layers. Subsequently, the estimated parameters results are examined by R2 and root mean squared error. The performance of the proposed THT-NN is discussed in this study.\n\nHow to cite: Liang, C.-W. and Tsai, J.-P.: Estimation of Hydraulic and Thermal Parameters Using Convolutional Neural Network and Hydraulic Tomography, EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-7272, https://doi.org/10.5194/egusphere-egu24-7272, 2024.\n\nWe are sorry, but presentations are only available for users who registered for the conference. Thank you.\n\nSatellite monitoring plays a significant role in monitoring nitrogen dioxide (NO2) concentrations in the atmospheric column, but it is often affected by clouds and ice and snow surface. This leads to much missing data. Deep learning with Partial Convolutional Neural Network (PCNN) is adept at handling incomplete or missing data in image processing by focusing only on the known pixels during convolution, thus making approach ideal for tasks such as image restoration, denoising, and enhancing resolution.\n\nIt is therefore important to reduce such data gaps.. Under cloudy skies, ground-level NO2 often tends to be higher. Clouds are typically associated with low pressure and increased wind speeds in mid-latitudes, leading to enhanced dispersion of pollutant. However, low cloud often occurs during periods of high pressure when boundary layer heights are lower and air pollutants are trapped closer to the ground. Additionally, clouds intensify the Surface Sensible Heat Flux, contributing to the urban heat island effect and potentially increasing NO2 concentrations. On the other hand, clouds decrease Surface Net Solar Radiation, which might mitigate NO2 photolysis.\n\nIt is therefore likely that NO2 concentrations close to the surface during cloudy conditions will not necessarily be well represented by satellite derived NO2 columns in clear sky conditions.. It becomes necessary to recalibrate satellite-derived data to reflect actual meteorological conditions. In this work we separate out ground-level data from an urban network across Paris, France, into two categories: those with contemporaneous TROPOMI and those without. Each category is then analyzed with the weather conditions at that time. This analysis helps estimate the variance in NO2 concentrations due to cloud presence. Subsequently, the determined percentage difference, indicative of the cloud cover's impact, is applied to the NO2 estimates provided by the PCNN model.\n\nThis adjustment not only strengthens the data's coverage but also its reliability, reducing the biases in the original satellite data resulting from clear sky viewing only and are therefore a closer representation of the urban atmospheric pollution. This approach, combining technical precision with contextual sensitivity, improves the use of satellite data as a tool for understanding and interpreting urban pollution.\n\nHow to cite: ma, W., Coe, H., Topping, D., Zheng, Z., Song, C., and Zhang, H.: Use of deep learning and a partial convolutional neural network to gap-fill a long term time series of NO2 columns from satellite impacted by cloud, EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-8843, https://doi.org/10.5194/egusphere-egu24-8843, 2024.\n\nDroughts are expected to increase in both frequency and severity, exacerbated by rising global temperatures associated with climate change. These trends pose serious threats to the agricultural sector, directly impacting food production and security. Moreover, increasing drought incidence increases the risks associated with agricultural and forestry disasters, including reduced crop yields, soil degradation, and wildfires. Given these challenges, the ability to accurately monitor and predict drought conditions is critical. Effective drought forecasting plays an important role in establishing agricultural and water management policies and enabling better handling of the impacts of these events. This will enable timely and informed decisions to ensure that appropriate measures are in place to mitigate the adverse impacts of drought on ecosystems, food supplies and overall environmental health. The development and improvement of tools for drought time series forecasting is therefore essential to ongoing efforts to adapt to and mitigate the impacts of climate change. This study introduces a model designed to predict Vegetation Health Index (VHI) time series data using the Predictive Recurrent Neural Network Version 2 (PredRNN-V2). The VHI, which effectively integrates land surface temperature and vegetation status, has been widely used in drought assessment. The study focuses on South Korea, utilizing long-term weekly VHI data from NOAA for short-term prediction. The PredRNN-V2 model utilizes a network of interconnected spatio-temporal LSTM cells to learn and predict the temporal and spatial characteristics of time series images. This architecture can properly handle the complex spatial and temporal dynamics inherent in satellite-based drought data and can therefore be an effective tool for drought prediction.\n\nThis research was supported by Basic Science Research Program through the National Research Foundation of Korea(NRF) funded by the Ministry of Education(NRF-2022R1I1A1A01073185)\n\nHow to cite: Lee, S.-J. and Lee, Y.: PredRNNv2-based drought prediction using Vegetation Health Index (VHI), EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-14437, https://doi.org/10.5194/egusphere-egu24-14437, 2024.\n\nVariations in earthquake frequency and magnitude across global subduction zones are thought to be influenced by a combination of geological and geophysical factors, such as the age and dip angle of the subducting plate. Despite numerous previous qualitative studies on the correlation between seismic behaviour and subduction zone characteristics, the parameters and mechanisms governing seismicity at subduction zones remain elusive. Our limited historical record of earthquakes further complicates this understanding. Finding underlying general correlations and mechanisms that are valid across different subduction trenches is critical for assessing seismic behaviour and earthquake hazards along subduction plate boundaries which are poorly monitored or have been seismically quiet during the short instrumental record.\n\nThis study aims to bridge the knowledge gaps highlighted above by applying specific unsupervised machine learning techniques to publicly available data on subduction zone parameters and earthquake catalogues. This approach is particularly adept at uncovering hidden correlations in complex, high-dimensional datasets, which might not be discernible through traditional analysis methods. We suggest that seismic behaviour may be describable as a non-linear combination of subduction margin parameters and present a quantitative tool for comparing seismic behaviours across different margins. This may help assess seismic hazards in regions with scant seismic records or that have been historically quiescent. By doing so, we hope to contribute significantly to the predictive modelling of earthquake occurrences and their potential impacts globally.\n\nHow to cite: Locher, V., Bell, R., John, C., and Salah, P.: Toward Determining the Controls on Subduction Zone Seismic Behaviour with Machine Learning, EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-18515, https://doi.org/10.5194/egusphere-egu24-18515, 2024.\n\nResearch Data Management (RDM) in Natural Science establishes a structured foundation for organizing and preserving scientific data. Effective management and access to these diverse data sources are crucial for supporting domain scientists in future knowledge discovery. Scientific publications, a primary data source often presented in Portable Document Format (PDF), serve as a rich source of information, encompassing text, tables, figures, and metadata. These components present information individually or collectively, offering the potential to explore exciting research directions. However, to fully address these aspects, it is necessary to be able to perform data acquisition from these publications, focusing on these data components, and conducting respective information extraction. Furthermore, modeling the extracted information into a Heterogeneous Information Network of publications enhances accessibility, collaboration, and information harvesting within the natural sciences domain.\n\nWe developed a comprehensive framework ensuring user accessibility and widespread applicability, which is capable of modeling diverse information from marine science publications into a Heterogeneous Information Network. The framework comprises three modules: Data Acquisition, Information Extraction, and Information Modeling. The Data Acquisition (DA) module extracts various data components from the relevant publications and transforms them into machine-readable formats. The Information Extraction (IE) module includes two sub-modules: Named Entity Recognition (NER) modules trained on marine science annotated text, capable of extracting eight different types of entities from plain text; and an information parser module responsible for extracting quantitative information from tabular data. It initially detects and then extracts scientific measurements, relevant spatial information, and other available characteristics. Finally, the information modeling module exhibits the extracted information from data components and performs information linking. Consequently, the information is structured into a Heterogeneous Information Network (HIN) of scientific publications, ensuring effective information delivery and providing diverse information to domain experts while supporting the Research Data Management initiative.\n\nHow to cite: Suryani, M. A., Burwicz-Galerne, E., Wallmann, K., and Renz, M.: Data Bridges: Modeling Marine Science Information to Heterogeneous Information Network for Research Data Management, EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-19139, https://doi.org/10.5194/egusphere-egu24-19139, 2024.\n\nThe Mesozoic in Chengdao-Zhuanghai area is affected by complex tectonic evolution, diverse sedimentary types and lithology, and the reservoir heterogeneity is extremely strong, and the prediction of reservoir quality is difficult, and the accurate identification and division of lithofacies types plays a crucial role in the classification and evaluation of reservoirs. In the well section with relatively few corings, four logging curves sensitive to diagenesis, GR, AC, DEN, and RD were selected as the basis for diagenetic facies division, and the diagenetic facies division was carried out by the method of machine Xi. The traditional machine Xi is divided into two Xi: supervised Xi and unsupervised, in which supervised Xi requires a large number of Xi samples to ensure its accuracy, and unsupervised Xi does not need to learn Xi samples, but the classification results may not be the expected classification type. Combined with the characteristics of strong heterogeneity, relatively few coring sections and limited results of unsupervised Xi in this area, the method of unsupervised Xi with single factor constraint was considered to identify and divide the logging facies of the three formations in the Chengdao-Zhuhai area. Combined with the geological data such as core, cast thin section identification, logging data, etc., the calibration of logging facies and diagenetic facies is realized, so as to complete the identification and division of regional diagenetic facies. Finally, the accuracy of the Xi method is verified by comparing the thin section identification results, which provides a basis for the identification of reservoir diagenetic facies in the lack of coring well sections.\n\nKeywords: clastic rocks; Chengdao-Zhuanghai area; The Mesozoic;Diagenetic facies logging identification; Univariate constrained unsupervised learning\n\nHow to cite: meng, Y. and zhang, L.: Identification and Application of Detrital Diagenetic Facies Logging Based on Unsupervised Xi Technology: A Case Study of the Mesozoic in Chengdao-Zhuanghai Area, EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-77, https://doi.org/10.5194/egusphere-egu24-77, 2024.\n\nMineral Prospectivity Mapping (MPM) is a crucial process in mineral exploration, traditionally hampered by subjective interpretations and labor-intensive methods leading to unreliable outcomes. Predominantly focused on Independent and Identically Distributed (IID) scenarios, traditional research in MPM often struggles to generalize in Out of Distribution (OOD) scenarios, which are vital for accurate mineral exploration. Addressing these challenges, we introduce an innovative automated conformalized causal learning system for MPM. This system integrates a comprehensive data preprocessing pipeline that includes interpolation, feature filtering, data augmentation, and splitting, effectively managing diverse and imbalanced geological datasets. A central component of the system is Bayesian Optimization, autonomously selecting optimal machine learning models and hyperparameters to significantly enhance performance over non-automated methods. The system's most significant innovation is the incorporation of conformalized causal learning, exceptionally effective in handling OOD data scenarios. This methodology introduces an 'uncertainty region' in predictive models through conformal prediction, substantially reducing misclassification risks, while causal learning elucidates complex cause-and-effect relationships among geological features, essential for precise mineral deposit predictions. We evaluated the performance of our approach on six datasets, where the Area Under the Receiver Operating Characteristic (AUC ROC) of our automated optimized system surpassed the baseline method by an overall 17.84%, and the false positive rate (FPR) was reduced by an overall 84.31%. This development marks a significant advancement in MPM, enhancing accuracy and efficiency in mineral resource exploration and setting a new benchmark in the field. Released as an open-source platform, it offers the geological community a highly efficient, adaptable, and user-friendly tool, poised to revolutionize mineral prospectivity mapping in varied real-world scenarios.\n\nHow to cite: Jaya, E. J., Wang, X., Zhou, C., and Ye, N.: An Automated Conformalized Causal Learning System for Enhanced Mineral Prospectivity Mapping, EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-8771, https://doi.org/10.5194/egusphere-egu24-8771, 2024.\n\nWe are sorry, but presentations are only available for users who registered for the conference. Thank you.\n\nIn our study, we present a segmented-based, rule-driven classification of igneous rocks through the analysis of thin section photomicrographs, representing a significant advancement over traditional petrographic methods. This deep learning-based approach is especially innovative in its recognition that the naming of rocks is intrinsically linked to the proportion of minerals they contain, a vital aspect frequently overlooked in conventional classification techniques. By focusing on accurately quantifying these mineral proportions, our method effectively addresses the subjectivity and observer variability inherent in traditional petrography. Utilizing semantic image segmentation on 963 petrographic thin section photomicrographs, we have successfully identified 29 distinct minerals and classified 15 types of igneous rocks. This showcases the precision and scope of our approach, which automates the quantification of mineral proportions, thus ensuring a more objective and precise rock classification. The development of our proprietary dataset mask, despite its labor-intensive nature and the challenges with incomplete labelling, was crucial for achieving accurate segmentation based on the proportional regions of each mineral within the photomicrographs. This segmentation, key to our rule-driven classification, streamlines the rock naming process. Our method not only sets new standards in igneous rock classification but also signifies a transformative leap in geological research. By integrating advanced image processing with deep learning, we are opening new frontiers in Earth sciences, highlighting the transformative impact of technology in refining traditional geological methodologies. Considering the dataset's incomplete and highly imbalanced mask scenario, our method achieves an accuracy of 73.32%, significantly surpassing the baseline method using VGG16 as the backbone, which attains only 63.64% classification accuracy.\n\nHow to cite: Jaya, E. J., Wang, X., Zhou, C., and Ye, N.: Revolutionizing Igneous Rock Classification: Proportion-Based Deep Learning Analysis of Petrographic Thin Section Photomicrographs, EGU General Assembly 2024, Vienna, Austria, 14–19 Apr 2024, EGU24-11850, https://doi.org/10.5194/egusphere-egu24-11850, 2024.\n\nWe are sorry, but presentations are only available for users who registered for the conference. Thank you."
    }
}