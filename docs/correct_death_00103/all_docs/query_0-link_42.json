{
    "id": "correct_death_00103_0",
    "rank": 42,
    "data": {
        "url": "https://worldwidescience.org/topicpages/h/historically%2Bimportant%2Bepoch.html",
        "read_more_link": "",
        "language": "en",
        "title": "historically important epoch: Topics by WorldWideScience.org",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/WWSlogo_wTag650px-min.png",
            "https://worldwidescience.org/topicpages/h/images/arrow-up.gif",
            "https://worldwidescience.org/topicpages/h/images/arrow-down.gif",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/OSTIlogo.svg",
            "https://worldwidescience.org/sites/www.osti.gov/files/public/image-files/ICSTIlogo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Epochs of radioactivity in historical evolution of the earth with reference to evolution of biosphere\n\nInternational Nuclear Information System (INIS)\n\nNeruchev, S.G.\n\n1976-01-01\n\nPeriodic epochs of intense contamination of the medium by uranium in the course of the Earth's evolution and the biogene mechanism of uranium accumulation in sediments during the lifetime are established. Global differentiation of the radioactivity epochs and essential effect of periodic radiation on the evolution of biosphere are shown. Radiational-mutational mechanism in shown to be extremely nonuniform during the evolution of the organic kingdom. It has been found that the intermittency in radioactive epochs is responsible for peculiarities in the stratigraphic distribution of sedimentary uranium, sapropelic shales, phosphorites, oil-producing rocks and other minerals\n\nEpisodes and Epochs in the Evolution of Danish Textile and Fashion Industry\n\nDEFF Research Database (Denmark)\n\nBoujarzadeh, Behnam; Turcan, Romeo V.; Dholakia, Nikhilesh\n\n2016-01-01\n\nIn this paper we explore the emergence and evolution of industries. Specifically we investigate the episodes and epochs in the emergence and evolution of Danish Textile and Fashion Industry. We collected historical data on Danish Textile and Fashion Industry between 1945 and 2015. We employ radar...\n\nImportance of epoch length and registration time on accelerometer measurements in younger children\n\nDEFF Research Database (Denmark)\n\nDencker, M; Svensson, J; El-Naaman, B\n\n2012-01-01\n\nThe aim of this study was to investigate the effect of epoch length on accumulation of minutes of physical activity per day over a spectrum of intensities, and the effect that selection of number of hours of acceptable registration required per day had on number of days that were considered accep...\n\nAdministering an epoch initiated for remote memory access\n\nScience.gov (United States)\n\nBlocksome, Michael A; Miller, Douglas R\n\n2012-10-23\n\nMethods, systems, and products are disclosed for administering an epoch initiated for remote memory access that include: initiating, by an origin application messaging module on an origin compute node, one or more data transfers to a target compute node for the epoch; initiating, by the origin application messaging module after initiating the data transfers, a closing stage for the epoch, including rejecting any new data transfers after initiating the closing stage for the epoch; determining, by the origin application messaging module, whether the data transfers have completed; and closing, by the origin application messaging module, the epoch if the data transfers have completed.\n\nPulsar slow-down epochs\n\nInternational Nuclear Information System (INIS)\n\nHeintzmann, H.; Novello, M.\n\n1981-01-01\n\nThe relative importance of magnetospheric currents and low frequency waves for pulsar braking is assessed and a model is developed which tries to account for the available pulsar timing data under the unifying aspect that all pulsars have equal masses and magnetic moments and are born as rapid rotators. Four epochs of slow-down are distinguished which are dominated by different braking mechanisms. According to the model no direct relationship exists between 'slow-down age' and true age of a pulsar and leads to a pulsar birth-rate of one event per hundred years. (Author) [pt\n\nThe quantum epochÃ©.\n\nScience.gov (United States)\n\nPylkkÃ¤nen, Paavo\n\n2015-12-01\n\nThe theme of phenomenology and quantum physics is here tackled by examining some basic interpretational issues in quantum physics. One key issue in quantum theory from the very beginning has been whether it is possible to provide a quantum ontology of particles in motion in the same way as in classical physics, or whether we are restricted to stay within a more limited view of quantum systems, in terms of complementary but mutually exclusive phenomena. In phenomenological terms we could describe the situation by saying that according to the usual interpretation of quantum theory (especially Niels Bohr's), quantum phenomena require a kind of epochÃ© (i.e. a suspension of assumptions about reality at the quantum level). However, there are other interpretations (especially David Bohm's) that seem to re-establish the possibility of a mind-independent ontology at the quantum level. We will show that even such ontological interpretations contain novel, non-classical features, which require them to give a special role to \"phenomena\" or \"appearances\", a role not encountered in classical physics. We will conclude that while ontological interpretations of quantum theory are possible, quantum theory implies the need of a certain kind of epochÃ© even for this type of interpretations. While different from the epochÃ© connected to phenomenological description, the \"quantum epochÃ©\" nevertheless points to a potentially interesting parallel between phenomenology and quantum philosophy. Copyright Â© 2015. Published by Elsevier Ltd.\n\nFaint Object Detection in Multi-Epoch Observations via Catalog Data Fusion\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nBudavÃ¡ri, TamÃ¡s; Szalay, Alexander S. [Department of Physics and Astronomy, The Johns Hopkins University, 3400 North Charles Street, Baltimore, MD 21218 (United States); Loredo, Thomas J. [Cornell Center for Astrophysics and Planetary Science, Cornell University, Ithaca, NY 14853 (United States)\n\n2017-03-20\n\nAstronomy in the time-domain era faces several new challenges. One of them is the efficient use of observations obtained at multiple epochs. The work presented here addresses faint object detection and describes an incremental strategy for separating real objects from artifacts in ongoing surveys. The idea is to produce low-threshold single-epoch catalogs and to accumulate information across epochs. This is in contrast to more conventional strategies based on co-added or stacked images. We adopt a Bayesian approach, addressing object detection by calculating the marginal likelihoods for hypotheses asserting that there is no object or one object in a small image patch containing at most one cataloged source at each epoch. The object-present hypothesis interprets the sources in a patch at different epochs as arising from a genuine object; the no-object hypothesis interprets candidate sources as spurious, arising from noise peaks. We study the detection probability for constant-flux objects in a Gaussian noise setting, comparing results based on single and stacked exposures to results based on a series of single-epoch catalog summaries. Our procedure amounts to generalized cross-matching: it is the product of a factor accounting for the matching of the estimated fluxes of the candidate sources and a factor accounting for the matching of their estimated directions. We find that probabilistic fusion of multi-epoch catalogs can detect sources with similar sensitivity and selectivity compared to stacking. The probabilistic cross-matching framework underlying our approach plays an important role in maintaining detection sensitivity and points toward generalizations that could accommodate variability and complex object structure.\n\nFaint Object Detection in Multi-Epoch Observations via Catalog Data Fusion\n\nInternational Nuclear Information System (INIS)\n\nBudavÃ¡ri, TamÃ¡s; Szalay, Alexander S.; Loredo, Thomas J.\n\n2017-01-01\n\nAstronomy in the time-domain era faces several new challenges. One of them is the efficient use of observations obtained at multiple epochs. The work presented here addresses faint object detection and describes an incremental strategy for separating real objects from artifacts in ongoing surveys. The idea is to produce low-threshold single-epoch catalogs and to accumulate information across epochs. This is in contrast to more conventional strategies based on co-added or stacked images. We adopt a Bayesian approach, addressing object detection by calculating the marginal likelihoods for hypotheses asserting that there is no object or one object in a small image patch containing at most one cataloged source at each epoch. The object-present hypothesis interprets the sources in a patch at different epochs as arising from a genuine object; the no-object hypothesis interprets candidate sources as spurious, arising from noise peaks. We study the detection probability for constant-flux objects in a Gaussian noise setting, comparing results based on single and stacked exposures to results based on a series of single-epoch catalog summaries. Our procedure amounts to generalized cross-matching: it is the product of a factor accounting for the matching of the estimated fluxes of the candidate sources and a factor accounting for the matching of their estimated directions. We find that probabilistic fusion of multi-epoch catalogs can detect sources with similar sensitivity and selectivity compared to stacking. The probabilistic cross-matching framework underlying our approach plays an important role in maintaining detection sensitivity and points toward generalizations that could accommodate variability and complex object structure.\n\nLinear Covariance Analysis and Epoch State Estimators\n\nScience.gov (United States)\n\nMarkley, F. Landis; Carpenter, J. Russell\n\n2014-01-01\n\nThis paper extends in two directions the results of prior work on generalized linear covariance analysis of both batch least-squares and sequential estimators. The first is an improved treatment of process noise in the batch, or epoch state, estimator with an epoch time that may be later than some or all of the measurements in the batch. The second is to account for process noise in specifying the gains in the epoch state estimator. We establish the conditions under which the latter estimator is equivalent to the Kalman filter.\n\nGeomagnetic Polarity Epochs: Sierra Nevada II.\n\nScience.gov (United States)\n\nCox, A; Doell, R R; Dalrymple, G B\n\n1963-10-18\n\nTen new determinations on volcanic extrusions in the Sierra Nevada with potassium-argon ages of 3.1 million years or less indicate that the remanent magnetizations fall into two groups, a normal group in which the remanent magnetization is directed downward and to the north, and a reversed group magnetized up and to the south. Thermomagnetic experiments and mineralogic studies fail to provide an explanation of the opposing polarities in terms of mineralogic control, but rather suggest that the remanent magnetization reflects reversals of the main dipole field of the earth. All available radiometric ages are consistent with this field-reversal hypothesis and indicate that the present normal polarity epoch (N1) as well as the previous reversed epoch (R1) are 0.9 to 1.0 million years long, whereas the previous normal epoch (N2) was at least 25 percent longer.\n\nBrain network segregation and integration during an epoch-related working memory fMRI experiment.\n\nScience.gov (United States)\n\nFransson, Peter; Schiffler, BjÃ¶rn C; Thompson, William Hedley\n\n2018-05-17\n\nThe characterization of brain subnetwork segregation and integration has previously focused on changes that are detectable at the level of entire sessions or epochs of imaging data. In this study, we applied time-varying functional connectivity analysis together with temporal network theory to calculate point-by-point estimates in subnetwork segregation and integration during an epoch-based (2-back, 0-back, baseline) working memory fMRI experiment as well as during resting-state. This approach allowed us to follow task-related changes in subnetwork segregation and integration at a high temporal resolution. At a global level, the cognitively more taxing 2-back epochs elicited an overall stronger response of integration between subnetworks compared to the 0-back epochs. Moreover, the visual, sensorimotor and fronto-parietal subnetworks displayed characteristic and distinct temporal profiles of segregation and integration during the 0- and 2-back epochs. During the interspersed epochs of baseline, several subnetworks, including the visual, fronto-parietal, cingulo-opercular and dorsal attention subnetworks showed pronounced increases in segregation. Using a drift diffusion model we show that the response time for the 2-back trials are correlated with integration for the fronto-parietal subnetwork and correlated with segregation for the visual subnetwork. Our results elucidate the fast-evolving events with regard to subnetwork integration and segregation that occur in an epoch-related task fMRI experiment. Our findings suggest that minute changes in subnetwork integration are of importance for task performance. Copyright Â© 2018 The Authors. Published by Elsevier Inc. All rights reserved.\n\nLate Globalization and Evolution, Episodes and Epochs of Industries\n\nDEFF Research Database (Denmark)\n\nTurcan, Romeo V.; Boujarzadeh, Behnam; Dholakia, Nikhilesh\n\nWhile the empirical focus of this paper is the Danish Textile and Fashion Industry (DTFI) â specifically the episodes and epochs in the emergence and evolution of DTFI, in essence the micro and macro time-slices â the theoretical intent is wider. We aim to explore the conceptual terrain of what we...... for further exploration of the late globalization phenomenon. To get to the empirical case study, we follow a macro-conceptual to a micro-empirical path. We discuss the multidisciplinary and multifaceted field of late globalization and employing the historic-analytic approach to study DTFI we draw out very...... specific, empirically derived, conceptual themes about the patterns of global interactions that characterized the evolutionary trajectory of DTFI. We return to a final macro-conceptual section on late globalization where the particular DTFI case study advances the knowledge register only slightly; and we...\n\nDesigning Successful Next-Generation Instruments to Detect the Epoch of Reionization\n\nScience.gov (United States)\n\nThyagarajan, Nithyanandan; Hydrogen Epoch of Reionization Array (HERA) team, Murchison Widefield Array (MWA) team\n\n2018-01-01\n\nThe Epoch of Reionization (EoR) signifies a period of intense evolution of the Inter-Galactic Medium (IGM) in the early Universe caused by the first generations of stars and galaxies, wherein they turned the neutral IGM to be completely ionized by redshift â¥ 6. This important epoch is poorly explored to date. Measurement of redshifted 21 cm line from neutral Hydrogen during the EoR is promising to provide the most direct constraints of this epoch. Ongoing experiments to detect redshifted 21 cm power spectrum during reionization, including the Murchison Widefield Array (MWA), Precision Array for Probing the Epoch of Reionization (PAPER), and the Low Frequency Array (LOFAR), appear to be severely affected by bright foregrounds and unaccounted instrumental systematics. For example, the spectral structure introduced by wide-field effects, aperture shapes and angular power patterns of the antennas, electrical and geometrical reflections in the antennas and electrical paths, and antenna position errors can be major limiting factors. These mimic the 21 cm signal and severely degrade the instrument performance. It is imperative for the next-generation of experiments to eliminate these systematics at their source via robust instrument design. I will discuss a generic framework to set cosmologically motivated antenna performance specifications and design strategies using the Precision Radio Interferometry Simulator (PRISim) -- a high-precision tool that I have developed for simulations of foregrounds and the instrument transfer function intended primarily for 21 cm EoR studies, but also broadly applicable to interferometer-based intensity mapping experiments. The Hydrogen Epoch of Reionization Array (HERA), designed in-part based on this framework, is expected to detect the 21 cm signal with high significance. I will present this framework and the simulations, and their potential for designing upcoming radio instruments such as HERA and the Square Kilometre Array (SKA).\n\nAssessing a potential solution for spatially referencing of historical aerial photography in South Africa\n\nScience.gov (United States)\n\nDenner, Michele; Raubenheimer, Jacobus H.\n\n2018-05-01\n\nHistorical aerial photography has become a valuable commodity in any country, as it provides a precise record of historical land management over time. In a developing country, such as South Africa, that has undergone enormous political and social change over the last years, such photography is invaluable as it provides a clear indication of past injustices and serves as an aid to addressing post-apartheid issues such as land reform and land redistribution. National mapping organisations throughout the world have vast repositories of such historical aerial photography. In order to effectively use these datasets in today's digital environment requires that it be georeferenced to an accuracy that is suitable for the intended purpose. Using image-to-image georeferencing techniques, this research sought to determine the accuracies achievable for ortho-rectifying large volumes of historical aerial imagery, against the national standard for ortho-rectification in South Africa, using two different types of scanning equipment. The research conducted four tests using aerial photography from different time epochs over a period of sixty years, where the ortho-rectification matched each test to an already ortho-rectified mosaic of a developed area of mixed land use. The results of each test were assessed in terms of visual accuracy, spatial accuracy and conformance to the national standard for ortho-rectification in South Africa. The results showed a decrease in the overall accuracy of the image as the epoch range between the historical image and the reference image increased. Recommendations on the applications possible given the different epoch ranges and scanning equipment used are provided.\n\nDescription of nighttime cough epochs in patients with stable COPD GOLD II-IV.\n\nScience.gov (United States)\n\nFischer, Patrick; Gross, Volker; Kroenig, Johannes; Weissflog, Andreas; Hildebrandt, Olaf; Sohrabi, Keywan; Koehler, Ulrich\n\nChronic cough is one of the main symptoms of COPD. Ambulatory objective monitoring provides novel insights into the determinants and characteristics of nighttime cough in COPD. Nighttime cough was monitored objectively by LEOSound lung sound monitor in patients with stable COPD II-IV. In 30 patients, with 10 patients in each stage group, nighttime cough was analyzed for epoch frequency, epoch severity (epoch length and coughs per epoch), and pattern (productive or nonproductive). Cough was found in all patients ranging from 1 to 294 events over the recording period. In 29 patients, cough epochs were monitored, ranging from 1 to 75 epochs. The highest amount of cough epochs was found in patients with COPD stage III. Active smokers had significantly more productive cough epochs (61%) than nonsmokers (24%). We found a high rate of nighttime cough epochs in patients with COPD, especially in those in stage III. Productive cough was predominantly found in patients with persistent smoking. LEOSound lung sound monitor offers a practical and valuable opportunity to evaluate cough objectively.\n\nIdentifying individual sleep apnea/hypoapnea epochs using smartphone-based pulse oximetry.\n\nScience.gov (United States)\n\nGarde, Ainara; Dekhordi, Parastoo; Ansermino, J Mark; Dumont, Guy A\n\n2016-08-01\n\nSleep apnea, characterized by frequent pauses in breathing during sleep, poses a serious threat to the healthy growth and development of children. Polysomnography (PSG), the gold standard for sleep apnea diagnosis, is resource intensive and confined to sleep laboratories, thus reducing its accessibility. Pulse oximetry alone, providing blood oxygen saturation (SpO2) and blood volume changes in tissue (PPG), has the potential to identify children with sleep apnea. Thus, we aim to develop a tool for at-home sleep apnea screening that provides a detailed and automated 30 sec epoch-by-epoch sleep apnea analysis. We propose to extract features characterizing pulse oximetry (SpO2 and pulse rate variability [PRV], a surrogate measure of heart rate variability) to create a multivariate logistic regression model that identifies epochs containing apnea/hypoapnea events. Overnight pulse oximetry was collected using a smartphone-based pulse oximeter, simultaneously with standard PSG from 160 children at the British Columbia Children's hospital. The sleep technician manually scored all apnea/hypoapnea events during the PSG study. Based on these scores we labeled each epoch as containing or not containing apnea/hypoapnea. We randomly divided the subjects into training data (40%), used to develop the model applying the LASSO method, and testing data (60%), used to validate the model. The developed model was assessed epoch-by-epoch for each subject. The test dataset had a median area under the receiver operating characteristic (ROC) curve of 81%; the model provided a median accuracy of 74% sensitivity of 75%, and specificity of 73% when using a risk threshold similar to the percentage of apnea/hypopnea epochs. Thus, providing a detailed epoch-by-epoch analysis with at-home pulse oximetry alone is feasible with accuracy, sensitivity and specificity values above 73% However, the performance might decrease when analyzing subjects with a low number of apnea/hypoapnea events.\n\nPliocene geomagnetic polarity epochs\n\nScience.gov (United States)\n\nDalrymple, G.B.; Cox, A.; Doell, Richard R.; Gromme, C.S.\n\n1967-01-01\n\nA paleomagnetic and K-Ar dating study of 44 upper Miocene and Pliocene volcanic units from the western United States suggests that the frequency of reversals of the earth's magnetic field during Pliocene time may have been comparable with that of the last 3.6 m.y. Although the data are too limited to permit the formal naming of any new polarity epochs or events, four polarity transitions have been identified: the W10 R/N boundary at 3.7 ?? 0.1 m.y., the A12 N/R boundary at 4.9 ?? 0.1 m.y., the W32 N/R boundary at 9.0 ?? 0.2m.y., and the W36 R/N boundary at 10.8 ?? 0.3 - 1.0 m.y. The loss of absolute resolution of K-Ar dating in older rocks indicates that the use of well defined stratigraphic successions to identify and date polarity transitions will be important in the study of Pliocene and older reversals. ?? 1967.\n\nThe epochs of international law\n\nCERN Document Server\n\nGrewe, Wilhelm G\n\n2000-01-01\n\nA theoretical overview and detailed analysis of the history of international law from the Middle Ages through to the end of the twentieth century (updated from the 1984 German language edition). Wilhelm Grewe's \"Epochen der VÃ¶lkerrechtsgeschichte\" is widely regarded as one of the classic twentieth century works of international law. This revised translation by Michael Byers of Oxford University makes this important book available to non-German readers for the first time. \"The Epochs of International Law\" provides a theoretical overview and detailed analysis of the history of international law from the Middle Ages, to the Age of Discovery and the Thirty Years War, from Napoleon Bonaparte to the Treaty of Versailles and the Age of the Single Superpower, and does so in a way that reflects Grewe's own experience as one of Germany's leading diplomats and professors of international law. A new chapter, written by Wilhelm Grewe and Michael Byers, updates the book to 1998, making the revised translation of interest ...\n\nReduction of CO2 Emissions in Houses of Historic and Visual Importance\n\nDirectory of Open Access Journals (Sweden)\n\nBirgit Dulski\n\n2010-01-01\n\nFull Text Available According to the âClimate Programmeâ the municipality of Amsterdam has the ambition to reduce the CO2 emissions within the city limits by 40% in the year 2025 compared to the year 1990. To realize this ambition substantial CO2 savings have to be realized at the 375,000 current houses in the city. A special challenge is formed by the houses of historic and visual importance, as the implementation of standard energy saving measures may conflict with the ambition to protect their cultural and historic values. Nyenrode Business University was asked to study the possibilities for a successful combination of ambitions in both fields. This article shows an overview of suggestions that focus on the combination of technical and process orientated innovations which can contribute to the acceleration of the reduction of CO2 emissions in houses of historic and visual importance. The article therefore addresses political and technical as well as financial and process related aspects in implementing energy saving measures in this category of buildings.\n\nExploring historical trends using taxonomic name metadata\n\nDirectory of Open Access Journals (Sweden)\n\nSchenk Ryan\n\n2008-05-01\n\nFull Text Available Abstract Background Authority and year information have been attached to taxonomic names since Linnaean times. The systematic structure of taxonomic nomenclature facilitates the ability to develop tools that can be used to explore historical trends that may be associated with taxonomy. Results From the over 10.7 million taxonomic names that are part of the uBio system 4, approximately 3 million names were identified to have taxonomic authority information from the years 1750 to 2004. A pipe-delimited file was then generated, organized according to a Linnaean hierarchy and by years from 1750 to 2004, and imported into an Excel workbook. A series of macros were developed to create an Excel-based tool and a complementary Web site to explore the taxonomic data. A cursory and speculative analysis of the data reveals observable trends that may be attributable to significant events that are of both taxonomic (e.g., publishing of key monographs and societal importance (e.g., world wars. The findings also help quantify the number of taxonomic descriptions that may be made available through digitization initiatives. Conclusion Temporal organization of taxonomic data can be used to identify interesting biological epochs relative to historically significant events and ongoing efforts. We have developed an Excel workbook and complementary Web site that enables one to explore taxonomic trends for Linnaean taxonomic groupings, from Kingdoms to Families.\n\nSystematic Uncertainties in Black Hole Masses Determined from Single Epoch Spectra\n\nDEFF Research Database (Denmark)\n\nDenney, Kelly D.; Peterson, Bradley M.; Dietrich, Matthias\n\n2008-01-01\n\nWe explore the nature of systematic errors that can arise in measurement of black hole masses from single-epoch spectra of active galactic nuclei (AGNs) by utilizing the many epochs available for NGC 5548 and PG1229+204 from reverberation mapping databases. In particular, we examine systematics due...\n\nSignals from the epoch of cosmological recombination (Karl Schwarzschild Award Lecture 2008)\n\nScience.gov (United States)\n\nSunyaev, R. A.; Chluba, J.\n\n2009-07-01\n\nThe physical ingredients to describe the epoch of cosmological recombination are amazingly simple and well-understood. This fact allows us to take into account a very large variety of physical processes, still finding potentially measurable consequences for the energy spectrum and temperature anisotropies of the Cosmic Microwave Background (CMB). In this contribution we provide a short historical overview in connection with the cosmological recombination epoch and its connection to the CMB. Also we highlight some of the detailed physics that were studied over the past few years in the context of the cosmological recombination of hydrogen and helium. The impact of these considerations is two-fold: The associated release of photons during this epoch leads to interesting and unique deviations of the Cosmic Microwave Background (CMB) energy spectrum from a perfect blackbody, which, in particular at decimeter wavelength and the Wien part of the CMB spectrum, may become observable in the near future. Despite the fact that the abundance of helium is rather small, it still contributes a sizeable amount of photons to the full recombination spectrum, leading to additional distinct spectral features. Observing the spectral distortions from the epochs of hydrogen and helium recombination, in principle would provide an additional way to determine some of the key parameters of the Universe (e.g. the specific entropy, the CMB monopole temperature and the pre-stellar abundance of helium). Also it permits us to confront our detailed understanding of the recombination process with direct observational evidence. In this contribution we illustrate how the theoretical spectral template of the cosmological recombination spectrum may be utilized for this purpose. We also show that because hydrogen and helium recombine at very different epochs it is possible to address questions related to the thermal history of our Universe. In particular the cosmological recombination radiation may\n\nHeavy metals in human bones in different historical epochs.\n\nScience.gov (United States)\n\nMartÃ­nez-GarcÃ­a, M J; Moreno, J M; Moreno-Clavel, J; Vergara, N; GarcÃ­a-SÃ¡nchez, A; GuillamÃ³n, A; PortÃ­, M; Moreno-Grau, S\n\n2005-09-15\n\nThe concentration of the metals lead, copper, zinc, cadmium and iron was determined in bone remains belonging to 30 individuals buried in the Region of Cartagena dating from different historical periods and in eight persons who had died in recent times. The metals content with respect to lead, cadmium and copper was determined either by anodic stripping voltammetry or by atomic absorption spectroscopy on the basis of the concentrations present in the bone remains. In all cases, zinc and iron were quantified by means of atomic absorption spectroscopy. The lead concentrations found in the bone remains in our city are greater than those reported in the literature for other locations. This led to the consideration of the sources of these metals in our area, both the contribution from atmospheric aerosols as well as that from the soil in the area. Correlation analysis leads us to consider the presence of the studied metals in the analysed bone samples to be the consequence of analogous inputs, namely the inhalation of atmospheric aerosols and diverse contributions in the diet. The lowest values found in the studied bone remains correspond to the Neolithic period, with similar contents to present-day samples with respect to lead, copper, cadmium and iron. As regards the evolution over time of the concentrations of the metals under study, a clear increase in these is observed between the Neolithic period and the grouping made up of the Bronze Age, Roman domination and the Byzantine period. The trend lines used to classify the samples into 7 periods show that the maximum values of lead correspond to the Roman and Byzantine periods. For copper, this peak is found in the Byzantine Period and for iron, in the Islamic Period. Zinc shows an increasing tendency over the periods under study and cadmium is the only metal whose trend lines shows a decreasing slope.\n\nEpochality, Global Capitalism and Ecology\n\nDirectory of Open Access Journals (Sweden)\n\nWayne Hope\n\n2018-05-01\n\nFull Text Available What type of capitalism do we live in today? My answer to this question draws upon two interrelated lines of argument. Firstly, I will argue that we inhabit an epoch of global capitalism. The precursors of this kind of capitalism originated from the late nineteenth century when the development of telegraph networks, modern transport systems and world time zones provided a global template for industrialisation and Western imperialism. From about 1980 a confluence of global events and processes bought a fully-fledged global capitalism into being. These included the collapse of Fordist Keynesianism, national Keynesianism and Soviet Communism along with First, Second and Third World demarcations; the international proliferation of neo-liberal policy regimes; the growth of transnational corporations in all economic sectors; the predominance of financialisation and the reconstitution of global workforces. Secondly, I will argue that the shift from organic surface energy to underground fossil energy intertwined the time of the earth with the time of human history as nature was being instrumentalised as a resource for humanity. Understanding the capitalist relations of power involved here requires that we rethink the emergence of industrial capitalism in the historical context of a world system built upon unequal socio-ecological exchange between core and periphery. Today, global capitalism has intensified the anthropogenic feedback loops associated with CO2 emissions and climate change and universalised the organisational frameworks of profit extraction and socio-ecological destruction. I refer here to the transnational systems of fossil fuel capitalism along with their interlinkages with financialisation and advertising/commodity fetishism. From the preceding lines of argument I will briefly outline the intra-capitalist and planetary-ecological crises out of which transnational coalitions of opposition might emerge.\n\nEpoch-based Entropy for Early Screening of Alzheimer's Disease.\n\nScience.gov (United States)\n\nHoumani, N; Dreyfus, G; Vialatte, F B\n\n2015-12-01\n\nIn this paper, we introduce a novel entropy measure, termed epoch-based entropy. This measure quantifies disorder of EEG signals both at the time level and spatial level, using local density estimation by a Hidden Markov Model on inter-channel stationary epochs. The investigation is led on a multi-centric EEG database recorded from patients at an early stage of Alzheimer's disease (AD) and age-matched healthy subjects. We investigate the classification performances of this method, its robustness to noise, and its sensitivity to sampling frequency and to variations of hyperparameters. The measure is compared to two alternative complexity measures, Shannon's entropy and correlation dimension. The classification accuracies for the discrimination of AD patients from healthy subjects were estimated using a linear classifier designed on a development dataset, and subsequently tested on an independent test set. Epoch-based entropy reached a classification accuracy of 83% on the test dataset (specificity = 83.3%, sensitivity = 82.3%), outperforming the two other complexity measures. Furthermore, it was shown to be more stable to hyperparameter variations, and less sensitive to noise and sampling frequency disturbances than the other two complexity measures.\n\nLEDDB : LOFAR Epoch of Reionization Diagnostic Database\n\nNARCIS (Netherlands)\n\nMartinez-Rubi, O.; Veligatla, V. K.; de Bruyn, A. G.; Lampropoulos, P.; Offringa, A. R.; Jelic, V.; Yatawatta, S.; Koopmans, L. V. E.; Zaroubi, S.\n\n2013-01-01\n\nOne of the key science projects of the Low-Frequency Array (LOFAR) is the detection of the cosmological signal coming from the Epoch of Reionization (EoR). Here we present the LOFAR EoR Diagnostic Database (LEDDB) that is used in the storage, management, processing and analysis of the LOFAR EoR\n\nA superposed epoch analysis of geomagnetic storms\n\nDirectory of Open Access Journals (Sweden)\n\nJ. R. Taylor\n\n1994-06-01\n\nFull Text Available A superposed epoch analysis of geomagnetic storms has been undertaken. The storms are categorised via their intensity (as defined by the Dst index. Storms have also been classified here as either storm sudden commencements (SSCs or storm gradual commencements (SGCs, that is all storms which did not begin with a sudden commencement. The prevailing solar wind conditions defined by the parameters solar wind speed (vsw, density (Ïsw and pressure (Psw and the total field and the components of the interplanetary magnetic field (IMF during the storms in each category have been investigated by a superposed epoch analysis. The southward component of the IMF, appears to be the controlling parameter for the generation of small SGCs (-100 nT< minimum Dst â¤ -50 nT for â¥ 4 h, but for SSCs of the same intensity solar wind pressure is dominant. However, for large SSCs (minimum Dst â¤ -100 nT for â¥ 4 h the solar wind speed is the controlling parameter. It is also demonstrated that for larger storms magnetic activity is not solely driven by the accumulation of substorm activity, but substantial energy is directly input via the dayside. Furthermore, there is evidence that SSCs are caused by the passage of a coronal mass ejection, whereas SGCs result from the passage of a high speed/ slow speed coronal stream interface. Storms are also grouped by the sign of Bz during the first hour epoch after the onset. The sign of Bz at t = +1 h is the dominant sign of the Bz for ~24 h before the onset. The total energy released during storms for which Bz was initially positive is, however, of the same order as for storms where Bz was initially negative.\n\nCoordinating supplier-retailer using multiple common replenishment epochs with retailersâ choices\n\nDirectory of Open Access Journals (Sweden)\n\nJuhwen Hwang\n\n2013-06-01\n\nFull Text Available Purpose: Provide a coordination strategy using multiple common replenishment epochs (MCRE for a single-supplier multi-retailer supply chain. Design/methodology/approach: The demand of a product occurs only with a group of heterogeneous and independent retailers with constant rates, whereas all their order requests are fulfilled by the supplier. The supplier decides a set of MCREs with general price and extra bonus to entice the retailers to join any one of the MCREs, or to let them remain with their original order time epochs. A retailer is willing to participate in a CRE as long as the retailerâs cost increase is within its tolerance. This paper provide a mixed integer programming to determine the MCRE strategies in order to minimize the total costs of the supplier. Findings: The results illustrate that MCRE model provided in the paper can generate a better replenishment coordination scheme than single CRE models. Practical implications: Replenishment coordination is one of the most important mechanisms to improve the efficiency in supply chains, e.g., chain convenience stores in the modern retail industry. Originality/value: This is a follow-up research on Joint Economic Lot Size (JELS models with a focus on multiple retailers with their replenishment coordination.\n\nImproving the repeatability of Motor Unit Number Index (MUNIX) by introducing additional epochs at low contraction levels.\n\nScience.gov (United States)\n\nPeng, Yun; Zhang, Yingchun\n\n2017-07-01\n\nTo evaluate the repeatability of (Motor Unit Number Index) MUNIX under repeatability conditions, specify the origin of variations and provide strategies for quality control. MUNIX calculations were performed on the bicep brachii muscles of eight healthy subjects. Negative effect of suboptimal electrode positions on MUNIX accuracy was eliminated by employing the high-density surface electromyography technique. MUNIX procedures that utilized a variety of surface interferential pattern (SIP) epoch recruitment strategies (including the original MUNIX procedure, two proposed improvement strategies and their combinations) were described. For each MUNIX procedure, ten thousands of different SIP pools were constructed by randomly recruiting necessary SIP epochs from a large SIP epoch pool (3 datasets, 9 independent electromyography recordings at different contraction levels per dataset and 10 SIP epochs per recording) and implemented for MUNIX calculation. The repeatability of each MUNIX procedure was assessed by summarizing the resulting MUNIX distribution and compared to investigate the effect of SIP epoch selection strategy on repeatability performance. SIP epochs selected at lower contraction levels have a stronger influence on the repeatability of MUNIX than those selected at higher contraction levels. MUNIX under repeatability conditions follows a normal distribution and the standard deviation can be significantly reduced by introducing more epochs near the MUNIX definition line. The MUNIX technique shows an inherent variation attributable to SIP epochs at low contraction levels. It is recommended that more epochs should be sampled at these low contraction levels to improve the repeatability. The present study thoroughly documented the inherent variation of MUNIX and the causes, and offered practical solutions to improve the repeatability of MUNIX. Copyright Â© 2017 International Federation of Clinical Neurophysiology. Published by Elsevier B.V. All rights reserved.\n\nObserving the epoch of galaxy formation.\n\nScience.gov (United States)\n\nSteidel, C C\n\n1999-04-13\n\nSignificant observational progress in addressing the question of the origin and early evolution of galaxies has been made in the past few years, allowing for direct comparison of the epoch when most of the stars in the universe were forming to prevailing theoretical models. There is currently broad consistency between theoretical expectations and the observations, but rapid improvement in the data will provide much more critical tests of theory in the coming years.\n\nHydrogen Epoch of Reionization Array (HERA)\n\nScience.gov (United States)\n\nDeBoer, David R.; HERA\n\n2015-01-01\n\nThe Hydrogen Epoch of Reionization Arrays (HERA - reionization.org) roadmap uses the unique properties of the neutral hydrogen (HI) 21cm line to probe our cosmic dawn: from the birth of the first stars and black holes, through the full reionization of the primordial intergalactic medium (IGM). HERA is a collaboration between the Precision Array Probing the Epoch of Reionization (PAPER - eor.berkeley.edu), the US-based Murchison Widefield Array (MWA - mwatelescope.org), and MIT Epoch of Reionization (MITEOR) teams along with the South African SKA-SA, University of KwaZulu Natal and the University of Cambridge Cavendish Laborabory. HERA has recently been awarded a National Science Foundation Mid-Scale Innovation Program grant to begin the next phase.HERA leverages the operation of the PAPER and MWA telescopes to explore techniques and designs required to detect the primordial HI signal in the presence of systematics and radio continuum foreground emission some four orders of magnitude brighter. With this understanding, we are now able to remove foregrounds to the limits of our sensitivity, culminating in the first physically meaningful upper limits. A redundant calibration algorithm from MITEOR improves the sensitivity of the approach.Building on this, the next stage of HERA incorporates a 14m diameter antenna element that is optimized both for sensitivity and for minimizing foreground systematics. Arranging these elements in a compact hexagonal grid yields an array that facilitates calibration, leverages proven foreground removal techniques, and is scalable to large collecting areas. HERA will be located in the radio quiet environment of the SKA site in the Karoo region of South Africa (where PAPER is currently located). It will have a sensitivity close to two orders of magnitude better than PAPER and the MWA to ensure a robust detection. With its sensitivity and broader frequency coverage, HERA can paint an uninterrupted picture through reionization, back to the\n\nThe effect of epoch length on estimated EEG functional connectivity and brain network organisation\n\nScience.gov (United States)\n\nFraschini, Matteo; Demuru, Matteo; Crobe, Alessandra; Marrosu, Francesco; Stam, Cornelis J.; Hillebrand, Arjan\n\n2016-06-01\n\nObjective. Graph theory and network science tools have revealed fundamental mechanisms of functional brain organization in resting-state M/EEG analysis. Nevertheless, it is still not clearly understood how several methodological aspects may bias the topology of the reconstructed functional networks. In this context, the literature shows inconsistency in the chosen length of the selected epochs, impeding a meaningful comparison between results from different studies. Approach. The aim of this study was to provide a network approach insensitive to the effects that epoch length has on functional connectivity and network reconstruction. Two different measures, the phase lag index (PLI) and the amplitude envelope correlation (AEC) were applied to EEG resting-state recordings for a group of 18 healthy volunteers using non-overlapping epochs with variable length (1, 2, 4, 6, 8, 10, 12, 14 and 16 s). Weighted clustering coefficient (CCw), weighted characteristic path length (L w) and minimum spanning tree (MST) parameters were computed to evaluate the network topology. The analysis was performed on both scalp and source-space data. Main results. Results from scalp analysis show a decrease in both mean PLI and AEC values with an increase in epoch length, with a tendency to stabilize at a length of 12 s for PLI and 6 s for AEC. Moreover, CCw and L w show very similar behaviour, with metrics based on AEC more reliable in terms of stability. In general, MST parameters stabilize at short epoch lengths, particularly for MSTs based on PLI (1-6 s versus 4-8 s for AEC). At the source-level the results were even more reliable, with stability already at 1 s duration for PLI-based MSTs. Significance. The present work suggests that both PLI and AEC depend on epoch length and that this has an impact on the reconstructed network topology, particularly at the scalp-level. Source-level MST topology is less sensitive to differences in epoch length, therefore enabling the comparison of brain\n\nGeomagnetic reversal in brunhes normal polarity epoch.\n\nScience.gov (United States)\n\nSmith, J D; Foster, J H\n\n1969-02-07\n\nThe magnetic stratigraphly of seven cores of deep-sea sediment established the existence of a short interval of reversed polarity in the upper part of the Brunches epoch of normal polarity. The reversed zone in the cores correlates well with paleontological boundaries and is named the Blake event. Its boundaries are estimated to be 108,000 and 114,000 years ago +/- 10 percent.\n\nPrimordial black hole formation during the QCD epoch\n\nInternational Nuclear Information System (INIS)\n\nJedamzik, K.\n\n1997-01-01\n\nWe consider the formation of horizon-size primordial black holes (PBH close-quote s) from pre-existing density fluctuations during cosmic phase transitions. It is pointed out that the formation of PBH close-quote s should be particularly efficient during the QCD epoch due to a substantial reduction of pressure forces during adiabatic collapse, or equivalently, a significant decrease in the effective speed of sound during the color-confinement transition. Our considerations imply that for generic initial density perturbation spectra PBH mass functions are expected to exhibit a pronounced peak on the QCD-horizon mass scale â¼1M circle-dot . This mass scale is roughly coincident with the estimated masses for compact objects recently observed in our galactic halo by the MACHO Collaboration. Black holes formed during the QCD epoch may offer an attractive explanation for the origin of halo dark matter evading possibly problematic nucleosynthesis and luminosity bounds on baryonic halo dark matter. copyright 1997 The American Physical Society\n\nThe Reel Deal: Interpreting HST Multi-Epoch Movies of YSO Jets.\n\nScience.gov (United States)\n\nFrank, Adam\n\n2010-09-01\n\nThe goal of this proposal is to bring the theoretical interpretation of Young Stellar Object jets and their environments to a new level of realism. We propose to build on the results of a successful Cycle 16 observing proposal that has obtained 3rd epoch images of HH jets. We will use Adaptive Mesh Refinement MHD simulations {developed by our team} to carry forward a detailed program of modeling and interpretation of the time-dependent behavior revealed in the new, extended multi-epoch data set. Only with the third epoch observations can we explore forces: i.e. accelerations, decelerations and structural changes to develop an accurate understanding of physical processes occurring in hypersonic, magnetized jet flows. Our studies will allow us to characterize the jets and, therefore, make the crucial link with jet central engines. We note an innovative feature of our project is its link with laboratory astrophysical experiments of jets. Our analysis of the observations will be used to determine future laboratory experiments which will explore A?clumpyA? jet propagation issues.\n\nClinical and Cost Comparison Evaluation of Inpatient Versus Outpatient Administration of EPOCH-Containing Regimens in Non-Hodgkin Lymphoma.\n\nScience.gov (United States)\n\nEvans, Sarah S; Gandhi, Arpita S; Clemmons, Amber B; DeRemer, David L\n\n2017-08-01\n\nEtoposide, prednisone, vincristine, cyclophosphamide, doxorubicin (EPOCH)-containing regimens are frequently utilized in non-Hodgkin's lymphoma, however, the incidence of febrile neutropenia (FN) in patients receiving inpatient versus outpatient EPOCH has not been described. Additionally, no comparisons have been made regarding financial implications of EPOCH administration in either setting. This study's primary objective was to compare hospital admissions for FN in patients receiving inpatient or outpatient EPOCH. A single-center, institutional review board-approved review was conducted for adults receiving EPOCH beginning January 2010. Clinical and financial data were collected through chart review and the institution's financial department. Descriptive statistics were utilized for analysis. A total of 25 patients received 86 cycles of an EPOCH-containing regimen (61 [70.9%] inpatient). Five (8.2%) inpatient cycles resulted in an admission for FN compared to 4 (16%) outpatient cycles. Prophylactic antifungal and antiviral agents were prescribed more often after inpatient cycles (>80%) compared to outpatient cycles (cost savings of approximately US$141 116 for both chemotherapy costs and hospital day avoidance. EPOCH-containing regimens can be safely administered in the outpatient setting, which may result in cost savings for healthcare institutions.\n\nA search for changing look quasars in second epoch imaging\n\nScience.gov (United States)\n\nFindlay, Joseph; Myers, Adam; McGreer, Ian\n\n2018-01-01\n\nOver nearly two decades, the Sloan Digital Sky Survey has compiled a catalog of over half a million confirmed quasars. During that period approximately ten percent of these objects have been spectroscopically observed in two or more epochs over baselines of ten or more years. This led recently to the discovery of the largest change in luminosity ever before observed in a quasar. The dimming emission was a reflection of very significant changes in continuum and broad line properties, the source had effectively transitioned from a Type I quasar to a Type II AGN. Since then several more \"changing look\" quasars have been discovered in multi-epoch SDSS spectroscopy. Among them are objects with rising and falling luminosities, appearing and disappearing broad lines. The origin of this behavior is still very uncertain, currently favored is the scenario in which an accreting black hole is simply starved of fuel. Other plausible scenarios include flaring due to stellar tidal disruption close to the black hole or large changes in accretion flow, which can occur during transitions between radiatively efficient and inefficient accretion regimes. Monitoring of larger numbers of changing look quasars will help to elucidate these ideas.In this poster, we report on the progress of a pilot study in which we hope to learn how to select changing look quasars in multi-epoch imaging. This will allow us to take advantage of the entire SDSS quasar catalog rather than just the ten percent of objects with multi-epoch spectroscopy. Comparing archival SDSS and more recent Legacy Survey imaging over ten-year baselines we select objects whose photometry is consistent with the large changes in luminosity expected in changing look quasars. We aim to build up a catalog of both transitioned and transitioning objects for future monitoring.\n\n'Anthropocene': An Ethical Crisis, Not a Geological Epoch\n\nScience.gov (United States)\n\nCuomo, Chris\n\n2017-04-01\n\nThe term 'anthropocene' has gained enormous popularity among scientists who believe we are in a global phase distinguished by the extensive and lasting impacts of social activities on Earth's sedimentary record and vital systems. Beyond its widespread informal use, a working group of the International Union of Geological Sciences seeks to formalize the term to name a new geological epoch, implying that the Holocene epoch has ended. I argue that the move to formalize the 'anthropocene' and to declare the demise of the Holocene is premature and ethically misguided, at best, and that the very name 'anthropocene' obscures rather than illuminates the serious moral and political/economic implications of the dire warnings evident in recent stratigraphic and ecological changes. If human-caused mass extinction and other ecological catastrophes are serious harms, ethical responses are required. Instead, the move to formalize the idea of an 'anthropocene' epoch treats dire ethical warnings as an opportunity to redefine the current dangerous situation as a new status quo. Have we met our responsibilities to protect Holocene Earth? This presentation will focus on the ethical implications of using the power and discourse of geology to demote Holocene ecological states from their role as the foundational benchmarks for guiding and assessing human relationships with nature and other species. Have geoscientists adequately consulted the biological, ecological and social sciences before declaring the end of the Holocene epoch? Upon what do we base environmental ethics if the Holocene is considered past history? I will also examine the ethical dimensions of naming the so-called 'anthropocene', asking: who is the presumed 'anthro' in the 'anthropocene'? Are the phenomena identified with the 'anthropocene' (nuclear fallout, mass species endangerment, ocean acidification, fossil fuel pollution, deforestation, mining) definitive accomplishments of the human species? Should the practices\n\nThe cultural and historical heritage of towns Trebinje and Jajce: A resource for the growth of tourism\n\nDirectory of Open Access Journals (Sweden)\n\nGuzijan Jasna\n\n2009-01-01\n\nFull Text Available This paper considers the possibility of including cultural heritage in cultural and tourist development policies. The tourist potential of historically and artistically significant urban entities will be described and assessed in the paper, with a focus on the cases of Trebinje and Jajce two Bosnian and Herzegovinian towns with preserved historical town cores. The two towns were both founded in the Middle Ages and have developed to this day, with their urban areas continuously expanding and being built up. Their spatial and cultural historical complexes are diverse and multilayered, with various natural and man-made structures dating back to different epochs. They are the greatest cultural monuments and a testimony of the past, of the physical and spiritual development of these communities. Trebinje is an old town located at the intersection of various influences and interests, with a rich and long history which has altered not only the appearance and contents of its town core, but also its significance and its functional impact on the broader surroundings. The Old Town, a surviving historical complex, which originated in the Middle Ages and developed considerably under Turkish rule is one of Trebinje's tourist resources. Nowadays, tourism is becoming one of the world's most important industries, its appeal coming from the natural cultural and historical values of towns and cities. Due to that, the natural cultural and historical values of Trebinje and Jajce can be preserved only if their economic potential is also taken into account.\n\nLinguistic Engineering and Linguistic of Engineering: Adaptation of Linguistic Paradigm for Circumstance of Engineering Epoch\n\nOpenAIRE\n\nNatalya Halina\n\n2014-01-01\n\nThe article is devoted to the problems of linguistic knowledge in the Engineering Epoch. Engineering Epoch is the time of adaptation to the information flows by knowledge management, The system of adaptation mechanisms is connected with linguistic and linguistic technologies, forming in new linguistic patterns Linguistic Engineering and Linguistic of Engineering.\n\nTHE TIME EVOLUTION OF HH 1 FROM FOUR EPOCHS OF HST IMAGES\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nRaga, A. C.; Esquivel, A. [Instituto de Ciencias Nucleares, Universidad Nacional AutÃ³noma de MÃ©xico, Ap. 70-543, 04510 D.F., MÃ©xico (Mexico); Reipurth, B. [Institute for Astronomy, University of Hawaii at Manoa, Hilo, HI 96720 (United States); Bally, J., E-mail: raga@nucleares.unam.mx [Center for Astrophysics and Space Astronomy, University of Colorado, UCB 389, Boulder, CO 80309 (United States)\n\n2016-05-15\n\nWe present an analysis of four epochs of HÎ± and [S ii]Â Î»Î» 6716/6731 Hubble Space Telescope (HST) images of HHÂ 1. For determining proper motions, we explore a new method based on the analysis of spatially degraded images obtained convolving the images with wavelet functions of chosen widths. With this procedure, we are able to generate maps of proper motion velocities along and across the outflow axis, as well as (angularly integrated) proper motion velocity distributions. From the four available epochs, we find the time evolution of the velocities, intensities, and spatial distribution of the line emission. We find that over the last two decades HHÂ 1 shows a clear acceleration. Also, the HÎ± and [S ii] intensities first dropped and then recovered in the more recent (2014) images. Finally, we show a comparison between the two available HST epochs of [O iii]Â Î»Â 5007 (1994 and 2014), in which we see a clear drop in the value of the [O iii]/HÎ± ratio.\n\nMethodological proposal for the jotted issue of the first epoch of the Hero magazine.\n\nDirectory of Open Access Journals (Sweden)\n\nMaitÃ© GarcÃ­a DÃ­az\n\n2013-07-01\n\nFull Text Available During the neocolonial republic emerges in Sancti Spiritus a very significative magazine of artistic, literary and scientific sketch: Hero, founded by Jacinto Gomer FernÃ¡ndez-Morera and Anastacio FernÃ¡ndez-Morera del Castillo, it first appeared on December 20th 1907. This issue constitutes a vivid reflect of the commercial, literary, cultural, scientific and historic panorama and above all, of the life of the middle and high class in Sancti Spiritus at the beginning of the XX century. The need to divulge the advantage the texts of Hero constitute for the high school and university students, also to humanistic profile graduates and others, such as investigators, evidenced the need to carry out an investigation that pursued such purposes. Thatâs why the methodological proposal for the jotted issue of the first epoch of the Hero magazine (1907-1908 takes place, composed by 38 publications, departing from the fundamental theorizations about the jotted issue of the presentation of the methodological proposal on behalf of updating these publication texts for its potential readers.\n\nEPICUREANISM AND CHRISTIANITY IN HISTORICAL NOVELS VALERIUS. A ROMAN STORY BY J.G. LOCKHART AND THE EPICUREAN BY T. MOORE\n\nDirectory of Open Access Journals (Sweden)\n\nElena V. Somova\n\n2017-03-01\n\nFull Text Available The article examines historical novels by J.G. Lockhart and T. Moore hitherto under- studied in Russia. It analyzes main principles and techniques of historical narrative in these novels; the influence of Walter Scott and F.R. Chateaubriand; philosophical Epicureanism in the novels; and the specificity of their work with historical sources. The author comes to the following conclusions. Lockhartâs and Mooreâs reflection on time and history results in the idea that every man is connected with the whole of creation, and that the culture of each epoch depends on the culture of earlier civilizations. Lockhartâs novel Valerius, for example, was influenced by the genre of the Enlightenment philosophical novella. Such categories as time, the meaning of life, death, place, and role of man in history are intro- duced in the narrative through the form of philosophical dialogue. Following the tradi- tion of F.R. Chateaubriand, Lockhart, and Moore largely draw on literary heritage: texts by Homer, Virgil, Horace, Cicero as well as philosophical works of antiquity: the writings of Epicurus, Lucretius, and Plato. Historical novels by Lockhart and Moore reveal cer- tain important aspects of the ethical and philosophical system of the 19 th century Victorian England.\n\nThe Cosmic Dawn and Epoch of Reionisation with SKA\n\nNARCIS (Netherlands)\n\nKoopmans, L.; Pritchard, J.; Mellema, G.; Aguirre, J.; Ahn, K.; Barkana, R.; van Bemmel, I.; Bernardi, G.; Bonaldi, A.; Briggs, F.; de Bruyn, A. G.; Chang, T. C.; Chapman, E.; Chen, X.; Ciardi, B.; Dayal, P.; Ferrara, A.; Fialkov, A.; Fiore, F.; Ichiki, K.; Illiev, I. T.; Inoue, S.; Jelic, V.; Jones, M.; Lazio, J.; Maio, U.; Majumdar, S.; Mack, K. J.; Mesinger, A.; Morales, M. F.; Parsons, A.; Pen, U. L.; Santos, M.; Schneider, R.; Semelin, B.; de Souza, R. S.; Subrahmanyan, R.; Takeuchi, T.; Vedantham, H.; Wagg, J.; Webster, R.; Wyithe, S.; Datta, K. K.; Trott, C.\n\n2014-01-01\n\nConcerted effort is currently ongoing to open up the Epoch of Reionization (EoR) ($z\\\\sim$15-6) for studies with IR and radio telescopes. Whereas IR detections have been made of sources (Lyman-$\\\\alpha$ emitters, quasars and drop-outs) in this redshift regime in relatively small fields of view, no\n\nThe Cosmic Dawn and Epoch of Reionisation with SKA\n\nNARCIS (Netherlands)\n\nKoopmans, L.; Pritchard, J.; Mellema, G.; Aguirre, J.; Ahn, K.; Barkana, R.; van Bemmel, I.; Bernardi, G.; Bonaldi, A.; Briggs, F.; de Bruyn, A. G.; Chang, T. C.; Chapman, E.; Chen, X.; Ciardi, B.; Dayal, P.; Ferrara, A.; Fialkov, A.; Fiore, F.; Ichiki, K.; Illiev, I. T.; Inoue, S.; Jelic, V.; Jones, M.; Lazio, J.; Maio, U.; Majumdar, S.; Mack, K. J.; Mesinger, A.; Morales, M. F.; Parsons, A.; Pen, U. L.; Santos, M.; Schneider, R.; Semelin, B.; de Souza, R. S.; Subrahmanyan, R.; Takeuchi, T.; Vedantham, H.; Wagg, J.; Webster, R.; Wyithe, S.; Datta, K. K.; Trott, C.\n\n2015-01-01\n\nConcerted effort is currently ongoing to open up the Epoch of Reionization (EoR) ($z\\\\sim$15-6) for studies with IR and radio telescopes. Whereas IR detections have been made of sources (Lyman-$\\\\alpha$ emitters, quasars and drop-outs) in this redshift regime in relatively small fields of view, no\n\nMetallogenic epoch of the Jiapigou gold belt, Jilin Province, China\n\nIndian Academy of Sciences (India)\n\nMetallogenic epoch of the Jiapigou gold belt, Jilin Province, China: ... The Jiapigou gold belt is located on the northern margin of the North China Craton, and is one of the ... 29, Xueyuan Road, Beijing 100083, People's Republic of China.\n\nA PRECISION MULTI-BAND TWO-EPOCH PHOTOMETRIC CATALOG OF 44 MILLION SOURCES IN THE NORTHERN SKY FROM A COMBINATION OF THE USNO-B AND SLOAN DIGITAL SKY SURVEY CATALOGS\n\nInternational Nuclear Information System (INIS)\n\nMadsen, G. J.; Gaensler, B. M.\n\n2013-01-01\n\nA key science driver for the next generation of wide-field optical and radio surveys is the exploration of the time variable sky. These surveys will have unprecedented sensitivity and areal coverage, but will be limited in their ability to detect variability on time scales longer than the lifetime of the surveys. We present a new precision, multi-epoch photometric catalog that spans 60Â yr by combining the US Naval Observatory-B (USNO-B) and Sloan Digital Sky Survey (SDSS) Data Release 9 (DR9) catalogs. We recalibrate the photometry of the original USNO-B catalog and create a catalog with two epochs of photometry in up to five different bands for 43,647,887 optical point sources that lie in the DR9 footprint of the northern sky. The recalibrated objects span a magnitude range 14 â² m â² 20 and are accurate to â0.1Â mag. We minimize the presence of spurious objects and those with inaccurate magnitudes by identifying and removing several sources of systematic errors in the two originating catalogs, with a focus on spurious objects that exhibit large apparent magnitude variations. After accounting for these effects, we find â250,000 stars and quasars that show significant (â¥4Ï) changes in brightness between the USNO-B and SDSS DR9 epochs. We discuss the historical value of the catalog and its application to the study of long time scale, large amplitude variable stars and quasars\n\nOn the spin-temperature evolution during the epoch of reionization\n\nNARCIS (Netherlands)\n\nThomas, Rajat M.; Zaroubi, Saleem\n\nSimulations estimating the brightness temperature (delta T-b) of the redshifted 21 cm from the epoch of reionization (EoR) often assume that the spin temperature (T-s) is decoupled from the background cosmic microwave background (CMB) temperature and is much larger than it, i.e. T-s T-CMB. Although\n\nLSST and the Epoch of Reionization Experiments\n\nScience.gov (United States)\n\nIveziÄ, Å½eljko\n\n2018-05-01\n\nThe Large Synoptic Survey Telescope (LSST), a next generation astronomical survey, sited on Cerro Pachon in Chile, will provide an unprecedented amount of imaging data for studies of the faint optical sky. The LSST system includes an 8.4m (6.7m effective) primary mirror and a 3.2 Gigapixel camera with a 9.6 sq. deg. field of view. This system will enable about 10,000 sq. deg. of sky to be covered twice per night, every three to four nights on average, with typical 5-sigma depth for point sources of r = 24.5 (AB). With over 800 observations in the ugrizy bands over a 10-year period, these data will enable coadded images reaching r = 27.5 (about 5 magnitudes deeper than SDSS) as well as studies of faint time-domain astronomy. The measured properties of newly discovered and known astrometric and photometric transients will be publicly reported within 60 sec after closing the shutter. The resulting hundreds of petabytes of imaging data for about 40 billion objects will be used for scientific investigations ranging from the properties of near-Earth asteroids to characterizations of dark matter and dark energy. For example, simulations estimate that LSST will discover about 1,000 quasars at redshifts exceeding 7; this sample will place tight constraints on the cosmic environment at the end of the reionization epoch. In addition to a brief introduction to LSST, I review the value of LSST data in support of epoch of reionization experiments and discuss how international participants can join LSST.\n\nAssessing worst case scenarios in movement demands derived from global positioning systems during international rugby union matches: Rolling averages versus fixed length epochs\n\nScience.gov (United States)\n\nCunningham, Daniel J.; Shearer, David A.; Carter, Neil; Drawer, Scott; Pollard, Ben; Bennett, Mark; Eager, Robin; Cook, Christian J.; Farrell, John; Russell, Mark\n\n2018-01-01\n\nThe assessment of competitive movement demands in team sports has traditionally relied upon global positioning system (GPS) analyses presented as fixed-time epochs (e.g., 5â40 min). More recently, presenting game data as a rolling average has become prevalent due to concerns over a loss of sampling resolution associated with the windowing of data over fixed periods. Accordingly, this study compared rolling average (ROLL) and fixed-time (FIXED) epochs for quantifying the peak movement demands of international rugby union match-play as a function of playing position. Elite players from three different squads (n = 119) were monitored using 10 Hz GPS during 36 matches played in the 2014â2017 seasons. Players categorised broadly as forwards and backs, and then by positional sub-group (FR: front row, SR: second row, BR: back row, HB: half back, MF: midfield, B3: back three) were monitored during match-play for peak values of high-speed running (>5 mÂ·s-1; HSR) and relative distance covered (mÂ·min-1) over 60â300 s using two types of sample-epoch (ROLL, FIXED). Irrespective of the method used, as the epoch length increased, values for the intensity of running actions decreased (e.g., For the backs using the ROLL method, distance covered decreased from 177.4 Â± 20.6 mÂ·min-1 in the 60 s epoch to 107.5 Â± 13.3 mÂ·min-1 for the 300 s epoch). For the team as a whole, and irrespective of position, estimates of fixed effects indicated significant between-method differences across all time-points for both relative distance covered and HSR. Movement demands were underestimated consistently by FIXED versus ROLL with differences being most pronounced using 60 s epochs (95% CI HSR: -6.05 to -4.70 mÂ·min-1, 95% CI distance: -18.45 to -16.43 mÂ·min-1). For all HSR time epochs except one, all backs groups increased more (p < 0.01) from FIXED to ROLL than the forward groups. Linear mixed modelling of ROLL data highlighted that for HSR (except 60 s epoch), SR was the only group not\n\nPeriod, epoch, and prediction errors of ephemerides from continuous sets of timing measurements\n\nScience.gov (United States)\n\nDeeg, H. J.\n\n2015-06-01\n\nSpace missions such as Kepler and CoRoT have led to large numbers of eclipse or transit measurements in nearly continuous time series. This paper shows how to obtain the period error in such measurements from a basic linear least-squares fit, and how to correctly derive the timing error in the prediction of future transit or eclipse events. Assuming strict periodicity, a formula for the period error of these time series is derived, ÏP = ÏT (12 / (N3-N))1 / 2, where ÏP is the period error, ÏT the timing error of a single measurement, and N the number of measurements. Compared to the iterative method for period error estimation by Mighell & Plavchan (2013), this much simpler formula leads to smaller period errors, whose correctness has been verified through simulations. For the prediction of times of future periodic events, usual linear ephemeris were epoch errors are quoted for the first time measurement, are prone to an overestimation of the error of that prediction. This may be avoided by a correction for the duration of the time series. An alternative is the derivation of ephemerides whose reference epoch and epoch error are given for the centre of the time series. For long continuous or near-continuous time series whose acquisition is completed, such central epochs should be the preferred way for the quotation of linear ephemerides. While this work was motivated from the analysis of eclipse timing measures in space-based light curves, it should be applicable to any other problem with an uninterrupted sequence of discrete timings for which the determination of a zero point, of a constant period and of the associated errors is needed.\n\nA FLUX SCALE FOR SOUTHERN HEMISPHERE 21 cm EPOCH OF REIONIZATION EXPERIMENTS\n\nEnergy Technology Data Exchange (ETDEWEB)\n\nJacobs, Daniel C.; Bowman, Judd [School of Earth and Space Exploration, Arizona State University, Tempe, AZ (United States); Parsons, Aaron R.; Ali, Zaki; Pober, Jonathan C. [Astronomy Department, University of California, Berkeley, CA (United States); Aguirre, James E.; Moore, David F. [Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA (United States); Bradley, Richard F. [Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA (United States); Carilli, Chris L. [National Radio Astronomy Observatory, Socorro, NM (United States); DeBoer, David R.; Dexter, Matthew R.; MacMahon, Dave H. E. [Radio Astronomy Lab., University of California, Berkeley, CA (United States); Gugliucci, Nicole E.; Klima, Pat [National Radio Astronomy Observatory, Charlottesville, VA (United States); Manley, Jason R.; Walbrugh, William P. [Square Kilometer Array, South Africa Project, Cape Town (South Africa); Stefan, Irina I. [Cavendish Laboratory, Cambridge (United Kingdom)\n\n2013-10-20\n\nWe present a catalog of spectral measurements covering a 100-200 MHz band for 32 sources, derived from observations with a 64 antenna deployment of the Donald C. Backer Precision Array for Probing the Epoch of Reionization (PAPER) in South Africa. For transit telescopes such as PAPER, calibration of the primary beam is a difficult endeavor and errors in this calibration are a major source of error in the determination of source spectra. In order to decrease our reliance on an accurate beam calibration, we focus on calibrating sources in a narrow declination range from â46Â° to â40Â°. Since sources at similar declinations follow nearly identical paths through the primary beam, this restriction greatly reduces errors associated with beam calibration, yielding a dramatic improvement in the accuracy of derived source spectra. Extrapolating from higher frequency catalogs, we derive the flux scale using a Monte Carlo fit across multiple sources that includes uncertainty from both catalog and measurement errors. Fitting spectral models to catalog data and these new PAPER measurements, we derive new flux models for Pictor A and 31 other sources at nearby declinations; 90% are found to confirm and refine a power-law model for flux density. Of particular importance is the new Pictor A flux model, which is accurate to 1.4% and shows that between 100 MHz and 2 GHz, in contrast with previous models, the spectrum of Pictor A is consistent with a single power law given by a flux at 150 MHz of 382 Â± 5.4 Jy and a spectral index of â0.76 Â± 0.01. This accuracy represents an order of magnitude improvement over previous measurements in this band and is limited by the uncertainty in the catalog measurements used to estimate the absolute flux scale. The simplicity and improved accuracy of Pictor A's spectrum make it an excellent calibrator in a band important for experiments seeking to measure 21 cm emission from the epoch of reionization.\n\nSYSTEMATIC UNCERTAINTIES IN BLACK HOLE MASSES DETERMINED FROM SINGLE-EPOCH SPECTRA\n\nInternational Nuclear Information System (INIS)\n\nDenney, Kelly D.; Peterson, Bradley M.; Dietrich, Matthias; Bentz, Misty C.; Vestergaard, Marianne\n\n2009-01-01\n\nWe explore the nature of systematic errors that can arise in measurement of black hole masses from single-epoch (SE) spectra of active galactic nuclei (AGNs) by utilizing the many epochs available for NGC 5548 and PG1229+204 from reverberation mapping (RM) databases. In particular, we examine systematics due to AGN variability, contamination due to constant spectral components (i.e., narrow lines and host galaxy flux), data quality (i.e., signal-to-noise ratio (S/N)), and blending of spectral features. We investigate the effect that each of these systematics has on the precision and accuracy of SE masses calculated from two commonly used line width measures by comparing these results to recent RM studies. We calculate masses by characterizing the broad HÎ² emission line by both the full width at half maximum and the line dispersion, and demonstrate the importance of removing narrow emission-line components and host starlight. We find that the reliability of line width measurements rapidly decreases for S/N lower than â¼ 10-20 (per pixel), and that fitting the line profiles instead of direct measurement of the data does not mitigate this problem but can, in fact, introduce systematic errors. We also conclude that a full spectral decomposition to deblend the AGN and galaxy spectral features is unnecessary, except to judge the contribution of the host galaxy to the luminosity and to deblend any emission lines that may inhibit accurate line width measurements. Finally, we present an error budget which summarizes the minimum observable uncertainties as well as the amount of additional scatter and/or systematic offset that can be expected from the individual sources of error investigated. In particular, we find that the minimum observable uncertainty in SE mass estimates due to variability is â¼ 20 pixel -1 ) spectra.\n\nModeling high-order synchronization epochs and transitions in the cardiovascular system\n\nScience.gov (United States)\n\nGarcÃ­a-Ãlvarez, David; Bahraminasab, Alireza; Stefanovska, Aneta; McClintock, Peter V. E.\n\n2007-12-01\n\nWe study a system consisting of two coupled phase oscillators in the presence of noise. This system is used as a model for the cardiorespiratory interaction in wakefulness and anaesthesia. We show that longrange correlated noise produces transitions between epochs with different n:m synchronisation ratios, as observed in the cardiovascular system. Also, we see that, the smaller the noise (specially the one acting on the slower oscillator), the bigger the synchronisation time, exactly as happens in anaesthesia compared with wakefulness. The dependence of the synchronisation time on the couplings, in the presence of noise, is studied; such dependence is softened by low-frequency noise. We show that the coupling from the slow oscillator to the fast one (respiration to heart) plays a more important role in synchronisation. Finally, we see that the isolines with same synchronisation time seem to be a linear combination of the two couplings.\n\nAtlas Basemaps in Web 2.0 Epoch\n\nScience.gov (United States)\n\nChabaniuk, V.; Dyshlyk, O.\n\n2016-06-01\n\nThe authors have analyzed their experience of the production of various Electronic Atlases (EA) and Atlas Information Systems (AtIS) of so-called \"classical type\". These EA/AtIS have been implemented in the past decade in the Web 1.0 architecture (e.g., National Atlas of Ukraine, Atlas of radioactive contamination of Ukraine, and others). One of the main distinguishing features of these atlases was their static nature - the end user could not change the content of EA/AtIS. Base maps are very important element of any EA/AtIS. In classical type EA/AtIS they were static datasets, which consisted of two parts: the topographic data of a fixed scale and data of the administrative-territorial division of Ukraine. It is important to note that the technique of topographic data production was based on the use of direct channels of topographic entity observation (such as aerial photography) for the selected scale. Changes in the information technology of the past half-decade are characterized by the advent of the \"Web 2.0 epoch\". Due to this, in cartography appeared such phenomena as, for example, \"neo-cartography\" and various mapping platforms like OpenStreetMap. These changes have forced developers of EA/AtIS to use new atlas basemaps. Our approach is described in the article. The phenomenon of neo-cartography and/or Web 2.0 cartography are analysed by authors using previously developed Conceptual framework of EA/AtIS. This framework logically explains the cartographic phenomena relations of three formations: Web 1.0, Web 1.0x1.0 and Web 2.0. Atlas basemaps of the Web 2.0 epoch are integrated information systems. We use several ways to integrate separate atlas basemaps into the information system - by building: weak integrated information system, structured system and meta-system. This integrated information system consists of several basemaps and falls under the definition of \"big data\". In real projects it is already used the basemaps of three strata: Conceptual\n\nEffects of Varying Epoch Lengths, Wear Time Algorithms, and Activity Cut-Points on Estimates of Child Sedentary Behavior and Physical Activity from Accelerometer Data.\n\nScience.gov (United States)\n\nBanda, Jorge A; Haydel, K Farish; Davila, Tania; Desai, Manisha; Bryson, Susan; Haskell, William L; Matheson, Donna; Robinson, Thomas N\n\n2016-01-01\n\nTo examine the effects of accelerometer epoch lengths, wear time (WT) algorithms, and activity cut-points on estimates of WT, sedentary behavior (SB), and physical activity (PA). 268 7-11 year-olds with BMI â¥ 85th percentile for age and sex wore accelerometers on their right hips for 4-7 days. Data were processed and analyzed at epoch lengths of 1-, 5-, 10-, 15-, 30-, and 60-seconds. For each epoch length, WT minutes/day was determined using three common WT algorithms, and minutes/day and percent time spent in SB, light (LPA), moderate (MPA), and vigorous (VPA) PA were determined using five common activity cut-points. ANOVA tested differences in WT, SB, LPA, MPA, VPA, and MVPA when using the different epoch lengths, WT algorithms, and activity cut-points. WT minutes/day varied significantly by epoch length when using the NHANES WT algorithm (p algorithms. Minutes/day and percent time spent in SB, LPA, MPA, VPA, and MVPA varied significantly by epoch length for all sets of activity cut-points tested with all three WT algorithms (all p algorithms (all p algorithms and activity cut-point definitions to match different epoch lengths may introduce significant errors. Estimates of SB and PA from studies that process and analyze data using different epoch lengths, WT algorithms, and/or activity cut-points are not comparable, potentially leading to very different results, interpretations, and conclusions, misleading research and public policy.\n\nEpoch making NIRS studies seen through citation trends\n\nInternational Nuclear Information System (INIS)\n\nDan, Ippeita\n\n2009-01-01\n\nNear-infrared spectroscopy (NIRS) studies through citation trends are investigated of literature concerning only the brain function measurement and its methodology together with NIRS principle, technological development, present state and future view. Investigation is conducted firstly for the survey of important author name of those concerned papers in Web of Science and Google Scholar with search words of NIRS, brain and optical topography as an option. Second, >100 papers of those authors citing any of them are picked up and their papers are ranked in accordance with Web of Science citation number, of which top-nineteen are presented here. Impact and epoch making papers are reviewed with explanations of: the establishment of measuring technology of cerebral blood flow change and subsequent brain function by NIRS; development with multi-channel detection; simultaneous measurement with other imaging modalities; examination of NIRS validity; spatial analysis of NIRS; and measurement of brain function. The highest times of citation are 1,238 of the paper by F. F. Jobsis in 'Science' (1977). It should be noted that 10 of top 19 papers are those by Japanese authors. However, review articles omitted in the present literature survey are mostly described by foreign authors: an effort to systemize the concerned fields might be required in this country. (K.T.)\n\nMulti-epoch VLBA Imaging of 20 New TeV Blazars: Apparent Jet Speeds\n\nScience.gov (United States)\n\nPiner, B. Glenn; Edwards, Philip G.\n\n2018-01-01\n\nWe present 88 multi-epoch Very Long Baseline Array (VLBA) images (most at an observing frequency of 8 GHz) of 20 TeV blazars, all of the high-frequency-peaked BL Lac (HBL) class, that have not been previously studied at multiple epochs on the parsec scale. From these 20 sources, we analyze the apparent speeds of 43 jet components that are all detected at four or more epochs. As has been found for other TeV HBLs, the apparent speeds of these components are relatively slow. About two-thirds of the components have an apparent speed that is consistent (within 2Ï) with no motion, and some of these components may be stationary patterns whose apparent speed does not relate to the underlying bulk flow speed. In addition, a superluminal tail to the apparent speed distribution of the TeV HBLs is detected for the first time, with eight components in seven sources having a 2Ï lower limit on the apparent speed exceeding 1c. We combine the data from these 20 sources with an additional 18 sources from the literature to analyze the complete apparent speed distribution of all 38 TeV HBLs that have been studied with very long baseline interferometry at multiple epochs. The highest 2Ï apparent speed lower limit considering all sources is 3.6c. This suggests that bulk Lorentz factors of up to about 4, but probably not much higher, exist in the parsec-scale radio-emitting regions of these sources, consistent with estimates obtained in the radio by other means such as brightness temperatures. This can be reconciled with the high Lorentz factors estimated from the high-energy data if the jet has velocity structures consisting of different emission regions with different Lorentz factors. In particular, we analyze the current apparent speed data for the TeV HBLs in the context of a model with a fast central spine and a slower outer layer.\n\nChronic pancreatitis. Some important historical aspects.\n\nScience.gov (United States)\n\nNavarro, Salvador\n\n2018-06-08\n\nSince ancient times the increase of size and hardness sometimes presented by the abdominal structure known as the pancreas has attracted attention. Portal was the first to describe the clinical signs of chronic pancreatitis in 1803. In 1815, Fleischman speculated about the potential role of excessive alcohol consumption. Comfort coined the term \"chronic relapsing pancreatitis\" in 1946 and described hereditary pancreatitis 6 years later. Zuidema defined tropical pancreatitis in 1959 and 2 years later Sarles described another form of pancreatitis to which Yoshida gave the name autoimmune pancreatitis in 1995. Groove pancreatitis was described by Potet in 1970. Obstructive pancreatitis was defined in 1984 and Ammann identified idiopathic pancreatitis 3 years later. This article gives a historical account of the pioneers who developed the knowledge of how to assess the characteristics that allowed the different forms of chronic pancreatitis to be defined. Copyright Â© 2018 Elsevier EspaÃ±a, S.L.U. All rights reserved.\n\nThe War in the Historical Memory of Nations\n\nDirectory of Open Access Journals (Sweden)\n\nNikolaj V. Pavlov\n\n2015-01-01\n\nFull Text Available There is no doubt that the most important event of the 20th century was a joint victory of the united front of peoples and states over German fascism. For some that was the victory in the Second World War. For the Russians - the victory in the Great Patriotic War which cost the Soviet Union incredible efforts, enormous sacrifices and material losses. Now when we celebrate the 70thyear since that epoch-making date we turn our attention once more to the lessons of history because the memory of the war has been imprinted deeply on our gene level of Russians and Germans. This is because every family from both sides sustained heavy losses. This memory is alive in literature, in movies and plays, songs, in memorials, biographies and historical dates. The Russian and German descendants of those who fought against each other are doing an important work searching for the killed, looking after the burial places, compensating the damage to the victims of this inhuman massacre, trying to understand critically our common and controversial past. What was the 9th of May for the Germans and the Russians in the perception of Germans and Russians? Was it a victory, a defeat or liberation? This is what the author of the article reflects on, convinced that we are anyway dealing with the greatest event of the 20th century, at least because it prevented the end of civilization.\n\nQuantifying the importance of diffuse minewater pollution in a historically heavily coal mined catchment\n\nInternational Nuclear Information System (INIS)\n\nMayes, W.M.; Gozzard, E.; Potter, H.A.B.; Jarvis, A.P.\n\n2008-01-01\n\nThere has been considerable progress in developing treatment systems for point sources of minewater pollution in recent years; however, there remains a knowledge gap in the characterisation and remediation of diffuse minewater sources. Data are presented from the River Gaunless catchment, a historically heavily coal mined catchment in the northeast of England. Instream iron (Fe) loadings were monitored alongside loadings arising from point minewater discharges over a 12-month period to assess the dynamic importance of diffuse sources of minewater pollution. In low flow, diffuse sources account for around 50% of instream loading, a proportion which increases to 98% in high flow conditions. The low flow sources appear to be dominated by direct discharge of contaminated groundwater to surface waters in lower reaches of the catchment. In high flow, resuspended Fe-rich sediments, which are both naturally occurring and derived from historic mining, become the dominant diffuse source of Fe in the water column. - Diffuse sources of minewater pollution significantly contribute to instream contaminant loadings under varying flow conditions\n\nThe Corporate University's Role in Managing an Epoch in Learning Organisation Innovation\n\nScience.gov (United States)\n\nDealtry, Richard\n\n2006-01-01\n\nPurpose: The purpose of this paper is to set the scene for some radical epochal thinking about the approach and future strategic directions in the management of organisational learning, following the author's earlier editorial theme concerning the need for exploration and innovation in organisational learning management.â¦\n\nAssessing enigmatic boulder deposits in NE Aegean Sea: importance of historical sources as tool to support hydrodynamic equations\n\nDirectory of Open Access Journals (Sweden)\n\nM. Vacchi\n\n2012-04-01\n\nFull Text Available Due to their importance in the assessment of coastal hazards, several studies have focused on geomorphological and sedimentological field evidence of catastrophic wave impacts related to historical tsunami events. Among them, many authors used boulder fields as important indicators of past tsunamis, especially in the Mediterranean Sea. The aim of this study was to understand the mechanism of deposition of clusters of large boulders, consisting of beachrock slabs, which were found on the southern coasts of Lesvos Island (NE Aegean Sea. Methods to infer the origin of boulder deposits (tsunami vs. storm wave are often based on hydrodynamic models even if different environmental complexities are difficult to be incorporated into numerical models. In this study, hydrodynamic equations did not provide unequivocal indication of the mechanism responsible for boulder deposition in the study area. Further analyses, ranging from geomorphologic to seismotectonic data, indicated a tsunami as the most likely cause of displacement of the boulders but still do not allow to totally exclude the extreme storm origin. Additional historical investigations (based on tsunami catalogues, historical photos and aged inhabitants interviews indicated that the boulders are likely to have been deposited by the tsunami triggered by the 6.7 Ms Chios-Karaburum earthquake of 1949 or, alternatively, by minor effects of the destructive tsunami produced by 1956's Amorgos Island earthquake. Results of this study point out that, at Mediterranean scale, to flank numerical models with the huge amount of the available historical data become a crucial tool in terms of prevention policies related to catastrophic coastal events.\n\nThe Square Kilometre Array Epoch of Reionisation and Cosmic Dawn Experiment\n\nScience.gov (United States)\n\nTrott, Cathryn M.\n\n2018-05-01\n\nThe Square Kilometre Array (SKA) Epoch of Reionisation and Cosmic Dawn (EoR/CD) experiments aim to explore the growth of structure and production of ionising radiation in the first billion years of the Universe. Here I describe the experiments planned for the future low-frequency components of the Observatory, and work underway to define, design and execute these programs.\n\nFaint galaxies - Bounds on the epoch of galaxy formation and the cosmological deceleration parameter\n\nInternational Nuclear Information System (INIS)\n\nYoshii, Yuzuru; Peterson, B.A.\n\n1991-01-01\n\nModels of galaxy luminosity evolution are used to interpret the observed color distributions, redshift distributions, and number counts of faint galaxies. It is found from the color distributions that the redshift corresponding to the epoch of galaxy formation must be greater than three, and that the number counts of faint galaxies, which are sensitive to the slope of the faint end of the luminosity function, are incompatible with q0 = 1/2 and indicate a smaller value. The models assume that the sequence of galaxy types is due to different star-formation rates, that the period of galaxy formation can be characterized by a single epoch, and that after formation, galaxies change in luminosity by star formation and stellar evolution, maintaining a constant comoving space density. 40 refs\n\nHistorical and Epistemological Reflections on the Culture of Machines around the Renaissance: How Science and Technique Work?\n\nDirectory of Open Access Journals (Sweden)\n\nRaffaele Pisano\n\n2014-10-01\n\nFull Text Available This paper is divided into two parts, this being the first one. The second is entitled âHistorical and Epistemological Reflections on the Culture of Machines around Renaissance: Machines, Machineries and Perpetual Motionâ and will be published in Acta Baltica Historiae et Philosophiae Scientiarum in 2015. Based on our recent studies, we provide here a historical and epistemological feature on the role played by machines and machineries. Ours is an epistemological thesis based on a series of historical examples to show that the relations between theoretical science and the construction of machines cannot be taken for granted, a priori. Our analysis is mainly based on the culture of machines around 15th and 17th centuries, namely the epoch of Late Renaissance and Early Modern Age. For this is the period of scientific revolution and this age offers abundant interesting material for researches into the relations of theoretical science/construction of machines as well. However, to prove our epistemological thesis, we will also exploit examples of machines built in other historical periods. Particularly, a discussion concerning the relationship between science theory and the development of science art crafts produced by non-recognized scientists in a certain historical time is presented. The main questions are: when and why did the tension between science (physics, mathematics and geometry give rise to a new scientific approach to applied discipline such as studies on machines and machineries? What kind of science was used (if at all for projecting machines and machineries? Was science at the time a necessary precondition to build a machine? In the first part we will focus on the difference between Aristotelian-Euclidean and Archimedean approaches and we will outline the heritage of these two different approaches in late medieval and Renaissance science. In the second part, we will apply our reconstructions to some historical and epistemological\n\nInterpretation of an Epoch in the Novel \"the Big Green Tent\" by L. Ulitskaya: Linguistic-Cultural Analysis of Verbal Lexicon\n\nDirectory of Open Access Journals (Sweden)\n\nIldar Ch. Safin\n\n2017-11-01\n\nFull Text Available This article is the verbal lexicon analysis based on the text of the novel \"The Big Green Tent\" by L. Ulitskaya. The creative manner of the contemporary writer attracts the attention of researchers, her writings describe the emotional experiences of the heroes and also give a generalized image of time full of historical details and features. The language of her stories and short stories is characterized by a special style in the description of time realities. A verb in the text allows the author to express the events and the circumstances that characterize an action in its dynamics due to the fact that verbal categories reflect the real reality in our consciousness. The method of linguistic cultural analysis of verbal lexicon in the novel \"The Big Green Tent\" made it possible to single out exactly those language units that the writer carefully selects for the creation and interpretation of the era. A special emphasis in the study is made on the creation of an expressive-emotional style of narration using the stylistic capabilities of the Russian verb. The individual author's methods of narration expressiveness creation are singled out: synonymous series, euphemisms, colloquial lexicon, etc. The conducted study and a careful analysis of the selected factual material testifies that, recreating an epoch, the master of the word invariably uses that language arsenal that brightly and fully conveys the color of time. L. Ulitskaya is able to be not only an indifferent witness of the epoch, but also her tenacious observer and interpreter. The analyzed factual material and the main points of this research can be used in the courses on stylistics and linguistic culturology, and also as an illustrative material during the classes on the linguistic analysis of a literary text.\n\nPolarization leakage in epoch of reionization windows : The Low Frequency Array Case\n\nNARCIS (Netherlands)\n\nAsad, Khan\n\n2017-01-01\n\nThe farther we look in space, the earlier we see in time. By observing a radio signal of 21cm wavelength coming from the epoch of reionization, when the universe was less than a billion years old, we can understand how the first stars, galaxies and black holes formed. This signal has not been\n\nDetectability of the 21-cm CMB cross-correlation from the epoch of reionization\n\nNARCIS (Netherlands)\n\nTashiro, Hiroyuki; Aghanim, Nabila; Langer, Mathieu; Douspis, Marian; Zaroubi, Saleem; Jelic, Vibor\n\nThe 21-cm line fluctuations and the cosmic microwave background (CMB) are powerful probes of the epoch of reionization of the Universe. We study the potential of the cross-correlation between 21-cm line fluctuations and CMB anisotropy to obtain further constraints on the reionization history. We\n\nImportance of Sulfate Aerosol in Evaluating the Relative Contributions of Regional Emissions to the Historical Global Temperature Change\n\nInternational Nuclear Information System (INIS)\n\nAndronova, N.; Schlesinger, M.\n\n2004-01-01\n\nDuring the negotiations of the Kyoto Protocol the delegation of Brazil presented an approach for distributing the burden of emissions reductions among the Parties based on the effect of their cumulative historical emissions on the global-average near-surface temperature. The Letter to the Parties does not limit the emissions to be considered to be only greenhouse gas (GHG) emissions. Thus, in this paper we explore the importance of anthropogenic SOx emissions that are converted to sulfate aerosol in the atmosphere, together with the cumulative greenhouse gas emissions, in attributing historical temperature change. We use historical emissions and our simple climate model to estimate the relative contributions to global warming of the regional emissions by four Parties: OECD90, Africa and Latin America, Asia, and Eastern Europe and the Former Soviet Union. Our results show that for most Parties the large warming contributed by their GHG emissions is largely offset by the correspondingly large cooling by their SOx emissions. Thus, OECD90 has become the dominant contributor to recent global warming following its large reduction in SOx emissions after 1980\n\nPhysicists epoch and personalities\n\nCERN Document Server\n\nFeinberg, E L; Leonidov, A V\n\n2011-01-01\n\nThe book is a collection of memoirs on famous Soviet physicists of the 20th century, such as Tamm, Vavilov, Sakharov, Landau and others. The narrative is situated within a remarkably well-described historical, cultural and social context. Of special interest are the chapters devoted to Soviet and German atomic projects.\n\nSub-horizon evolution of cold dark matter perturbations through dark matter-dark energy equivalence epoch\n\nInternational Nuclear Information System (INIS)\n\nPiattella, O.F.; Martins, D.L.A.; Casarini, L.\n\n2014-01-01\n\nWe consider a cosmological model of the late universe constituted by standard cold dark matter plus a dark"
    }
}