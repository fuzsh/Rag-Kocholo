{
    "id": "dbpedia_4777_3",
    "rank": 15,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/",
        "read_more_link": "",
        "language": "en",
        "title": "Complex imaging of phase domains by deep neural networks",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-iucrj.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-fig1.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efd1.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efi1.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efd2.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efd3.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efi2.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-fig2.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-fig3.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-fig4.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-fig5.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-fig6.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-fig7.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efd4.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efd5.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efd6.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efi3.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/bin/m-08-00012-efd7.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Longlong Wu",
            "Pavol Juhas",
            "Shinjae Yoo",
            "Ian Robinson"
        ],
        "publish_date": "2021-01-01T00:00:00",
        "summary": "",
        "meta_description": "Machine-learning approaches can greatly facilitate single-particle-imaging experiments at X-ray free-electron-laser facilities by providing real-time images from the coherent X-ray diffraction data stream, using methods presented in this article.The reconstruction ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7792998/",
        "text": "2.1. CNN model training and testing\n\nOur developed machine-learning model is based on a CNN framework that adopts the general ‘encoder–decoder’ architecture, as presented in Fig. 1 . It consists of two connected convolutional blocks to separately output the amplitude and phase information of a particle from its coherent X-ray diffraction data. The model mainly has three parts. The first part is a convolutional autoencoder, which represents the underlying manifold of the input coherent X-ray diffraction data in feature space (Ronneberger et al., 2015 ▸; Cherukara et al., 2018 ▸). Then, the encoded result is equally divided into two independent deconvolutional decoder parts to generate the amplitude and phase information of the measured particle. For the proposed model, we used the leaky rectified linear unit (LRLU) for all activations, except for the final convolutional layer where the rectified linear unit (RLU) was used. The modules shown in Fig. 1 to connect the input to the output are one type of convolution block (3 × 3 convolution + LRLU + BN, where BN refers to batch normalization), followed by another type of convolution block (3 × 1 convolution + 1 × 3 convolution + LRLU + BN). Additionally, it should also be mentioned that the size of the output amplitude or phase is one quarter of the size of the input diffraction pattern in our model (i.e. the size of the output amplitude or phase at each dimension is half of the size of the input diffraction, as shown in Fig. 1 ), in the spirit of keeping the problem overdetermined.\n\nSince the goal of any single-particle coherent X-ray diffraction imaging experiment is to numerically compute the complex-valued information inside a particle from the obtained coherent X-ray diffraction pattern, different variants of coherent X-ray diffraction experiments interpret this complex information in different ways. For coherent-diffraction-imaging experiments, Chapman et al. (2006 ▸) represented the reconstructed information as the local complex refractive index of a particle. In BCDI experiments, Robinson et al. (2001 ▸) and Williams et al. (2003 ▸) identified the phase of the reconstructed information as the local crystal lattice strain inside a particle via the Bragg diffraction geometry, plus a small contribution from refraction in the crystal discovered by Harder et al. (2007 ▸). In all cases, the coherent X-ray diffraction intensity I(Q) measured in these variants of single-particle experiments is given by the modulus squared of the Fourier transform of this corresponding complex field:\n\nwhere Q = q − h, q = k f − k i is the momentum transfer defined by the incident X-ray wavevector k i and the diffracted X-ray wavevector k f, and h is a reciprocal lattice vector of the crystal. Here, represents the complex-valued information inside the particle, where s(r) and ϕ(r) are the amplitude and phase distribution of the particle, respectively. Usually, s(r) is the shape function of the particle with s(r) = 0 outside and s(r) = 1 inside the particle. It can be seen that both the coherent X-ray diffraction intensity I(Q) and the particle density are in 3D space. Fig. 2 (a) shows a schematic illustration of the diffraction geometry of a typical single-particle-imaging experiment. The 3D diffraction intensity in reciprocal space is usually recorded by a 2D detector. The recorded intensity is a slice of the 3D diffraction intensity, where the slice plane is determined by the experimental geometry, as shown in Fig. 2 (a). Especially for an ultrafast X-ray experiment, only the 2D coherent X-ray intensity slice through the centre of the peak is recorded. Thus, to investigate the performance of our proposed CNN model, complex-valued real-space particles are needed to obtain the 2D coherent X-ray diffraction patterns. Generally, for a particle with an anisotropic shape s(r), its shape can be introduced into the formalism by applying an analytic or numerical computation. For demonstration purposes, we consider a shape known as a superellipsoid (Gridgeman, 1970 ▸; Wriedt, 2002 ▸), whose implicit form is written as\n\nwhere a, b, and c define the bounds along the x, y and z directions, respectively. Exponents n and e are the roundedness parameters. As illustrated in Fig. 2 (b), these parameters, a, b, c, e, and n, allow one to continuously and widely vary the particle shape. Specifically, a = b = c, e = 1 and n = 1 yields a sphere, while a = b = c, e = 2 and n = 2 describes an octahedral shape. Generally, since the phase information of real-world particles is diverse, it is hard to use one general function to describe all of them. We used a 3D Gaussian-correlated profile (Garcia & Stoll, 1984 ▸) to simulate the phase information ϕ(r) of the particles, which is given as\n\nwhere z u(x, y, z) obeys an uncorrelated Gaussian random distribution. L x, L y and L z are the transverse correlation lengths along the x, y and z directions, respectively. Once described by equations (2) and (3) , the complex field is randomly orientated into different directions by a 3D rotation matrix to obtain the 3D complex field of a particle. The phase inside the particle is allowed to span from −π to π to represent the ‘strong phase’ limit described above. Finally, the 2D diffraction intensity of the particle is obtained by taking the central slice of the 3D diffraction intensity, the phase is deleted and only the intensity information is retained. Additionally, a Gaussian filter is also applied to smooth the edges of the particle before the Fourier transformation.\n\nBy applying this method to a wide range of random parameters, we simulated 2D diffraction patterns to be used as the training data to train the proposed CNN model. In the results reported here, we generated 150 000 simulated diffraction patterns, and the CNN model was trained in a supervised fashion, with the output amplitude and phase of the particle being considered as known a priori. The phase of the particle was shifted and scaled to (0, 1), and the phase outside the particle is set to zero. During the training, the training data were split into two disjoint sets, where 95% of them were used as training data and 5% of them were kept for subsequent testing.\n\nFig. 3 (a) shows the training and validation loss as a function of the training epochs. Each epoch refers to one complete pass of the training data. Since our proposed model can output the amplitude and phase of the particle at the same time, the loss (or error metric) for both training and validation is computed using a self-defined loss function (see Appendix A for details), which is used to constrain their relation in real space as well as in reciprocal space at the same time. From Fig. 3 (a), it can be seen that the training and validation loss are decreasing as the epoch is increasing. Even after training for more epochs, the validation loss is still decreasing. Since no divergence occurs, this indicates the stability of our CNN. Since the validation loss of our CNN model is computed by a self-defined loss function, we use the χ2 error (see Appendix B for details) to estimate the quality of the reconstructed images in comparison with the ground truth of the testing data, which is commonly used in iterative phase-retrieval methods. Figs. 3 (b)–3(d) present the histograms of the χ2 error for the modulus of the coherent X-ray intensity in reciprocal space, together with the amplitude and phase of the imaged particle in real space. The computed χ2 errors in the testing data lie in narrow ranges, which indicates that our CNN model shows excellent performance in reconstructing the complex image of a particle from its modulus in reciprocal space. Furthermore, by fitting the corresponding error with a Gamma distribution function, the average χ2 error for the modulus is 0.019, for the amplitude is 0.005 and for the phase is 0.029. Since the phase distribution of the particles is generally more complicated than their amplitude, it is expected that the error of the reconstructed phase is greater than that of the amplitude, as seen. The χ2 error of the modulus lies in the middle of the two. By varying the range of models used for training the proposed CNN model, we also noticed that the proposed model had better performance (smaller errors) when the phase range of the particles was made narrower. Fig. 4 shows six representative results of reconstructions from testing data not used for training. It can be seen that the current CNN model shows a remarkable performance on the reconstruction of the amplitude and phase information of a particle from its previously unseen coherent X-ray diffraction intensity pattern.\n\n2.2. Comparison of CNN model with NNS and iteration methods\n\nThe proposed CNN model is a machine-learning method of phase retrieval, which, once trained, provides a very fast (∼0.5 ms computation in our case) inversion of a diffraction pattern, unlike from an iterative phase-retrieval method. As we showed in Figs. 3 and 4 , it can give an excellent reconstruction of testing data with very high accuracy. However, as a deep neural network, it works essentially as a deep approximator that learns from data chosen within a range of expected images. It is not expected that the proposed model would be quantitatively accurate for all coherent X-ray diffraction data, though it is very capable for a range of comprehensive complex-valued particles. When working with new data, it is prone to shifts based on the type of training dataset distributions. Also, an obvious question is whether the machine-learning approach provides any advantage over a NNS over calculated structures. We tested this by ‘look up’ of the best agreement of a new diffraction pattern with the 150 000 reference structures used for training. The average χ2 error over 300 ‘unseen’ test diffraction patterns was ∼0.08 for NNS compared with ∼0.02 for CNN for these same 300 diffraction patterns, The look-up procedure also took ∼30 s per pattern on our hardware, without any attempt at optimization, compared with ∼0.5 ms.\n\nAs we mentioned before, the other approach, iterative phase retrieval, is sensitive to the initial guess of the phase and the support. As reported in a number of articles, a good support is especially crucial for the iteration methods. On the other hand, the iterative methods are good at refining the output steadily if they are started under proper conditions. In this section, we demonstrate that using our proposed CNN model can provide a good initial guess for iterative algorithms to reconstruct the finer structural features of a particle.\n\nWe compare the outcomes of four different initializations of the iterative phase-retrieval method: (i) random phase and a rectangle support; (ii) random phase and the support from the CNN model; (iii) the phase and support from the CNN model; and (iv) the phase and support obtained from the NNS method. Fig. 5 (a) shows one of the coherent X-ray diffraction patterns from the testing dataset with a strong phase inside the particle. The strong phase is evident in the broken centrosymmetry of the diffraction pattern. The trained CNN model yields the reconstructed amplitude and phase of the particle shown in Figs. 5 (b) and 5 (c). The corresponding estimated χ2 error for the modulus of the coherent X-ray diffraction pattern intensity is 0.015, and it can be seen that the CNN model gives an excellent-looking reconstructed result. The obtained CNN result was then used to define a support, shown in Fig. 5 (d), by binarization of the predicted amplitude. Iterative phase-retrieval methods following the algorithm switch schedule indicated in Fig. 5 (e) (see Appendix B for details) were then applied using the different initial guesses, Fig. 5 (f) shows the corresponding results in the conventional format of χ2 error versus iteration number. Owing to the initial phase being randomly generated for the methods of (i) random phase and a rectangle support and (ii) random phase and the support from the CNN model, the corresponding reconstructions for both methods were repeated 300 times independently. As presented in Fig. 5 (f), the blue and green lines show the corresponding averaged χ2 error separately and the shaded areas indicate the error bars corresponding to their standard deviation. Furthermore, we also use the results (i.e. the amplitude and phase of the searched particle) from the NNS method as an initial guess for the iterative phase-retrieval method. The optimized amplitude and phase of the searched particle from the NNS method are presented in Fig. S1 of the Supporting information and the dependence on the size of the searched database is shown in Fig. S2. The corresponding χ2 error versus iteration number is also shown in Fig. 5 (f), as marked by the red line. As seen in Fig. 5 (f), with the CNN model initialization, the starting χ2 error was significantly lower than that of the random initialization or the initialization based on the NNS method. The final reconstruction was significantly better than what the CNN model and iterative method can achieve alone. This shows that machine learning with iterative refinement is an excellent combination for dramatic enhancement in reconstruction quality. The learned-phase initialization converged slightly faster than random phase, but the final result was not very different, while the use of the learned support made a large difference. Fig. 6 presents the evolution of these reconstructed images versus the iteration number with the different initial methods. It can be seen in Fig. 6 that the combination of the machine-learning model and iterative phase-retrieval converges much faster than the random initial guess or initialization from the NNS method.\n\nSince the inside complex structure of a new particle is usually unknown, this combination approach becomes vital once the CNN model fails to give a decent result. This will often be expected for experimental data, when little knowledge of the structure is available for building a training dataset. To demonstrate this, Fig. 7 (a) shows one representative experimental coherent X-ray diffraction pattern of an ∼200 nm diameter BaTiO3 (BTO) nanoparticle, measured at beamline 34-ID-C of the Advanced Photon Source using methods reported by Harder & Robinson (2013 ▸). By using the CNN model, the corresponding prediction is shown in Figs. 7 (b)–7 (d). The estimated χ2 error is 0.7 for the modulus of the coherent X-ray diffraction pattern intensity which shows that the current model has a poor performance for the given experimental data. This is attributed to the range of models used in the training data being far from the (unknown) structure of the particle. However, with the proposed combination of the CNN model results and the iteration method, Figs. 7 (e) and 7 (f) show a significantly better reconstruction result with a corresponding χ2 error reduced to 0.002. The iterative calculation used the CNN-generated support in Fig. 7 (d) and utilized the ‘shrink wrap’ refinement shown in the work of Marchesini et al. (2003 ▸), which allowed it to both increase and decrease in size.\n\nBased on these results, it can be concluded that our CNN method has great potential for studies to be performed in regimes of asymmetric data previously untested owing to the need to solve for a complex density function. Moreover, the combination of the CNN model with the classical iterative method can further improve the accuracy of the obtained results."
    }
}