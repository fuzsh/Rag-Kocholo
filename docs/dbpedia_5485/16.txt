I call the arrival of digital magnetic recording a paradigm shift because having heard so far today of the invention of magnetic recording and the early decades of activity you recognize that they were dedicated to the analog recording of sound and music. The history I am going to cover is that of computer data storage, to serve radically different applications and requiring entirely new technological implementations. (By the way, this change to digital storage is now also being exploited in sound, music and video recording). The companies and individuals leading this shift were driven by the needs of computing and information processing. Now the introduction of this new era is identified with the development during the 1940s of the ENIAC. This computer was the first based on a processor using electronics, vacuum tubes at that time. The electronics provided unparalleled calculation speed then. The computer had 20,000 vacuum tubes and for input and output used paper tape and punched cards. Thats where it all began. But the arrival of the electronic processor generated a demand for much faster data input and output rates with the memory to take advantage of the processor computational speed. The memory basically provided the source of data that the processor could immediately access. The early computer block diagrams in those days did not include a block identified as storage that would fit between I/O and memory to buffer and better match the relative speeds of the processor and input/output. Now the early developments were first driven by scientific computation, associated with the major increase in computer capabilities available and consequent new problems you could effectively undertake. Government funding was key in those early days. Commercial applications that then existed made use of punched card equipment and relay based computers and there was little anticipation of a major change. Universities played a leading role as a consequence at this stage. The most well known super computer that followed ENIAC was the Whirlwind at MIT. High speed memory. implementation went through the sequence of mercury delay lines, cathode ray tubes, magnetic core, and eventually ended up at semi-conductors. But, in addition to the "super" computer, there was great interest in computers that, while more modest in capability, could be low enough in cost to be widely available. UC Berkeley received funding from the Office of Naval Research to develop such an "intermediate" type computer. I was fortunate as a graduate student to work under Paul Morton as a member of this program from its formation. This computer (named the CALDIC), had to be low cost and a magnetic drum was chosen at that time as the optimum memory technology. The fact that the magnetic drum was a nonvolatile storage device was a plus. The required features for memory, and this is where a real paradigm shift in magnetic recording devices became evident; was that first of all you had to be capable of all modifying a single "word" or very short block of data, located in the midst of many other such words. Also, these blocks necessarily were binary encoded digital data.

The memory unit needed to provide continuous availability as well as very high reliability to the stored information. Further, the drum had to have a very short direct access time to all the data stored and be able to either read, write or update in place the stored information. That required non-contact spacing between the head and recording medium to avoid wear (the relative surface speed between the two was in the range of 1600 inches a second.) The desire for a high RPM arose both from the short access time sought and the desire for a high data rate. A unique advantage of the drum over other memory approaches at the time was that the storage device was nonvolatile. Now, as I mentioned, this program at Berkeley was run under professor Paul Morton from 1948 to 1952. We had heard of a some work at a company called ERA on a magnetic drum device, but our project was basically starting from scratch and, in particular, was one of the first major efforts to design a computer system based on a magnetic drum. I put the drum specs on the slide, and obviously you can see that the magnetic heads were not based on an air bearing for spacing. While the drum was stationary, you would move the head to just touch the drum surface and then back off slightly until you felt no contact would occur when the drum was turning. That led to approximately two thousandth's of an inch spacing between the head and medium. On the other hand, a drum could rotate relatively fast and the rpm was three times as high as later chosen for the RAMAC. Recording density was 800 bit per square inch. Design really focused on achieving the functional requirements for a memory. The capacity was the ten thousand words. Access time 8.3 milli-seconds. Every track had a magnetic head so you could get very quick access to any of the data. If you put two heads on the same track you could get much shorter access by just recirculating your data between them. Now, not only did this program lead in advancing magnetic drum technology and low end computer design but was a key source of trained students for the nascent computer industry as commercial efforts expanded. Student colleagues of mine who also went on to IBM and worked on the RAMAC included Lou Stevens and John Haanstra. This Berkeley computer project proceeded the formation of the San Jose Laboratory under Rey Johnson). This early work at Berkeley focused on a magnetic drum but the same digital magnetic recording techniques have much in common with other implementations of what I will call direct access data storage such as the magnetic disk. Now, how were things going to change? I will give you a little historical perspective here. Business data processing was a growing area. Magnetic tape made inroads into paper tape and punch cards. However, it also was a sequential medium and therefore the mode was still batch data processing. However, there was a growing interest in being able to do transaction processing. For example, in inventory control you could update all the records affected by a sale immediately (invoice, stock status, shipping order, etc) rather than sorting and running against a master tape. What was needed were the functional features associated with a magnetic drum but with a very high capacity at a reasonable cost. It is clear why such developments would be driven by computer systems companies, such as IBM, Univac, NCR, etc This chart is probably not readable as projected but was done by Bill Turner of IBM about thirty some years ago. I will use words to give you its message, Rey Johnson came to San Jose in 1952. I was invited to consult at his new Laboratory while a graduate student because of my on going magnetic recording work at Berkeley. In 1956 I went to work full time for Rey. He was a tremendously creative guy who loved to explore new ideas. What I am trying to say is Rey was great at exploratory research and he was a wonderful guy to work for, particularly if you had any ideas you wanted to work on. But the down side was if you wanted to get a product out. He protected his advance technology projects and resources. One of the things that struck me when I came into the Lab was that I saw this tremendous challenge and opportunity of the RAMAC project and only a small group of people assigned to make it happen. Then I walked to the other rooms and saw a whole bunch of people doing a lot of weird exotic things. And Rey was already starting to put in place a storage device to be much more advanced than the RAMAC. Rey got a lot of things started, and then other people would take over to provide the follow through. This turned out to be a very advantageous situation because Rey was able to create a lot of new project activity that really set the long range directions for the next generations of disk drives

In keeping with this spirit, the ADF program about which I will comment later was initiated and led by Rey well before the RAMAC was even announced. In fact this chart shows the number of design evolutions started before the first product had succeeded in the marketplace.

Again, you didn't design disk drives as consumer products. They needed to be integrated into systems and IBM was the primary mover in the computer systems market place. There were other company efforts but IBM disk drive products were the mainstream standard and the ones that carried the industry for many years. For that reason I am focusing on their activities in the period this talk is covering. This shows the air pressurized head used on the RAMAC. This is the only device I brought with me to this Conference, actually the only item I kept over the years since I was intimately involved in this magnetic head design. In those days it was hard to find a component you could carry in your pocket and show. Actually it is close to the size of the new IBM microdrive. This head has a little nozzle on it and a plastic tube carrying pressurized air to keep the head off the disk. The force of the pressurized air counterbalanced a force loading the head towards the disk and the spacing was set at the point these two forces were in equilibrium The cost and complexity of an air compressor and head assembly to operate heads this way led to the use of a single head pair for the disk stack. Before the RAMAC program was even announced, Rey was heading up an advanced file program called the ADF. This program was exceedingly important for a number of reasons. The basic design, with a head per surface was really the optimum way to design a disk drive in terms of access time and modularity. The capacity objective for the ADF was ten times that of RAMAC. The much larger capacity with an access time almost one tenth that of the RAMAC (due to reducing head positioning to only one dimension) opened up dramatically the applications that could be considered. The first major commercial test was the American Airlines reservation system which would for the first time upgrade a data processing system to a geographically dispersed real time transaction processing capability.

The first model of the ADF was to be shipped with the Stretch computer, a major step forward in scientific computers committed to the government by IBM. And the ADF was a critical component to achieve the performance specifications. IBM bet its credibility on meeting the schedule for this super computer. Every lab in IBM had their particular component responsibilities for this system and San Jose, of course, had the disk drive. San Jose being the newest Lab and the ADF disk drive being a major challenge placed the Lab under an unusual degree of pressure. The greatest exposure was that this drive involved three entirely new technologies for a disk drive. First, the use of flying heads (heads that did not require an air supply) . Second, a hydraulic actuator was selected to deal with the heavy head-arm assembly required by a head/surface design. Third, the choice of vertical (or perpendicular) recording based on the desire to have a much harder magnetic surface than that of the coated iron oxide then being used on disks. There were concerns about head/disk contact and the damage it would do and the idea of using an oxidized steel disk appeared to be a solution. Since under the oxidized layer the steel was soft magnetically, vertical recording was then possible and vertical head structures were a obvious choice to consider as well as appearing potentially cheaper than the longitudinal type of head. The ADF was like starting anew, there being almost no relation to the RAMAC technologies. The only thing that was really common was the disk diameter.