{
    "id": "dbpedia_1087_0",
    "rank": 98,
    "data": {
        "url": "https://www.pbs.org/wgbh/frontline/documentary/facebook-dilemma/transcript/",
        "read_more_link": "",
        "language": "en",
        "title": "The Facebook Dilemma",
        "top_image": "https://www.pbs.org/wgbh/frontline/wp-content/uploads/2023/03/3704_Mark_FB_Grabs007.jpg",
        "meta_img": "https://www.pbs.org/wgbh/frontline/wp-content/uploads/2023/03/3704_Mark_FB_Grabs007.jpg",
        "images": [
            "https://www.pbs.org/wgbh/frontline/wp-content/uploads/2024/08/4304_SG_013-300x169.jpg",
            "https://www.pbs.org/wgbh/frontline/wp-content/uploads/2024/08/4304_SG_013-510x290.jpg",
            "https://www.pbs.org/wgbh/frontline/wp-content/themes/fl-responsive-theme/library/images/fljs.png",
            "https://www.pbs.org/wgbh/frontline/wp-content/themes/fl-responsive-theme/library/images/pbs_logo.png",
            "https://www.pbs.org/wgbh/frontline/wp-content/themes/fl-responsive-theme/library/images/cpb_logo.png",
            "https://www.pbs.org/wgbh/frontline/wp-content/themes/fl-responsive-theme/library/images/abrams_logo_2022.png",
            "https://www.pbs.org/wgbh/frontline/wp-content/themes/fl-responsive-theme/library/images/park_logo_new.png",
            "https://www.pbs.org/wgbh/frontline/wp-content/themes/fl-responsive-theme/library/images/macarthur_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "patrice_taddonio@wgbh.org"
        ],
        "publish_date": "2018-10-29T20:51:56+00:00",
        "summary": "",
        "meta_description": "Watch FRONTLINE's documentary investigating how Facebook’s relentless pursuit of growth impacted privacy and democracy in the U.S. and around the world.",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "FRONTLINE",
        "canonical_link": "https://www.pbs.org/wgbh/frontline/documentary/facebook-dilemma/transcript/",
        "text": "PART I\n\nYOUNG MAN:\n\nAre we good?\n\nMARK ZUCKERBERG, Founder and CEO, Facebook:\n\nShould I put the beer down?\n\nYOUNG MAN:\n\nNo, no. Actually, I’m going to mention the beer.\n\nYOUNG MAN:\n\nHard at work.\n\nJune 2005\n\nYOUNG MAN:\n\nSo I’m here in Palo Alto, California, chilling with Mark Zuckerberg of the Facebook.com and we’re drinking out of a keg of Heineken because… What are we celebrating, Mark?\n\nMARK ZUCKERBERG:\n\nWe just got 3 million users.\n\nGROUP:\n\nEleven, 12, 13. Woo!\n\nYOUNG MAN:\n\nTell us, you know, simply what Facebook is.\n\nMARK ZUCKERBERG:\n\nI think Facebook is an online directory for colleges. I realized that because I didn’t have people’s information, I needed to make it interesting enough so that people would want to use the site and want to, like, put their information up. So we launched it at Harvard and within a couple of weeks two-thirds of the school had signed up. So we were like, all right, this is pretty sweet. Like, let’s just go all out. It’s just interesting seeing how it evolves. We have a sweet office.\n\nYOUNG MAN:\n\nYeah. Well, show us, show us around the crib.\n\nMARK ZUCKERBERG:\n\nWe didn’t want cubicles, so we got IKEA kitchen tables instead. I thought that kind of went along with our whole vibe here.\n\nYOUNG MAN:\n\nWhat’s in the fridge?\n\nMARK ZUCKERBERG:\n\nSome stuff. There’s some beer down there.\n\nYOUNG MAN:\n\nHow many people work for you?\n\nMARK ZUCKERBERG:\n\nIt’s actually 20 right now.\n\nYOUNG MAN:\n\nDid you get this shot? This one here, of the lady riding a pit bull.\n\nYOUNG MAN:\n\nOh, nice.\n\nMARK ZUCKERBERG:\n\nThat’s, that’s really all I’ve got.\n\nYOUNG MAN:\n\nAnd where are you taking Facebook at this point in your life?\n\nMARK ZUCKERBERG:\n\nI mean, there doesn’t necessarily have to be more.\n\nROGER MCNAMEE, Early Facebook investor:\n\nFrom the early days, Mark had this vision of connecting the whole world. So if Google was about providing you access to all the information, Facebook was about connecting all the people.\n\nINTERVIEWER:\n\nCan you just say your name and pronounce it so nobody messes it up and they have it on tape if they…\n\nMARK ZUCKERBERG:\n\nSure. It’s Mark Zuckerberg.\n\nINTERVIEWER:\n\nGreat.\n\nROGER MCNAMEE:\n\nIt was not crazy. Somebody was going to connect all those people. Why not him?\n\nFEMALE EMCEE:\n\nWe have our Facebook Fellow. We have Mark Zuckerberg.\n\nMALE EMCEE:\n\nI have the pleasure of introducing Mark Zuckerberg, founder of Facebook.com.\n\nMARK ZUCKERBERG:\n\nYo.\n\nROGER MCNAMEE:\n\nWhen Mark Zuckerberg was at Harvard, he was fascinated by hacker culture, this notion that software programmers could do things that would shock the world.\n\nMARK ZUCKERBERG:\n\nAnd a lot of times people are just, like, too careful. I think it’s more useful to, like, make things happen and then, like, apologize later than it is to make sure that you dot all your i’s now and then, like, just not get stuff done.\n\nROGER MCNAMEE:\n\nSo it was a little bit of a renegade philosophy and a disrespect for authority that led to the Facebook motto, “move fast and break things.”\n\nWOMAN:\n\nNever heard of Facebook?\n\nFEMALE STUDENT:\n\nOur school went crazy for the Facebook.\n\nMALE STUDENT:\n\nIt creates its own world that you get sucked into.\n\nMARK ZUCKERBERG:\n\nWe started adding things like status updates and photos and groups and apps. When we first launched, we were hoping for, you know, maybe 400, 500 people.\n\nMAN:\n\nHere’s to the first 100 million and the next 100 million.\n\nMARK ZUCKERBERG:\n\nCool.\n\nINTERVIEWER:\n\nSo you’re motivated by what?\n\nMARK ZUCKERBERG:\n\nBuilding things that, you know, change the world in a, in, in a way that it needs to be changed.\n\nPRESIDENT BARACK OBAMA:\n\nWho is Barack Obama? The answer is right there on my Facebook page.\n\nTHE SIMPSONS:\n\nMr. Zuckerberg. ’Sup, Zuck?\n\nROGER MCNAMEE:\n\nIn those days, “move fast and break things” didn’t seem to be sociopathic.\n\nMARK ZUCKERBERG:\n\nIf you’re building a product that people love, you can make a lot of mistakes.\n\nROGER MCNAMEE:\n\nIt wasn’t that they intended to do harm so much as they were unconcerned about the possibility that harm would result.\n\nINTERVIEWER:\n\nSo just to be clear, you’re not going to sell or share any of the information on Facebook?\n\nMARK ZUCKERBERG:\n\nWe’re not going to share people’s information, except for with the people that they’ve asked for it to be shared.\n\nROGER MCNAMEE:\n\nTechnology optimism was so deeply ingrained in the value system and in the beliefs of people in Silicon Valley…\n\nMARK ZUCKERBERG:\n\nWe’re here for a hackathon. So let’s get started.\n\nROGER MCNAMEE:\n\n…that they’d come to believe it as akin to the law of gravity – that, of course, technology makes the world a better place. It always had, it always will. And that assumption, essentially, masked a set of changes that were going on in the culture that were very dangerous.\n\nNEWS REPORT:\n\nFrom KXJZ in Sacramento…\n\nNEWS REPORT:\n\nFrom Monday June 27…\n\nNARRATOR:\n\nMark Zuckerberg’s quest to connect the world would bring about historic change and far-reaching consequences in politics, privacy and technology. We’ve been investigating warning signs that existed long before problems burst into public view.\n\nMARK ZUCKERBERG:\n\nIt was my mistake and I’m sorry.\n\nNARRATOR:\n\nBut for those inside Facebook, the story began with an intoxicating vision that turned into a lucrative business plan.\n\nMIKE HOEFFLINGER, Facebook Director of Global Business Marketing, 2009-2015:\n\nWell, the one thing that Mark Zuckerberg has been so good at is being incredibly clear and compelling about the mission that Facebook has always had.\n\nMARK ZUCKERBERG:\n\nFacebook’s mission is to give people the power to share… Give people the power to share… In order to make the world more open and connected… More open and connected… Open and connected… More open and connected.\n\nJAMES JACOBY, Correspondent:\n\nHow pervasive a mission was that inside of the company? Give me a sense of that.\n\nMIKE HOEFFLINGER:\n\nIt was something that, you know, Mark doesn’t just say when we do, you know, ordered calisthenics in the morning and we yell the mission to each other. Right? We would actually say it to each other, you know, when Mark wasn’t around.\n\nJAMES JACOBY:\n\nAnd that was a mission that you really believed in?\n\nELIZABETH LINDER, Facebook Politics and Government Specialist, 2008-2016:\n\nHow could you not? How exciting! What if connecting the world actually delivered a promise that we’ve been looking for to genuinely make the world a better place?\n\nJAMES JACOBY:\n\nWas there ever a point where there was questions internally about this mission being naive optimism?\n\nMIKE HOEFFLINGER:\n\nI think the short answer is completely yes, and I think that’s why we loved it, especially in a moment like when we crossed a billion monthly active users for the first time. And Mark’s… The, the way I recall Mark at the time, I remember thinking: I don’t think Mark is going to stop until he gets to everybody.\n\nTIM SPARAPANI, Facebook Director of Public Policy, 2009-2011:\n\nI think some of us had an early understanding that we were creating, in some ways, a digital nation-state. This was the greatest experiment in free speech in human history.\n\nSANDY PARAKILAS, Facebook Platform Operations Manager, 2011-2012:\n\nThere was a sense inside the company that we are building the future and there was a real focus on youth being a good thing.\n\nIt was not a particularly diverse workforce. It was very much the sort of Harvard, Stanford, Ivy League group of people who were largely in their 20s.\n\nANTONIO GARCÍA MARTÍNEZ, Facebook Product Manager, 2011-2013:\n\nI was a big believer in the company. Like I, I knew that it was going to be a paradigm-shifting thing. There was this, definitely this feeling of everything for the company, of this, you know, world-stirring vision. Everyone more or less dressed with the same fleece and swag with logo on it. Posters on the wall that looked somewhat Orwellian, but of course, you know, on a, in an upbeat way, obviously. And then, you know, some of the slogans are pretty well-known. “Move fast and break things.” “Fortune favors the bold.” “What would you do if you weren’t afraid?” You know, it was always this sort of rousing rhetoric that would push you to, to go further.\n\nNARRATOR:\n\nAntonio García Martínez, a former product manager on Facebook’s advertising team, is one of eight former Facebook insiders who agreed to talk on camera about their experiences.\n\nANTONIO GARCÍA MARTÍNEZ:\n\nIn Silicon Valley, there's a, you know, almost a Mafioso code of silence that you're not supposed to talk about the business in, in any but the most flattering way. Right? Basically, you can't say anything, you know, measured or truthful about the business. And I think, as perhaps with Facebook, it's kind of arrived at the point in which it's so important, it needs to be a little more transparent about how it works. Like, let's stop a little bulls--- parade about everyone in Silicon Valley, you know, creating, disrupting this, and improving the world. Right? It's, in many ways, a business like any other. It's just kind of more exciting and impactful.\n\nNARRATOR:\n\nBy 2007, Zuckerberg had made it clear that the goal of the business was worldwide expansion.\n\nMARK ZUCKERBERG:\n\nAlmost a year ago, when we were first discussing how to let everyone in the world into Facebook, I remember someone said to me, “Mark, we already have nearly every college student in the U.S. on Facebook. It’s incredible that we were even able to do that. But no one gets a second trick like that.” Well, let’s take a look at how we did.\n\nJAMES JACOBY:\n\nWhat was the Growth team about? What did you do at Growth?\n\nNAOMI GLEIT, Facebook Vice President of Social Good:\n\nThe story of Growth has really been about making Facebook available to people that wanted it but couldn’t have access to it.\n\nNARRATOR:\n\nNaomi Gleit, Facebook’s second-longest-serving employee, is one of five officials the company put forward to talk to FRONTLINE. She was an original member of the Growth team.\n\nNAOMI GLEIT:\n\nOne of my first projects was expanding Facebook to high school students. I worked on translating Facebook into over 100 languages. When I joined, there were 1 million users and now there’s over 2 billion people using Facebook every month.\n\nJAMES JACOBY:\n\nSome of the problems that have reared their head with Facebook over the past couple of years seemed to have been caused in some ways by this exponential growth.\n\nNAOMI GLEIT:\n\nSo I think Mark, and Mark has said this, that we have been slow to really understand the ways in which Facebook might be used for bad things. We’ve been really focused on the good things.\n\nMARK ZUCKERBERG:\n\nSo who are all of these new users?\n\nSANDY PARAKILAS:\n\nThe Growth team had tons of engineers figuring out how you could make the new user experience more engaging, how you could figure out how to get more people to sign up. Everyone was focused on growth, growth, growth.\n\nMARK ZUCKERBERG:\n\nGive people the power to share.\n\nNARRATOR:\n\nAnd the key to keeping all these new people engaged…\n\nMARK ZUCKERBERG:\n\n…a lot more open and connected.\n\nNARRATOR:\n\n…was Facebook’s most important feature…\n\nMARK ZUCKERBERG:\n\nNews Feed.\n\nNARRATOR:\n\n…News Feed, the seemingly endless stream of stories, pictures and updates shared by friends, advertisers and others.\n\nMARK ZUCKERBERG:\n\nIt analyzes all the information available to each user and it actually computes what’s going to be the most interesting piece of information and publishes a little story for them.\n\nANTONIO GARCÍA MARTÍNEZ:\n\nIt's your personalized newspaper. It's your The New York Times of You, Channel You. It is, you know, your customized, optimized vision on the world.\n\nNARRATOR:\n\nBut what appeared in users’ News Feed wasn’t random. It was driven by a secret mathematical formula, an algorithm.\n\nMARK ZUCKERBERG:\n\nThe stories are ranked in terms of what’s going to be the most important. And we design a lot of algorithms so we can produce interesting content for you.\n\nSANDY PARAKILAS:\n\nThe goal of the News Feed is to provide you, the user, with the content on Facebook that you most want to see. It is designed to make you want to keep scrolling, keep looking, keep Liking.\n\nANTONIO GARCÍA MARTÍNEZ:\n\nThat's the key. That's the secret sauce. That's how, that's why we're worth X billion dollars.\n\nNARRATOR:\n\nThe addition of the new Like button in 2009 allowed News Feed to collect vast amounts of users’ personal data that would prove invaluable to Facebook.\n\nSOLEIO CUERVO, Facebook Product Designer, 2005-2011:\n\nAt the time, we were a little bit skeptical about the Like button. We were concerned. And as it turned out, our intuition was just dead wrong. And what we found was that the Like button acted as a social lubricant. And of course, it was also driving this flywheel of engagement that people felt like they were heard on the platform whenever they shared something.\n\nMARK ZUCKERBERG:\n\nConnect to it by Liking it\n\nSOLEIO CUERVO:\n\nAnd it became a driving force for the product.\n\nMIKE HOEFFLINGER:\n\nIt was incredibly important because it allowed us to understand: Who are the people that you care more about that cause you to react? And who are the businesses, the pages, the other interests on Facebook that are important to you? And that gave us a degree of constantly increasing understanding about people.\n\nMARK ZUCKERBERG:\n\nNews Feed got off to a bit of a rocky start, and now our users love News Feed. They love it.\n\nNARRATOR:\n\nNews Feed’s exponential growth was spurred on by the fact that existing laws didn’t hold internet companies liable for all the content being posted on their sites.\n\nTIM SPARAPANI:\n\nSo Section 230 of the Communications Decency Act is the provision which allows the internet economy to grow and thrive. And Facebook is one of the principal beneficiaries of this provision. It says: Don’t hold this internet company responsible if some idiot says something violent on the site. Don’t hold the internet company responsible if somebody publishes something that creates conflict, that, that violates the law. It’s the quintessential provision that allows them to say, “Don’t blame us.”\n\nNARRATOR:\n\nSo it was up to Facebook to make the rules, and inside the company they made a fateful decision.\n\nTIM SPARAPANI:\n\nWe took a very libertarian perspective here. We allowed people to speak. And we said if you're going to incite violence, that's clearly out of bounds. We're going to kick you off immediately. But we're going to allow people to go right up to the edge and we're going to allow other people to respond.\n\nWe had to set up some ground rules. Basic decency, no nudity and no violent or hateful speech. And after that, we felt some reluctance to interpose our value system on this worldwide community that was growing.\n\nJAMES JACOBY:\n\nWas there not a concern, then, that it could come, become sort of a place of just utter confusion; that you have lies that are given the same weight as truths; and that it kind of just becomes a place where truth becomes completely obfuscated?\n\nTIM SPARAPANI:\n\nNo. We relied on what we thought were the public’s common sense and common decency to police the site.\n\nNARRATOR:\n\nThat approach would soon contribute to real-world consequences far from Silicon Valley, where Mark Zuckerberg’s optimistic vision at first seemed to be playing out.\n\nCAIRO, EGYPT 2011\n\nNARRATOR:\n\nThe Arab Spring had come to Egypt.\n\nDEMONSTRATORS:\n\n[subtitles] We will sacrifice our lives for our nation.\n\nNARRATOR:\n\nIt took hold with the help of a Facebook page protesting abuses by the regime of Hosni Mubarak.\n\nWAEL GHONIM, Arab Spring activist:\n\nNot that I was thinking that this Facebook page was going to be effective. I just did not want to look back and say that happened and I just didn’t do anything about it.\n\nNARRATOR:\n\nAt the time, Wael Ghonim was working for Google in the Middle East.\n\nWAEL GHONIM:\n\nIn just three days over 100,00 people joined the page. Throughout the next few months the page was growing until what happened in Tunisia.\n\nNEWS REPORT:\n\nEvents in Tunisia have captured the attention of viewers around the world and a lot of it was happening online.\n\nNEWS REPORT:\n\nIt took just 28 days to the fall of the regime.\n\nWAEL GHONIM:\n\nAnd it just created for me a moment of maybe we can do this. And I just posted an event calling for a revolution in 10 days. Like, we should all get to the street and we should all bring down Mubarak.\n\nNEWS REPORT:\n\nOrganized by a group of online activists…\n\nNEWS REPORT:\n\nThey’re calling it the Facebook Revolution.\n\nNARRATOR:\n\nWithin days, Ghonim’s online cry had helped fill the streets of Cairo with hundreds of thousands of protesters. Eighteen days later…\n\nNEWS REPORT:\n\nPresident Muhammad Hosni Mubarak has decided to step down.\n\nNEWS REPORT:\n\nThey have truly achieved the unimaginable.\n\nDEMONSTRATOR:\n\n[subtitles] I love Facebook! We are the youth of Facebook!\n\nNEWS REPORT:\n\nIt’s generally acknowledged that Ghonim’s Facebook page first sparked the protests.\n\nJAMES JACOBY:\n\nThere was a moment that you were being interviewed on CNN.\n\nWAEL GHONIM:\n\nYeah, I remember that.\n\nWOLF BLITZER, CNN:\n\nFirst Tunisia, now Egypt. What’s next?\n\nWAEL GHONIM:\n\nAsk Facebook.\n\nWOLF BLITZER:\n\nAsk what?\n\nWAEL GHONIM:\n\nFacebook.\n\nWOLF BLITZER:\n\nFacebook.\n\nWAEL GHONIM:\n\nThe technology was, for me, the enabler. I would have not have been able to engage with others. I would have not been able to propagate my ideas to others without social media, without Facebook.\n\nWOLF BLITZER:\n\nYou’re giving Facebook a lot of credit for this?\n\nWAEL GHONIM:\n\nYeah, for sure. I want to meet Mark Zuckerberg one day and thank him, actually.\n\nTHREE MONTHS LATER\n\nINTERVIEWER:\n\nHave you ever think that this could have an impact on revolution?\n\nMARK ZUCKERBERG:\n\nYou know, my own opinion is that it would be extremely arrogant for any specific technology company to claim any meaningful role in, in those. But I, I do think that the overall trend that’s at play here, which is people being able to share what they want with the people who they want, is an extremely powerful thing. Right? And, and we’re kind of fundamentally rewiring the world from the ground up. And it starts with people…\n\nSANDY PARAKILAS, Facebook Platform Operations Manager, 2011-2012:\n\nThey were relatively restrained externally about taking credit for it but internally they were, I would say, very happy to take credit for the idea that social media is being used to effect democratic change.\n\nELIZABETH LINDER, Facebook Politics and Government Specialist, 2008-2016:\n\nActivists and civil society leaders would just come up to me and say, you know, “Wow, we couldn’t have done this without you guys.” Government officials, you know, would say, “Does Facebook really realize how much you guys are changing our societies?”\n\nTIM SPARAPANI, Facebook Director of Global Public Policy, 2009-2011:\n\nIt felt like Facebook had extraordinary power and power for good.\n\nNARRATOR:\n\nBut while Facebook was enjoying its moment, back in Egypt on the ground and on Facebook, the situation was unraveling.\n\nWAEL GHONIM:\n\nFollowing the revolution, things went into a much worse direction than what we have anticipated.\n\nNEWS REPORT:\n\nThere’s a complete split between the civil community and those who are calling for an Islamic state.\n\nWAEL GHONIM:\n\nWhat was happening in Egypt was polarization.\n\nNEWS REPORT:\n\n…deadly clashes between Christians and military police.\n\nDEMONSTRATOR:\n\n[voice of translator] The Brotherhood cannot rule this country.\n\nWAEL GHONIM, Arab Spring activist:\n\nAnd all these voices started to clash. And the environment on social media breeded that kind of clash, like that polarization, rewarded it.\n\nZEYNEP TUFEKCI, UNC Chapel Hill:\n\nWhen the Arab Spring happened, I know that a lot of people in Silicon Valley thought our technologies helped bring freedom to people, which was true. But there's a twist to this, which is Facebook's News Feed algorithm.\n\nWAEL GHONIM:\n\nIf you increase the tone of your posts against your opponents, you are going to get more distribution.\n\nBecause we tend to be more tribal. So if I call my opponents names, my tribe is happy and celebrating. “Yes, do it. Like. Comment. Share.” So more people end up seeing it because the algorithm is going to say: Oh, okay, that’s engaging content, people like it. Show it to more people.\n\nNEWS REPORT:\n\nThere were also other groups of thugs, part of the patterns of sectarian violence.\n\nWAEL GHONIM:\n\nThe hardest part for me was seeing the tool that brought us together tearing us apart. These tools are just enablers for whomever. They, they don’t separate between what’s good and bad. They just look at engagement metrics.\n\nNARRATOR:\n\nGhonim himself became a victim of those metrics.\n\nWAEL GHONIM:\n\nThere was a page – it had like hundreds of thousands of followers. All what it did was creating fake statements. And I was a victim of that page.\n\n[subtitle] Wael is a spy for the Israeli intelligence.\n\nWAEL GHONIM:\n\nThey wrote statements about me insulting the army, which puts me at serious risk because that is not something I said. I was extremely naive in way I don’t like, actually, now, thinking that these are liberating tools.\n\nIt’s the spread of misinformation, fake news, in Egypt in 2011.\n\nNARRATOR:\n\nHe says he later talked to people he knew at Facebook and other companies about what was going on.\n\nWAEL GHONIM:\n\nI tried to talk to people who are in Silicon Valley, but I feel like it was not, it was not being heard.\n\nJAMES JACOBY:\n\nWhat were you trying to express to people in Silicon Valley at the time?\n\nWAEL GHONIM:\n\nIt’s very serious. Whatever that we, that you are building has massive, serious intend-, in-, unintended consequences on the lives of people on this planet. And you are not investing enough in trying to make sure that what you are building does not go in the wrong way.\n\nAnd it's very hard to be in their position. No matter how they try and move and change things, there will be always unintended consequences.\n\nELIZABETH LINDER:\n\nActivists in my region were on the front lines of, you know, spotting corners of Facebook that the rest of the world, the rest of the company, wasn't yet talking about because in a company that's built off numbers and metrics and measurements, anecdotes sometimes got lost along the way. And that was always a real challenge and, and always bothered me.\n\nNARRATOR:\n\nElizabeth Linder, Facebook’s representative in the region at the time, was also hearing warnings from government officials.\n\nELIZABETH LINDER:\n\nSo many country representatives were expressing to me a huge concern about the ability of rumors to spread on Facebook. And, and what do you do about that?\n\nJAMES JACOBY:\n\nHow did you respond to that at the time?\n\nELIZABETH LINDER:\n\nWe, we didn’t have a solution for it. And so the best that I could do is report back to headquarters that this is something that I was hearing on the ground.\n\nJAMES JACOBY:\n\nAnd what sort of response would you get from headquarters?\n\nELIZABETH LINDER:\n\nYou know, I… It's impossible to be specific about that because it was always just kind of a ‘this is what I'm hearing, this is what's going on.’ But I think in a, in a company where the, the, the, the, the people that could have actually, you know, had an impact on making those decisions are not necessarily seeing it firsthand.\n\nZEYNEP TUFEKCI:\n\nI think everything that happened after the Arab Spring should have been a warning sign to Facebook.\n\nNARRATOR:\n\nZeynep Tufekci, a researcher and former computer programmer, had also been raising alarms to Facebook and other social media companies.\n\nZEYNEP TUFEKCI:\n\nThese companies were terribly understaffed, in over their heads in terms of the important role they were playing. Like all of a sudden, you're the public sphere in Egypt. So I kept starting to talk to my friends at these companies and saying, “You have to staff up and you have to put in large amounts of people who speak the language, who understand the culture, who understand the complexities of wherever you happen to operate.”\n\nNARRATOR:\n\nBut Facebook hadn’t been set up to police the amount of content coming from all the new places it was expanding to.\n\nTIM SPARAPANI:\n\nI think no one at any of these companies in Silicon Valley has the resources for this kind of scale. You had queues of work for people to go through and hundreds of employees who would spend all day, every day, clicking yes, no, keep, take down, take down, take down, keep up, keep up. Making judgment calls, snap judgment calls about: Does it violate our terms of service? Does it violate our standards of decency? What are the consequences of this speech? So you have this fabulously talented group of mostly 20-somethings who are deciding what speech matters, and they're doing it in real time, all day, every day.\n\nJAMES JACOBY:\n\nIsn’t that scary?\n\nTIM SPARAPANI:\n\nIt’s terrifying. Right? The responsibility was awesome. No one could ever have predicted how fast Facebook would grow. The, the trajectory of growth of the user base and of the issues was like this. And of all, all staffing throughout the company was like this. The company was trying to make money. It was trying to keep costs down. It had to be a, a, a going concern. It had to be a revenue-generating thing or it would cease to exist.\n\nNARRATOR:\n\nIn fact, Facebook was preparing to take its rapidly growing business to the next level by going public.\n\nDAVID EBERSMAN, Facebook Chief Financial Officer, 2009-2014:\n\nI’m David Ebersman, Facebook’s CFO. Thank you for taking the time to consider an investment in Facebook.\n\nNEWS REPORT:\n\nThe social media giant hopes to raise $5 billion.\n\nMIKE HOEFFLINGER, Facebook Director of Global Business Marketing, 2009-2015:\n\nThe pressure heading into the IPO, of course, was to prove that Facebook was a great business. Otherwise we’d have no shareholders.\n\nNEWS REPORT:\n\nFacebook – is it worth $100 billion? Should it be valued at that?\n\nNARRATOR:\n\nZuckerberg’s challenge was to show investors and advertisers the profit that could be made from Facebook’s most valuable asset – the personal data it had on its users.\n\nMIKE HOEFFLINGER:\n\nMark, great as he was at vision and product, he had very little experience in building a big advertising business.\n\nNARRATOR:\n\nThat would be the job of Zuckerberg’s deputy, Sheryl Sandberg, who’d done the same for Google.\n\nSHERYL SANDBERG, Facebook Chief Operating Officer:\n\nAt Facebook we have a broad mission: We want to make the world more open and connected\n\nROGER MCNAMEE, Early Facebook investor:\n\nThe business model we see today was created by Sheryl Sandberg and the team she built at Facebook, many of whom had been with her at Google.\n\nNARRATOR:\n\nPublicly, Sandberg and Zuckerberg had been downplaying the extent of the personal data Facebook was collecting and emphasizing users’ privacy.\n\nNovember 2011\n\nSHERYL SANDBERG:\n\nWe are focused on privacy. We care the most about privacy. Our business model is, by far, the most privacy-friendly to consumers.\n\nMARK ZUCKERBERG:\n\nThat’s our mission. Right? I mean, we, we have to do that because if people feel like they don’t have control over how they’re sharing things, then, then we’re failing them.\n\nSHERYL SANDBERG:\n\nIt really is the point that the only things Facebook knows about you are things you’ve done and told us.\n\nNARRATOR:\n\nBut internally, Sandberg would soon lead Facebook in a very different direction.\n\nANTONIO GARCÍA MARTÍNEZ, Facebook Product Manager, 2011-2013:\n\nThere was a meeting – I think it was in March of 2012 – in which, you know, it was everyone who built stuff inside ads, myself among them. And you know, she basically recited the reality, which is, revenue was flattening. It wasn’t slow, it wasn’t declining, but it wasn’t growing nearly as fast as investors would have guessed. So she basically said, like, we have to do something. You people have to do something. And so there was a big effort to basically pull out all the stops and start experimenting way more aggressively.\n\nThe reality is, like, yeah, Facebook has a lot of personal data – your chat with your girlfriend or boyfriend, your drunk party photos from college, etc. The reality is that none of that is actually valuable to any marketer. They want commercially interesting data. You know, what products did you take off the shelf at Best Buy? What did you buy in your last grocery run? Did it include diapers? Do you have kids? Are you a head of household? Right? It’s things like that, things that exist in the outside world that just do not exist inside Facebook at all.\n\nNARRATOR:\n\nSandberg’s team started developing new ways to collect personal data from users wherever they went on the internet, and when they weren’t on the internet at all.\n\nTIM SPARAPANI, Facebook Director of Global Public Policy, 2009-2011:\n\nAnd so there's this extraordinary thing that happens that doesn't get much attention at the time. About four or five months before the IPO, the company announces its first relationship with data broker companies, companies that most Americans aren't at all aware of, that go out and buy up data about each and every one of us: what we buy, where we shop, where we live, what our traffic patterns are, what our families are doing, what our likes are, what magazines we read – data that the consumer doesn’t even know that’s being collected about them because it’s being collected from the rest of their lives by companies they don’t know. And it’s now being shared with Facebook so that Facebook can target ads back to the user.\n\nZEYNEP TUFEKCI, UNC Chapel Hill:\n\nWhat Facebook does is profile you. If you’re on Facebook it’s collecting everything you do. If you’re off Facebook, it’s using tracking pixels to collect what you are browsing. And for its micro-targeting to work, for its business model to work, it has to remain a surveillance machine.\n\nROGER MCNAMEE:\n\nThey made a product that was a better tool for advertisers than anything that had ever come before it.\n\nTIM SPARAPANI:\n\nAnd of course, the ad revenue spikes. That change alone, I think, is a sea change in the way the company felt about its future and the direction it was headed.\n\nNARRATOR:\n\nSparapani was so uncomfortable with the direction Facebook was going, he left before the company’s work with data brokers took effect.\n\nVIENNA, AUSTRIA\n\nNARRATOR:\n\nThe extent of Facebook’s data collection was largely a secret until a law student in Austria had a chance encounter with a company lawyer.\n\nMAX SCHREMS, Privacy advocate:\n\nI kind of wanted a semester off so I actually went to California to Santa Clara University in the Silicon Valley. And someone from Facebook was a guest speaker explaining to us basically how they deal with European privacy law. And the general understanding was you can do whatever you want to do in Europe because they do have data protection laws but they don’t really enforce them at all.\n\nSo I sent an email to Facebook saying I want to have a copy of all my data.\n\nSo I got from Facebook about 1,200 pages and I read through it.\n\nIn my personal file I think the most sensitive information was my messages. For example, a friend of mine was in the closed unit of the, of a psychological hospital in, in Vienna. I deleted all these messages but all of them came back up. And you have messages about, you know, love life and sexuality. And all of that is kept.\n\nFacebook tries to give you the impression that you share this only with friends. The reality is Facebook is always looking. There is a data category called “last location,” where they store where they think you’ve been the last time.\n\nIf you tag people in pictures, there’s GPS location, so by that they know which person has been in what place at what time. Back on the servers, there is like a treasure trove just like 10 times as big as anything we ever see on the screen.\n\nNARRATOR:\n\nAs Facebook was ramping up its data collection business ahead of the IPO, Schrems filed 22 complaints with the Data Protection Commission in Ireland, where Facebook has its international headquarters.\n\nMAX SCHREMS:\n\nAnd they had 20 people at the time over a little supermarket in a small town. It’s called Portarlington. It’s 5,000 people in the middle of nowhere. And they were meant to “regulate” Google or Facebook or LinkedIn and all of them.\n\nNARRATOR:\n\nSchrems claimed Facebook was violating European privacy law in the way it was collecting personal data and not telling users what they were doing with it.\n\nMAX SCHREMS:\n\nAnd after we filed these complaints, that was when, actually, Facebook reached out. Basically, say, you know, let’s sit down and have a coffee and talk about all of this.\n\nSo we actually had a little kind of notable meeting that was in 2012 at the airport in Vienna. But the interesting thing is that most of these points, they simply didn’t have an answer. You totally saw that their pants were down.\n\nHowever, at a certain point, I just got a text message from the data protection authority saying they’re not available to speak to me anymore. That was how this procedure basically ended. Facebook knew that the system plays in their favor, so even if you violate the law, the reality is it’s, it’s very likely not going to be enforced.\n\nNARRATOR:\n\nFacebook disputed Schrems’ claims and said it takes European privacy laws seriously. It agreed to make its policies clearer and stop storing some kinds of user data.\n\nKARA SWISHER AND WALT MOSSBERG:\n\nSo without further ado, Mark Zuckerberg.\n\nNARRATOR:\n\nIn Silicon Valley, those who covered the tech industry had also been confronting Facebook about how it was handling users’ personal data.\n\nKARA SWISHER, Executive Editor, Recode Media:\n\nPrivacy was my number one concern back then. So when we were thinking about talking to Mark, the platform was an issue. There were always a bunch of privacy violations. And that was what we wanted to talk to him about.\n\nIs there a level of privacy that just has to apply to everyone? Or do you think… I mean, you might have a view of: This is what privacy means to Mark Zuckerberg so this is what it’s going to mean at Facebook.\n\nMARK ZUCKERBERG:\n\nYeah, I mean, people can control this, right, themselves. I mean, simple control has always has been one of the important parts of using Facebook and…\n\nNARRATOR:\n\nKara Swisher has covered Zuckerberg since the beginning. She interviewed him after the company had changed its default privacy settings.\n\nKARA SWISHER:\n\nSo do you feel like it’s a backlash or do you feel like you’re violating people’s privacy?\n\nAnd when we started to ask questions, he became increasingly uncomfortable.\n\nMARK ZUCKERBERG:\n\nYou know, it’s…\n\nKARA SWISHER:\n\nI think the issue is: You became the head of the biggest social networking company on the planet.\n\nMARK ZUCKERBERG:\n\nYeah, no, so, but I, I…\n\nKARA SWISHER:\n\nSo everything you said then matters.\n\nMARK ZUCKERBERG:\n\n…think the, the interesting thing is that… You know, so I started this when I was, you know, started working on this type of stuff when I was 18.\n\nKARA SWISHER:\n\nSo he started to sweat quite a lot, and then a lot a lot, and then a real lot. So the kind of, this kind of thing, where, you know, like “Broadcast News” where it was dripping down, like, or Tom Cruise in that “Mission Impossible.” It was just, it was going to his chin and dripping off.\n\nMARK ZUCKERBERG:\n\nYou know, a lot of stuff changed as we’ve gone from building this project in a dorm room.\n\nKARA SWISHER:\n\nAnd it wasn’t stopping and I was noticing that one of the people from Facebook was like, oh, my god, and was… We were… I was trying figure out what to do.\n\nMARK ZUCKERBERG:\n\nYeah, I mean, you know, a lot of stuff happened, happened along the way. I think, you know, there were real learning points and turning points along the way in terms of, in terms of building things.\n\nKARA SWISHER:\n\nHe was in such distress and I know it sounds awful but I, I felt like his mother. Like, oh, my god, this poor guy is going to faint. I, I thought he was going to faint. I did.\n\nWant to take off the hoodie?\n\nMARK ZUCKERBERG:\n\nNo, no. Whoa.\n\nKARA SWISHER:\n\nWell, different people think different things. He’s told us he had the flu. I felt like he had a panic attack, is what happened.\n\nMARK ZUCKERBERG:\n\nMaybe I should take off the hoodie.\n\nKARA SWISHER:\n\nTake off the hoodie.\n\nWALT MOSSBERG:\n\nGo ahead. What the hell.\n\nKARA SWISHER:\n\nDo you want to? Are you hot? Okay. Of course not. That is a warm hoodie. Let me see.\n\nMARK ZUCKERBERG:\n\nYeah. No, it’s a thick hoodie. We… It’s, it’s a company hoodie. We print our mission on the inside.\n\nKARA SWISHER:\n\nWhat? Oh, my god, the inside of the hoodie, everybody. Take a look. What is it? Making the…\n\nMARK ZUCKERBERG:\n\nMaking the world more open and connected.\n\nKARA SWISHER:\n\nOh, my god. It’s like a secret cult.\n\nJAMES JACOBY, Correspondent:\n\nFrom that interview and from others, I mean, how would you have characterized Mark’s view of privacy?\n\nKARA SWISHER:\n\nWell, I, I, you know, I don’t know if he thought about that. It’s kind of interesting because they’re very, they’re very loose on it. They have a viewpoint that this helps you as the user to get more information and they will deliver up more… That’s the whole ethos of Silicon Valley, by the way. If you only give us everything, we will give you free stuff. There is a trade being made between the user and Facebook. The question is: Are they protecting that, that data?\n\nWALT MOSSBERG:\n\nThank you, Mark.\n\nNARRATOR:\n\nFacebook had been free to set its own privacy standards, because in the U.S., there are no overarching privacy laws that apply to this kind of data collection. But in 2010, authorities at the Federal Trade Commission became concerned.\n\nDAVID VLADECK, Director, FTC Bureau of Consumer Protection, 2009-2012:\n\nIn most other parts of the world, privacy is a right. United States, not exactly.\n\nNARRATOR:\n\nAt the FTC, David Vladeck was investigating whether Facebook had been deceiving its users. What he found was that Facebook had been sharing users’ personal data with so called third-party developers – companies that built games and apps for the platform.\n\nDAVID VLADECK:\n\nAnd our view was that, you know, it’s fine for Facebook to collect this data, but sharing this data with third parties without consent was a no-no.\n\nMARK ZUCKERBERG:\n\nBut at Facebook, of course, we believe that our users should have complete control of their information.\n\nDAVID VLADECK:\n\nThe heart of our cases against companies like Facebook was deceptive conduct. That is, they, they did not make it clear to consumers the extent to which their personal data would be shared with third parties.\n\nNARRATOR:\n\nThe FTC had another worry: They saw the potential for data to be misused because Facebook wasn’t keeping track of what the third parties were doing with it.\n\nDAVID VLADECK:\n\nThey had, in my view, no real control over the third-party app developers that had access to the site. They could have been anyone. There was no due diligence. Anyone, essentially, who could develop a third-party app, could get access to the site.\n\nJAMES JACOBY:\n\nIt could have been somebody working for a foreign adversary.\n\nDAVID VLADECK:\n\nCertainly. It could have been somebody working… Yes, for, you know, for the Russian government.\n\nNARRATOR:\n\nFacebook settled with the FTC without admitting guilt and, under a consent order, agreed to fix the problems.\n\nJAMES JACOBY:\n\nWas there an expectation at the time of the consent order that they would staff up to ensure that their users’ data was not leaking out all over the place?\n\nDAVID VLADECK:\n\nYes. That’s, that was the point of the, this provision of the consent order that required them to identify risk to personal privacy and to plug those gaps quickly.\n\nNARRATOR:\n\nInside Facebook, however, with the IPO on the horizon, they were also under pressure to keep monetizing all that personal information, not just fix the FTC’s privacy issues.\n\nSANDY PARAKILAS, Facebook Platform Operations Manager, 2011-2012:\n\nNine months into my first job in tech, I ended up in an interesting situation where because I had been the main person who was working on privacy issues with respect to Facebook platform, which had many, many, many privacy issues. It was a, it was a real hornet’s nest. And I ended up in a meeting with a bunch of the most senior executives at the company and they went around the room and they basically said, “Well, who’s in charge?” And the answer was me because no one else really knew anything about it. You’d think that a company of the size and importance of Facebook, you know, would have really focused and had a team of people and you know, very senior people working on these issues. But it ended up being me.\n\nJAMES JACOBY:\n\nWhat did you think about that at the time?\n\nSANDY PARAKILAS:\n\nI was horrified. I didn’t think I was qualified.\n\nNARRATOR:\n\nParakilas tried to examine all the ways that the data Facebook was sharing with third-party developers could be misused\n\nSANDY PARAKILAS:\n\nMy concerns at the time were that I knew that there were all these malicious actors who would do a wide range of bad things given the opportunity, given the ability to target people based on this information that Facebook had. So I started thinking through what are the worst case scenarios of what people could do with this data. And I showed some of the kinds of bad actors that might try to attack, and I shared it out with a, a, a number of senior executives. And the, the response was, was muted, I would say. I got the sense that it just, this just wasn’t their priority. They weren’t that concerned about the vulnerabilities that the company was creating. They were concerned about revenue growth and user growth.\n\nJAMES JACOBY:\n\nAnd that was expressed to you, or that’s something that you just gleaned from the, the interactions?\n\nSANDY PARAKILAS:\n\nFrom the lack of a response, I would, I, I gathered that. Yeah.\n\nJAMES JACOBY:\n\nAnd how senior were the senior executives?\n\nSANDY PARAKILAS:\n\nVery senior, like among the top five executives in the company.\n\nNARRATOR:\n\nFacebook has said it took the FTC order seriously and, despite Parakilas' account, had large teams of people working to improve users’ privacy. But to Parakilas and others inside Facebook, it was clear the business model continued to drive the mission. In 2012, Parakilas left the company, frustrated.\n\nSANDY PARAKILAS:\n\nI think there was a certain arrogance there that led to a lot of bad long-term decision-making. The long-term ramifications of those decisions was not well thought through at all. And it, it's got us to where we are right now.\n\nANNOUNCER:\n\nYour visionary, your founder, your leader. Mark, please come to the podium.\n\nNARRATOR:\n\nIn May of 2012, the company finally went public.\n\nNEWS REPORT:\n\nThe world’s largest social network managed to raise for than $18 billion, making it the largest technology IPO in U.S. history.\n\nNEWS REPORT:\n\nPeople literally lined up in Times Square around the NASDAQ board.\n\nMARK ZUCKERBERG:\n\nWe’ll ring this bell and we’ll, we’ll get back to work.\n\nNEWS REPORT:\n\nWith founder Mark Zuckerberg, ringing the NASDAQ opening bell remotely from Facebook headquarters in Menlo Park, California.\n\nNARRATOR:\n\nMark Zuckerberg was now worth an estimated $15 billion. Facebook would go on to acquire Instagram and WhatsApp on its way to becoming one of the most valuable companies in the world.\n\nMARK ZUCKERBERG:\n\nGoing public is an important milestone in our history. But here’s the thing. Our mission isn’t to be a public company. Our mission is to make the world more open and connected.\n\n[crowd cheers]\n\nNARRATOR:\n\nAt Facebook, the business model built on getting more and more of users’ personal data was seen as a success. But across the country, researchers working for the Department of Defense were seeing something else\n\nRAND WALTZMAN, Program Manager, DARPA 2010-2015:\n\nThe concern was that social media could be used for really nefarious purposes. The opportunities for disinformation, for deception, for everything else, are enormous. Bad guys or anybody could use this for any kind of purpose in a way that wasn’t possible before. That’s the concern.\n\nJAMES JACOBY, Correspondent:\n\nAnd what did you see as a potential threat of people giving up their data?\n\nRAND WALTZMAN:\n\nThat they’re opening themselves up to being targets for manipulation. I can manipulate you to buy something. I can manipulate you to vote for somebody. It’s like putting a target, painting a big target on your front and on your chest and on your back and saying, “Here I am. Come and manipulate me. You have every… I’ve given you everything you need. Have at it.” That’s the threat.\n\nNARRATOR:\n\nWaltzman says Facebook wouldn’t provide data to help his research. But from 2012 to 2015, he and his colleagues published more than 200 academic papers and reports about the threats they were seeing from social media\n\nRAND WALTZMAN:\n\nWhat I saw over the years of the program was that the medium enables you to really take disinformation and turn it into a serious weapon.\n\nJAMES JACOBY:\n\nWas your research revealing a potential threat to national security?\n\nRAND WALTZMAN:\n\nSure, if you, when you looked at how it actually worked, you see where the opportunities are for manipulation, mass manipulation.\n\nJAMES JACOBY:\n\nAnd is there an assumption there that people are easily misled?\n\nRAND WALTZMAN:\n\nYes. Yes. People are easily misled, if you do it the right way. For example, when you see people forming into communities, OK, what’s called filter bubbles. Now I’m going to exploit that to craft my message so that it resonates most exactly with that community, and I’ll do that for every single community. It would be pretty easy, it would be pretty easy to set up a fake account, and large number of fake accounts, embedded in different communities, and use them to disseminate propaganda.\n\nJAMES JACOBY:\n\nAt an enormous scale?\n\nRAND WALTZMAN:\n\nYes. Well, that’s why it’s a serious weapon because it’s an enormous scale. It’s the scale that makes it a weapon.\n\nST. PETERSBURG, RUSSIA\n\nNARRATOR:\n\nIn fact, Waltzman’s fears were already playing out at a secret propaganda factory in St. Petersburg, Russia, called the Internet Research Agency. Hundreds of Russian operatives were using social media to fight the anti-Russian government in neighboring Ukraine. Vitaly Bespalov says he was one them.\n\nJAMES JACOBY:\n\nCan you explain what is the Internet Research Agency?\n\nVITALY BESPALOV:\n\n[voice of translator] It’s a company that creates a fake perception of Russia. They use things like illustrations, pictures, anything that would influence people’s minds.\n\nWhen I worked there, I didn’t hear anyone say, “the government runs us” or “the Kremlin runs us.” But everyone there knew and everyone realized it.\n\nJAMES JACOBY:\n\nWas the main intention to make the Ukrainian government look bad?\n\nVITALY BESPALOV:\n\n[voice of translator] Yeah, yeah. That’s what it was. This was the intention with Ukraine. Put President Poroshenko in a bad light and the rest of the government and the military and so on.\n\nYou come to work and there’s a pile of SIM cards, many, many SIM cards, and an old mobile phone. You need an account to register for various social media sites. You pick a photo of a random person, choose a random last name, and start posting links to news in different groups.\n\nNARRATOR:\n\nThe Russian propaganda had its intended effect – helping to sow distrust and fear of the Ukrainian government.\n\nNEWS REPORT:\n\n…pro-Russian demonstrators against Ukraine’s new interim government.\n\nNEWS REPORT:\n\n“Russia, Russia,” they chant.\n\nCHRISTINA DOBROVOLSKA, Ukrainian cyber researcher:\n\nRussian propaganda was massive on social media. It was massive.\n\nDMYTRO SHYMKIV, Adviser to president of Ukraine, 2014-2018:\n\nThere were so many stories that start emerging on the Facebook.\n\nCHRISTINA DOBROVOLSKA:\n\n“Cruel, cruel Ukrainian nationalist killing people or torturing them because they speak Russian.”\n\nDMYTRO SHYMKIV:\n\nThey scared people. “You see they are going to attack. They’re going to burn your villages. You should worry.”\n\nNEWSCASTER:\n\n[subtitle] Ukrainians massively flee to Russia.\n\nCHRISTINA DOBROVOLSKA:\n\nThen fake staged news.\n\nNEWSCASTER:\n\n[subtitle] Now a story from a refugee.\n\nDMYTRO SHYMKIV:\n\n“Crucified child by Ukrainian soldiers,” which is totally nonsense.\n\nWOMAN:\n\n[subtitles] They nailed him like Jesus to the board. One nailed him while two held him down.\n\nCHRISTINA DOBROVOLSKA:\n\nIt got proven that those people were actually hired actors.\n\nDMYTRO SHYMKIV:\n\nComplete nonsense.\n\nCHRISTINA DOBROVOLSKA:\n\nBut it, it spreads on Facebook.\n\nDMYTRO SHYMKIV:\n\nSo Facebook was weaponized.\n\nNARRATOR:\n\nJust as in the Arab Spring, Facebook was being used to inflame divisions, but now by groups working on behalf of a foreign power, using Facebook’s tools built to help advertisers boost their content,\n\nDMYTRO SHYMKIV:\n\nBy that time in Facebook, you could pay money to promote these stories so your stories emerge on the top lines. And suddenly, you start to believe in this and you immediately get immediate response.\n\nYou can test all kind of nonsenses and understand to which nonsense people do not believe…\n\nPRO-UKRAINE ACTIVISTS:\n\n[subtitles] We are strong now. You can’t break us.\n\nDMYTRO SHYMKIV:\n\n…and to which nonsenses people start believing…\n\nPRO-RUSSIA ACTIVISTS:\n\n[subtitles] On your knees! Russia!\n\nDMYTRO SHYMKIV:\n\n…which will influence the behavior of person receptive to propaganda and then provoking that person on certain action.\n\nCHRISTINA DOBROVOLSKA:\n\nThey decided to undermine Ukraine from the inside, rather than from outside.\n\nDMYTRO SHYMKIV:\n\nI mean, basically, think about this: Russia hacked us.\n\nNARRATOR:\n\nDmytro Shymkiv, a top adviser to Ukraine’s president, met with Facebook representatives and says he asked them to intervene.\n\nDMYTRO SHYMKIV:\n\nThe response that Facebook gave us is, “Sorry, we are open platform. Anybody can do anything without, within the, our policy, which is written on the website.”\n\nAnd when I said, “But this is fake accounts, [laughs] you could verify that.” “Well, we’ll think about this but you know, we, we have a freedom of speech and we are very pro-democracy platform. Everybody can say anything.”\n\nJAMES JACOBY:\n\nIn the meeting, do you think you made it explicitly clear that Russia was using Facebook to meddle in Ukraine politics?\n\nDMYTRO SHYMKIV:\n\nI was explicitly saying that they’re a trolls factory, that there are posts and news that are fake, that are lying. And they are promoted on your platform, by very often fake accounts. Have a look. At least send in somebody to investigate.\n\nINTERVIEWER:\n\nAnd no one… Sorry.\n\nDMYTRO SHYMKIV:\n\nNo.\n\nINTERVIEWER:\n\nNo one was sent?\n\nDMYTRO SHYMKIV:\n\nNo, no. For them at that time, it was not an issue.\n\nNARRATOR:\n\nFacebook told FRONTLINE that Shymkiv didn’t raise the issue with misinformation in their meeting and that their conversations had nothing to do with what would happen in the United States two years later.\n\nJAMES JACOBY:\n\nIt was known to Facebook in 2014, there was a potential for Russian disinformation campaigns on Facebook.\n\nELIZABETH LINDER, Facebook Politics and Government Specialist, 2008-2016:\n\nYes! And there were disinformation campaigns from a number of different countries on Facebook. You know, disinformation campaigns were a regular facet of Facebookery abroad. And that’s… I mean, yeah, technically that should have led to a learning experience. I just don't know.\n\nJAMES JACOBY:\n\nThere was plenty that was known about the potential downsides of social media and Facebook. You know, potential for disinformation, potential for bad actors and abuse. Were these things that you just weren’t paying attention to or were these things that were kind of conscious choices to kind of say, “All right, we’re going to kind of abdicate responsibility from those things and just keep growing”?\n\nNAOMI GLEIT, Facebook Vice President of Social Good:\n\nI definitely think we’ve been paying attention to the things that we know. And one of the biggest challenges here is that this is really an evolving set of threats and risks. We had a big effort around scams. We had a big effort around bullying and harassment. We had a big effort around nudity and porn on Facebook. It’s always ongoing. And so, some of these threats and problems are new. And I think we’re grappling with that as a company, with other companies in the space, with governments, with other organizations. And so I, I wouldn’t say that everything is new. It’s just different problems.\n\nNEWS REPORT:\n\nFacebook is the ultimate growth stock.\n\nNARRATOR:\n\nAt Facebook headquarters in Menlo Park, they would stick to the mission and the business model, despite a gathering storm.\n\nNEWS REPORT:\n\n…their election news and decision-making material from Facebook.\n\nNARRATOR:\n\nBy 2016, Russia was continuing to use social media as a weapon. And division and polarization were running through the presidential campaign.\n\nPRESIDENT DONALD TRUMP:\n\nJust use it on lying, crooked Hillary.\n\nNEWS REPORT:\n\nThe race for the White House was shaken up again on Super Tuesday.\n\nNARRATOR:\n\nMark Zuckerberg saw threats to his vision of an open and connected world.\n\nSILICON VALLEY, APRIL 2016\n\nMARK ZUCKERBERG:\n\nAs I look around, I’m starting to see people and nations turning inward against this idea of a connected world and a global community. I hear fearful voices calling for building walls and distancing people they label as “others,” for blocking free expression, for slowing immigration, reducing trade and, in some cases around the world, even cutting access to the internet.\n\nNARRATOR:\n\nBut he continued to view his invention not as part of the problem but as the solution.\n\nMARK ZUCKERBERG:\n\nAnd that’s why I think the work that we’re all doing together is more important now than it’s ever been before.\n\n[applause]\n\nPART II\n\nHILLARY CLINTON, Candidate for president:\n\nI accept your nomination for president of the United States.\n\nDONALD TRUMP, Candidate for president:\n\nI humbly accept your nomination for the presidency of the United States.\n\nMARK ZUCKERBERG, Founder and CEO, Facebook:\n\nHey, everyone. We are live from my backyard where I am smoking a brisket and some ribs and getting ready for the presidential debate tonight.\n\nNEWS REPORT:\n\nSome of the questions for tonight’s debate will be formed by conversations happening on Facebook.\n\nNEWS REPORT:\n\nThirty-nine percent of people get their election news and decision-making material from Facebook.\n\nNEWS REPORT:\n\nFacebook getting over a billion political campaign posts.\n\nMARK ZUCKERBERG:\n\nI love this, all the, all the comments that are, that are coming in. It’s like I’m, I’m sitting here, smoking these meats and, and just hanging out with 85,000 people who are hanging out with me in my backyard.\n\nHILLARY CLINTON:\n\nMake no mistake. Everything you care about, everything I care about and I’ve worked for is at stake.\n\nDONALD TRUMP:\n\nI will beat Hillary Clinton, crooked Hillary. I will beat her so badly, so badly.\n\nMARK ZUCKERBERG:\n\nAnd I hope that all of you get out and vote. This is going to be an important one.\n\nDEBATE ANNOUNCER:\n\nTonight’s broadcast will also include Facebook, which has become a gathering place for political conversation.\n\nDONALD TRUMP:\n\nThank you. Thank you.\n\nKATIE HARBATH, Facebook Global Politics and Government Director:\n\nFacebook is really the new town hall.\n\nCNBC COMMENTATOR:\n\nBetter conversations happen on Facebook.\n\nCNBC COMMENTATORS:\n\nPoke for a vote. Poke for a vote.\n\n[Trump supporters chanting “USA”]\n\n[Clinton supporters chanting “Hillary”]\n\nFOX COMMENTATOR:\n\nFacebook is the ultimate growth stock.\n\nFOX COMMENTATOR:\n\nFacebook is utterly dominating this new mobile, digital economy.\n\nFOX COMMENTATOR:\n\nHave you been measuring political conversation on Facebook – the things like the most Likes, interactions, shares?\n\nDONALD TRUMP:\n\nHillary Clinton has evaded justice.\n\nHILLARY CLINTON:\n\nI thank you for giving me the opportunity to, in my view, clarify.\n\nNEWS REPORT:\n\n2016 is the social election.\n\nNEWS REPORT:\n\nFacebook getting over a billion political campaign posts.\n\nNARRATOR:\n\n2016 began as banner year for Mark Zuckerberg. His company had become one of the most popular and profitable in the world, despite an emerging dilemma that as it was connecting billions, it was inflaming divisions.\n\nNEWS REPORT:\n\nYou know, people are really forming these tribal identities on Facebook, where you will see people getting into big fights.\n\nNARRATOR:\n\nWe’ve been investigating warning signs that existed as Facebook grew, and interviewing those inside the company who were there at the time.\n\nANDREW ANKER, Facebook Director of Product Management, 2015-2017:\n\nWe saw a lot of our numbers growing like crazy, as did the rest of the media and the news world in particular. And so as a product designer, when you see your products being used more, you’re happy.\n\nKATIE HARBATH, Facebook Global Politics and Government Director:\n\nIt’s where we’re seeing conversation happening about the election, the candidates, the issues.\n\nNARRATOR:\n\nAmid all this political activity on Facebook, no one used the platform more successfully than Donald Trump’s digital media director, Brad Parscale.\n\nBRAD PARSCALE, Trump 2016 Digital Media Director:\n\nI asked Facebook, “I want to spend $100 million on your platform. Send me a manual.” They say, “We don’t have a manual.” I say, “Well, send me a human manual then.”\n\nJAMES JACOBY, Correspondent:\n\nAnd what does the manual provide?\n\nBRAD PARSCALE:\n\nYou have a manual for you car. If you didn’t have that for your car, there might be things you would never learn how to use in your car. Right? I spend $100 million on a platform, the most in history. It made sense for them to be there to help us make sure how we spent it right and then did it right.\n\nFACEBOOK EXPLAINER:\n\nWith custom audiences, you can get your ads to people you already know who are on Facebook.\n\nNARRATOR:\n\nWhat Facebook’s representatives showed them was how to harness its powerful advertising tools to find and target new and receptive audiences.\n\nFACEBOOK EXPLAINER:\n\nNow, I’ll target my ad to friends of people who like my page.\n\nBRAD PARSCALE:\n\nWhat I recognized was the simple process of marketing. I needed to find the right people and the right places and show them the right message. Micro-targeting allows you to do is say, well, these are the people most likely to show up to vote and these are the right audiences we need to show up. The numbers were showing in the consumer side that people were spending more and more hours of their day consuming Facebook content. So if you have any best place to show your content, it would be there. It was a place where their eyes were. That’s where they were reading their local newspaper and doing things. And so we could hear our message injected inside that stream. And that was a stream which was controlling the eyeballs of most places that we needed to win.\n\nNARRATOR:\n\nIt wasn’t just politics. By this time, Facebook was also dominating the news business.\n\nNEWS REPORT:\n\nSixty-two percent of Americans say they get their news from social media sites like Facebook.\n\nMARK ZUCKERBERG:\n\nMore than a dozen developers have worked with us to build social news apps all with the goal of helping you discover and read more news.\n\nNARRATOR:\n\nFacebook’s massive audience enticed media organizations to publish straight into the company’s News Feed, making it one of the most important distributors of news in the world.\n\nMARK ZUCKERBERG:\n\nI’m personally really excited about this. I think that it has the potential to not only rethink the way that we all read news, but to rethink the, a lot of the way that the whole news industry works.\n\nNARRATOR:\n\nBut unlike traditional media companies, Facebook didn’t see itself as responsible for insuring the accuracy of news and information on its site.\n\nALEXIS MADRIGAL, The Atlantic:\n\nThe responsibilities that they should have taken on are what used to be called editing. And editors had certain responsibilities for what was going to show up on the first page versus the last page, the relative importance of things, that don’t relate purely to money and don’t relate purely to popularity. So they took over the role of editing without ever taking on the responsibilities of editing.\n\nNARRATOR:\n\nInstead, Facebook’s editor was its algorithm, designed to feed users whatever was most engaging to them. Inside Facebook, they didn’t see that as a problem.\n\nJAMES JACOBY:\n\nWas there a realization inside Facebook as to what the responsibilities would be of becoming the main distributor of news?\n\nANDREW ANKER:\n\nI don’t think there was a lot of thinking about that, that idea. I don’t think there was any, any thought that the news content in particular had, had more value or had more need for protection than any of the other pieces of content on Facebook.\n\nNARRATOR:\n\nAndrew Anker was in charge of Facebook’s news products team, and is one of eight former Facebook insiders who agreed to talk on camera about their experiences.\n\nANDREW ANKER:\n\nI was surprised by a lot of things when I joined Facebook. And as someone who grew up in the media world, I expected there to be more of a sense of how people interact with media and how important media can be to certain people's information diet.\n\nWOMAN:\n\nWe have a video from Davida from Napoli.\n\nDAVIDA:\n\n[subtitles] Hi. I have a question about the role of Facebook in the media. Do you see it as an editor? Thank you very much.\n\nMARK ZUCKERBERG:\n\nNo. You know, we’re a technology company. We’re not a media company.\n\nCRAIG SILVERMAN, BuzzFeed:\n\nThe fact that so many big, well-known news brands really pushed into Facebook pretty aggressively legitimized it as a place to get kind of information. And I think that also strangely created the opportunity for people who weren't legitimate as well, because if the legitimate players are there and you're not legitimate, all you need to do is set up a website and then share links to it, and your stuff on Facebook is going to look similar enough that you've just gotten a huge leg up.\n\nDONALD TRUMP:\n\nHillary Clinton is the most corrupt person ever to seek the office…\n\nNARRATOR:\n\nBut as the 2016 campaign heated up…\n\nHILLARY CLINTON:\n\nAnd I’ll tell you, some of what I heard coming from my opponent…\n\nNARRATOR:\n\n…reporter Craig Silverman was sounding alarms that Facebook’s News Feed was spreading misinformation, what he called “fake news.”\n\nCRAIG SILVERMAN:\n\nFake news just seemed like the right term to use. And I was trying to get people to pay attention. I was trying to get journalists to pay attention. I was trying to also get Facebook and other companies like Twitter to pay attention to this as well.\n\nNARRATOR:\n\nSilverman traced the misinformation back to some unusual places.\n\nVELES, MACEDONIA 2016\n\nCRAIG SILVERMAN:\n\nWe started to see this small cluster of websites being run, the vast majority, from one town in Macedonia.\n\nINTERVIEWER:\n\nHow popular is it?\n\nMAN:\n\nAbout 200 people, maybe.\n\nINTERVIEWER:\n\n200 people?\n\nMAN:\n\nYeah.\n\nINTERVIEWER:\n\nMaking fake news websites?\n\nMAN:\n\nYes.\n\nCRAIG SILVERMAN:\n\nMost of them didn’t really care about who won the election. They weren’t in this for politics. If you put ads on these completely fake websites and you got a lot of traffic from Facebook, that was a good way to make money.\n\nMAN:\n\nThere are some people who made like 200K or something like that.\n\nINTERVIEWER:\n\n200,000 euros?\n\nMAN:\n\nYeah, yeah, yeah.\n\nCRAIG SILVERMAN:\n\nI remember one guy, I think he was 15 or 16 years, old telling me, you know, “Americans want to read about Trump, so I’m writing Trump stuff.” Trump earned them money.\n\nWe saw Macedonians publishing: Hillary Clinton being indicted, the pope endorsing Trump, Hillary Clinton selling weapons to ISIS – getting close to or above a million Shares, Likes, Comments. That’s an insane amount of engagement. It’s more, for example, than when The New York Times had a scoop about Donald Trump’s tax returns. How is it that a kid in Macedonia can get an article that gets more engagement than a scoop from The New York Times on Facebook?\n\nJAMES JACOBY:\n\nA headline during the campaign was “Pope endorses Trump,” which was not true but it went viral on Facebook. Was it known within Facebook that that had gone viral?\n\nANDREW ANKER:\n\nI’m sure it was. I didn’t necessarily know how viral it had gotten and I certainly didn’t believe that anybody believed it.\n\nJAMES JACOBY:\n\nBut would that have been a red flag inside the company that something that’s patently false was being propagated to millions of people on the platform?\n\nANDREW ANKER:\n\nI think if you ask the question that way, it would have been. But I think when you ask then the next question, which is the harder and the more important question was, which is: So what do you do about it? you then very quickly get into issues of not only free speech. But to what degree is it anybody’s responsibility, as a technology platform or as a distributor, to start to decide when you’ve gone over the line between something that is clearly false from something that may or may not be perceived by everybody to be clearly false and potentially can do damage?\n\nJAMES JACOBY:\n\nOver the course of the 2016 election, there was a lot of news about misinformation. I mean, there was famously the, the pope endorses Trump. Do you remember that?\n\nTESSA LYONS, Facebook Product Manager for News Feed Integrity:\n\nAbsolutely. I, I wasn’t working on these issues at the time but, but absolutely, I, I do remember it.\n\nNARRATOR:\n\nTessa Lyons was chief of staff to Facebook’s number two, Sheryl Sandberg, and is now in charge of fighting misinformation. She is one of five current officials Facebook put forward to answer questions.\n\nJAMES JACOBY:\n\nWas there any kind of sense of like: Oh, my goodness, Facebook is getting polluted with misinformation. Someone should do something about this.\n\nTESSA LYONS:\n\nThere certainly was and there were people who were thinking about it. What I don’t think there was a real awareness of internally or, or externally was the scope of the problem and the, the right course of action.\n\nJAMES JACOBY:\n\nHow could it be surprising that if you’re becoming the world’s information source that there may be a problem with misinformation?\n\nTESSA LYONS:\n\nThere was certainly awareness that there could be problems related to news or quality of news. And I think we all recognized afterwards that of all of the threats that we were considering, we’d focused a lot on threats that weren’t misinformation and underinvested in this one.\n\nNARRATOR:\n\nBut there was another problem that was going unattended on Facebook beyond misinformation.\n\nCRAIG SILVERMAN:\n\nOne of the big factors that emerged in the election was what, what started to be called hyperpartisan Facebook pages.\n\nThese were Facebook pages that kind of lived and died by really ginning up that partisanship. “We’re right, they’re wrong.” But not even just that. It was also: “They’re terrible people and we’re the best.” And the Facebook pages were getting tremendous engagement.\n\nALEXIS MADRIGAL, The Atlantic:\n\nA million migrants are coming over the wall and they’re going to like, rape your children. You know? That stuff is doing well.\n\nCRAIG SILVERMAN:\n\nAnd the stuff that was true would get far less shares.\n\nALEXIS MADRIGAL:\n\nThat development of these hyperpartisan sites, I think, turned the informational commons into this trash fire. And there’s some kind of parable in that for the broader effects of Facebook, that the very things that divide us most cause the most engagement…\n\nHILLARY CLINTON:\n\n[imitates barking]\n\nVLADIMIR PUTIN, President of Russia:\n\n[laughs]\n\nALEXIS MADRIGAL:\n\n…which means they go to the top of the News Feed, which means the most people see them.\n\nNARRATOR:\n\nThis worried an early Facebook investor who was once close to Zuckerberg.\n\nROGER MCNAMEE, Early Facebook investor:\n\nI am an analyst by training and profession and so my job is to watch and interpret. At this point, I have a series of different examples that suggest to me that there is something wrong systemically with the Facebook algorithms and business model. In effect, polarization was the key to the model – this idea of appealing to people’s lower-level emotions; things like fear and anger to create greater engagement and, in the context of Facebook, more time on site, more sharing, and therefore, more advertising value. I found that incredibly disturbing.\n\nNARRATOR:\n\nTen days before the election, McNamee wrote Zuckerberg and Sandberg about his concerns.\n\nROGER MCNAMEE:\n\nI mean, what I was really trying to do was to help Mark and Sheryl get this thing right. And their responses were more or less what I expected, which is to say that what I had seen were isolated problems and that they had addressed each and every one of them. I thought Facebook could stand up and say: We’re going to reassess our priorities. We’re going to reassess the metrics on which we run the company to try to take into account the fact that our impact is so much greater now than it used to be. And that as Facebook, as a company with, you know, billions of users, we have influence on how the whole social fabric works that no one’s had before.\n\nDONALD TRUMP:\n\nI’ve just received a call from Secretary Clinton.\n\nNEWS REPORT:\n\nClinton has called Trump to concede the election.\n\nNEWS REPORT:\n\nThe Clinton campaign is really a somber mood here.\n\nNEWS REPORT:\n\nThe crowd here at Trump campaign headquarters…\n\nNARRATOR:\n\nTrump’s targeted ads on Facebook paid off…\n\nNEWS REPORT:\n\nDid things like Facebook help one of the nastiest elections ever?\n\nNARRATOR:\n\n…leading to complaints that Facebook helped tilt the election…\n\nNEWS REPORT:\n\nFacebook elected Donald Trump. That’s basically…\n\nNARRATOR:\n\n…which the Trump campaign dismissed as anger over the results.\n\nNEWS REPORT:\n\nThere has been mounting criticism of Facebook.\n\nBRAD PARSCALE, Trump 2016 Digital Media Director:\n\nNo one ever complained about Facebook for a single day until Donald Trump was president. The only reason anyone’s upset about this is that Donald Trump is president and used a system that was all built by liberals. When I got on TV and told everybody after my interview of what we did at Facebook, it exploded. The funny thing is the Obama campaign used it, then went on TV and newspapers and they put it on the front of a magazine and the left and the media called them geniuses for doing that.\n\nNEWS REPORT:\n\nThe accusations that phony news stories helped Donald Trump win the presidency…\n\nNARRATOR:\n\nBut Trump’s victory put Facebook on the spot.\n\nNEWS REPORT:\n\nFacebook even promoted fake news into its trending category.\n\nNARRATOR:\n\nAnd two days after the election at a tech conference in Northern California, Zuckerberg spoke publicly about it for the first time.\n\nDAVID KIRKPATRICK, Editor-in-Chief, Techonomy:\n\nWell, you know, one of the things post-election, you’ve been getting a lot of pushback from people who feel that you didn’t filter out enough fake stories. Right?\n\nMARK ZUCKERBERG:\n\nYou know, I, I’ve seen some of the stories that you’re talking about around this election. There is a certain profound lack of empathy in asserting that the only reason why someone could have voted the way they did is because they saw some fake news. You know, personally, I think the, the idea that, you know, fake news on Facebook, of which, you know, it’s a, it’s a very small amount of, of, of the content, influenced the, the election in any way, I think, is a, a pretty crazy idea. Right? And it’s…\n\nKARA SWISHER, Executive Editor, Recode Media:\n\nIf I had been sitting there in an interview, I would have said, “You’re lying” when he said we had no impact on the election. That, I remember reading that and being furious. I was like, are you kidding me? Like, stop it. Like, you cannot say that and not be lying. Of course, they had an impact. It’s obvious. They were the most important distribution, news distribution. There’s so many statistics about that. Like, I, I don't know why, how you could possibly make that claim in public and with such a cavalier attitude. That infuri-, infuriated me. And I texted everybody there saying: You’re kidding me.\n\nJAMES JACOBY, Correspondent:\n\nIs he not recognizing the importance of his platform in our democracy at that point in time?\n\nKARA SWISHER:\n\nYes. I think he didn’t understand what he had built or didn’t, didn’t care to understand or wasn’t paying attention and doesn’t… They, they really do want to pretend, as they’re getting on their private planes, as they’re getting, going to their beautiful homes, as they’re collecting billions of dollars, they never want to acknowledge their power. They’re powerful and they have, they, they don’t.\n\nDAVID KIRKPATRICK:\n\nThank you so much for being here.\n\nMARK ZUCKERBERG:\n\nThank you, guys.\n\nANDREW ANKER, Facebook Director of Product Management, 2015-2017:\n\nI think it was very easy for all of us sitting in Menlo Park to not necessarily understand how valuable Facebook had become. I don't think any of us, Mark included, appreciated how much of an effect we might have had. And I don't even know today, two years later or almost two years later, that we really understand how much of a true effect we had. But I think more importantly, we all didn't have the information to be saying things like that at the time. My guess is, is that Mark now realizes that there was a lot more to the story than, than he or any of us could have imagined at that point.\n\nNARRATOR:\n\nBarely two months later, in Washington an even more serious situation was developing. Intelligence agencies were investigating Russian interference in the election and whether social media had played a role.\n\nJAMES CLAPPER, Director of National Intelligence, 2010-2017:\n\nClassical propaganda, disinformation, fake news.\n\nSEN. JACK REED, D-R.I.:\n\nDoes that continue?\n\nJAMES CLAPPER:\n\nYes.\n\nIn my view, we only scratched the surface. I say “we,” those that assembled the intelligence community assessment that we published on the 6th of January 2017. Meaning NSA, CIA, FBI, and, and my office. But I will tell you, frankly, that I didn’t appreciate the full magnitude of it until well after.\n\nNARRATOR:\n\nAmid growing scrutiny…\n\nMARK ZUCKERBERG:\n\nAll right.\n\nNARRATOR:\n\n…Zuckerberg set out on a cross-country trip he publicized by streaming on Facebook.\n\nMARK ZUCKERBERG:\n\nSo I’ve been going around to different states for my personal challenge for the year to see how, you know, different communities are working across the country.\n\nNARRATOR:\n\nBut while he was on the road, the news was getting worse.\n\nNEWS REPORT:\n\nThe U.S. intelligence community officially is blaming Russian President Vladimir Putin…\n\nNEWS REPORT:\n\nRussian President Vladimir Putin ordered an influence campaign aimed at the presidential election.\n\nNARRATOR:\n\nZuckerberg’s chief of security, Alex Stamos, had been asked to see what he could find on Facebook servers.\n\nALEX STAMOS, Facebook Chief Security Officer, 2015-2018:\n\nWe kicked off a big look into the fake news phenomenon, specifically what component of that might have a Russian part in its origin.\n\nNARRATOR:\n\nThey traced disinformation to what appeared to be Russian government-linked sources.\n\nJAMES JACOBY:\n\nSo what was it like bringing that news to others in the company and up to Mark and Sheryl, for instance?\n\nALEX STAMOS:\n\nYou know, we had a big responsibility in the security team to, to educate the right people about what had happened without being kind of overly dramatic. It’s kind of hard as a security person to balance that. Right? Like, everything seems like an emergency to you. But in this case, it really was. Right? This really was a situation in which we saw the tip of this iceberg and we knew there was some kind of iceberg beneath it.\n\nNARRATOR:\n\nStamos expanded his investigation to look at how the Russian operation may have also used Facebook’s targeted advertising system.\n\nALEX STAMOS:\n\nSo what we did is we then decided we’re going to look at all advertising and see if we can find any strange patterns that might link them to Russian activity.\n\nSo we enlisted huge parts of the company. We kind of dragooned everybody into one big, unified team. So you have people in a war room working 70-, 80-hour weeks, billions of dollars of ads, hundreds of millions of pieces of content, and by kind of a painstaking process of going through thousands and thousands of false positives, eventually found this large cluster that we were able to link to the Internet Research Agency of St. Petersburg.\n\nNARRATOR:\n\nIt was one of the same groups that had been using Facebook to spread disinformation in Ukraine three years earlier. This time, using fake accounts, Russian operatives had paid around $100,000 to run ads that promoted political messages and enticed people to join fake Facebook groups.\n\nALEX STAMOS:\n\nWhat the Internet Research Agency wants to do is they want to create the appearance of legitimate social movements. So they would create, for example, a pro-immigration group and an anti-immigration group, and both of those groups would be almost caricatures of what those two sides think of each other. And their goal of running ads were to find populations of people who are open to those kinds of messages to get them into those groups and then to deliver content on a regular basis to, to drive them apart.\n\nReally, what the Russians are trying to do is find these fault lines in U.S. society and amplify them and to make Americans not trust each other.\n\nNARRATOR:\n\nIn September 2017, nearly a year after the election, Zuckerberg announced on Facebook what the company had found.\n\nMARK ZUCKERBERG:\n\nWe are actively working with the U.S. government on its ongoing investigations into Russian interference. We’ve been investigating this for many months now and for a while we had found no evidence of fake accounts linked to Russian, linked to Russia running ads. And when we recently uncovered this activity, we provided that information to the special counsel. We also briefed Congress. And this morning, I directed our team to provide the ads we’ve found to Congress as well.\n\nSEN. MARK WARNER, D-Va.:\n\nWe do know that Facebook-related posts touched about 150 million Americans, that were posts that originated either through Russian fake accounts or through paid advertising from the Russians. But the paid advertising was really a relatively small piece of the overall problem. A much bigger problem was the ability for someone to say they were James in Washington, D.C. but it was actually Boris in St. Petersburg creating a fake persona that would generate followers and then they would seed it with the fake information and the false news and the political content.\n\nHOUSTON, TEXAS 2016\n\nSEN. MARK WARNER:\n\nOne account was set up to try to rally the Muslim community in, in Texas. Another was an attempt to kind of rally the right wing in Texas. They created an event.\n\nWOMAN:\n\nWhite power!\n\nCOUNTERPROTESTERS:\n\nStop the hate! Stop the fear!\n\nSEN. MARK WARNER:\n\nProtests with both sides protesting against each other at a mosque in Houston in 2016.\n\nMAN:\n\nThis is America. We have the right to speak out.\n\nCOUNTERPROTESTER:\n\nMuslim lives matter!\n\nSEN. MARK WARNER:\n\nBut for the good work of the Houston police, you could have had the kind of horrible activity take place then and there that I saw unfortunately take place in Charlottesville in my state last year. So the real human consequences of some of these, of some of this abuse, we’ve been very lucky that it hasn’t actually cost people’s lives.\n\nNARRATOR:\n\nFacebook also found that the Russians had used the site to orchestrate a pro-Trump rally outside of a Cheesecake Factory in Florida, and to promote an anti-Trump protest in New York City just after the election.\n\nPROTESTERS:\n\nHey, hey, ho, ho! Donald Trump has go to go!\n\nMAN:\n\nWe are under threat and I need to defend the country that I love.\n\nMICHAEL MOORE, Filmmaker:\n\nWe are right in the middle of the protest.\n\nNARRATOR:\n\nThe details of Facebook’s internal investigation set off alarm bells in Washington.\n\nJAMES CLAPPER:\n\nWe’re such a ripe target for that sort of thing and the Russians know that. So the Russians exploited that divisiveness, that polarization because they had, they had messages for everybody. You know, Black Lives Matter, white supremacists, gun control advocates, gun control opponents. It didn’t matter. They had messages for everybody.\n\nJAMES JACOBY:\n\nDid you think that was a pretty sophisticated campaign?\n\nJAMES CLAPPER:\n\nIt was. And I believe the Russians did a lot to get people out to vote that wouldn’t have and helped the appeal for, of, of Don-, of Donald Trump.\n\nJAMES JACOBY:\n\nAnd the role that social media played in that was what?\n\nJAMES CLAPPER:\n\nNo, it’s huge.\n\nALEX STAMOS:\n\nI mean it’s, it’s really quite both ingenious and evil to, to attack a democratic society in that manner.\n\nJAMES JACOBY, Correspondent:\n\nBut there were warning signs along the way in the trajectory of the company.\n\nALEX STAMOS:\n\nThe company’s been dealing with the negative side effects of its product for years. Right? When you have 2 billion people on a communication platform, there’s a[n] infinite number of potentially bad things that could happen. The tough part is trying to decide where you’re going to put your focus.\n\nNARRATOR:\n\nBut by 2017, Facebook was being accused of not focusing on other serious issues in developing, fragile democracies where the company had expanded its business…\n\nPHILIPPINES\n\nNARRATOR:\n\n…countries like the Philippines, where almost all internet users are on Facebook and problems had been mounting.\n\nMARIA RESSA, Executive Director, Rappler Media:\n\nIn a year, I probably met with more than 50 different officials, high-ranking officials, including Mark Zuckerberg. I wanted them to know what we were seeing. I wanted them to tell me what they thought about it. And I wanted them to fix it.\n\nNARRATOR:\n\nMaria Ressa, who runs a prominent news website, says she had been warning Facebook since 2016 that President Rodrigo Duterte was using a network of paid followers and fake accounts to spread lies about his policies and attack his critics…\n\nNEWS REPORT:\n\nThe U.N. has branded his war a crime under international law.\n\nNARRATOR:\n\n…especially critics of his brutal war on drugs, which has taken an estimated 12,000 lives.\n\nNEWS REPORT:\n\n…Human Rights Watch has called government-sanctioned butchery.\n\nMARIA RESSA:\n\nPresident Duterte was targeting anyone who questioned the drug war, anyone who questioned the alleged extrajudicial killings. Anyone on Facebook who questioned that would get brutally bashed.\n\nWe’re protected by the constitution. We’ve been stripped of those protections online.\n\nNARRATOR:\n\nRessa herself would eventually come under attack.\n\nMARIA RESSA:\n\nThere were attacks on the way I look, the way I sounded, that I should be raped, that I should be killed. We gave it a name: “patriotic trolling,” online state-sponsored hate that is meant to silence, meant to intimidate. So this is an information ecosystem that just turns democracy upside down.\n\nJAMES JACOBY:\n\nAnd where lies are prevalent.\n\nMARIA RESSA:\n\nWhere lies are truth.\n\nNARRATOR:\n\nShe traced the disinformation to a network of 26 fake accounts and reported it to Facebook at a meeting in Singapore in August of 2016\n\nJAMES JACOBY:\n\nWhat were you asking them to do?\n\nMARIA RESSA:\n\nExactly what every news group does, which is take control and be responsible for what you create.\n\nJAMES JACOBY:\n\nWere you given an explanation as to why they weren’t acting?\n\nMARIA RESSA, Executive Director, Rappler Media:\n\nNo. No.\n\nI think Facebook walked into the Philippines and they were focused on growth. What they didn’t realize is that countries like the Philippines – countries where institutions are weak, where corruption is rampant – these countries don't have the safeguards. And what happens when you bring everyone onto a platform and do not exercise any kind of rules, right, if you don't implement those rules beforehand, you're going to create chaos.\n\nJAMES JACOBY:\n\nThere's a problem in the Philippines. We’ve heard about from people on the ground there that Facebook has been, to some degree, weaponized by the Duterte regime there. What are you doing to, to stem this problem in the Philippines?\n\nMONIKA BICKERT, Facebook Vice President of Global Policy Management:\n\nOne thing we’re trying to do, any time that we think there might be a connection between violence on the ground and online speech, the first thing for us to do is actually understand the landscape.\n\nNARRATOR:\n\nMonika Bickert is Facebook’s head of global policy and worked for the Justice Department in Southeast Asia.\n\nMONIKA BICKERT:\n\nThere’s a, a fundamental question, which is: What should our role be? And as we are identifying misinformation, should we be telling people what we’re finding? Should we be removing that content? Should we be down-ranking that content? And we now have a team that is focused on how to deal with exactly that sort of situation.\n\nNARRATOR:\n\nIn April, Facebook created a news verification program and hired Ressa’s organization as one of its fact-checkers, though she says the problems are ongoing. The company ultimately took down the accounts Ressa identified and just last week removed dozens more.\n\nZEYNEP TUFEKCI, UNC Chapel Hill:\n\nI think what is happening is that this company is way in over its head in terms of its responsibilities. It's way in over its head in terms of what power it holds. The idea isn’t that it's just like you magically add Facebook and horrible things happen. But you have Facebook as this effective gasoline to simmering fires\n\nMYANMAR\n\nNARRATOR:\n\nElsewhere in the region…\n\nNEWS REPORT:\n\nBuddhists are inciting hatred and violence against Muslims through social media and mainstream media.\n\nNARRATOR:\n\nFacebook was also being used to fan ethnic tensions with even more dire consequences.\n\nNEWS REPORT:\n\nViolence between Buddhists and Muslims is continuing.\n\nDAVID MADDEN Tech entrepreneur:\n\nMisinformation, disinformation, rumors, extremist propaganda, all kinds of bad content.\n\nNARRATOR:\n\nFor several years, David Madden, a tech entrepreneur living in Myanmar, as well as journalists and activists, had been warning Facebook that the Muslim minority there was being targeted with hate speech.\n\nASHIN WIRATHU:\n\n[subtitle] We need to protect our religion.\n\nWORSHIPPERS:\n\n[subtitle] Yes, your Reverence.\n\nDAVID MADDEN:\n\nYou would see the use of memes, of images, things that were degrading and dehumanizing targeting the Muslim community.\n\nASHIN WIRATHU:\n\n[subtitles] They target women every day and rape them.\n\nNARRATOR:\n\nThe warning signs had been present as far back as 2014, when a fake news story spread on Facebook.\n\nDAVID MADDEN:\n\nReports later proved to be false that some Muslim man had raped a Buddhist woman was shared on Facebook.\n\nNEWS REPORT:\n\nAn angry mob of about 400 surrounded the Sun Tea Shop shouting and throwing bricks and stones.\n\nNARRATOR:\n\nTwo people died in the incident.\n\nNEWS REPORT:\n\nOne Buddhist and one Muslim were killed in riots today.\n\nDAVID MADDEN:\n\nI was really concerned that the seriousness of this was not understood. And so, I made a presentation at Facebook headquarters in May of 2015. I was pretty explicit about the state of the problem. I drew the analogy with what had happened in Rwanda, where radios had played a really key role in the execution of this genocide. And so I said, “Facebook runs the risk of being in Myanmar what radios were in Rwanda” – that this platform could be used to foment hate and to incite violence.\n\nJAMES JACOBY:\n\nWhat was the reaction to that at Facebook?\n\nDAVID MADDEN:\n\nI got an email shortly after that meeting to say that what had been discussed at that meeting had been shared internally and apparently taken very seriously.\n\nNARRATOR:\n\nThe violence intensified.\n\nNEWS REPORT:\n\n…massive waves of violence that displaced over 150,000 people.\n\nNARRATOR:\n\nAnd in early 2017, Madden and other local activists had another meeting with Facebook.\n\nDAVID MADDEN:\n\nThe objective of this meeting was, was really to be crystal clear about just how bad the problem was and that the processes that they had in place to try to identify and pull down problematic content, they just weren't working. And we were deeply concerned that something even worse was going to happen imminently. It was a sobering meeting. I think, I think the, the main response from Facebook was, “We'll need to go away and dig into this and come back with something substantive.” The thing was it never came.\n\nJAMES JACOBY:\n\nHow do you know that?\n\nDAVID MADDEN:\n\nWe can look at the evidence on the ground.\n\nNEWS REPORT:\n\nWhat we’ve seen here tells us a story of ethnic cleansing, of driving Muslims out of Myanmar.\n\n[subtitle] May the terrorists fall fast and die horribly.\n\nNARRATOR:\n\nThe United Nations would call the violence in Myanmar a genocide and found social media and Facebook in particular had played a significant role.\n\nYANGHEE LEE, U.N. Special Rapporteur, Myanmar:\n\nThe ultranationalist Buddhists have their own Facebooks and really inciting a lot of violence and hatred against ethnic minorities. Facebook has now turned into a beast than what it was originally intended to be used.\n\nJAMES JACOBY:\n\nI’m curious what it’s like when the UN comes out with a report that says that Facebook played a significant role in a genocide. What’s that like for you running content policy at Facebook?\n\nMONIKA BICKERT, Facebook Vice President of of Global Policy Management:\n\nWell, this would be important to me even if I didn’t work at Facebook, given my background. My background is as a federal prosecutor and I worked specifically in Asia and specifically on violent crimes against people in Asia. So something like that really hits home to me.\n\nJAMES JACOBY:\n\nFacebook was warned as early as 2015 about the potential for a really dangerous situation in Myanmar. What went wrong there? Why was it so slow?\n\nMONIKA BICKERT:\n\nWe met with civil society organizations in Myanmar far before 2015. This is an area where we’ve been focused. I think what we’ve learned over time is it’s important for us to build the right technical tools that can help us find some of this content and also work with organizations on the ground in a real-time fashion. We are in the process of building those relationships around the world on a much deeper level so that we can stay ahead of any kind of situation like that.\n\nNARRATOR:\n\nIn the past year, Facebook says it’s taken down problematic accounts in Myanmar, hired more language experts, and improved its policies.\n\nJAMES JACOBY, Correspondent:\n\nShould there be any liability or any legal accountability for a company like Facebook when something so disastrous goes wrong on your platform?\n\nMONIKA BICKERT:\n\nThere’s all sorts of accountability. But probably the group that holds us the most accountable are the people using the service. If it’s not a safe place for them to come and communicate, they are not going to use it.\n\nNAOMI GLEIT, Facebook Vice President of Social Good:\n\nWe are working here in Menlo Park, in Palo Alto, California. To the extent that some of these issues and problems manifest in other countries around the world, we didn’t have sufficient information and a pulse on what was happening in Southeast Asia.\n\nNARRATOR:\n\nNaomi Gleit is Facebook’s second-longest-serving employee.\n\nNAOMI GLEIT:\n\nAnd so one change that we’ve made, along with hiring so many more people, is that a lot of these people are based internationally and can give us that insight that we may not get from being here at our headquarters.\n\nJAMES JACOBY:\n\nI’m trying to understand, you know, the, the choices that are made. Do you regret choices going backward, decisions that were made about not taking into account risks or not measuring risks?\n\nNAOMI GLEIT:\n\nYeah. I definitely think we regret not having 20,000 people working on safety, secur-, and security back in the day. Yes. So I regret that we were too slow, that it wasn’t our priority.\n\nJAMES JACOBY:\n\nBut were those things even considered at the time – to kind of amp up safety and security? But there was some reason not to or…\n\nNAOMI GLEIT:\n\nNot really. I mean, we had a safety and security team. I think we just thought it was sufficient. I just… It, it’s not that we were like, wow, we could do so much more here, and decided not to. I think we, we just didn’t… Again, we were just a bit idealistic.\n\nDAVID MADDEN:\n\nIf Facebook has created this platform that in many countries, not just Myanmar, has become the dominant information platform and it has an outsized influence in lots of countries, that comes with a lot of responsibility.\n\nNEWS REPORT:\n\nUsing social media, rumors of alleged Muslim wrongdoing spread fast.\n\nDAVID MADDEN:\n\nMany of those countries are wrestling with some pretty big challenges, tensions between groups within countries. And we have seen this explode into what Mark Zuckerberg would call “real-world harm,” what others would just call violence or death, in many other markets. We're seeing it right now in India.\n\nNEWS REPORT:\n\nCalloo became a victim of India’s fake news.\n\nDAVID MADDEN:\n\nWe’ve seen examples of this in places like Sri Lanka.\n\nNEWS REPORT:\n\nTo keep the violence from spreading, Sri Lanka also shut down Facebook…\n\nDAVID MADDEN:\n\nThe Myanmar example should be sounding an alarm at the highest level of the company, that this requires a comprehensive strategy.\n\nLONDON, ENGLAND\n\nNARRATOR:\n\nBut it would be far from Myanmar and a very different kind of problem that would cause an international uproar over Facebook.\n\nNEWS REPORT:\n\nCambridge Analytica and its mining of data on millions of Americans for political purposes…\n\nNEWS REPORT:\n\nCambridge is alleged to have used all this data from tens of millions of Facebook users.\n\nNEWS REPORT:\n\nEscándalo Cambridge Analytica, Facebook…\n\nNARRATOR:\n\nIt was a scandal over how Facebook failed to protect users’ data, exposed by a whistleblower named Christopher Wylie.\n\nNEWS REPORT:\n\n…Christopher Wylie, he was able to come forward and say, “I can prove this.”\n\nNARRATOR:\n\nHe said that Facebook knew that a political consulting firm he’d worked for, Cambridge Analytica, had been using the personal data of more than 50 million users to try to influence voters.\n\nCAMBRIDGE ANALYTICA VIDEO:\n\nAt Cambridge Analytica we are creating the future of political campaigning.\n\nCHRISTOPHER WYLIE, Cambridge Analytica whistleblower:\n\nThis is a company that specializes and would advertise itself as specializing in rumor campaigns.\n\nCAMBRIDGE ANALYTICA VIDEO:\n\nPolitical campaigns have changed.\n\nCHRISTOPHER WYLIE:\n\nSeeding the internet with misinformation.\n\nCAMBRIDGE ANALYTICA VIDEO:\n\nPutting the right message in front of the right person at the right moment.\n\nCHRISTOPHER WYLIE:\n\nAnd that’s the power of data.\n\nCAMBRIDGE ANALYTICA VIDEO:\n\nEvery voter in the…\n\nCHRISTOPHER WYLIE:\n\nYou can literally figure out who are the people who are most susceptible.\n\nCAMBRIDGE ANALYTICA VIDEO:\n\n…of data about personality so you know exactly who to target with exactly what type of message.\n\nNARRATOR:\n\nThe firm had gained access to the data from a third party without Facebook’s permission.\n\nCHRISTOPHER WYLIE:\n\nThe overwhelming majority of people who had their data collected did not know. When data leaves Facebook servers, there is no way for Facebook to track that data, to know how that data is being used, or to find out how many copies there are.\n\nNARRATOR:\n\nFacebook eventually changed its data-sharing policies and ordered Cambridge Analytica to delete the data.\n\nNEWS REPORT:\n\nWe know that Facebook has known about this for at least two years.\n\nNARRATOR:\n\nAfter Wylie came forward, they banned the firm from their site and announced they were ending another controversial practice – working directly with companies known as data brokers. But the uproar was so intense that in April 2018, Mark Zuckerberg was finally called before Congress in what would become a reckoning over Facebook’s conduct, its business model, and its impact on democracy.\n\nSEN CHARLES GRASSLEY (R-Iowa):\n\nWe welcome everyone [to] today’s hearing on Facebook’s social media privacy and the use and abuse of data. I now turn to you, so proceed, sir.\n\nMARK ZUCKERBERG:\n\nWe face a number of important issues around privacy, safety and democracy. And you will rightfully have some hard questions for me to answer. Facebook is an idealistic and optimistic company. And as Facebook has grown, people everywhere have gotten a powerful new tool for making their voices heard and for building communities and businesses.\n\nBut it's clear now that we didn't do enough to prevent these tools from being used for harm as well. And that goes for fake news, for foreign interference in elections and hate speech, as well as developers and data privacy. We didn't take a broad enough view of our responsibility and that was a big mistake. And it was my mistake. And I'm sorry.\n\nZEYNEP TUFEKCI, UNC Chapel Hill:\n\nIf, like me, you’re following this stuff, you see years and years and years of people begging and pleading with the company, saying, “Please pay attention to this,” at every channel people could find, and basically being ignored. “We hear you, we’re concerned, we apologize. Of course we have a responsibility, we’ll do better.” And the public record here is that they are a combination of unable and unwilling to grasp and deal with this complexity.\n\nSEN. BEN SASSE (R-Neb.):\n\nYou may decide, or Facebook may decide, it needs to police a whole bunch of speech, that I think America might be better off not having policed by one company that has a really big and powerful platform.\n\nMARK ZUCKERBERG:\n\nSenator, I think of this as a really hard question. And I think it's one of the reasons why we struggle with it.\n\nALEX STAMOS, Facebook Chief Security Officer, 2015-2018:\n\nThese are very, very powerful corporations. They do not have any kind of traditional democratic accountability. And while I personally know a lot of people making these decisions, if we set the norms that these companies need to decide what, who does and does not have a voice online, eventually that is going to go to a very dark place.\n\nSEN. DAN SULLIVAN, (R-Alaska):\n\nWhen companies become big and powerful, there is a[n] instinct to either regulate or break up. Right?\n\nTIM WU, Author, “The Curse of Bigness”:\n\nI think we’re finding ourselves now in a position where people feel like something should be done. There’s a lot of questions what should be done, but there’s no question that something should be done.\n\nSEN. LINDSEY GRAHAM (R-S.C.):\n\nYou don’t think you have a monopoly?\n\nMARK ZUCKERBERG:\n\nAh, it certainly doesn’t feel like that to me.\n\nSEN. LINDSEY GRAHAM (R-S.C.):\n\nOK.\n\nTIM WU:\n\nYou know, there’s a lot of problems here, there, but all these problems get worse when one company has too much power, too much information over too many people.\n\nNARRATOR:\n\nAfter years of unchecked growth, the talk now is increasingly about how to rein in Facebook. Already in Europe, there’s a new internet privacy law aimed at companies like Facebook. Inside the company, the people we spoke to insisted that Facebook is still a force for good.\n\nJAMES JACOBY:\n\nHas there ever been a minute where you’ve questioned the mission, you know, internally? Whether anyone has taken a second to step back and say: All right, has this blinded us in some way? Have you had a moment like that?\n\nNAOMI GLEIT, Facebook Vice President for Social Good:\n\nI still continue to firmly believe in the mission. But in terms of stepping back, in terms of reflecting, absolutely. But that isn’t on the mission. The reflection is really about: How can we do a better job of minimizing bad experiences on Facebook?\n\nJAMES JACOBY:\n\nWhy wasn’t that part of the metric earlier in terms of how do you minimize the harm?\n\nNAOM"
    }
}