{
    "id": "dbpedia_6068_3",
    "rank": 25,
    "data": {
        "url": "https://www.mckinsey.com/capabilities/quantumblack/our-insights/exploring-opportunities-in-the-generative-ai-value-chain",
        "read_more_link": "",
        "language": "en",
        "title": "Exploring opportunities in the generative AI value chain",
        "top_image": "https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/exploring%20opportunities%20in%20the%20generative%20ai%20value%20chain/thumb-gettyimages-1470671176.jpg",
        "meta_img": "https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/exploring%20opportunities%20in%20the%20generative%20ai%20value%20chain/thumb-gettyimages-1470671176.jpg",
        "images": [
            "https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/what%20every%20ceo%20should%20know%20about%20generative%20ai/gen-ai-ceo-thumb.jpg?cq=50&mh=145&car=16:9&cpy=Center",
            "https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/exploring%20opportunities%20in%20the%20generative%20ai%20value%20chain/svgz-exploring-opportunities-gen-ai-ex1-v5.svgz?cq=50&cpy=Center",
            "https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/exploring%20opportunities%20in%20the%20generative%20ai%20value%20chain/svgz-exploring-opportunities-gen-ai-ex2-v6.svgz?cq=50&cpy=Center",
            "https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/generative%20ai%20is%20here%20how%20tools%20like%20chatgpt%20could%20change%20your%20business/thumb-gettyimages-1312389354.jpg?cq=50&mh=145&car=16:9&cpy=Center",
            "https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/exploring%20opportunities%20in%20the%20generative%20ai%20value%20chain/svgz-exploring-opportunities-gen-ai-ex3-v2.svgz?cq=50&cpy=Center",
            "https://www.mckinsey.com/~/media/mckinsey/featured%20insights/mckinsey%20explainers/what%20is%20generative%20ai/generative-ai-1219474321-thumb-1536x1536-v3.jpg?cq=50&mw=767&car=16:9&cpy=Center",
            "https://www.mckinsey.com/~/media/mckinsey/industries/retail/our%20insights/generative%20ai%20unlocking%20the%20future%20of%20fashion/generative-ai-unlocking-the-future-of-fashion-1132484892-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center",
            "https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/the%20state%20of%20ai%20in%202022%20and%20a%20half%20decade%20in%20review/thumb-ai-survey-2022.jpg?cq=50&mw=767&car=16:9&cpy=Center"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Tobias HÃ¤rlin",
            "Gardar BjÃ¶rnsson Rova",
            "Alex Singla",
            "Oleg Sokolov",
            "Alex Sukharevsky"
        ],
        "publish_date": "2023-04-26T00:00:00+00:00",
        "summary": "",
        "meta_description": "Generative AI is giving rise to an entire ecosystem, from hardware providers to application builders, that will help unlock its potential for business.",
        "meta_lang": "en",
        "meta_favicon": "/favicon.ico",
        "meta_site_name": "McKinsey & Company",
        "canonical_link": "https://www.mckinsey.com/capabilities/quantumblack/our-insights/exploring-opportunities-in-the-generative-ai-value-chain",
        "text": "Over the course of 2022 and early 2023, tech innovators unleashed generative AI en masse, dazzling business leaders, investors, and society at large with the technologyâs ability to create entirely new and seemingly human-made text and images.\n\nThe response was unprecedented.\n\nIn just five days, one million users flocked to ChatGPT, OpenAIâs generative AI language model that creates original content in response to user prompts. It took Apple more than two months to reach the same level of adoption for its iPhone. Facebook had to wait ten months and Netflix more than three years to build the same user base.\n\nAnd ChatGPT isnât alone in the generative AI industry. Stability AIâs Stable Diffusion, which can generate images based on text descriptions, garnered more than 30,000 stars on GitHub within 90 days of its releaseâeight times faster than any previous package.\n\nThis flurry of excitement isnât just organizations kicking the tires. Generative AI use cases are already taking flight across industries. Financial services giant Morgan Stanley is testing the technology to help its financial advisers better leverage insights from the firmâs more than 100,000 research reports. The government of Iceland has partnered with OpenAI in its efforts to preserve the endangered Icelandic language. Salesforce has integrated the technology into its popular customer-relationship-management (CRM) platform.\n\nThe breakneck pace at which generative AI technology is evolving and new use cases are coming to market has left investors and business leaders scrambling to understand the generative AI ecosystem. While deep dives into CEO strategy and the potential economic value that the technology could create globally across industries are forthcoming, here we share a look at the generative AI value chain composition. Our aim is to provide a foundational understanding that can serve as a starting point for assessing investment opportunities in this fast-paced space. Our assessments are based on primary and secondary research, including more than 30 interviews with business founders, CEOs, chief scientists, and business leaders working to commercialize the technology; hundreds of market reports and articles; and proprietary McKinsey research data.\n\nA brief explanation of generative AI\n\nTo understand the generative AI value chain, itâs helpful to have a basic knowledge of what generative AI is and how its capabilities differ from the âtraditionalâ AI technologiesÂ that companies use to, for example, predict client churn, forecast product demand, and make next-best-product recommendations.\n\nA key difference is its ability to create new content. This content can be delivered in multiple modalities, including text (such as articles or answers to questions), images that look like photos or paintings, videos, and 3-D representations (such as scenes and landscapes for video games).\n\nEven in these early days of the technologyâs development, generative AI outputs have been jaw-droppingly impressive, winning digital-art awards and scoring among or close to the top 10 percent of test takers in numerous tests, including the US bar exam for lawyers and the math, reading, and writing portions of the SATs, a college entrance exam used in the United States.\n\nMost generative AI models produce content in one format, but multimodal models that can, for example, create a slide or web page with both text and graphics based on a user prompt are also emerging.\n\nAll of this is made possible by training neural networks (a type of deep learning algorithm) on enormous volumes of data and applying âattention mechanisms,â a technique that helps AI models understand what to focus on. With these mechanisms, a generative AI system can identify word patterns, relationships, and the context of a userâs prompt (for instance, understanding that âblueâ in the sentence âThe cat sat on the mat, which was blueâ represents the color of the mat and not of the cat). Traditional AI also might use neural networks and attention mechanisms, but these models arenât designed to create new content. They can only describe, predict, or prescribe something based on existing content.\n\nThe value chain: Six links, but one outshines them all\n\nAs the development and deployment of generative AI systems gets under way, a new value chain is emerging to support the training and use of this powerful technology. At a glance, one might think itâs quite similar to a traditional AI value chain. After all, of the six top-level categoriesâcomputer hardware, cloud platforms, foundation models, model hubs and machine learning operations (MLOps), applications, and servicesâonly foundation models are a new addition (Exhibit 1).\n\nHowever, a deeper look reveals some significant differences in market opportunities. To begin with, the underpinnings of generative AI systems are appreciably more complex than most traditional AI systems. Accordingly, the time, cost, and expertise associated with delivering them give rise to significant headwinds for new entrants and small companies across much of the value chain. While pockets of value exist throughout, our research suggests that many areas will continue to be dominated by tech giants and incumbents for the foreseeable future.\n\nThe generative AI application market is the section of the value chain expected to expand most rapidly and offer significant value-creation opportunities to both incumbent tech companies and new market entrants. Companies that use specialized or proprietary data to fine-tune applications can achieve a significant competitive advantage over those that donât.\n\nComputer hardware\n\nGenerative AI systems need knowledgeâand lots of itâto create content. OpenAIâs GPT-3, the generative AI model underpinning ChatGPT, for example, was trained on about 45 terabytes of text data (akin to nearly one million feet of bookshelf space).\n\nItâs not something traditional computer hardware can handle. These types of workloads require large clusters of graphic processing units (GPUs) or tensor processing units (TPUs) with specialized âacceleratorâ chips capable of processing all that data across billions of parameters in parallel.\n\nOnce training of this foundational generative AI model is completed, businesses may also use such clusters to customize the models (a process called âtuningâ) and run these power-hungry models within their applications. However, compared with the initial training, these latter steps require much less computational power.\n\nWhile there are a few smaller players in the mix, the design and production of these specialized AI processors is concentrated. NVIDIA and Google dominate the chip design market, and one player, Taiwan Semiconductor Manufacturing Company Limited (TSMC), produces almost all of the accelerator chips. New market entrants face high start-up costs for research and development. Traditional hardware designers must develop the specialized skills, knowledge, and computational capabilities necessary to serve the generative AI market.\n\nCloud platforms\n\nGPUs and TPUs are expensive and scarce, making it difficult and not cost-effective for most businesses to acquire and maintain this vital hardware platform on-premises. As a result, much of the work to build, tune, and run large AI models occurs in the cloud. This enables companies to easily access computational power and manage their spend as needed.\n\nUnsurprisingly, the major cloud providers have the most comprehensive platforms for running generative AI workloads and preferential access to the hardware and chips. Specialized cloud challengers could gain market share, but not in the near future and not without support from a large enterprise seeking to reduce its dependence on hyperscalers.\n\nFoundation models\n\nAt the heart of generative AI are foundation models. These large deep learning models are pretrained to create a particular type of content and can be adapted to support a wide range of tasks. A foundation model is like a Swiss Army knifeâit can be used for multiple purposes. Once the foundation model is developed, anyone can build an application on top of it to leverage its content-creation capabilities. Consider OpenAIâs GPT-3 and GPT-4, foundation models that can produce human-quality text. They power dozens of applications, from the much-talked-about chatbot ChatGPT to software-as-a-service (SaaS) content generators Jasper and Copy.ai.\n\nFoundation models are trained on massive data sets. This may include public data scraped from Wikipedia, government sites, social media, and books, as well as private data from large databases. OpenAI, for example, partnered with Shutterstock to train its image model on Shutterstockâs proprietary images.\n\nDeveloping foundation models requires deep expertise in several areas. These include preparing the data, selecting the model architecture that can create the targeted output, training the model, and then tuning the model to improve output (which entails labeling the quality of the modelâs output and feeding it back into the model so it can learn).\n\nToday, training foundation models in particular comes at a steep price, given the repetitive nature of the process and the substantial computational resources required to support it. In the beginning of the training process, the model typically produces random results. To improve its next output so it is more in line with what is expected, the training algorithm adjusts the weights of the underlying neural network. It may need to do this millions of times to get to the desired level of accuracy. Currently, such training efforts can cost millions of dollars and take months. Training OpenAIâs GPT-3, for example, is estimated to cost $4 million to $12 million. As a result, the market is currently dominated by a few tech giants and start-ups backed by significant investment (Exhibit 2). However, there is work in progress toward making smaller models that can deliver effective results for some tasks and training that is more efficient, which could eventually open the market to more entrants. We already see that some start-ups have achieved certain success in developing their own modelsâCohere, Anthropic, and AI21, among others, build and train their own large language models (LLMs). Additionally, there is a scenario where most big companies would want to have LLMs working in their environmentsâsuch as for a higher level of data security and privacy, among other reasonsâand some players (such as Cohere) already offer this kind of service around LLMs.\n\nItâs important to note that many questions have yet to be answered regarding ownership and rights over the data used in the development of this nascent technologyâas well as over the outputs producedâwhich may influence how the technology evolves (see sidebar, âSome of the key issues shaping generative AIâs futureâ).\n\nModel hubs and MLOps\n\nTo build applications on top of foundation models, businesses need two things. The first is a place to store and access the foundation model. Second, they may need specialized MLOps tooling, technologies, and practices for adapting a foundation model and deploying it within their end-user applications. This includes, for example, capabilities to incorporate and label additional training data or build the APIs that allow applications to interact with it.\n\nModel hubs provide these services. For closed-source models in which the source code is not made available to the public, the developer of the foundation model typically serves as a model hub. It will offer access to the model via an API through a licensing agreement. Sometimes the provider will also deliver MLOps capabilities so the model can be tuned and deployed in different applications.\n\nFor open-source models, which provide code that anyone can freely use and modify, independent model hubs are emerging to offer a spectrum of services. Some may act only as model aggregators, providing AI teams with access to different foundation models, including those customized by other developers. AI teams can then download the models to their servers and fine-tune and deploy them within their application. Others, such as Hugging Face and Amazon Web Services, may provide access to models and end-to-end MLOps capabilities, including the expertise to tune the foundation model with proprietary data and deploy it within their applications. This latter model fills a growing gap for companies eager to leverage generative AI technology but lacking the in-house talent and infrastructure to do so.\n\nApplications\n\nWhile one foundation model is capable of performing a wide variety of tasks, the applications built on top of it are what enable a specific task to be completedâfor example, helping a businessâs customers with service issues or drafting marketing emails (Exhibit 3). These applications may be developed by a new market entrant seeking to deliver a novel offering, an existing solution provider working to add innovative capabilities to its current offerings, or a business looking to build a competitive advantage in its industry.\n\nThere are many ways that application providers can create value. At least in the near term, we see one category of applications offering the greatest potential for value creation. And we expect applications developed for certain industries and functions to provide more value in the early days of generative AI.\n\nApplications built from fine-tuned models stand out\n\nBroadly, we find that generative AI applications fall into one of two categories. The first represents instances in which companies use foundation models largely as is within the applications they buildâwith some customizations. These could include creating a tailored user interface or adding guidance and a search index for documents that help the models better understand common customer prompts so they can return a high-quality output.\n\nThe second category represents the most attractive part of the value chain: applications that leverage fine-tuned foundation modelsâthose that have been fed additional relevant data or had their parameters adjustedâto deliver outputs for a particular use case. While training foundation models requires massive amounts of data, is extremely expensive, and can take months, fine-tuning foundation models requires less data, costs less, and can be completed in days, putting it within reach of many companies.\n\nApplication builders may amass this data from in-depth knowledge of an industry or customer needs. For example, consider Harvey, the generative AI application created to answer legal questions. Harveyâs developers fed legal data sets into OpenAIâs GPT-3 and tested different prompts to enable the tuned model to generate legal documents that were far better than those that the original foundation model could create.\n\nOrganizations could also leverage proprietary data from daily business operations. A software developer that has tuned a generative AI chatbot specifically for banks, for instance, might partner with its customers to incorporate data from call-center chats, enabling them to continually elevate the customer experience as their user base grows.\n\nFinally, companies may create proprietary data from feedback loops driven by an end-user rating system, such as a star rating system or a thumbs-up, thumbs-down rating system. OpenAI, for instance, uses the latter approach to continuously train ChatGPT, and OpenAI reports that this helps to improve the underlying model. As customers rank the quality of the output they receive, that information is fed back into the model, giving it more âdataâ to draw from when creating a new outputâwhich improves its subsequent response. As the outputs improve, more customers are drawn to use the application and provide more feedback, creating a virtuous cycle of improvement that can result in a significant competitive advantage.\n\nIn all cases, application developers will need to keep an eye on generative AI advances. The technology is moving at a rapid pace, and tech giants continue to roll out new versions of foundation models with even greater capabilities. OpenAI, for instance, reports that its recently introduced GPT-4 offers âbroader general knowledge and problem-solving abilitiesâ for greater accuracy. Developers must be prepared to assess the costs and benefits of leveraging these advances within their application.\n\nPinpointing the first wave of application impact by function and industry\n\nWhile generative AI will likely affect most business functions over the longer term, our research suggests that information technology, marketing and sales, customer service, and product development are most ripe for the first wave of applications.\n\nInformation technology. Generative AI can help teams write code and documentation. Already, automated coders on the market have improved developer productivity by more than 50 percent, helping to accelerate software development.\n\nMarketing and sales. Teams can use generative AI applications to create content for customer outreach. Within two years, 30 percent of all outbound marketing messages are expected to be developed with the assistance of generative AI systems.\n\nCustomer service. Natural-sounding, personalized chatbots and virtual assistants can handle customer inquiries, recommend swift resolution, and guide customers to the information they need. Companies such as Salesforce, Dialpad, and Ada have already announced offerings in this area.\n\nProduct development. Companies can use generative AI to rapidly prototype product designs. Life sciences companies, for instance, have already started to explore the use of generative AI to help generate sequences of amino acids and DNA nucleotides to shorten the drug design phase from months to weeks.\n\nIn the near term, some industries can leverage these applications to greater effect than others. The media and entertainment industry can become more efficient by using generative AI to produce unique content (for example, localizing movies without the need for hours of human translation) and rapidly develop ideas for new content and visual effects for video games, music, movie story lines, and news articles. Banking, consumer, telecommunications, life sciences, and technology companies are expected to experience outsize operational efficiencies given their considerable investments in IT, customer service, marketing and sales, and product development.\n\nServices\n\nAs with AI in general, dedicated generative AI services will certainly emerge to help companies fill capability gaps as they race to build out their experience and navigate the business opportunities and technical complexities. Existing AI service providers are expected to evolve their capabilities to serve the generative AI market. Niche players may also enter the market with specialized knowledge for applying generative AI within a specific function (such as how to apply generative AI to customer service workflows), industry (for instance, guiding pharmaceutical companies on the use of generative AI for drug discovery), or capability (such as how to build effective feedback loops in different contexts).\n\nWhile generative AI technology and its supporting ecosystem are still evolving, it is already quite clear that applications offer the most significant value-creation opportunities. Those who can harness nicheâor, even better, proprietaryâdata in fine-tuning foundation models for their applications can expect to achieve the greatest differentiation and competitive advantage. The race has already begun, as evidenced by the steady stream of announcements from software providersâboth existing and new market entrantsâbringing new solutions to market. In the weeks and months ahead, we will further illuminate value-creation prospects in particular industries and functions as well as the impact generative AI could have on the global economy and the future of work."
    }
}