{
    "id": "dbpedia_7010_1",
    "rank": 52,
    "data": {
        "url": "https://yro.slashdot.org/story/23/12/11/2216207/mit-group-releases-white-papers-on-governance-of-ai",
        "read_more_link": "",
        "language": "en",
        "title": "MIT Group Releases White Papers On Governance of AI",
        "top_image": "https://a.fsdn.com/sd/topics/ai_64.png",
        "meta_img": "https://a.fsdn.com/sd/topics/ai_64.png",
        "images": [
            "https://a.fsdn.com/sd/topics/ai_64.png",
            "https://a.fsdn.com/sd/topics/government_64.png",
            "https://a.fsdn.com/sd/topics/space_64.png",
            "https://a.fsdn.com/sd/topics/court_64.png",
            "https://a.fsdn.com/sd/ccpa-optout.png",
            "https://slashdot.org/images/njs.gif?60"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "An anonymous reader quotes a report from MIT News: Providing a resource for U.S. policymakers, a committee of MIT leaders and scholars has released a set of policy briefs that outlines a framework for the governance of artificial intelligence. The approach includes extending current regulatory and l...",
        "meta_lang": "en",
        "meta_favicon": "/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://yro.slashdot.org/story/23/12/11/2216207/mit-group-releases-white-papers-on-governance-of-ai",
        "text": "Check out the new Slashdot job board to browse remote jobs or jobs in your area\n\nDo you develop on GitHub? You can keep using GitHub but automatically sync your GitHub releases to SourceForge quickly and easily with this tool so your projects have a backup location, and get your project in front of SourceForge's nearly 30 million monthly users. It takes less than a minute. Get new users downloading your project releases today!\n\n√ó\n\n172470059 story\n\nMIT Group Releases White Papers On Governance of AI (mit.edu)\n\nAn anonymous reader quotes a report from MIT News: Providing a resource for U.S. policymakers, a committee of MIT leaders and scholars has released a set of policy briefs that outlines a framework for the governance of artificial intelligence. The approach includes extending current regulatory and liability approaches in pursuit of a practical way to oversee AI. The aim of the papers is to help enhance U.S. leadership in the area of artificial intelligence broadly, while limiting harm that could result from the new technologies and encouraging exploration of how AI deployment could be beneficial to society.\n\nThe main policy paper, \"A Framework for U.S. AI Governance: Creating a Safe and Thriving AI Sector,\" suggests AI tools can often be regulated by existing U.S. government entities that already oversee the relevant domains. The recommendations also underscore the importance of identifying the purpose of AI tools, which would enable regulations to fit those applications. \"As a country we're already regulating a lot of relatively high-risk things and providing governance there,\" says Dan Huttenlocher, dean of the MIT Schwarzman College of Computing, who helped steer the project, which stemmed from the work of an ad hoc MIT committee. \"We're not saying that's sufficient, but let's start with things where human activity is already being regulated, and which society, over time, has decided are high risk. Looking at AI that way is the practical approach.\" [...]\n\n\"The framework we put together gives a concrete way of thinking about these things,\" says Asu Ozdaglar, the deputy dean of academics in the MIT Schwarzman College of Computing and head of MIT's Department of Electrical Engineering and Computer Science (EECS), who also helped oversee the effort. The project includes multiple additional policy papers and comes amid heightened interest in AI over last year as well as considerable new industry investment in the field. The European Union is currently trying to finalize AI regulations using its own approach, one that assigns broad levels of risk to certain types of applications. In that process, general-purpose AI technologies such as language models have become a new sticking point. Any governance effort faces the challenges of regulating both general and specific AI tools, as well as an array of potential problems including misinformation, deepfakes, surveillance, and more. These are the key policies and approaches mentioned in the white papers:\n\nExtension of Current Regulatory and Liability Approaches: The framework proposes extending current regulatory and liability approaches to cover AI. It suggests leveraging existing U.S. government entities that oversee relevant domains for regulating AI tools. This is seen as a practical approach, starting with areas where human activity is already being regulated and deemed high risk.\n\nIdentification of Purpose and Intent of AI Tools: The framework emphasizes the importance of AI providers defining the purpose and intent of AI applications in advance. This identification process would enable the application of relevant regulations based on the specific purpose of AI tools.\n\nResponsibility and Accountability: The policy brief underscores the responsibility of AI providers to clearly define the purpose and intent of their tools. It also suggests establishing guardrails to prevent misuse and determining the extent of accountability for specific problems. The framework aims to identify situations where end users could reasonably be held responsible for the consequences of misusing AI tools.\n\nAdvances in Auditing of AI Tools: The policy brief calls for advances in auditing new AI tools, whether initiated by the government, user-driven, or arising from legal liability proceedings. Public standards for auditing are recommended, potentially established by a nonprofit entity or a federal entity similar to the National Institute of Standards and Technology (NIST).\n\nConsideration of a Self-Regulatory Organization (SRO): The framework suggests considering the creation of a new, government-approved \"self-regulatory organization\" (SRO) agency for AI. This SRO, similar to FINRA for the financial industry, could accumulate domain-specific knowledge, ensuring responsiveness and flexibility in engaging with a rapidly changing AI industry.\n\nEncouragement of Research for Societal Benefit: The policy papers highlight the importance of encouraging research on how to make AI beneficial to society. For instance, there is a focus on exploring the possibility of AI augmenting and aiding workers rather than replacing them, leading to long-term economic growth distributed throughout society.\n\nAddressing Legal Issues Specific to AI: The framework acknowledges the need to address specific legal matters related to AI, including copyright and intellectual property issues. Special consideration is also mentioned for \"human plus\" legal issues, where AI capabilities go beyond human capacities, such as mass surveillance tools.\n\nBroadening Perspectives in Policymaking: The ad hoc committee emphasizes the need for a broad range of disciplinary perspectives in policymaking, advocating for academic institutions to play a role in addressing the interplay between technology and society. The goal is to govern AI effectively by considering both technical and social systems."
    }
}