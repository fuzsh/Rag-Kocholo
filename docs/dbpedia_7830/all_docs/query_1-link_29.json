{
    "id": "dbpedia_7830_1",
    "rank": 29,
    "data": {
        "url": "https://www.wired.com/story/bruce-willis-deepfake-rights-law/",
        "read_more_link": "",
        "language": "en",
        "title": "The Bruce Willis Deepfake Is Everyone’s Problem",
        "top_image": "https://media.wired.com/photos/634d9b913fc5e95b91106989/191:100/w_1280,c_limit/Why-Everyone-Should-Worry-About-Deepfake-Culture-800984764.jpg",
        "meta_img": "https://media.wired.com/photos/634d9b913fc5e95b91106989/191:100/w_1280,c_limit/Why-Everyone-Should-Worry-About-Deepfake-Culture-800984764.jpg",
        "images": [
            "https://www.wired.com/verso/static/wired/assets/logo-header.svg",
            "https://media.wired.com/photos/634d9b913fc5e95b91106989/master/w_2560%2Cc_limit/Why-Everyone-Should-Worry-About-Deepfake-Culture-800984764.jpg",
            "https://media.wired.com/photos/60b49754518969560d1947dc/master/.jpg",
            "https://media.wired.com/photos/66be44e1e5e0286b239ff7ec/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b3bbccf043d55c086141d4/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66be2815db4475a1c4c4ee60/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b9ef71db1e3403775e90ce/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66be44e1e5e0286b239ff7ec/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b3bbccf043d55c086141d4/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66be2815db4475a1c4c4ee60/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b9ef71db1e3403775e90ce/1:1/w_350%2Ch_350%2Cc_limit/undefined",
            "https://media.wired.com/photos/65e713be8b9298d090113e17/1:1/w_270%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b15556baba057eedc796ef/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66b12048cabb7f268cc85fe9/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66955f1af16ebbb57068374d/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66998d07935538ffaede60ae/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/669855e57857389ce8730582/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/6696f46793b5e6b71aac0cc8/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66abceea2a42e539ea389228/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://media.wired.com/photos/66bcfe7ef5cef6fa241bf0a3/16:9/w_800%2Ch_450%2Cc_limit/undefined",
            "https://www.wired.com/verso/static/wired/assets/logo-reverse.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "hollywood",
            "ethics",
            "deepfakes"
        ],
        "tags": null,
        "authors": [
            "Will Bedingfield",
            "Lily Hay Newman",
            "Rhett Allain",
            "Alistair Charlton",
            "Isabel Fraser",
            "Jennifer M. Wood",
            "Brian Stelter",
            "Jason Parham",
            "Angela Watercutter",
            "Jay Ruben Dayrit"
        ],
        "publish_date": "2022-10-17T14:19:31.193000-04:00",
        "summary": "",
        "meta_description": "There’s a fight brewing over how Hollywood stars can protect their identities. But it’s not just actors who should be paying attention.",
        "meta_lang": "en",
        "meta_favicon": "https://www.wired.com/verso/static/wired/assets/favicon.ico",
        "meta_site_name": "WIRED",
        "canonical_link": "https://www.wired.com/story/bruce-willis-deepfake-rights-law/",
        "text": "Jean-Luc Godard once claimed, regarding cinema, “When I die, it will be the end.” Godard passed away last month; film perseveres. Yet artificial intelligence has raised a kindred specter: that humans may go obsolete long before their artistic mediums do. Novels scribed by GPT-3; art conjured by DALL·E—machines could be making art long after people are gone. Actors are not exempt. As deepfakes evolve, fears are mounting that future films, TV shows, and commercials may not need them at all.\n\nNot even Bruce Willis. Last month the actor had the strange experience of “appearing” in an ad where he was tied to a bomb on the back of a yacht, growling \"Mississippi\" in a Russian accent. The Telegraph reported the deepfake was possible because he sold his performance rights. That wasn't quite true—a representative for Willis later told reporters the actor had done no such thing. And as my colleague Steven Levy wrote a few days ago, the company who made the ad—the cheekily named Deepcake—never claimed to hold Willis' future rights, but had struck a deal that allowed the company to map a digital version of his appearance onto another actor in a commercial for the Russian cell network Megafon.\n\nYet the question of “who owns Bruce Willis,” as Levy put it, isn’t only a concern for the Hollywood star and his representatives. It concerns actors unions across the world, fighting against contracts that exploit their members' naivety about AI. And, for some experts, it's a question that implicates everyone, portending a wilder, dystopian future—one in which identities are bought, sold, and seized.\n\nIn America, explains Jennifer Rothman, author of The Right of Publicity: Privacy Reimagined for a Public World, people have a right under various state laws to limit unauthorized appropriation of their identities, particularly their names and likenesses. The scope of protection varies state by state. Some have statutes protecting the “right of publicity” (a law barring unauthorized use of a person’s name, likeness, voice, or other indicia of identity without permission, usually for a commercial purpose), while others offer these safeguards through common, or judge-made, laws. A few have both statutory and common law protections.\n\nThe devil is in the details, though. \"A private individual or company that simply creates a deepfake of a person, without more, does not obviously run afoul of the right of publicity,\" explains David A. Simon, a research fellow at Petrie-Flom Center at Harvard Law School. In other words, if a Willis deepfake appears in an American ad for potato chips, then a claim becomes viable; if someone deepfakes Willis’ yippie-ki-yay swagger into a home movie and throws it on YouTube, the actor may not have much of a case. Under certain circumstances, deepfake makers are protected by the First Amendment. As one Northwestern University paper put it last year, “the government cannot prohibit speech merely because the speech is false; there must be some additional problem,” like defamation.\n\n“The right of publicity requires the commercial appropriation of identity while tort law does not always require a commercial element,” explains Simon. “If an actor's deepfake is manipulated to portray someone in a defamatory manner, or used to defame someone else, the actor may have the ability to sue in tort.\"\n\nActors unions have been fretting over deepfakes for decades. The Screen Actors Guild—American Federation of Television and Radio Artists (SAG-AFTRA)’s interest began with sports video games, which started generating their own image rights controversies back in 2013. Even just looking at the rudimentary and blocky depictions of athletes in video games it was clear that the tech would develop in a way that would make it possible to drop actors into movies as easily as developers could drop quarterbacks into Madden.\n\nIn a landscape of desperate actors, confusing contracts, and multivarious laws, it doesn't take an agile mind to grasp that SAG-AFTRA has its work cut out. The wrong consent given to the wrong company can lead to pretty much any nightmare the mind can weave. Remember that episode of Friends where Joey ended up in an STD advert after a spot of seemingly innocuous modeling? It’s like that, except, in some cases, Joey wouldn't have to model at all. In his (fictional) story, everything was fine at the end of the half-hour, but a different (real) actor could find it hard to get work after being deepfaked into an unflattering or controversial role. And it’s no longer just a problem of visual depiction: Deepfakes allow an actor to be “used,” in Simon’s words, with words quite literally put into their mouths. (TikTok had to settle a legal case recently around this very issue.)\n\n“This is relevant not just to AI contracts [for synthetic performances], but any contract involving rights to one’s likeness and voice,” says Danielle S. Van Lier, assistant general counsel, intellectual property and contracts at SAG-AFTRA. “We have been seeing contracts that now include ‘simulation rights’ to performers’ images, voices, and performances. These contract terms are buried deep in the boilerplate of performance agreements in traditional media.”\n\nYet, and here’s the rub, actors also see the rise of deepfakes as a chance to cash in. “While many never become ‘famous,’ their names, voices, images or likenesses still attain commercial value,” explains Van Lier. The commercial opportunities of synthetic performances–an actor’s voice used in an automated audiobook or appearance as a digital avatar, abound, hence why SAG-AFTRA is pushing away from the term deepfakes–and its association with porn–to terms like “digital double” or “AI-generated.”\n\nThis is where the importance of “transferability” of publicity rights comes in: A law passed in New York in 2020, for instance, allows postmortem rights to be transferred. “The ability to license and convey this property interest provides an important source of revenue to these professionals and their families,” says Van Lier. “Licensing allows creative professionals to work with entities and individuals with technological, financial and legal expertise, and to maximize the value of the asset.”\n\nIt’s crucial to understand here that transferability isn’t about authorizing uses of your identity for money; it’s about ownership, your identity conceived of as a transferable property right, like patents or copyrights, able to be bought and sold. “It affects whether the right over a person's identity is transferred (and taken away) from them and owned by a third party,” says Rothman.\n\nFor some experts, this transferability could lead to people losing control of their “personality” as firms take full ownership of their identity rather than just a licensed use for a particular purpose. In fact, the original calls for these kinds of transferability were made in the 1950s by studio lawyers who wanted to control the movies that actors appeared in and the products they endorsed. “One might (potentially) garner more money for such a total transfer, but the cost seems inconceivably great to the person and society,” Rothman says.\n\nStudent athletes, for instance, risk agents, managers, companies, or even the NCAA hoovering up their identities in the hope of extracting any future profit if they find big-league success. Actors, athletes, and average citizens, Rothman argues, are in danger of losing control of their \"own names, likenesses, and voices to creditors, ex-spouses, record producers, managers, and even Facebook.\"\n\nMany actors won’t be affected, simply because their identities won’t be valuable. But it is also true that celebrities like Kim Kardashian and Tom Cruise have bargaining power that others don’t: They can bullishly negotiate that the use of their image not extend beyond any particular show or film. Smaller actors, meanwhile, face the possibility of contracts that extract rights wholesale. \"There is a real risk that new actors (i.e., just starting out and desperate for breakthrough work) would be especially vulnerable to signing away their publicity rights as a condition of their first contracts,\" says Johanna Gibson, a professor of intellectual property law at Queen Mary, University of London. \"This power imbalance could be exploited by studios keen both to commercialize image and character and indeed to avoid libel (depending upon the nature of that commercialization), as the performer would no longer have rights to control how their image is used.\"\n\nThis could leave actors in a position of either missing out on work, or signing a contract that would later allow them to be deepfaked into content they find demeaning without legal recourse. In the film franchise model, Gibson argues, the risk is even greater.\n\nSAG-AFTRA disagrees, explaining that reasonable minds will always differ, even when working toward the same stated goal. “While some prominent commentators have expressed fear that a transferable right of publicity could lead to involuntary transfers or forced commercialization, there is little basis to believe this fear would come to fruition,” says Van Lier. ”There are no instances, to our knowledge, of the right being involuntarily transferred during anyone’s lifetime or anyone being forced to exploit it. The most notable attempt involved OJ Simpson and the court expressly refused to transfer it to his victim’s family.”\n\nEventually, AIs trained on Bruce Willis’ likeness won't need Bruce Willis at all. “If a company can train its AI algorithms to replicate the specific mannerisms, timing, tonality, etc. of a particular actor, it makes the AI-generated content more and more life-like,” says Van Lier. “This can have long-term implications.” In other words, actors—and everyone else—must learn how to protect their digital rights, or they could find themselves performing a role they did not expect."
    }
}