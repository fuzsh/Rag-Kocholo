{
    "id": "correct_subsidiary_00001_3",
    "rank": 58,
    "data": {
        "url": "https://opusresearch.net/2022/12/01/amazon-reinventing-alexa-it-doesnt-look-like-it/",
        "read_more_link": "",
        "language": "en",
        "title": "Amazon re:Inventing Alexa? It doesn’t Look Like It.",
        "top_image": "https://opusresearch.net/wp-content/uploads/2022/12/Alexa-Logo.png",
        "meta_img": "https://opusresearch.net/wp-content/uploads/2022/12/Alexa-Logo.png",
        "images": [
            "https://opusresearch.net/wp-content/uploads/2021/04/Screen_Alt2_Apr2021.png",
            "https://opusresearch.net/wp-content/uploads/2022/12/Alexa-Logo-300x300.png",
            "https://opusresearch.net/wp-content/uploads/2024/07/LeverageAI_featured-105x85.png",
            "https://opusresearch.net/wp-content/uploads/2024/06/Genesys-logo-105x85.png",
            "https://opusresearch.net/wp-content/uploads/2024/05/OpusEnghouse_speakers-105x85.png",
            "https://opusresearch.net/wp-content/uploads/2024/05/Vbot-105x85.png",
            "https://c.statcounter.com/2446294/0/13e565fc/0/"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Dan Miller"
        ],
        "publish_date": "2022-12-01T00:00:00",
        "summary": "",
        "meta_description": "News of \"massive layoffs\" at Amazon's Worldwide Digital Division rattled the cohort of individuals interested in voice-based services and Conversational AI.",
        "meta_lang": "en",
        "meta_favicon": "https://opusresearch.net/wp-content/uploads/2015/08/cropped-opus_dots_180-32x32.png",
        "meta_site_name": "",
        "canonical_link": "https://opusresearch.net/2022/12/01/amazon-reinventing-alexa-it-doesnt-look-like-it/",
        "text": "Amazon convened re:Invent 2022 in the midst of “massive layoffs” in its Worldwide Digital Division because it is on track to lose $10 billion this year. This news rattled the cohort of individuals interested in voice-based services and Conversational AI, who now question whether lack of interest and use of Alexa reflects overall disappointment in voice services, including the prospect of integrating Alexa into the customer care or digital commerce plans of major brands and global enterprises.\n\nMost of the post-mortems track back to an article by Eugene Kim in Business Insider (behind a paywall of course). Alexa is characterized as a pet project of founder and former CEO Jeff Bezos, who gave it tremendous runway when it was introduced in 2014. Yet numerous efforts to “monetize” the operation failed. Instead, the 70 million or so Echos and other devices that support Alexa were relegated to responding a a short set of commands like “tell me the news.” “What’s the weather” or “turn on the lights in the kitchen and start the coffee maker.” It never blossomed into a full-blown medium for ordering goods (from Amazon), entertainment or efforts to incorporate it into e-commerce strategies like ordering a pizza or summoning an Uber. All proved to be unpopular.\n\nThis led Ron Amadeo, author of the above-mentioned article in Ars Technics to ask the rhetorical question: “Are all voice assistants doomed?”, noting that Google Assistant suffers the same woes as Alexa. His implicit answer is “yes.” In the face of mounting losses both Google and Amazon are cutting resources to their respective divisions.\n\nIt Didn’t Have to be Thus\n\nA year ago at re:Invent 2021, in a session called “What’s new with Amazon Alexa”, Chief Technical Evangelist for Alexa, Jeff Blankenberg, painted a very rosy picture for the voice assistant. He noted that over 150,000 Alexa skills had been developed by its community of developers, noting that some percentage of them were “making seven-figures” from their skills. He also noted that “developer revenue” from “in-skill purchasing” had doubled year-over-year. Of special note in Blankenberg’s presentation were initiatives to address things like the “Voice Interoperability Issue”, where steps were being taken to enable individuals or businesses to build skills that employed their own wake-word and connected with a multiplicity of other voice assistants. Other innovations included a “Transit” app that let Alexa users do a better job of planning their commute; a “Find my” app to use Alexa to locate the devices or people that are important to the device owners; and Shopping Actions as a mechanism for merchants to sell goods or service through Alexa.\n\nAll of these initiatives are still in place. For instance, it was recently reported that more than 130,000 third-party sellers worldwide surpassed $100,000 in sales on Amazon using Shopping Actions during the holiday season in 2021. But they have a decidedly low profiled among all of AWS’s offerings. Upon reviewing the agenda on the virtual re:Invent 2022 Website, I could find no mention of a “What’s new with Amazon Alexa” to provide an updated picture. That left me doom scrolling Google, Twitter and LinkedIn for further mentions of Alexa’s cruel fate and, by extension, Siri, Google Assistant, Cortana, Bixby and other Voice Assistants. It became evident that each of the virtual assistants trying to tap into the prospects for repeated use and monetization shared a single Achilles heel. They don’t talk to one another and they don’t do a very good job of engaging with the customer care infrastructure that all brands have integrated into their contact centers, Web sites, mobile apps and digital messaging platforms.\n\nIn the 8+ years since Alexa was introduced, thousands of companies staffed up or contracted with developers to build their own Alexa Skill. Very few of these initiatives were designed to integrate with existing customer care contact centers. This should not be surprising because, even though it is a voice assistant, Alexa does not share any of the real-time voice stream created by its end-users. Instead Amazon captures and transcribes the spoken words in near-real time and shares transcriptions with the third parties (including skills developers). Gone is the rich content represented by the pitch, cadence and timbre that are routinely used in contact centers to gauge agent performance or user sentiment. Companies can’t use the voice of an individual be used to authenticating each end-user. Thus brands lacked sufficient confidence to pull up customer profiles and offer personalized services.\n\nCompetitive treat voice as an asset and make it a key component of the “Conversational Intelligence” that informs future conversations between customers and agents or between customers and bots. Amazon has all of that information. It just doesn’t share. That is the first Red Flag for enterprise implementers and major barrier to monetization.\n\nYou Can Now Reach an Agent Through Alexa, But it Isn’t Easy\n\nAmazon’s Echo devices were positioned initially as “smart speakers” and Alexa was the voice assistant mated to it. They were never telephones, although Alexa has also been instantiated as an app for smartphones, as well as a voice assistant on a few makes of automobiles like BMW and Lamborghini. It is also often used to understand commands for smart appliances, home controllers and lighting systems.\n\nInitiating a phone call or reaching out to a customer care agent in a contact center involves a whole different set of skills for Alexa. Two notable instances reflect the fact that there may be some fundamental demand for making voice calls through an Alexa while, at the same time showing that a lot of activity has to go on under the proverbial covers. One approach, described here, enables developers to employ an Alexa Skills Kit (ASK) to enable Alexa users to initiate a chat or trigger a call with a customer service agent.\n\nIt is the product of a marriage between the ASK and Amazon Connect, a proprietary Contact Center as a Service (CCaaS) offering. As described in the technical how-to, It appears to require the customer to use the Alexa app on a smartphone, instead of talking to an Echo or a car’s infocenter. Authors Cuong Do Vu and Soumiya Mathur, describe how an Alexa user, while using a skill provided by the brand of their choice can say “Connect me to an agent” and thus initiate a number of steps. After authenticating the user and it lets them initiate a chat session right away.\n\nIf the customer wants to talk to an agent, an instruction is sent to the brains in Amazon Connect to treat the session as a “Callback”. In other words, instead of calling into a business to reach an agent, the Alexa skill signals a resource in AWS to request that Amazon Connect initiate a call to the customer and then connects to an agent. Seems like a lot of processes are invoked to make a simple phone call and we have not feedback about whether any enterprise customer is using this function.\n\nAnother, longer standing effort to enable Alexa to make phone calls originates from the group that offers Chime SDK. It’s called “Skill Calling”. It is not restricted to talking only to an Amazon Connect contact center. Instead, it enables the user of an Alexa skill to place calls using simple voice commands. As an example, after the obligatory “Alexa” and opening a skill the user can simply say “Call customer support” and be connected to an existing support resource.\n\nWhile the user interface remains cumbersome, users no longer need to originate activity from an Alexa app on a smartphone. Nor are they triggering a succession of events that lead to a callback from Amazon Connect. A user is literally originating a phone call to a customer care agent. The call can be routed via SIP, a telephone number or (optimistically) connected to an Amazon Chime meeting. More importantly, “Relevant data such as the username, account ID, and reason for the call is attached by skill developers to the communication session to help reduce handle times and improve customer satisfaction scores.” It’s a small tunnel out of Alexa’s walled garden.\n\nRoom for Improvement\n\nMaking Alexa a financial success was always going to be a challenge. In addition to an inability to make a phone call, privacy concerns convinced some 40% of the potential market to forego purchase and use. The VUI is not conducive to including advertisements. The use of “alerts” or “notifications” to tell an Amazon shopper when it is time to re-order a frequently purchased item (paper towels, toilet paper, bottled water) has been regarded as intrusive. Yet the biggest factor is an underlying architecture and ecosystem that sets Alexa apart from other voice assistants and makes development of skills and applications incompatible with other platforms. Lack of standardization across platforms has been a huge barrier to enterprise customer service professionals who already have a multiplicity of messaging platforms and voice assistants to try to support.\n\nThe initiatives from Amazon Connect and Chime SDK try to tackle the challenges of interconnecting with contact centers and other customer support infrastructure. That’s a start. Outside of Amazon, Open Voice Network has initiated a number of projects and workshops designed to promote interoperability among voice assistance and to overcome many of the barriers to enterprise adoption of Conversational AI. With tens of millions of devices capable of understanding and responding to the words their owners say, it is not too late to open things up, expand capabilities to real-time communications and promote enterprise-aware applications.\n\nRelated\n\nCategories: Intelligent Assistants, Articles"
    }
}