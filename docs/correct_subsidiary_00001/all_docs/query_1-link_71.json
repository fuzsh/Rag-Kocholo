{
    "id": "correct_subsidiary_00001_1",
    "rank": 71,
    "data": {
        "url": "https://www.oii.ox.ac.uk/news-events/shes-not-listening-they-are-new-research-investigates-why-we-trust-amazons-alexa-in-our-homes/",
        "read_more_link": "",
        "language": "en",
        "title": "She’s not listening they are: New research investigates why we trust Amazon’s Alexa in our homes",
        "top_image": "https://www.oii.ox.ac.uk/wp-content/uploads/2023/10/AI-image-Katya-story-small-file-size-700x395.webp",
        "meta_img": "https://www.oii.ox.ac.uk/wp-content/uploads/2023/10/AI-image-Katya-story-small-file-size-700x395.webp",
        "images": [
            "https://www.oii.ox.ac.uk/wp-content/themes/OII2022/assets/logos/OII-white-text-140.png",
            "https://www.oii.ox.ac.uk/wp-content/themes/OII2022/assets/logos/OII-blue-text-140.png",
            "https://www.oii.ox.ac.uk/wp-content/uploads/2023/10/AI-image-Katya-story-small-file-size-700x395.webp 700w, https://www.oii.ox.ac.uk/wp-content/uploads/2023/10/AI-image-Katya-story-small-file-size-450x254.webp 450w",
            "https://www.oii.ox.ac.uk/wp-content/themes/OII2022/assets/logos/OII-white-text-140.png",
            "https://www.oii.ox.ac.uk/wp-content/uploads/2022/03/Ekaterina-Hertog-170x170.png",
            "https://www.oii.ox.ac.uk/wp-content/uploads/2023/10/Elizabeth-Fetterolf-headshot-170x170.webp",
            "https://www.oii.ox.ac.uk/wp-content/uploads/2022/03/DomesticAI.png",
            "https://www.oii.ox.ac.uk/wp-content/themes/OII2022/assets/logos/OII-white-text-140.png",
            "https://www.oii.ox.ac.uk/wp-content/themes/OII2022/assets/logos/Athena-Swan.png",
            "https://www.oii.ox.ac.uk/wp-content/plugins/gdpr-cookie-compliance/dist/images/gdpr-logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Ekaterina Hertog",
            "Elizabeth Fetterolf",
            "domestic work. View profile"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Users of Amazon’s voice assistant Alexa are employing three strategies to manage distrust in the technology, a new study by researchers at the University of Oxford and Stanford University finds.",
        "meta_lang": "en",
        "meta_favicon": "https://www.oii.ox.ac.uk/wp-content/themes/OII2022/assets/logos/favicon.ico?v=2",
        "meta_site_name": "",
        "canonical_link": "https://www.oii.ox.ac.uk/news-events/shes-not-listening-they-are-new-research-investigates-why-we-trust-amazons-alexa-in-our-homes/",
        "text": "Users of Amazon’s voice assistant Alexa are employing three strategies to manage distrust in the technology, a new study by researchers at the University of Oxford and Stanford University finds.\n\nIn their paper “It’s Not Her Fault: Trust through Anthropomorphism among Young Adult Amazon Alexa Users” published in the journal Convergence, Professor Ekaterina Hertog, Oxford Internet Institute, and Elizabeth Fetterolf a doctoral student at Stanford University, reveal how privacy and data collection concerns affect the use of the technology.\n\nThrough a series of interviews with Alexa users, the researchers found that despite a distrust of artificial intelligence (AI) in the home, users of Amazon’s Alexa managed their misgivings in three ways:\n\nAnthropomorphism: Users viewed Alexa as having a separate, individual identity from Amazon. This involved seeing the technology as a human-like “feminized secretary” enabling a sense of security to be built around the technology having a presence in their homes and access to personal data.\n\nDigital resignation: Whilst all participants expressed concerns about their personal data being used, with many being certain that Amazon was collecting it, there was a feeling that this was inevitable. Alexa was not seen as a source of the problem with the blame being placed on Amazon and tech companies in general.\n\nSetting boundaries: Alexa users in the study took action to prevent the device from having access to parts of their homes and lives that they explicitly wanted to remain private. This included not having the device in some areas of the house or switching it off during certain conversations.\n\nThe researchers noted that users of Alexa had a fluid, shifting view of the technology. For example, the language they used to refer to the device included the gendered pronouns “she” and “her” when discussing the voice assistant in a positive light. This demonstrated how Alexa was sometimes seen as a human-like companion. When speaking about Alexa in the context of Amazon the device was referred to as “it”. Professor Hertog notes that “This unstable use of pronouns potentially reflects users’ attempt to separate Alexa from Amazon deeming Alexa “trustworthy enough” while continuing to distrust its parent company”.\n\nThe researchers found that despite a complex relationship between the usefulness and enjoyment of the technology and an understanding that the device enabled their personal data to be collected, all users found a way to trust the device, albeit in a limited way for some.\n\n200 million Alexa voice assistant devices exist in homes around the world and sales of the device continue to grow.\n\nElizabeth Fetterolf, doctoral candidate in the Department of Communications at Stanford University, commented on the rise of AI in the home:\n\n“Amazon’s dominance in the home, not just via Alexa but in its attempt to become a one-stop-shop for many domestic needs, raises major concerns about privacy, surveillance, and trust. As people get more comfortable with the idea of “Alexa listening,” this could result in a lack of appetite to take substantive steps both to protect privacy on the individual level and imagine any kind of collective resistance to the severe human and environmental toll associated with the device’s production.”\n\nNote for Editors:\n\nContacts: for interviews and briefings, please contact press@oii.ox.ac.uk\n\nAbout the study\n\nNine months of fieldwork was conducted from November 2020-July 2021, with data collected via semi-structured interviews with 16 Amazon Alexa Users based in the USA. The individuals in the study were all childless in their early 20s and 30s. The CUREC number for this paper is SOC_R2_001_CIA_21_10. The research is funded by the European Social Fund; ES/T007265/1.\n\nThe full study is published here. The full title of the research is: “It’s Not Her Fault: Trust through Anthropomorphism among Young Adult Amazon Alexa Users”, Professor Ekaterina Hertog is an Associate Professor of AI and Society at Oxford Internet Institute and Institute for Ethics in AI. She studies how the rising digitalisation is reshaping private lives across the world. Elizabeth Fetterolf is a Doctoral Student at Stanford University and holds an MSc from the University of Oxford. They study how new technologies are changing care and domestic work, and how the existing crisis of care shapes how these same technologies are developed.\n\nAbout the OII\n\nThe Oxford Internet Institute (OII) is a multidisciplinary research and teaching department of the University of Oxford, dedicated to the social science of the Internet. Drawing from many different disciplines, the OII works to understand how individual and collective behaviour online shapes our social, economic and political world. Since its founding in 2001, research from the OII has had a significant impact on policy debate, formulation and implementation around the globe, as well as a secondary impact on people’s wellbeing, safety and understanding. Drawing on many different disciplines, the OII takes a combined approach to tackling society’s big questions, with the aim of positively shaping the development of the digital world for the public good.\n\nAbout the University of Oxford"
    }
}