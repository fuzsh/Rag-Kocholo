{
    "id": "dbpedia_1852_3",
    "rank": 63,
    "data": {
        "url": "https://github.com/liliu-avril/Awesome-Segment-Anything",
        "read_more_link": "",
        "language": "en",
        "title": "Anything: This repository is for the first comprehensive survey on Meta AI's Segment Anything Model (SAM).",
        "top_image": "https://opengraph.githubassets.com/ef2130009e4261350fffe93f124157bd9b6d37917423dd3b6a9ce7b95db3ad29/liliu-avril/Awesome-Segment-Anything",
        "meta_img": "https://opengraph.githubassets.com/ef2130009e4261350fffe93f124157bd9b6d37917423dd3b6a9ce7b95db3ad29/liliu-avril/Awesome-Segment-Anything",
        "images": [
            "https://camo.githubusercontent.com/50a927de513460609cfad453b7260a5882ecaef04403bf77b6eaf8839adbd32a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d61696e7461696e65642533462d7965732d677265656e2e737667",
            "https://camo.githubusercontent.com/91dd7f00641477630e6a2c46baeba2e1bf20b98d0257f55ce4ba06dcb5f7c6d2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c6174",
            "https://camo.githubusercontent.com/50cf39121274b3db22bf1bd72cbe25af9078e037441cb5b5bdef1cc9dc5eb2f7/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667",
            "https://avatars.githubusercontent.com/u/32026228?s=64&v=4",
            "https://avatars.githubusercontent.com/u/88330145?s=64&v=4",
            "https://avatars.githubusercontent.com/u/42180243?s=64&v=4",
            "https://avatars.githubusercontent.com/u/25822099?s=64&v=4",
            "https://avatars.githubusercontent.com/u/32676198?s=64&v=4",
            "https://avatars.githubusercontent.com/u/65330217?s=64&v=4"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "liliu-avril"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "This repository is for the first comprehensive survey on Meta AI's Segment Anything Model (SAM).  - GitHub - liliu-avril/Awesome-Segment-Anything: This repository is for the first comprehensive survey on Meta AI's Segment Anything Model (SAM).",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/liliu-avril/Awesome-Segment-Anything",
        "text": "Feng Liu, Qinlong Zhang, Weijie Zhang, Deqiang Cheng, Feng Zhang, Yating Deng, Guanzhen Yu.\n\n\"An analysis on efficacy of applying β-elemene intervention on chemically -induced tongue lesions using SAM algorithm.\" Anatomia, Histologia, Embryologia (2024). [paper] [2024.08]\n\nMSP-MVS: Zhenlong Yuan, Cong Liu, Fei Shen, Zhaoxin Li, Tianlu Mao, Zhaoqi Wang.\n\n\"MSP-MVS: Multi-granularity Segmentation Prior Guided Multi-View Stereo.\" AAAI (2024). [paper] [2024.08]\n\nSae-Jin Park, Cheonghwa Lee, Kisu Ok and Sung-Hoon Ahn.\n\n\"Enhancing Aviation Safety: An Automated System for FOD Detection and Removal in Support Vehicle Tires.\" AIAA Aviation Forum and ASCEND (2024). [paper] [2024.08]\n\nTheia: Jinghuan Shang, Karl Schmeckpeper, Brandon B. May, Maria Vittoria Minniti, Tarik Kelestemur, David Watkins, Laura Herlant.\n\n\"Theia: Distilling Diverse Vision Foundation Models for Robot Learning.\" ArXiv (2024). [paper] [code] [2024.08]\n\nHaoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski.\n\n\"Segment anything model 2: an application to 2D and 3D medical images.\" ArXiv (2024). [paper] [2024.08]\n\nXiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri.\n\n\"Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM.\" IEEE NSS and MIC (2024). [paper] [2024.08]\n\nDMESA: Yesheng Zhang, Xu Zhao.\n\n\"DMESA: Densely Matching Everything by Segmenting Anything.\" ArXiv (2024). [paper] [code] [2024.08]\n\nCC-SAM: Shreyank N Gowda, David A. Clifton.\n\n\"CC-SAM: SAM with Cross-feature Attention and Context for Ultrasound Image Segmentation.\" ECCV (2024). [paper] [2024.07]\n\nSAMCOD: Lv Tang, Bo Li.\n\n\"Evaluating SAM2's Role in Camouflaged Object Detection: From SAM to SAM2.\" ArXiv (2024). [paper] [code] [2024.07]\n\nFLAP-SAM: Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar.\n\n\"A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation.\" ArXiv (2024). [paper] [code] [2024.07]\n\nRoBox-SAM: Yuhao Huang, Xin Yang, Han Zhou, Yan Cao, Haoran Dou, Fajin Dong, Dong Ni.\n\n\"Robust Box Prompt based SAM for Medical Image Segmentation.\" MICCAI MLMI (2024). [paper] [2024.07]\n\nPascal Spiegler, Amirhossein Rasoulian, Yiming Xiao.\n\n\"Weakly Supervised Intracranial Hemorrhage Segmentation with YOLO and an Uncertainty Rectified Segment Anything Model.\" ArXiv (2024). [paper] [2024.07]\n\nICH: Pascal Spiegler, Amirhossein Rasoulian, Yiming Xiao.\n\n\"Uncertainty-Rectified YOLO-SAM for Weakly Supervised ICH Segmentation.\" SWITCH (2024). [paper] [2024.07]\n\nASI-Seg: Zhen Chen, Zongming Zhang, Wenwu Guo, Xingjian Luo, Long Bai, Jinlin Wu, Hongliang Ren, Hongbin Liu.\n\n\"ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding.\" IROS (2024). [paper] [code] [2024.07]\n\nLibrary Dataset: Artemis Llabrés, Arka Ujjal Dey, Dimosthenis Karatzas, Ernest Valveny.\n\n\"Image-text matching for large-scale book collections.\" ArXiv (2024). [paper] [code] [2024.07]\n\nAdaCLIP: Yunkang Cao, Jiangning Zhang, Luca Frittoli, Yuqi Cheng, Weiming Shen, Giacomo Boracchi.\n\n\"AdaCLIP: Adapting CLIP with Hybrid Learnable Prompts for Zero-Shot Anomaly Detection.\" ECCV (2024). [paper] [code] [2024.07]\n\nVDST-Net: Guiqiu Liao, Matjaz Jogan, Sai Koushik, Eric Eaton, Daniel A. Hashimoto.\n\n\"Disentangling spatio-temporal knowledge for weakly supervised object detection and segmentation in surgical video.\" ArXiv (2024). [paper] [2024.07]\n\nPixLabelCV: Dominik Schraml, et al.\n\n\"PixLabelCV - Labeling images for semantic segmentation fast, pixel-precise and offline.\" WSCG (2024). [paper] [2024.07]\n\nESOD: Kai Liu, Zhihang Fu, Sheng Jin, Ze Chen, Fan Zhou, Rongxin Jiang, Yaowu Chen, Jieping Ye.\n\n\"ESOD: Efficient Small Object Detection on High-Resolution Images.\" ArXiv (2024). [paper] [2024.07]\n\nRen Z, Zhang Y, Wang S.\n\n\"Large Foundation Model for Cancer Segmentation.\" Technology in Cancer Research & Treatment (2024). [paper] [2024.07]\n\nGuo Y, Xu Y, Cui H, Dang M, Li S.\n\n\"Segment anything model-based crack segmentation using low-rank adaption fine-tuning.\" Structural Health Monitoring (2024). [paper] [2024.07]\n\nSSTD: Zijian Zhu, Ali Zia, Xuesong Li, Bingbing Dan, Yuebo Ma, Enhai Liu, Rujin Zhao.\n\n\"SSTD: Stripe-Like Space Target Detection using Single-Point Supervision.\" ArXiv (2024). [paper] [2024.07]\n\nKneeSegmentWithSAM: Yaxi Chen, Aleksandra Ivanova, Shaheer U. Saeed, Rikin Hargunani, Jie Huang, Chaozong Liu, Yipeng Hu.\n\n\"Segmentation by registration-enabled SAM prompt engineering using five reference images.\" WBIR (2024). [paper] [code] [2024.07]\n\nSAM-MIL: Heng Fang, Sheng Huang, Wenhao Tang, Luwen Huangfu, Bo Liu.\n\n\"SAM-MIL: A Spatial Contextual Aware Multiple Instance Learning Approach for Whole Slide Image Classification.\" ACM MM (2024). [paper] [code] [2024.07]\n\nSAM-CP: Pengfei Chen, Lingxi Xie, Xinyue Huo, Xuehui Yu, Xiaopeng Zhang, Yingfei Sun, Zhenjun Han, Qi Tian.\n\n\"SAM-CP: Marrying SAM with Composable Prompts for Versatile Segmentation.\" ArXiv (2024). [paper] [code] [2024.07]\n\nJiyeop Kim, Jongwoo Lim.\n\n\"Integrating Meshes and 3D Gaussians for Indoor Scene Reconstruction with SAM Mask Guidance.\" ArXiv (2024). [paper] [2024.07]\n\nSAM2CLIP2SAM: Dimitrios Kollias, Anastasios Arsenos, James Wingate, Stefanos Kollias.\n\n\"SAM2CLIP2SAM: Vision Language Model for Segmentation of 3D CT Scans for Covid-19 Detection.\" ArXiv (2024). [paper] [2024.07]\n\nMedSAGa: Navyansh Mahla, Annie D'souza, Shubh Gupta, Bhavik Kanekar, Kshitij Sharad Jadhav.\n\n\"MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using Gradient Low-Rank Projection in SAM.\" ArXiv (2024). [paper] [2024.07]\n\nESP-MedSAM: Qing Xu, Jiaxuan Li, Xiangjian He, Ziyu Liu, Zhen Chen, Wenting Duan, Chenxin Li, Maggie M. He, Fiseha B. Tesema, Wooi P. Cheah, Yi Wang, Rong Qu, Jonathan M. Garibaldi.\n\n\"ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation.\" IEEE TMI (2024). [paper] [2024.07]\n\nSemantic-CC: Yongshuo Zhu, Lu Li, Keyan Chen, Chenyang Liu, Fugen Zhou, Zhenwei Shi.\n\n\"Semantic-CC: Boosting Remote Sensing Image Change Captioning via Foundational Knowledge and Semantic Guidance.\" ArXiv (2024). [paper] [2024.07]\n\nSeismic Fault SAM: Ran Chen, Zeren Zhang, Jinwen Ma.\n\n\"Seismic Fault SAM: Adapting SAM with Lightweight Modules and 2.5D Strategy for Fault Detection.\" ArXiv (2024). [paper] [2024.07]\n\nVISA: Cilin Yan, Haochen Wang, Shilin Yan, Xiaolong Jiang, Yao Hu, Guoliang Kang, Weidi Xie, Efstratios Gavves.\n\n\"VISA: Reasoning Video Object Segmentation via Large Language Models.\" ArXiv (2024). [paper] [code] [2024.07]\n\nG-SAM: Xiaoxiao Liu, Yan Zhao, Shigang Wang & Jian Wei .\n\n\"G-SAM: GMM-based segment anything model for medical image classification and segmentation.\" Cluster Comput (2024). [paper] [2024.07]\n\nUniFSS: Shijie Chang, Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu.\n\n\"Beyond Mask: Rethinking Guidance Types in Few-shot Segmentation.\" ArXiv (2024). [paper] [2024.07]\n\nTeethDreamer: Chenfan Xu, Zhentao Liu, Yuan Liu, Yulong Dou, Jiamin Wu, Jiepeng Wang, Minjiao Wang, Dinggang Shen, Zhiming Cui.\n\n\"TeethDreamer: 3D Teeth Reconstruction from Five Intra-oral Photographs.\" MICCAI (2024). [paper] [code] [2024.07]\n\nCorrosion SAM: Chengzhang Chai, Yan Gao, Haijiang Li, Xiaofeng Zhu.\n\n\"Corrosion SAM: Adapting Segment Anything Model with Parameter-Efficient Fine-Tuning for Structural Corrosion Inspection.\" ArXiv (2024). [paper] [2024.07]\n\nPartImageNet++: Xiao Li, Yining Liu, Na Dong, Sitian Qin, Xiaolin Hu.\n\n\"PartImageNet++ Dataset: Scaling up Part-based Models for Robust Recognition.\" ECCV (2024). [paper] [code] [2024.07]\n\nTeSO: Yaoting Wang, Peiwen Sun, Yuanchao Li, Honggang Zhang, Di Hu.\n\n\"Can Textual Semantics Mitigate Sounding Object Segmentation Preference?.\" ECCV (2024). [paper] [code] [2024.07]\n\nFoodMem: Ahmad AlMughrabi, Adrián Galán, Ricardo Marques, Petia Radeva.\n\n\"FoodMem: Near Real-time and Precise Food Video Segmentation.\" ArXiv (2024). [paper] [2024.07]\n\nSeFi-CD: Ling Zhao, Zhenyang Huang, Dongsheng Kuang, Chengli Peng, Jun Gan, Haifeng Li.\n\n\"SeFi-CD: A Semantic First Change Detection Paradigm That Can Detect Any Change You Want.\" ArXiv (2024). [paper] [2024.07]\n\nJaime Duque-Domingo, et al.\n\n\"Segmentaci ́on sem ́antica bajo paradigmaone-shot learning utilizando SAM y CP-CVV.\" Visión por Computador (2024). [paper] [2024.07]\n\nDriveSAM: K Kwakye, Y Seong, S Yi, A Aboah.\n\n\"DriveSAM: Cognitive Perspective on Driving Maneuvers Based on Drivers’ Attention Using Eye Gaze Data.\" IEOM International Conference on Smart Mobility and Vehicle Electrification (2024). [paper] [2024.07]\n\nSwiss DINO: Kirill Paramonov, Jia-Xing Zhong, Umberto Michieli, Jijoong Moon, Mete Ozay.\n\n\"Swiss DINO: Efficient and Versatile Vision Framework for On-device Personal Object Search.\" IROS (2024). [paper] [code] [2024.07]\n\nECoT: Michał Zawalski, William Chen, Karl Pertsch, Oier Mees, Chelsea Finn, Sergey Levine.\n\n\"Robotic Control via Embodied Chain-of-Thought Reasoning.\" ArXiv (2024). [paper] [code] [2024.07]\n\nCLIPtra: Tong Shao, Zhuotao Tian, Hang Zhao, Jingyong Su.\n\n\"Explore the Potential of CLIP for Training-Free Open Vocabulary Semantic Segmentation.\" ECCV (2024). [paper] [code] [2024.07]\n\nPaveSAM: Neema Jakisa Owor, Yaw Adu-Gyamfi, Armstrong Aboah and Mark Amo-Boateng.\n\n\"PaveSAM – segment anything for pavement distress.\" RMPD (2024). [paper] [2024.07]\n\nUCE: Shaozhe Hao, Kai Han, Zhengyao Lv, Shihao Zhao, Kwan-Yee K. Wong.\n\n\"ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction.\" ECCV (2024). [paper] [code] [2024.07]\n\nPseudo-RIS: Seonghoon Yu, Paul Hongsuck Seo, Jeany Son.\n\n\"Pseudo-RIS: Distinctive Pseudo-supervision Generation for Referring Image Segmentation.\" ECCV (2024). [paper] [code] [2024.07]\n\nMeshSegmenter: Ziming Zhong, Yanxu Xu, Jing Li, Jiale Xu, Zhengxin Li, Chaohui Yu, Shenghua Gao.\n\n\"MeshSegmenter: Zero-Shot Mesh Semantic Segmentation via Texture Synthesis.\" ECCV (2024). [paper] [code] [2024.07]\n\nSOSS: Mario Francisco Munoz, Hoang Vu Huy, Thanh-Dung Le.\n\n\"Hybrid Deep Learning-Based for Enhanced Occlusion Segmentation in PICU Patient Monitoring.\" ArXiv (2024). [paper] [2024.07]\n\nXingyue Zhao, Peiqi Li, Xiangde Luo, Meng Yang, Shi Chang, Zhongyu Li.\n\n\"SAM-Driven Weakly Supervised Nodule Segmentation with Uncertainty-Aware Cross Teaching.\" ISBI (2024). [paper] [2024.07]\n\nFryderyk Kögl, Anna Reithmeir, Vasiliki Sideri-Lampretsa, Ines Machado, Rickmer Braren, Daniel Rückert, Julia A. Schnabel, Veronika A. Zimmer.\n\n\"General Vision Encoder Features as Guidance in Medical Image Registration.\" WBIR MICCAI (2024). [paper] [code] [2024.07]\n\nDSAM: Zhenni Yu, Xiaoqin Zhang, Li Zhao, Yi Bin, Guobao Xiao.\n\n\"Exploring Deeper! Segment Anything Model with Depth Perception for Camouflaged Object Detection.\" ACM MM (2024). [paper] [code] [2024.07]\n\nOMG-Net: Zhuoyan Shen, Mikael Simard, Douglas Brand, Vanghelita Andrei, Ali Al-Khader, Fatine Oumlil, Katherine Trevers, Thomas Butters, Simon Haefliger, Eleanna Kara, Fernanda Amary, Roberto Tirabosco, Paul Cool, Gary Royle, Maria A. Hawkins, Adrienne M. Flanagan, Charles-Antoine Collins Fekete.\n\n\"OMG-Net: A Deep Learning Framework Deploying Segment Anything to Detect Pan-Cancer Mitotic Figures from Haematoxylin and Eosin-Stained Slides.\" ArXiv (2024). [paper] [2024.07]\n\nFastSAM-3DSlicer: Yiqing Shen, Xinyuan Shao, Blanca Inigo Romillo, David Dreizin, Mathias Unberath.\n\n\"FastSAM-3DSlicer: A 3D-Slicer Extension for 3D Volumetric Segment Anything Model with Uncertainty Quantification.\" ArXiv (2024). [paper] [code] [2024.07]\n\nCrowd-SAM: Zhi Cai, Yingjie Gao, Yaoyan Zheng, Nan Zhou, Di Huang.\n\n\"Crowd-SAM: SAM as a Smart Annotator for Object Detection in Crowded Scenes.\" ECCV (2024). [paper] [code] [2024.07]\n\nSLF: Jianhao Li, Tianyu Sun, Zhongdao Wang, Enze Xie, Bailan Feng, Hongbo Zhang, Ze Yuan, Ke Xu, Jiaheng Liu, Ping Luo.\n\n\"Segment, Lift and Fit: Automatic 3D Shape Labeling from 2D Prompts.\" ECCV (2024). [paper] [2024.07]\n\nYunya Gao.\n\n\"Leveraging Segment Anything Model in Identifying Buildings within Refugee Camps (SAM4Refugee) from Satellite Imagery for Humanitarian Operations.\" ArXiv (2024). [paper] [2024.07]\n\nWPS-SAM: Xinjian Wu, Ruisong Zhang, Jie Qin, Shijie Ma, Cheng-Lin Liu.\n\n\"WPS-SAM: Towards Weakly-Supervised Part Segmentation with Foundation Models.\" ECCV (2024). [paper] [code] [2024.07]\n\nLite-SAM: Jianhai Fu, Yuanjie Yu, Ningchuan Li, Yi Zhang, Qichao Chen, Jianping Xiong, Jun Yin, Zhiyu Xiang.\n\n\"Lite-SAM Is Actually What You Need for Segment Everything.\" ECCV (2024). [paper] [2024.07]\n\nWSESeg: Robin Schön, Daniel Kienzle, Rainer Lienhart.\n\n\"WSESeg: Introducing a Dataset for the Segmentation of Winter Sports Equipment with a Baseline for Interactive Segmentation.\" CBMI (2024). [paper] [2024.07]\n\nRAT: Zhiwen Yang, Haowei Chen, Ziniu Qian, Yang Zhou, Hui Zhang, Dan Zhao, Bingzheng Wei, Yan Xu.\n\n\"Region Attention Transformer for Medical Image Restoration.\" MICCAI (2024). [paper] [code] [2024.07]\n\nRveRNet: Seonwhee Jin.\n\n\"Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear.\" ArXiv (2024). [paper] [code] [2024.07]\n\nCACP: Qiushi Guo.\n\n\"Enrich the content of the image Using Context-Aware Copy Paste.\" ArXiv (2024). [paper] [2024.07]\n\nPRISM-placenta: Hao Li, Baris Oguz, Gabriel Arenas, Xing Yao, Jiacheng Wang, Alison Pouch, Brett Byram, Nadav Schwartz, Ipek Oguz.\n\n\"Interactive Segmentation Model for Placenta Segmentation from 3D Ultrasound images.\" ArXiv (2024). [paper] [code] [2024.07]\n\nIRSAM: Mingjin Zhang, Yuchun Wang, Jie Guo, Yunsong Li, Xinbo Gao, Jing Zhang.\n\n\"IRSAM: Advancing Segment Anything Model for Infrared Small Target Detection.\" ECCV (2024). [paper] [code] [2024.07]\n\nProtoSAM: Lev Ayzenberg, Raja Giryes, Hayit Greenspan.\n\n\"ProtoSAM - One Shot Medical Image Segmentation With Foundational Models.\" ArXiv (2024). [paper] [2024.07]\n\nCycleSAM: Aditya Murali, Pietro Mascagni, Didier Mutter, Nicolas Padoy.\n\n\"CycleSAM: One-Shot Surgical Scene Segmentation using Cycle-Consistent Feature Matching to Prompt SAM.\" ArXiv (2024). [paper] [2024.07]\n\nEWMA: Ahmed Maged, Herman Shen.\n\n\"Unsupervised Fault Detection using SAM with a Moving Window Approach.\" ArXiv (2024). [paper] [2024.07]\n\nDiffPNG: Danni Yang, Ruohan Dong, Jiayi Ji, Yiwei Ma, Haowei Wang, Xiaoshuai Sun, Rongrong Ji.\n\n\"Exploring Phrase-Level Grounding with Text-to-Image Diffusion Model.\" ECCV (2024). [paper] [code] [2024.07]\n\nAO-Planner: Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong.\n\n\"Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation.\" ArXiv (2024). [paper] [2024.07]\n\nMBA-Net: Yifan Gao, Wei Xia, Wenkui Wang, Xin Gao.\n\n\"MBA-Net: SAM-driven Bidirectional Aggregation Network for Ovarian Tumor Segmentation.\" MICCAI (2024). [paper] [2024.07]\n\nSAM-TAPIR: Athena Psalta, Vasileios Tsironis, Andreas El Saer, Konstantinos Karantzalos.\n\n\"Addressing single object tracking in satellite imagery through prompt-engineered solutions.\" IGARSS (2024). [paper] [2024.07]\n\nCPC-SAM: Juzheng Miao, Cheng Chen, Keli Zhang, Jie Chuai, Quanzheng Li, Pheng-Ann Heng.\n\n\"Cross Prompting Consistency with Segment Anything Model for Semi-supervised Medical Image Segmentation.\" MICCAI (2024). [paper] [code] [2024.07]\n\nSAM-Med3D-MoE: Guoan Wang, Jin Ye, Junlong Cheng, Tianbin Li, Zhaolin Chen, Jianfei Cai, Junjun He, Bohan Zhuang.\n\n\"SAM-Med3D-MoE: Towards a Non-Forgetting Segment Anything Model via Mixture of Experts for 3D Medical Image Segmentation.\" ArXiv (2024). [paper] [2024.07]\n\nLongfei Huang, Feng Yu, Zhihao Guan, Zhonghua Wan, Yang Yang.\n\n\"The Solution for the 5th GCAIAC Zero-shot Referring Expression Comprehension Challenge.\" ArXiv (2024). [paper] [2024.07]\n\nXudong Ma, Yuqi Zhang, Chenchong Wang, Wei Xu.\n\n\"Revolutionizing Alloy Microstructure Segmentation through SAM and Domain Knowledge without Extra Training.\" ArXiv (2024). [paper] [2024.07]\n\nSA4D: Shengxiang Ji, Guanjun Wu, Jiemin Fang, Jiazhong Cen, Taoran Yi, Wenyu Liu, Qi Tian, Xinggang Wang.\n\n\"Segment Any 4D Gaussians.\" ArXiv (2024). [paper] [code] [2024.07]\n\nWeiyi Xie, Nathalie Willems, Shubham Patil, Yang Li, Mayank Kumar.\n\n\"SAM Fewshot Finetuning for Anatomical Segmentation in Medical Images.\" WACV (2024). [paper] [2024.07]\n\nJFS: Seonghyeon Moon, Haein Kong, Muhammad Haris Khan.\n\n\"Success or Failure? Analyzing Segmentation Refinement with Few-Shot Segmentation.\" ArXiv (2024). [paper] [2024.07]\n\nCS3: Yi Shi, Xu-Peng Tian, Yun-Kai Wang, Tie-Yi Zhang, Bin Yao, Hui Wang, Yong Shao, Cen-Cen Wang, Rong Zeng, De-Chuan Zhan.\n\n\"CS3: Cascade SAM for Sperm Segmentation.\" MICCAI (2024). [paper] [2024.07]\n\nOneSAM: Khanh-Binh Nguyen, Chae Jung Park.\n\n\"OneSAM: One model for segment anything model in medical images on Laptop.\" ArXiv (2024). [paper] [2024.07]\n\nZdravko Marinov, Alexander Jaus, Jens Kleesiek, Rainer Stiefelhagen.\n\n\"Filters, Thresholds, and Geodesic Distances for Scribble-based Interactive Segmentation of Medical Images.\" CVPR Workshop (2024). [paper] [2024.07]\n\nZdravko Marinov, Alexander Jaus, Jens Kleesiek, Rainer Stiefelhagen.\n\n\"Taking a Step Back: Revisiting Classical Approaches for Efficient Interactive Segmentation of Medical Images.\" CVPR Workshop (2024). [paper] [2024.07]\n\nSONGXIAO YANG, Yizhou Li, Ye Chen, Zhuofeng Wu, Masatoshi Okutomi.\n\n\"A Light-weight Universal Medical Segmentation Network for Laptops Based on Knowledge Distillation.\" ArXiv (2024). [paper] [2024.07]\n\nRaphael Stock, Yannick Kirchhoff, Maximilian Rouven Rokuss, Ashis Ravindran, Klaus Maier-Hein.\n\n\"Segment Anything in Medical Images with nnUNet.\" CVPR Workshop (2024). [paper] [2024.07]\n\nQMedSAM: Haisheng Lu, Yujie Fu, Fan Zhang, Le Zhang.\n\n\"Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment.\" ArXiv (2024). [paper] [code] [2024.07]\n\nRepMedSAM: Zehan Zhang, Rui Huang, Ning Huang.\n\n\"RepMedSAM: Segment Anything in Medical Images with Lightweight CNN.\" CVPR Workshop (2024). [paper] [2024.07]\n\nDAFT: Alexander Tobias Pfefferle, Lennart Purucker, Frank Hutter.\n\n\"DAFT: Data-Aware Fine-Tuning of Foundation Models for Efficient and Effective Medical Image Segmentation.\" CVPR Workshop (2024). [paper] [2024.07]\n\nSwin-LiteMedSAM:: Ruochen Gao, Donghang Lyu.\n\n\"Swin-LiteMedSAM: A Lightweight Mulitple-Prompt-Based Segmentation Model for Large-Scale Medical Image Datasets.\" CVPR Workshop (2024). [paper] [code] [2024.07]\n\nZdravko Marinov, Alexander Jaus, Jens Kleesiek, Rainer Stiefelhagen.\n\n\"Filters, Thresholds, and Geodesic Distances for Scribble-based Interactive Segmentation of Medical Images.\" CVPR Workshop (2024). [paper] [2024.07]\n\nHaotian Guan, Bingze Dai, Jiajing Zhang.\n\n\"Lite Class-prompt Tiny-VIT for Multi-Modality Medical Image Segmentation.\" CVPR Workshop (2024). [paper] [2024.07]\n\nZhi Li, YAQI WANG.\n\n\"ExpertsMedSAM: Faster Medical Image Segment Anything with Mixture-of-Experts.\" ArXiv (2024). [paper] [2024.07]\n\nGraysAnatomySAM: YoungHwan Choi, In Kyu Lee, Jonghoe Ku.\n\n\"Gray’s Anatomy for Segment Anything Model: Optimizing Grayscale Medical Images for Fast and Lightweight Segmentation.\" CVPR Workshop (2024). [paper] [code] [2024.07]\n\nWentao Liu, weijin xu, Ruifeng Bian, Haoyuan Li, Tong Tian.\n\n\"LiteMedSAM with Low-Rank Adaptation and Multi-Box Efficient Inference for Medical Image Segmentation.\" ArXiv (2024). [paper] [2024.07]\n\nLei Yu.\n\n\"Efficient and Robust Medical Image Segmentation Using Lightweight ViT-Tiny based SAM and Model Quantization.\" ArXiv (2024). [paper] [2024.07]\n\nRep-MedSAM: Muxin Wei, Shuqing Chen, Silin Wu, Dabin Xu.\n\n\"Rep-MedSAM: Towards Real-time and Universal Medical Image Segmentation.\" CVPR Workshop (2024). [paper] [2024.07]\n\nRepViT-MedSAM: Muhammad Qasim Ali, Alexander Wong, Yuhao Chen.\n\n\"RepViT-MedSAM: Efficient Segment Anything in the Medical Images.\" CVPR Workshop (2024). [paper] [code] [2024.07]\n\nGBMSeg: Xueyu Liu, Guangze Shi, Rui Wang, Yexin Lai, Jianan Zhang, Lele Sun, Quan Yang, Yongfei Wu, MIng Li, Weixia Han, Wen Zheng.\n\n\"Feature-prompting GBMSeg: One-Shot Reference Guided Training-Free Prompt Engineering for Glomerular Basement Membrane Segmentation.\" MICCAI (2024). [paper] [code] [2024.07]\n\nMedficientSAM: Bao-Hiep Le, Dang-Khoa Nguyen-Vu, Trong-Hieu Nguyen-Mau, Hai-Dang Nguyen, Minh-Triet Tran.\n\n\"MedficientSAM: A Robust Medical Segmentation Model with Optimized Inference Pipeline for Limited Clinical Settings.\" CVPR Workshop (2024). [paper] [code] [2024.07]\n\nAS-OCT: Boyu Chen, Ameenat L. Solebo, Paul Taylor.\n\n\"Advancing Cell Detection in Anterior Segment Optical Coherence Tomography Images.\" ArXiv (2024). [paper] [code] [2024.07]\n\nYOLOv8n-DDA-SAM: Zhang, Gengming, Hao Cao, Yangwen Jin, Yi Zhong, Anbang Zhao, Xiangjun Zou, and Hongjun Wang.\n\n\"YOLOv8n-DDA-SAM: Accurate Cutting-Point Estimation for Robotic Cherry-Tomato Harvesting.\" Agriculture (2024). [paper] [2024.07]\n\nMMRo: Jinming Li, Yichen Zhu, Zhiyuan Xu, Jindong Gu, Minjie Zhu, Xin Liu, Ning Liu, Yaxin Peng, Feifei Feng, Jian Tang.\n\n\"MMRo: Are Multimodal LLMs Eligible as the Brain for In-Home Robotics?.\" ArXiv (2024). [paper] [code] [2024.07]\n\nOTVP: Takayuki Nishimura, Katsuyuki Kuyo, Motonari Kambara, Komei Sugiura.\n\n\"Object Segmentation from Open-Vocabulary Manipulation Instructions Based on Optimal Transport Polygon Matching with Multimodal Foundation Models.\" IROS (2024). [paper] [2024.07]\n\nMST_MIXER: Adnen Abdessaied, Lei Shi, Andreas Bulling.\n\n\"Multi-Modal Video Dialog State Tracking in the Wild.\" ECCV (2024). [paper] [code] [2024.07]\n\nMMedAgent: Binxu Li, Tiankai Yan, Yuanting Pan, Zhe Xu, Jie Luo, Ruiyang Ji, Shilong Liu, Haoyu Dong, Zihao Lin, Yixin Wang.\n\n\"MMedAgent: Learning to Use Medical Tools with Multi-modal Agent.\" ArXiv (2024). [paper] [2024.07]\n\nU-SAM: Shouhong Wan, hantao zhang, Weidong Guo et al.\n\n\"Tuning Vision Foundation Models for Rectal Cancer Segmentation from CT Scans: Development and Validation of U-SAM.\" ArXiv (2024). [paper] [2024.07]\n\nDisFormer: Sanket Gandhi, Atul, Samanyu Mahajan, Vishal Sharma, Rushil Gupta, Arnab Kumar Mondal, Parag Singla.\n\n\"Learning Disentangled Representation in Object-Centric Models for Visual Dynamics Prediction via Transformers.\" ArXiv (2024). [paper] [2024.07]\n\nBACON: Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng.\n\n\"BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations.\" ArXiv (2024). [paper] [code] [2024.07]\n\nCADe: Furqan Shaukat, Syed Muhammad Anwar, Abhijeet Parida, Van Khanh Lam, Marius George Linguraru, Mubarak Shah.\n\n\"Lung-CADex: Fully automatic Zero-Shot Detection and Classification of Lung Nodules in Thoracic CT Images.\" ArXiv (2024). [paper] [2024.07]\n\nISAMS: Katja Löwenstein, Johanna Rehrl, Anja Schuster, Michael Gadermayr.\n\n\"Virtually Objective Quantification of in vitro Wound Healing Scratch Assays with the Segment Anything Model.\" ArXiv (2024). [paper] [2024.07]\n\nHRSAM: You Huang, Wenbin Lai, Jiayi Ji, Liujuan Cao, Shengchuan Zhang, Rongrong Ji.\n\n\"HRSAM: Efficiently Segment Anything in High-Resolution Images.\" ArXiv (2024). [paper] [code] [2024.07]\n\nLabel Anything: Pasquale De Marinis, Nicola Fanelli, Raffaele Scaringi, Emanuele Colonna, Giuseppe Fiameni, Gennaro Vessio, Giovanna Castellano.\n\n\"Label Anything: Multi-Class Few-Shot Semantic Segmentation with Visual Prompts.\" ArXiv (2024). [paper] [code] [2024.07]\n\nSAVE: Khanh-Binh Nguyen, Chae Jung Park.\n\n\"SAVE: Segment Audio-Visual Easy way using Segment Anything Model.\" ArXiv (2024). [paper] [2024.07]\n\nPratyush Tripathy, Kathy Baylis, Kyle Wu, Jyles Watson, Ruizhe Jiang.\n\n\"Investigating the Segment Anything Foundation Model for Mapping Smallholder Agriculture Field Boundaries Without Training Labels.\" ArXiv (2024). [paper] [2024.07]\n\nMaskField: Zihan Gao, Lingling Li, Licheng Jiao, Fang Liu, Xu Liu, Wenping Ma, Yuwei Guo, Shuyuan Yang.\n\n\"Fast and Efficient: Mask Neural Fields for 3D Scene Segmentation.\" ArXiv (2024). [paper] [2024.07]\n\nASPS: Huiqian Li, Dingwen Zhang, Jieru Yao, Longfei Han, Zhongyu Li, Junwei Han.\n\n\"ASPS: Augmented Segment Anything Model for Polyp Segmentation.\" MICCAI (2024). [paper] [code] [2024.07]\n\nZongshuo Li, Ding Huo, Markus Meurer, Thomas Bergs.\n\n\"Efficient Cutting Tool Wear Segmentation Based on Segment Anything Model.\" MSEC (2024). [paper] [2024.07]\n\nHATs: Ruining Deng, Quan Liu, Can Cui, Tianyuan Yao, Juming Xiong, Shunxing Bao, Hao Li, Mengmeng Yin, Yu Wang, Shilin Zhao, Yucheng Tang, Haichun Yang, Yuankai Huo.\n\n\"HATs: Hierarchical Adaptive Taxonomy Segmentation for Panoramic Pathology Image Analysis.\" ArXiv (2024). [paper] [code] [2024.07]\n\nSolarSAM: Guohao Wang.\n\n\"SolarSAM: Building-scale Photovoltaic Potential Assessment Based on Segment Anything Model (SAM) and Remote Sensing for Emerging City.\" ArXiv (2024). [paper] [code] [2024.07]\n\nUnSAM: XuDong Wang, Jingfeng Yang, Trevor Darrell.\n\n\"Segment Anything without Supervision.\" ArXiv (2024). [paper] [code] [2024.06]\n\nEVF-SAM: Yuxuan Zhang, Tianheng Cheng, Rui Hu, ei Liu, Heng Liu, Longjin Ran, Xiaoxin Chen, Wenyu Liu, Xinggang Wang.\n\n\"EVF-SAM: Early Vision-Language Fusion for Text-Prompted Segment Anything Model.\" ArXiv (2024). [paper] [2024.06]\n\nTianli Liao, Ce Wang, Lei Li, Guangen Liu, Nan Li.\n\n\"Parallax-tolerant Image Stitching via Segmentation-guided Multi-homography Warping.\" ArXiv (2024). [paper] [code] [2024.06]\n\nRWKV-SAM: Haobo Yuan, Xiangtai Li, Lu Qi, Tao Zhang, Ming-Hsuan Yang, Shuicheng Yan, Chen Change Loy.\n\n\"Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment Anything Model.\" ArXiv (2024). [paper] [code] [2024.06]\n\nREC: Fuseini Mumuni, Alhassan Mumuni.\n\n\"Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO.\" ArXiv (2024). [paper] [2024.06]\n\nUNest: Vu Minh Hieu Phan, Yutong Xie, Bowen Zhang, Yuankai Qi, Zhibin Liao, Antonios Perperidis, Son Lam Phung, Johan W. Verjans, Minh-Son To.\n\n\"Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis.\" MICCAI (2024). [paper] [code] [2024.06]\n\nQiushi Guo.\n\n\"A Universal Railway Obstacle Detection System based on Semi-supervised Segmentation And Optical Flow.\" ArXiv (2024). [paper] [2024.06]\n\nMingxiao Huo, Pengliang Ji, Haotian Lin, Junchen Liu, Yixiao Wang, Yijun Chen.\n\n\"Composition Vision-Language Understanding via Segment and Depth Anything Model.\" ArXiv (2024). [paper] [code] [2024.06]\n\nD2GPLan: Jialun Pei, Ruize Cui, Yaoqian Li, Weixin Si, Jing Qin, Pheng-Ann Heng.\n\n\"Depth-Driven Geometric Prompt Learning for Laparoscopic Liver Landmark Detection.\" MICCAI (2024). [paper] [code] [2024.06]\n\nPoint-SAM: Yuchen Zhou, Jiayuan Gu, Tung Yen Chiang, Fanbo Xiang, Hao Su.\n\n\"Point-SAM: Promptable 3D Segmentation Model for Point Clouds.\" ArXiv (2024). [paper] [code] [2024.06]\n\nGIM: Yirui Chen, Xudong Huang, Quan Zhang, Wei Li, Mingjian Zhu, Qiangyu Yan, Simiao Li, Hanting Chen, Hailin Hu, Jie Yang, Wei Liu, Jie Hu.\n\n\"GIM: A Million-scale Benchmark for Generative Image Manipulation Detection and Localization.\" ArXiv (2024). [paper] [code] [2024.06]\n\nTP-DRSeg: Wenxue Li, Xinyu Xiong, Peng Xia, Lie Ju, Zongyuan Ge.\n\n\"TP-DRSeg: Improving Diabetic Retinopathy Lesion Segmentation with Explicit Text-Prompts Assisted SAM.\" ArXiv (2024). [paper] [code] [2024.06]\n\nSAM-EG: Quoc-Huy Trinh, Hai-Dang Nguyen, Bao-Tram Nguyen Ngoc, Debesh Jha, Ulas Bagci, Minh-Triet Tran.\n\n\"SAM-EG: Segment Anything Model with Egde Guidance framework for efficient Polyp Segmentation.\" ArXiv (2024). [paper] [2024.06]\n\nTraceNet: Mingyuan Wu, Zichuan Liu, Haozhen Zheng, Hongpeng Guo, Bo Chen, Xin Lu, Klara Nahrstedt.\n\n\"TraceNet: Segment one thing efficiently.\" ArXiv (2024). [paper] [2024.06]\n\nMUTR: Bin Cao, Yisi Zhang, Xuanxu Lin, Xingjian He, Bo Zhao, Jing Liu.\n\n\"2nd Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation.\" ArXiv (2024). [paper] [2024.06]\n\nSSAD: Zijian Cai, Xinquan Yang, Xuguang Li, Xiaoling Luo, Xuechen Li, Linlin Shen, He Meng, Yongqiang Deng.\n\n\"SSAD: Self-supervised Auxiliary Detection Framework for Panoramic X-ray based Dental Disease Diagnosis.\" ArXiv (2024). [paper] [code] [2024.06]\n\nSF-CLIP: Sepehr Sameni, Kushal Kafle, Hao Tan, Simon Jenni.\n\n\"Building Vision-Language Models on Solid Foundations with Masked Distillation.\" CVPR (2024). [paper] [2024.06]\n\nLU-AVS: Chen Liu, Peike Patrick Li, Qingtao Yu, Hongwei Sheng, Dadong Wang, Lincheng Li, Xin Yu.\n\n\"Benchmarking Audio Visual Segmentation for Long-Untrimmed Videos.\" CVPR (2024). [paper] [code] [2024.06]\n\nROSA: Yuhan Shen, Huiyu Wang, Xitong Yang, Matt Feiszli, Ehsan Elhamifar, Lorenzo Torresani, Effrosyni Mavroudi.\n\n\"Learning to Segment Referred Objects from Narrated Egocentric Videos.\" CVPR (2024). [paper] [2024.06]\n\nTSP-SAM: Wenjun Hui, Zhenfeng Zhu, Shuai Zheng, Yao Zhao.\n\n\"Endow SAM with Keen Eyes: Temporal-spatial Prompt Learning for Video Camouflaged Object Detection.\" CVPR (2024). [paper] [2024.06]\n\nOV3D: Li Jiang, Shaoshuai Shi, Bernt Schiele.\n\n\"Open-Vocabulary 3D Semantic Segmentation with Foundation Models.\" CVPR (2024). [paper] [2024.06]\n\nFM-FSOD: Guangxing Han, Ser-Nam Lim.\n\n\"Few-Shot Object Detection with Foundation Models.\" CVPR (2024). [paper] [2024.06]\n\nOV-DAR: Keyan Chen, Xiaolong Jiang, Haochen Wang, Cilin Yan, Yan Gao, Xu Tang, Yao Hu & Weidi Xie.\n\n\"OV-DAR: Open-Vocabulary Object Detection and Attributes Recognition.\" IJCV (2024). [paper] [2024.06]\n\nYang Su, Shunquan Tan, Jiwu Huang.\n\n\"A Novel Universal Image Forensics Localization Model Based on Image Noise and Segment Anything Model.\" IH&MMSec (2024). [paper] [2024.06]\n\nSGF: Li, Guanlin and Zhao, Bin and Li, Xuelong.\n\n\"Low-light Image Enhancement with SAM-based Structure Priors and Guidance.\" TMM (2024). [paper] [code] [2024.06]\n\nQin Li, Yizhe Zhang, Yan Li, Jun Lyu, Meng Liu, Longyu Sun, Mengting Sun, Qirong Li, Wenyue Mao, Xinran Wu, Yajing Zhang, Yinghua Chu, Shuo Wang, Chengyan Wang.\n\n\"An Empirical Study on the Fairness of Foundation Models for Multi-Organ Image Segmentation.\" MICCAI (2024). [paper] [2024.06]\n\nS2C: Hyeokjun Kweon, Kuk-Jin Yoon.\n\n\"From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation.\" CVPR (2024). [paper] [code] [2024.06]\n\nSAMAug-C: Pengfei Gu, Zihan Zhao, Hongxiao Wang, Yaopeng Peng, Yizhe Zhang, Nishchal Sapkota, Chaoli Wang, Danny Z. Chen.\n\n\"Boosting Medical Image Classification with Segmentation Foundation Model.\" ArXiv (2024). [paper] [2024.06]\n\nALPS: Song Zhang, Qingzhong Wang, Junyi Liu, Haoyi Xiong.\n\n\"ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model.\" ArXiv (2024). [paper] [code] [2024.06]\n\nEBSeg: Xiangheng Shan, Dongyue Wu, Guilin Zhu, Yuanjie Shao, Nong Sang, Changxin Gao.\n\n\"Open-Vocabulary Semantic Segmentation with Image Embedding Balancing.\" CVPR (2024). [paper] [code] [2024.06]\n\nRobustSAM: Wei-Ting Chen, Yu-Jiet Vong, Sy-Yen Kuo, Sizhuo Ma, Jian Wang.\n\n\"RobustSAM: Segment Anything Robustly on Degraded Images.\" CVPR (2024). [paper] [project] [code] [2024.06]\n\n4M-21: Roman Bachmann, Oğuzhan Fatih Kar, David Mizrahi, Ali Garjani, Mingfei Gao, David Griffiths, Jiaming Hu, Afshin Dehghan, Amir Zamir.\n\n\"4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities.\" ArXiv (2024). [paper] [code] [2024.06]\n\nICE-G: Vishnu Jaganathan, Hannah Hanyun Huang, Muhammad Zubair Irshad, Varun Jampani, Amit Raj, Zsolt Kira.\n\n\"ICE-G: Image Conditional Editing of 3D Gaussian Splats.\" CVPR AI4CC Workshop (2024). [paper] [code] [2024.06]\n\nAPSeg: Weizhao He, Yang Zhang, Wei Zhuo, Linlin Shen, Jiaqi Yang, Songhe Deng, Liang Sun.\n\n\"APSeg: Auto-Prompt Network for Cross-Domain Few-Shot Semantic Segmentatio.\" ArXiv (2024). [paper] [2024.06]\n\nRiVEG: Jinyuan Li, Ziyan Li, Han Li, Jianfei Yu, Rui Xia, Di Sun, Gang Pan.\n\n\"Advancing Grounded Multimodal Named Entity Recognition via LLM-Based Reformulation and Box-Based Segmentation.\" ArXiv (2024). [paper] [code] [2024.06]\n\nMarian Longa, João F. Henriques.\n\n\"Unsupervised Object Detection with Theoretical Guarantees.\" ArXiv (2024). [paper] [2024.06]\n\nST-BAVA: Juhyeong Seon, Woobin Im, Sebin Lee, Jumin Lee, Sung-Eui Yoon.\n\n\"Extending Segment Anything Model into Auditory and Temporal Dimensions for Audio-Visual Segmentation.\" ICIP (2024). [paper] [2024.06]\n\nCRSTM: Xiaoli Wei, Zhaoqing Wang, Yandong Guo, Chunxia Zhang, Tongliang Liu, Mingming Gong.\n\n\"Training-Free Robust Interactive Video Object Segmentation.\" ArXiv (2024). [paper] [2024.06]\n\nUSE: Xiaoqi Wang, Wenbin He, Xiwei Xuan, Clint Sebastian, Jorge Piazentin Ono, Xin Li, Sima Behpour, Thang Doan, Liang Gou, Han Wei Shen, Liu Ren.\n\n\"USE: Universal Segment Embeddings for Open-Vocabulary Image Segmentation.\" ArXiv (2024). [paper] [2024.06]\n\nSAM-PM: Muhammad Nawfal Meeran, Gokul Adethya T, Bhanu Pratyush Mantha.\n\n\"SAM-PM: Enhancing Video Camouflaged Object Detection using Spatio-Temporal Attention.\" ArXiv (2024). [paper] [code] [2024.06]\n\nMatthias Pijarowski, Alexander Wolpert, Martin Heckmann, Michael Teutsch.\n\n\"Utilizing grounded SAM for self-supervised frugal camouflaged human detection.\" Automatic Target Recognition XXXIV. SPIE(2024). [paper] [2024.06]\n\nASDeM: Liu, Xiaohu and Luo, Yichuang and Sun, Wei.\n\n\"ASDeM: Augmenting SAM With Decoupled Memory for Video Object Segmentation.\" ACCESS (2024). [paper] [2024.06]\n\nLNDVI: Balasundaram, Ananthakrishnan and Sharma, Alabhya and Kumaravelan, Swaathy and Shaik, Ayesha and Kavitha, Muthu Subash.\n\n\"An Improved Normalized Difference Vegetation Index (NDVI) Estimation Using Grounded Dino and Segment Anything Model for Plant Health Classification.\" ACCESS (2024). [paper] [2024.06]\n\nPDM: Dvir Samuel, Rami Ben-Ari, Matan Levy, Nir Darshan, Gal Chechik.\n\n\"Unveiling the Power of Diffusion Features For Personalized Segmentation and Retrieval.\" ArXiv (2024). [paper] [2024.06]\n\nLeSAM: Gu, Yunbo and Wu, Qianyu and Tang, Hui and Mai, Xiaoli and Shu, Huazhong and Li, Baosheng and Chen, Yang.\n\n\"LeSAM: Adapt Segment Anything Model for medical lesion segmentation.\" JBHI (2024). [paper] [2024.06]\n\nDF2LCZ-Net: Qianqian Wu, Xianping Ma, Jialu Sui and Man-On Pun.\n\n\"A SAM-EMPOWERED DUAL-STREAM FRAMEWORK FOR SCENE-LEVEL LOCAL CLIMATE ZONE CLASSIFICATION USING GOOGLE EARTH AND SENTINEL IMAGES.\" IGARSS (2024). [paper] [2024.06]\n\nU-SAM: Zhang, Hantao and Guo, Weidong and Wan, Shouhong and Zou, Bingbing and Wang, Wanqin and Qiu, Chenyang and Liu, Kaige and Jin, Peiquan and Yang, Jiancheng.\n\n\"Deep-Learning-Assisted Segmentation of Rectal Cancer from CT Scans: Development and Validation of U-SAM.\" Available at SSRN (2024). [paper] [2024.06]\n\nSAM-PR: Ricardo Montoya-del-Angel, Marawan Elbatel, Joel Vidal, Robert Martí.\n\n\"SAM-PR: enhancing 3D automated breast ultrasound imaging segmentation with probabilistic refinement of SAM.\" IWBI (2024). [paper] [2024.06]\n\nYunho Kim, Jeong Hyun Lee, Choongin Lee, Juhyeok Mun, Donghoon Youm, Jeongsoo Park, Jemin Hwangbo.\n\n\"Learning Semantic Traversability with Egocentric Video and Automated Annotation Strategy.\" ArXiv (2024). [paper] [2024.06]\n\nHeather Doig, Oscar Pizarro, Jacquomo Monk, Stefan Williams.\n\n\"Detecting Endangered Marine Species in Autonomous Underwater Vehicle Imagery Using Point Annotations and Few-Shot Learning.\" IROS (2024). [paper] [2024.06]\n\nVCP: Kuang, Senyun and Liu, Yang and Wang, Xin and Qu, Xiaobo and Wei, Yintao.\n\n\"An Universal Crack Detection Framework for Intelligent Road-Perceptive Vehicles.\" TIV (2024). [paper] [2024.06]\n\nSCD-SAM: Mei, Liye and Ye, Zhaoyi and Xu, Chuan and Wang, Hongzhu and Wang, Ying and Lei, Cheng and Yang, Wei and Li, Yansheng.\n\n\"SCD-SAM: Adapting Segment Anything Model for Semantic Change Detection in Remote Sensing Imagery.\" TGRS (2024). [paper] [code] [2024.06]\n\nMASA: Siyuan Li, Lei Ke, Martin Danelljan, Luigi Piccinelli, Mattia Segu, Luc Van Gool, Fisher Yu.\n\n\"Matching Anything by Segmenting Anything.\" CVPR (2024). [paper] [project] [code] [2024.06]\n\nImmunocto: Mikaël Simard, Zhuoyan Shen, Maria A. Hawkins, Charles-Antoine Collins-Fekete.\n\n\"Immunocto: a massive immune cell database auto-generated for histopathology.\" ArXiv (2024). [paper] [code] [2024.06]\n\nOpenGaussian: Yanmin Wu, Jiarui Meng, Haijie Li, Chenming Wu, Yahao Shi, Xinhua Cheng, Chen Zhao, Haocheng Feng, Errui Ding, Jingdong Wang, Jian Zhang.\n\n\"OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding.\" ArXiv (2024). [paper] [code] [2024.06]\n\nOpen-YOLO 3D: Mohamed El Amine Boudjoghra, Angela Dai, Jean Lahoud, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Fahad Shahbaz Khan.\n\n\"Open-YOLO 3D: Towards Fast and Accurate Open-Vocabulary 3D Instance Segmentation.\" ArXiv (2024). [paper] [code] [2024.06]\n\nFastLGS: Yuzhou Ji, He Zhu, Junshu Tang, Wuyi Liu, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan.\n\n\"FastLGS: Speeding up Language Embedded Gaussians with Feature Grid Mapping.\" ArXiv (2024). [paper] [code] [2024.06]\n\nYang Nan, Guang Yang.\n\n\"Deep asymmetric mixture model for unsupervised cell segmentation.\" ArXiv (2024). [paper] [2024.06]\n\nSemiRES: Danni Yang, Jiayi Ji, Yiwei Ma, Tianyu Guo, Haowei Wang, Xiaoshuai Sun, Rongrong Ji.\n\n\"SAM as the Guide: Mastering Pseudo-Label Refinement in Semi-Supervised Referring Expression Segmentation.\" ICML (2024). [paper] [code] [2024.06]\n\nAlignSAM: Duojun Huang, Xinyu Xiong, Jie Ma, Jichang Li, Zequn Jie, Lin Ma, Guanbin Li.\n\n\"AlignSAM: Aligning Segment Anything Model to Open Context via Reinforcement Learning.\" CVPR (2024). [paper] [code] [2024.06]\n\nAuxOL: Tianyu Huang, Tao Zhou, Weidi Xie, Shuo Wang, Qi Dou, Yizhe Zhang.\n\n\"Improving Segment Anything on the Fly: Auxiliary Online Learning and Adaptive Fusion for Medical Image Segmentation.\" ArXiv (2024). [paper] [code] [2024.06]\n\nSimSAM: Benjamin Towle, Xin Chen, Ke Zhou.\n\n\"SimSAM: Zero-shot Medical Image Segmentation via Simulated Interaction.\" ISBI (2024). [paper] [code] [2024.06]\n\nSAM-LAD: Yun Peng, Xiao Lin, Nachuan Ma, Jiayuan Du, Chuangwei Liu, Chengju Liu, Qijun Chen.\n\n\"SAM-LAD: Segment Anything Model Meets Zero-Shot Logic Anomaly Detection.\" ArXiv (2024). [paper] [2024.06]\n\nJimmy Xuekai Li, Tiancheng Zhang, Yiran Zhu, Zhongwei Chen.\n\n\"Artificial General Intelligence (AGI) for the oil and gas industry: a review.\" ArXiv (2024). [paper] [2024.06]\n\nSAM-VMNet: Xueying Zeng, Baixiang Huang, Yu Luo, Guangyu Wei, Songyan He, Yushuang Shao.\n\n\"SAM-VMNet: Deep Neural Networks For Coronary Angiography Vessel Segmentation.\" ArXiv (2024). [paper] [2024.06]\n\nDISAM: Ruipeng Zhang, Ziqing Fan, Jiangchao Yao, Ya Zhang, Yanfeng Wang.\n\n\"Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts.\" ICLR (2024). [paper] [code] [2024.05]\n\nSAM-E: Junjie Zhang, Chenjia Bai, Haoran He, Wenke Xia, Zhigang Wang, Bin Zhao, Xiu Li, Xuelong Li.\n\n\"SAM-E: Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation.\" ICML (2024). [paper] [project] [code] [2024.05]\n\nHaodi He, Colton Stearns, Adam W. Harley, Leonidas J. Guibas.\n\n\"View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields.\" ArXiv (2024). [paper] [code] [2024.05]\n\nFMARS: Edoardo Arnaudo, Jacopo Lungo Vaschetti, Lorenzo Innocenti, Luca Barco, Davide Lisi, Vanina Fissore, Claudio Rossi.\n\n\"FMARS: Annotating Remote Sensing Images for Disaster Management using Foundation Models.\" IGARSS (2024). [paper] [code] [2024.05]\n\nDeepSeek-VL: Haoyu Lu, Wen Liu, Bo Zhang, Bingxuan Wang, Kai Dong, Bo Liu, Jingxiang Sun, Tongzheng Ren, Zhuoshu Li, Hao Yang, Yaofeng Sun, Chengqi Deng, Hanwei Xu, Zhenda Xie, Chong Ruan.\n\n\"DeepSeek-VL: Towards Real-World Vision-Language Understanding.\" ArXiv (2024). [paper] [code] [2024.03]\n\nFinetuned-SAM: FNU Shivam, Megan Leight, Mary Kate Kelly, Claire Davis, Kelsey Clodfelter, Jacob Thrasher, Yenumula Reddy, Prashnna Gyawali.\n\n\"Segmentation of Maya hieroglyphs through fine-tuned foundation models.\" ArXiv (2024). [paper] [2024.05]\n\nQi Zhang, Guanyu Xing, Jianwei Zhang, Yanli Liu.\n\n\"Adaptive active contours driven by the squared Hellinger distance and local correlation features for inhomogeneous image segmentation.\" Multimed Tools Appl (2024). [paper] [2024.05]\n\nFocSAM: You Huang, Zongyu Lan, Liujuan Cao, Xianming Lin, Shengchuan Zhang, Guannan Jiang, Rongrong Ji.\n\n\"FocSAM: Delving Deeply into Focused Objects in Segmenting Anything.\" CVPR (2024). [paper] [code] [2024.05]\n\nReasoning3D: Tianrun Chen, Chunan Yu, Jing Li, Jianqi Zhang, Lanyun Zhu, Deyi Ji, Yong Zhang, Ying Zang, Zejian Li, Lingyun Sun.\n\n\"Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language Models.\" ArXiv (2024). [paper] [code] [2024.05]\n\nAditya Gunturu, Yi Wen, Jarin Thundathil, Nandi Zhang, Rubaiat Habib Kazi, Ryo Suzuki.\n\n\"Augmented Physics: A Machine Learning-Powered Tool for Creating Interactive Physics Simulations from Static Diagrams.\" ArXiv (2024). [paper] [2024.05]\n\nPLUG: Zhaochen Liu, Limeng Qiao, Xiangxiang Chu, Tingting Jiang.\n\n\"PLUG: Revisiting Amodal Segmentation with Foundation Model and Hierarchical Focus.\" ArXiv (2024). [paper] [2024.05]\n\nNIDS-Net: Yangxiao Lu, Jishnu Jaykumar P, Yunhui Guo, Nicholas Ruozzi, Yu Xiang.\n\n\"Adapting Pre-Trained Vision Models for Novel Instance Detection and Segmentation.\" ArXiv (2024). [paper] [code] [2024.05]\n\nMemSAM: Xiaolong Deng, Huisi Wu, Runhao Zeng, Jing Qin.\n\n\"MemSAM: Taming Segment Anything Model for Echocardiography Video Segmentation.\" CVPR (2024). [paper] [code] [2024.05]\n\nPart123: Anran Liu, Cheng Lin, Yuan Liu, Xiaoxiao Long, Zhiyang Dou, Hao-Xiang Guo, Ping Luo, Wenping Wang.\n\n\"Part123: Part-aware 3D Reconstruction from a Single-view Image.\" SIGGRAPH (2024). [paper] [code] [2024.05]\n\nPP-SAM: Md Mostafijur Rahman, Mustafa Munir, Debesh Jha, Ulas Bagci, Radu Marculescu.\n\n\"PP-SAM: Perturbed Prompts for Robust Adaptation of Segment Anything Model for Polyp Segmentation.\" CVPRW (2024). [paper] [code] [2024.05]\n\nSA-GS: Butian Xiong, Xiaoyu Ye, Tze Ho Elden Tse, Kai Han, Shuguang Cui, Zhen Li.\n\n\"SA-GS: Semantic-Aware Gaussian Splatting for Large Scene Reconstruction with Geometry Constrain.\" ArXiv (2024). [paper] [code] [2024.05]\n\nOV-SAM3D: Hanchen Tai, Qingdong He, Jiangning Zhang, Yijie Qian, Zhenyu Zhang, Xiaobin Hu, Yabiao Wang, Yong Liu.\n\n\"Open-Vocabulary SAM3D: Understand Any 3D Scene.\" ArXiv (2024). [paper] [project] [code] [2024.05]\n\nYuchun Guo, Zhiqing Lu, Yanling Zhou, Xin Jiang.\n\n\"Autonomous Quilt Spreading for Caregiving Robots.\" ArXiv (2024). [paper] [2024.05]\n\nMoME: Xinru Zhang, Ni Ou, Berke Doga Basaran, Marco Visentin, Mengyun Qiao, Renyang Gu, Cheng Ouyang, Yaou Liu, Paul M. Matthew, Chuyang Ye, Wenjia Bai.\n\n\"A Foundation Model for Brain Lesion Segmentation with Mixture of Modality Experts.\" MICCAI (2024). [paper] [2024.05]\n\nOLIVINE: Yifan Zhang, Junhui Hou.\n\n\"Fine-grained Image-to-LiDAR Contrastive Distillation with Visual Foundation Models.\" ArXiv (2024). [paper] [code] [2024.05]\n\nFreeTuner: Youcan Xu, Zhen Wang, Jun Xiao, Wei Liu, Long Chen.\n\n\"FreeTuner: Any Subject in Any Style with Training-free Diffusion.\" ArXiv (2024). [paper] [2024.05]\n\nUroSAM: Leng, Jixuan and Liu, Junfei and Cheng, Galen and Wang, Haohan and Quarrier, Scott Orzech and Luo, Jiebo and Jain, Rajat.\n\n\"Development of UroSAM: a machine learning model to automatically identify kidney stone composition from endoscopic video.\" Journal of Endourology (2024). [paper] [2024.05]\n\nDBA-CLIP: Xiaobo Yang, Xiaojin Gong.\n\n\"Tuning-free Universally-Supervised Semantic Segmentation.\" ArXiv (2024). [paper] [2024.05]\n\nFAM: Qijian Zhang, Junhui Hou, Wenping Wang, Ying He.\n\n\"Flatten Anything: Unsupervised Neural Surface Parameterization.\" ArXiv (2024). [paper] [2024.05]\n\nZipeng Qi, Chenyang Liu, Zili Liu, Hao Chen, Yongchang Wu, Zhengxia Zou, Zhenwei Sh.\n\n\"Multi-view Remote Sensing Image Segmentation With SAM priors.\" ArXiv (2024). [paper] [2024.05]\n\nDTLLM-VLT: Xuchen Li, Xiaokun Feng, Shiyu Hu, Meiqi Wu, Dailing Zhang, Jing Zhang, Kaiqi Huang.\n\n\"DTLLM-VLT: Diverse Text Generation for Visual Language Tracking Based on LLM.\" CVPRW (2024). [paper]\n\nWorldAfford: Changmao Chen, Yuren Cong, Zhen Kan.\n\n\"WorldAfford: Affordance Grounding based on Natural Language Instructions.\" ArXiv (2024). [paper] [2024.05]\n\nUO-SAM: Tingting Li, Gensheng Pei, Xinhao Cai, Huafeng Liu, Qiong Wang, Yazhou Yao.\n\n\"Universal Organizer of SAM for Unsupervised Semantic Segmentation.\" ICME (2024). [paper] [code] [2024.05]\n\nTAR: Tharun V. Puthanveettil, Fnu Obaid ur Rahman.\n\n\"Track Anything Rapter(TAR).\" ArXiv (2024). [paper] [code] [2024.05]\n\nZhiyu Xu, Qingliang Chen.\n\n\"NubbleDrop: A Simple Way to Improve Matching Strategy for Prompted One-Shot Segmentation.\" ArXiv (2024). [paper] [2024.05]\n\nMounes Zaval, Sedat Ozer.\n\n\"Improving the Explain-Any-Concept by Introducing Nonlinearity to the Trainable Surrogate Model.\" IEEE SIU (2024). [paper] [2024.05]\n\nSAMReg: Shiqi Huang, Tingfa Xu, Ziyi Shen, Shaheer Ullah Saeed, Wen Yan, Dean Barratt, Yipeng Hu.\n\n\"One registration is worth two segmentations.\" MICCAI (2024). [paper] [2024.05]\n\nUSIS10K & USIS-SAM: Lian, Shijie and Zhang, Ziyi and Li, Hua and Li, Wenjie and Yang, Laurence Tianruo and Kwong, Sam and Cong, Runmin.\n\n\"Diving into Underwater: Segment Anything Model Guided Underwater Salient Instance Segmentation and A Large-scale Dataset.\" ICML (2024). [paper] [code] [2024.05]\n\nM4oE: Yufeng Jiang, Yiqing Shen.\n\n\"M4oE: A Foundation Model for Medical Multimodal Image Segmentation with Mixture of Experts.\" ArXiv (2024). [paper] [code] [2024.05]\n\nSLIP: Saaketh Koundinya Gundavarapu, Arushi Arora, Shreya Agarwal.\n\n\"Zero Shot Context-Based Object Segmentation using SLIP (SAM+CLIP).\" ArXiv (2024). [paper] [2024.05]\n\nSAM3D: Trevor J. Chan, Aarush Sahni, Jie Li, Alisha Luthra, Amy Fang, Alison Pouch, Chamith S. Rajapakse.\n\n\"SAM3D: Zero-Shot Semi-Automatic Segmentation in 3D Medical Images with the Segment Anything Model.\" ArXiv (2024). [paper] [2024.05]\n\nJin Kousaka, Atsuko H. Iwane, Yuichi Togashi.\n\n\"Automated Cell Structure Extraction for 3D Electron Microscopy by Deep Learning.\" ArXiv (2024). [paper] [2024.05]\n\nElham Ravanbakhsh, Cheng Niu, Yongqing Liang, J. Ramanujam, Xin Li.\n\n\"Enhancing Weakly Supervised Semantic Segmentation with Multi-modal Foundation Models: An End-to-End Approach.\" ArXiv (2024). [paper] [2024.05]\n\nDiffMatch: Kaiyu Li, Xiangyong Cao, Yupeng Deng, Deyu Meng.\n\n\"DiffMatch: Visual-Language Guidance Makes Better Semi-supervised Change Detector.\" ArXiv (2024). [paper] [2024.05]\n\nSegAD: Aimira Baitieva, David Hurych, Victor Besnier, Olivier Bernard.\n\n\"Supervised Anomaly Detection for Complex Industrial Images.\" ArXiv (2024). [paper] [code] [2024.05]\n\nWBNet: Yi Wang, et al.\n\n\"WBNet: Weakly-supervised salient object detection via scribble and pseudo-background priors.\" Pattern Recognition (2024). [paper] [code] [2024.05]\n\nKevin Charles Bierlich, Sagar Karki, Clara N. Bird, Alan Fern, Leigh G. Torres.\n\n\"Automated body length and body condition measurements of whales from drone videos for rapid assessment of population health.\" Marine Mammal Science (2024). [paper] [2024.05]\n\nWSPoly-SAM: Tingting Cai and Hongping Yan and Kun Ding and Yan Zhang and Yueyue Zhou.\n\n\"WSPoly-SAM: Weakly-Supervised and Self-Guided Fine-Tuning of SAM for Colonoscopy Polyp Segmentation.\" ArXiv (2024). [paper] [2024.05]\n\nELiTe: Zhibo Zhang, Ximing Yang, Weizhong Zhang, Cheng Jin.\n\n\"ELiTe: Efficient Image-to-LiDAR Knowledge Transfer for Semantic Segmentation.\" ICME (2024). [paper] [2024.05]\n\nPTQ4SAM: Chengtao Lv, Hong Chen, Jinyang Guo, Yifu Ding, Xianglong Liu.\n\n\"PTQ4SAM: Post-Training Quantization for Segment Anything.\" CVPR (2024). [paper] [code] [2024.05]\n\nUnSAMFlow: Shuai Yuan, Lei Luo, Zhuo Hui, Can Pu, Xiaoyu Xiang, Rakesh Ranjan, Denis Demandolx.\n\n\"UnSAMFlow: Unsupervised Optical Flow Guided by Segment Anything Model.\" CVPR (2024). [paper] [code] [2024.05]\n\nYOLO-SAM: Yu Zhu, Qiang Yang, Li Xu.\n\n\"Active Learning Enabled Low-cost Cell Image Segmentation Using Bounding Box Annotation.\" ArXiv (2024). [paper] [2024.05]\n\nM2Depth: Yingshuang Zou, Yikang Ding, Xi Qiu, Haoqian Wang, Haotian Zhang.\n\n\"M2Depth: Self-supervised Two-Frame Multi-camera Metric Depth Estimation.\" ArXiv (2024). [paper] [code] [2024.05]\n\nPrateek Verma, Minh-Hao Van, Xintao Wu.\n\n\"Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis.\" ArXiv (2024). [paper] [2024.04]\n\nASAM: Bo Li, Haoke Xiao, Lv Tang.\n\n\"ASAM: Boosting Segment Anything Model with Adversarial Tuning.\" CVPR (2024). [paper] [code] [2024.04]\n\nMoPEFT: Rajat Sahay, Andreas Savakis.\n\n\"MoPEFT: A Mixture-of-PEFTs for the Segment Anything Model.\" CVPR Workshops (2024). [paper] [2024.04]\n\nShimian Zhang, Qiuhong Lu.\n\n\"Innovative Integration of Visual Foundation Model with a Robotic Arm on a Mobile Platform.\" ArXiv (2024). [paper] [2024.04]\n\nSAGHOG: Marco Peer, Florian Kleber, Robert Sablatnig.\n\n\"SAGHOG: Self-Supervised Autoencoder for Generating HOG Features for Writer Retrieval.\" ICDAR (2024). [paper] [code] [2024.04]\n\nAuto-Generate-WLs: Tanvi Deshpande, Eva Prakash, Elsie Gyang Ross, Curtis Langlotz, Andrew Ng, Jeya Maria Jose Valanarasu.\n\n\"Auto-Generating Weak Labels for Real & Synthetic Data to Improve Label-Scarce Medical Image Segmentation.\" MIDL (2024). [paper] [code] [2024.04]\n\nDr-SAM: Vazgen Zohranyan, Vagner Navasardyan, Hayk Navasardyan, Jan Borggrefe, Shant Navasardyan.\n\n\"Dr-SAM: An End-to-End Framework for Vascular Segmentation, Diameter Estimation, and Anomaly Detection on Angiography Images.\" ArXiv (2024). [paper] [code] [2024.04]\n\nMAS-SAM: Tianyu Yan, Zifu Wan, Xinhao Deng, Pingping Zhang, Yang Liu, Huchuan Lu.\n\n\"MAS-SAM: Segment Any Marine Animal with Aggregated Features.\" IJCAI (2024). [paper] [code] [2024.04]\n\nKuan-I Chung, Daniel Moyer.\n\n\"Does SAM dream of EIG? Characterizing Interactive Segmenter Performance using Expected Information Gain.\" ArXiv (2024). [paper] [2024.04]\n\nOMEGAS: Lizhi Wang, Feng Zhou, Jianqin Yin.\n\n\"OMEGAS: Object Mesh Extraction from Large Scenes Guided by Gaussian Segmentation.\" ArXiv (2024). [paper] [code] [2024.04]\n\nHOIST-Former: Supreeth Narasimhaswamy, Huy Anh Nguyen, Lihan Huang, Minh Hoai.\n\n\"HOIST-Former: Hand-held Objects Identification, Segmentation, and Tracking in the Wild.\" ArXiv (2024). [paper] [code] [2024.04]\n\nCLIP-GS: Guibiao Liao, Jiankun Li, Zhenyu Bao, Xiaoqing Ye, Jingdong Wang, Qing Li, Kanglin Liu.\n\n\"CLIP-GS: CLIP-Informed Gaussian Splatting for Real-time and View-consistent 3D Semantic Understanding.\" ArXiv (2024). [paper] [code] [2024.04]\n\nX-Ray: Tao Hu, Wenhang Ge, Yuyang Zhao, Gim Hee Lee.\n\n\"X-Ray: A Sequential 3D Representation for Generation.\" ArXiv (2024). [paper] [2024.04]\n\nBUSSAM: Zhengzheng Tu, Le Gu, Xixi Wang, Bo Jiang.\n\n\"Ultrasound SAM Adapter: Adapting SAM for Breast Lesion Segmentation in Ultrasound Images.\" ArXiv (2024). [paper] [code] [2024.04]\n\nGeoDiffuser: Rahul Sajnani, Jeroen Vanbaar, Jie Min, Kapil Katyal, Srinath Sridhar.\n\n\"GeoDiffuser: Geometry-Based Image Editing with Diffusion Models.\" ArXiv (2024). [paper] [code] [2024.04]\n\nYuyan Shi, Jialu Ma, Jin Yang, Shasha Wang, Yichi Zhang.\n\n\"Beyond Pixel-Wise Supervision for Medical Image Segmentation: From Traditional Models to Foundation Models.\" ArXiv (2024). [paper] [2024.04]\n\nPM-VIS: Zhangjing Yang, Dun Liu, Wensheng Cheng, Jinqiao Wang, Yi Wu.\n\n\"PM-VIS: High-Performance Box-Supervised Video Instance Segmentation.\" ArXiv (2024). [paper] [2024.04]\n\nSurgical-DeSAM: Yuyang Sheng, Sophia Bano, Matthew J. Clarkson, Mobarakol Islam.\n\n\"Surgical-DeSAM: Decoupling SAM for Instrument Segmentation in Robotic Surgery.\" ArXiv (2024). [paper] [2024.04]\n\nUrbanCross: Siru Zhong, Xixuan Hao, Yibo Yan, Ying Zhang, Yangqiu Song, Yuxuan Liang.\n\n\"UrbanCross: Enhancing Satellite Image-Text Retrieval with Cross-Domain Adaptation.\" ArXiv (2024). [paper] [2024.04]\n\nELEV-VISION-SAM: Yu-Hsuan Ho, Longxiang Li, Ali Mostafavi.\n\n\"ELEV-VISION-SAM: Integrated Vision Language and Foundation Model for Automated Estimation of Building Lowest Floor Elevation.\" ArXiv (2024). [paper] [2024.04]\n\nUni3DR^2: Tao Chu, Pan Zhang, Xiaoyi Dong, Yuhang Zang, Qiong Liu, Jiaqi Wang.\n\n\"Unified Scene Representation and Reconstruction for 3D Large Language Models.\" ArXiv (2024). [paper] [code] [2024.04]\n\nMM-ScatterNet: Yilong Chen, Zongyi Xu, xiaoshui Huang, Ruicheng Zhang, Xinqi Jiang, Xinbo Gao.\n\n\"Foundation Model assisted Weakly Supervised LiDAR Semantic Segmentation.\" ArXiv (2024). [paper] [2024.04]\n\nZip: Cheng Shi, Sibei Yang.\n\n\"The devil is in the object boundary: towards annotation-free instance segmentation using Foundation Models.\" ICLR (2024). [paper] [code] [2024.04]\n\nPPT: Qiyuan Dai, Sibei Yang.\n\n\"Curriculum Point Prompting for Weakly-Supervised Referring Image Segmentation.\" CVPR (2024). [paper] [2024.04]\n\nFlowSAM: Junyu Xie, Charig Yang, Weidi Xie, Andrew Zisserman.\n\n\"Moving Object Segmentation: All You Need Is SAM (and Flow).\" ArXiv (2024). [paper] [code] [2024.04]\n\nSOHES: Shengcao Cao, Jiuxiang Gu, Jason Kuen, Hao Tan, Ruiyi Zhang, Handong Zhao, Ani Nenkova, Liang-Yan Gui, Tong Sun, Yu-Xiong Wang.\n\n\"SOHES: Self-supervised Open-world Hierarchical Entity Segmentation.\" ICLR (2024). [paper] [code] [2024.04]\n\nYona Falinie A. Gaus, Neelanjan Bhowmik, Brian K. S. Isaac-Medina, Toby P. Breckon.\n\n\"Performance Evaluation of Segment Anything Model with Variational Prompting for Application to Non-Visible Spectrum Imagery.\" ArXiv (2024). [paper] [2024.04]\n\nYiqun Xie, Zhihao Wang, Weiye Chen, Zhili Li, Xiaowei Jia, Yanhua Li, Ruichen Wang, Kangyang Chai, Ruohan Li, Sergii Skakun.\n\n\"When are Foundation Models Effective? Understanding the Suitability for Pixel-Level Classification Using Multispectral Imagery.\" ArXiv (2024). [paper] [2024.04]\n\nLAECIPS: Shijing Hu, Ruijun Deng, Xin Du, Zhihui Lu, Qiang Duan, Yi He, Shih-Chia Huang, Jie Wu.\n\n\"LAECIPS: Large Vision Model Assisted Adaptive Edge-Cloud Collaboration for IoT-based Perception System.\" ArXiv (2024). [paper] [2024.04]\n\nESD: Jieming Yu, Long Bai, Guankun Wang, An Wang, Xiaoxiao Yang, Huxin Gao, Hongliang Ren.\n\n\"Adapting SAM for Surgical Instrument Tracking and Segmentation in Endoscopic Submucosal Dissection Videos.\" IEEE ICRA C4SR+ Workshop (2024). [paper] [2024.04]\n\nFinetune-SAM: Hanxue Gu, Haoyu Dong, Jichen Yang, Maciej A. Mazurowski.\n\n\"How to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with Segment Anything Model.\" ArXiv (2024). [paper] [code] [2024.04]\n\nOffline-evt: Fangwei Zhong, Kui Wu, Hai Ci, Churan Wang, Hao Chen.\n\n\"Empowering Embodied Visual Tracking with Visual Foundation Models and Offline RL.\" ArXiv (2024). [paper] [code] [2024.04]\n\nVFMM3D: Bonan Ding, Jin Xie, Jing Nie, Jiale Cao.\n\n\"VFMM3D: Releasing the Potential of Image by Vision Foundation Model for Monocular 3D Object Detection.\" ArXiv (2024). [paper] [2024.04]\n\nLLM-Seg: Junchi Wang, Lei Ke.\n\n\"LLM-Seg: Bridging Image Segmentation and Large Language Model Reasoning.\" ArXiv (2024). [paper] [code] [2024.04]\n\nJune Moh Goo, Zichao Zeng, Jan Boehm.\n\n\"Zero-shot detection of buildings in mobile LiDAR using Language Vision Model.\" ArXiv (2024). [paper] [2024.04]\n\nAuto-Prom: Abu Bakor Hayat Arnob, Xiangxue Wang, Yiping Jiao, Xiao Gan, Wenlong Ming, Jun Xu.\n\n\"Pathological Primitive Segmentation Based on Visual Foundation Model with Zero-Shot Mask Generation.\" ArXiv (2024). [paper] [code] [2024.04]\n\nRobin Schön, Julian Lorenz, Katja Ludwig, Rainer Lienhart.\n\n\"Adapting the Segment Anything Model During Usage in Novel Situations.\" ArXiv (2024). [paper] [2024.04]\n\nS-RA & T-RA: Yifan Shen, Zhengyuan Li, Gang Wang.\n\n\"Practical Region-level Attack against Segment Anything Models.\" ArXiv (2024). [paper] [2024.04]\n\nMedRG: Ke Zou, Yang Bai, Zhihao Chen, Yang Zhou, Yidi Chen, Kai Ren, Meng Wang, Xuedong Yuan, Xiaojing Shen, Huazhu Fu.\n\n\"MedRG: Medical Report Grounding with Multi-modal Large Language Model.\" ArXiv (2024). [paper] [2024.04]\n\nO2V-Mapping: Muer Tie, Julong Wei, Zhengjun Wang, Ke Wu, Shansuai Yuan, Kaizhao Zhang, Jie Jia, Jieru Zhao, Zhongxue Gan, Wenchao Ding.\n\n\"O2V-Mapping: Online Open-Vocabulary Mapping with Neural Implicit Representation.\" ArXiv (2024). [paper] [2024.04]\n\nLiu M, Cui M, Wei W, Xu X, Sun C, Li F, Song Z, Lu Y, Zhang J, Tian F, et al.\n\n\"Sorting of Mountage Cocoons Based on MobileSAM and Target Detection.\" Agriculture (2024). [paper] [2024.04]\n\nShadowSAM: Zeheng Qian and Wen Wu and Xian-Tao Wu and Xiao-Diao Chen.\n\n\"Omni-supervised shadow detection with vision foundation model.\" JVCI (2024). [paper] [code] [2024.04]\n\nMoghimi, Armin and Welzel, Mario and Celik, Turgay and Schlurmann, Torsten.\n\n\"A Comparative Performance Analysis of Popular Deep Learning Models and Segment Anything Model (SAM) for River Water Segmentation in Close-Range Remote Sensing Imagery.\" IEEE Access (2024). [paper] [code] [Dataset] [2024.04]\n\nSAMPA: Handi Deng, Yucheng Zhou, Jiaxuan Xiang, Liujie Gu, Yan Luo, Hai Feng, Mingyuan Liu, Cheng Ma.\n\n\"Streamlined Photoacoustic Image Processing with Foundation Models: A Training-Free Solution.\" ArXiv (2024). [paper] [code] [2024.04]\n\nSAM-I-Am: Waqwoya Abebe, Jan Strube, Luanzheng Guo, Nathan R. Tallent, Oceane Bel, Steven Spurgeon, Christina Doty, Ali Jannesari.\n\n\"SAM-I-Am: Semantic Boosting for Zero-shot Atomic-Scale Electron Micrograph Segmentation.\" ArXiv (2024). [paper] [2024.04]\n\nSaLIP: Sidra Aleem, Fangyijie Wang, Mayug Maniparambil, Eric Arazo, Julia Dietlmeier, Kathleen Curran, Noel E. O'Connor, Suzanne Little.\n\n\"Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero-shot Medical Image Segmentation.\" CVPR Workshops (2024). [paper] [code] [2024.04]\n\nCTL: Anas Gouda, Max Schwarz, Christopher Reining, Sven Behnke, Alice Kirchheim.\n\n\"Learning Embeddings with Centroid Triplet Loss for Object Identification in Robotic Grasping.\" ArXiv (2024). [paper] [code] [2024.04]\n\nDual-SAM: Pingping Zhang, Tianyu Yan, Yang Liu, Huchuan Lu.\n\n\"Fantastic Animals and Where to Find Them: Segment Any Marine Animal with Dual SAM.\" CVPR (2024). [paper] [code] [2024.04]\n\nYu Sheng, Lu Zhang, Xingchen Li, Yifan Duan, Yanyong Zhang, Yu Zhang, Jianmin Ji.\n\n\"Rendering-Enhanced Automatic Image-to-Point Cloud Registration for Roadside Scenes.\" ArXiv (2024). [paper] [2024.04]\n\nDL-EWF: Fatemeh Asghari, Mohammad Reza Soheili, Faezeh Gholamrezaie.\n\n\"DL-EWF: Deep Learning Empowering Women's Fashion with Grounded-Segment-Anything Segmentation for Body Shape Classification.\" ArXiv (2024). [paper] [2024.04]\n\nMuDI : Sangwon Jang, Jaehyeong Jo, Kimin Lee, Sung Ju Hwang.\n\n\"Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models.\" ArXiv (2024). [paper] [code] [2024.04]\n\nDavid Jurado-Rodr´ıguez, et al.\n\n\"SAM-Based Detection of Structural Anomalies in 3D Models for Preserving Cultural Heritage.\" ArXiv (2024). [paper] [2024.04]\n\nLiqun Shan, Yanchang Liu, Ke Du, Shovon Paul, Xingli Zhang, Xiali Hei.\n\n\"Drilling rock image segmentation and analysis using segment anything model.\" Advances in Geo-Energy Research (2024). [paper] [2024.04]\n\nSen Deng, et al.\n\n\"Semi-supervised TEE Segmentation via Interacting with SAM Equipped with Noise-Resilient Prompting.\" AAAI (2024). [paper] [2024.04]\n\nBSDSNet: Wang, Y.; Zhang, W.; Chen, W.; Chen, C.\n\n\"BSDSNet: Dual-Stream Feature Extraction Network Based on Segment Anything Model for Synthetic Aperture Radar Land Cover Classification.\" Remote Sens (2024). [paper] [2024.04]\n\nSweepMM: Weichen Xu; Xinxin Xu; Tianhao Fu; Jian Cao; Xiaoyang Xu; Yuetian Huang; Xixin Cao; Xing Zhang.\n\n\"SweepMM: A High-Quality Multimodal Dataset for Sweeping Robots in Home Scenarios for Vision-Language Model.\" ICASSP (2024). [paper] [2024.04]\n\n3DSAM: Shangjie Wang; Yan Zhang.\n\n\"3DSAM: Segment Anything in NeRF.\" ICASSP (2024). [paper] [2024.04]\n\nSAM-GEBD: Pranay Kashyap; Sourabh Vasant Gothe; Vibhav Agarwal; Jayesh Rajkumar Vachhani.\n\n\"SAM-GEBD: Zero-Cost Approach for Generic Event Boundary Detection.\" ICASSP (2024). [paper] [2024.04]\n\nSAM-CD: Zixuan Sun; Huihui Song; Kaihua Zhang; Gang Dong; Lingyan Liang; Yaqian Zhao.\n\n\"Segment Anything Model Guided Semantic Knowledge Learning For Remote Sensing Change Detection.\" ICASSP (2024). [paper] [2024.04]\n\nSkinSAM: Mingzhe Hu, Yuheng Li, Xiaofeng Yang.\n\n\"SkinSAM: adapting the segmentation anything model for skin cancer segmentation.\" SPIE (2024). [paper] [2024.04]\n\nBreastSAM: Mingzhe Hu, Yuheng Li, Xiaofeng Yang.\n\n\"BreastSAM: adapting the segmentation anything model for breast tumor segmentation in ultrasound imaging.\" SPIE (2024). [paper] [2024.04]\n\nYiqiao Liu, et al.\n\n\"Universal 3D CT lesion segmentation using SAM with RECIST annotation.\" SPIE (2024). [paper] [2024.04]\n\nSS2V: Xing Yao, et al.\n\n\"FNPC-SAM: uncertainty-guided false negative/positive control for SAM on noisy medical images.\" SPIE (2024). [paper] [code] [2024.04]\n\nSAM-Att: Zhu, Yaqi and Xiong, Changchun and Zhao, Heng and Yao, Yudong.\n\n\"SAM-Att: A Prompt-free SAM-related Model with an Attention Module for Automatic Segmentation of the Left Ventricle in Echocardiography.\" IEEE Access (2024). [paper] [2024.04]\n\nBarelySAM: Ding, Yuhang and Liu, Hongmin.\n\n\"Barely-supervised Brain Tumor Segmentation via Employing Segment Anything Model.\" TCSVT (2024). [paper] [2024.04]\n\nDesign2Cloth: Jiali Zheng, Rolandos Alexandros Potamias, Stefanos Zafeiriou.\n\n\"Design2Cloth: 3D Cloth Generation from 2D Masks.\" CVPR (2024). [paper] [code] [2024.04]\n\nFBM: Huang, Peng and Shu, Xiangbo and Yan, Rui and Tu, Zhewei and Tang, Jinhui.\n\n\"Appearance-Agnostic Representation Learning for Compositional Action Recognition.\" TCSVT (2024). [paper] [2024.04]\n\nSeda Camalan, Muhammad Khalid Khan Niazi, Charles Elmaraghy, Aaron C. Moberly, Metin N. Gurcan.\n\n\"Tympanic membrane segmentation of video frames to create composite images using SAM.\" SPIE (2024). [paper] [2024.04]\n\nMeyer, A., Mazellier, JP., Dana, J. et al.\n\n\"On-the-fly point annotation for fast medical video labeling.\" Int J CARS (2024). [paper] [code] [2024.04]\n\nUygun, T., Ozguven, M.M.\n\n\"Determination of tomato leafminer: Tuta absoluta (Meyrick) (Lepidoptera: Gelechiidae) damage on tomato using deep learning instance segmentation method.\" Eur Food Res Technol (2024). [paper] [2024.04]\n\niSeg: Itai Lang, Fei Xu, Dale Decatur, Sudarshan Babu, Rana Hanocka.\n\n\"iSeg: Interactive 3D Segmentation via Interactive Attention.\" ArXiv (2024). [paper] [code] [2024.04]\n\nGen3DSR: Andreea Dogaru, Mert Özer, Bernhard Egger.\n\n\"Generalizable 3D Scene Reconstruction via Divide and Conquer from a Single View.\" ArXiv (2024). [paper] [code] [2024.04]\n\nOW-VISCap: Anwesa Choudhuri, Girish Chowdhary, Alexander G. Schwing.\n\n\"OW-VISCap: Open-World Video Instance Segmentation and Captioning.\" ArXiv (2024). [paper] [code] [2024.04]\n\nUAD: Jiahao Lu, Xingyi Yang, Xinchao Wang.\n\n\"Unsegment Anything by Simulating Deformation.\" CVPR (2024). [paper] [code] [2024.04]\n\nFIGA: Krzysztof Jankowski, Bartlomiej Sobieski, Mateusz Kwiatkowski, Jakub Szulc, Michal Janik, Hubert Baniecki, Przemyslaw Biecek.\n\n\"Red-Teaming Segment Anything Model.\" CVPR Workshop (2024). [paper] [2024.04]\n\nDHR: Sanghyun Jo, Fei Pan, In-Jae Yu, Kyungsu Kim.\n\n\"DHR: Dual Features-Driven Hierarchical Rebalancing in Inter- and Intra-Class Regions for Weakly-Supervised Semantic Segmentation.\" ArXiv (2024). [paper] [code] [2024.04]\n\nDIT: Xiaorui Huang, Gen Luo, Chaoyang Zhu, Bo Tong, Yiyi Zhou, Xiaoshuai Sun, Rongrong Ji.\n\n\"Deep Instruction Tuning for Segment Anything Model.\" ArXiv (2024). [paper] [code] [2024.04]\n\nSegNext: Qin Liu, Jaemin Cho, Mohit Bansal, Marc Niethammer.\n\n\"Rethinking Interactive Image Segmentation with Low Latency, High Quality, and Diverse Prompts.\" CVPR (2024). [paper] [code] [2024.04]\n\nDetect2Interact: Jialou Wang, Manli Zhu, Yulei Li, Honglei Li, Longzhi Yang, Wai Lok Woo.\n\n\"Detect2Interact: Localizing Object Key Field in Visual Question Answering (VQA) with LLMs.\" IEEE Intelligent Systems (2024). [paper] [2024.04]\n\nMedCLIP-SAM: Taha Koleilat, Hojat Asgariandehkordi, Hassan Rivaz, Yiming Xiao.\n\n\"MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image Segmentation.\" ArXiv (2024). [paper] [2024.03]\n\nCOCO-ReM: Shweta Singh, Aayan Yadav, Jitesh Jain, Humphrey Shi, Justin Johnson, Karan Desai.\n\n\"Benchmarking Object Detectors with COCO: A New Path Forward.\" ArXiv (2024). [paper] [dataset] [code] [2024.03]\n\nYuiko Sakuma, Masakazu Yoshimura, Junji Otsuka, Atsushi Irie, Takeshi Ohashi.\n\n\"Mixed-precision Supernet Training from Vision Foundation Models using Low Rank Adapter.\" ArXiv (2024). [paper] [2024.03]\n\nTotal-Decom: Xiaoyang Lyu, Chirui Chang, Peng Dai, Yang-tian Sun, Xiaojuang Qi.\n\n\"Total-Decom: Decomposed 3D Scene Reconstruction with Minimal Interaction.\" CVPR (2024). [paper] [code] [2024.03]\n\nSAM-dPCR: Yuanyuan Wei, Shanhang Luo, Changran Xu, Yingqi Fu, Qingyue Dong, Yi Zhang, Fuyang Qu, Guangyao Cheng, Yi-Ping Ho, Ho-Pui Ho, Wu Yuan.\n\n\"SAM-dPCR: Real-Time and High-throughput Absolute Quantification of Biological Samples Using Zero-Shot Segment Anything Model.\" ArXiv (2024). [paper] [2024.03]\n\nH-SAM: Zhiheng Cheng, Qingyue Wei, Hongru Zhu, Yan Wang, Liangqiong Qu, Wei Shao, Yuyin Zhou.\n\n\"Unleashing the Potential of SAM for Medical Adaptation via Hierarchical Decoding.\" CVPR (2024). [paper] [code] [2024.03]\n\nAnnolid: Chen Yang, Thomas A. Cleland.\n\n\"Annolid: Annotate, Segment, and Track Anything You Need.\" ArXiv (2024). [paper] [2024.03]\n\nSAMME: Yihao Liu, Jiaming Zhang, Andres Diaz-Pinto, Haowei Li, Alejandro Martin-Gomez, Amir Kheradmand, Mehran Armand.\n\n\"Segment Any Medical Model Extended.\" ArXiv (2024). [paper] [2024.03]\n\nEgoLifter: Qiao Gu, Zhaoyang Lv, Duncan Frost, Simon Green, Julian Straub, Chris Sweeney.\n\n\"EgoLifter: Open-world 3D Segmentation for Egocentric Perception.\" ArXiv (2024). [paper] [code] [2024.03]\n\nDavid Jurado-Rodr´ıguez, et al.\n\n\"SAM-Based Detection of Structural Anomalies in 3D Models for Preserving Cultural Heritage.\" VISAPP (2024). [paper] [2024.03]\n\nMAkE-able: Christoph Pohl, Fabian Reister, Fabian Peller-Konrad and Tamim Asfour.\n\n\"MAkE-able: Memory-centered and Affordance-based Task Execution Framework for Transferable Mobile Manipulation Skills.\" ArXiv (2024). [paper] [code] [2024.03]\n\nGoodSAM: Weiming Zhang, Yexin Liu, Xu Zheng, Lin Wang.\n\n\"GoodSAM: Bridging Domain and Capacity Gaps via Segment Anything Model for Distortion-aware Panoramic Semantic Segmentation.\" CVPR (2024). [paper] [code] [2024.03]\n\nSPF+SPD: Quan Zhang, Xiaoyu Liu, Wei Li, Hanting Chen, Junchao Liu, Jie Hu, Zhiwei Xiong, Chun Yuan, Yunhe Wang.\n\n\"Distilling Semantic Priors from SAM to Efficient Image Restoration Models.\" ArXiv (2024). [paper] [2024.03]\n\nSAM-Road: Congrui Hetang, Haoru Xue, Cindy Le, Tianwei Yue, Wenping Wang, Yihui He.\n\n\"Segment Anything Model for Road Network Graph Extraction.\" ArXiv (2024). [paper] [code] [2024.03]\n\nSAM_DataAnnotation: Pranav Kulkarni, Adway Kanhere, Dharmam Savani, Andrew Chan, Devina Chatterjee, Paul H. Yi, Vishwa S. Parekh.\n\n\"Anytime, Anywhere, Anyone: Investigating the Feasibility of Segment Anything Model for Crowd-Sourcing Medical Image Annotations.\" ArXiv (2024). [paper] [code] [2024.03]\n\nCT-SAM3D: Heng Guo, Jianfeng Zhang, Jiaxing Huang, Tony C. W. Mok, Dazhou Guo, Ke Yan, Le Lu, Dakai Jin, Minfeng Xu.\n\n\"Towards a Comprehensive, Efficient and Promptable Anatomic Structure Segmentation Model using 3D Whole-body CT Scans.\" ArXiv (2024). [paper] [2024.03]\n\nALC: Hoyoung Kim, Sehyun Hwang, Suha Kwak, Jungseul Ok.\n\n\"Active Label Correction for Semantic Segmentation with Foundation Models.\" ArXiv (2024). [paper] [2024.03]\n\nDiffCriticEdit:Ruicheng Wang, Jianfeng Xiang, Jiaolong Yang, Xin Tong.\n\n\"Diffusion Models are Geometry Critics: Single Image 3D Editing Using Pre-Trained Diffusion Priors.\" ArXiv (2024). [paper] [code] [2024.03]\n\nRafaela Orenga Panizza, et al.\n\n\"Labeling Construction, Renovation, and Demolition Waste through Segment Anything Model (SAM).\" Construction Research Congress (2024). [paper] [2024.03]\n\nSAM-AutoMed: Jiakang Sun, Ke Chen, Zhiyi He, Siyuan Ren, Xinyang He, Xu Liu, Cheng Peng .\n\n\"Medical Image Analysis using Improved SAM-Med2D: Segmentation and Classification Perspectives.\" ArXiv (2024). [paper] [2024.03]\n\nRASP: Minghui Zhao, Junxi Xia, Kaiyuan Hou, Yanchen Liu, Stephen Xia, Xiaofan Jiang.\n\n\"RASP: A Drone-based Reconfigurable Actuation and Sensing Platform Towards Ambient Intelligent Systems.\" ArXiv (2024). [paper] [2024.03]\n\nWebSAM-Adapter: Ren, B., Qian, Z., Sun, Y., Gao, C., Zhang, C.\n\n\"WebSAM-Adapter: Adapting Segment Anything Model for Web Page Segmentation.\" ECIR (2024). [paper] [2024.03]\n\nProMamba: Jianhao Xie, Ruofan Liao, Ziang Zhang, Sida Yi, Yuesheng Zhu, Guibo Luo.\n\n\"ProMamba: Prompt-Mamba for polyp segmentation.\" ArXiv (2024). [paper] [2024.03]\n\nMTP: Di Wang, Jing Zhang, Minqiang Xu, Lin Liu, Dongsheng Wang, Erzhong Gao, Chengxi Han, Haonan Guo, Bo Du, Dacheng Tao, Liangpei Zhang.\n\n\"MTP: Advancing Remote Sensing Foundation Model via Multi-Task Pretraining.\" ArXiv (2024). [paper] [code] [2024.03]\n\nConnor Lee, Saraswati Soedarmadji, Matthew Anderson, Anthony J. Clark, and Soon-Jo Chung.\n\n\"Semantics from Space: Satellite-Guided Thermal Semantic Segmentation Annotation for Aerial Field Robots.\" ArXiv (2024). [paper] [code] [2024.03]\n\nLuna, Miguel, Philip Chikontwe, and Sang Hyun Park.\n\n\"Enhanced Nuclei Segmentation and Classification via Category Descriptors in the SAM Model.\" Bioengineering (2024). [paper] [2024.03]\n\nMoCA: Swapnil Bhosale, Haosen Yang, Diptesh Kanojia, Jiangkang Deng, Xiatian Zhu.\n\n\"Unsupervised Audio-Visual Segmentation with Modality Alignment.\" ArXiv (2024). [paper] [2024.03]\n\nLLaVASeg: Yuqi Yang, Peng-Tao Jiang, Jing Wang, Hao Zhang, Kai Zhao, Jinwei Chen, Bo Li.\n\n\"Empowering Segmentation Ability to Multi-modal Large Language Models.\" ArXiv (2024). [paper] [code] [2024.03]\n\nMaskSAM: Bin Xie, Hao Tang, Bin Duan, Dawen Cai, Yan Yan.\n\n\"MaskSAM: Towards Auto-prompt SAM with Mask Classification for Medical Image Segmentation.\" ArXiv (2024). [paper] [2024.03]\n\nSAL: Aljoša Ošep, Tim Meinhardt, Francesco Ferroni, Neehar Peri, Deva Ramanan, Laura Leal-Taixé.\n\n\"Better Call SAL: Towards Learning to Segment Anything in Lidar.\" ArXiv (2024). [paper] [code] [2024.03]\n\nSAMCT: Xian Lin, Yangyang Xiang, Zhehao Wang, Kwang-Ting Cheng, Zengqiang Yan, Li Yu.\n\n\"SAMCT: Segment Any CT Allowing Labor-Free Task-Indicator Prompts.\" ArXiv (2024). [paper] [code] [2024.03]\n\nEfrain Torres-Lomas, Jimena Lado-Jimena, Guillermo Garcia-Zamora, Luis Diaz-Garcia.\n\n\"Segment Anything for comprehensive analysis of grapevine cluster architecture and berry properties.\" ArXiv (2024). [paper] [2024.03]\n\nRoland Gruber, Steffen Rüger, Thomas Wittenberg.\n\n\"Adapting SAM for Volumetric X-Ray Data-sets of Arbitrary Sizes.\" ArXiv (2024). [paper] [2024.03]\n\nLocalStyleFool: Yuxin Cao, Jinghao Li, Xi Xiao, Derui Wang, Minhui Xue, Hao Ge, Wei Liu, Guangwu Hu.\n\n\"LocalStyleFool: Regional Video Style Transfer Attack Using Segment Anything Model.\" SPW (2024). [paper] [2024.03]\n\nCCC++: Mrityunjoy Gain, Avi Deb Raha, Rameswar Debnath.\n\n\"CCC++: Optimized Color Classified Colorization with Segment Anything Model (SAM) Empowered Object Selective Color Harmonization.\" ArXiv (2024). [paper] [2024.03]\n\nCFR: Shumeng Li, Lei Qi, Qian Yu, Jing Huo, Yinghuan Shi, Yang Gao.\n\n\"Concatenate, Fine-tuning, Re-training: A SAM-enabled Framework for Semi-supervised 3D Medical Image Segmentation.\" ArXiv (2024). [paper] [code] [2024.03]\n\nTA-LoRA: Xuehao Wang, Feiyang Ye, Yu Zhang.\n\n\"Task-Aware Low-Rank Adaptation of Segment Anything Model.\" ArXiv (2024). [paper] [2024.03]\n\nUA-SAM: Mingzhou Jiang, Jiaying Zhou, Junde Wu, Tianyang Wang, Yueming Jin, Min Xu.\n\n\"Uncertainty-Aware Adapter: Adapting Segment Anything Model (SAM) for Ambiguous Medical Image Segmentation.\" ArXiv (2024). [paper] [code] [2024.03]\n\nMS-UGCML: Shichao Kan, Yuhai Deng, Yixiong Liang, Lihui Cen, Zhe Qu, Yigang Cen, Zhihai He.\n\n\"Unsupervised Collaborative Metric Learning with Mixed-Scale Groups for General Object Retrieval.\" ArXiv (2024). [paper] [code] [2024.03]\n\nSAOM: Mariia Khan, Yue Qiu, Yuren Cong, Jumana Abu-Khalaf, David Suter, Bodo Rosenhahn.\n\n\"Segment Any Object Model (SAOM): Real-to-Simulation Fine-Tuning Strategy for Multi-Class Multi-Instance Segmentation.\" ArXiv (2024). [paper] [2024.03]\n\nFastSAM3D: Yiqing Shen, Jingxing Li, Xinyuan Shao, Blanca Inigo Romillo, Ankush Jindal, David Dreizin, Mathias Unberath.\n\n\"FastSAM3D: An Efficient Segment Anything Model for 3D Volumetric Medical Images.\" ArXiv (2024). [paper] [code] [2024.03]\n\nCMR2D+T-SAM: Zhennong Chen, Sekeun Kim, Hui Ren, Quanzheng Li, Xiang Li.\n\n\"Cardiac Magnetic Resonance 2D+T Short- and Long-axis Segmentation via Spatio-temporal SAM Adaptation.\" ArXiv (2024). [paper] [2024.03]\n\nGroup-Mix SAM: Wu Liang, X.-G. Ma.\n\n\"Group-Mix SAM: Lightweight Solution for Industrial Assembly Line Applications.\" ArXiv (2024). [paper] [2024.03]\n\nTransLandSeg: Changhong Hou, Junchuan Yu, Daqing Ge, Liu Yang, Laidian Xi, Yunxuan Pang, Yi Wen.\n\n\"TransLandSeg: A Transfer Learning Approach for Landslide Semantic Segmentation Based on Vision Foundation Model.\" ArXiv (2024). [paper] [2024.03]\n\nGrasp Anything: Malte Mosbach, Sven Behnke.\n\n\"Grasp Anything: Combining Teacher-Augmented Policy Gradient Learning with Instance Segmentation to Grasp Arbitrary Objects.\" ArXiv (2024). [paper] [code] [2024.03]\n\nRDC: Meixuan Li, Tianyu Li, Guoqing Wang, Peng Wang, Yang Yang, Heng Tao Shen.\n\n\"Region-aware Distribution Contrast: A Novel Approach to Multi-Task Partially Supervised Learning.\" ArXiv (2024). [paper] [2024.03]\n\nVISE: Tian Meng, Yang Tao, Ruilin Lyu, Wuliang Yin.\n\n\"Few-Shot Image Classification and Segmentation as Visual Question Answering Using Vision-Language Models.\" ArXiv (2024). [paper] [2024.03]\n\nDiffuMatting: Xiaobin Hu, Xu Peng, Donghao Luo, Xiaozhong Ji, Jinlong Peng, Zhengkai Jiang, Jiangning Zhang, Taisong Jin, Chengjie Wang, Rongrong Ji.\n\n\"DiffuMatting: Synthesizing Arbitrary Objects with Matting-level Annotation.\" ArXiv (2024). [paper] [2024.03]\n\nClickVOS: Pinxue Guo, Lingyi Hong, Xinyu Zhou, Shuyong Gao, Wanyun Li, Jinglun Li, Zhaoyu Chen, Xiaoqiang Li, Wei Zhang, Wenqiang Zhang.\n\n\"ClickVOS: Click Video Object Segmentation.\" ArXiv (2024). [paper] [code] [2024.03]\n\nKong, L.; Huang, M.; Zhang, L.; Chan, L.W.C.\n\n\"Enhancing Diagnostic Images to Improve the Performance of the Segment Anything Model in Medical Image Segmentation.\" Bioengineering (2024). [paper] [2024.03]\n\nFSViewFusion: Rukhshanda Hussain, Hui Xian Grace Lim, Borchun Chen, Mubarak Shah, Ser Nam Lim.\n\n\"FSViewFusion: Few-Shots View Generation of Novel Objects.\" ArXiv (2024). [paper] [2024.03]\n\nV-PRISM: Herbert Wright, Weiming Zhi, Matthew Johnson-Roberson, Tucker Hermans.\n\n\"V-PRISM: Probabilistic Mapping of Unknown Tabletop Scenes.\" ArXiv (2024). [paper] [code] [2024.03]\n\nCCSpO2Net: Sun, Xiantao and Wen, Tao and Chen, Weihai and Huang, Bin.\n\n\"CCSpO2Net: Camera-Based Contactless Oxygen Saturation Measurement Foundation Model in Clinical Settings.\" TIM (2024). [paper] [2024.03]\n\nUnveiling the Truth: Cartella, Giuseppe and Cuculo, Vittorio and Cornia, Marcella and Cucchiara, Rita.\n\n\"Unveiling the Truth: Exploring Human Gaze Patterns in Fake Images.\" APL (2024). [paper] [code] [2024.03]\n\nV-PRISM: Herbert Wright, Weiming Zhi, Matthew Johnson-Roberson, Tucker Hermans.\n\n\"V-PRISM: Probabilistic Mapping of Unknown Tabletop Scenes.\" ArXiv (2024). [paper] [code] [2024.03]\n\nStefan Denner, David Zimmerer, Dimitrios Bounias, Markus Bujotzek, Shuhan Xiao, Lisa Kausch, Philipp Schader, Tobias Penzkofer, Paul F. Jäger, Klaus Maier-Hein.\n\n\"Leveraging Foundation Models for Content-Based Medical Image Retrieval in Radiology.\" ArXiv (2024). [paper] [2024.03]\n\nChaoyi Wang, Yaozhe Song, Yafeng Zhang, Jun Pei, Lijie Xia, Jianpo Liu.\n\n\"Video Generation with Consistency Tuning.\" ArXiv (2024). [paper] [2024.03]\n\nSam-Rsp: Jiaguang Li, et al.\n\n\"Sam-Rsp: A New Few-Shot Segmentation Method Based on Segment Anything Model and Rough Segmentation Prompts.\" SSRN (2024). [paper] [code] [2024.03]\n\nLumen: Yang Jiao, Shaoxiang Chen, Zequn Jie, Jingjing Chen, Lin Ma, Yu-Gang Jiang.\n\n\"Lumen: Unleashing Versatile Vision-Centric Capabilities of Large Multimodal Models.\" ArXiv (2024). [paper] [code] [2024.03]\n\nRSBuilding: Mingze Wang, Keyan Chen, Lili Su, Cilin Yan, Sheng Xu, Haotian Zhang, Pengcheng Yuan, Xiaolong Jiang, Baochang Zhang.\n\n\"RSBuilding: Towards General Remote Sensing Image Building Extraction and Change Detection with Foundation Model.\" ArXiv (2024). [paper] [code] [2024.03]\n\nDragAnything: Weijia Wu, Zhuang Li, Yuchao Gu, Rui Zhao, Yefei He, David Junhao Zhang, Mike Zheng Shou, Yan Li, Tingting Gao, Di Zhang.\n\n\"DragAnything: Motion Control for Anything using Entity Representation.\" ArXiv (2024). [paper] [code] [homepage] [2024.03]\n\nARtVista: Trong-Vu Hoang, Quang-Binh Nguyen, Duy-Nam Ly, Khanh-Duy Le, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le.\n\n\"ARtVista: Gateway To Empower Anyone Into Artist.\" CHI (2024). [paper] [code] [2024.03]\n\nChemSAM: Bowen Tang, et al.\n\n\"Automated molecular structure segmentation from documents using ChemSAM.\" ArXiv (2024). [paper] [2024.03]\n\nDAL: Zhang, Fayong and Liu, Kejun and Liu, Yuanyuan and Wang, Chaofan and Zhou, Wujie and Zhang, Hongyan and Wang, Lizhe.\n\n\"Multi-target Domain Adaptation Building Instance Extraction of Remote Sensing Imagery with Domain-common Approximation learning.\" TGRS (2024). [paper] [2024.03]\n\nVisionGPT: Chris Kelly, Luhui Hu, Bang Yang, Yu Tian, Deshun Yang, Cindy Yang, Zaoshan Huang, Zihao Li, Jiayin Hu, Yuexian Zou.\n\n\"VisionGPT: Vision-Language Understanding Agent Using Generalized Multimodal Framework.\" ArXiv (2024). [paper] [2024.03]\n\nWeakSurg: Qiyuan Wang, Yanzhe Liu, Shang Zhao, Rong Liu, S. Kevin Zhou.\n\n\"WeakSurg: Weakly supervised surgical instrument segmentation using temporal equivariance and semantic continuity.\" ArXiv (2024). [paper] [2024.03]\n\nRef LDM-Seg: Chaoyang Wang, Xiangtai Li, Henghui Ding, Lu Qi, Jiangning Zhang, Yunhai Tong, Chen Change Loy, Shuicheng Yan.\n\n\"Explore In-Context Segmentation via Latent Diffusion Models.\" ArXiv (2024). [paper] [code] [2024.03]\n\nGaussianGrasper: Yuhang Zheng, Xiangyu Chen, Yupeng Zheng, Songen Gu, Runyi Yang, Bu Jin, Pengfei Li, Chengliang Zhong, Zengmao Wang, Lina Liu, Chao Yang, Dawei Wang, Zhen Chen, Xiaoxiao Long, Meiqing Wang.\n\n\"GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping.\" ArXiv (2024). [paper] [code] [2024.03]\n\nSoroush Seifi, Daniel Olmeda Reino, Fabien Despinoy, Rahaf Aljundi.\n\n\"Annotation Free Semantic Segmentation with Vision Foundation Models.\" ArXiv (2024). [paper] [2024.03]\n\nSLCF-Net: Helin Cao, Sven Behnke.\n\n\"SLCF-Net: Sequential LiDAR-Camera Fusion for Semantic Scene Completion using a 3D Recurrent U-Net.\" ICRA (2024). [paper] [2024.03]\n\nSAM-Lightening: Yanfei Songa, Bangzheng Pua, Peng Wanga, Hongxu Jiang, Dong Donga, Yiqing Shen.\n\n\"SAM-Lightening: A Lightweight Segment Anything Model with Dilated Flash Attention to Achieve 30 times Acceleration.\" ArXiv (2024). [paper] [code] [2024.03]\n\nDF4LCZ: Qianqian Wu, Xianping Ma, Jialu Sui, and Man-On Pun.\n\n\"DF4LCZ: A SAM-Empowered Data Fusion Framework for Scene-Level Local Climate Zone Classification.\" ArXiv (2024). [paper] [code] [2024.03]\n\nPosSAM: Vibashan VS, Shubhankar Borse, Hyojin Park, Debasmit Das, Vishal Patel, Munawar Hayat, Fatih Porikli.\n\n\"PosSAM: Panoptic Open-vocabulary Segment Anything.\" ArXiv (2024). [paper] [code] [2024.03]\n\nPLM+PMM: Hyung-Il Kim, Kimin Yun, Jun-Seok Yun, Yuseok Bae.\n\n\"Customizing Segmentation Foundation Model via Prompt Learning for Instance Segmentation.\" ArXiv (2024). [paper] [2024.03]\n\nWSI-SAM: Hong Liu, Haosen Yang, Paul J. van Diest, Josien P.W. Pluim, Mitko Veta.\n\n\"WSI-SAM: Multi-resolution Segment Anything Model (SAM) for histopathology whole-slide images.\" ArXiv (2024). [paper] [code] [2024.03]\n\nSAMDA: Yiran Wang, Li Xiao.\n\n\"SAMDA: Leveraging SAM on Few-Shot Domain Adaptation for Electronic Microscopy Segmentation.\" ArXiv (2024). [paper] [2024.03]\n\nZijian Wu, Adam Schmidt, Peter Kazanzides, Septimiu E. Salcudean.\n\n\"Real-time Surgical Instrument Segmentation in Video Using Point Tracking and Segment Anything.\" ArXiv (2024). [paper] [2024.03]\n\nZijian Wu, Adam Schmidt, Peter Kazanzides, Septimiu E. Salcudean.\n\nFluoroSAM: Benjamin D. Killeen, Liam J. Wang, Han Zhang, Mehran Armand, Russell H. Taylor, Greg Osgood, Mathias Unberath.\n\n\"FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation.\" ArXiv (2024). [paper] [code] [2024.03]\n\nReimaginedAct: Lan Wang, Vishnu Boddeti, Sernam Lim.\n\n\"Action Reimagined: Text-to-Pose Video Editing for Dynamic Human Actions.\" ArXiv (2024). [paper] [2024.03]\n\nGEOBIA: He, Tao and Chen, Jianyu and Kang, Linchong and Zhu, Qiankun.\n\n\"Evaluation of Global-Scale and Local-Scale Optimized Segmentation Algorithms in GEOBIA with SAM on Land Use and Land Cover.\" JSTARS (2024). [paper] [2024.03]\n\nObjectCompose: Hashmat Shadab Malik, Muhammad Huzaifa, Muzammal Naseer, Salman Khan, Fahad Shahbaz Khan.\n\n\"ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes.\" ArXiv (2024). [paper] [2024.03]\n\nYao Jiang, Xinyu Yan, Ge-Peng Ji, Keren Fu, Meijun Sun, Huan Xiong, Deng-Ping Fan, Fahad Shahbaz Khan.\n\n\"Effectiveness Assessment of Recent Large Vision-Language Models.\" ArXiv (2024). [paper] [2024.03]\n\nGiannakis, I., Bhardwaj, A., Sam, L., and Leontidis, G..\n\n\"Segment Anything Model (SAM) for Automatic Crater Detection.\" EGU General Assembly (2024). [paper] [2024.03]\n\nBocchino, F., Sergi, G., Ravanelli, R., and Crespi, M..\n\n\"Preliminary analysis of the potentialities of the Segment Anything Model (SAM) in the segmentation of Sentinel-2 imagery for water reservoir monitoring.\" EGU General Assembly (2024). [paper] [2024.03]\n\nRuiqing Yan , et al.\n\n\"Weakly-semi supervised extraction of rooftop photovoltaics from high-resolution images based on segment anything model and class activation map.\" Applied Energy (2024). [paper] [2024.03]\n\nCSFwinformer: Xie, Zhifeng and Wang, Sen and Yu, Qiucheng and Tan, Xin and Xie, Yuan.\n\n\"CSFwinformer: Cross-Space-Frequency Window Transformer for Mirror Detection.\" TIP (2024). [paper] [code] [2024.03]\n\nXiaoyuan Liu, et al.\n\n\"Stereo Vision Meta-Lens-Assisted Driving Vision.\" ACS Photonics (2024). [paper] [2024.03]\n\nPointSeg: Qingdong He, Jinlong Peng, Zhengkai Jiang, Xiaobin Hu, Jiangning Zhang, Qiang Nie, Yabiao Wang, Chengjie Wang.\n\n\"PointSeg: A Training-Free Paradigm for 3D Scene Segmentation via Foundation Models.\" ArXiv (2024). [paper] [2024.03]\n\nMEA: Hairong Shi, Songhao Han, Shaofei Huang, Yue Liao, Guanbin Li, Xiangxing Kong, Hua Zhu, Xiaomu Wang, Si Liu.\n\n\"Mask-Enhanced Segment Anything Model for Tumor Lesion Semantic Segmentation.\" ArXiv (2024). [paper] [2024.03]\n\nGAM-3DSC: Feibo Jiang, Yubo Peng, Li Dong, Kezhi Wang, Kun Yang, Cunhua Pan, Xiaohu You.\n\n\"Large Generative Model Assisted 3D Semantic Communication.\" ArXiv (2024). [paper] [2024.03]\n\nAPPLE: Zikang Xu, Fenghe Tang, Quan Quan, Qingsong Yao, S. Kevin Zhou.\n\n\"APPLE: Adversarial Privacy-aware Perturbations on Latent Embedding for Unfairness Mitigation.\" ArXiv (2024). [paper] [2024.03]\n\nFedFMS: Yuxi Liu, Guibo Luo, Yuesheng Zhu.\n\n\"FedFMS: Exploring Federated Foundation Models for Medical Image Segmentation.\" ArXiv (2024). [paper] [code] [2024.03]\n\nOmniCount: Anindya Mondal, Sauradip Nag, Xiatian Zhu, Anjan Dutta.\n\n\"OmniCount: Multi-label Object Counting with Semantic-Geometric Priors.\" ArXiv (2024). [paper] [2024.03]\n\nP^2SAM: Chenhui Zhao, Liyue Shen.\n\n\"Part-aware Personalized Segment Anything Model for Patient-Specific Segmentation.\" ArXiv (2024). [paper] [2024.03]\n\nSAM-PD: Tao Zhou, Wenhan Luo, Qi Ye, Zhiguo Shi, Jiming Chen.\n\n\"SAM-PD: How Far Can SAM Take Us in Tracking and Segmenting Anything in Videos by Prompt Denoising.\" ArXiv (2024). [paper] [code] [2024.03]\n\nSA-ICM: Takahiro Shindo, Kein Yamada, Taiju Watanabe, Hiroshi Watanabe.\n\n\"Image Coding for Machines with Edge Information Learning Using Segment Anything.\" ArXiv (2024). [paper] [2024.03]\n\nProMISe: Jinfeng Wang, Sifan Song, Xinkun Wang, Yiyi Wang, Yiyi Miao, Jionglong Su, S. Kevin Zhou.\n\n\"ProMISe: Promptable Medical Image Segmentation using SAM.\" ArXiv (2024). [paper] [2024.03]\n\nPopeye: Wei Zhang, Miaoxin Cai, Tong Zhang, Guoqiang Lei, Yin Zhuang, Xuerui Mao.\n\n\"Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection from Remote Sensing Imagery.\" ArXiv (2024). [paper] [2024.03]\n\nKevin Shen, Surabhi S Nath, Aenne Brielmann, Peter Dayan.\n\n\"Simplicity in Complexity.\" ArXiv (2024). [paper] [2024.03]\n\nCCC: Mrityunjoy Gain, Avi Deb Raha, Rameswar Debnath.\n\n\"CCC: Color Classified Colorization.\" ArXiv (2024). [paper] [2024.03]\n\nCAC: Yuhao Lin, Haiming Xu, Lingqiao Liu, Javen Qinfeng Shi.\n\n\"A Simple-but-effective Baseline for Training-free Class-Agnostic Counting.\" ArXiv (2024). [paper] [2024.03]\n\nKhatua, A., Bhattacharya, A., Goswami, A.K. et al.\n\n\"Developing approaches in building classification and extraction with synergy of YOLOV8 and SAM models.\" Spatial Information Research (2024). [paper] [2024.03]\n\nToki Tahmid Inan, Mingrui Liu, Amarda Shehu.\n\n\"Beyond Single-Model Views for Deep Learning: Optimization versus Generalizability of Stochastic Optimization Algorithms.\" AAAI (2024). [paper] [2024.03]\n\nOHTA: Xiaozheng Zheng, Chao Wen, Zhuo Su, Zeran Xu, Zhaohu Li, Yang Zhao, Zhou Xue.\n\n\"OHTA: One-shot Hand Avatar via Data-driven Implicit Priors.\" CVPR (2024). [paper] [code] [2024.02]\n\nFusionVision: Safouane El Ghazouali, Youssef Mhirit, Ali Oukhrid, Umberto Michelucci, Hichem Nouira.\n\n\"FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything.\" ArXiv (2024). [paper] [code] [2024.02]\n\nGROUNDHOG: Yichi Zhang, Ziqiao Ma, Xiaofeng Gao, Suhaila Shakiah, Qiaozi Gao, Joyce Chai.\n\n\"GROUNDHOG : Grounding Large Language Models to Holistic Segmentation.\" ArXiv (2024). [paper] [code] [2024.02]\n\nGEA: Xinqi Liu, Chenming Wu, Xing Liu, Jialun Liu, Jinbo Wu, Chen Zhao, Haocheng Feng, Errui Ding, Jingdong Wang.\n\n\"GEA: Reconstructing Expressive 3D Gaussian Avatar from Monocular Video.\" ArXiv (2024). [paper] [code] [2024.02]\n\nSurgment: Jingying Wang, Haoran Tang, Taylor Kantor, Tandis Soltani, Vitaliy Popov, Xu Wang.\n\n\"Surgment: Segmentation-enabled Semantic Search and Creation of Visual Question and Feedback to Support Video-Based Surgery Learning.\" ArXiv (2024). [paper] [2024.02]\n\nsViT: Young Kyung Kim, J. Matías Di Martino, Guillermo Sapiro.\n\n\"Vision Transformers with Natural Language Semantics.\" ArXiv (2024). [paper] [2024.02]\n\nHuang, Wenjun, Anzhu Yu, Qing Xu, Qun Sun, Wenyue Guo, Song Ji, Bowei Wen, and Chunping Qiu.\n\n\"Sea Ice Extraction via Remote Sensing Imagery: Algorithms, Datasets, Applications and Challenges.\" Remote Sensing (2024). [paper] [2024.02]\n\nOpenMEDLab: Xiaosong Wang, Xiaofan Zhang, Guotai Wang, Junjun He, Zhongyu Li, Wentao Zhu, Yi Guo, Qi Dou, Xiaoxiao Li, Dequan Wang, Liang Hong, Qicheng Lao, Tong Ruan, Yukun Zhou, Yixue Li, Jie Zhao, Kang Li, Xin Sun, Lifeng Zhu, Shaoting Zhang.\n\n\"OpenMEDLab: An Open-source Platform for Multi-modality Foundation Models in Medicine.\" ArXiv (2024). [paper] [code] [2024.02]\n\nRSAM-Seg: Jie Zhang, Xubing Yang, Rui Jiang, Wei Shao, Li Zhang.\n\n\"RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for Remote Sensing Image Semantic Segmentation.\" ArXiv (2024). [paper] [code] [2024.02]\n\nSTLM: Chenghao Li, Lei Qi, Xin Geng.\n\n\"A SAM-guided Two-stream Lightweight Model for Anomaly Detection.\" ArXiv (2024). [paper] [2024.02]\n\nKanyifeechukwu J. Oguine, Roger D. Soberanis-Mukul, Nathan Drenkow, Mathias Unberath.\n\n\"From Generalization to Precision: Exploring SAM for Tool Segmentation in Surgical Environments.\" ArXiv (2024). [paper] [2024.02]\n\nVRP-SAM: Yanpeng Sun, Jiahui Chen, Shan Zhang, Xinyu Zhang, Qiang Chen, Gang Zhang, Errui Ding, Jingdong Wang, Zechao Li.\n\n\"VRP-SAM: SAM with Visual Reference Prompt.\" CVPR (2024). [paper] [2024.02]\n\nSAM-DiffSR: Chengcheng Wang, Zhiwei Hao, Yehui Tang, Jianyuan Guo, Yujie Yang, Kai Han, Yunhe Wang.\n\n\"SAM-DiffSR: Structure-Modulated Diffusion Model for Image Super-Resolution.\" ArXiv (2024). [paper] [code] [2024.02]\n\nJintao Ren, Mathis Rasmussen, Jasper Nijkamp, Jesper Grau Eriksen, Stine Korreman.\n\n\"Segment anything model for head and neck tumor segmentation with CT, PET and MRI multi-modality images.\" ICCR (2024). [paper] [2024.02]\n\nAdaSEEM: Jia Wan, Qiangqiang Wu, Wei Lin, Antoni B. Chan.\n\n\"Robust Unsupervised Crowd Counting and Localization with Adaptive Resolution SAM.\" ArXiv (2024). [paper] [2024.02]\n\nBLO-SAM: Li Zhang, Youwei Liang, Pengtao Xie.\n\n\"BLO-SAM: Bi-level Optimization Based Overfitting-Preventing Finetuning of SAM.\" ICML (2024). [paper] [code] [2024.02]\n\nUN-SAM: Zhen Chen, Qing Xu, Xinyu Liu, Yixuan Yuan.\n\n\"UN-SAM: Universal Prompt-Free Segmentation for Generalized Nuclei Images.\" TMI (2024). [paper] [code] [2024.02]\n\nTV-SAM: Zekun Jiang, Dongjie Cheng, Ziyuan Qin, Jun Gao, Qicheng Lao, Kang Li, Le Zhang.\n\n\"Increasing SAM Zero-Shot Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation.\" ArXiv (2024). [paper] [code] [2024.02]\n\nCoFRIDA: Peter Schaldenbrand, Gaurav Parmar, Jun-Yan Zhu, James McCann, Jean Oh.\n\n\"CoFRIDA: Self-Supervised Fine-Tuning for Human-Robot Co-Painting.\" ArXiv (2024). [paper] [code] [2024.02]\n\nCVLM: Yunxin Li, Xinyu Chen, Baotian Hu, Haoyuan Shi, Min Zhang.\n\n\"Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension with Enhanced Visual Knowledge Alignment.\" ArXiv (2024). [paper] [2024.02]\n\nSAM-EDA: Wang, Ziquan, Yongsheng Zhang, Zhenchao Zhang, Zhipeng Jiang, Ying Yu, Li Li, and Lei Li.\n\n\"Exploring Semantic Prompts in the Segment Anything Model for Domain Adaptation.\" Remote Sensing (2024). [paper] [2024.02]\n\nDSAIL-TreeVision: Cedric Kiplimo and Collins Emasi Epege and Ciira wa Maina and Billy Okal.\n\n\"DSAIL-TreeVision: A software tool for extracting tree biophysical parameters from stereoscopic images.\" SoftwareX (2024). [paper] [code] [2024.02]\n\nXia, Jiahao and Gong, Gavin and Liu, Jiawei and Zhu, Zhigang and Tang, Hao.\n\n\"Pedestrian-Accessible Infrastructure Inventory: Enabling and Assessing Zero-Shot Segmentation on Multi-Mode Geospatial Data for All Pedestrian Types.\" Journal of Imaging (2024). [paper] [2024.02]\n\nLIMP: Benedict Quartey, Eric Rosen, Stefanie Tellex, George Konidaris.\n\n\"Verifiably Following Complex Robot Instructions with Foundation Models.\" ArXiv (2024). [paper] [code] [2024.02]\n\nLMPC: Jacky Liang, Fei Xia, Wenhao Yu, et al.\n\n\"Learning to Learn Faster from Human Feedback with Language Model Predictive Control.\" ArXiv (2024). [paper] [code] [2024.02]\n\nChong Di, Jie Gong.\n\n\"An AI-based approach to create spatial inventory of safety-related architectural features for school buildings.\" DBE (2024). [paper] [2024.02]\n\nWeakSAM: Lianghui Zhu, Junwei Zhou, Yan Liu, Xin Hao, Wenyu Liu, Xinggang Wang.\n\n\"WeakSAM: Segment Anything Meets Weakly-supervised Instance-level Recognition.\" ArXiv (2024). [paper] [code] [2024.02]\n\nSeqAE: Delong Chen, Samuel Cahyawijaya, Jianfeng Liu, Baoyuan Wang, Pascale Fung.\n\n\"Subobject-level Image Tokenization.\" ArXiv (2024). [paper] [code] [2024.02]\n\nDeiSAM: Hikaru Shindo, Manuel Brack, Gopika Sudhakaran, Devendra Singh Dhami, Patrick Schramowski, Kristian Kersting.\n\n\"DeiSAM: Segment Anything with Deictic Prompting.\" ArXiv (2024). [paper] [2024.02]\n\nOBJ-GSP: Wenxiao Cai, Wankou Yang.\n\n\"Object-level Geometric Structure Preserving for Natural Image Stitching.\" ArXiv (2024). [paper] [code] [2024.02]\n\nISCUTE: Shir Kozlovsky, Omkar Joglekar, Dotan Di Castro.\n\n\"ISCUTE: Instance Segmentation of Cables Using Text Embedding.\" ArXiv (2024). [paper] [2024.02]\n\nMATT: James E. Gallagher, Aryav Gogia, Edward J. Oughton.\n\n\"A Multispectral Automated Transfer Technique (MATT) for machine-driven image labeling utilizing the Segment Anything Model (SAM).\" ArXiv (2024). [paper] [2024.02]\n\nDPSM: Xin Zhang, Keren Fu, Qijun Zhao.\n\n\"Dynamic Patch-aware Enrichment Transformer for Occluded Person Re-Identification.\" ArXiv (2024). [paper] [2024.02]\n\nLaserSAM: Alexander Krawciw, Sven Lilge, Timothy D. Barfoot.\n\n\"LaserSAM: Zero-Shot Change Detection Using Visual Segmentation of Spinning LiDAR.\" ArXiv (2024). [paper] [2024.02]\n\nZero SAM: Tal Shaharabany, Lior Wolf.\n\n\"Zero Shot Medical Image Segmentation Based on Sparse Prompt Using Finetuned SAM.\" ArXiv (2024). [paper] [2024.02]\n\nAviad Dahan, Tal Shaharabany, Raja Giryes, Lior Wolf.\n\n\"Video Polyp Segmentation using Implicit Networks.\" ArXiv (2024). [paper] [2024.02]\n\nGurunath Reddy, Dattesh D. Shanbhag, Deepa Anand, Uday Patil.\n\n\"Data Adaptive few-shot multi label segmentation with Foundation models.\" ArXiv (2024). [paper] [2024.02]\n\nJiesi Hu, Yang Shang, Yanwu Yang, Guo Xutao, Hanyang Peng, Ting Ma.\n\n\"Synergizing In-context Learning Model and SAM in Medical Image Segmentation.\" ArXiv (2024). [paper] [2024.02]\n\nUnCLe SAM: Amin Ranem, Mohamed Afham Mohamed Aflal, Moritz Fuchs, Anirban Mukhopadhyay.\n\n\"UnCLe SAM: Unleashing SAM’s Potential for Continual Prostate MRI Segmentatio.\" ArXiv (2024). [paper] [2024.02]\n\nLester: Ruben Tous.\n\n\"Lester: rotoscope animation through video object segmentation and tracking.\" ArXiv (2024). [paper] [2024.02]\n\nFine-Tune Distillation: .\n\n\"Domain Adaptable Fine-Tune Distillation Framework For Advancing Farm Surveillance.\" ArXiv (2024). [paper] [code] [2024.02]\n\nYOLO + SAM: Henry Gann, Josiah Bull, Trevor Gee, Mahla Nejati.\n\n\"Improving Pallet Detection Using Synthetic Data.\" ACRA (2023). [paper] [2024.02]\n\nEfficientViT-SAM: Zhuoyang Zhang, Han Cai, Song Han.\n\n\"EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss.\" ArXiv (2024). [paper] [code] [2024.02]\n\nClickSAM: Aimee Guo, Gace Fei, Hemanth Pasupuletic, Jing Wang.\n\n\"ClickSAM: Fine-tuning Segment Anything Model using click prompts for ultrasound image segmentation.\" SPIE Medical Imaging Conference (2024). [paper] [2024.02]\n\nIris-SAM: Parisa Farmanifard, Arun Ross.\n\n\"Iris-SAM: Iris Segmentation Using a Foundational Model.\" ArXiv (2024). [paper] [2024.02]\n\nCAT-SAM: Aoran Xiao, Weihao Xuan, Heli Qi, Yun Xing, Ruijie Ren, Xiaoqin Zhang, Shijian Lu.\n\n\"CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model.\" ECCV (2024). [paper] [code] [2024.02]\n\nCOMRP: Zihan Ma, Yongshang Li, Ronggui Ma, Chen Liang.\n\n\"Unsupervised semantic segmentation of high-resolution UAV imagery for road scene parsing.\" ArXiv (2024). [paper] [2024.02]\n\nSAM+SLIC: Michal Shlapentokh-Rothman, Ansel Blume, Yao Xiao, Yuqun Wu, Sethuraman T V, Heyi Tao, Jae Yong Lee, Wilfredo Torres, Yu-Xiong Wang, Derek Hoiem.\n\n\"Region-Based Representations Revisited.\" ArXiv (2024). [paper] [2024.02]\n\nPolyp-DAM: Zhuoran Zheng, Chen Wu, Wei Wang, Yeying Jin, Xiuyi Jia.\n\n\"Polyp-DAM: Polyp segmentation via depth anything model.\" ArXiv (2024). [paper] [code] [2024.02]\n\nAnyChange: Zhuo Zheng, Yanfei Zhong, Liangpei Zhang, Stefano Ermon.\n\n\"Segment Any Change.\" ArXiv (2024). [paper] [2024.02]\n\nSureka Thiruchittampalam, Bikram P. Banerjee, Nancy F. Glenn, Simit Raval.\n\n\"Comparative Evaluation of Traditional and Deep Learning-Based Segmentation Methods for Spoil Pile Delineation Using UAV Images.\" ArXiv (2024). [paper] [2024.02]\n\nHi-SAM: Maoyuan Ye, Jing Zhang, Juhua Liu, Chenyu Liu, Baocai Yin, Cong Liu, Bo Du, Dacheng Tao.\n\n\"Hi-SAM: Marrying Segment Anything Model for Hierarchical Text Segmentation.\" ArXiv (2024). [paper] [code] [2024.01]\n\nConv-LoRA: Zihan Zhong, Zhiqiang Tang, Tong He, Haoyang Fang, Chun Yuan.\n\n\"Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model.\" ICLR (2024). [paper] [2024.01]\n\nKangcheng Liu, Xinhu Zheng, Chaoqun Wang, Hesheng Wang, Ming Liu, Kai Tang.\n\n\"Online Robot Navigation and and Manipulation with Distilled Vision-Language Models.\" ICRA (2024). [paper] [2024.01]\n\nMouSi: Xiaoran Fan, Tao Ji, Changhao Jiang, Shuo Li, Senjie Jin, Sirui Song, Junke Wang, Boyang Hong, Lu Chen, Guodong Zheng, Ming Zhang, Caishuang Huang, Rui Zheng, Zhiheng Xi, Yuhao Zhou, Shihan Dou, Junjie Ye, Hang Yan, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang.\n\n\"MouSi: Poly-Visual-Expert Vision-Language Models.\" ArXiv (2024). [paper] [code] [2024.01]\n\nSA-GS: Xu Hu, Yuxi Wang, Lue Fan, Junsong Fan, Junran Peng, Zhen Lei, Qing Li, Zhaoxiang Zhang.\n\n\"Semantic Anything in 3D Gaussians.\" ArXiv (2024). [paper] [2024.01]\n\nSimAda: Yiran Song, Qianyu Zhou, Xuequan Lu, Zhiwen Shao, Lizhuang Ma.\n\n\"SimAda: A Simple Unified Framework for Adapting Segment Anything Model in Underperformed Scenes.\" ArXiv (2024). [paper] [code] [2024.01]\n\nMESA: Yesheng Zhang, Xu Zhao.\n\n\"MESA: Matching Everything by Segmenting Anything.\" ArXiv (2024). [paper] [2024.01]\n\nMixSup: Yuxue Yang, Lue Fan, Zhaoxiang Zhang.\n\n\"MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D Object Detection.\" ICLR (2024). [paper] [code] [2024.01]\n\nGEM: Jing Hao, Moyun Liu, Kuo Feng Hung.\n\n\"GEM: Boost Simple Network for Glass Surface Segmentation via Segment Anything Model and Data Synthesis.\" ArXiv (2024). [paper] [code] [2024.01]\n\nLoRA-SAM: Zehao Ye, Lucy Lovell, Asaad Faramarzi, Jelena Ninic.\n\n\"SAM-based instance segmentation models for the automation of masonry crack detection.\" ArXiv (2024). [paper] [2024.01]\n\nSSR: Yanqi Ge, Ye Huang, Wen Li, Lixin Duan.\n\n\"SSR: SAM is a Strong Regularizer for domain adaptive semantic segmentation.\" ArXiv (2024). [paper] [2024.01]\n\nScaleFlow: Chengbo Yuan, Chuan Wen, Tong Zhang, Yang Gao.\n\n\"General Flow as Foundation Affordance for Scalable Robot Learning.\" ArXiv (2024). [paper] [code] [2024.01]\n\nHAZARD: Qinhong Zhou, Sunli Chen, Yisong Wang, Haozhe Xu, Weihua Du, Hongxin Zhang, Yilun Du, Joshua B. Tenenbaum, Chuang Gan.\n\n\"HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments.\" ICLR (2024). [paper] [code] [2024.01]\n\nLaura J. Brooks , Daniel Pearce, Kenton Kwok , Nikhil Jawade , Man Qi, Erola Fenollosa , Deniz Beker, James Whicker, Katrina Davis, Roberto Salguero-G´omez, Robin Wang, and Steve Chappell.\n\n\"A video-rate hyperspectral camera for monitoring plant health and biodiversity.\" ArXiv (2024). [paper] [2024.01]\n\nSAM-OBC: Hu, Yixin and Qi, Zhixin and Zhou, Zhexun and Qin, Yan.\n\n\"Detection of Benggang in Remote Sensing Imagery through Integration of Segmentation Anything Model with Object-Based Classification.\" ArXiv (2024). [paper] [2024.01]\n\nOK-Robot: Peiqi Liu,Yaswanth Orru, Chris Paxton, Nur Muhammad Mahi Shafiullah, Lerrel Pinto.\n\n\"OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics.\" ArXiv (2024). [paper] [code] [2024.01]\n\nBowei Xue, Han Cheng, Qingqing Yang, Yi Wang, and Xiaoning He.\n\n\"Adapting Segment Anything Model to Aerial Land Cover Classification with Low Rank Adaptation.\" IEEE LGRS (2024). [paper] [2024.01]\n\nPeng Qian,Tomer Ullman.\n\n\"Shape Guides Visual Pretense.\" ArXiv (2024). [paper] [2024.01]\n\nMultiDance-Zero: Zhe Xu, Kun Wei, Xu Yang, Cheng Deng.\n\n\"Do You Guys Want to Dance: Zero-Shot Compositional Human Dance Generation with Multiple Persons.\" ArXiv (2024). [paper] [2024.01]\n\nVary-toy: Haoran Wei, Lingyu Kong, Jinyue Chen, Liang Zhao, Zheng Ge, En Yu, Jianjian Sun, Chunrui Han, Xiangyu Zhang.\n\n\"Small Language Model Meets with Reinforced Vision Vocabulary.\" ArXiv (2024). [paper] [code] [2024.01]\n\nWildRGB-D: Hongchi Xia, Yang Fu, Sifei Liu, Xiaolong Wang.\n\n\"RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos.\" ArXiv (2024). [paper] [code] [2024.01]\n\nTyche: Marianne Rakic, Hallee E. Wong, Jose Javier Gonzalez Ortiz, Beth Cimini, John Guttag, Adrian V. Dalca.\n\n\"Tyche: Stochastic In-Context Learning for Medical Image Segmentation.\" ArXiv (2024). [paper] [code] [2024.01]\n\nGrounded SAM: Tianhe Ren, Shilong Liu, Ailing Zeng, Jing Lin, Kunchang Li, He Cao, Jiayu Chen, Xinyu Huang, Yukang Chen, Feng Yan, Zhaoyang Zeng, Hao Zhang, Feng Li, Jie Yang, Hongyang Li, Qing Jiang, Lei Zhang.\n\n\"Grounded SAM: Assembling Open-World Models for Diverse Visual Tasks.\" ArXiv (2024). [paper] [code] [2024.01]\n\nTriSAM: Jia Wan, Wanhua "
    }
}