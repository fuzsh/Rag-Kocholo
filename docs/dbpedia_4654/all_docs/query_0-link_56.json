{
    "id": "dbpedia_4654_0",
    "rank": 56,
    "data": {
        "url": "https://www.eejournal.com/article/rescuing-doctor-whos-k-9/",
        "read_more_link": "",
        "language": "en",
        "title": "Rescuing Doctor Who’s K-9",
        "top_image": "https://www.eejournal.com/wp-content/uploads/2018/05/SL-180531.jpg",
        "meta_img": "https://www.eejournal.com/wp-content/uploads/2018/05/SL-180531.jpg",
        "images": [
            "https://www.facebook.com/tr?id=1876893785684306&ev=PageView&noscript=1",
            "https://www.eejournal.com/wp-content/uploads/2017/05/cropped-EEJ_master_20years_onblack.png",
            "https://www.eejournal.com/wp-content/themes/techfocus-twentysixteen-child/images/icon_embedded25.png",
            "https://www.eejournal.com/wp-content/themes/techfocus-twentysixteen-child/images/icon_iot-mems25.png",
            "https://www.eejournal.com/wp-content/themes/techfocus-twentysixteen-child/images/icon_maker-hobby25.png",
            "https://www.eejournal.com/wp-content/themes/techfocus-twentysixteen-child/images/icon_robotics25.png",
            "https://www.eejournal.com/wp-content/themes/techfocus-twentysixteen-child/images/icon_semiconductor25.png",
            "https://www.eejournal.com/wp-content/uploads/2017/05/subscribe_EEJ_nl.png",
            "https://www.eejournal.com/wp-content/uploads/2018/05/SL-180531.jpg",
            "https://www.eejournal.com/wp-content/uploads/2018/05/K-9-Block-Diagram.png",
            "https://www.eejournal.com/wp-content/uploads/2018/05/K9-Final-Model-with-sensors.png",
            "https://www.eejournal.com/wp-content/uploads/2018/05/K-9-Gantt-Chart.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/facebook.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/twitter.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/youtube.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/linkedin.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/rss-feed.png",
            "https://www.reddit.com/static/spreddit7.gif",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/facebook.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/twitter.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/youtube.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/linkedin.png",
            "https://www.eejournal.com/wp-content/plugins/social-media-buttons-toolbar/inc/img/social-media-icons/rss-feed.png",
            "https://www.eejournal.com/wp-content/uploads/2019/10/CoolBeans.png",
            "https://i.ytimg.com/vi/SHFvtUrrIAA/hqdefault.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2018-05-31T13:07:11+00:00",
        "summary": "",
        "meta_description": "Optimism: Belief that everything will work out well. Irrational, bordering on insane. – K-9, “The Armageddon Factor, Episode One,” Doctor Who, 1977 When Abertay University student and computer scie…",
        "meta_lang": "en",
        "meta_favicon": "https://www.eejournal.com/wp-content/uploads/2017/05/cropped-EEJ_favicon_2020-copy-32x32.png",
        "meta_site_name": "EEJournal",
        "canonical_link": "https://www.eejournal.com/article/rescuing-doctor-whos-k-9/",
        "text": "Optimism: Belief that everything will work out well. Irrational, bordering on insane. – K-9, “The Armageddon Factor, Episode One,” Doctor Who, 1977\n\nWhen Abertay University student and computer science major Gary Taylor found the fried, water-damaged remains of K-9, Doctor Who’s reliable robotic canine companion, in a university lab last September, he made the remote-controlled robot celebrity the focus of his final-year dissertation even before getting the go-ahead from his project supervisor, Dr. Ian Ferguson. As Taylor explains, ““I love robotics, I love programming, I love dogs, and I love Doctor Who.”\n\nThe university purchased this K-9 during the 2011-2012 academic year, one of roughly a dozen prop K-9s sold off by the BBC. It had been abandoned over time. When Taylor found this lost little robot dog in a lab, he discovered that a roof leak had destroyed all of the interior electronic and electromechanical components, leaving only K-9’s easily recognized shell.\n\nThe original K-9 was introduced into the long-running “Doctor Who” television series in 1977. It was radio-controlled, and, because it was based on 1970s-era analog RC gear, the original K-9 was a fairly unreliable prop, as were most RC props of the era, like the R2-D2 robot prop used in “Star Wars.” The RC electronics and the broadcast video electronics in the studio interfered, causing the robot to crash into sets and frequently forcing many scene retakes.\n\nTaylor’s plan was to not only restore the K-9 robot but to make it better using 21st-century electronics. The dissertation’s title essentially explains the entire project: “Creating an Autonomous Robot Utilizing Raspberry Pi, Arduino, and Ultrasound Sensors for Mapping a Room.” This was no publicity stunt to reanimate a favorite TV mascot. It was a serious senior engineering project with the goal of creating an autonomous robot based on some very advanced electronics and software that merely lives inside a favorite TV mascot’s shell.\n\nThe project started in October of last year, and Taylor unveiled the restored and vastly improved K-9 last week at Abertay’s Digital Graduate Show.\n\nFrom the start, Taylor decided to build a distributed embedded system based on a Raspberry Pi 3 Model B and an Arduino Mega2560. He recognized that the project stood a better chance of success by offloading the real-time tasks—motor and sensor control—to the Arduino’s on-board microcontroller, which would allow the quad-core, 1.2GHz, 64-bit Arm Cortex-A53 microprocessor inside the board’s Broadcom BCM2837 application processor to handle the high-level mapping functions. The plan also included using the Raspberry Pi 3 Model B’s built-in Bluetooth wireless capabilities to link to a OnePlus 3T mobile phone. A custom-built app running on the phone serves as a handheld remote control for the robot.\n\nHere’s the resulting block diagram of the design project, taken from Taylor’s dissertation:\n\nThe Arduino Mega2560 directly operates the robot’s three HC-SR04 ultrasound sensors using GPIO pins and an existing ultrasound library. One sensor faces directly forward and the other two sensors are angled to the left and the right. The three white sensors appear along the bottom edge of the robot in this photo:\n\nThe Arduino Mega2560 controls the robot’s left and right traction motors through a Monster Moto Shield plugged into the Arduino’s shield headers. These motors drive a pair of wheels while a third, undriven pivot wheel towards the back of the robot provides stability. In aircraft jargon, this K-9 is a tail-dragger.\n\nThe motor-control shield uses a pair of ST Microelectronics VNH2SP30 full-bridge, high-current motor drivers capable of handling motor loads as large as 30A at 41V, although the robot uses much lower motor voltages and currents. As you can see from the block diagram above, the Arduino directly controls the VNH2SP30 full-bridge motor drivers on the shield through the Arduino’s existing PWM outputs using an existing Arduino software library. If you shop online, you can find copies of this motor-control shield for less than $6. At that price, you can hardly afford to roll your own—especially for a one-off project like this K-9 project.\n\nIn the original project plan, Taylor planned to use the Arduino to also control a TDK InvenSense MPU-6050 6-DOF (degrees of freedom) MEMS IMU (inertial measurement unit). The MPU-6050 combines a 3-axis gyroscope and a 3-axis accelerometer on the same silicon die and is popular for use in dead-reckoning guidance systems. Basically, it’s a motion-tracking sensor. The MPU-6050 sensor communicates over I2C, and it’s a favorite device for robotics experimenters, so there’s naturally an Arduino library for the MPU-6050 sensor as well as inexpensive breakout boards that make it easy for experimenters to work with the small SMT device.\n\nThe Raspberry Pi 3 Model B sends control messages to and receives sensor information from the Arduino Mega2560, which communicates over a USB connection. Taylor’s dissertation discusses serial communications alternatives such as asynchronous UART or I2C. However, both the Raspberry Pi and the Arduino have robust, community-supported libraries for USB communications, so that’s what he ultimately chose.\n\nUsing the sensor data obtained from the Arduino Mega2560, the Raspberry Pi 3 Model B would create a location and obstacle map as the robot explored its surroundings. The map is stored in an on-board SQLite 3 database, which is public-domain code already compiled to run on the Raspberry Pi.\n\nAs mentioned, the Raspberry Pi also supplies the Bluetooth communications to the OnePlus 3T cellular phone. For this, Taylor used the PyBluez Python-based wrapper for the official Bluez Linux Bluetooth stack. The Raspberry Pi 3 Model B is running the Raspbian flavor of the Debian operating system, which is based on the Linux kernel.\n\nTaylor’s dissertation charts a methodical approach to the project and includes a Gantt chart:\n\nThe first planned steps in the project included prototyping and coding the Arduino-based motor control functions. After all, you need a moving robot to continue with the next development steps. Once the basic sensor and motor platform could move around and avoid obstacles, Taylor planned to add mapping capabilities and autonomy via the Raspberry Pi.\n\nThis is a very ambitious engineering project, especially for a fourth-year undergraduate student, so there’s no surprise in finding out that the project didn’t progress exactly as planned on the Gantt chart. After all, that rarely happens in real life.\n\nAfter full integration, Taylor made a few test mapping runs and got inconsistent results. In the first test, which lasted three minutes, the robot detected objects that didn’t exist. In the second test, which lasted five minutes, the resulting map appeared to be too small. Something was clearly amiss.\n\nThe third test, another 3-minute test, appeared to produce better results, so Taylor pressed on by adding an obstacle to the environment before the fourth test. At this point, it became clear that the robot simply did not know where it was. There was a significant problem with the inertial-measurement portion of the design.\n\nThe fault lay in the interface to the MPU-6050 IMU. Reads from the MPU-6050 resulted in FIFO overload errors and the data from the IMU could not be used. If the robot didn’t know where it was and what route it had taken to get there, it could not draw an accurate map.\n\nThat’s when time ran out. Taylor could control his robot using an app running on the cellular phone but the robot could not navigate autonomously.\n\nIn his dissertation, Taylor writes:\n\n“The scale of the project was much larger than expected from the proposal stage of the project. Whenever a project scope gets added up or modified or enhanced, it leads to scope creep in the project. The scope creep has an impact on project quality and success factors such as cost, time, function points, number of developers etc.”\n\nLater, in a section labeled “Future Work,” he writes:\n\n“There is much room for improvement in this project. The final model was only a prototype to display the functionality of the device; changes would be required for a better functioning device.\n\n“Firstly, the robot software design needs to be changed to include the Gyroscope. The Gyroscope can make the robot motion more accurate and can be used to set the robot direction easier and solve the problem of the offset of the device. This would provide much more accurate results in terms of accurate data.”\n\nAlthough he did not ultimately develop an autonomous robot but more of a remote-controlled robot, this project was a huge success. Taylor gained many of the project-development skills he will need going forward, including careful project planning, good ongoing documentation, and the need to avoid deathly feature creep.\n\nThose are the obvious engineering skills he’s learned from his project.\n\nTaylor is also beginning to learn about another important skill—a soft one. Autonomous robot projects in universities are common. They’re cool, but they’re common, and none are likely to catch the public’s attention. However, by encasing his autonomous robot in a celebrity skin, K-9’s skin, he elevated his project’s recognition factor by many orders of magnitude.\n\nTaylor and his revived K-9 have now appeared in UK newspapers including The Scottish Sun, The Courier, and The Daily Record as well as the SyFy cable channel’s online news site SyFyWire and the Doctor Who fan site The Gallifreyan Newsroom. Taylor’s project has now exposed him to some of the fundamentals of marketing that every high-tech entrepreneur should master."
    }
}