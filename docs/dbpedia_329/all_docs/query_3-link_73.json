{
    "id": "dbpedia_329_3",
    "rank": 73,
    "data": {
        "url": "https://www.law.georgetown.edu/privacy-technology-center/our-work/",
        "read_more_link": "",
        "language": "en",
        "title": "Our Work",
        "top_image": "https://www.law.georgetown.edu/privacy-technology-center/wp-content/themes/georgetownlaw/georgetownlaw/images/favicons/favicon-32x32.png?v=0.0.1",
        "meta_img": "https://www.law.georgetown.edu/privacy-technology-center/wp-content/themes/georgetownlaw/georgetownlaw/images/favicons/favicon-32x32.png?v=0.0.1",
        "images": [
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/themes/georgetownlaw/georgetownlaw/images/logo-print-custom.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/themes/georgetownlaw/georgetownlaw/images/src/icons/logo.svg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/GJPLP-Symposium-Rejouis-1-Medium-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/Outbraving-logo-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/GJPLP-Symposium-Rejouis-1-Medium-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/pLSC-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/tm-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/lat-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/alkdjf-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/pic-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/mc-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/GLiwkzma8AIqdk_-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/Simone-Edwards-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/jf-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/aiaware-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/signal-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/baltsun-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/rental-application-form-financial-concept1-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/EmpowerDC-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/07/Seal-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/Screen-Shot-2024-01-09-at-2.42.37-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/02/HSS-2-2-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/Screen-Shot-2024-01-09-at-2.41.14-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/Screen-Shot-2024-01-09-at-2.38.40-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/Screen-Shot-2024-01-10-at-11.01.28-AM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/Screen-Shot-2024-01-09-at-2.36.19-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/UN-Human-Rights-Treaty-Body-logo-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/09/6508c4fc4504e.preview-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/07/Screenshot-2024-07-09-at-3.42.59 PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2024/01/Untitled-design2-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/07/Seal-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/07/ICE-officers-detain-a-man-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/07/Image-for-Our-Work-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/07/LRAN-logo-1-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/03/FTC-seal-copy1-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/07/RightsCon-Costa-Rica-logo-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/07/our-work-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/07/CBS-Baltimore-logo-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/05/Screen-Shot-2023-05-16-at-12.06.35-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/05/Screen-Shot-2023-05-16-at-12.04.44-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/05/Screen-Shot-2023-05-16-at-12.03.00-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/DSC_0592-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/Facial-recognition-copy-1-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/Meg-Foster-testifying-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/police-lights-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/NTIA-logo-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/Berkman-Klein-Center-logo-copy-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/25a6c8e0f24c0d1114215b09de0fbb1b-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/University-of-Richmond-logo-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/03/Tech-Policy-Press-logo-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/03/National-Association-of-Attorneys-General-logo-copy-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/03/FTC-seal-copy1-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/03/House-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/04/John_A._Wilson_Building_west_side-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/03/Algorithm-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/162827861_5331261950279009_1493161060867536920_n-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/Senate-seal-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/imrs-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/Untitled-2-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/Untitled-3-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/YLHLP4YUU4VYXXQW3NOMXA2F2Y-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/03/Untitled-design-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/methode_sundaytimes_prod_web_bin_26619bfc-debd-11ec-a8e5-0e2d1d181260-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/TV6IZ3FJGBC6PAWQWJHXMSJJUM-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/USA-Today-logo-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/imrs-1-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/Open-Society-Foundations-logo-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/Man-with-facial-analysis-superimposed-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/09/House-of-Commons-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/05/New-Jersey-facial-rec-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/05/The-Dark-Side-of-Reform-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2022/05/Office-of-Science-and-Technology-Policy-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2023/03/Community-Oversight-of-Surveillance-Coalition-logo-copy-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/11/CK_MIPA-Oct-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/11/Newsbeat-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/09/CK_NIST-0910-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/09/JS_WaPo-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/09/JS_WaPo-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/09/60-Minutes-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/5e1fd277f64941c26c2eaffc_Coded-Bias-e1612213148707-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/5e1fd277f64941c26c2eaffc_Coded-Bias-e1612213148707-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/04/ai4all-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/04/Screen-Shot-2021-04-07-at-11.05.45-AM-e1617808046300-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/04/CIty_Surveillance-e1617804716387-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/04/CIty_Surveillance-e1617804716387-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/04/MD-bill-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/Screen-Shot-2021-02-01-at-4.09.47-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/Screen-Shot-2021-02-01-at-4.09.47-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/FREEP-1-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/AU-AI-e1612213364632-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/AU-AI-e1612213364632-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/5e1fd277f64941c26c2eaffc_Coded-Bias-e1612213148707-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/Screen-Shot-2021-02-01-at-3.42.46-PM-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/Belfer-e1612210649462-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/CG2-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/slate-oped-1-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/slate-oped-1-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/NoTechForICE-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/MinnesotaLaw-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/FTC-520-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/AINow-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/Robinson-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/NACDL-e1612204126730-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/70million-scaled-e1612203988513-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/Screen-Shot-2021-02-01-at-1.18.11-PM-e1612203615719-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/BannedPDX-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/CG-e1612202712473-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/POGO-e1612202742334-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/RightsCon-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/AUW-clip-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/AUW-clip-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/AJ-Stream-e1612202773852-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/02/Josh-Chin-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/rotunda-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/Last-Week-Tonight-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/Last-Week-Tonight-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/ACLU-blog-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/True-safety-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/Enough_protest-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/covid-principles-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/asatt-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2021/01/state-letter-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/Carnegie-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/IAPP-webinar-copy-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/UFT-logo-1-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/js2-1-e1612201258713-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/OK-Google-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/AB-1-e1612201130276-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/Baltimore-Sun-e1612201083144-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/full-face-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/05/hsr-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/02/Boston-Globe-Logo-e1612200965968-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/02/Boston-Globe-Logo-e1612200965968-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/02/PSSB_seminar_img1_20191203-e1612200658268-300x225.jpeg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/01/jase-bloor-By1VMCg3K4I-unsplash-2-2-e1612200602369-300x209.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2020/01/jase-bloor-By1VMCg3K4I-unsplash-2-2-e1612200602369-300x209.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/11/VUW-copy-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/10/McKenzieFunk-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/10/McKenzieFunk-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/11/Clare2-copy-e1612200330154-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/10/UtahCapitol-copy-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/10/fbi-dhs-letter-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/10/fbi-dhs-letter-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/laptop-solid_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/laptop-solid_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/laptop-solid_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/laptop-solid_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/comments-regular_edit_2_f7f7f7_scale_change-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/comments-regular_edit_2_f7f7f7_scale_change-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/comments-regular_edit_2_f7f7f7_scale_change-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/comments-regular_edit_2_f7f7f7_scale_change-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/handshake-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/landmark-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/comments-regular_edit_2_f7f7f7_scale_change-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/landmark-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/video-solid_edit_2_f7f7f7-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/handshake-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/handshake-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/handshake-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/handshake-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/laptop-solid_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/handshake-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/envelope-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/handshake-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/newspaper-regular_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/balance-scale-solid_edit_2_f7f7f7.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/handshake-regular_edit_2_f7f7f7-300x225.png",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/comments-regular_edit_2_f7f7f7_scale_change-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/uploads/sites/9/2019/02/comments-regular_edit_2_f7f7f7_scale_change-300x225.jpg",
            "https://www.law.georgetown.edu/privacy-technology-center/wp-content/themes/georgetownlaw/georgetownlaw/images/logo-print.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "https://www.law.georgetown.edu/privacy-technology-center/wp-content/themes/georgetownlaw/georgetownlaw/images/favicons/apple-touch-icon-57x57.png?v=0.0.1",
        "meta_site_name": "",
        "canonical_link": "https://www.law.georgetown.edu/privacy-technology-center/our-work/",
        "text": "June 2024: Distinguished Fellow Gabrielle Rejouis spoke on \"Black Political Economy, Capital Racism and Technology (Economic & Legal)\" panel at Outbraving Summit. On the panel, she spoke about why privacy and algorithmic accountability policies should not be separated. She also discussed why regulations for workplace technology should address the impact of surveillance rather than focus on the technology used.\n\nMay 2024: The LA Times covered our latest report findings from \"Raiding the Genome: How the United States Government Is Abusing Its Immigration Powers to Amass DNA for Future Policing.\" In a front page article. Director of Research & Advocacy Stevie Glaberson was quoted \"Even when people know what’s happening, they’re terrified to ask questions, they’re terrified to object, they’re terrified to refuse.\"\n\nMay 2024: The Center signed on to coalition report, along with 39 others, that aimed to combat the inaccurate way in which the Senate positioned their roadmap as a starting point for understanding AI concerns. The \"Shadow Report to the US AI Policy Roadmap\" points out that this process has eaten up a year of this legislative session to produce yet another roadmap that superficially namechecks issues, instead of actual progress towards enforceable law.\n\nApril 2024: The Center co-sponsored (with Georgetown Tech Law, hosted by Digital Ethics Georgetown) a book talk moderated by Professor Laura DeNardis about The Secret Life of Data by Jesse Gilbert and Aram Sinnreich. The authors and Professor DeNardis discussed data surveillance, digital forensics, and generative AI. The book explores the unpredictable ways in which data surveillance, AI, and the constant presence of algorithms impact our culture and society in the age of global networks. No matter what form and what purpose we think it's being used for, data will always have a secret life. The book was published in May 2024.\n\nApril 2024: The Center's 2023-2024 Fritz Fellow Simone Edwards presented, along with Massive Data Institute team, at the annual Fritz Conference. Simone presented on her work as part of the Fritz team during the 2023-2024 school year. She discussed her work digesting documents disclosed in response to the Center's FOIA requests, as well as the strategic corporate research she undertook to find out more about the companies and individuals behind the technologies those documents revealed police departments to be buying, specifically probabilistic genotyping programs.\n\nApril 2024: In conjunction with Tech & Society Week 2024, the Center on Privacy & Technology co-hosted the “New Tech, Old Story: How Understanding the History of Worker Surveillance Should Inform Policies and Regulation” with United for Respect and the Athena Coalition. The panelists, EEOC General Counsel Karla Gilbride, founder and Executive Director of the Missouri Workers Center Jeremy Al-Haj, and the Center on Privacy and Technology’s Distinguished Fellow Gabrielle Rejouis, discussed how contemporary workplace surveillance policies are repeating patterns from the past. Each panelist outlined how worker surveillance has evolved from slavery to the post-pandemic workplace and how understanding this history can empower people to seek impactful change in workplace surveillance practices.\n\nMarch 2024: Executive Director Emily Tucker’s article \"Our Future Inside The Fifth Column - Or, What Chatbots Are Really For” was translated into Italian and published in the AI Aware magazine. In it, Tucker analyzes how major tech companies use chatbots and artificial intelligence as tools for marketing monopoly consolidation and political influence rather than for the common good. It also points out the media's lack of critical attention towards this and the dangers of corporate power accumulation. AI Aware aims to provide in-depth and accessible analysis on the ethical, social, and technical issues related to AI. The original piece, in English, was published on Tech Policy Press in June 2023.\n\nFebruary 2024: Senior Associate Cynthia Khoo appeared on a radio show, The Signal with Adam Walsh, CBC Newfoundland and Labrador. She spoke on the civil rights implications of artificial intelligence, including bias and abuse embedded in how AI-based tools are developed and deployed. Cynthia also emphasized factors that regulators should keep in mind when assessing the potential benefits and harms of AI, including: who is disproportionately harmed; false advertising of AI hiding human workers; and avoiding technosolutionism. Her interview was played on air for comment by the NL Information and Privacy Commissioner.\n\nJanuary 2024: David Vladeck co-authored an op-ed in Baltimore Sun \"You’re giving away your rights in those online contracts you don’t read\" which argued that businesses are stripping away consumer rights through online contracts. The piece called on the CFPB to outlaw the use of unfair clauses in some consumer contracts.\n\nDecember 2023: Senior Associate Cynthia Khoo, Director of Research and Advocacy Stevie Glaberson, and Justice Fellow Emerald Tse coordinated a virtual teach-in on algorithmic housing discrimination in DC. The teach-in featured speakers with legal and research expertise in or firsthand experiences of algorithmic housing discrimination, including: Natasha Duarte (Upturn); Susie McClannahan (Equal Rights Center); Troy and Monique Murphy (individual members of the Fair Budget Coalition), and Wanqian Zhang (3L at Georgetown Law and Student Attorney at the Communications and Technology Law Clinic).\n\nDecember 2023: Senior Associate Cynthia Khoo spoke to Daniel del Pielago, Housing Director at Empower DC, for their podcast Taking Action, a one-hour radio show aired live every Tuesday at 1pm ET on WPFW 89.3 FM. She was interviewed alongside Ben Winters, Senior Counsel and lead of the AI and Human Rights Project at the Electronic Privacy Information Center (EPIC). Cynthia and Ben spoke about algorithmic housing discrimination, as well as algorithmic discrimination more broadly.\n\nDecember 2023: The Privacy Center signed on to comments relating to OMB's guidance following the Biden AI EO. Comments were written by Just Futures Law, Surveillance Resistance Lab, UCLA Center on Race and Digital Justice, Mijente and Media Justice, many of whom have been and continue to be partners in Privacy Center efforts. The comments focused on the OMB guidance specifically as it relates to DHS and federal acquisition and use of AI impacting immigrant communities.\n\nNovember 2023: The Center’s Executive Director Emily Tucker and Clinical Fellow at the International Justice Clinic at UC Irvine Law co-authored a piece published in Tech Policy Press that highlights the United Nations Human Rights Committee's Concluding Observations that calls out how ICE’s surveillance practices conflict with human rights law and the right to privacy. Those observations echo our report co-written with the International Justice Clinic we submitted as part of their periodic review process.\n\nNovember 2023: The Privacy Center co-authored with Upturn a comment to the US Department of Health and Human Services on a proposed update to the agency’s regulations implementing Section 504 of the Rehabilitation Act of 1973, arguing that the proposed rule is incomplete because it fails to address the sites in the system where most discrimination occurs: reporting, screening, and investigation. Our comment also highlights how agencies may use algorithmic and data-driven tools that contribute to disability discrimination and provides recommendations to address discrimination at the front end of the system.\n\nOctober 2023: Congress proposed a bill to regulate police use of face recognition. Executive Director Emily Tucker made a statement in support of the bill. \"The Facial Recognition Act of 2023 takes a powerful stand against the spread of surveillance policing in the United States. As the movement to ban facial recognition builds across the country, Congressman Lieu's bill would set a solid federal floor to limit the harms of this corrupt technology in our communities. With a clear non-preemption statement, a private right of action, strong limits against integrating facial recognition with other surveillance databases and a prohibition on using facial recognition on protestors or for immigration enforcement, this legislation would make it more possible for people harmed by facial recognition to organize against it.\"\n\nOctober 2023: The Center signed onto a joint letter alongside 23 workers' rights, civil rights, and other civil society organizations calling on Senate Majority Leader Chuck Schumer to center workers and protect their rights in his efforts to address advances in artificial intelligence, such as through his \"AI Insight Forum\" series, which have to date featured a disproportionate concentration of industry representatives compared to civil society, civil rights, or workers' rights representatives. The letter presents several recommendations and calls on Senator Schumer and Congress to \"develop a new generation of economic policies and labor rights to prevent corporations like Amazon from leveraging tech-driven worker exploitation into profit and outcompeting rivals by taking the low road\".\n\nSeptember 2023: The Center on Privacy & Technology and the International Justice Clinic at UC Irvine Law co-authored a report submitted to United Nations Human Rights Committee arguing that ICE’s dragnet surveillance practices amount to an egregious violation of human rights law, and of US obligations under the ICCPR, specifically under Article 17 which guarantees the right to privacy as a fundamental human right and requires that any state interference with privacy be proscribed by a specific, accessible law, necessary to pursue a legitimate purpose, and proportionate to that purpose. Our report prompted a Human Rights Committee member (Prof. Soh) to show his concern about ICE's dragnet surveillance and asked US delegates, essentially, how the US ensures ICE's practice complies with ICCPR and when the US will legislate federal data privacy law. The Committee’s Concluding Observations on the fifth periodic report of the United States of America explicitly calls out ICE for surveillance practices that conflict with human rights law. This adds international pressure on ICE to stop dragnet surveillance.\n\nSeptember 2023: Director of Research & Advocacy Stevie Glaberson recently published an op-ed, \"It's family regulation, not a computer glitch,\" in the Arizona Daily Star. In the op-ed, Glaberson and her co-author Marshneil Lal write about the implications of the recent revelation by the Arizona Department of Child Safety that for two years, Arizona courts relied on a flawed computer system in as many as 3,800 cases to make decisions about whether Arizona should take children away from their parents. They write \"This is not just a story about a data glitch. It’s a revealing story about the \"surveillance tentacles\" of the state’s “child welfare” system, the pervasive failure of the system to listen to the people it targets, and the ways adding a layer of technology magnifies the system’s harms.\"\n\nAugust 2023: Executive Director Emily Tucker and philosopher David McNeill co-taught a virtual mini-course entitled No, We Don’t Live In A F%#*ing Simulation to 34 students exploring the simulation hypothesis, long-termism, and the imminent threat of artificial general intelligence (AGI). The course received 86 applicants coming from academia, government (globally), NGOs and non-profits (globally), law, social work, computer sciene, and private sector. The 34 students represented more than 12 countries. The Center on Privacy & Technology hopes to offer the course again.\n\nJuly 2023: Justice Fellow Meg Foster and Director of Research & Advocacy Stevie Glaberson submitted written testimony to the Massachusetts Joint Committee on Advanced Information Technology, the Internet and Cybersecurity in support of S.27, An Act to protect private electronic communication, browsing and other activity. The bill establishes warrant and reporting requirements for electronic communication and subscriber records, as well as the use of cell site simulators. It also prohibits law enforcement from requesting, and judges from granting, reverse-location and reverse-keyword requests. The testimony focused on the disparate impact that the dragnet surveillance tools and techniques regulated in S.27 have on marginalized communities, including on their First Amendment rights.\n\nJune 2023: The Center signed onto joint comments spearheaded by the Athena Coalition, submitted to the White House Office of Science and Technology Policy's Request for Information on Automated Worker Surveillance and Management. The submission, which Senior Associate Cynthia Khoo (among others) reviewed and provided feedback on, focuses on the harmful impacts of ubiquitous surveillance and punitive automated management at Amazon on its warehouse workers and delivery drivers. The comments also include a number of recommendations to the Biden-Harris administration to implement in protecting workers from continued exploitation through automated surveillance and management.\n\nJune 2023: Executive Director Emily Tucker was quoted in an article in The Intercept about ICE and LexisNexis contracts: “This is really concerning,” Emily Tucker, the executive director of Georgetown Law School’s Center on Privacy and Technology, told The Intercept. Tucker compared the contract to controversial and frequently biased predictive policing software, causing heightened alarm thanks to ICE’s use of license plate databases. “Imagine if whenever a cop used PredPol to generate a ‘hot list’ the software also generated a map of the most recent movements of any vehicle associated with each person on the hot list.”\n\nJune 2023: Executive Director Emily Tucker published an op-ed in Tech Policy Press entitled \"Our Future Inside The Fifth Column- Or, What Chatbots Are Really For\" about the corporate and capitalist goals of companies designing chatbots. Chatbots, Tucker warns, are part of a larger scheme to sow algorithmic dependence in the economic spaces most important to the public interest. “The goal is no longer to dominate crucial industries, but to convert crucial industries into owned intellectual property.”\n\nJune 2023: Distinguished Fellow Gabrielle Rejouis spoke at an LRAN workshop, \"American History, Race, Prison, and Surveillance: Atlanta’s Cop City, Extractive Economies and Amazon’s Culture of Surveillance\", presenting on the history of worker surveillance. Her presentation connected the history of surveillance to current Amazon surveillance of workers and their support of law enforcement surveillance of Black communities. The presentation drew from the research for the Color of Surveillance: Monitoring Poor and Working People.\n\nJune 2023: The Center signed onto a joint letter alongside 40 civil rights and technology policy advocacy organizations calling on the Federal Trade Commission to define discrimination as an unfair practice and to require testing of algorithmic systems for discrimination, as part of the Commission's Commercial Surveillance and Data Security Rulemaking. The letter also provided several recommendations for the FTC to develop concrete and specific protections for civil rights.\n\nJune 2023: Senior Associate Cynthia Khoo spoke on a panel at RightsCon 2023, titled, \"Reclaiming and Building Worker Power in an Age of Workplace Surveillance.\" She joined representatives from Coworker.org, TEDIC Paraguay, and other privacy and technology policy professionals. Cynthia presented on how both privacy laws and employment / labour laws fail to protect workers from surveillance and data-driven harms, and what lawyers, other advocates, and decision-makers can do to address the issue.\n\nMay 2023: Justice Fellow Meg Foster was quoted in Reason about TSA's face recognition pilot program: \"Whenever there is a power imbalance between powers, consent is not really possible,\" says Foster. \"How does TSA expect them to see and read an inconspicuous notice, let alone tell a TSA agent they want to opt out of face recognition? Especially if it may not be clear to them what the consequences of opting out will be.\"\n\nMay 2023: Justice Fellow Meg Foster spoke with CBS about the TSA face recognition pilot program: \"With regard to the TSA pilot, Foster said she has concerns that while the agency says it's not currently storing the biometric data it collects, what if that changes in the future? And while people are allowed to opt out, she said it's not fair to put the onus on harried passengers who might be worried about missing their flight if they do.\"\n\nApril 2023: Executive Director Emily Tucker and Associate Nina Wang were quoted in a Wired article revealing how ICE agents have regularly abused their access to surveillance databases, conducting unauthorized searches of exes and coworkers and on behalf of family and neighbors. The article also quotes the Center's report, American Dragnet: Data-Driven Deportation in the 21st Century, which showed that these databases enable ICE \"to pull detailed dossiers on nearly anyone, seemingly at any time.\" “All of that access to bulk data leaves the door wide open for misconduct,”said Wang.\n\nApril 2023: Executive Director Emily Tucker was quoted in WIRED for an article about ICE surveillance. Tucker said, \"I can’t help but feel that the federal government is using ICE as a data vacuum. They are looking for any way to access and integrate all kinds of data into massive databases.\"\n\nMarch 2023: The Center hosted a roundtable discussion during Georgetown's Tech Society Week previewing the Center's new interactive digital narrative Cop Out: Automation in the Criminal Legal System. The discussion featured Assia Boundaoui, journalist and filmmaker behind The Feeling of Being Watched and Inverse Surveillance Project; Nasser Eledroos, Managing Director of Northeastern Law’s Center on Law, Innovation, and Creativity; Meg Foster, Justice Fellow at the Center on Privacy & Technology; Puck Lo, Research Director at Community Justice Exchange; Freddy Martinez, Senior Researcher at Project on Government Oversight; and Paromita Shah, co-founder and Executive Director of Just Futures Law.\n\nMarch 2023: Justice Fellow Meg Foster was quoted in a Gizmodo story by Mack DeGuerin about a government face recognition program recently exposed through documents obtained by the ACLU. “While Janus may have ended, these documents demonstrate that the prevailing approach to surveillance technology is to put the cart before the horse, and given the growing number of wrongful arrests stemming from face recognition, we know that the most vulnerable among us will experience the consequences first and hardest,” Foster said.\n\nFebruary 2023: The Center signed on to a letter to the Consumer Financial Protection Bureau (CFPB) urging them to regulate the sale of \"credit header\" data, including names, addresses, and other sensitive personal information, which data brokers have purchased from sources like essential utility companies and sold to police and immigration enforcement. The letter's release was covered by WIRED.\n\nJanuary 2023: Former associate Korica Simon published a piece in a newsletter for the Initiative for a Representative First Amendment (IfRFA) at the Berkman Klein Center at Harvard University in their capacity as a former IfRFA fellow. The piece talks about new laws states have passed around abortion, the intersection the first amendment rights and whether they are constitutional.\n\nJanuary 2023: Former Center on Privacy & Technology Associates Jameson Spivack and Korica Simon co-published an article in the University of Richmond Public Interest Law Review entitled \"From Ban to Approval: What Virginia's Facial Recognition Technology Law Gets Wrong.\" The article uses Virginia’s recently passed legislation as a case study to show how legislation can fail to properly account for the harms of facial recognition technology in the law enforcement context.\n\nDecember 2022: Executive Director Emily Tucker's blog post \"Artifice and Intelligence\" was named the most-read Tech Policy Press Contributor post of 2022. The post explained why the Privacy Center decided to stop using the terms “artificial intelligence,” “AI,” and “machine learning” in its work to expose and mitigate the harms of digital technologies in the lives of individuals and communities.\n\nNovember 2022: The Center submitted a letter to the Federal Trade Commission's Advanced Notice of Proposed Rulemaking on Commercial Surveillance and Data Security, a key proceeding with the potential to establish long-needed protections from abusive business practices enabled by the mass collection of personal data. The Center's comments urged the Commission to keep three specific contexts of surveillance-fuelled harm and injustice in mind in its rulemaking determinations, namely worker surveillance, immigrant surveillance, and systems of policing and punishment.\n\nOctober 2022: Senior Associate Cynthia Khoo co-authored an op-ed in the Washington Post with Daniel Jellins, staff lawyer and clinical teaching fellow at the Communications and Technology Law Clinic at Georgetown Law. The op-ed sets out the differences between algorithmic discrimination and \"analog\" discrimination; explains why algorithmic discrimination requires legal reform to address; and calls on DC Council to pass the Stop Discrimination by Algorithms Act.\n\nOctober 2022: The Center submitted written testimony in support of the Stop Discrimination by Algorithms Act to the Council of the District of Columbia, co-authored by Senior Associate Cynthia Khoo, Associate Korica Simon, and Executive Director Emily Tucker. Their comments expanded on Khoo's oral testimony at hearing, further elaborating on the nature of algorithmic discrimination; arguing that business costs should not be weighed in prohibiting illegal discrimination; correcting industry talking points regarding technical definitions and the state of the relevant legal, policy, and research field; and urging DC Council to act now to reduce harm, rather than wait to follow potential future federal initiatives.\n\nSeptember 2022: Senior Associate Cynthia Khoo submitted oral testimony in support of the Stop Discrimination by Algorithms Act (SDAA), at a hearing held by the Committee on Government Operations and Facilities at the Council of the District of Columbia. She emphasized that algorithmic discrimination is distinct from \"analog\" discrimination and pointed out that intent is not determinative in anti-discrimination law and is often missing from the kind of sociotechnical systems that give rise to algorithmic discrimination.\n\nMay 2022: The ACLU of Illinois reached a settlement with Clearview AI on the matter of selling its faceprint databases. Last July, the Center, represented by Georgetown Law’s Civil Litigation Clinic, filed an amicus brief in the ACLU’s lawsuit, alleging violations of Illinois’ Biometric Information Privacy Act. While the lawsuit was specific to Illinois, the effects are far-reaching. It permanently bans Clearview from providing its massive faceprint database to private actors, nationwide, and bans them from providing it to law enforcement in Illinois for five years.\n\nMarch 2022: Associate Cynthia Khoo appeared before the Canadian House of Commons Standing Committee on Access to Information, Privacy and Ethics on March 21, 2022, testifying on police use of facial recognition technology based on her work as a Research Fellow at the Citizen Lab (University of Toronto). Khoo raised key concerns with facial recognition and algorithmic policing technologies, including systemic discrimination, constitutionality, transparency and accountability, and reliance of law enforcement on private sector commercial vendors.\n\nMarch 2022: The Center joined fifteen civil and digital rights groups in signing a letter and op-ed opposing law enforcement use of facial recognition technology in New Jersey. The letter highlights various harms that would result from law enforcement use of facial recognition technology, including an expansion to the over policing of Black and Brown communities.\n\nJanuary 2022: Associate Cynthia Khoo filed comments in response to the Office of Science and Technology Policy's Notice of Request for Information on Public and Private Sector Uses of Biometric Technologies. The Center's submission focused on biometric surveillance of low-wage workers, and highlighted the importance of situating biometric surveillance technologies in their full historical context through a racial justice and socioeconomic justice lens.\n\nJanuary 2022: The Community Control Over Police Surveillance Model Bill (CCOPS) was a bill supported by the Community Oversight of Surveillance coalition that would require DC entities to obtain Council approval before acquiring new surveillance technology and entities would be required to report why they wanted to use the technology and the impact it would have on civil rights and liberties. The Center on Privacy and Technology was a client of the Communications and Technology Law Clinic and asked the clinic to advocate on our behalf at coalition meetings about CCOPS.\n\nMarch 2020: Policy Associate Jameson Spivack argued in The Baltimore Sun that Maryland has one of the most invasive face recognition systems in the nation, and that it was time for the legislature to put a moratorium on police face recognition use.\n\nOctober 2019: “We’re all getting comfortable with face recognition,” Senior Associate Clare Garvie warns in a New York Times video op-ed. “But the convenience is blinding us to how risky this technology actually is, and how it is being used without us realizing.”\n\nMay 2019: Senior Associate Clare Garvie testified before the House Committee on Oversight and Reform. She argued that in the absence of regulation police use of face recognition poses risks to our First, Fourth, and Fourteenth Amendment rights. Because of those risks, a moratorium is appropriate.\n\nApril 2019: Founding Director Alvaro Bedoya delivered the U.S. Senator Dennis Chavez Endowed Lecture on Law & Civil Rights at the University of New Mexico School of Law. In his lecture, he drew upon the research underlying several Color of Surveillance conferences to argue that privacy should be considered a civil right, not just a civil liberty.\n\nApril 2019: In an blog post sent to close to half a million Twitter followers, Shahid Buttar of the Electronic Frontier Foundation promoted our founding director's Chavez lecture on the connection between privacy and civil rights. Buttar argued that the lecture, along with the Center's Color of Surveillance conference series, are \"key pieces of a growing effort to ensure that privacy and protection from surveillance are seen as part of defending civil rights.\"\n\nApril 2019: The Center's Policy Associate Jameson Spivack was interviewed and quoted in The Hill about recent legislative efforts to combat the potential discriminatory effects of AI. \"I think that any legislation needs to recognize that while these technologies affect everyone, they disproportionately affect vulnerable people.\"\n\nMarch 2019: The Center joined ACLU, EFF, and Innocence Project in filing an amicus brief in support of Willie Allen Lynch, petitioner to the Florida Supreme Court. The brief argues that the state failed in its obligation to disclose information about its use of face recognition technology to the petitioner.\n\nFebruary 2019: A federal law was signed prohibiting the use of children's information for deportation purposes until September 30, as part of the 2019 Homeland Security Appropriations Bill. The law followed a November 2018 letter, coordinated by the Center and co-signed by 111 other NGOs, calling for the termination of an interagency agreement that used children's information to find and deport their relatives.\n\nFebruary 2019: The Center signed on to a letter from 47 organizations calling on legislators to protect civil rights, equity, and equal opportunity in the digital ecosystem. The letter draws directly from the Civil Rights Principles for the Era of Big Data released in 2014 and includes a call for for fairness in automated decisions and an end to high-tech profiling.\n\nDecember 2018: Executive Director Laura Moy filed comments relevant to a planned Federal Trade Commission hearing on competition and consumer protection in the 21st Century. She argued that discriminatory data practices should not be allowed and that when consumers cannot avoid sharing their information, heightened privacy protections should apply.\n\nNovember 2018: The Center drafted, organized, and filed comments, signed by thirteen other organizations, regarding the administration's use of children's information to deport their relatives. The comments explain that deporting families using information collected to place unaccompanied children is not only inhumane, but also unlawful and poor policy.\n\nNovember 2018: The Center coordinated a letter to the Departments of Health and Human Services and Homeland Security calling for the recission of an interagency agreement that uses children's information to deport their relatives. 111 other civil rights and civil liberties organizations signed on to the letter, which received coverage in the Associated Press.\n\nNovember 2018: The Center submitted comments to the National Telecommunications and Information Administration urging the agency to move further in the direction of strong consumer protection as it defines the privacy outcomes and high-level goals that this administration will prioritize.\n\nNovember 2018: Senior Associate Clare Garvie spoke at the National Institute of Standards and Technology's first conference, on a panel about technical factors affecting the deployment and use of face recognition technology. Clare's remarks focused on the real-world consequences of differential error rates, including in the law enforcement context.\n\nOctober 2018: Executive Director Laura Moy testified about consumer privacy before the Senate Commerce Committee. She called for increased attention to commercial data practices that can lead to societal harms, such as discrimination, erosion of trust online, amplification of hate speech, and dissemination of propaganda, misinformation, and disinformation.\n\nOctober 2018: Executive Director Laura Moy testified about consumer privacy before the Senate Commerce Committee. She called for increased attention to commercial data practices that can lead to societal harms, such as discrimination, erosion of trust online, amplification of hate speech, and dissemination of propaganda, misinformation, and disinformation.\n\nOctober 2018: On October 5, 2018, a federal law was signed requiring privacy and racial bias assessments of the federal government's use of biometric technologies at airports—the first ever federal law requiring artificial intelligence bias testing. The law was enacted following the Center's December 2017 report, Not Ready For Takeoff, which found privacy and bias problems in these deployments.\n\nSeptember 2018: The Office of the Inspector General for the Department of Homeland Security conducted an audit of the agency's use of face scans at airport departure gates that closely tracked and validated many of the concerns raised in the Center's Not Ready for Takeoff report. OIG reported, among other things, that the program exhibits age bias, causes traveler delays, and may end up being far more costly than initial estimates.\n\nSeptember 2018: Executive Director Laura Moy spoke on a panel hosted by New America on police surveillance and the adoption—by a growing number of cities—of ordinances that help create opportunities for communities to exercise control over the surveillance technologies their police agencies have and use.\n\nJuly 2018: The third annual Color of Surveillance conference delved into the surveillance of religious minorities in the United States. In addition to discussions about this issue's contemporary impact, the conference featured a historian who spoke about surveillance of the Pilgrims in England.\n\nJuly 2018: The third annual Color of Surveillance conference delved into the surveillance of religious minorities in the United States. In addition to discussions about this issue's contemporary impact, the conference featured a historian who spoke about surveillance of the Pilgrims in England.\n\nJuly 2018: Senior Associate Clare Garvie wrote an op-ed for The Washington Post about how face surveillance technology risks changing our expectations of privacy, our right not to be investigated unless suspected of wrongdoing, and our freedom from deeply flawed policing practices.\n\nMay 2018: Deputy Director Laura Moy responded in Slate to a new science fiction short story by Meg Elison. In her reaction, Laura reflected on the story's themes of prejudice, outright racism, and the role of government surveillance in maintaining systems of oppression.\n\nMay 2018: After months of advocacy coordinated by the Center and others in the Immigrant Surveillance Working Group, the Department of Homeland Security formally dropped its \"Extreme Vetting Initiative.\" It would have automatically and continuously scanned American immigrants' social media posts to flag 10,000 individuals annually for deportation investigations.\n\nApril 2018: The Center co-wrote a 42-organization coalition letter to Axon's new \"AI Ethics Board.\" The letter urges the board to center the experiences of policed communities in its process, and argues that integrating face surveillance with body-worn cameras would be \"categorically unethical.\"\n\nApril 2018: For the fourth year, Georgetown Law and MIT students convened to pitch experts on the proposed privacy legislation they drafted in a course co-taught by Alvaro Bedoya, Laura Moy, and David Vladeck. The judges' panel included a state legislator, the former general counsel of the FBI, and representatives of the ACLU and the Department of Justice.\n\nMarch 2018: Citing the AI Experts Letter coordinated by the Immigrant Surveillance Working Group, the Congressional Black Caucus called on DHS to drop its \"Extreme Vetting Initiative,\" a plan to use machine learning to automatically vet American immigrants' online activities, and flag a minimum of 10,000 individuals annually for deportation investigations.\n\nDecember 2017: Senators Edward Markey (MA) and Mike Lee (UT) sent a letter urging the Department of Homeland Security to \"stop the expansion\" of its Biometric Exit program and to address privacy concerns about the program. The letter cited the Center's December 2017 report on the program, Not Ready for Takeoff, which raised many of the same concerns.\n\nDecember 2017: The Center released a report on the Department of Homeland Security's airport face scanning program, finding that the program never was justified, may violate federal law, is technically flawed, and has not been sufficiently evaluated for bias. The report recommends a suspension of the program pending correction of these problems.\n\nNovember 2017: The Center co-wrote and coordinated a letter signed by 50 computer scientists and AI specialists that called on the Department of Homeland Security to halt its planned use of machine learning to screen immigrants' social media posts. The Center also co-wrote and coordinated a letter signed by over 50 NGOs denouncing the program.\n\nNovember 2017: The Center co-wrote and coordinated a letter signed by 50 computer scientists and AI specialists that called on the Department of Homeland Security to halt its planned use of machine learning to screen immigrants' social media posts. The Center also co-wrote and coordinated a letter signed by over 50 NGOs denouncing the program.\n\nSeptember 2017: In an op-ed published in The Guardian, Clare Garvie argued that Apple’s incorporation of face recognition into the iPhone X may lead to a dangerous complacency to the risks of the pervasive deployment of the technology.\n\nJune 2017: The second annual Color of Surveillance conference examined the issue of government surveillance of American immigrants. The event encompassed historical perspectives of immigrant surveillance in the 20th and 21st Centuries and included a discussion with Professor Xiaoxing Xi, a US-based physics professor who was falsely accused of being a spy.\n\nMarch 2017: Executive Director Alvaro Bedoya testified before the House Oversight Committee about law enforcement's use of face recognition technology, with a focus on the threat the technology poses to privacy and civil rights. Chairman Jason Chaffetz (R-UT) called the hearing in direct response to the Center's October 2016 Perpetual Line-Up report.\n\nOctober 2016: The Center conducted a year-long investigation into how police use face recognition technology. The ensuing report is the most comprehensive survey to date on the topic and the risks this technology poses to privacy, civil liberties, and civil rights. It contains recommendations to police, legislators, and others, as well as a model state and federal bill that would control the use of face recognition technologies.\n\nMay 2016: Google publicly announces that it will no longer serve ads for payday loans, financial products that routinely harm low-income people, and that were being targeted to vulnerable consumers who searched for terms like \"I need money for rent\" and \"I need money for groceries.\" This comes after months of engagement with the Center, The Leadership Conference on Civil and Human Rights, Upturn, and other allies.\n\nMay 2016: Google publicly announces that it will no longer serve ads for payday loans, financial products that routinely harm low-income people, and that were being targeted to vulnerable consumers who searched for terms like \"I need money for rent\" and \"I need money for groceries.\" This comes after months of engagement with the Center, The Leadership Conference on Civil and Human Rights, Upturn, and other allies.\n\nApril 2016: The inaugural Color of Surveillance conference focused on the disproportionate amount of government surveillance on the African American community. It hosted robust conversations on the historic and current surveillance of this group, including a debate between a Pulitzer-winning MLK biographer and the general counsel of the FBI.\n\nJanuary 2016: In an essay for Slate, Executive Director Alvaro Bedoya argued that surveillance debates must reckon with \"the color of surveillance\"—the disparate impact of government monitoring. \"Across our history and to this day, people of color have been the disproportionate victims of unjust surveillance.\"\n\nDecember 2015: Clare Garvie and Founding Director Alvaro Bedoya filed a comment which examines how online lead generation creates and perpetuates the disparate impact of payday loans on African American borrowers. They urged the FTC to use its authority under ECOA and Section 5 of the FTC Act to investigate and bring enforcement actions against responsible companies."
    }
}