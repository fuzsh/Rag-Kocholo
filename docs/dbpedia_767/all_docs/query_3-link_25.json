{
    "id": "dbpedia_767_3",
    "rank": 25,
    "data": {
        "url": "https://arxiv.org/html/2312.17659v1",
        "read_more_link": "",
        "language": "en",
        "title": "Solar Radiation Prediction in the UTEQ based on Machine Learning Models",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/extracted/5322226/figures/pyranometer.jpg",
            "https://arxiv.org/html/extracted/5322226/figures/onedayradiation.png",
            "https://arxiv.org/html/extracted/5322226/figures/temp_hour_month.png",
            "https://arxiv.org/html/extracted/5322226/figures/correlationmatrix.png",
            "https://arxiv.org/html/extracted/5322226/figures/metricascomparison.jpg",
            "https://arxiv.org/html/extracted/5322226/figures/comparativemodels.png",
            "https://arxiv.org/html/extracted/5322226/figures/testing.png",
            "https://arxiv.org/html/extracted/5322226/figures/webprediction.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "License: CC BY-NC-SA 4.0\n\narXiv:2312.17659v1 [cs.LG] 29 Dec 2023\n\n\\tocauthor\n\nJordy Anchundia Troncoso, Ãngel Torres Quijije, Byron Oviedo, Cristian Zambrano-Vega\n\n11institutetext: State Technical University of Quevedo, Los RÃ­os, Ecuador\n\nDepartment of Engineering Science\n\n11email: {jordy.anchundia2018, atorres, czambrano}@uteq.edu.ec\n\n22institutetext: State Technical University of Quevedo, Los RÃ­os, Ecuador\n\nDepartment of Graduate Programs\n\n22email: boviedo@uteq.edu.ec\n\nSolar Radiation Prediction in the UTEQ based on Machine Learning Models\n\nJordy Anchundia Troncoso 11 Ãngel Torres Quijije Byron Oviedo 1122 Cristian Zambrano-Vega Corresponding author: czambrano@uteq.edu.ec11\n\nAbstract\n\nThis research explores the effectiveness of various Machine Learning (ML) models used to predicting solar radiation at the Central Campus of the State Technical University of Quevedo (UTEQ). The data was obtained from a pyranometer, strategically located in a high area of the campus. This instrument continuously recorded solar irradiance data since 2020, offering a comprehensive dataset encompassing various weather conditions and temporal variations. After a correlation analysis, temperature and the time of day were identified as the relevant meteorological variables that influenced the solar irradiance. Different machine learning algorithms such as Linear Regression, K-Nearest Neighbors, Decision Tree, and Gradient Boosting were compared using the evaluation metrics Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and the Coefficient of Determination (R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT). The study revealed that Gradient Boosting Regressor exhibited superior performance, closely followed by the Random Forest Regressor. These models effectively captured the non-linear patterns in solar radiation, as evidenced by their low MSE and high RÂ² values. With the aim of assess the performance of our ML models, we developed a web-based tool for the Solar Radiation Forecasting in the UTEQ available at http://https://solarradiationforecastinguteq.streamlit.app/. The results obtained demonstrate the effectiveness of our ML models in solar radiation prediction and contribute a practical utility in real-time solar radiation forecasting, aiding in efficient solar energy management.\n\nkeywords:\n\nSolar Radiation, Machine Learning, Forecasting, UTEQ\n\n1 Introduction\n\nThis study is significant as it not only contributes to the body of knowledge in solar radiation prediction but also demonstrates the practical application of ML in renewable energy management. The findings of this research could be instrumental in improving solar energy utilization, thereby supporting sustainable energy initiatives.\n\n2 Materials and Methods\n\n2.1 Data Collection\n\nThe data collection process was pivotal in developing an accurate predictive model for solar radiation. Primary data was obtained from a pyranometer, strategically located at the Universidad TÃ©cnica Estatal de Quevedo (UTEQ) (Fig. 1).\n\nThis instrument continuously recorded solar irradiance data since 2020, offering a comprehensive dataset encompassing various weather conditions and temporal variations. The data, sampled at 5 minutes intervals, included key parameters like solar radiation intensity and ambient temperature. To ensure data integrity, regular maintenance checks were conducted on the pyranometer, and anomalous readings were flagged for review.\n\n2.2 Data Description\n\nThe dataset primarily consisted of data measured by a pyranometer every 5 minutes. The key fields included:\n\nâ€¢\n\nSolar Irradiance: Quantitative, continuous data representing the solar radiation intensity, it is recorded in watts per square metre (W/mÂ²) units.\n\nâ€¢\n\nAmbient Temperature: Quantitative, continuous data indicating the surrounding air temperature in Kelvin (K).\n\nâ€¢\n\nTime Stamp: Qualitative, nominal data recording the date and time of each measurement.\n\nThe Month, Time of day and seasonality were extracted from the time stamp field to enhance the modelâ€™s predictive accuracy. The datasetâ€™s temporal range spanned from 2020 to the present, offering a rich historical perspective on solar rad patterns under varying weather conditions. The dataset is summarized in the following Table 1:\n\n2.3 Data Visualization\n\nThe Figure 2 illustrates the solar radiation measured throughout the day on May 2, 2020. The horizontal axis denotes the time of the day, and the vertical axis represents irradiance in W/m2ğ‘Šsuperscriptğ‘š2W/m^{2}italic_W / italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. Data points color and size depicting the average temperature in Kelvin per hour. Shades and sizes progress from light and small for cooler temperatures to dark and large for warmer temperatures, respectively, providing insights into the diurnal variation of solar irradiance and ambient temperature.\n\nThe Figure 3 represents the average hourly temperature for each month, as indicated by the color intensity. The horizontal axis lists the hours in a day, from 0 to 23, and the vertical axis enumerates the months. The gradation of colors, from light to dark, denotes the increase in temperature, measured in degrees Celsius. Notably, the map reveals that temperatures at midday during winter months are comparably high to day and night temperatures in other seasons, offering a clear depiction of temporal thermal patterns.\n\n2.4 Variables Selection\n\nThe correlation analysis conducted on the dataset reveals several key insights into the relationships between solar irradiance and other measured variables. The heatmap of the correlation matrix, as depicted in Figure 4, illustrates these relationships comprehensively.\n\nThe highest positive correlation observed with Irradiance is with Temperature, which has a coefficient of 0.76. This strong correlation suggests that as the temperature increases, there is a concomitant and substantial increase in Irradiance. Hence, Temperature is selected as a primary variable for predicting Solar Radiation due to its strong linear relationship. Conversely, the variable Time of Day has a relatively lower positive correlation with Irradiance, indicated by a coefficient of 0.13. Although this positive correlation is present, it is considerably weaker, suggesting that the time of day, while relevant, is not as strongly predictive of Solar Radiation levels as Temperature is. This analysis forms the basis for selecting the most influential variables for the predictive model. The strong correlation of temperature and time of day with solar radiation underlines their importance in forecasting solar radiation levels at UTEQ.\n\n2.5 Machine Learning Algorithms\n\nWith the aim of choose the best algorithm to build our predictive model, a comprehensive comparative analysis was conducted using various machine learning algorithms. The algorithms included were: Linear Regression, a basic predictive analysis algorithm focusing on the linear relationship between dependent and independent variables [1]; Polynomial Regression, an extension of linear regression, which models a non-linear relationship between the dependent and independent variables [2]; K-Nearest Neighbors (KNN), a non-parametric method used for regression and classification tasks [3]; Decision Tree Regressor, which models decisions and their possible consequences as a tree-like structure [4]; Support Vector Regression (SVR) with both Linear and Radial Basis Function (RBF) kernels, a powerful technique derived from Support Vector Machines (SVM) for regression tasks [5]; Random Forest Regressor, an ensemble learning method based on decision tree algorithms [6]; and Gradient Boosting Regressor, an ensemble technique that builds models sequentially to minimize the loss function [7]. These models were evaluated to determine the most effective approach for predicting solar radiation levels at UTEQ.\n\n2.6 Configuration of the Machine Learning Algorithms\n\nIn our analysis, we employed various machine learning algorithms, each with specific parameters, either set explicitly or left as default. The parameters for each algorithm are as follows:\n\nâ€¢\n\nLinear Regression: The LinearRegression algorithm was used with its default parameters, which include ordinary least squares fitting.\n\nâ€¢\n\nPolynomial Regression: PolynomialFeatures with a degree of 2 was applied, enhancing the algorithm to capture non-linear relationships by raising input features to the specified degree.\n\nâ€¢\n\nK-Nearest Neighbors: The KNeighborsRegressor was configured with algorithm=â€˜autoâ€™, which automatically chooses the appropriate algorithm based on the input data, metric=â€˜euclideanâ€™ for Euclidean distance measurement, weights=â€˜distanceâ€™ to weight points by the inverse of their distance, and n_neighbors=10 to consider the 10 nearest neighbors.\n\nâ€¢\n\nDecision Tree Regressor: This algorithm used DecisionTreeRegressor with max_depth=3, limiting the depth of the tree to 3, and random_state=42 for reproducibility of results.\n\nâ€¢\n\nSVR Kernel Lineal: The SVR algorithm with a kernel=â€˜linearâ€™ was used, which applies a linear kernel function in Support Vector Regression.\n\nâ€¢\n\nSVR Kernel RBF: Here, SVR was used with kernel=â€˜polyâ€™, employing a polynomial kernel function.\n\nâ€¢\n\nRandom Forest Regressor: The RandomForestRegressor was applied with n_estimators=100, setting the number of trees in the forest to 100, and random_state=42 for consistent results across runs.\n\nâ€¢\n\nGradient Boosting Regressor: For this algorithm, GradientBoostingRegressor was used with n_estimators=100 to define the number of boosting stages, learning_rate=0.2 to control the contribution of each tree, random_state=42 for reproducibility, and max_depth=5 to set the maximum depth of the individual regression estimators.\n\n2.7 Evaluation Metrics\n\nTo assess the performance of the built machine learning models in predicting solar radiation levels, the following evaluation metrics were applied:\n\nâ€¢\n\nMean Squared Error (MSE): It measures the average of the squares of the errors or deviations, that is, the difference between the estimator and what is estimated [8]. The MSE is calculated as:\n\nMâ¢Sâ¢E=1nâ¢âˆ‘i=1n(Yiâˆ’Y^i)2ğ‘€ğ‘†ğ¸1ğ‘›superscriptsubscriptğ‘–1ğ‘›superscriptsubscriptğ‘Œğ‘–subscript^ğ‘Œğ‘–2MSE=\\frac{1}{n}\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2}italic_M italic_S italic_E = divide start_ARG 1 end_ARG start_ARG italic_n end_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT (1)\n\nwhere Yisubscriptğ‘Œğ‘–Y_{i}italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the observed value and Y^isubscript^ğ‘Œğ‘–\\hat{Y}_{i}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the predicted value.\n\nâ€¢\n\nRoot Mean Squared Error (RMSE): It is the square root of the mean square error. The RMSE is a measure of the differences between values predicted by a model and the values observed [9]. It is given by:\n\nRâ¢Mâ¢Sâ¢E=Mâ¢Sâ¢Eğ‘…ğ‘€ğ‘†ğ¸ğ‘€ğ‘†ğ¸RMSE=\\sqrt{MSE}italic_R italic_M italic_S italic_E = square-root start_ARG italic_M italic_S italic_E end_ARG (2)\n\nâ€¢\n\nMean Absolute Error (MAE): This metric summarizes the average magnitude of the errors in a set of predictions, without considering their direction [8]. Itâ€™s calculated as:\n\nMâ¢Aâ¢E=1nâ¢âˆ‘i=1n|Yiâˆ’Y^i|ğ‘€ğ´ğ¸1ğ‘›superscriptsubscriptğ‘–1ğ‘›subscriptğ‘Œğ‘–subscript^ğ‘Œğ‘–MAE=\\frac{1}{n}\\sum_{i=1}^{n}|Y_{i}-\\hat{Y}_{i}|italic_M italic_A italic_E = divide start_ARG 1 end_ARG start_ARG italic_n end_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT | italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | (3)\n\nâ€¢\n\nCoefficient of Determination (R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT): This metric provides an indication of the goodness of fit of a set of predictions to the actual values. In other words, it indicates how well unseen samples are likely to be predicted by the model [10]. The R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT score is calculated as:\n\nR2=1âˆ’âˆ‘i=1n(Yiâˆ’Y^i)2âˆ‘i=1n(Yiâˆ’YÂ¯)2superscriptğ‘…21superscriptsubscriptğ‘–1ğ‘›superscriptsubscriptğ‘Œğ‘–subscript^ğ‘Œğ‘–2superscriptsubscriptğ‘–1ğ‘›superscriptsubscriptğ‘Œğ‘–Â¯ğ‘Œ2R^{2}=1-\\frac{\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2}}{\\sum_{i=1}^{n}(Y_{i}-\\bar% {Y})^{2}}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 1 - divide start_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - overÂ¯ start_ARG italic_Y end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG (4)\n\nwhere YÂ¯Â¯ğ‘Œ\\bar{Y}overÂ¯ start_ARG italic_Y end_ARG is the mean of the observed data.\n\nThese metrics are essential for evaluating and comparing the accuracy and effectiveness of different predictive models.\n\n3 Results\n\n3.1 Machine Learning Models Evaluation\n\nThe Table 2 shows the results of the comparative analysis of machine learning models for predicting solar radiation, demonstrate a range of performances as measured by the Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and the Coefficient of Determination (R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT).\n\nIn the Figure 5 the performance of each model is marked by a green dot, allowing for a visual comparison of their predictive accuracy and fit.\n\nThe Linear Regression model exhibits a moderate level of accuracy with an R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of 0.60, suggesting that approximately 60% of the variance in the radiation data is predictable from the model. However, its higher MSE and RMSE values indicate a greater average error in the predictions. Polynomial Regression shows an improvement over Linear Regression, with a lower MSE and a higher R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of 0.70, which implies a better fit to the data and the modelâ€™s ability to capture more complex relationships. K-Nearest Neighbors (KNN) achieves an even lower MSE and the highest R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT value among the first three models, reflecting its capability to closely predict the actual values. The localized nature of KNN likely contributes to its relatively high accuracy. Decision Tree Regressor offers a balance between complexity and interpretability, resulting in a decent R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of 0.68, but not outperforming KNN in terms of error metrics. SVR with a Linear Kernel and SVR with a Polynomial Kernel (RBF) struggle with this dataset, as indicated by their higher MSE and lower R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT values, especially the SVR with RBF kernel, which has the highest errors and lowest R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT value of 0.44, suggesting a poor fit. Random Forest and Gradient Boosting Regressors show the best performance among all the models, with the lowest MSE and RMSE values and the highest R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT values of 0.74 and 0.72, respectively. These ensemble methods, known for their high accuracy, confirm their effectiveness in the task of solar radiation prediction.\n\n3.2 Performance of the Solar Radiation Prediction\n\nThe comparative analysis of machine learning models for predicting solar radiation reveals varying degrees of accuracy and predictive performance. As illustrated in the scatter plots (see Figure 6), Linear Regression and SVR with Linear Kernel show a broader dispersion of predicted values from the actual measurements, resulting in lower R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT values of 0.60 and 0.56, respectively, and higher MSE, indicating a less precise fit to the data. Polynomial Regression and Decision Tree Regressor improve upon these metrics with R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT values of 0.70 and 0.68, respectively, suggesting a better but still not optimal fit. The K-Nearest Neighbors model exhibits a tighter cluster of predictions around the actual values with an R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of 0.73, indicating a good fit to the data. However, the Random Forest and Gradient Boosting models outperform the others with the highest R2superscriptğ‘…2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT values of 0.74 and 0.76, respectively. These models not only have a tighter clustering of predictions but also the lowest MSE, indicating a superior predictive performance.\n\nThe scatter plots in Figure 7 provide a visual comparison between actual and predicted solar radiation levels for a specific day, May 2nd, 2020.\n\nThe Polynomial Regression, K-Nearest Neighbors (KNN), Random Forest Regressor, and Gradient Boosting Regressor models were evaluated. The actual measurements are marked in black and the predictions in red, with the dot sizes indicating varying temperatures. It is observed that the Random Forest and Gradient Boosting models closely align with the actual data, especially during peak radiation hours, suggesting their higher efficacy in capturing the non-linear patterns associated with solar radiation. The slight discrepancies noted in the Polynomial Regression and KNN predictions during peak hours warrant further investigation and potential model refinement for improved accuracy.\n\n3.3 Interactive tool for Solar Radiation Forecasting\n\nWith the aim of provide an easy tool to assess the performance of the built Machine Learning models, we have developed an interactive web application for solar radiation forecasting, available at https://solarradiationforecastinguteq.streamlit.app/, offers real-time predictions based on temperature forecasts from the Meteosource API (https://www.meteosource.com/). It features a user-friendly interface that allows the selection of the best-performing models as identified in our comparative analysis: Polynomial Regression, K-Nearest Neighbors, Random Forest Regressor, and Gradient Boosting Regressor.\n\nThe Figure 8 shows the main dashboard, it provides a current forecast snapshot, displaying the temperature and predicted solar radiation at a specific time, alongside a graphical representation of the 24-hour forecast. The plots illustrate the predictions against the actual solar radiation data, with the modelsâ€™ performance visible through the close alignment of predicted (in red) and actual (in black) values. The integration of temperature data as dot sizes in the scatter plots offers an intuitive understanding of the relationship between temperature and solar radiation levels throughout the day.\n\n4 Conclusions and Future Works\n\nThis study demonstrated the viability of using machine learning models for predicting solar radiation at UTEQ. Among the models tested, Gradient Boosting Regressor exhibited superior performance, closely followed by the Random Forest Regressor. These models effectively captured the non-linear patterns in solar radiation, as evidenced by their low MSE and high RÂ² values. The integration of these models into a user-friendly web application underscores their practical utility in real-time solar radiation forecasting, aiding in efficient solar energy management.\n\nFuture research should focus on enhancing the accuracy of the predictive models further. This could involve exploring more sophisticated machine learning algorithms or deep learning techniques. Additionally, integrating a larger dataset with more diverse environmental variables could provide a more comprehensive understanding of the factors influencing solar radiation. Another promising avenue is the application of these models in other geographical locations to validate their generalizability and effectiveness. Finally, real-world implementation and feedback will be crucial in refining the models and maximizing their utility in practical applications.\n\nReferences\n\n[1] Montgomery, D.C., Peck, E.A., Vining, G.G.: Introduction to Linear Regression Analysis. John Wiley & Sons (2021)\n\n[2] Seber, G.A., Lee, A.J.: Linear Regression Analysis, vol. 329. John Wiley & Sons (2012)\n\n[3] Altman, N.S.: An introduction to kernel and nearest-neighbor nonparametric regression. The American Statistician 46(3), 175â€“185 (1992)\n\n[4] Breiman, L., Friedman, J., Olshen, R., Stone, C.: Classification and Regression Trees. CRC press (1984)\n\n[5] Drucker, H., Burges, C.J., Kaufman, L., Smola, A., Vapnik, V.: Support vector regression machines. Advances in neural information processing systems pp. 155â€“161 (1997)\n\n[6] Breiman, L.: Random forests. Machine learning 45(1), 5â€“32 (2001)\n\n[7] Friedman, J.H.: Greedy function approximation: a gradient boosting machine. Annals of statistics pp. 1189â€“1232 (2001)\n\n[8] Willmott, C.J., Matsuura, K.: Advantages of the mean absolute error (mae) over the root mean square error (rmse) in assessing average model performance. Climate research 30(1), 79â€“82 (2005)\n\n[9] Chai, T., Draxler, R.R.: Root mean square error (rmse) or mean absolute error (mae)? â€“ arguments against avoiding rmse in the literature. Geoscientific Model Development 7(3), 1247â€“1250 (2014)\n\n[10] James, G., Witten, D., Hastie, T., Tibshirani, R.: An Introduction to Statistical Learning. Springer (2013)"
    }
}