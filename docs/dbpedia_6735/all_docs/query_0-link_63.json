{
    "id": "dbpedia_6735_0",
    "rank": 63,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/",
        "read_more_link": "",
        "language": "en",
        "title": "Defining requirements for integrating information between design, manufacturing, and inspection",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-nistpa.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0001.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0002.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0004.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0005.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0006.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0007.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0008.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0009.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0010.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0011.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0012.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/bin/nihms-1918232-f0003.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "T. D. Hedberg",
            "M. E. Sharp",
            "T. M. M. Maw",
            "M. M. Helu",
            "M. M. Rahman",
            "S. Jadhav",
            "J. J. Whicker",
            "A. Barnard Feeney"
        ],
        "publish_date": "2022-08-29T00:00:00",
        "summary": "",
        "meta_description": "Industry desires a digital thread of information that aligns as-designed, as-planned, as-executed, and as-inspected viewpoints. An experiment was conducted to test selected open data standards’ ability to integrate the lifecycle stages of engineering ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11167730/",
        "text": "1. Introduction\n\nTo better understand and address the challenges faced in linking all stages of a manufacturing and design process, an investigative fabrication process was designed and enacted as part of a collaboration between the National Institute of Standards and Technology (NIST) and The Manufacturing Technology Centre (MTC). This collaboration sought to test selected open standards’ ability to integrate the lifecycle stages of engineering design, manufacturing, and quality assurance through a thorough implementation of a small scale model-based enterprise (MBE). Lessons learned through this exercise have been recorded and digested in such a manner as to both inform further development of standards as well as encourage the adoption of the most useful and effective existing standards. In this paper, the primary standards of interest are ASME Y14.41, ASME Y14.47, ISO 16792, ISO 10303–242, MTConnect, and ANSI/DMSC Quality Information Framework (QIF). The activities and results of the collaboration are described in this paper. The work of this collaboration builds upon past work and introduces novel contributions with studying a standards-based information integration from multiple sources using automatic data-alignment strategies.\n\nAt the onset, the most fundamental question and goal of this work was to understand the capabilities and limitations of implementing a standards-based information integration throughout the lifecycle of a product. From design, through production, and final inspections, what are the hurdles that a manufacturer would face during the development of a fully linked and integrated information chain? How can these obstacles be overcome or mitigated? What benefits or incentives can be gained from tracing or linking information through multiple stages of a product lifecycle - thus, creating a “digital thread” across the lifecycle? A digital thread is an integrated information flow that connects all the phases of the product lifecycle using accepted authoritative data sources (Kraft 2016; Hedberg Jr et al. 2016; Wardhani and Xu 2016). The digital thread focuses on integrating all phases of the product lifecycle for making efficient and effective measurements of the lifecycle in support of data-driven methods (Hedberg, Bajaj, and Camelio 2020).\n\nWhile we explored the research questions around the goals of this work, the results of our research point to the reality that a standards-based information integration in not achievable today because the standards do not data-alignment strategies without significant human intervention. Our results show that the popular data standards used in industry do not support automatic data alignment. Therefore, instead of documenting implementation schemes, we provide recommendations to the Standards Development Organizations (SDOs) for enhancing the standards that we expect would enable automatic data-alignment capabilities. We also expect that once automatic data-alignment capabilities are realized, researchers should then be able to discover methods for implementing and transferring standards-based information integration to practice.\n\n3. Methodology\n\nThe goal of this work is to explore and quantify the capabilities of integrating data and information between design, manufacturing, and inspection. As part of this, a secondary effort focused on identifying key process variables for determining optimal manufacturing parameters. MTC played the role of an original equipment manufacturer (OEM) and NIST played the role of a contracted design house and manufacturer. The test case was an assembly designed with input from both parties and was manufactured at NIST. Each component of the assembly also underwent a first-article inspection and 100 percent inspections at NIST. Data was collected at each step in the workflow - STEP AP242 and NC Code sheets for design information, MTConnect from manufacturing data, and QIF for quality data. The assembly components were then shipped to MTC, where an incoming and receiving inspection was conducted. The aim in this process was to determine the ability to effectively and efficiently integrate the data collected throughout this process.\n\nThe success criteria was identified as the ability to automatically align the features and characteristics across each data set. ASME Y14.5–2009 (American Society of Mechanical Engineers 2009) standard defines a feature as “a physical portion of a part such as a surface, pin, hole, or slot or its representation on drawings in models, or in digital data files.” ANSI/QIF Part 1–2015 (Digital Metrology Standards Consortium 2018) standard defines a characteristic as “a control placed on an element of a feature such as its size, location or form, which may be a specification limit, a nominal with tolerance, a feature control frame, or some other numerical or non-numerical control.” A design of experiments (DOE) is leveraged to induce variability in one of the parts in a structure. The DOE should enable linking any variability to its source. Any linking requires aligning data about the features and characteristics.\n\nOur work builds on the previous studies, but includes some novel additions. First, our work is the first investigation that used an assembly in the experiments. Reviewing the literature, all past model-based studies used single components as their test cases. Studying an assembly introduces a more realistic level of product complexity. Industry applies tolerances to features in definition of product components because those components must fit together in an assembly to realize the product. Studying only the data of a single component does not provide the full context in the overall quality of the assembly. Therefore, industry must review the quality of all components of a product and the relationship of each component to the assembly for understanding the quality of the product.\n\nSecond, our study tests data integration from multiple sources. The design and QIF data come from multiple vendors, suppliers, and tools. Collecting and integrating data from multiple sources is closer to a real MBE supply chain. More closely matching a real supply chain is a significant enhancement over previous work.\n\n3.1. Design of the Digital Assembly Definition\n\nTest cases from the NIST “MBE PMI Validation and Conformance Testing Project” (Lipman et al. 2017) were the starting point for the design of the assembly used in our study. Specifically, we used Fully-Toleranced Test Cases (FTC) 7 (box), 8 (lid), and 9 (mounting plate) (Lipman 2017). The decision to start with the FTC models was because these models had already undergone expert review and were designed to be an assembly. This minimized the time required to develop a valid assembly for our work.\n\nWhile we started with three models, we did make a few changes to ensure the assembly would meet all the needs of our study. First, we scaled down the original size of the designs to reduce the cost of the manufacturing step by allowing us to utilize a smaller 3-axis mill that had time available in its production schedule. Second, we added some additional features to all of the parts to increase the diversity of the types of characteristics. Lastly, we converted each design to standard metric units since the original designs used imperial units.\n\nThe complete assembly is comprised of the box, lid, and mounting plate, derived from the FTCs, an acrylic window to mount in the lid, and standard hardware procured through a third-party. All data from the work presented here, including the CAD models, are available in a published data set from Hedberg Jr et al. (2018).\n\nNo two-dimensional (2D) drawings were produced for the assembly or its components. All the product definition was included as product and manufacturing information (PMI) in the 3D CAD model. PMI included the typical information included historically on a 2D drawing, including dimensions, tolerances, and notes. PMI, in models, also includes meta-data stored as model attributes. Embedding the PMI in the CAD model enables shorter planning cycles in both manufacturing and inspection. For example, the inspection planner can use tools that read the characteristics’ requirements directly from the model. This eliminates the need for manual, human- based data entry, which also reduces the risk of injecting errors into the process. Also, PMI added to the model, in accordance with the ASME Y14.41–2012 (American Society of Mechanical Engineers 2012) standard1, will provide additional functionality to the user - the features associated with the PMI will highlight when selected by the user. 3D geometry combined with PMI provides a rich set of capabilities where both a computer and a human have interpretable information available for consuming the digital product definition in a process.\n\n3.2. Design of Experiments for Manufacturing Parameters\n\nThe influence of machining-process parameters on the quality of the final product is a complicated problem to model. Rather than modeling the problem, a DOE was proposed to control the parameters of data that would allow for the identification of strong correlations of machining parameters for this particular case. The experiment focused on the 16 hole features on the plate within our assembly.\n\nWe wanted to analyze the form error of the manufacturing process above the noise in the machining (and measurement) process. We decided not to make entirely identical parts as this would likely only achieve one single manufacturing signature type and background noise. The process parameters were changed sufficiently to distort the parts above the noise level and produce multiple manufacturing-signature types. The aim was to understand how much these process parameters affect variation in the part.\n\nTool length, tool speed, and feed rate were the three parameters chosen to be controlled for pocketing processes during the experiment to produce variation in the quality of the part. These parameters were identified as being the ones that are commonly varied in machining to modify the part. Initial values were specified at the recommended settings for given tools and component material. Each variable then had either one or two varied states to induce part variation. The variations were controlled to ensure the full parameter space is covered systematically rather than varying parameters based on a random choice. shows the DOE matrix, where “*” markers indicate the mean value between maximum and minimum manufacturer recommended values. Additional labels indicate the varied states of the respective parameter.\n\nTable 1.\n\nPart NumberTool LengthCutting SpeedFeed Rate01Short*Fast*High*02Short*Fast*Medium03Short*Fast*Low04Short*MediumHigh*05Short*MediumMedium06Short*MediumLow07Short*SlowHigh*08Short*SlowMedium09Short*SlowLow10LongFast*High*11LongFast*Medium12LongFast*Low13LongMediumHigh*14LongMediumMedium15LongMediumLow16LongSlowHigh*17LongSlowMedium18LongSlowLow19Operator’s ChoiceOperator’s ChoiceOperator’s Choice20Operator’s ChoiceOperator’s ChoiceOperator’s Choice\n\nThe DOE approach provided a reduced number of parameter sets and reduced number of variants of each control parameter. Confidence in the results and the repeatability of the process would come from analysis of the quality of the holes as a group.\n\nMason, Rahman, and Maw (2017) showed that the tool length, tool speed, and feed rate are critical variables within the drilling of holes in mild steel components. Understanding the sensitivity of each control parameter with regard to how much effect its variation has on the final part made of aluminum, relied on expert knowledge of the machining specialists. The values used for each tool used for the manufacture of these parts can be found in .\n\nTable 2.\n\nTool NameTool LengthCutting SpeedFeed RateShort*LongFast*MediumSlowHigh*MediumLowInchesRevolutions Per MinuteInches Per Minute0.093 inch\n\nEnd Mill0.375*1.37512k*9k6k36*27210.125 inch\n\nEnd Mill0.375*1.37512k*9k6k36*27210.25 inch\n\nEnd Mill0.5*1.512k*9k6k140*110800.5 inch\n\nEnd Mill0.75*1.7512k*9k6k140*110800.5 inch\n\nCounter Sink1.0*2.01k*0.75k0.5k2*1.513.0 inch\n\nFace Milln/an/a5k*3.75k2k120*90600.125 inch\n\nEngrave0.375*1.37512k*9k6k40*3020\n\nA new cutting edge was to be used at the start of every component such that tool wear can be reduced and monitored. Temperature and humidity readings were recorded at the start of production for each component. Fixturing was only done once after the initial material-preparation phase was completed. All subsequent machining operations were performed in-station to minimize alignment errors.\n\n3.3. Manufacturing and Inspection Planning and Execution\n\nBoth manufacturing and inspection planning were completed using model-based methods. We used commercially available software to program the fabrication and inspection programs. The various software packages were selected for their “off-the-shelf” support of the QIF standard and required no customization.\n\nThe CAD models were imported directly into the planning software with each model’s PMI utilized to the fullest extent supported by the software packages. The fabrication program’s paths and tooling selections were automatically determined by the CAM software when possible, but the majority of the decisions were made by the machining specialist based off his experience and knowledge. A numerical control (NC) program was generated and post-processed for the 3-axis mill fabricating the parts. Machine and process data was captured during the program run using MTConnect-compliant adapters and agents.\n\nFor the inspection, the NIST coordinate-measurement machine (CMM) was programmed automatically using the CMM manufacturer’s programming tool. The programming tool read the characteristics directly from the CAD model’s PMI, determined the needed CMM-probe configurations, and generated an execution-time optimized inspection program. The time to generate the first-article inspection programs for each part took less than ten minutes per part. The measurements and inspection results were captured in a database in real-time and then exported as QIF Results at the completion of the inspection.\n\nThe MTC CMM was a different manufacturer from the NIST CMM. The MTC CMM was programmed using a combination of third-party software package and the Dimensional Measuring Interface Standard (DMIS) for execution. The CAD model was translated into QIF MBD and imported into the third-party software. The software automatically read the PMI, recognized the features and characteristics for inspection, set datum structures, and assigned both a lightweight point strategy and simple scan strategies to the features. The CMM program was exported to DMIS 5.2 for execution on the CMM. The measurements were exported from the CMM manufacturer’s software to a DMIS .out file. The DMIS measurements file was imported to the third-party software and the inspection results were exported as QIF Results.\n\n3.4. Data and Information Flow\n\nIntegrating data from different sources is critical to extract information and knowledge which contains links between the manufacturing parameters and the final quality of features on the part. For example, to draw a link between the part quality and machining parameters at a specific time, it is necessary to obtain both measurement data (in QIF format) and machine parameters (encoded in the machine’s G-Code) in the same format to carry out further operations. Once this has been carried out it is also imperative that the integrated data is stored in a format that is easily readable by the software carrying out data mining. The format of the final information in the knowledge base must be easily readable by both humans and machines; a format such as comma-separated value (CSV) is most appropriate as this is easily read by commonly used data analysis software such as Microsoft Excel, Matlab, R, Python and any other analytics tools.\n\nAn important element of the data flow is the monitoring and collecting of NC-Code execution data from the CNC machine using an MTConnect adapter. This data contains in-process measurements of important machining parameters including feed rate and tool-rotation speed. By converting this to simulated G-Code, it is possible to determine the machine parameters at a given time. This level of traceability is essential to any data-manipulation operations as it enables data mapping to be carried out.\n\nThis traceability also gives a mechanism to make comparisons between the predefined parameters such as tool length, tool speed, and feed rate specified in the machine’s code and the actual values of these parameters recorded in-process. Part quality could then be linked to both the parameters specified to the machine and the true values of these parameters as measured in process. This step is currently being investigated further as the tools to perform such an action are not available. Development of such tools is an important step to automate the process and enable data analytics for the extraction of knowledge.\n\nillustrates the data flow throughout the data capture stages, including the different sources of data and the different standards which these data fall under. MTConnectR, a package within the R high-level programming language designed for statistical analysis (Joseph et al. 2017), was used to convert the extracted process data from the CNC machine code to the MTConnect XML format. The specific machine tool used to produce the parts did not report tool-path positions. Therefore, the MTConnectR package was also used to simulate the tool-path position and align it to the collected execution data using a dynamic time warping method (Helu, Joseph, and Hedberg 2018). The resulting data output and alignment from the MTConnectR package provided a structured dataset that was used in the data-mining portions of the study.\n\n4. Results\n\nAll of the data collected in this study is available in Hedberg Jr et al. (2018). The analysis of the produced parts centered around relating the machining input parameter specifications to the end quality measurements. The specific design features from each part could not be autonomously aligned with the recorded QIF tests due to inconsistent naming conventions between the separate sources of information. Despite this, there is much that can be learned from the analysis of the quality features for each of the separate parts produced.\n\n4.1. QIF Results\n\nDuring the course of this work a total of 20 assembled units were machined with QIF test results taken on each of the manufactured units. Of the three parts of the assembly, the Box exhibited zero quality test failures, the Cover showed one, and the Plate returned a total of 51 failed tests across the 20 units manufactured. From the results listed in , we can see that although the Plate had the most quality test failures (deviations found to be beyond the specified tolerances), the Box had the highest average deviation from nominal across all tests.\n\nTable 3.\n\nAssembly ItemFailed TestsMean % Deviation From NominalNumber of QIF TestsUnits TestedBox033.74%4718Cover112.46%2720Plate5133.63%3120\n\nTo some degree, the failures within the Plates were expected as the machining parameters were varied beyond recommended values to help correlate them to resulting quality. However, as seen in the quality results from the Box units show a strong bi-modal distribution for many of the captured test, with 14 of the 47 tests showing strong tendencies to be at the lower end of the allowable tolerance values. Almost all of these poor test results relate to the positioning of the respective feature. As the large deviations from nominal are consistent across all the units tested, the poor quality issues could be a result of bad tolerance selection, inadequate machining capabilities, or some other mis-specification of the machining parameters. By monitoring for such anomalous quality behavior despite a lack of failures, an investigation could be triggered to not only help trace down the problem, but perhaps suggest a solution.\n\nConversely, the test performance for the 20 Cover units was very strong across nearly all tests. Of the 27 individual quality tests performed, only one showed deviations more than approximately 10 percent from nominal, and the large majority less the five percent. Of those tests found to show large deviations, only one exhibited a grouping largely not centered near nominal. Strangely perhaps, the test with the worst average deviation did not produce a failure. Again, such anomalies can be monitored and trigger deeper investigations. A full description of the Cover QIF results can be found in .\n\nThe quality test deviations in the Plate units show a stark increase in the number of failures compared to those found in the other assembly parts, particularly in six of the total 20 Plate units tested. shows very clearly that the units labeled 10–18 have a clear increase in the average quality deviation and number of failures. Not coincidentally, this corresponds to the parts listed in as using the “Long” tool lengths. A more detailed analysis matching machining parameters to quality within the Plate units is presented in the next section.\n\nA very notable test failure is the “Cylinder 3 Radius 1” test (see ). All 20 of the manufactured units failed this test regardless of the various machining parameters employed during the manufacturing. This lends highly to the supposition that the error is derived from some requirement of the design. This could be a tolerance mis-specification, a feature that is not obtainable with the current plant machinery, etc. By directly linking the feature identified with this test to a design side feature, quick investigations into alterations can be created early in test production runs of new products.\n\nIt is interesting to note that all three assembly structures exhibited some of their worst quality test performance in tests relating feature position, perpendicularity, and flatness. this could indicate a shortcoming of the tolerancing, the ability of machines themselves to produce these features, or in the equipment used to measure these tests. Given that the respective units were produced on multiple machines with different manufacturers, this would tend to indicate either incorrect tolerancing or testing ability. Directed and coordinated analysis of quality data across multiple parts, can help to identify larger anomalies that might not be apparent when focusing on singular unit quality test results.\n\n4.2. Machining Parameter Analysis\n\nFor the 20 manufactured Plate units, the machining parameters were varied as prescribed in . As can be seen in , nearly half of the units exhibit a marked increase of the average deviation from nominal in the QIF recorded tests. These deviations can be directly correlated with the machining parameters chosen to direct the production of each unit.\n\nFor this analysis, an aggregation of the relative and actual values for these parameters is interpreted directly from the respective NC-Code input files. The exception to this is any reference to “Tool Length,” which is not directly recorded in the standard NC-Code file format. shows the calculated differences between the 20 Plate manufacturing input files. Please note that the files for units 7 and 16, as well as those for 6 and 15 are functionally identical. The only notable difference between these plates is the selection of the tool length, which is recorded external to the NC-File. The parameters collected to compare the machining of these parts were those that related to the spatial cutting path of the tool (X, Y, Z, I, J, K), the cutting speed (S), the feed rate (F), as well as preparatory commands and other miscellaneous inputs (G, M, H). Although this work is limited to 11 parameters within the NC-Code, for broader scale operations the analysis could be extended to all possible parameter inputs of NC-Code.\n\nTo characterize the relationships between the quality and the input machining parameters for these Plates, explicit interpretations of the input NC-Code is not needed. Instead, characterizations of the various parameter sequences were developed and compared on a relative scale. Ultimately, the selection of this characterization is somewhat arbitrary and matters only in its ability to capture the relative meaningful differences between the files. Towards this end, those parameters relating similar aspects of the machining process have been averaged together to allow a more meaningful interpretation of the results.\n\nWhen looking for machining parameters that have the biggest effect on the quality of a part, a correlation analysis can quickly reveal strong trends. shows the average correlation between the various selected machining parameters and the recorded quality test results. Based on the upper plot, selection of Tool Length is the most important parameter, closely followed by the Cutting Speed. Somewhat intuitively, but also highlighted by the lower plot of , the influence of Cutting Speed on quality is greatly influenced and exacerbated by Tool Length selection. This can be extrapolated to infer that parameter selection is not a one to one influence on the part quality; a confluence of various parameters can have complex end effects on the part quality.\n\nDespite noting that the effects of selecting one parameter may have influence over the effects of others, simple trends can easily be identified in analyses and be used to infer a quasi-optimal set of machining parameters; particularly if more in depth characterization of the NC-Code inputs and variations are made. Even when removing the confounding factor of Tool Length and only focusing on units produced with the Short Tool Length, there is a clear trend of better average quality with increasing Cutting Speed and Feed Rate (see ). This could be extrapolated such that one might expect even better quality if both were increased beyond the prescribed set of values, and in fact this exactly what is observed with the Operator’s Choice’ units produced (19 and 20) represented by blue squares in .\n\nA full detailing of the correlation to the various QIF tests to the recorded machining parameters is presented in . From these results it is clear that the selection of tool length has the biggest effect on the quality of various hole diameters, followed closely by slot lengths. Interestingly, this and other observations made during this analysis were corroborated by the operators who noted that:\n\nLonger tool lengths caused more vibration thus more chatter on the finish\n\nSlower RPMs caused chips to gather in flutes of smaller diameter end mills causing swirls on finish\n\nParts 16–18, the lower RPMs caused some of the holes to cut oversized due to flexing of small diameter, long length end mills\n\n6. Conclusions\n\nThis paper set out to present the activities and results of testing several popular manufacturing standards used in the context of smart manufacturing. We presented a test of the open, consensus-based standards’ ability to integrate lifecycle stages in a small-scale implementation of MBE. We conducted a design, build, inspect experiment to help inform the understanding and performance of the manufacturing standards. Studying data-mining methods, data-integration techniques, and implementation schemes were some of the goals of our work. However, making significant progress in these goals were not achieved because our data integrations could not leverage automatic data-alignment strategies. The results of our work show that the popular data standards used in industry do not support automatic data alignment. Therefore, we pivoted to providing recommendations to the SDOs for enhancing the standards that we expect would enable automatic data-alignment capabilities. We also expect that once automatic data-alignment capabilities are realized, researchers should then be able to discover methods for implementing and transferring standards-based information integration to practice.\n\nWe provided two recommendations to the SDOs. First, industry needs standardization of the data elements available across different implementations of the standards. The SDOs for MTConnect and QIF should consider requiring a select set of data element types, while continuing to make other element types optional. Requiring a set of element types would ensure industry can extract a common baseline of data across all operations. Second, industry needs the standards to provide and/or harmonize the ability to generate persistent identifiers (IDs) of features across data sets to enable monitoring the realization of products as they move through the phases of the entire product lifecycle.\n\nThe SDOs may partially address our recommendations by setting up implementer forums where solution providers and industry can come together to generate recommended practices for conforming to the standards. The forums would assist with harmonizing the implementations of each standard between the various solution providers who offer applications using the standards. Addressing the recommendations from our work herein would provide industry with a universal baseline of knowledge extraction and further support interoperability of data across the phases of the product lifecycle."
    }
}