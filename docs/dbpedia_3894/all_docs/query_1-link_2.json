{
    "id": "dbpedia_3894_1",
    "rank": 2,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3010734/",
        "read_more_link": "",
        "language": "en",
        "title": "From Singing to Speaking: Why Singing May Lead to Recovery of Expressive Language Function in Patients with Broca's Aphasia",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-nihpa.png",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3010734/bin/nihms-258790-f0001.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3010734/bin/nihms-258790-f0002.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3010734/bin/nihms-258790-f0003.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Gottfried Schlaug",
            "Sarah Marchina",
            "Andrea Norton"
        ],
        "publish_date": "2008-04-01T00:00:00",
        "summary": "",
        "meta_description": "It has been reported that patients with severely nonfluent aphasia are better at singing lyrics than speaking the same words. This observation inspired the development of Melodic Intonation Therapy (MIT), a treatment whose effects have been shown, but ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3010734/",
        "text": "Of the estimated 600,000-750,000 new strokes occurring in the US each year (according to data presented by the American Heart Association and the National Institutes of Health), approximately 20% result in some form of aphasia (http://www.wrongdiagnosis.com/artic/ninds_aphasia_information_page_ninds.htm). Aphasia is a condition characterized by either partial or total loss of the ability to communicate verbally. A person with aphasia may have difficulty speaking, reading, writing, recognizing the names of objects, and/or understanding what other people have said. Aphasia, a disorder caused by a brain injury (e.g., stroke, tumor, or trauma), can be subdivided into fluent and nonfluent categories. Nonfluent aphasia (as in the patients to be discussed here) generally results from lesions in the frontal lobe including the portion of the left frontal lobe known as Broca's region. Named for Paul Broca (1864), who first associated this area of the brain with nonfluent aphasia, this region is thought to consist of the posterior inferior frontal gyrus (IFG) encompassing Brodmann's areas 44 and 45. However, subsequent reports have shown that a wider array of lesions in the frontal lobes and in subcortical brain structures can also present a clinical picture of a Broca's aphasia (see Kertesz, Lesk, & McCabe, 1977).\n\nSurprisingly, there are no universally accepted methods for the treatment of nonfluent aphasia against which new or existing interventions can be tested, nor have any criteria been established for determining treatment efficacy. Most interventions in the subacute phase are conducted by speech therapists who evaluate patients' individual needs, then use a combination of techniques to help recover language/facilitate communication. Despite the lack of specific criterion for success, most therapists would agree that treatment efficacy would be defined by patients' ability to show improvement in speech output that generalizes to untrained language structures and/or contexts (Thompson & Shapiro, 2007).\n\nBecause the neural processes that underlie post-stroke language recovery remain largely unknown, it has not been possible to effectively target them using specific therapies. To date, functional imaging (mostly positron emission tomography) of language recovery has largely focused on spontaneous recovery, and patients have been imaged only after natural recovery has run its course (Warburton, Price, Swinburn, & Price, 1999; Weiller et al., 1995). Some studies emphasize the role of preserved language function in the left hemisphere (Cappa & Vallar, 1992; Heiss, Kessler, Thiel, Ghaemi, & Karbe, 1999), while others propose that language function is restored when right-hemisphere regions compensate for the loss (Basso, 1989; Blasi, Young, Tansy, Petersen, Snyder, & Corbetta, 2002; Cappa & Vallar, 1992; Cappa et al., 1997; Kinsbourne, 1998; Moore, 1989; Selnes, 1999; Weiller et al., 1995). Still other studies report evidence for bihemispheric language processing (Heiss & Thiel, 2006; Mimura, Kato, Sano, Kojima, Naeser, & Kashima, 1998; Rosen et al., 2000; Saur et al., 2006; Winhuisen et al., 2005). Interestingly, only a few studies have examined the neural correlates of an aphasia treatment by contrasting pre- and post-therapy assessments (Cornelissen, Laine, Tarkiainen, Järvensivu, Martin, & Salmelin, 2003; Musso, Weiller, Kiebel, Muller, Bulau, & Rijntjes, 1999; Saur et al., 2006; Small, Flores, & Noll, 1998; Thompson & Shapiro, 2005). The general consensus is that there are two routes to recovery. In patients with small lesions, there tends to be more activation of left hemisphere peri-lesional cortex and variable right hemisphere activation during the recovery process or after recovery. In patients with large left-hemisphere lesions that involve language regions in the fronto-temporal lobes, there tends to be more activation of the homologous language-capable regions in the right hemisphere.\n\nAssuming that potential facilitators of language recovery may be either undamaged portions of the left-hemisphere language network, language-capable regions in the right hemisphere, or both, it is necessary to explore treatments that can better engage these regions and ultimately, change the course of natural recovery through neural reorganization. One therapy capable of engaging regions in both hemispheres is Melodic Intonation Therapy (MIT; Albert, Sparks, & Helm, 1973; Sparks, Helm, & Albert, 1974), a method developed in response to the observation that severely aphasic patients can often produce well articulated, linguistically accurate words while singing, but not during speech (Gerstman, 1964; Geschwind, 1971; Hebert, Racette, Gagnon, & Peretz, 2003; Keith & Aronson, 1975; Kinsella, Prior, & Murray, 1988). MIT is a hierarchically structured treatment that uses intoned (sung) patterns to exaggerate the normal melodic content of speech at three levels of difficulty. The intonation works by translating prosodic speech patterns (sung phrases) using just two pitches. The higher pitches represent the syllables that would naturally be stressed (accented) during speech (see ).At the simplest level, patients learn to intone (sing) a series of 2-syllable words/phrases (e.g., “Water,” “Ice cream,” “Bathroom”) or simple, 2- or 3-syllable social phrases (e.g., “Thank you,” “I love you”). As each level is mastered, patients move to the next, and phrases gradually increase in length (e.g., “I am thirsty,” “A cup of coffee, please”). Beyond the increased phrase length, the primary change from level to level of MIT lies in the way the treatment is administered and the degree of support that is provided by the therapist.\n\nMIT contains two unique elements that set it apart from other, non-intonation-based therapies: (1) the melodic intonation (singing) with its inherent continuous voicing, and (2) the rhythmic tapping of each syllable (using the patient's left hand) while phrases are intoned and repeated. Since the initial account of its successful use in three chronic, nonfluent (Broca's) aphasic patients (Albert, Sparks, & Helm, 1973), reports have outlined a comprehensive program of MIT (Helm-Estabrooks & Albert, 1991; Sparks & Holland, 1976) including strict patient selection criteria (Helm-Estabrooks, Nicholas, & Morgan, 1989), and data that showed significant improvement on the Boston Diagnostic Aphasia Examination (BDAE; Goodglass & Kaplan, 1983) after treatment (Bonakdarpour, Eftekharzadeh, & Ashayeri, 2000; Sparks, Helm, & Albert, 1974). In a case study comparing MIT to a non-melodic control therapy, Wilson, Parsons, and Reutens (2006) found that MIT had a general facilitating effect on articulation, and a longer-term effect on phrase production that they attributed specifically to its melodic component. However, the outcomes of that study were measured by the patient's ability to produce practiced phrases prompted by the therapist, rather than by the transfer of language skills to untrained structures and/or contexts.\n\nAnother important characteristic of MIT is that, unlike many therapies administered in the chronic phase that involve one to two short sessions per week, MIT engages patients in intensive treatment totaling 1.5 hrs/day, five days/week until the patient has mastered all three levels of MIT. In addition to its unique elements, there are several other components that play an important role in MIT, but are also used by other therapies, among them are the slow rate of vocalization (one syllable/s) and an administration protocol that includes one-on-one sessions with a therapist who introduces and practices words/phrases using picture cues while giving continuous feedback. These shared features were carefully considered as we designed a control intervention for MIT that included the elements common to other therapies while specifically excluding the melodic intonation/continuous voicing and rhythmic tapping that may likely be the key factors in its effectiveness.\n\nThe original interpretation of MIT's path to successful recovery was that it engaged expressive language areas in the right hemisphere (Albert et al., 1973; Sparks et al., 1974), although to date, this has not yet been proven. Alternatively MIT may exert its effect by either unmasking existing music/language connections in both hemispheres, or by engaging preserved language-capable regions in either or both hemispheres. Since MIT incorporates both melodic and rhythmic aspects of music (Albert et al., 1973; Boucher, Garcia, Fleurant, & Paradis, 2001; Cohen & Masse, 1993; Helm-Estabrooks & Albert, 1991; Sparks & Holland, 1976), it may be unique in its potential ability to engage both hemispheres. Belin et al. (1996) suggested that MIT-facilitated recovery was associated with the reactivation of left-hemisphere regions, most notably the left pre-frontal cortex, just anterior to Broca's region. Although, this publication was the first to examine patients treated with an MIT-like intervention using functional neuroimaging, their findings were both surprising and somewhat contrary to the hypotheses proposed by the developers of MIT (Albert et al., 1973; Sparks et al., 1974). Furthermore, to help interpret Belin and colleagues' findings it is important to consider the following: First, only two of their seven patients had Broca's aphasia; the rest were diagnosed with global aphasia. Second, they conducted only one imaging session, which took place after therapy (no pre-/ post- comparison). And finally, their analysis was done in predefined regions of interest rather than across the entire brain space. It is interesting to note that although Belin and colleagues' primary finding was an activation of left prefrontal regions when participants were asked to repeat intoned words, there is an important aspect of their study that is not often reported. In their analysis comparing the repetition of spoken words with the hearing of those words, they found blood flow changes that occurred predominantly in the right hemisphere (including the right temporal lobe and the right central operculum), which concurs with some of our findings detailed below.\n\nThe aim of our study is to describe and discuss the unique and shared elements of MIT and to contrast the behavioral and neural treatment effects of MIT with a control intervention, Speech Repetition Therapy (SRT), in two prototypical patients.\n\nDiscussion\n\nThe traditional explanation for the dissociation between speaking and singing in aphasic patients is the presence of two routes for word articulation: one for spoken words through the brain's left hemisphere, and a separate route for sung words that uses either the right or both hemispheres. The small amount of empirical data available supports a bihemispheric role in the execution and sensorimotor control of vocal production for both speaking and singing (Bohland & Guenther, 2006; Brown, Martinez, Hodges, Fox, & Parsons, 2004; Guenther, Hampson, & Johnson, 1998; Jeffries, Fritz, & Braun, 2003; Ozdemir et al., 2006), with a tendency for greater left-lateralization for speaking under normal physiological conditions (i.e., faster rates of production during speaking than singing). The representation of sensory elements of music and language might be either separate, or in different locations with smaller degrees of overlap (for more details on this see also Koelsch, Fritz, Schulze, Alsop, & Schlaug, 2005; Koelsch, Gunter, von Cramon, Zysset, Lohmann, & Friederici, 2002; Patel, 2003; Peretz, 2003). Nevertheless, if there is a bihemispheric representation for speech production, then the question of why an intervention that uses singing or a form of singing such as MIT has the potential to facilitate syllable and word production, still remains. In theory, there are four possible mechanisms by which MIT's facilitating effect may be achieved: (1) Reduction of speed: in singing, words can be articulated at a slower rate than in speaking, thereby reducing dependence on the left-hemisphere; (2) Syllable lengthening: provides the opportunity to distinguish the individual phonemes that together form words and phrases. Such connected segmentation, coupled with the reduction of speed in singing, can help nonfluent aphasic patients become more fluent, and may receive greater support from right-hemisphere structures; (3) Syllable “chunking”: prosodic features such as intonation, change in pitch, and syllabic stress may help patients group syllables into words and words into phrases, and this “chunking”(Chase & Simon, 1973; de Groot, 1965) may also enlist more right-hemisphere support; and 4) Hand tapping: it is likely that MIT engages a right-hemispheric, sensorimotor network through the tapping of the patient's left hand as each syllable is sung (one tap/syllable, one syllable/s), which may in turn provide an impulse for verbal production in much the same way that a metronome has been shown to serve as a “pacemaker”in other motor activities (rhythmic anticipation, rhythmic entrainment; Thaut, Kenyon, Schauer, & McIntosh, 1999). In addition, there may be a set of shared neural correlates that control both hand movements and articulatory movements (Gentilucci, Benuzzi, Bertolani, Daprati, & Gangittano, 2000; Meister, Boroojerdi, Foltys, Sparing, Huber, & Topper, 2003; Tokimura, Tokimura, Oliviero, Asakura, & Rothwell, 1996; Uozumi, Tamagawa, Hashimoto, & Tsuji, 2004), and further, the sound produced by the tapping may encourage auditory-motor coupling (Lahav, Saltzman, & Schlaug, 2007).\n\nThe two unique elements of MIT most likely to make the strongest contribution to the therapy's beneficial effects are the melodic intonation with its inherent sustained vocalization, and tapping with the left hand. How might melodic intonation influence recovery? Functional imaging tasks targeting the perception of musical components that require a more global than local processing strategy (e.g., melodic contour, musical phrasing, and/or meter) tend to elicit greater activity in right-hemispheric brain regions than in left-hemispheric regions. It has been shown that tasks that emphasize spectral information over temporal information have shown more right- than left-hemispheric activation (Zatorre & Belin, 2001). Similarly, patients with right-hemisphere lesions have greater difficulty with global processing (e.g., melody and contour processing) than those with left-hemisphere lesions (Peretz, 1990; Schuppert, Munte, Wieringa, & Altenmueller, 2000). It is most likely that the two unique elements of MIT, the melodic intonation with its inherent sustained vocalization and the rhythmic tapping of the left hand, make the strongest contribution to the therapy's beneficial effect.\n\nThe effects of the left hand tapping should be considered in the same context. Once the right temporal lobe is specifically engaged by the melodic intonation and melodic contour, it is conceivable that the role of the left hand tapping could be the activation and priming of a right-hemispheric sensorimotor network for articulation. Since concurrent speech and hand use occurs in daily life, and gestures are frequently used during speech, hand movements, possibly in synchrony with articulatory movements, may have a facilitating effect on speech production, but the precise role of this facilitation is unknown. We hypothesize that tapping the left hand may engage a right-hemispheric sensorimotor network that coordinates not only hand movements but orofacial and articulatory movements as well. There is some evidence in the literature that such superordinate centers exist in the premotor cortex and share neural substrates for hand and orofacial movements (Meister et al., 2003; Tokimura et al., 1996; Uozumi et al., 2004). Furthermore, behavioral (Gentilucci et al., 2000), neurophysiological (Meister et al., 2003; Tokimura et al., 1996) and fMRI studies (Aziz-Zadeh, Wilson, Rizzolatti, & Iacoboni, 2006) have shown that motor and linguistic cortical representations of objects are closely linked, and that the premotor cortex may belong to an integrative network coordinating motor and linguistic expression. An additional or alternative explanation is that the left hand tapping may serve the same function as a pacemaker or metronome has in rehabilitation of other motor activities, and in so doing, may facilitate speech production through rhythmic anticipation, rhythmic entrainment, or auditory-motor coupling (see also Lahav et al., 2007, and Thaut et al., 1999).\n\nIn summary, the melodic intonation and left hand tapping are the critical, unique elements of MIT that may likely be responsible for its therapeutic effect and might explain the predominant right hemispheric activation pattern seen in our prototypical patient. Elements of MIT that are shared with other, non-intonation-based therapies (e.g., the intensity of the intervention, direct therapist/patient interaction, unison and antiphonal repetition of words and phrases) also have therapeutic effects, as can be seen in our patient treated with SRT. Although caution should be exercised when making generalizations from results in two prototypical patients, we hope that our findings will serve as a source for further discussion on the efficacy of MIT, the neural correlates of MIT, and the choice of appropriate control interventions for MIT."
    }
}