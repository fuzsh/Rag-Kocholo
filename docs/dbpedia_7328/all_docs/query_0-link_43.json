{
    "id": "dbpedia_7328_0",
    "rank": 43,
    "data": {
        "url": "https://www.techpowerup.com/forums/threads/tv-as-computer-monitor-1080p-1080i.207502/",
        "read_more_link": "",
        "language": "en",
        "title": "TV as computer monitor? 1080p/1080i?",
        "top_image": "https://tpucdn.com/forums/data/assets/logo/logo-og-v1.png",
        "meta_img": "https://tpucdn.com/forums/data/assets/logo/logo-og-v1.png",
        "images": [
            "https://tpucdn.com/forums/data/assets/logo/logo-v1.png",
            "https://tpucdn.com/forums/styles/tpu/logo-white-v1.png",
            "https://tpucdn.com/forums/data/avatars/l/32/32804.jpg?1384761604",
            "https://tpucdn.com/forums/data/avatars/l/40/40310.jpg?1591973247",
            "https://tpucdn.com/forums/data/avatars/l/75/75069.jpg?1384763534",
            "https://tpucdn.com/forums/styles/tpu/stars/7star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/40/40310.jpg?1591973247",
            "https://tpucdn.com/forums/data/avatars/l/20/20670.jpg?1384761197",
            "https://tpucdn.com/forums/data/avatars/l/32/32804.jpg?1384761604",
            "https://tpucdn.com/forums/data/avatars/l/65/65960.jpg?1396836780",
            "https://tpucdn.com/forums/styles/tpu/stars/6star-v1.gif",
            "https://tpucdn.com/forums/data/assets/smilies/mad-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/75/75069.jpg?1384763534",
            "https://tpucdn.com/forums/styles/tpu/stars/7star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/45/45327.jpg?1384762193",
            "https://tpucdn.com/forums/styles/tpu/stars/6star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/65/65960.jpg?1396836780",
            "https://tpucdn.com/forums/styles/tpu/stars/6star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/109/109386.jpg?1389096612",
            "https://tpucdn.com/forums/styles/tpu/stars/5star-v1.gif",
            "https://tpucdn.com/forums/data/assets/smilies/smile-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/20/20670.jpg?1384761197",
            "https://tpucdn.com/forums/data/avatars/l/105/105443.jpg?1698927049",
            "https://tpucdn.com/forums/styles/tpu/stars/7star-v1.gif",
            "https://tpucdn.com/forums/data/assets/smilies/rolleyes-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/138/138051.jpg?1494796152",
            "https://tpucdn.com/forums/styles/tpu/stars/7star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/65/65960.jpg?1396836780",
            "https://tpucdn.com/forums/styles/tpu/stars/6star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/20/20670.jpg?1384761197",
            "https://tpucdn.com/forums/data/avatars/l/32/32804.jpg?1384761604",
            "https://tpucdn.com/forums/data/avatars/l/75/75069.jpg?1384763534",
            "https://tpucdn.com/forums/styles/tpu/stars/7star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/32/32804.jpg?1384761604",
            "https://tpucdn.com/forums/data/avatars/l/65/65960.jpg?1396836780",
            "https://tpucdn.com/forums/styles/tpu/stars/6star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/1/1746.jpg?1670665534",
            "https://tpucdn.com/forums/data/avatars/l/138/138051.jpg?1494796152",
            "https://tpucdn.com/forums/styles/tpu/stars/7star-v1.gif",
            "https://tpucdn.com/forums/data/avatars/l/1/1746.jpg?1670665534",
            "https://tpucdn.com/forums/data/avatars/l/20/20670.jpg?1384761197",
            "https://tpucdn.com/forums/data/avatars/l/32/32804.jpg?1384761604"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "hat"
        ],
        "publish_date": "2014-11-25T04:00:44+00:00",
        "summary": "",
        "meta_description": "I used a TV as a computer monitor for the longest time, both with the VGA and later on with the HDMI input. It looked fine--at 1440x900, which was the...",
        "meta_lang": "en",
        "meta_favicon": "https://tpucdn.com/forums/data/assets/logo/icon-192-v1.png",
        "meta_site_name": "TechPowerUp Forums",
        "canonical_link": "https://www.techpowerup.com/forums/threads/tv-as-computer-monitor-1080p-1080i.207502/",
        "text": "I used a TV as a computer monitor for the longest time, both with the VGA and later on with the HDMI input. It looked fine--at 1440x900, which was the native resolution reported in Windows for the TV (even though it was a 1080i screen... I could select 1080i but it looked like ass).\n\nNow I have a different TV for testing purposes. It's a 1080p screen, and in Windows it shows the native resolution is 1980x1080... but it looks like ass. It looks kinda overbright, text doesn't look right, etc... but if I tune it down to 1366x768, it looks okay (only thought of 1366x768 as it seems to be the standard resolution to run on a TV from a computer).\n\nIs there something up with the TV? Maybe it's just not a good quality screen, or not designed to display an image from a PC? How do I choose a good TV that I intend to use with a PC? Or is it best to just use a monitor anyway?\n\nSide question: all this 1080p/1080i nonsense. I understand p is for progressive and i is for interlaced and it refers to how the video is recorded or somesuch. Doesn't really seem to apply to computers, or even a game console for that matter (when it comes to video games, anyway). It seems to have mostly to do with TV and movies and that sort of thing. So then, is there truly any such thing as a 1080p/1080i computer monitor?\n\nWhat is the exact model of the TV, and using VGA or HDMI? Also, since you have a Radeon, did you change the display underscan to 0% in CCC if using HDMI? (Why AMD is dumb with HDTVs on HDMI, I never found out, and missing EDID data shouldn't mean \"underscan the f*** out of the TV)\". Likewise, don't use the TV to overscan the underscanned output from the Radeon if it's doing that.\n\nFunny you say that as my overscan requirement change went away when i changed AV's lol. As far as i can tell witht he newer YAMAHA AV's the computer see's the TV not the AV so it shows in windows not what AV your using but what TV your using.\n\nIs there something up with the TV? Maybe it's just not a good quality screen, or not designed to display an image from a PC? How do I choose a good TV that I intend to use with a PC? Or is it best to just use a monitor anyway?\n\nIn my experience a lot of TVs do a shit load of stupid post processing to the image and it can really make things look shitty when using the TV as a monitor. However, there is almost always a mode in the TV menu that disables all that crap. If not, then you probably have to adjust the image settings manually and turn the different picture effects off manually as well.\n\nSide question: all this 1080p/1080i nonsense. I understand p is for progressive and i is for interlaced and it refers to how the video is recorded or somesuch. Doesn't really seem to apply to computers, or even a game console for that matter (when it comes to video games, anyway). It seems to have mostly to do with TV and movies and that sort of thing. So then, is there truly any such thing as a 1080p/1080i computer monitor?\n\nFrom what I've gathered, the 1080i label is/was misused by TV manufacturers. Back with tube TVs 480i meant the TV did 640x480 interlaced, so half the horizontal lines weren't used. With 480p, the TV did true 640x480 with all the horizontal lines being used. You'd think the same would apply to 1080i/p, the only difference being the resolution. But no. Instead, it seems like TV manufactures used 1080i to stand for any TV that had a native resolution higher than 720p but not 1080p. Most commonly TVs that used a 1366x768 panel were labeled as 1080i. They would accept a 1080i signal, but downscale it to the lower resolution. I guess they figured this was OK since they were also upscaling the 720p signal and a lot of times a 1080i signal would look better on the TV.\n\nSignal wise, 1080i is 1920x1080 interlaced like you'd expect.\n\nAny TV/Monitor that uses a native 1080p panel is truly a 1080p monitor/TV. There aren't, AFAIK, any truly 1080i monitors or TVs. Any TV labelled FullHD should be a native 1080p panel.\n\nIt's a Seiki SE24FE01-W. There is a problm with a damaged part of the screen anyway so we're returning it. Probably just gonna pick up an actual PC monitor as that's what it was gonna be used as anyway.\n\nThere were some options similar to what asrock said that made the picture appear bigger or smaller. I was using HDMI, not sure about overscan or underscan in CCC... I did look at it but I don't remember what it was set to. There was a VGA port on the TV though... Maybe this TV isn't really designed to be used as a PC monitor, at least with HDMI.\n\nI don't get why I couldn't just select the native res of 1920x1080 and go, like I did with my TV at 1440x900...\n\nI take it PC monitors are better suited to displaying an image from a PC than a TV anyways...\n\nthis thread hurts my brain\n\nnow consider this, if the tvs were ruining the pc image... dont you think they're also ruining the console+tv+bluray images as well? why arent we rioting in the streets due to all the bs that happens with tvs & hdmi\n\nthere is no way 1366x768 can look 'okay', if the tv has 1920x1080 pixels, well you better send it a 1920x1080 signal (p of course), anything not native is a blur, like every single pixel based monitor in existence other than CRTs\n\nnow... aside from panel types like TN/MVA/IPS, or screen types like LCD/plasma/etc, what you as a user have to do is calibrate as best as you can\n\ndisable overscan or underscan, disable dynamic anything, disable frivolous modes like 'game mode' or 'movie mode', start the sharpness setting at ZERO then adjust, make sure the full native resolution (p of course, for progressive) is being sent, finally adjust the brightness+contrast+color settings on the tv until they're decent using reference images like http://www.lagom.nl/lcd-test/\n\nif the tv or gfx card or console have the option, compare rgb full vs rgb limited if any of them have such an option (a ps3 does, for example), try to see as many colors/whites/blacks as you can in lagom's test images\n\nnow... after all of that tweaking... it may never be good enough, like a crappy insignia i've used, somehow it's still slightly blurry & of course a lot of the whites+blacks are crushed, the gamma is way off, it's just plain irritating...\n\ni certainly would love to have a GOOD tv... such as IPS panel without garbage settings that cant be disabled\n\nbut at the end of the day, what exactly does anyone need a tv for? speakers? atsc tuner? coax input? inches? several hdmi inputs? there's nothing really proprietary about them, a tv just puts them all in a single unit at the expense of terrible firmware most of the time\n\nI used a 2009 Insignia advanced 22\" 1080p TV for a couple years, and had interesting HDMI problems myself. After unscrewing the AMD underscan crap with my HD 5770, the picture was okay but any red colored text was super blurry. I was so happy when I purchased my ASUS VG236H monitor as the text was a lot cleaner along with everything else on DVI, but the HDMI is still crappy even to this day with Radeons at the least (had it on an R9 280X recently and all the colors were washed out and the picture was grainy. I'm trying the monitor with my laptop at the moment on HDMI (controlled by Intel HD 4600) and it actually looks fine with that, so probably Radeon HDMI crap going on mostly, along with potential TV processing crap too.\n\nI used a 2009 Insignia advanced 22\" 1080p TV for a couple years, and had interesting HDMI problems myself. After unscrewing the AMD underscan crap with my HD 5770, the picture was okay but any red colored text was super blurry. I was so happy when I purchased my ASUS VG236H monitor as the text was a lot cleaner along with everything else on DVI, but the HDMI is still crappy even to this day with Radeons at the least (had it on an R9 280X recently and all the colors were washed out and the picture was grainy. I'm trying the monitor with my laptop at the moment on HDMI (controlled by Intel HD 4600) and it actually looks fine with that, so probably Radeon HDMI crap going on mostly, along with potential TV processing crap too.\n\nreminded me of yet another setting... color subsampling, which is only good for video compression, i dont see why it should be an option for hardware, so go into CCC & play with the rgb/hdmi settings, avoid things like 4:2:0, go for 4:4:4, go for rgb full, etc\n\nI too use my TV(40\", 1080p) as my monitor. I have only experienced one consistent issue and that's with text. black text seems too have a redish hue here, blueish hue there, etc. Idk if it has to do with the PPI or not, but the only thing i could come up with is the pixels are so much larger than 1080p on a 22-27\" screen that the eye is able to differentiate minute differences in the 3 colors that make up a pixel?.....lol pure pull outa my arse logic but its the best i have.\n\nzoom in on a screenshot of cleartype text, you will see the pixels are colored around the edges, which creates a nice illusion of increased sharpness on monitors... but if the pixels are huge, you will see their colors (alternatively, if you horizontally glide your eyesight across the image, you should see how the colors disappear)\n\nthere is no way 1366x768 can look 'okay', if the tv has 1920x1080 pixels, well you better send it a 1920x1080 signal (p of course), anything not native is a blur, like every single pixel based monitor in existence other than CRTs\n\nThat simply is not true. Both HDTVs in my home that have PCs connected to them are 1920x1080 panels, and I run both at 1360x768 when using the PC and the image is okay. It is not as sharp as running at 1080p, but I wouldn't call it blurry either. The text is clear and readable.\n\nI've seen what you are talking about in the past, where running at anything other than the native resolution was extremely blurry. But that was on old 1280x1024 monitors running 1024x768.\n\ni add myself as: another \"TV as computer screen\"user\n\nToshiba 32L1343DG 1080i (no lines ... ? interlaced have lines right? ) using on HDMI (since it doesnt have anything else than HDMI or VGA) funniest thing is : i can't use my 24\" ASUS anymore ... it feels blurry and less good than my TV (also go find a 32\" monitor for under 299chf ... all of them cost the double of that, at minimum.)\n\nonly issue : with some game i have to 1. alt-tab win then alt-tab back to the game (under/overscan issue iirc) 2. set up to borderless windowed mode (when alt-tab solve nothing)\n\ni think one day i will take a 32\" (or a 27\" as they seems a bit more affordable)1440p for a change ... maybe i will ask santa claus\n\nall that to say : i prefer my 32\" TV over any of my 24\" 16/9 16/10 screen i had (2ms type)\n\nlast question : that Toshiba handle 1920x1200 at max it's safe or not? (well i assume it's not a good idea since it's a 16/9 panel and 1200 is a 16/10 res)\n\nThat simply is not true. Both HDTVs in my home that have PCs connected to them are 1920x1080 panels, and I run both at 1360x768 when using the PC and the image is okay. It is not as sharp as running at 1080p, but I wouldn't call it blurry either. The text is clear and readable.\n\nI've seen what you are talking about in the past, where running at anything other than the native resolution was extremely blurry. But that was on old 1280x1024 monitors running 1024x768.\n\ni dont mean it's super blurry, it's merely not perfect (i run an android box in 720 on a 1080 tv)\n\neven on old monitors, i dont mean non native is unreadable, but you cant mathematically fit one grid on another grid without altering the image... & i personally want as accurate as possible\n\nnow if you want to see something interesting, check out 'majin and the forsaken kingdom' on 360/ps3, they basically did nearest neighbor filtering to upscale 720 to 1080 (i tested the ps3 demo), so there is zero blur, it's real sharp, but you can see the pixel steps arent even, it reminds me of 90s games like magic carpet or doom\n\nToshiba 32L1343DG 1080i (no lines ... ? interlaced have lines right? )\n\n...\n\nonly issue : with some game i have to 1. alt-tab win then alt-tab back to the game (under/overscan issue iirc)\n\n...\n\nlast question : that Toshiba handle 1920x1200 at max it's safe or not? (well i assume it's not a good idea since it's a 16/9 panel and 1200 is a 16/10 res)\n\ninterlaced DATA has lines in an abstract sense, obviously the tv will merge the signal or duplicate the lines to display them on screen, otherwise you'll be looking through a fence of tiny black bars\n\nwhy arent you set to 1080p in your gfx driver settings? make sure all overscan settings in BOTH the gfx driver & the monitor are off or '100%'\n\ninteresting that it can handle x1200... it would either crop or shrink with black bars, either way there is a loss of 'data'\n\ni dont mean it's super blurry, it's merely not perfect (i run an android box in 720 on a 1080 tv)\n\neven on old monitors, i dont mean non native is unreadable, but you cant mathematically fit one grid on another grid without altering the image... & i personally want as accurate as possible\n\nnow if you want to see something interesting, check out 'majin and the forsaken kingdom' on 360/ps3, they basically did nearest neighbor filtering to upscale 720 to 1080 (i tested the ps3 demo), so there is zero blur, it's real sharp, but you can see the pixel steps arent even, it reminds me of 90s games like magic carpet or doom\n\nThat is the thing though, the image is \"okay\". It isn't perfect, but it is okay.\n\nAnd most of the time the lower resolution is being used either because the person is too far away from the screen or they have poor vision...or both. Either way, in the common situations you won't notice the slight blur."
    }
}