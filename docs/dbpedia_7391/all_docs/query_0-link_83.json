{
    "id": "dbpedia_7391_0",
    "rank": 83,
    "data": {
        "url": "https://introtcs.org/public/lec_19_cryptography.html",
        "read_more_link": "",
        "language": "en",
        "title": "Introduction to Theoretical Computer Science: Cryptography",
        "top_image": "https://introtcs.org/public/icons/cover.png",
        "meta_img": "https://introtcs.org/public/icons/cover.png",
        "images": [
            "https://introtcs.org/figure/encrypted_letter.jpg",
            "https://introtcs.org/figure/code_talkers.png",
            "https://introtcs.org/figure/confederate_cipher_disk.jpg",
            "https://introtcs.org/figure/confederate_message.jpg",
            "https://introtcs.org/figure/enigma.jpg",
            "https://introtcs.org/figure/encryptionvalid.png",
            "https://introtcs.org/figure/perfectsecrecy.png",
            "https://introtcs.org/figure/onetimepadtwobits.png",
            "https://introtcs.org/figure/onetimepad.png",
            "https://introtcs.org/figure/genevenona.png",
            "https://introtcs.org/figure/longkeygraph.png",
            "https://introtcs.org/figure/derandonetimepad.png",
            "https://introtcs.org/figure/rsadhmg.png",
            "https://introtcs.org/figure/publickeyenc.png",
            "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Boaz Barak"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Textbook on Theoretical Computer Science by Boaz Barak",
        "meta_lang": "en",
        "meta_favicon": "icons/apple-touch-icon-120x120.png",
        "meta_site_name": "",
        "canonical_link": "https://introtcs.org/",
        "text": "Cryptography\n\n“Human ingenuity cannot concoct a cipher which human ingenuity cannot resolve.”, Edgar Allen Poe, 1841\n\n“A good disguise should not reveal the person’s height”, Shafi Goldwasser and Silvio Micali, 1982\n\n““Perfect Secrecy” is defined by requiring of a system that after a cryptogram is intercepted by the enemy the a posteriori probabilities of this cryptogram representing various messages be identically the same as the a priori probabilities of the same messages before the interception. It is shown that perfect secrecy is possible but requires, if the number of messages is finite, the same number of possible keys.\", Claude Shannon, 1945\n\n“We stand today on the brink of a revolution in cryptography.”, Whitfeld Diffie and Martin Hellman, 1976\n\nCryptography - the art or science of “secret writing” - has been around for several millennia, and for almost all of that time Edgar Allan Poe’s quote above held true. Indeed, the history of cryptography is littered with the figurative corpses of cryptosystems believed secure and then broken, and sometimes with the actual corpses of those who have mistakenly placed their faith in these cryptosystems.\n\nYet, something changed in the last few decades, which is the “revolution” alluded to (and to a large extent initiated by) Diffie and Hellman’s 1976 paper quoted above. New cryptosystems have been found that have not been broken despite being subjected to immense efforts involving both human ingenuity and computational power on a scale that completely dwarves the “code breakers” of Poe’s time. Even more amazingly, these cryptosystems are not only seemingly unbreakable, but they also achieve this under much harsher conditions. Not only do today’s attackers have more computational power, but they also have more data to work with. In Poe’s age, an attacker would be lucky if they got access to more than a few encryptions of known messages. These days attackers might have massive amounts of data—terabytes or more—at their disposal. In fact, with public key encryption, an attacker can generate as many ciphertexts as they wish.\n\nThe key to this success has been a clearer understanding of both how to define security for cryptographic tools and how to relate this security to concrete computational problems. Cryptography is a vast and continuously changing topic, but we will touch on some of these issues in this chapter.\n\nClassical cryptosystems\n\nA great many cryptosystems have been devised and broken throughout the ages. Let us recount just some of these stories. In 1587, Mary, Queen of Scots, and the heir to the throne of England, wanted to arrange the assassination of her cousin, Queen Elizabeth I of England, so that she could ascend to the throne and finally escape the house arrest under which she had been for the last 18 years. As part of this complicated plot, she sent a coded letter to Sir Anthony Babington.\n\nMary used what’s known as a substitution cipher where each letter is transformed into a different obscure symbol (see Figure 21.1). At a first look, such a letter might seem rather inscrutable—a meaningless sequence of strange symbols. However, after some thought, one might recognize that these symbols repeat several times and moreover that different symbols repeat with different frequencies. Now it doesn’t take a large leap of faith to assume that perhaps each symbol corresponds to a different letter and the more frequent symbols correspond to letters that occur in the alphabet with higher frequency. From this observation, there is a short gap to completely breaking the cipher, which was in fact done by Queen Elizabeth’s spies, who used the decoded letters to learn of all the co-conspirators and to convict Queen Mary of treason, a crime for which she was executed. Trusting in superficial security measures (such as using “inscrutable” symbols) is a trap that users of cryptography have been falling into again and again over the years. (As with many things, this is the subject of a great XKCD cartoon, see Figure 21.2.)\n\nThe Vigenère cipher is named after Blaise de Vigenère, who described it in a book in 1586 (though it was invented earlier by Bellaso). The idea is to use a collection of substitution cyphers: if there are \\(n\\) different ciphers then the first letter of the plaintext is encoded with the first cipher, the second with the second cipher, the \\(n^{th}\\) with the \\(n^{th}\\) cipher, and then the \\(n+1^{st}\\) letter is again encoded with the first cipher. The key \\(k\\) is usually a word or a phrase of \\(n\\) letters. The \\(i^{th}\\) substitution cipher will shift each letter by the same shift needed to get from A to \\(k_i\\). If \\(k_i\\) is C, for example, the \\(i^{th}\\) substitution cipher will shift every letter by two places. This “flattens” the frequencies and makes it much harder to do frequency analysis, which is why this cipher was considered “unbreakable” for 300+ years and got the nickname “le chiffre indéchiffrable” (“the unbreakable cipher”). Nevertheless, Charles Babbage cracked the Vigenère cipher in 1854 (though he did not publish it). In 1863 Friedrich Kasiski broke the cipher and published the result. The idea is that once you guess the length of the cipher, you can reduce the task to breaking a simple substitution cipher which can be done via frequency analysis (can you see why?). Confederate generals used Vigenère regularly during the civil war, and their messages were routinely cryptanalyzed by Union officers.\n\nThe Enigma cipher was a mechanical cipher (looking like a typewriter, see Figure 21.5) where each letter typed would get mapped into a different letter depending on the (rather complicated) key and current state of the machine,d which had several rotors that rotated at different paces. An identically wired machine at the other end could be used to decrypt. Just as many ciphers in history, this has also been believed by the Germans to be “impossible to break” and even quite late in the war they refused to believe it was broken despite mounting evidence to that effect. (In fact, some German generals refused to believe it was broken even after the war.) Breaking Enigma was an heroic effort which was initiated by the Poles and then completed by the British at Bletchley Park, with Alan Turing (of the Turing machine) playing a key role. As part of this effort the Brits built arguably the world’s first large scale mechanical computation devices (though they looked more similar to washing machines than to iPhones). They were also helped along the way by some quirks and errors of the German operators. For example, the fact that their messages ended with “Heil Hitler” turned out to be quite useful.\n\nHere is one entertaining anecdote: the Enigma machine would never map a letter to itself. In March 1941, Mavis Batey, a cryptanalyst at Bletchley Park received a very long message that she tried to decrypt. She then noticed a curious property— the message did not contain the letter “L”.1 She realized that the probability that no “L”’s appeared in the message is too small for this to happen by chance. Hence she surmised that the original message must have been composed only of L’s. That is, it must have been the case that the operator, perhaps to test the machine, have simply sent out a message where he repeatedly pressed the letter “L”. This observation helped her decode the next message, which helped inform of a planned Italian attack and secure a resounding British victory in what became known as “the Battle of Cape Matapan”. Mavis also helped break another Enigma machine. Using the information she provided, the Brits were able to feed the Germans with the false information that the main allied invasion would take place in Pas de Calais rather than on Normandy.\n\nIn the words of General Eisenhower, the intelligence from Bletchley Park was of “priceless value”. It made a huge difference for the Allied war effort, thereby shortening World War II and saving millions of lives. See also this interview with Sir Harry Hinsley.\n\nDefining encryption\n\nMany of the troubles that cryptosystem designers faced over history (and still face!) can be attributed to not properly defining or understanding the goals they want to achieve in the first place. Let us focus on the setting of private key encryption. (This is also known as “symmetric encryption”; for thousands of years, “private key encryption” was synonymous with encryption and only in the 1970s was the concept of public key encryption invented, see Definition 21.11.) A sender (traditionally called “Alice”) wants to send a message (known also as a plaintext) \\(x\\in \\{0,1\\}^*\\) to a receiver (traditionally called “Bob”). They would like their message to be kept secret from an adversary who listens in or “eavesdrops” on the communication channel (and is traditionally called “Eve”).\n\nAlice and Bob share a secret key \\(k \\in \\{0,1\\}^*\\). (While the letter \\(k\\) is often used elsewhere in the book to denote a natural number, in this chapter we use it to denote the string corresponding to a secret key.) Alice uses the key \\(k\\) to “scramble” or encrypt the plaintext \\(x\\) into a ciphertext \\(y\\), and Bob uses the key \\(k\\) to “unscramble” or decrypt the ciphertext \\(y\\) back into the plaintext \\(x\\). This motivates the following definition which attempts to capture what it means for an encryption scheme to be valid or “make sense”, regardless of whether or not it is secure:\n\nWe will often write the first input (i.e., the key) to the encryption and decryption as a subscript and so can write Equation 21.1 also as \\(D_k(E_k(x))=x\\).\n\nSince the ciphertext length is always at least the plaintext length (and in most applications it is not much longer than that), we typically focus on the plaintext length as the quantity to optimize in an encryption scheme. The larger \\(L(n)\\) is, the better the scheme, since it means we need a shorter secret key to protect messages of the same length.\n\nDefining security of encryption\n\nDefinition 21.1 says nothing about the security of \\(E\\) and \\(D\\), and even allows the trivial encryption scheme that ignores the key altogether and sets \\(E_k(x)=x\\) for every \\(x\\). Defining security is not a trivial matter.\n\nThroughout history, many attacks on cryptosystems were rooted in the cryptosystem designers’ reliance on “security through obscurity”— trusting that the fact their methods are not known to their enemy will protect them from being broken. This is a faulty assumption - if you reuse a method again and again (even with a different key each time) then eventually your adversaries will figure out what you are doing. And if Alice and Bob meet frequently in a secure location to decide on a new method, they might as well take the opportunity to exchange their secrets. These considerations led Auguste Kerckhoffs in 1883 to state the following principle:\n\nA cryptosystem should be secure even if everything about the system, except the key, is public knowledge.2\n\nWhy is it OK to assume the key is secret and not the algorithm? Because we can always choose a fresh key. But of course that won’t help us much if our key is “1234” or “passw0rd!”. In fact, if you use any deterministic algorithm to choose the key then eventually your adversary will figure this out. Therefore for security we must choose the key at random and can restate Kerckhoffs’s principle as follows:\n\nThere is no secrecy without randomness\n\nThis is such a crucial point that is worth repeating:\n\nThere is no secrecy without randomness.\n\nAt the heart of every cryptographic scheme there is a secret key, and the secret key is always chosen at random. A corollary of that is that to understand cryptography, you need to know probability theory.\n\nPerfect secrecy\n\nIf you think about encryption scheme security for a while, you might come up with the following principle for defining security: “An encryption scheme is secure if it is not possible to recover the key \\(k\\) from \\(E_k(x)\\)”. However, a moment’s thought shows that the key is not really what we’re trying to protect. After all, the whole point of an encryption is to protect the confidentiality of the plaintext \\(x\\). So, we can try to define that “an encryption scheme is secure if it is not possible to recover the plaintext \\(x\\) from \\(E_k(x)\\)”. Yet it is not clear what this means either. Suppose that an encryption scheme reveals the first 10 bits of the plaintext \\(x\\). It might still not be possible to recover \\(x\\) completely, but on an intuitive level, this seems like it would be extremely unwise to use such an encryption scheme in practice. Indeed, often even partial information about the plaintext is enough for the adversary to achieve its goals.\n\nThe above thinking led Shannon in 1945 to formalize the notion of perfect secrecy, which is that an encryption reveals absolutely nothing about the message. There are several equivalent ways to define it, but perhaps the cleanest one is the following:\n\nExample: Perfect secrecy in the battlefield\n\nTo understand Definition 21.3, suppose that Alice sends only one of two possible messages: “attack” or “retreat”, which we denote by \\(x_0\\) and \\(x_1\\) respectively, and that she sends each one of those messages with probability \\(1/2\\). Let us put ourselves in the shoes of Eve, the eavesdropping adversary. A priori we would have guessed that Alice sent either \\(x_0\\) or \\(x_1\\) with probability \\(1/2\\). Now we observe \\(y=E_k(x_i)\\) where \\(k\\) is a uniformly chosen key in \\(\\{0,1\\}^n\\). How does this new information cause us to update our beliefs on whether Alice sent the plaintext \\(x_0\\) or the plaintext \\(x_1\\)?\n\nLet us define \\(p_0(y)\\) to be the probability (taken over \\(k\\sim \\{0,1\\}^n\\)) that \\(y=E_k(x_0)\\) and similarly \\(p_1(y)\\) to be \\(\\Pr_{k \\sim \\{0,1\\}^n}[y=E_k(x_1)]\\). Note that, since Alice chooses the message to send at random, our a priori probability for observing \\(y\\) is \\(\\tfrac{1}{2}p_0(y) + \\tfrac{1}{2}p_1(y)\\). However, as per Definition 21.3, the perfect secrecy condition guarantees that \\(p_0(y)=p_1(y)\\)! Let us denote the number \\(p_0(y)=p_1(y)\\) by \\(p\\). By the formula for conditional probability, the probability that Alice sent the message \\(x_0\\) conditioned on our observation \\(y\\) is simply\n\n\\[ \\Pr[i=0 | y=E_k(x_i)] = \\frac{\\Pr[i=0 \\wedge y = E_k(x_i)]}{\\Pr[y = E_k(x)]} \\;. \\;\\;(21.2) \\]\n\n(The equation Equation 21.2 is a special case of Bayes’ rule which, although a simple restatement of the formula for conditional probability, is an extremely important and widely used tool in statistics and data analysis.)\n\nSince the probability that \\(i=0\\) and \\(y\\) is the ciphertext \\(E_k(0)\\) is equal to \\(\\tfrac{1}{2}\\cdot p_0(y)\\), and the a priori probability of observing \\(y\\) is \\(\\tfrac{1}{2}p_0(y) + \\tfrac{1}{2}p_1(y)\\), we can rewrite Equation 21.2 as\n\n\\[ \\Pr[i=0 | y=E_k(x_i)] = \\frac{\\tfrac{1}{2}p_0(y)}{\\tfrac{1}{2}p_0(y)+\\tfrac{1}{2}p_1(y)} = \\frac{p}{p +p} = \\frac{1}{2} \\]\n\nusing the fact that \\(p_0(y)=p_1(y)=p\\). This means that observing the ciphertext \\(y\\) did not help us at all! We still would not be able to guess whether Alice sent “attack” or “retreat” with better than 50/50 odds!\n\nThis example can be vastly generalized to show that perfect secrecy is indeed “perfect” in the sense that observing a ciphertext gives Eve no additional information about the plaintext beyond her a priori knowledge.\n\nConstructing perfectly secret encryption\n\nPerfect secrecy is an extremely strong condition, and implies that an eavesdropper does not learn any information from observing the ciphertext. You might think that an encryption scheme satisfying such a strong condition will be impossible, or at least extremely complicated, to achieve. However it turns out we can in fact obtain a perfectly secret encryption scheme fairly easily. Such a scheme for two-bit messages is illustrated in Figure 21.8.\n\nIn fact, this can be generalized to any number of bits:\n\nNecessity of long keys\n\nSo, does Theorem 21.4 give the final word on cryptography, and means that we can all communicate with perfect secrecy and live happily ever after? No it doesn’t. While the one-time pad is efficient, and gives perfect secrecy, it has one glaring disadvantage: to communicate \\(n\\) bits you need to store a key of length \\(n\\). In contrast, practically used cryptosystems such as AES-128 have a short key of \\(128\\) bits (i.e., \\(16\\) bytes) that can be used to protect terabytes or more of communication! Imagine that we all needed to use the one time pad. If that was the case, then if you had to communicate with \\(m\\) people, you would have to maintain (securely!) \\(m\\) huge files that are each as long as the length of the maximum total communication you expect with that person. Imagine that every time you opened an account with Amazon, Google, or any other service, they would need to send you in the mail (ideally with a secure courier) a DVD full of random numbers, and every time you suspected a virus, you’d need to ask all these services for a fresh DVD. This doesn’t sound so appealing.\n\nThis is not just a theoretical issue. The Soviets have used the one-time pad for their confidential communication since before the 1940’s. In fact, even before Shannon’s work, the U.S. intelligence already knew in 1941 that the one-time pad is in principle “unbreakable” (see page 32 in the Venona document). However, it turned out that the hassle of manufacturing so many keys for all the communication took its toll on the Soviets and they ended up reusing the same keys for more than one message. They did try to use them for completely different receivers in the (false) hope that this wouldn’t be detected. The Venona Project of the U.S. Army was founded in February 1943 by Gene Grabeel (see Figure 21.10), a former home economics teacher from Madison Heights, Virgnia and Lt. Leonard Zubko. In October 1943, they had their breakthrough when it was discovered that the Russians were reusing their keys. In the 37 years of its existence, the project has resulted in a treasure chest of intelligence, exposing hundreds of KGB agents and Russian spies in the U.S. and other countries, including Julius Rosenberg, Harry Gold, Klaus Fuchs, Alger Hiss, Harry Dexter White and many others.\n\nUnfortunately it turns out that such long keys are necessary for perfect secrecy:\n\nComputational secrecy\n\nTo sum up the previous episodes, we now know that:\n\nIt is possible to obtain a perfectly secret encryption scheme with key length the same as the plaintext.\n\nand\n\nIt is not possible to obtain such a scheme with key that is even a single bit shorter than the plaintext.\n\nHow does this mesh with the fact that, as we’ve already seen, people routinely use cryptosystems with a 16 byte (i.e., 128 bit) key but many terabytes of plaintext? The proof of Theorem 21.5 does give in fact a way to break all these cryptosystems, but an examination of this proof shows that it only yields an algorithm with time exponential in the length of the key. This motivates the following relaxation of perfect secrecy to a condition known as “computational secrecy”. Intuitively, an encryption scheme is computationally secret if no polynomial time algorithm can break it. The formal definition is below:\n\nDefinition 21.6 raises two natural questions:\n\nIs it strong enough to ensure that a computationally secret encryption scheme protects the secrecy of messages that are encrypted with it?\n\nIt is weak enough that, unlike perfect secrecy, it is possible to obtain a computationally secret encryption scheme where the key is much smaller than the message?\n\nTo the best of our knowledge, the answer to both questions is Yes. This is just one example of a much broader phenomenon. We can use computational hardness to achieve many cryptographic goals, including some goals that have been dreamed about for millenia, and other goals that people have not even dared to imagine.\n\nComputational hardness is necessary and sufficient for almost all cryptographic applications.\n\nRegarding the first question, it is not hard to show that if, for example, Alice uses a computationally secret encryption algorithm to encrypt either “attack” or “retreat” (each chosen with probability \\(1/2\\)), then as long as she’s restricted to polynomial-time algorithms, an adversary Eve will not be able to guess the message with probability better than, say, \\(0.51\\), even after observing its encrypted form. (We omit the proof, but it is an excellent exercise for you to work it out on your own.)\n\nTo answer the second question we will show that under the same assumption we used for derandomizing \\(\\mathbf{BPP}\\), we can obtain a computationally secret cryptosystem where the key is almost exponentially smaller than the plaintext.\n\nStream ciphers or the “derandomized one-time pad”\n\nIt turns out that if pseudorandom generators exist as in the optimal PRG conjecture, then there exists a computationally secret encryption scheme with keys that are much shorter than the plaintext. The construction below is known as a stream cipher, though perhaps a better name is the “derandomized one-time pad”. It is widely used in practice with keys on the order of a few tens or hundreds of bits protecting many terabytes or even petabytes of communication.\n\nWe start by recalling the notion of a pseudorandom generator, as defined in Definition 20.9. For this chapter, we will fix a special case of the definition:\n\nIn this chapter we will call a cryptographic pseudorandom generator simply a pseudorandom generator or PRG for short. The optimal PRG conjecture of Section 20.4.2 implies that there is a pseudorandom generator that can “fool” circuits of exponential size and where the gap in probabilities is at most one over an exponential quantity. Since exponential grow faster than every polynomial, the optimal PRG conjecture implies the following:\n\nThe crypto PRG conjecture: For every \\(a \\in \\N\\), there is a cryptographic pseudorandom generator with \\(L(n)=n^a\\).\n\nThe crypto PRG conjecture is a weaker conjecture than the optimal PRG conjecture, but it too (as we will see) is still stronger than the conjecture that \\(\\mathbf{P} \\neq \\mathbf{NP}\\).\n\nComputational secrecy and \\(\\mathbf{NP}\\)\n\nWe’ve also mentioned before that an efficient algorithm for \\(\\mathbf{NP}\\) could be used to break all cryptography. We now give an example of how this can be done:\n\nNote that the “furthermore” part is extremely strong. It means that if the plaintext is even a little bit larger than the key, then we can already break the scheme in a very strong way. That is, there will be a pair of messages \\(x_0\\), \\(x_1\\) (think of \\(x_0\\) as “sell” and \\(x_1\\) as “buy”) and an efficient strategy for Eve such that if Eve gets a ciphertext \\(y\\) then she will be able to tell whether \\(y\\) is an encryption of \\(x_0\\) or \\(x_1\\) with probability very close to \\(1\\). (We model breaking the scheme as Eve outputting \\(0\\) or \\(1\\) corresponding to whether the message sent was \\(x_0\\) or \\(x_1\\). Note that we could have just as well modified Eve to output \\(x_0\\) instead of \\(0\\) and \\(x_1\\) instead of \\(1\\). The key point is that a priori Eve only had a 50/50 chance of guessing whether Alice sent \\(x_0\\) or \\(x_1\\) but after seeing the ciphertext this chance increases to better than 99/100.) The condition \\(\\mathbf{P}=\\mathbf{NP}\\) can be relaxed to \\(\\mathbf{NP}\\subseteq \\mathbf{BPP}\\) and even the weaker condition \\(\\mathbf{NP} \\subseteq \\mathbf{P_{/poly}}\\) with essentially the same proof.\n\nIn retrospect Theorem 21.10 is perhaps not surprising. After all, as we’ve mentioned before it is known that the Optimal PRG conjecture (which is the basis for the derandomized one-time pad encryption) is false if \\(\\mathbf{P}=\\mathbf{NP}\\) (and in fact even if \\(\\mathbf{NP}\\subseteq \\mathbf{BPP}\\) or even \\(\\mathbf{NP} \\subseteq \\mathbf{P_{/poly}}\\)).\n\nPublic key cryptography\n\nPeople have been dreaming about heavier-than-air flight since at least the days of Leonardo Da Vinci (not to mention Icarus from the greek mythology). Jules Verne wrote with rather insightful details about going to the moon in 1865. But, as far as I know, in all the thousands of years people have been using secret writing, until about 50 years ago no one has considered the possibility of communicating securely without first exchanging a shared secret key.\n\nYet in the late 1960’s and early 1970’s, several people started to question this “common wisdom”. Perhaps the most surprising of these visionaries was an undergraduate student at Berkeley named Ralph Merkle. In the fall of 1974 Merkle wrote in a project proposal for his computer security course that while “it might seem intuitively obvious that if two people have never had the opportunity to prearrange an encryption method, then they will be unable to communicate securely over an insecure channel… I believe it is false”. The project proposal was rejected by his professor as “not good enough”. Merkle later submitted a paper to the communication of the ACM where he apologized for the lack of references since he was unable to find any mention of the problem in the scientific literature, and the only source where he saw the problem even raised was in a science fiction story. The paper was rejected with the comment that “Experience shows that it is extremely dangerous to transmit key information in the clear.” Merkle showed that one can design a protocol where Alice and Bob can use \\(T\\) invocations of a hash function to exchange a key, but an adversary (in the random oracle model, though he of course didn’t use this name) would need roughly \\(T^2\\) invocations to break it. He conjectured that it may be possible to obtain such protocols where breaking is exponentially harder than using them, but could not think of any concrete way to doing so.\n\nWe only found out much later that in the late 1960’s, a few years before Merkle, James Ellis of the British Intelligence agency GCHQ was having similar thoughts. His curiosity was spurred by an old World-War II manuscript from Bell Labs that suggested the following way that two people could communicate securely over a phone line. Alice would inject noise to the line, Bob would relay his messages, and then Alice would subtract the noise to get the signal. The idea is that an adversary over the line sees only the sum of Alice’s and Bob’s signals, and doesn’t know what came from what. This got James Ellis thinking whether it would be possible to achieve something like that digitally. As Ellis later recollected, in 1970 he realized that in principle this should be possible, since he could think of an hypothetical black box \\(B\\) that on input a “handle” \\(\\alpha\\) and plaintext \\(x\\) would give a “ciphertext” \\(y\\) and that there would be a secret key \\(\\beta\\) corresponding to \\(\\alpha\\), such that feeding \\(\\beta\\) and \\(y\\) to the box would recover \\(x\\). However, Ellis had no idea how to actually instantiate this box. He and others kept giving this question as a puzzle to bright new recruits until one of them, Clifford Cocks, came up in 1973 with a candidate solution loosely based on the factoring problem; in 1974 another GCHQ recruit, Malcolm Williamson, came up with a solution using modular exponentiation.\n\nBut among all those thinking of public key cryptography, probably the people who saw the furthest were two researchers at Stanford, Whit Diffie and Martin Hellman. They realized that with the advent of electronic communication, cryptography would find new applications beyond the military domain of spies and submarines, and they understood that in this new world of many users and point to point communication, cryptography will need to scale up. Diffie and Hellman envisioned an object which we now call “trapdoor permutation” though they called “one way trapdoor function” or sometimes simply “public key encryption”. Though they didn’t have full formal definitions, their idea was that this is an injective function that is easy (e.g., polynomial-time) to compute but hard (e.g., exponential-time) to invert. However, there is a certain trapdoor, knowledge of which would allow polynomial time inversion. Diffie and Hellman argued that using such a trapdoor function, it would be possible for Alice and Bob to communicate securely without ever having exchanged a secret key. But they didn’t stop there. They realized that protecting the integrity of communication is no less important than protecting its secrecy. Thus they imagined that Alice could “run encryption in reverse” in order to certify or sign messages.\n\nAt the point, Diffie and Hellman were in a position not unlike physicists who predicted that a certain particle should exist but without any experimental verification. Luckily they met Ralph Merkle, and his ideas about a probabilistic key exchange protocol, together with a suggestion from their Stanford colleague John Gill, inspired them to come up with what today is known as the Diffie Hellman Key Exchange (which unbeknownst to them was found two years earlier at GCHQ by Malcolm Williamson). They published their paper “New Directions in Cryptography” in 1976, and it is considered to have brought about the birth of modern cryptography.\n\nThe Diffie-Hellman Key Exchange is still widely used today for secure communication. However, it still felt short of providing Diffie and Hellman’s elusive trapdoor function. This was done the next year by Rivest, Shamir and Adleman who came up with the RSA trapdoor function, which through the framework of Diffie and Hellman yielded not just encryption but also signatures. (A close variant of the RSA function was discovered earlier by Clifford Cocks at GCHQ, though as far as I can tell Cocks, Ellis and Williamson did not realize the application to digital signatures.) From this point on began a flurry of advances in cryptography which hasn’t died down till this day.\n\nDefining public key encryption\n\nA public key encryption consists of a triple of algorithms:\n\nThe key generation algorithm, which we denote by \\(KeyGen\\) or \\(\\ensuremath{\\mathit{KG}}\\) for short, is a randomized algorithm that outputs a pair of strings \\((e,d)\\) where \\(e\\) is known as the public (or encryption) key, and \\(d\\) is known as the private (or decryption) key. The key generation algorithm gets as input \\(1^n\\) (i.e., a string of ones of length \\(n\\)). We refer to \\(n\\) as the security parameter of the scheme. The bigger we make \\(n\\), the more secure the encryption will be, but also the less efficient it will be.\n\nThe encryption algorithm, which we denote by \\(E\\), takes the encryption key \\(e\\) and a plaintext \\(x\\), and outputs the ciphertext \\(y=E_e(x)\\).\n\nThe decryption algorithm, which we denote by \\(D\\), takes the decryption key \\(d\\) and a ciphertext \\(y\\), and outputs the plaintext \\(x=D_d(y)\\).\n\nWe now make this a formal definition:\n\nDefinition 21.11 allows \\(E\\) and \\(D\\) to be randomized algorithms. In fact, it turns out that it is necessary for \\(E\\) to be randomized to obtain computational secrecy. It also turns out that, unlike the private key case, we can transform a public-key encryption that works for messages that are only one bit long into a public-key encryption scheme that can encrypt arbitrarily long messages, and in particular messages that are longer than the key. In particular this means that we cannot obtain a perfectly secret public-key encryption scheme even for one-bit long messages (since it would imply a perfectly secret public-key, and hence in particular private-key, encryption with messages longer than the key).\n\nWe will not give full constructions for public key encryption schemes in this chapter, but will mention some of the ideas that underlie the most widely used schemes today. These generally belong to one of two families:\n\nGroup theoretic constructions based on problems such as integer factoring and the discrete logarithm over finite fields or elliptic curves.\n\nLattice/coding based constructions based on problems such as the closest vector in a lattice or bounded distance decoding.\n\nGroup-theory based encryptions such as the RSA cryptosystem, the Diffie-Hellman protocol, and Elliptic-Curve Cryptography, are currently more widely implemented. But the lattice/coding schemes are recently on the rise, particularly because the known group theoretic encryption schemes can be broken by quantum computers, which we discuss in Chapter 23.\n\nDiffie-Hellman key exchange\n\nAs just one example of how public key encryption schemes are constructed, let us now describe the Diffie-Hellman key exchange. We describe the Diffie-Hellman protocol in a somewhat of an informal level, without presenting a full security analysis.\n\nThe computational problem underlying the Diffie Hellman protocol is the discrete logarithm problem. Let’s suppose that \\(g\\) is some integer. We can compute the map \\(x \\mapsto g^x\\) and also its inverse \\(y \\mapsto \\log_g y\\). (For example, we can compute a logarithm is by binary search: start with some interval \\([x_{min},x_{max}]\\) that is guaranteed to contain \\(\\log_g y\\). We can then test whether the interval’s midpoint \\(x_{mid}\\) satisfies \\(g^{x_{mid}} > y\\), and based on that halve the size of the interval.)\n\nHowever, suppose now that we use modular arithmetic and work modulo some prime number \\(p\\). If \\(p\\) has \\(n\\) binary digits and \\(g\\) is in \\([p]\\) then we can compute the map \\(x \\mapsto g^x \\mod p\\) in time polynomial in \\(n\\). (This is not trivial, and is a great exercise for you to work this out; as a hint, start by showing that one can compute the map \\(k \\mapsto g^{2^k} \\mod p\\) using \\(k\\) modular multiplications modulo \\(p\\), if you’re stumped, you can look up this Wikipedia entry.) On the other hand, because of the “wraparound” property of modular arithmetic, we cannot run binary search to find the inverse of this map (known as the discrete logarithm). In fact, there is no known polynomial-time algorithm for computing this discrete logarithm map \\((g,x,p) \\mapsto \\log_g x \\mod p\\), where we define \\(\\log_g x \\mod p\\) as the number \\(a \\in [p]\\) such that \\(g^a = x \\mod p\\).\n\nThe Diffie-Hellman protocol for Bob to send a message to Alice is as follows:\n\nAlice: Chooses \\(p\\) to be a random \\(n\\) bit long prime (which can be done by choosing random numbers and running a primality testing algorithm on them), and \\(g\\) and \\(a\\) at random in \\([p]\\). She sends to Bob the triple \\((p,g,g^a \\mod p)\\).\n\nBob: Given the triple \\((p,g,h)\\), Bob sends a message \\(x \\in \\{0,1\\}^L\\) to Alice by choosing \\(b\\) at random in \\([p]\\), and sending to Alice the pair \\((g^b \\mod p, rep(h^b \\mod p) \\oplus x)\\) where \\(rep:[p] \\rightarrow \\{0,1\\}^*\\) is some “representation function” that maps \\([p]\\) to \\(\\{0,1\\}^L\\). (The function \\(rep\\) does not need to be one-to-one and you can think of \\(rep(z)\\) as simply outputting \\(L\\) of the bits of \\(z\\) in the natural binary representation, it does need to satisfy certain technical conditions which we omit in this description.)\n\nAlice: Given \\(g',z\\), Alice recovers \\(x\\) by outputting \\(rep(g'^a \\mod p) \\oplus z\\).\n\nThe correctness of the protocol follows from the simple fact that \\((g^a)^b = (g^b)^a\\) for every \\(g,a,b\\) and this still holds if we work modulo \\(p\\). Its security relies on the computational assumption that computing this map is hard, even in a certain “average case” sense (this computational assumption is known as the Decisional Diffie Hellman assumption). The Diffie-Hellman key exchange protocol can be thought of as a public key encryption where Alice’s first message is the public key, and Bob’s message is the encryption.\n\nOne can think of the Diffie-Hellman protocol as being based on a “trapdoor pseudorandom generator” where the triple \\(g^a,g^{b},g^{ab}\\) looks “random” to someone that doesn’t know \\(a\\), but someone that does know \\(a\\) can see that raising the second element to the \\(a\\)-th power yields the third element. The Diffie-Hellman protocol can be described abstractly in the context of any finite Abelian group for which we can efficiently compute the group operation. It has been implemented on other groups than numbers modulo \\(p\\), and in particular Elliptic Curve Cryptography (ECC) is obtained by basing the Diffie Hellman on elliptic curve groups which gives some practical advantages. Another common group theoretic basis for key-exchange/public key encryption protocol is the RSA function. A big disadvantage of Diffie-Hellman (both the modular arithmetic and elliptic curve variants) and RSA is that both schemes can be broken in polynomial time by a quantum computer. We will discuss quantum computing later in this course.\n\nOther security notions\n\nThere is a great deal to cryptography beyond just encryption schemes, and beyond the notion of a passive adversary. A central objective is integrity or authentication: protecting communications from being modified by an adversary. Integrity is often more fundamental than secrecy: whether it is a software update or viewing the news, you might often not care about the communication being secret as much as that it indeed came from its claimed source. Digital signature schemes are the analog of public key encryption for authentication, and are widely used (in particular as the basis for public key certificates) to provide a foundation of trust in the digital world.\n\nSimilarly, even for encryption, we often need to ensure security against active attacks, and so notions such as non-malleability and adaptive chosen ciphertext security have been proposed. An encryption scheme is only as secure as the secret key, and mechanisms to make sure the key is generated properly, and is protected against refresh or even compromise (i.e., forward secrecy) have been studied as well. Hopefully this chapter provides you with some appreciation for cryptography as an intellectual field, but does not imbue you with a false self confidence in implementing it.\n\nCryptographic hash functions are another widely used tool with a variety of uses, including extracting randomness from high entropy sources, achieving hard-to-forge short “digests” of files, protecting passwords, and much more.\n\nMagic\n\nBeyond encryption and signature schemes, cryptographers have managed to obtain objects that truly seem paradoxical and “magical”. We briefly discuss some of these objects. We do not give any details, but hopefully this will spark your curiosity to find out more.\n\nZero knowledge proofs\n\nOn October 31, 1903, the mathematician Frank Nelson Cole gave an hourlong lecture to a meeting of the American Mathematical Society where he did not speak a single word. Rather, he calculated on the board the value \\(2^{67}-1\\) which is equal to \\(147,573,952,589,676,412,927\\), and then showed that this number is equal to \\(193,707,721 \\times 761,838,257,287\\). Cole’s proof showed that \\(2^{67}-1\\) is not a prime, but it also revealed additional information, namely its actual factors. This is often the case with proofs: they teach us more than just the validity of the statements.\n\nIn Zero Knowledge Proofs we try to achieve the opposite effect. We want a proof for a statement \\(X\\) where we can rigorously show that the proofs reveals absolutely no additional information about \\(X\\) beyond the fact that it is true. This turns out to be an extremely useful object for a variety of tasks including authentication, secure protocols, voting, anonymity in cryptocurrencies, and more. Constructing these objects relies on the theory of \\(\\mathbf{NP}\\) completeness. Thus this theory that originally was designed to give a negative result (show that some problems are hard) ended up yielding positive applications, enabling us to achieve tasks that were not possible otherwise.\n\nFully homomorphic encryption\n\nSuppose that we are given a bit-by-bit encryption of a string \\(E_k(x_0),\\ldots,E_k(x_{n-1})\\). By design, these ciphertexts are supposed to be “completely unscrutable” and we should not be able to extract any information about \\(x_i\\)’s from it. However, already in 1978, Rivest, Adleman and Dertouzos observed that this does not imply that we could not manipulate these encryptions. For example, it turns out the security of an encryption scheme does not immediately rule out the ability to take a pair of encryptions \\(E_k(a)\\) and \\(E_k(b)\\) and compute from them \\(E_k(a \\ensuremath{\\mathit{NAND}} b)\\) without knowing the secret key \\(k\\). But do there exist encryption schemes that allow such manipulations? And if so, is this a bug or a feature?\n\nRivest et al already showed that such encryption schemes could be immensely useful, and their utility has only grown in the age of cloud computing. After all, if we can compute NAND then we can use this to run any algorithm \\(P\\) on the encrypted data, and map \\(E_k(x_0),\\ldots,E_k(x_{n-1})\\) to \\(E_k(P(x_0,\\ldots,x_{n-1}))\\). For example, a client could store their secret data \\(x\\) in encrypted form on the cloud, and have the cloud provider perform all sorts of computation on these data without ever revealing to the provider the private key, and so without the provider ever learning any information about the secret data.\n\nThe question of existence of such a scheme took much longer time to resolve. Only in 2009 Craig Gentry gave the first construction of an encryption scheme that allows to compute a universal basis of gates on the data (known as a Fully Homomorphic Encryption scheme in crypto parlance). Gentry’s scheme left much to be desired in terms of efficiency, and improving upon it has been the focus of an intensive research program that has already seen significant improvements.\n\nMultiparty secure computation\n\nCryptography is about enabling mutually distrusting parties to achieve a common goal. Perhaps the most general primitive achieving this objective is secure multiparty computation. The idea in secure multiparty computation is that \\(n\\) parties interact together to compute some function \\(F(x_0,\\ldots,x_{n-1})\\) where \\(x_i\\) is the private input of the \\(i\\)-th party. The crucial point is that there is no commonly trusted party or authority and that nothing is revealed about the secret data beyond the function’s output. One example is an electronic voting protocol where only the total vote count is revealed, with the privacy of the individual voters protected, but without having to trust any authority to either count the votes correctly or to keep information confidential. Another example is implementing a second price (aka Vickrey) auction where \\(n-1\\) parties submit bids to an item owned by the \\(n\\)-th party, and the item goes to the highest bidder but at the price of the second highest bid. Using secure multiparty computation we can implement second price auction in a way that will ensure the secrecy of the numerical values of all bids (including even the top one) except the second highest one, and the secrecy of the identity of all bidders (including even the second highest bidder) except the top one. We emphasize that such a protocol requires no trust even in the auctioneer itself, who will also not learn any additional information. Secure multiparty computation can be used even for computing randomized processes, with one example being playing Poker over the net without having to trust any server for correct shuffling of cards or not revealing the information.\n\nExercises\n\nBibliographical notes\n\nMuch of this text is taken from my lecture notes on cryptography.\n\nShannon’s manuscript was written in 1945 but was classified, and a partial version was only published in 1949. Still it has revolutionized cryptography, and is the forerunner to much of what followed.\n\nThe Venona project’s history is described in this document. Aside from Grabeel and Zubko, credit to the discovery that the Soviets were reusing keys is shared by Lt. Richard Hallock, Carrie Berry, Frank Lewis, and Lt. Karl Elmquist, and there are others that have made important contribution to this project. See pages 27 and 28 in the document.\n\nIn a 1955 letter to the NSA that only recently came forward, John Nash proposed an “unbreakable” encryption scheme. He wrote “I hope my handwriting, etc. do not give the impression I am just a crank or circle-squarer…. The significance of this conjecture [that certain encryption schemes are exponentially secure against key recovery attacks] .. is that it is quite feasible to design ciphers that are effectively unbreakable.”. John Nash made seminal contributions in mathematics and game theory, and was awarded both the Abel Prize in mathematics and the Nobel Memorial Prize in Economic Sciences. However, he has struggled with mental illness throughout his life. His biography, A Beautiful Mind was made into a popular movie. It is natural to compare Nash’s 1955 letter to the NSA to Gödel’s letter to von Neumann we mentioned before. From the theoretical computer science point of view, the crucial difference is that while Nash informally talks about exponential vs polynomial computation time, he does not mention the word “Turing machine” or other models of computation, and it is not clear if he is aware or not that his conjecture can be made mathematically precise (assuming a formalization of “sufficiently complex types of enciphering”).\n\nThe definition of computational secrecy we use is the notion of computational indistinguishability (known to be equivalent to semantic security) that was given by Goldwasser and Micali in 1982.\n\nAlthough they used a different terminology, Diffie and Hellman already made clear in their paper that their protocol can be used as a public key encryption, with the first message being put in a “public file”. In 1985, ElGamal showed how to obtain a signature scheme based on the Diffie Hellman ideas, and since he described the Diffie-Hellman encryption scheme in the same paper, the public key encryption scheme originally proposed by Diffie and Hellman is sometimes also known as ElGamal encryption.\n\nMy survey contains a discussion on the different types of public key assumptions. While the standard elliptic curve cryptographic schemes are as susceptible to quantum computers as Diffie-Hellman and RSA, their main advantage is that the best known classical algorithms for computing discrete logarithms over elliptic curve groups take time \\(2^{\\epsilon n}\\) for some \\(\\epsilon>0\\) where \\(n\\) is the number of bits to describe a group element. In contrast, for the multiplicative group modulo a prime \\(p\\) the best algorithm take time \\(2^{O(n^{1/3} polylog(n))}\\) which means that (assuming the known algorithms are optimal) we need to set the prime to be bigger (and so have larger key sizes with corresponding overhead in communication and computation) to get the same level of security.\n\nZero-knowledge proofs were constructed by Goldwasser, Micali, and Rackoff in 1982, and their wide applicability was shown (using the theory of \\(\\mathbf{NP}\\) completeness) by Goldreich, Micali, and Wigderson in 1986.\n\nTwo party and multiparty secure computation protocols were constructed (respectively) by Yao in 1982 and Goldreich, Micali, and Wigderson in 1987. The latter work gave a general transformation from security against passive adversaries to security against active adversaries using zero knowledge proofs.\n\nComments are posted on the GitHub repository using the utteranc.es app. A GitHub login is required to comment. If you don't want to authorize the app to post on your behalf, you can also comment directly on the GitHub issue for this page.\n\nCompiled on 12/06/2023 00:06:49\n\nCopyright 2023, Boaz Barak.\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
    }
}