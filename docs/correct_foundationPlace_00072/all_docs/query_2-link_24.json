{
    "id": "correct_foundationPlace_00072_2",
    "rank": 24,
    "data": {
        "url": "https://sites.google.com/ualberta.ca/ai-seminar/past-seminars/2022",
        "read_more_link": "",
        "language": "en",
        "title": "AI Seminar Intranet",
        "top_image": "https://lh6.googleusercontent.com/J8ZrNA5atKKyc0rDOL8VRFj_GCzYnUXLCu47cgQ9NJi8t_S-XdTwHw4ItvUiuFJ32jNoYsuBIqIScpj9gfoI0xE=w16383",
        "meta_img": "https://lh6.googleusercontent.com/J8ZrNA5atKKyc0rDOL8VRFj_GCzYnUXLCu47cgQ9NJi8t_S-XdTwHw4ItvUiuFJ32jNoYsuBIqIScpj9gfoI0xE=w16383",
        "images": [
            "https://lh6.googleusercontent.com/J8ZrNA5atKKyc0rDOL8VRFj_GCzYnUXLCu47cgQ9NJi8t_S-XdTwHw4ItvUiuFJ32jNoYsuBIqIScpj9gfoI0xE=w16383",
            "https://lh6.googleusercontent.com/J8ZrNA5atKKyc0rDOL8VRFj_GCzYnUXLCu47cgQ9NJi8t_S-XdTwHw4ItvUiuFJ32jNoYsuBIqIScpj9gfoI0xE=w16383"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "All available AI Seminar Recordings are posted on the Amii Youtube Channel. \u000bThey can also be accessed by clicking on the individual presentation titles below.",
        "meta_lang": "en",
        "meta_favicon": "https://ssl.gstatic.com/atari/images/public/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://sites.google.com/ualberta.ca/ai-seminar/past-seminars/2022",
        "text": "YouTube Video Coming Soon!\n\nAbstract:\n\nMany breakthroughs in one field are inspired by others. For example, neural networks are inspired by the structure and function of the human brain, and attention mechanisms borrow the idea from psychology. In this talk, we will present our recent findings in natural language processing inspired by the laws of human cognition, such as knowledge fusion, systematic generalization, and imitation learning. In the first one, we propose a plug-in framework called RoChBert to build a more robust language model explicitly for Chinese. By incorporating adversarial knowledge, we show how to fuse the necessary phonetic and glyph information into pre-trained representations to strengthen the robustness. In the next one, we investigate the extent to which neural networks can do the same as humans to generalize from old concepts to new ones systematically. We revisit this controversial topic from the perspective of meaningful learning, a concept from educational psychology. Our experimental results indicate that conventional sequence-to-sequence models can successfully one-shot generalize to novel concepts and compositions through shared semantic relationships, either inductively or deductively. In the last one, we reformulate text editing as an imitation game using behavioral cloning. Specifically, we convert standard sequence-to-sequence data into state-to-action demonstrations and propose to train an agent to mimic how humans revise texts iteratively, where the action space can be as flexible as needed. Overall, we hope this presentation will encourage and shed light on future studies at the junction of multiple fields.\n\nPresenter Bio:\n\nNing Shi is a 1st-year Ph.D. student working with Prof. Grzegorz Kondrak at the University of Alberta, associated with Alberta Machine Intelligence Institute (Amii). Previously, he was a senior algorithm engineer at Alibaba Group and a machine learning engineer at Learnable. Ning received an M.S. degree in Computer Science at the Georgia Institute of Technology, an M.S. degree in Applied Data Science at Syracuse University, an M.S. degree in Management and Systems at New York University, and a B.Mgt. degree in E-commerce at Donghua University. His current research interests primarily stand on computational linguistics and natural language processing at the junction of human cognition.\n\nhttps://www.youtube.com/watch?v=4_YmJrGsexw&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=26\n\nAbstract:\n\nAlgorithmic fairness has received increased attention in socially sensitive domains. While rich literature on mean fairness has been established, research on quantile fairness remains sparse but vital. To fulfill great needs and advocate the significance of quantile fairness, we propose a novel framework to learn a real-valued quantile function under the fairness requirement of Demographic Parity with respect to sensitive attributes, such as race or gender, and thereby derive a reliable fair prediction interval. Using optimal transport and functional synchronization techniques, we establish theoretical guarantees of distribution-free coverage and exact fairness for the induced prediction interval constructed by fair quantiles. A hands-on pipeline is provided to incorporate flexible quantile regressions with an efficient fairness adjustment post-processing algorithm. We demonstrate the superior empirical performance of this approach on several benchmark datasets.\n\nPresenter Bio:\n\nDr. Linglong Kong is a professor in the Department of Mathematical and Statistical Sciences at the University of Alberta. He holds a Canada Research Chair in Statistical Learning, a Canada CIFAR AI Chair, and is a fellow of the Alberta Machine Intelligence Institute (AMII). His publication record includes more than 70 peer-reviewed articles in top journals such as AOS, JASA and JRSSB as well as top conferences such as NeurIPS, ICML, ICDM, AAAI, and IJCAI. Dr. Kong currently serves as associate editor of the Journal of the American Statistical Association, the Canadian Journal of Statistics, and Statistics and its Interface, as well as guest editor of Statistics and its Interface. Additionally, Dr. Kong is a member of the Executive Committee of the Western North American Region of the International Biometric Society, chair of the ASA Statistical Computing Session program, and chair of the webinar committee. He served as a guest editor of Canadian Journal of Statistics, associate editor of International Journal of Imaging Systems and Technology, guest associate editor of Frontiers of Neurosciences, chair of the ASA Statistical Imaging Session, and member of the Statistics Society of Canada's Board of Directors. He is interested in the analysis of high-dimensional and neuroimaging data, statistical machine learning, robust statistics and quantile regression, as well as artificial intelligence for smart health.\n\nhttps://www.youtube.com/watch?v=6yCqjuuj90g&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=25\n\nAbstract:\n\nBuilding and maintaining state to learn policies and value functions is critical for deploying reinforcement learning (RL) agents in the real world. Recurrent neural networks (RNNs) have become a key point of interest for the state-building problem, and several large-scale reinforcement learning agents incorporate recurrent networks. While RNNs have become a mainstay in many RL applications, many choices are often under-reported and contain critical implementation details to improve performance. In this talk, we discuss one axis on which RNN architectures can be (and have been) modified for use in RL. Specifically, we will investigate how action information incorporates into the state update function of a recurrent cell. While action as the focus presents as an intuitive choice, several lines of research in cognitive science highlight the importance of action in perception. We will discuss several architectural choices centered on action and empirically evaluate the resulting architectures on a set of illustrative domains. This empirical evaluation includes an analysis of the learned state in a prediction problem, behavioral experiments, and performance when observations take the form of images and agent-centric sensor readings. Finally, we will discuss future work in developing and analyzing recurrent cells and key challenges needing attention in the partially observable setting.\n\nPresenter Bio:\n\nMatthew Schlegel is a PhD candidate at University of Alberta in Edmonton, Alberta, Canada. I have a BS in Physics and an MS in Computer Science both from Indiana University Bloomington. My current PhD work is focused on reinforcement learning, and specifically in understanding how agents may perceive their world. I focus primarily on prediction making, but have been known to dabble in control from time-to-time. My active research interests include: predictions as a component in intelligence (both artificial and biological), off-policy prediction and policy evaluation, deep learning and resulting learned representations in the reinforcement learning context, and discovery or attention of important abstractions (described as predictions) through interaction.\n\nYouTube Video Coming Soon!\n\nAbstract:\n\nIn computational reinforcement learning, a growing body of work seeks to construct an agent's knowledge of the world through predictions of future sensations. This area of work, often referred to as Predictive Knowledge, is distinctive for its epistemic stance. More than a collection of machine learning methods, Predictive Knowledge positions itself as a theory of machine knowledge. In this talk, we challenge Predictive Knowledge’s perspective on truth: that an agent’s predictions are true knowledge if they can be verified by comparing the estimated value to what is observed by the agent. We then argue that the use of prediction estimates in further decision making is key to understanding the construction of knowledge in such systems. To explore this, we introduce a meta-gradient descent process by which an agent learns 1) what predictions to make, 2) the estimates for its chosen predictions, and 3) how to use those estimates to inform a control learner that maximizes future reward.\n\nPresenter Bio:\n\nAlex Kearney is a PhD candidate in the RLAI lab supervised by Patrick Pilarski and Rich Sutton. Her work is focused on how artificial intelligence agents can construct knowledge by deciding both what to learn and how to learn, with minimal designer instruction. She enjoys reading smelly old books & learning about interdisciplinary relationships between ideas. Alex recently took up skateboarding to spend more time outside, and she sometimes like to implement w3c social web specs for the indieweb.\n\nYouTube Video Coming Soon!\n\nAbstract:\n\nDecentralized consensus learning has been hugely successful, which minimizes a finite sum of expected objective functions over a network of nodes. However, the local communication across neighboring nodes in the network may lead to the leakage of private information. To address this challenge, we propose a general differentially private (DP) learning framework for decentralized data that applies to many non-smooth learning problems. We show that the proposed algorithm retains the performance guarantee in terms of stability, generalization, and finite sample performance. We investigate the impact of local privacy-preserving computation on the global DP guarantee. Further, we extend the discussion by adopting a new class of noise-adding DP mechanisms based on generalized Gaussian distributions to improve the utility-privacy trade-offs. Our numerical results demonstrate the effectiveness of our algorithm and its better performance over the state-of-the-art baseline methods in various decentralized settings.\n\nPresenter Bio:\n\nDr. Bei Jiang is an Associate Professor at the Department of Mathematical and Statistical Sciences of the University of Alberta and Fellow of the Alberta Machine Intelligence Institute (Amii). She received her PhD in Biostatistics in 2014 from University of Michigan. Prior to joining the University of Alberta in 2015 as an Assistant Professor, she was a postdoctoral researcher at the Department of Biostatistics at the Columbia University from 2014 to 2015. Her main research interests focus on statistical integration of multi-source and multi-modal data, and statistical disclosure control and learning methods for privacy protection. She has also worked closely with collaborators in women’s health, mental health, neurology, and industry partners to apply cutting-edge statistical learning methods to real-world applications.\n\nYouTube Video Coming Soon!\n\nAbstract:\n\nOn the 28th of September 2022, the EU Commission published its long awaited proposal for an AI Liability Directive, alongside with a proposal for a revised product liability law. The new AI Liability Directive is expected to complement the draft AI Act which had been proposed in February 2021 and, since then, has gained much attention even outside Europe. The presentation will give a very brief overview of the proposed Directives and then examine whether the AI Liability Directive will be able to meet the expectations (maybe not) and whether the underlying concepts are convincing (unfortunately, no). Interestingly, altogether, the proposed legislation would focus on the responsibility of the manufacturer of AI systems rather than that of the user.\n\nPresenter Bio:\n\nGeorg Borges is a Professor of Civil Law, Legal Informatics, German and International Business Law and Legal Theory and the managing director of the Institute for Legal Informatics at Saarland University, Germany. From 2004 to 2014, he was Professor of Law at Ruhr-University Bochum. Beside this, he was also a Judge at the State Court of Appeals, Hamm Circuit. As an expert on Business Law with a focus on IT Law, Prof. Borges authored several books and numerous articles in the field of IT law. His current research is related to artificial intelligence, internet of things and data protection law.\n\nhttps://www.youtube.com/watch?v=LF_kfiWP0aI&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=20\n\nAbstract:\n\nZero-Shot Relation Extraction (ZRE) is the task of Relation Extraction where the training and test sets have no shared relation types. This very challenging domain is a good test of a model's ability to generalize. Previous approaches to ZRE reframed relation extraction as Question Answering (QA), allowing for the use of pre-trained QA models. However, this method required manually creating gold question templates for each new relation. Here, we do away with these gold templates and instead learn a model that can generate questions for unseen relations. Our technique can successfully translate relation descriptions into relevant questions, which are then leveraged to generate the correct tail entity. On tail entity extraction, we outperform the previous state-of-the-art by more than 16 F1 points without using gold question templates. On the RE-QA dataset where no previous baseline for relation extraction exists, our proposed algorithm comes within 1.5 F1 points of a system that uses gold question templates. Our model also approaches the state-of-the-art ZRE performance on the FewRel dataset, showing that QA models no longer need template questions to match the performance of models specifically tailored to the ZRE task.\n\nPresenter Bio:\n\nSaeed Najafi is a second-year Ph.D. student at the University of Alberta advised by Dr. Alona Fyshe. He has a keen interest in modelling language through machine learning and studies Question-Answering methods during his Ph.D. research.\n\nhttps://www.youtube.com/watch?v=xGEgAIEoJgs&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=22\n\nAbstract:\n\nInfectious diseases are a leading cause of morbidity and mortality worldwide. One persistent challenge in the mitigation of infectious diseases is in the ability to accurately diagnose the etiology of infections using standard clinical diagnostics. Metagenomic next-generation sequencing (mNGS) has transformed disease surveillance by enabling the rapid, unbiased detection and identification of microbes without pathogen-specific reagents, culturing, or a priori knowledge of the microbial landscape. However, mNGS data analysis requires a series of computationally intensive processing steps to accurately determine the microbial composition of a sample and downstream processing to translate the multidimensional data into actionable information. In this talk, I will present work by our team to develop tools and facilitate trainings that enable researchers around the world to analyze mNGS data, gaining further insight into the microbial composition of diverse sample types. I will then discuss how these tools have been applied alongside a variety of machine learning techniques to improve the diagnosis of infections in two distinct patient cohorts. In an initial study, these tools were applied to a cohort of 92 adults with acute respiratory failure due to infectious and non-infectious causes and the development of logistic regression models enabled improved diagnosis of lower respiratory tract infection. In a recent follow-up study, support vector machines were trained to classify patients with and without sepsis amongst a heterogeneous cohort of critically ill patients. Altogether, this talk will highlight the value of mNGS for diagnosis of infectious diseases, the tools that underlie the ability to develop, and considerations in early development of diagnostic tools.\n\nPresenter Bio:\n\nKatrina Kalantar is currently a Computational Biologist at the Chan Zuckerberg Initiative. Her work focuses on development of tools for analysis of metagenomic next-generation sequencing (mNGS) in the context of infectious diseases. She is deeply involved in capacity building efforts aimed at expanding and supporting researchers’ ability to perform NGS and data analysis globally. Her previous research focused on applying mNGS to improve diagnosis of lower respiratory tract infections and she continues to be involved in research through collaboration with scientists working on translational applications of mNGS technology.\n\nhttps://www.youtube.com/watch?v=0LWIyqNYots&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=23\n\nAbstract:\n\nText summarization aims to generate a short summary for an input text and has extensive real-world applications such as headline generation. State-of-the-art summarization models are mainly supervised; they require large labeled training corpora and thus cannot be applied to less popular areas, where paired data are rare, e.g., less spoken languages.\n\nIn this talk, I will we present a non-autoregressive unsupervised summarization model, which does not require parallel data for training. Our approach first performs edit-based search towards a heuristically defined score, and generates a summary as pseudo-groundtruth. Then, we train an encoder-only non-autoregressive Transformer based on the search results. Further, we design two length-control algorithms for the model, which perform dynamic programming on the model output and are able to explicitly control the number of words and characters in the generated summary, respectively. Such length control is important for the summarization task, because the main evaluation metric for summarization systems, i.e., ROUGE score~\\cite{lin2004rouge}, is sensitive to the summary length, and because real-word applications generally involve length constraints. Experiments on two benchmark datasets show that our approach achieves state-of-the-art performance for unsupervised summarization, yet largely improves inference efficiency. Further, our length-control algorithms are able to perform length-transfer generation, i.e., generating summaries of different lengths than the training target.\n\nPresenter Bio:\n\nPuyuan Liu is currently a Master’s student at the Department of Computing Science, University of Alberta; he received a Bachelor’s degree in Computing Science from the same university in 2020. His research interest lies in Natural Language Processing, Deep Learning, and Reinforcement Learning. During the Master’s program, he published a paper on unsupervised summarization at ACL2022, a top-tier conference in natural language processing.\n\nhttps://www.youtube.com/watch?v=wqmL3rJHWUw&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=21\n\nAbstract:\n\nModern machine learning techniques have been shown to successfully encode / decode linguistic information from brain signals. It therefore seems a natural next step to use neurolinguistic data in ML models as an additional input stream to many NLP tasks. In the domain of vision, it has been shown that by forcing models to predict neural data (as well as the learned similarity representations from brain signals), models can become more robust and make “better / more natural mistakes”. This begs the question whether this effect transfers over to the domain of language / NLP with human data. This additional input stream provides many desirable properties, as the modelling process is less susceptible to idiosyncrasies of a single input modality (e.g. covariate shift, adversarial examples and non-robustness). In this talk I will recount my journey tackling these issues during my PhD, using models to decode linguistic and semi-linguistic information from single-trial EEG data, touching on various training methods that I have shown boost performance over directly training on single-trial EEG data. This work forms the core of my recent paper at ACL 2022 entitled, “Decoding PoS from Human EEG”. A key theme present throughout this talk is the effect of confounding that arises when working with linguistic data, both in terms of the linguistic status of stimuli (that also generate strong neural responses), but also biological confounds such as eye-movements, whose interference can be even further pronounced in EEG data. I will then summarize some of the main issues I believe still face us and reflect on how these might be surmounted by utilizing recent developments in multimodal Transformer networks and prediction-based representation learning in Reinforcement Learning. These techniques afford us a bridge in which both cognitive neuroscience and machine learning can jointly benefit from advances in the intersection of both domains.\n\nPresenter Bio:\n\nAlex has recently completed his PhD at the University of Birmingham (UK) in Cognitive Neuroscience & NLP. His interests span many varied topics across (neuro)linguistics, cognitive neuroscience, machine learning and natural language processing. He holds a Bachelor's degree in Linguistics (Bangor University, Wales), alongside Masters degrees in Language Technology (University of Iceland) and IT & Cognition (University of Copenhagen, Denmark). During his PhD he was a Technical Intern on the Language Team at Google Brain (London) where he worked on analyzing brain data with state-of-the-art deep learning models. He is interested in how (human) neural data can be incorporated into natural language processing applications and more widely in other domains of artificial intelligence.\n\nhttps://www.youtube.com/watch?v=_SoE7nlV3KU&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=17\n\nAbstract:\n\nMulti-agent reinforcement learning algorithms have not been widely adopted in large-scale environments with many agents as they often scale poorly with the number of agents. Using mean field theory to aggregate agents has been proposed as a solution to this problem by prior works. However, almost all previous works in this area make a strong assumption of requiring a centralized learning system where all the agents in the environment obtain global observations and/or are effectively indistinguishable from each other (i.e., learn the same policy in the time limit). In this talk, I will provide a method that relaxes this assumption about requiring centralized learning protocols and propose a new mean field system known as Decentralized Mean Field Games, where each agent learns in a decentralized fashion based on their local observations, and can be quite different from others. Further, I will provide a theoretical solution concept and establish a fixed point guarantee for a Q-learning based iterative algorithm in this system. A practical consequence of our approach is that we can address a 'chicken-and-egg’ problem in empirical mean field reinforcement learning algorithms. Notably, it is possible to design efficient (function approximation based) Q-learning and actor-critic algorithms that use the decentralized mean field learning approach. Empirically, these algorithms give stronger performances compared to common baselines in this area. In this setting, agents do not need to be clones of each other and learn in a fully decentralized fashion. Hence, for the first time, the application of mean field learning methods can be extended to fully competitive environments, large-scale continuous action space environments, and other environments with heterogeneous agents. Importantly, I will also present an application of the mean field method in a ride-sharing problem using a real-world dataset. I will propose a decentralized solution to this problem, which is more practical than the centralized training approaches considered by prior research efforts.\n\nPresenter Bio:\n\nSriram is a PhD candidate in the department of Electrical and Computer Engineering at the University of Waterloo. He is also a postgraduate affiliate at the Vector Institute, Toronto. His primary research interest is in the area of multi-agent systems. Particularly, he is interested in the issues of scale, non-stationarity, communication, and sample complexity experienced by multi-agent learning algorithms. His research is motivated by the field of computational sustainability. His long-term research vision is to make multi-agent learning algorithms applicable to a variety of large-scale real-world problems and to bridge the widening gap between the theoretical understanding and empirical advances of multi-agent reinforcement learning.\n\nhttps://www.youtube.com/watch?v=aGdgKq-9V68&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=16\n\nAbstract:\n\nThe background for the presentation is described in this YouTube video https://youtu.be/9m5kWBayClU . The August 5th presentation substitutes for the September 24th event described in the video. The draft PowerPoint is at https://www.slideshare.net/ksolez/kim-solez-how-ai-can-improve-human-cooperation-through-suggesting-followup-action-for-modelled-newscasts3pptx Recently there has been concern expressed about the safety of machine learning/artificial intelligence in the long run by Eliezer Yudkowsky AGI Ruin: A List of Lethalities https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities widely quoted elsewhere. The first of the 40+ bolded sections of the piece is the most significant because of the way it is equally true of an AI utopia: “AGI will not be upper-bounded by human ability or human learning speed. Things much smarter than humans would be able to learn from less evidence than humans require” Reading the beginning of that paragraph it is true that AI has taught humans much more beautiful moves in the game of Go than we would ever have been able to design ourselves. That means that AI can teach us ways of cooperating with each other that are superior to human’s own innate ability to cooperate successfully. Therefore, increasing use of machine learning is not the beginning of the slippery slope toward humanity’s demise, it could be exactly the opposite, a transition toward a world better than anything we ever imagined. We can determine which of these two contrasting futures happens, and AI can assist with that! An AI may also be more foresighted and have a longer temporal horizon, both of which promote cooperation.\n\nPresenter Bio:\n\nKim Solez, MD is Professor of Pathology in the Faculty of Medicine and Dentistry at the University of Alberta, and Chair of the Regenerative Medicine Community of Practice in the American Society of Transplantation. He is an American pathologist and co-founder of the Banff Classification, the first standardized international classification for renal allograft biopsies. He is also the founder of the Banff Foundation for Allograft Pathology.\n\nKim Solez obtained his M.D. with AOA honours from the University of Rochester School of Medicine and Dentistry, and trained in pathology at Johns Hopkins Medical Institutions in Baltimore, Maryland where he was mentored in renal pathology by Robert Heptinstall. He joined the faculty at Johns Hopkins and in 1987 became chairman of the Department of Pathology at the University of Alberta in Edmonton, Canada. In 1991, he established the Banff Classification, the first standardized, international classification for renal allograft biopsies, with Johns Hopkins pathologist Lorraine Racusen. The Banff Classification, updated in regular intervals, continues to \"set standards worldwide for how biopsies from kidney and other solid organ transplants are interpreted\". He is the author of over 230 journal articles. He was awarded:\n\n· National Kidney Foundation International Distinguished Medal, 2009.\n\n· University of Alberta Faculty of Medicine and Dentistry Tier 1 Clinical Mentoring Award, 2016.\n\n· Catalan Society for Transplantation Gold Medal, 2017\n\n· American Society of Transplantation Fellowship, FAST designation 2020.\n\nIn 2011 Kim Solez pioneered a unique graduate level medical course Technology and the Future of Medicine at the University of Alberta with strong AI content LABMP 590. Computing Science Professors Rich Sutton, Osmar Zaiane, Patrick Pilarski, and Russ Greiner teach in the course. Doctor Kim's The Future and All That Jazz musical and poetic spinoff of the LABMP 590 course with singer Mallory Chipman had its first product release on May 15, 2022. https://www.youtube.com/watch?v=QturFFBynhA Heart Drive – My Ex Was Made of Flesh. Rich Sutton attended a 2016 Future and All That Jazz event on the same day as the great AlphaGo success! Dr. Solez and Dr. Sutton also attended the Strathearn Fall Festival together in 2015 where Kim Solez performed AI related poetry https://www.youtube.com/watch?v=jTVO74FW7dc .\n\nhttps://www.youtube.com/watch?v=chyt-7P8oLw&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=14\n\nAbstract:\n\nPart I: Sparse training in supervised and unsupervised deep learning (Decebal). The talk starts with a quick overview of my research line. Next, it introduces along this line one of the many challenges which prevent us from having truly scalable artificial neural networks at both levels, cloud and edge computing, i.e., dense connectivity. Next, an emerging state-of-the-art possible solution is presented, i.e., sparse-to-sparse training with static and dynamic sparsity. The discussion starts from the first works on complex Boltzmann machines [Mocanu et al., Machine Learning 2016] and sparse evolutionary training [Mocanu et al., Nature Communications 2018] in typical single task (un)supervised learning and gradually introduces newer approaches in the more challenging contexts of continual learning. Besides the fundamental theoretical novelty, some practical aspects, such as truly sparse implementations and deep learning energy efficiency are briefly considered.\n\nPart II: Sparse training in deep reinforcement learning (Elena). A fundamental task for artificial intelligence is learning. Up to now, everything was discussed in the context of supervised and unsupervised learning. Inspired by human learning, the reinforcement learning paradigm has high potential for autonomous agents, although it suffers from scalability issues [Mocanu et al. AAMAS 2021]. Further on, we introduce dynamic sparse training in deep reinforcement learning [Sokar et al., IJCAI 2022] and we pave the ground for scalable deep reinforcement learning. We describe some very recent progresses in the field that could be used to foster the generalization performance of sparsely trained RL agents over their densely trained counterparts, while at the same time, reducing considerably their computational and memory requirements in both, training and inference.\n\nPresenter Bio:\n\nDecebal Constantin Mocanu is an Assistant Professor in Artificial Intelligence and Machine Learning within the DMB group, EEMCS faculty at the University of Twente; and a Guest Assistant Professor within the DM group, M&CS department at TU Eindhoven. Currently, he is doing a research visit at the University of Alberta. He is an alumni member of TU Eindhoven Young Academy of Engineering. In 2017, Decebal received his PhD degree from TU Eindhoven. During his doctoral studies, he undertook three research visits at the University of Pennsylvania (2014), Julius Maximilians University of Würzburg (2015), and the University of Texas at Austin (2016). In the long term, Decebal is interested in studying the synergy between artificial intelligence, neuroscience, and network science for the benefits of science and society.\n\nElena Mocanu is an Assistant Professor within the Department of Computer Science at the University of Twente, the Netherlands. Currently, she is visiting the group of Matthew Taylor at the University of Alberta. She received her PhD in machine learning from Eindhoven University of Technology, in 2017. During her PhD, she visited the University of Texas at Austin, where she worked with Michael Webber and Peter Stone on machine learning, decision making, and autonomous systems through the means of sparse neural networks. As a mathematician with a big passion for neural networks, her current research is focused on understanding neural networks and how their learning capabilities can be improved.\n\nhttps://www.youtube.com/watch?v=g3Ojdaq7Y3o&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=12\n\nAbstract:\n\nConversational agents (CAs) such as Amazon Alexa, Google Assistant, and Apple Siri have become popular in recent years. Conversational agents are computer systems designed to have natural conversations with human users, either for casual chatting or to provide the user with relevant information for a specific task. In this project, in partnership with the Mood Disorders Society of Canada (MDSC), the Asia-Pacific Economic Cooperation (APEC), Digital Hub for Mental Health, the University of Alberta, University of Saskatchewan, Dalhousie University, and the University of Alberta’s AI4Society Signature Area, we developed a mental health conversational agent (MIRA), aiming to assist healthcare workers and their families in finding relevant mental health information and local services in the Canadian provinces of Alberta and Nova Scotia. You can find the chatbot via mymira.ca.\n\nPresenter Bio:\n\nI am an M.Sc. student at the University of Alberta in computing science under the supervision of Osmar R. Zaiane. Also, I am an ML Engineer, Data Scientist, NLP researcher, and member of Amii (Alberta Machine Intelligence Institute) with 3+ years of research and industrial experience in linguistics, sentiment analysis, intent detection, entity extraction, and text classification. Moreover, I developed and implemented a mental health chatbot (mymira.ca) through my M.Sc. thesis using ML and NLP techniques to support healthcare workers affected by mental health issues. Through developing the mental health chatbot, I showed strong teamwork skills by collaborating with healthcare workers and computer science students. Also, I have advanced knowledge of software engineering with 3+ years of experience in developing different websites.v\n\nAbstract:\n\nTechnology Alberta works with leaders across industry, government, and academia – to grow Alberta’s Tech Sector, which is very actively hiring. By gathering the insights of AI/ML graduate students, professors and entrepreneurial tech companies – the Technology Alberta FIRST (First Industry Research Science Technology) Jobs program was created in 2020 to help university students and new graduates launch their professional careers by providing entry level part-time jobs with industry. Over 200 companies have participated – providing work experience in areas such as Product Development, AI/ML, Data Science, Data Analytics, Software Development and more. Student participants have reported outstanding results – such as: expanding their networks to include 50 local tech company presidents, subsequent part-time and full-time job offers, and interesting work experience, working for companies that develop software products that address: cyber-bullying, crisis detection, clean-tech, gaming, and more. Sponsored by Government of Alberta, Advanced Education – the Technology Alberta FIRST Job Program will be open to all Alberta post-secondary students in July 2022 – so be ready to apply, and learn more about the over 3000 entrepreneurial tech companies in the province – and be part of Alberta’s tech community!\n\nPresenter Bio:\n\nGail has over 30 years of experience, working for companies such as Proctor & Gamble, Matrikon (now Honeywell), Willowglen Systems – as a software engineer, product manager, tech company executive and leader of technology associations. Gail is an award-winning community builder being recognized for supporting diversity in the workforce, inclusive workplace policies, and volunteer efforts in the local tech sector. In her role with Technology Alberta, she has worked with a large team of volunteer and community builders to create programs that create opportunities for Alberta students in local companies – as well as tech leadership programs that help grow the tech sector overall.\n\nhttps://www.youtube.com/watch?v=hzURHdMxf-Y&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=11\n\nAbstract:\n\nDustin's thesis develops foundations for the development of dependable, scalable reinforcement learning algorithms with strong connections to game theory. A key contribution is a proposal for a rationality objective for reinforcement learning that is grounded in the learner's experience and is connected with the rationality concepts of optimality and equilibrium. This notion of \"hindsight rationality\" is based on regret, a well-known concept for evaluating a sequence of decisions with unilateral deviations, and it demands resiliency to uncertainty, environmental changes, and adversarial pressures. In this talk, he will describe how particular natural sets of deviations can be constructed specifically for sequential decision-making settings to overcome computational challenges. Dustin shows how the strategic strength of special low-complexity deviation sets can be elevated with observable sequential rationality. He then presents a unifying algorithm: extensive-form regret minimization (EFR), which achieves observable sequential hindsight rationality for a broad and natural class of deviations. The EFR algorithm often performs better in practice when it uses stronger deviation types and EFR inherits the extensibility of the counterfactual regret minimization (CFR) algorithm. This talk outlines how his thesis provides the conceptual, theoretical, and algorithmic bases for practical research directions toward the advancement of both single and multi-agent reinforcement learning.\n\nPresenter Bio:\n\nDustin is a research scientist at Sony AI and a Ph.D. candidate at the University of Alberta and the Alberta Machine Intelligence Institute (Amii), co-supervised by Professor Michael Bowling and Professor Amy Greenwald of Brown University. He works on multi-agent reinforcement learning and scaleable, dependable learning algorithms. He is currently working on the GT Sophy project at Sony AI, extending and improving algorithms that learn to outpace expert e-sports racers in a realistic racing simulator. He is also a coauthor of DeepStack, an expert-level player of heads-up, no-limit, Texas hold'em poker, and he created a public match interface for Cepheus, a near solution to heads-up, limit, Texas hold'em. He completed a B.Sc. and M.Sc. in computing science at the University of Alberta, also supervised by Michael Bowling. As an undergraduate, he worked with the Computer Poker Research Group at the University of Alberta to create an open-source web interface to play against poker bots and to develop the 1st-place 3-player Kuhn poker entry in the 2014 Annual Computer Poker Competition.\n\nhttps://www.youtube.com/watch?v=2sseUO_TyAw&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=10\n\nAbstract:\n\nMany medical researchers want a tool that “does what a top medical clinician does, but does it better”. This presentation explores this goal. This requires first defining what “better” means, leading to the idea of outcomes that are “objective” and then to ones that are actionable, with a meaningful evaluation measure. We will discuss some of the subtle issues in this exploration – what does “objective” mean, the role of the (perhaps personalized) evaluation function, multi-step actions, counterfactual issues, distributional evaluations, etc. Collectively, this analysis argues we should learn models whose outcome labels are objective and actionable, as that will lead to tools that are useful and cost-effective.\n\nPresenter Bio:\n\nRuss Greiner worked in both academic and industrial research before settling at the University of Alberta, where he is now a Professor in Computing Science and the founding Scientific Director of the Alberta Machine Intelligence Institute. He has been Program/Conference Chair for various major conferences, and has served on the editorial boards of a number of other journals. He was elected a Fellow of the AAAI, has been awarded a McCalla Professorship and a Killam Annual Professorship; and in 2021, received the CAIAC Lifetime Achievement Award and became a CIFAR AI Chair. In 2022, the Telus World of Science museum honored him with a panel, and he received the (UofA) Precision Health Innovator Award. For his mentoring, he received a 2020 FGSR Great Supervisor Award. He has published over 300 refereed papers, most in the areas of machine learning and recently medical informatics, including 5 that have been awarded Best Paper prizes. The main foci of his current work are (1) bio- and medical- informatics; (2) learning and using effective probabilistic models and (3) formal foundations of learnability.\n\nhttps://www.youtube.com/watch?v=jg8s-i7aaio&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=8\n\nAbstract:\n\nIn December 2019, the UofA launched AI4Society as one of its five Signature Areas, conceived to take a holistic approach to the study of AI, including designing new data science, machine learning, and artificial intelligence algorithms, and developing appropriate computational platforms to implement them in real-world use cases, with awareness of the ethical concerns around data collection, and accountable and fair analysis. Since then AI4Society has seeded a number of interdisciplinary collaborations in a number of areas, such as manufacturing and construction, health, energy and clean technologies, business and finance, and education. In this presentation, I will talk about some of these initiatives and share some ways in which the community at large can be involved.\n\nPresenter Bio:\n\nDr. Eleni Stroulia is a Professor in the Department of Computing Science, at the University of Alberta. From 2011-2016, she held the NSERC/AITF Industrial Research Chair on Service Systems Management, with IBM. Her research focuses on addressing industry-driven problems, adopting AI and machine-learning methods to improve or automate tasks. Her flagship project in the area of health care is the Smart Condo in which she investigates the use of technology to support people with chronic conditions live independently longer and to educate health-science students to provide better care for these clients. In 2011, the Smart-Condo team received the UofA Teaching Unit Award. She has played leadership roles in the GRAND and AGE-WELL Networks of Centres of Excellence. in 2018 she received a McCalla professorship, and in 2019 she was recognized with a Killam Award for Excellence in Mentoring. She has supervised more than 60 graduate students and PDFs, who have gone forward to stellar academic and industrial careers. Since 2020, she is the Director of the University of Alberta's AI4Society Signature Area. Since 2021, she is serving as the Acting Vice Dean of the Faculty of Science.\n\nhttps://www.youtube.com/watch?v=mjjlf6vSFEQ&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=5\n\nAbstract:\n\nManual assessment of medical images is challenging due to high intra- and inter-observer variability. With improvements in computer vision techniques and hardware, it is now possible to quantitatively assess subtle visual features in histopathology and diagnostic images that are usually difficult to evaluate manually. Tumor and nuclei segmentation is one of the key modules in histopathological image analysis that could facilitate downstream analysis of tissue samples for assessing not only cancer grades or stages but also for predicting tumor recurrence, treatment effectiveness, and for quantifying intra-tumor heterogeneity. Identifying different types of nuclei, such as epithelial, neutrophils, lymphocytes, macrophages, etc., could yield information about the host immune response that could advance our understanding of the mechanisms governing treatment resistance and adaptive immunity in cancers of various organs. This talk will give an overview of state-of-the art machine learning algorithms for nuclei segmentation and classification from H&E stained tissue images while providing insights into the process of creating one of the largest nuclei segmentation datasets and organizing two international competitions on this theme. I will also discuss a few projects on applying machine learning algorithms for (1) identification of co-existence of multiple molecular subtypes of breast cancer in a patient, (2) radiomics based treatment outcome prediction in Glioblastoma patients, and (3) personalized survival prediction from pan-cancer whole transcriptome data.\n\nPresenter Bio:\n\nRuchika is an associate machine learning scientist at the Alberta Machine Intelligence Institute (Amii). Her research interests include machine learning and computer vision for digital healthcare and personalized medicine. She has applied machine learning algorithms to address various challenges in evidence-based personalized oncology such as tumor detection, generalized nuclei segmentation, survival, and treatment outcome prediction for cancer patients. She recently completed her PhD in Biomedical Engineering from Case Western Reserve University, Cleveland, Ohio, USA and received the Doctoral Excellence Award for her PhD thesis. She co-organized two international competitions on computational pathology focused on nuclei segmentation and classification. She also did academic internships at UCSF and UAlberta. Previously, she completed her masters and undergraduate studies in Electronics and Communication Engineering with specialization in digital signal processing and machine learning. She has also served as an instructor for 2 years in NIT Meghalaya, which is an institute of national importance funded by the Government of India. She was also a recipient of several prestigious awards including commonwealth scholarship 2017 by the UK Department for International Development (DFID).\n\nhttps://www.youtube.com/watch?v=UBzDVy8a0LM&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=6\n\nAbstract:\n\nExploiting invariances in the inputs is crucial for constructing efficient representations and accurate predictions in neural circuits. In neuroscience, translation invariance is at the heart of models of the visual system, while convolutional neural networks designed to exploit translation invariance triggered the first wave of deep learning successes. While the hallmark of convolutions, namely localised receptive fields that tile the input space, can be implemented with fully-connected neural networks, learning convolutions directly from inputs in a fully-connected network has so far proven elusive. In this talk, I will show how initially fully-connected neural networks solving a discrimination task can learn a convolutional structure directly from their inputs, resulting in localised, space-tiling receptive fields. Both translation invariance and non-trivial higher-order statistics are needed to learn convolutions from scratch. I will provide an analytical and numerical characterisation of the pattern-formation mechanism responsible for this phenomenon in a simple model, which results in an unexpected link between receptive field formation and the tensor decomposition of higher-order input correlations.\n\nPresenter Bio:\n\nAlessandro Ingrosso is a Senior Postdoctoral Fellow at The Abdus Salam International Centre for Theoretical Physics in Trieste, Italy. His current research focuses on computational neuroscience and machine learning, using methods from statistical physics of disordered systems. Alessandro studied cognitive psychology and physics. During his PhD, under the supervision of Riccardo Zecchina, he co-developed an analytical and computational framework for the study of generalization in neural networks based on local-entropy, an effective measure of flatness of the loss landscape. He moved to the U.S.A. for a postdoc at the Center for Theoretical Neuroscience, Columbia University, where he worked with Larry Abbott on computational and theoretical aspects of dynamics and learning in biologically plausible recurrent neural networks.\n\nhttps://www.youtube.com/watch?v=rvc7k208ssw&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=2\n\nAbstract:Trust and reputation systems constitute an active branch of research in multi-agent systems. In various application domains, agents interact with one another to collect information, goods, or services that help complete a set task. For such interactions to be largely successful, agents try to estimate how trustworthy other individual agents are. To evaluate the trustworthiness of an agent in a multi-agent system, one often combines two types of trust information: direct trust information derived from one's interactions with that agent, and indirect trust information based on advice from other agents.\n\nIn this work, we first focus on the trust established through indirect trust information. This is a non-trivial problem, since advice may not always be reliable; it may come from a deceptive agent whose goal is to mislead the truster. We propose a new and easy-to-implement method for computing indirect trust, based on a simple prediction from expert advice strategy as is often used in online learning. This method either competes with or outperforms all tested systems in most of the simulated settings while scaling substantially better. We also provide the first systematic study on when it is beneficial to combine the two types of trust as opposed to relying on only one of them. Our large-scale experimental study shows that strong methods for computing indirect trust make direct trust redundant in a surprisingly wide variety of scenarios. Further, a new method for the combination of the two trust types is proposed that, in the remaining scenarios, outperforms the ones known from the literature. Moreover, we propose a method based on the Page-Hinkley statistics to handle the dynamic behaviour of agents in a multi-agent system.\n\nPresenter Bios: Elham Parhizkar is a postdoctoral fellow at the University of Alberta, where she is working under the supervision of Dr. Levi Lelis. Currently, she is focused on developing algorithms for synthesizing effective and interpretable strategies for solving problems and playing games.\n\nShe completed her Ph.D. from the University of Regina under the supervision of Dr. Sandra Zilles in 2021. Her Ph.D. research focused on establishing trust between agents in multi-agent systems.\n\nhttps://www.youtube.com/watch?v=V_Oyl5cx4Mc\n\nAbstract: This seminar will highlight many of the interesting applications of Machine Learning in use and being explored at Electronic Arts, a leading gaming publisher. Just as machine learning is transforming many industries, the gaming industry is finding exciting ways to address many of the unique challenges that game software development presents, and EA is making great investments into the space. This seminar will also provide insight into EA’s commitment to attracting talent and should answer many questions about how one might join the organization as an AI/ML developer or scientist.\n\nPresenter Bios:\n\nWilliam Gordon (Bill) is a senior software engineer with Electronic Arts (EA), working in AI and rendering. He currently works on a DTS research and applications team conducting practical machine learning applications for advancing gameplay AI and game validation for all EA games. Bill’s currently is working on ML projects that include: Object-Detection, Object tracking, Image Classification, Image segmentation, Imitation Learning (IL), Reinforcement Learning (RL) and Natural Language Processing (NLP). Before joining EA, Bill worked at Disney and other mobile start-ups in a variety of low-level embedded software and mobile app development roles. Bill has a B.S.E.E. from Purdue University. He is a Disney Inventor and has patents pending with EA. In his free time, Bill loves spending time at the beach with his wife and kids in sunny Florida.\n\nAlex Lucas is the Director of Quality Verification for BioWare Studios. Although a Calgary native, he’s been with BioWare in Edmonton for the past 18 years, first as a software engineer and later as both a technical and department director. Alex has for many years been an advocate for leveraging relationships with academia and research (most notably with the University of Alberta and the NRCC) and has led many partnership engagements in the ML space. He has a BSc in Computer Science from the University of Calgary and several patents with EA. He is a new, first-time dad, and very tired.\n\nhttps://www.youtube.com/watch?v=08zjKrrGosU\n\nAbstract: Machine learning researchers have long noted a trade-off between interpretability and prediction performance. On the one hand, traditional models are often interpretable to humans but they cannot achieve high prediction performances. At the opposite end of the spectrum, deep models can achieve state-of-the-art performances in many tasks but their predictions are known to be uninterpretable to humans. We present a framework that shortens the gap between the two aforementioned groups of methods. Given an artificial neural network (ANN), our method finds a Gaussian process (GP) whose predictions almost match those of the ANN. As GPs are highly interpretable, we use the trained GP to explain the ANN’s decisions. The explanations provide intriguing insights about the ANNs’ decisions. We examine some of the known theoretical conditions under which an ANN is interpretable by GPs. Some of those theoretical conditions are too restrictive for modern architectures. However, we hypothesize that only a subset of those theoretical conditions are sufficient. We implement our framework as a publicly available tool called GPEX: www.github.com/amirakbarnejad/gpexPresenter Bio: Amir Akbarnejad is a PhD student at the University of Alberta working under supervision of Nilanjan Ray and Gilbert Bigras. His research is about machine learning and computer vision, with focus on histopathology data.\n\nhttps://www.youtube.com/watch?v=8Dk-O4OeEzc&list=PLKlhhkvvU8-ZYAernGzP2ZKMz1RILmXd6&index=6\n\nAbstract: Accurate forecasts of the number of newly infected people during an epidemic are critical for making effective timely decisions. This paper addresses this challenge using the SIMLR model, which incorporates machine learning (ML) into the epidemiological SIR model. For each region, SIMLR tracks the changes in the policies implemented at the government level, which it uses to estimate the time-varying parameters of an SIR model for forecasting the number of new infections one to four weeks in advance. It also forecasts the probability of changes in those government policies at each of these future times, which is essential for the longer-range forecasts. We applied SIMLR to data from in Canada and the United States, and show that its mean average percentage error is as good as state-of-the-art forecasting models, with the added advantage of being an interpretable model. We expect that this approach will be useful not only for forecasting COVID-19 infections, but also in predicting the evolution of other infectious diseases.\n\nPresenter Bio: Roberto Vega is a PhD candidate at the University of Alberta working under the supervision of Russ Greiner. His research focuses on how to combine machine learning with medical expert knowledge to learn accurate predictive models. He also collaborates with the local startup MEDO.ai, where he works alongside their AI team to automatically analyze ultrasound images for the detection of health problems.\n\nhttps://www.youtube.com/watch?v=L8BgNLzhPjE&list=PLKlhhkvvU8-ZYAernGzP2ZKMz1RILmXd6&index=3\n\nAbstract: In recent years, a growing number of deep model-based reinforcement learning (RL) methods have been introduced. The interest in deep model-based RL is not surprising, given their many potential benefits, such as higher sample efficiency and the potential for fast adaption to changes in the environment. However, we demonstrate, using an improved version of the recently introduced Local Change Adaptation (LoCA) setup, that the well-known model-based methods such as PlaNet and DreamerV2 perform poorly in their ability to adapt to local environmental changes. Combined with prior work that made a similar observation about the other popular model-based method, MuZero, a trend appears to emerge suggesting that current deep model-based methods have serious limitations. We dive deeper into the causes of this poor performance, by identifying elements that hurt adaptive behavior and linking these to underlying techniques frequently used in deep model-based RL. We empirically validate these insights in the case of linear function approximation by demonstrating that a modified version of linear Dyna achieves effective adaptation to local changes. Furthermore, we provide detailed insights into the challenges of building an adaptive non-linear model-based method, by experimenting with a non-linear version of Dyna.\n\nPresenter Bio:\n\nYi Wan is a fifth-year Ph.D. candidate in Computing Science at the University of Alberta, focusing on reinforcement learning, which he believes is the most promising way to artificial general intelligence. His Ph.D. supervisor is Professor Rich Sutton. His long-term research goal is to build simple, general, and scalable learning and planning algorithms for reinforcement learning problems. He is particularly interested in designing these algorithms 1) for the average reward problem setting, 2) with function approximation, and 3) with temporal abstractions. Previously, he earned a Bachelor degree in Electrical and Computer Engineering (ECE) from Shanghai Jiao Tong University (SJTU), where he worked in SJTU Speech Lab, advised by Professor Kai Yu. After that, he obtained a master degree, also in ECE, from University of Michigan. During his master, he worked in Intelligent Robotics Lab, advised by Professor Ben Kuipers. During his master and Ph.D., he interned as a researcher in Mila, Huawei, and Tusimple and also interned as an engineer in Yitu.\n\nhttps://www.youtube.com/watch?v=r6o05gOOtpg\n\nAbstract: We receive information about the world through our sensors and influence the world through our effectors. Such low-level experiential data has gradually come to play a greater role in AI during its 70-year history. I see this as occurring in four steps, two of which are mostly past and two of which are in progress or yet to come. The first step was to view AI as the design of agents which interact with the world and thereby have sensorimotor experience; this viewpoint became prominent in the 1980s and 1990s. The second step was to view the goal of intelligence in terms of experience, as in the reward signal of optimal control and reinforcement learning. The reward formulation of goals is now widely used but rarely loved. Many would prefer to express goals in non-experiential terms, such as reaching a destination or benefiting humanity, but settle for reward because, as an experiential signal, reward is directly available to the agent without human assistance or interpretation. This is the pattern that we see in all four steps. Initially a non-experiential approach seems more intuitive, is preferred and tried, but ultimately proves a limitation on scaling; the experiential approach is more suited to learning and scaling with computational resources. The third step in the increasing role of experience in AI concerns the agent’s representation of the world’s state. Classically, the state of the world is represented in objective terms external to the agent, such as “the grass is wet” and “the car is ten meters in front of me”, or with probability distributions over world states such as in POMDPs and other Bayesian approaches. Alternatively, the state of the world can be represented experientially in terms of summaries of past experience (e.g., the last four Atari video frames input to DQN) or predictions of future experience (e.g., successor representations). The fourth step is potentially the biggest: world knowledge. Classically, world knowledge has always been expressed in terms far from experience, and this has limited its ability to be learned and maintained. Today we are seeing more calls for knowledge to be predictive and grounded in experience. After reviewing the history and prospects of the four steps, I propose a minimal architecture for an intelligent agent that is entirely grounded in experience.\n\nPresenter Bio:\n\nRichard S. Sutton is a distinguished research scientist at DeepMind, a professor in the Department of Computing Science at the University of Alberta, and a fellow of the Royal Society (UK), the Royal Society of Canada, the Association for the Advancement of Artificial Intelligence, the Alberta Machine Intelligence Institute (Amii), and CIFAR. Sutton received a PhD in computer science from the University of Massachusetts in 1984 and a BA in psychology from Stanford University in 1978. Prior to joining the University of Alberta in 2003, he worked in industry at AT&T Labs and GTE Labs, and in academia at the University of Massachusetts. In Alberta, Sutton founded the Reinforcement Learning and Artificial Intelligence Lab, which now consists of ten principal investigators and about 100 people altogether. He joined DeepMind in 2017 to co-found their first satellite research lab, in Alberta. Sutton is co-author of the textbook Reinforcement Learning: An Introduction from MIT Press. His research interests center on the learning problems facing a decision-maker interacting with its environment, which he sees as central to intelligence. He has additional interests in animal learning psychology, in connectionist networks, and generally in systems that continually improve their representations and models of the world. His scientific publications have been cited more than 100,000 times. He is also a libertarian, a chess player, and a cancer survivor.\n\nhttps://www.youtube.com/watch?v=ddyFmyIPEHU&list=PLKlhhkvvU8-ZYAernGzP2ZKMz1RILmXd6&index=4\n\nAbstract:\n\nA Multi-armed bandit problem is a classical sequential decision-making problem in which the goal is to accumulate as much reward as possible. In this learning model, only a limited amount of information is revealed in each round. The imperfect feedback model results in the learning algorithm being in a dilemma between exploration (gaining information) and exploitation (accumulating reward). Thompson Sampling is one of the classical learning algorithms that can make a good balance between exploration and exploitation and it always has a very competitive empirical performance.\n\nIn the standard non-private learning, the learning algorithm can always get access to the true revealed information to make future decisions. However, if the revealed information is about individuals, to preserve privacy, the decisions made by the learning algorithm should not rely on the true revealed information. In this talk, I will present a Thompson Sampling-based algorithm, DP-TS, for private stochastic bandits. The regret upper bound for DP-TS matches the discovered regret lower bound up to an extra loglogT factor.\n\nPresenter Bio: Bingshan Hu is an Amii Postdoctoral Fellow co-hosted by Prof. Nidhi Hegde from University of Alberta and Prof. Mark Schmidt from University of British Columbia. She completed her PhD from University of Victoria under the supervision of Prof. Nishant Mehta in 2021. Her research lies in the theoretical side of machine learning, aiming at devising efficient and private online learning algorithms. She serves as reviewers for conferences such as NeurlPS, ICML, and AISTATS. She was recognized as one of the top 10% of high-scoring reviewers at NeurIPS 2020.\n\nPrior to pursuing her PhD studies, she worked in industry research labs as a wireless technology specialist. She invented/co-invented around 20 patents with more than half of them having been granted by either the European patent office or US patent office. Besides the foundations of online learning, she is also interested in the usage of online learning in novel applications in wireless networks.\n\nNo recording available\n\nAbstract: Samdesk is an Edmonton based start up that uses AI to detect and monitor global crises events in real time. Our system ingests a range of social media and traditional web sources, and the scope of problems that our AI tackles includes text classification, source trustworthiness estimation, input geo-localization, text similarity, and clustering. In this talk, we present how Samdesk helps our customers act smarter and faster, we examine some of the main ML and AI systems within samdesk, and we discuss some practical lessons that we have picked up in terms of gathering and processing data and applying AI in production.\n\nPresenter Bios:\n\nSky Sun finished her MA in Digital Humanities at the U of A and is working full time at samdesk as Data Intel Team Lead. Her role at samdesk is to enrich and manage data to support AI performance. She is passionate about taking a humanistic and interdisciplinary approach to solving technical problems.\n\nAdam St Arnaud received his MSc in Computing Science at the U of A in 2017 under the supervision of Greg Kondrak. Adam is a Lead Machine Learning Engineer at samdesk, where he has been working since 2017.\n\nhttps://www.youtube.com/watch?v=cJFlL6xcVWQ&list=PLKlhhkvvU8-bFpoIPFTCVsYmqFVpt7OTz&index=13\n\nAbstract:\n\nTechnology Alberta works with leaders across industry, government, and academia – to grow Alberta’s Tech Sector, which is very actively hiring. By gathering the insights of AI/ML graduate students, professors and entrepreneurial tech companies – the Technology Alberta FIRST (First Industry Research Science Technology) Jobs program was created in 2020 to help university students and new graduates launch their professional careers by providing entry level part-time jobs with industry. Over 200 companies have participated – providing work experience in areas such as Product Development, AI/ML, Data Science, Data Analytics, Software Development and more. Student participants have reported outstanding results – such as: expanding their networks to include 50 local tech company presidents, subsequent part-time and full-time job offers, and interesting work experience, working for companies that develop software products that address: cyber-bullying, crisis detection, clean-tech, gaming, and more. Sponsored by Government of Alberta, Advanced Education – the Technology Alberta FIRST Job Program will be open to all Alberta post-secondary students in July 2022 – so be ready to apply, and learn more about the over 3000 entrepreneurial tech companies in the province – and be part of Alberta’s tech community!\n\nJoin us at this session to hear more about the program – and to offer any program ideas on what you would like to see.\n\nhttps://technologyalberta.com/?page_id=1440\n\nAI/ML Tech Companies that have participated in the past include: AltaML, Areto Labs, Biostream, Chata.AI, HealthGauge, Honest Door, RunwithIT, StreamML – and many more.\n\nPresenter Bio:\n\nGail has over 30 years of experience, working for companies such as Proctor & Gamble, Matrikon (now Honeywell), Willowglen Systems – as a software engineer, product manager, tech company executive and leader of technology associations. Gail is an award-winning community builder being recognized for supporting diversity in the workforce, inclusive workplace policies, and volunteer efforts in the local tech sector. In her role with Technology Alberta, she has worked with a large team of volunteer and community builders to create programs that create opportunities for Alberta students in local companies – as well as tech leadership programs that help grow the tech sector overall."
    }
}