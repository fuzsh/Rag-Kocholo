{
    "id": "dbpedia_8305_1",
    "rank": 45,
    "data": {
        "url": "https://www.open-mpi.org/projects/hwloc/",
        "read_more_link": "",
        "language": "en",
        "title": "Portable Hardware Locality (hwloc)",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.open-mpi.org/images/open-mpi-logo.png",
            "https://www.open-mpi.org/images/left-e0-2.gif",
            "https://www.open-mpi.org/images/right-e0-2.gif",
            "https://www.open-mpi.org/projects/hwloc/lstopo.png",
            "https://www.open-mpi.org/images/pixel.gif",
            "https://www.open-mpi.org/images/pixel.gif",
            "https://www.open-mpi.org/images/pixel.gif",
            "https://www.open-mpi.org/images/pixel.gif",
            "https://www.open-mpi.org/images/pixel.gif",
            "https://www.open-mpi.org/images/pixel.gif",
            "https://www.open-mpi.org/images/pixel.gif",
            "https://www.open-mpi.org/images/pixel.gif",
            "https://www.open-mpi.org/about/members/inria.jpg",
            "https://www.open-mpi.org/images/spi-logo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "hwloc",
            "Hardware Locality",
            "topology",
            "locality",
            "hierarchy",
            "NUMA",
            "NUMAnode",
            "processor",
            "package",
            "cache",
            "core",
            "PU",
            "Open MPI",
            "HPC",
            "Linux"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "../../favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "The Portable Hardware Locality (hwloc) software package provides a portable abstraction (across OS, versions, architectures, ...) of the hierarchical topology of modern architectures, including NUMA memory nodes (DRAM, HBM, non-volatile memory, CXL, etc.), processor packages, shared caches, cores and simultaneous multithreading. It also gathers various system attributes such as cache and memory information as well as the locality of I/O devices such as network interfaces, InfiniBand HCAs or GPUs.\n\nhwloc primarily aims at helping applications with gathering information about increasingly complex parallel computing platforms so as to exploit them accordingly and efficiently. For instance, two tasks that tightly cooperate should probably be placed onto cores sharing a cache. However, two independent memory-intensive tasks should better be spread out onto different processor packages so as to maximize their memory throughput. As described in this paper, OpenMP threads have to be placed according to their affinities and to the hardware characteristics. MPI implementations apply similar techniques while also adapting their communication strategies to the network locality as described in this paper or this one.\n\nhwloc may also help many applications just by providing a portable CPU and memory binding API and a reliable way to find out how many cores and/or hardware threads are available.\n\nPortability and support\n\nhwloc supports the following operating systems:\n\nLinux (with knowledge of cgroups, heterogeneous memory, hybrid CPUs, offline CPUs, ScaleMP vSMP, and NumaScale NumaConnect) on all supported hardware.\n\nSolaris, AIX and HP-UX\n\nNetBSD, FreeBSD and kFreeBSD/GNU\n\nDarwin / OS X\n\nMicrosoft Windows (either using MinGW, Cygwin, CMake, or a native Visual Studio solution)\n\nIBM BlueGene/Q Compute Node Kernel (CNK)\n\nAndroid\n\nAdditionally hwloc can detect the locality PCI devices as well as software devices to manipulate accelerators (OpenCL, NVIDIA CUDA, AMD ROCm, Intel LevelZero, NEC Vector Engine, etc.), network and InfiniBand interfaces, etc. See the Best of lstopo for more examples of supported platforms. The topologies of many existing platforms are also available in the XML topology database for testing your software on architectures you don't have access to.\n\nhwloc may display the topology in multiple convenient formats (see v2.11.1 examples and the Best of lstopo). It also offers a powerful programming interface to gather information about the hardware, bind processes, and much more.\n\nSince it uses standard Operating System information, hwloc's support is almost always independent from the processor type (x86, ARM, RISC-V, POWER, etc), and just relies on the Operating System support. Whenever the OS does not support topology information (e.g. some BSDs), hwloc uses an x86-only CPUID-based backend.\n\nTo check whether hwloc works on a particular machine, just try to build it and run lstopo or lstopo-no-graphics. If some things do not look right (e.g. bogus or missing cache information), see Questions and bugs below\n\nDocumentation\n\nMore details are available in the Documentation (in both PDF and HTML). The documentation for each version contains examples of outputs and an API interface example (these links are for v2.11.1).\n\nThe materials from several hwloc tutorials are available online.\n\nGetting and using hwloc\n\nhwloc is open-source, available under the BSD license.\n\nThe latest hwloc releases are available on the download page. The GIT repository is also accessible for online browsing or checkout.\n\nThe version string of the latest release is available from the latest_release.txt link. For the latest release or release candidate, rather use the latest_snapshot.txt link. For the latest on a specific series, replace \"current\" with \"v2.9\" in these links for instance.\n\nhwloc is already available as official packages for many Linux distributions (at least Debian/Ubuntu, Fedora/RHEL, SUSE, ArchLinux, Slackware, Gentoo and their derivatives), as well as NetBSD, FreeBSD, Cygwin, Mac OS X ports (Homebrew), Windows vcpkg and HP-UX. It is also available as EasyBuild and Spack packages. The lstopo Android app is available in the Play Store and in F-Droid.\n\nThe following langages also have dedicated bindings:\n\nJulia on GitHub (thanks to Erik Schnetter).\n\nPerl on CPAN (thanks to Bernd Kallies).\n\nPython git tree (thanks to Guy Streeter).\n\nRust on GitHub (thanks to Michael Nitschinger).\n\nThe following software already benefit from hwloc or are being ported to it:\n\nMPI implementations:\n\nOpen MPI.\n\nThe MPICH process launcher Hydra.\n\nMVAPICH2.\n\nCEA and Paratools' Multiprocessor Computing framework (MPC).\n\nThe Newmadeleine communication library.\n\nRuntime systems and compilers:\n\nThe Chapel Parallel Programming Language.\n\nThe Legion Programming System.\n\nThe StarPU runtime system for heterogeneous multicore architectures.\n\nThe Parallel Runtime Scheduling and Execution Controller (PaRSEC) project.\n\nThe Nanos++ runtime library for OmpSs.\n\nThe High Performance ParalleX (HPX) runtime system.\n\nLLVM's OpenMP runtime.\n\nThe C++ Performance Portability Programming EcoSystem.\n\nIntel's oneTBB project.\n\nThe memkind heap manager.\n\nThe Qthreads project.\n\nThe Rose compiler.\n\nThe Portable Computing Language (POCL).\n\nThe H2M runtime for managing heterogeneous memory.\n\nThe former ForestGOMP OpenMP platform for hierarchical architectures.\n\nParallel scientific applications, libraries and toolkits:\n\nThe Gromacs software suite for high-performance molecular dynamics.\n\nThe CP2K quantum chemistry and solid state physics software package.\n\nThe Feel++ library for partial differential equations.\n\nThe Parallel Sparse matriX (PaStiX) package.\n\nThe Parallel Linear Algebra for Scalable Multi-core Architectures (PLASMA) project.\n\nThe Portable Extensible Toolkit for Scientific Computation (PETSc).\n\nThe librsb sparse linear algebra library.\n\nThe Magma dense linear algebra library.\n\nResource manager and job schedulers:\n\nThe SLURM workload manager.\n\nThe Open Grid Scheduler.\n\nThe TORQUE resource manager.\n\nUniva Grid Engine.\n\nAltair's PBS Professional solution (part of PBS Works).\n\nThe Ceph distributed storage system.\n\nPerformance analysis and debugging tools:\n\nThe performance-oriented tool suite LIKWID.\n\nThe Modular Assembly Quality Analyzer and Optimizer (MAQAO).\n\nThe interactive process viewer htop for Linux.\n\nThe parallel job inspector Padb.\n\nand even more!\n\nThe TensorFlow library for numerical computation using data flow graphs.\n\nApache Traffic Server.\n\nThe Scylla NoSQL server.\n\nGlobal Energy Optimization Power Management (GEOPM).\n\nThe Reference Implementation of the HPC Power API.\n\nThe OpenPMIx implementation of the Process Management Interface Exascale (PMIx) standard.\n\nThe aircrack-ng WiFi network security assesser.\n\nQuestions and bugs\n\nBugs should be reported in the tracker. Opening a new issue automatically displays lots of hints about how to debug and report issues.\n\nSee also the wiki page about Linux kernel bugs (or BIOS bugs) affecting locality information in hwloc.\n\nQuestions may be sent to the users or developers mailing lists.\n\nThere is also a #hwloc IRC channel on Libera Chat (irc.libera.chat) and Freenode (irc.freenode.net).\n\nPublications\n\nFor a general-purpose hwloc citations, please use the following one. This paper introduces hwloc, its goals and its implementation. It then shows how hwloc may be used by MPI implementations and OpenMP runtime systems as a way to carefully place processes and adapt communication strategies to the underlying hardware.\n\nFrançois Broquedis, Jérôme Clet-Ortega, Stéphanie Moreaud, Nathalie Furmento, Brice Goglin, Guillaume Mercier, Samuel Thibault, and Raymond Namyst. hwloc: a Generic Framework for Managing Hardware Affinities in HPC Applications. In Proceedings of the 18th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP2010), Pisa, Italia, February 2010. IEEE Computer Society Press. https://hal.inria.fr/inria-00429889\n\nFor citing how hwloc deals with new heterogeneous memory hierarchies (Knights Landing's MCDRAM, high-bandwidth memory (HBM), non-volatile memory (NVDIMM), etc), use this paper:\n\nBrice Goglin and Andrès Rubio Proaño. Using Performance Attributes for Managing Heterogeneous Memory in HPC Applications. In Proceedings of the 23rd IEEE International Workshop on Parallel and Distributed Scientific and Engineering Computing (PDSEC 2022), held in conjunction with IPDPS 2022, Lyon, France, May 2022. https://hal.inria.fr/hal-03599360\n\nWhen discussing the overhead of topology discovery and why XML or synthetic topologies are useful, use this paper:\n\nBrice Goglin. On the Overhead of Topology Discovery for Locality-aware Scheduling in HPC. In Proceedings of the 25th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP2017), St Petersburg, Russia, March 2017. https://hal.inria.fr/hal-01402755\n\nAbout the memory footprint of hwloc and the new shmem topology API in hwloc 2.0:\n\nBrice Goglin. Memory Footprint of Locality Information on Many-Core Platforms. In Proceedings of the 6th Workshop on Runtime and Operating Systems for the Many-core Era (ROME 2018), held in conjunction with IPDPS, Vancouvert, BC, Canada, May 2018. https://hal.inria.fr/hal-01644087\n\nFor citing hwloc's I/O device locality and cluster/multi-node support, please use the following one instead. This paper explains how I/O locality is managed in hwloc, how device details are represented, how hwloc interacts with other libraries, and how multiple nodes such as a cluster can be efficiently managed.\n\nBrice Goglin. Managing the Topology of Heterogeneous Cluster Nodes with Hardware Locality (hwloc). In Proceedings of 2014 International Conference on High Performance Computing & Simulation (HPCS 2014), Bologna, Italy, July 2014. https://hal.inria.fr/hal-00985096\n\nFor citing hwloc's hierarchical modeling of computing, memory and I/O resources as well as multi-node support, use this paper:\n\nBrice Goglin. Towards the Structural Modeling of the Topology of next-generation heterogeneous cluster Nodes with hwloc. Inria, November 2016. https://hal.inria.fr/hal-01400264\n\nHistory / credits\n\nhwloc is the evolution and merger of the libtopology and Portable Linux Processor Affinity (PLPA) projects. Because of functional and ideological overlap, these two code bases and ideas were merged and released under the name \"hwloc\" as an Open MPI sub-project. hwloc is now mostly developed by the TADaaM team at Inria (Bordeaux, France).\n\nlibtopology was initially developed by the Inria Runtime team-project as a way to discover hardware affinities inside the Marcel threading library. With the advent of multicore machines, this work became interesting for much more than multithreading. So libtopology was extracted from Marcel and became an independent library.\n\nPortability tests are performed thanks to the Inria Continuous Integration platform.\n\nHow do you pronounce \"hwloc\"?\n\nWhen in doubt, say \"hardware locality.\"\n\nSome of the core developers say \"H. W. Loke\"; others say \"H. W. Lock\". We've heard several other pronunciations as well. We don't really have a strong preference for how you say it; we chose the name for its Google-ability, not its pronunciation.\n\nBut now at least you know how we pronounce it. :-)"
    }
}