{
    "id": "dbpedia_8305_3",
    "rank": 27,
    "data": {
        "url": "https://journals.plos.org/plosone/article%3Fid%3D10.1371/journal.pone.0221068",
        "read_more_link": "",
        "language": "en",
        "title": "TreeCluster: Clustering biological sequences using phylogenetic trees",
        "top_image": "https://journals.plos.org/plosone/article/figure/image?id=10.1371/journal.pone.0221068.g006&size=inline",
        "meta_img": "https://journals.plos.org/plosone/article/figure/image?id=10.1371/journal.pone.0221068.g006&size=inline",
        "images": [
            "https://journals.plos.org/resource/img/orcid_16x16.png",
            "https://journals.plos.org/resource/img/orcid_16x16.png",
            "https://journals.plos.org/resource/img/logo-plos.png",
            "https://journals.plos.org/plosone/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g001",
            "https://journals.plos.org/plosone/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g002",
            "https://journals.plos.org/plosone/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.t001",
            "https://journals.plos.org/plosone/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g003",
            "https://journals.plos.org/plosone/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g004",
            "https://journals.plos.org/plosone/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g005",
            "https://journals.plos.org/plosone/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g006",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g001",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e001",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e002",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e003",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e004",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e005",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e006",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e007",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e008",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e009",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e010",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e011",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e012",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e013",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e014",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e015",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e016",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e017",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g002",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.t001",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g003",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g004",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pone.0221068.e018",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g005",
            "https://journals.plos.org/plosone/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pone.0221068.g006",
            "https://journals.plos.org/resource/img/icon.reddit.16.png",
            "https://journals.plos.org/resource/img/icon.fb.16.png",
            "https://journals.plos.org/resource/img/icon.linkedin.16.png",
            "https://journals.plos.org/resource/img/icon.mendeley.16.png",
            "https://journals.plos.org/resource/img/icon.twtr.16.png",
            "https://journals.plos.org/resource/img/icon.email.16.png",
            "https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_BW_horizontal.svg",
            "https://journals.plos.org/resource/img/logo-plos-footer.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Phylogenetic analysis",
            "Phylogenetics",
            "Trees",
            "Sequence alignment",
            "Algorithms",
            "HIV epidemiology",
            "HIV",
            "Multiple alignment calculation"
        ],
        "tags": null,
        "authors": [
            "Uyen Mai",
            "Xingfan Jia",
            "Siavash Mirarab",
            "Metin Balaban",
            "Niema Moshiri"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Clustering homologous sequences based on their similarity is a problem that appears in many bioinformatics applications. The fact that sequences cluster is ultimately the result of their phylogenetic relationships. Despite this observation and the natural ways in which a tree can define clusters, most applications of sequence clustering do not use a phylogenetic tree and instead operate on pairwise sequence distances. Due to advances in large-scale phylogenetic inference, we argue that tree-based clustering is under-utilized. We define a family of optimization problems that, given an arbitrary tree, return the minimum number of clusters such that all clusters adhere to constraints on their heterogeneity. We study three specific constraints, limiting (1) the diameter of each cluster, (2) the sum of its branch lengths, or (3) chains of pairwise distances. These three problems can be solved in time that increases linearly with the size of the tree, and for two of the three criteria, the algorithms have been known in the theoretical computer scientist literature. We implement these algorithms in a tool called TreeCluster, which we test on three applications: OTU clustering for microbiome data, HIV transmission clustering, and divide-and-conquer multiple sequence alignment. We show that, by using tree-based distances, TreeCluster generates more internally consistent clusters than alternatives and improves the effectiveness of downstream applications. TreeCluster is available at https://github.com/niemasd/TreeCluster.",
        "meta_lang": "en",
        "meta_favicon": "/resource/img/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0221068",
        "text": "Algorithms\n\nProblem definition.\n\nLet T = (V, E) be an unrooted binary tree represented by an undirected acyclic graph with vertices V (each with degree one or three), weighted edges E, and leafset . We denote the path length between leaves u and v on T with dT (u, v) or simply d(u, v) when clear by context. The weight of an edge (u, v) (i.e., its branch length) is denoted by w(u, v).\n\nA clustering of the leaves of the tree T can be defined by cutting a subset of edges C ⊆ E. We define a partition {L1, L2⋯, LN} of to be an admissible clustering if it can be obtained by removing some edge set C from E and assigning leaves of each of the resulting connected components to a set Li (note: N ≤ |C| + 1).\n\nFor a given tree T, let be a function that maps a subset of the leafset to a real number. The purpose of fT is to characterize the diversity of elements at the leaves within each cluster, and it is often defined as a function of the edge weights in the cluster. For example, it can be the diameter of a subset: fT = maxu,v∈L dT(u, v). We define a family of problems that seek to minimize the number of clusters while each cluster has to adhere to constraints defined using fT. More formally:\n\nDefinition 1 (Min-cut partitioning problem family). Given a tree T with leafset and a real number α, find an admissible partition {L1…LN} of that satisfies ∀i, fT ≤ α and has the minimum cardinality (N) among all such clusterings.\n\nA natural way to limit the diversity within a cluster is to constrain all pairwise distances among members of the cluster to be less than a given threshold:\n\nDefinition 2 (Max-diameter min-cut partitioning problem). The Min-cut partitioning problem (Definition 1) is called Max-diameter min-cut partitioning problem when .\n\nOne potential disadvantage of max diameter min-cut partitioning is its susceptibility to outliers: the largest distance within a cluster may not be always an accurate representation of the degree of diversity in the cluster. A natural choice that may confine the effect of outliers is the following:\n\nDefinition 3 (Sum-length min-cut partitioning problem). The Min-cut partitioning problem is called Sum-length min-cut partitioning problem when where T|L is the tree T restricted to a subset of leaves L.\n\nWe also study a third problem, which we will motivate later:\n\nDefinition 4 (Single-linkage min-cut partitioning problem). The Min-cut partitioning problem is called Single-linkage min-cut partitioning problem when .\n\nNext, we will show linear-time algorithms for the Max-diameter, Sum-length, and Single-linkage min-cut partitioning problems. All three algorithms use variations of the same greedy algorithm and two of them (max and sum) have already been described in the theoretical computer science literature. Nevertheless, we reiterate the solutions using consistent terminology and provide alternative proofs of their correctness.\n\nLinear-time solution for Max-diameter min-cut partitioning.\n\nA linear-time solution for the Max-diameter min-cut partitioning problem was first published by Parley et al. [17] (with all edge weights equal to 1). We present Algorithm 1, which is similar to the Parley et al. algorithm (but adds branch lengths), and we give an alternative proof. The algorithm operates on To, which is an arbitrary rooting of T at node o. We denote the subtree rooted at an internal node u as U. Let the two children of u be called ul and ur, and let the tree rooted by them be Ul and Ur. We use wl and wr to denote w(u, ul) and w(u, ur), respectively, when clear by context.\n\nAlgorithm 1: Linear-time solution for Max-diameter min-cut partitioning\n\nInput: A tree To = (V, E) and a threshold α\n\n1 B(v) ← 0 for v ∈ V\n\n2 for u ∈ post order traversal of internal nodes of To do\n\n3 if B(ul) + wl + B(ur) + wr > α then\n\n4 if B(ul) + wl ≤ B(ur) + wr then\n\n5 E ← E − {(u, ur)}\n\n6 B(u) ← B(ul) + wl\n\n7 else\n\n8 E ← E − {(u, ul)}\n\n9 B(u) ← B(ur) + wr\n\n10 else\n\n11 B(u) ← max(B(ul) + wl, B(ur)+ wr)\n\n12 return Leafsets of every connected component in To\n\nFor a cut set C of the tree, we define B(C, u) to be the length of the path from u to the most distant connected leaf in U in the clustering defined by C. The algorithm uses a bottom-up traversal of the tree and for each node u that we visit, we may decide to cut one of its child edges. Thus, at each stage, a current clustering Cu is defined; we use B(u) a shorthand for B(Cu, u). When we arrive at node u, one or more new paths form between the two trees Ur and Ul. Among those paths, the longest one has the length B(ul) + wl + B(ur) + wr. If this value exceeds the threshold, we break either (u, ur) or (u, ul), depending on which minimizes B(u). Note that the algorithm always cuts at most one child edge of every node, and thus, B(u) is always well-defined.\n\nTheorem 1. Let A(u) be the minimum number of clusters under U, each with a diameter less than α (i.e., A(o) is the objective function). Algorithm 1 computes a clustering with the minimum A(o) for the rooted tree To. In addition, among all possible such clusterings, the algorithm picks arg minC B(C, o).\n\nCorollary 1. Let C′ be the cut set obtained by running Algorithm 1 on an arbitrary rooting To of tree T. C′ optimally solves the Max-diameter min-cut partitioning problem.\n\nThe proof of the theorem and the corollary are both given in S1 Appendix.\n\nLinear solution for the Sum-length min-cut partitioning problem.\n\nA linear-time algorithm that partitions trees into the fewest clusters, each with total node weights less than or equal to α, has been previously published by Kundu et al. [18]. In order to solve the Sum-length min-cut partitioning problem, we present an altered version of the original algorithm that works on edge (instead of node) weights and that focuses on binary trees. Algorithm 1 with two simple modifications solves the Sum-length min-cut partitioning problem optimally (see Algorithm A in S1 Appendix). The first modification is that we define the auxiliary variable B(C, u) to denote the sum of weights of all descendent edges connected to u at the stage it is processed by the algorithm. Secondly, in the bottom-up traversal of internal nodes of To, for node u, w.l.o.g, let B(ul) + wl ≥ B(ur) + wr. If the sum of branch lengths in the combined subtree exceeds α, we break the edge (u, ul). Unlike Algorithm 1, where B(ul) + wl + B(ur) + wr ≤ α, here, B(u) is set to B(ul) + wl + B(ur) + wr. The proof for the correctness of the algorithm is analogous to that of Algorithm 1 and is given in S1 Appendix.\n\nSingle-linkage min-cut partitioning.\n\nWe now address the Single-linkage min-cut partitioning problem (Definition 4), which can be considered a relaxation of the Max-diameter min-cut partitioning. To motivate this problem, first consider the following definition.\n\nDefinition 5 (Single-linkage clustering). We call a partition of to be a Single-linkage clustering when for every , a and b are in the same cluster if and only if there exists a chain , where a = c0 and b = cm+1, and for every 0 ≤ i ≤ m, we have d(ci, ci+1) ≤ α.\n\nThus, every pair of nodes is put in the same cluster if (but not only if) their distance is below the threshold (the rest follows from transitivity). The next result (proved in S1 Appendix.) motivates the choice of fT in Definition 4.\n\nProposition 1. The optimal solution to the Single-linkage min-cut partitioning problem (Definition 4) is identical to the Single-linkage clustering of Definition 5.\n\nAlgorithm 2 shows a linear-time solution to the Single-linkage min-cut partitioning problem. For each node u, the algorithm first finds the closest leaf in the left and right sub-trees of u via post-order traversal, and it then finds the closest leaf outside the sub-tree rooted at u via pre-order traversal. Then, on a post-order traversal, it cuts each child edge iff the minimum distance of leaves under it to leaves under its sibling and to any leaf outside the node both exceed the threshold. The following theorem states the correctness of the algorithm (proof is given in S1 Appendix).\n\nAlgorithm 2: Single-Linkage Single-linkage min-cut partitioning\n\n1 minBelow[u] ← minAbove[u] ← ∞ for v ← V\n\n2 for u∈ post order traversal of To do\n\n3 if u in then\n\n4 minBelow[u] ← 0;\n\n5 else\n\n6 minBelow[u] ← min(minBelow[ul] + wl, minBelow[ur] + wr);\n\n7 for u ∈ pre order traversal of To do\n\n8 if u ≠ o then\n\n9 minAbove[u] ← min(minBelow[s] + w(v, s), minAbove[v] + w(v, v));\n\n10 for u ∈ post order traversal of internal nodes of To do\n\n11 if minBelow[ul] + wl + minBelow[ur] + wr > α and\n\nminBelow[ul] + wl + minAbove[u]> α then\n\n12 E ← E\\(u, ul)\n\n13 if minBelow[ul] + wl + minBelow[ur] + wr > α and\n\nminBelow[ur] + wr + minAbove[u]>α then\n\n14 E ← E\\(u, ur)\n\n15 if minBelow[ul] + wl + minAbove[u] > α and\n\nminBelow[ur] + wr + minAbove[u] > α then\n\n16 E ← E\\(v, u)\n\n17 return Leafsets of every connected component in To\n\nTheorem 2. The partitioning computed by Algorithm 2 optimally the solves Single-linkage min-cut partitioning problem (Definition 5).\n\nClade constraint for rooted trees.\n\nSo far, we have focused on unrooted trees. This choice is partially driven by the fact that phylogenetic reconstruction tools predominantly use time-reversible models of sequence evolution (e.g. GTR [19]) and therefore output an unrooted tree. Nevertheless, researchers have developed various methods for rooting trees [20, 21], including accurate and linear-time methods such as MV rooting [16]. When a rooted tree is available, each “monophyletic clade,” i.e., group of entities that includes all descendants of their common ancestor, is a biologically meaningful unit. Thus, we may want to constrain each cluster to be a clade. These “clade” constraints make clustering easier: our algorithms can be easily altered to ascertain that each cluster is also a clade. Specifically, in Algorithm 1, when we have B(ul) + wl + B(ur) + wr > α, we simply need to cut both (u, ul) and (u, ur) (instead of cutting only the longer one). This small modification allows the Max-diameter, Sum-length, and Single-linkage min-cut partitioning problems to be solved in linear time while imposing the clade constraint.\n\nCentroid (representative) sequence.\n\nMany sequencing clustering methods produce a representative sequence per cluster, often one that is used internally by the algorithm. Our clustering approach is representative-free. However, if a representative is needed for downstream applications, several choices are available. For example, one can in linear-time find the midpoint or balance point of a cluster [16] (i.e., the node that minimizes variance of root to tip distances); then, the leaf closest to the midpoint or balance point can be used as the representative. Another alternative is to use the consensus sequence among all sequences belonging to a cluster (i.e., choosing the most frequent letter for each site). Constructing and using a consensus sequence may be preferable to using one of the given sequences as the centroid [22]. A third alternative that we explore in our results is to use ancestral sequence reconstruction. For each subtree defined by a cluster, we first root it at its balance point. Then, we perform maximum likelihood ancestral state reconstruction (ASR) and use the reconstructed root sequence as the centroid.\n\nThree applications of TreeCluster\n\nWhile sequence clustering has many applications, in this paper, we highlight three specific areas as examples.\n\nApplication 1: OTU clustering.\n\nBiological Problem. For microbiome analyses using 16S sequences generated from whole communities, the standard pipeline uses operational taxonomic units (OTUs). Sequences with similarity at or above a certain threshold (e.g. 97%) are grouped into OTUs, which are the most fine-grained level at which organisms are distinguished. All sequences assigned to the same OTU are treated as one organism in downstream analyses, such as taxonomic profiling, taxonomic identification, sample differentiation, or machine learning. The use of a similarity threshold instead of a biological concept of species is to avoid the notoriously difficult problem of defining species for microbial organisms [24, 25]. Futher, the use of clusters of similar sequences as OTUs can provide a level of robustness with respect to sequencing errors.\n\nMost applications of OTUs are closed-reference: a reference database of known organisms is selected, and OTUs are defined for reference sequences using methods such as UCLUST [2] and Dotur [3]. These methods cluster sequences based on a chosen threshold of similarity, often picking a centroid sequence to represent an OTU. Reads from a 16S sample are then compared to the OTUs, and the closest OTU is found for each read (judging distance by sequence similarity). Once all reads are processed for all samples, an OTU table can be built such that rows represent samples, columns represent OTUs, and each cell gives the frequency of an OTU in a sample. This table is then used in downstream analyses. Several large reference databases exist for these OTU-based analyses [26–28]. One of these databases, popularized through pipelines such as Qiita [29], is Greengenes [28].\n\nRegardless of the downstream application of an OTU table, one would prefer the OTUs to be maximally coherent (i.e., internally consistent) so they represent organisms as faithfully as possible. We will focus our experiments on the closed-reference OTU picking methods and the Greengenes as the reference library. However, note that open-reference OTU picking and sub-operational-taxonomic-unit (sOTU) methods [30–32] also exist and involve a similar need for sequence clustering.\n\nExisting methods. Despite the availability of hierarchical clustering tools for OTU clustering [3, 33], non-hierarchical clustering methods [2, 34] are more widely used, perhaps due to their lower computational demand. Two prominent methods are UCLUST [2] and CD-HIT [34], which share the same algorithmic strategy: for a given threshold α, UCLUST determines a set of representative sequences dynamically by assigning query sequences into representative sequences (centroids) such that, ideally, the distance between each query and its assigned centroid is less than α while distances between centroids is more than α. UCLUST is a heuristic algorithm, and the processing order of the queries may affect the resulting clustering. CD-HIT differs from UCLUST primarily in its strategy for computing distances.\n\nFormulation as min-cut partitioning. We define OTUs by solving the Min-diameter, Sum-Length, or Single-linkage min-cut partitioning problems using a chosen threshold α and an inferred ML phylogeny. Each cluster in the resulting partition is designated as an OTU.\n\nExperiments. We evaluate the quality of tree-based OTU clustering by comparing it to UCLUST as used by Greengenes [28]. We run TreeCluster on the phylogenetic tree of 203,452 sequences in the Greengenes v13.5 database in three modes: max, sum, and single-linkage. We use the following 20 thresholds: [0.005, 0.05] with a step size of 0.005, and (0.05, 0.15] with a step size of 0.01. For single-linkage, we only go up to 0.1 because, above this threshold, the number of clusters becomes much smaller than other methods.\n\nFrom the same Greengenes database, we extract OTU clusters for all available sequence identity thresholds up to 0.15 (i.e., 0.03, 0.06, 0.09, 0.12, and 0.15). We measure the quality of a clustering {L1, …, LN} by its weighted average of average pairwise distance per cluster (which we call cluster diversity for shorthand), given by the following formula: (1) where n denotes the number of sequences clustered. We compute distance d(i, j) between two elements using two methods: tree distance, which is the path length on the inferred phylogenetic tree, and sequence-based Hamming distance. Hamming distances are computed pairwise from the multiple sequence alignment of all 203,452 sequences in the Greengenes database and ignore any site that includes a gap in the pairwise alignment. Clearly, cluster diversity alone is insufficient to judge results (singletons have zero diversity). Instead, we compare methods at the same level of clustering with respect to their diversity. Thus, as we change the threshold α, we compare methods for choices of the threshold where they result in (roughly) equal numbers of clusters. Given the same number of clusters, a method with lower cluster diversity is considered preferable.\n\nWe measure the quality of a representative sequence set using two metrics. For a clustering {L1, …, LN}, let {L1, …, LN′} denote all non-singleton clusters. The first metric is the average of average distance to the centroid per cluster, formally defined as: (2) where g is a function that maps a cluster to a (representative) sequence. The second metric is the average of maximum distance to the representative per cluster, formally defined as: (3) We define these metrics on the set of non-singleton clusters because a trivial clustering which assigns many singletons will trivially have a very low value for ν and ξ (near zero).\n\nGreengenes database is distributed with precomputed representative sequence sets. For centroid selection for TreeCluster, we consider two methods g: consensus and ASR. We perform ASR using TreeTime [35] under GTR model. We use RAxML 8 [36] to infer GTR model parameters from the Greengenes multiple sequence alignment of representative sequences at 15 percent threshold. We compute distance d(i, j) between two elements using Hamming distance.\n\nApplication 2: HIV transmission cluster analyses.\n\nBiological Problem. HIV evolves rapidly, so phylogenetic relationships between sequences contain information about the history of transmission [37]. The ability to perform phylogenetic analyses of HIV sequences is critical for epidemiologists who design and evaluate HIV control strategies [38–42]. The results of these analyses can provide information about the genetic linkage [43] and transmission histories [44], as well as mixing across subpopulations [45]. A recent advancement in computational molecular epidemiology is the use of transmission clustering to predict at-risk individuals and epidemic growth: infer transmission clusters from pairwise sequence distances, monitor the growth of clusters over time, and prioritize clusters with the highest growth rates [46]. In this monitoring framework, two natural questions come about: What is the optimal way to infer transmission clusters from molecular data, and how can transmission cluster inference be performed more efficiently?\n\nExisting methods. We focus on two popular tools that perform such clustering. Cluster Picker [4] is given a distance threshold, a phylogenetic tree, and sequences. It clusters individuals such that each cluster defines the leaves of a clade in the tree, the maximum pairwise sequence-based distance in each cluster is below the threshold, and the number of clusters is minimized. HIV-TRACE is a tool that, given a distance threshold and sequences, clusters individuals such that, for each pair of individuals u and v, if the Tamura-Nei 93 (TN93) distance [47] between u and v is below the threshold, u and v are placed in the same cluster [5]. Both methods scale worse than linearly with the number of sequences (quadratically and cubically, respectively, for HIV-TRACE and Cluster Picker), and for large datasets, they can take hours, or even days, to run (however, HIV-TRACE enjoys trivial parallelism and is fast in practice).\n\nFormulation as min-cut partitioning. Transmission clustering is similar to our problem formulation in that it involves cutting edges such that the resulting clusters (as defined by the leafsets resulting from the cuts) must adhere to certain constraints. Both Cluster Picker and HIV-TRACE utilize pairwise distances computed from sequences, but when reformulated to utilize tree-based distances from an inferred phylogeny, Cluster Picker becomes analogous to our Max-diameter min-cut partitioning (with an added constraint that clusters must define clades in the phylogeny), and HIV-TRACE becomes analogous to the Single-linkage min-cut partitioning.\n\nExperiments. To evaluate the effectiveness of HIV transmission clustering, we first simulate HIV epidemic data using FAVITES [48]. For the simulation parameters, we use the parameters described in Moshiri et. al. [48] to model the San Diego HIV epidemic between 2005 and 2014. However, we deviate from the original parameter set in one key way: originally, all HIV patients were sequenced at the end time of the epidemic, yielding an ultrametric tree in the unit of time, but to better capture reality, we instead sequence each patient the first time they receive Antiretroviral Treatment (ART). In our simulations, we vary two parameters: the expected time to begin ART as well as the expected degree of the social contact network, which underlies the transmission network. Higher ART rates and lower degrees both result in a slower epidemic and change patterns of phylogenetic branch length [48]. The complete FAVITES parameter set can be found in the supplementary materials (List A in S1 Appendix). We infer phylogenies from simulated sequences under the GTR+Γ model using FastTree-II [8], and we use the MinVar algorithm to root the trees using FastRoot [49].\n\nWe use HIV-TRACE [5] as well as multiple clustering modes of TreeCluster to infer transmission clusters. We were unable to use Cluster Picker [4] due to its excessive running time. For HIV-TRACE, we use a clustering threshold of 1.5% as suggested by its authors [46]. Because HIV-TRACE estimates pairwise sequences distances under the TN93 model, [47] which tend to be underestimates of phylogenetic distance estimated under the GTR model, we use a clustering threshold of 3% for Single-Linkage TreeCluster. The default Cluster Picker threshold for Max-diameter clustering is 4.5% [4], so we use this as our clustering threshold for Max-Diameter TreeCluster (both with and without the Clade constraint). For Sum-length TreeCluster (with and without the Clade constraint), we simply double the Max-diameter threshold and use 9%. In addition to using these default thresholds, we also test a wide range of thresholds for each transmission clustering method for robustness.\n\nWe measure cluster growth from year 8 to year 9 of the simulation and select the 1,000 highest-priority individuals, where individuals are prioritized in descending order of respective cluster growth. To measure the risk of a given individual u, we count the number of HIV transmission events u → v between years 9 and 10. To measure the effectiveness of a given clustering, we average the risk of the selected top 1,000 individuals. Higher numbers imply the ability to prevent more transmissions by targeting a fixed number of individuals (1,000) and are thus desirable. As a control, we also show the mean number of transmissions per population, which is what a random selection of 1,000 individuals would give in expectation (we call this “expected” risk).\n\nApplication 3: Divide-and-conquer multiple sequence alignment.\n\nAlgorithmic idea. Tree-based clustering has also been used for multiple sequence alignment (MSA) using divide-and-conquer. To solve the MSA problem using divide-and-conquer, the tree structure can be used to divide sequences into smaller subsets (i.e., clusters), which can each be aligned separately and then merged. The phylogeny and the MSA can be inferred simultaneously by iterating between tree and MSA inference, and this technique has been used in algorithms such as SATe [50, 51] and PASTA [52]. Divide-and-conquer has been proven to be particularly useful for MSA of very large datasets [9, 10, 50]. We note that not all MSA tools use divide-and-conquer and that we only study the usage of min-cut partitioning in divide-and-conquer methods. We examine the effectiveness of min-cut partitioning in PASTA [52], a scalable software which infers both MSAs and trees for ultra-large datasets (tested for up to 1,000,000 sequences).\n\nPASTA first builds a quick-and-dirty estimate of the phylogeny that is used as a guidance to cluster the sequences. In its “divide” phase, PASTA clusters the input sequences into subsets so that each subset contains less diverse sequences than the full set. Then, an accurate (but often computationally demanding) method is run on the subsets to infer the MSA and/or the tree. Finally, the results on the subsets are merged using various techniques. The accuracy of the output depends not only on the accuracy of the base method used on the subsets and the merging method, but also on the effectiveness of the method used to divide the tree into subsets [51].\n\nPASTA computes an initial alignment using HMMs implemented in HMMER [53] and an initial tree using FastTree-II [8]; then, it performs several iterations (3 by default) of the divide-and-conquer strategy described before using MAFFT [54] for aligning subsets and using a combination of OPAL [55] and a technique using transitivity for merging subalignments. A tree is generated using FastTree-II at the end of each iteration, which is then used as the guide tree for the next iteration. The method has shown great accuracy on simulated and real data, especially in terms of tree accuracy, where it comes very close to the accuracy obtained using the true alignment, leaving little room for improvement. However, in terms of the alignment accuracy, it has substantial room for improvement on the most challenging datasets.\n\nThe clustering used in PASTA is based on the centroid-edge decomposition. Given the guide tree (available from the previous iteration), the decomposition is defined recursively: divide the tree into two halves, such that the two parts have equal size (or are as close in size as possible). Then, recurse on each subtree until there are no more than a given number of leaves (200 by default) in each subset.\n\nFormulation as min-cut partitioning. The centroid edge decomposition involves cutting edges and includes a constraint defined on the subsets. However, it is defined procedurally and does not optimize any natural objective function. The min-cut partitioning can produce a decomposition similar to the centroid decomposition in its constraints but different in outcome. We set all edge weights of the guide tree to 1 and solve the Sum-length min-cut partitioning problem with threshold α = 2m − 2; the result is a partition such that no cluster has more than m leaves and the number of subsets is minimized. Thus, this “max-size min-cut partitioning” is identical to centroid decomposition in its constraints but guarantees to find the minimum number of clusters.\n\nExperiments. To evaluate how our new decomposition impacts PASTA, we run PASTA version 1.8.3 on two datasets, and for each, we compare the accuracy of the two decomposition strategies: centroid and max-size min-cut partitioning. Other parameters (including maximum subset size) are all kept fixed for both decomposition strategies. We used two datasets both from the original PASTA paper: 10 replicates of a simulated RNAsim dataset with 10,000 leaves and a set of 19 real HomFam datasets with 10,099 to 93,681 protein sequences. The RNASim is based on a very complex model of RNA evolution. Here, the true alignment, known in simulations, is used as the reference. For HomFam, since the true alignment is not known, following previous papers, we rely on a very small number of seed sequences with a hand-curated reliable alignment as reference [9, 56]. In both cases, we measure alignment error using two standard metrics computed using FastSP [57]: SPFN (the percentage of homologies in the reference alignment not recovered in the estimated alignment) and SPFP (the percentage of homologies in the estimated alignment not present in the reference).\n\nResults for Application 1: OTU clustering\n\nOn the Greengenes dataset, as we change the threshold between 0.005 and 0.15, we get between 181, 574 and 10, 112 clusters (note that singletons are also counted). The cluster diversity has a non-linear relationship with the number of clusters: it drops more quickly with higher thresholds where fewer clusters are formed (Fig 2A and S1 Fig). Comparing the three objective functions that can be used in TreeCluster, we observe that Max-diameter and Sum-length have similar trends of cluster diversity scores, whereas Single-linkage min-cut partitioning has substantially higher diversity compared to the other two methods (S1 Fig). This pattern is observed regardless of whether tree distances or sequence distances are used, but differences are larger for tree distances. Finally, note that, even though tree distances are, as expected, larger than sequence distances (S2 Fig), the cluster diversity is lower when computed using tree distances, showing that clusters are tight in the phylogenetic space.\n\n(A) Cluster diversity (Eq 1) for Greengenes and TreeCluster versus the number of OTUs. Cluster diversity is measured both with respect to hamming distance and tree-based distance. The threshold α is shown for all data points corresponding to Greengenes and for some points of TreeCluster. See S1 Fig for comparison to other TreeCluster modes. (B) Average-average (ν) and average-maximum (ξ) distance to the centroid for Greengenes and TreeCluster versus the number of clusters. TreeCluster centroids are computed using ancestral state reconstruction or using consensus.\n\nhttps://doi.org/10.1371/journal.pone.0221068.g002\n\nCompared to the default Greengenes OTUs, which are defined using UCLUST, Max-diameter min-cut partitioning defines tighter clusters for tree-based scores (Fig 2A). When distances between sequences are measured in tree distance, the cluster diversity score for Greengenes OTUs is substantially lower for all thresholds, and the gap is larger for higher thresholds. For example, the cluster diversity of Greengenes OTUs is three times higher than TreeCluster OTUs for α = 0.15. When distances between sequences are measured in Hamming distance, Greengenes and TreeCluster perform similarly for low threshold values (e.g. α = 0.03 for Greengenes, which is similar to α = 0.02 for TreeCluster in terms of the number of clusters). However, when the number of OTUs is reduced, remarkably, TreeCluster outperforms Greengenes OTUs by up to 1.4-fold (e.g. α = 0.15). This is despite the fact that UCLUST is working based on sequence distances and TreeCluster is not.\n\nSize of the largest cluster in Greengenes is larger compared to TreeCluster (Table 1). For example, for α = 0.09, both methods have similar number of clusters (22,090 and 23,631 for Greengenes and TreeCluster, respectively) but the size of largest cluster in Greengenes is three times that of TreeCluster (1,659 versus 540). On the other hand, for the same threshold value, the number of singleton clusters comprises 48% of all clusters for Greengenes whereas only 27% of the clusters are singletons for TreeCluster. Thus, GreenGenes has more clusters that are very small or very large, compared to TreeCluster.\n\nComputed using either consensus or ASR method, representative sequences in TreeCluster are closer to other sequences of the cluster than Greengenes (Fig 2B). Using ASR representative sequences performs slightly worse than consensus centroids according to the ν score (e.g. ν = 0.062 and ν = 0.057, respectively when α = 0.15). When evaluated using ξ score, ASR representative sequences perform slightly better than consensus in all threshold levels (e.g. ξ = 0.03 and ξ = 0.04 respectively when α = 0.005) and the gap again widens as the number of clusters increases. Both types of centroids computed using TreeCluster perform better than Greengenes representative sequences according to both metrics, and the gap increases as the threshold α increases (e.g. up to 1.7-fold when α = 0.15 for ν)."
    }
}