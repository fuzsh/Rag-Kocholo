{
    "id": "yago_21673_2",
    "rank": 21,
    "data": {
        "url": "https://www.pbs.org/video/the-future-of-ai-1708554067/",
        "read_more_link": "",
        "language": "en",
        "title": "The potential dangers of AI tool creating realistic video",
        "top_image": "https://image.pbs.org/video-assets/bXTLN6H-asset-mezzanine-16x9-CVFcSu0.jpg?focalcrop=1200x630x50x10&format=auto",
        "meta_img": "https://image.pbs.org/video-assets/bXTLN6H-asset-mezzanine-16x9-CVFcSu0.jpg?focalcrop=1200x630x50x10&format=auto",
        "images": [
            "https://image.pbs.org/contentchannels/wfz2HrT-show-poster2x3-LAEAUFk.jpeg?crop=96x144&format=auto",
            "https://image.pbs.org/curate/2022080_001-qt9v1y-gq5gki.jpg?crop=280x157&format=auto",
            "https://image.pbs.org/curate/elections_1920x1280-f2i9fq.jpg?crop=280x157&format=auto",
            "https://image.pbs.org/curate/henry_louis_gates-amts8w.jpeg?crop=280x157&format=auto",
            "https://image.pbs.org/curate/climatehero_2-80lvky-ev9400.jpg?crop=280x157&format=auto",
            "https://image.pbs.org/curate/ken_burns_16x9-eo945g.jpeg?crop=280x157&format=auto",
            "https://image.pbs.org/curate-console/f21fa6f2-004d-4680-9d31-62cc83aa9320.jpg?resize=370x&format=auto",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/masterpiece_color.ed8c7900f891.svg",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/masterpiece_color.ed8c7900f891.svg",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/masterpiece_white.f0f40564e29a.svg",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbsdocumentaries_color.e1dbadb4a524.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbsdocumentaries_color.e1dbadb4a524.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbsdocumentaries_white.a5034c7aca42.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbsliving_color.afea32f13e91.svg",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbsliving_color.afea32f13e91.svg",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbsliving_white.962d4dbbaf37.svg",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbskids_amazon_color.a1b720fc5d0c.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbskids_amazon_color.a1b720fc5d0c.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/pbskids_amazon_white.e6b50d7a0556.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/appletv_color.0ae09a737b88.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/appletv_color.0ae09a737b88.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/appletv_white.52ccf54e119c.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/google-play_color.c2ac5a69b3cf.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/google-play_color.c2ac5a69b3cf.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/google-play_white.8e304072b5b4.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/vudu_color.d46831dad57b.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/vudu_color.d46831dad57b.png",
            "https://www.pbs.org/static/images/shop-megamenu__logo-row/vudu_white.4587499c276f.png",
            "https://image.pbs.org/video-assets/bXTLN6H-asset-mezzanine-16x9-CVFcSu0.jpg?resize=185x104&format=auto",
            "https://image.pbs.org/contentchannels/19/YW8sg7sQzIb1ZQWwz8Ogiw.jpg?crop=224x335&format=auto",
            "https://image.pbs.org/contentchannels/S97DSva-show-poster2x3-JxR2MR4.jpg?crop=224x335&format=auto",
            "https://image.pbs.org/contentchannels/9MagrVo-show-poster2x3-d3mylgP.jpg?crop=224x335&format=auto",
            "https://image.pbs.org/contentchannels/GhyGX6P-show-poster2x3-1Y3sgKu.jpg?crop=224x335&format=auto",
            "https://image.pbs.org/contentchannels/52/3GqTnczjtCMReDmbKk56Q.jpg?crop=224x335&format=auto"
        ],
        "movies": [
            "https://player.pbs.org/viralplayer/3088776040"
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "www.facebook.com"
        ],
        "publish_date": "2024-02-21T22:21:00+00:00",
        "summary": "",
        "meta_description": "The potentially dangerous implications of an AI tool creating extremely realistic video",
        "meta_lang": "en",
        "meta_favicon": "https://www.pbs.org/static/images/favicons/apple-touch-icon.cd53d5e995a1.png",
        "meta_site_name": "PBS.org",
        "canonical_link": "https://www.pbs.org/video/the-future-of-ai-1708554067/",
        "text": "WILLIAM BRANGHAM: I want to show you some video.\n\nLook at that adorable puppy trying to navigate those window sills in Italy, or this woman strolling at night through downtown Tokyo, or this, a street parade celebrating the Chinese lunar new year.\n\nNone of these is real.\n\nThey're 100 percent generated by an artificial intelligence program created by OpenAI called Sora.\n\nAnd they were created with a very simple text prompt, just a sentence or two saying, make a video of a stylish woman dressed in black walking down a street in Tokyo.\n\nAnd these are the results.\n\nThe implications of this technology, of being able to create extremely realistic-looking video with nothing more than a few words of suggestion, is one of the more remarkable and potentially scary developments we have seen so far in artificial intelligence.\n\nOren Etzioni studies A.I.\n\nand its implications.\n\nHe's the founder of TrueMedia.Org, an organization that fights against A.I.-based disinformation.\n\nOren Etzioni, thank you so much for being here.\n\nBefore we get to the implications of this, I wonder, when you first saw those videos and knew how they were created, what was your reaction?\n\nOREN ETZIONI, Founder, TrueMedia.Org: I was absolutely terrified.\n\nIt's the future and it's come very fast and a lot sooner than any of us expected.\n\nWILLIAM BRANGHAM: So, terrified.\n\nI have to say, I was at first struck by just -- I couldn't believe that they were able to make such extraordinarily realistic videos with such simple prompts like that.\n\nWhy does it terrify you?\n\nOREN ETZIONI: What terrifies me is deepfakes, is the use of this technology, which, of course, has many positive uses, but the use of it to create forgeries, and particularly coming up on one of the most consequential elections in history.\n\nWILLIAM BRANGHAM: So walk me through some of those.\n\nLike, sketch out some of the kinds of things that you worry this technology could be used for.\n\nOREN ETZIONI: We have already had robocalls in New Hampshire that were supposed to be by President Biden, but they weren't.\n\nThat's nothing compared to seeing videos on social media of different candidates doing things that didn't happen.\n\nWILLIAM BRANGHAM: I mean, yes, you could certainly see a late-breaking circumstance right before an election, as you're saying, where some nefarious actor posts a video.\n\nI mean, there is just something that is so convincing about this kind of video.\n\nOREN ETZIONI: We're visual animals.\n\nYou see a political candidate being rushed to the hospital.\n\nYou see talking heads getting on television, his doctor saying, it doesn't look good.\n\nBut it's all fake.\n\nAnd you can see a lot of it coming at once.\n\nWe used to have state actors doing this, but now practically anybody can do it.\n\nWILLIAM BRANGHAM: I mean, the -- what is the solution for this?\n\nI mean, some of the bigger companies say that they will put these so-called watermarks, sort of transparent image that will be imprinted on the video to signal that it is generated by A.I.\n\nBut not everyone's going to do that, certainly not the bad actors.\n\nWhat is the - - what do -- how do we get around this?\n\nOREN ETZIONI: There's no silver bullet.\n\nThe problem with watermarks is, what if they're using a model that doesn't have watermarks, doesn't have these identifying characteristics?\n\nWe are trying to build detection technology at TrueMedia.Org, so if you upload a video or social media post, we can assess whether it's true or fake.\n\nBut that can be circumvented as well.\n\nWe need better regulations.\n\nWe need better education.\n\nAnd we need everybody to chip in.\n\nWILLIAM BRANGHAM: I mean, there are times where you can see the fakery.\n\nI mean, A.I.\n\nseems to have a hard time depicting human hands for some reason.\n\nAnd even OpenAI on Sora posted some examples that are clearly where the software is off.\n\nBut isn't it just going to be this constant escalating arms race of new creations and then the trying to play catchup with detecting that fakery?\n\nOREN ETZIONI: This is moving so fast, it's going to get worse before it gets better.\n\nAnd with low-resolution video that looks like it's shot by a phone, you often will not be able to tell whether this is fake or real.\n\nWILLIAM BRANGHAM: I mean, right now, right, I'm talking to you via Skype, but you're sitting in Mexico.\n\nIt's hard to know that that's really you sitting there.\n\nOREN ETZIONI: Well, we had an instance of a scam where somebody gave away $25 million because he thought he was talking to his colleagues on a video call.\n\nIt's absolutely a case of be careful what your eyes are telling you.\n\n(LAUGHTER) WILLIAM BRANGHAM: Congress and the White House have been debating what rules or regulations that they could do to try to help solve this issue.\n\nDo you think that there is a tool or law that could come out of Washington that might address this?\n\nOREN ETZIONI: We are seeing laws and regulations coming out of the states already passed in several states, including California, Washington, Minnesota, et cetera, prohibiting deepfakes 30 days, 90 days before the election.\n\nSo I do think that there are things we can put in place.\n\nI don't know if they will come out of Washington, but they will be in place.\n\nIt won't solve the problem because foreign adversaries can do this sort of thing as well.\n\nWe need to step up and do whatever we can.\n\nWILLIAM BRANGHAM: So you think the genie is sort of out of the bottle here?\n\nOREN ETZIONI: Genie is out of the bottle.\n\nIt's just a question of how much damage it'll do in what's a very close election.\n\nWILLIAM BRANGHAM: All right, Oren Etzioni of TrueMedia.org, if that really is you sitting there, it's a pleasure to talk to you.\n\nThank you so much.\n\nOREN ETZIONI: The pleasure is mine."
    }
}