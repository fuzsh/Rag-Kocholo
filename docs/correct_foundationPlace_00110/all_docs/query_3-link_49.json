{
    "id": "correct_foundationPlace_00110_3",
    "rank": 49,
    "data": {
        "url": "https://sites.research.google/med-palm/",
        "read_more_link": "",
        "language": "en",
        "title": "PaLM: A Medical Large Language Model",
        "top_image": "https://lh3.googleusercontent.com/Ac3tnl3nfpl24JSZYDpIlHPo1Ci_dcn8-I9Gwtn4pkVHkinoZD_MttmtXOLNlH1HA6vMh_XGqCwrpRurzde8gAuAP4_bEqZ_fTas2_M=w2880-e365-pa-nu",
        "meta_img": "https://lh3.googleusercontent.com/Ac3tnl3nfpl24JSZYDpIlHPo1Ci_dcn8-I9Gwtn4pkVHkinoZD_MttmtXOLNlH1HA6vMh_XGqCwrpRurzde8gAuAP4_bEqZ_fTas2_M=w2880-e365-pa-nu",
        "images": [
            "https://lh3.googleusercontent.com/Ac3tnl3nfpl24JSZYDpIlHPo1Ci_dcn8-I9Gwtn4pkVHkinoZD_MttmtXOLNlH1HA6vMh_XGqCwrpRurzde8gAuAP4_bEqZ_fTas2_M=w2880-e365-pa-nu",
            "https://lh3.googleusercontent.com/cLOd1iPIr6Qp2sQg038Pl1OgOp7Fq2ZXb4bLeGTnkRUKo7H00sDCj99-_XzBu4_cv8EarQTAVoZAWiYx8_hxPCAcn_XMIwe6IHTcyw=w2880-e365-pa-nu",
            "https://storage.googleapis.com/googwebreview.appspot.com/grow-ext-cloud-images-uploads/2z73455wyhhm-5D5tE8JeAvxYJpessX4vKb-bb5be944f5ac55cdfda8c1f334eda745-USMLE_30FE2A5B.svg",
            "https://lh3.googleusercontent.com/W208O3VBTHHApTTUQbtrpeWjyf8YNWy74uEmxVlKUUww60GRAXekmQYDo_v2ClSV-bj4a-ZxP5dkmWGHkLlsHTfPHIoLV1XROdTb3Q=w2880-e365-pa-nu",
            "https://storage.googleapis.com/googwebreview.appspot.com/grow-ext-cloud-images-uploads/2z73455wyhhm-6a0EAA6NXfSVouEY68yb8-93182defe96ead44a758434a32f7001b-QA_Card_-_incontinence_9BD2D9D4.svg",
            "https://storage.googleapis.com/googwebreview.appspot.com/grow-ext-cloud-images-uploads/2z73455wyhhm-6JGjnId4AW6kSYBdsLRjMK-6076cb193098b83aad1caa5dbdc6cc9c-QA_Card_-_rosacea_1D5D53C6.svg",
            "https://storage.googleapis.com/googwebreview.appspot.com/grow-ext-cloud-images-uploads/2z73455wyhhm-6pW737w3ejFcTLP5Y7i7fs-ad550b0d8a1ea1ba14f9a3ac3c3cb587-QA_Card_-_CT_scan_32AF0EC9.svg",
            "https://lh3.googleusercontent.com/moE5KML0hMTaoyka5GbKVkirCuKz7_N-3oY8fHWCjLn6GNmkyce-hJX2aSo74Oo68_D3n4pLC9X4Q5gzcBwUFq7vI8aN0xvBsWgSf1a4=w2880-e365-pa-nu"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Discover Med-PaLM, a large language model designed for medical purposes. See how we developed our AI system to accurately answer medical questions.",
        "meta_lang": "en",
        "meta_favicon": "https://research.google/static/images/favicon-6da5620880159634213e197fafca1dde0272153be3e4590818533fab8d040770.ico",
        "meta_site_name": "Med-PaLM: A Medical Large Language Model - Google Research",
        "canonical_link": "https://sites.research.google/med-palm/",
        "text": "Med-PaLM is a large language model (LLM) designed to provide high quality answers to medical questions. Our second version, Med-PaLM 2, is one of the research models that powers MedLMâ a family of foundation models fine-tuned for the healthcare industry. MedLM is now available to Google Cloud customers who have been exploring a range of applications, from basic tasks to complex workflows.\n\nMed-PaLM harnesses the power of Googleâs large language models, which we have aligned to the medical domain and evaluated using medical exams, medical research, and consumer queries. Our first version of Med-PaLM, preprinted in late 2022 and published in Nature in July 2023, was the first AI system to surpass the pass mark (>60%) in the U.S. Medical Licensing Examination (USMLE) style questions. Med-PaLM also generates accurate, helpful long-form answers to consumer health questions, as judged by panels of physicians and users.\n\nWe introduced Med-PaLM 2 at Google Healthâs annual event, The Check Up, in March 2023. Med-PaLM 2 was the first to reach human expert level on answering USMLE-style questions. According to physicians, the model's long-form answers to consumer medical questions improved substantially.\n\nMedical questionâanswering: a grand challenge for AI\n\nProgress in AI over the last decade has enabled it to play an increasingly important role in healthcare and medicine. Breakthroughs such as the Transformer have enabled LLMs â such as PaLM âÂ and other large models to scale to billions of parametersletting generative AI move beyond the limited pattern-spotting of earlier AIs and into the creation of novel expressions of content, from speech to scientific modeling.Â\n\nDeveloping AI that can answer medical questions accurately has been a long-standing challenge with several research advances over the past few decades. While the topic is broad, answering USMLE-style questions has recently emerged as a popular benchmark for evaluating medical question answering performance.\n\nAbove is an example USMLE-style question. You are presented with a vignette containing a description of the patient, symptoms, and medications.\n\nAnswering the question accurately requires the reader to understand symptoms, examine findings from a patientâs tests, perform complex reasoning about the likely diagnosis, and ultimately, pick the right answer for what disease, test, or treatment is most appropriate. In short, a combination of medical comprehension, knowledge retrieval, and reasoning is necessary to do well. It takes years of training for clinicians to be able to accurately and consistently answer these questions.\n\nThe generation capabilities of large language models also enable them to produce long-form answers to consumer medical questions. However, ensuring model responses are accurate, safe, and helpful has been a crucial research challenge, especially in this safety-critical domain.\n\nEvaluating answer quality\n\nWe assessed Med-PaLM and Med-PaLM 2 against a benchmark we call âMultiMedQAâ, which combines seven question answering datasets spanning professional medical exams, medical research, and consumer queries. Med-PaLM was the first AI system to obtain a passing score on USMLE-style questions from the MedQA dataset, with an accuracy of 67.6%. Med-PaLM 2 improves on this further with state of the art performance of 86.5%.\n\nImportantly, in this work we go beyond multiple-choice accuracy to measure and improve model capabilities in medical question answering. Our modelâs long-form answers were tested against several criteria â including scientific factuality, precision, medical consensus, reasoning, bias, and likelihood of possible harm â which were evaluated by clinicians and non-clinicians from a range of backgrounds and countries. Both Med-PaLM and Med-PaLM 2 performed encouragingly across three datasets of consumer medical questions. In a pairwise study, Med-PaLM 2 answers were preferred to physician answers across eight of nine axes considered.\n\nExtending Med-PaLM 2 Beyond Language\n\nThe practice of medicine is inherently multi-modal and incorporates information from images, electronic health records, sensors, wearables, genomics and more. We believe AI systems that leverage these data at scale using self-supervised learning with careful consideration of privacy, safety and health equity will be the foundation of the next generation of medical AI systems that scale world-class healthcare to everyone.\n\nBuilding on the âPaLM-Eâ vision-language model, we designed a multimodal version of Med-PaLM, called Med-PaLM M. This system can synthesize and communicate information from images like chest X-rays, mammograms, and more to help doctors provide better patient care. Within scope are several modalities alongside language: dermatology, retina, radiology (3D and 2D), pathology, health records and genomics. Weâre excited to explore how this technology can benefit clinicians in the future.\n\nLimitations\n\nWhile Med-PaLM 2 reached state-of-the-art performance on several multiple-choice medical question answering benchmarks, and our human evaluation shows answers compare favorably to physician answers across several clinically important axes, we know that more work needs to be done to ensure these models are safely and effectively deployed.\n\nCareful consideration will need to be given to the ethical deployment of this technology including rigorous quality assessment in different clinical settings with guardrails to mitigate against risks. For example, the potential harms of using a LLM for diagnosing or treating an illness are much greater than using a LLM for information about a disease or medication. Additional research will be needed to assess LLMs used in healthcare for homogenization and amplification of biases and security vulnerabilities inherited from base models.\n\nWe dive into many important areas for further research in our Med-PaLM and Med-PaLM 2 papers."
    }
}