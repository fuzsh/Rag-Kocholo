{
    "id": "dbpedia_3634_0",
    "rank": 93,
    "data": {
        "url": "https://profiles.stanford.edu/michelle-odden",
        "read_more_link": "",
        "language": "en",
        "title": "Michelle Odden's Profile",
        "top_image": "https://profiles.stanford.edu/images/favicon.ico;jsessionid=FD12D1D4265D036D5A046D34F6E1543F.cap-su-capappprd98?r=10.8.0",
        "meta_img": "https://profiles.stanford.edu/images/favicon.ico;jsessionid=FD12D1D4265D036D5A046D34F6E1543F.cap-su-capappprd98?r=10.8.0",
        "images": [
            "https://profiles.stanford.edu/proxy/api/cap/profiles/200836/resources/profilephoto/350x350.1658770071479.jpg",
            "https://profiles.stanford.edu/images/orcid_32x32.png",
            "https://profiles.stanford.edu/images/orcid_32x32.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Michelle Odden is part of Stanford Profiles, official site for faculty, postdocs, students and staff information (Expertise, Bio, Research, Publications, and more). The site facilitates research and collaboration in academic endeavors.",
        "meta_lang": "en",
        "meta_favicon": "/images/favicon.ico;jsessionid=FD12D1D4265D036D5A046D34F6E1543F.cap-su-capappprd98?r=10.8.0",
        "meta_site_name": "",
        "canonical_link": "https://profiles.stanford.edu/michelle-odden;jsessionid=FD12D1D4265D036D5A046D34F6E1543F.cap-su-capappprd98",
        "text": "Abstract\n\nFor older adults with kidney failure who are not referred for transplant, medical management is an alternative to dialysis.To compare survival and home time between older adults who started dialysis at an estimated glomerular filtration rate (eGFR) less than 12 mL/min/1.73 m2 and those who continued medical management.Observational cohort study using target trial emulation.U.S. Department of Veterans Affairs, 2010 to 2018.Adults aged 65 years or older with chronic kidney failure and eGFR below 12 mL/min/1.73 m2 who were not referred for transplant.Starting dialysis within 30 days versus continuing medical management.Mean survival and number of days at home.Among 20 440 adults (mean age, 77.9 years [SD, 8.8]), the median time to dialysis start was 8.0 days in the group starting dialysis and 3.0 years in the group continuing medical management. Over a 3-year horizon, the group starting dialysis survived 770 days and the group continuing medical management survived 761 days (difference, 9.3 days [95% CI, -17.4 to 30.1 days]). Compared with the group continuing medical management, the group starting dialysis had 13.6 fewer days at home (CI, 7.7 to 20.5 fewer days at home). Compared with the group continuing medical management and forgoing dialysis completely, the group starting dialysis had longer survival by 77.6 days (CI, 62.8 to 91.1 days) and 14.7 fewer days at home (CI, 11.2 to 16.5 fewer days at home).Potential for unmeasured confounding due to lack of symptom assessments at eligibility; limited generalizability to women and nonveterans.Older adults starting dialysis when their eGFR fell below 12 mL/min/1.73 m2 who were not referred for transplant had modest gains in life expectancy and less time at home.U.S. Department of Veterans Affairs and National Institutes of Health.\n\nView details for DOI 10.7326/M23-3028\n\nView details for PubMedID 39159459\n\nAbstract\n\nIt is known that cesarean birth affects maternal outcomes in subsequent pregnancies, but specific effect estimates are lacking. We sought to quantify the effect of cesarean birth reduction among nulliparous, term, singleton, vertex (NTSV) births (i.e., preventable cesarean births) on severe maternal morbidity (SMM) in the second birth.We examined birth certificates linked with maternal hospitalization data (2007-19) from California for NTSV births with a second birth (N = 779,382). The exposure was cesarean delivery in first birth and the outcome was SMM in the second birth. We used adjusted Poisson regression models to calculate risk ratios and population attributable fraction for SMM in the second birth and conducted a counterfactual impact analysis to estimate how lowering NTSV cesarean births could reduce SMM in second birth.The adjusted risk ratio for SMM in the second birth given a prior cesarean birth was 1.7 (95% CI 1.5-1.9); 15.5% (95% CI 15.3%-15.7%) of this SMM may be attributable to prior cesarean birth. In a counterfactual analysis where 12% of the California population least likely to get a cesarean birth instead delivered vaginally, we observed 174 fewer SMM events in a population of individuals with a low-risk first birth and a subsequent birth.In our counterfactual analysis, lowering primary cesarean birth among a NTSV population was associated with fewer downstream SMM events in subsequent births and overall. Additionally, our findings reflect the importance of considering the cumulative accrual of risks across the reproductive life-course.\n\nView details for DOI 10.1097/EDE.0000000000001775\n\nView details for PubMedID 39058553\n\nAbstract\n\nBACKGROUND: Mitochondrial dysfunction manifests in neurodegenerative diseases and other age-associated disorders. In this study, we examined variation in inherited mitochondrial DNA (mtDNA) sequences in Black and White participants from two large aging studies to identify variants related to cognitive function.METHODS: Participants included self-reported Black and White adults aged ≥ 70 years in the Lifestyle Interventions and Independence for Elders (LIFE; N=1319) and Health Aging and Body Composition (Health ABC; N=7888) studies. Cognitive function was measured by the digit-symbol substitution test (DSST), and the Modified Mini-Mental State Exam (3MSE) at baseline and over follow-up in LIFE (3.6 years) and Health ABC (10 years). We examined joint effects of multiple variants across 16 functional mitochondrial regions with cognitive function using a sequence kernel association test. Based on these results, we prioritized meta-analysis of common variants in Black and White participants using mixed effects models. A Bonferroni adjusted p-value of <0.05 was considered statistically significant.RESULTS: Joint variation in subunits ND1, ND2, and ND5 of Complex I, 12S RNA, and hypervariable region (HVR) were significantly associated with DSST and 3MSE at baseline. In meta-analyses among Black participants, variant m.4216T>C, ND1 was associated with a faster decline in 3MSE, and variant m.462C>T in the HVR was associated with a slower decline in DSST. Variant m.5460G>C, ND2 was associated with slower and m.182C>T in the HVR was associated with faster decline in 3MSE in White participants.CONCLUSION: Among Black and White adults, oxidative phosphorylation Complex I variants were associated with cognitive function.\n\nView details for DOI 10.1093/gerona/glae170\n\nView details for PubMedID 39007867\n\nAbstract\n\nAntihypertensive treatment changes are common in long-term care residents, yet data on the frequency and predictors of changes are lacking. We described the patterns of antihypertensive changes and examined the triggering factors.Retrospective cohort study.A total of 24,870 Department of Veterans Affairs (VA) nursing home residents ≥65 years with long-term stays (≥180 days) from 2006 to 2019.We obtained data from the VA Corporate Data Warehouse. Based on Bar Code Medication Administration medication data, we defined 2 types of change events in 180 days of admission: deprescribing (reduced number of antihypertensives or dose reduction of ≥30% compared with the previous week and maintained for at least 2 weeks) and intensification (opposite of deprescribing). Mortality was identified within 2 years after admission.More than 85% of residents were prescribed antihypertensives and 68% of them experienced ≥1 change event during the first 6 months of the nursing home stay. We categorized residents into 10 distinct patterns: no change (27%), 1 deprescribing (11%), multiple deprescribing (5%), 1 intensification (10%), multiple intensification (7%), 1 deprescribing followed by 1 intensification (3%), 1 intensification followed by 1 deprescribing (4%), 3 changes with mixed events (7%), >3 changes with mixed events (10%), and no antihypertensive use (15%). Treatment changes were more frequent in residents with better physical function and/or cognitive function. Potentially triggering factors differed by the type of antihypertensive change: incident high blood pressure and cardiovascular events were associated with intensification, and low blood pressure, weight loss, and falls were associated with deprescribing. Death occurred in 7881 (32%) residents over 2 years. The highest mortality was for those without antihypertensive medication (incidence = 344/1000 person-years).Patterns of medication changes existing in long-term care residents are complex. Future studies should explore the benefits and harms of these antihypertensive treatment changes.\n\nView details for DOI 10.1016/j.jamda.2024.105119\n\nView details for PubMedID 38950584\n\nAbstract\n\nAir pollution is a modifiable risk factor for dementia. Yet, studies on specific sources of air pollution (i.e., toxic chemical emissions from industrial facilities) and dementia risk are scarce. We examined associations between toxicity-weighted concentrations of industrial pollution and dementia outcomes among a large, multi-site cohort of older adults.Participants (n = 2770) were ≥ 65 years old (Mean = 75.3, SD = 5.1 years) from the Cardiovascular Health Cognition Study (1992-1999). Toxicity-weighted concentrations were estimated using the Risk Screening Environmental Indicator (RSEI) model which incorporates total reported chemical emissions with toxicity, fate, and transport models. Estimates were aggregated to participants' baseline census tract, averaged across 1988-1992, and log2-transformed. Dementia status was clinically adjudicated in 1998-1999 and categorized by subtype (Alzheimer's, vascular, mixed). We assessed whether RSEI-estimated toxicity-weighted concentrations were associated with 1) odds of prevalent dementia and 2) incident dementia risk by subtype.After adjusting for individual and census-tract level covariates, a doubling in toxicity-weighted concentrations was associated with 9 % higher odds of prevalent dementia (OR = 1.09, 95 % CI: 1.00, 1.19). In discrete-time survival models, each doubling in toxicity-weighted concentrations was associated with a 16 % greater hazard of vascular dementia (HR = 1.16, 95 % CI: 1.01, 1.34) but was not significantly associated with all-cause, Alzheimer's disease, or mixed dementia (p's > 0.05).Living in regions with higher toxicity-weighted concentrations was associated with higher odds of prevalent dementia and a higher risk of incident vascular dementia in this large, community-based cohort of older adults. These findings support the need for additional studies to examine whether toxic chemical emissions from industrial and federal facilities may be a modifiable target for dementia prevention.\n\nView details for DOI 10.1016/j.scitotenv.2024.173706\n\nView details for PubMedID 38866169\n\nAbstract\n\nHeart failure (HF) and frailty frequently coexist and may share a common pathobiology, although the underlying mechanisms remain unclear. Understanding these mechanisms may provide guidance for preventing and treating both conditions.To identify shared pathways between incident HF and frailty in late life using large-scale proteomics.In this cohort study, 4877 aptamers (Somascan v4) were measured among participants in the community-based longitudinal Atherosclerosis Risk In Communities (ARIC) cohort study at visit 3 (V3; 1993-1995; n = 10 638) and at visit 5 (V5; 2011-2013; n = 3908). Analyses were externally replicated among 3189 participants in the Cardiovascular Health Study (CHS). Data analysis was conducted from February 2022 to June 2023.Protein aptamers, measured at study V3 and V5.Outcomes assessed included incident HF hospitalization after V3 and after V5, prevalent frailty at V5, and incident frailty between V5 and visit 6 (V6; 2016-2017; n = 4131). Frailty was assessed using the Fried criteria. Analyses were adjusted for age, gender, race, field center, hypertension, diabetes, smoking status, body mass index, estimated glomerular filtration rate, prevalent coronary heart disease, prevalent atrial fibrillation, and history of myocardial infarction. Mendelian randomization (MR) analysis was performed to assess potential causal effects of candidate proteins on HF and frailty.A total of 4877 protein aptamers were measured among 10 638 participants at V3 (mean [SD] age, 60 [6] years; 4886 [46%] men). Overall, 286 proteins were associated with incident HF after V3 (822 events; P < 1.0 × 10-5), 83 of which were also associated with incident after V5 (336 events; P < 1.7 × 10-4). Among HF-free participants at V5 (n = 3908; mean [SD] age, 75 [5] years; 1861 [42%] men), 48 of 83 HF-associated proteins were associated with prevalent frailty (223 cases; P < 6.0 × 10-4), 18 of which were also associated with incident frailty at V6 (152 cases; P < 1.0 × 10-3). These proteins enriched fibrosis and inflammation pathways and demonstrated stronger associations with incident HF with preserved ejection fraction (HFpEF) than HF with reduced ejection fraction. All 18 proteins were associated with both prevalent frailty and incident HF in CHS. MR identified potential causal effects of several proteins on frailty and HF.In this study, the proteins associated with risk of HF and frailty enrich for pathways related to inflammation and fibrosis as well as risk of HFpEF. Several of these proteins could potentially contribute to the shared pathophysiology of frailty and HF.\n\nView details for DOI 10.1001/jamacardio.2024.1178\n\nView details for PubMedID 38809565\n\nAbstract\n\nNeighborhood concentration of racial, income, education, and housing deprivation is known to be associated with higher rates of hypertension. The objective of this study is to examine the association between tract-level spatial social polarization and hypertension in a cohort with relatively equal access to health care, a Veterans Affairs nursing home.41,973 long-term care residents aged ≥65 years were matched with tract-level Indices of Concentration at the Extremes across four socioeconomic domains. We modeled high blood pressure against these indices controlling for individual-level cardiovascular confounders.We found participants who had resided in the most disadvantaged quintile had a 1.10 (95% 1.01, 1.19) relative risk of high blood pressure compared to those in the other quintiles for the joint measuring race/ethnicity and income domain.We achieved our objective by demonstrating that concentrated deprivation is associated with worse cardiovascular outcomes even in a population with equal access to care. Measures that jointly consider economic and racial/ethnic polarization elucidate larger disparities than single domain measures.\n\nView details for DOI 10.1016/j.healthplace.2024.103243\n\nView details for PubMedID 38663339\n\nAbstract\n\nLimited evidence exists on the association between initiation of antihypertensive medication and risk of fractures in older long-term nursing home residents.To assess the association between antihypertensive medication initiation and risk of fracture.This was a retrospective cohort study using target trial emulation for data derived from 29 648 older long-term care nursing home residents in the Veterans Health Administration (VA) from January 1, 2006, to October 31, 2019. Data were analyzed from December 1, 2021, to November 11, 2023.Episodes of antihypertensive medication initiation were identified, and eligible initiation episodes were matched with comparable controls who did not initiate therapy.The primary outcome was nontraumatic fracture of the humerus, hip, pelvis, radius, or ulna within 30 days of antihypertensive medication initiation. Results were computed among subgroups of residents with dementia, across systolic and diastolic blood pressure thresholds of 140 and 80 mm Hg, respectively, and with use of prior antihypertensive therapies. Analyses were adjusted for more than 50 baseline covariates using 1:4 propensity score matching.Data from 29 648 individuals were included in this study (mean [SD] age, 78.0 [8.4] years; 28 952 [97.7%] male). In the propensity score-matched cohort of 64 710 residents (mean [SD] age, 77.9 [8.5] years), the incidence rate of fractures per 100 person-years in residents initiating antihypertensive medication was 5.4 compared with 2.2 in the control arm. This finding corresponded to an adjusted hazard ratio (HR) of 2.42 (95% CI, 1.43-4.08) and an adjusted excess risk per 100 person-years of 3.12 (95% CI, 0.95-6.78). Antihypertensive medication initiation was also associated with higher risk of severe falls requiring hospitalizations or emergency department visits (HR, 1.80 [95% CI, 1.53-2.13]) and syncope (HR, 1.69 [95% CI, 1.30-2.19]). The magnitude of fracture risk was numerically higher among subgroups of residents with dementia (HR, 3.28 [95% CI, 1.76-6.10]), systolic blood pressure of 140 mm Hg or higher (HR, 3.12 [95% CI, 1.71-5.69]), diastolic blood pressure of 80 mm Hg or higher (HR, 4.41 [95% CI, 1.67-11.68]), and no recent antihypertensive medication use (HR, 4.77 [95% CI, 1.49-15.32]).Findings indicated that initiation of antihypertensive medication was associated with elevated risks of fractures and falls. These risks were numerically higher among residents with dementia, higher baseline blood pressures values, and no recent antihypertensive medication use. Caution and additional monitoring are advised when initiating antihypertensive medication in this vulnerable population.\n\nView details for DOI 10.1001/jamainternmed.2024.0507\n\nView details for PubMedID 38648065\n\nView details for PubMedCentralID PMC11036308\n\nAbstract\n\nINTRODUCTION: Accurate data capture is integral for research and quality improvement efforts. Unfortunately, limited guidance for defining and documenting regional anesthesia has resulted in wide variation in documentation practices, even within individual hospitals, which can lead to missing and inaccurate data. This cross-sectional study sought to evaluate the performance of a natural language processing (NLP)-based algorithm developed to identify regional anesthesia within unstructured clinical notes.METHODS: We obtained postoperative clinical notes for all patients undergoing elective non-cardiac surgery with general anesthesia at one of six Veterans Health Administration hospitals in California between January 1, 2017, and December 31, 2022. After developing and executing our algorithm, we compared our results to a frequently used referent, the Corporate Data Warehouse structured data, to assess the completeness and accuracy of the currently available data. Measures of agreement included sensitivity, positive predictive value, false negative rate, and accuracy.RESULTS: We identified 27,713 procedures, of which 9310 (33.6%) received regional anesthesia. 96.6% of all referent regional anesthesia cases were identified in the clinic notes with a very low false negative rate and good accuracy (false negative rate=0.8%, accuracy=82.5%). Surprisingly, the clinic notes documented more than two times the number of regional anesthesia cases that were documented in the referent (algorithm n=9154vs referent n=4606).DISCUSSION: While our algorithm identified nearly all regional anesthesia cases from the referent, it also identified more than two times as many regional anesthesia cases as the referent, raising concerns about the accuracy and completeness of regional anesthesia documentation in administrative and clinical databases. We found that NLP was a promising alternative for identifying clinical information when existing databases lack complete documentation.\n\nView details for DOI 10.1136/rapm-2024-105340\n\nView details for PubMedID 38580338\n\nAbstract\n\nLittle is known about how well trial participants with chronic kidney disease (CKD) represent real-world adults with CKD. We assessed the population representativeness of clinical trials supporting the 2021 Kidney Disease: Improving Global Outcomes blood pressure (BP) guidelines in real-world adults with CKD.Using a cross-sectional analysis, we identified patients with CKD who met the guideline definition of hypertension based on use of antihypertensive medications or sustained systolic BP ≥120 mm Hg in 2019 in the Veterans Affairs and Kaiser Permanente of Southern California. We applied the eligibility criteria from 3 BP target trials, SPRINT (Systolic Pressure Intervention Trial), ACCORD (Action to Control Cardiovascular Risk in Diabetes), and AASK (African American Study of Kidney Disease), to estimate the proportion of adults with a systolic BP above the guideline-recommended target and the proportion who met eligibility criteria for ≥1 trial. We identified 503 480 adults in the Veterans Affairs and 73 412 adults in Kaiser Permanente of Southern California with CKD and hypertension in 2019. We estimated 79.7% in the Veterans Affairs and 87.3% in the Kaiser Permanente of Southern California populations had a systolic BP ≥120 mm Hg; only 23.8% [23.7%-24.0%] in the Veterans Affairs and 20.8% [20.5%-21.1%] in Kaiser Permanente of Southern California were trial-eligible. Among trial-ineligible patients, >50% met >1 exclusion criteria.Major BP target trials were representative of fewer than 1 in 4 real-world adults with CKD and hypertension. A large proportion of adults who are at risk for cardiovascular morbidity from hypertension and susceptible to adverse treatment effects lack relevant treatment information.\n\nView details for DOI 10.1161/JAHA.123.031742\n\nView details for PubMedID 38533947\n\nAbstract\n\nThe identification of protein targets that exhibit anti-aging clinical potential could inform interventions to lengthen the human health span. Most previous proteomics research has been focused on chronological age instead of longevity. We leveraged two large population-based prospective cohorts with long follow-ups to evaluate the proteomic signature of longevity defined by survival to 90 years of age. Plasma proteomics was measured using a SOMAscan assay in 3067 participants from the Cardiovascular Health Study (discovery cohort) and 4690 participants from the Age Gene/Environment Susceptibility-Reykjavik Study (replication cohort). Logistic regression identified 211 significant proteins in the CHS cohort using a Bonferroni-adjusted threshold, of which 168 were available in the replication cohort and 105 were replicated (corrected p value <0.05). The most significant proteins were GDF-15 and N-terminal pro-BNP in both cohorts. A parsimonious protein-based prediction model was built using 33 proteins selected by LASSO with 10-fold cross-validation and validated using 27 available proteins in the validation cohort. This protein model outperformed a basic model using traditional factors (demographics, height, weight, and smoking) by improving the AUC from 0.658 to 0.748 in the discovery cohort and from 0.755 to 0.802 in the validation cohort. We also found that the associations of 169 out of 211 proteins were partially mediated by physical and/or cognitive function. These findings could contribute to the identification of biomarkers and pathways of aging and potential therapeutic targets to delay aging and age-related diseases.\n\nView details for DOI 10.1111/acel.14136\n\nView details for PubMedID 38440820\n\nAbstract\n\n“Sick quitting”, a phenomenon describing reductions in alcohol consumption following poor health, may explain observations that alcohol appears protective for frailty risk. We examined associations between frailty and reductions in drinking frequency among people with HIV (PWH). At six Centers for AIDS Research Network of Integrated Clinical Systems (CNICS) sites between January 2012 and August 2021, we assessed whether frailty, measured via validated modified frailty phenotype, precedes reductions in drinking frequency. We associated time-updated frailty with quitting and reducing frequency of any drinking and heavy episodic drinking (HED), adjusted for demographic and clinical characteristics in Cox models. Among 5,654 PWH reporting drinking, 60% reported >monthly drinking and 18% reported ≥monthly HED. Over an average of 5.4 years, frail PWH had greater probabilities of quitting (HR:1.56, 95%CI:1.13–2.15) and reducing (HR:1.35, 95%CI:1.13–1.62) drinking frequency, as well as reducing HED frequency (HR:1.58, 95%CI:1.20–2.09) vs. robust PWH. Sick quitting likely confounds the association between alcohol use and frailty risk, requiring investigation for control.\n\nView details for DOI 10.1097/JNC.0000000000000445\n\nView details for PubMedID 38150573\n\nView details for PubMedCentralID PMC10753926\n\nAbstract\n\nFew studies have evaluated environmental factors that predict survival to old age. Our study included 913 African American participants in the Jackson Heart Study (JHS) who resided in the tri-county area of the Jackson, MS metropolitan area and were 65-80 years at baseline. Participants were followed from 2000 through 2019 for the outcome of survival to 85 years old. We evaluated each of the following census tract-level measures of the social/physical environment as exposures: socioeconomic status, cohesion, violence, disorder, healthy food stores, residential land use, and walkability. We assessed mediation by physical activity and chronic conditions. As a complementary ecologic analysis, we used census-tract data to examine factors associated with a greater life expectancy. A total of 501 (55%) JHS participants survived to age 85 years or older. Higher social cohesion and greater residential land use were modestly associated with survival to old age (risk difference = 25%, 95% CI: 0-49%; and 4%, 95% CI: 1-7%, respectively). These neighborhood effects were modestly mediated through leisure time physical activity; additionally, social cohesion was mediated through home and yard activity. In our ecologic analysis, a greater percentage of homeowners and a greater proportion of people living in partnered families were associated with higher census-tract level life expectancy. African American older adults living in residential neighborhoods or neighborhoods with high social cohesion were more likely to survive to old age.\n\nView details for DOI 10.1016/j.pmedr.2023.102360\n\nView details for PubMedID 37588880\n\nView details for PubMedCentralID PMC10425932\n\nAbstract\n\nHypertension frequently accompanies chronic kidney disease (CKD) as etiology and sequela. We examined contemporary trends in hypertension treatment and control in a national sample of adults with CKD.We evaluated 5% cross-sectional samples of adults with CKD between 2011 and 2019 in the Veterans Health Administration. We defined CKD as a sustained estimated glomerular filtration rate value <60 mL/min per 1.73 m2 or a urine albumin-to-creatinine ratio ≥30 mg/g. The main outcomes were blood pressure (BP) control, defined as a systolic BP <140 mm Hg and a diastolic BP <90 mm Hg based on the mean of monthly BP measurements, and prescriptions for antihypertensive medications.The annual samples ranged between n=22 110 and n=33 039 individuals, with a mean age of 72 years, 96% of whom were male. Between 2011 and 2014, the age-adjusted proportion of adults with controlled BP declined from 78.0% to 72.2% (P value for linear trend, <0.001), reached a nadir of 71.0% in 2015, and then increased to 72.9% by 2019 (P value for linear trend, <0.001). Among adults with BP above goal, the age-adjusted proportion who did not receive antihypertensive treatment increased throughout the decade from 18.8% to 21.6%, and the age-adjusted proportion who received ≥3 antihypertensive medications decreased from 41.8% to 36.3%. Prescriptions for first-line antihypertensive agents also decreased.Among adults with CKD treated in the Veterans Health Administration, the proportion with controlled BP declined between 2011 and 2015 followed by a modest increase, coinciding with fewer prescriptions for antihypertensive medications.\n\nView details for DOI 10.1161/HYPERTENSIONAHA.123.21523\n\nView details for PubMedID 37706307\n\nAbstract\n\nProteomic approaches have unique advantages in the identification of biological pathways that influence physical frailty, a multifactorial geriatric syndrome predictive of adverse health outcomes in older adults. To date, proteomic studies of frailty are scarce, and few evaluated prefrailty as a separate state or examined predictors of incident frailty. Using plasma proteins measured by 4955 SOMAmers in the Atherosclerosis Risk in Community study, we identified 134 and 179 proteins cross-sectionally associated with prefrailty and frailty, respectively, after Bonferroni correction (p < 1 × 10-5 ) among 3838 older adults aged ≥65 years, adjusting for demographic and physiologic factors and chronic diseases. Among them, 23 (17%) and 82 (46%) were replicated in the Cardiovascular Health Study using the same models (FDR p < 0.05). Notably, higher odds of prefrailty and frailty were observed with higher levels of growth differentiation factor 15 (GDF15; pprefrailty = 1 × 10-15 , pfrailty = 2 × 10-19 ), transgelin (TAGLN; pprefrailty = 2 × 10-12 , pfrailty = 6 × 10-22 ), and insulin-like growth factor-binding protein 2 (IGFBP2; pprefrailty = 5 × 10-15 , pfrailty = 1 × 10-15 ) and with a lower level of growth hormone receptor (GHR, pprefrailty = 3 × 10-16 , pfrailty = 2 × 10-18 ). Longitudinally, we identified 4 proteins associated with incident frailty (p < 1 × 10-5 ). Higher levels of triggering receptor expressed on myeloid cells 1 (TREM1), TAGLN, and heart and adipocyte fatty-acid binding proteins predicted incident frailty. Differentially regulated proteins were enriched in pathways and upstream regulators related to lipid metabolism, angiogenesis, inflammation, and cell senescence. Our findings provide a set of plasma proteins and biological mechanisms that were dysregulated in both the prodromal and the clinical stage of frailty, offering new insights into frailty etiology and targets for intervention.\n\nView details for DOI 10.1111/acel.13975\n\nView details for PubMedID 37697678\n\nAbstract\n\nThe local environment remains an understudied contributor to elevated blood pressure among older adults. Untargeted approaches can identify neighborhood conditions interrelated with racial segregation that drive hypertension disparities.To evaluate independent associations of sociodemographic, economic, and housing neighborhood factors with elevated blood pressure.In this cohort study, the sample included Health and Retirement Study participants who had between 1 and 3 sets of biennial sphygmomanometer readings from 2006 to 2014 or 2008 to 2016. Statistical analyses were conducted from February 5 to November 30, 2021.Fifty-one standardized American Community Survey census tract variables (2005-2009).Elevated sphygmomanometer readings over the study period (6-year period prevalence): a value of at least 140 mm Hg for systolic blood pressure and/or at least 90 mm Hg for diastolic blood pressure. Participants were divided 50:50 into training and test data sets. Generalized estimating equations were used to summarize multivariable associations between each neighborhood variable and the period prevalence of elevated blood pressure, adjusting for individual-level covariates. Any neighborhood factor associated (Simes-adjusted for multiple comparisons P ≤ .05) with elevated blood pressure in the training data set was rerun in the test data set to gauge model performance. Lastly, in the full cohort, race- and ethnicity-stratified associations were evaluated for each identified neighborhood factor on the likelihood of elevated blood pressure.Of 12 946 participants, 4565 (35%) had elevated sphygmomanometer readings (median [IQR] age, 68 [63-73] years; 2283 [50%] male; 228 [5%] Hispanic or Latino, 502 [11%] non-Hispanic Black, and 3761 [82%] non-Hispanic White). Between 2006 and 2016, a lower likelihood of elevated blood pressure was observed (relative risk for highest vs lowest tertile, 0.91; 95% CI, 0.86-0.96) among participants residing in a neighborhood with recent (post-1999) in-migration of homeowners. This association was precise among participants with non-Hispanic White and other race and ethnicity (relative risk, 0.91; 95% CI, 0.85-0.97) but not non-Hispanic Black participants (relative risk, 0.97; 95% CI, 0.85-1.11; P = .48 for interaction) or Hispanic or Latino participants (relative risk, 0.84; 95% CI, 0.65-1.09; P = .78 for interaction).In this cohort study of older adults, recent relocation of homeowners to a neighborhood was robustly associated with reduced likelihood of elevated blood pressure among White participants but not their racially and ethnically marginalized counterparts. Our findings indicate that gentrification may influence later-life blood pressure control.\n\nView details for DOI 10.1001/jamanetworkopen.2023.35534\n\nView details for PubMedID 37747730\n\nAbstract\n\nTobacco smoking increases frailty risk among the general population and is common among people with HIV (PWH), who experience higher rates of frailty at earlier ages than the general population.We identified 8,608 PWH across 6 Centers for AIDS Research Network of Integrated Clinical Systems (CNICS) sites who completed ≥2 patient-reported outcome assessments, including a frailty phenotype measuring unintentional weight loss, poor mobility, fatigue, and inactivity, scored 0-4. Smoking was measured as baseline pack-years and time-updated never, former, or current use with cigarettes/day. We used Cox models to associate smoking with risk of incident frailty (score ≥3) and deterioration (frailty score increase by ≥2 points), adjusted for demographics, antiretroviral medication, and time-updated CD4 count.Mean follow-up of PWH was 5.3 years (median: 5.0), the mean age at baseline was 45 years, 15% were female, and 52% were non-White. At baseline, 60% reported current or former smoking. Current (HR: 1.79; 95%CI: 1.54-2.08) and former (HR: 1.31; 95%CI: 1.12-1.53) smoking were associated with higher incident frailty risk, as was higher pack-years. Current smoking (among younger PWH) and pack-years, but not former smoking, were associated with higher risk of deterioration.Among PWH, smoking status and duration are associated with incident and worsening frailty.\n\nView details for DOI 10.1097/QAI.0000000000003242\n\nView details for PubMedID 37368939\n\nAbstract\n\nRandomized clinical trials of hypertension treatment intensity evaluate effects on incident major adverse cardiovascular events (MACE) and serious adverse events (SAE). Occurrences after a non-fatal index event have not been rigorously evaluated. The current aim was to evaluate the association of intensive (<120 mmHg) to standard (<140 mmHg) blood pressure treatment to mortality mediated through a non-fatal MACE or non-fatal SAE in 9,361 Systolic Blood Pressure Intervention trial participants.Logistic regression and causal mediation modeling to obtain direct and mediated effects of intensive BP treatment. Primary outcome was all-cause mortality (ACM). Secondary outcomes were cardiovascular (CVM) and non-CV mortality (non-CVM).The direct effect of intensive treatment was a lowering of ACM [OR 0.75, 0.60-0.94]. The MACE-mediated effect substantially attenuated [OR 0.96, 0.92-0.99] ACM; while the SAE-mediated effect was associated with increased [OR 1.03, 1.01-1.05] ACM. Similar patterns were noted for intensive BP treatment on CVM and non-CVM. We also noted the SAE incidence was 3.9-fold higher than MACE incidence (13.7% vs 3.5%), and there was a total of 365 (3.9%) ACM with non-CVM 2.6-fold higher than CVM [2.81% (263/9,361) vs 1.09% (102/9,361)]. The SAE to MACE and non-CVM to CVM preponderance was across all age-groups with the ≥ 80-year age group having the highest differences.The current analytic techniques demonstrated that intensive BP treatment was associated with an attenuated mortality benefit when MACE-mediated and possibly harmful when SAE-mediated. Current cardiovascular trial reporting of treatment effects does not allow expansion of the lens to focus on important occurrences after the index event.\n\nView details for DOI 10.1093/eurjpc/zwad132\n\nView details for PubMedID 37185634\n\nAbstract\n\nRegression discontinuity design (RDD) is a quasi-experimental method intended for causal inference in observational settings. While RDD is gaining popularity in clinical studies, there are limited real-world studies examining the performance on estimating known trial casual effects. The goal of this paper is to estimate the effect of statins on myocardial infarction (MI) using RDD and compare with propensity score matching and Cox regression. For the RDD, we leveraged a 2008 UK guideline that recommends statins if a patient's 10-year cardiovascular disease (CVD) risk score>20%. We used UK electronic health record data from the Health Improvement Network on 49,242 patients aged 65+in 2008-2011 (baseline) without a history of CVD and no statin use in the two years prior to the CVD risk score assessment. Both the regression discontinuity (n=19,432) and the propensity score matched populations (n=24,814) demonstrated good balance of confounders. Using RDD, the adjusted point estimate for statins on MI was in the protective direction and similar to the statin effect observed in clinical trials, although the confidence interval included the null (HR=0.8, 95% CI 0.4, 1.4). Conversely, the adjusted estimates using propensity score matching and Cox regression remained in the harmful direction: HR=2.42 (95% CI 1.96, 2.99) and 2.51 (2.12, 2.97). RDD appeared superior to other methods in replicating the known protective effect of statins with MI, although precision was poor. Our findings suggest that, when used appropriately, RDD can expand the scope of clinical investigations aimed at causal inference by leveraging treatment rules from everyday clinical practice.\n\nView details for DOI 10.1007/s10654-023-00982-w\n\nView details for PubMedID 36935439\n\nAbstract\n\nOptimal systolic BP (SBP) control in nursing home residents is uncertain, largely because this population has been excluded from clinical trials. We examined the association of SBP levels with the risk of cardiovascular (CV) events and mortality in Veterans Affairs (VA) nursing home residents on different numbers of antihypertensive medications.Our study included 36,634 residents aged ≥65 years with a VA nursing home stay of ≥90 days from October 2006-June 2019. SBP was averaged over the first week after admission and divided into categories. Cause-specific hazard ratios (HRs) of SBP categories with CV events (primary outcome) and all-cause mortality (secondary outcome) were examined using Cox regression and multistate modeling stratified by the number of antihypertensive medications used at admission (0, 1 or 2, and ≥3 medications).More than 76% of residents were on antihypertensive therapy and 20% received ≥3 medications. In residents on antihypertensive therapy, a low SBP < 110 mmHg (compared with SBP 130 ~ 149 mmHg) was associated with a greater CV risk (adjusted HR [95% confidence interval]: 1.47 [1.28-1.68] in 1 or 2 medications group, and 1.41 [1.19-1.67] in ≥3 medications group). In residents on no antihypertensives, both low SBP < 110 mmHg and high SBP ≥ 150 mmHg were associated with higher mortality; while in residents receiving any antihypertensives, a low SBP was associated with higher mortality and the highest point estimates were for SBP < 110 mmHg (1.36 [1.28-1.45] in 1 or 2 medications group, and 1.47 [1.31-1.64] in ≥3 medications group).The associations of SBP with CV and mortality risk varied by the intensity of antihypertensive treatment among VA nursing home residents. A low SBP among those receiving antihypertensives was associated with increased CV and mortality risk, and untreated high SBP was associated with higher mortality. More research is needed on the benefits and harms of SBP lowering in long-term care populations.\n\nView details for DOI 10.1111/jgs.18301\n\nView details for PubMedID 36826917\n\nAbstract\n\n\"Heterogeneous treatment effects\" is a term which refers to conditional average treatment effects (i.e., CATEs) that vary across population subgroups. Epidemiologists are often interested in estimating such effects because they can help detect populations who may particularly benefit from or be harmed by a treatment. However, standard regression approaches for estimating heterogeneous effects are limited by pre-existing hypotheses, test a single effect modifier at a time, and are subject to the multiple comparisons problem. The objective of this text is to offer a practical guide to honest causal forests, an ensemble tree-based learning method which can discover as well as estimate heterogeneous treatment effects using a data-driven approach. We discuss the fundamentals of tree-based methods, describe how honest causal forests can identify and estimate heterogeneous effects, and demonstrate an implementation of this method using simulated data. Our implementation highlights the steps required to simulate datasets, build honest causal forests, and assess model performance across a variety of simulation scenarios. Overall, this paper is intended for epidemiologists and other population health researchers who lack an extensive background in machine learning yet are interested in utilizing an emerging method for identifying and estimating heterogeneous treatment effects.\n\nView details for DOI 10.1093/aje/kwad043\n\nView details for PubMedID 36843042\n\nAbstract\n\nABSTRACT: Modifications to Fried's frailty phenotype (FFP) are common. We evaluated a self-reported modified frailty phenotype (Mod-FP) used among people with HIV (PWH). Among 522 PWH engaged in two longitudinal studies, we assessed validity of the four-item Mod-FP compared with the five-item FFP. We compared the phenotypes via receiver operator characteristic curves, agreement in classifying frailty, and criterion validity via association with having experienced falls. Mod-FP classified 8% of PWH as frail, whereas FFP classified 9%. The area under the receiver operator characteristic curve for Mod-FP classifying frailty was 0.93 (95% CI = 0.91-0.96). We observed kappa ranging from 0.64 (unweighted) to 0.75 (weighted) for categorizing frailty status. Both definitions found frailty associated with a greater odds of experiencing a fall; FFP estimated a slightly greater magnitude (i.e., OR) for the association than Mod-FP. The Mod-FP has good performance in measuring frailty among PWH and is reasonable to use when the gold standards of observed assessments (i.e., weakness and slowness) are not feasible.\n\nView details for DOI 10.1097/JNC.0000000000000389\n\nView details for PubMedID 36652200\n\nAbstract\n\nExposure of biological systems to acute or chronic insults triggers a host of molecular and physiological responses to either tolerate, adapt, or fully restore homeostasis; these responses constitute the hallmarks of resilience. Given the many facets, dimensions, and discipline-specific focus, gaining a shared understanding of \"resilience\" has been identified as a priority for supporting advances in cardiovascular health. This report is based on the working definition: \"Resilience is the ability of living systems to successfully maintain or return to homeostasis in response to physical, molecular, individual, social, societal, or environmental stressors or challenges,\" developed after considering many factors contributing to cardiovascular resilience through deliberations of multidisciplinary experts convened by the National Heart, Lung, and Blood Institute during a workshop entitled: \"Enhancing Resilience for Cardiovascular Health and Wellness.\" Some of the main emerging themes that support the possibility of enhancing resilience for cardiovascular health include optimal energy management and substrate diversity, a robust immune system that safeguards tissue homeostasis, and social and community support. The report also highlights existing research challenges, along with immediate and long-term opportunities for resilience research. Certain immediate opportunities identified are based on leveraging existing high-dimensional data from longitudinal clinical studies to identify vascular resilience measures, create a 'resilience index,' and adopt a life-course approach. Long-term opportunities include developing quantitative cell/organ/system/community models to identify resilience factors and mechanisms at these various levels, designing experimental and clinical interventions that specifically assess resilience, adopting global sharing of resilience-related data, and cross-domain training of next-generation researchers in this field.\n\nView details for DOI 10.1096/fj.202201407R\n\nView details for PubMedID 36322029\n\nAbstract\n\nOBJECTIVE: To identify which Veteran populations are routinely accessing video-based care.DATA SOURCES AND STUDY SETTING: National, secondary administrative data from electronic health records at the Veterans Health Administration (VHA), 2019-2021 STUDY DESIGN: This retrospective cohort analysis identified patient characteristics associated with the odds of using any video care; and then, among those with a previous video visit, the annual rate of video care utilization. Video care use was reported overall and stratified into care type (e.g., primary, mental health, and specialty video care) between March 10, 2020 and February 28, 2021.DATA COLLECTION: Veterans active in VA health care (>1 outpatient visit between March 11, 2019 and March 10, 2020) were included in this study.PRINCIPAL FINDINGS: Among 5,389,129 Veterans in this evaluation, approximately 27.4% of Veterans had at least one video visit. We found differences in video care utilization by type of video care: 14.7% of Veterans had at least one primary care video visit, 10.6% a mental health video visit, and 5.9% a specialty care video visit. Veterans with a history of housing instability had a higher overall rate of video care driven by their higher usage of video for mental health care compared with Veterans in stable housing. American Indian/Alaska Native Veterans had reduced odds of video visits, yet similar rates of video care when compared to White Veterans. Low-income Veterans had lower odds of using primary video care yet slightly elevated rates of primary video care among those with at least one video visit when compared to Veterans enrolled at VA without special considerations.CONCLUSIONS: Variation in video care utilization patterns by type of care identified Veteran populations that might require greater resources and support to initiate and sustain video care use. Our data support service specific outreach to homeless and American Indian/Alaska Native Veterans.\n\nView details for DOI 10.1111/1475-6773.14098\n\nView details for PubMedID 36345235\n\nAbstract\n\nThe biological mechanisms underlying decline in physical function with age remain unclear. We examined the plasma proteomic profile associated with longitudinal changes in physical function measured by gait speed and grip strength in community-dwelling adults. We applied an aptamer-based platform to assay 1154 plasma proteins on 2854 participants (60% women, aged 76 years) in the Cardiovascular Health Study (CHS) in 1992-1993 and 1130 participants (55% women, aged 54 years) in the Framingham Offspring Study (FOS) in 1991-1995. Gait speed and grip strength were measured annually for 7 years in CHS and at cycles 7 (1998-2001) and 8 (2005-2008) in FOS. The associations of individual protein levels (log-transformed and standardized) with longitudinal changes in gait speed and grip strength in two populations were examined separately by linear mixed-effects models. Meta-analyses were implemented using random-effects models and corrected for multiple testing. We found that plasma levels of 14 and 18 proteins were associated with changes in gait speed and grip strength, respectively (corrected p < 0.05). The proteins most strongly associated with gait speed decline were GDF-15 (Meta-analytic p = 1.58 × 10-15 ), pleiotrophin (1.23 × 10-9 ), and TIMP-1 (5.97 × 10-8 ). For grip strength decline, the strongest associations were for carbonic anhydrase III (1.09 × 10-7 ), CDON (2.38 × 10-7 ), and SMOC1 (7.47 × 10-7 ). Several statistically significant proteins are involved in the inflammatory responses or antagonism of activin by follistatin pathway. These novel proteomic biomarkers and pathways should be further explored as future mechanisms and targets for age-related functional decline.\n\nView details for DOI 10.1111/acel.13736\n\nView details for PubMedID 36333824\n\nAbstract\n\nMore intensive BP goals have been recommended for patients with CKD. We estimated the prevalence of apparent treatment-resistant hypertension among patients with CKD according to the 2017 American College of Cardiology/American Heart Association (ACC/AHA; BP goal <130/80 mm Hg) and 2021 Kidney Disease Improving Global Outcomes (KDIGO; systolic BP <120 mm Hg) guidelines in two US health care systems.We included adults with CKD (an eGFR <60 ml/min per 1.73 m2) and treated hypertension from Kaiser Permanente Southern California and the Veterans Health Administration. Using electronic health records, we identified apparent treatment-resistant hypertension on the basis of (1) BP above the goal while prescribed three or more classes of antihypertensive medications or (2) prescribed four or more classes of antihypertensive medications regardless of BP. In a sensitivity analysis, we required diuretic use to be classified as apparent treatment-resistant hypertension. We estimated the prevalence of apparent treatment-resistant hypertension per clinical guideline and by CKD stage.Among 44,543 Kaiser Permanente Southern California and 241,465 Veterans Health Administration patients with CKD and treated hypertension, the prevalence rates of apparent treatment-resistant hypertension were 39% (Kaiser Permanente Southern California) and 35% (Veterans Health Administration) per the 2017 ACC/AHA guideline and 48% (Kaiser Permanente Southern California) and 55% (Veterans Health Administration) per the 2021 KDIGO guideline. By requiring a diuretic as a criterion for apparent treatment-resistant hypertension, the prevalence rates of apparent treatment-resistant hypertension were lowered to 31% (Kaiser Permanente Southern California) and 23% (Veterans Health Administration) per the 2017 ACC/AHA guideline. The prevalence rates of apparent treatment-resistant hypertension were progressively higher at more advanced stages of CKD (34%/33%, 42%/36%, 52%/41%, and 60%/37% for Kaiser Permanente Southern California/Veterans Health Administration eGFR 45-59, 30-44, 15-29, and <15 ml/min per 1.73 m2, respectively) per the 2017 ACC/AHA guideline.Depending on the CKD stage, up to a half of patients with CKD met apparent treatment-resistant hypertension criteria.\n\nView details for DOI 10.2215/CJN.04110422\n\nView details for PubMedID 36400564\n\nAbstract\n\nBACKGROUND: Communication of the benefits and harms of blood pressure lowering strategy is crucial for shared decision-making.OBJECTIVES: To quantify the effect of intensive versus standard systolic blood pressure lowering in terms of the number of event-free days DESIGN: Post hoc analysis of the Systolic Blood Pressure Intervention Trial PARTICIPANTS: A total of 9361 adults 50 years or older without diabetes or stroke who had a systolic blood pressure of 130-180 mmHg and elevated cardiovascular risk INTERVENTIONS: Intensive (systolic blood pressure goal <120 mmHg) versus standard blood pressure lowering (<140 mmHg) MAIN MEASURES: Days free of major adverse cardiovascular events (MACE), serious adverse events (SAE), and monitored adverse events (hypotension, syncope, bradycardia, electrolyte abnormalities, injurious falls, or acute kidney injury) over a median follow-up of 3.33 years KEY RESULTS: The intensive treatment group gained 14.7 more MACE-free days over 4 years (difference, 14.7 [95% confidence interval: 5.1, 24.4] days) than the standard treatment group. The benefit of the intensive treatment varied by cognitive function (normal: difference, 40.7 [13.0, 68.4] days; moderate-to-severe impairment: difference, -15.0 [-56.5, 26.4] days; p-for-interaction=0.009) and self-rated health (excellent: difference, -22.7 [-51.5, 6.1] days; poor: difference, 156.1 [31.1, 281.2] days; p-for-interaction=0.001). The mean overall SAE-free days were not significantly different between the treatments (difference, -14.8 [-35.3, 5.7] days). However, the intensive treatment group had 28.5 fewer monitored adverse event-free days than the standard treatment group (difference, -28.5 [-40.3, -16.7] days), with significant variations by frailty status (non-frail: difference, 38.8 [8.4, 69.2] days; frail: difference, -15.5 [-46.6, 15.7] days) and self-rated health (excellent: difference, -12.9 [-45.5, 19.7] days; poor: difference, 180.6 [72.9, 288.4] days; p-for-interaction <0.001).CONCLUSIONS: Over 4 years, intensive systolic blood pressure lowering provides, on average, 14.7 more MACE-free days than standard treatment, without any difference in SAE-free days. Whether this time-based effect summary improves shared decision-making remains to be elucidated.TRIAL REGISTRATION: ClinicalTrials.gov Registration: NCT01206062.\n\nView details for DOI 10.1007/s11606-022-07753-5\n\nView details for PubMedID 35945470\n\nAbstract\n\nBACKGROUND: research on the association between hearing impairment and psychosocial outcomes is not only limited but also yielded mixed results.METHODS: we investigated associations between annual self-reports of hearing problems, depressive symptoms and social network strength among 5,888 adults from the Cardiovascular Health Study over a period of 9 years. Social network strength and depressive symptoms were defined using the Lubben Social Network Scale (LSNS), and the Center for Epidemiological Studies Depression Scale (CES-D).RESULTS: hearing problems were associated with weaker social networks and more depressive symptoms. These association differed for prevalent versus incident hearing problems. Participants with prevalent hearing problems scored an adjusted 0.47 points lower (95% CI: -2.20, -0.71) on the LSNS and 0.71 points higher (95% CI: 0.23, 1.19) on the CES-D than those without hearing problems. Participants with incident hearing problems had a greater decline of 0.12 points (95% CI: -0.12, -0.03) per year in social network score than individuals with no hearing problems after adjusting for confounders. Females appeared to be more vulnerable to changes in social network strength than males (P-value for interaction=0.02), but not for changes in depressive score. Accounting for social network score did not appear to attenuate the association between hearing problems and depressive score.CONCLUSION: findings suggest that older adults with prevalent hearing problems may be more at risk for depression, but individuals with incident hearing problems may be at greater risk for a winnowing of their social network.\n\nView details for DOI 10.1093/ageing/afac181\n\nView details for PubMedID 35977151\n\nAbstract\n\nBACKGROUND: In the last decade, genomic studies have identified and replicated thousands of genetic associations with measures of health and disease and contributed to the understanding of the etiology of a variety of health conditions. Proteins are key biomarkers in clinical medicine and often drug-therapy targets. Like genomics, proteomics can advance our understanding of biology.METHODS AND RESULTS: In the setting of the Cardiovascular Health Study (CHS), a cohort study of older adults, an aptamer-based method that has high sensitivity for low-abundance proteins was used to assay 4979 proteins in frozen, stored plasma from 3188 participants (61% women, mean age 74years). CHS provides active support, including central analysis, for seven phenotype-specific working groups (WGs). Each CHS WG is led by one or two senior investigators and includes 10 to 20 early or mid-career scientists. In this setting of mentored access, the proteomic data and analytic methods are widely shared with the WGs and investigators so that they may evaluate associations between baseline levels of circulating proteins and the incidence of a variety of health outcomes in prospective cohort analyses. We describe the design of CHS, the CHS Proteomics Study, characteristics of participants, quality control measures, and structural characteristics of the data provided to CHS WGs. We additionally highlight plans for validation and replication of novel proteomic associations.CONCLUSION: The CHS Proteomics Study offers an opportunity for collaborative data sharing to improve our understanding of the etiology of a variety of health conditions in older adults.\n\nView details for DOI 10.1007/s10654-022-00888-z\n\nView details for PubMedID 35790642\n\nAbstract\n\nOBJECTIVE: Behavioral risk factors for dementia tend to co-occur and inter-relate, especially poor diet, physical inactivity, sleep disturbances, and depression. Having multiple of these modifiable behavioral risk factors (MBRFs) may predict a particularly shortened cognitive healthspan, and therefore, may signal high-risk status/high intervention need.METHODS: This secondary analyses of data from the Cardiovascular Health Study included 3149 participants aged 65-74 years (mean age = 69.5, standard deviation (SD) = 2.5; 59.6% female). MBRF exposures were self-reports regarding: (1) diet, (2) activity, (3) sleep, and (4) depression symptoms. We primarily analyzed MBRF counts. Over up to 26 years of follow-up, we assessed the: (1) number of remaining cognitively healthy life years (CHLYs); and (2) percentage of remaining life years (LYs) that were CHLYs (%CHLY). We estimated CHLYs as time before a dementia diagnosis, cognitive screener scores indicating impairment, proxy port indicating significant cognitive decline, or dementia medication use.RESULTS: Participants averaged a remaining 16 LYs (SD = 7), 12.2 CHLYs (SD = 6.6), and 78.1% of LYs being CHLYs (SD = 25.6). Compared with having no MBRFs, having one was associated with ~1 less LY and CHLY, but not a relatively lower %CHLY. In contrast, having 3+ MBRFs was associated with about 2-3 fewer LYs and CHLYs as well as about 6% lower %CHLY (95% confidence interval: -9.0, -2.5 %CHLYs), p = 0.001).CONCLUSIONS: MBRF-related reductions in the cognitive healthspan are most apparent when people have multiple MBRFs. Future research is needed to determine if/how behavioral risks converge mechanistically, and if dementia prevention efficacy improves when targeting MBRF combinations.\n\nView details for DOI 10.1097/PSY.0000000000001100\n\nView details for PubMedID 35796682\n\nAbstract\n\nUntested psychosocial or economic factors mediate associations between perceived discrimination and suboptimal antihypertensive therapy. This study included two waves of data from the Health and Retirement Study participants with self-reported hypertension (N=8557, 73% Non-Hispanic White, 17% Non-Hispanic Black, and 10% Hispanic/Latino) over four years (2008-2014). Our primary exposures were frequency of experiencing discrimination in everyday life or across seven lifetime circumstances. Candidate mediators were self-reported depressive symptoms, subjective social standing, and household wealth. We evaluated with causal mediation methods the interactive and mediating associations between each discrimination measure and reported antihypertensive use at the subsequent wave. In unmediated analyses, everyday (OR; 95% CI: 0.86; 0.78, 0.95) as well as lifetime discrimination (OR; 95% CI: 0.91; 0.85, 0.98) were associated with a lower likelihood of antihypertensive use. Discrimination was associated with lower wealth, greater depressive symptoms, and decreased subjective social standing. Estimates for associations due to neither interaction nor mediation resembled unmediated associations for most discrimination-mediator combinations. Lifetime discrimination was indirectly associated with reduced antihypertensive use via depressive symptomology (OR; 95% CI: 0.99; 0.98, 1.00). In conclusion, the impact of lifetime discrimination on the underuse of antihypertensive therapy appears partially mediated by depressive symptoms.\n\nView details for DOI 10.1093/aje/kwac102\n\nView details for PubMedID 35689640\n\nAbstract\n\nBACKGROUND: Inadequate treatment of high blood pressure (BP) can lead to preventable adverse events in nursing home residents, while excessive treatment can lead to associated harms.METHODS: Data were extracted from the VA electronic health record and Bar Code Medication Administration system on 40,079 long-term care residents aged ≥65years from October 2006 through September 2018 (FY2007-2018). Hypertension prevalence at admission was identified by ICD code(s) in the year prior, and antihypertensive medication use was defined as administration ≥50% of days. BP measures were averaged over 2-year epochs.RESULTS: The age-standardized prevalence of hypertension diagnosis at admission increased from 75.2% in FY2007-2008 to 85.1% in FY2017-2018 (p-value for trend <0.001). Rates of BP treatment and control among residents with hypertension at admission declined slightly over time (p-values for trend <0.001) but remained high (80.3% treated in FY2017-2018, 80.1% with average BP <140/90mmHg). The age-adjusted prevalence of chronic low BP (average <90/60mmHg) also declined from 11.1% in FY2007-2008 to 4.7% in FY2017-2018 (p-value for trend <0.001). Persons identified as Black race or Hispanic ethnicity and those with a history of diabetes, stroke, and renal disease were less likely to have an average BP <140/90mmHg.CONCLUSIONS: Hypertension is well controlled in VA nursing homes, and recent trends of less intensive BP control were accompanied by a lower prevalence of chronic low BP. Nonetheless, some high-risk populations have average BP levels >140/90mmHg. Future research is needed to better understand the benefits and harms of BP control in nursing home residents.\n\nView details for DOI 10.1111/jgs.17821\n\nView details for PubMedID 35524763\n\nAbstract\n\nDespite their well-established benefits for the prevention of cardiovascular disease, robust evidence on the effects of statins on cognition is largely inconclusive. We apply various study designs and analytical approaches to mimic randomized controlled trial effects from observational data.We used observational data from 5 580 participants enrolled in the Cardiovascular Health Study from 1989/1990 to 1999/2000. We conceptualized the cohort as an overlapping sequence of nonrandomized trials. We compared multiple selection (eligible population, prevalent users, new users) and analytic approaches (multivariable adjustment, inverse-probability treatment weights, propensity score matching) to evaluate the association between statin use and 5-year change in global cognitive function, assessed using the Modified Mini-Mental State Examination (3MSE).When comparing prevalent users to nonusers (N = 2 772), statin use was associated with slower cognitive decline over 5 years (adjusted annual change in 3MSE = 0.34 points/year; 95% CI: 0.05-0.63). Compared to prevalent user design, estimates from new user designs (eg, comparing eligible statin initiators to noninitiators) were attenuated showing either null or negative association, though not significant. For example, in a propensity score-matched sample of statin-eligible individuals (N = 454), the annual 3MS change comparing statin initiators to noninitiators was -0.21 points/year (95% CI: -0.81 to 0.39).The association of statin use and cognitive decline is attenuated toward the null when using rigorous analytical approaches that more closely mimic randomized controlled trials. Point estimates, even within the same study, may vary depending on the analytical methods used. Further studies that leverage natural or quasi experiments around statin use are needed to replicate our findings.\n\nView details for DOI 10.1093/gerona/glab220\n\nView details for PubMedID 34331536\n\nView details for PubMedCentralID PMC9071443\n\nAbstract\n\nBACKGROUND: Geographic and contextual socioeconomic risk factors in adolescence may be more strongly associated with young adult hypertension than individual-level risk factors. This study examines the association between individual, neighborhood, and school-level influences during adolescence on young adult blood pressure.METHODS: Data were analyzed from the National Longitudinal Study of Adolescent to Adult Health (1994-1995 aged 11-18 and 2007-2008 aged 24-32). We categorized hypertension as systolic blood pressure ≥140 mm Hg and/or diastolic blood pressure ≥90 mm Hg. Secondary outcomes included continuous systolic and diastolic blood pressure. We fit a series of cross-classified multilevel models to estimate the associations between young adulthood hypertension with individual-level, school-level, and neighborhood-level factors during adolescence (i.e., fixed effects) and variance attributable to each level (i.e., random effects). Models were fit using Bayesian estimation procedures. For linear models, intra-class correlations (ICC) are reported for random effects.RESULTS: The final sample included 13,911 participants in 128 schools and 1,917 neighborhoods. Approximately 51% (7,111) young adults were hypertensive. Individual-level characteristics-particularly older ages, Non-Hispanic Black race, Asian race, male sex, BMI, and current smoking-were associated with increased hypertension. Non-Hispanic Black (OR = 1.21; 95% CI: 1.03-1.42) and Asian (OR = 1.28; 95% CI: 1.02-1.62) students had higher odds of hypertension compared to non-Hispanic White students. At the school level, hypertension was associated with the percentage of non-Hispanic White students (OR for 10% higher = 1.06; 95% CI: 1.01-1.09). Adjusting for individual, school, and neighborhood predictors attenuated the ICC for both the school (from 1.4 null to 0.9 fully-adjusted) and neighborhood (from 0.4 to 0.3).CONCLUSION: We find that adolescents' schools and individual-level factors influence young adult hypertension, more than neighborhoods. Unequal conditions in school environments for adolescents may increase the risk of hypertension later in life. Our findings merit further research to better understand the mechanisms through which adolescents' school environments contribute to adult hypertension and disparities in hypertension outcomes later in life.\n\nView details for DOI 10.1371/journal.pone.0266729\n\nView details for PubMedID 35482649\n\nAbstract\n\nRacial residential segregation is associated with multiple adverse health outcomes in Black individuals. Yet, the influence of structural racism and racial residential segregation on brain aging is less understood. In this study, we investigate the association between cumulative exposure to racial residential segregation over 25 years (1985-2010) of young adulthood, measured by the Getis-Ord Gi*-statistic, and year 25 measures of brain volume in midlife (cerebral, gray matter, white matter, and hippocampal volumes). We studied 290 Black participants with available brain imaging data who were enrolled in the Coronary Artery Risk Development in Young Adults (CARDIA) prospective cohort study. CARDIA originally recruited 2637 Black participants aged 18 to 30 years old from 4 field centers across the United States. We conducted analyses using marginal structural models, incorporating inverse probability weighting and inverse censoring weighting. We found that compared to low/medium segregation, greater cumulative exposure to residential segregation throughout young adulthood was associated with smaller brain volumes in general (e.g. β for cerebral volume: -0.08 [95% CI]: [-0.15, -0.02]) and with a more pronounced reduction in hippocampal volume, though results were not statistically significant. Our findings suggest that exposure to segregated neighborhoods may be associated with worse brain aging.\n\nView details for DOI 10.1093/aje/kwab297\n\nView details for PubMedID 35020781\n\nAbstract\n\nRecent evidence suggests potential clinical benefits of statin in cancer chemoprevention and treatment. Non-alcoholic fatty liver disease (NAFLD) is expected to become the leading cause of hepatocellular carcinoma (HCC). We aimed to investigate the association between statin initiation and the risk of HCC among patients with NAFLD.In this study using the Optum de-identified Clinformatics® database, cox proportional-hazards regression model was performed to determine the risk of HCC in statin initiators versus nonusers. We incorporated inverse probability of treatment weighting (IPTW) to minimize potential confounding.Among 272,431 adults with NAFLD diagnosis, IPTW model shows that statin initiators had a 53% less risk of developing HCC compared to nonusers (HR: 0.47, 95% confidence interval: 0.36-0.60). In the sub-cohort with FIB-4 data available, statin initiation was associated with a 56% hazard reduction of developing HCC in NAFLD after adjusting for FIB-4 score (HR: 0.44; 0.30-0.65). The association between statin initiation and lower risk of HCC development was observed for both lipophilic statin (HR: 0.49; 0.37-0.65) and hydrophilic statin (HR: 0.40; 0.21-0.76). Moreover, we observed a greater hazards reduction as the dose and duration of statin use increased. NAFLD patients with more than 600 cDDDs of statin had a 70% reduction in hazards of developing HCC (HR: 0.30; 0.20-0.43).Our study provides strong evidence for the association between statin initiation and reduced risk of HCC development in NAFLD patients. These findings imply that statin can be used as a protective medication for NAFLD patients to reduce the risk of HCC.\n\nView details for DOI 10.1016/j.cgh.2022.01.057\n\nView details for PubMedID 35158055\n\nAbstract\n\nCertain classes of antihypertensive medication may have different associations with cognitive impairment.To examine the association between prevalent use of antihypertensive medications that stimulate (thiazides, dihydropyridine calcium channel blockers, angiotensin type I receptor blockers) versus inhibit (angiotensin-converting enzyme inhibitors, beta-blockers, non-dihydropyridine calcium channel blockers) type 2 and 4 angiotensin II receptors on cognitive impairment among older adults residing in Veterans Affairs (VA) nursing homes for long-term care.Retrospective cohort study. Long-term care residents aged 65 + years admitted to a VA nursing home from 2012 to 2019 using blood pressure medication and without cognitive impairment at admission. Main exposure was prevalent use of angiotensin II receptor type 2 and 4-'stimulating' (N = 589), 'inhibiting' (N = 3,219), or 'mixed' (N = 1,715) antihypertensive medication regimens at admission. Primary outcome was any cognitive impairment (Cognitive Function Scale).Over an average of 5.4 months of follow-up, prevalent use of regimens containing exclusively 'stimulating' antihypertensives was associated with a lower risk of any incident cognitive impairment as compared to prevalent use of regimens containing exclusively 'inhibiting' antihypertensives (HR 0.83, 95% CI 0.74-0.93). Results for the comparison between 'mixed' versus 'inhibiting' regimens were in the same direction but not statistically significant (HR 0.96, 95% CI 0.88-1.06).For residents without cognitive impairment at baseline, prevalent users of regimens containing exclusively antihypertensives that stimulate type 2 and 4 angiotensin II receptors had lower rates of cognitive impairment as compared to prevalent users of regimens containing exclusively antihypertensives that inhibit these receptors. Residual confounding cannot be ruled out.\n\nView details for DOI 10.3233/JAD-215393\n\nView details for PubMedID 35147539\n\nAbstract\n\nBACKGROUND: Aging is accompanied by an overall dysregulation of many dynamic physiologic processes including those related to blood pressure (BP). While year-to-year BP variability is associated with cardiovascular events and mortality, no studies have examined this trend with more frequent BP assessments. Our study objective is to take the next step to examine week-to-week BP dynamics - pattern, variability, and complexity - before death.METHODS: Using a retrospective study design, we assessed BP dynamics in the 6 months before death in long-term nursing home residents between 10/1/2006 and 9/30/2017. Variability was characterized using standard deviation and mean square error after adjusting for diurnal variations. Complexity (i.e., amount of novel information in a trend) was examined using Shannon's entropy (bits). Generalized linear models were used to examine factors associated with overall BP variability.RESULTS: We identified 17,953 nursing home residents (98.0% male, 82.5% White, mean age 80.2 years, and mean BP 125.7/68.6 mmHg). Despite a slight trend of decreasing systolic week-to-week BP over time (delta=7.2mmHg), week-to-week complexity did not change in the six months before death (delta=0.02 bits). Average weekly BP variability was stable until the last 3-4 weeks of life, at which point variability increased by 30% for both systolic and diastolic BP. Factors associated with BP variability include average weekly systolic/diastolic BP, days in the nursing home, days in the hospital, and changes to antihypertensive medications.CONCLUSIONS: Week-to-week BP variability increases substantially in the last month of life, but complexity does not change. Changes in care patterns may drive the increase in BP variability as one approaches death.\n\nView details for DOI 10.1093/ajh/hpab142\n\nView details for PubMedID 34505872\n\nAbstract\n\nBACKGROUND: the interrelatedness between social determinants of health impedes researchers to identify important social factors for health investment. A new approach is needed to quantify the aggregate effect of social factors and develop person- centred social interventions.METHODS: participants ([n=7,383], 54.5% female) were aged 65years or above who complete an additional psychosocial questionnaire in the health and retirement study in 2006 or 2008. Social determinants of health encompassed five social domains: economic stability, neighbourhood and physical environment, education, community and social context, and healthcare system. We used the forward stepwise logistic regression to derive a polysocial score model for 5-year mortality. Indices of goodness-of-fit, discrimination and reclassification were used to assess model performance. We used logistic regression to identify the association between polysocial score and mortality. Subgroup analyses were conducted to examine sex- and race-specific association.RESULTS: polysocial score was created using 14 social determinants of health. In the training cohort, the C-statistic was 0.71 for the reference model (only age, sex and race/ethnicity) and increased to 0.75 for the continuous and categorical polysocial score. Compared with the reference model, the integrated discrimination index for adding the continuous or categorical polysocial score was both 0.03 (P values < 0.001). Participants with an intermediate (odds ratio [OR]=0.69; 95% confidence interval [CI], 0.51-0.82) or high (OR=0.48; 95% CI, 0.38-0.60) polysocial score had lower odds of death than those in the low category in the fully adjusted model, respectively.CONCLUSIONS: the polysocial approach may offer possible solutions to monitor social environments and suggestions for older people to improve their social status for specific health outcomes.\n\nView details for DOI 10.1093/ageing/afab174\n\nView details for PubMedID 34473824\n\nAbstract\n\nBACKGROUND: Associations between multiple forms of discrimination and blood pressure control in older populations remain unestablished.METHODS: Participants were 14582 non-institutionalized individuals (59% women) in the Health and Retirement Study aged at least 51 years (76% Non-Hispanic White, 15% Non-Hispanic Black, 9% Hispanic/Latino). Primary exposures included the mean frequency of discrimination in everyday life, intersectional discrimination (defined as marginalization ascribed to more than one reason), and the sum of discrimination over the lifespan. We assessed whether discrimination was associated with change in measured hypertension status (N=14582) and concurrent medication use among reported hypertensives (N=9086) over four years (2008-2014).RESULTS: There was no association between the frequency of everyday discrimination and change in measured hypertension. Lifetime discrimination was associated with higher odds of hypertension four years later among men (OR: 1.21, 95% CI: 1.08, 1.36) but not women (OR: 0.98, 95% CI: 0.86, 1.13). Only among men, everyday discrimination due at least two reasons was associated with a 1.44 (95% CI: 1.03, 2.01)-fold odds of hypertension than reporting no everyday discrimination; reporting intersectional discrimination was not associated with developing hypertension among women (OR: 0.91, 95% CI: 0.70, 1.20). All three discriminatory measures were inversely related to time-averaged antihypertensive medication use, without apparent gender differences (e.g., OR for everyday discrimination-antihypertensive use associations: 0.85, 95% CI: 0.77, 0.94)).CONCLUSIONS: Gender differences in marginalization may more acutely elevate hypertensive risk among older men than similarly aged women. Experiences of discrimination appear to decrease the likelihood of antihypertensive medication use among older adults overall.\n\nView details for DOI 10.1093/gerona/glab234\n\nView details for PubMedID 34390331\n\nAbstract\n\nOBJECTIVES: To evaluate the incidence of deprescribing of antihypertensive medication among older adults residing in Veterans Affairs (VA) nursing homes for long-term care and rates of deprescribing after potentially triggering events.DESIGN: Retrospective cohort study.SETTING AND PARTICIPANTS: Long-term care residents aged 65years and older admitted to a VA nursing home from 2006 to 2019 and using blood pressure medication at admission.METHODS: Data were extracted from the VA electronic health record, and Centers for Medicare & Medicaid Services Minimum Data Set and Bar Code Medication Administration. Deprescribing was defined on a rolling basis as a reduction in the number or dose of antihypertensive medications, sustained for ≥2weeks. We examined potentially triggering events for deprescribing, including low blood pressure (<90/60mmHg), acute renal impairment (creatinine increase of 50%), electrolyte imbalance (potassium below 3.5 mEq/L, sodium decrease by 5 mEq/L), and falls.RESULTS: Among 31,499 VA nursing home residents on antihypertensive medication, 70.4% had ≥1 deprescribing event (median length of stay= 6months), and 48.7% had a net reduction in antihypertensive medications over their stay. Deprescribing events were most common in the first 4weeks after admission and the last 4weeks of life. Among potentially triggering events, a 50% increase in serum creatinine was associated with the greatest increase in the likelihood of deprescribing over the subsequent 4weeks: residents with this event had a 41.7% chance of being deprescribed compared with 11.5% in those who did not (risk difference= 30.3%, P < .001). A fall in the past 30days was associated with the smallest magnitude increased risk of deprescribing (risk difference= 3.8%, P < .001) of the events considered.CONCLUSIONS AND IMPLICATIONS: Deprescribing of antihypertensive medications is common among VA nursing home residents, especially after a potential renal adverse event.\n\nView details for DOI 10.1016/j.jamda.2021.07.009\n\nView details for PubMedID 34364847\n\nAbstract\n\nPURPOSE: The association between CVD risk factors and mortality is well established, however, current tools for addressing subgroups have focused on the overall burden of disease. The identification of risky combinations of characteristics may lead to a better understanding of physiologic pathways that underlie morbidity and mortality in older adults.METHODS: Participants included 5,067 older adults from the Cardiovascular Health Study, followed for up to 6 years. Using latent class analysis (LCA), we created CV damage phenotypes based on probabilities of abnormal brain infarctions, major echocardiogram abnormalities, N-terminal pro-brain natriuretic peptide, troponin T, interleukin-6, c reactive-protein, galectin-3, cystatin C. We assigned class descriptions based on the probability of having an abnormality among risk factors, such that a healthy phenotype would have low probabilities in all risk factors. Participants were assigned to phenotypes based on the maximum probability of membership. We used Cox-proportional hazards regression to evaluate the association between the categorical CV damage phenotype and all-cause and CVD-mortality.RESULTS: The analysis yielded 5 CV damage phenotypes consistent with the following descriptions: healthy (59%), cardio-renal (11%), cardiac (15%), multisystem morbidity (6%), and inflammatory (9%). All four phenotypes were statistically associated with a greater risk of all-cause mortality when compared with the healthy phenotype. The multisystem morbidity phenotype had the greatest risk of all-cause death (HR: 4.02; 95% CI: 3.44, 4.70), and CVD-mortality (HR: 4.90, 95% CI: 3.95, 6.06).CONCLUSION: Five CV damage phenotypes emerged from CVD risk factor measures. CV damage across multiple systems confers a greater mortality risk compared to damage in any single domain.\n\nView details for DOI 10.1016/j.annepidem.2021.07.012\n\nView details for PubMedID 34339835\n\nAbstract\n\nImportance: Socioeconomically marginalized communities have been disproportionately affected by the COVID-19 pandemic. Income inequality may be a risk factor for SARS-CoV-2 infection and death from COVID-19.Objective: To evaluate the association between county-level income inequality and COVID-19 cases and deaths from March 2020 through February 2021 in bimonthly time epochs.Design, Setting, and Participants: This ecological cohort study used longitudinal data on county-level COVID-19 cases and deaths from March 1, 2020, through February 28, 2021, in 3220 counties from all 50 states, Puerto Rico, and the District of Columbia.Main Outcomes and Measures: County-level daily COVID-19 case and death data from March 1, 2020, through February 28, 2021, were extracted from the COVID-19 Data Repository by the Center for Systems Science and Engineering at Johns Hopkins University in Baltimore, Maryland.Exposure: The Gini coefficient, a measure of unequal income distribution (presented as a value between 0 and 1, where 0 represents a perfectly equal geographical region where all income is equally shared and 1 represents a perfectly unequal society where all income is earned by 1 individual), and other county-level data were obtained primarily from the 2014 to 2018 American Community Survey 5-year estimates. Covariates included median proportions of poverty, age, race/ethnicity, crowding given by occupancy per room, urbanicity and rurality, educational level, number of physicians per 100 000 individuals, state, and mask use at the county level.Results: As of February 28, 2021, on average, each county recorded a median of 8891 cases of COVID-19 per 100 000 individuals (interquartile range, 6935-10 666 cases per 100 000 individuals) and 156 deaths per 100 000 individuals (interquartile range, 94-228 deaths per 100 000 individuals). The median county-level Gini coefficient was 0.44 (interquartile range, 0.42-0.47). There was a positive correlation between Gini coefficients and county-level COVID-19 cases (Spearman rho=0.052; P<.001) and deaths (Spearman rho=0.134; P<.001) during the study period. This association varied over time; each 0.05-unit increase in Gini coefficient was associated with an adjusted relative risk of COVID-19 deaths: 1.25 (95% CI, 1.17-1.33) in March and April 2020, 1.20 (95% CI, 1.13-1.28) in May and June 2020, 1.46 (95% CI, 1.37-1.55) in July and August 2020, 1.04 (95% CI, 0.98-1.10) in September and October 2020, 0.76 (95% CI, 0.72-0.81) in November and December 2020, and 1.02 (95% CI, 0.96-1.07) in January and February 2021 (P<.001 for interaction). The adjusted association of the Gini coefficient with COVID-19 cases also reached a peak in July and August 2020 (relative risk, 1.28 [95% CI, 1.22-1.33]).Conclusions and Relevance: This study suggests that income inequality within US counties was associated with more cases and deaths due to COVID-19 in the summer months of 2020. The COVID-19 pandemic has highlighted the vast disparities that exist in health outcomes owing to income inequality in the US. Targeted interventions should be focused on areas of income inequality to both flatten the curve and lessen the burden of inequality.\n\nView details for DOI 10.1001/jamanetworkopen.2021.8799\n\nView details for PubMedID 33938935\n\nAbstract\n\nBACKGROUND: Myocardial strain, measured by speckle-tracking echocardiography, is a novel measure of subclinical cardiovascular disease and may reflect myocardial aging. We evaluated the association between myocardial strain and frailty-a clinical syndrome of lack of physiological reserve.METHODS: Frailty was defined in participants of the CHS (Cardiovascular Health Study) as having ≥3 of the following clinical criteria: weakness, slowness, weight loss, exhaustion, and inactivity. Using speckle-tracking echocardiography data, we examined the cross-sectional (n=3206) and longitudinal (n=1431) associations with frailty among participants who had at least 1 measure of myocardial strain, left ventricular longitudinal strain (LVLS), left ventricular early diastolic strain rate and left atrial reservoir strain, and no history of cardiovascular disease or heart failure at the time of echocardiography.RESULTS: In cross-sectional analyses, lower (worse) LVLS was associated with prevalent frailty; this association was robust to adjustment for left ventricular ejection fraction (adjusted odds ratio, 1.32 [95% CI, 1.07-1.61] per 1-SD lower strain; P=0.007) and left ventricular stroke volume (adjusted OR, 1.32 [95% CI, 1.08-1.61] per 1-SD lower strain; P=0.007). In longitudinal analyses, adjusted associations of LVLS and left ventricular early diastolic strain with incident frailty were 1.35 ([95% CI, 0.96-1.89] P=0.086) and 1.58 ([95% CI, 1.11-2.27] P=0.013, respectively). Participants who were frail and had the worst LVLS had a 2.2-fold increased risk of death (hazard ratio, 2.20 [95% CI, 1.81-2.66]; P<0.0001).CONCLUSIONS: In community-dwelling older adults without prevalent cardiovascular disease, worse LVLS by speckle-tracking echocardiography, reflective of subclinical myocardial dysfunction, was associated with frailty. Frailty and LVLS have an additive effect on mortality risk.\n\nView details for DOI 10.1161/CIRCIMAGING.120.012116\n\nView details for PubMedID 33993730\n\nAbstract\n\nBACKGROUND: Little is known about long-term lipid variability in young adulthood in relation to cognitive function and brain integrity in midlife.METHODS: We studied 3,328 adults from the Coronary Artery Risk Development in Young Adults. We defined low- and high- density lipoprotein (LDL, HDL) variability as the intra-individual standard deviation of lipid measurements over 20 years of young adulthood (1985-2005). Cognitive tests were administered in 2010. Brain scans were performed in 2010 on 714 participants. To facilitate comparison, cognitive tests and brain metrics were z-scored.RESULTS: Mean age at baseline was 25.4 years. Higher 20-year LDL variability was associated with worse verbal memory in midlife (beta=-0.25, 95% CI [-0.42, -0.08]), adjusted for important covariates. Higher 20-year HDL variability was associated with worse processing speed in midlife (beta=-0.80, 95% CI [-1.18, -0.41]) and brain integrity, e.g. smaller total brain volume (beta=-0.58, 95% CI [-0.82, -0.34]) and worse total brain fractional anisotropy (beta=-1.13, 95% CI [-1.87, -0.39]).CONCLUSIONS: Higher long-term lipid variability in adulthood was associated with worse cognition and brain integrity in midlife, in a relatively young cohort.\n\nView details for DOI 10.1093/gerona/glab108\n\nView details for PubMedID 33839774\n\nAbstract\n\nBackground Only one third of patients recommended intensified treatment by the 2017 American College of Cardiology/American Heart Association (ACC/AHA) guideline for high blood pressure would have been eligible for the clinical trials on which recommendations were largely based. We sought to identify characteristics of adults who would have been trial-ineligible in order to inform clinical practice and research priorities. Methods and Results We examined the proportion of adults diagnosed with hypertension who met trial inclusion and exclusion criteria, stratified by age, diabetes mellitus status, and guideline recommendations in a cross-sectional study of the National Health and Nutrition Examination Survey, 2013-2016. Of the 107.7million adults (95% CI, 99.3-116.0million) classified as having hypertension by the ACC/AHA guideline, 23.1% (95% CI, 20.8%-25.5%) were below the target blood pressure of 130/80mmHg, 22.2% (95% CI, 20.1%-24.4%) would be recommended nonpharmacologic treatment, and 54.6% (95% CI, 52.5%-56.7%) would be recommended additional pharmacotherapy. Only 20.6% (95% CI, 18.8%-22.4%) of adults with hypertension would be trial-eligible. The majority of adults <50 years were excluded because of low cardiovascular risk and lack of access to primary care. The majority of adults aged ≥70 years were excluded because of multimorbidity and limited life expectancy. Reasons for trial exclusion were similar for patients with and without diabetes mellitus. Conclusions Intensive blood pressure treatment trials were not representative of many younger adults with low cardiovascular risk and older adults with multimorbidity who are now recommended more intensive blood pressure goals.\n\nView details for DOI 10.1161/JAHA.120.019707\n\nView details for PubMedID 33754796\n\nAbstract\n\nBACKGROUND: Previous studies have demonstrated an association between gait speed and cognitive function. However, the relationship between balance and cognition remains less well explored. This study examined the cross-sectional and longitudinal relationship of balance and cognitive decline in older adults.METHODS: A cohort of 4,811 adults, aged ≥65years, participating in the Cardiovascular Health Study was followed for 6years. Modified Mini-Mental State Examination (3MSE) and Digit Symbol Substitution Test (DSST) were used to measure cognition. Tandem balance measures were used to evaluate balance. Regression models were adjusted for demographics, behavioural and disease factors.RESULTS: Worse balance was independently associated with worse cognition in cross-sectional analysis. Longitudinally, participants aged ≥76years with poorer balance had a faster rate of decline after adjustment for co-variates: -0.97 points faster decline in 3MSE per year (95% confidence interval (CI): -1.32, -0.63) compared to the participants with good balance. There was no association of balance and change in 3MSE among adults aged <76years (P value for balance and age interaction < 0.0001). DSST scores reflected -0.21 (95% CI: -0.37, -0.05) points greater decline when adjusted for co-variates. In Cox proportional hazard models, participants with worse balance had a higher risk of being cognitively impaired over the 6 years of follow-up visits (adjusted HR:1.72, 95% CI: 1.30, 2.29).CONCLUSIONS: Future studies should evaluate standing balance as a potential screening technique to identify individuals at risk of cognitive decline. Furthermore, a better understanding of the pathophysiological link between balance and cognition may inform strategies to prevent cognitive decline.\n\nView details for DOI 10.1093/ageing/afab038\n\nView details for PubMedID 33693525\n\nAbstract\n\nNegative affect (NA) and positive affect (PA) are established modifiable psychosocial correlates of cognitive health and have demonstrated capacity for meaningful within-person fluctuations based on person-environment interactions, age, and measurement approach. Previous research has shown NA is associated with increased response time inconsistency (RTI), an early performance-based indicator of cognitive health and aging. It is unclear, however, whether PA is associated with RTI, and whether affect-RTI associations exist within persons over time or change as individuals get older. We utilized data from a measurement burst study (Cognition, Health and Aging Project) to explore within- and between-person associations between affect and RTI in community-dwelling older adults (N=111, M=80.04 years, SD=6.30). Affect and RTI were assessed on six days over a two-week period, every six months for two years. Results revealed a significant association between NA-low arousal and RTI within persons over time. RTI was higher on sessions when NA-low arousal was higher than usual (b=0.21, 95%CI=0.08 to 0.35, p<.01). This association decreased in magnitude over time (b=-0.09, 95%CI=-0.14 to - 0.03, p<.001), ultimately resulting in increased NA-low arousal being associated with decreased RTI two years later (b=-.14, 95%CI=-0.27 to -0.01, p<.05). No PA-RTI associations emerged. The results suggest efforts focused on maximizing resource allocation and personalizing cognitive health efforts should consider for whom and when mitigating NA may be maximally beneficial to daily cognition, whereas additional work is needed to determine influences from PA.\n\nView details for DOI 10.1177/0165025420937081\n\nView details for PubMedID 33758448\n\nView details for PubMedCentralID PMC7984415\n\nAbstract\n\nWhether high burden of subclinical vascular disease (SVD) is associated with increased premature mortality among middle-aged adults is not adequately understood. The association of midlife SVD burden with premature mortality among middle-aged adults free of clinical cardiovascular disease (CVD) could provide further insights into stratifying premature death beyond clinical CVD.To determine whether high burden of subclinical vascular disease is associated with increased premature mortality among middle-aged adults.We leveraged data from the Atherosclerosis Risk in Communities Study.Thirteen thousand eight hundred seventy-six community-dwelling blacks and whites aged 45-64 years from the Atherosclerosis Risk in Communities Study.Each SVD measure-ankle-brachial index, carotid intima-media thickness, and electrocardiogram-was scored 0 (no abnormalities), 1 (minor abnormalities), or 2 (major abnormalities). An index was constructed as the sum of three measures, ranging from 0 (lowest burden) to 6 (highest burden). We used the Cox proportional-hazards model to determine the association of SVD burden with premature mortality (death before age 70) among persons free of clinical CVD. We then tested the difference in point estimates between SVD and clinical CVD.Among persons without CVD, the premature death was 1.7, 2.1, 2.5, and 3.8 per 1000 person-years among those with an SVD score of 0 (lowest burden), 1, 2, and 3-6 (highest burden), respectively. After multivariable-adjustment, highest SVD burden (score = 3-6; HR = 1.47) was significantly associated with premature death among persons initially without CVD. In the model where persons with and without CVD were included, high SVD burden (score: 3-6 vs. 0) and CVD did not have hugely different association with premature death (HR = 1.49 vs. 1.68; P = 0.32 for comparison).Midlife SVD burden was associated with premature mortality and it could stratify premature death beyond clinical CVD. It is important to take SVD into account when designing interventions for reducing premature mortality.\n\nView details for DOI 10.1007/s11606-020-06398-6\n\nView details for PubMedID 33469773\n\nAbstract\n\nThe timed 25-foot walk (T25FW) is a key clinical outcome measure in multiple sclerosis patient management and clinical research.To evaluate T25FW performance and factors associated with its change in the Multiple Sclerosis Outcome Assessments Consortium (MSOAC) Placebo Database (n = 2465).We created confirmed disability progression (CDP) variables for T25FW and Expanded Disability Status Scale (EDSS) outcomes. We used intraclass correlation coefficients (ICCs) and Bland Altman plots to evaluate reliability. We evaluated T25FW changes and predictive validity using a mixed-effects model, survival analysis, and nested case-control analysis.The mean baseline score for the T25FW in this study population was 9.2 seconds, median = 6.1 (standard deviation = 11.0, interquartile range (IQR) = 4.8, 9.0). The T25FW measure demonstrated excellent test-retest reliability (ICC = 0.98). Walk times increased with age, disability, disease type, and disease duration; relapses were not associated with an increase. Patients with T25FW progression had a faster time to EDSS-CDP compared to those without (hazards ratio (HR): 2.6; confidence interval (CI): 2.2, 3.1). Changes in the T25FW were more likely to precede changes in EDSS.This research confirms the association of the T25FW with disability and provides some evidence of predictive validity. Our findings support the continued use of the T25FW in clinical practice and clinical trials.\n\nView details for DOI 10.1177/13524585211017013\n\nView details for PubMedID 34100297\n\nAbstract\n\nFew studies have examined the association of neighborhood environment and mortality among community-dwelling older populations. Geographic Information Systems (GIS)-based measures of neighborhood physical environment may provide new insights on the health effects of the social and built environment.We studied 4,379 community-dwelling older adults in the US aged ≥65 years from the Cardiovascular Health Study. Principal component analysis was used to identify neighborhood components from 48 variables assessing facilities and establishments, demographic composition, socio-economic status, and economic prosperity. We used a Cox model to evaluate the association of neighborhood components with five-year mortality. Age, sex, race, education, income, marital status, body mass index, smoking status, disability, coronary heart disease, and diabetes were included as covariates. We also examined the interactions between neighborhood components and sex and race (Black vs. white or other).We identified five neighborhood components, representing facilities and resources, immigrant communities, community-level economic deprivation, resident-level socio-economic status and residents' age. Communities' economic deprivation and residents' socio-economic status were significantly associated with five-year mortality. We did not find interactions between sex or race and any of the five neighborhood components. The results were similar in a sensitivity analysis where we used ten-year mortality as the outcome.We found that communities' economic status but not facilities in communities was associated with mortality among older adults. These findings revealed the importance and benefits living in a socio-economically advantaged neighborhood could have on health among older residents with different demographic backgrounds.\n\nView details for DOI 10.1093/gerona/glab319\n\nView details for PubMedID 34669918\n\nAbstract\n\nBACKGROUND: Despite evidence that African Americans shoulder a high burden of mobility limitation, little is known about factors associated with recovery.METHODS: Participants from the Jackson Heart Study underwent three in-person exams from 2000-2013. Mobility limitations were assessed over this period by self-reported limitations in walking half a mile or climbing stairs during annual phone calls. The outcome of interest, recovery from mobility limitation, was defined as no mobility limitation the year following an incident event. Candidate predictor variables were assessed in logistic regression models, including sociodemographic, psychosocial, and health measures. Inverse probability weights were used to address missing data in the outcome.RESULTS: Among 4,526 participants [mean (SD) age = 54.5 (12.8) years] without a mobility limitation at baseline, 1,445 (32%) had an incident mobility limitation over 12 years of follow-up, and 709 (49%) reported recovery from mobility limitation by one year later. Low income and daily discrimination were associated with a lower likelihood of recovery even after adjustment for covariates. In adjusted models, greater comorbidity was associated with a lower likelihood of recovering (p-value for trend = 0.05). History of heart failure and cancer were associated with a lower likelihood of recovering from mobility limitation (OR: 0.52, 95% CI: 0.29, 0.94 and 0.74, 95% CI: 0.55, 1.00). Adiposity, smoking status, and physical activity were not associated with recovery from mobility limitation.CONCLUSION: Half of incident mobility limitations in this population of middle-aged African Americans were transient. Adverse sociodemographic factors and comorbidities were associated with lower likelihood"
    }
}