{
    "id": "correct_subsidiary_00073_1",
    "rank": 74,
    "data": {
        "url": "https://www.pewresearch.org/internet/2020/02/21/concerns-about-democracy-in-the-digital-age/",
        "read_more_link": "",
        "language": "en",
        "title": "3. Concerns about democracy in the digital age",
        "top_image": "https://www.pewresearch.org/wp-content/uploads/sites/20/2020/02/PI_20.01.24_FutureOfTechAndDemocracy_feature-jpg.webp?w=1200&h=628&crop=1",
        "meta_img": "https://www.pewresearch.org/wp-content/uploads/sites/20/2020/02/PI_20.01.24_FutureOfTechAndDemocracy_feature-jpg.webp?w=1200&h=628&crop=1",
        "images": [
            "https://www.pewresearch.org/wp-content/plugins/prc-block-library/blocks/promo/assets/weekly.svg",
            "https://www.pewresearch.org/wp-content/plugins/prc-block-library/blocks/promo/assets/journalism.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Reem Nadeem",
            "Janna Anderson",
            "Lee Rainie"
        ],
        "publish_date": "2020-02-21T00:00:00",
        "summary": "",
        "meta_description": "Experts who expressed optimism often voiced concerns about democracy in the digital age. This section includes comments about problems.",
        "meta_lang": "en",
        "meta_favicon": "https://www.pewresearch.org/wp-content/themes/prc-block-theme/assets/img/square.png",
        "meta_site_name": "Pew Research Center",
        "canonical_link": "https://www.pewresearch.org/internet/2020/02/21/concerns-about-democracy-in-the-digital-age/",
        "text": "About half of the experts responding to this canvassing said people’s uses of technology will mostly weaken core aspects of democracy and democratic representation, but even those who expressed optimism often voiced concerns. This section includes comments about problems that were made by all respondents regardless of their answer to the main question about the impact of technology on democracy by 2030. These worries are organized under seven themes.\n\nEmpowering the powerful: Corporate and government agendas generally do not serve democratic goals or achieve democratic outcomes. They serve the goals of those in power\n\nAn internet pioneer and technology developer and administrator predicted, “My expectation is that by 2030, as much of 75% of the world’s population will be enslaved by artificial intelligence-based surveillance systems developed in China and exported around the world. These systems will keep every citizen under observation 24 hours a day, seven days a week, monitoring their every action.”\n\nDan Gillmor, co-founder of the News Co/Lab at Arizona State University’s Walter Cronkite School of Journalism and Mass Communication, and professor of practice in digital media literacy commented, “Governments (and their corporate partners) are broadly using technology to create a surveillance state, and what amounts to law by unaccountable black-box algorithm, far beyond anything Orwell imagined. But this can only happen in a society that can’t be bothered to protect liberty – or is easily led/stampeded into relinquishing it – and that is happening in more and more of the Western democracies. The re-emergence of public bigotry has nothing to do with technology, except to the extent that bigots use it to promote their malignant goals. Meanwhile, the institutions that are supposed to protect liberty – journalism among them – are mostly failing to do so. In a tiny number of jurisdictions, people have persuaded leaders to push back on the encroachments, such as a partial ban on government use of facial recognition in San Francisco. But the encroachments are overwhelming and accelerating.”\n\nLeah Lievrouw, professor of information studies at the University of California-Los Angeles, wrote, “To date, virtually no democratic state or system has sorted out how to deal with this challenge to the fundamental legitimacy of democratic processes, and my guess is that only a deep and destabilizing crisis (perhaps growing out of the rise of authoritarian, ethnic or cultural nationalism) will prompt a serious response.”\n\nSeth Finkelstein, programmer, consultant and EFF Pioneer of the Electronic Frontier Award winner, wrote, “Warren Buffett has said, ‘There’s class warfare, all right, but it’s my class, the rich class, that’s making war, and we’re winning.’ We can examine how this class warfare changes with advances in technology, analogous to how military warfare has been affected by technology. But no weapons technology to date has inevitably produced democracy over dictatorship (or vice-versa). For example, there once was a type of boosterism that talked about how ordinary people could make websites and promoted its very rare cause célèbre success. But that storyline is now going out of fashion. It’s finally getting to be pundit knowledge that there’s a whole system behind which material gets promoted. Paid professional liars can both make websites themselves and work this system better than amateurs. There’s currently a national panic over Russian trolls. But native fiends can do the same thing, with more skill, incentive and opportunities.”\n\nDavid Bray, executive director for the People-Centered Internet Coalition, commented, “The power of narratives is exactly their ability to shape and institutionalize norms and power distribution in our human communities. … Now, however, our world is much broader than our immediate environment, and this has dangerous side effects, such as challenges in reaching consensus or disputing the relevant facts for a situation. We are seeing increasing polarization in open societies, partly as a result of these questions of where we want to go not being considered in ways that can translate to action. An even larger question is where do different localities want to go in terms of progress in parallel to what values or norms they want to hold dear? This is a question that spans sectors. No one organization or influencer or group with power can either solely answer or execute actions toward that desired future state. In the absence of finding ways to build bridges that span sectors, power – through narratives, laws, or technologies – will be grabbed by whomever aspires to this. An important question for the future is can we build such bridges across sectors? Will our divisions be our undoing as open, pluralistic societies? Can we develop narratives of hope for open, pluralistic societies that bring people together?”\n\nTechnology can improve or undermine democracy depending on how it is used and who controls it. Right now, it is controlled by too few. Kevin Gross\n\nMiguel Moreno, professor of philosophy at the University of Granada, Spain, an expert in ethics, epistemology and technology, commented, “There is a clear risk of bias, manipulation, abusive surveillance and authoritarian control over social networks, the internet and any uncensored citizen expression platform, by private or state actors. There are initiatives promoted by state actors to isolate themselves from a common internet and reduce the vulnerability of critical infrastructures to cyberattacks. This has serious democratic and civic implications. In countries with technological capacity and a highly centralized political structure, favorable conditions exist to obtain partisan advantages by limiting social contestation, freedom of expression and eroding civil rights.”\n\nRichard Jones, an entrepreneur based in Europe, said, “Government will lag exploitation of data by state and corporate actors in unforeseen ways. Biased censorship (both well-intentioned and corrupt) and propaganda onslaughts will shape opinions as – combined with an anti-scientific revolution – confidence in the institutions and establishment figures essential to peaceful orderly improvement of societies crumbles further. Hysterical smear attacks will further intensify as attempts to placate minority pressure groups continue. Biased technocratic groupthink will continue its march toward authoritarianism. Charismatic leadership will flourish in truly liberal systems. Authoritarianism will take root elsewhere. Online preference surveys may be developed to guide many choices facing government, but it is not clear that can correct the current democratic deficit in a helpful way. As during the Gutenberg process, accompanying the digestion of ‘free-range’ information will be the reevaluation of secular and religious values and objectives.”\n\nJohn Sniadowski, a systems architect based in the United Kingdom, wrote, “It is proving very difficult to regulate multinational corporations because of the variety of different national government agendas. A globally enacted set of rules to control multinationals is unlikely to happen because some sovereign states have very illiberal and hierarchical control over agendas and see technology as a way to dominate their citizens with their agendas as well as influence the democratic viewpoints of what they consider to be hostile states. Democracy in technological terms can be weaponized.”\n\nKevin Gross, an independent technology consultant, commented, “Technology can improve or undermine democracy depending on how it is used and who controls it. Right now, it is controlled by too few. The few are not going to share willingly. I don’t expect this to change significantly by 2030. History knows that when a great deal of power is concentrated in the hands of a few, the outcome is not good for the many, not good for democracy.”\n\nRobert Epstein, senior research psychologist at the American Institute for Behavioral Research and Technology, said, “As of 2015, the outcomes of upward of 25 of the national elections in the world were being determined by Google’s search engine. Democracy as originally conceived cannot survive Big Tech as currently empowered. If authorities do not act to curtail the power of Big Tech companies – Google, Facebook and similar companies that might emerge in coming years – in 2030, democracy might look very much as it does now to the average citizen, but citizens will no longer have much say in who wins elections and how democracies are run. My research – dozens of randomized, controlled experiments involving tens of thousands of participants and five national elections – shows that Google search results alone can easily shift more than 20% of undecided voters – up to 80% in some demographic groups – without people knowing and without leaving a paper trail (see my paper on the search engine manipulation effect). I’ve also shown that search suggestions can turn a 50/50 split among undecided voters into a 90/10 split – again, without people knowing they have been influenced. The content of answer boxes can increase the impact of the search engine manipulation effect by an additional 10% to 30%. I’ve identified about a dozen largely subliminal effects like these and am currently studying and quantifying seven of them. I’ve also shown that the ‘Go Vote’ prompt that Google posted on its home page on Election Day in 2018 gave one political party at least 800,000 more votes than went to the opposing party – possibly far more if the prompt had been targeted to the favored party.”\n\nA longtime internet-rights activist based in South Africa responded, “Whether the powers of states and tech corporations can be reined in effectively is the current struggle. The genie is out of the bottle and it does not bode well for systems of democracy that have already been undermined in Western states. A state of global cyber war now exists and is likely to persist over the next decade. The oligopoly of state-supported tech companies, whether in the U.S. or China, will be difficult to break. It is trite to differentiate between a Google or an Alibaba – both received substantial state support from their respective governments – the Googles by failure to apply antitrust law to prevent monopolization, the Alibabas by state protection against competition in China.”\n\nDavid P. Reed, a pioneering architect of the internet expert in networking, spectrum and internet policy, wrote, “‘Democracy’ in 2030 will be democracy in name only. The mechanisms of widespread corporate surveillance of user behavior and modification of user behavior are becoming so sophisticated that the citizen interests of democratic-structured countries will no longer be represented in any meaningful way. That is, by collecting vast amounts of information about user preferences and responses, and the use of highly targeted behavior modification techniques, citizens’ choices will be manipulated more and more in the interests of those who can pay to drive that system. The current forms of democracy limit citizen participation to election events every few years, where issues and candidates are structured by political parties into highly targeted single-vote events that do not represent individuals’ interests. Instead, a small set of provocative ‘wedge’ issues are made the entire focus of the citizen’s choice. This is not representation of interests. It is a managed poll that can easily be manipulated by behavior modification of the sort that technology is moving toward.”\n\nA pioneering technology editor and reporter for one of the world’s foremost global news organizations wrote, “I do not have great faith that the institutions tasked with ensuring that online discourse is civil and adheres to standards of truth and fairness will be able to prevail over tendencies of autocratic governments and powerful private sector actors to use cyberspace for narrow political ends. … The internet has never had an effective governing body with any considerable clout to set policy that might guarantee network neutrality on a global scale, inhibit censorship and apply such conventions as the Universal Bill of Human Rights. Further, a handful of platforms whose moral compass has been questioned have come to dominate the online world. Some are dominated by governments. Others owe allegiance only to shareholders.”\n\nJerry Michalski, founder of REX, the Relationship Economy eXpedition, wrote, “‘Capital G’ Government has devolved into a phony consumer mass-marketing exercise. ‘Small g’ governance could involve active, ongoing collaboration among citizens, but it won’t as long as the major platforms they use have as their business models to addict them to TikTok videos, and to sell off their private data to companies that want to stalk them.”\n\nJonathan Kolber, author of “A Celebration Society: Solving the Coming Automation Crisis,” said, “Deepfakes will completely muddy the difference between facts and falsehood, a distinction that few citizens are equipped to make even now. This will have devastating effects upon democratic institutions and processes. … We are increasingly seeing George Orwell’s nightmare unfold as governments learn to use internet-enabled smart devices (televisions, smartphones, etc.) for surveillance. When the Internet of Things extends to smart cars, smart homes and so forth, the surveillance will be universal and unending. Governments are also increasingly redefining facts and history.”\n\nA professor of computer science said, “Artificial intelligence technology, especially machine learning, has a feedback loop that strongly advantages first movers. Google’s advantages in being a better search engine have now been baked in by its ability to accumulate more data about user search behavior. This dynamic is inherently monopolistic, even more so than prior technological advances. Persuasive technologies built using these technologies are capable of refining and shaping public opinion with a reach and power that totalitarian governments of the 20th century could only dream of. We can be sure that today’s regulatory mood will either dissipate with nothing done, or more likely, become a driver that entrenches existing monopolies further by creating technical demands that no competitor can surmount. Democratic institutions will have a very difficult time countering this dynamic. Uber’s ‘greyball’ program, intended to defeat regulation and meaningful audit, is a harbinger of the future.”\n\nJonathan Taplin, author of “Move Fast and Break Things: How Google, Facebook and Amazon Cornered Culture and Undermined Democracy,” said, “Social media will continue to enable new and more-sophisticated forms of propaganda and disinformation. Artificial intelligence will enable deepfake videos that the average citizen will be taken in by. Facebook, YouTube and Twitter will continue to enable this content in their unending chase for revenue. Politicians will make noises about regulation, but since these platforms will become their primary source of advertising and publicity, they will never commit to the elimination of Safe Harbor and other rules that protect the social networks.”\n\nBulbul Gupta, founding adviser, Socos Labs, a think tank designing artificial intelligence to maximize human potential, responded, “Given the current state of tech and artificial intelligence ownership, I expect democracy to be even more unequal between the haves and have-nots by 2030, and a major uprising happening from the masses who are being quickly left behind. Tech and AI are owned by their creators, the top 1%, with decisions made about the 100% in every sector of society that have little to no transparency, human judgment or much recourse, and that may not get made the same if they were being forced to happen face to face. People will need their own personal AIs in their corner to protect their basic civil and human rights.”\n\nCarlos Afonso, an internet pioneer and digital rights leader based in Rio de Janeiro, Brazil, wrote, “Thomas Piketty and others demonstrate that inequality is, if anything, rising everywhere. Democracy understood as pluralist participation in political processes involving the electoral (supposedly unbiased) choices of government representatives, and the decision-making processes in building policies, legislation and regulation, cannot survive in these conditions. … One of the greatest achievements of the UN community was the consensus agreement on trying to reach the 17 sustainable development goals by 2030. However, conflicts of all kinds, internal and inter-country, give us no hope that the essential components of those goals will be achieved worldwide. Also, there is (partly in consequence of the various manifestations of a growing economic crisis with the financial speculators at the head of these processes) little chance that resources will increase to cover the essential needs of the majority.”\n\nEven former pillars of democracy, Britain and France, are challenged by forces misusing digital tools. Norton Gusky\n\nJames Sigaru Wahu, assistant professor, media, culture and communication, New York University and fellow at Harvard’s Berkman Klein Center, wrote, “As we have seen across the Global North, tech has only worked to make worse offline tension. This has resulted in multiple challenges toward notions of democracy as shown by the Brexit debacle, 2016 presidential elections and violence against immigrant groups. We have also seen states get in the act through the use of technology to expand their surveillance powers, as is the case in China and in the UK (with its large CCTV camera presence). States in the Global South have also gotten into the surveillance game, which does not bode well for organizations and people advocating for human rights. What we have thus seen is countries like Russia and China growing in strength in tech surveillance and misinformation/disinformation while the United States and several police departments across the country rely on companies such as Palantir to expand their surveillance on citizens. Both of these have led to disastrous results.”\n\nLokman Tsui, professor at the School of Journalism and Communication of The Chinese University of Hong Kong, formerly Google’s Head of Free Expression in Asia and the Pacific, said, “The political economy of new technologies that are on the horizon leaves me with many concerns for how they will impact democracy and its institutions. First, many of the new technologies, including artificial intelligence, machine learning and big data, are closed and centralized in nature. Unlike the open web before it, these technologies are closed and centralized, both in terms of technical design and also in terms of business model. The technology can indeed be used to improve democratic institutions and processes, but it will be hard and there will be many obstacles to overcome. Second, the new technologies are not only not helping democracies, but they, by their design, are also helping and strengthening non-democracies to further censorship and surveillance. While there are also technologies to counteract these tendencies, the balance tends to tip (heavily) in favor of the other side. Third, I’m concerned there is a global rat race toward the bottom when it comes to the collection of (personal) data, which has the potential to enable the suppression of many other rights.”\n\nNorton Gusky, a futurist and advocate for implementing technology to empower people, commented, “For many years I truly believed that the internet would bring greater access to information that would strengthen democracy. However, in the past four to five years, I’ve witnessed a darker side to the internet. We now see countries like Russia interfering in the elections of not just the United States, but other countries throughout the world. I think there will be a swing, but for the next two to four years, the darker forces will prevail. We’ll see countries like Turkey, China and Egypt limiting the access to the ‘truth.’ Even former pillars of democracy, Britain and France, are challenged by forces misusing digital tools.”\n\nPaola Ricaurte, fellow, Berkman Klein Center for Internet & Society, wrote, “Even after we are aware of the negative implications that technology can have on democratic processes, we have not seen significant actions by the U.S. government to limit the power of tech corporations. The extraterritorial control of technology companies will be further expanded and will continue to have consequences for the democracies of the Global South. The knowledge gap between data-rich countries and data-poor countries will deepen.”\n\nIan O’Byrne, assistant professor of education at the College of Charleston, wrote, “Power and money ultimately influence decisions made by democratic bodies. With growing unrest, citizens can use social media and current/new digital tools to make themselves heard. Ultimately this will be pushed back again by existing powerholders and nothing may ultimately change. The existing powerholders will continue to exert their influence, and citizens will be left to continue to voice their opinions by shouting into the cyberverse.”\n\nJeffrey Alexander, senior manager for innovation policy at RTI International, said, “In societies where people are accustomed to power being centralized in a few institutions, and where central governments already exert power through surveillance and state authority, digital technology will facilitate intimidation, disinformation and other mechanisms for reducing individual liberty, suppressing minority opinion and enforcing authoritarian control. This will enable such governments to enhance the appearance of following democratic norms, such as offering ‘free and open’ elections, but use those mechanisms to reinforce their power by suppressing dissent well before voters reach the polls. In societies with strong individual education and a tradition of liberty and citizen-driven initiatives, digital technology could help thwart the rise of authoritarian rule, improve oversight and governance of law enforcement and policy processes, and enhance citizen involvement in government and politics.”\n\nJohn Pike, director and founder of GlobalSecurity.org, said, “Democracy in 2030 will face the best of times and the worst of times. All the optimistic predictions about social media and other online implementations strengthening citizen participation will be realized. All the pessimistic predictions about the ease with which the surveillance state can manipulate public opinion will also be realized. Autocratic regimes such as Russia and China are skilled at such dark arts at home and will practice them globally. In the old days it was pretty obvious that the Communist Party USA member hawking the Daily Worker was working for Moscow, but now attribution is difficult and contested.”\n\nShane Kerr, an engineer for an internet security firm, said, “Those with resources will be able to harness technology more effectively to influence opinion and policies, ultimately working against democratic ideals. We already see this in a nascent form today, but it will likely evolve into such a pervasive narrative that the average citizen will not even be aware of it, unless they study history (assuming that ‘1984’-style revisionist history does not become the norm).”\n\n[the fact that they]\n\nSasha Costanza-Chock, associate professor of civic media at Massachusetts Institute of Technology, wrote, “Core aspects of the democratic process are deeply stressed or broken. In the United States, we need significant reforms to enable broader and more meaningful participation in democratic decision-making, such as instant runoff or rank-order voting, expansion of voting days and times, expanded voting rights for formerly incarcerated people, campaign finance reform, rethinking the electoral college and much more. Unfortunately, most of these are extremely unlikely. Instead, we seem locked into an elitist and extremely expensive electoral system where the players with the most money and connection to wealthy backers rig the system to their advantage. In this context, many technological tools primarily advance those who can develop and customize them for their own ends – again, the biggest players. There are some countervailing forces such as the ability of insurgent candidates to leverage social media.”\n\nDenise N. Rall, academic researcher of popular culture, Southern Cross University, New South Wales, Australia, said, “I believe technology will help the dictators that we now have stay on top and control more aspects of all of our lives, worsening the prospects for democracy as has already happened in most economic powerhouses of the world (U.S., Russia, China, and right-wing elections in Europe, the absurdity of Brexit in the UK, North Korea, etc.). I think environmental degradation will increase exponentially and people will be fighting over resources like energy, water and food quite soon. I do not think technology will have the power to change these outcomes without real desire by governments to reduce resource consumption and a global birth control program of some kind.”\n\nAn anonymous respondent commented, “China has the potential to stall trends toward democracy and regime change through increased monitoring of their citizenry and refinement of their ‘social credit’ legislation/monetization of following the whims of their single party. There is a potential for China to help prop up regimes in developing countries where they have vested interests by distributing such technologies to undemocratic regimes that want to remain in power. I think that India could go either way depending on whether or not widespread corruptions in their political environment exploit or are thwarted by increased access to technology and information by their citizenry.”\n\nTechnologies of identification and surveillance will expand in usage, eating away at the private sphere of social life. Retired professor\n\nRichard Lachmann, professor of political sociology at the State University of New York-Albany, said, “Democracy will continue to weaken but technology is only a secondary factor. More important in the decline of democracy are the disappearance or weakening of labor unions, the growing power of corporations in all sectors due to mergers, extreme levels of inequality and the ability of the rich and of political actors to manipulate ‘veto points’ to paralyze government initiatives, which then increases citizens’ cynicism about politicians and lessens their participation. All of these preceded the expansion of the internet and will not be significantly lessened by citizens’ online activities.”\n\nVince Carducci, researcher of new uses of communication to mobilize civil society and dean at the College of Creative Studies, wrote, “Institutional changes are occurring more as a function of power and money rather than technology, particularly in the selection of candidates and in the judicial system. Those are more of threat than technology.”\n\nA cofounder of one of the internet’s first and best-known online communities wrote, “Democracy is under threat. The blame can’t ultimately go to the internet or to computer-aided automation or to artificial intelligence. The vast power of personal and corporate wealth to wield these technologies in support of their selfish interests will increasingly suppress egalitarian and democratic values.”\n\nA research scientist for a U.S. federal agency wrote, “We are in a period of growing isolationism, nativism and backlash that will weaken democracies around the world, and it will probably have reached a peak by 2030. Although technology and online dissemination of information will be a tool of information and disinformation, and it will be a tool of policing populations, the underlying economic and environmental shifts are mostly responsible for changes resulting in weaker democracies.”\n\nA retired professor commented, “Corporations will have more power over employees and customers. This will be achieved as part of the ongoing corporate takeover of democratic institutions, which U.S. President Eisenhower warned of long ago. Technologies of identification and surveillance will expand in usage, eating away at the private sphere of social life. Social media will continue to reinforce strong social ties among family and friends while reducing the formation of the weak social ties among acquaintances that support intergroup cooperation necessary in a diverse society. Worsening climate and its consequences for health, agriculture and infrastructure will create increasing irrational forms of blame and global conflict. Global conflicts will include electronic and biological forms of aggression against the militarily powerful countries. More citizen backlash is to be expected, but will likely be directed against inappropriate targets. Societies as we know them will stumble from disaster to disaster, toward a massive die-off of our species. I hope I’m wrong. I would like to see our species survive with its democratic values intact. I have grandchildren. I would like their grandchildren to inherit a better world than the one that our present technocratic capitalist economy is racing toward.”\n\nAnonymous respondents commented:\n\n“The internet under capitalism will only serve the few, not the many, and democracy will weaken as a result. The problem is about competitive economic imperatives rather than technological affordances.”\n\n“It’s not the technology that will cause the changes, but the systems and structures that create various tech.”\n\n“The loudest voices will continue to be those that are heard. While the media may change, the elite will still run everything.”\n\n“Technology companies and governments have incentives to avoid doing things to address the damaging ways in which internet platforms damage democratic institutions.”\n\n“Power corrupts. Look at the tech giants today – manipulation and propaganda. They are elitists who think they know best.”\n\n“The combination of big data and supercomputing power seems to be having a negative effect on democracy, and I see no signs that that can be effectively policed or regulated, particularly given the power (and data troves) of very large internet companies and of governments.”\n\n“I do not believe that governments understand the tools, and they will fail repeatedly to regulate or organize them properly; I also do not have faith the private companies are democratic, and therefore they are apt to reinforce capitalism alone, not democracy.”\n\nDiminishing the governed: Digitally networked surveillance capitalism creates an undemocratic class system pitting the controllers against the controlled\n\nCharles Ess, professor of digital ethics, at the University of Oslo, said, “Democracy – its foundational norms and principles, including basic rights to privacy, freedom of expression and rights to contest and conscientiously disobey – may survive in some form and in some places by 2030; but there are many strong reasons, alas, to think that it will be pushed to the margins in even traditionally democratic countries by the forces of surveillance capitalism, coupled with increasing citizen feelings of powerlessness against these forces, along with manipulation of information and elections, etc. Not to mention China’s increasingly extensive exports of the technologies of ‘digital authoritarianism’ modelled on their emerging Social Credit System.”\n\nThere is simply no reason to believe that technology can strengthen democracy. Gina Neff\n\nRob Frieden, a professor of telecommunications law at Penn State who previously worked with Motorola and has held senior policy positions at the Federal Communications Commission and the National Telecommunications and Information Administration, said, “Technological innovations appear better suited for expanding government power versus improving the ability of individuals to evade surveillance. Across the entire spectrum of political ideology, national governments can justify increased budgets for ever-more-sophisticated surveillance technologies based on noble-sounding rationales, such as national security. Governments have little incentives and incur even fewer penalties when they fail to calibrate surveillance technology for lawful reasons. Innocent people will have reasonable privacy expectations eroded, particularly with technologies that have massive processing power and range coupled with an ambiguous mandate. Unless and until citizens push back, governments will use surveillance technologies to achieve goals beyond promoting national security. We risk becoming inured and numbed by ubiquitous surveillance, so much so that pushback seems too difficult and unproductive.”\n\nGina Neff, senior research fellow, Oxford Internet Institute, studying innovation and digital transformation, wrote, “There is simply no reason to believe that technology can strengthen democracy. Western democracies are grappling with the power from the increased concentration of financial capital and its response in the form of the rise of populism. Without attention to strengthening our core technology and communications infrastructure, those forces will continue to damage how people participate in – and indeed make – democracy.”\n\nZizi Papacharissi, professor of communication and political science, University of Illinois-Chicago, responded, “Our present system of governance supports strong capitalism/soft democracy. Until this balance is reorganized, to support soft capitalism/strong democracy, any technology we create will continue to underserve democracy. In short, the technology we have created was designed to generate profit, not to support democracy. It is possible to do both. We just have not designed it that way, however. By 2030, we will see a weakening of democratic and political processes facilitated by technology. This will happen not because there is something inherently bad or undemocratic about technology. It is because most technology is designed, implemented and/or deployed through mechanisms that support a strong capitalist model that was created centuries ago and needs to be updated in order to be compatible with contemporary societies, democratic and non.”\n\nJohn Harlow, smart-city research specialist in the Engagement Lab at Emerson College, said, “Although there is rising anti-monopoly sentiment, 2030 is soon, and the dominant digital commons for speech (Facebook, Twitter, YouTube) are likely to draw out (in the courts) any regulatory action to change their business models and/or practices. Currently, they are governed by algorithms designed to maximize ‘engagement’ time and thereby advertising revenue, and those algorithms have prioritized extreme content over accurate content (among other problems). This has enabled and supported the rise of the authoritarian far right the world over, and has destabilized faith and participation in democratic institutions and processes.”\n\nAn expert on online trust and identity active in the multistakeholder organizations that build and maintain the internet said, “Uses are shaped by social and economic factors that drive toward consolidation and control. Having created a prefect panopticon that maps every endpoint and every device on the network, and with the rise of middle-box collectors that use massive computing power to correlate identifiers, the end result will tilt toward command and control.”\n\nAn expert in socio-technical systems wrote, “Social media tech firms will continue to resist control and meaningful regulation in order to preserve their core business, aptly described by Shoshana Zuboff as ‘surveillance capitalism.’ The oligarchs, perhaps still aided by foreign interests, will continue to manipulate public opinion for their own benefit. Economic inequality will continue to increase, as will resentment, misdirected toward immigrants and the ‘elites.’”\n\nAn expert in human-computer design wrote, “The decay of democracy should be attributed foremost to capitalism itself, and thus only in a secondary way to technology. Capitalism seems overdue for major shock, enough so that predicting much of anything so far ahead as 2030 seems foolish. The present moment witnesses the close of a decade of ever-intensified distraction engineering.”\n\nAn expert in the law who previously worked for a U.S. government agency wrote, “Increasingly sophisticated marketing based on data and inferred data on every individual threatens to cross the line between persuasion and manipulation and coercion, and the First Amendment restraints on government will require a substantial degree of proof of coercion before the government will be able to intervene to safeguard individuals from clear overreaching. The threat of manipulation – and we saw the first signs of that in 2018 with the Cambridge Analytica fiasco – is real and growing. Whether industry or government can curb it is an open question. Industry of course has a conflict of interest – the more successful its manipulation is, the more money industry makes. And government has the restraints of the First Amendment that limit its role.”\n\n[cyberspace as a venue for war, along with land, sea, air, space]\n\nThe problem with everyone having a megaphone is that we get drowned in more noise than useful information. Sam Adams\n\nEmilio Velis, executive director, Appropedia Foundation, said, “The way user participation has been shaped by technological platforms for the past 10 years turned the power of decentralized information back to the big corporations, platforms and stakeholders. Or, even worse, it has weakened the capacity of individuals of action while maintaining a false perception that they have control.”\n\nPeter Lunenfeld, professor of design, media arts and digital humanities, University of California-Los Angeles, and author of “Tales of the Computer as Culture Machine,” wrote, “Commercial platform-driven communication technologies like Facebook, Twitter and their eventual successors are unlikely to strengthen representative democracy in the coming decades of the 21st century. They may add ‘voices’ to the conversation, but they will be unlikely to support and sustain the 20th century’s dominant forms of successful democracies – those that designated representatives to debate and legislate on their behalf, from coherent parties that had established ideologies and platforms. What we are starting to see is the development of dialoguing ‘communities’ that mimic the give and take of true democratic action without offering actual power to its participants, like the Italian Five Star Movement, or the emergence of personality-driven, single-issue pop-ups like Nigel Farage’s Brexit Party. Like Five Star and the Brexit Party, future political movements will use social media to offer the affordances of democratic dialogue without actually empowering participants to control or direct the movements. Social media technologies are creating skeuomorphs of democracies; they will have design attributes that look and feel democratic, but they will be authoritarian to the core.”\n\nAn anonymous respondent commented, “The degree of tracking of comments by individuals will increase dramatically in the future as DeepMind-style algorithms are applied to internet-based material. It will become much harder for people to make comments without knowing that their attitudes are being logged and accumulated by organisations of all manner, so there will be a reluctance to speak one’s mind. Hence ‘free speech’ will be constrained and thus the democratic process hindered.”\n\nA distinguished professor of electrical engineering and computer science who is an expert in the future of communications networks at a U.S. university wrote, “Social media makes it possible to reach voters in targeted ways and deliver information from a distance that is tailored to specific goals, rather than fostering local community discussion and participation. The lack of privacy in internet service platforms, along with artificial intelligence and big data, now make it possible for candidates to identify and influence voters in ways that could not have been imagined only a few years ago. Without corrective action (such as new election rules limiting the use of private citizen information), these new capabilities could lead to increased political instability and possibly the breakdown of entire democratic systems. The U.S. appears to be the first such casualty in the Western world.”\n\nSam Adams, a 24-year veteran of IBM now working as a senior research scientist in artificial intelligence for RTI International, architecting national-scale knowledge graphs for global good, said, “The internet provides a global megaphone to everyone in that anyone can publish their opinions and views instantly and essentially for free. The problem with everyone having a megaphone is that we get drowned in more noise than useful information. This is even more problematic since interest groups from all sides have used their power and resources to amplify their own voices far above the average citizen, even to the point of effectively silencing the average citizen by burying their smaller voice under a landslide of blaring voices controlled by wealthy interest groups. Given the interest-driven news cycles and echo chambers of social media, only the loudest or most extreme voices get repeated. This further exacerbates the level of emotion in the public discussion and drives listeners to the extremes instead of more common ground. A democracy must fairly represent its people’s views if it is to succeed. And part of that fairness in this technology-dominant world must include balancing the volume of the voices.”\n\nPhilip Rhoades, a business futurist and consultant based in Australia, wrote, “The neoliberal, developed Western world is sliding into fascism as the world’s sixth mass extinction reaches its inevitable conclusion. As this ecological collapse and political regression proceeds, modern technology will mostly be used for suppression of the great majority of people/citizens. Some technology may help defend the populations against state suppression and terror, but its effectiveness will be minor in the greater scheme of things.”\n\nDavid Noelle, professor and researcher into computational cognitive neuroscience, University of California-Merced, wrote, “In the U.S., policy and public opinion have been increasingly shaped so as to support powered interests rather than the interests of the people. Regulation is dismissed as a threat to our troubled economy, encouraging corporate powers to pursue dangerous short-sighted strategies for producing return for investors. The unrepresented have been all but muted by electoral processes designed to sustain those in power. The most influential technologies of our times have been designed to depend on large centralized infrastructure. Data drives many new innovations, and few are in a position to collect and aggregate extensive data on the people. The focus on technologies that depend on controllable infrastructure, whether privately held or manipulated by political powers, will strengthen the positions of those currently in power, increasingly limiting the ability of the people to demand democratic representation. Note that this opinion is not intended as a call to limit technology but as a cry to radically alter political and economic institutions so as to provide representation to all of the people. A more democratic system will produce more democratic technologies.”\n\nDeirdre Williams, an independent internet activist based in the Caribbean, commented, “We are being taught that convenience is the most important priority. ‘Innovation’ is killing ingenuity. I would expect that over the next 10 years the pendulum will swing in the opposite direction, but it will take a while to repair the divide that has been (deliberately?) introduced between citizen and government, and to remind governments of their duty of care to all of the citizens.”\n\nGiacomo Mazzone, head of institutional relations, European Broadcasting Union and Eurovision, wrote, “I don’t believe that internet platforms will be able to self-reform, despite all announcements and efforts shown. And so only a break-up solution or ‘publicization’ of the internet giants could change the future. The amount of power that has been transferred by citizens and by states to these actors that are not accountable to anybody (even to the U.S. government) is too big to think that they could renounce voluntarily. Do you remember ‘Sliding Doors’ – the 1998 movie with Gwyneth Paltrow as leading actor? The future could (in a 50/50 chance) go totally wrong or fantastically well. A digital interconnected society based on trust and respect of individual and human rights could be the next arcadia. A digital interconnected and mass-surveillance-oriented society based on exploitation of human weakness and on polarization of society could be the perfect implementation of the Orwell dystopia of ‘1984.’ The two futures are equally possible. It’s up to government and civil society to decide in which direction we shall go.”\n\nScott B. MacDonald, an experienced chief economist and international economic adviser, said, “The future has a very real potential to be a dark Orwellian place, transfixed between strong technology under the control of a few wealthy and powerful and the great unwashed masses made economically redundant by machines and waiting for their daily dose of Soylent Green. One big change is that people may no longer have to go and vote but vote from hand-held or implanted communications devices. If we are not careful technology will be a device for greater control, not democracy, much as in China. Facial recognition anyone?”\n\nEstee Beck, author of “A Theory of Persuasive Computer Algorithms for Rhetorical Code Studies,” commented, “Unless Congress takes action and passes protective consumer legislation to limit private industry powers with technological growth, i.e., surveillance and privacy erosion, democratic institutions will face greater dangers from domestic and foreign threats, loss of trust among the American public and devaluation of private technological companies among the marketplace. The infrastructure of technology, with faulty programming that allows for penetration and deep hacks, the decisions made now with select leaders in technology companies driving pro-China surveillance growth, anti-U.S. and Mexico relations via border surveillance, marketing of biosecurity technologies and the eventual promotion of artificial intelligence consumer goods and services will divide the faith of the nation and leave the American public ill-trusting of Congress to take action for the public good.”\n\nMatt Colborn, a freelance writer and futurist based in Europe, said, “I do not deny the potential for technology to strengthen or even revolutionise democracy. In fact, this is what I hoped for at the beginning of the revolution in the 1990s. However, from a citizen perspective, the new technology seems to me to have already reduced mental autonomy and the capacity for intelligent choice. Why? 1) Platforms like YouTube seem to be more appropriate for distributing propaganda and for involuntary brainwashing because of the algorithms used. 2) Extreme tribalism has also increased because of the ‘echo chamber’ nature of personalised media. 3) Government and corporations are demolishing any kind of privacy. Neurotech, where thoughts are read, is the ‘final frontier’ of this. The problem, too, is the toxic interaction between archaic authoritarian institutions, right-wing populism and new tech. These effects mean that democracy is diluted whilst a ‘surveillance’ state is strengthened and while deep tribal divisions are exacerbated. Although there are certainly counter movements to this, economic inequality is such that basically the rich and powerful are in a position to cash in on these developments and the rest of us are not. Those who want political innovation will find it tough in this environment.”\n\nDemocratic regimes could become less democratic from the misuse of surveillance systems with the justification of national security. Anonymous respondent\n\nAn artificial intelligence expert predicted, “‘Democracy’ is likely to be even more of an elitist endeavor by 2030 than it is now. Life is good if you’re a big corporation, but not if you’re an ordinary working-class citizen. Who has a voice in this world will depend even more on money and power. Civic technologists will first promise to save democracy with technology but then start charging for it after five years because ‘someone has to pay for maintenance.’ And they will get away with it, because no one will remember that political rights are a basic right and not a commodity.”\n\nAn anonymous respondent wrote, “Recently Hong Kong protesters had to buy single-trip transit cards with cash to be able to exercise democratic power; this will be impossible when mass face-recognition technology is implemented. Essentially, it is becoming almost impossible to behave democratically.”\n\nAnonymous respondents commented:\n\n“Technology is going to aggregate people’s individual voices and remove individual democracy.”\n\n“Democratic regimes could become less democratic from the misuse of surveillance systems with the justification of national security.”\n\n“I am sadly confident that democratic institutions will not be affected in any positive way in future by citizen’s perspectives; instead, technology will continue to create disenfranchised, disempowered citizens.”\n\nExploiting digital illiteracy: Citizens’ lack of digital fluency and their apathy produce an ill-informed and/or dispassionate public, weakening democracy and the fabric of society\n\nJames S. O’Rourke IV, a University of Notre Dame professor whose research specialty is reputation management, said, “As Neil Postman wrote in 1985, ‘We no longer engage in civil public discourse. We are simply amusing ourselves to death.’ Among the more insidious effects of digital life has been a reduction in tolerance for long-form text. People, particularly the young, will read, but not if it involves more than a few paragraphs. Few among them will buy and read a book. News sites have discovered that more people will click on the video than scroll through the text of a story. Given how easy it now is to manipulate digital video images, given how easy it is to play to people’s preconceptions and prejudice, and given how indolent most in our society have become in seeking out news, opinion and analysis, those who seek to deceive, distract or bully now have the upper hand. Jesuits have long cautioned that ‘No man can understand his own argument until he has visited the position of a man who disagrees.’ Such visits are increasingly rare. The long-predicted ‘filter bubble’ effect is increasingly visible. People will simply not seek out, read or take time to understand positions they do not understand or do not agree with. A sizeable majority now live with a thin collection of facts, distorted information and an insufficient cognitive base from which to make a thoughtful decision. Accurate information is no longer driving out false ideas, propaganda, innuendo or deceit.”\n\nBernie Hogan, senior research fellow, Oxford Internet Institute, said, “Technology without civics is capitalism with crystallised logic and unbounded scope. Democratic institutions and civic societies are premised on boundaries and intelligible scales, like the ‘local paper’ or the ‘provincial radio.’ Technology is allowing for the transcendence of scale, which we might think is great. Certainly, from a logistics and delivery side it is very impressive. But social cohesion requires levels of understanding that there’s a coherent bounded population to care about and define one’s identity through and against. It requires people seeing and doing things as more than consumers and occasional partisan voters.”\n\nPeople don’t know what to believe, so they often choose either to believe nothing or to believe whatever their gut tells them. Research scientist\n\nLarry Rosen, a professor emeritus of psychology at California State University-Dominguez Hills, known as an international expert on the psychology of technology, wrote, “I worry that many in the public will and do not have the skills to determine truth from fiction, and twisted truth can and does lead to misunderstanding the content.”\n\nCarolyn Heinrich, professor of education and public policy at Vanderbilt University, said, “As internet content is increasingly customized for us by who we know and where we click, the range of information and perspectives we are exposed to will narrow unless we make the effort to read more widely ourselves. To minimize the negative effects, we have to proactively make the effort to broaden our circles of communication and sources of information/knowledge. As technology increasingly pervades our K-12 school curricula, we also need to examine exactly what technology vendors are conveying in their content, and who is the ‘face’ of that content in instructional videos. That is something we are currently investigating in our research.”\n\nCliff Zukin, professor of public policy and political science, Rutgers University, responded, “In the U.S. anyway, increasing political apathy has accompanied increasing use of technology. It has, on the one hand, been diversional from attention to matters of governance and citizenship. On the other, the centrifugal forces of interests made more available by increasing technology has eroded the core knowledge base of citizens, as well as the norms of citizenship. It does allow for mass movements to organize more quickly and put pressure on leaders, but the right-wing, post-recession populism and withdrawal from globalism is not, in my judgment, a good thing.”\n\nAn anonymous respondent said, “Unfortunately, fundamentally undemocratic processes in the United States, like the electoral college, will continue to be undermined by fake news and technology-backed manipulation of rural states, which have outsized electoral college voting power but typically lack education and will likely remain vulnerable to such exploits.”\n\nA fellow at a major university’s center for internet and society wrote, “I am worried that the ease with which hostile powers and trolls can manipulate public opinion will only increase and become more sophisticated, leading to voters having increasingly lower levels of factual information at their disposal or, worse yet, increasing apathy toward or cynicism about voting and the democratic process entirely.”\n\nEric Royer, assistant professor of political science, Saint Louis University, said, “The breakdown of norms creates an environment of false truths that is directly tied to political polarization, especially among the fringes, and citizen mistrust and apathy with anything ‘government.’ Technology, especially in social media platforms, holds unlimited potential to make the world less of an unfamiliar place, however, its manipulation and influence in our daily lives is truly misunderstood at the current expense of democratic processes and institutions globally and domestically.”\n\nA research scientist focused on fairness, transparency and accountability in artificial intelligence said, “The rise of fake news and manipulated media like deepfakes has sown a greater distrust of media and institutions that is undermining democracy, leading to a less-informed and less civically engaged population. People don’t know what to believe, so they often choose either to believe nothing or to believe whatever their gut tells them. Moreover, foreign actors that use social media manipulation tactics to sway elections further undermine democracy’s legitimacy.”\n\nContinuous media weakens people’s ability to seek information and form their own opinion. Gretchen Steenstra\n\nMark Andrejevic, associate professor of communications, University of Iowa, wrote, “Much of my career has been built around my profound concerns about the impact that technology is having on democratic processes of deliberation, public accountability and representation. This is because technology needs to be understood within the context of the social relations within which it is deployed, and these have been conducive to privileging an abstract consumerist individualism that suppresses the underlying commitment to a sense of common, shared or overlapping interests necessary to participation in democratic society. I see the forms of hyper-customization and targeting that characterize our contemporary information environment (and our devices and mode of information ‘consumption’) as fitting within a broader pattern of the systematic dismantling of social and political institutions (including public education, labor unions and social services) that build upon and help reproduce an understanding of interdependence that make the individual freedoms we treasure possible. Like many, I share concerns about rising political polarization and the way this feeds upon the weaponization of false and misleading information via automated curation systems that privilege commercial over civic imperatives. These trends predate the rise of social media and would not have the purchase they do without the underlying forms of social and civic de-skilling that result from the offloading of inherently social functions and practices onto automated systems in ways that allow us to suppress and misrecognize underlying forms of interdependence, commonality and public good. I am not optimistic that anything short of a social/political/economic disaster will divert our course.”\n\nCarlos Afonso, an internet pioneer and digital rights leader based in Rio de Janeiro, Brazil, wrote, “Thinking here of a planet with 7 billion-plus persons, most of them (including many of the supposedly ‘connected’) are unable to discern the many aspects of disinformation that reaches them through traditional (entrepreneurial) media, social networking apps and local political influences.”\n\nA longtime CEO and internet and telecommunications expert commented, “Citizens will increasingly act absent of any understanding of critical analysis and reasoning, fact-checking or even rule of law. Under the guise of ‘acting out against injustice’ we will continue to see cyber vigilantism, whereby social media firestorms effectively ‘try and convict’ anyone accused of word or deed not supportive of their values.”\n\nGretchen Steenstra, a technology consultant for associations and nonprofit organizations, wrote, “I am concerned about higher velocity of information that does not include all critical and supporting information. Data is used to inform one view without context. Consumers do not fact-check (on many issues regardless of party). Americans are not focused on social responsibility or downstream impacts – they only want instant results. Continuous media weakens people’s ability to seek information and form their own opinion. Constant connectedness prevents reflection and allows your brain to relax. No one can argue with the desire for understanding.”\n\nA fellow at a think tank’s center for technology and innovation wrote, “Democracy will be driven by more artificial intelligence systems, which will automate a range of decisions. Consequently, individuals may have limited input into their own decisions because data will be extrapolated from machines. What this will mean is a looser connection to democratic processes or connections driven by what one sees, hears and senses through dominant platforms. Without some level of policy restraint when it comes to specific use cases, such as voting, technology may serve to erode public trust, while simultaneously relying less on actual public input due to the level of sophistication that emerging technologies offer.”\n\nAyden Férdeline, technology policy fellow, Mozilla Foundation, responded, “Technology will continue to be exploited by those who seek to increase political apathy and undermine our trust in established institutions. This may happen more subtly than in the past, but the corrosive effect on democracy will be just the same.”\n\nThe internet amplifies trends that have been with us for a while – extremism and apathy. Pamela McCorduck\n\nPhilip J. Salem, professor emeritus, Texas State University, expert in complexity of organizational change, said, “People will become increasingly more careful about how they use the internet. Each person must be more mindful of use. My concern is that reflexive, non-mindful reactions can spread so fast and have more tragic consequences with the speed of the internet.”\n\nJeff Johnson, a professor of computer science, University of San Francisco, who previously worked at Xerox, HP Labs and Sun Microsystems, said, “Today’s social media encourages the spread of unverified information, which can skew policymaking and elections. People tend to be lazy and do not even read most of the articles they comment on, much less check the truth of the articles. In the TV era, before social media, putting out false information about a political opponent or ballot measure was expensive and subject to laws against ‘false advertising.’ Political hit pieces had to be well-funded, vaguely worded and carefully timed (to just before the election) in order to sway elections. That is no longer true. Strong regulation of social media could perhaps mitigate this, but such regulation seems unlikely in the foreseeable future.”\n\nPamela McCorduck, writer, consultant and author of several books, including “Machines Who Think,” said, “I am not sanguine about democracy right now. The internet amplifies trends that have been with us for a while – extremism and apathy. Our proportion of potential voters who actually vote only rose once or twice in the past few elections. Mostly it is dismal. Partly this is a result of voter suppression (not just removing voters from the rolls, but also making the process of voting far more cumbersome than it needs to be). Partly this is the realization by voters that elected officials are more beholden to dark money than to the people who elected them. I hope I am wrong about the future of this country I love.”\n\nLuis German Rodriguez, researcher and consultant on knowledge society and sociotechnical impact based at Universidad Central de Venezuela, commented, “Democracy is likely to be weakened by 2030. … Authoritarian rule seems to be growing stronger wherever you look, supported by the emerging technologies.”\n\nAnonymous respondents commented:\n\n“People will not use the internet to research the issue, rather, they will simply go with whatever biased opinion is put in front of them.”\n\n“The problem is that with the erosion of critical-thinking skills, true journalism versus opinion journalism (and the prevalence of ‘sound bites’ in lieu of serious debate based on facts) lack of proper policy and governance principles, these tools are being used to spread false information.”\n\n“The public made more gullible by a short attention spans, eroding reasoning skills, becomes a malleable target for those who seek to erode the fundamental institutions of our democracy.”\n\n“I’m less concerned about technology than I am the ability and willingness of my fellow citizens to educate themselves about the sources of information they consult.”\n\n“The biggest threat to democracy is people’s lack of critical-thinking skills to be able to distinguish between information and misinformation.”\n\nWaging info-wars: Technology can be weaponized by anyone, anywhere, anytime to target vulnerable populations and engineer elections\n\nRichard Bennett, founder of the High-Tech Forum and ethernet and Wi-Fi standards co-creator, wrote, “The economic model of social media platforms makes it inevitable that these tools will do more harm than good. As long as spreading outrage and false information generates more profits than dealing in facts, reason, science and evidence, the bad guys will continue to win. Until we devise a model where doing the right thing is more profitable than exploiting the public’s ignorance, the good guys will keep losing. … One hypothetical change that I would like to see would be the emergence of social media platforms that moderate less for tone and emotion and more for adherence to standards of truthfulness and evidence. Making this approach succeed financially is the major obstacle.”\n\nMutale Nkonde, adviser on artificial intelligence at Data & Society and fellow at Harvard’s Berkman Klein Center for Internet and Society, wrote, “Without significant regulation, our future elections will be ruled by the parties that can optimize social media recommendation algorithms most effectively. In the present moment, those are parties like Cambridge Analytica who used fear, racism and xenophobia to influence elections across the world.”\n\nEduardo Villanueva-Mansilla, associate professor of communications at Pontificia Universidad Catolica, Peru, and editor of the Journal of Community Informatics, said, “The lack of agreement about how to deal with these issues among governments is a serious threat to democracy, as much as the potential for misuse of technological innovations. In the next decade, the complete control by a few multinational firms will be completely outside of regulatory and policy reach of developing countries’ governments. This will increase the instability that has been normalized as a feature of governance in these countries.”\n\nThis is not like armed revolution; this is small numbers of employees able to affect what thousands, if not millions, see. Rich Salz\n\nAn expert in the ethics of autonomous systems based in Europe said, “Digital devices provide more and more new means to enhance the power of leaders to control people and to manipulate an inferior substitute for democracy to their benefit. They simulate and broadcast false flavours of democratic representations to the population. Decisions that restrict people’s rights, autonomy and freedom are promoted as necessary for enhancing the security, care and well-being of the population, while in fact the purpose is to protect the interests of those who seek power and influence. New digital means (biometrics, facial recognition, big data, deep learning, artificial intelligence) allow those in power to recognize and to profile people (position, behavior, location, ways of thinking, ideas, political opinions, level of life, health, origins, money, social relationships and so on). Stakeholders can use these devices to make appropriate decisions concerning what they consider subversive people and moreover to fight them if necessary. Robots and autonomous AI systems will be very efficient slaves to help to educate people who will not fit the requirements and rules imposed by the dominant class. This model will be developed in more and more states in the world and will progressively narrow freedom and decrease the quality of life of ordinary people belonging to medium and low social classes. At the same time, the field of available jobs will be more and more narrow because AI and robots will replace human beings in most areas and lead the majority of people to be unable to find means to work to support and fulfill themselves.”\n\nLarry Masinter, internet pioneer, formerly with Adobe, ATT Labs, Xerox PARC, who helped create internet and web standards with IETF and W3C, said, “Traditional democracy and democratic institutions rely on geographically defined boundaries for constituencies. Enabling technology will accelerate the rise of cross-jurisdictional malfeasance, whether it’s called collusion or something else.”\n\nAn anonymous respondent warned, “Authoritarians will weaken checks and balances, turn courts into extensions of those in power and thus undermine representative democracy – enabled by the manipulation of digital media to stoke fear and mask inconvenient truths. … Extreme partisanship is putting all of our democratic institutions at risk to the point that shared power and orderly transitions may not exist in 10 years. Civil unrest seems inevitable.”\n\nRich Salz, senior architect, Akamai Technologies, wrote, “Individual citizens cannot stand up to the organized ‘power’ of other countries. This is not like armed revolution; this is small numbers of employees able to affect what thousands, if not millions, see.”\n\nHeywood Sloane, entrepreneur and banking and securities consultant, said, “The current U.S. administration is leading the way to misuse technology. It permeates the public air with disinformation and lies, while putting a heavy hand on the scale in the background. It welcomes trolls to conferences in the White House and encourages them. Even if the administration changes it will take time and work to undo the damage. Media technology corporations have lost control of their platforms and marketing staffs – witness Facebook and Cambridge Analytica. Already we have rogue state sponsors altering our dialogues, yet we ignore them and chortle away with their leaders.”\n\nAn associate dean of research for science and engineering said, “Over the next 10 years, we will see an increase in the current trend of using technology to further engineer elections (including gerrymandering) and to target those most vulnerable to manipulation (on all political sides). A result is overrepresentation in elected government of self-interested minority points of view (extremes on many sides), increased obstacles to ousting parties from power (especially in two-party systems like the U.S.), and, for a while at least, the continued divisiveness of political discourse.”\n\nA consultant who works for U.S. government agencies said, “The biggest fear of technology will be the use of artificial intelligence. While at present we have control of AI, in time we will lose that control. As systems are augmented with AI, it will remove the human element over time. We can say what we like about technology and our control of technology, but in time external forces will replace the human element. This will happen in all areas of technology, including the governmental technology world. At some point it will go beyond its own programing doing what it believes is in our best interest.”\n\nSowing confusion: Tech-borne reality distortion is crushing the already-shaky public trust in the institutions of democracy\n\nThe leader of a technology innovation group at one of the world’s top five technology organizations wrote, “Technology has already and will continue to place huge strains on democracy. First, digital technology makes it immensely easy for a small number of leveraged actors to exercise great control over our public discourse. We see this as they exercise control over the information made available and presented to citizens. Second, digital technology makes it immensely easy for actors to hide or obscure their involvement and their intent. Third, digital technology makes it immensely easy to erode truth through fabrications or amplifications.”\n\nHate, polarization, oversimplification and lack of well-considered thought are and will be on the increase. Alejandro Pisanty\n\nNigel Cameron, president emeritus, Center for Policy on Emerging Technologies, said, “I fear deepening distortions in public perception by the leveraging of digital media on the part of governments (our own and foreign), tech corporations and other actors – as new technologies like fake video make it even easier to shape opinion. It will be some time before (assuming it happens) we have the will and the tech to rein in these abuses. As things stand, partisanship by politicians and the ‘sorry, not sorry’ approach of Mark Zuckerberg and the other tech leaders portend deepening problems.”\n\n[Technology]\n\nAlejandro Pisanty, professor at UNAM, the National University of Mexico, and an activist in multistakeholder internet governance, wrote, “Hate, polarization, oversimplification and lack of well-considered thought are and will be on the increase. They are orders of magnitude easier to construct and propagate than the ways of countering them (the ‘bullshit asymmetry’ principle, on steroids). Manipulation of elections and other processes will continue to be rife as long as there exist those who want to do it and those susceptible to manipulation. Among the hardest hit will be the U.S., which has a gullible population unable to see the meta-layers of attack they are subjected to. There is hope for improvement in a smaller, smarter, more-democratic sector of society fighting the acritical reactions of the naive and uneducated. Better information, resilient systems (by design) and deliberations nested at all levels from the ultra-local to the global, an architecture of multistakeholder deliberations and decisions, and a lot of luck, may lead to improvement. Otherwise splintering and other forms of dark days loom.”\n\nRich Ling, professor, Nanyang Technological University, Singapore; expert on the social consequences of mobile communication, said, “The forces that want to confuse/undercut legitimate information are learning how to best use these systems. They are also learning how to calibrate the messages they send so as to enhance their divisiveness. This division plays on confirmation bias and, in turn, undercuts the common ground that is needed for effective governing and democracy.”\n\nKarl Auerbach, chief technology officer, InterWorking Labs, active in internet design since the early 1970s, had less faith in multistakeholder organizations, writing, “Democracy is dying at the hands of a concept called ‘stakeholder.’ This has little to do with technology except that people are being led to believe that they are not skilled enough or smart enough to decide for themselves, that technological experts ought to decide on their behalf. We are moving toward not improved democracy (direct or indirect) but closer to an oligarchy of ‘stakeholders.’”\n\nGlyn Moody, a prolific technology journalist, blogger and speaker based in Europe, said, “Lies propagate more easily than truth. It is proving far easier to use the latest technology to undermine the things we thought were safe and stable. It is proving very hard to counter that abuse of technology.”\n\nA computing science professor emeritus from a top U.S. technological university wrote, “As artificial intelligence technologies are employed to create ever-more-realistic disinformation videos and as multiplication of software AI disinformation bots can be replicated and spread easily by individuals or small groups, more and more people will be fooled by disinformation, thus weakening our democracy.”\n\nA professor of sociology at a major California university said, “Powerful governments and their allies are using technology to destroy the concept of a single, accepted truth. While not always succeeding in implanting particular beliefs in the minds of citizens and residents, the constant assault on truth leads to fatigue and resignation, that the actual truth cannot be known, or that all political actors are equally bad. This resignation, moving into apathy, allows those in power to behave badly and centralize their power. The wild card is whether new technologies can detect bots and fake video/audio, and whether mainstream media and social media companies behave responsibly to bring an accepted truth back to life.” Alan Honick, project director for PROSOCIAL, said, “My work is focused on the need to make the internet and associated information technologies trustworthy and reliable. … The most important variable for the question at hand is whether or not information technology can move in the direction of becoming a trusted and reliable source of information, and at present the trend seems to indicate not.”\n\nAnnemarie Bridy, professor of law specializing in the impact of new technologies on existing legal frameworks, said, “Social media platforms have a steep hill to climb over the coming years when it comes to dealing effectively with disinformation and coordinated inauthentic behavior aimed at manipulating voters and electoral outcomes. Viral disinformation online will continue to be a serious threat to democratic institutions and the integrity of elections.”\n\nGarth Graham, a longtime leader of Telecommunities Canada, said, “The digital age is characterised by a disintermediation of authority. Authority as a principle for structural organization is disappearing. Democracy is predicated by the agreement to accept authority to represent. Most people are no longer willing to accept that anyone else can represent them.”\n\nStephanie Fierman, partner, Futureproof Strategies, said, “Many parties have an incentive to issue false and damaging statements and content that people believe. Until we return to a world in which a fact is a fact is a fact, we will see a continuing degradation of truth and the existence of checks and balances, both of which being so vital to the presence of democracy.”\n\nStuart Umpleby, retired professor of management and director of research at George Washington University, commented, “The operators of social media platforms, such as Facebook, need to take responsibility for content. Otherwise they benefit by distributing falsehoods.”\n\nViral disinformation online will continue to be a serious threat to democratic institutions and the integrity of elections. Annemarie Bridy\n\nSatish Babu, founding director of the International Centre for Free and Open Source Software, said, “If the world does not recognize the pitfalls and take corrective action, technology is likely to adversely impact the quality and practice of democracy. In particular, the pragmatics of democracy will deteriorate into an ‘anything goes,’ free-for-all fight where artificial intelligence will be used to dig up or magnify or even create antecedents of candidates from historical records and social media will be used to push such ‘facts’ to every citizen.”\n\nA professor of sociology and public policy wrote, “Bot armies and databases of persuadable people that include information on what sets them off empower the worst nationalistic and international actors to tear down democracies. Via technology, people can enter alternate realities where others reinforce their fantasies and strengthen them – flat earthers, those who believe in vaccine and climate conspiracies, moon landing hoaxers and so forth. These are problematic in their own right, but also lend themselves to further manipulation, destruction of trust in institutions, scapegoat seeking, and the rejection of science.”\n\nFilippo Menczer, a grantee in the Knight Foundation’s Democracy Project and professor of informatics and computer science at Indiana University, said, “Technology … mediates our access to information and opinions. This will in part strengthen democracy, for example making it easier to check facts. It will also weaken democracy, as vulnerabilities due to the interplay of cognitive, social and algorithmic biases continue to be exploited and new ones are discovered. On balance, my prediction is that things will get worse before they get better. We are only just beginning discussions about the legal implications of countermeasures, for example the issues related to social bots, disinformation campaigns, suppression of speech and the First Amendment in the U.S.”\n\nNancy Heltman, manager of a state agency based in the U.S., wrote, “The negative aspects of bots and influencers driving opinions are likely to outweigh the positive aspects of increasing involvement in the political process.”\n\nDavid Gans, musician, songwriter and journalist, said, “I fear that deliberate falsehoods will continue to crowd objective reality out of the discourse. The social networks seem neither able nor particularly willing to intervene on behalf of the truth, and there are powerful and well-funded entities with a strong interest in misinforming the public.”\n\nA research leader for a U.S. federal agency said, “Working to be respectful of First Amendment rights while not allowing the perpetuation of mis- or disinformation is of critical concern. I don’t expect that to be resolved within the next 10 years. We are living in the times of 50 shades of gray. In many cases, the determination is not black and white. The headline may be misleading, but not entirely untrue. I think that’s appealing to the media right now.”\n\nKenneth R. Fleischmann, associate professor at the School of Information at the University of Texas-Austin, wrote, “Technology will have complex effects on society that will be difficult to predict, that depend on the decisions of tech companies, governments, the press and citizens. … Trust will be key, not just blind trust, but trust based on transparent provenance of information that can help users exercise their autonomy and agency.”\n\nAnonymous respondents commented:\n\n“Technology will weaken our ability to come to consensus; by nurturing smaller communities and fringe ideas, it will make compromise and finding a modus vivendi much more difficult.”\n\n“Social media will continue to erode faith in facts and reason; echo chambers and emotion-driven communications plus security problems in voting will undermine public discourse and faith in elections.”\n\n“There seems to be no realistic way to check the effects of IT on polarization and misinformation. The true beliefs and actions of political leaders will continue to have decreasing influence on voting.”\n\n“Foreign countries and hate groups will grow more sophisticated in their ability to infiltrate the web with biased stories and ads designed to suppress or sway voters and negatively impact public opinion.”\n\n“While it enables voices to be heard, tech has already weakened democracy by enabling governments and corporations to erode privacy and silence those who might otherwise speak out.”\n\n“We don’t need mass armies anymore. New technology enables centralized control to a degree never imagined before.”\n\n“In 2030, there will still be splintering and increased political polarization as individuals are able to challenge democratic ideals and influence political processes through anonymous activities.”\n\n“Democracy is, and will always be, filled with fake news and preposterous bloviation.”\n\nWeakening journalism: There seems to be no solution for problems caused by the rise of social media-abetted tribalism and the decline of trusted, independent journalism\n\nChristopher Mondini, vice president of business engagement for ICANN, commented, “The decline of independent journalism and critical thinking and research skills resulting from easy reliance on the internet make citizens more susceptible to manipulation and demagoguery. A growing proportion of politically active citizens are digital natives with no recollection of life before social media became the primary medium for debate and influence. The pursuit of clicks, retweets and page views encourages extremist or provocative rhetoric. Viral memes and soundbites distract from thoughtful analysis, deliberation and debate. Of course, the vast majority of citizens are not politically active, but they increasingly consume news and adopt a worldview shaped by their online communities. Participation in political processes may rise because of newly inflamed passions brought about by online discourse, but they may crowd out more measured voices.”\n\nYaakov J. Stein, CTO, RAD Data Communications, based in Israel, responded, “Social media as they are at present have a polarizing effect that destabilizes democracy. The reason is that advertising (and disinformation) is targeted at and tailored to people according to their preexisting views (as predicted based on their social media behavior). This strengthens these preexisting views, reinforces disparagement of those with opposing views and weakens the possibility of being exposed to opposing views. The result is that free press no longer encourages democracy by enabling people to select from a marketplace of ideas. Instead the right to free press is being used to protect the distribution of disinformation and being manipulated to ensure that people are not exposed to the full spectrum of viewpoints. Perhaps an even more insidious result is that people attempting to keep open minds can no longer trust information being offered online, but that free information online has led to the bankruptcy of traditional news outlets that spend resources on fact-checking.”\n\nThe decline of independent journalism and critical thinking and research skills resulting from easy reliance on the internet make citizens more susceptible to manipulation and demagoguery. Christopher Mondini\n\nRey Junco, director of research at CIRCLE in the Tisch College of Civic Life, Tufts University, said, “We can expect that attempts to influence public perceptions of candidates and elections are not only ongoing, but that they will continue to be successful. Technology use by citizens, civil society and governments will first weaken core aspects of democracy and democratic representation before there is a restructuring of technological systems and processes that will then help strengthen core aspects of democracy. There are two issues at play: 1) Ideological self-sorting in online spaces that is bolstered by algorithmic polarization and 2) The relative unwillingness of technology companies to address misinformation on their platforms. Individuals who get their news online (a larger proportion who are young – Pew Research) choose media outlets that are ideologically similar and rarely read news from the opposing side (Flaxman, Goel, & Rao, 2018). In fact, these individuals are rarely exposed to moderate viewpoints (Flaxman, Goel, & Rao, 2018). Social media, in turn, allow for not just informational self-sorting as with online news, but such self-sorting is bolstered through algorithmic curation of feeds that promotes ideological separation. … Although major technology companies are aware of how misinformation was promoted and propagated through their networks during the 2016 elections and resultant congressional hearings on the topic, little has been done to mitigate the impact of such deliberate spreading of misinformation. Analyses from the security and intelligence communities show that state actors continue their attempts to manipulate public sentiment in social spaces, while the increased polarization of traditional outlets has minimized the impact of these reports. State actors are emboldened by the fact that the United States has not addressed the spread of misinformation through technological change or through public education.”\n\nAn associate professor of computer science who previously worked with Microsoft, said, “I worry about three related trends: 1) the increasing decentralization of news generation, 2) the lack of easy-to-use, citizen-facing mechanisms for determining the validity of digital media objects like videos and 3) personalization ecosystems that increase the tendency toward confirmation bias and intellectual narrowing. All three trends decrease the number of informed voters and increase social division. Governments will eventually become less averse to regulating platforms for news generation and news dissemination, but a key challenge for the government will be attracting top tech talent; currently, that talent is mostly lured to industry due to higher salaries and the perception of more interesting work. Increasing the number of technologists in government (both as civil servants and as politicians) is crucial for enabling the government to proactively address the negative societal impacts of technology.”\n\nKenneth Sherrill, professor emeritus of political science, Hunter College, said, “When I’m pessimistic, I believe that the fragmentation of information sources will interact with selective attention – the tendency only to follow news sources that one expects to agree with. This will generate even greater polarization without any of the moderating effects and respect for democratic processes that come from genuine participation. This can lead to the collapse of democratic processes. Right now, I’m pessimistic. The 2020 election may be the test.”\n\nEric Keller, lecturer in international relations and U.S. foreign policy, University of Tennessee-Knoxville, wrote, “Social media will heighten the current strong polarization that we already have. This is mainly from ‘information stovepipes’ and mutually reinforcing narratives that demonize the opposition. This creates the danger of democratic institutions being degraded in the name of ‘saving’ them from the opposing political party.”\n\nA Europe-based internet governance advocate and activist said, “If current trends continue, there won’t be a real democracy in most countries by 2030. The internet’s funding model based on targeted advertising is destroying investigative journalism and serious reporting. More and more of what is published is fake news. Citizens cannot make informed decisions in the absence of reliable information.”\n\nThe coordinator of a public-good program in Bulgaria wrote, “By 2030 we will still see fighting between small groups and communities that leads to extremes. This will give ground to governments to become more authoritative and build up even stronger control via the internet.”\n\nBill D. Herman, researcher working at the intersection of human rights and technology said, “The combination of news fragmentation, systematic disinformation and motivated reasoning will continue to spiral outward. We’re headed for a civil war, and the hydra-headed right-wing hate machine is the root of the problem.”\n\nAn internet pioneer and technology developer and administrator said, “The foundation of democracy is an informed public. By undermining the economic foundation of journalism and enabling the distribution of disinformation on a mass scale, social media has unleashed an unprecedented assault on the foundation of democracy. The decline of newspapers, to just highlight one downside, has had a quantifiable effect (as measured in bond prices) on governmental oversight and investor trust.”\n\nA professor and expert in learning in 3D environments said, “The explosion in the volume of information has led to the majority of people tending to rely on or trust the major platforms to filter and distribute information rather than managing their own personal learning environments with feeds from trusted independent sources. … As the filtering mechanisms become more sophisticated and more personalized to the individual, the opportunities for the wealthy to manipulate opinion will become even greater. The democratic system depends fundamentally on free access to reliable information, and once this is gone the system will effectively become less and less democratic.”\n\nMike Douglass, an independent developer, wrote, “Facebook sold people on the idea that a race to accumulate ‘friends’ was a good thing – then people paid attention to what those ‘friends’ said. As we now know, many of those ‘friends’ were bots or malicious actors. If we continue in this manner, then things can only get worse. We need to reestablish the real-life approach to gaining friends and acquaintances. Why should we pay any attention to people we don’t know? Unfortunately, technology allows mis/disinformation to spread at an alarming rate.”\n\nEric Goldman, professor and director of the High-Tech Law Institute at the Santa Clara University School of Law, commented, “Our politicians have embraced internet communications as a direct channel to lie to their constituents without the fact-checking of traditional media gatekeepers. So long as technology helps politicians lie without accountability, we have little hope of good governance.”\n\nJanet Salmons, consultant with Vision2Lead, said, “The internet, with unregulated power in the hands of commercial entities that have little sense of social responsibility, will continue to unravel Western-style democracies and civic institutions. Companies profiting from sales of personal data or on risky practices have little self-interest in promoting the kinds of digital and advanced literacy people need to discern between fact and fiction. In the U.S., the free press and educational systems that can potentially illuminate this distinction are under siege. As a result, even when presented with the opportunity to vote or otherwise inveigh on decision-making, they do so from weak and uninformed positions. The lowest common denominator, the mass views based on big data, win.”\n\nA researcher and teacher of digital literacies and technologies said, “In the early internet days, there was a claim it would bring a democratization of power. What we’re seeing now is the powerful having larger and more overwhelming voices, taking up more of the space rather than less. This leads to polarization, rather than a free-flowing exchange of ideas. Anyone falling within the middle of a hot issue is declared a traitor by both sides of that issue and is shamed and/or pushed aside.”\n\nAn anonymous respondent commented, “Increased engagement is largely a product of the media environment, and – in places where the press is absent, restricted or has become blatantly politicized – that engagement will bear the marks of a distorted information environment.”\n\nResponding too slowly: The speed, scope and impact of the technologies of manipulation may be difficult to overcome as the pace of change accelerates\n\nThe core concepts of democracy, representation, elections and tenure of government will be greatly undermined by artificial intelligence. Emmanuel Edet\n\nKathleen M. Carley, director of the Center for Computational Analysis of Social and Organizational Systems at Carnegie Mellon University, said, “Disinformation and deepfakes in social media as well as the ability of individuals and media-propaganda teams to manipulate both who is and can communicate with whom and who and what they are talking about are undermining democratic principles and practice. Technological assistants such as bots, and information tools such as memes, are being used in ways that exploit features of the social media and web platforms, such as their prioritization rules, to get certain actors and information in front of people. Human cognitive biases, and our cognitive tendencies to view the world from a social or group perspective, are exploited by social media-based information maneuvers. The upshot is that traditional methods for recognizing disinformation no longer work. Strategies for mitigating disinformation campaigns as they play out across multiple media are not well understood. Global policies for 1) responding to disinformation and its creators, and 2) technical infrastructure that forces information to carry its provenance and robust scalable tools for detecting that an information campaign is underway, who is conducting it and why do not exist.”\n\nJason Hong, professor of Human-Computer Interaction Institute, Carnegie-Mellon University, said, “Basically, it’s 1) easier for small groups of people to cause lots of damage (e.g., disinformation, deepfakes), and 2) easier for those already in power to use these technologies than those who need to organize. In the early days of the internet, new technologies empowered new voices, which led to a lot of utopian views. However, we’ve seen in recent years that these same technologies are now being used to entrench those already in power. We see this in the form of targeted advertising (being used for highly targeted political campaigns), analytics (being used for gerrymandering), disinformation and fake news (being used both domestically and by foreign powers, both unintentionally and intentionally) and filter bubbles where people can seek out just the information that they want to hear. All of this was possible before the internet, but it was harder because of natural barriers. We also haven’t seen the political effects of deepfakes and are just starting to see the effects of widespread surveillance by police forces.”\n\nMark Raymond, assistant professor of international security, University of Oklahoma, wrote, “Over the next 30 years, democracy faces at least three kinds of technology-based risks. First, actual or apparent manipulation of voting data and systems by state actors will likely undermine trust in democratic processes. Second, social media manipulation (by states and by political campaigns and other nonstate actors) will compound echo chamber effects and increase societal polarization. Decreased trust will heighten social conflict, including, but not limited to, conflict over elections. Third, ‘deepfakes’ will undermine confidence even in video-based media reports. Taken together, there is the risk that these trends could increase the willingness of voters to accept fundamentally authoritarian shifts in their politics. Absent that, it is still likely that increased polarization will make the operation of democratic systems (which are heavily dependent on mutual acceptance of informal norms) incredibly difficult.”\n\nEmmanuel Edet, legal adviser, National Information Technology Development Agency, Nigeria, said, “The core concepts of democracy, representation, elections and tenure of government will be greatly undermined by artificial intelligence. The use of social media coupled with faceless artificial intelligence-driven opinions can manipulate popular opinion that will deny people the right to express their choice for fear of going against the crowd.”\n\nMatt Moore, innovation manager at Disruptor’s Handbook, Sydney, Australia, said, “The issue is not that essential democratic institutions will change, it is that they will not change enough. Elections, voting, representatives, parties – none of these things will go away. They may mean more or less (likely less) than they used to. The number of democracies in the world is likely to decrease as weak or destabilised states fall into authoritarian populism. Western democracies will continue to age and grow more economically unequal. States like China will continue to grow in power, often using new technologies to control their populations. Everyone is talking up the potential of blockchain for democracy. This is mostly nonsense. The issue is not that people do not have the opportunity to vote enough. It is that no one really knows what that vote means. Many of those who vote – or rather, who do not vote – have no sense of what their vote means. Many of those who are voted for, also do not know what that vote means – which is why they rely on polling and focus groups. Deliberative democracy offers a potential new form of political engagement and decision-making – if (and this is a big ‘if’) it can be made to work beyond isolated experiments.”\n\nMike O’Connor, retired, a former member of the ICANN policy development community, said, “There is cause for hope – but it’s such a fragile flower compared to the relative ease with which the negative forces prevail. ‘A lie can get around the world while truth is getting its boots on’ – pick your attribution.”\n\nA longtime technology journalist for a major U.S. news organization commented, “Our laws and Constitution are largely designed for a world that existed before the industrial age, not to mention the information age. These technologies have made the nation-state obsolete and we have not yet grasped the ways they facilitate antidemocratic forces.”\n\nHume Winzar, associate professor and director of the business analytics undergraduate program at Macquarie University, Sydney, Australia, said, “Corporations and government have the information and the technology to create highly targeted messages designed to favour their own agendas. We, as citizens, have"
    }
}