{
    "id": "dbpedia_2146_1",
    "rank": 63,
    "data": {
        "url": "https://dl.acm.org/doi/abs/10.1145/3503161.3548373",
        "read_more_link": "",
        "language": "en",
        "title": "Learning from Label Relationships in Human Affect",
        "top_image": "https://dl.acm.org/cms/asset/07cc948b-4d38-4de2-abe7-c5dcb8d7e1af/3503161.cover.jpg",
        "meta_img": "https://dl.acm.org/cms/asset/07cc948b-4d38-4de2-abe7-c5dcb8d7e1af/3503161.cover.jpg",
        "images": [
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-dl-logo-white-1ecfb82271e5612e8ca12aa1b1737479.png",
            "https://dl.acm.org/doi/abs/10.1145/specs/products/acm/releasedAssets/images/acm-logo-1-ad466e729c8e2a97780337b76715e5cf.png",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/footer-logo1-45ae33115db81394d8bd25be65853b77.png",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/Default_image_lazy-0687af31f0f1c8d4b7a22b686995ab9b.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81100074462&format=rel-imgonly&assetId=adbc.jpg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/loader-7e60691fbe777356dc81ff6d223a82a6.gif",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-logo-dl-8437178134fce530bc785276fc316cbf.png",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-logo-3-10aed79f3a6c95ddb67053b599f029af.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "United Kingdom View Profile",
            "Niki Maria Foteinopoulou",
            "Ioannis Patras"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/pb-assets/head-metadata/apple-touch-icon-1574252172393.png",
        "meta_site_name": "ACM Conferences",
        "canonical_link": "https://dl.acm.org/doi/10.1145/3503161.3548373",
        "text": "Abstract\n\nHuman affect and mental state estimation in an automated manner, face a number of difficulties, including learning from labels with poor or no temporal resolution, learning from few datasets with little data (often due to confidentiality constraints) and, (very) long, in-the-wild videos. For these reasons, deep learning methodologies tend to overfit, that is, arrive at latent representations with poor generalisation performance on the final regression task. To overcome this, in this work, we introduce two complementary contributions. First, we introduce a novel relational loss for multilabel regression and ordinal problems that regularises learning and leads to better generalisation. The proposed loss uses label vector inter-relational information to learn better latent representations by aligning batch label distances to the distances in the latent feature space. Second, we utilise a two-stage attention architecture that estimates a target for each clip by using features from the neighbouring clips as temporal context. We evaluate the proposed methodology on both continuous affect and schizophrenia severity estimation problems, as there are methodological and contextual parallels between the two. Experimental results demonstrate that the proposed methodology outperforms the baselines that are trained using the supervised regression loss, as well as pre-training the network architecture with an unsupervised contrastive loss. In the domain of schizophrenia, the proposed methodology outperforms previous state-of-the-art by a large margin, achieving a PCC of up to 78% performance close to that of human experts (85%) and much higher than previous works (uplift of up to 40%). In the case of affect recognition, we outperform previous vision-based methods in terms of CCC on both the OMG and the AMIGOS datasets. Specifically for AMIGOS, we outperform previous SoTA CCC for both arousal and valence by 9% and 13% respectively, and in the OMG dataset we outperform previous vision works by up to 5% for both arousal and valence.\n\nSupplementary Material\n\nMP4 File (MM22-mmfp2871.mp4)\n\nPresentation video - DL library version\n\nDownload\n\n42.49 MB\n\nReferences\n\n[1]\n\nSamuel Albanie and Andrea Vedaldi. 2016. Learning Grimaces by Watching TV. In BMVC 2016. http://arxiv.org/abs/1610.02255 arXiv: 1610.02255.\n\n[2]\n\nAmerican Psychiatric Association. 2013. Diagnostic and Statistical Manual of Mental Disorders (fifth edition ed.). American Psychiatric Association. https://doi.org/10.1176/appi.books.9780890425596\n\n[3]\n\nPablo Barros, Nikhil Churamani, Egor Lakomkin, Henrique Siqueira, Alexander Sutherland, and Stefan Wermter. 2018. The OMG-Emotion Behavior Dataset. In 2018 International Joint Conference on Neural Networks (IJCNN). 1--7. https://doi.org/10.1109/IJCNN.2018.8489099 ISSN: 2161--4407.\n\n[4]\n\nMina Bishay, Petar Palasek, Stefan Priebe, and Ioannis Patras. 2018. SchiNet: Automatic Estimation of Symptoms of Schizophrenia from Facial Behaviour Analysis. IEEE Transactions on Affective Computing (2018). https://doi.org/10.1109/TAFFC.2019.2907628\n\n[5]\n\nMina Adel Thabet Bishay. 2020. Automatic Facial Expression Analysis in Diagnosis and Treatment of Schizophrenia. Thesis. Queen Mary University of London. https://qmro.qmul.ac.uk/xmlui/handle/123456789/69449 Accepted: 2020-12-18T16:23:10Z.\n\n[6]\n\nAdrian Bulat, Shiyang Cheng, Jing Yang, Andrew Garbett, Enrique Sanchez, and Georgios Tzimiropoulos. 2021. Pre-training strategies and datasets for facial representation learning. arXiv:2103.16554 [cs] (March 2021). http://arxiv.org/abs/2103.16554 arXiv: 2103.16554.\n\n[7]\n\nQiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi, and Andrew Zisserman. 2018. Vggface2: A dataset for recognising faces across pose and age. In 2018 13th IEEE international conference on automatic face & gesture recognition (FG 2018). IEEE, 67--74.\n\n[8]\n\nWheidima Carneiro de Melo, Eric Granger, and Abdenour Hadid. 2020. A Deep Multiscale Spatiotemporal Network for Assessing Depression from Facial Dynamics. IEEE Transactions on Affective Computing (2020), 1-1. https://doi.org/10.1109/TAFFC.2020.3021755\n\n[9]\n\nJoao Carreira, Eric Noland, Andras Banki-Horvath, Chloe Hillier, and Andrew Zisserman. 2018. A Short Note about Kinetics-600. arXiv:1808.01340 [cs] (Aug. 2018). http://arxiv.org/abs/1808.01340 arXiv: 1808.01340.\n\n[10]\n\nTing Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations. In International conference on machine learning. PMLR, 1597--1607.\n\n[11]\n\nTing Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E Hinton. 2020. Big self-supervised models are strong semi-supervised learners. Advances in neural information processing systems 33 (2020), 22243--22255.\n\n[12]\n\nDidan Deng, Zhaokang Chen, Yuqian Zhou, and Bertram Shi. 2020. MIMAMO Net: Integrating Micro- and Macro-Motion for Video Emotion Recognition. Proceedings of the AAAI Conference on Artificial Intelligence 34, 03 (April 2020), 2621--2628. https://doi.org/10.1609/aaai.v34i03.5646\n\n[13]\n\nJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. 2009. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09.\n\n[14]\n\nPaul Ekman and Wallace V. Friesen. 1978. Facial action coding system: Investigator's guide. Consulting Psychologists Press.\n\n[15]\n\nCourtney Forbes, Jack J. Blanchard, Melanie Bennett, William P. Horan, Ann Kring, and Raquel Gur. 2010. Initial development and preliminary validation of a new negative symptom measure: The Clinical Assessment Interview for Negative Symptoms (CAINS). Schizophrenia Research 124, 1--3 (Dec. 2010), 36--42. https://doi.org/10.1016/j.schres.2010.08.039\n\n[16]\n\nNiki Maria Foteinopoulou, Christos Tzelepis, and Ioannis Patras. 2021. Estimating continuous affect with uncertainty. Nara, Japan. https://doi.org/10.1109/ACII52823.2021.9597425\n\n[17]\n\nXavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Deep sparse rectifier neural networks. In Proceedings of the fourteenth international conference on artificial intelligence and statistics. JMLR Workshop and Conference Proceedings, 315--323.\n\n[18]\n\nIan J. Goodfellow, Dumitru Erhan, Pierre Luc Carrier, Aaron Courville, Mehdi Mirza, Ben Hamner, Will Cukierski, Yichuan Tang, David Thaler, Dong-Hyun Lee, Yingbo Zhou, Chetan Ramaiah, Fangxiang Feng, Ruifan Li, Xiaojie Wang, Dimitris Athanasakis, John Shawe-Taylor, Maxim Milakov, John Park, Radu Ionescu, Marius Popescu, Cristian Grozea, James Bergstra, Jingjing Xie, Lukasz Romaszko, Bing Xu, Zhang Chuang, and Yoshua Bengio. 2013. Challenges in Representation Learning: A report on three machine learning contests. arXiv:1307.0414 [cs, stat] (July 2013). http://arxiv.org/abs/1307.0414 arXiv: 1307.0414.\n\n[19]\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. 770--778. https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html\n\n[20]\n\nTomu Hirata, Yusuke Mukuta, and Tatsuya Harada. 2021. Making Video Recognition Models Robust to Common Corruptions With Supervised Contrastive Learning. In ACM Multimedia Asia (MMAsia '21). Association for Computing Machinery, New York, NY, USA, 1--6. https://doi.org/10.1145/3469877.3497692\n\n[21]\n\nYan-Jia Huang, Yi-Ting Lin, Chen-Chung Liu, Lue-En Lee, Shu-Hui Hung, Jun-Kai Lo, and Li-Chen Fu. 2022. Assessing Schizophrenia Patients through Linguistic and Acoustic Features using Deep Learning Techniques. IEEE Transactions on Neural Systems and Rehabilitation Engineering (2022), 1-1. https://doi.org/10.1109/TNSRE.2022.3163777 Conference Name: IEEE Transactions on Neural Systems and Rehabilitation Engineering.\n\n[22]\n\nJyoti Joshi, Roland Goecke, Sharifa Alghowinem, Abhinav Dhall, MichaelWagner, Julien Epps, Gordon Parker, and Michael Breakspear. 2013. Multimodal assistive technologies for depression diagnosis and monitoring. Journal on Multimodal User Interfaces 7, 3 (2013), 217--228. https://doi.org/10.1007/s12193-013-0123-2\n\n[23]\n\nJyoti Joshi, Roland Goecke, Gordon Parker, and Michael Breakspear. 2013. Can Body Expressions Contribute to Automatic Depression Analysis? Automatic Face and Gesture Recognition (FG), 2013 10Th IEEE International Conference and Workshops (2013). https://doi.org/10.1109/FG.2013.6553796\n\n[24]\n\nS. R. Kay, A. Fiszbein, and L. A. Opler. 1987. The Positive and Negative Syndrome Scale (PANSS) for Schizophrenia. Schizophrenia Bulletin 13, 2 (Jan. 1987), 261--276. https://doi.org/10.1093/schbul/13.2.261\n\n[25]\n\nWill Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, Mustafa Suleyman, and Andrew Zisserman. 2017. The Kinetics Human Action Video Dataset. arXiv:1705.06950 [cs] (May 2017). http://arxiv.org/abs/1705.06950 arXiv: 1705.06950.\n\n[26]\n\nPrannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, and Dilip Krishnan. 2020. Supervised Contrastive Learning. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 18661--18673. https://proceedings.neurips.cc/paper/2020/file/d89a66c7c80a29b1bdbab0f2a1a94af8-Paper.pdf\n\n[27]\n\nDaeha Kim and Byung Cheol Song. 2021. Contrastive Adversarial Learning for Person Independent Facial Emotion Recognition. Proceedings of the AAAI Conference on Artificial Intelligence 35, 7 (May 2021), 5948--5956. https://ojs.aaai. org/index.php/AAAI/article/view/16743 Number: 7.\n\n[28]\n\nDimitrios Kollias and Stefanos Zafeiriou. 2019. A Multi-component CNN-RNN Approach for Dimensional Emotion Recognition in-the-wild. arXiv:1805.01452 [cs, eess, stat] (Dec. 2019). http://arxiv.org/abs/1805.01452 arXiv: 1805.01452.\n\n[29]\n\nFu Li, Chuang Gan, Xiao Liu, Yunlong Bian, Xiang Long, Yandong Li, Zhichao Li, Jie Zhou, and Shilei Wen. 2017. Temporal Modeling Approaches for Largescale Youtube-8M Video Understanding. arXiv:1707.04555 [cs] (July 2017). http://arxiv.org/abs/1707.04555 arXiv: 1707.04555.\n\n[30]\n\nXuewei Li, Hongjun Wu, Mengzhu Li, and Hongzhe Liu. 2022. Multi-label video classification via coupling attentional multiple instance learning with label relation graph. Pattern Recognition Letters 156 (2022), 53--59. https://doi.org/10.1016/j.patrec.2022.01.003\n\n[31]\n\nCheng Lu, Wenming Zheng, Chaolong Li, Chuangao Tang, Suyuan Liu, Simeng Yan, and Yuan Zong. 2018. Multiple Spatio-Temporal Feature Learning for Video-Based Emotion Recognition in the Wild. In Proceedings of the 20th ACM International Conference on Multimodal Interaction (Boulder, CO, USA) (ICMI '18). Association for Computing Machinery, New York, NY, USA, 646--652. https://doi.org/10.1145/3242969.3264992\n\n[32]\n\nDavid Melhart, Antonios Liapis, and Georgios N. Yannakakis. 2021. Towards General Models of Player Experience: A Study Within Genres. In 2021 IEEE Conference on Games (CoG). 01--08. https://doi.org/10.1109/CoG52621.2021.9618902\n\n[33]\n\nW. C. de Melo, E. Granger, and A. Hadid. 2019. Depression Detection Based on Deep Distribution Learning. In 2019 IEEE International Conference on Image Processing (ICIP). 4544--4548. https://doi.org/10.1109/ICIP.2019.8803467 ISSN: 2381--8549.\n\n[34]\n\nJuan Abdon Miranda Correa, Mojtaba Khomami Abadi, Niculae Sebe, and Ioannis Patras. 2018. AMIGOS: A Dataset for Affect, Personality and Mood Research on Individuals and Groups. IEEE Transactions on Affective Computing (2018), 1-1. https://doi.org/10.1109/TAFFC.2018.2884461\n\n[35]\n\nWenxuan Mou, Hatice Gunes, and Ioannis Patras. 2019. Alone versus In-a-groupA Multi-modal Framework for Automatic Affect Recognition. ACM Transactions on Multimedia Computing, Communications, and Applications 15, 2 (June 2019), 1--23. https://doi.org/10.1145/3321509\n\n[36]\n\nSongyou Peng, Le Zhang, Yutong Ban, Meng Fang, and Stefan Winkler. 2018. A deep network for arousal-valence emotion prediction with acoustic-visual cues. arXiv preprint arXiv:1805.00638 (2018).\n\n[37]\n\nStefan Priebe, Mark Savill, Til Wykes, RP Bentall, Ulrich Reininghaus, Christoph Lauber, Stephen Bremner, Sandra Eldridge, and Frank Röhricht. 2016. Effectiveness of group body psychotherapy for negative symptoms of schizophrenia: multicentre randomised controlled trial. The British Journal of Psychiatry 209, 1 (2016), 54--61.\n\n[38]\n\nRui Qian, Tianjian Meng, Boqing Gong, Ming-Hsuan Yang, HuishengWang, Serge Belongie, and Yin Cui. 2021. Spatiotemporal Contrastive Video Representation Learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 6964--6974.\n\n[39]\n\nJames A. Russell. 1980. A circumplex model of affect. Journal of Personality and Social Psychology 39, 6 (1980), 1161--1178. https://doi.org/10.1037/h0077714\n\n[40]\n\nDoyo Setiono, David Saputra, Kaleb Putra, Jurike V. Moniaga, and Andry Chowanda. 2021. Enhancing Player Experience in Game With Affective Computing. Procedia Computer Science 179 (2021), 781--788. https://doi.org/10.1016/j. procs.2021.01.066 5th International Conference on Computer Science and Computational Intelligence 2020.\n\n[41]\n\nErin Smith, Eric A. Storch, Helen Lavretsky, Jeffrey L. Cummings, and Harris A. Eyre. 2020. Affective Computing for Brain Health Disorders. Springer International Publishing, Cham, 1--14. https://doi.org/10.1007/978-3-319-75479-6_36-1\n\n[42]\n\nAntoine Toisoul, Jean Kossaifi, Adrian Bulat, Georgios Tzimiropoulos, and Maja Pantic. 2021. Estimation of continuous valence and arousal levels from faces in naturalistic conditions. Nature Machine Intelligence 3, 1 (Jan. 2021), 42--50. https://doi.org/10.1038/s42256-020-00280-0 Number: 1 Publisher: Nature Publishing Group.\n\n[43]\n\nMinh Tran, Ellen Bradley, Michelle Matvey, Joshua Woolley, and Mohammad Soleymani. 2021. Modeling Dynamics of Facial Behavior for Mental Health Assessment. (Aug. 2021). https://scirate.com/arxiv/2108.09934\n\n[44]\n\nTalia Tron, Abraham Peled, Alexander Grinsphoon, and Daphna Weinshall. 2015. Automated facial expressions analysis in schizophrenia: A continuous dynamic approach. In International Symposium on Pervasive Computing Paradigms for Mental Health. Springer, 72--81.\n\n[45]\n\nTalia Tron, Abraham Peled, Alexander Grinsphoon, and Daphna Weinshall. 2016. Facial expressions and flat affect in schizophrenia, automatic analysis from depth camera data. In 2016 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI). IEEE, 220--223.\n\n[46]\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. arXiv:1706.03762 [cs] (Dec. 2017). http://arxiv.org/abs/1706.03762 arXiv: 1706.03762.\n\n[47]\n\nYa Wang, Dongliang He, Fu Li, Xiang Long, Zhichao Zhou, Jinwen Ma, and Shilei Wen. 2020. Multi-Label Classification with Label Graph Superimposing. Proceedings of the AAAI Conference on Artificial Intelligence 34, 07 (April 2020), 12265--12272. https://doi.org/10.1609/aaai.v34i07.6909\n\n[48]\n\nChao-Yuan Wu, Christoph Feichtenhofer, Haoqi Fan, Kaiming He, Philipp Krähenbühl, and Ross Girshick. 2019. Long-Term Feature Banks for Detailed Video Understanding. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (June 2019). https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Long-Term_ Feature_Banks_for_Detailed_Video_Understanding_CVPR_2019_paper.html\n\n[49]\n\nElaheh Yadegaridehkordi, Nurul Fazmidar Binti Mohd Noor, Mohamad Nizam Bin Ayub, Hannyzzura Binti Affal, and Nornazlita Binti Hussin. 2019. Affective computing in education: A systematic review and future research. Computers & Education 142 (2019), 103649. https://doi.org/10.1016/j.compedu.2019.103649\n\n[50]\n\nZhengyuan Yang, Amanda Kay, Yuncheng Li, Wendi Cross, and Jiebo Luo. 2021. Pose-based Body Language Recognition for Emotion and Psychiatric Symptom Interpretation. In 2020 25th International Conference on Pattern Recognition (ICPR). 294--301. https://doi.org/10.1109/ICPR48806.2021.9412591\n\n[51]\n\nLi-Wei Zhang, Jingting Li, Su-Jing Wang, Xian-Hua Duan, Wen-Jing Yan, Hai-Yong Xie, and Shu-Cheng Huang. 2020. Spatio-temporal fusion for Macro- and Micro-expression Spotting in Long Video Sequences. In 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020). 734--741. https://doi.org/10.1109/FG47880.2020.00037\n\n[52]\n\nJiaming Zhou, Kun-Yu Lin, Haoxin Li, and Wei-Shi Zheng. 2021. Graph-Based High-Order Relation Modeling for Long-Term Action Recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 8984--8993.\n\nCited By\n\nView all\n\nBarattin STzelepis CPatras ISebe NAttribute-Preserving Face Dataset Anonymization via Latent Code Optimization2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)10.1109/CVPR52729.2023.00773(8001-8010)\n\nIndex Terms\n\nLearning from Label Relationships in Human Affect\n\nComputing methodologies\n\nArtificial intelligence\n\nComputer vision\n\nComputer vision representations\n\nMachine learning\n\nMachine learning approaches\n\nLearning latent representations\n\nNeural networks\n\nRecommendations\n\nSupervised representation learning for multi-label classification\n\nAbstract\n\nRepresentation learning is one of the most important aspects of multi-label learning because of the intricate nature of multi-label data. Current research on representation learning either fails to consider label knowledge or is affected by the ...\n\nTransductive Multilabel Learning via Label Set Propagation\n\nThe problem of multilabel classification has attracted great interest in the last decade, where each instance can be assigned with a set of multiple class labels simultaneously. It has a wide variety of real-world applications, e.g., automatic image ...\n\nSemi-supervised partial label learning algorithm via reliable label propagation\n\nAbstract\n\nPartial label learning (PLL) is a weakly supervised learning method that is able to predict one label as the correct answer from a given candidate label set. In PLL, when all possible candidate labels are as signed to real-world training examples, ...\n\nInformation & Contributors\n\nInformation\n\nPublished In\n\n7537 pages\n\nISBN:9781450392037\n\nDOI:10.1145/3503161\n\nGeneral Chairs:\n\nJoão Magalhães\n\nNOVA University of Lisbon, Portugal\n\n,\n\nAlberto del Bimbo\n\nUniversity of Florence, Italy\n\n,\n\nShin'ichi Satoh\n\nNational Institute of Informatics, Japan\n\n,\n\nNicu Sebe\n\nUniversity of Trento, Italy\n\n,\n\nProgram Chairs:\n\nXavier Alameda-Pineda\n\nInria, Grenoble, France\n\n,\n\nQin Jin\n\nRenmin University of China, China\n\n,\n\nVincent Oria\n\nNew Jersey Institute of Technology, USA\n\n,\n\nLaura Toni\n\nUniversity College London, UK\n\nCopyright © 2022 ACM.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from [email protected].\n\nPublisher\n\nAssociation for Computing Machinery\n\nNew York, NY, United States\n\nPublication History\n\nPublished: 10 October 2022\n\nPermissions\n\nRequest permissions for this article.\n\nCheck for updates\n\nAuthor Tags\n\ncontinuous affect estimation\n\nmultilabel\n\nrepresentation learning\n\nQualifiers\n\nResearch-article\n\nFunding Sources\n\nEPSRC\n\nEU H2020 AI4Media\n\nConference\n\nMM '22\n\nAcceptance Rates\n\nOverall Acceptance Rate 995 of 4,171 submissions, 24%\n\nUpcoming Conference\n\nContributors\n\nOther Metrics\n\nBibliometrics & Citations\n\nBibliometrics\n\nArticle Metrics\n\n1\n\nTotal Citations\n\nView Citations\n\n178\n\nTotal Downloads\n\nDownloads (Last 12 months)61\n\nDownloads (Last 6 weeks)5\n\nOther Metrics\n\nCitations\n\nCited By\n\nView all\n\nBarattin STzelepis CPatras ISebe NAttribute-Preserving Face Dataset Anonymization via Latent Code Optimization2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)10.1109/CVPR52729.2023.00773(8001-8010)\n\nView Options\n\nGet Access\n\nLogin options\n\nCheck if you have access through your login credentials or your institution to get full access on this article.\n\nSign in\n\nFull Access\n\nView options\n\nPDF\n\nView or Download as a PDF file.\n\nPDF\n\neReader\n\nView online with eReader.\n\neReader\n\nMedia\n\nFigures\n\nOther\n\nTables\n\nShare\n\nShare\n\nShare this Publication link\n\nCopied!\n\nCopying failed.\n\nShare on social media\n\nAffiliations\n\nNiki Maria Foteinopoulou\n\nQueen Mary University of London, London, United Kingdom\n\nIoannis Patras\n\nQueen Mary University of London, London, United Kingdom\n\nRequest permissions Authors Info & Affiliations"
    }
}