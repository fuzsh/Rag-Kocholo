{
    "id": "dbpedia_4551_3",
    "rank": 63,
    "data": {
        "url": "https://github.com/twintproject/twint",
        "read_more_link": "",
        "language": "en",
        "title": "twintproject/twint: An advanced Twitter scraping & OSINT tool written in Python that doesn't use Twitter's API, allowing you to scrape a user's followers, following, Tweets and more while evading most",
        "top_image": "https://opengraph.githubassets.com/3ca3087f5ff0f184fb2341f464bd9aa87b65ea56cd6ebf509555750287882fa1/twintproject/twint",
        "meta_img": "https://opengraph.githubassets.com/3ca3087f5ff0f184fb2341f464bd9aa87b65ea56cd6ebf509555750287882fa1/twintproject/twint",
        "images": [
            "https://camo.githubusercontent.com/ee56cead9796e91c5cf38e57154961703b7065db13deaf81e2924af932f93ad9/68747470733a2f2f692e696d6775722e636f6d2f6961483373377a2e706e67",
            "https://camo.githubusercontent.com/91819969d97ed8451c7fd4d34aad0ccdca15ebc351213569816a87d1555ddb78/68747470733a2f2f692e696d6775722e636f6d2f6856654372714c2e706e67",
            "https://camo.githubusercontent.com/e0c8ad0e6e3c090592342f1d7ea9c45c11a6d38eb850b2d134374a661bc849cc/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7477696e742e737667",
            "https://camo.githubusercontent.com/402d439e84acb7feb786cc1455cac04baa7e24c9b5c84d2272280ac76e72bf13/68747470733a2f2f7472617669732d63692e6f72672f7477696e7470726f6a6563742f7477696e742e7376673f6272616e63683d6d6173746572",
            "https://camo.githubusercontent.com/862dda0fdfb14ca7b6e07d80dcffa3bceae86b9f278b0ef511a863b3a0d4269d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e36253246332e37253246332e382d626c75652e737667",
            "https://camo.githubusercontent.com/405c494a6ac3fb2314c5498510ed3937af172d6366ae87424b84f0baff26f5ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6861636365722f74776565702e737667",
            "https://camo.githubusercontent.com/3030de7f7fa7ce09581947cbabb0d6fe997ddbbc68f0c536628d31b8b5a79e7b/68747470733a2f2f706570792e746563682f62616467652f7477696e74",
            "https://camo.githubusercontent.com/11f544d73ced7cf583c88f4f88428cd537dccc82f5b78c685e70441d1bcdfb7c/68747470733a2f2f706570792e746563682f62616467652f7477696e742f7765656b",
            "https://camo.githubusercontent.com/3373785922d5e5f7cce96423a244e4ecba9a451bc87cddb4585d1b6d63bf81d0/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e742e7376673f75726c3d68747470733a253246253246736869656c6473696f2d70617472656f6e2e6865726f6b756170702e636f6d2532467477696e7470726f6a656374",
            "https://camo.githubusercontent.com/3552bbcb86898cddda4ca65c92ecae76fc0255aa66f015389bdbb60583a307b3/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6e6f6e65707269766163792e7376673f6c6162656c3d466f6c6c6f77267374796c653d736f6369616c",
            "https://camo.githubusercontent.com/8de9d2bd75535731f3b2284c79185e01c499263fa8a58fc17b6b051933db363f/68747470733a2f2f692e696d6775722e636f6d2f45454a7142386e2e706e67",
            "https://camo.githubusercontent.com/c45166371ff479f3d184337a707df7c2b14bc100baa21f3ecccfb39d94ea54f6/68747470733a2f2f692e696d6775722e636f6d2f447a636649674c2e706e67",
            "https://github.githubassets.com/assets/patreon-96b15b9db4b9.svg",
            "https://avatars.githubusercontent.com/u/147507744?s=64&v=4",
            "https://avatars.githubusercontent.com/u/176148432?s=64&v=4",
            "https://avatars.githubusercontent.com/u/175530353?s=64&v=4",
            "https://avatars.githubusercontent.com/u/175530353?s=64&v=4",
            "https://avatars.githubusercontent.com/u/90832375?s=64&v=4",
            "https://avatars.githubusercontent.com/u/103772720?s=64&v=4",
            "https://avatars.githubusercontent.com/u/25952589?s=64&v=4",
            "https://avatars.githubusercontent.com/u/20042337?s=64&v=4",
            "https://avatars.githubusercontent.com/u/17363750?s=64&v=4",
            "https://avatars.githubusercontent.com/u/22013186?s=64&v=4",
            "https://avatars.githubusercontent.com/u/5204252?s=64&v=4",
            "https://avatars.githubusercontent.com/u/8553310?s=64&v=4",
            "https://avatars.githubusercontent.com/u/5607572?s=64&v=4",
            "https://avatars.githubusercontent.com/u/12037308?s=64&v=4",
            "https://avatars.githubusercontent.com/u/5335554?s=64&v=4",
            "https://avatars.githubusercontent.com/u/6927348?s=64&v=4",
            "https://avatars.githubusercontent.com/u/10365452?s=64&v=4",
            "https://avatars.githubusercontent.com/u/22371870?s=64&v=4",
            "https://avatars.githubusercontent.com/u/42121860?s=64&v=4",
            "https://avatars.githubusercontent.com/u/1628214?s=64&v=4",
            "https://avatars.githubusercontent.com/u/4249447?s=64&v=4",
            "https://avatars.githubusercontent.com/u/6548211?s=64&v=4"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "An advanced Twitter scraping & OSINT tool written in Python that doesn't use Twitter's API, allowing you to scrape a user's followers, following, Tweets and more while evading most API limitations. - twintproject/twint",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/twintproject/twint",
        "text": "No authentication. No API. No limits.\n\nTwint is an advanced Twitter scraping tool written in Python that allows for scraping Tweets from Twitter profiles without using Twitter's API.\n\nTwint utilizes Twitter's search operators to let you scrape Tweets from specific users, scrape Tweets relating to certain topics, hashtags & trends, or sort out sensitive information from Tweets like e-mail and phone numbers. I find this very useful, and you can get really creative with it too.\n\nTwint also makes special queries to Twitter allowing you to also scrape a Twitter user's followers, Tweets a user has liked, and who they follow without any authentication, API, Selenium, or browser emulation.\n\nSome of the benefits of using Twint vs Twitter API:\n\nCan fetch almost all Tweets (Twitter API limits to last 3200 Tweets only);\n\nFast initial setup;\n\nCan be used anonymously and without Twitter sign up;\n\nNo rate limitations.\n\nTwitter limits scrolls while browsing the user timeline. This means that with .Profile or with .Favorites you will be able to get ~3200 tweets.\n\nPython 3.6;\n\naiohttp;\n\naiodns;\n\nbeautifulsoup4;\n\ncchardet;\n\ndataclasses\n\nelasticsearch;\n\npysocks;\n\npandas (>=0.23.0);\n\naiohttp_socks;\n\nschedule;\n\ngeopy;\n\nfake-useragent;\n\npy-googletransx.\n\nGit:\n\ngit clone --depth=1 https://github.com/twintproject/twint.git cd twint pip3 install . -r requirements.txt\n\nPip:\n\npip3 install twint\n\nor\n\npip3 install --user --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint\n\nPipenv:\n\npipenv install git+https://github.com/twintproject/twint.git#egg=twint\n\nMarch 2, 2021 Update\n\nAdded: Dockerfile\n\nNoticed a lot of people are having issues installing (including me). Please use the Dockerfile temporarily while I look into them.\n\nA few simple examples to help you understand the basics:\n\ntwint -u username - Scrape all the Tweets of a user (doesn't include retweets but includes replies).\n\ntwint -u username -s pineapple - Scrape all Tweets from the user's timeline containing pineapple.\n\ntwint -s pineapple - Collect every Tweet containing pineapple from everyone's Tweets.\n\ntwint -u username --year 2014 - Collect Tweets that were tweeted before 2014.\n\ntwint -u username --since \"2015-12-20 20:30:15\" - Collect Tweets that were tweeted since 2015-12-20 20:30:15.\n\ntwint -u username --since 2015-12-20 - Collect Tweets that were tweeted since 2015-12-20 00:00:00.\n\ntwint -u username -o file.txt - Scrape Tweets and save to file.txt.\n\ntwint -u username -o file.csv --csv - Scrape Tweets and save as a csv file.\n\ntwint -u username --email --phone - Show Tweets that might have phone numbers or email addresses.\n\ntwint -s \"Donald Trump\" --verified - Display Tweets by verified users that Tweeted about Donald Trump.\n\ntwint -g=\"48.880048,2.385939,1km\" -o file.csv --csv - Scrape Tweets from a radius of 1km around a place in Paris and export them to a csv file.\n\ntwint -u username -es localhost:9200 - Output Tweets to Elasticsearch\n\ntwint -u username -o file.json --json - Scrape Tweets and save as a json file.\n\ntwint -u username --database tweets.db - Save Tweets to a SQLite database.\n\ntwint -u username --followers - Scrape a Twitter user's followers.\n\ntwint -u username --following - Scrape who a Twitter user follows.\n\ntwint -u username --favorites - Collect all the Tweets a user has favorited (gathers ~3200 tweet).\n\ntwint -u username --following --user-full - Collect full user information a person follows\n\ntwint -u username --timeline - Use an effective method to gather Tweets from a user's profile (Gathers ~3200 Tweets, including retweets & replies).\n\ntwint -u username --retweets - Use a quick method to gather the last 900 Tweets (that includes retweets) from a user's profile.\n\ntwint -u username --resume resume_file.txt - Resume a search starting from the last saved scroll-id.\n\nMore detail about the commands and options are located in the wiki\n\nTwint can now be used as a module and supports custom formatting. More details are located in the wiki\n\nimport twint # Configure c = twint.Config() c.Username = \"realDonaldTrump\" c.Search = \"great\" # Run twint.run.Search(c)\n\nOutput\n\n955511208597184512 2018-01-22 18:43:19 GMT <now> pineapples are the best fruit\n\nimport twint c = twint.Config() c.Username = \"noneprivacy\" c.Custom[\"tweet\"] = [\"id\"] c.Custom[\"user\"] = [\"bio\"] c.Limit = 10 c.Store_csv = True c.Output = \"none\" twint.run.Search(c)\n\nWrite to file;\n\nCSV;\n\nJSON;\n\nSQLite;\n\nElasticsearch.\n\nDetails on setting up Elasticsearch with Twint is located in the wiki.\n\nGraph details are also located in the wiki.\n\nWe are developing a Twint Desktop App.\n\nI tried scraping tweets from a user, I know that they exist but I'm not getting them\n\nTwitter can shadow-ban accounts, which means that their tweets will not be available via search. To solve this, pass --profile-full if you are using Twint via CLI or, if are using Twint as module, add config.Profile_full = True. Please note that this process will be quite slow.\n\nTo get only follower usernames/following usernames\n\ntwint -u username --followers\n\ntwint -u username --following\n\nTo get user info of followers/following users\n\ntwint -u username --followers --user-full\n\ntwint -u username --following --user-full\n\nTo get only user info of user\n\ntwint -u username --user-full\n\nTo get user info of users from a userlist\n\ntwint --userlist inputlist --user-full\n\nTo get 100 english tweets and translate them to italian\n\ntwint -u noneprivacy --csv --output none.csv --lang en --translate --translate-dest it --limit 100\n\nor\n\nimport twint c = twint.Config() c.Username = \"noneprivacy\" c.Limit = 100 c.Store_csv = True c.Output = \"none.csv\" c.Lang = \"en\" c.Translate = True c.TranslateDest = \"it\" twint.run.Search(c)\n\nNotes:\n\nGoogle translate has some quotas\n\nHow to use Twint as an OSINT tool\n\nBasic tutorial made by Null Byte\n\nAnalyzing Tweets with NLP in minutes with Spark, Optimus and Twint\n\nLoading tweets into Kafka and Neo4j\n\nContact"
    }
}