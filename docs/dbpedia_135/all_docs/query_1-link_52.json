{
    "id": "dbpedia_135_1",
    "rank": 52,
    "data": {
        "url": "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/journal.pcbi.1009585",
        "read_more_link": "",
        "language": "en",
        "title": "Repeated measures ASCA+ for analysis of longitudinal intervention studies with multivariate outcome data",
        "top_image": "https://journals.plos.org/ploscompbiol/article/figure/image?id=10.1371/journal.pcbi.1009585.g004&size=inline",
        "meta_img": "https://journals.plos.org/ploscompbiol/article/figure/image?id=10.1371/journal.pcbi.1009585.g004&size=inline",
        "images": [
            "https://journals.plos.org/resource/img/orcid_16x16.png",
            "https://journals.plos.org/resource/img/orcid_16x16.png",
            "https://journals.plos.org/resource/img/orcid_16x16.png",
            "https://journals.plos.org/resource/img/orcid_16x16.png",
            "https://journals.plos.org/resource/img/logo-plos.png",
            "https://journals.plos.org/ploscompbiol/article/figure/image?size=inline&id=10.1371/journal.pcbi.1009585.g001",
            "https://journals.plos.org/ploscompbiol/article/figure/image?size=inline&id=10.1371/journal.pcbi.1009585.g002",
            "https://journals.plos.org/ploscompbiol/article/figure/image?size=inline&id=10.1371/journal.pcbi.1009585.g003",
            "https://journals.plos.org/ploscompbiol/article/figure/image?size=inline&id=10.1371/journal.pcbi.1009585.g004",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e001",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e002",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e003",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e004",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e005",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e006",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e007",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e008",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e009",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e010",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e011",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e012",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e013",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e014",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e015",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e016",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e017",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e018",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e019",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e020",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e021",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e022",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e023",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e024",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e025",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e026",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e027",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e028",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pcbi.1009585.g001",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pcbi.1009585.g002",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/file?type=thumbnail&id=10.1371/journal.pcbi.1009585.e029",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pcbi.1009585.g003",
            "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/article/figure/image?size=inline&id=10.1371/journal.pcbi.1009585.g004",
            "https://journals.plos.org/resource/img/icon.reddit.16.png",
            "https://journals.plos.org/resource/img/icon.fb.16.png",
            "https://journals.plos.org/resource/img/icon.linkedin.16.png",
            "https://journals.plos.org/resource/img/icon.mendeley.16.png",
            "https://journals.plos.org/resource/img/icon.twtr.16.png",
            "https://journals.plos.org/resource/img/icon.email.16.png",
            "https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_BW_horizontal.svg",
            "https://journals.plos.org/resource/img/logo-plos-footer.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Principal component analysis",
            "Metabolites",
            "Chemotherapy",
            "Surgical and invasive medical procedures",
            "Randomized controlled trials",
            "Cancers and neoplasms",
            "Confidence intervals",
            "Metabolomics"
        ],
        "tags": null,
        "authors": [
            "Age K. Smilde",
            "Johan A. Westerhuis",
            "Torfinn S. Madssen",
            "Guro F. Giskeødegård"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Author summary Clinical trials are increasingly generating large amounts of complex biological data. Examples can include measuring metabolism or gene expression in tissue or blood sampled repeatedly over the course of a treatment. In such cases, one might wish to compare changes in not one, but hundreds, or thousands of variables simultaneously. In order to effectively analyze such data, both the study design and the multivariate nature of the data should be considered during data analysis. ANOVA simultaneous component analysis+ (ASCA+) is a statistical method which combines general linear models with principal component analysis, and provides a way to separate and visualize the effects of different factors on complex biological data. In this work, we describe how repeated measures linear mixed models, a class of models commonly used when analyzing changes over time and treatment effects in longitudinal studies, can be used together with ASCA+ for analyzing clinical trials in a novel method called repeated measures-ASCA+ (RM-ASCA+).",
        "meta_lang": "en",
        "meta_favicon": "/resource/img/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009585",
        "text": "Repeated measures.\n\nIn a repeated measures model, the baseline value of the response variable is included in the responses in the same way as the follow-up measurements. Suppose that a response variable y is measured at K timepoints (k = 1..K) for a total of I subjects (i = 1..I), where each subject belongs to one of H groups (h = 1..H). If the number of timepoints K = 3, and the number of groups H = 2, then a repeated measures model for this data is: where β0–5 are the coefficients to be estimated from the data, t1k and t2k are indicator values for the time factor, gh is an indicator variable value for the group factor, t1k * gh and t2k * gh are factor interaction values, γ0i represents a subject-specific random intercept, which is , and eihk is a residual term, which is . Both the random intercepts and residuals are assumed to be independent. The model is here shown for only three timepoints and two groups, but can easily be extended to an arbitrary number of timepoints and groups by including more indicator variables.\n\nWhen entering categorical variables (e.g. experimental factors such as time and treatment) into a regression model, a choice must be made regarding how the different factor levels should be represented in the model. In general, to enter a categorical factor with k levels, (k– 1) variables are needed. While choice of coding does not impact the overall fit of the model, it determines the interpretation of the model coefficients, and therefore also the interpretation of the effect matrices estimated by ASCA. Two commonly used coding systems for representing categorical variables are reference coding and sum coding. With reference coding, one of the factor levels is selected as the reference level, and represented by setting all indicator variables to zero, while the other levels are represented by one of the indicator variables taking on the value 1. Thus, representing the time factor with reference coding can be done as:\n\nThis coding causes the effects of t1 and t2 to be expressed relative to the baseline timepoint t0 (k = 1, the reference level). In sum coding no reference level is selected, but every level is instead compared to the mean across all levels. To represent the time factor with sum coding, instead of representing the omitted level with a row of zeros, it is represented by a row of -1:\n\nWith this coding, the effects of t1 and t2 are expressed relative to the mean response across all three levels. The effect of t0, or whichever level is omitted, is not directly estimated, but can be calculated from the remaining effects. In the models discussed in this section, the indicator variables for time (t1 and t2) will be reference coded with the first timepoint as the reference level. Depending on whether the indicator variable g is reference coded (0 or 1) or sum coded (-1 or 1), the coefficients for time, β1 and β2 in the repeated measures model will represent either the time effect (i.e. change from baseline) for the reference group, or the average time effect across both groups. In both cases β3 represents the group differences at baseline, while the interaction effects β4 and β5 represent the group difference in within-group change from baseline to each of the timepoints. If g is reference coded, the intercept (β0) represents the estimated baseline mean for the reference group, while if g is sum coded, it represents the baseline mean across both groups.\n\nWhen assessing whether the mean change in the response variable over time is different between the groups, a decision has to be made whether an adjustment for baseline differences in the response variable should be made. Although it is often believed that such an adjustment is made by assessing changes instead of directly comparing means, this is not correct (8). This is in part because the group with the highest baseline value will be expected to decrease slightly more than the group with the lowest baseline value, due to regression to the mean, even if the treatment has no effect. Conversely, the group with the lowest baseline value will be expected to increase slightly more. Simply comparing changes without adjusting for this variation can therefore lead to either over- or underestimation of the true treatment effect. The interaction coefficients β4 and β5 in the above model are unadjusted, because they are only assessing whether the within-group change is different between the groups. Typically, one adjusts for a variable by including it as a covariate. However, in a repeated measures model, where the baseline values already are included in the responses, an adjustment can instead be made by removing the main effect for treatment, β3gh, from the model while keeping its interactions with time:\n\nBecause the time factor is reference coded with baseline as the reference level, and because there is no main effect for treatment, the estimated group means are constrained to be the same at baseline. This is also known as a constrained longitudinal data analysis (cLDA) model [9], while the previous model with the main effect for treatment included is sometimes referred to as an unconstrained longitudinal data analysis (ucLDA) model. The result of this constraint is that the interaction effects β3 and β4 will be adjusted for baseline.\n\nIn addition to adjusting for the baseline value of the response variable, it is also possible to adjust for other baseline covariates. In general, the decision of whether to adjust for baseline covariates depends primarily on the study design, and the research question of interest. When using general linear (mixed) models to analyze treatment effects in a randomized controlled trial, and the treatment effect is expressed as a difference in means, it is generally recommended to adjust for baseline (pre-randomization) covariates which are known in advance to influence the response variable [10–12]. Because of the randomization, doing so does not bias or change the interpretation of the treatment effect, but results in smaller standard errors, and thereby increased precision [13]. This property of the treatment effect estimator is referred to as collapsibility, meaning that the marginal and conditional treatment effect estimates are on expectation equal in the absence of confounding. Another situation where covariate adjustment can increase statistical power is in trials with stratified randomization. This is because the stratification induces a positive correlation between the treatment groups, which results in too wide confidence intervals for the treatment effect estimate. This can be accounted for by including the stratification factor as a covariate in the model [14,15]. These possibilities have so far not been leveraged in ASCA, but this can be done in our framework.\n\nFor non-randomized studies, the situation is more complex. In this situation, the treatment groups are typically already different before treatment is given. Adjusting for baseline covariates in this setting can induce spurious effects, except in situations in which the treatment allocation is determined by the included baseline covariates (e.g. regression discontinuity designs) [10]. The adjusted estimate will then have a different interpretation from the unadjusted one. This phenomenon is known as Lord’s paradox [16], and implies that baseline adjustments must be done with care in non-randomized settings. In general, the decision to adjust for any covariate is dependent on prior knowledge about the study design and the measured variables, as well as on assumptions about how they causally interact. This applies to all forms of covariate adjustment, of which baseline adjustment is only a special case. Causal diagrams in the form of directed acyclic graphs provide a general framework for determining whether adjustment for a given variable creates or reduces bias with respect to the effect of interest [17].\n\nIn our examples we model time as a categorical variable, as is typical in ASCA. However, time can also be modeled as a continuous variable, where different functional forms can be assumed for the time effect, e.g. linear, polynomial, or splines [18,19]. Additionally, more complex random effect structures can be considered, for example modeling time with random slopes. However, we will limit our discussion to random intercept models, in order to keep the number of estimated parameters to a minimum.\n\nRM-ASCA+.\n\nIn the methodology presented here, RM-ASCA+, we combine repeated measures linear mixed models with ASCA+ to estimate the multivariate effects of time and the interaction between time and group in an unbalanced setting, while also accounting for within-subject dependency. We do this without applying the initial PCA-step as done in LiMM-PCA, and the effects are therefore estimated directly based on the full response matrix: where B is a p×J fixed effect parameter matrix, and U is an IK×J matrix containing the random effect coefficients, and E is an IK×J residual matrix. Since all of the variation in Y is included when estimating the effects, it avoids the issue of selecting the appropriate number of components as in LiMM-PCA, although the methods for hypothesis testing and quantifying explained variance are also lost as a result. The effect matrices are then constructed in the same way as in ASCA+/LiMM-PCA:\n\nHowever, in order to obtain the baseline constraint as shown previously, it is necessary to deviate from the sum coding usually used in ASCA+. This is because constraining the baseline means requires the time factor to be reference coded with baseline as the reference timepoint, as was shown in cLDA. For illustration, suppose we fit a RM-ASCA+ model using an ucLDA-model, where the time effect is reference coded with baseline as reference, and group is sum coded:\n\nWith this coding system the intercept matrix M0 represents the overall baseline mean, while MT represents the time effect expressed as the change from M0. The matrix MG represents the group differences at baseline, expressed as deviations from M0, while MT*G represents the group difference in within-group change (i.e. the treatment effect) from baseline to each of the timepoints, expressed as deviations from the general time effect.\n\nAs discussed, the treatment effect estimated in a ucLDA-model is not adjusted for baseline. If the treatment effect should be adjusted for baseline, this can be achieved by removing the treatment main effect, G, from the design matrix before fitting the model:\n\nWhen the main effect for treatment, G, is omitted from the model matrix X, the treatment effect described by MT*G will be adjusted for baseline.\n\nIt is also possible to use reference coding for both the time and treatment factor:\n\nIf this coding is used, the time effect will change from describing the overall time effect, to only describing the time effect of the reference group. The treatment effect will then be expressed as deviations from the trajectory of the reference group. These two approaches (i.e. using either sum or reference coding for the treatment effect) are related to two earlier methods, known as scaled-to-maximum, aligned, and reduced trajectories (SMART)-analysis [22], and principal response curves (PRC) [23], which involve expressing temporal trajectories relative to a baseline timepoint, or relative to a control group, respectively. Analyzing MT + MT*G is similar to SMART, whereas if we reference code both the time and treatment factors, and then analyze MG + MT*G, the result will be similar to PRC. However, neither SMART nor PRC allow inclusion of random effects or baseline adjustments, whereas both are possible in our framework.\n\nUsing reference coding for the time factor has implications for the orthogonality of the effect matrices. Because reference coding does not result in orthogonal contrasts, the effect matrices estimated using the repeated measures model are also not mutually orthogonal. Hence, the variance decomposition method commonly used in ASCA is not possible here. However, the interpretation of the effect matrices is still meaningfully defined, as discussed in the previous paragraph. It should also be noted that whenever continuous covariates are included in the model, the design will generally not be fully orthogonal, as there will always be imbalances in the covariate levels between the groups. Hence, the main goal of this approach is not to precisely quantify and decompose mutually independent sources of variation, but rather to estimate and visualize time-varying multivariate treatment effects with improved precision, by extending covariate adjustment strategies used in RCTs to the multivariate case.\n\nSo far the random effects structure in the model is only used when estimating the fixed effects in B. However, the random effects themselves can also be included and visualized in various ways. In ASCA+/LiMM-PCA the effect matrices are often augmented with the model residuals in order to visualize residual variability in the score plots. For example, if we apply PCA to the time effect matrix, so that MT = TTPT′, the augmented score matrix is calculated as [24]. This can be used to assess the size of the effect compared with the unexplained variation, thereby providing an indirect and qualitative measure of statistical significance. Similarly, we can also augment the effect matrices with the random effects, (ZU+E), which can be used to visualize the individual offsets (ZU), as well as residual variability in response over time (E). This can for example be done by applying PCA to the combined effect matrices for the time- and time*treatment interaction effect matrices, so that (MT + MT*G) = TT+T*GPT+T*G′, and then calculating the augmented score matrix as . If no other covariates have been included, this becomes equivalent to projecting the raw values onto the components estimated for (MT + MT*G). Alternatively, it is also possible to analyze the random effects matrix ZU and the residual matrix E separately. In a repeated measures model with only a random intercept, the random effect matrix ZU is essentially the estimated intercepts for each subject, and will therefore give similar results to a direct PCA on the baseline values. Analyzing the residual matrix E is useful for discovering patterns unaccounted for by the model, as well as violations of model assumptions."
    }
}