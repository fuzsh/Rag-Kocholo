{
    "id": "dbpedia_988_2",
    "rank": 29,
    "data": {
        "url": "https://graphics.fandom.com/wiki/Computer_graphics",
        "read_more_link": "",
        "language": "en",
        "title": "Computer graphics",
        "top_image": "https://static.wikia.nocookie.net/ucp-internal-test-starter-commons/images/a/aa/FandomFireLogo.png/revision/latest?cb=20210713142711",
        "meta_img": "https://static.wikia.nocookie.net/ucp-internal-test-starter-commons/images/a/aa/FandomFireLogo.png/revision/latest?cb=20210713142711",
        "images": [
            "https://static.wikia.nocookie.net/ff185fe4-8356-4b6b-ad48-621b95a82a1d",
            "https://static.wikia.nocookie.net/f3fc9271-3d5e-4c73-9afc-e6a9f6154ff1",
            "https://static.wikia.nocookie.net/464fc70a-5090-490b-b47e-0759e89c263f",
            "https://static.wikia.nocookie.net/f7bb9d33-4f9a-4faa-88fe-2a0bd8138668"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Contributors to Computer Graphics"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Template:Otheruses4 Computer graphics (CG) is the field of visual computing, where one utilizes computers both to generate visual images synthetically and to integrate or alter visual and spatial information sampled from the real world. The first major advance in computer graphics was the...",
        "meta_lang": "en",
        "meta_favicon": "/skins-ucp/mw139/common/favicon.ico",
        "meta_site_name": "Computer Graphics",
        "canonical_link": "https://graphics.fandom.com/wiki/Computer_graphics",
        "text": "Template:Otheruses4\n\nComputer graphics (CG) is the field of visual computing, where one utilizes computers both to generate visual images synthetically and to integrate or alter visual and spatial information sampled from the real world.\n\nThe first major advance in computer graphics was the development of Sketchpad in 1962 by Ivan Sutherland.\n\nThis field can be divided into several areas: real-time 3D rendering (often used in video games), computer animation, video capture and video creation rendering, special effects editing (often used for movies and television), image editing, and modeling (often used for engineering and medical purposes). Development in computer graphics was first fueled by academic interests and government sponsorship. However, as real-world applications of computer graphics in broadcast television and movies proved a viable alternative to more traditional special effects and animation techniques, commercial parties have increasingly funded advances in the field.\n\nIt is often thought that the first feature film to use computer graphics was 2001: A Space Odyssey (1968), which attempted to show how computers would be much more graphical in the future. However, all the \"computer graphic\" effects in that film were hand-drawn animation, and the special effects sequences were produced entirely with conventional optical and model effects.\n\nPerhaps the first use of computer graphics specifically to illustrate computer graphics was in Futureworld (1976), which included an animation of a human face and hand--produced by Ed Catmull and Fred Parke at the University of Utah.\n\n2D[]\n\nMain article: 2D computer graphics\n\nThe first advance in computer graphics was in the use of CRTs. There are two approaches to 2D computer graphics: vector and raster graphics. Vector graphics stores precise geometric data, topology and style such as: coordinate positions of points, the connections between points (to form lines or paths), and the color, thickness, and possible fill of the shapes. Most vector graphic systems can also use primitives of standard shapes such as circles, rectangles, etc. In most cases, a vector graphic image has to be converted to a raster image to be viewed. Raster graphics is a uniform 2-dimensional grid of pixels. Each pixel has a specific value such as, for instance, brightness, color, transparency, or a combination of such values. A raster image has a finite resolution of a specific number of rows and columns. Standard computer displays shows a raster image of resolutions such as 1280(columns)x1024(rows) of pixels. Today, one often combines raster and vector graphics in compound file formats (pdf, swf).\n\n3D[]\n\nMain article: 3D computer graphics\n\nWith the birth of workstation computers (like LISP machines, paintbox computers and Silicon Graphics workstations) came 3D computer graphics, based on vector graphics. Instead of the computer storing information about points, lines, and curves on a 2-dimensional plane, the computer stores the location of points, lines, and, typically, faces (to construct a polygon) in 3-dimensional space.\n\n3-dimensional polygons are the lifeblood of virtually all 3D computer graphics. As a result, most 3D graphics engines are based around storing points (single 3-dimensional coordinates), lines that connect those points together, faces defined by the lines, and then a sequence of faces to create 3D polygons.\n\nModern-day computer graphics software goes far beyond just the simple storage of polygons in computer memory. Today's graphics are not only the product of massive collections of polygons into recognizable shapes, but they also result from techniques in shading, texturing, and rasterization.\n\nShading[]\n\nThe process of shading (in the context of 3D computer graphics) involves the computer simulating (or, more accurately, calculating) how the faces of a polygon will look when illuminated by a virtual light source. The exact calculation varies depending on not only what data is available about the face being shaded, but also the shading.\n\nImage-Based Rendering[]\n\nComputer graphics is all about obtaining 2D images from 3D models. In order to get highly accurate and photo-realistic images, the input 3D models should be very accurate in terms of geometry and colors. Simulating the real 3D world scene using Computer Graphics is difficult, because obtaining accurate 3D geometry of the world is difficult. Instead of obtaining 3D models, image-based rendering (IBR) uses the images taken from particular view points and tries to obtain new images from other view points. Though the term \"image-based rendering\" was coined recently, it has been in practice since the inception of research in computer vision. In 1996, two image-based rendering techniques were presented in SIGGRAPH: light field rendering and Lumigraph rendering. These techniques received special attention in the research community. Since then, many representations for IBR were proposed. One popular method is view-dependent texture mapping, an IBR technique from University of Southern California. Andrew Zisserman, et. al from Oxford University used machine learning concepts for IBR.\n\nFlat shading: A technique that shades each polygon of an object based on the polygon's \"normal\" and the position and intensity of a light source.\n\nGouraud shading: Invented by Henri Gouraud in 1971, a fast and resource-conscious technique used to simulate smoothly shaded surfaces by interpolating vertex colors across a polygon's surface.\n\nTexture mapping: A technique for simulating surface detail by mapping images (textures) onto polygons.\n\nPhong shading: Invented by Bui Tuong Phong, a smooth shading technique that approximates curved-surface lighting by interpolating the vertex normals of a polygon across the surface; the lighting model includes glossy reflection with a controllable level of gloss.\n\nBump mapping: Invented by Jim Blinn, a normal-perturbation technique used to simulate bumpy or wrinkled surfaces.\n\nRay tracing: A method based on the physical principles of geometric optics that can simulate multiple reflections and transparency.\n\nRadiosity: a technique for global illumination that uses radiative transfer theory to simulate indirect (reflected) illumination in scenes with diffuse surfaces.\n\nBlobs: a technique for representing surfaces without specifying a hard boundary representation, usually implemented as a procedural surface like a Van der Waals equipotential (in chemistry).\n\nTexturing[]\n\nPolygon surfaces (the sequence of faces) can contain data corresponding to not only a color but, in more advanced software, can be a virtual canvas for a picture, or other rasterized image. Such an image is placed onto a face, or series of faces, and is called a texture.\n\nTextures add a new degree of customization as to how a faces and polygons will ultimately look after being shaded, depending on the shading method, and how the image is interpreted during shading.\n\nSee Also[]\n\nSeveral important topics in 2D and 3D graphics include:\n\nColor theory\n\nRaster graphics\n\nVector graphics\n\nGeometric surface representations\n\nincluding, polygons, BÃ©zier surfaces, splines, subdivision surfaces, implicit surfaces, point-set surfaces, and NURBS\n\nMaterial properties, including BRDFs\n\nImage compression\n\nAnimation\n\nRendering\n\nCompositing\n\nProjection\n\n3D projection\n\nHidden surface determination\n\nVertex shaders and pixel shaders\n\nFull screen effects\n\nNon-photorealistic rendering\n\nReal-time computer graphics\n\nToolkits & APIs[]\n\nFor an application relying heavily on computer graphics, the following could be useful:\n\nAdobe Systems\n\nAutodesk\n\nBlender3d\n\nBRL-CAD\n\nComputer Graphics Metafile (CGM)\n\nCrystal Space\n\nPower Render\n\nDirectX\n\nGLUT\n\nGraphical Kernel System (GKS)\n\nMacromedia Flash\n\nMacromedia Shockwave\n\nOpen Inventor\n\nOpenGL\n\nPixia\n\nPostScript\n\nScalable Vector Graphics (SVG)\n\nsvgalib\n\nX Window System\n\nMiscellaneous[]\n\nBresenham's line algorithm\n\nComputer-generated imagery\n\nDigital image editing\n\nTimeline of CGI in films\n\nComputer vision\n\nDigital image processing\n\nDigital geometry\n\nGraphics processing unit\n\nPOV-ray\n\nGraphical output devices\n\nList of computer graphics and descriptive geometry topics\n\nUtah Teapot\n\nStanford Bunny\n\nSIGGRAPH\n\nASCII art\n\n[]"
    }
}