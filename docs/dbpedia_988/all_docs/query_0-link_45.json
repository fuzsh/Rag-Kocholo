{
    "id": "dbpedia_988_0",
    "rank": 45,
    "data": {
        "url": "https://ohiostate.pressbooks.pub/graphicshistory/back-matter/glossary/",
        "read_more_link": "",
        "language": "en",
        "title": "Glossary – Computer Graphics and Computer Animation: A Retrospective Overview",
        "top_image": "https://ohiostate.pressbooks.pub/app/themes/pressbooks-book/dist/images/favicon-32x32.png",
        "meta_img": "https://ohiostate.pressbooks.pub/app/themes/pressbooks-book/dist/images/favicon-32x32.png",
        "images": [
            "https://ohiostate.pressbooks.pub/app/themes/pressbooks-book/packages/buckram/assets/images/cc-by-nc-nd.svg",
            "https://ohiostate.pressbooks.pub/app/themes/pressbooks-book/assets/images/yt_icon_mono_dark.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Wayne E. Carlson"
        ],
        "publish_date": "2017-06-20T00:00:00",
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "https://ohiostate.pressbooks.pub/app/themes/pressbooks-book/dist/images/apple-touch-icon.png",
        "meta_site_name": "",
        "canonical_link": "https://ohiostate.pressbooks.pub/graphicshistory/back-matter/glossary/",
        "text": "Glossary\n\nA\n\nA-buffer or Alpha-buffer\n\nAn extra Color channel to hold transparency information; pixels become quad values (RGBA). In a 32-bit frame buffer there are 24 bits of color, 8 each for red, green, and blue, along with an 8-bit alpha channel. Alpha is used for determining and displaying transparency, shadows, and anti-aliasing.\n\nRelated Glossary Terms: Antialiasing, Frame buffer\n\nTerm Source: Chapter 19 – Noise functions and Fractals\n\nAbel, Robert\n\nRobert Abel was a pioneer in visual effects, computer animation and interactive media, best known for the work of his company, Robert Abel and Associates. He received degrees in Design and Film from UCLA. He began his work in computer graphics in the 1950s, as an apprentice to John Whitney. In the 1960s and early 1970s, Abel wrote or directed several films, including The Making of the President, 1968, Elvis on Tour and Let the Good Times Roll.\n\nIn 1971, Abel and Con Pederson founded Robert Abel and Associates (RA&A), creating slit- scan effects and using motion-controlled cameras for television commercials and films. RA&A began using Evans & Sutherland computers to pre-visualize their effects; this led to the creation of the trailer for The Black Hole, and the development of their own software for digitally animating films (including Tron).In 1984, Robert Abel and Associates produced a commercial named Brilliance for the Canned Food Information Council for airing during the Super Bowl. It featured a sexy robot with reflective environment mapping and human-like motion.\n\nAbel & Associates closed in 1987 following an ill-fated merger with now defunct Omnibus Computer Graphics, Inc., a company which had been based in Toronto.In the 1990s, Abel founded Synapse Technologies, an early interactive media company, which produced pioneering educational projects for IBM, including “Columbus: Discovery, Encounter and Beyond” and “Evolution/Revolution: The World from 1890-1930”.He received numerous honors, including a Golden Globe Award (for Elvis on Tour), 2 Emmy Awards, and 33 Clios.\n\nAbel died from complications following a myocardial infarction at the age of 64.\n\nRelated Glossary Terms: DOA\n\nTerm Source: Chapter 6 – Robert Abel and Associates\n\nAbstract expressionism\n\nA painting movement in which artists typically applied paint rapidly, and with force to their huge canvases in an effort to show feelings and emotions, painting gesturally, non- geometrically, sometimes applying paint with large brushes, sometimes dripping or even throwing it onto canvas. Their work is characterized by a strong dependence on what appears to be accident and chance, but which is actually highly planned. Some Abstract Expressionist artists were concerned with adopting a peaceful and mystical approach to a purely abstract image. Usually there was no effort to represent subject matter. Not all work was abstract, nor was all work expressive, but it was generally believed that the spontaneity of the artists’ approach to their work would draw from and release the creativity of their unconscious minds. The expressive method of painting was often considered as important as the painting itself.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 9 – Ed Emshwiller\n\nAffine transformation\n\nIn geometry, an affine transformation or affine map or an affinity (from the Latin, affinis, “connected with”) is a transformation which preserves straight lines (i.e., all points lying on a line initially still lie on a line after transformation) and ratios of distances between points lying on a straight line (e.g., the midpoint of a line segment remains the midpoint after transformation). It does not necessarily preserve angles or lengths.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Plants\n\nAlpha channel\n\nthe concept of an alpha channel was introduced by Alvy Ray Smith in the late 1970s, and fully developed in a 1984 paper by Thomas Porter and Tom Duff. In a 2D image element, which stores a color for each pixel, additional data is stored in the alpha channel with a value between 0 and 1. A value of 0 means that the pixel does not have any coverage information and is transparent; i.e. there was no color contribution from any geometry because the geometry did not overlap this pixel. A value of 1 means that the pixel is opaque because the geometry completely overlapped the pixel.\n\nRelated Glossary Terms: Frame buffer\n\nTerm Source: Chapter 5 – Cornell and NYIT, Chapter 15 – Early hardware\n\nAnalog\n\nRelating to, or being a device in which data are represented by continuously variable, measurable, physical quantities, such as length, width, voltage, or pressure; a device having an output that is proportional to the input.\n\nRelated Glossary Terms: Digital\n\nTerm Source: Chapter 1 – Early analog computational devices\n\nAnisotropic reflection\n\nAnisotropic Reflections are just like regular reflections, except stretched or blurred based on the orientation of small grooves (bumps, fibers or scratches) that exist on a reflective surface. The kinds of objects include anything that has a fine grain that goes all in predominantly one direction. Good everyday examples would be hair, brushed metals, pots and pans, or reflections in water that’s being perturbed (for example, by falling rain).\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – Cal Tech and North Carolina State\n\nAntialiasing\n\nantialiasing is a software technique for diminishing jaggies – stair-step-like lines that should be smooth. Jaggies occur because the output device, the monitor or printer, doesn’t have a high enough resolution to represent a smooth line. Antialiasing reduces the prominence of jaggies by surrounding the stair-steps with intermediate shades of gray (for gray-scaling devices) or color (for color devices). Although this reduces the jagged appearance of the lines, it also makes them fuzzier.\n\nRelated Glossary Terms: A-buffer or Alpha-buffer, Jaggies\n\nTerm Source: Chapter 15 – Early hardware\n\nAPI\n\nAPI, an abbreviation of application program interface, is a set of routines, protocols, and tools for building software applications. A good API makes it easier to develop a program by providing all the building blocks. A programmer then puts the blocks together.\n\nMost operating environments, such as the Apple Quartz API, provide an API so that programmers can write applications consistent with the operating environment. Although APIs are designed for programmers, they are ultimately good for users because they guarantee that all programs using a common API will have similar interfaces. This makes it easier for users to learn new programs.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 15 – Graphics Accelerators\n\nAtkinson, Bill\n\nBill Atkinson is a computer engineer and photographer. Atkinson worked at Apple Computer from 1978 to 1990. He received his undergraduate degree from the University of California, San Diego, where Apple Macintosh developer Jef Raskin was one of his professors. Atkinson continued his studies as a graduate student at the University of Washington. Atkinson was part of the Apple Macintosh development team and was the creator of the ground-breaking MacPaint application, among others. He also designed and implemented QuickDraw, the fundamental toolbox that the Macintosh used for graphics. QuickDraw’s performance was essential for the success of the Macintosh’s graphical user interface. Atkinson also designed and implemented HyperCard, the first popular hypermedia system.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 16 – Apple Computer\n\nAugmented reality\n\nAugmented reality (AR) is a live, direct or indirect, view of a physical, real-world environment whose elements are augmented by computer-generated sensory input such as sound, video, graphics or GPS data. It is related to a more general concept called mediated reality, in which a view of reality is modified (possibly even diminished rather than augmented) by a computer. As a result, the technology functions by enhancing one’s current perception of reality. By contrast, virtual reality replaces the real world with a simulated one.\n\nRelated Glossary Terms: Virtual reality\n\nTerm Source: Chapter 17 – Virtual Reality\n\nB\n\nB-rep\n\nIn solid modeling and computer-aided design, boundary representation—often abbreviated as B-rep or BREP—is a method for representing shapes using the limits. A solid is represented as a collection of connected surface elements, the boundary between solid and non-solid.\n\nBoundary representation models are composed of two parts: topology and geometry (surfaces, curves and points). The main topological items are: faces, edges and vertices. A face is a bounded portion of a surface; an edge is a bounded piece of a curve and a vertex lies at a point. Other elements are the shell (a set of connected faces), the loop (a circuit of edges bounding a face) and loop-edge links (also known as winged edge links or half- edges) which are used to create the edge circuits. The edges are like the edges of a table, bounding a surface portion.\n\nRelated Glossary Terms: Solids modeling\n\nTerm Source: Chapter 10 – SDRC / Unigraphics\n\nBadler, Norman\n\nNorman I. Badler is professor of computer and information science at the University of Pennsylvania and has been on that faculty since 1974. He has been active in computer graphics since 1968, with research interests centered on computational connections between language and human action. Badler received the B.A. degree in creative studies mathematics from the University of California at Santa Barbara in 1970. He received the M.Sc. in mathematics in 1971 and the Ph.D. in computer science in 1975, both from the University of Toronto. He directs the SIG Center for Computer Graphics and the Center for Human Modeling and Simulation at Penn.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – Illinois-Chicago and University of Pennsylvania\n\nBaecker, Ron\n\nDr. Baecker is an expert in human-computer interaction (“HCI”) and user interface (“UI”) design. His research interests include work on electronic memory aids and other cognitive prostheses; computer applications in education; computer-supported cooperative learning, multimedia and new media; software visualization; groupware and computer-supported cooperative work; computer animation and interactive computer graphics; computer literacy and how computers can help us work better and safer; and entrepreneurship and the management of small business as well as the stimulation of innovation. Baecker is also interested in the social implications of computing, especially the issue of responsibility when humans and computers interact.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – UNC and Toronto\n\nBaraff, David\n\nDavid Baraff is a Senior Animation Scientist at Pixar Animation Studios. He received a BsE in Computer Science from the University of Pennsylvania, and a Ph.D. in Computer Science from Cornell. From 1992 to 1998 Baraff was a Professor of Robotics at Carnegie Mellon University in Pennsylvania. Simulation software from Physical Effects, Inc., a software company he co-founded, has been used in numerous movies at studios outside of Pixar. In 2006 he received a Scientific and Technical Academy Award for his work on cloth simulation.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Physical-based Modeling\n\nBarr, Al\n\nAl Barr, PhD RPI, now on the faculty at Caltech, works “to enhance the mathematical and scientific foundations of computer graphics, extending it beyond mere picture-making to the point that reconfigurable models have great predictive power.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – Cal Tech and North Carolina State\n\nBass, Saul\n\nSaul Bass was a graphic designer and filmmaker, perhaps best known for his design of film posters and motion picture title sequences. During his 40-year career Bass worked for some of Hollywood’s greatest filmmakers, including Alfred Hitchcock, Otto Preminger, Billy Wilder, Stanley Kubrick and Martin Scorsese. Amongst his most famous title sequences are the animated paper cut-out of a heroin addict’s arm for Preminger’s The Man with the Golden Arm, the credits racing up and down what eventually becomes a high-angle shot of the C.I.T. Financial Building in Hitchcock’s North by Northwest, and the disjointed text that races together and apart in Psycho.\n\nBass designed some of the most iconic corporate logos in North America, including the AT&T “bell” logo in 1969, as well as AT&T’s “globe” logo in 1983 after the breakup of the Bell System. He also designed Continental Airlines’ 1968 “jetstream” logo and United Airlines’ 1974 “tulip” logo which became some of the most recognized airline industry logos of the era.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Robert Abel and Associates\n\nBergeron, Philippe\n\nPhilippe Bergeron holds a B.Sc. and M.Sc. in Computer Science from University of Montreal. He wrote over a dozen articles on computer graphics. He co-directed the short “Tony de Peltrie,” the world’s first 3-D CGI human with emotions. It closed SIGGRAPH’85. He was technical research director at Digital Productions, and head of Production Research at Whitney/Demos Productions where he character animated “Stanley and Stella in Breaking The Ice.” Bergeron is also an actor and landscape designer.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 8 – Introduction\n\nBezier curves\n\nA Bézier curve is a parametric curve frequently used in computer graphics and related fields. Generalizations of Bézier curves to higher dimensions are called Bézier surfaces, of which the Bézier triangle is a special case.\n\nIn vector graphics, Bézier curves are used to model smooth curves that can be scaled indefinitely. “Paths,” as they are commonly referred to in image manipulation programs, are combinations of linked Bézier curves. Paths are not bound by the limits of rasterized images and are intuitive to modify. Bézier curves are also used in animation as a tool to control motion\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 14 – CGI and Effects in Films and Music Videos\n\nBézier, Pierre\n\nPierre Étienne Bézier was a French engineer and one of the founders of the fields of solid, geometric and physical modeling as well as in the field of representing curves, especially in CAD/CAM systems. As an engineer at Renault, he became a leader in the transformation of design and manufacturing, through mathematics and computing tools, into computer-aided design and three-dimensional modeling. Bézier patented and popularized, but did not invent the Bézier curves and Bézier surfaces that are now used in most computer-aided design and computer graphics systems.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 4 – Other research efforts\n\nBit BLT\n\nBit BLT (which stands for bit-block [image] transfer but is pronounced bit blit) is a computer graphics operation in which several bitmaps are combined into one using a raster operator.\n\nThe operation involves at least two bitmaps, a source and destination, possibly a third that is often called the “mask” and sometimes a fourth used to create a stencil. The pixels of each are combined bitwise according to the specified raster operation (ROP) and the result is then written to the destination.\n\nThis operation was created by Dan Ingalls, Larry Tesler, Bob Sproull, and Diana Merry at Xerox PARC in November 1975 for the Smalltalk-72 system.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 15 – Early hardware, Chapter 16 – Xerox PARC\n\nBlinn, James\n\nJames F. Blinn is a computer scientist who first became widely known for his work as a computer graphics expert at NASA’s Jet Propulsion Laboratory (JPL), particularly his work on the pre-encounter animations for the Voyager project, his work on the Carl Sagan Cosmos documentary series and the research of the Blinn–Phong shading model.\n\nBlinn devised new methods to represent how objects and light interact in a three dimensional virtual world, like environment mapping and bump mapping. He is well known for creating animation for three television series: Carl Sagan’s Cosmos: A Personal Voyage; Project MATHEMATICS!; and the pioneering instructional graphics in The Mechanical Universe. His simulations of the Voyager spacecraft visiting Jupiter and Saturn have been seen widely. He is now a graphics fellow at Microsoft Research. Blinn also worked at the New York Institute of Technology in the summer of 1976\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 4 – JPL and National Research Council of Canada\n\nBlue Screen\n\nChroma key compositing, or chroma keying, is a special effects / post-production technique for compositing (layering) two images or video streams together, used heavily in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture and videogame industries. A color range in the top layer is made transparent, revealing another image behind. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as color keying, color-separation overlay (CSO), or by various terms for specific color- related variants such as green screen, and blue screen – chroma keying can be done with backgrounds of any color that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from most human skin colors and no part of the subject being filmed or photographed may duplicate a color used in the background\n\nRelated Glossary Terms: Chroma key compositing\n\nTerm Source: Chapter 14 – CGI and Effects in Films and Music Videos\n\nBrooks, Frederick\n\nFrederick Phillips Brooks, Jr. is a software engineer and computer scientist, best known for managing the development of IBM’s System/360 family of computers and the OS/360 software support package, then later writing candidly about the process in his seminal book The Mythical Man-Month. Brooks has received many awards, including the National Medal of Technology in 1985 and the Turing Award in 1999. It was in The Mythical Man- Month that Brooks made the now-famous statement: “Adding manpower to a late software project makes it later.” This has since come to be known as the Brooks’s law.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 17 – Interaction\n\nBump mapping\n\nBump mapping is a technique in computer graphics for simulating bumps and wrinkles on the surface of an object. This is achieved by perturbing the surface normals of the object and using the perturbed normal during lighting calculations. The result is an apparently bumpy surface rather than a smooth surface although the surface of the underlying object is not actually changed. Bump mapping was introduced by Blinn in 1978\n\nRelated Glossary Terms: Blinn, University of Utah\n\nTerm Source:\n\nBurtnyk, Nestor\n\nNRC scientists Nestor Burtnyk and Marceli Wein, were recently honored at the Festival of Computer Animation in Toronto. They were recognized as Fathers of Computer Animation Technology in Canada. Burtnyk, who began his career with NRC in 1950, started Canada’s first substantive computer graphics research project in the 1960s. Wein, who joined this same project in 1966, had been exposed to the potential of computer imaging while studying at McGill. He teamed up with Burtnyk to pursue this promising field.\n\nOne of their main contributions was the Academy Award nominated film “Hunger/La Faim” (produced by the National Film Board of Canada) using their famous key-frame animation approach and system.\n\nRelated Glossary Terms: Wein, Marceli\n\nTerm Source: Chapter 4 – JPL and National Research Council of Canada\n\nBuxton, Bill\n\nWilliam Arthur Stewart “Bill” Buxton (born March 10, 1949) is a Canadian computer scientist and designer. He is currently a Principal researcher at Microsoft Research. He is known for being one of the pioneers in the human–computer interaction field.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – UNC and Toronto\n\nC\n\nCAD\n\nCAD – computer-aided design\n\nThe use of computer programs and systems to design detailed two- or three-dimensional models of physical objects, such as mechanical parts, buildings, and molecules.\n\nRelated Glossary Terms: CADD, CAE, CAID, CAM\n\nTerm Source: Chapter 3 – General Motors DAC, Chapter 10 – Introduction, Chapter 10 – Introduction\n\nCADD\n\nCADD – Computer Aided Drafting and Design, Computer-Aided Design & Drafting, or Computer-Aided Design Development\n\nThe use of the computer to help with the drafting of product plans.\n\nRelated Glossary Terms:CAD, CAE, CAID, CAM\n\nTerm Source: Chapter 3 – General Motors DAC Chapter 10 – Introduction\n\nCAE\n\nCAE – computer-aided engineering\n\nUse of computers to help with all phases of engineering design work. Like computer aided design, but also involving the conceptual and analytical design steps.\n\nRelated Glossary Terms: CADD, CAD, CAID, CAM\n\nTerm Source: Chapter 10 – Introduction Chapter 10 – SDRC / Unigraphics\n\nCAID\n\nComputer-aided industrial design (CAID) is CAD adapted and specialized for aesthetic design. From a designer’s point of view, CAD is for the pocket-protector brigade, while CAID is for the creative.\n\nRelated Glossary Terms: CADD, CAE, CAD, CAM\n\nTerm Source: Chapter 8 – Alias Research\n\nCAM\n\nCAM – computer-aided manufacturing\n\nThe process of using specialized computers to control, monitor, and adjust tools and machinery in manufacturing.\n\nRelated Glossary Terms: CADD, CAE, CAID, CAD\n\nDrag related terms here\n\nTerm Source: Chapter 10 – Introduction, Chapter 10 – MCS / CalComp / McAuto\n\nCarpenter, Loren\n\nLoren Carpenter is a computer graphics researcher and developer. He is co-founder and chief scientist of Pixar Animation Studios and the co-inventor of the Reyes rendering algorithm. He is one of the authors of the PhotoRealistic RenderMan software which implements Reyes and is used to create the imagery for Pixar’s movies. Following Disney’s acquisition of Pixar, Carpenter became a Senior Research Scientist at Disney Research.[1]\n\nCarpenter began work at Boeing Computer Services in Seattle, Washington. In 1980 he gave a presentation at the SIGGRAPH conference, in which he showed “Vol Libre”, a 2 minute computer generated movie. This showcased his software for generating and rendering fractally generated landscapes. At Pixar Carpenter worked on the “genesis effect” scene of Star Trek II: The Wrath of Khan, which featured an entire fractally- landscaped planet.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Noise functions and Fractals\n\nCathode Ray Tube\n\nA vacuum tube generating a focused beam of electrons that can be deflected by electric fields, magnetic fields, or both. The terminus of the beam is visible as a spot or line of luminescence caused by its impinging on a sensitized screen at one end of the tube. Cathode-ray tubes are used to study the shapes of electric waves, to reproduce images in television receivers, to display alphanumeric and graphical information on computer monitors, as an indicator in radar sets, etc. Abbreviation: CRT\n\nRelated Glossary Terms: Vacuum tube\n\nTerm Source: Chapter 1 – Electronic devices\n\nCaustics\n\nIn optics, a caustic or caustic network is the envelope of light rays reflected or refracted by a curved surface or object, or the projection of that envelope of rays on another surface. The caustic is a curve or surface to which each of the light rays is tangent, defining a boundary of an envelope of rays as a curve of concentrated light. Therefore in an image the caustics can be the patches of light or their bright edges. These shapes often have cusp singularities.\n\nIn computer graphics, most modern rendering systems support caustics. Some of them even support volumetric caustics. This is accomplished by raytracing the possible paths of the light beam through the glass, accounting for the refraction and reflection. Photon mapping is one implementation of this.\n\nRelated Glossary Terms: Photon mapping, Ray-trace\n\nTerm Source: Chapter 20 – CG Icons\n\nCharactron\n\na cathode-ray tube used in information display units to reproduce letters, numbers, map symbols, and other characters. Invented in the USA in 1941, the Charactron is an instantaneous-operation numerical indicator tube.\n\nIn the Charactron, the characters reproduced on the tube’s screen are formed by means of a matrix, which is an opaque plate containing a set of 64 to 200 microscopic openings in the shape of the characters to be displayed. The matrix is located in the path of the electron beam between two deflection systems. The first deflection system guides the beam to the desired character on the matrix; the second system guides the shaped beam to the desired location on the screen. When the beam passes through the matrix, the cross section of the beam takes on the shape of the character through which it has passed. Hence, an image of the desired character—rather than a point, as in ordinary cathode-ray tubes—is illuminated at the place where the beam strikes the screen.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 3 – Other output devices\n\nChroma key compositing\n\nChroma key compositing, or chroma keying, is a special effects / post-production technique for compositing (layering) two images or video streams together, used heavily in many fields to remove a background from the subject of a photo or video – particularly the newscasting, motion picture and video game industries. A color range in the top layer is made transparent, revealing another image behind. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as color keying, color-separation overlay (CSO), or by various terms for specific color- related variants such as green screen, and blue screen – chroma keying can be done with backgrounds of any color that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from most human skin colors and no part of the subject being filmed or photographed may duplicate a color used in the background\n\nRelated Glossary Terms: Blue Screen\n\nTerm Source:\n\nClipping\n\nAny procedure which identifies that portion of a picture which is either inside or outside a region to be displayed on a CRT or screen is referred to as a clipping algorithm or clipping.\n\nThe region against which an object is to be clipped is called clipping window.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 3 – General Motors DAC, Chapter 4 – MIT and Harvard\n\nColormap\n\nColor mapping is a function that maps (transforms) the colors of one (source) image to the colors of another (target) image. A color mapping may be referred to as the algorithm that results in the mapping function or the algorithm that transforms the image colors. Color mapping is also sometimes called color transfer or, when grayscale images are involved, brightness transfer function (BTF).\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 18 – Hardware and Software\n\nCombinatorial geometry\n\nComputational (sometimes referred to as combinatorial) geometry is a branch of computer science devoted to the study of algorithms which can be stated in terms of geometry. Some purely geometrical problems arise out of the study of computational geometric algorithms, and such problems are also considered to be part of computational geometry.\n\nThe main impetus for the development of computational geometry as a discipline was progress in computer graphics and computer-aided design and manufacturing (CAD/CAM), but many problems in computational geometry are classical in nature, and may come from mathematical visualization.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – MAGI\n\nComputational fluid dynamics\n\nComputational fluid dynamics, usually abbreviated as CFD, is a branch of fluid mechanics that uses numerical methods and algorithms to solve and analyze problems that involve fluid flows. Computers are used to perform the calculations required to simulate the interaction of liquids and gases with surfaces defined by boundary conditions.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 18 – Introduction\n\nComputer graphics\n\npictorial computer output produced on a display screen, plotter, or printer.\n\nthe study of the techniques used to produce such output.\n\nthe use of a computer to produce and manipulate pictorial images on a video screen, as in animation techniques or the production of audiovisual aids\n\nRelated Glossary Terms:\n\nTerm Source: Preface – Preface\n\nComputer-generated art\n\nDigital art is a general term for a range of artistic works and practices that use digital technology as an essential part of the creative and/or presentation process. Since the 1970s, various names have been used to describe the process including computer art, computer-generated art, and multimedia art, and digital art is itself placed under the larger umbrella term new media art.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 9 – Lillian Schwartz\n\nConstructivist\n\nConstructivism, Russian Konstruktivizm, Russian artistic and architectural movement that was first influenced by Cubism and Futurism and is generally considered to have been initiated in 1913 with the “painting reliefs”—abstract geometric constructions—of Vladimir Tatlin.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 9 – Manfred Mohr\n\nContinuous shading\n\nContinuous shading is the smooth shading of polygons with bilinear interpolation. In other words, the brightness of the shading varies within individual polygons, without altering the color being applied. It is often referred to as Gouraud shading.\n\nRelated Glossary Terms: Gouraud shading\n\nTerm Source: Chapter 17 – Virtual Reality\n\nContour plots\n\nA contour plot is a graphical technique for representing a 3-dimensional surface by plotting constant z slices, called contours, on a 2-dimensional format. That is, given a value for z, lines are drawn for connecting the (x,y) coordinates where that z value occurs.\n\nThe contour plot is an alternative to a 3-D surface plot.\n\nRelated Glossary Terms: Isolines, Isosurfaces\n\nTerm Source: Chapter 18 – Algorithms\n\nCoons, Steven\n\nSteven Anson Coons (March 7, 1912 – August 1979) was an early pioneer in the field of computer graphical methods. He was a professor at the Massachusetts Institute of Technology in the Mechanical Engineering Department. Steven Coons had a vision of interactive computer graphics as a design tool to aid the engineer.\n\nThe Association for Computing Machinery SIGGRAPH has an award named for Coons. The Steven Anson Coons Award for Outstanding Creative Contributions to Computer Graphics is given in odd-numbered years to an individual to honor that person’s lifetime contribution to computer graphics and interactive techniques. It is considered the field’s most prestigious award.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 4 – MIT and Harvard\n\nCore memory\n\nMagnetic-core memory was the predominant form of random-access computer memory for 20 years (circa 1955–75). It uses tiny magnetic toroids (rings), the cores, through which wires are threaded to write and read information. Each core represents one bit of information. The cores can be magnetized in two different ways (clockwise or counterclockwise) and the bit stored in a core is zero or one depending on that core’s magnetization direction. The wires are arranged to allow an individual core to be set to either a “one” or a “zero”, and for its magnetization to be changed, by sending appropriate electric current pulses through selected wires. The process of reading the core causes the core to be reset to a “zero”, thus erasing it. This is called destructive readout.\n\nSuch memory is often just called core memory, or, informally, core. Although core memory had been superseded by semiconductor memory by the end of the 1970s, memory is still occasionally called “core”\n\nEach core was a donut shaped metal, often ferrite, that had two electrical wires strung through it. Neither wire was strong enough in power to change the state of the magnetism of the core, but together they were. Thus it was a randomly addressable storage and access medium.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 2 – Whirlwind and SAGE\n\nCray\n\nCray Inc.is an American supercomputer manufacturer based in Seattle, Washington. The company’s predecessor, Cray Research, Inc. (CRI), was founded in 1972 by computer designer Seymour Cray. Seymour Cray went on to form the spin-off Cray Computer Corporation (CCC), in 1989, which went bankrupt in 1995, while Cray Research was bought by SGI the next year. Cray Inc. was formed in 2000 when Tera Computer Company purchased the Cray Research Inc. business from SGI and adopted the name of its acquisition. Their computers included the Cray-1, Cray-2, and Cray X-MP\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Digital Productions (DP)\n\nCSG\n\nConstructive solid geometry (CSG) is a technique used in solid modeling. Constructive solid geometry allows a modeler to create a complex surface or object by using Boolean operators to combine objects. Often CSG presents a model or surface that appears visually complex, but is actually little more than cleverly combined or decombined objects.\n\nIn 3D computer graphics and CAD CSG is often used in procedural modeling. CSG can also be performed on polygonal meshes, and may or may not be procedural and/or parametric.\n\nRelated Glossary Terms: Solids modeling\n\nTerm Source: Chapter 10 – Introduction\n\nCsuri, Charles\n\nCharles Csuri is best known for pioneering the field of computer graphics, computer animation and digital fine art, creating the first computer art in 1964. Csuri has been recognized as the father of digital art and computer animation by Smithsonian, and as a leading pioneer of computer animation by the Museum of Modern Art (MoMA) and The Association for Computing Machinery Special Interest Group Graphics (ACM SIGGRAPH). Between 1971 and 1987, while a senior professor at the Ohio State University, Charles Csuri founded the Computer Graphics Research Group, the Ohio Super Computer Graphics Project, and the Advanced Computing Center for Art and Design, dedicated to the development of digital art and computer animation. Csuri was co-founder of Cranston/ Csuri Productions (C/CP), one of the world’s first computer animation production companies.\n\nRelated Glossary Terms: The Ohio State University\n\nTerm Source: Chapter 4 – University of Utah, Chapter 4 – The Ohio State University\n\nCuba, Larry\n\nLarry Cuba is a computer-animation artist who became active in the late 1970s and early 80s. He received A.B. from Washington University in St. Louis in 1972 and his Master’s Degree from California Institute of the Arts In 1975, John Whitney, Sr. invited Cuba to be the programmer on one of his films. The result of this collaboration was “Arabesque”. Subsequently, Cuba produced three more computer-animated films: 3/78 (Objects and Transformations), Two Space, and Calculated Movements. Cuba also produced computer graphics for Star Wars Episode IV: A New Hope in 1977 on Tom DeFanti’s Grass system at EVL. His animation of the Death Star is shown to pilots in the Rebel Alliance. Cuba received grants for his work from the American Film Institute and The National Endowment for the Arts\n\nRelated Glossary Terms: EVL\n\nTerm Source: Chapter 9 – Larry Cuba\n\nD\n\nDAC-1\n\nDAC-1, for Design Augmented by Computer, was one of the earliest graphical computer aided design systems. Developed by General Motors, IBM was brought in as a partner in 1960 and the two developed the system and released it to production in 1963. It was publicly unveiled at the fall Joint Computer Conference in Detroit 1964. GM used the DAC system, continually modified, into the 1970s when it was succeeded by CADANCE.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 3 – General Motors DAC\n\nData-driven\n\nComputer graphics visualization has evolved by focusing algorithmic approaches to the synthesis of imagery. Recently, various methods have been introduced to exploit pre- recorded data to improve the performance and/or realism of things like dynamic deformations. This data can guide the algorithms, or in some cases determine which algorithms are used in the synthesis process. It has seen successful usage in visualizations of music, dynamic deformation of faces, soft volumetric tissue, and cloth, as examples.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Data-driven Imagery\n\nDataflow\n\nDataflow is a software architecture based on the idea that changing the value of a variable should automatically force recalculation of the values of variables which depend on its value.\n\nThere have been a few programming languages created specifically to support dataflow. In particular, many (if not most) visual programming languages have been based on the idea of dataflow.\n\nRelated Glossary Terms: Modular visualization environments\n\nTerm Source: Chapter 18 – Visualization Systems\n\nDebevec, Paul\n\nPaul Debevec is a researcher in computer graphics at the University of Southern California’s Institute for Creative Technologies. He is best known for his pioneering work in high dynamic range imaging and image-based modeling and rendering. Debevec received a Ph.D. in computer science from UC Berkeley in 1996; his thesis research was in photogrammetry, or the recovery of the 3D shape of an object from a collection of still photographs taken from various angles.In 1997 he and a team of students produced The Campanile Movie, a virtual flyby of UC Berkeley’s famous Campanile tower. Debevec’s more recent research has included methods for recording real-world illumination for use in computer graphics; a number of novel inventions for recording ambient and incident light have resulted from the work of Debevec and his team, including the light stage, of which five or more versions have been constructed, each an evolutionary improvement over the previous. Techniques based on Debevec’s work have been used in several major motion pictures, including The Matrix (1999), Spider-Man 2 (2004), King Kong (2005), Superman Returns (2006), Spider-Man 3 (2007), and Avatar (2009). In addition Debevec and his team have produced several short films that have premiered at SIGGRAPH’s annual Electronic Theater, including Fiat Lux (1999) and The Parthenon (2004).\n\nDebevec, along with Tim Hawkins, John Monos and Mark Sagar, was awarded a 2009 Scientific and Engineering Award from the Academy of Motion Picture Arts and Sciences for the design and engineering of the Light Stage capture devices and the image-based facial rendering system developed for character relighting in motion pictures.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Global Illumination\n\nDeFanti, Tom\n\nTom DeFanti is a computer graphics researcher and pioneer. His work has ranged from early computer animation, to scientific visualization, virtual reality, and grid computing. He is a distinguished professor of Computer Science at the University of Illinois at Chicago, and a research scientist at the California Institute for Telecommunications and Information Technology. DeFanti did his PhD work in the early 1970s at Ohio State University, under Charles Csuri in the Computer Graphics Research Group. For his dissertation, he created the GRASS programming language, a three-dimensional, real-time animation system usable by computer novices.\n\nIn 1973, he joined the faculty of the University of Illinois at Chicago. With Dan Sandin, he founded the Circle Graphics Habitat, now known as the Electronic Visualization Laboratory (EVL). At UIC, DeFanti further developed the GRASS language, and later created an improved version, ZGRASS. The GRASS and ZGRASS languages have been used by a number of computer artists, including Larry Cuba, in his film 3/78 and the animated Death Star sequence for Star Wars. Later significant work done at EVL includes development of the graphics system for the Bally home computer, invention of the first data glove, co- editing the 1987 NSF-sponsored report Visualization in Scientific Computing that outlined the emerging discipline of scientific visualization, invention of PHSColograms, and invention of the CAVE Automatic Virtual Environment.\n\nDeFanti contributed greatly to the growth of the SIGGRAPH organization and conference. He served as Chair of the group from 1981 to 1985, co-organized early film and video presentations (which became the Electronic Theatre), and in 1979 started the SIGGRAPH Video Review, a video archive of computer graphics research.\n\nDeFanti is a Fellow of the Association for Computing Machinery. He has received the 1988 ACM Outstanding Contribution Award, the 2000 SIGGRAPH Outstanding Service Award, and the UIC Inventor of the Year Award.\n\nRelated Glossary Terms:EVL, Sandin, Dan\n\nTerm Source: Chapter 5 – Illinois-Chicago and University of Pennsylvania\n\nDeGraf, Brad\n\nDeGraf has been an innovator in computer animation in the entertainment industry since 1982, particularly in the areas of realtime characters, ride films, and the Web. He founded and/or managed several ground-breaking animation studios including Protozoa (aka Dotcomix), Colossal Pictures Digital Media, deGraf/Wahrman, and Digital Productions. In 2000, Wired called Brad “an icon in the world of 3D animation”. Brad is currently CEO and co-founder (with Michael Tolson formerly of XAOS and Envoii) of Sociative Inc.\n\nHis film credits include: Duke2000.com, a campaign with Garry Trudeau to get his Ambassador Duke character elected president; Moxy, emcee for the Cartoon Network, the first virtual character for television; Floops, the first Web episodic cartoon; Peter Gabriel’s Grammy award- winning video, Steam; “The Funtastic World of Hanna-Barbera”, the first computer-generated ride film; Feature films “The Last Starfighter”, “2010′′, “Jetsons: the Movie”, “Robocop 2′′,\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Digital Productions (DP)\n\nDemos, Gary\n\nGary Demos was one of the principals of the Motion Picture Project at Information International Inc. (1974–1981), Digital Productions (1981–1986), and Whitney/Demos Productions (1986–1988). In 1988 Demos formed DemoGraFX, which became involved in technology research for advanced television systems and digital cinema, as well as consulting and contracting for computer companies and visual effects companies. DemoGraFX was sold to Dolby Labs in 2003. Demos attended Cal Tech and worked with Ivan Sutherland at E&S and later at the Picture/Design Group before co-founding the graphics group at Triple-I.\n\nRelated Glossary Terms: DOA\n\nTerm Source: Chapter 6 – Digital Productions (DP)\n\nDiffuse reflection\n\nDiffuse reflection is the reflection of light from a surface such that an incident ray is reflected at many angles rather than at just one angle as in the case of specular reflection. An illuminated ideal diffuse reflecting surface will have equal luminance from all directions in the hemisphere surrounding the surface (Lambertian reflectance).\n\nRelated Glossary Terms: Lambertian, Specular reflection\n\nTerm Source:\n\nDigital\n\nA description of data which is stored or transmitted as a sequence of discrete symbols from a finite set, most commonly this means binary data represented using electronic or electromagnetic signals.\n\nRelated Glossary Terms: Analog\n\nTerm Source: Chapter 1 – Early digital computational devices\n\nDigital compositing\n\nCompositing is the combining of visual elements from separate sources into single images, often to create the illusion that all those elements are parts of the same scene. Live-action shooting for compositing is variously called “chroma key”, “blue screen”, “green screen” and other names. Today, most, though not all, compositing is achieved through digital image manipulation. Pre-digital compositing techniques, however, go back as far as the trick films of Georges Méliès in the late 19th century; and some are still in use.\n\nRelated Glossary Terms:\n\nTerm Source:\n\nDigital painting\n\nDigital painting differs from other forms of digital art, particularly computer-generated art, in that it does not involve the computer rendering from a model. The artist uses painting techniques to create the digital painting directly on the computer. All digital painting programs try to mimic the use of physical media through various brushes and paint effects. Included in many programs are brushes that are digitally styled to represent the traditional style like oils, acrylics, pastels, charcoal, pen and even media such as airbrushing. There are also certain effects unique to each type of digital paint which portraying the realistic effects of say watercolor on a digital ‘watercolor’ painting\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 11 – Pixar\n\nDigital Scene Simulation\n\nDigital Scene Simulation was Digital Productions’ philosophy for creating visual excellence in computer-generated imagery and simulation. The approach it advocated required the use of powerful hardware, sophisticated software, and top creative talent. With a CRAY supercomputer at the heart of its computer network and its own proprietary image rendering and simulation software, Digital Productions was revolutionizing state-of-the-art computer graphics. At the forefront of computer graphics technology, Digital Productions was redefining traditional methods of visual communications and creating new forms of self-expression, instruction, and entertainment.\n\n(From the Abstract of the invited paper “Digital scene simulations: The synergy of computer technology and human creativity”, by Demos, G.; Brown, M.D.; and Weinberg, R.A. Proceedings of the IEEE, Volume: 72 , Issue: 1, Jan. 1984, Page(s): 22 – 31 )\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Information International Inc. (Triple-I), Chapter 6 – Information International Inc. (Triple-I)\n\nDigitize\n\nto convert (data) to digital form for use in a computer.\n\nto convert (analogous physical measurements) to digital form.\n\nRelated Glossary Terms: Digital\n\nTerm Source: Chapter 4 – MIT and Harvard\n\nDOA\n\nDOA == Digital/Omnibus/Abel\n\nIn about 1985, the Digital Productions board went along with a hostile takeover bid by Omnibus and their leader, John Pennie, breaking the agreement with partners John Whitney Jr. and Gary Demos. Later that same year, Omnibus also purchased Robert Abel and Associates. The huge amount of debt, much of it provided by the Royal Bank of Canada, proved to be a burden for the company, and they declared bankruptcy) only 9 months later on April 13th of 1987. The closure had significant rippling effects on the CG industry, and impacted the lives of many top-flight CG professionals.\n\nRelated Glossary Terms: Abel, Robert, Demos, Gary, Pennie, John\n\nTerm Source: Chapter 8 – Wavefront Technologies\n\nDrum plotter\n\nA graphics output device that draws lines with a continuously moving pen on a sheet of paper rolled around a rotating drum that moves the paper in a direction perpendicular to the motion of the pen.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 10 – MCS / CalComp / McAuto\n\nDynamics\n\nIn the field of physics, the study of the causes of motion and changes in motion is dynamics. In other words the study of forces and why objects are in motion. Dynamics includes the study of the effect of torques on motion. These are in contrast to kinematics, the branch of classical mechanics that describes the motion of objects without consideration of the causes leading to the motion.\n\nRelated Glossary Terms: Kinematics\n\nTerm Source: Chapter 8 – Introduction\n\nE\n\nElin, Larry\n\nLarry Elin started his career as an animator at Mathematical Applications Group, Inc., in Elmsford, NY, in 1973, one of the first 3-D computer animation companies. By 1980, Elin had become head of production, and hired Chris Wedge, who later founded Blue Sky Studios, among others. Elin and Wedge were the key animators on MAGI’s work on the feature film Tron, which included the Lightcycle, Recognizer, and Tank sequences. Elin later became executive producer at Kroyer Films, which produced the animation for FernGully: The Last Rainforest.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – MAGI\n\nEllipsoids\n\na geometric surface, symmetrical about the three coordinate axes, whose plane sections are ellipses or circles. Standard equation: x2/a2 + y2/b2 + z2/c2 = 1, where ±a, ±b, ±c are the intercepts on the x-, y-, and z- axes\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 13 – Other Approaches\n\nEm, David\n\nDavid Em is one of the first artists to make art with pixels. He was born in Los Angeles and grew up in South America. He studied painting at the Pennsylvania Academy of the Fine Arts and film directing at the American Film Institute. Em created digital paintings at the Xerox Palo Alto Research Center (Xerox PARC) in 1975 with SuperPaint, “the first complete digital paint system”. In 1976, he made an articulated 3D digital insect at Information International, Inc. (III) that could walk, jump, and fly, the first 3D character created by a fine artist.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 9 – David Em\n\nEmshwiller, Ed\n\nEmshwiller was one of the earliest video artists. With Scape-Mates (1972), he began his experiments in video, combining computer animation with live-action. In 1979, he produced Sunstone, a groundbreaking three-minute 3-D computer-generated video made at the New York Institute of Technology with Alvy Ray Smith. Now in the Museum of Modern Art’s video collection, Sunstone was exhibited at SIGGRAPH 79, the 1981 Mill Valley Film Festival and other festivals. In 1979, it was shown on WNET’s Video/Film Review, and a single Sunstone frame was used on the front cover of Fundamentals of Interactive Computer Graphics, published in 1982 by Addison-Wesley\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 9 – Ed Emshwiller\n\nEngelbart, Douglas C.\n\nDouglas Carl Engelbart (born January 30, 1925) is an American inventor, and an early computer and internet pioneer. He is best known for his work on the challenges of human– computer interaction, particularly while at his Augmentation Research Center Lab in SRI International, resulting in the invention of the computer mouse,[3] and the development of hypertext, networked computers, and precursors to graphical user interfaces.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 3 – Input devices\n\nENIAC\n\nENIAC stands for Electronic Numerical Integrator and Computer. It was a secret World War II military project carried out by John Mauchly, a 32-year-old professor at Penn’s Moore School of Electrical Engineering and John Presper Eckert Jr., a 24-year-old genius inventor and lab assistant. The challenge was to speed up the tedious mathematical calculations needed to produce artillery firing tables for the Army. ENIAC was not completed until after the war but it performed until 1955 at Aberdeen, Md. ENIAC was enormous. It contained 17,500 vacuum tubes, linked by 500,000 soldered connections. It filled a 50-foot long basement room and weighed 30 tons. Today, a single microchip, no bigger than a fingernail, can do more than those 30 tons of hardware.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 2 – Programming and Artistry\n\nEnvironment mapping\n\nEnvironment mapping is a technique that simulates the results of ray-tracing. Because environment mapping is performed using texture mapping hardware, it can obtain global reflection and lighting results in real-time.\n\nEnvironment mapping is essentially the process of pre-computing a texture map and then sampling texels from this texture during the rendering of a model. The texture map is a projection of 3D space to 2D space.\n\nRelated Glossary Terms: Reflection mapping\n\nTerm Source:\n\nEuler operators\n\nIn mathematics, Euler operators are a small set of operators to create polygon meshes. They are closed and sufficient on the set of meshes, and they are invertible.\n\nA “polygon mesh” can be thought of as a graph, with vertices, and with edges that connect these vertices. In addition to a graph, a mesh has also faces: Let the graph be drawn (“embedded”) in a two-dimensional plane, in such a way that the edges do not cross (which is possible only if the graph is a planar graph). Then the contiguous 2D regions on either side of each edge are the faces of the mesh.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – Other labs and NSF\n\nEvans, David\n\nDavid Cannon Evans (February 24, 1924 – October 3, 1998) was the founder of the computer science department at the University of Utah and co-founder (with Ivan Sutherland) of Evans & Sutherland, a computer firm which is known as a pioneer in the domain of computer-generated imagery\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 4 – University of Utah\n\nF\n\nFacial animation\n\nComputer facial animation is primarily an area of computer graphics that encapsulates models and techniques for generating and animating images of the human head and face. Due to its subject and output type, it is also related to many other scientific and artistic fields from psychology to traditional animation. The importance of human faces in verbal and non-verbal communication and advances in computer graphics hardware and software have caused considerable scientific, technological, and artistic interests in computer facial animation.\n\nRelated Glossary Terms: Kinematics, Motion capture\n\nTerm Source: Chapter 8 – Alias/Wavefront\n\nFarnsworth, Philo\n\nPhilo Taylor Farnsworth was an American inventor and television pioneer. Although he made many contributions that were crucial to the early development of all-electronic television, he is perhaps best known for inventing the first fully functional all-electronic image pickup device (video camera tube), the “image dissector”, the first fully functional and complete all-electronic television system, and for being the first person to demonstrate such a system to the public. Farnsworth developed a television system complete with receiver and camera, which he produced commercially in the firm of the Farnsworth Television and Radio Corporation, from 1938 to 1951.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 1 – Electronic devices\n\nFetter, William\n\nWilliam Fetter was a graphic designer for Boeing Aircraft Co. and in 1960, was credited with coining the phrase “Computer Graphics” to describe what he was doing at Boeing at the time.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 2 – Programming and Artistry\n\nFilm recorder\n\nA Film Recorder is a graphical output device for transferring digital images to photographic film.\n\nAll film recorders typically work in the same manner. The image is fed from a host computer as a raster stream over a digital interface. A film recorder exposes film through various mechanisms; flying spot (early recorders; photographing a high resolution video monitor; electron beam recorder (Sony); a CRT scanning dot (Celco); focused beam of light from an LVT (Light Valve Technology) recorder; a scanning laser beam (ARRILASER); or recently, full-frame LCD array chips;\n\nRelated Glossary Terms: Optical printers\n\nTerm Source: Chapter 6 – Digital Effects\n\nFinite Element Analysis\n\nThe finite element method (FEM) (its practical application often known as finite element analysis (FEA)) is a numerical technique for finding approximate solutions of partial differential equations (PDE) as well as integral equations. The solution approach is based either on eliminating the differential equation completely (steady state problems), or rendering the PDE into an approximating system of ordinary differential equations, which are then numerically integrated using standard techniques such as Euler’s method, Runge- Kutta, etc.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 10 – SDRC / Unigraphics\n\nFlicker\n\na visual sensation, often seen in a television or CRT image, produced by periodic fluctuations, often due to the rate of refreshing the image on the screen, in the brightness of light at a frequency below that covered by the persistence of vision\n\nRelated Glossary Terms: Cathode Ray Tube\n\nTerm Source: Chapter 3 – Other output devices\n\nFloating point\n\nA real number (that is, a number that can contain a fractional part). The following are floating-point numbers: 3.0, -111.5, 1⁄2, 3E-5 The last example is a computer shorthand for scientific notation. It means 3*10-5 (or 10 to the negative 5th power multiplied by 3).\n\nThe term floating point is derived from the fact that there is no fixed number of digits before and after the decimal point; that is, the decimal point can float. There are also representations in which the number of digits before and after the decimal point is set, called fixed-point representations. In general, floating-point representations are slower and less accurate than fixed-point representations, but they can handle a larger range of numbers.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 15 – Graphics Accelerators\n\nFoonly F1\n\nFoonly was the computer company formed by Dave Poole, who was one of the principal Super Foonly designers. The Foonly was to be a successor to the DEC PDP-10, and was to have been built (along with a new operating system) by the Super Foonly project at the Stanford Artificial Intelligence Laboratory (SAIL). The intention was to leapfrog from the old DEC timesharing system SAIL was then running to a new generation, bypassing TENEX which at that time was the ARPANET standard. ARPA funding for both the Super Foonly and the new operating system was cut in 1974. The design for Foonly contributed greatly to the design of the PDP-10 model KL10. One of the prototype models was built for Information International Incorporated (Triple-I) and was used to compute CG for TRON.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Information International Inc. (Triple-I)\n\nForced perspective\n\nForced perspective is a technique that employs optical illusion to make an object appear farther away, closer, larger or smaller than it actually is. It is used primarily in photography, filmmaking and architecture. It manipulates human visual perception through the use of scaled objects and the correlation between them and the vantage point of the spectator or camera.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 14 – CGI and Effects in Films and Music Videos\n\nForeshortening\n\nForeshortening occurs when an object appears compressed when seen from a particular viewpoint, and the effect of perspective causes distortion. Foreshortening is a particularly effective artistic device, used to give the impression of three-dimensional volume and create drama in a picture.\n\nForeshortening is most successful when accurately rendered on the picture plane to create the illusion of a figure in space.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 20 – CG Icons\n\nForm factor\n\nIn radiative heat transfer, a form factor is the proportion of all that radiation which leaves surface A and strikes surface B.\n\nIn radiosity calculations, the “form factor” describes the fraction of energy which leaves one surface and arrives at a second surface. It takes into account the distance between the surfaces, computed as the distance between the center of each of the surfaces, and their orientation in space relative to each other, computed as the angle between each surface’s normal vector and a vector drawn from the center of one surface to the center of the other surface. It is a dimensionless quantity.\n\nRelated Glossary Terms: Radiosity\n\nTerm Source: Chapter 19 – Global Illumination\n\nFractal\n\nA geometrical or physical structure having an irregular or fragmented shape at all scales of measurement between a greatest and smallest scale such that certain mathematical or physical properties of the structure, as the perimeter of a curve or the flow rate in a porous medium, behave as if the dimensions of the structure (fractal dimensions) are greater than the spatial dimensions.\n\nA fractal is a rough or fragmented geometric shape that can be subdivided in parts, each of which is (at least approximately) a reduced-size copy of the whole. Fractals are generally self-similar and independent of scale, that is they have similar properties at all levels of magnification or across all times.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Noise functions and Fractals\n\nFrame buffer\n\nA frame buffer (or framebuffer) is a video output device that drives a video display from a memory buffer containing a complete frame of data.The information in the memory buffer typically consists of color values for every pixel (point that can be displayed) on the screen. Color values are commonly stored in 1-bit binary (monochrome), 4-bit palettized, 8-bit palettized, 16-bit high color and 24-bit true color formats. An additional alpha channel is sometimes used to retain information about pixel transparency. The total amount of the memory required to drive the frame buffer depends on the resolution of the output signal, and on the color depth and palette size.\n\nFrame buffers differ significantly from the vector displays that were common prior to the advent of the frame buffer. With a vector display, only the vertices of the graphics primitives are stored. The electron beam of the output display is then commanded to move from vertex to vertex, tracing an analog line across the area between these points. With a frame buffer, the electron beam (if the display technology uses one) is commanded to trace a left- to-right, top-to-bottom path across the entire screen, the way a television renders a broadcast signal. At the same time, the color information for each point on the screen is pulled from the frame buffer, creating a set of discrete picture elements (pixels).\n\nRelated Glossary Terms: A-buffer or Alpha-buffer\n\nTerm Source: Chapter 6 – Information International Inc. (Triple-I)\n\nFrame-grabbing\n\nA frame grabber is an electronic device that captures individual, digital still frames from an analog video signal or a digital video stream. It is usually employed as a component of a computer vision system, in which video frames are captured in digital form and then displayed, stored or transmitted in raw or compressed digital form. Historically, frame grabbers were the predominant way to interface cameras to PC’s\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 16 – Amiga\n\nFree-form surface\n\nFree-form surface, or freeform surfacing, is used in CAD and other computer graphics software to describe the skin of a 3D geometric element. Freeform surfaces do not have rigid radial dimensions, unlike regular surfaces such as planes, cylinders and conic surfaces. They are used to describe forms such as turbine blades, car bodies and boat hulls. Initially developed for the automotive and aerospace industries, freeform surfacing is now widely used in all engineering design disciplines from consumer goods products to ships. Most systems today use nonuniform rational B-spline (NURBS) mathematics to describe the surface forms; however, there are other methods such as Gorden surfaces or Coons surfaces .\n\nRelated Glossary Terms: B-rep, Solids modeling\n\nTerm Source: Chapter 10 – Intergraph / Bentley / Dassault\n\nFuchs, Henry\n\nProf. Henry Fuchs is a fellow of the American Academy of Arts and Sciences (AAAS) and the Association for Computing Machinery (ACM) and the Federico Gill Professor of Computer Science at the University of North Carolina at Chapel Hill (UNC). He is also an adjunct professor in biomedical engineering. His research interests are in computer graphics, particularly rendering algorithms, hardware, virtual environments, telepresence systems, and applications in medicine. In 1992, he received both the ACM SIGGRAPH Achievement Award and the Academic Award of the National Computer Graphics Association (NCGA)\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – UNC and Toronto\n\nG\n\nGates, Bill\n\nWilliam Henry “Bill” Gates III is the former chief executive and current chairman of Microsoft, the world’s largest personal-computer software company, which he co-founded with Paul Allen. He is consistently ranked among the world’s wealthiest people. During his career at Microsoft, Gates held the positions of CEO and chief software architect, and remains the largest individual shareholder.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 16 – The IBM PC and Unix\n\nGehring, Bo\n\nBo Gehring was hired by Phil Mittleman of MAGI in 1972 to develop the division of the company focused on computer image making (MAGI Synthavision). He was the principle of Gehring Aviation and Bo Gehring Associates in Venice, California, and originally came to the west coast to do computer animation tests for Steven Spielberg’s CLOSE ENCOUNTERS OF THE THIRD KIND.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Bo Gehring and Associates\n\nGenlocking\n\nGenlock (generator locking) is a common technique where the video output of one source, or a specific reference signal from a signal generator, is used to synchronize other television picture sources together. The aim in video applications is to ensure the coincidence of signals in time at a combining or switching point. When video instruments are synchronized in this way, they are said to be generator locked, or genlocked.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 16 – Amiga\n\nGlobal illumination\n\nGlobal illumination is a general name for a group of algorithms used in 3D computer graphics that are meant to add more realistic lighting to 3D scenes. Such algorithms take into account not only the light which comes directly from a light source (direct illumination), but also subsequent cases in which light rays from the same source are reflected by other surfaces in the scene, whether reflective or not (indirect illumination).\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Global Illumination\n\nGlyphs\n\nA glyph (pronounced GLIHF ; from a Greek word meaning carving) is a graphic symbol that provides the appearance or form for a character . A glyph can be an alphabetic or numeric font or some other symbol that pictures an encoded character.\n\nIt is a particular graphical representation, in a particular typeface, of a grapheme, or sometimes several graphemes in combination (a composed glyph), or a part of a grapheme. It can also be a grapheme or grapheme-like unit of text, as found in natural language writing systems (scripts). It may be a letter, a numeral, a punctuation mark, or a pictographic or decorative symbol such as dingbats. A character or grapheme is an abstract unit of text, whereas a glyph is a graphical unit.\n\nFor example, the sequence ffi contains three characters, but can be represented by one glyph, the three characters being combined into a single unit known as a ligature. Conversely, some typewriters require the use of multiple glyphs to depict a single character (for example, two hyphens in place of an em-dash, or an overstruck apostrophe and period in place of an exclamation mark).\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 16 – Xerox PARC\n\nGouraud shading\n\nGouraud shading, named after Henri Gouraud, is an interpolation method used in computer graphics to produce continuous shading of surfaces represented by polygon meshes. In practice, Gouraud shading is most often used to achieve continuous lighting on triangle surfaces by computing the lighting at the corners of each triangle and linearly interpolating the resulting colors for each pixel covered by the triangle. Gouraud first published the technique in 1971.\n\nRelated Glossary Terms: Continuous shading, Phong shading\n\nTerm Source: Chapter 14 – CGI and Effects in Films and Music Videos\n\nGraphics acceleration\n\nGraphics accelerators are a type of graphics hardware that contains its own processor to boost performance levels. These processors are specialized for computing graphical transformations, so they achieve better results than the general-purpose CPU used by the computer. In addition, they free up the computer’s CPU to execute other commands while the graphics accelerator is handling graphics computations.\n\nThe popularity of graphical applications, and especially multimedia applications, has made graphics accelerators not only a common enhancement, but a necessity. Most computer manufacturers now bundle a graphics accelerator with their mid-range and high-end systems.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 13 – Evans and Sutherland, Chapter 15 – Graphics Accelerators\n\nGraphics processing unit\n\nA graphics processing unit or GPU (also occasionally called visual processing unit or VPU) is a specialized electronic circuit designed to rapidly manipulate and alter memory in such a way so as to accelerate the building of images in a frame buffer intended for output to a display.\n\nRelated Glossary Terms: Graphics acceleration\n\nTerm Source: Chapter 15 – Graphics Accelerators\n\nGraphics tablet\n\nA graphics tablet (or digitizing tablet , graphics pad , drawing tablet ) is a computer input device that allows one to hand-draw images and graphics, similar to the way one draws images with a pencil and paper. These tablets may also be used to capture data of handwritten signatures.\n\nA graphics tablet (also called pen pad) consists of a flat surface upon which the user may “draw” an image using an attached stylus, a pen-like drawing apparatus. The image generally does not appear on the tablet itself but, rather, is displayed on the computer monitor. Some tablets however, come as a functioning secondary computer screen that you can interact with directly using the stylus.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 3 – Input devices\n\nGraphics workstation\n\nA workstation is a high-end microcomputer designed for technical or scientific applications. Intended primarily to be used by one person at a time. It is commonly connected to a local area network and run multi-user operating systems.\n\nHistorically, workstations had offered higher performance than desktop computers, especially with respect to CPU and graphics, memory capacity, and multitasking capability. Graphics workstations are optimized for the visualization and manipulation of different types of complex data such as 3D mechanical design, engineering simulation (e.g. computational fluid dynamics), animation and rendering of images, and mathematical plots. Consoles consist of a high resolution display, a keyboard and a mouse at a minimum, but also offer multiple displays, graphics tablets, 3D mice (devices for manipulating 3D objects and navigating scenes), etc.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 15 – Apollo / Sun / SGI\n\nGreenberg, Donald P.\n\nDonald Peter Greenberg is the Jacob Gould Schurman Professor of Computer Graphics at Cornell University. He joined the Cornell faculty in 1968 with a joint appointment in the College of Engineering and College of Architecture. He currently serves as Director of the Program of Computer Graphics.\n\nIn 1971, Greenberg produced an early sophisticated computer graphics movie, Cornell in Perspective, using the General Electric Visual Simulation Laboratory. Greenberg also co- authored a series of papers on the Cornell Box.\n\nAn internationally recognized pioneer in computer graphics, Greenberg has authored hundreds of articles and served as a teacher and mentor to many prominent computer graphic artists and animators. Greenberg was the founding director of the National Science Foundation Science and Technology Center for Computer Graphics and Scientific Visualization when it was created in 1991.\n\nGreenberg received the Steven Anson Coons Award in 1987, the most prestigious award in the field of computer graphics.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – Cornell and NYIT\n\nGUI (Graphical User Interface)\n\nAn interface for issuing commands to a computer utilizing a pointing device, such as a mouse, that manipulates and activates graphical images on a monitor.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 3 – Work continues at MIT, Chapter 16 – Xerox PARC\n\nH\n\nHaptic\n\nHaptic technology, or haptics, is a tactile feedback technology which takes advantage of the sense of touch by applying forces, vibrations, or motions to the user. This mechanical stimulation can be used to assist in the creation of virtual objects in a computer simulation, to control such virtual objects, and to enhance the remote control of machines and devices (telerobotics). It has been described as “doing for the sense of touch what computer graphics does for vision”. Haptic devices may incorporate tactile sensors that measure forces exerted by the user on the interface.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 17 – Interaction\n\nHausdorff-Besicovich dimension\n\nthe Hausdorff dimension (also known as the Hausdorff–Besicovitch dimension) is an extended non-negative real number associated with a metric space. The Hausdorff dimension generalizes the notion of the dimension of a real vector space in that the Hausdorff dimension of an n-dimensional inner product space equals n. This means, for example, the Hausdorff dimension of a point is zero, the Hausdorff dimension of a line is one, and the Hausdorff dimension of the plane is two. There are, however, many irregular sets that have noninteger Hausdorff dimension. The concept was introduced in 1918 by the mathematician Felix Hausdorff. Many of the technical developments used to compute the Hausdorff dimension for highly irregular sets were obtained by Abram Samoilovitch Besicovitch.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Noise functions and Fractals\n\nHead-mounted displays\n\nA head-mounted display or helmet mounted display, both abbreviated HMD, is a display device, worn on the head or as part of a helmet, that has a small display optic in front of one (monocular HMD) or each eye (binocular HMD).\n\nA typical HMD has either one or two small displays with lenses and semi-transparent mirrors embedded in a helmet, eye-glasses (also known as data glasses) or visor. The display units are miniaturized and may include CRT, LCDs, Liquid crystal on silicon (LCos), or OLED.\n\nRelated Glossary Terms: Stereoscopic display\n\nTerm Source: Chapter 17 – Virtual Reality\n\nHeads-up display\n\nA head-up display or heads-up display—also known as a HUD—is any transparent display that presents data without requiring users to look away from their usual viewpoints. The origin of the name stems from a pilot being able to view information with the head positioned “up” and looking forward, instead of angled down looking at lower instruments.\n\nAlthough they were initially developed for military aviation, HUDs are now used in commercial aircraft, automobiles, and other applications.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 17 – Interaction\n\nHeight maps\n\nIn computer graphics, a height map or height field is a raster image used to store values, such as surface elevation data, for display in 3D computer graphics. A height map can be used in bump mapping to calculate where this 3D data would create shadow in a material, in displacement mapping to displace the actual geometric position of points over the textured surface, or for terrain where the height map is converted into a 3D mesh.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 13 – Other Approaches\n\nHidden line elimination\n\nHidden line elimination is an extension of wireframe model rendering where lines (or segments of lines) covered by surfaces of a model are not drawn, resulting in a more accurate representation of a 3D object.\n\nRelated Glossary Terms: Hidden surfaces\n\nTerm Source:\n\nHidden surfaces\n\nIn 3D computer graphics, hidden surface determination (also known as hidden surface removal (HSR), occlusion culling (OC) or visible surface determination (VSD)) is the process used to determine which surfaces and parts of surfaces are not visible from a certain viewpoint. A hidden surface determination algorithm is a solution to the visibility problem, which was one of the first major problems in the field of 3D computer graphics.\n\nRelated Glossary Terms: Hidden line elimination\n\nTerm Source: Chapter 17 – Virtual Reality\n\nHopper, Grace\n\nRear Admiral Grace Murray Hopper was an American computer scientist and United States Navy officer. A pioneer in the field, she was one of the first programmers of the Harvard Mark I computer, and developed the first compiler for a computer programming language. She conceptualized the idea of machine-independent programming languages, which led to the development of COBOL, one of the first modern programming languages. She is credited with popularizing the term “debugging” for fixing computer glitches (motivated by an actual moth removed from the computer).\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 2 – Programming and Artistry\n\nI\n\nI&D architectures\n\nI&D (instructions and data) – refers to the ability to address instructions and data in the same computer “word”\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 3 – TX-2 and DEC\n\nImage processing\n\nIn imaging science, image processing is any form of signal processing for which the input is an image, such as a photograph or video frame; the output of image processing may be either an image or a set of characteristics or parameters related to the image. Most image- processing techniques involve treating the image as a two-dimensional signal and applying standard signal-processing techniques to it.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 13 – NASA\n\nImax\n\nIMAX is a motion picture film format and a set of proprietary cinema projection standards created by the Canadian company IMAX Corporation. IMAX has the capacity to record and display images of far greater size and resolution than conventional film systems.\n\nRelated Glossary Terms:\n\nTerm Source:\n\nChapter 11 – Sogitec Audiovisuel\n\nInk and paint\n\nDigital ink-and-paint is the computerized version of finalizing animation art using scanning, instead of inking, for each pencil drawing, and digitally coloring instead of hand-painting each cel. With all the ink-and-paint programs now available it is possible to drop fill (single- click paint an entire enclosed area) or use a digital paintbrush to fill colors into characters.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 11 – Metrolight / Rezn8\n\nIntegrated circuit\n\nA circuit of transistors, resistors, and capacitors constructed on a single semiconductor wafer or chip, in which the components are interconnected to perform a given function. Abbreviation: IC\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 1 – Electronic devices\n\nInterpolation\n\nLinear interpolation, in computer graphics often called “LERP” (Linear interpolation), is a very (if not the simplest) method of interpolation.\n\nFor a set of discrete values linear interpolation can approximate other values in between, assuming a linear development between these discrete values. An interpolated value, calculated with linear interpolation, is calculated only in respect to the two surrounding values, which makes it a quite inappropriate choice if the desired curve should be smooth. If a curvier interpolation is needed, cubic interpolation or splines might be an option.\n\nLinear interpolation is the simplest method of getting values at positions in between the data points. The points are simply joined by straight line segments.\n\nCubic interpolation is the simplest method that offers true continuity between segments. As such it requires more than just the two endpoints of the segment but also the two points on either side of them. So the function requires 4 points in all.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 8 – Introduction\n\nIsolines\n\nAn isoline (also contour line, isopleth, or isarithm) of a function of two variables is a curve along which the function has a constant value. For example, in cartography, a contour line (often just called a “contour”) joins points of equal elevation (height) above a given level, such as mean sea level.[ A contour map is a map illustrated with contour lines, for example a topographic map, which thus shows valleys and hills, and the steepness of slopes. The contour interval of a contour map is the difference in elevation between successive contour lines.\n\nRelated Glossary Terms: Isosurfaces\n\nTerm Source: Chapter 18 – Introduction\n\nIsosurfaces\n\nAn isosurface is a three-dimensional analog of an isoline. It is a surface that represents points of a constant value (e.g. pressure, temperature, velocity, density) within a volume of space; in other words, it is a level set of a continuous function whose domain is 3D-space.\n\nRelated Glossary Terms: Contour plots, Isolines\n\nTerm Source: Chapter 18 – Introduction\n\nIterated function systems\n\nIn mathematics, iterated function systems or IFSs are a method of constructing fractals; the resulting constructions are always self-similar.\n\nIFS is the term originally devised by Michael Barnsley and Steven Demko for a collection of contraction mappings over a complete metric space, typically compact subsets of Rn . The landmark papers of John Hutchinson and, independently, Barnsley and Demko showed how such systems of mappings with associated probabilities could be used to construct fractal sets and measures: the former from a geometric measure theory setting and the latter from a probabilistic setting.\n\nhttp://links.uwaterloo.ca/ResearchIFSFractalCoding.html\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Plants\n\nJ\n\nJaggies\n\nJaggies” is the informal name for artifacts in raster images, most frequently from aliasing,[1] which in turn is often caused by non-linear mixing effects producing high-frequency components and/or missing or poor anti-aliasing filtering prior to sampling.\n\nJaggies are stair like lines that appear where there should be smooth straight lines or curves. For example, when a nominally straight, un-aliased line steps across one pixel, a dogleg occurs halfway through the line, where it crosses the threshold from one pixel to the other.\n\nRelated Glossary Terms: Antialiasing\n\nTerm Source: Chapter 15 – Graphics Accelerators\n\nJobs, Steve\n\nSteven Paul “Steve” Jobs was an American entrepreneur who is best known as the co- founder, chairman, and chief executive officer of Apple Inc. Through Apple, he was widely recognized as a charismatic pioneer of the personal computer revolution and for his influential career in the computer and consumer electronics fields. Jobs also co-founded and served as chief executive of Pixar Animation Studios; he became a member of the board of directors of The Walt Disney Company in 2006, when Disney acquired Pixar.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 16 – Apple Computer\n\nK\n\nKajiya, Jim\n\nJim Kajiya is a pioneer in the field of computer graphics. He is perhaps best known for the development of the rendering equation.Kajiya received his PhD from the University of Utah in 1979, was a professor at Caltech from 1979 through 1994, and is currently a researcher at Microsoft Research.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 5 – Cal Tech and North Carolina State, Chapter 19 – Global Illumination\n\nKawaguchi, Yoichiro\n\nYoichiro Kawaguchi is a Japanese computer graphics artist, professor at the University of Tokyo. Kawaguchi rose to international prominence in 1982 when he presented “Growth Model” in the international conference SIGGRAPH.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 9 – Yoichiro Kawaguchi\n\nKeyframe\n\nA key frame in animation and filmmaking is a drawing that defines the starting and ending points of any smooth transition. They are called “frames” because their position in time is measured in frames on a strip of film. A sequence of keyframes defines which movement the viewer will see, whereas the position of the keyframes on the film, video or animation defines the timing of the movement. Because only two or three keyframes over the span of a second do not create the illusion of movement, the remaining frames are filled with in- betweens.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 4 – University of Utah, Chapter 4 – The Ohio State University, Chapter 4 – JPL and National Research Council of Canada\n\nKinematics\n\nForward kinematic animation is a method in 3D computer graphics for animating models.\n\nThe essential concept of forward kinematic animation is that the positions of particular parts of the model at a specified time are calculated from the position and orientation of the object, together with any information on the joints of an articulated model. So for example if the object to be animated is an arm with the shoulder remaining at a fixed location, the location of the tip of the thumb would be calculated from the angles of the shoulder, elbow, wrist, thumb and knuckle joints. Three of these joints (the shoulder, wrist and the base of the thumb) have more than one degree of freedom, all of which must be taken into account. If the model were an entire human figure, then the location of the shoulder would also have to be calculated from other properties of the model.\n\nForward kinematic animation can be distinguished from inverse kinematic animation by this means of calculation – in inverse kinematics the orientation of articulated parts is calculated from the desired position of certain points on the model. It is also distinguished from other animation systems by the fact that the motion of the model is defined directly by the animator – no account is taken of any physical laws that might be in effect on the model, such as gravity or collision with other models.\n\nRelated Glossary Terms: Dynamics\n\nTerm Source: Chapter 8 – Introduction\n\nKinetic Art\n\nKinetic art is art that contains moving parts or depends on motion for its effect. The moving parts are generally powered by wind, a motor or the observer. Kinetic art encompasses a wide variety of overlapping techniques and styles.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 9 – Vera Molnar\n\nKleiser, Jeff\n\nJeff Kleiser is widely recognized as a leader in animation and visual effects. He has produced and directed visual effects for numerous award-winning television commercials, and has created unique location-based entertainment projects such as the 3D stereoscopic films Corkscrew Hill (for Bush Gardens), Santa Lights up New York (for Radio City Music Hall), and The Amazing Adventures of Spider-Man (for Universal Studios). Kleiser’s film credits range from Walt Disney’s Tron, the ground-breaking CGI movie released to critical acclaim in 1982, to recent Hollywood releases such as X-Men (including X-Men 2 and X- Men: The Last Stand), Fantastic Four, Scary Movie (3 and 4), Slither, Son of the Mask, Exorcist: The Beginning, and many more. In 1987 Kleiser and partner Diana Walczak founded the visual effects studio Kleiser-Walczak and together coined the term “synthespian” to describe digital actors (synthetic thespians). In 2005 Kleiser and Walczak founded Synthespian Studios (synthespians.net) to create original projects for animated characters.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Digital Effects\n\nKodalith\n\nA high contrast black and white film made by Kodak, used also as a special effect film in the darkroom (allowed for the recording ultra high contrast images)\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 2 – Programming and Artistry\n\nKovacs, Bill\n\nBill Kovacs received a Bachelor of Architecture degree from Carnegie Mellon University in 1971. He worked for Skidmore, Owings and Merrill (New York office) while getting a Masters of Environmental Design from Yale University (1972). He was then transferred to the Chicago Office, where he worked on a computer-aided design system.\n\nIn 1978, Kovacs left SOM to become VP of R&D for the early computer animation company Robert Abel and Associates (1978-1984). At Abel, Kovacs (along with Roy Hall and others) developed the company’s animation software. Kovacs used this software, with others in the film Tron. He later co-founded Wavefront Technologies as CTO (1984-1994), leading the development of products such as The Advanced Visualizer as well as animated productions. Along with Richard Childers and Chris Baker, he was a key organizer of the Infinite Illusions at the Smithsonian Institution exhibit in 1991.\n\nFollowing retirement from Wavefront, Kovacs co-founded Instant Effects, worked as a consultant to Electronic Arts and RezN8, serving as RezN8’s CTO from 2000 until his death. In 1998, Kovacs received a 1997 (Scientific and Engineering) Academy Award from the Academy of Motion Picture Arts and Sciences. In 1980, he received two Clio Awards for his work on animated TV commercials.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Robert Abel and Associates\n\nKristoff, Jim\n\nPresident of Cranston/Csuri Productions, and founder of Metrolight Productions in Los Angeles.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Cranston/Csuri Productions\n\nKrueger, Myron\n\nMyron Krueger is an American computer artist who developed early interactive works. He is also considered to be one of the first generation virtual reality and augmented reality researchers. He earned a Ph.D. in Computer Science at the University of Wisconsin– Madison and in 1969, he collaborated with Dan Sandin, Jerry Erdman and Richard Venezky on a computer controlled environment called “glowflow,” a computer-controlled light sound environment that responded to the people within it. Krueger went on to develop Metaplay, an integration of visuals, sounds, and responsive techniques into a single framework. A later project, “Videoplace,” was funded by the National Endowment for the arts and a two- way exhibit was shown at the Milwaukee Art Museum in 1975. From 1974 to 1978 Krueger performed computer graphics research at the Space Science and Engineering Center of the University of Wisconsin–Madison in exchange for institutional support for his “Videoplace” work. In 1978, joined the computer science faculty at the University of Connecticut, where he taught courses in hardware, software, computer graphics and artificial intelligence.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 17 – Hypermedia and Art\n\nL\n\nL-systems\n\nAn L-system or Lindenmayer system, is a parallel rewriting system, namely a variant of a formal grammar, most famously used to model the growth processes of plant development, but also able to model the morphology of a variety of organisms. An L-system consists of an alphabet of symbols that can be used to make strings, a collection of production rules which expand each symbol into some larger string of symbols, an initial “axiom” string from which to begin construction, and a mechanism for translating the generated strings into geometric structures. L-systems can also be used to generate self-similar fractals such as iterated function systems.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Plants\n\nLambertian\n\nIf a surface exhibits Lambertian reflectance, light falling on it is scattered such that the apparent brightness of the surface to an observer is the same regardless of the observer’s angle of view. More technically, the surface luminance is isotropic. For example, unfinished wood exhibits roughly Lambertian reflectance, but wood finished with a glossy coat of polyurethane does not, since specular highlights may appear at different locations on the surface. Not all rough surfaces are perfect Lambertian reflectors, but this is often a good approximation when the characteristics of the surface are unknown. Lambertian reflectance is named after Johann Heinrich Lambert.\n\nIn computer graphics, Lambertian reflection is often used as a model for diffuse reflection. This technique causes all closed polygons (such as a triangle within a 3D mesh) to reflect light equally in all directions when rendered.\n\nRelated Glossary Terms: Diffuse reflection, Specular reflection\n\nTerm Source: Chapter 19 – Global Illumination\n\nLanglois, Daniel\n\nDaniel Langlois is the president and founder of the Daniel Langlois Foundation, Ex-Centris, and Media Principia Inc. He also founded Softimage Inc., serving as its president and chief technology officer from November 1986 to July 1998. The company is recognized in the fields of cinema and media creation for its digital technologies and especially its 3-D computer animation techniques. Softimage software was used to create most of the 3-D effects in the movies Star Wars Episode I: The Phantom Menace, The Matrix, Titanic, Men in Black, Twister, Jurassic Park, The Mask and The City of Lost Children.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 8 – SoftImage\n\nLaposky, Ben\n\nBen Laposky was a mathematician and artist from Iowa. In 1950, he created the first graphic images generated by an electronic (in his case, an analog) machine.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 2 – Programming and Artistry\n\nLasseter, John\n\nJohn Alan Lasseter is an American animator, film director and the chief creative officer at Pixar and Walt Disney Animation Studios. He is also currently the Principal Creative Advisor for Walt Disney Imagineering. Lasseter’s first job was with The Walt Disney Company, where he became an animator. Next, he joined Lucasfilm, where he worked on the then- groundbreaking use of CGI animation. After the Graphics Group of the Computer Division of Lucasfilm was sold to Steve Jobs and became Pixar in 1986, Lasseter oversaw all of Pixar’s films and associated projects as executive producer and he directed Toy Story, A Bug’s Life, Toy Story 2, Cars, and Cars 2.\n\nHe has won two Academy Awards, for Animated Short Film (for Tin Toy), as well as a Special Achievement Award (for Toy Story).\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – MAGI\n\nLight pen\n\na rodlike device which, when focused on the screen of a cathode-ray tube, can detect the time of passage of the illuminated spot across that point thus enabling a computer to determine the position on the screen being pointed at\n\nRelated Glossary Terms: Cathode Ray Tube\n\nTerm Source: Chapter 3 – General Motors DAC, Chapter 3 – Input devices\n\nLofting\n\nThe creation of a 3D surface model by joining adjacent cross-sectional data with surface elements, such as triangles.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 18 – Algorithms\n\nLytle, Wayne\n\nWayne Lytle is the founder of Animusic, an American musical computer animation company. In 1988, he joined the Cornell Theory Center, where he could experiment with his idea as a scientific visualization producer. He created the piece More Bells & Whistles at Cornell in 1990 and composed Beyond The Walls in 1996. Lytle founded Animusic (originally under the name Visual Music) in 1995 with his associate David Crognale.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Data-driven Imagery\n\nM\n\nMachover, Carl\n\nCarl Machover,a computer graphics pioneer and graphics “evangelist” is president of Machover Associates Corp (MAC), a computer graphics consultancy he founded in 1976,which provides a broad range of management, engineering, marketing, and financial services worldwide to computer graphics users, suppliers, and investors. Machover is also an Adjunct Professor at RPI, president of ASCI, past-president of NCGA, SID, and Computer Graphics Pioneers, on the editorial boards of many industry publications, writes and lectures world-wide on all aspects of computer graphics, and was guest editor of special computer graphics art issues of Computer and Graphics and the IEEE Computer Graphics and Applications, Machover received the North Carolina State University, Orthogonal Award , the NCGA Vanguard Award, .and was was inducted into the FAMLI Computer Graphics Hall of Fame. Machover passed away in 2012.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – MAGI\n\nMandelbrot, Benoit\n\nBenoît B. Mandelbrot was a French American mathematician. Born in Poland, he moved to France with his family when he was a child. Mandelbrot spent much of his life living and working at IBM in the United States, where he worked on a wide range of mathematical problems, including mathematical physics and quantitative finance. He is best known as the father of fractal geometry. He coined the term fractal and described the Mandelbrot set.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 19 – Noise functions and Fractals\n\nMarks, Harry\n\nHarry Marks is considered by many to be the founding father of modern broadcast design. He began his career as a typographer and publications designer at Oxford University Press. In the mid-1960s, he moved to Los Angeles and landed a job at ABC-TV, where his assignment was to improve the on-air graphic appearance of the network. He is also known for his work as an independent graphics consultant, including six years of on-air graphics for NBC-TV, brand packaging for international TV networks, and an Emmy-winning main title for Entertainment Tonight. Harry is well known for his innovative use of emerging technologies, such as computer graphics and slit scan. He has earned nearly every award in broadcast design and promotion, including an Emmy and the first Lifetime Achievement Award from the Broadcast Design Association. In 1984, Harry had the notion of facilitating a gathering of people from the converging worlds of technology, entertainment, and design, so he partnered with Richard Saul Wurman and created the TED Conference.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 6 – Pacific Data Images, Chapter 6 – Robert Abel and Associates\n\nMax, Nelson\n\nMax’s research interests are in the areas of scientific visualization, computer animation, and realistic computer graphics rendering. In visualization he works on molecular graphics, and volume and flow visualization, particularly on irregular finite element meshes. He has rendered realistic lighting effects in clouds, trees, and water waves, and has produced numerous computer animations, shown at the annual SIGGRAPH conferences, and in Omnimax at the Fujitu Pavilions at Expo ’85 in Tsukuba Japan, and Expo ’90 in Osaka Japan. His early work was done at Lawrence Livermore and he is currently affiliated with UC-Davis.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 4 – Bell Labs and Lawrence Livermore\n\nMetaballs\n\nMetaballs are, in computer graphics, organic-looking n-dimensional objects. The technique for rendering metaballs was invented by Jim Blinn in the early 1980s. Each metaball is defined as a function in n-dimensions.\n\nRelated Glossary Terms:\n\nTerm Source: Chapter 8 – Side Effects, Chapter 9 – Yoichiro Kawaguchi\n\nMIP mapping\n\nIn 3D computer graphics texture filtering, mipmaps (also MIP maps) are pre-calculated, optimized collections of images that accompany a main texture, intended to increase rendering speed and reduce aliasing artifacts. They are widely used in 3D computer games, flight simulators and other 3D imaging systems. Mipmapping was invented by Lance Williams in 1983 and is described in his paper Pyramidal parametrics.\n\nRelated Glossary Terms:\n\nTerm Source:\n\nModular visualization environments\n\nseveral systems have been developed around the concepts of applying visual languages to visualization application building; decomposing a visualization application into separable process (such as data analysis, geometric representation, and rendering); and finally creating a real-time development environment where applications are created interactively. These systems have given rise to disposable applications by utilizing reusable visualization and graphics algorithms. These techniques can be connected in a visual manner to create problem-targeted applications with a short lifetime, which dramatically reduces the time devoted to problem solving.\n\nBecause of their focus, these systems blur the distinction between program visualization (the process of dynamically viewing the execution ordering of a program), visualization programming (creating visualization applications using graphics libraries), and visualization prototyping (building visualization applications interactively).\n\nRelated Glossary Terms: Dataflow\n\nTerm Source: Chapter 18 – Visualization Systems\n\nMonte Carlo method\n\nMonte Carlo methods (or Monte Carlo experiments) are a class of computational algorithms that rely on repeated random samplin"
    }
}