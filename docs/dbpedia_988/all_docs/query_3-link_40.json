{
    "id": "dbpedia_988_3",
    "rank": 40,
    "data": {
        "url": "https://arxiv.org/html/2407.09013v1",
        "read_more_link": "",
        "language": "en",
        "title": "Procedural Content Generation via Generative Artificial Intelligence",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Xinyu Mao\n\nGraduate School of Information Sciences\n\nTohoku University\n\n&Wanli Yu\n\nGraduate School of Information Sciences\n\nTohoku University\n\n&Kazunori D Yamada\n\nGraduate School of Information Sciences\n\nTohoku University\n\nUnprecedented-scale Data Analytics Center\n\nTohoku University\n\n&Michael R. Zielewski\n\nGraduate School of Information Sciences\n\nTohoku University\n\nAbstract\n\nThe attempt to utilize machine learning in PCG has been made in the past. In this survey paper, we investigate how generative artificial intelligence (AI), which saw a significant increase in interest in the mid-2010s, is being used for PCG. We review applications of generative AI for the creation of various types of content, including terrains, items, and even storylines. While generative AI is effective for PCG, one significant issues it faces is that building high-performance generative AI requires vast amounts of training data. Because content generally highly customized, domain-specific training data is scarce, and straightforward approaches to generative AI models may not work well. For PCG research to advance further, issues related to limited training data must be overcome. Thus, we also give special consideration to research that addresses the challenges posed by limited training data.\n\n1 Introduction\n\nVideo games have been continuously advancing technologically from their inception to the present day. From the early pixel-based games to modern high-resolution, physics-based rendering, the evolution of games has been remarkable. Amidst these technological revolutions, the approach to game content generation has also undergone significant changes. The emergence of PCG has played a major role in this transformation.\n\nPCG is a technology that dynamically generates game content using algorithm-based methods Togelius et al., 2011a . By “content” here, we refer to everything within the game, including terrain, characters, items, stories, music, and so on. This technology is useful in reducing development costs by automatically generating content that would otherwise require a significant amount of human effort. For example, PCG is especially useful for small development teams, which may not have developers dedicated to generating content, and for large-scale open-world games, which require vast amounts of content. Moreover, it is an essential technique for roguelike games that offer different experiences, through unique and new content, with each playthrough.\n\nInitial approaches to PCG relied on simple randomization algorithms and fixed rule sets, but over time, PCG has become more sophisticated. Amidst this evolution, the 2000s saw a boom in artificial intelligence, spurred by advancements in deep neural networks. While most developments have been in the realms of computer vision and natural language processing, the applications of AI have expanded and it is now utilized in many fields. Notably, recent advancements in AI, especially in machine learning, have further expanded the potential of PCG. Deep neural networks contribute to the generation of diverse game content, from game environments and character behaviors to narrative creation. In the mid-2010s, generative AI gained significant attention due to highly influential developments in the field. These developments in generative AI were particularly important because they generated high quality information or content without human interaction or guidance. The interest in generative AI has spread to many other fields, and it is now used for producing various types of media, including text, images, music, and videos.\n\nIn the field of PCG, existing approaches have various limitations. One perspective for improving PCG aims to create methods that generate content without inconsistencies. For example, in a game level, certain combinations of tiles may be visually unappealing, or even render a level unplayable. Another approach to improving PCG addresses challenges faced by PCG as a whole, rather than limitations of specific approaches. As previously mentioned, PCG can provide players with a fresh and unpredictable gaming experience by generating new and unique content. However, many PCG approaches generate content with easily identifiable patterns and structure. Thus, while seemingly different for PCG methods, multiple pieces of content can be percieved as identical to human players. Therefore, it seems natural to leverage the increasingly practical applications of AI to address such issues. Indeed, there has been active discussion on how to utilize AI in PCG in the past (Guzdial et al.,, 2019).\n\nWhile the term “game” encompasses a variety of types, including video games, board games, and card games, this survey paper primarily focuses on video games. Several review papers, including those on PCG research, already exist (Hendrikx et al.,, 2013; Togelius et al., 2011b, ). There are also review papers specifically focusing on studies that utilize machine learning methods for PCG (Summerville et al.,, 2018; Liu et al.,, 2021). Furthermore, there are research papers that compile previous studies on applying reinforcement learning to PCG, aiming to formulate the PCG problem in a format suitable for reinforcement learning (Khalifa et al.,, 2020). However, there has not been a survey paper focusing on the use of generative AI to date, though there is a survey paper focusing on the use of Transformer (Vaswani et al.,, 2017) to PCG (Mohaghegh et al.,, 2023). This paper provides an overview of research applying generative AI to PCG, highlighting both past trends and current developments.\n\nWe have conducted a comprehensive investigation into the achievements of past research, ranging from the early attempts of using AI in PCG to the state-of-the-art techniques and their practical applications. Initially, we delve into the history of PCG research that employed AI, constructed using traditional machine learning methods. Following that, we highlight how the latest AI technology, known as generative AI, is being applied in PCG. Concluding our survey, we offer insights, based on our findings, into the potential evolution of game development and the gaming experience in the future.\n\n2 Prerequisites\n\n2.1 The Rise of Procedural Content Generation\n\nPCG refers to the semi-automatic generation of in-game content using algorithms. These methods are designed to function with limited input or instructions. The scope of PCG encompasses everything within the game, including terrain, characters, items, stories, music, and more. While PCG is most often utilized to aid game development, there are also games that have been developed featuring PCG as a core element of their design.\n\nOne of the primary reasons for implementing PCG is to reduce the cost of content creation. Considerations include the cost-saving perspective of disk space constraints on devices running the game, as well as the reduction of manual labor involved in content generation by humans. For example, modern video games often encompass vast spaces filled with various items and characters. Creating such expansive content might take hundreds of hours across many game developers, which may be impractical for smaller development teams. PCG has the potential to reduce these development costs, allowing smaller teams to produce high-quality games that rival those produced by large studios.\n\nAnother reason for implementing PCG is to provide players with a novel content experience. For instance, in games like roguelikes where the content changes with each playthrough, PCG is not just a tool to aid game development but an indispensable element. Thus, without PCG, games that rely on an extensive variety of unique content might not even exist. From the perspective of offering a novel content experience, there are instances where PCG is utilized to generate content that, due to its algorithmic nature, exceeds what is feasible by human developers.\n\nWhile PCG has been utilized for video game development from various standpoints, the earliest video game that employed PCG was Rogue, developed in 1980. Rogue is a game where players explore dungeons, encountering various monsters and obstacles while searching for treasures and leveling up. A distinctive feature of the game is that dungeon layout, monster placement, and item appearance is randomly generated each playthrough. While the content generation algorithm in Rogue primarily relies on randomness, rule-based algorithms supplement the randomly generated content to ensure consistency. For instance, the task of connecting rooms randomly generated on a map follows specific rules. Generating content purely at random, without any constraints, could lead to issues with game balance or even result in a non-functional game.\n\n2.2 Procedural Content Generation and Artificial Intelligence\n\nAI is an entity constructed on a computer that imitates human intelligence. Given such a definition, the randomness-based content generation methods used in Rogue and subsequent roguelike games can be broadly considered a type of AI. The inclusion of human designed rules does not detract from this, as the rules are typically created to limit the space of combinations of content and to guide the AI towards generating content that is meaningful and functional.\n\nHowever, with the evolution of video games, there has been a growing demand for more complex content generation and real-time content creation, among other requirements. To meet these needs, instead of relying solely on human-defined rule-based methods, there has been increasing interest in using machine learning methods based on player behavior and experience-derived data. Especially recently, with the booming interest in AI, various PCG methods incorporating the latest technologies are being devised.\n\nMachine learning methods create AI based on data. From the perspective of training AI, machine learning methods can often be categorized into the following three types:\n\n1.\n\nSupervised learning,\n\n2.\n\nUnsupervised learning,\n\n3.\n\nReinforcement learning.\n\nSupervised learning trains AI using a combination of input data and associated label data. The goal of supervised learning is to ensure that when new input data is fed into the constructed AI, it produces an appropriate label corresponding to that input. It can be used to predict continuous and discrete values, in the tasks of regression and classification, respectively. Machine learning models that can be trained using supervised learning include neural networks, support vector machines, linear regression, decision trees, among others.\n\nUnsupervised learning refers to a method of training AI without the use of labeled data. Thus, in unsupervised learning, the only data used to train the machine learning model is the input data. Typically, AI trained through unsupervised learning do not produce predictive values for given input data. Instead, these AI are often used to grasp trends present in the given data. They are utilized for tasks such as clustering, which groups data with similar characteristics, visualizing high-dimensional data that might be incomprehensible through human capabilities, and extracting features from data. Algorithms used in unsupervised learning include k-means, hierarchical clustering, principal component analysis, neural networks, among others.\n\nReinforcement learning is a method of training AI by providing it with feedback called a reward, and optimizing the AI to maximize the accumulated value of rewards. In the field of reinforcement learning, this AI is referred to as an agent. The agent exists in some environment and learns to maximize the rewards it obtains through a series of actions. Algorithms used in reinforcement learning include Markov decision processes, dynamic programming, and Q-learning, among others.\n\nAs described above, there are several types of machine learning methods. Moreover, even within the same machine learning method, various models exist. For instance, the support vector machine, which can be trained using supervised learning, is a classical model used for solving regression and classification problems. On the other hand, within the same supervised learning category, there are models used to construct generative AI, which generates data as if starting from a state with no input values. This generative AI experienced a boom in the mid-2010s, expanding the possibilities of AI. Another field that has been vigorously researched in recent AI studies, alongside generative AI, is reinforcement learning.\n\n2.3 Applications of Classical Machine Learning and Reinforcement Learning\n\nClassical machine learning methods, other than generative AI or reinforcement learning, have been utilized in PCG research in various ways, as detailed in the prior survey paper (Summerville et al.,, 2018). Classical machine learning models include support vector machines, decision trees, principal component analysis, and many others. In the context of PCG, these models are sometimes used to interpret content generation as a kind of sequence. For instance, Snodgrass et al. employed Markov chains for PCG (Snodgrass and Ontañón,, 2014). In deep learning, there is a model designed to handle sequence data, long short-term memory, which is a type of recurrent neural network. Summerville et al. utilized this architecture for PCG (Summerville and Mateas,, 2016).\n\nReinforcement learning is currently being actively researched and developed, and various techniques are being devised daily in the field of game research. For instance, deep Q-networks, which are deep reinforcement learning algorithms that utilize deep neural networks, have demonstrated performance surpassing humans in certain games. In terms of reinforcement learning agents playing games, AlphaGo is the most renowned (Silver et al.,, 2016). AlphaGo is an AI designed to play the game of Go, and in 2017, it competed against and defeated the Go player considered the best in the world at the time.\n\nHowever, there are rare examples of applying reinforcement learning to PCG. How reinforcement learning has been utilized in PCG research, and how it should be applied to PCG, is detailed in a prior study (Khalifa et al.,, 2020). For instance, Chen et al. constructed an agent in 2018 using the Q-learning method to generate superior decks for card games(Chen et al.,, 2018). Conversely, there are also studies that have used content generated by PCG as a learning environment for reinforcement learning to enhance the generalization performance of the AI being trained (Mnih et al.,, 2015).\n\n2.4 Generative Artificial Intelligence\n\nMachine learning models can be classified into discriminative models and generative models. Firstly, the discriminative model is represented by the following equation:\n\nf⁢(x)𝑓𝑥\\displaystyle f(x)italic_f ( italic_x ) =arg⁡maxy⁡p⁢(y|x).absentsubscript𝑦𝑝conditional𝑦𝑥\\displaystyle=\\arg\\max_{y}p(y|x).= roman_arg roman_max start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_p ( italic_y | italic_x ) . (1)\n\nwhere, f𝑓fitalic_f represents the model, x𝑥xitalic_x is the input data to the model, and y𝑦yitalic_y is the output value from the model. In this model, the y𝑦yitalic_y that maximizes the probability of occurrence when some data x𝑥xitalic_x is given is determined. For instance, when considering a classification problem, p⁢(y|x)𝑝conditional𝑦𝑥p(y|x)italic_p ( italic_y | italic_x ) is the probability that x𝑥xitalic_x belongs to class y𝑦yitalic_y.\n\nOn the other hand, the generative model is represented by the following equation:\n\nf⁢(x)𝑓𝑥\\displaystyle f(x)italic_f ( italic_x ) =arg⁡maxy⁡p⁢(x|y)⁢p⁢(y).absentsubscript𝑦𝑝conditional𝑥𝑦𝑝𝑦\\displaystyle=\\arg\\max_{y}p(x|y)p(y).= roman_arg roman_max start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_p ( italic_x | italic_y ) italic_p ( italic_y ) . (2)\n\nIn this model, p⁢(y)𝑝𝑦p(y)italic_p ( italic_y ) represents the occurrence probability of y𝑦yitalic_y. Moreover, p⁢(x|y)𝑝conditional𝑥𝑦p(x|y)italic_p ( italic_x | italic_y ) represents the occurrence probability of x𝑥xitalic_x when a class y𝑦yitalic_y is given. In this model, it is considered that x𝑥xitalic_x is generated based on some probability distribution. It is also considered that this probability distribution varies for each class y𝑦yitalic_y. In other words, p⁢(x|y)𝑝conditional𝑥𝑦p(x|y)italic_p ( italic_x | italic_y ) can be interpreted as the probability that x𝑥xitalic_x arises from the class y𝑦yitalic_y. In this model, the y𝑦yitalic_y that maximizes this probability is identified.\n\nBoth of these models have the capability to be used for predictive purposes, and thus may seem similar. However, in the generative model, the probability distribution for p⁢(x|y)𝑝conditional𝑥𝑦p(x|y)italic_p ( italic_x | italic_y ) is modeled. Therefore, using this probability distribution model, it is possible to generate new pseudo-data that belongs to the class y𝑦yitalic_y.\n\nA representative example of a generative model is the generative adversarial network (GAN). A GAN consists of a model called the generator, which generates data that belongs to the “real” class, and another model called the discriminator, which determines the authenticity of the generated data. Additionally, diffusion models and large language models (LLMs) like ChatGPT can also be considered as generative models.\n\n3 Types of Content\n\nGames, as a form of interactive entertainment media, have significantly different content generation requirements compared to non-interactive media. Most game content must be coherent, as the aesthetic generally suffers when coherence is lacking (Liu et al.,, 2021).\n\nAdditionally, because different content types play distinct roles in the overall presentation of a game, their generation requirements often vary greatly. Certain types of game content are crucial to the core gaming experience of players, such as level designs in most games and storyline generation in narrative-driven games. For these types of content, the primary goal of content generation is to make sense, or to be playable, to the player. A secondary goal would be to make content that is more entertaining. Other types of content may be less critical; assets like sprites of minor characters or textures for less significant scenes may be allowed to be imperfect for greater efficiency.\n\n3.1 Game Environments\n\n3.1.1 2D Game Levels\n\nGame levels are fundamental components of many games, particularly in genres like platformers, role-playing games, or rougelike games. While actual game levels often serve complex and varied purposes, in research related to procedural level generation, a level typically refers to a playable scene unit. Since related research usually distinguishes between 2D game levels and 3D terrain generation, the discussion in this section will not cover 3D games.\n\nThe most distinguished feature of game levels is their functional requirements. Unlike faces or sentences that can still be understood even with generation errors, game levels that that block access to essential paths or objectives are unplayable, regardless of their aesthetic appeal (Rodriguez Torrado et al.,, 2020). Therefore, the most basic goal of generating a level is to ensure its playability, and any advanced techniques aim to enhance coherence, diversity, and other factors that improve the quality of the level.\n\nMost research on procedural level generation regarding generative AI revolves around GAN-based improvements. For example, Irfan et al. explored how to use Deep Convolutional Generative Adversarial Networks (DCGANs) to generate general video game levels (Irfan et al.,, 2019). Fontaine et al. proposed using Quality-Diversity algorithms to search the latent space of Generative Adversarial Networks (Fontaine et al.,, 2021), while Torrado et al. introduced a new GAN architecture and training process called Conditional Embedding Self-Attention GAN (CESAGAN) (Rodriguez Torrado et al.,, 2020). This architecture integrates attention mechanisms and conditional inputs, enabling better capture of correlations between distant objects and considering level features, such as the number of enemies, as conditions.\n\n3.1.2 3D Terrain\n\nTerrain, often used in 3D open world games and sandbox games, refers to the topography in virtual environments, typically represented by a heightmap.\n\nResearches on terrain modeling have spanned over thirty years, accumulating many classic methods. Fractal Subdivision, one of the oldest and most common procedural terrain generation techniques, generates terrain by recursively increasing the resolution of the terrain and adjusting the height of each new point(Raffe et al.,, 2012). The terrains produced by this method typically have a fractal, self-similar structure and details. Other mainstream or efficient procedural terrain generation methods include evolutionary algorithms, erosion simulation, parameter-controlled methods, and user-assisted methods.\n\nIn the field of Generative AI, Guérin et al. presents a novel example-based authoring pipeline for generating realistic virtual terrains using Conditional Generative Adversarial Networks (cGANs) (Guérin et al.,, 2017). They proposed that GANs offer significant advantages in terrain generation, including enhanced realism, user control, efficiency, learning from real-world examples, and ease of use, making them a superior choice over traditional terrain modeling techniques.\n\n3.2 Art and Visual Assets\n\n3.2.1 Sprites\n\nSprites are graphic elements widely used in game development. They first appeared in early computer and video games, and over time, they continue to play a crucial role in modern game development. Sprites can represent various actions of game characters (such as walking, running, jumping, etc.), where each action consists of multiple frames to achieve smooth animation effects. It can also be used as background elements in game scenes or as map tiles in 2D games to create complex game environments. These individual sprites are often organized into sprite sheets, which consolidate multiple small images into a single large image for efficient storage and rendering.\n\nAs project scales increase, the number of sprites also grows, making the management and maintenance of these individual graphic elements increasingly complex. Adding new sprites, deleting old ones, or updating existing ones all require manual adjustments, which is not only time-consuming but also prone to errors. Moreover, for content that needs frequent updates or dynamic loading, traditional methods of sprite management struggle to meet efficiency requirements and demand more optimization and new technological solutions. This is particularly true when dealing with sprite sheets, which are collections of individual sprites organized into a single image for efficient storage and rendering.\n\nIn recent years, there has been a growing interest in combining generative networks with sprites to find better methods for improving the efficiency of image generation and processing.\n\n3.2.2 Motion\n\nIn games, human movement, such as walking, running, and jumping, is driven by the skeleton that moves the torso and limbs. Skeletal animation is a method of 3D animation that uses a hierarchical set of interconnected bones to animate a mesh or character model. It simulates the movement of bones to create realistic and efficient animations for characters and objects in games and other digital media. It breaks down characters into two parts: bones and the skin, and manipulates the bones to drive the movement of the skin. This method provides dynamic and lifelike movements for characters and objects in games.\n\nCreating skeletal animations that adhere to anatomical and physical principles while also considering character personality and emotional expression is a challenging aspect of animation production. Overall, skeletal animation presents a significant challenge in game development, requiring developers to possess extensive experience and skills, and to use advanced techniques and tools to address various technical problems and ensure the quality and effectiveness of game animations.\n\nIn this context, generative network technologies have shown great potential in skeletal animation production. Through adversarial training between a generator and a discriminator, these technologies can produce realistic and natural animation sequences. This approach not only reduces the workload for developers but also enhances the realism and expressiveness of animations.\n\n3.2.3 Character Face\n\nFacial customization systems are a key feature in modern video games and virtual character creation, allowing players to design and customize the facial features of game characters according to their preferences. This system is widely used in role-playing games, simulation games, and social platforms. By utilizing generative networks, it is possible to generate personalized facial features based on player inputs and make adjustments to enhance player engagement.\n\nIn the process of character creation and animation, game developers often start with a base model known as a neutral face. These neutral face models are designed with minimal expression, serving as a blank canvas for further customization and animation. This approach allows developers to add various expressions and emotional portrayals on top of this neutral base, ensuring consistency across different characters and animations.\n\nBy leveraging the adversarial training mechanisms in GANs, it is possible to effectively decouple expression parameters from identity parameters. This decoupling allows the system to generate and manipulate neutral face characters while preserving the unique facial features of the characters. This capability is particularly valuable in facial customization systems, as it enables players to create distinctive characters that can express a wide range of emotions without losing their core identity features.\n\n3.3 Narrative Components\n\nNarrative components are the essential elements that complete a game. Well-crafted narratives can deeply engage players, providing motivation and context for their actions within the game world.\n\nNarrative in games comprise a story and discourse (Kybartas and Bidarra,, 2017). A story is composed of plot and space, where plot involves structured events, and space includes characters and settings. The other component of narrative, discourse, determines how the story is presented.\n\nOne of the most recent research examples that resonates this definition is made by Park et al., who shows a revolutionary approach to narrative content in games using generative AI (Park et al.,, 2023). By creating AI-driven characters with sophisticated memory and planning capabilities, the generative agents framework introduced in the paper enables the emergence of dynamic, player-influenced narratives. These generative agents populate the game world, forming the space of the narrative with their distinct personalities and behaviors. As they interact with each other and the environment, they generate a plot filled with structured yet unpredictable events. The way these interactions unfold and are perceived by the player forms the discourse of the narrative. This AI-driven approach allows for a level of narrative complexity and responsiveness previously unattainable in games. Players can experience unique stories that evolve organically based on their choices and the autonomous decisions of the AI agents, leading to heightened immersion and replayability. By leveraging generative AI in this manner, game developers can create living, breathing worlds where every playthrough tells a different story, pushing the boundaries of interactive storytelling in the digital age.\n\n3.4 Music and Sound Effects\n\nMusic and sound effects, while not essential for the core gameplay progression, are significant elements that greatly enhance the immersive experience of a game.\n\nTraditional sound synthesis methods have certain limitations in terms of generation quality, control over diversity, efficiency, and ease of use. Sampling synthesis methods require pre-recorded source materials, and then create sound effects by mixing and processing different layers of sound, which is time-consuming and labor-intensive. Procedural audio synthesis methods generate sound effects in real-time using mathematical models, but the generated sound quality is often poor and cannot match the quality of recorded sound effects. These traditional methods struggle to efficiently produce a sufficient number of sound effect variants, which fails to effectively reduce auditory fatigue during gameplay, thereby affecting immersion.\n\nNew methods based on deep learning are attempting to address these issues. For example, Andreu and Aylagas present a method for generating controllable variations of sound effects that can be used in the creative process of sound designers for video games(Andreu and Villanueva Aylagas,, 2022). They adopt WaveFlow, a generative flow model that works directly on raw audio and has proven effective for speech synthesis.\n\n4 Methods for Generating Content\n\n4.1 Generative Adversarial Networks\n\nGANs are a kind of generative model based on game theory(Goodfellow et al.,, 2020). GANs train two networks simultaneously: a generator that creates fake data and a discriminator that classifies data as real or fake. The generator aims to fool the discriminator, while the discriminator learns to distinguish between real and generated samples. This adversarial process continues as both networks improve over time.\n\nIn 2018, Giacomello et al. applied GANs to PCG for the game DOOM (Giacomello et al.,, 2018), which is a seminal first-person shooter where players navigate through a series of levels filled with demons and monsters, fighting to reach the exit while collecting weapons, ammunition, and power-ups. The authors trained two GAN models using a dataset of over 1000 human-designed DOOM levels. The first model was an unconditional GAN using only images, while the second was a cGAN that included additional topological features extracted from the levels. The authors analyzed each level to extract six types of images representing various features such as walls, floor height, and game objects. They also extracted numerical and categorical attributes describing the topology of the level. The cGAN included a selection of seven features, such as the number of rooms and equivalent diameter. Their results demonstrated that both GANs could capture the intrinsic structure of DOOM levels, with the cGAN generating levels that were structurally closer to human-designed ones. They evaluated the generated levels using custom metrics inspired by those used for indoor map quality assessment. This research shows that GANs can be a promising tool for procedural generation in first-person shooter games.\n\nSimilarly, Volz et al. also applied GANs to level creation, but for the game Super Mario Bros (Volz et al.,, 2018). In Super Mario Bros, players must traverse a side-scrolling level to reach the end of the level, while avoiding dangerous terrain and enemies. In this work, the authors evaluated the ability of a GAN to generate content when trained on a single sample level. Additionally, they also investigated how the latent space of the GAN could be searched with latent variable evolution (LVE) to create levels with desired properties. The results showed that performing one-hot encoding on tile types provided sufficient information for the GAN to learn level structure. Furthermore, despite only using a single training level, the model produced playable levels resembling those created by human designers. The experiments with LVE showed that level content and properties could be controlled by modifying the fitness function of covariance matrix adaptation evolution strategy (CMA-ES). In their first representation-based approach, the fitness function depended upon the presence of certain types of tiles in the level. By varying the target tile counts, the authors could accurately control the content in the level and craft a progressively harder experience. The second approach was agent-based, and used a fitness function that examined the actions of an agent in a playthrough of the level. Their results showed that this approach was also able to successfully vary the difficulty of a level. This work showed that GANS can be successfully trained even in cases with limited training data, and that LVE could be used to search the latent space for levels with desired properties.\n\nInspired by the work of Volz et al. (Volz et al.,, 2018), Irfan et al.(Irfan et al.,, 2019) adopted a similar approach of generating game levels with GANs. However, one primary difference is the use of image-based data rather than tile type-based data. The dataset used to train their model was itself generated using a random level generator. Additionally, the authors generate levels for three games, namely, Freeway, Zelda, and Colourscape. These games were selected due to how challenging they are for game-playing agents, and are classified as, difficult, average, and easy, respectively. The training process shows that while the model initially cannot generate valid levels, it eventually learns to do so, supporting the use of image-based data for level generation. Finally, after evaluating the generated levels with a game-playing agent, the authors observe that only less than 20% of the levels generated for each game are unplayable. By showing that GANs can generate valid levels with image-based data, this study emphasizes the flexibility of GANs, and provides supporting evidence for their use in generating content for games.\n\nAn often-mentioned barrier to using GANs for PCG in games is the necessity of domain-specific training data. This need is driven by the requirement for the GAN not only to generate usable content, but for the content to also have desired properties, such as realism. Wulff-Jensen et al. (Wulff-Jensen et al.,, 2018) study the generation of 3D landscapes with GANs. As a core component of a 3D playable space, landscapes should contain a mixture of hills, mountains, ravines, and other suitable features. While hand-crafted landscapes may be one of the first choices for training data, they are scarcely available due to high development costs. Instead of using such data, Wulff-Jensen et al. train a GAN on digital elevation data from real locations in Norway and the Alps. One benefit of using data based on real locations is the ability of a GAN to capture and generate features specific to individual locations. Another benefit is the expected realism of generated content. Indeed, evaluators found the generated content to be acceptable realistic, and commented positively on the relatability and traversability of the landscape. These results show how data from the real world can be used to produce varied and realistic content without the costs associated with hand-crafted data.\n\nPark et al. present another application of GANs to level generation, but for educational games rather than for entertainment games(Park et al.,, 2019). Games are an effective tool for education because they provide an engaging environment for students to practice critical thinking and problem-solving skills. However, one challenge that developers of educational games face is developing levels that cover varying levels of competency and expertise. For example, students who are unfamiliar with games may find interacting with games to be challenging, and give up if faced with a level that introduces too many new concepts. Thus, a wide variety of game levels are necessary to promote the development of specific skills. To address the prohibitive cost of generating many levels manually, Park et al. develop a multistep GAN-based framework for level generation in an educational game. The multistep approach was adopted to balance level novelty with solvability. The first step of their approach trains a GAN to generate novel, but not necessarily solvable, levels from human created levels. The second step of their approach filters out generated levels that are unsolvable, and trains a second GAN only on the levels that are solvable. Levels from the second GAN are evaluated on the basis of novelty and solvability, and results show that the multistep approach effectively balances the two metrics. This work shows how some limitations of using GANs can be overcome through an approach that utilizes multiple networks.\n\nPanagiotou et al. formulate another approach to PCG that employs multiple GANs in a sequential manner(Panagiotou and Charou,, 2020; Panagiotou et al.,, 2020). Their goal is the generation of 3D terrains by separately generating overhead satellite-like images and digital elevation models (DEMs). To accomplish this, they first train a progressively growing GAN (ProGAN) (Karras et al.,, 2018) to mimic satellite images. This specific GAN variant both stabilizes and shortens training, and produces high quality images. Next, the authors train a cGAN to generate DEMs. A cGAN framework is used for this purpose so that the output DEM can be influenced by the image generated in the first step such that the 3D terrain generated from the image and DEM appears natural. The authors show that the combination of GANs produces images and DEMs that create believable 3D terrains.\n\nThe advantages of cGANs are evaluated by Hald et al., who generate levels for a tile matching game using both a standard GAN and a cGAN (Hald et al.,, 2020). The game contains a variety of tile type, broadly categorized as structural, non-interactive, and interactive. The data used to condition the GAN generators consists of level shape information using a matrix of structural tile indicators, and piece distribution using the desired proportions of non-interactive and interactive tiles. For the cGAN, this information is also provided to the discriminator. The two generative models are evaluated based on level shape, tile distribution, tile placement, and tile combination. Results show the models perform acceptably with respect to shape and tile combination, but less so for tile distribution and placement. In general, the cGAN improves upon the standard GAN and generates levels that more closely resemble the training set. This work is unique in that it explicitly compares results from a GAN and cGAN and highlights the benefits of using additional information in GAN architectures.\n\nCoutinho and Chaimowicz proposed a Pix2Pix-based (Isola et al.,, 2017)generative model to translate pixel art character sprites from one pose to another (Coutinho and Chaimowicz,, 2022). This approach avoids relying on artificial bone-graph datasets and does not restrict character shapes, offering flexibility in dataset size and diversity. The generator, a U-net structure, translates 64×64646464\\times 6464 × 64 RGBA images into target-pose sprites, while a PatchGAN discriminator performs local image evaluation(Demir and Ünal,, 2018). The study focuses on the effects of different discriminator patch sizes on result quality and the improvement in shape quality using alpha channel information. Experiments with various datasets show that the model can translate colors and shapes of character parts to some extent, though color transfer is sometimes inaccurate, and generated images may have high-frequency noise and blurred edges. Despite this, the model demonstrates some generalization ability, capable of translating poses using similar but different information.\n\nIn 2020, Tianyang Shi et al. proposed PokerFace-GAN, a novel method using generative networks for facial similarity measurement and parameter prediction to achieve automatic game character creation (Shi et al.,, 2020). Their framework consists of three main components: a predictor for facial parameter prediction, a differentiable character renderer that converts these parameters into 3D characters, and a discriminator that classifies whether the generated facial parameters contain expressions. The predictor includes two facial feature extractors, LightCNN-29v2(Wu et al.,, 2018) and ResNet-50(He et al.,, 2015), for capturing identity-variant facial descriptions and precise facial parameters, and a parameter translator to convert these features into identity, expression, and pose parameters. The renderer simulates the behavior of the game engine to transform the parameters into 2D facial images. The discriminator uses a poker face pool for adversarial training to ensure generated parameters do not contain expressions. Trained on the CelebA dataset(Liu et al.,, 2015), PokerFace-GAN successfully generated 3D characters highly similar to input photos, demonstrating its potential for automatic character creation in games and highlighting the effectiveness of combining GANs with differentiable rendering and adversarial training in procedural character generation.\n\nWhile images typically contain local structures like edges and textures, audio signals exhibit periodicity and long-range dependencies that require different architectural considerations. Donahue et al. introduce WaveGAN, a GAN model adapted for raw waveform generation, and SpecGAN, which operates on spectrogram representations(Donahue et al.,, 2019). Techniques like phase shuffling are also proposed to mitigate artifacts specific to audio generation. Experiments on several audio datasets, including spoken digits and environmental sounds, demonstrate that both WaveGAN and SpecGAN can produce coherent audio samples. While SpecGAN achieves higher inception scores, human evaluators preferred the sound quality and speaker diversity of WaveGAN outputs. This is to say that, both waveform and spectrogram approaches show promise for unsupervised audio synthesis, opening up possibilities for creative sound design and other audio generation applications.\n\n4.2 Diffusion Models\n\nA diffusion model is a Markov chain that adds random noise to existing data and then learns the reversed process to transform the noise into structured outputs gradually. It uses neural networks to model Gaussian transitions, enabling it to generate samples matching the original data distribution(Ho et al.,, 2020).\n\nZhang et al. are one of the first to propose using diffusion models to generate human motion from text input (Zhang et al., 2024a, ). Their proposal, MotionDiffuse, offers many improvements over other types of models and architectures. First, motions are generated in a probabilistic way, leading to increased diversity over deterministic counterparts. Second, the model learns a variety of movements and is able to accurately reproduce fine details from text. Finally, the model coordinates signals for different body parts and allows time-varied instructions. Experimental results show that MotionDiffuse is superior to existing methods in all metrics tested, and that movements generated are perceived to be more natural. The remarkable results of MotionDiffuse demonstrate the suitability of diffusion models for generation of complex content.\n\nGenerating long sequences of human motion is generally considered challenging, as many approaches result in unnatural artifacts between repeated motions and a lack in motion diversity. Zhang et al. discuss the promising nature of diffusion models, but note the challenges of long-term generation (Zhang et al.,, 2023). They propose a diffusion-based model in which they align the temporal-axis of the motion sequence with the time-axis of the diffusion process, combined with a buffer of frames of temporally-varying noise. This results in the ability to continuously produce clean and natural frames of motion while allowing the model to explore realistic future movements through increasingly noisy frames. Additionally, guided generation is also possible by replacing frames with a set of guide frames, and allowing the model to smoothly transition towards them. The evaluation shows that the proposal successfully generates natural long-term motions.\n\nAnother significant work regarding the use of diffusion models in human motion generation was conducted by Tevet et al., who introduced the Motion Diffusion Model (Tevet et al.,, 2023). It achieves state-of-the-art results in various human motion generation tasks while being more efficient and versatile than previous approaches. Motion Diffusion Model is a generic approach that can handle different types of conditioning like text and action classes, or even unconditioned generation, all within a single model. One of the most significant improvements of Motion Diffusion Model is its ability to incorporate geometric losses. Geometric losses refer to the loss functions used in human motion generation models to enforce physical properties and prevent artifacts. These loss functions encourage the generation of natural and coherent motions. In the paper, three common geometric losses are experimented with: positions, foot contact, and velocities. By combining geometric loss functions with conventional generative loss functions, the model is designed to enhance the quality and realism of the generated motions. Using these loss functions in diffusion models is challenging but crucial for the motion domain.\n\nTo generate materials for computer graphics, Vecchio et al. propose MatFuse, an approach that uses diffusion models to generate spatially-varying bidirectional reflectance distribution function (SVBRDF) maps (Vecchio et al.,, 2024). The novelty of their approach lies in the ability of MatFuse to use multiple sources of conditioning, including text, color palettes, pictures, and sketches. Additionally, conditions can be applied both at the global level, influencing high-level features of the material, and at the local level, influencing specific details of the material. These features of MatFuse enable a high degree of controllability in material generation. The effectiveness of MatFuse is evident through its performance in quantitative and qualitative evaluations, showing that it can compete with and surpass other generative models.\n\nDai et al. apply unconditional diffusion models to the task of level generation from single examples for Super Mario Bros, a 2D game, and Minecraft, a 3D game (Dai et al.,, 2024). To overcome the challenges faced by many generative models and distinguish their proposal from others, the authors make several modifications to common practices. First, instead of using one-hot encoded vectors to represent pieces in levels, the authors adopt a word embedding approach to represent pieces using dense continuously valued vectors. This modification proves to be more scalable and leads to improved training stability and convergence. Second, in order to reduce overfitting on single examples, the authors restrict the receptive field of the denoising network by using fully convolutional networks with residual connections and train using random crops of levels. When compared to other single example generative methods, the proposed method captures finer details, such as features of houses, and exhibits fewer visual artifacts, such as floating blocks.\n\n4.3 Transformers\n\nThe Transformer is a straightforward network architecture based solely on attention mechanisms, eliminating the need for recurrence and convolutions(Vaswani et al.,, 2017). This architecture has revolutionized various aspects of AI, including natural language processing and content generation. Its ability to handle sequential data and capture long-range dependencies has made it particularly useful in creative applications.\n\nCreating movies is a complex process that requires graphic animation rendering. In 2023, He et al. proposed an AI for generating videos from query texts (He et al.,, 2023). The AI constructed in this study searches for video candidates with scenes and motions suitable for the query texts and then generates videos by combining them to follow the desired plot. Various machine learning technologies such as LLMs, Markov chains, and diffusion models have been applied to construct the AI proposed in this study. Although this research is not specifically focused on content generation in video games, its nature suggests that it could be easily applied to video games.\n\nSudhakaran et al. identify one of the main shortcomings of popular generative methods that rely on latent spaces, such as GANs; tunable generation can only be achieved through a costly search process (Sudhakaran et al.,, 2023). They propose MarioGPT, a method that generates game levels for Super Mario Bros. By proposing an approach that leverages the capabilities of LLMs trained on a diverse corpus, the authors overcome the limitations of latent space-based methods. In terms of usability, the most significant improvement from this approach is tunable generation without the need for searching. This is enabled by the natural language nature of the LLM, allowing one to simply ask for a desired result, rather than searching for it. Additionally, content quality also high, with the majority of levels being diverse and playable. This is a result of using a pre-trained LLM without adding unnecessary layers, such as adaptors. This work highlights the potential of LLMs for PCG, demonstrating simple usage with quality results.\n\nZhang et al. take a multi-modal approach to generating human motion (Zhang et al., 2024b, ). They approach human motion generation by asking a transformer-based LLM to produce desired human motion from an instruction prompt. What makes their proposal unique, and multi-modal, is the inclusion of non-text pose information in the form of discrete codes learned by a vector quantized-variational autoencoder model (van den Oord et al.,, 2017). Their results indicate that the inclusion of pose information is the main factor responsible for the ability of their approach to surpass the performance of other state-of-the-art approaches. They also find that including information of multiple poses throughout a movement are more effective than that of initial or final poses. This work sets a precedent for multi-modal approaches with LLMs and indicates additional improvements may be achieved through other types of data, such as audio.\n\n5 Discussion\n\n5.1 Challenges in Procedural Content Generation for Generative Artificial Intelligence\n\nIn the area of PCG, generative networks face a series of challenges in the domain of visual assets. Firstly, a major issue is the lack of diversity; existing models often perform inadequately when generating visual assets of different styles or types, resulting in outcomes that are neither rich nor diverse. Additionally, generating complex scenes and richly detailed characters remains a significant challenge, especially when dealing with the creation of large-scale game worlds. Current generative models may struggle to handle high-complexity visual content, and the generated visual assets might fall short in terms of realism and aesthetic appeal, with noise issues potentially compromising the quality of the final results.\n\nSimilar issues also arise in game level generation. Since datasets for game levels often come from specific games, their training data is typically small in scale, which is insufficient for training effective generative AI. Additionally, learning for game levels not only requires models to understand spatial relationships, so as to select appropriate tiles and terrains, but also player behavior logic. Learning this logic is necessary to create levels of varying difficulty as well as levels that require various skills. However, neural network models often struggle learning this, leading to content that overly imitates training data.\n\nAnother challenge in PCG is the validation of generated content. While flawed content is undesirable, the effects of it on a game highly depend upon the flaw and type of content. For example, mismatched styles of tiles or colors in a sprite may be visually unappealing, but do not necessarily change gameplay. On the other hand, a level generated through PCG may contain elements that prevent progression. Detecting these aesthetic and functional flaws, and validating desired properties, is a difficult task. One automated approach to this is the use of metrics, which attempt to measure quality on a continuous scale. These are convenient because they can be calculated automatically, reducing unnecessary developer interaction, but should not be used alone as they lack detail. Another approach specific to game levels is the use of gameplaying agents, commonly pathfinding algorithms or other hand-crafted AI, to determine playability. While these are effective, they come at a high computational cost and usually only provide binary indicators as to whether a level has the desired property or not.\n\nFinally, the computational cost of generative AI itself is a significant, yet not often discussed, challenge. Many generative AI models use deep neural networks, which utilize GPUs. While players are expected to have GPUs in order to play games, they typically use these for graphical purposes. Allocating a certain amount of resources to generative AI may necessitate the use of lower graphical settings, detracting from the overall user experience. Furthermore, if generative AI is to be used in real-time, then the computational demand of generation must also be considered to ensure a consistent experience across a range of devices with varying computational capabilities.\n\n5.2 Current Approaches to Procedural Content Generation With Generative AI\n\nThe works that we focus on use different techniques for generation, and there is a clear pattern in their usage over time. Initially, GANs were popular as they were a breakthrough in generative neural networks. Later, when diffusion models and transformers were proposed, they demonstrated significant improvements and gained popularity. Compared to GANs, diffusion models often exhibit more stable training, fewer problems with convergence, and higher quality results. For transformer models, the primary advantage is being able to query a model in natural language. This trend indicates that breakthroughs in neural network technologies result in rapid changes to state-of-the-art methods, suggesting that developers must be flexible when using generative AI methods.\n\nOne common factor among many papers is a combination of techniques and algorithms to produce a generative AI system. For example, a standard GAN alone may not produce desired output every time the generator is used to generate content. This may be improved through the use of a cGAN, in which output can be influenced. However, repeating the generation process is still not guaranteed to produce output with specific features. To address this, the latent space can be searched with an optimization method, resulting in in a guided search that gradually becomes closer to the desired output (Volz et al.,, 2018). This work demonstrates that a combination of effective techniques, algorithms, and models is key to high quality generative AI.\n\nIt is worth noting that generative AI is typically constructed using supervised or unsupervised machine learning methods, which differ from reinforcement learning. Generative AI is built by learning rules encapsulated within vast amounts of data, while reinforcement learning involves providing predefined rules and constructing AI that can operate in accordance with those rules. In the context of PCG, if one can generate vast amounts of data, it seems beneficial to use generative AI. On the other hand, if there is not an abundance of learnable data available, it might be more appropriate to utilize reinforcement learning. This distinction offers a potential guideline for choosing between the two methods based on the data at hand.\n\n5.3 Potential of Generative Artificial Intelligence as Game Mechanics\n\nThe potential of procedural content generation is not just limited to increasing the efficiency of game development, but also includes using it as game mechanics to enhance the experience or even create brand new types of gameplay.\n\nGenerative AI shows great capability in narrative creation, where non-player characters (NPCs) can be set with diverse characteristics and speak as their personalities dictate. With recent advancements in nature language processing, similar ideas have been gradually applied to games such as Treacherous Waters Online and The Portopia Serial Murder Case. In the former, every NPC in the main town is given a unique personality and uses the ChatGPT pre-trained model to converse with players in real time. In the latter, the boundaries of text adventure games are broken, allowing players to gather information and solve cases by “conversing” with related characters, rather than selecting predetermined dialogue options. These attempts represent the frontier of transforming narrative interaction in games, and are worthy of deep exploration by game designers.\n\nUser-Generated Content (UGC) refers to any form of content, such as text, images, videos, and reviews, that is created and shared by users of a platform or service rather than by its official administrators(Kasapakis and Gavalas,, 2017). The concept of UGC has garnered significant attention in recent years due to its success in party games like Eggy Party. The technology of generating game content through Generative AI can play a special role in the development and design of UGC editors. While traditional UGC editors provide game users with crafted assets for tasks such as level creation, generative UGC editors can offer users textures, images, or even 3D models based on specific needs, helping users create more stylized game content with less effort.\n\n5.4 Future Developments for Generative AI in Procedural Content Generation\n\nConsidering recent developments in generative AI for PCG, we expect that future developments will be focused on higher quality content and ease of use. Higher quality content, while an important and natural direction, is not necessarily easily achievable and is attempted through different approaches. Equally important is ease of use. Generative AI that is hard to implement, train, or use, will not see widespread adoption in industry.\n\nOne approach to improving the quality of generated content is to combine multiple technologies. Indeed, this is already common to some extent in existing papers. For example, exploring the latent space of a GAN with search algorithms is used to find content that matches strict criteria. Another example is combining multiple types of neural networks to create generative AI that takes multi-modal input influencing generated content. These examples show that combinations of technologies are necessary for creating content with specific details. We expect there will be future research focusing on combining state-of-the-art techniques from various fields.\n\nAnother factor that influences the quality of content is the size and amount of training data. While many applications of PCG in games note the challenges faced by limited training data, this is not a challenge that is unique to games. For example, AI in medicine frequently faces limited data, especially for rare diseases. A solution that is commonly applied during training is data augmentation, which slightly transforms training data. These augmentations are key to improving performance and preventing overfitting. Despite being frequently used in other fields, few papers mention data augmentation when training models for PCG. One reason for this may be the lack of meaningful transforms for game data. As an example, a vertical flip is a basic data augmentation in image classification. However, vertically flipping images, such as game levels, may not be appropriate for games as it can transform data into a form that is unnatural and would never be encountered otherwise. Therefore, because data augmentation has shown promise in other fields, we expect more researches to address the limits of training data size by evaluating the effectiveness of data augmentation and developing unique transformations for game data.\n\nLastly, ease of use is an important practical concern that significantly affects the usage of techniques by practitioners. Models that require significant training or interaction may offset the time saved from using PCG techniques, potentially discouraging developers. One significant breakthrough in this area is transformers and LLMs, which allow developers to prompt a model, in natural language, for desired content. Generative AI using these models not only understand specific details conveyed through language, but are also easy to use. In the future, we expect more models to include text input and feedback mechanisms.\n\n6 Conclusion\n\nThis paper explores the application of generative AI to Procedural Content Generation, focusing on three primary methods: Generative Adversarial Networks, Transformers, and Diffusion Networks. The application of these generative models in various PCG scenarios is summarized, offering insights for game developers and researchers.\n\nGANs demonstrate a wide range of applications in generating high-quality game environments, characters, and sounds. However, they continue to face challenges with result instability and noise, necessitating further optimization. Transformers excel in handling long sequential data due to their self-attention mechanism, making them particularly suitable for tasks such as movie production, game level generation, and human action generation. Their ability to produce coherent and logical content is a significant advantage in these contexts. Diffusion modeling, an emerging technique that generates high-quality data through gradual noise addition, shows remarkable capabilities in human action generation, material creation, and game level design. Its potential in PCG applications is becoming increasingly evident.\n\nGenerative AI provides diverse methods for PCG, showing potentials and research gaps for researchers or game developers to dig deeper into. Future research should focus on not only improving the models, but also other parts like validating the content, training the dataset and balancing the demand for computing resources and the user experience.\n\nAuthor Contributions\n\nAll authors conducted the survey, contributed to manuscript writing, and approved the final version of the manuscript.\n\nFunding\n\nThis work was supported in part by the Top Global University Project of the Ministry of Education, Culture, Sports, Science and Technology of Japan (MEXT).\n\nAcknowledgments\n\nThe authors have used generative AI technologies for proofreading and translating. Specifically, ChatGPT 3.5 and Claude 2.0 were utilized.\n\nReferences\n\nAndreu and Villanueva Aylagas, (2022) Andreu, S. and Villanueva Aylagas, M. (2022). Neural synthesis of sound effects using flow-based deep generative models. Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, 18(1):2–9.\n\nChen et al., (2018) Chen, Z., Amato, C., Nguyen, T.-H. D., Cooper, S., Sun, Y., and El-Nasr, M. S. (2018). Q-DeckRec: A fast deck recommendation system for collectible card games. IEEE Conference on Computational Intelligence and Games, pages 1–8.\n\nCoutinho and Chaimowicz, (2022) Coutinho, F. and Chaimowicz, L. (2022). Generating pixel art character sprites using GANs. In 2022 21st Brazilian Symposium on Computer Games and Digital Entertainment (SBGames), pages 1–6.\n\nDai et al., (2024) Dai, S., Zhu, X., Li, N., Dai, T., and Wang, Z. (2024). Procedural level generation with diffusion models from a single example. Proceedings of the AAAI Conference on Artificial Intelligence, 38(9):10021–10029.\n\nDemir and Ünal, (2018) Demir, U. and Ünal, G. B. (2018). Patch-based image inpainting with generative adversarial networks. ArXiv, abs/1803.07422.\n\nDonahue et al., (2019) Donahue, C., McAuley, J., and Puckette, M. (2019). Adversarial audio synthesis. In International Conference on Learning Representations.\n\nFontaine et al., (2021) Fontaine, M., Liu, R., Khalifa, A., Modi, J., Togelius, J., Hoover, A., and Nikolaidis, S. (2021). Illuminating Mario scenes in the latent space of a generative adversarial network. Proceedings of the AAAI Conference on Artificial Intelligence, 35:5922–5930.\n\nGiacomello et al., (2018) Giacomello, E., Lanzi, P. L., and Loiacono, D. (2018). DOOM level generation using generative adversarial networks. IEEE Games, Entertainment, Media Conference, pages 316–323.\n\nGoodfellow et al., (2020) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2020). Generative adversarial networks. Commun. ACM, 63(11):139–144.\n\nGuérin et al., (2017) Guérin, E., Digne, J., Galin, E., Peytavie, A., Wolf, C., Benes, B., and Martinez, B. (2017). Interactive example-based terrain authoring with conditional generative adversarial networks. ACM Trans. Graph., 36(6).\n\nGuzdial et al., (2019) Guzdial, M., Liao, N., Chen, J., Chen, S.-Y., Shah, S., Shah, V., Reno, J., Smith, G., and Riedl, M. O. (2019). Friend, collaborator, student, manager: How design of an AI-driven game level editor affects creators. The 2019 CHI Conference on Human Factors in Computing Systems, pages 1–13.\n\nHald et al., (2020) Hald, A., Hansen, J. S., Kristensen, J., and Burelli, P. (2020). Procedural content generation of puzzle games using conditional generative adversarial networks. In Proceedings of the 15th International Conference on the Foundations of Digital Games, FDG ’20, New York, NY, USA. Association for Computing Machinery.\n\nHe et al., (2015) He, K., Zhang, X., Ren, S., and Sun, J. (2015). Deep residual learning for image recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778.\n\nHe et al., (2023) He, Y., Xia, M., Chen, H., Cun, X., Gong, Y., Xing, J., Zhang, Y., Wang, X., Weng, C., Shan, Y., and Chen, Q. (2023). Animate-a-story: Storytelling with retrieval-augmented video generation. arXiv, 2307.06940.\n\nHendrikx et al., (2013) Hendrikx, M., Meijer, S., Van Der Velden, J., and Iosup, A. (2013). Procedural content generation for games: A survey. ACM Transactions on Multimedia Computing, Communications, and Applications, 9(1):1–22.\n\nHo et al., (2020) Ho, J., Jain, A., and Abbeel, P. (2020). Denoising diffusion probabilistic models. In Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS ’20, Red Hook, NY, USA. Curran Associates Inc.\n\nIrfan et al., (2019) Irfan, A., Zafar, A., and Hassan, S. (2019). Evolving levels for general games using deep convolutional generative adversarial networks. 11th Computer Science and Electronic Engineering, pages 96–101.\n\nIsola et al., (2017) Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5967–5976.\n\nKarras et al., (2018) Karras, T., Aila, T., Laine, S., and Lehtinen, J. (2018). Progressive growing of GANs for improved quality, stability, and variation. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net.\n\nKasapakis and Gavalas, (2017) Kasapakis, V. and Gavalas, D. (2017). User-generated content in pervasive games. Comput. Entertain., 16(1).\n\nKhalifa et al., (2020) Khalifa, A., Bontrager, P., Earle, S., and Togelius, J. (2020). PCGRL: Procedural content generation via reinforcement learning. The 16th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, pages 95–101.\n\nKybartas and Bidarra, (2017) Kybartas, B. and Bidarra, R. (2017). A survey on story generation techniques for authoring computational narratives. IEEE Transactions on Computational Intelligence and AI in Games, 9(3):239–253.\n\nLiu et al., (2021) Liu, J., Snodgrass, S., Khalifa, A., Risi, S., Yannakakis, G. N., and Togelius, J. (2021). Deep learning for procedural content generation. Neural Computing and Applications, 33(1):19–37.\n\nLiu et al., (2015) Liu, Z., Luo, P., Wang, X., and Tang, X. (2015). Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV).\n\nMnih et al., (2015) Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves, A., Riedmiller, M., Fidjeland, A. K., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra, D., Legg, S., and Hassabis, D. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540):529–533.\n\nMohaghegh et al., (2023) Mohaghegh, S., Dehnavi, M. A. R., Abdollahinejad, G., and Hashemi, M. (2023). PCGPT: Procedural content generation via transformers. arXiv, 2310.02405.\n\nPanagiotou and Charou, (2020) Panagiotou, E. and Charou, E. (2020). Procedural 3D terrain generation using generative adversarial networks. In Giannakopoulos, G., Galiotou, E., and Vasillas, N., editors, Workshops of the 11th EETN Conference on Artificial Intelligence 2020 co-located with the 11th EETN Conference on Artificial Intelligence (SETN 2020), Athens, Greece, September 2-4, 2020, volume 2844 of CEUR Workshop Proceedings, pages 9–14. CEUR-WS.org.\n\nPanagiotou et al., (2020) Panagiotou, E., Chochlakis, G., Grammatikopoulos, L., and Charou, E. (2020). Generating elevation surface from a single RGB remotely sensed image using deep learning. Remote Sensing, 12(12).\n\nPark et al., (2023) Park, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. (2023). Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, UIST ’23, New York, NY, USA. Association for Computing Machinery.\n\nPark et al., (2019) Park, K., Mott, B. W., Min, W., Boyer, K. E., Wiebe, E. N., and Lester, J. C. (2019). Generating educational game levels with multistep deep convolutional generative adversarial networks. IEEE Conference on Games, pages 1–8.\n\nRaffe et al., (2012) Raffe, W. L., Zambetta, F., and Li, X. (2012). A survey of procedural terrain generation techniques using evolutionary algorithms. In 2012 IEEE Congress on Evolutionary Computation, pages 1–8.\n\nRodriguez Torrado et al., (2020) Rodriguez Torrado, R., Khalifa, A., Cerny Green, M., Justesen, N., Risi, S., and Togelius, J. (2020). Bootstrapping conditional GANs for video game level generation. In 2020 IEEE Conference on Games (CoG), pages 41–48.\n\nShi et al., (2020) Shi, T., Zou, Z., Song, X., Song, Z., Gu, C., Fan, C., and Yuan, Y. (2020). Neutral face game character auto-creation via PokerFace-GAN. In Proceedings of the 28th ACM International Conference on Multimedia, MM ’20, page 3201–3209, New York, NY, USA. Association for Computing Machinery.\n\nSilver et al., (2016) Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., van den Driessche, G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., Dieleman, S., Grewe, D., Nham, J., Kalchbrenner, N., Sutskever, I., Lillicrap, T., Leach, M., Kavukcuoglu, K., Graepel, T., and Hassabis, D. (2016). Mastering the game of Go with deep neural networks and tree search. Nature, 529(7587):484–489.\n\nSnodgrass and Ontañón, (2014) Snodgrass, S. and Ontañón, S. (2014). Experiments in map generation using Markov chains. The 9th International Conference on the Foundations of Digital Games.\n\nSudhakaran et al., (2023) Sudhakaran, S., González-Duque, M., Freiberger, M., Glanois, C., Najarro, E., and Risi, S. (2023). MarioGPT: Open-ended text2level generation through large language models. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S., editors, Advances in Neural Information Processing Systems, volume 36, pages 54213–54227. Curran Associates, Inc.\n\nSummerville et al., (2018) Summerville, A., Snodgrass, S., Guzdial, M., Holmgård, C., Hoover, A. K., Isaksen, A., Nealen, A., and Togelius, J. (2018). Procedural content generation via machine learning. IEEE Transactions on Games, 10(3):257–270.\n\nSummerville and Mateas, (2016) Summerville, A. J. and Mateas, M. (2016). Super Mario as a string: Platformer level generation via LSTMs. The First International Joint Conference of DiGRA and FDG, 13(1).\n\nTevet et al., (2023) Tevet, G., Raab, S., Gordon, B., Shafir, Y., Cohen-or, D., and Bermano, A. H. (2023). Human motion diffusion model. In The Eleventh International Conference on Learning Representations.\n\n(40) Togelius, J., Kastbjerg, E., Schedl, D., and Yannakakis, G. N. (2011a). What is procedural content generation? Mario on the borderline. The 2nd International Workshop on Procedural Content Generation in Games, 3:1–6.\n\n(41) Togelius, J., Yannakakis, G. N., Stanley, K. O., and Browne, C. (2011b). Search-based procedural content generation: A taxonomy and survey. IEEE Transactions on Computational Intelligence and AI in Games, 3(3):172–186.\n\nvan den Oord et al., (2017) van den Oord, A., Vinyals, O., and Kavukcuoglu, K. (2017). Neural discrete representation learning. In Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS’17, page 6309–6318, Red Hook, NY, USA. Curran Associates Inc.\n\nVaswani et al., (2017) Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. (2017). Attention is all you need. In Advances in Neural Information Processing Systems, NIPS’17, page 6000–6010, Red Hook, NY, USA. Curran Associates Inc.\n\nVecchio et al., (2024) Vecchio, G., Sortino, R., Palazzo, S., and Spampinato, C. (2024). MatFuse: Controllable material generation with diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 4429–4438.\n\nVolz et al., (2018) Volz, V., Schrum, J., Liu, J., Lucas, S. M., Smith, A., and Risi, S. (2018). Evolving Mario levels in the latent space of a deep convolutional generative adversarial network. Proceedings of the Genetic and Evolutionary Computation Conference, page 221–228.\n\nWu et al., (2018) Wu, X., He, R., Sun, Z., and Tan, T. (2018). A light cnn for deep face representation with noisy labels. IEEE Transactions on Information Forensics and Security, 13(11):2884–2896.\n\nWulff-Jensen et al., (2018) Wulff-Jensen, A., Rant, N. N., Møller, T. N., and Billeskov, J. A. (2018). Deep convolutional generative adversarial network for procedural 3D landscape generation based on DEM. Interactivity, Game Creation, Design, Learning, and Innovation, pages 85–94.\n\n(48) Zhang, M., Cai, Z., Pan, L., Hong, F., Guo, X., Yang, L., and Liu, Z. (2024a). Motiondiffuse: Text-driven human motion generation with diffusion model. IEEE Transactions on Pattern Analysis & Machine Intelligence, 46(06):4115–4128.\n\n(49) Zhang, Y., Huang, D., Liu, B., Tang, S., Lu, Y., Chen, L., Bai, L., Chu, Q., Yu, N., and Ouyang, W. (2024b). MotionGPT: Finetuned LLMs are general-purpose motion generators. Proceedings of the AAAI Conference on Artificial Intelligence, 38(7):7368–7376.\n\nZhang et al., (2023) Zhang, Z., Liu, R., Aberman, K., and Hanocka, R. (2023). TEDi: Temporally-entangled diffusion for long-term motion synthesis. arXiv, 2307.15042."
    }
}