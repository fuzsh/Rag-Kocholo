{
    "id": "dbpedia_4771_2",
    "rank": 92,
    "data": {
        "url": "https://levelup.gitconnected.com/the-history-of-early-programming-languages-1b4067f624a1",
        "read_more_link": "",
        "language": "en",
        "title": "A Brief History of Early Programming Languages",
        "top_image": "https://miro.medium.com/v2/resize:fit:1200/1*0y6lDv_BI077Q56GRNOS9w.jpeg",
        "meta_img": "https://miro.medium.com/v2/resize:fit:1200/1*0y6lDv_BI077Q56GRNOS9w.jpeg",
        "images": [
            "https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:88:88/1*H6iZUQAQsC1L6rKGzR8QVw.jpeg",
            "https://miro.medium.com/v2/resize:fill:48:48/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg",
            "https://miro.medium.com/v2/resize:fill:144:144/1*H6iZUQAQsC1L6rKGzR8QVw.jpeg",
            "https://miro.medium.com/v2/resize:fill:64:64/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Alex Moltzau",
            "alexmoltzau.medium.com"
        ],
        "publish_date": "2020-09-13T23:04:06.355000+00:00",
        "summary": "",
        "meta_description": "From Babbage to Babel and Beyond is an article written by Linda Weiser Friedman. This text is a summary of her article that reviews the history of computer programming languages. She describes four…",
        "meta_lang": "en",
        "meta_favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*MMpkJtmeCME-6BmGNH5l8A.png",
        "meta_site_name": "Medium",
        "canonical_link": "https://levelup.gitconnected.com/the-history-of-early-programming-languages-1b4067f624a1",
        "text": "From Babbage to Babel and Beyond is an article written by Linda Weiser Friedman. This text is a summary of her article that reviews the history of computer programming languages. She describes four ‘generations’ of software starting with machine code through to different languages, paradigms and environments.\n\nAccording to Friedman in the 90’s (the time of writing) some of the oldest programming languages were the most popular ones. She mentions FORTRAN and COBOL in particular. She also argues that:\n\n“To study high-level programming languages by examining only the state of such languages as they exist today would be incomplete.”\n\nShe asks the question.\n\nWhy did high-level languages evolve?\n\nWhy are we not still programming in machine code?\n\nEarly programming languages have a lot of influence on later ones. Many programming languages have similar constructs.\n\nPerhaps it is important to examine previous languages.\n\nShe refers to a series of previous studies. Amongst them Knuth who has studied mathematical and numerical algorithms from antiquity to the modern era. From describing ‘static functional relationships’ ( such as equations in mathematics) to notations for a dynamic process (algorithms).\n\n“Often, in order to denote an algorithm as an input-output transformation, one would simply express it as y=f(x), where x is the input variable, y is the output variable, and f is the abstract (or “black box”) model, the (possibly numerical) algorithm.”\n\nShe claims that Algorithms have been ‘wordy’ and ‘imprecise’ before entering an examination of early computing hardware and software.\n\nThe Analytics Engine\n\nThe earliest known computer is acknowledged to be Charles Babbage’s design for an Analytic Engine in 1834. It was designed to provide changeable sequence of numerical operations and internal storage of data. It could not be built in his lifetime, but still his collaborator Lady Augusta Ada, Countess of Lovelace(and daughter of the poet Lord Byron), coded programs for it.\n\nMachine-code operations on Babbage’s machine were of the form:\n\nV~ × V2= V3, with operations(e.g. the multiply operation)and variable.\n\nIt used punchcards (Jacquards).\n\nCards were fed into a machine and worked on internal data.\n\nConditioned inside to accommodate conditional ‘jumps’ (done by physically jumping over cards).\n\nLady Lovelace thinking about the repetitive sequences of operations is therefore credited to have innovated the concept of a loop or repetition construct.\n\nBabbage can be credited as the first computer architect, and Lovelace as the first computer programmer.\n\nEDVAC\n\nIt was not before 1945 that stored-program computer was described and implemented. This occurred with the University of Pennsylvania of John von Neumann's: \"First Draft of a Report on the EDVAC\".\n\nThe EDVAC (Electronic Discrete Variable Arithmetic Computer) describes a processor coupled with primary storage.\n\nThis configuration has become known as the von Neumann architecture:\n\n“…describes a configuration in which the processor is tightly coupled to primary storage, primary storage is large enough to store vast amounts of data along with the program code and operations are executed sequentially without the parallelism that was needed on earlier machines to counteract their extremely limited storage capabilities.”\n\nDevelopments in Hardware\n\nFriedman (1992) constructed a frame to help gain an overview of the development of hardware. This looks like the following:\n\nShe describes this as a historical overview of computer machinery from early experimental projects to Japan’s Fifth Generation Project.\n\nThe first electronic computer for commercial use on the list is the Remington Rand’s UNIVAC from 1951. The first was purchased by the U.S. Department of the Census. This was based on vacuum tubes.\n\nThe later computers were characterised by new and different technology:\n\nTransistors.\n\nIntegrated circuits.\n\nLarge-scale integration.\n\nApparently in 1951 with the installation of the UNIVAC it was predicted that 12 computers would be in the U.S. by 1975. They were quite wrong. By 1975 there were 155,000 computers in use. By the end of 1989 this figure was up to 54 million.\n\nFriedman goes on to described software generations as a ladder:\n\nFirst software generation — machine language programming\n\nFriedman discusses software in four generations. According to her it relates to a sort of rung in the ‘ladder’ between human and computer user.\n\n“The first generation of computer software is the era of machine language programming.”\n\nDuring the 1940’s and the early 1950’s all coding was done in machine language. That means the computer’s own internal (binary-based) instruction set.\n\nMachine coding or ‘hand coding’ remained popular long after this. Every machine had its own built in code.\n\nEvery task was coded ‘from scratch’ with little opportunity for generalising.\n\n“The word wasn’t programming then, but coding, and programmers were coders.”\n\nAccording to Friedman the word programmer originated in England, it crossed the Atlantic over to the US in the 1950’s and by then it was more ‘prestigious’ to be a programmer than a coder.\n\nIn form of formal communication between members of the community there was not much.\n\nHowever, The Association for Computing Machinery (ACM) was formed in 1947 and journals began publishing a few years later.\n\nLittle thought was given to ownership because it was hard to attribute to a single source.\n\nFriedman says:\n\n“In 1947, an event occurred which is of special interest to programmers and students of computing. Grace Murray Hopper, in investigating why the Mark I1 computer was not working properly, discovered a small dead moth in the machine and removed it with a tweezer. The moth went into her logbook along with a note recording the incident for posterity. From then on, computing errors were called “bugs” and the process of finding and removing them known as “debugging”.”\n\nAs a side note, although the author claims this there seems to be a few ‘bugs’ or errors with this statement.\n\nHoward Aiken suggested a ‘coding machine’ for the Mark III. By pressing a button machine code would be punched on a paper tape. In this way a human coder would not have to bother memorising many complicated sequences of binary code.\n\nFriedman describes this as a spark towards the second generation of software.\n\nSecond software generation — the pre-compiler era\n\nThe second generation coding aids such as for machine language coding specialists.\n\nThis included different automations and assemblers. A time ‘marked by many firsts’.\n\nFriedman asks us to consider the programming or ‘coding’ culture at the time in light of the innovations that came:\n\n“we have to bear in mind, firstly, that the mindset of the coding establishment was such that anything other than hand-coding was considered to be inferior and, secondly, that those hand-coded machine language programs were actually very complex and intricate and did as much with less storage as our sophisticated programs do today.”\n\nShe also says that the scepticism was warranted since these systems turned out programs that were less efficient and more costly than the equivalent hand-coded versions produced by clever, inventive human coders.\n\nSo, at this time programmers did not always program ‘from scratch’. Many would manually copy sections of code.\n\nCopying was fraught with ‘transcription errors’.\n\nIn 1949 John Mauchly proposed ‘Short-Order Code’ or ‘Short Code’ for the BINAC (BINary Automatic Computer). The computer was built by John Mauchly and J. Presper Eckert, it was later bought out by Remington-Rand.\n\nShort Code: was a set of interpretive subroutines stored in memory. Short Code executed about fifty times slower than the equivalent hand-coded program.\n\nThe years 1950–1951 saw an emergence of a host of artificial machine languages or ‘pseudo codes’.\n\n“In the early 1950’s Betty Holbertson’s Sort-Merge Generator was a first attempt towards using a computer to write programs and inspired a whole family of other program generators.”\n\nIn 1951 the first textbook for programming came over from England. It was called “The Preparation of Programs for a Digital Computer,” authored by Wilkes, Wheeler and Gill.\n\nIt discussed ‘assembly routine’, referring to: “…a piece of code which would combine a set of subroutines and allocate storage as blocks of relocatable addressed called ‘floating addresses’.”\n\nIn 1951, Grace Murray Hopper working on Remington-Rand’s UNIVAC I came up with what she called a ‘compiling routine’, as the act of translating ‘pseudo-code’ into a complete set of machine language instructions.\n\nIn 1952, Millie Coss came out with the ‘Editing Generator’ taking arithmetic operations and printing an output readable by managers and other humans.\n\nFriedman described the 1952 development of an AUTOCODE system by Alick E. Glennie as a link to the ‘third generation’ of software. It was a primitive, highly machine-dependent algebraic compiler that translated algebraic statements into the machine language of the Manchester Mark I.\n\nThird software generation — procedural languages\n\nIn 1945, a theoretical programming language was developed in Fed. Rep. Germany by Konrad Zuse, called Plankalkul (programcalculus), although this went unnoticed until about 1972.\n\nIn Italy Corrado Bohm’s doctoral dissertation from 1951 describes a system that defines every statement as a special case of the assigned statement, for example S would be equivalent to ‘set the program counter to the value of the variable S’.\n\nThe first algebraic compiler is considered to be for MIT’s WHIRLWIND computer designed by Jay Forrester and Ken Olsen. It was the first 16-bit minicomputer capable of parallel processing and real-time computing. It was demonstrated in spring 1953 and up and running January 1954.\n\nIn 1955, Grace Murray Hoppe’s programming team began to develop an algebraic programming language that users some English keywords.\n\nIn 1957, it was released as MATH-MATIC, and it executed inefficiently. In 1957 IBM finally delivered the compiler for FORTRAN. It was increasingly accepted in the computing community.\n\nIn 1958, FLOW-MATIC was released and became an important factor in the subsequent design of COBOL.\n\nFORTRAN (FORmula TRANslating System)\n\nIn 1954, John Backus led an IBM team of researcher (later named the Programming Research Group) to design and develop automatic translators of mathematical formulas into IBM 704 machine code. They would accept nothing less than something as efficient as their hand-coded counterparts. Their overriding concern was efficiency, as according to Friedman it may be more likely to be accepted by the coding community. Language design aspect was handled quickly. Described by Friedman: “…in the manner of a chore that had to be completed before the ‘real’ work (the design of the compiler) could be done.”\n\nFORmula TRANslating System,or FORTRAN was released in 1954 with a large part of the document devoted to the justification of the system, including an optimistic expectation that FORTRAN would eliminate coding and debugging.\n\nIn 1958, FORTRAN compilers were released for the IBM 709 and the 650; in 1960 for the 1620 and 7070. The versions were not necessarily identical and a program written on one computer did not necessarily produce the same result on another.\n\nIn 1961, FORTRAN compilers were made available for other computers (UNIVAC, Remington-Rand LARC and ALTAC).\n\nIn 1964 there were more than 40 different FORTRAN compilers on the market. It must be said that it was not machine-independent language, and computer differently on different computers.\n\nIn 1958 FORTRAN II was released, followed by FORTRAN III and FORTRAN IV in 1962. FORTRAN IV was the standard for the language until FORTRAN 77 was released in 1978.\n\nLISP (LISt Processor)\n\nDuring the years 1956–1958 an interactive, applicative language was designed at Darthmouth by John McCarthy.\n\nIn 1959, this was later implemented at MIT with a reference manual published in 1960.\n\nLISP is based on lambda-calculus, and unlike other languages it was designed for symbolic formula manipulation. Friedman argues it became the ‘lingua franca’ (medium of communication) for the artificial intelligence community.\n\nShe lists some innovative features as the following:\n\nThe function as the basic program unit.\n\nThe list as the basic data structure.\n\nDynamic data structures.\n\nFacilities for ‘garbage collections’.\n\nUse of symbolic expressions as opposed to numbers.\n\nRecursion.\n\nConditional expression as control structures.\n\nThe ‘eval’ function for interactive evaluation of LISP statements.\n\nALGOL (ALGOrithmic -Language)\n\nIn 1958, a committee held meetings in Zurich to design a universal high-level programming language. It featured European representatives from GAMM (German association for applied mathematics and mechanics), and the Association for Computing Machinery. One of the members of the committee was John Backus, who had led the FORTRAN development group.\n\nOne of the goals was to facilitate communication and exchange in the international computing community alongside the practical goal to bring a compiler to Europe (they were still hand-coding). One of the reasons a new language was desired was that FORTRAN was a proprietary IBM product. Adopting FORTRAN would therefore somewhat mean buying only IBM machines, and there was a wish for IBM not to dominate in Europe.\n\nThe language was first named IAL, for International Algebraic Language ,and eventually renamed ALGOL (ALGOrithmic -Language). The first version was known as ALGOL 58.\n\nThe committee met again in Paris in 1960 to improve the language and eliminate weaknesses.\n\n“The influence of ALGOL60 on programming language design, and on the development of computer science in general, has been nothing less than profound.”\n\nFriedman lists a few innovative features:\n\nBNF (Backus Normal Form), metalanguage for programming language definition.\n\nThe programming language as an object of study rather than just a means towards an end.\n\nUsed as a publication language for algorithms.\n\nBlock structure and localised data environments.\n\nNesting of program units.\n\nFree-format program code.\n\nExplicit type declerations.\n\nDynamic memory allocation.\n\nParameter passing by value and name.\n\nIf /then/else and begin/end to delimit compound statements.\n\nScoping rules.\n\nDeclaration of local variables.\n\nParameters passed by name, value or reference.\n\nCOBOL (COmmonBusiness-Oriented-Language\n\nIn 1959, another group met under the oversight of the Department of the Defense in the United States to discuss developing a ‘common’ programming language.\n\n“This group, composed of about 40 members, represented computer manufacturers and users from industry, universities, and government and became known as the CODASYL Committee(COOnferenceon DAta SYstemsLanguages).”\n\nIt was in the interest of both computer manufacturers and the government to design a language that could work on different machines.\n\nIn April 1960 a language called COBOL was made.\n\nUnlike FORTRAN the language started out relatively ‘machine-independent’.\n\nFor many first and second generation programming was poorly understood by most and considered as Friedman says: a ‘black art’.\n\nImportant innovations in COBOL according to Friedman are the following:\n\nThe record data structure.\n\nFile descriptions and manipulation facilities.\n\nMachine independence of data and program descriptions.\n\nEqual emphasis on data descriptions in the Data Divisions and the operations in the Procedure Division.\n\nInfluence of English in the use of verbs, clauses, sentences, paragraphs, sections, and divisions.\n\nA relatively natural language styles, including noise words for readability.\n\nThe overall effort towards a language that would produce self-documenting program code.\n\nThey started an important trend toward data-oriented languages. Friedman argues this has culminated in the proliferation of database management systems, query languages, and database-centred high-productivity programming tools and environments.\n\nThere was a widespread availability of COBOL compilers partly due to government involvement:\n\n“…the Department of Defense sent a strongly worded letter to all computer manufacturers advising them that if they wanted to continue to sell computers to the Department of Defense(the largest computer contracter and endower of research grants) they had better put a COBOL compiler on it.”\n\nFriedman comments that FORTRAN, COBOL and LISP were among the most used programming languages at the time of writing (approx. 1990).\n\nBabel → 1960’s and 1970's\n\n“The decades of the 1960s and the 1970s saw a truly amazing proliferation of programming languages.It was this hubub of activity that Jean Sammetin 1969 likened to the Biblical Tower of Babel.”\n\nAPL (A Programming Language). Defined and introduced to the public in 1962 through a book by Kenneth Iverson at Harvard, who took part in designing this. It required a special keyboard and did not become widely used.\n\nSNOBOL (StriNg Oriented symBOlic Language). First implemented in 1963, it was designed by researchers at Bell Laboratories as a string manipulation language. The implementation was actually named SEXI (String EXpression Interpreter), but it was apparently considered unacceptable. The name of the language was a humorous jab at acronyms: SNOBOL (StriNg OrientedsymBOlicLanguag). SNOBOL4 was released in 1968 designed for third generation computer hardware, it treats patterns as data objects. The unique feature was its facility for string and pattern matching.\n\nBASIC (Beginner's All-purpose Symbolic Instructional Code). Code ran in 1964, and the language design was intended to introduce students in non-scientific disciplines to computing. Simplicity was chosen over compiler efficiency, and clear error messages were provided.\n\nPL/1 (Programming Language/one). Released 1966, intended as the ‘language to end all languages’, but not as popular as IBM had hoped. Compilers were inefficient and unreliable. It has been criticised as a language to big, as it tried to include every conceivable element of language design.\n\nLogo. Developed over the years 1966–1968. Designed specifically for mathematics education, used experimentally in classrooms. Logo is very similar to LISP. It includes ‘turtle graphics’, for teaching kids geometric principles.\n\nFORTH (fourth-generation language). Charles H. Moore wanted a language efficient enough for scientific and engineering applications, yet allow for faster programming using fewer lines of code. Two (apparently) conflicting design goals it seems. According to Friedman it cannot be considered a fourth generation language today.\n\nSIMULA. Designed in 1962 by Kristen Nygaard and Ole-Johan Dahl at the Norwegian Computing Center under contract with Univac. Motivated by a wish to simulate applications — a technique of operations research successfully used in a number of diverse areas. This language introduced the ‘class concept’, an important abstraction for object-oriented programming.\n\nPascal (named after 17th century French philosopher and mathematician Blaise Pascal). The revision of ALGOL68 (from ALGOL60) was not popular, as it was needlessly big and awkward. One of the ‘dissenters’ Niklaus Wirth designed Pascal, which was first implemented in 1970. Friedman argues that Pascal designed for use in education stood out: “…in opposition to a trend”. A trend of complicating a language with features so no user could expect to know all of them.\n\nC. Kenneth Thompson and Dennis Ritchie developed C for coding the routines in a UNIX operating system. C was an extension of B (also designed by Thompson) that drew on an earlier language BCPL. C created the notion of a portable operating system. Friedman argues that a concise syntax makes C programs difficult to read, understand, debug and maintain.\n\nModula-2 (MODUlar LAnguage/two). Descendant of Pascal, intended for large systems. The module facilitates information sharing, encapsulating code in clearly delineated pieces.\n\nAda. Proposed in 1980 and standardised in 1983 it had similar intents as PL/1 (language to end all languages) and similar success.\n\nAfter the announcement of FORTRAN with the report in 1954 there were a great deal of languages that attempted to: “…tame the electronic computer for high-level use by humans in every application area.”\n\nFriedman has been so kind as to draw a model of some of the influences between the different languages:\n\nFourth software generation — declarative languages\n\n“The von Neumann-typeof computer architecture, while serving as catalyst for a generation of programming languages may also, it appears, be guilty in large part for the degree of stagnation we have seen in the conceptual development of programming language technology.”\n\nWhat Friedman refers to is the stored program in memory locations with a single counter in a flow of sequence instructions. Programming languages relying on this prior paradigm (procedural) architecture tend to be:\n\nStatement-oriented (assuming sequential execution of a limited number of operations).\n\nComposed of vast numbers of lines of code. Debugging is arduous and lengthy.\n\nMaintenance is time-consuming and costly.\n\nFriedman argues that this next paradigm is declerative:\n\n“A fourth generation language is declarative, i.e. its instructions to the computer concentrate more on what is to be done rather than on describing in detail how to do it.”\n\nFourth generation seeks to optimise human labour over computer time.\n\nFrequently aimed at a non-technical user in a particular application area.\n\nSome of the trends according to Friedman are:\n\nDeclarative language.\n\nPackaged software.\n\nIntegrated packages.\n\nUser-friendly interactive environments.\n\nQuery languages.\n\nHigh-productivity programming tools.\n\nThe integration of languages.\n\nProgramming tools (editor, linker, translators, file handler and user interface within a single interactive system).\n\nShe mentions that not all systems are non-procedural and the classification is arbitrary.\n\nIn 1961, the statistical package BMD (BioMeDicalpackage) is developed at the University of California Berkeley and implemented in FORTRAN on the IBM 7090.\n\nIn 1967, Arthur S. Couch developed DATATEXT at Harvard University aimed at social scientists.\n\nPROLOG (Programming in LOGic). Implemented in 1972 in ALGOL-W for the purpose of natural-language processing. Since 1981 it became associated with Japan’s Fifth Generation Project.\n\nOPS (Official Production System). A production-system or rule-based language used in the field of artificial intelligence. OPS5 released in 1977.\n\nSmalltalk. Designed and implemented at Xerox Palo Alto Research Center (PARC) as the software component of: “Alan Kay’s legendary Dynabook, a notebook-sized personal computer for the non-technical user.” The environment was important: mouse for selecting and pointing; graphical user menus and so on. Steve Jobs used this approach with the Apple Computers Lisa and Macintosh operating system.\n\nQuery languages. Made to make databases accessible to people with minimal training, query languages were developed to be user-friendly. SQL was developed for SystemsR and several other ways to query. SQL was designed at IBM and marketed in 1979 by Oracle.\n\nFriedman argues:\n\n“A fourth-generation high-productivity tool is largely non-procedural, user-friendly, and problem-oriented.”\n\nFurther, she says that these systems have been centred around a database and include components of a database management system.\n\nSoftware began with humans forced to ‘think’ in code for a specific machine.\n\nAt the time of writing Friedman already argues that computers can ‘think’ or act to some extent like human beings.\n\nLinda Weiser Friedman’s article is a fascinating read and I do of course recommend that you read it in full rather than my limited summary.\n\nI hope you enjoyed this article!"
    }
}