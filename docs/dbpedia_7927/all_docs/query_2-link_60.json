{
    "id": "dbpedia_7927_2",
    "rank": 60,
    "data": {
        "url": "https://www.science.gov/topicpages/f/first-order%2Bautoregressive%2Bprocess",
        "read_more_link": "",
        "language": "en",
        "title": "order autoregressive process: Topics by Science.gov",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.science.gov/scigov/desktop/en/images/SciGov_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "A time series model: First-order integer-valued autoregressive (INAR(1))\n\nNASA Astrophysics Data System (ADS)\n\nSimarmata, D. M.; Novkaniza, F.; Widyaningsih, Y.\n\n2017-07-01\n\nNonnegative integer-valued time series arises in many applications. A time series model: first-order Integer-valued AutoRegressive (INAR(1)) is constructed by binomial thinning operator to model nonnegative integer-valued time series. INAR (1) depends on one period from the process before. The parameter of the model can be estimated by Conditional Least Squares (CLS). Specification of INAR(1) is following the specification of (AR(1)). Forecasting in INAR(1) uses median or Bayesian forecasting methodology. Median forecasting methodology obtains integer s, which is cumulative density function (CDF) until s, is more than or equal to 0.5. Bayesian forecasting methodology forecasts h-step-ahead of generating the parameter of the model and parameter of innovation term using Adaptive Rejection Metropolis Sampling within Gibbs sampling (ARMS), then finding the least integer s, where CDF until s is more than or equal to u . u is a value taken from the Uniform(0,1) distribution. INAR(1) is applied on pneumonia case in Penjaringan, Jakarta Utara, January 2008 until April 2016 monthly.\n\nModified Confidence Intervals for the Mean of an Autoregressive Process.\n\nDTIC Science & Technology\n\n1985-08-01\n\nValidity of the method 45 3.6 Theorem 47 4 Derivation of corrections 48 Introduction 48 The zero order pivot 50 4.1 Algorithm 50 CONTENTS The first...of standard confidence intervals. There are several standard methods of setting confidence intervals in simulations, including the regener- ative... method , batch means, and time series methods . We-will focus-s on improved confidence intervals for the mean of an autoregressive process, and as such our\n\nMathematical model with autoregressive process for electrocardiogram signals\n\nNASA Astrophysics Data System (ADS)\n\nEvaristo, Ronaldo M.; Batista, Antonio M.; Viana, Ricardo L.; Iarosz, Kelly C.; Szezech, JosÃ© D., Jr.; Godoy, Moacir F. de\n\n2018-04-01\n\nThe cardiovascular system is composed of the heart, blood and blood vessels. Regarding the heart, cardiac conditions are determined by the electrocardiogram, that is a noninvasive medical procedure. In this work, we propose autoregressive process in a mathematical model based on coupled differential equations in order to obtain the tachograms and the electrocardiogram signals of young adults with normal heartbeats. Our results are compared with experimental tachogram by means of PoincarÃ© plot and dentrended fluctuation analysis. We verify that the results from the model with autoregressive process show good agreement with experimental measures from tachogram generated by electrical activity of the heartbeat. With the tachogram we build the electrocardiogram by means of coupled differential equations.\n\nModeling Polio Data Using the First Order Non-Negative Integer-Valued Autoregressive, INAR(1), Model\n\nNASA Astrophysics Data System (ADS)\n\nVazifedan, Turaj; Shitan, Mahendran\n\nTime series data may consists of counts, such as the number of road accidents, the number of patients in a certain hospital, the number of customers waiting for service at a certain time and etc. When the value of the observations are large it is usual to use Gaussian Autoregressive Moving Average (ARMA) process to model the time series. However if the observed counts are small, it is not appropriate to use ARMA process to model the observed phenomenon. In such cases we need to model the time series data by using Non-Negative Integer valued Autoregressive (INAR) process. The modeling of counts data is based on the binomial thinning operator. In this paper we illustrate the modeling of counts data using the monthly number of Poliomyelitis data in United States between January 1970 until December 1983. We applied the AR(1), Poisson regression model and INAR(1) model and the suitability of these models were assessed by using the Index of Agreement(I.A.). We found that INAR(1) model is more appropriate in the sense it had a better I.A. and it is natural since the data are counts.\n\nIs First-Order Vector Autoregressive Model Optimal for fMRI Data?\n\nPubMed\n\nTing, Chee-Ming; Seghouane, Abd-Krim; Khalid, Muhammad Usman; Salleh, Sh-Hussain\n\n2015-09-01\n\nWe consider the problem of selecting the optimal orders of vector autoregressive (VAR) models for fMRI data. Many previous studies used model order of one and ignored that it may vary considerably across data sets depending on different data dimensions, subjects, tasks, and experimental designs. In addition, the classical information criteria (IC) used (e.g., the Akaike IC (AIC)) are biased and inappropriate for the high-dimensional fMRI data typically with a small sample size. We examine the mixed results on the optimal VAR orders for fMRI, especially the validity of the order-one hypothesis, by a comprehensive evaluation using different model selection criteria over three typical data types--a resting state, an event-related design, and a block design data set--with varying time series dimensions obtained from distinct functional brain networks. We use a more balanced criterion, Kullback's IC (KIC) based on Kullback's symmetric divergence combining two directed divergences. We also consider the bias-corrected versions (AICc and KICc) to improve VAR model selection in small samples. Simulation results show better small-sample selection performance of the proposed criteria over the classical ones. Both bias-corrected ICs provide more accurate and consistent model order choices than their biased counterparts, which suffer from overfitting, with KICc performing the best. Results on real data show that orders greater than one were selected by all criteria across all data sets for the small to moderate dimensions, particularly from small, specific networks such as the resting-state default mode network and the task-related motor networks, whereas low orders close to one but not necessarily one were chosen for the large dimensions of full-brain networks.\n\nTheoretical results on fractionally integrated exponential generalized autoregressive conditional heteroskedastic processes\n\nNASA Astrophysics Data System (ADS)\n\nLopes, SÃ­lvia R. C.; Prass, Taiane S.\n\n2014-05-01\n\nHere we present a theoretical study on the main properties of Fractionally Integrated Exponential Generalized Autoregressive Conditional Heteroskedastic (FIEGARCH) processes. We analyze the conditions for the existence, the invertibility, the stationarity and the ergodicity of these processes. We prove that, if { is a FIEGARCH(p,d,q) process then, under mild conditions, { is an ARFIMA(q,d,0) with correlated innovations, that is, an autoregressive fractionally integrated moving average process. The convergence order for the polynomial coefficients that describes the volatility is presented and results related to the spectral representation and to the covariance structure of both processes { and { are discussed. Expressions for the kurtosis and the asymmetry measures for any stationary FIEGARCH(p,d,q) process are also derived. The h-step ahead forecast for the processes {, { and { are given with their respective mean square error of forecast. The work also presents a Monte Carlo simulation study showing how to generate, estimate and forecast based on six different FIEGARCH models. The forecasting performance of six models belonging to the class of autoregressive conditional heteroskedastic models (namely, ARCH-type models) and radial basis models is compared through an empirical application to Brazilian stock market exchange index.\n\nMultifractality and autoregressive processes of dry spell lengths in Europe: an approach to their complexity and predictability\n\nNASA Astrophysics Data System (ADS)\n\nLana, X.; BurgueÃ±o, A.; Serra, C.; MartÃ­nez, M. D.\n\n2017-01-01\n\nDry spell lengths, DSL, defined as the number of consecutive days with daily rain amounts below a given threshold, may provide relevant information about drought regimes. Taking advantage of a daily pluviometric database covering a great extension of Europe, a detailed analysis of the multifractality of the dry spell regimes is achieved. At the same time, an autoregressive process is applied with the aim of predicting DSL. A set of parameters, namely Hurst exponent, H, estimated from multifractal spectrum, f( Î±), critical HÃ¶lder exponent, Î± 0, for which f( Î±) reaches its maximum value, spectral width, W, and spectral asymmetry, B, permits a first clustering of European rain gauges in terms of the complexity of their DSL series. This set of parameters also allows distinguishing between time series describing fine- or smooth-structure of the DSL regime by using the complexity index, CI. Results of previous monofractal analyses also permits establishing comparisons between smooth-structures, relatively low correlation dimensions, notable predictive instability and anti-persistence of DSL for European areas, sometimes submitted to long droughts. Relationships are also found between the CI and the mean absolute deviation, MAD, and the optimum autoregressive order, OAO, of an ARIMA( p, d,0) autoregressive process applied to the DSL series. The detailed analysis of the discrepancies between empiric and predicted DSL underlines the uncertainty over predictability of long DSL, particularly for the Mediterranean region.\n\nFirst- and second-order processing in transient stereopsis.\n\nPubMed\n\nEdwards, M; Pope, D R; Schor, C M\n\n2000-01-01\n\nLarge-field stimuli were used to investigate the interaction of first- and second-order pathways in transient-stereo processing. Stimuli consisted of sinewave modulations in either the mean luminance (first-order stimulus) or the contrast (second-order stimulus) of a dynamic-random-dot field. The main results of the present study are that: (1) Depth could be extracted with both the first-order and second-order stimuli; (2) Depth could be extracted from dichoptically mixed first- and second-order stimuli, however, the same stimuli, when presented as a motion sequence, did not result in a motion percept. Based upon these findings we conclude that the transient-stereo system processes both first- and second-order signals, and that these two signals are pooled prior to the extraction of transient depth. This finding of interaction between first- and second-order stereoscopic processing is different from the independence that has been found with the motion system.\n\nAutoregressive Processes in Homogenization of GNSS Tropospheric Data\n\nNASA Astrophysics Data System (ADS)\n\nKlos, A.; Bogusz, J.; Teferle, F. N.; Bock, O.; Pottiaux, E.; Van Malderen, R.\n\n2016-12-01\n\nOffsets due to changes in hardware equipment or any other artificial event are all a subject of a task of homogenization of tropospheric data estimated within a processing of Global Navigation Satellite System (GNSS) observables. This task is aimed at identifying exact epochs of offsets and estimate their magnitudes since they may artificially under- or over-estimate trend and its uncertainty delivered from tropospheric data and used in climate studies. In this research, we analysed a common data set of differences of Integrated Water Vapour (IWV) from GPS and ERA-Interim (1995-2010) provided for a homogenization group working within ES1206 COST Action GNSS4SWEC. We analysed daily IWV records of GPS and ERA-Interim in terms of trend, seasonal terms and noise model with Maximum Likelihood Estimation in Hector software. We found that this data has a character of autoregressive process (AR). Basing on this analysis, we performed Monte Carlo simulations of 25 years long data with two different noise types: white as well as combination of white and autoregressive and also added few strictly defined offsets. This synthetic data set of exactly the same character as IWV from GPS and ERA-Interim was then subjected to a task of manual and automatic/statistical homogenization. We made blind tests and detected possible epochs of offsets manually. We found that simulated offsets were easily detected in series with white noise, no influence of seasonal signal was noticed. The autoregressive series were much more problematic when offsets had to be determined. We found few epochs, for which no offset was simulated. This was mainly due to strong autocorrelation of data, which brings an artificial trend within. Due to regime-like behaviour of AR it is difficult for statistical methods to properly detect epochs of offsets, which was previously reported by climatologists.\n\nExplanation of power law behavior of autoregressive conditional duration processes based on the random multiplicative process\n\nNASA Astrophysics Data System (ADS)\n\nSato, Aki-Hiro\n\n2004-04-01\n\nAutoregressive conditional duration (ACD) processes, which have the potential to be applied to power law distributions of complex systems found in natural science, life science, and social science, are analyzed both numerically and theoretically. An ACD(1) process exhibits the singular second order moment, which suggests that its probability density function (PDF) has a power law tail. It is verified that the PDF of the ACD(1) has a power law tail with an arbitrary exponent depending on a model parameter. On the basis of theory of the random multiplicative process a relation between the model parameter and the power law exponent is theoretically derived. It is confirmed that the relation is valid from numerical simulations. An application of the ACD(1) to intervals between two successive transactions in a foreign currency market is shown.\n\nExplanation of power law behavior of autoregressive conditional duration processes based on the random multiplicative process.\n\nPubMed\n\nSato, Aki-Hiro\n\n2004-04-01\n\nAutoregressive conditional duration (ACD) processes, which have the potential to be applied to power law distributions of complex systems found in natural science, life science, and social science, are analyzed both numerically and theoretically. An ACD(1) process exhibits the singular second order moment, which suggests that its probability density function (PDF) has a power law tail. It is verified that the PDF of the ACD(1) has a power law tail with an arbitrary exponent depending on a model parameter. On the basis of theory of the random multiplicative process a relation between the model parameter and the power law exponent is theoretically derived. It is confirmed that the relation is valid from numerical simulations. An application of the ACD(1) to intervals between two successive transactions in a foreign currency market is shown.\n\n[Correlation coefficient-based classification method of hydrological dependence variability: With auto-regression model as example].\n\nPubMed\n\nZhao, Yu Xi; Xie, Ping; Sang, Yan Fang; Wu, Zi Yi\n\n2018-04-01\n\nHydrological process evaluation is temporal dependent. Hydrological time series including dependence components do not meet the data consistency assumption for hydrological computation. Both of those factors cause great difficulty for water researches. Given the existence of hydrological dependence variability, we proposed a correlationcoefficient-based method for significance evaluation of hydrological dependence based on auto-regression model. By calculating the correlation coefficient between the original series and its dependence component and selecting reasonable thresholds of correlation coefficient, this method divided significance degree of dependence into no variability, weak variability, mid variability, strong variability, and drastic variability. By deducing the relationship between correlation coefficient and auto-correlation coefficient in each order of series, we found that the correlation coefficient was mainly determined by the magnitude of auto-correlation coefficient from the 1 order to p order, which clarified the theoretical basis of this method. With the first-order and second-order auto-regression models as examples, the reasonability of the deduced formula was verified through Monte-Carlo experiments to classify the relationship between correlation coefficient and auto-correlation coefficient. This method was used to analyze three observed hydrological time series. The results indicated the coexistence of stochastic and dependence characteristics in hydrological process.\n\nHow to compare cross-lagged associations in a multilevel autoregressive model.\n\nPubMed\n\nSchuurman, NoÃ©mi K; Ferrer, Emilio; de Boer-Sonnenschein, Mieke; Hamaker, Ellen L\n\n2016-06-01\n\nBy modeling variables over time it is possible to investigate the Granger-causal cross-lagged associations between variables. By comparing the standardized cross-lagged coefficients, the relative strength of these associations can be evaluated in order to determine important driving forces in the dynamic system. The aim of this study was twofold: first, to illustrate the added value of a multilevel multivariate autoregressive modeling approach for investigating these associations over more traditional techniques; and second, to discuss how the coefficients of the multilevel autoregressive model should be standardized for comparing the strength of the cross-lagged associations. The hierarchical structure of multilevel multivariate autoregressive models complicates standardization, because subject-based statistics or group-based statistics can be used to standardize the coefficients, and each method may result in different conclusions. We argue that in order to make a meaningful comparison of the strength of the cross-lagged associations, the coefficients should be standardized within persons. We further illustrate the bivariate multilevel autoregressive model and the standardization of the coefficients, and we show that disregarding individual differences in dynamics can prove misleading, by means of an empirical example on experienced competence and exhaustion in persons diagnosed with burnout. (PsycINFO Database Record (c) 2016 APA, all rights reserved).\n\nProcessing on weak electric signals by the autoregressive model\n\nNASA Astrophysics Data System (ADS)\n\nDing, Jinli; Zhao, Jiayin; Wang, Lanzhou; Li, Qiao\n\n2008-10-01\n\nA model of the autoregressive model of weak electric signals in two plants was set up for the first time. The result of the AR model to forecast 10 values of the weak electric signals is well. It will construct a standard set of the AR model coefficient of the plant electric signal and the environmental factor, and can be used as the preferences for the intelligent autocontrol system based on the adaptive characteristic of plants to achieve the energy saving on agricultural productions.\n\nKepler AutoRegressive Planet Search: Motivation & Methodology\n\nNASA Astrophysics Data System (ADS)\n\nCaceres, Gabriel; Feigelson, Eric; Jogesh Babu, G.; Bahamonde, Natalia; Bertin, Karine; Christen, Alejandra; CurÃ©, Michel; Meza, Cristian\n\n2015-08-01\n\nThe Kepler AutoRegressive Planet Search (KARPS) project uses statistical methodology associated with autoregressive (AR) processes to model Kepler lightcurves in order to improve exoplanet transit detection in systems with high stellar variability. We also introduce a planet-search algorithm to detect transits in time-series residuals after application of the AR models. One of the main obstacles in detecting faint planetary transits is the intrinsic stellar variability of the host star. The variability displayed by many stars may have autoregressive properties, wherein later flux values are correlated with previous ones in some manner. Auto-Regressive Moving-Average (ARMA) models, Generalized Auto-Regressive Conditional Heteroskedasticity (GARCH), and related models are flexible, phenomenological methods used with great success to model stochastic temporal behaviors in many fields of study, particularly econometrics. Powerful statistical methods are implemented in the public statistical software environment R and its many packages. Modeling involves maximum likelihood fitting, model selection, and residual analysis. These techniques provide a useful framework to model stellar variability and are used in KARPS with the objective of reducing stellar noise to enhance opportunities to find as-yet-undiscovered planets. Our analysis procedure consisting of three steps: pre-processing of the data to remove discontinuities, gaps and outliers; ARMA-type model selection and fitting; and transit signal search of the residuals using a new Transit Comb Filter (TCF) that replaces traditional box-finding algorithms. We apply the procedures to simulated Kepler-like time series with known stellar and planetary signals to evaluate the effectiveness of the KARPS procedures. The ARMA-type modeling is effective at reducing stellar noise, but also reduces and transforms the transit signal into ingress/egress spikes. A periodogram based on the TCF is constructed to concentrate the signal\n\nKepler AutoRegressive Planet Search (KARPS)\n\nNASA Astrophysics Data System (ADS)\n\nCaceres, Gabriel\n\n2018-01-01\n\nOne of the main obstacles in detecting faint planetary transits is the intrinsic stellar variability of the host star. The Kepler AutoRegressive Planet Search (KARPS) project implements statistical methodology associated with autoregressive processes (in particular, ARIMA and ARFIMA) to model stellar lightcurves in order to improve exoplanet transit detection. We also develop a novel Transit Comb Filter (TCF) applied to the AR residuals which provides a periodogram analogous to the standard Box-fitting Least Squares (BLS) periodogram. We train a random forest classifier on known Kepler Objects of Interest (KOIs) using select features from different stages of this analysis, and then use ROC curves to define and calibrate the criteria to recover the KOI planet candidates with high fidelity. These statistical methods are detailed in a contributed poster (Feigelson et al., this meeting).These procedures are applied to the full DR25 dataset of NASAâs Kepler mission. Using the classification criteria, a vast majority of known KOIs are recovered and dozens of new KARPS Candidate Planets (KCPs) discovered, including ultra-short period exoplanets. The KCPs will be briefly presented and discussed.\n\nOrder Selection for General Expression of Nonlinear Autoregressive Model Based on Multivariate Stepwise Regression\n\nNASA Astrophysics Data System (ADS)\n\nShi, Jinfei; Zhu, Songqing; Chen, Ruwen\n\n2017-12-01\n\nAn order selection method based on multiple stepwise regressions is proposed for General Expression of Nonlinear Autoregressive model which converts the model order problem into the variable selection of multiple linear regression equation. The partial autocorrelation function is adopted to define the linear term in GNAR model. The result is set as the initial model, and then the nonlinear terms are introduced gradually. Statistics are chosen to study the improvements of both the new introduced and originally existed variables for the model characteristics, which are adopted to determine the model variables to retain or eliminate. So the optimal model is obtained through data fitting effect measurement or significance test. The simulation and classic time-series data experiment results show that the method proposed is simple, reliable and can be applied to practical engineering.\n\nCharacteristics of the transmission of autoregressive sub-patterns in financial time series\n\nNASA Astrophysics Data System (ADS)\n\nGao, Xiangyun; An, Haizhong; Fang, Wei; Huang, Xuan; Li, Huajiao; Zhong, Weiqiong\n\n2014-09-01\n\nThere are many types of autoregressive patterns in financial time series, and they form a transmission process. Here, we define autoregressive patterns quantitatively through an econometrical regression model. We present a computational algorithm that sets the autoregressive patterns as nodes and transmissions between patterns as edges, and then converts the transmission process of autoregressive patterns in a time series into a network. We utilised daily Shanghai (securities) composite index time series to study the transmission characteristics of autoregressive patterns. We found statistically significant evidence that the financial market is not random and that there are similar characteristics between parts and whole time series. A few types of autoregressive sub-patterns and transmission patterns drive the oscillations of the financial market. A clustering effect on fluctuations appears in the transmission process, and certain non-major autoregressive sub-patterns have high media capabilities in the financial time series. Different stock indexes exhibit similar characteristics in the transmission of fluctuation information. This work not only proposes a distinctive perspective for analysing financial time series but also provides important information for investors.\n\nCharacteristics of the transmission of autoregressive sub-patterns in financial time series\n\nPubMed Central\n\nGao, Xiangyun; An, Haizhong; Fang, Wei; Huang, Xuan; Li, Huajiao; Zhong, Weiqiong\n\n2014-01-01\n\nThere are many types of autoregressive patterns in financial time series, and they form a transmission process. Here, we define autoregressive patterns quantitatively through an econometrical regression model. We present a computational algorithm that sets the autoregressive patterns as nodes and transmissions between patterns as edges, and then converts the transmission process of autoregressive patterns in a time series into a network. We utilised daily Shanghai (securities) composite index time series to study the transmission characteristics of autoregressive patterns. We found statistically significant evidence that the financial market is not random and that there are similar characteristics between parts and whole time series. A few types of autoregressive sub-patterns and transmission patterns drive the oscillations of the financial market. A clustering effect on fluctuations appears in the transmission process, and certain non-major autoregressive sub-patterns have high media capabilities in the financial time series. Different stock indexes exhibit similar characteristics in the transmission of fluctuation information. This work not only proposes a distinctive perspective for analysing financial time series but also provides important information for investors. PMID:25189200\n\nFirst-order inflation\n\nNASA Technical Reports Server (NTRS)\n\nKolb, Edward W.\n\n1991-01-01\n\nIn the original proposal, inflation occurred in the process of a strongly first-order phase transition. This model was soon demonstrated to be fatally flawed. Subsequent models for inflation involved phase transitions that were second-order, or perhaps weakly first-order; some even involved no phase transition at all. Recently the possibility of inflation during a strongly first-order phase transition has been revived. In this talk I will discuss some models for first-order inflation, and emphasize unique signatures that result if inflation is realized in a first-order transition. Before discussing first-order inflation, I will briefly review some of the history of inflation to demonstrate how first-order inflation differs from other models.\n\nMixture of autoregressive modeling orders and its implication on single trial EEG classification\n\nPubMed Central\n\nAtyabi, Adham; Shic, Frederick; Naples, Adam\n\n2016-01-01\n\nAutoregressive (AR) models are of commonly utilized feature types in Electroencephalogram (EEG) studies due to offering better resolution, smoother spectra and being applicable to short segments of data. Identifying correct ARâs modeling order is an open challenge. Lower model orders poorly represent the signal while higher orders increase noise. Conventional methods for estimating modeling order includes Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC) and Final Prediction Error (FPE). This article assesses the hypothesis that appropriate mixture of multiple AR orders is likely to better represent the true signal compared to any single order. Better spectral representation of underlying EEG patterns can increase utility of AR features in Brain Computer Interface (BCI) systems by increasing timely & correctly responsiveness of such systems to operatorâs thoughts. Two mechanisms of Evolutionary-based fusion and Ensemble-based mixture are utilized for identifying such appropriate mixture of modeling orders. The classification performance of the resultant AR-mixtures are assessed against several conventional methods utilized by the community including 1) A well-known set of commonly used orders suggested by the literature, 2) conventional order estimation approaches (e.g., AIC, BIC and FPE), 3) blind mixture of AR features originated from a range of well-known orders. Five datasets from BCI competition III that contain 2, 3 and 4 motor imagery tasks are considered for the assessment. The results indicate superiority of Ensemble-based modeling order mixture and evolutionary-based order fusion methods within all datasets. PMID:28740331\n\nThe Performance of Multilevel Growth Curve Models under an Autoregressive Moving Average Process\n\nERIC Educational Resources Information Center\n\nMurphy, Daniel L.; Pituch, Keenan A.\n\n2009-01-01\n\nThe authors examined the robustness of multilevel linear growth curve modeling to misspecification of an autoregressive moving average process. As previous research has shown (J. Ferron, R. Dailey, & Q. Yi, 2002; O. Kwok, S. G. West, & S. B. Green, 2007; S. Sivo, X. Fan, & L. Witta, 2005), estimates of the fixed effects were unbiased, and Type Iâ¦\n\nKepler AutoRegressive Planet Search\n\nNASA Astrophysics Data System (ADS)\n\nCaceres, Gabriel Antonio; Feigelson, Eric\n\n2016-01-01\n\nThe Kepler AutoRegressive Planet Search (KARPS) project uses statistical methodology associated with autoregressive (AR) processes to model Kepler lightcurves in order to improve exoplanet transit detection in systems with high stellar variability. We also introduce a planet-search algorithm to detect transits in time-series residuals after application of the AR models. One of the main obstacles in detecting faint planetary transits is the intrinsic stellar variability of the host star. The variability displayed by many stars may have autoregressive properties, wherein later flux values are correlated with previous ones in some manner. Our analysis procedure consisting of three steps: pre-processing of the data to remove discontinuities, gaps and outliers; AR-type model selection and fitting; and transit signal search of the residuals using a new Transit Comb Filter (TCF) that replaces traditional box-finding algorithms. The analysis procedures of the project are applied to a portion of the publicly available Kepler light curve data for the full 4-year mission duration. Tests of the methods have been made on a subset of Kepler Objects of Interest (KOI) systems, classified both as planetary `candidates' and `false positives' by the Kepler Team, as well as a random sample of unclassified systems. We find that the ARMA-type modeling successfully reduces the stellar variability, by a factor of 10 or more in active stars and by smaller factors in more quiescent stars. A typical quiescent Kepler star has an interquartile range (IQR) of ~10 e-/sec, which may improve slightly after modeling, while those with IQR ranging from 20 to 50 e-/sec, have improvements from 20% up to 70%. High activity stars (IQR exceeding 100) markedly improve. A periodogram based on the TCF is constructed to concentrate the signal of these periodic spikes. When a periodic transit is found, the model is displayed on a standard period-folded averaged light curve. Our findings to date on real\n\nStudy on homogenization of synthetic GNSS-retrieved IWV time series and its impact on trend estimates with autoregressive noise\n\nNASA Astrophysics Data System (ADS)\n\nKlos, Anna; Pottiaux, Eric; Van Malderen, Roeland; Bock, Olivier; Bogusz, Janusz\n\n2017-04-01\n\nA synthetic benchmark dataset of Integrated Water Vapour (IWV) was created within the activity of \"Data homogenisation\" of sub-working group WG3 of COST ES1206 Action. The benchmark dataset was created basing on the analysis of IWV differences retrieved by Global Positioning System (GPS) International GNSS Service (IGS) stations using European Centre for Medium-Range Weather Forecats (ECMWF) reanalysis data (ERA-Interim). Having analysed a set of 120 series of IWV differences (ERAI-GPS) derived for IGS stations, we delivered parameters of a number of gaps and breaks for every certain station. Moreover, we estimated values of trends, significant seasonalities and character of residuals when deterministic model was removed. We tested five different noise models and found that a combination of white and autoregressive processes of first order describes the stochastic part with a good accuracy. Basing on this analysis, we performed Monte Carlo simulations of 25 years long data with two different types of noise: white as well as combination of white and autoregressive processes. We also added few strictly defined offsets, creating three variants of synthetic dataset: easy, less-complicated and fully-complicated. The 'Easy' dataset included seasonal signals (annual, semi-annual, 3 and 4 months if present for a particular station), offsets and white noise. The 'Less-complicated' dataset included above-mentioned, as well as the combination of white and first order autoregressive processes (AR(1)+WH). The 'Fully-complicated' dataset included, beyond above, a trend and gaps. In this research, we show the impact of manual homogenisation on the estimates of trend and its error. We also cross-compare the results for three above-mentioned datasets, as the synthetized noise type might have a significant influence on manual homogenisation. Therefore, it might mostly affect the values of trend and their uncertainties when inappropriately handled. In a future, the synthetic dataset\n\nGaussian Process Autoregression for Simultaneous Proportional Multi-Modal Prosthetic Control With Natural Hand Kinematics.\n\nPubMed\n\nXiloyannis, Michele; Gavriel, Constantinos; Thomik, Andreas A C; Faisal, A Aldo\n\n2017-10-01\n\nMatching the dexterity, versatility, and robustness of the human hand is still an unachieved goal in bionics, robotics, and neural engineering. A major limitation for hand prosthetics lies in the challenges of reliably decoding user intention from muscle signals when controlling complex robotic hands. Most of the commercially available prosthetic hands use muscle-related signals to decode a finite number of predefined motions and some offer proportional control of open/close movements of the whole hand. Here, in contrast, we aim to offer users flexible control of individual joints of their artificial hand. We propose a novel framework for decoding neural information that enables a user to independently control 11 joints of the hand in a continuous manner-much like we control our natural hands. Toward this end, we instructed six able-bodied subjects to perform everyday object manipulation tasks combining both dynamic, free movements (e.g., grasping) and isometric force tasks (e.g., squeezing). We recorded the electromyographic and mechanomyographic activities of five extrinsic muscles of the hand in the forearm, while simultaneously monitoring 11 joints of hand and fingers using a sensorized data glove that tracked the joints of the hand. Instead of learning just a direct mapping from current muscle activity to intended hand movement, we formulated a novel autoregressive approach that combines the context of previous hand movements with instantaneous muscle activity to predict future hand movements. Specifically, we evaluated a linear vector autoregressive moving average model with exogenous inputs and a novel Gaussian process ( ) autoregressive framework to learn the continuous mapping from hand joint dynamics and muscle activity to decode intended hand movement. Our approach achieves high levels of performance (RMSE of 8Â°/s and ). Crucially, we use a small set of sensors that allows us to control a larger set of independently actuated degrees of freedom of a hand\n\nTexture classification using autoregressive filtering\n\nNASA Technical Reports Server (NTRS)\n\nLawton, W. M.; Lee, M.\n\n1984-01-01\n\nA general theory of image texture models is proposed and its applicability to the problem of scene segmentation using texture classification is discussed. An algorithm, based on half-plane autoregressive filtering, which optimally utilizes second order statistics to discriminate between texture classes represented by arbitrary wide sense stationary random fields is described. Empirical results of applying this algorithm to natural and sysnthesized scenes are presented and future research is outlined.\n\nFirst-order inflation. [in cosmology\n\nNASA Technical Reports Server (NTRS)\n\nKolb, Edward W.\n\n1991-01-01\n\nIn the original proposal, inflation occurred in the process of a strongly first-order phase transition. This model was soon demonstrated to be fatally flawed. Subsequent models for inflation involved phase transitions that were second-order, or perhaps weakly first-order; some even involved no phase transition at all. Recently the possibility of inflation during a strongly first-order phase transition has been revived. In this paper, some models for first-order inflation are discussed, and unique signatures that result if inflation is realized in a first-order transition are emphasized. Some of the history of inflation is reviewed to demonstrate how first-order inflation differs from other models.\n\nInvestigating local network interactions underlying first- and second-order processing.\n\nPubMed\n\nEllemberg, Dave; Allen, Harriet A; Hess, Robert F\n\n2004-01-01\n\nWe compared the spatial lateral interactions for first-order cues to those for second-order cues, and investigated spatial interactions between these two types of cues. We measured the apparent modulation depth of a target Gabor at fixation, in the presence and the absence of horizontally flanking Gabors. The Gabors' gratings were either added to (first-order) or multiplied with (second-order) binary 2-D noise. Apparent \"contrast\" or modulation depth (i.e., the perceived difference between the high and low luminance regions for the first-order stimulus, or between the high and low contrast regions for the second-order stimulus) was measured with a modulation depth-matching paradigm. For each observer, the first- and second-order Gabors were equated for apparent modulation depth without the flankers. Our results indicate that at the smallest inter-element spacing, the perceived reduction in modulation depth is significantly smaller for the second-order than for the first-order stimuli. Further, lateral interactions operate over shorter distances and the spatial frequency and orientation tuning of the suppression effect are broader for second- than first-order stimuli. Finally, first- and second-order information interact in an asymmetrical fashion; second-order flankers do not reduce the apparent modulation depth of the first-order target, whilst first-order flankers reduce the apparent modulation depth of the second-order target.\n\nLinear models of coregionalization for multivariate lattice data: Order-dependent and order-free cMCARs.\n\nPubMed\n\nMacNab, Ying C\n\n2016-08-01\n\nThis paper concerns with multivariate conditional autoregressive models defined by linear combination of independent or correlated underlying spatial processes. Known as linear models of coregionalization, the method offers a systematic and unified approach for formulating multivariate extensions to a broad range of univariate conditional autoregressive models. The resulting multivariate spatial models represent classes of coregionalized multivariate conditional autoregressive models that enable flexible modelling of multivariate spatial interactions, yielding coregionalization models with symmetric or asymmetric cross-covariances of different spatial variation and smoothness. In the context of multivariate disease mapping, for example, they facilitate borrowing strength both over space and cross variables, allowing for more flexible multivariate spatial smoothing. Specifically, we present a broadened coregionalization framework to include order-dependent, order-free, and order-robust multivariate models; a new class of order-free coregionalized multivariate conditional autoregressives is introduced. We tackle computational challenges and present solutions that are integral for Bayesian analysis of these models. We also discuss two ways of computing deviance information criterion for comparison among competing hierarchical models with or without unidentifiable prior parameters. The models and related methodology are developed in the broad context of modelling multivariate data on spatial lattice and illustrated in the context of multivariate disease mapping. The coregionalization framework and related methods also present a general approach for building spatially structured cross-covariance functions for multivariate geostatistics. Â© The Author(s) 2016.\n\nEstimates of Zenith Total Delay trends from GPS reprocessing with autoregressive process\n\nNASA Astrophysics Data System (ADS)\n\nKlos, Anna; Hunegnaw, Addisu; Teferle, Felix Norman; Ebuy Abraha, Kibrom; Ahmed, Furqan; Bogusz, Janusz\n\n2017-04-01\n\nNowadays, near real-time Zenith Total Delay (ZTD) estimates from Global Positioning System (GPS) observations are routinely assimilated into numerical weather prediction (NWP) models to improve the reliability of forecasts. On the other hand, ZTD time series derived from homogeneously re-processed GPS observations over long periods have the potential to improve our understanding of climate change on various temporal and spatial scales. With such time series only recently reaching somewhat adequate time spans, the application of GPS-derived ZTD estimates to climate monitoring is still to be developed further. In this research, we examine the character of noise in ZTD time series for 1995-2015 in order to estimate more realistic magnitudes of trend and its uncertainty than would be the case if the stochastic properties are not taken into account. Furthermore, the hourly sampled, homogeneously re-processed and carefully homogenized ZTD time series from over 700 globally distributed stations were classified into five major climate zones. We found that the amplitudes of annual signals reach values of 10-150 mm with minimum values for the polar and Alpine zones. The amplitudes of daily signals were estimated to be 0-12 mm with maximum values found for the dry zone. We examined seven different noise models for the residual ZTD time series after modelling all known periodicities. This identified a combination of white plus autoregressive process of fourth order to be optimal to match all changes in power of the ZTD data. When the stochastic properties are neglected, ie. a pure white noise model is employed, only 11 from 120 trends were insignificant. Using the optimum noise model more than half of the 120 examined trends became insignificant. We show that the uncertainty of ZTD trends is underestimated by a factor of 3-12 when the stochastic properties of the ZTD time series are ignored and we conclude that it is essential to properly model the noise characteristics of\n\nMaximum likelihood estimation for periodic autoregressive moving average models\n\nUSGS Publications Warehouse\n\nVecchia, A.V.\n\n1985-01-01\n\nA useful class of models for seasonal time series that cannot be filtered or standardized to achieve second-order stationarity is that of periodic autoregressive moving average (PARMA) models, which are extensions of ARMA models that allow periodic (seasonal) parameters. An approximation to the exact likelihood for Gaussian PARMA processes is developed, and a straightforward algorithm for its maximization is presented. The algorithm is tested on several periodic ARMA(1, 1) models through simulation studies and is compared to moment estimation via the seasonal Yule-Walker equations. Applicability of the technique is demonstrated through an analysis of a seasonal stream-flow series from the Rio Caroni River in Venezuela.\n\nKepler AutoRegressive Planet Search\n\nNASA Astrophysics Data System (ADS)\n\nFeigelson, Eric\n\nNASA's Kepler mission is the source of more exoplanets than any other instrument, but the discovery depends on complex statistical analysis procedures embedded in the Kepler pipeline. A particular challenge is mitigating irregular stellar variability without loss of sensitivity to faint periodic planetary transits. This proposal presents a two-stage alternative analysis procedure. First, parametric autoregressive ARFIMA models, commonly used in econometrics, remove most of the stellar variations. Second, a novel matched filter is used to create a periodogram from which transit-like periodicities are identified. This analysis procedure, the Kepler AutoRegressive Planet Search (KARPS), is confirming most of the Kepler Objects of Interest and is expected to identify additional planetary candidates. The proposed research will complete application of the KARPS methodology to the prime Kepler mission light curves of 200,000: stars, and compare the results with Kepler Objects of Interest obtained with the Kepler pipeline. We will then conduct a variety of astronomical studies based on the KARPS results. Important subsamples will be extracted including Habitable Zone planets, hot super-Earths, grazing-transit hot Jupiters, and multi-planet systems. Groundbased spectroscopy of poorly studied candidates will be performed to better characterize the host stars. Studies of stellar variability will then be pursued based on KARPS analysis. The autocorrelation function and nonstationarity measures will be used to identify spotted stars at different stages of autoregressive modeling. Periodic variables with folded light curves inconsistent with planetary transits will be identified; they may be eclipsing or mutually-illuminating binary star systems. Classification of stellar variables with KARPS-derived statistical properties will be attempted. KARPS procedures will then be applied to archived K2 data to identify planetary transits and characterize stellar variability.\n\nChemical Dosing and First-Order Kinetics\n\nERIC Educational Resources Information Center\n\nHladky, Paul W.\n\n2011-01-01\n\nCollege students encounter a variety of first-order phenomena in their mathematics and science courses. Introductory chemistry textbooks that discuss first-order processes, usually in conjunction with chemical kinetics or radioactive decay, stop at single, discrete dose events. Although single-dose situations are important, multiple-dose events,â¦\n\nDetecting P and S-wave of Mt. Rinjani seismic based on a locally stationary autoregressive (LSAR) model\n\nNASA Astrophysics Data System (ADS)\n\nNurhaida, Subanar, Abdurakhman, Abadi, Agus Maman\n\n2017-08-01\n\nSeismic data is usually modelled using autoregressive processes. The aim of this paper is to find the arrival times of the seismic waves of Mt. Rinjani in Indonesia. Kitagawa algorithm's is used to detect the seismic P and S-wave. Householder transformation used in the algorithm made it effectively finding the number of change points and parameters of the autoregressive models. The results show that the use of Box-Cox transformation on the variable selection level makes the algorithm works well in detecting the change points. Furthermore, when the basic span of the subinterval is set 200 seconds and the maximum AR order is 20, there are 8 change points which occur at 1601, 2001, 7401, 7601,7801, 8001, 8201 and 9601. Finally, The P and S-wave arrival times are detected at time 1671 and 2045 respectively using a precise detection algorithm.\n\nSmall Sample Properties of Bayesian Multivariate Autoregressive Time Series Models\n\nERIC Educational Resources Information Center\n\nPrice, Larry R.\n\n2012-01-01\n\nThe aim of this study was to compare the small sample (N = 1, 3, 5, 10, 15) performance of a Bayesian multivariate vector autoregressive (BVAR-SEM) time series model relative to frequentist power and parameter estimation bias. A multivariate autoregressive model was developed based on correlated autoregressive time series vectors of varyingâ¦\n\nSleep analysis for wearable devices applying autoregressive parametric models.\n\nPubMed\n\nMendez, M O; Villantieri, O; Bianchi, A; Cerutti, S\n\n2005-01-01\n\nWe applied time-variant and time-invariant parametric models in both healthy subjects and patients with sleep disorder recordings in order to assess the skills of those approaches to sleep disorders diagnosis in wearable devices. The recordings present the Obstructive Sleep Apnea (OSA) pathology which is characterized by fluctuations in the heart rate, bradycardia in apneonic phase and tachycardia at the recovery of ventilation. Data come from a web database in www.physionet.org. During OSA the spectral indexes obtained by time-variant lattice filters presented oscillations that correspond to the changes brady-tachycardia of the RR intervals and greater values than healthy ones. Multivariate autoregressive models showed an increment in very low frequency component (PVLF) at each apneic event. Also a rise in high frequency component (PHF) occurred over the breathing restore in the spectrum of both quadratic coherence and cross-spectrum in OSA. These autoregressive parametric approaches could help in the diagnosis of Sleep Disorder inside of the wearable devices.\n\nMethodology for the AutoRegressive Planet Search (ARPS) Project\n\nNASA Astrophysics Data System (ADS)\n\nFeigelson, Eric; Caceres, Gabriel; ARPS Collaboration\n\n2018-01-01\n\nThe detection of periodic signals of transiting exoplanets is often impeded by the presence of aperiodic photometric variations. This variability is intrinsic to the host star in space-based observations (typically arising from magnetic activity) and from observational conditions in ground-based observations. The most common statistical procedures to remove stellar variations are nonparametric, such as wavelet decomposition or Gaussian Processes regression. However, many stars display variability with autoregressive properties, wherein later flux values are correlated with previous ones. Providing the time series is evenly spaced, parametric autoregressive models can prove very effective. Here we present the methodology of the Autoregessive Planet Search (ARPS) project which uses Autoregressive Integrated Moving Average (ARIMA) models to treat a wide variety of stochastic short-memory processes, as well as nonstationarity. Additionally, we introduce a planet-search algorithm to detect periodic transits in the time-series residuals after application of ARIMA models. Our matched-filter algorithm, the Transit Comb Filter (TCF), replaces the traditional box-fitting step. We construct a periodogram based on the TCF to concentrate the signal of these periodic spikes. Various features of the original light curves, the ARIMA fits, the TCF periodograms, and folded light curves at peaks of the TCF periodogram can then be collected to provide constraints for planet detection. These features provide input into a multivariate classifier when a training set is available. The ARPS procedure has been applied NASA's Kepler mission observations of ~200,000 stars (Caceres, Dissertation Talk, this meeting) and will be applied in the future to other datasets.\n\nEfficient collective influence maximization in cascading processes with first-order transitions\n\nPubMed Central\n\nPei, Sen; Teng, Xian; Shaman, Jeffrey; Morone, Flaviano; Makse, HernÃ¡n A.\n\n2017-01-01\n\nIn many social and biological networks, the collective dynamics of the entire system can be shaped by a small set of influential units through a global cascading process, manifested by an abrupt first-order transition in dynamical behaviors. Despite its importance in applications, efficient identification of multiple influential spreaders in cascading processes still remains a challenging task for large-scale networks. Here we address this issue by exploring the collective influence in general threshold models of cascading process. Our analysis reveals that the importance of spreaders is fixed by the subcritical paths along which cascades propagate: the number of subcritical paths attached to each spreader determines its contribution to global cascades. The concept of subcritical path allows us to introduce a scalable algorithm for massively large-scale networks. Results in both synthetic random graphs and real networks show that the proposed method can achieve larger collective influence given the same number of seeds compared with other scalable heuristic approaches. PMID:28349988\n\nEfficient collective influence maximization in cascading processes with first-order transitions\n\nNASA Astrophysics Data System (ADS)\n\nPei, Sen; Teng, Xian; Shaman, Jeffrey; Morone, Flaviano; Makse, HernÃ¡n A.\n\n2017-03-01\n\nIn many social and biological networks, the collective dynamics of the entire system can be shaped by a small set of influential units through a global cascading process, manifested by an abrupt first-order transition in dynamical behaviors. Despite its importance in applications, efficient identification of multiple influential spreaders in cascading processes still remains a challenging task for large-scale networks. Here we address this issue by exploring the collective influence in general threshold models of cascading process. Our analysis reveals that the importance of spreaders is fixed by the subcritical paths along which cascades propagate: the number of subcritical paths attached to each spreader determines its contribution to global cascades. The concept of subcritical path allows us to introduce a scalable algorithm for massively large-scale networks. Results in both synthetic random graphs and real networks show that the proposed method can achieve larger collective influence given the same number of seeds compared with other scalable heuristic approaches.\n\nIncorporating measurement error in n = 1 psychological autoregressive modeling\n\nPubMed Central\n\nSchuurman, NoÃ©mi K.; Houtveen, Jan H.; Hamaker, Ellen L.\n\n2015-01-01\n\nMeasurement error is omnipresent in psychological data. However, the vast majority of applications of autoregressive time series analyses in psychology do not take measurement error into account. Disregarding measurement error when it is present in the data results in a bias of the autoregressive parameters. We discuss two models that take measurement error into account: An autoregressive model with a white noise term (AR+WN), and an autoregressive moving average (ARMA) model. In a simulation study we compare the parameter recovery performance of these models, and compare this performance for both a Bayesian and frequentist approach. We find that overall, the AR+WN model performs better. Furthermore, we find that for realistic (i.e., small) sample sizes, psychological research would benefit from a Bayesian approach in fitting these models. Finally, we illustrate the effect of disregarding measurement error in an AR(1) model by means of an empirical application on mood data in women. We find that, depending on the person, approximately 30â50% of the total variance was due to measurement error, and that disregarding this measurement error results in a substantial underestimation of the autoregressive parameters. PMID:26283988\n\nIncorporating measurement error in n = 1 psychological autoregressive modeling.\n\nPubMed\n\nSchuurman, NoÃ©mi K; Houtveen, Jan H; Hamaker, Ellen L\n\n2015-01-01\n\nMeasurement error is omnipresent in psychological data. However, the vast majority of applications of autoregressive time series analyses in psychology do not take measurement error into account. Disregarding measurement error when it is present in the data results in a bias of the autoregressive parameters. We discuss two models that take measurement error into account: An autoregressive model with a white noise term (AR+WN), and an autoregressive moving average (ARMA) model. In a simulation study we compare the parameter recovery performance of these models, and compare this performance for both a Bayesian and frequentist approach. We find that overall, the AR+WN model performs better. Furthermore, we find that for realistic (i.e., small) sample sizes, psychological research would benefit from a Bayesian approach in fitting these models. Finally, we illustrate the effect of disregarding measurement error in an AR(1) model by means of an empirical application on mood data in women. We find that, depending on the person, approximately 30-50% of the total variance was due to measurement error, and that disregarding this measurement error results in a substantial underestimation of the autoregressive parameters.\n\nTime to burn: Modeling wildland arson as an autoregressive crime function\n\nTreesearch\n\nJeffrey P. Prestemon; David T. Butry\n\n2005-01-01\n\nSix Poisson autoregressive models of order p [PAR(p)] of daily wildland arson ignition counts are estimated for five locations in Florida (1994-2001). In addition, a fixed effects time-series Poisson model of annual arson counts is estimated for all Florida counties (1995-2001). PAR(p) model estimates reveal highly significant arson ignition autocorrelation, lasting up...\n\nTrans-dimensional inversion of microtremor array dispersion data with hierarchical autoregressive error models\n\nNASA Astrophysics Data System (ADS)\n\nDettmer, Jan; Molnar, Sheri; Steininger, Gavin; Dosso, Stan E.; Cassidy, John F.\n\n2012-02-01\n\nstate space that spans multiple subspaces of different dimensionalities. The order of the autoregressive process required to fit the data is determined here by posterior residual-sample examination and statistical tests. Inference for earth model parameters is carried out on the trans-dimensional posterior probability distribution by considering ensembles of parameter vectors. In particular, vs uncertainty estimates are obtained by marginalizing the trans-dimensional posterior distribution in terms of vs-profile marginal distributions. The methodology is applied to microtremor array dispersion data collected at two sites with significantly different geology in British Columbia, Canada. At both sites, results show excellent agreement with estimates from invasive measurements.\n\nSimulated lumped-parameter system reduced-order adaptive control studies\n\nNASA Technical Reports Server (NTRS)\n\nJohnson, C. R., Jr.; Lawrence, D. A.; Taylor, T.; Malakooti, M. V.\n\n1981-01-01\n\nTwo methods of interpreting the misbehavior of reduced order adaptive controllers are discussed. The first method is based on system input-output description and the second is based on state variable description. The implementation of the single input, single output, autoregressive, moving average system is considered.\n\nFunctional MRI and Multivariate Autoregressive Models\n\nPubMed Central\n\nRogers, Baxter P.; Katwal, Santosh B.; Morgan, Victoria L.; Asplund, Christopher L.; Gore, John C.\n\n2010-01-01\n\nConnectivity refers to the relationships that exist between different regions of the brain. In the context of functional magnetic resonance imaging (fMRI), it implies a quantifiable relationship between hemodynamic signals from different regions. One aspect of this relationship is the existence of small timing differences in the signals in different regions. Delays of 100 ms or less may be measured with fMRI, and these may reflect important aspects of the manner in which brain circuits respond as well as the overall functional organization of the brain. The multivariate autoregressive time series model has features to recommend it for measuring these delays, and is straightforward to apply to hemodynamic data. In this review, we describe the current usage of the multivariate autoregressive model for fMRI, discuss the issues that arise when it is applied to hemodynamic time series, and consider several extensions. Connectivity measures like Granger causality that are based on the autoregressive model do not always reflect true neuronal connectivity; however, we conclude that careful experimental design could make this methodology quite useful in extending the information obtainable using fMRI. PMID:20444566\n\nAdaptive spline autoregression threshold method in forecasting Mitsubishi car sales volume at PT Srikandi Diamond Motors\n\nNASA Astrophysics Data System (ADS)\n\nSusanti, D.; Hartini, E.; Permana, A.\n\n2017-01-01\n\nSale and purchase of the growing competition between companies in Indonesian, make every company should have a proper planning in order to win the competition with other companies. One of the things that can be done to design the plan is to make car sales forecast for the next few periods, itâs required that the amount of inventory of cars that will be sold in proportion to the number of cars needed. While to get the correct forecasting, on of the methods that can be used is the method of Adaptive Spline Threshold Autoregression (ASTAR). Therefore, this time the discussion will focus on the use of Adaptive Spline Threshold Autoregression (ASTAR) method in forecasting the volume of car sales in PT.Srikandi Diamond Motors using time series data.In the discussion of this research, forecasting using the method of forecasting value Adaptive Spline Threshold Autoregression (ASTAR) produce approximately correct.\n\nDiscriminating between first- and second-order cognition in first-episode paranoid schizophrenia.\n\nPubMed\n\nBliksted, Vibeke; Samuelsen, Erla; Sandberg, Kristian; Bibby, Bo Martin; Overgaard, Morten Storm\n\n2017-03-01\n\nAn impairment of visually perceiving backward masked stimuli is commonly observed in patients with schizophrenia, yet it is unclear whether this impairment is the result of a deficiency in first or higher order processing and for which subtypes of schizophrenia it is present. Here, we compare identification (first order) and metacognitive (higher order) performance in a visual masking paradigm between a highly homogenous group of young first-episode patients diagnosed with paranoid schizophrenia (Nâ=â11) to that of carefully matched healthy controls (Nâ=â13). We find no difference across groups in first-order performance, but find a difference in metacognitive performance, particularly for stimuli with relatively high visibility. These results indicate that the masking deficit is present in first-episode patients with paranoid schizophrenia, but that it is primarily an impairment of metacognition.\n\nPrediction of global ionospheric VTEC maps using an adaptive autoregressive model\n\nNASA Astrophysics Data System (ADS)\n\nWang, Cheng; Xin, Shaoming; Liu, Xiaolu; Shi, Chuang; Fan, Lei\n\n2018-02-01\n\nIn this contribution, an adaptive autoregressive model is proposed and developed to predict global ionospheric vertical total electron content maps (VTEC). Specifically, the spherical harmonic (SH) coefficients are predicted based on the autoregressive model, and the order of the autoregressive model is determined adaptively using the F-test method. To test our method, final CODE and IGS global ionospheric map (GIM) products, as well as altimeter TEC data during low and mid-to-high solar activity period collected by JASON, are used to evaluate the precision of our forecasting products. Results indicate that the predicted products derived from the model proposed in this paper have good consistency with the final GIMs in low solar activity, where the annual mean of the root-mean-square value is approximately 1.5 TECU. However, the performance of predicted vertical TEC in periods of mid-to-high solar activity has less accuracy than that during low solar activity periods, especially in the equatorial ionization anomaly region and the Southern Hemisphere. Additionally, in comparison with forecasting products, the final IGS GIMs have the best consistency with altimeter TEC data. Future work is needed to investigate the performance of forecasting products using the proposed method in an operational environment, rather than using the SH coefficients from the final CODE products, to understand the real-time applicability of the method.\n\nComputational problems in autoregressive moving average (ARMA) models\n\nNASA Technical Reports Server (NTRS)\n\nAgarwal, G. C.; Goodarzi, S. M.; Oneill, W. D.; Gottlieb, G. L.\n\n1981-01-01\n\nThe choice of the sampling interval and the selection of the order of the model in time series analysis are considered. Band limited (up to 15 Hz) random torque perturbations are applied to the human ankle joint. The applied torque input, the angular rotation output, and the electromyographic activity using surface electrodes from the extensor and flexor muscles of the ankle joint are recorded. Autoregressive moving average models are developed. A parameter constraining technique is applied to develop more reliable models. The asymptotic behavior of the system must be taken into account during parameter optimization to develop predictive models.\n\nAssessment and prediction of air quality using fuzzy logic and autoregressive models\n\nNASA Astrophysics Data System (ADS)\n\nCarbajal-HernÃ¡ndez, JosÃ© Juan; SÃ¡nchez-FernÃ¡ndez, Luis P.; Carrasco-Ochoa, JesÃºs A.; MartÃ­nez-Trinidad, JosÃ© Fco.\n\n2012-12-01\n\nIn recent years, artificial intelligence methods have been used for the treatment of environmental problems. This work, presents two models for assessment and prediction of air quality. First, we develop a new computational model for air quality assessment in order to evaluate toxic compounds that can harm sensitive people in urban areas, affecting their normal activities. In this model we propose to use a Sigma operator to statistically asses air quality parameters using their historical data information and determining their negative impact in air quality based on toxicity limits, frequency average and deviations of toxicological tests. We also introduce a fuzzy inference system to perform parameter classification using a reasoning process and integrating them in an air quality index describing the pollution levels in five stages: excellent, good, regular, bad and danger, respectively. The second model proposed in this work predicts air quality concentrations using an autoregressive model, providing a predicted air quality index based on the fuzzy inference system previously developed. Using data from Mexico City Atmospheric Monitoring System, we perform a comparison among air quality indices developed for environmental agencies and similar models. Our results show that our models are an appropriate tool for assessing site pollution and for providing guidance to improve contingency actions in urban areas.\n\nMonthly streamflow forecasting with auto-regressive integrated moving average\n\nNASA Astrophysics Data System (ADS)\n\nNasir, Najah; Samsudin, Ruhaidah; Shabri, Ani\n\n2017-09-01\n\nForecasting of streamflow is one of the many ways that can contribute to better decision making for water resource management. The auto-regressive integrated moving average (ARIMA) model was selected in this research for monthly streamflow forecasting with enhancement made by pre-processing the data using singular spectrum analysis (SSA). This study also proposed an extension of the SSA technique to include a step where clustering was performed on the eigenvector pairs before reconstruction of the time series. The monthly streamflow data of Sungai Muda at Jeniang, Sungai Muda at Jambatan Syed Omar and Sungai Ketil at Kuala Pegang was gathered from the Department of Irrigation and Drainage Malaysia. A ratio of 9:1 was used to divide the data into training and testing sets. The ARIMA, SSA-ARIMA and Clustered SSA-ARIMA models were all developed in R software. Results from the proposed model are then compared to a conventional auto-regressive integrated moving average model using the root-mean-square error and mean absolute error values. It was found that the proposed model can outperform the conventional model.\n\nAnomalous Fluctuations in Autoregressive Models with Long-Term Memory\n\nNASA Astrophysics Data System (ADS)\n\nSakaguchi, Hidetsugu; Honjo, Haruo\n\n2015-10-01\n\nAn autoregressive model with a power-law type memory kernel is studied as a stochastic process that exhibits a self-affine-fractal-like behavior for a small time scale. We find numerically that the root-mean-square displacement Î(m) for the time interval m increases with a power law as mÎ± with Î± < 1/2 for small m but saturates at sufficiently large m. The exponent Î± changes with the power exponent of the memory kernel.\n\nMultivariate Autoregressive Modeling and Granger Causality Analysis of Multiple Spike Trains\n\nPubMed Central\n\nKrumin, Michael; Shoham, Shy\n\n2010-01-01\n\nRecent years have seen the emergence of microelectrode arrays and optical methods allowing simultaneous recording of spiking activity from populations of neurons in various parts of the nervous system. The analysis of multiple neural spike train data could benefit significantly from existing methods for multivariate time-series analysis which have proven to be very powerful in the modeling and analysis of continuous neural signals like EEG signals. However, those methods have not generally been well adapted to point processes. Here, we use our recent results on correlation distortions in multivariate Linear-Nonlinear-Poisson spiking neuron models to derive generalized Yule-Walker-type equations for fitting ââhiddenâ Multivariate Autoregressive models. We use this new framework to perform Granger causality analysis in order to extract the directed information flow pattern in networks of simulated spiking neurons. We discuss the relative merits and limitations of the new method. PMID:20454705\n\nEEG data reduction by means of autoregressive representation and discriminant analysis procedures.\n\nPubMed\n\nBlinowska, K J; Czerwosz, L T; Drabik, W; Franaszczuk, P J; Ekiert, H\n\n1981-06-01\n\nA program for automatic evaluation of EEG spectra, providing considerable reduction of data, was devised. Artefacts were eliminated in two steps: first, the longer duration eye movement artefacts were removed by a fast and simple 'moving integral' methods, then occasional spikes were identified by means of a detection function defined in the formalism of the autoregressive (AR) model. The evaluation of power spectra was performed by means of an FFT and autoregressive representation, which made possible the comparison of both methods. The spectra obtained by means of the AR model had much smaller statistical fluctuations and better resolution, enabling us to follow the time changes of the EEG pattern. Another advantage of the autoregressive approach was the parametric description of the signal. This last property appeared to be essential in distinguishing the changes in the EEG pattern. In a drug study the application of the coefficients of the AR model as input parameters in the discriminant analysis, instead of arbitrary chosen frequency bands, brought a significant improvement in distinguishing the effects of the medication. The favourable properties of the AR model are connected with the fact that the above approach fulfils the maximum entropy principle. This means that the method describes in a maximally consistent way the available information and is free from additional assumptions, which is not the case for the FFT estimate.\n\nA Stable Clock Error Model Using Coupled First and Second Order Gauss-Markov Processes\n\nNASA Technical Reports Server (NTRS)\n\nCarpenter, Russell; Lee, Taesul\n\n2008-01-01\n\nLong data outages may occur in applications of global navigation satellite system technology to orbit determination for missions that spend significant fractions of their orbits above the navigation satellite constellation(s). Current clock error models based on the random walk idealization may not be suitable in these circumstances, since the covariance of the clock errors may become large enough to overflow flight computer arithmetic. A model that is stable, but which approximates the existing models over short time horizons is desirable. A coupled first- and second-order Gauss-Markov process is such a model.\n\nFirst Order Kinetics Visualized by Capillary Flow and Simple Data Acquisition\n\nERIC Educational Resources Information Center\n\nFestersen, Lea; Gilch, Peter; Reiffers, Anna; Mundt, Ramona\n\n2018-01-01\n\nFirst order processes are of paramount importance for chemical kinetics. In a well-established demonstration experiment, the flow of water out of a vertical glass tube through a capillary simulates a chemical first order process. Here, a digital version of this experiment for lecture hall demonstrations is presented. To this end, water flowing outâ¦\n\nFirst-order inflation. [in cosmology\n\nNASA Technical Reports Server (NTRS)\n\nTurner, Michael S.\n\n1992-01-01\n\nI discuss the most recent model of inflation. In first-order inflation the inflationary epoch is associated with a first-order phase transition, with the most likely candidate being GUT symmetry breaking. The transition from the false-vacuum inflationary phase to the true-vacuum radiation-dominated phase proceeds through the nucleation and percolation of true-vacuum bubbles. The first successful and simplest model of first-order inflation, extended inflation, is discussed in some detail: evolution of the cosmic-scale factor, reheating, density perturbations, and the production of gravitational waves both from quantum fluctuations and bubble collisions. Particular attention is paid to the most critical issue in any model of first-order inflation: the requirements on the nucleation rate to ensure a graceful transition from the inflationary phase to the radiation-dominated phase.\n\nGet Over It! A Multilevel Threshold Autoregressive Model for State-Dependent Affect Regulation.\n\nPubMed\n\nDe Haan-Rietdijk, Silvia; Gottman, John M; Bergeman, Cindy S; Hamaker, Ellen L\n\n2016-03-01\n\nIntensive longitudinal data provide rich information, which is best captured when specialized models are used in the analysis. One of these models is the multilevel autoregressive model, which psychologists have applied successfully to study affect regulation as well as alcohol use. A limitation of this model is that the autoregressive parameter is treated as a fixed, trait-like property of a person. We argue that the autoregressive parameter may be state-dependent, for example, if the strength of affect regulation depends on the intensity of affect experienced. To allow such intra-individual variation, we propose a multilevel threshold autoregressive model. Using simulations, we show that this model can be used to detect state-dependent regulation with adequate power and Type I error. The potential of the new modeling approach is illustrated with two empirical applications that extend the basic model to address additional substantive research questions.\n\nImage interpolation by adaptive 2-D autoregressive modeling and soft-decision estimation.\n\nPubMed\n\nZhang, Xiangjun; Wu, Xiaolin\n\n2008-06-01\n\nThe challenge of image interpolation is to preserve spatial details. We propose a soft-decision interpolation technique that estimates missing pixels in groups rather than one at a time. The new technique learns and adapts to varying scene structures using a 2-D piecewise autoregressive model. The model parameters are estimated in a moving window in the input low-resolution image. The pixel structure dictated by the learnt model is enforced by the soft-decision estimation process onto a block of pixels, including both observed and estimated. The result is equivalent to that of a high-order adaptive nonseparable 2-D interpolation filter. This new image interpolation approach preserves spatial coherence of interpolated images better than the existing methods, and it produces the best results so far over a wide range of scenes in both PSNR measure and subjective visual quality. Edges and textures are well preserved, and common interpolation artifacts (blurring, ringing, jaggies, zippering, etc.) are greatly reduced.\n\nTo center or not to center? Investigating inertia with a multilevel autoregressive model.\n\nPubMed\n\nHamaker, Ellen L; Grasman, Raoul P P P\n\n2014-01-01\n\nWhether level 1 predictors should be centered per cluster has received considerable attention in the multilevel literature. While most agree that there is no one preferred approach, it has also been argued that cluster mean centering is desirable when the within-cluster slope and the between-cluster slope are expected to deviate, and the main interest is in the within-cluster slope. However, we show in a series of simulations that if one has a multilevel autoregressive model in which the level 1 predictor is the lagged outcome variable (i.e., the outcome variable at the previous occasion), cluster mean centering will in general lead to a downward bias in the parameter estimate of the within-cluster slope (i.e., the autoregressive relationship). This is particularly relevant if the main question is whether there is on average an autoregressive effect. Nonetheless, we show that if the main interest is in estimating the effect of a level 2 predictor on the autoregressive parameter (i.e., a cross-level interaction), cluster mean centering should be preferred over other forms of centering. Hence, researchers should be clear on what is considered the main goal of their study, and base their choice of centering method on this when using a multilevel autoregressive model.\n\nTo center or not to center? Investigating inertia with a multilevel autoregressive model\n\nPubMed Central\n\nHamaker, Ellen L.; Grasman, Raoul P. P. P.\n\n2015-01-01\n\nWhether level 1 predictors should be centered per cluster has received considerable attention in the multilevel literature. While most agree that there is no one preferred approach, it has also been argued that cluster mean centering is desirable when the within-cluster slope and the between-cluster slope are expected to deviate, and the main interest is in the within-cluster slope. However, we show in a series of simulations that if one has a multilevel autoregressive model in which the level 1 predictor is the lagged outcome variable (i.e., the outcome variable at the previous occasion), cluster mean centering will in general lead to a downward bias in the parameter estimate of the within-cluster slope (i.e., the autoregressive relationship). This is particularly relevant if the main question is whether there is on average an autoregressive effect. Nonetheless, we show that if the main interest is in estimating the effect of a level 2 predictor on the autoregressive parameter (i.e., a cross-level interaction), cluster mean centering should be preferred over other forms of centering. Hence, researchers should be clear on what is considered the main goal of their study, and base their choice of centering method on this when using a multilevel autoregressive model. PMID:25688215\n\nApplication of multivariate autoregressive spectrum estimation to ULF waves\n\nNASA Technical Reports Server (NTRS)\n\nIoannidis, G. A.\n\n1975-01-01\n\nThe estimation of the power spectrum of a time series by fitting a finite autoregressive model to the data has recently found widespread application in the physical sciences. The extension of this method to the analysis of vector time series is presented here through its application to ULF waves observed in the magnetosphere by the ATS 6 synchronous satellite. Autoregressive spectral estimates of the power and cross-power spectra of these waves are computed with computer programs developed by the author and are compared with the corresponding Blackman-Tukey spectral estimates. The resulting spectral density matrices are then analyzed to determine the direction of propagation and polarization of the observed waves.\n\nCompression of head-related transfer function using autoregressive-moving-average models and Legendre polynomials.\n\nPubMed\n\nShekarchi, Sayedali; Hallam, John; Christensen-Dalsgaard, Jakob\n\n2013-11-01\n\nHead-related transfer functions (HRTFs) are generally large datasets, which can be an important constraint for embedded real-time applications. A method is proposed here to reduce redundancy and compress the datasets. In this method, HRTFs are first compressed by conversion into autoregressive-moving-average (ARMA) filters whose coefficients are calculated using Prony's method. Such filters are specified by a few coefficients which can generate the full head-related impulse responses (HRIRs). Next, Legendre polynomials (LPs) are used to compress the ARMA filter coefficients. LPs are derived on the sphere and form an orthonormal basis set for spherical functions. Higher-order LPs capture increasingly fine spatial details. The number of LPs needed to represent an HRTF, therefore, is indicative of its spatial complexity. The results indicate that compression ratios can exceed 98% while maintaining a spectral error of less than 4âdB in the recovered HRTFs.\n\nTaiWan Ionospheric Model (TWIM) prediction based on time series autoregressive analysis\n\nNASA Astrophysics Data System (ADS)\n\nTsai, L. C.; Macalalad, Ernest P.; Liu, C. H.\n\n2014-10-01\n\nAs described in a previous paper, a three-dimensional ionospheric electron density (Ne) model has been constructed from vertical Ne profiles retrieved from the FormoSat3/Constellation Observing System for Meteorology, Ionosphere, and Climate GPS radio occultation measurements and worldwide ionosonde foF2 and foE data and named the TaiWan Ionospheric Model (TWIM). The TWIM exhibits vertically fitted Î±-Chapman-type layers with distinct F2, F1, E, and D layers, and surface spherical harmonic approaches for the fitted layer parameters including peak density, peak density height, and scale height. To improve the TWIM into a real-time model, we have developed a time series autoregressive model to forecast short-term TWIM coefficients. The time series of TWIM coefficients are considered as realizations of stationary stochastic processes within a processing window of 30 days. These autocorrelation coefficients are used to derive the autoregressive parameters and then forecast the TWIM coefficients, based on the least squares method and Lagrange multiplier technique. The forecast root-mean-square relative TWIM coefficient errors are generally <30% for 1 day predictions. The forecast TWIM values of foE and foF2 values are also compared and evaluated using worldwide ionosonde data.\n\nIdentification of AR(I)MA processes for modelling temporal correlations of GPS observations\n\nNASA Astrophysics Data System (ADS)\n\nLuo, X.; Mayer, M.; Heck, B.\n\n2009-04-01\n\nIn many geodetic applications observations of the Global Positioning System (GPS) are routinely processed by means of the least-squares method. However, this algorithm delivers reliable estimates of unknown parameters und realistic accuracy measures only if both the functional and stochastic models are appropriately defined within GPS data processing. One deficiency of the stochastic model used in many GPS software products consists in neglecting temporal correlations of GPS observations. In practice the knowledge of the temporal stochastic behaviour of GPS observations can be improved by analysing time series of residuals resulting from the least-squares evaluation. This paper presents an approach based on the theory of autoregressive (integrated) moving average (AR(I)MA) processes to model temporal correlations of GPS observations using time series of observation residuals. A practicable integration of AR(I)MA models in GPS data processing requires the determination of the order parameters of AR(I)MA processes at first. In case of GPS, the identification of AR(I)MA processes could be affected by various factors impacting GPS positioning results, e.g. baseline length, multipath effects, observation weighting, or weather variations. The influences of these factors on AR(I)MA identification are empirically analysed based on a large amount of representative residual time series resulting from differential GPS post-processing using 1-Hz observation data collected within the permanent SAPOSÂ® (Satellite Positioning Service of the German State Survey) network. Both short and long time series are modelled by means of AR(I)MA processes. The final order parameters are determined based on the whole residual database; the corresponding empirical distribution functions illustrate that multipath and weather variations seem to affect the identification of AR(I)MA processes much more significantly than baseline length and observation weighting. Additionally, the modelling\n\nA comparison of zero-order, first-order, and monod biotransformation models\n\nUSGS Publications Warehouse\n\nBekins, B.A.; Warren, E.; Godsy, E.M.\n\n1998-01-01\n\nUnder some conditions, a first-order kinetic model is a poor representation of biodegradation in contaminated aquifers. Although it is well known that the assumption of first-order kinetics is valid only when substrate concentration, S, is much less than the half-saturation constant, K(s), this assumption is often made without verification of this condition. We present a formal error analysis showing that the relative error in the first-order approximation is S/K(S) and in the zero-order approximation the error is K(s)/S. We then examine the problems that arise when the first-order approximation is used outside the range for which it is valid. A series of numerical simulations comparing results of first- and zero-order rate approximations to Monod kinetics for a real data set illustrates that if concentrations observed in the field are higher than K(s), it may better to model degradation using a zero-order rate expression. Compared with Monod kinetics, extrapolation of a first-order rate to lower concentrations under-predicts the biotransformation potential, while extrapolation to higher concentrations may grossly over-predict the transformation rate. A summary of solubilities and Monod parameters for aerobic benzene, toluene, and xylene (BTX) degradation shows that the a priori assumption of first-order degradation kinetics at sites contaminated with these compounds is not valid. In particular, out of six published values of KS for toluene, only one is greater than 2 mg/L, indicating that when toluene is present in concentrations greater than about a part per million, the assumption of first-order kinetics may be invalid. Finally, we apply an existing analytical solution for steady-state one-dimensional advective transport with Monod degradation kinetics to a field data set.A formal error analysis is presented showing that the relative error in the first-order approximation is S/KS and in the zero-order approximation the error is KS/S where S is the substrate\n\nSpatial Autocorrelation And Autoregressive Models In Ecology\n\nTreesearch\n\nJeremy W. Lichstein; Theodore R. Simons; Susan A. Shriner; Kathleen E. Franzreb\n\n2003-01-01\n\nAbstract. Recognition and analysis of spatial autocorrelation has defined a new paradigm in ecology. Attention to spatial pattern can lead to insights that would have been otherwise overlooked, while ignoring space may lead to false conclusions about ecological relationships. We used Gaussian spatial autoregressive models, fit with widely available...\n\nFORCinel Version 3.0: An Integrated Environment for Processing, Analysis and Simulation of First-Order Reversal Curve Diagrams\n\nNASA Astrophysics Data System (ADS)\n\nLascu, I.; Harrison, R. J.\n\n2016-12-01\n\nFirst-order reversal curve (FORC) diagrams are a powerful method to characterise the hysteresis properties of magnetic grain ensembles. Methods of processing, analysis and simulation of FORC diagrams have developed rapidly over the past few years, dramatically expanding their utility within rock magnetic research. Here we announce the latest release of FORCinel (Version 3.0), which integrates many of these developments into a unified, user-friendly package running within Igor Pro (www.wavemetrics.com). FORCinel v. 3.0 can be downloaded from https://wserv4.esc.cam.ac.uk/nanopaleomag/. The release will be accompanied by a series of video tutorials outlining each of the new features, including: i) improved work flow, with unified smoothing approach; ii) increased processing speed using multiple processors; iii) control of output resolution, enabling large datasets (> 500 FORCs) to be smoothed in a matter of seconds; iv) load, process, analyse and average multiple FORC diagrams; v) load and process non-gridded data and data acquired on non-PMC systems; vi) improved method for exploring optimal smoothing parameters; vii) interactive and un-doable data-pretreatments; viii) automated detection and removal of measurement outliers; ix) improved interactive method for the generation and optimisation of colour scales; x) full integration with FORCem1 - supervised quantitative unmixing of FORC diagrams using principle component analysis (PCA); xi) full integration with FORCulator2 - micromagnetic simulation of FORC diagrams; xiii) simulate TRM acquisition using the kinetic Monte Carlo simulation algorithm of Shcherbakov3. 1. Lascu, I., Harrison, R.J., Li, Y., Muraszko, J.R., Channell, J.E.T., Piotrowski, A.M., Hodell, D.A., 2015. Magnetic unmixing of first-order reversal curve diagrams using principal component analysis. Geochemistry, Geophys. Geosystems 16, 2900-2915. 2. Harrison, R.J., Lascu, I., 2014. FORCulator: A micromagnetic tool for simulating first-order reversal\n\nAutoregressive processes with exponentially decaying probability distribution functions: applications to daily variations of a stock market index.\n\nPubMed\n\nPorto, Markus; Roman, H Eduardo\n\n2002-04-01\n\nWe consider autoregressive conditional heteroskedasticity (ARCH) processes in which the variance sigma(2)(y) depends linearly on the absolute value of the random variable y as sigma(2)(y) = a+b absolute value of y. While for the standard model, where sigma(2)(y) = a + b y(2), the corresponding probability distribution function (PDF) P(y) decays as a power law for absolute value of y-->infinity, in the linear case it decays exponentially as P(y) approximately exp(-alpha absolute value of y), with alpha = 2/b. We extend these results to the more general case sigma(2)(y) = a+b absolute value of y(q), with 0 < q < 2. We find stretched exponential decay for 1 < q < 2 and stretched Gaussian behavior for 0 < q < 1. As an application, we consider the case q=1 as our starting scheme for modeling the PDF of daily (logarithmic) variations in the Dow Jones stock market index. When the history of the ARCH process is taken into account, the resulting PDF becomes a stretched exponential even for q = 1, with a stretched exponent beta = 2/3, in a much better agreement with the empirical data.\n\nParallel Coding of First- and Second-Order Stimulus Attributes by Midbrain Electrosensory Neurons\n\nPubMed Central\n\nMcGillivray, Patrick; Vonderschen, Katrin; Fortune, Eric S.; Chacron, Maurice J.\n\n2015-01-01\n\nNatural stimuli often have time-varying first-order (i.e., mean) and second-order (i.e., variance) attributes that each carry critical information for perception and can vary independently over orders of magnitude. Experiments have shown that sensory systems continuously adapt their responses based on changes in each of these attributes. This adaptation creates ambiguity in the neural code as multiple stimuli may elicit the same neural response. While parallel processing of first- and second-order attributes by separate neural pathways is sufficient to remove this ambiguity, the existence of such pathways and the neural circuits that mediate their emergence have not been uncovered to date. We recorded the responses of midbrain electrosensory neurons in the weakly electric fish Apteronotus leptorhynchus to stimuli with first- and second-order attributes that varied independently in time. We found three distinct groups of midbrain neurons: the first group responded to both first- and second-order attributes, the second group responded selectively to first-order attributes, and the last group responded selectively to second-order attributes. In contrast, all afferent hindbrain neurons responded to both first- and second-order attributes. Using computational analyses, we show how inputs from a heterogeneous population of ON- and OFF-type afferent neurons are combined to give rise to response selectivity to either first- or second-order stimulus attributes in midbrain neurons. Our study thus uncovers, for the first time, generic and widely applicable mechanisms by which parallel processing of first- and second-order stimulus attributes emerges in the brain. PMID:22514313\n\nFinding higher order Darboux polynomials for a family of rational first order ordinary differential equations\n\nNASA Astrophysics Data System (ADS)\n\nAvellar, J.; Claudino, A. L. G. C.; Duarte, L. G. S.; da Mota, L. A. C. P.\n\n2015-10-01\n\nFor the Darbouxian methods we are studying here, in order to solve first order rational ordinary differential equations (1ODEs), the most costly (computationally) step is the finding of the needed Darboux polynomials. This can be so grave that it can render the whole approach unpractical. Hereby we introduce a simple heuristics to speed up this process for a class of 1ODEs.\n\nPowder Bed Layer Characteristics: The Overseen First-Order Process Input\n\nNASA Astrophysics Data System (ADS)\n\nMindt, H. W.; Megahed, M.; Lavery, N. P.; Holmes, M. A.; Brown, S. G. R.\n\n2016-08-01\n\nPowder Bed Additive Manufacturing offers unique advantages in terms of manufacturing cost, lot size, and product complexity compared to traditional processes such as casting, where a minimum lot size is mandatory to achieve economic competitiveness. Many studiesâboth experimental and numericalâare dedicated to the analysis of how process parameters such as heat source power, scan speed, and scan strategy affect the final material properties. Apart from the general urge to increase the build rate using thicker powder layers, the coating process and how the powder is distributed on the processing table has received very little attention to date. This paper focuses on the first step of every powder bed build process: Coating the process table. A numerical study is performed to investigate how powder is transferred from the source to the processing table. A solid coating blade is modeled to spread commercial Ti-6Al-4V powder. The resulting powder layer is analyzed statistically to determine the packing density and its variation across the processing table. The results are compared with literature reports using the so-called \"rain\" models. A parameter study is performed to identify the influence of process table displacement and wiper velocity on the powder distribution. The achieved packing density and how that affects subsequent heat source interaction with the powder bed is also investigated numerically.\n\nGeneral and specific consciousness: a first-order representationalist approach\n\nPubMed Central\n\nMehta, Neil; Mashour, George A.\n\n2013-01-01\n\nIt is widely acknowledged that a complete theory of consciousness should explain general consciousness (what makes a state conscious at all) and specific consciousness (what gives a conscious state its particular phenomenal quality). We defend first-order representationalism, which argues that consciousness consists of sensory representations directly available to the subject for action selection, belief formation, planning, etc. We provide a neuroscientific framework for this primarily philosophical theory, according to which neural correlates of general consciousness include prefrontal cortex, posterior parietal cortex, and non-specific thalamic nuclei, while neural correlates of specific consciousness include sensory cortex and specific thalamic nuclei. We suggest that recent data support first-order representationalism over biological theory, higher-order representationalism, recurrent processing theory, information integration theory, and global workspace theory. PMID:23882231\n\nFirst order ball bearing kinematics\n\nNASA Technical Reports Server (NTRS)\n\nKingbury, E.\n\n1984-01-01\n\nTwo first order equations are given connecting geometry and internal motions in an angular contact ball bearing. Total speed, kinematic equivalence, basic speed ratio, and modal speed ratio are defined and discussed; charts are given for the speed ratios covering all bearings and all rotational modes. Instances where specific first order assumptions might fail are discussed, and the resulting effects on bearing performance reviewed.\n\nA novel framework to simulating non-stationary, non-linear, non-Normal hydrological time series using Markov Switching Autoregressive Models\n\nNASA Astrophysics Data System (ADS)\n\nBirkel, C.; Paroli, R.; Spezia, L.; Tetzlaff, D.; Soulsby, C.\n\n2012-12-01\n\nIn this paper we present a novel model framework using the class of Markov Switching Autoregressive Models (MSARMs) to examine catchments as complex stochastic systems that exhibit non-stationary, non-linear and non-Normal rainfall-runoff and solute dynamics. Hereby, MSARMs are pairs of stochastic processes, one observed and one unobserved, or hidden. We model the unobserved process as a finite state Markov chain and assume that the observed process, given the hidden Markov chain, is conditionally autoregressive, which means that the current observation depends on its recent past (system memory). The model is fully embedded in a Bayesian analysis based on Markov Chain Monte Carlo (MCMC) algorithms for model selection and uncertainty assessment. Hereby, the autoregressive order and the dimension of the hidden Markov chain state-space are essentially self-selected. The hidden states of the Markov chain represent unobserved levels of variability in the observed process that may result from complex interactions of hydroclimatic variability on the one hand and catchment characteristics affecting water and solute storage on the other. To deal with non-stationarity, additional meteorological and hydrological time series along with a periodic component can be included in the MSARMs as covariates. This extension allows identification of potential underlying drivers of temporal rainfall-runoff and solute dynamics. We applied the MSAR model framework to streamflow and conservative tracer (deuterium and oxygen-18) time series from an intensively monitored 2.3 km2 experimental catchment in eastern Scotland. Statistical time series analysis, in the form of MSARMs, suggested that the streamflow and isotope tracer time series are not controlled by simple linear rules. MSARMs showed that the dependence of current observations on past inputs observed by transport models often in form of the long-tailing of travel time and residence time distributions can be efficiently explained by\n\nContrast gain control in first- and second-order motion perception.\n\nPubMed\n\nLu, Z L; Sperling, G\n\n1996-12-01\n\nA novel pedestal-plus-test paradigm is used to determine the nonlinear gain-control properties of the first-order (luminance) and the second-order (texture-contrast) motion systems, that is, how these systems' responses to motion stimuli are reduced by pedestals and other masking stimuli. Motion-direction thresholds were measured for test stimuli consisting of drifting luminance and texture-contrast-modulation stimuli superimposed on pedestals of various amplitudes. (A pedestal is a static sine-wave grating of the same type and same spatial frequency as the moving test grating.) It was found that first-order motion-direction thresholds are unaffec"
    }
}