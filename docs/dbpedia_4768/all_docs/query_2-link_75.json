{
    "id": "dbpedia_4768_2",
    "rank": 75,
    "data": {
        "url": "https://joequery.me/notes/programming-language-design-issues/",
        "read_more_link": "",
        "language": "en",
        "title": "Programming Language Design Issues",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "(This post is part of the programming languages 4th edition series.)\n\nThese notes are based on Programming Languages: Design and Implementation.\n\nSection 1.1: Why study programming languages?\n\n1. To improve your ability to develop effective algorithms\n\nMany languages provide features that can be extremely useful when used properly but waste a large amount of time when used improperly. Algorithms behave similarly, so the habit of making correct decisions with a programming language can carry over to making correct decisions with an algorithm.\n\n2. To improve your use of your existing programming language\n\nBy understanding exactly how the features in a programming language are implemented, you learn how to effectively use them. When you know how the language components such as lists/arrays/strings work, you can use them more efficiently.\n\n3. To increase your vocab of useful programming constructs\n\nWhen thinking about a set of data/program structures to solve a problem, it's typical to only think about the structures that are immediately available within the programming language you're working with. By knowing the constructs of other programming languages, you can find one that fits your scenario better and possibly implement it yourself.\n\n4. To allow a better choice of programming language\n\nSome languages are better suited than others for particular projects. You can reduce effort by picking the one that works best.\n\n5. To make it easier to learn a new language\n\nA thorough knowledge of programming language constructs and implementation techniques allows programmers to learn new languages more easily.\n\n6. To make it easier to design a new language\n\nThough you may not be making the next C or Java programming language, it's actually fairly common to create a form of programming language on a small scale within a project.\n\nStudying features and their implementations\n\nThere's a lot more to studying programming languages than just comparing their features. Some languages may share the same features, but those features could be implemented in entirely different ways, with some implementations possibly more efficient than others\n\nSection 1.2: A short history of programming languages\n\n1950s: FORTRAN, LISP\n\n1970s: Ada, C, Pascal, Prolog, Smalltalk\n\n1980s: C++, ML, Perl, Postscript\n\n1990s: Java\n\nIn a survey conducted by the US DoD in the 1970s, it found that over 500 languages were being used on defense projects.\n\nSection 1.2.1: Development of Early Languages\n\nWe'll summarize language development from the mid 1950s to the early 1970s. Later developments will be covered throughout the series.\n\nNumerically based languages\n\nIn the 1940s, the main role for computers during WWII was solving differential equations to determine ballistics trajectories.\n\nIn the 1950s, symbolic notations started to appear:\n\nGrace Hopper developed the A-0 language\n\nJohn Backus developed Speedcoding\n\nBoth A-0 and Speedcoding were designed to compile simple arithmetic expressions into executable machine language.\n\nFORTRAN\n\nIn 1957, Backus managed a team to develop FORTRAN, meaning FORmula TRANSlator. While FORTRAN was oriented around numerical calculations, its goal was a full-fledged programming language including:\n\ncontrol structures\n\nconditionals\n\ninput/output statements\n\nMany doubted FORTRAN would compete with hand-coded assembly, so much effort was put into making FORTRAN execution extremely efficient. Some of this efficiency came from making statements specifically for the IBM 704. FORTRAN was extremely successful and dominated in the 1970s.\n\nIn 1958, FORTRAN was revised as FORTRAN II, and FORTRAN IV came a few years later. Soon, many manufacturers had implemented a version of the language, as there was no standard. In 1966, FORTRAN IV became the standard, and went by the name FORTRAN 66. FORTRAN 66 has been updated to FORTRAN 77 and then FORTRAN 90.\n\nALGOL\n\nThe success of FORTRAN caused fear of IBM's industry dominance. GAMM (the Germany Society of Applied Mathematics) organized a committee to design a universal language. The US's ACM, (Association f or Computing Machinery) organized a similar committee, and the two committees eventually merged. Under the leadership of Peter Naur, the International Algorithmic Language (IAL) was developed. The name was eventually changed to ALGOL, and became known as ALGOL 58. The ALGOL 60 revision became the standard academic computing language from the 1960s to the early 1970s.\n\nFORTRAN was designed for efficient execution on the IBM 704 machine, but ALGOL had different goals.\n\nALGOL notation should be close to standard math notation\n\nALGOL should be useful for the description of algorithms\n\nPrograms in ALGOL should be compilable into machine language\n\nALGOL should not be bound to a single computer architecture\n\nThese goals had large implications. This meant that, in the context of the time period, input/output was not included in the language, nor was special procedures. Implementations of ALGOL were incompatible. Subprograms were viewed as macro substitution, a concept named call by name.\n\nBackus was editor of the ALGOL report defining the language, and he used a notation similar to that developed by Chomsky for describing context free languages. This introduced formal grammar theory to programming languages. Peter Naur's and Backus' role in the development of ALGOL caused the notation used to represent the grammar of a language to be called Backus Naur Form (BNF).\n\nBusiness Languages\n\nAfter establishing domain of numerical calculations with computers, business data processing came soon after. Grace Hopper developed FLOWMATIC in 1955, with the goal of developing business applications with a form of English-like text. In 1959, The US DoD sponsored a meeting to develop the Common Business Language(CBL), a language whose goal was to use English as much as possible for its notation. The specifications for CBL designed in 1960 became the designs for COBOL (COmmon Business Oriented Language). Cobol was standardized in 1968.\n\nArtificial-intelligence languages\n\nThe Information Processing Language (IPL) was developed by the Rand Corporation. IPL-V was widely known but had limited use. John McCarthy of MIT designed LIst PRocessing (LISP) for the IBM 704. LISP 1.5 became the standard LISP implementation for many years.\n\nSystems languages\n\nIn this early era, efficiency was required, so assembly language was mostly used in the systems area. CPL and BCPL were designed but never gained traction. C changed the systems area, but that did not come until the 1970s.\n\nSection 1.2.2: Evolution of Software Architectures\n\nThe hardware that supports a language has a large impact language design.\n\ndefine operating/target environment:\n\nThe external environment supporting the execution of a program\n\ndefine host environment:\n\nThe environment in which a program is designed, coded, tested, and debugged\n\nThe Mainframe Era\n\nThe large mainframe dominated between the 1940s and 1970s. A single, expensive computer filled a roomed and required many technicians.\n\nBatch environments\n\nOnly external files of data. A program would take a set of data files as input and produce a set of output files after processing. FORTRAN, COBOL and Pascal were initially designed for batch-processing.\n\nInteractive environments\n\nInteractive programming appeared in the early 1970s near the end of the mainframe era. CRT terminals were connected to the computer. Computers were able to divide computation time amongst all concurrent users, a process known as time share\n\nEffects on language design\n\nLanguages were designed for batch processing bearing in mind that files were the basis for I/O. Other properties of languages designed for this era:\n\nA terminated program must be completely rerun, but termination is acceptable\n\nNo external help from the user is possible\n\nNo way to monitor or change the speed of execution\n\nFile I/O and interactive I/O end up being very different. Languages designed for batch-processing can have a hard time adapting to interactive environments. In interactive environments, termination is usually not acceptable.\n\nPersonal Computer Era\n\nTime sharing in mainframes did not last very long before personal computers came about.\n\nPersonal Computers\n\nIn the 1970s, computers became progressively smaller, cheaper, and faster. In 1978, Apple released the Apple II, the first true commercial PC. It was a small desktop that ran BASIC, and had a major impact on the educational market.\n\nIn 1981, the PC was released by IBM. In January 1984, Apple announced the Macintosh computer during the US superbowl. It contained a windows-based GUI with a mouse. Although the technology was previously developed by Xerox, the Macintosh was the first commercial applications. Microsoft quickly mimicked Macintosh with the Windows OS.\n\nEmbedded-system environments\n\ndefine embedded computer:\n\nA computer system that controls a larger system such as a plant, aircraft, machine, etc.\n\nEmbedded system failure can be catastrophic\n\nReliability and correctness are essential\n\nAda, C, C++ used\n\nEffects on language design\n\nPerformance is less of a concern in many domains\n\nUI interfaces and low prices lead to single-user computers. No time share\n\nUsers are used to windows-based UI, which can be hard to program. OO makes it easy via libraries and packages.\n\nIn regards to embedded systems,\n\nPrograms must interact directly with device for I/O\n\nAccess to devices provided via registers, memory locations, subprograms\n\nAll errors must be handled. Termination is not acceptable\n\nEmbedded system must be able to work in real-time\n\nOften a distributed system\n\nNetworking Era\n\nDistributed computing\n\nFaster, cheaper, smaller computers in 1980s caused more to be used in business\n\nUses included\n\npayroll\n\nreport writing\n\norder processing\n\nLocal Area Networks (LANs) developed to facilitate communication between computers.\n\nLANs used a client-server model\n\nAirline reservation client prime example of single server having multiple clients.\n\nInternet\n\nMid 1990s, distributed LAN known as the Internet emerged\n\n1970s, Defense Advanced Research Projects Agency (DARPA) wanted to link mainframes via network to aid military information transfer.\n\nThe network, ARPANET, evolved into the research-oriented Internet\n\nEarly internet use required certain protocols to retrieve information.\n\ntelnet made user appear as part of a server\n\nFTP allowed client to send or receive files\n\nIn both cases, the user had to already know what machine had the desired info\n\nSimple Mail Transfer Protocol (SMTP)\n\nBasis for today's email\n\nMachines have unique names, users have unique logins\n\nCould send mail using SMTP client just knowing user and machine name.\n\nA goal in the late 1980s was to make information retrieval as easy as sending email.\n\n1989 at CERN, Bernerls-Lee developed the HTML hyperlink\n\nMosaic web browser in 1993 + HTTP led to the internet as we know it\n\nEffects on language design\n\nUsers access servers via local client machines for local processing\n\nThe language must allow interaction between server and client\n\nInitial web pages were static. E-commerce needed two-way information flow\n\nJava and Perl provide such features\n\nSecurity became very important\n\nPerformance in server-client communication became important\n\nServers could become overloaded with client requests\n\nA way of coping is to make client process information\n\nRequired the sending of small executables\n\nServer doesn't know what client computer is like, so the executables must work regardless of client computer type\n\nJava aimed to solve these problems\n\nSection 1,2.3: Application Domains\n\nThe best language to be used often depends on the application domain.\n\nApplications of the 1960s\n\nBusiness processing\n\nLarge data processing applications running on big iron mainframes\n\norder-entry\n\ninventory\n\npayroll\n\nRead in data on tape drives, write out new data\n\nCOBOL developed for these applications\n\nCOBOL devs needed months to compose a what-if application\n\nScientific\n\nCharacterized by solution of math equations\n\nnumerical analysis\n\ndifferential equations\n\nintegral functions\n\ngenerating statistics\n\nComputer first developed in the Scientific domain for WWII ballistics tables\n\nFORTRAN dominated\n\nSyntax is close to math\n\nScientists find it easy to use\n\nSystem\n\nFor building OSes and implementing compilers, no effective language existed\n\nAssembly language was often the choice\n\nJOVIAL, an ALGOL variant, was used on some U.S DoD projects\n\nForth was developed to address power station / assembly line control\n\nAssembly language was still the most often used in these domains\n\nArtificial Intelligence\n\nAI relatively new research area\n\nLISP dominated\n\nPrograms search through large data spaces\n\nExample: Playing chess, searching for the best move\n\nApplications of the 21st century\n\nThe programming language situation today is probably more complex than it was during the 60s.\n\nBusiness processing\n\nCOBOL dominated in the late 90s, though C(++) were sometimes used\n\nSpreadsheet applications handle the what-if scenario COBOL struggled with\n\nFourth-generation languages (4GLs) have some market share\n\nlanguages designed for specific business application domains\n\ntypically provide a window-based programmer interface\n\nprovide easy access to database records\n\nEasy to generate input forms / output reports\n\nE-commerce has large influences on business programming\n\nThe need for interaction between user and vendor gave rise to new languages\n\nJava, Perl, JavaScript used\n\nScientific\n\nFORTRAN, C++, Java\n\nSystem\n\nC and C++ dominate system programming\n\nefficient execution\n\nfull access to the OS and hardware\n\nModula and modern BASIC variatons\n\nAda (though not a major shareholder)\n\nFor real-time applications, C, C++, and Ada are used.\n\nExamples of real-time applications include\n\ncars\n\nmicrowave ovens\n\nvideo games\n\ndigital watches\n\nArtificial Intelligence\n\nLISP is still used, but modern versions are used in place of LISP 1.5\n\nScheme\n\nCommon Lisp\n\nBoth are very good at searching applications\n\nPublishing\n\nRelatively new application\n\nOwn syntax for input commands and output files\n\nThe TEX translator produces Postscript programs\n\nProcess\n\nProcesses are programs that control another\n\nback up files every midnight\n\nsync time once an hour\n\nsend automatic email reply on vacation\n\nautomatically test a program when it compiles successfully\n\nUnix Shell / Shell scripts\n\nOther scripting languages such as TCL and Perl are used for similar purposes\n\nNew paradigms\n\nML used to investigate type theory\n\nSmalltalk has a large influence on language design\n\nNot used very much commercially, though\n\nOO features in C++ and Ada had origins in Smalltalk\n\nSection 1.3: Role of Programming Languages\n\nBy mid 1960s, language priority became ease of use over efficiency\n\nALGOL is no longer used\n\nNewer languages like Java and C++ have been greatly influenced by the languages before them. These influences include:\n\nComputer capabilities\n\nSpeed of modern computers\n\nOS software between programming language and hardware\n\nApplications\n\nApplications are no longer only for military, science, business\n\nPCs, Internet, and gaming have new requirements languages must fill\n\nProgramming methods\n\nLanguage designs have changed to reflect good programming practices\n\nImplementation methods\n\nBetter implementation methods affected feature choices in languages\n\nTheoretical studies\n\nFormal mathematical methods have deepened our understanding of languages\n\nStrengths and weaknesses of language features have been deeply evaluated\n\nStandardization\n\nThe need for programs to move from computer to computer led to standards\n\nThese standards shape how the language is designed\n\nSection 1.3.1: What makes a good language?\n\nAll languages have shortcomings, but some are still much better than others. External forces can influence language popularity, but programmers ultimately decide what languages live and die.\n\nAttributes of a good language\n\nThere are a lot of reasons why one programming language could be viewed as preferable to another.\n\nClarity, simplicity, unity\n\nThe language must provide a framework for thinking about algorithms\n\nThe language must provide a way to express ideas of algorithm implementations\n\nIts concepts should be simple so they can be used in developing algorithms\n\nThe language should have a minimum number of concepts (conceptual integrity)\n\nLanguage syntax determines ease of writing, reading, testing, modifying code\n\nCryptic syntax may be easy to write but is usually hard to read\n\nConstructs that mean different things should look different.\n\nOrthogonality\n\ndefine orthogonality\n\nthe attribute of being able to combine various features with all combinations of features being meaningful.\n\nEx: Language can evaluate expression to get boolean T/F. Language also has conditionals based on T/F. If any expression can be used/evaluated within a conditional statement, these features are orthogonal.\n\nOrthogonal features makes a language easier to learn\n\nA negative aspect is that it may hide errors\n\nNaturalness for the application\n\nLanguage syntax should allow the program structure to reflect the algorithm\n\nExamples of algorithms differing in structure are:\n\nsequential\n\nconcurrent\n\nlogic\n\nThe language should provide the following tools for solving a problem:\n\nappropriate data structures\n\nappropriate operations\n\nappropriate control structures\n\na natural syntax for the problem\n\nSupport for abstraction\n\nThere is always a gap between abstract data structures and primitive data structures.\n\nThe language should allow data structures, data types, and operations to be defined and maintained as self-contained abstractions.\n\nAda developed for lack of abstraction in Pascal, C++ for lack of abstraction in C\n\nEase of program verification\n\nReliability of programs is a huge concern\n\nMethods of testing program correctness:\n\nformal verification\n\ndesk checking\n\ntesting via input data\n\nA combination of the above methods are used for large projects\n\nHard program verification may outweigh language features\n\nSimple syntax/semantics makes program verification simpler\n\nProgramming environment\n\nA weak language with a good environment can be easier than a strong language\n\nFactors that influence the programming environment include:\n\nreliable, efficient, well-documented implementation\n\nSpecial editors\n\nSpecial testing packages\n\nVersion control\n\nSmalltalk designed around a programming environment\n\nPortability of programs\n\nTransportability of the computer a program is developed on to other computers\n\nA language should be widely available\n\nA language's definition is independent of a particular machine\n\nADA, FORTRAN, C have standardized definitions for portable application dev\n\nCost of use\n\nCost of program execution\n\nMain focus of early programming years\n\nSpeed not a high concern anymore\n\n10% or 20% execution time tolerated for other benefits\n\nCost of program translation\n\nStudent programs are compiled frequently but executed few times\n\nA fast compiler is important for programming education\n\nCost of program creation, testing, use\n\nSmalltalk and Perl can help solve problems with minimum investment in programmer time and energy.\n\nProgramming time minimized, but execution time may be larger in comparison to other languages.\n\nCost of program maintenance\n\nStudies show largest cost is over the life of the program, not initial\n\nMaintenance includes repair of errors and enhancements\n\nA language that makes it easy to adjust programs may be cheaper in the long run\n\nSyntax and Semantics\n\ndefine syntax:\n\nWhat the program looks like. How statements, declarations, and other language constructs are written.\n\ndefine semantics:\n\nThe meaning given to the various syntactic constructs.\n\nSection 1.3.2: Language Paradigms\n\nThere are four basic computational models that describe most programming.\n\nImperative languages\n\nAlso known as procedural\n\nCommand-driven or statement-oriented\n\nA program consists of a sequence of statements, execution causes machine to enter a new state.\n\nSyntax of imperative languages is of the form\n\nstatement1; statement2; ...\n\nProgram development is building successive states to arrive at solution\n\nUsually the first model one learns, and also the most widely used\n\nC\n\nC++\n\nFORTRAN\n\nALGOL\n\nPL/I\n\nPascal\n\nAda\n\nSmalltalk\n\nCOBOL\n\nModel follows from the hardware of a computer that executes sequentially\n\nApplicative languages\n\nAlso known as functional languages\n\nLook at the function the program represents\n\nLook at the desired result rather than available data\n\nProgram develops by creating functions from previous functions that manipulate the initial data set until the solution is achieved.\n\nOnce the functions are created, we apply the initial data\n\nThe syntax of function languages is of the form\n\nfunction_n(...function_2(function_1(data))...)\n\nLISP and ML are functional languages\n\nRule-based languages\n\nAlso known as logical programming languages\n\nCheck for condition, executes an appropriate action\n\nMost common rule-based language is Prolog\n\nSet of filters to apply to data storage\n\nSimilar to imperative but statements are not sequential\n\nThe syntax of rule-based languages is of the form\n\nenabling condition_1 => action_1 enabling condition_2 => action_2 ... enabling condition_n => action_n\n\nCommon business application of rules-based languages are decision tables\n\nProgramming often consists of building a matrix/table of conditions and the appropriate actions\n\nBNF parsing techniques and YACC are rule-based techniques\n\nObject-oriented programming\n\nComplex data objects are ubilt, functions are designed to operate on the data\n\nComplex objects are extensions of simpler objects, inheriting properties\n\nA combination of the applicative and imperative models\n\nGenerality of the Computational Model\n\nHow one uses a language depends on a programmer\n\nYou can technically write \"sequential LISP\" or \"functional C\"\n\nApplicative techniques provide effective ways to prove correctness\n\nSection 1.3.3: Language Standardization\n\nA concept of a programming language is tied to an implementation of it\n\nEx: Can you move a C program to another computer using a different compiler?\n\nIf you extend features of a language, is it still that language?\n\nTo solve the above issues, many languages have standard definitions. All implementations should adhere to the standard. There are two types of standards:\n\nProprietary standards: definitions by the company that developed and owns the language. This doesn't work for widely used languages.\n\nConsensus standards: Documents produced by organizations on an agreement. Currently the major method of ensuring uniformity.\n\nAlmost every country has one or more organizations in charge of developing standards.\n\nIn US: American National Standards Institute (ANSI)\n\nProg language standards: Committee X3 of Computer Business Equipment Manufacturers Association.\n\nInstitute of Electrical and Electronic Engineers (IEEE)\n\nIn UK, British Standards Institute (BSI)\n\nInternationally, International Standards Organization (ISO)\n\nStandards making is a consensus process. Not everyone gets their way\n\nCreating standards is partially technical, partially political\n\nTo use standards effectively we need , timeliness, conformance, and Obsolescence\n\nTimeliness\n\nWhen to standardize is important\n\nFORTRAN standard came after there were many incompatible versions\n\nADA standard in 1983 came before any implementation\n\nNo one knew if the language would even work\n\nFirst compilers did not even appear until 1987\n\nGoal should be early enough to avoid incompatible implementations, but not so early that no one has experience with the language.\n\nConformance\n\nA program is conformant if it only uses features defined in the standard\n\nA conformant compiler produces correct output given a conformant program\n\nThe standard says nothing about computation results of non-conformant programs\n\nMany compilers have features not addressed by the standard\n\nObsolescence\n\nStandards should be reviewed every so often\n\nMost standards require backwards compatibility\n\nLanguages may get messy with so many obsolete constructs\n\nDeprecation and obsolescent features have recently developed\n\nobsolescent features may be dropped in the next version\n\ndeprecated features may be obsolescent in the next version\n\nThis cycle provides a 10-20 year warning that new programs can't use the old features.\n\nSection 1.3.4: Internationalization\n\nProgramming increasingly a global activity\n\nLanguages must be usable in multiple countries\n\nLocal conventions on the storage and processing of data leads to some issues\n\nCollating sequences\n\nIn what collating sequence should the characters be order?\n\nSorting - The position of non-Roman characters is not uniformly defined\n\nCase - Some languages don't have uppercase/lowercase\n\nJapanese\n\nArabic\n\nHebrew\n\nThai\n\nScanning direction - Most languages read left to right, but some right to left\n\nCountry specific date/time formats\n\n11/26/02 in the US is 26/11/02 in England, 26.11.02 in France\n\n5:40pm in the US is 17:40 in Japan, 17h40 in France\n\nTime zones\n\nSome time zones are not a whole number apart.\n\nTime changes do not occur uniformly around the world.\n\nTranslating local time to worldwide standard time is not easy.\n\nIdeographic systems\n\nSome languages do not use characters forming an alphabet\n\nJapanese\n\nChinese\n\nKorean\n\n16 bits might be needed to represent these languages\n\nCurrency\n\nRepresentation of currency varies by country.\n\nSection 1.4: Programming Environments\n\nProgramming environment is where programs are created, tested.\n\nUsually consists of support tools and command language for invoking them\n\nTypical tools include:\n\neditors\n\ndebuggers\n\nverifiers\n\npretty printers\n\ntest data generators\n\nSection 1.4.1: Effects on Language Design\n\nProgramming environments have had two large effects on language design:\n\nFeatures aiding separate compilation/assembly from components\n\nFeatures aiding program testing and debugging\n\nSeparate compilation\n\nFor large programs, different programmers will be working on separate parts\n\nThis requires a language that can compile the parts and merge together later\n\nSeparate compilation can be difficult because subprograms might need each other\n\nThere are ways to provide information to subprograms during separate compilation:\n\nInformation may need to be redeclared (FORTRAN)\n\nAn order of compilation may be required (Ada)\n\nA library containing relevant specifications may be required (Java/C++)\n\nOption 1 above uses independent compilation. The subprogram is entirely self contained. The disadvantage is inability to check inconsistency of data between external declaration and internal redeclaration. You will have assembly errors even though the subprograms may have 0 errors.\n\nOptions 2 and 3 require the use of libraries. The body is usually omitted during the compilation of subprograms.\n\nSeparate compilation has the side effect of enabling name collisions issues\n\nSeveral subprograms or portions of programs may have the same name\n\nThis may not be determined until attempting to merge all subprograms\n\nThere are three main ways languages avoid these name collisions\n\nUse of naming conventions (obligation is the programmer's)\n\nUse of scoping rules (Used by Pascal, C, Ada)\n\nAdd name definitions from external library(inheritance in Object oriented)\n\nTesting and debugging\n\nA few typical examples of testing and debugging features:\n\nExecution trace\n\nProlog, LISP, many others have execution tracing tools.\n\nAllows for statements and variables to be tagged for tracing\n\nWhen a tagged statement is called, program stops, debug trace is printed.\n\nBreakpoints\n\nSpecified by programmer\n\nWhen breakpoint is reached, execution is interrupted, control given to user\n\nUser can inspect and modify variables and restart the program\n\nAssertions\n\nA special conditional expression\n\nIf assertion fails, program is interrupted.\n\nException handler may print or take other actions upon failed assertion\n\nAfter debugging, assertions may be disabled.\n\nSection 1.4.2: Environment Frameworks\n\nSupport environment: Uses infrastructure services called environment framework\n\nEnvironment framework: supplies data repository, GUI, security, communication\n\nEx: An environment framework would contain the following\n\nA window manager such as Motif\n\nVB and Visual Studio provide for libraries to build windows\n\nSection 1.4.3 Job Control and Process Languages\n\nUsed to wait for each compilation step to finish before fixing/moving on\n\n1960s, programs began using return code\n\nThis allowed for OS to process sequence of preloaded steps.\n\nUNIX extended concept of job control\n\nControl language was more complex, not just job checking\n\nPrograms could link together operations from other programs\n\nPrograms could use results of previous operations and also file contents\n\nThis led to UNIX shells such as Bash, C, Korn\n\nThe shell concept led to process/scripting languages\n\nUsually interpreted\n\nView programs and files as primitive data\n\nAWK, Perl, TCL\n\nScripting languages important for communicating with web server\n\nInternet time: The process software dev needs to match speed of the Internet\n\nScripting languages allows for rapid prototyping of applications\n\nSection 1.5: C Overview\n\nHistory of C\n\nDeveloped 1972 by Dennis Ritchie and Ken Thompson\n\nAT&T Bell Telephone Laboratories\n\nRelated to ALGOL/Pascal in style\n\nGeneral purpose language, but popular as systems programming language\n\nIn late 1960s, Bell Labs dropped out of MIT and GE project to developer Multics OS. Ken Thompson began UNIX.\n\nMultics programmed in PL/I. Thompson didn't want to use PL/I for UNIX.\n\nDeveloped B, a minimal subset of BCPL.\n\nTypes, structures, and more were added to B, and B became C.\n\nC is general-purpose, but closely associated with systems programming.\n\nFirst used to write UNIX kernel\n\nTied to UNIX implementations ever since.\n\nIn 1970s, C mostly a university curiosity\n\nIn 1980s, commercial UNIX OS's began to appear\n\nCommercial UNIX versions led to C popularity\n\n1989 ANSI C standard\n\nMany new languages have syntax and semantics partially based on C\n\nBrief overview of C\n\nThe C Language:\n\nRelatively small\n\nLimited number of features\n\nThe C Preprocessor\n\nNot part of the C language!\n\nThe C interface assumptions\n\nSet of conventions have grown\n\ninterface definitions assumed to be defined in header file\n\nThe C library\n\nMany important functions were written in C, and are not part of the language\n\nANSI C lists these functions as required library functions for compilers\n\nA C module consists of global declarations and a sequence of functions.\n\nMultiple modules loaded together to form executable\n\nEach function can invoke a function and access local or global data\n\nMakes data storage simple\n\nLocal data is dynamic, allows for recursion\n\nEach function has access to global data\n\nC has pointers\n\n\"Equivalence\" between arrays and pointers\n\nEquivalence permits programs to use appropriate access method\n\nStrings are arrays of characters\n\nLarge set of arithmetic operators\n\nFlexible type definition\n\nStrongly AND weakly typed?!\n\nMost data items are subtypes of integers\n\nSome type errors may be missed for this reason.\n\nCompiler executes\n\nInvokes preprocessor first\n\n#define and #include evaluated\n\nTagged as computer science\n\nTweet\n\n(This post is part of the programming languages 4th edition series.)"
    }
}