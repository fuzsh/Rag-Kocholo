{
    "id": "correct_foundationPlace_00002_3",
    "rank": 80,
    "data": {
        "url": "https://github.com/IBM/automation-data-foundation",
        "read_more_link": "",
        "language": "en",
        "title": "foundation: Automation logic to provision Cloud Pak for Data Foundation on an OpenShfit cluster",
        "top_image": "https://opengraph.githubassets.com/f0c1c34c48ca91f2579ca1dde2167e407bf1935c491e02bdc2c117916c56f2b7/IBM/automation-data-foundation",
        "meta_img": "https://opengraph.githubassets.com/f0c1c34c48ca91f2579ca1dde2167e407bf1935c491e02bdc2c117916c56f2b7/IBM/automation-data-foundation",
        "images": [
            "https://github.com/IBM/automation-data-foundation/raw/main/images/cp4d-diagram.jpg",
            "https://github.com/IBM/automation-data-foundation/raw/main/images/cp4d-route.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Automation logic to provision Cloud Pak for Data Foundation on an OpenShfit cluster - IBM/automation-data-foundation",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/IBM/automation-data-foundation",
        "text": "01/2023 - Updated for CP4D 4.6, using Cloud Pak Deployer\n\n11/2022 - Updated for Terragrunt & GitOps provider support\n\n08/2022 - Added CPD 4.0.x version, fixed broken links\n\n06/2022 - Fixed typos like GitClone script, replace maximo with CP4D from README\n\n06/2022 - Support for CP4D Data source services DB2OLTP and DB2Warehouse (removed)\n\n06/2022 - Support for Azure\n\n05/2022 - Initial Release\n\nThis collection of Cloud Pak for Data terraform automation layers has been crafted from a set of Terraform modules created by the IBM GSI Ecosystem Lab team part of the IBM Partner Ecosystem organization. Please contact Matthew Perrins mjperrin@us.ibm.com, Sean Sundberg seansund@us.ibm.com, Tom Skill tskill@us.ibm.com, or Andrew Trice amtrice@us.ibm.com or Bala Sivasubramanian bala@us.ibm.com for more details or raise an issue on the repository.\n\nThe automation will support the installation of Cloud Pak For Data on three cloud platforms (AWS, Azure, and IBM Cloud) by leveraging the Cloud Pak Deployer in-cluster in a GitOps configuration. Data Foundation is the minimum base layer of the Cloud Pak for Data that is required to install additional tools, services or cartridges, such as DB2 Warehouse, Data Virtualization, Watson Knowledge Studio, or multi-product solutions like Data Fabric. Additional cartridges can be installed by changing installation options in the cp4d.tfvars file, as described later in this document.\n\nThe Cloud Pak for Data - Foundation automation assumes you have an OpenShift cluster already configured on your cloud of choice. The supported managed options are ROSA for AWS, ARO for Azure or ROKS for IBM Cloud .\n\nBefore you start to install and configure Cloud Pak for Data, you will need to identify what your target infrastructure is going to be. You can start from scratch and use one of the pre-defined reference architectures from IBM or bring your own.\n\n⚠️ Cloud Pak for Data 4.6 requires an OpenShift 4.10 cluster.\n\nThe reference architectures are provided in three different forms, with increasing security and associated sophistication to support production configuration. These three forms are as follows:\n\nQuick Start - a simple architecture to quickly get an OpenShift cluster provisioned\n\nStandard - a standard production deployment environment with typical security protections, private endpoints, VPN server, key management encryption, etc\n\nAdvanced - a more advanced deployment that employs network isolation to securely route traffic between the different layers.\n\nFor each of these reference architecture, we have provided a detailed set of automation to create the environment for the software. If you do not have an OpenShift environment provisioned, please use one of these. They are optimized for the installation of this solution.\n\nNote: Cloud Pak for Data 4.6 system requirements recommend at least 3 worker nodes, with minimum 16vCPU per node and minimum 64 GB RAM per done (128 GB RAM is recommended).\n\nCloud Platform Automation and Documentation IBM Cloud IBM Cloud Quick Start\n\nIBM Cloud Standard - Coming soon\n\nIBM Cloud Advanced - Coming soon AWS AWS Quick Start - Coming soon\n\nAWS Standard - Coming soon\n\nAWS Advanced - Coming soon Azure Azure Quick Start\n\nAzure Standard - Coming soon\n\nAzure Advanced - Coming soon Bring Your Own Infrastructure You will need a cluster with at least 16 CPUs and 64 GB of memory per node and at least 3 nodes to support storage and IBM Cloud Paks.\n\nWithin this repository you will find a set of Terraform template bundles that embody best practices for provisioning the Data Foundation in multiple cloud environments. This README.md describes the SRE steps required to provision the Data Foundation software.\n\nThis suite of automation can be used for a Proof of Technology environment, or used as a foundation for production workloads with a fully working end-to-end cloud-native environment. The software installs using GitOps best practices with Red Hat Open Shift GitOps\n\nThe following reference architecture represents the logical view of how Data Foundation works after it is installed. If targeting IBM Cloud, Data Foundation is deployed with OpenShift Data Foundation storage, within an OpenShift Cluster. If targeting Amazon or AWS, the OpenShift cluster must already have OpenShift Data Foundation configured prior to using this automation.\n\nThe following instructions will help you install Cloud Pak for Data (CP4D) into AWS, Azure, and IBM Cloud OpenShift Kubernetes environment.\n\nDetails on Cloud Pak for Data licensing available at https://www.ibm.com/docs/en/cloud-paks/cp-data/4.6.x?topic=planning-licenses-entitlements\n\nYou must have your IBM entitlement API key to access images in the IBM Entitled Registry.\n\nAfter you purchase Cloud Pak for Data, an entitlement API key for the software is associated with your My IBM account. You need this key to complete the Cloud Pak for Data installation. To obtain the entitlement key, complete the following steps:\n\nLog in to Container software library on My IBM with the IBM ID and password that are associated with the entitled software.\n\nOn the Get entitlement key tab, select Copy key to copy the entitlement key to the clipboard.\n\nSave the API key for later in this installation.\n\nThe Data Foundation automation is broken into what we call layers of automation or bundles. The bundles enable SRE activities to be optimized. The automation is generic between clouds other than configuration storage options, which are platform specific.\n\nBOM ID Name Description Run Time 200 200 - OpenShift Gitops Set up OpenShift GitOps tools in an OpenShift cluster. This is required to install the software using gitops approaches. 10 Mins 210 210 - IBM Portworx Storage\n\n210 - IBM OpenShift Data Foundation\n\n210 - AWS Portworx Storage\n\n210 - Azure Portworx Storage Use this automation to deploy a storage solution for your cluster. 10 Mins 300 300 - Cloud Pak for Data Foundation Deploy the Cloud Pak for Data Foundation components 30 Mins\n\nAt this time the most reliable way of running this automation is with Terraform in your local machine either through a bootstrapped container image or with native tools installed. We provide a Container image that has all the common SRE tools installed. CLI Tools Image, Source Code for CLI Tools\n\nBefore you start the installation please install the pre-req tools on your machine.\n\nWe have tested this on a modern Mac laptop. We are testing on M1 machines. You will need to setup the tools natively in your M1 Mac OS and not run the launch.sh script.\n\nPlease install the following Pre-Req tools to help you get started with the SRE tasks for installing Data Foundation into an existing OpenShift Cluster on AWS, Azure, or IBM Cloud.\n\nPre-requisites:\n\nCheck you have a valid GitHub ID that can be used to create a repository in your own organization GitHub or GitHub Enterprise account.\n\nInstall a code editor, we recommend Visual Studio Code\n\nInstall Brew\n\nEnsure you have the following before continuing:\n\nGithub account exists\n\nA Github token is available with permissions set to create and remove repositories\n\nYou are able to login to the OpenShift cluster and obtain an OpenShift login token\n\nCloud Pak entitlement key, this can be obtained from visiting the IBM Container Library as described above.\n\nIf you are deploying on IBM Cloud Satellite, please review the Satellite prerequisites.\n\nOpenShift Data Foundation - If targeting AWS or Azure clusters, you must configure OpenShift Data Foundation prior to running this automation.\n\nThe installation process will use a standard GitOps repository that has been built using the Modules to support Data Foundation installation. The automation is consistent across three cloud environments AWS, Azure, and IBM Cloud.\n\nAt this time the most reliable way of running this automation is with Terraform in your local machine either through a bootstrapped docker image or Virtual Machine. We provide both a container image and a virtual machine cloud-init script that have all the common SRE tools installed.\n\nWe recommend using Docker Desktop if choosing the container image method, and Multipass if choosing the virtual machine method. Detailed instructions for downloading and configuring both Docker Desktop and Multipass can be found in RUNTIMES.md\n\nFirst step is to clone the automation code to your local machine. Run this git command in your favorite command line shell.\n\ngit clone https://github.com/IBM/automation-data-foundation.git\n\nNavigate into the automation-data-foundation folder using your command line.\n\na. The README.md has a comprehensive instructions on how to install this into other cloud environments than TechZone. This document focuses on getting it running in a TechZone requested environment.\n\nNext you will need to set-up your credentials.properties file. This will enable a secure deployment to your cluster.\n\ncp credentials.template credentials.properties code credential.properties\n\nIn the credentials.properties file you will need to populate the values for your deployment.\n\n## Add the values for the Credentials to access the OpenShift Environment ## Instructions to access this information can be found in the README.MD ## This is a template file and the ./launch.sh script looks for a file based on this template named credentials.properties ## gitops_repo_host: The host for the git repository #export TF_VAR_gitops_repo_host=github.com ## gitops_repo_username: The username of the user with access to the repository #export TF_VAR_gitops_repo_username= ## gitops_repo_token: The personal access token used to access the repository #export TF_VAR_gitops_repo_token= ## TF_VAR_server_url: The url for the OpenShift api server export TF_VAR_server_url= ## TF_VAR_cluster_login_token: Token used for authentication to the api server export TF_VAR_cluster_login_token= ## TF_VAR_entitlement_key: The entitlement key used to access the IBM software images in the container registry. Visit https://myibm.ibm.com/products-services/containerlibrary to get the key export TF_VAR_entitlement_key= # Only needed if targeting IBM Cloud Deployment export TF_VAR_ibmcloud_api_key=\n\nIf you would like to use GitHub for your GitOps repo, then you will need to populate these values. Add your GitHub username and your Personal Access Token to TF_VAR_gitops_repo_username and TF_VAR_gitops_repo_token. If these values are left blank, the automation will deploy Gitea into the OpenShift cluster for the GitOps deployment, requiring no additional user interaction.\n\nFrom you OpenShift console click on top right menu and select Copy login command and click on Display Token\n\nCopy the API Token value into the cluster_login_token value\n\nCopy the Server URL into the server_url value, only the part starting with https\n\nCopy the entitlement key, this can be obtained from visiting the IBM Container Library and place it in the entitlement_key variable.\n\nIf targeting IBM Cloud, be sure to specify an API key in the ibmcloud_api_key variable, to be used to automatically configure ODF storage. If targeting AWS or Azure, be sure to configure ODF prior to using this automation.\n\nLaunch the automation runtime.\n\nIf using Docker Desktop, run ./launch.sh. This will start a container image with the prompt opened in the /terraform directory.\n\nIf using Multipass, run mutlipass shell cli-tools to start the interactive shell, and cd into the /automation/{template} directory, where {template} is the folder you've cloned this repo. Be sure to run source credentials.properties once in the shell.\n\nNext we need to create a workspace to run the Terraform automation. Below you can see the parameters to configure your workspace for terraform execution.\n\n/terraform $ ./setup-workspace.sh -h Creates a workspace folder and populates it with automation bundles you require. Usage: setup-workspace.sh options: -p Cloud provider (aws, azure, ibm) -n (optional) prefix that should be used for all variables -c (optional) Self-signed Certificate Authority issuer CRT file -b (optional) the banner text that should be shown at the top of the cluster -g (optional) the git host that will be used for the gitops repo. If left blank gitea will be used by default. (Github, Github Enterprise, Gitlab, Bitbucket, zure DevOps, and Gitea servers are supported) -h Print this help\n\nYou will need to select the cloud provider of your choice, storage option, and if desired, a prefix for naming new resource instances on the Cloud account.\n\nRun the command setup-workspace.sh -p ibm -n df and include optional parameters as needed.\n\n/terraform $ ./setup-workspace.sh -p ibm Setting up workspace in '/terraform/../workspaces/current' ***** Setting up workspace in /workspaces/current ***** Setting up current/105-existing-openshift from 105-existing-openshift Setting up current/200-openshift-gitops from 200-openshift-gitops Setting up current/210-ibm-odf-storage from 210-ibm-odf-storage Setting up current/300-cloud-pak-for-data-foundation from 300-cloud-pak-for-data-foundation move to /workspaces/current this is where your automation is configured\n\n⚠️ If you are deploying on IBM Cloud Satellite, be sure the cluster has ODF storage option configured.\n\nThe default cluster.tfvars, cp4d.tfvars, and gitops.tfvars files are symbolically linked to the new workspaces/current folder so this enables you to edit the file in your native operating system using your editor of choice.\n\nEdit the default cp4d.tfvars file this will enable you to configure the Cloud Pak for Data deployment. You MUST specify a value for the cluster_ingress.\n\nEdit the default gitops.tfvars file this will enable you to setup the GitOps parameters, or leave the default configuration to use Gitea in-cluster for the GitOps repository.\n\nThe following you will be prompted for and some suggested values.\n\nVariable Description Suggested Value gitops-repo_host The host for the git repository. github.com gitops-repo_type The type of the hosted git repository (github or gitlab). github gitops-repo_org The org/group/username where the git repository exists github userid or org - if left blank the value will default to your username gitops-repo_repo The short name of the repository to create cp4d-gitops\n\nThe gitops-repo_repo, gitops-repo_token, entitlement_key, server_url, and cluster_login_token values will be loaded automatically from the credentials.properties file that was configured in an earlier step.\n\nYou will see that the repo_type and repo_host are set to GitHub you can change these to other Git Providers, like GitHub Enterprise or GitLab.\n\nFor the repo_org value set it to your default org name, or specific a custom org value. This is the organization where the GitOps Repository will be created in. Click on top right menu and select Your Profile to take you to your default organization.\n\nSet the repo_repo value to a unique name that you will recognize as the place where the GitOps configuration is going to be placed before Data Foundation is installed into the cluster.\n\nYou can change the gitops-cluster-config_banner_text banner text to something useful for your client project or demo.\n\nSave the all changes to the tfvars files.\n\nNavigate into the /workspaces/current folder\n\n❗️ Do not skip this step. You must execute from the /workspaces/current folder.\n\n⚠️ If you are deploying on IBM Cloud Satellite, you must delete the /workspaces/current/210-ibm-odf-storage folder ODF will already have been deployed into the Satellite cluster. For additional detail, please see the Satellite prerequisites.\n\n⚠️ If your cluster already has ODF configured, you must delete the /workspaces/current/210-ibm-odf-storage folder.\n\nTo perform the deployment automatically, execute the ./apply-all.sh script in the /workspaces/current directory. This will apply each of the Data Foundation layers sequentially. This operation will complete in 10-15 minutes, and the Data Foundation will continue asynchronously in the background. This can take an additional 60 minutes.\n\nAlternatively you can run each of the layers individually, by following the manual deployment instructions.\n\nOnce complete, skip to the Access the Data Foundation Deployment section\n\nOnce deployment is complete, go back into the OpenShift cluster user interface and navigate to view Routes for the cpd-instance namespace. Here you can see the URL to the deployed Cloud Pak for Data instance. Open this url in a new browser window.\n\nNavigate to Secrets in the cpd-instance namespace, and find the admin-user-details secret. Copy the value of initial_admin_password key inside of that secret.\n\nGo back to the Cloud Pak for Data Foundation instance that you opened in a separate window. Log in using the username admin with the password copied in the previous step.\n\nUpdate the deployment using GitOps\n\nYou can change the installed cartridges on the deployed Cloud Pak for Data instance by modifying the gitops configuration. This will automatically trigger a new job on the cluster that executes the Cloud Pak Deployer and applies the desired changes.\n\nIn the GitOps repo, find the values.yaml file located at cp4d--gitops/payload/1-infrastructure/namespace/cloud-pak-deployer/cp4d-deployer/values.yaml. You can change the boolean values from false to true to install the additional cartridges. Once you commit changes to this file, OpenShift GitOps will automatically detect the change and trigger the job which will apply the updates to the existing Cloud Pak for Data instance.\n\nApplying these changes is an asynchronous process that can take a few minutes, or more than an hour, depending on the changes that are being applied. You can monitor the deployment status using the OpenShift GitOps (ArgoCD) user interface, which is accessible through the OpenShift cluster's Application Launcher menu.\n\nThis concludes the instructions for installing Data Foundation on AWS, Azure, and IBM Cloud.\n\nPlease refer to the Troubleshooting Guide for uninstallation instructions and instructions to correct common issues.\n\nIf you continue to experience issues with this automation, please file an issue or reach out on our public Dischord server.\n\nThis set of automation packages was generated using the open-source isacable tool. This tool enables a Bill of Material yaml file to describe your software requirements. If you want up stream releases or versions you can use iascable to generate a new terraform module.\n\nThe iascable tool is targeted for use by advanced SRE developers. It requires deep knowledge of how the modules plug together into a customized architecture. This repository is a fully tested output from that tool. This makes it ready to consume for projects."
    }
}