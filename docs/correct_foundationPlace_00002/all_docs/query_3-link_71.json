{
    "id": "correct_foundationPlace_00002_3",
    "rank": 71,
    "data": {
        "url": "https://docs.redhat.com/en/documentation/red_hat_openshift_data_foundation/4.9/html/deploying_openshift_data_foundation_using_ibm_cloud/deploying_openshift_container_storage_using_ibm_cloud_rhodf",
        "read_more_link": "",
        "language": "en",
        "title": "Chapter 1. Deploying OpenShift Data Foundation using IBM Cloud",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://docs.redhat.com/Logo-Red_Hat-Documentation-A-Reverse-RGB.svg",
            "https://docs.redhat.com/Logo-Red_Hat-Documentation-A-Reverse-RGB.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Chapter 1. Deploying OpenShift Data Foundation using IBM Cloud | Red Hat Documentation",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": "https://docs.redhat.com/en/documentation/red_hat_openshift_data_foundation/4.9/html/deploying_openshift_data_foundation_using_ibm_cloud/deploying_openshift_container_storage_using_ibm_cloud_rhodf",
        "text": "1.1. Deploying on IBM Cloud public\n\nWhen you create a Red Hat OpenShift on IBM Cloud cluster, you can choose between classic or Virtual Private Cloud (VPC) infrastructure. The Red Hat OpenShift Data Foundation managed cluster add-on supports both infrastructure providers. For classic clusters, the add-on deploys the OpenShift Data Foundation operator with the Local Storage operator. For VPC clusters, the add-on deploys the OpenShift Data Foundation operator which you can use with IBM Cloud Block Storage on VPC storage volumes.\n\nBenefits of using the OpenShift Data Foundation managed cluster add-on to install OpenShift Data Foundation instead of installing from OperatorHub\n\nDeploy OpenShift Data Foundation from a single CRD instead of manually creating separate resources. For example, in the single CRD that add-on enables, you configure the namespaces, storagecluster, and other resources you need to run OpenShift Data Foundation.\n\nClassic - Automatically create PVs using the storage devices that you specify in your OpenShift Data Foundation CRD.\n\nVPC - Dynamically provision IBM Cloud Block Storage on VPC storage volumes for your OpenShift Data Foundation storage cluster.\n\nGet patch updates automatically for the managed add-on.\n\nUpdate the OpenShift Data Foundation version by modifying a single field in the CRD.\n\nIntegrate with IBM Cloud Object Storage by providing credentials in the CRD.\n\n1.1.1. Deploying on classic infrastructure in IBM Cloud\n\nYou can deploy OpenShift Data Foundation on IBM Cloud classic clusters by using the managed cluster add-on to install the OpenShift Data Foundation operator and the Local Storage operator. After you install the OpenShift Data Foundation add-on in your IBM Cloud classic cluster, you create a single custom resource definition that contains your storage device configuration details.\n\nFor more information, see the Preparing your cluster for OpenShift Data Foundation.\n\n1.1.2. Deploying on VPC infrastructure in IBM Cloud\n\nYou can deploy OpenShift Data Foundation on IBM Cloud VPC clusters by using the managed cluster add-on to install the OpenShift Data Foundation operator. After you install the OpenShift Data Foundation add-on in your IBM Cloud classic cluster, you create a custom resource definition that contains your worker node information and the IBM Cloud Block Storage for VPC storage classes that you want to use to dynamically provision the OpenShift Data Foundation storage devices.\n\nFor more information, see the Preparing your cluster OpenShift Data Foundation.\n\n1.2. Deploying on IBM Cloud Satellite\n\nWith IBM Cloud Satellite, you can create a location with your own infrastructure, such as an on-premises data center or another cloud provider, to bring IBM Cloud services anywhere, including where your data resides. If you store your data by using Red Hat OpenShift Data Foundation, you can use Satellite storage templates to consistently install OpenShift Data Foundation across the clusters in your Satellite location. The templates help you create a Satellite configuration of the various OpenShift Data Foundation parameters, such as the device paths to your local disks or the storage classes that you want to use to dynamically provision volumes. Then, you assign the Satellite configuration to the clusters where you want to install OpenShift Data Foundation.\n\nBenefits of using Satellite storage to install OpenShift Data Foundation instead of installing from OperatorHub\n\nCreate versions your OpenShift Data Foundation configuration to install across multiple clusters or expand your existing configuration.\n\nUpdate OpenShift Data Foundation across multiple clusters consistently.\n\nStandardize storage classes that developers can use for persistent storage across clusters.\n\nUse a similar deployment pattern for your apps with Satellite Config.\n\nChoose from templates for an OpenShift Data Foundation cluster using local disks on your worker nodes or an OpenShift Data Foundation cluster that uses dynamically provisioned volumes from your storage provider.\n\nIntegrate with IBM Cloud Object Storage by providing credentials in the template.\n\n1.2.1. Using OpenShift Data Foundation with the local storage present on your worker nodes in IBM Cloud Satellite\n\nFor an OpenShift Data Foundation configuration that uses the local storage present on your worker nodes, you can use a Satellite template to configure your OpenShift Data Foundation configuration. Your cluster must meet certain requirements, such as CPU and memory requirements and size requirements of the available raw unformatted, unmounted disks. Choose a local OpenShift Data Foundation configuration when you want to use the local storage devices already present on your worker nodes, or statically provisioned raw volumes that you attach to your worker nodes.\n\nFor more information, see the IBM Cloud Satellite local OpenShift Data Foundation storage documentation.\n\n1.2.2. Using OpenShift Data Foundation with remote, dynamically provisioned storage volumes in IBM Cloud Satellite\n\nFor an OpenShift Data Foundation configuration that uses remote, dynamically provisioned storage volumes from your preferred storage provider, you can use a Satellite storage template to create your storage configuration. In your OpenShift Data Foundation configuration, you specify the storage classes that you want use and the volume sizes that you want to provision. Your cluster must meet certain requirements, such as CPU and memory requirements. Choose the OpenShift Data Foundation-remote storage template when you want to use dynamically provisioned remote volumes from your storage provider in your OpenShift Data Foundation configuration.\n\nFor more information, see the IBM Cloud Satellite remote OpenShift Data Foundation storage documentation."
    }
}