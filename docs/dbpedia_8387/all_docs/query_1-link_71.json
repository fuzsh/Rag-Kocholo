{
    "id": "dbpedia_8387_1",
    "rank": 71,
    "data": {
        "url": "https://en.citizendium.org/wiki/History_of_economic_thought",
        "read_more_link": "",
        "language": "en",
        "title": "History of economic thought",
        "top_image": "https://en.citizendium.org/images/favicon1.ico",
        "meta_img": "https://en.citizendium.org/images/favicon1.ico",
        "images": [
            "https://s9.addthis.com/button1-share.gif",
            "https://en.citizendium.org/wiki/images/8/89/Statusbar0.png",
            "https://en.citizendium.org/wiki/images/thumb/1/1f/Subpages.png/14px-Subpages.png",
            "https://en.citizendium.org/wiki/images/thumb/4/4f/Metadata.png/14px-Metadata.png",
            "https://en.citizendium.org/wiki/images/thumb/0/07/Print_button.png/17px-Print_button.png",
            "https://en.citizendium.org/wiki/resources/assets/licenses/cc-by-nc-sa.png",
            "https://en.citizendium.org/wiki/resources/assets/poweredby_mediawiki_88x31.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/images/favicon1.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Modern economic thought is generally considered to have originated in the late eighteenth century with the work of David Hume and Adam Smith, the founders of classical economics. The nineteenth and twentieth centuries saw major developments in the methodology and scope of economic theory; and the early twenty-first century has seen a rethinking of some previously accepted tenets.\n\nNineteenth- and early twentieth-century economists applied deductive reasoning to axioms considered to be self-evident and simplified assumptions which were thought to capture the essential features of economic activity. That methodology yielded concepts such as elasticity and utility, tools such as marginal analysis, and theorems such as the law of comparative advantage. An understanding of the relationships governing transactions between consumers and producers was considered to provide all that was necessary to explain the behaviour of the economic system.\n\nThe development, in the latter half of the 20th century, of systems of economic statistics enabled economists to use inductive reasoning to test theoretical findings against observed economic behaviour, and to develop new theories. By that time, the concept had emerged of the national economy as a complex interactive system, and analysis of that concept provided explanations of recessions, unemployment and inflation that were not previously available. The application of empirical data and inductive reasoning enabled those theories to be refined, and led to the development of forecasting models that could be used as tools of economic management.\n\nThe development of economic thought in the early 21st century has been stimulated by the financial crisis and Great Recession, and the questions that these events raised concerning the functioning of the global financial system and the part that it plays in the functioning of the economic system generally.\n\nThe search for understanding continues.\n\nOverview: categories of economic thought\n\nHistorians categorise economic thought into “periods” and “schools”, and tend to attribute each innovation to one individual. This categorisation is helpful for the purpose of exposition, but the reality has been a story of interwoven intellectual threads in which advances attributed to particular individuals or schools have often prompted the work of others. For example, the quantity theory of money, which achieved prominence in the twentieth century and is associated with Milton Friedman, was first formulated at least three centuries earlier. Many of those threads, that have permeated the categories referred to as \"Classical economics\" and \"Neoclassical economics\", had earlier origins. \"Classical\", in economics, denotes the adoption in the late eighteenth century of an approach that was inspired by the enlightenment and the methodology of the physical sciences, and that had abandoned previous examinations of economics in terms of ethics, religion and politics. Preoccupation with those threads was overshadowed in the twentieth century by the responses of Keynesianism and monetarism to the problems of unemployment and inflation, but the development of neoclassical economics started before that time, and has continued thereafter. The introduction of new tools of exploration has since led to the vigorous development of that, and other, threads, and an expansion in the scope of economics into many new directions.\n\nClassical Economics\n\nDavid Hume\n\nThe Scottish philosopher David Hume was an early exponent of what was later known as monetary economics, and was an opponent of \"mercantilism\". Mercanilist policy at the time, regulated trade in ways that subsidised exports so as to promote inflows of gold and silver, and restricted imports in order to discourage outflows. Hume contested the mercantilist thesis, partly on the grounds that an inflow of money would cause inflation, and partly on the grounds that nations would benefit from the international specialisation that would result from the introduction of free trade. More generally, Hume argued that all government intervention in commerce tended to obstruct economic progress.[1].\n\nAdam Smith\n\nA major advance in the development of economics occurred with the publication in 1776 of Adam Smith's An Inquiry into the Nature and Causes of The Wealth of Nations.[2]. Smith wrote a comprehensive treatment of the subject, using deductive logic in a manner similar to its use in the physical sciences. His main purpose was to recommend changes of economic policy in the interests of economic growth. He argued that the division of labour was the main cause of economic growth. His famous maxim was that the extent of the market is determined by the division of labour. To thus expand markets, required that they should not be impeded by governmental policies. He therefore opposed government intervention in commerce (as in mercantilist trade regulation). But he did not oppose all governmental intervention into the economy. He advocated government spending upon what are now termed public goods such as defence, law enforcement, infrastructure, and education of the children of people who could not afford it. He identified what he considered to be the economic drawbacks of all forms of taxation (except the taxation of land values) and of public expenditure. He examined the relation of price to value and concluded that the price of a product tends to equality with its cost of production, which he termed its \"natural price\". He reasoned that \"when the quantity brought to market is just sufficient to supply the effectual demand and no more, the market price naturally comes to be either exactly, or as nearly as can be judged of, the same with the natural price\" - an outcome which he took to be the normal result of market bargaining.\n\nJean-Baptiste Say\n\nJean-Baptiste Say[3] was an influential advocate of Adam Smith's teaching in French government circles, but his best-known contribution was what came to be known as \"Say's Law of Markets.\" Later paraphrased as \"supply creates its own demand,\" Say's law stated that, although there could be an imbalance between the supply and the demand for particular products, no such imbalance could exist in the economy as a whole. It was based upon the postulate that money plays no part in the functioning of the economy beyond its role as a medium of exchange. (The claim that money is nothing but a medium of exchange, is another way of saying that people use money only for buying things (including stocks and bonds). Say justified that postulate by arguing that it would be foolish to hold money out of circulation because that would mean needlessly going without things (or without dividends or interest). Say's Law remained part of mainstream classical economics until John Maynard Keynes drew attention to the speculative and precautionary motives for holding money.\n\nThomas Malthus\n\nIn his influential Essay on the Principle of Population, Thomas Malthus postulated that the population would grow at a geometric rate (2, 4, 8, 16...) while food production could only increase arithmetically (1, 2, 3, 4 ....) and concluded that the food supply would eventually be insufficient to support the population.[4] This theory led him to oppose the introduction of the UK's Poor Law, and to advocate the protection of agriculture. In other respects, he followed Adam Smith in opposing government intervention in commerce. Evidence in support of his postulates was lacking at the time, and they have since been found to be mistaken[5], mainly because they took no account of the benefits of technical change.\n\nDavid Ricardo\n\nWith minor reservations, David Ricardo accepted and extended Adam Smith’s economics. In his major work,The Principles of Political Economy and Taxation, he accepted the concept of a value-determined “natural price”, although he considered value to be determined by labour value added, rather than cost.[6] Following Adam Smith’s lead, he also developed the wage fund concept that the amount available for the payment of wages is fixed at any particular level of capital investment, so that an increase in the supply of labour would lead to a reduction in wage rates. He pioneered a definition of rent as the difference between the produce of a unit of labour on the land in question, and its produce on the least productive land in use. In a further extension to Adam Smith’s work, he explored the incidence of taxation on wages, profits, houses, and rent, identifying in each case (but with the exception of rent) its harm to the economy. Probably his most influential contribution, however, was his development of his \"Law of Comparative advantage\" that challenged the belief that the trading of a product is possible only with those with a lesser ability to produce it. Ricardo produced a logical demonstration that there can be mutually beneficial trade between two countries, one of which is better able than the other to produce all of the commodities that are traded.\n\nKarl Marx\n\nKarl Marx[7] adapted Ricardo's concept of labour value and put it to an entirely different use. In his analysis, as in Ricardo's, labour consumption determines value. This, Marx termed exchange value. But Marx regarded each labourer as a product, whose exchange value is determined by the labour inputs required to feed, clothe, and train him. He reasoned that what the employer receives is the labourer's use value, which is determined by the utility of his products. Marx noted that a labourer's use value normally exceeds his exchange value, and he termed the difference surplus value, which was the employer's profit. Like Adam Smith and his classical predecessors, Marx was preoccupied with the subject of economic growth but, unlike them, he saw technical progress as a major contributor.\n\nMarx was probably the first economist to make a systematic attempt to explain the fluctuations in economic activity known as the business cycle. He considered that if technical progress were to slow down, the only way to maintain growth would be to invest more and more in machinery and buildings, as a result of which the rate of profit on new investment would fall, leading to a further reduction in growth. Also, in his view, any departure from the conditions necessary for steady growth would lead to the accumulation of unwanted stocks of goods, producing a downturn in economic activity - until price-cutting, in order to get rid of surpluses, put the process into reverse.\n\nIn his major work, Das Kapital[8] Marx puts his findings in an historical, concludes that economic conditions shape history, and forecasts a breakdown of the capitalist system and its replacement by socialism.\n\nOther contributors\n\nAmong the many lesser contributors to classical economic theory, the best-known was John Stuart Mill. His Principles of Political Economy[9], although intended by the author merely to bring together the works of others, offered some fresh insights into increasing returns to scale and their consequences for the development of monopolies, and anticipated (though not in these terms) the neoclassical concepts of elasticity and the determination of price by the interaction of supply and demand.\n\nWritten during the classical period, but without recognition at the time, was the Theory of the Firm by the French economist and mathematician Antoine Augustin Cournot. Cournot used differential calculus to demonstrate the profit-maximising requirement of equality between marginal cost and marginal revenue, thus anticipating some of the more important developments of neoclassical economics.\n\nNeoclassical Economics\n\nThe neoclassical approach\n\nThe term \"neoclassical\" is commonly applied to all of the continuing developments in economic thinking that followed the replacement of value-based concepts by the concept of markets that are governed by the interaction of supply and demand. In that sense, the term denotes a period rather than a consistent approach - although it is a period that overlaps the competing approaches of Keynesianism and monetarism. It is nevertheless a period in which most economists have deduced their findings from the same hypothetical postulates - including the assumption of competitive markets in which consumers maximise utility and producers maximise profits. Within that framework of postulates, neoclassical economists have explored a variety of aspects of economic activity in a variety of different ways.\n\nMarginal analysis\n\nThe neoclassical period is also marked by an expansion in the number of people applying their minds to the problems of economics, as a result of which there have frequently been similar contributions from a number of different thinkers. That was true of the innovative concepts of marginal analysis, that are attributable to the contributions of William Stanley Jevons [10] , Carl Menger [11] and Léon Walras [12]. Their contributions have been brought together by Alfred Marshall in his Principles of Economics [13], which provides the reader with an accessible and readable (and non-mathematical) account of those and other contributions. The concept of utility, was given more prominence, and it was demonstrated logically (and mathematically) that a rational consumer would continue to buy additional units of a product until its marginal utility (the increase in utility obtainable from one additional unit of the product) became level with to its price; and that a rational supplier would continue to offer additional units of a product until its marginal cost became level with the marginal revenue that he would get from selling it. The American economist, John Bates Clark, subsequently applied the concept to a market in which a rational employer would continue to hire labour until its marginal product became level with the prevailing wage rate.\n\nEquilibrium and the Price Mechanism\n\nThe concept of \"market equilibrium\" is central to the neoclassical model. Léon Walras[14] thought of it as the achievement of an imaginary auctioneer who adjusts a notional opening price in response to a succession of bids by buyers and sellers, and permits transactions to take place only when a price is reached at which buyers are willing to buy all that is offered for sale. That is the process of price determination by supply and demand which marks the abandonment of the concept of value-determined price, and which is examined in detail in Alfred Marshall's Economics and in Milton Friedman's Price Theory[15]. Walras, and subsequently the Italian economist Vilfredo Pareto [16], later developed the concept of a general equilibrium in which supply is equal to demand in every market in a closed economy. The normal assumption of neoclassical economics is that of a stable equilibrium to which the economy will automatically return after a disturbance. In such an economy, unemployment does not persist because any excess in the supply of labour, relative to its demand, is corrected by a reduction in wages.\n\nWelfare and Efficiency\n\nThe most politically influential of the contributions of the neoclassical economists was probably their development of the concept of welfare. In accordance with the precepts of representative government, they assumed the criterion for the success of an economic system to be the welfare of the individual, and they introduced the concept of economic efficiency as a measure of that success. Vilfredo Pareto took the lead in defining efficiency as a state in which no-one could be made better off without making someone worse off. The three types of efficiency were identified as productive efficiency (the production of good at minimum cost), allocative efficiency (the provision of the mix of goods that consumers want) and distributive efficiency (the distribution of the goods in such a way as to maximise individual welfare). That work laid the foundations for the subsequent development of the theory of welfare economics by Sir John Hicks and others. (The subject of economic welfare is discussed extensively in Arthur Pigou's Economics of Welfare [17], and the theorems of welfare economics are summarised in William Baumol's Economic Theory and Operations Analysis [18])\n\nCompetition\n\nThe theorems of welfare economics establish a presumption that allocative efficiency - that is to say that resources will be optimally allocated as between the production of alternative products - will be achieved under the hypothetical conditions of perfect competition. (Those conditions include the requirement that for each product there is no supplier large enough to influence prices, that all producers supply identical products, and that all consumers are well informed and behave rationally.) Despite the unreasonableness of those requirements, most economists advocate a presumption that restrictions upon competition will result in a reduction in efficiency . Those theoretical developments were the foundation for antitrust and other forms of competition policy, the economics and politics of which have been developed by George Stigler .\n\nThe theory of the firm\n\nThe tools of welfare economics were also used to develop the theory of the firm by Nicholas Kaldor of the London School of Economics in his Equilibrium of the Firm [19] and Ronald Coase in his \"The Nature of the Firm [20]. (Those theoretical developments have been summarised in William Baumol's Economic Theory and Operations Analysis [21]. An empirical study of the way firms actually behave is provided by Cyert and March's Behavioral Theory of the Firm [22])\n\nEconomic growth\n\nThere has been succession of attempts to create models of economic growth that identify the contributions of such factors as investment, productivity, innovation and institutional environment; and that explain the differences in growth experienced by different regions of the world. In the simple model proposed by Malthus in 1850, growth could not exceed population growth, but it was not long before it became evident that it was doing so. The Harrod-Domar model [23], and its successors, assume that there would be sufficient economic growth to enable some to go into growth-enhancing investments. In a later development, the 1956 Solow model [24] introduced the influence of the substitution of capital for labour that results from investment in improved capital equipment. Solow also pioneered the technique of growth accounting , which he used to estimate relative contributions to historical growth in the United States; and he identified an unexplained residual which he termed total factor productivity, the growth of which he attributed to technological change. Technological change was exogenous to the Solow model, in that it was not the consequence of factors that were represented in the model. As a result of subsequent research, notably that of Paul Romer [25] and Robert Lucas [26], some of the factors believed to influence technological change, such as expenditure on R&D and training, have since been embodied in the growth models, which are termed endogenous growth models. The most recent work on the subject has sought to identify the contributions to economic growth of institutional factors such as quality of governance, trust, and ethic diversity; and to explore its links with geographical factors and globalisation.\n\nKeynesian macroeconomics\n\nThe contribution of John Maynard Keynes\n\nThe most important contribution to economic thought by John Maynard Keynes was his examination of the factors determining the levels of national income and employment, and the causes of economic fluctuations. His major (and hard to read) work, the General Theory of Employment, Interest and Money, contains a sustained attack on much of the thinking of classical economics - mainly on the grounds that their postulates were unrealistic. His first target was Say's law of markets with its denial of the possibility of a general deficiency of demand. He challenged its implicit assumption that money is no more than a medium of exchange by drawing attention to the speculative motive for holding money. Secondly, he attacked the classical economists' contention that it was the interest rate that reconciled savings plans with investment plans, claiming that the level of savings was largely determined by the level of national income. Thirdly, he rejected the classical economists' assumption that any tendency for unemployment to rise would be corrected by a reduction in the general level of wages, substituting the contention that \"wages are sticky downward\". Having substituted his assumptions for those of his predecessors, he advanced the thesis that a deficiency of demand could occur if there was an excess of planned savings over planned investment, because such an excess could be removed only by a reduction in national income. The implication of that thesis was that the economy could settle down into a condition of high unemployment, lacking the self-righting mechanism envisaged by the classical economists.\n\nNeo-Keynesianism\n\nShortly after the publication of Keynes' General Theory, John Hicks published an article entitled \"Mr Keynes and the Classics\"[27], in which he produced a synthesis between the Keynesian and neoclassical models. Its main feature is the IS/LM diagram with its intersecting curves, one of which (Investment/Savings) relates the demand for savings to the interest rate, and the other (Liquidity/Money Supply) relates the demand for money to the interest rate - and in which the point of intersection of the two curves represents an equilibrium level of demand. (The IS/LM diagram subsequently came to be known as the Hicks-Hansen diagram in recognition of prior work by the American economist Alvin Hansen . The important feature of the synthesised model is that it can be made to depict behaviour in accordance with either the Keynesian model or the neoclassical model, depending upon what is assumed concerning the slopes of the two curves. In doing so it introduced a fundamental departure in the methodology of economics - a change from an exclusive reliance upon logical deduction from a priori postulates, to the increasing use of the inductive process of testing hypotheses against empirical evidence, that was made possible at the time by the comparatively recent practice of systematically collecting economic statistics. The work of a large body of economists was subsequently devoted to testing such hypotheses, using the mathematical technique known as \"econometrics\". That work does not appear to have resolved the controversy concerning the usefulness of the two models (except that some economists now acknowledge that one or the other seems to have worked better from time to time and in some countries' economies)\n\nPolicy Implications\n\nA Keynesian consensus dominated the economic policies of the developed countries for two or three decades following the second world war. Keynesian stabilisation policy required governments to counter downturns in demand by cutting taxes or increasing public expenditure. Since it takes some years for such actions to take effect, their timing had to be based upon forecasts using computerised economic forecasting models, but forecasting errors and misguided attempts to stimulate growth often had destabilising consequences. Measures that unwittingly stimulated demand at a time when an economy was operating at its full capacity, frequently gave rise to rising inflation - for which the only remedy appeared to be wage restraint - and the situation was sometimes exacerbated by the operation of foreign exchange policies. Opposition to those policy actions came from economists of the Austrian School, and from economists of the Chicago School whose thinking is described below.\n\nMonetarism and the Chicago School\n\nThe Chicago School\n\nThe University of Chicago School of Economics [28] has enjoyed a reputation for economic excellence since its foundation in 1892 However, the term Chicago School is usually taken to refer to the outlook and methodology of its economists during the period that started in the 1960s - including Milton Friedman, George Stigler, Ronald Coase, Robert Lucas, Cary Becker, Harry Johnson and Merton Miller, and to some like-minded economists in other universities. It is best known for its advocacy of monetarism but its economists have also made contributions on a wide range of other topics, including international trade, rational expectations and institutional economics. Their methodology embodies an approach, which philosophers term instrumentalist, that gives the predictive value of a theory priority over the representativeness of its assumptions [29]\n\nMonetarism\n\nThe quantity theory of money, which is often attributed to the economist Irving Fisher, but which undoubtedly had earlier origins, equated the volume of money in circulation multiplied by a notional \"velocity of circulation\". to the volume of physical output multiplied by its unit price (usually written as MV = PT). If the velocity of circulation were roughly constant, that would imply an association between inflation and growth in the money supply. Milton Friedman found that to have been the case during various periods in United States history [30], and that periods of monetary expansion had been followed by periods of inflation, although with long and variable time-lags. That led him to argue that Keynesian demand management would be ineffective in the long run because it would be accompanied by a damaging rise in the money supply; and that stability of demand and prices could better be achieved by control of the money supply. The controversy that followed was mainly concerned with the nature of the transmission mechanism (the question whether an excess of money would bid up the prices of goods, or whether it would be invested in interest-bearing bonds without affecting the prices of goods).\n\nA theory connecting the money supply and the balance of payments had previously been put forward by Harry Johnson when he was a professor of economics at Manchester University. The conventional view had been that the exchange rate is determined by the balance between the supply and demand of exports and imports, but Harry Johnson treated it as the relative price of the moneys in circulation in the two countries [31]. One of the implications of his theory is that if the exchange rate is fixed, the money supply cannot be controlled - which was a consideration that influenced the Chicago School's campaign to put an end to the system of fixed exchange rates then in operation. Another is that if the money supply is held constant, the balance of payments is self-correcting.\n\nExpectations\n\nMilton Friedman also attacked the thinking behind the Phillips curve (which had reflected the observation that inflation tended to fall when there was a rise in unemployment) on the grounds that it failed to take account of expectations. He proposed its replacement by the expectations-augmented Phillips curve [32], and used that construction to counter fears that a reduction in growth of the money supply would lead to a sustained increase in unemployment. To do so, he introduced the concept of the non-accelerating-inflation rate of unemployment (NAIRU), which is usually referred to as its natural rate, and which is the unemployment rate at which the expected inflation rate is the same as its actual rate. He argued that if a reduction in money supply growth caused unemployment to rise above its natural rate, the expected inflation rate would fall, setting in motion a sequence of events that would cause unemployment to revert to its natural rate. Conversely, a reduction in unemployment accompanying an increase in the money supply would cause an increase in expected inflation, prompting wage demands which would lead to an increase in actual inflation - a process which could continue indefinitely.\n\nApplying the concept of \"rational expectations\"[33] formulated by his former colleague, John Muth, to the operation of economic policy, Robert Lucas of the Chicago School put forward what has become known as the Lucas Critique[34] . He argued that policy actions tend to change people's expectations so that the same policy action could have future consequences that differ from the consequences that it had in the past. That possibility has fundamental implications for the construction of forecasting models, and the Lucas critique also raises the possibility that public reactions could frustrate the achievement of policy objectives.\n\nPolicy implications and outcomes\n\nThe Chicago School's prescription for stabilisation problem was confined to the control the money supply, and its prescription for the reduction of unemployment was to take measures to improve wage - and price flexibility. Concern for rising inflation, and the failure of attempts to control it by wage restraint, led to the widespread adoption of the first of those prescriptions in the late 1970s. In the United States, the Congress passed The Full Employment and Balanced Growth Act (known as the Humphrey-Hawkins Act) which required the Federal Reserve Bank to set one-year target ranges for money supply growth twice a year and to report the targets to Congress. In the United Kingdom, the Callaghan administration adopted a specific money supply objective: a practice that was enthusiastically adopted by its successor Thatcher administration. In both countries, attempts to keep the growth of the money supply within pre-set limits were generally unsuccessful (and in the United Kingdom, money supply growth actually increased [35]) and were eventually abandoned. Some central bankers have said that they take account of long-term money supply trends, but none consider control of the money supply to be a practicable instrument of stabilisation policy. Consensus monetary policy since the late 1980s uses interest rates as a means of stabilising both prices and output[36], and the median inflation rate in 13 industrialised countries has fallen from around 15 per cent in the mid 1970s and early 1980s to around 2 per cent in 2005[37].\n\nInstitutional Economics\n\nThe Institutionalist School\n\nThe term Institutionalist refers to economists who argue that economic activity cannot properly be understood except in the context of the public and social structure in which it takes place. That approach to the can be traced back to the German Historical School, which included Friedrich List and Max Weber, who is best known for his The Protestant Ethic and the Spirit of Capitalism. But the term is more commonly applied to the views of a pre-war group of American economists whose leading member was Thorstein Veblen - the man who coined the term conspicuous consumption - and whose lasting contributions were the collection of economic statistics and the study of business cycles.\n\nModern institutional economics\n\nA major contributor to the theory of institutional economics has been Ronald Coase, who summarised his approach in his 1991 Nobel Prize lecture [38]. Early in his career as an economist he had formulated what came to be known as the Coase Theorem which was the proposition that economic efficiency will be achieved provided that property rights are fully allocated and can freely be traded; a proposition which he developed further in his 1960 paper The Problem of Social Cost [39]. The development of institutional economics by economists at the University of Chicago has taken them across the conventional borders of economics into the disciplines of law, sociology and politics. (An extreme example has been the publication of the best-selling Freakonomics that was jointly authored by the Chicago economist Steven Levitt and the New York journalist Stephen Dubner, and which applies economic thinking to such questions as cheating, drug dealing and the connection between crime and abortion.)\n\nMechanism design theory\n\nA recent extension to institutional economics is concerned with how well different institutions and allocation mechanisms achieve goals such as welfare and private profit. Contributions to that subject by Leonid Hurwicz of the University of Minnesota, Eric Maskin of Princeton and Roger Myerson of Chicago earned them the 2007 Nobel Prize in Economics.\n\nPublic choice theory\n\nA different approach to the same questions [40] had previously been put forward under the heading of public choice theory, the principle contribution to which had been James Buchanan and Gordon Tullock's major treatise, The Calculus of Choice [41]. However, Buchanan and Tullock are best known for their analysis of the behaviour of politicians, civil servants and voters on the assumption that they are mainly motivated by personal gain, rather than a desire to serve the public interest.\n\nInternational economics\n\nThe gains from trade\n\nDavid Ricardo's law of comparative advantage - and its implication that trade restrictions are damaging to the interests of the country that imposes them - was the starting-point of the historical development of trade theory [42]. The subsequent theoretical developments of \"classical\" trade theory have mainly been attempts to create mathematical models of inter-country trade. The best-known of those was the Heckscher-Ohlin Theory [43], which deduced from a range of highly restrictive assumptions that a country will export those commodities that are intensive in the factor of production in which it is most well-endowed. That theory was extended by Paul Samuelson to conclude that, in the absence of productivity differences, trading between two countries would tend to equalise wages and capital costs in those countries. However, doubt was cast upon the relevance of the Heckscher-Ohlin theory by Wassily Leontief's discovery that the United States, which is the world's most capital-intensive country, had been exporting labour-intensive commodities and importing capital-intensive commodities. The general conclusion has been that international trade is mainly driven by factors other than labour-intensity and capital-intensity. \"Modern\" trade theory depends mainly upon the econometric analysis of international trade statistics,and has produced a range of findings concerning the influence of factors such as innovation and training.\n\nInfant industries\n\nThere was opposition in the early nineteenth century to the proposition that trade restrictions reduce welfare from a small group of economists, including Friedrich List of the German Historical School, who argued that free trade should not be permitted until the government had taken the measures necessary to establish the country's \"productive powers\". That was the precursor of the argument for infant-industry protection that was politically influential in the early twentieth century and which led to the introduction of the Smoot-Hartley system of industrial tariffs in the United States. It has been given recent expression in Ha-Joon Chang's book Kicking Away the Ladder [44] which suggests that industrial successes in Britain and the United States (and later in creating an automobile industry in South Korea) were attributable to the fact that they were protected from overseas competition until they were large enough to benefit from economies of scale. The mainstream reaction among economists concedes that the case for free trade does not take account of the benefits of scale economies, and that welfare gains from temporary trade restrictions might in principle be possible if a government were sufficiently successful in \"picking winners\" but that tax incentives and subsidies are more effective than tariffs [45] .\n\nGlobalisation\n\nGlobalisation is seen by most economists as contributing to economic welfare by promoting competition and the division of labour. But there are exceptions. Professor Joseph Stiglitz [46] [47] of the Columbia Business School has advanced the infant industry case for protection in developing countries and criticised the conditions imposed for help by the International Monetary Fund [48]. And Professor Dani Rodrik of Harvard[49] has noted that the benefits of globalisation are unevenly spread, leading to income inequalities that, in his view, lead to damaging losses of social capital, and to the migration of labour causing social stresses in receiving countries [50]\n\nFinancial economics\n\nOverview\n\nEconomists and professional investors gave little attention to financial economics until the adoption in the 1970s of models based upon the efficient markets hypothesis. That hypothesis was the basis of risk analysis using the assumption that price variations on the markets for financial assets could be treated as random variations, which could be represented by established probability distributions. The international financial industry made use of the models to select investments that were predicted to give the best return for a stipulated level of risk. It was not until the 2008 financial crisis that it was widely recognised that the efficient market hypothesis was no more than a statement of a general tendency, and that additional risks could arise from statistically unpredictable patterns of investor conduct.\n\nThe finance market\n\nThe study of financial economics had its origin in a 1900 thesis entitled Theorie de la Speculation by the French mathematician Louis Bachelier [51], according to which price fluctuations in a speculative market are analogous to the Brownian Movement of physics (the random walk of statistics theory), such that there is no combination of prices that offer the prospect of a certain gain. In 1933, the American economist Alfred Cowles[52] developed a similar thesis, which he published in a paper entitled Can Stock Market Forecasters Forecast?. According to Cowles' efficient market hypothesis, all of the available information that was relevant to an asset's prospects would already be embodied in its price (so that the answer to his question was \"no\"). The hypothesis depended upon the assumptions that most traders behave rationally, and that the activities of the others are mutually cancelling. Those assumptions were widely accepted, and on their basis, financial markets were taken to be essentially stable. Hyman Minsky's 1986 financial instability hypothesis, which suggested that financial markets are apt to become unstable after a period of sustained economic growth, received little attention at the time. A number of mathematical models of finance markets based upon the efficient markets hypothesis were developed in the course of the 20th century and were widely applied as guides to investment, but financial economics was then considered by most of the economics profession to be a specialised subject of little general interest, regarding the financial system as a collection of secondary markets whose internal characteristics do not affect the rest of the economy.\n\nPortfolio and asset price theory\n\nA sequence of Nobel Prize-winning advances concerning the problem of getting the best return from an investment without exceeding a chosen level of risk, occurred during the period from the 1950s to the 1970s. The sequence started in the late 1950s, when James Tobin [53] and Harry Markowitz laid the foundations of modern portfolio management. In his \"Separation Theorem\", Tobin proposed a two-stage process in which the required risk ceiling could be maintained by mixing risky and riskless assets, and Markowitz demonstrated the benefits of a diversified portfolio in which the prices of it assets would not rise and fall together, using the statistical concept of covariance. In 1970, William Sharpe[54] applied that concept to the tendency of the price of an asset to rise and fall in concert with the all-share index, assigning the title \"Beta\" to its mathematical definition, and used it to derive a pricing method know as the Capital Asset Pricing Model, and in 1973, Fischer Black [55] and Myron Scholes [56] developed the Black-Scholes model which made use of the fact that the expected volatility of an asset is reflected in its price in the options market, which led to the development by Robert Merton [57] of the \"Contingency Claims Analysis\" method of pricing assets.\n\nCorporate finance\n\nDuring the same period there was a sequence of advances in the economics of corporate finance. It started with the demonstration by Franco Modigliani [58] and Merton Miller [59] that shareholders should be indifferent to the level of a corporation's debts provided that it was possible to repay them costlessly with money available at a riskless rate of interest. Other economists subsequently augmented the Modigliani-Miller theory with allowances for the effects of taxation and of information asymmetry.\n\nRecent developments\n\nThe Greenspan era\n\nDivergences of view about economic management persisted into the early 21st century, but a consensus developed among those responsible for the management of the major economies, along the lines of a speech by the then United States Federal Reserve Board Chairman, Alan Greenspan[60]. The use of Keynesian fiscal policy to regulate output was considered to have proved ineffective and inflationary, and monetarist attempts to control the money supply were seen to have been unsuccessful. The new rôle of fiscal policy was the maintenance of fiscal stability, responsibility for the management of the economy had become the exclusive function of monetary policy, and monetary policy was confidently expected to prevent serious interruption to economic growth (the President of the American Economic Association had declared that \"The central problem of depression-prevention [has] been solved, for all practical purposes\"[61]). The financial system was considered to be essentially stable, making financial regulation unnecessary.\n\nThe conclusion of the era was marked by Alan Greenspan's 2008 congressional testimony:\n\n\"In recent decades, a vast risk management and pricing system has evolved combining the best insights of mathematicians and finance experts supported by major advances in computer and communications technology. A Nobel prize was awarded for the discovery of the pricing model that underpins much of the advance in the derivatives markets. This modern risk management paradigm held sway for decades. The whole intellectual edifice, however, collapsed in the summer of last year.\"[62]\n\nThe shortcomings of economic theory in that respect have been held [63] to have played a major role in the the financial crisis of 2008.\n\nPost-Great Recession thinking\n\nThe financial crisis of 2008 and the resulting Great Recession prompted much re-thinking of economic theory. Professor Shin of Princeton University reported that the \"race is on\" to add a new perspective to macroeconomics by the incorporation into it of a new theory of financial economics[64], and there was new thinking about the use of financial regulation to reduce the risk of fresh financial shocks. A re-examination of the rôle of fiscal policy had been triggered among economists and politicians by a 2008 proposal by Britain's Gordon Brown for a coordinated fiscal stimulus to counter the expected recessionary effects of the financial crisis. The idea was dismissed as ineffective by some economists[65][66], and as inflationary by others [67], and it was rejected by Germany's Angela Merkel[68] and ridiculed by her finance minister as \"crass Keynesianism\"[69] Although fiscal stimulus packages were implemented during the recession of 2009, they were not sustained by European governments to support the faltering recovery in 2010, and programmes of fiscal contraction were widely introduced in 2011. The main reason that was given for that reversal of fiscal policy was the fear that operators in the bond market would lose confidence in governments' ability to service the levels of public debt that their continuation would involve. The European Union's Fiscal Compact (which places mandatory restrictions upon the use of fiscal policy by its signatories) may gain political approval, but its economic consequences are likely to remain a matter of controversy. Unlike the European governments, the United States government has not introduced a major programme of fiscal contraction, and the Congress has not been able to agree on a plan for the reduction of the government's budget deficit[70]. A controversy also remains unresolved concerning the merit of techniques known as quantitative easing by which central banks seek to increase the money supply in order to relieve credit crunches and stimulate economic activity[71][72].\n\nThe history of economic thought has taken an unexpected turn, and a new consensus on economic management has not yet emerged."
    }
}