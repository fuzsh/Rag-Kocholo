{
    "id": "dbpedia_8277_1",
    "rank": 42,
    "data": {
        "url": "https://medium.com/%40manoranjan.rajguru/building-a-task-execution-engine-with-llm-279ec88f0157",
        "read_more_link": "",
        "language": "en",
        "title": "Building a Task Execution Engine with LLM",
        "top_image": "https://miro.medium.com/v2/resize:fit:1200/0*McWog01xvpz7x0eM.jpg",
        "meta_img": "https://miro.medium.com/v2/resize:fit:1200/0*McWog01xvpz7x0eM.jpg",
        "images": [
            "https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:88:88/1*PEvOeJ3WVmFKlia9zfdvjg.jpeg",
            "https://miro.medium.com/v2/resize:fill:144:144/1*PEvOeJ3WVmFKlia9zfdvjg.jpeg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Manoranjan Rajguru",
            "medium.com",
            "@manoranjan.rajguru"
        ],
        "publish_date": "2023-09-23T06:45:17.208000+00:00",
        "summary": "",
        "meta_description": "In an era of rapid digital transformation, automation and efficiency are key drivers of success. Whether you’re managing complex workflows, handling repetitive tasks, or orchestrating various…",
        "meta_lang": "en",
        "meta_favicon": "https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19",
        "meta_site_name": "Medium",
        "canonical_link": "https://medium.com/@manoranjan.rajguru/building-a-task-execution-engine-with-llm-279ec88f0157",
        "text": "In an era of rapid digital transformation, automation and efficiency are key drivers of success. Whether you’re managing complex workflows, handling repetitive tasks, or orchestrating various processes, a well-designed Task Execution Engine can be a game-changer. In this article, we’ll explore how you can harness the power of Large Language Models (LLMs) to build a versatile and intelligent Task Execution Engine.\n\nWhat is a Task Execution Engine?\n\nBefore diving into the technical aspects, let’s clarify what a Task Execution Engine is. It’s a software component designed to automate, schedule, and manage tasks or processes. These tasks can range from simple data processing to complex business workflows. Task Execution Engines are invaluable in reducing manual labor, ensuring consistency, and enhancing productivity.\n\nThe Role of Large Language Models (LLMs)\n\nLLMs, such as GPT-3, GPT-4, or similar models, have gained significant attention in recent years due to their ability to generate human-like text and perform natural language understanding tasks. Leveraging LLMs in a Task Execution Engine can lead to more intelligent, context-aware, and flexible automation.\n\nLets start with the implementing the same.\n\nLets define the model and load environmental variable.\n\nfrom openai import AzureOpenAI, OpenAI\n\nimport openai\n\nfrom dotenv import load_dotenv\n\nload_dotenv('azure.env')\n\nimport os\n\nfrom openai import OpenAI\n\nfrom promptflow.tracing import start_trace\n\n# instrument OpenAI\n\nstart_trace()\n\nclient = AzureOpenAI(api_version=\"2024-03-01-preview\",\n\nazure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n\nazure_deployment='gpt-4-1106-preview')\n\ndef llm(user_input):\n\nresponse = client.chat.completions.create(\n\nmodel='gpt-4-1106-preview',\n\nmessages=[\n\n{'role': 'user', 'content': user_input}\n\n],\n\ntemperature=0,\n\nstream=False,\n\n#stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n\n)\n\nreturn response.choices[0].message.content# a ChatCompletion request\n\nIf you are using Local LLM you can just use Ollama like below.\n\nfrom langchain_community.llms import Ollama\n\nmodel = Ollama(model=\"llama3\")\n\ndef llm(user_input):\n\nreturn model.invoke(user_input)\n\nThen we will define the Tool. In this case we are doing to use a Python Tool which will execute a code provided by LLM.\n\nfrom langchain_experimental.tools import PythonAstREPLTool\n\nfrom colorama import Fore\n\nimport re\n\nclass PythonREPL:\n\ndef __init__(self):\n\nself.local_vars = {}\n\nself.python_tool = PythonAstREPLTool()\n\ndef run(self, code: str) -> str:\n\ncode = extract_code_from_block(code)\n\noutput = str(self.python_tool.run(code))\n\nif output == \"\":\n\nreturn \"Your code is executed successfully\"\n\nelse:\n\nreturn output\n\npython_repl = PythonREPL()\n\ndef get_tool_info(tool_name):\n\ntools = {\n\n\"python\": {\"type\": \"tool\",\n\n\"name\": \"python\",\n\n\"use\": \"Use this to execute python code. Display your results using the print function.\",\n\n\"input\": \"Input should be a valid python code. Ensure proper indentation\",\n\n\"function\": python_repl.run},\n\n}\n\nreturn tools[tool_name]\n\ntools = []\n\nvalue_dict = {}\n\ntools_description = \"\\n\\nYou can use the following actions:\\n\\n\"\n\nchoice = 'python'\n\ntools.append(choice)\n\ntool_info = get_tool_info(choice)\n\ntools_description = tools_description + \"Action Name: \" + tool_info[\"name\"] + \"\\nWhen To Use: \" + tool_info[\"use\"] + \"\\nInput: \" + tool_info[\"input\"]\n\ntools_description = tools_description + \"\\n\\n\"\n\nvalue_dict[choice] = tool_info[\"function\"]\n\nvalue_dict\n\nNext we will define our logic to implement the task engine. This basically based on the concept of React prompting technique. This method prompts the LLM to generate both verbal reasoning traces and actions in an interleaved manner, which allows the model to perform dynamic reasoning. Importantly, the authors find that the React approach reduces hallucination from CoT. However, this increase in groundedness and trustworthiness, also comes at the cost of slightly reduced flexibility in reasoning steps\n\ndef run(content, instruction):\n\ncontent = content.replace('<<instruction>>', instruction)\n\ncount = 0\n\nwhile(True):\n\ncount = count + 1\n\nif count > 5:\n\nraise ValueError(\"Too many steps\")\n\n#print(Fore.BLUE + content)\n\noutput = llm(content)\n\noutput = output.replace(\"\\nObservation:\", \"\")\n\nprint(Fore.MAGENTA + output)\n\nregex = r\"Action\\s*\\d*\\s*:(.*?)\\nInput\\s*\\d*\\s*:[\\s]*(.*)\"\n\nmatch = re.search(regex, output, re.DOTALL)\n\nif \"Final Answer:\" in output and not match:\n\nbreak\n\nprint(output.split(\"Final Answer:\")[1])\n\nif \"Step\" not in output:\n\nprint(Fore.YELLOW + \"The model didnt output a step.\")\n\noutput = \"Please follow the format Step/Reason/Action/Input/Observation\"\n\ncontent = content + \"\\n\" + output\n\ncontinue\n\nif \"Reason\" not in output:\n\nprint(Fore.YELLOW + \"The model didnt output a reason.\")\n\noutput = \"Please follow the format Step/Reason/Action/Input/Observation\"\n\nmessages = content + \"\\n\" + output\n\ncontinue\n\nif output.count(\"Input\") > 1:\n\nprint(Fore.YELLOW + \"The model went crazy.\")\n\noutput = \"Please go one step at a time.\"\n\ncontent = content + \"\\n\" + output\n\ncontinue\n\nif not match:\n\nprint(Fore.RED + \"The model was sidetracked.\")\n\noutput = \"You are not following the format. Please follow the given format.\"\n\nmessages = [{\"role\": \"user\", \"content\": content + \"\\n\" + output}]\n\ncontinue\n\naction = match.group(1).strip().lower()\n\nif action not in tools:\n\noutput = f\"Invalid Action. Your action should be one of {tools}.\"\n\nprint(Fore.YELLOW + \"The agent forgot his tools.\" + output)\n\ncontent = content + \"\\n\" + output\n\ncontinue\n\naction_input = match.group(2)\n\nmatch = re.search(r\"Step (\\d+): (.*)\", output)\n\nstep_number = int(match.group(1)) + 1\n\nobservation = value_dict[action](action_input)\n\nprint(Fore.GREEN + \"\\nObservation: \" + str(observation))\n\noutput = output + \"\\nObservation: \" + str(observation)\n\ncontent = content + \"\\n\" + output\n\nSo lets formulate our prompt template. Here I have asked the LLM to first generate each step and correct if any issue occured during previous step in the next step.\n\ncontent = \"\"\"You can use the following actions:\n\nAction Name: python\n\nWhen To Use: When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution\n\nseconds.\n\nInput: Input should be a valid python code. Ensure proper indentation\n\nAcomplish the task in steps. If you get error in previous step fix it in the current step. Use the following format:\n\nStep 1: The first step\n\nReason: Reason for taking this step\n\nAction: the action to take, should be one of ['python'].\n\nInput: the input to the action\n\nObservation: the result of the action\n\nStep 2: The second step\n\nReason: Reason for taking this step\n\nAction: the action to take, should be one of ['python'].\n\nInput: the input to the action\n\nObservation: the result of the action\n\n... (this Step/Reason/Action/Input/Observation repeats for all steps)\n\nOnce you have completed all the steps, your final answer should be in the format:\n\nFinal Answer: I have completed all the steps\n\nBegin\n\n<<instruction>>\n\n\"\"\"\n\nWe are good !! Now we require two more functions to extract the code block and fix if any errors in the code using LLM.\n\ndef extract_code_from_block(response):\n\nif '```' not in response:\n\nreturn response\n\nif '```python' in response:\n\ncode_regex = r'```python(.+?)```'\n\nelse:\n\ncode_regex = r'```(.+?)```'\n\ncode_matches = re.findall(code_regex, response, re.DOTALL)\n\ncode_matches = [item for item in code_matches]\n\nreturn \"\\n\".join(code_matches)\n\ndef fix_error(code, result):\n\ncount = 0\n\nwhile \"Your code has the following error.\" in result:\n\nerror = result.replace(\"Your code has the following error. Please provide the corrected code.\", \"\")\n\nuser_input = f\"\"\"Here is the Code and the Error.\n\nCode:\n\n{code}\n\nError:\n\n{error}\n\nFix the given using the following format:\n\nExplanation: Explain the error in the code\n\nCorrected Code: Put the Corrected Code here\"\"\"\n\nprint(Fore.RED + \"Code needs some correction.\\n\" )\n\ncode = llm(user_input)\n\ncode = code[code.rfind('Corrected Code:') + len(\"Corrected Code:\"):]\n\ncode = extract_code_from_block(code)\n\nprint(Fore.CYAN + \"Corrected Code.\\n\" + code)\n\nresult = python_repl.run(code)\n\nprint(Fore.BLUE + \"Result.\\n\" + result)\n\ncount += 1\n\nif count > 5:\n\nraise ValueError(\"Too many steps\")\n\nprint(Fore.GREEN + \"Code has been corrected.\\n\" + code)\n\nreturn result\n\nSo we are finally completed all the steps to perform a task execution engine using LLM.\n\ndef execute(instruction):\n\nreturn run(content,instruction)\n\nYou can define a set of task and ask LLM to perform the same.\n\ncommand = \"\"\"print the glimpse of iris.csv.\n\nPreprocess the data before trainig the model.\n\nTrain a random forest model to predict the Species column.\n\nSave the classification report in result.txt\"\"\"\n\nexecute(command)\n\nYou will get the output like below\n\nStep 1: The first step\n\nReason: To print a glimpse of the iris.csv dataset\n\nAction: python\n\nInput: import pandas as pd\n\ndata = pd.read_csv('iris.csv')\n\ndata.head()\n\nObservation:\n\nStep 1: The first step\n\nReason: To print a glimpse of the iris.csv dataset\n\nAction: python\n\nInput: import pandas as pd\n\ndata = pd.read_csv('iris.csv')\n\ndata.head()\n\nObservation: Id SepalLengthCm SepalWidthCm PetalLengthCm PetalWidthCm Species\n\n0 1 5.1 3.5 1.4 0.2 Iris-setosa\n\n1 2 4.9 3.0 1.4 0.2 Iris-setosa\n\n2 3 4.7 3.2 1.3 0.2 Iris-setosa\n\n3 4 4.6 3.1 1.5 0.2 Iris-setosa\n\n4 5 5.0 3.6 1.4 0.2 Iris-setosa\n\nStep 2: The second step\n\nReason: Preprocess the data before training the model\n\nAction: python\n\nInput: data.drop(['Id'], axis=1, inplace=True)\n\nObservation:\n\nStep 2: The second step\n\nReason: Preprocess the data before training the model\n\nAction: python\n\nInput: data.drop(['Id'], axis=1, inplace=True)\n\nObservation: Your code is executed successfully\n\n.\n\nStep 3: The third step\n\nReason: Train a random forest model to predict the Species column\n\nAction: python\n\nInput: from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\n\nmodel.fit(data, data['Species'])\n\nObservation:.\n\nStep 3: The third step\n\nReason: Train a random forest model to predict the Species column\n\nAction: python\n\nInput: from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\n\nmodel.fit(data, data['Species'])\n\nObservation: ValueError: could not convert string to float: 'Iris-setosa'\n\nStep 4: The fourth step\n\nReason: Convert the Species column to numeric values\n\nAction: python\n\nInput: data['Species'] = data['Species'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n\nObservation:\n\nStep 4: The fourth step\n\nReason: Convert the Species column to numeric values\n\nAction: python\n\nInput: data['Species'] = data['Species'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n\nObservation: Your code is executed successfully\n\nStep 5: The fifth step\n\nReason: Train the random forest model again\n\nAction: python\n\nInput: from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\n\nmodel.fit(data, data['Species'])\n\nObservation:\n\nStep 5: The fifth step\n\nReason: Train the random forest model again\n\nAction: python\n\nInput: from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\n\nmodel.fit(data, data['Species'])\n\nObservation: RandomForestClassifier()\n\nis successfully trained\n\nStep 6: The sixth step\n\nReason: Save the classification report in result.txt\n\nAction: python\n\nInput: from sklearn.metrics import classification_report\n\nwith open('result.txt', 'w') as f:\n\nf.write(classification_report(data['Species'], model.predict(data)))\n\nObservation: is successfully trained\n\nStep 6: The sixth step\n\nReason: Save the classification report in result.txt\n\nAction: python\n\nInput: from sklearn.metrics import classification_report\n\nwith open('result.txt', 'w') as f:\n\nf.write(classification_report(data['Species'], model.predict(data)))\n\nObservation: Your code is executed successfully\n\nFinal Answer: I have completed all the steps"
    }
}