{
    "id": "dbpedia_8277_3",
    "rank": 89,
    "data": {
        "url": "https://sebastianraschka.com/blog/2015/writing-pymle.html",
        "read_more_link": "",
        "language": "en",
        "title": "Writing 'Python Machine Learning'",
        "top_image": "https://sebastianraschka.com/images/favicons/favicon-32x32.png",
        "meta_img": "https://sebastianraschka.com/images/favicons/favicon-32x32.png",
        "images": [
            "https://sebastianraschka.com/images/logos/ahead-of-ai-icon.png",
            "https://sebastianraschka.com/images/logos/twitter-bw.jpg",
            "https://sebastianraschka.com/images/logos/linkedin-bw.jpg",
            "https://sebastianraschka.com/images/logos/ahead-of-ai-icon.png",
            "https://sebastianraschka.com/images/logos/ahead-of-ai-icon.png",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/pymle_cover.jpg",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/engineer_syllogism.png",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/constraints.png",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/manuals.png",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/24h_day.jpg",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/fieldnotes.jpg",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/mindmap.png",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/is_it_worth_the_time.png",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/plain-gtd-1.png",
            "https://sebastianraschka.com/images/blog/2015/writing-pymle/plain-gtd-2.png",
            "https://sebastianraschka.com/images/logos/ahead-of-ai-icon.png",
            "https://sebastianraschka.com/images/books/pyml4-cover.jpg",
            "https://sebastianraschka.com/images/books/2023-ml-ai-beyond.jpg",
            "https://sebastianraschka.com/images/books/llms-from-scratch-cover.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Sebastian Raschka"
        ],
        "publish_date": "2015-09-24T10:00:00+00:00",
        "summary": "",
        "meta_description": "I'm Sebastian: a machine learning & AI researcher, programmer, and author. As Staff Research Engineer Lightning AI, I focus on the intersection of AI research, software development, and large language models (LLMs).",
        "meta_lang": "en",
        "meta_favicon": "/images/favicons/apple-touch-icon.png",
        "meta_site_name": "Sebastian Raschka, PhD",
        "canonical_link": "https://sebastianraschka.com/blog/2015/writing-pymle.html",
        "text": "Itâs been about time. I am happy to announce that âPython Machine Learningâ was finally released today! Sure, I could just send an email around to all the people who were interested in this book. On the other hand, I could put down those 140 characters on Twitter (minus what it takes to insert a hyperlink) and be done with it. Even so, writing âPython Machine Learningâ really was quite a journey for a few months, and I would like to sit down in my favorite coffeehouse once more to say a few words about this experience.\n\nISBN-10: 1783555130\n\nISBN-13: 978-1783555130\n\nPaperback: 454 pages, ebook\n\nPackt Publishing Ltd. (September 24th, 2015)\n\nOver time, several people asked me what this book was all about and how I found the time to â¦ (1) write it, (2) read all these interesting articles that I post on twitter, (3) do research, (4) relax and enjoy my life, â¦ Technically, I could summarize point no. 1 in one sentence: I believe that all tech books a written more or less in leisure time. I figured that I could âjustâ cut down on hobby coding projects and blogging for a few months to make this work.\n\nWrite what you know. That should leave you with a lot of free time.\n\nâ Howard Nemerov\n\nYou donât agree? Maybe my little bag of productivity tricks can convince youâif you are interested, more on that later. First, let me tell you a bit more about the book.\n\nSections\n\nâPython Machine Learning?â - What Is This All About?\n\nWhere We Are Going With This Book\n\nWhat This Book Is About and What It Is Not\n\nQuicklinks\n\nA Cover That May or May Not Make Sense\n\nSo, I Decided to Write a Book\n\nTime for Credits\n\nMy Productivity Hacks That Are Not for Everyone\n\nGrowing Ideas on Paper\n\nPlaintext-GTD to Keep Me Sane\n\nThanks!\n\nâPython Machine Learning?â - What Is This All About?\n\nIt all started with my good intentions of compiling a useful reference for the aspiring machine learning practitioner. Okay, âPython Machine Learningâ turned out to be quite a tome, but writing wasnât the actual issue here. Quite the contrary, if you are passionate about a topic, you could go on and on and on. The real challenge was to draw the line!\n\nNow, âwhatâs so exciting about machine learning and Python so that you decided to devote almost all of your free-time to it?â If all my posts on our favorite social networking sites havenât convinced you yet, I guess I am left with no alternative but to say it with someone elseâs words:\n\nWe live in the midst of a data deluge. According to recent estimates, 2.5 quintillion (1018) bytes of data are generated on a daily basis. This is so much data that over 90 percent of the information that we store nowadays was generated in the past decade alone. Unfortunately, most of this information cannot be used by humans. Either the data is beyond the means of standard analytical methods, or it is simply too vast for our limited minds to even comprehend.\n\nThrough Machine Learning, we enable computers to process, learn from, and draw actionable insights out of the otherwise impenetrable walls of big data. From the massive supercomputers that support Googleâs search engines to the smartphones that we carry in our pockets, we rely on Machine Learning to power most of the world around usâoften, without even knowing it.\n\nAs modern pioneers in the brave new world of big data, it then behooves us to learn more about Machine Learning. What is Machine Learning and how does it work? How can I use Machine Learning to take a glimpse into the unknown, power my business, or just find out what the Internet at large thinks about my favorite movie? All of this and more will be covered in the following chapters authored by my good friend and colleague, Sebastian Raschka. [â¦]\n\nâ Dr. Randal S. Olson (excerpt from the Foreword)\n\n(Source: https://xkcd.com/1570/)\n\nGranted, machine learning is quite hot these days for various reasons, but âwhy Python?â My short answer is that it is an intuitive and productive environment that is âcapableâ on so many levels. Talking âproductiveâ, I think was just about to start straying from the current debate for a second, and I hope you donât mind if delegate this discussion to my previous post, Python, Machine Learning, and Language Wars. A Highly Subjective Point of View.\n\nTechnology is nothing. Whatâs important is that you have a faith in people, that theyâre basically good and smart, and if you give them tools, theyâll do wonderful things with them.\n\nâ Steve Jobs\n\nWhere We Are Going With This Book\n\nâIs this book any different from other books about Python and machine learning?ââthere are quite a few out there by now. I believe so! When the publisher asked me for the first time, I politely declined the offer since there were already a couple of books out there that cover these topics. Well, after I declined, I reconsidered after I got the chance to read through some of those. I donât want to say that other books are better or worse, however, what Iâve seen was a little bit different from what Iâd have in mind for a machine learning book with practical Python examples.\n\n[â¦] So, with machine learning computers program themselves, itâs a bit like the scientific method except that it being done by a computer, and itâs on steroids because itâs much faster and can deal with a lot more data.\n\nâ Pedro Domingos (excerpt from an interview with Pedro Domingos on his new book: A Master Algorithm in Machine Learning Could Change Everything)\n\nThere are great books out there that focus on the machine learning theory. Some of my favorite books among them are C. Bishopâs Pattern Recognition and Machine Learning and Pattern Classification by Duda, Hart, and Stork. These books are great, really great. I think there is no need to write something similar. However, although they are considered as âintroâ books, they can be pretty hard on beginners in this field. Although I would really recommend them to everyone who is serious about machine learning, I would rather tend to recommend it as part of the âfurther readingâ section rather than a first machine learning book. Anyway, I think that implementing and tinkering with machine learning algorithms along with reading the theory is probably the way to get the best bang for your buck (=time) in this field.\n\nThen, there are books that very practical and read like a * documentation (* insert scikit-learn, Vowpal Wabbit, caret or any other ML library/API here). I think that these are good books too, but I also think that detailed discussions about libraries should be left to the (online) library documentation itself where it can be kept up to date and serve as a reliable, interactive reference.\n\nThere are three rules for writing a novel. Unfortunately, no one knows what they are.\n\nâ W. Somerset Maugham\n\nMy goals for a book were the three essentials building blocks: (1) explaining the big picture concepts (2) augmenting these with the necessary math intuition, and (3) providing examples and applications. The big picture helps us to connect all the different pieces, and the math is required to understand what is going on under the hood and helps us to outmaneuver the common pitfalls. The practical examples definitely help benefit the learning experience. Lastly, itâs really important that we get our hands âdirty,â that is, writing code that puts the learned material into action. We want to understand the concepts, but eventually, we also want to use them for real-world problem solving.\n\n(Source: https://xkcd.com/1045/)\n\nThroughout this book, we will make use of various libraries such as scikit-learn and Theano among others, which are efficient and well-tested tools that we would want to use in our âreal-worldâ applications. However, we will also implement several algorithms from scratch. This helps us to understand these algorithms, to learn how the libraries work, and to practice implementing our own algorithmsâsome of them are not part of scikit-learn, yet.\n\nWhat This Book Is About and What It Is Not\n\nThis book is not a âdata scienceâ book. It is not about formulating hypotheses, collecting data, and drawing conclusions from the analysis of novel and exotic data sets; the focus is on the machine learning. However, besides talking about different learning algorithms, I think that it is very important to discuss the other aspects of a typical machine learning and model building pipeline starting with the preprocessing of a data set. We will cover topics such as dealing with missing values, transforming categorical variables into machine-learning suitable formats, selecting informative features, and compressing data onto lower dimensional subspaces. There is a full chapter on model evaluation discussing hold-out cross-validation, k-fold cross-validation, nested cross-validation, hyperparameter tuning, and different performance metrics. As a little refresher, I also added a chapter about embedding machine learning models into a web application to share it with the world.\n\n(Source: https://xkcd.com/1343/)\n\nThis is not yet just another âthis is how scikit-learn worksâ book. I aim to explain how Machine Learning works, tell you everything you need to know in terms of best practices and caveats, and then we will learn how to put those concepts into action using NumPy, scikit-learn, Theano, and so on. Sure, this book will also contain a decent amount of âmath & equations,â and in my opinion, there is no way around it if we want to get away from the âblack box thinking.â However, I hope I managed to make it really easy to follow so that it can be read by a person who doesnât have a strong math background. Many parts of this book will provide examples in scikit-learn, in my opinion, the most beautiful and practical machine learning library.\n\nHereâs a quick chapter overview:\n\n01 - Machine Learning - Giving Computers the Ability to Learn from Data\n\n02 - Training Machine Learning Algorithms for Classification\n\n03 - A Tour of Machine Learning Classifiers Using Scikit-Learn\n\n04 - Building Good Training Sets â Data Pre-Processing\n\n05 - Compressing Data via Dimensionality Reduction\n\n06 - Learning Best Practices for Model Evaluation and Hyperparameter Optimization\n\n07 - Combining Different Models for Ensemble Learning\n\n08 - Applying Machine Learning to Sentiment Analysis\n\n09 - Embedding a Machine Learning Model into a Web Application\n\n10 - Predicting Continuous Target Variables with Regression Analysis\n\n11 - Working with Unlabeled Data â Clustering Analysis\n\n12 - Training Artificial Neural Networks for Image Recognition\n\n13 - Parallelizing Neural Network Training via Theano\n\nGitHub Repository for general info and code examples\n\nLiterature References & Resources for Further Reading\n\nLinks to the ebook and paperback versions at Amazon.com, Amazon.co.uk, Packt, Apple iBooks, and Google Books\n\nSample chapter\n\nThanks for the nice feedback so far!\n\nErrata\n\nAs for the Errata, I was thinking about how to turn something negative like little annoying typos and other errors into something more positive. I am going to reward each error with a small donation to UNICEF USA, the US branch of the United Nations agency for raising funds to provide emergency food and healthcare for children in developing countries. So, if you are interested in reading this book, and if you should find some mishaps in this first edition, please let me know! I will keep the list up to date here.\n\nPaperbacks and E-books\n\nUnfortunately, I canât say much about the different e-book versions since I havenât seen them, yet. Personally, I prefer to read technical books in paperback format or PDF over ePub or Amazon Kindle. I know that the digital version at Packt includes PDF, ePub, and Mobi formats, but I am not sure about Amazon though. I havenât bought a non-fiction e-book at Amazon, yet, but I believe it is Mobi only?\n\nIn any case, you can get the code examples (mostly in IPython notebook format) from the publisherâs website no matter whether you got the book from there or not (access to the code examples requires a quick registration though). However, for your convenience, I will also upload the code examples to the GitHub repository shortly!\n\nA Cover That May or May Not Make Sense\n\nWhat do you think about the cover? I remember that a neuroscientist asked me why there were neurons on the cover. A fair question and ample ammunition for an epic discussion that could rival the best programming language and text editor wars. The publisher seems to be into architecture and nature. When I was presented with the initial collection of about 20 stock images, the best I could find was some glass roof of a city hall somewhere in Poland. It was a really nice picture but as a book cover, hm, but as a book cover? So when we later added about 200 extra pages to the âinitialâ final draft, the publisher took the liberty to present me with a whole new cover. I didnât get to choose this time, but hey, I liked itâitâs so much better than the previous cover.\n\nThere are books of which the backs and covers are by far the best parts.\n\nâ Charles Dickens (Oliver Twist)\n\nAnyway, I think that neurons are quite fitting overall if you think back of the origins of machine learning (which I briefly introduce in the second chapter). It all started when W. S. McCulloch and W. Pitts proposed the McCulloch-Pitt (MCP) Neuron, a first model of how a neuron in a mammalâs brain could work (A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4):115â133, 1943). This was followed by one of the early ML algorithms, the perceptron (F. Rosenblatt. The perceptron, a perceiving and recognizing automaton. Project Para. Cornell Aeronautical Laboratory, 1957). Soon thereafter, we had our Adaline (adaptive linear neuron) based on gradient descent optimization (B. Widrow. Adaptive âAdalineâ neuron using chemical âmemistorsâ. Number Technical Report 1553-2. Stanford Electron. Labs., Stanford, CA, October 1960). About the same time, researchers started connected these single learning units to powerful multi-layered network architectures, replacing linear by non-linear cost functions.\n\nThis is the brief story how the multi-layer perceptron came to life sometime in the midst of the 20th century.\n\nNo matter how much the biological brain and artificial neural networks eventually have in common, we and at least say that the former is kindling spark and namesake of the latter. And yes, understanding and using concepts from biological information-processing pipelines is still a hot topic in modern research for inventing and improving upon machine learning algorithms!\n\nI am in the camp that believes in developing artificial neural nets that work really well and then making them more brain-like when you understand the computational advantages of adding an additional brain-like property.\n\nâ Geoff Hinton (from his Reddit AMA)\n\nSo, I Decided to Write a Book\n\nYes, that it happened back in March 2015, I reconsidered the inital offer by the publisher and eventually decided to write this book. I know, half a year sounds there was plenty of time, but â¦\n\nA Day Only Has 24 Hours After All\n\nOf course, I had to do the math first: There a always too many things I have and want to do, how does âwriting a bookâ fit into my (24h) day?\n\nSure, pie charts are considered âevilâ by data visualization experts, but since this is a very rough estimate at best, I found it quite fitting in this context. First and foremost, my day is centered around 8h of work/research. Moreover, I canât imagine a life without spending time with friends and/or family. Sure, sleeping sounds like the most boring task, but it is (still) quite necessary. And while machine learning is eating the software world, I also need my breakfast, lunch, and dinner time. To stay sane, I really need my daily walk to work or some exercise like soccer, and there is the occasional coffee break to keep the creative juices flowing.\n\nThere is only one kind of shock worse than the totally unexpected: the expected for which one has refused to prepare.\n\nâ Mary Renault (The Charioteer)\n\nLastly, how can I call it a day without drifting off in the fictional world of a good book before I go to sleep? Now, that leaves myself with roughly three hours of writing a day, sometimes more, sometimes less. Even if push comes to shove, donât you dare to think about carving out precious hours from your good nightâs sleepâhere, I feel guilty on many occasions.\n\nYour time is your life. You are absolutely the final authority on how you will use it.\n\nâ Anne Katherine\n\nEven though I had this queasy feeling that I may have missed something in my pie chartâhey come on, itâs a pie chart after all, what do you expectâI was also pretty enthusiastic about getting a chance to write about my favorite topic(s). So, the initial chapter proposal was ready beginning of April. This was just a rough idea of the 10 chapters I wanted to write about, a bunch of headlines accompanied by short summaries. Next, I had roughly two weeks per chapter to put it down on paper. The challenging part was that the book was supposed to be 180 - 230 pages long for the format (an âEssentialsâ book) that the publisher had in mind.\n\nWriterâs block is a fancy term made up by whiners so they can have an excuse to drink alcohol.\n\nâ Steve Martin\n\nLater, it turned out that I had largely underestimated how much (time and) space it takes to write a chapter. Initially, I put down 20 pages per chapter in my outline-proposal, but later it ended up being ~25 pages. And those are 25 pages after aggressive shortening! It sounds somewhat paradoxical, but having to think carefully about the sections and paragraphs I could remove without turning the book into a resource that raises more questions than it answers was the real challenge here! Good news is that after I handed in the last chapter in July, the publisher really liked the book and granted me some extra pages; this resulted in a 454 page book eventually. Of course, I could and wanted to write so much more, but you have to draw the line somewhere, right?!\n\nThere is no real ending. Itâs just the place where you stop the story.\n\nâ Frank Herbert\n\nIn any case, to get the initial draft together, I had to reach deep into my box of productivity tricks and habits that I accumulated over the years. They are surely not useful for everyone, maybe they are not useful to anyone, but if you are interested, I can write a little about these later.\n\nTime for Credits\n\nI really want to thank all the people who were involved in this project as reviewers and editors. It was a great experience, and I am happy to have such exceptional assistance at my side!\n\nDr. Vahid Mirjalili. I can truly say that Vahid is one of the best friends and colleagues one can have. Vahid is not only an exceptional reviewer, but his professional career is truly impressive and inspiring! Starting with aerospace engineering, winning the two most recent, worldwide competitions for protein structure prediction and refinement with his group (CASP 2012 and 2014), Vahid is now busy working on the next big thing: Using Big Data and Cloud Computing to help researchers in the bio-sciences on their next breakthrough. And by the way, he was actually the one who convinced me to write this book after I have blown off the first request by the publisher.\n\nDmytro Taranovsky. What a great reviewer! His feedback was really outstanding. I donât want to imagine how this book would look like without his help!\n\nDr. Randal S. Olson. Randy, a good friend, a great colleague, and also an endless source of inspiration. Randy is not yet another Machine Learning and Artificial Intelligence researcherâif youâve seen his data visualization blog you probably know what I am talking about. Thanks for the nice Foreword, Randy!\n\nOne problem with writing technical books about the topics you are really excited about is that you are so into it and forget the outsiderâs perspective. Thus, I was happy to have Richard Dutton on board to help me simplify all these sections rich in technical jargon.\n\nActually, all the reviewers were really invaluable during this process. Think of ensemble learning methods, a committee of experts! Thanks Dave Julian and Hamidreza Sattari!\n\nA special thanks goes to Jason Wolosonovich. Although Jason was not part of the initial âreview crew,â he sent me tons of nice and motivational feedback when he was reading the final draft along with a comprehensive list of typos that slipped through the copy-editing stage.\n\nLastly, I was really impressed with Riddhi Tuljapurkarâs patience; she was the âContent Development Editorâ of this book. Well, despite all the deliberate planning, I have to admit that I missed a deadline here and there, and it was just nice to have such a nice and understanding person on the other side. Thanks!\n\nMy Productivity Hacks That Are Not for Everyone\n\nI think thatâs all I wanted to say, but do you remember the âproductivityâ hacks I mentioned earlier? I had about three hours a day reserved for writing, and a little more on weekends. Thatâs actually not that much when it comes to writing a book, and there were a few old habits of mine that may or may not have been helpful during this process. Read on if you are interested.\n\nGrowing Ideas on Paper\n\nWell, ideas come at strange times at strange places. Most often it happens on my walk to/from work.\n\nOne always has a better book in oneâs mind than one can manage to get onto paper.\n\nâ Michael Cunningham\n\nAlthough I have a car and could technically drive to work to save an hour a day for the back and forth, I really enjoy a nice walk during the warmer times of the year; itâs also a great way to âreadâ some booksâI mean listening to audio books of course! Nevertheless, I always have this worn-out notebook in my back pocketâideas come at strange times at strange places.\n\nYet, writing down those random thoughts doesnât make a book. I am not sure if it is a blessing or burden, but my German genes like the process of deliberate planning. Here is just a short three-stage checklist that I (try) to use for all kinds of writing.\n\n1. Outline & Create\n\nmindmap for ideas\n\nwrite the headings\n\nadd sub-headings if appropriate\n\nwrite paragraph headings (can be deleted later)\n\nadd keywords to each paragraph\n\ninsert references for further information to limit the scope\n\ncreate/insert figures that help explaining complicated concepts\n\nYour intuition knows what to write, so get out of the way.\n\nâ Ray Bradbury\n\nMind maps are a classic, but it really works! When I start a new topic, I just sit down for a few minutes put all the crazy thinks that come into a mind map format as spontaneously as possible. Writing about topics such as machine learning is an extremely challenging task, because all the concepts are connected and intertwined. Connecting them in a mind map is intuitive and easy, and I would worry about putting them into a linear format (for instance, a written chapter) later.\n\nI typically use software for that since it is a 2-step process for me. The second step includes reordering, cleaning it up, and making additions here and there. Eventually, I end up with a main mind map of topics that I want to cover. Next, I think about the headings and so forth.\n\nAn Image is worth more than 1000 words! What may sound like yet another hollow phrase is also something I really believe in. Creating illustrative images of the most complex concepts truly helps both the writer and the reader!\n\n2. Write & Rewrite\n\nflesh out the paragraphs (quickly); donât worry about the grammar\n\nre-read the whole text and change the organization if necessary\n\nthe introduction should address the âwhy should I care?â question\n\nprovide a roadmap at the beginning before diving into details\n\nre-read and re-write, and re-read and re-write â¦\n\nuse some objects in the text (metaphors) to explain tricky concepts\n\nItâs no good to get bogged down in the nitty-gritty details at the early stages of a draft. Fixing grammar and spelling, and worrying about the sentence structure is probably the biggest trap and time sink. Eventually, we may end up removing or changing most of it later anyway. There is no reason to be embarrassed about bad style, metaphorically speaking, write with the âdoor shut.â\n\n3. Double-Check & Finalize\n\nremove jargon that is inappropriate for the audience\n\nmake sure all mathematical symbols are defined\n\nmake sure that all important figure elements are described in the text\n\nif you are using algorithms and models by other people, ensure they are credited\n\n(remove informalities (donât -> do not))\n\nremove redundancies / duplications / repetitions\n\nprefer active voice over passive\n\nshorten lengthy sentences\n\nsubstitute some adverbs by action verbs\n\ncheck for correct comma usage\n\ncheck for correct semicolon usage\n\ncheck for correct usage of parentheses\n\ncheck for correct usages of dashes -\n\ncheck for correct usage of em dashes â\n\nrun your grammar & spelling checking tool\n\ncheck for consistent spelling, e.g., âdatasetâ vs. âdata setâ\n\ngive it a last one complete read before you pass it on to the reviewer\n\n3A. Plot specific\n\nUse color, shade or size in a scatter plot vs. 3D plots\n\nuse âplain Englishâ instead of variable names like âx[1]â on your plot axes\n\nmake sure that the graphs are readable by color blind people\n\nadd a scatter plot overlay when using box plots or bar plots\n\naxes in multi-panel plots are all on the same scale\n\nthe coloring is consistent for the same variables in different figures\n\n3B. Data science specific\n\ndescribe the purpose of the analysis before you analyze\n\ncause or lead to shouldnât be used in correlation analyses\n\nAfter the initial âoutliningâ stage, that is, when I think that the overall structure makes sense, itâs about time to apply some polish. Although it may look like overkill, I still like to use a checklist to make sure that I donât forget anything.\n\nHere is a lesson in creative writing. First rule: Do not use semicolons. They are transvestite hermaphrodites representing absolutely nothing. All they do is show youâve been to college. â Kurt Vonnegut (A Man Without a Country)\n\nPlaintext-GTD to Keep Me Sane\n\nI may disregard some pearls of wisdom from more elaborate studies about best practices here and there, but this is what works for me. I think that work flows are really person- and task-specific, so I wouldnât recommend you to take it too seriously, but maybe you will find one or the other useful in this section.\n\nMy favorite things in life donât cost any money. Itâs really clear that the most precious resource we all have is time.\n\nâ Steve Jobs\n\nThe key message is: Keep the future out of your head to make room for the present. In contrast to computer memory, which doubles every couple of years, our brainâs short-term memory is only capable of juggling 4 âthingsâ on average (or 7 depending on whom you ask). Unfortunately, we canât just simply buy more RAM for our biological motherboard, thus, it is important to reserve the precious storage space for the most important things.\n\nThe key lesson I got from David Allenâs GTD approach is to write things down. Thatâs why always carry a small pen and piece of paper or paper notebook. Sometimes I also just use my smartphone to compose a quick email to myself with the thought in the subject lineâespecially if the âitemâ is really important since my email inbox is something that I check at least twice a day. While I am at my computer, I simply keep an __inbox__ directory and an __inbox__.txt file where I can dump the stuff that I want to take a look at later as it happens. It goes without saying that cleaning out those paper, email, and digital inboxes once or twice a day is mandatory if you want to make sure that nothing slips through the cracks. These âinbox thingsâ eventually end up in either one of these locations: My ToDo-list, my notes directory, or the trash.\n\n(Source: https://xkcd.com/1205/)\n\nWhen it comes to my ToDo-list, I keep it plain and simple. Just type âGTD todoâ into your favorite web search engine and you will find a fast amount of tools that have been developed for these purposes. Well, I tried several of those over the years, but I wasnât happy with either of them. The price tags for stand alone software and/or monthly subscriptions aside, they never really clicked with me for long. Most of them come with convenient bells and whistles yet all of them have their quirks. Remember, organizing your ToDos is one thing, but actually doing them is what it is all about!\n\nI am really not a big fan of proprietary formats when it comes to my project and task management. I want to be flexible and somewhat independent of the platform developer. Take Evernote for example, I was a heavy user a couple of years ago. Even though it comes with somewhat useful export features, I can tell you that it is quite a hassle to transfer your data from one tool into the other. I constantly have this uneasy feeling that if I use a proprietary tool, I invariably need to be prepared for the worst-case scenario; the time when this tool is not supported anymore will certainly come sooner or later (The First Dead Unicorn is Already Here, You Just Donât Know It Yet).\n\nAnd just by the way: Most of the bells and whistle can be a distraction anyways. Remember, organizing your to dos is one thing, but actually doing them is what is important!\n\nThe most important aspect of ToDo lists is to check your items off! Yes! Checking tasks off is truly satisfactory, just striking a golf ball with a club on the teeing ground. Ye goode olde paper ToDo list is really great for that purpose. I like paper, but I am also into digital logging and keeping things. I use a simple text expansion tool with a shortcut ( ddate) that gets expanded to the current date (2015-09-24), which use to check off the tasks of my plaintext ToDo list. Yes, I use a simple text file to stay organized. It just works (for me)! This is accompanied by a simple 150liner written in Python as my task management tool, letâs call it plaintext-gtd.py.\n\nAt the end of the day, I simply execute plaintext-gtd.py from my terminal, and all my completed tasks are moved into a todolog.txt file for future reference, and I have a brief summary of my daily productivity printed in the terminal for reflection. If these tasks were part of a bigger project, this gets checked off as well, and I get to see a motivational quote as a reward. Since I keep all of that in Dropbox, it is available across all my computers, and I donât have to worry about platform-specific workarounds.\n\nSince my little helper tool is tailored to my personal needs and probably not very intuitive to other people, I recommend checking out taskwarrior, which offers a more mature version of this idea.\n\nThanks!\n\nThis article certainly became longer than I intended it to be. You probably didnât read all of it, but I hope that you at least skipped forward to this last section! Beause I really want to say âThank you!â I believe that without the great communities that evolved around machine learning, Python, and machine learning in Python, I would have never found the motivation to write such a book. Python and machine learning are immensily useful in my everyday life and exciting topics for sure. Yet, sharing this passion with other people is a whole different level. The informative resources we share on social media platforms and the interactions with the âmachine learningâ and âdata scienceâ communities â¦ Itâs great to be part of it!\n\nA big thanks also goes to scikit-learn, one of the greatest open-source efforts I have ever seen. It is really a pleasure to work with the people who are involved in this project. All these efforts that went into creating, improving, and maintaining this project for us machine learning practitioners merit deep and absolute respect."
    }
}