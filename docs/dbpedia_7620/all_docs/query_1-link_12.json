{
    "id": "dbpedia_7620_1",
    "rank": 12,
    "data": {
        "url": "https://www.academia.edu/115251456/A_Review_on_Music_Genre_Classification_Methods",
        "read_more_link": "",
        "language": "en",
        "title": "A Review on Music Genre Classification Methods",
        "top_image": "http://a.academia-assets.com/images/open-graph-icons/fb-paper.gif",
        "meta_img": "http://a.academia-assets.com/images/open-graph-icons/fb-paper.gif",
        "images": [
            "https://a.academia-assets.com/images/academia-logo-redesign-2015-A.svg",
            "https://a.academia-assets.com/images/academia-logo-redesign-2015.svg",
            "https://a.academia-assets.com/images/single_work_splash/adobe.icon.svg",
            "https://0.academia-photos.com/attachment_thumbnails/111713269/mini_magick20240222-1-9munef.png?1708593234",
            "https://0.academia-photos.com/64525554/16772444/38453502/s65_international_journal_of_scientific_research_in_computer_science_engineering_and_information_technology.ijsrcseit.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loaders/paper-load.gif",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "International Journal of Scientific Research in Computer Science, Engineering and Information Technology IJSRCSEIT",
            "Information Technology IJSRCSEIT",
            "technoscienceacademy.academia.edu"
        ],
        "publish_date": "2024-02-22T00:00:00",
        "summary": "",
        "meta_description": "Music has become an important part in our life. We have an always evolving music industry, producing various songs each day. This study delves into the realm of music genre classification using machine learning techniques, acknowledging the pivotal",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": "https://www.academia.edu/115251456/A_Review_on_Music_Genre_Classification_Methods",
        "text": "With the recent upsurge in music consumption, music recommendation systems have gained substantial prominence. Platforms like Spotify are increasingly relied upon by users for curated music, underscoring the need for improved recommendation algorithms. While the analysis of user preferences and historical listening behaviours has conventionally been employed to tailor recommendations, these techniques are often restricted to examining textual data, such as lyrics and titles, thereby potentially limiting the effectiveness of the recommendations. The current study proposes a novel approach that extends beyond textual analysis to investigate the audio aspect of music, which directly influences listeners' emotions. This exploration encompasses the feature extraction and selection phases based on multi-models, contributing to robustness and interpretability, especially when contending with noise generated by the audio signal. Three distinct strategies for feature extraction and selection were incorporated, focusing on musical characteristics such as speed, rhythm, tonality, and signal changes. These strategies employed Librosa, PyAudio analyses, and Convolutional Neural Networks (CNNs) using the VGG16 model. Subsequently, features were classified to assess their efficacy and provide a preliminary evaluation of the proposed recommendation system. The system's personalisation was achieved by enabling users to select a piece of music, from which their preferences were extracted. The efficacy of this approach was validated through extensive experiments using the GTZAN dataset, comprising 10 distinct music genres with 100 audio files lasting 30 seconds each. Findings suggest that CNNs present a reliable method for generating personalised music recommendations, particularly for users with preferences for similar artists or diverse genres. Conversely, for users favouring a specific genre, Librosa appeared to provide a more effective means of achieving optimal recommendation accuracy. Therefore, this study illuminates new pathways for music analysis and classification, with the ultimate goal of enhancing understanding of the auditory world and improving the music recommendation experience for users.\n\nThis survey extensively studies music genre classification, a critical task in music information retrieval, to automatically categorize audio recordings into various genres. It provides a comprehensive review of approaches, methodologies, and recent advancements in genre classification from audio data. Scholars and practitioners in the field will find this study to be a valuable resource as it covers various aspects of the discipline, including feature extraction, classification methods, dataset exploration, evaluation metrics, and recent developments. The survey aims to enhance the understanding of music genre classification and foster further research and progress in the field by critically evaluating state-of-the-art techniques discussed in research papers, discussing their strengths and limitations, and providing a comprehensive overview of the field.\n\nThis review paper provides a comprehensive analysis of the advancements in COVID-19 cough audio classification through deep learning techniques. With the ongoing global pandemic, there is a growing need for non-intrusive and rapid diagnostic tools, and the utilization of audio-based methods for COVID-19 detection has gained considerable attention. The paper systematically reviews and compares various deep learning models, methodologies, and datasets employed for COVID-19 cough audio classification. The effectiveness, challenges, and future directions of these approaches are discussed, shedding light on the potential of audio-based diagnostics in the context of the current public health crisis.\n\nPlaying music through a digital platform that has a large database of songs requires automated classification of music genres, highlighting the need to develop a model for music genre classification that is more efficient and accurate. This study evaluated the hyperparameters in the music genre classification process using CNN in the GTZAN dataset with 30-second duration data optimized using MFCC feature extraction. The model that is formed with a time of 3 (three) seconds classifies music genres in the first 3 seconds of music. This model has a high potential for error because the first 3 seconds of initial music are varied and cannot be used as a benchmark in determining music genres. This study performed hyperparameters on batch size, epoch, and split data set variables with various scenarios. The highest precision result was obtained at 72% with a data split of 85%:15%, 32 batch sizes, and 500 epochs.\n\nThe paper encapsulates recognition of music genres by using convolution neural networks (CNNs). Three different approaches were considered for implementing the solution to the problem. The first approach is to extract Melspectrograms , second one is to extract MFCC plots and the last one is by plotting chroma STFT features of the audio files. The aim of this project work is to test the different audio features which are best suitable for such kinds of tasks.\n\nIn the modern scenario, everyone uses the internet to find music, movies, products, services and other commodities on a regular basis to make their lives easier. Because of a lot of data on millions of music, movie, products and services on websites, we need a recommender system very much to assist people in making decisions more quickly and easily. In this research study, we have developed an intelligent music recommendation system by integrating a Music Genre Classification (MGC) with different types of Deep Learning Techniques such as RNN-LSTM, GRU and CNN. We have used the GTZAN Genre dataset to training our system. We have extracted the features from GTZAN dataset by the help of Mel Frequency Cepstral Coefficients (MFCCs) then pass the MFCCs into our deep learning networks. After classifying the appropriate music genre, recommended the music from particular genre from the labelled database which has been classified by our system. From our proposed models the GRU, CNN and RNN-LS..."
    }
}