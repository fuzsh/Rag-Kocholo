{
    "id": "dbpedia_7620_2",
    "rank": 44,
    "data": {
        "url": "https://www.academia.edu/8837334/Continuous_Wavelet_Like_Transform_Based_Music_Similarity_Features_for_Intelligent_Music_Navigation",
        "read_more_link": "",
        "language": "en",
        "title": "Continuous Wavelet-Like Transform Based Music Similarity Features for Intelligent Music Navigation",
        "top_image": "http://a.academia-assets.com/images/open-graph-icons/fb-paper.gif",
        "meta_img": "http://a.academia-assets.com/images/open-graph-icons/fb-paper.gif",
        "images": [
            "https://a.academia-assets.com/images/academia-logo-redesign-2015-A.svg",
            "https://a.academia-assets.com/images/academia-logo-redesign-2015.svg",
            "https://a.academia-assets.com/images/single_work_splash/adobe.icon.svg",
            "https://0.academia-photos.com/attachment_thumbnails/35178169/mini_magick20190317-19332-qno9jv.png?1552824870",
            "https://0.academia-photos.com/19244422/5992518/6800108/s65_hadi.harb.jpg_oh_18c2d36f33911d889bc962d244ee7422_oe_54db4a9b___gda___1423098713_458925363eb2dfd35cac68a2421f7769",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loaders/paper-load.gif",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png",
            "https://a.academia-assets.com/images/loswp/related-pdf-icon.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Hadi Harb",
            "ec-lyon.academia.edu"
        ],
        "publish_date": "2014-10-17T00:00:00",
        "summary": "",
        "meta_description": "Continuous Wavelet-Like Transform Based Music Similarity Features for Intelligent Music Navigation",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": "https://www.academia.edu/8837334/Continuous_Wavelet_Like_Transform_Based_Music_Similarity_Features_for_Intelligent_Music_Navigation",
        "text": "The aim of this study is to evaluate a machine-learning method in which symbolic representations of folk songs are segmented and classified into tune families with Haar-wavelet filtering. The method is compared with previously proposed Gestaltbased method. Melodies are represented as discrete symbolic pitch-time signals. We apply the continuous wavelet transform (CWT) with the Haar wavelet at specific scales, obtaining filtered versions of melodies emphasizing their information at particular time-scales. We use the filtered signal for representation and segmentation, using the wavelet coefficients’ local maxima to indicate local boundaries and classify segments by means of k-nearest neighbours based on standard vector-metrics (Euclidean, cityblock), and compare the results to a Gestalt-based segmentation method and metrics applied directly to the pitch signal. We found that the wavelet based segmentation and waveletfiltering of the pitch signal lead to better classification accuracy...\n\nOne of the goals in the field of Music Information Retrieval is to obtain a measure of similarity between two musical recordings. Such a measure is at the core of automatic classification, query, and retrieval systems, which have become a necessity due to the ever increasing availability and size of musical databases. This paper proposes a method for calculating a similarity distance between two music signals. The method extracts a set of features from the audio recordings, models the features, and determines the distance between models. While further work is needed, preliminary results show that the proposed method has the potential to be used as a similarity measure for musical signals.\n\nABSTRACT The vast amount of music available electronically presents considerable challenges for information retrieval. There is a need to annotate music items with descriptors in order to facilitate retrieval. In this paper we present a process for determining the music genre of an item using the Discrete Wavelet Transform and a round-robin classification technique. The wavelet transform is used to extract time and frequency features that are used to classify items by genre.\n\nABSTRACT We develop a method for discovering the latent structure in MFCC feature data using the Hierarchical Dirichlet Process (HDP). Based on this structure, we compute timbral similarity between recorded songs. The HDP is a nonparametric Bayesian model. Like the Gaussian Mixture Model (GMM), it represents each song as a mixture of some number of multivariate Gaussian distributions However, the number of mixture components is not ���xed in the HDP, but is determined as part of the posterior inference process.\n\nIn recent years, the revenue earned through digital music stood at a billion-dollar market and the US remained the most profitable market for Digital music. Due to the digital shift, today people have access to millions of music clips from online music applications through their smart phones. In this context, there are some issues identified between the music listeners, music search engine by querying and retrieving music clips from a large collection of music data set. Classification is one of the fundamental problems in music information retrieval (MIR). Still, there are some hurdles according to their listener's preferences regarding music collections and their categorization. In this paper, different music extraction features are addressed, which can be used in various tasks related to music classification like a listener's mood, instrument recognition, artist identification, genre, query-by-humming, and music annotation. This review illustrates various features that can be used for addressing the research challenges posed by music mining."
    }
}