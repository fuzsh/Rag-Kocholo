{
    "id": "dbpedia_6734_3",
    "rank": 94,
    "data": {
        "url": "https://www.nature.com/articles/s41467-023-36741-4",
        "read_more_link": "",
        "language": "en",
        "title": "Surprising combinations of research contents and contexts are related to impact and emerge with scientific outsiders from distant disciplines",
        "top_image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41467-023-36741-4/MediaObjects/41467_2023_36741_Fig1_HTML.png",
        "meta_img": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41467-023-36741-4/MediaObjects/41467_2023_36741_Fig1_HTML.png",
        "images": [
            "https://pubads.g.doubleclick.net/gampad/ad?iu=/285/nature_communications/article&sz=728x90&c=-1018634836&t=pos%3Dtop%26type%3Darticle%26artid%3Ds41467-023-36741-4%26doi%3D10.1038/s41467-023-36741-4%26techmeta%3D129,139,141%26subjmeta%3D264,496,648,680,689,706%26kwrd%3DInstitutions,Interdisciplinary+studies,Research+management",
            "https://media.springernature.com/full/nature-cms/uploads/product/ncomms/header-7001f06bc3fe2437048388e9f2f44215.svg",
            "https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41586-022-05543-x/MediaObjects/41586_2022_5543_Fig1_HTML.png",
            "https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41562-022-01351-5/MediaObjects/41562_2022_1351_Fig1_HTML.png",
            "https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-020-71009-7/MediaObjects/41598_2020_71009_Fig1_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-36741-4/MediaObjects/41467_2023_36741_Fig1_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-36741-4/MediaObjects/41467_2023_36741_Fig2_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-36741-4/MediaObjects/41467_2023_36741_Fig3_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-36741-4/MediaObjects/41467_2023_36741_Fig4_HTML.png",
            "https://pubads.g.doubleclick.net/gampad/ad?iu=/285/nature_communications/article&sz=300x250&c=148026343&t=pos%3Dright%26type%3Darticle%26artid%3Ds41467-023-36741-4%26doi%3D10.1038/s41467-023-36741-4%26techmeta%3D129,139,141%26subjmeta%3D264,496,648,680,689,706%26kwrd%3DInstitutions,Interdisciplinary+studies,Research+management",
            "https://www.nature.com/static/images/logos/sn-logo-white-ea63208b81.svg",
            "https://www.nature.com/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg",
            "https://verify.nature.com/verify/nature.png",
            "https://www.nature.com/m2x0tzag/article/s41467-023-36741-4"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2023-03-24T00:00:00",
        "summary": "",
        "meta_description": "We investigate the degree to which impact in science and technology is associated with surprising breakthroughs, and how those breakthroughs arise. Identifying breakthroughs across science and technology requires models that distinguish surprising from expected advances at scale. Drawing on tens of millions of research papers and patents across the life sciences, physical sciences and patented inventions, and using a hypergraph model that predicts realized combinations of research contents (article keywords) and contexts (cited journals), here we show that surprise in terms of unexpected combinations of contents and contexts predicts outsized impact (within the top 10% of citations).&nbsp;These surprising advances emerge across, rather than within researchers or teams—most commonly when scientists from one field publish problem-solving results to an audience from a distant field. Our approach characterizes the frontier of science and technology as a complex hypergraph drawn from high-dimensional embeddings of research contents and contexts, and offers a measure of path-breaking surprise in science and technology. Here, using hypergraph modeling the authors show that surprising research (in terms of unexpected combinations of research contents and contexts) is associated with impact and arises from scientific outsiders solving problems in distant disciplines.",
        "meta_lang": "en",
        "meta_favicon": "/static/images/favicons/nature/apple-touch-icon-f39cb19454.png",
        "meta_site_name": "Nature",
        "canonical_link": "https://www.nature.com/articles/s41467-023-36741-4",
        "text": "To predict new innovations in science and technology, we develop a model that generates normal discoveries as combinations of prior knowledge28,29,30,31. Our model articulates a simple cognitive process: Scientists and inventors combine things together that are (1) scientifically or technologically close and (2) cognitively salient. While formally simple, this model is more effective than those from the literature and even advanced deep learning models in capturing surprise and impact (see SI for detailed comparisons). Following from this design, we model the likelihood that contents or contexts become combined in the future as a function of (1) their proximity in a latent embedding space derived from the complex network structure of prior relationship among contents and contexts and (2) their salience to scientists through prior usage frequency.\n\nSpecifically, we develop a generative hypergraph model that extends the mixed-membership stochastic block model32 into high-dimensions, characterizing complete combinations of contents and contexts (Fig. 1). The model (1) constructs a continuous embedding for nodes from the hypergraph of contents or contexts in a given year, (2) allows that embedding to evolve stochastically, then (3) draws a new hypergraph from the updated embedding, which forms our prediction for next year’s combinations in published articles33. This design allows us to predict which new combinations are expected to occur based on current trends in content and context. This, in turn, allows us to identify surprising combinations—those least likely according to our model—when they arise and forecast their impact (see “Methods” for details).\n\nIn this study, we apply our methodology to three major corpora of scientific knowledge and technological advance: 19,916,562 biomedical articles published between 1865 and 2009 from the MEDLINE database; 541,448 articles published between 1893 and 2013 in the physical sciences from journals published by the American Physical Society (APS), and 6,488,262 patents granted between 1979 and 2017 from the US Patent database (see “Methods” for details.) We operationalize research contents as keywords distilled within community-curated ontologies—Medical Subject Heading (MeSH) terms for MEDLINE papers, Physics and Astronomy Classification Scheme (PACS) codes for APS papers, and United States Patent Classification (USPC) codes for patents. We operationalize contexts as disciplinary journals and conferences referenced within a paper (or technology classes cited by a patent). For each dataset in each year we build a hypergraph of contents where each node corresponds to a content keyword and each hyperedge (a “link” between ≥2 nodes) to a research paper or patent that combines all such keywords. Meanwhile, for each dataset in each year we separately build a hypergraph of contexts where each node corresponds to a journal or conference (or major technological area for patents) and each hyperedge to a paper or patent that references these disciplinary contexts as sources of inspiration and influence.\n\nAcross biomedical sciences, physical sciences, and inventions, our model correctly distinguishes between a content combination that turned into a publication and a random combination more than 95% of the time for a given year when trained on data from previous years (Biomedicine: AUC = 0.98; Physics: AUC = 0.97; Inventions: AUC = 0.95). New context combinations are also predictable (Biomedicine: AUC = 0.99; Physics: AUC = 0.88; Inventions: AUC = 0.83). See “Methods” for detailed model evaluations. The successful prediction of future combinations suggests that our model inscribes a space of latent knowledge. Researchers tend to wander locally across this space in generating new papers and patents. This aligns with previous findings regarding inertia and conservative search in science24,34,35,36,37 and gives us further confidence in the model.\n\nWith a measure of what science and technology is expected, we can assess the novelty of a combination h as its improbability or surprisal38. Isofar as we model contents and contexts separately—a paper is simultaneously a combination of contents (e.g., curated keywords) and a combination of contexts (e.g., cited journals)—we also measure the content and context novelty of a paper separately corresponding to the suprisal of its content and context combinations, respectively.\n\nThe research our model identifies as surprising is perceived and labeled as groundbreaking by established scientists who review it for the Faculty Opinions platform—formerly Faculty of 1000 (facultyopinions.com), as detailed below (and in Supplementary Fig. 7 and SI). Surprising papers also achieve outsized impact. For example, the work of Grynkiewicz and colleagues39 defines a novel family of chemical compounds including Fura-2, discovered to be highly fluorescent and bind to free calcium. This was a surprising discovery—pulling diverse properties together that crossed traditional field boundaries with content and context novelties in the 99th percentile and receiving more than 16,000 citations to date. Research by Yanagisawa and colleagues40 isolated endothelin, one of the most potent vasoconstrictors at the time (1988), and employed several distinct, community spanning methods to examine its properties and mechanisms, discovering its potential as a modulator of ion channels. This discovery is in the 95th percentile of content and context novelty, receiving more than 14,000 citations since publication. By contrast, content and context novelties diverge in work by Altschul and others41, which lies in the 97th percentile of context novelty, but only the 15th percentile of content novelty. The work used a computer system to search protein and DNA databases and did not itself represent a surprising biomedical discovery, but produced a widely used tool sourced from across the computational and bio-sciences fields, making it one of the 15 most cited articles of all time42.\n\nSurprise relates to impact\n\nWe sytematically examine how surprise relates to citation impact and awards by dividing biomedical science (MEDLINE) papers into citation deciles and normalizing novelty scores, transforming them into percentiles. The decile-averaged content and context novelties increase significantly with citation decile, as shown in Fig. 2a, b. The same pattern is observed in physical science (APS) papers and patents (Supplementary Figs. 4 and 5). Further, Nobel prize-winning papers, which are all in the top 10% citation group, have lower-than-average context novelty, but high content novelty. Most general award-winning papers across Biology and Medicine lie in the top 10% of citations and follow the same pattern. This divergence between citations and awards for papers with high context novelty follows from the distinction in audience. Citations are conferred by all scientists who credit an advance, but awards are offered by disciplinary communities, which overvalue advances within their contexts and undervalue trans-disciplinary research that violates context boundaries43.\n\nThe probability of being a hit paper—in the top 10% of most cited papers published in the same year—increases monotonically with novelty percentile. For biomedical (MEDLINE) papers, those with the most surprising combinations of context are on average four times more likely to be a hit paper than random, surprising content combinations are two times more likely (Fig. 2c), and the most surprising content and context combinations are approximately five times more likely (Fig. 2d). These effects are amplified for super hits in the top 1% most cited papers (see Supplementary Fig. 6 and SI.) On average, nearly 50% of papers in the group of highest joint content and context novelties are hit papers, as shown in Fig. 2d. This predictive power outperforms other predictive models of hit papers in the literature. Moreover, it improves upon baseline models that predict impact with features—like content and context—available prior to publication (See SI for a detailed comparison.).\n\nContent versus context novelty\n\nBoth content and context novelties predict outsized impact, but they provide nearly independent information regarding the ongoing construction of scientific ideas and technological artifacts. The correlation between propensities for content and context combinations are low across biomedical science (MEDLINE: Pearson-r(5259751)<0.001, two-tailed p = 0.94), physical science (APS: Pearson-r(136274) = 0.03, two-tailed p < 0.001), and invention (USPatent: Pearson-r(2019493)<0.001, two-tailed p = 0.29). These findings suggest that our separation of content and context is necessary as they capture distinctive aspects of a scientific or technical advance. The experienced distinction between content and context novelty is reinforced by expert classifications of biomedical papers from the Faculty Opinions platform, in which selected publishing scientists post favorite papers (74% of which are hits) and annotate them with predefined tags including “New finding”, “New drug target”, “Technical advance”, “Interesting hypothesis”, and “Controversial”. When we consider papers selected and tagged by experts between 1990 and 2000, comparing against each other and all published papers from that period, we find that content novelty is most strongly and distinctively associated with New findings and Drug targets, while context novelty is most distinctively linked to Controversial, Interesting hypothesis and Technical advance (see Supplementary Fig. 7 and SI for details). These associations are above baseline, and distinct from one another. These associations provide support for our argument that novel content combinations yield legible advances within research fields, while novel context combinations generate field-violating controversy and surprise.\n\nDistinctions between science and technology\n\nResults for patents relate to those from the biological and physical sciences in ways that illuminate distinctions between institutions of scientific and technological advance. The most surprising patents are two times more likely to be hits than random (Supplementary Fig. 5), but context novelty possesses less predictive power for patents. Disciplinary boundaries are weaker in technology space, where patent examiners, unlike scientific reviewers, do not enforce them. The lack of discrete fields enables inventors to search more widely, but removes the signal from violations of context in the prediction of advance. When we calculate content similarity between cited journals and venues where citing papers are published (see “Methods” for details), we see that scientists cite contexts similar to their publishing venue 500% more intensively than contexts that are distant (Fig. 3a)44, presenting their work as if “standing on the shoulders” of likely reviewers45. Inventors of patented technologies cite distant sources with at least the same likelihood as those nearby. They are not reviewed by peers and present their work as if to highlight their novel distinction from neighboring work. Following from this difference, we find that the distribution of collective attention differs in science versus technology. We quantify the spread of attention with the normalized entropy of the number of publications containing each content node, shown in Fig. 3b. Keywords in the patent space receive more equal attention (higher entropy), while attention is more peaked and focused in biological and physical science.\n\nSources of innovation\n\nFinally, we assess sources of surprising advance in the form of surprising researchers, surprising research teams, and surprising research expeditions. A surprising scientist or inventor is one with an unexpected biography combining diverse research experiences. A surprising team is one comprising an unexpected combination of team members—scientists or engineers from an unusual collection of backgrounds. A surprising research expedition is one in which scientists or inventors travel from their disciplines an unexpected distance or direction to address problems framed by a distant audience. Using context embeddings, inscribed by journals and conferences, and Eq. 2, we quantify (1) career novelty for a scientist or engineer as the improbability or surprisal of the combination of contexts in which she has ever published, (2) team novelty by the surprisal of contexts brought together across team members’ publication histories, and (3) expedition novelty by the average distance between team members’ publishing backgrounds and the publication venue of their focal paper or patent (See “Methods” for formal definitions). Figure 4a shows that for biomedical (MEDLINE) papers the probability of being a hit paper increases gradually with career and team novelty, but expedition novelty rises more quickly as the strongest predictor.\n\nPapers representing the most surprising publication expeditions are 3.5 times more likely than random to be hit papers. Three-dimensional novelty distributions graphed in Fig. 4b also show that career and team novelties are correlated, suggesting that successful teams not only have members from multiple disciplines, but also members with diverse backgrounds who stitch interdisciplinary teams together. Successful knowledge expeditions (i.e., those that result in publications), however, are most correlated with breakthrough discovery. Figure 4b reveals how high expedition novelty in the absence of team and career novelty remains associated with an increased probability of hit papers. The pattern of effects in the physical sciences (APS) is consistent with those in the biomedical sciences (MEDLINE) with the association between expedition novelty and the probability of hit papers even more pronounced (Supplementary Fig. 8). These findings align with observations in the literature that creative researchers including Nobel laureates search across structural holes46,47, as well as literature on individual and team impacts48,49,50,51,52. This pattern is different for patents (Supplementary Fig. 9) where expedition novelty is not significantly associated with hits because (1) novelty is the primary basis of patent evaluation, (2) subfields are not enforced and, as a result, (3) expedition novelty is so frequent that it loses its value as a signal of outsized impact: its skewness is .61, nearly three times larger than in the life sciences (skewness 0.26) and the flipside of physics, where such expeditions are less common (−0.36).\n\nThere are no human or animal subjects involved in this study. According to the University of Chicago Social and Behavioral Sciences Institutional Review Board, the study “does not meet the definition of regulated human subjects research requiring review per 45 CFR 46.102(e)(1).”\n\nData\n\nThis work investigates three major corpora of scientific and technological knowledge: 19,916,562 papers published between 1865 and 2009 in biomedical sciences from the MEDLINE database, 541,448 papers published between 1893 and 2013 in physical sciences from all journals published by the American Physical Society, and 6,488,262 patents granted between 1979 and 2017 from the US Patent database (USPTO). The building blocks of content for those articles and patents are identified using community-curated ontologies—Medical Subject Heading (MeSH) terms for MEDLINE, the Physics and Astronomy Classification Scheme (PACS) codes for APS, and United States Patent Classification (USPC) codes for patents. Then we build hypergraphs of content where each node represents a code from the ontologies and each hyperedge corresponds to a paper or patent that realizes a combination of the nodes.\n\nWe acknowledge the potential conservative influence from using established keyword ontologies rather than all of the words from titles, abstracts or full-text of articles and patents. Nevertheless, we note that the ontologies we examine do evolve over time, with active additions following the concentration of research in a given area. Moreover, these ontologies allow us to use the community of authors (APS), annotators (MEDLINE), and examiners (USPTO) to crowdsource the disambiguation of scientific and technological terms. Future work may explore how words differ from keywords, especially in the emergence of new fields.\n\nMedline\n\nMEDLINE is the U.S. National Library of Medicine’s (NLM) bibliographic database. It contains abstracts, citations, and other metadata for more than 25 million journal articles in biomedicine and health, broadly defined to encompass those areas of the life sciences, behavioral sciences, chemical sciences, and bioengineering. The version of data used in this study contains 19,916,562 papers published between 1865 and 2009. Because coverage for papers prior to 1966 is limited, our main analysis focuses on papers published in and after 1966, but with pre-1966 papers as background information when predicting new content and context combinations. To allow the published papers to accumulate enough citations for assessing their impact, our novelty analysis focuses on papers published in and before 2000. In sum, all papers are used to estimate the hypergraph embedding model and 10,057,935 papers are used in the novelty analysis.\n\nMedical Subject Headings (MeSH) is the National Library of Medicine’s controlled terminology used for indexing articles in MEDLINE. It is designed to facilitate the determination of subject content in the biomedical literature. MeSH terms are organized hierarchically as a tree with the top-level terms (called headings) corresponding to major branches such as “Diseases” and “Chemicals and Drugs”, with multiple levels under each branch. Terms in the bottom level are the most fine-grained, detailed concepts associated with distinct biological phenomena, chemicals, and methods. We use the bottom-level terms from the three branches that are central to the biomedical field— “Diseases”, “Chemicals and Drugs”, and “Analytical, Diagnostic and Therapeutic Techniques and Equipment” (or methods for short)—as nodes in the hypergraphs of content of MEDLINE papers. Terms from the Diseases branch include conditions such as “lathyrism” and “endometriosis”; examples from the Chemicals and Drugs branch include “elastin”, “tropoelastin”, “aminocaproates”, “aminocaproic acids”, “amino acids”, “aminoacetonitrile”, and “amyloid beta-protein”; and examples from the Analytical, Diagnostic and Therapeutic Techniques and Equipment branch include “polyacrylamide gel electrophoresis”, “ion exchange chromatography”, and “ultracentrifugation”. NLM curators manually affix MeSH codes to papers as they are ingested into MEDLINE and made available through the popular PubMed platform.\n\nAPS\n\nThe APS dataset is released by the American Physical Society (APS). It contains 541,448 papers published between 1893 and 2013 in 12 physics journals: Physical Review, Physical Review A, B, C, D, E, I and X, Physical Review Special Topics - Acceler and Physics, Physical Review Letters, and Reviews of Modern Physics.\n\nThe dataset contains basic metadata for each paper including title, publication year, abstract, etc. It also contains the Physics and Astronomy Classification Scheme (PACS) codes associated with each paper. We use the PACS codes as nodes in hypergraphs of content to characterize APS papers. Similar to MeSH, PACS is also a hierarchical partition of the whole spectrum of subject matter in physics, astronomy, and related sciences. Example PACS codes include “Mathematical methods in physics”, which range from “Quantum Monte Carlo Methods” to “Fourier analysis”; “Instruments…” such as “Electron and ion spectrometers” and “X-ray microscopes”; “Specific theories…” like “Quark-gluon plasma” and “Chiral Langrangians”; and “...specific particles” ranging from “Baryons” to “Quarks”. Unlike MeSH codes, which are added by curators, PACS codes are affixed by authors to their own papers through the publishing process. The PACS codes were developed by the American Institute of Physics in 1970 and have been used by APS since 1975. Since PACS codes are not available for papers published before 1975 and the coverage of them in papers prior to 1980 is limited, our main analysis is restricted to APS papers published after 1980, but with the pre-1980 papers as background information when predicting new content and context combinations. To allow the published papers to accumulate enough citations for assessing their impact, our novelty analysis focuses on papers published in and before 2000. In sum, all papers are used to estimate the hypergraph embedding model and 148,786 papers are used in the novelty analysis.\n\nThe dataset only contains citations between the APS papers. In order to obtain external citations we query the Web of Science (WOS) database to collect all the journals cited by the APS papers. Particularly, in the WOS database we find all the papers published by the 12 APS journals, and then all the journals cited by those papers. The journals are then used as nodes in hypergraphs of context for the APS papers. In addition, we query the WOS database to collect the number of citations a paper receives for more accurate assessment of the paper’s impact.\n\nUS Patents\n\nThe US Patent dataset is released by the US Patent & Trademark Office (USPTO). It contains 6,488,262 patents published between 1976 and 2015. The dataset contains basic metadata for each patent such as title, publication year, USPC (United States Patent Classification) codes, etc. The USPC is a classification system used by USPTO to organize all U.S. patent documents and other technical documents into specific technology groupings based on common subject matter. The USPC is a two-layer classification system. The top layer consists of terms called classes, and each class contains subcomponents called subclasses. According to USPTO, a class generally delineates one technology from another and every patent is assigned a main class. As such, we use the class codes as nodes in the hypergraphs of context for patents. Subclasses delineate processes, structural features, and functional features of the subject matter encompassed within the scope of a class, and thus we use subclass codes as content nodes for the patents. In total, there are 158,073 subclass codes (content nodes) and 496 class codes (context nodes).\n\nTo allow the granted patents to accumulate enough citations for assessing their impact, our novelty analysis focuses on patents granted in and before 2000. In sum, all patents are used to estimate the hypergraph embedding model and 2,436,257 patents between 1976 and 2000 are used in the novelty analysis.\n\nNobel prize papers\n\nThe Nobel prize-winning papers are derived from the Nobel laureates dataset by Li et al.78, which contains publication histories of nearly all Nobel prize winners from the past century. However, the focus of that dataset is on the Nobel laureates, but our study focuses on award-winning papers. While it is relatively easy to find out the person who won a prize, it is hard to pinpoint the papers that contribute to the winning of the prize. Li et al. take a generous approach by including papers cited by Nobel lectures and papers published in the same period of one’s prize-winning work (while satisfying several inclusion criteria). This results in noise for our analysis as not every paper in their dataset is a prize-winning paper. As a conservative solution, for every Nobel laureate we take their most cited paper in the dataset and use only those papers as award-winning papers in our analysis. We acknowledge that a few Nobel prizes are attributed to an opus of work and this filtering process might miss a few relevant papers, but the most important (in terms of impact) paper for every prize is kept, with every paper representing an award-winning paper.\n\nGeneral award-winning papers\n\nIn Fig. 2, we compare the content and context novelty of our entire population of MEDLINE papers with those receiving awards. The general awards data is from Foster et al.25. They define award-winning papers as those authored by a scientist who won an international award or prize. They first created a large list of prizes by drawing from the category pages for biology awards, medicine awards, and chemistry awards in Wikipedia and then validated them with several biomedical scientists. Then they identified the winners of 137 different prizes and awards from biology, medicine, and chemistry. For each winner, if at all possible, they retrieved all papers written from 0 year to 30 years before the award was granted.\n\nFalse positives could be introduced due to mis-assignments of papers to awards. However, as these false-positive papers would be typical rather than award-winning, they likely behave like the majority of published papers and dilute the effect we report. False negatives are also possible if we missed papers published by certain award winners. For instance, papers written by authors with non-English characters in their names are underrepresented. These false negatives similarly dilute our estimate of the distinctiveness of award-winning papers. Our non-Nobel prize findings should therefore be viewed as a conservative estimate of the difference between prize winning papers and the pool of all papers. Still, we are able to identify that prize winning papers are significantly higher in content novelty than the average paper within a given citation decile, but that they are not systematically higher in context novelty, likely because awards are typically conferred by a single context—a journal, association, or field.\n\nHypergraph embedding model\n\nWe model discoveries and inventions as hypergraphs of contents and contexts with a combinatorial process that assembles previous concepts and technologies from prior papers or patents. Past research examining combinatorial discovery and invention has modeled only partial combinations, deconstructing new products into component pairs8,79 and resting on mature analysis tools for simple graphs, which define direct links between entities. Here we model science and technology as a complex hypergraph drawn from an embedding of research contents and contexts, where individual discoveries or inventions are rendered as complete sets of each. For a given hypergraph, whether composed of content or context nodes, the propensity of any combination of nodes to form a hyperedge is modeled as a product of two factors: proximity between nodes in the combination and their cognitive salience. Combinations with higher propensity will be more likely to turn into papers and patents, agreeing with the intuition that people tend to search locally and pursue trending topics.\n\nTo formalize this idea, each node i is associated with a latent vector θi that embeds the node in a latent space constructed to optimize the likelihood of observed papers and patents. Each entry θid of the latent vector denotes the probability that node i belongs to a latent dimension d, and thus \\({\\sum }_{d=1}^{D}{\\theta }_{{id}}=1\\). Dimensions underlying these latent vectors naturally recover scientific fields; see Supplementary Fig. 1. The complementarity between nodes in a combination h is modeled as the probability that those nodes belong to the same dimension, ∑d∏i∈hθid . This hypergraph embedding model can be understood as an extension of the mixed-membership stochastic block model32, which was designed for networks with only pairwise interactions.\n\nWe also account for each node’s cognitive availability because most empirical networks display great heterogeneity in node connectivity, with a few popular contents and contexts attracting the most attention—intensively drawn upon by many papers and patents. Previous work has shown that by integrating heterogeneity of node connectivity, the performance of community detection in real-world networks improves80. Accordingly, we associate each node i with a latent scalar ri to account for its salience, presumably tied with its overall connectivity in the network.\n\nAssembling these components, we model the propensity (λh) of combination h—our expectation of its appearance in actual papers and patents—as the product of proximity between nodes in h and their salience or visibility:\n\n$${\\lambda }_{h}=\\mathop{\\sum}\\limits_{d}\\mathop{\\prod}\\limits_{i\\in h}{\\theta }_{id}\\times \\mathop{\\prod}\\limits_{i\\in h}{r}_{i}.$$\n\nThen the number of publications or patents that realize combination h is modeled as a Poisson random variable with λh, the propensity of that combination, as its mean:\n\n$${X}_{h}\\sim {{Poisson}}\\left({\\lambda }_{h}\\right)$$\n\nAccordingly, the probability of observing a hypergraph G is the product of probabilities for observing all possible combinations:\n\n$$P\\left(G{{{{{\\rm{|}}}}}}\\Theta,R\\right)=\\mathop{\\prod}\\limits_{h\\in H}P\\left({x}_{h}{{{{{\\rm{|}}}}}}\\Theta,R\\right),$$\n\nwhere \\({x}_{h}\\) is the number of observed papers or patents that realize combination h and H is the set of all possible combinations. (Θ,R) denotes all unknown parameters:\n\n$$\\varTheta=\\left({\\theta }_{1},...,{\\theta }_{n}\\right){{{{{\\rm{and}}}}}}\\,R=\\left({r}_{1},...,{r}_{n}\\right).$$\n\nFinally, we model a time sequence of hypergraphs \\(\\left({G}^{1},...,{G}^{T}\\right)\\) as the output of a Hidden Markov Process on latent parameters \\(\\varTheta,R\\):\n\n$$ P\\left({G}^{1},...,{G}^{T}{{{{{\\rm{|}}}}}}{\\varTheta }^{1},..,{\\varTheta }^{T},{R}^{1},...,{R}^{T}\\right)=P\\left({G}^{1}{{{{{\\rm{|}}}}}}{\\varTheta }^{1},{R}^{1}\\right)\\\\ \\mathop{\\prod }\\limits_{t=2}^{T}P\\left({\\varTheta }^{t},{R}^{t}{{{{{\\rm{|}}}}}}{\\varTheta }^{t-1},{R}^{t-1}\\right)P\\left({G}^{t}{{{{{\\rm{|}}}}}}{\\varTheta }^{t},{R}^{t}\\right),$$\n\nwhere time is indexed by the superscript \\(t\\), and the transition density \\(P\\left({\\varTheta }^{t},{R}^{t}|{\\varTheta }^{t-1},{R}^{t-1}\\right)\\) is a Gaussian density.\n\nGiven articles published by a certain year T, we estimate parameters \\(\\left({\\varTheta }^{1},...,{\\varTheta }^{T},{R}^{1},...,{R}^{T}\\right)\\) by maximizing the likelihood function above via stochastic gradient descent. Then the model enables us to predict combinations in year T + 1. However, even with stochastic gradient descent, model estimation is still computationally challenging due to the vast space of possible combinations. We address issues in the estimation process as follows.\n\nFirst, the space of possible combinations is exponentially large (on the order of \\({2}^{n}\\)), and it is computationally prohibitive to go over all possible combinations even with stochastic gradient descent. However, it is rare for large combinations to turn into hyperedges, and hence, we restrict the set of possible combinations to include only combinations no larger than the largest hyperedge observed.\n\nSecond, because the real hypergraphs are sparse, the sets of hyperedges and non-hyperedge combinations are exceedingly unbalanced with the number of hyperedges to be on the order of n but the number of non-hyperedge combinations on the order of \\({n}^{D}\\)(where D is the size of the largest hyperedge). We employ a widely used approach in machine learning, negative sampling, to address this imbalance issue. Specifically, in each iteration of the training (optimization) process, we randomly sample as many non-hyperedge combinations as hyperedges to construct balanced hyperedge and non-hyperedge sets. Negative sampling effectively changes the objective function we optimize. The original objective function can be rewritten as \\({\\log P}\\left({G|}\\theta,R\\right)={\\sum }_{h\\in E}\\log P\\left({x}_{h}|\\theta,R\\right)+{\\sum }_{h\\in \\bar{E}}\\log P\\left({x}_{h}|\\theta,R\\right)\\), where E is the set of hyperedges and \\(\\bar{E}\\) is the set of non-hyperedge combinations. Negative sampling turns the second term in the objective function into a random function \\(X={\\sum }_{h \\sim P\\left(h\\right)}\\log P\\left({x}_{h}|\\theta,R\\right)\\) where h is randomly drawn from \\(\\bar{E}\\). This random function is a biased estimator of the original objective. To illustrate the bias, assuming the simplest case of stochastic gradient descent where we draw 1 negative sample for each positive sample, the expectation of X then becomes \\({\\sum }_{h}\\log P\\left({x}_{h}|\\theta, \\, R\\right)P\\left(h\\right)=\\frac{1}{|\\overline{E}|}\\sum \\log P\\left({x}_{h}|\\theta, \\, R\\right)\\) where \\(|\\overline{E}|\\) is the size of \\(\\bar{E}\\) and \\(P\\left(h\\right)=1/|\\bar{E}|\\) because h is a draw from \\(\\bar{E}\\) uniformly at random. The result for more complex stochastic gradient descent algorithms can be derived similarly with more complicated factors in front of the second term. In general, the effect from the second term is down-weighted due to negative sampling. Despite this estimator’s statistical bias, it works well in practice for word embeddings81, question answering82, and many other applications, outperforming the comparable but unbiased contrastive learning approach by co-minimizing bias and variance81. We also found this approach worked best in our model as seen in high predictive power despite bias. Nonetheless, we acknowledge that estimation could be further improved by considering more advanced sampling schemes83, which we defer to future work.\n\nLastly, to facilitate the stochastic gradient descent, we take a mini-batch of hyperedges and non-hyperedges to compute the gradient of the objective function at each step of the training process.\n\nModel evaluation\n\nAs a brief summary, we investigate three datasets: MEDLINE, APS, and US Patent; each dataset contains hypergraph data over several decades; and we model content and context hypergraphs separately. Consequently, for each dataset, for each year t covered by the dataset, we fit the model to the hypergraph of contents and separately to the hypergraph of contexts up to year t. In total, we estimate \\(2\\times \\left({T}_{{{MEDLINE}}}+{T}_{{{APS}}}+{T}_{{{Patents}}}\\right)\\) models where T is the number of years covered by our study from the corresponding dataset. Then, we evaluate the fitness of each model by its predictive performance of (out-of-sample) future combinations.\n\nFor example, given hypergraphs of MeSH terms up to and including year 2008, we estimate the hypergraph embedding model, and use the estimated model to predict hyperedges in 2009. Specifically, using the estimates of the parameters \\(\\left(\\theta,r\\right)\\), we can compute the propensity \\({\\lambda }_{h}\\) of any combination h of MeSH terms in year 2009, following Equation (1) \\({\\lambda }_{h}={\\sum }_{d}{\\prod }_{i\\in h}{\\theta }_{{id}}\\times {\\prod }_{i\\in h}{r}_{i}\\). Then we assess the model’s predictive performance in terms of its AUC (Area Under the Operator-Receiver Curve). Statistically, AUC is the probability that a random combination which turned into a hyperedge (positive combination) in 2009 would have a larger propensity than a random combination that did not turn into a hyperedge (negative combination) in 2009. To estimate this quantity, we randomly sample a positive combination and a negative combination of the same size from 2009, and check whether the positive combination has a larger propensity than the negative. The simulation is repeated for 10000 times and we calculate the fraction of times where the positive has larger propensity than the negative, which is the estimation of the AUC score in predicting hyperedges in 2009. It is easy to see that a perfect predictor would achieve an AUC score of 1 and random guesses would have an AUC of around 0.5. The larger the number, the better the predictive performance.\n\nProbability of hit papers and patents\n\nA hit paper (or patent) is defined as one among the top 10% most cited papers (or patents) published in the same year. For example, for all the papers published in 1990, we count all the citations they received in the time period covered by our dataset, and the top 10% most cited papers are hit papers.\n\nTo study the effect of novelty on the probability of being a hit paper, for all the papers published in each year, we first transform the raw novelty scores of the papers into percentiles, and then divide them into 30 equally sized bins in ascending order of the novelty scores. Then we assess the probability of hit papers for each bin as the fraction of hit papers in that bin. Finally, the probability of hit papers for each bin is plotted against the center percentile value in that bin in Figs. 2, 4, Supplementary Figs. 4, 5, 6, 8 and 9.\n\nSimilarly, to study the joint correlation of different novelties with the probability of being a hit paper, we divide the papers into multiple bins according to content and context novelty simultaneously. For the joint effect of content and context novelty, we divide the paper into 30-by-30 bins in terms of both novelties, then calculate the fraction of hit papers in each bin. Next we regress the probability of being a hit to content and context novelties. Fitted values of hit probability are then visualized as a 2D heat map across the full range of content and context novelty scores.\n\nFor the joint effect of career, team, and expedition novelty, we divide the papers into 20-by-20-by-20 bins in terms of their source novelty scores, and then calculate the fraction of hit papers in each bin. Again, we fit a polynomial function between hit probability and the three novelties to obtain the average relationship:\n\n$$P\\left({hit}\\right)\\sim \\mathop{\\sum }\\limits_{i,j,k=0}^{1}{careernovelt}{y}^{i}\\times {teamnovelt}{y}^{\\,\\,j}\\times {expeditionnovelt}{y}^{k}$$\n\nThe resulting 3D heat cube comprises 6 2D heatmaps where color denotes the fitted probability of hit for any given values of (career novelty, team novelty, expedition novelty).\n\nA detailed comparison with other models in predicting hit papers or patents is presented in the Supplementary Information.\n\nPreferences on context in citations\n\nTo assess the intensity with which scientists and inventors cite contexts (e.g., journals and conferences) familiar to their audience, we compute the similarity between every pair of context nodes where one cites the other. For example, for a paper i published in journal X, we calculate the similarity between the journal X and every journal cited by paper i. Similarity is quantified by the cosine similarity between two vectors representing the content of the two journals, conditioned on the content of paper i. Specifically, each journal is represented by a vector and each entry in the vector corresponds to a content node (MeSH terms, PACS codes, or patent subclasses); the value of an entry is the number of papers containing the corresponding content node and ever published by the journal, appropriately normalized so that the sum of the vector is 1. In other words, the vector consists of the loadings of the journal on different contents. When calculating the similarity between two journals, we do not directly compute the cosine similarity between their vectors, as those vectors contain substantial information irrelevant to the paper currently under consideration. Instead, we use only the entries corresponding to content nodes in paper i to calculate the cosine similarity between the two journals.\n\nAs we sweep through all papers (or patents), we obtain a distribution of the similarity between citing-cited context pairs: the number of times for which context nodes at a given similarity with the audience context (i.e., the citing context) are cited. To normalize this distribution, we also compute the potential space of citation similarity—the number of times at which context nodes at a given similarity would be cited at random. We achieve this by the following procedure: for each paper, sample as many context nodes uniformly at random from all context nodes as those originally cited, treat the sampled context nodes as if they were cited by the paper, and carry out the same similarity calculations as above. Finally, we have two distributions of similarity between citing-cited context pairs—one observed and one simulated by random sampling—and we take the ratio of the two as the likelihood of citing a context at a given similarity with the audience’s context.\n\nCareer, team and expedition novelty\n\nAssuming \\({\\theta }_{i}\\) is the embedding of context node i (e.g., a journal or conference), we define career, team, and expedition novelty as follows.\n\nCareer novelty\n\nFor any scientist, we collect all contexts (e.g., journals) in which she has ever published papers into list C. Then we calculate the surprisal across all contexts in her career using Eq. (2):\\({career\\; novelty}=-\\log {\\sum }_{d}{\\prod }_{i\\in C}{\\theta }_{{id}}\\). Next, given a paper, we use the average career novelty across the authors of the paper to assess how career novelty associates with paper impact.\n\nTeam novelty\n\nFor any paper, we first pool all the contexts (e.g., journals) where authors of the paper have published, without duplication. We denote this list of contexts by T. Next, we use Eq. (2) again to calculate the surprisal of this list: \\({team\\; novelty}=-\\log {\\sum }_{d}{\\prod }_{i\\in T}{\\theta }_{{id}}\\). Finally, we compare the paper’s team novelty to its impact to assess their association.\n\nExpedition novelty\n\nFor any paper, we again collect all contexts where its authors have published into a list T. Denoting the context where this paper is published by \\({\\theta }_{v}\\), we calculate the expedition novelty of this paper (or the authors of the paper) by \\({expedition\\; novelty}={averag}{e}_{i\\in T}\\left(1-{\\theta }_{i}\\cdot {\\theta }_{v}\\right)\\).\n\nOur career, team and expedition novelty measures also contribute to the literature on interdisciplinarity measures84, which include prominent measures that approach interdisciplinarity from the perspective of journal keyword combinations using the Web of Science75,85,86 and diversity or inequality indices (e.g., the Simpson Index, Shannon Entropy, and the GINI coefficient) assessed over these keywords87,88. Our measures differ from those above by being more granular and embedding the keywords into a continuous, high-dimensional space. Other work in the literature accounts for the similarity or difference between research fields combined89,90. Our measure does this automatically by accounting for the combinations of keywords required to characterize current literature and predict future research. Still others are built atop measures of centrality in networks of publication. By measuring the inner product of term vectors, our measure also approaches a continuous measure of centrality within the embedding space of contents and contexts. In short, our measure captures desiderata from each of the major categories of novelty measurement—diversity of combination, accounting for differences between components, and which represents centrality in the continuous embedded manifold.\n\nReporting summary\n\nFurther information on research design is available in the Nature Portfolio Reporting Summary linked to this article."
    }
}