{
    "id": "wrong_mix_random_nbateam_00096_0",
    "rank": 1,
    "data": {
        "url": "https://scalableinteractionparadigms.uni-oldenburg.de/blog/conversations/",
        "read_more_link": "",
        "language": "en",
        "title": "Conversations – SPP 2199 – Scalable Interaction Paradigms for Pervasive Computing Environments",
        "top_image": "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2022/04/ScippBlue-1.jpg",
        "meta_img": "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2022/04/ScippBlue-1.jpg",
        "images": [
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2022/04/ScippBlue-1.jpg",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2022/01/20201117-Angela-Sasse-1280x720-v2-e1642673150400-289x300.jpg",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2022/01/Koelle_Marion-3-2021-2-e1642782849630-300x300.jpg",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2022/01/Untitled.png",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2022/01/michael-coldewey-bild-208x300.jpeg",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2021/12/stefanie-mueller-profile-picture-300x300.jpeg",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2021/11/Francisco-Ortega-1-257x300.jpeg",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2021/11/rt-731x1024.jpg",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2021/11/Duchowski-Dikablis-900x900-1.png",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2021/11/wobbrock.jpeg",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2023/05/collage.png",
            "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2021/10/PGQ2V0UW.jpeg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "https://scalableinteractionparadigms.uni-oldenburg.de/blog/wp-content/uploads/2022/04/ScippBlue-1.jpg",
        "meta_site_name": "",
        "canonical_link": "https://scalableinteractionparadigms.uni-oldenburg.de/blog/conversations/",
        "text": "Usable is not enough: towards of human-centred, positive and inclusive security\n\nProf. Dr. Angela Sasse, Tuesday, Feb. 1st, 1700 CET\n\nBio: Dr. Angela Sasse is a computer scientist whose research spans the areas of human-computer interaction and computer security. She is Horst Görtz Endowed Professor of Human-Centred Security at Ruhr University Bochum and has a part-time position as Professor of Human-Centred Technology at University College London. Angela will conduct a conversation titled “Usable is not enough: towards human-centred positive and inclusive security.\n\nAbstract Usable security as a research area can be traced back to 1999, the year when the seminal papers “Why Johnny Can’t Encrypt” and “Users are not the Enemy” were published. But in the practitioner discourse, humans are still portrayed as the “weakest link”, and much of the research effort has focused on “fixing” people through education and persuasion, or motivating them through fear. Human-centred security is changing the focus: paying more attention to marginalised user groups, giving users more agency, and engaging them in the design process. As important as good design is to foster the development of secure habits that work across contexts and empower users, rather than leaving them scared and helpless.\n\nHCI in Safety-Critical Spaces\n\nMargareta Holtensdotter Lützhöft & Philippe Palanque, Tuesday, Jan. 18th, 1700 CET\n\nBio: Dr. Margareta Lützhöft is a master mariner, trained at Kalmar Maritime Academy in Sweden. After leaving the sea, she studied for a Bachelor’s degree in Cognitive science and a Master’s in Computer Science. In 2004 she received a PhD in Human-Machine Interaction and was associate Professor at Chalmers University of technology and Professor of Nautical Studies at the University of Tasmania, Australia. Presently, she is holding a position as Professor in the MarSafe group at the Western Norway University of Applied Sciences, and leader of the MarCATCH Research Centre. Her research interests include human-centered design and the effects of new technology, and she has published in these and other areas relating to maritime safety.\n\nBio: Dr. Philippe Palanque is Professor in Computer Science at the University Toulouse 3 “Paul Sabatier” and is head of the Interactive Critical Systems group at the Institut de Recherche en Informatique de Toulouse (IRIT) in France. He is involved in the research network HALA! (Higher Automation Levels in Aviation) funded by SESAR programme which targets at building the future European air traffic management system. He has worked for more than 10 years on research projects to improve interactive Ground Segment Systems at the Centre National d’Etudes Spatiales (CNES) and is also involved in the development of software architectures and user interface modeling for interactive cockpits in large civil aircraft (funded by Airbus). Philippe received the ACM Lifetime Service Award in 2021.\n\nMultimodal Interaction for Immersive analytics\n\nFrancisco R. Ortega, Tuesday, Nov. 30th, 1700 CET\n\nBio: Francisco R. Ortega is an Assistant Professor at Colorado State University (CSU) and Director of the Natural User Interaction lab (NUILAB). Dr. Ortega earned his Ph.D. in Computer Science (CS) in the field of Human-Computer Interaction (HCI) and 3D User Interfaces (3DUI) from Florida International University (FIU). He also held the position of Post-Doc and Visiting Assistant Professor at FIU between February 2015 to July 2018. Broadly speaking, his research has focused on multimodal and unimodal interaction (gesture-centric), which includes gesture recognition and elicitation (e.g., a form of participatory design). His main research area focuses on improving user interaction by (a) multimodal elicitation, (b) developing interactive techniques, and (c) improving augmented reality visualization techniques. The primary domains for interaction include immersive analytics, assembly, Navy use cases, and collaborative environments using augmented reality headsets.\n\nDr. Ortega’s funding record comes from National Science Foundation (NSF), DARPA, and Office of Naval Research ONR), among others. He was a co-PI for the DARPA Communicating with Computers project (over 4 million dollars). He is currently a PI for a 3-year effort for ONR (PM: Dr. Peter Squire) titled Perceptual/Cognitive Aspects of Augmented Reality: Experimental Research and a Computational Model along co-PIs Dr. Chris Wickens and Dr. Ben Clegg.\n\nAbstract: Dr. Ortega’s motivation comes from Dr. Weiser’s article about the computing of the 21st century, where the idea is to allow users to concentrate on daily tasks without the barriers posed by technology. Hence, making the computer invisible. Dr. Ortega’s early approach was concentrated on gestures, which will be described during this talk. From this knowledge, Dr. Ortega’s Natural User Interaction lab (NUILAB) has been working on gestures and multimodal interaction. One important question is which domain would provide the best-case scenario to generalize AR multimodal input modalities? Dr. Ortega and his lab have concentrated on Immersive Analytics (i.e., 3D visualization in stereoscopic rendering). During the talk, Dr. Ortega will talk about the existing challenges, preliminary results, and the way forward. Today, more than ever, the saying “There is no single silver bullet” for interaction remains at the heart of Dr. Ortega’s research on multimodal interaction.\n\nReal-Time Eye Tracking: Applications, Analytics, Implementation\n\nAndrew Duchowski, Tuesday, Nov. 16th, 1700 CET\n\nBio: Dr. Duchowski is a professor of Computer Science at Clemson University. He received his baccalaureate (1990) from Simon Fraser University, Canada, and doctorate (1997) from Texas A&M University, USA, both in Computer Science. His research and teaching interests include visual attention and perception, computer vision, and computer graphics. He is a noted research leader in the field of eye tracking, having produced a corpus of related papers and a monograph on eye tracking methodology, and has delivered courses and seminars on the subject at international conferences. He maintains the eyeCU, Clemson’s eye tracking laboratory and teaches a regular course on eye tracking methodology attracting students from various disciplines across campus.\n\nAbstract: Starting with an overview of eye-tracking applications, interactive applications are reviewed: assistive (gaze-responsive), active (selection, look to shoot), passive (foveated rendering, a.k.a. gaze-contingent displays), and expressive (gaze synthesis). These applications expose the need for advanced real-time eye movement processing beyond the current state-of-the-art. Offline event detection via velocity-based filtering or position-variance approaches seem inadequate in online settings. Suggestions are made regarding possible approaches to event detection, ambient/focal attention modeling, smooth pursuit tracking and interaction, and real-time pupillometric measures, e.g., of cognitive load. Interactive Python demonstrations will be given of potential real-time approaches to illustrate present limitations and directions for future development.\n\n“My Work In Gesture: Design, Recognition & Open Questions“\n\nJacob Wobbrock, Tuesday, Nov. 9th, 1700 CET\n\nBio: Jacob Wobbrock is a Professor of human-computer interaction (HCI) in The Information School and, by courtesy, in the Paul G. Allen School of Computer Science & Engineering at the University of Washington, where he directs the ACE Lab and co-directs the CREATE Center. He is also a founding member of the DUB Group and the MHCI+D degree. His Ph.D. students come from information science and computer science.\n\nHis research seeks to scientifically understand people’s experiences of computers and information, and to improve those experiences by inventing and evaluating new interactive technologies, especially for people with disabilities. His specific research topics include input and interaction techniques, human performance measurement and modeling, HCI research and design methods, mobile computing, and accessible computing.\n\nHomepage\n\nTwitter Account\n\nGaze for Interaction with Ubiquitous Computing Systems: Basics, Foundations, Advances, and Challenges.\n\nEnkelejda Kasneci and Hans Gellersen, Tuesday, Nov. 2nd, 1700 CET\n\nBio: Enkelejda Kasneci is a full professor of Computer Science at the University of Tübingen, Germany, where she leads the Human-Computer Interaction Group. As a BOSCH-scholar, she received her M.Sc. degree in Computer Science from the University of Stuttgart in 2007. In 2013, she received her PhD in Computer Science from the University of Tübingen. For her PhD research, she was awarded the research prize of the Federation Südwestmetall in 2014. From 2013 to 2015, she was a Margarete-von-Wrangell Fellow. Her main research interests are applied machine learning, eye-tracking technology and applications. She is a reviewer and PC member for several journals and major conferences. In 2016, she founded LeadersLikeHer, the world’s first open career network for women from industrial, research and public organizations.\n\nHomepage\n\nTwitter Account\n\nBio: Hans Gellersen is a full professor in the department of computing and communications at Lancaster University. His interest is in HCI, human interface technology, and the design of novel sensing and interaction techniques for anything from smart devices to AR/VR. In particularly he interested in eye movement and recently won an ERC Advanced Grant to investigate new foundations in for gaze and gestural interaction. Over the last ten years, his group has contributed major innovations on gaze in HCI, notably smooth pursuit interfaces and techniques, gaze-supported manual input, and eye-head interaction. Recently he also investigated interaction in 3D but he maintains long-standing interests in ubiquitous computing, cross-device interaction and interfaces that blend the digital and the virtual.\n\nHomepage\n\nTwitter Account\n\nDigital Touch: Somatic Symbiosis, Correspondence, Alterity, or Monster\n\nKristina Höök, Tuesday, Oct. 26th, 1700 CEST\n\nBio: Kristina Höök is a professor in Interaction Design at\n\nKTH Royal Institute of Technology in Stockholm (and used to be the director of the Mobile Life centre). Her research interests include affective interaction, somaesthetic design, internet of things and anything that makes life with technology more meaningful, enjoyable, creative and aesthetically appealing.\n\nAbstract:\n\nThree recent technical and societal developments are challenging the existing ideals of interaction design, namely the move towards hybrid physical/digital materials, the emergence of an increasingly complex and fluid digital ecology, and the increasing proportion of autonomous or partially autonomous systems changing their behavior over time and with use. These challenges in turn motivate us to propose three directions in which new ideals for interaction design might be sought: the first is to go beyond the language-body divide that implicitly frames most of our current understandings of experience and meaning, the second is to extend the scope of interaction design from individual interfaces to the complex socio-technical fabric of human and nonhuman actors, and the third is to go beyond predictability by learning to design with machine learning. This had lead to a rise of novel theoretical positions on how to define our relationship to smart objects, autonomous technologies, infrastructures or wearables. Theories such as postphenomenological, pragmatist, somaesthetics, feminist and sociological theories propose other engagements, other ways of interacting, sometimes decentring the “human”, sometimes enriching or questioning what can be understood as the category “human”. The postphenomenological position is that embodiment is but one of the possible interactions: engaging with an alterity or entering into a hermeneutic relationship could be other ways of framing our interactions with technology. In somaesthetics and different feminist theories, pluralist, soma-grounded understanding of the human condition leads to richer, complex somasensory entanglements with technologies. Theories of correspondence helps us shift beyond the idea of dialogue or interaction. Sometimes, the experience is best framed as in the humanities: as a monster.\n\nThe talk is based on:\n\nHöök, K. (2018). Designing with the body: Somaesthetic interaction design. MIT Press.\n\nHöök, K., Löwgren, J. (2021). Characterizing interaction design by its ideals: A discipline in transition. She Ji: The Journal of Design, Economics and Innovation. Accepted for publication.\n\nKarpashevich, P., Sanches, P., Cotton, K., Garrett, R., Luft, Y., Tsaknaki, V., and Höök, K.; (forthcoming, 2022) Touching Our Breathing through Shape-Change: Other, Cyborg or Twisted Mirror, Accepted to TOCHI’s special issue on Digital Touch, forthcoming, 2022.\n\nKristina Höök, Steve Benford, Paul Tennent, Vasiliki Tsaknaki, Miquel Alfaras, Juan Martinez Avila, Christine Li, Joseph Marshall, Claudia Daudén Roquet, Pedro Sanches, Anna Ståhl, Muhammad Umair, Charles Windlin, and Feng Zhou. 2021. Unpacking non-dualistic design: the soma design case. (December 2021), 35 pages"
    }
}