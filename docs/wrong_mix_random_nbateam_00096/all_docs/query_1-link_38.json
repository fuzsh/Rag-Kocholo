{
    "id": "wrong_mix_random_nbateam_00096_1",
    "rank": 38,
    "data": {
        "url": "https://chi2013.acm.org/program/best-of-chi/",
        "read_more_link": "",
        "language": "en",
        "title": "Best of CHI",
        "top_image": "https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/banner/home.jpg",
        "meta_img": "",
        "images": [
            "https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/facebook.png",
            "https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/twitter.png",
            "https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/gplus.png",
            "https://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/banner/home.jpg",
            "http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/best.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "B. Jones",
            "H. Benko",
            "E. Ofek",
            "A. Wilson",
            "R. Kumar",
            "A. Satyanarayan",
            "C. Torres",
            "M. Lim",
            "S. Ahmad",
            "S. Klemmer"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "CHI 2013",
        "canonical_link": "https://chi2013.acm.org/program/best-of-chi/",
        "text": "PPDMon. 2pm Paper: Weighted Graph Comparison Techniques for Brain Connectivity Analysis\n\nB. Alper (Univ. of California, Santa Barbara, USA), B. Bach, N. Henry Riche, T. Isenberg, J. Fekete\n\nB. Alper (Univ. of California, Santa Barbara, USA)B. Bach (INRIA, FR)N. Henry Riche (Microsoft Research, USA)T. Isenberg (INRIA, FR)J. Fekete (INRIA, FR)\n\nThis paper presents the design and evaluation of two visualizations for comparing weighted graphs. Results have implications for the design of brain connectivity analysis and other graph visualization tools.The analysis of brain connectivity is a vast field in neuroscience with a frequent use of visual representations and an increasing need for visual analysis tools. Based on an in-depth literature review and interviews with neuroscientists, we explore high-level brain connectivity analysis tasks that need to be supported by dedicated visual analysis tools. A significant example of such a task is the comparison of different connectivity data in the form of weighted graphs. Several approaches have been suggested for graph comparison within information visualization, but the comparison of weighted graphs has not been addressed. We explored the design space of applicable visual representations and present augmented adjacency matrix and node-link visualizations. To assess which representation best support weighted graph comparison tasks, we performed a controlled experiment. Our findings suggest that matrices support these tasks well, outperforming node-link diagrams. These results have significant implications for the design of brain connectivity analysis tools that require weighted graph comparisons. They can also inform the design of visual analysis tools in other domains, e.g. comparison of weighted social networks or biological pathways.\n\nPJMTue. 11am Paper: Analyzing User-Generated YouTube Videos to Understand Touchscreen Use by People with Motor Impairments\n\nL. Anthony (Univ. of Maryland, Baltimore County, USA), Y. Kim, L. Findlater\n\nL. Anthony (Univ. of Maryland, Baltimore County, USA)Y. Kim (Univ. of Maryland, USA)L. Findlater (Univ. of Maryland, USA)\n\nTo inform accessible touchscreen design, we analyzed 187 YouTube videos depicting people with physical disabilities interacting with mobile touchscreen devices. We report on challenges observed and user-initiated adaptations being made.Most work on the usability of touchscreen interaction for people with motor impairments has focused on lab studies with relatively few participants and small cross-sections of the population. To develop a richer characterization of use, we turned to a previously untapped source of data: YouTube videos. We collected and analyzed 187 non-commercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mainstream mobile touchscreen device. We coded the videos along a range of dimensions to characterize the interaction, the challenges encountered, and the adaptations being adopted in daily use. To complement the video data, we also invited the video uploaders to complete a survey on their ongoing use of touchscreen technology. Our findings show that, while many people with motor impairments find these devices empowering, accessibility issues still exist. In addition to providing implications for more accessible touchscreen design, we reflect on the application of user-generated content to study user interface design.\n\nPHQThu. 2pm Paper: What is “Critical” About Critical Design?\n\nJ. Bardzell (Indiana Univ. Bloomington, USA), S. Bardzell\n\nJ. Bardzell (Indiana Univ. Bloomington, USA)S. Bardzell (Indiana Univ. Bloomington, USA)\n\nWe provide a critique of Critical Design and propose a broader, more practical reframing, based on humanistic scholarship on critical theory and criticism.Critical design is a research through design methodology that foregrounds the ethics of design practice, reveals potentially hidden agendas and values, and explores alternative design values. While it seems to be a timely fit for today’s socially, aesthetically, and ethically oriented approaches to HCI, its adoption seems surprisingly limited. We argue that its central concepts and methods are unclear and difficult to adopt. Rather than merely attempting to decode the intentions of its originators, Dunne and Raby, we instead turn to traditions of critical thought in the past 150 years to explore a range of critical ideas and their practical uses. We then suggest ways that these ideas and uses can be leveraged as practical resources for HCI researchers interested in critical design. We also offer readings of two designs, which are not billed as critical designs, but which we argue are critical using a broader formulation of the concept than the one found in the current literature.\n\nPGZTue. 11am Paper: The Dubuque Electricity Portal: Evaluation of a City-Scale Residential Electricity Consumption Feedback System\n\nT. Erickson (IBM T.J. Watson Research Center, USA), M. Li, Y. Kim, A. Deshpande, S. Sahu, T. Chao, P. Sukaviriya, M. Naphade\n\nT. Erickson (IBM T.J. Watson Research Center, USA)M. Li (IBM T.J. Watson Research Center, USA)Y. Kim (IBM T.J. Watson Research Center, USA)A. Deshpande (IBM T.J. Watson Research Center, USA)S. Sahu (IBM T.J. Watson Research Center, USA)T. Chao (IBM T.J. Watson Research Center, USA)P. Sukaviriya (IBM T.J. Watson Research Center, USA)M. Naphade (IBM T.J. Watson Research Center, USA)\n\nEvaluation of an electricity portal deployed to 765 homes for 20 weeks that used feedback and social techniques to support decreased electricity consumption. Can assist designers of residential feedback systems. This paper describes the Dubuque Electricity Portal, a city-scale system aimed at supporting voluntary reductions of electricity consumption. The Portal provided each household with fine-grained feedback on its electricity use, as well as using incentives, comparisons, and goal setting to encourage conservation. Logs, a survey and interviews were used to evaluate the user experience of the Portal during a 20-week pilot with 765 volunteer households. Although the volunteers had already made a wide range of changes to conserve electricity prior to the pilot, those who used the Portal decreased their electricity use by about 3.7%. They also reported increased understanding of their usage, and reported taking an array of actions ¬ – both changing their behavior and their electricity infrastructure. The paper discusses the experience of the system’s users, and describes challenges for the design of ECF systems, including balancing accessibility and security, a preference for time-based visualizations, and the advisability of multiple modes of feedback, incentives and information presentation.\n\nPSFWed. 11am Paper: Improving Navigation-Based File Retrieval\n\nS. Fitchett (Univ. of Canterbury, NZ), A. Cockburn, C. Gutwin\n\nS. Fitchett (Univ. of Canterbury, NZ)A. Cockburn (Univ. of Canterbury, NZ)C. Gutwin (Univ. of Saskatchewan, CA)\n\nIntroduces three interfaces to improve navigation-based file retrieval. Empirical studies show they are subjectively preferred and decrease retrieval times for both new and revisited items.Navigating through a file hierarchy is one of the most common methods for accessing files, yet it can be slow and repetitive. New algorithms that predict upcoming file accesses have the potential to improve navigation-based file retrieval, but it is unknown how best to present their predictions to users. We present three design goals aiming to improve navigation-based file retrieval interfaces: minimise the time spent at each hierarchical level en route to the target file; reduce the number of levels traversed by providing shortcuts; and promote rehearsal of the retrieval mechanics to facilitate expertise. We introduce three interfaces that augment standard file browsers based on each of these goals: Icon Highlights give greater prominence to predicted items in the current folder; Hover Menus provide shortcuts to predicted folder content; and Search Directed Navigation uses predictive highlighting to guide users through the hierarchy in response to query terms. Results from a user evaluation show that all three interfaces improve file retrieval times, with Icon Highlights and Hover Menus best suited for frequently accessed items and Search Directed Navigation best suited for infrequent ones. We also show that the benefits are larger when folder content is spatially unstable. Finally, we discuss how the interfaces could be combined and deployed in existing file browsers.\n\nPFUWed. 9am Paper: SPRWeb: Preserving Subjective Responses to Website Colour Schemes through Automatic Recolouring\n\nD. Flatla (Univ. of Saskatchewan, CA), K. Reinecke, C. Gutwin, K. Gajos\n\nD. Flatla (Univ. of Saskatchewan, CA)K. Reinecke (Harvard Univ., USA)C. Gutwin (Univ. of Saskatchewan, CA)K. Gajos (Harvard Univ., USA)\n\nSPRWeb equalizes website experience for people with colour vision deficiency by improving colour differentiation (like previous recolouring tools), but also maintains the original colour scheme’s subjective properties (‘warmth’, ‘weight’, ‘activity’).Colours are an important part of user experiences on the Web. Colour schemes influence the aesthetics, first impressions and long-term engagement with websites. However, five percent of people perceive a subset of all colours because they have colour vision deficiency (CVD), resulting in an unequal and less-rich user experience on the Web. Traditionally, people with CVD have been supported by recolouring tools that improve colour differentiability, but do not consider the subjective properties of colour schemes while recolouring. To address this, we developed SPRWeb, a tool that recolours websites to preserve subjective responses and improve colour differentiability – thus enabling users with CVD to have similar online experiences. To develop SPRWeb, we extended existing models of non-CVD subjective responses to CVD, then used this extended model to steer the recolouring process. In a lab study, we found that SPRWeb did significantly better than a standard recolouring tool at preserving the temperature and naturalness of websites, while achieving similar weight and differentiability preservation. We also found that recolouring did not preserve activity, and hypothesize that visual complexity influences activity more than colour. SPRWeb is the first tool to automatically preserve the subjective and perceptual properties of website colour schemes thereby equalizing the colour-based web experience for people with CVD.\n\nPCHMon. 2pm Paper: The Efficacy of Human Post-Editing for Language Translation\n\nS. Green (Stanford Univ., USA), J. Heer, C. Manning\n\nS. Green (Stanford Univ., USA)J. Heer (Stanford Univ., USA)C. Manning (Stanford Univ., USA)\n\nWe analyzed human post-editing of machine translation output, a common feature in translator interfaces. We found that machine suggestions reduce human translation time and improved final quality.Language translation is slow and expensive, so various forms of machine assistance have been devised. Automatic machine translation systems process text quickly and cheaply, but with quality far below that of skilled human translators. To bridge this quality gap, the translation industry has investigated post-editing, or the manual correction of machine output. We present the first rigorous, controlled analysis of post-editing and find that post-editing leads to reduced time and, surprisingly, improved quality for three diverse language pairs (English to Arabic, French, and German). Our statistical models and visualizations of experimental data indicate that some simple predictors (like source text part of speech counts) predict translation time, and that post-editing results in very different interaction patterns. From these results we distill implications for the design of new language translation interfaces.\n\nPGXThu. 2pm Paper: Mind the Theoretical Gap: Interpreting, Using, and Developing Behavioral Theory in HCI Research\n\nE. Hekler (Arizona State Univ., USA), P. Klasnja, J. Froehlich, M. Buman\n\nE. Hekler (Arizona State Univ., USA)P. Klasnja (Univ. of Michigan, USA)J. Froehlich (Univ. of Maryland, USA)M. Buman (Arizona State Univ., USA)\n\nAre you trying to use behavioral theory in your work? Our paper will help by providing a context and organizing framework for interpreting, using, and developing behavioral theory. Researchers in HCI and behavioral science are increasingly exploring the use of technology to support behavior change in domains such as health and sustainability. This work, however, remain largely siloed within the two communities. We begin to address this silo problem by attempting to build a bridge between the two disciplines at the level of behavioral theory. Specifically, we define core theoretical terms to create shared understanding about what theory is, discuss ways in which behavioral theory can be used to inform research on behavior change technologies, identify shortcomings in current behavioral theories, and outline ways in which HCI researchers can not only interpret and utilize behavioral science theories but also contribute to improving them.\n\nPMLMon. 4pm Paper: Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk\n\nL. Irani (Univ. of California, Irvine, USA), M. Silberman\n\nL. Irani (Univ. of California, Irvine, USA)M. Silberman (Bureau of Economic Interpretation, USA)\n\nWith Turkopticon, we contribute an example of a long-term systems building project that reworks employer-worker relations in Amazon Mechanical Turk. We analyze the system in feminist, infrastrastructural, and political terms. As HCI researchers have explored the possibilities of human computation, they have paid less attention to ethics and values of crowdwork. This paper offers an analysis of Amazon Mechanical Turk, a popular human computation system, as a site of technically mediated worker-employer relations. We argue that human computation currently relies on worker invisibility. We then present Turkopticon, an activist system that allows workers to publicize and evaluate their relationships with employers. As a common infrastructure, Turkopticon also enables workers to engage one another in mutual aid. We conclude by discussing the potentials and challenges of sustaining activist technologies that intervene in large, existing socio-technical systems.\n\nPCJTue. 9am Paper: IllumiRoom: Peripheral Projected Illusions for Interactive Experiences\n\nB. Jones (Univ. of Illinois at Urbana-Champaign, USA), H. Benko, E. Ofek, A. Wilson\n\nB. Jones (Univ. of Illinois at Urbana-Champaign, USA)H. Benko (Microsoft Research, USA)E. Ofek (Microsoft Research, USA)A. Wilson (Microsoft Research, USA)\n\nIllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions.\n\nPLBThu. 11am Paper: Webzeitgeist: Design Mining the Web\n\nR. Kumar (Stanford Univ., USA), A. Satyanarayan, C. Torres, M. Lim, S. Ahmad, S. Klemmer, J. Talton\n\nR. Kumar (Stanford Univ., USA)A. Satyanarayan (Stanford Univ., USA)C. Torres (Stanford Univ., USA)M. Lim (Stanford Univ., USA)S. Ahmad (Massachusetts Institute of Technology, USA)S. Klemmer (Stanford Univ., USA)J. Talton (Intel Corporation, USA)\n\nThis paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools.Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes. This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools. This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables.\n\nPFLWed. 2pm Paper: LaserOrigami: Laser-Cutting 3D Objects\n\nS. Mueller (Hasso Plattner Institute, DE), B. Kruck, P. Baudisch\n\nS. Mueller (Hasso Plattner Institute, DE)B. Kruck (Hasso Plattner Institute, DE)P. Baudisch (Hasso Plattner Institute, DE)\n\nLaserOrigami is a rapid prototyping system that produces 3D objects using a laser cutter. LaserOrigami is substantially faster than 3D-printing and unlike traditional laser cutting it requires no manual assembly.We present LaserOrigami, a rapid prototyping system that produces 3D objects using a laser cutter. Laser¬Origami is substantially faster than traditional 3D fabrication techniques such as 3D printing and unlike traditional laser cutting the resulting 3D objects require no manual assembly. The key idea behind LaserOrigami is that it achieves three-dimensionality by folding and stretching the workpiece, rather than by placing joints, thereby eliminating the need for manual assembly. Laser¬Origami achieves this by heating up selected regions of the workpiece until they become compliant and bend down under the force of gravity. LaserOrigami administers the heat by defocusing the laser, which distributes the laser’s power across a larger surface. LaserOrigami implements cutting and bending in a single integrated process by automatically moving the cutting table up and down—when users take out the workpiece, it is already fully assembled. We present the three main design elements of Laser¬Origami: the bend, the suspender, and the stretch, and demonstrate how to use them to fabricate a range of physical objects. Finally, we demonstrate an interactive fabrication version of Laser¬Origami, a process in which user interaction and fabrication alternate step-by-step.\n\nPKZMon. 4pm Paper: Labor Dynamics in a Mobile Micro-Task Market\n\nM. Musthag (Univ. of Massachusetts, USA), D. Ganesan\n\nM. Musthag (Univ. of Massachusetts, USA)D. Ganesan (Univ. of Massachusetts, USA)\n\nThis paper provides an in-depth exploration of labor dynamics in mobile task markets which require spatial mobility based on a year-long dataset from a leading mobile crowdsourcing platform. The ubiquity of smartphones has led to the emergence of mobile crowdsourcing markets, where smartphone users participate to perform tasks in the physical world. Mobile crowdsourcing markets are uniquely different from their online counterparts in that they require spatial mobility, and are therefore impacted by geographic factors and constraints that are not present in the online case. Despite the emergence and importance of such mobile marketplaces, little to none is known about the labor dynamics and mobility patterns of agents. This paper provides an in-depth exploration of labor dynamics in mobile task markets based on a year-long dataset from a leading mobile crowdsourcing platform. We find that a small core group of workers (< 10%) account for a disproportionately large proportion of activity (> 80%) generated in the market. We find that these super agents are more efficient than other agents across several dimensions: a) they are willing to move longer distances to perform tasks, yet they amortize travel across more tasks, b) they work and search for tasks more efficiently, c) they have higher data quality in terms of accepted submissions, and d) they improve in almost all of these efficiency measures over time. We find that super agent efficiency stems from two simple optimizations — they are 3x more likely than other agents to chain tasks and they pick fewer lower priced tasks than other agents. We compare mobile and online micro-task markets, and discuss differences in demographics, data quality, and time of use, as well as similarities in super agent behavior. We conclude with a discussion of how a mobile micro-task market might leverage some of our results to improve performance.\n\nPTFWed. 4pm Paper: Job Opportunities through Entertainment: Virally Spread Speech-Based Services for Low-Literate Users\n\nA. Raza (Carnegie Mellon Univ., USA), F. Ul Haq, Z. Tariq, M. Pervaiz, S. Razaq, U. Saif, R. Rosenfeld\n\nA. Raza (Carnegie Mellon Univ., USA)F. Ul Haq (Lahore Univ. of Management Sciences, PK)Z. Tariq (Lahore Univ. of Management Sciences, PK)M. Pervaiz (Northeastern Univ., USA)S. Razaq (Lahore Univ. of Management Sciences, PK)U. Saif (Lahore Univ. of Management Sciences, PK)R. Rosenfeld (Carnegie Mellon Univ., USA)\n\nA speech-based entertainment service spread virally to low-literate Pakistani telephone users, exceeding 85,000 users and 495,000 calls in four months, while spreading low-skill job opportunities to 27,000 of them.We explore how telephone-based services might be mass adopted by low-literate users in the developing world. We focus on speech and push-button dialog systems requiring neither literacy nor training. Building on the success of Polly, a simple telephone-based voice manipulation and forwarding system that was first tested in 2011, we report on its first large-scale sustained deployment. In 24/7 operation in Pakistan since May 9, 2012, as of mid-September Polly has spread to 85,000 users, engaging them in 495,000 interactions, and is continuing to spread to 1,000 new people daily. It has also attracted 27,000 people to a job search service, who in turn listened 279,000 times to job ads and forwarded them 22,000 times to their friends. We report users’ activity over time and across demographics, analyze user behavior within several randomized controlled trials, and describe lessons learned regarding spread, scalability and sustainability of telephone-based speech-based services.\n\nPAPTue. 11am Paper: At Home with Agents: Exploring Attitudes Towards Future Smart Energy Infrastructures\n\nT. Rodden (The Univ. of Nottingham, UK), J. Fischer, N. Pantidi, K. Bachour, S. Moran\n\nT. Rodden (The Univ. of Nottingham, UK)J. Fischer (The Univ. of Nottingham, UK)N. Pantidi (The Univ. of Nottingham, UK)K. Bachour (The Univ. of Nottingham, UK)S. Moran (The Univ. of Nottingham, UK)\n\nThis paper considers critical socio-economical issues regarding how consumers might relate to future smart energy infrastructures and suggests a number of key design principles to address those.Energy systems researchers are proposing a broad range of future “smart” energy infrastructures to promote more efficient management of energy resources. This paper considers how consumers might relate to these future smart grids within the UK. To address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. Users’ reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to consider how to design software agents to enhance trust in these socio-economic settings.\n\nPTVTue. 4pm Paper: Screenfinity: Extending the Perception Area of Content on Very Large Public Displays\n\nC. Schmidt (Telekom Innovation Laboratories, TU Berlin, DE), J. Müller, G. Bailly\n\nC. Schmidt (Telekom Innovation Laboratories, TU Berlin, DE)J. Müller (Univ. of the Arts, DE)G. Bailly (Telekom Innovation Laboratories, TU Berlin, DE)\n\nPresents a model for the perception area of visual interfaces, and a novel public display increasing the perception area and allowing interaction while walking. Useful for designers of large displays.We propose and validate a model of the perception area of content on public displays in order to predict from where users can read. From this model, we derive Screenfinity, a technique to rotate, translate, and zoom content in order to enable reading while passing by very large displays. Screenfinity is comfortable to read when close, supports different content for different users, does not waste screen real estate and allows expert passers-by to read content while walking. A laboratory study shows that expert users are able to perceive content when it moves. A field study evaluates the effect of Screenfinity on novice users in an ecologically valid setting. We find 1) first time users can read content without slowing down or stopping; 2) Passers-by stopping did so to explore the technology. Users explore the interaction, the limits of the system, manipulate the technology, and look behind the screen.\n\nNFBTue. 2pm Note: NailDisplay: Bringing an Always Available Visual Display to Fingertips\n\nC. Su (National Taiwan Univ., TW), L. Chan, C. Weng, R. Liang, K. Cheng, B. Chen\n\nC. Su (National Taiwan Univ., TW)L. Chan (Academia Sinica, TW)C. Weng (National Taiwan Univ., TW)R. Liang (Academia Sinica, TW)K. Cheng (National Taiwan Univ., TW)B. Chen (National Taiwan Univ., TW)\n\nExplores the possibility of turing fingernails into places for system input and visual output by adding a nail-mounted display.This work presents a novel and always-available nail mounted display known as NailDisplay. The proposed display augments the use of a finger by allowing for always-available visual feedback owing to its fast accessibility and binding user controls with the display, i.e. what you control is what you see (through the display). Potential benefits of NailDisplay are demonstrated in three applications: from displaying to combining it with user controls. In the first application, NailDisplay can reveal what is occluded under a finger touch, making it a solution to operate small UI elements. In the second application, NailDisplay is complementary to an imaginary interface, helping users to learn an imaginary interface (e.g., on the users’ arms) and allowing them to reassure the interface when their memory of it becomes unclear. In the third application, NailDisplay is integrated with rich finger interactions, such as swiping in the air. We also report users’ feedbacks gathered from an explorative user study.\n\nPLQTue. 2pm Paper: Reasons to Question Seven Segment Displays\n\nH. Thimbleby (Swansea Univ., UK)\n\nH. Thimbleby (Swansea Univ., UK)\n\nSeven segment displays are familiar and ubiquitous, yet their use is problematic. This paper reviews many readability and use problems, and provides a range design questions and fixes.Seven segment number displays are ubiquitous and popular. They are simple and familiar. They seem to make economic sense, and with only seven segments they require little wiring and electronics to support. They are cheap to buy and cheap to use; they make seemingly effective and unproblematic products. This paper illustrates many examples of problematic uses of seven segment displays that could have been avoided. More generally, the paper raises design questions and some solutions to be considered when designing numerical displays, and certainly before uncritically using seven segment displays. Although there are markets and applications where cost may be an overriding consideration, for safety critical and other dependable types of use (including general purpose devices that may sometimes be used for critical tasks) more legible alternatives than standard seven segment displays should be preferred.\n\nPSXMon. 11am Paper: The Many Faces of Facebook: Experiencing Social Media as Performance, Exhibition, and Personal Archive\n\nX. Zhao (Cornell Univ., USA), N. Salehi, S. Naranjit, S. Alwaalan, S. Voida, D. Cosley\n\nX. Zhao (Cornell Univ., USA)N. Salehi (Sharif Univ. of Technology, IR)S. Naranjit (Cornell Univ., USA)S. Alwaalan (King Saud Univ., SA)S. Voida (Cornell Univ., USA)D. Cosley (Cornell Univ., USA)\n\nWe bring new perspectives to the design of social media by drawing from Goffman’s theatrical metaphor and Hogan’s exhibition approach to explore how people manage social media data over time. The growing use of social media means that an increasing amount of people’s lives are visible online. We draw from Goffman’s theatrical metaphor and Hogan’s exhibition ap-proach to explore how people manage their personal collec-tion of social media data over time. We conducted a quali-tative study of 13 participants to reveal their day-to-day decision-making about producing and curating digital traces on Facebook. Their goals and strategies showed that people experience the Facebook platform as consisting of three different functional regions: a performance region for man-aging recent data and impression management, an exhibi-tion region for longer term presentation of self-image, and a personal region for archiving meaningful facets of life. Further, users’ need for presenting and archiving data in these three regions is mediated by temporality. These find-ings trigger a discussion of how to design social media that support these dynamic and sometimes conflicting needs.\n\nNNFWed. 2pm Note: FreeD – A Freehand Digital Sculpting Tool\n\nA. Zoran (Massachusetts Institute of Technology, USA), J. Paradiso\n\nA. Zoran (Massachusetts Institute of Technology, USA)J. Paradiso\n\nThis paper explores the intersection of craft and digital fabrication through the FreeD, a handheld milling device, preserving the maker’s freedom to sculpt and carve based on virtual 3D models. In this paper, we present an approach to combining digital fabrication and craft, emphasizing the user experience. While many researchers strive to enable makers to design and produce 3D objects, our research seeks to present a new fabrication approach to make unique, one-of-a-kind artifacts. To that end, we developed the FreeD, a hand-held digital milling device. The system is guided and monitored by a computer while preserving the maker’s freedom to sculpt and carve, and to manipulate the work in many creative ways. Relying on a predesigned 3D model, the computer gets into action only when the milling bit risks the object’s integrity, by slowing down the spindle’s speed or by drawing back the shaft, while the rest of the time it allows complete gestural freedom. We describe the key concepts of our work and its motivation, present the FreeD’s architecture and technology, and discuss two projects made with the tool.\n\nPGUTue. 4pm Paper: Benevolent Deception in Human Computer Interaction\n\nE. Adar (Univ. of Michigan, USA), D. Tan, J. Teevan\n\nE. Adar (Univ. of Michigan, USA)D. Tan (Microsoft Research, USA)J. Teevan (Microsoft Research, USA)\n\nIn this work we analyze deception intended to help the user. Using a criminology-inspired metaphor we describe the means, motive, and opportunities for deception and ideas for future research.Though it has been asserted that “good design is honest,” [42] deception exists throughout human-computer interaction research and practice. Because of the stigma associated with deception—in many cases rightfully so—the research community has focused its energy on eradicating malicious deception, and ignored instances in which deception is positively employed. In this paper we present the notion of benevolent deception, deception aimed at benefitting the user as well as the developer. We frame our discussion using a criminology-inspired model and ground components in various examples. We assert that this provides us with a set of tools and principles that not only helps us with system and interface design, but that opens new research areas. After all, as Cockton claims in his 2004 paper “Value-Centered HCI” [13], “Traditional disciplines have delivered truth. The goal of HCI is to deliver value.”\n\nNMQWed. 4pm Note: Leading People to Longer Queries\n\nE. Agapie (Harvard Univ., USA), G. Golovchinsky, P. Qvarfordt\n\nE. Agapie (Harvard Univ., USA)G. Golovchinsky (FX Palo Alto Laboatory, Inc., USA)P. Qvarfordt (FX Palo Alto Laboatory, Inc., USA)\n\nAn experiment to test the effects of halos on query length was conducted. Results suggest that the interface may be effective for eliciting longer queries. Although longer queries can produce better results for information seeking tasks, people tend to type short queries. We created an interface designed to encourage people to type longer queries, and evaluated it in two Mechanical Turk experiments. Results suggest that our interface manipulation may be effective for eliciting longer queries.\n\nPDHMon. 11am Paper: Quantifying the Invisible Audience in Social Networks\n\nM. Bernstein (Stanford Univ., USA), E. Bakshy, M. Burke, B. Karrer\n\nM. Bernstein (Stanford Univ., USA)E. Bakshy (Facebook, Inc., USA)M. Burke (Facebook, Inc., USA)B. Karrer (Facebook, Inc., USA)\n\nWhen you share content in a social network, who is listening? We combine survey and log data to examine how well users’ audience perceptions match their true audience on Facebook.When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users’ perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000 Facebook users’ posts over the course of one month and find that publicly visible signals — friend count, likes, and comments — vary widely and do not strongly indicate the audience of a single post. Despite the variation, users typically reach 61% of their friends each month. Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.\n\nPTDTue. 4pm Paper: Squaring the Circle: How Framing Influences User Behavior around a Seamless Cylindrical Display\n\nG. Beyer (Univ. of Munich (LMU), DE), F. Köttner, M. Schiewe, I. Haulsen, A. Butz\n\nG. Beyer (Univ. of Munich (LMU), DE)F. Köttner (Univ. of Munich (LMU), DE)M. Schiewe (Fraunhofer FOKUS, DE)I. Haulsen (Fraunhofer FOKUS, DE)A. Butz (Univ. of Munich (LMU), DE)\n\nAnalyzes user behavior around a cylindrical and seamless interactive column display in the wild. Helps to better understand how framing influences user positions around more complex non-planar display shapes.Recent research has presented large public displays in novel non-flat shapes such as spheres, curved planes and cylinders, and looked at the influence of the form factor on user behavior. Yet, the basic shape cannot be considered in isolation when interpreting the behavior of passers-by around such displays. In this paper we investigate two further display factors, framedness and seamlessness, that have to be considered in conjunction with the form factor to understand user behavior in front of large non-flat displays. We present the findings from a field study with an interactive column display and take a closer look at how these factors influence actor and bystander behavior. Our results show that rectangular frames act as a sort of funnel for user position and can easily override effects of the non-flat shape on user position and interaction, even though the users didn’t recall the presence of these frames.\n\nPJKMon. 4pm Paper: GravitySpace: Tracking Users and Their Poses in a Smart Room Using a Pressure-Sensing Floor\n\nA. Bränzel (Hasso Plattner Institute, DE), C. Holz, D. Hoffmann, D. Schmidt, M. Knaust, P. Lühne, R. Meusel, S. Richter, P. Baudisch\n\nA. Bränzel (Hasso Plattner Institute, DE)C. Holz (Hasso Plattner Institute, DE)D. Hoffmann (Hasso Plattner Institute, DE)D. Schmidt (Hasso Plattner Institute, DE)M. Knaust (Hasso Plattner Institute, DE)P. Lühne (Hasso Plattner Institute, DE)R. Meusel (Hasso Plattner Institute, DE)S. Richter (Hasso Plattner Institute, DE)P. Baudisch (Hasso Plattner Institute, DE)\n\nIntroduces new approach to tracking people and objects in smart rooms based on a high-resolution pressure-sensitive floor. Provides consistent wall-to-wall coverage, is less susceptible and less privacy-critical than camera-based systems.We explore how to track people and furniture based on a high-resolution pressure-sensitive floor. Gravity pushes people and objects against the floor, causing them to leave imprints of pressure distributions across the surface. While the sensor is limited to sensing direct contact with the surface, we can sometimes conclude what takes place above the surface, such as users’ poses or collisions with virtual objects. We demonstrate how to extend the range of this approach by sensing through passive furniture that propagates pressure to the floor. To explore our approach, we have created an 8 m2 back-projected floor prototype, termed GravitySpace, a set of passive touch-sensitive furniture, as well as algorithms for identifying users, furniture, and poses. Pressure-based sensing on the floor offers four potential benefits over camera-based solutions: (1) it provides consistent coverage of rooms wall-to-wall, (2) is less susceptible to occlusion between users, (3) allows for the use of simpler recognition algorithms, and (4) intrudes less on users’ privacy.\n\nPRKWed. 11am Paper: Digital Portraits: Photo-sharing After Domestic Violence\n\nR. Clarke (Newcastle Univ., UK), P. Wright, M. Balaam, J. McCarthy\n\nR. Clarke (Newcastle Univ., UK)P. Wright (Newcastle Univ., UK)M. Balaam (Newcastle Univ., UK)J. McCarthy (Univ. College Cork, IE)\n\nTaking a feminist arts action research approach, we detail an account of engaging women in photo-sharing who have had experiences of domestic violence, in the early stages of longitudinal participatory research.This paper explores the potential role of photography in re-building of lives after domestic violence. We worked in the context of a women’s centre where women are accessing support after leaving abusive relationships. The paper contributes a feminist participatory arts action research approach to studying photo-sharing practices and helps to frame an understanding of the ongoing tensions in the construction of self with others that the women experience. We argue that the affirmation of new bonds, control in sharing the process of ‘moving on’, and supporting discursive negotiations of privacy are important considerations for design focused on interpersonal social processes around the use of digital technology.\n\nNRUWed. 11am Note: Using Fake Cursors to Secure On-Screen Password Entry\n\nA. De Luca (Univ. of Munich (LMU), DE), E. von Zezschwitz, L. Pichler, H. Hussmann\n\nA. De Luca (Univ. of Munich (LMU), DE)E. von Zezschwitz (Univ. of Munich (LMU), DE)L. Pichler (Univ. of Munich (LMU), DE)H. Hussmann (Univ. of Munich (LMU), DE)\n\nPresents a system that uses fake cursors to secure password entry on on-screen keyboards. An evaluation of the system shows that shoulder surfing resistance is significantly improved.In this paper, we present a concept using fake cursors to disguise on-screen password entry. We performed two user studies with different amounts of dummy cursors and differently colored cursors. The results show that dummy cursors significantly improve security. At the same time, decrease in performance is kept within an acceptable range. Depending on the required degree of security, the studies favor 8 or 16 differently colored cursors as the best trade-off between security and usability.\n\nPRVWed. 11am Paper: Back-of-Device Authentication on Smartphones\n\nA. De Luca (Univ. of Munich (LMU), DE), E. von Zezschwitz, N. Nguyen, M. Maurer, E. Rubegni, M. Scipioni, M. Langheinrich\n\nA. De Luca (Univ. of Munich (LMU), DE)E. von Zezschwitz (Univ. of Munich (LMU), DE)N. Nguyen (Univ. of Munich (LMU), DE)M. Maurer (Univ. of Munich (LMU), DE)E. Rubegni (Univ. of Lugano, CH)M. Scipioni (Univ. of Lugano, CH)M. Langheinrich (Univ. of Lugano, CH)\n\nPresents a system that uses gestures on the back of a mobile device to authenticate. Shoulder surfing resistance is significantly improved while remaining reasonably fast and easy to use.This paper presents BoD Shapes, a novel authentication method for smartphones that uses the back of the device for input. We argue that this increases the resistance to shoulder surfing while remaining reasonably fast and easy-to-use. We performed a user study (n=24) comparing BoD Shapes to PIN authentication, Android grid unlock, and a front version of our system. Testing a front version allowed us to directly compare performance and security measures between front and back authentication. Our results show that BoD Shapes is significantly more secure than the three other approaches. While performance declined, our results show that BoD Shapes can be very fast (up to 1.5 seconds in the user study) and that learning effects have an influence on its performance. This indicates that speed improvements can be expected in long-term use.\n\nPQPTue. 9am Paper: AnyType: Provoking Reflection and Exploration with Aesthetic Interaction\n\nL. Devendorf (Univ. of California, Berkeley, USA), K. Ryokai\n\nL. Devendorf (Univ. of California, Berkeley, USA)K. Ryokai (Univ. of California, Berkeley, USA)\n\nAnyType generates unique typefaces from photographs of shapes people find in their environment. In keeping with the principles of aesthetic interaction, AnyType supports opportunities for surprise, storytelling, and expression.AnyType is a mobile application that generates unique typefaces from photographs of shapes that people find in their environment. In keeping with the principles of aesthetic interaction, the design of AnyType supports opportunities for surprise, storytelling, and expression. This paper presents data collected from two observational studies of AnyType. In both studies, we found that people appropriated the application to create highly personalized messages. They found inspiration in unexpected locations, created memories from nuanced details in their lives, and creatively explored the design space provided by the system. Drawing from our observations, we discuss possible roles mobile devices could play in people’s personal meaning making, creative process, and discovery, in interaction with elements of their physical environment.\n\nPGETue. 4pm Paper: The Effects of Tactile Feedback and Movement Alteration on Interaction and Awareness with Digital Embodiments\n\nA. Doucette (Univ. of Saskatchewan, CA), R. Mandryk, C. Gutwin, M. Nacenta, A. Pavlovych\n\nA. Doucette (Univ. of Saskatchewan, CA)R. Mandryk (Univ. of Saskatchewan, CA)C. Gutwin (Univ. of Saskatchewan, CA)M. Nacenta (Univ. of St Andrews, UK)A. Pavlovych (Univ. of Saskatchewan, CA)\n\nPresents and evaluates methods for affecting group behaviour in tabletop groupware by providing cues of physical boundaries in digital space.Collaborative tabletop systems can employ direct touch, where people’s real arms and hands manipulate objects, or indirect input, where people are represented on the table with digital embodiments. The input type and the resulting embodiment dramatically influence tabletop interaction: in particular, the touch avoidance that naturally governs people’s touching and crossing behavior with physical arms is lost with digital embodiments. One result of this loss is that people are less aware of each others’ arms, and less able to coordinate actions and protect personal territories. To determine whether there are strategies that can influence group interaction on shared digital tabletops, we studied augmented digital arm embodiments that provide tactile feedback or movement alterations when people touched or crossed arms. The study showed that both augmentation types changed people’s behavior (people crossed less than half as often) and also changed their perception (people felt more aware of the other person’s arm, and felt more awkward when touching). This work shows how groupware designers can influence people’s interaction, awareness, and coordination abilities when physical constraints are absent.\n\nNDFMon. 2pm Note: Age-Related Differences in Performance with Touchscreens Compared to Traditional Mouse Input\n\nL. Findlater (Univ. of Maryland, USA), J. Froehlich, K. Fattal, J. Wobbrock, T. Dastyar\n\nL. Findlater (Univ. of Maryland, USA)J. Froehlich (Univ. of Maryland, USA)K. Fattal (Univ. of Maryland, USA)J. Wobbrock (Univ. of Washington, USA)T. Dastyar (Univ. of Maryland, USA)\n\nWe compared performance of older and younger adults on a range of desktop and touchscreen tasks. The touchscreen reduced the performance gap between the two groups relative to the desktop. Despite the apparent popularity of touchscreens for older adults, little is known about the psychomotor performance of these devices. We compared performance between older adults and younger adults on four desktop and touchscreen tasks: pointing, dragging, crossing and steering. On the touchscreen, we also examined pinch-to-zoom. Our results show that while older adults were significantly slower than younger adults in general, the touchscreen reduced this performance gap relative to the desktop and mouse. Indeed, the touchscreen resulted in a significant movement time reduction of 35% over the mouse for older adults, compared to only 16% for younger adults. Error rates also decreased.\n\nPGDWed. 2pm Paper: Gestures and Widgets: Performance in Text Editing on Multi-Touch Capable Mobile Devices\n\nV. Fuccella (Univ. di Salerno, IT), P. Isokoski, B. Martin\n\nV. Fuccella (Univ. di Salerno, IT)P. Isokoski (Univ. of Tampere, FI)B. Martin (Univ. de Lorraine, FR)\n\nWe present the design and evaluation of a gestural text editing technique for touchscreens. Gestures drawn on the soft keyboard are often faster than conventional editing techniques.We describe the design and evaluation of a gestural text editing technique for touchscreen devices. The gestures are drawn on top of the soft keyboard and interpreted as commands for moving the caret, performing selections, and controlling the clipboard. Our implementation is an Android service that can be used in any text editing task on Android-based devices. We conducted an experiment to compare the gestural editing technique against the widget-based technique available on a smartphone (Samsung Galaxy II with Android 2.3.5). The results show a performance benefit of 13-24% for the gestural technique depending on the font size. Subjective feedback from the participants was also positive. Because the two editing techniques use different input areas, they can co-exist on a device. This means that the gestural editing can be added on any soft keyboard without interfering with user experience for those users that choose not to use it.\n\nPSEThu. 11am Paper: Evaluation of Alternative Glyph Designs for Time Series Data in a Small Multiple Setting\n\nJ. Fuchs (Univ., DE), F. Fischer, F. Mansmann, E. Bertini, P. Isenberg\n\nJ. Fuchs (Univ., DE)F. Fischer (Univ., DE)F. Mansmann (Univ., DE)E. Bertini (Univ., USA)P. Isenberg (INRIA, FR)\n\n1. Evaluation of alternative glyph designs for time series data. 2. Design considerations and guidelines for creating glyphs for time series data. We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting. Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring. Several visualization techniques have, thus, been proposed in the literature. Among these, iconic displays or glyphs are an appropriate choice because of their expressiveness and effective use of screen space. Through a controlled experiment, we compare the performance of four glyphs that use different combinations of visual variables to encode two properties of temporal data: a) the position of a data point in time and b) the quantitative value of this data point. Our results show that depending on tasks and data density, the chosen glyphs performed differently. Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations. From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.\n\nPTBWed. 4pm Paper: Materials, Materiality, and Media\n\nV. Fuchsberger (Univ. of Salzburg, AT), M. Murer, M. Tscheligi\n\nV. Fuchsberger (Univ. of Salzburg, AT)M. Murer (Univ. of Salzburg, AT)M. Tscheligi (Univ. of Salzburg, AT)\n\nReflects on Marshall McLuhan’s media analysis, as well as Bruno Latour’s Actor-Network Theory regarding materials in HCI interaction design. Presents transferred ideas and junctures for the materiality discourse. In HCI, and especially in interaction design, the material aspect of interactions is currently emphasized. Nevertheless, it is challenging to theoretically frame the variety of digital or immaterial, and physical materials. In order to contribute to this materiality discourse, we reflect on McLuhan’s work on media analysis and on Latour’s Actor-Network Theory in this paper. Both emphasize the active role of the material – be it media or any other kind of non-human actors – in the interplay with the human. Thus, we establish junctures between their findings and materials, as used in interaction design in HCI. We discuss McLuhan’s claim to focus on new sensory effects and ways of interaction brought forth by new media. Furthermore, we illustrate how describing the connections between materials, designers, and users in terms of Latour’s Actor-Networks can be beneficial for interaction design. Finally, we discuss the respective methodology and its relation to research through design.\n\nPLGThu. 2pm Paper: Indoor Weather Stations: Investigating a Ludic Approach to Environmental HCI Through Batch Prototyping\n\nW. Gaver (Goldsmiths, Univ. of London, UK), J. Bowers, K. Boehner, A. Boucher, D. Cameron, M. Hauenstein, N. Jarvis, S. Pennington\n\nW. Gaver (Goldsmiths, Univ. of London, UK)J. Bowers (Goldsmiths, Univ. of London, UK)K. Boehner (Goldsmiths, Univ. of London, UK)A. Boucher (Goldsmiths, Univ. of London, UK)D. Cameron (Goldsmiths, Univ. of London, UK)M. Hauenstein (Goldsmiths, Univ. of London, UK)N. Jarvis (Goldsmiths, Univ. of London, UK)S. Pennington (Goldsmiths, Univ. of London, UK)\n\nThree ‘weatherstations’, designed to take a ludic approach to environmental issues, were deployed to twenty households. The result is a distinctive example of environmental HCI, batch production, and ludic design.In this project, we investigated how a ludic approach might open new possibilities for environmental HCI by designing three related devices that encourage environmental awareness while eschewing utilitarian or persuasive agendas. In addition, we extended our methodological approach by batch-producing multiple copies of each device and deploying them to 20 households for several months, gathering a range of accounts about how people engaged and used them. The devices, collectively called the ‘Indoor Weather Stations’, reveal the home’s microclimate by highlighting small gusts of wind, the colour of ambient light, and temperature differentials within the home. We found that participants initially tended to relate to the devices in line with two ‘orienting narratives’ of environmental tools or ludic designs, finding the devices disappointing from either perspective. Most of our participants showed lingering affection for the devices, however, for a variety of reasons. We discuss the implications of this ‘sporadic interaction’, and the more general lessons from the project, both for environmental HCI and ludic design.\n\nPAETue. 4pm Paper: Digital Artifacts as Legacy: Exploring the Lifespan and Value of Digital Data\n\nR. Gulotta (Carnegie Mellon Univ., USA), W. Odom, H. Faste, J. Forlizzi\n\nR. Gulotta (Carnegie Mellon Univ., USA)W. Odom (Carnegie Mellon Univ., USA)H. Faste (Carnegie Mellon Univ., USA)J. Forlizzi (Carnegie Mellon Univ., USA)\n\nWe designed interactive systems to investigate how digital materials might be passed down. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. Legacy is the meaningful and complex way in which information, values, and possessions are passed on to others. As digital systems and information become meaningfully parts of people’s everyday and social relationships, it is essential to develop new insights about how technology intersects with legacy and inheritance practices. We designed three interactive systems to investigate how digital materials might be passed down in the future. We conducted in-home interviews with ten parents using the systems to provoke discussion about how technology might support or complicate their existing practices. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. Findings are interpreted to describe design considerations for future work in this emerging space.\n\nPKGTue. 9am Paper: Stories of the Smartphone in Everyday Discourse: Conflict, Tension & Instability\n\nE. Harmon (Univ. of California, Irvine, USA), M. Mazmanian\n\nE. Harmon (Univ. of California, Irvine, USA)M. Mazmanian (Univ. of California, Irvine, USA)\n\nThis analysis of popular stories about the smartphone highlights three areas of conflict, tension and instability relevant to the relationships among values, mobile ICTs, user experience, and everyday practice.As the smartphone proliferates in American society, so too do stories about its value and impact. In this paper we draw on advertisements and news articles to analyze cultural discourse about the smartphone. We highlight two common tropes: one calling for increased technological integration, the other urging individuals to dis-integrate the smartphone from daily life. We examine the idealized subject positions of these two stories and show how both simplistic tropes call on the same overarching values to compel individuals to take opposing actions. We then reflect on the conflicts individuals experience in trying to align and account for their actions in relation to multiple contradictory narratives. Finally, we call for CHI researchers to tell and provoke more complicated stories of technologies and their relationships with values in conversations, publications, and future designs.\n\nPLPMon. 11am Paper: In Search of Learning: Facilitating Data Analysis in Educational Games\n\nE. Harpstead (Carnegie Mellon Univ., USA), B. Myers, V. Aleven\n\nE. Harpstead (Carnegie Mellon Univ., USA)B. Myers (Carnegie Mellon Univ., USA)V. Aleven (Carnegie Mellon Univ., USA)\n\nWe present a toolkit and methodology for recording and analyzing player log data in educational games, that allows game designers and researches multiple ways to explore student learning.The field of Educational Games has seen many calls for added rigor. One avenue for improving the rigor of the field is developing more generalizable methods for measuring student learning within games. Throughout the process of development, what is relevant to measure and assess may change as a game evolves into a finished product. The field needs an approach for game developers and researchers to be able to prototype and experiment with different measures that can stand up to rigorous scrutiny, as well as provide insight into possible new directions for development. We demonstrate a toolkit and analysis tools that capture and analyze students’ performance within open educational games. The system records relevant events during play, which can be used for analysis of player learning by designers. The tools support replaying student sessions within the original game’s environment, which allows researchers and developers to explore possible explanations for student behavior. Using this system, we were able to facilitate a number of analyses of student learning in an open educational game developed by a team of our collaborators as well as gain greater insight into student learning with the game and where to focus as we iterate.\n\nPQRWed. 9am Paper: Love it or Hate it! Interactivity and User Types\n\nJ. Hart (The Univ. of Manchester, UK), A. Sutcliffe, A. De Angeli\n\nJ. Hart (The Univ. of Manchester, UK)A. Sutcliffe (The Univ. of Manchester, UK)A. De Angeli (Univ. of Trento, IT)\n\nDemonstrates a mixed methods approach that identifies the importance of interactivity and repeated exposure in positively influencing UX and shows that different levels of UX can be explained through use typesThis paper investigates general and individual evaluations of User Experience (UX) with interactive web sites. A series of studies investigate user judgment on web sites with different interactivity levels over repeated exposures. The more interactive websites produced more positive affect, had better design quality ratings, which improved with exposure, and were preferred. Differences between the more interactive sites indicated overall UX was influenced by users’ preferences for interactive styles, with both sites having enthusiast, potential adopter, and non-adopter users. The implications for models and frameworks of UX are discussed.\n\nPAGWed. 9am Paper: Extracting Usability and User Experience Information from Online User Reviews\n\nS. Hedegaard (Univ. of Copenhagen, DK), J. Simonsen\n\nS. Hedegaard (Univ. of Copenhagen, DK)J. Simonsen (Univ. of Copenhagen, DK)\n\nWe chart the occurrences of usability and user experience dimensions and their associated vocabulary found in online reviews of software and video games. Internet review sites allow consumers to write detailed reviews of products potentially containing information related to user experience (UX) and usability. Using 5198 sentences from 3492 online reviews of software and video games, we investigate the content of online reviews with the aims of (i) charting the distribution of information in reviews among different dimensions of usability and UX, and (ii) extracting an associated vocabulary for each dimension using techniques from natural language processing and machine learning. We (a) find that 13%–49% of sentences in our online reviews pool contain usability or UX information; (b) chart the distribution of four sets of dimensions of usability and UX across reviews from two product categories; (c) extract a catalogue of important word stems for a number of dimensions. Our results suggest that a greater understanding of users’ preoccupation with different dimensions of usability and UX may be inferred from the large volume of self-reported experiences online, and that research focused on identifying pertinent dimensions of usability and UX may benefit further from empirical studies of user-generated experience reports.\n\nPBDTue. 11am Paper: Designing Action-based Exergames for Children with Cerebral Palsy\n\nH. Hernandez (Queen’s Univ., CA), Z. Ye, T. Graham, D. Fehlings, L. Switzer\n\nH. Hernandez (Queen’s Univ., CA)Z. Ye (Queen’s Univ., CA)T. Graham (Queen’s Univ., CA)D. Fehlings (Holland Bloorview Kids Rehabilitation Hospital, CA)L. Switzer (Holland Bloorview Kids Rehabilitation Hospital, CA)\n\nWe present guidelines for the design of action-oriented exergames for people with motor disabilities. These preserve the core message of traditional guidelines, while mitigating their push to slow-paced gameplay.Children with cerebral palsy (CP) want to play fast-paced action-oriented videogames similar to those played by their peers without motor disabilities. This is particularly true of exergames, whose physically-active gameplay matches the fast pace of action games. But disabilities resulting from CP can make it difficult to play action games. Guidelines for developing games for people with motor disabilities steer away from high-paced action, including recommendations to avoid the need for time-sensitive actions and to keep game pace slow. Through a year-long participatory design process with children with CP, we have discovered that it is in fact possible to develop action-oriented exergames for children with CP at level III on the Gross Motor Function Classification Scale. We followed up the design process with an eight-week home trial, in which we found the games to be playable and enjoyable. In this paper, we discuss the design of these games, and present a set of design recommendations for how to achieve both action-orientation and playability.\n\nPSHThu. 11am Paper: Evaluation of Tablet Apps to Encourage Social Interaction in Children with Autism Spectrum Disorders\n\nJ. Hourcade (Univ. of Iowa, USA), S. Williams, E. Miller, K. Huebner, L. Liang\n\nJ. Hourcade (Univ. of Iowa, USA)S. Williams (Univ. of Iowa, USA)E. Miller (Univ. of Iowa, USA)K. Huebner (Univ. of Iowa, USA)L. Liang (Univ. of Iowa, USA)\n\nComparison of app-based and paper-based activities by children with autism spectrum disorders. Using the apps was associated with increased verbal communication, physical interaction, and supportive comments.The increasing rates of diagnosis for Autism Spectrum Disorders (ASDs) have brought unprecedented attention to these conditions. Interventions during childhood can increase the likelihood of independent living later in life, but most adults with ASDs who benefited from early intervention do not live independently. There is a need for novel therapies and interventions that can help children with ASDs develop the social skills necessary to live independently. Since the launch of the iPad, there has been a great deal of excitement in the autism community about multitouch tablets and their possible use in interventions. There are hundreds of apps listed as possibly helping children with ASDs, yet there is little empirical evidence that any of them have positive effects. In this paper we present a study on the use of a set of apps from Open Autism Software at an afterschool program for children with ASDs. The apps are designed to naturally encourage positive social interactions through creative, expressive, and collaborative activities. The study compared activities conducted with the apps to similar activities conducted without the apps. We video recorded the activities, and coded children’s behavior. We found that during the study children spoke more sentences, had more verbal interactions, and were more physically engaged with the activities when using the apps. We also found that children made more supportive comments during activities conducted with two of the apps. The results suggest the approach to using apps evaluated in this paper can increase positive social interactions in children with ASDs.\n\nPEMThu. 2pm Paper: Whoo.ly: Facilitating Information Seeking For Hyperlocal Communities Using Social Media\n\nY. Hu (Arizona State Univ., USA), S. Farnham, A. Monroy-Hernández\n\nY. Hu (Arizona State Univ., USA)S. Farnham (Microsoft Research, USA)A. Monroy-Hernández (Microsoft Research, USA)\n\nWe present Whoo.ly, an extraction service for hyperlocal information: events, topics, people and places; from neighborhood-specific tweets. We demonstrate that users prefer its use for neighborhood exploration over competing approaches. Social media systems promise powerful opportunities for people to connect to timely, relevant information at the hyper local level. Yet, finding the meaningful signal in noisy social media streams can be quite daunting to users. In this paper, we present and evaluate Whoo.ly, a web service that provides neighborhood-specific information based on Twitter posts that were automatically inferred to be hyperlocal. Whoo.ly automatically extracts and summarizes hyperlocal information about events, topics, people, and places from these Twitter posts. We provide an overview of our design goals with Whoo.ly and describe the system including the user interface and our unique event detection and summarization algorithms. We tested the usefulness of the system as a tool for finding neighborhood information through a comprehensive user study. The outcome demonstrated that most participants found Whoo.ly easier to use than Twitter and they would prefer it as a tool for exploring their neighborhoods.\n\nPDSMon. 4pm Paper: Mastering the Art of War: How Patterns of Gameplay Influence Skill in Halo\n\nJ. Huang (Univ. of Washington, USA), T. Zimmermann, N. Nagapan, C. Harrison, B. Phillips\n\nJ. Huang (Univ. of Washington, USA)T. Zimmermann (Microsoft Research, USA)N. Nagapan (Microsoft Research, USA)C. Harrison (Microsoft, USA)B. Phillips (Microsoft, USA)\n\nWe look at patterns of skill through large-scale gameplay analysis and player surveys to identify how different factors (play intensity, skill change over time, demographics, breaks, and prior games played) affect players’ skill in Halo.How do video game skills develop, and what sets the top players apart? We study this question of skill through a rating generated from repeated multiplayer matches called TrueSkill. Using these ratings from 7 months of games from over 3 million players, we look at how play intensity, breaks in play, skill change over time, and other games affect skill. These analyzed factors are then combined to model future skill and games played; the results show that skill change in early matches is a useful metric for modeling future skill, while play intensity explains eventual games played. The best players in the 7-month period, who we call “Master Blasters”, have varied skill patterns that often run counter to the trends we see for typical players. The data analysis is supplemented with a 70 person survey to explore how players’ self-perceptions compare to the gameplay data; most survey responses align well with the data and provide insight into player beliefs and motivation. Finally, we wrap up with a discussion about hiding skill information from players, and implications for game designers.\n\nPGJThu. 11am Paper: Canyon: Providing Location Awareness of Multiple Moving Objects in a Detail View on Large Displays\n\nA. Ion (Univ. of Applied Sciences Upper Austria, AT), Y. Chang, M. Haller, M. Hancock, S. Scott\n\nA. Ion (Univ. of Applied Sciences Upper Austria, AT)Y. Chang (Univ. of Waterloo, CA)M. Haller (Univ. of Applied Sciences Upper Austria, AT)M. Hancock (Univ. of Waterloo, CA)S. Scott (Univ. of Waterloo, CA)\n\nA novel interaction technique, Canyon, was implemented and evaluated addressing the problem of data exiting a person’s field of view on large displays. Results indicate higher accuracy and comparable speed.Overview+Detail interfaces can be used to examine the details of complex data while retaining the data’s overall context. Dynamic data introduce challenges for these interfaces, however, as moving objects may exit the detail view, as well as a person’s field of view if they are working at a large interactive surface. To address this “off-view” problem, we propose a new information visualization technique, called Canyon. This technique attaches a small view of an off-view object, including some surrounding context, to the external boundary of the detail view. The area between the detail view and the region containing the off-view object is virtually “folded” to conserve space. A comparison study was conducted contrasting the benefits and limitations of Canyon to an established technique, called Wedge. Canyon was more accurate across a number of tasks, especially more complex tasks, and was comparably efficient.\n\nPSTTue. 9am Paper: Echoes From the Past: How Technology Mediated Reflection Improves Well-Being\n\nE. Isaacs (Palo Alto Research Center (PARC), USA), A. Konrad, A. Walendowski, T. Lennig, V. Hollis, S. Whittaker\n\nE. Isaacs (Palo Alto Research Center (PARC), USA)A. Konrad (Univ. of California, Santa Cruz, Santa Cruz)A. Walendowski (Samsung Research America, USA)T. Lennig (Univ. of California at Santa Cruz , USA)V. Hollis (Univ. of California at Santa Cruz , USA)S. Whittaker (Univ. of California at Santa Cruz, USA)\n\nWe explored technology mediated reminiscence (TMR) by building Echo, a novel smartphone application for recording and reflecting on everyday experiences. Three deployments with 44 users show TMR improves well-being.As people document more of their lives online, some recent systems are encouraging people to later revisit those recordings, a practice we’re calling technology-mediated reflection (TMR). Since we know that unmediated reflection benefits psychological well-being, we explored whether and how TMR affects well-being. We built Echo, a smartphone application for recording everyday experiences and reflecting on them later. We conducted three system deployments with 44 users who generated over 12,000 recordings and reflections. We found that TMR improves well-being as assessed by four psychological metrics. By analyzing the content of these entries we discovered two mechanisms that explain this improvement. We also report benefits of very long-term TMR.\n\nPMVWed. 4pm Paper: Infrastructure and Vocation: Field, Calling, and Computation in Ecology\n\nS. Jackson (Cornell Univ., USA), S. Barbrow\n\nS. Jackson (Cornell Univ., USA)S. Barbrow (Univ. of Michigan, USA)\n\nEthnographic study exploring relationship between computational change and ecology as a vocation. Argues that new computational development remediates ecology’s crucial field relations, with implications for design and engagement.HCI studies of computational change in the sciences have made important design and analytic contributions, to other fields of science and to HCI itself. But some of the longer-term effects and complexities of infrastructural change in the sciences aren’t easily captured under short-term, design- or artifact-centered accounts. Drawing on extended ethnographic study of computational development in ecology, this paper explores the relationship between new computational infrastructure and the nature of ecology as a vocation: roughly, the deeply held sense of what it means to ‘be’ an ecologist, and to ‘do’ ecology. We analyze in particular the nature of the field and field work as a central site of ecological practice and identity; how new computational developments are remediating this crucial relation; and the emergent vocational values that new and more computationally-intensive forms of ecology may give rise to.\n\nPJBMon. 11am Paper: A Conversation Between Trees: What Data Feels Like In The Forest\n\nR. Jacobs (The Univ. of Nottingham, UK), S. Benford, M. Selby, M. Golembewski, D. Price, G. Giannachi\n\nR. Jacobs (The Univ. of Nottingham, UK)S. Benford (The Univ. of Nottingham, UK)M. Selby (The Univ. of Nottingham, UK)M. Golembewski (The Univ. of Nottingham, UK)D. Price (The Univ. of Nottingham, UK)G. Giannachi (The Univ. of Exeter, UK)\n\nStudy of an environmentally engaged artwork reveals how artists’ strategies of embodying, performing and juxtaposing different views of climate data fostered emotional engagement and interpretation among visitors.A study of an interactive artwork shows how artists engaged the public with scientific climate change data. The artwork visualised live environmental data collected from remote trees, alongside both historical and forecast global CO2 data. Visitors also took part in a mobile sensing experience in a nearby forest. Our study draws on the perspectives of the artists, visitors and a climate scientist to reveal how the work was designed and experienced. We show that the artists adopted a distinct approach that fostered an emotional engagement with data rather than an informative or persuasive one. We chart the performative strategies they used to achieve this including sensory engagement with data, a temporal structure that balanced liveness with slowness, and the juxtaposition of different treatments of the data to enable interpretation and dialogue.\n\nNTQThu. 11am Note: Picode: Inline Photos Representing Posture Data in Source Code\n\nJ. Kato (The Univ. of Tokyo, JP), D. Sakamoto, T. Igarashi\n\nJ. Kato (The Univ. of Tokyo, JP)D. Sakamoto (The Univ. of Tokyo, JP)T. Igarashi (The Univ. of Tokyo, JP)\n\nPicode is a text-based development environment augmented with inline photos of human and robots. They contain richer context information than mere posture data, and enhance the programming experience.Current programming environments use textual or symbolic representations. While these representations are appropriate for describing logical processes, they are not appropriate for representing raw values such as human and robot posture data, which are necessary for handling gesture input and controlling robots. To address this issue, we propose Picode, a text-based development environment integrated with visual representations: photos of human and robots. With Picode, the user first takes a photo to bind it to posture data. S/he then drag-and-drops the photo into the code editor, where it is displayed as an inline image. A preliminary in-house user study implied positive effects of taking photos on the programming experience.\n\nPNTTue. 9am Paper: Tables in the Wild: Lessons Learned from a Large-Scale Multi-Tabletop Deployment\n\nA. Kharrufa (Newcastle Univ., UK), M. Balaam, P. Heslop, D. Leat, P. Dolan, P. Olivier\n\nA. Kharrufa (Newcastle Univ., UK)M. Balaam (Newcastle Univ., UK)P. Heslop (Newcastle Univ., UK)D. Leat (Newcastle Univ., UK)P. Dolan (Northumbria Univ., UK)P. Olivier (Newcastle Univ., UK)\n\nThe paper presents the analysis of our observations and design recommendations for multi-tabletop applications designed for and deployed within a realistic classroom setting.This paper presents the results and experiences of a six-week deployment of multiple digital tabletops in a school. Dillenbourg’s orchestration framework was used both to guide the design and analysis of the study. Four themes, which directly relate to the design of the technology for the classroom, out of the 15 orchestration factors are considered. For each theme, we present our design choices, the relevant observations, feedback from teachers and students, and we conclude with a number of lessons learned in the form of design recommendations. The distinguishing factors of our study are its scale (in terms of duration, number of classes, subjects, and teachers), and its ‘in-the-wild’ character, with the entire study being conducted in a school, led by the teachers, and using teacher-prepared, curriculum-based tasks. Our primary contributions are the analysis of our observations and design recommendations for future multi-tabletop applications designed for and deployed within the classroom. Our analyses and recommendations meaningfully extend HCI’s current design understandings of such settings.\n\nPHYMon. 2pm Paper: TapBoard: Making a Touch Screen Keyboard More Touchable\n\nS. Kim (KAIST (Korea Advanced Institute of Science and Technology), KR), J. Son, G. Lee, H. Kim, W. Lee\n\nS. Kim (KAIST (Korea Advanced Institute of Science and Technology), KR)J. Son (KAIST (Korea Advanced Institute of Science and Technology), KR)G. Lee (KAIST (Korea Advanced Institute of Science and Technology), KR)H. Kim (KAIST (Korea Advanced Institute of Science and Technology), KR)W. Lee (KAIST (Korea Advanced Institute of Science and Technology), KR)\n\nTapBoard is a touch screen software keyboard that regards tapping actions as keystrokes and enables other touches for more useful operations; such as resting, feeling surface textures, and making gestures.A physical keyboard key has three states, whereas a touch screen usually has only two. Due to this difference, the state corresponding to the touched state of a physical key is missing in a touch screen keyboard. This touched state is an important factor in the usability of a keyboard. In order to recover the role of a touched state in a touch screen, we propose the TapBoard, a touch screen software keyboard that regards tapping actions as keystrokes and other touches as the touched state. In a series of user studies, we validate the effectiveness of the TapBoard concept. First, we show that tapping to type is in fact compatible with the existing typing skill of most touch screen keyboard users. Second, users quickly adapt to the TapBoard and learn to rest their fingers in the touched state. Finally, we confirm by a controlled experiment that there is no difference in text-entry performance between the TapBoard and a traditional touch screen software keyboard. In addition to these experimental results, we demonstrate a few new interaction techniques that will be made possible by the TapBoard.\n\nPAUThu. 11am Paper: How Tools in IDEs Shape Developers’ Navigation Behavior\n\nJ. Krämer (RWTH Aachen Univ., DE), T. Karrer, J. Kurz, M. Wittenhagen, J. Borchers\n\nJ. Krämer (RWTH Aachen Univ., DE)T. Karrer (RWTH Aachen Univ., DE)J. Kurz (RWTH Aachen Univ., DE)M. Wittenhagen (RWTH Aachen Univ., DE)J. Borchers (RWTH Aachen Univ., DE)\n\nIntroduces a model to describe the code navigation behavior of programmers; this model can be used to analyze the influence of different call graph navigation tools on navigation strategies.Understanding source code is crucial for successful software maintenance, and navigating the call graph is especially helpful to understand source code. We compared maintenance performance across four different development environments: an IDE without any call graph exploration tool, a Call Hierarchy tool as found in Eclipse, and the tools Stacksplorer and Blaze. Using any of the call graph exploration tools more developers could solve certain maintenance tasks correctly. Only Stacksplorer and Blaze, however, were also able to decrease task completion times, although the Call Hierarchy offers access to a larger part of the call graph. To investigate if this result was caused by a change in navigation behavior between the tools, we used a set of predictive models to create formally comparable descriptions of programmer navigation. The results suggest that the decrease in task completion times has been caused by Stacksplorer and Blaze promoting call graph navigation more than the Call Hierarchy tool.\n\nPJRTue. 9am Paper: Challenges and Opportunities for Technology in Foreign Language Classrooms\n\nK. Kuksenok (Univ. of Washington, USA), M. Brooks, Q. Wang, C. Lee\n\nK. Kuksenok (Univ. of Washington, USA)M. Brooks (Univ. of Washington, USA)Q. Wang (Univ. of Washington, USA)C. Lee (Univ. of Washington, USA)\n\nThe roles of artifacts in language learning, based on ethnographic study of introductory Russian classrooms, informing design for this stressful, yet creative, cooperative environment.We present the results of a two-month ethnographic study of three introductory Russian classrooms. Through observation and interviews, we identify several distinct roles played by physical artifacts in the classrooms, such as providing a reference to necessary foreign-language material and serving as props in creative role-play. The range of roles taken on by artifacts and the attitudes students have toward them provide a basis for our discussion about how technology might be more effectively introduced into the socially negotiated environment of the introductory foreign-language classroom. We identify the need to balance between collaborative and personal technology in a stressful, but social, context. Our findings inform a range of roles that technology can undertake in replacing or augmenting existing classroom artifacts.\n\nNFDTue. 4pm Note: Warping Time for More Effective Real-Time Crowdsourcing\n\nW. Lasecki (Univ. of Rochester, USA), C. Miller, J. Bigham\n\nW. Lasecki (Univ. of Rochester, USA)C. Miller (Univ. of Rochester, USA)J. Bigham (Univ. of Rochester, USA)\n\nWe present TimeWarp, a crowdsourcing approach that allows workers to individually complete continuous tasks that involve streaming media at reduced speeds, while the crowd can collectively keep up with real-time. In this paper, we introduce the idea of ”warping time” to improve crowd performance on the difficult task of captioning speech in real-time. Prior work has shown that the crowd can collectively caption speech in real-time by merging the partial results of multiple workers. Because non-expert workers cannot keep up with natural speaking rates, the task is frustrating and prone to errors as workers buffer what they hear to type later. The TimeWarp approach automatically increases and decreases the speed of speech playback systematically across individual workers who caption only the periods played at reduced speed. Studies with 139 remote crowd workers and 24 local participants show that this approach improves median coverage (14.8%), precision (11.2%), and per-word latency (19.1%). Warping time may also help crowds outperform individuals on other difficult real-time performance tasks.\n\nPERTue. 2pm Paper: Sublimate: State-Changing Virtual and Physical Rendering to Augment Interaction with Shape Displays\n\nD. Leithinger (Massachusetts Institute of Technology, USA), S. Follmer, A. Olwal, S. Luescher, A. Hogge, J. Lee, H. Ishii\n\nD. Leithinger (Massachusetts Institute of Technology, USA)S. Follmer (Massachusetts Institute of Technology, USA)A. Olwal (Massachusetts Institute of Technology, USA)S. Luescher (Massachusetts Institute of Technology, USA)A. HoggeJ. Lee (Media Lab, USA)H. Ishii (Massachusetts Institute of Technology, USA)\n\nSublimate co-locates spatial 3D visuals with actuated shape displays. We introduce interfaces and applications that combine virtual graphics and physical form, and explores the transitions between those states.Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and vaporization, as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video see-through AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how free- hand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.\n\nPCLWed. 9am Paper: Flights in my Hands: Coherence Concerns in Designing Strip’TIC, a Tangible Space for Air Traffic Controllers\n\nC. Letondal (ENAC, FR), C. Hurter, R. Lesbordes, J. Vinot, S. Conversy\n\nC. Letondal (ENAC, FR)C. Hurter (ENAC, FR)R. Lesbordes (DGAC DSNA, FR)J. Vinot (ENAC, FR)S. Conversy (ENAC, FR)\n\nWe reflect upon the design of a paper-based tangible space to support air traffic control. We propose a new account of coherence for mixed interaction that integrates cognitive externalization mechanisms.We reflect upon the design of a paper-based tangible interactive space to support air traffic control. We have observed, studied, prototyped and discussed with controllers a new mixed interaction system based on Anoto, video projection, and tracking. Starting from the understanding of the benefits of tangible paper strips, our goal is to study how mixed physical and virtual augmented data can support the controllers’ mental work. The context of the activity led us to depart from models that are proposed in tangible interfaces research where coherence is based on how physical objects are representative of virtual objects. We propose a new account of coherence in a mixed interaction system that integrates externalization mechanisms. We found that physical objects play two roles: they act both as representation of mental objects and as tangible artifacts for interacting with augmented features. We observed that virtual objects represent physical ones, and not the reverse, and, being virtual representations of physical objects, should seamlessly converge with the cognitive role of the physical object. Finally, we show how coherence is achieved by providing a seamless interactive space.\n\nPDCThu. 11am Paper: Modeling How People Extract Color Themes from Images\n\nS. Lin (Stanford Univ., USA), P. Hanrahan\n\nS. Lin (Stanford Univ., USA)P. Hanrahan (Stanford Univ., USA)\n\nWe present a method for extracting color themes from images, using a regression model trained on themes people extract. Model-extracted themes match the source image more closely than previous approaches.Color choice plays an important role in works of graphic art and design. However, it can be difficult to choose a compelling set of colors, or emph{color theme}, from scratch. In this work, we present a method for extracting color themes from images using a regression model trained on themes created by people. We collect 1600 themes from Mechanical Turk as well as from artists. We find that themes extracted by Turk participants were similar to ones extracted by artists. In addition, people tended to select diverse colors and focus on colors in salient image regions. We show that our model can match human-extracted themes more closely compared to previous work. Themes extracted by our model were also rated higher as representing the image than previous approaches in a Mechanical Turk study.\n\nPRCMon. 11am Paper: Health Vlogger-Viewer Interaction in Chronic Illness Management\n\nL. Liu (Univ. of Washington, USA), J. Huh, T. Neogi, K. Inkpen, W. Pratt\n\nL. Liu (Univ. of Washington, USA)J. Huh (Univ. of Washington, USA)T. Neogi (Univ. of Washington, USA)K. Inkpen (Microsoft Research, USA)W. Pratt (Univ. of Washington, USA)\n\nHealth vlogs allow individuals with chronic illnesses to share experiences. We examined methods that vloggers use to connect with viewers. We present design implications that facilitate sustainable communities for vloggers.Health video blogs (vlogs) allow individuals with chronic illnesses to share their stories, experiences, and knowledge with the general public. Furthermore, health vlogs help in creating a connection between the vlogger and the viewers. In this work, we present a qualitative study examining the various methods that health vloggers use to establish a connection with their viewers. We found that vloggers used genres to express specific messages to their viewers while using the uniqueness of video to establish a deeper connection with their viewers. Health vloggers also explicitly sought interaction with their viewers. Based on these results, we present design implications to help facilitate and build sustainable communities for vloggers.\n\nPQJTue. 2pm Paper: Looking Past Yesterday’s Tomorrow: Using Futures Studies Methods to Extend the Research Horizon\n\nJ. Mankoff (Carnegie Mellon Univ., USA), H. Faste, J. Rode\n\nJ. Mankoff (Carnegie Mellon Univ., USA)H. Faste (Carnegie Mellon Univ., USA)J. Rode (Drexel Univ., USA)\n\nA review of futures studies methods used to forecast and think critically about alternative futures and their relevance for HCI research.Doing research is, in part, an act of foresight. Even though it is not explicit in many projects, we especially value research that is still relevant five, ten or more years after it is completed. However, published research in the field of interactive computing (and technology research in general) often lacks evidence of systematic thinking about the long-term impacts of current trends. For example, trends on an exponential curve change much more rapidly than intuition predicts. As a result, research may accidentally emphasize near-term thinking. When thinking about the future is approached systematically, we can critically examine multiple potential futures, expand the set of externalities under consideration, and address both negative and positive forecasts of the future. The field of Futures Studies provides methods that can support analysis of long-term trends, support the identification of new research areas and guide design and evaluation. We survey methods for futuristic thinking and discuss their relationship to Human Computer Interaction. Using the sustainability domain an example, we present a case study of a Futures Studies approach–the Delphi Method. We show how Futures Studies can be incorporated into Human Computer Interaction and highlight future work such as rethinking the role of externalities in the validation process.\n\nPAVMon. 4pm Paper: Using Crowdsourcing to Support Pro-Environmental Community Activism\n\nE. Massung (Univ. of Bristol, UK), D. Coyle, K. Cater, M. Jay, C. Preist\n\nE. Massung (Univ. of Bristol, UK)D. Coyle (Univ. of Bristol, UK)K. Cater (Univ. of Bristol, UK)M. Jay (Univ. of Bristol, UK)C. Preist (Univ. of Bristol, UK)\n\nWe developed mobile applications and investigated motivational techniques to support crowdsourcing and pro-environmental community activism. The paper offers new insights and recommendations for environmental technologies targeting communities, rather than individuals.Community activist groups typically rely on core groups of highly motivated members. In this paper we consider how crowdsourcing strategies can be used to supplement the activities of pro-environmental community activists, thus increasing the scalability of their campaigns. We focus on mobile data collection applications and strategies that can be used to engage casual participants in pro-environmental data collection. We report the results of a study that used both quantitative and qualitative methods to investigate the impact of different motivational factors and strategies, including both intrinsic and extrinsic motivators. The study compared and provides empirical evidence for the effectiveness of two extrinsic motivation strategies, pointification – a subset of gamification – and financial incentives. Prior environmental interest is also assessed as an intrinsic motivation factor. In contrast to previous HCI research on pro-environmental technology, much of which has focused on individual behavior change, this paper offers new insights and recommendations on the design of systems that target groups and communities.\n\nPHVMon. 2pm Paper: Community Insights: Helping Community Leaders Enhance the Value of Enterprise Online Communities\n\nT. Matthews (IBM Research, USA), S. Whittaker, H. Badenes, B. Smith, M. Muller, K. Ehrlich, M. Zhou, T. Lau\n\nT. Matthews (IBM Research, USA)S. Whittaker (Univ. of California at Santa Cruz, USA)H. Badenes (IBM, AR)B. Smith (IBM Research, USA)M. Muller (IBM, USA)K. Ehrlich (IBM, USA)M. Zhou (IBM Research, USA)T. Lau (Willow Garage, USA)\n\nEvidence-based design and evaluation of a novel tool that provides community leaders with useful, actionable, and contextualized analytics. Benefits designers of and practitioners using analytic tools to foster successful communities.Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member- rather than leader-centric. We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.\n\nPTSTue. 2pm Paper: Imaging the Body: Embodied Vision in Minimally Invasive Surgery\n\nH. Mentis (Microsoft Research, UK), A. Taylor\n\nH. Mentis (Microsoft Research, UK)A. Taylor (Microsoft Research, UK)\n\nPresents findings concerning the constructed and embodied use of images during neurosurgery. Lends itself to a discussion of the directions for new imaging interaction technologies. Recent years have seen the possibilities of new imaging and interaction technologies for minimally invasive surgery such as touchless interaction and high definition renderings of three-dimensional anatomy. With this paper we take a step back to review the historical introduction and assimilation of imaging technologies in the surgical theatre in parallel with the productive and cross-referential nature of surgical practice and image use. We present findings from a field study of image use during neurosurgery where we see that the work to see medical images is highly constructed and embodied with the action of manipulating the body. This perspective lends itself to a discussion of the directions for new imaging interaction technologies.\n\nNNMTue. 9am Note: Direct Manipulation Video Navigation in 3D\n\nC. Nguyen (Portland State Univ., USA), Y. Niu, F. Liu\n\nC. Nguyen (Portland State Univ., USA)Y. Niu (Portland State Univ., USA)F. Liu (Portland State Univ., USA)\n\nThis paper presents a 3D DMVN system that visualizes the video frame and motion in 3D, resolves temporal ambiguities, and allows a user to manipulate an object along its trajectory. Direct Manipulation Video Navigation (DMVN) systems allow a user to navigate a video by dragging an object along its motion trajectory. These systems have been shown effective for space-centric video browsing. Their performance, however, is often limited by temporal ambiguities in a video with complex motion, such as recurring motion, self-intersecting motion, and pauses. The ambiguities come from reducing the 3D spatial-temporal motion (x, y, t) to the 2D spatial motion (x, y) in visualizing the motion and dragging the object. In this paper, we present a 3D DMVN system that maps the spatial-temporal motion (x, y, t) to 3D space (x, y, z) by mapping time t to depth z, visualizes the motion and video frame in 3D, and allows to navigate the video by spatial-temporally manipulating the object in 3D. We show that since our 3D DMVN system preserves all the motion information, it resolves the temporal ambiguities and supports intuitive navigation on challenging videos with complex motion.\n\nNPJMon. 4pm Note: Touchbugs: Actuated Tangibles on Multi-Touch Tables\n\nD. Nowacka (Newcastle Univ., UK), K. Ladha, N. Hammerla, D. Jackson, C. Ladha, E. Rukzio, P. Olivier\n\nD. Nowacka (Newcastle Univ., UK)K. Ladha (Newcastle Univ., UK)N. Hammerla (Newcastle Univ., UK)D. Jackson (Newcastle Univ., UK)C. Ladha (Newcastle Univ., UK)E. Rukzio (Ulm Univ., DE)P. Olivier (Newcastle Univ., UK)\n\nWe present a novel approach to graspable interfaces using Touchbugs, small tangibles that are able to move across surfaces by employing vibrating motors and to communicate with interactive surfaces by using infrared LEDs.We present a novel approach to graspable interfaces using Touchbugs, actuated physical objects for interacting with interactive surface computing applications. Touchbugs are active tangibles that are able to move across surfaces by employing vibrating motors and can communicate with camera based multi-touch surfaces using infrared LEDs. Touchbug’s embedded inertial sensors and computational capabilities open a new interaction space by providing autonomous capabilities for tangibles that allow goal directed behavior.\n\nPRYTue. 2pm Paper: Designing for the Living Room: Long-Term User Involvement in a Living Lab\n\nC. Ogonowski (Univ. of Siegen, DE), B. Ley, J. Hess, L. Wan, V. Wulf\n\nC. Ogonowski (Univ. of Siegen, DE)B. Ley (Univ. of Siegen, DE)J. Hess (Univ. of Siegen, DE)L. Wan (Univ. of Siegen, DE)V. Wulf (Univ. of Siegen, DE)\n\nWe present lessons learned from a 2.5 year period of a Living Lab project and discuss aspects that need to be considered when setting up such a research framework.Living Labs provide a research infrastructure for long-term user involvement in Participatory Design processes. Users take part in software co-creation during context analysis, for concept development, reflecting on early-stage prototypes and evaluations in the field. In this paper we describe lessons learned from our Living Lab in the area of home entertainment, with 27 participants from 16 households, over a 2.5 year period. We show that this kind of long-term participation of users involves various challenges over the lifetime of the project. We highlight several aspects that need to be considered carefully when setting up such a Living Lab, concerning the selection of participants, maintenance of participants’ motivation, establishment of a trust relationship, and the coordination of collaboration.\n\nNPVWed. 2pm Note: ZoomBoard: A Diminutive QWERTY Soft Keyboard Using Iterative Zooming for Ultra-Small Devices\n\nS. Oney (Carnegie Mellon Univ., USA), C. Harrison, A. Ogan, J. Wiese\n\nS. Oney (Carnegie Mellon Univ., USA)C. Harrison (Carnegie Mellon Univ., USA)A. Ogan (Carnegie Mellon Univ., USA)J. Wiese (Carnegie Mellon Univ., USA)\n\nWe present Zoomboard, a keyboard that uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size.The proliferation of touchscreen devices has made soft keyboards a routine part of life. However, ultra-small computing platforms like the Sony SmartWatch and Apple iPod Nano lack a means of text entry. This limits their potential, despite the fact they are quite capable computers. In this work, we present a soft keyboard interaction technique called ZoomBoard that enables text entry on ultra-small devices. Our approach uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size. We based our design on a QWERTY layout, so that it is immediately familiar to users and leverages existing skill. As the ultimate test, we ran a text entry experiment on a keyboard measuring just 16 x 6mm – smaller than a US penny. After eight practice trials, users achieved an average of 9.3 words per minute, with accuracy comparable to a full-sized physical keyboard. This compares favorably to existing"
    }
}