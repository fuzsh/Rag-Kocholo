{
    "id": "dbpedia_4874_3",
    "rank": 70,
    "data": {
        "url": "https://www.philipzucker.com/state_o_knuck/",
        "read_more_link": "",
        "language": "en",
        "title": "State of Knuckledragger, a Semi-Automated Python Proof Assistant",
        "top_image": "https://www.philipzucker.com/assets/logo.png",
        "meta_img": "https://www.philipzucker.com/assets/logo.png",
        "images": [
            "https://raw.githubusercontent.com/philzook58/knuckledragger/main/logo.webp"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Hey There Buddo!"
        ],
        "publish_date": "2024-08-05T00:00:00+00:00",
        "summary": "",
        "meta_description": "I’ve been working on Knuckledragger, my Z3 based semi-automated python proof assistant, on and off for 6 months (or arguably five years). I’ve realized I’ve done a bunch of stuff and despite writing often, not written the slightest bit about much of it.",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "Hey There Buddo!",
        "canonical_link": "https://www.philipzucker.com/state_o_knuck/",
        "text": "I’ve been working on Knuckledragger, my Z3 based semi-automated python proof assistant, on and off for 6 months (or arguably five years). I’ve realized I’ve done a bunch of stuff and despite writing often, not written the slightest bit about much of it.\n\nSo here is a fast sketchy run down of:\n\nThe basic design and kernel\n\nIdeas and starts on theories like intervals, complex numbers, set theory, groups, linear algebra, software verification\n\nConvenience systems like tactics, syntax, and systematic approaches to induction principles and refinements.\n\nRepo is here https://github.com/philzook58/knuckledragger\n\nGot a new logo! Been adding docs, tutorials, CI, etc. All that software jazz.\n\nPrevious posts in this vein:\n\nhttps://www.philipzucker.com/python-itp/\n\nhttps://www.philipzucker.com/knuckledrag2/\n\nZ3 Expressions Types\n\nA design principle I’ve narrowed in on is piggy packing on the z3 AST datatypes for my theorem datatypes.\n\nI was toying with making my own first order logic / higher order logic AST in python and then interpreting it into Z3. So far, I think this is an unnecessary indirection and was just burning time, lines of code, and design energy to no benefit. Z3 already has a feature rich access api and maybe the only thing I would have added to my type is built in polymorphism/sort generics.\n\nThis has the benefit that if you know how to write z3 python, you know how to write knuckledragger. If you know smtlib, you know knuckledragger. And regardless of the fate of knuckledragger, these are useful skills.\n\nThis has the downside of me having no control over how Z3 did things. I’m monkey patching in new functions onto ExprRef pretty often, which isn’t great for python tooling and maybe tougher for reading by humans. Things that I would make attributes of a custom class or wrapper I’m instead sometimes putting into a global dictionary to be looked up (single dispatch overloading in particular I’m thinking of).\n\nOn the whole I think the positives outweigh the negatives.\n\nThe Kernel\n\nhttps://github.com/philzook58/knuckledragger/blob/main/knuckledragger/kernel.py\n\nThe core principle of knuckledragger is that it is just as thin as possible framework to chain calls to automated theorem provers in a principled way. By restricting our logic to more or less what the solvers already offer, we get a lot of distance and usability for free. The less code I write the better.\n\nI have a lot of experience using z3 to model problems in python. I like it. However, there is a need to break it up. Z3 does not have a mechanism to distinguish between theorems to be proved and theorems proven.\n\nI had been considering signing Proofs cryptographically or other scams, but I’ve reverted to a pretty straightforward protected Proof datatype.\n\nThe details of what follows have been simplified a bit from what is actually in the library, which has more convenience and safety checks https://github.com/philzook58/knuckledragger/blob/main/knuckledragger/kernel.py\n\nThe proof datatype is constructed through two functions axiom and lemma. Proof itself is made difficult to get at outside of the kernel module (although not impossible). You are not supposed to directly construct Proof itself. It isn’t really protected from construction, since you are always free to call axiom, but that is on you. All interactive theorem provers also have the ability to introduce axioms.\n\nAlso important though is the ability to make new definitions. Without this, you can’t ever abstract much of anything or you need to introduce your new definitions as raw axiom calls every time.\n\nYou also are going to often to want to make recursive definitions. define should check if you are making a recursive definition, but does not currently.\n\nMy current idea about define_fix is to write your definition body in the fixpoint style using a python lambda. I can record all the subcalls easily, which I prefer to digging through the AST. The termination could be discharged via default measure relations or by a call to aprove or similar termination checker.\n\nHaving these global lemma / define functions and global defns dictionaries is a bit goofy. It might be nice to separate into different contexts.\n\nApplications and Theories\n\nI think it is very very important to be example driven. I could definitely spend all my time on making cute little syntax or logic gizmos. Some of that is good, but only when informed by actual problems.\n\nThese are the sorts of theories I’ve been attacking to varying success.\n\nNats\n\nA basic datatype that you expect in a theorem prover is the natural numbers. There is a school of thought that the naturals are the root of mathematics (“God made the integers; all else is the work of man.”).\n\nFrom my perspective, it is unfortunate that smtlib does not offer a built in natural type. Instead it offers an integer type. So two different options for naturals are to cut them out of the built in integers or to use a Peano algerbaic datatype.\n\nPeano\n\nWe can model Naturals using an algebraic datatype consisting of a zero and successor constructor type nat = Zero | Succ of nat.\n\nThis is a principled way of constructing them via a textbook style. It was by first inclination but now I have my doubts.\n\nhttps://www.philipzucker.com/sqrt2_2/ I wrote a bit about this here. I also toyed with an interesting style of defining via reflection into the Ints using reflect reify combinators.\n\nYou can define arithmetic (plus, times, etc) on these things via structural indiction.\n\nYou need to define an induction principle, more on how to do this generally later. For Nats it’s easy to do by hand as an axiom schema (an axiom parametrized by data, in this case the data is a python or z3 lambda specifying a predicate P)\n\nI’ve been finding this kind of clunky to work with.\n\nOr similarly to this a binary datatype (a list of bits type nat = list bool)\n\nNats as subsets\n\nNats can be perceived as part of a general phenomenon of a sort that is a subset of another sort, namely the integers. More on doing this generally in the refinement section.\n\nNats a subset of Ints, but ints are in turn a subset of the reals. There is also utility in considering the nonnegative reals as an entity of interest (real induction).\n\nThere are “induction” principles that directly work over Ints, like two sided induction. Maybe these are useful. https://math.stackexchange.com/questions/4867269/how-does-one-perform-induction-on-integers-in-both-directions\n\nLists\n\nLists are a useful and prominent type. We can define an induction principle similar to the above. Everything needs to be parametrized on the sort in question.\n\nSequences are a built in that may serve better https://microsoft.github.io/z3guide/docs/theories/Sequences/ . They are basically a free monoid type but with some useful stuff that you’d need to define for your own list type.\n\nA suggested induction principle for sequences.\n\nReals\n\nI’ve been thinking about the reals a lot because I want knuckledragger to be good at the kinds of things I would do in an engineering or physics context. Also I want to do basic calculus.\n\nLots and lots of junk on the reals.\n\nAvoiding all the epsilon-delta calculus pain seems desirable, so I’ve been considering alternatives.\n\nformal power series, streams, Nat -> R\n\nReal induction. These might be useful axiom schema to throw in as a version of completeness of the reals. https://math.stackexchange.com/questions/4202/induction-on-real-numbers\n\nsequences\n\nconvergence\n\nintermediate value theorem. Axiomatizing that bisection means something is a relative of completeness.\n\nextended reals. https://en.wikipedia.org/wiki/Extended_real_number_line Make an algebraic datatype with special +- infinity constructors. Relatedly can work with projectively extended https://en.wikipedia.org/wiki/Projectively_extended_real_line with only a single infinity\n\nTry Eudoxus reals? https://en.wikipedia.org/wiki/Construction_of_the_real_numbers#Construction_from_integers_(Eudoxus_reals) . Harrison recommended somewhere.\n\nFormal Power Series\n\nFormal power series are “just” N >> R. They have pointwise addition and a convolutional multiplication. These are normal perfectly computable things. Also division, composition, and inversion. You can also define operations analogous to differentiation and integration. So they’re a cool algebraic thing. You need to show they converge if you want to connect back to more ordinary definitions\n\nhttps://www.cs.dartmouth.edu/~doug/powser.html My all time favorite pearl about power series in haskell.\n\nSympy and sage also have support for these power series like things.\n\nStreams are supported in cvc5 https://cvc5.github.io/docs/cvc5-1.0.0/api/python/pythonic/dt.html . This could be an alternative encoding. Or perhaps take coinduction as an inspiration for our modelling.\n\nDifferentiation\n\nI think the seeds of an approach can be found here https://www.philipzucker.com/z3_diff/\n\nWe can axiomatize a reasonable syntactic-ish differentiation operation. It isn’t connected automatically to the analytic definition, and it can’t be since differentiation is not a total operation on functions.\n\nA “yoneda-like” trick is useful to define a sin = sinR . : (R -> R) -> (R -> R) function because it automatically associates all compose to the right.\n\nRounding\n\nConvergence is a painful thing to deal with. A bit surprising to me, but obvious in hindsight is that you need a good theory of rounding/floor. That’s how you derive the appropriate N for proofs of convergence. https://www.philipzucker.com/analysis_knuckle/\n\nRounding is actually kind of tricky. The z3 built ins ToReal and ToInt are a start, but they don’t have that strong of reasoning power. They need to be helped along a little. This s actually evidence I think of the utility of knuckledragger. I could not get some basic theorems to go through in one shot through z3, but with some guidance I could. This probably has to do with seeding the ematching mechanism or preventing z3 from using some built in theory where it can’t make use of the appropriate high level reasoning.\n\nHyperReals\n\nSequences of R can have an equivalence structure put on them that gives you infinitesimals.\n\nOr can directly axiomatize it and directly build a transfer schema. Doing this makes me uncomfrotable. The schema to do this requires traversal of the ast and tracking of which definitions are tainted by the std predicate.\n\nacl2(R) uses the hyperreals.\n\nhttps://www.researchgate.net/publication/220532005_Nonstandard_analysis_in_ACL2 Gamboa thesis Hyperreals in ACL2 acl2(r). There’s also a chapter in Applications of ACL2 book. Some follow up works. I saw someone\n\nhttps://www.youtube.com/watch?v=U-y8UNccnIw&t=909s&ab_channel=Galois max von hippel is using acl2(r)\n\nThere is a line of older automated reasoning work claiming the hyperreals makes problems way easier (Bledsoe and Ballantyne). The Hyperreals kind of algebrize calculus.\n\nhttps://www.cs.utexas.edu/ftp/techreports/atp71.pdf [3] W. W. Bledsoe. Some automatic proofs in analysis.\n\nhttps://www.sciencedirect.com/science/article/abs/pii/0004370272900410 computer assisted limit theorems 9172 bledsoe\n\nhttps://link.springer.com/article/10.1023/A:1005843328643 The Heine–Borel Challenge Problem. In Honor of Woody Bledsoe\n\nBledsoe, W.: Challenge problems in elementary analysis, Journal of Automated Reasoning 6 (1990),\n\nBledsoe, W. W.: Heine–Borel Theorem Analogy Example, Technical Report Memo ATP 124, University of Texas Computer Science Dept., Austin, TX, 1994.\n\nhttps://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=70050293723ef74d0747323be1cd06eabe5ebbc5 Non resolution theorem proving\n\nBallantyne, M. and Bennett, W., Graphing methods for topological proofs, The University of Texas at Austin Math. Dept. Memo ATP-7 (1973).\n\nBallantyne, A. M. and Bledsoe, W. W., Automatic proofs of theorems in analysis using nonstandard techniques, The University of Texas at Austin Math. Dept. Memo ATP-23 (July 1975); J. ACM, to appear, July 1977. -\n\nA. Michael Ballantyne: The Metatheorist: Automatic Proofs of Theorems in Analysis Using Non-Standard Techniques, Part II.\n\nIsabelle Hyperreals https://isabelle.in.tum.de/library/HOL/HOL-Nonstandard_Analysis/Hyperreal.html\n\nhttps://www.cl.cam.ac.uk/~lp15/papers/Isabelle/fleuriot-princip-CADE.pdf hyperreals applied to newton\n\nComplex\n\nDefining a complex number as a record of its real and imaginary part is very natural.\n\nPowers\n\nWhile z3 has good built in powers x**4, it does not have great reasoning principles for abstract powers x**n\n\nThere is reason to believe I may have to axiomatize it. Power is kind of special. It is a homomorphism between the group of addition and multiplication. https://en.wikipedia.org/wiki/Exponential_field\n\nz3 really doesn’t like reasoning over its native powers. It’s best to wrap them in definitions.\n\nExp, Sine, Cosine\n\nThey’re tricky. Basically they kind of need calculus.\n\nSine and cosine don’t actually because the addition formula (which are relatives of the summation formula for powers)\n\nWould it be good to define sine and cosine through the complex numbers? Maybe.\n\nAn interesting option is bolting in bounds from flint, which I think are as trustworthy as anything I’m doing.\n\nrational trignometry. https://web.maths.unsw.edu.au/~norman/Rational1.htm https://www.cut-the-knot.org/pythagoras/RationalTrig/CutTheKnot.shtml “angles don’t exist” Only the combo sin(theta) not raw theta. https://en.wikipedia.org/wiki/List_of_trigonometric_identities\n\nA simple but good test problem is bounding the value of e from first principles.\n\nSets\n\nAttempting a ZF like set theory. We can postulate a undefined sort Set and give it some properties. Everything is defined by it’s relation to elem which is awkward. ArraySort(Set,BoolSort()) is a useful stand-in for classes.\n\nThere are still kinks to work out for sure.\n\nThis is interesting https://lawrencecpaulson.github.io/2022/02/02/Formalising_Math_Set_theory.html in particular Art Quaife. Automated Deduction in von Neumann–Bernays–Gödel Set Theory. https://rdcu.be/cJtDU\n\nAlternative set theories are intriguing https://plato.stanford.edu/entries/settheory-alternative/ https://en.wikipedia.org/wiki/List_of_alternative_set_theories . Mizar is supposedly based around Tarski Grothedieck\n\nLinear Algebra\n\nLinear algebra is ubiquitously useful and an algebraic theory. I want to attack numpy problems. I the ability to make correctness bounds on numpy operations.\n\nFixed Dimension\n\nA simple but useful thing to do is worry about low dimensional vectors spaces. Dimension 2,3,4 have all sorts of geometric utility.\n\nFinite Dimension\n\nA more mathy thing to do is consider all finite vector spaces.\n\nIt’d be nice to attack it at the level of Linear Algerba done right https://linear.axler.net/ Or Halmos Finite Dimensional Vector Spaces.\n\nCould go totally axiomatic\n\nLists seemed somewhat natural, but actually were a bit awkward.\n\nA universe to work in for finite dimensional algebra is using Z >> R == ArraySort(IntSort(), RealSort()) as a vector space. This has all finite dimensional subspaces in it.\n\nThere is a theme of needing to subset of finite Support (indices for which a vector is possibly non zero) in an infinite space. Sequences / Lists of Nats can supply a way of specifying a support.\n\nGeometry\n\nI have experimented with a purely logical form of postulating an undeclared sort called Point and the Point pairs as a directed segment, then undirected segment as a quotient of this, then lines as a quotient of this, and so on. Probably this is a goofy kind of hard mode. A tower of refining equivalences is an interesting pattern.\n\nMore straightforward is to define Point = Record((\"x\", RealSort()), (\"y\", RealSort())). We can construct Set(Point) such as lines and circles using algebraic constraints line = kd.define(\"line\", [a,b,c] Lambda([p], a * p.x + b * p.y == c)) and circle = kd.define(\"circle\", [c,r], Lambda([p], (p.x - c.x)**2 + (p.x - c.y) ** 2 == r)). is_line can be constructed requiring the Set be affine\n\nGroup Theory\n\nGroup theory is a nice one because it’s very algebraic. The homomorphism theorems are a fairly elementary thing that can be considered real abstract math. It is also difficult to see how to formulate the homomorphism theorem in a meaningful way into ATPs.\n\nIndividual finitely presentable groups seem easy enough to axiomatize directly. Declare sorts and constants and multiplication/identity/inverse functions with the appropriate properties. The Calc macro is nice for proofs. Using sage and hence GAP/Magma can help automatically discharge\n\nA theme I’ve seen is it is nice to have a “Universe” datatype. I think here, permutations on the integers (a subset of Nat -> Nat) is an interesting and rich Universe in which we can embed all countable groups (The content of the Cayley representation). All finite groups are isomorphic to some subset of this object. This is a metafact which maybe we can’t express, because what exactly is a group in the first place? A sort that posesses functions that fit the axioms?\n\nWe could also declare some uninterpreted sort called Grp\n\nCategory Theory\n\nIn some respects, there are roots in this project in my experiences trying to use Z3 and other ATPs as a category theory prover.\n\nhttps://www.philipzucker.com/category-theory-in-the-e-automated-theorem-prover/\n\nhttps://www.philipzucker.com/theorem-proving-for-catlab-2-lets-try-z3-this-time-nope/\n\nI think I knew how to write fully safe axioms, but they had lots of side conditions I thought were redundant. Knuckledragger is principled enough that I could prove these side conditions are unneeded.\n\nSome general helper/tactic framework for embedding Generalized Algebraic theories into z3 seems possible. Discharging typing obligations early, since they are fairly automatic. Help to write/generate the right typing assumptions.\n\nSoftware\n\nModelling CPUs\n\nTwo things systems I think are interesting are modelling the Nand2Tetris CPU and RiscV cpus. The first for educational value, the second maybe could actually be useful.\n\nThe general plan is to define instruction datatypes, a state datatype,\n\nSome nand2tetris circuitry buildup\n\nHoare and WP\n\nI could perhaps make Hoarse as a new judgement, a different kind of Proof. I can also deeply internalize into the system. This might be necessary to use cvc5 separation logic too.\n\nI’ve done deeply internalized WP in smtlib before. It’s kind of clunky.\n\nMetatheory\n\nOn thing people do in proof assistants is logical or programming language metatheory. They want to prove their language is type safe or terminating or that their logic is sound or has other interesting properties.\n\nI need serious investment into the inductive relations subsystem before this becomes more tractable.\n\nNumerical Computation\n\nIntervals\n\nI spent some nice time on a plane doing interval arithmetic. It is tempting to do intervals over the extended reals.\n\nThat intervals can be improper is discomfitting.\n\nI’m particular interested in the ability of interval analysis to give verified bounds on differential / integral equations. There is a fixed point procedure for iteratively improving an approximate solutions to an ODE $y’(t) = Ly(t)$, $y_{n+1}(t) = y(0) + \\int y’{n}(t)dt = y(0) + \\int Ly{n}(t)dt $. This is picard-lindelof iteration / born approximation / other names. If you lift this to intervals, the integral of intervals is seinsibly over approximable. If you can find a interval approximation of y that maps into itself, you can eventually show the true solution must lie within there. A neat kind of bootstrapping.\n\nhttps://www.philipzucker.com/z3_diff/\n\nhttps://www.philipzucker.com/z3-cegar-interval/\n\nhttps://www.philipzucker.com/more-stupid-z3py-tricks-simple-proofs/\n\nComputational Functional Analysis by Moore https://www.amazon.com/Computational-Functional-Analysis-Mathematics-Applications/dp/1904275249\n\nIntroduction to Interval Analysis https://epubs.siam.org/doi/10.1137/1.9780898717716 http://www-sbras.nsc.ru/interval/Library/InteBooks/IntroIntervAn.pdf\n\nmethods and applications of inverval analysis https://epubs.siam.org/doi/book/10.1137/1.9781611970906\n\nInterval Analysis: Application in the Optimal Control Problems\n\nReal Analysis: A Constructive Approach Through Interval Arithmetic - bridger\n\nInterval Methods for Systems of Equations\n\nhttps://fab.cba.mit.edu/classes/S62.12/docs/Hickey_interval.pdf\n\nbishop\n\nConstructive functional analysis\n\nFixed\n\nSMT fixed point airthmetic theory. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7324132/\n\nToInt and ToReal give a theory of rounding. Want to actually work with bitvectors too though.\n\nFloats\n\nI left off last month a bit stumped on the floats. The built in support for Real <-> Float reasoning is pretty weak. I’m not comfortable axiomatizing it. So not super sure how to continue, but I haven’t attacked it recently.\n\nFeatures\n\nMoving on from applications, we can discuss the niceties of syntax or general modelling problems of being in multi-sorted first orderlv logic.\n\nOverloading\n\nThis is honestly one of the most useful things knuckledragger offers right now.\n\nPython has single dispatch in the standard library. https://peps.python.org/pep-0443/ https://docs.python.org/3/library/functools.html#functools.singledispatch Hence, I consider this to be an accepted python pattern.\n\nBut I can’t dispatch on the python class because z3 python does not produce different classes for different sorts. So the thing needs to be modified slightly to dispatch on sorts. This is not too hard to achieve. By monkey patching these dispatch objects onto the operators for ExprRef, we can overload the operators.\n\nhttps://github.com/philzook58/knuckledragger/blob/c02b9521aafdc141364179119256955fcf37ef34/knuckledragger/notation.py#L54\n\nThere is a question whether the overloading mechanism should do interesting search. Multiple dispatch could be nice. Typeclasses could be nice, Oleg style.\n\nDatatype fields\n\nIt is an extremely useful overload to enable getting the fields of z3 datatype via dot notation rather that getting at the accessors through the . It really really makes expressions easier to read, and easiness to read is part of what makes it more likely what you write is what you meant.\n\nPython __getattr__ is what gets called when a field is not found on the class as a fallback. The following snippet then searches through\n\nhttps://github.com/philzook58/knuckledragger/blob/c02b9521aafdc141364179119256955fcf37ef34/knuckledragger/notation.py#L103\n\nNotation\n\nSyntax via https://github.com/lark-parser/lark . lark is a very nice arser generator framework. You actually can mix and match parser fragments. In this way, we could offer a framework for custom syntaxes, including unicode. I have not explored this direction much, as it isn’t really to my taste.\n\nTactics\n\nCalc\n\nA thing I really like is calc tactics. These let you write an equational proof. I’ve moved over to using a Calc python class as it enables better syntax. It can be used either by chaining or by mutation. It is not part of the kernel. It discharges it’s obligations through the kernel function lemma. When you call c.qed() it takes all the equational step lemmas it has found and asks the kernel if they combine from the total left hand side to right hand side.\n\nhttps://github.com/philzook58/knuckledragger/blob/c02b9521aafdc141364179119256955fcf37ef34/knuckledragger/tactics.py#L5\n\nSimp\n\nA simplification tactic is at the core of a good experience. You hammer on these in lean, coq, or isabelle.\n\nI thought maybe I’d need an extensive metaprogramming system to do this but now I’m not so sure.\n\nActually for the first time I found the z3 Tactic system super useful. I can give a Goal the defns database or maybe other simp databases and use demodulator, simplify, elim-predicates, macro-finder as promising simplifiers. By making a dummy variable “knuckle_goal” I can track what is my original term (I saw caleb do this trick). This is not trusted kernel code. Once i have a suspected good simplified term, I can send it to lemma to actually confirm.\n\nI should make a mechanism to store simp databases.\n\nhttps://github.com/AliveToolkit/alive2/blob/fc3ea52ba741306e1595d46753aa2795ca4aaab2/smt/solver.cpp#L584 tactic usage in alive2, the only place I’ve heard of it happening usefully.\n\nOther\n\nBackwards\n\nMizar / Isar combinstors\n\nUnification helper for z3 ast might be nice\n\nBinders\n\nEgraph - Maybe my external z3 egraph https://www.philipzucker.com/ext_z3_egraph/ is good for a tactic. There is also a z3 tactic “euf-completion” which is intriguing\n\nAlternative Solvers\n\nlemma has an extra keyword parameter solver which defaults to z3. By mocking out other solvers, cvc5, vampire etc to match the z3 Solver python interface, they should also be supported. This is a work in progress. There are a variety of utility functions for printing tptp and smtlib. https://github.com/philzook58/knuckledragger/blob/main/knuckledragger/utils.py\n\nLemma Database\n\nSomething I resist is requiring you to give the system a name for every lemma. It would be kind of nice, but then you’ld have to write the names twice my_good_lemma = lemma(\"my_good_lemma\", ...). In other languages like Julia, they have macros for this kind of thing `@lemma my_good_lemma. I kind of hate (other people’s) macros though.\n\nPython is super duper dynamic and introspectable though. A kind of fiendish but cool thing is that I can scan the entire system for Proof objects. Imported modules are just another python object , so by looking into the __dict__, I can find the name you used. This is super hacky just to avoid doing this in a boring way. I’m not sure.\n\nThese databases might be useful for machine learning training sets and for extracting theorem prover competition benchmarks. By erasing intermediate nodes in the proof tree, you can make a sequence of harder and harder problem, until you ask for the top level theorem given only the leaf axioms of the proof.\n\nRefinement and Partiality\n\nThis is a complicated subject and needs to be a post in its own right.\n\nIt is a consistent need to have a good mechanism to talk about subsets of some sort. Dependent type theories use sum types for this. This isn’t quite an option.\n\nOne low effort thing that helps is a notion of quantified forall and exists combinators. These get you a lot of distancew for not too much. If I tag sorts with a special property wf for their well formedness condition, these combinators automatically add that upon quantifying over a variable of that sort.\n\nFree logic https://plato.stanford.edu/entries/logic-free/ . The E predicate is much like my wf. Identical maybe.\n\nThere are some design choices for how to build refinement sorts/ subsets.\n\npredicates describing the subset. Even(x) = Exists([y], x == 2*y)\n\nProjection functions. These are the analog of choice functions to the predicate functions. A projection function is idempotent proj(prof(x)) = x. A projection function defines a subset such that proj(x) = x. Because of idempotency proj(x) always obeys this condition. proj_even(x) = 2 * (x / 2)\n\nNew sorts by fiat E = DeclareSort(\"Even\"), inj = Function(\"inj\", Int, E), proj = Function(\"proj\", E, Int), Implies(Even(x), proj(inj(x)) == x)\n\nNewtype sorts combined with projection functions. The newtypes can also contain useful witnesses. type Even = Even {x : Int, y : Int} wf(e) = e.x == 2*e.y\n\nExistentials\n\nManual skolemization is probably wise. You can often find a natural candidate for naming these things when you do it manually. THis is important, because you can then help z3 along. Z3 is not strong at nested quantifiers. Maybe with Vampire coming online, I can suffer more quantifier nesting.\n\nFor example even(x) = exists y, x == 2*y. However, there is an obvious definition\n\nLambdas\n\nUse lambdas sparingly and defunctionalize immediately. You will be surprised by what things about lambdas z3 will understand and won’t. It can normalize lambdas, but don’t count on much beyond that. Perhaps when I have better support for using Vampire or Eprover I can amend this suspicion of using lambdas.\n\nI’ve complained before that python doesn’t have a good lambda manipulation library. Well, actually, z3 is not a bad version of that really. It has enough functionality that a locally nameless open_binder combinator is easy to write. Be forewarned, alpha equivalent lambdas are not eq.\n\nInduction\n\nDon’t have a great answer. I have built wrappers around the z3 Datatype mechanism to derive induction and recursion definitions. Not in love with it.\n\nA very preliminary prototype\n\nInductive Relations\n\nA useful modelling capability is inductive relations, which are served by dependent type definitions in systems like lean and coq. Dependent types are not necessary for some version of inductive relations though.\n\nIn my Justified SMT post https://www.philipzucker.com/minikanren_inside_z3/ , I discussed the basic idea of how I intend to encode this. You can use the clark completion to define all the ways a relation can become true. If you add an extra parameter to the relation that describes the tree and existential witnesses of the proof, these become well founded relations. Induction over the relation is really induction over this proof object.\n\nThese are related to refinements in that we need an extra consistency condition that the proof object attached to the relation actually checks.\n\nGenerics\n\nA big problem for smtlib is that you can’t easily write sort generic/polymorphic definitions. This can be got around by writing generic functions/definitions such that they take in the z3 sort as a parameter to a python function. This is analogous to using a module system to achieve\n\nAnother intriguing option is the addition of an open or closed Any universe. One can define a datatype ClosedAny or declare an uninterpreted sort OpenAny that has injectors and projectors from all other types. Things that have to be generic can work over this type sometimes. Without auto conversions, this may be rather clunky. It is interesting the relationship between this Any type and type theory universes.\n\nStaging might be interesting to explore to remove overhead of the dynamic typing approach. Often the types will resaolve to something concrete.\n\nContext\n\nIt would be nice sometimes to not have to keep repeating ForAll([x], foo, bar, biz) all the time and keep some lemmas in the by clause by default. One solution is to make local lemma wrappers. Could do something trickier or more stateful though. Not sure.\n\nAlgebraic Hierarchy\n\nAn interesting and tough problem is building algebraic hierarchies in your system. The theories of monoids, groups, rings, fields, etc have a relation to one another. This relation is a quite possibly complicated partial order and there may be more than one may to interpret the naturals as a group for example. There are other less algebraic examples such as different strengths of continuity or differentiability in analysis.\n\nI spent a bit of time thinking about this. It’s tough and seemingly tied to generics. So far, it looks like it would require building a lot of metasystem in python. I’m punting on this one. Let’s prove some concrete things before worrying about how to abstract them. I suspect the generic weakness of knuckledragger means it will never have an awesome solution to this problem. It’s like trying to model Lean in C. You can probably do it in some sense, but at extreme encoding cost.\n\nQuotients\n\nOne thing the Lean folks claim is a big deal is that Lean has a culture of supporting quotients, possibly even in the core system.\n\nQuotients do exist and are useful. They feel dual in some way to the problems of refinements\n\nThere are a couple strategies.\n\ncanon function.\n\nSets of equal elements\n\nBy fiat declare new undefined quotient sort.\n\nZ/2 is kind of the quotient analog of even/odd\n\nite chains\n\nIt is unfortunate that the z3 python bindings do not offer a pattern matching construct even though the surface language of smtlib2 does. Big nested sequences of If are ugly, hard to read, and hence easy to get wrong.\n\nhttps://docs.pola.rs/api/python/stable/reference/expressions/api/polars.when.html The dataframe ecosystem has a convention to solve a similar problem. I’m trying to use familiar python idioms when one can work.\n\nI could do purely functional chaining or stateful. I’m kind of offering both here by returning self.\n\nOne possibility to sanity check the totality of your cases is to put a fresh variable in the otherwise and then do a relational check prove(e1 == e2) where e1 and e2 only differ by the fresh constant in the otherwise default case. If this check does not pass, your cases are not total. And you can achieve this without going to a Maybe or keeping aside some other special error value. Kind of cute.\n\nSpeed\n\nAm I hanging myself by being in python? I find myself worrying about eventually needing everything cached and how complicated that will be. So far, everything runs fast.\n\nIt would be good to line profile\n\nMachine Learning\n\nI haven’t done much of anything yet. Lemma databases might be helpful for this.\n\nCopilot rules though. It does a decent job of filling in both my theorem statements and proofs.\n\nBits and Bobbles\n\nGordon plotkin, decision procedure for partial derivatives https://www.youtube.com/watch?v=j_w6GNUIQDo&ab_channel=AppliedCategoryTheory%40UCR\n\nMarshall https://github.com/andrejbauer/marshall https://dl.acm.org/doi/pdf/10.1145/3341703 MarshallB . Awesome exact real system. Based around a principle that refining reals don’t have equality. So the language has a more pirmitve thing than Bools, the sierpinski truth value (a stream that eventually ends in Unit).\n\nhttps://codac.io/ Interval tubes for robotics\n\nMeta Z3\n\nSkolem\n\nhttps://www.cs.utexas.edu/~moore/acl2/manuals/latest/index.html?topic=ACL2____DEFCHOOSE\n\nhttps://www.cs.utexas.edu/~moore/acl2/manuals/current/manual/index-seo.php/ACL2____DEFUN-SK\n\nCan I use a z3 skolem tactic?\n\nRefinements\n\nReplace with bounded quantifiers forall x, P(x) —> forall x, wf(x) -> P(x) exists x, P(x) —> exists x, wf(x) /\\ P(x)\n\nIn what sense is this a sufficient alternative?\n\nIt’s a design choice of refinement using newtype wrapper\n\nQuestion is are there confusing situations where one might construct the record\n\nIs any of this worth it though\n\nTwo big problems I have are representing quotients and refinements\n\nMake new sorts\n\nParametrize them\n\nMeta records\n\nInternalizing a refinement system using quotation.\n\nWhat about Boole.\n\nSee we want variables to be tagged with their assumptions, which can be deischarged when we quantify over them. Maybe if I had a variation of first order logic. x|x>=0 |- t –> |- forall x, x >=0 => t I could tuple (“x”, x >= 0) and bubble up. But then I need to double everything NatForAll(vars, f) = ForAll([vars], Implies(x >= 0, f)) NatExists(vars, f) = Exists([vars], And(x >= 0, f))\n\nhttps://isabelle.in.tum.de/~haftmann/pdf/data_refinement_in_isabelle_hol_haftmann_krauss_kuncar_nipkow.pdf data refinement in isabelle 2013\n\nhttps://www.andreipopescu.uk/pdf/NF.pdf non free datatypes\n\nhttps://www21.in.tum.de/~kuncar/huffman-kuncar-itp2012.pdf Lifting and Transfer: A Modular Design for Quotients in Isabelle/HOL\n\nCezary Kaliszyk and Christian Urban. Quotients revisited for Isabelle/HOL. In William C. Chu, W. Eric Wong, Mathew J. Palakal, and Chih-Cheng Hung, editors, Proc. of the 26th ACM Symposium on Applied Computing (SAC’11), pages 1639–\n\nACM, 2011.\n\nAlexander Krauss. Simplifying Automated Data Refinement via Quotients. Technical report, Technische Universität München, July 2011. http://www21.in.tum. de/~krauss/papers/refinement.pdf.\n\nLawrence C. Paulson. Defining functions on equivalence classes. ACM Trans. Comput. Logic, 7(4):658–675, October 2006.\n\nPos = DeclareType(“Pos”) inj = DeclareFunction(“inj”, Pos, Int)\n\ndef pos_induct(P): ForAll([x], Implies(x >= 0, P(x))) == ForAll([y], P(y))\n\nIs there a P(x,y) style “induction” principle that is natural?\n\nhttps://arxiv.org/abs/2303.05244 Transport via Partial Galois Connections and Equivalences Kevin Kappelmann\n\nhttps://z3prover.github.io/papers/z3internals.html#sec-refinement-types refinment types in z3. Suggested to use user propagation\n\nThis doesn’t work for incoming assumptions. It can determine some expression is unconditionally positive.\n\nA different style using projector functions.\n\nQuotients\n\nforall x —> forall x exists x —-> exists x, P(x)_/\\ forall y, y = x -> P(y)\n\nhttps://arxiv.org/abs/1907.07591 Defining Functions on Equivalence Classes\n\nCanon functions. We don’t need a new sort if we can define a function that canonizes.\n\nCan also directly axiomatize these functions. Can also combine with a projection?\n\ncauchy_canon_proj = eq(x,y) == (cauchy(x) == cauchy(y)) /\n\ncauchy(x) => canon(x) ==\n\nSeq\n\nhttps://en.wikipedia.org/wiki/Equivalence_class#canonical_surjection\n\ncanon(canon(x)) = canon(x) # idem. is projection eq(x,y) == (canon(x) == canon(y)) # reflect equiv ForAll([y], Exists([x], Implies(canon(x) == canon(y), canon(x) == x))) # for all equiv class, there exists a self mapping element / fixed point. Is this a theorem or axiom?\n\nExists([x], canon(x) == x)\n\nInductive Relations\n\nOption / Parametric\n\nMultiSolver\n\nMake solver objects. Mock z3 interface\n\nmonkey patch for pytest kd.kernel.lemma = lambda *args, **kwargs: kd.kernel.lemma(kwargs[“solver”]=VampireSolver) kd.lemma ="
    }
}