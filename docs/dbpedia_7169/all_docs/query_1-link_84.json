{
    "id": "dbpedia_7169_1",
    "rank": 84,
    "data": {
        "url": "https://dokumen.pub/pg-de-gennes-impact-on-science-volume-ii-soft-matter-and-biophysics-soft-matter-and-biophysics-9789814280648-9789814280631.html",
        "read_more_link": "",
        "language": "en",
        "title": "Volume Ii: Soft Matter And Biophysics: Soft Matter and Biophysics 9789814280648, 9789814280631",
        "top_image": "https://dokumen.pub/img/pg-de-gennes-impact-on-science-volume-ii-soft-matter-and-biophysics-soft-matter-and-biophysics-9789814280648-9789814280631.jpg",
        "meta_img": "https://dokumen.pub/img/pg-de-gennes-impact-on-science-volume-ii-soft-matter-and-biophysics-soft-matter-and-biophysics-9789814280648-9789814280631.jpg",
        "images": [
            "https://dokumen.pub/dokumenpub/assets/img/dokumenpub_logo.png",
            "https://dokumen.pub/img/200x200/non-equilibrium-soft-matter-physics-9814360627-9789814360623.jpg",
            "https://dokumen.pub/img/200x200/soft-matter-a-very-short-introduction-9780192533913.jpg",
            "https://dokumen.pub/img/200x200/frontiers-and-progress-of-current-soft-matter-research-9811592969-9789811592966.jpg",
            "https://dokumen.pub/img/200x200/theoretical-physics-of-soft-condensed-matter.jpg",
            "https://dokumen.pub/img/200x200/biophysics.jpg",
            "https://dokumen.pub/img/200x200/raman-spectroscopy-for-soft-matter-applications-0470453834-9780470453834-9780470475980-0470475986.jpg",
            "https://dokumen.pub/img/200x200/the-oxford-handbook-of-soft-condensed-matter-0199667926-9780199667925.jpg",
            "https://dokumen.pub/img/200x200/the-oxford-handbook-of-soft-condensed-matter-9780199667925-0199667926.jpg",
            "https://dokumen.pub/img/200x200/pg-de-gennes-impact-on-science-volume-i-solid-state-and-liquid-crystals-solid-state-and-liquid-crystals-9789814273817-9789814273800.jpg",
            "https://dokumen.pub/img/200x200/computational-modeling-of-intelligent-soft-matter-shape-memory-polymers-and-hydrogels-0443194203-9780443194207.jpg",
            "https://dokumen.pub/img/200x200/pg-de-gennes-impact-on-science-volume-ii-soft-matter-and-biophysics-soft-matter-and-biophysics-9789814280648-9789814280631.jpg",
            "https://dokumen.pub/dokumenpub/assets/img/dokumenpub_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "This publication, in two volumes, is devoted to the scientific impact of the work of Nobel Laureate, Pierre-Gilles de Ge...",
        "meta_lang": "en",
        "meta_favicon": "https://dokumen.pub/dokumenpub/assets/img/apple-icon-57x57.png",
        "meta_site_name": "dokumen.pub",
        "canonical_link": "https://dokumen.pub/pg-de-gennes-impact-on-science-volume-ii-soft-matter-and-biophysics-soft-matter-and-biophysics-9789814280648-9789814280631.html",
        "text": "Citation preview\n\n7395tp.indd 1\n\n7/8/09 11:12:32 AM\n\nSERIES ON DIRECTIONS IN CONDENSED MATTER PHYSICS Published Vol. 1:\n\nDirections in Condensed Matter Physics — Memorial Volume in Honor of Shang-Keng Ma eds. G. Grinstein and G. Mazenko\n\nVol. 2:\n\nIonic Solids at High Temperatures ed. A. Stoneham\n\nVol. 3:\n\nDirections in Chaos (Vol. 1) ed. B.-L. Hao\n\nVol. 4:\n\nDirections in Chaos (Vol. 2) ed. B.-L. Hao\n\nVol. 5:\n\nDefect Processes Induced by Electronic Excitation in Insulators ed. N. Itoh\n\nVol. 6:\n\nSpin Glasses and Biology ed. D. Stein\n\nVol. 7:\n\nInteraction of Electromagnetic Field with Condensed Matter eds. N. N. Bogolubov, Jr., A. S. Shumovsky and V. I. Yukalov\n\nVol. 8:\n\nScattering and Localization of Classical Waves in Random Media ed. P. Sheng\n\nVol. 9:\n\nGeometry in Condensed Matter Physics ed. J. F. Sadoc\n\nVol. 10: Fractional Statistics & Anyon Superconductivity (also published as a special issue of IJMPB) ed. F. Wilczek Vol. 11: Quasicrystals — The State of the Art eds. D. DiVincenzo and P. Steinhardt Vol. 12: Spin Glasses and Random Fields ed. A. P. Young Vol. 13: The Superconducting State in Magnetic Fields ed. C. Sa de Melo Vol. 14: Morphological Organization in Epitaxial Growth & Removal eds. Z.-Y. Zhang and Max G. Lagally Vol. 15: Thin Films: Heteroepitaxial Systems eds. Amy W. K. Liu and Michael B. Santos Vol. 16: Quasicrystals — The State of the Art (2nd Edition) eds. D. DiVencenzo and P. Steinhardt Vol. 17: Insulating and Semiconducting Glasses ed. P. Boolchand Vol. 18: P.G. de Gennes’ Impact in Science – Vol. I Solid State and Liquid Crystals eds. J. Bok, J. Prost and F. Brochard-Wyart\n\nAlvin - P-G De Gennes Vol. II.pmd\n\n2\n\n9/4/2009, 2:13 PM\n\nWorld Scientific\n\n7395tp.indd 2\n\n7/8/09 11:12:33 AM\n\nPublished by World Scientific Publishing Co. Pte. Ltd. 5 Toh Tuck Link, Singapore 596224 USA office: 27 Warren Street, Suite 401-402, Hackensack, NJ 07601 UK office: 57 Shelton Street, Covent Garden, London WC2H 9HE\n\nThe editors and publisher would like to thank the following publishers of the various journals and books for their permission to include the selected reprints found in this volume: Academic des Sciences, Institut de France (C. R. Acad. Sci.); American Chemical Society (J. Phys. Chem.); American Institute of Physics (J. Chem. Phys.); EDP Sciences (Le Journal de Physique); Elsevier Science Publishers (Phys. Lett. A); National Academy of Sciences (Proc. Natl. Acad. Sci. USA).\n\nBritish Library Cataloguing-in-Publication Data A catalogue record for this book is available from the British Library.\n\nSeries on Directions in Condensed Matter Physics — Vol. 19 P.G. DE GENNES’ IMPACT ON SCIENCE — Volume II Soft Matter and Biophysics Copyright © 2009 by World Scientific Publishing Co. Pte. Ltd. All rights reserved. This book, or parts thereof, may not be reproduced in any form or by any means, electronic or mechanical, including photocopying, recording or any information storage and retrieval system now known or to be invented, without written permission from the Publisher.\n\nFor photocopying of material in this volume, please pay a copying fee through the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to photocopy is not required from the publisher.\n\nISBN-13 978-981-4280-65-5 (Set) ISBN-10 981-4280-65-8 (Set) ISBN-13 978-981-4280-63-1 ISBN-10 981-4280-63-1 ISBN-13 978-981-4291-05-7 (pbk) (Set) ISBN-10 981-4291-05-6 (pbk) (Set) ISBN-13 978-981-4291-04-0 (pbk) ISBN-10 981-4291-04-8 (pbk)\n\nPrinted in Singapore.\n\nAlvin - P-G De Gennes Vol. II.pmd\n\n1\n\n9/4/2009, 2:13 PM\n\nApril 24, 2009\n\n15:21\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nsans\n\nv\n\nPierre-Gilles de Gennes\n\nThis page intentionally left blank\n\nJuly 9, 2009\n\n16:48\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\npreface\n\nvii\n\nPREFACE\n\nIn the Pantheon of Science, a few giants emerge: they opened avenues in our quest for more knowledge of our surrounding world. Among them, a tall, elegant man is still very present in our minds and hearts — Pierre-Gilles de Gennes. He has influenced many fields of science and many of us. The ideas Pierre-Gilles introduced were almost always very novel, creating many possibilities. Hundreds of people would start working right away on a new suggestion of PierreGilles’ ! His ideas bear important consequences in the present as well. Thus, it became natural to pick out a few of these contributions and ask some of the leaders in their fields first to explain the ideas, and then to show how it led to the current state of the art. This is what World Scientific asked Francoise Brochard-Wyart, Julien Bok and myself to organise in two volumes. The first one is dedicated to solid state and liquid crystal physics. The second deals with soft condensed matter and biological physics. The general title “P.G. de Gennes’ Impact on Science” reflects the goal that we would like to attain: to give the reader an idea of Pierre-Gilles’ contribution to science. Rather than just “an idea”, perhaps “a measure” would be better but how is it possible to gauge more than 500 original papers in more than 15 different areas from solid state physics to biology? Three aspects of his contributions will be missing though. The first one concerns PierreGilles’ impact in chemistry: he had a great admiration for the inventiveness of chemists and was able to make many relevant suggestions during his conversations with synthetic chemists. His papers on asymmetric synthesis, written to commemorate Pierre and Jacques Curie’s discovery of piezoelectricity, are in Pierre Curie’s vein: they are important for theorists but do not reflect the real influence he had on liquid crystal, polymer and colloidal chemistry. The second one concerns the impact he had on the industry. He has been the scientific advisor of companies such as General Electric, Exxon, Rhˆ one Poulenc and Rhodia. He was also on the board of directors of several other companies. I know he had a significant influence in many important decisions, but by their nature they cannot be public knowledge. The third important aspect is Pierre-Gilles’ dedication and gift for communicating his passion for science. To give an example, after being awarded his Nobel Prize, Pierre-Gilles went throughout France to high schools for several years and gave lectures on soft matter which triggered many vocations in this area of science. In the following paragraphs, I try to explain how Pierre-Gilles’ scientific life helped us narrow the scope of the present books.\n\nApril 16, 2009\n\n14:3\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nviii\n\nWhen he starts his career in 1955, Jacrot and Cribier at Saclay have just observed antiferromagnetic order with neutron scattering. The young Pierre-Gilles works out the theory, which is still a landmark nowadays. Philippe Monod tells me that Pierre-Gilles is also the first to suggest the use of neutron scattering to show the existence of vortex lattices in the superconducting Schubnikov phase. During his postdoc in Charles Kittel’s group at Berkeley in 1957, he keeps working on magnetism, in particular, on double exchange and ferromagnetic resonance in rare-earth garnets. Jacques Friedel has fully understood the scientific interest motivating all this work and attracts him to Orsay. In 1958, they write a paper together discussing resistive anomalies in magnetic metals: early “spintronics”! We are very grateful to Jacques Friedel for accepting to describe this work along with its consequences. All throughout his life, Pierre-Gilles will be eager to learn new fields. He quickly gets interested in superconductivity. He sets up a very active group where theories and experiments are simultaneously investigated. Superconductivity is a very competitive field, which blooms after the BCS theory provides the long expected microscopic understanding of the phenomenon. Here, Pierre-Gilles provides us with an original perspective. He understands that the gap between the phenomenological Landau–Ginzburg theory and the microscopic BCS theory must be bridged, which he does simultaneously with Gork’ov in Moscow. This allows him and his collaborators to discuss surface effects and vortices. With Saint James he predicts the existence of a surface critical field Hc3 , which is subsequently observed by Alexis Martinet, one of his young collaborators. He also predicts with Saint James, one year before Andreev what is now known as the Andreev–Saint James reflection: electrons impinging on a normal superconductor interface from the normal side can be reflected as holes when a Cooper pair is transmitted on the superconducting side. The experimental activity is also brilliant. Pierre-Gilles has built a very active young group world-renowned as the “Orsay superconductor group”. In 1967, he summarises his thoughts on superconductivity in the book Superconductivity in Metals and Alloys which is still a reference in the domain. It is time for him to sail towards new continents. Yet, he will always keep an eye on superconductors and superfluids, and once in a while publish a paper. In 1988, when high temperature superconductors are discovered, he proposes a mechanism based on magnetic interactions. At the same time, he attracts his friend Julien Bok to ESPCI (Ecole Sup´erieure de Physique et Chimie Industrielles), asking him to develop the activity on “High Tc s”. Julien is a brilliant proponent of the Van Hove singularity with conventional electron-phonon interactions, Pierre-Gilles is not a man of cliquishness; he is only concerned with the quest for understanding and he knows Julien will do well. It was thus natural to ask Julien Bok to write a contribution on high Tc s in this volume. He discusses the high Tc problem in the light of Pierre-Gilles’ very last paper, which he published in 2007 with Guy Deutscher who was one of his early collaborators. In turn, Guy Deutscher has played an important role in convincing the international community that the Andreev effect should be named the Saint James–Andreev effect. He was indeed a witness at Orsay when this important work was made. Guy tells us that he asked Pierre-Gilles if he wanted the effect to be called “de Gennes–Saint James–Andreev” but Pierre-Gilles declined\n\npreface\n\nApril 16, 2009\n\n14:3\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\npreface\n\nix\n\nthe offer although he was a co-author in the first paper. Guy Deutscher’s contribution deals naturally with elementary excitations in the vicinity of a normal metal-superconducting metal contact. One cannot switch to another field of interest of Pierre-Gilles without mentioning uncharged superfluids. He contributes to the description of the dynamics of triple lines involving superfluid helium, to that of the symmetries of the helium 3 superfluid order parameter, and in these last years becomes very interested in supersolids. This leads him to describe what is, to my knowledge, the first theoretical description of the motion of a dislocation in the quantum regime. He has long discussions on supersolids with S´ebastien Balibar. In the book, we asked S´ebastien to discuss Pierre-Gilles’ suggestions together with the stateof-the-art results. In 1967, the new continent is soft matter. Pierre-Gilles starts by describing the dynamics of dilute polymer suspensions. Neutron scattering provides a check of his theory on conventional polymers. Nowadays, light scattering in dilute DNA solutions allows us to observe all predicted regimes with excellent accuracy and to confront theory with essentially no adjustable parameter. He also discusses the “coil-stretch” transition of polypeptides. In the following few years, Pierre-Gilles focuses his attention on liquid crystals. The community wavers between a completely obsolete “short range” view and a mathematically formal continuum description. In 1968, Pierre-Gilles simplifies the continuum description, showing where the relevant physics is. He explains the strong light scattering by nematics, and much of their dynamical behaviour. He draws around him again a large number of bright physicists. The “Orsay liquid crystal group” soon becomes as famous as the “Orsay superconductor group” was. One of the young experimentalists working on nematodynamics at that time is Pawel Pieranski in Etienne Guyon’s lab. We asked him to give his view on this aspect. Pierre-Gilles also used the Landau approach to describe phase transitions in liquid crystals. He is first very successful with the isotropic-nematic transition which he argues should be mean field-like. All his predictions are born out by experiment. He then shows a beautiful analogy between the nematic-smectic A transition and the normal conductor-superconductor transition. The smectic density modulation is analogous to the superconductor order parameter, the nematic director analogous to the vector potential, the dislocations analogous to vortices; gauge coupling is an expression of rotational invariance. The only difference is that there is no gauge invariance in general. Among the key predictions is Helium-like critical behaviour and the existence of a phase equivalent to the Schubnikov vortex phase. The success of the isotropic-nematic transition theory has been so impressive that laboratories all around the world jump to work on the problem. The critical behaviour turns out to be only qualitatively in agreement with the predictions. In particular, critical exponents seem to be anisotropic. It takes about fifteen years to observe the equivalent of the vortex phase and to work out a complete theory but the initial prediction is beautifully confirmed! Tom Lubensky, who coined the name Twist Grain Boundary to that phase is no doubt the physicist who contributed most to the fine understanding of the nematic-smectic A transition: his contribution is the penultimate of the first volume. Pierre-Gilles’ strong ties with liquid crystals ends soon after the publication of the book The Physics of Liquid Crystals in\n\nApril 16, 2009\n\n14:3\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nx\n\n1972. As for superconductors, he keeps on following new developments in the field and from time to time introduces one more original idea like that of “artificial muscle” or fracture and spreading in smectics. Somewhat arbitrarily, we have included in the first volume a discussion on Pierre-Gilles’s impact in the physics of macroscopic random media, by Jean-Pierre Hulin, Etienne Guyon and Stephane Roux. This could have appeared in the second volume as well. Etienne, who was a member of the early superconductor and liquid crystal groups, was asked by Pierre-Gilles to reorganise the ESPCI hydrodynamics laboratory, opening its research areas to a wide variety of problems including dynamic instabilities, turbulence, magnetic fluids, wetting, and the physics of macroscopic random media. Indeed Pierre-Gilles had taken responsibility of ESPCI a few years after being appointed at the College de France. The style introduced by Etienne is in perfect harmony with Pierre-Gilles’ conception of research. Coming back to the early seventies, the years of 1971–1972 are Anno Mirabilis for PierreGilles. While making major contributions to liquid crystals, he provides fundamental input in polymer science. Improving on the tube image introduced earlier by Sam Edwards, he introduces the reptation concept which provides an elegant and powerful tool for discussing polymer dynamics. This opens the way to a large number of theoretical and experimental works which Michael Rubinstein discusses in the second volume dedicated to soft matter and biological physics. A long-standing problem is that of a self-avoiding random walk. It describes, among other things, the statistics of polymer chains in good solvents. K. Wilson has just invented a renormalization group expansion, which explains the origin of the non-trivial critical exponents characterising continuous phase transitions. He sends his preprint to friends. This is not an easy paper to read and understand. Pierre-Gilles sees right away that when the number of components of the vector is set to zero, the described situation is that of a self-avoiding random walk, a conceptual tour de force. He is so fast that his paper on the self-avoiding walk comes out before K. Wilson’s paper on the renormalisation group approach to phase transitions! Tom Witten, who has worked on the renormalisation group description of polymers during his postdoc with Pierre-Gilles, provides an analysis of this exceptional contribution to science. The renormalisation group techniques are not easy to handle: Pierre-Gilles invents the image of “blobs” which allows anyone to use the corresponding concepts without knowing it! The polymer community can now discuss very complex situations in simple terms and understand the emerging scaling laws! The price to pay is the absence of prefactors in the formulae, but the physics comes out nicely. In the second volume, Fran¸coise BrochardWyart and Karine Guevorkian illustrate the use of this beautiful tool in the context of polymers in confined geometries. Some aspects of polyelectrolytes can be discussed with scaling laws, some others like the semi-dilute polyelectrolyte solutions require keeping track of prefactors. Pierre-Gilles’ long time friend Philip Pincus discusses these cases together with Omar Saleh. In 1979, Pierre-Gilles publishes the book Scaling Concepts in Polymer Physics. Contrarily to what happened with superconductors and liquid crystals, the publication of this book does not really slow down his activity on polymers. Among some of the important areas he\n\npreface\n\nApril 16, 2009\n\n14:3\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\npreface\n\nxi\n\ntackles a few years later are those of adhesion and friction in which polymers are essential. All the knowledge acquired on polymer dynamics proves to be important in understanding these phenomena — the use of which is ubiquitous in every day’s life. We asked Hugh Brown to expose Pierre-Gilles’ contributions. Although Pierre-Gilles keeps in touch with the development on polymers, he sails towards new continents. After the first oil crisis, oil recovery motivates strong research activity on micro-emulsions. Pierre-Gilles again contributes with a few seminal papers, introducing an important length characterising interfaces, and describing the main features of complex phase diagrams. He also becomes interested in wetting and dewetting phenomena, which play an important role in areas as diverse as textile and printing industries on the one hand, and automobile and aeronautical industries on the other. Spreading of a fluid on a wettable surface is surprisingly universal, independent of the substrate wettability. Macroscopic theories fail to explain experimental observations. Pierre-Gilles shows how the idea of a precursor film reconciles observations and theory. First, a film of microscopic thickness spreads on the substrate and then the bulk fluid spreads on the film. As always, he investigates a large number of situations: he shows the importance of van der Waals forces, discusses the spreading of polymers, smectics, magnetic fluids as well as superfluid Helium IV. He also discusses the influence of volatile impurities on the spreading velocity, the importance of the substrate topographic and chemical heterogeneities, describing in detail the case of a pinning point. Dewetting in situations mimicking either aquaplaning or printing is also investigated. A book comes naturally to summarise this activity. The French version Gouttes, bulles, perles et ondes comes out in 2002, the English version Capillarity and Wetting Phenomena: Drops, Bubbles, Pearls, Waves in 2004. For a change, there are three authors: Pierre-Gilles de Gennes, Fran¸coise Brochard-Wyart, and David Qu´er´e. We asked Lyderic Bocquet to write the article on wetting/dewetting phenomena. Looking just at Pierre-Gilles’ scientific production, one easily overlooks the fact that he was awarded the 1991 Nobel Prize! Answering an enormous amount of mail, giving television and radios interviews, interacting with high-level politicians and visiting high schools does not really slow him down. After retiring from Coll`ege de France and ESPCI, Pierre-Gilles joins the Curie Institute and learns a great deal of biology. In his amazingly elegant style, he shows an analogy between bacterial chemotaxis and gravitational interactions! He predicts the existence of a number of original phenomena, which are currently being tested experimentally. Naturally, Pierre-Gilles is interested in cell adhesion and cell spreading. He shows that the collective dynamics is important and predicts scaling regimes. Pierre Nassoy, who collaborated on the experimental side, describes the current situation. In 2006, Pierre-Gilles gives a “biologist” series of lectures on the brain function: almost no equations, but a fascinating description of the state-of-the-art knowledge. He works on olfactive memory storage and neuronal growth. In May 2007, he is working simultaneously on superconductivity with Guy Deutscher and on the creeping behaviour of a cell subjected to a uniaxial tensile stress. He has just published a few papers on solid friction with Jacques Friedel, and the analysis of the\n\nApril 16, 2009\n\n14:3\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\npreface\n\nxii\n\nquantum motion of a dislocation! On the 18th of the same month, we lose one of the brightest scientists of the second half of the twentieth century and a dear friend. Fran¸coise Brochard-Wyart, Julien Bok and myself are extremely grateful to the authors, who did not hesitate one second to accept the difficult task that we were asking for. I am personally very grateful to Fran¸coise and Julien who have been doing all of the editorial work and to Jacqueline Bouvier whose help has been essential in all aspects of the preparation of the two volumes. Jacques Prost\n\nxiii\n\nACKNOWLEDGMENTS\n\nThe editors thank the Foundation Pierre-Gilles de Gennes and ESPCI ParisTech for their ﬁnancial support.\n\nThis page intentionally left blank\n\nJune 8, 2009\n\n16:23\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\ncontents\n\nxv\n\nCONTENTS\n\nPreface\n\nvii\n\nAcknowledgments\n\nxiii\n\nThe n = 0 Discovery Thomas A. Witten\n\n1\n\nP. G. de Gennes, Phys. Lett. A 38, 339–340 (1972) Exponents for the excluded volume problem as derived by the Wilson method\n\n18\n\nDynamics of Entangled Polymers: The Three Key Ideas Michael Rubinstein\n\n20\n\nP. G. de Gennes, J. Chem. Phys. 55, 572–579 (1971) Reptation of a Polymer Chain in a Presence of Fixed Obstacles\n\n35\n\nP. G. de Gennes, J. Phys. France 36, 1199–1203 (1975) Reptation of Stars\n\n43\n\nPolyelectrolytes: The de Gennes Legacy Philip Pincus and Omar A. Saleh\n\n48\n\nP. G. de Gennes, P. Pincus, R. M. Velasco and F. Brochard, J. de Phys. 37, 1461–1473 (1976) Remarks on polyelectrolyte conformation\n\n56\n\nPolymers in Confined Geometries Karine Guevorkian and Francoise Brochard-Wyart\n\n69\n\nF. Brochard and P. G. de Gennes, J. Chem. Phys. 67, 52–56 (1977) Dynamics of confined polymers chains\n\n96\n\nSeptember 4, 2009\n\n10:1\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\ncontents\n\nxvi\n\nPierre-Gilles de Gennes, PNAS 96, 7262–7264 (1999) Passive entry of a DNA molecule into a small pore\n\n101\n\nAdhesion and Friction Hugh Brown\n\n104\n\nE. Rapha¨el and P. G. de Gennes, J. Phys. Chem. 96, 4002–4007 (1992) Rubber-rubber adhesion with connector molecules\n\n115\n\nF. Brochard-Wyart, P. G. de Gennes, L. L´eger, Y. Marciano and E. Rapha¨el, J. Phys. Chem. 98, 9405–9410 (1994) Adhesion promoters\n\n121\n\nAn Approach to Cell Adhesion Inspired from Polymer Physics Pierre Nassoy\n\n127\n\nFran¸coise Brochard-Wyart and Pierre-Gilles de Gennes, C. R. Physique 4, 281–287 (2003) Unbinding of adhesive vesicles\n\n139\n\nSpreading Made a Splash Lyd´eric Bocquet\n\n146\n\nPierre-Gilles de Gennes, C. R. Acad. Sci. 298, 111–115 (1984) Dynamique d’´etalement d’une goutte\n\n160\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n1\n\nThe n = 0 Discovery\n\nThomas A. Witten James Franck Institute, University of Chicago Chicago, Illinois 60637, USA [email protected] We describe Pierre-Gilles de Gennes’ 1972 letter explaining polymer swelling as a form of critical phenomenon. We trace the impact of this “n = 0” discovery on polymer theory and experiment. We discuss later developments in mainstream statistical physics that reflect the n = 0 insight of this paper. We collect the views of several leading statistical physicists on the significance of the discovery.\n\n1.\n\nIntroduction\n\nDuring the midwinter holidays of 1971–1972, the statistical physics community was abuzz with rumors of a breakthrough. A professor named Kenneth Wilson had announced1 a new way to understand the famous problem of critical fluctuations of certain dense gases. Under just the right conditions these critical gases have regions of high and low density. The regions range from molecular size to thousands of times larger, giving them a distinctive opalescent appearance. Wilson called his method the renormalization group. It embodied a symmetry relating the patterns of density seen at a large spatial scale to the sub-patterns within those patterns on smaller scales. This symmetry under spatial dilation had been qualitatively appreciated by others.2 However, Wilson’s method of expressing it gave unprecedented power. It allowed one to account for the peculiar measured power laws describing the growth of the fluctuations as the critical conditions of temperature and pressure were approached. Explaining these “critical exponents” was the nub of the problem of critical fluctuations. The new theory got its power by connecting the intractable critical fluctuations to a simpler regime of weak fluctuations. The new approach had a generality that went beyond critically opalescent gases. Since the anomalous power-law behavior arose from a symmetry, any system with the same form of symmetry should show the same power laws. Moreover, fluctuating quantities more general than a scalar density field could be explained. For\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\n2\n\nexample, the theory could also explain the vector fluctuations of the local magnetization in a metal on the verge of becoming a ferromagnet. Indeed, it could handle analogous fluctuations of a general vector field with an arbitrary number of components n. For the gas, n = 1; for the magnet, n = 3. The vector dimension n is often called a spin index, adopting the language of magnetic phase transitions. As these rumors about the Wilson theory were circulating, Pierre-Gilles de Gennes was on a skiing vacation. But other things were on his mind. As reported by Fran¸coise Brochard, 3 he had been in the United States the previous summer and had discussed Wilson’s ideas with physicists there. On his return to France in Autumn 1971, de Gennes had lectured on these ideas in his course at the College de France (lecture 15). He had seen a connection between Wilson’s theory and a very different puzzle — the famous “excluded volume problem” of polymer physics (lecture 16). Polymers are long chain molecules whose links twist randomly under thermal fluctuations when they are dissolved in a suitable liquid. Such a chain is a type of random walk, whose spatial extent should vary as the square root of its length. However, the measured properties of real polymers were different from this prediction. The spatial extent grew too quickly with chain length, and there was no systematic explanation for the anomalous power law describing its growth. There were only ad hoc arguments that attempted to account for the excluded volume or self avoidance of the chain. These attempts tried to extrapolate from the simple cases of one contact between parts of the chain, then two contacts, and so forth. De Gennes and others had noticed a resemblance between this counting of contacts and an analogous form of counting in a dense gas. The gas molecules — like the polymer subunits — cannot intersect one another. This collective mutual repulsion must be treated by a painstaking calculational scheme in order to avoid double counting. It was this scheme which resembled the perturbations of a polymer owing to self avoidance. Both schemes kept track of the accounting by means of diagrams representing classes of self-intersecting configurations to be corrected for. As de Gennes puzzled over the two forms of diagrams, he had noticed closer and closer correspondences, especially when he used Wilson’s style of accounting. In Wilson’s method, the same set of diagrams described fluctuating fields with arbitrary numbers of vector components n. In this scheme there was a perfect correspondence between each polymer diagram and a corresponding vector field diagram. Moreover, the mathematical expression associated with a given polymer diagram was identical to that for the vector field, provided one chose the proper value of n. What was this magical value of n? Zero!4 Now, these diagrams were the only input needed by the Wilson theory in order to determine its renormalization-group symmetry, and thence its critical exponents. The approximate formulas for these exponents were expressed as explicit functions of n. By setting n = 0 in these formulas, one was discovering information about self-avoiding polymers. Interpreting these power laws required another insight of interpretation. How could the critical exponents describing thermodynamic effects involving density and temperature apply to the purely geometric polymer properties of chain length and spatial extent? The field theory language of the Wilson theory allowed one to make the proper correspondence, by recalling the physical situations that each diagram represented. Now de Gennes could explain the\n\nwitten\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n3\n\nexcluded volume exponent of polymers merely by transcribing from the Wilson theory of critical phenomena. Armed with this insight, making this transcription was a simple matter. It could be explained in a 1 1/2-page paper. It was this paper that the journal Physics Letters received on January 10, 1972.5 It appeared, peppered with misprints, in the issue of February 28. With this paper two of the most important puzzles of statistical physics were recognized as aspects of a single phenomenon. Often when two very different phenomena are unified in this way, the implications are profound. De Gennes n = 0 discovery carried such implications. First, it cast important light on Wilson’s renormalization symmetry. Up to that point, renormalization symmetry had been viewed as an exclusive feature of phase transitions. As such, the notion of renormalization was entangled with the separate notion of spontaneous symmetry breaking, a necessary feature of phase transitions. The new polymer realization of renormalization symmetry disentangled these two features. Polymers were not a phase transition and had no spontaneous symmetry breaking. Thus the polymer case provided insight into the essence of renormalization symmetry. As important as this insight was for renormalization symmetry, the implications for polymer physics were no less profound. Transcribing well-developed arguments from phase transitions to their polymeric counterparts led to clear cut predictions for a range of polymer properties where previous understanding had been murky and ambiguous. In this chapter I explore the implications of the n = 0 paper. I first describe the paper itself, providing a gloss on each paragraph in turn. Then I review the impact on polymer physics. Next I review the impact on mainstream renormalization theory and statistical physics. Finally I report the reflections of several prominent physicists whose work was influenced. Since our task is to judge the importance of an idea, the outcome is necessarily subjective. The account below comes from an avowed devotee of the n = 0 paper. Other observers might relegate the n = 0 paper to a much smaller historical importance. A thoughtful weighing of the evidence might prove them right. With these caveats, I give my own subjective and tentative impressions below.\n\n2.\n\nGloss\n\nThe note is titled “Exponents for the excluded volume problem as derived by the Wilson method.” Clearly this terse account is addressed to experts. The excluded volume problem is the polymer physicist’s name for explaining how the size R of a self-repelling polymer grows with its length N . This amounts to finding the exponent ν in the formula R ∼ N ν . The Wilson method refers specifically to a technique of calculating the diagrams mentioned above. Since the numerical value corresponding to a given diagram depends only on distances between selected interaction points, each diagram has a simple, explicit dependence on the dimension d of space. The critical point where the interesting behavior appears is just the point where the numerical values diverge. The technical achievement of the renormalization group is that it provides a way to make sense of the diagrams despite this divergence. Still, concrete predictions using the diagrams require definite numbers, not divergent integrals. Here a final observation by Wilson was crucial. The divergences\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\n4\n\nwent away above a special dimension: d = 4. If one pretended that the dimension of space were very close to four, one could obtain finite quantities by the technique of performing a Taylor expansion in the small parameter ≡ 4 − d. (Thus Wilson’s famous renormalization group paper — still unpublished at the time of de Gennes’ writing — was titled “Critical exponents in 3.99 dimensions.”)1 The Wilson paper had calculated critical exponents by expanding to second order in this , and then obtaining the prediction for three-dimensional space by evaluating the expansion at = 1. De Gennes’ two-sentence abstract reports the result of this procedure using his n = 0 realization to calculate ν. The body of the paper begins by defining the partition function needed to determine ¯ of a self-avoiding polymer. It is the number of distinct the average end-to-end separation R ¯ ∼ N ν , this self-avoiding walks of length N with ends separated by R, denoteda ΓN (R) If R Γ quantity must show it. In order to make contact with Wilson’s quantities, de Gennes immediately introduces the quantity G, a transform of Γ. The spatial variable is replaced by its Fourier transform variable k. The chain length variable is likewise replaced by its Laplace transform P , nowadays known as the monomer chemical potential. At this point, G is claimed to have a divergence as this potential approaches a certain value P C : G(0, P ) ∼ P (P − Pc )−γ . This amounts to saying ZN ≡ R ΓN (R) ∼ N γ−1 eN Pc . This kind of scaling behavior had been suspected on numerical grounds12, 13 but not established. Thus this claim is justified by the arguments to follow. A second claim follows, regarding the dependence of G(k, P ) on k when P takes its critical value Pc . G is said to vary as a power of k involving a second exponent denoted η. The justification for this claim is also found in the arguments to follow. Now the desired ¯ of the chain is claimed to be related to the γ and η just exponent ν governing the size R defined. The “usual scaling arguments” are invoked to justify it. These arguments amount to saying that G(k, P ) has a fixed functional form as ∆P ≡ P − Pc → 0. The fixed functional form means that the only difference between G(k, ∆P ) and the same quantity evaluated λ times farther from the critical point is a difference of scale factors in the k and G dependence: G(k, ∆P ) = µG G(µk k, λ(∆P )), where µG (λ) and µk (λ) are the scale factors needed to reflect the expansion of ∆P by a factor λ. This homogeneity or scaling law connects the claimed behavior of G for k = 0 to that for ∆P = 0. From the k = 0 behavior we infer. µG ∝ λγ , (by taking λ = 1/∆P ). From the ∆P = 0 behavior, we infer µG ∝ µk 2−η . Thus µk ∝ λγ/(2−η) . That is, a change in ∆p (or inverse chain length) by a factor λ is equivalent to a change in k (or inverse spatial distance) by a factor λγ/(2−η) . This is the content of the statementb ν = γ/(2 − η) in de Gennes’ note. Such “usual scaling arguments” were common and accepted in the phase transition literature, 11 but not among polymer physicists.12 The reason for this difference may be experimental. For phase transitions, experimental support for these scaling arguments in the vicinity of the critical a Here b Here\n\nan apparent misprint was corrected. an apparent misprint was corrected.\n\nwitten\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n5\n\ntemperature Tc spanned 4 to 5 decades in T − Tc in 1971.11 The corresponding range of N in polymer systems was scarcely two decades, and was subject to technical uncertainties in determining the chain length N . Thus, de Gennes’ invocation of the “usual scaling arguments” rested chiefly on the correspondence to phase transitions that was to be argued in the sequel. Shortly de Gennes will describe the diagrammatic correspondence between the polymer problem and the phase transition problem. The structure of the polymer diagrams, which accounted for a self-repulsion between monomers with a strength v0 had been articulated e.g. by Fixman.14 The n = 0 correspondence with phase-transition diagrams is to be asserted below. But first de Gennes makes a digression to comment on the “renormalized repulsion” denoted vR . The digression is aimed at explaining a widely believed property of polymers in Wilson’s renormalized language. The strength of the repulsion v0 was believed not to affect the value of the exponent ν. This fact is naturally explained if the diagrams can be cast into a form in which v0 is replaced by a fixed quantity. The renormalization procedure aims to perform this recasting. Renormalization aims to describe the calculation of a quantity such as G(k, P ) by replacing the original lattice degrees of freedom such as monomer density by local averages. One may account for the overall effects of self-avoidance using only these local averages. Moreover, the locally averaged calculation has the same form as the original one, except that the input parameters such as v0 have different values. The quantity playing the role of v0 in the locally averaged calculation is denoted vR . One may determine vR from v0 for a given type of averaging. On the other hand, one may use the anticipated scaling dependence of the calculated quantity e.g. G ∼ k −2+η to determine how vR must vary with the averaging length scale. Equation (3) is an expression for vR of this form. It does not refer to an averaging length scale directly; rather, it uses P − Pc the monomer chemical potential that would generate polymers of the desired scale. The aim of this equation is to show that vR reaches a fixed value. In the following paragraph de Gennes sketches a way to reach the same conclusion using a variant of the polymer problem in which the polymer is confined to a finite volume with a fixed, small, average monomer density. Both of these arguments about vR are sketchy and obscure. In any case they address a side issue. They aim to justify a point that will be better justified by the simple observation in the following paragraph. The next paragraph gives the central observation of the paper: the G function for polymers is a special case of a corresponding G function for phase transitions. The argument is based on the perturbation diagrams described above. Figure 1 shows a typical diagram for the counterpart of G for an n-vector field. Each line in the diagram accounts for the correlations of the field at the two end points of the line. The lines terminate at interaction points shown as heavy rectangles. The field interacts with itself at every point; the statistical weight of the field at any point differs from what it would be without the interaction. This altered statistical weight influences the field elsewhere because of its correlations, in particular, the field at other interaction points is altered. By allowing the interaction points to be at arbitrary positions one accounts for part of the effects of the interaction on G. This diagram represent a mathematical expression that contributes to the Taylor expansion for\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\n6\n\nFig. 1. Top: Perturbation diagram for the n-vector field shown in two equivalent drawings. Meaning of the lines and rectangles is explained in the text. Light lines denote loops. Bottom: Perturbation diagram for a self-repelling polymer, also shown by two equivalent drawings. The lower pair is obtained from the upper pair by removing the loops.\n\nG in powers of v0 . Since there are five interaction points, this diagram is part of the v0 5 term in this expansion. By connecting the interaction points in all possible ways and adding the corresponding mathematical expressions together, one obtains the full v0 5 contribution. One feature of the illustrated diagram is the appearance of the two loop lines shown as narrow lines. These lines indicate field correlations that pass from one interaction point to another and eventually return to the original point. The light and dark lines have the same mathematical meaning. Such a loop disturbance can occur for any of the n degrees of freedom of the vector field. Thus the overall disturbance carried by such a loop is proportional to n. A factor n for this loop must appear in the mathematical expression for the diagram. The same is true for both loops in this diagram and for all other loops in other diagrams. Now we consider a polymer diagram for the G of Eq. (1). Its interpretation is simpler. The thick line represents the polymer, following some arbitrary path through space. As pictured in the diagram this polymer intersects itself at two points indicated by black rectangles. The statistical weight of such paths is altered by the self repulsion of strength v 0 . This diagram, with its two interaction points, thus contributes to the power series expansion in v0 in order v0 2 . We now observe that the polymer diagram may be obtained from the n-vector field diagram by simply removing the two loops. This fact, illustrated with this diagram, is true in general. If one considers an arbitrary n-vector diagram and removes the loops, one obtains a polymer diagram. Conversely, every polymer diagram is contained (exactly once) within the set of loop-removed n-vector diagrams. As noted above, the mathematical expression corresponding to the polymer diagram is identical to that for the n-vector diagram. This equivalence arises partly from a fundamental similarity between the two systems. In the polymer diagrams, the lines between interaction points represent random walks (segments of noninteracting polymer) between the points. These random walks are equivalent to a diffusive motion, as Einstein noted in his famous paper relating Brownian motion and diffusion.6 In the n-vector diagrams the corresponding line represents spatial correlations between the fluctuating vector field at two different points. In effect, these correlations\n\nwitten\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n7\n\nalso arise by diffusion: a statistical weight tending to make the field at a point equal to the average of the field at neighboring points. The equivalence between the polymer and the n-vector diagrammatic expressions also required some mathematical jiggering. The quantity G constructed in de Gennes’ Eq. (1) has been devised to make the mathematical correspondence exact. Once one knows the mathematical expression for the n-vector diagrams, it is absurdly simple to extract the expression for the polymer diagrams. This simplicity arises from our observation above that each loop in an n-vector diagram contributes a factor n to the mathematical expression for that diagram. We have noted that the sum of contributions from all the (infinite number of) diagrams completely accounts for the effects of the interaction v 0 on G. Once one has the expression encompassing all n-vector diagrams, the corresponding expression encompassing all loopless diagrams is thus obtained by simply setting n = 0 in the n-vector expression. Thus the G function for polymers is a mere special case of the G for the n-vector field. Naturally this equivalence extends to the critical exponents of the n-vector model. De Gennes’ paragraph points out this diagrammatic correspondence, without pictures, in a way that an expert in these diagrams can follow. The next step is to make use of the correspondence. He quotes Wilson’s calculation for the exponents γ and η expanded to next leading order in the the difference of spatial dimensionality d from 4. He evaluates these expressions for n = 0 and d = 3, then uses the exponent relations cited above to get the desired exponent ν. This ν is then compared with the best available value and observed to be in good agreement. He also compares with two theoretical hypotheses which, like the Wilson values, can be evaluated for general dimension d. He notes that their expansions in d − 4 do not agree with the Wilson counterparts. Though de Gennes cites a precise value of ν and compares it closely with other values, one should note that the d − 4 expansion provides only ambiguous information about the three-dimensional world. For example, if one expands 2ν = γ/(2 − η) to order (4 − d) 2 , and evaluates it for d = 3, one obtains 2ν = 1.1835 . . ., rather than de Gennes’ value of 1.195. By using such schemes, one could obtain a wide range of estimates for ν. The Wilson prescription does not provide a way to choose among such alternative estimates. The claims of this brief paper seem to have been immediately accepted by the statistical physics community. The n = 0 finding is reported as established in the Cargese lectures on renormalization group7 in 1973 and in the review article by Wilson and Kogut8 in 1974.\n\n3. 3.1.\n\nPolymer Impact Antecedents\n\nThe excluded volume problem addressed in Ref. 5 is at the heart of much of polymer physics. Any property related to a concentration or molecular weight dependence in a good solvent necessarily involves the exponent ν cited above. In order to deal with these properties decisively, one must thus have a framework for understanding this ν and hence the excluded volume problem.\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\n8\n\nThe importance of the excluded volume problem had been recognized since early 20th century, when it was first established that polymers were flexible chains9 of many independent statistical segments. By mid-century this common feature of polymers had given rise to a powerful body of theory led by Paul Flory.10 Flory devised a simple and appealing explanation of why self-repulsion or excluded volume causes a polymer’s size R to grow as its molecular weight M to a power ν greater than 1/2. The Flory theory predicted ν = 3/(d+2) in d dimensions, and this value was completely consistent with experiments. The explanation was deemed adequate by those who worked with polymers daily. Yet efforts 12, 14 to justify its assumptions and develop the idea into a systematic theory remained at the level of ad hoc attempts. Meanwhile, the analogous statistical problem of the self-avoiding walk on a lattice was recognized as fundamental. Statistical theorists like Fisher15 and Domb16 were devising systematic ways to infer the asymptotic functional form of R(N ) and the number of walks Z N of length N . One approach was to enumerate all self-avoiding walks up to a given size, and then examine the consistency of these exact results with a given asymptotic form. A second approach was to view the self-avoidance constraint as a perturbation on the ensemble of unrestricted random walks. Since the large-M behavior of unrestricted walks was completely understood, the limitations of the small-M enumerations were removed. One could then calculate the effects of this perturbation systematically by assigning a statistical penalty v 0 for each intersection and then performing an expansion in powers of v0 .14 This approach leads to the diagrams discussed in the last section. However, the limit of interest is one where the unrestricted walks have many self-intersections and hence many complicated diagrams. Thus the potential of this method seemed very limited. Only for dense and strongly interpenetrating polymer solutions could these diagrams be reduced to a tractable form,17 in this concentrated regime all signs of excluded volume swelling had vanished. Yamakawa’s18 widely-read 1971 monograph reviewed these different approaches. It was clear that understanding of the excluded-volume effect was fragmentary and unsatisfactory. 3.2.\n\nEarly impact\n\nAlmost immediately after the n = 0 discovery, de Gennes’ colleague Des Cloizeaux proved an important generalization.19 The n = 0 paper concerns the critical state of a gas or magnet at a temperature Tc at which a symmetry begins to be spontaneously broken. Here the spatial correlations grow to infinity in their range. For systems with n > 1, a form of long-range correlation persists in the symmetry-broken, magnetized state below Tc . Spontaneously broken symmetry means that all directions of magnetization are equal in energy. Thus the magnetization is free to rotate throughout the sample with no energy cost. This freedom of rotation is known as a Goldstone mode. It amounts to an infinite range correlation. This range is only made finite by applying a symmetry-breaking magnetic field. Remarkably, an analogous phenomenon occurs in the polymer domain. To find the analogy, one has only to ask what the perturbation diagrams for T < Tc look like when n = 0. The diagrams consist of many polymer lines interacting with each other. The density of ends is proportional to the applied magnetic field. Evidently this is equivalent to the concentration of polymer chains. When this end concentration is low for a given\n\nwitten\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n9\n\nmonomer concentration, the polymers must be long. As the magnetic field goes to zero, the length and size of these polymers evidently diverge. This is the polymer analog of the divergent correlation length below Tc for a magnet. Again, a complicated system of fluctuating spins has been replaced by a prosaic liquid containing flexible chain molecules. A concrete interpretation of these so-called semi-dilute solutions soon emerged in the neutron scattering group connected with de Gennes. The solution could be viewed as a dense packing of self-avoiding “blobs” linked end-to-end to form chains. These chains should show no self-avoidance beyond the scale of a blob. This picture led to several direct predictions for how the scattered neutron intensity should depend on wave-vector, chain length and concentration. Soon after the n = 0 paper, these predictions were satisfyingly confirmed. 20 A year before the n = 0 paper de Gennes had conceived the notion of reptation to describe the kinetics of relaxation of an entangled polymer solution.21 The notion of blobs complemented the reptation idea and extended its predictive power. 3.3.\n\nFurther implications\n\nTheoretical reflection turned up further striking analogies. One was an extension of the critical amplitude ratios seen in phase transitions. For example one may observe the divergence of the correlation length ξ by approaching the critical temperature Tc from either above or below. The rate of divergence is governed by the same critical exponent ν in both cases. Thus the ratio of the two lengths ξ(Tc + ∆T )/ξ(Tc − ∆T ) must remain finite as ∆T → 0. It was observed that this ratio took the same value for all critical points of the same type. The Wilson theory justified this similarity. Like the critical exponents, these amplitude ratios were calculable by the renormalized theory, which was independent of the specifics of the critical system being studied. Similar universal ratios should exist in polymer solutions. The most accessible ones were not comparisons between the quantities above and below T c . But they did preserve the general feature of being ratios of diverging quantities known to diverge with the same power.22 A variant of critical phase transitions proved to have a striking polymer analog. It can happen that magnetism can set in at the surface of a metal slightly before magnetism appears in the bulk. The correlations (the lines in the perturbation diagrams) have altered mathematical expressions in the vicinity of the surface, owing to the boundary conditions it imposes on the field. The result is a critical point with a new renormalization symmetry, known as the “special critical point.” By examining the corresponding diagrams for n = 0 one can divine the polymer analog. Polymers are weakly attracted to the surface of the solution — so weakly that the adsorbed polymers extend arbitrarily far into the solution. The new exponents appear in the form of the concentration profile.23 Again an esoteric phenomenon in the domain of phase transitions proves to have a prosaic and accessible polymer analog. Soon polymer theorists found further variants. Further new exponents arose when the polymers were adsorbed in a wedge or a corner.24 Without motivation from phase transitions, polymer theorists sought to find how exponents such as ν would be influenced by changing the architecture of the polymers. The chemists could make star-shaped polymers with a desired number f of arms. They could also make loops. These each showed instructive behavior when one examined the quantity\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\n10\n\nZN giving the number of configurations. As noted above, this ZN for an ordinary polymer is governed by the exponent γ. However, for loops, one need only know the exponent ν governing the size. For the stars, the exponent γf depended on the number of arms f in a nontrivial way. These exponents γf are experimentally relevant. They dictate the thermodynamic work required to assemble the star from separated arms. Analogous quantities in phase transitions were soon found. By comparing the diagrams, one could identify the γ f exponents as “anomalous dimensions of composite operators.”7 visible only by evaluating multi-point correlation functions in special limits. In the polymer case, all this subtlety was sidestepped simply by synthesizing a polymer with the proper architecture. Like polymers, diffusing particles are random walks. Thus it is easy to represent the interaction between diffusing particles and polymers by simple modifications of the n = 0 diagrams. One had only to remove the self-interaction lines from the diagram lines representing the diffusing particles.25 If f of these particles meet the polymer at a point, one may again ask how the number of configurations varies with f . The corresponding exponents γ˜f describe the interaction of a self-avoiding polymer that absorbs a diffusing substance. These γ˜f exponents again prove to have a nontrivial dependence on f . This fact had conceptual importance. It showed that the probability distribution of absorption on a dilation-symmetric structure like a polymer is a multifractal or fractal measure.26 These fractal measures had been postulated in other phenomena, such as the distribution of vorticity in a highly turbulent fluid. A fractal measure has a complicated form of dilation symmetry that requires a one-index set of critical exponents to characterize it. The polymer absorber example showed in a straightforward way how fractal measures were a natural consequence of diffusion onto a dilation-symmetric object. By the early nineties, the methodology of renormalization was fully accepted by polymer theorists as the way to treat excluded volume effects. It had grown beyond its origins in phase transition theory as an independent realization of the basic renormalization ideas. 27 The methodology was explained in textbooks and monographs by polymer theorists. 28–30 Polymer theorists could readily extract the polymer implications from discoveries in the phase-transition domain. They could also generalize the formalism to discover new forms of dilation symmetry in polymer phenomena with no obvious counterpart in phase transitions. An example is the new exponent governing the demixing of immiscible polymers in a common solvent.31 The n = 0 paper opened the door to this culmination.\n\n4.\n\nField Theory Implications: A Paradoxical Limit\n\nThe aim of the n = 0 paper was to address polymer phenomena. Still, the n = 0 discovery inevitably had an influence on the statistical field theory that made the discovery possible. Some of this influence has been indicated above. The polymeric realization of renormalization symmetry sharpened understanding of this symmetry by decoupling it from the domain of phase transitions and spontaneously broken symmetry. It added a new level of concreteness to our idea of what it means for a system to embody renormalization symmetry. The polymer aspect of phenomena like composite operators enabled insight into field theory that would otherwise have been more difficult.32 The polymer example was the first instance of\n\nwitten\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n11\n\nself-organized criticality33 where dilation symmetry is attained without the need to tune a parameter like temperature to its critical value. In this section we deal with a deeper implication of n = 0. The idea of n = 0 forces one to embrace a paradox. How could a vector field with zero components represent anything but empty space? How could one imagine a broken-symmetry field with minus one Goldstone modes? The perturbation diagrams give a perfectly unambiguous answer to these questions. But since the diagrammatic correspondence is complete, n = 0 represents a polymer beyond the confines of any calculational technique. The passage to the paradoxical state reveals a completely new kind of object. The n = 0 paper does not dwell on this paradox. Still, it establishes a clear meaning for a state where no meaning would have been thought possible beforehand. Since the n = 0 paper, several other n = 0 states have been discovered. Like the polymer case, these states, when viewed naively, represent nothing but empty space. However, when they are treated as de Gennes treated the polymer case, they too reveal surprising states. The simplest case was the generalization from de Gennes’ self-avoiding curves to arbitrary self-avoiding lattice clusters, the so-called lattice animals. In 1975 Lubensky 34 found that these animals emerge from another field theory in just the way that polymers emerge from the conventional critical field theory. His discovery established the equivalence between lattice animals and the randomly-branched polymers long considered by the polymer community.35 The broken symmetry phase of this theory represented another object important in stochastic geometrical objects: the spanning clusters of a randomly-filled lattice at its percolation threshold. Following the polymeric counterpart of this regime led to striking experimental discoveries about the how branched polymers interpenetrate and compress one another.36 Striking differences from linear polymers were thus revealed. A second and more pervasive instance of n = 0 is Edwards’ replica trick.37 It was invented to represent fields such as the vector fields above in the presence of a frozen, disordered environment. One must account for the frozen randomness of the environment differently from the fluctuating randomness of the fields. The replica trick is a way of accounting for the frozen randomness. One imagines n copies or replicas of the vector field, all having the same state of the random environment. Next one allows the random variables representing the environment to fluctuate as the field variables do. With the frozen variables removed, one may calculate the properties of the n-replica state using ordinary methods of statistical physics. Finally, to represent the frozen randomness, one takes the limit in which the number of replicas goes to zero. Edwards had certainly thought about de Gennes’ n = 0 paper before he formulated the replica trick.4 However, there is no evidence that the two discoveries were causally related. The replica trick reveals an n = 0 state, like the cases above, with no apparent relation to the n 6= 0 states that gave rise to it. Here the limit reveals not a new geometry but a new state of randomness. As with the cases above, the ordered phase yields additional insight. By construction all the replicas are equivalent, yet at low temperature the replicas may become spontaneously different. This spontaneously broken replica symmetry 38 persists to n = 0 and represents an important transition in the state of frozen disorder.\n\nMay 25, 2009\n\n16:51\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\n12\n\n5.\n\nAssessment\n\nThe ultimate measure of the importance of an idea is its impact on people’s thinking. How would physicists have thought differently about phase transitions and polymers if the n = 0 paper had not been written? Potential answers to this question range widely. At one extreme, one might view the discovery as a simple bookkeeping trick, like the Dyson formula for summing repeated insertions into a diagram.39 Such a trick would likely have been quickly discovered elsewhere if the original discovery had not been reported. At the other extreme are profound notions such as the duality linking high temperature and low temperature behavior of a phase transition system, discovered by Kramers and Wannier in 1941.40 No student first learning of duality can avoid a sense of wonder that interacting fields can embody such a unifying symmetry. In order to gauge the effect of the n = 0 paper on people’s thinking, the author sought the opinion of several experts within the polymer field and outside it. These scientists gave their permission for their remarks to be used in this chapter. Still, they should not be held responsible for the author’s misinterpretations of their statements. Sir Sam Edwards’ impact spans both polymer physics and statistical field theory. His development of the diagrammatic description set the stage for de Gennes’ insight. He is one of the fathers of the paradigmatic state of frozen disorder: the spin glass.37 In his reply to the author’s query, he focussed on the central problem of computing the exponent ν. He summarized the various ad hoc theories of ν such as Flory’s and noted that he had found a more systematic argument to justify the Flory result. He recalls the series expansion methods noted above. Then he comments on the n = 0 paper: “The paper of dG left me puzzled. Clearly the mean field approach did not give correct indices even though it was pretty accurate so for complex problems one had to work with methods like mean field but there seemed no way of getting that last bit of accuracy. RG [the Renormalization Group] is hopelessly too complicated for real life problems even though, as in Karl [Freed]’s book,28 it offers a rigorous basis for polymer theory. My own view is [that] this whole area is overtaken by the work of Baumgartner and Muthukumar,41 who showed that one can write a program that allows the series expansion to be computerized and the (divergent) series can be summed by Pade summation easily and quickly. It is enormously easier than RG.”\n\nEdwards addresses the n = 0 paper on its own terms, as a means to determine the numerical value of ν. He notes that if this is the goal, the most efficient means need not be based on the renormalization symmetry that ν represents. Edwards views the paper as a clever idea to address an academic issue about the means to achieve arbitrary accuracy for a fundamental number that was well-enough known for practical purposes. The implications of deeper understanding argued above were not the point of the n = 0 paper. Giorgio Parisi is another giant of statistical physics. He was an early participant in developing the renormalization group for phase transitions.7 He co-discovered the notion of replica symmetry breaking in the spin glass.38 Parisi writes: “I do not remember exactly when I learned the de Gennes paper. Quite soon, I guess, because it was used in the framework of the epsilon [4 − d] expansion\n\nwitten\n\nMay 25, 2009\n\n16:51\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n13\n\nto confirm the prediction for the critical exponents. I think that this paper has played a very important role and opened the way to others people to make analytic continuation in n. I think that also the formalism for localization originates for that paper. I do not know how much Edwards and Anderson37 have been influenced by that paper. There was also a paper by Brout in the 50’s42 [titled] “Statistical Mechanical Theory of a Random Ferromagnetic System,” . . . but I do not know if it has influenced the developing of the replica method. Certainly I arrived to spin glasses because I wanted to understand better the n = 0 limit for branched polymers that was developed by Lubensky (I guess).”\n\nParisi goes farther than Edwards in acknowledging a conceptual advance in the n = 0 paper. Yet it does not seem to have exerted a pivotal influence on his own thinking. Instead, he cites the more direct influence of Lubensky’s use of n = 0 in his treatment of branched polymers, summarized above. This impact was evidently strong. It led from a polymeric form of n = 0 to its replica realization to implement frozen randomness. Parisi also raises the possibility of previous awareness of the replica trick in Brout’s early paper. (The author has not investigated this possibility.) Tom Lubensky, the inspiration for Parisi’s work, offered his own views about the importance of the n = 0 paper. As noted above, Lubensky showed that branched polymers, random lattice animals and percolation clusters are realizations of renormalization symmetry, using an n = 0 representation. He is the coauthor of the leading textbook about soft matter statistical physics.43 Lubensky writes: “I don’t remember the exact moment I heard about the n = 0 paper. I believe I saw it in preprint form before it was published. I found it to be a major discovery — so simple yet so powerful. It opened up the statistics of polymers to the entire arsenal of renormalization group techniques. In the end, other RG techniques not relying on the n = 0 trick produced equivalent results in a more physical context, but the n = 0 idea showed that all of this was possible. This paper and the subsequent ones by Des Cloizeaux and by de Gennes on adding an external field to treat semi-dilute systems did have a great impact on my thinking though not immediately. In the late 70’s I extended the n = 0 ideas to branched polymers, where the number of components of the field was merely the fugacity for polymer number, so n → 0 allowed me to develop field theory techniques to study the statistics of individual branched polymers and lattice animals. The de Gennes work also had an impact on my thinking about percolation and the statistics of clusters near the percolation threshold. I think that the n = 0 approach has fallen from favor. The modern polymer focus more on scaling and the Direct RG approach (developed by Des Cloizeaux if memory serves me) and discussed in de Gennes’ book.44 The original concept, however, stands as a very important idea that brought modern RG ideas to polymers.”\n\nLubensky accords the n = 0 paper a fundamental role. He views it as leading the way to understand renormalization symmetry on a deeper and more general basis than was previously seen via phase transitions. He calls this “direct renormalization,” and notes that it is no longer dependent on the phase-transition context that gave birth to it. Thus the n = 0 connection is no longer of great relevance for calculations of polymers. In this sense it has “fallen out of favor.” The cross-fertilization between polymer and phase transition\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\n14\n\nphenomena is no longer primary in his view. Still its fundamental significance of unifying two dissimilar forms of dilation symmetry is acknowledged. The author queried Elihu Abrahams, a father of the theory of waves in disordered media.45 The purpose was to judge the impact of the n = 0 paper on this domain. Abrahams writes: . . . “I would not say that the paper (or rather, note) affected my own work, since I was interested in an entirely different sector of critical phenomena. On the other hand, I think it does represent a substantial contribution, when one recognizes how influential it was on the work of lots of other people.”\n\nBernard Nienhuis is another father of modern statistical physics. The power of dilation symmetry has proven much greater in two dimensions than in three, and much of this power was brought to light by Nienhuis.46 Nienhuis writes: “I remember precisely how I learned of this result. It was quoted and used by H. Hilhorst in a lecture, in 1976. I was very pleased to learn it. Not many years later I heard de Gennes speak about the subject in Vlieland, a small island of the Netherlands, at national theoretical physics meeting. Indeed it influenced my thinking. Especially the usefulness of generalizing models and parameters beyond their original definition. Later I worked with the O(n) [n-vector] model including the limit n → 0, in a paper with Domany Mukamel and Schwimmer (Nucl Phys B190). Soon it enabled me to calculate critical exponents of the O(n) model in two dimensions (PRL 49, 1982). I think de Gennes indeed had an essential influence on my thinking, and his work attracted me to the subject of polymers. Concerning the question if this was a unexpected breakthrough or a follow up on earlier work, I tend to lean to the latter opinion. I think de Gennes’ major contribution was that he understood and used the full consequences of the connection, and developed it into a complete scaling theory.”\n\nNienhuis acknowledges de Gennes’ influence and the power of the n = 0 thinking to draw new implications from field theory. He views the n = 0 finding as one element of an extended process rather than a pivotal discovery. At the time of the n = 0 paper Russia was an active center for polymer field theory, as it is today. The author consulted Alexander Grosberg to learn of its impact there. Grosberg went on to co-author a highly respected monograph on polymer statistical physics. 29 Grosberg writes: “I was a student in 1972, and I could understand nothing in this n = 0 paper until after I learned a little bit of Wilson concurrently with de Gennes. Ilya M. Lifshitz, my teacher, was busy at the time working on the collapsed state of chains, on globules. When the strength of de Gennes approach became evident, there was a huge excitement about the fact that de Gennes approach to what happens above theta-point and Lifshitz approach to what happens below are complementary and together cover the whole range in a way that was seen as a uniformly solid physics (not solid state physics, but solidly built physics). In the subsequent years, there was a huge effort in Moscow to learn the polymer papers by de Gennes and his group. Special seminar was organized, chaired by Lifshitz and working every Tuesday for several years. A significant fraction of the seminar was about reviewing and discussing the French group’s papers. De Gennes’ book44\n\nwitten\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n15\n\nwas translated and published in Russian very soon after the original. In this sense, n = 0 and subsequent work very much shaped our thinking exactly along the lines of complementarity between this approach to good solvent and Lifshitz approach to the bad solvent. This is how our book with Khokhlov 29 is written.”\n\nGrosberg and his colleagues clearly found the n = 0 notion and its implications exciting. For them it was an integral part of the “scaling concepts”44 that gave de Gennes work on polymers their major impact. The author himself was greatly influenced by the paper: “Like several of the others quoted above, I learned of the n = 0 discovery secondhand. In this period I was learning about the renormalization group as a postdoc. I viewed the n = 0 discovery as a profound realization. On the one hand, it meant that all the powerful results from phase transition renormalization were immediately applicable to the polymer domain, where understanding was much more primitive. On the other hand, the polymer interpretation of the diagrams revealed the renormalization symmetry as a phenomenon of striking and concrete simplicity. It was much more accessible than its phase transition counterpart. These implications were clear from the statement of the n = 0 correspondence, even though none of these implications were stated in the paper. The implications that this paper brought to light were the seed leading to the advances much celebrated above.”\n\n6.\n\nConclusion\n\nAlmost forty years have passed since the n = 0 paper of Ref. 5 was published. The strong activity of exploring the implications of anomalous scaling properties like the exponent ν have largely subsided. The main activity in polymers concerns dense fluids and solids where these good-solvent scaling properties are of little importance. Likewise the search for analogous “anomalous scaling” phenomena in the domain of phase transitions has subsided. How should we interpret this decline in activity? Were the n = 0 paper and those that followed it a distraction from the problems of ongoing importance? Another interpretation seems more likely. These papers about excluded volume effects, both theoretical and experimental, transformed our understanding of this issue. What had been a central puzzle of polymers is now a settled problem. We now have the means to understand why exponents such as ν appear and to calculate these exponents as accurately as needed. We know how to devise well-founded scaling laws that show the consequences of these exponents for measured properties. Finally, we know how to recognize combinations of measured quantities that must approach universal, system-independent values for sufficiently long chains. For polymer physics the n = 0 paper revealed the key idea that enabled this framework of understanding to be built for polymers. But the benefits of the paper do not stop there. The recognition that polymers are a realization of the renormalization group gave profound insight into the nature of renormalization symmetry. Using the polymer example, the process of establishing the dilation symmetry of a system via renormalization was shown to be simpler and more direct than in the phase transition phenomena where renormalization was invented. One could infer the symmetry merely by examining a single long polymer\n\nJune 8, 2009\n\n16:25\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\n16\n\nconfiguration. As noted above, the scope of dilation symmetric phenomena has expanded greatly since that time. Stochastic geometric objects like random animals, disordered quantum states, stochastic growth processes and chaotic dynamics have all shown dilation symmetry. For all such phenomena, the polymer example served as an early inspiration and continues to serve as one of the simplest paradigms of nontrivial dilation symmetry.\n\nReferences 1. K. G. Wilson and M. E. Fisher, Critical exponents in 3.99 dimensions, Phys. Rev. Lett. 28, 240 (1972). 2. L. Kadanoff, Scaling laws for Ising models near Tc , Phys. 2, 263 (1966). 3. Fran¸coise Brochard, private communication. 4. S. F. Edwards (private communication) recalls that de Gennes had recognized the n = 0 connection years before submitting the n = 0 paper. He had seen that the n-vector diagrams for n = 0 were those needed to account for polymer excluded volume. Such diagrams for general n had been known before Wilson used them to calculate exponents. However de Gennes had not published this observation since at that time he saw no concrete use to be made of it. 5. P. G. de Gennes, Exponents for excluded volume problem as derived by Wilson method, Phys. Lett. A 38, 339 (1972). 6. A. Einstein, Ann. Physik 17, 549 (1905); 19, 371 (1906). 7. E. Br´ezin and J. M. Charap (eds.), Carg`ese Lectures in Field Theory and Critical Phenomena (Gordon and Breach, New York, 1975). 8. K. G. Wilson and J. Kogut, The renormalization group and the epsilon expansion, Phys. Repts. 12, 75–200 (1974). ¨ 9. H. Staudinger, Uber Polymerisation, Berich. Deut. Chem. Ges. 53, 1073 (1920). 10. Paul J. Flory, Statistical Mechanics of Chain Molecules (Interscience, New York, 1969). 11. H. E. Stanley, Introduction to Phase Transitions and Critical Phenomona (Clarendon Press, Oxford, 1971). 12. H. Yamakawa et al., J. Chem. Phys. 45, 1938 (1966). 13. F. T. Wall and J. J. Erpenbeck, J. Chem. Phys. 30, 634 (1959). 14. M. Fixman, J. Chem. Phys. 23, 1657 (1955). 15. M. E. Fisher and M. F. Sykes, Excluded-Volume Problem and the Ising Model of Ferromagnetism, Phys. Rev. 114, 45 (1959). 16. C. Domb and M. F. Sykes, Use of series expansions for Ising model susceptibility and excluded volume problem, J. Math. Phys. 2, 63 (1961). 17. S. F. Edwards, Statistical mechanics of polymers with excluded volume, Proc. Phys. Soc. London 85, 613 (1965). 18. H. Yamakawa, Modern Theory of Polymer Solutions (Harper and Row, New York, 1971). 19. J. des Cloizeaux, Lagrangian theory of polymer-solutions at intermediate concentrations, J. de Phys. 36, 281 (1975). 20. M. Daoud, J. P. Cotton, B. Farnoux, G. Jannink, G. Sarma, H. Benoit, R. Duplessix, C. Picot and P. G. de Gennes, Solutions of flexible polymers — neutron experiments and interpretation, Macromolecules 8, 804 (1975). 21. P. G. de Gennes, Reptation of a polymer chain in presence of fixed obstacles, J. Chem. Phys. 55, 572 (1971). 22. T. A. Witten and L. Sch¨ afer, Two critical ratios in polymer solutions, J. Phys. A 11, 1843 (1978). 23. E. Eisenriegler, K. Kremer and K. Binder, Adsorption of polymer-chains at surfaces: scaling and Monte-Carlo analyses, J. Chem. Phys 77, 6296 (1982).\n\nwitten\n\nMay 8, 2009\n\n16:33\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nwitten\n\n17\n\n24. Z. G. Wang, A. M. Nemirovsky and K. F. Freed, Polymers with excluded volume in various geometries — renormalization-group methods, J. Chem. Phys. 86, 4266 (1987). 25. M. E. Cates and T. A. Witten, A family of exponents for Laplace’s equation near a Polymer, Phys. Rev. Lett. 56, 2497 (1986). 26. T. C. Halsey, M. H. Jensen, L. P. Kadanoff, I. Procaccia and B. I. Shraiman, Fractal measures and their singularities — the characterization of strange sets, Phys. Rev. A 33, 1141 (1986). 27. J. des Cloizeaux, Polymers in solutions — principles and applications of a direct renormalization method, J. de Phys. 42, 635 (1981). 28. K. F. Freed, Renormalization Group Theory of Macromolecules (Wiley, New York, 1987). 29. A. Yu. Grosberg and A. R. Khokhlov, Statistical Physics of Macromolecules (AIP Press, New York, 1994). 30. L. Sch¨ afer, Excluded Volume Effects in Polymer Solutions as Explained by the Renormalization Group (Springer, New York, 1999). 31. J. F. Joanny, L. Leibler and R. Ball, Is chemical mismatch important in polymer-solutions? J. Chem. Phys. 81, 4640 (1984). 32. B. Duplantier, Polymer network of fixed topology — renormalization, exact critical exponent gamma in 2 dimensions, and d = 4-epsilon, Phys. Rev. Lett. 57, 941 (1986). 33. P. Bak, C. Tang and K. Wiesenfeld, Self-organized criticality, Phys. Rev. A 38, 364 (1988). 34. T. C. Lubensky, Critical properties of random-spin models from epsilon expansion, Phys. Rev. B 11, 3573 (1975); T. C. Lubensky and J. Isaacson, Statistics of lattice animals and dilute branched polymers, Phys. Rev. A 20, 2130 (1979). 35. W. H. Stockmayer, Theory of molecular size distribution and gel formation in branched-chain polymers, J. Chem. Phys. 11, 45 (1943). 36. M. Daoud, F. Family and G. Jannink, Dilution and polydispersity in branched polymers, J. de Phys. Lett. 45, L199 (1984). 37. S. F. Edwards and P. W. Anderson, Theory of spin glasses, J. Phys. F 5, 965 (1975). 38. M. Mezard, G. Parisi, N. Sourlas, G. Toulouse and M. Virasoro, Replica symmetry-breaking and the nature of the spin-glass phase, J. de Phys. 45, 843 (1984). 39. L. P. Kadanoff and G. Baym, Quantum Statistical Mechanics (Benjamin, New York, 1962). 40. R. Savit, Duality in field-theory and statistical systems, Rev. Mod. Phys. 52, 453 (1980). 41. The author could not find a reference to this work. 42. R. Brout, Statistical mechanical theory of a random ferromagnetic system, Phys. Rev. 115, 824 (1959). 43. P. Chaikin and T. Lubensky, Principles of Condensed Matter Physics (Cambridge Press, Cambridge, 1995). 44. P.-G. de Gennes, Scaling Concepts in Polymer Physics (Cornell Univ. Press, Ithaca NY, 1979). 45. E. Abrahams, P. W. Anderson, D. C. Licciardello and T. V. Ramakrishnan, Scaling theory of localization — absence of quantum diffusion in 2 dimensions, Phys. Rev. Lett. 42, 673 (1979). 46. B. Nienhuis, Exact critical-point and critical exponents of O(n) models in 2 dimensions, Phys. Rev. Lett. 49, 1062 (1982).\n\n18\n\nVolume 38A, number 5\n\n28 February 1972\n\nPHYSICS L E T T E R S\n\nE X P O N E N T S FOR THE E X C L U D E D VOLUME P R O B L E M AS D E R I V E D BY T H E W I L S O N M E T H O D P. G. DE GENNES College de France, pi. M. Berthelot, 75 Paris 5e, France Received 10 January 1972 By an expansion to second order in e = 4-d, we derive the mean square extension fl2 for a random, self excluding walk of N jumps on a d-dimensional lattice. The result is: R% = const. JV^-^^(for d = 3).\n\nLet Tn(R) be the number of non intersecting walks of N steps connecting the sites 0 and R on the lattice, and: 00\n\nG(P,k)=\n\n£ 2 TAR) N^OR \"\n\nexp(ift-/?) exp(--tfP) . (1)\n\nWhen P decreases, on the real axis, down to a certain value P c , we reach a singularity of G: limp _\n\np\n\nG(P, k =0) = const. {P-Pc)'y\n\n.\n\nN -» °°, N - °°, N/N = p o o\n\n(2)\n\nThe total number of non-intersecting walks of N steps starting from the origin is: 71\n\nZn = const. N '\n\nDefine the thermodynamic functions S(P), S(P, p), b y :\n\nexp (S(P,p)) = Hw exp (-NP)\\N=NQP\n\nJust at P = Pc, we expect that G(Pc,k) = const, k -2+f?. From the usual scaling arguments, the mean square distance traveled during a self-avoiding walk of N steps is i?2 = const. N%vwithy =7/2-77. In the present note we compute y and 77 using the method of Wilson [1]. We expand G in powers of the excluded volume parameter v0. The corresponding diagrams are described in the literature [2]. The scaling results are known to be independent of the magnitude of v0, provided that v0 > 0. We then choose v0 so that the renormalised coupling constant r satisfies the scaling requirement for the 4-point vertex*: r=\n\nfinite.\n\nexp(S(P)) = EH M exp(-JV-p) N\n\nexp(NPc) .\n\nconst. r£ \" 2?j/2 -r\\,\n\nEq. (3) may also be obtained as follows: for real values of P below P c , it is possible to define a continuation to the problem of eq. (1). Consider a lattice of N0 sites, and call H the number of ways of drawing on this lattice one self excluding chain of lenght N. The limit of interest is:\n\n(P-\n\nPp)r\n\n* This derivation of eq. (3) was suggested by P. Martin.\n\n(3)\n\n.\n\nThese functions are also singular at P = P c . The funtionS (P, p) may be expanded in powers of p. With the usual scaling assumption and notation, the expansion is: S(P, p) = a ( P - P ) 2 - « ' 0 c +\n\n+\n\na 1 (P c -P)^'p + ia2(Pc-P) y '\" 2 V\n\n(4)\n\nThe coefficient of £p2 is the renormalised coupling constant. Again through scaling relations, it coincides with eq. (3). The diagrams for the spin problem of ref. [1] and the diagrams for the chain problem have the same topology, if the interactions are drawn as point-like. But, if the interactions are r e presented by dotted lines, a distinction appears. For instance, in the first order corrections to G, the \"direct\" diagram with one closed particle loop, which contributes a term propor339\n\n19\n\nVolume 38A, number 5\n\nPHYSICS L E T T E R S\n\n28 February 1972\n\nthis would give y = 1 + e / 6 , in disagreement with eq. (5). A similar criticism applies to the Gaussian variational method [5] where 2vG = 4/d -> i + e/4 .\n\ntional to the spin index n in ref. [ 1], has no counterpart for the chain problem: only the \"exchange\" diagram remains. Finally the Wilson formulae may be used provided that (a) the index n is set equal to zero; (b) the Wilson interaction constant uQ is replaced by jv0- The results a r e :\n\nIt is a pleasure to thank P. Martin, J. des Cloiseaux and P. Hohenberg for various discussions on related subjects.\n\ny = l + e / 8 + 1 3 e 2 / 2 8 + 0(e 3 ) (5) T/ = (e 2 /64)[l + 17e/l6] + 0(e 4 ) .\n\nReferences\n\nFor e = 1 (d= 3), y = 1.176, 77 = 0.032 and 2v = 1.195, in very good agreement with the series results of Fisher and Hiley [3]. The result for 2v is close the Flory value (2VY = I), but this is somewhat fortuitous: for an arbitrary d ( 100) have an overlap parameter P > 10. These melts are liquids, but have elastic properties at short time scales similar to polymer networks. For example, silly putty is a polymer liquid (melt), but it bounces off the floor like a rubber ball. This “bouncing” capability is reflected by the characteristic rubbery plateau region in the stress relaxation function of a melt.1, 2 Elastic properties of polymer melts on short time scales were attributed to topological interactions (called entanglements) between chains as early as in 1930’s and 1940’s. 3, 4 These entanglements arise because polymers cannot cross each other and impose topological constraints on polymer motion [see Fig. 1(a)]. Topological constraints in polymer melts were P ∼\n\nrubinstein\n\nJune 8, 2009\n\n16:38\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nrubinstein\n\n21\n\nFig. 1. (a) An entanglement is often visualized as a pairwise topological constraint between two chains. (b) Pairwise entanglements due to non-crossability of chains were represented by a temporary cross-link in early models (shown in the figure by associations between green reversible “stickers”).\n\ncalled temporary entanglements because they put temporary restrictions on the motion of polymers (as opposed to permanent entanglements as in an Olympic gel).5 Entanglements between polymer chains in a melt are arguably the most important and the most characteristic property of the dynamics of polymer melts. The precise definition of a temporary entanglement between chains in a melt was not given in 1930’s and unfortunately still does not exist now. Early models of entanglements treated them as temporary cross-links [see Fig. 1(b)].6–8 On time scales shorter than the lifetime τ of such cross-links, properties of polymer melts were similar to those of permanent networks. Cross-links were assumed to break and re-connect on time scales on the order of τ , allowing a polymer melt to flow. The problem with this class of models is that in order for them to agree with experiments, one would need to assume that the life-time of crosslinks depends on the degree of polymerization of chains in a melt. This assumption was hard to justify as entanglements were visualized as local constraints. This class of models is currently extensively used to describe unentangled reversible networks with temporary cross-links representing reversible associations between the groups along the chains. 9–12 An alternative model of the dynamics of entangled polymer melts13 was proposed by Bueche in 1952. Bueche introduced the idea of entanglement friction and analyzed it by studying snaking circular motion of chains around entanglements. This idea is closest in spirit to the de Gennes’ reptation model that was proposed two decades later and revolutionized the field of polymer dynamics.\n\n2.\n\nTube Model\n\nThe first major breakthrough in modeling polymer entanglements was made by Edwards 14 for polymer networks in which such entanglements are permanent.15 Topological restrictions of surrounding network strands imposed on a given chain were represented by the topological potential applied to every monomer of the chain. This potential effectively restricts fluctuations of the chain to a confining tube (Fig. 2). Edwards’ tube model reduces a many-chain problem with complicated topological interactions to a much simpler problem of a single chain in a potential. Each entangled chain in a network fluctuates around the axis of its confining tube, called the primitive path.1 The diameter a of the confining tube determines the length scale at which the confining potential restricts free fluctuations of the chain. On smaller length scales the chain “does not know” that it is entangled, as the\n\nJune 8, 2009\n\n16:38\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nrubinstein\n\n22\n\nFig. 2. Topological constraints imposed by neighboring chains (left sketch) are replaced\n\nFig. 2. Topological constraints imposed by neighboring chains (left sketch) are replaced by a potential that restricts chain fluctuations to a confining tube (right sketch) in the Edwards tube model. The center line of the tube is called primitive path (dashed line).\n\neffect of a confining potential on chain fluctuations is less than thermal energy kB T . On length scales larger than tube diameter a, chain fluctuations are strongly suppressed by the confining potential and the chain is forced to follow the trajectory of the primitive path. The primitive path is a random walk with the same end-to-end vector as the chain, but with step size on the order of the tube diameter a and with an average contour length of the tube hLi ≈ b2 N/a ,\n\n(2)\n\nhR2 i ≈ b2 N ≈ hLia ,\n\n(3)\n\nwhere\n\nis the mean square end-to-end distance of the chain. The confining tube model is consistent with the experimental observations16 of the nonzero limiting value of the modulus of polymer networks with increasing molecular weight between cross-links. This limiting value of the elastic modulus, Ge , is related to the strength of the confining potential as expressed by the entanglement strand with degree of polymerization, Ne , and size defined by the tube diameter a ≈ bNe1/2 .\n\n(4)\n\nThe elastic modulus Ge , called the plateau modulus, is on the order of thermal energy kB T per entanglement strand Ge ≈\n\nkB T . b 3 Ne\n\n(5)\n\nTypical values of tube diameter are a ∼ 5 nm and of plateau modulus are Ge ∼ 1 MPa. 3.\n\nReptation Model\n\nThe giant step of extending the confining tube idea to uncross-linked chains for which topological interactions are not permanent was made by P. G. de Gennes17 (see the first reprint paper at the end of the present chapter). In his classic paper that started a new era of polymer dynamics, de Gennes considered a single chain in an array of fixed obstacles1 (e.g. free chain diffusing through cross-linked network). He represented topological constraints of these obstacles by a confining tube. The confining tube that was permanent in Edwards\n\nJune 8, 2009\n\n16:38\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nrubinstein\n\n23\n\nFig. 3. An elementary step of de Gennes’ reptation model. (a) A small unentangled loop (defect) is formed at one end of the chain, “erasing” the section of the tube there. (b) The unentangled loop diffuses along the tube. (c) The loop (defect) is released at the other end of the chain, creating a new section of the tube at that end.\n\nmodel of entangled polymer networks14 became temporary in the de Gennes model of a free chain diffusing through an array of fixed obstacles17 as it was moving with the chain. The process by which the chain moves along its confining tube was called reptation by analogy with the snaking movement of reptiles. The main idea of the reptation model is that although chain motion perpendicular to the axis of the confining tube is topologically restricted by the confining potential, its motion along the contour of the tube remains unconstrained.5 De Gennes analyzed the main mode of this motion — chain diffusion along the primitive path of the confining tube. He attributed this motion to the diffusion of small unentangled loops, that he called “defects” (see first reprint paper for details). These small loops of stored length are created by fluctuations at one end of the tube [Fig. 3(a)] and diffuse along the contour of the tube [Fig. 3(b)] to the other end, where they are released and form a new section of the tube [Fig. 3(c)]. Since the motion of the chain along the contour of the tube is unconstrained, the corresponding curvilinear friction coefficient of the chain is the same as the friction coefficient of an unentangled chain. In a melt with screened hydrodynamic interactions, this friction coefficient is linearly proportional to the number of monomers per chain ζ = ζ0 N ,\n\n(6)\n\nwhere ζ0 is the monomeric friction coefficient. The related curvilinear diffusion coefficient is obtained from the fluctuation-dissipation theorem (Einstein relation) Dc =\n\nkB T D0 kB T = = , ζ ζ0 N N\n\n(7)\n\nwhere D0 is the monomeric diffusion coefficient. The time it takes for the chain to reptate out of its original tube is called the reptation time τrep ≈\n\nhLi2 N3 ≈ τ0 , Dc Ne\n\n(8)\n\nwhere the monomeric relaxation time is τ0 ≈\n\nζ0 b2 . kB T\n\n(9)\n\nDuring reptation time τrep the chain diffuses an average distance hLi along the contour of the tube and a distance R ≈ bN 1/2 in three-dimensional space with the corresponding 3-d diffusion coefficient D3d ≈\n\nNe R2 ≈ D0 2 . τrep N\n\n(10)\n\nMay 22, 2009\n\n19:14\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nrubinstein\n\n24\n\nThe success of the reptation model is that its two main predictions, reptation time and diffusion coefficient, obtained in an elegant and relatively simple way were found to be in reasonable agreement with experiments. The experimentally measured dependence of the diffusion coefficient on the degree of polymerization18 D ∼ N −2 was found to be in agreement with the prediction of the reptation model [Eq. (10)], while the measured N-dependence of the relaxation time of a polymer melt is slightly stronger19 τrelax ∼ N 3.4\n\n(11)\n\nthan that predicted by reptation. We address the possible reason for this disagreement in Sec. 6.2 below. Despite the crude approximations made by the reptation model, which describes the motion of a single chain in an array of fixed obstacles and ignores the motion of surrounding chains, the agreement between its predictions and results of experiments and computer simulations20 is astonishing.\n\n4.\n\nConstraint Release\n\nIt was not at all obvious why and how the reptation model could be extended from describing the motion of a chain in an array of fixed obstacles to a polymer melt in which all chains are free to diffuse and therefore constraints they impose on a given chain change with time.21 The confining tube of a chain in polymer melts is renewed not only at chain ends by reptation, but also all along its contour.1 The first model describing the effect of the motion of surrounding chains on the dynamics of a given entangled polymer was proposed by de Gennes22 in 1975 (see the second reprint paper at the end of the present chapter). When a neighboring chain reptates away, the constraint it used to impose on a given polymer is released and the confining tube of this polymer can locally rearrange (see Fig. 4). This rearrangement corresponds to the local change of the primitive path of this tube — its local “hop” by a distance on the order of tube diameter a. De Gennes proposed to use the Rouse model to describe this rearrangement process of a confining tube of a chain due to reptation of surrounding polymers. This approach remains the state of the art even today. In his 1975 paper (see second reprint paper) de Gennes assumed that the rate of the constraint release process (jump rate of primitive path segments) is proportional to the fraction of chain ends.22 This assumption was corrected and replaced a couple of years later23, 24 by a more physical assumption that the lifetime of\n\nFig. 4. Constraint release process. As chain B reptates away, it releases a constraint it used to impose on chain A and allows its tube to locally rearrange. The lower set of drawings represents local Rouse-like hop of the primitive path of chain A due to this event.\n\nMay 22, 2009\n\n19:14\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nrubinstein\n\n25\n\na constraint is proportional to the reptation time of the corresponding neighboring chains P3 τP ≈ τ 0 , (12) Ne where P is the degree of polymerization of surrounding polymers. The resulting diffusion time of the primitive path of a test N -mer due to the constraint release process, caused by the reptation of surrounding P -mers, is calculated as the Rouse time of a chain consisting of N/Ne primitive path segments 2 N P 3N 2 τcr ≈ τP (13) ≈ τ0 Ne Ne3 where τP is the hop time of a primitive path segment [Eq. (12)]. The constraint release time is much longer than reptation time of an N -mer for sufficiently well-entangled surrounding P -mers which is certainly the case in a monodisperse melt (P = N > Ne ). The above estimate suggests that contribution of constraint release to the diffusion of a test N -mer is negligible in comparison to the contribution of reptation [Eq. (10)] for (P/Ne )3 N/Ne . This justifies ignoring the motion of surrounding chains in the calculation of polymer diffusion in monodisperse melts (P = N ) and validates the assumption of fixed obstacles made in the original reptation model. See Sec. 6.3 for a more recent modification of the constraint release model.\n\n5.\n\nArm Retraction\n\nChain ends play an essential role in the de Gennes reptation model.17 Small loops of stored length (defects) are formed at one end of the chain and released at the other end (Fig. 3). Branched polymers, such as stars, present the first conceptual challenge for the reptation model, as branch points cannot slide along the confining tube. If they did, several strands of the molecule would be pulled into the confining tube of one of the arms. This process is entropically unfavorable and is therefore exponentially suppressed (for stars with more than three arms). Entangled stars in an array of fixed obstacles diffuse by the arm retraction process that was proposed by de Gennes in the same 1975 paper (see second reprint paper).22 The arm retraction process requires for an arm of a branched polymer to double-fold, forming a huge loop. This double-folding process can be visualized by the end of an arm moving up along its confining tube towards the branch point (Fig. 5). Any “mistake” in this retraction process would lead to an unacceptable conformation and the chain end would have to go back and start the retraction process again. The probability of a successful arm retraction is therefore exponentially low in the number of primitive path steps N/Ne which the end has to make in order to reach the branch point p ∼ exp(−νN/Ne ), where ν is a constant on the order of unity. The resulting arm retraction time is exponentially large in the number of primitive path steps τarm ∼ exp(υN/Ne ) This prediction of the de Gennes’ arm retraction model ments.25\n\n(14) 22\n\nhas been confirmed by experi-\n\nMay 22, 2009\n\n19:14\n\nWSPC — Reprint Volume Book - Trim Size:- 10in x 7in\n\nrubinstein\n\n26\n\nFig. 5.\n\nArm retraction process of a branched polymer in an array of fixed obstacles (represented by circles).\n\nDe Gennes did not consider rea"
    }
}