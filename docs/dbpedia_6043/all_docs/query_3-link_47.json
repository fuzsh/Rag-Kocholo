{
    "id": "dbpedia_6043_3",
    "rank": 47,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/",
        "read_more_link": "",
        "language": "en",
        "title": "IsoSCM: improved and alternative 3′ UTR annotation using multiple change-point inference",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-rna.gif",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14f01.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14eq01.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14eq02.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14eq03.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14eq04.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14eq05.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14f02.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14f03.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14f04.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14f05.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14eq06.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/bin/14f06.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Sol Shenker",
            "Pedro Miura",
            "Piero Sanfilippo",
            "Eric C. Lai"
        ],
        "publish_date": "2015-01-29T00:00:00",
        "summary": "",
        "meta_description": "Major applications of RNA-seq data include studies of how the transcriptome is modulated at the levels of gene expression and RNA processing, and how these events are related to cellular identity, environmental condition, and/or disease status. While ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4274634/",
        "text": "INTRODUCTION\n\nThe recent astonishing advances in RNA-sequencing (RNA-seq) technologies have spurred the development of numerous methods to exploit these data for diverse applications, such as inferring transcript structures, differential gene expression, and alternative RNA processing. These analyses require models of transcript structure that serve as a foundation for transcriptome analysis, and to quantify differences in read mapping between conditions (Martin and Wang 2011). While transcript structures were historically inferred from full-length cDNA sequences (Adams et al. 1995), the wealth of data from RNA-seq experiments has greatly expanded transcriptome annotation pipelines more recently (Djebali et al. 2012; Brown et al. 2014).\n\nStrategies for transcript assembly can be categorized based on their dependence on a reference genome sequence. Genome-independent (de novo) approaches typically construct a De Brujin graph representing reads sharing compatible subsequences, then use heuristics to decompose this graph to recover full-length transcript sequences (Martin and Wang 2011). Genome-dependent approaches decompose the transcript assembly problem into smaller subproblems by first mapping the reads to the reference sequence, and then constructing gene models that are consistent with the aligned reads (Denoeud et al. 2008; Mortazavi et al. 2008; Yassour et al. 2009; Guttman et al. 2010; Trapnell et al. 2010). Since these strategies operate in the absence of any reference gene models, they are termed ab initio transcript assembly methods.\n\nIn addition to transcript assembly, a separate class of methods attempts to quantify the relative abundance of transcripts and isoforms using RNA-seq data (Feng et al. 2011; Li et al. 2011a,b; Behr et al. 2013; Hiller and Wong 2013). Since alternatively processed gene products are frequently encoded in overlapping genomic locales, and RNA-seq reads typically cannot be unambiguously assigned to overlapping transcripts, these methods attempt to construct parsimonious models for transcript abundance that are consistent with observed read counts. Importantly, these approaches cannot be applied if a set of reference models is not available, and may provide inaccurate quantification if these models are not complete.\n\nWhile the problem of full-length transcript assembly from short reads is in general difficult and underdetermined (Behr et al. 2013), current methods have particular difficulties in annotating 3′ terminal exons correctly. In contrast to the boundaries of internal exons, which can be identified precisely by virtue of reads that span splice junctions, terminal exon boundaries only evince themselves in RNA-seq data as the position at which read coverage decreases. To identify terminal boundaries the popular transcriptome assembly tool Cufflinks constructs a minimum path cover from compatible RNA-seq reads, resulting in a single terminal exon annotation that extends from the last splice acceptor site to the position where there is zero read coverage (Trapnell et al. 2010). Since low-frequency polyadenylation site read-through events are captured in RNA-seq experiments, this strategy will often result in the terminal 3′ exon boundary being extended beyond the dominantly used polyadenylation site. Cufflinks implements a post hoc trimming process to mitigate this problem. Another well-utilized transcriptome assembly tool, Scripture, identifies transcribed segments of the genome using scan statistics. Here, the terminal exon boundary is determined as the location where the statistic calculated within a window overlapping the terminal exon drops below the genome-wide significance threshold (Guttman et al. 2010).\n\nNeither of these strategies is specifically designed to identify the set of positions at which the level of RNA-seq coverage transitions from high-to-low coverage, and neither is capable of generating more than one terminal exon annotation. Consequently, the terminal exon annotations built from RNA-seq data can be inaccurate and incomplete. This point was emphasized during a recent comparative assessment of 14 different algorithms for transcript assembly and exon identification, conducted as part of the RNA-seq Genome Annotation Assessment Project (RGASP) (Steijger et al. 2013). In particular, the outputs for transcript termini from all of the algorithms tested were sufficiently inaccurate that a relaxed criteria exon correctness was used that evaluated only on the 5′ boundary of the 3′ terminal exon (Steijger et al. 2013). This highlighted the need for improved methods to identify transcript termini from RNA-seq data.\n\nThe 3′ untranslated region (3′ UTR) is an important location of post-transcriptional regulation, and deregulation of 3′ end formation has medical relevance (Elkon et al. 2013). In recent years, there has been increasing appreciation that most genes are subject to alternative cleavage and polyadenylation (APA) to yield multiple 3′ UTR isoforms, and that APA is frequently modulated in tissue-specific, state-specific, or environmentally responsive manner (Miura et al. 2014). Although various specialized techniques have been developed to sequence the 3′ ends of transcripts (Elkon et al. 2013), conventional RNA-seq methods remain the methodology of choice for most laboratories, and the amount of existing RNA-seq data is far greater than for 3′-seq data. Thus, it would be highly desirable to improve the accuracy with which we can infer 3′ UTR boundaries and alternative isoform expression from RNA-seq data.\n\nRecently, we used tissue-specific RNA-seq data to refine terminal exon models in the human and mouse genomes (Miura et al. 2013). We encountered unique challenges when refining terminal exons, which motivated the implementation of a specialized annotation process for 3′ terminal exons. For example, while transposable element insertions are strongly selected against in the coding exons of a gene, UTRs are less constrained and harbor thousands of repetitive elements genome wide (Chen et al. 2009). Nonuniform read coverage arising from sequence specific (Hansen et al. 2010; Lahens et al. 2014) as well as positional biases (Bohnert and Rätsch 2010), and uncertain allocation of multimapping reads (Mortazavi et al. 2008) can cause artificial local gaps in RNA-seq coverage, making it difficult to annotate full-length 3′ UTR models using next-generation sequencing data alone ( A). We previously developed an ad hoc procedure to bridge short gaps in RNA-seq coverage when known sources of sequencing bias could be identified. This enabled us to extend thousands of 3′ UTR models in the extensively annotated mouse and human genomes. A substantial proportion of these extensions show tissue-specific expression patterns, and identify a previously unappreciated potential for post-transcriptional regulation in the extended genes (Miura et al. 2013).\n\nWe formalize this procedure here, extending our previous work for terminal exon annotation, using a segmentation approach that integrates long-range patterns of RNA-seq coverage to identify polyadenylation sites with greater sensitivity and specificity than existing methods. More importantly, we demonstrate its utility for identifying complex patterns of tandem polyadenylation site usage that are inaccessible with conventional annotation strategies. We implement our approach as the stand-alone program Isoform Structural Change Model (IsoSCM), which is available from our website (https://github.com/shenkers/isoscm).\n\nRESULTS\n\nTransitions in coverage depth identify 3′ UTR boundaries\n\nRNA-seq protocols sample reads from across transcript bodies, approximately uniformly, although with certain biases (Mortazavi et al. 2008). Existing approaches use minimum path coverage (Trapnell et al. 2010), or a scan statistic (Guttman et al. 2010), to identify transcribed segments, and annotate at most one 3′ boundary for each terminal exon, typically the longest isoform compatible with the reads. Since the longest isoform will not in general reflect the dominant 3′ UTR isoform used by a gene, Cufflinks uses a heuristic post-assembly processing step to trim terminal exon annotations to a prespecified fraction of the average level of coverage. While such a strategy will identify high abundance short isoforms at a subset of loci, a single trimming parameter will not result in optimal annotations genome wide. Moreover, these strategies tend to generate incomplete 3′ UTR assemblies because they cannot capture tandem terminal exon isoforms that are coexpressed in a given sample, as illustrated in B.\n\nGiven the unique challenges associated with transcript assembly within 3′ UTRs, and to address the limitations of existing tools, we developed a more expressive framework for transcript assembly that incorporates information from the patterns of read coverage into the process of UTR boundary definition. If we assume that sequenced reads are distributed approximately uniformly across the transcript, the boundaries of transcription will be marked by a change in the level of coverage. In instances where a shorter exon is nested within a longer exon, there can still be a significant number of reads aligning downstream from the shorter isoform, creating a “step-like” pattern of coverage at the boundary of the nested exon model. For example, RNA-seq data for the Hdlbp and Ict1 genes show such drop-offs within their 3′ UTRs, indicative of tandem APA events ( B,C).\n\nTo identify terminal exon boundaries, we thus seek critical points (“change points”) that mark transitions in RNA-seq coverage. Previously, segmentation approaches were used to identify transcript boundaries from tiling microarray probe intensities (Huber et al. 2006), and while these change points have been described in RNA-seq data (Nagalakshmi et al. 2008), no existing RNA-seq ab initio transcript assembly tool fully leverages this information to annotate 3′ UTR boundaries. To fill this gap, we adapt multiple change-point inference to the problem of 3′ UTR isoform identification.\n\nInference for multiple change-point problems\n\nTo implement change-point inference, we made use of a Bayesian framework for change-point inference established previously (Fearnhead 2006). For a sequence of n observations y1:n = y1,…,yn representing the level of coverage at sequential genomic positions, we consider all possible combinations of m change points τ1,…,τm where 0 < τi < n and τi < τi+1, and 0 ≤ m < n, such that the jth segment pertains to the observed level of coverage between two successive change points. We assume that the level of coverage observed at each position within a segment are independent samples from a common probability distribution f(x|θ), parameterized by θ, with prior distribution π(θ). To model the expected length of a segment, we define a probability mass function g(t) for the length t of the genomic segment between two successive change points, with a cumulative mass function G(t)=∑s=1tg(s). Given this probability model, the goal of change-point inference is to identify the set of change points that maximizes the marginal likelihood of the data, i.e., the set of change points that “best explain” the observed pattern of read coverage.\n\nTo achieve this, we implemented a dynamic programming algorithm that recursively calculates the maximum marginal likelihood solution for nested subsequences of the observations. To begin, for all indices in a subsequences yt:s, such that 0 ≤ t ≤ s ≤ n we calculate a marginal likelihood P(t,s) that the observations yt:s were sampled from a common distribution as the integral of the joint data likelihood over the possible parameter values within that segment:\n\n(1)\n\nThe most likely segmentation using this model is defined recursively in terms of the likelihood of the current segment ( C, red bracket), and the likelihood of the remainder of the data ( C, blue bracket), and alternately, the likelihood of the remainder of the data coming from a single segment ( C, green bracket). This requires the construction of two tables Q(t) and R(t) of length n, indexed by t, the location of the start of the current segment. Q(t) stores the maximum marginal likelihood of a segmentation of the subsequence of observations from yt:n, given a change point at t − 1, while R(t) stores the index of the next change point in the maximum marginal likelihood segmentation, given a change point at t − 1. These tables can be recursively computed in O(n2) operations using the formulas:\n\n(2)\n\n(3)\n\nThe sequence of change points can be recovered by performing a trace-back through table R(t); the location of the first change point τ1 is given by R(1), and subsequent change points are given by τj + 1 = R(τj), while τj < n. A more detailed derivation of these equations along with proofs is given previously (Fearnhead 2006).\n\nConstraining the location of change points\n\nAlthough the change point model is able to tolerate a degree of variation within each segment, real RNA-seq data contain sequencing biases that can cause the sampling of reads across the transcript body to deviate from a uniform distribution. These biases typically cause short segments of the transcript to be sequenced at a lower frequency, resulting in a local drop in the level of coverage. The conventional (unconstrained) implementation of the change-point detection procedure identifies these local in-homogeneities in coverage as a segment with a distinct coverage distribution. However, in the context of annotating terminal exon boundaries we wish to disregard these local aberrations as they do not correspond to terminal exon boundaries. In order to minimize the effect of local biases on transcript model inference we introduce additional constraints to the change-point identification procedure.\n\nTo distinguish local changes from change points that mark a sustained decrease in the level of coverage, we restrict the set of identified change points to conform to a pattern of monotonically decreasing coverage over sequential segments. Solutions satisfying this requirement are achieved by discarding any configurations of change points in which the fold change in the level of coverage between two neighboring segments is less than a specified fold-ϕ.\n\nThis constraint is implemented by modifying the recursions in Equations 2 and 3. To do so, we introduce the functions M(t,s) to represent a point estimator of the level of coverage for observations yt:s, and C(s) to represent the maximum estimated coverage of the most likely segmentation of observations ys:n, respectively. We enforce this constraint by assigning zero probability to all configurations in which the estimated coverage of a downstream segment exceeds the estimated coverage of an upstream segment. Formally, this requires replacing the unconstrained recursions (Equations 2 and 3), with constrained versions (Equations 4 and 5).\n\n(4)\n\n(5)\n\nHere, a parameterization ϕ = 1 corresponds to a requirement that the level of coverage of sequential segments are strictly decreasing, while ϕ = 2 the level of coverage of sequential segments drops at least twofold at each change point. The consequences of including these constraints are illustrated for a toy example in D. In this scenario, a hypothetical 3′ UTR has relatively uniform coverage, except for a local region ( D, bracket), where read coverage is underrepresented. When the unconstrained implementation of change-point detection procedure is applied to identify polyadenylation sites within the last exon, it detects two locations where the coverage drops, one upstream of the underrepresented segment, and the other at the polyadenylation site of the hypothetical exon. While this accurately reflects the observed pattern of coverage, for the purpose of polyadenylation site annotation, we are only interested in the location of the second change point.\n\nApplication of the constrained segmentation procedure has the desired effect; a change point is reported at the position of the polyadenylation site, while the change point caused by the local drop in coverage is omitted. While this limits the ability to identify arbitrary combinations of change points, reads sampled from tandem terminal exon isoforms are expected to produce a “step-like” coverage pattern. Thus, this constraint is intended to promote sensible inference of change-point location in situations where read distributions deviate from a theoretically uniform sampling across the transcript body.\n\nImplementing change-point detection for 3′ UTR annotation\n\nIn order to implement the described change-point inference algorithm, one needs to specify the distributions f(yi|θ), π(θ), and g(t). While the depth of sequencing coverage is a discrete counting process and would typically be modeled using a Poisson distribution, it has been suggested that read counts from sequencing data are overdispersed, and are more appropriately modeled by a Negative Binomial distribution (Anders and Huber 2010). Therefore, we model f(yi|θ) ∼ NB(p,r), and use an uninformative conjugate prior π(p) ∼ β(1,1), which allows for analytical integration of Equation 1.\n\nWhile the procedure described above efficiently identifies optimal sets of change points, these do not by themselves provide meaningful transcript models. For this reason the change points need to be interpreted in the context of the exon that they occur. For example, a transition from high-to-low coverage (over increasing genomic coordinates) would suggest the presence of a polyadenylation site on the plus strand, and vice versa for a gene on the minus strand. To enable application of change-point detection in an ab initio setting, prior to segmentation, covered genomic segments and spliced reads are used to identify regions that will be searched for change points. The output, including inferred overlapping terminal exons models, is reported in a compact splice graph. This graph identifies exon boundaries and connections between exons supported by spliced reads. The stages of the IsoSCM annotation algorithm are illustrated in .\n\nMethod evaluation: simulated data\n\nTo assess the benefit of incorporating coverage-based segmentation for terminal exon annotation, we compared the performance of IsoSCM with two widely used ab initio reference based annotation tools: Cufflinks (Trapnell et al. 2010) and Scripture (Guttman et al. 2010). We prepared a test set using simulated data, where the transcript structures underlying the sequencing data are known a priori (illustrated in Supplemental Fig. 1A). This test set was comprised of 14,263 nonoverlapping genes, based on transcript models obtained from the mouse Ensembl 73 release. For each gene, we selected a single-transcript isoform, and generated a new isoform by randomly truncating the terminal exon at a random position that was at least 150 nt from both the 5′ and 3′ boundaries of the original exon.\n\nAs we expect the accuracy of assembled models to relate to sequencing depth, we measured the performance of each method over a range of coverage levels. For each pair of isoforms we simulated reads sampled uniformly across the body of the transcript, such that the aggregate density of reads over exonic segments was 2000 reads per kilo base (kb). This library was recursively subsampled such that evaluations spanned a range of read densities from 5 to 2000 reads/kb. For each simulated data set, we used IsoSCM, Cufflinks, and Scripture to assemble a set of predicted transcript models. For each assembly we assessed the correctness of 3′ UTR predictions by classifying assembled terminal exons as true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) with respect to the reference ground truth transcript set.\n\nSince it is difficult to predict nested terminal exon boundaries with nucleotide-level accuracy from RNA-seq data, and there is value in an annotation that is “close” to the true transcript model, we use a classification scheme that allows a degree of flexibility. In contrast to the relatively generous assessment scheme used by the RGASP project (Steijger et al. 2013), which required only the spliced 5′ boundary of the terminal exon to match the reference and disregards the predicted 3′ end, we require both 5′ and 3′ boundaries to be similar to reference models. We classified predictions that are within a small (100 nt) distance of a reference model to be correct by dividing the interval spanning the terminal exon into segments that are positive or negative for polyadenylation, such that assemblies can be judged for their consistency with these segments (Supplemental Fig. 1C). The genomic segments within 100 nt of a reference 3′ ends were counted as TPs if an assembled 3′ end fell within that segment, and were otherwise counted as FN. Likewise, segments >100 nt from a reference end were counted as FP if an assembled 3′ end fell within that segment, and TN otherwise. Using these counts we calculated the PPV = TP/TP + FP, TPR = TP/TP + FN, FPR = FP/FP + TN, NPV = TN/TN+ FN, for each assembly.\n\nThese metrics are plotted as a function of sequencing depth in A,B and Supplemental Figure 2. In these simulations, IsoSCM identifies the terminal exon boundaries with a PPV comparable to Cufflinks and Scripture at all sequencing depths, indicating that the change-point inference procedure does not inappropriately increase the number of false positives compared with methods that attempt to assemble only a single 3′ UTR isoform. In contrast, comparisons of the TPR achieved by each method highlight the fact that the models built by Cufflinks and Scripture were unable to annotate tandem terminal exons. Even as the number of available reads is increased toward infinity, the maximum TPR achieved by these methods was 0.5. A priori, we expect that Cufflinks and Scripture cannot exceed this level of sensitivity since the gene models they build are not expressive enough to represent tandem overlapping terminal exons, and one out of every two 3′ terminal exons in the test set is nested within a longer exon. In contrast, given sufficient data to statistically identify changes in the level of coverage, IsoSCM is able to achieve perfect TPR for the test set ( A).\n\nWe explored TPR, PPV, NPV, FPR measurements further, by subdividing the aggregate performance on the entire test set into component corresponding to proximal and distal isoforms exclusively (Supplemental Fig. 2). The methods performed comparably for the task of distal isoform identification, and the performance gain achieved by IsoSCM corresponds to an increased number of correct annotations of nested isoforms. To explore the relationship between sequencing depth and annotation accuracy we repeated the evaluation, requiring that predictions be within 10 nt of the reference transcript to be classified as TP. Under these conditions, we observed qualitatively the same pattern; only IsoSCM is able to reconstruct the nested isoforms correctly (Supplemental Fig. 3). However, while a sequencing depth of 200 reads/kb was sufficient to achieve a TPR = 0.9 and FPR = 0.1 with 100-nt resolution, this level of performance required over 1000 reads/kb at the 10-nt resolution. We note that all methods fail to reliably assemble low expressed transcripts, and that the advantages of IsoSCM are more fully realized when there are sufficient data to distinguish overlapping isoforms. Nevertheless, IsoSCM performs equally or better to Cufflinks and Scripture over a range of sequencing depths.\n\nMethod evaluation: real RNA-seq data\n\nOf course, we do not expect experimentally generated RNA-seq data to be as well-behaved as simulated data. To verify that the benefits observed in our simulation experiment are achieved when IsoSCM is applied to real RNA-seq data, we utilized published RNA-seq data comprised of nine mouse tissues analyzed in triplicates (Merkin et al. 2012). In contrast to the simulation experiment, the ground truth set of transcripts expressed in each sample is not known a priori. As a first measure of model correctness, we compared the terminal boundaries of constructed transcript models with those in the Ensembl 73 reference annotation. However, as existing 3′ UTR reference annotations are incomplete (Miura et al. 2013), we expect that sole comparisons to the Ensembl reference to inflate FPR estimates. Therefore, we sought additional orthogonal sources of evidence to support predicted polyadenylation sites. Directed 3′-sequencing (3′-seq) protocols permit experimental mapping of polyadenylation sites, and we used an atlas of 3′-seq data from multiple mouse tissues (Derti et al. 2012). As well, cleavage and polyadenylation sites have long been known to be associated with a polyadenylation signal (PAS) hexamer (Proudfoot and Brownlee 1976), most frequently either AATAAA or ATTAAA, located ∼21 upstream of the cleavage site. While such motifs are not sufficient to specify 3′ end formation, we could assay PAS enrichment in the vicinity of novel 3′ end annotations as another measure of their quality.\n\nWe first sought to evaluate change-point cutoffs that delivered appropriate accuracy for genuine 3′ termini. We tested this using mouse brain (SRR594393), and partitioned predicted ends into quintiles by the magnitude of the change point. We then evaluated the positional enrichment of PAS and 3′-seq data supporting these groups, to examine the genomic precision with which IsoSCM called 3′ termini. We observed robust positional enrichments of PAS and 3′-seq tags in the appropriate locations relative to IsoSCM annotations ( C,D), demonstrating that these sources of evidence could be used to evaluate de novo predictions. As expected, annotated 3′ termini associated with the sharpest drops in coverage identified genuine polyadenylation sites with greatest accuracy, while positional support for PAS and 3′-seq tags was distributed more broadly for weaker change points. We focused on models for which the coverage drops at least fourfold in order to balance sensitivity and specificity of the predictions.\n\nWe then compared the performance of the different transcript assembly methods on the mouse brain RNA-seq reads, from which 11,000 3′ terminal exon models were constructed by IsoSCM, 9722 by Cufflinks, and 6282 by Scripture. Upon examining the distribution of the distance to the closest Ensembl 3′ end for each method ( E) we observed that all three methods generate two populations of predictions distinguished by the precision with which they identify Ensembl 3′ ends. The inflection point at ∼20 nt identifies a population of predictions that capture annotated termini quite precisely, while a second inflection point at ∼100 nt identifies a set of predictions that are localized in a wider window around annotated 3′ ends ( E, “imprecise”). For many types of genome-wide analysis, i.e., when assessing general trends of transcript isoform expression, nucleotide-precise annotations of 3′ termini are not necessary. Nevertheless, as the narrow 20-nt window enables the merits of predicted models to be evaluated stringently, we assessed how frequently each method produced 3′ termini that were validated by polyadenylation site features at a distance of ±20 nt ( F).\n\nOf the total set of predictions, IsoSCM made 4785 annotations that were ±20 nt of Ensembl 3′ ends, compared with 2450 by Cufflinks and 1827 by Scripture. In addition, each method annotated thousands of termini not supported by reference models. Among these, IsoSCM identified 2718 novel termini supported by 3′-seq tags, PAS, or both features, within 20 nt, compared with 1914 identified by Cufflinks and 941 identified by Scripture ( F). These evaluations demonstrate the strong performance of IsoSCM on real RNA-seq data using a stringent cutoff. Finally, a substantial portion of the remaining termini annotated by each method (“no evidence”) could be considered validated if one utilized a broader window, e.g., 100 nt. Since the majority of these events can be defined as being “imprecise” captures of Ensembl ends, we have noted their numbers within the “no evidence” category of F, and using the relaxed 100-nt criteria in Supplemental Figure 4A. A full accounting of the termini annotated by the three algorithms using both 20- and 100-nt windows is given in Supplemental Table 1. Overall, we find that IsoSCM correctly annotates more 3′ UTRs while simultaneously reporting the fewest unvalidated annotations, regardless of the window size used for model evaluation.\n\nPositional enrichments of functional features in predicted 3′ termini\n\nTo gain further insight into the resolution of the predictions made by each method, we investigated positional enrichments of PAS signals, 3′-seq reads, and conservation profiles around predicted 3′ termini. Considering all predictions of each method in aggregate, we see PAS signals enriched ∼21-nt upstream, 3′-seq tags at position 0, and a conservation profile characteristic of polyadenylation sites for all three methods ( A–C). However, when we compare the relative frequency of evidence at these positions, we see that ends predicted by IsoSCM are supported 22.6%–23.1% more frequently by 3′-seq ( A) and 19.9%–20.4% more frequently by a PAS ( B) than either Cufflinks or Scripture. The 3′ ends annotated by IsoSCM also exhibited greater overall conservation, as assessed by PhastCons ( C).\n\nClose inspection of these analyses reveal differential biases of the methods. In particular, consideration of the tail of “imprecise” PAS and 3′-seq predictions showed that they are biased to be upstream of annotations provided by Scripture, while they are more likely to be downstream from Cufflinks and IsoSCM predictions ( A,B). This suggests that Scripture has some tendency to overextend transcript models, whereas IsoSCM and Cufflinks are slightly more likely to truncate 3′ UTRs. The overextension bias observed for Scripture is a known consequence of the scan statistic used by this method to define the boundaries of transcribed regions (Huber et al. 2006). We might expect a bias toward slight truncation using IsoSCM and Cufflinks if the regions directly upstream of the polyadenylation site are underrepresented in input reads, perhaps due to a cloning, sequencing, or mapping bias. Nevertheless, the robust peaks at positions −21 and 0, for PAS and 3′-seq evidence, respectively, indicate that IsoSCM accurately localizes polyadenylation sites in the majority of its predictions, and that its performance is substantially higher than Cufflinks or Scripture.\n\nWe next judged the qualities of the substantial populations of 3′ end annotations that were specific to each method. Of the 11,000 annotations of 3′ ends, IsoSCM identified 4115 termini that were >100 nt away from annotations made by either Cufflinks or Scripture, and these annotations exhibit enrichment for polyadenylation site features that is comparable to the aggregate set of predictions for the three methods ( D–F). In contrast, analysis of 3′ end annotations specific to Cufflinks (n = 3717) or Scripture (n = 2962) outputs show little or no positional enrichment of 3′-seq tags ( D) or PAS ( E) at the appropriate locations. Therefore, IsoSCM identifies thousands of sites that in aggregate exhibit the expected features of 3′ ends, and are not reported by either Cufflinks or Scripture. Reciprocally, the ends that are uniquely provided by the other methods are not supported by similar evidence.\n\nFinally, we were interested to assess the quality of substantially novel, method-specific termini. As mentioned, all methods report a population of ends that localize near Ensembl termini, but do not identify cleavage sites precisely ( C). We found that positional assessments of bulk novel ends was compromised by inclusion of these “Ensembl-imprecise” termini, which create offset peaks of evidence at the boundary of the window utilized (Supplemental Fig. 4B–D). To provide clarity to these comparisons, we differentiated the population of “substantially novel” ends from imprecise annotations, by investigating predictions located >250 nt from Ensembl annotations. At this distance, IsoSCM identified 2472 termini, compared with 3513 by Cufflinks and 2367 by Scripture (Supplemental Fig. 4D). To highlight the differences between methods, we focused on “substantially novel” annotations that were specific to each method. This yielded sets of IsoSCM-specific (n = 1340), Cufflinks-specific (n = 2485), and Scripture-specific (n = 1969) ends that were >100 nt from each other. Analysis of these novel 3′ termini showed that only the IsoSCM-specific ends were enriched for 3′-seq tags ( G) and PAS ( H), whereas the other sets of method-specific ends were not distinguishable from background. As well, the IsoSCM-specific novel ends exhibited the highest level of genomic conservation ( I).\n\nRobust performance of IsoSCM across data sets\n\nTo assess if the performance differences we observed are representative, we used the framework for evaluating transcript assemblies from the simulation experiment to compare the performance of each method for 26 other mouse tissue RNA-seq data sets (Merkin et al. 2012). To provide a compact visualization of the evaluation, we used evidence of Ensembl terminal exons, 3′-seq, and PAS within ±20 nt to define sets of true and false predicted 3′ ends and plotted the differences in TPR and PPV obtained using IsoSCM and Cufflinks or Scripture in A.\n\nWhile there is sample-to-sample variability in these estimated performance metrics, IsoSCM consistently achieved a TPR that is at least 12.2% higher than the other methods, without compromising the PPV. Additional metrics of predictive performance for each method, including evaluations at both the 20-nt and 100-nt resolution, are provided in Supplemental Table 2. Concrete examples illustrating how IsoSCM reduces the number of incorrectly truncated 3′ UTRs and identifies additional 3′ UTR isoforms that are missed by Cufflinks and Scripture are given in B.\n\nApplication of IsoSCM to identify tissue-differential tandem APA events\n\nTo illustrate a practical application, we next applied change-point inference to examine differential usage of 3′ UTR isoforms between different tissues. In the previous section, we demonstrate that the IsoSCM segmentation strategy is effective for annotating terminal transcript boundaries within an individual sample; however, the quantification of differential isoform usage requires an accounting of all transcripts expressed among the samples being compared. When generating a single annotation that is representative of two samples, one could attempt to merge annotations assembled independently from each sample. However, it is not obvious what the optimal strategy is for combining annotations from separate samples, while preserving alternative events. For example, the cuffmerge program, available as part of the Cufflinks suite, merges transcript models that share overlapping and compatible chains of introns, and during this process discards shorter terminal exon annotations, reporting only the longest 3′ exon. While such an approach could be used to identify the longest 3′ UTR isoform, it discards potential alternative events, and is thus inappropriate for assessing tissue-differential tandem APA events.\n\nConveniently, the change-point detection framework described above can be extended naturally to the assembly of tandem 3′ UTR boundaries from multiple samples simultaneously. To do this, we define Pjoint, the joint likelihood of k independent samples,\n\n(6)\n\nwhere Pi is the marginal likelihood of the ith sample. Thus, by replacing P in Equations 2 and 3 with Pjoint, the segmentation procedure will identify the configuration of change points that maximize the joint marginal likelihood of all the samples simultaneously. Importantly, this modification enables identification of polyadenylation sites that are specific to one condition, in addition to sites that are common among the samples being compared.\n\nPreviously, we and others observed that the nervous system accumulates many transcripts with longer 3′ UTR isoforms than in other tissues, whereas the testis expresses many transcripts with relatively shorter 3′ UTR isoforms (Zhang et al. 2005; Jan et al. 2011; Derti et al. 2012; Smibert et al. 2012; Ulitsky et al. 2012; Miura et al. 2013). Using the IsoSCM framework, we reexamined these observations by analyzing differential polyadenylation site usage in nine mouse tissues. By performing the joint segmentation for each pair of tissues, we identified a set of change points representing tandem polyadenylation events. For each of these events, we estimated a polyadenylation-site-usage index in each condition, representing the relative frequency with which a particular polyadenylation site is used. By calculating the difference in this index between a pair of conditions, we identified polyadenylation events with differential usage patterns among tissues. St8sia3 and Sap30l typify transcripts IsoSCM identifies as being differentially polyadenylated between a pair of tissues, and are illustrated in A. By identifying global differences in the distribution of the polyadenylation-site-usage statistic at proximal sites between tissue pairs, we assessed whether there were systematic patterns of altered 3′ UTR length. Indeed, we observed clear signatures in which the termini annotated by IsoSCM were broadly extended in brain relative to all other tissues, whereas they were generally shorter in testis relative to all other tissues ( B).\n\nTo emphasize the importance of using accurate terminal exon annotations when quantifying tandem terminal exon expression patterns, we repeated the analysis using the transcript assemblies of Cufflinks and Scripture in place of the models generated by IsoSCM. As these methods do not provide a means to assemble transcript models considering two samples simultaneously, we used the union of terminal exon models from tissues being compared to define the set of tandem polyadenylation events identified by these methods. As shown in B, there is only modest agreement between patterns identified using models built by Cufflinks and Scripture and IsoSCM. Enhanced usage of proximal polyadenylation sites in the testis was reliably recovered using Cufflinks. This is likely because the abrupt truncation events observed in testis can be captured by the Cufflinks assembly procedure, as is the case for St8sia3 ( A). However, neither Cufflinks nor Scripture were able to assemble models that consistently captured the pattern of increased abundance of extended 3′ UTRs when comparing brain with other tissues ( B).\n\nCufflinks and Scripture seek only to annotate the longest terminal isoform that is consistent with the reads, and in brain we observe many cases where both isoforms are expressed and only their relative usage changes between tissues. In such cases, it is expected that the short 3′ UTR isoform will not be captured by these methods. This is illustrated by the gene Sap30l in A, for which both a short and long isoform are expressed in brain and liver, but there is a higher proportion of isoforms bearing the extended 3′ UTR in the brain. In this case, using Cufflinks or Scripture this alternative event is not identified, since neither method annotates the short isoform correctly.\n\nWe previously provided extensive molecular validation of neural 3′ UTR lengthening events of a similar quality to those identified by the IsoSCM pipeline, although those APA events were previously cataloged by a combination of visual annotation and partially automated procedures (Smibert et al. 2012; Miura et al. 2013). Along these lines, we tested a 3′ UTR extension for Shank2 identified by IsoSCM ( C) by Northern blot. We designed double stranded DNA probes that either hybridize to the region common to both transcripts (“uni”), or that exclusively recognizes the extended 3′ UTR isoform (“ext”). Based on the predicted size of the full-length transcript differing only in the 3′ boundary of the terminal exon, we expect full-length transcripts of length 8.2 and 9.7 kb. Northern blotting showed that the common probe hybridize to two dominant bands that are consistent with these lengths, while extension-specific probe hybridizes exclusively to the longer RNA species ( D), confirming our inference of tandem terminal exon boundaries from stepped patterns of RNA-seq coverage. Overall, these analyses are consistent with previously described patterns of tissue-specific APA, and suggest that the methodology encapsulated by IsoSCM can be readily applied in other settings to gain new insights into alternative 3′ UTR isoform regulation.\n\nCONCLUSIONS\n\nThe inference of transcript structures from short RNA-seq reads is a complex problem, particularly for the identification of 3′ UTR boundaries. As we have illustrated, confounding factors such as the presence of repetitive sequences, overlapping coexpressed isoforms, and nonuniform coverage patterns make the identification of 3′ UTR boundaries from RNA-seq data a nontrivial problem. These issues are exacerbated by the absence of a framework to incorporate observed patterns of read depth into the transcript assembly process. To address these challenges and the limitations of existing tools, we developed IsoSCM. By benchmarking IsoSCM against state of the art methods for transcript assembly on simulated and experimentally generated RNA-seq data sets, we have demonstrated by several measures that the performance of IsoSCM is superior to existing tools for 3′ UTR reconstruction. Although evaluations indicate substantial benefits of change-point inference, we reiterate that the advantages of IsoSCM are manifest where sufficient levels of isoform expression exist, and that it does not correctly identify 3′ UTR isoforms if the level of coverage over exonic segments is not proportional to isoform abundance. These are indeed general challenges for ab initio transcript assemblers. Nevertheless, we show that IsoSCM consistently identifies thousands of functionally supported 3′ termini in excess of Cufflinks and Scripture, and reduces the number of false predictions reported.\n\nThe improvement in sensitivity and accuracy of reconstructed transcript models gained by using IsoSCM has implications beyond transcriptome annotation. A major application of RNA-seq technologies is for the inference of alternative isoform regulation, and these inferences require accurate gene models. By analyzing a panel of RNA-seq samples from different tissues, we demonstrate how previously observed patterns of APA are faithfully recapitulated by IsoSCM. Moreover, by extending the constrained change-point detection procedure we developed for single-sample annotation to the joint analysis of two samples, we obtain an effective method to detect and annotate differential APA in an ab initio setting. Notably, these patterns are not recovered using existing tools for transcript reconstruction, because these methods are by design not expressive enough to annotate tandem 3′ UTR isoforms.\n\nWhile this work was in revision, Wagner and colleagues reported their algorithm DaPars and used it to identify genes with altered polyadenylation patterns following CFIm25 knockdown and in glioblastoma (Masamha et al. 2014). While their work also exploits change points in RNA-seq data, it provides only a subset of the functionalities of IsoSCM, making direct comparisons of the methods difficult. A significant advantage of IsoSCM is that it operates in an ab initio setting, and its accuracy does not depend on the quality and completeness of a reference annotation. Even for the well-annotated mouse transcriptome, dominant isoforms are missing (i.e., the extended isoform of Sap30l) ( A), and could only be analyzed using ab initio methods such as IsoSCM. For many species, especially nonmodel organisms, 3′ UTR models are incomplete or absent, precluding the application of DaPars to these transcriptomes. The generality of IsoSCM will enable change-point analysis to be applied to APA in a wider scope of problems.\n\nWhile IsoSCM utilizes only RNA-seq to identify 3′ ends, there also exist specialized protocols for high-throughput mapping of 3′ UTR boundaries by direct cloning and sequencing of 3′ ends. Clearly such methods provide greater and more direct information on 3′ ends. However, as these strategies are technically more complicated than conventional RNA-seq protocols, the available 3′-seq data are only a small fraction of the aggregate RNA-seq data that are available for diverse organisms. We present IsoSCM as a methodological advance for ab initio 3′ end identification that can take advantage of existing RNA-seq data and extend its analysis beyond current algorithms. The refinement of 3′ UTR boundaries provided by IsoSCM provides greater accuracy and more systematic accounting of 3′ end processing, and enables diverse studies of differential APA using the wealth of RNA-seq data now available."
    }
}