{
    "id": "dbpedia_1694_3",
    "rank": 66,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734307/",
        "read_more_link": "",
        "language": "en",
        "title": "Classification of evoked responses to inverted faces reveals both spatial and temporal cortical response abnormalities in Autism spectrum disorder",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-nic.gif",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734307/bin/gr1.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734307/bin/gr2.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734307/bin/gr3.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734307/bin/gr4.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734307/bin/gr5.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Adonay S. Nunes",
            "Fahimeh Mamashli",
            "Nataliia Kozhemiako",
            "Sheraz Khan",
            "Nicole M. McGuiggan",
            "Ainsley Losh",
            "Robert M. Joseph",
            "Jyrki Ahveninen",
            "Sam M. Doesburg",
            "Matti S. Hämäläinen"
        ],
        "publish_date": "2021-08-27T00:00:00",
        "summary": "",
        "meta_description": "The neurophysiology of face processing has been studied extensively in the context of social impairments associated with autism spectrum disorder (ASD), but the existing studies have concentrated mainly on univariate analyses of responses to upright faces, ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734307/",
        "text": "1. Introduction\n\nAutism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by, among other traits, impaired social communication and interaction (American Psychiatric Association, 2013). Face perception plays a critical role in social interactions, and involves a large network of brain areas (Haxby et al., 2000, Li et al., 2009, Magnuson et al., 2019, Turk-Browne et al., 2010) that includes the highly specialized fusiform face area (FFA) (Humphreys et al., 2008, Kanwisher et al., 1997). Face processing is also associated with specific neurophysiological time signatures (Barbeau et al., 2008, Eimer, 2000, Itier et al., 2006, Linkenkaer-Hansen et al., 1998, Puce et al., 2013). In investigations of face processing in ASD, many studies have documented behavioral impairments in processing faces in ASD (Gauthier et al., 2009, Jiang et al., 2013, Tang et al., 2015), alongside neurophysiological abnormalities (Khan et al., 2013, Mamashli et al., 2018, Naumann et al., 2018, O’Connor et al., 2007).\n\nOne line of research on abnormalities associated with face processing in ASD revolves around comparing the processing of upright faces in ASD to the processing of inverted faces. For upright faces, the non-verbal information extracted from the combination of mutable face elements requires a holistic perception that decodes face expression by taking into account several elements in conjunction (McKone et al., 2007, Piepers and Robbins, 2012). In contrast, inverted faces are believed to disrupt this holistic processing, and result in greater impairment in face recognition than the impairments in recognition produced by inverting other, non-face, images (Bruyer, 2011, Yin, 1969). The resulting effect, commonly referred to as the Face Inversion effect (FIE), has been investigated in ASD, again with mixed results. The FIE is typically assessed by measuring the reaction time to identify upright faces, versus the reaction time to identify inverted faces. While some earlier studies found a reduced FIE in ASD (Gauthier et al., 2009, Teunisse and De Gelder, 2003), other studies found no such indications (Tang et al., 2015, Tavares et al., 2016, Weigelt et al., 2012). These inconsistencies could be due to differences in study design such as stimulus parameters, specific methodological details, age groups, or cohort characteristics more generally, and thus the question of neurophysiological differences associated with cortical responses to upright faces relative to the cortical responses to inverted faces in ASD remains unresolved.\n\nHere, we chose to combine the inverted versus upright processing line of research with a machine learning multivarate approach. Previous studies used machine learning decoding in visual perception (King et al., 2016), object recognition (Cichy et al., 2016), face processing (Van de Nieuwenhuijzen et al., 2013) and timing of face perception (Dobs et al., 2019), and to detect participants with mild cognitive impairment (Hughes et al., 2019), neurological or brain injuries (Aoe et al., 2019, Claassen et al., 2019), and schizophrenia (Shim et al., 2016), to mention a few. In this study we use machine learning-based brain signal decoding to investigate the spatial and temporal characterisitics of the evoked response to neutral upright faces and inverted faces, in ASD versus typically developing (TD) participants, using whole head magnetoencephalography (MEG). More specifically, we tested whether evoked responses to upright faces and evoked responses to house could be classified with better than chance probability in both ASD and TD groups, and whether evoked responses to inverted faces and evoked responses to house could be classified with better than chance probability in both ASD and TD. We tested this using both temporal and spatial dimensions of the evoked response. While this approach does not address the FIE directly, due to the lack of behavioral reaction time data demonstrating this effect in our cohort, it nonetheless addresses cortical processing of upright versus inverted neutral faces in a novel way. We were interested in this question because previously, when studying the processing of neutral upright faces, we found no group differences in cortical evoked responses between individuals with ASD and IQ and age matched TD individuals (Khan et al., 2013, Mamashli et al., 2018). However, we had used a univariate approach to studying the evoked responses. We were further interested in studying the responses to inverted faces in parallel, in order to follow the line of research on dissociating holistic and non holistic processing of faces in ASD, given their different contribution to communication.\n\nThe multivariate data-driven approach pursued here is more sensitive to multidimensional parameters captured by the MEG data, and so presents a novel approach with which to revisit this question. While classical statistical modelling approaches rely on theoretical models with assumptions and probabilities to infer univariate relations between conditions, machine learning decoding is a multi-variate data-driven approach that makes predictions based on combinations of patterns in the data. We had previously found neurophysiological group differences in ASD in the cortical processing of faces (Khan et al., 2013, Mamashli et al., 2018), but none of these differences were at the level of evoked resonses. Therefore, we hypothesized that our prior, univariate, approaches might not have been sufficiently sensitive to group differences, and that a multivariate approach will detect group differences between the ASD and TD group when processing upright faces that were not previously detectable. In addition, given that inverted faces hinder holistic processing in comparison to upright faces, and generally elicit a stronger response, we expected to find significantly greater group differences when classifying evoked responses to inverted faces relative to evoked responses to houses. Lastly, we expected that classification by spatial characteristics would yield significant group differences, but that this would not be the case for classification by temporal charateristics because the temporal parameters are simpler to capture also with previously studied univariate approaches. We tested these hypotheses using data from 21 individuals with ASD, ages 8–16, and 29 age and IQ matched controls ( ). For the temporal domain, we used data from the MEG sensors, since temporal characteristics do not change from sensor space to source space. For the spatial classification, we used source space data, i.e. MEG signals projected from the MEG sensors onto the cortical surface.\n\nTable 1\n\nASDTDSample size (females)21 (2)29 (4)Age, years12.3 ± 2.411.7 ± 3.3NVIQ109.0 ± 19.106.9 ± 10.0VIQ108.2 ± 15.9111.3 ± 14.0ADOSSA9.7 ± 4.7\n\n2. Methods\n\n2.1. Participants\n\nFifty right-handed participants from the age of 7 to 19 years underwent an MEG recording and a structural T1 MRI scan. 21 participants had a diagnosis of ASD and the ASD group had a mean age of 12.1 ± 2.5, and 29 TD comparison participants had a mean age of 11.9 ± 3.5. Verbal IQ (VIQ) and nonverbal IQ (NVIQ) were assessed using the Kaufman Brief Intelligence Test – II (Kaufman, 2004) or the Differential Ability Scales – II (Elliot, 2007). There were no signficant group differences in age, NVIQ, or VIQ. The Autism Diagnostic Observation Schedule, Second Edition (ADOS-2) (Lord et al., 2012) was administered by a trained researcher. Of the 21 participants diagnosed with ASD, 14 participants were administered Module 3 and 7 participants were administered Module 4 of the ADOS assessment. For those that were administered Module 4, a revised algorithm to increase comparability across modules was used (Hus and Lord, 2014). The ADOS raw overall total and raw domain totals were calculated. For the correlations with ADOS, we used the Social Affect domain total of the ADOS algorithm (ADOSSA), which consists of communication and reciprocal social interaction scores, and is comparable across modules 3 and 4. Exlusion criteria included major comorbidities such as epilepsy, major psychiatric episodes, Fragile-X syndrome or substance use over the 6 months prior to enrollment. This study was approved by MGH institutional review board and informed written consent was obtained for every participant and their parents or guardians.\n\n2.2. Experimental paradigm\n\nDuring the MEG recording, houses, upright neutral faces, inverted neutral faces, and emotional faces (the latter condition is not discussed here), were presented on the screen for 1 s in random order, followed by an intertrial period of 1 s with a fixation cross. To assess attention, participants were asked to press a button when the same face appeared successively (1-back); this occurred on 15% of the trials and repeat presentations were excluded from the analyses, and from the count of trials per condition. The experiment was broken down into three recordings with short breaks for rests. In total, each stimulus condition was presented for at least 150 trials, in random order (exclusive of 1-back trials). The face stimuli were collected from three databases: Karolinska Directed Emotional Faces (KDEF) (Lundqvist et al., 1998), NimStim Face Stimulus Set (Tottenham et al., 2009), and Gur (Gur et al., 2002). The houses stimuli were obtained from the Kanwisher Laboratory database at the Massachusetts Institute of Technology. All stimuli were homogenized for brightness and contrast, and by using an oval black mask. The sequence of stimuli was generated and presented using the psychophysics toolbox (Brainard, 1997, Pelli, 1997), and presented with a projector through an opening in the wall onto a back‐projection screen placed 100 cm in front of the participant inside a magnetically shielded room. A illustrates the timeline and stimuli used in this paradigm.\n\n2.3. MEG and aMRI data acquisition\n\nThe MEG data were acquired at the Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, with a 306-channel Neuromag Vectorview whole-head system (Elekta Neuromag, Finland) inside a magnetically shielded room. The HPI locations and the participant’s head shape were digitized using a Fastrak digitizer (Polhemus Inc., Colchester, VT) integrated with the VectorView system, and later used for MEG and MRI corregistration. The vertical and horizontal electrooculogram (EOG) and electrocardiogram (ECG) signals were also acquired. The data were bandpass filtered between 0.5 and 200 Hz prior to sampling at 600 Hz. Additionally, five min of empty room data were collected immediately before or immediately after each experimental session, for noise estimation purposes. Structural T1-weighted MPRAGE images were acquired on a 3T scanner (Siemens Medical Systems, Erlangen, Germany) using a 32-channel phase array head coil. Segmentation of the cortical surface was estimated using FreeSurfer (Dale et al., 1999, Fischl et al., 1999), subjects cortical surfaces were morphed into a common space with ~ 10.000 vertices per hemisphere.\n\n2.4. MEG preprocessing\n\nA signal space separation spatial filter was applied to the data to correct for head motion and suppress external source noise (Taulu et al., 2004, Taulu and Simola, 2006), using the default MNE-python v.19 SSS parameters. To remove eye and cardiac artifacts, signal space projection was employed (Gramfort et al., 2014). Then, the data were bandpass filtered between 0.1 and 40 Hz and a 60 Hz notch filter was applied to suppress line-frequency noise. The MEG recordings were divided into epochs of 1 s, from −500 ms before the stimuli presentation and 500 ms after the onset. For the analyses, gradiometers sensors were selected and epochs with peak-to-peak amplitude above 1000 fT/cm in any of the gradiometers were excluded from further analysis. There were no group differences in head motion, or in the number of “bad trials” dropped due to excessive artefacts, as illustrated in supplementary Fig. S1. A minimum of 47 trials per participants per condition were used. The number of trials per participant per condition ranged from 47 to 156, with no significant differences in the total number of trials per subject between groups (t-test: p = 0.18). In Suppl. Fig. S2, a swarm plot illustrates the number of trials per conditions by group, and in Suppl. Fig. S3, a scatterplot shows the relationship between mean decoding accuracy and number of trials, demonstrating that these two values are not correlated.\n\n2.5. MEG source reconstruction\n\nSource reconstruction was estimated on the cortical surface for each participant using Freesurfer cortical segmentation. A watershed algorithm was used to generate the inner skull surface triangulations. The MEG forward solution was calculated using a single compartment boundary-element model (Hämäläinen and Sarvas, 1989). Minimum-norm estimate (MNE) software was used to estimate the cortical current distribution and the orientation of the sources were fixed perpendicular to the cortical mesh. Empty-room recordings were used as a noise–covariance matrix to calculate the inverse operator. To reduce the bias toward superficial currents, a depth weighting was used to adjust the source covariance matrix to favor deep source locations (Lin et al., 2006).\n\n2.6. Temporal classification\n\nTo compute classification accuracies using the temporal patterns of the evoked responses to the different stimuli (“temporal classification”, irrespective of the spatial distribution, a linear kernel support vector classifier (SVC, Cortes and Vapnik, 1995), implemented in the sci-kit learn Python library (Pedregosa et al., 2011), was used for each participant to estimate the stimuli type at each time point of the trial using the 204 sensor gradiometer signals. An SVC finds a hyperplane that separates the condition classes as best as possible. SVCs learn a linear binary decision rule, h(x)=sign{wTx+b}, where the weight vector w and threshold b together define a hyperplane L:wTx+b=0. The function h(x) thus indicates the location of a given point x with respect to L and divides the data into two classes. The classification accuracy metric used was the Area Under the Curve (AUC), as it is a metric that balances specificity and sensitivity. A 5-fold cross-validation (CV) was used to test the generalizability, and the accuracies were averaged across CVs. The stimuli of interest for classification were (1) upright neutral faces versus houses, and (2) inverted neutral faces versus houses. A statistical learning model was used to test if the subject’s temporal accuracies are sufficient for classifying ASD and TD participants using SVC.\n\n2.7. Spatial classification\n\nTo compute classification accuracies using the spatial patterns of the evoked responses to the different stimuli (“spatial classification”), irrespective of the temporal parameters, we first projected sensor data onto the cortical surface. At each vertex, the time series dimensionality were reduced using Principal Component Analysis (PCA, probabilistic implementation, Tipping and Bishop, 1999) and extracting the first 50 PCA components in order to reduce the temporal dimensionality of the time series. These components were used as features for SVC classification. Again, as for the temporal domain analysis, the stimuli of interest for classification were (1) upright neutral faces versus houses, and (2) inverted neutral faces versus houses. The spatial accuracies for all vertices were used to classify ASD and TD groups. B illustrates the workflow for the temporal and spatial classification analyses.\n\n2.8. Statistical analysis\n\nTo test for group differences and for correlations with the ADOS Social Affect domain totals (ADOSSA), Partial Least Squares (PLS) multivariate statistical analysis was used (Krishnan et al., 2011, McIntosh and Lobaugh, 2004). Mean-centred PLS was used for assessing group differences in accuracy and behavioral PLS for testing associations between accuracy and ADOSSA scores. The inputs for mean-centred PLS were two data matrices with dimensions subjects × features (where features are timepoints in case of temporal classification and vertices in case of spatial classification) for ASD and TD groups containing SVC accuracies. The input for behavioral PLS was a data matrix with SVC accuracies in ASD group and a matrix containing ADOSSA scores for each participant with ASD. PLS decomposes the data matrix M with m features and n groups through singular value decomposition (SVD), giving M = UΣVT, where U is the eigenvectors of the row space, V the the eigenvectors of the column space, and the singular values Σ as a diagonal matrix. U reprents the feature subspace, V represents the group subspace and Σ captures their magnitude or variance of the eigenvectors. A permutation test is applied to assess if Σ from the original subspace is significantly higher than the null distribution where group labels are randomized. The permutation test results in a single p-value indicating statistical significance, which intrinsically addresses the multiple comparision concern, by having only one test. Then, boostraping is applied by removing members of the group one by one to estimate the standard error (SE) of each feature and U is divided by the SE to provide a measure of feature reliability generating a z-score bootstrap ratio for each feature. In this study, 5000 permutation and bootstrapping iterations were performed and the threshold for z-scores was set to 3, which represents a reliability index above the 99th percentile of a normal distribution.\n\n4. Discussion\n\nWe used a multivariate machine-learning decoding approach to identify altered cortical response patterns to inverted and upright neutral faces in ASD. We were interested in a dual set of questions. The first question was whether responses to upright faces and responses to inverted faces would be equally accurately classifiable relative to responses to houses, for both the ASD and TD groups. We found that while it was possible to accurately classify evoked responses to upright faces relative to houses for both groups, differences between the TD and ASD groups emerged only for classification accuracies in response to inverted faces relative to houses. The results for upright faces align with prior studies from our group and others showing no group differences in evoked responses to upright faces in ASD (Apicella et al., 2013, Khan et al., 2013, Mamashli et al., 2018), and confirms that a multivariate approach to this question yields results that are in line with previously used univariate approaches, as expected. The results for inverted neutral faces, in contrast, were novel, and did show a group difference that did not manifest for upright neutral faces. The second question was whether any differences that do emerge between the groups and conditions, would manifest equally in both the temporal and spatial dimensions of the responses. In response to this question, we found significant group differences in both the temporal and spatial domains of the evoked responses to inverted neutral faces in ASD. Importantly, the accuracy associated with each participant in classifying cortical responses to inverted faces vs houses correlated significantly with ASD severity in the the spatial and temporal domains.\n\nThe results in the temporal domain, while not in line with our original hypothesis, are consistent with observations that responses to faces are known to peak between 100 ms and 200 ms. Classification accuracies for inverted faces versus houses differed significantly between the groups around the two known components of the response to faces – the M120 and the M170. The M120, which has been measures using both EEG and MEG, and occurs between 100 and 130 ms typically, in response to upright or inverted faces (also referred to as P1 / P120 / P100 when measured using EEG) is believed to correlate with face categorization or selectivity, but not face recognition (Eimer and Holmes, 2002, Linkenkaer-Hansen et al., 1998, Liu et al., 2002). The response component at 170 ms is of course the the best known component of the evoked response to faces, and has been documented using both EEG and MEG (Eimer, 2000, Itier et al., 2006, Liu et al., 2013). It is particularly interesting to note that in spite of the fact that decoding accurracies remained high throughout the trial, even at 500 ms after stimulus onset, the group differences were only significant at time windows that overlapped with known components of the evoked response to faces. This is likely because it is as those time windows that the response is most face specific, and therefore is more likely to be impacted in ASD. Furthermore, fact that our methodology detected differences in the temporal domain that overlap with known peaks of the response to faces, substantially increases confidence in the validity of the results. The fact that these differences were not observed previously, speaks to the strength of this multivariate data-driven approach. Importantly, lower classification accuracy was correlated with increased ASD severity as measured using the ADOS, confirming the relevance of the results to the ASD phenotype.\n\nIn our spatially-based analyses, the classification accuracy was significantly lower in the ASD vs. TD participants in the SMG, IPS and pSTS areas. It was unexpected that all the differences in evoked responses to inverted faces emerged from non-specialized face processing areas. Previous studies suggest that the face-processing “core” system involves the FFA, occipital face area (OFA) and posterior superior temporal sulcus (pSTS) (Haxby and Gobbini, 2011, Nunes et al., 2019). We did not find any group differences in either the FFA or the OFA. It is possible that with univariate approaches, the lack of group differences in these more dominant face processing areas overshadows differences in less prominent face processing areas. The multivariate approach taken here, in contrast, picked up non-specialized areas associated with the face processing network. The pSTS is a higher order associative area with top-down regulation (Turk-Browne et al., 2010), while the IPS is part of the dorsal attention system that is involved in reorienting attention to unexpected stimuli, and is also involved in Theory of Mind tasks (Krall et al., 2015). The SMG has been shown to also be critical for holistic processing (Huberle and Karnath, 2012, Rennig et al., 2013). Thus, while none of these areas are specialized for faces, they are all part of the face processing cortical network. Importantly, again affirming the relevance of the results to ASD, group differences in classification accuracies of classifying inverted faces relative to houses in all of these areas were correlated with ASD severity. More specifically, lower classification accuracy was correlated with increased ASD severity, and has more generally previously been associated with discriminative deficits in processing inverted faces (Jiang et al., 2013, Zürcher et al., 2013).\n\nOverall, these findings are consistent with mounting evidence that the ASD brain is more idiosyncratic both at rest and during processing of stimuli (Hahamy et al., 2015, Magnuson et al., 2020, Nunes et al., 2018). Such variability in brain function might explain reduced ability of the classifier to distinguish brain activity patterns elicited by different stimuli. Alternatively, our results are also consistent with the hypothesis that face processing difficulties arise due to reduced interest in facial stimuli starting early in life, which in turn would result in an underdeveloped face-processing network (Pierce et al., 2011, Rice et al., 2012). This could result in less differentiation in responses to upright versus inverted faces, and classification accuracies for inverted faces that are more similar to those found for upright faces in the ASD group. One limitation of the study stems from the relatively small sample size, as well as from the smaller number of trials in a few of the participants; while we did not observe a correlation between accuracy and number of trials, the relatively low variability in number of trials per participant means this result is not conclusive. Another potential limitation is the relatively large age range, although that is likely mitigated at least somewhat by the groups being matched on age. Furthermore, the maturation of the M170 attenuates substantially (i.e. is close to mature) by around age 8 or 9, and there is evidence this is the case also for earlier components of the response (Haist and Anzures, 2017, Kuefner et al., 2010), meaning the age range is not likely to be a significant concern for this study. In the spatial domain, there is indeed evidence of refinement of the spatial distribution of the response with age (Zhu et al., 2016). So, while this remains a limitation and, the fact that the groups were age matched, along with the correlations with ASD severity and the fact that the identified areas are indeed part of the face processing network, all increase the confidence in the findings. One caveat of data-driven decoding approaches concerns the relevance of the features used for classification, which are derived from the data blindly, and therefore the neurophysiological interpretation of these features is not necessarily obvious or intuitive. That said, the correlations with the behaviorally derived ASD measures reinforce our hypotheses that these features are in fact relevant to the ASD phenotype.\n\nMore generally, the differences observed here between the processing of upright faces in ASD, which appears intact relative to the TD group, and the processing of inverted faces in ASD, which is abnormal relative to the TD group, merits further discussion. It is possible that the abnormalities observed in the context of inverted face but not upright faces stem for the greater reliance of processing of inverted faces on top-down regulation (Papathomas and Bono, 2004, Gazzaley and Nobre, 2012, Mayer et al., 2007). Reduced top-down modulations is consistent with multiple reports of abnormalities in top-down processing in ASD (Cook et al., 2012, Frith, 2004, Gomot and Wicker, 2012, Khan et al., 2015, Mamashli et al., 2017, Neumann et al., 2006, Seymour et al., 2019, Sinha et al., 2014), including during face processing (Leung et al., 2014, Loth et al., 2010). Thus, while this study does not examine directly what specific changes yield the differences in the processing of inverted, but not upright, faces in the ASD group, abnormal top-down modulations provide one plausible explanation for this difference.\n\nIn sum, we found that evoked responses to upright neutral faces and evoked responses to houses were equally accurately classified in both the ASD and TD groups, using both the spatial and temporal domains of the evoked responses. In contrast, evoked responses to inverted neutral faces and evoked responses to houses were classified with significantly reduced accuracy in the ASD group, using both the spatial and temporal domains of the event related responses. The time window when accuracy of classification was most different between the two groups was consistent with the temporal pattern of responses to faces, around 120 ms and 170 ms post stimulus onset. So, while we did not initially hypothesize that we will find a significant difference here, the difference that did emerge is highly consistent with studies of face processing. Interestingly, the spatial pattern that was most predictive of group differences did not include specialized face processing areas, and instead spanned activated components of visual object processing that are not specialized for faces (Haxby et al., 2002). For both the spatial and temporal domains, individual classification accuracies were negatively correlated with ASD severity, specifically in the social-affective domain, as measured using the ADOSSA. These negative correlations support the literature suggesting that the brain in ASD is more idiosyncratic (Hahamy et al., 2015, Magnuson et al., 2020, Nunes et al., 2018), and thus this approach offers a new direction through which to address this question in future studies. The multivariate data-driven approach taken here revealed patterns of abnormalities in the evoked responses to inverted faces in ASD in the spatial domain that were hitherto undocumented, underscoring the importance of using such approaches in ASD. The multivariate approach applied here is likely to be particularly useful for understanding the neural bases of ASD, given the idiosyncratic nature of the ASD brain, resulting in greater spatial and temporal variability and reduced predictability of the pattern of abnormalities associated with the disorder."
    }
}