{
    "id": "dbpedia_2453_1",
    "rank": 94,
    "data": {
        "url": "https://cstheory.stackexchange.com/questions/1168/what-papers-should-everyone-read",
        "read_more_link": "",
        "language": "en",
        "title": "What papers should everyone read?",
        "top_image": "https://cdn.sstatic.net/Sites/cstheory/Img/apple-touch-icon@2.png?v=da033b2b5220",
        "meta_img": "https://cdn.sstatic.net/Sites/cstheory/Img/apple-touch-icon@2.png?v=da033b2b5220",
        "images": [
            "https://cdn.sstatic.net/Sites/cstheory/Img/logo.svg?v=10b092e532a3",
            "https://cstheory.stackexchange.com/posts/1168/ivc/0eda?prg=39d2bc55-7d80-4ba1-8026-81480ff43e70"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2010-09-12T00:43:39",
        "summary": "",
        "meta_description": "This question is (inspired by)/(shamefully stolen from) a similar question at MathOverflow, but I expect the answers here will be quite different. \n\nWe all have favorite papers in our own respective",
        "meta_lang": "en",
        "meta_favicon": "https://cdn.sstatic.net/Sites/cstheory/Img/favicon.ico?v=b72736ad174d",
        "meta_site_name": "Theoretical Computer Science Stack Exchange",
        "canonical_link": "https://cstheory.stackexchange.com/questions/1168/what-papers-should-everyone-read",
        "text": "What Every Computer Scientist Should Know About Floating-Point Arithmetic\n\nThis paper explains and reinforces the notion that floating point isn't magic. It explains overflow, underflow, what denormalized numbers are, what NaNs are, what inf is, and all the things these imply. After reading this paper, you'll know why a == a + 1.0 can be true, why a==a can be false, why running your code on two different machines can give you two different answers, why summing numbers in a different order can give you an order of magnitude difference and all the wacky stuff that happens in the world of mapping an uncountably infinite set of numbers onto a countably finite set.\n\nAn edited version is also available on the web.\n\nHartmanis and Stearns, \"On the computational complexity of algorithms\", Transactions of the American Mathematical Society 117: 285–306 (1965)\n\nThis was the first paper that took the study of time complexity seriously, and surely was the primary impetus for Hartmanis and Stearns' joint Turing award. While their initial definitions are not quite what we use today, the paper remains extremely readable. You really get the feeling of how things were in the old \"Wild West\" frontier of the 60's.\n\nQuantum Mechanical Computers (PDF) by Richard Feynman.\n\nHe introduces the idea of quantum computation, describes quantum circuits, explains how classical circuits can be simulated by quantum circuits, and shows how quantum circuits can compute functions without lots of garbage qubits (using uncomputation).\n\nHe then shows how any classical circuit can be encoded into a time-independent Hamiltonian! His proof goes through for quantum circuits too, therefore showing that time evolving Hamiltonians is BQP-hard! His Hamiltonian construction is also used in the proof of the quantum version of the Cook-Levin theorem, proved by Kitaev, which shows that k-local Hamiltonian is QMA-complete.\n\nExpander graphs and their applications, S. Hoory, N. Linial, and A. Wigderson is an extremely nice survey on expander graphs. No surprise that it won the 2008 AMS Conant Prize.\n\nI want to recall that expander graphs are the key ingredient in recent breakthroughs in TCS, eg.\n\nlog-space algorithm for undirected connectivity (by Reingold, STOC, 2005)\n\nthe alternative proof of the PCP Theorem (by Dinur, ECCC, TR05-046, 2005)\n\nand not so recent:\n\nAKS sorting network, which achieves depth $O(\\log n)$ and size $O(n \\log n)$ for sorting $n$ inputs (by Ajtai, Komlós and Szemerédi, STOC, 1983)\n\nLinear-time encodable and decodable error-correcting codes (by Spielman, STOC, 1995)\n\nI'm surprised that no one has come up with Hastad's \"Some Optimal Inapproximability Results\" (JACM 2001; originally STOC 1997). This landmark paper has been written so well, you can come to it with little other than mathematical maturity and it will make you want to learn several things well, such as its Fourier techniques, parallel repetition, gadgets, and whatnot.\n\nLes Valiant's Theory of the Learnable (1984) set the agenda for learning theory for decades, and it's a nice and readable paper!\n\nThere's also quite a bit of intuitive explanation in the paper that makes it fun and compelling. Various parts of this paper are still routinely quoted in COLT/ALT talks.\n\nThe complexity of theorem-proving procedures by Stephen A. Cook. This paper proves that all the languages decided by polytime nondeterministic Turing machines can be (Cook-)reduced to the set of propositional tautologies.\n\nThe importance of this result is (at least) twofold: first, it shows that there exist problems in NP which are at least as hard as the whole class, the NP-complete problems; furthermore, it provides a concrete example of such a problem, which can then be reduced to others in order to prove them complete.\n\nNowadays Karp reductions are more commonly used than Cook reductions, but the main proof of this paper can be easily adapted to show that SAT is NP-complete with respect to Karp reductions.\n\nC.A.R. Hoare, An Axiomatic Basis for Computer Programming.\n\nFrom the abstract: In this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics.\n\nIt has six pages that are quite easy to follow.\n\nExtractors and Pseudorandom Generators by Luca Trevisan. In this paper good randomness extractor is built by the means of error-correcting codes and combinatorial designs. Construction is quite easy to understand but it is completely stunning, because it is not obvious at all what is the connection between extractors, codes and designs.\n\nAfter all, it is a good example of a result in TCS that requires some fancy combinatorics.\n\nIf I may quote Sarah Palin on this issue: \"All of them\".\n\nMore seriously, I think most papers should not be read in the original. As time passes people figure out better way of understanding and presenting the original problem/solution. Except for the Turing original paper, which is of historical importance, I would not recommend reading most original papers if there is followup work that cleaned it up. In particular, of a lot of stuff is presented much better in books than in the original."
    }
}