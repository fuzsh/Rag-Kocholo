{
    "id": "dbpedia_2453_0",
    "rank": 16,
    "data": {
        "url": "https://blog.computationalcomplexity.org/2014/",
        "read_more_link": "",
        "language": "en",
        "title": "Computational Complexity",
        "top_image": "https://blog.computationalcomplexity.org/favicon.ico",
        "meta_img": "https://blog.computationalcomplexity.org/favicon.ico",
        "images": [
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhJze1w94ouk96CLHSmYwmmmNi4pWdjrs29rmedWMxH7IrGgmDo-MZejSPqQ_4P5TmqJTfTisQe8sgMFrAB35_2j_SdvJ41DUz58aUVljk4P4vg6ymjZ0BlDnofpG3IoZaO_mXX/s1600/IMG_1295.JPG",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://resources.blogblog.com/img/icon18_email.gif",
            "https://resources.blogblog.com/img/icon18_edit_allbkg.gif",
            "https://pup-assets.imgix.net/onix/images/9780691175782.jpg?w=640",
            "https://i.creativecommons.org/l/by-nc/4.0/88x31.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Lance Fortnow"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch",
        "meta_lang": "en",
        "meta_favicon": "https://blog.computationalcomplexity.org/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://blog.computationalcomplexity.org/2014/",
        "text": "The NIPS Experiment\n\nThe NIPS (machine learning) conference ran an interesting experiment this year. They had two separate and disjoint program committees with the submissions split between them. 10% (166) of the submissions were given to both committees. If either committee accepted one of those papers it was accepted to NIPS.\n\nAccording to an analysis by Eric Price, of those 166, about 16 (about 10%) were accepted by both committees, 43 (26%) by exactly one of the committees and 107 (64%) rejected by both committees. Price notes that of the accepted papers, over half (57%) of them would not have been accepted with a different PC. On the flip side 83% of the rejected papers would still be rejected. More details of the experiment here.\n\nNo one who has ever served on a program committee should be surprised by these results. Nor is there anything really wrong or bad going on here. A PC will almost always accept the great papers and almost always reject the mediocre ones, but the middle ground are at a similar quality level and personal tastes come into play. There is no objective perfect ordering of the papers and that's why we task a program committee to make those tough choices. The only completely fair committees would either accept all the papers or reject all the papers.\n\nThese results can lead to a false sense of self worth. If your paper is accepted you might think you had a great submission, more likely you had a good submission and got lucky. If your paper was rejected, you might think you had a good submission and was unlucky, more likely you had a mediocre paper that would never get in.\n\nIn the few days since NIPS announced these results, I've already seen people try to use them not only to trash program committees but for many other subjective decision making. In the end we have to make choices on who to hire, who to promote and who to give grants. We need to make subjective decisions and those done by our peers aren't always consistent but they work much better than the alternatives. Even the machine learning conference doesn't use machine learning to choose which papers to accept.\n\nGuest Post about Barbie `I can be an engineer' -- Sounds good but its not.\n\nThere is now a I can be an engineer Barbie. That sounds good! It's not. Imagine how this could be turned around and made sexist. What you are imagining might not be as bad as the reality. Depends on your imagination.\n\nGuest Blogger Brittany Terese Fasy explains:\n\nRemember the controversy over the Barbie doll that said\n\n\"Math class is tough!\"? Well, Barbie strikes again.\n\nIf you haven't heard about II can be a computer engineer it is a story about how Barbie, as a \"computer engineer\" designs a game, but cannot code it herself. She enlists the help of her two friends, Steven and Brian, to do it for her. Then, she gets a computer virus and naively shares it with hersister. Again, Steven and Brian must come to the rescue. Somehow, in the end, she takes credit for all of their work and says that she can be a computer engineer. Gender issues aside, she does not embody a computer engineer in this book. For more details, please see here.\n\nChildren need role models. Naturally, parents are their first role models. And, not everyone's parent is a computer engineer / computer scientist. So, books exploring different career choices to children provides the much-needed opportunity for them to learn about something new, to have a role model (even if if that role model is fictional). In principle, this book is fantastic; however, it fails to convey the right message. That is why I started a petition to Random House to pull this book off the market.The petition is here.\n\nProgress was made as Barbie issued an apology: here. And Amazon and Barnes and Nobles removed the book from its catalog. However, neither Random House, nor the author of the book have issued a statement, and it is still available at Walmart.\n\nUntil the book is completely off the market we should not stop! And maybe one day, we'll see\n\nBarbie: I can be a Computational Geometer on the shelves.\n\nA Fly on the wall for a Harvard Faculty meeting: Not interesting for Gossip but interesting for a more important reason\n\nI was recently in Boston for Mikefest (which Lance talked about here) and found time to talk to my adviser Harry Lewis at Harvard (adviser? Gee, I already finished my PhD. Former-Advisor? that doesn't quite sound right. I'll stick with Adviser, kind of like when they refer to Romney as Governor Romney, or Palin as half-governor Palin). He also invited me to goto a Harvard Faculty meeting.\n\nNO, I didn't see anything worth gossiping about. NO I am not going to quote Kissinger ``Academic battles are so fierce because the stakes were so low'' NO I am not going to say that under the veneer or cordiality\n\nyou could tell there were deep seated tensions. It was all very civilized. Plus there was a free lunch.\n\nThe topic was (roughly) which courses count in which categories incomputer science for which requirements. Why is this interesting? (hmmm- IS it interesting? You'd prob rather hear that Harry Lewis stabbed Les Valiant with a fork in a dispute about whether there should be an ugrad learning theory course). Because ALL Comp sci depts face these problems. At Mikefest and other conferences I've heard the following issues brought up:\n\nShould CS become a service department? Math did that with Calculus many years ago. PRO: They get to tell the dean `we need to hire more tenure track faculty to teach calculus', CON: They have to have their tenure track faculty teach calculus. (I know its more complicated than that.)\n\nWhat should a non-majors course have in it?\n\nWhat should CS1,CS2,CS3 have in it (often misconstrued by the question ``what is a good first language'' which misses the point of what you are trying to accomplish). For that matter, should it be a 3-long intro sequence (it is at UMCP).\n\nCan our majors take the non-majors courses? (At UMCP our non majors course on web design has material in it that is NOT in any majors course.)\n\nWhen new courses come about (comp-bio, programming hand-held devices, Computational flavor-of-the-month) what categories to they fit into? (For an argument in favor of Machine Learning see Daume's post. ) What should the categories be anyway? And what about the functors?\n\nWhich courses were at one point important but aren't any more? UMCP no longer requires a Hardware course-- is that bad? (Yes- when I tell my students that PARITY can't be solved by a constant depth poly sized circuit, they don't know what a circuit is!)\n\nI don't have strong opinions to any of these questions (except that, despite my best efforts, we do not require all students to learn Ramsey Theory), but I note that all depts face these questions (or need to- I wonder if some depts are still teaching FORTRAN and COBOL- and even that's not quite a bad thing since there is so much legacy code out there.)\n\nI have this notion (perhaps `grass is always greener on the other side') that MATH (and most other majors) don't have these problems. AT UMCP there have only been TWO new math courses introduced on the ugrad level since 1985 :Crypto (which is cross-listed with CS), and Chaos Theory. CS has new courses, new emphasis, new requirements every few years. Oddly enough when I tell this to Math Profs they ENVY that we CAN change our courses so much. What is better chaos or stability?\n\nWhen I saw Back to the future 2 in 1989 I noticed that their depiction of academic computer science in 2015 was that Comp Sci Depts across the country agreed on what was important and be similar (as I imagine math is). Instead the opposite has happened- these things are still in flux. (If you can't trust a Science Fiction movie staring Michael J Fox what can you trust?) As a sign of that, the advanced GRE in CS never really worked and has now been discontinued.\n\nSo- will CS settle down by 2015? We still have a year to go, but I doubt it. 2025? Before P vs NP is solved?\n\nand is it OKAY if it doesn't?\n\nNon controversial thoughts on rankings\n\nUS News has a ranking of CS depts and various subcategories. Recently MohammadTaghi Hajiaghay and Luca Trevisan have suggested alternative rankings here (Moh) and here (Luca). These rankings inspire me to record some thoughts about rankings.\n\nWhen making a ranking one must ask: What is it for? For Academic depts it may be to help guide potential ugrads or grads in their choice of where to go. Rankings of the most influential people of all time (Michael Harts book here), or in a given year (Time magazine does this) are made to (I think) organize our thoughts and start debates. Michael Hart also did a book about the most influential people as soon from the year 3000 (so half are fictional) as a way to speculate (see here). My own ranking of Bob Dylan satires here was done for my own amusement.\n\nTransparency sounds like a plus. But if a ranking is too transparent, and is considered important, than organizations might game the system. Recall Goodhart's law: When a measure becomes a target is ceases to be a measure. On the other hand, if the measure really is good then it may be okay if it becomes a target. Some measures are hard to game- like surveys of what people think.\n\nThere have been a variety of rankings of presidents (see here). These ranking say something about the times they were done. Studying how they change over time could itself be a historical project of interest. Another thought: the book Hail to the chiefs it notes that James Buchanan and Andrew Johnson usually rank as the worst presidents, while Lincoln ranks as one of the best--- but this is unfair!--- Buchanan could not stop the civil war (but nobody really could) and Johnson had to clean up the mess after it (but nobody really could). The Lincoln presidency was almost entirely the civil war which Ameican won, so he gets the credit. More to the point--- ranking presidents is odd since it may depend very much on the times they govern.\n\nBill James (KEY Baseball statistician who I think should go into the Hall of Fame for changing the way we think about Baseball) has tried to have lists of GREAT TEAMS. But there is a problem (which he fully notes)- some teams are GREAT in terms of having great players, but didn't win the world series, or have only one pennant. Less than the sum of its parts.\n\nNumerical ratings may be odd in that they lump different items together. GPA is a bit odd--- do you prefer a student who got an A in Theory and a C in Operations Systems, or a student who got a B in both? I don't know the answer, but GPA wipes out the distinction.\n\nRankings that compare very unlike objects are useless. Here is a ranking of CS blogs--- the criteria seems to be just one guys opinion. I disagree with his ranking, but I have no idea what he cares about. Also, he includes Harry Lewis's fine blog BITS AND PIECES, which is often about academic stuff, and also Terry Tao's fine blog WHATS NEW which is really a math blog. Very hard to compare those two to each other or to others.\n\nThe tigher the focus the more useful a ranking can be. Ranking the best novelty songs of all time would be impossible (Number one is PDQ Bach's Classical Rap) but if you restrict to, say, best science fiction Satires I(Luke Ski's Grease Wars part 1, part 2, Part 3)- then its easier (Trivia note- Science fiction satire songs are often called FILK SONGS--- the urban legend is that at an early Science Fiction Convention Science fiction Folk Songs was mispelled as Science fiction Filk Songs and hence the term was born.)\n\nSO, what really would help potential CS Grad Students in theory? Perhaps a grid where for every department is listed the theory faculty, and for each one the number of pubs in top tier confs, second tier confs, and journals in the last 5 years, and their area, and a pointer to their website. Then RESIST the urge to boil it down to one number.\n\nI\"m reminded of being on the Grad Admissions committee. I get to look at the transcript (much more informative than the GPA), letters, possibly papers. Fortunately I don't have to boil it down to one number--- there are very few categories (accept, wait list of some sort, reject, but there can be a few others involving scholarships, but VERY few categories really).\n\nFinding what you want: I think that Raiders of the lost ark has tone of the best ending-of-a-movie ever. So I Googled best movie ending and variants of it, and alas, Raiders did not do well. One of the rankings didn't have it in the top 50. So I then Googled best movie endings Raiders of the lost ark and I found a ranking that had Raider in the top 10. Yeah! But this is all silly- I found some person who agrees with me.\n\nSteve Skienna and Charlie Ward have written a book Who's bigger: Where historical figures really rank which has a transparent and reasonable way to measure... not clear. Probably fame. For a review see here\n\nA few more notes about Sipser and Sipser-60th\n\nWhile Lance was AT Mikefest (Sipser's 60th Bday conference), helping to organize it, emceeing the personal statements, I was... also there.\n\nA few notes\n\nAside from his graying hair, Mike still looks like a teenager.\n\nIn 1985 Mike was one of the few people who thought P=BPP. He wrote a paper about how a certain kind of expander implies what we would now call a hard vs randomness result and presented it at the 1986 CCC (called STRUCTURES then). After the Nisan-Wigderson Hard vs Rand results most everyone thought P=BPP. But Mike was there first.\n\nI took his grad complexity class in the early 1980's. I remember him proving results that either he or someone else had JUST proven the last week. He did a good job too! What struck me then and now is how vibrant CS is as a field that material taught LAST WEEK can be in an INTRO grad course (that's not as true anymore).\n\nAfter PARITY not in AC_0, and the monotone circuit results, Sipser and others were OPTIMISTIC that P vs NP would be solved ``soon''. Oh, to be in a field in the early days when people were optimistic. But see next point.\n\nMike claims he STILL thinks P vs NP will be solved in 20 years. I don't quite know if he REALLY thinks this or wants to make the point that we should be optmistic. Similar to Lipton thinking P=NP--- does he really think that or does he want to make the point that we shouldn't all be so sure of ourselves?\n\nAnd two non-sipers notes (sort of) from Mikefest\n\nSteve Rudich told me that I misquoted him in a blog post and people often say `Steve, do you really think we are 6 months from an independence result'. I am not surprised that I made a MISTAKE in a blog post. I am surprised that people read it, remembered it, and asked him about it. In any case I have edited that post to SAY it was a mistake and I re-iterate it now: STEVE RUDICH DOES NOT THINK WE ARE SIX MONTHS AWAY FROM AN IND PROOF FOR P VS NP.\n\nI spoke to Mauricio Karchmer who, with Avi W and others, had an approach to P vs NC^1 via comm. comp which at the time I thought was very promising--- since we really can prove things in comm. comp. Alas it still has not panned out. However, Mauricio now thinks that (1) We can't prove lower bounds because they are false, and (2) we can't prove upper bounds because we are stupid.\n\nMetrics in Academics\n\nCongratulations to the San Francisco Giants, winning the World Series last night. In honor of their victory let's talk metrics. Baseball has truly embraced metrics as evidenced in the book and movie Moneyball about focusing on statistics to choose which players to trade for. This year we saw a dramatic increase in the infield shift, the process of moving the infielders to different locations for each batter based on where they hit the ball, all based on statistics.\n\nMetrics work in baseball because we do have lots of statistics, but also an objective goal of winning games and ultimately the World Series. You can use machine learning techniques to predict the effects of certain players and positions and the metrics can drive your decisions.\n\nIn the academic world we certainly have our own statistics, publications counts and citations, grant income, teaching evaluation scores, sizes of classes and majors, number of faculty and much more. We certainly draw useful information from these values and they feed into the decisions of hiring and promotion and evaluation of departments and disciplines. But I don't like making decisions solely based on metrics, because we don't have an objective outcome.\n\nWhat does it mean to be a great computer scientist? It's not just a number, not necessarily the person with a large number of citations or a high h-index, or the one who brings in huge grants, or the one with high teaching scores, or whose students gets high paying jobs. It's a much more subjective measure, the person who has a great impact. in the many various ways one can have an impact. It's why faculty applications require recommendation letters. It's why we have faculty recruiting and P&T committees, instead of just punching in a formula. It's why we have outside review committees that review departments and degrees, and peer review of grant proposals.\n\nAs you might have guessed this post is motivated by attempts to rank departments based on metrics, such as described in the controversial guest post last week or by Mitzenmacher. There are so many rankings based on metrics, you just need to find one that makes you look good. But metric-based rankings have many problems, most importantly they can't capture the subjective measure of greatness and people will disagree on which metric to use. If a ranking takes hold, you may optimize to the metric instead of to the real goals, a bad allocation of resources.\n\nI prefer the US News & World report approach to ranking CS Departments, which are based heavily on surveys filled out by department and graduate committee chairs. For the subareas, it would be better to have, for example, theory people rank the theory groups but I still prefer the subjective approach.\n\nIn the end, the value of a program is its reputation, for a strong reputation is what attracts faculty and students. Reputation-based rankings can best capture the relative strengths of academic departments in what really matters.\n\nMartin Gardner Centennial\n\nMartin Gardner was born on October 21, 1914, so today is his Centennial (he died on May 22, 2010, at the age of 95). We've mentioned him in the blog before:\n\nThe Life of Martin Gardner\n\nContribute to the Gardner Centennial\n\nAnother Post on Martin Gardner\n\nI used the anagram Tim Andrer Gran in both my review of the Lipton-Regan book (see here) and my Applications of Ramsey Theory to History paper (see here)\n\nSo what can I add on his centennial?\n\nHe was not the first person to write on recreational mathematics, but he was certainly early and did it for a long time.\n\nI suspect he influenced everyone reading this who is over 50. For every y, y is under 50 and reading this column, there exists x such that MG influenced x and x influenced y.\n\nThe line between ``recreational'' and ``serious'' math is sometimes blurry or hard to see. An obvious case of this was Euler and the Bridges problem leading to graph theory. At one time solving equations was done for competition, which seems recreational. Galois theory is not recreational.\n\nDonald Knuth's book Selected Papers in Discrete Math (reviewed by me here) states I've never been able to see the boundary between scientific research and game playing.\n\nI am reading a book Martin Gardner in the 21st century which is papers by people who were inspired by him. The papers really do blur the distinction between recreational and serious. Some are rather difficult but all start out with a fun problem.\n\nAside from recreational math he did other things- magic, and debunking bad science. (Fads and Fallacies in the name of science was excellent.) He was a well rounded person which is rare now.\n\nBrian Hayes and Ian Stewart and others do what he did, but given the times we live in now, its hard capture the attention of a large segment of the public. (analogous to that when I was a kid there were only a handful of TV stations, now there are... too many?)\n\nWhen I was in high school I went to the library looking for math books I could read (naive?). I found one of his books (collection of his columns) and began reading it. I learned about casting out nines and I learned what was to be the first theorem I ever learned a proof of outside of class (given that I was probably 12 it may be the first proof I learned ever). It was that (in todays lang) a graph is Eulerian iff every vertex is even degree.\n\nLuddite or not?\n\nMy first ever guest post for Lance was on Are you a luddite. I certainly am to some extent a luddite, but there are some things where it not clear if they are luddite-ish or not.\n\nI prefer reading books to blogs. This came up when I reviewed both Lipton and Lipton-Regan blog-books, and I am now reading some of Terry Tao's Blog book. l look forward to reading Scott's Blog book. At first I thought that preferring books was luddite-ish. But some high tech people and some young people who I've asked AGREE with me. Why is this?\n\nWhen reading a blog (or doing anything on line) its so easy to get distracted, e.g. OH, I WONDER IF WHITEY FORD IS STILL ALIVE SO I\"LL PUT HIM ON MY LIST OF LIVING FAMOUS PEOPLE OVER 80 (he is, he's 85, and has the same birthday (though not year) as Martin Gardner), OH, I wonder if the word Buypartisan (that is NOT misspelled) is on my list-of-cool-new-words that I keep, OH I wonder how many people have registered for Theory Day. OH, Lipton just posted about Definitions not being needed and used that quote from The Treasure of Sierra Madre (see here) that was satirized in the movie UHF, I wonder if that clip is on You-Tube (It is here). OH, I can write a blog about Math in Weird-Al songs, for example Polka Patterns.\n\nIf I read a blog with a proof in it I tend to say I'll read that later.\n\nI work better with pen and paper on hand. This may change if the way to mark up pdf and other documents gets better.\n\n(I do not why it restarted at number 1. I don't care to fix it- is that Luddite or not wanting to waste time on something unimportant?)\n\nOf course, the blog reading issue is MY fault for being distracted.\n\nI don't pay my bills on line. There have been many data breaches and that gets darling and I nervous. Is this Luddite? Not sure--- is banking off-line any safer? I ask non-rhetorically.\n\nIn a small class I use the blackboard. Some of my systems faculty have gone from board to slides and then back to board. For a big class I have to use slides, though that may be an argument for small classes.\n\nBILL: When I goto that conference I am going to bring some math to read during the talks I don't understand.\n\nDARLING: Isn't that rude?\n\nBILL: Many people in the audience will have their laptops out, reading email, managing their facebook page, etc.\n\nDARLING: But the speaker can at least imagine they are taking notes\n\nBILL: Unlikely. In the next talk the speaker will become the laptop person.\n\nThe fact that I don't look at a laptop during a talk is probably a plus- and not a Luddite thing.\n\nWe still don't have Netflix. We watch less TV this way? Worse TV this way? Not clear how this one goes.\n\nI used to write things out before typing them in, now I type them in directly. I wonder if that's good or bad.\n\nI used to have notebooks of random math stuff in them. Now I can't get myself to write things out by hand. That's probably bad.\n\nIf someone asks me a question I am too quick to goto the web rather than try to answer it myself. This is mixed--- I don't waste time on problems I can't solve, but I also don't have the joy of solving them. I think of myself as not being a good problems-solver, but this could be a self-fulfilling prophecy that the web makes easier to indulge in.\n\nThis is a DUH-comment- I hate technology that does not work. One of the worst episodes of Star Trek was The Ultimate Computer which showed that a good human is better than a MALFUNCTIONING computer. Well DUH. I had a rant about electronic refereeing - and not a single comment accused me of being a Luddite. In short- I hate technology that doesn't work. Duh.\n\nSo- your thoughts? Some Luddite things may not be Luddite, but just better. And technology will change yet again, making us all Luddites.\n\nThe Complexity of NIM. Open?\n\nRecall 1-pile NIM:\n\nLet A be a finite set of Naturals. NIM(A) is the following game: There are n stones on the board. Players I and II alternate removing a\\in A stones. The first player who can't win loses. Note that if 1\\in A then `can't move' means that the other player took the last stone. If (say) 2 is the min elt of A then its possible there is 1 stone on the board and a player can't move.\n\nThe following are known and easy to prove:\n\nIf A={1,L} and L is even then II wins iff n\\equiv 0,2,4,...,L-2 mod L+1\n\nIf A={1,L,L+1} and L is odd then II wins iff n\\equiv 0,2,4,...L-1 mod 2L+1\n\nIf A={1,L,L+1} and L is even then II wins iff n\\equiv o,2,4,...,L-2 mod 2L\n\nIf A= {L,...,M} then II wins iff n\\equiv 0,2,4,...,L-2 mod L+1\n\nFor ANY set A there will be a mod pattern, after a certain point.\n\n(I think that if 1\\in A then the mod pattern goes from the beginning, but if 1\\notin A then its possible that it does not start for a while.)\n\nThis raises the following computational problem: How hard is the problem of, given finite set A, find the mod pattern. I would want to know the complexity as a function of the size of the representation of A, or possibly just |A|log_2(max elt of A). Has this been looked at? Some Google searches and asking around did not yield anything. I'm hoping that asking my readers may yield something.\n\nDagstuhl on Algebra in Computational Complexity\n\n(Reminder- Theory day at UMCP: here is the link. )\n\nThere was a Dagstuhl on Algebra in Computational Complexity Sept 22-26.\n\nI learned stuff in the talks, over meals, and even in my room alone at night.\n\n1) Recall that a while back Ryan Williams (the theorist, not the American-Football player) showed that NEXP is not in ACC. His proof involved MANY things but one of the core things was an ALGORITHM for a version of SAT (I think Succinct-SAT) that was ever-so-slightly better than brute force. So one lesson is that people in complexity theory should know some algorithms. At Dagstuhl Ryan presented work that shows that people in algorithms should know complexity. He used some old results about circuits to obtain algorithm for all-pairs shortest path that has complexity n^3/X where X=2^{\\Omega(log n)^{1/2}. The ultimate goal is to either prove or disproof that all-pairs... has n^{3-ep} algorithms or not. On the NOT side he has (with other people, including Virginia Williams) a large class of problems , including APSP, that either all have n^{3=ep} or none of them do.\n\n2) There were two (possibly three) talks on VP and VNP. Both are circuit classes defined by Valiant. Meena Mahajan has some natural problems that are complete for VNP (if you consider looking at Homomorphic polynomials natural) and Eric Allennder had a dual notion to VP and VNP. A sequence of polynomials is in VP if there is an arithmetic circuit family of polynomial bounded size and degree that computes the sequence. (Circuit C_n computes poly f_n). VNP is if there is a sequence C_n of poly bounded size and degree such that f_n(x) = sum as y\\in {0,1}^p(n) C_n(x,y).\n\nThis is usually discussed over a finite field. Eric's result depended on which field it was.\n\n3) Stephen Fenner talked about some combinatorial games that were PSPACE complete. The black-white-poset-game is as follows: there is a poset where every node is colored white or black. One player is called black, the other is called white. Players alternate removing nodes of their color, and if they remove a node they remove all nodes above it. Either player can go first, so you may have a game where if B goes first he wins, but if he goes second he does not. Fenner and his co-authors have shown that the general problem of, given a Black-whie Poset and who goes first, determining who wins, is PSPACE complete. They showed that other versions are in P.\n\n4) In the 1990's Karchmar and Wigderson had an approach to NC^1 vs NC^2 and P vs NC^1 that looked promising--- they defined problems in communication complexity (where we actually DO have results!) that would imply some separations. This lead to monotone circuit results, but not to real circuit results. Or Meir spoke on some problems in that realm which can now be approaced with information complexity. Are we closer to a true separation? Next Dagstuhl!\n\n5) David Zuckerman gave a nice talk on Malleable codes. I was intrigued by some of the math that he did. The Sum-Product theorems are along the lines of: If A, B are large sets of reals (or other domains) then either A+A or AA is large. Or one could say that if A,B,C are all large than AB+C is large. David used an entropy version of this--- if A,B,C have large min-entropy, then so does AB+C.\n\n6) Kopparty showed that Polynomial Id Testing and Polynomail Factoring are related and may be equivalent.\n\n7) Over Lunch Jacobo Toran told me the following rather odd result.\n\na) Imagine the following GI algorithm: given two graphs look at the degree sequence, then the degrees of the degress, then... (this goes on n times). Two graphs are isom if they are never found to be non-isom. DOESN\"T WORK- Cai-First-Immerman showed that. Even so, we'll call that FOCSI-isom. Note that FOCS-isom is in P.\n\nb) Recall that G (as a matrix) and H (as a matrix) are isom if there exists a Perm Matrix P such that GP = PH. We can expand what P can be- say to doubly-stocastic (every row and every column adds to 1) We call two graphs G,H STOC-isom if there exists a Double stocastic matrix P such that GP=PH. This is in Poly Time by Linera Programming.\n\nc) FOCS-isom and STOC-isom are the same! Too bad, I thought that STOC-isom might be a way to get GI in P.\n\n8) Sometimes at a conference I find a book in the library and read it at night and learn something out of nowhere. This happened with Mitzenmacher-Upfal book on Prob. and Computing (It could be called ``The Alice book'' as there is a picture of Alice from Alice in Wonderland on the cover. For the longest time a famous compiler book was called The Dragon Book). I read parts of it and even made up notes that I may use in an ugrad course: the coupon collector problem: A cereal company puts coupons labeled 1,2,...,n at random in boxes. If you mail in one of each you get a free box of cereal. You are DETERMINED to get that box of cereal. What is the expected number of boxes of cereal you must buy? It turns out to be nln(n), and is very tight around that.\n\n9) I learned more from the talks, more from the meals, and more from my own alone time, but what is above is a good sampling.\n\n10) More chalk-talks then I would have thought. Either chalk or slides can be done well or poorly.\n\n11) Looking forward to the next Dagstuhl!"
    }
}