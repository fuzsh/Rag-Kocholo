{
    "id": "dbpedia_4099_2",
    "rank": 43,
    "data": {
        "url": "https://www.atlanticcouncil.org/in-depth-research-reports/report/how-modern-militaries-are-leveraging-ai/",
        "read_more_link": "",
        "language": "en",
        "title": "How modern militaries are leveraging AI",
        "top_image": "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/cover-image-e1691617924468.jpg",
        "meta_img": "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/cover-image-e1691617924468.jpg",
        "images": [
            "https://px.ads.linkedin.com/collect/?pid=1698650&fmt=gif",
            "https://www.atlanticcouncil.org/wp-content/uploads/2022/03/ACYellow-adjust.png",
            "https://www.atlanticcouncil.org/wp-content/themes/atlantic-council/dist/images/icon-search.svg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/Photo-1.jpg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/Figure-1-1024x456.png",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/photo-2-1024x683.jpg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/Picture1.png",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/photo-3-1024x683.jpg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/Picture4.jpg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/Picture4-1.jpg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/photo-6.png",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/07/Picture7.jpg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2019/08/LM-logo-300x82.png",
            "https://www.atlanticcouncil.org/wp-content/uploads/2019/10/Tate-Nurkin-headshot-231x300.jpg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2023/04/Julia-Siegel_07-WEB-225x300.jpg",
            "https://www.atlanticcouncil.org/wp-content/uploads/2024/05/Forward-Defense.png",
            "https://www.atlanticcouncil.org/wp-content/themes/atlantic-council/dist/images/AC-logo-light.svg"
        ],
        "movies": [
            "https://e.issuu.com/embed.html?d=battlefield_applications_for_human-machine_teaming&u=atlanticcouncil"
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "dmanson"
        ],
        "publish_date": "2023-08-14T13:00:00+00:00",
        "summary": "",
        "meta_description": "This report investigates the incorporation of AI into military operations with a focus on challenges to the US DOD's adoption of HMT.",
        "meta_lang": "en",
        "meta_favicon": "https://www.atlanticcouncil.org/wp-content/uploads/2019/09/favicon-150x150.png",
        "meta_site_name": "Atlantic Council",
        "canonical_link": "https://www.atlanticcouncil.org/in-depth-research-reports/report/how-modern-militaries-are-leveraging-ai/",
        "text": "By Tate Nurkin and Julia Siegel\n\nTable of contents\n\nThe importance of human-machine teaming and key insights\n\nApplications of human-machine teaming\n\nDemonstrating advantage through use cases\n\nPathways to HMT adoption at scale and pace\n\nSummary of recommendations and conclusion\n\nAcknowledgements\n\nAbout the authors\n\nThe importance of human-machine teaming and key insights\n\nKey takeaways\n\nLooking through the lens of three military applications for HMT, the authors arrive at the following conclusions.\n\nHMT has the potential to change warfare and solve key operational challenges: AI and HMT could potentially transform conflict and noncombat operations by increasing situational awareness, improving decision-making, extending the range and lethality of human operators, and gaining and maintaining advantage across the multi-domain fight. HMT can also drive efficiencies in many supporting functions such as logistics, sustainment, and back-office administration, reducing the costs and timelines of these processes and freeing up humans to carry out higher-value tasks within these mission areas.\n\nDOD must expand its definitions for HMT: Definitions of HMT should be expanded to include the breadth of human interactions with autonomous uncrewed systems and AI agents, including those that have no physical form (e.g., decision support software). Extending the definition beyond interactions between humans and robots allows DOD to realize the wide-ranging use cases for HMT—ranging from the use of lethal weapon systems and drone swarms in high-intensity warfare to leveraging algorithms to fuse data and realize virtual connections in the information domain.\n\nHMT development and employment must prioritize human-centric teaming: AI development is moving at an impressive pace, driving potential leaps ahead in machine capability and placing a premium on ensuring the safety, reliability, and trustworthiness of AI agents. As much attention must be dedicated to developing the competencies, comfort levels, and trust of human operators to effectively exploit the value of HMT and ensure humans stay at the center of human-machine teams.\n\nDOD must move from the conceptual to the practical: HMT as a concept is gaining momentum within some elements of the DOD enterprise. Still, advocates for increased AI and HMT adoption stress the need to move the conversation from the conceptual to the practical—transitioning capability development into the real-time testing and employment of HMT capabilities, as has been demonstrated by the Navy’s experimentation with AI through Task Force 59—to better articulate and demonstrate the operational advantages HMT can deliver.\n\nExperimentation is crucial to building trust: Iterative, real-world experimentation in which humans develop new operational concepts, test the limits of their machine teammates, and better understand their breaking points, strengths, and weaknesses of machines in a range of environments will play a key role in speeding HMT adoption. This awareness is also essential to human operators as they develop the trust in their AI teammates required to effectively capitalize on the potential of HMT.\n\nDOD must address bureaucratic challenges to AI adoption: DOD’s risk-averse culture and siloed bureaucracy is slowing acquisition, experimentation, and adoption of HMT concepts and capabilities. Increasing the agility and flexibility of the acquisition process for HMT capabilities, iterative experimentation, incentives to take on risks, and digital literacy across the force are necessary to overcome these adoption challenges.\n\nBack to top\n\nApplications of human-machine teaming\n\nHMT is most frequently envisioned narrowly as the process of humans interacting with anywhere from one to several hundred or more autonomous uncrewed systems. In its most basic form, this vision of HMT is not new: Humans have collaborated with intelligent machines for decades—with early machine talents epitomized in 1997 by supercomputer Deep Blue defeating world champion Gary Kasparov in a game of chess—and militaries have long tested concepts to move the needle in this critical capability. The recent impressive pace of development in AI as well as in robotics, however, is driving increased consideration of the new capabilities, efficiencies, and advantages these technologies can enable.\n\nThe “loyal wingman” concept is a frequently cited example of this manifestation of HMT in which a human pilot controls the tasking and operations of a handful of relatively inexpensive, modular, attritable autonomous uncrewed aerial systems (UAS). These wingman aircraft can fly forward of the crewed aircraft to carry out a range of missions, including electronic attack or defense, intelligence, surveillance, and reconnaissance (ISR), or strike, or as decoys to attract fire away from other assets and “light up” enemy air defenses.\n\nInterest in this manifestation of HMT has increased not just in the United States but also in most modern militaries. In addition to the United States, Australia, China, Russia, the United Kingdom, Turkey, and India all have at least one active loyal wingman development program, while the sixth-generation fighter efforts Global Combat Air Programme (United Kingdom, Italy, Japan), Next Generation Air Dominance programs (US Air Force and Navy), and Future Combat Air System (Germany, France, Spain) involve system of systems concepts of airpower that stress both HMT and machine-machine teaming.\n\nAs important as this category of HMT is and will continue to be to emerging military capabilities, discussion of HMT should include the full breadth of human interaction with AI agents (which learn from and make determinations based on their environments, experiences, and inputs), including the overwhelming majority of interactions that occur with algorithms that possess no physical form. Project Maven is one example of how DOD and now the National Geospatial-Intelligence Agency use this category of HMT to autonomously detect, tag, and trace objects or humans of interest from various forms of media and collected intelligence, enabling human analysts and operators to prioritize their areas of focus.\n\nBy combining the processing power and decision support capabilities of AI with the social intelligence and judgment of humans and, in some cases, the force-multiplying effects of uncrewed systems with different degrees of autonomy, HMT can provide multiple layers of overlapping advantages to the United States and its allies and partners, including those high-level advantages listed in Figure 1.\n\nFigure 1: High-level description of three layers of HMT value.\n\nDOD recognition of the current and future multilayered value of HMT as part of broader efforts to “accelerate the adoption of AI and the creation of a force fit for our time” has increased. Still, several persistent challenges to adoption of AI and HMT endure throughout the Pentagon. To accelerate and deepen HMT adoption, the DOD must commit to an approach that aligns development efforts and private sector engagement, creating flexibility for acquisition officials to scale HMT solutions across the defense enterprise. This approach must be complemented by:\n\nContinued and increased focus on building trust between humans and machine partners;\n\nLeading in establishing best practices and norms around ethics and safety;\n\nAggressive and iterative experimentation; and\n\nClear and consistent messaging\n\nThese elements are crucial to realizing the value and advantages HMT can deliver across the multi-domain future fight.\n\nBack to top\n\nDemonstrating advantage through use cases\n\nUse cases serve as a means of better understanding how HMT can provide value and lead to advantage in and across several missions and environments. Certainly, practitioners have seen or experienced use cases in various settings—including through war games and analysis of the ongoing war in Ukraine—and the slow nature of HMT adoption may call into question the utility of use cases. Still, highlighting the varied and, in certain instances, underappreciated applications of HMT can help demonstrate the different contexts in which HMT acts as a force multiplier and how this capability can support the US military in meeting the demands of the modern battlefield.\n\nHowever, changing the perceptions of HMT across a large organization such as DOD is an iterative task and requires the frequent reinforcement of its value, especially as the technologies and concepts supporting HMT create new or enhanced opportunities. The three use cases discussed below are far from inclusive—our workshops and research explored several other compelling use cases—but the authors chose them because they reflect the layered value of HMT in serving missions and meeting operational threats and challenges being urgently considered by defense planners, as described in Table 1.\n\nTable 1: A high-level review of the advantages of each of the case studies discussed in this briefing.\n\nAnti-access and area-denial (A2/AD): Coping with mass, range, and attrition\n\nDetermining how to conduct operations in an A2/AD environment is a clear priority for defense planners. This is especially the case in the Indo-Pacific, where the military modernization effort of the People’s Republic of China has emphasized utilizing pervasive multi-domain sensors and a surfeit of kinetic and non-kinetic strike assets to establish cordons in which US and allied forces are highly vulnerable to enemy fires and, in the worst-case scenario, unable to operate effectively.\n\nHMT will not mitigate all risks of operating against robust A2/AD systems, though it can help US and allied forces better manage these risks in several ways, including in processing and analyzing large and complex datasets to support better and faster human decision-making.\n\nTeaming uncrewed systems, crewed assets, and human operators\n\nThe use of attritable and expendable uncrewed systems, in conjunction with crewed assets and human controllers and decision-makers, can achieve several important objectives in the A2/AD context. Most notably, these smaller, less expensive, generally modular systems can be used to saturate A2/AD systems, identify enemy defenses, and force adversaries to expend their deep stores of munitions—all while extending the operating range of higher-value crewed and uncrewed assets and reducing the risks to crewed assets and their human operators.\n\nThe use of attritable and expendable uncrewed systems, in conjunction with crewed assets and human controllers and decision-makers, can achieve several important objectives in the A2/AD context.Attritable or reusable systems are those that are considerably lower cost than higher-end uncrewed systems such as the MQ-9 Reaper. Most notably, these smaller, less expensive, generally modular systems can be used to saturate A2/AD systems, identify enemy defenses, and force adversaries to expend their deep stores of munitions—all while extending the operating range of higher-value crewed and uncrewed assets and reducing the risks to crewed assets and their human operators.\n\nTo that end, reducing risk to human operators does not mean eliminating this risk, and the use of attritable uncrewed aerial systems (UAS) and uncrewed surface vehicles (USVs) will still incur costs. Moreover, even attritable systems and their payloads can be worth several million dollars. New calculations of value as well as increased capacity to reconstitute systems must keep pace with expected levels of attrition to ensure the right sizing of HMT-enabling force structures.\n\nSense-making and decision support: Enhanced situational awareness and improved decision-making at the pace of relevance\n\nThe A2/AD environment also serves as an example of how machines can support humans in the crucial and increasingly demanding task of sense-making—the art of interpreting and fusing data for enhanced decision-making.\n\nSense-making in A2/AD environments\n\nA2/AD environments will be characterized by an abundance of complex datasets and both signal and noise across domains including in the electromagnetic spectrum. The amount of data available to operators will be overwhelming. Multi-domain sensors and surveillance and strike assets will be actively operating and engaging with both friendly and adversary forces, creating a need for AI agents to help process and filter data and feed relevant information back to the warfighter. The result will be to improve the quality and speed at which human operators filter data and then fix and track critical nodes in adversary A2/AD systems. This high-level A2/AD example reveals one context in which AI-enabled data fusion and processing of complex datasets can increase situational awareness and speed up decision-making. But the applications of this sense-making are impressively broad, including in increasing the speed and precision of identifying targets, determining appropriate kinetic or non-kinetic weapons to use to strike the target, and ensuring precision of effects.\n\nTargeting: Joint all-domain command and control (JADC2)\n\nDOD’s “connect everything” JADC2 effort offers another example of how HMT can be applied to support improved targeting and speeding up sensor-to-shooter processing. As a January 2022 Congressional Research Service report observed, “JADC2 intends to enable commanders to make better decisions by collecting data from numerous sensors, processing the data using AI algorithms to identify targets, then recommending the optimal weapon—both kinetic and non-kinetic—to engage the target.” While JADC2 is still largely a concept rather than an architecture for future military operations, the US military is already using AI to help find and track possible targets or entities of interest on the battlefield. In September 2021, Secretary of the US Air Force Frank Kendall acknowledged that the Air Force had “deployed AI algorithms for the first time to a live operational kill chain” to provide “automated target recognition.” Kendall noted that by doing so, the Air Force hoped to “significantly reduce the manpower-intensive tasks of manually identifying targets—shortening the kill chain and accelerating the speed of decision-making.”\n\nAI in the intelligence field\n\nSense-making through human-machine teams is also shaping the future of disciplines such as intelligence analysis and mission planning (see sidebar below), in which AI-enabled data fusion, pattern and anomaly detection, and research and analysis support are helping analysts manage and exploit the explosion in available sources and data. Tasks that would take days for humans to perform can now be performed in hours, allowing humans to concentrate on the most relevant pieces of information derived from large datasets. For example, through the war in Ukraine, the Ukrainian Armed Forces are already using natural language processing tools that leverage AI to translate and analyze intercepted Russian communications, saving analysts time and allowing them to focus on key messages and intelligence. The use of AI is not only speeding up analysis but also demonstrating value in bringing “unknown knowns”—observed but ignored or forgotten connections, insights, and information—to the attention of an analyst and articulating the value or quality of information to the human decision-maker.\n\nPresence, prioritization, and deterrence: Coping with distance and complexity\n\nExporting Task Force 59: A sandbox for AI experimentation and integration\n\nIn September 2021, CENTCOM’s 5th Fleet established Task Force 59—the Navy’s testing ground for unmanned systems and AI—to experiment with teaming human operators and both smart robots and AI agents to increase presence across the region, provide persistent and expanded maritime domain awareness (MDA), and prioritize threats for in-demand crewed and high-value assets.\n\nTask Force 59’s experimentation efforts combine AI and uncrewed systems—particularly USVs but also vertical take-off and landing UAS, which are valuable in expanding the coverage of the Navy’s ISR networks in the region—and are further amplified by cooperation with partners and allies. In comments at the February 2023 International Defence Conference in Abu Dhabi, 5th Fleet Commander Vice Admiral Brad Cooper explained that each of the small USVs with which Task Force 59 is experimenting can extend the range of ISR networks by thirty kilometers, meaning that even a modest investment in smart uncrewed systems can deliver a significant increase in MDA.\n\nAI agents then process the millions of data points collected by the uncrewed systems to create an understanding of normal patterns of life, which, in turn, serves as a baseline for AI agents to identify anomalies that require further investigation by human operators and watchkeepers. In doing so, human-machine teams can cultivate a deeper understanding of the operational environment, moving toward a predictive model in which the DOD can possibly anticipate and prevent future threats and prioritize allocation of limited resources to areas that AI agents determined are most vulnerable to disruption.\n\nBuilding on the success of the Navy’s Task Force 59, both the Army and Air Force components of CENTCOM have stood up task forces to experiment with emerging technology and HMT concepts. The Army component, Task Force 39, was established in November 2022 to advance experimentation in counter-small UAS solutions that can be scaled not just within CENTCOM environments but across the DOD. The Air Force’s Task Force 99 was stood up in October 2022 as an operational task force to pair unmanned and digital technologies to improve air domain awareness in much the same way that Task Force 59 seeks to improve MDA by expanding presence and anticipating emergent threats. Lieutenant General Alexus Grynkewich, commander of CENTCOM’s Air Force component, stated in February 2023 that the objective is “not just tracking objects in the air, but maybe finding things that could be on the ground about to be launched into the air and how those could be a threat to us.”\n\nThe applicability of this HMT approach is not limited to CENTCOM; indeed, it is now being adopted in other commands. In April 2023, the US Navy announced the expansion of its experimentation with unmanned and AI tools into US Southern Command’s 4th Fleet to increase MDA awareness in a region with its own particular dynamics, threats, and MDA requirements. Notably, 4th Fleet is taking a different approach to adoption of HMT lessons and new HMT capabilities, deciding to integrate them into its command and staff structure rather than through the standing up of a discrete task force. While these task forces provide valuable models for quickly bringing off-the-shelf technologies to the warfighter, the challenge rests in scaling these solutions across services and domains (and the defense enterprise at large).\n\nBack to top\n\nPathways to HMT adoption at scale and pace\n\nThe pace of AI and HMT technology development has exceeded the capacity of the DOD to adopt these technologies at scale. To more fully realize the advantages of HMT, DOD must:\n\nAddress several cultural, bureaucratic, and organizational challenges;\n\nEnsure continued focus on HMT ethics, safety, and agency;\n\nEmbrace rapid and realistic experimentation of HMT; and\n\nDevelop the human component and enhance trust in their machine teammates.\n\nCulture, acquisition, and melting the “frozen middle”\n\nOrganizational and cultural constraints radiate across the DOD, affecting the way the enterprise acquires and adopts the technologies, concepts, and capabilities necessary to enable HMT. Innovation and adoption are hindered by DOD’s “frozen middle”—layers of relatively senior military and civilian personnel within DOD bound by an underlying set of inherited assumptions, incentives, and instincts that are resisting the adaptive, collaborative practices necessary for adoption of HMT concepts and capabilities at pace and scale. These organizational layers and bureaucratic proclivities have a cascading effect as they embed in a DOD acquisition system. According to former Secretary of Defense Mark Esper and former Secretary of the Air Force Deborah Lee James, co-chairs of the Atlantic Council’s Commission on Defense Innovation Adoption, the effect is slowing adoption by requiring multiple levels of review “because incentives do not exist to be bold and to move fast.”\n\nOrganizational “tribalism” also has an enervating effect on the DOD’s acquisition of key technologies and adoption of HMT-relevant capabilities. Examples of cross-service and cross-command collaboration do exist. Workshop participants highlighted joint projects on AI transparency between service laboratories and the ability of the US Special Operations Command, as a functional command, to work across regions and services. Far more frequently, though, disjointed development and vendor engagement and procurement efforts have been the norm. To achieve the necessary momentum for adoption across DOD—and, most importantly, the salutary outcomes of this adoption—requires an increased willingness to share and subsequently align research, information, development efforts, acquisition models, and best practices across the department and, particularly, the services.\n\nIn June 2022, David Tremper, director for electronic warfare in the Office of the Under Secretary of Defense for Acquisition and Sustainment, provided an example of how DOD siloes slow adoption of HMT-enabling capabilities. Tremper highlighted an incident in which the Navy developed an electronic warfare algorithm that was of interest to the Army, though transfer of the algorithm could not take place without a memorandum of understanding (MoU) between the two service’s labs. It took nine months for the lab that developed the algorithm to approve the transfer, and, after eighteen months, the MoU was determined to be inadequate to support the algorithm migration. According to Tremper, “one service just lawyered up against the other . . . and prevented a critical capability . . . from going from one service to another service.” This example highlights the hurdles blocking the services from learning and gaining from one another’s strides in HMT; the cross-service applicability of HMT solutions is critical to avoid a service unnecessarily depleting its resources in a field where its sister service has already paved the way.\n\nTo melt this frozen middle and reduce cultural and organizational obstacles to HMT adoption, the DOD must center its efforts around three high-level aims. First, acquisition reform is a necessary and foundational step. The ability to develop, build, and acquire advanced platforms and systems with longer development times remains important to achieving DOD missions. There is also growing and urgent demand for the technologies and capabilities enabling HMT, such as software and lower-cost uncrewed systems, across the Pentagon. The program-centric system used to acquire and develop many advanced platforms—with the development of requirements, budgets, and capabilities completed individually for hundreds of programs—is not optimized for the rapid acquisition of the innovative technologies and capabilities developed by traditional defense suppliers and the commercial sector.\n\nWhile the objective of this report is not to provide a comprehensive set of recommendations for acquisition reform, two principles are useful in guiding this reform: 1) the need for increased flexibility and agility within the acquisition process, enabling response to changing technologies and requirements; and 2) new incentives that stimulate an enhanced degree of risk tolerance.\n\nSecond, among the workforce setting requirements for and working alongside machine teammates, a lack of understanding surrounding HMT and its applications is slowing adoption. The human element of this equation must be adequately prioritized through recruitment, retention, and training programs. Specifically, DOD must provide its personnel with opportunities to enhance digital literacy and understanding of the technologies, concepts, and applications of HMT capabilities within not just the acquisition force and those that set requirements but also among many senior decision-makers.\n\nThe human component: Trust and training\n\nBuilding and calibrating appropriate levels of human trust in AI teammates is essential to HMT adoption across the DOD. This discussion typically begins with several actions designed to ensure the reliability—that is, the trustworthiness—of AI agents, such as establishment and implementation of effective best practices for the design, rigorous testing, iterative experimentation, and deployment of AI-enabled machines. Enhancing data security is another frequently cited component of building trust: Humans cannot trust algorithms if they lack faith in the integrity of the data being processed or used to train the algorithm.\n\nLimitations in AI transparency (i.e., how machines perceive the environments they are in) and explainability (i.e., how machines come to decisions) pose another challenge. While not prohibitive to the employment of HMT in many missions and contexts, reducing the “black box” nature of AI outputs will have a positive impact on the capacity for humans to trust their machine teammates and, in turn, on the pace of adoption for the range of HMT applications.\n\nIncreased experimentation—in terms of frequency, rigor, and realism—can enhance the human operator’s understanding of how an AI agent reached a certain conclusion. The DOD must embrace accelerated experimentation across a diverse set of scenarios and use cases. By asking humans to “try to break the technology,” operators and analysts can develop a better understanding of the limits, strengths, and weaknesses of their AI-enabled teammates as well as any possible unexpected behaviors. Rapid and aggressive experimentation in conditions that replicate real-world operational conditions has been a regularly highlighted feature of Task Force 59’s success to date, though there is concern that this practice has not been adopted broadly across DOD.\n\nThis is especially the case in situations in which a general-purpose machine or set of machines is interacting with multiple humans rather than just one human controller. Protocols for determining who is in control, whose priorities are executed, and how to manage contradictory instructions become essential.\n\nEthics, agency, judgment, and reliability: Maintaining leadership and retaining relevance\n\nPathways to adoption of HMT at speed and scale do not solely rely on the DOD doing things radically differently or applying new incentives and structures. Rather, they can build on the momentum of ongoing initiatives.\n\nThe DOD has already expended commendable energy in understanding and addressing questions of ethics, safety, alignment, and agency—all of which emerged as acute areas of interest and concern during the project workshops. The DOD, in collaboration with other parts of the US government, has been proactive in articulating its positions on key questions of ethics and safety around AI development and use for military purposes since first adopting principles for AI ethics in February 2020. In February 2023, at the conclusion of the Responsible AI in the Military Domain conference, the US Department of State released a “Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy” as the foundation for the establishment of international norms and standards for the development and use of military AI. The document includes twelve best practices that emphasize concepts such as safe and secure development, extensive testing, and human control and oversight, among others, that endorsing states should implement.\n\nThese principles and best practices as well as current laws, policies, and regulations provide a useful foundation for resolving critical questions about agency, such as:\n\nStill, as technologies, concepts, applications, and competitions evolve, new questions are likely to be raised. Old practices may need to be iteratively revisited to ensure that adoption efforts remain relevant, current, and appropriate. DOD efforts to maintain leadership at home and internationally in establishing AI and HMT ethics and safety guidelines should be viewed as a process to follow rather than an end state to be achieved.\n\nUnderstanding knock-on effects of HMT incorporation\n\nDOD adoption of HMT into military operations will elicit responses from competitors and lead to changing risks, competitions, opportunities, and doctrine. For example, the use of HMT-enabled UAS swarms could shift targeting priorities from forward-deployed machines to the human controllers and decision-makers situated well behind contested environments. Another example can be found in the use of an AI-enabled machine to patrol a contested border, which could reduce immediate risk to human life and, as a result, reduce risks of rapid escalation. However, immediate loss of life may not be the only escalation pathway perceived by an adversary. If destroying autonomous systems is lower stakes than firing on humans, how many downed UASs would the United States tolerate? Alternatively, what if the AI-enabled machine recommends or makes a bad decision that leads to an unprovoked loss of life in the adversary state?\n\nThe United States and its allies should intensify examination of these types of what-if scenarios associated with HMT adoption. First, to preempt arguments that DOD has not thought through the long-term implications of HMT employment, and then to determine the most efficacious concepts of use and prepare for possible future risks. A combination of iterative tabletop, seminar-style, and live war games and model-based simulations would be especially useful in identifying and preparing for longer-term implications of HMT. These exercises could then inform live testing of HMT concepts and capabilities.\n\nShaping the narrative around military applications of HMT\n\nMixed feelings and misperceptions about the DOD’s use of AI and uncrewed systems persist within the defense enterprise and the US polity and society more broadly. Despite an increase in the number of young personnel who are considered to be more intuitively inclined to technological adoption, pockets of stubbornness and contrarianism, and efforts to protect institutional equities, remain throughout the force. In addition, some social and political perspectives on HMT may be skewed by fears of fully autonomous weapons systems and singularities in which AI overcomes human control with devastating consequences. Identifying and managing the variety of strategic, operational, social, and philosophical concerns about accelerating HMT adoption will necessitate a coherent and consistent campaign to shape the narrative around military AI use and HMT. This narrative should stress:\n\nThe demonstrated and prospective advantages HMT will provide to warfighters and decision-makers, and the budgetary efficiencies that could be gained through deeper adoption of HMT;\n\nThe measures DOD is taking to ensure the safe and ethical development and use of AI and to build humans’ trust in machines; and\n\nThe centrality of human agency to human-machine teams.\n\nBack to top\n\nSummary of recommendations and conclusion\n\nHMT offers several advantages to twenty-first-century militaries. As such, the DOD must invest sufficient time and resources to address the challenges to adoption discussed above. Catalyzing HMT adoption will necessitate a combination of new ideas, procedures, and incentives, as well as intensification of promising ongoing adoption acceleration efforts, especially related to the following areas:\n\nThe United States’ AI strides are not occurring in a vacuum; if the Pentagon is slow to adopt HMT at scale, it risks conceding military edge to strategic competitors like China that view AI as a security imperative. Machines and AI agents are becoming ubiquitous across the twenty-first-century battlespace, and the onus is on DOD to demonstrate, communicate, and realize HMT’s value to achieving future missions and national objectives.\n\nBack to top\n\nAcknowledgements\n\nTo produce this report, the authors conducted a number of interviews and workshops. Listed below are some of the individuals consulted and whose insights informed this report. The analysis and recommendations presented here are those of the authors alone and do not necessarily represent the views of the individuals consulted. Moreover, the named individuals participated in a personal, not institutional, capacity.\n\nMaj Ezra Akin, USMC, technical PhD analyst, Commandant’s Office of Net Assessment\n\nSamuel Bendett, adjunct senior fellow, Technology and National Security Program, Center for a New American Security\n\nAugust Cole, nonresident senior fellow, Forward Defense, Scowcroft Center for Strategy and Security, Atlantic Council\n\nOwen J. Daniels, Andrew W. Marshall fellow, Center for Security and Emerging Technology, Georgetown University\n\nPhil Freidhoff, vice president for human centered design projects, 2Mi\n\nDr. Gerald F. Goodwin, senior research scientist, personnel sciences, US Army Research Institute for the Behavioral and Social Sciences\n\nDr. Neera Jain, associate professor, School of Mechanical Engineering, Purdue University\n\nLCDR Marek Jestrab, USN, senior US Navy fellow, Forward Defense, Scowcroft Center for Strategy and Security, Atlantic Council\n\nZak Kallenborn, policy fellow, Schar School of Policy and Government, George Mason University\n\nHarry Kemsley OBE, president, government and national security, Janes Group\n\nDr. Margarita Konaev, nonresident senior fellow, Forward Defense, Scowcroft Center for Strategy and Security, Atlantic Council\n\nJustin Lynch, nonresident senior fellow, Forward Defense, Scowcroft Center for Strategy and Security, Atlantic Council\n\nDr. Joseph Lyons, principal research psychologist, Air Force Research Laboratory\n\nBrig Gen Patrick Malackowski, USAF (ret.), director, F-16, conventional weapons, and total force, Lockheed Martin Corporation\n\nCol Michelle Melendez, USMC, senior US Marine Corps fellow, Forward Defense, Scowcroft Center for Strategy and Security, Atlantic Council\n\nRob Murray, nonresident senior fellow, Forward Defense, Scowcroft Center for Strategy and Security, Atlantic Council\n\nDr. Julie Obenauer-Motley, senior national security analyst, Johns Hopkins University Applied Physics Lab\n\nJohn T. Quinn II, head, futures branch, concepts and plans division, Marine Corps Warfighting Lab\n\nDr. Laura Steckman, program officer, trust and influence, Air Force Office of Scientific Research\n\nBack to top\n\nThis report was generously sponsored by Lockheed Martin Corporation. The report is written and published in accordance with the Atlantic Council Policy on Intellectual Independence. The authors are solely responsible for its analysis and recommendations. The Atlantic Council and its donors do not determine, nor do they necessarily endorse or advocate for, any of this report’s conclusions.\n\nAbout the authors"
    }
}