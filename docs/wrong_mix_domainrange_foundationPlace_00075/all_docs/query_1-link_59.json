{
    "id": "wrong_mix_domainrange_foundationPlace_00075_1",
    "rank": 59,
    "data": {
        "url": "https://www.usenix.org/conference/usenixsecurity23/fall-accepted-papers",
        "read_more_link": "",
        "language": "en",
        "title": "USENIX Security '23 Fall Accepted Papers",
        "top_image": "https://www.usenix.org/sites/default/files/sec23_banner_social_share_soldout_1200x630.png",
        "meta_img": "https://www.usenix.org/sites/default/files/sec23_banner_social_share_soldout_1200x630.png",
        "images": [
            "https://www.usenix.org/sites/default/files/styles/neat_conference_menu_logo/public/sec23_wordmark_stacked_yellow_soldout_400x164.png?itok=nM4vC5Pi",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/slides.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/video.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Akram Faqih",
            "Muslum Ozgur Ozmen",
            "Vireshwar Kumar",
            "Z. Berkay Celik",
            "Dongyan Xu",
            "Ning Zhang",
            "Manuela Veloso",
            "Dacheng Tao",
            "Roya Ensafi",
            "Khaled Serag"
        ],
        "publish_date": "2023-03-22T14:40:59-07:00",
        "summary": "",
        "meta_description": "USENIX Security brings together researchers, practitioners, system administrators, system programmers, and others to share and explore the latest advances in the security and privacy of computer systems and networks.",
        "meta_lang": "en",
        "meta_favicon": "https://www.usenix.org/sites/default/files/waves_favicon.ico",
        "meta_site_name": "USENIX",
        "canonical_link": "https://www.usenix.org/conference/usenixsecurity23/fall-accepted-papers",
        "text": "Employees Who Dont Accept the Time Security Takes Are Not Aware Enough: The CISO View of Human-Centred Security\n\nJonas Hielscher and Uta Menges, Ruhr University Bochum; Simon Parkin, TU Delft; Annette Kluge and M. Angela Sasse, Ruhr University Bochum\n\nIn larger organisations, the security controls and policies that protect employees are typically managed by a Chief Information Security Officer (CISO). In research, industry, and policy, there are increasing efforts to relate principles of human behaviour interventions and influence to the practice of the CISO, despite these being complex disciplines in their own right. Here we explore how well the concepts of human-centred security (HCS) have survived exposure to the needs of practice: in an action research approach we engaged with n=30 members of a Swiss-based community of CISOs in five workshop sessions over the course of 8 months, dedicated to discussing HCS. We coded and analysed over 25 hours of notes we took during the discussions. We found that CISOs far and foremost perceive HCS as what is available on the market, namely awareness and phishing simulations. While they regularly shift responsibility either to the management (by demanding more support) or to the employees (by blaming them) we see a lack of power but also silo-thinking that prevents CISOs from considering actual human behaviour and friction that security causes for employees. We conclude that industry best practices and the state-of-the-art in HCS research are not aligned.\n\nMillions of people are watching you: Understanding the Digital-Safety Needs and Practices of Creators\n\nPatrawat Samermit, Anna Turner, Patrick Gage Kelley, Tara Matthews, Vanessia Wu, Sunny Consolvo, and Kurt Thomas, Google\n\nOnline content creatorswho create and share their content on platforms such as Instagram, TikTok, Twitch, and YouTubeare uniquely at-risk of increased digital-safety threats due to their public prominence, the diverse social norms of wide-ranging audiences, and their access to audience members as a valuable resource. We interviewed 23 creators to understand their digital-safety experiences. This includes the security, privacy, and abuse threats they have experienced across multiple platforms and how the threats have changed over time. We also examined the protective practices they have employed to stay safer, including tensions in how they adopt the practices. We found that creators have diverse threat models that take into consideration their emotional, physical, relational, and financial safety. Most adopted protectionsincluding distancing from technology, moderating their communities, and seeking external or social supportonly after experiencing a serious safety incident. Lessons from their experiences help us better prepare and protect creators and ensure a diversity of voices are present online.\n\nSecurity is not my field, Im a stats guy: A Qualitative Root Cause Analysis of Barriers to Adversarial Machine Learning Defenses in Industry\n\nJaron Mink, University of Illinois at Urbana-Champaign; Harjot Kaur, Leibniz University Hannover; Juliane Schmser and Sascha Fahl, CISPA Helmholtz Center for Information Security; Yasemin Acar, Paderborn University and George Washington University\n\nAdversarial machine learning (AML) has the potential to leak training data, force arbitrary classifications, and greatly degrade overall performance of machine learning models, all of which academics and companies alike consider as serious issues. Despite this, seminal work has found that most organizations insufficiently protect against such threats. While the lack of defenses to AML is most commonly attributed to missing knowledge, it is unknown why mitigations are unrealized in industry projects. To better understand the reasons behind the lack of deployed AML defenses, we conduct semi-structured interviews (n=21) with data scientists and data engineers to explore what barriers impede the effective implementation of such defenses. We find that practitioners ability to deploy defenses is hampered by three primary factors: a lack of institutional motivation and educational resources for these concepts, an inability to adequately assess their AML risk and make subsequent decisions, and organizational structures and goals that discourage implementation in favor of other objectives. We conclude by discussing practical recommendations for companies and practitioners to be made more aware of these risks, and better prepared to respond.\n\nA Data-free Backdoor Injection Approach in Neural Networks\n\nPeizhuo Lv, Chang Yue, Ruigang Liang, and Yunfei Yang, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; Shengzhi Zhang, Department of Computer Science, Metropolitan College, Boston University, USA; Hualong Ma, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; Kai Chen, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; Beijing Academy of Artificial Intelligence, China\n\nRecently, the backdoor attack on deep neural networks (DNNs) has been extensively studied, which causes the backdoored models to behave well on benign samples, whereas performing maliciously on controlled samples (with triggers attached). Almost all existing backdoor attacks require access to the original training/testing dataset or data relevant to the main task to inject backdoors into the target models, which is unrealistic in many scenarios, e.g., private training data. In this paper, we propose a novel backdoor injection approach in a \"data-free\" manner. We collect substitute data irrelevant to the main task and reduce its volume by filtering out redundant samples to improve the efficiency of backdoor injection. We design a novel loss function for fine-tuning the original model into the backdoored one using the substitute data, and optimize the fine-tuning to balance the backdoor injection and the performance on the main task. We conduct extensive experiments on various deep learning scenarios, e.g., image classification, text classification, tabular classification, image generation, and multimodal, using different models, e.g., Convolutional Neural Networks (CNNs), Autoencoders, Transformer models, Tabular models, as well as Multimodal DNNs. The evaluation results demonstrate that our data-free backdoor injection approach can efficiently embed backdoors with a nearly 100\\% attack success rate, incurring an acceptable performance downgrade on the main task.\n\nA Large Scale Study of the Ethereum Arbitrage Ecosystem\n\nRobert McLaughlin, Christopher Kruegel, and Giovanni Vigna, University of California, Santa Barbara\n\nThe Ethereum blockchain rapidly became the epicenter of a complex financial ecosystem, powered by decentralized exchanges (DEXs). These exchanges form a diverse capital market where anyone can swap one type of token for another. Arbitrage trades are a normal and expected phenomenon in free capital markets, and, indeed, several recent works identify these transactions on decentralized exchanges.\n\nUnfortunately, existing studies leave significant knowledge gaps in our understanding of the system as a whole, which hinders research into the security, stability, and economic impacts of arbitrage. To address this issue, we perform two large-scale measurements over a 28-month period. First, we design a novel arbitrage identification strategy capable of analyzing over 10x more DEX applications than prior work. This uncovers 3.8 million arbitrages, which yield a total of $321 million in profit. Second, we design a novel arbitrage opportunity detection system, which is the first to support modern complex price models at scale. This system identifies 4 billion opportunities and would generate a weekly profit of 395 Ether (approximately $500,000, at the time of writing). We observe two key insights that demonstrate the usefulness of these measurements: (1) an increasing percentage of revenue is paid to the miners, which threatens consensus stability, and (2) arbitrage opportunities occasionally persist for several blocks, which implies that price-oracle manipulation attacks may be less costly than expected.\n\nA Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots\n\nBoyang Zhang and Xinlei He, CISPA Helmholtz Center for Information Security; Yun Shen, NetApp; Tianhao Wang, University of Virginia; Yang Zhang, CISPA Helmholtz Center for Information Security\n\nBuilding advanced machine learning (ML) models requires expert knowledge and many trials to discover the best architecture and hyperparameter settings. Previous work demonstrates that model information can be leveraged to assist other attacks, such as membership inference, generating adversarial examples. Therefore, such information, e.g., hyperparameters, should be kept confidential. It is well known that an adversary can leverage a target ML model's output to steal the model's information. In this paper, we discover a new side channel for model information stealing attacks, i.e., models' scientific plots which are extensively used to demonstrate model performance and are easily accessible. Our attack is simple and straightforward. We leverage the shadow model training techniques to generate training data for the attack model which is essentially an image classifier. Extensive evaluation on three benchmark datasets shows that our proposed attack can effectively infer the architecture/hyperparameters of image classifiers based on convolutional neural network (CNN) given the scientific plot generated from it. We also reveal that the attack's success is mainly caused by the shape of the scientific plots, and further demonstrate that the attacks are robust in various scenarios. Given the simplicity and effectiveness of the attack method, our study indicates scientific plots indeed constitute a valid side channel for model information stealing attacks. To mitigate the attacks, we propose several defense mechanisms that can reduce the original attacks' accuracy while maintaining the plot utility. However, such defenses can still be bypassed by adaptive attacks.\n\nAbuse Vectors: A Framework for Conceptualizing IoT-Enabled Interpersonal Abuse\n\nSophie Stephenson and Majed Almansoori, University of Wisconsin--Madison; Pardis Emami-Naeini, Duke University; Danny Yuxing Huang, New York University; Rahul Chatterjee, University of Wisconsin--Madison\n\nTech-enabled interpersonal abuse (IPA) is a pervasive problem. Abusers, often intimate partners, use tools such as spyware to surveil and harass victim-survivors. Unfortunately, anecdotal evidence suggests that smart, Internet-connected devices such as home thermostats, cameras, and Bluetooth item finders may similarly be used against victim-survivors of IPA. To tackle abuse involving smart devices, it is vital that we understand the ecosystem of smart devices that enable IPA. Thus, in this work, we conduct a large-scale qualitative analysis of the smart devices used in IPA. We systematically crawl Google Search results to uncover web pages discussing how abusers use smart devices to enact IPA. By analyzing these web pages, we identify 32 devices used for IPA and detail the varied strategies abusers use for spying and harassment via these devices. Then, we design a simple, yet powerful frameworkabuse vectorswhich conceptualizes IoT-enabled IPA as four overarching patterns: Covert Spying, Unauthorized Access, Repurposing, and Intended Use. Using this lens, we pinpoint the necessary solutions required to address each vector of IoT abuse and encourage the security community to take action.\n\nACon^2: Adaptive Conformal Consensus for Provable Blockchain Oracles\n\nSangdon Park, Georgia Institute of Technology; Osbert Bastani, University of Pennsylvania; Taesoo Kim, Georgia Institute of Technology\n\nBlockchains with smart contracts are distributed ledger systems that achieve block-state consistency among distributed nodes by only allowing deterministic operations of smart contracts. However, the power of smart contracts is enabled by interacting with stochastic off-chain data, which in turn opens the possibility to undermine the block-state consistency. To address this issue, an oracle smart contract is used to provide a single consistent source of external data; but, simultaneously, this introduces a single point of failure, which is called the oracle problem. To address the oracle problem, we propose an adaptive conformal consensus (ACon2) algorithm that derives a consensus set of data from multiple oracle contracts via the recent advance in online uncertainty quantification learning. Interesting, the consensus set provides a desired correctness guarantee under distribution shift and Byzantine adversaries. We demonstrate the efficacy of the proposed algorithm on two price datasets and an Ethereum case study. In particular, the Solidity implementation of the proposed algorithm shows the potential practicality of the proposed algorithm, implying that online machine learning algorithms are applicable to address security issues in blockchains.\n\nAdversarial Training for Raw-Binary Malware Classifiers\n\nKeane Lucas, Samruddhi Pai, Weiran Lin, and Lujo Bauer, Carnegie Mellon University; Michael K. Reiter, Duke University; Mahmood Sharif, Tel Aviv University\n\nMachine learning (ML) models have shown promise in classifying raw executable files (binaries) as malicious or benign with high accuracy. This has led to the increasing influence of ML-based classification methods in academic and real-world malware detection, a critical tool in cybersecurity. However, previous work provoked caution by creating variants of malicious binaries, referred to as adversarial examples, that are transformed in a functionality-preserving way to evade detection. In this work, we investigate the effectiveness of using adversarial training methods to create malware classification models that are more robust to some state-of-the-art attacks. To train our most robust models, we significantly increase the efficiency and scale of creating adversarial examples to make adversarial training practical, which has not been done before in raw-binary malware detectors. We then analyze the effects of varying the length of adversarial training, as well as analyze the effects of training with various types of attacks. We find that data augmentation does not deter state-of-the-art attacks, but that using a generic gradient-guided method, used in other discrete domains, does improve robustness. We also show that in most cases, models can be made more robust to malware-domain attacks by adversarially training them with lower-effort versions of the same attack. In the best case, we reduce one state-of-the-art attack's success rate from 90% to 5%. We also find that training with some types of attacks can increase robustness to other types of attacks. Finally, we discuss insights gained from our results, and how they can be used to more effectively train robust malware detectors.\n\nAegis: Mitigating Targeted Bit-flip Attacks against Deep Neural Networks\n\nJialai Wang, Tsinghua University; Ziyuan Zhang, Beijing University of Posts and Telecommunications; Meiqi Wang, Tsinghua University; Han Qiu, Tsinghua University and Zhongguancun Laboratory; Tianwei Zhang, Nanyang Technological University; Qi Li, Tsinghua University and Zhongguancun Laboratory; Zongpeng Li, Tsinghua University and Hangzhou Dianzi University; Tao Wei, Ant Group; Chao Zhang, Tsinghua University and Zhongguancun Laboratory\n\nBit-flip attacks (BFAs) have attracted substantial attention recently, in which an adversary could tamper with a small number of model parameter bits to break the integrity of DNNs. To mitigate such threats, a batch of defense methods are proposed, focusing on the untargeted scenarios. Unfortunately, they either require extra trustworthy applications or make models more vulnerable to targeted BFAs. Countermeasures against targeted BFAs, stealthier and more purposeful by nature, are far from well established.\n\nIn this work, we propose Aegis, a novel defense method to mitigate targeted BFAs. The core observation is that existing targeted attacks focus on flipping critical bits in certain important layers. Thus, we design a dynamic-exit mechanism to attach extra internal classifiers (ICs) to hidden layers. This mechanism enables input samples to early-exit from different layers, which effectively upsets the adversary's attack plans. Moreover, the dynamic-exit mechanism randomly selects ICs for predictions during each inference to significantly increase the attack cost for the adaptive attacks where all defense mechanisms are transparent to the adversary. We further propose a robustness training strategy to adapt ICs to the attack scenarios through simulating BFAs during the IC training phase, to increase model robustness. Extensive evaluations over four well-known datasets and two popular DNN structures reveal that Aegis could effectively mitigate different state-of-the-art targeted attacks, reducing attack success rate by 5-10x, significantly outperforming existing defense methods. We open source the code of Aegis.\n\nAIRS: Explanation for Deep Reinforcement Learning based Security Applications\n\nJiahao Yu, Northwestern University; Wenbo Guo, Purdue University; Qi Qin, ShanghaiTech University; Gang Wang, University of Illinois at Urbana-Champaign; Ting Wang, The Pennsylvania State University; Xinyu Xing, Northwestern University\n\nRecently, we have witnessed the success of deep reinforcement learning (DRL) in many security applications, ranging from malware mutation to selfish blockchain mining. Like all other machine learning methods, the lack of explainability has been limiting its broad adoption as users have difficulty establishing trust in DRL models' decisions. Over the past years, different methods have been proposed to explain DRL models but unfortunately, they are often not suitable for security applications, in which explanation fidelity, efficiency, and the capability of model debugging are largely lacking.\n\nIn this work, we propose AIRS, a general framework to explain deep reinforcement learning-based security applications. Unlike previous works that pinpoint important features to the agent's current action, our explanation is at the step level. It models the relationship between the final reward and the key steps that a DRL agent takes, and thus outputs the steps that are most critical towards the final reward the agent has gathered. Using four representative security-critical applications, we evaluate AIRS from the perspectives of explainability, fidelity, stability, and efficiency. We show that AIRS could outperform alternative explainable DRL methods. We also showcase AIRS's utility, demonstrating that our explanation could facilitate the DRL model's failure offset, help users establish trust in a model decision, and even assist the identification of inappropriate reward designs.\n\nAn Input-Agnostic Hierarchical Deep Learning Framework for Traffic Fingerprinting\n\nJian Qu, Xiaobo Ma, and Jianfeng Li, Xian Jiaotong University; Xiapu Luo, The Hong Kong Polytechnic University; Lei Xue, Sun Yat-sen University; Junjie Zhang, Wright State University; Zhenhua Li, Tsinghua University; Li Feng, Southwest Jiaotong University; Xiaohong Guan, Xi'an Jiaotong University\n\nDeep learning has proven to be promising for traffic fingerprinting that explores features of packet timing and sizes. Although well-known for automatic feature extraction, it is faced with a gap between the heterogeneousness of the traffic (i.e., raw packet timing and sizes) and the homogeneousness of the required input (i.e., input-specific). To address this gap, we design an input-agnostic hierarchical deep learning framework for traffic fingerprinting that can hierarchically abstract comprehensive heterogeneous traffic features into homogeneous vectors seamlessly digestible by existing neural networks for further classification. The extensive evaluation demonstrates that our framework, with just one paradigm, not only supports heterogeneous traffic input but also achieves better or comparable performance compared to state-of-the-art methods black across a wide range of traffic fingerprinting tasks.\n\nAraa: Discovering and Characterizing Password Guessing Attacks in Practice\n\nMazharul Islam, University of WisconsinMadison; Marina Sanusi Bohuk, Cornell Tech; Paul Chung, University of WisconsinMadison; Thomas Ristenpart, Cornell Tech; Rahul Chatterjee, University of WisconsinMadison\n\nRemote password guessing attacks remain one of the largest sources of account compromise. Understanding and characterizing attacker strategies is critical to improving security but doing so has been challenging thus far due to the sensitivity of login services and the lack of ground truth labels for benign and malicious login requests. We perform an in-depth measurement study of guessing attacks targeting two large universities. Using a rich dataset of more than 34 million login requests to the two universities as well as thousands of compromise reports, we were able to develop a new analysis pipeline to identify 29 attack clustersmany of which involved compromises not previously known to security engineers. Our analysis provides the richest investigation to date of password guessing attacks as seen from login services. We believe our tooling will be useful in future efforts to develop real-time detection of attack campaigns, and our characterization of attack campaigns can help more broadly guide mitigation design.\n\nARGUS: Context-Based Detection of Stealthy IoT Infiltration Attacks\n\nPhillip Rieger, Marco Chilese, Reham Mohamed, Markus Miettinen, Hossein Fereidooni, and Ahmad-Reza Sadeghi, Technical University of Darmstadt\n\nIoT application domains, device diversity and connectivity are rapidly growing. IoT devices control various functions in smart homes and buildings, smart cities, and smart factories, making these devices an attractive target for attackers. On the other hand, the large variability of different application scenarios and inherent heterogeneity of devices make it very challenging to reliably detect abnormal IoT device behaviors and distinguish these from benign behaviors. Existing approaches for detecting attacks are mostly limited to attacks directly compromising individual IoT devices, or, require predefined detection policies. They cannot detect attacks that utilize the control plane of the IoT system to trigger actions in an unintended/malicious context, e.g., opening a smart lock while the smart home residents are absent.\n\nIn this paper, we tackle this problem and propose ARGUS, the first self-learning intrusion detection system for detecting contextual attacks on IoT environments, in which the attacker maliciously invokes IoT device actions to reach its goals. ARGUS monitors the contextual setting based on the state and actions of IoT devices in the environment. An unsupervised Deep Neural Network (DNN) is used for modeling the typical contextual device behavior and detecting actions taking place in abnormal contextual settings. This unsupervised approach ensures that ARGUS is not restricted to detecting previously known attacks but is also able to detect new attacks. We evaluated ARGUS on heterogeneous real-world smart-home settings and achieve at least an F1-Score of 99.64% for each setup, with a false positive rate (FPR) of at most 0.03%.\n\nARI: Attestation of Real-time Mission Execution Integrity\n\nJinwen Wang, Yujie Wang, and Ao Li, Washington University in St. Louis; Yang Xiao, University of Kentucky; Ruide Zhang, Wenjing Lou, and Y. Thomas Hou, Virginia Polytechnic Institute and State University; Ning Zhang, Washington University in St. Louis\n\nWith the proliferation of autonomous safety-critical cyber-physical systems (CPS) in our daily life, their security is becoming ever more important. Remote attestation is a powerful mechanism to enable remote verification of system integrity. While recent developments have made it possible to efficiently attest IoT operations, autonomous systems that are built on top of real-time cyber-physical control loops and execute missions independently present new unique challenges.\n\nIn this paper, we formulate a new security property, Real-time Mission Execution Integrity (RMEI) to provide proof of correct and timely execution of the missions. While it is an attractive property, measuring it can incur prohibitive overhead for the real-time autonomous system. To tackle this challenge, we propose policy-based attestation of compartments to enable a trade-off between the level of details in measurement and runtime overhead. To further minimize the impact on real-time responsiveness, multiple techniques were developed to improve the performance, including customized software instrumentation and timing recovery through re-execution. We implemented a prototype of ARI and evaluated its performance on five CPS platforms. A user study involving 21 developers with different skill sets was conducted to understand the usability of our solution.\n\nARMore: Pushing Love Back Into Binaries\n\nLuca Di Bartolomeo, Hossein Moghaddas, and Mathias Payer, EPFL\n\nStatic rewriting enables late-state code changes (e.g., to add mitigations, to remove unnecessary code, or to instrument for code coverage) at low overhead in security-critical environments. Most research on static rewriting has so far focused on the x86 architecture. However, the prevalence and proliferation of ARM-based devices along with a large amount of personal data (e.g., health and sensor data) that they process calls for efficient introspection and analysis capabilities on the ARM platform. Addressing the unique challenges on aarch64, we introduce ARMore, the first efficient, robust, and heuristic-free static binary rewriter for arbitrary aarch64 binaries that produces reassembleable assembly. The key improvements introduced by ARMore make the recovery of indirect control flow an option rather than a necessity. Instead of crashing, the cost of an uncovered target only causes the small overhead of an additional branch. ARMore can rewrite binaries from different languages and compilers (even arbitrary hand-written assembly), both on PIC and non-PIC code, with or without symbols, including exception handling for C++ and Go binaries, and also including binaries with mixed data and text. ARMore is sound as it does not rely on any assumptions about the input binary. ARMore is also efficient: it does not employ any expensive dynamic translation techniques, incurring negligible overhead (<1% in our evaluated benchmarks). Our AFL++ coverage instrumentation pass enables fuzzing of closed-source aarch64 binaries at three times the speed compared to the state-of-the-art (AFL-QEMU), and we found 58 unique crashes in closed-source software. ARMore is the only static rewriter whose rewritten binaries correctly pass all SQLite3 and coreutils test cases and autopkgtest of 97.5% Debian packages.\n\nAttacks are Forwarded: Breaking the Isolation of MicroVM-based Containers Through Operation Forwarding\n\nJietao Xiao and Nanzi Yang, State Key Lab of ISN, School of Cyber Engineering, Xidian University, China; Wenbo Shen, Zhejiang University, China; Jinku Li and Xin Guo, State Key Lab of ISN, School of Cyber Engineering, Xidian University, China; Zhiqiang Dong and Fei Xie, Tencent Security Yunding Lab, China; Jianfeng Ma, State Key Lab of ISN, School of Cyber Engineering, Xidian University, China\n\nPeople proposed to use virtualization techniques to reinforce the isolation between containers. In the design, each container runs inside a lightweight virtual machine (called microVM). MicroVM-based containers benefit from both the security of microVM and the high efficiency of the container, and thus are widely used on the public cloud.\n\nHowever, in this paper, we demonstrate a new attack surface that can be exploited to break the isolation of the microVM-based container, called operation forwarding attacks. Our key observation is that certain operations of the microVM-based container are forwarded to host system calls and host kernel functions. The attacker can leverage the operation forwarding to exploit the host kernels vulnerabilities and exhaust host resources. To fully understand the security risk of operation forwarding attacks, we divide the components of the microVM-based container into three layers according to their functionalities and present corresponding attacking strategies to exploit the operation forwarding of each layer. Moreover, we design eight attacks against Kata Containers and Firecracker-based containers and conduct experiments on the local environment, AWS, and Alibaba Cloud. Our results show that the attacker can trigger potential privilege escalation, downgrade 93.4% IO performance and 75.0% CPU performance of the victim container, and even crash the host. We further give security suggestions for mitigating these attacks.\n\nAURC: Detecting Errors in Program Code and Documentation\n\nPeiwei Hu, Ruigang Liang, and Ying Cao, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China, and School of Cyber Security, University of Chinese Academy of Sciences, China; Kai Chen, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China, and Beijing Academy of Artificial Intelligence, China; Runze Zhang, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China, and School of Cyber Security, University of Chinese Academy of Sciences, China\n\nError detection in program code and documentation is a critical problem in computer security. Previous studies have shown promising vulnerability discovery performance by extensive code or document-guided analysis. However, the state-of-the-arts have the following significant limitations: (i) They assume the documents are correct and treat the code that violates documents as bugs, thus cannot find documents defects and codes bugs if APIs have defective documents or no documents. (ii) They utilize majority voting to judge the inconsistent code snippets and treat the deviants as bugs, thus cannot cope with situations where correct usage is minor or all use cases are wrong.\n\nIn this paper, we present AURC, a static framework for detecting code bugs of incorrect return checks and document defects. We observe that three objects participate in the API invocation, the document, the caller (code that invokes API), and the callee (the source code of API). Mutual corroboration of these three objects eliminates the reliance on the above assumptions. AURC contains a context-sensitive backward analysis to process callees, a pre-trained model-based document classifier, and a container that collects conditions of if statements from callers. After cross-checking the results from callees, callers, and documents, AURC delivers them to the correctness inference module to infer the defective one. We evaluated AURC on ten popular codebases. AURC discovered 529 new bugs that can lead to security issues like heap buffer overflow and sensitive information leakage, and 224 new document defects. Maintainers acknowledge our findings and have accepted 222 code patches and 76 document patches.\n\nAuthenticated private information retrieval\n\nSimone Colombo, EPFL; Kirill Nikitin, Cornell Tech; Henry Corrigan-Gibbs, MIT; David J. Wu, UT Austin; Bryan Ford, EPFL\n\nThis paper introduces protocols for authenticated private information retrieval. These schemes enable a client to fetch a record from a remote database server such that (a) the server does not learn which record the client reads, and (b) the client either obtains the \"authentic\" record or detects server misbehavior and safely aborts. Both properties are crucial for many applications. Standard private-information-retrieval schemes either do not ensure this form of output authenticity, or they require multiple database replicas with an honest majority. In contrast, we offer multi-server schemes that protect security as long as at least one server is honest. Moreover, if the client can obtain a short digest of the database out of band, then our schemes require only a single server. Performing an authenticated private PGP-public-key lookup on an OpenPGP key server's database of 3.5 million keys (3 GiB), using two non-colluding servers, takes under 1.2 core-seconds of computation, essentially matching the time taken by unauthenticated private information retrieval. Our authenticated single-server schemes are 30-100 more costly than state-of-the-art unauthenticated single-server schemes, though they achieve incomparably stronger integrity properties.\n\nAutoFR: Automated Filter Rule Generation for Adblocking\n\nHieu Le, Salma Elmalaki, and Athina Markopoulou, University of California, Irvine; Zubair Shafiq, University of California, Davis\n\nAdblocking relies on filter lists, which are manually curated and maintained by a community of filter list authors. Filter list curation is a laborious process that does not scale well to a large number of sites or over time. In this paper, we introduce AutoFR, a reinforcement learning framework to fully automate the process of filter rule creation and evaluation for sites of interest. We design an algorithm based on multi-arm bandits to generate filter rules that block ads while controlling the trade-off between blocking ads and avoiding visual breakage. We test AutoFR on thousands of sites and we show that it is efficient: it takes only a few minutes to generate filter rules for a site of interest. AutoFR is effective: it generates filter rules that can block 86% of the ads, as compared to 87% by EasyList, while achieving comparable visual breakage. Furthermore, AutoFR generates filter rules that generalize well to new sites. We envision that AutoFR can assist the adblocking community in filter rule generation at scale.\n\nautofz: Automated Fuzzer Composition at Runtime\n\nYu-Fu Fu, Jaehyuk Lee, and Taesoo Kim, Georgia Institute of Technology\n\nFuzzing has gained in popularity for software vulnerability detection by virtue of the tremendous effort to develop a diverse set of fuzzers. Thanks to various fuzzing techniques, most of the fuzzers have been able to demonstrate great performance on their selected targets. However, paradoxically, this diversity in fuzzers also made it difficult to select fuzzers that are best suitable for complex real-world programs, which we call selection burden. Communities attempted to address this problem by creating a set of standard benchmarks to compare and contrast the performance of fuzzers for a wide range of applications, but the result was always a suboptimal decisionthe best-performing fuzzer on average does not guarantee the best outcome for the target of a user's interest.\n\nTo overcome this problem, we propose an automated, yet non-intrusive meta-fuzzer, called autofz, to maximize the benefits of existing state-of-the-art fuzzers via dynamic composition. To an end user, this means that, instead of spending time on selecting which fuzzer to adopt (similar in concept to hyperparameter tuning in ML), one can simply put all of the available fuzzers to autofz (similar in concept to AutoML), and achieve the best, optimal result. The key idea is to monitor the runtime progress of the fuzzers, called trends (similar in concept to gradient descent), and make a fine-grained adjustment of resource allocation (e.g., CPU time) of each fuzzer. This is a stark contrast to existing approaches that statically combine a set of fuzzers, or via exhaustive pre-training per target program - autofz deduces a suitable set of fuzzers of the active workload in a fine-grained manner at runtime. Our evaluation shows that, given the same amount of computation resources, autofz outperforms any best-performing individual fuzzers in 11 out of 12 available benchmarks and beats the best, collaborative fuzzing approaches in 19 out of 20 benchmarks without any prior knowledge in terms of coverage. Moreover, on average, autofz found 152% more bugs than individual fuzzers on UNIFUZZ and FTS, and 415% more bugs than collaborative fuzzing on UNIFUZZ.\n\nAutomated Cookie Notice Analysis and Enforcement\n\nRishabh Khandelwal and Asmit Nayak, University of WisconsinMadison; Hamza Harkous, Google, Inc.; Kassem Fawaz, University of WisconsinMadison\n\nOnline websites use cookie notices to elicit consent from the users, as required by recent privacy regulations like the GDPR and the CCPA. Prior work has shown that these notices are designed in a way to manipulate users into making website-friendly choices which put users' privacy at risk. In this work, we present CookieEnforcer, a new system for automatically discovering cookie notices and extracting a set of instructions that result in disabling all non-essential cookies. In order to achieve this, we first build an automatic cookie notice detector that utilizes the rendering pattern of the HTML elements to identify the cookie notices. Next, we analyze the cookie notices and predict the set of actions required to disable all unnecessary cookies. This is done by modeling the problem as a sequence-to-sequence task, where the input is a machine-readable cookie notice and the output is the set of clicks to make. We demonstrate the efficacy of CookieEnforcer via an end-to-end accuracy evaluation, showing that it can generate the required steps in 91% of the cases. Via a user study, we also show that CookieEnforcer can significantly reduce the user effort. Finally, we characterize the behavior of CookieEnforcer on the top 100k websites from the Tranco list, showcasing its stability and scalability.\n\nAutomated Exploitable Heap Layout Generation for Heap Overflows Through Manipulation Distance-Guided Fuzzing\n\nBin Zhang, Jiongyi Chen, Runhao Li, Chao Feng, Ruilin Li, and Chaojing Tang, National University of Defense Technology\n\nGenerating exploitable heap layouts is a fundamental step to produce working exploits for heap overflows. For this purpose, the heap primitives identified from the target program, serving as functional units to manipulate the heap layout, are strategically leveraged to construct exploitable states. To flexibly use primitives, prior efforts only focus on particular program types or programs with dispatcher-loop structures. Beyond that, automatically generating exploitable heap layouts is hard for general-purpose programs due to the difficulties in explicitly and flexibly using primitives.\n\nThis paper presents Scatter, enabling the generation of exploitable heap layouts for heap overflows in general-purpose programs in a primitive-free manner. At the center of Scatter is a fuzzer that is guided by a new manipulation distance which measures the distance to the corruption of a victim object in the heap layout space. To make the fuzzing-based approach practical, Scatter leverages a set of techniques to improve the efficiency and handle the side effects introduced by the heap manager's sophisticated behaviors in the real-world environment. Our evaluation demonstrates that Scatter can successfully generate a total of 126 exploitable heap layouts for 18 out of 27 heap overflows in 10 general-purpose programs.\n\nBalanceProofs: Maintainable Vector Commitments with Fast Aggregation\n\nWeijie Wang, Annie Ulichney, and Charalampos Papamanthou, Yale University\n\nWe present BalanceProofs, the first vector commitment that is maintainable (i.e., supporting sublinear updates) while also enjoying fast proof aggregation and verification. The basic version of BalanceProofs has O(nlogn) update time and O(n) query time and its constant-size aggregated proofs can be produced and verified in milliseconds. In particular, BalanceProofs improves the aggregation time and aggregation verification time of the only known maintainable and aggregatable vector commitment scheme, Hyperproofs (USENIX SECURITY 2022), by up to 1000 and up to 100 respectively. Fast verification of aggregated proofs is particularly useful for applications such as stateless cryptocurrencies (and was a major bottleneck for Hyperproofs), where an aggregated proof of balances is produced once but must be verified multiple times and by a large number of nodes. As a limitation, the updating time in BalanceProofs compared to Hyperproofs is roughly 6 slower, but always stays in the range from 10 to 18 milliseconds. We finally study useful tradeoffs in BalanceProofs between (aggregate) proof size, update time and (aggregate) proof computation and verification, by introducing a bucketing technique, and present an extensive evaluation as well as a comparison to Hyperproofs.\n\nBilingual Problems: Studying the Security Risks Incurred by Native Extensions in Scripting Languages\n\nCristian-Alexandru Staicu, CISPA Helmholtz Center for Information Security; Sazzadur Rahaman, University of Arizona; gnes Kiss and Michael Backes, CISPA Helmholtz Center for Information Security\n\nScripting languages are continuously gaining popularity due to their ease of use and the flourishing software ecosystems surrounding them. These languages offer crash and memory safety by design. Thus, developers do not need to understand and prevent low-level security issues like the ones plaguing the C code. However, scripting languages often allow native extensions, a way for custom C/C++ code to be invoked directly from the high-level language. While this feature promises several benefits, such as increased performance or the reuse of legacy code, it can also break the languages guarantees, e.g., crash safety.\n\nIn this work, we first provide a comparative analysis of the security risks of native extension APIs in three popular scripting languages. Additionally, we discuss a novel methodology for studying the misuse of the native extension API. We then perform an in-depth study of npm, an ecosystem that is most exposed to threats introduced by native extensions. We show that vulnerabilities in extensions can be exploited in their embedding library by producing reads of uninitialized memory, hard crashes, or memory leaks in 33 npm packages simply by invoking their API with well-crafted inputs. Moreover, we identify six open-source web applications in which a weak adversary can deploy such exploits remotely. Finally, we were assigned seven security advisories for the work presented in this paper, most labeled as high severity.\n\nBlack-box Adversarial Example Attack towards FCG Based Android Malware Detection under Incomplete Feature Information\n\nHeng Li, Huazhong University of Science and Technology; Zhang Cheng, NSFOCUS Technologies Group Co., Ltd. and Huazhong University of Science and Technology; Bang Wu, Liheng Yuan, Cuiying Gao, and Wei Yuan, Huazhong University of Science and Technology; Xiapu Luo, The Hong Kong Polytechnic University\n\nThe function call graph (FCG) based Android malware detection methods have recently attracted increasing attention due to their promising performance. However, these methods are susceptible to adversarial examples (AEs). In this paper, we design a novel black-box AE attack towards the FCG based malware detection system, called BagAmmo. To mislead its target system, BagAmmo purposefully perturbs the FCG feature of malware through inserting \"never-executed\" function calls into malware code. The main challenges are two-fold. First, the malware functionality should not be changed by adversarial perturbation. Second, the information of the target system (e.g., the graph feature granularity and the output probabilities) is absent.\n\nTo preserve malware functionality, BagAmmo employs the try-catch trap to insert function calls to perturb the FCG of malware. Without the knowledge about feature granularity and output probabilities, BagAmmo adopts the architecture of generative adversarial network (GAN), and leverages a multi-population co-evolution algorithm (i.e., Apoem) to generate the desired perturbation. Every population in Apoem represents a possible feature granularity, and the real feature granularity can be achieved when Apoem converges.\n\nThrough extensive experiments on over 44k Android apps and 32 target models, we evaluate the effectiveness, efficiency and resilience of BagAmmo. BagAmmo achieves an average attack success rate of over 99.9% on MaMaDroid, APIGraph and GCN, and still performs well in the scenario of concept drift and data imbalance. Moreover, BagAmmo outperforms the state-of-the-art attack SRL in attack success rate.\n\nBleem: Packet Sequence Oriented Fuzzing for Protocol Implementations\n\nZhengxiong Luo, Junze Yu, Feilong Zuo, Jianzhong Liu, and Yu Jiang, Tsinghua University; Ting Chen, University of Electronic Science and Technology of China; Abhik Roychoudhury, National University of Singapore; Jiaguang Sun, Tsinghua University\n\nProtocol implementations are essential components in network infrastructures. Flaws hidden in the implementations can easily render devices vulnerable to adversaries. Therefore, guaranteeing their correctness is important. However, commonly used vulnerability detection techniques, such as fuzz testing, face increasing challenges in testing these implementations due to ineffective feedback mechanisms and insufficient protocol state-space exploration techniques.\n\nThis paper presents Bleem, a packet-sequence-oriented black-box fuzzer for vulnerability detection of protocol implementations. Instead of focusing on individual packet generation, Bleem generates packets on a sequence level. It provides an effective feedback mechanism by analyzing the system output sequence noninvasively, supports guided fuzzing by resorting to state-space tracking that encompasses all parties timely, and utilizes interactive trafc information to generate protocol-logic-aware packet sequences. We evaluate Bleem on 15 widely-used implementations of well-known protocols (e.g., TLS and QUIC). Results show that, compared to the state-of-the-art protocol fuzzers such as Peach, Bleem achieves substantially higher branch coverage (up to 174.93% improvement) within 24 hours. Furthermore, Bleem exposed 15 security-critical vulnerabilities in prominent protocol implementations, with 10 CVEs assigned.\n\nBoKASAN: Binary-only Kernel Address Sanitizer for Effective Kernel Fuzzing\n\nMingi Cho, Dohyeon An, Hoyong Jin, and Taekyoung Kwon, Yonsei University\n\nKernel Address Sanitizer (KASAN), an invaluable tool for finding use-after-free and out-of-bounds bugs in the Linux kernel, needs the kernel source for compile-time instrumentation. To apply KASAN to closed-source systems, we should develop a binary-only KASAN, which is challenging. A technique that uses binary rewriting and processor support to run KASAN for binary modules needs a KASAN-applied kernel, thereby still the kernel source. Dynamic instrumentation offers an alternative way to it but greatly increases the performance overhead, rendering the kernel fuzzing impractical.\n\nTo address these problems, we present the first practical, binary-only KASAN named BoKASAN, which conducts address sanitization through dynamic instrumentation for the entire kernel binaries efficiently. Our key idea is selective sanitization, which identifies target processes to sanitize and hooks the page fault mechanism for significantly reducing the performance overhead of dynamic instrumentation. Our key insight is that the kernel bugs are most relevant to the processes created by a fuzzer. Thus, BoKASAN deliberately sanitizes the target memory regions related to these processes and leaves the remains unsanitized for effective kernel fuzzing.\n\nOur evaluation results show that BoKASAN is practical on closed-source systems, achieving the compiler-level performance of KASAN even on binary-only kernels and modules. Compared to KASAN on the Linux kernel, BoKASAN detected slightly more bugs in the Janus dataset and slightly fewer bugs in the Syzkaller/SyzVegas dataset; and BoKASAN found the same number of unique bugs in the 5-day fuzzing and executed the similar number of basic blocks. For binary modules on the Windows kernel and the Linux kernel, resp., BoKASAN was effective in finding bugs. An ablation result shows that selective sanitization affected these outcomes.\n\nBug Hunters Perspectives on the Challenges and Benefits of the Bug Bounty Ecosystem\n\nOmer Akgul, University of Maryland; Taha Eghtesad, Pennsylvania State University; Amit Elazari, University of California, Berkeley; Omprakash Gnawali, University of Houston; Jens Grossklags, Technical University of Munich; Michelle L. Mazurek, University of Maryland; Daniel Votipka, Tufts University; Aron Laszka, Pennsylvania State University\n\nDistinguished Paper Award Winner\n\nAlthough researchers have characterized the bug-bounty ecosystem from the point of view of platforms and programs, minimal effort has been made to understand the perspectives of the main workers: bug hunters. To improve bug bounties, it is important to understand hunters motivating factors, challenges, and overall benefits. We address this research gap with three studies: identifying key factors through a free listing survey (n=56), rating each factors importance with a larger-scale factor-rating survey (n=159), and conducting semi-structured interviews to uncover details (n=24). Of 54 factors that bug hunters listed, we find that rewards and learning opportunities are the most important benefits. Further, we find scope to be the top differentiator between programs. Surprisingly, we find earning reputation to be one of the least important motivators for hunters. Of the challenges we identify, communication problems, such as unresponsiveness and disputes, are the most substantial. We present recommendations to make the bug-bounty ecosystem accommodating to more bug hunters and ultimately increase participation in an underutilized market.\n\nBunnyHop: Exploiting the Instruction Prefetcher\n\nZhiyuan Zhang, Mingtian Tao, and Sioli O'Connell, The University of Adelaide; Chitchanok Chuengsatiansup, The University of Melbourne; Daniel Genkin, Georgia Tech; Yuval Yarom, The University of Adelaide\n\nThe instruction prefetcher is a microarchitectural component whose task is to bring program code into the instruction cache. To predict which code is likely to be executed, the instruction prefetcher relies on the branch predictor.\n\nIn this paper we investigate the instruction prefetcher in modern Intel processors. We first propose BunnyHop, a technique that uses the instruction prefetcher to encode branch prediction information as a cache state. We show how to use BunnyHop to perform low-noise attacks on the branch predictor. Specifically, we show how to implement attacks similar to Flush+Reload and Prime+Probe on the branch predictor instead of on the data caches. We then show that BunnyHop allows using the instruction prefetcher as a confused deputy to force cache eviction within a victim. We use this to demonstrate an attack on an implementation of AES protected with both cache coloring and data prefetch.\n\nCAPatch: Physical Adversarial Patch against Image Captioning Systems\n\nShibo Zhang, USSLAB, Zhejiang University; Yushi Cheng, BNRist, Tsinghua University; Wenjun Zhu, Xiaoyu Ji, and Wenyuan Xu, USSLAB, Zhejiang University\n\nThe fast-growing surveillance systems will make image captioning, i.e., automatically generating text descriptions of images, an essential technique to process the huge volumes of videos efficiently, and correct captioning is essential to ensure the text authenticity. While prior work has demonstrated the feasibility of fooling computer vision models with adversarial patches, it is unclear whether the vulnerability can lead to incorrect captioning, which involves natural language processing after image feature extraction. In this paper, we design CAPatch, a physical adversarial patch that can result in mistakes in the final captions, i.e., either create a completely different sentence or a sentence with keywords missing, against multi-modal image captioning systems. To make CAPatch effective and practical in the physical world, we propose a detection assurance and attention enhancement method to increase the impact of CAPatch and a robustness improvement method to address the patch distortions caused by image printing and capturing. Evaluations on three commonly-used image captioning systems (Show-and-Tell, Self-critical Sequence Training: Att2in, and Bottom-up Top-down) demonstrate the effectiveness of CAPatch in both the digital and physical worlds, whereby volunteers wear printed patches in various scenarios, clothes, lighting conditions. With a size of 5% of the image, physically-printed CAPatch can achieve continuous attacks with an attack success rate higher than 73.1% over a video recorder.\n\nCapstone: A Capability-based Foundation for Trustless Secure Memory Access\n\nJason Zhijingcheng Yu, National University of Singapore; Conrad Watt, University of Cambridge; Aditya Badole, Trevor E. Carlson, and Prateek Saxena, National University of Singapore\n\nCapability-based memory isolation is a promising new architectural primitive. Software can access low-level memory only via capability handles rather than raw pointers, which provides a natural interface to enforce security restrictions. Existing architectural capability designs such as CHERI provide spatial safety, but fail to extend to other memory models that security-sensitive software designs may desire. In this paper, we propose Capstone, a more expressive architectural capability design that supports multiple existing memory isolation models in a trustless setup, i.e., without relying on trusted software components. We show how Capstone is well-suited for environments where privilege boundaries are fluid (dynamically extensible), memory sharing/delegation are desired both temporally and spatially, and where such needs are to be balanced with availability concerns. Capstone can also be implemented efficiently. We present an implementation sketch and through evaluation show that its overhead is below 50% in common use cases. We also prototype a functional emulator for Capstone and use it to demonstrate the runnable implementations of six real-world memory models without trusted software components: three types of enclave-based TEEs, a thread scheduler, a memory allocator, and Rust-style memory safetyall within the interface of Capstone.\n\nCarpetFuzz: Automatic Program Option Constraint Extraction from Documentation for Fuzzing\n\nDawei Wang, Ying Li, and Zhiyu Zhang, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; Kai Chen, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; Beijing Academy of Artificial Intelligence, China\n\nThe large-scale code in software supports the rich and diverse functionalities, and at the same time contains potential vulnerabilities. Fuzzing, as one of the most popular vulnerability detection methods, continues evolving in both industry and academy, aiming to find more vulnerabilities by covering more code. However, we find that even with the state-of-the-art fuzzers, there is still some unexplored code that can only be triggered using a specific combination of program options. Simply mutating the options may generate many invalid combinations due to the lack of consideration of constraints (or called relationships) among options. In this paper, we leverage natural language processing (NLP) to automatically extract option descriptions from program documents and analyze the relationship (e.g., conflicts, dependencies) among the options before filtering out invalid combinations and only leaving the valid ones for fuzzing. We implemented a tool called CarpetFuzz and evaluated its performance. The results show that CarpetFuzz accurately extracts the relationships from documents with 96.10% precision and 88.85% recall. Based on these relationships, CarpetFuzz reduced the 67.91% option combinations to be tested. It helps AFL find 45.97% more paths that other fuzzers cannot discover. After analyzing 20 popular open-source programs, CarpetFuzz discovered 57 vulnerabilities, including 43 undisclosed ones. We also successfully obtained CVE IDs for 30 vulnerabilities.\n\nCatch You and I Can: Revealing Source Voiceprint Against Voice Conversion\n\nJiangyi Deng, Yanjiao Chen, Yinan Zhong, and Qianhao Miao, Zhejiang University; Xueluan Gong, Wuhan University; Wenyuan Xu, Zhejiang University\n\nVoice conversion (VC) techniques can be abused by malicious parties to transform their audios to sound like a target speaker, making it hard for a human being or a speaker verification/identification system to trace the source speaker. In this paper, we make the first attempt to restore the source voiceprint from audios synthesized by voice conversion methods with high credit. However, unveiling the features of the source speaker from a converted audio is challenging since the voice conversion operation intends to disentangle the original features and infuse the features of the target speaker. To fulfill our goal, we develop Revelio, a representation learning model, which learns to effectively extract the voiceprint of the source speaker from converted audio samples. We equip Revelio with a carefully-designed differential rectification algorithm to eliminate the influence of the target speaker by removing the representation component that is parallel to the voiceprint of the target speaker. We have conducted extensive experiments to evaluate the capability of Revelio in restoring voiceprint from audios converted by VQVC, VQVC+, AGAIN, and BNE. The experiments verify that Revelio is able to rebuild voiceprints that can be traced to the source speaker by speaker verification and identification systems. Revelio also exhibits robust performance under inter-gender conversion, unseen languages, and telephony networks.\n\nCipherfix: Mitigating Ciphertext Side-Channel Attacks in Software\n\nJan Wichelmann, Anna Ptschke, Luca Wilke, and Thomas Eisenbarth, University of Lbeck\n\nTrusted execution environments (TEEs) provide an environment for running workloads in the cloud without having to trust cloud service providers, by offering additional hardware-assisted security guarantees. However, main memory encryption as a key mechanism to protect against system-level attackers trying to read the TEE's content and physical, off-chip attackers, is insufficient. The recent Cipherleaks attacks infer secret data from TEE-protected implementations by analyzing ciphertext patterns exhibited due to deterministic memory encryption. The underlying vulnerability, dubbed the ciphertext side-channel, is neither protected by state-of-the-art countermeasures like constant-time code nor by hardware fixes.\n\nThus, in this paper, we present a software-based, drop-in solution that can harden existing binaries such that they can be safely executed under TEEs vulnerable to ciphertext side-channels, without requiring recompilation. We combine taint tracking with both static and dynamic binary instrumentation to find sensitive memory locations, and mitigate the leakage by masking secret data before it gets written to memory. This way, although the memory encryption remains deterministic, we destroy any secret-dependent patterns in encrypted memory. We show that our proof-of-concept implementation protects various constant-time implementations against ciphertext side-channels with reasonable overhead.\n\nControlled Data Races in Enclaves: Attacks and Detection\n\nSanchuan Chen, Fordham University; Zhiqiang Lin, The Ohio State University; Yinqian Zhang, Southern University of Science and Technology\n\nThis paper introduces controlled data race attacks, a new class of attacks against programs guarded by trusted execution environments such as Intel SGX. Controlled data race attacks are analog to controlled channel attacks, where the adversary controls the underlying operating system and manipulates the scheduling of enclave threads and handling of interrupts and exceptions. Controlled data race attacks are of particular interest for two reasons: First, traditionally non-deterministic data race bugs can be triggered deterministically and exploited for security violation in the context of SGX enclaves. Second, an intended single-threaded enclave can be concurrently invoked by the adversary, which triggers unique interleaving patterns that would not occur in traditional settings. To detect the controlled data race vulnerabilities in real-world enclave binaries (including the code linked with the SGX libraries), we present a lockset-based binary analysis detection algorithm. We have implemented our algorithm in a tool named SGXRacer, and evaluated it with four SGX SDKs and eight open-source SGX projects, identifying 1,780 data races originated from 476 shared variables.\n\nCSHER: A System for Compact Storage with HE-Retrieval\n\nAdi Akavia and Neta Oren, University of Haifa; Boaz Sapir and Margarita Vald, Intuit Israel Inc.\n\nHomomorphic encryption (HE) is a promising technology for protecting data in use, with considerable progress in recent years towards attaining practical runtime performance. However, the high storage overhead associated with HE remains an obstacle to its large-scale adoption. In this work we propose a new storage solution in the two-server model resolving the high storage overhead associated with HE, while preserving rigorous data confidentiality. We empirically evaluated our solution in a proof-of-concept system running on AWS EC2 instances with AWS S3 storage, demonstrating storage size with zero overhead over storing AES ciphertexts, and 10s amortized end-to-end runtime. In addition, we performed experiments on multiple clouds, i.e., where each server resides on a different cloud, exhibiting similar results. As a central tool we introduce the first perfect secret sharing scheme with fast homomorphic reconstruction over the reals; this may be of independent interest.\n\nDid the Shark Eat the Watchdog in the NTP Pool? Deceiving the NTP Pools Monitoring System\n\nJonghoon Kwon, ETH Zrich; Jeonggyu Song and Junbeom Hur, Korea University; Adrian Perrig, ETH Zrich\n\nThe NTP pool has become a critical infrastructure for modern Internet services and applications. With voluntarily joined thousands of timeservers, it supplies millions of distributed (heterogeneous) systems with time. While numerous efforts have been made to enhance NTP's accuracy, reliability, and security, unfortunately, the NTP pool attracts relatively little attention. In this paper, we provide a comprehensive analysis of NTP pool security, in particular the NTP pool monitoring system, which oversees the correctness and responsiveness of the participating servers. We first investigate strategic attacks that deceive the pool's health-check system to remove legitimate timeservers from the pool. Then, through empirical analysis using monitoring servers and timeservers injected into the pool, we demonstrate the feasibility of our approaches, show their effectiveness, and debate the implications. Finally, we discuss designing a new pool monitoring system to mitigate these attacks.\n\nDiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing\n\nJiawei Zhang, UIUC; Zhongzhu Chen, University of Michigan, Ann Arbor; Huan Zhang, Carnegie Mellon University; Chaowei Xiao, Arizona State University; Bo Li, UIUC\n\nDiffusion models have been leveraged to perform adversarial purification and thus provide both empirical and certified robustness for a standard model. On the other hand, different robustly trained smoothed models have been studied to improve the certified robustness. Thus, it raises a natural question: Can diffusion model be used to achieve improved certified robustness on those robustly trained smoothed models? In this work, we first theoretically show that recovered instances by diffusion models are in the bounded neighborhood of the original instance with high probability; and the \"one-shot\" denoising diffusion probabilistic models (DDPM) can approximate the mean of the generated distribution of a continuous-time diffusion model, which approximates the original instance under mild conditions. Inspired by our analysis, we propose a certifiably robust pipeline DiffSmooth, which first performs adversarial purification via diffusion models and then maps the purified instances to a common region via a simple yet effective local smoothing strategy. We conduct extensive experiments on different datasets and show that DiffSmooth achieves SOTA-certified robustness compared with eight baselines. For instance, DiffSmooth improves the SOTA-certified accuracy from 36.0% to 53.0% under &ell;2 radius 1.5 on ImageNet.\n\nDiving into Robocall Content with SnorCall\n\nSathvik Prasad, Trevor Dunlap, Alexander Ross, and Bradley Reaves, North Carolina State University\n\nUnsolicited bulk telephone calls  termed \"robocalls\"  nearly outnumber legitimate calls, overwhelming telephone users. While the vast majority of these calls are illegal, they are also ephemeral. Although telephone service providers, regulators, and researchers have ready access to call metadata, they do not have tools to investigate call content at the vast scale required. This paper presents SnorCall, a framework that scalably and efficiently extracts content from robocalls. SnorCall leverages the Snorkel framework that allows a domain expert to write simple labeling functions to classify text with high accuracy. We apply SnorCall to a corpus of transcripts covering 232,723 robocalls collected over a 23-month period. Among many other findings, SnorCall enables us to obtain first estimates on how prevalent different scam and legitimate robocall topics are, determine which organizations are referenced in these calls, estimate the average amounts solicited in scam calls, identify shared infrastructure between campaigns, and monitor the rise and fall of election-related political calls. As a result, we demonstrate how regulators, carriers, anti-robocall product vendors, and researchers can use SnorCall to obtain powerful and accurate analyses of robocall content and trends that can lead to better defenses.\n\nDont be Dense: Efficient Keyword PIR for Sparse Databases\n\nSarvar Patel and Joon Young Seo, Google; Kevin Yeo, Google and Columbia University\n\nDistinguished Paper Award Winner\n\nIn this paper, we introduce SparsePIR, a single-server keyword private information retrieval (PIR) construction that enables querying over sparse databases. At its core, SparsePIR is based on a novel encoding algorithm that encodes sparse database entries as linear combinations while being compatible with important PIR optimizations including recursion. SparsePIR achieves response overhead that is half of state-of-the art keyword PIR schemes without requiring long-term client storage of linear-sized mappings. We also introduce two variants, SparsePIRg and SparsePIRc, that further reduces the size of the serving database at the cost of increased encoding time and small additional client storage, respectively. Our frameworks enable performing keyword PIR with, essentially, the same costs as standard PIR. Finally, we also show that SparsePIR may be used to build batch keyword PIR with halved response overhead without any client mappings.\n\nDuoram: A Bandwidth-Efficient Distributed ORAM for 2- and 3-Party Computation\n\nAdithya Vadapalli, University of Waterloo; Ryan Henry, University of Calgary; Ian Goldberg, University of Waterloo\n\nWe design, analyze, and implement Duoram, a fast and bandwidth-efficient distributed ORAM protocol suitable for secure 2- and 3-party computation settings. Following Doerner and shelat's Floram construction (CCS 2017), Duoram leverages (2,2)-distributed point functions (DPFs) to represent PIR and PIR-writing queries compactlybut with a host of innovations that yield massive asymptotic reductions in communication cost and notable speedups in practice, even for modestly sized instances. Specifically, Duoram introduces a novel method for evaluating dot products of certain secret-shared vectors using communication that is only logarithmic in the vector length. As a result, for memories with n addressable locations, Duoram can perform a sequence of m arbitrarily interleaved reads and writes using just O(mlgn) words of communication, compared with Floram's O(mn) words. Moreover, most of this work can occur during a data-independent preprocessing phase, leaving just O(m) words of online communication cost for the sequencei.e., a constant online communication cost per memory access.\n\nEducators Perspectives of Using (or Not Using) Online Exam Proctoring\n\nDavid G. Balash, Elena Korkes, Miles Grant, and Adam J. Aviv, The George Washington University; Rahel A. Fainchtein and Micah Sherr, Georgetown University\n\nThe onset of the COVID-19 pandemic changed the landscape of education and led to increased usage of remote proctoring tools that are designed to monitor students when they take assessments outside the classroom. While prior work has explored students' privacy and security concerns regarding online proctoring tools, the perspective of educators is under explored. Notably, educators are the decision makers in the classrooms and choose which remote proctoring services and the level of observations they deem appropriate. To explore how educators balance the security and privacy of their students with the requirements of remote exams, we sent survey requests to over 3,400 instructors at a large private university that taught online classes during the 2020/21 academic year. We had n=125 responses: 21% of the educators surveyed used online exam proctoring services during the remote learning period, and of those, 35% plan to continue using the tools even when there is a full return to in-person learning. Educators who use exam proctoring services are often comfortable with their monitoring capabilities. However, educators are concerned about students sharing certain types of information with exam proctoring companies, particularly when proctoring services collect identifiable information to validate students' identities. Our results suggest that many educators developed alternative assessments that did not require online proctoring and that those who did use online proctoring services often considered the tradeoffs between the potential risks to student privacy and the utility or necessity of exam proctoring services.\n\nELASM: Error-Latency-Aware Scale Management for Fully Homomorphic Encryption\n\nYongwoo Lee, Seonyoung Cheon, and Dongkwan Kim, Yonsei University; Dongyoon Lee, Stony Brook University; Hanjun Kim, Yonsei University\n\nThanks to its fixed-point arithmetic and SIMD-like vectorization, among fully homomorphic encryption (FHE) schemes that allow computation on encrypted data, RNS-CKKS is widely used for privacy-preserving machine learning services. Prior works have partly automated a daunting scale management task required for RNS-CKKS fixed-point arithmetic, yet none takes an output error into consideration, preventing users from exploring a better error-latency trade-off.\n\nThis work proposes a new error- and latency-aware scale management (ELASM) scheme for the RNS-CKKS FHE scheme. By actively controlling the scale of a ciphertext, one can effectively make the impact of noise on an error smaller because an error is a scaled noise introduced by an RNS-CKKS operation. ELASM explores different scale management plans that repurpose an upscale operation as an error reduction operation, estimates the output error and latency of each plan, and iteratively finds the best plan that minimizes the error-latency cost function. In addition, this work proposes a new scale-to-noise ratio (SNR) parameter and introduces fine-grained noise-aware waterlines (a minimum scale requirement) for different RNS-CKKS operations, opening a new opportunity to further improve an error-latency trade-off.\n\nThis work implements the proposed ideas in the ELASM compiler along with a new FHE language and type system that enforces the RNS-CKKS constraints including SNR-based noise-aware waterlines. For ten machine and deep learning benchmarks, ELASM finds the better error and latency trade-offs (lower Pareto curves) than the state-of-the-art solutions such as EVA and Hecate.\n\nEos: Efficient Private Delegation of zkSNARK Provers\n\nAlessandro Chiesa, UC Berkeley and EPFL; Ryan Lehmkuhl, MIT; Pratyush Mishra, Aleo and University of Pennsylvania; Yinuo Zhang, UC Berkeley\n\nSuccinct zero knowledge proofs (i.e. zkSNARKs) are powerful cryptographic tools that enable a prover to convince a verifier that a given statement is true without revealing any additional information. Their attractive privacy properties have led to much academic and industrial interest.\n\nUnfortunately, existing systems for generating zkSNARKs are expensive, which limits the applications in which these proofs can be used. One approach is to take advantage of powerful cloud servers to generate the proof. However, existing techniques for this (e.g., DIZK) sacrifice privacy by revealing secret information to the cloud machines. This is problematic for many applications of zkSNARKs, such as decentralized private currency and computation systems.\n\nIn this work we design and implement privacy-preserving delegation protocols for zkSNARKs with universal setup. Our protocols enable a prover to outsource proof generation to a set of workers, so that if at least one worker does not collude with other workers, no private information is revealed to any worker. Our protocols achieve security against malicious workers without relying on heavyweight cryptographic tools.\n\nWe implement and evaluate our delegation protocols for a state-of-the-art zkSNARK in a variety of computational and bandwidth settings, and demonstrate that our protocols are concretely efficient. When compared to local proving, using our protocols to delegate proof generation from a recent smartphone (a) reduces end-to-end latency by up to 26, (b) lowers the delegator's active computation time by up to 1447, and (c) enables proving up to 256 larger instances.\n\nEvery Vote Counts: Ranking-Based Training of Federated Learning to Resist Poisoning Attacks\n\nHamid Mozaffari, Virat Shejwalkar, and Amir Houmansadr, University of Massachusetts Amherst\n\nFederated learning (FL) allows untrusted clients to collaboratively train a common machine learning model, called global model, without sharing their private/proprietary training data. However, FL is susceptible to poisoning by malicious clients who aim to hamper the accuracy of the global model by contributing malicious updates during FL's training process.\n\nWe argue that the key factor to the success of poisoning attacks against existing FL systems is the large space of model updates available to the clients to choose from. To address this, we propose Federated Rank Learning (FRL). FRL reduces the space of client updates from model parameter updates (a continuous space of float numbers) in standard FL to the space of parameter rankings (a discrete space of integer values). To be able to train the global model using parameter ranks (instead of parameter weights), FRL leverage ideas from recent supermasks training mechanisms. Specifically, FRL clients rank the parameters of a randomly initialized neural network (provided by the server) based on their local training data, and the FRL server uses a voting mechanism to aggregate the parameter rankings submitted by the clients.\n\nIntuitively, our voting-based aggregation mechanism prevents poisoning clients from making significant adversarial modifications to the global model, as each client will have a single vote! We demonstrate the robustness of FRL to poisoning through analytical proofs and experimentation, and we show its high communication efficiency.\n\nExorcising \"Wraith\": Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks\n\nQifan Xiao, Xudong Pan, Yifan Lu, Mi Zhang, Jiarun Dai, and Min Yang, Fudan University\n\nAutomated driving systems rely on 3D object detectors to recognize possible obstacles from LiDAR point clouds. However, recent works show the adversary can forge non-existent cars in the prediction results with a few fake points (i.e., appearing attack). By removing statistical outliers, existing defenses are however designed for specific attacks or biased by predefined heuristic rules. Towards more comprehensive mitigation, we first systematically inspect the mechanism of previous appearing attacks: Their common weaknesses are observed in crafting fake obstacles which (i) have obvious differences in the local parts compared with real obstacles and (ii) violate the physical relation between depth and point density.\n\nIn this paper, we propose a novel plug-and-play defensive module which works by side of a trained LiDAR-based object detector to eliminate forged obstacles where a major proportion of local parts have low objectness, i.e., to what degree it belongs to a real object. At the core of our module is a local objectness predictor, which explicitly incorporates the depth information to model the relation between depth and point density, and predicts each local part of an obstacle with an objectness score. Extensive experiments show, our proposed defense eliminates at least 70% cars forged by three known appearing attacks in most cases, while, for the best previous defense, less than 30% forged cars are eliminated. Meanwhile, under the same circumstance, our defense incurs less overhead for AP/precision on cars compared with existing defenses. Furthermore, We validate the effectiveness of our proposed defense on simulation-based closed-loop control driving tests in the open-source system of Baidu's Apollo.\n\nExtending a Hand to Attackers: Browser Privilege Escalation Attacks via Extensions\n\nYoung Min Kim and Byoungyoung Lee, Seoul National University\n\nWeb browsers are attractive targets of attacks, whereby attackers can steal security- and privacy-sensitive data, such as online banking and social network credentials, from users. Thus, browsers adopt the principle of least privilege (PoLP) to minimize damage if compromised, namely, the multiprocess architecture and site isolation. We focus on browser extensions, which are third-party programs that extend the features of modern browsers (Chrome, Firefox, and Safari). The browser also applies PoLP to the extension architecture; that is, two primary extension components are separated, where one component is granted higher privilege, and the other is granted lower privilege.\n\nIn this paper, we first analyze the security aspect of extensions. The analysis reveals that the current extension architecture imposes strict security requirements on extension developers, which are difficult to satisfy. In particular, 59 vulnerabilities are found in 40 extensions caused by violated requirements, allowing the attacker to perform privilege escalation attacks, including UXSS (universal cross-site scripting) and stealing passwords or cryptocurrencies in the extensions. Alarmingly, extensions are used by more than half and a third of Chrome and Firefox users, respectively. Furthermore, many extensions in which vulnerabilities are found are extremely popular and have more than 10 million users.\n\nTo address the security limitations of the current extension architecture, we present FistBump, a new extension architecture to strengthen PoLP enforcement. FistBump employs strong process isolation between the webpage and content script; thus, the aforementioned security requirements are satisfied by design, thereby eliminating all the identified vulnerabilities. Moreover, FistBumps design maintains the backward compatibility of the extensions; therefore, the extensions can run with FistBump without modification.\n\nEye-Shield: Real-Time Protection of Mobile Device Screen Information from Shoulder Surfing\n\nBrian Jay Tang and Kang G. Shin, University of Michigan\n\nPeople use mobile devices ubiquitously for computing, communication, storage, web browsing, and more. As a result, the information accessed and stored within mobile devices, such as financial and health information, text messages, and emails, can often be sensitive. Despite this, people frequently use their mobile devices in public areas, becoming susceptible to a simple yet effective attack  shoulder surfing. Shoulder surfing occurs when a person near a mobile user peeks at the user's mobile device, potentially acquiring passcodes, PINs, browsing behavior, or other personal information. We propose, Eye-Shield, a solution to prevent shoulder surfers from accessing/stealing sensitive on-screen information. Eye-Shield is designed to protect all types of on-screen information in real time, without any serious impediment to users' interactions with their mobile devices. Eye-Shield generates images that appear readable at close distances, but appear blurry or pixelated at farther distances and wider angles. It is capable of protecting on-screen information from shoulder surfers, operating in real time, and being minimally intrusive to the intended users. Eye-Shield protects images and text from shoulder surfers by reducing recognition rates to 24.24% and 15.91%. Our implementations of Eye-Shield achieved high frame rates for 1440  3088 screen resolutions (24 FPS for Android and 43 FPS for iOS). Eye-Shield also incurs acceptable memory usage, CPU utilization, and energy overhead. Finally, our MTurk and in-person user studies indicate that Eye-Shield protects on-screen information without a large usability cost for privacy-conscious users.\n\nFABRID: Flexible Attestation-Based Routing for Inter-Domain Networks\n\nCyrill Krhenbhl, Marc Wyss, and David Basin, ETH Zrich; Vincent Lenders, armasuisse; Adrian Perrig, ETH Zrich; Martin Strohmeier, armasuisse\n\nIn its current state, the Internet does not provide end users with transparency and control regarding on-path forwarding devices. In particular, the lack of network device information reduces the trustworthiness of the forwarding path and prevents end-user applications requiring specific router capabilities from reaching their full potential. Moreover, the inability to influence the traffic's forwarding path results in applications communicating over undesired routes, while alternative paths with more desirable properties remain unusable.\n\nIn this work, we present FABRID, a system that enables applications to forward traffic flexibly, potentially on multiple paths selected to comply with user-defined preferences, where information about forwarding devices is exposed and transparently attested by autonomous systems (ASes). The granularity of this information is chosen by each AS individually, protecting them from leaking sensitive network details, while the secrecy and authenticity of preferences embedded within the users' packets are protected through efficient cryptographic operations. We show the viability of FABRID by deploying it on a global SCION network test bed, and we demonstrate high throughput on commodity hardware.\n\nFact-Saboteurs: A Taxonomy of Evidence Manipulation Attacks against Fact-Verification Systems\n\nSahar Abdelnabi and Mario Fritz, CISPA Helmholtz Center for Information Security\n\nMis- and disinformation are a substantial global threat to our security and safety. To cope with the scale of online misinformation, researchers have been working on automating fact-checking by retrieving and verifying against relevant evidence. However, despite many advances, a comprehensive evaluation of the possible attack vectors against such systems is still lacking. Particularly, the automated fact-verification process might be vulnerable to the exact disinformation campaigns it is trying to combat. In this work, we assume an adversary that automatically tampers with the online evidence in order to disrupt the fact-checking model via camouflaging the relevant evidence or planting a misleading one. We first propose an exploratory taxonomy that spans these two targets and the different threat model dimensions. Guided by this, we design and propose several potential attack methods. We show that it is possible to subtly modify claim-salient snippets in the evidence and generate diverse and claim-aligned evidence. Thus, we highly degrade the fact-checking performance under many different permutations of the taxonomys dimensions. The attacks are also robust against post-hoc modifications of the claim. Our analysis further hints at potential limitations in models inference when faced with contradicting evidence. We emphasize that these attacks can have harmful implications on the inspectable and human-in-the-loop usage scenarios of such models, and we conclude by discussing challenges and directions for future defenses.\n\nFine-grained Poisoning Attack to Local Differential Privacy Protocols for Mean and Variance Estimation\n\nXiaoguang Li, Xidian University and Purdue University; Ninghui Li and Wenhai Sun, Purdue University; Neil Zhenqiang Gong, Duke University; Hui Li, Xidian University\n\nAlthough local differential privacy (LDP) protects individual users' data from inference by an untrusted data curator, recent studies show that an attacker can launch a data poisoning attack from the user side to inject carefully-crafted bogus data into the LDP protocols in order to maximally skew the final estimate by the data curator.\n\nIn this work, we further advance this knowledge by proposing a new fine-grained attack, which allows the attacker to fine-tune and simultaneously manipulate mean and variance estimations that are popular analytical tasks for many real-world applications. To accomplish this goal, the attack leverages the characteristics of LDP to inject fake data into the output domain of the local LDP instance. We call our attack the output poisoning attack (OPA). We observe a security-privacy consistency where a small privacy loss enhances the security of LDP, which contradicts the known security-privacy trade-off from prior work. We further study the consistency and reveal a more holistic view of the threat landscape of data poisoning attacks on LDP. We comprehensively evaluate our attack against a baseline attack that intuitively provides false input to LDP. The experimental results show that OPA outperforms the baseline on three real-world datasets. We also propose a novel defense method that can recover the result accuracy from polluted data collection and offer insight into the secure LDP design.\n\nFormal Analysis and Patching of BLE-SC Pairing\n\nMin Shi, Jing Chen, Kun He, Haoran Zhao, Meng Jia, and Ruiying Du, Wuhan University\n\nBluetooth Low Energy (BLE) is the mainstream Bluetooth standard and BLE Secure Connections (BLC-SC) pairing is a protocol that authenticates two Bluetooth devices and derives a shared secret key between them. Although BLE-SC pairing employs well-studied cryptographic primitives to guarantee its security, a recent study revealed a logic flaw in the protocol.\n\nIn this paper, we develop the first comprehensive formal model of the BLE-SC pairing protocol. Our model is compliant with the latest Bluetooth specification version 5.3 and covers all association models in the specification to discover attacks caused by the interplay between different association models. We also partly loosen the perfect cryptography assumption in traditional symbolic analysis approaches by designing a low-entropy key oracle to detect attacks caused by the poorly derived keys. Our analysis confirms two existing attacks and discloses a new attack. We propose a countermeasure to fix the flaws found in the BLE-SC pairing protocol and discuss the backward compatibility. Moreover, we extend our model to verify the countermeasure, and the results demonstrate its effectiveness in our extended model.\n\nFormal Analysis of Session-Handling in Secure Messaging: Lifting Security from Sessions to Conversations\n\nCas Cremers, CISPA Helmholtz Center for Information Security; Charlie Jacomme, Inria Paris; Aurora Naska, CISPA Helmholtz Center for Information Security\n\nThe building blocks for secure messaging apps, such as Signals X3DH and Double Ratchet (DR) protocols, have received a lot of attention from the research community. They have notably been proved to meet strong security properties even in the case of compromise such as Forward Secrecy (FS) and Post-Compromise Security (PCS). However, there is a lack of formal study of these properties at the application level. Whereas the research works have studied such properties in the context of a single ratcheting chain, a conversation between two persons in a messaging application can in fact be the result of merging multiple ratcheting chains.\n\nIn this work, we initiate the formal analysis of secure messaging taking the session-handling layer into account, and apply our approach to Sesame, Signals session management. We first experimentally show practical scenarios in which PCS can be violated in Signal by a clone attacker, despite its use of the Double Ratchet. We identify how this is enabled by Signals session-handling layer. We then design a formal model of the session-handling layer of Signal that is tractable for automated verification with the Tamarin prover, and use this model to rediscover the PCS violation and propose two provably secure mechanisms to offer stronger guarantees.\n\nFormal Analysis of SPDM: Security Protocol and Data Model version 1.2\n\nCas Cremers, Alexander Dax, and Aurora Naska, CISPA Helmholtz Center for Information Security\n\nDMTF is a standards organization by major industry players in IT infrastructure including AMD, Alibaba, Broadcom, Cisco, Dell, Google, Huawei, IBM, Intel, Lenovo, and NVIDIA, which aims to enable interoperability, e.g., including cloud, virtualization, network, servers and storage. It is currently standardizing a security protocol called SPDM, which aims to secure communication over the wire and to enable device attestation, notably also explicitly catering for communicating hardware components.\n\nThe SPDM protocol inherits requirements and design ideas from IETFs TLS 1.3. However, its state machines and transcript handling are substantially different and more complex. While architecture, specification, and open-source libraries of the current versions of SPDM are publicly available, these include no significant security analysis of any kind.\n\nIn this work we develop the first formal models of the three modes of the SPDM protocol version 1.2.1, and formally analyze their main security properties.\n\nForming Faster Firmware Fuzzers\n\nLukas Seidel, Qwiet AI; Dominik Maier, TU Berlin; Marius Muench, VU Amsterdam and University of Birmingham\n\nA recent trend for assessing the security of an embedded systems firmware is rehosting, the art of running the firmware in a virtualized environment, rather than on the original hardware platform. One significant use case for firmware rehosting is fuzzing to dynamically uncover security vulnerabilities.\n\nHowever, state-of-the-art implementations suffer from high emulator-induced overhead, leading to less-than-optimal execution speeds. Instead of emulation, we propose near-native rehosting: running embedded firmware as a Linux userspace process on a high-performance system that shares the instruction set family with the targeted device. We implement this approach with SAFIREFUZZ, a throughput-optimized rehosting and fuzzing framework for ARM Cortex-M firmware. SAFIREFUZZ takes monolithic binary-only firmware images and uses high-level emulation (HLE) and dynamic binary rewriting to run them on far more powerful hardware with low overhead. By replicating experiments of HALucinator, the state-of-the-art HLE-based rehosting system for binary firmware, we show that SAFIREFUZZ can provide a 690x throughput increase on average during 24-hour fuzzing campaigns while covering up to 30% more basic blocks.\n\nFreeEagle: Detecting Complex Neural Trojans in Data-Free Cases\n\nChong Fu, Xuhong Zhang, and Shouling Ji, Zhejiang University; Ting Wang, Pennsylvania State University; Peng Lin, Chinese Aeronautical Establishment; Yanghe Feng, National University of Defense Technology; Jianwei Yin, Zhejiang University\n\nTrojan attack on deep neural networks, also known as backdoor attack, is a typical threat to artificial intelligence. A trojaned neural network behaves normally with clean inputs. However, if the input contains a particular trigger, the trojaned model will have attacker-chosen abnormal behavior. Although many backdoor detection methods exist, most of them assume that the defender has access to a set of clean validation samples or samples with the trigger, which may not hold in some crucial real-world cases, e.g., the case where the defender is the maintainer of model-sharing platforms. Thus, in this paper, we propose FreeEagle, the first data-free backdoor detection method that can effectively detect complex backdoor attacks on deep neural networks, without relying on the access to any clean samples or samples with the trigger. The evaluation results on diverse datasets and model architectures show that FreeEagle is effective against various complex backdoor attacks, even outperforming some state-of-the-art non-data-free backdoor detection methods.\n\nGAP: Differentially Private Graph Neural Networks with Aggregation Perturbation\n\nSina Sajadmanesh, Idiap Research Institute and EPFL; Ali Shahin Shamsabadi, Alan Turing Institute; Aurlien Bellet, Inria; Daniel Gatica-Perez, Idiap Research Institute and EPFL\n\nIn this paper, we study the problem of learning Graph Neural Networks (GNNs) with Differential Privacy (DP). We propose a novel differentially private GNN based on Aggregation Perturbation (GAP), which adds stochastic noise to the GNN's aggregation function to statistically obfuscate the presence of a single edge (edge-level privacy) or a single node and all its adjacent edges (node-level privacy). Tailored to the specifics of private learning, GAP's new architecture is composed of three separate modules: (i) the encoder module, where we learn private node embeddings without relying on the edge information; (ii) the aggregation module, where we compute noisy aggregated node embeddings based on the graph structure; and (iii) the classification module, where we train a neural network on the private aggregations for node classification without further querying the graph edges. GAP's major advantage over previous approaches is that it can benefit from multi-hop neighborhood aggregations, and guarantees both edge-level and node-level DP not only for training, but also at inference with no additional costs beyond the training's privacy budget. We analyze GAP's formal privacy guarantees using Rnyi DP and conduct empirical experiments over three real-world graph datasets. We demonstrate that GAP offers significantly better accuracy-privacy trade-offs than state-of-the-art DP-GNN approaches and naive MLP-based baselines. Our code is publicly available at https://github.com/sisaman/GAP.\n\nGoing through the motions: AR/VR keylogging from user head motions\n\nCarter Slocum, Yicheng Zhang, Nael Abu-Ghazaleh, and Jiasi Chen, University of California, Riverside\n\nAugmented Reality/Virtual Reality (AR/VR) are the next step in the evolution of ubiquitous computing after personal computers to mobile devices. Applications of AR/VR continue to grow, including education and virtual workspaces, increasing opportunities for users to enter private text, such as passwords or sensitive corporate information. In this work, we show that there is a serious security risk of typed text in the foreground being inferred by a background application, without requiring any special permissions. The key insight is that a users head moves in subtle ways as she types on a virtual keyboard, and these motion signals are sufficient for inferring the text that a user types. We develop a system, TyPose, that extracts these signals and automatically infers words or characters that a victim is typing. Once the sensor signals are collected, TyPose uses machine learning to segment the motion signals in time to determine word/character boundaries, and also perform inference on the words/characters themselves. Our experimental evaluation on commercial AR/VR headsets demonstrate the feasibility of this attack, both in situations where multiple users data is used for training (82% top-5 word classification accuracy) or when the attack is personalized to a particular victim (92% top-5 word classification accuracy). We also show that first-line defenses of reducing the sampling rate or precision of head tracking are ineffective, suggesting that more sophisticated mitigations are needed.\n\nHECO: Fully Homomorphic Encryption Compiler\n\nAlexander Viand, Patrick Jattke, Miro Haller, and Anwar Hithnawi, ETH Zurich\n\nIn recent years, Fully Homomorphic Encryption ( FHE) has undergone several breakthroughs and advancements leading to a leap in performance. Today, performance is no longer a major barrier to adoption. Instead, it is the complexity of developing an efficient FHE application that currently limits deploying FHE in practice and at scale. Several FHE compilers have emerged recently to ease FHE development. However, none of these answer how to automatically transform imperative programs to secure and efficient FHE implementations. This is a fundamental issue that needs to be addressed before we can realistically expect broader use of FHE. Automating these transformations is challenging because the restrictive set of operations in FHE and their non-intuitive performance characteristics require programs to be drastically transformed to achieve efficiency. Moreover, existing tools are monolithic and focus on individual optimizations. Therefore, they fail to fully address the needs of end-to-end FHE development. In this paper, we present HECO, a new end-to-end design for FHE compilers that takes high-level imperative programs and emits efficient and secure FHE implementations. In our design, we take a broader view of FHE development, extending the scope of optimizations beyond the cryptographic challenges existing tools focus on.\n\nHey Kimya, Is My Smart Speaker Spying on Me? Taking Control of Sensor Privacy Through Isolation and Amnesia\n\nPiet De Vaere and Adrian Perrig, ETH Zrich\n\nAlthough smart speakers and other voice assistants are becoming increasingly ubiquitous, their always-standby nature continues to prompt significant privacy concerns. To address these, we propose Kimya, a hardening framework that allows device vendors to provide strong data-privacy guarantees. Concretely, Kimya guarantees that microphone data can only be used for local processing, and is immediately discarded unless a user-auditable notification is generated. Kimya thus makes devices accountable for their data-retention behavior. Moreover, Kimya is not limited to voice assistants, but is applicable to all devices with always-standby, event-triggered sensors. We implement Kimya for ARM Cortex-M, and apply it to a wake-word detection engine. Our evaluation shows that Kimya introduces low overhead, can be used in constrained environments, "
    }
}