{
    "id": "dbpedia_7722_2",
    "rank": 56,
    "data": {
        "url": "https://www.linkedin.com/posts/christoph-molnar_interpretable-machine-learning-a-brief-activity-7125749481857310720-3dNA",
        "read_more_link": "",
        "language": "en",
        "title": "Christoph Molnar on LinkedIn: Interpretable Machine Learning -- A Brief History, State-of-the-Art andâ€¦",
        "top_image": "https://media.licdn.com/dms/image/v2/D4D10AQF9I4CyDNM4Vg/image-shrink_1280/image-shrink_1280/0/1698911041186?e=2147483647&v=beta&t=VGLyKIBRJVrkeooZMxzmH1QUE2EhuE3aZHLi9Fv_pSA",
        "meta_img": "https://media.licdn.com/dms/image/v2/D4D10AQF9I4CyDNM4Vg/image-shrink_1280/image-shrink_1280/0/1698911041186?e=2147483647&v=beta&t=VGLyKIBRJVrkeooZMxzmH1QUE2EhuE3aZHLi9Fv_pSA",
        "images": [
            "https://media.licdn.com/dms/image/v2/D5616AQGtKh1FtmWc8Q/profile-displaybackgroundimage-shrink_200_800/profile-displaybackgroundimage-shrink_200_800/0/1690900899970?e=2147483647&v=beta&t=K_NoTUBhbFkDbm7azG9YGZobvJi5PfnhPHvIeLKbrKs"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Christoph Molnar"
        ],
        "publish_date": "2023-11-02T07:44:26.467000+00:00",
        "summary": "",
        "meta_description": "The fastest way* to get a high-level view of interpretable ML / XAI research.\n\nInterpretable Machine Learning - A Brief History, State of the Art, andâ€¦ | 10 comments on LinkedIn",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/posts/christoph-molnar_interpretable-machine-learning-a-brief-activity-7125749481857310720-3dNA",
        "text": "ðŸ“Š New Survey Reveals Techniques to Mitigate Biases in Machine Learning Systems A recent scholarly report has highlighted the critical issue of bias in Machine Learning (ML) algorithms and presented a range of strategies to mitigate such biases. The survey, titled \"Survey on Machine Learning Biases and Mitigation Techniques,\" offers a comprehensive review of bias mitigation techniques within ML, delving into methods including adversarial training designed to counteract systematic discrepancies in algorithmic decision-making. The survey underscores that ML biases can occur at various stages, from data collection to model evaluation, and outlines diverse strategies for their reduction. Researchers and developers are directed to consider a mixture of alterations to data, model constraints, or a combination of both to enhance fairness in outcomes. The report provides a nuanced examination of pre-processing, in-processing, and post-processing methodologies, each with their respective benefits and drawbacks. Quantifying the effectiveness of these strategies and offering empirical support, the paper serves as a valuable guide for those in research, applied domains, or policy-making. The goal is to foster a well-rounded understanding of biases in ML and to equip stakeholders with the knowledge required for the responsible and equitable application of these powerful technologies. #MachineLearning #BiasMitigation #DataScience #AI #Technology #Research Sources: https://lnkd.in/gqX6YkAB\n\nHappy Weekend!ðŸ’ƒðŸ’ƒ Let's kick off the weekend with some machine learning insights. While reading \"Machine Learning for Humans\" this week, I stumbled upon a concise illustration of overfitting: - Overfitting: \"Sherlock, your explanation is too specific to the situation.\" - Regularization: \"Don't overcomplicate things, Sherlock. I'll penalize you for every extra word.\" - Hyperparameter (A): \"Here's the strength of my penalty for extra words.\" Interesting, right? ðŸ˜¹ Now, let's dive into these terms. Overfitting occurs when a machine learning model becomes too fixated on the training data, making it unable to generalize to unseen data. Think of it like cramming information from a course without understanding it; you won't be able to apply it to future problems. In machine learning, this means the model fits the training data so closely that it struggles to predict on new data, which is called generalization. Overfitting's causes: 1. The model is too complex for the data. 2. Insufficient training data. Ways to reduce overfitting: 1. Use a simpler model: - Opt for a linear model, like linear regression, instead of polynomial regression. When dealing with neural networks, reduce the number of layers and units. Understanding your data's shape is crucial. 2. Add more training data: - If you have limited data, consider expanding your dataset. 3. Regularize the model: - Techniques like L1 regularization, L2 regularization, dropout, and batch normalization help control model complexity. Fine-tune the regularization hyperparameters to strike the right balance. Check out the full blog post here: https://lnkd.in/df2UKTBG #machinelearning #artificialintelligence #neuralnetworks #computerscience #technology #techenthusiast #tech https://lnkd.in/df2UKTBG"
    }
}