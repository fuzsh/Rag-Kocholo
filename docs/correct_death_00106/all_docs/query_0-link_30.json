{
    "id": "correct_death_00106_0",
    "rank": 30,
    "data": {
        "url": "https://www.science.gov/topicpages/k/key%2Bepidemiological%2Bparameters",
        "read_more_link": "",
        "language": "en",
        "title": "key epidemiological parameters: Topics by Science.gov",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.science.gov/scigov/desktop/en/images/SciGov_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Inferring epidemiological parameters from phylogenetic information for the HIV-1 epidemic among MSM\n\nNASA Astrophysics Data System (ADS)\n\nQuax, Rick; van de Vijver, David A. M. C.; Frentz, Dineke; Sloot, Peter M. A.\n\n2013-09-01\n\nThe HIV-1 epidemic in Europe is primarily sustained by a dynamic topology of sexual interactions among MSM who have individual immune systems and behavior. This epidemiological process shapes the phylogeny of the virus population. Both fields of epidemic modeling and phylogenetics have a long history, however it remains difficult to use phylogenetic data to infer epidemiological parameters such as the structure of the sexual network and the per-act infectiousness. This is because phylogenetic data is necessarily incomplete and ambiguous. Here we show that the cluster-size distribution indeed contains information about epidemiological parameters using detailed numberical experiments. We simulate the HIV epidemic among MSM many times using the Monte Carlo method with all parameter values and their ranges taken from literature. For each simulation and the corresponding set of parameter values we calculate the likelihood of reproducing an observed cluster-size distribution. The result is an estimated likelihood distribution of all parameters from the phylogenetic data, in particular the structure of the sexual network, the per-act infectiousness, and the risk behavior reduction upon diagnosis. These likelihood distributions encode the knowledge provided by the observed cluster-size distrbution, which we quantify using information theory. Our work suggests that the growing body of genetic data of patients can be exploited to understand the underlying epidemiological process.\n\nParameter Estimation in Epidemiology: from Simple to Complex Dynamics\n\nNASA Astrophysics Data System (ADS)\n\nAguiar, MaÃ­ra; Ballesteros, SebastiÃ©n; Boto, JoÃ£o Pedro; Kooi, Bob W.; Mateus, LuÃ­s; Stollenwerk, Nico\n\n2011-09-01\n\nWe revisit the parameter estimation framework for population biological dynamical systems, and apply it to calibrate various models in epidemiology with empirical time series, namely influenza and dengue fever. When it comes to more complex models like multi-strain dynamics to describe the virus-host interaction in dengue fever, even most recently developed parameter estimation techniques, like maximum likelihood iterated filtering, come to their computational limits. However, the first results of parameter estimation with data on dengue fever from Thailand indicate a subtle interplay between stochasticity and deterministic skeleton. The deterministic system on its own already displays complex dynamics up to deterministic chaos and coexistence of multiple attractors.\n\nSelection of key ambient particulate variables for epidemiological studies - applying cluster and heatmap analyses as tools for data reduction.\n\nPubMed\n\nGu, Jianwei; Pitz, Mike; Breitner, Susanne; Birmili, Wolfram; von Klot, Stephanie; Schneider, Alexandra; Soentgen, Jens; Reller, Armin; Peters, Annette; Cyrys, Josef\n\n2012-10-01\n\nThe success of epidemiological studies depends on the use of appropriate exposure variables. The purpose of this study is to extract a relatively small selection of variables characterizing ambient particulate matter from a large measurement data set. The original data set comprised a total of 96 particulate matter variables that have been continuously measured since 2004 at an urban background aerosol monitoring site in the city of Augsburg, Germany. Many of the original variables were derived from measured particle size distribution (PSD) across the particle diameter range 3 nm to 10 Î¼m, including size-segregated particle number concentration, particle length concentration, particle surface concentration and particle mass concentration. The data set was complemented by integral aerosol variables. These variables were measured by independent instruments, including black carbon, sulfate, particle active surface concentration and particle length concentration. It is obvious that such a large number of measured variables cannot be used in health effect analyses simultaneously. The aim of this study is a pre-screening and a selection of the key variables that will be used as input in forthcoming epidemiological studies. In this study, we present two methods of parameter selection and apply them to data from a two-year period from 2007 to 2008. We used the agglomerative hierarchical cluster method to find groups of similar variables. In total, we selected 15 key variables from 9 clusters which are recommended for epidemiological analyses. We also applied a two-dimensional visualization technique called \"heatmap\" analysis to the Spearman correlation matrix. 12 key variables were selected using this method. Moreover, the positive matrix factorization (PMF) method was applied to the PSD data to characterize the possible particle sources. Correlations between the variables and PMF factors were used to interpret the meaning of the cluster and the heatmap analyses\n\nInferring epidemiological parameters from phylogenies using regression-ABC: A comparative study\n\nPubMed Central\n\nGascuel, Olivier\n\n2017-01-01\n\nInferring epidemiological parameters such as the R0 from time-scaled phylogenies is a timely challenge. Most current approaches rely on likelihood functions, which raise specific issues that range from computing these functions to finding their maxima numerically. Here, we present a new regression-based Approximate Bayesian Computation (ABC) approach, which we base on a large variety of summary statistics intended to capture the information contained in the phylogeny and its corresponding lineage-through-time plot. The regression step involves the Least Absolute Shrinkage and Selection Operator (LASSO) method, which is a robust machine learning technique. It allows us to readily deal with the large number of summary statistics, while avoiding resorting to Markov Chain Monte Carlo (MCMC) techniques. To compare our approach to existing ones, we simulated target trees under a variety of epidemiological models and settings, and inferred parameters of interest using the same priors. We found that, for large phylogenies, the accuracy of our regression-ABC is comparable to that of likelihood-based approaches involving birth-death processes implemented in BEAST2. Our approach even outperformed these when inferring the host population size with a Susceptible-Infected-Removed epidemiological model. It also clearly outperformed a recent kernel-ABC approach when assuming a Susceptible-Infected epidemiological model with two host types. Lastly, by re-analyzing data from the early stages of the recent Ebola epidemic in Sierra Leone, we showed that regression-ABC provides more realistic estimates for the duration parameters (latency and infectiousness) than the likelihood-based method. Overall, ABC based on a large variety of summary statistics and a regression method able to perform variable selection and avoid overfitting is a promising approach to analyze large phylogenies. PMID:28263987\n\nParameter and uncertainty estimation for mechanistic, spatially explicit epidemiological models\n\nNASA Astrophysics Data System (ADS)\n\nFinger, Flavio; Schaefli, Bettina; Bertuzzo, Enrico; Mari, Lorenzo; Rinaldo, Andrea\n\n2014-05-01\n\nEpidemiological models can be a crucially important tool for decision-making during disease outbreaks. The range of possible applications spans from real-time forecasting and allocation of health-care resources to testing alternative intervention mechanisms such as vaccines, antibiotics or the improvement of sanitary conditions. Our spatially explicit, mechanistic models for cholera epidemics have been successfully applied to several epidemics including, the one that struck Haiti in late 2010 and is still ongoing. Calibration and parameter estimation of such models represents a major challenge because of properties unusual in traditional geoscientific domains such as hydrology. Firstly, the epidemiological data available might be subject to high uncertainties due to error-prone diagnosis as well as manual (and possibly incomplete) data collection. Secondly, long-term time-series of epidemiological data are often unavailable. Finally, the spatially explicit character of the models requires the comparison of several time-series of model outputs with their real-world counterparts, which calls for an appropriate weighting scheme. It follows that the usual assumption of a homoscedastic Gaussian error distribution, used in combination with classical calibration techniques based on Markov chain Monte Carlo algorithms, is likely to be violated, whereas the construction of an appropriate formal likelihood function seems close to impossible. Alternative calibration methods, which allow for accurate estimation of total model uncertainty, particularly regarding the envisaged use of the models for decision-making, are thus needed. Here we present the most recent developments regarding methods for parameter and uncertainty estimation to be used with our mechanistic, spatially explicit models for cholera epidemics, based on informal measures of goodness of fit.\n\nParameter Estimation with Almost No Public Communication for Continuous-Variable Quantum Key Distribution\n\nNASA Astrophysics Data System (ADS)\n\nLupo, Cosmo; Ottaviani, Carlo; Papanastasiou, Panagiotis; Pirandola, Stefano\n\n2018-06-01\n\nOne crucial step in any quantum key distribution (QKD) scheme is parameter estimation. In a typical QKD protocol the users have to sacrifice part of their raw data to estimate the parameters of the communication channel as, for example, the error rate. This introduces a trade-off between the secret key rate and the accuracy of parameter estimation in the finite-size regime. Here we show that continuous-variable QKD is not subject to this constraint as the whole raw keys can be used for both parameter estimation and secret key generation, without compromising the security. First, we show that this property holds for measurement-device-independent (MDI) protocols, as a consequence of the fact that in a MDI protocol the correlations between Alice and Bob are postselected by the measurement performed by an untrusted relay. This result is then extended beyond the MDI framework by exploiting the fact that MDI protocols can simulate device-dependent one-way QKD with arbitrarily high precision.\n\nTurboelectric Aircraft Drive Key Performance Parameters and Functional Requirements\n\nNASA Technical Reports Server (NTRS)\n\nJansen, Ralph H.; Brown, Gerald V.; Felder, James L.; Duffy, Kirsten P.\n\n2016-01-01\n\nThe purpose of this paper is to propose specific power and efficiency as the key performance parameters for a turboelectric aircraft power system and investigate their impact on the overall aircraft. Key functional requirements are identified that impact the power system design. Breguet range equations for a base aircraft and a turboelectric aircraft are found. The benefits and costs that may result from the turboelectric system are enumerated. A break-even analysis is conducted to find the minimum allowable electric drive specific power and efficiency that can preserve the range, initial weight, operating empty weight, and payload weight of the base aircraft.\n\nTurboelectric Aircraft Drive Key Performance Parameters and Functional Requirements\n\nNASA Technical Reports Server (NTRS)\n\nJansen, Ralph; Brown, Gerald V.; Felder, James L.; Duffy, Kirsten P.\n\n2015-01-01\n\nThe purpose of this presentation is to propose specific power and efficiency as the key performance parameters for a turboelectric aircraft power system and investigate their impact on the overall aircraft. Key functional requirements are identified that impact the power system design. Breguet range equations for a base aircraft and a turboelectric aircraft are found. The benefits and costs that may result from the turboelectric system are enumerated. A break-even analysis is conducted to find the minimum allowable electric drive specific power and efficiency that can preserve the range, initial weight, operating empty weight, and payload weight of the base aircraft.\n\nTurboelectric Aircraft Drive Key Performance Parameters and Functional Requirements\n\nNASA Technical Reports Server (NTRS)\n\nJansen, Ralph H.; Brown, Gerald V.; Felder, James L.; Duffy, Kirsten P.\n\n2015-01-01\n\nThe purpose of this paper is to propose specific power and efficiency as the key performance parameters for a turboelectric aircraft power system and investigate their impact on the overall aircraft. Key functional requirements are identified that impact the power system design. Breguet range equations for a base aircraft and a turboelectric aircraft are found. The benefits and costs that may result from the turboelectric system are enumerated. A break-even analysis is conducted to find the minimum allowable electric drive specific power and efficiency that can preserve the range, initial weight, operating empty weight, and payload weight of the base aircraft.\n\nBridging the data gaps in the epidemiology of hepatitis C virus infection in Malaysia using multi-parameter evidence synthesis.\n\nPubMed\n\nMcDonald, Scott A; Mohamed, Rosmawati; Dahlui, Maznah; Naning, Herlianna; Kamarulzaman, Adeeba\n\n2014-11-07\n\nCollecting adequate information on key epidemiological indicators is a prerequisite to informing a public health response to reduce the impact of hepatitis C virus (HCV) infection in Malaysia. Our goal was to overcome the acute data shortage typical of low/middle income countries using statistical modelling to estimate the national HCV prevalence and the distribution over transmission pathways as of the end of 2009. Multi-parameter evidence synthesis methods were applied to combine all available relevant data sources - both direct and indirect - that inform the epidemiological parameters of interest. An estimated 454,000 (95% credible interval [CrI]: 392,000 to 535,000) HCV antibody-positive individuals were living in Malaysia in 2009; this represents 2.5% (95% CrI: 2.2-3.0%) of the population aged 15-64 years. Among males of Malay ethnicity, for 77% (95% CrI: 69-85%) the route of probable transmission was active or a previous history of injecting drugs. The corresponding proportions were smaller for male Chinese and Indian/other ethnic groups (40% and 71%, respectively). The estimated prevalence in females of all ethnicities was 1% (95% CrI: 0.6 to 1.4%); 92% (95% CrI: 88 to 95%) of infections were attributable to non-drug injecting routes of transmission. The prevalent number of persons living with HCV infection in Malaysia is estimated to be very high. Low/middle income countries often lack a comprehensive evidence base; however, evidence synthesis methods can assist in filling the data gaps required for the development of effective policy to address the future public health and economic burden due to HCV.\n\nImproving the Linkages between Air Pollution Epidemiology and Quantitative Risk Assessment\n\nPubMed Central\n\nBell, Michelle L.; Walker, Katy; Hubbell, Bryan\n\n2011-01-01\n\nBackground: Air pollution epidemiology plays an integral role in both identifying the hazards of air pollution as well as supplying the risk coefficients that are used in quantitative risk assessments. Evidence from both epidemiology and risk assessments has historically supported critical environmental policy decisions. The extent to which risk assessors can properly specify a quantitative risk assessment and characterize key sources of uncertainty depends in part on the availability, and clarity, of data and assumptions in the epidemiological studies. Objectives: We discuss the interests shared by air pollution epidemiology and risk assessment communities in ensuring that the findings of epidemiological studies are appropriately characterized and applied correctly in risk assessments. We highlight the key input parameters for risk assessments and consider how modest changes in the characterization of these data might enable more accurate risk assessments that better represent the findings of epidemiological studies. Discussion: We argue that more complete information regarding the methodological choices and input data used in epidemiological studies would support more accurate risk assessmentsâto the benefit of both disciplines. In particular, we suggest including additional details regarding air quality, demographic, and health data, as well as certain types of data-rich graphics. Conclusions: Relatively modest changes to the data reported in epidemiological studies will improve the quality of risk assessments and help prevent the misinterpretation and mischaracterization of the results of epidemiological studies. Such changes may also benefit epidemiologists undertaking meta-analyses. We suggest workshops as a way to improve the dialogue between the two communities. PMID:21816702\n\nKey parameters controlling the performance of catalytic motors\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nEsplandiu, Maria J.; Afshar Farniya, Ali; Reguera, David, E-mail: dreguera@ub.edu\n\n2016-03-28\n\nThe development of autonomous micro/nanomotors driven by self-generated chemical gradients is a topic of high interest given their potential impact in medicine and environmental remediation. Although impressive functionalities of these devices have been demonstrated, a detailed understanding of the propulsion mechanism is still lacking. In this work, we perform a comprehensive numerical analysis of the key parameters governing the actuation of bimetallic catalytic micropumps. We show that the fluid motion is driven by self-generated electro-osmosis where the electric field originates by a proton current rather than by a lateral charge asymmetry inside the double layer. Hence, the surface potential andmoreÂ Â» the electric field are the key parameters for setting the pumping strength and directionality. The proton flux that generates the electric field stems from the proton gradient induced by the electrochemical reactions taken place at the pump. Surprisingly the electric field and consequently the fluid flow are mainly controlled by the ionic strength and not by the conductivity of the solution, as one could have expected. We have also analyzed the influence of the chemical fuel concentration, electrochemical reaction rates, and size of the metallic structures for an optimized pump performance. Our findings cast light on the complex chemomechanical actuation of catalytic motors and provide important clues for the search, design, and optimization of novel catalytic actuators.Â«Â less\n\nKey parameters controlling the performance of catalytic motors.\n\nPubMed\n\nEsplandiu, Maria J; Afshar Farniya, Ali; Reguera, David\n\n2016-03-28\n\nThe development of autonomous micro/nanomotors driven by self-generated chemical gradients is a topic of high interest given their potential impact in medicine and environmental remediation. Although impressive functionalities of these devices have been demonstrated, a detailed understanding of the propulsion mechanism is still lacking. In this work, we perform a comprehensive numerical analysis of the key parameters governing the actuation of bimetallic catalytic micropumps. We show that the fluid motion is driven by self-generated electro-osmosis where the electric field originates by a proton current rather than by a lateral charge asymmetry inside the double layer. Hence, the surface potential and the electric field are the key parameters for setting the pumping strength and directionality. The proton flux that generates the electric field stems from the proton gradient induced by the electrochemical reactions taken place at the pump. Surprisingly the electric field and consequently the fluid flow are mainly controlled by the ionic strength and not by the conductivity of the solution, as one could have expected. We have also analyzed the influence of the chemical fuel concentration, electrochemical reaction rates, and size of the metallic structures for an optimized pump performance. Our findings cast light on the complex chemomechanical actuation of catalytic motors and provide important clues for the search, design, and optimization of novel catalytic actuators.\n\nEpidemiologic and clinical parameters of West Nile virus infections in humans: a scoping review.\n\nPubMed\n\nYeung, Man Wah; Shing, Emily; Nelder, Mark; Sander, Beate\n\n2017-09-06\n\nClinical syndromes associated with West Nile virus (WNV) infection range from fever to neuroinvasive disease. Understanding WNV epidemiology and disease history is important for guiding patient care and healthcare decision-making. The objective of this review was to characterize the existing body of peer-reviewed and surveillance literature on WNV syndromes and summarize epidemiologic and clinical parameters. We followed scoping review methodology described by the Joanna Briggs Institute. Terms related to WNV epidemiology, hospitalization, and surveillance were searched in four bibliographic databases (MEDLINE, EMBASE, Scopus, and CINAHL) for literature published from January 1999 to December 2015. In total, 2334 non-duplicated titles and abstracts were screened; 92 primary studies were included in the review. Publications included one randomized controlled trial and 91 observational studies. Sample sizes ranged from under 25 patients (nâ=â19) to over 400 patients (nâ=â28). Eight studies were from Canada, seven from Israel, and the remaining (nâ=â77) from the United States. Nâ=â17 studies were classified as outbreak case investigations following epidemics; nâ=â37 with results of regional/national surveillance and monitoring programs. Mean patient ages were >â40Â years old; three studies (3%) focused on the pediatric population. Patients with encephalitis fared worse than patients with meningitis and fever, considering hospitalization, length of stay, discharge, recovery, and case-fatality. Several studies examined risk factors; however, age was the only risk factor for neuroinvasive disease/death consistently identified. Overall, patients with acute flaccid paralysis or encephalitis fared worse than patients with meningitis and West Nile fever in terms of hospitalization and mortality. Among the included studies, proportion hospitalized, length of stay, proportion discharged home and case-fatality ranged considerably. Our review highlights the\n\n[How to write high-quality epidemiological research paper â ¥. Strengthening the Reporting of Observational Studies in Epidemiology-Nutritional Epidemiology (STROBE-nut)].\n\nPubMed\n\nDing, C Y; Cao, Y; Yang, C; Sun, F; Zhan, S Y\n\n2017-01-10\n\nConcerns have been raised about the reporting quality in nutritional epidemiology. Therefore, strengthening the reporting of observational studies in epidemiology-nutritional epidemiology (STROBE-nut) has been proposed by extending the STROBE statement to include additional recommendations on issues related to nutritional epidemiology and dietary assessment, aiming to provide more specific guidelines on how to report observational research in the field. This paper presents a brief introduction to STROBE-nut and also an explanation of the key points in the additional items, with an example illustrating the application of the checklist.\n\nCalculations of key magnetospheric parameters using the isotropic and anisotropic SPSU global MHD code\n\nNASA Astrophysics Data System (ADS)\n\nSamsonov, Andrey; Gordeev, Evgeny; Sergeev, Victor\n\n2017-04-01\n\nAs it was recently suggested (e.g., Gordeev et al., 2015), the global magnetospheric configuration can be characterized by a set of key parameters, such as the magnetopause distance at the subsolar point and on the terminator plane, the magnetic field in the magnetotail lobe and the plasma sheet thermal pressure, the cross polar cap electric potential drop and the total field-aligned current. For given solar wind conditions, the values of these parameters can be obtained from both empirical models and global MHD simulations. We validate the recently developed global MHD code SPSU-16 using the key magnetospheric parameters mentioned above. The code SPSU-16 can calculate both the isotropic and anisotropic MHD equations. In the anisotropic version, we use the modified double-adiabatic equations in which the Tâ¥/Tâ¥ (the ratio of perpendicular to parallel thermal pressures) has been bounded from above by the mirror and ion-cyclotron thresholds and from below by the firehose threshold. The results of validation for the SPSU-16 code well agree with the previously published results of other global codes. Some key parameters coincide in the isotropic and anisotropic MHD simulations, but some are different.\n\nPartially Turboelectric Aircraft Drive Key Performance Parameters\n\nNASA Technical Reports Server (NTRS)\n\nJansen, Ralph H.; Duffy, Kirsten P.; Brown, Gerald V.\n\n2017-01-01\n\nThe purpose of this paper is to propose electric drive specific power, electric drive efficiency, and electrical propulsion fraction as the key performance parameters for a partially turboelectric aircraft power system and to investigate their impact on the overall aircraft performance. Breguet range equations for a base conventional turbofan aircraft and a partially turboelectric aircraft are found. The benefits and costs that may result from the partially turboelectric system are enumerated. A break even analysis is conducted to find the minimum allowable electric drive specific power and efficiency, for a given electrical propulsion fraction, that can preserve the range, fuel weight, operating empty weight, and payload weight of the conventional aircraft. Current and future power system performance is compared to the required performance to determine the potential benefit.\n\nChannel-parameter estimation for satellite-to-submarine continuous-variable quantum key distribution\n\nNASA Astrophysics Data System (ADS)\n\nGuo, Ying; Xie, Cailang; Huang, Peng; Li, Jiawei; Zhang, Ling; Huang, Duan; Zeng, Guihua\n\n2018-05-01\n\nThis paper deals with a channel-parameter estimation for continuous-variable quantum key distribution (CV-QKD) over a satellite-to-submarine link. In particular, we focus on the channel transmittances and the excess noise which are affected by atmospheric turbulence, surface roughness, zenith angle of the satellite, wind speed, submarine depth, etc. The estimation method is based on proposed algorithms and is applied to low-Earth orbits using the Monte Carlo approach. For light at 550 nm with a repetition frequency of 1 MHz, the effects of the estimated parameters on the performance of the CV-QKD system are assessed by a simulation by comparing the secret key bit rate in the daytime and at night. Our results show the feasibility of satellite-to-submarine CV-QKD, providing an unconditionally secure approach to achieve global networks for underwater communications.\n\nKey parameters design of an aerial target detection system on a space-based platform\n\nNASA Astrophysics Data System (ADS)\n\nZhu, Hanlu; Li, Yejin; Hu, Tingliang; Rao, Peng\n\n2018-02-01\n\nTo ensure flight safety of an aerial aircraft and avoid recurrence of aircraft collisions, a method of multi-information fusion is proposed to design the key parameter to realize aircraft target detection on a space-based platform. The key parameters of a detection wave band and spatial resolution using the target-background absolute contrast, target-background relative contrast, and signal-to-clutter ratio were determined. This study also presented the signal-to-interference ratio for analyzing system performance. Key parameters are obtained through the simulation of a specific aircraft. And the simulation results show that the boundary ground sampling distance is 30 and 35 m in the mid- wavelength infrared (MWIR) and long-wavelength infrared (LWIR) bands for most aircraft detection, and the most reasonable detection wavebands is 3.4 to 4.2 Î¼m and 4.35 to 4.5 Î¼m in the MWIR bands, and 9.2 to 9.8 Î¼m in the LWIR bands. We also found that the direction of detection has a great impact on the detection efficiency, especially in MWIR bands.\n\nTriangulation in aetiological epidemiology.\n\nPubMed\n\nLawlor, Debbie A; Tilling, Kate; Davey Smith, George\n\n2016-12-01\n\nTriangulation is the practice of obtaining more reliable answers to research questions through integrating results from several different approaches, where each approach has different key sources of potential bias that are unrelated to each other. With respect to causal questions in aetiological epidemiology, if the results of different approaches all point to the same conclusion, this strengthens confidence in the finding. This is particularly the case when the key sources of bias of some of the approaches would predict that findings would point in opposite directions if they were due to such biases. Where there are inconsistencies, understanding the key sources of bias of each approach can help to identify what further research is required to address the causal question. The aim of this paper is to illustrate how triangulation might be used to improve causal inference in aetiological epidemiology. We propose a minimum set of criteria for use in triangulation in aetiological epidemiology, summarize the key sources of bias of several approaches and describe how these might be integrated within a triangulation framework. We emphasize the importance of being explicit about the expected direction of bias within each approach, whenever this is possible, and seeking to identify approaches that would be expected to bias the true causal effect in different directions. We also note the importance, when comparing results, of taking account of differences in the duration and timing of exposures. We provide three examples to illustrate these points. Â© The Author 2017. Published by Oxford University Press on behalf of the International Epidemiological Association.\n\nCancer Epidemiology Cohorts\n\nCancer.gov\n\nCohort studies are fundamental for epidemiological research by helping researchers better understand the etiology of cancer and provide insights into the key determinants of this disease and its outcomes.\n\nAgainst Popperized epidemiology.\n\nPubMed\n\nJacobsen, M\n\n1976-03-01\n\nThe recommendation of Popper's philosophy of science should be adopted by epidemiologists is disputed. Reference is made to other authors who have shown that the most constructive elements in Popper's ideas have been advocated by earlier philosophers and have been used in epidemiology without abandoning inductive reasoning. It is argued that Popper's denigration of inductive methods is particularly harmful to epidemiology. Inductive reasoning and statistical inference play a key role in the science; it is suggested that unfamiliarity with these ideas contributes to widespread misunderstanding of the function of epidemiology. Attention is drawn to a common fallacy involving correlations between three random variables. The prevalence of the fallacy may be related to confusion between deductive and inductive logic.\n\nTriangulation in aetiological epidemiology\n\nPubMed Central\n\nLawlor, Debbie A; Tilling, Kate; Davey Smith, George\n\n2016-01-01\n\nAbstract Triangulation is the practice of obtaining more reliable answers to research questions through integrating results from several different approaches, where each approach has different key sources of potential bias that are unrelated to each other. With respect to causal questions in aetiological epidemiology, if the results of different approaches all point to the same conclusion, this strengthens confidence in the finding. This is particularly the case when the key sources of bias of some of the approaches would predict that findings would point in opposite directions if they were due to such biases. Where there are inconsistencies, understanding the key sources of bias of each approach can help to identify what further research is required to address the causal question. The aim of this paper is to illustrate how triangulation might be used to improve causal inference in aetiological epidemiology. We propose a minimum set of criteria for use in triangulation in aetiological epidemiology, summarize the key sources of bias of several approaches and describe how these might be integrated within a triangulation framework. We emphasize the importance of being explicit about the expected direction of bias within each approach, whenever this is possible, and seeking to identify approaches that would be expected to bias the true causal effect in different directions. We also note the importance, when comparing results, of taking account of differences in the duration and timing of exposures. We provide three examples to illustrate these points. PMID:28108528\n\nAn Immuno-epidemiological Model of Paratuberculosis\n\nNASA Astrophysics Data System (ADS)\n\nMartcheva, M.\n\n2011-11-01\n\nThe primary objective of this article is to introduce an immuno-epidemiological model of paratuberculosis (Johne's disease). To develop the immuno-epidemiological model, we first develop an immunological model and an epidemiological model. Then, we link the two models through time-since-infection structure and parameters of the epidemiological model. We use the nested approach to compose the immuno-epidemiological model. Our immunological model captures the switch between the T-cell immune response and the antibody response in Johne's disease. The epidemiological model is a time-since-infection model and captures the variability of transmission rate and the vertical transmission of the disease. We compute the immune-response-dependent epidemiological reproduction number. Our immuno-epidemiological model can be used for investigation of the impact of the immune response on the epidemiology of Johne's disease.\n\nCriticality in epidemiology\n\nNASA Astrophysics Data System (ADS)\n\nStollenwerk, Nico; Jansen, Vincent A. A.\n\nFor a long time criticality has been considered in epidemiological models. We review the body of theory developed over the last twenty five years for the simplest models. It is at first glance difficult to imagine that an epidemiological system operates at a very fine tuned critical state as opposed to any other parameter region. However, the advent of self-organized criticality has given hints in how to interpret large fluctuations observed in many natural systems including epidemiological systems. We show some scenarios where criticality has been observed (e.g., measles under vaccination) and where evolution towards a critical state can explain fluctuations (e.g., meningococcal disease.)\n\nA Systematic Bayesian Integration of Epidemiological and Genetic Data\n\nPubMed Central\n\nLau, Max S. Y.; Marion, Glenn; Streftaris, George; Gibson, Gavin\n\n2015-01-01\n\nGenetic sequence data on pathogens have great potential to inform inference of their transmission dynamics ultimately leading to better disease control. Where genetic change and disease transmission occur on comparable timescales additional information can be inferred via the joint analysis of such genetic sequence data and epidemiological observations based on clinical symptoms and diagnostic tests. Although recently introduced approaches represent substantial progress, for computational reasons they approximate genuine joint inference of disease dynamics and genetic change in the pathogen population, capturing partially the joint epidemiological-evolutionary dynamics. Improved methods are needed to fully integrate such genetic data with epidemiological observations, for achieving a more robust inference of the transmission tree and other key epidemiological parameters such as latent periods. Here, building on current literature, a novel Bayesian framework is proposed that infers simultaneously and explicitly the transmission tree and unobserved transmitted pathogen sequences. Our framework facilitates the use of realistic likelihood functions and enables systematic and genuine joint inference of the epidemiological-evolutionary process from partially observed outbreaks. Using simulated data it is shown that this approach is able to infer accurately joint epidemiological-evolutionary dynamics, even when pathogen sequences and epidemiological data are incomplete, and when sequences are available for only a fraction of exposures. These results also characterise and quantify the value of incomplete and partial sequence data, which has important implications for sampling design, and demonstrate the abilities of the introduced method to identify multiple clusters within an outbreak. The framework is used to analyse an outbreak of foot-and-mouth disease in the UK, enhancing current understanding of its transmission dynamics and evolutionary process. PMID:26599399\n\nPrediction of Geomagnetic Activity and Key Parameters in High-Latitude Ionosphere-Basic Elements\n\nNASA Technical Reports Server (NTRS)\n\nLyatsky, W.; Khazanov, G. V.\n\n2007-01-01\n\nPrediction of geomagnetic activity and related events in the Earth's magnetosphere and ionosphere is an important task of the Space Weather program. Prediction reliability is dependent on the prediction method and elements included in the prediction scheme. Two main elements are a suitable geomagnetic activity index and coupling function -- the combination of solar wind parameters providing the best correlation between upstream solar wind data and geomagnetic activity. The appropriate choice of these two elements is imperative for any reliable prediction model. The purpose of this work was to elaborate on these two elements -- the appropriate geomagnetic activity index and the coupling function -- and investigate the opportunity to improve the reliability of the prediction of geomagnetic activity and other events in the Earth's magnetosphere. The new polar magnetic index of geomagnetic activity and the new version of the coupling function lead to a significant increase in the reliability of predicting the geomagnetic activity and some key parameters, such as cross-polar cap voltage and total Joule heating in high-latitude ionosphere, which play a very important role in the development of geomagnetic and other activity in the Earth s magnetosphere, and are widely used as key input parameters in modeling magnetospheric, ionospheric, and thermospheric processes.\n\nModelling the effect of heterogeneity of shedding on the within herd Coxiella burnetii spread and identification of key parameters by sensitivity analysis.\n\nPubMed\n\nCourcoul, AurÃ©lie; Monod, HervÃ©; Nielen, Mirjam; Klinkenberg, Don; Hogerwerf, Lenny; Beaudeau, FranÃ§ois; Vergu, Elisabeta\n\n2011-09-07\n\nCoxiella burnetii is the bacterium responsible for Q fever, a worldwide zoonosis. Ruminants, especially cattle, are recognized as the most important source of human infections. Although a great heterogeneity between shedder cows has been described, no previous studies have determined which features such as shedding route and duration or the quantity of bacteria shed have the strongest impact on the environmental contamination and thus on the zoonotic risk. Our objective was to identify key parameters whose variation highly influences C. burnetii spread within a dairy cattle herd, especially those related to the heterogeneity of shedding. To compare the impact of epidemiological parameters on different dynamical aspects of C. burnetii infection, we performed a sensitivity analysis on an original stochastic model describing the bacterium spread and representing the individual variability of the shedding duration, routes and intensity as well as herd demography. This sensitivity analysis consisted of a principal component analysis followed by an ANOVA. Our findings show that the most influential parameters are the probability distribution governing the levels of shedding, especially in vaginal mucus and faeces, the characteristics of the bacterium in the environment (i.e. its survival and the fraction of bacteria shed reaching the environment), and some physiological parameters related to the intermittency of shedding (transition probability from a non-shedding infected state to a shedding state) or to the transition from one type of shedder to another one (transition probability from a seronegative shedding state to a seropositive shedding state). Our study is crucial for the understanding of the dynamics of C. burnetii infection and optimization of control measures. Indeed, as control measures should impact the parameters influencing the bacterium spread most, our model can now be used to assess the effectiveness of different control strategies of Q fever within\n\n[Scientific, practical and educational aspects of clinical epidemiology].\n\nPubMed\n\nBriko, N I\n\n2012-01-01\n\nThis article defines clinical epidemiology and describes its goal and objectives. The author claims that clinical epidemiology is a section of epidemiology which underlies the development of evidence-based standards for diagnostics, treatment and prevention and helps to select the appropriate algorithm for each clinical case. The study provides a comprehensive overview of the relationship between clinical epidemiology and evidence-based medicine. Epidemiological research is shown to be methodological basis of clinical epidemiology and evidence-based medicine with randomized controlled trials being the \"gold standard\" for obtaining reliable data. The key stages in the history of clinical epidemiology are discussed and further development of clinical epidemiology and the integration of courses on clinical epidemiology in education is outlined for progress in medical research and health care practice.\n\nMeasuring Two Key Parameters of H3 Color Centers in Diamond\n\nNASA Technical Reports Server (NTRS)\n\nRoberts, W. Thomas\n\n2005-01-01\n\nA method of measuring two key parameters of H3 color centers in diamond has been created as part of a continuing effort to develop tunable, continuous-wave, visible lasers that would utilize diamond as the lasing medium. (An H3 color center in a diamond crystal lattice comprises two nitrogen atoms substituted for two carbon atoms bonded to a third carbon atom. H3 color centers can be induced artificially; they also occur naturally. If present in sufficient density, they impart a yellow hue.) The method may also be applicable to the corresponding parameters of other candidate lasing media. One of the parameters is the number density of color centers, which is needed for designing an efficient laser. The other parameter is an optical-absorption cross section, which, as explained below, is needed for determining the number density. The present method represents an improvement over prior methods in which optical-absorption measurements have been used to determine absorption cross sections or number densities. Heretofore, in order to determine a number density from such measurements, it has been necessary to know the applicable absorption cross section; alternatively, to determine the absorption cross section from such measurements, it has been necessary to know the number density. If, as in this case, both the number density and the absorption cross section are initially unknown, then it is impossible to determine either parameter in the absence of additional information.\n\nInference of Epidemiological Dynamics Based on Simulated Phylogenies Using Birth-Death and Coalescent Models\n\nPubMed Central\n\nBoskova, Veronika; Bonhoeffer, Sebastian; Stadler, Tanja\n\n2014-01-01\n\nQuantifying epidemiological dynamics is crucial for understanding and forecasting the spread of an epidemic. The coalescent and the birth-death model are used interchangeably to infer epidemiological parameters from the genealogical relationships of the pathogen population under study, which in turn are inferred from the pathogen genetic sequencing data. To compare the performance of these widely applied models, we performed a simulation study. We simulated phylogenetic trees under the constant rate birth-death model and the coalescent model with a deterministic exponentially growing infected population. For each tree, we re-estimated the epidemiological parameters using both a birth-death and a coalescent based method, implemented as an MCMC procedure in BEAST v2.0. In our analyses that estimate the growth rate of an epidemic based on simulated birth-death trees, the point estimates such as the maximum a posteriori/maximum likelihood estimates are not very different. However, the estimates of uncertainty are very different. The birth-death model had a higher coverage than the coalescent model, i.e. contained the true value in the highest posterior density (HPD) interval more often (2â13% vs. 31â75% error). The coverage of the coalescent decreases with decreasing basic reproductive ratio and increasing sampling probability of infecteds. We hypothesize that the biases in the coalescent are due to the assumption of deterministic rather than stochastic population size changes. Both methods performed reasonably well when analyzing trees simulated under the coalescent. The methods can also identify other key epidemiological parameters as long as one of the parameters is fixed to its true value. In summary, when using genetic data to estimate epidemic dynamics, our results suggest that the birth-death method will be less sensitive to population fluctuations of early outbreaks than the coalescent method that assumes a deterministic exponentially growing infected\n\nThe Research and Implementation of Vehicle Bluetooth Hands-free Devices Key Parameters Downloading Algorithm\n\nNASA Astrophysics Data System (ADS)\n\nZhang, Xiao-bo; Wang, Zhi-xue; Li, Jian-xin; Ma, Jian-hui; Li, Yang; Li, Yan-qiang\n\nIn order to facilitate Bluetooth function realization and information can be effectively tracked in the process of production, the vehicle Bluetooth hands-free devices need to download such key parameters as Bluetooth address, CVC license and base plate numbers, etc. Therefore, it is the aim to search simple and effective methods to download parameters for each vehicle Bluetooth hands-free device, and to control and record the use of parameters. In this paper, by means of Bluetooth Serial Peripheral Interface programmer device, the parallel port is switched to SPI. The first step is to download parameters is simulating SPI with the parallel port. To perform SPI function, operating the parallel port in accordance with the SPI timing. The next step is to achieve SPI data transceiver functions according to the programming parameters of options. Utilizing the new method, downloading parameters is fast and accurate. It fully meets vehicle Bluetooth hands-free devices production requirements. In the production line, it has played a large role.\n\nEffect of the Key Mixture Parameters on Shrinkage of Reactive Powder Concrete\n\nPubMed Central\n\nZubair, Ahmed\n\n2014-01-01\n\nReactive powder concrete (RPC) mixtures are reported to have excellent mechanical and durability characteristics. However, such concrete mixtures having high amount of cementitious materials may have high early shrinkage causing cracking of concrete. In the present work, an attempt has been made to study the simultaneous effects of three key mixture parameters on shrinkage of the RPC mixtures. Considering three different levels of the three key mixture factors, a total of 27 mixtures of RPC were prepared according to 33 factorial experiment design. The specimens belonging to all 27 mixtures were monitored for shrinkage at different ages over a total period of 90 days. The test results were plotted to observe the variation of shrinkage with time and to see the effects of the key mixture factors. The experimental data pertaining to 90-day shrinkage were used to conduct analysis of variance to identify significance of each factor and to obtain an empirical equation correlating the shrinkage of RPC with the three key mixture factors. The rate of development of shrinkage at early ages was higher. The water to binder ratio was found to be the most prominent factor followed by cement content with the least effect of silica fume content. PMID:25050395\n\nEffect of the key mixture parameters on shrinkage of reactive powder concrete.\n\nPubMed\n\nAhmad, Shamsad; Zubair, Ahmed; Maslehuddin, Mohammed\n\n2014-01-01\n\nReactive powder concrete (RPC) mixtures are reported to have excellent mechanical and durability characteristics. However, such concrete mixtures having high amount of cementitious materials may have high early shrinkage causing cracking of concrete. In the present work, an attempt has been made to study the simultaneous effects of three key mixture parameters on shrinkage of the RPC mixtures. Considering three different levels of the three key mixture factors, a total of 27 mixtures of RPC were prepared according to 3(3) factorial experiment design. The specimens belonging to all 27 mixtures were monitored for shrinkage at different ages over a total period of 90 days. The test results were plotted to observe the variation of shrinkage with time and to see the effects of the key mixture factors. The experimental data pertaining to 90-day shrinkage were used to conduct analysis of variance to identify significance of each factor and to obtain an empirical equation correlating the shrinkage of RPC with the three key mixture factors. The rate of development of shrinkage at early ages was higher. The water to binder ratio was found to be the most prominent factor followed by cement content with the least effect of silica fume content.\n\nInvited commentary: do-it-yourself modern epidemiology--at last!\n\nPubMed\n\nMorabia, Alfredo\n\n2014-10-01\n\nIn this issue of the Journal, Keyes and Galea (Am J Epidemiol. 2014;180(7):661-668) propose \"7 foundational steps\" for introducing epidemiologic methods and concepts to beginners. Keyes and Galea's credo is that the methododological and conceptual components that comprise epidemiology, today scattered in textbook chapters, come together as an integrated and coherent methodological corpus in the process of designing studies. Thus, they expound, the process of designing studies should be the core of teaching epidemiology. Two aspects of their 7-steps-to-epidemiology, do-it-yourself user manual stand out as novel: 1) the approach, because of its emphasis on modern epidemiology's causal framework of a dynamic population in a steady state evolving across time, and 2) the ambition to teach modern epidemiology in introductory courses, instead of the popular mix of classical and modern epidemiology that is often used today to keep introductory courses simple. Both aspects are of potentially great significance for our discipline. Â© The Author 2014. Published by Oxford University Press on behalf of the Johns Hopkins Bloomberg School of Public Health. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.\n\nSequential weighted Wiener estimation for extraction of key tissue parameters in color imaging: a phantom study\n\nNASA Astrophysics Data System (ADS)\n\nChen, Shuo; Lin, Xiaoqian; Zhu, Caigang; Liu, Quan\n\n2014-12-01\n\nKey tissue parameters, e.g., total hemoglobin concentration and tissue oxygenation, are important biomarkers in clinical diagnosis for various diseases. Although point measurement techniques based on diffuse reflectance spectroscopy can accurately recover these tissue parameters, they are not suitable for the examination of a large tissue region due to slow data acquisition. The previous imaging studies have shown that hemoglobin concentration and oxygenation can be estimated from color measurements with the assumption of known scattering properties, which is impractical in clinical applications. To overcome this limitation and speed-up image processing, we propose a method of sequential weighted Wiener estimation (WE) to quickly extract key tissue parameters, including total hemoglobin concentration (CtHb), hemoglobin oxygenation (StO2), scatterer density (Î±), and scattering power (Î²), from wide-band color measurements. This method takes advantage of the fact that each parameter is sensitive to the color measurements in a different way and attempts to maximize the contribution of those color measurements likely to generate correct results in WE. The method was evaluated on skin phantoms with varying CtHb, StO2, and scattering properties. The results demonstrate excellent agreement between the estimated tissue parameters and the corresponding reference values. Compared with traditional WE, the sequential weighted WE shows significant improvement in the estimation accuracy. This method could be used to monitor tissue parameters in an imaging setup in real time.\n\nUsing a Functional Simulation of Crisis Management to Test the C2 Agility Model Parameters on Key Performance Variables\n\nDTIC Science & Technology\n\n2013-06-01\n\n1 18th ICCRTS Using a Functional Simulation of Crisis Management to Test the C2 Agility Model Parameters on Key Performance Variables...AND SUBTITLE Using a Functional Simulation of Crisis Management to Test the C2 Agility Model Parameters on Key Performance Variables 5a. CONTRACT...command in crisis management. C2 Agility Model Agility can be conceptualized at a number of different levels; for instance at the team\n\nDetermination of key parameters of vector multifractal vector fields\n\nNASA Astrophysics Data System (ADS)\n\nSchertzer, D. J. M.; Tchiguirinskaia, I.\n\n2017-12-01\n\nFor too long time, multifractal analyses and simulations have been restricted to scalar-valued fields (Schertzer and Tchiguirinskaia, 2017a,b). For instance, the wind velocity multifractality has been mostly analysed in terms of scalar structure functions and with the scalar energy flux. This restriction has had the unfortunate consequences that multifractals were applicable to their full extent in geophysics, whereas it has inspired them. Indeed a key question in geophysics is the complexity of the interactions between various fields or they components. Nevertheless, sophisticated methods have been developed to determine the key parameters of scalar valued fields. In this communication, we first present the vector extensions of the universal multifractal analysis techniques to multifractals whose generator belong to a Levy-Clifford algebra (Schertzer and Tchiguirinskaia, 2015). We point out further extensions noting the increased complexity. For instance, the (scalar) index of multifractality becomes a matrice. Schertzer, D. and Tchiguirinskaia, I. (2015) `Multifractal vector fields and stochastic Clifford algebra', Chaos: An Interdisciplinary Journal of Nonlinear Science, 25(12), p. 123127. doi: 10.1063/1.4937364. Schertzer, D. and Tchiguirinskaia, I. (2017) `An Introduction to Multifractals and Scale Symmetry Groups', in Ghanbarian, B. and Hunt, A. (eds) Fractals: Concepts and Applications in Geosciences. CRC Press, p. (in press). Schertzer, D. and Tchiguirinskaia, I. (2017b) `Pandora Box of Multifractals: Barely Open ?', in Tsonis, A. A. (ed.) 30 Years of Nonlinear Dynamics in Geophysics. Berlin: Springer, p. (in press).\n\nParameter optimization in biased decoy-state quantum key distribution with both source errors and statistical fluctuations\n\nNASA Astrophysics Data System (ADS)\n\nZhu, Jian-Rong; Li, Jian; Zhang, Chun-Mei; Wang, Qin\n\n2017-10-01\n\nThe decoy-state method has been widely used in commercial quantum key distribution (QKD) systems. In view of the practical decoy-state QKD with both source errors and statistical fluctuations, we propose a universal model of full parameter optimization in biased decoy-state QKD with phase-randomized sources. Besides, we adopt this model to carry out simulations of two widely used sources: weak coherent source (WCS) and heralded single-photon source (HSPS). Results show that full parameter optimization can significantly improve not only the secure transmission distance but also the final key generation rate. And when taking source errors and statistical fluctuations into account, the performance of decoy-state QKD using HSPS suffered less than that of decoy-state QKD using WCS.\n\nAssessment of chronic kidney disease using skin texture as a key parameter: for South Indian population.\n\nPubMed\n\nUdhayarasu, Madhanlal; Ramakrishnan, Kalpana; Periasamy, Soundararajan\n\n2017-12-01\n\nPeriodical monitoring of renal function, specifically for subjects with history of diabetic or hypertension would prevent them from entering into chronic kidney disease (CKD) condition. The recent increase in numbers may be due to food habits or lack of physical exercise, necessitates a rapid kidney function monitoring system. Presently, it is determined by evaluating glomerular filtration rate (GFR) that is mainly dependent on serum creatinine value and demographic parameters and ethnic value. Attempted here is to develop ethnic parameter based on skin texture for every individual. This value when used in GFR computation, the results are much agreeable with GFR obtained through standard modification of diet in renal disease and CKD epidemiology collaboration equations. Once correlation between CKD and skin texture is established, classification tool using artificial neural network is built to categorise CKD level based on demographic values and parameter obtained through skin texture (without using creatinine). This network when tested gives almost at par results with the network that is trained with demographic and creatinine values. The results of this Letter demonstrate the possibility of non-invasively determining kidney function and hence for making a device that would readily assess the kidney function even at home.\n\nKey Parameters for Operator Diagnosis of BWR Plant Condition during a Severe Accident\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nClayton, Dwight A.; Poore, III, Willis P.\n\n2015-01-01\n\nThe objective of this research is to examine the key information needed from nuclear power plant instrumentation to guide severe accident management and mitigation for boiling water reactor (BWR) designs (specifically, a BWR/4-Mark I), estimate environmental conditions that the instrumentation will experience during a severe accident, and identify potential gaps in existing instrumentation that may require further research and development. This report notes the key parameters that instrumentation needs to measure to help operators respond to severe accidents. A follow-up report will assess severe accident environmental conditions as estimated by severe accident simulation model analysis for a specific US BWR/4-MarkmoreÂ Â» I plant for those instrumentation systems considered most important for accident management purposes.Â«Â less\n\nCrop Damage by Primates: Quantifying the Key Parameters of Crop-Raiding Events\n\nPubMed Central\n\nWallace, Graham E.; Hill, Catherine M.\n\n2012-01-01\n\nHuman-wildlife conflict often arises from crop-raiding, and insights regarding which aspects of raiding events determine crop loss are essential when developing and evaluating deterrents. However, because accounts of crop-raiding behaviour are frequently indirect, these parameters are rarely quantified or explicitly linked to crop damage. Using systematic observations of the behaviour of non-human primates on farms in western Uganda, this research identifies number of individuals raiding and duration of raid as the primary parameters determining crop loss. Secondary factors include distance travelled onto farm, age composition of the raiding group, and whether raids are in series. Regression models accounted for greater proportions of variation in crop loss when increasingly crop and species specific. Parameter values varied across primate species, probably reflecting differences in raiding tactics or perceptions of risk, and thereby providing indices of how comfortable primates are on-farm. Median raiding-group sizes were markedly smaller than the typical sizes of social groups. The research suggests that key parameters of raiding events can be used to measure the behavioural impacts of deterrents to raiding. Furthermore, farmers will benefit most from methods that discourage raiding by multiple individuals, reduce the size of raiding groups, or decrease the amount of time primates are on-farm. This study demonstrates the importance of directly relating crop loss to the parameters of raiding events, using systematic observations of the behaviour of multiple primate species. PMID:23056378\n\nResilience of Key Biological Parameters of the Senegalese Flat Sardinella to Overfishing and Climate Change.\n\nPubMed\n\nBa, Kamarel; Thiaw, Modou; Lazar, Najih; Sarr, Alassane; Brochier, TimothÃ©e; Ndiaye, IsmaÃ¯la; Faye, Alioune; Sadio, Oumar; Panfili, Jacques; Thiaw, Omar Thiom; Brehmer, Patrice\n\n2016-01-01\n\nThe stock of the Senegalese flat sardinella, Sardinella maderensis, is highly exploited in Senegal, West Africa. Its growth and reproduction parameters are key biological indicators for improving fisheries management. This study reviewed these parameters using landing data from small-scale fisheries in Senegal and literature information dated back more than 25 years. Age was estimated using length-frequency data to calculate growth parameters and assess the growth performance index. With global climate change there has been an increase in the average sea surface temperature along the Senegalese coast but the length-weight parameters, sex ratio, size at first sexual maturity, period of reproduction and condition factor of S. maderensis have not changed significantly. The above parameters of S. maderensis have hardly changed, despite high exploitation and fluctuations in environmental conditions that affect the early development phases of small pelagic fish in West Africa. This lack of plasticity of the species regarding of the biological parameters studied should be considered when planning relevant fishery management plans.\n\nEpidemiology and the Tobacco Epidemic: How Research on Tobacco and Health Shaped Epidemiology.\n\nPubMed\n\nSamet, Jonathan M\n\n2016-03-01\n\nIn this article, I provide a perspective on the tobacco epidemic and epidemiology, describing the impact of the tobacco-caused disease epidemic on the field of epidemiology. Although there is an enormous body of epidemiologic evidence on the associations of smoking with health, little systematic attention has been given to how decades of research have affected epidemiology and its practice. I address the many advances that resulted from epidemiologic research on smoking and health, such as demonstration of the utility of observational designs and important parameters (the odds ratio and the population attributable risk), guidelines for causal inference, and systematic review approaches. I also cover unintended and adverse consequences for the field, including the strategy of doubt creation and the recruitment of epidemiologists by the tobacco industry to serve its mission. The paradigm of evidence-based action for addressing noncommunicable diseases began with the need to address the epidemic of tobacco-caused disease, an imperative for action documented by epidemiologic research. Â© The Author 2016. Published by Oxford University Press on behalf of the Johns Hopkins Bloomberg School of Public Health. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.\n\nRecruiting minorities into the profession of epidemiology. Surveying the applicants' mail. American College of Epidemiology Committee on Minority Affairs.\n\nPubMed\n\nMorssink, C B; Kumanyika, S; Tell, G S; Schoenbach, V J\n\n1996-01-01\n\nThe underrepresentation in epidemiology of members of racial/ethnic minority groups is greater than in medicine and health fields in general. Using printed recruitment materials, we evaluated the impression that epidemiology programs might make on prospective minority students. Mainstream recruitment materials were solicited from all identifiable U.S. epidemiology programs (n = 70) by requesting copies of typical mailings to prospective students. Of 51 respondents, 46 sent materials that could be analyzed by tabulating and evaluating minority-related content in text and pictures. Materials reflected a generally low-key approach to epidemiology student recruitment. Most minority-related text referred to affirmative action or financial aid and was at the school level rather than specific to the epidemiology programs. Few minority-related epidemiology course titles or research interests were identified. We recommend including more information about epidemiology and its relevance to minority health in mainstream recruitment materials as one possible strategy for increasing the number of minority applicants.\n\nTeaching Epidemiology at the Undergraduate Level: Considerations and Approaches.\n\nPubMed\n\nGoldmann, Emily; Stark, James H; Kapadia, Farzana; McQueen, Matthew B\n\n2018-06-01\n\nThe rapid growth in undergraduate public health education has offered training in epidemiology to an increasing number of undergraduate students. Epidemiology courses introduce undergraduate students to a population health perspective and provide opportunities for these students to build essential skills and competencies such as ethical reasoning, teamwork, comprehension of scientific methods, critical thinking, quantitative and information literacy, ability to analyze public health information, and effective writing and oral communication. Taking a varied approach and incorporating active learning and assessment strategies can help engage students in the material, improve comprehension of key concepts, and further develop key competencies. In this commentary, we present examples of how epidemiology may be taught in the undergraduate setting. Evaluation of these approaches and others would be a valuable next step.\n\nA Bayesian Framework for Coupled Estimation of Key Unknown Parameters of Land Water and Energy Balance Equations\n\nNASA Astrophysics Data System (ADS)\n\nFarhadi, L.; Abdolghafoorian, A.\n\n2015-12-01\n\nThe land surface is a key component of climate system. It controls the partitioning of available energy at the surface between sensible and latent heat, and partitioning of available water between evaporation and runoff. Water and energy cycle are intrinsically coupled through evaporation, which represents a heat exchange as latent heat flux. Accurate estimation of fluxes of heat and moisture are of significant importance in many fields such as hydrology, climatology and meteorology. In this study we develop and apply a Bayesian framework for estimating the key unknown parameters of terrestrial water and energy balance equations (i.e. moisture and heat diffusion) and their uncertainty in land surface models. These equations are coupled through flux of evaporation. The estimation system is based on the adjoint method for solving a least-squares optimization problem. The cost function consists of aggregated errors on state (i.e. moisture and temperature) with respect to observation and parameters estimation with respect to prior values over the entire assimilation period. This cost function is minimized with respect to parameters to identify models of sensible heat, latent heat/evaporation and drainage and runoff. Inverse of Hessian of the cost function is an approximation of the posterior uncertainty of parameter estimates. Uncertainty of estimated fluxes is estimated by propagating the uncertainty for linear and nonlinear function of key parameters through the method of First Order Second Moment (FOSM). Uncertainty analysis is used in this method to guide the formulation of a well-posed estimation problem. Accuracy of the method is assessed at point scale using surface energy and water fluxes generated by the Simultaneous Heat and Water (SHAW) model at the selected AmeriFlux stations. This method can be applied to diverse climates and land surface conditions with different spatial scales, using remotely sensed measurements of surface moisture and temperature states\n\nThe tale wagged by the DAG: broadening the scope of causal inference and explanation for epidemiology.\n\nPubMed\n\nKrieger, Nancy; Davey Smith, George\n\n2016-12-01\n\n'Causal inference', in 21st century epidemiology, has notably come to stand for a specific approach, one focused primarily on counterfactual and potential outcome reasoning and using particular representations, such as directed acyclic graphs (DAGs) and Bayesian causal nets. In this essay, we suggest that in epidemiology no one causal approach should drive the questions asked or delimit what counts as useful evidence. Robust causal inference instead comprises a complex narrative, created by scientists appraising, from diverse perspectives, different strands of evidence produced by myriad methods. DAGs can of course be useful, but should not alone wag the causal tale. To make our case, we first address key conceptual issues, after which we offer several concrete examples illustrating how the newly favoured methods, despite their strengths, can also: (i) limit who and what may be deemed a 'cause', thereby narrowing the scope of the field; and (ii) lead to erroneous causal inference, especially if key biological and social assumptions about parameters are poorly conceived, thereby potentially causing harm. As an alternative, we propose that the field of epidemiology consider judicious use of the broad and flexible framework of 'inference to the best explanation', an approach perhaps best developed by Peter Lipton, a philosopher of science who frequently employed epidemiologically relevant examples. This stance requires not only that we be open to being pluralists about both causation and evidence but also that we rise to the challenge of forging explanations that, in Lipton's words, aspire to 'scope, precision, mechanism, unification and simplicity'. Â© The Author 2016; all rights reserved. Published by Oxford University Press on behalf of the International Epidemiological Association.\n\nA systemic study on key parameters affecting nanocomposite coatings on magnesium substrates.\n\nPubMed\n\nJohnson, Ian; Wang, Sebo Michelle; Silken, Christine; Liu, Huinan\n\n2016-05-01\n\nNanocomposite coatings offer multiple functions simultaneously to improve the interfacial properties of magnesium (Mg) alloys for skeletal implant applications, e.g., controlling the degradation rate of Mg substrates, improving bone cell functions, and providing drug delivery capability. However, the effective service time of nanocomposite coatings may be limited due to their early delamination from the Mg-based substrates. Therefore, the objective of this study was to address the delamination issue of nanocomposite coatings, improve the coating properties for reducing the degradation of Mg-based substrates, and thus improve their cytocompatibility with bone marrow derived mesenchymal stem cells (BMSCs). The surface conditions of the substrates, polymer component type of the nanocomposite coatings, and post-deposition processing are the key parameters that contribute to the efficacy of the nanocomposite coatings in regulating substrate degradation and bone cell responses. Specifically, the effects of metallic surface versus alkaline heat-treated hydroxide surface of the substrates on coating quality were investigated. For the nanocomposite coatings, nanophase hydroxyapatite (nHA) was dispersed in three types of biodegradable polymers, i.e., poly(lactic-co-glycolic acid) (PLGA), poly(l-lactic acid) (PLLA), or poly(caprolactone) (PCL) to determine which polymer component could provide integrated properties for slowest Mg degradation. The nanocomposite coatings with or without post-deposition processing, i.e., melting, annealing, were compared to determine which processing route improved the properties of the nanocomposite coatings most significantly. The results showed that optimizing the coating processes addressed the delamination issue. The melted then annealed nHA/PCL coating on the metallic Mg substrates showed the slowest degradation and the best coating adhesion, among all the combinations of conditions studied; and, it improved the adhesion density of BMSCs\n\nEpidemiology: Then and Now.\n\nPubMed\n\nKuller, Lewis H\n\n2016-03-01\n\nTwenty-five years ago, on the 75th anniversary of the Johns Hopkins Bloomberg School of Public Health, I noted that epidemiologic research was moving away from the traditional approaches used to investigate \"epidemics\" and their close relationship with preventive medicine. Twenty-five years later, the role of epidemiology as an important contribution to human population research, preventive medicine, and public health is under substantial pressure because of the emphasis on \"big data,\" phenomenology, and personalized medical therapies. Epidemiology is the study of epidemics. The primary role of epidemiology is to identify the epidemics and parameters of interest of host, agent, and environment and to generate and test hypotheses in search of causal pathways. Almost all diseases have a specific distribution in relation to time, place, and person and specific \"causes\" with high effect sizes. Epidemiology then uses such information to develop interventions and test (through clinical trials and natural experiments) their efficacy and effectiveness. Epidemiology is dependent on new technologies to evaluate improved measurements of host (genomics), epigenetics, identification of agents (metabolomics, proteomics), new technology to evaluate both physical and social environment, and modern methods of data collection. Epidemiology does poorly in studying anything other than epidemics and collections of numerators and denominators without specific hypotheses even with improved statistical methodologies. Â© The Author 2015. Published by Oxford University Press on behalf of the Johns Hopkins Bloomberg School of Public Health. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.\n\nKey Performance Parameter Driven Technology Goals for Electric Machines and Power Systems\n\nNASA Technical Reports Server (NTRS)\n\nBowman, Cheryl; Jansen, Ralph; Brown, Gerald; Duffy, Kirsten; Trudell, Jeffrey\n\n2015-01-01\n\nTransitioning aviation to low carbon propulsion is one of the crucial strategic research thrust and is a driver in the search for alternative propulsion system for advanced aircraft configurations. This work requires multidisciplinary skills coming from multiple entities. The feasibility of scaling up various electric drive system technologies to meet the requirements of a large commercial transport is discussed in terms of key parameters. Functional requirements are identified that impact the power system design. A breakeven analysis is presented to find the minimum allowable electric drive specific power and efficiency that can preserve the range, initial weight, operating empty weight, and payload weight of the base aircraft.\n\nTurbulence study in the vicinity of piano key weir: relevance, instrumentation, parameters and methods\n\nNASA Astrophysics Data System (ADS)\n\nTiwari, Harinarayan; Sharma, Nayan\n\n2017-05-01\n\nThis research paper focuses on the need of turbulence, instruments reliable to capture turbulence, different turbulence parameters and some advance methodology which can decompose various turbulence structures at different levels near hydraulic structures. Small-scale turbulence research has valid prospects in open channel flow. The relevance of the study is amplified as we introduce any hydraulic structure in the channel which disturbs the natural flow and creates discontinuity. To recover this discontinuity, the piano key weir (PKW) might be used with sloped keys. Constraints of empirical results in the vicinity of PKW necessitate extensive laboratory experiments with fair and reliable instrumentation techniques. Acoustic Doppler velocimeter was established to be best suited within range of some limitations using principal component analysis. Wavelet analysis is proposed to decompose the underlying turbulence structure in a better way.\n\nAn animated depiction of major depression epidemiology.\n\nPubMed\n\nPatten, Scott B\n\n2007-06-08\n\nEpidemiologic estimates are now available for a variety of parameters related to major depression epidemiology (incidence, prevalence, etc.). These estimates are potentially useful for policy and planning purposes, but it is first necessary that they be synthesized into a coherent picture of the epidemiology of the condition. Several attempts to do so have been made using mathematical modeling procedures. However, this information is not easy to communicate to users of epidemiological data (clinicians, administrators, policy makers). In this study, up-to-date data on major depression epidemiology were integrated using a discrete event simulation model. The mathematical model was animated in Virtual Reality Modeling Language (VRML) to create a visual, rather than mathematical, depiction of the epidemiology. Consistent with existing literature, the model highlights potential advantages of population health strategies that emphasize access to effective long-term treatment. The paper contains a web-link to the animation. Visual animation of epidemiological results may be an effective knowledge translation tool. In clinical practice, such animations could potentially assist with patient education and enhanced long-term compliance.\n\nEpidemiological Data Management during an Outbreak of Ebola Virus Disease: Key Issues and Observations from Sierra Leone.\n\nPubMed\n\nOwada, Kei; Eckmanns, Tim; Kamara, Kande-Bure O'Bai; Olu, Olushayo Oluseun\n\n2016-01-01\n\nSierra Leone experienced intense transmission of Ebola virus disease (EVD) from May 2014 to November 2015 during which a total of 8,704 confirmed cases and over 3,589 confirmed deaths were reported. Our field observation showed many issues in the EVD data management system, which may have contributed to the magnitude and long duration of the outbreak. In this perspective article, we explain the key issues with EVD data management in the field, and the resulting obstacles in analyzing key epidemiological indicators during the outbreak response work. Our observation showed that, during the latter part of the EVD outbreak, surveillance and data management improved at all levels in the country as compared to the earlier stage. We identified incomplete filling and late arrival of the case investigation forms at data management centers, difficulties in detecting double entries and merging identified double entries in the database, and lack of clear process of how death of confirmed cases in holding, treatment, and community care centers are reported to the data centers as some of challenges to effective data management. Furthermore, there was no consolidated database that captured and linked all data sources in a structured way. We propose development of a new application tool easily adaptable to new occurrences, regular data harmonization meetings between national and district data management teams, and establishment of a data quality audit system to assure good quality data as ways to improve EVD data management during future outbreaks.\n\nPhylodynamic Inference with Kernel ABC and Its Application to HIV Epidemiology.\n\nPubMed\n\nPoon, Art F Y\n\n2015-09-01\n\nThe shapes of phylogenetic trees relating virus populations are determined by the adaptation of viruses within each host, and by the transmission of viruses among hosts. Phylodynamic inference attempts to reverse this flow of information, estimating parameters of these processes from the shape of a virus phylogeny reconstructed from a sample of genetic sequences from the epidemic. A key challenge to phylodynamic inference is quantifying the similarity between two trees in an efficient and comprehensive way. In this study, I demonstrate that a new distance measure, based on a subset tree kernel function from computational linguistics, confers a significant improvement over previous measures of tree shape for classifying trees generated under different epidemiological scenarios. Next, I incorporate this kernel-based distance measure into an approximate Bayesian computation (ABC) framework for phylodynamic inference. ABC bypasses the need for an analytical solution of model likelihood, as it only requires the ability to simulate data from the model. I validate this \"kernel-ABC\" method for phylodynamic inference by estimating parameters from data simulated under a simple epidemiological model. Results indicate that kernel-ABC attained greater accuracy for parameters associated with virus transmission than leading software on the same data sets. Finally, I apply the kernel-ABC framework to study a recent outbreak of a recombinant HIV subtype in China. Kernel-ABC provides a versatile framework for phylodynamic inference because it can fit a broader range of models than methods that rely on the computation of exact likelihoods. Â© The Author 2015. Published by Oxford University Press on behalf of the Society for Molecular Biology and Evolution.\n\nEpidemiology and causation: a realist view.\n\nPubMed Central\n\nRenton, A\n\n1994-01-01\n\nIn this paper the controversy over how to decide whether associations between factors and diseases are causal is placed within a description of the public health and scientific relevance of epidemiology. It is argued that the rise in popularity of the Popperian view of science, together with a perception of the aims of epidemiology as being to identify appropriate public health interventions, have focussed this debate on unresolved questions of inferential logic, leaving largely unanalysed the notions of causation and of disease at the ontological level. A realist ontology of causation of disease and pathogenesis is constructed within the framework of \"scientific materialism\", and is shown to provide a coherent basis from which to decide causes and to deal with problems of confounding and interaction in epidemiological research. It is argued that a realist analysis identifies a richer role for epidemiology as an integral part of an ontologically unified medical science. It is this unified medical science as a whole rather than epidemiological observation or experiment which decides causes and, in turn, provides a key element to the foundations of rational public health decision making. PMID:8138775\n\nGlossary for econometrics and epidemiology.\n\nPubMed\n\nGunasekara, F Imlach; Carter, K; Blakely, T\n\n2008-10-01\n\nEpidemiologists and econometricians are often interested in similar topics-socioeconomic position and health outcomes-but the different languages that epidemiologists and economists use to interpret and discuss their results can create a barrier to mutual communication. This glossary defines key terms used in econometrics and epidemiology to assist in bridging this gap.\n\nA key factor to the spin parameter of uniformly rotating compact stars: crust structure\n\nNASA Astrophysics Data System (ADS)\n\nQi, Bin; Zhang, Nai-Bo; Sun, Bao-Yuan; Wang, Shou-Yu; Gao, Jian-Hua\n\n2016-04-01\n\nWe study the dimensionless spin parameter j â¡ cJ/(GM2) of different kinds of uniformly rotating compact stars, including traditional neutron stars, hyperonic neutron stars and hybrid stars, based on relativistic mean field theory and the MIT bag model. It is found that jmax Ë 0.7, which had been suggested in traditional neutron stars, is sustained for hyperonic neutron stars and hybrid stars with M > 0.5 Mâ. Not the interior but rather the crust structure of the stars is a key factor to determine jmax for three kinds of selected compact stars. Furthermore, a universal formula j = 0.63(f/fK) - 0.42(f/fK)2 + 0.48(f/fK)3 is suggested to determine the spin parameter at any rotational frequency f smaller than the Keplerian frequency fK.\n\nDark energy and key physical parameters of clusters of galaxies\n\nNASA Astrophysics Data System (ADS)\n\nBisnovatyi-Kogan, G. S.; Chernin, A. D.\n\n2012-04-01\n\nWe study physics of clusters of galaxies embedded in the cosmic dark energy background. Under the assumption that dark energy is described by the cosmological constant, we show that the dynamical effects of dark energy are strong in clusters like the Virgo cluster. Specifically, the key physical parameters of the dark mater halos in clusters are determined by dark energy: (1) the halo cut-off radius is practically, if not exactly, equal to the zero-gravity radius at which the dark matter gravity is balanced by the dark energy antigravity; (2) the halo averaged density is equal to two densities of dark energy; (3) the halo edge (cut-off) density is the dark energy density with a numerical factor of the unity order slightly depending on the halo profile. The cluster gravitational potential well in which the particles of the dark halo (as well as galaxies and intracluster plasma) move is strongly affected by dark energy: the maximum of the potential is located at the zero-gravity radius of the cluster.\n\nInternational Solar-Terrestrial Program Key Parameter Visualization Tool Data: USA_NASA_DDF_ISTP_KP_0139\n\nNASA Technical Reports Server (NTRS)\n\nOcuna, M. H.; Ogilvie, K. W.; Baker, D. N.; Curtis, S. A.; Fairfield, D. H.; Mish, W. H.\n\n1999-01-01\n\nThe Global Geospace Science Program (GGS) is designed to improve greatly the understanding of the flow of energy, mass and momentum in the solar-terrestrial environment with particular emphasis on \"Geospace\". The Global Geospace Science Program is the US contribution to the International Solar-Terrestrial Physics (ISTP) Science Initiative. This CD-ROM issue describes the WIND and POLAR spacecraft, the scientific experiments carried onboard, the Theoretical and Ground Based investigations which constitute the US Global Geospace Science Program and the ISTP Data Systems which support the data acquisition and analysis effort. The International Solar-Terrestrial Physics Program (ISTP) Key Parameter Visualization Tool (KPVT), provided on the CD-ROM, was developed at the ISTP Science Planning and Operations Facility (SPOF). The KPVT is a generic software package for visualizing the key parameter data produced from all ISTP missions, interactively and simultaneously. The tool is designed to facilitate correlative displays of ISTP data from multiple spacecraft and instruments, and thus the selection of candidate events and data quality control. The software, written in IDL, includes a graphical/widget user interface, and runs on many platforms, including various UNIX workstations, Alpha/Open VMS, Macintosh (680x0 and PowerPC), and PC/Windows NT, Windows 3.1, and Windows 95.\n\nInternational Solar-Terrestrial Program Key Parameter Visualization Tool Data: USA_NASA_DDF_ISTP_KP_0192\n\nNASA Technical Reports Server (NTRS)\n\nOcuna, M. H.; Ogilvie, K. W.; Baker, D. N.; Curtis, S. A.; Fairfield, D. H.; Mish, W. H.\n\n2001-01-01\n\nThe Global Geospace Science Program (GGS) is designed to improve greatly the understanding of the flow of energy, mass and momentum in the solar-terrestrial environment with particular emphasis on \"Geospace\". The Global Geospace Science Program is the US contribution to the International Solar-Terrestrial Physics (ISTP) Science Initiative. This CD-ROM issue describes the WIND and POLAR spacecraft, the scientific experiments carried onboard, the Theoretical and Ground Based investigations which constitute the US Global Geospace Science Program and the ISTP Data Systems which support the data acquisition and analysis effort. The International Solar-Terrestrial Physics Program (ISTP) Key Parameter Visualization Tool (KPVT), provided on the CD-ROM, was developed at the ISTP Science Planning and Operations Facility (SPOF). The KPVT is a generic software package for visualizing the key parameter data produced from all ISTP missions, interactively and simultaneously. The tool is designed to facilitate correlative displays of ISTP data from multiple spacecraft and instruments, and thus the selection of candidate events and data quality control. The software, written in IDL, includes a graphical/widget user interface, and runs on many platforms, including various UNIX workstations, Alpha/Open VMS, Macintosh (680x0 and PowerPC), and PC/Windows NT, Windows 3.1, and Windows 95.\n\nThe epidemiology of pneumococcal carriage and infections in Malaysia.\n\nPubMed\n\nLe, Cheng-Foh; Jefferies, Johanna M; Yusof, Mohd Yasim Mohd; Sekaran, Shamala Devi; Clarke, Stuart C\n\n2012-06-01\n\nIn Malaysia, various aspects of the epidemiology of pneumococcal carriage and disease remain largely unclear due to the lack of supporting data. Although a number of relevant studies have been documented, their individual discrete findings are not sufficient to inform experts on pneumococcal epidemiology at a national level. Therefore, in this review we aim to bring together and systematically evaluate the key information regarding pneumococcal disease epidemiology in Malaysia and provide a comprehensive overview of the data. Major aspects discussed include pneumococcal carriage, disease incidence and prevalence, age factors, invasiveness of pneumococci, serotypes, molecular epidemiology and antibiotic susceptibility. Penicillin resistance is increasingly prevalent and studies suggest that the majority of pneumococcal serotypes causing pneumococcal disease in Malaysia are covered by currently available conjugate vaccines. Continued surveillance is needed to provide a better understanding of pneumococcal epidemiology in Malaysia.\n\nNetworks and the Epidemiology of Infectious Disease\n\nPubMed Central\n\nDanon, Leon; Ford, Ashley P.; House, Thomas; Jewell, Chris P.; Keeling, Matt J.; Roberts, Gareth O.; Ross, Joshua V.; Vernon, Matthew C.\n\n2011-01-01\n\nThe science of networks has revolutionised research into the dynamics of interacting elements. It could be argued that epidemiology in particular has embraced the potential of network theory more than any other discipline. Here we review the growing body of research concerning the spread of infectious diseases on networks, focusing on the interplay between network theory and epidemiology. The review is split into four main sections, which examine: the types of network relevant to epidemiology; the multitude of ways these networks can be characterised; the statistical methods that can be applied to infer the epidemiological parameters on a realised network; and finally simulation and analytical methods to determine epidemic dynamics on a given network. Given the breadth of areas covered and the ever-expanding number of publications, a comprehensive review of all work is impossible. Instead, we provide a personalised overview into the areas of network epidemiology that have seen the greatest progress in recent years or have the greatest potential to provide novel insights. As such, considerable importance is placed on analytical approaches and statistical methods which are both rapidly expanding fields. Throughout this review we restrict our attention to epidemiological issues. PMID:21437001\n\nEcogeographic Genetic Epidemiology\n\nPubMed Central\n\nSloan, Chantel D.; Duell, Eric J.; Shi, Xun; Irwin, Rebecca; Andrew, Angeline S.; Williams, Scott M.; Moore, Jason H.\n\n2009-01-01\n\nComplex diseases such as cancer and heart disease result from interactions between an individual's genetics and environment, i.e. their human ecology. Rates of complex diseases have consistently demonstrated geographic patterns of incidence, or spatial âclustersâ of increased incidence relative to the general population. Likewise, genetic subpopulations and environmental influences are not evenly distributed across space. Merging appropriate methods from genetic epidemiology, ecology and geography will provide a more complete understanding of the spatial interactions between genetics and environment that result in spatial patterning of disease rates. Geographic Information Systems (GIS), which are tools designed specifically for dealing with geographic data and performing spatial analyses to determine their relationship, are key to this kind of data integration. Here the authors introduce a new interdisciplinary paradigm, ecogeographic genetic epidemiology, which uses GIS and spatial statistical analyses to layer genetic subpopulation and environmental data with disease rates and thereby discern the complex gene-environment interactions which result in spatial patterns of incidence. PMID:19025788\n\nSoluble CD26 levels and its association to epidemiologic parameters in a sample population.\n\nPubMed\n\nDe Chiara, Loretta; RodrÃ­guez-PiÃ±eiro, Ana M; Cordero, Oscar J; RodrÃ­guez-Berrocal, Francisco J; Ayude, Daniel; Rivas-Hervada And, Francisco J; de la Cadena, MarÃ­a PÃ¡ez\n\n2009-01-01\n\nPrevious studies have suggested the use of soluble CD26 (sCD26) as a tumour marker for the detection of colorectal cancer (CRC) and advanced adenomas. The aim of this study was to assess the sCD26 concentration in a large cohort to evaluate its association to epidemiologic parameters and CRC-related symptoms/pathologies. Serum samples were collected from 2,754 putatively healthy individuals with ages ranging from 30-65 years, and with personal or familial history of polyps, CRC and/or CR symptoms. sCD26 levels were measured by ELISA. No association was found between the sCD26 concentration and age (< 50 and 50), the personal or familial history of polyps or CRC, rectal bleeding, haemorrhoids or diverticula. However, sCD26 was related to non-inflammatory benign pathologies (excluding rectal bleeding, changes in bowel habits, haemorrhoids, diverticula) and to inflammatory benign pathologies. Our results confirm that the sCD26 can be easily offered and evaluated in a large cohort. Additionally, the validation of sCD26 as a tumour marker for screening and case-finding purposes requires a further comparison with an established non-invasive test like the faecal occult blood.\n\nConduct Disorder and Oppositional Defiant Disorder in a National Sample: Developmental Epidemiology\n\nERIC Educational Resources Information Center\n\nMaughan, Barbara; Rowe, Richard; Messer, Julie; Goodman, Robert; Meltzer, Howard\n\n2004-01-01\n\nBackground: Despite an expanding epidemiological evidence base, uncertainties remain over key aspects of the epidemiology of the \"antisocial\" disorders in childhood and adolescence. Methods: We used cross-sectional data on a nationally representative sample of 10,438 5-15-year-olds drawn from the 1999 British Child Mental Health Surveyâ¦\n\nA Seven-Year Retrospective View of a Course in Epidemiology and Biostatistics.\n\nERIC Educational Resources Information Center\n\nMulvihill, Michael N.; And Others\n\n1980-01-01\n\nModifications of a course in epidemiology and biostatistics, designed to facilitate the presentation of difficult material in a clinically relevant manner, are described. Key strategies include seminar sessions devoted to methods of epidemiology and the critique of pairs of published studies, and the use of a course-specific syllabus. (JMD)\n\n[Eco-epidemiology: towards epidemiology of complexity].\n\nPubMed\n\nBizouarn, Philippe\n\n2016-05-01\n\nIn order to solve public health problems posed by the epidemiology of risk factors centered on the individual and neglecting the causal processes linking the risk factors with the health outcomes, Mervyn Susser proposed a multilevel epidemiology called eco-epidemiology, addressing the interdependence of individuals and their connection with molecular, individual, societal, environmental levels of organization participating in the causal disease processes. The aim of this epidemiology is to integrate more than a level of organization in design, analysis and interpretation of health problems. After presenting the main criticisms of risk-factor epidemiology focused on the individual, we will try to show how eco-epidemiology and its development could help to understand the need for a broader and integrative epidemiology, in which studies designed to identify risk factors would be balanced by studies designed to answer other questions equally vital to public health. Â© 2016 mÃ©decine/sciences â Inserm.\n\nParadigms in epidemiology textbooks: in the footsteps of Thomas Kuhn.\n\nPubMed Central\n\nBhopal, R\n\n1999-01-01\n\nThis article attempts to contribute to the debate on the future of epidemiology by combining Thomas Kuhn's ideas on scientific paradigms with the author's observations on some epidemiology textbooks. The author's interpretations were based on his readings of Kuhn's The Structure of Scientific Revolutions, epidemiology textbooks, and papers on the future of epidemiology. Thomas Kuhn's view is that sciences mostly work with a single paradigm driven by exemplars of successful work, and that proposals for paradigm change are resisted. Sciences that are maturing or changing do not have a dominant paradigm. Epidemiology textbooks showed diversity in their concepts, content, and approach. Most exemplars related to etiologic research rather than public health practice. One key focus of the recent controversy regarding the role of epidemiology has been the increasing inability of epidemiology to solve socially based public health problems. Kuhn's views help explain the polarization of views expressed. Kuhn's philosophy of science offers insights into controversies such as whether a paradigm shift is needed or imminent and the gap between epidemiology and public health practice. Interaction between science philosophers, epidemiologists, and public health practitioners may be valuable. PMID:10432899\n\nParadigms in epidemiology textbooks: in the footsteps of Thomas Kuhn.\n\nPubMed\n\nBhopal, R\n\n1999-08-01\n\nThis article attempts to contribute to the debate on the future of epidemiology by combining Thomas Kuhn's ideas on scientific paradigms with the author's observations on some epidemiology textbooks. The author's interpretations were based on his readings of Kuhn's The Structure of Scientific Revolutions, epidemiology textbooks, and papers on the future of epidemiology. Thomas Kuhn's view is that sciences mostly work with a single paradigm driven by exemplars of successful work, and that proposals for paradigm change are resisted. Sciences that are maturing or changing do not have a dominant paradigm. Epidemiology textbooks showed diversity in their concepts, content, and approach. Most exemplars related to etiologic research rather than public health practice. One key focus of the recent controversy regarding the role of epidemiology has been the increasing inability of epidemiology to solve socially based public health problems. Kuhn's views help explain the polarization of views expressed. Kuhn's philosophy of science offers insights into controversies such as whether a paradigm shift is needed or imminent and the gap between epidemiology and public health practice. Interaction between science philosophers, epidemiologists, and public health practitioners may be valuable.\n\nSpatial evolutionary epidemiology of spreading epidemics\n\nPubMed Central\n\n2016-01-01\n\nMost spatial models of hostâparasite interactions either neglect the possibility of pathogen evolution or consider that this process is slow enough for epidemiological dynamics to reach an equilibrium on a fast timescale. Here, we propose a novel approach to jointly model the epidemiological and evolutionary dynamics of spatially structured host and pathogen populations. Starting from a multi-strain epidemiological model, we use a combination of spatial moment equations and quantitative genetics to analyse the dynamics of mean transmission and virulence in the population. A key insight of our approach is that, even in the absence of long-term evolutionary consequences, spatial structure can affect the short-term evolution of pathogens because of the build-up of spatial differentiation in mean virulence. We show that spatial "
    }
}