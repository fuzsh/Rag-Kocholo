{
    "id": "dbpedia_2333_1",
    "rank": 29,
    "data": {
        "url": "https://www.2024.ieeeigarss.org/community_contributed_sessions.php",
        "read_more_link": "",
        "language": "en",
        "title": "Community-Contributed Sessions",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.2024.ieeeigarss.org/images/IG24_Logo_OutlineWhite.svg",
            "https://www.2024.ieeeigarss.org/images/IEEELogoW.svg",
            "https://www.2024.ieeeigarss.org/images/GRSS_Logo_White.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "3D SAR imaging can reconstruct the layovers in 2D SAR images, which is one of the important development directions of SAR imaging. Traditional 3D SAR imaging techniques, for example, based on SAR tomography or array InSAR, approach the imaging process purely from a signal processing perspective. Such methodologies, while effective, tend to overlook the vast potential of SAR image information beyond mere cross-track samples. The concept of \"Microwave Vision\" represents a physical intelligence for understanding microwave imaging information. It proposes a harmonious merger of visual semantics with the intricate microwave scattering mechanisms intrinsic to SAR imaging. By leveraging the power of computational electromagnetics combined with semantic vision extraction and state-of-the-art deep learning technologies, Microwave Vision has the potential to redefine 3D SAR imaging technology. The envisaged outcomes include enhanced 3D SAR imaging fidelity, a reduction in reliance on a huge number of cross-track samples, and a profound enhancement in target scene understanding. Given its pioneering nature and the hybridization of different fields, Microwave Vision does not integrate into the existing thematic sessions at IGARSS. But we believe it will receive widespread attention. This dedicated session aims to be the epicenter of discussions, debates, and disclosures around 3D SAR imaging with Microwave Vision. It will provide researchers and industry experts an unparalleled platform to present recent findings, exchange groundbreaking ideas, identify burgeoning trends, and network with an international assembly of SAR imaging enthusiasts. The scope of this session includes but not limited to: A. Semantic Electromagnetic Scattering and 3D SAR Information Retrieval 1. Semantic Scattering Modeling 2. Inverse Scattering and Information Retrieval 3. 3D SAR Information Retrieval B. Vision Perception in 3D SAR imaging 1. Visual feature extraction and model interpretation 2. Visual recognition, detection, and segmentation 3. 3D vision techniques in microwave imaging 4. Computer vision applications in microwave imaging C. 3D/4D SAR imaging technologies based on Microwave Vision 1. 3D/4D SAR imaging meets microwave vision 2. Three-dimensional microwave imaging principle study and system design 3. Applications of three-dimensional microwave imaging 4. Fusion of three-dimensional SAR imaging and other sensors and its applications\n\nA major impediment in the use of thermal remote sensing data in ecology and agriculture has been the data limitation of having no fine resolution (< 100m), long temporal repeat (16 days), and no multispectral channels for emissivity correction. The successful launch of ECOSTRESS and installation on the International Space Station (ISS) in July 2018 has provided global multispectral thermal data at 70 m resolution and for a 3-5 day repeat cycle of day-night pairs. Future planned NASA SGB (2027), the Indian-French TRISHNA (end 2024) and ESA LSTM (2 satellites 2028) missions with the harmonization of data sets and orbits will extend and enhance current thermal data availability with 60m resolution, multispectral, and daily day-night pairs. The main use of thermal data has been estimating agricultural evapotranspiration and water management. Thermal remote sensing can provide environmental measuring tools with capabilities for measuring both managed and natural ecosystem development and integrity. Recent advances in applying principles of nonequilibrium thermodynamics to ecology provide fundamental insights into energy partitioning in ecosystems. Ecosystems are nonequilibrium systems, open to material and energy flows, which grow and develop structures and processes to increase energy degradation. More developed terrestrial ecosystems will be more effective at dissipating the solar gradient degrading its exergy content. Terrestrial ecosystem's surface temperatures have been measured using airborne and satellite sensors for several decades. Using NASA’s Thermal Infrared Multispectral Scanner (TIMS) Luvall and his coworkers (Luvall and Holbo 1989; Luvall et al 1990; Luvall and Holbo 1991) have documented ecosystem energy budgets for including tropical forests, mid-latitude varied ecosystems, and semiarid ecosystems. These data show that within a given biome type, and under similar environmental conditions (air temperature, relative humidity, winds, and solar irradiance), the more developed the ecosystem, the cooler it's surface temperature and the more degraded the quality of its reradiated energy. These data suggest that ecosystems develop structure and function that degrades the quality of the incoming energy more effectively, that is they degrade more exergy, which agrees with the predictions of nonequilibrium thermodynamic theory (Schneider and Kay 1994a; Kay and Schneider 1994; Schneider; Sagan 2005 and Hamberg et al. 2020). The ecosystem temperature, Rn/K*, Beta Index, and TRN are excellent candidates for indicators of ecological integrity. The same thermodynamic approach can be used for determining crop yield and optimum nitrogen fertilizer application. Alzaben (2020), using exergy destruction principle (EDP) tested under greenhouse and field conditions on corn plants at three different scales (i.e., leaf, canopy and over a plot area). Agricultural crops experiencing greater growth and providing greater yield will have lower surface temperature. Two hypotheses are developed as predicted by the EDP. It is hypothesized that agricultural crops experiencing greater growth and providing greater yield will have lower surface temperatures. The second hypothesis is that crops grown under optimum/higher rates of nitrogen will have lower surface temperatures compared to crops grown under nitrogen stress conditions.\n\nContinuous urbanization in a world of ongoing climate change dramatically transforms human life and creates an important necessity for cities, resilience and sustainability. This involves a deep understanding of socio-economic dynamics as well and an overall need for holistic approaches to provide new insights into the ways we should move towards liveable societies. The realization of the above calls for an implementation frame and the 2030 Agenda for Sustainable Development provides such a global framework for action on sustainable development. For the monitoring of progress towards specific SDGs and associated targets, accurate, robust and timely data from diverse sources are imperative. Although the contribution of many types of data to further sustainable development is widely recognized, great focus is placed on Earth Observation (EO), especially for its potential to complement traditional sources of socio-economic. Few of the questions in place are: how can we improve or deliver new types of environmental information combined with censuses and household surveys? how can remotely mapped land cover over time can be linked to the economic use of the respective land? how do we reveal new insights into climate change associated risks and map vulnerabilities and impacts for different sectors? how can we promote the overall wellbeing of Earth citizen’s as the absolute indicator of our future society’s success? Human’s wellbeing is linked to several aspects of everyday life in cities, where EO can really support the understanding of the perplexed interactions and interfaces. For example, extreme heat can have adverse effects on human health, particularly among vulnerable population groups, and its effects can be especially detrimental in cities which also have limited green, open spaces, poor ventilation, and various types of surfaces that absorb heat. Air pollutants, for which impacts on health is well established and threshold values are framed, are also monitored though EO and, complemented by sophisticated atmospheric models, can deliver health-related indices to delineate pollution impacts on overall wellbeing. Urbanization and climate change are also critical for their impacts on World Heritage properties, and in the case of urban heritage, there is an additional critical need to integrate different aspects of the sustainable development agenda, including urban resilience and sustainable urbanization, with the protection of heritage values, considering the centrality of cultural heritage’s social, ecological and economic dimensions for sustainable urban development. The objective of the session is to better understand the spatial and temporal dimensions of various wellbeing aspects as above, and demonstrate through projects and examples the progress achieved during the last years on creating synergetic and multi-disciplinary approaches involving EO in support of the relevant policy frames, including the 2030 Agenda of SDGs.\n\nPolarimetry is going to start a new operational ere with the upcoming polarimetric satellite SAR missions (ALOS4, NISAR, and Tandem-L) equipped with digital antenna beaming. ALOS4 planned for launch in 2023 will permit polarimetric SAR imaging at 3m resolution and 100km swath. This is a significant advance in comparison with the existing polarimetric satellite SAR missions (RADARSAT-2, ALOS2, and TerraSAR) of limited swath (50km). With the approach of this new ere of operational use of polarimetric SAR in support of key applications, it is important to reconsider the state of the art in the methodology and tools currently adopted for polarimetric information extraction. This special session will allow us to learn more about the most advanced tools recently developed for optimum polarimetric information extraction such as target scattering decomposition, speckle filtering, image classification, and polarimetric SAR modeling. The session that will gather edge leading guest scientists will also give the opportunity to discuss the gaps that would have to be fulfilled to fully exploit the polarimetric information provided by satellite and airborne SAR in support of key applications.\n\nHistorically, observations of natural phenomena and physical processes by remote sensing systems were coincidental with the overflight of the instruments available. The global mapping strategy has been excellent for monitoring and unraveling large scale, long duration processes. For example, prevailing winds or even hurricanes have become far better understood through this type of missions. Even geostationary low Earth orbits have provided vast quantities of well registered data, globally. However, the study of many smaller scale, short duration processes and phenomena are only fueled with coincidental capture during the normal scanning cycle. Global mapping missions are essential to the long-term monitoring of the state of the Earth. But novel observing strategies (NOS) can now be considered for a variety of purposes. With the advent of constellations of satellites with both passive and active sensors, low-latency downlinks, and AI algorithms running on edge computing, there is an opportunity to use the output of the sensor to task it and other sensors, remote, airborne or in situ. Not only does this capability enable more concentrated process studies but also attention to transient and transitional phenomena, such as tornadoes, extreme storms, and biological phenomena that operate at the time scale of the diurnal cycle, Novel observing strategies can be placed into service, that were only imagined before. For example, cooperating observing systems, such as TROPICS, can observe phenomena from multiple angles or a string of satellites can observe a short-lived or dynamical phenomenon for much longer periods of time. An array of multiple platforms of identical sensors can work as a phased array, maintaining focus for as long as it is observable by shifting the focal point.. They can also be used to improve signal to noise ratios, etc. Novel observing strategies can also be considered when planning a new mission driven by the need for a new measurement. They could facilitate the creation of “virtual missions” composed of several existing missions and/or sensors as well as of additional in-situ, airborne or space sensors, from various organizations (government, industry and academia), nationally and internationally. NOS would provide the capability to optimize the use of an existing portfolio and to complement it with other well-chosen sensors, thus reducing risk, cost and time of development of new observations. The purpose of this session is to share experience and concepts related to the NOS in Earth Observation, although many of the control and monitoring technologies needed for these environments are re-usable in different domains, such as heliophysics and planetary. This is directly related to digital twin technology.\n\nEarth Observation (EO) sensors are acquiring Big Data volumes at very high data rates (e.g., the Copernicus missions produce 12 TB of data per day). In particular, next generation SAR systems will offer a quantum leap in performance using large bandwidths and digital beam forming techniques in combination with multiple acquisition channels. These innovative spaceborne radar techniques have been introduced to overcome the limitations imposed by classical SAR imaging for the acquisition of wide swaths and, at the same time, of finer resolutions, and they are currently being widely applied in studies, technology developments and even mission concepts conducted at various space agencies and industries. Such significant developments in terms of system capabilities are clearly associated with the generation of large volumes of data to be gathered in a shorter time interval, which, in turn, implies harder requirements for the onboard memory and downlink capacity of the system. Similar considerations can be drawn with respect to optical sensors, such as multispectral and hyperspectral ones, which provide nowadays large amounts of images at high resolution. Therefore, the proper quantization/compression of the acquired data prior to downlink to the ground is of utmost importance, as it defines, on the one hand, the amount of onboard data and, on the other hand, it directly affects the quality of the generated EO products. EO data show unique features posing important challenges and potentials, such as learning the data models for optimal compression to preserve data quality and to avoid artefacts hindering further analysis. For instance, based on the peculiarities of the imaged scene (e.g., in radar imaging these are characterized by the reflectivity, polarization, incidence angle, but also by the specific system architecture, which may offer opportunities for efficient data quantization; differently, multispectral data are characterized by the land cover or the presence of clouds), a more efficient data representation can be achieved by searching for the best quantizer and the ad-hoc tuning of the inner quantization parameters. Additionally, onboard preprocessing of the acquired data to a sparse domain (e.g., range compression in the case of SAR data) can also lead to a more compact data representation. Artificial Intelligence (AI) represents one of the most promising approaches in the remote sensing community, enabling scalable exploration of big data and bringing new insights on information retrieval solutions. In the past three decades the EO data compression field progressed slowly, but the recent advances in AI are now opening the perspective of a change of paradigm in data compression. AI algorithms and onboard processing could be exploited to generate/discover novel and more compact data representations. This session would like to bring to the field new methodologies for both loss-less and lossy compression of remote sensing data. Several data compression topics are welcomed to the session, which include (but are not limited to): data-driven and model-based compression methods, Kolmogorov complexity-based algorithms, source coding with side information, neural data compression, compression of correlated sources, integrated classification and compression, semantic coding, big data compression and application-oriented compression.\n\nRecent advances in sensor and aircraft technologies allow us to acquire huge amounts of remote sensing data. Diverse information on Earth's surface can be derived from these multi-resolution and multimodal data, providing a much more comprehensive interpretation for Earth observation, e.g., spectral information from multi- and hyperspectral images can help to reveal the material composition, elevation information from LiDAR data helps to estimate the height of the observed objects, synthetic aperture radar (SAR) data can measure dielectric properties and the surface roughness, panchromatic data are instead focused on spatial features of the acquired landscape, and so forth. State-of-art works have proven that the fusion of these multi-resolution and multimodal images provided better performance than those only using a single image source. However, challenges remain when applying these data for some applications (classification, target detection, geological mapping, etc.). For example, classical issues could be related to the misalignment of multimodal images, the presence of clouds or shadows (in particular, when optical data are involved), and spectral/spatial differences hampering the post-fusion of these data. This invited session will focus on multi-resolution and multimodal image processing and interpretation, such as multimodal image alignment, restoration, sharpening of multi-spectral and hyperspectral images (e.g., pansharpening, hyperspectral pansharpening, and hypersharpening), use of machine learning approaches devoted to several tasks (e.g., feature extraction and classification) exploiting the multimodality of the data, and so forth. We will discuss the latest methods/techniques for multi-resolution and multimodal image processing, as well as how this can benefit our interpretation.\n\nPolarimetric GNSS-R (Global Navigation Satellite System-Reflectometry) represents the evolution of GNSS-R technology, poised to enhance land and cryosphere assessments significantly. The integration of polarimetry into forward scattering measurements plays a pivotal role in disentangling critical factors like vegetation, soil moisture, roughness, sea ice characteristics, and freeze/thaw state investigations. For instance, a long-standing objective in GNSS-R has been the retrieval of soil moisture in a single pass, without heavy reliance on ancillary data. Accomplishing this objective would empower small satellites equipped with GNSS-R payloads to conduct autonomous land monitoring, negating the need for additional dynamic measurements. However, prior research has highlighted the complexity and low accuracy associated with single-pass soil moisture retrieval in the absence of in-situ moisture or ancillary data. An avenue to surmount this challenge is to enhance existing GNSS-R instruments with polarimetric capabilities, enabling more versatile Earth surface analysis, particularly in polarimetrically significant regions like icy surfaces, bare soil, or vegetated areas. Present-day trends in Polarimetric GNSS-R revolve around the utilization of either two circular polarization antennas (RHCP/LHCP) or two linearly polarized antennas (H/V). Collaborative discussions among experts in the field are essential to propel progress and furnish improved guidelines for determining when one polarization scheme should be preferred over the other. Such dialogues are expected to foster fruitful exchanges among peers hailing from diverse teams and backgrounds. Topics under scrutiny include the impact of polarimetric GNSS-R, ranging from modeling and data simulations for future missions, drawing inspiration from existing non-polarimetric missions, to the analysis of actual polarimetric data. This session holds significant relevance for upcoming polarimetric GNSS-R missions, such as ESA's HydroGNSS, as well as for future missions that may arise, requiring polarimetric capabilities to yield higher-quality GNSS-R products, such as soil moisture measurements or cryosphere characterization, and even novel products like vegetation opacity. Furthermore, the adoption of polarimetric GNSS-R retrievals could facilitate the independent retrieval of critical geophysical parameters like soil moisture, obviating the need for ancillary data. Thus, these retrievals would provide complementary datasets to those currently available from ongoing missions, serving as valuable training and validation resources for future algorithm development. Combining models with data from existing GNSS-R missions (e.g., CYGNSS, BuFeng-1, FY-3E, Spire, SMAP reflectometry) will enable a deeper understanding of the potential outcomes of a polarimetric GNSS-R mission. The session will encompass presentations from international teams engaged in polarimetric GNSS-R, spanning efforts in model development, existing spaceborne measurements, and the anticipated launch of polarimetric GNSS-R missions.\n\nIn a rapidly changing world, understanding and mitigating the impacts of environmental changes on our planet has become an imperative. Earth System Digital Twins (ESDTs) have emerged as a revolutionary approach, seamlessly integrating Earth sciences, AI technologies, and real-time data to simulate, monitor, and predict Earth's complex systems. This technical session explores the intersection of Earth Action applications, what-if decision making, and the pivotal role of AI-driven software technologies in advancing ESDTs. Earth Action Application: The Earth Action application component of ESDTs emphasizes the real-world relevance of these digital twins. Through the incorporation of multidisciplinary data sources, such as geospatial, atmospheric, oceanographic, and ecological data, ESDTs enable comprehensive modeling of Earth's dynamic systems. This session will feature papers on emerging applications and prototypes that demonstrate how ESDTs can revolutionize our capacity to assess and respond to environmental challenges, from tracking wildfire propagation to assessing urban resilience against climate-induced hazards. What-If Decision Making: One of the most compelling aspects of ESDTs is their capacity to support what-if decision making. This session will explore how ESDTs empower stakeholders with the ability to simulate various scenarios and assess the consequences of different policy choices. In doing so, ESDTs provide invaluable insights for informed decision making, offering tools to anticipate, prepare for, and mitigate the impacts of environmental changes. AI-Driven Software Technologies: Central to the success of ESDTs are the sophisticated AI-driven software technologies that underpin their development and operation. This session delves into the latest advancements in machine learning, deep learning, and data assimilation techniques, which enable ESDTs to process vast and heterogeneous datasets in real-time. Moreover, we explore how these AI technologies enhance the predictive capabilities of ESDTs, improving their accuracy and responsiveness. Topics covered will include data integration and fusion, model validation and calibration, scalable computing infrastructure, and user-friendly interfaces and visualizations for decision-makers. By attending this technical session, participants will gain a deep understanding of how ESDTs can transform the way we interact with and manage our planet's complex systems. They will also explore the critical role of AI-driven software technologies in creating actionable insights for addressing global environmental challenges.\n\nThe Sendai Framework for Disaster Risk Reduction was adopted at the Third UN World Conference on Disaster Risk Reduction in Sendai, Japan, on March 18, 2015. The goals outlined in this framework have encouraged the development of risk reduction strategies by a wide array of sectors, including anticipatory action for humanitarian aid. As such, stakeholders of the humanitarian aid domain define a set of actions taken to prevent or mitigate potential disaster impacts before a shock or before acute impacts are felt. Anticipatory humanitarian action, is reshaping the humanitarian system and is increasingly recognized as a key solution to reducing the impacts of climate change and extreme weather events to local communities. A critical challenge for the application of anticipatory action is to maximize the window of opportunity between the moment of prediction and the arrival of a forecasted shock to trigger interventions that prevent or mitigate imminent humanitarian impacts. In order to be properly applied, anticipatory action requires a variety of data, to feed forecast models, quantify impact to population and assets, and eventually inform decisions through agreed early-action protocols. The role of Earth Observation (EO) becomes increasingly important for improving the aforementioned predictions related to impact of various hazards and provides an independent, continuous and synoptic view of the communities-regions-countries to be impacted. The session reflects on inputs from the humanitarian community for reducing entry barriers to EO, develop simple solutions for non-expert users and eventually advance and mainstream the use of EO for anticipatory action. The session will focus on the use of EO and other collateral data for geospatial applications in anticipatory humanitarian action, including a wide field of relevant themes: - Identification of capability gaps in EO-based systems - New methods and approaches towards anticipating hazards for humanitarian aid applications (e.g. application of Artificial Intelligence for anticipatory action) - Methodologies to validate forecasts Validation methods - Evaluating the impact of EO-based anticipatory action on the ground - Standards towards a harmonized, repeatable EO-driven monitoring, evaluation, accountability and learning (MEAL) - Space-based services beyond EO: GNSS and SatCom for anticipatory action.\n\nThe session 'Advancing Technologies for Wildfire Risk Management in the Context of the 2030 Green Deal' promises to be a crucial and forward-looking discussion at the intersection of environmental protection and cutting-edge technology. As we embark on the journey to achieve the goals outlined in the 2030 Green Deal, addressing the escalating threat of wildfires is of paramount importance. This session will provide a comprehensive exploration of innovative solutions (e.g., multimodal data fusion, applications of AI for wildfire science problems, sensor networks) and strategies to mitigate wildfire risks in an environmentally responsible manner. Wildfires are increasing in intensity and frequency, exacerbated by climate change and land use patterns. In response to this pressing issue, the session will bring together experts from various fields, including environmental science, technology, policy and firefighting, to examine how emerging technologies can be used to improve wildfire prevention, detection and response. Participants can expect to gain insights into cutting-edge tools such as satellite imagery, drones, AI-driven modelling and sensor networks that are transforming our ability to monitor and manage wildfires. The discussion will also explore the ethical and environmental implications of using advanced technologies to manage wildfires, ensuring that solutions are consistent with the principles of sustainability and environmental protection. The 2030 Green Deal places a strong emphasis on promoting a harmonious coexistence between humans and nature. This session will explore how technology can help achieve this balance, not only by reducing the destruction caused by wildfires, but also by facilitating ecosystem restoration and recovery after fires. Ultimately, \"Advancing Technologies for Wildfire Risk Management in the Context of the 2030 Green Deal\" is an opportunity for policymakers, scientists, technologists, and environmental advocates to come together, exchange ideas, and forge a path forward to protect our planet from the growing threat of wildfire.\n\n“They just work” is a common argument for the use of artificial intelligence and machine learning (AI/ML) systems for inference. However, it is not sufficient for applications where an AI system is asked to detect rare or important events that are associated with high-consequence decision making, which is often the case in hyperspectral image analysis. Remote sensing end users, i.e., humans who have to decide what to do with what their algorithms tell them, have been rightfully reluctant to adopt the “black box” class of machine learning algorithms – uninterpretable algorithms that have otherwise been shown to be effective in fields outside of remote sensing. This reluctance to “black box” methods is because model explainability (XAI) and interpretability are critically important for an end user that must act, with confidence, on an AI system’s predictions. Nevertheless, AI/ML techniques are becoming increasingly more ubiquitous in hyperspectral remote sensing analysis, particularly with the ever-growing volume of hyperspectral remote sensing data in both public and commercial sectors. And because many of the research results are promising, an increased emphasis on explainability is all the more urgent. AI systems in our community need to not only be predictable, but they also need to be transparent in their reasoning, and they need to be interpretable. In our Community Contributed Session, we will emphasize techniques for end-to-end, traceable explainability – starting with the model training inputs, through the system architecture, and to the outputs, while considering sensor design and domain information throughout. In doing so, we will open the “black box” that typically obfuscates insights into AI/ML models in hyperspectral target detection. Because AI/ML explainability methods can apply to different domains within remote sensing, we hope that this session will demonstrate transferable techniques as well as enable cross-pollination of new ideas.\n\nBy 2050, around 70% of the world's population will live in cities. Around 90% of this growth is expected to happen in Low-and-Middle-Iincome Countries (LMICs), often in areas that are deprived in terms of housing conditions, services, infrastructure etc. SDG 11 but also several related SDGs (e.g., SDGs 1, 6 and 7) aim at sustainable cities and communities that are well-serviced. Several recent high-level political events (e.g., the 2023 SDG Summit) stressed that the progress of SDGs is lagging behind. The UN Secretary-General stressed the need for a Rescue Plan for the SDGs. Beyond the slow progress, high uncertainty exists in measuring the progress across many SDGs (e.g., SDGs 11 indicators have been declared as Tier 1 without a scalable and spatial approach). Earth Observation (EO) combined with Geospatial Data have great potential to fill reporting gaps and quantify uncertainties. However, EO data are often not used to their full potential for SDG monitoring, even though many initiatives have opened up EO data and methods to experts on SDG reporting (e.g., the Earth Observations Toolkit for Sustainable Cities and Human Settlements). Within this session, we will reflect on innovations in developing global, scalable and transferable methods to reduce monitoring uncertainties, focusing on LMICs and urban poverty, deprivation and service gaps. Session contributions will present methods that focus on scalability, low cost of data, transferability and the documentation of uncertainties. We will also look into new EO data sources (e.g., SDGSAT-1), multi-source data integration (e.g., citizen science data), and communication of spatially explicit uncertainty measurements. This session will bring experts on different urban poverty-related SDG goals and targets together to allow exchange and discussion about technical solutions and how to increase the impact of EO and GEO-spatial methods. Our session topic is timely and links to the 2025 comprehensive review of the indicator framework. Timely, trustworthy, and open data are essential for global monitoring of the 2030 agenda to support stakeholders involved in the local and national reviews of SDGs and increase access to data for the ongoing development of reporting platforms.\n\nThis session welcomes contributions that delve into the practical and theoretical aspects of leveraging causality and/or machine learning techniques, all within the context of the critical role played by Remote Sensing and Earth Observation data. By emphasizing the significance of these technologies, we aim to pave the way for a more sustainable future in agriculture and food security. Specifically, the methodological direction of the session is two-fold. To drive sustainability, we need to continuously monitor agricultural activity at different scales and answer causal questions for decision making. The ability to properly harness the wealth of information provided by Remote Sensing and Earth Observation is critical. The creation of predictive models that remain consistent and reliable across diverse agricultural landscapes is crucial. Machine learning building on causal principles can lead to the development of this necessary type of geolocation-invariant models. Moreover, Remote Sensing and Earth Observation data provide the foundation material for answering causal questions (i.e. causal discovery in complex environments, causal effect estimation,), which are essential for evidence-based policymaking. This data-rich environment enables us to develop proactive strategies for sustainable agriculture and to establish transparent, accountable agricultural systems. Towards secure food production, several applications of machine learning in agriculture aims to augment conventional farming practices through automation and the integration of contemporary technologies, thereby mitigating risks, fostering sustainability, and enhancing predictability, ultimately striving to bolster agricultural productivity. Some notable applications of AI within Agriculture 5.0 include monitoring agricultural crop vegetation status and health, automated crop identification, early-stage disease detection, automatic determination of site-specific crop requirements in terms of water and nutrients, formulation of farming strategies pertaining to chemical and mechanical treatment control, and the utilization of AI-based intelligent decision support systems for yield and price estimation. Additionally, the future integration of agri-robots for sowing and harvesting stands as a promising prospect.\n\nIn the rapidly evolving intersection of Artificial Intelligence (AI) and Earth Observation (EO), the session titled “AI-DataEng-EO: AI-powered Data Engineering and Reusability for Earth Observation Applications” will focus on the pivotal role of AI in reshaping EO data engineering and promoting data reusability. This session focuses on the application of AI methods, such as representation learning and knowledge modelling and representation, to transform, explain, fuse or otherwise prepare large and complex EO datasets for (re)use in downstream applications. In addition, it will welcome contributions on AI-powered semantic data annotation and metadata enrichment, due to their significance in improving data discoverability, understandability, and reusability, fostering a culture of informed and sustainable data-driven decisions in geoscience and remote sensing. More specifically, a non-exhaustive list of topics relevant to this session is the following: 1. Data Preprocessing and Enhancement: AI-driven techniques for preprocessing and enhancing Earth Observation data, including noise reduction, feature extraction, and data augmentation. 2. Data Fusion and Integration: Address the challenges and solutions related to integrating data from multiple sources, including satellite, aerial, and ground-based sensors, using AI-based fusion techniques. 3. Time-Series Analysis: AI models and approaches for analysing time-series data from Earth Observation sources. 4. Data Reusability and Open Data Initiatives: AI for complementing best practices for making Earth Observation data more accessible, reusable, and interoperable. 5. Semantic Data Annotation: AI-driven semantic annotation, metadata enrichment and knowledge extraction to improve Earth Observation data discovery and understanding. 6. Data Quality Assessment: AI-driven data quality assessment, anomaly detection, and error correction in Earth Observation datasets. 7. AI-Enhanced Data Products: AI-powered data products and services that leverage Earth Observation data for various sectors. 8. AI for Data Search and Retrieval: Discuss AI algorithms and technologies that enhance the search and retrieval of relevant Earth Observation data from large archives. 9. Data Privacy and Ethics: Ethical and privacy considerations when applying AI to generate Earth Observation data derivatives, including issues related to personal privacy, consent, and data security.\n\nA series of Advanced Land Observing Satellite (ALOS) by the Japan Aerospace Exploration Agency (JAXA) has been continuously operated since 2006 and is currently observed by ALOS-2 for precise observations. ALOS series consists of missions by the high-resolution optical and L-band Synthetic Aperture Radar (SAR) named the Phased Array type L-band SAR (PALSAR). An L-band SAR mission is taken over by ALOS-2 and will be followed by ALOS-4 which is planned to be launched soon. The optical mission was followed by ALOS-3, however the launch failed due to H-3 rocket Test Flight 1 malfunction. As a result, the study of the next-generation high-resolution optical mission has been accelerated, intensive studies are underway within JAXA, and the project is expected to be launched in the near future. The ALOS-4 follow-on mission is also being considered within JAXA, and continuous L-band SAR observations with no gaps in time are expected. The primary mission objectives of the ALOS series are to contribute the disaster monitoring and prevention, national land and infrastructure information updates, and global forest and environmental monitoring which are major research and application themes in geoscience and remote sensing fields. In this Community Contributed Session, what should be focused on the ALOS series missions, Cal/Val, science, and applications will be discussed. The summaries of achievements by ALOS and ALOS-2 will be introduced and planned to be conducted by ALOS-4. The perspectives of the future ALOS series missions of both optical and L-band SAR will be discussed based on these results, which may cover the importance of mission continuity, international collaborations, advantages, and disadvantages that should be reflected in future missions.\n\nMany satellite data users lack the expertise, infrastructure, and internet bandwidth to efficiently and effectively access, pre-process, and utilize the growing volume of space-based data for local, regional, and national decision-making. Even sophisticated users of Earth Observation (EO) data typically invest a large proportion of their effort into data preparation. This is a major barrier to the successful utilisation of space-based EO data. This barrier presents a major obstacle to mainstreaming the use of EO data to realise the full value of EO data and is a threat to the success of major global and regional initiatives supported by the Committee on Earth Observation Satellites (CEOS). As data volumes grow, this barrier is becoming more significant for the majority of users. Countries and international organizations have expressed a desire for support from CEOS to facilitate access to and processing of satellite data into “Analysis Ready Data”. Systematic and regular provision of CEOS-ARD has the potential to reduce the burden on global satellite data users and, as a direct consequence, boost data use and it is the first step towards interoperability. In 2016, the CEOS created a definition for CEOS-ARD and subsequently developed a Framework and Product Family Specifications. This session is being organised by CEOS Land Surface Imaging Virtual Constellation (LSI-VC) in collaboration with Geoscience Australia, the United States Geological Survey (USGS), and the European Commission (EC). It aims to share with the international community the latest developments on CEOS-ARD initiative as well as to continue the dialogue with the private sector with the objective of exploring new opportunities and understanding challenges when considering user needs, discovery, and access to CEOS-ARD compliant datasets.\n\nThe session will focus on work done by researchers that have used Capella Space Synthetic Aperture Radar (SAR) data. Here is a brief description of the proposed session. Capella Space provided datasets to a number of researchers for variety of scientific studies. Last year we organized organized a community contributed session to show how very high-resolution SAR imagery positively contributes to study oceanography, geology, disaster management in case of flooding event, sea ice glaciology and amplitude change detection using signal processing and machine learning techniques. In 2024, we would like to cover additional studies to show the value that commercial very high-resolution SAR data brings to the Earth Observation remote sensing community. In particular, we aim to present more research works leveraging interferometric compatible images from New Space systems, such as Capella, and to foster discussion about how commercial small SAR satellites can augment other SAR systems, such as TerraSARX, NISAR, Sentinel-1 and RADARSAT-2 / RCM. In this context, we aim to discuss the advantages of having SAR systems launched in mid-latitude inclined orbits or using small satellite systems in bistatic or multi-static configuration. This session addresses many of the IGARSS 2024 themes such as S/M.1: Spaceborne SAR Missions and S/M.7: New Space Missions, and earth science focused areas such as D/S.5: Risk and Disaster Management, C.3: Sea Ice, as well as methodological areas such as SAR T/D.14: Change Detection and Temporal Analysis, T/S.2: Differential SAR Interferometry T/S.5: Bistatic SAR.\n\nAtmospheric active remote sensing from space is growing at an exponential rate. Current and upcoming complex aerosol and cloud profiler missions (e.g. CALIPSO-NASA, Aeolus-ESA, EarthCARE-ESA/JAXA, AOS-NASA, ACLD-CNSA, Aeolus2-EUMETSAT/ESA, INCUS-NASA, Earth-Explorer candidate mission Wivern-ESA) and upcoming constellations of CubeSats and micro-satellites (e.g. Tomorrow IO), will enhance EO-based research to advance our understanding of the role that cloud and aerosol play in the Earth’s radiation budget, while enabling the optimization of Earth System Models through data assimilation. Prior to the exploitation of the new datasets, validation activities are critical to ensure the quality, credibility, and integrity of the Earth observation data. The upcoming missions are foreseen to have several validation challenges, due to the multi-sensor complexity/diversity and the innovation of their standalone and synergistic products. Hence, a clear need arises for establishing best practices in the field of cloud, precipitation, and aerosol profile validation. The aim of the session is to promote discussions between scientists towards defining best practices for space-borne aerosol, cloud and precipitation profile products. Additionally, new retrievals and scientific findings from space-borne profiles are invited. This session is welcoming contributions on all relevant aspects, such as: Lessons learned from past/recent campaigns/studies Lidar/Radar Fiducial Reference Measurements Cal/Val protocols Upcoming campaigns and new measurement strategies Cal/Val needs for current/upcoming Lidar/Radar satellite missions new profiling retrievals science applications/findings\n\nThe management of increasingly scarce natural resources and the growing severity and frequency of natural disasters constitutes one of the most demanding challenges societies are facing in current times. Exploiting insights from the vast amount of Earth Observation (EO) and Geoscience data through large-scale analytics promises to be one of the key tools to address and resolve this challenge. However, the sheer volume of data required for Earth observational purposes often exceeds the capabilities of existing cloud data centers that usually process much smaller machine-learning benchmark datasets for experimental purposes. We invite the global EO analytics community to collaborate in discussing, conceptualizing, and implementing open-science, open-source distributed computing and distributed machine learning approaches to effectively tackle this challenge. Connecting distributed infrastructures through federation-algorithms will play a crucial role in developing scalable machine learning models to address mentioned and other global challenges. Geospatial observations aggregate terabytes of data daily. Managing is costly and complex, as it typically spread across different locations and organizations. However, existing deep insights algorithms that provide scientific and business value, require all the data to be co-located in one place, presenting a unique challenge also known as \"data gravity\". Physically relocating data to a single High-Performance Computing center for integration is extremely costly, time consuming and highly undesired. There are two distinct alternatives to overcome this large geospatial data challenge. The first is to represent and manage distributed data in a unified way, through data federation. This way not all the data, needs to be transferred, but only the fraction that is needed by locally running models. This approach solves a part of the problem only. The second approach involves training novel distributed algorithms on distributed data \"at the edge\", i.e. where the data is. Only small amounts of highly compressed data (meta data) needs to be exchanged between locations. This is known as model federation. Notably, the latter approach avoids the expensive and time-consuming process of transferring raw data from one location to another. This method holds the potential to deliver time-sensitive insights efficiently, even within a potentially heterogeneous network of resource-constrained nodes, such as e.g. a network of orbiting satellites. For this session we welcome submissions concerned with schemes and technologies that facilitate unified views of data and models at the user interface, while underneath, federation and distributed technologies are at work. They may span across, but are not limited to the following areas: •Space-based data centers, •Federated learning in Space, •Distributed Artificial Intelligence in Space, •Smart compression of satellite data in Space, •Hyper-parameter optimization of AI algorithms for EO, •Temporal analysis of EO data in Space, •Anomaly detection in large-scale EO data, •Methods and tools for handling large-scale EO data, •Hardware solutions for in-orbit data centers, •Hardware acceleration of AI in Space, •Data storage and transport, •Data-access schemes, •Privacy and authentication, •Model training and execution (inference), •Model distribution and unification, •Big data in Space, •New trends and open questions in big data systems in Space.\n\nIn an era characterized by the complex and evolving Health challenges posed by climate change, the intersection of Earth Observation (EO) technologies and Artificial Intelligence (AI) is providing us with capabilities that can lead to new tools to combat and control them. This Session embarks on a comprehensive exploration of the application of AI-enhanced EO technologies that contribute to climate-change-induced diseases, including vector-borne diseases, water-borne diseases, air pollution-related, and heat wave-induced health threats. In this Session we are interested (but not limited) in: Development and deployment of early warning systems, aiming to empower communities and health organizations with timely information to mitigate disease outbreaks and prepare for climatic shifts. Furthermore, there is high interest in state-of-the-art explainability techniques, enabling stakeholders to interpret AI-driven insights and decision-making processes and key factors identification. Additionally, the establishment of reliable and trustworthy AI algorithms is a critical part of the health applications, seeking to enhance the robustness and effectiveness of our health resilience strategies. We are interested in quantifying and measuring the confidence of the AI algorithms and the area of applicability of the AI models. In the context of climate change, a key component is to understand the evolving dynamics of diseases, their relationship to climatic conditions, and the subsequent implications for public health. Additionally, the Session aims on the exploration of mitigation actions designed to reduce the impact of climate change on disease prevalence and health outcomes. Both traditional statistical learning and deep learning approaches that relaying on EO data and can provide information useful for health relible applications are welcome on this Session\n\nCryosphere components such as snow cover, glaciers and permafrost are very sensitive to temperature increase and related atmospheric changes. Remote sensing data offer essential tools to monitor these changes, particularly in large and inaccessible regions such as mountain areas. In the last decades retrieval of physical snow parameters and assimilating of EO products into models were advanced and help to get a better knowledge on the status of seasonal snowpack and understanding of the cryosphere. But there are still challenges and gaps to be solved such as the snow in forests and shaded regions, and discrimination between cloud and snow. Moreover, some key snow parameters of large interest such as snow water equivalent, snow depth and quantitative information on snow wetness are still in an early development phase or missing. Accurate and reliable products with attached uncertainty information in this direction will also be useful in model assimilation approaches thus consequently improving model predictions (Zheng et al. 2023). In this view, the exploitation of the recently launched or upcoming satellite missions based on L-band SAR such as NISAR, SAOCOM and the upcoming Copernicus ROSE-L and the image spectroscopy provided by hyperspectral sensors such as PRISMA and EnMAP and the upcoming CHIME are of utmost important to provide more accurate information on the cryosphere processes. This session will highlight the main current challenges in the cryosphere monitoring and how these can be addressed with current and next generation of satellites and where gaps remain to be filled with future satellite missions as well as with improvement more accurate and reliable algorithms, including the combination of different sensors.\n\nHigh spectral resolution lidar (HSRL) is a significant lidar technique for atmospheric and oceanic measurements. Using various optical filters (e.g., Fabry–Pérot interferometer, atomic/molecular absorption filter), it is capable of distinguishing the particle/aerosol scattering spectra and the molecule scattering spectra, which are mixed up in the backscattering lights from the atmosphere or water. Utilizing this principle, the optical properties (extinction coefficient, backscatter coefficient, lidar ratio, etc.) of the objective particles (aerosol and cloud in the atmosphere, phytoplankton in the ocean) could be detected accurately, and then the concentration, the particle type/species could be derived. Moreover, the HSRL can also be deployed as wind detection instrument as it has the capability to detect the Doppler shift in the atmosphere backscattering light. Spaceborne HSRLs provide globally high temporal-spatial resolution aerosol/cloud/wind/phytoplankton observation profiles. This session will focus on the ongoing Chinese HSRL satellite DQ-1 (Daqi-1) to discuss its lidar techniques and applications. The Chinese atmospheric environment monitoring satellite DQ-1 has been successfully launched on 16 April 2022. As an integrated detection scientific research satellite, it will serve as an important part of Chinese atmospheric environment monitoring system. The DQ-1 is operated in a sun-synchronous orbit at the altitude of 705 km and provides global comprehensive monitoring of atmospheric particles, carbon dioxide (CO2), aerosols and clouds. The DQ-1 equips five sensors including an Aerosol and Carbon Detection Lidar (ACDL), a Particulate Observing Scanning Polarimeter (POSP), a Directional Polarization Camera (DPC), an Environmental trace gas Monitoring Instrument (EMI) and a Wide Swath Imaging system (WSI). As the primary payload among them, ACDL consist of two different modules. One is the aerosol-measurement module which provides aerosols and clouds profile measurements with high accuracy globally, and another is the CO2-measurement module for atmospheric column CO2 observations. The aerosol-measurement module of ACDL is an HSRL with two-wavelength polarization detection, that can be utilized to derive the aerosol optical properties. The aerosol and cloud optical properties products of ACDL include total depolarization ratio, backscatter coefficient, extinction coefficient, lidar ratio and color ratio.\n\nOver the past decade, near-surface geophysics and close-range remote sensing have emerged as pivotal tools in the realms of environmental and urban monitoring. Researchers have dedicated substantial efforts to digitally reconstructing built structures and forestry elements, encompassing buildings, infrastructure, and trees. The resultant information models, including Geographic Information Systems (GIS), Building Information Modeling (BIM), or Computer-Aided Design (CAD), have gained increasing significance in applications such as urban planning, disaster management, sustainability assessment, and forest monitoring.With the fast development of machine learning and deep learning, the current analytical toolkits, spanning from spatial to intelligent analysis, offer potential for profound multi-data integration, enhancing outcomes and engendering more efficient techniques in the domain of land cover and land use detection. However, with regard to near-surface geophysics and close-range remote sensing, this integration remains this integration still remains at a basic level, involving just pixel-by-pixel composition or basic analysis. Typically, close-range sensing technologies like laser scanning and photogrammetry are harnessed for digitizing manmade objects. This necessitates the unsupervised interpretation of complex scenes and the automated extraction of parameters from a diverse array of domain-specific objects, such as heritage sites, structures, and individual trees. In the last few years, there has been intense research activity towards the automation of this process. However, there is still important work to be carried out involving (i) the collection and processing of close-range sensing data (ii) scene interpretation including semantic segmentation and object detection, and (iii) parameter extraction for the final information models. This workshop will present new technologies and methodologies that target the above objectives. We welcome submissions that cover but are not limited to the following: Close-range sensing systems; Geometric evaluation of mapping systems; Close-range sensing data structures and models; Scene interpretation, including semantic segmentation, classification, and object detection; multi-sensor data fusion.\n\nCoastal interfaces are the nexus of lateral flow and exchange of water, carbon, and sediment between land and sea. They are highly dynamic and complex systems that provide a wide range of ecosystem services, including regulating and maintaining coastal water quality, providing habitat for biodiversity, protecting coastal communities from storms and flooding, and supporting coastal economies through tourism and fisheries. Earth observation (EO) and geosciences play a vital role in understanding and managing coastal interfaces. EO provides data on a wide range of coastal processes, such as sea surface temperature, chlorophyll concentration, suspended sediment concentration, wave height, and tide height. This data can be used to monitor changes in the coastal environment, identify emerging threats, and develop adaptation strategies. Geosciences provide a fundamental understanding of the physical, chemical, and biological processes that shape the coastal interface. This knowledge is essential for developing effective management strategies. EO and geosciences can be used to support the achievement of several Sustainable Development Goals (SDGs), including: • SDG 6: EO data can be used to monitor water quality in coastal areas, identify pollution sources, and track the spread of harmful algal blooms. This information can be used to develop strategies to protect human health and coastal ecosystems. • SDG 11: EO data can be used to assess the vulnerability of coastal communities to sea level rise and coastal erosion. This information can be used to develop adaptation strategies, such as building seawalls or relocating communities to higher ground. • SDG 13: EO data can be used to monitor changes in the coastal environment, such as sea level rise, sea surface temperature, and ice cover. This information can be used to understand the impacts of climate change on the coastal zone and to develop adaptation strategies. • SDG 14: EO data can be used to monitor the distribution and abundance of marine life, as well as the health of marine ecosystems. This information can be used to develop sustainable fishing practices and to conserve marine biodiversity. • SDG 15: EO data can be used to monitor coastal ecosystems, such as mangroves and coral reefs. This information can be used to develop strategies to protect and conserve these ecosystems. EO and geosciences play a vital role in understanding and managing coastal interfaces. They can also be used to support the achievement of several SDGs, including those related to clean water and sanitation, sustainable cities and communities, climate action, life below water, and life on land. This session is open to papers from a wide range of papers spanning over use of EO data for applications in hydrology, coastal oceanography, biogeochemistry, ecology, and geomorphology. We encourage researchers to submit papers that present new and innovative ideas for addressing the grand challenge of coastal interfaces using EO and geoscience.\n\nThe proposed session aims to bring together remote sensing experts, environmentalists, and policymakers to explore the burgeoning domain of predictive modelling under the umbrella of the OneHealth initiative. In particular, the Horizon Europe projectOneAquaHealth is committed to bolstering the sustainability and integrity of urban freshwater ecosystems, elucidating the intricate nexus between ecosystem health and human well-being. The overarching goal is to empower decision-makers with timely and adequate data, facilitating efficacious measures to return the health of aquatic ecosystems and promote the ethos of OneHealth. By harnessing the potential of Artificial Intelligence (AI)-assisted tools, OneAquaHealth seeks to evolve environmental monitoring paradigms, thereby enabling the early identification of warning indicators pertinent to ecosystem health. This session envisages fostering a rich dialogue on how Earth Observation (EO) and Remote Sensing (RS) technologies can be ingeniously leveraged to buttress the objectives of the OneAquaHealth project and the OneHealth initiative. Topics for Attendance: 1. Advancements in Predictive Modeling: Delve into the recent advancements in predictive modelling techniques and their application in monitoring of biodiversity, ecological quality, environmental health and restoration of rivers and other aquatic ecosystems. 2. AI-Assisted Environmental Monitoring: Explore the role of AI and machine learning in enhancing environmental monitoring, identifying early warning indicators, and aiding in decision-making processes. 3. Earth Observation and Remote Sensing Technologies: Discuss the significance and the innovative applications of EO and RS technologies in understanding and monitoring ecosystem health, specially then urban freshwater ecosystems. 4. Interdisciplinary Approaches to Ecosystem Health: Engage in discussions on the interdisciplinary approaches embodying geoscience, remote sensing, and public health domains, fostering a holistic understanding and management of ecosystem health. 5. Policy Implications and Decision Support: Examine how predictive modelling and enhanced environmental monitoring can inform policy, support decision-makers, and promote practical measures to restore and sustain ecosystem health. 6. Case Studies on OneHealth Initiative: Share and learn from case studies where the OneHealth initiative has been instrumental in restoring aquatic ecosystems and promoting human well-being.\n\nThe Copernicus Data Space Ecosystem and DestinE Core Platform, conceived and operated on behalf of the European Commission by the European Space Agency, provide synergetic access to a wealth of vital information on the state of our planet. Copernicus is the most ambitious Earth observation programme to date. It provides accurate, timely and easily accessible information to improve the management of the environment, understand and mitigate the effects of climate change and ensure civil security. The Copernicus Space Component provides essential data from Space allowing the continuous monitoring of our environment for the benefit of all European Citizens and makes it available via the Copernicus Data Space Ecosystem. Copernicus Data Space Ecosystem is the new exploration element of the Copernicus Programme. The Data Space represents a paradigm shift from data distribution via downloads towards in-code API access, allowing processing, filtering, spectral index and zonal statistics calculation, limiting downloads to the resulting information. Therefore, the speed of creating insight is substantially improved and the data volumes to move are drastically reduced. Access is provided through the Copernicus Browser for user-friendly, open and intuitive online viewing, sharing and downloading of the data. In addition, the Data Space provides online coding tools and code libraries with direct access to the data, and in a commercial option, virtual machine processing capacity is made available with Sentinel imagery already on board. The Ecosystem is an open invitation to third parties to create their own complementary value-add services with the available tools and data. It provides a stable, lasting platform for building large-scale operational services, commercializing Earth Observation solutions and educating newcomers to remote sensing. Destination Earth unlocks the potential of digital modelling of the Earth system at a level that represents a real breakthrough in terms of accuracy, local detail, access-to-information speed and interactivity. The DestinE Core Platform will be accessible to a full range of stakeholders from experts, scientists and policymakers to individuals, and will employ novel digital technologies, such as cloud-based supercomputing and artificial intelligence for providing extreme-scale data analytics, Earth-system monitoring, simulation and prediction capabilities. At the same time, it will allow users to customise the platform, integrate their own data and develop their own applications. This session aims to highlight efforts and opportunities within the Copernicus Data Space and DestinE Core Platform to contribute to a rich ecosystem of advanced applications and services, providing an overview of how they work together and for some of the possibilities for onboarding and federation and empowering users to access and provide actionable information to measure and act to improve sustainability and resilience to the benefit of our planet.\n\nThis is a working session for advancing the IEEE GRSS EO data service. GRSS is developing the next-generation EO infrastructure for the archival, curation, and sharing of open data and computational resources - for the membership, by the membership. This task responds to the growing need for infrastructure support within the GRSS community, including TCs, Chapters, Global Activities, Industry. Further, it is a response to GRSS strategic direction SD1 EO Data and Compute Resources for Technical Development. Stakeholders of this infrastructure activity include GRSS (to address SD1, increase membership, contribute to outreach); TCs (common platform to leverage); GRSS members (centralized resources - links to publications, data, platform, code); general public (incentive to join, centralized repo and platform), Chapters (platform for sharing/using datasets and training). To start with, as agreed in the December 2021 AdCom, in 2022 existing cloud platforms and services should be explored and studied, among others. This infrastructure is being established utilizing NASA Visualization, Exploration, and Data Analysis (VEDA) tool together with the rasdaman (raster data manager) engine which offers analysis-ready datacube analytics and AI through user-centric APIs. Additionally, via rasdaman the worldwide largest datacube federation, EarthServer, with its 160+ PB of Earth data is integrated. EO-Cube is a Strategic Initiative of IEEE GRSS implemented by the Earth Science Informatics (ESI) Technical Committee, supported by IEEE GRSS Strategic Initiative funds which is gratefully acknowledged. Agenda: - NASA VEDA: Visualization, Exploration, and Data Analysis (Manil Maskey) - EO-Cube: The IEEE GRSS Datacube Service (Peter Baumann) - Moderated Discussion: Co-Designing the IEEE GRSS EO Service (Manil Maskey & Peter Baumann)\n\nIt is evident that data has played an important role in driving the advancement of artificial intelligence (AI). While historical attention has primarily focused on the progress of AI models, there is now a growing momentum within the AI community to establish a dedicated platform for discussing the significance of data. This momentum has resulted in data-centric AI concept that addresses the need to systematically manage data throughout the AI lifecycle which includes a spectrum of approaches aimed at the creation, iteration, evaluation, and maintenance of data within AI systems. This momentum is equally significant for the Geospatial AI community, which leverages AI to address various geoscience questions, uncover Earth science events, enrich our understanding of physical processes, and drive scientific discoveries. Additionally, the data-centric AI approach is particularly important in geoscience due to increasing dependency on data-driven methodologies. Given the scale of large Earth science missions and high-resolution numerical model simulations, a data-centric AI framework is crucial for enhancing the returns on these expensive missions and projects. While a growing body of literature on data-centric AI exists, the momentum for its adoption within the geoscience community appears relatively slow. To address this, this session will delve into critical aspects of data-centric AI and foster a collaborative environment that gathers a diverse group of geoscience researchers, practitioners, domain experts, data and platform providers, and data/AI engineers. Moreover, this session also seeks to gauge the interest in creating a dedicated venue for the Geospatial AI community to publish their work on data-centric AI. The discussion topics will encompass, but not be limited to: -Methods of Earth science data collection, aggregation, and benchmarking -Frameworks for data governance in the context of geospatial AI -Implications of data bias, variance, and drift in geoscience AI applications -Role of data in geospatial foundation models: pre-training, prompting, fine-tuning -Optimal data strategies for standard evaluation framework amidst evolving model landscapes -Data-centric explainable AI within geoscience -Studies pertaining to active learning, data cleaning, and data acquisition for AI in geoscience applications -Specialized tools and infrastructure designed to support the implementation of data-centric AI approaches in geoscience\n\nArtificial intelligence technologies for Earth observation have been dramatically improved in the last dozen years, during which a set of state-of-the-art methods involving Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Transformers, and the latest fundamental models have been widely studied and exploited for the popular tasks such as object detection, object tracking, semantic segmentation, change detection, super-resolution, and by covering various sectors such as land cover and land use analysis, urban management, security, disaster resilience. Along with the diverse and highly accurate algorithms, datasets and benchmarks are the indispensable ingredients for training deep networks, monitoring the learning process, and evaluating performance. Although numerous datasets have been proposed in recent years, we still urgently need more large-scale datasets for different tasks in different domains, especially at a time when fundamental models are popular. This session will continue last year's focus on datasets and benchmarks, with a preference for those that are large-scale, multimodal, and aligned with sustainable development goals. Firstly, larger datasets provide more comprehensive and reliable insights, leading to more accurate and effective machine learning models. This is because larger datasets allow for more diverse training examples, better coverage of the problem space, and less chance of overfitting (i.e., the model performs well on the training data but poorly on new, unseen data). Secondly, multi-modal data integration can provide richer and more comprehensive information about the Earth's surface and atmosphere by fusing data from multiple sensors, frequencies, and temporal resolutions. Thirdly, we insist that all the efforts in technology and datasets should serve for humans involving improving quality of life, boosting economic development, protecting the environment, and reducing poverty. Topics include but are not limited to - Large-scale remote sensing datasets and benchmarks; - Earth observation datasets and benchmarks with multimodal data; - datasets, benchmarks, and events relevant to sustainability (climate change, natural hazards, urban sprawl, carbon emissions, poverty, etc.) based on remote sensing data.\n\nIn the last forty years plenty of algorithms and solution have been defined for fully exploiting the potential of SAR images and extracting information by SAR data. Therefore, SAR processing has been assessed as one of the main important tools for the Earth Observation. Thanks to their coherent nature and to the ability of working in any meteorological conditions, SAR data are being intensively used for many different applications such as 3D reconstruction, feature extraction, land cover, target recognition, scatterer detection, data fusion and many others, within different domains (urban, natural, marine, etc…). In the last years, the SAR processing domain is observing a shift from traditional model-based solution to the deep learning (DL) based one. Indeed, the need of a fast and precise processing of the great amount of data new advanced sensors provide with short revisiting time matches with the versatility, efficiency, and wide applicability of DL methods. The ability of automatically extracting features from the data allow to achieve State-of-Art performance in many fields such as denoising, super-resolution and so on, perfectly fit with the need of a fast and precise processing of SAR images for a continuous Earth Observation. The actual obtained results are impressive, but many issues are still open for many applications. The main issue shared by all the DL based method for SAR image processing is the lack of real ground truth to be used as reference for the training. As matter of fact, the lack of ground truth has made many strategies to arise leveraging on synthetic data, processing of temporal series of real data or unsupervised training. This session addresses the issue of the lack of a real ground truth for DL based method within the SAR image processing framework. In particular, it focuses on the actual state-of-art solutions and on new perspective that are arising in all the possible are of SAR image processing: SAR, InSAR, PolSAR and TomoSAR. The aim is to stimulate an open discussion on the presented results and on what is worth to investigate in the near future.\n\nDigital twins are at the frontier of science when we discuss about studying and understanding complex systems and phenomena in our environment. They allow us to experiment in a well-defined environment with our current understanding of various processes and enable us to learn more about how those systems would react to changing conditions. The scientific progress plays an important role here and provides a starting point of a much longer value chain. Many different initiatives at national and international level are currently supporting the development of both necessary technologies for interoperability and exchange of data as well as the setup of digital twins in various domains for starting the modelling process. In Europe alone we have initiatives like Destination Earth, The Digital Twin of the Ocean and the Digital Twins of Environment, all contributing to the scientific progress in this domain. Additionally, many countries are launching their own targeted programs in parallel. This gives great opportunity to progress in this field but is also generating a certain risk for entropy and doubling of efforts. It is hence paramount to enable a dialog between all involved parties and exchange on as many levels as possible, from the design of the underlying software architecture and infrastructures to host those software stacks over the combination of various types of physical based and data-driven models. Questions of data quality and studies of the reliability of results in such complex systems can’t be neglected as well and ask for automated solutions, as well as making sure that the results are distributed following open science principles and the concept of FAIR data. This session aims at providing an overview of ongoing development and implementations of digital twins in the European research community. It covers both infrastructure and architectural design questions as well as examples of a successful implementation of digital twins in context of Earth Observation and related disciplines. Exchange on current developments Harmonization on the architectural design Discuss interoperability between different implementations Discuss best practices for implementation and operation of digital twins\n\nThe frequency of natural hazards associated with the land, hydrosphere, cryosphere, and atmosphere is increasing. Such an increase is evident in the mountainous region (like the Himalayas) due to climate change. The glacial lakes in the higher mountainous regions are very sensitive to climate change, the increasing temperature triggers the lake bursts that breach the dams causing floods affecting people living in the foothills and surrounding areas. All kinds of natural hazards occurring in mountainous and coastal areas that are associated with extreme events (precipitation, cloud bursts) are sensitive to climate change. The small satellites, and drone sensors together with the ground data are being used to analyze data with the AI/ML for providing early warning, mapping, and recovery plans prior to and after the natural hazards to help the community living in the vulnerable and affected areas. The space agencies are planning for new missions to help the community with the natural hazards. The session invites papers dealing with the satellite, drone, and airborne data and modeling to provide an early warning, recovery plans, and damage assessment for the benefit of the community in the affected areas.\n\nRecent advancements in the fields of remote sensing, artificial intelligence (AI) and edge computing present intriguing opportunities across various domains of science and industry that stand to directly benefit from in-orbit data processing capabilities. Such real-life applications include, but are not limited to environmental monitoring, precision agriculture, object detection and tracking, detection of natural disasters, extraction of soil properties, and many more. The integration of AI into space-based systems holds the potential to expedite responses to diverse events, primarily due to the rapid transformation of exceptionally voluminous raw data, such as multispectral or hyperspectral images, as well as the Synthetic Aperture Radar data into actionable insights directly within satellite platforms. Consequently, the transmission of such data to ground stations is significantly accelerated and cheaper, thereby offering a substantial scope for scalability in the application of AI solutions on a global scale. Nevertheless, formidable challenges persist, spanning hardware limitations, energy constraints, the utilization of limited computational resources, the scarcity of ground truth data, and the establishment of “trust” in AI-driven solutions. Additionally, (deep) machine learning models deployed on board satellites need to be robust against varying-quality data of potentially changing distribution, and are commonly trained from very limited and not necessarily spatially representative training sets, as real-world ground-truth data do not exist before the satellite is in orbit. Therefore, there have been a plethora approaches utilizing a variety of transfer learning, few-/zero-shot learning, semi-supervised learning algorithms, as well as various data augmentation algorithms to deal with this issue. Overall, to effectively deploy (deep) machine learning algorithms on board satellites, the community still needs to address important challenges related to, among others, the ground-truth data availability, efficient training and deployment of AI models, compressing the models to fit the target hardware which is both computationally- and memory-constrained. This session undertakes the above-mentioned challenges of deploying AI on board satellites (and other edge devices), and will welcome submissions spanning across, but not limited to, the following topics: - On-board deep learning for Earth observation applications, - On-board satellite data compression, - On-board band selection and feature extraction, - On-board continual learning techniques and tools, - On-board algorithm configuration and hyperparameter tuning, - Compression of deep learning models for edge devices, - Deep learning architecture design approaches for on-board processing, - On-board training and fine-tuning of machine learning models, - Robustifying on-board AI against low-quality and/or noisy data, - Few- and zero-shot learning for on-board AI, - On-board image quality enhancement, - Multi-modal on-board data analysis, - Distributed computing and distributed machine learning in Space, - Hardware approaches for accelerating on-board processing, - Data-level digital twins for synthesizing training data, - Explainable AI for on-board processing, - Validation and benchmarking of AI for on-board processing, - Examples of industrial, scientific and societal real-world impact of on-board AI.\n\n“The Sustainable Development Goals (SDG) are a universal call to action to end poverty, protect the planet and improve the lives and prospects of everyone, everywhere”. The definition of the SDG and the associated Global Indicator Framework represent a data-driven framework helping countries in evidence-based decision-making and in development policies in different domains, being the security and safety of human beings and societies at the heart of the agenda. In parallel, Earth Observation (EO) is one of the data sources to build-on to address many of these indicators. EO, together with advanced technologies for data processing, such as data fusion or artificial intelligence, enable tools that offer decision-makers enhanced capacity to monitoring, assess and act, incorporating visualization ability which is key to understand a large number of scenarios. Relevant organizations around the Globe are working in policy and decision-making mechanisms that incorporate information from different data sources, including EO, to face challenges in domains such as food security, water security, energy security or health security, with the final goal of contributing to the achievement of specific SDG indicators. However, a big challenge is encountered when some indicators in different domains are interconnected, as it is difficult to be aware and access the most recent insights obtained by the different parties involved. Thus, it is necessary to invest and put in place measures to get together current state-of-the-art solutions and results in different domains and raise awareness and foster synergies between key actors. This session will focus on current EO-based initiatives and results obtained by key actors in the international stage that are supporting the achievement of several SDG indicators in key domains, aiming at analysing the status-quo in each of the domains, while fostering cooperation and exchange of know-how and capacities.\n\nThe Earth is experiencing unprecedented climatic, geomorphologic, environmental, and anthropogenic changes. Facing the population growth effects, global warming and climate change, the Digital Twin Earth (DTE) provides capabilities to visualize, monitor and forecast natural and human activity on the planet, that contributes to sustainable development and environmental improvement. The global Earth Observation (EO) plays an important role to develop DTE. Among EO sensors, the Synthetic Aperture Radar (SAR), due to the observation capability during day and night and independence on atmospheric effects, are the only EO technology to insure global and continuous observations. SAR, unlike optical sensors, transmits pulsed signals and afterwards receives echoes reflected from objects. The 2-dimensional SAR image is then created by focusing using signal processing techniques, exhibiting the scattering behaviors of the observed field's interactions with the electromagnetic wave. A deluge of SAR sensors has increased the availability of data for diverse SAR applications. The allure of data-driven learning originates from its ability to automatically extract abstract features from massive data volumes; hence, a considerable number of deep learning researches for SAR applications have been conducted during the past few years. Current popular AI methods predominantly follows the data-driven paradigm, where a large number of SAR data is all you need to drive an intelligent network. This would address the issue of insufficient data, physical inconsistency of the prediction, and lack of interpretability. To this end, it is crucial to develop explainable and trustworthy AI technologies for various SAR applications in the future. The inherent knowledge and physics of SAR domain contribute to improving the explainability and trustworthiness of AI models. Aiming at various SAR applications, such as SAR/PolSAR/InSAR/TomoSAR..., target detection/recognition/tracking, image classification and segmentation, data generation, 3D reconstruction, etc., we encourage researchers to study and develop explainable, physics-aware, and trustworthy learning methods including but not limit to: physics-aware hybrid model, interpretable deep neural networks, post-hoc explanation algorithms, robust and trustworthy results, uncertainty quantification and explanations, physics-aware generative models, causal inference, etc. These technologies are intended for the next generation of the DTE system.\n\nThe Community Contributed Session, “Exploration and Exploitation of New Earth-Observing Satellite Applications for Weather and Climate Science”, will focus on innovative ways to utilize Earth-Observing data from new and existing satellite instruments. Already there is a plethora of Earth-Observing sensors in Geostationary (GEO) and Low Earth (LEO) orbit, managed by a multitude of international organizations that provide extensive datasets of Earth's climate and weather dynamics on both regional and global scales. However, such wealth of information is still ripe for additional exploitation, and this session aims to explore novel approaches, concepts and techniques to improve current capabilities and create new applications. Such potentials may include providing high-resolution and short-term forecasting, extreme weather prediction and monitoring, new ways to provide imaging and sounding solutions from existing sensors, and new environmental, hydrological and ecological data products and applications. This may require improved integration of sensors across the electromagnetic spectrum, implementation of more frequent or higher resolution data collection and transmission, and improvements in radiometric and spectral ground and on-orbit references. Other potential ways to achieve this include novel machine learning (ML) and deep learning algorithms for improved environmental classification and prediction applications, improvements in atmospheric composition analysis, and better integration with ground-based systems, including Earth System Digital Twins and data assimilation based on ML. In addition, technologies such as Hyper-resolution Imaging, Lidar Systems, Radio Occultation, or emerging technologies like Hyperspectral Sounding, Quantum Sensors, and SmallSats & Constellations will be needed to explore new applications in support of reducing data gaps and have a more comprehensive information of the state of the Earth. These advancements, in addition to new innovations in how the earth and atmosphere is measured and characterized, can reshape and advance our understanding and current capabilities for weather and climate science goals. It can also provide benefits in terms of more accurate predictions and earlier warnings for localized and extreme weather events, enhancements in data quality, and additional insights into the global environment.\n\nIn the Global South, the urban poor living in deprived urban areas, including ‘slums’, are more vulnerable than other urban dwellers to climate-related hazards that can negatively affect their health and wellbeing. This heightened vulnerability stems from various factors, including environmental and morphological conditions at the area level (such as building density and lack of green spaces) and household-level characteristics (such as the type of building materials used and overcrowding). Climate change exacerbates this inequality, particularly with the rise in extreme weather events like heat waves. In this session, innovative Earth Observation methods and advancements for modelling, mapping, and quantifying the urban population exposed and susceptible to extreme heat hazards will be presented, with a focus on deprived areas. AI models utilising Earth Observation, open geospatial data and Citizen Science data for fine-grained mapping of urban air temperature, population distribution and deprivation will be showcased. The contribution of local communities to the process and their active participation will be emphasised. Additionally, specific challenges faced in this field of research will be discussed, such as limited data availability, limited access to the field, and the necessity for cost-effective and scalable methods. Urban thermal inequality in the Global South must be put on the map and quantified to support advocacy efforts, facilitate dialogues between communities and local governments, and develop practical adaptation measures. This research aligns with Sustainable Development Goals (SDGs) 1 (no poverty), 3 (good health and wellbeing), 11 (sustainable cities and communities) and 13 (climate action). Its outcome has the potential to favour community-based initiatives involving simple, local, low-cost solutions, including those rooted in nature-based approaches.\n\nThe EY Open Science Data Challenge is in an annual competition for students and early career professionals interested in AI solutions to address global sustainability issues. Participants are provided with satellite data and are asked to build machine learning models focused on one of the United Nations Sustainable Development Goals (SDG). Since 2021, EY has focused the challenge topics (e.g., fire detection, biodiversity species distribution, rice crop yield forecasting) on geoscience issues and Earth remote sensing datasets. For 2024, the challenge is focused on coastal resilience. Some of the most vulnerable areas to climate change are low-lying coastal zones in developing countries and small island states. Coastal zones are characterized by narrow stretches of land that host critical ecosystems, infrastructure, and economic assets, often with conflicting interests and uses. Characterizing the environmental and socioeconomic exposure at local scales, and changes over time, is becoming increasingly critical for the sustainable management of coastlines, planning adaptation to the impacts of climate change, and the management of other climate risks. The primary goal of the challenge will be to develop baseline data products for coastal resilience in data-poor environments (e.g., Caribbean, Pacific Islands) through classification models that identify coastal infrastructure and ecosystems at local scales using satellite data and machine learning algorithms. A secondary goal of the challenge is to develop a practical disaster response plan that uses these models and uses generative AI to build a sample climate risk plan that considers other potential datasets (e.g., topography, population, socioeconomic) to address future coastal vulnerability to tropical storms. This session will present a summary of the EY Open Science Data Challenge and papers from the three international finalists.\n\nIn an era where space exploration and applications are transitioning from government-led endeavors to multi-stakeholder ventures, optimizing funding is paramount. Input will be sought from various stakeholders of the Space Domain, such as Space Agencies, leading firms in the field and research institutes that will attempt to illuminate the intricate web of financing mechanisms available – from national funds and venture capital (VCs) to European Space Agency (ESA) contributions. This session delves into the diverse funding mechanisms fueling groundbreaking research and operational infrastructures. By examining the intersection of national and international cooperation programs, this session unveils the transformative potential of collaborative efforts towards Space innovation and excellence. Key areas of discussion include the strategic exploitation of flagship programs, enabling a seamless fusion of technology, research, and investment. The session highlights how these programs serve as catalysts, propelling innovation, and scientific inquiry forward. Moreover, it addresses the critical engagement of users, sectors, and decision-makers, emphasizing the importance of inclusive collaboration. From public-private partnerships to innovative funding models, the session sheds light on creative financing approaches that empower the space industry to flourish. Participants can expect in-depth analyses of success stories, challenges faced, and lessons learned, providing invaluable insights for future endeavors. By showcasing exemplary models of collaboration and funding, this session inspires stakeholders to invest in cutting-edge technologies, shaping the future landscape of space exploration and services.\n\nAgriculture is directly affected by the ever-increasing frequency of weather extremes. In a changing climate, heavy precipitation events, droughts, flash-floods, prolonged periods of temperature extremes (heatwaves / frosts) that are occurring more often and are more intense, can destroy a year’s yield on a broad spectrum of crop types. The repetitiveness of damages from weather perils in many cases is threatening to the economic viability of the farmer. In many of those instances, however, consequences can be mitigated or even reduced to a minimum if early warning systems are available and information is timely and effectively communicated to the farmers. For that to happen, distilled information from every available source needs to emerge through novel and easy to understand tools that denote both the current state in detail as well as provide a trustworthy reachout for the near future. Services that consult on the optimal seeding time, raise alerts along the cropping season for perils that can be counterbalanced so as to avoid excessive damage (e.g. adjustments in irrigation, optimal use of pesticides, etc) and even consult of the associated risk as the harvest approaches, that can protect the effort of a whole cropping season. In recent years, a number of such services have been utilising the best of what numerical models, earth observational datasets and in-situ instruments have to offer, while in some cases hybrid approaches blend two or more of these worlds together. This session aims to showcase such exemplary attempts that help to pave a safe path towards a more sustainable agriculture in a changing climate and reduce the impact to food chain and food security.\n\nPlanetary geology studies and the understanding of outer space exotic worlds is largely based on analyses of various remote sensing data acquired by space missions. Space borne remote sensing is fundamental in understanding the formation and evolution of planetary surfaces and of their shallow subsurfaces. The surfaces of the terrestrial planets and their satellites have been largely shaped through volcanic and tectonic processes. Extreme conditions on outer solar system bodies, such as the Jovian, Saturnian, and ice giant satellites, result in different types of volcanism and tectonism. Fracturing and faulting processes mainly affect minor bodies such as asteroids and small moons, where volcanism and tectonism have not played an important role. We invite contributions that cover a wide range of topics including geomorphology and composition of volcanic deposits, edifices, and plumes, volcano-induced deformation and edifice growth and collapse to tectonic structures, faulting and fracturing processes, crustal stress and strain analysis, cryovolcanism, and any study related to planetary endogenic processes. Furthermore, studies that relay interactions between planetary interiors, surfaces, and atmospheres are welcome. Comparative studies of volcanic or tectonic systems on Earth with a strong remote sensing component are encouraged, as well as studies on terrestrial analogues that help understanding the working mechanisms of outer space bodies and vice versa.\n\nClimate change, through consequences such as global warming, rising sea levels, extended dry seasons or floods, acid rain, heavy storms, is threatening our cultural heritage and affecting our cultural landscapes. Safeguarding and protecting cultural heritage from the effects of climate change and natural hazards is urgent. There is a pressing need to explore and test innovative ways to monitor and protect monuments, historical buildings and sites from climatic risks and natural hazards. Today, Earth Observation data has the potential to provide enhanced monitoring of heritage sites over time leveraging on several technologies and techniques: ground penetrating radars (GPR), global navigation satellite systems (GNSS), LIDAR, Sonar, unmanned aerial vehicles (UAV), Autonomous Underwater Vehicles (AUV), Multispectral, Hyperspectral, SAR and 3D Remote Sensing techniques, artificial intelligence, machine learning and deep learning. A multi-source integration of space-based data and in situ observations is essential in this regard to obtain high level products and provide advanced information about ongoing risks at underwater, coastal, urban heritage sites but also cultural landscapes. This session focuses on recent advances that contribute to the protection of heritage exposed to climatic, natural, and anthropogenic hazards. Contributions may include the development of remote sensing methods and techniques, models (including 3D models), laboratory tests and field applications to enhance the ability of heritage and connected communities to withstand and adapt to the era of extreme events. Potential contributions include, but are not limited, to the following: • Innovative prototypes, models and algorithms that advance monitoring and contribute to fundamental understanding of the effects of climate-change and natural hazards on cultural heritage • Machine learning and artificial intelligence methods to identify, quantify and mitigate risks derived from natural, climatic, anthropogenic and biological hazards, including both single- and multi-hazard scenarios, at various types of heritage. • Aerial, ground, underwater, as well as integrated sensing solutions for monitoring heritage risks. • Advanced methods, including differential interferometry and time series processing, for monitoring ecosystems to assess risk for expected and unexpected events and assess their impact at heritage. • Early warning and decision support systems powered by remote sensing data to optimize heritage management. • Material characterization and advanced prediction capabilities for heritage deterioration. • Data fusion methods that enhance the development of high-performance earth observation “data cubes'' for a given cultural heritage location or epoch\n\nArtificial Intelligence (AI) applied to remotely-sensed data, particularly satellite images (like hyperspectral and multispectral images, HSI and MSI), plays a crucial role in environmental monitoring. It enables timely actions to mitigate gas emissions, identify unexpected emitters (e.g., methane sources), monitor inland water quality, extract soil parameters, and estimate pollutant data for large areas. These applications extend to scenarios requiring rapid responses and present unique challenges. Detecting and assessing floods is complex due to the environmental effects of water in affected regions. On the other hand, wildfires are natural threats that devastate ecosystems and have far-reaching socio-economic consequences. Fire behavior depends on factors such as fuel type, flammability, quantity, climate change, topography, and wind conditions. Traditionally, fire area estimation relied on field methods using GPS data, but this approach could only determine the perimeter of the hazardous area. It also faced challenges due to inaccessibility and changing fire dynamics over time. Remote sensing technology, particularly MSI/HSI, provides a more comprehensive solution. It may be exploited to extrat changes over time, enabling the identification of active fires, burned areas (also with decreased chlorophyll content), and potential fire resurgence (partial fuel burnout). This method offers advantages over traditional techniques that only consider the perimeter. Additionally, it allows for continuous monitoring of fire evolution and early detection. Volcanic ash, a cons"
    }
}