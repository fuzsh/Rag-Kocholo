{
    "id": "dbpedia_4944_3",
    "rank": 71,
    "data": {
        "url": "http://iccvm.org/2024/program.htm",
        "read_more_link": "",
        "language": "en",
        "title": "",
        "top_image": "http://www.asiagraphics.org/wp-content/uploads/2023/10/Pengshuai.jpg",
        "meta_img": "",
        "images": [
            "https://www.mip.informatik.uni-kiel.de/en/team/prof.-dr.-ing.-reinhard-koch/reinhard/@@images/37794431-b0bb-408d-90d1-3d2dfceb2f2f.jpeg",
            "http://www.asiagraphics.org/wp-content/uploads/2023/10/Pengshuai.jpg",
            "https://cseweb.ucsd.edu/~ravir/ravi-recent.jpg",
            "http://iccvm.org/2024/images/Kevin.png",
            "http://iccvm.org/2024/images/Xuequan.jpeg",
            "http://iccvm.org/2024/images/Nadia.jpeg",
            "http://iccvm.org/2024/images/Alex.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "CVM 2024 Conference Program\n\nDay 1 Wednesday, April 10, 2024 09:00 - 09:20 Opening Session 09:20 - 10:20 Keynote Speech I - Bridging the gap between 2D and 3D - 30 years of research in camera-based 3D scene reconstruction (Prof. Reinhard Koch) 10:20 - 10:40 Tea Break 10:40 - 12:20 Paper Session 1: Content Generation and Editing (Session Chair: Lin Gao, Institute of Computing, CAS) Bo Han, Yuheng Li, Yixuan Shen, Yi Ren\n\nDance2MIDI: Dance-driven Multi-Instruments Music Generation Junhong Zhao, Bing Xue, Mengjie Zhang\n\nSGformer: Boosting Transformers for Lighting Estimation from a Single Image Guo-Wei Yang, Dong-Yu Chen, Tai-Jiang Mu\n\nSketch-2-4D: Sketch Driven Dynamic 3D Scene Generation Akinobu Maejima, Seitaro Shinagawa, Hiroyuki Kubo, Takuya Funatomi, Tatsuo Yotsukura, Satoshi Nakamura, Yasuhiro Mukaigawa\n\nContinual Few-shot Patch-based Learning for Anime-style Colorization Yun Zhang, Yu-Kun Lai, Lang Nie, Fang-Lue Zhang, Lin Xu\n\nRecStitchNet: Learning to Stitch Images with Rectangular Boundaries 12:20 - 13:20 Lunch 13:20 - 15:00 Paper Session 2: Interaction and Visualization (Session Chair: Andrew Chalmers, Victoria University of Wellington) Zhaofeng Xuan, Dayan Wu, Wanqian Zhang, Qinghang Su, Bo Li, Weiping Wang\n\nCentral Similarity Consistency Hashing for Asymmetric Image Retrieval Sen-Zhe Xu, Jia-Hong Liu, Ge Yu, Song-Hai Zhang\n\nEfficiently Bypassing Obstacles to Reach Specified Locations: A Curvature Gain-Based Redirected Walking Strategy Xueyang Qin, Lishuang Li, Jingyao Tang, Fei Hao, Meiling Ge, Guangyao Pang\n\nMulti-task Visual Semantic Embedding Network for Image-text Retrieval Yang Yang, Kecheng Lu, Yu Wu, Yunhai Wang, Yi Cao\n\nCorrelation-aware Probabilistic Data Summarization for Large-scale Multi-block Scientific Data Visualization (invited CVMJ paper) Chongke Bi, Xin Gao, Baofeng Fu, Yuheng Zhao, Siming Chen, Ying Zhao, Yunhai Wang\n\nPCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation (invited CVMJ paper) 15:00 - 15:15 Tea Break 15:15 - 16:15 Paper Session 3: Crafting Reality (Session Chair: Yoonsang Lee, Hanyang University) Kangrui Zhang, Han Yan, Jia-Ming Lu, Bo Ren\n\nRod-Bonded Discrete Element Method Youxin Xing, Haowen Tan, Yanning Xu, Lu Wang\n\nA Tiny Example-Based Procedural Model for Real-Time Glinty Appearance Rendering Xiaokang Liu, Lin Lu, Lingxin Cao, Oliver Deussen, Changhe Tu\n\nAuxetic Dihedral Escher Tessellations 16:15 - 17:30 Poster Session 1: Geometry and Rendering Zhangyang Xiong, Dong Du, Yushuang Wu, Jingqi Dong, Di Kang, Linchao Bao, Xiaoguang Han\n\nPIFu for the Real World: A Self-supervised Framework to Reconstruct Dressed Human from Single-view Images Pengfei Xu, Banhuai Ruan, Youyi Zheng, Hui Huang\n\nSketchformer++: A Hierarchical Transformer Architecture for Vector Sketch Representation Yuzhou Ji, Xin Tan, He Zhu, Wuyi Liu, Jiachen Xu, Yuan Xie, Lizhuang Ma\n\nLeveraging Panoptic Prior for 3D Zero-shot Semantic Understanding within Language Embedded Radiance Fields Tong Xu, Ruhao Wang, Fei Luo, Chunxia Xiao\n\nMulti-Scale Implicit Surfaces Reconstruction for Outdoor Scenes Rongsen Chen, Junhong Zhao, Fang-Lue Zhang, Andrew Chalmers, Taehyun Rhee\n\nNeural Radiance Fields for Dynamic View Synthesis using Local Temporal Priors Gaoyang Zhang, Xinguo Liu\n\nPoint Cloud Segmentation with Guided Sampling and Continuous Interpolation Sheldon Fung, Wei Pan, Xiao Liu, John Yearwood, Richard Dazeley, Xuequan Lu\n\nTopFormer: Topology-Aware Transformer for Point Cloud Registration Jingyu Xiang, Xuanxiang Lin, Ke Chen, Kui Jia\n\nAdversarial Geometric Transformations of Point Clouds for Physical Attack Haobo Qin, Yinchang Zhou, Chao Liu, Xiaopeng Zhang, Zhanglin Cheng, Jianwei Guo\n\nSARNet: Semantic Augmented Registration of Large-Scale Urban Point Clouds Haoyu Qin, Haonan Zhang, Jie Guo, Ming Yang, Wenyang Bai, Yanwen Guo\n\nFASSET: Frame Supersampling and Extrapolation using Implicit Neural Representations of Rendering Contents Liping Wu, Bin Cheng, Wentao Chao, JunLi Zhao, Fuqing Duan\n\nMatTrans: Material Reflectance Property Estimation of Complex Objects with Transformer Day 2 Thursday, April 11, 2024 09:00 - 10:00 Keynote Speech II - Octree-based 3D Neural Networks for Graphics (Prof. Peng-Shuai Wang) 10:00 - 10:20 Tea Break Joint Workshop on Applications of Visual Media in the New Era 10:20 - 10:50 Kevin Romond, Miramar Creative Center, Victoria University of Wellington 10:50 - 11:20 Xuequan Lu, La Trobe University, Australia 11:20 - 11:30 Introduction Video of XVerse Ltd. 11:30 - 12:00 Nadia Pantidi, School of Design Innovation, Victoria University of Wellington 12:00 - 12:30 Alex Doronin, School of Engineering and Computer Science, Victoria University of Wellington 12:30 - 13:20 Lunch 13:20 - 15:00 Paper Session 4: Point Cloud (Session Chair: Ying He, Nanyang Technological University) Weijia Wang, Xiao Liu, Hailing Zhou, Lei Wei, Zhigang Deng, Manzur Murshed, Xuequan Lu\n\nNoise4Denoise: Leveraging Noise for Unsupervised Point Cloud Denoising Shuxian Cai, Yuanyan Ye, Juan Cao, Zhonggui Chen\n\nFACE: Feature-Preserving CAD Model Surface Reconstruction Junjie Gao, Qiujie Dong, Ruian Wang, Shuangmin Chen, Shiqing Xin, Changhe Tu, Wenping Wang\n\nOAAFormer: Robust and Efficient Point Cloud Registration Through Overlapping-Aware Attention in Transformer Qun-Ce Xu, Yong-Liang Yang, Bailin Deng\n\nPoint Cloud Denoising Using a Generalized Error Metric Boyuan Tan, Hongxing Qin, Xiaoxi Zhang, Yiqun Wang, Tao Xiang, Baoquan Chen\n\nUsing Multi-level Consistency Learning for Partial-to-Partial Point Cloud Registration (invited TVCG paper) 15:00 - 15:20 Tea Break 15:20 - 16:20 Paper Session 5: Human and Face (Session Chair: Alex Doronin, Victoria University of Wellington) Xu Wang, Pengkun Wang, Yudong Zhang, Binwu Wang\n\nFace Anti-spoofing with Unknown Attacks: A Comprehensive Feature Extraction and Representation Perspective Yongwei Nie, Meihua Zhao, Qing Zhang, Ping Li, Jian Zhu, Hongmin Cai\n\nMake Static Person Walk Again via Separating Pose Action From Shape Mingyuan Shen, Qun-Ce Xu, Tai-Jiang Mu\n\nDisentangling Head NeRF for 3D Facial Animation 16:20 - 17:35 Poster Session 2: Interactions and Visual Content Generation Jiancheng Huang, Yifan Liu, Linxiao Shi, Jin Qin, Shifeng Chen\n\nBK-Editer: Body-Keeping Text-Conditioned Real Image Editing Er-Xia Luo, Khang Yeu Tang, Sen-Zhe Xu, Qiang Tong, Song-Hai Zhang\n\nWalking Telescope: Exploring the Zooming Effect in Expanding Detection Threshold Range for Translation Gain Huabin Yang, Zhongjian Zhang, Yan Wang, Deyu Guan, Kangshuai Guo, Yu Chang, Yanru Zhang\n\nA U-Shaped Spatio-Temporal Transformer as Solver for Motion Capture Yunchi Zhang, Rao Fu, Ling-Xiao Zhang, Jie Yang, Fang-Lue Zhang, Yu-Kun Lai, Lin Gao\n\nROSAN: Rotation-Robust Scale-Sensitive Structure-Aware Network for Fine-grained 3D Shape Retrieval Dingyun Zhang, Heyuan Li, Juyong Zhang\n\nZero-shot Real Facial Attribute Separation and Transfer at Novel Views Yiting Wang, Shen Chen, Taiping Yao, Lizhuang Ma, Zhizhong Zhang, Xin Tan\n\nExplore and Enhance the Generalization of Anomaly DeepFake Detection Baoyun Peng, Min Liu, Zhaoning Zhang, Kai Xu, Dongsheng Li\n\nDeep Tiny Network for Recognition-Oriented Face Image Quality Assessment Yongwei Nie, Rong Pan, Qing Zhang, Xuemiao Xu, Guiqing Li, Hongmin Cai\n\nFace Expression Recognition via Product-Cross Dual Attention and Neutral-Aware Anchor Loss Yuanbin Ding, Kehan Zhu, Ping Wei, Yu Lin, Ruxin Wang\n\nDeformable CNN With Position Encoding For Arbitrary-Scale Super-Resolution Xiaonan Fang, Song-Hai Zhang\n\nSingle-Video Temporal Consistency Enhancement With Rolling Guidance [supplementary material] Pengfei Xu, Weiran Shi, Xin Hu, Hongbo Fu, Hui Huang\n\nGTLayout: Learning General Trees for Structured Grid Layout Generation Yiyu Fu, Baoquan Zhao, Chenlei Lv, Guanghui Yue, Ruomei Wang, Fan Zhou\n\nImproved Text-Driven Human Motion Generation via Out-of-Distribution Detection and Rectification[supplementary material] 18:00 - 20:00 Conference Banquet @ Harbourside Function Venue, 4 Taranaki Street, Te Aro, Wellington 6011 Day 3 Friday, April 12, 2024 09:00 - 10:00 Keynote Speech III - Image-Based Rendering: From View Synthesis to Neural Radiance Fields and Beyond (Prof. Ravi Ramamoorthi) 10:00 - 10:20 Tea Break 10:20 - 11:20 Paper Session 6: NeRF (Session Chair: Junhong Zhao, Victoria University of Wellington) Keyang Ye, Hongzhi Wu, Xin Tong, Kun Zhou\n\nA Real-time Method for Inserting Virtual Objects into Neural Radiance Fields Kuo Xu, Jie Li, Zhenqiang Li, Yangjie Cao\n\nSG-NeRF: Sparse-Input Generalized Neural Radiance Fields for Novel View Synthesis Yu-Jie Yuan, Xinyang Han, Yue He, Fang-Lue Zhang, Lin Gao\n\nMuNeRF: Robust Makeup Transfer in Neural Radiance Fields (invited TVCG paper) 11:20 - 12:20 Poster Session 3: Understanding and Stylization Xiao Cui, Nan Li, Chi Zhang, Qian Zhang, Wei Feng, Liang Wan\n\nSilhouette-based 6D Object Pose Estimation Xuechun Wang, Wentao Chao, Fuqing Duan\n\nRobust Light Field Depth Estimation over Occluded and Specular Regions Tianran Hao, Ying Tao, Meng Li, Xiao Ma, Peng Dong, Lisha Cui, Pei Lv, Mingliang Xu\n\nForeground and Background Separate Adaptive Equilibrium Gradients Loss for Long-Tail Object Detection Yue He, Lan Chen, Yu-Jie Yuan, Shu-Yu Chen, Lin Gao\n\nMulti-Level Patch Transformer for Style Transfer with Single Reference Image Zheng-Jun Du, Jia-Wei Zhou, Zi-Xun Xia, Bing-Feng Seng, Kun Xu\n\nPalette-based Content-Aware Image Recoloring Wuqin Liu, Minxuan Lin, Haibin Huang, Chongyang Ma, Weiming Dong\n\nFreeStyler: A Free-Form Stylization Method via Multimodal Vector Quantization Yaru Zhang, Xiao-Yu Zhang, Haichao Shi\n\nDenoised Dual-level Contrastive Network for Weakly-supervised Temporal Sentence Grounding Wei Zhang, Yuan Xie, Zhizhong Zhang, Xin Tan\n\nIsolation and Integration: A Strong Pre-trained Model-Based Paradigm for Class-Incremental Learning Feifei Xu, Yingchen Zhou, Zheng Zhong, Guangzhen Li\n\nObject Category-Based Visual Dialog for Effective Question Generation Zichuan Zhao, Tianhang Tang, Jie Chen, Xuelei Shi, Yiguang Liu\n\nAST: An Attention-guided Segment Transformer for Drone-based Cross-view Geo-localization Yitong Lin, Yiguang Liu\n\nImproved YOLOv5 Algorithm for Small Object Detection in Drone Images 12:20 - 13:20 Lunch 13:20 - 15:00 Paper Session 7: Visual Media Understanding (Session Chair: Can Wang, LINX Robot) Yongchi Ma, Xiao Ma, Tianran Hao, Lisha Cui, Shaohui Jin, Pei Lv\n\nKnowledge Distillation via Hierarchical Matching for Small Object Detection Zhongyu Yang, Chen Shen, Wei Shao, Tengfei Xing, Runbo Hu, Pengfei Xu, Hua Chai, Ruini Xue\n\nLDTR: Transformer-based Lane Detection with Chain-anchor Representation Dong Wang, Qi Wang, Weidong Min, Di Gai, Qing Han, Longfei Li, Yuhan Geng\n\nSAM-driven MAE Pre-training and Background-aware Meta-learning for Unsupervised Vehicle Re-identification Jiaao Li, Yixiang Huang, Ming Wu, Bin Zhang, Xu Ji, Chuang Zhang\n\nCLIP-SP:Vision-language Model with Adaptive Prompting for Scene Parsing Canbin Li, Yiguang Liu\n\nMulti-Scale Depth Guidance Transformer for Monocular Depth Estimation 15:00 - 15:20 Tea Break 15:20 - 16:20 Paper Session 8: Mesh and Modelling (Session Chair: Jianwei Guo, Institute of Automation, CAS) Yi-Bo Kou, Yi-Fei Feng, Li-Yong Shen, Xin Li, Chun-Ming Yuan\n\nAdaptive Spline Surface Fitting with Arbitrary Topological Control Mesh Zeyu Huang, Sisi Dai, Kai Xu, Hao Zhang, Hui Huang, Ruizhen Hu\n\nDINA: Deformable INteraction Analogy Long Ma, Ying He, Jianmin Zheng, Yuanfeng Zhou, Shiqing Xin, Caimin Zhang, Wenping Wang\n\nComputing Smooth and Integrable Cross Fields via Iterative Singularity Adjustment 16:20 - 16:40 Closing Session\n\nKeynote Speakers\n\nReinhard Koch, Kiel University, Germany\n\nTitle:\n\nBridging the gap between 2D and 3D - 30 years of research in camera-based 3D scene reconstruction\n\nAbstract:\n\nComputing a truthful reconstruction of 3D scenes from camera images has been an eminent topic in computer vision for at least 30 years. Ever since the groundbreaking work of Longuet-Higgins in the 1980th and Faugeras, Hartley and Zisserman and others in the 1990th, researchers have investigated solutions for this ill-posed problem. Today, deep learning approaches take over, but are still in need of basic reconstruction tasks. In my talk I will revise the approaches of this research area, from calibrated and uncalibrated Structure from Motion and SLAM, over special camera setups like Lightfield cameras or RGB-D Systems, to applications like 3D television and augmented reality.\n\nSpeaker's Biography:\n\nProf. Reinhard Koch is a professor of computer science at Kiel University since 1999 and an internationally recognized expert in 3D computer vision, visual computing and 3D scene reconstruction from different image modalities, structure from motion, time-of-flight cameras and plenoptic imaging systems. His work was honoured with numerous awards, like the David Marr Award (the highest award in computer vision), Olympus-Award, and numerous best paper awards. He served the community as chair and co-chair of the German Pattern Recognition Society and as German delegate to the International Association for Pattern Recognition (IAPR, a prestigious organization driving advancements in pattern recognition and artificial intelligence worldwide) for nine years and was elected IAPR fellow. Since 2016 he also serves as vice dean and dean of the faculty of engineering at Kiel University.\n\nPeng-Shuai Wang, Peking University, China\n\nTitle:\n\nOctree-based 3D Neural Networks for Graphics\n\nAbstract:\n\n3D deep learning has been widely applied in graphics to understand, generate, simulate, and render 3D data. However, 3D data comes in diverse representations, such as point clouds, voxels, and meshes. For different 3D representations and tasks, researchers typically design separate neural network architectures. This approach significantly increases the complexity of network design and hinders the development of general 3D intelligent models. In this talk, I will introduce my work towards developing a unified 3D deep learning framework with octree-based neural networks for graphics, including octree-based CNNs, GNNs, and transformers. The core idea is to leverage the sparsity of 3D data to constrain neural network computations to important 3D regions within an octree-based 3D representation. These efforts enable a unified, efficient, and effective 3D deep learning framework, greatly improving the efficiency of developing 3D learning methods and potentially advancing the development of general 3D intelligent systems.\n\nSpeaker's Biography:\n\nDr. Peng-Shuai Wang is a tenure-track Assistant Professor at Peking University. Before joining Peking University in 2022, he was a senior researcher in Microsoft Research Asia. He got Ph.D. degree from the Institute for Advanced Study at Tsinghua University in 2018, under the supervision of Dr. Baining Guo. His research interest includes deep learning, geometry processing and computer graphics. He was awarded the AsiaGraphics Young Researcher Award in 2023 and the AI 2000 Most Influential Scholar Award Honorable Mention by AMiner in recognition of my contributions in the field of Computer Graphics from 2012 to 2022.\n\nRavi Ramamoorthi, University of California, San Diego, USA\n\nTitle:\n\nImage-Based Rendering: From View Synthesis to Neural Radiance Fields and Beyond\n\nAbstract:\n\nApplications in augmented reality, 3D photography, immersive experiences and appearance acquisition require solving the view synthesis problem - given a few images of an object or scene of interest, how can we synthesize images from new viewpoints. This is a fundamental problem in computer vision and graphics, often referred to as image-based rendering, and can be encapsulated as reconstructing the light field of all light passing through a scene from a set of observations. In this talk, I will briefly describe the early history of the problem, and a series of efforts my group has made in light field synthesis from sparse images, ultimately leading to the now widely used neural radiance field representation. I discuss the impact of this work and follow-ups, leading to newer work from my group on personalized avatars, enabling real-time radiance fields or live 3D portraits from a single image.\n\nSpeaker's Biography:\n\nRavi Ramamoorthi is the Ronald L. Graham Professor of Computer Science at University of California, San Diego. He is currently the Director of UC San Diego Center for Visual Computing. He got his Ph.D. in Computer Science from Stanford University in 2002. His research interest includes computer graphics, computer vision and signal processing. His work has led to more than 150 publications, including more than 75 SIGGRAPH or TOG papers, and has been recognized in 2005 by a Sloan Fellowship and an NSF CAREER award, in 2007 with an ONR Young Investigator Award and the ACM SIGGRAPH Significant New Researcher Award, and more recently in 2023 by an Frontiers of Science Award. He is a fellow of both IEEE and ACM, and was selected into the SIGGRAPH Academy in 2019.\n\nWorkshop Speakers\n\nKevin Romond, Miramar Creative Center, Victoria University of Wellington\n\nTitle:\n\nBuilding a high-quality performance capture pipeline\n\nAbstract:\n\nThis talk will be an overview of how we developed a fully-featured performance capture workflow, capable of being operated by 1 or 2 operators. The talk will include an overview of performance capture goals, our approach to development, and outcomes from the effort.\n\nSpeaker's Biography:\n\nKevin Romond is an expert practitioner in performance capture, virtual production, animation, and visual effects. He has over 20 years of experience producing computer generated visual effects for feature films. His credits include King Kong (2005), Avatar (2009), Avengers (2012), The Planet of the Apes series, and many others. Kevin has spent the last 8 years working with real-time technologies for immersive experiences, VFX and filmmaking use cases. Kevin is currently Director of the Miramar Creative Centre and Senior Lecturer in Animation and Visual Effects. He has a BFA from the School of Visual Arts in New York City.\n\nXuequan Lu, La Trobe University, Australia\n\nTitle:\n\nAI-Based 3D Visual Computing\n\nAbstract:\n\nAI-based 3D visual computing has attracted noticeable attention recently, in terms of various visual tasks and multi-disciplinary research. At first, Dr Xuequan Lu will briefly introduce himself, explain 3D visual computing. Then he will introduce one of his representative recent works on 3D point cloud data, with elaborating motivations, the proposed technique and showing experimental results.\n\nSpeaker's Biography:\n\nDr. Xuequan Lu is currently a Senior Lecturer (equiv. to Associate Professor in North American System) in La Trobe University in Australia. His research interests are AI-based visual computing, with a focus on 3D vision (processing and analysis), VR/AR, and the applications to interdisciplinary digital health. He achieved an Outstanding PhD Award when graduated at Zhejiang University (only awarded to 2 students in 2016). He also achieved the School's Research Award in 2022. He is invited to act as an Associate Editor in IEEE TNNLS (top journal, JCR Q1, IF: 10.4), Neurocomputing (JCR Q1, Impact factor: 6.0) and the Visual Computer Journal (JCR Q1, Impact factor: 3.5). He serves as a Guest Editor in IEEE Intelligent Systems (JCR Q1, 1st AI journal in IEEE). In addition, he is the Program Chair for the 37th CASA 2024, the 10th IEEE ICVR 2024 and the 9th IEEE ICVR 2023.\n\nNadia Pantidi, School of Design Innovation, Victoria University of Wellington\n\nTitle:\n\nUser Experience as a Driver for System Development\n\nAbstract:\n\nMy research spans the areas of Computer Science, Interaction Design and Psychology with a particular focus on considering users' experience for the design and evaluation of technologies. Having worked across a number of application areas such as health, education, citizen science and across a range of technologies e.g. touch screens, mobile apps and more recently immersive reality systems, I have experienced first-hand the significant benefits of involving users in the development of new technologies. In this talk, I will discuss, through examples of my work, how taking a user-centered, holistic approach for the design and evaluation of interactive systems can offer deeper understanding of people's practices, needs and values, lead to novel insights for the assemblage of systems and people, and support ecological validity.\n\nSpeaker's Biography:\n\nDr. Nadia Pantidi (BA, MEng, PhD) is a Senior Lecturer in Interaction Design at the School of Design Innovation, Te Herenga Waka-Victoria University of Wellington (THW-VUW). Her research is in the area of Human Computer Interaction (HCI) and focuses on participatory and user-centered approaches for the design and evaluation of digital systems. Her work is regularly published in high impact international conferences and journals in the field of HCI, such as the Association for Computing Machinery (ACM) Conferences on Human Factors in Computing Systems (CHI), Designing Interactive Systems (DIS), Computer Supported Cooperative Work (CSCW). She has held several chairing roles in HCI venues and is currently the elected Chair of the ACM SIGCHI New Zealand Chapter. Prior to joining THW-VUW, she was a Lecturer in Human Computer Interaction at University College Cork, Ireland, and a post-doctoral researcher at the Mixed Reality Lab at the University of Nottingham, UK.\n\nAlex Doronin, School of Engineering and Computer Science, Victoria University of Wellington\n\nTitle:\n\nLight Transport in Turbid Media: Modern Applications and Synergy with Machine Learning\n\nAbstract:\n\nA fundamental understanding of the complex effects of wave propagation in turbid media is essential for applications in computer graphics, biomedical optics, and 3D visualization. This requires precise computational techniques to accurately account for the multiple scattering of light. In response to this need, we introduce a novel Monte Carlo algorithm optimized for energy-efficient processors. This algorithm distinguishes itself by surpassing existing solutions in both accuracy and performance. Our implementation focuses on photon transport simulations, leveraging the low-power yet high-performance capabilities of Apple's M-family chips. Additionally, we explore the integration of Machine Learning (ML) techniques to develop an efficient forward solver for the Radiative Transport Equation. This integration highlights the superior performance of select ML models in this domain, demonstrating our approach's potential to significantly advance the field.\n\nSpeaker's Biography:\n\nDr. Alexander Doronin is a Senior Lecturer within the School of Engineering and Computer Science at Victoria University of Wellington (New Zealand). He received his PhD in Biophotonics and Biomedical Imaging from University of Otago, New Zealand in 2014 and went on to a semi-industrial postdoctoral fellowship to Yale University, USA. His research interests are interdisciplinary and lie at the interface between Computer Graphics, Biomedical Optics and most recently Artificial Intelligence focusing on modelling of light transport in turbid media, development of novel optical diagnostics modalities, physically-based rendering, optical measurements/instrumentation, acquisition and building of realistic material models, colour perception, translucency, appearance and biomedical visualization. He has extensive recognized experience in the design of forward and inverse algorithms of light scattering in turbid tissue-like media simulations and created a generalized Monte Carlo model of photon migration which has found a widespread application as an open-access computational tool for the needs of light transport communities in Biophotonics, Biomedical Imaging and Graphics."
    }
}