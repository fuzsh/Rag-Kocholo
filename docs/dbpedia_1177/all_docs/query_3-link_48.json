{
    "id": "dbpedia_1177_3",
    "rank": 48,
    "data": {
        "url": "https://link.springer.com/article/10.1007/s11229-023-04048-y",
        "read_more_link": "",
        "language": "en",
        "title": "When iota meets lambda",
        "top_image": "https://static-content.springer.com/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Figa_HTML.png",
        "meta_img": "https://static-content.springer.com/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Figa_HTML.png",
        "images": [
            "https://link.springer.com/oscar-static/images/darwin/header/img/logo-springerlink-39ee2a28d8.svg",
            "https://media.springernature.com/w72/springer-static/cover-hires/journal/11229?as=webp",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-030-86059-2?as=webp",
            "https://media.springernature.com/w215h120/springer-static/image/art%3Aplaceholder%2Fimages/placeholder-figure-springernature.png",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-662-54332-0?as=webp",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Figa_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Figb_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Figc_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Fig1_HTML.png",
            "https://media.springernature.com/lw548/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Equ12_HTML.png",
            "https://media.springernature.com/lw480/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Equ13_HTML.png",
            "https://media.springernature.com/lw560/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Equ14_HTML.png",
            "https://media.springernature.com/lw256/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Equ15_HTML.png",
            "https://media.springernature.com/lw399/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Equ16_HTML.png",
            "https://media.springernature.com/lw202/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Equ17_HTML.png",
            "https://media.springernature.com/lw251/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Equ18_HTML.png",
            "https://media.springernature.com/lw308/springer-static/image/art%3A10.1007%2Fs11229-023-04048-y/MediaObjects/11229_2023_4048_Equ19_HTML.png",
            "https://link.springer.com/oscar-static/images/logo-springernature-white-19dd4ba190.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2023-02-15T00:00:00",
        "summary": "",
        "meta_description": "Definite descriptions are widely discussed in linguistics and formal semantics, but their formal treatment in logic is surprisingly modest. In this article",
        "meta_lang": "en",
        "meta_favicon": "/oscar-static/img/favicons/darwin/apple-touch-icon-92e819bf8a.png",
        "meta_site_name": "SpringerLink",
        "canonical_link": "https://link.springer.com/article/10.1007/s11229-023-04048-y",
        "text": "In natural languages naming expressions are used not only, and even not always, to refer to objects. They are also important information-conveying ingredients of every discourse. One of the most important class of such expressions are definite descriptions, expressions of the form ‘the so and so’, such as ‘the author of «On Denoting»’. Definite descriptions are ubiquitous not only in natural languages but also in mathematics and science (‘The sum of 7 and 5’). In artificial languages it is the iota-operator, \\(\\iota \\), due to Peano, that is usually applied to formalise definite descriptions: ‘the F’ is represented formally as \\(\\iota xF\\).\n\nThe investigation of definite descriptions since Russell’s paper “On Denoting” (1905) occupies a central place in logical, semantical, and linguistic research and many deep and detailed studies have been carried out ever since. The second half of the 20th century saw the development of new approaches to this phenomenon based on non-classical logics, in particular free logic in which, contrary to Frege’s and Russell’s assumptions, characteristic for classical logic, it is not assumed that every term refers. Such solutions found a place in the application to intensional logics where the distinctions between terms which denote existent or non-existent objects, in a rigid or non-rigid way, or simply are non-denoting, are crucial. Yet despite the long history of research into definite descriptions and a variety of solutions to the problems they pose, we can hardly say that any theory of definite descriptions is obvious or commonly accepted. In some approaches definite descriptions are not even treated as naming expressions, but rather as binary quantifiers (Neale, 1990; Kürbis, 2019a, 2021a) or predicative expressions (Graff, 2001).\n\nIn modern approaches, the category of singular terms is usually limited to proper names and functional expressions formed from the former. As a consequence, proof-theoretic tools are badly prepared to deal with reasoning tasks in natural languages, where subsentential parts, including several complex naming expressions, play a privileged role. The inclusion of a wider category of terms was characteristic for the earlier stage of the development of mathematical logic in the works of Frege (1893), Hilbert and Bernays (1968), Bernays (1958), Carnap (1947), Quine (1982), and Rosser (1978). Later, the restriction to functional terms became a norm, especially in automated deduction. In particular, definite descriptions, despite their importance in logic and formal semantics, are largely ignored. Possibly, the fact that modern treatments of theories are limited to functional terms is related to the fact that several non-equivalent theories of definite descriptions are on the market and it is not always evident which of them is fit for purpose.\n\nSince the role of definite descriptions in the field of proof theory and automated deduction has so far been underestimated, it is important to stress some advantages that using them may bring. First of all, definite descriptions are more expressive than functional terms: \\(f^n(t_1, \\ldots , t_n)\\) can be represented as \\(\\iota xF^n(t_1, \\ldots , t_n, x)\\). Getting rid of functional terms by means of definite description is also in the spirit of Russell, who, for philosophical reasons, did not introduce the former to his logic. On the other hand, not every (proper) description can be expressed using functional terms. Consider descriptions like ‘the winner of the ultimate fight’, ‘the bear we have seen recently’. It is not at all clear which parts of these expressions could be treated as functors and which as arguments. Moreover, in the case of using definite descriptions instead of functional terms we do not need extra bridge principles showing how the information encoded by the latter is represented by predicates (e.g., \\(f(x)=y \\leftrightarrow F(x,y)\\)). In languages with functional terms such bridge principles are usually necessary as enthymematic premises in an analysis of obviously valid arguments. If we use definite descriptions, such bridge principles become superfluous. Moreover, the presence of functions in formal languages often easily leads to generating infinite Herbrand domains even when finite domains are allowed. Let us illustrate this with a simple example. From \\(\\forall x(a=f(x))\\) we infer \\(a=f(a), a=f(f(a)), a=f(f(f(a))), \\ldots \\) On the other hand, from the corresponding \\(\\forall x(a=\\iota y F(x,y))\\) we can obtain a single-element model satisfying \\(a = a, F(a,a)\\), e.g., by means of tableau rules proposed by Indrzejczak and Zawidzki (2021). Additionally, definite descriptions can be used to provide smooth definitions of new terms, and even new operators, in formal languages. For example, one may define the abstraction operator in set theory in an elegant way (Tennant, 2004). Finally, it is also noteworthy that definite descriptions have recently found applications in other areas such as verification of hybrid systems (Bohrer et al., 2019), formal ontology (Oppenheimer & Zalta, 2011; Blumson, 2020), or knowledge representation (Artale et al., 2021).\n\nThese virtues of definite descriptions have not hitherto been thoroughly examined mainly because of a lack of good formal systems expressing their theories. An enormous number of books and papers have been devoted to offering solutions to logical and linguistic problems connected with definite descriptions, but the number of formal systems and their studies is relatively modest. Moreover, most approaches to the formalisation of theories of definite descriptions follow the axiomatic approach. Only comparatively few natural deduction (ND), tableau systems, or sequent calculi (SC) have been formulated. One may mention here ND systems of: Kalish and Montague (1957), Kalish et al. (1980), Stenlund (1973, 1975), Tennant (1978, 2004), Garson (2006), Carlström (2005), Francez and Więckowski (2014), and Kürbis (2019a, 2019b). But only a few of them (namely Tennant’s and Kürbis’ works) deal with definite descriptions by means of rules which allow for finer proof analysis and provide normalisation proofs. SC systems were proposed by Czermak (1974), Gratzl (2015), Orlandelli (2021), Kürbis (2021a, 2021b, 2021c), and Indrzejczak (2018, 2019, 2020a, 2020b, 2021b). There are also a few tableau calculi, due to Bencivenga et al. (1986), Gumb (2001), Bostock (1997), Fitting and Mendelsohn (1998), and Indrzejczak and Zawidzki (2021). However, with the exception of the last one, these systems introduce definite descriptions by means of rather complex rules, which makes them quite difficult to maneuver.\n\nGiven the importance of definite descriptions in formal semantics and of deductive systems such as natural deduction and sequent or tableau calculi in formal logic, it is rather surprising that so little attention has been paid to what each can contribute to the other. In this paper we focus on the problem of decent formalisation of Russell’s approach to definite descriptions which initiated the whole line of research in formal logic. However, the semantics and syntactical formalisation we offer departs from the original one, which helps us avoid some recognised drawbacks of the latter while saving its essential features, and enables its application to automated deduction.\n\nIn Sect. 2 we briefly characterise the Russellian approach to definite descriptions, then, in Sect. 3, we explain in what way the introduction of predicate-abstracts can help in avoiding some of the known pitfalls of Russell’s original account. Section 4 introduces the syntax and semantics of the considered logic, whereas in Sect. 5 we present a suitable cut-free tableau calculus. Soundness and completeness of the calculus is proved in Sect. 6. Section 7 contains a proof of the interpolation theorem and shows how, through the Beth definability property, it can be checked whether an individual constant from a given signature can be replaced by an appropriate definite description under a considered theory. The paper is briefly concluded in Sect. 8.\n\nAlmost 120 years have passed since Bertrand Russell published his groundbreaking article “On denoting” (1905). It deals with many semantical questions of a general character, but it became famous mainly for the considerations on the problem of definite descriptions. Russell’s work stands, with the works of Frege, at the beginning of the development of modern mathematical logic, and his theory of definite descriptions, presented first in the cited paper and elaborated in “Principia Mathematica” (Whitehead & Russell, 1910) and in Russell’s later work (1920), plays a central role in the foundations of logic and formal semantics. Although Russell’s theory of definite descriptions was not the first one (pride of place for the first formalisation of definite descriptions in logic belongs to Frege (1893, § 11, § 18)), it gave an enormous impact on all further studies in this area. Despite of its weak and controversial points, widely criticised (see, e.g., Strawson (1950), Donnellan (1966), Kripke (1977)), Russell’s theory has become a standard point of reference of almost all works devoted to the analysis of definite descriptions, even those which are very critical towards its applicability to definite descriptions in natural language (see, e.g., Ludlow (2021)). Moreover, it is still widely accepted by formal logicians as a proper way of handling descriptions; the scores of textbooks that use it as their official theory of definite descriptions count as witnesses for this claim. Russell’s theory has also strong affinities to logics closely connected with applications in constructive mathematics and computer science like the logic of the existence predicate by Scott (1979) or the logic of partial terms by Beeson (1985), also called the basic system of definedness logics. The latter is treated as a wider family of systems specialised to deal with partial untyped combinatorics and lambda calculi (Feferman, 1995).\n\nRussell was prompted by reflections on improper definite descriptions: what do sentences like ‘The present King of France is bald’ mean? His approach to definite descriptions (shortly RDD) was developed in opposition to Meinong’s and Frege’s views. Both Frege and Russell assumed that terms must denote but reacted in different ways to the failure of denotation (the phenomenon of improper descriptions). Frege considered four different attempts, analysed by Pelletier and Linsky (2009), and in general he urged that all definite descriptions must have designates, even if they are to be arbitrary. On the other hand, Russell refused definite descriptions the status of terms and left variables as the only terms of the formal language of mathematics. In contrast to Frege’s view, he treated descriptions as a kind of incomplete signs and showed how to get rid of them by means of contextual definitions of the form:\n\nA characteristic feature of Russell’s approach is that no meaning is assigned to the expression ‘the F’ standing alone, but only in the context of complete sentences in which it occurs. ‘The F is G’ means ‘There is exactly one F and it is G’. Thus the complex term ‘The F’ disappears upon logical analysis. Other distinctive properties of RDD, which mainly follow from Russell’s policy of omitting singular terms from the primitive expressions of a formal language altogether, are:\n\n(1)\n\na fixed truth-value (falsity) of all atomic formulas with non-denoting terms;\n\n(2)\n\nquantification rules of universal instantiation and existential generalisation restricted to variables;\n\n(3)\n\nidentity with reflexivity restricted to variables.\n\nIn fact the most important point is (1), as (2) and (3) are its consequences. According to (2), when the universal quantifier is eliminated, we cannot unrestrictedly substitute the quantified variable with an arbitrary term satisfying the conditions of proper substitution. For instance, for a non-denoting term we can deduce a formula which is false because of (1). Therefore the rule of universal elimination (or existential generalisation) must be restricted to terms known in advance to be denoting, that is, to variables as instantiated terms. Similarly in (3): if t is non-denoting, then even \\(t=t\\) is false according to (1). Therefore, reflexivity must be restricted to variables as well. Summing up: these three desiderata constitute a logic which is currently identified as a kind of negative free logic rather than classical logic.\n\nNevertheless, Russell’s account has also serious formal drawbacks. As it stands, (R) must be restricted to atomic \\(\\psi \\) or it is necessary to add means for marking scope distinctions. For example, let \\(\\psi \\) be \\(\\lnot \\)G, then the result is ambiguous between the internal and external negation of \\(\\psi (\\iota x\\varphi (x))\\), that is, between ‘It is not the case that the F is G’ and ‘The F is not G’. If we still admit complex \\(\\psi \\) in (R), the situation is even worse. If we use a valid \\(\\psi \\) and an inconsistent \\(\\varphi \\), we run into a contradiction. For example:\n\n$$\\begin{aligned} \\big [A(\\iota y(B(y)\\wedge \\lnot B(y)))\\rightarrow & {} A(\\iota y(B(y)\\wedge \\lnot B(y)))\\big ] \\\\&\\leftrightarrow&\\exists x\\big [\\forall y((B(y)\\wedge \\lnot B(y)) \\leftrightarrow y = x)\\wedge (A(y)\\rightarrow A(y))\\big ] \\end{aligned}$$\n\nleads to \\(B(a)\\wedge \\lnot B(a)\\) (modulo constant renaming).\n\nTo avoid the problems, Whitehead and Russell introduced a rather clumsy method for drawing scope distinctions that is far from ideal, which is demonstrated by the fact that almost no one uses it. Instead, a restricted binary quantifier is used to overcome scope difficulties (Bostock, 1997; Kürbis, 2019a, 2021a). One is even tempted to conjecture that a reason for the lack of proof-theoretic investigations into definite descriptions is a perceived tension between the need for drawing scope distinctions in the symbolism and the difficulties encountered in doing so.Footnote 1\n\nEven without scoping problems, the Russellian policy of reducing the category of terms only to variables seems to be inadequate, or at least problematic and artificial, with respect to processing reasoning tasks in natural languages. In fact, there is a tension between the theoretical treatment of definite descriptions by Russell and their practical applications. Whitehead and Russell (1910) formulate several theorems with definite descriptions occurring as terms. Also Kalish et al. (1980), as well as Pelletier and Linsky (2009) provide lists of theorems and rules correct in RDD and containing occurrences of definite descriptions. This shows that it is possible to save some features of the original Russellian approach to definite descriptions, yet to treat them as genuine terms. Henceforth, by RDD we mean a theory where all the abovementioned features of the Russellian approach are saved except that definite descriptions are treated as terms. In this case (R) is replaced with an object-language biconditional which can serve as a characteristic axiom of a logic. Such a logic is essentially equivalent to Feferman’s definedness logic, but expressed in a language in which the definedness predicate is eliminated. This equivalence was proved by Indrzejczak (2021a). In such a form RDD was formalised as ND by Kalish et al. (1980) and recently by Francez and Więckowski (2014). However, all these formalisations involve complex rules or axioms. Recently Indrzejczak (2021b) provided an analytic and cut-free SC equivalent to RDD as formalised by Kalish et al. (1980). In all these systems (R) is restricted to atomic predicates and special rules are required to evaluate all formulas with improper definite descriptions as false. The necessity of such a restriction of (R) can be seen as another pitfall of RDD, in particular in the context of natural language and its formalisations. Bostock rightly noticed that the qualification of some predicates as atomic is to some extent arbitrary, though reflected in signatures of non-logical symbols for a given logic. Can we offer any improvement to the state of the art? Below we introduce a variant of RDD based on the use of predicate abstracts, which avoids the discussed shortcomings while saving all plausible features of the Russellian approach.\n\nTo sum up: despite of the linguistic and philosophical problems with the Russellian approach to definite descriptions, which have enormous literature devoted to it, we have also some significant formal problems described above. It seems that we can avoid the latter problems if we enrich the language with the lambda-operator and restrict the range of what can be predicated of definite descriptions to predicate abstracts of the form \\(\\lambda x\\varphi \\), where \\(\\varphi \\) is any formula. Thus, \\(\\lambda x\\varphi \\) is a unary predicate and \\((\\lambda x\\varphi )(t)\\), where t is a term, is a formula called a lambda-atom. Accordingly, atomic formulas in the strict sense are built from predicate symbols and individual variables or constants only; definite descriptions can only be attached as arguments to lambda-atoms.\n\nPredicate abstracts built by means of the lambda-operator were first proposed in the context of studies on modal predicate logic by Stalnaker and Thomason (1968) and then the idea was further developed by Bressan (1972) and Fitting (1975). Independently, this technique was used by Scales (1969) in his formulation of attributional logic, where Aristotle’s distinction between the negation of a sentence and of a predicate is formally expressible. In fact, Scales seems to be the first one to apply predicate abstraction to formalise a theory of definite descriptions which utilises Russell’s principle (R) without restricting it to atomic predicates. However, in other respects his system is considerably far from RDD, being a kind of negative logic with some extra constraints. Predicate abstracts were also successfully applied by Fitting and Mendelsohn (1998) to obtain a theory of definite descriptions in a modal setting. Such an approach, with slight modifications, was further developed by Indrzejczak (2020a) to obtain a cut-free SC for hybrid modal logic.\n\nIn the area of modal logic this tool is mainly used for taking control over scoping difficulties concerning modal operators but also complex terms like definite descriptions. From the standpoint of proof theory it has additional advantages. In general, introducing complex terms leads to serious problems revolved around unrestricted instantiation of such terms for variables. Unrestricted instantiation in quantifier rules usually destroys the subformula property and interferes with a cut-elimination proof. Applying predicate abstracts opens a way to avoid such problems by drawing a distinction between direct predication restricted to variables and indirect predication via the lambda-operators. Since definite descriptions may appear only as arguments of predicate abstracts, respective rules for quantifiers may be restricted to individual variables or constants as the only allowed instantiated terms without losing generality or introducing some additional instantiation rules (see Indrzejczak (2020b)).\n\nSince definite descriptions are used only as arguments of predicate abstracts, the modified version of (R) is (\\(R_\\lambda \\)):\n\nwhere \\(\\varphi \\) does not contain free occurrences of x. In this way we avoid problems with scope and inconsistency described above. Not only atomic predicates but also arbitrary formulas may be used to constitute lambda atoms and definite descriptions. Moreover, no additional denotation principles for atomic formulas are needed. Indeed, for variables they hold by the fact that all variables denote, and for definite descriptions they follow from (\\(R_\\lambda \\)). This is important if someone agrees, e.g., with the abovementioned criticism of Bostock about the status of atomic predicates.\n\nTo sum up: we define the logic \\({\\textbf{L}}_{R_{\\lambda }}\\) as pure FOLI (first-order logic with identity) with added (\\(R_\\lambda \\)) and \\(\\beta \\)-conversion for the lambda-operator. More concretely, its axiomatisation is the standard axiomatisation of pure FOLI augmented with (\\(R_\\lambda \\)) and \\((\\lambda x\\psi )(b) \\leftrightarrow \\psi [x/b]\\), where b is a free variable (parameter), substituted for x in \\(\\psi \\). In general, we will consider it as defined for an arbitrary signature (the set of predicates and individual constants, but with no function symbols). Notice, however, that if any individual constants are present, then the rules for quantifier elimination and the principle of \\(\\beta \\)-conversion apply to both variables and individual constants.\n\n\\({\\textbf{L}}_{R_{\\lambda }}\\) saves the essential features of the Russellian approach. Moreover, it avoids several problems like arbitrary restriction of (R) to atomic predicates symbols, scoping difficulties, or running into contradictions. However, in the semantics it retains the eliminativist Russellian flavour in the sense that definite descriptions are not characterised in the model by an interpretation function like in other approaches. Instead they are handled only by a specific clause for lambda-atoms in the definition of the forcing relation. Such a solution considerably simplifies a formulation of the semantics and completeness proof, since we avoid simultaneous induction on the complexity of terms and formulas.\n\n4.1 Syntax\n\nWe consider sentences, that is, formulas with no free variables, built in the standard first-order language \\({\\mathcal {L}}\\) with identity treated as a logical constant. The vocabulary of \\({\\mathcal {L}}\\) consists of:\n\na countably infinite set of bound individual variables \\(\\textsf{VAR}=\\{ x, y, z\\ldots \\}\\),\n\na countably infinite set of parametric (free) individual variables \\(\\textsf{PAR}=\\{ a, b, c,\\ldots \\}\\),\n\nthe contradiction symbol \\(\\bot \\),\n\na set of propositional connectives: \\(\\lnot \\), \\(\\wedge \\),\n\nthe universal quantifier \\(\\forall \\),\n\nthe definite description operator \\(\\iota \\),\n\nthe abstraction operator \\(\\lambda \\),\n\nthe identity relation \\(=\\),\n\nleft and right parentheses: (, ).\n\nA signature \\(\\Sigma \\) for the language \\({\\mathcal {L}}\\) is a triple \\((\\textsf{PRED},\\textsf{CONS},\\textsf{ar})\\), where \\(\\textsf{PRED}\\) is a (possibly empty) set of predicates, \\(\\textsf{CONS}\\) is a (possibly empty) set of individual constants, and \\(\\textsf{ar}: \\textsf{PRED} \\longrightarrow {\\mathbb {N}}_+\\) is a function assigning a (positive) arity to each predicate.\n\nGiven a signature \\(\\Sigma =(\\textsf{PRED},\\textsf{CONS},\\textsf{ar})\\), a set of terms \\(\\textsf{TERM}\\) and a set of formulas \\(\\textsf{FOR}\\) over \\(\\Sigma \\) are defined simultaneously by the following context-free grammars:\n\n$$\\begin{aligned}&\\displaystyle \\textsf{TERM}:{:=} x \\mid a \\mid c \\mid \\iota x \\varphi ,\\\\&\\displaystyle \\textsf{FOR}:{:=} \\bot \\mid P(s_1,\\ldots , s_n) \\mid s_1 = s_2 \\mid \\lnot \\varphi \\mid \\varphi \\wedge \\psi \\mid \\forall x \\varphi \\mid (\\lambda x \\psi )(t), \\end{aligned}$$\n\nwhere \\(x \\in \\textsf{VAR}\\), \\(a \\in \\textsf{PAR}\\), \\(c \\in \\textsf{CONS}\\), \\(\\varphi ,\\psi \\in \\textsf{FOR}\\), \\(s_1, \\ldots , s_n \\in \\textsf{VAR} \\cup \\textsf{PAR} \\cup \\textsf{CONS}\\), \\(t \\in \\textsf{TERM}\\) such that x does not occur in t, and \\(P \\in \\textsf{PRED}\\) with \\(\\textsf{ar}(P)=n\\). Henceforth, we will refer to the set \\(\\textsf{VAR} \\cup \\textsf{PAR} \\cup \\textsf{CONS}\\) as \\(\\textsf{TERM}^-\\). An expression \\(\\varphi [s]\\) indicates that s occurs (freely if it is a variable) in \\(\\varphi \\). A formula \\(\\varphi [s_1/s_2]\\) is the result of a uniform substitution of \\(s_1\\) with \\(s_2\\) in \\(\\varphi \\), whereas \\(\\varphi [s_1//s_2]\\) is a result of replacing some occurrences of \\(s_1\\) in \\(\\varphi \\) with \\(s_2\\). Note that this notation is restricted to \\(s_1,s_2\\in \\textsf{TERM}^-\\) so we can make substitutions and replacements only using variables, parameters, or individual constants, but not definite descriptions. In practice, when constructing a tableau proof, variables are substituted only with parameters or constants, however in the formulation of the semantics and in metalogical proofs it may happen that variables are substituted for variables. In such cases it is assumed that the substituted variable is free after the substitution.\n\nFinally, we also use the following standard abbreviations:\n\n$$\\begin{aligned}&\\displaystyle s_1 \\ne s_2:= \\lnot (s_1=s_2) \\qquad \\top := \\lnot \\bot \\\\&\\displaystyle \\exists x \\varphi := \\lnot \\forall x \\lnot \\varphi \\qquad \\varphi \\vee \\psi := \\lnot (\\lnot \\varphi \\wedge \\lnot \\psi )\\\\&\\displaystyle \\varphi \\rightarrow \\psi := \\lnot \\varphi \\vee \\psi \\qquad \\varphi \\leftrightarrow \\psi := (\\varphi \\rightarrow \\psi ) \\wedge (\\psi \\rightarrow \\varphi ), \\end{aligned}$$\n\nwhere \\(s_1,s_2 \\in \\textsf{TERM}^-\\).\n\nNote that the absence of function symbols in considered signatures for \\({\\mathcal {L}}\\) is due to the fact, already mentioned, that they can be simulated by using the operator \\(\\iota \\).\n\n4.2 Semantics\n\nGiven a signature \\(\\Sigma = (\\textsf{PRED},\\textsf{CONS},\\textsf{ar})\\), a model over \\(\\Sigma \\) is a structure \\({\\mathcal {M}}=( {\\mathcal {D}}, {\\mathcal {I}})\\), where \\({\\mathcal {D}}\\ne \\emptyset \\) is called a domain and \\({\\mathcal {I}}\\) is an interpretation. For each predicate \\(P \\in \\textsf{PRED}\\), \\({\\mathcal {I}}(P)\\subseteq {\\mathcal {D}}^n\\), where n is the arity of P. For each constant \\(c\\in \\textsf{CONS}\\), \\({\\mathcal {I}}(c) \\in {\\mathcal {D}}\\). An assignment v is defined as a function mapping variables and parameters to elements of the domain. An x-variant \\(v'\\) of v agrees with v on all arguments, save, possibly, x. We will write \\(v^x_o\\) to denote the x-variant of v with \\(v^x_o(x) = o\\).\n\nGiven a signature \\(\\Sigma =(\\textsf{PRED},\\textsf{CONS},\\textsf{ar})\\), sets \\(\\textsf{TERM}\\) and \\(\\textsf{FOR}\\) over \\(\\Sigma \\), a model \\({\\mathcal {M}}= ({\\mathcal {D}}, {\\mathcal {I}})\\) over \\(\\Sigma \\), and an assignment v, let \\({\\mathcal {I}}_v(s)\\) be v(s) if \\(s \\in \\textsf{VAR} \\cup \\textsf{PAR}\\), or \\({\\mathcal {I}}(s)\\) if \\(s \\in \\textsf{CONS}\\). Then the notion of satisfaction of a formula \\(\\varphi \\) in \\({\\mathcal {M}}\\) under v, in symbols \\(M, v \\models \\varphi \\), is defined inductively as follows:\n\nwhere \\(P \\in \\textsf{PRED}\\) with \\(\\textsf{ar}(P) = n\\), \\(s, s_1, \\ldots , s_n \\in \\textsf{TERM}^-\\), \\(x,y \\in \\textsf{VAR}\\), and \\(\\varphi , \\psi \\in \\textsf{FOR}\\), and x is not free in \\(\\varphi \\) in condition for \\((\\lambda x\\psi )(\\iota y\\varphi )\\).\n\nA formula \\(\\varphi \\) over a signature \\(\\Sigma \\) is called satisfiable if there exists a model \\({\\mathcal {M}}\\) over \\(\\Sigma \\) and a valuation v such that \\({\\mathcal {M}}, v \\models \\varphi \\). \\(\\varphi \\) is valid, in symbols \\(\\models \\varphi \\), if, for all models \\({\\mathcal {M}}\\) and valuations v, \\({\\mathcal {M}}, v \\models \\varphi \\). In the remainder of the paper, instead of writing \\({\\mathcal {M}}, v \\models \\varphi _1, \\ldots , {\\mathcal {M}}, v \\models \\varphi _n\\), we will write \\({\\mathcal {M}}, v \\models \\varphi _1, \\ldots , \\varphi _n\\). Semantically we identify \\({\\textbf{L}}_{R_{\\lambda }}\\) as the set of all valid formulas.\n\nExample 1\n\nConsider the following sentence: ‘The oldest daughter of Anne got married to some businessman and is the richest woman in the family (of Anne)’. Let \\(d_1\\) abbreviate the first and \\(d_2\\) the second description, which after unpacking are: \\(\\iota x(D(x,a)\\wedge \\forall y(D(y,a)\\wedge y\\ne x\\rightarrow O(x,y)))\\) and \\(\\iota x\\forall y(F(y,a)\\wedge W(y)\\wedge y\\ne x\\rightarrow R(x,y))\\). Then the sentence in question is formalised as \\((\\lambda z(\\exists y(B(y)\\wedge M(z,y)) \\wedge (\\lambda u(z=u))(d_2)))(d_1)\\). It can be shown that it implies, e.g., ‘Some daughter of Anne got married to a businessman’. Let us notice that the formalisation of the above sentence in Russell’s original theory leads to a much more convoluted formula.\n\nAlthough definite descriptions are only allowed in the scope of \\(\\lambda \\)-expressions, this does not preclude the possibility of them interacting with other referring expressions such as individual constants in a single formula.\n\nExample 2\n\nConsider the following sentence: ‘Scott is the author of «Waverley».’ It states identity of a proper name (individual constant) and a definite description. The logic \\({\\textbf{L}}_{R_{\\lambda }}\\) provides us with a means to formally capture this sentence. The definite description involved can be written as \\(\\iota yA(y,w)\\), where w is the individual constant representing “Waverley” and A represents the relation of authorship. Then the discussed identity is expressed by the following formula: \\((\\lambda xs=x)(\\iota yA(y,w))\\), where s represents Scott.\n\nThe syntax and semantics of \\({\\textbf{L}}_{R_{\\lambda }}\\) make it possible to distinguish between different usages of negation, namely internal and external, without resorting to any external tools for scope demarcation, which was not possible in Russell’s original setting.\n\nExample 3\n\nConsider the sentences: ‘It is not the case that the least integer is even’ and ‘The least integer is not even’. Let the set of all integers be the domain of our interest. Then the definite description ‘the least integer’ can be formalised as \\(\\iota y(\\forall z(z\\ne y \\rightarrow z>y))\\). The first of the discussed sentences can be written as \\(\\lnot (\\lambda x D(x,2))(\\iota y\\forall z(z\\ne y \\rightarrow z>y))\\), where D is the relation of divisibility. According to the relevant semantic condition it is false that there exists a unique object o simultaneously satisfying D(o, 2) and \\(\\forall z(z\\ne o \\rightarrow z>o)\\). In other words, for each object o in the domain, either it is the case that \\(\\lnot D(o,2)\\), or \\(\\exists z(z\\ne o \\wedge z<o)\\), or there exists \\(o'\\ne o\\) in the domain such that \\(\\forall z(z\\ne o' \\rightarrow z>o')\\). On the other hand, the latter of the considered sentences can be formalised as \\((\\lambda x \\lnot D(x,2))(\\iota y\\forall z(z\\ne y \\rightarrow z>y))\\). By the semantics of \\({\\textbf{L}}_{R_{\\lambda }}\\), this formula being true implies that there exists a unique object o in the domain satisfying \\(\\lnot D(o,2)\\) and \\(\\forall z(z\\ne o \\rightarrow z>o)\\). An obvious consequence of the difference between the semantics of internally and externally used negation is that the equivalence \\(\\lnot (\\lambda x D(x,2))(\\iota y\\forall z(z\\ne y \\rightarrow z>y)) \\leftrightarrow (\\lambda x \\lnot D(x,2))(\\iota y\\forall z(z\\ne y \\rightarrow z>y))\\) is not a theorem of \\({\\textbf{L}}_{R_{\\lambda }}\\).\n\nIn this section we focus on the construction of a tableau calculus for the logic of Russellian descriptions \\({\\textbf{L}}_{R_{\\lambda }}\\), henceforth abbreviated as \\({\\textbf{TC}}_{R_{\\lambda }}\\).\n\nA tableau \\({\\mathcal {T}}\\) generated by a calculus \\({\\textbf{TC}}_{R_{\\lambda }}\\) is a derivation tree whose nodes are assigned formulas in the language of deduction. A branch of \\({\\mathcal {T}}\\) is a simple path from the root to a leaf of \\({\\mathcal {T}}\\). For simplicity, we will identify each branch \\({\\mathcal {B}}\\) with the set of formulas assigned to nodes on \\({\\mathcal {B}}\\).\n\nA general form of rules is as follows: \\(\\frac{\\Phi }{\\Psi _1 | \\ldots | \\Psi _n}\\), where \\(\\Phi \\) is the set of premises and each \\(\\Psi _i\\), for \\(i\\in \\{1,\\ldots ,n\\}\\), is a set of conclusions. If a rule has more than one set of conclusions, it is called a branching rule. Otherwise it is non-branching. Thus, if a rule \\(\\frac{\\Phi }{\\Psi _1 | \\ldots | \\Psi _n}\\) is applied to \\(\\Phi \\) occurring on \\({\\mathcal {B}}\\), \\({\\mathcal {B}}\\) splits into n branches: \\({\\mathcal {B}}\\cup \\{\\Psi _1\\}, \\ldots , {\\mathcal {B}}\\cup \\{\\Psi _n\\}\\). A rule \\(({\\textsf{R}})\\) with \\(\\Phi \\) as the set of its premises is applicable to \\(\\Phi \\) occurring on a branch \\({\\mathcal {B}}\\) if it has not yet been applied to \\(\\Phi \\) on \\({\\mathcal {B}}\\). A set \\(\\Phi \\) is called \\(({\\textsf{R}})\\)-expanded on \\({\\mathcal {B}}\\) if \\(({\\textsf{R}})\\) has already been applied to \\(\\Phi \\) on \\({\\mathcal {B}}\\). We say that \\((\\textsf{R})\\) is sound if, whenever \\(\\Phi \\) is satisfiable, then \\(\\Phi \\cup \\Psi _i\\) is satisfiable, for some \\(i \\in \\{1,\\ldots ,n\\}\\). \\((\\textsf{R})\\) is invertible if it is sound and, for each \\(i \\in \\{1,\\ldots ,n\\}\\), if \\(\\Psi _i\\) is satisfiable, then \\(\\Phi \\cup \\Psi _i\\) is satisfiable. A term t is called fresh on a branch \\({\\mathcal {B}}\\) if it has not yet occurred on \\({\\mathcal {B}}\\). We call a branch \\({\\mathcal {B}}\\) closed if the inconsistency symbol \\(\\bot \\) occurs on \\({\\mathcal {B}}\\). If \\({\\mathcal {B}}\\) is not closed, it is open. A branch is fully expanded if it is closed or no rules are applicable to (sets of) formulas occurring on \\({\\mathcal {B}}\\). Note that due to the fact that new parameters can be introduced to a branch by, e.g., \\((\\lnot \\forall )\\) or \\((\\iota _1)\\), fully expanded branches do not need to be finite. A tableau \\({\\mathcal {T}}\\) is called closed if all of its branches are closed. Otherwise \\({\\mathcal {T}}\\) is called open. Finally, \\({\\mathcal {T}}\\) is fully expanded if all its branches are fully expanded. A tableau proof of a formula \\(\\varphi \\) is a closed tableau with \\(\\lnot \\varphi \\) at its root. A formula \\(\\varphi \\) is tableau-valid (with respect to the calculus \\({\\textbf{TC}}_{R_{\\lambda }}\\)) if there exists a tableau proof of \\(\\varphi \\). It is known that a tableau calculus is confluent, that is, every partial tableau proof of a formula \\(\\varphi \\) can be expanded into a full proof (Hähnle & Beckert, 1999), if all rules are invertible. In the case of \\({\\textbf{TC}}_{R_{\\lambda }}\\) all rules are trivially invertible, as all formulas introduced to a branch at some point remain available for further rule applications. This makes \\({\\textbf{TC}}_{R_{\\lambda }}\\) a confluent tableau calculus, yet the order of rule application imposed by a decision procedure based on \\({\\textbf{TC}}_{R_{\\lambda }}\\) may affect its efficiency. We will not be pursuing this problem any further, as it is beyond the scope of this paper.\n\nIn Fig. 1 we present the rules constituting \\({\\textbf{TC}}_{R_{\\lambda }}\\). We transfer the notation from the previous section with the caveat that a denotes a parameter that is fresh on the branch, whereas \\(b, b_1, b_2\\) denote parameters or constants that have already been present on the branch. Finally, \\(b_1 \\approx b_2\\) stands for either \\(b_1 = b_2\\) or \\(b_2 = b_1\\). While the closure, propositional, quantifier rules, Leibniz’s rule and the non-empty domain rule are standard and need no further explanation, a commentary on the specific rules for the \\(\\iota \\) and \\(\\lambda \\) operators is in order.\n\n\\((\\iota _1)\\) handles the scenario where a definite description occurs in the scope of a \\(\\lambda \\)-expression. Then \\((\\iota _1)\\) stipulates that both the formulas hold of the same fresh parameter. If, moreover, a formula constituting a definite description occurs independently on the branch, then \\((\\iota _2)\\) guarantees that all the parameters it holds of are identical. If a definite description \\(\\iota y \\varphi \\) in the scope of a \\(\\lambda \\)-expression \\(\\lambda x \\psi \\) occurs in the negated form, then for any parameter b present on the branch, either \\(\\varphi \\) does not hold of b, or \\(\\psi \\) does not hold of b, or we can introduce a fresh parameter a distinct from b such that \\(\\varphi \\) holds of a. Finally, \\((\\lambda )\\) and \\((\\lnot \\lambda )\\) are tableau-counterparts of standard \\(\\beta \\)-reduction known from \\(\\lambda \\)-calculus. Their application is restricted to parameters and individual constants. Note that the rules \\((\\forall )\\) and \\((\\lnot \\iota )\\) both have an enthymematic meta-premise ‘a parameter b is present on the branch’, which manifests itself in the presence of b in the conclusions of both of them. Consequently, like any other rule, \\((\\forall )\\) and \\((\\lnot \\iota )\\) can be applied only once to a given combination of its premise and a parameter present on the branch. Observe that if there are no parameters on a branch, then neither \\((\\forall )\\) nor \\((\\lnot \\iota )\\) can be applied. In such a case, if no other rules are applicable, we apply the rule \\(({\\textsf{NE}})\\), which corresponds to the fact that we only consider non-empty domains. By that means we introduce to the branch a fresh parameter which can then fire the aforementioned rules. What is also worth noting is that whenever an application of a rule results with a formula \\(\\varphi \\) where a term \\(b_2\\) was substituted for a term \\(b_1\\), or \\(b_2\\) replaced \\(b_1\\), there is no risk that \\(b_2\\) will be bound in \\(\\varphi \\) thanks to the fact that \\(\\textsf{VAR}\\) and \\(\\textsf{PAR}\\) (as well as \\(\\textsf{VAR}\\) and \\(\\textsf{CONS}\\)) are disjoint sets.\n\nExample 4\n\nFor the sake of example, let us consider a \\({\\textbf{TC}}_{R_{\\lambda }}\\)-proof of (\\(R_\\lambda \\)), where \\(\\psi = P(x)\\) and \\(\\varphi = Q(y)\\):\n\n$$\\begin{aligned} (\\lambda x P(x))(\\iota y Q(y)) \\wedge \\forall x \\lnot (\\forall y[(\\lnot (Q(y) \\wedge y \\ne x) \\wedge \\lnot (y=x \\wedge \\lnot Q(y))]\\wedge P(x)) \\end{aligned}$$\n\nThis is a pre-processed form involving only those operators which occur in \\({\\textbf{TC}}_{R_{\\lambda }}\\); the original implication is \\((\\lambda x P(x))(\\iota y Q(y)) \\rightarrow \\exists x(\\forall y(Q(y) \\leftrightarrow y =x )\\wedge P(x))\\).\n\nNote also that the presence of the \\(\\lambda \\)-operator in the calculus prevents us from stumbling upon contradictions like in the example from p. 6.\n\nExample 5\n\nConsider the following formulas: \\(\\psi (x):=A(x)\\rightarrow A(x)\\) and \\(\\varphi (y):=B(y)\\wedge \\lnot B(y)\\). After suitably rewriting \\(\\psi (x)\\), we can show within \\({\\textbf{TC}}_{R_{\\lambda }}\\) that the formula \\((\\lambda x \\psi (x))(\\iota y \\varphi (y))\\) is not a \\({\\textbf{L}}_{R_{\\lambda }}\\) tautology, even if we assume that the domain of individual objects is non-empty, that is, there occurs a parameter on the branch (say b):\n\nConsequently, the right-hand side of (\\(R_\\lambda \\)) cannot be derived, which means that we will not get a contradiction of the form \\(B(c) \\wedge \\lnot B(c)\\).\n\nLet us now consider the following pair of formulas: \\(\\chi (x):= S(x,x)\\), \\(\\theta (y):= \\forall z (S(y,z) \\leftrightarrow \\lnot S(z,z))\\), where S(x, y) stands for ‘x shaves y’. If any of the formulas \\((\\lambda x \\chi (x))(\\iota y \\theta (y))\\) or \\((\\lambda x \\lnot \\chi (x))(\\iota y \\theta (y))\\) turned out true, this would lead to a form of Russell’s paradox. By means of \\({\\textbf{TC}}_{R_{\\lambda }}\\), however, after rewriting \\((\\lambda x \\chi (x))(\\iota y \\theta (y))\\) in the language of \\({\\textbf{L}}_{R_{\\lambda }}\\) it is possible to prove that both of them are contradictory, and hence, false. Thus, the equivalence \\((\\lambda x \\chi (x))(\\iota y \\theta (y))\\leftrightarrow (\\lambda x \\lnot \\chi (x))(\\iota y \\theta (y))\\) is indeed a theorem of \\({\\textbf{L}}_{R_{\\lambda }}\\), but, by the argument discussed in Example 3, \\({\\textbf{L}}_{R_{\\lambda }}\\) does not make true the equivalence \\((\\lambda x \\chi (x))(\\iota y \\theta (y))\\leftrightarrow \\lnot ((\\lambda x \\chi (x))(\\iota y \\theta (y)))\\), which helps us avoid the paradox. In the trees below we unpack the definition: \\(\\varphi \\leftrightarrow \\psi :=\\lnot (\\varphi \\wedge \\lnot \\psi )\\wedge \\lnot (\\psi \\wedge \\lnot \\varphi )\\).\n\nExample 6\n\nConsider the definite description from Example 2, namely ‘the author of “Waverley”’. Notice that \\({\\textbf{TC}}_{R_{\\lambda }}\\) does not prove the sentence ‘The author of “Waverley” is the author of ” Waverley”’, represented in \\({\\textbf{L}}_{R_{\\lambda }}\\) as \\((\\lambda x x=x)(\\iota y A(y,w))\\). Indeed, a derivation tree for \\(\\lnot (\\lambda x x=x)(\\iota y A(y,w))\\) looks as follows:\n\nThe formula \\((\\lambda x x=x)(\\iota y A(y,w))\\) is not provable in \\({\\textbf{TC}}_{R_{\\lambda }}\\), as we do not know whether \\(\\iota y A(y,w)\\) is a proper definite description. This is consistent with Russell’s assumptions. Notice, however, that over all theories where \\(\\iota y A(y,w)\\) is proper, that is, theories which entail \\(\\exists ! x A(x,w)\\), \\((\\lambda x x=x)(\\iota y A(y,w))\\) is provable in \\({\\textbf{TC}}_{R_{\\lambda }}\\).\n\nNow, consider two sentences: ‘Scott is the author of “Waverley”’ and ‘Scott is the author of “Ivanhoe”’, represented as \\((\\lambda x s=x)(\\iota y A(y,w))\\) and \\((\\lambda x s=x)(\\iota y A(y,i))\\), respectively. In \\({\\textbf{TC}}_{R_{\\lambda }}\\) we can show that the sentence ‘The author of “Waverley” is the author of “Ivanhoe”’, formalised as \\((\\lambda x(\\lambda y x=y)(\\iota z A(z,w)))(\\iota u A(u, i))\\), is derivable from the above sentences. Indeed:\n\nMore generally speaking, using \\({\\textbf{TC}}_{R_{\\lambda }}\\) we can show, in a similar way, that from any two of the above-mentioned sentences the remaining one is derivable.\n\nIn this section we will rely on two well-known lemmas which we recall without proofs (see, e.g., Ebbinghaus, Flum, and Thomas ( 1994, Sections III.4 and III.8)).\n\nLemma 1\n\n(Coincidence Lemma) Let \\(\\varphi \\in \\textsf{FOR} \\), let \\({\\mathcal {M}}= ( {\\mathcal {D}},{\\mathcal {I}})\\) be a model, and let \\(v_1,v_2\\) be assignments. If \\(v_1(s)=v_2(s)\\) for each free variable or parameter s occurring in \\(\\varphi \\), then \\({\\mathcal {M}}, v_1 \\models \\varphi \\) if and only if \\({\\mathcal {M}}, v_2 \\models \\varphi \\).\n\nLemma 2\n\n(Substitution Lemma) Let \\(\\varphi \\in \\textsf{FOR} \\), \\(s\\in \\textsf{TERM} ^-\\), and let \\({\\mathcal {M}}= ( {\\mathcal {D}},{\\mathcal {I}})\\) be a model. Then \\({\\mathcal {M}}, v \\models \\varphi [x/s]\\) if and only if \\({\\mathcal {M}}, v^x_{{\\mathcal {I}}_v(s)}\\models \\varphi \\).\n\n6.1 Soundness\n\nWe start the section with a lemma that relies on the notion of sound rule introduced in the preceding section.\n\nLemma 3\n\nAll rules of \\(\\textsf{TC} _{R_{\\lambda }}\\) are sound.\n\nProof\n\nSince the closure, propositional, and quantifier rules, as well as Leibniz’s and the non-empty domain rule are standard, we restrict ourselves to proving soundness of \\(\\iota \\)-rules and \\(\\lambda \\)-rules. In what follows, we assume that \\(b, b_1, b_2\\) are parameters, as a proof for them being constants is analogous.\n\n\\((\\iota _1)\\) Assume that \\((\\lambda x\\psi )(\\iota y \\varphi )\\) is satisfiable. It means that there exists a model \\({\\mathcal {M}}= ({\\mathcal {D}}, {\\mathcal {I}})\\) and an assignment v such that \\({\\mathcal {M}}, v \\models (\\lambda x \\psi )(\\iota y \\varphi )\\). Hence, by the respective satisfaction condition, there exists an object \\(o \\in {\\mathcal {D}}\\) such that \\({\\mathcal {M}},v^x_o \\models \\varphi [y/x], \\psi \\) and for all y-variants \\(v'\\) of \\(v^x_o\\), if \\({\\mathcal {M}}, v' \\models \\varphi \\), then \\(v'(y) = o\\). Without loss of generality let’s assume that a is a fresh parameter such that \\(v(a) = o\\). By the Substitution Lemma, we get that \\({\\mathcal {M}}, v \\models \\varphi [y/(x/a)],\\psi [x/a]\\), where \\(\\varphi [y/(x/a)]\\) is the result of substituting y with a which replaced x. The substitution of y with x follows from the semantic condition for lambda-atoms involving definite descriptions, wheres the substitution of x with a follows from the Substitution Lemma. Consequently, \\({\\mathcal {M}}, v \\models \\varphi [y/a],\\psi [x/a]\\), as desired.\n\n\\((\\iota _2)\\) Assume that \\((\\lambda x\\psi )(\\iota y \\varphi )\\), \\(\\varphi [y/b_1]\\), and \\(\\varphi [y/b_2]\\) are jointly satisfiable. It means that there exists a model \\({\\mathcal {M}}= ({\\mathcal {D}}, {\\mathcal {I}})\\) and an assignment v such that \\({\\mathcal {M}}, v \\models (\\lambda x \\psi )(\\iota y \\varphi ), \\varphi [y/b_1], \\varphi [y/b_2]\\). Hence, by the respective satisfaction condition, there exists an object \\(o \\in {\\mathcal {D}}\\) such that \\({\\mathcal {M}},v^x_o \\models \\varphi [y/x], \\psi \\) and, for any y-variant \\(v'\\) of \\(v^x_o\\), if \\({\\mathcal {M}}, v' \\models \\varphi \\), then \\(v'(y) = o\\). Let \\(v(b_1) = o'\\) and \\(v(b_2) = o''\\). By the Substitution Lemma, \\({\\mathcal {M}}, v^y_{o'} \\models \\varphi \\) and \\({\\mathcal {M}},v^y_{o''} \\models \\varphi \\). Since x does not occur freely in \\(\\varphi \\), by the Coincidence Lemma we get \\({\\mathcal {M}}, (v^x_o)^y_{o'} \\models \\varphi \\) and \\({\\mathcal {M}}, (v^x_o)^y_{o''} \\models \\varphi \\). Since both \\((v^x_o)^y_{o'}\\) and \\((v^x_o)^y_{o''}\\) are y-variants of \\(v^x_o\\), we obtain \\((v^x_o)^y_{o'}(y) = o\\) and \\((v^x_o)^y_{o''}(y) = o\\), and so, \\(o = o' = o''\\). As \\(o = v(b_1) = v(b_2)\\), the respective satisfaction condition yields \\({\\mathcal {M}}, v \\models b_1 = b_2\\), as expected.\n\n\\((\\lnot \\iota )\\)d Assume that \\(\\lnot (\\lambda x \\psi )(\\iota y \\varphi )\\) is satisfiable. Then there exists a model \\({\\mathcal {M}}= ({\\mathcal {D}}, {\\mathcal {I}})\\) and an assignment v such that \\({\\mathcal {M}}, v \\models \\lnot (\\lambda x \\psi )(\\iota y \\varphi )\\). By the respective satisfiability conditions it means that for all objects \\(o \\in {\\mathcal {B}}\\) (at least) one of the following three conditions holds: (1) \\({\\mathcal {M}}, v^x_o \\not \\models \\psi \\); (2) \\({\\mathcal {M}}, v^x_o \\not \\models \\varphi [y/x]\\); (3) there exists a y-variant \\(v'\\) of \\(v^x_o\\) such that \\({\\mathcal {M}}, v' \\models \\varphi \\) and \\(v'(y) \\ne o\\). Let b be a parameter present on the branch and \\(v(b) = o'\\). If (1) holds for \\(o'\\), i.e., \\({\\mathcal {M}}, v^x_{o'} \\not \\models \\psi \\), then, by the Substitution Lemma, \\({\\mathcal {M}}, v \\not \\models \\psi [x/b]\\), whence, by the respective satisfaction condition, we get \\({\\mathcal {M}}, v \\models \\lnot \\psi [x/b]\\). Let (2) hold for \\(o'\\), i.e., \\({\\mathcal {M}}, v^x_{o'} \\not \\models \\varphi [y/x]\\). By the Substitution Lemma we get \\({\\mathcal {M}}, v \\not \\models \\varphi [y/(x/b)]\\), which is equivalent to \\({\\mathcal {M}}, v \\not \\models \\varphi [y/b]\\). By the satisfaction condition for negation we obtain \\({\\mathcal {M}},v \\models \\lnot \\varphi [y/b]\\). Assume that (3) holds for \\(o'\\), that is, there exists a y-variant \\(v'\\) of \\(v^x_{o'}\\) such that \\({\\mathcal {M}}, v' \\models \\varphi \\) and \\(v'(y) \\ne o'\\). Let \\({\\mathcal {D}}\\ni o'' \\ne o'\\) be such that \\({\\mathcal {M}}, (v^x_{o'})^y_{o''} \\models \\varphi \\). Without loss of generality we may assume that there exists \\(a \\in \\textsf{PAR}\\) such that a does not occur freely in \\(\\varphi \\) and \\(v(a) = o''\\). Since x does not occur freely in \\(\\varphi \\), we can apply the Substitution Lemma twice and from \\({\\mathcal {M}}, (v^x_{o'})^y_{o''} \\models \\varphi \\) obtain \\({\\mathcal {M}}, v \\models \\varphi [y/a]\\), as desired.\n\n\\((\\lambda )\\) Let b be a parameter present on the branch. Assume that \\((\\lambda x \\psi )(b)\\) is satisfiable. Then there exists a model \\({\\mathcal {M}}= ({\\mathcal {D}}, {\\mathcal {I}})\\) and an assignment v such that \\({\\mathcal {M}}, v \\models (\\lambda x \\psi )(b)\\). By the respective satisfaction condition it means that \\(v(b) = o\\), for some \\(o \\in {\\mathcal {D}}\\), and \\({\\mathcal {M}}, v^x_o \\models \\psi \\). By the Substitution Lemma it holds that \\({\\mathcal {M}}, v \\models \\psi [x/b]\\), hence \\(\\psi [x/b]\\) is satisfiable.\n\n\\((\\lnot \\lambda )\\) Let b be a parameter present on the branch. Assume that \\(\\lnot (\\lambda x \\psi )(b)\\) is satisfiable. Then there exists a model \\({\\mathcal {M}}= ({\\mathcal {D}}, {\\mathcal {I}})\\) and an assignment v such that \\({\\mathcal {M}}, v \\models \\lnot (\\lambda x \\psi )(b)\\). By the respective satisfaction condition it means that \\({\\mathcal {M}}, v \\not \\models (\\lambda x \\psi )(b)\\). Assume that \\(v(b) = o\\) for some \\(o \\in {\\mathcal {D}}\\). Then by the respective satisfaction condition \\({\\mathcal {M}}, v^x_o \\not \\models \\varphi \\). By the Substitution Lemma we get that \\({\\mathcal {M}}, v \\not \\models \\psi [x/b]\\). Again, by the satisfaction condition for negation it follows that \\({\\mathcal {M}}, v \\models \\lnot \\psi [x/b]\\), hence \\(\\lnot \\psi [x/b]\\) is satisfiable. \\(\\square \\)\n\nNow we are ready to prove the following theorem.\n\nTheorem 4\n\n(Soundness)] The tableau calculus \\(\\textsf{TC} _{R_{\\lambda }}\\) is sound.\n\nProof\n\nLet \\(\\varphi \\) be a formula over a signature \\(\\Sigma \\). Let \\({\\mathcal {T}}\\) be a \\({\\textbf{TC}}_{R_{\\lambda }}\\)-proof of \\(\\varphi \\). Each branch of \\({\\mathcal {T}}\\) is closed. By Lemma 3 all the rules of \\({\\textbf{TC}}_{R_{\\lambda }}\\) preserve satisfiability, and so, going from the bottom to the top of \\({\\mathcal {T}}\\), we can “push” unsatisfiability of \\(\\bot \\) upwards, eventually reaching the root. Since at the root we have \\(\\lnot \\varphi \\), we conclude that it is unsatisfiable. By the well-known duality between satisfiability and validity we obtain that \\(\\varphi \\) is valid. \\(\\square \\)\n\n6.2 Completeness\n\nBelow we will show that \\({\\textbf{TC}}_{R_{\\lambda }}\\) is complete, that is, for each formula \\(\\varphi \\), if \\(\\models \\varphi \\), then there exists a \\({\\textbf{TC}}_{R_{\\lambda }}\\)-proof of \\(\\varphi \\). In order to do that, we will show the contrapositive, i.e., that whenever \\({\\textbf{TC}}_{R_{\\lambda }}\\) yields an open tableau \\({\\mathcal {T}}\\) for a formula \\(\\lnot \\varphi \\), with an open and fully expanded branch \\({\\mathcal {B}}\\), then there exists a model \\({\\mathcal {M}}_{\\mathcal {B}}= ({\\mathcal {D}}_{\\mathcal {B}}, {\\mathcal {I}}_{\\mathcal {B}})\\) and a valuation \\(v_{\\mathcal {B}}\\), that can be constructed using the data from \\({\\mathcal {B}}\\), such that \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\varphi \\). Thus, in short, we will show that if there is no \\({\\textbf{TC}}_{R_{\\lambda }}\\)-proof for \\(\\varphi \\), then \\(\\not \\models \\varphi \\). We will assume that the rules are used fairly in the sense that whenever one of them can be applied, it will eventually be applied. Moreover, let us observe that the symmetry rule \\(\\frac{s_1 = s_2}{s_2 = s_1}\\) is derivable in \\({\\textbf{TC}}_{R_{\\lambda }}\\). Indeed, it suffices to apply \\((\\textsf{L})\\) to \\(s_1 = s_2\\) (which plays a double role here: an identity formula and a formula within which we replace identical parameters) twice to obtain, subsequently, \\(s_1 = s_1\\) and \\(s_2 = s_1\\). Thus, in this section we will use expressions of the forms \\(s_1 = s_2\\) and \\(s_2 = s_1\\) interchangeably whenever necessary.\n\nLet \\(\\varphi \\) be a formula over a signature \\(\\Sigma = (\\textsf{PAR},\\textsf{CONS},\\textsf{ar})\\). Let \\({\\mathcal {T}}\\) be an open \\({\\textbf{TC}}_{R_{\\lambda }}\\)-tableau for \\(\\varphi \\), where \\({\\mathcal {B}}\\) is an open and fully expanded branch. Let \\(\\textsf{CONS}({\\mathcal {B}})\\), \\(\\textsf{VAR}({\\mathcal {B}})\\), and \\(\\textsf{PAR}({\\mathcal {B}})\\) be the sets of, respectively, all constants, all bound variables, and all parameters occurring on \\({\\mathcal {B}}\\). We define a binary relation \\(\\sim _{\\mathcal {B}}\\) on \\(\\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\). Let \\(s_1,s_2 \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\). Then:\n\n$$\\begin{aligned} s_1\\sim _{\\mathcal {B}}s_2\\quad \\text {iff}\\quad s_1=s_ 2\\text { occurs on }{\\mathcal {B}}\\ \\text { or }\\ s_1\\text { is identical to }s_2. \\end{aligned}$$\n\nProposition 5\n\n\\(\\sim _{\\mathcal {B}}\\) is an equivalence relation.\n\nProof\n\nOf course, \\(\\sim _{\\mathcal {B}}\\) is reflexive. Indeed, every \\(s \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\) is identical to itself, hence, by the definition of \\(\\sim _{\\mathcal {B}}\\), \\(s \\sim _{\\mathcal {B}}s\\). Symmetry of \\(\\sim _{\\mathcal {B}}\\) is a consequence of \\({\\mathcal {B}}\\) being fully expanded and the rule \\(\\frac{s_1 = s_2}{s_2 = s_1}\\) being derivable in \\({\\textbf{TC}}_{R_{\\lambda }}\\). Indeed, if \\(s_1,s_2 \\in \\textsf{CONS}({\\mathcal {B}})\\cup \\textsf{PAR}({\\mathcal {B}})\\) are distinct and \\(s_1 \\sim _{\\mathcal {B}}s_2\\), it means that \\(s_1 = s_2\\) was on \\({\\mathcal {B}}\\). Hence \\(s_2 = s_1\\) is also on \\({\\mathcal {B}}\\), and so, \\(s_2 \\sim _{\\mathcal {B}}s_1\\). For transitivity assume that \\(s_1,s_2,s_3 \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\), \\(s_1 \\sim _{\\mathcal {B}}s_2\\), and \\(s_2 \\sim _{\\mathcal {B}}s_3\\). If \\(s_1\\) is identical to \\(s_2\\) or \\(s_2\\) is identical to \\(s_3\\), we immediately obtain \\(s_1 \\sim _{\\mathcal {B}}s_3\\). If \\(s_1, s_2, s_3\\) are pairwise distinct, the identities \\(s_1 = s_2\\) and \\(s_2 = s_3\\) must have occurred on \\({\\mathcal {B}}\\). A single application of \\((\\textsf{L})\\) to both of them yields \\(s_1 = s_3\\) and since \\({\\mathcal {B}}\\) is fully expanded, \\(s_1 = s_3 \\in {\\mathcal {B}}\\). Hence, \\(s_1 \\sim _{\\mathcal {B}}s_3\\). \\(\\square \\)\n\nObviously, thanks to the rule \\((\\textsf{L})\\) and expandedness of \\({\\mathcal {B}}\\), \\(\\sim _{\\mathcal {B}}\\) is also a congruence, that is, for any \\(s_1,s_2 \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\) such that \\(s_1 \\sim _{\\mathcal {B}}s_2\\), it holds that \\(\\varphi [s_1] \\in {\\mathcal {B}}\\) if and only if \\(\\varphi [s_1/s_2] \\in {\\mathcal {B}}\\).\n\nDefinition 1\n\n(Branch model and valuation) Let \\({\\mathcal {B}}\\) be an open and fully expanded branch of a \\({\\textbf{TC}}_{R_{\\lambda }}\\)-tableau \\({\\mathcal {T}}\\) with \\(\\varphi \\) over a signature \\(\\Sigma = (\\textsf{PRED}, \\textsf{CONS}, \\textsf{ar})\\) at the root.\n\nA branch model is a tuple \\({\\mathcal {M}}_{\\mathcal {B}}= ({\\mathcal {D}}_{\\mathcal {B}}, {\\mathcal {I}}_{\\mathcal {B}})\\) such that:\n\n\\({\\mathcal {D}}_{\\mathcal {B}}\\) is a set of \\(\\sim _{\\mathcal {B}}\\)-equivalenve classes over \\(\\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\) (note that thanks to the rule \\(({\\textsf{NE}})\\), \\({\\mathcal {D}}_{\\mathcal {B}}\\) is non-empty, as required);\n\nFor each \\(c \\in \\textsf{CONS}({\\mathcal {B}})\\), \\({\\mathcal {I}}(c) = [c]_{\\sim _{\\mathcal {B}}}\\);\n\nFor each \\(P \\in \\textsf{PRED}\\) and \\(n \\in {\\mathbb {N}}_+\\) such that \\(\\textsf{ar}(P) = n\\), \\({\\mathcal {I}}_{\\mathcal {B}}(P) = \\{\\langle {\\mathcal {I}}_{v_{\\mathcal {B}}}(s_1),\\ldots ,{\\mathcal {I}}_{v_{\\mathcal {B}}}(s_n)\\rangle \\mid P(s_1,\\ldots ,s_n) \\in {\\mathcal {B}}\\}\\).\n\nA branch valuation is a function \\(v_{\\mathcal {B}}:\\textsf{PAR}({\\mathcal {B}}) \\cup \\textsf{VAR}({\\mathcal {B}}) \\longrightarrow {\\mathcal {D}}_{\\mathcal {B}}\\) defined as follows:\n\n$$\\begin{aligned} v_{\\mathcal {B}}(s) = {\\left\\{ \\begin{array}{ll} {[}s]_{\\sim _{\\mathcal {B}}},&{}\\text { if } s\\in \\textsf{PAR}({\\mathcal {B}});\\\\ {[}s_0]_{\\sim _{\\mathcal {B}}},&{}\\text { if } s\\in \\textsf{VAR}({\\mathcal {B}}), \\end{array}\\right. } \\end{aligned}$$\n\nwhere \\(s_0\\) is the parameter that occurred on \\({\\mathcal {B}}\\) first.\n\nOf course, all branch models and branch valuations are, respectively, models and valuations in the sense of Sect. 4.2.\n\nWe are now ready to prove the key results of this section.\n\nLemma 6\n\nLet \\(\\varphi \\) be a formula over a signature \\(\\Sigma =(\\textsf{PRED} ,\\textsf{CONS} ,\\textsf{ar} )\\), \\({\\mathcal {T}}\\) be an open \\(\\textsf{TC} _{R_{\\lambda }}\\)-tableau with \\(\\lnot \\varphi \\) at the root, and \\({\\mathcal {B}}\\) an open and fully expanded branch of \\({\\mathcal {T}}\\). Then for each formula \\(\\psi \\):\n\n$$\\begin{aligned} \\text {If} \\quad \\psi \\in {\\mathcal {B}},\\quad \\text {then} \\quad {\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\psi . \\end{aligned}$$\n\nProof\n\nThe proof is by induction on complexity of \\(\\psi \\). Note that since \\({\\mathcal {B}}\\) is open, \\(\\bot \\) could not have occurred on \\({\\mathcal {B}}\\).\n\n\\(\\psi = P(s_1,\\ldots ,s_n)\\) Assume that \\(P(s_1,\\ldots ,s_n) \\in {\\mathcal {B}}\\). Then \\(s_1,\\ldots ,s_n \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\) and by the definition of \\({\\mathcal {M}}_{\\mathcal {B}}\\) and \\(v_{\\mathcal {B}}\\), \\({\\mathcal {I}}_{v_{\\mathcal {B}}}(s_i) = [s_i]_{\\sim _{\\mathcal {B}}}\\), \\(1 \\le i \\le n\\), \\(\\langle {\\mathcal {I}}_{v_{\\mathcal {B}}}(s_1), \\ldots , {\\mathcal {I}}_{v_{\\mathcal {B}}}(s_n)\\rangle \\in {\\mathcal {I}}_{\\mathcal {B}}(P)\\), and so, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models P(s_1,\\ldots ,s_n)\\).\n\n\\(\\psi = s_1=s_2\\) Assume that \\(s_1=s_2 \\in {\\mathcal {B}}\\). It means that \\(s_1,s_2 \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\). By the definition of \\(\\sim _{\\mathcal {B}}\\), \\([s_1]_{\\sim _{\\mathcal {B}}} = [s_2]_{\\sim _{\\mathcal {B}}}\\), and so, \\({\\mathcal {I}}_{v_{\\mathcal {B}}}(s_1) = {\\mathcal {I}}_{v_{\\mathcal {B}}}(s_2)\\). Thus, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models s_1=s_2\\).\n\n\\(\\psi = (\\lambda x \\chi )(s)\\) Assume that \\((\\lambda x \\chi )(s)\\in {\\mathcal {B}}\\). Since \\({\\mathcal {B}}\\) is fully expanded, the rule \\((\\lambda )\\) must have been applied to \\(\\psi \\), yielding \\(\\chi [x/s] \\in {\\mathcal {B}}\\). By the inductive hypothesis, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\chi [x/s]\\). By the Substitution Lemma, \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[s]_{\\sim _{\\mathcal {B}}}} \\models \\chi \\), which, together with the fact that \\({\\mathcal {I}}_{v_{\\mathcal {B}}}(s) = [s]_{\\sim _{\\mathcal {B}}}\\), gives \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models (\\lambda x \\chi )(s)\\).\n\n\\(\\psi = (\\lambda x \\chi )(\\iota y \\theta )\\) Assume that \\((\\lambda x \\chi )(\\iota y \\theta )\\in {\\mathcal {B}}\\). Due to expandedness of \\({\\mathcal {B}}\\), the rule \\((\\iota _1)\\) must have been applied to \\(\\psi \\), yielding \\(\\chi [x/a], \\theta [y/a] \\in {\\mathcal {B}}\\). By the inductive hypothesis, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\chi [x/a],\\theta [y/a]\\). By the Substitution Lemma, \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[a]_{\\sim _{\\mathcal {B}}}} \\models \\chi , \\theta [y/a]\\). Now, let b be a parameter such that \\(\\theta [y/b] \\in {\\mathcal {B}}\\). Then \\((\\iota _2)\\) was applied to \\(\\theta [y/a]\\) and \\(\\theta [y/b]\\) yielding \\(a=b \\in {\\mathcal {B}}\\). By the inductive hypothesis \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\theta [y/b]\\). Since, by the construction of \\({\\textbf{L}}_{R_{\\lambda }}\\)-atoms involving definite descriptions, x does not occur in \\(\\theta [y/b]\\), by the Coincidence Lemma we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})_{[a]_{\\sim _{\\mathcal {B}}}}^x \\models \\theta [y/b]\\). Further, by the Substitution Lemma, it follows that \\({\\mathcal {M}}_{\\mathcal {B}}, ((v_{\\mathcal {B}})^x_{[a]_{\\sim _{\\mathcal {B}}}})^y_{[b]_{\\sim _{\\mathcal {B}}}} \\models \\theta \\). Also by the inductive hypothesis \\(v_{\\mathcal {B}}(b)=v_{\\mathcal {B}}(a)\\). Since b is arbitrary and \\(((v_{\\mathcal {B}})^x_{[a]_{\\sim _{\\mathcal {B}}}})^y_{[b]_{\\sim _{\\mathcal {B}}}}\\) is a y-variant of \\((v_{\\mathcal {B}})^x_{[a]_{\\sim _{\\mathcal {B}}}}\\), we get \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models (\\lambda x \\chi )(\\iota y \\theta )\\).\n\n\\(\\psi = \\chi \\wedge \\theta \\) Assume that \\(\\chi \\wedge \\theta \\in {\\mathcal {B}}\\). Since \\({\\mathcal {B}}\\) is fully expanded, \\((\\wedge )\\) must have been applied to \\(\\chi \\wedge \\theta \\), and so \\(\\chi ,\\theta \\in {\\mathcal {B}}\\). By the inductive hypothesis, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\chi ,\\theta \\), and so, by the satisfaction condition for \\(\\wedge \\), \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\chi \\wedge \\theta \\).\n\n\\(\\psi = \\forall x \\chi \\) Assume that \\(\\forall x \\chi \\in {\\mathcal {B}}\\) and that \\(b \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\). By expandedness of \\({\\mathcal {B}}\\), \\((\\forall )\\) must have been applied to \\(\\forall x \\chi \\) and b yielding \\(\\varphi [x/b] \\in {\\mathcal {B}}\\). By the inductive hypothesis we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\varphi [x/b]\\), whence, by the Substitution Lemma, we get \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[b]_{\\sim _{\\mathcal {B}}}}\\models \\varphi \\). Since b was arbitrary and \\({\\mathcal {D}}_{\\mathcal {B}}\\) is defined over the set of all constants and parameters on \\({\\mathcal {B}}\\), we arrive at \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\forall x \\chi \\).\n\n\\(\\psi = \\lnot \\bot \\) Assume that \\(\\lnot \\bot \\in {\\mathcal {B}}\\). Since \\({\\mathcal {M}}_{\\mathcal {B}}\\) is a well-defined \\({\\textbf{L}}_{R_{\\lambda }}\\) model and \\(v_{\\mathcal {B}}\\) is a well-defined \\({\\textbf{L}}_{R_{\\lambda }}\\) valuation, we have \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\not \\models \\bot \\). By the satisfaction condition for \\(\\lnot \\) we obtain \\({\\mathcal {M}}_{\\mathcal {B}},v_{\\mathcal {B}}\\models \\lnot \\bot \\).\n\n\\(\\psi = \\lnot P(s_1,\\ldots ,s_n)\\) Assume that \\(\\lnot P(s_1,\\ldots ,s_n) \\in {\\mathcal {B}}\\). Then \\(s_1,\\ldots ,s_n \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\) and since \\({\\mathcal {B}}\\) is open, \\(P(s_1,\\ldots ,s_n)\\notin {\\mathcal {B}}\\). Then, by the definition of \\({\\mathcal {M}}_{\\mathcal {B}}\\) and \\(v_{\\mathcal {B}}\\), it holds that \\({\\mathcal {I}}_{v_{\\mathcal {B}}}(s_i) = [s_i]_{\\sim _{\\mathcal {B}}}\\), \\(1 \\le i \\le n\\), \\(\\langle {\\mathcal {I}}_{v_{\\mathcal {B}}}(s_1), \\ldots , {\\mathcal {I}}_{v_{\\mathcal {B}}}(s_n)\\rangle \\) \\(\\notin {\\mathcal {I}}_{\\mathcal {B}}(P)\\). Thus, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\not \\models P(s_1,\\ldots ,s_n)\\), and so, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot P(s_1,\\ldots ,s_n)\\).\n\n\\(\\psi = s_1\\ne s_2\\) Assume that \\(s_1\\ne s_2 \\in {\\mathcal {B}}\\). It means that \\(s_1,s_2 \\in \\textsf{CONS}({\\mathcal {B}}) \\cup \\textsf{PAR}({\\mathcal {B}})\\). By openness of \\({\\mathcal {B}}\\), \\(s_1=s_2 \\notin {\\mathcal {B}}\\), and by the definition of \\(\\sim _{\\mathcal {B}}\\), \\([s_1]_{\\sim _{\\mathcal {B}}} \\ne [s_2]_{\\sim _{\\mathcal {B}}}\\). Therefore, \\({\\mathcal {I}}_{v_{\\mathcal {B}}}(s_1) \\ne {\\mathcal {I}}_{v_{\\mathcal {B}}}(s_2)\\), and so, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\not \\models s_1=s_2\\) and \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models s_1\\ne s_2\\).\n\n\\(\\psi = \\lnot (\\lambda x \\chi )(s)\\) Assume that \\(\\lnot (\\lambda x \\chi )(s)\\in {\\mathcal {B}}\\). Since \\({\\mathcal {B}}\\) is fully expanded, the rule \\((\\lnot \\lambda )\\) was applied to \\(\\psi \\), giving \\(\\lnot \\chi [x/s] \\in {\\mathcal {B}}\\). By the inductive hypothesis, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\chi [x/s]\\). By the Substitution Lemma, \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[s]_{\\sim _{\\mathcal {B}}}} \\models \\lnot \\chi \\), and so, \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[s]_{\\sim _{\\mathcal {B}}}} \\not \\models \\chi \\). Since \\({\\mathcal {I}}_{v_{\\mathcal {B}}}(s) = [s]_{\\sim _{\\mathcal {B}}}\\), the satisfaction condition for \\(\\lambda \\)-expressions (without \\(\\iota \\)-expressions) yields \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot (\\lambda x \\chi )(s)\\).\n\n\\(\\psi = \\lnot (\\lambda x \\chi )(\\iota y \\theta )\\) Assume that \\(\\lnot (\\lambda x\\chi )(\\iota y \\theta )\\in {\\mathcal {B}}\\) and that b is a parameter present on \\({\\mathcal {B}}\\). Since \\({\\mathcal {B}}\\) is fully expanded, the rule \\((\\lnot \\iota )\\) was applied to \\(\\psi \\), making, for any b on the branch, one of the following three hold: (1) \\(\\lnot \\chi [x/b] \\in {\\mathcal {B}}\\), (2) \\(\\lnot \\theta [y/b] \\in {\\mathcal {B}}\\), (3) there is a fresh a such that \\(\\theta [y/a], a\\ne b \\in {\\mathcal {B}}\\). Assume (1) is the case. By the inductive hypothesis we get \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\chi [x/b]\\). By the Substitution Lemma we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[b]_{\\sim _{\\mathcal {B}}}} \\models \\lnot \\chi \\), and so, \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[b]_{\\sim _{\\mathcal {B}}}} \\not \\models \\chi \\). If (2) holds, then by, the inductive hypothesis, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\theta [y/b]\\). By the Substitution Lemma we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^y_{[b]_{\\sim _{\\mathcal {B}}}} \\models \\lnot \\theta \\), and so, \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[b]_{\\sim _{\\mathcal {B}}}} \\not \\models \\theta [y/x]\\). Finally, let (3) hold. Then, by the inductive hypothesis, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\theta [y/a], a\\ne b\\), whence \\([a]_{\\sim _{\\mathcal {B}}} \\ne [b]_{\\sim _{\\mathcal {B}}}\\). Since x does not occur freely in \\(\\theta [y/a]\\), it holds that \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[b]_{\\sim _{\\mathcal {B}}}} \\models \\theta [y/a]\\) By the Substitution Lemma we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, ((v_{\\mathcal {B}})^x_{[b]_{\\sim _{\\mathcal {B}}}})^y_{[a]_{\\sim _{\\mathcal {B}}}} \\models \\theta \\). As previously noted, \\([a]_{\\sim _{\\mathcal {B}}} \\ne [b]_{\\sim _{\\mathcal {B}}}\\), which means, by the respective satisfaction condition, that taking these three possibilities together, we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, ((v_{\\mathcal {B}})^x_{[b]_{\\sim _{\\mathcal {B}}}})^y_{[a]_{\\sim _{\\mathcal {B}}}} \\not \\models (\\lambda x \\chi )(\\iota y \\theta )\\) and \\({\\mathcal {M}}_{\\mathcal {B}}, ((v_{\\mathcal {B}})^x_{[b]_{\\sim _{\\mathcal {B}}}})^y_{[a]_{\\sim _{\\mathcal {B}}}} \\models \\lnot (\\lambda x \\chi )(\\iota y \\theta )\\). Neither x nor y occurs freely in \\(\\lnot (\\lambda x \\chi )(\\iota y \\theta )\\), so after applying the Substitution Lemma twice we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot (\\lambda x \\chi )(\\iota y \\theta )\\).\n\n\\(\\psi = \\lnot \\lnot \\chi \\) Assume that \\(\\lnot \\lnot \\chi \\in {\\mathcal {B}}\\). Since \\({\\mathcal {B}}\\) is fully expanded, \\((\\lnot \\lnot )\\) was applied to \\(\\lnot \\lnot \\chi \\), which resulted in \\(\\chi \\in {\\mathcal {B}}\\). By the inductive hypothesis, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\chi \\). Applying the satisfaction condition for \\(\\lnot \\) twice, we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\lnot \\chi \\).\n\n\\(\\psi = \\lnot (\\chi \\wedge \\theta )\\) Assume that \\(\\lnot (\\chi \\wedge \\theta ) \\in {\\mathcal {B}}\\). By expandedness of \\({\\mathcal {B}}\\) we know that \\((\\lnot \\wedge )\\) was applied to \\(\\lnot (\\chi \\wedge \\theta )\\), which resulted in \\(\\lnot \\chi \\in {\\mathcal {B}}\\) or \\(\\lnot \\theta \\in {\\mathcal {B}}\\). Assume the former. By the inductive hypothesis, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\chi \\), and therefore, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\not \\models \\chi \\). By the satisfaction condition for \\(\\wedge \\) it follows that \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\not \\models \\chi \\wedge \\theta \\). Consequently, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot (\\chi \\wedge \\theta )\\). The reasoning for the latter case is analogous.\n\n\\(\\psi = \\lnot \\forall x \\chi \\) Assume that \\(\\lnot \\forall x \\chi \\in {\\mathcal {B}}\\). Since \\({\\mathcal {B}}\\) is fully expanded, \\((\\lnot \\forall )\\) was applied to \\(\\lnot \\forall x \\chi \\) resulting in \\(\\lnot \\varphi [x/a] \\in {\\mathcal {B}}\\) for some then fresh parameter \\(a \\in \\textsf{PAR}({\\mathcal {B}})\\). By the inductive hypothesis we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\varphi [x/a]\\) and \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\not \\models \\varphi [x/a]\\), whence, by the Substitution Lemma, we get \\({\\mathcal {M}}_{\\mathcal {B}}, (v_{\\mathcal {B}})^x_{[a]_{\\sim _{\\mathcal {B}}}} \\not \\models \\varphi \\). By the satisfaction condition for \\(\\forall \\) we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\not \\models \\forall x \\chi \\), and thus, \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\forall x \\chi \\). \\(\\square \\)\n\nFinally, we are able to establish the completeness result.\n\nTheorem 7\n\n(Completeness) \\(\\textsf{TC} _{R_{\\lambda }}\\) is complete.\n\nProof\n\nWe show that if a formula \\(\\varphi \\) does not have a \\({\\textbf{TC}}_{R_{\\lambda }}\\)-proof, then it is not valid. Assume that \\(\\varphi \\) does not have a \\({\\textbf{TC}}_{R_{\\lambda }}\\)-proof. Then each fully expanded tableau \\({\\mathcal {T}}\\) with \\(\\lnot \\varphi \\) at the root has an open and fully expanded branch. Let \\({\\mathcal {B}}\\) be such a branch. By Lemma 6 we know that \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\models \\lnot \\varphi \\). Since \\({\\mathcal {M}}_{\\mathcal {B}}\\) is a well-defined model and \\(v_{\\mathcal {B}}\\) is a well-defined valuation, we obtain \\({\\mathcal {M}}_{\\mathcal {B}}, v_{\\mathcal {B}}\\not \\models \\varphi \\), hence \\(\\varphi \\) is not valid. \\(\\square \\)\n\nIn this section we will show that \\({\\textbf{L}}_{R_{\\lambda }}\\) satisfies two important properties: the Craig interpolation property and the Beth definability property. We say that a logic \\({\\textsf{L}}\\) satisfies the Craig interpolation property if, for all \\({\\textsf{L}}\\)-formulas \\(\\varphi \\) and \\(\\psi \\) (over any signature), if \\(\\models \\varphi \\rightarrow \\psi \\), then we can construct an interpolant formula, that is, a formula \\(\\chi \\) such that \\(\\models \\varphi \\rightarrow \\chi \\), \\(\\models \\chi \\rightarrow \\psi \\) and \\(\\chi \\) contains only predicates, constants and parameters common to both \\(\\varphi \\) and \\(\\psi \\). Let \\({\\textsf{L}}\\) be an extension of first-order logic with equality and let \\(\\textsf{Th}\\) be an \\({\\textsf{L}}\\)-theory over \\(\\Sigma =(\\textsf{PRED},\\textsf{CONS},\\textsf{ar})\\). We say that a constant c is implicitly definable with respect to \\(\\textsf{Th}\\) if, for any two models \\({\\mathcal {M}}, {\\mathcal {M}}'\\) of \\(\\textsf{Th}\\) such that \\({\\mathcal {M}}\\mid _{\\Sigma {\\setminus }\\{c\\}} = {\\mathcal {M}}'\\mid _{\\Sigma {\\setminus }\\{c\\}}\\), and any formula \\(\\psi \\) over \\(\\Sigma \\), \\({\\mathcal {M}}\\models \\psi \\) if and only if \\({\\mathcal {M}}' \\models \\psi \\). In other words, c is implicitly definable if whenever \\({\\mathcal {M}}\\) and \\({\\mathcal {M}}'\\) are identical with respect to all formulas over the reduced signature \\(\\Sigma '=(\\textsf{PRED},\\textsf{CONST}{\\setminus }\\{c\\}, \\textsf{ar})\\), then they are identical with respect to all formulas over the full signature \\(\\Sigma \\). A constant c is said to be explicitly definable with respect to \\(\\textsf{Th}\\) if there exists a formula \\(\\psi \\) over \\(\\Sigma '=(\\textsf{PRED},\\textsf{CONS} {\\setminus }\\{c\\}, \\textsf{ar})\\) such that \\(\\textsf{Th} \\models \\forall x,\\overline{y}(x=c \\leftrightarrow \\psi (x,\\overline{y}))\\). Implicit and explicit definability of predicates is defined analogously. \\({\\textsf{L}}\\) has the Beth definability property if, for any signature \\(\\Sigma = (\\textsf{PRED},\\textsf{CONS},\\textsf{ar})\\), any \\({\\textsf{L}}\\)-theory \\(\\textsf{Th}\\) over \\(\\Sigma \\), and any \\(\\alpha \\in \\textsf{PRED} \\cup \\textsf{CONS}\\) implicit and explicit definability of \\(\\alpha \\) are equivalent. Since for the purpose of this section we are interested in constants rather than predicates,Footnote 2 we provide a formalisation of the condition for implicit definability restricted to constants (Hermes, 1973). Let \\({\\textsf{L}}\\) have the Beth definability property and let c be a constant like characterised above. Then the following conditions are equivalent:\n\n(i)\n\n\\(\\textsf{Th} \\cup \\textsf{Th}' \\models c = c'\\)\n\n(ii)\n\n\\(\\textsf{Th} \\models \\forall x,\\overline{y} (x=c \\leftrightarrow \\psi (x,\\overline{y}))\\),\n\nwhere \\(\\mathsf {Th'}\\) is a theory resulting from replacing all occurrences of c in \\(\\textsf{Th}\\) with \\(c'\\) and \\(\\psi \\) is a formula over \\(\\Sigma ' = (\\textsf{PRED},\\textsf{CONS}{\\setminus }\\{c\\}, \\textsf{ar})\\) and \\(\\overline{y}\\) is a tuple of variables of arbitrary length.\n\nA nice feature of our calculus \\({\\textbf{TC}}_{R_{\\lambda }}\\) is that it can be used to prove that the logic \\({\\textbf{L}}_{R_{\\lambda }}\\) enjoys the Craig interpolation property by actually showing, for a valid implication \\(\\varphi \\rightarrow \\psi \\), how to construct an interpolant. To this end we exploit a technique introduced by Smullyan (1968) and further adjusted to the tableaux setting by Fitting (1996). To take full advantage of this method we need to modify \\({\\textbf{TC}}_{R_{\\lambda }}\\) so that all the rules, save \\((\\bot _1)\\), are single-premise rules. Consider the following two transformed rules:\n\n$$\\begin{aligned}{} & {} (\\mathsf {L'})\\ \\dfrac{\\varphi [b_1]}{b_1\\ne b_2 \\mid \\varphi [b_1//b_2]}\\\\{} & {} ( \\iota _2') \\ \\dfrac{(\\lambda x\\psi )(\\iota y \\varphi )}{\\lnot \\varphi [y/b_1] \\mid \\lnot \\varphi [y/b_2] \\mid b_1 = b_2} \\end{aligned}$$\n\nLet \\({\\textbf{TC}}_{R_{\\lambda }}'\\) be \\({\\textbf{TC}}_{R_{\\lambda }}\\) with \\((\\textsf{L})\\) and \\((\\iota _2)\\) replaced with \\((\\mathsf {L'})\\) and \\((\\iota _2')\\), respectively. In what follows we want to show that \\({\\textbf{TC}}_{R_{\\lambda }}\\) and \\({\\textbf{TC}}_{R_{\\lambda }}'\\) coincide. To that end we will exploit the cut rule:\n\n$$\\begin{aligned} (\\textsf{cut})\\ \\dfrac{\\ }{\\varphi \\mid \\lnot \\varphi } \\end{aligned}$$\n\nand the following proposition.\n\nProposition 8\n\n\\((\\textsf{cut} )\\) is admissible in \\(\\textsf{TC} _{R_{\\lambda }}\\).\n\nProof\n\nWe will show that whatever is provable in \\({\\textbf{TC}}_{R_{\\lambda }}\\) with the added \\((\\textsf{cut})\\)-rule, is provable in sole \\({\\textbf{TC}}_{R_{\\lambda }}\\). It follows from completeness of \\({\\textbf{TC}}_{R_{\\lambda }}\\) and the fact that \\((\\textsf{cut})\\) is a sound rule. Assume that \\(\\varphi \\) is not provable in \\({\\textbf{TC}}_{R_{\\lambda }}\\), although it has a proof in \\({\\textbf{TC}}_{R_{\\lambda }}\\) with \\((\\textsf{cut})\\). Hence, by completeness of \\({\\textbf{TC}}_{R_{\\lambda }}\\), \\(\\lnot \\varphi \\) is satisfiable. Since \\((\\textsf{cut})\\) is sound, then every application of it to an open branch in a tableau for \\(\\lnot \\varphi \\) leads to a satisfiable extension, contrary to our assumption. \\(\\square \\)\n\nTherefore we can apply \\((\\textsf{cut})\\) safely in \\({\\textbf{TC}}_{R_{\\lambda }}\\) to show derivability of other rules.\n\nLemma 9\n\n\\(\\textsf{TC} _{R_{\\lambda }}\\) and \\(\\textsf{TC} _{R_{\\lambda }}'\\) are equivalent.\n\nProof\n\nFirst we prove that \\(( \\iota _2')\\) is derivable in \\({\\textbf{TC}}_{R_{\\lambda }}\\):\n\nBelow we show that \\((\\iota _2)\\) is derivable in \\({\\textbf{TC}}_{R_{\\lambda }}'\\):\n\nIn a similar way we prove derivability of \\((\\mathsf {L'})\\) in \\({\\textbf{TC}}_{R_{\\lambda }}\\) (again with \\((\\textsf{cut})\\)) and derivability of \\((\\textsf{L})\\) in \\({\\textbf{TC}}_{R_{\\lambda }}'\\) (without \\((\\textsf{cut})\\)). Hence the two calculi are equivalent, both cut-free and analytic. \\(\\square \\)\n\nThanks to Lemma 9 we can use \\({\\textbf{TC}}_{R_{\\lambda }}'\\) for proving the interpolation property for \\({\\textbf{L}}_{R_{\\lambda }}\\).\n\nLet us consider closed tableaux for valid implications in \\({\\textbf{TC}}_{R_{\\lambda }}'\\). Each tableau can be mechanically transformed into a biased tableau in the following way. Without loss of generality we assume that at the root of a proof tree of a valid implication we have a formula of the form \\(\\varphi \\wedge \\lnot \\psi \\). We delete the root, replace \\(\\varphi \\) with \\(\\texttt{L}\\ \\varphi \\) and \\(\\lnot \\psi \\) with \\(\\texttt{R}\\lnot \\psi \\), and continue the process of assigning prefixes \\(\\texttt{L}, \\texttt{R}\\): for each application of a rule we precede with \\(\\texttt{L}\\) all conclusions of the premise prefixed with \\(\\texttt{L}\\) and with \\(\\texttt{R}\\) all conclusions of the R-premise. This way all formulas, save \\(\\bot \\) at the end of each branch, are signed in a way that makes explicit their ancestry: they follow either from the antecedent \\(\\texttt{L}\\ \\varphi \\) or from the succedent \\(\\texttt{R}\\ \\psi \\) of the original implication.\n\nTheorem 10\n\n(Craig interpolation) \\(\\textsf{L} _{R_{\\lambda }}\\) enjoys the Craig interpolation property.\n\nProof\n\nLet us recall that we are dealing with sentences only, so \\(\\varphi , \\psi \\) contain no free variables. To simplify the presentation, we will be using freely non-primitive constants \\(\\vee , \\rightarrow , \\exists \\), assuming tacitly that in respective tableau proofs their definitions are used. We build up an interpolant constructively, starting from each occurrence of \\(\\bot \\) at the end of a branch, and going up the tree. In general, at each stage we consider the last applied rule and having already established interpolants for conclusions of the applied rule we extract an interpolant for the premise with respect to all formulas which are above on the branch. Thus, the general scheme is:\n\nIf \\(\\chi _1, ..., \\chi _k\\) are interpolants for \\(\\Gamma \\cup \\{\\Psi _1\\}, \\ldots , \\Gamma \\cup \\{\\Psi _k\\}\\), then \\(\\texttt{I}(\\chi _1, \\ldots , \\chi _k)\\) is an interpolant for \\(\\Gamma \\cup \\{\\varphi \\}\\), where \\(\\varphi \\) is the premise of the applied rule and \\(\\Psi _1, \\ldots , \\Psi _k\\) are all the (sets of) conclusions, and \\(\\Gamma \\) is the set of all formulas on the branch above the premise.\n\nClearly, the specific rules for calculating interpolants are in two versions for each rule: the L-variant with \\(\\texttt{L}\\), or the R-variant with \\(\\texttt{R}\\) assigned to the premise and conclusions (in the case of \\((\\bot _1)\\) there are four combinations). Let \\(\\gamma _1,..., \\gamma _n\\) be the set of all formulas such that \\(\\texttt{L}\\ \\gamma _i\\in \\Gamma \\), and let \\(\\delta _1,..., \\delta _m\\) be the set of all formulas such that \\(\\texttt{R}\\ \\delta _i\\in \\Gamma \\). For each rule we are showing that for its L-variant:\n\nIf, for every \\(i\\le k\\), \\(\\models \\psi _i\\wedge \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\chi _i\\) and \\(\\models \\chi _i\\rightarrow \\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\), then \\(\\models \\varphi \\wedge \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow I(\\chi _1, \\ldots , \\chi _k)\\)\n\nand for the R-variant:\n\nIf, for every \\(i\\le k\\), \\(\\models \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\chi _i\\) and \\(\\models \\chi _i\\rightarrow \\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\vee \\lnot \\psi _i\\), then \\(\\models I(\\chi _1, \\ldots , \\chi _k)\\rightarrow \\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\vee \\lnot \\varphi \\)\n\nBelow we state the principles for calculating interpolants for the specific rules of \\({\\textbf{TC}}_{R_{\\lambda }}'\\). For the remaining rules they can be found in Fitting’s work (1996).\n\n\\((\\bot _2^\\texttt{L})\\):\n\n\\(\\bot \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ b\\ne b\\}\\).\n\n\\((\\bot _2^\\texttt{R})\\):\n\n\\(\\top \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ b\\ne b\\}\\).\n\n\\((\\mathsf {L'}^\\texttt{L})\\):\n\nIf \\(\\chi _1\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ b_1\\ne b_2\\}\\) and \\(\\chi _2\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\varphi [b_1// b_2]\\}\\), then \\(\\forall x(\\chi _1\\vee \\chi _2[b_2/x])\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\varphi [b_1]\\}\\).\n\n\\((\\mathsf {L'}^\\texttt{R})\\):\n\nIf \\(\\chi _1\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ b_1\\ne b_2\\}\\) and \\(\\chi _2\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\varphi [b_1// b_2]\\}\\), then \\(\\exists x(\\chi _1\\wedge \\chi _2[b_2/x])\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\varphi [b_1]\\}\\).\n\n\\((\\lambda ^\\texttt{L})\\):\n\nIf \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\psi [x/b]\\}\\), then \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ (\\lambda x\\psi )(b)\\}\\).\n\n\\((\\lambda ^\\texttt{R})\\):\n\nIf \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\psi [x/b]\\}\\), then \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ (\\lambda x\\psi )(b)\\}\\).\n\n\\((\\lnot \\lambda ^\\texttt{L})\\):\n\nIf \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\lnot \\psi [x/b]\\}\\), then \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\lnot ((\\lambda x\\psi )(b))\\}\\).\n\n\\((\\lnot \\lambda ^\\texttt{R})\\):\n\nIf \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\lnot \\psi [x/b]\\}\\), then \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\lnot ((\\lambda x\\psi )(b))\\}\\).\n\n\\((\\iota _1^\\texttt{L})\\):\n\nIf \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\psi [x/a], \\texttt{L}\\ \\varphi [x/a]\\}\\), then \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ (\\lambda x\\psi )(\\iota y\\varphi )\\}\\).\n\n\\((\\iota _1^\\texttt{R})\\):\n\nIf \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\psi [x/a], \\texttt{R}\\ \\varphi [x/a]\\}\\), then \\(\\chi \\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ (\\lambda x\\psi )(\\iota y\\varphi )\\}\\).\n\n\\(({\\iota _2'}^\\texttt{L})\\):\n\nIf \\(\\chi _1\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\lnot \\varphi [y/b_1]\\}\\), \\(\\chi _2\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\lnot \\varphi [y/b_2]\\}\\) and \\(\\chi _3\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ b_1 = b_2\\}\\), then \\(\\forall x\\forall y(\\chi _1\\vee \\chi _2\\vee \\chi _3[b_1/x,b_2/y])\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ (\\lambda x\\psi )(\\iota y\\varphi )\\}\\).\n\n\\(({\\iota _2'}^\\texttt{R})\\):\n\nIf \\(\\chi _1\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\lnot \\varphi [y/b_1]\\}\\), \\(\\chi _2\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\lnot \\varphi [y/b_2]\\}\\) and \\(\\chi _3\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ b_1 = b_2\\}\\), then \\(\\exists x\\exists y(\\chi _1\\wedge \\chi _2\\wedge \\chi _3[b_1/x,b_2/y])\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ (\\lambda x\\psi )(\\iota y\\varphi )\\}\\).\n\n\\((\\lnot \\iota ^\\texttt{L})\\):\n\nIf \\(\\chi _1\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\lnot \\psi [y/b]\\}\\), \\(\\chi _2\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\lnot \\varphi [y/b]\\}\\) and \\(\\chi _3\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\varphi [y/a], \\texttt{L}\\ a\\ne b\\}\\), then \\(\\forall x(\\chi _1\\vee \\chi _2\\vee \\chi _3[b/x])\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{L}\\ \\lnot ((\\lambda x\\psi )(\\iota y\\varphi ))\\}\\).\n\n\\((\\lnot \\iota ^\\texttt{R})\\):\n\nIf \\(\\chi _1\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\lnot \\psi [y/b]\\}\\), \\(\\chi _2\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\lnot \\varphi [y/b]\\}\\) and \\(\\chi _3\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\varphi [y/a], \\texttt{R}\\ a\\ne b\\}\\), then \\(\\exists x(\\chi _1\\wedge \\chi _2\\wedge \\chi _3[b/x])\\) is an interpolant for \\(\\Gamma \\cup \\{\\texttt{R}\\ \\lnot ((\\lambda x\\psi )(\\iota y\\varphi ))\\}\\)\n\nLet us check the hardest case of \\((\\iota _2')\\). The remaining ones can be shown by using an analogous argument. For the L-variant we assume that:\n\n1\n\n\\(\\models \\lnot \\varphi [y/b_1]\\wedge \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\chi _1\\)\n\n2\n\n\\(\\models \\chi _1\\rightarrow \\lnot \\delta _1\\vee ...\\vee \\lnot \\delta _m\\)\n\n3\n\n\\(\\models \\lnot \\varphi [y/b_2]\\wedge \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\chi _2\\)\n\n4\n\n\\(\\models \\chi _2\\rightarrow \\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\)\n\n5\n\n\\(\\models b_1 = b_2\\wedge \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\chi _3\\)\n\n6\n\n\\(\\models \\chi _3\\rightarrow \\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\)\n\nOn this basis we can show that \\(\\forall x\\forall y(\\chi _1\\vee \\chi _2\\vee \\chi _3[b_1/x, b_2/y])\\) is the required interpolant. Let us assume that one or both of \\(b_1\\), \\(b_2\\) occur in any of \\(\\chi _1, \\chi _2, \\chi _3\\), but not in \\(\\gamma _1, \\ldots , \\gamma _n\\). It follows that they must also occur in \\(\\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\). If the assumption is not satisfied, then the universal quantification of \\(\\chi _1\\vee \\chi _2\\vee \\chi _3\\) is either unnecessary (if they occur also in \\(\\gamma _1, \\ldots , \\gamma _n\\)) or void (if they are not in \\(\\chi _1, \\chi _2, \\chi _3\\)), and hence, also unnecessary. From 2, 4, 6 it obviously follows that \\(\\models \\forall x \\forall y(\\chi _1\\vee \\chi _2\\vee \\chi _3[b_1/x, b_2/y])\\rightarrow \\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\). We show, using \\({\\textbf{TC}}_{R_{\\lambda }}\\), that from 1, 3, 5 it follows that \\(\\models (\\lambda x\\psi )(\\iota y\\varphi )\\wedge \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\forall x \\forall y(\\chi _1\\vee \\chi _2\\vee \\chi _3[b_1/x, b_2/y])\\). Assume, towards a contradiction, that this implication is not valid, that is, by completeness of \\({\\textbf{TC}}_{R_{\\lambda }}\\), there is an open branch in the tableau containing \\((\\lambda x\\psi )(\\iota y\\varphi ), \\gamma _1, \\ldots , \\gamma _n, \\lnot \\forall x \\forall y(\\chi _1\\vee \\chi _2\\vee \\chi _3[b_1/x, b_2/y])\\). Since \\(b_1\\), \\(b_2\\) are not present on the branch, we can add \\(\\lnot \\chi _1, \\lnot \\chi _2, \\lnot \\chi _3\\) to the branch with these parameters as fresh. Again, by completeness of \\({\\textbf{TC}}_{R_{\\lambda }}\\) we know that each of 1, 3, 5 has a proof, hence applying \\((\\textsf{cut})\\) thrice with these implications and their negations as cut formulas we obtain their occurrences on the open branch. By applying systematically branching rules to them we obtain \\(\\varphi [y/b_1], \\varphi [y/b_2], b_1 \\ne b_2\\); all other branches containing \\(\\lnot \\gamma _1, \\ldots , \\lnot \\gamma _n, \\chi _1, \\chi _2, \\chi _3\\) must be closed. Eventually, an application of \\((\\iota _2)\\) yields \\(b_1 = b_2\\) on the branch, thus making it closed, so \\(\\models (\\lambda x\\psi )(\\iota y\\varphi )\\wedge \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\forall x\\forall y(\\chi _1\\vee \\chi _2\\vee \\chi _3[b_1/x, b_2/y])\\), contrary to our assumption. Since \\(\\forall x\\forall y(\\chi _1\\vee \\chi _2\\vee \\chi _3[b_1/x, b_2/y])\\) contains only predicates and parameters which are common to \\((\\lambda x\\psi )(\\iota y\\varphi )\\wedge \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\) and \\(\\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\), we are done.\n\nFor the R-variant we assume that:\n\n1’.:\n\n\\(\\models \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\chi _1\\);\n\n2’.:\n\n\\(\\models \\chi _1\\rightarrow \\lnot \\delta _1\\vee ...\\vee \\lnot \\delta _m\\vee \\varphi [y/b_1]\\);\n\n3’.:\n\n\\(\\models \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\chi _2\\);\n\n4’.:\n\n\\(\\models \\chi _2\\rightarrow \\lnot \\delta _1\\vee ...\\vee \\lnot \\delta _m\\vee \\varphi [y/b_2]\\);\n\n5’.:\n\n\\(\\models \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\chi _3\\);\n\n6’.:\n\n\\(\\models \\chi _3\\rightarrow \\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\vee b_1\\ne b_2\\);\n\nOn this basis we can show that \\(\\exists x\\exists y(\\chi _1\\wedge \\chi _2\\wedge \\chi _3[b_1/x, b_2/y])\\) is the required interpolant. Let us assume that one or both of \\(b_1, b_2\\) occur in any of \\(\\chi _1, \\chi _2, \\chi _3\\), but not in \\(\\delta _1, \\ldots , \\delta _m\\). It follows that they must also occur in \\(\\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\). If, on the other hand, our assumption is false, then the existential quantification of \\(\\chi _1\\wedge \\chi _2\\wedge \\chi _3\\) is either unnecessary (if one or both of \\(b_1, b_2\\) occur also in \\(\\delta _1, \\ldots , \\delta _m\\)) or void (if they are not in \\(\\chi _1, \\chi _2, \\chi _3\\)), and hence, also unnecessary. From 1’, 3’, 5’ it straightforwardly follows that \\(\\models \\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\rightarrow \\exists x \\exists y(\\chi _1\\wedge \\chi _2\\wedge \\chi _3[b_1/x, b_2/y])\\). We show, using \\({\\textbf{TC}}_{R_{\\lambda }}\\), that 2’, 4’, 6’ imply \\(\\models \\exists x \\exists y(\\chi _1\\wedge \\chi _2\\wedge \\chi _3[b_1/x, b_2/y])\\rightarrow \\lnot \\delta _1\\vee ...\\vee \\lnot \\delta _m\\vee \\lnot (\\lambda x\\psi )(\\iota y\\varphi )\\). For the sake of contradiction assume that the implication is false. Hence, by completeness of \\({\\textbf{TC}}_{R_{\\lambda }}\\), there is an open branch in a tableau containing \\(\\exists x \\exists y(\\chi _1\\wedge \\chi _2\\wedge \\chi _3[b_1/x, b_2/y]), \\delta _1, \\ldots , \\delta _m, (\\lambda x\\psi )(\\iota y\\varphi )\\). Since \\(b_1, b_2\\) are absent from the branch, we can add \\(\\chi _1, \\chi _2, \\chi _3\\) to the branch with these parameters as fresh. Again, from completeness of \\({\\textbf{TC}}_{R_{\\lambda }}\\) we derive that each of 2’, 4’, 6’ has a proof, hence by applying \\((\\textsf{cut})\\) three times with these implications and their negations as cut formulas we make them occur on an open branch. By systematic applications of branching rules to them we obtain \\(\\varphi [y/b_1], \\varphi [y/b_2], b_1 \\ne b_2\\) on an open branch. All other branches containing \\(\\lnot \\chi _1, \\lnot \\chi _2, \\lnot \\chi _3, \\lnot \\delta _1, \\ldots , \\lnot \\delta _m\\) must be closed. Finally, an application of \\((\\iota _2)\\) introduces \\(b_1 = b_2\\) to the branch and closes it, therefore \\(\\models \\exists x \\exists y(\\chi _1\\wedge \\chi _2\\wedge \\chi _3[b_1/x, b_2/y])\\rightarrow \\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\vee \\lnot (\\lambda x\\psi )(\\iota y\\varphi )\\), contradicting the assumption. Since \\(\\exists x \\exists y(\\chi _1\\wedge \\chi _2\\wedge \\chi _3[b_1/x, b_2/y])\\) contains only predicates and parameters occurring both in \\(\\gamma _1\\wedge \\ldots \\wedge \\gamma _n\\) and \\(\\lnot \\delta _1\\vee \\ldots \\vee \\lnot \\delta _m\\vee \\lnot (\\lambda x\\psi )(\\iota y\\varphi )\\), it concludes the proof. \\(\\square \\)\n\nAs a consequence of Theorem 10 we get:\n\nTheorem 11\n\n(Beth definability) \\(\\textsf{L} _{R_{\\lambda }}\\) enjoys the Beth definability property.\n\nImplicit definability follows almost immediately from explicit definability. If we assume (ii), then the equivalence form (i) can be obtained by the assumption that c (and thus, \\(c'\\)) does not occur in the defining formula. For the converse implication we employ the Craig interpolation property and the deduction theorem for \\({\\textsf{L}}\\) to show that an interpolant obtained in a series of derivations can play the role of the formula on the right-hand side of the equivalence in (ii). See Andrews (2002, Theorem 4200) for details.\n\nKnowing that \\({\\textbf{L}}_{R_{\\lambda }}\\) satisfies the Beth definability property results in a straightforward method of determining, for any signature \\(\\Sigma = (\\textsf{PRED},\\textsf{CONS},\\textsf{ar})\\), any theory \\(\\textsf{Th}\\) over \\(\\Sigma \\) and any constant \\(c \\in \\textsf{CONS}\\), whether c can be defined by a formula \\(\\psi \\) over \\(\\Sigma ' = (\\textsf{PRED},\\textsf{CONS}\\setminus \\{c\\},\\textsf{ar})\\) under \\(\\textsf{Th}\\). In other words, we can decide whether there exists a formula that can form a definite description satisfied by the object that c denotes. Indeed, it suffices to check for implicit definability of c, that is, check if a tableau with the following formula at the root is closed:\n\n$$\\begin{aligned} \\bigwedge (\\textsf{Th} \\cup \\textsf{Th}')\\wedge c\\ne c', \\end{aligned}$$\n\nwhere \\(\\mathsf {Th'}\\) is defined like at the beginning of the section. Since, by Theorem 11, implicit definability implies explicit definability, we can replace such a constant with definite description \\(\\iota x\\psi \\), where \\(\\psi \\) is a definiens of c, whenever such a replacement results in a syntactically correct expression.\n\nExample 7\n\nConsider a theory \\(\\textsf{Th}\\) which provides characteristics of two individuals: Charles and Dana. The one thing that \\(\\textsf{Th}\\) stipulates is that only Charles and Dana are politicians. Formally:\n\n$$\\begin{aligned} \\textsf{Th} = \\{\\forall x (P(x) \\rightarrow (x=c \\vee x=d)), P(c), P(d)\\}. \\end{aligned}$$\n\nUsing \\({\\textbf{TC}}_{R_{\\lambda }}\\) it is not difficult to check that d is implicitly definable in \\(\\textsf{Th}\\) (in the proof tree below we exploit the definitions: \\(\\varphi \\vee \\psi := \\lnot (\\lnot \\varphi \\wedge \\lnot \\psi ))\\) and \\(\\varphi \\rightarrow \\psi :=\\lnot (\\varphi \\wedge \\lnot \\psi )\\)):\n\nOne can easily verify that, since \\(\\textsf{Th}\\) does not specify whether Charles and Dana are the same person, d in \\(\\textsf{Th}\\) is unambiguously characterised by the formula \\(P(x) \\wedge (x\\ne c \\vee \\lnot \\exists y(y\\ne x\\wedge P(y)))\\) saying that either Dana is a politician distinct from Charles or the only politician that exists, thus it can be replaced with \\(\\iota x(P(x) \\wedge (x\\ne c \\vee \\lnot \\exists y(y\\ne x\\wedge P(y))))\\) in every syntactically permitted contex. In fact, the above tableau reveals that even in the reduct of \\(\\textsf{Th}\\) only consisting of \\(\\forall x (P(x) \\rightarrow (x=c \\vee x=d))\\) and P(d), d is implicitly (and therefore, explicitly) definable, for P(c) does not take active part in closing the tree. Indeed, in such a reduced theory d can be defined explicitly by the same formula. If, on the other hand, we remove P(d) from \\(\\textsf{Th}\\) and keep P(c) instead, d will no longer be implicitly (and thus, explicitly) definable in such a reduct, as we will no longer have a means to close the branches with \\(\\lnot P(d)\\) and \\(\\lnot P(d')\\).\n\n\\({\\textbf{TC}}_{R_{\\lambda }}\\) is an accessible, well-behaved tableau calculus which represents essential features of the Russellian approach to definite descriptions and at the same time avoids its shortcomings. Moreover, the proposed methodology is open for further extensions to several other theories of definite descriptions. In particular, we can use it to formalise the approaches to definite descriptions developed in the area of free logics. Indrzejczak and Zawidzki (2021) proposed tableau systems for the minimal theory of definite descriptions expressed in several variants of free logics. The language of these systems is standard in the sense that predicate abstracts are not admitted and definite descriptions are directly used as arguments of predicates on a par with variables and individual constants. Moreover, the characterisation of definite descriptions is based on the weaker principle, often called Lambert’s axiom. Only in negative free logic Lambert’s axiom can be proved equivalent to Russell’s axiom being the basis of the approach presented in this paper. Rules for definite descriptions involve equalities with definite descriptions as arguments and to obtain completeness we need a restricted form of cut on equalities with definite descriptions already present on the branch. Introducing the lambda-operator and restricting occurrences of definite descriptions to arguments of lambda-atoms has a potential of simplifying the mentioned tableau systems for these theories. Roughly, it seems that to adjust \\({\\textbf{TC}}_{R_{\\lambda }}\\) to positive free logics we would only need to slightly modify the rules for quantifiers and for lambda-atoms. If we want negative free logics to be covered by a transformed version of \\({\\textbf{TC}}_{R_{\\lambda }}\\), we must additionally alter the rules for equality and add some extra rules expressing special denotation principles. An advantage offerred by the setting based on a modified version of \\({\\textbf{TC}}_{R_{\\lambda }}\\) for free logics over previous tableau systems by Indrzejczak and Zawidzki (2021) is that (the restricted form of) cut is no longer required, which decreases the search space in a proof.\n\nAnother promising field of application of the presented setting is modal logic, where tableau systems with lambda- and iota-terms were already examined by Fitting and Mendelsohn (1998) and then characterised by means of sequent calculi by Orlandelli (2021) and Indrzejczak (2020a). The application of lambda-abstracts to the problem of distinguishing between de dicto and de re reading of a modality is direct: \\(\\Box (\\lambda x\\varphi )(t)\\) and \\((\\lambda x \\Box \\varphi )(t)\\). Fitting and Mendelsohn introduced labelled tableaux and applied the lambda-operator, but did not characterise definite descriptions by means of well-behaved rules. Both Orlandelli’s and Indrzejczak’s approaches rely on the same theory of definite descriptions, again based on Lambert’s axiom, but, contrary to Fitting and Mendelsohn, provide sequent calculi with well-defined rules. The difference between them is that in the former external labels are used and rules for definite descriptions are built on the basis of a special denotation predicate, whereas in the latter hybrid logic and a special equality predicate are exploited to characterise definite descriptions. In both cases cut elimination is proved and lambda-predicates are introduced mainly for dealing with modal scoping difficulties. In the case of the system introduced in this paper the role of the lambda-operator is rather to solve the known problems caused by the Russellian approach to definite descriptions and to introduce tighter constraints on treating descriptions as terms. In particular, in all mentioned alternative approaches definite descriptions are semantically treated as terms, whereas in the present approach, they are characterised sematically only as arguments of lambda atoms. This is what makes metalogical proofs almost standard in contrast to proofs conducted within approaches where definite descriptions are semantically characterised as independent terms. Nevertheless, since the solutions proposed in this paper, with particular focus on restricting the part of the syntax revolved around definite descriptions, were not considered in the aforementioned works, it opens a path for cross-fertilisation of the techniques developed in all presented approaches.\n\nAlso, notice that to prove interpolation we had to refer to admissibility of cut on the basis of completness of the cut-free version of the calculus. From the theoretical standpoint it is desirable to have the cut elimination theorem proved constructively for this calculus. This problem has recently been solved by Indrzejczak and Kürbis (2022).\n\nAn interesting task for future research would be extending the present approach to intuitionistic and, possibly, intermediate logics. Intuitionistic logic could be handled by simply adding labels representing states in an S4 modal frame, and slightly modifying the rules to account for this extra dimension. Feasibility of this enterprise becomes evident when we use sequent calculus instead of tableaux. Since all rules specific for definite descriptions have never more than one formula in the succedent (in the tableau setting: negated formulas), we can simply add them to the standard intuitionistic version of sequent calculus. Tackling some known intermediate logics which have modal frames based on an order relation in a uniform fashion also seems achievable.\n\nFinally, from the practical standpoint the presented tableau system requires a proper implementation for its efficiency to be firmly tested."
    }
}