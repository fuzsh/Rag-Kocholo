{
    "id": "dbpedia_8606_3",
    "rank": 10,
    "data": {
        "url": "https://github.com/leoferres/sarcasm/blob/master/sarcasm.bib",
        "read_more_link": "",
        "language": "en",
        "title": "sarcasm/sarcasm.bib at master · leoferres/sarcasm",
        "top_image": "https://opengraph.githubassets.com/c67c75aa1b503755c863406904cef677c714ae36d87a640a765b2997896aaf8c/leoferres/sarcasm",
        "meta_img": "https://opengraph.githubassets.com/c67c75aa1b503755c863406904cef677c714ae36d87a640a765b2997896aaf8c/leoferres/sarcasm",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "A curated bibliography on identifying sarcasm in tweets - sarcasm/sarcasm.bib at master · leoferres/sarcasm",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/leoferres/sarcasm/blob/master/sarcasm.bib",
        "text": "@article{Sulis2016,\n\ntitle = {Figurative messages and affect in Twitter: Differences between \\#irony, \\#sarcasm and \\#not},\n\njournal = {Knowledge-Based Systems},\n\nvolume = {108},\n\npages = {132 - 143},\n\nyear = {2016},\n\nnote = {New Avenues in Knowledge Bases for Natural Language Processing},\n\nissn = {0950-7051},\n\ndoi = {http://dx.doi.org/10.1016/j.knosys.2016.05.035},\n\nurl = {http://www.sciencedirect.com/science/article/pii/S0950705116301320},\n\nauthor = {Sulis, Emilio and Herna\\'{n}dez Far\\'{\\i}as, Delia Iraz\\'{u} and Rosso, Paolo and Patti, Viviana and Ruffo, Giancarlo},\n\nkeywords = {Figurative language},\n\nkeywords = {Affective knowledge},\n\nkeywords = {Irony},\n\nkeywords = {Sarcasm},\n\nkeywords = {Twitter},\n\nabstract = {The use of irony and sarcasm has been proven to be a pervasive phenomenon in social media posing a challenge to sentiment analysis systems. Such devices, in fact, can influence and twist the polarity of an utterance in different ways. A new dataset of over 10,000 tweets including a high variety of figurative language types, manually annotated with sentiment scores, has been released in the context of the task 11 of SemEval-2015. In this paper, we propose an analysis of the tweets in the dataset to investigate the open research issue of how separated figurative linguistic phenomena irony and sarcasm are, with a special focus on the role of features related to the multi-faceted affective information expressed in such texts. We considered for our analysis tweets tagged with \\#irony and \\#sarcasm, and also the tag \\#not, which has not been studied in depth before. A distribution and correlation analysis over a set of features, including a wide variety of psycholinguistic and emotional features, suggests arguments for the separation between irony and sarcasm. The outcome is a novel set of sentiment, structural and psycholinguistic features evaluated in binary classification experiments. We report about classification experiments carried out on a previously used corpus for \\#irony vs \\#sarcasm. We outperform in terms of F-measure the state-of-the-art results on this dataset. Overall, our results confirm the difficulty of the task, but introduce new data-driven arguments for the separation between \\#irony and \\#sarcasm. Interestingly, \\#not emerges as a distinct phenomenon.}\n\n}\n\n@article{FariasPattiRosso2016,\n\nabstract = {Irony has been proven to be pervasive in social media, posing a challenge to sentiment analysis systems. It is a creative linguistic phenomenon where affect-related aspects play a key role. In this work, we address the problem of detecting irony in tweets, casting it as a classification problem. We propose a novel model that explores the use of affective features based on a wide range of lexical resources available for English, reflecting different facets of affect. Classification experiments over different corpora show that affective information helps in distinguishing among ironic and nonironic tweets. Our model outperforms the state of the art in almost all cases.},\n\nauthor = {Herna\\'{n}dez Far\\'{\\i}as, Delia Iraz\\'{u} and Patti, Viviana and Rosso, Paolo},\n\ntitle = {Irony Detection in Twitter: The Role of Affective Content},\n\njournal = {ACM Transactions on Internet Technology},\n\nissue_date = {2016},\n\nvolume = {16},\n\nnumber = {3},\n\nmonth = jul,\n\nyear = {2016},\n\nissn = {1533-5399},\n\npages = {19:1--19:24},\n\narticleno = {19},\n\nnumpages = {24},\n\nurl = {http://doi.acm.org/10.1145/2930663},\n\ndoi = {10.1145/2930663},\n\nacmid = {2930663},\n\npublisher = {ACM},\n\naddress = {New York, NY, USA},\n\nkeywords = {Irony detection, affective resources, figurative language processing},\n\n}\n\n@inproceedings{Karoui2017},\n\ntitle={Exploring the Impact of Pragmatic Phenomena on Irony Detection in Tweets: A Multilingual Corpus Study},\n\nauthor = {Karoui, Jihen and Farah, Benamara and Moriceau, Veronique and Patti, Viviana and Bosco, Cristina},\n\nyear = {2017},\n\nbooktitle = {{Proceedings of the European Chapter of the Association for Computational Linguistics (EACL 2017)},\n\nnote= {In press},\n\nabstract = {This paper provides a linguistic and pragmatic analysis of the phenomenon of irony in order to represent how Twitter's users exploit irony devices within their communication strategies for generating textual contents. We aim to measure the impact of a wide-range of pragmatic phenomena in the interpretation of irony, and to investigate how these phenomena interact with contexts local to the tweet. Informed by linguistic theories, we propose for the first time a multi-layered annotation schema for irony and its application to a corpus of French, English and Italian tweets. We detail each layer, explore their interactions, and discuss our results according to a qualitative and quantitative perspective}\n\n}\n\n@article{BoscoPattiBolioli13,\n\nauthor = {Bosco, Cristina and\n\nPatti, Viviana and\n\nBolioli, Andrea},\n\ntitle = {Developing Corpora for Sentiment Analysis: The Case of Irony and Senti-TUT},\n\njournal = {{IEEE} Intelligent Systems},\n\nvolume = {28},\n\nnumber = {2},\n\npages = {55--63},\n\nyear = {2013},\n\nurl = {http://dx.doi.org/10.1109/MIS.2013.28},\n\ndoi = {10.1109/MIS.2013.28},\n\nabstract={Senti-TUT-an ongoing Italian project that investigates sentiment and irony in online political discussions-illustrates how to develop corpora for mining and analyzing opinion and sentiment in social media.},\n\nISSN={1541-1672}\n\n}\n\n@article{Reyes-Rosso-Veale2013,\n\nabstract = {Irony is a pervasive aspect of many online texts, one made all the more difficult by the absence of face-to-face contact and vocal intonation. As our media increasingly become more social, the problem of irony detection will become even more pressing. We describe here a set of textual features for recognizing irony at a linguistic level, especially in short texts created via social media such as Twitter postings or \"tweets\". Our experiments concern four freely available data sets that were retrieved from Twitter using content words (e.g. \"Toyota\") and user-generated tags (e.g. \"\\#irony\"). We construct a new model of irony detection that is assessed along two dimensions: representativeness and relevance. Initial results are largely positive, and provide valuable insights into the figurative issues facing tasks such as sentiment analysis, assessment of online reputations, or decision making.},\n\nyear={2013},\n\njournal={Language Resources and Evaluation},\n\nvolume={47},\n\nnumber={1},\n\ndoi={10.1007/s10579-012-9196-x},\n\ntitle={A {M}ultidimensional {A}pproach for {D}etecting {I}rony in {T}witter},\n\npublisher={Springer Netherlands},\n\nauthor={Reyes, Antonio and Rosso, Paolo and Veale, Tony},\n\npages={239-268}\n\n}\n\n@misc{Schifanella2016,\n\nabstract = {Sarcasm is a peculiar form of sentiment expression, where the surface sentiment differs from the implied sentiment. The detection of sarcasm in social media platforms has been applied in the past mainly to textual utterances where lexical indicators (such as interjections and intensifiers), linguistic markers, and contextual information (such as user profiles, or past conversations) were used to detect the sarcastic tone. However, modern social media platforms allow to create multimodal messages where audiovisual content is integrated with the text, making the analysis of a mode in isolation partial. In our work, we first study the relationship between the textual and visual aspects in multimodal posts from three major social media platforms, i.e., Instagram, Tumblr and Twitter, and we run a crowdsourcing task to quantify the extent to which images are perceived as necessary by human annotators. Moreover, we propose two different computational frameworks to detect sarcasm that integrate the textual and visual modalities. The first approach exploits visual semantics trained on an external dataset, and concatenates the semantics features with state-of-the-art textual features. The second method adapts a visual neural network initialized with parameters trained on ImageNet to multimodal sarcastic posts. Results show the positive effect of combining modalities for the detection of sarcasm across platforms and methods.},\n\narchivePrefix = {arXiv},\n\narxivId = {1608.02289},\n\nauthor = {Schifanella, Rossano and de Juan, Paloma and Tetreault, Joel and Cao, Liangliang},\n\ndoi = {10.1145/2964284.2964321},\n\neprint = {1608.02289},\n\nfile = {:home/leo/Dropbox/papers/SdJTC2016.pdf:pdf},\n\nkeywords = {bibchecked,deep learning,machine learning,nn,vision},\n\nmendeley-tags = {bibchecked,deep learning,machine learning,nn,vision},\n\nmonth = {aug},\n\ntitle = {{Detecting Sarcasm in Multimodal Social Platforms}},\n\nurl = {http://arxiv.org/abs/1608.02289 http://dx.doi.org/10.1145/2964284.2964321},\n\nyear = {2016}\n\n}\n\n@article{Giachanou2016,\n\nabstract = {Sentiment analysis inTwitter is a field that has recently attracted researchinterest. Twitter is one of themost popular microblog platforms on which users can publish their thoughts and opinions. Sentiment analysis in Twitter tackles the problem of analyzing the tweets in terms of the opinion they express. This survey provides an overview of the topic by investigating and briefly describing the algorithms that have been proposed for sentiment analysis in Twitter. The presented studies are categorized according to the approach they follow. In addition, we discuss fields related to sentiment analysis in Twitter including Twitter opinion retrieval, tracking sentiments over time, irony detection, emotion detection, and tweet sentiment quantification, tasks that have recently attracted increasing attention. Resources that have been used in the Twitter sentiment analysis literature are also briefly presented. Themain contributions of this survey include the presentation of the proposed approaches for sentiment analysis in Twitter, their categorization according to the technique they use, and the discussion of recent research trends of the topic and its related fields},\n\nauthor = {Giachanou, Anastasia and Crestani, Fabio},\n\ndoi = {10.1145/2938640},\n\nfile = {:home/leo/Dropbox/papers/GC2016.pdf:pdf},\n\nissn = {03600300},\n\njournal = {ACM Computing Surveys},\n\nkeywords = {Sentiment analysis,algorithm,bibchecked,microblogs,opinion mining,survey,twitter},\n\nmendeley-tags = {bibchecked,algorithm,survey},\n\nmonth = {jun},\n\nnumber = {2},\n\npages = {1--41},\n\npublisher = {ACM},\n\ntitle = {{Like It or Not: A Survey of Twitter Sentiment Analysis Methods}},\n\nurl = {http://dl.acm.org/citation.cfm?doid=2966278.2938640},\n\nvolume = {49},\n\nyear = {2016}\n\n}\n\n@article{Joshi2016a,\n\nabstract = {Sarcasm annotation extends beyond linguistic expertise, and often involves cultural context. This paper presents our first-of-its-kind study that deals with impact of cultural differences on the quality of sarcasm annotation. For this study, we consider the case of American text and Indian annotators. For two sarcasm- labeled datasets of American tweets and dis- cussion forum posts that have been annotated by American annotators, we obtain annota- tions from Indian annotators. Our Indian an- notators agree with each other more than their American counterparts, and face difficulties in case of unfamiliar situations and named en- tities. However, these difficulties in sarcasm annotation result in statistically insignificant degradation in sarcasm classification. We also show that these disagreements between annotators can be predicted using textual prop- erties. Although the current study is limited to two annotators and one culture pair, our paper opens up a novel direction in evaluation of the quality of sarcasm annotation, and the impact of this quality on sarcasm classification. This study forms a stepping stone towards system- atic evaluation of quality of these datasets an- notated by non-native annotators, and can be extended to other culture combinations.},\n\naddress = {Berlin},\n\nannote = {Datasets:\n\nTweet-A. This dataset, introduced by Riloff et al. (2013), consists of 2278 manually labeled tweets, out of which 506 are sarcastic. We},\n\nauthor = {Joshi, Aditya and Bhattacharyya, Pushpak and Carman, Mark and Saraswati, Jaya and Shukla, Rajita},\n\nfile = {:home/leo/Dropbox/papers/JBCSS2016.pdf:pdf},\n\njournal = {LaTeCH 2016},\n\nkeywords = {bibchecked,human,indian,multilingual},\n\nmendeley-tags = {bibchecked,human,indian,multilingual},\n\nnumber = {1984},\n\npages = {1--5},\n\npublisher = {Association for Computational Linguistics},\n\ntitle = {{How Do Cultural Differences Impact the Quality of Sarcasm Annotation ? : A Case Study of Indian Annotators and American Text}},\n\nurl = {https://aclweb.org/anthology/W/W16/W16-2111.pdf},\n\nyear = {2016}\n\n}\n\n@article{Joshi2016,\n\nabstract = {Automatic detection of sarcasm has witnessed interest from the sentiment analysis research community. With diverse approaches, datasets and analyses that have been reported, there is an essential need to have a collective understanding of the research in this area. In this survey of automatic sarcasm detection, we describe datasets, approaches (both supervised and rule-based), and trends in sarcasm detection research. We also present a research matrix that summarizes past work, and list pointers to future work.},\n\narchivePrefix = {arXiv},\n\narxivId = {1602.03426},\n\nauthor = {Joshi, Aditya and Bhattacharyya, Pushpak and Carman, Mark James},\n\neprint = {1602.03426},\n\nfile = {:home/leo/Dropbox/papers/Joshi, Bhattacharyya, Carman - 2016 - Automatic Sarcasm Detection A Survey.pdf:pdf},\n\njournal = {arxiv},\n\nkeywords = {bibchecked,survey},\n\nmendeley-tags = {bibchecked,survey},\n\nmonth = {feb},\n\ntitle = {{Automatic Sarcasm Detection: A Survey}},\n\nurl = {http://arxiv.org/abs/1602.03426},\n\nyear = {2016}\n\n}\n\n@article{Bharti2016,\n\nabstract = {Sarcasm is a type of sentiment where people express their negative feelings using positive or intensified positive words in the text. While speaking, people often use heavy tonal stress and certain gestural clues like rolling of the eyes, hand movement, etc. to represent sarcastic. In the textual data, these tonal and gestural clues are missing, making sarcasm detection very difficult for an average human. Due to these challenges, researchers are showing interest in sarcasm detection of social media text, especially in tweets. Rapid growth of tweets in volume and its analysis pose major challenges. In this paper, we proposed a Hadoop based framework that captures real time tweets and process it with a set of algorithms which identifies sarcastic sentiment efficiently. We observe that the elapse time for analysing and processing under Hadoop based framework significantly outperforms the conventional methods and is more suited for real time streaming tweets.},\n\nauthor = {Bharti, Santosh Kumar and Vachha, B. and Pradhan, R.K. and Babu, Korra Sathya and Jena, Sanjay Kumar},\n\ndoi = {10.1016/j.dcan.2016.06.002},\n\nfile = {:home/leo/Dropbox/papers/BVPBJ2016.pdf:pdf},\n\nissn = {23528648},\n\njournal = {Digital Communications and Networks},\n\nkeywords = {algorithm,bibchecked,deep,hadoop,hpc,rule-based},\n\nmendeley-tags = {bibchecked,algorithm,deep,hadoop,hpc,rule-based},\n\ntitle = {{Sarcastic Sentiment Detection in Tweets Streamed in Real time: A Big Data Approach}},\n\nurl = {http://linkinghub.elsevier.com/retrieve/pii/S235286481630027X},\n\nyear = {2016}\n\n}\n\n@article{Thompson2016,\n\nabstract = {We present 2 studies that investigate the use of emoticons in clarifying message intent. We examine sarcasm in particular, which can be especially hard to interpret correctly in written communication. In both studies, participants were required to make the intentions of their messages clear. In the first, they clarified the meaning of existing sentences without altering the wording; in the second, they produced their own sentences. Results provided clear evidence that tongue and wink emoticons are the principal indicators of sarcastic intent, and that ellipsis is associated more with criticism, rather than with sarcasm. These findings highlight the significant role emoticons play in clarifying message intention, compensating for the absence of nonverbal cues in written communication.},\n\nauthor = {Thompson, Dominic and Filik, Ruth},\n\ndoi = {10.1111/jcc4.12156},\n\nfile = {:home/leo/Dropbox/papers/TF2016.pdf:pdf},\n\nissn = {10836101},\n\njournal = {Journal of Computer-Mediated Communication},\n\nkeywords = {CMC,Emoticons,Irony,Language Production,Pragmatics,Sarcasm,Text Messaging,bibchecked,experimental,human},\n\nmendeley-tags = {bibchecked,experimental,human},\n\nmonth = {mar},\n\nnumber = {2},\n\npages = {105--120},\n\npublisher = {John Wiley {\\&} Sons, Inc.},\n\ntitle = {{Sarcasm in Written Communication: Emoticons are Efficient Markers of Intention}},\n\nurl = {http://doi.wiley.com/10.1111/jcc4.12156},\n\nvolume = {21},\n\nyear = {2016}\n\n}\n\n@inproceedings{Bouazizi2015b,\n\nabstract = {Opinion mining and sentiment analysis refer to the identification and the aggregation of attitudes or opinions expressed by internet users towards a specific topic. However, due to the limitation in terms of characters (i.e. 140 characters per tweet) and the use of informal language, the state-of-the-art approaches of sentiment analysis present lower performances in Twitter than that when they are applied on longer texts. More- over, presence of sarcasm makes the task even more challenging. Sarcasm is when a person conveys implicit information, usually the opposite of what is said, within the message he transmits. In this paper we propose a method that makes use of a minimal set of features, yet, efficiently classifies tweets regardless of their topic. We also study the importance of detecting sarcastic tweets automatically, and demonstrate how the accuracy of sentiment analysis can be enhanced knowing which tweets are sarcastic and which are not.},\n\naddress = {New York, New York, USA},\n\nauthor = {Bouazizi, Mondher and Ohtsuki, Tomoaki},\n\nbooktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015 - ASONAM '15},\n\ndoi = {10.1145/2808797.2809350},\n\nfile = {:home/leo/Dropbox/papers/BO2015.pdf:pdf},\n\nisbn = {9781450338547},\n\nkeywords = {bibchecked,machine learning,svm},\n\nmendeley-tags = {bibchecked,machine learning,svm},\n\npages = {1594--1597},\n\npublisher = {ACM Press},\n\ntitle = {{Opinion Mining in Twitter How to Make Use of Sarcasm to Enhance Sentiment Analysis}},\n\nurl = {http://dl.acm.org/citation.cfm?doid=2808797.2809350},\n\nyear = {2015}\n\n}\n\n@inproceedings{Altrabsheh2015,\n\nabstract = {Sarcasm is a sophisticated form of act where one says or writes the opposite of what they mean. Sarcasm is a common issue in sen- timent analysis and detecting it is a challenge. While models for sarcasm detection have been proposed for general purposes (e.g. Twitter data, Amazon reviews), there is no research addressing this issue in an edu- cational context, despite the increased use of social media in education. In this paper we experiment with several machine learning techniques, features and preprocessing levels to identify sarcasm from students' feed- back collected via Twitter.},\n\nauthor = {Altrabsheh, Nabeela and Cocea, Mihaela and Fallahkhair, Sanaz},\n\nbooktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},\n\ndoi = {10.1007/978-3-319-24258-3_57},\n\nfile = {:home/leo/Dropbox/papers/ACF2015.pdf:pdf},\n\nisbn = {9783319242576},\n\nissn = {16113349},\n\nkeywords = {Sarcasm detection,Sentiment analysis,Students feedback,bibchecked,education,machine learning,students},\n\nmendeley-tags = {bibchecked,education,machine learning,students},\n\npages = {551--555},\n\ntitle = {{Detecting Sarcasm from students' feedback in twitter}},\n\nurl = {http://link.springer.com/10.1007/978-3-319-24258-3{\\_}57},\n\nvolume = {9307},\n\nyear = {2015}\n\n}\n\n@inproceedings{Rajadesingan2015b,\n\nabstract = {Sarcasm is a nuanced form of language in which individuals state the opposite of what is implied. With this intentional ambiguity, sarcasm detection has always been a challenging task, even for humans. Current approaches to automatic sar- casm detection rely primarily on lexical and linguistic cues. This paper aims to address the difficult task of sarcasm de- tection on Twitter by leveraging behavioral traits intrinsic to users expressing sarcasm. We identify such traits using the user's past tweets. We employ theories from behavioral and psychological studies to construct a behavioral mod- eling framework tuned for detecting sarcasm. We evaluate our framework and demonstrate its efficiency in identifying sarcastic tweets},\n\naddress = {New York, New York, USA},\n\nauthor = {Rajadesingan, Ashwin and Zafarani, Reza and Liu, Huan},\n\nbooktitle = {Proceedings of the Eighth ACM International Conference on Web Search and Data Mining - WSDM '15},\n\ndoi = {10.1145/2684822.2685316},\n\nfile = {:home/leo/Dropbox/papers/RZL2015.pdf:pdf},\n\nisbn = {9781450333177},\n\nkeywords = {behavioral modeling,bibchecked,cognitive,machine learning,sarcasm detection,social media},\n\nmendeley-tags = {bibchecked,cognitive,machine learning},\n\npages = {97--106},\n\npublisher = {ACM Press},\n\ntitle = {{Sarcasm Detection on Twitter}},\n\nurl = {http://dl.acm.org/citation.cfm?doid=2684822.2685316},\n\nyear = {2015}\n\n}\n\n@inproceedings{BBJ2015,\n\nabstract = {Sentiment Analysis is a technique to identify peo- ple's opinion, attitude, sentiment, and emotion towards any specific target such as individuals, events, topics, product, or- ganizations, services etc. Sarcasm is a special kind of sentiment that comprise of words which mean the opposite of what you really want to say (especially in order to insult or wit someone, to show irritation, or to be funny). People often expressed it verbally through the use of heavy tonal stress and certain gestural clues like rolling of the eyes. These tonal and gestural clues are obviously not available for expressing sarcasm in text, making its detection reliant upon other factors. In this paper, two approaches to detect sarcasm in the text of Twitter data were proposed. The first is a parsing-based lexicon generation algorithm (PBLGA) and the second was to detect sarcasm based on the occurrence of the interjection word. The combination of two approaches is also shown and compared with the existing state-of-the-art approach to detect sarcasm. First approach attains a 0.89, 0.81 and 0.84 precision, recall and f − score respectively. Second approach attains 0.85, 0.96 and 0.90 precision, recall and f − score respectively in tweets with sarcastic hashtag.},\n\naddress = {New York, New York, USA},\n\nauthor = {Bharti, Santosh Kumar and Babu, Korra Sathya and Jena, Sanjay Kumar},\n\nbooktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015 - ASONAM '15},\n\ndoi = {10.1145/2808797.2808910},\n\nfile = {:home/leo/Dropbox/papers/BBJ2015.pdf:pdf},\n\nisbn = {9781450338547},\n\nkeywords = {Natural language processing,Opinion mining,Parsing,Sarcasm,Sentiment,Tweets,bibchecked,parsing,pos},\n\nmendeley-tags = {bibchecked,parsing,pos},\n\npages = {1373--1380},\n\npublisher = {ACM Press},\n\ntitle = {{Parsing-based Sarcasm Sentiment Recognition in Twitter Data}},\n\nurl = {http://dl.acm.org/citation.cfm?doid=2808797.2808910},\n\nyear = {2015}\n\n}\n\n@article{Ghosh2015,\n\nabstract = {Sarcasm is generally characterized as a figure of speech that involves the substi- tution of a literal by a figurative mean- ing, which is usually the opposite of the original literal meaning. We re-frame the sarcasm detection task as a type of word sense disambiguation problem, where the sense of a word is either literal or sar- castic. We call this the Literal/Sarcastic Sense Disambiguation (LSSD) task. We address two issues: 1) how to collect a set of target words that can have either literal or sarcastic meanings depending on con- text; and 2) given an utterance and a target word, howto automatically detect whether the target word is used in the literal or the sarcastic sense. For the latter, we investi- gate several distributional semantics meth- ods and show that a Support Vector Ma- chines (SVM) classifier with a modified kernel using word embeddings achieves a 7-10{\\%} F1 improvement over a strong lexical baseline.},\n\naddress = {Stroudsburg, PA, USA},\n\nauthor = {Ghosh, Debanjan and Guo, Weiwei and Muresan, Smaranda},\n\ndoi = {10.18653/v1/D15-1116},\n\nfile = {:home/leo/Dropbox/papers/Ghosh, Guo, Muresan - 2015 - Sarcastic or Not Word Embeddings to Predict the Literal or Sarcastic Meaning of Words.pdf:pdf},\n\nisbn = {9781941643327},\n\njournal = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},\n\nkeywords = {bibchecked,distributional semantics,svm,word-sense disambiguation},\n\nmendeley-tags = {bibchecked,distributional semantics,svm,word-sense disambiguation},\n\nnumber = {September},\n\npages = {1003--1012},\n\npublisher = {Association for Computational Linguistics},\n\ntitle = {{Sarcastic or Not: Word Embeddings to Predict the Literal or Sarcastic Meaning of Words}},\n\nurl = {http://aclweb.org/anthology/D15-1116},\n\nyear = {2015}\n\n}\n\n@article{Kunneman2015a,\n\nabstract = {To avoid a sarcastic message being understood in its unintended literal meaning, in microtexts such as messages on Twitter.com sarcasm is often explicitly marked with a hashtag such as '{\\#}sarcasm'. We collected a training corpus of about 406 thousand Dutch tweets with hashtag synonyms denoting sarcasm. Assuming that the human labeling is correct (annotation of a sample indicates that about 90{\\%} of these tweets are indeed sarcastic), we train a machine learning classifier on the harvested examples, and apply it to a sample of a day's stream of 2.25 million Dutch tweets. Of the 353 explicitly marked tweets on this day, we detect 309 (87{\\%}) with the hashtag removed. We annotate the top of the ranked list of tweets most likely to be sarcastic that do not have the explicit hashtag. 35{\\%} of the top-250 ranked tweets are indeed sarcastic. Analysis indicates that the use of hashtags reduces the further use of linguistic markers for signaling sarcasm, such as exclamations and intensifiers. We hypothesize that explicit markers such as hashtags are the digital extralinguistic equivalent of non-verbal expressions that people employ in live interaction when conveying sarcasm. Checking the consistency of our finding in a language from another language family, we observe that in French the hashtag '{\\#}sarcasme' has a similar polarity switching function, be it to a lesser extent.},\n\nauthor = {Kunneman, Florian and Liebrecht, Christine and {Van Mulken}, Margot and {Van Den Bosch}, Antal},\n\ndoi = {10.1016/j.ipm.2014.07.006},\n\nfile = {:home/leo/Dropbox/papers/KLvMvdB2014.pdf:pdf},\n\nisbn = {03064573 (ISSN)},\n\nissn = {03064573},\n\njournal = {Information Processing and Management},\n\nkeywords = {Automatic sentiment analysis,Opinion mining,Sarcasm,Social media,Verbal irony,bibchecked,cognitive,labelling,linguistic},\n\nmendeley-tags = {bibchecked,cognitive,labelling,linguistic},\n\nmonth = {jul},\n\nnumber = {4},\n\npages = {500--509},\n\npublisher = {Elsevier Ltd},\n\ntitle = {{Signaling sarcasm: From hyperbole to hashtag}},\n\nurl = {http://dx.doi.org/10.1016/j.ipm.2014.07.006 http://linkinghub.elsevier.com/retrieve/pii/S0306457314000661},\n\nvolume = {51},\n\nyear = {2015}\n\n}\n\n@incollection{Wang2015,\n\nabstract = {Automatically detecting sarcasm in twitter is a challenging task because sarcasm transforms the polarity of an apparently positive or negative utterance into its opposite. Previous work focus on feature modeling of the single tweet, which limit the performance of the task. These methods did not leverage contextual information regarding the author or the tweet to improve the performance of sarcasm detection. However, tweets are filtered through streams of posts, so that a wider context, e.g. a conversation or topic, is always available. In this paper, we compared sarcastic utterances in twitter to utterances that express positive or negative attitudes without sarcasm. The sarcasm detection problem is modeled as a sequential classification task over a tweet and his contextual information. A Markovian formulation of the Support Vector Machine discriminative model as embodied by the SV M hmm algorithm has been employed to assign the category label to entire sequence. Exper- imental results show that sequential classification effectively embodied evidence about the context information and is able to reach a relative increment in detection performance},\n\nauthor = {Wang, Zelin and Wu, Zhijian and Wang, Ruimin and Ren, Yafeng},\n\nbooktitle = {Proceedings, Part I, of the 16th International Conference on Web Information Systems Engineering --- WISE 2015 - Volume 9418},\n\ndoi = {10.1007/978-3-319-26190-4_6},\n\nfile = {:home/leo/Dropbox/papers/WWWR2015.pdf:pdf},\n\nkeywords = {Sarcasm detection,Sentiment classification,Sequential classification,Support vector machine,bibchecked,markov,svm},\n\nmendeley-tags = {bibchecked,markov,svm},\n\npages = {77--91},\n\npublisher = {Springer-Verlag New York, Inc.},\n\ntitle = {{Twitter Sarcasm Detection Exploiting a Context-Based Model}},\n\nurl = {http://link.springer.com/10.1007/978-3-319-26190-4{\\_}6},\n\nyear = {2015}\n\n}\n\n@article{Ghosh2015a,\n\nabstract = {This report summarizes the objectives and evaluation of the SemEval 2015 task on the sentiment analysis of figurative language on Twitter (Task 11). This is the first sentiment analysis task wholly dedicated to analyzing figurative language on Twitter. Specifically, three broad classes of figurative language are considered: irony, sarcasm and metaphor. Gold standard sets of 8000 training tweets and 4000 test tweets were annotated using workers on the crowdsourcing platform CrowdFlower. Participating systems were required to provide a fine-grained sentiment score on an 11-point scale (-5 to +5, including 0 for neutral intent) for each tweet, and systems were evaluated against the gold standard using both a Cosine- similarity and a Mean-Squared-Error measure.},\n\nauthor = {Ghosh, Aniruddha and Li, Guofu and Veale, Tony and Rosso, Paolo and Shutova, Ekaterina and Reyes, Antonio and Barnden, John},\n\nfile = {:home/leo/Dropbox/papers/SemEval080.pdf:pdf},\n\njournal = {Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {SemEval},\n\npages = {470--478},\n\ntitle = {{SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter}},\n\nurl = {http://alt.qcri.org/semeval2015/cdrom/pdf/SemEval080.pdf},\n\nyear = {2015}\n\n}\n\n@article{Bamman2015a,\n\nabstract = {Sarcasm requires some shared knowledge between speaker and audience; it is a profoundly contextual phe- nomenon. Most computational approaches to sarcasm detection, however, treat it as a purely linguistic matter, using information such as lexical cues and their corre- sponding sentiment as predictive features.We showthat by including extra-linguistic information from the con- text of an utterance on Twitter – such as properties of the author, the audience and the immediate communicative environment – we are able to achieve gains in accuracy compared to purely linguistic features in the detection of this complex phenomenon, while also shedding light on features of interpersonal interaction that enable sar- casm in conversation.},\n\nauthor = {Bamman, David and Smith, Noah A},\n\ndoi = {10.1145/2684822.2685316},\n\nfile = {:home/leo/Dropbox/papers/Bamman, Smith - Unknown - Contextualized Sarcasm Detection on Twitter.pdf:pdf;:home/leo/Dropbox/papers/10538-46441-1-PB.pdf:pdf},\n\nisbn = {9781577357339},\n\njournal = {Icwsm (International AAAI Conference on Web and Social Media)},\n\nkeywords = {Poster Papers,bibchecked,pragmatics,profiling},\n\nmendeley-tags = {bibchecked,pragmatics,profiling},\n\npages = {574--577},\n\ntitle = {{Contextualized Sarcasm Detection on Twitter}},\n\nurl = {http://www.cs.cmu.edu/{~}nasmith/papers/bamman+smith.icwsm15.pdf},\n\nyear = {2015}\n\n}\n\n@article{Filik2015,\n\nabstract = {Most theorists agree that sarcasm serves some communicative function that would not be achieved by speaking directly, such as eliciting a particular emotional response in the recipient. One debate concerns whether this kind of language serves to enhance or mute the positive or negative nature of a message. The role of textual devices commonly used to accompany written sarcastic remarks is also unclear. The current research uses a rating task to investigate the influence of textual devices (emoticons and punctuation marks), on the comprehension of, and emotional responses to, sarcastic vs. literal criticism and praise, for both unambiguous (Experiment 1) and ambiguous (Experiment 2) materials. Results showed that sarcastic criticism was rated as less negative than literal criticism, and sarcastic praise was rated as less positive than literal praise, suggesting that sarcasm serves to mute the positive or negative nature of the message. In terms of textual devices, results showed that emoticons had a larger influence on both comprehension and emotional impact than punctuation marks.},\n\nauthor = {Filik, Ruth and Turcan, Alexandra and Thompson, Dominic and Harvey, Nicole and Davies, Harriet and Turner, Amelia},\n\ndoi = {10.1080/17470218.2015.1106566},\n\nfile = {:home/leo/Dropbox/papers/filik2015.pdf:pdf},\n\nissn = {1747-0226},\n\njournal = {Quarterly Journal of Experimental Psychology},\n\nkeywords = {bibchecked,emoticons,emotion,fi c form of,figurative language,forms of nonliteral language,irony and sarcasm are,language comprehension,of,sarcasm,sarcasm is a speci,that are often used,to communicate the opposite,what is literally said},\n\nmendeley-tags = {bibchecked},\n\nmonth = {nov},\n\nnumber = {November},\n\npages = {1--17},\n\npmid = {26513274},\n\npublisher = {Routledge},\n\ntitle = {{Sarcasm and Emoticons: Comprehension and Emotional Impact}},\n\nurl = {https://www.tandfonline.com/doi/full/10.1080/17470218.2015.1106566 http://www.ncbi.nlm.nih.gov/pubmed/26513274},\n\nvolume = {0218},\n\nyear = {2015}\n\n}\n\n@book{Joshi2015,\n\nabstract = {The relationship between context incongruity and sarcasm has been studied in linguistics. We present a computational system that harnesses context incongruity as a basis for sarcasm detection. Our statistical sarcasm classifiers incorporate two kinds of incongruity features: explicit and implicit. We show the benefit of our incongruity features for two text forms - tweets and discussion forum posts. Our system also outperforms two past works (with Fscore improvement of 10-20{\\%}). We also show how our features can capture intersentential incongruity.},\n\naddress = {Beijing, China},\n\nauthor = {Joshi, Aditya and Sharma, Vinita and Bhattacharyya, Pushpak},\n\nbooktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},\n\nfile = {:home/leo/Dropbox/papers/JSB2015.pdf:pdf},\n\nisbn = {9781937284732},\n\nkeywords = {bibchecked,semantics},\n\nmendeley-tags = {bibchecked,semantics},\n\npages = {757--762},\n\npublisher = {Association for Computational Linguistics},\n\ntitle = {{Harnessing Context Incongruity for Sarcasm Detection}},\n\nurl = {http://www.aclweb.org/anthology/P15-2083},\n\nvolume = {2},\n\nyear = {2015}\n\n}\n\n@inproceedings{Fersini2015,\n\nabstract = {The automatic detection of sarcasm and irony in user generated contents is one of the most challenging task of Nat- ural Language Processing. In this paper we address this problem by introducing Bayesian Model Averaging (BMA), an ensemble approach to take into account several classifiers according to their reliabilities and their marginal probability predictions. The impact of the most used expressive signals (pragmatic particles and POS tags) have been evaluated in baseline models (traditional classifiers and majority voting) as well as in the proposed BMA approach. Experimental results highlight two main findings: (1) not all the features are equally able to characterize sarcasm and irony and (2) BMA not only outperforms traditional state of the art models, but is also able to ensure notable generalization capabilities both on ironic and sarcastic text.},\n\nauthor = {Fersini, Elisabetta and Pozzi, Federico Alberto and Messina, Enza},\n\nbooktitle = {Data Science and Advanced Analytics (DSAA), 2015. 36678 2015. IEEE International Conference on},\n\ndoi = {10.1109/DSAA.2015.7344888},\n\nfile = {:home/leo/Dropbox/papers/FPM2015.pdf:pdf},\n\nisbn = {9781467382731},\n\nkeywords = {bibchecked,machine learning,svm},\n\nmendeley-tags = {bibchecked,machine learning,svm},\n\nmonth = {oct},\n\nnumber = {April 2016},\n\npages = {1--8},\n\npublisher = {IEEE},\n\ntitle = {{Detecting irony and sarcasm in microblogs: The role of expressive signals and ensemble classifiers}},\n\nurl = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7344888},\n\nyear = {2015}\n\n}\n\n@inproceedings{MariaAlcaide2015,\n\nabstract = {The detection of secondary emotions, like sarcasm, in online dialogues is a difficult task that has rarely been treated in the literature. In this work (This work has been partially supported by the Spanish Ministry of Science under grant TIN2011-28169-C05-04, and by the Basque Government under grant IT685-13.), we tackle this problem as an affective pattern recognition problem. Specifically, we consider different kind of information sources (statistical and semantic) and propose alternative ways of combining them. We also provide a comparison of a Support Vector Machine (SVM) classification method with a simpler Naive Bayes parametric classifier. The experimental results show that combining statistical and semantic feature sets comparable performances can be achieved with Naive Bayes and SVM classifiers.},\n\nauthor = {{Maria Alcaide}, Jose and Justo, Raquel and {Ines Torres}, Maria},\n\nbooktitle = {Pattern Recognition and Image Analysis (IBPRIA 2015)},\n\ndoi = {10.1007/978-3-319-19390-8_74},\n\nfile = {:home/leo/Dropbox/papers/AJT2015.pdf:pdf},\n\nisbn = {978-3-319-19390-8},\n\nissn = {0302-9743},\n\nkeywords = {Affective pattern recognition,Sarcasm detection,bibchecked,naive bayes,semantics,statistics,svm},\n\nmendeley-tags = {bibchecked,naive bayes,semantics,statistics,svm},\n\npages = {662--671},\n\ntitle = {{Combining Statistical and Semantic Knowledge for Sarcasm Detection in Online Dialogues}},\n\nurl = {http://link.springer.com/10.1007/978-3-319-19390-8{\\_}74},\n\nvolume = {9117},\n\nyear = {2015}\n\n}\n\n@article{Li2015,\n\nabstract = {Twitter is an intriguing source of topical content for tasks involving the detection of phenomena such as sarcasm and metaphor. The hashtags that users employ to self-annotate their own micro-texts can often facilitate the targeted retrieval of texts with the desired characteristics. Though tweets tagged with {\\#}sarcasm are highly likely to be sarcastic, the lack of a topic model for sarcastic tweets makes it difficult to detect when such tags are used in the expected way, or indeed, to retrieve tweets that are not explicitly tagged in this way. In this study, we explore how a tweet-retrieval and classification system can benefit from a topic model when constructing a task-specific Twitter corpus, such as for irony, sarcasm or metaphor detection.},\n\nauthor = {Li, Guofu and Ghosh, Aniruddha and Veale, Tony},\n\ndoi = {10.1145/2824864.2824866},\n\nfile = {:home/leo/Dropbox/papers/figurativelge.pdf:pdf},\n\nisbn = {9781450337557},\n\njournal = {Proceedings of the Forum for Information Retrieval Evaluation on - FIRE '14},\n\nkeywords = {bibchecked,expansion,figurative language,information retrieval,latent semantic,twitter},\n\nmendeley-tags = {bibchecked},\n\npages = {130--133},\n\ntitle = {{Constructing A Corpus Of Figurative Language For a Tweet Classification and Retrieval Task}},\n\nurl = {http://dl.acm.org/citation.cfm?doid=2824864.2824866},\n\nyear = {2015}\n\n}\n\n@misc{McCulloch2015,\n\nauthor = {McCulloch, Gretchen},\n\nbooktitle = {http://the-toast.net/},\n\ntitle = {{A Linguist Explains How We Write Sarcasm on the Internet}},\n\nurl = {http://the-toast.net/2015/06/22/a-linguist-explains-how-we-write-sarcasm-on-the-internet/},\n\nurldate = {2016-08-13},\n\nyear = {2015}\n\n}\n\n@inproceedings{Khattri2015,\n\nabstract = {Sarcasm understanding may require infor- mation beyond the text itself, as in the case of ‘I absolutely love this restaurant!' which may be sarcastic, depending on the contextual situation. We present the first quantitative evidence to show that histori- cal tweets by an author can provide addi- tional context for sarcasm detection. Our sarcasm detection approach uses two com- ponents: a contrast-based predictor (that identifies if there is a sentiment contrast within a target tweet), and a historical tweet-based predictor (that identifies if the sentiment expressed towards an entity in the target tweet agrees with sentiment ex- pressed by the author towards that entity in the past).},\n\naddress = {Stroudsburg, PA, USA},\n\nauthor = {Khattri, Anupam and Joshi, Aditya and Bhattacharyya, Pushpak and Carman, Mark James},\n\nbooktitle = {6TH WORKSHOP ON COMPUTATIONAL APPROACHES TO SUBJECTIVITY, SENTIMENT AND SOCIAL MEDIA ANALYSIS WASSA 2015},\n\ndoi = {10.18653/v1/W15-2905},\n\nfile = {:home/leo/Dropbox/papers/Khattri et al. - 2015 - Your Sentiment Precedes You Using an author's historical tweets to predict sarcasm.pdf:pdf},\n\nkeywords = {bibchecked,shallow},\n\nmendeley-tags = {bibchecked,shallow},\n\npages = {25},\n\npublisher = {Association for Computational Linguistics},\n\ntitle = {{Your Sentiment Precedes You: Using an author's historical tweets to predict sarcasm}},\n\nurl = {http://aclweb.org/anthology/W15-2905},\n\nyear = {2015}\n\n}\n\n@article{Bouazizi2015,\n\nabstract = {Sarcasm is a special form of irony by which the person conveys implicit information, usually the opposite of what is said, within the message he transmits. Sarcasm is largely used in social networks and microblogging websites, where people mock or criticize in a way that makes it difficult even for humans to tell if what is said is what is meant. Recognizing sarcastic statements can be very useful when it comes to improving automatic sentiment analysis of data collected from social networks. It helps also enhance the efficiency of after-sales services or consumer assistance through understanding the intentions and real opinions of consumers when browsing their feedbacks or complaints. In this paper we propose a method to detect sarcasm in Twitter that makes use of the different components of the tweet. We propose four sets of features that cover different types of sarcasm we defined, and that will be used to classify tweets into sarcastic and non-sarcastic. We evaluate the performances of our approach. We study the importance of each of the proposed sets of features and evaluate its added value to the classification.},\n\nauthor = {Bouazizi, Mondher and Ohtsuki, Tomoaki},\n\ndoi = {10.1109/GLOCOM.2015.7417640},\n\nfile = {:home/leo/Dropbox/papers/BO2015b.pdf:pdf},\n\nisbn = {VO -},\n\njournal = {2015 IEEE Global Communications Conference (GLOBECOM)},\n\nkeywords = {Context,Feature extraction,Sentiment analysis,Speech,Tagging,Twitter,after-sales service efficiency enhancement,automatic sentiment analysis improvement,bibchecked,consumer assistance,consumer behaviour,consumer intentions,consumer opinions,f-scores,machine learning,microblogging Web sites,nonsarcastic tweets,pattern classification,sarcasm detection,sarcastic statement recognition,sarcastic tweets,sentiment analysis,social networking (online),social networks,tweets classification},\n\nmendeley-tags = {bibchecked,f-scores,machine learning},\n\nmonth = {dec},\n\npages = {1--6},\n\npublisher = {IEEE},\n\ntitle = {{Sarcasm Detection in Twitter: \"All Your Products Are Incredibly Amazing!!!\" - Are They Really?}},\n\nurl = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7417640},\n\nyear = {2015}\n\n}\n\n@article{Tungthamthiti2014,\n\nabstract = {Sarcasm is a form of communication that is intended to mock or harass someone by us- ing words with the opposite of their literal meaning. However, identification of sarcasm is somewhat difficult due to the gap between its literal and intended meaning. Recognition of sarcasm is a task that can potentially pro- vide a lot of benefits to other areas of nat- ural language processing. In this research, we propose a new method to identify sarcasm in tweets that focuses on several approaches: 1) sentiment analysis, 2) concept level and common-sense knowledge 3) coherence and 4) machine learning classification. We will use support vector machine (SVM) to classify sarcastic tweet based on our proposed features as well as ordinary N-grams. Our proposed classifier is an ensemble of two SVMs with two different feature sets. The results of the experiment show our method outperforms the baseline method and achieves 80{\\%} accuracy.},\n\nauthor = {Tungthamthiti, P},\n\nfile = {:home/leo/Dropbox/papers/Y141047.pdf:pdf},\n\njournal = {Proceedings of Pacific {\\ldots}},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {404--413},\n\ntitle = {{Recognition of sarcasm in tweets based on concept level sentiment analysis and supervised learning approaches}},\n\nurl = {http://anthology.aclweb.org/Y/Y14/Y14-1047.pdf},\n\nyear = {2014}\n\n}\n\n@article{Barbieri2014b,\n\nauthor = {Barbieri, Francesco and Ronzano, Francesco and Saggion, Horacio},\n\nfile = {:home/leo/Dropbox/papers/CLICIT201416.pdf:pdf},\n\nnumber = {1975},\n\npages = {28--32},\n\ntitle = {{Italian Irony Detection in Twitter: a First Approach}},\n\nyear = {2014}\n\n}\n\n@article{Wallace2014,\n\nabstract = {Automatically detecting verbal irony (roughly, sarcasm) is a challenging task because ironists say something other than – and often opposite to – what they actually mean. Discerning ironic intent exclusively from the words and syntax comprising texts (e.g., tweets, forum posts) is therefore not always possible: additional contextual information about the speaker and/or the topic at hand is often necessary. We introduce a new corpus that provides empirical evidence for this claim. We show that annota- tors frequently require context to make judgements concerning ironic intent, and that machine learning approaches tend to misclassify those same comments for which annotators required additional context.},\n\nauthor = {Wallace, Byron C and Choe, Do Kook and Kertz, Laura and Charniak, Eugene},\n\nfile = {:home/leo/Dropbox/papers/WCKC2014.pdf:pdf},\n\nisbn = {9781937284732},\n\njournal = {Acl},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {512--516},\n\ntitle = {{Humans Require Context to Infer Ironic Intent ( so Computers Probably do , too )}},\n\nyear = {2014}\n\n}\n\n@article{Rosenthal2014,\n\nabstract = {We describe the Sentiment Analysis in Twitter task, ran as part of SemEval-2014. It is a continuation of the last year's task that ran successfully as part of SemEval-2013. As in 2013, this was the most popular SemEval task; a total of 46 teams contributed 27 submissions for subtask A (21 teams) and 50 submissions for subtask B (44 teams). This year, we introduced three newtest sets: (i) regular tweets, (ii) sarcastic tweets, and (iii) LiveJournal sentences. We further tested on (iv) 2013 tweets, and (v) 2013 SMS messages. The highest F1-score on (i) was achieved by NRC-Canada at 86.63 for subtask A and by TeamX at 70.96 for subtask B.},\n\nauthor = {Rosenthal, Sara and Ritter, Alan and Nakov, Preslav and Stoyanov, Veselin},\n\nfile = {:home/leo/Dropbox/papers/RRNS2014.pdf:pdf},\n\njournal = {Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {SemEval},\n\npages = {73--80},\n\ntitle = {{SemEval-2014 Task 9: Sentiment Analysis in Twitter}},\n\nurl = {http://alt.qcri.org/semeval2014/cdrom/pdf/SemEval009.pdf},\n\nyear = {2014}\n\n}\n\n@article{Justo2014,\n\nabstract = {Automatic detection of emotions like sarcasm or nastiness in online written conversation is a difficult task. It requires a system that can manage some kind of knowledge to interpret that emotional language is being used. In this work, we try to provide this knowledge to the system by considering alternative sets of features obtained according to different criteria. We test a range of different feature sets using two different classifiers. Our results show that the sarcasm detection task benefits from the inclusion of linguistic and semantic information sources, while nasty language is more easily detected using only a set of surface patterns or indicators.},\n\nauthor = {Justo, Raquel and Corcoran, Thomas and Lukin, Stephanie M. and Walker, Marilyn and Torres, M. In{\\'{e}}s In??s},\n\ndoi = {10.1016/j.knosys.2014.05.021},\n\nfile = {:home/leo/Dropbox/papers/JCLWT2014.pdf:pdf},\n\nissn = {09507051},\n\njournal = {Knowledge-Based Systems},\n\nkeywords = {Emotional language,Feature extraction,Nastiness,Sarcasm,Social web,bibchecked},\n\nmendeley-tags = {bibchecked},\n\nmonth = {oct},\n\nnumber = {1},\n\npages = {124--133},\n\npublisher = {Elsevier B.V.},\n\ntitle = {{Extracting relevant knowledge for the detection of sarcasm and nastiness in the social web}},\n\nurl = {http://dx.doi.org/10.1016/j.knosys.2014.05.021 http://linkinghub.elsevier.com/retrieve/pii/S0950705114002226},\n\nvolume = {69},\n\nyear = {2014}\n\n}\n\n@inproceedings{Barbieri2014a,\n\nabstract = {Computational creativity is one of the central research topics of Artificial Intel-ligence and Natural Language Process-ing today. Irony, a creative use of language, has received very little atten-tion from the computational linguistics research point of view. In this study we investigate the automatic detection of irony casting it as a classification prob-lem. We propose a model capable of de-tecting irony in the social network Twit-ter. In cross-domain classification experi-ments our model based on lexical features outperforms a word-based baseline previ-ously used in opinion mining and achieves state-of-the-art performance. Our features are simple to implement making the ap-proach easily replicable.},\n\nauthor = {Barbieri, Francesco and Saggion, Horacio},\n\nbooktitle = {Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14)},\n\nfile = {:home/leo/Dropbox/papers/Barbieri, Saggion - Unknown - Modelling Irony in Twitter.pdf:pdf},\n\nkeywords = {Emotion Recognition/Generation,Opinion Mining,Sentiment Analysis,bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {56--64},\n\ntitle = {{Modelling Irony in Twitter}},\n\nyear = {2014}\n\n}\n\n@inproceedings{Tayal2014,\n\nabstract = {Sarcasm is an activity of saying or writing in such a way that the$\\backslash$ntextual meaning of what is said is opposite of what is meant. Generally,$\\backslash$nsarcastic sentences are used to express negative feelings. Thus in$\\backslash$npolitical polarity detection, it can be used to know the dissatisfaction$\\backslash$nof people against a particular party, candidate or government and hence$\\backslash$nconsidering this other aspects can determine the poll results. This$\\backslash$npaper presents two algorithms, one to identify a sarcastic tweet and$\\backslash$nother to perform polarity detection on political sarcastic tweets. It$\\backslash$nalso includes the current approach we are using to identify the$\\backslash$nsarcastic political tweets and future aspects. It also emphasizes on$\\backslash$nusing the social networking sites and mainly Twitter as a source fur$\\backslash$npredicting political results.},\n\nauthor = {Tayal, D. K. and Yadav, Sumit and Gupta, Komal and Rajput, Bhawna and Kumari, Kiran},\n\nbooktitle = {2014 International Conference on Computing for Sustainable Global Development, INDIACom 2014},\n\ndoi = {10.1109/IndiaCom.2014.6828037},\n\nfile = {:home/leo/Dropbox/papers/tayal2014.pdf:pdf},\n\nisbn = {9789380544120},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nmonth = {mar},\n\npages = {625--628},\n\npublisher = {IEEE},\n\ntitle = {{Polarity detection of sarcastic political tweets}},\n\nurl = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6828037},\n\nyear = {2014}\n\n}\n\n@article{Maynard,\n\nabstract = {Sarcasm is a common phenomenon in social media, and is inherently difficult to analyse, not just automatically but often for humans too. It has an important effect on sentiment, but is usually ignored in social media analysis, because it is considered too tricky to handle. While there exist a few systems which can detect sarcasm, almost no work has been carried out on studying the effect that sarcasm has on sentiment in tweets, and on incorporating this into automatic tools for sentiment analysis. We perform an analysis of the effect of sarcasm scope on the polarity of tweets, and have compiled a number of rules which enable us to improve the accuracy of sentiment analysis when sarcasm is known to be present. We consider in particular the effect of sentiment and sarcasm contained in hashtags, and have developed a hashtag tokeniser for GATE, so that sentiment and sarcasm found within hashtags can be detected more easily. According to our experiments, the hashtag tokenisation achieves 98{\\%} Precision, while the sarcasm detection achieved 91{\\%} Precision and polarity detection 80{\\%}.},\n\nauthor = {Maynard, Diana and Greenwood, Mark A},\n\nfile = {:home/leo/Dropbox/papers/Maynard, Greenwood - Unknown - Who cares about sarcastic tweets Investigating the impact of sarcasm on sentiment analysis.pdf:pdf;:home/leo/Dropbox/papers/MG2014.pdf:pdf},\n\nisbn = {978-2-9517408-8-4},\n\njournal = {LREC},\n\nkeywords = {bibchecked,opinion mining,sarcasm,social media},\n\nmendeley-tags = {bibchecked},\n\npages = {4238--4243},\n\ntitle = {{Who cares about Sarcastic Tweets? Investigating the Impact of Sarcasm on Sentiment Analysis.}},\n\nurl = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/67{\\_}Paper.pdf},\n\nyear = {2014}\n\n}\n\n@article{Ptacek2014,\n\nabstract = {This paper presents a machine learning approach to sarcasm detection on Twitter in two languages – English and Czech. Although there has been some research in sarcasm detection in languages other than English (e.g., Dutch, Italian, and Brazilian Portuguese), our work is the first attempt at sarcasm detection in the Czech language. We created a large Czech Twitter corpus consisting of 7,000 manually-labeled tweets and provide it to the community. We evaluate two classifiers with various combinations of features on both the Czech and English datasets. Furthermore, we tackle the issues of rich Czech morphology by examining different preprocessing techniques. Experiments show that our language-independent approach significantly outperforms adapted state-of-the-art methods in English (F-measure 0.947) and also represents a strong baseline for further research in Czech (F-measure 0.582).},\n\nauthor = {Pt{\\'{a}}{\\v{c}}ek, Tom{\\'{a}}{\\v{s}} and Habernal, Ivan and Hong, Jun},\n\nfile = {:home/leo/Dropbox/papers/C14-1022.pdf:pdf},\n\nisbn = {9781941643266},\n\njournal = {Proceedings of the 25th International Conference on Computational Linguistics: Technical Papers (COLING 2014)},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {213--223},\n\ntitle = {{Sarcasm Detection on Czech and English Twitter}},\n\nurl = {http://www.aclweb.org/anthology/C14-1022},\n\nyear = {2014}\n\n}\n\n@inproceedings{Nagwanshi2014,\n\nabstract = {Sarcasm is a figure of speech used to express a strong opinion in a mild manner. It is often used to convey the opposite sense of what is expressed. Automatic recognition of sarcasm is a complex task. Sarcasm detection is of importance in effective opinion mining. Most sarcasm detectors use lexical and pragmatic features for this purpose. We incorporate statistical as well as linguistic features. Our approach considers the semantic and flipping of sentiment as main features. We use machine learning techniques for classification of sarcastic statements. We conduct experiments on different types of data sets, and compare our results with an existing approach in the literature. We also present human evaluation results. We propose to augment the present encouraging results by a new approach of integrating linguistic and cognitive aspects of text processing.},\n\naddress = {Rome},\n\nauthor = {Nagwanshi, Prateek and {Veni Madhavan}, C. E.},\n\nbooktitle = {KDIR 2014 - Proceedings of the International Conference on Knowledge Discovery and Information Retrieval},\n\ndoi = {10.5220/0005153504180424},\n\nfile = {:home/leo/Dropbox/papers/Nagwanshi2014.pdf:pdf},\n\nisbn = {9789897580482},\n\nkeywords = {Classification,Computational linguistics,Natural language processing,Opinionmining,Sarcasm detection,bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {418--424},\n\npublisher = {SCITEPRESS - Science and and Technology Publications},\n\ntitle = {{Sarcasm detection using sentiment and semantic features}},\n\nurl = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84909969590{\\&}partnerID=tZOtx3y1},\n\nyear = {2014}\n\n}\n\n@inproceedings{Liu2014,\n\nabstract = {Sarcasm is a pervasive linguistic phenomenon in online documents that express subjective and deeply-felt opinions. Detection of sarcasm is of great importance and beneficial to many NLP applications, such as sentiment analysis, opinion mining and advertising. Current studies consider automatic sarcasm detection as a simple text classification problem. They do not use explicit features to detect sarcasm and ignore the imbalance between sarcastic and non-sarcastic samples in real applications. In this paper, we first explore the characteristics of both English and Chinese sarcastic sentences and introduce a set of features specifically for detecting sarcasm in social media. Then, we propose a novel multi-strategy ensemble learning approach(MSELA) to handle the imbalance problem. We evaluate our proposed model on English and Chinese data sets. Experimental results show that our ensemble approach outperforms the state-of-the-art sarcasm detection approaches and popular imbalanced classification methods. {\\textcopyright} 2014 Springer International Publishing Switzerland.},\n\nauthor = {Liu, Peng and Chen, Wei and Ou, Gaoyan and Wang, Tengjiao and Yang, Dongqing and Lei, Kai},\n\nbooktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},\n\ndoi = {10.1007/978-3-319-08010-9_49},\n\nfile = {:home/leo/Dropbox/papers/LCOWYL2014.pdf:pdf},\n\nisbn = {9783319080093},\n\nissn = {16113349},\n\nkeywords = {bibchecked,ensemble learning,imbalanced classification,sarcasm detection,sarcasm features},\n\nmendeley-tags = {bibchecked},\n\npages = {459--471},\n\ntitle = {{Sarcasm detection in social media based on imbalanced classification}},\n\nurl = {http://link.springer.com/10.1007/978-3-319-08010-9{\\_}49},\n\nvolume = {8485 LNCS},\n\nyear = {2014}\n\n}\n\n@article{Barbieri2014,\n\nabstract = {Automatic detection of figurative language is a challenging task in computational lin- guistics. Recognising both literal and fig- urative meaning is not trivial for a ma- chine and in some cases it is hard even for humans. For this reason novel and accurate systems able to recognise figura- tive languages are necessary. We present in this paper a novel computational model capable to detect sarcasm in the social network Twitter (a popular microblogging service which allows users to post short messages). Our model is easy to imple- ment and, unlike previous systems, it does not include patterns of words as features. Our seven sets of lexical features aim to detect sarcasm by its inner structure (for example unexpectedness, intensity of the terms or imbalance between registers), ab- stracting from the use of specific terms.},\n\nauthor = {Barbieri, Francesco and Saggion, Horacio and Ronzano, Francesco},\n\nfile = {:home/leo/Dropbox/papers/BSR2014.pdf:pdf},\n\nisbn = {9781941643112},\n\njournal = {Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {50--58},\n\ntitle = {{Modelling Sarcasm in Twitter, a Novel Approach}},\n\nyear = {2014}\n\n}\n\n@inproceedings{Lunando2013,\n\nabstract = {Sarcasm is considered one of the most difficult problem in sentiment analysis. In our observation on Indonesian social media, for certain topics, people tend to criticize something using sarcasm. Here, we proposed two additional features to detect sarcasm after a common sentiment analysis is conducted. The features are the negativity information and the number of interjection words. We also employed translated SentiWordNet in the sentiment classification. All the classifications were conducted with machine learning algorithms. The experimental results showed that the additional features are quite effective in the sarcasm detection.},\n\narchivePrefix = {arXiv},\n\narxivId = {1505.03085},\n\nauthor = {Lunando, Edwin and Purwarianti, Ayu},\n\nbooktitle = {2013 International Conference on Advanced Computer Science and Information Systems, ICACSIS 2013},\n\ndoi = {10.1109/ICACSIS.2013.6761575},\n\neprint = {1505.03085},\n\nfile = {:home/leo/Dropbox/papers/Lunando, Purwarianti - 2015 - Indonesian Social Media Sentiment Analysis With Sarcasm Detection.pdf:pdf},\n\nisbn = {VO -},\n\nkeywords = {SentiWordNet,Sentiment analysis,bibchecked,classification,sarcasm},\n\nmendeley-tags = {bibchecked},\n\nmonth = {may},\n\npages = {195--198},\n\ntitle = {{Indonesian social media sentiment analysis with sarcasm detection}},\n\nurl = {http://arxiv.org/abs/1505.03085 http://dx.doi.org/10.1109/ICACSIS.2013.6761575},\n\nyear = {2013}\n\n}\n\n@article{Liebrecht2013,\n\nabstract = {To avoid a sarcastic message being understood in its unintended literal meaning, in microtexts such as messages on Twitter.com sarcasm is often explicitly marked with the hashtag ‘{\\#}sar- casm'. We collected a training corpus of about 78 thousand Dutch tweets with this hashtag. Assuming that the human labeling is correct (annotation of a sample indicates that about 85{\\%} of these tweets are indeed sarcastic), we train a machine learning classifier on the har- vested examples, and apply it to a test set of a day's stream of 3.3 million Dutch tweets. Of the 135 explicitly marked tweets on this day, we detect 101 (75{\\%}) when we remove the hashtag. We annotate the top of the ranked list of tweets most likely to be sarcastic that do not have the explicit hashtag. 30{\\%} of the top-250 ranked tweets are indeed sarcastic. Analysis shows that sarcasm is often signalled by hy- perbole, using intensifiers and exclamations; in contrast, non-hyperbolic sarcastic messages often receive an explicit marker. We hypothe- size that explicit markers such as hashtags are the digital extralinguistic equivalent of non- verbal expressions that people employ in live interaction when conveying sarcasm.},\n\nauthor = {Liebrecht, Christine and Kunneman, Florian and Bosch, Antal Van Den},\n\nfile = {:home/leo/Dropbox/papers/LKB2013.pdf:pdf},\n\nisbn = {9781937284473},\n\njournal = {Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {June},\n\npages = {29--37},\n\ntitle = {{The perfect solution for detecting sarcasm in tweets {\\#} not}},\n\nyear = {2013}\n\n}\n\n@article{Lukin2013,\n\nabstract = {More and more of the information on the web is dialogic, from Facebook newsfeeds, to fo- rum conversations, to comment threads on news articles. In contrast to traditional, mono- logic Natural Language Processing resources such as news, highly social dialogue is fre- quent in social media, making it a challenging context for NLP. This paper tests a bootstrap- ping method, originally proposed in a mono- logic domain, to train classifiers to identify two different types of subjective language in dialogue: sarcasm and nastiness. We explore two methods of developing linguistic indica- tors to be used in a first level classifier aimed at maximizing precision at the expense of re- call. The best performing classifier for the first phase achieves 54{\\%} precision and 38{\\%} recall for sarcastic utterances. We then use general syntactic patterns from previous work to cre- ate more general sarcasm indicators, improv- ing precision to 62{\\%} and recall to 52{\\%}. To further test the generality of the method, we then apply it to bootstrapping a classifier for nastiness dialogic acts. Our first phase, using crowdsourced nasty indicators, achieves 58{\\%} precision and 49{\\%} recall, which increases to 75{\\%} precision and 62{\\%} recall when we boot- strap over the first level with generalized syn- tactic patterns.},\n\nauthor = {Lukin, Stephanie and Walker, Marilyn},\n\nfile = {:home/leo/Dropbox/papers/LASM04.pdf:pdf},\n\nisbn = {9781937284473},\n\njournal = {Proceedings of the Workshop on Language Analysis in Social Media},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {Lasm},\n\npages = {30--40},\n\ntitle = {{Really? Well. Apparently Bootstrapping Improves the Performance of Sarcasm and Nastiness Classifiers for Online Dialogue}},\n\nurl = {http://www.aclweb.org/anthology/W13-1104{\\%}5Cnhttp://csctec-tsh.kdis.edu.cn/downloads/resource/72ad9679a64dc7015ea7d6db0ff3aef3.pdf{\\#}page=40},\n\nvolume = {1},\n\nyear = {2013}\n\n}\n\n@article{Riloff2013,\n\nabstract = {A common form of sarcasm on Twitter con- sists of a positive sentiment contrasted with a negative situation. For example, many sarcas- tic tweets include a positive sentiment, such as “love” or “enjoy”, followed by an expression that describes an undesirable activity or state (e.g., “taking exams” or “being ignored”).We have developed a sarcasm recognizer to iden- tify this type of sarcasm in tweets. We present a novel bootstrapping algorithmthat automati- cally learns lists of positive sentiment phrases and negative situation phrases from sarcastic tweets. We show that identifying contrast- ing contexts using the phrases learned through bootstrapping yields improved recall for sar- casm recognition. 1},\n\nauthor = {Riloff, Ellen and Qadir, Ashequl and Surve, Prafulla and Silva, Lalindra De and Gilbert, Nathan and Huang, Ruihong},\n\nfile = {:home/leo/Dropbox/papers/RQSSGH2013.pdf:pdf;:home/leo/Dropbox/papers/official-emnlp13-sarcasm.pdf:pdf},\n\nisbn = {9781937284978},\n\njournal = {Emnlp},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {Emnlp},\n\npages = {704--714},\n\ntitle = {{Sarcasm as Contrast between a Positive Sentiment and Negative Situation}},\n\nyear = {2013}\n\n}\n\n@article{Rakov2013,\n\nabstract = {While a fair amount of work has been done on automatically detecting emotion in human speech, there has been little research on sarcasm detection. Although sarcastic speech acts are inherently subjective, humans have relatively clear intuitions as to what constitutes sarcastic speech. In this paper, we present a system for automatic sarcasm detection. Using a new acted speech corpus that is annotated for sarcastic and sincere speech, we examine a number of features that are indicative of sarcasm. The first set of features looks at a baseline of basic acoustic features that have been found to be helpful in human sarcasm identification. We then present an effective way of modeling and applying prosodic contours to the task of automatic sarcasm detection. This approach applies sequential modeling to categorical representations of pitch and intensity contours obtained via k-means clustering. Using a SimpleLogistic (LogitBoost) classifier, we are able to predict sarcasm with 81.57{\\%} accuracy. This result suggests that certain pitch and intensity contours are predictive of sarcastic speech.},\n\nauthor = {Rakov, Rachel and Rosenberg, Andrew},\n\nfile = {:home/leo/Dropbox/papers/rakov2013sarcasm.pdf:pdf},\n\nissn = {19909772},\n\njournal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},\n\nkeywords = {Emotion detection,Prosody modeling,Sarcasm,Speech recognition,bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {842--846},\n\ntitle = {{\"Sure, I did the right thing\": A system for sarcasm detection in speech}},\n\nyear = {2013}\n\n}\n\n@article{Averbeck2013,\n\nabstract = {Due to frequent confusion over what exactly an ironic argument is and how it differs from sarcasm, this study seeks to distinguish between irony and sarcasm in the interpersonal context. Conceptual differences are offered between irony and sarcasm, and literal, ironic, and sarcastic arguments are compared in terms of appropri- ateness and effectiveness. Results showed that sarcastic arguments were rated the least effective and least appropriate. Ironic arguments were rated moderately appropriate and most effective. The literal arguments were rated moderately effective and most appropriate. With these distinctions made between irony and sarcasm future directions are offered.},\n\nauthor = {Averbeck, Joshua M.},\n\nfile = {:home/leo/Dropbox/papers/Averbeck - 2013 - Comparisons of Ironic and Sarcastic Arguments in Terms of Appropriateness and Effectiveness in Personal Relationships.pdf:pdf},\n\nissn = {1051-1431},\n\njournal = {Argumentation and Advocacy},\n\nkeywords = {Argument Effectiveness,Irony,Message Processing,Sarcasm},\n\nnumber = {1},\n\npages = {47--57},\n\npublisher = {American Forensic Association},\n\ntitle = {{Comparisons of Ironic and Sarcastic Arguments in Terms of Appropriateness and Effectiveness in Personal Relationships}},\n\nvolume = {50},\n\nyear = {2013}\n\n}\n\n@article{Filatova2012,\n\nabstract = {Abstract The ability to reliably identify sarcasm and irony in text can improve the performance of many Natural Language Processing (NLP) systems including summarization, sentiment analysis, etc. The existing sarcasm detection systems have focused on identifying sarcasm on a sentence level or for a specific phrase. However, often it is impossible to identify a sentence containing sarcasm without knowing the context. In this paper we describe a corpus generation experiment where we collect regular and sarcastic Amazon product reviews. We perform qualitative and quantitative analysis of the corpus. The resulting corpus can be used for identifying sarcasm on two levels: a document and a text utterance (where a text utterance can be as short as a sentence and as long as a whole document).},\n\nauthor = {Filatova, Elena},\n\nfile = {:home/leo/Dropbox/papers/661{\\_}Paper.pdf:pdf},\n\nisbn = {978-2-9517408-7-7},\n\njournal = {Lrec},\n\nkeywords = {bibchecked,corpus,product reviews,sarcasm},\n\nmendeley-tags = {bibchecked},\n\npages = {392--398},\n\ntitle = {{Irony and Sarcasm: Corpus Generation and Analysis Using Crowdsourcing}},\n\nurl = {http://storm.cis.fordham.edu/{~}filatova/PDFfiles/FilatovaLREC2012.pdf},\n\nyear = {2012}\n\n}\n\n@book{Mounts2012,\n\nauthor = {Mounts, Joel},\n\ntitle = {{A History of Sarcasm : Effects of Balanced Use of Sarcasm in a Relationship Effects of Balanced Use of Sarcasm in a Relationship}},\n\nurl = {http://scholarworks.gvsu.edu/honorsprojects http://scholarworks.gvsu.edu/honorsprojects/155},\n\nyear = {2012}\n\n}\n\n@article{Campbell2012,\n\nabstract = {This article investigates the contextual components utilized to convey sarcastic verbal irony, testing whether theoretical components deemed as necessary for creating a sense of irony are, in fact, necessary. A novel task was employed: Given a set of statements that out of context were not rated as sarcastic, partic- ipants were instructed to either generate discourse context that would make the statements sarcastic or meaningful (without further specification). In a series of studies, these generated contexts were shown to differ from one another along the dimensions presumed as necessary (failed expectation, pragmatic insincerity, negative tension, and presence of a victim) and along stylistic components (as indexed by the Linguistic Inquiry and Word Count program). However, none of these componentswere found to be necessary. Indeed, in each case, the items rated as highest in sarcasm were often at the lowest levels on the putative “necessary” characteristic. These data are taken as consistentwith constraint satisfactionmodels of sarcasm processing in which various linguistic and extralinguistic informa- tion provide probabilistic (but not necessary) support for or against a sarcastic interpretation. A},\n\nauthor = {Campbell, John D. and Katz, Albert N.},\n\ndoi = {10.1080/0163853X.2012.687863},\n\nfile = {:home/leo/Dropbox/papers/campbelkatz.pdf:pdf},\n\nissn = {0163-853X},\n\njournal = {Discourse Processes},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {6},\n\npages = {459--480},\n\ntitle = {{Are There Necessary Conditions for Inducing a Sense of Sarcastic Irony?}},\n\nvolume = {49},\n\nyear = {2012}\n\n}\n\n@article{Camp2012,\n\nabstract = {Traditional theories of sarcasm treat it as a case of a speaker's meaning the opposite of what she says. Recently, ‘expressivists' have argued that sarcasm is not a type of speaker meaning at all, but merely the expression of a dissociative attitude toward an evoked thought or perspective. I argue that we should analyze sarcasm in terms of meaning inversion, as the traditional theory does; but that we need to construe ‘meaning' more broadly, to include illocutionary force and evaluative attitudes as well as propositional content. I distinguish four subclasses of sarcasm, individuated in terms of the target of inversion. Three of these classes raise serious challenges for a standard implicature analysis.},\n\nauthor = {Camp, Elisabeth},\n\ndoi = {10.1111/j.1468-0068.2010.00822.x},\n\nfile = {:home/leo/Dropbox/papers/Camp.SarcProofs.pdf:pdf},\n\nissn = {00294624},\n\njournal = {Nous},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {4},\n\npages = {587--634},\n\ntitle = {{Sarcasm, pretense, and the semantics/pragmatics distinction}},\n\nvolume = {46},\n\nyear = {2012}\n\n}\n\n@article{Bowes2011,\n\nabstract = {The use of sarcasm sometimes lessens and sometimes enhances the negativity inherent in a sarcastic statement. Using a realistic conversational format, partici- pants read either a sarcastic or a non-sarcastic aggressive argument between same- gendered interlocutors, and rated the pragmatic goals being expressed using a range of measures taken from previous studies. A factor analysis meaningfully grouped the dependent variables into separate factors, one of which indexed “victimization” and a second of which indexed “relational aggression.” The sarcastic version was perceived as more victimizing and more relationally aggressive, contrary to the muting hypothesis. Secondary analyses demonstrated that participants perceived the negative comment of the aggressor as more humorous and less aggressive when taking the perspective of the aggressor than when taking the perspective of the victim, and that male participants reported greater use of sarcasm in everyday life, but did not produce more when given the opportunity to do so.},\n\nauthor = {Bowes, Andrea and Katz, Albert},\n\ndoi = {10.1080/0163853X.2010.532757},\n\nfile = {:home/leo/Dropbox/papers/Bowes, Katz - 2011 - When Sarcasm Stings.pdf:pdf},\n\nissn = {0163-853X},\n\njournal = {Discourse Processes},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nmonth = {apr},\n\nnumber = {4},\n\npages = {215--236},\n\ntitle = {{When Sarcasm Stings}},\n\nurl = {http://www.tandfonline.com/doi/abs/10.1080/0163853X.2010.532757},\n\nvolume = {48},\n\nyear = {2011}\n\n}\n\n@article{Cheang2011,\n\nabstract = {The goal of the present research was to determine whether certain speaker inten- tions conveyed through prosody in an unfamiliar language can be accurately recognized. English and Cantonese utterances expressing sarcasm, sincerity, humorous irony, or neutrality through prosody were presented to English and Cantonese listeners unfamiliar with the other language. Listeners identified the communicative intent of utterances in both languages in a crossed design. Participants successfully identified sarcasm spoken in their native language but identified sarcasm at near-chance levels in the unfamiliar language. Both groups were relatively more successful at recognizing the other attitudes when listening to the unfamiliar language (in addition to the native language). Our data suggest that while sarcastic utterances in Cantonese and English share certain acoustic features, these cues are insufficient to recognize sarcasm between languages; rather, this ability depends on (native) language experience.},\n\nauthor = {Cheang, Henry S and Pell, Marc D},\n\ndoi = {10.1075/pc.19.2.02che},\n\nfile = {:home/leo/Dropbox/papers/cheng{\\_}{\\_}pell{\\_}2011.pdf:pdf},\n\nisbn = {0929-0907, 0929-0907},\n\nissn = {0929-0907},\n\njournal = {Pragmatics {\\&} Cognition},\n\nkeywords = {Cantonese,bibchecked,communicative intentions,cross-linguistic,sarcasm,speech perception},\n\nmendeley-tags = {bibchecked},\n\nnumber = {2},\n\npages = {203--223},\n\ntitle = {{Recognizing sarcasm without language: A cross-linguistic study of English and Cantonese}},\n\nurl = {http://www.jbe-platform.com/content/journals/10.1075/pc.19.2.02che},\n\nvolume = {19},\n\nyear = {2011}\n\n}\n\n@article{Gonzalez-Ibanez2011,\n\nabstract = {Sarcasm transforms the polarity of an ap- parently positive or negative utterance into its opposite. We report on a method for constructing a corpus of sarcastic Twitter messages in which determination of the sarcasm of each message has been made by its author. We use this reliable corpus to compare sarcastic utterances in Twitter to utterances that express positive or negative attitudes without sarcasm. We investigate the impact of lexical and pragmatic factors on machine learning effectiveness for iden- tifying sarcastic utterances and we compare the performance of machine learning tech- niques and human judges on this task. Per- haps unsurprisingly, neither the human judges nor the machine learning techniques perform very well.},\n\nauthor = {Gonz{\\'{a}}lez-Ib{\\'{a}}{\\~{n}}ez, Roberto and Muresan, Smaranda and Wacholder, Nina},\n\nfile = {:home/leo/Dropbox/papers/GMW2011.pdf:pdf},\n\nisbn = {978-1-932432-88-6},\n\njournal = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {581--586},\n\npublisher = {Association for Computational Linguistics},\n\ntitle = {{Identifying sarcasm in Twitter: a closer look}},\n\nyear = {2011}\n\n}\n\n@article{Davidov2010,\n\nabstract = {Sarcasm is a form of speech act in which the speakers convey their message in an implicit way. The inherently ambiguous nature of sarcasm sometimes makes it hard even for humans to decide whether an ut- terance is sarcastic or not. Recognition of sarcasm can benefit many sentiment analy- sis NLP applications, such as review sum- marization, dialogue systems and review ranking systems. In this paper we experiment with semi- supervised sarcasm identification on two very different data sets: a collection of 5.9 million tweets collected from Twit- ter, and a collection of 66000 product re- views from Amazon. Using the Mechani- cal Turk we created a gold standard sam- ple in which each sentence was tagged by 3 annotators, obtaining F-scores of 0.78 on the product reviews dataset and 0.83 on the Twitter dataset. We discuss the dif- ferences between the datasets and how the algorithm uses them (e.g., for the Amazon dataset the algorithm makes use of struc- tured information). We also discuss the utility of Twitter {\\#}sarcasm hashtags for the task.},\n\nauthor = {Davidov, Dmitry and Tsur, Oren and Rappoport, Ari},\n\ndoi = {10.1145/1964858.1964874},\n\nfile = {:home/leo/Dropbox/papers/Davidov, Tsur, Rappoport - 2010 - Semi-supervised recognition of sarcastic sentences in Twitter and Amazon.pdf:pdf},\n\nisbn = {1932432833},\n\nissn = {1932432833},\n\njournal = {Fourteenth Conference on Computational Natural Language Learning},\n\nkeywords = {Information Retrieval {\\&} Textual Information Access,Natural Language Processing,User Modelling for Computer Human Interaction,bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {July},\n\npages = {107--116},\n\npublisher = {Association for Computational Linguistics},\n\ntitle = {{Semi-Supervised Recognition of Sarcastic Sentences in Twitter and Amazon.}},\n\nurl = {http://eprints.pascal-network.org/archive/00007069/},\n\nyear = {2010}\n\n}\n\n@article{Tsur2010,\n\nabstract = {Sarcasm is a sophisticated form of speech act widely used in online communities. Automatic recognition of sarcasm is, however, a novel task. Sarcasm recognition could contribute to the performance of review summarization and ranking systems. This paper presents SASI, a novel Semi-supervised Algorithm for Sarcasm Identification that recognizes sarcastic sentences in product reviews. SASI has two stages: semisupervised pattern acquisition, and sarcasm classification. We experimented on a data set of about 66000 Amazon reviews for various books and products. Using a gold standard in which each sentence was tagged by 3 annotators, we obtained precision of 77{\\%} and recall of 83.1{\\%} for identifying sarcastic sentences. We found some strong features that characterize sarcastic utterances. However, a combination of more subtle pattern-based features proved more promising in identifying the various facets of sarcasm. We also speculate on the motivation for using sarcasm in online communities and social networks.},\n\nauthor = {Tsur, Oren and Rappoport, Ari and Davidov, Dmitry},\n\nfile = {:home/leo/Dropbox/papers/1495-7855-1-PB.pdf:pdf},\n\nisbn = {9781577354451},\n\njournal = {International AAAI Conference on Weblogs and Social Media},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {9},\n\npages = {162--169},\n\ntitle = {{ICWSM – A Great Catchy Name: Semi-Supervised Recognition of Sarcastic Sentences in Online Product Reviews}},\n\nurl = {www.cs.huji.ac.il/∼arir},\n\nyear = {2010}\n\n}\n\n@article{Hao2010,\n\nabstract = {Irony is an effective but challenging mode of communication that allows a speaker to express viewpoints rich in sentiment with concision, sharpness and humour. Creative irony is especially common in online documents that express subjective and deeply-felt opinions, and thus represents a significant obstacle to the accurate analysis of sentiment in web texts. In this paper we look at one commonly used framing device for linguistic irony-the simile-to show how even the most creative uses of irony are often marked in ways that make them computationally feasible to detect. We conduct a very large corpus analysis of web-harvested similes to identify the most interesting characteristics of ironic comparisons, and provide an empirical evaluation of a new algorithm for separating ironic from non-ironic similes. [ABSTRACT FROM AUTHOR]},\n\nauthor = {Hao, Yanfen and Veale, Tony},\n\ndoi = {10.1007/s11023-010-9211-1},\n\nfile = {:home/leo/Dropbox/papers/ironicfist.pdf:pdf},\n\nisbn = {0924-6495},\n\nissn = {09246495},\n\njournal = {Minds and Machines},\n\nkeywords = {Expectation,Irony,Mis-representation,Pretence,Sentiment,bibchecked},\n\nmendeley-tags = {bibchecked},\n\nnumber = {4},\n\npages = {635--650},\n\ntitle = {{An ironic fist in a velvet glove: Creative mis-representation in the construction of ironic similes}},\n\nvolume = {20},\n\nyear = {2010}\n\n}\n\n@article{Carvalho2009,\n\nabstract = {We investigate the accuracy of a set of surface patterns in identifying ironic sentences in comments submitted by users to an on-line newspaper. The initial focus is on identifying irony in sentences containing positive predicates since these sentences are more exposed to irony, making their true polarity harder to recognize. We show that it is possible to find ironic sentences with relatively high precision (from 45{\\%} to 85{\\%}) by exploring certain oral or gestural clues in user comments, such as emoticons, onomatopoeic expressions for laughter, heavy punctuation marks, quotation marks and positive interjections. We also demonstrate that clues based on deeper linguistic information are relatively inefficient in capturing irony in user-generated content, which points to the need for exploring additional types of oral clues.},\n\nauthor = {Carvalho, Paula and Sarmento, Lu{\\'{i}}s and Silva, M{\\'{a}}rio J and de Oliveira, Eug{\\'{e}}nio},\n\ndoi = {10.1145/1651461.1651471},\n\nfile = {:home/leo/Dropbox/papers/Carvalho09.pdf:pdf},\n\nisbn = {9781605588056},\n\njournal = {Proceeding of the 1st international CIKM workshop on Topic-sentiment analysis for mass opinion - TSA '09},\n\nkeywords = {bibchecked,irony detection,opinion mining,user-generated content},\n\nmendeley-tags = {bibchecked},\n\npages = {53},\n\ntitle = {{Clues for detecting irony in user-generated contents}},\n\nurl = {http://portal.acm.org/citation.cfm?doid=1651461.1651471},\n\nyear = {2009}\n\n}\n\n@misc{Kreuz2007,\n\nabstract = {Speakers and listeners make use of a variety of pragmatic factors to produce and identify sarcastic statements. It is also possible that lexical factors play a role, although this possibility has not been investigated previously. College students were asked to read excerpts from published works that originally contained the phrase said sarcastically, although the word sarcastically was deleted. The participants rated the characters' statements in these excerpts as more likely to be sarcastic than those from similar excerpts that did not originally contain the word sarcastically. The use of interjections, such as gee or gosh, predicted a significant amount of the variance in the participants' ratings of sarcastic intent. This outcome suggests that sarcastic statements may be more formulaic than previously realized. It also suggests that computer software could be written to recognize such lexical factors, greatly increasing the likelihood that non-literal intent could be correctly interpreted by such programs, even if they are unable to identify the pragmatic components of nonliteral language.},\n\nauthor = {Kreuz, Roger J. and Caucci, Gina M.},\n\nbooktitle = {Proceedings of the Workshop on Computational Approaches to Figurative Language},\n\ndoi = {10.3115/1611528.1611529},\n\nfile = {:home/leo/Dropbox/papers/KC2007.pdf:pdf},\n\nkeywords = {bibchecked},\n\nmendeley-tags = {bibchecked},\n\npages = {1--4},\n\npublisher = {Association for Computational Linguistics},\n\ntitle = {{Lexical influences on the perception of sarcasm}},\n\nurl = {http://dl.acm.org/citation.cfm?id=1611528.1611529},\n\nyear = {2007}\n\n}\n\n@article{Wilson2006a,\n\nabstract = {This paper considers two post-Gricean attempts to provide an explanatory account of verbal irony. The first treats irony as an echoic use of language in which the speaker tacitly dissociates herself from an attributed utterance or thought. The second treats irony as a type of pretence in which the speaker \"makes as if\" to perform a certain speech act, expecting her audience to see through the pretence and recognise the mocking or critical attitude behind it. The two approaches have sometimes been seen as empirically or theoretically indistinguishable, and several hybrid accounts incorporating elements of both have been proposed. I will argue that the echoic and pretence accounts are distinguishable on both theoretical and empirical grounds, and that while echoic use is essential to standard cases of verbal irony, pretence is not. However, the term irony has been applied to a very wide range of phenomena, not all of which can be explained in the same way, and I will end by briefly mentioning some less central cases where varieties of pretence or simulation do indeed achieve ironical effects. ?? 2006.},\n\nauthor = {Wilson, Deirdre},\n\ndoi = {10.1016/j.lingua.2006.05.001},\n\nfile = {:home/leo/Dropbox/papers/wilson2006.pdf:pdf;:home/leo/Dropbox/papers/wilson2006 (Case Conflict).pdf:pdf},\n\nisbn = {0024-3841},\n\nissn = {00243841},\n\njournal = {Lingua},\n\nkeywords = {Echoic use,Irony,Metarepresentation,Pretence,Relevance theory,bibchecked},\n\nmendeley-tags = {bibchecked},\n\nmonth = {oct},\n\nnumber = {10},\n\npages = {1722--1743},\n\npublisher = {North-Holland},\n\ntitle = {{The pragmatics of verbal irony: Echo or pretence?}},\n\nurl = {http://linkinghub.elsevier.com/retrieve/pii/S0024384106001124},\n\nvolume = {116},\n\nyear = {2006}\n\n}\n\n@article{Tepperman2006,\n\nabstract = {See, stats, and : https : / / www . researchgate . net / publication / 221491095 Yeah : Sarcasm dialogue Conference Source : DBLP CITATIONS 20 READS 158 3 , including : David University 270 , 013 SEE Shrikanth University 683 , 065 SEE All - text , letting . Available : David Retrieved : 08 ABSTRACT The robust understanding of sarcasm in a spoken dialogue system requires a reformulation of the dialogue manager ' s basic assumptions behind , for example , user behavior and grounding strategies . But automatically detecting a sarcastic tone of voice is not a simple matter . This paper presents some experiments toward sarcasm recognition using prosodic , spectral , and contextual cues . Our results demonstrate that spectral and contextual features can be used to detect sarcasm as well as a human annotator would , and confirm a long - held claim in the field of psychology – that prosody alone is not sufficient to discern whether a speaker is being sarcastic .},\n\nauthor = {Tepperman, Joseph and Traum, David and Narayanan, Shrikanth},\n\nfile = {:home/leo/Dropbox/papers/Tepperman, Traum, Narayanan - 2006 - Yeah right Sarcasm recognition for spoken dialogue systems.pdf:pdf},\n\nkeywords = {Index Terms,bibchecked,dialogue,sarcasm,speech acts,user modeling},\n\nmendeley-tags = {bibchecked},\n\ntitle = {{\" YEAH RIGHT \" : SARCASM RECOGNITION FOR SPOKEN DIALOGUE SYSTEMS}},\n\nyear = {2006}\n\n}\n\n@article{Ivanko2004,\n\nabstract = {In the present research, the authors examined the effects of self-perceived use of sarcasm on the production, interpretation, and processing of verbal irony. Accordingly, they first devised and evaluated a sarcasm self-report scale (SSS). In Experiment 1, results showed that participants' self-perceived use of sarcastic irony (as assessed by the SSS) predicted their use of ironic statements in a production task and was related to their interpretation of ironic criticisms and ironic compliments. In Experiment 2, results showed that partici- pants' perceived use of irony was related to their processing of ironic statements: SSS scores were related to relative processing speeds for literal and ironic statements. The results of these experiments indicate that there are individual differences in purported use of sarcasm that influence interpretation and processing of verbal irony. Keywords:},\n\nauthor = {Ivanko, Stacey and Penmax, Penny M. and Olineck, Karam},\n\ndoi = {10.1177/0261927X04266809},\n\nfile = {:home/leo/Dropbox/papers/Ivanko, Penmax, Olineck - 2004 - How Sarcastic are You Individual Differences and Verbal Irony.pdf:pdf},\n\nisbn = {0261-927X},\n\nissn = {0261-927X},\n\njournal = {Journal of Language and Social Psychology},\n\nkeywords = {and a num-,bibchecked,considerable body of research,examined,figurative languages,in which the interpre-,individual differences,sarcasm,tation and processing of,there is now a,verbal irony,verbal irony have been},\n\nmendeley-tags = {bibchecked},\n\nmonth = {sep},\n\nnumber = {3},\n\npages = {244--271},\n\ntitle = {{How Sarcastic are You?: Individual Differences and Verbal Irony}},\n\nurl = {http://jls.sagepub.com/cgi/doi/10.1177/0261927X04266809},\n\nvolume = {23},\n\nyear = {2004}\n\n}\n\n@article{Attardo2003,\n\nabstract = {Two studies using multimodal stimuli collected from television situation comedies show that there exist markers of irony and sarcasm which involve into national and visual clues. Our first conclusion is that there exists no \"ironical intonation\" per se, but rather that pitch is a contrastive marker for irony or sarcasm. Our second conclusion is that there exists a facial expression, characterized as a \"blank face,\" which is a visual marker of irony or sarcasm. We further discuss paracommunicative and metacommunicative alerts to ironical/sarcastic intent. [ABSTRACT FROM AUTHOR]},\n\nauthor = {Attardo, Salvatore and Eisterhold, Jodi and Hay, Jennifer and Poggi, Isabella and {Attardo JodiHay, JenniferyPoggi, Isabella}, SalvatoreEisterhold},\n\ndoi = {10.1515/humr.2003.012},\n\nfile = {:home/leo/Dropbox/papers/AEHP2003.pdf:pdf},\n\nisbn = {0933-1719},\n\nissn = {09331719},\n\njournal = {Humor: International Journal of Humor Research},\n\nkeywords = {IRONY,TELEVISION comedies,add to it in,and,bibchecked,blank face,but significant literature on,facial expression,in this paper,irony,markers of irony and,more significantly,on the,sarcasm,some of the literature,the markers of irony,there exists a small,two respects,we intro-,we will briefly review},\n\nmendeley-tags = {bibchecked},\n\nmonth = {jan},\n\nnumber = {2},\n\npages = {243},\n\ntitle = {{Multimodal markers of irony and sarcasm}},\n\nurl = {http://www.degruyter.com/view/j/humr.2003.16.issue-2/humr.2003.012/humr.2003.012.xml http://search.ebscohost.com/login.aspx?direct=true{\\&}db=pbh{\\&}AN=10064517{\\&}site=ehost-live{\\%}5Cnhttp://www.degruyter.com/view/j/humr.2003.16.issue-2/humr.2003.012/humr.2003.012.xm},\n\nvolume = {16},\n\nyear = {2003}\n\n}\n\n@article{Bryant2002,\n\nabstract = {We explored the differential impact of auditory information and written contextual information on the recognition of verbal irony in spontaneous speech. Based on rele- vance theory, we predicted that speakers would provide acoustic disambiguation cues when speaking in situations that lack other sources of information, such as a vi- sual channel.We further predicted that listeners would use this information, in addi- tion to context, when interpreting the utterances. People were presented with sponta- neously produced ironic and nonironic utterances from radio talk shows in written or auditory form, with or without written contextual information. When the utterances were read without written contextual information, all utterances were rated as equally ironic. But when they were heard as opposed to read, or when they were pre- sented in irony-biasing contexts, originally ironic utterances were rated as more sar- castic than originally nonironic utterances. This evidence suggests both acoustic and contextual information are used when inferring ironic intent in spontaneous speech, and validates previous manipulations of intonation in studies of irony understanding. “That's},\n\nauthor = {Bryant, Gregory a. and {Fox Tree}, Jean E.},\n\ndoi = {10.1207/S15327868MS1702_2},\n\nfile = {:home/leo/Dropbox/papers/mandsym.pdf:pdf},\n\nisbn = {1092-6488$\\backslash$r1532-7868},\n\nissn = {1092-6488},\n\njournal = {Metaphor and Symbol},\n\nnumber = {2},\n\npages = {99--119},\n\ntitle = {{Recognizing Verbal Irony in Spontaneous Speech}},\n\nvolume = {17},\n\nyear = {2002}\n\n}\n\n@article{Toplak2000,\n\nabstract = {The studies reported here contrasted the effects of making a criticism directly with that of making it indirectly (via sarcasm). These effects were examined either when the focus was on the person who uttered the criticism (Study 1) or when the focus was on the person to whom the barb is directed (Study 2). Moreover, we studied the beliefs associated with sarcastic uses from four different points-of-view: from that of the speaker, from that of the target of the crit- icism, from that of an incidental overhearer and from a control no-perspective orientation. The main task involved reading a set of passages in which one of the characters criticized another either directly or via sarcasm. Participants completed a questionnaire for each passage about why the criticism was made. A set of reasons discriminated sarcastic from direct criti- cism, with twice as many discriminating reasons being observed when one considers what is in the mind of the person making the sarcastic comment (Study 1) relative to what is in the mind of the person who receives it (Study 2). Factor analyses indicated that many of the seemingly separate reasons reflect a common basis, primarily verbal aggression, though sep- arate factors indicated that verbal aggression made via sarcasm differs in some ways from that when made directly. Finally, there were some differences found in point-of-view, indicating that the effect the speaker believes his criticism has sometimes differs from the effect as seen by the victim.},\n\nauthor = {Toplak, Maggie and Katz, Albert N.},\n\ndoi = {10.1016/S0378-2166(99)00101-0},\n\nfile = {:home/leo/Dropbox/papers/Toplak, Katz - 2000 - On the uses of sarcastic irony.pdf:pdf},\n\nisbn = {0378-2166, Print},\n\nissn = {03782166},\n\njournal = {Journal of Pragmatics},\n\nkeywords = {bibchecked,indirect language,intention,listener interpretation,of canada,perspective,peter denny,pragmatic functions,sarcastic irony,sciences,speaker,the research reported here,was supported by a,we wish to thank},\n\nmendeley-tags = {bibchecked},\n\nmonth = {sep},\n\nnumber = {10},\n\npages = {1467--1488},\n\ntitle = {{On the uses of sarcastic irony}},\n\nurl = {http://linkinghub.elsevier.com/retrieve/pii/S0378216699001010},\n\nvolume = {32},\n\nyear = {2000}\n\n}\n\n@article{Utsumi2000,\n\nabstract = {This paper proposes an implicit display theory of verbal irony in order to provide a plausible explanation of how irony is distinguished from nonirony. The implicit display theory claims that verbal irony is an utterance or a statement that implicitly displays ironic environment, a proper situational setting in the discourse context, and that verbal irony is a prototype-based category. The notion of implicit display provides typicality conditions characterizing the prototype of verbal irony; the similarity between the prototype and an utterance is formulated as the degree of ironicalness. In order for an utterance to be interpreted ironically, the utterance must be recognized as achieving implicit display through the process of assessing the degree of ironicalness, and the discourse situation must be identified as ironic environment through the process of checking or inferring its constituent events/states. If these two criteria are satisfied, the utterance is judged to be ironic, otherwise it is judged to be non-ironic. This paper also argues that the implicit display theory overcomes several difficulties of the existing irony studies and that it is consistent with the empirical findings from psycholinguistics. These arguments indicate that the implicit display theory is a more adequate and comprehensive theory of verbal irony than the traditional pragmatic theory, the echoic interpretation theory, the pretense theory, and other theories.},\n\nauthor = {Utsumi, Akira},\n\ndoi = {10.1016/S0378-2166(99)00116-2},\n\nfile = {:home/leo/Dropbox/papers/jop2000-utsumi.pdf:pdf},\n\nisbn = {0378-2166},\n\nissn = {03782166},\n\njournal = {Journal of Pragmatics},\n\nkeywords = {bibchecked,implicit dis-,ironic environment,nonliteral language,play theory,prototype,psychology of irony,verbal irony},\n\nmendeley-tags = {bibchecked},\n\nnumber = {12},\n\npages = {1777--1806},\n\ntitle = {{Verbal irony as implicit display of ironic environment: Distinguishing ironic utterances from nonirony}},\n\nvolume = {32},\n\nyear = {2000}\n\n}\n\n@article{Jorgensen1996,\n\nabstract = {Brown and Levinson's (1987) theory of politeness, while partly supported by empirical studies, may not accommodate a number of relevant social and psychological variables. Accordingly, Kasper (1990) suggests investigating the 'forms and meanings of politeness' in a variety of discourse and social contexts. Since Brown and Levinson contend that irony may be used for face-saving, and Sperber and Wilson (1981) explain why irony is especially suitable for remarking on the failure of an expectation, the face-saving function of sarcastic irony in American discourse is the focus of this paper. The first study shows that sarcastic irony is typically used to complain to or criticize intimates, who are usually hearers of the remarks. Hearers' reactions to both sarcastic and directly stated remarks with comparable content were explored, and remarks expressing trivial and serious complaints, occurring in conversations between same-sex best friends, were compared. Overall, the results show that sarcasm can serve a face-saving f"
    }
}