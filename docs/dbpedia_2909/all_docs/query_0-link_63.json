{
    "id": "dbpedia_2909_0",
    "rank": 63,
    "data": {
        "url": "https://muse.jhu.edu/article/844162",
        "read_more_link": "",
        "language": "en",
        "title": "Atomic Shocks of the Old: Putting Water at the Center of Nuclear Energy History",
        "top_image": "https://muse.jhu.edu/article/844162/og_image.jpg",
        "meta_img": "https://muse.jhu.edu/article/844162/og_image.jpg",
        "images": [
            "https://muse.jhu.edu/images/institution.png",
            "https://muse.jhu.edu/images/person.png",
            "https://muse.jhu.edu/images/icon_accessibility.png",
            "https://muse.jhu.edu/images/muselogo.png",
            "https://muse.jhu.edu/images/muselogo_notext.png",
            "https://muse.jhu.edu/images/search_blue.png",
            "https://muse.jhu.edu/images/search_blue.png",
            "https://muse.jhu.edu/images/search_blue.png",
            "https://muse.jhu.edu/publisher/1/image/colophon.jpg",
            "https://muse.jhu.edu/images/html_icon.png",
            "https://muse.jhu.edu/images/pdf.png",
            "https://muse.jhu.edu/article/844162/image/fig01?format=thumb",
            "https://muse.jhu.edu/article/844162/image/fig02?format=thumb",
            "https://muse.jhu.edu/article/844162/image/fig03?format=thumb",
            "https://muse.jhu.edu/images/muselogo_notext.png",
            "https://muse.jhu.edu/images/footer_icon_fb.png",
            "https://muse.jhu.edu/images/footer_icon_linkedin.png",
            "https://muse.jhu.edu/images/footer_icon_twitter.png",
            "https://muse.jhu.edu/images/muselogoblack.png",
            "https://muse.jhu.edu/images/muselogo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Per Högselius (bio)",
            "Per Högselius"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Introduction\n\nNuclear energy has long fascinated historians of technology. Over the past fifty years, Technology and Culture has published dozens of articles on the subject, and interest has grown markedly in recent years.1 The literature is intriguing in many ways, but it also features some peculiar paradoxes. One concerns the common argument that the invention of nuclear fission constitutes a radical rupture in world history.2 Nuclear energy and nuclear weapons are portrayed as revolutionary technologies that offered radically new methods to produce electricity, gave rise to previously unimaginable environmental hazards, and forever changed the art of war.3 They are framed as exceptional phenomena with no counterpart in world [End Page 1] history, as Faustian bargains veiled in utopian-dystopian mystery, and with a mythology linked to a few famous physicists and chemists.4\n\nThis exceptionalist narrative is in stark contrast to how nuclear engineers describe their technology. James Mahaffey, for example, claims that a nuclear power plant is \"just another steam engine,\" thus placing it in an engineering tradition that saw its breakthrough during the eighteenth-century Industrial Revolution and whose origins can be traced back to ancient Roman inventiveness. The World Nuclear Association, in a similar vein, argues that nuclear power is just a \"way of boiling water to make steam which drives turbine generators. Except for the reactor, a nuclear power station works like most coal or gas-fired power stations.\"5 Such descriptions are, of course, biased by the nuclear industry's interest in downplaying the spectacular risks linked to nuclear fission. It is, nevertheless, striking that typical schematic representations depict a nuclear power plant as a complex—but not very exceptional—water- and steam-circulating device. There is a missing link somewhere in this story, between the grand narrative of the \"atomic age,\" driven by the latest science-based technologies, and nuclear energy in its concrete, down-to-earth context.\n\nA related paradox is nuclear history scholarship's obsession with reactors.6 The other components that make up a nuclear power plant are generally discussed only in passing, if at all.7 This is a strange bias, because precisely [End Page 2] these components are at the heart of the thousands of pages of operators' reports on nuclear accidents around the world each year. There, we read about pumps that stopped working, water pipes that corroded and leaked, valves accidentally left open or closed, and, beyond the nuclear facility itself, dikes and seawalls that collapsed.8 It seems that these technologies, rather than the reactor, would need to be at the center of our analysis if we are properly to grasp the history of nuclear (un)safety.\n\nThese paradoxes pose two major challenges for nuclear historians. The first is to seriously disentangle how nuclear energy combines \"old\" and \"new\" technologies, \"complex\" and \"simple\" systems, \"high-tech\" and \"low-tech.\" Scholars like David Edgerton provide inspiration by claiming that historians of technology are generally too obsessed with high-tech, complex, and \"new\" technologies at the unfortunate expense of everything else. Edgerton favors an alternative history where \"technology-in-use\" rather than \"invention\" and \"innovation\" takes center stage. Such a history would necessarily gravitate toward artefacts and systems that are not necessarily \"new.\"9 In the case of nuclear energy, this translates into a need to explore the \"everyday lives\" of nuclear power plants, not just their making and unmaking. Another recent strand of relevant research looks at maintenance and repair.10 Indeed, the career of many a nuclear power plant could be described as a sequence of attempts to fix problems, deal with unexpected incidents, and control aging systems.\n\nEdgerton notes that in use-centered histories, technologies \"mix and match across the centuries.\"11 This \"messy hybridization\" of old and new technologies, as I propose to call it, becomes particularly intriguing if analyzed in relation to the social and historical study of risk. If a nuclear plant comprises components and systems that are both \"old\" and \"new,\" it will have inevitably inherited old, well-known vulnerabilities and risky practices—past weaknesses in, say, the construction of pipes or dikes—and new, less well-known ones linked to nuclear fission and radioactivity. The systemic nature of any nuclear plant and its tightly coupled subsystems, as analyzed most strikingly by Charles Perrow, ensures that the old and the new risks interact on a daily basis.12 As I will argue, the \"old\" nuclear risks can be traced back centuries and even millennia, and I contend that they are mainly linked to human experiences in water management and hydraulic engineering. [End Page 3]\n\nThe second challenge is to carefully unpack the \"wet\" nature of nuclear energy. Here, historians of nuclear energy have a lot to learn from water and environmental historians. Water history is very much the study of organizational and technological attempts to manage, manipulate, and control water flows—activities that, as the technical literature on nuclear accidents suggests, are equally central to nuclear energy. Moreover, water history is often about risk. As a matter of fact, most nuclear risks can be considered water risks. This article shows that we may even fruitfully borrow terms such as \"droughts\" and \"floods\" from water history when analyzing core meltdowns and other nuclear accidents.13 Water historians also teach us that water users—from farms and households to cities and industries—are important to analyze as part of geographically wider wet environments. Scholars like Richard White, Marc Cioc, and, in particular, Sara Pritchard have shown the value of integrating nuclear facilities as large-scale water users into such wider analyses.14 Pritchard suggests considering nuclear power plants as part of spatially large \"envirotechnical systems,\" which she defines as a conceptual extension of Hughesian Large Technical Systems.15 From this perspective, a nuclear facility does not end at the reactor containment, or in the turbine hall, or at the fences delimiting the plant area; as a \"wet\" system, it reaches far beyond the plant, extending along coasts and rivers and—taking into account the nuclear fuel cycle—to distant countries where uranium is mined and processed and nuclear waste stored. Plant operators and owners do their best to downplay the \"nuclearity,\" to use Gabrielle Hecht's concept, of the wider region where a nuclear plant is located, but this should not stop us from exploring the \"far reaches\" of these facilities.16 [End Page 4]\n\nIn relation to these considerations, and taking inspiration from ongoing attempts to synthesize the history of technology, environmental history, and science and technology studies, we may usefully theorize the history of nuclear energy not only as the \"messy hybridization\" of old and new technologies but also as a development that \"coproduces\" technology and nature.17 Environmental factors such as the availability of water constrain nuclear energy's range of technological forms, thus strongly influencing engineering decisions. But once in place, nuclear facilities also transform the environment through radioactive contamination, thermal pollution, local climate change, visual changes to the landscape, and so on. Such environmental transformations may in turn trigger adaptations in the technology or spark social and political processes that lead to its abandonment. Into such a coproduction framework, it is also logical to integrate \"nature's agency,\" a popular notion in the environmental history community, since storms, droughts, floods, earthquakes, pollution, erosion, and climate change trigger technological innovations aimed at enhancing safety.18\n\nThe remainder of this article develops these themes further and reexamines the history of nuclear power and nuclear accidents as a history of water, water-manipulating technologies, water-related risks, and wet landscapes. It argues that the crucial importance of large-scale uninterrupted water flows to cool nuclear reactor cores, and the need to simultaneously protect nuclear facilities from flooding and contaminating their wet surroundings, turned nuclear engineers into a category of hydraulic engineers. What some call the \"atomic age\" is fundamentally a hydraulic age, and as such it draws heavily on—and has to be understood in relation to—the experiences of past water-manipulating societies. These historical affinities become particularly visible in times of crisis. [End Page 5]\n\nThe Rise of Nuclear Hydraulic Engineering\n\nWater was at the heart of nuclear engineering projects long before they produced energy. The first nonexperimental reactor ever built, the B Reactor at Hanford in the state of Washington, served plutonium production for the Manhattan Project. It also generated unwanted heat, a huge headache for Colonel Franklin Mathias and DuPont, the chemical company in charge of construction. To dissipate the heat, engineers designed a cooling system centered on 2,004 metal pipes. Uranium slugs were inserted into the pipes, and the heat emitted by the slugs was then removed by cold water pumped through the pipes from the adjacent Columbia River. Failure to cool the slugs would have been disastrous. The heat would have caused them to melt, setting in motion a chain of events that could have ended with radioactive contamination of the entire region. The welds on the pipes thus had to be perfect—no leaks could be tolerated. Against this background it is hardly surprising that a shortage of qualified welders was \"the most severe problem\" during construction. A shortage of pipefitters likewise held up work critically.19\n\nLater nuclear plants did not rely on the primitive single-circuit cooling system at Hanford, one reason being that copious amounts of radioactivity inevitably leaked into the environment following direct contact between river water and uranium fuel. The first civilian reactor models in the 1950s and 1960s included at least two interlinked cooling systems: a primary system, where the coolant circulated in a closed, isolated loop, heated directly by nuclear fission; and a secondary system, where the primary coolant was cooled by another coolant in an open loop, thus interacting with the natural environment. Some reactor systems—including pressurized water reactors, which became very popular over time—even included a tertiary cooling system.20\n\nStandard accounts on nuclear energy history feature an impressive range of \"light-water reactors,\" \"heavy-water reactors,\" \"gas-cooled reactors,\" and \"sodium-cooled reactors.\" These labels are partly misleading, because reactor builders could only choose between coolants for the closed, primary loop. In the secondary (or tertiary) system, which needed much larger volumes of coolant, plain water was the only available option, for the simple reason that no other material with the desired properties could be mobilized at a reasonable cost.21 In this sense, all nuclear power plants were water-cooled. Britain's Magnox reactors used carbon dioxide as their primary coolant and plain water as their secondary coolant; the fast [End Page 6] breeder reactor prototypes of the 1960s relied on two loops of liquid sodium for primary and secondary cooling, but plain water for cooling these two circuits in a tertiary system. Canadian CANDU reactors used heavy water as their primary coolant, combined with plain water in their secondary and tertiary cooling loops.22\n\nThe amounts of water needed for cooling were modest in the pilot projects but increased dramatically once plants were scaled up from around 1965. Volumes varied from plant to plant, but a large reactor needed several dozen cubic meters of water per second. The small U.S. (581 MWe) Ginna nuclear power plant required 22 cubic meters (6,000 gallons) of water per second, whereas two larger reactors at Calvert Cliffs each required 75 cubic meters (20,000 gallons) per second. The two 970 MWe reactors at South Africa's only nuclear power station at Koeberg, near Cape Town, required 40 cubic meters per second.23 Given such massive cooling requirements, it is hardly surprising that virtually all nuclear power plants were built in the immediate vicinity of large bodies of water: rivers, lakes, and especially seas. All large-scale nuclear power plants in Japan, China, South Korea, Taiwan, Britain, Sweden, Finland, and East Germany were built on the coast. Likewise, a string of nuclear facilities dotted France's and India's coasts. Some plants, like East Germany's Greifswald and Britain's Hartlepool station, were next to popular seaside resorts. Others featured in the background of windsurfing competitions, like at California's San Onofre plant. Salty seawater is problematic owing to the risk of corrosion. But since nuclear energy's water needs are so colossal and the sea is generally colder than inland waters, nuclear builders have always opted for seaside locations whenever available. No other category of power plants has ever favored seaside locations to this extent (see figure 1).\n\nIt is interesting to follow the historical-geographical trajectories of nuclear siting worldwide. Early reactors were small, built for research and experimental purposes, and only needed negligible, if any, volumes of external cooling water. They were in urban settings and in convenient proximity to institutions conducting nuclear research such as in Chicago, Montreal, Moscow, and Stockholm. When the scale of plants grew and electricity production became more important, however, the facilities moved to sites with ample volumes of water. In Britain, the military reactors at Calder Hall (England) and Chapelcross (Scotland) were inland. The next were built on the banks of the Severn estuary, and all subsequent plants were built on the coast. Following a similar trajectory, Sweden built [End Page 7]\n\nClick for larger view\n\nView full resolution\n\nits first electricity-producing reactor, the Ågesta nuclear power plant, on a small lake in Stockholm's southern suburbs, but likewise preferred coastal locations for all subsequent projects. China's nuclear history started in landlocked Beijing before moving to the coast.24\n\nNot all states with nuclear ambitions have had access to coastal locations, however. Hence, inland waters also became crucial components in the global geography of nuclear energy. Many of the industrialized world's rivers underwent rapid nuclearization between the 1960s and the 1980s. In the United States, the Mississippi and its tributaries saw the arrival of nuclear builders early on, as did the Susquehanna and smaller East Coast rivers. In the Soviet Union, the Don, Dnieper, and Volga basins were exploited. In Western Europe, the Rhine emerged as a nuclear mecca, as Swiss, German, French, and Dutch power companies planned several dozen plants along the main river and its tributaries. France also turned to the Rhône, as Sara Pritchard has detailed, and to the Loire basin. Italy harnessed the Po. Other rivers subjected to far-reaching nuclearization included [End Page 8] the multinational Danube and Elbe, whose cooling potential captured the imagination of nuclear engineers on both sides of the Iron Curtain.25\n\nLakeside locations were no less popular. Ninety-five percent of Canada's nuclear energy is currently generated on the Great Lakes. The Great Lakes additionally supply fourteen U.S. reactors with cooling water.26 And if lakes were not available, they could be constructed. Numerous American and Soviet—and also Spanish—nuclear builders used artificial lakes and ponds supported by dams, weirs, and levees in (or linked to) a river. Such lakes became popular recreational areas, featuring activities like sailing, canoeing, hiking, picnicking, camping, swimming, waterskiing, fishing, and hunting.27\n\nTo harness the atom, then, was to tap into wet landscapes. Micro-engineering at the levels of atoms and nuclei was enabled by macro-engineering that manipulated large-scale water flows. Seas, lakes, and rivers became intrinsically part of the world's nuclear facilities—just like a river, as Heidegger famously asserted, was always intrinsically part of the hydropower plants built within it.28 Technology was intensely coproduced with nature, and this guaranteed a safely operating reactor. As long as the cooling water kept on flowing, there could be no core meltdown.\n\nThe key technologies ensuring proper cooling included canals and dams, pumps and pipes, pressurizers and condensers, and other artefacts that had little to do with reactor physics. Seawalls and dikes, erected to protect facilities from flooding disasters, added to the \"wet\" technological ensemble. Water pumps were a particularly critical technology. In the primary cooling system, nuclear engineers could rely on the natural circulation of the coolant up to electrical effects of 100 MW, but beyond that, enforced circulation, dependent on powerful pumps, was necessary. The circulation pumps were supplied by specialized engineering firms. The British company Hayward Tyler became the dominant pump supplier to [End Page 9] nuclear power plants across Western Europe. Canal-building was equally critical. As the size of reactors grew, nuclear plant builders constructed ever larger canals, interconnecting the designated water supply source with the turbine building, and an impressive wastewater infrastructure for the discharged—now significantly warmer—cooling water. Swedish plant builder Vattenfall, mobilizing its expertise in hydroelectric construction, even built subterranean tunnels.29\n\nMany of these systems were based on centuries and even millennia of hydraulic engineering efforts worldwide. Culturally speaking, they originated in earlier civilizations whose prosperity depended on water control—from ancient Egypt to the modern Netherlands. Nuclear hydraulic engineering built directly on insights and scientific advancements during the European Renaissance, when scientists started measuring water flows and theorizing in new ways about the circulation of water in larger hydrological systems. It linked up with water storage and water withdrawal technologies developed for agricultural and industrial needs. And, last but not least, it utilized the same steam and piping technologies that had emerged during the Industrial Revolution.30\n\nAs a matter of fact, the challenges that nuclear hydraulic engineers faced were no different in principle from those their nonnuclear peers had been tackling for thousands of years: mobilizing water supplies, preventing the disruption of flows, coping with water scarcity, ensuring flood protection, and managing wet pollution. Paraphrasing David Edgerton, we may refer to these deeper historical continuities in nuclear energy development as \"atomic shocks of the old.\" Alternatively, we may argue, with Lewis Mumford, that the experiences of earlier water-intensive societies constituted the \"cultural preparation\" necessary for the spectacular breakthrough of the atomic age.31\n\nThe Fear of External Water Shortages\n\nThe history of water and hydraulic engineering features countless stories of crisis and disaster—be it in the form of droughts, floods, or pollution. From China's mythical first emperor, Yu the Great, to the famous Dutch water agency Rijkswaterstaat, hydraulic engineers constantly had to cope with multiple risks and vulnerabilities. What, then, happened when these risks and vulnerabilities from a deeper past carried on into the [End Page 10] nuclear age—when the potential consequences of failure were of a totally different magnitude and type?\n\nLet us first look at the fear of what I will call \"nuclear droughts.\" If a nuclear power plant's chief engineer lies awake all night, the reason is probably the same as for her ancestors who designed a wet rice plantation in ancient China, a water-powered textile mill in the Industrial Revolution, or an early twentieth-century coal power plant: she knows there is a risk that water will not be available when it is most direly needed. In each case, water might be unavailable for external reasons, such as a severe drought in a river, or for internal reasons, when a dam, dike, pump, pipe, valve, or any other part of the hydraulic machinery breaks or fails.32\n\nWhat makes nuclear power unique, however, is that the flow of water must continue at all times. Not even a minute of interrupted supply can be tolerated, because the nuclear fuel will then start to heat up in a dangerous way. While water shortages can certainly cause much trouble in nonnuclear contexts, there is no counterpart to a core meltdown in rice fields or textile mills, nor in a modern coal power plant. Most worryingly, even a reactor that has been shut down will continue to produce large volumes of heat for many days, due to processes of unstoppable radioactive decay. If, during this period, the flow of cold water is disrupted, the situation will gradually become dangerous. After a few hours, the reactor core will start melting. Suddenly an entire landscape or region will be under threat of becoming uninhabitable for the foreseeable future. The only way to prevent such a horror scenario is to ensure that water is always available and that the supply is not disrupted.33\n\nNuclear hydraulic engineers responded to this challenge in different ways. Regarding the threat of external nuclear droughts, the siting of plants was key. The safest way to avoid external nuclear droughts was to pick sites near the sea or large lakes, where there was no conceivable risk of the water somehow disappearing. In the absence of coastal sites, inland waterways had to suffice, but not all of these were deemed fit for the nuclear age. The size of the river was not necessarily the decisive factor, as evidenced by the siting of large-scale nuclear plants on small rivers such as the Moselle and the Aare (see figure 2). Instead, as Sara Pritchard has shown with the Rhône, nuclear builders needed rivers providing a steady and predictable flow of water.34 In practice, this requirement translated into rivers that had undergone far-reaching \"improvement\" in the past, in the form of rectification, [End Page 11]\n\nClick for larger view\n\nView full resolution\n\ndiking, dredging, and damming. Nuclear hydraulic engineers eagerly exploited these feats of their nonnuclear predecessors. It is no coincidence that the world's main nuclearized rivers also feature prominently in histories of river regulation. The Upper Rhine, for example, is not only a heavily nuclearized river but also an iconic landscape in water history: it was here that Johann Gottfried Tulla famously pioneered his ground-breaking new approach to river rectification in the early nineteenth century. Two catastrophic floods in 1840 and 1856 sparked similar developments with the Rhône. In the United States, several large nuclear plants, including the infamous Three Mile Island station, were built along the Susquehanna River, whose \"particular geology and variable water flows,\" as Christopher Jones writes, had caused much trouble for those trying to use it for transport or power. \"During the spring melt, the river often rose significantly and flooded. During the dry season in late summer and early fall, the great river was frequently reduced to a trickle.\" In the early twentieth century, hydroelectric companies \"tamed\" the wild river by damming it at several locations, producing a much more regular flow. This prepared the Susquehanna for its later role in the atomic age.35 Siting decisions aside, the fear of external water shortage found expression in the artificial nuclear [End Page 12] lakes or ponds mentioned in the preceding section. These provided ample backup capacity and hence reduced the risk of nuclear drought—and, by extension, core meltdowns. The idea of storing water dated back to ancient hydraulic societies; in dry regions such as Mesopotamia, large-scale water reservoirs often played existential roles by reducing the risk of famine. Water storage was also key in early water-powered industrialization, ensuring that the factory wheels would not grind to a halt when a river's water level changed. From the late nineteenth century, reservoir technology advanced to hydroelectric dam construction.36\n\nNuclear hydraulic engineers took inspiration from these traditions. Given the immense amount of water required, however, nuclear water reservoirs had to be exceptionally large, covering many square kilometers. Thus, they could only be built in areas where large tracts of (cheap, and preferably uninhabited) land were available. Notably in Spain and the Soviet Union, cooling ponds also played an important role in nonnuclear water supply, as dammed nuclear ponds were equipped with hydroelectric facilities and supplied water for large-scale irrigation. This practice forms a fascinating—and contested—part of the coproduction of technology and nature in nuclear energy history. Spanish farmers protested vehemently against the entanglement between nuclear energy and agriculture, because they did not think that the water in the reservoirs would be enough for both nuclear cooling and irrigation.37\n\nWhere ponds were not a realistic option, nuclear hydraulic engineers built cooling towers. These turned the ancient technology of water storage into distinctly modern artefacts that radically altered the visual appearance of the nuclear power plant and the surrounding landscape. Like a nuclear pond, a cooling tower reduced—but did not eliminate—the plant's dependence on continuous external water supplies.38 Often cooling towers were regarded as an essential investment, given the rapidly growing demand for cooling and fierce competition for scarce water resources. In 1968, the U.S. Senate's Public Works Committee noted that in certain heavily populated and industrialized northeastern U.S. watersheds, \"100 percent of available flows may be passed through the various power-generating stations within the watersheds during low-flow periods!\"39 The situation was not much [End Page 13] better along the Rhine in Western Europe. In 1970, a group of German experts calculated that, in order to accommodate all proposed nuclear stations, \"we will need two Rhines for cooling in the 1970s and four additional ones in the 1980s\"—all told, a total of six Rhines! Cooling towers were seen as suitable technical fixes, as they promised to radically reduce the need for water withdrawals. In addition, engineers viewed them as a solution to the growing problem of \"thermal pollution.\"40\n\nCooling towers and ponds were usually built at continental nuclear sites only, such as in the interior of the United States, France, Switzerland, and Germany. Coastal locations provided so much natural cooling water that external droughts of any kind seemed impossible and unimaginable. For this reason, coastal plants looked completely different. There was no \"smoke,\" and a typical coastal nuclear power plant looked more like an electronics factory, a warehouse, or perhaps most of all a temple, a sacred place far from everything, than an energy production site. The plant dominated the surrounding landscape, as British architect James Munce noted in 1964, \"embracing the countryside as the great Gothic Cathedrals embraced the towns.\" The architecture provided a sense of mysterious pride, often with nationalist overtones.41\n\nIn the twenty-first century, however, things have changed. The trend is now toward building cooling towers, even at seaside sites. Although seawater might be available in the desired quantities, water quality cannot be guaranteed. In 2013, Finnish nuclear operator Fortum announced a new investment program at its Loviisa plant, centering on the construction of cooling towers to \"improve safety in extreme conditions when seawater becomes unavailable for cooling, such as an oil catastrophe in the Gulf of Finland, or an exceptional natural phenomenon such as excessive algae growth.\"42 On the other side of the Finnish Gulf, Russian nuclear agency Rosatom likewise set out to build cooling towers at its Sosnovy Bor site. Typical for the coproduction of technology and nature, water-related environmental problems that at first glance appeared totally unrelated to nuclear power were increasingly framed as risks in the context of nuclear safety.\n\nEven without pollution, nuclear water supplies caused troubles. Over the years, many plants faced huge problems with excessive silt, seaweed, [End Page 14] kelp, and fish getting into their cooling systems.43 Such events repeatedly forced operators to shut down entire plants and declare an emergency. In April 2003, staff at Cook nuclear power plant discovered that alewives—a species of herring—were intruding on a massive scale from Lake Michigan. Large volumes of fish were sucked into the cooling system. The staff responded by \"scramming\" the plant's two reactors, but the situation was still dangerous, because the fish had also blocked the cooling water flow to the emergency diesel generators. In other words, if an electricity blackout had occurred at this time, the feedwater pumps would almost certainly have come to a halt and a core meltdown might have occurred. Similar events were reported along the Rhône in France that summer, as \"large amounts of mud and plant debris impaired the cooling systems\" at the Cruas and Tricastin plants, triggering emergency plans and reactor shutdowns. These are striking cases of nature's agency in the history of nuclear energy.44\n\nInternal Nuclear Droughts\n\nNuclear hydraulic engineers devoted a lot of effort to coping with the risk of not only external but also internal nuclear droughts. Here the key methods relied on a messy hybridization of old and new risk management practices. While external nuclear drought approaches took inspiration from ancient water storage and pre-nuclear river reengineering projects, internal nuclear drought management built on historical practices in thermal-hydraulic engineering and, in particular, earlier experiences with steam engine and coal power plant operations.\n\nEarly on, regulating agencies set out to ensure that nuclear power plant builders adhered to existing thermal-hydraulic safety standards, that is to say, standards developed for pre-nuclear thermal-hydraulic installations. Reactor pressure vessels needed to be strong enough. There was ample evidence from two centuries of steam engine operations that drought-like conditions inside a boiler could cause it to rupture and explode.45 In response to this dramatic risk, the American Society for Mechanical Engineers had created the influential Boiler and Pressure Vessel Code back in 1914. When Westinghouse, General Electric, and other manufacturers set out to design civilian nuclear reactors in the 1950s, regulators made this document the basis for nuclear power plant inspections, and so the Code carried on into the nuclear age.46 The Code was quickly adopted in Canada, [End Page 15] and from the 1960s it accompanied the export of light-water reactors from the United States to other countries. There, state or private agencies in charge of inspecting old steam boilers—like the Corps des Mines in France or the regional Technische Überwachungsvereine in Germany—took on the inspection of nuclear technology. However, growing insights into the effects of radiation on pressure vessels soon led to conflicts, especially in France, over whether a more specific nuclear pressure vessel code was needed. Ultimately, as Siegfried Evens has recently shown, \"nuclear safety codes, legislation, and guidebooks became a hybrid of measures specifically directed towards the risks of radiation on the one hand, and older laws or regulations for preventing steam explosions on the other.\"47\n\nAnother risk strategy was based on the traditional engineering notion of a \"design basis accident\": the maximum breakdown or technological failure that a technical system was designed to withstand. In the nuclear age, this old concept metamorphosed into something called the Maximum Credible Accident, a contentious term that became subject to much debate over the years, especially in Germany. The catastrophic bursting of a reactor pressure vessel was not taken into consideration, despite the fact that it might well happen. Instead, once the U.S. Atomic Energy Commission started elaborating on the Maximum Credible Accident concept in 1959, it became synonymous with a serious malfunction of the primary cooling system and, in particular, the rupture of a main primary coolant pipe. More broadly, the nuclear industry started discussing the possibility of various \"loss of coolant accidents\" (\"LOCAs\"). In response to the threat of such internal droughts, nuclear hydraulic engineers offered the technical fix of an \"emergency cooling system\"—an independent system of water pumps, pipes, and valves that would (hopefully) come to the rescue in case of a LOCA. This emergency system, with no counterpart in pre-nuclear hydraulic engineering, was soon recognized as a main guarantor of nuclear safety.48\n\nAt the same time, there was much emphasis on ensuring that the regular water pumps would under no circumstances come to a standstill. The main vulnerability was the pumps' dependence on a steady electricity supply. Engineers and operators needed to make sure that electricity would be available even in the case of an external electricity blackout. Most nuclear facilities relied on backup electricity supply in the form of diesel-fueled generators. As the case of Chernobyl showed, this was not a straightforward solution. Soviet nuclear hydraulic engineers knew it would take up to 90 seconds for the diesel generators to reach full power for Chernobyl-type reactors, a delay they recognized as a serious security risk. Aiming to eliminate this risk, they came up with the idea that the rotational inertia of a spinning (but electrically disconnected) turbine could restore internal [End Page 16] power for the pumps. \"In a design basis accident, involving total loss of power for the unit's internal requirements, cooling water is fed to the damaged part by feedwater pumps powered by the turbogenerator rundown,\" the engineers explained. In April 1986, the Soviets were ready to test this emergency solution.49\n\nWe know how that test ended. Rather than solving safety problems with the reactor, the experiment ended up posing totally new challenges for the engineers and operators in charge regarding the interaction between the nuclear fuel, the graphite moderator, and the cooling water. The reactor overheated, and the entire reactor vessel exploded, unable to withstand the pressure of the excessive steam.50\n\nWhen probabilistic risk analysis gained traction in the 1970s, attention shifted from the Maximum Credible Accident to the potential failure of smaller components. These included, in particular, the myriad pipes and valves that kept the water (and steam) flowing under the correct pressure, at the right speed, and in the right direction. Probabilistic risk analysis had a fresh, new research image and close ties with the U.S. space program. However, this modern image did not prevent risk analysts from making ample use of historical data. While assessing the probability that pipes and valves in a nuclear plant fail, they discovered they could draw on the long experience of failures in older, nonnuclear thermal-hydraulic systems, notably in coal power plants. This was good news because the historical records enabled them to achieve surprisingly accurate probability estimates. There was also some bad news: the history of coal power plants showed that valve and pipe failures were extremely common. It seemed impossible to eliminate them. Unsurprisingly, this turned out to be the case in nuclear facilities too.51\n\nPipes and valves—seemingly simple, mundane technologies—thus feature throughout reports about nuclear accidents and incidents. The 1979 Three Mile Island accident in Pennsylvania, as Charles Perrow noted in Normal Accidents, was caused by two valves \"accidentally left in a closed position.\" At the Browns Ferry plant in Alabama, the opposite occurred in 1984: a valve that was supposed to be closed was left open. This led to elevated pressure inside some water pipes. \"Had the piping broken, it would have opened a large hole for water to drain from the reactor vessel, while at the same time depriving the plant of a primary means of refilling the reactor vessel with water.\" In other words, a nuclear drought would have [End Page 17] occurred. Other incidents involving valves occurred at Oyster Creek and Dresden (both in 1985), and again at Oyster Creek in 1996.52\n\nThe many miles of pipes in large-scale plants were also vulnerable. The Electric Power Research Institute reported no fewer than 4,064 piping failures in U.S. nuclear power plants between 1961 and 1997, equating to about two piping failures per week. In half the cases, the problematic pipe was identified before it burst. But in 2,247 cases, the piping failure resulted in water leakages, often with far-reaching consequences for the plant's safety. Conventional power plants and steam engines could often tolerate a pipe failure. Not so in the nuclear industry, where it might jeopardize reactor safety and cause radioactive contamination. In September 1974, all boiling water reactors in the United States had to be shut down owing to concerns over pipe ruptures. This shifted the entire debate toward a preference for pressurized water reactors over boiling water reactors. Yet as the statistics clearly indicate, pressurized water reactor pipes were also prone to failure. Common reasons for pipe failures were corrosion, erosion, construction and design errors, and fatigue. Sooner or later all pipes had to be replaced, as their metal walls thin out over time, but this happened much more quickly than anticipated.53\n\nCoping with Nuclear Floods\n\nGoing from one extreme to another, nuclear hydraulic engineers faced the challenge of not just insufficient water but also too much water. Like nuclear droughts, \"nuclear floods,\" as I propose to call them, were historically either internal or external. Internal floods are caused by leaking equipment in the nuclear power plant. Such events are closely related to some of the internal drought-related problems discussed in the preceding section. A pipe rupture may, as we have seen, cause a nuclear drought, but it may also cause an internal flooding event. Examples include events at the Quad Cities plant in 1972 and Three Mile Island in 1977 (two years before its more iconic accident), both involving condenser circulating water systems, then at the Surry plant in 1975 and 1977, and at East Hatch in 1978, where malfunctioning service water valves caused floods.54 Operators feared such incidents because the internal flood waters threatened to destroy electric and electronic equipment. Moreover, since the water usually flowed through the pipes at very high pressures and temperatures, it often [End Page 18] flashed to steam when a pipe burst—accidents that over the years killed many employees and destroyed critical components.55\n\nMoreover, if water leaked from the primary cooling system, it was inevitably radioactive. Such an accident occurred at Canada's Chalk River NRX experimental reactor in 1952. In what has been dubbed \"the world's first core meltdown,\" the basement of the reactor building \"filled with one million gallons of water containing 10,000 curies of various radioactive fission products.\" To remove them, plant workers and Canadian military personnel built a pipeline leading to \"a flat sandy area about a mile from the plant, and the heavily contaminated coolant out of the basement was pumped there and allowed to seep up into the ground, where it apparently disappeared.\"56 Needless to say, the fear that radioactive waters from leaking nuclear power plants will contaminate the environment is a recurring theme in the history of nuclear energy.\n\nConcerning external nuclear floods, it is important to bear in mind the most basic feature of global nuclear geography: all nuclear power plants are located near seas, rivers, or large lakes, which guarantee external access to cooling water.57 As a direct but unintended consequence, the sites have become disproportionally vulnerable to flooding. Violent storms, tsunamis, high tides, and rising sea levels have repeatedly jeopardized nuclear safety. The key technology for countering such external nuclear floods is many thousand years old: it takes the form of dikes and levees—and, if need be, sandbags—designed to protect the plant against rising waters. These technologies are, of course, well established and mature in every way. Yet they have failed on numerous occasions. A worrying but not necessarily surprising fact, given ongoing global warming and rising sea levels, is that the failures have become more common over time. A 2012 British government report stated that twelve of its nineteen civil nuclear sites would be at risk of flooding by the 2080s. One of the twelve sites is Hinkley Point, where a new reactor block is currently under construction.58\n\nOne of the most breathtaking nuclear floods occurred during an Atlantic winter storm on December 27, 1999. The date is, of course, not without apocalyptic significance. At risk was the Blayais nuclear power plant in France, located in the Gironde estuary downstream from Bordeaux. The [End Page 19] plant was surrounded by a system of dikes made of earth, partly protected by piles of rocks. A breach in the dikes led to flooding of the site: \"The waves moved the rocks protecting the dike, and part of it was washed away alongside the River Gironde.\" Electricity connections to the plant were destroyed, and several safety systems stopped working, including \"the two low-head safety injection pumps and the containment spray pumps. The pumps were deemed by the operator to be totally unavailable.\"59 Most seriously, one of two pumps supplying the cooling system with seawater failed at the same time as the flood knocked out the emergency cooling system.60 Nature's agency and the messy hybridization of old and new technologies—earthen dikes, electricity lines, protective rocks, safety injection pumps, and so on—jeopardized nuclear safety.\n\nIn the United States, flooding became a problem especially along the Mississippi and the Missouri and their nuclearized tributaries. For several weeks in June and July 2011, the Missouri rose so high that the Cooper plant in Nebraska was forced into lengthy emergency status. Measures to cope with the crisis included \"strategic placement of sandbags at building entrances and important facilities.\" The Fort Calhoun plant, situated 150 km upstream north of Omaha, suffered even worse consequences. It was surrounded by the floodwaters. Flood protection measures were rudimentary and relied on a temporary levee in the form of \"an 8 feet (2.4 m) high and 2,000 feet (610 m) long rubber berm\" surrounding the reactor building. However, the berm collapsed after a few days, and water entered some of the buildings. Luckily the plant had been shut down two months previously for refueling, so there was no risk of the flood causing a core meltdown. Yet operators worried about decay heat from a pool containing spent nuclear fuel.61\n\nThe Fukushima disaster in Japan ended less happily. The Fukushima Daiichi nuclear power plant was protected by 5.7-meter-high seawalls (see figure 3). That might sound impressive, but they were 10 meters too low for the tsunami on March 11, 2011. The plant's electricity supply failed, and since the emergency diesel generators were also flooded, they could not be started up. Consequently, the water pumps could no longer supply the cores of several reactors with cold water. The nuclear flood turned into a nuclear drought.62\n\nHow could operators allow events like these to overwhelm their facilities [End Page 20]\n\nClick for larger view\n\nView full resolution\n\ngiven centuries and millennia of experiences in the field of dike construction and flood protection? Had nuclear energy's dike builders not learned anything from their peers in nonnuclear days? At Blayais, there were historical records of 213 floods between the years 585 and 1900—many of them more severe than the 1999 event—which lived on in collective memory. It was well known what could happen. Whereas the 1999 flood reached 5.3 meters above sea level, several known instances of floods reached 8–12 meters. In the Fukushima case, analyses (carried out long before the accident) of the terrible 1896 Sanriku earthquake's impact made clear that tsunamis of immense heights (up to 38 meters!) could be expected—albeit only extremely rarely. Yet neither of the nuclear operators, EDF and TEPCO, had constructed taller dikes. At Fukushima, the \"design maximum height\" was originally defined at 3.1 meters, based on a 1960 tsunami experience. A revision in 2002 raised the level to 5.7 meters, based on new numerical simulations of the potential impact of an earthquake and tsunami on a par with events off Fukushima in 1938. The possibility of even higher waves, such as registered further north in 1896, was not deemed relevant for the stretch of coast at Fukushima.63 [End Page 21]\n\nNumerous analysts have tried to understand what happened—and why—at Blayais, Fukushima, Fort Calhoun, and elsewhere. Common explanations range from technical design flaws to weak government oversight.64 One thing is clear, however: throughout history, hydraulic engineers have discussed flood management in terms of the (un)likelihood of rare events. Some floods are very common. The most severe—including the worst tsunamis—occur once every century, millennium, or ten thousand years. The \"hundred-year flood\" is a common concept in water and flood protection history, along with the even rarer \"thousand-year flood.\" For millennia there has been a strong consensus among dike builders that you cannot protect yourself against everything. They agree that a hundred-year or thousand-year flood is such a rare phenomenon that the destruction it causes has to be accepted. Residents in the affected region will certainly be shocked to find their houses and infrastructure destroyed, and restoring them is a considerable expense; however, since it is such a rare, exceptional event, the outcome can be tolerated. It is this thinking that has historically determined how tall a dike should be, for example, along the Yellow River in China, the Rhine in Germany, the Missouri in America, or the Dutch and Belgian coast in Atlantic Europe.65\n\nThe consensus in the nuclear age was clearly that a nuclear accident with widespread radioactive contamination could never be allowed to happen—not even once every hundred or thousand years. The stakes were too high. Residents in an affected area would not be able to start rebuilding their demolished houses soon after a storm's destruction of a nuclear power plant in their neighborhood. Their region might remain uninhabitable for the foreseeable future. The \"potential seriousness of the failure of a nuclear power plant,\" as one hydraulic engineer stated, meant that the traditional focus on \"frequency analysis\" had to be modified.66\n\nThe U.S. Army Corps of Engineers suggested basing nuclear siting and design decisions on the \"probable maximum flood\" concept, defined as a hypothetical flood produced by \"the most severe combination of hydrometeorological and/or seismic parameters reasonably possible for a particular location.\"67 The calculations proved more difficult than expected and [End Page 22] irritatingly uncertain, however, especially when the task was to assess the probability and combination of events for which there were no historical records. Moreover, while hydrologists emphasized the possibility of very rare, extreme flooding hazards, nuclear plant builders criticized the \"probable maximum\" approach for being \"unduly conservative,\" as General Electric's nuclear safety experts argued in 1973. \"Such conservatism restricts otherwise acceptable sites and is not in the overall public interest.\" Similarly, Fukushima operator TEPCO did not consider an offshore earthquake with a magnitude higher than 9, such as the one that caused the 2011 tsunami, \"a credible event in the Japan Trench.\"68\n\nIt was perhaps inevitable that not all worst-case scenarios were considered in siting decisions and flood mitigation plans. Not only would plant construction become excessively expensive, but also not one geographical site might be suitable and no technical equipment good enough to deal with hazards that, from a statistics viewpoint, were so rare that few people could imagine them happening. Hence, nuclear builders did precisely what their nonnuclear predecessors had always done: they protected their plants against everything except the most severe floods. Just like dike builders in the past, they reasoned that the possibility of an extreme flood, which in the atomic age might cause a full-scale nuclear disaster, would have to be accepted.69\n\nThe nuclear floods at Blayais and Fukushima inspired regulatory agencies and hydraulic engineers globally to rethink flood protection strategies and reengineer their nuclear facilities. The extreme floods made it more difficult to argue that protection against the rarest hazards was unnecessary. In Germany, where four nuclear power plants had been erected along estuaries resembling the Gironde, the Federal Office for Radiation Protection set out to examine the deeper flood history of the North Sea. It concluded that the German facilities must be able to withstand the onslaught of an external hazard on a par with the famous Storegga slide, a submarine landslide off the coast of what is now Norway; it occurred around 6200 BC and is believed to have caused an extreme tsunami in the North Sea region.70\n\nAt Blayais, operator EDF decided to raise the dikes from 5 to 8 meters. Needless to say, demands for strengthened flood mitigation measures were even stronger in the aftermath of the Fukushima disaster. Physical improvements to power plants worldwide ranged from strengthening dikes and providing more sandbags to installing \"flood resistant doors.\" Decision-makers in some countries, however, notably Germany, concluded that no technical fixes would suffice to guarantee nuclear safety. They opted to [End Page 23] abandon nuclear energy entirely and invest in alternative and, as they imagined, less risky energy technologies.71\n\nConclusion\n\nThe history of nuclear energy can and should be analyzed as a history of water. Reinterpreting nuclear energy as a hydraulic technology, this article has shown that technologies traditionally considered as \"conventional\" or \"nonnuclear\" components are utterly critical for the operation and (un)safety of nuclear power plants. Through the mediation of these technologies, water shaped nuclear geographies, technological choices, safety concerns, and risk management practices. Nuclear power plant builders appropriated earlier hydraulic engineering traditions to produce electricity through the new, science-based technology of nuclear fission. Standing on the shoulders of their nonnuclear peers, however, nuclear hydraulic engineers did not always anticipate the resulting, unique dangers. This helps to explain why nuclear power plants have been prone to accidents.\n\nA wider implication of this study is that the history of technology has everything to gain from interaction with related scholarly fields—in this case water and environmental history. Such interaction can inspire new research questions, theories, and concepts, challenging mainstream interpretations of technologies, their making and unmaking, and their everyday lives. In our case, the strong relationship between nuclear safety considerations and historical (nonnuclear) risk management practices inspired a reinterpretation of numerous nuclear accidents and incidents as \"nuclear droughts\" and \"nuclear floods.\" It also inspired the exploration of nuclear siting dilemmas in relation to earlier river reengineering projects, the placement of cooling towers in the proud engineering tradition of water storage, and the notion of the hundred-year flood from a nuclear safety perspective. Moreover, thinking through nuclear energy history as a history of water forced a reconsideration of the exceptionalist view long dominating nuclear historiography. The water lens helped to show that the \"atomic age\" is essentially a hydraulic age, with strong cultural links to water-manipulating societies in the past—from ancient Mesopotamia to early industrial Europe. This integrates nuclear energy into a much longer and deeper history of human civilization. [End Page 24]"
    }
}